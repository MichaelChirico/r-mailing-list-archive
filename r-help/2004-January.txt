From v.demart at libero.it  Thu Jan  1 19:34:00 2004
From: v.demart at libero.it (v.demart@libero.it)
Date: Thu,  1 Jan 2004 19:34:00 +0100
Subject: [R] Barplot errors in MASS script
Message-ID: <HQTQ8O$42307DA111C610C93AA5CF2444DF075A@libero.it>

Reading "Modern Applied Statististics with S" and trying the corresponding
examples both in the book and in ../lib/R/library/MASS/script, I'm now trying
chapter 4 plotting bars with the following code on a linux box with R 1.8.1:
----------------------
library(MASS)
library(lattice)
options(echo=T, width=65, digits=5)
lung.deaths <- aggregate(ts.union(mdeaths, fdeaths), 1)
barplot(t(lung.deaths), names = dimnames(lung.deaths)[[1]],
        main = "UK deaths from lung disease")
if(interactive())
    legend(locator(1), c("Males", "Females"), fill = c(2, 3))
-----------------------

The legend doesn't look correct with respect to the picture at page 72 of the
book for two reasons:

1) The legend has a transparent background while in the book is "correctly"
opaque (and, above all, this is the background I expect!);

2) One of the two variables is represented in the legend with a different colour
from the same variable in the bars plot (green instead of yellow)

How could I set 1 and 2 right?

Thanks for your help

Vittorio



From sdavis2 at mail.nih.gov  Thu Jan  1 19:59:28 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 01 Jan 2004 13:59:28 -0500
Subject: [R] Segmentation fault with data.frame
Message-ID: <BC19D840.52B%sdavis2@mail.nih.gov>

All,

I have some code that I have been working on that crashes R (1.8.1 on MacOS
X installed from source).  Here are excerpts of the code and data
structures.  When the lists that I am using to construct the data.frame are
truncated (shortened), R catches the differing rows and warns.  However,
when the entire lists are used (I haven't looked for an exact breakpoint or
for a particular list value), segmentation fault occurs.  I suppose that I
could send individuals the data if that would help.

Thanks,
Sean
-- 
Sean Davis, M.D., Ph.D.
Clinical Fellow
Combined Pediatric Hematology/Oncology Fellowship
Johns Hopkins/National Institutes of Health
NHGRI/NCI
--



> str(b[1:20])
List of 20
 $ cHsKG501A10: chr "2"
 $ cHsKG501A11: NULL
 $ cHsKG501A12: chr "2"
 $ cHsKG501A2 : chr "16"
 $ cHsKG501A3 : chr "1"
 $ cHsKG501A4 : chr "19"
 $ cHsKG501A5 : chr "3"
 $ cHsKG501A6 : chr "2"
 $ cHsKG501A7 : chr "8"
 $ cHsKG501A8 : chr "7"
 $ cHsKG501A9 : NULL
 $ cHsKG501B1 : chr "17"
 $ cHsKG501B10: chr "5"
 $ cHsKG501B11: chr "X"
 $ cHsKG501B12: chr "9"
 $ cHsKG501B2 : chr "19"
 $ cHsKG501B3 : chr "16"
 $ cHsKG501B4 : chr "1"
 $ cHsKG501B5 : NULL
 $ cHsKG501B6 : chr "10"
> str(c[1:20])
 Named num [1:20]  1.20e+08        NA  9.79e+07 -4.99e+06 -1.53e+08 ...
 - attr(*, "names")= chr [1:20] "cHsKG501A10" "cHsKG501A11" "cHsKG501A12"
"cHsKG501A2" ...
> str(a[1:20])
List of 20
 $ cHsKG501A10: Named num 1.20e+08
  ..- attr(*, "names")= chr "2"
 $ cHsKG501A11: logi NA
 $ cHsKG501A12: Named num 97883920
  ..- attr(*, "names")= chr "2"
 $ cHsKG501A2 : Named num -4987429
  ..- attr(*, "names")= chr "16"
 $ cHsKG501A3 : Named num -1.53e+08
  ..- attr(*, "names")= chr "1"
 $ cHsKG501A4 : Named num 45948618
  ..- attr(*, "names")= chr "19"
 $ cHsKG501A5 : Named num 44876718
  ..- attr(*, "names")= chr "3"
 $ cHsKG501A6 : Named num -55212004
  ..- attr(*, "names")= chr "2"
 $ cHsKG501A7 : Named num 3.8e+07
  ..- attr(*, "names")= chr "8"
 $ cHsKG501A8 : Named num -99310824
  ..- attr(*, "names")= chr "7"
 $ cHsKG501A9 : logi NA
 $ cHsKG501B1 : Named num 38671548
  ..- attr(*, "names")= chr "17"
 $ cHsKG501B10: Named num -1.69e+08
  ..- attr(*, "names")= chr "5"
 $ cHsKG501B11: Named num 1.46e+08
  ..- attr(*, "names")= chr "X"
 $ cHsKG501B12: Named num 4975244
  ..- attr(*, "names")= chr "9"
 $ cHsKG501B2 : Named num -52426291
  ..- attr(*, "names")= chr "19"
 $ cHsKG501B3 : Named num -30493284
  ..- attr(*, "names")= chr "16"
 $ cHsKG501B4 : Named num -16827011
  ..- attr(*, "names")= chr "1"
 $ cHsKG501B5 : logi NA
 $ cHsKG501B6 : Named num -71546026
  ..- attr(*, "names")= chr "10"
> d <- a[1:20]
> e <- b[1:20]
> f <- c[1:20]
> df <- data.frame(t1=d,t2=e,t3=f)
Error in data.frame(cHsKG501A10 = "2", cHsKG501A11 = NULL, cHsKG501A12 =
"2",  : 
    arguments imply differing number of rows: 1, 0
> length(a)
[1] 11039
> length(b)
[1] 11039
> length(c)
[1] 11039
> d <- a[1:11039]
> e <- b[1:11039]
> f <- c[1:11039]
> df <- data.frame(t1=d,t2=e,t3=f)

Process R segmentation fault at Thu Jan  1 13:45:55 2004



From ligges at statistik.uni-dortmund.de  Thu Jan  1 20:09:52 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 01 Jan 2004 20:09:52 +0100
Subject: [R] Barplot errors in MASS script
In-Reply-To: <HQTQ8O$42307DA111C610C93AA5CF2444DF075A@libero.it>
References: <HQTQ8O$42307DA111C610C93AA5CF2444DF075A@libero.it>
Message-ID: <3FF47080.6060703@statistik.uni-dortmund.de>

v.demart at libero.it wrote:
> Reading "Modern Applied Statististics with S" and trying the corresponding
> examples both in the book and in ../lib/R/library/MASS/script, I'm now trying
> chapter 4 plotting bars with the following code on a linux box with R 1.8.1:
> ----------------------
> library(MASS)
> library(lattice)
> options(echo=T, width=65, digits=5)
> lung.deaths <- aggregate(ts.union(mdeaths, fdeaths), 1)
> barplot(t(lung.deaths), names = dimnames(lung.deaths)[[1]],
>         main = "UK deaths from lung disease")
> if(interactive())
>     legend(locator(1), c("Males", "Females"), fill = c(2, 3))
> -----------------------
> 
> The legend doesn't look correct with respect to the picture at page 72 of the
> book for two reasons:
> 
> 1) The legend has a transparent background while in the book is "correctly"
> opaque (and, above all, this is the background I expect!);

Set the  argument bg = "white"


> 2) One of the two variables is represented in the legend with a different colour
> from the same variable in the bars plot (green instead of yellow)

Use heat.colors() (barplot() uses it to generate the colors).


> How could I set 1 and 2 right?

   legend(locator(1), c("Males", "Females"), fill = heat.colors(2),
       bg = "white")



That points us to a documentation bug in ?legend, whioch tells us in its 
Arguments section:

bg  the background color for the legend box. (Note that this is only 
used if bty = "n".)

Obviously, it is used if bty = "o", but *not* if "n".


Uwe Ligges



> Thanks for your help
> 
> Vittorio
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From fredrik.lundgren at norrkoping.mail.telia.com  Thu Jan  1 21:04:41 2004
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Thu, 1 Jan 2004 21:04:41 +0100
Subject: [R] force fixed format
Message-ID: <00e701c3d0a2$84d903c0$2d0ffea9@oemcomputer>

Hello,
A small problem I can't solve

 > p <- 0.0001
> p
[1] 1e-04

How can I force the printout of p to 0.0001?
I have tried 'format', 'round', 'signif', 'print' in different combinations without success.
                      
Fredrik Lundgren



From gb at stat.umu.se  Thu Jan  1 21:37:15 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 1 Jan 2004 21:37:15 +0100
Subject: [R] force fixed format
In-Reply-To: <00e701c3d0a2$84d903c0$2d0ffea9@oemcomputer>
References: <00e701c3d0a2$84d903c0$2d0ffea9@oemcomputer>
Message-ID: <20040101203715.GA32025@stat.umu.se>

On Thu, Jan 01, 2004 at 09:04:41PM +0100, Fredrik Lundgren wrote:
> Hello,
> A small problem I can't solve
> 
>  > p <- 0.0001
> > p
> [1] 1e-04
> 
> How can I force the printout of p to 0.0001?
> I have tried 'format', 'round', 'signif', 'print' in different combinations without success.

You may check 'formatC':

> formatC(p)
[1] "0.0001"
-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From jfox at mcmaster.ca  Thu Jan  1 22:12:56 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 01 Jan 2004 16:12:56 -0500
Subject: [R] force fixed format
In-Reply-To: <00e701c3d0a2$84d903c0$2d0ffea9@oemcomputer>
Message-ID: <5.1.0.14.2.20040101161032.0203a1f0@127.0.0.1>

At 09:04 PM 1/1/2004 +0100, Fredrik Lundgren wrote:
>Hello,
>A small problem I can't solve
>
>  > p <- 0.0001
> > p
>[1] 1e-04
>
>How can I force the printout of p to 0.0001?
>I have tried 'format', 'round', 'signif', 'print' in different 
>combinations without success.
>

If the issue is general, try the scipen option:

 > options(scipen=10)
 > p <- 0.0001
 > p
[1] 0.0001

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From jadhavpr at vcu.edu  Thu Jan  1 23:52:55 2004
From: jadhavpr at vcu.edu (Pravin)
Date: Thu, 1 Jan 2004 17:52:55 -0500
Subject: [R] force fixed format
In-Reply-To: <00e701c3d0a2$84d903c0$2d0ffea9@oemcomputer>
Message-ID: <000001c3d0b9$fec64640$0200a8c0@Pravin>

formatC(p,format="fg")
or
formatC(p,format="f",digits=#)

#-specify number of digits

should do the job.


 
Pravin
 
Pravin Jadhav

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Fredrik Lundgren
Sent: Thursday, January 01, 2004 3:05 PM
To: R-help
Subject: [R] force fixed format

Hello,
A small problem I can't solve

 > p <- 0.0001
> p
[1] 1e-04

How can I force the printout of p to 0.0001?
I have tried 'format', 'round', 'signif', 'print' in different combinations
without success.
                      
Fredrik Lundgren

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From adavies at ideaglobal.com  Fri Jan  2 09:29:15 2004
From: adavies at ideaglobal.com (Ashley Davies)
Date: Fri, 02 Jan 2004 16:29:15 +0800
Subject: [R] Importing Excel/Openoffice Dates into R
Message-ID: <3FF52BDB.501@ideaglobal.com>

Hi,

I would like to import some daily financial data from excel via csv. 
More specifically, I would like to be able to use the ts.union function 
from the tseries library as the dates are irregular and I need to line 
up the dates so that I can place all the variables into one data frame.

The trouble is, how do I import the dates from excel into R? At the 
moment I'm just importing the data via read.csv, but I don't know how to 
bring the dates in as well.

Example: Here are two csv files.  The first file is missing Jan 13th and 
  the second is missing the 8th.

file 1: cboevix.csv
	          VIX
1/1/1999	24.42
1/4/1999	26.17
1/5/1999	24.46
1/6/1999	23.34
1/7/1999	24.37
1/8/1999	23.28
1/11/1999	25.46
1/12/1999	28.1
1/14/1999	32.98

file 2: yenv.csv

		YENV
1/1/1999	19.5
1/4/1999	22.2
1/5/1999	23.2
1/6/1999	21
1/7/1999	20.2
1/11/1999	21.6
1/12/1999	20.9
1/13/1999	19.1
1/14/1999	19.3

# Read the files in via read.csv
A<-read.csv("cboevix.csv",skip=1,header=FALSE)
B<-read.csv("yenv.csv",skip=1,header=FALSE)

#define variables
VIX<-A$V2
YENV<-B$V2

# MISSING STEP!
#apply dates from original csv files to the variables.
#the dates are stilling sitting in A$V1 and B$V1
#how do I apply them to VIX and YENV?
#????

#use ts.union function to line up the dates and create data frame 
#"vixyen" with lined up data

vixyen<-ts.union(VIX,YENV)

Can anyone help me fill in those missing steps?  Thanks very much!

Cheers,

-- 
Ashley Davies
Economist- Australia and New Zealand
IDEAglobal - Singapore
Tel: 65- 6332-0759
Fax: 65- 6332-0701
adavies at ideaglobal.com



From ripley at stats.ox.ac.uk  Fri Jan  2 10:10:21 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 Jan 2004 09:10:21 +0000 (GMT)
Subject: [R] Importing Excel/Openoffice Dates into R
In-Reply-To: <3FF52BDB.501@ideaglobal.com>
Message-ID: <Pine.LNX.4.44.0401020854260.18288-100000@gannet.stats>

I am puzzled: `csv' means `comma-separated values' and those files have no 
commas in them.  You could use

A <- read.table("cboevix.csv")
B <- read.table("yenv.csv")

which looks better.  You can then merge the two dfs by

> (AB <- merge(A, B, by="row.names", all=T))
   Row.names   VIX YENV
1   1/1/1999 24.42 19.5
2  1/11/1999 25.46 21.6
3  1/12/1999 28.10 20.9
4  1/14/1999 32.98 19.3
5   1/4/1999 26.17 22.2
6   1/5/1999 24.46 23.2
7   1/6/1999 23.34 21.0
8   1/7/1999 24.37 20.2
9   1/8/1999 23.28   NA
10 1/13/1999    NA 19.1

and then convert to R's date format by 

Date <- as.POSIXct(strptime(as.character(AB$Row.names), "%m/%d/%Y"))
row.names(AB) <- Date
AB <- AB[sort.list(Date),-1]
AB
             VIX YENV
1999-01-01 24.42 19.5
1999-01-04 26.17 22.2
1999-01-05 24.46 23.2
1999-01-06 23.34 21.0
1999-01-07 24.37 20.2
1999-01-08 23.28   NA
1999-01-11 25.46 21.6
1999-01-12 28.10 20.9
1999-01-13    NA 19.1
1999-01-14 32.98 19.3

Second, as ts.union is not part of tseries, and is for regular time series
I don't see how you hoped to use it.  You could for example use

irts(row.names(AB), as.matrix(AB))

to create an object of class "irts", or you could use the `its' package
from CRAN (which is what I would use).



On Fri, 2 Jan 2004, Ashley Davies wrote:

> Hi,
> 
> I would like to import some daily financial data from excel via csv. 
> More specifically, I would like to be able to use the ts.union function 
> from the tseries library as the dates are irregular and I need to line 
> up the dates so that I can place all the variables into one data frame.
> 
> The trouble is, how do I import the dates from excel into R? At the 
> moment I'm just importing the data via read.csv, but I don't know how to 
> bring the dates in as well.
> 
> Example: Here are two csv files.  The first file is missing Jan 13th and 
>   the second is missing the 8th.
> 
> file 1: cboevix.csv
> 	          VIX
> 1/1/1999	24.42
> 1/4/1999	26.17
> 1/5/1999	24.46
> 1/6/1999	23.34
> 1/7/1999	24.37
> 1/8/1999	23.28
> 1/11/1999	25.46
> 1/12/1999	28.1
> 1/14/1999	32.98
> 
> file 2: yenv.csv
> 
> 		YENV
> 1/1/1999	19.5
> 1/4/1999	22.2
> 1/5/1999	23.2
> 1/6/1999	21
> 1/7/1999	20.2
> 1/11/1999	21.6
> 1/12/1999	20.9
> 1/13/1999	19.1
> 1/14/1999	19.3
> 
> # Read the files in via read.csv
> A<-read.csv("cboevix.csv",skip=1,header=FALSE)
> B<-read.csv("yenv.csv",skip=1,header=FALSE)
> 
> #define variables
> VIX<-A$V2
> YENV<-B$V2
> 
> # MISSING STEP!
> #apply dates from original csv files to the variables.
> #the dates are stilling sitting in A$V1 and B$V1
> #how do I apply them to VIX and YENV?
> #????
> 
> #use ts.union function to line up the dates and create data frame 
> #"vixyen" with lined up data
> 
> vixyen<-ts.union(VIX,YENV)
> 
> Can anyone help me fill in those missing steps?  Thanks very much!
> 
> Cheers,
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Fri Jan  2 10:22:55 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Jan 2004 10:22:55 +0100
Subject: [R] Importing Excel/Openoffice Dates into R
In-Reply-To: <3FF52BDB.501@ideaglobal.com>
References: <3FF52BDB.501@ideaglobal.com>
Message-ID: <x2d6a2ogb4.fsf@biostat.ku.dk>

Ashley Davies <adavies at ideaglobal.com> writes:

> Hi,
> 
> I would like to import some daily financial data from excel via csv.
> More specifically, I would like to be able to use the ts.union
> function from the tseries library as the dates are irregular and I
> need to line up the dates so that I can place all the variables into
> one data frame.
> 
> The trouble is, how do I import the dates from excel into R? At the
> moment I'm just importing the data via read.csv, but I don't know how
> to bring the dates in as well.
> 
> Example: Here are two csv files.  The first file is missing Jan 13th
> and the second is missing the 8th.
> 
> file 1: cboevix.csv
> 	          VIX
> 1/1/1999	24.42
> 1/4/1999	26.17
> 1/5/1999	24.46
> 1/6/1999	23.34
> 1/7/1999	24.37
> 1/8/1999	23.28
> 1/11/1999	25.46
> 1/12/1999	28.1
> 1/14/1999	32.98
> 
> file 2: yenv.csv
> 
> 		YENV
> 1/1/1999	19.5
> 1/4/1999	22.2
> 1/5/1999	23.2
> 1/6/1999	21
> 1/7/1999	20.2
> 1/11/1999	21.6
> 1/12/1999	20.9
> 1/13/1999	19.1
> 1/14/1999	19.3

Umm, those are not the exact contents, are they? CSV==comma-separated-variable

There should be commas between columns or a sep="\t" in the
read.csv(), (or use read.delim() for what it was designed for). 
 
> # Read the files in via read.csv
> A<-read.csv("cboevix.csv",skip=1,header=FALSE)
> B<-read.csv("yenv.csv",skip=1,header=FALSE)
> 
> #define variables
> VIX<-A$V2
> YENV<-B$V2

(why not just change the names() of A and B?)

> # MISSING STEP!
> #apply dates from original csv files to the variables.
> #the dates are stilling sitting in A$V1 and B$V1
> #how do I apply them to VIX and YENV?
> #????

help(strptime) would be the obvious place to start. The read.csv (or
whatever) also have the colClasses argument that you can use to
specify arbitrary conversion of inputs, but it seems like overkill in
this case.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From marwan.khawaja at aub.edu.lb  Thu Jan  1 17:28:54 2004
From: marwan.khawaja at aub.edu.lb (Marwan Khawaja)
Date: Thu, 1 Jan 2004 11:28:54 -0500
Subject: [R] ade4
Message-ID: <CLECJBOEBGOMOKJHJNDAGEFBDIAA.marwan.khawaja@aub.edu.lb>

Dear All,
I am using the scatter.dudi finction in the 'ade4' package to produce
correspondence analysis (nice) plots.
I do not seem to figure out how to plot the raw coordinates only -- or column
coordinates only.  I would appreciate any help in doing that.
Here is the example I am following -- from the package.

data(banque)
>      banque.acm <- dudi.acm(banque, scann = FALSE, nf = 3)
>      scatter.dudi(banque.acm)

Using,
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    8.1
year     2003
month    11
day      21
language R

TIA, Marwan

-------------------------------------------------------------------
Marwan Khawaja         http://departments.aub.edu.lb/~mk36



From adavies at ideaglobal.com  Fri Jan  2 10:55:57 2004
From: adavies at ideaglobal.com (Ashley Davies)
Date: Fri, 02 Jan 2004 17:55:57 +0800
Subject: [R] Importing Excel/Openoffice Dates into R
In-Reply-To: <Pine.LNX.4.44.0401020854260.18288-100000@gannet.stats>
References: <Pine.LNX.4.44.0401020854260.18288-100000@gannet.stats>
Message-ID: <3FF5402D.5000507@ideaglobal.com>

/"I am puzzled: `csv' means `comma-separated values' and those files 
have no
commas in them. You could use"
/
Yes sorry about that. The data posted was from the original csv files. I 
just copy and pasted a subsection from the spreadsheet as an example.

/"(AB <- merge(A, B, by="row.names", all=T))"/

I did a "?merge" in R, and it said that this was for two dataframes. I 
would like to find a more general solution for a large number of 
variables with different dates. Financial time series dates are often 
dictated by the holidays of the respective stock/futures exchanges. This 
is a common problem I face.

/"Date <- as.POSIXct(strptime(as.character(AB$Row.names), "%m/%d/%Y"))
row.names(AB) <- Date
AB <- AB[sort.list(Date),-1]
AB"

/That looks like something I could use.

/"Second, as ts.union is not part of tseries, and is for regular time 
series. I don't see how you hoped to use it."
/
I was inspired by the "get.hist.quote" function. From the help file for 
"get.hist.quote"


x <- get.hist.quote(instrument = "^spc", start = "1998-01-01",
quote = "Close")
plot(x)

x <- get.hist.quote(instrument = "ibm", quote = c("Cl", "Vol"))
plot(x, main = "International Business Machines Corp")

spc <- get.hist.quote(instrument = "^spc", start = "1998-01-01")
ibm <- get.hist.quote(instrument = "ibm", start = "1998-01-01")
x <- na.remove(ts.union(spc, ibm))
plot(x, main = "IBM vs S&P 500")


This example, downloads the data from yahoo, lines up the dates, and 
removes any NAs. I would like to be able to do the same for data that I 
have downloaded in my excel from a Reuters or Bloomberg terminal. I will 
play around further with what you have suggested later on tonight, and 
see if I can post back a solution. I'm in Singapore and at the end of 
the working day.

Thanks for your help.

Ashley

Prof Brian Ripley wrote:

>I am puzzled: `csv' means `comma-separated values' and those files have no 
>commas in them.  You could use
>
>A <- read.table("cboevix.csv")
>B <- read.table("yenv.csv")
>
>which looks better.  You can then merge the two dfs by
>
>  
>
>>(AB <- merge(A, B, by="row.names", all=T))
>>    
>>
>   Row.names   VIX YENV
>1   1/1/1999 24.42 19.5
>2  1/11/1999 25.46 21.6
>3  1/12/1999 28.10 20.9
>4  1/14/1999 32.98 19.3
>5   1/4/1999 26.17 22.2
>6   1/5/1999 24.46 23.2
>7   1/6/1999 23.34 21.0
>8   1/7/1999 24.37 20.2
>9   1/8/1999 23.28   NA
>10 1/13/1999    NA 19.1
>
>and then convert to R's date format by 
>
>Date <- as.POSIXct(strptime(as.character(AB$Row.names), "%m/%d/%Y"))
>row.names(AB) <- Date
>AB <- AB[sort.list(Date),-1]
>AB
>             VIX YENV
>1999-01-01 24.42 19.5
>1999-01-04 26.17 22.2
>1999-01-05 24.46 23.2
>1999-01-06 23.34 21.0
>1999-01-07 24.37 20.2
>1999-01-08 23.28   NA
>1999-01-11 25.46 21.6
>1999-01-12 28.10 20.9
>1999-01-13    NA 19.1
>1999-01-14 32.98 19.3
>
>Second, as ts.union is not part of tseries, and is for regular time series
>I don't see how you hoped to use it.  You could for example use
>
>irts(row.names(AB), as.matrix(AB))
>
>to create an object of class "irts", or you could use the `its' package
>from CRAN (which is what I would use).
>
>
>
>On Fri, 2 Jan 2004, Ashley Davies wrote:
>
>  
>
>>Hi,
>>
>>I would like to import some daily financial data from excel via csv. 
>>More specifically, I would like to be able to use the ts.union function 
>>from the tseries library as the dates are irregular and I need to line 
>>up the dates so that I can place all the variables into one data frame.
>>
>>The trouble is, how do I import the dates from excel into R? At the 
>>moment I'm just importing the data via read.csv, but I don't know how to 
>>bring the dates in as well.
>>
>>Example: Here are two csv files.  The first file is missing Jan 13th and 
>>  the second is missing the 8th.
>>
>>file 1: cboevix.csv
>>	          VIX
>>1/1/1999	24.42
>>1/4/1999	26.17
>>1/5/1999	24.46
>>1/6/1999	23.34
>>1/7/1999	24.37
>>1/8/1999	23.28
>>1/11/1999	25.46
>>1/12/1999	28.1
>>1/14/1999	32.98
>>
>>file 2: yenv.csv
>>
>>		YENV
>>1/1/1999	19.5
>>1/4/1999	22.2
>>1/5/1999	23.2
>>1/6/1999	21
>>1/7/1999	20.2
>>1/11/1999	21.6
>>1/12/1999	20.9
>>1/13/1999	19.1
>>1/14/1999	19.3
>>
>># Read the files in via read.csv
>>A<-read.csv("cboevix.csv",skip=1,header=FALSE)
>>B<-read.csv("yenv.csv",skip=1,header=FALSE)
>>
>>#define variables
>>VIX<-A$V2
>>YENV<-B$V2
>>
>># MISSING STEP!
>>#apply dates from original csv files to the variables.
>>#the dates are stilling sitting in A$V1 and B$V1
>>#how do I apply them to VIX and YENV?
>>#????
>>
>>#use ts.union function to line up the dates and create data frame 
>>#"vixyen" with lined up data
>>
>>vixyen<-ts.union(VIX,YENV)
>>
>>Can anyone help me fill in those missing steps?  Thanks very much!
>>
>>Cheers,
>>
>>
>>    
>>
>
>  
>


-- 
Ashley Davies
Economist- Australia and New Zealand
IDEAglobal - Singapore
Tel: 65- 6332-0759
Fax: 65- 6332-0701
adavies at ideaglobal.com



From ripley at stats.ox.ac.uk  Fri Jan  2 11:23:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 Jan 2004 10:23:01 +0000 (GMT)
Subject: [R] Importing Excel/Openoffice Dates into R
In-Reply-To: <3FF5402D.5000507@ideaglobal.com>
Message-ID: <Pine.LNX.4.44.0401021012570.30645-100000@gannet.stats>

On Fri, 2 Jan 2004, Ashley Davies wrote:

> /"I am puzzled: `csv' means `comma-separated values' and those files 
> have no
> commas in them. You could use"
> /
> Yes sorry about that. The data posted was from the original csv files. I 
> just copy and pasted a subsection from the spreadsheet as an example.
> 
> /"(AB <- merge(A, B, by="row.names", all=T))"/
> 
> I did a "?merge" in R, and it said that this was for two dataframes. I 
> would like to find a more general solution for a large number of 
> variables with different dates. Financial time series dates are often 
> dictated by the holidays of the respective stock/futures exchanges. This 
> is a common problem I face.

merge() *is* the general solution: just apply it recursively.

> /"Date <- as.POSIXct(strptime(as.character(AB$Row.names), "%m/%d/%Y"))
> row.names(AB) <- Date
> AB <- AB[sort.list(Date),-1]
> AB"
> 
> /That looks like something I could use.
> 
> /"Second, as ts.union is not part of tseries, and is for regular time 
> series. I don't see how you hoped to use it."
> /
> I was inspired by the "get.hist.quote" function. From the help file for 
> "get.hist.quote"
> 
> 
> x <- get.hist.quote(instrument = "^spc", start = "1998-01-01",
> quote = "Close")
> plot(x)
> 
> x <- get.hist.quote(instrument = "ibm", quote = c("Cl", "Vol"))
> plot(x, main = "International Business Machines Corp")
> 
> spc <- get.hist.quote(instrument = "^spc", start = "1998-01-01")
> ibm <- get.hist.quote(instrument = "ibm", start = "1998-01-01")
> x <- na.remove(ts.union(spc, ibm))
> plot(x, main = "IBM vs S&P 500")

This no longer works for me, BTW.

> This example, downloads the data from yahoo, lines up the dates, and 

It doesn't.  It relies on those being regular series once get.hist.quote 
has finished with them.  Take a closer look at get.hist.quote.

> removes any NAs. I would like to be able to do the same for data that I 
> have downloaded in my excel from a Reuters or Bloomberg terminal. I will 
> play around further with what you have suggested later on tonight, and 
> see if I can post back a solution. I'm in Singapore and at the end of 
> the working day.

If you want a regular daily series with all non-trading days as NAs then 
the way get.hist.quote does it is the way forward.  But that is not what 
you said you wanted ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From edd at debian.org  Fri Jan  2 15:24:37 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 2 Jan 2004 08:24:37 -0600
Subject: [R] Importing Excel/Openoffice Dates into R
In-Reply-To: <3FF52BDB.501@ideaglobal.com>
References: <3FF52BDB.501@ideaglobal.com>
Message-ID: <20040102142437.GA4537@sonny.eddelbuettel.com>

On Fri, Jan 02, 2004 at 04:29:15PM +0800, Ashley Davies wrote:
> I would like to import some daily financial data from excel via csv. 
> More specifically, I would like to be able to use the ts.union function 
> from the tseries library as the dates are irregular and I need to line 
> up the dates so that I can place all the variables into one data frame.

In short, you cannot. The ts objects require _regular_ time series with
fixed increments or frequencies. This works great for annual, quarterly or
monthly macroeconomic series, but is much more difficult for business-daily
data with weekends, holidays and all that.

What you really want is the its package now on CRAN. It provides an object
for _irregular_ time series', as for example business or market daily
series. You can then subset, join, intersect, ... at will. This uses the
very powerful data arithmetic features which R contains, but shields a lot
of the at-first somewhat intimidating complexity of the datetime objects.
Its is a real gem. And do search the archives for this list. There have been
many usage examples for its, often provided directly by the most helpful
author of its, and some contain examples starting from csv files.

Good luck,  Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From patrick.giraudoux at univ-fcomte.fr  Fri Jan  2 15:29:56 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Fri, 2 Jan 2004 15:29:56 +0100
Subject: [R] bwplot and panel.bwplot
Message-ID: <018b01c3d13d$33285f80$5e9c0c50@PC728329681112>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040102/d2dd13b1/attachment.ksh

From dray at biomserv.univ-lyon1.fr  Fri Jan  2 16:52:34 2004
From: dray at biomserv.univ-lyon1.fr (Stephane DRAY)
Date: Fri, 02 Jan 2004 16:52:34 +0100
Subject: [R] ade4
In-Reply-To: <CLECJBOEBGOMOKJHJNDAGEFBDIAA.marwan.khawaja@aub.edu.lb>
Message-ID: <5.2.1.1.0.20040102165116.00b2ccc8@biomserv.univ-lyon1.fr>

You can try:

s.label(banque.acm$li)

s.arrow(banque.acm$c1)



At 17:28 01/01/2004, Marwan Khawaja wrote:
>Dear All,
>I am using the scatter.dudi finction in the 'ade4' package to produce
>correspondence analysis (nice) plots.
>I do not seem to figure out how to plot the raw coordinates only -- or column
>coordinates only.  I would appreciate any help in doing that.
>Here is the example I am following -- from the package.
>
>data(banque)
> >      banque.acm <- dudi.acm(banque, scann = FALSE, nf = 3)
> >      scatter.dudi(banque.acm)
>
>Using,
>platform i386-pc-mingw32
>arch     i386
>os       mingw32
>system   i386, mingw32
>status
>major    1
>minor    8.1
>year     2003
>month    11
>day      21
>language R
>
>TIA, Marwan
>
>-------------------------------------------------------------------
>Marwan Khawaja         http://departments.aub.edu.lb/~mk36
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

St?phane DRAY
-------------------------------------------------------------------------------------------------- 

D?partement des Sciences Biologiques
Universit? de Montr?al, C.P. 6128, succursale centre-ville
Montr?al, Qu?bec H3C 3J7, Canada

Tel : 514 343 6111 poste 1233
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From brahm at alum.mit.edu  Fri Jan  2 17:52:28 2004
From: brahm at alum.mit.edu (David Brahm)
Date: Fri, 2 Jan 2004 11:52:28 -0500
Subject: [R] force fixed format
References: <5.1.0.14.2.20040101161032.0203a1f0@127.0.0.1>
Message-ID: <16373.41420.942531.346349@arbres1a.fmr.com>

John Fox wrote:
> If the issue [of suppressing scientific notation] is general, try the scipen
> option:
>  > options(scipen=10)
>  > p <- 0.0001
>  > p
> [1] 0.0001

To explain further: R normally prints in scientific notation if it requires
fewer characters than standard notation.  By setting options(scipen=10), you
are imposing an addition 10-character SCIentific notation PENalty whenever this
comparison is made.  Negative values would favor scientific notation.
-- 
                              -- David Brahm (brahm at alum.mit.edu)



From kasia at darwin.epbi.cwru.edu  Fri Jan  2 18:49:41 2004
From: kasia at darwin.epbi.cwru.edu (Catherine Stein)
Date: Fri, 02 Jan 2004 12:49:41 -0500 (EST)
Subject: [R] SEM help!!!
Message-ID: <Pine.OSF.4.30.0401021246580.118054-100000@darwin.epbi.cwru.edu>


I have just started using the SEM package in R, so I'm not sure I'm doing
everything right, but I keep getting an error concerning startvalues and I
can't figure out how to fix it.  Is anyone willing to read over my code
and help me out??? Please email me if you are willing to look at my code
and I will send it to you.

Thank you so much, and Happy New Year!

cathy

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Catherine M. Stein
Research Assistant, Tuberculosis Research Unit
Doctoral Candidate in Genetic Epidemiology
Department of Epidemiology and Biostatistics
Case Western Reserve University
office: (216)368-0875 or (216)778-1378
e-mail: kasia at darwin.cwru.edu, or cmstein at cwru.edu

EPBI Student Resources Page:
http://hal.epbi.cwru.edu/stures/
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From jfox at mcmaster.ca  Fri Jan  2 18:59:32 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 02 Jan 2004 12:59:32 -0500
Subject: [R] SEM help!!!
In-Reply-To: <Pine.OSF.4.30.0401021246580.118054-100000@darwin.epbi.cwru .edu>
Message-ID: <5.1.0.14.2.20040102125620.02036818@127.0.0.1>

Dear Catherine,

The most common user error that I've encountered is the omission of 
error-variance terms from the model (for both measurement errors and 
structural disturbances).

If this isn't the source of your difficulty, then send me the code along 
with an explanation of what you're trying to do (e.g., a path diagram) and 
I'll take a look at it.

I'm sorry that you're experiencing problems.
  John

At 12:49 PM 1/2/2004 -0500, Catherine Stein wrote:

>I have just started using the SEM package in R, so I'm not sure I'm doing
>everything right, but I keep getting an error concerning startvalues and I
>can't figure out how to fix it.  Is anyone willing to read over my code
>and help me out??? Please email me if you are willing to look at my code
>and I will send it to you.
>
>Thank you so much, and Happy New Year!
>
>cathy

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From spencer.graves at pdf.com  Fri Jan  2 19:23:13 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 02 Jan 2004 10:23:13 -0800
Subject: [R] SEM help!!!
In-Reply-To: <Pine.OSF.4.30.0401021246580.118054-100000@darwin.epbi.cwru.edu>
References: <Pine.OSF.4.30.0401021246580.118054-100000@darwin.epbi.cwru.edu>
Message-ID: <3FF5B711.8030408@pdf.com>

Can you get a simlified model to work?  If yes, have you tried adding 
one parameter at a time, using previous parameters as starting values? 

hope this helps.  spencer graves

Catherine Stein wrote:

>I have just started using the SEM package in R, so I'm not sure I'm doing
>everything right, but I keep getting an error concerning startvalues and I
>can't figure out how to fix it.  Is anyone willing to read over my code
>and help me out??? Please email me if you are willing to look at my code
>and I will send it to you.
>
>Thank you so much, and Happy New Year!
>
>cathy
>
>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>Catherine M. Stein
>Research Assistant, Tuberculosis Research Unit
>Doctoral Candidate in Genetic Epidemiology
>Department of Epidemiology and Biostatistics
>Case Western Reserve University
>office: (216)368-0875 or (216)778-1378
>e-mail: kasia at darwin.cwru.edu, or cmstein at cwru.edu
>
>EPBI Student Resources Page:
>http://hal.epbi.cwru.edu/stures/
>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From patrick.giraudoux at univ-fcomte.fr  Fri Jan  2 22:49:48 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Fri, 2 Jan 2004 22:49:48 +0100
Subject: [R] type III sum of squares - ssType
Message-ID: <003901c3d17a$78bfd900$c831fac1@PC728329681112>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040102/3dfb47b9/attachment.ksh

From JLee at acamllc.com  Sat Jan  3 00:09:51 2004
From: JLee at acamllc.com (Jeff Lee)
Date: Fri, 2 Jan 2004 18:09:51 -0500 
Subject: [R] (no subject)
Message-ID: <71E1B4F35918D31184290008C74560C33CB725@ANUBIS>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040102/53fa5a08/attachment.ksh

From jfox at mcmaster.ca  Sat Jan  3 00:14:12 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 02 Jan 2004 18:14:12 -0500
Subject: [R] type III sum of squares - ssType
In-Reply-To: <003901c3d17a$78bfd900$c831fac1@PC728329681112>
Message-ID: <5.1.0.14.2.20040102181315.01fef700@127.0.0.1>

Dear Patrick,

The Anova function in the car package may do what you want (but be careful 
with contrast coding).

I hope that this helps,
  John

At 10:49 PM 1/2/2004 +0100, Patrick Giraudoux wrote:
>Hello,
>
>It seems that, unlike Splus, the anova.lm function of R does not take the 
>argument ssType=3 into account. How can one get an anova table with the 
>adjusted sum of squares in R?
>
>Thanks in advance,
>
>Patrick Giraudoux

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From mjcohen at acm.org  Sat Jan  3 06:45:38 2004
From: mjcohen at acm.org (Martin Cohen)
Date: Fri, 02 Jan 2004 21:45:38 -0800
Subject: [R] R doesn't run on g4 iBook with Panther 
Message-ID: <3FF65702.9040108@acm.org>

I have a 12" G4 iBook with the latest os (Panther) with the recent 
updates. When I start R by double clicking, it expands for a fraction of 
a second and then, nothing happens.

There is mention in the readme about using something called "i-install" 
to uninstall a mistakenly installed library, but I do not know how to do 
this.

Any help would be appreciated.

Thanks,

Martin Cohen
mjcohen at acm.org



From maechler at stat.math.ethz.ch  Sat Jan  3 13:47:14 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 3 Jan 2004 13:47:14 +0100
Subject: [R] error "evaluation nested too deeply" {was "Heatmap"}
In-Reply-To: <5.2.0.9.0.20040102100242.00bad230@kiev.biotech.kth.se>
References: <5.2.0.9.0.20040102100242.00bad230@kiev.biotech.kth.se>
Message-ID: <16374.47570.442802.779935@gargle.gargle.HOWL>

I'm diverting this to the more appropriate mailing list, R-help,
since heatmap() is standard R function.

>>>>> "Johan" == Johan Lindberg <johanl at kiev.biotech.kth.se>
>>>>>     on Fri, 02 Jan 2004 10:04:14 +0100 writes:

    Johan> I am trying to plot a matrix of m-values in a heatmap
    Johan> with "average linkage". The rows are M-values of
    Johan> genes and the columns are my slides.  I do the
    Johan> following and get the following error message:

    >> heatmap(Matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram(sclus),col=rbg)

    Johan>  Error in match.fun(FUN) : evaluation is
    Johan> nested too deeply: infinite recursion?  Error:
    Johan> evaluation is nested too deeply: infinite recursion?

The problem happens when trying to plot a large dendrogram.
The "dendrogam" class is implemented as an S-level "tree", i.e.,
a nested list  and plot.dendrogram() uses recursion for
plotting.

To avoid infinite recursion (which would typically "freeze" your
computer), there's a limit in R (and S),
	   options(expressions = 500)

for how deeply recursions are allowed
to go.  The limit is currently too low for the typical
dendrograms that people consider in microarray analysis of
several thousand genes.
Setting
	options(expressions = 10000)
should solve the problems for these data sizes.

[when replying to this, please do *drop*  bioconductor at .. now;  it's a n R topic]

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From lap0t at yandex.ru  Sat Jan  3 15:54:21 2004
From: lap0t at yandex.ru (Eugenij P. Altshuler)
Date: Sat, 3 Jan 2004 17:54:21 +0300
Subject: [R]: isoMDS using
Message-ID: <009301c3d209$7a823c80$cb8017d9@m6h4m4>

Happy New Year!

I tried to use isoMDS to present graphically matrix of coefficients of
divergence, and I
have seen error "NAs/Infs not allowed in d".

But there no NAs or Inf's in my matrix!
Function `as.vector' (which is applied to test input data with
`!is.finite' ) returns in one case input matrix and in other case returns
sequence of values of input matrix. When it returns matrix I  receive error
"NAs/Infs not allowed in d". When it returns sequence
of values I don't receive this error.

Is it possible to use coefficients of divergence instead dissimilarity?

Thank you!!

-------------------
Altshuler Eugenij P.
Moscow South-West High School
mailto:lap0t at yandex.ru



From sherry_forbes at hotmail.com  Sat Jan  3 20:27:41 2004
From: sherry_forbes at hotmail.com (Sherry Forbes)
Date: Sat, 3 Jan 2004 19:27:41 -0000
Subject: [R] (no subject)
Message-ID: <000a01c3d22f$a7825be0$b2e901a3@SANT141801>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040103/c396f5d7/attachment.pl

From andrewr at uidaho.edu  Sat Jan  3 20:42:29 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Sat, 3 Jan 2004 11:42:29 -0800
Subject: [R] R doesn't run on g4 iBook with Panther 
Message-ID: <200401031142.29767.andrewr@uidaho.edu>

Martin,

check the Console application for error messages.  They will help you/us 
diagnose the problem.  During my installation I observed similar behavior, 
only to discover that I had yet to install the libreadline package from the 
download.  

Andrew
-- 
Andrew Robinson                      Ph: 208 885 7115
Department of Forest Resources       Fa: 208 885 6226
University of Idaho                  E : andrewr at uidaho.edu
PO Box 441133                        W : http://www.uidaho.edu/~andrewr
Moscow ID 83843                      Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From spencer.graves at pdf.com  Sat Jan  3 22:28:28 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 03 Jan 2004 13:28:28 -0800
Subject: [R] (no subject)
In-Reply-To: <000a01c3d22f$a7825be0$b2e901a3@SANT141801>
References: <000a01c3d22f$a7825be0$b2e901a3@SANT141801>
Message-ID: <3FF733FC.3080906@pdf.com>

      What do you want to simulate?  Have you looked at "help.start()" 
-> "An introduction to R" -> "probability distributions"?  This contains 
a list of standard distributions with the comment, "Prefix the name 
given here by d for the density, p for the CDF, q for the quantile 
function and r for simulation (random deviates)."  For example, 
runif(1000) produces a vector of 1000 uniform pseudo-random deviates, 
while rnorm(1000) produces a vector of 1000 normal(0, 1) pseudo-random 
variates.  If you want other distributions, you can do a search of the 
archives at "www.r-project.org" for the distribution of your choice.  If 
this doesn't answer your question, you might try being more specific -- 
e.g., trying something, then asking why it doesn't produce what you want. 

      hope this helps.  spencer graves    

Sherry Forbes wrote:

>Is there a package available (to modify?) for Monte Carlo simulation?
>Thanks so much!
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From pyabo at 2vias.com.ar  Sat Jan  3 23:58:29 2004
From: pyabo at 2vias.com.ar (Pablo Yabo)
Date: Sat, 03 Jan 2004 19:58:29 -0300
Subject: [R] Exception handling
Message-ID: <001101c3d24d$1adb99e0$daca73c8@timy>

Hi,
I want to know if it's possible to prevent that a stop call stops my
program.
I want to call a function that can fail calling a stop. But in that case I
want to keep the control and do something else, not stop the program and
print a message.
Is that possible?

Thanks, in advance

Pablo Yabo



From baron at psych.upenn.edu  Sun Jan  4 00:05:47 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sat, 3 Jan 2004 18:05:47 -0500
Subject: [R] Exception handling
In-Reply-To: <001101c3d24d$1adb99e0$daca73c8@timy>
References: <001101c3d24d$1adb99e0$daca73c8@timy>
Message-ID: <20040103230547.GA5500@mail2.sas.upenn.edu>

On 01/03/04 19:58, Pablo Yabo wrote:
>Hi,
>I want to know if it's possible to prevent that a stop call stops my
>program.
>I want to call a function that can fail calling a stop. But in that case I
>want to keep the control and do something else, not stop the program and
>print a message.

Perhaps something like:

if (CONDITION) {stop("ERROR MESSAGE")} else {DO SOMETHING ELSE}

or just

if (CONDITION) {stop("ERROR MESSAGE")}

and the do something else comes later.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From spencer.graves at pdf.com  Sun Jan  4 00:07:58 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 03 Jan 2004 15:07:58 -0800
Subject: [R] Exception handling
In-Reply-To: <001101c3d24d$1adb99e0$daca73c8@timy>
References: <001101c3d24d$1adb99e0$daca73c8@timy>
Message-ID: <3FF74B4E.9080909@pdf.com>

have you considered "try"?  hope this helps.  spencer graves

Pablo Yabo wrote:

>Hi,
>I want to know if it's possible to prevent that a stop call stops my
>program.
>I want to call a function that can fail calling a stop. But in that case I
>want to keep the control and do something else, not stop the program and
>print a message.
>Is that possible?
>
>Thanks, in advance
>
>Pablo Yabo
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From pyabo at 2vias.com.ar  Sun Jan  4 00:36:31 2004
From: pyabo at 2vias.com.ar (Pablo Yabo)
Date: Sat, 03 Jan 2004 20:36:31 -0300
Subject: [R] Exeption handling
Message-ID: <002f01c3d252$73ccaad0$daca73c8@timy>

but try is a C keyword, I writing code in R.
I need something like a try / catch block in C, but written in R.

----- Original Message ----- 
From: "Spencer Graves" <spencer.graves at pdf.com>
To: "Pablo Yabo" <pyabo at 2vias.com.ar>
Cc: <r-help at stat.math.ethz.ch>
Sent: Saturday, January 03, 2004 8:07 PM
Subject: Re: [R] Exception handling


> have you considered "try"?  hope this helps.  spencer graves
>
> Pablo Yabo wrote:
>
> >Hi,
> >I want to know if it's possible to prevent that a stop call stops my
> >program.
> >I want to call a function that can fail calling a stop. But in that case
I
> >want to keep the control and do something else, not stop the program and
> >print a message.
> >Is that possible?
> >
> >Thanks, in advance
> >
> >Pablo Yabo
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
>



From rpeng at jhsph.edu  Sun Jan  4 01:16:21 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sat, 03 Jan 2004 19:16:21 -0500
Subject: [R] Exeption handling
In-Reply-To: <002f01c3d252$73ccaad0$daca73c8@timy>
References: <002f01c3d252$73ccaad0$daca73c8@timy>
Message-ID: <3FF75B55.3000706@jhsph.edu>

Try looking at ?try or ?tryCatch in R.

-roger

Pablo Yabo wrote:

> but try is a C keyword, I writing code in R.
> I need something like a try / catch block in C, but written in R.
> 
> ----- Original Message ----- 
> From: "Spencer Graves" <spencer.graves at pdf.com>
> To: "Pablo Yabo" <pyabo at 2vias.com.ar>
> Cc: <r-help at stat.math.ethz.ch>
> Sent: Saturday, January 03, 2004 8:07 PM
> Subject: Re: [R] Exception handling
> 
> 
> 
>>have you considered "try"?  hope this helps.  spencer graves
>>
>>Pablo Yabo wrote:
>>
>>
>>>Hi,
>>>I want to know if it's possible to prevent that a stop call stops my
>>>program.
>>>I want to call a function that can fail calling a stop. But in that case
> 
> I
> 
>>>want to keep the control and do something else, not stop the program and
>>>print a message.
>>>Is that possible?
>>>
>>>Thanks, in advance
>>>
>>>Pablo Yabo
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>
>>>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From deepayan at stat.wisc.edu  Sat Jan  3 10:21:16 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 3 Jan 2004 09:21:16 +0000
Subject: [R] bwplot and panel.bwplot
In-Reply-To: <018b01c3d13d$33285f80$5e9c0c50@PC728329681112>
References: <018b01c3d13d$33285f80$5e9c0c50@PC728329681112>
Message-ID: <200401030921.16040.deepayan@stat.wisc.edu>

On Friday 02 January 2004 14:29, Patrick Giraudoux wrote:
> Hello,
> 
> I am trying to use "bwplot" to display whisker boxes according to some
> conditioning factors ("age" has two values 1/2). I get the following
> messages:
 
>
> > library(trellis)

I'm not aware of any such package, but I'll assume you are talking about 
something else.

> > bwplot(dvk95~age|site*season,panel=function(x,y){panel.bwplot(x,y)})

Why are you explicitly specifying a panel function ? Doesn't the default 
work ?

> Error in tapply(1:0, structure(list(INDICES = numeric(0)), .Names =
> "INDICES"),  : 
>         arguments must have same length 
> In addition: Warning messages: 
> 1: is.na() applied to non-(list or vector) in: is.na(x) 
> 2: is.na() applied to non-(list or vector) in: is.na(x) 
> 3: is.na() applied to non-(list or vector) in: is.na(x) 
> 4: is.na() applied to non-(list or vector) in: is.na(x) 
> 5: is.na() applied to non-(list or vector) in: is.na(x) 
> 6: is.na() applied to non-(list or vector) in: is.na(x)
> 
> I suspect this may come from not-anwered (NA) combinations of categories
> (data are field data on hazel grouse and the sampling is not balanced).
> Using  "xyplot" however leads to a correct display of data, the "NAs"
> combinations of categories being simply empty in the panel plot.
> 
> Passing na.action = na.omit or similar expressions don't lead to anything
> (actually every vector used has not any NA values).
> 
> Is there a way to get a display with bwplot (and panel.bwplot) in this
> case?
>
> Thanks in advance for any hint,

Difficult to guess without access to the data. Could you send me (offlist) 
your data frame (preferably saved using 'save') along with actual code that 
reproduces the error ?

Deepayan



From patrick.giraudoux at univ-fcomte.fr  Sun Jan  4 10:45:16 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 4 Jan 2004 10:45:16 +0100
Subject: [R] bwplot and panel.bwplot
References: <018b01c3d13d$33285f80$5e9c0c50@PC728329681112>
	<200401030921.16040.deepayan@stat.wisc.edu>
Message-ID: <005101c3d2a7$e1b82920$53eef9c1@PC728329681112>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040104/6e74cea2/attachment.pl

From marwan.khawaja at aub.edu.lb  Sat Jan  3 19:57:56 2004
From: marwan.khawaja at aub.edu.lb (Marwan Khawaja)
Date: Sat, 3 Jan 2004 13:57:56 -0500
Subject: [R] ade4
In-Reply-To: <5.2.1.1.0.20040102165116.00b2ccc8@biomserv.univ-lyon1.fr>
Message-ID: <CLECJBOEBGOMOKJHJNDAEEFKDIAA.marwan.khawaja@aub.edu.lb>

Dear Stephane,
Yes, it worked fine -- a nice plot -- many thanks for your help.
Marwan



-------------------------------------------------------------------
Marwan Khawaja         http://departments.aub.edu.lb/~mk36
-------------------------------------------------------------------


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Stephane DRAY
> Sent: Friday, January 02, 2004 10:53 AM
> To: Marwan Khawaja; R
> Subject: Re: [R] ade4
>
>
> You can try:
>
> s.label(banque.acm$li)
>
> s.arrow(banque.acm$c1)
>
>
>
> At 17:28 01/01/2004, Marwan Khawaja wrote:
> >Dear All,
> >I am using the scatter.dudi finction in the 'ade4' package to produce
> >correspondence analysis (nice) plots.
> >I do not seem to figure out how to plot the raw coordinates only -- or column
> >coordinates only.  I would appreciate any help in doing that.
> >Here is the example I am following -- from the package.
> >
> >data(banque)
> > >      banque.acm <- dudi.acm(banque, scann = FALSE, nf = 3)
> > >      scatter.dudi(banque.acm)
> >
> >Using,
> >platform i386-pc-mingw32
> >arch     i386
> >os       mingw32
> >system   i386, mingw32
> >status
> >major    1
> >minor    8.1
> >year     2003
> >month    11
> >day      21
> >language R
> >
> >TIA, Marwan
> >
> >-------------------------------------------------------------------
> >Marwan Khawaja         http://departments.aub.edu.lb/~mk36
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> St?phane DRAY
> ----------------------------------------------------------------------
> ----------------------------
>
> D?partement des Sciences Biologiques
> Universit? de Montr?al, C.P. 6128, succursale centre-ville
> Montr?al, Qu?bec H3C 3J7, Canada
>
> Tel : 514 343 6111 poste 1233
> E-mail : stephane.dray at umontreal.ca
> ----------------------------------------------------------------------
> ----------------------------
>
> Web                                          http://www.steph280.freesurf.fr/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From johanl at kiev.biotech.kth.se  Sun Jan  4 13:38:16 2004
From: johanl at kiev.biotech.kth.se (Johan Lindberg)
Date: Sun, 04 Jan 2004 13:38:16 +0100
Subject: [R] Analyzing dendograms??
Message-ID: <5.2.0.9.0.20040104130037.00bada60@kiev.biotech.kth.se>


I have used heatmap to visualize my microarray data. I have a matrix of 
M-values. I do the following.

#The distance between the columns.
sampdist <- dist(t(matrix[,]), method="euclidean")
sclus <- hclust(sampdist, method="average")
#The distance between the rows.
genedist <- dist(matrix[,], method="euclidean")
gclus <- hclust(genedist, method="average")
heatmap(matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram(sclus), col=rbg)

So far so good. But what if I want to look at a group of genes that appear 
to have the same expression pattern in the heatmap? How do I zoom in on a 
dendogram in a heatmap to look at which genes that are forming the 
interesting clusters? I would really appreciate if someone could give me a 
pointer.

Best regards.

/ Johan



*******************************************************************************************
Johan Lindberg
Royal Institute of Technology
AlbaNova University Center
Stockholm Center for Physics, Astronomy and Biotechnology
Department of Molecular Biotechnology
106 91 Stockholm, Sweden

Phone (office): +46 8 553 783 45
Fax: + 46 8 553 784 81
Visiting adress: Roslagstullsbacken 21, Floor 3
Delivery adress: Roslagsv?gen 30B



From nusbj at hotmail.com  Sun Jan  4 14:42:55 2004
From: nusbj at hotmail.com (Z P)
Date: Sun, 04 Jan 2004 21:42:55 +0800
Subject: [R] array problem
Message-ID: <Sea2-F352oJ2KpGbgtP0000f1f7@hotmail.com>

Dear all,

I define , for n=5 or any integer greater than 0.

A<-array((1/2)^n , c(rep(2,n)))

then for any i not equal to j, and 1<=i,j<=n,

B<-apply(a,c(i,j),sum)

now B is a 2 by 2 matrix, I also define another costant 2 by 2 matrix G,

How can I change the values of each elements of array A, according the rule 
that,

for example, i=3,j=5,

A[i1,i2,m,i4,l]<-A[i1,i2,m,i4,l]*G[m,l]/B[m,l]  , where m,l=1,2 and 
i1,i2,i4=1,2

I can control this given any i and j, however, I must do the iteration

for i in 1:(n-1) {
    for j in (i,n)
          {B<-apply(a,c(i,j),sum)
           here change the value of every elements of A according to my rule
            }
                     }

Is there any easy way to change the value of A in the iteration? Thank you.

_________________________________________________________________
Find love on MSN Personals http://personals.msn.com.sg/



From ggrothendieck at myway.com  Sun Jan  4 17:51:47 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun,  4 Jan 2004 11:51:47 -0500 (EST)
Subject: [R] array problem
Message-ID: <20040104165147.E7C093967@mprdmxin.myway.com>



Replace your line that updates A with this:

p <- unique(c(i,j,1:5))
f <- function(x) diag( matrix(x,4,4) )
AA <- apply( outer(A,G/B), p[-(1:2)], f )   # form product
A <- aperm( array( AA, dim(A) ), order(p) ) # reshape

Here are a couple of tests.  You might want to do some
more tests yourself as well since these are the only
ones I did:

> 
> i <- 3; j <- 5
> G <- 100 * matrix(1:4,2)
> B <- 1+0*G  # all ones
> A <- array(1:32,c(2,2,2,2,2))
> A2 <- A
> A2[,,1,,1] <- A2[,,1,,1] * G[1,1]
> A2[,,1,,2] <- A2[,,1,,2] * G[1,2]
> A2[,,2,,1] <- A2[,,2,,1] * G[2,1]
> A2[,,2,,2] <- A2[,,2,,2] * G[2,2]
> 
> test <- function(A,i,j) {
+ p <- unique(c(i,j,1:5))
+ f <- function(x) diag( matrix(x,4,4) )
+ AA <- apply( outer(A,G/B), p[-(1:2)], f )   # form product
+ A <- aperm( array( AA, dim(A) ), order(p) ) # reshape
+ A
+ }
> 
> identical(test(A,i,j),A2)
[1] TRUE
> 
> 
> i <- 2; j <- 4
> A3 <- A
> A3[,1,,1,] <- A3[,1,,1,] * G[1,1]
> A3[,1,,2,] <- A3[,1,,2,] * G[1,2]
> A3[,2,,1,] <- A3[,2,,1,] * G[2,1]
> A3[,2,,2,] <- A3[,2,,2,] * G[2,2]
> 
> identical(test(A,i,j),A3)
[1] TRUE
> 




--- 
Date: Sun, 04 Jan 2004 21:42:55 +0800 
From: Z P <nusbj at hotmail.com>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] array problem 

 
 
Dear all,

I define , for n=5 or any integer greater than 0.

A<-array((1/2)^n , c(rep(2,n)))

then for any i not equal to j, and 1<=i,j<=n,

B<-apply(a,c(i,j),sum)

now B is a 2 by 2 matrix, I also define another costant 2 by 2 matrix G,

How can I change the values of each elements of array A, according the rule 
that,

for example, i=3,j=5,

A[i1,i2,m,i4,l]<-A[i1,i2,m,i4,l]*G[m,l]/B[m,l] , where m,l=1,2 and 
i1,i2,i4=1,2

I can control this given any i and j, however, I must do the iteration

for i in 1:(n-1) {
for j in (i,n)
{B<-apply(a,c(i,j),sum)
here change the value of every elements of A according to my rule
}
}

Is there any easy way to change the value of A in the iteration? Thank you.



From tblackw at umich.edu  Sun Jan  4 19:31:48 2004
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Sun, 4 Jan 2004 13:31:48 -0500 (EST)
Subject: [R] Analyzing dendograms??
In-Reply-To: <5.2.0.9.0.20040104130037.00bada60@kiev.biotech.kth.se>
References: <5.2.0.9.0.20040104130037.00bada60@kiev.biotech.kth.se>
Message-ID: <Pine.SOL.4.58.0401041315480.3170@timepilot.gpcc.itd.umich.edu>

Johan  -

Disclaimer:  I've never used  heatmap(), so probably I shouldn't
be answering this.

However ... the function  heatmap() probably calls either  plot()
or  image() (regular graphics) or  xyplot() (lattice graphics)  in
order to set up axes and initialize the actual plotting.  heatmap()
may also have a  "..."  argument which passes additional parameters
through to  plot(), unchanged.  If both of my guesses are correct
(use  help("heatmap")  to find out) then I would try calling
heatmap() again with an additional parameter  ylim=c(a,b),  where
"a" and "b" are two numbers, with  a < b,  which indicate plotting
coordinates which bracket the group of genes you wish to zoom in on.

It will take a bit of experimentation to figure out what internal
coordinate system  heatmap()  uses to do the plotting, but this
seems like a direct way to zoom in on just a part of the plot.

This is completely untested.  I leave it to you to read  help("heatmap")
and see whether any of this makes sense.  Hope this helps.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Sun, 4 Jan 2004, Johan Lindberg wrote:

>
> I have used heatmap to visualize my microarray data. I have a matrix of
> M-values. I do the following.
>
> #The distance between the columns.
> sampdist <- dist(t(matrix[,]), method="euclidean")
> sclus <- hclust(sampdist, method="average")
> #The distance between the rows.
> genedist <- dist(matrix[,], method="euclidean")
> gclus <- hclust(genedist, method="average")
> heatmap(matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram(sclus), col=rbg)
>
> So far so good. But what if I want to look at a group of genes that appear
> to have the same expression pattern in the heatmap? How do I zoom in on a
> dendogram in a heatmap to look at which genes that are forming the
> interesting clusters? I would really appreciate if someone could give me a
> pointer.
>
> Best regards.
>
> / Johan
>
>
>
> *******************************************************************************************
> Johan Lindberg
> Royal Institute of Technology
> AlbaNova University Center
> Stockholm Center for Physics, Astronomy and Biotechnology
> Department of Molecular Biotechnology
> 106 91 Stockholm, Sweden
>
> Phone (office): +46 8 553 783 45
> Fax: + 46 8 553 784 81
> Visiting adress: Roslagstullsbacken 21, Floor 3
> Delivery adress: Roslagsv?gen 30B
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From rrsilva at ib.usp.br  Sun Jan  4 21:29:21 2004
From: rrsilva at ib.usp.br (=?iso-8859-1?q?Rog=E9rio=20Rosa=20da=20Silva?=)
Date: Sun, 4 Jan 2004 18:29:21 -0200
Subject: [R] Error running as.phylo (package ape)
Message-ID: <200401041829.21112.rrsilva@ib.usp.br>

Hi all,

I  try to  convert hclust object to phylo object, using as.phylo (package 
ape), but got an error like the following:

> tese<- read.table ("tese_guildas.txt", header=T)
> library(mva)
> library(ape)
> hclust.tree<-hclust(dist(tese[1:156,]))
> phylo.tree<- as.phylo(hclust.tree)
> Segmentation fault (core dumped)

Can someone give me a hint where I migth be going wrong? Is there something I
forgot to do?

Best regards,

Rog?rio

[R Version: 1.8.0; Platform: Mandrake 9.2]



From sorenh at agrsci.dk  Sun Jan  4 22:54:26 2004
From: sorenh at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Sun, 4 Jan 2004 22:54:26 +0100
Subject: [R] R-analogue to the estimate and lsmeans statements in SAS
Message-ID: <001901c3d30d$5bcccd50$f2f1d7c3@djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040104/e45231ed/attachment.pl

From dk.tyler at virgin.net  Mon Jan  5 00:25:50 2004
From: dk.tyler at virgin.net (David Tyler)
Date: Sun, 4 Jan 2004 23:25:50 -0000
Subject: [R] Density Plots
Message-ID: <000f01c3d31a$179188d0$69e76b51@DLZTYLERHOME>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040104/7041191e/attachment.pl

From jasont at indigoindustrial.co.nz  Mon Jan  5 02:05:47 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 05 Jan 2004 14:05:47 +1300
Subject: [R] Density Plots
In-Reply-To: <000f01c3d31a$179188d0$69e76b51@DLZTYLERHOME>
References: <000f01c3d31a$179188d0$69e76b51@DLZTYLERHOME>
Message-ID: <3FF8B86B.1010406@indigoindustrial.co.nz>

David Tyler wrote (using an e-mail client that doesn't wrap lines):

> I am using an older version of R (1.6.2) to run a Monte Carlo 
 >
> simulation, generating 10,000 samples per 'run'.  When I plot 
 > histograms I get the expected 'bins' on the x-axis and the
 > frequency distribution on the y-axis. However when I ask R
 > to plot the SAME data set with a density curve the x-axis
 > emains the same but the y-axis can generate values of up to 1e8 etc.

> Can anyone (a) explain why this might be so and/or (b) suggest a fix?

try

hist(..., freq=FALSE)

This should give the same numbers as the density plots' y-axes.

It sounds like you've got a narrow range of x-axis values (small 
numbers, or small differences between them, or both).  The total area 
under a density estimate curve must equal 1 by definition, so nothing's 
really "broken".  The only fix is to re-scale the x axis to different 
units, or draw a different y-axis on after the fact.  Something like...

foo <- density(...)
plot(foo, yaxt="n")
axis(...)  # something that means something to you here.

Since this isn't a density plot any longer, it would help to be clear to 
your readers what's going on with the plots.

Hope that helps

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From allan at stats.uct.ac.za  Mon Jan  5 10:30:39 2004
From: allan at stats.uct.ac.za (allan clark)
Date: Mon, 05 Jan 2004 11:30:39 +0200
Subject: [R] r: lm question
Message-ID: <3FF92EBF.59C35255@stats.uct.ac.za>

Hi all

this is a silly question since i should know the answer.

lm(y~x) perfroms linear regression with the intercept included.

How  do i estimate the equation without the intercept?

cheers



From JonesW at kssg.com  Mon Jan  5 10:30:57 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Mon, 5 Jan 2004 09:30:57 -0000 
Subject: [R] r: lm question
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0F07@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040105/7a87c21c/attachment.pl

From Ivar.Herfindal at bio.ntnu.no  Mon Jan  5 10:46:21 2004
From: Ivar.Herfindal at bio.ntnu.no (Ivar Herfindal)
Date: Mon, 05 Jan 2004 10:46:21 +0100
Subject: [R] r: lm question
In-Reply-To: <3FF92EBF.59C35255@stats.uct.ac.za>
References: <3FF92EBF.59C35255@stats.uct.ac.za>
Message-ID: <opr1aqrjnfndboo6@mail.bio.ntnu.no>

I think this should work:

lm(y ~ x - 1)

Ivar

On Mon, 05 Jan 2004 11:30:39 +0200, allan clark <allan at stats.uct.ac.za> 
wrote:

> Hi all
>
> this is a silly question since i should know the answer.
>
> lm(y~x) perfroms linear regression with the intercept included.
>
> How  do i estimate the equation without the intercept?
>
> cheers
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Roger.Bivand at nhh.no  Mon Jan  5 10:46:02 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 5 Jan 2004 10:46:02 +0100 (CET)
Subject: [R] r: lm question
In-Reply-To: <3FF92EBF.59C35255@stats.uct.ac.za>
Message-ID: <Pine.LNX.4.44.0401051044520.4409-100000@reclus.nhh.no>

On Mon, 5 Jan 2004, allan clark wrote:

> Hi all
> 
> this is a silly question since i should know the answer.
> 
> lm(y~x) perfroms linear regression with the intercept included.
> 
> How  do i estimate the equation without the intercept?

?formula:

"The '-' operator removes the specified terms, so that '(a+b+c)^2 - a:b'
is identical to 'a + b + c + b:c + a:c'.  It can also used to remove the
intercept term: 'y~x - 1' is a line through the origin.  A model with no
intercept can be also specified as 'y~x + 0' or '0 + y~x'."

Roger

> 
> cheers
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From p.dalgaard at biostat.ku.dk  Mon Jan  5 10:55:42 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Jan 2004 10:55:42 +0100
Subject: [R] r: lm question
In-Reply-To: <3FF92EBF.59C35255@stats.uct.ac.za>
References: <3FF92EBF.59C35255@stats.uct.ac.za>
Message-ID: <x23cauafdt.fsf@biostat.ku.dk>

allan clark <allan at stats.uct.ac.za> writes:

> Hi all
> 
> this is a silly question since i should know the answer.
> 
> lm(y~x) perfroms linear regression with the intercept included.
> 
> How  do i estimate the equation without the intercept?

y ~ x - 1 (or y ~ x + 0)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From johanl at kiev.biotech.kth.se  Mon Jan  5 12:19:11 2004
From: johanl at kiev.biotech.kth.se (Johan Lindberg)
Date: Mon, 05 Jan 2004 12:19:11 +0100
Subject: [R] Analyzing dendograms??
In-Reply-To: <Pine.SOL.4.58.0401041315480.3170@timepilot.gpcc.itd.umich. edu>
References: <5.2.0.9.0.20040104130037.00bada60@kiev.biotech.kth.se>
	<5.2.0.9.0.20040104130037.00bada60@kiev.biotech.kth.se>
Message-ID: <5.2.0.9.0.20040105120121.00bde0c8@kiev.biotech.kth.se>

Thanks for the ideas but I already tested to give the heatmapfunction the 
argument ylim but I get the following error message:

Error in image.default(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5 +  :
         formal argument "ylim" matched by multiple actual arguments

So then I tried to adjust the function and changed the ylim argument when 
the "heatmapfunction" calls "image". But this only makes it possible to 
zoom in on the "picture" that is drawn in the heatmapfunction. The result 
is that the function draws the full dendogram on a truncated picure.

Any ideas, anyone?

/ Johan


At 13:31 2004-01-04 -0500, you wrote:
>Johan  -
>
>Disclaimer:  I've never used  heatmap(), so probably I shouldn't
>be answering this.
>
>However ... the function  heatmap() probably calls either  plot()
>or  image() (regular graphics) or  xyplot() (lattice graphics)  in
>order to set up axes and initialize the actual plotting.  heatmap()
>may also have a  "..."  argument which passes additional parameters
>through to  plot(), unchanged.  If both of my guesses are correct
>(use  help("heatmap")  to find out) then I would try calling
>heatmap() again with an additional parameter  ylim=c(a,b),  where
>"a" and "b" are two numbers, with  a < b,  which indicate plotting
>coordinates which bracket the group of genes you wish to zoom in on.
>
>It will take a bit of experimentation to figure out what internal
>coordinate system  heatmap()  uses to do the plotting, but this
>seems like a direct way to zoom in on just a part of the plot.
>
>This is completely untested.  I leave it to you to read  help("heatmap")
>and see whether any of this makes sense.  Hope this helps.
>
>-  tom blackwell  -  u michigan medical school  -  ann arbor  -
>
>On Sun, 4 Jan 2004, Johan Lindberg wrote:
>
> >
> > I have used heatmap to visualize my microarray data. I have a matrix of
> > M-values. I do the following.
> >
> > #The distance between the columns.
> > sampdist <- dist(t(matrix[,]), method="euclidean")
> > sclus <- hclust(sampdist, method="average")
> > #The distance between the rows.
> > genedist <- dist(matrix[,], method="euclidean")
> > gclus <- hclust(genedist, method="average")
> > heatmap(matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram(sclus), 
> col=rbg)
> >
> > So far so good. But what if I want to look at a group of genes that appear
> > to have the same expression pattern in the heatmap? How do I zoom in on a
> > dendogram in a heatmap to look at which genes that are forming the
> > interesting clusters? I would really appreciate if someone could give me a
> > pointer.
> >
> > Best regards.
> >
> > / Johan
> >
> >
> >
> > 
> *******************************************************************************************
> > Johan Lindberg
> > Royal Institute of Technology
> > AlbaNova University Center
> > Stockholm Center for Physics, Astronomy and Biotechnology
> > Department of Molecular Biotechnology
> > 106 91 Stockholm, Sweden
> >
> > Phone (office): +46 8 553 783 45
> > Fax: + 46 8 553 784 81
> > Visiting adress: Roslagstullsbacken 21, Floor 3
> > Delivery adress: Roslagsv?gen 30B
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >

*******************************************************************************************
Johan Lindberg
Royal Institute of Technology
AlbaNova University Center
Stockholm Center for Physics, Astronomy and Biotechnology
Department of Molecular Biotechnology
106 91 Stockholm, Sweden

Phone (office): +46 8 553 783 45
Fax: + 46 8 553 784 81
Visiting adress: Roslagstullsbacken 21, Floor 3
Delivery adress: Roslagsv?gen 30B



From pyabo at 2vias.com.ar  Mon Jan  5 12:25:41 2004
From: pyabo at 2vias.com.ar (Pablo Yabo)
Date: Mon, 05 Jan 2004 08:25:41 -0300
Subject: [R] Exeption handling
References: <002f01c3d252$73ccaad0$daca73c8@timy> <3FF75B55.3000706@jhsph.edu>
Message-ID: <003a01c3d37e$a74e6a60$daca73c8@timy>

ok, thanks.

----- Original Message ----- 
From: "Roger D. Peng" <rpeng at jhsph.edu>
To: "Pablo Yabo" <pyabo at 2vias.com.ar>
Cc: <r-help at stat.math.ethz.ch>
Sent: Saturday, January 03, 2004 9:16 PM
Subject: Re: [R] Exeption handling


> Try looking at ?try or ?tryCatch in R.
>
> -roger
>
> Pablo Yabo wrote:
>
> > but try is a C keyword, I writing code in R.
> > I need something like a try / catch block in C, but written in R.
> >
> > ----- Original Message ----- 
> > From: "Spencer Graves" <spencer.graves at pdf.com>
> > To: "Pablo Yabo" <pyabo at 2vias.com.ar>
> > Cc: <r-help at stat.math.ethz.ch>
> > Sent: Saturday, January 03, 2004 8:07 PM
> > Subject: Re: [R] Exception handling
> >
> >
> >
> >>have you considered "try"?  hope this helps.  spencer graves
> >>
> >>Pablo Yabo wrote:
> >>
> >>
> >>>Hi,
> >>>I want to know if it's possible to prevent that a stop call stops my
> >>>program.
> >>>I want to call a function that can fail calling a stop. But in that
case
> >
> > I
> >
> >>>want to keep the control and do something else, not stop the program
and
> >>>print a message.
> >>>Is that possible?
> >>>
> >>>Thanks, in advance
> >>>
> >>>Pablo Yabo
> >>>
> >>>______________________________________________
> >>>R-help at stat.math.ethz.ch mailing list
> >>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>>
> >>>
> >>
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >



From oliver.bossdorf at ufz.de  Mon Jan  5 13:30:25 2004
From: oliver.bossdorf at ufz.de (Oliver Bossdorf)
Date: Mon, 05 Jan 2004 13:30:25 +0100
Subject: [R] MANOVA power, degrees of freedom, and RAO's paradox
Message-ID: <3FF958E1.6050909@ufz.de>

Hi,

I have a nested unbalanced data set of four correlated variables. When I 
do univariate analyses, my factor of interest is significant or 
marginally significant with all of the variables. Small effect size but 
always in the same direction. If I do a MANOVA instead (because the 
variables are not independent!) then my factor is far from being 
significant. How does that come about?

I have found a mention of a so-called Rao's paradox, which seems to deal 
with exactly this phenomenon. Does anyone know more about it, e.g. a 
reference?

The next strange thing is that if do the MANOVA in R, then both 
hypothesis and error degrees of freedom are multiplied by the number of 
variables. When I do it in SAS, however, only the hypothesis d.f. are 4 
x univariate, while the error d.f. are as in univariate, minus 3. This 
is irritating, in particular since no indication is given in the 
handbooks as to how degrees of freedom are calculated in a MANOVA? Can 
anyone tell me more about this? Are there different philosphies that are 
responsible for the differences between R and SAS?

I would be grateful for any help.

Regards, Oliver



From ripley at stats.ox.ac.uk  Mon Jan  5 13:48:05 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jan 2004 12:48:05 +0000 (GMT)
Subject: [R] MANOVA power, degrees of freedom, and RAO's paradox
In-Reply-To: <3FF958E1.6050909@ufz.de>
Message-ID: <Pine.LNX.4.44.0401051244070.10861-100000@gannet.stats>

R's manova is not intended to handle `nested unbalanced data': it
cross-references ?aov, which says the unbalanced part, and ?manova says
the nested part.

On Mon, 5 Jan 2004, Oliver Bossdorf wrote:

> Hi,
> 
> I have a nested unbalanced data set of four correlated variables. When I 
> do univariate analyses, my factor of interest is significant or 
> marginally significant with all of the variables. Small effect size but 
> always in the same direction. If I do a MANOVA instead (because the 
> variables are not independent!) then my factor is far from being 
> significant. How does that come about?
> 
> I have found a mention of a so-called Rao's paradox, which seems to deal 
> with exactly this phenomenon. Does anyone know more about it, e.g. a 
> reference?
> 
> The next strange thing is that if do the MANOVA in R, then both 
> hypothesis and error degrees of freedom are multiplied by the number of 
> variables. When I do it in SAS, however, only the hypothesis d.f. are 4 
> x univariate, while the error d.f. are as in univariate, minus 3. This 
> is irritating, in particular since no indication is given in the 
> handbooks as to how degrees of freedom are calculated in a MANOVA? Can 
> anyone tell me more about this? Are there different philosphies that are 
> responsible for the differences between R and SAS?
> 
> I would be grateful for any help.
> 
> Regards, Oliver
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gguigon at pasteur.fr  Mon Jan  5 13:53:36 2004
From: gguigon at pasteur.fr (Ghislaine Guigon)
Date: Mon, 05 Jan 2004 13:53:36 +0100
Subject: [R] install on windows
Message-ID: <5.0.2.1.2.20040105134332.00b3d418@mail.pasteur.fr>


   I'm trying to install packages on windows XP and I have trouble with
   command Rcmd build (R version 1.8.1) :
   In the Windows console for package maanova for example, answer is :
   C:\Documents and Settings\dillies\Mes documents\ghis\packages>Rcmd
   build maanova
   * checking for file 'maanova/DESCRIPTION' ... OK
   * preparing 'maanova':
   * cleaning src
   * checking whether 'INDEX' is up-to-date ... NO
   * use '--force' to overwrite the existing 'INDEX'
   * removing junk files
   * building 'maanova_0.91-3.tar.gz'
   tar: and: Cannot stat: No such file or directory
   tar: Settings/dillies/Mes : Cannot stat: No such file or directory
   tar: documents/ghis/packages/maanova_0.91-3.tar: Cannot stat: No such
   file or directory
   tar: Error exit delayed from previous errors
   tar: and: Not found in archive
   tar: Settings/dillies/Mes: Not found in archive
   tar: documents/ghis/packages/maanova_0.91-3.tar: Not found in archive
   tar: Error exit delayed from previous errors
   tar: and: Cannot stat: No such file or directory
   tar: Settings/dillies/Mes: Cannot stat: No such file or directory
   tar: documents/ghis/packages/maanova_0.91-3.tar: Cannot stat: No such
   file or di
   rectory
   tar: maanova: Cannot stat: No such file or directory
   tar: Error exit delayed from previous errors
   maanova_0.91-3.tar: No such file or directory
   Is someone still have same problem ?
   Rtools are installed.
   Thanks for answers,

   Ghislaine GUIGON
   Biostatisticienne
   Plate-forme 2 Puces a ADN
   INSTITUT PASTEUR
   25-28 rue du Dr ROUX
   75724 Paris cedex 15
   FRANCE
   tel: (33) (0)1 40 61 86 51
   fax: (33) (0)1 45 68 84 06


From statho3 at web.de  Mon Jan  5 14:14:18 2004
From: statho3 at web.de (Thomas Stabla)
Date: Mon, 5 Jan 2004 14:14:18 +0100 (CET)
Subject: [R] Set values in namespaces
Message-ID: <Pine.LNX.4.44.0401051405110.2157-100000@spock.vulcan>

Hello,

I want to use global variables in a package which is using a namespace.
But I don`t know how to change the values of the global variables.

I know how to get the value of the variables, e.g.

> base::pi
[1] 3.141593

but following code doesn`t work

> base::pi <- 3.14
Error: Object "base" not found

Thanks for your help,
Thomas Stabla

--
> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    8.1
year     2003
month    11
day      21
language R



From ripley at stats.ox.ac.uk  Mon Jan  5 14:27:22 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jan 2004 13:27:22 +0000 (GMT)
Subject: [R] install on windows
In-Reply-To: <5.0.2.1.2.20040105134332.00b3d418@mail.pasteur.fr>
Message-ID: <Pine.LNX.4.44.0401051317360.10920-100000@gannet.stats>

Two comments:

1) Rcmd build does not install packages, it packages up source packages.
As all the documentation says it is Rcmd INSTALL which installs a source
package.

2) You have ignored the advice not to have spaces in your path, and the
request at the top of readme.packages `not to report problems to R-help
unless you have followed all the prescriptions', one of which is

   Do not use paths with spaces in: you can always use the short forms.

And as you have discovered, that advice was given for a good reason.


On Mon, 5 Jan 2004, Ghislaine Guigon wrote:

> 
>    I'm trying to install packages on windows XP and I have trouble with
>    command Rcmd build (R version 1.8.1) :
>    In the Windows console for package maanova for example, answer is :
>    C:\Documents and Settings\dillies\Mes documents\ghis\packages>Rcmd
>    build maanova
>    * checking for file 'maanova/DESCRIPTION' ... OK
>    * preparing 'maanova':
>    * cleaning src
>    * checking whether 'INDEX' is up-to-date ... NO
>    * use '--force' to overwrite the existing 'INDEX'
>    * removing junk files
>    * building 'maanova_0.91-3.tar.gz'
>    tar: and: Cannot stat: No such file or directory
>    tar: Settings/dillies/Mes : Cannot stat: No such file or directory
>    tar: documents/ghis/packages/maanova_0.91-3.tar: Cannot stat: No such
>    file or directory
>    tar: Error exit delayed from previous errors
>    tar: and: Not found in archive
>    tar: Settings/dillies/Mes: Not found in archive
>    tar: documents/ghis/packages/maanova_0.91-3.tar: Not found in archive
>    tar: Error exit delayed from previous errors
>    tar: and: Cannot stat: No such file or directory
>    tar: Settings/dillies/Mes: Cannot stat: No such file or directory
>    tar: documents/ghis/packages/maanova_0.91-3.tar: Cannot stat: No such
>    file or di
>    rectory
>    tar: maanova: Cannot stat: No such file or directory
>    tar: Error exit delayed from previous errors
>    maanova_0.91-3.tar: No such file or directory
>    Is someone still have same problem ?
>    Rtools are installed.
>    Thanks for answers,
> 
>    Ghislaine GUIGON
>    Biostatisticienne
>    Plate-forme 2 Puces a ADN
>    INSTITUT PASTEUR
>    25-28 rue du Dr ROUX
>    75724 Paris cedex 15
>    FRANCE
>    tel: (33) (0)1 40 61 86 51
>    fax: (33) (0)1 45 68 84 06
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jmacdon at med.umich.edu  Mon Jan  5 14:34:37 2004
From: jmacdon at med.umich.edu (James MacDonald)
Date: Mon, 05 Jan 2004 08:34:37 -0500
Subject: [R] Analyzing dendograms??
Message-ID: <sff921a7.051@med-gwia-01a.med.umich.edu>

You are using the xlim and ylim arguments incorrectly. You should be doing something like xlim=c(0.5, nc+0.5), ylim=c(0.5, nc+0.5). The error message gave you this hint.

HTH,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> Johan Lindberg <johanl at kiev.biotech.kth.se> 01/05/04 06:19AM >>>
Thanks for the ideas but I already tested to give the heatmapfunction the 
argument ylim but I get the following error message:

Error in image.default(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5 +  :
         formal argument "ylim" matched by multiple actual arguments

So then I tried to adjust the function and changed the ylim argument when 
the "heatmapfunction" calls "image". But this only makes it possible to 
zoom in on the "picture" that is drawn in the heatmapfunction. The result 
is that the function draws the full dendogram on a truncated picure.

Any ideas, anyone?

/ Johan


At 13:31 2004-01-04 -0500, you wrote:
>Johan  -
>
>Disclaimer:  I've never used  heatmap(), so probably I shouldn't
>be answering this.
>
>However ... the function  heatmap() probably calls either  plot()
>or  image() (regular graphics) or  xyplot() (lattice graphics)  in
>order to set up axes and initialize the actual plotting.  heatmap()
>may also have a  "..."  argument which passes additional parameters
>through to  plot(), unchanged.  If both of my guesses are correct
>(use  help("heatmap")  to find out) then I would try calling
>heatmap() again with an additional parameter  ylim=c(a,b),  where
>"a" and "b" are two numbers, with  a < b,  which indicate plotting
>coordinates which bracket the group of genes you wish to zoom in on.
>
>It will take a bit of experimentation to figure out what internal
>coordinate system  heatmap()  uses to do the plotting, but this
>seems like a direct way to zoom in on just a part of the plot.
>
>This is completely untested.  I leave it to you to read  help("heatmap")
>and see whether any of this makes sense.  Hope this helps.
>
>-  tom blackwell  -  u michigan medical school  -  ann arbor  -
>
>On Sun, 4 Jan 2004, Johan Lindberg wrote:
>
> >
> > I have used heatmap to visualize my microarray data. I have a matrix of
> > M-values. I do the following.
> >
> > #The distance between the columns.
> > sampdist <- dist(t(matrix[,]), method="euclidean")
> > sclus <- hclust(sampdist, method="average")
> > #The distance between the rows.
> > genedist <- dist(matrix[,], method="euclidean")
> > gclus <- hclust(genedist, method="average")
> > heatmap(matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram(sclus), 
> col=rbg)
> >
> > So far so good. But what if I want to look at a group of genes that appear
> > to have the same expression pattern in the heatmap? How do I zoom in on a
> > dendogram in a heatmap to look at which genes that are forming the
> > interesting clusters? I would really appreciate if someone could give me a
> > pointer.
> >
> > Best regards.
> >
> > / Johan
> >
> >
> >
> > 
> *******************************************************************************************
> > Johan Lindberg
> > Royal Institute of Technology
> > AlbaNova University Center
> > Stockholm Center for Physics, Astronomy and Biotechnology
> > Department of Molecular Biotechnology
> > 106 91 Stockholm, Sweden
> >
> > Phone (office): +46 8 553 783 45
> > Fax: + 46 8 553 784 81
> > Visiting adress: Roslagstullsbacken 21, Floor 3
> > Delivery adress: Roslagsv?gen 30B
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
> >

*******************************************************************************************
Johan Lindberg
Royal Institute of Technology
AlbaNova University Center
Stockholm Center for Physics, Astronomy and Biotechnology
Department of Molecular Biotechnology
106 91 Stockholm, Sweden

Phone (office): +46 8 553 783 45
Fax: + 46 8 553 784 81
Visiting adress: Roslagstullsbacken 21, Floor 3
Delivery adress: Roslagsv?gen 30B

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Mon Jan  5 14:40:58 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jan 2004 13:40:58 +0000 (GMT)
Subject: [R] Set values in namespaces
In-Reply-To: <Pine.LNX.4.44.0401051405110.2157-100000@spock.vulcan>
Message-ID: <Pine.LNX.4.44.0401051327430.10920-100000@gannet.stats>

On Mon, 5 Jan 2004, Thomas Stabla wrote:

> I want to use global variables in a package which is using a namespace.
> But I don`t know how to change the values of the global variables.
> 
> I know how to get the value of the variables, e.g.
> 
> > base::pi
> [1] 3.141593
> 
> but following code doesn`t work
> 
> > base::pi <- 3.14
> Error: Object "base" not found

Base is a special case, and

assign("pi", 3.14, envir=NULL)

will do this (although please don't).

All other namespaces are sealed, so you will get something like

> library(MASS)
> assign("lda", pi, pos=2)
Error in assign("lda", pi, pos = 2) : can't change value of a locked binding

Now, that attempts to change the export, and not the value in the
namespace, so there is a question of which you want and why you want to
change it.  (Changing the value in the namespace does not change the
export, which is a copy, but as _both_ the namespace and exports
environments are sealed, this would not matter much.)

There are ways around this and if you peruse the R sources you will find 
them.  For example, grid sets up an environment in its namespace for its 
global variables, and in R-devel there is assignInNamespace().

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Simon.Fear at synequanon.com  Mon Jan  5 15:44:58 2004
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Mon, 5 Jan 2004 14:44:58 -0000
Subject: [R] Analyzing dendograms??
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F02163@synequanon01>

I don't think Jim has the answer: c(0.5, nc+0.5) and
0.5 + c(0, nc) are identical.

I think the problem is this call within heatmap():

    image(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5 + 
        c(0, nr), axes = FALSE, xlab = "", ylab = "", ...)

So, if you put a `ylim` in your ... argument, the above call has two
ylim arguments.

Edit your own copy of myheatmap <- fix(heatmap); put
xlim = NULL, ylim = NULL in the arguments to
the myheatmap function, change the image call to state

xlim = if (is.null(xlim)) 0.5 + c(0, nc) else xlim,
ylim = if (is.null(ylim)) 0.5 + c(0, nc) else ylim,

and then you can specify a ylim or not, as required.

WARNING: THE ABOVE CODE IS NOT TESTED

Simon

PS it is always good to read `heatmap` as well as `?heatmap`!

> -----Original Message-----
> From: James MacDonald [mailto:jmacdon at med.umich.edu]
> Sent: 05 January 2004 13:35
> To: johanl at kiev.biotech.kth.se; r-help at stat.math.ethz.ch
> Subject: Re: [R] Analyzing dendograms??
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> You are using the xlim and ylim arguments incorrectly. You 
> should be doing something like xlim=c(0.5, nc+0.5), 
> ylim=c(0.5, nc+0.5). The error message gave you this hint.
> 
> HTH,
> 
> Jim
> 
> 
> 
> James W. MacDonald
> Affymetrix and cDNA Microarray Core
> University of Michigan Cancer Center
> 1500 E. Medical Center Drive
> 7410 CCGC
> Ann Arbor MI 48109
> 734-647-5623
> 
> >>> Johan Lindberg <johanl at kiev.biotech.kth.se> 01/05/04 06:19AM >>>
> Thanks for the ideas but I already tested to give the 
> heatmapfunction the 
> argument ylim but I get the following error message:
> 
> Error in image.default(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), 
> ylim = 0.5 +  :
>          formal argument "ylim" matched by multiple actual arguments
> 
> So then I tried to adjust the function and changed the ylim 
> argument when 
> the "heatmapfunction" calls "image". But this only makes it 
> possible to 
> zoom in on the "picture" that is drawn in the 
> heatmapfunction. The result 
> is that the function draws the full dendogram on a truncated picure.
> 
> Any ideas, anyone?
> 
> / Johan
> 
> 
> At 13:31 2004-01-04 -0500, you wrote:
> >Johan  -
> >
> >Disclaimer:  I've never used  heatmap(), so probably I shouldn't
> >be answering this.
> >
> >However ... the function  heatmap() probably calls either  plot()
> >or  image() (regular graphics) or  xyplot() (lattice graphics)  in
> >order to set up axes and initialize the actual plotting.  heatmap()
> >may also have a  "..."  argument which passes additional parameters
> >through to  plot(), unchanged.  If both of my guesses are correct
> >(use  help("heatmap")  to find out) then I would try calling
> >heatmap() again with an additional parameter  ylim=c(a,b),  where
> >"a" and "b" are two numbers, with  a < b,  which indicate plotting
> >coordinates which bracket the group of genes you wish to zoom in on.
> >
> >It will take a bit of experimentation to figure out what internal
> >coordinate system  heatmap()  uses to do the plotting, but this
> >seems like a direct way to zoom in on just a part of the plot.
> >
> >This is completely untested.  I leave it to you to read  
> help("heatmap")
> >and see whether any of this makes sense.  Hope this helps.
> >
> >-  tom blackwell  -  u michigan medical school  -  ann arbor  -
> >
> >On Sun, 4 Jan 2004, Johan Lindberg wrote:
> >
> > >
> > > I have used heatmap to visualize my microarray data. I 
> have a matrix of
> > > M-values. I do the following.
> > >
> > > #The distance between the columns.
> > > sampdist <- dist(t(matrix[,]), method="euclidean")
> > > sclus <- hclust(sampdist, method="average")
> > > #The distance between the rows.
> > > genedist <- dist(matrix[,], method="euclidean")
> > > gclus <- hclust(genedist, method="average")
> > > 
> heatmap(matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram
> (sclus), 
> > col=rbg)
> > >
> > > So far so good. But what if I want to look at a group of 
> genes that appear
> > > to have the same expression pattern in the heatmap? How 
> do I zoom in on a
> > > dendogram in a heatmap to look at which genes that are forming the
> > > interesting clusters? I would really appreciate if 
> someone could give me a
> > > pointer.
> > >
> > > Best regards.
> > >
> > > / Johan
> > >
> > >
> > >
> > > 
> > 
> **************************************************************
> *****************************
> > > Johan Lindberg
> > > Royal Institute of Technology
> > > AlbaNova University Center
> > > Stockholm Center for Physics, Astronomy and Biotechnology
> > > Department of Molecular Biotechnology
> > > 106 91 Stockholm, Sweden
> > >
> > > Phone (office): +46 8 553 783 45
> > > Fax: + 46 8 553 784 81
> > > Visiting adress: Roslagstullsbacken 21, Floor 3
> > > Delivery adress: Roslagsv?gen 30B
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
> > >
> 
> **************************************************************
> *****************************
> Johan Lindberg
> Royal Institute of Technology
> AlbaNova University Center
> Stockholm Center for Physics, Astronomy and Biotechnology
> Department of Molecular Biotechnology
> 106 91 Stockholm, Sweden
> 
> Phone (office): +46 8 553 783 45
> Fax: + 46 8 553 784 81
> Visiting adress: Roslagstullsbacken 21, Floor 3
> Delivery adress: Roslagsv?gen 30B
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From sam.kemp2 at ntlworld.com  Mon Jan  5 16:06:50 2004
From: sam.kemp2 at ntlworld.com (Samuel Kemp)
Date: Mon, 05 Jan 2004 15:06:50 +0000
Subject: [R] corrupt data object/session???
Message-ID: <3FF97D8A.2000803@ntlworld.com>

Hi,

I have written the following R function.....

GT <- function(data, p)
{
     if(!is.loaded(symbol.C("runGT")))
 
dyn.load("/home/sekemp/Documents/RFiles/GammaProject/Test/GammaImproved2.so")
     dim <- length(data)
     M <- length(data[,dim])
     reconstruct <- array(dim=c(M,dim))
     for(i in 1:(dim-1))
     {
         reconstruct[,i] <- data[,i]
     }
     outputs <- array(data[,dim])
     inputs <- array(as.matrix(dist(reconstruct, method="euclidean", 
diag=TRUE, upper=TRUE)), dim=c(M,M))
     overall <- .C("runGT",
     as.double(inputs),
     as.double(outputs),
     as.integer(M),
     as.integer(p),
     rd = double(p),
     rg = double(p))
     deltas <- overall$rd
     gammas <- overall$rg
     GT <- data.frame(deltas, gammas)
     return(GT)
}

When I use the function it returns the correct results. However, when I 
call the function for a second (3rd, 4th, etc) time it runs OK but does 
not return the correct result.

I am using R on the latest version of Red Hat Linux.

Does anyone have any ideas on a fix for this problem????

Cheers,

Sam.



From statho3 at web.de  Mon Jan  5 16:07:37 2004
From: statho3 at web.de (Thomas Stabla)
Date: Mon, 5 Jan 2004 16:07:37 +0100 (CET)
Subject: [R] Set values in namespaces
In-Reply-To: <Pine.LNX.4.44.0401051327430.10920-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0401051546400.2253-100000@spock.vulcan>

On Mon, 5 Jan 2004, Prof Brian Ripley wrote:

> On Mon, 5 Jan 2004, Thomas Stabla wrote:
>
> > I want to use global variables in a package which is using a namespace.
> > But I don`t know how to change the values of the global variables.
> >
> > I know how to get the value of the variables, e.g.
> >
> > > base::pi
> > [1] 3.141593
> >
> > but following code doesn`t work
> >
> > > base::pi <- 3.14
> > Error: Object "base" not found
>
> Base is a special case, and
>
> assign("pi", 3.14, envir=NULL)
>
> will do this (although please don't).
>
> All other namespaces are sealed, so you will get something like
>
> > library(MASS)
> > assign("lda", pi, pos=2)
> Error in assign("lda", pi, pos = 2) : can't change value of a locked binding
>
> Now, that attempts to change the export, and not the value in the
> namespace, so there is a question of which you want and why you want to
> change it.  (Changing the value in the namespace does not change the
> export, which is a copy, but as _both_ the namespace and exports
> environments are sealed, this would not matter much.)
>

In which manuals do I have to look to learn more about namespaces, exports
and sealed environments? I`m not yet very familiar with this concepts.

I want to be able to change the values, so that the user of the package
can control in some way how some of the functions in the package will work.

"useless" example:

mypackage::username = "Thomas"
mypackage::printusername = function() print(username)

> There are ways around this and if you peruse the R sources you will find
> them.  For example, grid sets up an environment in its namespace for its
> global variables, and in R-devel there is assignInNamespace().
>

Well, I looked at grid sources, and found the piece of code you mentioned,
but wasn`t able to understand it fully.
As a work-around, I now use the function assignInNamespace() from R-devel,
which also works in R 1.8.1 if it`s pasted in the running R process.

Thanks,
Thomas Stabla



From Simon.Fear at synequanon.com  Mon Jan  5 16:20:33 2004
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Mon, 5 Jan 2004 15:20:33 -0000
Subject: [R] Analyzing dendograms??
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F02164@synequanon01>

Post script: I'm afraid my `solution` was no good, because
I forgot the need to change nc and nr. (I got bogged down
in passing ylim and lost track of your real question.)

Hopefully someone with a deeper understanding of the
original problem will come to the rescue. If not there may
be milage on restricting your matrix[,] to matrix[<cond1>,<cond2>]
according to information in sclus and gclus. But I am in
over my depth here.

> >On Sun, 4 Jan 2004, Johan Lindberg wrote:
> >
> > >
> > > I have used heatmap to visualize my microarray data. I 
> have a matrix of
> > > M-values. I do the following.
> > >
> > > #The distance between the columns.
> > > sampdist <- dist(t(matrix[,]), method="euclidean")
> > > sclus <- hclust(sampdist, method="average")
> > > #The distance between the rows.
> > > genedist <- dist(matrix[,], method="euclidean")
> > > gclus <- hclust(genedist, method="average")
> > > 
> heatmap(matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram
> (sclus), 
> > col=rbg)
> > >
> > > So far so good. But what if I want to look at a group of 
> genes that appear
> > > to have the same expression pattern in the heatmap? How 
> do I zoom in on a
> > > dendogram in a heatmap to look at which genes that are forming the
> > > interesting clusters? I would really appreciate if 
> someone could give me a
> > > pointer.  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From ligges at statistik.uni-dortmund.de  Mon Jan  5 16:46:57 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 05 Jan 2004 16:46:57 +0100
Subject: [R] corrupt data object/session???
In-Reply-To: <3FF97D8A.2000803@ntlworld.com>
References: <3FF97D8A.2000803@ntlworld.com>
Message-ID: <3FF986F1.2030903@statistik.uni-dortmund.de>

Samuel Kemp wrote:

> Hi,
> 
> I have written the following R function.....
> 
> GT <- function(data, p)
> {
>     if(!is.loaded(symbol.C("runGT")))
> 
> dyn.load("/home/sekemp/Documents/RFiles/GammaProject/Test/GammaImproved2.so") 
> 
>     dim <- length(data)
>     M <- length(data[,dim])
>     reconstruct <- array(dim=c(M,dim))
>     for(i in 1:(dim-1))
>     {
>         reconstruct[,i] <- data[,i]
>     }
>     outputs <- array(data[,dim])
>     inputs <- array(as.matrix(dist(reconstruct, method="euclidean", 
> diag=TRUE, upper=TRUE)), dim=c(M,M))
>     overall <- .C("runGT",
>     as.double(inputs),
>     as.double(outputs),
>     as.integer(M),
>     as.integer(p),
>     rd = double(p),
>     rg = double(p))
>     deltas <- overall$rd
>     gammas <- overall$rg
>     GT <- data.frame(deltas, gammas)
>     return(GT)
> }
> 
> When I use the function it returns the correct results. However, when I 
> call the function for a second (3rd, 4th, etc) time it runs OK but does 
> not return the correct result.
> 
> I am using R on the latest version of Red Hat Linux.
> 
> Does anyone have any ideas on a fix for this problem????

Some hints:

What is "overall"? Where do you get that variable from? Is it chnaged in 
the other environment?
What does your C level function? Does it use random numbers or do you 
change values in R from this C level function?

You have to debug your function youself, since nobody else can reproduce 
your examples!

Uwe Ligges



> Cheers,
> 
> Sam.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From SuzieBlatt at netscape.net  Mon Jan  5 16:50:48 2004
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Mon, 05 Jan 2004 10:50:48 -0500
Subject: [R] Installing spdep
Message-ID: <121324EA.46D05D8C.0D1322AF@netscape.net>

Hello all,

I am trying to install the package 'spdep' and get the following error message when I invoke library(spdep) at the R prompt:

Error in loadNamespace(i, c(lib.loc, .libPaths()), keep.source)
    There is no package called 'maptools'
Error in library(spdep) : package/namespace load failed

I get this if I try to install 'on the fly' AND if I download directly from the download mirror (http://probability.ca/cran/) and then install inside my terminal (in superuser of course).

Any thoughts on where I can get 'maptools' or why it can't seem to locate it if it is indeed on my machine?

Thanks,

Suzanne



From rpeng at jhsph.edu  Mon Jan  5 16:55:46 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 05 Jan 2004 10:55:46 -0500
Subject: [R] Installing spdep
In-Reply-To: <121324EA.46D05D8C.0D1322AF@netscape.net>
References: <121324EA.46D05D8C.0D1322AF@netscape.net>
Message-ID: <3FF98902.40309@jhsph.edu>

maptools is a CRAN package.  You need to install that first (using 
install.packages() for example).

-roger

Suzanne E. Blatt wrote:
> Hello all,
> 
> I am trying to install the package 'spdep' and get the following error message when I invoke library(spdep) at the R prompt:
> 
> Error in loadNamespace(i, c(lib.loc, .libPaths()), keep.source)
>     There is no package called 'maptools'
> Error in library(spdep) : package/namespace load failed
> 
> I get this if I try to install 'on the fly' AND if I download directly from the download mirror (http://probability.ca/cran/) and then install inside my terminal (in superuser of course).
> 
> Any thoughts on where I can get 'maptools' or why it can't seem to locate it if it is indeed on my machine?
> 
> Thanks,
> 
> Suzanne
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Simon.Fear at synequanon.com  Mon Jan  5 16:58:58 2004
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Mon, 5 Jan 2004 15:58:58 -0000
Subject: [R] Set values in namespaces
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F02165@synequanon01>

Digressing somewhat from the namespace discussion, and
focussing on

> I want to be able to change the values, so that the user of 
> the package
> can control in some way how some of the functions in the 
> package will work.
> 
> "useless" example:
> 
> mypackage::username = "Thomas"
> mypackage::printusername = function() print(username)
> 

you might instead just put this info into a list perhaps called
mypackageOptions, which would allow the user to change 
things such as mypackageOptions$username <- "Simon", or
you could even write a friendlier wrapper (like options itself).

I realise this is not as beautiful as you are trying to achieve, but 
it's there if you need a quick fix.  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From Roger.Bivand at nhh.no  Mon Jan  5 17:05:55 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 5 Jan 2004 17:05:55 +0100 (CET)
Subject: [R] Installing spdep
In-Reply-To: <121324EA.46D05D8C.0D1322AF@netscape.net>
Message-ID: <Pine.LNX.4.44.0401051703530.7302-100000@reclus.nhh.no>

On Mon, 5 Jan 2004, Suzanne E. Blatt wrote:

> Hello all,
> 
> I am trying to install the package 'spdep' and get the following error
> message when I invoke library(spdep) at the R prompt:
> 
> Error in loadNamespace(i, c(lib.loc, .libPaths()), keep.source)
>     There is no package called 'maptools'
> Error in library(spdep) : package/namespace load failed
> 
> I get this if I try to install 'on the fly' AND if I download directly
> from the download mirror (http://probability.ca/cran/) and then install
> inside my terminal (in superuser of course).
> 
> Any thoughts on where I can get 'maptools' or why it can't seem to
> locate it if it is indeed on my machine?

This was answered in 

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/13242.html

The spdep package depends on the maptools package, so install maptools
first, then spdep. That should mean that you can use it.

Roger

> 
> Thanks,
> 
> Suzanne
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From christoph.lehmann at gmx.ch  Mon Jan  5 17:13:07 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Mon, 05 Jan 2004 17:13:07 +0100
Subject: [R] lda() called with data=subset() command
Message-ID: <1073319187.6509.171.camel@christophl>

Hi
I have a data.frame with a grouping variable having the levels 

C, 
mild AD, 
mod AD, 
O and 
S

since I want to compute a lda only for the two groups 'C' and 'mod AD' I
call lda with data=subset(mydata.pca,GROUP == 'mod AD' | GROUP == 'C')


my.lda <- lda(GROUP ~ Comp.1 + Comp.2 + Comp.3 + Comp.4+  Comp.5 +
Comp.6 + Comp.7 + Comp.8  , data=subset(mydata.pca,GROUP == 'mod AD' |
GROUP == 'C'), CV = TRUE)

this results in the warning "group(s) mild AD O S are empty in:
lda.default(x, grouping, ...)" of course...

my.lda$class now shows 

 [1] C       C       C       C       C       C       C       C       C
[10] C       C       C       C       C       C       C       C       C
[19] C       C       C       mild AD mild AD mild AD mild AD mild AD
mild AD
[28] mild AD C       mild AD mild AD mild AD C       C       mild AD
mild AD
[37] mild AD mild AD
Levels: C mild AD mod AD O S

it seems it just took the second level (mild AD) for the second class,
even though the second level was not used for the lda computation (only
the first level (C) and the third level (mod AD)

what shall I do to resolve this (little) problem?

thanks for a  hint

christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From I3tv-bounces at udius.com  Mon Jan  5 17:56:16 2004
From: I3tv-bounces at udius.com (I3tv-bounces@udius.com)
Date: Mon, 05 Jan 2004 11:56:16 -0500
Subject: [R] =?iso-8859-1?q?Votre_abonnement_=E0_la_liste_I3tv_a_=E9t=E9_?=
 =?iso-8859-1?q?r=E9sili=E9?=
Message-ID: <mailman.0.1073321776.5719.i3tv_udius.com@udius.com>



From Deborah.Renz at stud.unibas.ch  Mon Jan  5 18:27:25 2004
From: Deborah.Renz at stud.unibas.ch (Deborah.Renz@stud.unibas.ch)
Date: Mon,  5 Jan 2004 18:27:25 +0100
Subject: [R] Heeeeeelp! Estimatet Marginal Means of ANOVA needed!
Message-ID: <1073323645.3ff99e7d86e7e@webmail.unibas.ch>


Hello!

I urgently need to know if it is possible (and if so, how to do) to get 
the "Estimatet marginal means" from an ANOVA.
Or explained more coplicated: It's about plants sewn in 2 densities & 2 
patterns. The Variable is biomass and I also use a Covariate. There are highly 
significant differences between density & pattern but I don't know which of the 
2 densities gives the higher biomass values.
I would like to get something analoge to the "Estimatet Marginal Means" you get 
with SPSS.
Who can help me as soon as possible?

Thanks
Deborah Renz


-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From spencer.graves at pdf.com  Mon Jan  5 18:35:32 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 05 Jan 2004 09:35:32 -0800
Subject: [R] Heeeeeelp! Estimatet Marginal Means of ANOVA needed!
In-Reply-To: <1073323645.3ff99e7d86e7e@webmail.unibas.ch>
References: <1073323645.3ff99e7d86e7e@webmail.unibas.ch>
Message-ID: <3FF9A064.2060200@pdf.com>

Have you considered feeding the ANOVA fit to "predict"?  A second 
alternative might be "tapply".  hope this helps.  spencer graves

Deborah.Renz at stud.unibas.ch wrote:

>Hello!
>
>I urgently need to know if it is possible (and if so, how to do) to get 
>the "Estimatet marginal means" from an ANOVA.
>Or explained more coplicated: It's about plants sewn in 2 densities & 2 
>patterns. The Variable is biomass and I also use a Covariate. There are highly 
>significant differences between density & pattern but I don't know which of the 
>2 densities gives the higher biomass values.
>I would like to get something analoge to the "Estimatet Marginal Means" you get 
>with SPSS.
>Who can help me as soon as possible?
>
>Thanks
>Deborah Renz
>
>
>-------------------------------------------------
>This mail sent through IMP: http://horde.org/imp/
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ripley at stats.ox.ac.uk  Mon Jan  5 18:59:42 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jan 2004 17:59:42 +0000 (GMT)
Subject: [R] lda() called with data=subset() command
In-Reply-To: <1073319187.6509.171.camel@christophl>
Message-ID: <Pine.LNX.4.44.0401051749440.11624-100000@gannet.stats>

I presume is lda from the uncredited package MASS and you ignored the
advice to ask the maintainer?

The short answer is `don't ignore the warning', and set up a proper data 
frame with just the groups you actually want.

As a quick fix, look in lda.default and alter the line that looks like

        cl <- factor(max.col(dist), levels=seq(along=lev1), labels=lev1)

to be exactly like that.  (You will need fixInNamespace to do so.)


On Mon, 5 Jan 2004, Christoph Lehmann wrote:

> Hi
> I have a data.frame with a grouping variable having the levels 
> 
> C, 
> mild AD, 
> mod AD, 
> O and 
> S
> 
> since I want to compute a lda only for the two groups 'C' and 'mod AD' I
> call lda with data=subset(mydata.pca,GROUP == 'mod AD' | GROUP == 'C')
> 
> 
> my.lda <- lda(GROUP ~ Comp.1 + Comp.2 + Comp.3 + Comp.4+  Comp.5 +
> Comp.6 + Comp.7 + Comp.8  , data=subset(mydata.pca,GROUP == 'mod AD' |
> GROUP == 'C'), CV = TRUE)
> 
> this results in the warning "group(s) mild AD O S are empty in:
> lda.default(x, grouping, ...)" of course...
> 
> my.lda$class now shows 
> 
>  [1] C       C       C       C       C       C       C       C       C
> [10] C       C       C       C       C       C       C       C       C
> [19] C       C       C       mild AD mild AD mild AD mild AD mild AD
> mild AD
> [28] mild AD C       mild AD mild AD mild AD C       C       mild AD
> mild AD
> [37] mild AD mild AD
> Levels: C mild AD mod AD O S
> 
> it seems it just took the second level (mild AD) for the second class,
> even though the second level was not used for the lda computation (only
> the first level (C) and the third level (mod AD)
> 
> what shall I do to resolve this (little) problem?
> 
> thanks for a  hint
> 
> christoph
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jingwu at stat.purdue.edu  Mon Jan  5 19:18:06 2004
From: jingwu at stat.purdue.edu (Jing Wu)
Date: Mon, 5 Jan 2004 13:18:06 -0500 (EST)
Subject: [R] build R package on winXP
Message-ID: <Pine.A41.4.58.0401051317400.150712@odds.stat.purdue.edu>

Hello,

I wrote an R function and want to build an R package on winXP. I have
set my
path:C:\bin;C:\MinGW\bin;C:\Perl\bin\;C:\Tcl\bin;C:\texmf\miktex\bin;C:\Program
Files\R\rw1081\bin;

I tried to run "Rcmd build --help" but failed. Under
C:\WINDOWS\System32\cmd.exe, I got the error message:
Please set TMPDIR to a valid temporary directory.

Under Cygwin, I got the error message:
Can't locate R/Dcf.pm in @INC <@INC contains: c
\PROGRA~1\R\rw1081\share\perl; /usr/lib/perl5/5.8.0/cygwin-multi-64int
/usr/lib/perl5/site_perl/5.8.0/cygwin-multi-64int
/usr/lib/perl5/site_perl/5.8.0 /usr/lib/perl5/site_perl .> at
c:\PROGRA~1\R\rw1081/bin/build line 34.
BEGIN failed--compilation aborted at c:\PROGRA~1\R\rw1081/bin/build line
34.

I have Dcf.pm in \PROGRA~1\R\rw1081\share\perl\R. Why Rcmd build can not
find it?

Thanks.

Jing



From ripley at stats.ox.ac.uk  Mon Jan  5 19:32:30 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jan 2004 18:32:30 +0000 (GMT)
Subject: [R] build R package on winXP
In-Reply-To: <Pine.A41.4.58.0401051317400.150712@odds.stat.purdue.edu>
Message-ID: <Pine.LNX.4.44.0401051827130.11737-100000@gannet.stats>

On Mon, 5 Jan 2004, Jing Wu wrote:

> I wrote an R function and want to build an R package on winXP. I have
> set my
> path:C:\bin;C:\MinGW\bin;C:\Perl\bin\;C:\Tcl\bin;C:\texmf\miktex\bin;C:\Program
> Files\R\rw1081\bin;
> 
> I tried to run "Rcmd build --help" but failed. Under
> C:\WINDOWS\System32\cmd.exe, I got the error message:
> Please set TMPDIR to a valid temporary directory.

So, please do as you were asked: it is discussed in readme.packages.

> Under Cygwin, I got the error message:

You said you wanted to build on winXP, not under Cygwin.

> Can't locate R/Dcf.pm in @INC <@INC contains: c
> \PROGRA~1\R\rw1081\share\perl; /usr/lib/perl5/5.8.0/cygwin-multi-64int
> /usr/lib/perl5/site_perl/5.8.0/cygwin-multi-64int
> /usr/lib/perl5/site_perl/5.8.0 /usr/lib/perl5/site_perl .> at
> c:\PROGRA~1\R\rw1081/bin/build line 34.
> BEGIN failed--compilation aborted at c:\PROGRA~1\R\rw1081/bin/build line
> 34.
> 
> I have Dcf.pm in \PROGRA~1\R\rw1081\share\perl\R. Why Rcmd build can not
> find it?

Because you are not following the instructions, which are to use *Windows* 
Perl.  Once again, this is in the file readme.packages.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From eric.esposito at gazdefrance.com  Mon Jan  5 13:07:08 2004
From: eric.esposito at gazdefrance.com (Eric ESPOSITO)
Date: Mon, 5 Jan 2004 13:07:08 +0100
Subject: [R] runif and sample with reproducibility
Message-ID: <OFF132900B.CF0F4C6E-ON41256E12.00424078@notes.edfgdf.fr>

Hello,
I already sent such an email before Christmas, but nobody answered, so here
is my problem:
I would like to sample a population but the result needs to be
reproducible, using 'runif' or 'sample' is the good way to do it but I
can't manage to make the results reproducible even with the 'set.seed'
function.
My aim is that th call to 'sample(1:100,10)' gives always the same result,
how can I do that?
Thanks!

Eric Esposito



From rpeng at jhsph.edu  Mon Jan  5 19:42:54 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 05 Jan 2004 13:42:54 -0500
Subject: [R] runif and sample with reproducibility
In-Reply-To: <OFF132900B.CF0F4C6E-ON41256E12.00424078@notes.edfgdf.fr>
References: <OFF132900B.CF0F4C6E-ON41256E12.00424078@notes.edfgdf.fr>
Message-ID: <3FF9B02E.9010800@jhsph.edu>

When I use set.seed() in R 1.8.1, I get the following:

 > set.seed(1)
 > sample(1:100, 10)
  [1] 27 37 57 89 20 86 97 62 58  6
 > set.seed(1)
 > sample(1:100, 10)
  [1] 27 37 57 89 20 86 97 62 58  6
 > set.seed(1)
 > sample(1:100, 10)
  [1] 27 37 57 89 20 86 97 62 58  6
 > set.seed(2)
 > runif(10)
  [1] 0.1848823 0.7023740 0.5733263 0.1680519 0.9438393 0.9434750 0.1291590
  [8] 0.8334488 0.4680185 0.5499837
 > set.seed(2)
 > runif(10)
  [1] 0.1848823 0.7023740 0.5733263 0.1680519 0.9438393 0.9434750 0.1291590
  [8] 0.8334488 0.4680185 0.5499837


What output do you get?  Also, keep in mind that the default random 
number generator changed in (I believe) R 1.7.0 so you may need to use 
RNGversion() to reproduce results from earlier versions of R.

-roger

Eric ESPOSITO wrote:
> Hello,
> I already sent such an email before Christmas, but nobody answered, so here
> is my problem:
> I would like to sample a population but the result needs to be
> reproducible, using 'runif' or 'sample' is the good way to do it but I
> can't manage to make the results reproducible even with the 'set.seed'
> function.
> My aim is that th call to 'sample(1:100,10)' gives always the same result,
> how can I do that?
> Thanks!
> 
> Eric Esposito
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Mon Jan  5 19:50:54 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Jan 2004 18:50:54 +0000 (GMT)
Subject: [R] runif and sample with reproducibility
In-Reply-To: <OFF132900B.CF0F4C6E-ON41256E12.00424078@notes.edfgdf.fr>
Message-ID: <Pine.LNX.4.44.0401051847350.11827-100000@gannet.stats>

On Mon, 5 Jan 2004, Eric ESPOSITO wrote:

> Hello,
> I already sent such an email before Christmas, but nobody answered, so here

There *was* an answer posted, see the archives here:

https://www.stat.math.ethz.ch/pipermail/r-help/2003-December/042422.html

and none of the rest of us has any idea why this does not work for you
(if indeed it does not).

> is my problem:
> I would like to sample a population but the result needs to be
> reproducible, using 'runif' or 'sample' is the good way to do it but I
> can't manage to make the results reproducible even with the 'set.seed'
> function.
> My aim is that th call to 'sample(1:100,10)' gives always the same result,
> how can I do that?
> Thanks!
> 
> Eric Esposito

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From anielsen at math.ku.dk  Mon Jan  5 19:56:23 2004
From: anielsen at math.ku.dk (Anders Nielsen)
Date: Mon, 5 Jan 2004 19:56:23 +0100 (CET)
Subject: [R] runif and sample with reproducibility
In-Reply-To: <OFF132900B.CF0F4C6E-ON41256E12.00424078@notes.edfgdf.fr>
Message-ID: <Pine.LNX.4.40.0401051954340.26821-100000@shannon.math.ku.dk>

Hi Eric,

How about:

> set.seed(1234567)
> sample(1:100,10)
 [1] 57 72 90  3 74 46  9 81 95 78
> set.seed(1234567)
> sample(1:100,10)
 [1] 57 72 90  3 74 46  9 81 95 78
>

Cheers,

Anders.


On Mon, 5 Jan 2004, Eric ESPOSITO wrote:

> Hello,
> I already sent such an email before Christmas, but nobody answered, so here
> is my problem:
> I would like to sample a population but the result needs to be
> reproducible, using 'runif' or 'sample' is the good way to do it but I
> can't manage to make the results reproducible even with the 'set.seed'
> function.
> My aim is that th call to 'sample(1:100,10)' gives always the same result,
> how can I do that?
> Thanks!
>
> Eric Esposito
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From ggrothendieck at myway.com  Mon Jan  5 20:00:10 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon,  5 Jan 2004 14:00:10 -0500 (EST)
Subject: [R] runif and sample with reproducibility
Message-ID: <20040105190010.A59D63991@mprdmxin.myway.com>



With this sort of problem you will get better chance of
a response if you reduce your program down to a small 
reproducable example which illustrates the behavior.
Also give your R version and your OS version.

When I try running sample(100,10) repeatedly on R 1.8.1 under 
Windows 2000 Pro it works fine:

> f <- function() { set.seed(1); sample(100,10) }
> 
> a <- f()
> for(i in 1:1000) if (!identical(f(),a)) cat("not identical\n")
> 

Note that no output was produced showing the random numbers were
always the same.

---
Date: Mon, 5 Jan 2004 13:07:08 +0100 
From: Eric ESPOSITO <eric.esposito at gazdefrance.com>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] runif and sample with reproducibility 

 
 
Hello,
I already sent such an email before Christmas, but nobody answered, so here
is my problem:
I would like to sample a population but the result needs to be
reproducible, using 'runif' or 'sample' is the good way to do it but I
can't manage to make the results reproducible even with the 'set.seed'
function.
My aim is that th call to 'sample(1:100,10)' gives always the same result,
how can I do that?
Thanks!

Eric Esposito

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From edd at debian.org  Mon Jan  5 20:04:15 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 5 Jan 2004 13:04:15 -0600
Subject: [R] runif and sample with reproducibility
In-Reply-To: <OFF132900B.CF0F4C6E-ON41256E12.00424078@notes.edfgdf.fr>
References: <OFF132900B.CF0F4C6E-ON41256E12.00424078@notes.edfgdf.fr>
Message-ID: <20040105190415.GA1660@sonny.eddelbuettel.com>

On Mon, Jan 05, 2004 at 01:07:08PM +0100, Eric ESPOSITO wrote:
> I would like to sample a population but the result needs to be
> reproducible, using 'runif' or 'sample' is the good way to do it but I
> can't manage to make the results reproducible even with the 'set.seed'
> function.
> My aim is that th call to 'sample(1:100,10)' gives always the same result,
> how can I do that?

help(set.seed)

Hth, Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From andy_liaw at merck.com  Mon Jan  5 20:06:20 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 5 Jan 2004 14:06:20 -0500
Subject: [R] Heeeeeelp! Estimatet Marginal Means of ANOVA needed!
Message-ID: <3A822319EB35174CA3714066D590DCD504AF75AD@usrymx25.merck.com>

I've never used SPSS, so don't know what it refers to as "estimated marginal
means".  However, my guess is that they are probably what SAS calls LS
(least squares) means.  I know Prof. Yandell has written a lsmeans()
function for his "pda" package (supporting his book, "Practical Data
Analysis for Designed Experiments") which you can find on his web page.

Hope this helps,
Andy

> From: Deborah.Renz at stud.unibas.ch
> 
> Hello!
> 
> I urgently need to know if it is possible (and if so, how to 
> do) to get 
> the "Estimatet marginal means" from an ANOVA.
> Or explained more coplicated: It's about plants sewn in 2 
> densities & 2 
> patterns. The Variable is biomass and I also use a Covariate. 
> There are highly 
> significant differences between density & pattern but I don't 
> know which of the 
> 2 densities gives the higher biomass values.
> I would like to get something analoge to the "Estimatet 
> Marginal Means" you get 
> with SPSS.
> Who can help me as soon as possible?
> 
> Thanks
> Deborah Renz


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From lisas at salford-systems.com  Mon Jan  5 20:29:46 2004
From: lisas at salford-systems.com (Lisa Solomon)
Date: Mon, 05 Jan 2004 11:29:46 -0800
Subject: [R] DATA MINING Conference
 =?windows-1252?q?=96_30th_January_is_the_d?=
 =?windows-1252?q?eadline_for_early-bird_registration_discount=2E?=
Message-ID: <3FF9BB2A.6000901@salford-systems.com>

Apologies for cross posting....
Early-Bird Registration Discount Deadline

Just a quick reminder.
If you are interested in attending CART Data 
Mining 2004 (San Francisco), the EARLY-BIRD discounted registration 
deadline is January 30th, 2004.  Registration materials are available 
at: http://www.cartdatamining.com/RegCART04.pdf

Other deadlines:
Paper Submission: January 12th
Student Contest: January 10th
---------------------------------------------------------------------
CART Data Mining'04: First International CART(R) Conferences
    Focusing on the Data Mining technology of
Leo Breiman, Jerome Friedman, Richard Olshen, Charles Stone
    (CART, MARS(R), TreeNet(tm), PRIM(tm)...)
---------------------------------------------------------------------

  US Venue:  San Francisco, March 22-24, 2004
  EU Venue:  Madrid,        May   11-12, 2004

Conference home page: http://www.cartdatamining.com

----------------------------------------------------------

Keynote Speakers:

Leo Breiman,     University of California, Berkeley
Jerome Friedman, Stanford University
Richard Olshen,  Stanford University
Charles Stone,   University of California, Berkeley

Conference Sponsor:         Salford Systems, http://www.salford-systems.com

The conferences are intended to serve several functions:

o A festschrift and opportunity to honor the four
authors of CART and meet with them in person. Each
is planning to offer a keynote paper.

o A venue to exchange ideas and experiences focused
on the practice of data mining.

o A networking opportunity leading to the creation of
local user  groups and the establishment of a user
newsletter.

o A place to learn about extensions to CART related
technology and anticipated future developments

o An opportunity to obtain both basic and advanced training
offered by practical and theoretical experts

The conference series will provide an opportunity for data mining
professionals to exchange ideas on the art and practice of the real
world analysis of complex data.  Presentations will report on real world 
data and reflect applied data analysis utilizing CART, MARS, PRIM, and 
TreeNet, including innovative and unusual applications.

Breiman's Random Forests will be the subject of an introductory
tutorial.  A workshop devoted solely to RF will be scheduled separately.

Industry sessions:

Financial Services
Targeted marketing, customer Acquisition
Fraud Detection
CRM: Customer Retention
Risk management and score card development
Loss management in insurance
Financial Markets Modeling
Stock Selection and Portfolio Management
Business Cycle Forecasting
Telecommunications
Churn modeling
Collections management
Fraud detection
Bioinformatics, Healthcare and Medicine
DNA Microarray Data Analysis
Proteomics
Drug Discovery
Web Mining and Text Mining
User profiling
Recommendation Systems
Learning from Designed Experiments
     eCommerce
Engineering, Manufacturing, and Quality Control
Semiconductor quality control
Public Sector, Defense, Security

Conference Participation

If you have an interest in attending this conference
please let us know via email at info at cartdatamining.com
Please contact me if you have any questions.

Best regards,
Lisa Solomon

Voice:(619)543-8880 x21, Fax:(619)543-8888
e-Mail: lisas at salford-systems.com
Homepage: http://www.cartdatamining.com



From jfox at mcmaster.ca  Mon Jan  5 20:35:10 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 05 Jan 2004 14:35:10 -0500
Subject: [R] Heeeeeelp! Estimatet Marginal Means of ANOVA needed!
In-Reply-To: <1073323645.3ff99e7d86e7e@webmail.unibas.ch>
Message-ID: <5.0.2.1.0.20040105143423.00b11258@127.0.0.1>

Dear Deborah,

The effects package may do what you want.

John

At 06:27 PM 1/5/2004 +0100, Deborah.Renz at stud.unibas.ch wrote:

>Hello!
>
>I urgently need to know if it is possible (and if so, how to do) to get
>the "Estimatet marginal means" from an ANOVA.
>Or explained more coplicated: It's about plants sewn in 2 densities & 2
>patterns. The Variable is biomass and I also use a Covariate. There are 
>highly
>significant differences between density & pattern but I don't know which 
>of the
>2 densities gives the higher biomass values.
>I would like to get something analoge to the "Estimatet Marginal Means" 
>you get
>with SPSS.
>Who can help me as soon as possible?
>
>Thanks
>Deborah Renz

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From jahaye at wm.edu  Mon Jan  5 20:54:30 2004
From: jahaye at wm.edu (John Hayes)
Date: Mon, 05 Jan 2004 14:54:30 -0500
Subject: [R] loading matrix from file
Message-ID: <1073332469.6934.15927.camel@xizor.incogen.com>

What is the best way to load a matrix from a text file if it's already
in a matrix form?  I'd like the parser function to automagically
recognize that line separators indicate a new row.  The technique I've
been using is the following:

output <- matrix(scan(inputFile), byrow=T, ncol=2)

However, I don't want to have to specify ncol=2.  

Thanks!

John



From abunn at montana.edu  Mon Jan  5 21:36:12 2004
From: abunn at montana.edu (Andy Bunn)
Date: Mon, 5 Jan 2004 13:36:12 -0700
Subject: [R] loading matrix from file
In-Reply-To: <1073332469.6934.15927.camel@xizor.incogen.com>
Message-ID: <000401c3d3cb$977b7c20$78f05a99@msu.montana.edu>

What's wrong with read.table? It's the principal function for reading
data into R.
-Andy



From ggrothendieck at myway.com  Mon Jan  5 21:37:51 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon,  5 Jan 2004 15:37:51 -0500 (EST)
Subject: [R] loading matrix from file
Message-ID: <20040105203751.437553996@mprdmxin.myway.com>



You could try:

   as.matrix( read.table( filename ) )


Date: Mon, 05 Jan 2004 14:54:30 -0500 
From: John Hayes <jahaye at wm.edu>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] loading matrix from file 

 
 
What is the best way to load a matrix from a text file if it's already
in a matrix form? I'd like the parser function to automagically
recognize that line separators indicate a new row. The technique I've
been using is the following:

output <- matrix(scan(inputFile), byrow=T, ncol=2)

However, I don't want to have to specify ncol=2. 

Thanks!

John



From Kang.Changku at epamail.epa.gov  Mon Jan  5 21:45:16 2004
From: Kang.Changku at epamail.epa.gov (Kang.Changku@epamail.epa.gov)
Date: Mon, 05 Jan 2004 15:45:16 -0500
Subject: [R] optim function : "BFGS" vs "L-BFGS-B"
Message-ID: <OF2801A464.D16DC291-ON85256E12.00713A41-85256E12.007202A4@epamail.epa.gov>





Dear kind R-experts.

Does anybody have an experience to use optim function?
If yes, what is the main difference between two method "BFGS" vs
"L-BFGS-B"?
I used "BFGS" method and got what I wanted. But when I used "L-BFGS-B"
the error message said that "L-BFGS-B needs finite values of fn". So
that means
"BFGS" method can handle even if fn function is infinite value?

What I really want to know is that can I get the same result by using
L-BFGS-B method?

+++++++++++++++++++++++++++++++++++++++++++++++++++++
Changku Kang
National Center for Environmental Assessment
EPA  (B211F)
919-541-1396
919-541-0245 (fax)
Kang.Changku at epa.gov

Graduate Student
Department of Statistics, NCSU
ckang2 at stat.ncsu.edu
919-513-2956
+++++++++++++++++++++++++++++++++++++++++++++++++++++



From rpeng at jhsph.edu  Mon Jan  5 23:00:56 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 05 Jan 2004 17:00:56 -0500
Subject: [R] optim function : "BFGS" vs "L-BFGS-B"
In-Reply-To: <OF2801A464.D16DC291-ON85256E12.00713A41-85256E12.007202A4@epamail.epa.gov>
References: <OF2801A464.D16DC291-ON85256E12.00713A41-85256E12.007202A4@epamail.epa.gov>
Message-ID: <3FF9DE98.9050309@jhsph.edu>

The help page for optim() says:

      Function 'fn' can return 'NA' or 'Inf' if the function cannot be
      evaluated at the supplied value, but the initial value must have a
      computable finite value of 'fn'. (Except for method '"L-BFGS-B"'
      where the values should always be finite.)

-roger

Kang.Changku at epamail.epa.gov wrote:
> 
> 
> 
> Dear kind R-experts.
> 
> Does anybody have an experience to use optim function?
> If yes, what is the main difference between two method "BFGS" vs
> "L-BFGS-B"?
> I used "BFGS" method and got what I wanted. But when I used "L-BFGS-B"
> the error message said that "L-BFGS-B needs finite values of fn". So
> that means
> "BFGS" method can handle even if fn function is infinite value?
> 
> What I really want to know is that can I get the same result by using
> L-BFGS-B method?
> 
> +++++++++++++++++++++++++++++++++++++++++++++++++++++
> Changku Kang
> National Center for Environmental Assessment
> EPA  (B211F)
> 919-541-1396
> 919-541-0245 (fax)
> Kang.Changku at epa.gov
> 
> Graduate Student
> Department of Statistics, NCSU
> ckang2 at stat.ncsu.edu
> 919-513-2956
> +++++++++++++++++++++++++++++++++++++++++++++++++++++
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From tlumley at u.washington.edu  Mon Jan  5 23:20:43 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 5 Jan 2004 14:20:43 -0800 (PST)
Subject: [R] optim function : "BFGS" vs "L-BFGS-B"
In-Reply-To: <OF2801A464.D16DC291-ON85256E12.00713A41-85256E12.007202A4@epamail.epa.gov>
References: <OF2801A464.D16DC291-ON85256E12.00713A41-85256E12.007202A4@epamail.epa.gov>
Message-ID: <Pine.A41.4.58.0401051413010.70308@homer11.u.washington.edu>

On Mon, 5 Jan 2004 Kang.Changku at epamail.epa.gov wrote:

>
>
>
>
> Dear kind R-experts.
>
> Does anybody have an experience to use optim function?
> If yes, what is the main difference between two method "BFGS" vs
> "L-BFGS-B"?
> I used "BFGS" method and got what I wanted. But when I used "L-BFGS-B"
> the error message said that "L-BFGS-B needs finite values of fn". So
> that means
> "BFGS" method can handle even if fn function is infinite value?

Yes. BFGS can handle a function that gives NA or infinite values at some
points (though it requires a finite starting value).  L-BFGS-B cannot.

> What I really want to know is that can I get the same result by using
> L-BFGS-B method?

It will depend on your starting values.  If your starting values are good
enough then L-BFGS-B may not encounter any infinite or undefined points
before reaching the optimum.  You may also be able to use the box
constraints in L-BFGS-B to restrict the algorithm to a portion of the
parameter space where there aren't any infinite or undefined values.

If you don't start close enough to the optimum or if the problem is badly
conditioned enough, then neither algorithm might converge, or they might
converge to different local optima, or one might converge and the other
might not.   There aren't a lot of guarantees in numerical optimisation.


	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From Kang.Changku at epamail.epa.gov  Mon Jan  5 23:42:52 2004
From: Kang.Changku at epamail.epa.gov (Kang.Changku@epamail.epa.gov)
Date: Mon, 05 Jan 2004 17:42:52 -0500
Subject: [R] optim function : "BFGS" vs "L-BFGS-B"
Message-ID: <OFAD5E9377.578793B9-ON85256E12.007BCA18-85256E12.007CC6A2@epamail.epa.gov>





Well, thanks for your quick response.
In fact, I have another question.
There is a function in Splus, "nlminb". I want to do the same things
in R. According to help, nlminb function uses a quasi-Newton
method and this minimization is subject to box constraint. So, in
this sense I tried to use "BFGS" and "L-BFGS-B". But in both cases,
I couldn't get same result. I'm not sure which method coincide with
that of Splus or at least more similar.
Any suggestions would be very welcome.

+++++++++++++++++++++++++++++++++++++++++++++++++++++
Changku Kang
National Center for Environmental Assessment
EPA  (B211F)
919-541-1396
919-541-0245 (fax)
Kang.Changku at epa.gov

Graduate Student
Department of Statistics, NCSU
ckang2 at stat.ncsu.edu
919-513-2956
+++++++++++++++++++++++++++++++++++++++++++++++++++++



From service at genscript.com  Tue Jan  6 03:59:00 2004
From: service at genscript.com (Sally Wang)
Date: Mon, 5 Jan 2004 18:59 -0800
Subject: [R] Boost Protein Expression by Codon Optimization
Message-ID: <200401060011.i060BEr2001017@hypatia.math.ethz.ch>

Dear Colleague,

Happy New Year!

As we know, codon preference among different species could be dramatically different.  To enhance the expression level of a foreign protein in a particular expression system (E.coli, Yeast, Insect, or Mammalian cell), it is very important to adjust the codon frequency of the foreign protein to match that of the host expression system.  One classic example is GFP (green fluorescent protein) which was optimized to achieve high-level of expression in mammalian cells. 

GenScript has developed a proprietary algorithm for codon optimization.  This algorithm can optimize sequences for protein expression using either your own codon usage table or those from publicly available codon usage database.  It can converts your amino acid sequence into a DNA sequence with overall codon usage similar to a specified organism, and also optimizes the RNA secondary structure, GC content, repetitive codons etc. Using Genscript optimized synthetic genes, many of our customers have reported dramatic increase on protein expression. 

The optimized gene can be synthesized by GenScript gene synthesis technology with 100% fidelity.  The cost is as low as $2.35 per base pair.  Our service is very flexible, we can clone the optimized gene into our standard vectors (without extra charge), or any expression vector that you provide (for $400 extra charge).

Gene synthesis is a powerful technology and it has many other applications.  Another application example is to replace PCR Cloning.  Please visit our web (http://www.genscript.com/gene_synthesis.html) to learn more about this technology.  

Besides Gene Synthesis, we also provide custom vector-based siRNA, siRNA cassette, peptide, oligo, cloning and protein expression, biochemical reagents, and labwares.  Please visit our web site (http://www.genscript.com) to learn more about our services.


Sincerely,
 
Sally Wang
Account Manager
GenScript Corporation
120 Centennial Ave.
Piscataway, New Jersey 08854, USA
Tel: 1-732-885-9188, 1-732-357-3839
Fax: 1-732-210-0262
Email: sallyw at genscript.com
Web: http://www.genscript.com


==============================================

P.S.   If you prefer not to receive GenScript News and Offers in email, please follow this link:
https://www.genscript.com/ssl-bin/uns_email?number=W1191M2A654A2447W897&email=r-help at lists.r-project.org, and we apologize



From apt2003 at columbia.edu  Tue Jan  6 02:38:00 2004
From: apt2003 at columbia.edu (Ashutosh Tayshete)
Date: Mon, 5 Jan 2004 20:38:00 -0500 (EST)
Subject: [R] "Smart update" utility (or coding) for data files
Message-ID: <Pine.GSO.4.58.0401051943410.10513@papaya.cc.columbia.edu>

Hi,

I am a new user of R and this is my first e-mail here. Please enlighten me
on any etiquette issues I may have overstepped on.

My questions is as follows:

I need to do some data analysis for data from .csv files for stocks
(that I have obtained from yahoo)

How can I do a "smart update" of this data from Yahoo (or any other
site if you wish), so that in some way, I do not have to go and download
the new data from Excel every day.

I am running my code from a script file. So every time I start the program
I'd like the data to be up-to-date (ofcourse I shall be connected to the
internet.) Is there a utility I can download for this? If not, any hints
on how to code this will be appreciated.

many thanks
A



From stranda at cofc.edu  Tue Jan  6 03:32:54 2004
From: stranda at cofc.edu (Allan Strand)
Date: Mon, 05 Jan 2004 21:32:54 -0500
Subject: [R] rmetasim: a population genetic simulation environment
Message-ID: <87llol4xih.fsf@linum.cofc.edu>

Hi all,

My student, James Niehaus, and I have been working on an
individual-based population genetic simulation package in R.
Currently, the package is still rough, but useful enough that it may
be of interest to population/ecological geneticists.

The best description of the basic model (implemented in C++) can be
found in:

Allan E. Strand. Metasim 1.0: an individual-based environment for
simulating population genetics of complex population
dynamics. Mol. Ecol. Notes, 2:373-376, 2002.

My idea was to produce an extremely flexible engine that could
simulate genotypic data that result from most any demographic
scenario.  These data can be used as null distributions to compare to
observed datasets.  Results of simulations can be exported to a
variety of canned population genetic analysis programs, and rmetasim
implements a few rudimentary analyses (e.g Weir&Cockerhams theta,
mismatch distributions, and assignment tests) as well.  Several
example sessions are included in pdf files found in the rmetasim/doc
subdirectory.

rmetasim is mostly a wrapper for the C++ engine described in the paper
cited above.  Because it simulates individuals directly, rmetasim is
not terribly fast, even though the majority of the processing occurs
in compiled code.  Nevertheless, I have found it useful, and running
multiple simulations from the same starting conditions seems to work
in a cluster environment using Rmpi.

We are actively working on this package, and would appreciate feedback
so that we can improve its quality.

The source distribution can be found at:
http://linum.cofc.edu:/filedrop/rmetasim_0.0.3.tar.gz

It should compile on linux boxes (that have R installed), though doing
so takes a while.

Binary distribution for Mac OS X:
http://linum.cofc.edu:/filedrop/rmetasim_0.0.3_R_powerpc-apple-darwin6.8.tar.gz

Binary distribution for Windows:
http://linum.cofc.edu:/filedrop/rmetasim_0.0.3.zip

cheers,
a.
-- 
Allan Strand,   Biology    http://linum.cofc.edu
College of Charleston      Ph. (843) 953-9189
Charleston, SC 29424       Fax (843) 953-9199



From jingwu at stat.purdue.edu  Tue Jan  6 03:50:07 2004
From: jingwu at stat.purdue.edu (Jing Wu)
Date: Mon, 5 Jan 2004 21:50:07 -0500 (EST)
Subject: [R] build R package on winXP
In-Reply-To: <Pine.LNX.4.44.0401051827130.11737-100000@gannet.stats>
References: <Pine.LNX.4.44.0401051827130.11737-100000@gannet.stats>
Message-ID: <Pine.A41.4.58.0401052144460.57268@odds.stat.purdue.edu>



On Mon, 5 Jan 2004, Prof Brian Ripley wrote:

> On Mon, 5 Jan 2004, Jing Wu wrote:
>
> > I wrote an R function and want to build an R package on winXP. I have
> > set my
> > path:C:\bin;C:\MinGW\bin;C:\Perl\bin\;C:\Tcl\bin;C:\texmf\miktex\bin;C:\Program
> > Files\R\rw1081\bin;
> >
> > I tried to run "Rcmd build --help" but failed. Under
> > C:\WINDOWS\System32\cmd.exe, I got the error message:
> > Please set TMPDIR to a valid temporary directory.
>
I moved my folder 'IHF' to C:\Program Files\R\rw1081\src\library. Then I
typed the commond:
C:\Program Files\R\rw1081\src\library >Rcmd build --binary IHF
I got this error message:
Error: cannot change to directory 'C:/Documents'.

Where did I go wrong? Thanks.

Jing



From petr.pikal at precheza.cz  Tue Jan  6 08:37:50 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 06 Jan 2004 08:37:50 +0100
Subject: [R] runif and sample with reproducibility
In-Reply-To: <OFF132900B.CF0F4C6E-ON41256E12.00424078@notes.edfgdf.fr>
Message-ID: <3FFA73DE.27244.3154D8@localhost>

Hallo

I think I have seen an answer to it but did not search for it.

set.seed() with sample() is perfectly reprodicble for me (well, I 
tried it only three times :-)

> set.seed(111)
> sample(1:100,10)
 [1]  8 93 38 14 23 51 86 31 75 34
> set.seed(111)
> sample(1:100,10)
 [1]  8 93 38 14 23 51 86 31 75 34
> set.seed(111)
> sample(1:100,10)
 [1]  8 93 38 14 23 51 86 31 75 34
 
I suspect you called "set seed" only once.

Cheers
Petr


On 5 Jan 2004 at 13:07, Eric ESPOSITO wrote:

> Hello,
> I already sent such an email before Christmas, but nobody answered, so
> here is my problem: I would like to sample a population but the result
> needs to be reproducible, using 'runif' or 'sample' is the good way to
> do it but I can't manage to make the results reproducible even with
> the 'set.seed' function. My aim is that th call to 'sample(1:100,10)'
> gives always the same result, how can I do that? Thanks!
> 
> Eric Esposito
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ripley at stats.ox.ac.uk  Tue Jan  6 08:45:34 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 Jan 2004 07:45:34 +0000 (GMT)
Subject: [R] build R package on winXP
In-Reply-To: <Pine.A41.4.58.0401052144460.57268@odds.stat.purdue.edu>
Message-ID: <Pine.LNX.4.44.0401060740310.12724-100000@gannet.stats>

On Mon, 5 Jan 2004, Jing Wu wrote:

> > On Mon, 5 Jan 2004, Jing Wu wrote:
> >
> > > I wrote an R function and want to build an R package on winXP. I have
> > > set my
> > > path:C:\bin;C:\MinGW\bin;C:\Perl\bin\;C:\Tcl\bin;C:\texmf\miktex\bin;C:\Program
> > > Files\R\rw1081\bin;
> > >
> > > I tried to run "Rcmd build --help" but failed. Under
> > > C:\WINDOWS\System32\cmd.exe, I got the error message:
> > > Please set TMPDIR to a valid temporary directory.
> >
> I moved my folder 'IHF' to C:\Program Files\R\rw1081\src\library. Then I
> typed the commond:
> C:\Program Files\R\rw1081\src\library >Rcmd build --binary IHF
> I got this error message:
> Error: cannot change to directory 'C:/Documents'.
> 
> Where did I go wrong? Thanks.

Did you actually read the file readme.packages that I pointed you to in my
previous reply?  What does it say about paths containing spaces?

   Do not use paths with spaces in: you can always use the short forms.

You appear to have done so *twice*.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Tue Jan  6 09:00:18 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 06 Jan 2004 09:00:18 +0100
Subject: [R] build R package on winXP
In-Reply-To: <Pine.A41.4.58.0401052144460.57268@odds.stat.purdue.edu>
References: <Pine.LNX.4.44.0401051827130.11737-100000@gannet.stats>
	<Pine.A41.4.58.0401052144460.57268@odds.stat.purdue.edu>
Message-ID: <3FFA6B12.5000108@statistik.uni-dortmund.de>

Jing Wu wrote:

> 
> On Mon, 5 Jan 2004, Prof Brian Ripley wrote:
> 
> 
>>On Mon, 5 Jan 2004, Jing Wu wrote:
>>
>>
>>>I wrote an R function and want to build an R package on winXP. I have
>>>set my
>>>path:C:\bin;C:\MinGW\bin;C:\Perl\bin\;C:\Tcl\bin;C:\texmf\miktex\bin;C:\Program
>>>Files\R\rw1081\bin;
>>>
>>>I tried to run "Rcmd build --help" but failed. Under
>>>C:\WINDOWS\System32\cmd.exe, I got the error message:
>>>Please set TMPDIR to a valid temporary directory.
>>
> I moved my folder 'IHF' to C:\Program Files\R\rw1081\src\library. Then I
> typed the commond:
> C:\Program Files\R\rw1081\src\library >Rcmd build --binary IHF
> I got this error message:
> Error: cannot change to directory 'C:/Documents'.
 >
> Where did I go wrong? Thanks.

I think Prof. Ripley already told you that there are blanks in your path 
("Program Files" contains a blank!). Simply use another one without 
blanks in it.

Uwe Ligges

> Jing
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Jan  6 10:26:38 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 06 Jan 2004 10:26:38 +0100
Subject: [R] "Smart update" utility (or coding) for data files
In-Reply-To: <Pine.GSO.4.58.0401051943410.10513@papaya.cc.columbia.edu>
References: <Pine.GSO.4.58.0401051943410.10513@papaya.cc.columbia.edu>
Message-ID: <3FFA7F4E.8090001@statistik.uni-dortmund.de>

Ashutosh Tayshete wrote:

> Hi,
> 
> I am a new user of R and this is my first e-mail here. Please enlighten me
> on any etiquette issues I may have overstepped on.
> 
> My questions is as follows:
> 
> I need to do some data analysis for data from .csv files for stocks
> (that I have obtained from yahoo)
> 
> How can I do a "smart update" of this data from Yahoo (or any other
> site if you wish), so that in some way, I do not have to go and download
> the new data from Excel every day.
> 
> I am running my code from a script file. So every time I start the program
> I'd like the data to be up-to-date (ofcourse I shall be connected to the
> internet.) Is there a utility I can download for this? If not, any hints
> on how to code this will be appreciated.
> 
> many thanks
> A
> 

See ?url for such a connection.


Instead of read.csv("filename"), use
  read.csv(url("TheRelevantURL"))

Uwe Ligges



From ripley at stats.ox.ac.uk  Tue Jan  6 10:59:28 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 Jan 2004 09:59:28 +0000 (GMT)
Subject: [R] "Smart update" utility (or coding) for data files
In-Reply-To: <3FFA7F4E.8090001@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0401060958380.16901-100000@gannet.stats>

On Tue, 6 Jan 2004, Uwe Ligges wrote:

> Ashutosh Tayshete wrote:
> 
> > Hi,
> > 
> > I am a new user of R and this is my first e-mail here. Please enlighten me
> > on any etiquette issues I may have overstepped on.
> > 
> > My questions is as follows:
> > 
> > I need to do some data analysis for data from .csv files for stocks
> > (that I have obtained from yahoo)
> > 
> > How can I do a "smart update" of this data from Yahoo (or any other
> > site if you wish), so that in some way, I do not have to go and download
> > the new data from Excel every day.
> > 
> > I am running my code from a script file. So every time I start the program
> > I'd like the data to be up-to-date (ofcourse I shall be connected to the
> > internet.) Is there a utility I can download for this? If not, any hints
> > on how to code this will be appreciated.
> > 
> > many thanks
> > A
> > 
> 
> See ?url for such a connection.
> 
> 
> Instead of read.csv("filename"), use
>   read.csv(url("TheRelevantURL"))

For yahoo, see get.hist.quote() in package tseries which may do all you 
want.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From johanl at kiev.biotech.kth.se  Tue Jan  6 12:49:59 2004
From: johanl at kiev.biotech.kth.se (Johan Lindberg)
Date: Tue, 06 Jan 2004 12:49:59 +0100
Subject: [R] Analyzing dendograms??
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572F02164@synequanon01>
Message-ID: <5.2.0.9.0.20040106122638.00badeb8@kiev.biotech.kth.se>

Id like to thank you guys how have taken the time to look into my problem. 
I think the question drifted away from my original question as Simon Fear 
said. What I wanted to know was the following:

""I have used heatmap to visualize my microarray data. I have a matrix of 
M-values. I do the following.

#The distance between the columns.
sampdist <- dist(t(matrix[,]), method="euclidean")
sclus <- hclust(sampdist, method="average")
#The distance between the rows.
genedist <- dist(matrix[,], method="euclidean")
gclus <- hclust(genedist, method="average")
heatmap(matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram(sclus), col=rbg)

So far so good. But what if I want to look at a group of genes that appear 
to have the same expression pattern in the heatmap? How do I zoom in on a 
dendogram in a heatmap to look at which genes that are forming the 
interesting clusters? I would really appreciate if someone could give me a 
pointer.""

But since I did not get any good answers of how to analyze 
dendograms/heatmaps/hclust in R in a proper way I ask myself, is there a 
way of doing this in R? or is this a limitation of the functions available 
today in the R programming language. I know there are some functions like 
cutree etc but the documentation is really, really sparse. Are there any 
tutorials out there of how to do these things? or should one turn to 
alternative programs like MEV from TIGR?

A confused mind looking for answers..

/ J





At 15:20 2004-01-05 +0000, Simon Fear wrote:
>Post script: I'm afraid my `solution` was no good, because
>I forgot the need to change nc and nr. (I got bogged down
>in passing ylim and lost track of your real question.)
>
>Hopefully someone with a deeper understanding of the
>original problem will come to the rescue. If not there may
>be milage on restricting your matrix[,] to matrix[<cond1>,<cond2>]
>according to information in sclus and gclus. But I am in
>over my depth here.
>
> > >On Sun, 4 Jan 2004, Johan Lindberg wrote:
> > >
> > > >
> > > > I have used heatmap to visualize my microarray data. I
> > have a matrix of
> > > > M-values. I do the following.
> > > >
> > > > #The distance between the columns.
> > > > sampdist <- dist(t(matrix[,]), method="euclidean")
> > > > sclus <- hclust(sampdist, method="average")
> > > > #The distance between the rows.
> > > > genedist <- dist(matrix[,], method="euclidean")
> > > > gclus <- hclust(genedist, method="average")
> > > >
> > heatmap(matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram
> > (sclus),
> > > col=rbg)
> > > >
> > > > So far so good. But what if I want to look at a group of
> > genes that appear
> > > > to have the same expression pattern in the heatmap? How
> > do I zoom in on a
> > > > dendogram in a heatmap to look at which genes that are forming the
> > > > interesting clusters? I would really appreciate if
> > someone could give me a
> > > > pointer.
>
>Simon Fear
>Senior Statistician
>Syne qua non Ltd
>Tel: +44 (0) 1379 644449
>Fax: +44 (0) 1379 644445
>email: Simon.Fear at synequanon.com
>web: http://www.synequanon.com
>
>Number of attachments included with this message: 0
>
>This message (and any associated files) is confidential and\...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

*******************************************************************************************
Johan Lindberg
Royal Institute of Technology
AlbaNova University Center
Stockholm Center for Physics, Astronomy and Biotechnology
Department of Molecular Biotechnology
106 91 Stockholm, Sweden

Phone (office): +46 8 553 783 45
Fax: + 46 8 553 784 81
Visiting adress: Roslagstullsbacken 21, Floor 3
Delivery adress: Roslagsv?gen 30B



From sdavis2 at mail.nih.gov  Tue Jan  6 13:22:24 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 6 Jan 2004 07:22:24 -0500
Subject: [R] Analyzing dendograms??
References: <5.2.0.9.0.20040106122638.00badeb8@kiev.biotech.kth.se>
Message-ID: <000901c3d44f$be15caf0$2f643744@WATSON>

Johan,

This is possible.  It is not an interactive process, though--R does not have
that capability with heatmap.  See ?cutree which you can apply to gclus to
get the indices of genes in clusters that you define based on the dendrogram
and then use these genes as input to heatmap (this will amount to a subset
of your M-matrix).

Sean

----- Original Message -----
From: "Johan Lindberg" <johanl at kiev.biotech.kth.se>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, January 06, 2004 6:49 AM
Subject: RE: [R] Analyzing dendograms??


Id like to thank you guys how have taken the time to look into my problem.
I think the question drifted away from my original question as Simon Fear
said. What I wanted to know was the following:

""I have used heatmap to visualize my microarray data. I have a matrix of
M-values. I do the following.

#The distance between the columns.
sampdist <- dist(t(matrix[,]), method="euclidean")
sclus <- hclust(sampdist, method="average")
#The distance between the rows.
genedist <- dist(matrix[,], method="euclidean")
gclus <- hclust(genedist, method="average")
heatmap(matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram(sclus),
col=rbg)

So far so good. But what if I want to look at a group of genes that appear
to have the same expression pattern in the heatmap? How do I zoom in on a
dendogram in a heatmap to look at which genes that are forming the
interesting clusters? I would really appreciate if someone could give me a
pointer.""

But since I did not get any good answers of how to analyze
dendograms/heatmaps/hclust in R in a proper way I ask myself, is there a
way of doing this in R? or is this a limitation of the functions available
today in the R programming language. I know there are some functions like
cutree etc but the documentation is really, really sparse. Are there any
tutorials out there of how to do these things? or should one turn to
alternative programs like MEV from TIGR?

A confused mind looking for answers..

/ J





At 15:20 2004-01-05 +0000, Simon Fear wrote:
>Post script: I'm afraid my `solution` was no good, because
>I forgot the need to change nc and nr. (I got bogged down
>in passing ylim and lost track of your real question.)
>
>Hopefully someone with a deeper understanding of the
>original problem will come to the rescue. If not there may
>be milage on restricting your matrix[,] to matrix[<cond1>,<cond2>]
>according to information in sclus and gclus. But I am in
>over my depth here.
>
> > >On Sun, 4 Jan 2004, Johan Lindberg wrote:
> > >
> > > >
> > > > I have used heatmap to visualize my microarray data. I
> > have a matrix of
> > > > M-values. I do the following.
> > > >
> > > > #The distance between the columns.
> > > > sampdist <- dist(t(matrix[,]), method="euclidean")
> > > > sclus <- hclust(sampdist, method="average")
> > > > #The distance between the rows.
> > > > genedist <- dist(matrix[,], method="euclidean")
> > > > gclus <- hclust(genedist, method="average")
> > > >
> > heatmap(matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram
> > (sclus),
> > > col=rbg)
> > > >
> > > > So far so good. But what if I want to look at a group of
> > genes that appear
> > > > to have the same expression pattern in the heatmap? How
> > do I zoom in on a
> > > > dendogram in a heatmap to look at which genes that are forming the
> > > > interesting clusters? I would really appreciate if
> > someone could give me a
> > > > pointer.
>
>Simon Fear
>Senior Statistician
>Syne qua non Ltd
>Tel: +44 (0) 1379 644449
>Fax: +44 (0) 1379 644445
>email: Simon.Fear at synequanon.com
>web: http://www.synequanon.com
>
>Number of attachments included with this message: 0
>
>This message (and any associated files) is confidential and\...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

****************************************************************************
***************
Johan Lindberg
Royal Institute of Technology
AlbaNova University Center
Stockholm Center for Physics, Astronomy and Biotechnology
Department of Molecular Biotechnology
106 91 Stockholm, Sweden

Phone (office): +46 8 553 783 45
Fax: + 46 8 553 784 81
Visiting adress: Roslagstullsbacken 21, Floor 3
Delivery adress: Roslagsv?gen 30B

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From nusbj at hotmail.com  Tue Jan  6 14:34:52 2004
From: nusbj at hotmail.com (Z P)
Date: Tue, 06 Jan 2004 21:34:52 +0800
Subject: [R] numerical derivative
Message-ID: <Sea2-F56W7F4ann1AFn00025c40@hotmail.com>

Dear all,

I now want to get the numerical derivative of some multivariate function 
y=f(x_1,...,x_k) at some specific point x_0=(x_10,...,x_k0).

I know deriv() funtion can give the numerical derivative when f is an known 
fuction. Now the f is an unknown fuction, but I can give many points 
x_i=(x_1i,...,x_ki) around x_0 and their respective response y_i. I just 
want some rough estimation of this derivative, so I do not want to do the 
non-parametric regression. It is better to have an existing function in R to 
do the job like derive() for the known function f. Thank you.

Regards,

Zhen

_________________________________________________________________
Find gifts, buy online with MSN Shopping. http://shopping.msn.com.sg/



From christian_mora at vtr.net  Tue Jan  6 15:56:38 2004
From: christian_mora at vtr.net (christian_mora@vtr.net)
Date: Tue, 6 Jan 2004 10:56:38 -0400
Subject: [R] proxy
Message-ID: <3FE94891000167FD@hudson.vtr.net>

Hi all;

I?m working with the latest version of R under Win2000. My internet connection
(using a proxy) requires my username and password. In this situation I?m
not able to update the packages from CRAN (unless I download and install
them from a local drive). I tried looking at information on the list servers
but I couldn?t figure out how to change 'environment variables' or something
like that. I also tried renaming the files internet2.dll to internet.dll
and so on. Any 'new' idea how to solve this situation.

Thanks in advance
 
Christian Mora



From buffa at gci.ac.uk  Tue Jan  6 15:56:04 2004
From: buffa at gci.ac.uk (Francesca Buffa)
Date: Tue, 6 Jan 2004 14:56:04 -0000
Subject: [R] help on rmeta
Message-ID: <000001c3d465$352a35d0$9701000a@pc5571005>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040106/cf94553b/attachment.pl

From wise at cs.umass.edu  Tue Jan  6 16:04:30 2004
From: wise at cs.umass.edu (Alexander Wise)
Date: Tue, 6 Jan 2004 10:04:30 -0500
Subject: [R] Constructing a lm for predict() by hand
Message-ID: <A139F6F0-4059-11D8-B94A-000A95784200@cs.umass.edu>

Hello, this probably seems like an odd question, but...

If I have the formula and the coefficients for a linear model that I 
would like to apply to some data using predict() -- is there a way I 
construct an object of type lm such that predict() will work with it? 
Or another way besides predict()?

Alexander Wise
Senior Software Engineer
http://laser.cs.umass.edu



From dmurdoch at pair.com  Tue Jan  6 16:08:12 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 06 Jan 2004 10:08:12 -0500
Subject: [R] proxy
In-Reply-To: <3FE94891000167FD@hudson.vtr.net>
References: <3FE94891000167FD@hudson.vtr.net>
Message-ID: <hnjlvvk2q7570o77spiqggq110c7d6pcqh@4ax.com>

On Tue, 6 Jan 2004 10:56:38 -0400, christian_mora at vtr.net wrote :

>Hi all;
>
>I?m working with the latest version of R under Win2000. My internet connection
>(using a proxy) requires my username and password. In this situation I?m
>not able to update the packages from CRAN (unless I download and install
>them from a local drive). I tried looking at information on the list servers
>but I couldn?t figure out how to change 'environment variables' or something
>like that. I also tried renaming the files internet2.dll to internet.dll
>and so on. Any 'new' idea how to solve this situation.

Have you tried the methods described in the "FAQ on R for Windows"
(item 2.17 in version 1.8.1)?

Duncan Murdoch



From tlumley at u.washington.edu  Tue Jan  6 16:19:38 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 6 Jan 2004 07:19:38 -0800 (PST)
Subject: [R] help on rmeta
In-Reply-To: <000001c3d465$352a35d0$9701000a@pc5571005>
References: <000001c3d465$352a35d0$9701000a@pc5571005>
Message-ID: <Pine.A41.4.58.0401060712550.29972@homer10.u.washington.edu>

On Tue, 6 Jan 2004, Francesca Buffa wrote:

> Hello
>
>
>
> I'm trying to plot hazard risk values using the function metaplot with
> the specifications:
>
> > metaplot(HR,SE,W,labels=row.names(lc),xlab="Hazard
> Ratio",ylab="Covariates",
> logeffect=TRUE,logticks=FALSE,colors=meta.colors(box="black",lines="dark
> gray",zero="darkgray"),cex=1.5,cex.lab=1.5,font=3)
>
> However, in the plot the x axis starts after my minimum point;
> precisely, the x axis ticks start at 2 even if my minimum hazard is 0.44
> (i.e. exp(-0.8));  I've also tried to use xlim in metaplot (by fixing
> xlim<-c(0.44, 4)) but when I do this the HR error bars behave
> incorrectly (they shrink and I some cases disappear). can anyone suggest
> a cause/solution?
>

You don't want to change xlim, which has nothing to do with the axis -- it
specifies how wide the plot is.  The solution is to specify xaxt="n", as
the help page says

    xaxt: use '"n"' for no x-axis (to add a customised one)

You will get a metaplot with no x-axis, and you can then use
axis(1, at=, labels=) to put your own axis on.  It turns out to be quite
hard to get good automatic tick marks and axis range for these plots,
since pretty() isn't designed for log scales and tends to overextend the
left end of the axis.

	-thomas



From paradis at isem.univ-montp2.fr  Tue Jan  6 16:20:00 2004
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Tue, 06 Jan 2004 16:20:00 +0100
Subject: [R] Error running as.phylo (package ape)
In-Reply-To: <200401041829.21112.rrsilva@ib.usp.br>
Message-ID: <4.2.0.58.20040106161627.00b3e660@isem.isem.univ-montp2.fr>

At 18:29 04/01/2004 -0200, vous avez ?crit:
>Hi all,
>
>I  try to  convert hclust object to phylo object, using as.phylo (package
>ape), but got an error like the following:
>
> > tese<- read.table ("tese_guildas.txt", header=T)
> > library(mva)
> > library(ape)
> > hclust.tree<-hclust(dist(tese[1:156,]))
> > phylo.tree<- as.phylo(hclust.tree)
> > Segmentation fault (core dumped)
>
>Can someone give me a hint where I migth be going wrong? Is there something I
>forgot to do?
>
>Best regards,
>
>Rog?rio
>
>[R Version: 1.8.0; Platform: Mandrake 9.2]

I have just uploaded a new version of ape (1.2) to CRAN which should fix 
this problem, together with a few new functions.

Emmanuel Paradis

>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From edd at debian.org  Tue Jan  6 16:24:37 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 6 Jan 2004 09:24:37 -0600
Subject: [R] proxy
In-Reply-To: <3FE94891000167FD@hudson.vtr.net>
References: <3FE94891000167FD@hudson.vtr.net>
Message-ID: <20040106152437.GA11507@sonny.eddelbuettel.com>

On Tue, Jan 06, 2004 at 10:56:38AM -0400, christian_mora at vtr.net wrote:
> Hi all;
> 
> I?m working with the latest version of R under Win2000. My internet connection
> (using a proxy) requires my username and password. In this situation I?m
> not able to update the packages from CRAN (unless I download and install
> them from a local drive). I tried looking at information on the list servers
> but I couldn?t figure out how to change 'environment variables' or something
> like that. I also tried renaming the files internet2.dll to internet.dll
> and so on. Any 'new' idea how to solve this situation.

See the 'R on Windows' FAQ, Section 2.17.   

Personally, I use http_proxy="....." in the file ~/.Renviron -- i.e. a file
called .Renviron in the directory pointed to by the $HOME env. variable.

Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From christoph.lehmann at gmx.ch  Tue Jan  6 16:31:05 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 06 Jan 2004 16:31:05 +0100
Subject: [R] comparing classification methods: 10-fold cv or leaving-one-out
	?
Message-ID: <1073403065.6509.1607.camel@christophl>

Hi
what would you recommend to compare classification methods such as LDA,
classification trees (rpart), bagging, SVM, etc:

10-fold cv (as in Ripley p. 346f)

or

leaving-one-out (as e.g. implemented in LDA)?

my data-set is not that huge (roughly 200 entries)

many thanks for a hint

Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From ryszard.czerminski at pharma.novartis.com  Tue Jan  6 16:52:28 2004
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Tue, 6 Jan 2004 10:52:28 -0500
Subject: [R] dist(x, y) ???
Message-ID: <OFE52847F6.445A8719-ON85256E13.0056FFD0-85256E13.005751C8@EU.novartis.net>

Is there a function in R (similar to dist) which would calculate
distances between rows in two different matrices ?

Ryszard



From ripley at stats.ox.ac.uk  Tue Jan  6 17:13:13 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 Jan 2004 16:13:13 +0000 (GMT)
Subject: [R] comparing classification methods: 10-fold cv or
	leaving-one-out ?
In-Reply-To: <1073403065.6509.1607.camel@christophl>
Message-ID: <Pine.LNX.4.44.0401061607200.3505-100000@gannet.stats>

Leave-one-out is very inaccurate for some methods, notably trees, but fine 
for some others (e.g. LDA) if used with a good measure of accuracy.

Hint: there is a very large literature on this, so read any good book on 
classification to find out what is known.

On Tue, 6 Jan 2004, Christoph Lehmann wrote:

> Hi
> what would you recommend to compare classification methods such as LDA,
> classification trees (rpart), bagging, SVM, etc:
> 
> 10-fold cv (as in Ripley p. 346f)

Not a valid reference:  did you mean Venables & Ripley (2000, p.346f)?
Try reading Ripley (1996), for example.

> or
> 
> leaving-one-out (as e.g. implemented in LDA)?
> 
> my data-set is not that huge (roughly 200 entries)

That's rather small to compare error rates on.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jingwu at stat.purdue.edu  Tue Jan  6 17:18:02 2004
From: jingwu at stat.purdue.edu (Jing Wu)
Date: Tue, 6 Jan 2004 11:18:02 -0500 (EST)
Subject: [R] build R package on winXP
In-Reply-To: <Pine.LNX.4.44.0401060853390.13014-100000@gannet.stats>
References: <Pine.LNX.4.44.0401060853390.13014-100000@gannet.stats>
Message-ID: <Pine.A41.4.58.0401061106420.109182@odds.stat.purdue.edu>

Dear Professor Ripley,

Sorry I didn't get what the manual says. I read readme.package and also R
for Windows Users several times but the pieces didn't come together. Your
guess is right. The TMPDIR was set to c:\Documents
and Settings\ and I didn't know this was a problem since I only checked
Path and didn't see any path to be c:\Documents.... I think the Path
"Program Files" should be substitute with "PROGRA~1" but what I should use
for "Documents and Settings"? Thanks a lot for your help.

Jing

On Tue, 6 Jan 2004, Prof Brian Ripley wrote:

> The issue here is that some other path has been set to
>
> c:\Documents and Settings\...
>
> and I suspect that to be TMPDIR, as when I do that I get exactly this
> symptom.
>
> Why Jing Wu claims to quote me but excises everything I said, and also
> ignores everything I wrote, I don't know.  He is showing a phenomenal lack
> of respect, and owes us an apology.
>
> On Tue, 6 Jan 2004, Uwe Ligges wrote:
>
> > Jing Wu wrote:
> >
> > >
> > > On Mon, 5 Jan 2004, Prof Brian Ripley wrote:
> > >
> > >
> > >>On Mon, 5 Jan 2004, Jing Wu wrote:
> > >>
> > >>
> > >>>I wrote an R function and want to build an R package on winXP. I have
> > >>>set my
> > >>>path:C:\bin;C:\MinGW\bin;C:\Perl\bin\;C:\Tcl\bin;C:\texmf\miktex\bin;C:\Program
> > >>>Files\R\rw1081\bin;
> > >>>
> > >>>I tried to run "Rcmd build --help" but failed. Under
> > >>>C:\WINDOWS\System32\cmd.exe, I got the error message:
> > >>>Please set TMPDIR to a valid temporary directory.
> > >>
> > > I moved my folder 'IHF' to C:\Program Files\R\rw1081\src\library. Then I
> > > typed the commond:
> > > C:\Program Files\R\rw1081\src\library >Rcmd build --binary IHF
> > > I got this error message:
> > > Error: cannot change to directory 'C:/Documents'.
> >  >
> > > Where did I go wrong? Thanks.
> >
> > I think Prof. Ripley already told you that there are blanks in your path
> > ("Program Files" contains a blank!). Simply use another one without
> > blanks in it.
> >
> > Uwe Ligges
> >
> > > Jing
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From tplate at acm.org  Tue Jan  6 17:24:01 2004
From: tplate at acm.org (Tony Plate)
Date: Tue, 06 Jan 2004 09:24:01 -0700
Subject: [R] Constructing a lm for predict() by hand
In-Reply-To: <A139F6F0-4059-11D8-B94A-000A95784200@cs.umass.edu>
Message-ID: <5.2.1.1.2.20040106091533.044e74b8@mailhost.blackmesacapital.com>

One relatively easy way would be to construct some dummy data with the 
appropriate names and formula, use lm() to construct the model object, and 
then change the coefficients in the model object to be what you want (e.g., 
by fit$coefficients[2] <- 0.79).  This should then work with 
predict().  Don't make the mistake of thinking that output than output from 
anything other than predict(obj, newdata=data) will mean anything sensible 
-- summary(), predict(, se=T), ...

If your data is all numeric, then the easiest way might be just to use 
matrix computations:

pred <- cbind(1, data) %*% coef

where data is n x k matrix, coef is a vector of length k+1, and the 
intercept is the first element of coef.

hope this helps,

Tony Plate

At Tuesday 10:04 AM 1/6/2004 -0500, Alexander Wise wrote:
>Hello, this probably seems like an odd question, but...
>
>If I have the formula and the coefficients for a linear model that I would 
>like to apply to some data using predict() -- is there a way I construct 
>an object of type lm such that predict() will work with it? Or another way 
>besides predict()?
>
>Alexander Wise
>Senior Software Engineer
>http://laser.cs.umass.edu
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Tony Plate   tplate at acm.org



From tplate at acm.org  Tue Jan  6 17:31:37 2004
From: tplate at acm.org (Tony Plate)
Date: Tue, 06 Jan 2004 09:31:37 -0700
Subject: [R] comparing classification methods: 10-fold cv or
	leaving-one-out ?
In-Reply-To: <1073403065.6509.1607.camel@christophl>
Message-ID: <5.2.1.1.2.20040106092502.044c6e58@mailhost.blackmesacapital.com>

I would recommend reading the following:  Dietterich, T. G., (1998). 
Approximate Statistical Tests for Comparing Supervised Classification 
Learning Algorithms. Neural Computation, 10 (7) 1895-1924. 
http://web.engr.oregonstate.edu/~tgd/publications/index.html

The issues in comparing methods are subtle and difficult.  With such a 
small data set I would be a little surprised if you could get any result 
that are truly statistically significant, especially if your goal is to 
compare among good non-linear methods (i.e., in which there are unlikely to 
huge differences because of model misspecification).  However, because the 
issues are subtle, it is easy to get results that appear significant...

hope this helps,

Tony Plate

At Tuesday 04:31 PM 1/6/2004 +0100, Christoph Lehmann wrote:
>Hi
>what would you recommend to compare classification methods such as LDA,
>classification trees (rpart), bagging, SVM, etc:
>
>10-fold cv (as in Ripley p. 346f)
>
>or
>
>leaving-one-out (as e.g. implemented in LDA)?
>
>my data-set is not that huge (roughly 200 entries)
>
>many thanks for a hint
>
>Christoph
>--
>Christoph Lehmann <christoph.lehmann at gmx.ch>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Tony Plate   tplate at acm.org



From apt2003 at columbia.edu  Tue Jan  6 17:46:21 2004
From: apt2003 at columbia.edu (Ashutosh Tayshete)
Date: Tue, 6 Jan 2004 11:46:21 -0500 (EST)
Subject: [R] Problem while reading .csv files
Message-ID: <Pine.GSO.4.58.0401061138460.22559@mango.cc.columbia.edu>


I have this line at the start of my code file.

QQQ<-read.csv("c:/QQQ.csv", header=TRUE,row.names=1)

And I get an error ...

Error in parse(file, n, text, prompt) : syntax error on line 2

What does this error mean and how can I correct it?
What is the standard way I can read from a .csv file.

Thanks
a



From tplate at acm.org  Tue Jan  6 18:15:26 2004
From: tplate at acm.org (Tony Plate)
Date: Tue, 06 Jan 2004 10:15:26 -0700
Subject: [R] Problem while reading .csv files
In-Reply-To: <Pine.GSO.4.58.0401061138460.22559@mango.cc.columbia.edu>
Message-ID: <5.2.1.1.2.20040106100929.0451a958@mailhost.blackmesacapital.com>

You might get more useful answers if you gave more information about 
exactly what you did.  My wild guess is that you are sourcing a file (with 
the function source()), the first line of which is the QQQ<-..., and the 
second line of which has a syntax error.

One of the nice things about R is that you can cut and paste from script 
files in order to try to track down errors.  Did you try that with the 
QQQ<- line?  (It looks fine to me, and this works for me to read .csv files.)

-- Tony Plate

At Tuesday 11:46 AM 1/6/2004 -0500, Ashutosh Tayshete wrote:

>I have this line at the start of my code file.
>
>QQQ<-read.csv("c:/QQQ.csv", header=TRUE,row.names=1)
>
>And I get an error ...
>
>Error in parse(file, n, text, prompt) : syntax error on line 2
>
>What does this error mean and how can I correct it?
>What is the standard way I can read from a .csv file.
>
>Thanks
>a
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Tony Plate   tplate at acm.org



From hodgess at gator.uhd.edu  Tue Jan  6 18:41:15 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Tue, 6 Jan 2004 11:41:15 -0600
Subject: [R] dist(x,y)
Message-ID: <200401061741.i06HfFC29408@gator.dt.uh.edu>

Hi Ryszard!

There is a dist function in R.
It's in the mva package.
You can set the kind of distance that you want.

Thanks,
Erin
mailto:hodgess at gator.uhd.edu



From elvis at xlsolutions-corp.com  Tue Jan  6 18:38:43 2004
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue,  6 Jan 2004 10:38:43 -0700
Subject: [R] Course***Advanced R/Splus Programming***January 2004 by
	XLSolutions Corp.
Message-ID: <20040106173843.21560.qmail@webmail-2-2.mesa1.secureserver.net>


   Happy New Year
   XSolutions Corp ([1]www.xlsolutions-corp.com) is proud to announce
   a 2-day "Advanced R/Splus programming" taught by R Development
   Core Team Guru.
   *********Princeton, NJ ----------  January 29-30, 2004
   *********San Francisco ----------  January 15-16, 2004
   *********Boston, MA    ----------  TBD
   *********Washington DC ----------  TBD
               Reserve your seat Now  (payment due after the class)
   Registration:
   [2]www.xlsolutions-corp.com/training.htm
   Email Sue Turner: [3]sue at xlsolutions-corp.com
   Phone: 206-686-1578
   Course outline:
   - Overview of R/S fundamentals: Syntax and Semantics
   - Class and Inheritance in R/S-Plus
   - Concepts, Construction and good use of language objects
   - Coercion and efficiency
   - Object-oriented programming in R and S-Plus
   - Advanced manipulation tools: Parse, Deparse, Substitute, etc.
   - How to fully take advantage of Vectorization
   - Generic and Method Functions; S4 (S-Plus 6)
   - Search path, databases and frames Visibility
   - Working with large objects
   - Handling Properly Recursion and iterative calculations
   - Managing loops; For (S-Plus) and for() loops
   - Consequences of Lazy Evaluation
   - Efficient Code practices for large computations
   - Memory management and Resource monitoring
   - Writing R/S-Plus functions to call compiled code
   - Writing and debugging compiled code for R/S-Plus system
   - Connecting R/S-Plus to External Data Sources
   - Understanding the structure of model fitting functions in R/S-Plus
   - Designing and Packaging efficiently
    Early-bird group research fee: $995!
   This course will also deal with lots of S-Plus efficiency issues and
   any special topics from participants is welcome.
   Please let us know if you and your colleagues are interested in this
   class to take advantage of group discount. Over half of the seats in
   both classes are currently reserved.  Register now to secure your seat
   in this course!

   Cheers,
   Elvis Miller, PhD
   Manager Training.
   XLSolutions Corporation
   206 686 1578
   [4]www.xlsolutions-corp.com

References

   1. http://www.xlsolutions-corp.com/
   2. http://www.xlsolutions-corp.com/training.htm
   3. mailto:sue at xlsolutions-corp.com
   4. http://www.xlsolutions-corp.com/


From dmurdoch at pair.com  Tue Jan  6 18:54:57 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 06 Jan 2004 12:54:57 -0500
Subject: [R] build R package on winXP
In-Reply-To: <Pine.A41.4.58.0401061106420.109182@odds.stat.purdue.edu>
References: <Pine.LNX.4.44.0401060853390.13014-100000@gannet.stats>
	<Pine.A41.4.58.0401061106420.109182@odds.stat.purdue.edu>
Message-ID: <mdtlvvc7pf0kiseibku5e1m772bpk0sk3m@4ax.com>

On Tue, 6 Jan 2004 11:18:02 -0500 (EST), Jing Wu
<jingwu at stat.purdue.edu> wrote :
> I think the Path
>"Program Files" should be substitute with "PROGRA~1" but what I should use
>for "Documents and Settings"? Thanks a lot for your help.

This works in XP:

Open a command window (Start | Run | cmd), then do "dir c:\ /x", and
you see it displayed.  It's probably  DOCUME~1, but not necessarily.

Duncan Murdoch



From ryszard.czerminski at pharma.novartis.com  Tue Jan  6 19:07:41 2004
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Tue, 6 Jan 2004 13:07:41 -0500
Subject: [R] dist(x,y)
Message-ID: <OF126BBAAC.4EA50427-ON85256E13.00637BC2-85256E13.0063B2B8@EU.novartis.net>

Hi Erin,

CLARIFICATION: I am looking for function which can calculate distances 
between
rows in two different matrices (not in the same matrix as dist).
Of course I can get the desired result by using rbind() and fiddling with 
indices of the result, which I already did,
but I wonder if there is a function (or some variant of dist), which does 
it directly ?

Ryszard





Erin Hodgess <hodgess at gator.uhd.edu>
Sent by: r-help-bounces at stat.math.ethz.ch
01/06/2004 12:41 PM

 
        To:     r-help at stat.math.ethz.ch
        cc: 
        Subject:        [R] dist(x,y)


Hi Ryszard!

There is a dist function in R.
It's in the mva package.
You can set the kind of distance that you want.

Thanks,
Erin
mailto:hodgess at gator.uhd.edu

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jingwu at stat.purdue.edu  Tue Jan  6 19:18:53 2004
From: jingwu at stat.purdue.edu (Jing Wu)
Date: Tue, 6 Jan 2004 13:18:53 -0500 (EST)
Subject: [R] build R package on winXP
In-Reply-To: <mdtlvvc7pf0kiseibku5e1m772bpk0sk3m@4ax.com>
References: <Pine.LNX.4.44.0401060853390.13014-100000@gannet.stats>
	<Pine.A41.4.58.0401061106420.109182@odds.stat.purdue.edu>
	<mdtlvvc7pf0kiseibku5e1m772bpk0sk3m@4ax.com>
Message-ID: <Pine.A41.4.58.0401061311460.45950@odds.stat.purdue.edu>

Thanks. I changed TMPDIR and TMP to c:\Temp. But "Rcmd build" failed
again. This time the problem is the path of "make". Although
I put C:\bin in front of path but "build" went to $R_home/bin to find
"make". "Rcmd make" was succesful before. I think the path is still not
correct.

Jing

On Tue, 6 Jan 2004, Duncan Murdoch wrote:

> On Tue, 6 Jan 2004 11:18:02 -0500 (EST), Jing Wu
> <jingwu at stat.purdue.edu> wrote :
> > I think the Path
> >"Program Files" should be substitute with "PROGRA~1" but what I should use
> >for "Documents and Settings"? Thanks a lot for your help.
>
> This works in XP:
>
> Open a command window (Start | Run | cmd), then do "dir c:\ /x", and
> you see it displayed.  It's probably  DOCUME~1, but not necessarily.
>
> Duncan Murdoch
>



From dmyers at umiacs.umd.edu  Tue Jan  6 20:03:47 2004
From: dmyers at umiacs.umd.edu (Daniel Sumers Myers)
Date: Tue, 6 Jan 2004 14:03:47 -0500
Subject: [R] Problem reading large tables
Message-ID: <20040106190343.GB21560@lysine.umiacs.umd.edu>

Hi, 
	I'm trying to read in a fairly large (92 observations by 3680 variables)
table into R from a space-delimited text file (attached) using the command: d8
<- read.table('d8.r', header=T). The function call runs to completion, and I
get back a valid table object. However, starting at column 999, the table
records the value TRUE when it should record T (T's in columns 998 and earlier
are fine). I've looked at the data file, and I can see no difference between
(e.g.) the T at position 998 in row 1 and the T in position 999 in row 1, yet
998 is recorded as T and 999 as TRUE. 

I know I could just update the table in R to change all TRUEs to Ts, but I'm
worried there may be some underlying limit I'm running up against. I've tried
this on both R-1.7.1 and 1.8.1 on Linux/IA-32. Can anyone help?

Thanks,
Daniel

-- 
Daniel Myers
Laboratory of Dr. Michael P. Cummings
Center for Bioinformatics and Computational Biology
University of Maryland
Agri/LFSc Surge Building #296
College Park, MD 20742-3360
dmyers at umiacs.umd.edu
301.405.1262 work
http://serine.umiacs.umd.edu/personnel/myers_daniel/
-
"Think of your breed; for brutish ignorance / Your mettle was not made; you 
were made men / To follow after knowledge and excellence."
As if I also was hearing for the first time: like the blast of a trumpet, 
like the voice of God. For a moment I forget who I am and where I am.
--Primo Levi, Survival in Auschwitz



From dmurdoch at pair.com  Tue Jan  6 20:43:22 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 06 Jan 2004 14:43:22 -0500
Subject: [R] Problem reading large tables
In-Reply-To: <20040106190343.GB21560@lysine.umiacs.umd.edu>
References: <20040106190343.GB21560@lysine.umiacs.umd.edu>
Message-ID: <3d3mvvo8b3fkece7lt5crg08osleem2jn3@4ax.com>

On Tue, 6 Jan 2004 14:03:47 -0500, Daniel Sumers Myers
<dmyers at umiacs.umd.edu> wrote :

>Hi, 
>	I'm trying to read in a fairly large (92 observations by 3680 variables)
>table into R from a space-delimited text file (attached) using the command: d8
><- read.table('d8.r', header=T). The function call runs to completion, and I
>get back a valid table object. However, starting at column 999, the table
>records the value TRUE when it should record T (T's in columns 998 and earlier
>are fine). I've looked at the data file, and I can see no difference between
>(e.g.) the T at position 998 in row 1 and the T in position 999 in row 1, yet
>998 is recorded as T and 999 as TRUE. 

The special-looking value 999 is probably just a coincidence.  Likely
what happened is that column 999 was the first column that looked to
the type.convert function like   a purely logical column (because all
values are T there?).  You can tell R not to automatically convert
values by using the colClasses argument to read.table, e.g. colClasses
= "character" forces everything to stay as a character.

Duncan Murdoch

P.S. You can't send attachments to the mailing list, so I didn't see
your data file.



From dmyers at umiacs.umd.edu  Tue Jan  6 20:51:04 2004
From: dmyers at umiacs.umd.edu (Daniel Sumers Myers)
Date: Tue, 6 Jan 2004 14:51:04 -0500
Subject: [R] Problem reading large tables
In-Reply-To: <3d3mvvo8b3fkece7lt5crg08osleem2jn3@4ax.com>
References: <20040106190343.GB21560@lysine.umiacs.umd.edu>
	<3d3mvvo8b3fkece7lt5crg08osleem2jn3@4ax.com>
Message-ID: <20040106195102.GB23245@lysine.umiacs.umd.edu>

Thanks to all, it was a conversion problem (now fixed).

Daniel

On Tue, Jan 06, 2004 at 02:43:22PM -0500, Duncan Murdoch wrote:
> On Tue, 6 Jan 2004 14:03:47 -0500, Daniel Sumers Myers
> <dmyers at umiacs.umd.edu> wrote :
> 
> >Hi, 
> >	I'm trying to read in a fairly large (92 observations by 3680 variables)
> >table into R from a space-delimited text file (attached) using the command: d8
> ><- read.table('d8.r', header=T). The function call runs to completion, and I
> >get back a valid table object. However, starting at column 999, the table
> >records the value TRUE when it should record T (T's in columns 998 and earlier
> >are fine). I've looked at the data file, and I can see no difference between
> >(e.g.) the T at position 998 in row 1 and the T in position 999 in row 1, yet
> >998 is recorded as T and 999 as TRUE. 
> 
> The special-looking value 999 is probably just a coincidence.  Likely
> what happened is that column 999 was the first column that looked to
> the type.convert function like   a purely logical column (because all
> values are T there?).  You can tell R not to automatically convert
> values by using the colClasses argument to read.table, e.g. colClasses
> = "character" forces everything to stay as a character.
> 
> Duncan Murdoch
> 
> P.S. You can't send attachments to the mailing list, so I didn't see
> your data file.

-- 
Daniel Myers
Laboratory of Dr. Michael P. Cummings
Center for Bioinformatics and Computational Biology
University of Maryland
Agri/LFSc Surge Building #296
College Park, MD 20742-3360
dmyers at umiacs.umd.edu
301.405.1262 work
http://serine.umiacs.umd.edu/personnel/myers_daniel/
-
"Think of your breed; for brutish ignorance / Your mettle was not made; you 
were made men / To follow after knowledge and excellence."
As if I also was hearing for the first time: like the blast of a trumpet, 
like the voice of God. For a moment I forget who I am and where I am.
--Primo Levi, Survival in Auschwitz



From MikeJones at westat.com  Tue Jan  6 23:10:54 2004
From: MikeJones at westat.com (Mike Jones)
Date: Tue, 6 Jan 2004 17:10:54 -0500 
Subject: [R] .Rdata file size
Message-ID: <9B425F151083D311A218009027B00EA60AC66D34@Remailnt1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040106/3cd2ae4d/attachment.pl

From olafm at tako.de  Wed Jan  7 00:09:22 2004
From: olafm at tako.de (Olaf Mersmann)
Date: Wed, 07 Jan 2004 00:09:22 +0100
Subject: [R] Grouping data.frames
Message-ID: <f188fe730e2130f1cb9e439810eeaeb5@Inken.local.>

Hello all,

I'm new to R (and the S language in general) so go easy on me if this is really simple.

Given a data.frame df which looks like this:
	f1	f2	f3	f4	c1	c2
1	y	y	a	b	10	20	
2	n	y	b	a	20	20
3	n	n	b	b	 8	10
4	y	n	a	a	30	 5

I'd like to aggregate it by the factors f1 and f2 (or f2 and f3, or any other combination of the three) and compute the sum of c1 and c2 (as separate values). I can do this just fine as long as there is only one column with counts using tapply of mApply out of Hmisc, but I've been unable to come up with a solution that works with two or more columns.

In SQL a query to achieve this would look something like this:
SELECT f1, f2, sum(c1), sum(2) FROM df GROUP BY f1, f2

An hints on how this is done efficiently in R would be greatly appreciated.

Thanks,
Olaf Mersmann



From p.dalgaard at biostat.ku.dk  Wed Jan  7 00:46:00 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 07 Jan 2004 00:46:00 +0100
Subject: [R] Grouping data.frames
In-Reply-To: <f188fe730e2130f1cb9e439810eeaeb5@Inken.local.>
References: <f188fe730e2130f1cb9e439810eeaeb5@Inken.local.>
Message-ID: <x2d69wmyiv.fsf@biostat.ku.dk>

Olaf Mersmann <olafm at tako.de> writes:

> Hello all,
> 
> I'm new to R (and the S language in general) so go easy on me if this is really simple.
> 
> Given a data.frame df which looks like this:
> 	f1	f2	f3	f4	c1	c2
> 1	y	y	a	b	10	20	
> 2	n	y	b	a	20	20
> 3	n	n	b	b	 8	10
> 4	y	n	a	a	30	 5
> 
> I'd like to aggregate it by the factors f1 and f2 (or f2 and f3, or any other combination of the three) and compute the sum of c1 and c2 (as separate values). I can do this just fine as long as there is only one column with counts using tapply of mApply out of Hmisc, but I've been unable to come up with a solution that works with two or more columns.
> 
> In SQL a query to achieve this would look something like this:
> SELECT f1, f2, sum(c1), sum(2) FROM df GROUP BY f1, f2
> 
> An hints on how this is done efficiently in R would be greatly appreciated.

I think aggregate() will do what you want. If not, notice that
whatever you can do with a single factor, you can also do with
interaction(f1,f2) or maybe interaction(f1,f2, drop=TRUE). 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From andy_liaw at merck.com  Wed Jan  7 00:58:16 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 6 Jan 2004 18:58:16 -0500
Subject: [R] .Rdata file size
Message-ID: <3A822319EB35174CA3714066D590DCD504AF75BD@usrymx25.merck.com>

No.  I've dealt with .RData files in excess of 1GB several times.  The limit
is likely with your hardware, which you did not specify.

Andy

> From:  Mike Jones
> 
> Is there a limit to this?  I'm working with a .Rdata file 
> about 190 Mgs in
> size and R won't open it...thanks...mj


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ggrothendieck at myway.com  Wed Jan  7 04:57:08 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue,  6 Jan 2004 22:57:08 -0500 (EST)
Subject: [R] 
Message-ID: <20040107035708.F11793993@mprdmxin.myway.com>


One thing to watch out for is adjustments:

- if the data is not adjusted for dividends and splits then
you may be able to just download data since your last download
yourself but depending on what you want to do with the data you 
may get misleading results.

For example, if the stock trades at $100 and there is a 2 for 1
split then the next day there will be twice as many shares with
each share at $50.  If the stock does not move that day then
the unadjusted return is -50% whereas the adjusted return is 0%.

- if the data _is_ adjusted for splits and dividends you will 
still have this problem if you just add new data onto the end
of the old data you downloaded.   For example, if you use the 
data you downloaded yesterday and then just download today's
data today then you will have the exact same problem as cited 
above even if the data is adjusted since you are using yesterday's
data for the prior days which was only adjusted today and you did
not re-download that.

To get around this you would have to at least redownload
yesterday's and today's data and compare yesterday's data with
the data for yesterday that you downloaded yesterday.  If 
they are not equal then adjustments are necessary and you would 
have to redownload all the data.

I don't know whether the data you are using it adjusted or 
unadjusted but be careful of these subtle problems.

---
Date: Mon, 5 Jan 2004 20:38:00 -0500 (EST) 
From: Ashutosh Tayshete <apt2003 at columbia.edu>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] "Smart update" utility (or coding) for data files 

 
 
Hi,

I am a new user of R and this is my first e-mail here. Please enlighten me
on any etiquette issues I may have overstepped on.

My questions is as follows:

I need to do some data analysis for data from .csv files for stocks
(that I have obtained from yahoo)

How can I do a "smart update" of this data from Yahoo (or any other
site if you wish), so that in some way, I do not have to go and download
the new data from Excel every day.

I am running my code from a script file. So every time I start the program
I'd like the data to be up-to-date (ofcourse I shall be connected to the
internet.) Is there a utility I can download for this? If not, any hints
on how to code this will be appreciated.

many thanks
A

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Wed Jan  7 05:16:37 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue,  6 Jan 2004 23:16:37 -0500 (EST)
Subject: [R] dist(x,y)
Message-ID: <20040107041637.A8878399E@mprdmxin.myway.com>



If a is m x r and b is n x r then 

   apply(outer(a,t(b),"-"),c(1,4),function(x)sqrt(sum(diag(x*x))))

is the m x n matrix of distances between the m rows of a and 
n rows of b.

Modify, as necessary, if you want distances other than euclidean.

---
Date: Tue, 6 Jan 2004 13:07:41 -0500 
From: <ryszard.czerminski at pharma.novartis.com>
To: Erin Hodgess <hodgess at gator.uhd.edu> 
Cc: <r-help at stat.math.ethz.ch>, <r-help-bounces at stat.math.ethz.ch> 
Subject: Re: [R] dist(x,y) 

 
 
Hi Erin,

CLARIFICATION: I am looking for function which can calculate distances 
between
rows in two different matrices (not in the same matrix as dist).
Of course I can get the desired result by using rbind() and fiddling with 
indices of the result, which I already did,
but I wonder if there is a function (or some variant of dist), which does 
it directly ?

Ryszard





Erin Hodgess <hodgess at gator.uhd.edu>
Sent by: r-help-bounces at stat.math.ethz.ch
01/06/2004 12:41 PM


To: r-help at stat.math.ethz.ch
cc: 
Subject: [R] dist(x,y)


Hi Ryszard!

There is a dist function in R.
It's in the mva package.
You can set the kind of distance that you want.

Thanks,
Erin
mailto:hodgess at gator.uhd.edu



From renaud.lancelot at pasteur.mg  Wed Jan  7 07:30:55 2004
From: renaud.lancelot at pasteur.mg (Renaud Lancelot)
Date: Wed, 07 Jan 2004 09:30:55 +0300
Subject: [R] length of tick marks in grid.xaxis and grid.yaxis
Message-ID: <3FFBA79F.5050807@pasteur.mg>

Dear all,

How can I control the length of tick marks in grid.xaxis and grid.yaxis 
(package grid) ?

Best regards,

Renaud

-- 
Dr Renaud Lancelot
v?t?rinaire ?pid?miologiste
Ambassade de France - SCAC
BP 834 Antannarivo 101
Madagascar

t?l. +261 (0)32 04 824 55 (cell)
      +261 (0)20 22 494 37 (home)



From kjhealy at u.arizona.edu  Wed Jan  7 07:44:42 2004
From: kjhealy at u.arizona.edu (Kieran Healy)
Date: Tue, 6 Jan 2004 23:44:42 -0700 (MST)
Subject: [R] Sweave and X11 on OSX 10.3
Message-ID: <Pine.GSO.4.58.0401062334360.4520@ptah.u.arizona.edu>

Hi -

I'm running R 1.8.1 (compiled from source) on Mac OS X 10.3 (Panther). I
find that, if Apple's X11 application is not running, Sweave gives an
error when it wants to create a pdf or eps figure. E.g., in the package's
own example-1.Snw file a boxplot is created at chunk 2:

<<fig=TRUE,echo=FALSE>>=
boxplot(Ozone ~ Month, data = airquality)
@

Normally this will create a pdf and an eps version of the boxplot. I get:

> Sweave("example-1.Snw")
Writing to file example-1.tex
Processing code chunks ...
 1 : echo term verbatim
 2 : term verbatim eps pdf
Warning message:
unable to open connection to X11 display`'

Error:  chunk 2
Error in X11(display, width, height, pointsize, gamma, colortype,
maxcubesize,  :
        unable to start device X11

If I start the X11 application, Sweave runs as normal but displays any
figures on an x11() device in addition to creating the eps / pdf files.

I don't remember this happening before and experience teaches me to assume
the issue is with my own setup rather than Sewave. Maybe there's a
problem with the DISPLAY variable, or something that I did while upgrading
to Panther -- but I can't see what it is. Has anyone else had this
issue?

Thanks,

Kieran

--
Kieran Healy, http://www.u.arizona.edu/~kjhealy
Asst Professor, Sociology Dept, University of Arizona.



From jiafucang at hotmail.com  Wed Jan  7 08:20:12 2004
From: jiafucang at hotmail.com (Fucang Jia)
Date: Wed, 07 Jan 2004 15:20:12 +0800
Subject: [R] Questions on RandomForest
Message-ID: <Law11-F78WBLYu7AHfo00003e76@hotmail.com>

Hi, erveryone,

I show much thanks to Andy and Matthew on former questions. I now sample 
only a small segment of a image can segment the image into several classes 
by RandomForest successfully. Now I have some confusion on it:

1.  What is the internal component classifier in RandomForest? Are they the 
CART implemented in the rpart package?

2. I use training samples to predict new samples. But in the population, if 
I sample not the whole components, but several components I am interested, 
can randomforest not classify the non-similar components in the testing 
samples, that is to say, label them as outliers?

3. When random forest is used to predict, the testing samples should be no 
contribution to the classifiers(which should be done). So I think the memory 
usage should not increase much, but when I use RF to predict a 256*256*141 
samples by 1329 samples (3 variables), on a SGI Octane2 with 2Giga RAM, it 
runs out of memory. Then I have to segment the big dataset into two, one is 
256*256*70, and the other is 256*256*71. Why do RF consume so much memory in 
the prediction? Does it produce other things other than class label?


Thank you very much!

Fucang



From henkenjo at amadeus.statistik.uni-dortmund.de  Wed Jan  7 09:16:58 2004
From: henkenjo at amadeus.statistik.uni-dortmund.de (Nadine Henkenjohann)
Date: Wed, 07 Jan 2004 09:16:58 +0100
Subject: [R] Spatial regression model
Message-ID: <3FFBC07A.9040409@amadeus.statistik.uni-dortmund.de>

Hello,

is there a package which allows to fit a spatial regression model  for 
any k-dimensional data?
The spatial regression model is composed of three components:

y=mu+Z+epsilon,   

where mu is a low order polynomial, Z is a realization of a second-order 
stochastic process with covariance matrix Sigma and epsilon is a 
realization of a white-noise process. The covariance function belongs to 
the class of  either isotropic or anisotropic functions. Mean and 
covariance parameters are estimated simultaneously by ML or REML.

I hope somebody can answer my question.
Thank you!

Nadine Henkenjohann



From Roger.Bivand at nhh.no  Wed Jan  7 09:30:43 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 7 Jan 2004 09:30:43 +0100 (CET)
Subject: [R] Spatial regression model
In-Reply-To: <3FFBC07A.9040409@amadeus.statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0401070926260.3730-100000@reclus.nhh.no>

On Wed, 7 Jan 2004, Nadine Henkenjohann wrote:

> Hello,
> 
> is there a package which allows to fit a spatial regression model  for 
> any k-dimensional data?

This site:

http://sal.agecon.uiuc.edu/csiss/Rgeo/index.html

tries to provide some guidance about the availability of packages for 
analysis of spatial data. The Geostatistics section of that site lists a 
number of packages perhaps relevant to your problem, but there are other 
possibilities too.

Roger

> The spatial regression model is composed of three components:
> 
> y=mu+Z+epsilon,   
> 
> where mu is a low order polynomial, Z is a realization of a second-order 
> stochastic process with covariance matrix Sigma and epsilon is a 
> realization of a white-noise process. The covariance function belongs to 
> the class of  either isotropic or anisotropic functions. Mean and 
> covariance parameters are estimated simultaneously by ML or REML.
> 
> I hope somebody can answer my question.
> Thank you!
> 
> Nadine Henkenjohann
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From f.calboli at ucl.ac.uk  Wed Jan  7 11:52:14 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 07 Jan 2004 10:52:14 +0000
Subject: [R] malecot migration matrix
Message-ID: <1073472734.2961.16.camel@monkey>

Dear All,

I would like to ask if there is any package that would calculate Malecot
migration matrix (or the Imaizumi or Pena implementations of the MMM). I
did a site-wide search, and went trough the table of contents of a
number of packages that seemed promising, but with no luck.

Regards,

Federico Calboli 
 
-- 



=================================

Federico C. F. Calboli

PLEASE NOTE NEW ADDRESS

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 251 208

f.calboli at ucl.ac.uk



From SAULEAUEA at ch-mulhouse.fr  Wed Jan  7 10:16:09 2004
From: SAULEAUEA at ch-mulhouse.fr (=?iso-8859-1?Q?SAULEAU_Erik-Andr=E9?=)
Date: Wed, 7 Jan 2004 10:16:09 +0100 
Subject: [R] generic name of variables
Message-ID: <A91EF0B9121F834EA6484582DFE1CF4436F09E@messagerie.chm.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040107/d7c07184/attachment.pl

From Rau at demogr.mpg.de  Wed Jan  7 12:57:46 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Wed, 7 Jan 2004 12:57:46 +0100
Subject: [R] Survival, Kaplan-Meier, left truncation
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A05A0@hermes.demogr.mpg.de>

Dear all,

I have data from 1970 to 1990 for people above age 50.
Now I want to calculate survival curves by age starting at age 50 using the
Kaplan Meier Estimator.
The problem I have is that there are already people in 1970 who are older
than 50 years.
I guess this is called delayed entry or left truncation (?).

I thought the code would be:

roland <- survfit(Surv(time=age.enter, time2=age.exit, event=status,
type="interval")~1, weights=gewicht,
	type="kaplan-meier")

But then R tells me that it can handle only right-censored or counting data.

Is there another function which allows me to calculate the Kaplan Meier
estimator?

Thanks,
Roland




+++++
This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked.   If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.



From ripley at stats.ox.ac.uk  Wed Jan  7 12:59:53 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 7 Jan 2004 11:59:53 +0000 (GMT)
Subject: [R] generic name of variables
In-Reply-To: <A91EF0B9121F834EA6484582DFE1CF4436F09E@messagerie.chm.com>
Message-ID: <Pine.LNX.4.44.0401071151310.1110-100000@gannet.stats>

On Wed, 7 Jan 2004, SAULEAU Erik-Andr? wrote:

> Dear R-list,
> 
> I wish a very happy new year and send you a little question: I have
> different variables which names are m1, m2, m4, .., m10, ... and want to
> obtain for example mean of each of them without typing each mean(m1),
> mean(m2), .... What is the solution for decomposing names in mXX?


Without knowing exactly the pattern, let me guess

nms <- ls(pattern="^m[0-9]+")
sapply(nms, function(m) mean(get(m)))

would do what you want.

As Thomas Lumley often says, it is probably better to use a list rather 
than m1, m2, m4, ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gb at stat.umu.se  Wed Jan  7 13:15:09 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 7 Jan 2004 13:15:09 +0100
Subject: [R] Survival, Kaplan-Meier, left truncation
In-Reply-To: <3699CDBC4ED5D511BE6400306E1C0D81030A05A0@hermes.demogr.mpg.de>
References: <3699CDBC4ED5D511BE6400306E1C0D81030A05A0@hermes.demogr.mpg.de>
Message-ID: <20040107121509.GB25168@stat.umu.se>

On Wed, Jan 07, 2004 at 12:57:46PM +0100, Rau, Roland wrote:
> Dear all,
> 
> I have data from 1970 to 1990 for people above age 50.
> Now I want to calculate survival curves by age starting at age 50 using the
> Kaplan Meier Estimator.
> The problem I have is that there are already people in 1970 who are older
> than 50 years.
> I guess this is called delayed entry or left truncation (?).
> 
> I thought the code would be:
> 
> roland <- survfit(Surv(time=age.enter, time2=age.exit, event=status,
> type="interval")~1, weights=gewicht,
> 	type="kaplan-meier")

Not type = "interval", but "count" (or just leave it out)
You can also use 'plot.Surv' in package 'eha' (for plotting).

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From maechler at stat.math.ethz.ch  Wed Jan  7 14:11:48 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 7 Jan 2004 14:11:48 +0100
Subject: [R] Attachments in R-help postings {was "... reading large tables"}
In-Reply-To: <3d3mvvo8b3fkece7lt5crg08osleem2jn3@4ax.com>
References: <20040106190343.GB21560@lysine.umiacs.umd.edu>
	<3d3mvvo8b3fkece7lt5crg08osleem2jn3@4ax.com>
Message-ID: <16380.1428.217189.68645@gargle.gargle.HOWL>

>>>>> "Duncan" == Duncan Murdoch <dmurdoch at pair.com>
>>>>>     on Tue, 06 Jan 2004 14:43:22 -0500 writes:

    Duncan> On Tue, 6 Jan 2004 14:03:47 -0500, Daniel Sumers
    Duncan> Myers <dmyers at umiacs.umd.edu> wrote :

    ..........

    Duncan> P.S. You can't send attachments to the mailing list,
yes, you can, if you use the proper "Content-Type", e.g.,
'text/plain' is ok, see below.

    Duncan> so I didn't see your data file.

He forgot it, and then tried to resend it.  That second try
failed because the full length message became over 500k bytes;
and these currently are completely filtered irrespectively of
content (one needs a limit for large messages: these could bog
down the machine(s) that do the mail filtering).

On the topic of e-mail attachments,
http://www.R-project.org/mail.html#instructions  says

 >> Furthermore, most binary e-mail attachments are not accepted,
 >> i.e., they are removed from the posting completely. As an
 >> exception, we allow application/pdf, application/postscript,
 >> and image/png (and x-tar and gzip on R-devel). You can use
 >> text/plain as well, or simply paste text into your message instead.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From andy_liaw at merck.com  Wed Jan  7 14:11:30 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 7 Jan 2004 08:11:30 -0500
Subject: [R] Questions on RandomForest
Message-ID: <3A822319EB35174CA3714066D590DCD504AF75BF@usrymx25.merck.com>

Fucang,

Questions like these that are specific to one package are best addressed
directly to the package maintainer(s) first (me in this case), as the
discussion is unlikely to be of general interest to the whole list.

1.  The contituent classifier in randomForest uses the CART algorithm
(suitably modified for randomForest), based on Leo Breiman's Fortran code.
I believe the gut of rpart is written in C by Terry Therneau.

2.  There's no built-in functionality for randomForest (or most other
algorithms, for that matter) to detect "outliers".

3.  The predict() function will need to have the entire forest in memory, in
addition to the test set data.  There's nothing wrong with predicting the
test set in pieces.  I routinely do predictions on test sets with > 800,000
cases, but in pieces of sizes 10,000-50,000.

HTH,
Andy

> From: Fucang Jia
> 
> Hi, erveryone,
> 
> I show much thanks to Andy and Matthew on former questions. I 
> now sample 
> only a small segment of a image can segment the image into 
> several classes 
> by RandomForest successfully. Now I have some confusion on it:
> 
> 1.  What is the internal component classifier in 
> RandomForest? Are they the 
> CART implemented in the rpart package?
> 
> 2. I use training samples to predict new samples. But in the 
> population, if 
> I sample not the whole components, but several components I 
> am interested, 
> can randomforest not classify the non-similar components in 
> the testing 
> samples, that is to say, label them as outliers?
> 
> 3. When random forest is used to predict, the testing samples 
> should be no 
> contribution to the classifiers(which should be done). So I 
> think the memory 
> usage should not increase much, but when I use RF to predict 
> a 256*256*141 
> samples by 1329 samples (3 variables), on a SGI Octane2 with 
> 2Giga RAM, it 
> runs out of memory. Then I have to segment the big dataset 
> into two, one is 
> 256*256*70, and the other is 256*256*71. Why do RF consume so 
> much memory in 
> the prediction? Does it produce other things other than class label?
> 
> 
> Thank you very much!
> 
> Fucang
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From rodrigo.abt at sii.cl  Wed Jan  7 15:30:47 2004
From: rodrigo.abt at sii.cl (Rodrigo Abt)
Date: Wed, 07 Jan 2004 11:30:47 -0300
Subject: [R] Multiple response dv repeated measures
Message-ID: <000201c3d52a$d7aae5f0$2a01240a@rodrigoabt>

Dear R-listers,

I have a dataset where I'm studying differences between a treatment group
and a control group for an intervention in a certain point of time for two
responses simoultaneously, so I looked for a manova approach first.
According to R help, manova does not support the inclusion of an Error()
term in the formula call, and I have repeated measures data, this mean I
can't account for subject variance in time. I've searched through r-help for
a similar problem and found nothing. Any lights ?

Regards,

Rodrigo Abt,
Analyst,
Department of Economic and Tributary Studies,
SII, Chile.



From flom at ndri.org  Wed Jan  7 16:13:30 2004
From: flom at ndri.org (Peter Flom)
Date: Wed, 07 Jan 2004 10:13:30 -0500
Subject: [R] rpart question on loss matrix
Message-ID: <sffbdbe2.082@MAIL.NDRI.ORG>

Hello again

I've looked through ?rpart, Atkinson & Therneau (1997), Chap 10 of
Venables and Ripley, Breman et al., and the r hgelp archives  but
haven't seen the answer to these two questions

1) How does rpart deal with asymmetric loss matrices?  Breiman et al.
suggest some possibilities, but, of course, do not say how rpart does
it.

2) In the loss matrix, which direction (column or row) is 'truth' and
which 'output of program'?  e.g., if you have a 3 level DV (say the
levels are A, B, C) and you want a higher cost for misclassifying as
later in the alphabet, would it be

0  3  5  
1  0  2
2  1  0

or

0  1  2
3  0  1  
5  2  0


Thanks in advance

Peter



From walton.green at yale.edu  Wed Jan  7 16:41:03 2004
From: walton.green at yale.edu (Walton A. Green)
Date: Wed, 7 Jan 2004 10:41:03 -0500 (EST)
Subject: [R] Analyzing dendrograms
In-Reply-To: <200401071115.i07B6up8000160@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0401071001290.23080-100000@ares.its.yale.edu>


Ladies and Gentlemen,

As Johan Lindberg points out, the documentation for handling dendrograms
is sparse....Does anyone know who is responsible for or working on 
development of tree methods and objects? I've written a couple of scripts   
for my own use to translate between parenthetical (A(B(CD))) or binary  
A00 B10 C11 D11 tree formats and cluster objects in R, but as an 
inexperienced programmer have had difficulty integrating them with the 
existing framework--I'm trying to write some resampling routines and 
sensitivity tests for tree objects.

Perhaps this question should go to the r-devel list instead....

Yours,
Walton Green

> Date: Tue, 06 Jan 2004 12:49:59 +0100
> From: Johan Lindberg <johanl at kiev.biotech.kth.se>
> Subject: RE: [R] Analyzing dendograms??
> To: <r-help at stat.math.ethz.ch>
> Message-ID: <5.2.0.9.0.20040106122638.00badeb8 at kiev.biotech.kth.se>
> Content-Type: text/plain; charset="iso-8859-1"; format=flowed

> ...dendograms/heatmaps/hclust in R in a proper way I ask myself, is 
> there a way of doing this in R? or is this a limitation of the 
> functions available today in the R programming language. I know there 
> are some functions like cutree etc but the documentation is really, 
> really sparse. Are there any tutorials out there of how to do these 
> things? or should one turn to alternative programs like MEV from TIGR?

> / J



From Friedrich.Leisch at ci.tuwien.ac.at  Wed Jan  7 16:52:02 2004
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Wed, 7 Jan 2004 16:52:02 +0100
Subject: [R] Sweave and X11 on OSX 10.3
In-Reply-To: <Pine.GSO.4.58.0401062334360.4520@ptah.u.arizona.edu>
References: <Pine.GSO.4.58.0401062334360.4520@ptah.u.arizona.edu>
Message-ID: <16380.11042.561160.100462@celebrian.ci.tuwien.ac.at>

>>>>> On Tue, 6 Jan 2004 23:44:42 -0700 (MST),
>>>>> Kieran Healy (KH) wrote:

  > Hi -
  > I'm running R 1.8.1 (compiled from source) on Mac OS X 10.3 (Panther). I
  > find that, if Apple's X11 application is not running, Sweave gives an
  > error when it wants to create a pdf or eps figure. E.g., in the package's
  > own example-1.Snw file a boxplot is created at chunk 2:

  > <<fig=TRUE,echo=FALSE>>=
  > boxplot(Ozone ~ Month, data = airquality)
  > @

  > Normally this will create a pdf and an eps version of the boxplot. I get:

  >> Sweave("example-1.Snw")
  > Writing to file example-1.tex
  > Processing code chunks ...
  >  1 : echo term verbatim
  >  2 : term verbatim eps pdf
  > Warning message:
  > unable to open connection to X11 display`'

  > Error:  chunk 2
  > Error in X11(display, width, height, pointsize, gamma, colortype,
  > maxcubesize,  :
  >         unable to start device X11

  > If I start the X11 application, Sweave runs as normal but displays any
  > figures on an x11() device in addition to creating the eps / pdf files.

  > I don't remember this happening before and experience teaches me to assume
  > the issue is with my own setup rather than Sewave. Maybe there's a
  > problem with the DISPLAY variable, or something that I did while upgrading
  > to Panther -- but I can't see what it is. Has anyone else had this
  > issue?

Your R session has obviously x11() as the default plotting device
... e.g.,

	plot(1:10)

at the prompt should also give an error, if no graphics device is
open. I don't know too much about MacOS X, but having the DISPLAY
variable set without having an X11 server surely means asking for
trouble on Linux, and I guess MacOS X is not different ...

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From Gerald.Jean at spgdag.ca  Wed Jan  7 17:13:22 2004
From: Gerald.Jean at spgdag.ca (Gerald.Jean@spgdag.ca)
Date: Wed, 7 Jan 2004 11:13:22 -0500
Subject: [R] Installing R on 64-bit Solaris 2.8
Message-ID: <OFDB0FA98E.F5A3993E-ON85256E14.005790E7@spgdag.ca>

Hello,

I am installing R on a Sun Solaris 64-bit machine.  I followed the
instructions in the "R Installation and Administration" guide.  I am amazed
at how much is going on during the installation process and I congratulate
the people who have put all this together for the ones amongst us who don't
have the required skills to do it.

The installation went fairly well I think, I got the following Warnings
from "configure".  I guess that the required packages to build the
different R manuals were not found on the machine, I am a little surprised
regarding the PDF manuals since Acrobat reader is installed and
"/opt/Acrobat5/bin" is on the PATH; emacs is also installed and in the PATH
variable?

configure: WARNING: you cannot build DVI versions of the R manuals
configure: WARNING: you cannot build info versions of the R manuals
configure: WARNING: you cannot build PDF versions of the R manuals

"make" ran with no complaints.  "make check" ended with the following
messages, is that a concern, should I pursue the installation or is this
realy a fatal error as the message states?  If so what should I do
differently?

running tests of Internet and socket functions
  expect some differences
running code in 'internet.R' ...*** Error code 1
make: Fatal error: Command failed for target `internet.Rout'
Current working directory /actuaria/application/R-1.8.1/tests
*** Error code 1 (ignored)

Thank you very much for your support,

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming



From tlumley at u.washington.edu  Wed Jan  7 17:20:40 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 7 Jan 2004 08:20:40 -0800 (PST)
Subject: [R] Survival, Kaplan-Meier, left truncation
In-Reply-To: <3699CDBC4ED5D511BE6400306E1C0D81030A05A0@hermes.demogr.mpg.de>
References: <3699CDBC4ED5D511BE6400306E1C0D81030A05A0@hermes.demogr.mpg.de>
Message-ID: <Pine.A41.4.58.0401070816350.114106@homer07.u.washington.edu>

On Wed, 7 Jan 2004, Rau, Roland wrote:

> Dear all,
>
> I have data from 1970 to 1990 for people above age 50.
> Now I want to calculate survival curves by age starting at age 50 using the
> Kaplan Meier Estimator.
> The problem I have is that there are already people in 1970 who are older
> than 50 years.
> I guess this is called delayed entry or left truncation (?).

Yes

> I thought the code would be:
>
> roland <- survfit(Surv(time=age.enter, time2=age.exit, event=status,
> type="interval")~1, weights=gewicht,
> 	type="kaplan-meier")
>
> But then R tells me that it can handle only right-censored or counting data.

The `interval' type is for interval-censored data.  Left-truncated,
right-censored data are so easy to handle with hazard-based models that
they are the default.  You want

  roland <- survfit(Surv(age.enter, age.exit, status))


	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From rpeng at jhsph.edu  Wed Jan  7 17:23:49 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 07 Jan 2004 11:23:49 -0500
Subject: [R] Installing R on 64-bit Solaris 2.8
In-Reply-To: <OFDB0FA98E.F5A3993E-ON85256E14.005790E7@spgdag.ca>
References: <OFDB0FA98E.F5A3993E-ON85256E14.005790E7@spgdag.ca>
Message-ID: <3FFC3295.60200@jhsph.edu>

You probably don't have LaTeX installed, which is why you cannot build 
the PDF manuals.  It has nothing to do with Acrobat or Emacs.  I believe 
the checks in internet.R can be ignored (as the output says).  Does the 
R installation run?

-roger

Gerald.Jean at spgdag.ca wrote:
> Hello,
> 
> I am installing R on a Sun Solaris 64-bit machine.  I followed the
> instructions in the "R Installation and Administration" guide.  I am amazed
> at how much is going on during the installation process and I congratulate
> the people who have put all this together for the ones amongst us who don't
> have the required skills to do it.
> 
> The installation went fairly well I think, I got the following Warnings
> from "configure".  I guess that the required packages to build the
> different R manuals were not found on the machine, I am a little surprised
> regarding the PDF manuals since Acrobat reader is installed and
> "/opt/Acrobat5/bin" is on the PATH; emacs is also installed and in the PATH
> variable?
> 
> configure: WARNING: you cannot build DVI versions of the R manuals
> configure: WARNING: you cannot build info versions of the R manuals
> configure: WARNING: you cannot build PDF versions of the R manuals
> 
> "make" ran with no complaints.  "make check" ended with the following
> messages, is that a concern, should I pursue the installation or is this
> realy a fatal error as the message states?  If so what should I do
> differently?
> 
> running tests of Internet and socket functions
>   expect some differences
> running code in 'internet.R' ...*** Error code 1
> make: Fatal error: Command failed for target `internet.Rout'
> Current working directory /actuaria/application/R-1.8.1/tests
> *** Error code 1 (ignored)
> 
> Thank you very much for your support,
> 
> G?rald Jean
> Analyste-conseil (statistiques), Actuariat
> t?lephone            : (418) 835-4900 poste (7639)
> t?lecopieur          : (418) 835-6657
> courrier ?lectronique: gerald.jean at spgdag.ca
> 
> "In God we trust all others must bring data"  W. Edwards Deming
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From tlumley at u.washington.edu  Wed Jan  7 17:30:04 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 7 Jan 2004 08:30:04 -0800 (PST)
Subject: [R] Sweave and X11 on OSX 10.3
In-Reply-To: <16380.11042.561160.100462@celebrian.ci.tuwien.ac.at>
References: <Pine.GSO.4.58.0401062334360.4520@ptah.u.arizona.edu>
	<16380.11042.561160.100462@celebrian.ci.tuwien.ac.at>
Message-ID: <Pine.A41.4.58.0401070823140.114106@homer07.u.washington.edu>

On Wed, 7 Jan 2004 Friedrich.Leisch at ci.tuwien.ac.at wrote:

> open. I don't know too much about MacOS X, but having the DISPLAY
> variable set without having an X11 server surely means asking for
> trouble on Linux, and I guess MacOS X is not different ...
>

Yes, except there is no excuse for doing this under Linux and there are
good reasons for doing it on OS X.  Under Linux, if you are running X then
all your terminals were probably started after the X server, and they are
usually children of the X root window.  Under OS X the terminals are
usually started independently of X11 and may have been running before the
X server was started.  I don't know any automatic way to have DISPLAY set
correctly when the server is running and unset when it isn't.

The result is that you either need to have DISPLAY set in .tcshrc or
equivalent, or remember to set it when needed.


	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From adi at roda.ro  Wed Jan  7 17:29:37 2004
From: adi at roda.ro (Adrian Dusa)
Date: Wed, 7 Jan 2004 18:29:37 +0200
Subject: [R] segments in 3d space
Message-ID: <000201c3d53b$7771a870$6901a8c0@roda.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040107/a870d105/attachment.pl

From Friedrich.Leisch at ci.tuwien.ac.at  Wed Jan  7 17:35:20 2004
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Wed, 7 Jan 2004 17:35:20 +0100
Subject: [R] Sweave and X11 on OSX 10.3
In-Reply-To: <Pine.A41.4.58.0401070823140.114106@homer07.u.washington.edu>
References: <Pine.GSO.4.58.0401062334360.4520@ptah.u.arizona.edu>
	<16380.11042.561160.100462@celebrian.ci.tuwien.ac.at>
	<Pine.A41.4.58.0401070823140.114106@homer07.u.washington.edu>
Message-ID: <16380.13640.861086.541421@celebrian.ci.tuwien.ac.at>

>>>>> On Wed, 7 Jan 2004 08:30:04 -0800 (PST),
>>>>> Thomas Lumley (TL) wrote:

  > On Wed, 7 Jan 2004 Friedrich.Leisch at ci.tuwien.ac.at wrote:
  >> open. I don't know too much about MacOS X, but having the DISPLAY
  >> variable set without having an X11 server surely means asking for
  >> trouble on Linux, and I guess MacOS X is not different ...
  >> 

  > Yes, except there is no excuse for doing this under Linux and there are
  > good reasons for doing it on OS X.  Under Linux, if you are running X then
  > all your terminals were probably started after the X server, and they are
  > usually children of the X root window.  Under OS X the terminals are
  > usually started independently of X11 and may have been running before the
  > X server was started.  I don't know any automatic way to have DISPLAY set
  > correctly when the server is running and unset when it isn't.

  > The result is that you either need to have DISPLAY set in .tcshrc or
  > equivalent, or remember to set it when needed.

I see, could in this case R for the Mac be smarter about what the
default graphics device should be? This is not an Sweave issue, it
simply means that under the setup described above any call to plot()
---without actively opening a device first---will fail ...

.f



From ripley at stats.ox.ac.uk  Wed Jan  7 17:38:26 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 7 Jan 2004 16:38:26 +0000 (GMT)
Subject: [R] Installing R on 64-bit Solaris 2.8
In-Reply-To: <OFDB0FA98E.F5A3993E-ON85256E14.005790E7@spgdag.ca>
Message-ID: <Pine.LNX.4.44.0401071635500.7143-100000@gannet.stats>

On Wed, 7 Jan 2004 Gerald.Jean at spgdag.ca wrote:

> Hello,
> 
> I am installing R on a Sun Solaris 64-bit machine.  I followed the
> instructions in the "R Installation and Administration" guide.  I am amazed
> at how much is going on during the installation process and I congratulate
> the people who have put all this together for the ones amongst us who don't
> have the required skills to do it.
> 
> The installation went fairly well I think, I got the following Warnings
> from "configure".  I guess that the required packages to build the
> different R manuals were not found on the machine, I am a little surprised
> regarding the PDF manuals since Acrobat reader is installed and
> "/opt/Acrobat5/bin" is on the PATH; emacs is also installed and in the PATH
> variable?
> 
> configure: WARNING: you cannot build DVI versions of the R manuals
> configure: WARNING: you cannot build info versions of the R manuals
> configure: WARNING: you cannot build PDF versions of the R manuals

You probably don't have tex, pdftex nor makeinfo installed.

> "make" ran with no complaints.  "make check" ended with the following
> messages, is that a concern, should I pursue the installation or is this
> realy a fatal error as the message states?  If so what should I do
> differently?
> 
> running tests of Internet and socket functions
>   expect some differences
> running code in 'internet.R' ...*** Error code 1
> make: Fatal error: Command failed for target `internet.Rout'
> Current working directory /actuaria/application/R-1.8.1/tests
> *** Error code 1 (ignored)

Look in the file tests/internet.Rout.fail.  It is probably an
authentication problem (might you need a proxy set?), but it would be wise
to track it a bit further.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From agustin.perez at umh.es  Wed Jan  7 17:53:56 2004
From: agustin.perez at umh.es (Perez Martin, Agustin)
Date: Wed, 7 Jan 2004 17:53:56 +0100 
Subject: [R] assign
Message-ID: <5AFDDD57E2771B409224CD858CC6DE0D02DAB352@mailer-e051.umh.es>

DeaR useRs:

I would like to assign a values in an object using a loop 'for'.
This is a reduce example of my problem, my real problem is a few
complicated:

for (j in 1:10) {
	x.j<-rnorm(100)
}

I want to create 10 objects as "x.1, x.2, ... , x.9, x.10" with values in
it.
I used the "assign" function but nothing happens.
Thank you very much



From petr.pikal at precheza.cz  Wed Jan  7 17:56:50 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 07 Jan 2004 17:56:50 +0100
Subject: [R] locale problem in W98
Message-ID: <3FFC4862.5035.20A14C5@localhost>

Dear all

I am using two computers, one with Windows2000 and the other one with W98 
both have the same version (precompiled binary) R 1.8.1 and I have experienced a 
slight problem with text used in plotting on W98 machine.

When I try to write some local characters into R console

????? (not sure if it is OK on your computers)

in W2000 **everything** is OK but in W98 some of the characters (1,3,4,5) are 
changed (and the same is when I try to annotate a plot with them). When I copy it 
from R console to some editor (e.g. Notepad) the characters are again OK and 
when I copy the characters from editor back to console they are again corrupted.

> Sys.getlocale()
[1] "LC_COLLATE=Czech_Czech Republic.1250;LC_CTYPE=Czech_Czech 
Republic.1250;LC_MONETARY=C;LC_NUMERIC=C;LC_TIME=Czech_Czec
h Republic.1250"
>

is same on both and I have checked Rprofile and my profile on both computers 
and it seems to be the same.

I can put Czech characters on finished plots with some other program (GIMP) 
but I prefer to do all possible annotation in R.

Please, can you give me some hint where to look for possible solution on W98 
machine setting.

Thank you 

Petr Pikal
petr.pikal at precheza.cz



From spencer.graves at pdf.com  Wed Jan  7 17:59:36 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 07 Jan 2004 08:59:36 -0800
Subject: [R] segments in 3d space
In-Reply-To: <000201c3d53b$7771a870$6901a8c0@roda.local>
References: <000201c3d53b$7771a870$6901a8c0@roda.local>
Message-ID: <3FFC3AF8.40206@pdf.com>

Have you looked at the documentation on "persp", especially the function 
"trans3d" in the examples?  Also, have you tried www.r-project.org -> 
search -> "R site search", searching for what you want?  This "persp" -> 
"trans3d" was mentioned in another recent discussion on this list. 

hope this helps.  spencer graves

Adrian Dusa wrote:

>Hi all,
>
> 
>
>Is it possible to draw line segments in a 3d space plot?
>
>I'm interested to draw the errors from an observed value to the
>regression plane, for a textbook example in an Intro Stats handbook for
>multiple regression.
>
>I used the scatterplot3d package to draw the regression plane.
>
> 
>
>Many thanks,
>
>Adrian
>
> 
>
>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>Adrian Dusa (adi at roda.ro)
>Romanian Social Data Archive (www.roda.ro)
>1, Schitu Magureanu Bd.
>76625 Bucharest sector 5
>Romania
>
>
>Tel./Fax:
>
>+40 (21) 312.66.18\
>
>+40 (21) 312.02.10/ int.101
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ripley at stats.ox.ac.uk  Wed Jan  7 18:32:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 7 Jan 2004 17:32:59 +0000 (GMT)
Subject: [R] locale problem in W98
In-Reply-To: <3FFC4862.5035.20A14C5@localhost>
Message-ID: <Pine.LNX.4.44.0401071717320.7184-100000@gannet.stats>

What happens if you

1) source() a file containing those characters.
2) Use Rterm?
3) Change the fonts both for the console and for graphics.  Is this the 
same for all fonts?

It sounds as if at least part of the problem is the character map that 
Rgui is using on your W98 machine.

BTW, I don't think they are `corrupted', just not treated as being in the 
encoding you intended (which has nothing to do with locales per se under 
Windows).  Rgui does not itself handle encodings, so it accepts whatever 
keycode it gets and prints/plots that code in the current font.

You do know that MicroSoft no longer supports W98?

On Wed, 7 Jan 2004, Petr Pikal wrote:

> Dear all
> 
> I am using two computers, one with Windows2000 and the other one with W98 
> both have the same version (precompiled binary) R 1.8.1 and I have experienced a 
> slight problem with text used in plotting on W98 machine.
> 
> When I try to write some local characters into R console
> 
> ????????? (not sure if it is OK on your computers)

I strongly suspect they are not: I cannot display ISO-8859-2.

> in W2000 **everything** is OK but in W98 some of the characters (1,3,4,5) are 
> changed (and the same is when I try to annotate a plot with them). When I copy it 
> from R console to some editor (e.g. Notepad) the characters are again OK and 
> when I copy the characters from editor back to console they are again corrupted.
> 
> > Sys.getlocale()
> [1] "LC_COLLATE=Czech_Czech Republic.1250;LC_CTYPE=Czech_Czech 
> Republic.1250;LC_MONETARY=C;LC_NUMERIC=C;LC_TIME=Czech_Czec
> h Republic.1250"
> >
> 
> is same on both and I have checked Rprofile and my profile on both computers 
> and it seems to be the same.
> 
> I can put Czech characters on finished plots with some other program (GIMP) 
> but I prefer to do all possible annotation in R.
> 
> Please, can you give me some hint where to look for possible solution on W98 
> machine setting.
> 
> Thank you 
> 
> Petr Pikal
> petr.pikal at precheza.cz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Wed Jan  7 18:34:49 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 07 Jan 2004 18:34:49 +0100
Subject: [R] assign
In-Reply-To: <5AFDDD57E2771B409224CD858CC6DE0D02DAB352@mailer-e051.umh.es>
Message-ID: <3FFC5149.28112.22CDE49@localhost>

Hi

is it possible for you to use one object (data frame) and assign 
along its collumns?

> x<-rep(0,10)
> x<-cbind(x,x,x,x,x,x)
> x
      x x x x x x
 [1,] 0 0 0 0 0 0
 [2,] 0 0 0 0 0 0
 [3,] 0 0 0 0 0 0
 [4,] 0 0 0 0 0 0
 [5,] 0 0 0 0 0 0
 [6,] 0 0 0 0 0 0
 [7,] 0 0 0 0 0 0
 [8,] 0 0 0 0 0 0
 [9,] 0 0 0 0 0 0
[10,] 0 0 0 0 0 0
> for(i in 1:6) x[,i]<-rnorm(10)


or you can use list in quite similar manner.

Cheers
Petr


On 7 Jan 2004 at 17:53, Perez Martin, Agustin wrote:

> DeaR useRs:
> 
> I would like to assign a values in an object using a loop 'for'.
> This is a reduce example of my problem, my real problem is a few
> complicated:
> 
> for (j in 1:10) {
>  x.j<-rnorm(100)
> }
> 
> I want to create 10 objects as "x.1, x.2, ... , x.9, x.10" with values
> in it. I used the "assign" function but nothing happens. Thank you
> very much
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From s-plus at wiwi.uni-bielefeld.de  Wed Jan  7 18:35:46 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Wed, 07 Jan 2004 18:35:46 +0100
Subject: [R] assign
References: <5AFDDD57E2771B409224CD858CC6DE0D02DAB352@mailer-e051.umh.es>
Message-ID: <3FFC4372.2040608@wiwi.uni-bielefeld.de>

Perez Martin, Agustin wrote:

>DeaR useRs:
>
>I would like to assign a values in an object using a loop 'for'.
>This is a reduce example of my problem, my real problem is a few
>complicated:
>
>for (j in 1:10) {
>	x.j<-rnorm(100)
>}
>
>I want to create 10 objects as "x.1, x.2, ... , x.9, x.10" with values in
>it.
>I used the "assign" function but nothing happens.
>Thank you very much
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>
Use eval or assign:

 > for(j in 1:10) eval(parse(text=paste("x",j,"<-",j,sep="")))
 > x1
[1] 1
 > x8
[1] 8
 > for(j in 1:10) eval(parse(text=paste("x",j,"<-rnorm(10)",sep="")))
 > x1
 [1]  0.49045324  0.44842510 -1.18015351 -0.04325187 -0.75345939 -0.99181309
 [7]  0.62517301 -0.68466635  0.33383560 -0.62189500
 > x2
 [1] -0.4344948  2.0276137  1.2783173  1.1170551  0.3546490 -0.0748969
 [7] -0.8817247 -1.4649175 -1.5461995 -0.6575016
 > for(j in 1:10) assign(paste("y",j,sep=""),rnorm(10))
 > y1
 [1] 1.7255925 0.4993323 1.8846513 0.2058971 0.2284036  -3.1971553
 [7]  -0.2629365 0.2724788  -0.9911388  -0.6341857
 > y2
 [1] 0.11301503  -1.28497666 0.40670853 0.08479014 1.05818411  -1.10843908
 [7] 1.30441911  -0.49050833  -1.21438645 0.03923849
ls()
 [1] "j"   "x1"  "x10" "x2"  "x3"  "x4"  "x5"  "x6"  "x7"  "x8"  "x9"  "y1"
[13] "y10" "y2"  "y3"  "y4"  "y5"  "y6"  "y7"  "y8"  "y9"

pw



From abunn at montana.edu  Wed Jan  7 18:36:58 2004
From: abunn at montana.edu (Andy Bunn)
Date: Wed, 7 Jan 2004 10:36:58 -0700
Subject: [R] assign
In-Reply-To: <5AFDDD57E2771B409224CD858CC6DE0D02DAB352@mailer-e051.umh.es>
Message-ID: <001d01c3d544$eb863740$78f05a99@msu.montana.edu>

This is one way:
for (j in 1:10) {
   assign(paste("x", j, sep="."), rnorm(100)) 
}

BTW, there have been many similar posts like this in the past. They are
easily found using the search function at
http://cran.r-project.org/search.html

HTH, Andy



From Roger.Bivand at nhh.no  Wed Jan  7 18:37:49 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 7 Jan 2004 18:37:49 +0100 (CET)
Subject: [R] assign
In-Reply-To: <5AFDDD57E2771B409224CD858CC6DE0D02DAB352@mailer-e051.umh.es>
Message-ID: <Pine.LNX.4.44.0401071831420.3730-100000@reclus.nhh.no>

On Wed, 7 Jan 2004, Perez Martin, Agustin wrote:

> DeaR useRs:
> 
> I would like to assign a values in an object using a loop 'for'.
> This is a reduce example of my problem, my real problem is a few
> complicated:
> 
> for (j in 1:10) {
> 	x.j<-rnorm(100)
> }
> 
> I want to create 10 objects as "x.1, x.2, ... , x.9, x.10" with values in
> it.

Actually, you assigned ten times to object x.j. As was mentioned earlier 
today in reference to a different question, you will almost always find 
that what you think you need and what works best are not the same - a list 
here would be much more convenient:

x <- vector(mode="list", length=10)
for (j in 1:10) {
  x[[j]] <- rnorm(100)
}

for example. For more complicated list elements, the arguments for using 
lists are even stronger. Take a little time to make lists your friends, 
they are powerful and flexible.

> I used the "assign" function but nothing happens.
> Thank you very much
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From rpeng at jhsph.edu  Wed Jan  7 18:53:10 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 07 Jan 2004 12:53:10 -0500
Subject: [R] assign
In-Reply-To: <5AFDDD57E2771B409224CD858CC6DE0D02DAB352@mailer-e051.umh.es>
References: <5AFDDD57E2771B409224CD858CC6DE0D02DAB352@mailer-e051.umh.es>
Message-ID: <3FFC4786.1020404@jhsph.edu>

Use assign().

varnames <- paste("x", 1:10, sep = ".")
for(j in 1:10) {
	assign(varnames[j], rnorm(10))
}

-roger

Perez Martin, Agustin wrote:
> DeaR useRs:
> 
> I would like to assign a values in an object using a loop 'for'.
> This is a reduce example of my problem, my real problem is a few
> complicated:
> 
> for (j in 1:10) {
> 	x.j<-rnorm(100)
> }
> 
> I want to create 10 objects as "x.1, x.2, ... , x.9, x.10" with values in
> it.
> I used the "assign" function but nothing happens.
> Thank you very much
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dieter.menne at menne-biomed.de  Wed Jan  7 20:04:51 2004
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed, 7 Jan 2004 20:04:51 +0100
Subject: [R] GLMM (lme4) vs. glmmPQL output
Message-ID: <JLEPLGAANFCEAEDCAGJNOEDACHAA.dieter.menne@menne-biomed.de>

Dear List,

As I understand, GLMM (in experimental lme4) and glmmPQL (MASS) do
similar things using somewhat different methods. Trying both,
I get the same coefficients, but markedly different std. errors and
p-values.
Any help in understanding the models tested by both procedures?

Dieter Menne


UseMASS<-T # must restart R after changing because of nlme/lme4 clash
if (UseMASS){
  library(MASS)
  summary(glmmPQL(y ~ trt + I(week > 2), random = ~ 1 | ID,
                  family = binomial, data = bacteria))
} else
{
  library(lme4)
  summary(GLMM(y ~ trt + I(week > 2), random = ~ 1 | ID,
                  family = binomial, data = bacteria,method="PQL"))
}

(MASS output)
Fixed effects: y ~ trt + I(week > 2)
                    Value Std.Error  DF   t-value p-value
(Intercept)      3.412012 0.5185028 169  6.580509  0.0000
trtdrug         -1.247355 0.6440627  47 -1.936698  0.0588
trtdrug+        -0.754327 0.6453971  47 -1.168780  0.2484
I(week > 2)TRUE -1.607256 0.3583378 169 -4.485310  0.0000

(lme4 output)
Fixed effects: y ~ trt + I(week > 2)
                 Estimate Std. Error  DF z value Pr(>|z|)
(Intercept)       3.41202    3.93293 169  0.8676   0.3856
trtdrug          -1.24736    1.52156  47 -0.8198   0.4123
trtdrug+         -0.75433    1.21963  47 -0.6185   0.5363
I(week > 2)TRUE  -1.60726    2.19660 169 -0.7317   0.4644



From tlumley at u.washington.edu  Wed Jan  7 20:05:49 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 7 Jan 2004 11:05:49 -0800 (PST)
Subject: [R] Sweave and X11 on OSX 10.3
In-Reply-To: <16380.13640.861086.541421@celebrian.ci.tuwien.ac.at>
References: <Pine.GSO.4.58.0401062334360.4520@ptah.u.arizona.edu>
	<16380.11042.561160.100462@celebrian.ci.tuwien.ac.at>
	<Pine.A41.4.58.0401070823140.114106@homer07.u.washington.edu>
	<16380.13640.861086.541421@celebrian.ci.tuwien.ac.at>
Message-ID: <Pine.A41.4.58.0401071052070.104212@homer38.u.washington.edu>

On Wed, 7 Jan 2004 Friedrich.Leisch at ci.tuwien.ac.at wrote:
> I see, could in this case R for the Mac be smarter about what the
> default graphics device should be? This is not an Sweave issue, it
> simply means that under the setup described above any call to plot()
> ---without actively opening a device first---will fail ...
>

R for the mac should probably be less smart. Since options("device") is
set at start-up there isn't much ability to tell what it should be, and we
could just use "postscript" (though "pdf" might be more appropriate on a
Mac).  We have been reluctant to special-case mac code unnecessarily, but
this does indicate a case where it might be necessary.

In the medium term this problem should go away if we get the quartz()
driver working more widely.


	-thomas



From kjhealy at actewagl.net.au  Wed Jan  7 22:50:47 2004
From: kjhealy at actewagl.net.au (Kieran Healy)
Date: Thu, 08 Jan 2004 08:50:47 +1100
Subject: [R] Sweave and X11 on OSX 10.3
In-Reply-To: <16380.11042.561160.100462@celebrian.ci.tuwien.ac.at>
Message-ID: <BC22CA67.2193%kjhealy@actewagl.net.au>

I see. Unsetting the DISPLAY variable

 % unset DISPLAY  

solves the problem at the terminal.

Kieran

On 1/8/04 2:52 AM, "Friedrich.Leisch at ci.tuwien.ac.at"
<Friedrich.Leisch at ci.tuwien.ac.at> wrote:

>>>>>> On Tue, 6 Jan 2004 23:44:42 -0700 (MST),
>>>>>> Kieran Healy (KH) wrote:
> 
>> Hi -
>> I'm running R 1.8.1 (compiled from source) on Mac OS X 10.3 (Panther). I
>> find that, if Apple's X11 application is not running, Sweave gives an
>> error when it wants to create a pdf or eps figure. E.g., in the package's
>> own example-1.Snw file a boxplot is created at chunk 2:
> 
>> <<fig=TRUE,echo=FALSE>>=
>> boxplot(Ozone ~ Month, data = airquality)
>> @
> 
>> Normally this will create a pdf and an eps version of the boxplot. I get:
> 
>>> Sweave("example-1.Snw")
>> Writing to file example-1.tex
>> Processing code chunks ...
>>  1 : echo term verbatim
>>  2 : term verbatim eps pdf
>> Warning message:
>> unable to open connection to X11 display`'
> 
>> Error:  chunk 2
>> Error in X11(display, width, height, pointsize, gamma, colortype,
>> maxcubesize,  :
>>         unable to start device X11
> 
>> If I start the X11 application, Sweave runs as normal but displays any
>> figures on an x11() device in addition to creating the eps / pdf files.
> 
>> I don't remember this happening before and experience teaches me to assume
>> the issue is with my own setup rather than Sewave. Maybe there's a
>> problem with the DISPLAY variable, or something that I did while upgrading
>> to Panther -- but I can't see what it is. Has anyone else had this
>> issue?
> 
> Your R session has obviously x11() as the default plotting device
> ... e.g.,
> 
> plot(1:10)
> 
> at the prompt should also give an error, if no graphics device is
> open. I don't know too much about MacOS X, but having the DISPLAY
> variable set without having an X11 server surely means asking for
> trouble on Linux, and I guess MacOS X is not different ...

-- 
Kieran Healy, http://www.u.arizona.edu/~kjhealy
Assistant Professor, Sociology Dept, University of Arizona.
Research Fellow, SPT, RSSS, Australian National University.



From hastie at stanford.edu  Thu Jan  8 00:10:04 2004
From: hastie at stanford.edu (Trevor Hastie)
Date: Wed, 7 Jan 2004 15:10:04 -0800
Subject: [R] Statistical Learning and Datamining course based on R/Splus
	tools
Message-ID: <007d01c3d573$627b50f0$ec6640ab@stuk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040107/62d77606/attachment.pl

From mmchug4 at lsu.edu  Thu Jan  8 00:11:24 2004
From: mmchug4 at lsu.edu (Maurice McHugh)
Date: Wed, 7 Jan 2004 17:11:24 -0600
Subject: [R] 3-dimensional looping Q.
Message-ID: <002101c3d573$920ebaa0$3e8be344@br.no.cox.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040107/0e04c0bf/attachment.pl

From ligges at statistik.uni-dortmund.de  Thu Jan  8 08:39:06 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 08 Jan 2004 08:39:06 +0100
Subject: [R] 3-dimensional looping Q.
In-Reply-To: <002101c3d573$920ebaa0$3e8be344@br.no.cox.net>
References: <002101c3d573$920ebaa0$3e8be344@br.no.cox.net>
Message-ID: <3FFD091A.5020002@statistik.uni-dortmund.de>

Maurice McHugh wrote:
> Hello everyone-
> 
> I have a 3-d array with the 1st dimension being monthly mean data that
> I would like to correlate with some time series index, for example, and 
> save the coefficients in an array.
> 
> The code I am currently running is....
> 
> 
>    rData <- array(0,c(73,144))   # array to store results
>    for (i in 1:73) {
>         for (j in 1:144) {
>               rData[i,j] <- cor(slp[,i,j],y)
>         }
>     }
> 
>     Rather than running this analysis embedded with two outer loops, are =
>     there any more efficient ways of doing this?
>     Many thanks!


Don't know whether it's more efficient:
You can try to apply() the function rcorr() in package "Hmisc" to your 
problem...

Uwe Ligges




>     
> 
> Maurice
> 
> Maurice McHugh
> Department of Geography and Anthropology
> Louisiana State University
> Baton Rouge, LA
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Jan  8 08:45:13 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 08 Jan 2004 08:45:13 +0100
Subject: [R] segments in 3d space
In-Reply-To: <000201c3d53b$7771a870$6901a8c0@roda.local>
References: <000201c3d53b$7771a870$6901a8c0@roda.local>
Message-ID: <3FFD0A89.5040101@statistik.uni-dortmund.de>

Adrian Dusa wrote:

> Hi all,
> 
>  
> 
> Is it possible to draw line segments in a 3d space plot?
> 
> I'm interested to draw the errors from an observed value to the
> regression plane, for a textbook example in an Intro Stats handbook for
> multiple regression.
> 
> I used the scatterplot3d package to draw the regression plane.


An example on how to draw segments for residuals on a regression plane 
with scatterplot3d is shown in Section 4.2.2 (pp. 20-22) of

Ligges, U. and M?chler, M. (2002): Scatterplot3d - an R Package for 
Visualizing Multivariate Data. Technical Report 22/2002. SFB 475, 
Department of Statistics, University of Dortmund, Germany.
http://www.statistik.uni-dortmund.de/sfb475/berichte/tr22-02.pdf

Uwe Ligges





>  
> 
> Many thanks,
> 
> Adrian
> 
>  
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Adrian Dusa (adi at roda.ro)
> Romanian Social Data Archive (www.roda.ro)
> 1, Schitu Magureanu Bd.
> 76625 Bucharest sector 5
> Romania
> 
> 
> Tel./Fax:
> 
> +40 (21) 312.66.18\
> 
> +40 (21) 312.02.10/ int.101
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From mkondrin at hppi.troitsk.ru  Thu Jan  8 20:49:57 2004
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Thu, 08 Jan 2004 11:49:57 -0800
Subject: [R] length of tick marks in grid.xaxis and grid.yaxis
In-Reply-To: <3FFBA79F.5050807@pasteur.mg>
References: <3FFBA79F.5050807@pasteur.mg>
Message-ID: <3FFDB465.5090405@hppi.troitsk.ru>

Renaud Lancelot wrote:

> Dear all,
>
> How can I control the length of tick marks in grid.xaxis and 
> grid.yaxis (package grid) ?
>
> Best regards,
>
> Renaud
>
in grid tick marks are always drawn with length unit(1,"char") So the 
possible way to change tick length is set gp parameter of viewport, 
where the axis is drawn, like this viewport(...,gp=gpar(fontsize=24)) 
for larger ticks ot fontsize=6 for smaller (although it will of course 
change the size of all text annotations on this viweport, so the special 
care should be taken to override default gp in all text annotations).



From wgbeldman at student.han.nl  Thu Jan  8 10:22:02 2004
From: wgbeldman at student.han.nl (W. Beldman)
Date: Thu,  8 Jan 2004 10:22:02 +0100
Subject: [R] (no subject)
Message-ID: <1073553722.3ffd213add497@webmail.han.nl>

Recently I tried to install a package in R version 1.8.1 for Windows. First I 
un".tar.gz"ed it and ".zip"ed it back in to be able to use the option Install 
package(s) from local zip files...

Unfortunately tis error message appeared:
Error in unpackPkg(pkgs[i], pkgnames[i], lib, installWithVers) : 
         Malformed bundle DESCRIPTION file, no Contains field


It's correct that the DESCRIPTION file does not have a Contains field, but I 
can't figure out why it's mandatory and what values it may contain. The manual 
Writing R Extensions doesn't even mention this field in paragraph 1.1.1

Any clues how I can make this package running? 
Note that it's not CRAN but self written, but as I'm told it have worked before 
(probably in a Linux environment).

W. Beldman



From gb at stat.umu.se  Thu Jan  8 10:21:50 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 8 Jan 2004 10:21:50 +0100
Subject: [R] [R-pkgs] New version of eha
Message-ID: <20040108092150.GA1179@stat.umu.se>

A new version of 'eha' (0.92-1) is now on CRAN. From the ChangeLog:

0.92-1 (January 7, 2004)
	
	* mlreg: Geometric distribution (i.e., constant baseline discrete
	hazard) added. Not for frailty models, yet (on the TODO list).

	* mlreg: New argument, 'n.points', added to 'control'. Controls
	the number of points used in the Gauss-Hermite quadrature.

	* mlreg: Stricter control of numerical problems, especially in the
	frailty fit.
	
	* clean: Replaced by the new functions check.spells and join.spells.

	* Return values changed to conform with R-1.8.0 (and later).
-------------------------
As usual, comments and bug reports are welcome!

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From Roger.Bivand at nhh.no  Thu Jan  8 10:48:39 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 8 Jan 2004 10:48:39 +0100 (CET)
Subject: [R] (no subject)
In-Reply-To: <1073553722.3ffd213add497@webmail.han.nl>
Message-ID: <Pine.LNX.4.44.0401081031540.5140-100000@reclus.nhh.no>

On Thu, 8 Jan 2004, W. Beldman wrote:

> Recently I tried to install a package in R version 1.8.1 for Windows. First I 
> un".tar.gz"ed it and ".zip"ed it back in to be able to use the option Install 
> package(s) from local zip files...
> 
> Unfortunately tis error message appeared:
> Error in unpackPkg(pkgs[i], pkgnames[i], lib, installWithVers) : 
>          Malformed bundle DESCRIPTION file, no Contains field
> 
> 
> It's correct that the DESCRIPTION file does not have a Contains field,
> but I can't figure out why it's mandatory and what values it may
> contain. The manual Writing R Extensions doesn't even mention this field
> in paragraph 1.1.1
> 
> Any clues how I can make this package running?  Note that it's not CRAN
> but self written, but as I'm told it have worked before (probably in a
> Linux environment).

You have taken a *source* package, changed it from a tar.gz archive file
to a zip archive file, but are trying to install it as a Windows 
zip archive of a *binary* package. See the R Windows FAQ:

http://cran.r-project.org/bin/windows/rw-FAQ.html#Packages 

or Help > FAQ on R for Windows

within R on Windows

To proceed, you can install the tools needed to make and install a binary
package from a source package under Windows. This is documented with links 
in the FAQ under "Can I install packages (libraries) in this version?" The 
important file "readme.packages" is in the directory R lives in, 
usually rw1081 for the current version.

Roger


> 
> W. Beldman
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From ripley at stats.ox.ac.uk  Thu Jan  8 10:55:34 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 Jan 2004 09:55:34 +0000 (GMT)
Subject: [R] (no subject)
In-Reply-To: <1073553722.3ffd213add497@webmail.han.nl>
Message-ID: <Pine.LNX.4.44.0401080952330.10299-100000@gannet.stats>

On Thu, 8 Jan 2004, W. Beldman wrote:

> Recently I tried to install a package in R version 1.8.1 for Windows. First I 
> un".tar.gz"ed it and ".zip"ed it back in to be able to use the option Install 
> package(s) from local zip files...

So it was not a binary package, but a source package?  No wonder it
failed.  Please let us know from which document you got the idea that your
procedure would produce a valid package, so we can correct it.

> Unfortunately tis error message appeared:
> Error in unpackPkg(pkgs[i], pkgnames[i], lib, installWithVers) : 
>          Malformed bundle DESCRIPTION file, no Contains field

Note `Bundle' here.  Your file format is completely wrong.

> It's correct that the DESCRIPTION file does not have a Contains field, but I 
> can't figure out why it's mandatory and what values it may contain. The manual 
> Writing R Extensions doesn't even mention this field in paragraph 1.1.1
> 
> Any clues how I can make this package running? 
> Note that it's not CRAN but self written, but as I'm told it have worked before 
> (probably in a Linux environment).

You have to INSTALL source packages even on Windows: it is all explained 
in the rw-FAQ.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From merser at tiscali.dk  Thu Jan  8 11:47:05 2004
From: merser at tiscali.dk (merser@tiscali.dk)
Date: Thu, 8 Jan 2004 11:47:05 +0100
Subject: [R] multiple plot
Message-ID: <3F7956600000B59E@cpfe2.be.tisc.dk>

hi there
i've got this litle strange problem working with multiple plots i one screen
the title dissapears when more than 4 images comes up
up to 4 plots the title it shows nicely

the display is set up like:

split.screen(figs=c(3,4), erase=TRUE)

some plots

close.screen(all=T)

title(main='TITLE 1')

what am i doing wrong here

regards soren



From s-plus at wiwi.uni-bielefeld.de  Thu Jan  8 12:00:27 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Thu, 08 Jan 2004 12:00:27 +0100
Subject: [R] 3-dimensional looping Q.
References: <002101c3d573$920ebaa0$3e8be344@br.no.cox.net>
	<3FFD091A.5020002@statistik.uni-dortmund.de>
Message-ID: <3FFD384B.4040806@wiwi.uni-bielefeld.de>

You can compute cor by hand without loops but the code is not much 
faster (dim(slp)[1]==3):

<<*>>=
set.seed(13)
n<-3
y<-1:n
slp<-array(rnorm(n*73*144),c(3,73,144))
n.1<-length(y)-1

print(system.time({
rData <- array(0,c(73,144))   # array to store results
   for (i in 1:73) {
        for (j in 1:144) {
              rData[i,j] <- cor(slp[,i,j],y)
        }
    }
}))

print(system.time({
n.1<-length(y)-1
mean.slp<-apply(slp,c(2,3),mean)
mean.y<-mean(y); sy<-var(y)^0.5
sqslp<-apply(slp*slp,c(2,3),sum)/n.1-mean.slp^2*n/n.1
sslpy<-apply(slp*y,c(2,3),sum)/n.1-mean.slp*mean.y*n/n.1
rslpy<-sslpy/(sqslp^0.5*sy)
}))

print(all(round(100*rslpy)==round(100*rData)))

@
output-start
[1] 1.49 0.00 1.49 0.00 0.00
[1] 0.92 0.00 0.92 0.00 0.00
[1] TRUE
output-end

Peter Wolf


Uwe Ligges wrote:

> Maurice McHugh wrote:
>
>> Hello everyone-
>>
>> I have a 3-d array with the 1st dimension being monthly mean data that
>> I would like to correlate with some time series index, for example, 
>> and save the coefficients in an array.
>>
>> The code I am currently running is....
>>
>>
>>    rData <- array(0,c(73,144))   # array to store results
>>    for (i in 1:73) {
>>         for (j in 1:144) {
>>               rData[i,j] <- cor(slp[,i,j],y)
>>         }
>>     }
>>
>>     Rather than running this analysis embedded with two outer loops, 
>> are =
>>     there any more efficient ways of doing this?
>>     Many thanks!
>
>
>
> Don't know whether it's more efficient:
> You can try to apply() the function rcorr() in package "Hmisc" to your 
> problem...
>
> Uwe Ligges
>
>
>
>
>>    
>> Maurice
>>
>> Maurice McHugh
>> Department of Geography and Anthropology
>> Louisiana State University
>> Baton Rouge, LA
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From rksh at soc.soton.ac.uk  Thu Jan  8 12:32:01 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Thu, 8 Jan 2004 11:32:01 +0000
Subject: [R] gamma() function for complex arguments
Message-ID: <a0600200dbc22ee729159@[139.166.242.29]>

Hello everyone

before I reinvent the wheel, has anyone out there coded up the gamma() function
for complex arguments?




-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From so13839 at alltel.net  Thu Jan  8 13:52:14 2004
From: so13839 at alltel.net (Stephen Opiyo)
Date: Thu, 08 Jan 2004 06:52:14 -0600
Subject: [R] Help with acf
Message-ID: <3FFD527E.3040907@alltel.net>

I would like to get the result of acf min of lag 2 and max of lag 50. 
 When I use time series  ( acf,  lag.max = 50, type="covariance"),  I 
got lag 0 to lag 50.  How do I get lag 2 to lag 50?

Sincerely,

Stephen



From ripley at stats.ox.ac.uk  Thu Jan  8 14:00:23 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 Jan 2004 13:00:23 +0000 (GMT)
Subject: [R] title after split.screen (was multiple plot)
In-Reply-To: <3F7956600000B59E@cpfe2.be.tisc.dk>
Message-ID: <Pine.LNX.4.44.0401081244310.14421-100000@gannet.stats>

[Please use an less vague subject line.  You are only using one of 
several wasy to get multiple plots, and not what most people mean by the 
term.  Indeed, why are you not using par(mfrow=c(3,4))? ]

I would not expect this to work, and it does not work for me with even 4
screens.  You are asking for title to write in the top margin of an
existing plot, and there is none.

Try

par(new=T); plot.new(); title(main='TITLE 1')

to ensure that you have a plotting surface set up for title to plot into.

Or, probably better, set up an outer margin and put the title there:

par(oma=c(0,0,2,0))
split.screen(figs=c(3,4))
for(i in 1:12) {screen(i); plot(1:10)}
close.screen(all=T)
title(main='TITLE 1', outer=T)

On Thu, 8 Jan 2004 merser at tiscali.dk wrote:

> hi there
> i've got this litle strange problem working with multiple plots i one screen
> the title dissapears when more than 4 images comes up
> up to 4 plots the title it shows nicely
> 
> the display is set up like:
> 
> split.screen(figs=c(3,4), erase=TRUE)
> 
> some plots
> 
> close.screen(all=T)
> 
> title(main='TITLE 1')
> 
> what am i doing wrong here
> 
> regards soren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Jan  8 14:06:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 Jan 2004 13:06:12 +0000 (GMT)
Subject: [R] Help with acf
In-Reply-To: <3FFD527E.3040907@alltel.net>
Message-ID: <Pine.LNX.4.44.0401081300380.14421-100000@gannet.stats>

On Thu, 8 Jan 2004, Stephen Opiyo wrote:

> I would like to get the result of acf min of lag 2 and max of lag 50. 
>  When I use time series  ( acf,  lag.max = 50, type="covariance"),  I 
> got lag 0 to lag 50.  How do I get lag 2 to lag 50?

Subset the answer in the standard way, as in:

data(Nile)
acf(Nile, lag.max = 50, type="covariance", plot=F)$acf[3:51,,]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sb at ihe.se  Thu Jan  8 14:01:54 2004
From: sb at ihe.se (Sixten Borg)
Date: Thu, 08 Jan 2004 14:01:54 +0100
Subject: [R] (no subject)
Message-ID: <sffd62e0.031@gwmail.ihe.se>


Hello,

I have trouble converting a character string to a R object. Let me describe this by an example;

> dim(a)
[1] 270  14
> dim("a")
NULL

> names(a)
 [1] "Var1"  "Var2"  "Var3"  "Var4"  "Var5"  "Var6"  "Var7"  "Var8"  "Var9" 
[10] "Var10" "Var11" "Var12" "Var13" "Var14"
> names("a")
NULL

I realise that the character string lacks both a dimension and any column names; my question is how to make R understand that I look for the object a when I write "a".

Like a type cast in C;      (R data.frame) "a"      for those familiar with C.

The underlying reason for this is that I am writing a script that imports several datasets. The file names of the datasets contain the '_' character which forces me to construct a valid dataset name for each file. Although I can do this by hand, I would like to know if there is any solution to my first approach.

Thanks in advance,
Sixten


Sixten Borg

IHE
Box 2127
S-220 02 Lund
Sweden

tel: +46 46 32 91 07
fax:+46 46 12 16 04

www.ihe.se
*******************************************************************
Note: The information contained in this message and attachments may be privileged
and confidential and protected from disclosure. If the reader of this message is not 
the intended recipient you are hereby notified that any dissemination, distribution
or copying of this communication is strictly prohibited. If you have received this 
communication in error, please notify us immediately by replying to the message 
and deleting it from your computer. Thank you. IHE



From andy_liaw at merck.com  Thu Jan  8 14:22:10 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 8 Jan 2004 08:22:10 -0500
Subject: [R] (no subject)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF75CC@usrymx25.merck.com>

Seems like get() is what you are looking for; e.g., try dim(get("a")),
names(get("a")), etc.

HTH,
Andy

> From: Sixten Borg
> 
> Hello,
> 
> I have trouble converting a character string to a R object. 
> Let me describe this by an example;
> 
> > dim(a)
> [1] 270  14
> > dim("a")
> NULL
> 
> > names(a)
>  [1] "Var1"  "Var2"  "Var3"  "Var4"  "Var5"  "Var6"  "Var7"  
> "Var8"  "Var9" 
> [10] "Var10" "Var11" "Var12" "Var13" "Var14"
> > names("a")
> NULL
> 
> I realise that the character string lacks both a dimension 
> and any column names; my question is how to make R understand 
> that I look for the object a when I write "a".
> 
> Like a type cast in C;      (R data.frame) "a"      for those 
> familiar with C.
> 
> The underlying reason for this is that I am writing a script 
> that imports several datasets. The file names of the datasets 
> contain the '_' character which forces me to construct a 
> valid dataset name for each file. Although I can do this by 
> hand, I would like to know if there is any solution to my 
> first approach.
> 
> Thanks in advance,
> Sixten
> 
> 
> Sixten Borg
> 
> IHE
> Box 2127
> S-220 02 Lund
> Sweden
> 
> tel: +46 46 32 91 07
> fax:+46 46 12 16 04
> 
www.ihe.se


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From karlknoblich at yahoo.de  Thu Jan  8 14:29:41 2004
From: karlknoblich at yahoo.de (=?iso-8859-1?q?Karl=20Knoblick?=)
Date: Thu, 8 Jan 2004 14:29:41 +0100 (CET)
Subject: [R] plot in win.metafile in nlme
Message-ID: <20040108132941.32853.qmail@web10002.mail.yahoo.com>

Hallo!

I want to plot grouped data in a wmf-file. The
following example gives an error:

library(lattice)
library(nlme)
data(Loblolly) # example data from nlme
win.metafile("Loblolly.wmf")
plot(Loblolly)
dev.off()
 
After the plot(Loblolly) the following error occurs:
"Error in get(x, envir, mode, inherits) : variable
"win.metafile:Loblolly.wmf" was not found"
The file Loblolly.wmf exists but is just white.

With "normal" plot it works, e.g.:
win.metafile("Loblolly2.wmf")
plot(Loblolly$age, Loblolly$height)
dev.off()

Does anybody know how to solve the problem above or a
nice workaround?
(Using plotSave works in general but the colors are
bad.)

Karl



From ripley at stats.ox.ac.uk  Thu Jan  8 14:31:40 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 Jan 2004 13:31:40 +0000 (GMT)
Subject: [R] converting a character string to a R object
In-Reply-To: <sffd62e0.031@gwmail.ihe.se>
Message-ID: <Pine.LNX.4.44.0401081326290.14484-100000@gannet.stats>

Please do use a meaningful subject line.

You are looking for get(): get("a") returns the R object named "a" (if one 
is in scope).

Note that if you use R-devel (the development version of R, see the FAQ) 
you _can_ use underscore in object names.

On Thu, 8 Jan 2004, Sixten Borg wrote:

> I have trouble converting a character string to a R object. Let me
> describe this by an example;
> 
> > dim(a)
> [1] 270  14
> > dim("a")
> NULL
> 
> > names(a)
>  [1] "Var1"  "Var2"  "Var3"  "Var4"  "Var5"  "Var6"  "Var7"  "Var8"  "Var9" 
> [10] "Var10" "Var11" "Var12" "Var13" "Var14"
> > names("a")
> NULL
> 
> I realise that the character string lacks both a dimension and any
> column names; my question is how to make R understand that I look for
> the object a when I write "a".
> 
> Like a type cast in C;      (R data.frame) "a"      for those familiar with C.

Rather, more like following a pointer in C.  A cast would be
as.data.frame("a")  or as("a", "data.frame"), which is not what you want.

> The underlying reason for this is that I am writing a script that
> imports several datasets. The file names of the datasets contain the '_'
> character which forces me to construct a valid dataset name for each
> file. Although I can do this by hand, I would like to know if there is
> any solution to my first approach.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From merser at tiscali.dk  Thu Jan  8 14:33:56 2004
From: merser at tiscali.dk (merser@tiscali.dk)
Date: Thu, 8 Jan 2004 14:33:56 +0100
Subject: [R] title after split.screen (was multiple plot)
Message-ID: <3F7956600000B632@cpfe2.be.tisc.dk>

par(oma=c(0,0,2,0)) and title(main='TITLE 1', outer=T)
solved my problem
i'm much obliged
kind regards soren
btw sorry for the vague subject line



From nils.olav.handegard at imr.no  Thu Jan  8 14:29:06 2004
From: nils.olav.handegard at imr.no (Handegard, Nils Olav)
Date: Thu, 8 Jan 2004 14:29:06 +0100 
Subject: [R] Fitting curves with discontinuous derivatives
Message-ID: <3418BE5B6E6DD511991400B0D0D034E4024C0964@hipost.imr.no>

Dear Group Readers,

I have a response variable Y (fish swimming speed) and three explanatory
variables X1 (distance to ship propeller), X2 (distance to fishing gear
wire) and Depth. Y=f(X1) initially looks like a straight line, then an
increase to a higher level at X1=100, and then a decrease after X1=-800.
Y=f(X2) looks similar, but the increase to a higher level at X2=100 is more
abrupt, and the decrease start earlier, around X2=0. I explain this as the
reaction occurs closer and is stronger to X2 as opposed to X1. Most likely
both variables are important. I would like to assess this "importance". 

The idea was to use GAM to resolve the dependence, but since X1 - X2 is
small (i.e. plot(X1,X2) is along a narrow band around X1=X2) this did not
work. I must therefore work with the variables separately.

I would like to try a continuous model defined as:
       { k_1                  , x<a
f(x) = { \sum_i^4 k_{i+1} x^i , a<=x<b
       { k_6                  , x>=b,
with continuity as an additional requirement. 

1. The first problem is that a and b are not given, and the derivatives with
respect to these are not defined. This can be overcome by searching the
definition space using optimise(), as outlined in:
http://maths.newcastle.edu.au/~rking/R/help/01c/3175.html. However,
suggestions for a neater solution are welcomed.

2. How can I specify this model. If the model were lines, I guess something
like
lm(y~bs(1:20, knots=c(5,11), degree=1))
would do, and if the lines were of similar degree, splines could be used.
But is it possible to define splines with different order between the knots,
and continuity as only requirement?

3. The idea is to bootstrap the estimates of a and b to find the start point
of the reaction. However, using this parameterised curve may be a bit ad
hoc. Other suggestions are warmly appreciated. I have also tried nls with a
logistic function:
est <- try(nls(y~cbind(exp((x-beta)*alpha)/
	(1+exp((x-beta)*alpha)) ), start=c(beta=Beta,alpha=Alpha),
      algorithm="plinear",contr=ctrl), silent=T)
but the fit were bad.

Sincerely,
Nils Olav Handegard
PhD Student

Please send any responses directly to me.


lm



From andy_liaw at merck.com  Thu Jan  8 14:40:47 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 8 Jan 2004 08:40:47 -0500
Subject: [R] plot in win.metafile in nlme
Message-ID: <3A822319EB35174CA3714066D590DCD504AF75CD@usrymx25.merck.com>

This seems to be a rather common error:  Use trellis.device(win.metafile,
file="Loblolly.wmf") instead of calling win.metafile() directly.

HTH,
Andy

> From: Karl Knoblick
> 
> Hallo!
> 
> I want to plot grouped data in a wmf-file. The
> following example gives an error:
> 
> library(lattice)
> library(nlme)
> data(Loblolly) # example data from nlme
> win.metafile("Loblolly.wmf")
> plot(Loblolly)
> dev.off()
>  
> After the plot(Loblolly) the following error occurs:
> "Error in get(x, envir, mode, inherits) : variable
> "win.metafile:Loblolly.wmf" was not found"
> The file Loblolly.wmf exists but is just white.
> 
> With "normal" plot it works, e.g.:
> win.metafile("Loblolly2.wmf")
> plot(Loblolly$age, Loblolly$height)
> dev.off()
> 
> Does anybody know how to solve the problem above or a
> nice workaround?
> (Using plotSave works in general but the colors are
> bad.)
> 
> Karl


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ripley at stats.ox.ac.uk  Thu Jan  8 14:57:51 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 Jan 2004 13:57:51 +0000 (GMT)
Subject: [R] plot in win.metafile in nlme
In-Reply-To: <20040108132941.32853.qmail@web10002.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0401081353210.14545-100000@gannet.stats>

What is your version of R, nlme and lattice (and have you run 
update.packages() recently)?

This works correctly for me in the current versions.

On Thu, 8 Jan 2004, Karl Knoblick wrote:

> Hallo!
> 
> I want to plot grouped data in a wmf-file. The
> following example gives an error:
> 
> library(lattice)

Not needed, BTW, as done by nlme.

> library(nlme)
> data(Loblolly) # example data from nlme
> win.metafile("Loblolly.wmf")
> plot(Loblolly)
> dev.off()
>  
> After the plot(Loblolly) the following error occurs:
> "Error in get(x, envir, mode, inherits) : variable
> "win.metafile:Loblolly.wmf" was not found"
> The file Loblolly.wmf exists but is just white.
> 
> With "normal" plot it works, e.g.:
> win.metafile("Loblolly2.wmf")
> plot(Loblolly$age, Loblolly$height)
> dev.off()
> 
> Does anybody know how to solve the problem above or a
> nice workaround?
> (Using plotSave works in general but the colors are
> bad.)
> 
> Karl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bxc at steno.dk  Thu Jan  8 15:50:12 2004
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Thu, 8 Jan 2004 15:50:12 +0100
Subject: [R] Strange parametrization in polr
Message-ID: <267DD1034F2988418DE27613376C8DC502CF9214@exdkba023.novo.dk>

In Venables \& Ripley 3rd edition (p. 231) the proportional odds model
is described as:

logit(p<=k) = zeta_k + eta

but polr apparently thinks there is a minus in front of eta,
as is apprent below.

Is this a bug og a feature I have overlooked?


Here is the naked code for reproduction, below the results.
------------------------------------------------------------------------
---
version
library( MASS )
data( housing )
hnames <- lapply( housing[,-5], levels )
house.plr <- polr( Sat ~ Infl + Type + Cont, data=housing, weights=Freq
)
summary( house.plr )
newdat <- expand.grid( hnames[-1] )[1:5,]
cbind( newdat, predict( house.plr, newdat, type="probs" ) )
# Baseline probs:
diff( c(0,tigol( c(-0.4961,0.6907) ), 1) )
# First level of Infl:
diff( c(0,tigol( c(-0.4961,0.6907) + 0.5663922 ), 1) )
# But the change of sign for eta is needed to reproduce the fitted
values:
# Line 2:
diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 ), 1) )
# Line 5:
diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 + 0.5723552 ), 1) )
------------------------------------------------------------------------
---

Here is the resulting output:
------------------------------------------------------------------------
---
> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    8.1            
year     2003           
month    11             
day      21             
language R              
> library( MASS )
> data( housing )
> hnames <- lapply( housing[,-5], levels )
> house.plr <- polr( Sat ~ Infl + Type + Cont, data=housing,
weights=Freq )
> summary( house.plr )

Re-fitting to get Hessian

Call:
polr(formula = Sat ~ Infl + Type + Cont, data = housing, weights = Freq)

Coefficients:
                   Value Std. Error   t value
InflMedium     0.5663922 0.10465276  5.412109
InflHigh       1.2888137 0.12715609 10.135682
TypeApartment -0.5723552 0.11923800 -4.800107
TypeAtrium    -0.3661908 0.15517331 -2.359882
TypeTerrace   -1.0910073 0.15148595 -7.202036
ContHigh       0.3602803 0.09553577  3.771156

Intercepts:
            Value   Std. Error t value
Low|Medium  -0.4961  0.1248    -3.9740
Medium|High  0.6907  0.1255     5.5049

Residual Deviance: 3479.149 
AIC: 3495.149 
> newdat <- expand.grid( hnames[-1] )[1:5,]
> cbind( newdat, predict( house.plr, newdat, type="probs" ) )
    Infl      Type Cont       Low    Medium      High
1    Low     Tower  Low 0.3784485 0.2876755 0.3338760
2 Medium     Tower  Low 0.2568261 0.2742125 0.4689614
3   High     Tower  Low 0.1436927 0.2110841 0.6452232
4    Low Apartment  Low 0.5190450 0.2605077 0.2204473
5 Medium Apartment  Low 0.3798522 0.2875967 0.3325511
> # Baseline probs:
> diff( c(0,tigol( c(-0.4961,0.6907) ), 1) )
[1] 0.3784576 0.2876650 0.3338774
> # First level of Infl:
> diff( c(0,tigol( c(-0.4961,0.6907) + 0.5663922 ), 1) )
[1] 0.5175658 0.2609593 0.2214749
> # But the change of sign for eta is needed to reproduce the fitted
values:
> # Line 2:
> diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 ), 1) )
[1] 0.2568335 0.2742035 0.4689630
> # Line 5:
> diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 + 0.5723552 ), 1) )
[1] 0.3798613 0.2875862 0.3325525
> 
------------------------------------------------------------------------
-----

----------------------
Bendix Carstensen
Senior Statistician
Steno Diabetes Center
Niels Steensens Vej 2
DK-2820 Gentofte
Denmark
tel: +45 44 43 87 38
mob: +45 30 75 87 38
fax: +45 44 43 07 06
bxc at steno.dk
www.biostat.ku.dk/~bxc



From Gerald.Jean at spgdag.ca  Thu Jan  8 15:52:14 2004
From: Gerald.Jean at spgdag.ca (Gerald.Jean@spgdag.ca)
Date: Thu, 8 Jan 2004 09:52:14 -0500
Subject: [R] Installing R on 64-bit Solaris 2.8 --- follow-up
Message-ID: <OF2A74F467.57A465D1-ON85256E15.004FE019@spgdag.ca>

Hello R-users,

thanks to Brian Ripley and Roger Peng for there prompt replies on
installing R on a Solaris 64-bit machine.  R is now running and seems to be
doing fine.  I realy would like to have access to the manuals so I can
climb most of the learning curve on my own -- I am a long time user of
Splus, hence I am not expecting the learning curve to be too steep.  On the
Sun machine that R is installed neither LaTeX, nor pdfLaTeX nor infomake is
installed, hence the manuals could not be built.  I am not administrator of
the machine and the admin. people are vey reluctant to install the required
freeware, I am looking for a workaround.

I have LaTeX and pdfLaTeX installed on my PC, from which I am accessing the
Sun to run Splus, and soon R I hope.  ESS and Emacs are installed on both
machines.  I routinely produce EPS graphs and LaTeX tables on the Sun and
through Emacs import them on the PC and imbed them in my LaTeX
documentation for stats. projects.  My question: is it possible, without
building R on the PC, to build the manuals on the PC either through
bringing parts of the R tree on the Solaris machine or by downloading parts
of the PC distribution from CRAN.  Any pointers in the direction of
instructions on how to proceed would be very highly appreciated.  By the
way, if that could be useful, I also have Cygwin installed on the PC.

Thank you very much for your support,

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming



From ernesto at ipimar.pt  Thu Jan  8 16:00:12 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu, 08 Jan 2004 15:00:12 +0000
Subject: [R] Using geoR krige.conv
Message-ID: <1073574012.8482.27.camel@gandalf.local>

Hi,

I'm using the function krige.conv from package geoR but I'm getting a
warning that I do not understand:

Warning messages:
1: NaNs produced in: sqrt(variance)
2: NaNs produced in: sqrt(variance)

I'm performimg an ordinary kriging with a log transform (lambda=0).

Does anyone knows where this comes from ?

Thanks and regards

EJ



From tlumley at u.washington.edu  Thu Jan  8 15:56:29 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 8 Jan 2004 06:56:29 -0800 (PST)
Subject: [R] Installing R on 64-bit Solaris 2.8 --- follow-up
In-Reply-To: <OF2A74F467.57A465D1-ON85256E15.004FE019@spgdag.ca>
References: <OF2A74F467.57A465D1-ON85256E15.004FE019@spgdag.ca>
Message-ID: <Pine.A41.4.58.0401080655380.50640@homer08.u.washington.edu>

On Thu, 8 Jan 2004 Gerald.Jean at spgdag.ca wrote:

> Hello R-users,
>
> thanks to Brian Ripley and Roger Peng for there prompt replies on
> installing R on a Solaris 64-bit machine.  R is now running and seems to be
> doing fine.  I realy would like to have access to the manuals so I can
> climb most of the learning curve on my own -- I am a long time user of
> Splus, hence I am not expecting the learning curve to be too steep.  On the
> Sun machine that R is installed neither LaTeX, nor pdfLaTeX nor infomake is
> installed, hence the manuals could not be built.  I am not administrator of
> the machine and the admin. people are vey reluctant to install the required
> freeware, I am looking for a workaround.
>

You can download the PDF manuals from CRAN.

	-thomas



From renaud.lancelot at pasteur.mg  Thu Jan  8 15:58:02 2004
From: renaud.lancelot at pasteur.mg (Renaud Lancelot)
Date: Thu, 08 Jan 2004 17:58:02 +0300
Subject: [R] plot in win.metafile in nlme
In-Reply-To: <20040108132941.32853.qmail@web10002.mail.yahoo.com>
References: <20040108132941.32853.qmail@web10002.mail.yahoo.com>
Message-ID: <3FFD6FFA.6070505@pasteur.mg>

Karl Knoblick a ?crit :

> Hallo!
> 
> I want to plot grouped data in a wmf-file. The
> following example gives an error:
> 
> library(lattice)
> library(nlme)
> data(Loblolly) # example data from nlme
> win.metafile("Loblolly.wmf")
> plot(Loblolly)
> dev.off()
>  
> After the plot(Loblolly) the following error occurs:
> "Error in get(x, envir, mode, inherits) : variable
> "win.metafile:Loblolly.wmf" was not found"
> The file Loblolly.wmf exists but is just white.
> 
> With "normal" plot it works, e.g.:
> win.metafile("Loblolly2.wmf")
> plot(Loblolly$age, Loblolly$height)
> dev.off()
> 
> Does anybody know how to solve the problem above or a
> nice workaround?
> (Using plotSave works in general but the colors are
> bad.)
> 
> Karl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

library(nlme)
data(Loblolly) # example data from nlme
plot(Loblolly)
dev.copy(win.metafile, filename = "Loblolly.wmf")
dev.off()

works fine for me

Best,

Renaud

-- 
Dr Renaud Lancelot
v?t?rinaire ?pid?miologiste
Ambassade de France - SCAC
BP 834 Antannarivo 101
Madagascar

t?l. +261 (0)32 04 824 55 (cell)
      +261 (0)20 22 494 37 (home)



From bob.ohara at helsinki.fi  Thu Jan  8 15:58:57 2004
From: bob.ohara at helsinki.fi (Anon.)
Date: Thu, 08 Jan 2004 16:58:57 +0200
Subject: [R] Using split.screen
Message-ID: <3FFD7031.3010603@helsinki.fi>

I want to draw a figure with several panels of unequal size, so i 
thought I would try using screen().  However, I can't figure out how to 
define the sizes as a matrix.  I've tried this:

split.screen(matrix(c(0,0.5,0,0.5,  0.5,1,0.5,1), byrow=F, ncol=4))

and a couple of variants on it, but get the same error:

Error in par(.split.screens[[cur.screen]]) :
         invalid value specified for graphics parameter "fig".

The help usefully says that they are defined in NDC units, but I don't 
know what an NDC unit is, and there isn't any example.  The code in 
kjetil brinchmann halvorsen's message on R-help on  Mar 31 2003 (do a 
search for "NDC units"!) didn't work either, it gives the same message:

 > split.screen( matrix( c(0, 0.3, 0.5, 1, 0.3, 0.7, 0.5, 1,
+ + 0.7, 1, 0.5, 1, 0, 0.5, 0, 0.5,
+ + 0.5, 1, 0, 0.5), 5, 4, byrow=TRUE))
Error in par(.split.screens[[cur.screen]]) :
         invalid value specified for graphics parameter "fig".

I get the same in R-1.8.1 on Windows, and R-1.5.1 on Linux.
As Kjetil pointed out then, "NDC" is not explained in the help pages, 
and I don't have my copy of MASS with me.

Bob

-- 
Bob O'Hara

Rolf Nevanlinna Institute
P.O. Box 4 (Yliopistonkatu 5)
FIN-00014 University of Helsinki
Finland
Telephone: +358-9-191 23743
Mobile: +358 50 599 0540
Fax:  +358-9-191 22 779
WWW:  http://www.RNI.Helsinki.FI/~boh/



From tlumley at u.washington.edu  Thu Jan  8 16:00:32 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 8 Jan 2004 07:00:32 -0800 (PST)
Subject: [R] Strange parametrization in polr
In-Reply-To: <267DD1034F2988418DE27613376C8DC502CF9214@exdkba023.novo.dk>
References: <267DD1034F2988418DE27613376C8DC502CF9214@exdkba023.novo.dk>
Message-ID: <Pine.A41.4.58.0401080656350.50640@homer08.u.washington.edu>

On Thu, 8 Jan 2004, BXC (Bendix Carstensen) wrote:

> In Venables \& Ripley 3rd edition (p. 231) the proportional odds model
> is described as:
>
> logit(p<=k) = zeta_k + eta
>
> but polr apparently thinks there is a minus in front of eta,
> as is apprent below.
>
> Is this a bug og a feature I have overlooked?

If there is really a bug I would guess that it was in the book rather than
the code. This is not an unusual parametrisation for this model.  It is
the parametrisation that reduces to logistic regression for binary data,
and makes the regression coefficients positive when the association is
positive.

	-thomas

>
> Here is the naked code for reproduction, below the results.
> ------------------------------------------------------------------------
> ---
> version
> library( MASS )
> data( housing )
> hnames <- lapply( housing[,-5], levels )
> house.plr <- polr( Sat ~ Infl + Type + Cont, data=housing, weights=Freq
> )
> summary( house.plr )
> newdat <- expand.grid( hnames[-1] )[1:5,]
> cbind( newdat, predict( house.plr, newdat, type="probs" ) )
> # Baseline probs:
> diff( c(0,tigol( c(-0.4961,0.6907) ), 1) )
> # First level of Infl:
> diff( c(0,tigol( c(-0.4961,0.6907) + 0.5663922 ), 1) )
> # But the change of sign for eta is needed to reproduce the fitted
> values:
> # Line 2:
> diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 ), 1) )
> # Line 5:
> diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 + 0.5723552 ), 1) )
> ------------------------------------------------------------------------
> ---
>
> Here is the resulting output:
> ------------------------------------------------------------------------
> ---
> > version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    8.1
> year     2003
> month    11
> day      21
> language R
> > library( MASS )
> > data( housing )
> > hnames <- lapply( housing[,-5], levels )
> > house.plr <- polr( Sat ~ Infl + Type + Cont, data=housing,
> weights=Freq )
> > summary( house.plr )
>
> Re-fitting to get Hessian
>
> Call:
> polr(formula = Sat ~ Infl + Type + Cont, data = housing, weights = Freq)
>
> Coefficients:
>                    Value Std. Error   t value
> InflMedium     0.5663922 0.10465276  5.412109
> InflHigh       1.2888137 0.12715609 10.135682
> TypeApartment -0.5723552 0.11923800 -4.800107
> TypeAtrium    -0.3661908 0.15517331 -2.359882
> TypeTerrace   -1.0910073 0.15148595 -7.202036
> ContHigh       0.3602803 0.09553577  3.771156
>
> Intercepts:
>             Value   Std. Error t value
> Low|Medium  -0.4961  0.1248    -3.9740
> Medium|High  0.6907  0.1255     5.5049
>
> Residual Deviance: 3479.149
> AIC: 3495.149
> > newdat <- expand.grid( hnames[-1] )[1:5,]
> > cbind( newdat, predict( house.plr, newdat, type="probs" ) )
>     Infl      Type Cont       Low    Medium      High
> 1    Low     Tower  Low 0.3784485 0.2876755 0.3338760
> 2 Medium     Tower  Low 0.2568261 0.2742125 0.4689614
> 3   High     Tower  Low 0.1436927 0.2110841 0.6452232
> 4    Low Apartment  Low 0.5190450 0.2605077 0.2204473
> 5 Medium Apartment  Low 0.3798522 0.2875967 0.3325511
> > # Baseline probs:
> > diff( c(0,tigol( c(-0.4961,0.6907) ), 1) )
> [1] 0.3784576 0.2876650 0.3338774
> > # First level of Infl:
> > diff( c(0,tigol( c(-0.4961,0.6907) + 0.5663922 ), 1) )
> [1] 0.5175658 0.2609593 0.2214749
> > # But the change of sign for eta is needed to reproduce the fitted
> values:
> > # Line 2:
> > diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 ), 1) )
> [1] 0.2568335 0.2742035 0.4689630
> > # Line 5:
> > diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 + 0.5723552 ), 1) )
> [1] 0.3798613 0.2875862 0.3325525
> >
> ------------------------------------------------------------------------
> -----
>
> ----------------------
> Bendix Carstensen
> Senior Statistician
> Steno Diabetes Center
> Niels Steensens Vej 2
> DK-2820 Gentofte
> Denmark
> tel: +45 44 43 87 38
> mob: +45 30 75 87 38
> fax: +45 44 43 07 06
> bxc at steno.dk
> www.biostat.ku.dk/~bxc
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From rpeng at jhsph.edu  Thu Jan  8 16:17:07 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 08 Jan 2004 10:17:07 -0500
Subject: [R] Installing R on 64-bit Solaris 2.8 --- follow-up
In-Reply-To: <OF2A74F467.57A465D1-ON85256E15.004FE019@spgdag.ca>
References: <OF2A74F467.57A465D1-ON85256E15.004FE019@spgdag.ca>
Message-ID: <3FFD7473.7070600@jhsph.edu>

If you just want to look at the manuals, you can download them from the 
CRAN website in PDF format.  Otherwise, you can build R on a Windows 
machine but it's not as straightforward (in my opinion) as on a Unix 
system.  There are detailed instructions included with the sources.

-roger

Gerald.Jean at spgdag.ca wrote:
> Hello R-users,
> 
> thanks to Brian Ripley and Roger Peng for there prompt replies on
> installing R on a Solaris 64-bit machine.  R is now running and seems to be
> doing fine.  I realy would like to have access to the manuals so I can
> climb most of the learning curve on my own -- I am a long time user of
> Splus, hence I am not expecting the learning curve to be too steep.  On the
> Sun machine that R is installed neither LaTeX, nor pdfLaTeX nor infomake is
> installed, hence the manuals could not be built.  I am not administrator of
> the machine and the admin. people are vey reluctant to install the required
> freeware, I am looking for a workaround.
> 
> I have LaTeX and pdfLaTeX installed on my PC, from which I am accessing the
> Sun to run Splus, and soon R I hope.  ESS and Emacs are installed on both
> machines.  I routinely produce EPS graphs and LaTeX tables on the Sun and
> through Emacs import them on the PC and imbed them in my LaTeX
> documentation for stats. projects.  My question: is it possible, without
> building R on the PC, to build the manuals on the PC either through
> bringing parts of the R tree on the Solaris machine or by downloading parts
> of the PC distribution from CRAN.  Any pointers in the direction of
> instructions on how to proceed would be very highly appreciated.  By the
> way, if that could be useful, I also have Cygwin installed on the PC.
> 
> Thank you very much for your support,
> 
> G?rald Jean
> Analyste-conseil (statistiques), Actuariat
> t?lephone            : (418) 835-4900 poste (7639)
> t?lecopieur          : (418) 835-6657
> courrier ?lectronique: gerald.jean at spgdag.ca
> 
> "In God we trust all others must bring data"  W. Edwards Deming
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From paulojus at est.ufpr.br  Wed Jan  7 07:07:45 2004
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Wed, 7 Jan 2004 04:07:45 -0200 (BRST)
Subject: [R] Using geoR krige.conv
In-Reply-To: <1073574012.8482.27.camel@gandalf.local>
References: <1073574012.8482.27.camel@gandalf.local>
Message-ID: <Pine.LNX.4.58L0.0401070407090.9861@est.ufpr.br>

Hi Ernesto

Please send me a reproducible exemple code

P.J.

On Thu, 8 Jan 2004, Ernesto Jardim wrote:

> Hi,
>
> I'm using the function krige.conv from package geoR but I'm getting a
> warning that I do not understand:
>
> Warning messages:
> 1: NaNs produced in: sqrt(variance)
> 2: NaNs produced in: sqrt(variance)
>
> I'm performimg an ordinary kriging with a log transform (lambda=0).
>
> Does anyone knows where this comes from ?
>
> Thanks and regards
>
> EJ
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From ripley at stats.ox.ac.uk  Thu Jan  8 16:23:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 Jan 2004 15:23:12 +0000 (GMT)
Subject: [R] Installing R on 64-bit Solaris 2.8 --- follow-up
In-Reply-To: <OF2A74F467.57A465D1-ON85256E15.004FE019@spgdag.ca>
Message-ID: <Pine.LNX.4.44.0401081519370.14707-100000@gannet.stats>

What OS does the `PC' run?  If Windows, the only differences between the 
manuals built under Windows and under Solaris will be in the reference
manual, and you can get a PDF version of that from 
http://cran.r-project.org/manuals.html (although I doubt if you really 
want it).   PDF versions of all the other manuals are there too.

On Thu, 8 Jan 2004 Gerald.Jean at spgdag.ca wrote:

> Hello R-users,
> 
> thanks to Brian Ripley and Roger Peng for there prompt replies on
> installing R on a Solaris 64-bit machine.  R is now running and seems to be
> doing fine.  I realy would like to have access to the manuals so I can
> climb most of the learning curve on my own -- I am a long time user of
> Splus, hence I am not expecting the learning curve to be too steep.  On the
> Sun machine that R is installed neither LaTeX, nor pdfLaTeX nor infomake is
> installed, hence the manuals could not be built.  I am not administrator of
> the machine and the admin. people are vey reluctant to install the required
> freeware, I am looking for a workaround.
> 
> I have LaTeX and pdfLaTeX installed on my PC, from which I am accessing the
> Sun to run Splus, and soon R I hope.  ESS and Emacs are installed on both
> machines.  I routinely produce EPS graphs and LaTeX tables on the Sun and
> through Emacs import them on the PC and imbed them in my LaTeX
> documentation for stats. projects.  My question: is it possible, without
> building R on the PC, to build the manuals on the PC either through
> bringing parts of the R tree on the Solaris machine or by downloading parts
> of the PC distribution from CRAN.  Any pointers in the direction of
> instructions on how to proceed would be very highly appreciated.  By the
> way, if that could be useful, I also have Cygwin installed on the PC.
> 
> Thank you very much for your support,
> 
> G?rald Jean
> Analyste-conseil (statistiques), Actuariat
> t?lephone            : (418) 835-4900 poste (7639)
> t?lecopieur          : (418) 835-6657
> courrier ?lectronique: gerald.jean at spgdag.ca
> 
> "In God we trust all others must bring data"  W. Edwards Deming
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Jan  8 16:32:07 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 Jan 2004 15:32:07 +0000 (GMT)
Subject: [R] Using split.screen
In-Reply-To: <3FFD7031.3010603@helsinki.fi>
Message-ID: <Pine.LNX.4.44.0401081524220.14707-100000@gannet.stats>

NDC is a coordinate system with (0,0) at the bottom left and (1,1) at the 
top right of the device region.

Take a look at your matrix

> matrix(c(0,0.5,0,0.5,  0.5,1,0.5,1), byrow=F, ncol=4)
     [,1] [,2] [,3] [,4]
[1,]  0.0  0.0  0.5  0.5
[2,]  0.5  0.5  1.0  1.0
      left right bot top

so both your figures are 0 wide and 0 tall.  How about

split.screen(matrix(c(0,0.5,0,0.5,  0.5,1,0.5,1), byrow=T, ncol=4))

If you mess up the layout, you do need to do close.screen(all=TRUE) to 
proceed.


On Thu, 8 Jan 2004, Anon. wrote:

> I want to draw a figure with several panels of unequal size, so i 
> thought I would try using screen().  However, I can't figure out how to 
> define the sizes as a matrix.  I've tried this:
> 
> split.screen(matrix(c(0,0.5,0,0.5,  0.5,1,0.5,1), byrow=F, ncol=4))
> 
> and a couple of variants on it, but get the same error:
> 
> Error in par(.split.screens[[cur.screen]]) :
>          invalid value specified for graphics parameter "fig".
> 
> The help usefully says that they are defined in NDC units, but I don't 
> know what an NDC unit is, and there isn't any example.  The code in 
> kjetil brinchmann halvorsen's message on R-help on  Mar 31 2003 (do a 
> search for "NDC units"!) didn't work either, it gives the same message:
> 
>  > split.screen( matrix( c(0, 0.3, 0.5, 1, 0.3, 0.7, 0.5, 1,
> + + 0.7, 1, 0.5, 1, 0, 0.5, 0, 0.5,
> + + 0.5, 1, 0, 0.5), 5, 4, byrow=TRUE))
> Error in par(.split.screens[[cur.screen]]) :
>          invalid value specified for graphics parameter "fig".
> 
> I get the same in R-1.8.1 on Windows, and R-1.5.1 on Linux.
> As Kjetil pointed out then, "NDC" is not explained in the help pages, 
> and I don't have my copy of MASS with me.
> 
> Bob
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu Jan  8 16:43:58 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Jan 2004 16:43:58 +0100
Subject: [R] Strange parametrization in polr
In-Reply-To: <267DD1034F2988418DE27613376C8DC502CF9214@exdkba023.novo.dk>
References: <267DD1034F2988418DE27613376C8DC502CF9214@exdkba023.novo.dk>
Message-ID: <x2k742h2dd.fsf@biostat.ku.dk>

"BXC (Bendix Carstensen)" <bxc at steno.dk> writes:

> Here is the naked code for reproduction, below the results.

That would be easier to reproduce if you had remembered to define

logit <- function(p)log(p/(1-p))
tigol <- function(x)exp(x)/(1+exp(x)) #inverse logit

first... Also, beware the line-breaking Jabberwock, my friend: The
line with "values:" is syntactically incomplete.

        -p


> ------------------------------------------------------------------------
> ---
> version
> library( MASS )
> data( housing )
> hnames <- lapply( housing[,-5], levels )
> house.plr <- polr( Sat ~ Infl + Type + Cont, data=housing, weights=Freq
> )
> summary( house.plr )
> newdat <- expand.grid( hnames[-1] )[1:5,]
> cbind( newdat, predict( house.plr, newdat, type="probs" ) )
> # Baseline probs:
> diff( c(0,tigol( c(-0.4961,0.6907) ), 1) )
> # First level of Infl:
> diff( c(0,tigol( c(-0.4961,0.6907) + 0.5663922 ), 1) )
> # But the change of sign for eta is needed to reproduce the fitted
> values:
> # Line 2:
> diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 ), 1) )
> # Line 5:
> diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 + 0.5723552 ), 1) )
> ------------------------------------------------------------------------
> ---
> 
> Here is the resulting output:
> ------------------------------------------------------------------------
> ---
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    8.1            
> year     2003           
> month    11             
> day      21             
> language R              
> > library( MASS )
> > data( housing )
> > hnames <- lapply( housing[,-5], levels )
> > house.plr <- polr( Sat ~ Infl + Type + Cont, data=housing,
> weights=Freq )
> > summary( house.plr )
> 
> Re-fitting to get Hessian
> 
> Call:
> polr(formula = Sat ~ Infl + Type + Cont, data = housing, weights = Freq)
> 
> Coefficients:
>                    Value Std. Error   t value
> InflMedium     0.5663922 0.10465276  5.412109
> InflHigh       1.2888137 0.12715609 10.135682
> TypeApartment -0.5723552 0.11923800 -4.800107
> TypeAtrium    -0.3661908 0.15517331 -2.359882
> TypeTerrace   -1.0910073 0.15148595 -7.202036
> ContHigh       0.3602803 0.09553577  3.771156
> 
> Intercepts:
>             Value   Std. Error t value
> Low|Medium  -0.4961  0.1248    -3.9740
> Medium|High  0.6907  0.1255     5.5049
> 
> Residual Deviance: 3479.149 
> AIC: 3495.149 
> > newdat <- expand.grid( hnames[-1] )[1:5,]
> > cbind( newdat, predict( house.plr, newdat, type="probs" ) )
>     Infl      Type Cont       Low    Medium      High
> 1    Low     Tower  Low 0.3784485 0.2876755 0.3338760
> 2 Medium     Tower  Low 0.2568261 0.2742125 0.4689614
> 3   High     Tower  Low 0.1436927 0.2110841 0.6452232
> 4    Low Apartment  Low 0.5190450 0.2605077 0.2204473
> 5 Medium Apartment  Low 0.3798522 0.2875967 0.3325511
> > # Baseline probs:
> > diff( c(0,tigol( c(-0.4961,0.6907) ), 1) )
> [1] 0.3784576 0.2876650 0.3338774
> > # First level of Infl:
> > diff( c(0,tigol( c(-0.4961,0.6907) + 0.5663922 ), 1) )
> [1] 0.5175658 0.2609593 0.2214749
> > # But the change of sign for eta is needed to reproduce the fitted
> values:
> > # Line 2:
> > diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 ), 1) )
> [1] 0.2568335 0.2742035 0.4689630
> > # Line 5:
> > diff( c(0,tigol( c(-0.4961,0.6907) - 0.5663922 + 0.5723552 ), 1) )
> [1] 0.3798613 0.2875862 0.3325525
> > 
> ------------------------------------------------------------------------
> -----
> 
> ----------------------
> Bendix Carstensen
> Senior Statistician
> Steno Diabetes Center
> Niels Steensens Vej 2
> DK-2820 Gentofte
> Denmark
> tel: +45 44 43 87 38
> mob: +45 30 75 87 38
> fax: +45 44 43 07 06
> bxc at steno.dk
> www.biostat.ku.dk/~bxc
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Thu Jan  8 16:45:08 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 Jan 2004 15:45:08 +0000 (GMT)
Subject: [R] Strange parametrization in polr
In-Reply-To: <Pine.A41.4.58.0401080656350.50640@homer08.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0401081532380.14707-100000@gannet.stats>

The problem is not in the book nor the code, but in Mr Carstensen not
looking up the actual reference given in ?polr.

There was a + in early printings of MASS3, and that difference is in the
on-line Errata.  But both the DESCRIPTION file and ?polr are explicitly to
the fourth edition.  As Thomas says, the minus seemed a more natural
parametrization and so we changed to it.

On Thu, 8 Jan 2004, Thomas Lumley wrote:

> On Thu, 8 Jan 2004, BXC (Bendix Carstensen) wrote:
> 
> > In Venables \& Ripley 3rd edition (p. 231) the proportional odds model
> > is described as:
> >
> > logit(p<=k) = zeta_k + eta
> >
> > but polr apparently thinks there is a minus in front of eta,
> > as is apprent below.
> >
> > Is this a bug og a feature I have overlooked?
> 
> If there is really a bug I would guess that it was in the book rather than
> the code. This is not an unusual parametrisation for this model.  It is
> the parametrisation that reduces to logistic regression for binary data,
> and makes the regression coefficients positive when the association is
> positive.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wang at galton.uchicago.edu  Thu Jan  8 17:21:03 2004
From: wang at galton.uchicago.edu (Yong Wang)
Date: Thu, 8 Jan 2004 10:21:03 -0600 (CST)
Subject: [R] how to input incomplete data?
In-Reply-To: <200401081136.i08BG5wN026831@hypatia.math.ethz.ch>
References: <200401081136.i08BG5wN026831@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0401081016120.814@galton.uchicago.edu>

Dear all
the question is:
the data is not same length for each variable(the column length 
unequal), how can R read this data? I tried 
read.table(filename,na.strings),not work.
thanks
best
yong



From Gerald.Jean at spgdag.ca  Thu Jan  8 19:54:15 2004
From: Gerald.Jean at spgdag.ca (Gerald.Jean@spgdag.ca)
Date: Thu, 8 Jan 2004 13:54:15 -0500
Subject: [R] Installing R on 64-bit Solaris 2.8 --- I am up and running
	thanks to all
Message-ID: <OF205C0075.25526172-ON85256E15.0067877D@spgdag.ca>


Thank you to all respondants, quite a few.  To solution for the
documentation was simple.  Looks like I had not done my homework properly,
never crossed my mind to lookup CRAN, I apologize for that.

Thanks again,

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming



From martin_muellner at yahoo.com  Thu Jan  8 20:15:01 2004
From: martin_muellner at yahoo.com (=?iso-8859-1?q?Martin=20M=FCllner?=)
Date: Thu, 8 Jan 2004 20:15:01 +0100 (CET)
Subject: [R] problem
Message-ID: <20040108191501.38144.qmail@web40912.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040108/33571f8c/attachment.pl

From jingwu at stat.purdue.edu  Thu Jan  8 22:03:39 2004
From: jingwu at stat.purdue.edu (Jing Wu)
Date: Thu, 8 Jan 2004 16:03:39 -0500 (EST)
Subject: [R] build R package on winXP
In-Reply-To: <mdtlvvc7pf0kiseibku5e1m772bpk0sk3m@4ax.com>
References: <Pine.LNX.4.44.0401060853390.13014-100000@gannet.stats>
	<Pine.A41.4.58.0401061106420.109182@odds.stat.purdue.edu>
	<mdtlvvc7pf0kiseibku5e1m772bpk0sk3m@4ax.com>
Message-ID: <Pine.A41.4.58.0401081600580.76532@odds.stat.purdue.edu>

Dear all,

I finally figured out what went wrong with the path. I was compiling under
C:\Program Files...> which had a space and the space ruined the building.
Thanks a lot for your help.

Jing

On Tue, 6 Jan 2004, Duncan Murdoch wrote:

> On Tue, 6 Jan 2004 11:18:02 -0500 (EST), Jing Wu
> <jingwu at stat.purdue.edu> wrote :
> > I think the Path
> >"Program Files" should be substitute with "PROGRA~1" but what I should use
> >for "Documents and Settings"? Thanks a lot for your help.
>
> This works in XP:
>
> Open a command window (Start | Run | cmd), then do "dir c:\ /x", and
> you see it displayed.  It's probably  DOCUME~1, but not necessarily.
>
> Duncan Murdoch
>



From pols1oh at bestweb.net  Thu Jan  8 22:23:08 2004
From: pols1oh at bestweb.net (michaell taylor)
Date: 08 Jan 2004 16:23:08 -0500
Subject: [R] Sweave & xtable
Message-ID: <1073596988.3421.33.camel@xeon>


I am just starting to learn Sweave (really neat tool).  I am pretty
early in the learning curve (I had to think a moment ago whether a # or
% was the appropriate comment character).

I have successfully incorporated simple graphics and outputs, but am
having trouble getting a latex (xtable) table to function properly. 
Latex is seemingly treating the xtable code as input or verbatim text. 
That is, if I run Sweave('myfile.Snw', echo=T) I get the latex syntax
xtable code handed to me twice in the myfile.dvi.  Turning echo off, I
get the xtable code (not the nicely formated latex table) back in the
dvi.

There seems nothing wrong with the myfile.tex file itself.  (I attach a
snip below).  Everything run fine if I manually edit the myfile.tex file
and delete the :

\begin{Schunk}
\begin{Soutput} 

and,

\end{Soutput}
\end{Schunk}

commands.  Dropping these, I get the properly formated latex table in
the dvi.  

I see that others have used xtable, so I assume Sweave.sty handle xtable
ok.

What am I missing?

code and output chunks follow....

===snip=====
n<- xtable(final[,1:3])
@
\begin{tiny}
<< trial>>=
print(n)
@
\end{tiny}
\end{document}
===snip===

which produces

===snip===

\begin{tiny}
\begin{Schunk}
\begin{Soutput}
% latex table generated in R 1.8.1 by xtable 1.2-2 package
% Thu Jan  8 16:03:23 2004
\begin{table}[ht]
\begin{center}
\begin{tabular}{rrrr}
\hline
 & shares & invested.sums & weighted.price \\
\hline
JBLU & 5.78 & 260.00 & 44.68 \\
IYR & 25.12 & 2395.00 & 94.48 \\
WM & 41.09 & 1565.00 & 38.00 \\
SPY & 37.27 & 3840.00 & 102.84 \\
IBM & 25.24 & 2130.00 & 83.45 \\
EWM & 177.20 & 1059.00 & 5.88 \\
KO & 25.61 & 1130.00 & 43.44 \\
EWJ & 230.00 & 1924.00 & 8.32 \\
DIA & 48.36 & 4295.00 & 89.06 \\
EWH & 123.16 & 1095.00 & 8.79 \\
QQQ & 98.12 & 2991.00 & 31.22 \\
IWZ & 78.03 & 2475.00 & 31.70 \\
IVE & 47.44 & 2158.00 & 45.36 \\
EWW & 73.39 & 1079.00 & 14.50 \\
IBB & 24.28 & 1390.00 & 58.28 \\
EWG & 67.07 & 879.00 & 12.93 \\
C & 62.81 & 2015.00 & 33.17 \\
TYC & 80.61 & 1325.00 & 16.80 \\
RHAT & 223.92 & 1425.00 & 6.89 \\
\hline
\end{tabular}
\end{center}
\end{table}
\end{Soutput}
\end{Schunk}
\end{tiny}
===snip===

Michaell



From tura at centroin.com.br  Thu Jan  8 23:04:05 2004
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Thu, 08 Jan 2004 20:04:05 -0200
Subject: [R] Fit non-linear regressor
In-Reply-To: <87llol4xih.fsf@linum.cofc.edu>
References: <87llol4xih.fsf@linum.cofc.edu>
Message-ID: <6.0.1.1.2.20040108200315.02c64150@pop.centroin.com.br>




Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil 

From tlumley at u.washington.edu  Thu Jan  8 23:53:05 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 8 Jan 2004 14:53:05 -0800 (PST)
Subject: [R] Sweave & xtable
In-Reply-To: <1073596988.3421.33.camel@xeon>
References: <1073596988.3421.33.camel@xeon>
Message-ID: <Pine.A41.4.58.0401081450570.67800@homer35.u.washington.edu>

On Thu, 8 Jan 2004, michaell taylor wrote:
> I have successfully incorporated simple graphics and outputs, but am
> having trouble getting a latex (xtable) table to function properly.
> Latex is seemingly treating the xtable code as input or verbatim text.
> That is, if I run Sweave('myfile.Snw', echo=T) I get the latex syntax
> xtable code handed to me twice in the myfile.dvi.  Turning echo off, I
> get the xtable code (not the nicely formated latex table) back in the
> dvi.
>

A quick look through some of my Sweave files produced the snippet
------
The \code{xtable} package produces HTML and \LaTeX\ formatted tables
<<echo=false,fig=false,results=tex>>=
library(xtable)
data(tli)
tli.table <- xtable(tli[1:10,])
digits(tli.table)[c(2,6)] <- 0
print(tli.table)
@
-------
so it looks like results=tex is what you want.

	-thomas



From tplate at acm.org  Thu Jan  8 23:55:02 2004
From: tplate at acm.org (Tony Plate)
Date: Thu, 08 Jan 2004 15:55:02 -0700
Subject: [R] Fit non-linear regressor
In-Reply-To: <6.0.1.1.2.20040108200315.02c64150@pop.centroin.com.br>
References: <87llol4xih.fsf@linum.cofc.edu>
 <87llol4xih.fsf@linum.cofc.edu>
Message-ID: <5.2.1.1.2.20040108155022.043959b8@mailhost.blackmesacapital.com>

Maybe you intended to supply a little more information in the body of your 
message, but without that, the best suggestion I can give with a similar 
degree of effort on my part is:

?nls

At Thursday 08:04 PM 1/8/2004 -0200, Bernardo Rangel Tura wrote:



>Thanks in advance
>
>Bernardo Rangel Tura, MD, MSc
>National Institute of Cardiology Laranjeiras
>Rio de Janeiro Brazil
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Tony Plate   tplate at acm.org



From jfkincaidsu at netscape.net  Fri Jan  9 00:05:30 2004
From: jfkincaidsu at netscape.net (Joel Kincaid)
Date: Thu, 08 Jan 2004 18:05:30 -0500
Subject: [R] Sweave & xtable
In-Reply-To: <1073596988.3421.33.camel@xeon>
References: <1073596988.3421.33.camel@xeon>
Message-ID: <3FFDE23A.2000307@netscape.net>



pols1oh at bestweb.net wrote:

> I am just starting to learn Sweave <snip> 
and
> having trouble getting a latex (xtable) table to function properly. 
> Latex is seemingly treating the xtable code as input or verbatim text. 
The following is what I use for printing a table of a data.frame called
'ImportExport'

<<results=tex>>=
xtable(ImportExport[1:6,1:6],type=tex,caption='First Six Variables')
@

Inserting the "results=tex" in your code should do the trick,

Cheers,



> That is, if I run Sweave('myfile.Snw', echo=T) I get the latex syntax
> xtable code handed to me twice in the myfile.dvi.  Turning echo off, I
> get the xtable code (not the nicely formated latex table) back in the
> dvi.
> 
> There seems nothing wrong with the myfile.tex file itself.  (I attach a
> snip below).  Everything run fine if I manually edit the myfile.tex file
> and delete the :
> 
> \begin{Schunk}
> \begin{Soutput} 
> 
> and,
> 
> \end{Soutput}
> \end{Schunk}
> 
> commands.  Dropping these, I get the properly formated latex table in
> the dvi.  
> 
> I see that others have used xtable, so I assume Sweave.sty handle xtable
> ok.
> 
> What am I missing?
> 
> code and output chunks follow....
> 
> ===snip=====
> n<- xtable(final[,1:3])
> @
> \begin{tiny}
> << trial>>=
> print(n)
> @
> \end{tiny}
> \end{document}
> ===snip===
> 
> which produces
> 
> ===snip===
> 
> \begin{tiny}
> \begin{Schunk}
> \begin{Soutput}
> % latex table generated in R 1.8.1 by xtable 1.2-2 package
> % Thu Jan  8 16:03:23 2004
> \begin{table}[ht]
> \begin{center}
> \begin{tabular}{rrrr}
> \hline
>  & shares & invested.sums & weighted.price \\
> \hline
> JBLU & 5.78 & 260.00 & 44.68 \\
> IYR & 25.12 & 2395.00 & 94.48 \\
> WM & 41.09 & 1565.00 & 38.00 \\
> SPY & 37.27 & 3840.00 & 102.84 \\
> IBM & 25.24 & 2130.00 & 83.45 \\
> EWM & 177.20 & 1059.00 & 5.88 \\
> KO & 25.61 & 1130.00 & 43.44 \\
> EWJ & 230.00 & 1924.00 & 8.32 \\
> DIA & 48.36 & 4295.00 & 89.06 \\
> EWH & 123.16 & 1095.00 & 8.79 \\
> QQQ & 98.12 & 2991.00 & 31.22 \\
> IWZ & 78.03 & 2475.00 & 31.70 \\
> IVE & 47.44 & 2158.00 & 45.36 \\
> EWW & 73.39 & 1079.00 & 14.50 \\
> IBB & 24.28 & 1390.00 & 58.28 \\
> EWG & 67.07 & 879.00 & 12.93 \\
> C & 62.81 & 2015.00 & 33.17 \\
> TYC & 80.61 & 1325.00 & 16.80 \\
> RHAT & 223.92 & 1425.00 & 6.89 \\
> \hline
> \end{tabular}
> \end{center}
> \end{table}
> \end{Soutput}
> \end{Schunk}
> \end{tiny}
> ===snip===
> 
> Michaell
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From tazapa at yahoo.com  Fri Jan  9 01:24:17 2004
From: tazapa at yahoo.com (Ian Garcia)
Date: Thu, 8 Jan 2004 16:24:17 -0800 (PST)
Subject: [R] R and Postgresql (DBI)
Message-ID: <20040109002417.19861.qmail@web60103.mail.yahoo.com>


 Hi,

 I'm running Debian (Sid), Postgres (7.3.4) and
 R (1.8.1).
 
 I get the following error when I tri to use DBI
 
 >library("DBI")
 > p <- dbDriver("PostgreSQL") 
 Error in do.call(as.character(drvName), list(...)) :
        couldn't find function "PostgreSQL"

 Is there any other package I need in order to
 interface between R and Postgres ?

 thanks

 Ian

__________________________________


From edd at debian.org  Fri Jan  9 02:13:04 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 8 Jan 2004 19:13:04 -0600
Subject: [R] R and Postgresql (DBI)
In-Reply-To: <20040109002417.19861.qmail@web60103.mail.yahoo.com>
References: <20040109002417.19861.qmail@web60103.mail.yahoo.com>
Message-ID: <20040109011304.GA8310@sonny.eddelbuettel.com>

On Thu, Jan 08, 2004 at 04:24:17PM -0800, Ian Garcia wrote:
>  I'm running Debian (Sid), Postgres (7.3.4) and
>  R (1.8.1).
>  
>  I get the following error when I tri to use DBI
>  
>  >library("DBI")
>  > p <- dbDriver("PostgreSQL") 
>  Error in do.call(as.character(drvName), list(...)) :
>         couldn't find function "PostgreSQL"
> 
>  Is there any other package I need in order to
>  interface between R and Postgres ?

No, you simply can't do that. 

Long answer: that doesn't even work as the R DBI infrastructure still lacks a 
a Postgres connector package (like the existing one for SQLite, Oracle, ...).

However, the BioConductor project has two packages that provide a parallel
track to DBI -- called Rdbi, confusingly enough -- as well as its connector
package RdbiPgSQL to connect via Rdbi to Postgresql.  You find them at
www.bioconductor.org in source form.

Alternatively, you can use the CRAN RODBC package along with the Postgres
ODBC package -- and a quick
	$ apt-get install r-cran-rodbc odbc-postgresql 
should get them installed for you.  This needs a little bit of configuration
in /etc/odbcinst.ini:

edd at homebud:~/debian> cat /etc/odbcinst.ini
[PostgreSQL]
Description     = PostgreSQL ODBC driver for Linux and Windows
#Driver         = /usr/lib/postgresql/lib/libodbcpsql.so
#Setup          = /usr/lib/odbc/libodbcpsqlS.so
Driver          = /usr/lib/postgresql/lib/psqlodbc.so
Setup           = /usr/lib/odbc/libodbcpsqlS.so
Debug           = 0
CommLog         = 1

as well as a DSN definition, either in /etc/odbc.ini or in $HOME:
edd at homebud:~/debian> cat ~/.odbc.ini
[ODBC Data Sources]
foo = Foo Database
bar = Bar Database
dbd_odbc_test_db

[Foo]
Driver       = /usr/lib/postgresql/lib/psqlodbc.so
Database     = foo
Servername   = localhost
ReadOnly     = 0

[bar]
Driver       = /usr/lib/libmyodbc.so
Database     = bar
Servername   = localhost
ReadOnly     = 0

[dbd_odbc_test_db]
Driver       = /usr/lib/postgresql/lib/psqlodbc.so
Database     = dbd_odbc_test_db
ReadOnly     = 0
Servername   = localhost

[ODBC]
InstallDir = /usr/lib


Let me know in private mail if you need more help.

Hth, Dirk


-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From jg_liao at yahoo.com  Fri Jan  9 04:27:58 2004
From: jg_liao at yahoo.com (Jason Liao)
Date: Thu, 8 Jan 2004 19:27:58 -0800 (PST)
Subject: [R] minimization using Powell's method without derivative
Message-ID: <20040109032758.10068.qmail@web10509.mail.yahoo.com>

Good evening! I have a multi-dimensional minimization problem whose
gradient is pretty hard to code. I tried Nelder and Mead method
implemented in function optim and it does not work well. I also tried
the quasi Newton method in optim using difference as approximate
derivative. It does not work well either. I just went through Numerical
Recipes book. The book discusses another method without derivative
called Powell's method which should work better based on my
understanding. But optim does not have this routine in it. Does anyone
have an R callable implementation for this method? Thank you very much
in advance.

Jason
  

=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone 732-235-5429, fax (732) 235-5464
http://www.geocities.com/jg_liao



From Matthew.Redding at dpi.qld.gov.au  Fri Jan  9 07:01:39 2004
From: Matthew.Redding at dpi.qld.gov.au (Redding, Matthew)
Date: Fri, 9 Jan 2004 16:01:39 +1000
Subject: [R] Letter Spacing
Message-ID: <200401090601.i0961eJJ016012@dpi-gw1.dpi.qld.gov.au>

Hi All, 

I've been trying to make some adjustments to the graphics in a paper I wrote some time ago, for which the comments have been 
returned from the reviewers.

I always use R for publication graphics...I think it does the best job available, for the things I am interested in.

I could not get my graphics in R 181 to look the same as the old ones (completed 8 months ago), 
the text seemed a bit squashed 
together when I copied graphics as meta-files into word.  

I have found that by re-installing version 1.51, the graphics look as nice as the previous ones, with the text nicely spaced.

Is there a "par" parameters that will adjust the letter spacing, so I can use version 181 for this type of job?

Thanks,

Matt R. Redding
Senior Environmental Scientist, Intensive livestock and sheep
Agency for Food and Fibre Sciences
Department of Primary Industries

Telephone 07 4688 1372  Fax 07 4688 1192
Email matthew.redding at dpi.qld.gov.au
Website  http://www.dpi.qld.gov.au/ilsu/  Call Centre 13 25 23 

********************************DISCLAIMER******************...{{dropped}}



From jg_liao at yahoo.com  Fri Jan  9 07:02:20 2004
From: jg_liao at yahoo.com (Jason Liao)
Date: Thu, 8 Jan 2004 22:02:20 -0800 (PST)
Subject: [R] minimization routines in R
Message-ID: <20040109060220.71208.qmail@web10507.mail.yahoo.com>

I spent several hours trying out another function, nlm, which worked
out so much better than optim. The iteration from nlm gives a very
clear picture where the iteration is going while the two algorithms in
optim just wander around. Thought this might be useful to others.

=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone 732-235-5429, fax (732) 235-5464
http://www.geocities.com/jg_liao



From nusbj at hotmail.com  Fri Jan  9 07:41:52 2004
From: nusbj at hotmail.com (Z P)
Date: Fri, 09 Jan 2004 14:41:52 +0800
Subject: [R] numerical derivative
Message-ID: <Sea2-F6sb0ADIt7Nn9u0001d791@hotmail.com>





>Dear all,
>
>I now want to get the numerical derivative of some multivariate function 
>y=f(x_1,...,x_k) at some specific point x_0=(x_10,...,x_k0).
>
>I know deriv() funtion can give the numerical derivative when f is an known 
>fuction. Now the f is an unknown fuction, but I can give many points 
>x_i=(x_1i,...,x_ki) around x_0 and their respective response y_i. I just 
>want some rough estimation of this derivative, so I do not want to do the 
>non-parametric regression. It is better to have an existing function in R 
>to do the job like derive() for the known function f. Thank you.
>
>Regards,
>
>Zhen
>



From petr.pikal at precheza.cz  Fri Jan  9 08:04:06 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 09 Jan 2004 08:04:06 +0100
Subject: [R] locale problem in W98
In-Reply-To: <Pine.LNX.4.44.0401071717320.7184-100000@gannet.stats>
References: <3FFC4862.5035.20A14C5@localhost>
Message-ID: <3FFE6076.30262.185C44@localhost>

Hallo

On 7 Jan 2004 at 17:32, Prof Brian Ripley wrote:

> What happens if you
> 
> 1) source() a file containing those characters.
it was the same

> 2) Use Rterm?
did not try it

> 3) Change the fonts both for the console and for graphics.  Is this
> the same for all fonts?

I tried and now it is ok. It helped to change Courier New to 
Courier and to add CE to some font declaration as Times New 
Roman CE.

BTW I tried help.search("font") and went through Rsite search 
but nothing pointed me to correct solution (Rdevga, Rconsole). 
Adding "For some locale font problems see also Rdevga, 
Rconsole" would be great let say in Hershey font page.

Thank you again for pointing me to right direction.

> 
> It sounds as if at least part of the problem is the character map that
> Rgui is using on your W98 machine.
> 
> BTW, I don't think they are `corrupted', just not treated as being in
> the encoding you intended (which has nothing to do with locales per se
> under Windows).  Rgui does not itself handle encodings, so it accepts
> whatever keycode it gets and prints/plots that code in the current
> font.
> 
> You do know that MicroSoft no longer supports W98?
> 
> On Wed, 7 Jan 2004, Petr Pikal wrote:
> 
> > Dear all
> > 
> > I am using two computers, one with Windows2000 and the other one
> > with W98 both have the same version (precompiled binary) R 1.8.1 and
> > I have experienced a slight problem with text used in plotting on
> > W98 machine.
> > 
> > When I try to write some local characters into R console
> > 
> > ????????? (not sure if it is OK on your computers)
> 
> I strongly suspect they are not: I cannot display ISO-8859-2.
> 
> > in W2000 **everything** is OK but in W98 some of the characters
> > (1,3,4,5) are changed (and the same is when I try to annotate a plot
> > with them). When I copy it from R console to some editor (e.g.
> > Notepad) the characters are again OK and when I copy the characters
> > from editor back to console they are again corrupted.
> > 
> > > Sys.getlocale()
> > [1] "LC_COLLATE=Czech_Czech Republic.1250;LC_CTYPE=Czech_Czech
> > Republic.1250;LC_MONETARY=C;LC_NUMERIC=C;LC_TIME=Czech_Czec h
> > Republic.1250"
> > >
> > 
> > is same on both and I have checked Rprofile and my profile on both
> > computers and it seems to be the same.
> > 
> > I can put Czech characters on finished plots with some other program
> > (GIMP) but I prefer to do all possible annotation in R.
> > 
> > Please, can you give me some hint where to look for possible
> > solution on W98 machine setting.
> > 
> > Thank you 
> > 
> > Petr Pikal
> > petr.pikal at precheza.cz
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self) 1 South
> Parks Road,                     +44 1865 272866 (PA) Oxford OX1 3TG,
> UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ripley at stats.ox.ac.uk  Fri Jan  9 09:26:08 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 Jan 2004 08:26:08 +0000 (GMT)
Subject: [R] locale problem in W98
In-Reply-To: <3FFE6076.30262.185C44@localhost>
Message-ID: <Pine.LNX.4.44.0401090808470.16280-100000@gannet.stats>

On Fri, 9 Jan 2004, Petr Pikal wrote:

> Hallo
> 
> On 7 Jan 2004 at 17:32, Prof Brian Ripley wrote:
> 
> > What happens if you
> > 
> > 1) source() a file containing those characters.
> it was the same
> 
> > 2) Use Rterm?
> did not try it

Please do so: is it so very hard?

> > 3) Change the fonts both for the console and for graphics.  Is this
> > the same for all fonts?
> 
> I tried and now it is ok. It helped to change Courier New to 
> Courier and to add CE to some font declaration as Times New 
> Roman CE.
> 
> BTW I tried help.search("font") and went through Rsite search 
> but nothing pointed me to correct solution (Rdevga, Rconsole). 

It is in the rw-FAQ, Q6.2!  Note your search term did not describe your 
problem, which is with encodings, not just fonts, but the chapter in the 
rw-FAQ

6 The R Console and Fonts
*************************

is a pretty obvious place to look, and the posting guide does ask you to 
check the FAQs before posting.  I don't understand how you read through 
the rw-FAQ and missed this.

> Adding "For some locale font problems see also Rdevga, 
> Rconsole" would be great let say in Hershey font page.

But this has nothing to do with Hershey fonts.  It is entirely and only to
do with the fact that the fonts you selected for normal (not vector)  
graphics and the console lack the encoding you were trying to use on your
obselete version of Windows.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan  9 09:33:13 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 Jan 2004 08:33:13 +0000 (GMT)
Subject: [R] Letter Spacing
In-Reply-To: <200401090601.i0961eJJ016012@dpi-gw1.dpi.qld.gov.au>
Message-ID: <Pine.LNX.4.44.0401090826520.16308-100000@gannet.stats>

We are not aware of any related changes between R 1.5.1 and R 1.8.1, and
no one else has reported a problem.  Text strings in R graphics are
plotted directly in the font specified and not as individual letters, so
there is nothing you can do about letter spacing in R.

I would first cross-check that the same fonts have been used in both 
systems (and that includes exact sizes of fonts), then check that a 
metafile viewer (Windows XP comes with one, for example) shows the 
difference.  I am afraid that most of the problems we have investigated 
with metafiles were traced to bugs in Word.

On Fri, 9 Jan 2004, Redding, Matthew wrote:

> Hi All, 
> 
> I've been trying to make some adjustments to the graphics in a paper I wrote some time ago, for which the comments have been 
> returned from the reviewers.
> 
> I always use R for publication graphics...I think it does the best job available, for the things I am interested in.
> 
> I could not get my graphics in R 181 to look the same as the old ones (completed 8 months ago), 
> the text seemed a bit squashed 
> together when I copied graphics as meta-files into word.  
> 
> I have found that by re-installing version 1.51, the graphics look as nice as the previous ones, with the text nicely spaced.
> 
> Is there a "par" parameters that will adjust the letter spacing, so I can use version 181 for this type of job?
> 
> Thanks,
> 
> Matt R. Redding
> Senior Environmental Scientist, Intensive livestock and sheep
> Agency for Food and Fibre Sciences
> Department of Primary Industries
> 
> Telephone 07 4688 1372  Fax 07 4688 1192
> Email matthew.redding at dpi.qld.gov.au
> Website  http://www.dpi.qld.gov.au/ilsu/  Call Centre 13 25 23 
> 
> ********************************DISCLAIMER******************...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From phgrosjean at sciviews.org  Fri Jan  9 10:12:49 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 9 Jan 2004 10:12:49 +0100
Subject: [R] Wich character coding for source under Windows?
Message-ID: <MABBLJDICACNFOLGIHJOKELDEAAA.phgrosjean@sciviews.org>

I know that R can cope with the different formats regarding carriage return
and/or line feed (the Unix, or Windows, or Mac convention), which is very
nice. However, it is not clear in my mind which character encoding is used:
ASCII, ANSI, other? There is not much differences between ANSI and DOS
encoding for instance, for the first 128 characters. But it is very
different for the rest.
Best,

Philippe Grosjean

.......................................................<?}))><....
 ) ) ) ) )
( ( ( ( (   Prof. Philippe Grosjean
\  ___   )
 \/ECO\ (   Numerical Ecology of Aquatic Systems
 /\___/  )  Mons-Hainaut University, Pentagone
/ ___  /(   8, Av. du Champ de Mars, 7000 Mons, Belgium
 /NUM\/  )
 \___/\ (   phone: + 32.65.37.34.97, fax: + 32.65.37.33.12
       \ )  email: Philippe.Grosjean at umh.ac.be
 ) ) ) ) )  SciViews project coordinator (http://www.sciviews.org)
( ( ( ( (
...................................................................



From ripley at stats.ox.ac.uk  Fri Jan  9 10:55:06 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 Jan 2004 09:55:06 +0000 (GMT)
Subject: [R] Wich character coding for source under Windows?
In-Reply-To: <MABBLJDICACNFOLGIHJOKELDEAAA.phgrosjean@sciviews.org>
Message-ID: <Pine.LNX.4.44.0401090931440.16538-100000@gannet.stats>

Unless you change it, no encoding is used.  That is, characters are just
treated as 8-bit numbers (as they are in all C programs).  Encodings are
only relevant if you want to display a character (or type at a keyboard),
and in general R assumes that you have set your fonts and keyboard to a 
single consistent encoding (which Petr Pikal had not).

You can reencode on input (See ?connections) and on output where there is
an encoding step (see ?postscript).  So if you have Mac files you can
reencode them on read transparently.  What you can't do is to re-encode
text files on output, mainly because there is no way to mark such files 
are encoded.

On Fri, 9 Jan 2004, Philippe Grosjean wrote:

> I know that R can cope with the different formats regarding carriage return
> and/or line feed (the Unix, or Windows, or Mac convention), which is very
> nice. However, it is not clear in my mind which character encoding is used:
> ASCII, ANSI, other? There is not much differences between ANSI and DOS
> encoding for instance, for the first 128 characters. But it is very
> different for the rest.

I don't believe there is a single `DOS' encoding, rather a whole series of 
codepages.  And ASCII is a 7-bit encoding.  There are various wide 
encodings out there too.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From allan at stats.uct.ac.za  Fri Jan  9 11:16:19 2004
From: allan at stats.uct.ac.za (allan clark)
Date: Fri, 09 Jan 2004 12:16:19 +0200
Subject: [R] r: fortran help
Message-ID: <3FFE7F73.512B881D@stats.uct.ac.za>

Hi all


I would like to know if anybody knows of either a good book or web site
that explains one how to use Fortran. I would like to call some of the
Fortran subroutines but before I can do that I first want to learn how
to code in Fortran.

Regards
Allan



From csoares at liacc.up.pt  Fri Jan  9 11:10:03 2004
From: csoares at liacc.up.pt (Carlos Soares)
Date: Fri, 09 Jan 2004 10:10:03 +0000
Subject: [R] apply to multiple arrays simultaneously
Message-ID: <3FFE7DFB.3070002@liacc.up.pt>

Dear R users,
 
Suppose two arrays which partly have the same dimensions. For instance, 
a1 and a2 with dim(a1) is c(3,4,5,6) and dim(a2) is c(3,4,7,8). How can 
I perform an apply on the equivalent part of the dimensions on both 
arrays simultaneously? Something like:
 
  apply(list(a1, a2), c(1,2), function(x,y) {my.function(x,y)})
 
A useful bonus would be, assuming that my.function always returns an 
array withthe same dimensions (e.g., c(2,3,4), that the final result 
would be an array wit
h dimensions c(3,4,2,3,4).
 
With best regards,
Carlos



From vanecekpavel2 at seznam.cz  Fri Jan  9 11:28:24 2004
From: vanecekpavel2 at seznam.cz (=?us-ascii?Q?PaTa=20PaTaS?=)
Date: Fri, 09 Jan 2004 11:28:24 +0100 (CET)
Subject: [R] problems with large data
Message-ID: <211846.583520-8283-1834176697-1073644104@seznam.cz>

Hello,
I exprerienced a problem with large data sets in R: I cannot import these data via procedure "read.table" (insuficient memory) and some other functions end with the same expception. Could you tell me how to handle large data sets in R?

Thank you. Pavel Vanecek
____________________________________________________________
Licitovat nejvyhodnejsi nab?dku je postavene na hlavu! Skoda Fabia nyni se zvyhodnenim az 50.000 Kc!http://ad2.seznam.cz/redir.cgi?instance=68739%26url=http://www.skoda-auto.cz/action/fast



From tobias.verbeke at bivv.be  Fri Jan  9 11:32:03 2004
From: tobias.verbeke at bivv.be (tobias.verbeke@bivv.be)
Date: Fri, 9 Jan 2004 11:32:03 +0100
Subject: Betr.: [R] r: fortran help
In-Reply-To: <3FFE7F73.512B881D@stats.uct.ac.za>
Message-ID: <OF596C755E.DBB0D05E-ONC1256E16.00398712-C1256E16.0039DEC7@BIVV.BE>






> I would like to know if anybody knows of either a good book or web site
> that explains one how to use Fortran. I would like to call some of the
> Fortran subroutines but before I can do that I first want to learn how
> to code in Fortran.
>
There is a wealth of resources in the fortran faq

http://www.faqs.org/faqs/fortran-faq/

(including two freely downloadable f77-books)


HTH,

Tobias



From alessandro.semeria at cramont.it  Fri Jan  9 11:49:46 2004
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Fri, 9 Jan 2004 11:49:46 +0100
Subject: [R] problems with large data
Message-ID: <OF6669D240.6A393893-ONC1256E16.003B2371@tomware.it>


Read the manual distributed with R about import/export data.
However with large data set is preferable the direct use of the function
scan (read.table is built with it).
best regards! ...and good year
A.S.

----------------------------

Alessandro Semeria
Models and Simulations Laboratory
Montecatini Environmental Research Center (Edison Group),
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: alessandro.semeria at cramont.it



From ripley at stats.ox.ac.uk  Fri Jan  9 12:00:20 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 Jan 2004 11:00:20 +0000 (GMT)
Subject: [R] problems with large data
In-Reply-To: <211846.583520-8283-1834176697-1073644104@seznam.cz>
Message-ID: <Pine.LNX.4.44.0401091054510.16703-100000@gannet.stats>

On Fri, 9 Jan 2004, PaTa PaTaS wrote:

> I exprerienced a problem with large data sets in R: I cannot import
> these data via procedure "read.table" (insuficient memory) and some
> other functions end with the same expception. Could you tell me how to
> handle large data sets in R?

We need more details.  Have you followed all the hints in ?read.table and
the Data Import/Export manual?  If you have, then probably your data set
is too large for the memory of your version of R, and the simplest
solution is to get more memory.

To be more helpful we would need full details of the dataset and of the 
commands you used and the environment you are using (OS, how much RAM and 
how much virtual memory at least).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gguigon at pasteur.fr  Fri Jan  9 12:04:30 2004
From: gguigon at pasteur.fr (Ghislaine Guigon)
Date: Fri, 09 Jan 2004 12:04:30 +0100
Subject: [R] pb with install
Message-ID: <5.0.2.1.2.20040109120041.00b56dd8@mail.pasteur.fr>

dear all,

I try to update my Rversion fro 1.7.1 to 1.8.1 on linux. I have a problem 
when I try to install pacakges from Bioconductors with :

source("http://www.bioconductor.org/getBioC.R")
and
        getBioC(relLevel="release")

somme errors append and when I make a library(affy) for example I obtain :

 > library(affy)
Error in setIs("character", "characterORMIAME", where = where) :
         Class "character" is sealed; new superclasses can not be defined, 
except by setClassUnion
Error in setIs("character", "characterORMIAME", where = where) :
         Class "character" is sealed; new superclasses can not be defined, 
except by setClassUnion
Error in getClass(Class, where = topenv(parent.frame())) :
         "MIAME" is not a defined class
Error in library(affy) : .First.lib failed

Is someone still have this problem ?



Ghislaine GUIGON
Biostatisticienne



From phgrosjean at sciviews.org  Fri Jan  9 12:21:43 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 9 Jan 2004 12:21:43 +0100
Subject: [R] Wich character coding for source under Windows?
In-Reply-To: <Pine.LNX.4.44.0401090931440.16538-100000@gannet.stats>
Message-ID: <MABBLJDICACNFOLGIHJOOELFEAAA.phgrosjean@sciviews.org>

OK, now with these infos and some experiment, it appears that the ANSI
encoding is used by default under Windows for source(), sink(), etc...
That is, if I understand correctly:

- source() that uses parse(file= ) is assuming nothing, because it just
reads bytes and the S language uses only characters among the first 128
ones, which are the same in ANSI or DOS encoding.
- sink() is consistent with this behaviour *under RGUI* and uses ANSI, as
does the default encoding for connections() with getOption("encoding) ==
0:255 assumes the same as does sink()

Now, my problem comes with Rterm... as it is a console program that uses DOS
encoding under Windows. So, with Rterm, there is a "translation" of the ANSI
characters sourced from a text file into DOS characters (for instance, those
in a cat(".....") instruction... and the reverse with sink(). Is this
inconsistent behaviour between Rgui and Rterm purposedly decided for some
reasons? Or is it just a consequence of the inconsistence between window
programs (Rgui) and command line programs (Rterm) under Windows?

Anyway, how could I use characters encoded over the 128th position in a
character string with source(), sink(), cat(), etc... and get the same
behaviour between Rgui and Rterm? Also, I suppose I would have problems with
such characters in Unix/Linux and MacOS, which would interpret them
differently?

Best,

Philippe Grosjean

.......................................................<?}))><....
 ) ) ) ) )
( ( ( ( (   Prof. Philippe Grosjean
\  ___   )
 \/ECO\ (   Numerical Ecology of Aquatic Systems
 /\___/  )  Mons-Hainaut University, Pentagone
/ ___  /(   8, Av. du Champ de Mars, 7000 Mons, Belgium
 /NUM\/  )
 \___/\ (   phone: + 32.65.37.34.97, fax: + 32.65.37.33.12
       \ )  email: Philippe.Grosjean at umh.ac.be
 ) ) ) ) )  SciViews project coordinator (http://www.sciviews.org)
( ( ( ( (
...................................................................

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Friday, 09 January, 2004 10:55
To: Philippe Grosjean
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Wich character coding for source under Windows?


Unless you change it, no encoding is used.  That is, characters are just
treated as 8-bit numbers (as they are in all C programs).  Encodings are
only relevant if you want to display a character (or type at a keyboard),
and in general R assumes that you have set your fonts and keyboard to a
single consistent encoding (which Petr Pikal had not).

You can reencode on input (See ?connections) and on output where there is
an encoding step (see ?postscript).  So if you have Mac files you can
reencode them on read transparently.  What you can't do is to re-encode
text files on output, mainly because there is no way to mark such files
are encoded.

On Fri, 9 Jan 2004, Philippe Grosjean wrote:

> I know that R can cope with the different formats regarding carriage
return
> and/or line feed (the Unix, or Windows, or Mac convention), which is very
> nice. However, it is not clear in my mind which character encoding is
used:
> ASCII, ANSI, other? There is not much differences between ANSI and DOS
> encoding for instance, for the first 128 characters. But it is very
> different for the rest.

I don't believe there is a single `DOS' encoding, rather a whole series of
codepages.  And ASCII is a 7-bit encoding.  There are various wide
encodings out there too.

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan  9 12:46:47 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 Jan 2004 11:46:47 +0000 (GMT)
Subject: [R] Wich character coding for source under Windows?
In-Reply-To: <MABBLJDICACNFOLGIHJOOELFEAAA.phgrosjean@sciviews.org>
Message-ID: <Pine.LNX.4.44.0401091138080.16807-100000@gannet.stats>

As I said, Rterm/Rgui do no encoding.  If you use cat or sink, the exact 
numeric char you used is written out.  Maybe if you *display* it you see 
something different, but I have already explained that.

Unless you do octal/hex dumps on files you will be confused by display 
encodings.

On Fri, 9 Jan 2004, Philippe Grosjean wrote:

> OK, now with these infos and some experiment, it appears that the ANSI
> encoding is used by default under Windows for source(), sink(), etc...

No, it is the native encoding.  There is no `ANSI' encoding, but your 
machine is probably set up to use WinANSI (not ANSI).

> That is, if I understand correctly:
> 
> - source() that uses parse(file= ) is assuming nothing, because it just
> reads bytes and the S language uses only characters among the first 128
> ones, which are the same in ANSI or DOS encoding.

Not true: S can use 8-bit characters.

> - sink() is consistent with this behaviour *under RGUI* and uses ANSI, as
> does the default encoding for connections() with getOption("encoding) ==
> 0:255 assumes the same as does sink()
> 
> Now, my problem comes with Rterm... as it is a console program that uses DOS
> encoding under Windows. So, with Rterm, there is a "translation" of the ANSI
> characters sourced from a text file into DOS characters (for instance, those
> in a cat(".....") instruction... and the reverse with sink(). Is this
> inconsistent behaviour between Rgui and Rterm purposedly decided for some
> reasons? Or is it just a consequence of the inconsistence between window
> programs (Rgui) and command line programs (Rterm) under Windows?
> 
> Anyway, how could I use characters encoded over the 128th position in a
> character string with source(), sink(), cat(), etc... and get the same
> behaviour between Rgui and Rterm? Also, I suppose I would have problems with
> such characters in Unix/Linux and MacOS, which would interpret them
> differently?

You *do* get the same behaviour.  If you do example(text) you get the same 
chars in RGui and Rterm, even if 

options(pager="console")
help(text)

displays them differently.  That is nothing to do with Rterm, though.

And if you want to transfer files from Windows to another OS, you have to 
tell R on that OS what encoding you used.  That is all.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From alessandro.semeria at cramont.it  Fri Jan  9 13:12:37 2004
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Fri, 9 Jan 2004 13:12:37 +0100
Subject: [R] pb with install
Message-ID: <OF4A8E6392.F42250D6-ONC1256E16.00423F94@tomware.it>


May be:
Have you correctly updated  R to version 1.8.1 before the Bioconductor's
installation?
....you have to remove, or place in a different place, old bioconductor
libraries and set
LIB var to point to the new ones...

A.S.

----------------------------

Alessandro Semeria
Models and Simulations Laboratory
Montecatini Environmental Research Center (Edison Group),
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: alessandro.semeria at cramont.it



                                                                                                                                            
                      Ghislaine Guigon                                                                                                      
                      <gguigon at pasteur.fr>          To:      r-help at stat.math.ethz.ch                                                       
                      Sent by:                      cc:                                                                                     
                      r-help-bounces at stat.m         Subject: [R] pb with install                                                            
                      ath.ethz.ch                                                                                                           
                                                                                                                                            
                                                                                                                                            
                      09-01-2004 12.04                                                                                                      
                                                                                                                                            
                                                                                                                                            




dear all,

I try to update my Rversion fro 1.7.1 to 1.8.1 on linux. I have a problem
when I try to install pacakges from Bioconductors with :

source("http://www.bioconductor.org/getBioC.R")
and
        getBioC(relLevel="release")

somme errors append and when I make a library(affy) for example I obtain :

 > library(affy)
Error in setIs("character", "characterORMIAME", where = where) :
         Class "character" is sealed; new superclasses can not be defined,
except by setClassUnion
Error in setIs("character", "characterORMIAME", where = where) :
         Class "character" is sealed; new superclasses can not be defined,
except by setClassUnion
Error in getClass(Class, where = topenv(parent.frame())) :
         "MIAME" is not a defined class
Error in library(affy) : .First.lib failed

Is someone still have this problem ?



Ghislaine GUIGON
Biostatisticienne

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From paradis at isem.univ-montp2.fr  Fri Jan  9 13:35:13 2004
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Fri, 09 Jan 2004 13:35:13 +0100
Subject: [R] minimization routines in R
In-Reply-To: <20040109060220.71208.qmail@web10507.mail.yahoo.com>
Message-ID: <4.2.0.58.20040109133142.00b19fd8@isem.isem.univ-montp2.fr>

At 22:02 08/01/2004 -0800, vous avez ?crit:
>I spent several hours trying out another function, nlm, which worked
>out so much better than optim. The iteration from nlm gives a very
>clear picture where the iteration is going while the two algorithms in
>optim just wander around. Thought this might be useful to others.

I confirm this statement from my (limited) experience with likelihood 
estimation: I have used nlm for some time now and tried optim so see if the 
results were similar, but the latter failed in spite of me trying several 
methods. Anyway, nlm is much easier to use than optim.

Emmanuel Paradis


>=====
>Jason G. Liao, Ph.D.
>Division of Biometrics
>University of Medicine and Dentistry of New Jersey
>335 George Street, Suite 2200
>New Brunswick, NJ 08903-2688
>phone 732-235-5429, fax (732) 235-5464
>http://www.geocities.com/jg_liao
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Fri Jan  9 14:39:43 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 9 Jan 2004 08:39:43 -0500
Subject: [R] apply to multiple arrays simultaneously
Message-ID: <3A822319EB35174CA3714066D590DCD504AF75D8@usrymx25.merck.com>

Off the top of my head, seems like you can abind() the two together and then
run apply.  See the abind package on CRAN.

HTH,
Andy

> From: Carlos Soares
> 
> Dear R users,
>  
> Suppose two arrays which partly have the same dimensions. For 
> instance, 
> a1 and a2 with dim(a1) is c(3,4,5,6) and dim(a2) is 
> c(3,4,7,8). How can 
> I perform an apply on the equivalent part of the dimensions on both 
> arrays simultaneously? Something like:
>  
>   apply(list(a1, a2), c(1,2), function(x,y) {my.function(x,y)})
>  
> A useful bonus would be, assuming that my.function always returns an 
> array withthe same dimensions (e.g., c(2,3,4), that the final result 
> would be an array wit
> h dimensions c(3,4,2,3,4).
>  
> With best regards,
> Carlos


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From vanecekpavel2 at seznam.cz  Fri Jan  9 15:08:44 2004
From: vanecekpavel2 at seznam.cz (=?us-ascii?Q?PaTa=20PaTaS?=)
Date: Fri, 09 Jan 2004 15:08:44 +0100 (CET)
Subject: [R] problems with large data II
In-Reply-To: <211846.583520-8283-1834176697-1073644104@seznam.cz>
Message-ID: <235625.618821-18226-391315645-1073657323@seznam.cz>

Thank you all for your help. The problem is not only with reading the data (5000 cases times 2000 integer variables, imported either from SPSS or TXT file) into my R 1.8.0 but also with the procedure I would like to use = "randomForest" from library "randomForest". It is not possible to run it with such a data set (because of the insuficient memory exception). Moreover, my data has factors with more than 32 classes, which causes another error.

Could you suggest any solution for my problem? Thank you a lot. 
____________________________________________________________
Licitovat nejvyhodnejsi nab?dku je postavene na hlavu! Skoda Octavia nyni se zvyhodnenim az 90.000 Kc! http://ad2.seznam.cz/redir.cgi?instance=68740%26url=http://www.skoda-auto.cz/action/fast



From RSimon at nih.gov  Fri Jan  9 15:20:27 2004
From: RSimon at nih.gov (Simon, Richard (NIH/NCI))
Date: Fri, 9 Jan 2004 09:20:27 -0500 
Subject: [R] Raqua edit.data.frame()
Message-ID: <9D7EF737FA4C6F4FBBFC52FC30B83690B10B22@nihexchange7.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040109/d6a87d0a/attachment.pl

From csoares at niaad.liacc.up.pt  Fri Jan  9 15:14:02 2004
From: csoares at niaad.liacc.up.pt (Carlos Soares)
Date: Fri, 09 Jan 2004 14:14:02 +0000
Subject: [R] apply to multiple arrays simultaneously
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF75D8@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF75D8@usrymx25.merck.com>
Message-ID: <3FFEB72A.3070702@laboratorio>

abind only allows one of the dimensions to be different. In may case 
they differ on several dimensions. For instance, in the example I gave 
(which was probably not clear enough), I would like
my.function to be called 3*4 times, each time being passed 2 matrices x 
and y with dim(x)=c(5,6) and dim(y)=c(7,8).

Anyway, thanks for the tip, Andy.
Carlos

Liaw, Andy wrote:

>Off the top of my head, seems like you can abind() the two together and then
>run apply.  See the abind package on CRAN.
>
>HTH,
>Andy
>
>  
>
>>From: Carlos Soares
>>
>>Dear R users,
>> 
>>Suppose two arrays which partly have the same dimensions. For 
>>instance, 
>>a1 and a2 with dim(a1) is c(3,4,5,6) and dim(a2) is 
>>c(3,4,7,8). How can 
>>I perform an apply on the equivalent part of the dimensions on both 
>>arrays simultaneously? Something like:
>> 
>>  apply(list(a1, a2), c(1,2), function(x,y) {my.function(x,y)})
>> 
>>A useful bonus would be, assuming that my.function always returns an 
>>array withthe same dimensions (e.g., c(2,3,4), that the final result 
>>would be an array wit
>>h dimensions c(3,4,2,3,4).
>> 
>>With best regards,
>>Carlos
>>    
>>
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments, contains
>information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New
>Jersey, USA 08889), and/or its affiliates (which may be known outside the
>United States as Merck Frosst, Merck Sharp & Dohme or MSD) that may be
>confidential, proprietary copyrighted and/or legally privileged, and is
>intended solely for the use of the individual or entity named on this message.
>If you are not the intended recipient, and have received this message in
>error, please immediately return this by e-mail and then delete it.
>------------------------------------------------------------------------------
>  
>



From spencer.graves at pdf.com  Fri Jan  9 15:58:56 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 09 Jan 2004 06:58:56 -0800
Subject: [R] problems with large data II
In-Reply-To: <235625.618821-18226-391315645-1073657323@seznam.cz>
References: <235625.618821-18226-391315645-1073657323@seznam.cz>
Message-ID: <3FFEC1B0.30205@pdf.com>

      If you can't get more memory, you could read portions of the file 
using "scan(..., skip = ..., nlines = ...)" and then compress the data 
somehow to reduce the size of the object you pass to "randomForest".  
You could run "scan" like this in a loop each time processing, e.g., 10% 
of the data file. 

      Alternatively, you could pass each portion to "randomForest" and 
compare the results from several calls to "randomForest".  This would 
produce a type of cross validation, which might be a wise thing to do, 
anyway. 

      hope this helps. 
      spencer graves

PaTa PaTaS wrote:

>Thank you all for your help. The problem is not only with reading the data (5000 cases times 2000 integer variables, imported either from SPSS or TXT file) into my R 1.8.0 but also with the procedure I would like to use = "randomForest" from library "randomForest". It is not possible to run it with such a data set (because of the insuficient memory exception). Moreover, my data has factors with more than 32 classes, which causes another error.
>
>Could you suggest any solution for my problem? Thank you a lot. 
>____________________________________________________________
>Licitovat nejvyhodnejsi nab?dku je postavene na hlavu! Skoda Octavia nyni se zvyhodnenim az 90.000 Kc! http://ad2.seznam.cz/redir.cgi?instance=68740%26url=http://www.skoda-auto.cz/action/fast
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From renaud.lancelot at pasteur.mg  Fri Jan  9 16:06:05 2004
From: renaud.lancelot at pasteur.mg (Renaud Lancelot)
Date: Fri, 09 Jan 2004 18:06:05 +0300
Subject: [R] Letter Spacing
In-Reply-To: <200401090601.i0961eJJ016012@dpi-gw1.dpi.qld.gov.au>
References: <200401090601.i0961eJJ016012@dpi-gw1.dpi.qld.gov.au>
Message-ID: <3FFEC35D.1020803@pasteur.mg>

Redding, Matthew a ?crit :

> Hi All, 
> 
> I've been trying to make some adjustments to the graphics in a paper I wrote some time ago, for which the comments have been 
> returned from the reviewers.
> 
> I always use R for publication graphics...I think it does the best job available, for the things I am interested in.
> 
> I could not get my graphics in R 181 to look the same as the old ones (completed 8 months ago), 
> the text seemed a bit squashed 
> together when I copied graphics as meta-files into word.  
> 
> I have found that by re-installing version 1.51, the graphics look as nice as the previous ones, with the text nicely spaced.
> 
> Is there a "par" parameters that will adjust the letter spacing, so I can use version 181 for this type of job?

I am using Word 2000. I have the best results copying the screen output 
to a file using dev.copy(), e.g.

plot(blabla)
dev.copy(win.metafile, "mygraph.wmf")
dev.off()

(and then insert the graphic file into the Word document).

In particular, it gives me neater lines than with the GUI menus, either 
copying/pasting the graph into Word, or saving it to a file.

Best,

Renaud

-- 
Dr Renaud Lancelot
v?t?rinaire ?pid?miologiste
Ambassade de France - SCAC
BP 834 Antannarivo 101
Madagascar

t?l. +261 (0)32 04 824 55 (cell)
      +261 (0)20 22 494 37 (home)



From m at rkstjohn.com  Fri Jan  9 16:12:07 2004
From: m at rkstjohn.com (Mark St.John)
Date: Fri, 9 Jan 2004 07:12:07 -0800 (PST)
Subject: [R] Poisson distribution help requested
Message-ID: <20040109151210.A11B57265@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040109/976e0e31/attachment.pl

From andy_liaw at merck.com  Fri Jan  9 15:53:58 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 9 Jan 2004 09:53:58 -0500
Subject: [R] problems with large data II
Message-ID: <3A822319EB35174CA3714066D590DCD504AF75DD@usrymx25.merck.com>

If you have a large enough machine, you'll be able to run randomForest with
that size data (we have done that regularly).  One thing that many people
don't seem to realize is that the "formula interface" has significant
overhead.  For large data sets, try running randomForest without using the
formula.  Other tips are: If you don't need to predict future data, set
keep.forest to FALSE.  Storing the forest takes lots of memory.  If you
already have the test set data, give it to randomForest along with the
training data, instead of using predict() afterward.  If you have a
classification problem, try using the sampsize option to reduce the number
of cases used to grow each tree.

As to the problem of having categorical predictors with more than 32
categories:  Prof. Breiman's new version can deal with categorical
predictors with (IMHO) obscene number of categories.  However I have chosen
to give that a very low priority for adding to the R package.  The reason is
that, IMHO, such variables need some massaging (collapsing/merging/whatever)
before they will be somewhat meaningful in a model, anyway.  (And personally
I have no need for such feature.)

HTH,
Andy

> From: PaTa PaTaS
> 
> Thank you all for your help. The problem is not only with 
> reading the data (5000 cases times 2000 integer variables, 
> imported either from SPSS or TXT file) into my R 1.8.0 but 
> also with the procedure I would like to use = "randomForest" 
> from library "randomForest". It is not possible to run it 
> with such a data set (because of the insuficient memory 
> exception). Moreover, my data has factors with more than 32 
> classes, which causes another error.
> 
> Could you suggest any solution for my problem? Thank you a lot. 
> ____________________________________________________________
> Licitovat nejvyhodnejsi nab?dku je postavene na hlavu! Skoda 
> Octavia nyni se zvyhodnenim az 90.000 Kc! 
> http://ad2.seznam.cz/redir.cgi?instance=68740%26url=http://www
.skoda-auto.cz/action/fast



From spencer.graves at pdf.com  Fri Jan  9 16:32:09 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 09 Jan 2004 07:32:09 -0800
Subject: [R] Poisson distribution help requested
In-Reply-To: <20040109151210.A11B57265@sitemail.everyone.net>
References: <20040109151210.A11B57265@sitemail.everyone.net>
Message-ID: <3FFEC979.5090309@pdf.com>

 > ppois(0:11, 2)
 [1] 0.1353353 0.4060058 0.6766764 0.8571235 0.9473470 0.9834364 0.9954662
 [8] 0.9989033 0.9997626 0.9999535 0.9999917 0.9999986

This is the cumulative distribution function of the Poisson with mean 2 
at the values 0 - 11. 

hope this helps.  spencer graves

Mark St.John wrote:

>Could somebody help me to understand the syntax of R's ppois function? I'm looking to calculate the cumulative probability density of an observed value (y) given the expected mean (mu) and the level of significance (alpha). I'm coming from using SAS to do this and don't recognize the descriptions of the arguments for ppois. The definitions of lambda and p as stated in the R manuals are foreign to me!
>
>Thanks, Mark
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From commercial at s-boehringer.de  Fri Jan  9 16:46:23 2004
From: commercial at s-boehringer.de (Stefan =?ISO-8859-1?Q?B=F6hringer?=)
Date: 09 Jan 2004 16:46:23 +0100
Subject: [R] ipred and lda
Message-ID: <1073663183.20043.20.camel@hgX>

Dear all,

can anybody help me with the program below? The function predict.lda
seems to be defined but cannot be used by errortest.

The R version is 1.7.1

Thanks in advance,

	Stefan

----------------
library("MASS");
library("ipred");

data(iris3);
tr <- sample(1:50, 25);
train <- rbind(iris3[tr,,1], iris3[tr,,2], iris3[tr,,3]);
test <- rbind(iris3[-tr,,1], iris3[-tr,,2], iris3[-tr,,3]);
cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)));
z <- lda(train, cl);
predict(z, test)$class;

data.frame(class=cl, train);
flowers <- data.frame(class=cl, train);
errorest(class ~ ., data=flowers, model=lda, estimator="cv",
predict=predict.lda);

Error-Message is :
Error: Object "predict.lda" not found



From maechler at stat.math.ethz.ch  Fri Jan  9 17:14:01 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 9 Jan 2004 17:14:01 +0100
Subject: [R] ipred and lda
In-Reply-To: <1073663183.20043.20.camel@hgX>
References: <1073663183.20043.20.camel@hgX>
Message-ID: <16382.54089.470619.685599@gargle.gargle.HOWL>

>>>>> "Stefan" == Stefan B?hringer <commercial at s-boehringer.de>
>>>>>     on 09 Jan 2004 16:46:23 +0100 writes:

    Stefan> Dear all, can anybody help me with the program
    Stefan> below? The function predict.lda seems to be defined
    Stefan> but cannot be used by errortest.

    Stefan> The R version is 1.7.1

  >>   library("MASS");
  >>   library("ipred");
  >> 
  >>   data(iris3);
  >>   tr <- sample(1:50, 25);
  >>   train <- rbind(iris3[tr,,1], iris3[tr,,2], iris3[tr,,3]);
  >>   test <- rbind(iris3[-tr,,1], iris3[-tr,,2], iris3[-tr,,3]);
  >>   cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)));
  >>   z <- lda(train, cl);
  >>   predict(z, test)$class;
  >> 
  >>   data.frame(class=cl, train);
  >>   flowers <- data.frame(class=cl, train);
  >>   errorest(class ~ ., data=flowers, model=lda, estimator="cv",
  >>   predict=predict.lda);

    Stefan> Error-Message is : 
    Stefan> Error: Object "predict.lda" not found

predict.lda is not exported from new versions of MASS
since one should use  predict( <lda-fit> , ...).

i.e., I presume that

errorest(class ~ ., data=flowers, model=lda, estimator="cv", predict=predict)

will work.

BTW: Please, remove the  ";" at the end of lines.
     In S code, they are just plain ugly.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From maechler at stat.math.ethz.ch  Fri Jan  9 17:16:41 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 9 Jan 2004 17:16:41 +0100
Subject: [R] Poisson distribution help requested
In-Reply-To: <3FFEC979.5090309@pdf.com>
References: <20040109151210.A11B57265@sitemail.everyone.net>
	<3FFEC979.5090309@pdf.com>
Message-ID: <16382.54249.584480.471469@gargle.gargle.HOWL>

>>>>> "Spencer" == Spencer Graves <spencer.graves at pdf.com>
>>>>>     on Fri, 09 Jan 2004 07:32:09 -0800 writes:

    >> ppois(0:11, 2)
    Spencer>  [1] 0.1353353 0.4060058 0.6766764 0.8571235
    Spencer> 0.9473470 0.9834364 0.9954662 [8] 0.9989033
    Spencer> 0.9997626 0.9999535 0.9999917 0.9999986

    Spencer> This is the cumulative distribution function of the
    Spencer> Poisson with mean 2 at the values 0 - 11.

    Spencer> hope this helps.  spencer graves

and from Mark's "level of significance (alpha)",
I presume Mark really wants  qpois()  which computes quantiles,
i.e., the *inverse* of ppois().

    Spencer> Mark St.John wrote:

    >> Could somebody help me to understand the syntax of R's
    >> ppois function? I'm looking to calculate the cumulative
    >> probability density of an observed value (y) given the
    >> expected mean (mu) and the level of significance
    >> (alpha). I'm coming from using SAS to do this and don't
    >> recognize the descriptions of the arguments for
    >> ppois. The definitions of lambda and p as stated in the R
    >> manuals are foreign to me!

    >> Thanks, Mark



From ligges at statistik.uni-dortmund.de  Fri Jan  9 17:21:12 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 09 Jan 2004 17:21:12 +0100
Subject: [R] ipred and lda
In-Reply-To: <1073663183.20043.20.camel@hgX>
References: <1073663183.20043.20.camel@hgX>
Message-ID: <3FFED4F8.4090603@statistik.uni-dortmund.de>

Stefan B?hringer wrote:

> Dear all,
> 
> can anybody help me with the program below? The function predict.lda
> seems to be defined but cannot be used by errortest.
> 
> The R version is 1.7.1


R-1.8.1 is recent.

predict.lda() is hidden in a namespace, so you cannot access it that 
way. Please use the generic (predict(), which calls the method) rather 
than calling methods directly.

However, predict.lda() won't work in errorest() (not errortest, BTW) as is.

Use an own function like mypredict.lda() which looks like:
   mypredict.lda <- function(object, newdata)
     predict(object, newdata = newdata)$class
which is given in the examples of ?errorest.

Uwe Ligges





> Thanks in advance,
> 
> 	Stefan
> 
> ----------------
> library("MASS");
> library("ipred");
> 
> data(iris3);
> tr <- sample(1:50, 25);
> train <- rbind(iris3[tr,,1], iris3[tr,,2], iris3[tr,,3]);
> test <- rbind(iris3[-tr,,1], iris3[-tr,,2], iris3[-tr,,3]);
> cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)));
> z <- lda(train, cl);
> predict(z, test)$class;
> 
> data.frame(class=cl, train);
> flowers <- data.frame(class=cl, train);
> errorest(class ~ ., data=flowers, model=lda, estimator="cv",
> predict=predict.lda);
> 
> Error-Message is :
> Error: Object "predict.lda" not found
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Fri Jan  9 17:19:34 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 Jan 2004 16:19:34 +0000 (GMT)
Subject: [R] ipred and lda
In-Reply-To: <1073663183.20043.20.camel@hgX>
Message-ID: <Pine.LNX.4.44.0401091614450.17647-100000@gannet.stats>

On 9 Jan 2004, Stefan B?hringer wrote:

> can anybody help me with the program below? The function predict.lda
> seems to be defined but cannot be used by errortest.

Precisely.  You should not be calling a method directly and in any case
that is not what is needed here.  ?errorest shows you a correct example,
so why not follow it?

> The R version is 1.7.1

You are overdue for an update then.  See what the posting guide asks you
to do if you find a problem and are not using the current version.

> 
> Thanks in advance,
> 
> 	Stefan
> 
> ----------------
> library("MASS");
> library("ipred");
> 
> data(iris3);
> tr <- sample(1:50, 25);
> train <- rbind(iris3[tr,,1], iris3[tr,,2], iris3[tr,,3]);
> test <- rbind(iris3[-tr,,1], iris3[-tr,,2], iris3[-tr,,3]);
> cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)));
> z <- lda(train, cl);
> predict(z, test)$class;
> 
> data.frame(class=cl, train);
> flowers <- data.frame(class=cl, train);
> errorest(class ~ ., data=flowers, model=lda, estimator="cv",
> predict=predict.lda);
> 
> Error-Message is :
> Error: Object "predict.lda" not found
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Fri Jan  9 17:22:27 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 9 Jan 2004 08:22:27 -0800 (PST)
Subject: [R] Poisson distribution help requested
In-Reply-To: <20040109151210.A11B57265@sitemail.everyone.net>
References: <20040109151210.A11B57265@sitemail.everyone.net>
Message-ID: <Pine.A41.4.58.0401090816460.148750@homer05.u.washington.edu>

On Fri, 9 Jan 2004, Mark St.John wrote:

> Could somebody help me to understand the syntax of R's ppois function?
> I'm looking to calculate the cumulative probability density of an
> observed value (y) given the expected mean (mu) and the level of
> significance (alpha). I'm coming from using SAS to do this and don't
> recognize the descriptions of the arguments for ppois. The definitions
> of lambda and p as stated in the R manuals are foreign to me!
>

You can't specify y and mu and alpha simultaneously. It's not clear what
you want, but it might be one of:

ppois(y,lambda=mu)  gives the probability of an observed value less than
or equal to y if the true mean is mu.

ppois(y,lambda=mu,lower.tail=FALSE)  give the probability of an observed
value greater than y if the true mean is mu.

qpois(alpha, lambda=mu,lower.tail=FALSE) gives the value of Y exceeded
with probability alpha.


	-thomas



From ligges at statistik.uni-dortmund.de  Fri Jan  9 17:31:55 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 09 Jan 2004 17:31:55 +0100
Subject: [R] how to input incomplete data?
In-Reply-To: <Pine.LNX.4.58.0401081016120.814@galton.uchicago.edu>
References: <200401081136.i08BG5wN026831@hypatia.math.ethz.ch>
	<Pine.LNX.4.58.0401081016120.814@galton.uchicago.edu>
Message-ID: <3FFED77B.1050605@statistik.uni-dortmund.de>

Yong Wang wrote:

> Dear all
> the question is:
> the data is not same length for each variable(the column length 
> unequal), how can R read this data? I tried 
> read.table(filename,na.strings),not work.

See ?read.table.

read.table() will work if there are seperators beween missing values 
(you have to specify 'sep' in that case!).
If the number of separators is unequal for some lines, the argument 
'fill' might help. If not, consider to use scan() or readLines() and 
postprocess the imported stuff.

Uwe Ligges


> thanks
> best
> yong
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From phgrosjean at sciviews.org  Fri Jan  9 17:32:46 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 9 Jan 2004 17:32:46 +0100
Subject: [R] ipred and lda
In-Reply-To: <16382.54089.470619.685599@gargle.gargle.HOWL>
Message-ID: <MABBLJDICACNFOLGIHJOIELLEAAA.phgrosjean@sciviews.org>

I got also this problem and I solved it a couple of months ago.
Unfortunatelly, I do not have access to the machine with my code before
monday, so, I cannot give you the exact recipe... I am just recalling from
my poor memory!

If I remember, the problem occured when MASS moved to use namespace, so,
predict.lda was not visible externally any more, something that some ipred
function assumed in the version I used at that time. The solution was to
change the code of ipred to explicitly call the predict.lda function in
MASS, that is, something like:
MASS:::predict.lda

give it a try. Since you use an old version of R (1.7.1), you may face a
similar problem. I suppose the solution is to use latest versions of R, MASS
and ipred.
Best,

Philippe Grosjean

P.S.: Andrea and Thorsten: sorry for not having mentioned this when I got
the problem. I was in a rush,... and then I forgot! But I suppose the latest
version of ipred is OK now, isn't it?

.......................................................<?}))><....
 ) ) ) ) )
( ( ( ( (   Prof. Philippe Grosjean
\  ___   )
 \/ECO\ (   Numerical Ecology of Aquatic Systems
 /\___/  )  Mons-Hainaut University, Pentagone
/ ___  /(   8, Av. du Champ de Mars, 7000 Mons, Belgium
 /NUM\/  )
 \___/\ (   phone: + 32.65.37.34.97, fax: + 32.65.37.33.12
       \ )  email: Philippe.Grosjean at umh.ac.be
 ) ) ) ) )  SciViews project coordinator (http://www.sciviews.org)
( ( ( ( (
...................................................................

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Martin Maechler
Sent: Friday, 09 January, 2004 17:14
To: Stefan B?hringer
Cc: R Help
Subject: Re: [R] ipred and lda


>>>>> "Stefan" == Stefan B?hringer <commercial at s-boehringer.de>
>>>>>     on 09 Jan 2004 16:46:23 +0100 writes:

    Stefan> Dear all, can anybody help me with the program
    Stefan> below? The function predict.lda seems to be defined
    Stefan> but cannot be used by errortest.

    Stefan> The R version is 1.7.1

  >>   library("MASS");
  >>   library("ipred");
  >>
  >>   data(iris3);
  >>   tr <- sample(1:50, 25);
  >>   train <- rbind(iris3[tr,,1], iris3[tr,,2], iris3[tr,,3]);
  >>   test <- rbind(iris3[-tr,,1], iris3[-tr,,2], iris3[-tr,,3]);
  >>   cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)));
  >>   z <- lda(train, cl);
  >>   predict(z, test)$class;
  >>
  >>   data.frame(class=cl, train);
  >>   flowers <- data.frame(class=cl, train);
  >>   errorest(class ~ ., data=flowers, model=lda, estimator="cv",
  >>   predict=predict.lda);

    Stefan> Error-Message is :
    Stefan> Error: Object "predict.lda" not found

predict.lda is not exported from new versions of MASS
since one should use  predict( <lda-fit> , ...).

i.e., I presume that

errorest(class ~ ., data=flowers, model=lda, estimator="cv",
predict=predict)

will work.

BTW: Please, remove the  ";" at the end of lines.
     In S code, they are just plain ugly.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From RBaskin at ahrq.gov  Fri Jan  9 17:29:26 2004
From: RBaskin at ahrq.gov (RBaskin@ahrq.gov)
Date: Fri, 9 Jan 2004 11:29:26 -0500 
Subject: [R] Poisson distribution help requested
Message-ID: <3598558AD728D41183350008C7CF291C0F16BA36@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040109/3f5ae24e/attachment.pl

From p.dalgaard at biostat.ku.dk  Fri Jan  9 18:03:09 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Jan 2004 18:03:09 +0100
Subject: [R] Poisson distribution help requested
In-Reply-To: <16382.54249.584480.471469@gargle.gargle.HOWL>
References: <20040109151210.A11B57265@sitemail.everyone.net>
	<3FFEC979.5090309@pdf.com>
	<16382.54249.584480.471469@gargle.gargle.HOWL>
Message-ID: <x2vfnloy0i.fsf@biostat.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> >>>>> "Spencer" == Spencer Graves <spencer.graves at pdf.com>
> >>>>>     on Fri, 09 Jan 2004 07:32:09 -0800 writes:
> 
>     >> ppois(0:11, 2)
>     Spencer>  [1] 0.1353353 0.4060058 0.6766764 0.8571235
>     Spencer> 0.9473470 0.9834364 0.9954662 [8] 0.9989033
>     Spencer> 0.9997626 0.9999535 0.9999917 0.9999986
> 
>     Spencer> This is the cumulative distribution function of the
>     Spencer> Poisson with mean 2 at the values 0 - 11.
> 
>     Spencer> hope this helps.  spencer graves
> 
> and from Mark's "level of significance (alpha)",
> I presume Mark really wants  qpois()  which computes quantiles,
> i.e., the *inverse* of ppois().

But SAS doesn't seem to do Poisson quantiles....

However,

data;
input x;
y = poisson(1,x);
datalines;
0
1
2
3
4
;
proc print;
run;

Produces

 Obs    x       y

  1     0    0.36788
  2     1    0.73576
  3     2    0.91970
  4     3    0.98101
  5     4    0.99634

which is similar to

> ppois(0:4,1)
[1] 0.3678794 0.7357589 0.9196986 0.9810118 0.9963402


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From m at rkstjohn.com  Fri Jan  9 18:24:03 2004
From: m at rkstjohn.com (Mark St.John)
Date: Fri, 9 Jan 2004 09:24:03 -0800 (PST)
Subject: [R] Poisson distribution help requested
Message-ID: <20040109172404.06700725C@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040109/f00623ee/attachment.pl

From maechler at stat.math.ethz.ch  Fri Jan  9 18:58:11 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 9 Jan 2004 18:58:11 +0100
Subject: [R] Analyzing dendrograms
In-Reply-To: <Pine.LNX.4.44.0401071001290.23080-100000@ares.its.yale.edu>
References: <200401071115.i07B6up8000160@hypatia.math.ethz.ch>
	<Pine.LNX.4.44.0401071001290.23080-100000@ares.its.yale.edu>
Message-ID: <16382.60339.717423.563262@gargle.gargle.HOWL>

>>>>> "Walton" == Walton A Green <walton.green at yale.edu>
>>>>>     on Wed, 7 Jan 2004 10:41:03 -0500 (EST) writes:

    Walton> Ladies and Gentlemen,

    Walton> As Johan Lindberg points out, the documentation for
    Walton> handling dendrograms is sparse....Does anyone know
    Walton> who is responsible for or working on development of
    Walton> tree methods and objects? I've written a couple of
    Walton> scripts for my own use to translate between
    Walton> parenthetical (A(B(CD))) or binary A00 B10 C11 D11
    Walton> tree formats and cluster objects in R, but as an
    Walton> inexperienced programmer have had difficulty
    Walton> integrating them with the existing framework--I'm
    Walton> trying to write some resampling routines and
    Walton> sensitivity tests for tree objects.

Well, the R-core team is responsible for some...
at least, some of us (mainly Fritz Leisch, then me) have defined
and used the "dendrogram" class.

where  help(dendrogram) says quite clearly

  >> The code is still in testing stage and the API may change in the
  >> future.

Then, there's the much more general S4 classes in Bioconductor's 
"graph" package (which has a maintainer as every addon package...)

    Walton> Perhaps this question should go to the r-devel list
    Walton> instead....

yes.  There you could also elaborate a bit about what you
wanted, what you did, and where your difficulties were.

    Walton> Yours, Walton Green

      >> Date: Tue, 06 Jan 2004 12:49:59 +0100
      >> From: Johan Lindberg <johanl at kiev.biotech.kth.se>
      >> Subject: RE: [R] Analyzing dendograms??

      >> ...dendograms/heatmaps/hclust in R in a proper way I ask
      >> myself, is there a way of doing this in R? or is this a
      >> limitation of the functions available today in the R
      >> programming language. I know there are some functions
      >> like cutree etc but the documentation is really, really
      >> sparse. Are there any tutorials out there of how to do
      >> these things? or should one turn to alternative programs
      >> like MEV from TIGR?

      >> / J

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From bates at stat.wisc.edu  Fri Jan  9 19:26:21 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 09 Jan 2004 12:26:21 -0600
Subject: [R] GLMM (lme4) vs. glmmPQL output
In-Reply-To: <JLEPLGAANFCEAEDCAGJNOEDACHAA.dieter.menne@menne-biomed.de>
References: <JLEPLGAANFCEAEDCAGJNOEDACHAA.dieter.menne@menne-biomed.de>
Message-ID: <6roetd0yia.fsf@bates4.stat.wisc.edu>

I believe the distinction is explained in the lme4 documentation but,
in any case, the standard errors and the approximate log-likelihood
for glmmPQL are from the lme model that is the last step in the
optimization.  The corresponding quantities from GLMM are from another
approximation that should be more reliable.

"Dieter Menne" <dieter.menne at menne-biomed.de> writes:

> Dear List,
> 
> As I understand, GLMM (in experimental lme4) and glmmPQL (MASS) do
> similar things using somewhat different methods. Trying both,
> I get the same coefficients, but markedly different std. errors and
> p-values.
> Any help in understanding the models tested by both procedures?
> 
> Dieter Menne
> 
> 
> UseMASS<-T # must restart R after changing because of nlme/lme4 clash
> if (UseMASS){
>   library(MASS)
>   summary(glmmPQL(y ~ trt + I(week > 2), random = ~ 1 | ID,
>                   family = binomial, data = bacteria))
> } else
> {
>   library(lme4)
>   summary(GLMM(y ~ trt + I(week > 2), random = ~ 1 | ID,
>                   family = binomial, data = bacteria,method="PQL"))
> }
> 
> (MASS output)
> Fixed effects: y ~ trt + I(week > 2)
>                     Value Std.Error  DF   t-value p-value
> (Intercept)      3.412012 0.5185028 169  6.580509  0.0000
> trtdrug         -1.247355 0.6440627  47 -1.936698  0.0588
> trtdrug+        -0.754327 0.6453971  47 -1.168780  0.2484
> I(week > 2)TRUE -1.607256 0.3583378 169 -4.485310  0.0000
> 
> (lme4 output)
> Fixed effects: y ~ trt + I(week > 2)
>                  Estimate Std. Error  DF z value Pr(>|z|)
> (Intercept)       3.41202    3.93293 169  0.8676   0.3856
> trtdrug          -1.24736    1.52156  47 -0.8198   0.4123
> trtdrug+         -0.75433    1.21963  47 -0.6185   0.5363
> I(week > 2)TRUE  -1.60726    2.19660 169 -0.7317   0.4644
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From Mike.Prager at noaa.gov  Fri Jan  9 20:03:34 2004
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Fri, 09 Jan 2004 14:03:34 -0500
Subject: [R] r: fortran help
In-Reply-To: <3FFE7F73.512B881D@stats.uct.ac.za>
References: <3FFE7F73.512B881D@stats.uct.ac.za>
Message-ID: <6.0.1.1.2.20040109133120.01d3f878@hermes.nos.noaa.gov>

At 05:16 AM 1/9/2004, allan clark wrote:

>I would like to know if anybody knows of either a good book or web site
>that explains one how to use Fortran. I would like to call some of the
>Fortran subroutines but before I can do that I first want to learn how
>to code in Fortran.

Interesting question.  The name "Fortran" is generally used for the current 
version of the language (Fortran 95), while FORTRAN often means the 
previous version (FORTRAN 77). Despite many advances in Fortran 95 
(whole-array operations, better modularization, many safety features, and 
others), both versions are widely used, probably because a free compiler is 
available for FORTRAN 77 but not yet for Fortran 95.  So the answer to your 
question depends on which language you want to learn.

(By the way, it's not clear to me if routines compiled with a suitable 
modern Fortran (95) compiler can be linked into R. I would love to have 
enough time to find out, but programming is a small part of my job these days.)

Modern Fortran is an excellent scientific programming language.  A very 
good, concise book is Metcalf and Reid, "Fortran 90/95 Explained," 
published by Oxford University Press.

The best book I ever came across for FORTRAN 77 was by someone named 
Calderbank.  It was thin, readable, and complete. However, I've got rid of 
it (since I now use modern Fortran), and it's out of print.

As Tobias Verbeke suggests, there's quite a lot of material on both 
languages on the Web.

A couple of more FYI's:

Fortran 95 is a proper superset of FORTRAN 77.  Therefore, any 
standard-conforming FORTRAN 77 code can be compiled on any Fortran 95 
compiler.  Because FORTRAN 77 was limited in many ways, much code was 
written with vendor extensions.  Many were incorporated into Fortran 95, 
and the most common others are generally available in current Fortran 95 
compilers.

The next version of Fortran, which I believe will be called Fortran 2004, 
is expected soon. My understanding is that it includes (among other things) 
more features for object orientation and features for better (and more 
portable) interoperability with C.

I hope that helps.

Mike



-- 
Michael Prager
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516  USA
http://shrimp.ccfhrb.noaa.gov/~mprager/

NOTE: Opinions expressed are personal, not official. No government
endorsement of any product is made or implied.



From tura at centroin.com.br  Fri Jan  9 19:35:41 2004
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Fri, 09 Jan 2004 16:35:41 -0200
Subject: [R] Fit non-linear regressor
Message-ID: <6.0.1.1.2.20040109163309.02c51010@pop.centroin.com.br>

Hi R masters,

Sorry for first mensage, this is orignal text...

y<-c(2.8150,3.5239,4.0980,4.5845,5.0709,5.4824,5.8427,6.3214,6.7349,7.3651)
x<-c(37,42,47,52,57,62,67,72,77,82)

I need fit R and A in y=f(x)=R*exp(A*x), with minimize sd= sqrt(SRR/(n-2)) where SRR is Sum of the Square of the Residuals 
and n is number of data points (in this case 10)

How do I make this?


Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil 

From bwheeler at echip.com  Fri Jan  9 21:20:03 2004
From: bwheeler at echip.com (Bob Wheeler)
Date: Fri, 09 Jan 2004 15:20:03 -0500
Subject: [R] Call and memory
Message-ID: <3FFF0CF3.60707@echip.com>

I use a large real matrix, X, in C code that is passed from R and 
transposed in place in the C code. I would like to conserve memory and, 
if possible, allocate space for only one copy of X -- hence I would like 
to pass a pointer to the data in the X object to the C code.

The Writing R Extensions manual says that neither .Call nor .External 
copy their arguments. They also say that these arguments should be 
treated as read only.

Fine, but in testing I seem to be able to transpose very large X's in 
place, in C code without an error. This leads me to assume that the 
manual was just giving good advice about treating arguments as read 
only. However, I find that I have done nothing to the X in R. It seems 
that a copy has been made after all. I may as well call the code with .C 
  and avoid the use of macros.

Could someone please point out the error in my thinking or suggest a way 
to accomplish my goal?

My code follows:

"mListTest" <-
function(X,N,k) {

	.Call("mList",as.double(X),as.integer(N),as.integer(k));
}


SEXP mList(
	SEXP Xi,
	SEXP Ni,
	SEXP ki
)
{
	double *pX=NUMERIC_POINTER(Xi);
	int	N=INTEGER_POINTER(Ni)[0];
	int k=INTEGER_POINTER(ki)[0];
	SEXP alist;
	SEXP avector;
	SEXP nvector;
	SEXP rvector;
	SEXP kvector;
	int n;
	int i;

	transposeMatrix(pX,N,k);

	n=4;
	PROTECT(alist=NEW_LIST(n));
	PROTECT(avector=NEW_NUMERIC(200));

	for (i=0;i<200;i++) {
		NUMERIC_POINTER(avector)[i]=pX[i];
	}
	SET_ELEMENT(alist,0,avector);
	UNPROTECT(1);
	PROTECT(nvector=NEW_INTEGER(1));
	INTEGER_POINTER(nvector)[0]=N;
	SET_ELEMENT(alist,1,nvector);
	UNPROTECT(1);
	PROTECT(rvector=NEW_NUMERIC(1));
	NUMERIC_POINTER(rvector)[0]=0.5;
	SET_ELEMENT(alist,2,rvector);
	UNPROTECT(1);
	PROTECT(kvector=NEW_INTEGER(1));
	INTEGER_POINTER(kvector)[0]=k;
	SET_ELEMENT(alist,3,kvector);
	UNPROTECT(1);

	UNPROTECT(1);
	return alist;

}

-- 
Bob Wheeler --- http://www.bobwheeler.com/
         ECHIP, Inc. ---
Randomness comes in bunches.



From tplate at acm.org  Fri Jan  9 21:58:45 2004
From: tplate at acm.org (Tony Plate)
Date: Fri, 09 Jan 2004 13:58:45 -0700
Subject: [R] Fit non-linear regressor
In-Reply-To: <6.0.1.1.2.20040109163309.02c51010@pop.centroin.com.br>
Message-ID: <5.2.1.1.2.20040109135337.03875d88@mailhost.blackmesacapital.com>

It's reasonably straightforward to use nls() for this:

 > d <- 
data.frame(x=c(37,42,47,52,57,62,67,72,77,82),y=c(2.8150,3.5239,4.0980,4.5845,5.0709,5.4824,5.8427,6.3214,6.7349,7.3651))
 > fit <- nls(y~R*exp(x*A),start=list(R=2,A=0.1),data=d)
 > plot(x,y)
 > lines(x, coef(fit)[1]*exp(x*coef(fit)[2]))
 >

You might want to check that your objective does not have local optima (in 
which case the assumption that minimizing the  sum-squared residual will 
minimize your objective may be false).

hope this helps,

Tony Plate

At Friday 04:35 PM 1/9/2004 -0200, Bernardo Rangel Tura wrote:
>Hi R masters,
>
>Sorry for first mensage, this is orignal text...
>
>y<-c(2.8150,3.5239,4.0980,4.5845,5.0709,5.4824,5.8427,6.3214,6.7349,7.3651)
>x<-c(37,42,47,52,57,62,67,72,77,82)
>
>I need fit R and A in y=f(x)=R*exp(A*x), with minimize sd= sqrt(SRR/(n-2)) 
>where SRR is Sum of the Square of the Residuals
>and n is number of data points (in this case 10)
>
>How do I make this?
>
>
>Thanks in advance
>
>Bernardo Rangel Tura, MD, MSc
>National Institute of Cardiology Laranjeiras
>Rio de Janeiro Brazil
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Tony Plate   tplate at acm.org



From George_Heine at blm.gov  Fri Jan  9 23:05:24 2004
From: George_Heine at blm.gov (George_Heine@blm.gov)
Date: Fri, 9 Jan 2004 15:05:24 -0700
Subject: [R] degree-min-sec data
Message-ID: <OFD8D87ED9.A7D7B282-ON87256E16.00771B68@blm.gov>





Hello -

Have both astronomic and geodetic data sets with values in the form
"ddd:mm:ss.sssss", where dd is an integer between -180 and 180, mm is an
integer between 0 and 60, and ss is a floating-point
number between 0 and 60.0.  In order to do anything useful with these
values they need to be turned into their "decimal degree" equivalent.

Assuming the data is a vector y, the following works, sort of:

z<-strsplit(as.character(y),split=":")
zz<-sapply(z,as.numeric)
x<- t(c(1,1/60,1/3600) %*% zz)

Trouble comes if there are any NA's in the data.  In this case, R refuses
to coerce zz into matrix form, but leaves it as a "list of lists".  How can
the above routine be patched up to pass NAs through?
I can think of some inelegant solutions (e.g.  recoding NA as "-200:-1:-1")
but surely there is a better way!
Or is this the wrong technique?

More generally, is there a way to "unzip" a character vector along some
split marker, handling irregulatirites gracefully?  For example, from

y<-c("aaa#bbb", "ccc#ddd", "eee","fff"),

strsplit(y,split="#") would produce

c(c("aaa","bbb"), c("ccc","ddd"), c("eee","fff")).

Is there a way to produce instead

c(c("aaa","ccc","eee"),c("bbb","ddd","fff")) ?

Thanks for your assistance.

<>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>
George Heine, PhD
Mathematical Analyst
National IRM Center
U.S. Bureau of Land Management
voice   (303) 236-0099
fax       (303) 236-1974
pager   (303) 826-8182 or gheine at my2way.com
<>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>



From p.dalgaard at biostat.ku.dk  Fri Jan  9 23:41:51 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Jan 2004 23:41:51 +0100
Subject: [R] degree-min-sec data
In-Reply-To: <OFD8D87ED9.A7D7B282-ON87256E16.00771B68@blm.gov>
References: <OFD8D87ED9.A7D7B282-ON87256E16.00771B68@blm.gov>
Message-ID: <x2smio4uds.fsf@biostat.ku.dk>

George_Heine at blm.gov writes:

> Hello -
> 
> Have both astronomic and geodetic data sets with values in the form
> "ddd:mm:ss.sssss", where dd is an integer between -180 and 180, mm is an
> integer between 0 and 60, and ss is a floating-point
> number between 0 and 60.0.  In order to do anything useful with these
> values they need to be turned into their "decimal degree" equivalent.
> 
> Assuming the data is a vector y, the following works, sort of:
> 
> z<-strsplit(as.character(y),split=":")
> zz<-sapply(z,as.numeric)
> x<- t(c(1,1/60,1/3600) %*% zz)
> 
> Trouble comes if there are any NA's in the data.  In this case, R refuses
> to coerce zz into matrix form, but leaves it as a "list of lists".  How can
> the above routine be patched up to pass NAs through?
> I can think of some inelegant solutions (e.g.  recoding NA as "-200:-1:-1")
> but surely there is a better way!
> Or is this the wrong technique?

Not necessarily. I might try something like

z <- strsplit(ifelse(is.na(y),y,"::NA"))
..etc..


There are also fancier possibilities:

z <- scan(textConnection(y),sep=":",fill=TRUE,what=list(a=0,b=0,c=0))
x <- z$a + z$b/60 + z$c/3600

or even

x <- with(z, a + b/60 + c/3600)

> More generally, is there a way to "unzip" a character vector along some
> split marker, handling irregulatirites gracefully?  For example, from
> 
> y<-c("aaa#bbb", "ccc#ddd", "eee","fff"),
> 
> strsplit(y,split="#") would produce
> 
> c(c("aaa","bbb"), c("ccc","ddd"), c("eee","fff")).
> 
> Is there a way to produce instead
> 
> c(c("aaa","ccc","eee"),c("bbb","ddd","fff")) ?

?? Was that what you intended to write? 

> dput(strsplit(y,split="#"))
list(c("aaa", "bbb"), c("ccc", "ddd"), "eee", "fff")


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tlumley at u.washington.edu  Sat Jan 10 00:45:55 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 9 Jan 2004 15:45:55 -0800 (PST)
Subject: [R] Call and memory
In-Reply-To: <3FFF0CF3.60707@echip.com>
References: <3FFF0CF3.60707@echip.com>
Message-ID: <Pine.A41.4.58.0401091540510.179798@homer04.u.washington.edu>

On Fri, 9 Jan 2004, Bob Wheeler wrote:

> I use a large real matrix, X, in C code that is passed from R and
> transposed in place in the C code. I would like to conserve memory and,
> if possible, allocate space for only one copy of X -- hence I would like
> to pass a pointer to the data in the X object to the C code.
>
> The Writing R Extensions manual says that neither .Call nor .External
> copy their arguments. They also say that these arguments should be
> treated as read only.
>
> Fine, but in testing I seem to be able to transpose very large X's in
> place, in C code without an error. This leads me to assume that the
> manual was just giving good advice about treating arguments as read
> only. However, I find that I have done nothing to the X in R. It seems
> that a copy has been made after all. I may as well call the code with .C
>   and avoid the use of macros.
>
> Could someone please point out the error in my thinking or suggest a way
> to accomplish my goal?
>
> My code follows:
>
> "mListTest" <-
> function(X,N,k) {
>
> 	.Call("mList",as.double(X),as.integer(N),as.integer(k));
> }
>


as.double(X) returns a copy of X, so you are only passing a copy to C.


	-thomas



From ggrothendieck at myway.com  Sat Jan 10 00:51:47 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri,  9 Jan 2004 18:51:47 -0500 (EST)
Subject: [R] apply to multiple arrays simultaneously
Message-ID: <20040109235147.D5CD53976@mprdmxin.myway.com>




Try something like this:

mat.a1 <- apply( a1, 1:2, list )
mat.a2 <- apply( a2, 1:2, list )
mapply( my.function, a1, a2 )

Note that mat.a1 and mat.a2 are 3x4 matrices,
each element of which holds a matrix.


Date:   Fri, 09 Jan 2004 10:10:03 +0000 
From:   Carlos Soares <csoares at liacc.up.pt>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] apply to multiple arrays simultaneously 

 
Dear R users,

Suppose two arrays which partly have the same dimensions. For instance, 
a1 and a2 with dim(a1) is c(3,4,5,6) and dim(a2) is c(3,4,7,8). How can 
I perform an apply on the equivalent part of the dimensions on both 
arrays simultaneously? Something like:

apply(list(a1, a2), c(1,2), function(x,y) {my.function(x,y)})

A useful bonus would be, assuming that my.function always returns an 
array withthe same dimensions (e.g., c(2,3,4), that the final result 
would be an array wit
h dimensions c(3,4,2,3,4).

With best regards,
Carlos

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From roger at ysidro.econ.uiuc.edu  Sat Jan 10 01:11:52 2004
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Fri, 9 Jan 2004 18:11:52 -0600 (CST)
Subject: [R] edit windows in RAqua
Message-ID: <Pine.SOL.4.30.0401091752020.10097-100000@ysidro.econ.uiuc.edu>

I'm just beginning to explore Raqua on a new G5 machine.  Generally,
it feels very natural, but I'm puzzled by the behavior of editing
windows.  When you use fix() or vi() or edit() you get a new
window;  this is fine, but is there a way to:

	o  specify what editor is operating in this window

	o  control the size of the window

	o  allow control to revert back to the R console with
		the editing window open?

I guess what I'm really asking is whether there is a built in way
to spawn an xterm editing window running vi for such tasks that
would leave the console active or some equivalent functionality.


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820



From Phguardiol at aol.com  Sat Jan 10 03:42:07 2004
From: Phguardiol at aol.com (Phguardiol@aol.com)
Date: Fri, 9 Jan 2004 21:42:07 EST
Subject: [R] menuRandomSample funciton in S+ -> R?
Message-ID: <6a.3a3e385a.2d30c07f@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040109/83e78615/attachment.pl

From Matthew.Redding at dpi.qld.gov.au  Sat Jan 10 05:25:46 2004
From: Matthew.Redding at dpi.qld.gov.au (Redding, Matthew)
Date: Sat, 10 Jan 2004 14:25:46 +1000
Subject: FW: [R] Letter Spacing
Message-ID: <200401100425.i0A4PmJJ017217@dpi-gw1.dpi.qld.gov.au>

Thanks for your help with this behaviour.

I have tried a few other things, and it looks like it is an issue of using the clipboard to copy it in rather than saving to a 
file then copying.

A bit odd, but maybe nothing to do with R!

Matt Redding

-----Original Message-----
From: Redding, Matthew 
Sent: Saturday, 10 January 2004 2:09 PM
To: 'Prof Brian Ripley'
Subject: RE: [R] Letter Spacing


Hi All,
Thanks to everyone who answered the question!

Just a little more information on the behaviour.

I re-installed the latest version of R, and re-installed version 1.51.

I ran the r program that produces the graph in each of the versions.

The latest version produces compressed text when they are inserted in Word 2000, 
while the older version did not.

I am pretty sure it is a real effect, since it has occured with new installations, the same
r program, and the same version of windows and word. 

I have only tested it with enhanced metafont files, have yet to try it with pdf.

Using pdf is a good call though....usually fixes a lot of word bad behaviour.

Thanks, 

Matt Redding


-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Friday, 9 January 2004 6:33 PM
To: Redding, Matthew
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Letter Spacing


We are not aware of any related changes between R 1.5.1 and R 1.8.1, and
no one else has reported a problem.  Text strings in R graphics are
plotted directly in the font specified and not as individual letters, so
there is nothing you can do about letter spacing in R.

I would first cross-check that the same fonts have been used in both 
systems (and that includes exact sizes of fonts), then check that a 
metafile viewer (Windows XP comes with one, for example) shows the 
difference.  I am afraid that most of the problems we have investigated 
with metafiles were traced to bugs in Word.

On Fri, 9 Jan 2004, Redding, Matthew wrote:

> Hi All, 
> 
> I've been trying to make some adjustments to the graphics in a paper I wrote some time ago, for which the comments have been 
> returned from the reviewers.
> 
> I always use R for publication graphics...I think it does the best job available, for the things I am interested in.
> 
> I could not get my graphics in R 181 to look the same as the old ones (completed 8 months ago), 
> the text seemed a bit squashed 
> together when I copied graphics as meta-files into word.  
> 
> I have found that by re-installing version 1.51, the graphics look as nice as the previous ones, with the text nicely spaced.
> 
> Is there a "par" parameters that will adjust the letter spacing, so I can use version 181 for this type of job?
> 
> Thanks,
> 
> Matt R. Redding
> Senior Environmental Scientist, Intensive livestock and sheep
> Agency for Food and Fibre Sciences
> Department of Primary Industries
> 
> Telephone 07 4688 1372  Fax 07 4688 1192
> Email matthew.redding at dpi.qld.gov.au
> Website  http://www.dpi.qld.gov.au/ilsu/  Call Centre 13 25 23 
> 
> ********************************DISCLAIMER******************...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595 

********************************DISCLAIMER******************...{{dropped}}



From ripley at stats.ox.ac.uk  Sat Jan 10 09:00:35 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 10 Jan 2004 08:00:35 +0000 (GMT)
Subject: [R] menuRandomSample funciton in S+ -> R?
In-Reply-To: <6a.3a3e385a.2d30c07f@aol.com>
Message-ID: <Pine.LNX.4.44.0401100755580.18717-100000@gannet.stats>

It supports the menu system in S-PLUS for Windows, and R doesn't have that
menu system. You don't need it: to sample rows from a data frame use

DF[sample(nrow(DF), size), ]

or something like that.

On Fri, 9 Jan 2004 Phguardiol at aol.com wrote:

> Hi all
> I cannot find the menuRandomSample function, which is available in S+, in R. 
> Does it exist in R ? If so, what is its name ?
> Thanks
> Philippe


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Jan 10 10:09:04 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 10 Jan 2004 09:09:04 +0000 (GMT)
Subject: [R] Call and memory
In-Reply-To: <Pine.A41.4.58.0401091540510.179798@homer04.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0401100859170.18898-100000@gannet.stats>

On Fri, 9 Jan 2004, Thomas Lumley wrote:

> On Fri, 9 Jan 2004, Bob Wheeler wrote:
> 
> > I use a large real matrix, X, in C code that is passed from R and
> > transposed in place in the C code. I would like to conserve memory and,
> > if possible, allocate space for only one copy of X -- hence I would like
> > to pass a pointer to the data in the X object to the C code.
> >
> > The Writing R Extensions manual says that neither .Call nor .External
> > copy their arguments. They also say that these arguments should be
> > treated as read only.
> >
> > Fine, but in testing I seem to be able to transpose very large X's in
> > place, in C code without an error. This leads me to assume that the
> > manual was just giving good advice about treating arguments as read
> > only. However, I find that I have done nothing to the X in R. It seems
> > that a copy has been made after all. I may as well call the code with .C
> >   and avoid the use of macros.
> >
> > Could someone please point out the error in my thinking or suggest a way
> > to accomplish my goal?
> >
> > My code follows:
> >
> > "mListTest" <-
> > function(X,N,k) {
> >
> > 	.Call("mList",as.double(X),as.integer(N),as.integer(k));
> > }
> >
> 
> 
> as.double(X) returns a copy of X, so you are only passing a copy to C.

storage.mode(X) <- "double" is the standard paradigm to avoid an copy here 
if not needed (even with .C, which would make two copies of X on entry and 
one on exit).

Both arima() and the Kalman fitering code used by StructTS() makes use of
the ability of .Call to alter its arguments, so the advice given is
definitely right.

It is hard to predict when R will make a copy, not least because from time 
to time we spot an unnecessary copy or add a necessary one.  So if you do 
want .Call to alter its arguments you need to test your assumptions (and 
retest when R is updated).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Ted.Harding at nessie.mcc.ac.uk  Sat Jan 10 10:21:06 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 10 Jan 2004 09:21:06 -0000 (GMT)
Subject: [R] Fit non-linear regressor
In-Reply-To: <6.0.1.1.2.20040109163309.02c51010@pop.centroin.com.br>
Message-ID: <XFMail.040109203406.Ted.Harding@nessie.mcc.ac.uk>

On 09-Jan-04 Bernardo Rangel Tura wrote:
> Hi R masters,
> 
> Sorry for first mensage, this is orignal text...
> 
> y<-c(2.8150,3.5239,4.0980,4.5845,5.0709,5.4824,5.8427,6.3214,6.7349,7.36
> 51)
> x<-c(37,42,47,52,57,62,67,72,77,82)
> 
> I need fit R and A in y=f(x)=R*exp(A*x), with minimize sd=
> sqrt(SRR/(n-2)) where SRR is Sum of the Square of the Residuals 
> and n is number of data points (in this case 10)
> 
> How do I make this?

What is your objection, with these data, to a linear regression
of log(y) on x? This would give you log(R) as intercept
and A as slope, and you can get back to y by exponentiating;
though it would not quite minimise what you want, rather minimising
the SS of residuals of log(y).

Or indeed, now that I look more closely, even a simple linear
regression of y on x?

[Perhaps you need the fitted relationship to be "realistic" over
 the unobserved range (0,36) of x; but the lower end of this will
 be poorly estimated.]

  y<-c(2.8150,3.5239,4.0980,4.5845,5.0709,
       5.4824,5.8427,6.3214,6.7349,7.3651)
  x<-c(37,42,47,52,57,62,67,72,77,82)
  lm1<-lm(y~x)
  lm2<-lm(log(y)~x)
  plot(x,y,xlim=c(0,85),ylim=c(0,8))
  a<-lm1$coefficients[1];b<-lm1$coefficients[2]
  lR<-lm2$coefficients[1];A<-lm2$coefficients[2]
  u<-(0:85)
  lines(u,a+b*u,col="red")
  lines(u,exp(lR+A*u))

shows that the the fit lm(y~x) fits the data better than lm(log(y)~x),
over the range of X considered. The data do not match the curvature
of the exponentiated lm2 fit.

I tend to doubt that taking the trouble to do a non-linear fit which
minimises the residuals of y would make a meaningful improvement on
lm(log(y)~x) over this range!

More interesting, perhaps, is the apparent sinusoidal effect -- slight,
but clearly visible relative to the above fitted straight line ...

... what does "x" represent?

With best wishes,
Ted.



From gb at stat.umu.se  Sat Jan 10 12:03:25 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sat, 10 Jan 2004 12:03:25 +0100
Subject: [R] GLMM (lme4) vs. glmmPQL output
In-Reply-To: <6roetd0yia.fsf@bates4.stat.wisc.edu>
References: <JLEPLGAANFCEAEDCAGJNOEDACHAA.dieter.menne@menne-biomed.de>
	<6roetd0yia.fsf@bates4.stat.wisc.edu>
Message-ID: <20040110110325.GA21545@stat.umu.se>

On Fri, Jan 09, 2004 at 12:26:21PM -0600, Douglas Bates wrote:
> I believe the distinction is explained in the lme4 documentation but,
> in any case, the standard errors and the approximate log-likelihood
> for glmmPQL are from the lme model that is the last step in the
> optimization.  The corresponding quantities from GLMM are from another
> approximation that should be more reliable.

It would be interesting to see what glmmML, which uses yet another 
approximation, gives on this particular data set. Could you (Dieter)
try it, and perhaps also share your data with us?


> 
> "Dieter Menne" <dieter.menne at menne-biomed.de> writes:
> 
> > Dear List,
> > 
> > As I understand, GLMM (in experimental lme4) and glmmPQL (MASS) do
> > similar things using somewhat different methods. Trying both,
> > I get the same coefficients, but markedly different std. errors and
> > p-values.
> > Any help in understanding the models tested by both procedures?
> > 
> > Dieter Menne
> > 
> > 
> > UseMASS<-T # must restart R after changing because of nlme/lme4 clash
> > if (UseMASS){
> >   library(MASS)
> >   summary(glmmPQL(y ~ trt + I(week > 2), random = ~ 1 | ID,
> >                   family = binomial, data = bacteria))
> > } else
> > {
> >   library(lme4)
> >   summary(GLMM(y ~ trt + I(week > 2), random = ~ 1 | ID,
> >                   family = binomial, data = bacteria,method="PQL"))
> > }
> > 
> > (MASS output)
> > Fixed effects: y ~ trt + I(week > 2)
> >                     Value Std.Error  DF   t-value p-value
> > (Intercept)      3.412012 0.5185028 169  6.580509  0.0000
> > trtdrug         -1.247355 0.6440627  47 -1.936698  0.0588
> > trtdrug+        -0.754327 0.6453971  47 -1.168780  0.2484
> > I(week > 2)TRUE -1.607256 0.3583378 169 -4.485310  0.0000
> > 
> > (lme4 output)
> > Fixed effects: y ~ trt + I(week > 2)
> >                  Estimate Std. Error  DF z value Pr(>|z|)
> > (Intercept)       3.41202    3.93293 169  0.8676   0.3856
> > trtdrug          -1.24736    1.52156  47 -0.8198   0.4123
> > trtdrug+         -0.75433    1.21963  47 -0.6185   0.5363
> > I(week > 2)TRUE  -1.60726    2.19660 169 -0.7317   0.4644
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> -- 
> Douglas Bates                            bates at stat.wisc.edu
> Statistics Department                    608/262-2598
> University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From tlumley at u.washington.edu  Sat Jan 10 18:30:47 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 10 Jan 2004 09:30:47 -0800 (PST)
Subject: [R] edit windows in RAqua
In-Reply-To: <Pine.SOL.4.30.0401091752020.10097-100000@ysidro.econ.uiuc.edu>
References: <Pine.SOL.4.30.0401091752020.10097-100000@ysidro.econ.uiuc.edu>
Message-ID: <Pine.A41.4.58.0401100923540.73650@homer36.u.washington.edu>

On Fri, 9 Jan 2004, Roger Koenker wrote:

> I'm just beginning to explore Raqua on a new G5 machine.  Generally,
> it feels very natural, but I'm puzzled by the behavior of editing
> windows.  When you use fix() or vi() or edit() you get a new
> window;  this is fine, but is there a way to:
>
> 	o  specify what editor is operating in this window

No. This is a bug, since we claim pico(), vi() etc work

> 	o  control the size of the window

No. This isn't a bug, but would be a useful feature.

> 	o  allow control to revert back to the R console with
> 		the editing window open?

No. This is related to R's lack of threading. We can't do this on any
system.

> I guess what I'm really asking is whether there is a built in way
> to spawn an xterm editing window running vi for such tasks that
> would leave the console active or some equivalent functionality.

This is why many of us use Emacs/ESS rather than the GUI on Mac and
Windows.

It's easy to spawn an xterm running vi and allow R to continue, the hard
thing is getting the contents back to R afterwards.

	-thomas



From bitwrit at ozemail.com.au  Sat Jan 10 22:21:33 2004
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Sun, 11 Jan 2004 08:21:33 +1100
Subject: [R] Error in R-1.8.1 build
Message-ID: <20040110211430.LUEW29851.smta07.mail.ozemail.net@there>

Hi,

Searchng the archives for the messages containing:

error & making & R-1.8
error & make & R-1.8

I found two possibly relevant messages. Both concerned compression routines, 
and the one reply that I could find indicated that the local libraries might 
be out of date or corrupt. I think these are the relevant libraries:

/usr/lib/libz.so.1
/usr/lib/libz.so.1.1.3
/usr/lib/libzvt.so.2.2.10
/usr/lib/libzvt.so.2
/usr/lib/libz.a
/usr/lib/libz.so

Building R-1.8.1 on:

RedHat v7.2
gcc v2.96

produces the following error messages:

make[4]: Entering directory `/usr/local/R-1.8.1/src/extra/zlib'
...
making infutil.d from infutil.c
make[4]: *** [infutil.d] Segmentation fault
make[4]: Leaving directory `/usr/local/R-1.8.1/src/extra/zlib'
make[3]: *** [R] Error 2
make[3]: Leaving directory `/usr/local/R-1.8.1/src/extra/zlib'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/usr/local/R-1.8.1/src/extra'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/usr/local/R-1.8.1/src'
make: *** [R] Error 1

I suspect a type mismatch, but was unable to find it. The Makefile is so 
cryptic that I couldn't work out the compilation command and thus couldn't 
get more info. Thanks for any help.

Jim



From allanlao at macau.ctm.net  Sun Jan 11 06:44:11 2004
From: allanlao at macau.ctm.net (allanlao)
Date: Sun, 11 Jan 2004 13:44:11 +0800
Subject: [R] Wavelet on time series.
Message-ID: <4000E2AB.2060009@macau.ctm.net>

Dear Sir/ Madam,

I am new to R. I would like to make a wavelet analysis on the 
temperature data from 1901-2003. Is there any example about wavelet 
analyst on the time-series data.

Allan Lao



From ripley at stats.ox.ac.uk  Sun Jan 11 09:22:40 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 11 Jan 2004 08:22:40 +0000 (GMT)
Subject: [R] Error in R-1.8.1 build
In-Reply-To: <20040110211430.LUEW29851.smta07.mail.ozemail.net@there>
Message-ID: <Pine.LNX.4.44.0401110813180.28899-100000@gannet.stats>

You got a segmentation fault from the compiler.  It is the notorious gcc
`2.96' (see gcc.gnu.org -- there is no such version according to the gcc
developers).  It used to be a frequent source of grief (but then RedHat
7.2 is old now), and the advice is to use a released version of gcc.

At least some versions of `2.96' will compile R but the build will crash 
during the tests.

On Sun, 11 Jan 2004, Jim Lemon wrote:

> Hi,
> 
> Searchng the archives for the messages containing:
> 
> error & making & R-1.8
> error & make & R-1.8

Try searching for gcc & 2.96.

> I found two possibly relevant messages. Both concerned compression routines, 
> and the one reply that I could find indicated that the local libraries might 
> be out of date or corrupt.

Yes, but that was R not running correctly (later in the build), and your 
build is trying to compile libz from the sources since your libz *is* out 
of date (and a security risk).

> I think these are the relevant libraries:
> 
> /usr/lib/libz.so.1
> /usr/lib/libz.so.1.1.3
> /usr/lib/libzvt.so.2.2.10
> /usr/lib/libzvt.so.2
> /usr/lib/libz.a
> /usr/lib/libz.so
> 
> Building R-1.8.1 on:
> 
> RedHat v7.2
> gcc v2.96
> 
> produces the following error messages:
> 
> make[4]: Entering directory `/usr/local/R-1.8.1/src/extra/zlib'
> ...
> making infutil.d from infutil.c
> make[4]: *** [infutil.d] Segmentation fault
> make[4]: Leaving directory `/usr/local/R-1.8.1/src/extra/zlib'
> make[3]: *** [R] Error 2
> make[3]: Leaving directory `/usr/local/R-1.8.1/src/extra/zlib'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/usr/local/R-1.8.1/src/extra'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/usr/local/R-1.8.1/src'
> make: *** [R] Error 1
> 
> I suspect a type mismatch, but was unable to find it. The Makefile is so 
> cryptic that I couldn't work out the compilation command and thus couldn't 
> get more info. Thanks for any help.

Note: it is not compiling at this point but producing a dependency file.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wolfgangpauli at web.de  Sun Jan 11 17:27:32 2004
From: wolfgangpauli at web.de (Wolfgang Pauli)
Date: Sun, 11 Jan 2004 17:27:32 +0100
Subject: [R] newbie question on contrasts and aov
Message-ID: <200401111727.33138.wolfgangpauli@web.de>

I try to move from SPSS to R/S and am trying to reproduce the results of SPSS 
in R. I calculated a one-way anova with "spk" as experimental factor and erp 
as depended variable. 
The result of the Anova are the same concearning the mean square, F and p 
values. But I also wanted to caculate the contr.sdif(4) contrast on spk. The 
results are completely different now. I hope anybody can help me.

Thanks, Wolfgang

This is what I get in SPSS:
Tests of Within-Subjects Contrasts
Measure: MEASURE_1 
Source		SPKType III Sum of Squares	df	Mean Square	F	Sig.
SPK		Level 2 vs. Level 1	3,493	1	3,493	2,026	,178
			Level 3 vs. Previous	20,358	1	20,358	10,168	,007
			Level 4 vs. Previous	18,808	1	18,808	15,368	,002
Error(SPK)	Level 2 vs. Level 1	22,414	13	1,724			
			Level 3 vs. Previous	26,030	13	2,002			
			Level 4 vs. Previous	15,911	13	1,224			

This is the result in R:
Error: sub
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 13 205.79   15.83

Error: Within
          Df Sum Sq Mean Sq F value    Pr(>F)
spk        3 29.425   9.808  9.4467 8.055e-05 ***
spk: p   1  1.747   1.747  1.6821 0.2022649
spk: q   1 13.572  13.572 13.0719 0.0008479 ***
spk: r   1 14.106  14.106 13.5861 0.0006915 ***
Residuals 39 40.493   1.038
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1



Spk.df <- data.frame(sub,spk,erp)
subset(Spk.df, subset=(sub!="14oddball" & sub!="18odd" & sub!="19odd" & 
sub!="20oddball")) -> Spk.selected.df
contrasts(Spk.selected.df$spk) <- contr.sdif(4)
aov(erp ~ spk + Error(sub), data=Spk.selected.df) -> Spk.aov
summary(Spk.aov,data=Spk.selected.df,split=list(spk=list(p=1,q=2,r=3)))

this is the the beginning of the dataframe, which I use:
         sub  spk    erp
1  10oddball spk1  2.587
2  11oddball spk1 -0.335
3  12oddball spk1  5.564
5  15oddball spk1  0.691
6  17oddball spk1 -1.846
10 21oddball spk1  1.825
11 22oddball spk1  0.370
12  2oddball spk1  3.234
13  3oddball spk1  1.462
14  5oddball spk1  2.535
15  6oddball spk1  9.373
16  7oddball spk1  2.132
17  8oddball spk1 -0.518
18  9oddball spk1  2.450
19 10oddball spk2  2.909
20 11oddball spk2  0.708
21 12oddball spk2  4.684
23 15oddball spk2  3.599
...



From spencer.graves at pdf.com  Sun Jan 11 17:35:19 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 11 Jan 2004 08:35:19 -0800
Subject: [R] Wavelet on time series.
In-Reply-To: <4000E2AB.2060009@macau.ctm.net>
References: <4000E2AB.2060009@macau.ctm.net>
Message-ID: <40017B47.3090002@pdf.com>

      I just got 31 hits by searching for "wavelet time series" at 
www.r-project.org -> search -> "R site search".  Have you tried that? 

      hope this helps.  spencer graves

allanlao wrote:

> Dear Sir/ Madam,
>
> I am new to R. I would like to make a wavelet analysis on the 
> temperature data from 1901-2003. Is there any example about wavelet 
> analyst on the time-series data.
>
> Allan Lao
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Sun Jan 11 18:07:41 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 11 Jan 2004 17:07:41 +0000 (GMT)
Subject: [R] newbie question on contrasts and aov
In-Reply-To: <200401111727.33138.wolfgangpauli@web.de>
Message-ID: <Pine.LNX.4.44.0401111656250.18224-100000@gannet.stats>

Notice  `SPKType III Sum of Squares'.  I don't believe your contrasts are 
orthogonal, and R's are sequential sum of squares.

Also, are you sure these are the same contrasts?  I presume this is
contr.sdif from MASS (in which case it is churlish not to credit it), and
SPSS's contrasts look more like Helmert contrasts from their labelling.

Since it appears all your treatments are within subjects you do seem to be 
making life difficult for yourself. Although I would have done a simple 
fixed-effects analysis, applying summary.lm to the bottom stratum would 
give you simple t-tests for each contrast, including actual estimates of 
the magnitudes.

On Sun, 11 Jan 2004, Wolfgang Pauli wrote:

> I try to move from SPSS to R/S and am trying to reproduce the results of SPSS 
> in R. I calculated a one-way anova with "spk" as experimental factor and erp 
> as depended variable. 
> The result of the Anova are the same concearning the mean square, F and p 
> values. But I also wanted to caculate the contr.sdif(4) contrast on spk. The 
> results are completely different now. I hope anybody can help me.
> 
> Thanks, Wolfgang
> 
> This is what I get in SPSS:
> Tests of Within-Subjects Contrasts
> Measure: MEASURE_1 
> Source		SPKType III Sum of Squares	df	Mean Square	F	Sig.
> SPK		Level 2 vs. Level 1	3,493	1	3,493	2,026	,178
> 			Level 3 vs. Previous	20,358	1	20,358	10,168	,007
> 			Level 4 vs. Previous	18,808	1	18,808	15,368	,002
> Error(SPK)	Level 2 vs. Level 1	22,414	13	1,724			
> 			Level 3 vs. Previous	26,030	13	2,002			
> 			Level 4 vs. Previous	15,911	13	1,224			
> 
> This is the result in R:
> Error: sub
>           Df Sum Sq Mean Sq F value Pr(>F)
> Residuals 13 205.79   15.83
> 
> Error: Within
>           Df Sum Sq Mean Sq F value    Pr(>F)
> spk        3 29.425   9.808  9.4467 8.055e-05 ***
> spk: p   1  1.747   1.747  1.6821 0.2022649
> spk: q   1 13.572  13.572 13.0719 0.0008479 ***
> spk: r   1 14.106  14.106 13.5861 0.0006915 ***
> Residuals 39 40.493   1.038
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> 
> 
> 
> Spk.df <- data.frame(sub,spk,erp)
> subset(Spk.df, subset=(sub!="14oddball" & sub!="18odd" & sub!="19odd" & 
> sub!="20oddball")) -> Spk.selected.df
> contrasts(Spk.selected.df$spk) <- contr.sdif(4)
> aov(erp ~ spk + Error(sub), data=Spk.selected.df) -> Spk.aov
> summary(Spk.aov,data=Spk.selected.df,split=list(spk=list(p=1,q=2,r=3)))
> 
> this is the the beginning of the dataframe, which I use:
>          sub  spk    erp
> 1  10oddball spk1  2.587
> 2  11oddball spk1 -0.335
> 3  12oddball spk1  5.564
> 5  15oddball spk1  0.691
> 6  17oddball spk1 -1.846
> 10 21oddball spk1  1.825
> 11 22oddball spk1  0.370
> 12  2oddball spk1  3.234
> 13  3oddball spk1  1.462
> 14  5oddball spk1  2.535
> 15  6oddball spk1  9.373
> 16  7oddball spk1  2.132
> 17  8oddball spk1 -0.518
> 18  9oddball spk1  2.450
> 19 10oddball spk2  2.909
> 20 11oddball spk2  0.708
> 21 12oddball spk2  4.684
> 23 15oddball spk2  3.599
> ...
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Mon Jan 12 04:22:32 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 11 Jan 2004 22:22:32 -0500
Subject: [R] [R-pkgs] new version of randomForest (4.0-7)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF75EB@usrymx25.merck.com>

Dear R users,

I've just released a new version of randomForest (available on CRAN now).
This version contained quite a number of new features and bug fixes,
compared to version prior to 4.0-x (and few more since 4.0-1).

For those not familiar with randomForest, it's an ensemble
classifier/regression tool.  Please see
http://www.math.usu.edu/~adele/forests/ for more detailed information, as
well as the Fortran code.

Comments/questions/bugs reports/patches much appreciated! 

A few notes about the new version:

o  There is a new tuneRF() function for searching for the optimal mtry,
following Breiman's suggestion.  PLEASE use it to see if result can be
improved!

o  A new variable importance measure replaces the one based on margin.  This
new measure is the same as in Breiman's V5.  The analogous measure is also
implemented for regression.  This new measure is designed to be more robust
against data where predictor variables have very different number of
possible splits (i.e., unique values/categories).  The previous measure
tends to make variables with more possible splits look more important.

o  For classification, the new meassure is also computed on a per-class
basis.

o  There is the new `sampsize' option for down-sampling larger classes.
E.g., if in a two-class problem, there are 950 class 1s and 50 class 2s, use
sampsize=c(50, 50) will usually give a more `balanced' classifier.

o  There is a new importance() function for extracting the importance
measure.

o  The predict() method has an option to return predictions by the component
trees.

o  There is a new getTree() function for looking at one of the trees in the
forest. 

o  For dealing with missing values in the predictor variables, there are
na.roughfix() and rfImpute(), which correspond to the `missquick' and
`missright' options in Breiman's V4/V5 code.  Both works for classification
as well as regression.

o  There is an experimental bias reduction step in regression (the corr.bias
argument in randomForest) that could be very effective for some data (but
essentially no effect for some others).


Some notes about differences between the package and Breiman's Fortran code:

o  Breiman uses the class weights to cast weighted votes.  This is not done
in the R version.  However, one can use the threshold argument to
randomForest to get similar (but not exactly the same) effect.

o  In Breiman's V4/V5 code, the Gini-based importance is weighted by the
out-of-bag data.  This has not been implemented in the R version.

o  Breiman's V4/V5 code can handle categorical predictors with more than 32
categories.  This has not been implemented in the R version.

o  Breiman's classification code uses mtry differently than the R version:
the mtry variables are sampled *with replacement* at each node.  The R
version samples without replacement, so that if mtry is set to number of
predictors, one gets the same result as bagging.  Breiman's regression code
*does* sample the variables without replacement.

o  In the R version, ties are randomly broken when finding best variables,
or when making predictions.  In Breiman's code, the first one found wins.

o  The `prototypes' Breiman described have not been implemented.  There are
situations when they can be misleading, so I have chosen not to implement
it.

o  The `interaction detection' feature in Breiman's V5 has not been
implemented (but is fairly high on my to-do list).


Best,
Andy


Andy Liaw, PhD
Biometrics Research      PO Box 2000, RY33-300     
Merck Research Labs           Rahway, NJ 07065
mailto:andy_liaw at merck.com        732-594-0820




------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From Eric.Kort at vai.org  Mon Jan 12 05:42:10 2004
From: Eric.Kort at vai.org (Kort, Eric)
Date: Sun, 11 Jan 2004 23:42:10 -0500
Subject: [R] Wrote new tiff package, would like big-endian tiffs for testing
Message-ID: <74D0F0AB07F2E647A02D839ED79520F9208885@VAIEXCH02.vai.org>

Over the years I have noted a couple of people interested in an R package that will read tiff files.  There were some valid arguments against (e.g. R is not an image editting suite, libtiff does not support all tiff files, etc.).  True enough, when I want to work with family photos, I use Gimp.  But in my research I use tiffs as data sets in the context of computational biology and molecular epidemiology.  The results of my analyses in this case will not be mailed to family members, but used in subsequent statistical analyses.  For this reason, I like to be able to read my images from within R.

So, with that long-winded introduction, I am writing to r-help today because I have implemented a package that reads tiffs and returns the image data as a pixmap object (with additional slots for the original raw data that has NOT be rescaled to 0-1 occurs in the pixmap data slots for plotting).  I based the package on libtiff, not because it is perfect, but because it is efficient and will allow access to a broad, even if not comprehensive, range of tiff images. (By the way, one problem with libtiff is that its TIFFReadRGBAImage function truncates 16 bit images to 8 bits...my library circumvents this path for 16bit images, thus maintaining the full 16bit data--at least for non-tiled images).

What I am in need in, however, are "big-endian" (byte order=MM), 16-bit tiff files to test my package against.  Working exclusively with intel processors, I only have little endian tiffs (and the test images that come with libtiff all seem to be little endian as well).  Does anyone have a couple such images you can send me?

If any of you are interested in testing out my (still pretty alpha) package, please feel free to contact me.  While at the moment it only reads tiffs, I plan to add tiff writing functionality soon (writing a tiff is, after all, much simpler than reading one because of all the variations you must be prepared for in reading).

Sorry for the length.  Thanks for the help.

Eric Kort
eric.kort at vai.org
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential information.  Any unauthorized review, use, disclosure or distribution is prohibited.  If you are not the intended recipient(s) please contact the sender by reply email and destroy all copies of the original message.  Thank you.



From hi_ono2001 at ybb.ne.jp  Mon Jan 12 06:01:56 2004
From: hi_ono2001 at ybb.ne.jp (Hisaji Ono)
Date: Mon, 12 Jan 2004 14:01:56 +0900
Subject: [R] Wrote new tiff package,
	would like big-endian tiffs for testing
References: <74D0F0AB07F2E647A02D839ED79520F9208885@VAIEXCH02.vai.org>
Message-ID: <002201c3d8c9$33cfac20$818001db@webgis>

Hi.

 Do you know RGDAL(http://rgdal.sourceforge.net/) which can read Tiff files?

> So, with that long-winded introduction, I am writing to r-help today
because I have implemented a package that reads tiffs and returns the image
data as a pixmap object (with additional slots for the original raw data
that has NOT be rescaled to 0-1 occurs in the pixmap data slots for
plotting).  I based the package on libtiff, not because it is perfect, but
because it is efficient and will allow access to a broad, even if not
comprehensive, range of tiff images. (By the way, one problem with libtiff
is that its TIFFReadRGBAImage function truncates 16 bit images to 8
bits...my library circumvents this path for 16bit images, thus maintaining
the full 16bit data--at least for non-tiled images).



From wgbeldman at student.han.nl  Mon Jan 12 10:15:50 2004
From: wgbeldman at student.han.nl (W. Beldman)
Date: Mon, 12 Jan 2004 10:15:50 +0100
Subject: [R] Matrix indexes
Message-ID: <1073898950.400265c685da0@webmail.han.nl>

Two questions about matrix indexing:

Is is correct that   V <- V[lower.tri(V, diag=TRUE)]   returns the lower 
triangular of matrix V, that is: all elements above diagonal are set to zero? I 
understand that the triangle of matrix elements of V for which lower.tri is 
TRUE are returned while the others (above diagonal) are set to zero (or NA ???).



If D and B are vectors of logicals,
what does  V  contain after   V <- v[D, B, drop=FALSE]   ?
I guess that elements are returned if both indexes D and B are TRUE, but I'm 
not really convinced... (And again, what about the other elements?)




These are probably tutorial questions, but I'm still not sure after reading "R 
Language Definition (draft): Evaluation of expressions" and applicable sections 
of "The R Reference Manual". Thanx!

W. Beldman



From ripley at stats.ox.ac.uk  Mon Jan 12 11:17:03 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Jan 2004 10:17:03 +0000 (GMT)
Subject: [R] Matrix indexes
In-Reply-To: <1073898950.400265c685da0@webmail.han.nl>
Message-ID: <Pine.LNX.4.44.0401121006310.28529-100000@gannet.stats>

On Mon, 12 Jan 2004, W. Beldman wrote:

> Two questions about matrix indexing:

Not about `matrix indexing', which may have confused you.  Matrix indexing
of a matrix is when the index is a two-column matrix of row-column number
pairs.

> Is is correct that   V <- V[lower.tri(V, diag=TRUE)]   returns the lower 
> triangular of matrix V, that is: all elements above diagonal are set to zero? I 

No, omitted.

> understand that the triangle of matrix elements of V for which lower.tri is 
> TRUE are returned while the others (above diagonal) are set to zero (or NA ???).

So this is vector indexing by a logical vector.  It does no harm to try 
it:

> V <- matrix(1:16, 4,4)
> V
     [,1] [,2] [,3] [,4]
[1,]    1    5    9   13
[2,]    2    6   10   14
[3,]    3    7   11   15
[4,]    4    8   12   16
> lower.tri(V, diag=TRUE)
     [,1]  [,2]  [,3]  [,4]
[1,] TRUE FALSE FALSE FALSE
[2,] TRUE  TRUE FALSE FALSE
[3,] TRUE  TRUE  TRUE FALSE
[4,] TRUE  TRUE  TRUE  TRUE
> V[lower.tri(V, diag=TRUE)]
 [1]  1  2  3  4  6  7  8 11 12 16

so the result is the lower triangle read out as a vector in the usual
first-index-varies fastest order.

> If D and B are vectors of logicals,
> what does  V  contain after   V <- v[D, B, drop=FALSE]   ?
> I guess that elements are returned if both indexes D and B are TRUE, but I'm 
> not really convinced... (And again, what about the other elements?)

Yes. Again, simple example:

> B <- c(T, F, T, F)
> D <- c(T, T, F, F)
> outer(B, D)
     [,1] [,2] [,3] [,4]
[1,]    1    1    0    0
[2,]    0    0    0    0
[3,]    1    1    0    0
[4,]    0    0    0    0
> V[B, D]
     [,1] [,2]
[1,]    1    5
[2,]    3    7


And finally an example of matrix indexing

> U <- matrix(c(1,1,2,3), 2, 2, byrow=T)
> U
     [,1] [,2]
[1,]    1    1
[2,]    2    3
> V[U]
[1]  1 10


> These are probably tutorial questions, but I'm still not sure after reading "R 
> Language Definition (draft): Evaluation of expressions" and applicable sections 
> of "The R Reference Manual". Thanx!

Some of the books in the FAQ, notably `S Programming', will help a lot.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bitwrit at ozemail.com.au  Sun Jan 11 12:42:32 2004
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Sun, 11 Jan 2004 22:42:32 +1100
Subject: [R] Error in R-1.8.1 build
In-Reply-To: <Pine.LNX.4.44.0401110813180.28899-100000@gannet.stats>
References: <Pine.LNX.4.44.0401110813180.28899-100000@gannet.stats>
Message-ID: <20040112111458.SECJ29090.smta09.mail.ozemail.net@there>

Prof Brian Ripley wrote:

> You got a segmentation fault from the compiler.  It is the notorious gcc
> `2.96' (see gcc.gnu.org -- there is no such version according to the gcc
> developers).  It used to be a frequent source of grief (but then RedHat
> 7.2 is old now), and the advice is to use a released version of gcc.
>...

Thanks, gcc v3.2.3 in RedHat's Enterprise 3 Linux worked fine.

Jim



From stanghel at stat.unipg.it  Mon Jan 12 12:38:37 2004
From: stanghel at stat.unipg.it (Elena Stanghellini)
Date: Mon, 12 Jan 2004 12:38:37 +0100 (MET)
Subject: [R] Help on Discriminant analysis
Message-ID: <Pine.SOL.4.50.0401121232430.16501-100000@pearson.stat.unipg.it>

Dear All,

I wonder if there are routines in R to perform any test to discarding
variables from a function to discriminate between two multinormal
populations (such as e.g. Rao test , 1973, explained in Mardia Kent and
Bibby 1979, pag. 323).

Many thanks in advance, Elena
**********************************************
Elena Stanghellini
Dipartimento di Scienze Statistiche
Via A. Pascoli - C.P. 1315 Succ. 1
06100 Perugia (Italy)

Tel +39 075 5855229 or 5855242
Fax +39 075 5855950

email: elena.stanghellini at stat.unipg.it
home page: http://www.stat.unipg.it/DSS/html/elena.html



From Enrico.Curiotto at aem.torino.it  Mon Jan 12 12:57:13 2004
From: Enrico.Curiotto at aem.torino.it (Enrico Curiotto)
Date: Mon, 12 Jan 2004 12:57:13 +0100
Subject: [R] (no subject)
Message-ID: <s00299be.033@pegaso.aem.torino.it>



From bearedj at marlab.ac.uk  Mon Jan 12 13:33:56 2004
From: bearedj at marlab.ac.uk (Doug Beare)
Date: 12 Jan 2004 12:33:56 +0000
Subject: [R] barplots with no lines around each bar
Message-ID: <1073910836.410.144.camel@pclnx6.marlab.ac.uk>



Hi,
I want to do a barplot with no black lines drawn around each bar and no 
space between each bar. I can do the nospace bit but keep getting black
line around each bar no matter what I try.
Ie. for a red bar I want a red border, for a yellow bar a yellow border 
and so on. I've tried everything I can think of but no luck. Any 
suggestions? At the moment I'm using R 5.1 under Redhat Linux 8.
Regards,
Doug Beare.



From Eric.Kort at vai.org  Mon Jan 12 13:45:25 2004
From: Eric.Kort at vai.org (Kort, Eric)
Date: Mon, 12 Jan 2004 07:45:25 -0500
Subject: [R] Wrote new tiff package,
	would like big-endian tiffs for testing
Message-ID: <74D0F0AB07F2E647A02D839ED79520F9208886@VAIEXCH02.vai.org>

> -----Original Message-----
> From: Hisaji Ono [mailto:hi_ono2001 at ybb.ne.jp]
> 
> 
> Hi.
> 
>  Do you know RGDAL(http://rgdal.sourceforge.net/) which can 
> read Tiff files?

Yes.  Thanks for mentioning this excellent alternative.  This may be a fine solution for some/many/most/nearly all people.  However, I still think it would be elegant for those not doing geospatial research to have a stand alone tiff package, and one that does not require GDAL libraries, etc, to compile and install.  For one thing, since my embryonic package is focused solely on TIFFs, it allows close attention to be paid to things like bit preservation (at least in theory).  I would bet $1 U.S. that this is an attractive solution for at least 3 people in the known universe.  I only hope all three of those people aren't me.

But, obviously, to each his/her own.

-Eric

> 
> > So, with that long-winded introduction, I am writing to r-help today
> because I have implemented a package that reads tiffs and 
> returns the image
> data as a pixmap object (with additional slots for the 
> original raw data
> that has NOT be rescaled to 0-1 occurs in the pixmap data slots for
> plotting).  I based the package on libtiff, not because it is 
> perfect, but
> because it is efficient and will allow access to a broad, even if not
> comprehensive, range of tiff images. (By the way, one problem 
> with libtiff
> is that its TIFFReadRGBAImage function truncates 16 bit images to 8
> bits...my library circumvents this path for 16bit images, 
> thus maintaining
> the full 16bit data--at least for non-tiled images).
> 
> 
This email message, including any attachments, is for the so...{{dropped}}



From ripley at stats.ox.ac.uk  Mon Jan 12 14:40:00 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Jan 2004 13:40:00 +0000 (GMT)
Subject: [R] barplots with no lines around each bar
In-Reply-To: <1073910836.410.144.camel@pclnx6.marlab.ac.uk>
Message-ID: <Pine.LNX.4.44.0401121328240.1741-100000@gannet.stats>

On 12 Jan 2004, Doug Beare wrote:

> I want to do a barplot with no black lines drawn around each bar and no
> space between each bar. I can do the nospace bit but keep getting black
> line around each bar no matter what I try.
> Ie. for a red bar I want a red border, for a yellow bar a yellow border
> and so on. I've tried everything I can think of but no luck. Any
> suggestions? At the moment I'm using R 5.1 under Redhat Linux 8.

It is a bit difficult for us to help you, as we've only got to R 1.8.1 and
are unskilled in time travel.  But in that version the most obvious thing,
namely

barplot(1:5, space=0, col="red", border="red")

works.  Perhaps it will get broken at some time in the future?

[If perchance you meant R 1.5.1, you are well overdue for an update as
there have been 7 releases since.]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bbonsu at columbus.rr.com  Mon Jan 12 15:07:59 2004
From: bbonsu at columbus.rr.com (Bema Bonsu)
Date: Mon, 12 Jan 2004 09:07:59 -0500
Subject: [R] re: help with Hmisc/ Design installation in R-aqua (apple).
Message-ID: <BC28146F.4E1%bbonsu@columbus.rr.com>

Hello, everyone. I am new at this, but having a great time using R.

I have, however, run into a small problem.

I have tried, unsuccessfully, to install the Hmisc and Design libraries
(Harrell FE Jr) in R-aqua (Apple). These libraries are in source code only
(i.e. not yet in ready-to-use binary format). Unfortunately, when I download
the libraries in source format and attempt to install them directly or
manually, I get an error message that states the following:

Warning messages: 
1: Installation of package Design had non-zero exit status in:
install.packages(ui.pkgs, CRAN = getOption(where), lib = .libPaths()[1])
2: Installation of package Hmisc had non-zero exit status in:
install.packages(ui.pkgs, CRAN = getOption(where), lib = .libPaths()[1])

I would be grateful for any assistance in getting around this problem.

Thanks

Bema Bonsu
Ohio State University.



From ryszard.czerminski at pharma.novartis.com  Mon Jan 12 15:15:12 2004
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Mon, 12 Jan 2004 09:15:12 -0500
Subject: [R] tune(): how to specify a kernel ?
Message-ID: <OFF43E1AD8.93143CFB-ON85256E19.004E16EB-85256E19.004E6A84@EU.novartis.net>

I would like to use tune() for tuning parameters for svm method, but it is 
not clear
to me how to specify a kernel.

I am trying to use something like this:

> obj <- tune(svm, Species~., data = iris, ranges = list(kernel = 
c('radial', 'linear')))
Error in pmatch(x, table, duplicates.ok) :
        argument is not of mode character

but it generates an error.

Ryszard



From dieter.menne at menne-biomed.de  Mon Jan 12 15:20:27 2004
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 12 Jan 2004 15:20:27 +0100
Subject: [R] GLMM (lme4) vs. glmmPQL output
Message-ID: <JLEPLGAANFCEAEDCAGJNIEDLCHAA.dieter.menne@menne-biomed.de>

Goran,

from my reply to a message from Douglas Bates; ">" is quoted from a mail by
DG.

> I believe the distinction is explained in the lme4 documentation but,
> in any case, the standard errors and the approximate log-likelihood
> for glmmPQL are from the lme model that is the last step in the
> optimization.  The corresponding quantities from GLMM are from another
> approximation that should be more reliable.

I have compared glmmPQL, glmmML, geese and GLMM, results and code see below.
I am aware that glmmPQL uses another method to handle the problem, and
geese (geepack) has considerable different assumptions, but the
results are very similar. On the other hand, I had expected that glmmML
results, if reasonable at all, should be close to GLMM. Yet they are not,
but rather come close to the other three.

See for example the last factor (I(week>2): significant effects in all
cases except GLMM.

-----------------------------
(glmmPQL)
Fixed effects: y ~ trt + I(week > 2)
                Value Std.Error  DF t-value p-value
(Intercept)      3.41     0.519 169    6.58  0.0000
trtdrug         -1.25     0.644  47   -1.94  0.0588
trtdrug+        -0.75     0.645  47   -1.17  0.2484
I(week > 2)TRUE -1.61     0.358 169   -4.49  0.0000

(glmmML)
                  coef se(coef)     z Pr(>|z|)
(Intercept)      3.579    0.701  5.10  3.3e-07
trtdrug         -1.369    0.694 -1.97  4.8e-02
trtdrug+        -0.789    0.700 -1.13  2.6e-01
I(week > 2)TRUE -1.627    0.482 -3.38  7.3e-04

(geese from geepack)
                estimate san.se  wald        p
(Intercept)        2.844  0.529 28.92 7.56e-08
trtdrug           -1.113  0.586  3.61 5.76e-02
trtdrug+          -0.634  0.544  1.36 2.44e-01
I(week > 2)TRUE   -1.325  0.368 12.96 3.18e-04

(GLMM)
                 Estimate Std. Error  DF z value Pr(>|z|)
(Intercept)       3.41202    3.93293 169  0.8676   0.3856
trtdrug          -1.24736    1.52156  47 -0.8198   0.4123
trtdrug+         -0.75433    1.21963  47 -0.6185   0.5363
I(week > 2)TRUE  -1.60726    2.19660 169 -0.7317   0.4644

---------------
data(bacteria,package="MASS")
UseMASS<-F# must restart R after changing because of nlme/lme4 clash
if (UseMASS){
  library(MASS) # required for bacteria
  options(digits=3)
  print(summary(glmmPQL(y ~ trt + I(week > 2), random = ~ 1 | ID,
                  family = binomial, data = bacteria)))
  library(glmmML)
  print(glmmML(y=="y"~trt+I(week>2), data=bacteria,cluster=bacteria$ID))
  library(geepack)
  summary(geese(y == "y" ~ trt + I(week > 2), family = binomial,
     id = ID, corstr = "exchangeable",data=bacteria))
} else
{
  library(lme4)
  # try a well documented "old" lme to compare lme4/lme3 for normal things
#  data(Orthodont,package=nlme)
#  fm <- lme(distance ~ Sex*I(age-11), data =
Orthodont,random=~I(age-11)|Subject)
#  summary(fm)
  summary(GLMM(y ~ trt + I(week > 2), random = ~ 1 | ID,
                  family = binomial, data = bacteria,method="PQL"))
 }



From p.dalgaard at biostat.ku.dk  Mon Jan 12 16:24:34 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 Jan 2004 16:24:34 +0100
Subject: [R] GLMM (lme4) vs. glmmPQL output
In-Reply-To: <JLEPLGAANFCEAEDCAGJNIEDLCHAA.dieter.menne@menne-biomed.de>
References: <JLEPLGAANFCEAEDCAGJNIEDLCHAA.dieter.menne@menne-biomed.de>
Message-ID: <x2k73xqjf1.fsf@biostat.ku.dk>

"Dieter Menne" <dieter.menne at menne-biomed.de> writes:

> I have compared glmmPQL, glmmML, geese and GLMM, results and code see below.
> I am aware that glmmPQL uses another method to handle the problem, and
> geese (geepack) has considerable different assumptions, but the
> results are very similar. On the other hand, I had expected that glmmML
> results, if reasonable at all, should be close to GLMM. Yet they are not,
> but rather come close to the other three.

I suspect that a small simulation study would be enlightening. Given
the experimental status of lme4, I wouldn't feel too sure that there
is agreement between theory and implementation. There might be a bug
there, or maybe all the other methods make essentially the same
(large) error. In either case, I'd certainly like to know the reason.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From wingen.luzie at mh-hannover.de  Mon Jan 12 16:29:25 2004
From: wingen.luzie at mh-hannover.de (Luzie U. Wingen)
Date: Mon, 12 Jan 2004 16:29:25 +0100
Subject: [R] ReadLines does not give results with urls
Message-ID: <20040112152925.GA3721@avocado.w2k>

Hello,

I am using R version 1.8.1 on a linux machine (Suse 8.2.).
I have problems to use readLines() with urls.

This seems to be a problem with our proxy-server. 
Downloading files work with download.file() with wget but not without:

> download.file(url = "http://cran.r-project.org/src/contrib/PACKAGES", destfile = "test.txt", method = "wget", cacheOK = FALSE)
This works!

> download.file(url = "http://cran.r-project.org/src/contrib/PACKAGES", destfile = "test.txt", cacheOK = FALSE)
This does not work!

For readLines() there seems not to be the possibility to use wget.
So I can only read the local pages which are accessible without proxy-server
but not:

> readLines(url("http://cran.r-project.org/src/contrib/PACKAGES"))
This does give the following response after 60 sec:
>Error in readLines(url("http://cran.r-project.org/src/contrib/PACKAGES"),  : 
        cannot open the connection
>In addition: Warning message: 
>unable to connect to 'cran.r-project.org' on port 80. 

After reading the help pages I checked the http_proxy environmental 
variable, which seems to be OK to me:

> Sys.getenv("http_proxy")
    http_proxy 
		"http://proxy.mh-hannover.de:8080/" 
> Sys.getenv("no_proxy")
		no_proxy 
    "" 

Setting the options options(download.file.method="wget") helps
for download.file() but not for "readLines().

Does anybody has a further idea, how to manipulate readLines()
so that it uses the proxy-server?

Thank you

Luzie
-- 
Luzie U. Wingen, Institut fuer Zell- und Molekularpathologie,
Medizinische Hochschule Hannover, Carl-Neuberg-Str. 1, 30625 Hannover,
Tel.: (+49) 0511-532-9432, Fax: -4521, Email: wingen.luzie at mh-hannover.de



From jahaye at wm.edu  Mon Jan 12 17:25:24 2004
From: jahaye at wm.edu (John Hayes)
Date: Mon, 12 Jan 2004 11:25:24 -0500
Subject: [R] source problem
Message-ID: <1073924724.32620.36.camel@xizor.incogen.com>

Hi,

I'm trying to call an R script from the command-line ("firstScript.r"
below).  This script then sources another script in another directory
using the absolute path to the file
("/home/john/R_script/secondScript.r").  That script then needs to
source an R script in the same directory using a relative path
("thirdScript.r").   Neither script should know that it is being
sourced.  For example,

/usr/local/algo/R/script/firstScript.r 
/home/john/R_script/secondScript.r
/home/john/R_script/thirdScript.r

However, I am getting a message that this last file cannot be found. 
I've changed the chdir and local attributes of source to TRUE and this
does not seem to change the behavior.  Is there a way to do this without
passing the absolute path to the R files around?  Thanks for any help
you can offer.

John



From therneau at mayo.edu  Mon Jan 12 17:58:14 2004
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 12 Jan 2004 10:58:14 -0600 (CST)
Subject: [R] graphlets
Message-ID: <200401121658.i0CGwEb15582@natasha.mayo.edu>

  I have an application where the Splus graphlets() package would work
very well, and would like to know if there is any comparable work in 
R.  In response to a similar query on this list about 1.5 years ago the
Orca package was mentioned, but it seems to be inactive.
  For those who don't know, graphlets are an extended java graphics
device.  The identify function, for instance, allows one to link both
a label and a set of html links to each point.  I am aware of the
Sjava package in Omega, and am exploring that, but would be very interested
if there is anything more.
	Terry Therneau
	Mayo Clinic



From jahaye at wm.edu  Mon Jan 12 18:01:14 2004
From: jahaye at wm.edu (John Hayes)
Date: Mon, 12 Jan 2004 12:01:14 -0500
Subject: [R] source problem
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572F02178@synequanon01>
References: <6C8A8033ABC1E3468048ABC4F13CE572F02178@synequanon01>
Message-ID: <1073926874.32620.48.camel@xizor.incogen.com>

Thanks for the quick response!  

That's essentially how I was expecting to have to do it in the worst
case.  However, I was thinking that setting the chdir = TRUE should have
taken care of this for me.  Is this a bug?  Or am I using it
incorrectly?  It seems like we shouldn't have to pass the paths around
like that.  

John  

On Mon, 2004-01-12 at 11:39, Simon Fear wrote:
> I would sidestep the issue by using explicit paths at all times
> but keeping the directory roots in variables; e.g.
> 
> firstPath <- "/usr/local/algo/R/script/f"
> secondPath <- "/home/john/R_script/"
> 
> and then you can call things like
> 
> source(paste(firstpath, "firstScript.r", sep="")
> 
> This scheme does require the pathnames to be set when called.
> If you wanted your second script to run stand-alone you would
> have to put in a test such as
> 
> if (!exists(secondPath)) secondPath <- "/home/john/R_script/"
> 
> but I find it easier to define such things in .first or
> some other file I *always* source before working on the
> project. (Actually I create a list of them, which I call global.pathnames.)
> 
> HTH
> 
> > -----Original Message-----
> > From: John Hayes [mailto:jahaye at wm.edu]
> > Sent: 12 January 2004 16:25
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] source problem
> > 
> > 
> > Security Warning: 
> > If you are not sure an attachment is safe to open please contact  
> > Andy on x234. There are 0 attachments with this message. 
> > ________________________________________________________________ 
> >  
> > Hi,
> > 
> > I'm trying to call an R script from the command-line ("firstScript.r"
> > below).  This script then sources another script in another directory
> > using the absolute path to the file
> > ("/home/john/R_script/secondScript.r").  That script then needs to
> > source an R script in the same directory using a relative path
> > ("thirdScript.r").   Neither script should know that it is being
> > sourced.  For example,
> > 
> > /usr/local/algo/R/script/firstScript.r 
> > /home/john/R_script/secondScript.r
> > /home/john/R_script/thirdScript.r
> > 
> > However, I am getting a message that this last file cannot be found. 
> > I've changed the chdir and local attributes of source to TRUE and this
> > does not seem to change the behavior.  Is there a way to do 
> > this without
> > passing the absolute path to the R files around?  Thanks for any help
> > you can offer.
> > 
> > John
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >  
>  
> Simon Fear 
> Senior Statistician 
> Syne qua non Ltd 
> Tel: +44 (0) 1379 644449 
> Fax: +44 (0) 1379 644445 
> email: Simon.Fear at synequanon.com 
> web: http://www.synequanon.com
>   
> Number of attachments included with this message: 0 
>   
> This message (and any associated files) is confidential and  
> contains information which may be legally privileged.  It is  
> intended for the stated addressee(s) only.  Access to this  
> email by anyone else is unauthorised.  If you are not the  
> intended addressee, any action taken (or not taken) in  
> reliance on it, or any disclosure or copying of the contents of  
> it is unauthorised and unlawful.  If you are not the addressee,  
> please inform the sender immediately and delete the email  
> from your system. 
>  
> This message and any associated attachments have been  
> checked for viruses using an internationally recognised virus  
> detection process.  However, Internet communications cannot  
> be guaranteed to be secure or error-free as information could  
> be intercepted, corrupted, lost, destroyed, arrive late or  
> incomplete. Therefore, we do not accept responsibility for any  
> errors or omissions that are present in this message, or any  
> attachment, that have arisen as a result of e-mail transmission.   
> If verification is required, please request a hard-copy version.  
> Any views or opinions presented are solely those of the author  
> and do not necessarily represent those of Syne qua non. 
>  
> 
>



From ripley at stats.ox.ac.uk  Mon Jan 12 18:01:54 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Jan 2004 17:01:54 +0000 (GMT)
Subject: [R] GLMM (lme4) vs. glmmPQL output
In-Reply-To: <JLEPLGAANFCEAEDCAGJNIEDLCHAA.dieter.menne@menne-biomed.de>
Message-ID: <Pine.LNX.4.44.0401121652540.1729-100000@gannet.stats>

Although it has not been stated nor credited, this is very close to an
example in MASS4 (there seems a difference in coding).  Both the dataset 
and much of the alternative analyses are from the work of my student James 
McBroom (and other students have contributed).

MASS4 does contain comparisons with other methods, including our
implementation of the `gold standards', numerical ML and Bayes posterior
densities with a vague prior.  We have also run this example against
several other implementations and simulated from the fitted (by numerical
ML) model.  All of our comparisons have suggested that glmmPQL is in the
right ball park, so once I realised the origin of the example the GLMM
results surprised me.

On Mon, 12 Jan 2004, Dieter Menne wrote:

> Goran,
> 
> from my reply to a message from Douglas Bates; ">" is quoted from a mail by
> DG.
> 
> > I believe the distinction is explained in the lme4 documentation but,
> > in any case, the standard errors and the approximate log-likelihood
> > for glmmPQL are from the lme model that is the last step in the
> > optimization.  The corresponding quantities from GLMM are from another
> > approximation that should be more reliable.
> 
> I have compared glmmPQL, glmmML, geese and GLMM, results and code see below.
> I am aware that glmmPQL uses another method to handle the problem, and
> geese (geepack) has considerable different assumptions, but the
> results are very similar. On the other hand, I had expected that glmmML
> results, if reasonable at all, should be close to GLMM. Yet they are not,
> but rather come close to the other three.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Jan 12 18:12:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Jan 2004 17:12:19 +0000 (GMT)
Subject: [R] ReadLines does not give results with urls
In-Reply-To: <20040112152925.GA3721@avocado.w2k>
Message-ID: <Pine.LNX.4.44.0401121705200.1729-100000@gannet.stats>

It is not readLines() that does not work but url().  Have you tried
looking at the increased level of output which is available to see why?
It is described under ?download.file and ?option, option "internet.info".

We can't tell from your diagnostics if no_proxy is set but empty or unset.
It does have to be unset and I believe SuSe systems have a habit of having 
it set but empty.


On Mon, 12 Jan 2004, Luzie U. Wingen wrote:

> Hello,
> 
> I am using R version 1.8.1 on a linux machine (Suse 8.2.).
> I have problems to use readLines() with urls.
> 
> This seems to be a problem with our proxy-server. 
> Downloading files work with download.file() with wget but not without:
> 
> > download.file(url = "http://cran.r-project.org/src/contrib/PACKAGES", destfile = "test.txt", method = "wget", cacheOK = FALSE)
> This works!
> 
> > download.file(url = "http://cran.r-project.org/src/contrib/PACKAGES", destfile = "test.txt", cacheOK = FALSE)
> This does not work!
> 
> For readLines() there seems not to be the possibility to use wget.
> So I can only read the local pages which are accessible without proxy-server
> but not:
> 
> > readLines(url("http://cran.r-project.org/src/contrib/PACKAGES"))
> This does give the following response after 60 sec:
> >Error in readLines(url("http://cran.r-project.org/src/contrib/PACKAGES"),  : 
>         cannot open the connection
> >In addition: Warning message: 
> >unable to connect to 'cran.r-project.org' on port 80. 
> 
> After reading the help pages I checked the http_proxy environmental 
> variable, which seems to be OK to me:
> 
> > Sys.getenv("http_proxy")
>     http_proxy 
> 		"http://proxy.mh-hannover.de:8080/" 
> > Sys.getenv("no_proxy")
> 		no_proxy 
>     "" 
> 
> Setting the options options(download.file.method="wget") helps
> for download.file() but not for "readLines().
> 
> Does anybody has a further idea, how to manipulate readLines()
> so that it uses the proxy-server?
> 
> Thank you
> 
> Luzie
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dominicb at cvs.rochester.edu  Mon Jan 12 18:26:06 2004
From: dominicb at cvs.rochester.edu (Dominic Barraclough)
Date: Mon, 12 Jan 2004 12:26:06 -0500
Subject: [R] question about how summary.lm works
Message-ID: <4.3.1.2.20040112121906.0213f878@cvs.rochester.edu>

Hi,

While exploring how summary.lm generated its output I came across a section 
that left me puzzled.



at around line 57
     R <- chol2inv(Qr$qr[p1, p1, drop = FALSE])
     se <- sqrt(diag(R) * resvar)


I'm hoping somebody could explain the logic of these to steps or 
alternatively point me in the direction of a text that will explain these 
steps.

In particular I'm puzzled what is the relationship between QR factorization 
and the cholesky factorization such that one can give a (sort of ) R matrix 
as a parameter of chol2inv(). I say sort of R matrix as the matrix 
generated by Qr$qr[p1, p1, drop = FALSE] has a lower triangle with non zero 
entries although the upper triangle corresponds to the values in the R matrix.


Thank you

Dominic









summary.lm
function (object, correlation = FALSE, symbolic.cor = FALSE,
     ...)
{
     z <- object
     p <- z$rank
     if (p == 0) {
         r <- z$residuals
         n <- length(r)
         w <- z$weights
         if (is.null(w)) {
             rss <- sum(r^2)
         }
         else {
             rss <- sum(w * r^2)
             r <- sqrt(w) * r
         }
         resvar <- rss/(n - p)
         ans <- z[c("call", "terms")]
         class(ans) <- "summary.lm"
         ans$aliased <- is.na(coef(object))
         ans$residuals <- r
         ans$df <- c(0, n, length(ans$aliased))
         ans$coefficients <- matrix(NA, 0, 4)
         dimnames(ans$coefficients) <- list(NULL, c("Estimate",
             "Std. Error", "t value", "Pr(>|t|)"))
         ans$sigma <- sqrt(resvar)
         ans$r.squared <- ans$adj.r.squared <- 0
         return(ans)
     }
     Qr <- object$qr
     if (is.null(z$terms) || is.null(Qr))
         stop("invalid 'lm' object:  no terms nor qr component")
     n <- NROW(Qr$qr)
     rdf <- n - p
     if (rdf != z$df.residual)
         warning("inconsistent residual degrees of freedom. -- please report!")
     p1 <- 1:p
     r <- z$residuals
     f <- z$fitted
     w <- z$weights
     if (is.null(w)) {
         mss <- if (attr(z$terms, "intercept"))
             sum((f - mean(f))^2)
         else sum(f^2)
         rss <- sum(r^2)
     }
     else {
         mss <- if (attr(z$terms, "intercept")) {
             m <- sum(w * f/sum(w))
             sum(w * (f - m)^2)
         }
         else sum(w * f^2)
         rss <- sum(w * r^2)
         r <- sqrt(w) * r
     }
     resvar <- rss/rdf
     R <- chol2inv(Qr$qr[p1, p1, drop = FALSE])
     se <- sqrt(diag(R) * resvar)
     est <- z$coefficients[Qr$pivot[p1]]
     tval <- est/se
     ans <- z[c("call", "terms")]
     ans$residuals <- r
     ans$coefficients <- cbind(est, se, tval, 2 * pt(abs(tval),
         rdf, lower.tail = FALSE))
     dimnames(ans$coefficients) <- list(names(z$coefficients)[Qr$pivot[p1]],
         c("Estimate", "Std. Error", "t value", "Pr(>|t|)"))
     ans$aliased <- is.na(coef(object))
     ans$sigma <- sqrt(resvar)
     ans$df <- c(p, rdf, NCOL(Qr$qr))
     if (p != attr(z$terms, "intercept")) {
         df.int <- if (attr(z$terms, "intercept"))
             1
         else 0
         ans$r.squared <- mss/(mss + rss)
         ans$adj.r.squared <- 1 - (1 - ans$r.squared) * ((n -
             df.int)/rdf)
         ans$fstatistic <- c(value = (mss/(p - df.int))/resvar,
             numdf = p - df.int, dendf = rdf)
     }
     else ans$r.squared <- ans$adj.r.squared <- 0
     ans$cov.unscaled <- R
     dimnames(ans$cov.unscaled) <- dimnames(ans$coefficients)[c(1,
         1)]
     if (correlation) {
         ans$correlation <- (R * resvar)/outer(se, se)
         dimnames(ans$correlation) <- dimnames(ans$cov.unscaled)
         ans$symbolic.cor <- symbolic.cor
     }
     class(ans) <- "summary.lm"
     ans
}
<environment: namespace:base>



From dieter.menne at menne-biomed.de  Mon Jan 12 18:32:20 2004
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 12 Jan 2004 18:32:20 +0100
Subject: [R] GLMM (lme4) vs. glmmPQL output
In-Reply-To: <Pine.LNX.4.44.0401121652540.1729-100000@gannet.stats>
Message-ID: <JLEPLGAANFCEAEDCAGJNIEDNCHAA.dieter.menne@menne-biomed.de>


Prof Brian Ripley wrote:

> Although it has not been stated nor credited, this is very close to an
> example in MASS4 (there seems a difference in coding).

I apologize for the oversight. This is to state that the code starting

> data(bacteria,package="MASS")
> UseMASS<-F# must restart R after changing because of nlme/lme4 clash
> if (UseMASS){
>   library(MASS) # required for bacteria

is slightly modified from MASS (Modern Applied Statistics, by W.N. Venables
and Prof. B. Ripley, Code in MASS\scripts\ch10.R). ISBN Code upon request.

Dieter Menne



From wingen.luzie at mh-hannover.de  Mon Jan 12 18:44:13 2004
From: wingen.luzie at mh-hannover.de (Luzie U. Wingen)
Date: Mon, 12 Jan 2004 18:44:13 +0100
Subject: [R] ReadLines does not give results with urls
In-Reply-To: <Pine.LNX.4.44.0401121705200.1729-100000@gannet.stats>
References: <20040112152925.GA3721@avocado.w2k>
	<Pine.LNX.4.44.0401121705200.1729-100000@gannet.stats>
Message-ID: <20040112174413.GA4040@avocado.w2k>

OK, that  was the hint I needed:

tcsh> unsetenv no_proxy

did the magic!  Now readLines() works!
The no_proxy variable is empty but present in the normal SuSe system.
Thank you for your help

Luzie


On Mon, Jan 12, 2004 at 05:12:19PM +0000, Prof Brian Ripley wrote:
> It is not readLines() that does not work but url().  Have you tried
> looking at the increased level of output which is available to see why?
> It is described under ?download.file and ?option, option "internet.info".
> 
> We can't tell from your diagnostics if no_proxy is set but empty or unset.
> It does have to be unset and I believe SuSe systems have a habit of having 
> it set but empty.
> 
> 
> On Mon, 12 Jan 2004, Luzie U. Wingen wrote:
> 
> > Hello,
> > 
> > I am using R version 1.8.1 on a linux machine (Suse 8.2.).
> > I have problems to use readLines() with urls.
> > 
> > This seems to be a problem with our proxy-server. 
> > Downloading files work with download.file() with wget but not without:
> > 
> > > download.file(url = "http://cran.r-project.org/src/contrib/PACKAGES", destfile = "test.txt", method = "wget", cacheOK = FALSE)
> > This works!
> > 
> > > download.file(url = "http://cran.r-project.org/src/contrib/PACKAGES", destfile = "test.txt", cacheOK = FALSE)
> > This does not work!
> > 
> > For readLines() there seems not to be the possibility to use wget.
> > So I can only read the local pages which are accessible without proxy-server
> > but not:
> > 
> > > readLines(url("http://cran.r-project.org/src/contrib/PACKAGES"))
> > This does give the following response after 60 sec:
> > >Error in readLines(url("http://cran.r-project.org/src/contrib/PACKAGES"),  : 
> >         cannot open the connection
> > >In addition: Warning message: 
> > >unable to connect to 'cran.r-project.org' on port 80. 
> > 
> > After reading the help pages I checked the http_proxy environmental 
> > variable, which seems to be OK to me:
> > 
> > > Sys.getenv("http_proxy")
> >     http_proxy 
> > 		"http://proxy.mh-hannover.de:8080/" 
> > > Sys.getenv("no_proxy")
> > 		no_proxy 
> >     "" 
> > 
> > Setting the options options(download.file.method="wget") helps
> > for download.file() but not for "readLines().
> > 
> > Does anybody has a further idea, how to manipulate readLines()
> > so that it uses the proxy-server?
> > 
> > Thank you
> > 
> > Luzie
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 

-- 
Luzie U. Wingen, Institut fuer Zell- und Molekularpathologie,
Medizinische Hochschule Hannover, Carl-Neuberg-Str. 1, 30625 Hannover,
Tel.: (+49) 0511-532-9432, Fax: -4521, Email: wingen.luzie at mh-hannover.de



From p.dalgaard at biostat.ku.dk  Mon Jan 12 18:53:27 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 Jan 2004 18:53:27 +0100
Subject: [R] question about how summary.lm works
In-Reply-To: <4.3.1.2.20040112121906.0213f878@cvs.rochester.edu>
References: <4.3.1.2.20040112121906.0213f878@cvs.rochester.edu>
Message-ID: <x27jzxqciw.fsf@biostat.ku.dk>

Dominic Barraclough <dominicb at cvs.rochester.edu> writes:

> Hi,
> 
> While exploring how summary.lm generated its output I came across a
> section that left me puzzled.
> 
> 
> 
> at around line 57
>      R <- chol2inv(Qr$qr[p1, p1, drop = FALSE])
>      se <- sqrt(diag(R) * resvar)
> 
> 
> I'm hoping somebody could explain the logic of these to steps or
> alternatively point me in the direction of a text that will explain
> these steps.
> 
> In particular I'm puzzled what is the relationship between QR
> factorization and the cholesky factorization such that one can give a
> (sort of ) R matrix as a parameter of chol2inv(). I say sort of R
> matrix as the matrix generated by Qr$qr[p1, p1, drop = FALSE] has a
> lower triangle with non zero entries although the upper triangle
> corresponds to the values in the R matrix.

It's fairly easy, at least if we ignore the pivoting. We want
inv(X'X) where X is the design matrix, and we have X=QR where Q has
orthogonal columns. So Q'Q is the identity and X'X = R'R, i.e. R is a
Choleski factor of X'X, and we can use chol2inv to get to the inverse
of X'X. The rest is storage issues.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From salaheddin.mahmud at mcgill.ca  Mon Jan 12 18:55:53 2004
From: salaheddin.mahmud at mcgill.ca (Salah Mahmud)
Date: Mon, 12 Jan 2004 12:55:53 -0500
Subject: [R] Doubly interval-censored data
In-Reply-To: <Pine.LNX.4.44.0401111656250.18224-100000@gannet.stats>
Message-ID: <000f01c3d935$54d9cd80$39b5ce84@NewSalah>


Does anyone know of the existence of R code for estimating the survivor
function and its standard error where survival time (T) is defined as
the time between two interval-censored events, i.e., both events are
only known to occur within an interval? This is the situation that
commonly arises in longitudinal studies of viral infections. For
instance T could be the time of clearing HPV infection when the dates of
acquisition and loss (clearance) of infection are not measured exactly
but known to occur between two consecutive dates (dates of prescheduled
follow-up visits).

Many thanks,

Salah



From spencer.graves at pdf.com  Mon Jan 12 19:19:02 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 12 Jan 2004 10:19:02 -0800
Subject: [R] Doubly interval-censored data
In-Reply-To: <000f01c3d935$54d9cd80$39b5ce84@NewSalah>
References: <000f01c3d935$54d9cd80$39b5ce84@NewSalah>
Message-ID: <4002E516.8030500@pdf.com>

Have you looked at library(survival)?  Unless I misunderstand what you 
want, it should be there.  Further documentation is provided in Venables 
and Ripley (2002) Modern Applied Statistics with W, Therneau and 
Grambsch (2000) Modeling Survival Data, Harrell (2001) Regression 
Modeling Strategies (all Springer), and in materials downloadable from 
www.r-project.org;  see especially search -> "R site search".  Have you 
tried these sources? 

      hope this helps.  spencer graves

Salah Mahmud wrote:

>Does anyone know of the existence of R code for estimating the survivor
>function and its standard error where survival time (T) is defined as
>the time between two interval-censored events, i.e., both events are
>only known to occur within an interval? This is the situation that
>commonly arises in longitudinal studies of viral infections. For
>instance T could be the time of clearing HPV infection when the dates of
>acquisition and loss (clearance) of infection are not measured exactly
>but known to occur between two consecutive dates (dates of prescheduled
>follow-up visits).
>
>Many thanks,
>
>Salah
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From therneau at mayo.edu  Mon Jan 12 19:31:23 2004
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 12 Jan 2004 12:31:23 -0600 (CST)
Subject: [R] graphlets -- more
Message-ID: <200401121831.i0CIVNG21166@natasha.mayo.edu>

  I have already recieved two very helpful replies.  Let me describe the
problem we are trying to solve more clearly -- one of the suggestions was
along a line I'd never thought of, and I'd like to encourage more!

   R is being used in a microarray/QC situation, in essentially a batch
mode.  The applications that are "running the show" in terms of interacting
with the user's terminal and the main database are constrained to a
very particular environment, due to other reasons (ones I happen to agree
with, it's not just politics).  This outer application "X"
	- interact with the user to define "what data to look at"
	- and what to do with it
	- toss off an R batch script (a few calls, to perhaps complex
	functions) and a bunch of data
 	- R sends back a "blob" that X can display

The "blob" is an html doc with tables and plots.  The graphlet part comes
from the desire to allow the lab tech to drill down to plots that are
always defined and present, but rarely displayed.  The main plot contains
results from several experiments, one looks odd, so they can click on it
to see the per-experiment results.
  Because of environmental and speed constraints, this is not an interactive
R session.  The graphlets package allows this type of operation with java.

	Terry Therneau



From rossini at blindglobe.net  Mon Jan 12 21:00:20 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 12 Jan 2004 12:00:20 -0800
Subject: [R] graphlets -- more
In-Reply-To: <200401121831.i0CIVNG21166@natasha.mayo.edu> (Terry Therneau's
	message of "Mon, 12 Jan 2004 12:31:23 -0600 (CST)")
References: <200401121831.i0CIVNG21166@natasha.mayo.edu>
Message-ID: <85ptdp9bu3.fsf@blindglobe.net>


You might check out the prada package in Bioconductor; it's designed
for a different, but similar problem (96/384 well plate assays).
It isn't released, but the code is in the Bioconductor CVS repository,
which can be viewed and retrieved over the WWW:

http://franz.stat.wisc.edu/cgi-bin/viewcvs.cgi/Rpacks/?cvsroot=Bioconductor

best,
-tony


Terry Therneau <therneau at mayo.edu> writes:

>   I have already recieved two very helpful replies.  Let me describe the
> problem we are trying to solve more clearly -- one of the suggestions was
> along a line I'd never thought of, and I'd like to encourage more!
>
>    R is being used in a microarray/QC situation, in essentially a batch
> mode.  The applications that are "running the show" in terms of interacting
> with the user's terminal and the main database are constrained to a
> very particular environment, due to other reasons (ones I happen to agree
> with, it's not just politics).  This outer application "X"
> 	- interact with the user to define "what data to look at"
> 	- and what to do with it
> 	- toss off an R batch script (a few calls, to perhaps complex
> 	functions) and a bunch of data
>  	- R sends back a "blob" that X can display
>
> The "blob" is an html doc with tables and plots.  The graphlet part comes
> from the desire to allow the lab tech to drill down to plots that are
> always defined and present, but rarely displayed.  The main plot contains
> results from several experiments, one looks odd, so they can click on it
> to see the per-experiment results.
>   Because of environmental and speed constraints, this is not an interactive
> R session.  The graphlets package allows this type of operation with java.
>
> 	Terry Therneau
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From Ted.Harding at nessie.mcc.ac.uk  Mon Jan 12 21:19:58 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 12 Jan 2004 20:19:58 -0000 (GMT)
Subject: [R] ? data.entry "read-only" ?
Message-ID: <XFMail.040112201958.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

The spreadsheet-like layout displayed when 'data.entry' is
invoked is very useful simply for legible display of data,
quite apart from its intended use for the purpose of entering
or editing data.

If one wants to use it _simply_ as a display device, so that
one can look around inside a data-set while working on it,
then it is not a good idea to have its _editing_ capabilities
active: this is dangerous, since an inadvertent keystroke
could change the data.

So: is there a way to invoke 'data.entry' in "read-only"
mode? Or some other function with equivalent display which
can be run "read-only"?

[Bonus question: is there a way to change its cosmetics,
 e.g. background colour, font, ... ?]

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 12-Jan-04                                       Time: 20:19:58
------------------------------ XFMail ------------------------------



From ripley at stats.ox.ac.uk  Mon Jan 12 22:38:56 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Jan 2004 21:38:56 +0000 (GMT)
Subject: [R] ? data.entry "read-only" ?
In-Reply-To: <XFMail.040112201958.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0401122128320.2418-100000@gannet.stats>

There are I believe three separate data displays behind data.entry (on 
Xll, Windows and Aqua).  As far as I know none of them allow much 
customization, or to be read-only.

I had thought about a read-only version of the first two, but then
realized that people happily use spreadsheets for display, as well as data
editors in several other packages.  What is more important is that the
data editors are modal (at least the first two), so you cannot leave them
open whilst working on a dataset, since you will not be able to get back
to the prompt.  Read-only non-modal versions might be worth pursuing.

On Mon, 12 Jan 2004 Ted.Harding at nessie.mcc.ac.uk wrote:

> Hi Folks,
> 
> The spreadsheet-like layout displayed when 'data.entry' is
> invoked is very useful simply for legible display of data,
> quite apart from its intended use for the purpose of entering
> or editing data.
> 
> If one wants to use it _simply_ as a display device, so that
> one can look around inside a data-set while working on it,
> then it is not a good idea to have its _editing_ capabilities
> active: this is dangerous, since an inadvertent keystroke
> could change the data.
> 
> So: is there a way to invoke 'data.entry' in "read-only"
> mode? Or some other function with equivalent display which
> can be run "read-only"?
> 
> [Bonus question: is there a way to change its cosmetics,
>  e.g. background colour, font, ... ?]
> 
> With thanks,
> Ted.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jzhao at unity.ncsu.edu  Mon Jan 12 23:16:14 2004
From: jzhao at unity.ncsu.edu (Jieping)
Date: Mon, 12 Jan 2004 17:16:14 -0500
Subject: [R] data structure problem
Message-ID: <DHENIKLIEHEFHIDGEABNIEPLCAAA.jzhao@unity.ncsu.edu>

HI, there,
   I have a data set with special structure.
   It is in n*(5*p): n is the number of observations or data points
                     5*p is the matrix for each data point
   I'd like to conduct discriminant analysis to this data set. How could I
do? And where could I find related references to solve this problem?

Thanks a lot!


Jieping Zhao
PhD student in Bioinformatics, NCSU
Lab homepage: http://coltrane.gnets.ncsu.edu/index.html



From jfox at mcmaster.ca  Mon Jan 12 23:13:22 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 12 Jan 2004 17:13:22 -0500
Subject: [R] ? data.entry "read-only" ?
In-Reply-To: <XFMail.040112201958.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <5.0.2.1.0.20040112170749.00b0a618@127.0.0.1>

Dear Ted,

edit(df) invokes data.entry() on the data frame df and returns the edited 
version without altering the original. Thus
df <- edit(df) [or fix(df)] actually to change df, or invisible(edit(df)), 
or something equivalent, simply to look (and discard changes if they are made).

I hope that this helps,
  John

At 08:19 PM 1/12/2004 +0000, you wrote:
>Hi Folks,
>
>The spreadsheet-like layout displayed when 'data.entry' is
>invoked is very useful simply for legible display of data,
>quite apart from its intended use for the purpose of entering
>or editing data.
>
>If one wants to use it _simply_ as a display device, so that
>one can look around inside a data-set while working on it,
>then it is not a good idea to have its _editing_ capabilities
>active: this is dangerous, since an inadvertent keystroke
>could change the data.
>
>So: is there a way to invoke 'data.entry' in "read-only"
>mode? Or some other function with equivalent display which
>can be run "read-only"?
>
>[Bonus question: is there a way to change its cosmetics,
>  e.g. background colour, font, ... ?]
>
>With thanks,
>Ted.
>
>
>--------------------------------------------------------------------
>E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
>Fax-to-email: +44 (0)870 167 1972
>Date: 12-Jan-04                                       Time: 20:19:58
>------------------------------ XFMail ------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From Ted.Harding at nessie.mcc.ac.uk  Mon Jan 12 23:40:06 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 12 Jan 2004 22:40:06 -0000 (GMT)
Subject: [R] ? data.entry "read-only" ?
In-Reply-To: <Pine.LNX.4.44.0401122128320.2418-100000@gannet.stats>
Message-ID: <XFMail.040112224006.Ted.Harding@nessie.mcc.ac.uk>

Thanks, Brian, for these comments.

On 12-Jan-04 Prof Brian Ripley wrote:
> There are I believe three separate data displays behind data.entry (on 
> Xll, Windows and Aqua).  As far as I know none of them allow much 
> customization, or to be read-only.
> 
> I had thought about a read-only version of the first two, but then
> realized that people happily use spreadsheets for display, as well as
> data editors in several other packages.

Linux has no spreadsheet as standard, though you could get one by
installing some monster like StarOffice. In any case, any real
spreadsheet has much more functionality than one needs for data
editing, and more again than one needs merely for data display.

> What is more important is
> that the data editors are modal (at least the first two), so you
> cannot leave them open whilst working on a dataset, since you will not
> be able to get back to the prompt.

This is precisely why it's really danegrous! In order to get back to
the prompt you have to quit, so any unintended changes to the data get
written back to the data-set, and silently: you get no warning
if you've changed anything.

> Read-only non-modal versions might be worth pursuing.

Agreed. I've often used 'data.entry' to look at a data-set, and
of course it's inconvenient that you have to close it down in
order to get on with the job -- in particular losing your place
in the data. However, I've had a look at the R code and the C source,
and have not managed to work out where to make a change for this
purpose, nor even how to avoid the write-back on exit (since I've not
managed to determine the path from the entry arguments to wherever
it is that the function exits, so that the "return" could be
encapsulated in an "if(...){return;}" which tested for whether
a "read-only" option had been set.

However, as a result of looking a bit closer into it following
your comments, it now seems that invoking the associated function
'de' along the lines of

  junk<-de(dataset)

would do: you get the display, and any unintended changes get
written to 'junk' and not to 'dataset' -- 'data.entry', of course,
writes back to its argument. This still leaves the inconvenience of
the "modal" operation, but perhaps that's for another day ...

Thanks, and it would be interesting to read commments from others.
Ted.

> On Mon, 12 Jan 2004 Ted.Harding at nessie.mcc.ac.uk wrote:
> 
>> Hi Folks,
>> 
>> The spreadsheet-like layout displayed when 'data.entry' is
>> invoked is very useful simply for legible display of data,
>> quite apart from its intended use for the purpose of entering
>> or editing data.
>> 
>> If one wants to use it _simply_ as a display device, so that
>> one can look around inside a data-set while working on it,
>> then it is not a good idea to have its _editing_ capabilities
>> active: this is dangerous, since an inadvertent keystroke
>> could change the data.
>> 
>> So: is there a way to invoke 'data.entry' in "read-only"
>> mode? Or some other function with equivalent display which
>> can be run "read-only"?
>> 
>> [Bonus question: is there a way to change its cosmetics,
>>  e.g. background colour, font, ... ?]
>> 
>> With thanks,
>> Ted.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 12-Jan-04                                       Time: 22:40:06
------------------------------ XFMail ------------------------------



From d.firth at warwick.ac.uk  Mon Jan 12 23:50:42 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Mon, 12 Jan 2004 22:50:42 +0000
Subject: [R] ? data.entry "read-only" ?
In-Reply-To: <XFMail.040112201958.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <C01A8300-4551-11D8-AE3B-0050E4C03977@warwick.ac.uk>

The function showData() in the relimp package does something like this  
(and has a go at your bonus question), in a Tk widget.  It's far from a  
polished product, but gives some idea of what can be done using the  
tcltk package.  Usage is, for example,

data(trees)
showData(trees)

It will be very slow with very large datasets, but fine for smaller  
ones.

I just discovered, though, that showData() has at least one serious  
bug, arising from changes (quite a while ago now! I should have mended  
this earlier) in the tcltk package.  I'll put a new version of relimp  
on CRAN soon, and in the meantime I have put a fixed version of  
showData() at
http://www2.warwick.ac.uk/fac/sci/statistics/staff/academic/firth/ 
software/relimp/showdata.r
--  In case it's of use.

David

On Monday, Jan 12, 2004, at 20:19 Europe/London, (Ted Harding) wrote:

> Hi Folks,
>
> The spreadsheet-like layout displayed when 'data.entry' is
> invoked is very useful simply for legible display of data,
> quite apart from its intended use for the purpose of entering
> or editing data.
>
> If one wants to use it _simply_ as a display device, so that
> one can look around inside a data-set while working on it,
> then it is not a good idea to have its _editing_ capabilities
> active: this is dangerous, since an inadvertent keystroke
> could change the data.
>
> So: is there a way to invoke 'data.entry' in "read-only"
> mode? Or some other function with equivalent display which
> can be run "read-only"?
>
> [Bonus question: is there a way to change its cosmetics,
>  e.g. background colour, font, ... ?]
>
> With thanks,
> Ted.
>
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 12-Jan-04                                       Time: 20:19:58
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!  
> http://www.R-project.org/posting-guide.html



From p.connolly at hortresearch.co.nz  Tue Jan 13 00:14:46 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 13 Jan 2004 12:14:46 +1300
Subject: [R] ? data.entry "read-only" ?
In-Reply-To: <XFMail.040112224006.Ted.Harding@nessie.mcc.ac.uk>;
	from Ted.Harding@nessie.mcc.ac.uk on Mon, Jan 12, 2004 at
	10:40:06PM -0000
References: <Pine.LNX.4.44.0401122128320.2418-100000@gannet.stats>
	<XFMail.040112224006.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <20040113121446.O935@hortresearch.co.nz>

On Mon, 12-Jan-2004 at 10:40PM -0000, Ted Harding wrote:

|> Thanks, Brian, for these comments.
|> 
|> On 12-Jan-04 Prof Brian Ripley wrote:
|> > There are I believe three separate data displays behind data.entry (on 
|> > Xll, Windows and Aqua).  As far as I know none of them allow much 
|> > customization, or to be read-only.
|> > 
|> > I had thought about a read-only version of the first two, but then
|> > realized that people happily use spreadsheets for display, as well as
|> > data editors in several other packages.
|> 
|> Linux has no spreadsheet as standard, though you could get one by
|> installing some monster like StarOffice. In any case, any real

No need to get that drastic.  Gnumeric is much lighter weight and can
handle date formats Excel (and probably StarOffice) can't.  Gnumeric
is pretty close to being standard with Linux distros.  I seem to
remember it will work with KDE as well as Gnome.



-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From p.dalgaard at biostat.ku.dk  Tue Jan 13 00:14:24 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Jan 2004 00:14:24 +0100
Subject: [R] ? data.entry "read-only" ?
In-Reply-To: <Pine.LNX.4.44.0401122128320.2418-100000@gannet.stats>
References: <Pine.LNX.4.44.0401122128320.2418-100000@gannet.stats>
Message-ID: <x2eku44v5b.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> There are I believe three separate data displays behind data.entry (on 
> Xll, Windows and Aqua).  As far as I know none of them allow much 
> customization, or to be read-only.
> 
> I had thought about a read-only version of the first two, but then
> realized that people happily use spreadsheets for display, as well as data
> editors in several other packages.  What is more important is that the
> data editors are modal (at least the first two), so you cannot leave them
> open whilst working on a dataset, since you will not be able to get back
> to the prompt.  Read-only non-modal versions might be worth pursuing.

Not sure read-only really factors in there. As soon as object viewers
become non-modal (in the GUI sense, not edit/browse) you have to deal
with what should happen if something else modifies the object. 

What SAS does is to lock a dataset once it is opened in their
Viewtable tool, editable or not, and to much confusion for the naive
user who sees code that worked a minute before suddenly having no
effect whatsoever. In R that would get tricky, even if we wanted to
clone that mode of operation, since we have no way of making
individual objects (recursively) unmodifiable. 

I see two other options: the "scope" model and the "editor" model. The
scope model would try to keep the data viewer/editor in sync with the
object in the workspace at all times. That would likely get even more
tricky. R has copy-on-modify semantics (in principle and sometimes in
practice) so once part of an object changes, you may have to look in
new places for anything that contained it, including possibly the
object itself.

The editor model works like a text editor, where you're dealing with a
copy of what the object looked like when you started the viewer; if
the object changes, you just don't see it and if you subsequently save
the contents, you overwrite whatever got changed. Crude, but hey, it
works for file systems... You can of course make this read-only if you
want, but its not particularly harder to make it editable, is it? In
both cases, the user needs to be aware that it is probably not a good
idea to modify the object that he's viewing.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tazapa at yahoo.com  Tue Jan 13 00:49:16 2004
From: tazapa at yahoo.com (Ian Garcia)
Date: Mon, 12 Jan 2004 15:49:16 -0800 (PST)
Subject: [R] extract data from a data.frame
Message-ID: <20040112234916.17935.qmail@web60102.mail.yahoo.com>


 Hi,

 I'm reading part of a table from postgres, so I'm
getting a data frame. 

 how can I extract the numerica values so I can 
 operate on them.

> res <- dbGetResult(mydata)
> str(res)
`data.frame':   5 obs. of  8 variables:
 $ cyx.1: num   0.149 -0.278  0.114  0.060  0.109
 $ cyx.2: num   0.158 -0.070  0.063  0.149  0.150
 $ cyx.3: num   0.052 -0.350  0.114  0.126  0.238
 $ cyx.4: num   0.085 -0.009  0.097  0.121  0.258
 $ cyx.5: num   0.131 -0.028  0.068 -0.106  0.029
 $ cyx.6: num   0.140 -0.090  0.242 -0.071  0.713
 $ cyx.7: num   0.741 -0.290  0.215 -0.556  0.979
 $ cyx.8: num   0.129  0.043  0.287  0.1945 0.0265

 Thanks

 Ian



From Ted.Harding at nessie.mcc.ac.uk  Tue Jan 13 00:17:47 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 12 Jan 2004 23:17:47 -0000 (GMT)
Subject: [R] ? data.entry "read-only" ? [and segfault]
In-Reply-To: <5.0.2.1.0.20040112170749.00b0a618@127.0.0.1>
Message-ID: <XFMail.040112231747.Ted.Harding@nessie.mcc.ac.uk>

On 12-Jan-04 John Fox wrote:
> Dear Ted,
> [...]
> invisible(edit(df)), 
> or something equivalent, simply to look (and discard changes if they
> are made).

Thanks for the reminder about "invisible" -- as well as junk<-de(df)
one could use invisible(de(df)).

However, users please note:

  invisible(data.entry(df))

will change df (since that's what data.entry does "internally" on exit,
as a "side effect", whether wrapped in "invisible" or not).

Thanks,
Ted.

PS:

And now, playing with data.entry while writing this mail, I find
that clicking on the "COPY" button causes R to segfault:

arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    8.0              
year     2003             
month    10               
day      08               
language R

[installed from RPM specially compiled for RedHat-9]



--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 12-Jan-04                                       Time: 23:17:47
------------------------------ XFMail ------------------------------



From Eric.Kort at vai.org  Tue Jan 13 01:58:43 2004
From: Eric.Kort at vai.org (Kort, Eric)
Date: Mon, 12 Jan 2004 19:58:43 -0500
Subject: [R] extract data from a data.frame
Message-ID: <74D0F0AB07F2E647A02D839ED79520F90B945D@VAIEXCH02.vai.org>

> -----Original Message-----
> From: Ian Garcia [mailto:tazapa at yahoo.com]
>  Hi,
> 
>  I'm reading part of a table from postgres, so I'm
> getting a data frame. 
> 
>  how can I extract the numerica values so I can 
>  operate on them.
> 
> > res <- dbGetResult(mydata)
> > str(res)
> `data.frame':   5 obs. of  8 variables:
>  $ cyx.1: num   0.149 -0.278  0.114  0.060  0.109
>  $ cyx.2: num   0.158 -0.070  0.063  0.149  0.150
>  $ cyx.3: num   0.052 -0.350  0.114  0.126  0.238
>  $ cyx.4: num   0.085 -0.009  0.097  0.121  0.258
>  $ cyx.5: num   0.131 -0.028  0.068 -0.106  0.029
>  $ cyx.6: num   0.140 -0.090  0.242 -0.071  0.713
>  $ cyx.7: num   0.741 -0.290  0.215 -0.556  0.979
>  $ cyx.8: num   0.129  0.043  0.287  0.1945 0.0265

#one way
res$cyx.1

#as in:
sum(res$cyx.1)

#another way:
attach res
sum(cyx.1)

#or by row index
res[1, ]

#as in
for (i in 1:nrow(res)) {
  print(sum(res[i,]))
}

#or by column index
for (i in 1:ncol(res)) {
  print(sum(res[,i]))
}

hope that helps.
-Eric

> 
>  Thanks
> 
>  Ian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
This email message, including any attachments, is for the so...{{dropped}}



From jfox at mcmaster.ca  Tue Jan 13 03:41:19 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 12 Jan 2004 21:41:19 -0500
Subject: [R] ? data.entry "read-only" ? [and segfault]
In-Reply-To: <XFMail.040112231747.Ted.Harding@nessie.mcc.ac.uk>
References: <5.0.2.1.0.20040112170749.00b0a618@127.0.0.1>
Message-ID: <5.1.0.14.2.20040112214027.02041eb0@127.0.0.1>

Dear Ted,

At 11:17 PM 1/12/2004 +0000, Ted Harding wrote:
>On 12-Jan-04 John Fox wrote:
> > Dear Ted,
> > [...]
> > invisible(edit(df)),
> > or something equivalent, simply to look (and discard changes if they
> > are made).
>
>Thanks for the reminder about "invisible" -- as well as junk<-de(df)
>one could use invisible(de(df)).
>
>However, users please note:
>
>   invisible(data.entry(df))
>
>will change df (since that's what data.entry does "internally" on exit,
>as a "side effect", whether wrapped in "invisible" or not).

Indeed, which is why I suggested edit() rather than calling data.entry() 
directly.

Regards,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From andy_liaw at merck.com  Tue Jan 13 04:00:13 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 12 Jan 2004 22:00:13 -0500
Subject: [R] data structure problem
Message-ID: <3A822319EB35174CA3714066D590DCD504AF75F7@usrymx25.merck.com>

Without more information on the context of the data, it's hard to say much
that will be useful.

One possibility is to treat the 5*p entries as 5*p variables, and apply the
commonly available discriminant tools to that.  Given more information, it
might be possible to do better.  As an example, one data set that has been
used as benchmark is the scanned images of hand-written digits.  Each digit
is encoded in a k x k matrix of values expressing the grayscale level of
each pixel (don't remember what k is).  A straight-forward way to train a
algorithm for pattern recognition is to treat the data as having kxk
variables.  However, smarter (but custom-built, rather than off-the-shelf)
algorithms can make use of the fact that the data is actually an image, and
possibly get better results.

Cheers,
Andy 

> From: Jieping
> 
> HI, there,
>    I have a data set with special structure.
>    It is in n*(5*p): n is the number of observations or data points
>                      5*p is the matrix for each data point
>    I'd like to conduct discriminant analysis to this data 
> set. How could I
> do? And where could I find related references to solve this problem?
> 
> Thanks a lot!
> 
> 
> Jieping Zhao
> PhD student in Bioinformatics, NCSU
> Lab homepage: http://coltrane.gnets.ncsu.edu/index.html
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From s.mcclatchie at paradise.net.nz  Tue Jan 13 04:35:09 2004
From: s.mcclatchie at paradise.net.nz (Sam McClatchie)
Date: Tue, 13 Jan 2004 03:35:09 +0000
Subject: [R] reinstalling R/ mandrake 9.1/ rpm
Message-ID: <4003676D.6070009@paradise.net.nz>

OS: linux Mandrake 9.1
R Version 1.8.1  (2003-11-21),
GNU Emacs 21.2.93.1
-------------------

Colleagues

I'm reinstalling R after reformatting a partition containing the 
applications software. The urpmi returned this error:

[root at localhost R]# urpmi R-1.8.1-1mdk.i586.rpm
installing R-1.8.1-1mdk.i586.rpm

Preparing... 
##################################################
    1:R                      #################error: unpacking of 
archive failed on file 
/usr/lib/R/library/base/html/00Index.html;40036372: cpio: read

I did not see any mention of this problem in the help archive Is there 
any problem with the rpm? Or perhaps just something odd on my system? 
Should I uninstall the rpm using something like urpmi.removemedia, and 
then try and install the source with ./congure, make and make install?

Any suggestions welcome. Thanks.

Sam
-- 
Sam McClatchie,
Sub-program leader, Pelagic Fisheries
South Australian Aquatic Sciences Centre
PO Box 120, Henley Beach 5022
Adelaide, South Australia
email <mcclatchie.sam at saugov.sa.gov.au>
Telephone: (61-8) 8200 2433
FAX: (61-8) 8200 2481
Research home page <http://www.smcc.150m.com/>
                   /\
        >><xX(&>
                /// \\\
               //// \\\\
              ///  <%)Xx><<
             /////  \\\\\\
       ><(((@>
   ><(((%>      ..>><xX(?>O<?)Xx><<



From Soren.Hojsgaard at agrsci.dk  Tue Jan 13 08:00:36 2004
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Tue, 13 Jan 2004 08:00:36 +0100
Subject: [R] How to get the full (overparametrized) model matrix
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC6BFC03@DJFPOST01.djf.agrsci.dk>

Dear all,
If I use model.matrix on a formula including factors, then "superflous" columns of the model matrix are removed (or rather estimability constraints are imposed). Is there a way of getting the "full" model matrix, i.e. without removing redundant columns?
Best regards
S?ren H?jsgaard

=============================================================================================
S?ren H?jsgaard,  PhD, Head of Research Unit     Phone: +45 8999 1703
Biometry Research Unit, 			    Fax:     +45 8999 1300
Danish Institute of Agricultural Sciences        E-mail: sorenh at agrsci.dk
Research Centre Foulum, DK-8830 Tjele, Denmark   Homepage : http://www.jbs.agrsci.dk/~sorenh/



From s.mcclatchie at paradise.net.nz  Tue Jan 13 10:53:31 2004
From: s.mcclatchie at paradise.net.nz (Sam McClatchie)
Date: Tue, 13 Jan 2004 09:53:31 +0000
Subject: [R] reinstalling R/ mandrake 9.1/ rpm
In-Reply-To: <20040113170104.R935@hortresearch.co.nz>
References: <4003676D.6070009@paradise.net.nz>
	<20040113170104.R935@hortresearch.co.nz>
Message-ID: <4003C01B.1@paradise.net.nz>

Patrick Connolly wrote:
> On Tue, 13-Jan-2004 at 03:35AM +0000, Sam McClatchie wrote:
> 
> |> OS: linux Mandrake 9.1
> |> R Version 1.8.1  (2003-11-21),
> |> GNU Emacs 21.2.93.1
> |> -------------------
> |> 
> |> Colleagues
> |> 
> |> I'm reinstalling R after reformatting a partition containing the 
> |> applications software. The urpmi returned this error:
> 
> I've not used urpmi.  Is that to say you had it working from an rpm
> already and this is a way to get it onto another petition?
> 
> 
> |> Should I uninstall the rpm using something like urpmi.removemedia, and 
> 
> rpm -e is sufficient, IIRC.
> 
> |> then try and install the source with ./congure, make and make install?
> 
> 
> The only Mandrake I've tried is 9.0 which gave me all sorts of
> problems with things not working (some bits didn't seem to get from
> the installation CDs).  I've gone back to Redhat 7.3.
> 
> Having said that, I prefer to install from the tgz file.  The
> installation procedure is very well thought out and it takes at most
> 20 minutes.  Another good reason is so that you can still use previous
> versions if something appears to be a 'new' bug.  For most other
> things, rpms are great.
> 
> HTH
> 
> 
--------------------
OS: linux Mandrake 9.1
R Version 1.8.1  (2003-11-21),
GNU Emacs 21.2.93.1

Hi Patrick

My need to reinstall R arose from a classic mistake. I had copied the 
gnucash rpm into /usr/lib/, and then installed it, which resulted in a 
/usr/lib/usr/lib structure. In correcting my error, I was too quick with 
my fingers, and as root, deleted my /usr/lib directory (I had to laugh, 
after I finished cursing). Anyway, I had to reformat my software partition.

There does seem to be a problem with the mandrake 9.1 rpm. I've just 
installed the R 1.8.1 sources with ./configure, make, make install 
(after installing the C, C++ and Fortran compilers from the Mandrake 
software management gui). Everything worked beautifully.

Thanks

Sam
-- 
Sam McClatchie,
Sub-program leader, Pelagic Fisheries
South Australian Aquatic Sciences Centre
PO Box 120, Henley Beach 5022
Adelaide, South Australia
email <mcclatchie.sam at saugov.sa.gov.au>
Telephone: (61-8) 8200 2433
FAX: (61-8) 8200 2481
Research home page <http://www.smcc.150m.com/>
                   /\
        >><xX(&>
                /// \\\
               //// \\\\
              ///  <%)Xx><<
             /////  \\\\\\
       ><(((@>
   ><(((%>      ..>><xX(?>O<?)Xx><<



From rodrigo.abt at sii.cl  Tue Jan 13 13:05:27 2004
From: rodrigo.abt at sii.cl (Rodrigo Abt)
Date: Tue, 13 Jan 2004 09:05:27 -0300
Subject: [R] Manova for repeated measures
Message-ID: <000001c3d9cd$88e8ff40$2a01240a@rodrigoabt>

Hi everyone,

I'm posting again, since I haven't got an answer (yet :( ).

According to R help, manova does not support the inclusion of the Error()
term in the formula call. I have repeated measures data for two dependent
variables,
so this means I can't account for subject variance in time?. Any lights?

Thanks in advance,

Rodrigo Abt,
Department of Economic Studies,
SII, Chile.



From renaud.lancelot at pasteur.mg  Tue Jan 13 13:36:29 2004
From: renaud.lancelot at pasteur.mg (Renaud Lancelot)
Date: Tue, 13 Jan 2004 15:36:29 +0300
Subject: [R] Manova for repeated measures
In-Reply-To: <000001c3d9cd$88e8ff40$2a01240a@rodrigoabt>
References: <000001c3d9cd$88e8ff40$2a01240a@rodrigoabt>
Message-ID: <4003E64D.2060809@pasteur.mg>

Rodrigo Abt a ?crit :
> Hi everyone,
> 
> I'm posting again, since I haven't got an answer (yet :( ).
> 
> According to R help, manova does not support the inclusion of the Error()
> term in the formula call. I have repeated measures data for two dependent
> variables,
> so this means I can't account for subject variance in time?. Any lights?
> 
> Thanks in advance,
> 
> Rodrigo Abt,
> Department of Economic Studies,
> SII, Chile.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

For exploratory purposes, you might want to try pta() in the contributed 
package ade4. You might find additional documentation on the ADE4 
website: http://pbil.univ-lyon1.fr/ADE-4/ADE-4.html

Otherwise, I think you will have to use a specialized software such as 
MLwiN (http://multilevel.ioe.ac.uk/index.html) which can fit 
multivariate and multilevel models.

Hope this helps,

Renaud

-- 
Dr Renaud Lancelot
v?t?rinaire ?pid?miologiste
Ambassade de France - SCAC
BP 834 Antananarivo 101
Madagascar

t?l. +261 (0)32 04 824 55 (cell)
      +261 (0)20 22 494 37 (home)



From tlumley at u.washington.edu  Tue Jan 13 14:45:24 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 13 Jan 2004 05:45:24 -0800 (PST)
Subject: [R] Doubly interval-censored data
In-Reply-To: <4002E516.8030500@pdf.com>
References: <000f01c3d935$54d9cd80$39b5ce84@NewSalah>
	<4002E516.8030500@pdf.com>
Message-ID: <Pine.A41.4.58.0401130544530.60194@homer18.u.washington.edu>

On Mon, 12 Jan 2004, Spencer Graves wrote:

> Have you looked at library(survival)?  Unless I misunderstand what you
> want, it should be there

It isn't.

	-thomas



>	.  Further documentation is provided in Venables
> and Ripley (2002) Modern Applied Statistics with W, Therneau and
> Grambsch (2000) Modeling Survival Data, Harrell (2001) Regression
> Modeling Strategies (all Springer), and in materials downloadable from
> www.r-project.org;  see especially search -> "R site search".  Have you
> tried these sources?
>
>       hope this helps.  spencer graves
>
> Salah Mahmud wrote:
>
> >Does anyone know of the existence of R code for estimating the survivor
> >function and its standard error where survival time (T) is defined as
> >the time between two interval-censored events, i.e., both events are
> >only known to occur within an interval? This is the situation that
> >commonly arises in longitudinal studies of viral infections. For
> >instance T could be the time of clearing HPV infection when the dates of
> >acquisition and loss (clearance) of infection are not measured exactly
> >but known to occur between two consecutive dates (dates of prescheduled
> >follow-up visits).
> >
> >Many thanks,
> >
> >Salah
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From Deborah.Renz at stud.unibas.ch  Tue Jan 13 16:39:35 2004
From: Deborah.Renz at stud.unibas.ch (Deborah.Renz@stud.unibas.ch)
Date: Tue, 13 Jan 2004 16:39:35 +0100
Subject: [R] Average Graph
Message-ID: <1074008375.40041137dd416@webmail.unibas.ch>


Hi Everyone!

I need to average some graphs of the same plot. How do I do that?
It's a plot of different Kfn-Graphs, but "Kaver()" only works for simulated 
data.

Who can help?
Thx
Deborah



From Deborah.Renz at stud.unibas.ch  Tue Jan 13 16:50:01 2004
From: Deborah.Renz at stud.unibas.ch (Deborah.Renz@stud.unibas.ch)
Date: Tue, 13 Jan 2004 16:50:01 +0100
Subject: [R] Kaver
Message-ID: <1074009001.400413a974d33@webmail.unibas.ch>


O.k., "Kaver"forms the average of a series of (usually simulated) K-functions.
How do I apply it on non-simulated K-functions?

Deborah Renz



From otoomet at econ.dk  Tue Jan 13 17:12:43 2004
From: otoomet at econ.dk (Ott Toomet)
Date: Tue, 13 Jan 2004 17:12:43 +0100
Subject: [R] R killed on Solaris
Message-ID: <200401131612.i0DGChaa032121@hugo.obs.ee>

Hello,

I am running a preliminary data-processing job on solaris.  Basically,
the program reads a large number of ascii-lines (about 1M) by blocks
(size 25000 lines), selects suitable observations (around 5000) and
writes the results into a dataframe for latter processing.

The problem is that when I run the job interactively (in emacs/ESS),
everything works fine.  If I try to run it from shell using R CMD
BATCH, R will be killed after around 100 000 lines.  Solaris says
simply "killed" and thats it.  The total memory consumption seems not
to be a problem, around 200M on a 4G machine.  

Any suggestions?  Has anyone else seen something similar?

Best wishes

Ott
---
this is R 1.7.1, compiled as 32-bit appication, on 64bit sparc solaris
9 (sunos 5.9).



From Gerald.Jean at spgdag.ca  Tue Jan 13 18:32:43 2004
From: Gerald.Jean at spgdag.ca (Gerald.Jean@spgdag.ca)
Date: Tue, 13 Jan 2004 12:32:43 -0500
Subject: [R] Installing the Rcmdr and tclk package
Message-ID: <OF3EAAD383.88C63DC8-ON85256E1A.005F1F7D@spgdag.ca>

Hello R-users,

Version 1.8.1 on a 64-bit Solaris 5.8 OS

I am trying to instal the Rcmdr package for which the tclk package is
required.  Once both package installed I issued the command:

> library(tcltk)

and received the following error message

Error in firstlib(which.lib.loc, package) :
      Tcl/Tk support is not available on this system
Error in library(tcltk) : .First.lib failed

Upon which I searched for Tcl and Tk on our system and didn't find them,
hence I requested the admin. person to get them from the "sunfreeware" site
and install them.  The packages are now installed under "/usr/local", same
place than R is installed.  If I open a shell and cd to this directory and
type "tcl" at the Unix prompt "tcl" starts.  But if go back in R and try
the "library(tcltk)" command I receive the same error message as above.

I searched the "r-projec", the tcltk documentation and the mail archives in
the hope of finding out if environment variables needed to be set or if I
had missed something else, but I had no luck!

Anyone could point me in the right direction as what needs to be done so
Tcl and Tk become visible to R?

Thank you much,

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming



From Kang.Changku at epamail.epa.gov  Tue Jan 13 19:11:02 2004
From: Kang.Changku at epamail.epa.gov (Kang.Changku@epamail.epa.gov)
Date: Tue, 13 Jan 2004 13:11:02 -0500
Subject: [R] nlminb(Splus) vs optim(R)
Message-ID: <OF2B1C7D55.64E03F0A-ON85256E1A.0062F92E-85256E1A.0063E390@epamail.epa.gov>





Dear, R experts.

I have two program codes, one is made by Splus and the other
is made by transferring from Splus code. Because "nlminb" function
in Splus is equivalent to "optim" in R, I expected to get exactly same
result. But, sometime there is too large differece (greater than 2%)
between two outputs. I looked two help files.
According to those, in Splus, quasi-Newton method was used
with hessian or gradient option unchecked and in R, "BFGS" method
is a quasi-Newton method. Therefore, if we use "BFGS" method in R,
we are using same method to Splus. Is there another consideration
when we transferring from Splus to R? Or any suggestions or comments?

Thanks in advance.

+++++++++++++++++++++++++++++++++++++++++++++++++++++
Changku Kang
National Center for Environmental Assessment
EPA  (B211F)
919-541-1396
919-541-0245 (fax)
Kang.Changku at epa.gov

Graduate Student
Department of Statistics, NCSU
ckang2 at stat.ncsu.edu
919-513-2956
+++++++++++++++++++++++++++++++++++++++++++++++++++++



From mendigo at netcabo.pt  Tue Jan 13 21:37:13 2004
From: mendigo at netcabo.pt (M. M. Palhoto N. Rodrigues)
Date: Tue, 13 Jan 2004 20:37:13 -0000
Subject: [R] How can I test if a not independently and not identically
	distributed time series residuals' are uncorrelated ? 
Message-ID: <000c01c3da15$0c8ad7a0$b4a616d5@galactic>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040113/f0bb1817/attachment.pl

From jzhao at unity.ncsu.edu  Tue Jan 13 22:17:45 2004
From: jzhao at unity.ncsu.edu (Jieping)
Date: Tue, 13 Jan 2004 16:17:45 -0500
Subject: [R] data structure problem
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF75F7@usrymx25.merck.com>
Message-ID: <DHENIKLIEHEFHIDGEABNMEPOCAAA.jzhao@unity.ncsu.edu>

my situtation is that each data point is made up of p correlated 5-dimension
vectors. Those 5 dimensions are orthogonal.
Any suggestions will be appreciated!

JP


-----Original Message-----
From: Liaw, Andy [mailto:andy_liaw at merck.com]
Sent: Monday, January 12, 2004 10:00 PM
To: 'Jieping'; r-help at stat.math.ethz.ch
Subject: RE: [R] data structure problem


Without more information on the context of the data, it's hard to say much
that will be useful.

One possibility is to treat the 5*p entries as 5*p variables, and apply the
commonly available discriminant tools to that.  Given more information, it
might be possible to do better.  As an example, one data set that has been
used as benchmark is the scanned images of hand-written digits.  Each digit
is encoded in a k x k matrix of values expressing the grayscale level of
each pixel (don't remember what k is).  A straight-forward way to train a
algorithm for pattern recognition is to treat the data as having kxk
variables.  However, smarter (but custom-built, rather than off-the-shelf)
algorithms can make use of the fact that the data is actually an image, and
possibly get better results.

Cheers,
Andy

> From: Jieping
>
> HI, there,
>    I have a data set with special structure.
>    It is in n*(5*p): n is the number of observations or data points
>                      5*p is the matrix for each data point
>    I'd like to conduct discriminant analysis to this data
> set. How could I
> do? And where could I find related references to solve this problem?
>
> Thanks a lot!
>
>
> Jieping Zhao
> PhD student in Bioinformatics, NCSU
> Lab homepage: http://coltrane.gnets.ncsu.edu/index.html
>


----------------------------------------------------------------------------
--
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From adler at lifesci.ucsb.edu  Tue Jan 13 22:52:05 2004
From: adler at lifesci.ucsb.edu (Peter Adler)
Date: Tue, 13 Jan 2004 13:52:05 -0800
Subject: [R] Running out of memory
Message-ID: <6.0.0.22.1.20040113132554.01bfc270@lifesci.ucsb.edu>

I'm working with large data frames and running out of memory.  I hope some 
of you may be able to suggest a more efficient approach.

I have grid/lattice data representing a time series of 1 m2 quadrats in a 
grassland: Each 1 cm2 cell or pixel contains one ecological state (ie grass 
or bare ground).  The goal is to calculate, for each cell, the transition 
probabilities to all available states (given that a cell is occupied by 
grass, what are the probabilities it will change to grass or bare ground in 
the next time step?).  I am using multinom (in package nnet, MASS) to 
calculate these transitions as a function of the density of each state in 
some defined neighborhood around the focal cell.  So I generate a data 
frame with the following columns:

quadrat, year, x coordinate, y coordinate, state at time t, state at time 
t+1, density of state 1 at time t, density of state 2,...state n.

Thus each quadrat to quadrat transition, using 100x100 cell quadrats, can 
generate 10,000 records.  Right now I import, make calculations and store 
the data for each quadrat-to-quadrat transition in a temporary array, then 
use rbind to append this array on to the whole (final) data frame, then 
repeat for the next year (re-using the same temporary array).  I use up my 
max memory allocation (1024Mb) after about 130 quadrat-years of data.  I 
could increase my max memory allocation some more, but this will simply 
raise the ceiling, not solve the problem.

I don't understand why R runs out of memory so soon, since text files 
containing this same data are much smaller. For example, 35 years of data 
for one quadrat uses only 11Mb when stored in a text file on my hard drive, 
but when I import it into R it occupies over 100Mb (according to 
memory.size() ).

Should I think about exporting the data to text files as I go?

Thanks for your help,

Peter
------------------------
Peter Adler, PhD
Dept. Ecology, Evolution and Marine Biology
University of California
Santa Barbara, CA 93106
tel: (805) 893-7416
http://www.lifesci.ucsb.edu/~adler/



From ryszard.czerminski at pharma.novartis.com  Tue Jan 13 23:02:57 2004
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Tue, 13 Jan 2004 17:02:57 -0500
Subject: [R] prcomp: error code 17 from Lapack routine dgesdd
Message-ID: <OF0B63AF9E.2A0A2118-ON85256E1A.0078E007-85256E1A.00793D93@EU.novartis.net>

I am trying to use prcomp and I am getting this error:

> p <- prcomp(xtr, retx = TRUE, center = TRUE, scale = TRUE, tol = NULL)
Error in La.svd(x, nu, nv, method) : error code 17 from Lapack routine 
dgesdd
> dim(xtr)
[1]  301 2439

Does it mean that the matrix is to big ?

R



From Bill.Venables at csiro.au  Wed Jan 14 00:21:16 2004
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Wed, 14 Jan 2004 09:21:16 +1000
Subject: [R] Manova for repeated measures
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A9276720@roper-cv.qld.cmis.csiro.au>

One useful way of looking at she S language, which R implements, is as a
complete programming language with some very powerful operators already
available.  Why not think about putting those operators together to do the
computations that you need to do in this case?  It's not like starting from
scratch in bog Fortran.

I suspect this doesn't help much if you don't know enough about the
computations you need to do, though.  Perhaps there is a hidden message if
that is the case.

End of sermon.

Bill Venables.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rodrigo Abt
Sent: Tuesday, 13 January 2004 10:05 PM
To: 'Lista de Correo de R'
Subject: [R] Manova for repeated measures
Importance: High


Hi everyone,

I'm posting again, since I haven't got an answer (yet :( ).

According to R help, manova does not support the inclusion of the Error()
term in the formula call. I have repeated measures data for two dependent
variables, so this means I can't account for subject variance in time?. Any
lights?

Thanks in advance,

Rodrigo Abt,
Department of Economic Studies,
SII, Chile.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From hanspeter.bornhauser at ch.abb.com  Wed Jan 14 07:25:25 2004
From: hanspeter.bornhauser at ch.abb.com (hanspeter.bornhauser@ch.abb.com)
Date: Wed, 14 Jan 2004 07:25:25 +0100
Subject: [R] copula functions
Message-ID: <OF69854154.7984320A-ONC1256E1B.0023241B@ch.abb.com>

Hi there

does anyone know about a downloadable CRAN for copula functions for R?

Thank you so much for your answers.

Hanspeter



From uaca at alumni.uv.es  Wed Jan 14 09:24:22 2004
From: uaca at alumni.uv.es (uaca@alumni.uv.es)
Date: Wed, 14 Jan 2004 09:24:22 +0100
Subject: [R] summary() within a function
Message-ID: <20040114082422.GA18168@pusa.informat.uv.es>


I have the following function

f <- function {

	...

	model <- lm(rttx[,1] ~ rttx[,2] + 0);
	summary(model);

	...
}

while summary(model) shows the summary if I execute the function line by line
in the Command Line Interface, if I call f() summary is silent

how to solve it? or is there workaround?

thanks in advance

	Ulisses

                Debian GNU/Linux: a dream come true
-----------------------------------------------------------------------------
"Computers are useless. They can only give answers."            Pablo Picasso

--->	Visita http://www.valux.org/ para saber acerca de la	<---
--->	Asociaci?n Valenciana de Usuarios de Linux		<---



From marwan.khawaja at aub.edu.lb  Tue Jan 13 16:48:26 2004
From: marwan.khawaja at aub.edu.lb (Marwan Khawaja)
Date: Tue, 13 Jan 2004 10:48:26 -0500
Subject: [R] email problem
Message-ID: <CLECJBOEBGOMOKJHJNDACELDDIAA.marwan.khawaja@aub.edu.lb>

Hello
Is anyone else having problems receiving email from the list?  No email from R
help today!
Thanks Marwan


-------------------------------------------------------------------
Marwan Khawaja         http://departments.aub.edu.lb/~mk36



From patrick.giraudoux at univ-fcomte.fr  Wed Jan 14 09:48:55 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Wed, 14 Jan 2004 09:48:55 +0100
Subject: [R] Trellis graph and two colors display
References: <200401111115.i0BB52lN019805@hypatia.math.ethz.ch>
Message-ID: <001001c3da7b$48a65a00$754637c1@PC728329681112>

Hello,

I would like to display two groups of dots in different colors or style and additionnaly a linear regression for all the dots in
panel plots of a Trellis graph.  Actually to get in each panel the equivalent of:

plot(x[mois==3],y[mois==3],col="blue")
points(x[mois==9],y[mois==9],col="red")
abline(lm(y~x), col="green")

"mois" being a grouping variable and ID (see below) the conditioning variable in a data.frame of 230 rows

After several really disatreous trials, I have tried the following:

xyplot(y~x|ID,panel=function(x,y){panel.superpose(x,y,subscripts=1:230,groups=mois);panel.abline(lm(y~x),col="green")})

1/ I am not sure to have well understood what  the role of subscripts (with no default) is in the function panel.superpose and if
the values passed are appropriate here;

2/ this apparently displays all the points without changes of style between groups (neither symbols or colors).

3/ this does not allow changes in color for points display

Can anybody give me a hint on where I am wrong?

Sorry to be probably very clumpsy,

Kind regards,

Patrick Giraudoux



From maechler at stat.math.ethz.ch  Wed Jan 14 09:59:46 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 14 Jan 2004 09:59:46 +0100
Subject: [R] Installing the Rcmdr and tclk package
In-Reply-To: <OF3EAAD383.88C63DC8-ON85256E1A.005F1F7D@spgdag.ca>
References: <OF3EAAD383.88C63DC8-ON85256E1A.005F1F7D@spgdag.ca>
Message-ID: <16389.1282.826268.772699@gargle.gargle.HOWL>

>>>>> "Gerald" == Gerald Jean <Gerald.Jean at spgdag.ca>
>>>>>     on Tue, 13 Jan 2004 12:32:43 -0500 writes:

    Gerald> Hello R-users,
    Gerald> Version 1.8.1 on a 64-bit Solaris 5.8 OS

    Gerald> I am trying to instal the Rcmdr package for which the tclk package is
    Gerald> required.  Once both package installed I issued the command:

    >> library(tcltk)

    Gerald> and received the following error message

    Gerald> Error in firstlib(which.lib.loc, package) :
    Gerald> Tcl/Tk support is not available on this system
    Gerald> Error in library(tcltk) : .First.lib failed

    Gerald> Upon which I searched for Tcl and Tk on our system
    Gerald> and didn't find them, hence I requested the
    Gerald> admin. person to get them from the "sunfreeware"
    Gerald> site and install them.  The packages are now
    Gerald> installed under "/usr/local", same place than R is
    Gerald> installed.  If I open a shell and cd to this
    Gerald> directory and type "tcl" at the Unix prompt "tcl"
    Gerald> starts.  But if go back in R and try the
    Gerald> "library(tcltk)" command I receive the same error
    Gerald> message as above.

You need to re-install R.  Yours has "remembered" that tcl/tk is
not available.  In particular, do call  ./configure  again and probably
make will be sufficient (otherwise clean the whole installation
and configure; make; ...).

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From wgbeldman at student.han.nl  Wed Jan 14 10:13:17 2004
From: wgbeldman at student.han.nl (W. Beldman)
Date: Wed, 14 Jan 2004 10:13:17 +0100
Subject: [R] 'solve' algorithm
Message-ID: <1074071597.4005082d6952f@webmail.han.nl>

I'm looking for the algorithm of the  solve  function (base package). As I 
understand the help text neither Linpack nor Lapack's ZESV is used (in the 
simple example below) but what algorithm is? Something like Gauss Jordan 
Elimination should be applicable to solve a linear system

In particular I want to be able to translate it into i.e. Delphi, but in the 
example below I'm not convinced that I understand what's happening. vD seems 
rather small...


TIA,

W. Beldman



 vD <- matrix(0.305625, 1, 1)
> vD
         [,1]
[1,] 0.305625
> v <- matrix(c(0.348125, .296875, .305625), 1, 3)
> v
         [,1]     [,2]     [,3]
[1,] 0.348125 0.296875 0.305625
> A <- solve(vD, v)
> A
         [,1]      [,2] [,3]
[1,] 1.139059 0.9713701    1



From christoph.lehmann at gmx.ch  Wed Jan 14 10:35:57 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Wed, 14 Jan 2004 10:35:57 +0100
Subject: [R] array(list(),c(2,5)) gives error in R 1.8.1
Message-ID: <1074072927.1570.4.camel@christophl>

Hi

In R 1.7 the following worked fine:

> array(list(),c(2,5))
     [,1] [,2] [,3] [,4] [,5]
[1,] NULL NULL NULL NULL NULL
[2,] NULL NULL NULL NULL NULL

now in R 1.8.1 I get the error:

Error in rep.int(data, t1) : invalid number of copies in "rep"
In addition: Warning message:
NAs introduced by coercion

thanks for help, I need this possibility for storing objects (lm
results) in an array

cheers

Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From ripley at stats.ox.ac.uk  Wed Jan 14 10:52:33 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Jan 2004 09:52:33 +0000 (GMT)
Subject: [R] 'solve' algorithm
In-Reply-To: <1074071597.4005082d6952f@webmail.han.nl>
Message-ID: <Pine.LNX.4.44.0401140950360.15811-100000@gannet.stats>

On Wed, 14 Jan 2004, W. Beldman wrote:

> I'm looking for the algorithm of the  solve  function (base package). As I 
> understand the help text neither Linpack nor Lapack's ZESV is used (in the 

Well, your example is not complex.  By default (LINPACK=FALSE), DGESV is 
used: just read the code.

> simple example below) but what algorithm is? Something like Gauss Jordan 
> Elimination should be applicable to solve a linear system
> 
> In particular I want to be able to translate it into i.e. Delphi, but in the 
> example below I'm not convinced that I understand what's happening. vD seems 
> rather small...
> 
> 
> TIA,
> 
> W. Beldman
> 
> 
> 
>  vD <- matrix(0.305625, 1, 1)
> > vD
>          [,1]
> [1,] 0.305625
> > v <- matrix(c(0.348125, .296875, .305625), 1, 3)
> > v
>          [,1]     [,2]     [,3]
> [1,] 0.348125 0.296875 0.305625
> > A <- solve(vD, v)
> > A
>          [,1]      [,2] [,3]
> [1,] 1.139059 0.9713701    1
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mendigo at netcabo.pt  Wed Jan 14 11:55:59 2004
From: mendigo at netcabo.pt (M. M. Palhoto N. Rodrigues)
Date: Wed, 14 Jan 2004 10:55:59 -0000
Subject: [R] How can I test if a not independently and not identically
	distributed time series residuals' are uncorrelated ? 
Message-ID: <002901c3da8e$49c711a0$65a616d5@galactic>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040114/b03d8ee9/attachment.pl

From giampi at speech.kth.se  Wed Jan 14 11:55:59 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Wed, 14 Jan 2004 11:55:59 +0100 (CET)
Subject: [R] clustering indexes/indices
Message-ID: <Pine.LNX.4.58.0401141143030.20535@bayes.speech.kth.se>

Hi,
I read a post back in April 2000 that wondered if it was possible to use
hclust objects in cclust, so to take advantage of the clustIndex function
to compute indexes that can be used to estimate the "true" number of
clusters in the data.

The answer there was that this was not possible at the moment, but that an
unification of the clustering classes from different packages was probably
a good idea for the future.

I was wondering if this had happened in the meantime, or if it is planned for
the near future.

Thank you!
Giampiero



From maechler at stat.math.ethz.ch  Wed Jan 14 12:19:57 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 14 Jan 2004 12:19:57 +0100
Subject: [R] email problem
In-Reply-To: <CLECJBOEBGOMOKJHJNDACELDDIAA.marwan.khawaja@aub.edu.lb>
References: <CLECJBOEBGOMOKJHJNDACELDDIAA.marwan.khawaja@aub.edu.lb>
Message-ID: <16389.9693.442384.453158@gargle.gargle.HOWL>

>>>>> "Marwan" == Marwan Khawaja <marwan.khawaja at aub.edu.lb>
>>>>>     on Tue, 13 Jan 2004 10:48:26 -0500 writes:

    Marwan> Hello Is anyone else having problems receiving email
    Marwan> from the list?  No email from R help today!  Thanks
    Marwan> Marwan

Yes, quite a few people will not have gotten e-mail from our
mailing lists.

Reason: One IT person decided to improve our server's firewall
	which has been active for 21 hours; now remedied ..... ;-(

The queue of outgoing e-mails has been emptying since 10:30 MET
now, and hopefully all mails will have been sent within a few
more hours.

I'm sorry about this (and have complained with our IT staff (BCC'ed)).

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From geoff.grimwood at paradise.net.nz  Wed Jan 14 12:33:32 2004
From: geoff.grimwood at paradise.net.nz (Geoff Grimwood)
Date: Thu, 15 Jan 2004 00:33:32 +1300
Subject: [R] RMySQL : Not loading
Message-ID: <7B7CD71E-4685-11D8-B58F-000393AA6416@paradise.net.nz>

Hello,

I'm tearing my hair out over this. Any help will be very much 
appreciated. It's been two long nights battling with RMySQL.

 > library(RMySQL)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
         unable to load shared library 
"/usr/local/lib/R/library/RMySQL/libs/RMySQL.so":
   dlcompat: dyld: /usr/local/lib/R/bin/R.bin Undefined symbols:
_getopt_long
Error in library(RMySQL) : .First.lib failed

I am running Mac OS 10.2.8, R 1.8.1, RMySQL 0.5-3, MySQL 4.0.17. R and 
MySQL are well otherwise

I have moved away from the Fink sourced (ie /sw) version of R and MySQL 
to regular /usr/local types. Mainly because the Fink R is 1.7 and can't 
do the MySQL business. And I was wondering if the RMySQL install was 
comin to grief because it couldn't find the /sw mysql files.

Anyway, RMySQL seems to have install OK. I see it with 
installed.packages(). There was the apparent inability to find 
lmysqlclient and mysql.h but that seems to be a red herring (see below).

Regards

Geoff Grimwood
Wellington
New Zealand


[SIDLAW02:~/Desktop] geoff% sudo R CMD INSTALL 
--configure-args='--with-mysql-inc=/usr/local/mysql/include 
--with-mysql-lib=/usr/local/mysql/lib' RMySQL_0.5-3.tar.gz
* Installing *source* package 'RMySQL' ...
creating cache ./config.cache
checking how to run the C preprocessor... cc -E
checking for mysql_init in -lmysqlclient... no
checking for mysql.h... no
updating cache ./config.cache
creating ./config.status
creating src/Makevars
** libs
gcc -no-cpp-precomp -I/usr/local/lib/R/include 
-I/usr/local/mysql/include -I/sw/include   -fno-common  -g -O2 -c 
RS-DBI.c -o RS-DBI.o
gcc -no-cpp-precomp -I/usr/local/lib/R/include 
-I/usr/local/mysql/include -I/sw/include   -fno-common  -g -O2 -c 
RS-MySQL.c -o RS-MySQL.o
gcc -bundle -flat_namespace -undefined suppress -L/sw/lib 
-L/usr/local/lib -o RMySQL.so RS-DBI.o RS-MySQL.o 
-L/usr/local/mysql/lib -lmysqlclient -lz -lcc_dynamic 
-L/usr/local/lib/R/bin -lR
[SNIP]

SIDLAW02:library/RMySQL/libs] geoff% ls -ltr
total 500
-rwxr-xr-x    1 root     staff      254816 Jan 14 23:45 RMySQL.so
-rwxr-xr-x    1 root     staff      249856 Jan 14 23:46 libmySQL.dll
-rw-r--r--    1 root     staff         155 Jan 14 23:46 
libMySQL_4.0.16.txt



From ripley at stats.ox.ac.uk  Wed Jan 14 12:58:53 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Jan 2004 11:58:53 +0000 (GMT)
Subject: [R] summary() within a function
In-Reply-To: <20040114082422.GA18168@pusa.informat.uv.es>
Message-ID: <Pine.LNX.4.44.0401141157550.16310-100000@gannet.stats>

On Wed, 14 Jan 2004 uaca at alumni.uv.es wrote:

> 
> I have the following function
> 
> f <- function {
> 
> 	...
> 
> 	model <- lm(rttx[,1] ~ rttx[,2] + 0);
> 	summary(model);
> 
> 	...
> }
> 
> while summary(model) shows the summary if I execute the function line by line
> in the Command Line Interface, if I call f() summary is silent
> 
> how to solve it? or is there workaround?

You didn't do anything with the return value from summary(.lm).  You need 
to print() it, which happens automatically at the command line.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mendigo at netcabo.pt  Wed Jan 14 13:00:31 2004
From: mendigo at netcabo.pt (M. M. Palhoto N. Rodrigues)
Date: Wed, 14 Jan 2004 12:00:31 -0000
Subject: [R] How can I test if a not independently and not
	identicallydistributed time series residuals' are uncorrelated ? 
Message-ID: <000e01c3da96$02ac4620$65a616d5@galactic>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040114/2b50b141/attachment.pl

From rksh at soc.soton.ac.uk  Wed Jan 14 13:01:12 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Wed, 14 Jan 2004 12:01:12 +0000
Subject: [R] arrows on contour lines
Message-ID: <a06002016bc281f9119f1@[139.166.242.29]>

Hello everybody

I'm using contour() to draw streamlines of potential flow, eg

  jj <- seq(from= -4, to=4,len=20)
  jj <- outer(jj,jj,function(x,y){x})+1i*outer(jj,jj,function(x,y){y})

  f <- function(x){x^2}
  contour(Im(f(jj)), nlevels=44 , labels="")

How best to put arrows on the contour lines to show the direction of flow?
  (ie  I want contour lines looking like ---<---  and ---->----)

I think this is a lot of work, which I don't mind doing, but it'd be 
good to hear the list's ideas before starting to bark up the wrong 
tree, so to speak.



-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From ligges at statistik.uni-dortmund.de  Wed Jan 14 13:24:02 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 14 Jan 2004 13:24:02 +0100
Subject: [R] R killed on Solaris
In-Reply-To: <200401131612.i0DGChaa032121@hugo.obs.ee>
References: <200401131612.i0DGChaa032121@hugo.obs.ee>
Message-ID: <400534E2.2040608@statistik.uni-dortmund.de>

Ott Toomet wrote:
> Hello,
> 
> I am running a preliminary data-processing job on solaris.  Basically,
> the program reads a large number of ascii-lines (about 1M) by blocks
> (size 25000 lines), selects suitable observations (around 5000) and
> writes the results into a dataframe for latter processing.
> 
> The problem is that when I run the job interactively (in emacs/ESS),
> everything works fine.  If I try to run it from shell using R CMD
> BATCH, R will be killed after around 100 000 lines.  Solaris says
> simply "killed" and thats it.  The total memory consumption seems not
> to be a problem, around 200M on a 4G machine.  

200M of the data size processed or 200M of RAM consumption by R?
Does the .Rout file tell you anything interesting?

200M RAM is nothing, hence only an issue if there are quotas defined on 
your system.

Uwe Ligges


BTW: R-1.8.1 is recent.



> Any suggestions?  Has anyone else seen something similar?
> 
> Best wishes
> 
> Ott
> ---
> this is R 1.7.1, compiled as 32-bit appication, on 64bit sparc solaris
> 9 (sunos 5.9).
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From petr.pikal at precheza.cz  Wed Jan 14 13:38:59 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 14 Jan 2004 13:38:59 +0100
Subject: [R] arrows on contour lines
In-Reply-To: <a06002016bc281f9119f1@[139.166.242.29]>
Message-ID: <40054673.212.13B2EB4@localhost>

Hi

On 14 Jan 2004 at 12:01, Robin Hankin wrote:

> Hello everybody
> 
> I'm using contour() to draw streamlines of potential flow, eg
> 
>   jj <- seq(from= -4, to=4,len=20)
>   jj <- outer(jj,jj,function(x,y){x})+1i*outer(jj,jj,function(x,y){y})
> 
>   f <- function(x){x^2}
>   contour(Im(f(jj)), nlevels=44 , labels="")

something like that 

contour(Im(f(jj)), nlevels=44 , labels=c(">","<"))

will give you direction.

I would use some coded vector of directions for selecting a direction

> vec<-rep(c(1,2),22)
> set.seed(1)
> vec<-sample(vec,44)
>   contour(Im(f(jj)), nlevels=44 , labels=c(">","<")[vec])

will give you directions.

Hope this helps

Petr

> 
> How best to put arrows on the contour lines to show the direction of
> flow?
>   (ie  I want contour lines looking like ---<---  and ---->----)
> 
> I think this is a lot of work, which I don't mind doing, but it'd be
> good to hear the list's ideas before starting to bark up the wrong
> tree, so to speak.
> 
> 
> 
> -- 
> Robin Hankin
> Uncertainty Analyst
> Southampton Oceanography Centre
> SO14 3ZH
> tel +44(0)23-8059-7743
> initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam
> precaution)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From James_A_Rogers at groton.pfizer.com  Wed Jan 14 14:00:14 2004
From: James_A_Rogers at groton.pfizer.com (Rogers, James A [PGRD Groton])
Date: Wed, 14 Jan 2004 08:00:14 -0500
Subject: [R] RE: Trellis graph and two colors display
Message-ID: <C735670CCC69D61193DA0002A58EE9900AEB7461@groexmb07.pfizer.com>

>From: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
>
>Hello,
>
>I would like to display two groups of dots in different colors 
>or style and additionnaly a linear regression for all the dots in
>panel plots of a Trellis graph.  Actually to get in each panel 
>the equivalent of:
>
>plot(x[mois==3],y[mois==3],col="blue")
>points(x[mois==9],y[mois==9],col="red")
>abline(lm(y~x), col="green")
>
>"mois" being a grouping variable and ID (see below) the 
>conditioning variable in a data.frame of 230 rows
>
>After several really disatreous trials, I have tried the following:
>
>xyplot(y~x|ID,panel=function(x,y){panel.superpose(x,y,subscript
>s=1:230,groups=mois);panel.abline(lm(y~x),col="green")})
>

You don't need to mess around with the subscripts argument for this. I think
the problem is that you are not passing the necessary graphical parameters
to your panel function. You could do:

dat <- expand.grid(ID = 1:4, mois = c(3, 9))
dat <- dat[rep(seq(nrow(dat)), rep(10, nrow(dat))), ]
dat <- data.frame(dat, x = rnorm(nrow(dat)), y = rnorm(nrow(dat)))
dat$ID <- factor(dat$ID)

lset(list(superpose.symbol = list(col = c("blue", "red"), pch = c(1, 1))))

xyplot(y ~ x | ID, data = dat,
       groups = mois,
       panel = function(x, y, ...) {
         panel.superpose(x, y, ...)
         panel.abline(lm(y~x), col = "green")
       })

Cheers,
Jim 

James A. Rogers 
Manager, Biometrics
PGR&D Groton Labs
Eastern Point Road (MS 8260-1331)
Groton, CT 06340
office: (860) 686-0786
fax: (860) 715-5445
 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From ripley at stats.ox.ac.uk  Wed Jan 14 14:17:43 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Jan 2004 13:17:43 +0000 (GMT)
Subject: [R] Installing the Rcmdr and tclk package
In-Reply-To: <OF3EAAD383.88C63DC8-ON85256E1A.005F1F7D@spgdag.ca>
Message-ID: <Pine.LNX.4.44.0401141315400.16364-100000@gannet.stats>

On Tue, 13 Jan 2004 Gerald.Jean at spgdag.ca wrote:

> Hello R-users,
> 
> Version 1.8.1 on a 64-bit Solaris 5.8 OS
> 
> I am trying to instal the Rcmdr package for which the tclk package is
> required.  Once both package installed I issued the command:
> 
> > library(tcltk)
> 
> and received the following error message
> 
> Error in firstlib(which.lib.loc, package) :
>       Tcl/Tk support is not available on this system
> Error in library(tcltk) : .First.lib failed
> 
> Upon which I searched for Tcl and Tk on our system and didn't find them,
> hence I requested the admin. person to get them from the "sunfreeware" site
> and install them.  The packages are now installed under "/usr/local", same
> place than R is installed.  If I open a shell and cd to this directory and
> type "tcl" at the Unix prompt "tcl" starts.  But if go back in R and try
> the "library(tcltk)" command I receive the same error message as above.
> 
> I searched the "r-projec", the tcltk documentation and the mail archives in
> the hope of finding out if environment variables needed to be set or if I
> had missed something else, but I had no luck!

Tcl/Tk has to be available when you build R, not just at run time.

I am pretty sure that for a 64-bit build of R you need a 64-bit build of 
Tcl/Tk.

> Anyone could point me in the right direction as what needs to be done so
> Tcl and Tk become visible to R?

Rebuild R, preferably after compiling Tcl/Tk from the sources yourself (it 
is probably simpler than build R).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Wed Jan 14 14:17:33 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 14 Jan 2004 08:17:33 -0500
Subject: [R] data structure problem
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7607@usrymx25.merck.com>

If the data somewhat resembles multivariate Gaussian, I suppose one
possibility is to construct (by hand) something like LDA, but with the
covariance matrix constrained to be block-diagonal.  Just an idea.

Cheers,
Andy


> From: Jieping [mailto:jzhao at unity.ncsu.edu] 
> 
> my situtation is that each data point is made up of p 
> correlated 5-dimension
> vectors. Those 5 dimensions are orthogonal.
> Any suggestions will be appreciated!
> 
> JP
>
> From: Liaw, Andy [mailto:andy_liaw at merck.com]
> 
> Without more information on the context of the data, it's 
> hard to say much
> that will be useful.
> 
> One possibility is to treat the 5*p entries as 5*p variables, 
> and apply the
> commonly available discriminant tools to that.  Given more 
> information, it
> might be possible to do better.  As an example, one data set 
> that has been
> used as benchmark is the scanned images of hand-written 
> digits.  Each digit
> is encoded in a k x k matrix of values expressing the 
> grayscale level of
> each pixel (don't remember what k is).  A straight-forward 
> way to train a
> algorithm for pattern recognition is to treat the data as having kxk
> variables.  However, smarter (but custom-built, rather than 
> off-the-shelf)
> algorithms can make use of the fact that the data is actually 
> an image, and
> possibly get better results.
> 
> Cheers,
> Andy
> 
> > From: Jieping
> >
> > HI, there,
> >    I have a data set with special structure.
> >    It is in n*(5*p): n is the number of observations or data points
> >                      5*p is the matrix for each data point
> >    I'd like to conduct discriminant analysis to this data
> > set. How could I
> > do? And where could I find related references to solve this problem?
> >
> > Thanks a lot!
> >
> >
> > Jieping Zhao
> > PhD student in Bioinformatics, NCSU
> > Lab homepage: http://coltrane.gnets.ncsu.edu/index.html
> >
> 
> 
> --------------------------------------------------------------
> --------------
> --
> Notice:  This e-mail message, together with any attachments, contains
> information of Merck & Co., Inc. (One Merck Drive, Whitehouse 
> Station, New
> Jersey, USA 08889), and/or its affiliates (which may be known 
> outside the
> United States as Merck Frosst, Merck Sharp & Dohme or MSD) that may be
> confidential, proprietary copyrighted and/or legally 
> privileged, and is
> intended solely for the use of the individual or entity named on this
> message.
> If you are not the intended recipient, and have received this 
> message in
> error, please immediately return this by e-mail and then delete it.
> --------------------------------------------------------------
> --------------
> --
> 
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From seanpor at acm.org  Wed Jan 14 14:21:20 2004
From: seanpor at acm.org (Sean O'Riordain)
Date: Wed, 14 Jan 2004 13:21:20 +0000
Subject: [R] R killed on Solaris
In-Reply-To: <200401131612.i0DGChaa032121@hugo.obs.ee>
References: <200401131612.i0DGChaa032121@hugo.obs.ee>
Message-ID: <40054250.2090904@acm.org>

Hi Ott,

could it be a per process "limit" or "ulimit"s set?

i don't have a solaris box here so i can't remember what the appropriate 
commands are...

cheers,
Sean


Ott Toomet wrote:
> Hello,
> 
> I am running a preliminary data-processing job on solaris.  Basically,
> the program reads a large number of ascii-lines (about 1M) by blocks
> (size 25000 lines), selects suitable observations (around 5000) and
> writes the results into a dataframe for latter processing.
> 
> The problem is that when I run the job interactively (in emacs/ESS),
> everything works fine.  If I try to run it from shell using R CMD
> BATCH, R will be killed after around 100 000 lines.  Solaris says
> simply "killed" and thats it.  The total memory consumption seems not
> to be a problem, around 200M on a 4G machine.  
> 
> Any suggestions?  Has anyone else seen something similar?
> 
> Best wishes
> 
> Ott
> ---
> this is R 1.7.1, compiled as 32-bit appication, on 64bit sparc solaris
> 9 (sunos 5.9).
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From jennyb at raunvis.hi.is  Wed Jan 14 14:20:54 2004
From: jennyb at raunvis.hi.is (=?iso-8859-1?Q?Jenn=FD_Brynjarsd=F3ttir?=)
Date: Wed, 14 Jan 2004 13:20:54 -0000
Subject: [R] Fixed parameters in an AR (or arima) model
Message-ID: <026701c3daa1$3d9bb3f0$4946d082@ibms7rj0morjbg>

Hello

I want to fit an AR model were two of the coefficients are fixed to zero
(the second and third ar-coefficients).

I used the "arima" function with the "fixed" argument but the ar3
coefficient is not set to zero:

==============================================
> arima(Y, order=c(4,0,0), xreg=1:23, fixed=c(NA,0,0,NA,NA,NA))

Call:
arima(x = Y, order = c(4, 0, 0), xreg = 1:23, fixed = c(NA, 0, 0, NA, NA,
NA))

Coefficients:
         ar1  ar2     ar3      ar4  intercept     1:23
       0.5370    0  0.4338  -0.8078     5.2991  -0.0421
s.e.  0.0735    0  0.0000   0.1096     0.1081   0.0079

sigma^2 estimated as 0.02665:  log likelihood = 6.77,  aic = -3.54
===============================================

Why?

Thanks,
Jenn? Brynjarsd?ttir



From Gerald.Jean at spgdag.ca  Wed Jan 14 14:43:39 2004
From: Gerald.Jean at spgdag.ca (Gerald.Jean@spgdag.ca)
Date: Wed, 14 Jan 2004 08:43:39 -0500
Subject: =?iso-8859-1?Q?R=E9f=2E_=3A_[R]_email_problem?=
Message-ID: <OF2EEE0146.7599792A-ON85256E1B.004B37DC@spgdag.ca>


Hello R-users,

same here no PM (EST) mail.  I posted a message and never saw it appear in
my mail box and no other R-mail in the afternoon yesterday.

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming



From bruno at speech.kth.se  Wed Jan 14 14:47:31 2004
From: bruno at speech.kth.se (Bruno Giordano)
Date: Wed, 14 Jan 2004 14:47:31 +0100
Subject: [R] non-nested models testing
Message-ID: <011501c3daa4$f5ac5730$b943ed82@brungio>

Hi,
I'm trying to figure out some stastistics for non-nested models testing.
Among them:
[1] Vuong statistic (Vuong, 1989)
[2] Distribution-free test by Clarke (2003).
Did someone wrote a piece of [R] code to compute any of them?
Many thanks,
    Bruno

~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Bruno L. Giordano - Ph. D. student
Dipartimento di Psicologia Generale
Via Venezia 8 - 35131 Padova, Italy

currently hosted by

KTH - Royal Institute of Technology
TMH - Department of Speech, Music and Hearing
Drottning Kristinas v. 31
SE-100 44 Stockholm, Sweden



From sekemp at glam.ac.uk  Wed Jan 14 14:53:10 2004
From: sekemp at glam.ac.uk (Samuel Kemp (Comp))
Date: Wed, 14 Jan 2004 13:53:10 +0000
Subject: [R] univariant time series
Message-ID: <400549C6.3010900@glam.ac.uk>

Hi,

I am trying to use the stl function in the ts package. It requires that 
the data is a univariant time series at the moment my data is in a 
vector. I have coerced it to a time series using....

crimets <- ts(crimeData)

However, this does not work.

Does anyone have any suggestions?

Cheers,

Sam.

p.s. I am fairly new to R so apologies if this is a stupid posting.



From SuzieBlatt at netscape.net  Wed Jan 14 15:05:28 2004
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Wed, 14 Jan 2004 09:05:28 -0500
Subject: [R] cca in vegan
Message-ID: <45DDFB32.0B124A34.0D1322AF@netscape.net>

Hello all,

I'm hoping this is a simple problem.

I'm trying to do cca of my data.  I have my plant data and environmental data as 2 separate files.  I have 3 years of data, stacked vertically, within these files.  I want to conduct the cca for each year and am trying to create separate year files using the following:

cnts94 <- cnts[1:27,]
env94 <- env[1:27,]

when I run

cca(cnts94, env94)

I get the following error message:

Error in cca.default(cnts94, env94): All row and column sums must be >0 in the community matrix

There are no missing data points in the data set.

If I run the whole data set:

cca(cnts, env)

it works, and I can plot and do all the associated stuff.

Why not work if I specify a smaller data set?  Am I specifying it wrong?

Thanks,
Suzanne

__________________________________________________________________
New! Unlimited Netscape Internet Service.
Only $9.95 a month -- Sign up today at http://isp.netscape.com/register



From hrust at pik-potsdam.de  Wed Jan 14 16:03:58 2004
From: hrust at pik-potsdam.de (Henning Rust)
Date: Wed, 14 Jan 2004 16:03:58 +0100
Subject: [R] seasonal fractional ARIMA models
Message-ID: <40055A5E.4040709@pik-potsdam.de>

Hello,
does anyone know about:

a) simulating seasonal ARIMA models? arima out of package ts can fit it, 
but it does not look like it can simulates data from seasonal models

b) fitting and simulating fractional seasonal ARIMA models?

Hints will be appreciated,
	Henning


-- 
Henning Rust
Potsdam Institute for Climate Impact Research
Dept. Integrated Systems Analysis
Tel.: #49/331/288-2596	
Fax.: #49/331/288-2640
PGP : pgp.mit.edu

Please avoid sending me Word or PowerPoint attachments,
send plain text or PDF instead.
See http://www.fsf.org/philosophy/no-word-attachments.html



From hrust at pik-potsdam.de  Wed Jan 14 16:15:47 2004
From: hrust at pik-potsdam.de (Henning Rust)
Date: Wed, 14 Jan 2004 16:15:47 +0100
Subject: [R] Fixed parameters in an AR (or arima) model
In-Reply-To: <026701c3daa1$3d9bb3f0$4946d082@ibms7rj0morjbg>
References: <026701c3daa1$3d9bb3f0$4946d082@ibms7rj0morjbg>
Message-ID: <40055D23.8080801@pik-potsdam.de>

Hi,
arima expects an order 4 model by specifying order=c(4,0,0). It looks 
like you want to fit an order 6 model with parameters 2 and 3 fixed to 
0. Try order=c(6,0,0) and fixed=c(NA,0,0,NA,NA,NA,NA), the last NA is 
for the intercept.
Henning


Jenn? Brynjarsd?ttir wrote:
> Hello
> 
> I want to fit an AR model were two of the coefficients are fixed to zero
> (the second and third ar-coefficients).
> 
> I used the "arima" function with the "fixed" argument but the ar3
> coefficient is not set to zero:
> 
> ==============================================
> 
>>arima(Y, order=c(4,0,0), xreg=1:23, fixed=c(NA,0,0,NA,NA,NA))
> 
> 
> Call:
> arima(x = Y, order = c(4, 0, 0), xreg = 1:23, fixed = c(NA, 0, 0, NA, NA,
> NA))
> 
> Coefficients:
>          ar1  ar2     ar3      ar4  intercept     1:23
>        0.5370    0  0.4338  -0.8078     5.2991  -0.0421
> s.e.  0.0735    0  0.0000   0.1096     0.1081   0.0079
> 
> sigma^2 estimated as 0.02665:  log likelihood = 6.77,  aic = -3.54
> ===============================================
> 
> Why?
> 
> Thanks,
> Jenn? Brynjarsd?ttir
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Henning Rust
Potsdam Institute for Climate Impact Research
Dept. Integrated Systems Analysis
Tel.: #49/331/288-2596	
Fax.: #49/331/288-2640
PGP : pgp.mit.edu

Please avoid sending me Word or PowerPoint attachments,
send plain text or PDF instead.
See http://www.fsf.org/philosophy/no-word-attachments.html



From ripley at stats.ox.ac.uk  Wed Jan 14 16:12:23 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Jan 2004 15:12:23 +0000 (GMT)
Subject: [R] Fixed parameters in an AR (or arima) model
In-Reply-To: <026701c3daa1$3d9bb3f0$4946d082@ibms7rj0morjbg>
Message-ID: <Pine.LNX.4.44.0401141506210.16460-100000@gannet.stats>

On Wed, 14 Jan 2004, Jenn? Brynjarsd?ttir wrote:

> Hello
> 
> I want to fit an AR model were two of the coefficients are fixed to zero
> (the second and third ar-coefficients).
> 
> I used the "arima" function with the "fixed" argument but the ar3
> coefficient is not set to zero:

See the help page: you have forgotten about transform.pars. In the current
version of R (1.8.1) this works for me, with a warning, so I surmise your
version is not the current one (indeed looks like it is 1.7.0 or earlier).

> Y <- rnorm(23)
> arima(Y, order=c(4,0,0), xreg=1:23, fixed=c(NA,0,0,NA,NA,NA))

Call:
arima(x = Y, order = c(4, 0, 0), xreg = 1:23, fixed = c(NA, 0, 0, NA, NA, 
NA))

Coefficients:
          ar1  ar2  ar3      ar4  intercept    1:23
      -0.4515    0    0  -0.0415    -0.3711  0.0236
s.e.   0.2414    0    0   0.2336     0.1991  0.0147

sigma^2 estimated as 0.4303:  log likelihood = -23.05,  aic = 56.11
Warning message:
some AR parameters were fixed: setting transform.pars = FALSE in: arima(Y, 
order = c(4, 0, 0), xreg = 1:23, fixed = c(NA, 0, 0,

If you really have only 23 observations you are expecting a lot here!

> 
> ==============================================
> > arima(Y, order=c(4,0,0), xreg=1:23, fixed=c(NA,0,0,NA,NA,NA))
> 
> Call:
> arima(x = Y, order = c(4, 0, 0), xreg = 1:23, fixed = c(NA, 0, 0, NA, NA,
> NA))
> 
> Coefficients:
>          ar1  ar2     ar3      ar4  intercept     1:23
>        0.5370    0  0.4338  -0.8078     5.2991  -0.0421
> s.e.  0.0735    0  0.0000   0.1096     0.1081   0.0079
> 
> sigma^2 estimated as 0.02665:  log likelihood = 6.77,  aic = -3.54
> ===============================================
> 
> Why?
> 
> Thanks,
> Jenn? Brynjarsd?ttir


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rodrigo.abt at sii.cl  Wed Jan 14 16:35:39 2004
From: rodrigo.abt at sii.cl (Rodrigo Abt)
Date: Wed, 14 Jan 2004 12:35:39 -0300
Subject: [R] summary() within a function
Message-ID: <000901c3dab4$10d663c0$2a01240a@rodrigoabt>

Ulisses, could you be a little more specific ?. What OS, R version and data
you are using ?

I've tested this as an example and works fine (at least for me):

> f<-function(){
	x<-1:10
	y<-rnorm(10)
	s<-lm(y~x+0)
	summary(s)
}

>f()

Call:
lm(formula = y ~ x + 0)

Residuals:
    Min      1Q  Median      3Q     Max
-1.8488 -0.6693  0.2065  0.5043  1.5903

Coefficients:
  Estimate Std. Error t value Pr(>|t|)
x  0.07631    0.05400   1.413    0.191

Rodrigo Abt B.,
SII, Chile.

---

Date: Wed, 14 Jan 2004 09:24:22 +0100
From: uaca at alumni.uv.es
Subject: [R] summary() within a function
To: r-help at stat.math.ethz.ch
Message-ID: <20040114082422.GA18168 at pusa.informat.uv.es>
Content-Type: text/plain; charset=iso-8859-1

I have the following function

f <- function {

	...

	model <- lm(rttx[,1] ~ rttx[,2] + 0);
	summary(model);

	...
}

while summary(model) shows the summary if I execute the function line by
line
in the Command Line Interface, if I call f() summary is silent

how to solve it? or is there workaround?

thanks in advance

	Ulisses

                Debian GNU/Linux: a dream come true
----------------------------------------------------------------------------
-
"Computers are useless. They can only give answers."            Pablo
Picasso

--->	Visita http://www.valux.org/ para saber acerca de la	<---
--->	Asociacisn Valenciana de Usuarios de Linux		<---



From ripley at stats.ox.ac.uk  Wed Jan 14 16:40:58 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Jan 2004 15:40:58 +0000 (GMT)
Subject: [R] seasonal fractional ARIMA models
In-Reply-To: <40055A5E.4040709@pik-potsdam.de>
Message-ID: <Pine.LNX.4.44.0401141536560.16626-100000@gannet.stats>

On Wed, 14 Jan 2004, Henning Rust wrote:

> Hello,
> does anyone know about:
> 
> a) simulating seasonal ARIMA models? arima out of package ts can fit it, 
> but it does not look like it can simulates data from seasonal models

Well, it doesn't simulate at all.  arima.sim simulates non-seasonal models
and you can just expand out a seasonal ARIMA model to get a non-seasonal 
one.

> b) fitting and simulating fractional seasonal ARIMA models?

For simulating, the same comment applies, using fracdiff.sim in package 
fracdiff.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mendigo at netcabo.pt  Wed Jan 14 16:52:24 2004
From: mendigo at netcabo.pt (M. M. Palhoto N. Rodrigues)
Date: Wed, 14 Jan 2004 15:52:24 -0000
Subject: [R] How can I test if a not independently and not identically
	distributed time series residuals' are uncorrelated ?
References: <18D602BD42B7E24EB810D6454A58DB90047307BA@ibfftce505.is.de.dresdnerkb.com>
Message-ID: <004201c3dab6$67ee9d60$65a616d5@galactic>

Ok I made Jarque-Bera test to the residuals (merv.reg$residual)

library(tseries)
jarque.bera.test(merv.reg$residual)
X-squared = 1772.369, df = 2, p-value = < 2.2e-16
And I reject the null hypotesis (H0: merv.reg$residual are normally
distributed)

So I know that:
1 - merv.reg$residual aren't independently distributed (Box-Ljung test)
2 - merv.reg$residual aren't indentically distributed (Breusch-Pagan test)
3 - merv.reg$residual aren't normally distributed (Jarque-Bera test)

My questions is:
It is possible merv.reg$residual   be uncorrelated ?
cov[residual_t, residual_(t+k)] = 0 ?
Even when residuals  are not independent distributed !
(and we know that they aren't normally distributed and they aren't
indentically distributed )
And how can I tested it ?

Thanks.


> Hint, if a ts is normally distributed then independence and
uncorrelatedness
> are equivalent, hence you can test for normally distributed errors (e.g.
> Jarque-Bera-Test).
>
> HTH,
> Bernhard
>
> >



From lecoutre at stat.ucl.ac.be  Wed Jan 14 16:53:45 2004
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Wed, 14 Jan 2004 16:53:45 +0100
Subject: [R] summary() within a function
In-Reply-To: <000901c3dab4$10d663c0$2a01240a@rodrigoabt>
References: <000901c3dab4$10d663c0$2a01240a@rodrigoabt>
Message-ID: <6.0.1.1.2.20040114165109.020c9130@stat4ux.stat.ucl.ac.be>


Unless 'summary' is the last evaluated object within your function (and 
then it is the one implicitely returned by the function), you have to 
explicitely ask for printing it:


f <- function {
         ...
         model <- lm(rttx[,1] ~ rttx[,2] + 0);
         # Print summary for the model
         print(summary(model));
         ...
}


At 16:35 14/01/2004, Rodrigo Abt wrote:
>Ulisses, could you be a little more specific ?. What OS, R version and data
>you are using ?
>
>I've tested this as an example and works fine (at least for me):
>
> > f<-function(){
>         x<-1:10
>         y<-rnorm(10)
>         s<-lm(y~x+0)
>         summary(s)
>}
>
> >f()
>
>Call:
>lm(formula = y ~ x + 0)
>
>Residuals:
>     Min      1Q  Median      3Q     Max
>-1.8488 -0.6693  0.2065  0.5043  1.5903
>
>Coefficients:
>   Estimate Std. Error t value Pr(>|t|)
>x  0.07631    0.05400   1.413    0.191
>
>Rodrigo Abt B.,
>SII, Chile.
>
>---
>
>Date: Wed, 14 Jan 2004 09:24:22 +0100
>From: uaca at alumni.uv.es
>Subject: [R] summary() within a function
>To: r-help at stat.math.ethz.ch
>Message-ID: <20040114082422.GA18168 at pusa.informat.uv.es>
>Content-Type: text/plain; charset=iso-8859-1
>
>I have the following function
>
>f <- function {
>
>         ...
>
>         model <- lm(rttx[,1] ~ rttx[,2] + 0);
>         summary(model);
>
>         ...
>}
>
>while summary(model) shows the summary if I execute the function line by
>line
>in the Command Line Interface, if I call f() summary is silent
>
>how to solve it? or is there workaround?
>
>thanks in advance
>
>         Ulisses
>
>                 Debian GNU/Linux: a dream come true
>----------------------------------------------------------------------------
>-
>"Computers are useless. They can only give answers."            Pablo
>Picasso
>
>--->    Visita http://www.valux.org/ para saber acerca de la    <---
>--->    Asociacisn Valenciana de Usuarios de Linux              <---
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



--------------------------------------------------
L'erreur est certes humaine, mais un vrai d?sastre
n?cessite un ou deux ordinateurs. Citation anonyme
--------------------------------------------------
Eric Lecoutre
Informaticien/Statisticien
Institut de Statistique / UCL

TEL (+32)(0)10473050       lecoutre at stat.ucl.ac.be
URL http://www.stat.ucl.ac.be/ISpersonnel/lecoutre



From bates at stat.wisc.edu  Wed Jan 14 16:56:00 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 14 Jan 2004 09:56:00 -0600
Subject: [R] prcomp: error code 17 from Lapack routine dgesdd
In-Reply-To: <OF0B63AF9E.2A0A2118-ON85256E1A.0078E007-85256E1A.00793D93@EU.novartis.net>
References: <OF0B63AF9E.2A0A2118-ON85256E1A.0078E007-85256E1A.00793D93@EU.novartis.net>
Message-ID: <6rn08q5xtb.fsf@bates4.stat.wisc.edu>

Admittedly this is a rather crytic message but it means that the
algorithm in dgesdd for determining the singular values did not
converge.  From the Lapack documentation for dgesdd

       INFO    (output) INTEGER
               = 0:  successful exit.
               < 0:  if INFO = -i, the i-th argument had an illegal value.
               > 0:  DBDSDC did not converge, updating process failed.

ryszard.czerminski at pharma.novartis.com writes:

> I am trying to use prcomp and I am getting this error:
> 
> > p <- prcomp(xtr, retx = TRUE, center = TRUE, scale = TRUE, tol = NULL)
> Error in La.svd(x, nu, nv, method) : error code 17 from Lapack routine 
> dgesdd
> > dim(xtr)
> [1]  301 2439
> 
> Does it mean that the matrix is to big ?



From tplate at blackmesacapital.com  Wed Jan 14 16:58:11 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Wed, 14 Jan 2004 08:58:11 -0700
Subject: [R] array(list(),c(2,5)) gives error in R 1.8.1
In-Reply-To: <1074072927.1570.4.camel@christophl>
Message-ID: <5.2.1.1.2.20040114083805.0534a448@mailhost.blackmesacapital.com>

I confirmed this -- array(list(), c(2,2)) works in R 1.6.2 and R 1.7.1, but 
not in R 1.8.0.  This appears to be due to a change in array(): rep(data, 
t1) was changed to rep.int(data, t1).  When data=list(), t1==Inf, and 
rep(data, t1) returns list(), while rep.int(data, t1) gives an 
error.  Here's a transcript from R 1.8.0:

 > array
function (data = NA, dim = length(data), dimnames = NULL)
{
     data <- as.vector(data)
     vl <- prod(dim)
     if (length(data) != vl) {
         t1 <- ceiling(vl/length(data))
         data <- rep.int(data, t1)
         if (length(data) != vl)
             data <- data[1:vl]
     }
     if (length(dim))
         dim(data) <- dim
     if (is.list(dimnames) && length(dimnames))
         dimnames(data) <- dimnames
     data
}
<environment: namespace:base>
 > rep(list(), Inf)
list()
 > rep.int(list(), Inf)
Error in rep.int(list(), Inf) : invalid number of copies in "rep"
In addition: Warning message:
NAs introduced by coercion
 > array(numeric(3), 0,0)
numeric(0)
 >

There's also the dangerous construct data[1:v1] in array() 
(data[seq(len=v1)] would be much safer).  However, it appears that the 1:0 
trap doesn't occur under normal circumstances (because if v1=0, then t1 
will be either 0 or Inf, and length(rep.int(data, t1)) will be 0 or an 
error will have occurred (with most common data types at 
least).  However^2, given that functions in R don't always produce the 
results one might expect, it might be safer to change this to 
data[seq(len=v1)].

A workaround is to give array() a data value of the correct length:

 > array(list()[1:4], c(2,2))
      [,1] [,2]
[1,] NULL NULL
[2,] NULL NULL
 >

-- Tony Plate

At Wednesday 10:35 AM 1/14/2004 +0100, you wrote:
>Hi
>
>In R 1.7 the following worked fine:
>
> > array(list(),c(2,5))
>      [,1] [,2] [,3] [,4] [,5]
>[1,] NULL NULL NULL NULL NULL
>[2,] NULL NULL NULL NULL NULL
>
>now in R 1.8.1 I get the error:
>
>Error in rep.int(data, t1) : invalid number of copies in "rep"
>In addition: Warning message:
>NAs introduced by coercion
>
>thanks for help, I need this possibility for storing objects (lm
>results) in an array
>
>cheers
>
>Christoph
>--
>Christoph Lehmann <christoph.lehmann at gmx.ch>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From uaca at alumni.uv.es  Wed Jan 14 17:12:32 2004
From: uaca at alumni.uv.es (uaca@alumni.uv.es)
Date: Wed, 14 Jan 2004 17:12:32 +0100
Subject: [R] summary() within a function
In-Reply-To: <6.0.1.1.2.20040114165109.020c9130@stat4ux.stat.ucl.ac.be>
References: <000901c3dab4$10d663c0$2a01240a@rodrigoabt>
	<6.0.1.1.2.20040114165109.020c9130@stat4ux.stat.ucl.ac.be>
Message-ID: <20040114161232.GA21834@pusa.informat.uv.es>

On Wed, Jan 14, 2004 at 04:53:45PM +0100, Eric Lecoutre wrote:
> 
> Unless 'summary' is the last evaluated object within your function (and 
> then it is the one implicitely returned by the function), you have to 
> explicitely ask for printing it:

Thanks for the explanation

> 
> 
> f <- function {
>         ...
>         model <- lm(rttx[,1] ~ rttx[,2] + 0);
>         # Print summary for the model
>         print(summary(model));
>         ...
> }

It worked as spected

regards

	Ulisses

                Debian GNU/Linux: a dream come true
-----------------------------------------------------------------------------
"Computers are useless. They can only give answers."            Pablo Picasso

--->	Visita http://www.valux.org/ para saber acerca de la	<---
--->	Asociaci?n Valenciana de Usuarios de Linux		<---



From abunn at montana.edu  Wed Jan 14 17:17:19 2004
From: abunn at montana.edu (Andy Bunn)
Date: Wed, 14 Jan 2004 09:17:19 -0700
Subject: [R] cca in vegan
In-Reply-To: <45DDFB32.0B124A34.0D1322AF@netscape.net>
Message-ID: <001201c3dab9$f452ae10$78f05a99@msu.montana.edu>

Curious.

> I get the following error message:
> 
> Error in cca.default(cnts94, env94): All row and column sums 
> must be >0 in the community matrix

Check the row and column sums if you haven't:
colSums(cnts94)
rowSums(cnts94)

There is probably a veg plot (row) that has all zeros in it.

Just a thought.
-Andy



From zednikova at yahoo.com  Wed Jan 14 17:25:06 2004
From: zednikova at yahoo.com (Mirka Zednikova)
Date: Wed, 14 Jan 2004 08:25:06 -0800 (PST)
Subject: [R] R equivalent of Splus peaks() function?
Message-ID: <20040114162506.77836.qmail@web12302.mail.yahoo.com>

If there something available in R that has the
functionality of the S-PLUS peaks() function?

Thanks,

Mirka



From mendigo at netcabo.pt  Wed Jan 14 17:21:57 2004
From: mendigo at netcabo.pt (M. M. Palhoto N. Rodrigues)
Date: Wed, 14 Jan 2004 16:21:57 -0000
Subject: [R] How can I test if time series residuals' are uncorrelated ? 
Message-ID: <005801c3daba$88298320$65a616d5@galactic>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040114/9bdc5f00/attachment.pl

From Pascal.Niklaus at unibas.ch  Wed Jan 14 17:30:45 2004
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Wed, 14 Jan 2004 17:30:45 +0100
Subject: [R] error message in plot(aov-object)
Message-ID: <40056EB5.3010003@unibas.ch>

Hi all,

A student at our institute asked me for help with the following problem:

After fitting an aov model, she wanted diagnostic plots, and got the 
following error message:

 > plot(p.aov)
Hit <Return> to see next plot:
Hit <Return> to see next plot:
Error in plot.window(xlim, ylim, log, asp, ...) :
        need finite ylim values
In addition: Warning message:
X11 used font size 8 when 9 was requested

The second plot was not produced. I then tried to produced the plot 
manually, which worked, and checked the range of the residuals:

 > qqnorm(resid(p.aov))
 > range(resid(p.aov))
[1] -0.2428688  0.2020649

She used R 1.7.1 on a Mac, but I reproduced the problem on R 1.8.1 under 
Linux.

Any help regarding the source of this problem is appreciated

Pascal



From Kurt.Sys at UGent.be  Wed Jan 14 17:41:17 2004
From: Kurt.Sys at UGent.be (Kurt Sys)
Date: Wed, 14 Jan 2004 17:41:17 +0100
Subject: [R] How can I test if time series residuals' are uncorrelated ? 
In-Reply-To: <005801c3daba$88298320$65a616d5@galactic>
References: <005801c3daba$88298320$65a616d5@galactic>
Message-ID: <1074098477.4005712dc3487@mail.ugent.be>

Hi,

I tried to unsubscribe because this emailadress won't be valid anymore from 
next week on. I send a mail to r-help-requests at stat.math.ethz.ch 
with 'unsubscribe'in the body, and got the following reply:


-----
Date:  Tue, 13 Jan 2004 11:04:11 +0100 
From:  r-help-bounces at stat.math.ethz.ch 
To:  kurt.sys at ugent.be 
Subject:  The results of your email commands 
Part(s):   2 unnamed message/rfc822 0.96 KB  
 
The results of your email command are provided below. Attached is your 
original message. 

- Results: 
    Kurt.Sys at UGent.be is not a member of the R-help mailing list 

- Done. 


 

 2.1 unnamed text/plain 0.01 KB  
 
unsubscribe 
-----

If I'm not a member of the list, why do I recieve the messages?


tnx,
Kurt.



From mn216 at columbia.edu  Wed Jan 14 17:35:12 2004
From: mn216 at columbia.edu (Murad Nayal)
Date: Wed, 14 Jan 2004 11:35:12 -0500
Subject: [R] model-based clustering
Message-ID: <40056FC0.2D049970@columbia.edu>



Hello,

I was wondering whether a Poisson mixture modeler/cluster analysis
package is available for R. I scanned CRAN packages and couldn't find
anything but I thought I'd ask. If not could anyone recommend a non-R
open source package. I have found 'snob' but this program seems a bit
hard to use in an automated, non interactive fashion.

regards,
Murad


-- 
Murad Nayal M.D. Ph.D.
Department of Biochemistry and Molecular Biophysics
College of Physicians and Surgeons of Columbia University
630 West 168th Street. New York, NY 10032
Tel: 212-305-6884	Fax: 212-305-6926



From otoomet at econ.dk  Wed Jan 14 17:49:40 2004
From: otoomet at econ.dk (Ott Toomet)
Date: Wed, 14 Jan 2004 17:49:40 +0100
Subject: [R] R killed on Solaris
In-Reply-To: <400534E2.2040608@statistik.uni-dortmund.de> (message from Uwe
	Ligges on Wed, 14 Jan 2004 13:24:02 +0100)
References: <200401131612.i0DGChaa032121@hugo.obs.ee>
	<400534E2.2040608@statistik.uni-dortmund.de>
Message-ID: <200401141649.i0EGneHg020189@hugo.obs.ee>

Hi,

thanks for you reply.  Actually I think it has more to do with solaris
than with R.  The simple workaround is to run the program
interactively.

 | Date: Wed, 14 Jan 2004 13:24:02 +0100
 | From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
 | 
 | 200M of the data size processed or 200M of RAM consumption by R?
 | Does the .Rout file tell you anything interesting?

This is 200M in all.  I dont think it is quotas, perhaps something
with stack size, but unfortunately I dont understand the manual
(e.g. http://docs.sun.com/db/doc/806-1075/6jacsnimq?a=view):

<quote>
killed

  Cause

   A process, which attempts to allocate large amounts of memory
   either as an array or by using malloc, fails when launched by the
   shell. This problem has been seen while allocating 240,000,000
   elements as either an array of doubles or using malloc to allocate
   the 1,920,000,000 bytes of space.

  Action

   This can have one of two causes. Resolve it accordingly.

   1. Lack of swap space

   Try running the program as root on the console; if it runs, this is
   not the problem.

   2. Stack size and data segment size are in conflict

   If  the stack size is set too large, this can conflict with the
   data segment, and the process cannot
   be started. Setting the stack size to the default value of 8192
   resolves this problem and allows the
   programs to start.
</quote>

I have used stack size 8192, ulimits seem to be ok.

 | 200M RAM is nothing, hence only an issue if there are quotas defined on 
 | your system.
 | 
 | Uwe Ligges
 | 
 | 
 | BTW: R-1.8.1 is recent.

R 1.7.1 may still be the most recent piece of software on that box.
You have probably seen servers before with strict usage policy and
admins who don't care much about software.  Other ,,cool'' stuff
include gcc 2.95 (which cannot make 64-bit executables on sparc) and
ghostscript 5.10.

Best wishes,

Ott

 | > Hello,
 | > 
 | > I am running a preliminary data-processing job on solaris.  
 | > writes the results into a dataframe for latter processing.
 | > 
 | > The problem is that when I run the job interactively (in emacs/ESS),
 | > everything works fine.  If I try to run it from shell using R CMD
 | > BATCH, R will be killed after around 100 000 lines.  Solaris says
 | > simply "killed" and thats it.  The total memory consumption seems not
 | > to be a problem, around 200M on a 4G machine.



From myao at ou.edu  Wed Jan 14 18:05:12 2004
From: myao at ou.edu (Yao, Minghua)
Date: Wed, 14 Jan 2004 11:05:12 -0600
Subject: [R] Help Needed on plot Function
Message-ID: <78B50CF247E5D04B8A5E02D001CC8E9A595BF1@XMAIL.sooner.net.ou.edu>

Dear all,
 
I want the title of the plot to print some parameters that change. Also, I want some spots on the plot to be labeled. Is that possible?
 
Thanks in advance for your help.
 
Minghua



From nortonsm at verizon.net  Wed Jan 14 18:11:21 2004
From: nortonsm at verizon.net (Scott Norton)
Date: Wed, 14 Jan 2004 12:11:21 -0500
Subject: [R] Collapsing a factor in R
Message-ID: <000801c3dac1$6f09c380$6901a8c0@scott>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040114/c90f78f0/attachment.pl

From p.dalgaard at biostat.ku.dk  Wed Jan 14 18:21:30 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Jan 2004 18:21:30 +0100
Subject: [R] How can I test if time series residuals' are uncorrelated ?
In-Reply-To: <1074098477.4005712dc3487@mail.ugent.be>
References: <005801c3daba$88298320$65a616d5@galactic>
	<1074098477.4005712dc3487@mail.ugent.be>
Message-ID: <x28yka4fad.fsf@biostat.ku.dk>

Kurt Sys <Kurt.Sys at UGent.be> writes:

> If I'm not a member of the list, why do I recieve the messages?

There was a messup in Zurich causing the outgoing queue to be stalled.
My guess is that you're receiving mails that were sent to you before
your subscription.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From abunn at montana.edu  Wed Jan 14 18:23:02 2004
From: abunn at montana.edu (Andy Bunn)
Date: Wed, 14 Jan 2004 10:23:02 -0700
Subject: [R] Help Needed on plot Function
In-Reply-To: <78B50CF247E5D04B8A5E02D001CC8E9A595BF1@XMAIL.sooner.net.ou.edu>
Message-ID: <002401c3dac3$220cd4d0$78f05a99@msu.montana.edu>

Look at ?substitute, ?expression, and ?paste. The archives are dense
with worked examples. Here's one example of a parameter in the title:

param <- pi
plot(1:100, log(1:100))
title(substitute(hat(theta) == param, list(param=param))) 

A search of the archives for "label points plot" turns up 100s of hits.
http://cran.r-project.org/search.html

HTH, Andy



From rpeng at jhsph.edu  Wed Jan 14 19:21:21 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 14 Jan 2004 13:21:21 -0500
Subject: [R] Collapsing a factor in R
In-Reply-To: <000801c3dac1$6f09c380$6901a8c0@scott>
References: <000801c3dac1$6f09c380$6901a8c0@scott>
Message-ID: <400588A1.2050203@jhsph.edu>

Will aggregate() do what you want?

-roger

Scott Norton wrote:
> I'm trying to collapse the following table along the sub-group factor.  In
> this case, collapsing means taking the average ages within a subgroup and
> creating a new table.  I seem to be running into trouble trying to create
> this new data frame. I can use the ave() function to find averages within a
> subgroup but how do I maintain the Group/Gender factors after collapsing?
> (see bottom table) Can anyone help??
> 
> Thanks in advance!!
> 
> Here's the starting point (table)
> 
> Age   Group  SubGroup	Gender
> 12	g1	a	f
> 32	g1	a	f
> 81	g1	a	f
> 63	g1	b	m
> 24	g1	b	m
> 24	g1	b	m
> 70	g1	c	f
> 82	g1	c	f
> 71	g1	c	f
> 61	g1	c	f
> 25	g2	d	m
> 29	g2	d	m
> 43	g2	e	f
> 17	g2	e	f
> 42	g2	e	f
> 55	g2	e	f
> 52	g2	f	f
> 19	g2	f	f
> 12	g2	f	f
> 
> The following is what I'm trying to achieve (as a new dataframe)
> 
> AvgAgeSubgroup	Group	Subgroup	Gender
> 41.67			g1	a		f
> 37			g1	b		m
> 71			g1	c		f
> 27			g2	d		m
> 39.25			g2	e		f
> 27.67			g2	f		f
> 
> Can anyone help?
> 
> -Scott
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Kristian.Omland at uvm.edu  Wed Jan 14 19:57:21 2004
From: Kristian.Omland at uvm.edu (Kristian Omland)
Date: Wed, 14 Jan 2004 13:57:21 -0500
Subject: [R] nonlinear regression and Excel solver
Message-ID: <40059111.3070207@uvm.edu>

Hi all,

Earlier today I posted this question on s-news, so apologies to some for 
the duplication.

> Please put aside your snobbery about Microsoft products for a moment.
> 
> I am fitting population models to annual survey data for trout. For those of you familiar with ecological models, I am working in the Lefkovitch matrix framework; for those unfamiliar with that shorthand, the modeled variable is a vector of abundances of fish in five size classes, with a system of linear equations (represented by a matrix) governing survival, advancement from smaller to larger stages, and reproduction.
> 
> So far, I have been using a likelihood approach in an Excel spreadsheet. The spreadsheet includes the annual survey data, the Lefkovitch matrix, and projections of the model, i.e., realizations to be compared to the data. It computes the negative log-likelihood of each realization assuming log-normally distributed noise and the sum of those likelihood components. I use the Solver add-in to minimize the negative log-likelihood over the parameters in the Lefkovitch matrix.
> 
> I have made a tentative stab at using nlminb() [minor success] and ms() [no success] to fit the model in S-Plus, but my proficiency is such that I still have greater flexibility fitting the models with Excel. Thus my question for you all is ...
> 
> Is Excel?s Solver an adequate tool for numerical approximation in general and nonlinear regression in particular? Or should I push on writing S-Plus code?
> 
> Is anyone out there interested in assisting me with S-Plus code with the potential payoff of collaboration on a publication in the ecological literature?

Obviously, I would be equally enthused if an R user was interested in a 
collaboration.

Thanks in advance,
Kristian
-- 
Kristian Omland
Postdoctoral Research Associate
Vermont Cooperative Fish & Wildlife Research Unit
Rubenstein School of Environment & Natural Resources
University of Vermont
Burlington VT 05405
voice: (802)656-2496 fax: (802)656-8683
web page: http://www.uvm.edu/~komland



From macq at llnl.gov  Wed Jan 14 20:02:16 2004
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 14 Jan 2004 11:02:16 -0800
Subject: [R] RMySQL : Not loading
In-Reply-To: <7B7CD71E-4685-11D8-B58F-000393AA6416@paradise.net.nz>
References: <7B7CD71E-4685-11D8-B58F-000393AA6416@paradise.net.nz>
Message-ID: <p06002008bc2b3b94dfab@[128.115.153.6]>

Geoff,

I can offer a work-around.

I have been encountering this same problem on one of two OS X 
systems, and one Solaris system. I've been corresponding with the 
RMySQL maintainer, David James (who I CC'd), and he knows everything 
that I do (and more, of course!). We don't have a proper solution 
yet, but here is a work-around that I found.

To get RMySQL working on the OS X system where it did not, I 
installed the gnugetopt package from fink, and then explicitly told 
RMySQL about it when installing RMySQL. In order to do this you first 
need to have a local copy of the RMySQL distribution file, 
RMySQL_0.5-3.tar.gz. Then, in the directory where that file resides 
define environment variables PKG_CPPFLAGS and PKG_LIBS so that:

    [198]% printenv | grep PKG
    PKG_CPPFLAGS=-I/usr/local/mysql/include -I/sw/include/gnugetopt
    PKG_LIBS=-L/usr/local/mysql/lib -lmysqlclient -lgnugetopt

Then,

R CMD INSTALL --configure-args='--with-mysql-dir=/usr/local/mysql' 
RMySQL_0.5-3.tar.gz

Be sure to replace /usr/local/mysql with whatever is correct for you.

This is only a work-around; there are a number of reasons to believe 
that getopt_long should be present and available when RMySQL is 
installed--but as long as it's not, this is one way to get it.

I have mysql 4.0.16-standard (binary distribution downloaded from 
www.mysql.com),  R 1.8.1 Patched (2004-01-12) (installed from source 
code), and OS X 10.2.8. The gcc is:

[205]% gcc -v
Reading specs from /usr/libexec/gcc/darwin/ppc/3.3/specs
Thread model: posix
gcc version 3.3 20030304 (Apple Computer, Inc. build 1493)



On my other OS X system, where I did not encounter this problem, I'm 
still at R 1.8.0; the mysql is 4.0.15, and it is the version 
distributed by Server Logistics at 
http://www.macintoshhosting.net/mysql.php. That machine is OS X 
10.3.something. I don't have the gcc version information handy.

David James has a successful installation with mysql installed from 
fink in 10.2.8, and R 1.8.1.

I hope this helps; stay tuned as I plan to keep working on this.

-Don


At 12:33 AM +1300 1/15/04, Geoff Grimwood wrote:
>Hello,
>
>I'm tearing my hair out over this. Any help will be very much 
>appreciated. It's been two long nights battling with RMySQL.
>
>>  library(RMySQL)
>Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library 
>"/usr/local/lib/R/library/RMySQL/libs/RMySQL.so":
>   dlcompat: dyld: /usr/local/lib/R/bin/R.bin Undefined symbols:
>_getopt_long
>Error in library(RMySQL) : .First.lib failed
>
>I am running Mac OS 10.2.8, R 1.8.1, RMySQL 0.5-3, MySQL 4.0.17. R 
>and MySQL are well otherwise
>
>I have moved away from the Fink sourced (ie /sw) version of R and 
>MySQL to regular /usr/local types. Mainly because the Fink R is 1.7 
>and can't do the MySQL business. And I was wondering if the RMySQL 
>install was comin to grief because it couldn't find the /sw mysql 
>files.
>
>Anyway, RMySQL seems to have install OK. I see it with 
>installed.packages(). There was the apparent inability to find 
>lmysqlclient and mysql.h but that seems to be a red herring (see 
>below).
>
>Regards
>
>Geoff Grimwood
>Wellington
>New Zealand
>
>
>[SIDLAW02:~/Desktop] geoff% sudo R CMD INSTALL 
>--configure-args='--with-mysql-inc=/usr/local/mysql/include 
>--with-mysql-lib=/usr/local/mysql/lib' RMySQL_0.5-3.tar.gz
>* Installing *source* package 'RMySQL' ...
>creating cache ./config.cache
>checking how to run the C preprocessor... cc -E
>checking for mysql_init in -lmysqlclient... no
>checking for mysql.h... no
>updating cache ./config.cache
>creating ./config.status
>creating src/Makevars
>** libs
>gcc -no-cpp-precomp -I/usr/local/lib/R/include 
>-I/usr/local/mysql/include -I/sw/include   -fno-common  -g -O2 -c 
>RS-DBI.c -o RS-DBI.o
>gcc -no-cpp-precomp -I/usr/local/lib/R/include 
>-I/usr/local/mysql/include -I/sw/include   -fno-common  -g -O2 -c 
>RS-MySQL.c -o RS-MySQL.o
>gcc -bundle -flat_namespace -undefined suppress -L/sw/lib 
>-L/usr/local/lib -o RMySQL.so RS-DBI.o RS-MySQL.o 
>-L/usr/local/mysql/lib -lmysqlclient -lz -lcc_dynamic 
>-L/usr/local/lib/R/bin -lR
>[SNIP]
>
>SIDLAW02:library/RMySQL/libs] geoff% ls -ltr
>total 500
>-rwxr-xr-x    1 root     staff      254816 Jan 14 23:45 RMySQL.so
>-rwxr-xr-x    1 root     staff      249856 Jan 14 23:46 libmySQL.dll
>-rw-r--r--    1 root     staff         155 Jan 14 23:46 libMySQL_4.0.16.txt
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From j.c.ten.holt at student.rug.nl  Wed Jan 14 20:03:54 2004
From: j.c.ten.holt at student.rug.nl (Janke ten Holt)
Date: Wed, 14 Jan 2004 20:03:54 +0100
Subject: [R] discriminant analysis
Message-ID: <4005929A.9050406@student.rug.nl>

Hello,

I have run a discriminant analysis (with lda() from the MASS package) 
but I can't find a way to examine the p-values for the discriminant 
functions. I would like to calculate a Wilk's lambda and then the 
Bartlett's V statistic which is distributed as a chi squared and test 
its significance, but I haven't found out how to do so. Can anyone help?

Thank you,
Janke ten Holt.



From james.lindsey at luc.ac.be  Wed Jan 14 20:35:57 2004
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Wed, 14 Jan 2004 20:35:57 +0100 (MET)
Subject: [R] copula functions
In-Reply-To: <OF69854154.7984320A-ONC1256E1B.0023241B@ch.abb.com> from
	"hanspeter.bornhauser@ch.abb.com" at Jan 14, 2004 07:25:25 AM
Message-ID: <200401141935.UAA15490@luc.ac.be>


> 
> Hi there
> 
> does anyone know about a downloadable CRAN for copula functions for R?

Not on CRAN, but on my homepage (www.luc.ac.be/~jlindsey/rcode.html).
gausscop in my repeated library handles gaussian copulas.
  Jim

> 
> Thank you so much for your answers.
> 
> Hanspeter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From maj at stats.waikato.ac.nz  Wed Jan 14 20:39:24 2004
From: maj at stats.waikato.ac.nz (maj@stats.waikato.ac.nz)
Date: Thu, 15 Jan 2004 08:39:24 +1300 (NZDT)
Subject: [R] model-based clustering
In-Reply-To: <40056FC0.2D049970@columbia.edu>
References: <40056FC0.2D049970@columbia.edu>
Message-ID: <10318.203.118.174.195.1074109164.squirrel@webmail.scms.waikato.ac.nz>

The list could probably be more useful if you gave more details about your
data and the problem. I have written a bit of R code myself for fitting a
finite mixture of univariate Poissons by EM and found it very simple to
program in R. I suspect that your problem is multivariate, but that should
not present any difficulties.

The Snob program employs a fairly sophisticated model search strategy
based on the Minimum Message Length criterion. If you do not know much
about the solution that you are seeking it might be a good way to go. I
appreciate that Snob can be rather complex to set up and get going but I
think that you should be able to get quite a bit of help from the Monash
University people behind the program. They are usually quite keen to
encourage new users of Snob.

Murray Jorgensen

>
> Hello,
>
> I was wondering whether a Poisson mixture modeler/cluster analysis
> package is available for R. I scanned CRAN packages and couldn't find
> anything but I thought I'd ask. If not could anyone recommend a non-R
> open source package. I have found 'snob' but this program seems a bit
> hard to use in an automated, non interactive fashion.
>
> regards,
> Murad
>
>
> --
> Murad Nayal M.D. Ph.D.
> Department of Biochemistry and Molecular Biophysics
> College of Physicians and Surgeons of Columbia University
> 630 West 168th Street. New York, NY 10032
> Tel: 212-305-6884	Fax: 212-305-6926
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>



From s.o at online.de  Wed Jan 14 20:40:18 2004
From: s.o at online.de (Simon Ohrem)
Date: Wed, 14 Jan 2004 20:40:18 +0100
Subject: [R] Testing a timeseries for heteroscedastic (lmtest)
Message-ID: <1074109218.19035.25.camel@billabong.weh.rwth-aachen.de>

Hello,

my intention is to test a given timeseries (vector) for heteroscedastic.
Now I found the gqtest/bptest/hmctest in the lmtest package but a
"formula" as argument is needed.
What is meant by formula and how du I interpret the timeseries as
formula.

Thanks in advance

Simon



From rodrigo.abt at sii.cl  Wed Jan 14 20:53:13 2004
From: rodrigo.abt at sii.cl (Rodrigo Abt)
Date: Wed, 14 Jan 2004 16:53:13 -0300
Subject: [R] summary() within a function
Message-ID: <000301c3dad8$0bdc3d80$2a01240a@rodrigoabt>

Ulisses, by the way I forgot something, If your function doesn?t end with
summary you'll have to print it explicitly

f<-function(){
 x<-1:10
 y<-rnorm(10)
 s<-lm(y~x+0)
 ...
 print(summary(s))
 ...
}

---

Date: Wed, 14 Jan 2004 09:24:22 +0100
From: uaca at alumni.uv.es
Subject: [R] summary() within a function
To: r-help at stat.math.ethz.ch
Message-ID: <20040114082422.GA18168 at pusa.informat.uv.es>
Content-Type: text/plain; charset=iso-8859-1

I have the following function

f <- function {

	...

	model <- lm(rttx[,1] ~ rttx[,2] + 0);
	summary(model);

	...
}

while summary(model) shows the summary if I execute the function line by
line
in the Command Line Interface, if I call f() summary is silent

how to solve it? or is there workaround?

thanks in advance

	Ulisses

                Debian GNU/Linux: a dream come true
----------------------------------------------------------------------------
-
"Computers are useless. They can only give answers."            Pablo
Picasso

--->	Visita http://www.valux.org/ para saber acerca de la	<---
--->	Asociacisn Valenciana de Usuarios de Linux		<---



Rodrigo Abt,
SII, Chile

 -----Mensaje original-----
De: 	Rodrigo Abt [mailto:rodrigo.abt at sii.cl]
Enviado el:	Mi?rcoles, 14 de Enero de 2004 12:36
Para:	'Lista de Correo de R'
CC:	'uaca at alumni.uv.es'
Asunto:	Re: [R] summary() within a function

Ulisses, could you be a little more specific ?. What OS, R version and data
you are using ?

I've tested this as an example and works fine (at least for me):

> f<-function(){
	x<-1:10
	y<-rnorm(10)
	s<-lm(y~x+0)
	summary(s)
}

>f()

Call:
lm(formula = y ~ x + 0)

Residuals:
    Min      1Q  Median      3Q     Max
-1.8488 -0.6693  0.2065  0.5043  1.5903

Coefficients:
  Estimate Std. Error t value Pr(>|t|)
x  0.07631    0.05400   1.413    0.191

Rodrigo Abt B.,
SII, Chile.

---

Date: Wed, 14 Jan 2004 09:24:22 +0100
From: uaca at alumni.uv.es
Subject: [R] summary() within a function
To: r-help at stat.math.ethz.ch
Message-ID: <20040114082422.GA18168 at pusa.informat.uv.es>
Content-Type: text/plain; charset=iso-8859-1

I have the following function

f <- function {

	...

	model <- lm(rttx[,1] ~ rttx[,2] + 0);
	summary(model);

	...
}

while summary(model) shows the summary if I execute the function line by
line
in the Command Line Interface, if I call f() summary is silent

how to solve it? or is there workaround?

thanks in advance

	Ulisses

                Debian GNU/Linux: a dream come true
----------------------------------------------------------------------------
-
"Computers are useless. They can only give answers."            Pablo
Picasso

--->	Visita http://www.valux.org/ para saber acerca de la	<---
--->	Asociacisn Valenciana de Usuarios de Linux		<---



From buter at cwts.leidenuniv.nl  Wed Jan 14 21:08:05 2004
From: buter at cwts.leidenuniv.nl (Renald Buter)
Date: Wed, 14 Jan 2004 21:08:05 +0100
Subject: [R] Using pam, agnes or clara as prediction models?
Message-ID: <20040114200805.GA18663@infinite.fsw.leidenuniv.nl>

Hello list,

I am new to R, so if the question is rather silly, please ignore it.

I was wondering wether it would be possible to use the models generated
by pam, clara and the like as predictors? Scanning through the available
documentation shed no light (for me) upon the subject.

Regards,

Renald



From fredrik.lundgren at norrkoping.mail.telia.com  Wed Jan 14 21:10:51 2004
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Wed, 14 Jan 2004 21:10:51 +0100
Subject: [R] estimation of lambda and gamma with std errors for a weibull model
Message-ID: <005001c3dada$833dd8a0$2d0ffea9@oemcomputer>

Dear R experts,

How should lambda and gamma (with std.errors) be calculated for a weibull model with age as an independent predictor? I have assumed that this can be done with survreg with e. g. (summary(survreg(Surv(time, status) ~ age, dist = 'weibull')) ) and predict.survreg with e.g. (predict(model, se.fit = T,  newdata = data.frame(age = seq(50, 80, 5)) but unfortunately I'm uncapable to sort out how to get the lambda and gamma values (with std.errors). I haven't found any example of this in the help pages and would really appreciate  any help!

With best wishes and thanks in advance for any help

Fredrik Lundgren



From andy_liaw at merck.com  Wed Jan 14 21:18:10 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 14 Jan 2004 15:18:10 -0500
Subject: [R] Using pam, agnes or clara as prediction models?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7617@usrymx25.merck.com>

If pam produces the cluster medoids, you should be able to use the
1-nearest-neighbor classifier for prediction of future data, using the
medoids as the `training' data.  1-NN is available in the `class' package,
part of the `VR' bundle.

HTH,
Andy

> From: Renald Buter
> 
> Hello list,
> 
> I am new to R, so if the question is rather silly, please ignore it.
> 
> I was wondering wether it would be possible to use the models 
> generated
> by pam, clara and the like as predictors? Scanning through 
> the available
> documentation shed no light (for me) upon the subject.
> 
> Regards,
> 
> Renald


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From Gerald.Jean at spgdag.ca  Wed Jan 14 21:59:43 2004
From: Gerald.Jean at spgdag.ca (Gerald.Jean@spgdag.ca)
Date: Wed, 14 Jan 2004 15:59:43 -0500
Subject: [R]Update on:  Installing the Rcmdr and tclk package
Message-ID: <OFF013E77A.0CA4CD2C-ON85256E1B.00709DEB@spgdag.ca>

Hello R-users,

first thanks to all who responded my questions regarding the installation
of the Rcmdr and tcltk packages.  The problem is with the tclk package on
which Rcmdr depends.

Following Prof Ripley's advice I re-installed Tcl and Tk, compiling from
sources and making sure the "--enable-64bit" option of their configure was
set and setting the environment variable "CC" to "cc" since I want to
compile R in 64bit and
use the Sunpro "cc" compiler.  Everything worked fine. CDing to the tcl
directory and typing "wish8.4" at the Unix prompt started tk, similarly
tclsh8.4 started tcl.

I then rebuilt R from the sources again, setting the appropriate C and
Fortran flags in "config.site", as in the "R Installation and Admin" and
specifying the options:
"with-tcl-config=/path to the tclConfig.sh file" and
"with-tk-config=/path to the tkConfig.sh file" for configure.

configure still gave me the following warning:

checking for /home/jeg002/tcl8.4.5/lib... /home/jeg002/tcl8.4.5/lib
checking for /home/jeg002/tcl8.4.5/lib... /home/jeg002/tcl8.4.5/lib
./configure: .: /home/jeg002/tcl8.4.5/lib: is a directory
./configure: test: -lt: unary operator expected
./configure: .: /home/jeg002/tcl8.4.5/lib: is a directory
./configure: test: -lt: unary operator expected
configure: WARNING: Tcl and Tk major or minor versions disagree

I also had this message on the first built of R.  But looking up in
tclConfig.sh I get for version:

# Tcl's version number.
TCL_VERSION='8.4'
TCL_MAJOR_VERSION='8'
TCL_MINOR_VERSION='4'
TCL_PATCH_LEVEL='.5'

and in tkConfig.sh I get:

# Tk's version number.
TK_VERSION='8.4'
TK_MAJOR_VERSION='8'
TK_MINOR_VERSION='4'
TK_PATCH_LEVEL='.5'

sure look the same to me?  Then make worked fine as did make check, I only
got and error upon checking internet connection, which is problematic at
this time on our Sun server (I get the R, Tcl, etc. distributions through
Internet Explorer on my PC, which as a connection to the Unix machine).
Then make install worked fine, R seems to work fine, but again if I try to
attach the tcltk library I get:

> library(tcltk)
Error in firstlib(which.lib.loc, package) :
      Tcl/Tk support is not available on this system
Error in library(tcltk) : .First.lib failed

which I could predict of course since the "tcltk" file in the
.../library/tcltk/R had only the ".First.lib" function with the unique
command "stop(Tcl / Tk support blablabla)".

I am puzzled, and very frustrated, I have no idea what to look next, not
even what to think next!  Does the problem lie with the OS, Tcl/Tk, R, me
(most likely), something else?

Any insights very (extremely) welcome, thanks,

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming



From mn216 at columbia.edu  Wed Jan 14 22:00:40 2004
From: mn216 at columbia.edu (Murad Nayal)
Date: Wed, 14 Jan 2004 16:00:40 -0500
Subject: [R] model-based clustering
References: <40056FC0.2D049970@columbia.edu>
	<10318.203.118.174.195.1074109164.squirrel@webmail.scms.waikato.ac.nz>
Message-ID: <4005ADF8.C66D1026@columbia.edu>


Hello Murray,

thanks for the response. I would actually love to hear alternative
suggestions about the problem I am trying to solve. I just thought a
short question will be less of a burden on people's time and have a
higher chance of being answered.

basically the data sets I need to analyze contain 2000-10000 objects.
each characterized by, depending on the data set, 9-20 attributes. all
integers greater than zero, typically the range is [0,1000] with numbers
< 5 particularly common. there is no apriori reason why these objects
should cluster into discrete groups. and in fact when the data is
explored graphically (xgobi) it doesn't show an obvious clustering
pattern. however, with 9-20 dimensions involved, it is probably easy to
miss subtle patterns. I have tried clustering the data using a number of
standard approaches including hclust,kmeans,fanny etc. but these methods
didn't seem to be able to generate convincingly distinct, homogeneous
clusters. of course given the type of the data involved Poisson mixtures
seem like the natural choice.

I have experimented a bit with snob using contrived data sets (where you
know which class objects really belong to) and it has been fairly
promising, except maybe for snob's tendency to break the known classes
into multiple subclasses. 

I actually would like to try to code this in R. It would be very helpful
to me in fact if you can contribute any code/code fragments/examples
from your earlier work on this, either to the list or privately.

many thanks
Murad



maj at stats.waikato.ac.nz wrote:
> 
> The list could probably be more useful if you gave more details about your
> data and the problem. I have written a bit of R code myself for fitting a
> finite mixture of univariate Poissons by EM and found it very simple to
> program in R. I suspect that your problem is multivariate, but that should
> not present any difficulties.
> 
> The Snob program employs a fairly sophisticated model search strategy
> based on the Minimum Message Length criterion. If you do not know much
> about the solution that you are seeking it might be a good way to go. I
> appreciate that Snob can be rather complex to set up and get going but I
> think that you should be able to get quite a bit of help from the Monash
> University people behind the program. They are usually quite keen to
> encourage new users of Snob.
> 
> Murray Jorgensen
> 
> >
> > Hello,
> >
> > I was wondering whether a Poisson mixture modeler/cluster analysis
> > package is available for R. I scanned CRAN packages and couldn't find
> > anything but I thought I'd ask. If not could anyone recommend a non-R
> > open source package. I have found 'snob' but this program seems a bit
> > hard to use in an automated, non interactive fashion.
> >
> > regards,
> > Murad
> >
> >
> > --
> > Murad Nayal M.D. Ph.D.
> > Department of Biochemistry and Molecular Biophysics
> > College of Physicians and Surgeons of Columbia University
> > 630 West 168th Street. New York, NY 10032
> > Tel: 212-305-6884     Fax: 212-305-6926
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >

-- 
Murad Nayal M.D. Ph.D.
Department of Biochemistry and Molecular Biophysics
College of Physicians and Surgeons of Columbia University
630 West 168th Street. New York, NY 10032
Tel: 212-305-6884	Fax: 212-305-6926



From rvaradha at jhsph.edu  Wed Jan 14 22:11:22 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Wed, 14 Jan 2004 16:11:22 -0500
Subject: [R] Generalized least squares using "gnls" function
Message-ID: <24ca0124cbe2.24cbe224ca01@jhsph.edu>

Hi:

I have data from an assay in the form of two vectors, one is response 
and the other is a predictor. When I attempt to fit a 5 parameter 
logistic model with "nls", I get converged parameter estimates. I also 
get the same answers with "gnls" without specifying the "weights" 
argument.

However, when I attempt to use the "gnls" function and try to estimate 
the variance function, as a power function, I get the following error 
message:

> ans51g <- gnls(log(b51) ~ p0 + p1/(1 + exp(-(log(dose)-p2)/p3))^p4, 
start=list(p0=3,p1=1,p2=4,p3=2,p4=1.5),control=gnlsControl(tol=1.e-
07),weights=varPower())
Error in eval(expr, envir, enclos) : Object "." not found
> 

What am I doing wrong here and how can I do a GLS analysis with a 
variance function that is estimated from the data?

Here is my data:

> b51 <- c(17447.60674, 7060.37234, 2872.53012,  796.40426,  
454.47222,  260.22340,  120.11905,    83.40196,  51.45745,    
36.87912,  26.73256,    25.18681, 17.97674)
> dose <- c( 1.000000e+04, 1.000000e+03, 2.500000e+02, 6.250000e+01, 
3.125000e+01,  1.562500e+01, 7.812500e+00, 3.906250e+00, 
1.953125e+00, 9.765625e-01, 4.882813e-01, 2.441406e-01, 1.000000e-03)

thanks for the help,
Ravi.



From bolker at zoo.ufl.edu  Wed Jan 14 22:34:22 2004
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Wed, 14 Jan 2004 16:34:22 -0500 (EST)
Subject: [R] rcmd check question.
Message-ID: <Pine.LNX.4.44.0401141353590.30771-100000@bolker.zoo.ufl.edu>


  I was getting similar errors, which I finally tracked down to the 
following:

  I had accidentally left an extraneous "test.R" in my pkg/R directory;  
that file contained a system call to an external program that created a
particular file, which I then tried to read into R.  The R code that
triggered the error from .tryQuietly was the attempt to open the file. I
figured this out by stripping the "test.R" file down to

system("test1.bin")
con <- file("test.out","r")

where "test1.bin" is a binary executable that produces a file called 
"test.out". 

Wrapping the lines above in a function, so they don't get executed when R 
evaluates the code, also gets rid of the problem.

  Apparently (I surmise) R does find the binary (replacing
system("test.bin") with system("junk") produces a warning message), but
the file that gets created gets cleaned up or put somewhere other than the 
current working directory.

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From gb at stat.umu.se  Wed Jan 14 22:45:56 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 14 Jan 2004 22:45:56 +0100
Subject: [R] estimation of lambda and gamma with std errors for a weibull
	model
In-Reply-To: <005001c3dada$833dd8a0$2d0ffea9@oemcomputer>
References: <005001c3dada$833dd8a0$2d0ffea9@oemcomputer>
Message-ID: <20040114214556.GB2440@stat.umu.se>

On Wed, Jan 14, 2004 at 09:10:51PM +0100, Fredrik Lundgren wrote:
> Dear R experts,
> 
> How should lambda and gamma (with std.errors) be calculated for a weibull model with age as an independent predictor? I have assumed that this can be done with survreg with e. g. (summary(survreg(Surv(time, status) ~ age, dist = 'weibull')) ) and predict.survreg with e.g. (predict(model, se.fit = T,  newdata = data.frame(age = seq(50, 80, 5)) but unfortunately I'm uncapable to sort out how to get the lambda and gamma values (with std.errors). I haven't found any example of this in the help pages and would really appreciate  any help!

In my package 'eha', function 'weibreg', you will find short discussion of the
different parametrizations of the Weibull distribution. Weibull (in base) and
weibreg (eha) use the same parametrization, different from the one in 
survreg. See the help page for weibreg. Oops, I can spot an error in that page;
the reference to 'dgamma' should really be to 'dweibull'.

G?ran

> 
> With best wishes and thanks in advance for any help
> 
> Fredrik Lundgren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From tura at centroin.com.br  Wed Jan 14 22:53:18 2004
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Wed, 14 Jan 2004 19:53:18 -0200
Subject: [R] NLS mensagem error...
Message-ID: <6.0.1.1.2.20040114194910.02f8eeb0@pop.centroin.com.br>

Hi R-masters,

I have a problem with nls() and my research data. Look this example:



X2000<-c(1.205268,2.850695,5.100860,8.571610,15.324513,25.468599,39.623418,61.798856,91.470006,175.152509)
age<-c(37,42,47,52,57,62,67,72,77,82)
fit <- nls(X2000~R*exp(A*age),start=list(R=.1,A=.1))

Error mensage:

Error in nls(X2000 ~ R * exp(A * age), start = list(R = 0.1, A = 0.1)) : 
        singular gradient
In addition: Warning message: 
no finite arguments to min; returning Inf

How I fix this problem? Other command? 


Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil 

From ahenningsen at agric-econ.uni-kiel.de  Wed Jan 14 23:12:00 2004
From: ahenningsen at agric-econ.uni-kiel.de (Arne Henningsen)
Date: Wed, 14 Jan 2004 23:12:00 +0100
Subject: [R] nonlinear regression and Excel solver
In-Reply-To: <40059111.3070207@uvm.edu>
References: <40059111.3070207@uvm.edu>
Message-ID: <200401142312.00363.ahenningsen@agric-econ.uni-kiel.de>

Hi,

I don't know S-Plus and its functions nlminb() and ms(). However, in R I would 
use optim(), optimize or nlm(). I used these functions quiet often and had 
only very few problems. I think that R is better, easier and more flexible 
than Excel (at least in the long run), but since I don't anything about the 
Lefkovitch matrix framework I might be wrong in this case.

Best wishes,
Arne

On Wednesday 14 January 2004 19:57, Kristian Omland wrote:
> Hi all,
>
> Earlier today I posted this question on s-news, so apologies to some for
> the duplication.
>
> > Please put aside your snobbery about Microsoft products for a moment.
> >
> > I am fitting population models to annual survey data for trout. For those
> > of you familiar with ecological models, I am working in the Lefkovitch
> > matrix framework; for those unfamiliar with that shorthand, the modeled
> > variable is a vector of abundances of fish in five size classes, with a
> > system of linear equations (represented by a matrix) governing survival,
> > advancement from smaller to larger stages, and reproduction.
> >
> > So far, I have been using a likelihood approach in an Excel spreadsheet.
> > The spreadsheet includes the annual survey data, the Lefkovitch matrix,
> > and projections of the model, i.e., realizations to be compared to the
> > data. It computes the negative log-likelihood of each realization
> > assuming log-normally distributed noise and the sum of those likelihood
> > components. I use the Solver add-in to minimize the negative
> > log-likelihood over the parameters in the Lefkovitch matrix.
> >
> > I have made a tentative stab at using nlminb() [minor success] and ms()
> > [no success] to fit the model in S-Plus, but my proficiency is such that
> > I still have greater flexibility fitting the models with Excel. Thus my
> > question for you all is ...
> >
> > Is Excel?s Solver an adequate tool for numerical approximation in general
> > and nonlinear regression in particular? Or should I push on writing
> > S-Plus code?
> >
> > Is anyone out there interested in assisting me with S-Plus code with the
> > potential payoff of collaboration on a publication in the ecological
> > literature?
>
> Obviously, I would be equally enthused if an R user was interested in a
> collaboration.
>
> Thanks in advance,
> Kristian

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From gb at stat.umu.se  Wed Jan 14 23:14:28 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 14 Jan 2004 23:14:28 +0100
Subject: [R] estimation of lambda and gamma with std errors for a weibull
	model
In-Reply-To: <20040114214556.GB2440@stat.umu.se>
References: <005001c3dada$833dd8a0$2d0ffea9@oemcomputer>
	<20040114214556.GB2440@stat.umu.se>
Message-ID: <20040114221428.GA2853@stat.umu.se>

On Wed, Jan 14, 2004 at 10:45:56PM +0100, G?ran Brostr?m wrote:
> On Wed, Jan 14, 2004 at 09:10:51PM +0100, Fredrik Lundgren wrote:
> > Dear R experts,
> > 
> > How should lambda and gamma (with std.errors) be calculated for a weibull model with age as an independent predictor? I have assumed that this can be done with survreg with e. g. (summary(survreg(Surv(time, status) ~ age, dist = 'weibull')) ) and predict.survreg with e.g. (predict(model, se.fit = T,  newdata = data.frame(age = seq(50, 80, 5)) but unfortunately I'm uncapable to sort out how to get the lambda and gamma values (with std.errors). I haven't found any example of this in the help pages and would really appreciate  any help!
> 
> In my package 'eha', function 'weibreg', you will find short discussion of the
> different parametrizations of the Weibull distribution. Weibull (in base) and
> weibreg (eha) use the same parametrization, different from the one in 
> survreg. See the help page for weibreg. Oops, I can spot an error in that page;
> the reference to 'dgamma' should really be to 'dweibull'.
> 
> G?ran

To elaborate further, you should maybe be satisfied with the standard errors 
you get on the log scale. Calculate confidence intervals (or whatever you
want the se's for) on that scale, and transform these intervals to any scale 
you like. Usually much better than doing it in reverse order, ie, calculating
se's (via the delta method) for 'lambda' and 'gamma', and then the confidence
intervals.

G?ran

> 
> > 
> > With best wishes and thanks in advance for any help
> > 
> > Fredrik Lundgren
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> -- 
>  G?ran Brostr?m                    tel: +46 90 786 5223
>  Department of Statistics          fax: +46 90 786 6614
>  Ume? University                   http://www.stat.umu.se/egna/gb/
>  SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From bates at stat.wisc.edu  Wed Jan 14 23:33:39 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 14 Jan 2004 16:33:39 -0600
Subject: [R] NLS error message...
In-Reply-To: <6.0.1.1.2.20040114194910.02f8eeb0@pop.centroin.com.br>
References: <6.0.1.1.2.20040114194910.02f8eeb0@pop.centroin.com.br>
Message-ID: <6rr7y2tb24.fsf@bates4.stat.wisc.edu>

Bernardo Rangel Tura <tura at centroin.com.br> writes:

> I have a problem with nls() and my research data. Look this example:
> 
> X2000<-c(1.205268,2.850695,5.100860,8.571610,15.324513,25.468599,39.623418,61.798856,91.470006,175.152509)
> age<-c(37,42,47,52,57,62,67,72,77,82)
> fit <- nls(X2000~R*exp(A*age),start=list(R=.1,A=.1))
> 
> Error mensage:
> 
> Error in nls(X2000 ~ R * exp(A * age), start = list(R = 0.1, A = 0.1)) : 
>         singular gradient
> In addition: Warning message: 
> no finite arguments to min; returning Inf
> 
> How I fix this problem? Other command? 

The problem is your starting value for R.  This is a case where the
"plinear" algorithm is very helpful because you only need a starting
estimate for A, the nonlinear parameter.

> fm1 = nls(X2000 ~ exp(A*age), start = c(A = .1), alg = 'plinear', trace = TRUE)
172.7589 : 0.10000000 0.04645409 
161.7483 : 0.10315347 0.03619599 
161.6661 : 0.10343465 0.03539847 
161.6656 : 0.10345546 0.03534014 
161.6656 : 0.10345698 0.03533590 
161.6656 : 0.10345709 0.03533559 
> summary(fm1)

Formula: X2000 ~ exp(A * age)

Parameters:
     Estimate Std. Error t value Pr(>|t|)    
A    0.103457   0.004578  22.598 1.56e-08 ***
.lin 0.035336   0.012841   2.752    0.025 *  
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Residual standard error: 4.495 on 8 degrees of freedom

Correlation of Parameter Estimates:
           A
.lin -0.9983

Notice that you have extremely high correlation of these parameter
estimates.  Also it is unlikely that you will have homoscedastic
(i.e. same variance) errors on those observations so you may want to
consider fitting log(X2000) to age, which would be a linear model.



From zeileis at ci.tuwien.ac.at  Wed Jan 14 23:36:54 2004
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Wed, 14 Jan 2004 23:36:54 +0100 (CET)
Subject: [R] Testing a timeseries for heteroscedastic (lmtest)
In-Reply-To: <1074109218.19035.25.camel@billabong.weh.rwth-aachen.de>
Message-ID: <Pine.LNX.3.96.1040114232621.415A-100000@thorin.ci.tuwien.ac.at>

On Wed, 14 Jan 2004, Simon Ohrem wrote:

> Hello,
> 
> my intention is to test a given timeseries (vector) for heteroscedastic.
> Now I found the gqtest/bptest/hmctest in the lmtest package but a
> "formula" as argument is needed.
> What is meant by formula and how du I interpret the timeseries as
> formula.

lmtest is designed for testing linear regression models which are
typically described by a formula. The simplest conceivable model is
  x ~ 1
i.e. x (which can be a time series) is described as a mean plus noise. And
the above mentioned tests test whether the noise is homoskedastic or not.

The package lmtest also has a vignette telling you a bit more about how
these tests can be applied. Also note that in certain cases the tests in
the package strucchange and some diagnostic tests from tseries can be used
for testing for heteroskedasticity.

hth,
Z
 
> Thanks in advance
> 
> Simon
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From p.connolly at hortresearch.co.nz  Thu Jan 15 00:28:25 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 15 Jan 2004 12:28:25 +1300
Subject: [R] Binomial glms with very small numbers
Message-ID: <20040115122825.U935@hortresearch.co.nz>

V&R describes binomial GLMs with mortality out of 20 budworms.

Is it appropriate to use the same approach with mortality out of
numbers as low as 3?  I feel reticent to do so with data that is not
very continuous.  There are one continuous and one categorical
independent variables.

Would it be more appropriate to treat the response as an ordered
factor with four levels?  If so, what family would one use?

TIA

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From Benjamin.STABLER at odot.state.or.us  Thu Jan 15 00:52:46 2004
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Wed, 14 Jan 2004 15:52:46 -0800
Subject: [R] R internal data types
Message-ID: <76A000A82289D411952F001083F9DD06047FE417@exsalem4-bu.odot.state.or.us>

I am trying to figure out R data types and/or storage mode.  For example:

> #From a clean workspace
> gc()
         used (Mb) gc trigger (Mb)
Ncells 415227 11.1     597831   16
Vcells 103533  0.8     786432    6

> x <- seq(0,100000,1)
> is.integer(x)
[1] FALSE
> is.double(x)
[1] TRUE

> object.size(x)
[1] 800036

> gc()
         used (Mb) gc trigger (Mb)
Ncells 415247 11.1     667722 17.9
Vcells 203543  1.6     786432  6.0

> x <- as.integer(x)
> is.integer(x)
[1] TRUE
> is.double(x)
[1] FALSE

> gc()
         used (Mb) gc trigger (Mb)
Ncells 415249 11.1     741108 19.8
Vcells 153543  1.2     786432  6.0

> x <- 1:100000
> is.integer(x)

> gc()
         used (Mb) gc trigger (Mb)
Ncells 415278 11.1     741108 19.8
Vcells 153553  1.2     786432  6.0

> is.integer(3)
[1] FALSE
> is.double(3)
[1] TRUE

> is.integer(3 * as.integer(5))
[1] FALSE
> is.integer(as.integer(3) * as.integer(5))
[1] TRUE

> is.integer(c(as.integer(5),as.integer(6),as.integer(7)))
[1] TRUE
> is.integer(c(as.integer(5),as.integer(6),7))
[1] FALSE

> is.integer(seq(as.integer(5),as.integer(10),1))
[1] FALSE
> is.integer(seq(as.integer(5),as.integer(10),as.integer(1)))
[1] TRUE

So it looks like R stores numbers as doubles unless the are converted to
integers (long) with the as.integer() function or they are created with the
: operator.  If any of the numbers to a function are not type integer than
the function returns type double.  Is this the case?  Thanks.

Ben Stabler
Oregon Department of Transportation



From sdavis2 at mail.nih.gov  Mon Jan  5 17:38:11 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 05 Jan 2004 11:38:11 -0500
Subject: [R] Analyzing dendograms??
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572F02164@synequanon01>
Message-ID: <BC1EFD23.564%sdavis2@mail.nih.gov>



I think that for heatmap, one needs to "preprocess" the data before passing
it to heatmap.  In particular, if you know the row indices of the genes of
interest, you may pass just those rows with or without the row dendrogram.
If one has a dendrogram object, using "cutree" (see ?cutree)  will give
indices of genes in k clusters or with splits above a certain height; the
resulting indices can then be passed to heatmap.

Sean


On 1/5/04 10:20, "Simon Fear" <Simon.Fear at synequanon.com> wrote:

> Post script: I'm afraid my `solution` was no good, because
> I forgot the need to change nc and nr. (I got bogged down
> in passing ylim and lost track of your real question.)
> 
> Hopefully someone with a deeper understanding of the
> original problem will come to the rescue. If not there may
> be milage on restricting your matrix[,] to matrix[<cond1>,<cond2>]
> according to information in sclus and gclus. But I am in
> over my depth here.
> 
>>> On Sun, 4 Jan 2004, Johan Lindberg wrote:
>>> 
>>>> 
>>>> I have used heatmap to visualize my microarray data. I
>> have a matrix of
>>>> M-values. I do the following.
>>>> 
>>>> #The distance between the columns.
>>>> sampdist <- dist(t(matrix[,]), method="euclidean")
>>>> sclus <- hclust(sampdist, method="average")
>>>> #The distance between the rows.
>>>> genedist <- dist(matrix[,], method="euclidean")
>>>> gclus <- hclust(genedist, method="average")
>>>> 
>> heatmap(matrix[,],Rowv=as.dendrogram(gclus),Colv=as.dendrogram
>> (sclus), 
>>> col=rbg)
>>>> 
>>>> So far so good. But what if I want to look at a group of
>> genes that appear
>>>> to have the same expression pattern in the heatmap? How
>> do I zoom in on a
>>>> dendogram in a heatmap to look at which genes that are forming the
>>>> interesting clusters? I would really appreciate if
>> someone could give me a
>>>> pointer.  
> 
> Simon Fear 
> Senior Statistician
> Syne qua non Ltd 
> Tel: +44 (0) 1379 644449
> Fax: +44 (0) 1379 644445
> email: Simon.Fear at synequanon.com
> web: http://www.synequanon.com
> 
> Number of attachments included with this message: 0
> 
> This message (and any associated files) is confidential and\...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Thu Jan 15 02:15:04 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 14 Jan 2004 17:15:04 -0800
Subject: [R] Binomial glms with very small numbers
In-Reply-To: <20040115122825.U935@hortresearch.co.nz>
References: <20040115122825.U935@hortresearch.co.nz>
Message-ID: <4005E998.4080106@pdf.com>

      The advisability of using "glm" with mortality depends not on the 
size of sample groups but on the assumption of independence:  Whether 
you have 3 individuals per group or 30 or 1, is it plausible to assume 
that all individuals represented in your data.frame have independent 
chances of survival give the potentially explanatory variables?  If the 
answer is "yes", then "glm" is appropriate.  If the answer is "no", then 
some other tool may be preferable.  However, "glm" is quick and easy in 
R, and I might start with that, even if I felt the assumption of 
independence was violated.  If I found nothing there, I would not likely 
find anything with techniques that handled more appropriately the 
violations of independence. 

      Similarly, I can't see how it would matter whether potentially 
explanatory variables were continuous or categorical, as long as a 
categorical variable were appropriately coded as a factor (or 
"character", which is then treated as a factor) if it has more than 2 
levels. 

      Hope this helps. 
      spencer graves

Patrick Connolly wrote:

>V&R describes binomial GLMs with mortality out of 20 budworms.
>
>Is it appropriate to use the same approach with mortality out of
>numbers as low as 3?  I feel reticent to do so with data that is not
>very continuous.  There are one continuous and one categorical
>independent variables.
>
>Would it be more appropriate to treat the response as an ordered
>factor with four levels?  If so, what family would one use?
>
>TIA
>
>  
>



From davidD at qimr.edu.au  Thu Jan 15 02:25:01 2004
From: davidD at qimr.edu.au (David Duffy)
Date: Thu, 15 Jan 2004 11:25:01 +1000 (EST)
Subject: [R] Re: R-help Digest, Vol 11, Issue 14
In-Reply-To: <200401141109.i0EB0WX9002491@hypatia.math.ethz.ch>
References: <200401141109.i0EB0WX9002491@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0401151121490.4133@orpheus.qimr.edu.au>

Rodrigo Abt <rodrigo.abt at sii.cl> wrote:

> According to R help, manova does not support the inclusion of the Error()
> term in the formula call. I have repeated measures data for two dependent
> variables,
> so this means I can't account for subject variance in time?. Any lights?
>

John Fox's sem package.

| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From p.connolly at hortresearch.co.nz  Thu Jan 15 02:54:01 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 15 Jan 2004 14:54:01 +1300
Subject: [R] Binomial glms with very small numbers
In-Reply-To: <4005E998.4080106@pdf.com>;
	from spencer.graves@pdf.com on Wed, Jan 14, 2004 at 05:15:04PM
	-0800
References: <20040115122825.U935@hortresearch.co.nz> <4005E998.4080106@pdf.com>
Message-ID: <20040115145400.V935@hortresearch.co.nz>

On Wed, 14-Jan-2004 at 05:15PM -0800, Spencer Graves wrote:

|>       The advisability of using "glm" with mortality depends not on
|> the size of sample groups but on the assumption of independence:
|> Whether you have 3 individuals per group or 30 or 1, is it

I think we can assume independence.  What concerned me more was the
fact that there will be rather a lot of 0s and 1s, corresponding to
-Inf and Inf on the transformed scale.  Only half the possible values
(namely, 1 & 2) will be usable in the fitting.  On second thoughts,
since the response can be given as a binary, perhaps I was
unnecessarily concerned.


|> plausible to assume that all individuals represented in your
|> data.frame have independent chances of survival give the
|> potentially explanatory variables?  If the answer is "yes", then
|> "glm" is appropriate.  If the answer is "no", then some other tool
|> may be preferable.  However, "glm" is quick and easy in R, and I
|> might start with that, even if I felt the assumption of
|> independence was violated.  If I found nothing there, I would not
|> likely find anything with techniques that handled more
|> appropriately the violations of independence.

Thanks for that suggestion.

|> 
|>       Similarly, I can't see how it would matter whether potentially 
|> explanatory variables were continuous or categorical, as long as a 
|> categorical variable were appropriately coded as a factor (or 
|> "character", which is then treated as a factor) if it has more than 2 
|> levels. 

I didn't think it would make a difference but I included it in case
someone more knowledgeable had reasons why it did.

Thanks.

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From spencer.graves at pdf.com  Thu Jan 15 02:56:30 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 14 Jan 2004 17:56:30 -0800
Subject: [R] Binomial glms with very small numbers
In-Reply-To: <20040115145400.V935@hortresearch.co.nz>
References: <20040115122825.U935@hortresearch.co.nz> <4005E998.4080106@pdf.com>
	<20040115145400.V935@hortresearch.co.nz>
Message-ID: <4005F34E.6010707@pdf.com>

      Yes, but "glm" maximizes the binomial likelihood assuming 
log(p/(1-p)) is a linear model.  Therefore, you don't have to transform 
the 0's and 1's.  There are cases where a particular combination of 
potential explanatory variables will clearly separate mortalities from 
survivors.  I don't know that the algorithm does with such cases, but it 
should send a slope essentially to infinite.  However, if you don't have 
this case, "glm" should do what you want. 

      hope this helps.  spencer graves

Patrick Connolly wrote:

>On Wed, 14-Jan-2004 at 05:15PM -0800, Spencer Graves wrote:
>
>|>       The advisability of using "glm" with mortality depends not on
>|> the size of sample groups but on the assumption of independence:
>|> Whether you have 3 individuals per group or 30 or 1, is it
>
>I think we can assume independence.  What concerned me more was the
>fact that there will be rather a lot of 0s and 1s, corresponding to
>-Inf and Inf on the transformed scale.  Only half the possible values
>(namely, 1 & 2) will be usable in the fitting.  On second thoughts,
>since the response can be given as a binary, perhaps I was
>unnecessarily concerned.
>
>
>|> plausible to assume that all individuals represented in your
>|> data.frame have independent chances of survival give the
>|> potentially explanatory variables?  If the answer is "yes", then
>|> "glm" is appropriate.  If the answer is "no", then some other tool
>|> may be preferable.  However, "glm" is quick and easy in R, and I
>|> might start with that, even if I felt the assumption of
>|> independence was violated.  If I found nothing there, I would not
>|> likely find anything with techniques that handled more
>|> appropriately the violations of independence.
>
>Thanks for that suggestion.
>
>|> 
>|>       Similarly, I can't see how it would matter whether potentially 
>|> explanatory variables were continuous or categorical, as long as a 
>|> categorical variable were appropriately coded as a factor (or 
>|> "character", which is then treated as a factor) if it has more than 2 
>|> levels. 
>
>I didn't think it would make a difference but I included it in case
>someone more knowledgeable had reasons why it did.
>
>Thanks.
>
>  
>



From Bill.Venables at csiro.au  Thu Jan 15 06:04:32 2004
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Thu, 15 Jan 2004 15:04:32 +1000
Subject: [R] Binomial glms with very small numbers
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A927673B@roper-cv.qld.cmis.csiro.au>

V&R has a binomial glm with binary data, in fact, (e.g. the birth weight
data) and this is quite usual.

Going to large numbers of trials for each probability is really only
important if you plan to use the absolute residual deviance as a test of
fit.  With binary data the distribution of the deviance is a can of worms,
but the distribution of the difference in deviances for two fixed models is
usually still well approximated by the appropriate chi-squared distribution.

Note that for that particular example in V&R they discuss other possible
methods of dealing with it.  That's probably a good idea for lots of things.

V.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Connolly
Sent: Thursday, 15 January 2004 9:28 AM
To: R-help
Subject: [R] Binomial glms with very small numbers


V&R describes binomial GLMs with mortality out of 20 budworms.

Is it appropriate to use the same approach with mortality out of numbers as
low as 3?  I feel reticent to do so with data that is not very continuous.
There are one continuous and one categorical independent variables.

Would it be more appropriate to treat the response as an ordered factor with
four levels?  If so, what family would one use?

TIA

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all the
beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From itayf at fhcrc.org  Thu Jan 15 08:08:44 2004
From: itayf at fhcrc.org (Itay Furman)
Date: Wed, 14 Jan 2004 23:08:44 -0800 (PST)
Subject: [R] Legend text -- discrepancy between X11 and postscript
Message-ID: <Pine.LNX.4.44.0401142226500.28902-100000@cezanne.fhcrc.org>


Hi,

When I place a legend on a plot it looks exactly as I intended
on the screen. However, almost always, when I export this to 
postscript file, the legend's text protrudes through the legend's 
frame (the latter being placed correctly).
See the appended example code. I can send the EPS file as well 
for those that are interested (<4 kb; <200 lines).

I found nothing in the FAQS, or in R-intro to enlighten me. I 
tried few things --- changing font size, setting legend's text 
width, etc. --- but eventually gave up.

How can I get a consistent X11 and PS rendering?

(R 1.8.1 on Linux RedHat 9; GhostView 3.5.8)

	TIA
	Itay

####  Example for X11-EPS discrepancy in legend rendering  ####

## A useless data to plot
x    <- 0:10;         XY <- list(x=x, y=2*x)

## Set lims explicitly; use later in placing the legend.
xlim <- range(XY$x);  ylim <- range(XY$y)                     

plot(XY, xlim=xlim, ylim=ylim, type="l", lty=1, col=2, axes=FALSE)
axis(1); axis(2)

## Legend and plot share the bottom-right corner.
legend(xlim[2], ylim[1], "A set of random numbers",
       lty=1, col=2, xjust=1, yjust=0)

## On the screen: OK. Now produce EPS file.
dev.copy2eps(file="test.eps", paper="letter")
#########################   End example   ##################

--
itayf at fhcrc.org



From buter at cwts.leidenuniv.nl  Thu Jan 15 09:07:01 2004
From: buter at cwts.leidenuniv.nl (Renald Buter)
Date: Thu, 15 Jan 2004 09:07:01 +0100
Subject: [R] Using pam, agnes or clara as prediction models?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7617@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7617@usrymx25.merck.com>
Message-ID: <20040115080701.GA4451@infinite.fsw.leidenuniv.nl>

On Wed, Jan 14, 2004 at 03:18:10PM -0500, Liaw, Andy wrote:
> If pam produces the cluster medoids, you should be able to use the
> 1-nearest-neighbor classifier for prediction of future data, using the
> medoids as the `training' data.  1-NN is available in the `class' package,
> part of the `VR' bundle.
> 

Thanks very much for your quick answer! I've tried your suggestion in
the following way:

 # separate the ruspini data into train and test set
 > train<-ruspini[1:50,]
 > test<-ruspini[51:75,]
 > pamx<-pam(train,4)
 > knnx<-knn(pamx$medoids,test,factor(c("a","b","c","d")),k=3)
 > knnx
 [1] d d b b d c b c c d c a a d c c a a c a a d c d a
 Levels: a b c d

But the result of applying the test set to the knn should only contain 2
clusters, since the upper half of the ruspini data contains only 2
clusters.

Could you tell me what I am missing here?

Regards,

Renald



From maechler at stat.math.ethz.ch  Thu Jan 15 09:09:49 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 15 Jan 2004 09:09:49 +0100
Subject: [R] univariant time series
In-Reply-To: <400549C6.3010900@glam.ac.uk>
References: <400549C6.3010900@glam.ac.uk>
Message-ID: <16390.19149.666449.520519@gargle.gargle.HOWL>

>>>>> "Samuel" == Samuel Kemp (Comp) <sekemp at glam.ac.uk>
>>>>>     on Wed, 14 Jan 2004 13:53:10 +0000 writes:

    Samuel> Hi, I am trying to use the stl function in the ts
    Samuel> package. It requires that the data is a univariant
    Samuel> time series at the moment my data is in a vector. I
    Samuel> have coerced it to a time series using....

    Samuel> crimets <- ts(crimeData)

    Samuel> However, this does not work.

yes, the above usually works  IFF  'crimeData' is really a
numeric vector.

Do look at the result of
     str(crimeData)
and  str(crimets)

In any case ``does not work'' is not informative for us to be of
real help.  Did you read the posting guide (mentioned at the end
of every R-help message) ?

Regards,
Martin



From p.pagel at gsf.de  Thu Jan 15 09:07:35 2004
From: p.pagel at gsf.de (Philipp Pagel)
Date: Thu, 15 Jan 2004 09:07:35 +0100
Subject: [R] Legend text -- discrepancy between X11 and postscript
In-Reply-To: <Pine.LNX.4.44.0401142226500.28902-100000@cezanne.fhcrc.org>
References: <Pine.LNX.4.44.0401142226500.28902-100000@cezanne.fhcrc.org>
Message-ID: <20040115080735.GA2816@porcupine.gsf.de>

	Hi!

On Wed, Jan 14, 2004 at 11:08:44PM -0800, Itay Furman wrote:
> When I place a legend on a plot it looks exactly as I intended
> on the screen. However, almost always, when I export this to 
> postscript file, the legend's text protrudes through the legend's 
> frame (the latter being placed correctly).

This routinely happens to me when using dev.copy2eps. If I use a
postscript device to begin with everything is fine.

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From ripley at stats.ox.ac.uk  Thu Jan 15 09:15:32 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2004 08:15:32 +0000 (GMT)
Subject: [R] Binomial glms with very small numbers
In-Reply-To: <4005F34E.6010707@pdf.com>
Message-ID: <Pine.LNX.4.44.0401150811080.2085-100000@gannet.stats>

On Wed, 14 Jan 2004, Spencer Graves wrote:

>       Yes, but "glm" maximizes the binomial likelihood assuming 
> log(p/(1-p)) is a linear model.  Therefore, you don't have to transform 
> the 0's and 1's.  There are cases where a particular combination of 
> potential explanatory variables will clearly separate mortalities from 
> survivors.  I don't know that the algorithm does with such cases, but it 
> should send a slope essentially to infinite.  However, if you don't have 
> this case, "glm" should do what you want. 

Even in that case glm will do what you want (return fitted probabilities 
rather close to 0 or 1), just somewhat inefficiently.  The standard errors 
are often hard to interpret and Wald tests are misleading. Even that case 
is covered in V&R!   We also discuss the problems of interpreting the 
residual deviance (in the current edition, and in the complements for 
earlier eds) when the expected number of either successes or failures is 
small (and what small is: it will be with n=3).

> 
>       hope this helps.  spencer graves
> 
> Patrick Connolly wrote:
> 
> >On Wed, 14-Jan-2004 at 05:15PM -0800, Spencer Graves wrote:
> >
> >|>       The advisability of using "glm" with mortality depends not on
> >|> the size of sample groups but on the assumption of independence:
> >|> Whether you have 3 individuals per group or 30 or 1, is it
> >
> >I think we can assume independence.  What concerned me more was the
> >fact that there will be rather a lot of 0s and 1s, corresponding to
> >-Inf and Inf on the transformed scale.  Only half the possible values
> >(namely, 1 & 2) will be usable in the fitting.  On second thoughts,
> >since the response can be given as a binary, perhaps I was
> >unnecessarily concerned.
> >
> >
> >|> plausible to assume that all individuals represented in your
> >|> data.frame have independent chances of survival give the
> >|> potentially explanatory variables?  If the answer is "yes", then
> >|> "glm" is appropriate.  If the answer is "no", then some other tool
> >|> may be preferable.  However, "glm" is quick and easy in R, and I
> >|> might start with that, even if I felt the assumption of
> >|> independence was violated.  If I found nothing there, I would not
> >|> likely find anything with techniques that handled more
> >|> appropriately the violations of independence.
> >
> >Thanks for that suggestion.
> >
> >|> 
> >|>       Similarly, I can't see how it would matter whether potentially 
> >|> explanatory variables were continuous or categorical, as long as a 
> >|> categorical variable were appropriately coded as a factor (or 
> >|> "character", which is then treated as a factor) if it has more than 2 
> >|> levels. 
> >
> >I didn't think it would make a difference but I included it in case
> >someone more knowledgeable had reasons why it did.
> >
> >Thanks.
> >
> >  
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Jan 15 09:25:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2004 08:25:55 +0000 (GMT)
Subject: [R] Legend text -- discrepancy between X11 and postscript
In-Reply-To: <Pine.LNX.4.44.0401142226500.28902-100000@cezanne.fhcrc.org>
Message-ID: <Pine.LNX.4.44.0401150816030.2085-100000@gannet.stats>

The short answer is not to copy the device, but to replot on the new 
device.  That is the advice given in MASS, for example.

When you copy a device, you replay the device list and hence the lines and 
text are placed at the positions calculated using the font metrics of the 
first device and not the second.  dev.copy2eps does not try to adjust the 
pointsize of the postscript device, and provided the fonts match you 
should just be able to adjust the pointsize in this case.

You do need to be suspicious of on-screen viewers and indeed of 
ghostscript, for they are often not pixel-perfect and ghostscript does 
font substitution (it does not have Helvetica).  I would always test by 
printing on a postscript printer.

On Wed, 14 Jan 2004, Itay Furman wrote:

> 
> Hi,
> 
> When I place a legend on a plot it looks exactly as I intended
> on the screen. However, almost always, when I export this to 
> postscript file, the legend's text protrudes through the legend's 
> frame (the latter being placed correctly).
> See the appended example code. I can send the EPS file as well 
> for those that are interested (<4 kb; <200 lines).
> 
> I found nothing in the FAQS, or in R-intro to enlighten me. I 
> tried few things --- changing font size, setting legend's text 
> width, etc. --- but eventually gave up.
> 
> How can I get a consistent X11 and PS rendering?
> 
> (R 1.8.1 on Linux RedHat 9; GhostView 3.5.8)
> 
> 	TIA
> 	Itay
> 
> ####  Example for X11-EPS discrepancy in legend rendering  ####
> 
> ## A useless data to plot
> x    <- 0:10;         XY <- list(x=x, y=2*x)
> 
> ## Set lims explicitly; use later in placing the legend.
> xlim <- range(XY$x);  ylim <- range(XY$y)                     
> 
> plot(XY, xlim=xlim, ylim=ylim, type="l", lty=1, col=2, axes=FALSE)
> axis(1); axis(2)
> 
> ## Legend and plot share the bottom-right corner.
> legend(xlim[2], ylim[1], "A set of random numbers",
>        lty=1, col=2, xjust=1, yjust=0)
> 
> ## On the screen: OK. Now produce EPS file.
> dev.copy2eps(file="test.eps", paper="letter")
> #########################   End example   ##################
> 
> --
> itayf at fhcrc.org
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Jan 15 09:32:45 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2004 08:32:45 +0000 (GMT)
Subject: [R] Using pam, agnes or clara as prediction models?
In-Reply-To: <20040115080701.GA4451@infinite.fsw.leidenuniv.nl>
Message-ID: <Pine.LNX.4.44.0401150827310.2085-100000@gannet.stats>

On Thu, 15 Jan 2004, Renald Buter wrote:

> On Wed, Jan 14, 2004 at 03:18:10PM -0500, Liaw, Andy wrote:
> > If pam produces the cluster medoids, you should be able to use the
> > 1-nearest-neighbor classifier for prediction of future data, using the
> > medoids as the `training' data.  1-NN is available in the `class' package,
> > part of the `VR' bundle.
> > 
> 
> Thanks very much for your quick answer! I've tried your suggestion in
> the following way:
> 
>  # separate the ruspini data into train and test set
>  > train<-ruspini[1:50,]
>  > test<-ruspini[51:75,]
>  > pamx<-pam(train,4)
>  > knnx<-knn(pamx$medoids,test,factor(c("a","b","c","d")),k=3)
>  > knnx
>  [1] d d b b d c b c c d c a a d c c a a c a a d c d a
>  Levels: a b c d
> 
> But the result of applying the test set to the knn should only contain 2
> clusters, since the upper half of the ruspini data contains only 2
> clusters.
> 
> Could you tell me what I am missing here?

You asked that the upper half be divided into 4 clusters.  Did you look at 
the object pamx?  It contains 4 clusters covering only the first part of 
the dataset.

Given that when you apply pam to the whole dataset there is a cluster that
only occurs for objects 61:75, there is no way you can find that cluster
when no member of it is in your training set.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Thu Jan 15 09:36:13 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 15 Jan 2004 09:36:13 +0100
Subject: [R] R equivalent of Splus peaks() function?
In-Reply-To: <20040114162506.77836.qmail@web12302.mail.yahoo.com>
Message-ID: <40065F0D.26145.374664@localhost>

Hi

#---------------------------------------------------------------------------------
# funkce pro automaticke oznaceni piku ve spektru (peaks)
# autor Brian Ripley

# span has to be odd number

peaks<-function(series,span=3)
{
z <- embed(series, span)
s <- span%/%2
v<- max.col(z) == 1 + s
result <- c(rep(FALSE,s),v)
result <- result[1:(length(result)-s)]
result
}

HTH 
Petr Pikal

On 14 Jan 2004 at 8:25, Mirka Zednikova wrote:

> If there something available in R that has the
> functionality of the S-PLUS peaks() function?
> 
> Thanks,
> 
> Mirka
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From maechler at stat.math.ethz.ch  Thu Jan 15 09:36:18 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 15 Jan 2004 09:36:18 +0100
Subject: [R] R internal data types
In-Reply-To: <76A000A82289D411952F001083F9DD06047FE417@exsalem4-bu.odot.state.or.us>
References: <76A000A82289D411952F001083F9DD06047FE417@exsalem4-bu.odot.state.or.us>
Message-ID: <16390.20738.890531.442992@gargle.gargle.HOWL>

>>>>> "Benjamin" == Benjamin STABLER <Benjamin.STABLER at odot.state.or.us>
>>>>>     on Wed, 14 Jan 2004 15:52:46 -0800 writes:

	  <........>

    Benjamin> So it looks like R stores numbers as doubles
    Benjamin> unless the are converted to integers (long) with
    Benjamin> the as.integer() function or they are created with
    Benjamin> the : operator.  
+/- yes;
In most cases, this should not matter though.

There are a few other functions that return integer ``by
definition'', e.g.,
length(), dim(), nrow(), ncol()  {the latter 3 return 'NULL' or an integer}.


    Benjamin> If any of the numbers to a function are not type
    Benjamin> integer than the function returns type double.  Is
    Benjamin> this the case?

Most functions will return double even when all numeric arguments are
integer.  Also, e.g. length() will return integer() in any case.

Only for some "arithmetic" functions
      (+, -, *, %%, %/%, also min(), max(), sum())
your statement is true.
But really, in most cases, code shouldn't rely on this.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From buter at cwts.leidenuniv.nl  Thu Jan 15 09:46:47 2004
From: buter at cwts.leidenuniv.nl (Renald Buter)
Date: Thu, 15 Jan 2004 09:46:47 +0100
Subject: [R] Using pam, agnes or clara as prediction models?
In-Reply-To: <Pine.LNX.4.44.0401150827310.2085-100000@gannet.stats>
References: <20040115080701.GA4451@infinite.fsw.leidenuniv.nl>
	<Pine.LNX.4.44.0401150827310.2085-100000@gannet.stats>
Message-ID: <20040115084647.GA5188@infinite.fsw.leidenuniv.nl>

On Thu, Jan 15, 2004 at 08:32:45AM +0000, Prof Brian Ripley wrote:
> On Thu, 15 Jan 2004, Renald Buter wrote:
> 
> > On Wed, Jan 14, 2004 at 03:18:10PM -0500, Liaw, Andy wrote:
> > > If pam produces the cluster medoids, you should be able to use the
> > > 1-nearest-neighbor classifier for prediction of future data, using the
> > > medoids as the `training' data.  1-NN is available in the `class' package,
> > > part of the `VR' bundle.
> > > 
> > 
> > Thanks very much for your quick answer! I've tried your suggestion in
> > the following way:
> > 
> >  # separate the ruspini data into train and test set
> >  > train<-ruspini[1:50,]
> >  > test<-ruspini[51:75,]
> >  > pamx<-pam(train,4)
> >  > knnx<-knn(pamx$medoids,test,factor(c("a","b","c","d")),k=3)
> >  > knnx
> >  [1] d d b b d c b c c d c a a d c c a a c a a d c d a
> >  Levels: a b c d
> > 
> > But the result of applying the test set to the knn should only contain 2
> > clusters, since the upper half of the ruspini data contains only 2
> > clusters.
> > 
> > Could you tell me what I am missing here?
> 
> You asked that the upper half be divided into 4 clusters.  Did you look at 
> the object pamx?  It contains 4 clusters covering only the first part of 
> the dataset.

Yes, that what was I understood. My objective was to use this division
by applying it to the test set: for each point in the test set, predict
what cluster it would enter.

> Given that when you apply pam to the whole dataset there is a cluster that
> only occurs for objects 61:75, there is no way you can find that cluster
> when no member of it is in your training set.

By isn't that what the knn does: locate the nearest neighbour of a point
and assigning its (nn) label to the point-to-be-classified?

I thought that I was doing:
 1. create a clustering of data using PAM
 2. train a knn with the medoids of the PAM clustering
 3. apply the knn to the test set
 4. look at the result

Could you tell me what I'm not getting here?

Regards,

Renald



From ripley at stats.ox.ac.uk  Thu Jan 15 09:49:20 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2004 08:49:20 +0000 (GMT)
Subject: [R] R internal data types
In-Reply-To: <76A000A82289D411952F001083F9DD06047FE417@exsalem4-bu.odot.state.or.us>
Message-ID: <Pine.LNX.4.44.0401150836240.2181-100000@gannet.stats>

On Wed, 14 Jan 2004 Benjamin.STABLER at odot.state.or.us wrote:

> I am trying to figure out R data types and/or storage mode.  For example:

[...]

> So it looks like R stores numbers as doubles unless the are converted to
> integers (long) with the as.integer() function or they are created with the
> : operator.  If any of the numbers to a function are not type integer than
> the function returns type double.  Is this the case?  Thanks.

Nearly!

Non-complex `numbers' can have storage mode "double" or "integer".  
Storage mode "integer" is the C `int' type and not the C `long' type, so
probably on all current R platforms doubles are stored in 8 bytes and
integers in 4.

The storage mode is largely under the user/programmer's control: you can 
do

storage.mode(x) <- "double"

for example.  The storage mode of the return value of a function depends 
on how it was programmed, not on the types of its arguments, for example

> x <- seq(10)
> storage.mode(x)
[1] "integer"

Just a few base functions normally return integer results: you have 
mentioned : and as.integer() and I have illustrated seq().  table() and 
tabulate() are two others I know of, and factors are integer vectors with 
particular attributes.

Current versions of S use integer storage mode much more widely, and it is 
quite possible that in due course more functions in R will make use of it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Jan 15 09:59:37 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2004 08:59:37 +0000 (GMT)
Subject: [R] Using pam, agnes or clara as prediction models?
In-Reply-To: <20040115084647.GA5188@infinite.fsw.leidenuniv.nl>
Message-ID: <Pine.LNX.4.44.0401150849440.2181-100000@gannet.stats>

On Thu, 15 Jan 2004, Renald Buter wrote:

> On Thu, Jan 15, 2004 at 08:32:45AM +0000, Prof Brian Ripley wrote:
> > On Thu, 15 Jan 2004, Renald Buter wrote:
> > 
> > > On Wed, Jan 14, 2004 at 03:18:10PM -0500, Liaw, Andy wrote:
> > > > If pam produces the cluster medoids, you should be able to use the
> > > > 1-nearest-neighbor classifier for prediction of future data, using the
> > > > medoids as the `training' data.  1-NN is available in the `class' package,
> > > > part of the `VR' bundle.
> > > > 
> > > 
> > > Thanks very much for your quick answer! I've tried your suggestion in
> > > the following way:
> > > 
> > >  # separate the ruspini data into train and test set
> > >  > train<-ruspini[1:50,]
> > >  > test<-ruspini[51:75,]
> > >  > pamx<-pam(train,4)
> > >  > knnx<-knn(pamx$medoids,test,factor(c("a","b","c","d")),k=3)
> > >  > knnx
> > >  [1] d d b b d c b c c d c a a d c c a a c a a d c d a
> > >  Levels: a b c d
> > > 
> > > But the result of applying the test set to the knn should only contain 2
> > > clusters, since the upper half of the ruspini data contains only 2
> > > clusters.
> > > 
> > > Could you tell me what I am missing here?
> > 
> > You asked that the upper half be divided into 4 clusters.  Did you look at 
> > the object pamx?  It contains 4 clusters covering only the first part of 
> > the dataset.
> 
> Yes, that what was I understood. My objective was to use this division
> by applying it to the test set: for each point in the test set, predict
> what cluster it would enter.
>
> > Given that when you apply pam to the whole dataset there is a cluster that
> > only occurs for objects 61:75, there is no way you can find that cluster
> > when no member of it is in your training set.
> 
> By isn't that what the knn does: locate the nearest neighbour of a point
> and assigning its (nn) label to the point-to-be-classified?
> 
> I thought that I was doing:
>  1. create a clustering of data using PAM
>  2. train a knn with the medoids of the PAM clustering
>  3. apply the knn to the test set
>  4. look at the result
> 
> Could you tell me what I'm not getting here?

You created a clustering of the training set, yet interpreted it against
the clustering of the whole set using the now irrelevant statement

`the upper half of the ruspini data contains only 2 clusters'

which applies to the wrong clustering.  I pointed out that the training 
set does not contain a single member of one of _those_ clusters so you are 
bound to get a completely different clustering.

When you divided a dataset into `training' and `testing' sets you are 
assuming an least exchangeability whereas this dataset is clearly ordered.
So it is not credible that `train' and `test' are samples from the same 
population.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From a.trapletti at bluewin.ch  Thu Jan 15 11:08:31 2004
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Thu, 15 Jan 2004 11:08:31 +0100
Subject: [R] How can I test if a not independently and not identically
	distributed time series residuals' are uncorrelated ?
Message-ID: <4006669F.4010003@bluewin.ch>

>
>
>I'm analizing the Argentina stock market (merv)
>I  download  the data from yahoo
>
>library(tseries)
>Argentina <- get.hist.quote(instrument="^MERV","1996-10-08","2003-11-03", quote="Close")
>
>merv <- na.remove(log(Argentina))
>
>I made the Augmented Dickey-Fuller test to analyse
>if merv have unit root:
>adf.test(merv,k=13)
>Dickey-Fuller = -1.4645, p-value = 0.805,
>merv have unit root than diff(merv,1) is stationary.
>
>Than I made Breushch-Pagan test to test if residuals are identically distributed:
>library(lmtest)
>bptest(merv[2:1730]~-1+merv[1:1729],~merv[1:1729]+I(merv[1:1729])2)
>BP = 81.3443, df = 2, p-value = < 2.2e-16
>So merv.reg$resid aren't identically distributed. Than merv is heteroscedastik.
>
>Finally I made  Box-Ljung test  to test if residuals are independently distributed:
>(H0: merv.reg$resid are independently distributed)
>library(ts)
>merv.reg <- lm(merv[2:1730]~-1+merv[1:1729])
>Box.test(merv.reg$resid, lag=25,type="Ljung")
>X-squared = 54.339, df = 25, p-value = 0.0006004
>So, there is evidence to not reject the null hypothesis,
>than the residuals are independently distributed.
>
Palhoto,

Box.test is a test, which tests for independence using the acf of a time 
series. That means the test is in fact a test for uncorrelatedness 
rather than independence. Applying Box.test to the squares of the 
residuals is testing for ARCH effects in the time series. With stock 
index data, usually the time series are uncorrelated, but show strong 
ARCH effects, ie., are not independent. Other tests for independence are 
bds.test and terasvirta.test from tseries. The former is a more general 
test for independence, the latter focuses on neglected non-linearity in 
the conditional mean (white.test is designed for the same, but I do not 
recommend it). With stock index data, usually the time series are not 
i.i.d. according to the bds.test due to ARCH effects. With 
terasvirta.test you find sometimes neglected non-linearity in the 
conditional mean. However, from my experience, this is often due to an 
exogenuous structural break and not due to endogenuous non-linearity in 
conditional mean.

best
Adrian
                   

>Because the residuals are not independently distributed, we know that the
>squares of residuals are correlated:
>cov[(residuals_t)2, (residuals_(t-k))2] <> 0 (not zero for  k <> 0)
>
>But, the residuals could be uncorrelated, (even when they 
>are not independent distributed):
>cov[residuals_t, residual_(t-k)]=0 !
>How can I test that merv.reg$residuals are uncorrelated ?
>
>Thanks a lot.
>
>
>	[[alternative HTML version deleted]]
>

-- 
Dr. Adrian Trapletti
Trapletti Statistical Computing
Wildsbergstrasse 31, 8610 Uster
Switzerland
Phone & Fax : +41 (0) 1 994 5631
Mobile : +41 (0) 76 370 5631
Email : mailto:a.trapletti at bluewin.ch
WWW : http://trapletti.homelinux.com



From eesteves at ualg.pt  Thu Jan 15 11:44:39 2004
From: eesteves at ualg.pt (eesteves@ualg.pt)
Date: Thu, 15 Jan 2004 10:44:39 +0000
Subject: [R] model II regression
Message-ID: <1074163479.40066f172588b@wmail.ualg.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040115/03d13b52/attachment.pl

From buter at cwts.leidenuniv.nl  Thu Jan 15 12:22:18 2004
From: buter at cwts.leidenuniv.nl (Renald Buter)
Date: Thu, 15 Jan 2004 12:22:18 +0100
Subject: [R] Using pam, agnes or clara as prediction models?
In-Reply-To: <Pine.LNX.4.44.0401150849440.2181-100000@gannet.stats>
References: <20040115084647.GA5188@infinite.fsw.leidenuniv.nl>
	<Pine.LNX.4.44.0401150849440.2181-100000@gannet.stats>
Message-ID: <20040115112218.GA6050@infinite.fsw.leidenuniv.nl>

On Thu, Jan 15, 2004 at 08:59:37AM +0000, Prof Brian Ripley wrote:
[snip]
> > > >  # separate the ruspini data into train and test set
> > > >  > train<-ruspini[1:50,]
> > > >  > test<-ruspini[51:75,]
> > > >  > pamx<-pam(train,4)
> > > >  > knnx<-knn(pamx$medoids,test,factor(c("a","b","c","d")),k=3)
> > > >  > knnx
> > > >  [1] d d b b d c b c c d c a a d c c a a c a a d c d a
> > > >  Levels: a b c d
> > > > 
> > > > But the result of applying the test set to the knn should only contain 2
> > > > clusters, since the upper half of the ruspini data contains only 2
> > > > clusters.
> > > > 
> > > > Could you tell me what I am missing here?
[snip]
> When you divided a dataset into `training' and `testing' sets you are 
> assuming an least exchangeability whereas this dataset is clearly ordered.
> So it is not credible that `train' and `test' are samples from the same 
> population.
> 

Thank you *very* much for your help. I thought I'd let the list know
what I did to get it right:

 # create a seed vector
 > seed<-rank(runif(75))
 > train<-ruspini[seed[1:60],]
 > test<-ruspini[seed[61:75],]
 > pamx<-pam(train,4)
 > knnx<-knn(pamx$medoids,test,factor(c("a","b","c","d")),k=1)

And now the result makes sense!

Thanks again,

Renald



From a.trapletti at bluewin.ch  Thu Jan 15 12:37:03 2004
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Thu, 15 Jan 2004 12:37:03 +0100
Subject: [R] How can I test if time series residuals' are uncorrelated
 ?
Message-ID: <40067B5F.1030804@bluewin.ch>

>
> Ok I made Jarque-Bera test to the residuals (merv.reg$residual)
>
> library(tseries)
> jarque.bera.test(merv.reg$residual)
> X-squared = 1772.369, df = 2, p-value = < 2.2e-16
> And I reject the null hypotesis (H0: merv.reg$residual are normally
> distributed)
>
> So I know that:
> 1 - merv.reg$residual aren't independently distributed (Box-Ljung test)
> 2 - merv.reg$residual aren't indentically distributed (Breusch-Pagan test)
> 3 - merv.reg$residual aren't normally distributed (Jarque-Bera test)
>
> My questions is:
> It is possible merv.reg$residual be uncorrelated ?
> cov[residual_t, residual_(t+k)] = 0 ?
> Even when residuals are not independent distributed !


Yes. E.g., in an ARCH(1) process, cov[y_t, y_(t+k) ] = 0 (k \neq 0), but 
cov[(y_t)^2, (y_(t+k))^2 ] \neq 0, hence no independence (and this is 
typical for financial time series).

>
> (and we know that they aren't normally distributed and they aren't
> indentically distributed )
> And how can I tested it ?


>
> Thanks.
>
>
>>> Hint, if a ts is normally distributed then independence and
>
> uncorrelatedness
>
>>> are equivalent, hence you can test for normally distributed errors (e.g.
>>> Jarque-Bera-Test).
>>>
>>> HTH,
>>> Bernhard
>>>
>
>
>
> [[alternative HTML version deleted]]
>

Typically, financial time series exhibit fat tails, i.e., are not 
normally distributed (and in an ARCH setup, financial time series are 
usually not even conditionally normally distributed. The fat tails are 
fatter than what we would expect from the clustering of volatility).

best
Adrian

-- 
Dr. Adrian Trapletti
Trapletti Statistical Computing
Wildsbergstrasse 31, 8610 Uster
Switzerland
Phone & Fax : +41 (0) 1 994 5631
Mobile : +41 (0) 76 370 5631
Email : mailto:a.trapletti at bluewin.ch
WWW : http://trapletti.homelinux.com



From Matthias.Kohl at uni-bayreuth.de  Thu Jan 15 14:55:22 2004
From: Matthias.Kohl at uni-bayreuth.de (Matthias Kohl)
Date: Thu, 15 Jan 2004 13:55:22 +0000
Subject: [R] Exactness of ppois
Message-ID: <40069BCA.60109@uni-bayreuth.de>

Hello,

by checking the precision of a convolution algorithm, we found the 
following "inexactness":
We work with R Version 1.8.1 (2003-11-21) on Windows systems (NT, 2000, 
XP).

Try the code:
## Kolmogorov distance between two methods to
## determine P(Poisson(lambda)<=x)
Kolm.dist <- function(lam, eps){
  x <- seq(0,qpois(1-eps, lambda=lam), by=1)
  max(abs(ppois(x, lambda=lam)-cumsum(dpois(x, lambda=lam))))
}
erg<-optimize(Kolm.dist, lower=900, upper=1000, maximum=TRUE, eps=1e-15)
erg

Kolm1.dist <- function(lam, eps){
  x <- seq(0,qpois(1-eps, lambda=lam), by=1)
  which.max(abs(ppois(x, lambda=lam)-cumsum(dpois(x, lambda=lam))))
}
Kolm1.dist(lam=erg$max, eps=1e-15)

So for lambda=977.8 and x=1001 we get a distance of about 5.2e-06.
(This inexactness seems to hold for all lambda values greater than about 
900.)

BUT, summing about 1000 terms of exactness around 1e-16,
we would expect an error of order 1e-13.

We suspect algorithm AS 239 to cause that flaw.
Do you think this could cause other problems apart from
that admittedly extreme example?

Thanks for your attention!
Matthias



From sdavis2 at mail.nih.gov  Thu Jan 15 14:27:53 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 15 Jan 2004 08:27:53 -0500
Subject: [R] Sjava question on MacOS 10.3
Message-ID: <BC2BFF89.35DE%sdavis2@mail.nih.gov>

I am running R-1.81, apple's JVM installed with OS 10.3.2, and installed
Sjava-0.65.X (a patched version of Sjava for MacOS from Simon Urbanek, which
I know is inherently dangerous, but...).  This version installed fine and
some aspects seem to work as expected.  However, this is one of the examples
and causes R to hang.  Any insights?  What other information should I
provide to make it easier to answer this question?  Finally, is there a
stable version of Sjava for the MacOS 10.3 that I should be using? (See
below.)

Thanks,
Sean
-- 
Sean Davis, M.D., Ph.D.

Clinical Fellow
National Institutes of Health
National Cancer Institute
National Human Genome Research Institute

Clinical Fellow, Johns Hopkins
Department of Pediatric Oncology
-- 


Here is the R-Session:
R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

> options(STERM='iESS', editor='emacsclient')
> library(SJava)
Warning message: 
The Java machine is no longer initialized automatically. You must explicitly
load it in: firstlib(which.lib.loc, package)
> .JavaInit()
> JavaConfig()
Error: couldn't find function "JavaConfig"
> javaConfig()
$classPath
[1] 
"/Users/sdavis/R-1.81/lib/R/library/SJava/org/omegahat/Jars/Environment.jar"
[2] "/Users/sdavis/R-1.81/lib/R/library/SJava/org/.."
[3] "/Users/sdavis/R-1.81/lib/R/library/SJava/org/omegahat/Jars/antlr.jar"
[4] "/Users/sdavis/R-1.81/lib/R/library/SJava/org/omegahat/Jars/jas.jar"
[5] "/Users/sdavis/R-1.81/lib/R/library/SJava/org/omegahat/Jars/jhall.jar"

$properties
                                                                 EmbeddedInR
                                                                      "true"
                                                       InterfaceManagerClass
             "org/omegahat/Interfaces/NativeInterface/OmegaInterfaceManager"
                                                   ForeignReferenceBaseClass
                                     "org/omegahat/R/Java/RForeignReference"
                                                               java.compiler
                                                                      "NONE"
                                                                  OMEGA_HOME
                     "/Users/sdavis/R-1.81/lib/R/library/SJava/org/omegahat"
                                                          OmegahatSearchPath
".,${OMEGA_HOME}/Environment/Scripts/Run,${OMEGA_HOME}/Jars/Environment.jar"
                                                           java.library.path
                             "/Users/sdavis/R-1.81/lib/R/library/SJava/libs"

$libraryPath
[1] "/Users/sdavis/R-1.81/lib/R/library/SJava/libs"

> .Java("Math","sin","PI")
$key
[1] "1"

$className
[1] "org.omegahat.Environment.Language.StaticMethodAlias"

attr(,"class")
[1] "AnonymousOmegahatReference"
> .Java("Math","sin",3.141592654)
[1] -4.102069e-10
> f <- .JavaConstructor("JFrame")



From johanl at kiev.biotech.kth.se  Thu Jan 15 14:35:36 2004
From: johanl at kiev.biotech.kth.se (Johan Lindberg)
Date: Thu, 15 Jan 2004 14:35:36 +0100
Subject: [R] A language technical question.
Message-ID: <5.2.0.9.0.20040115142509.00bafce8@kiev.biotech.kth.se>

If I have 100 objekts in a folder and I prefer not to load them manually I 
wonder how I do this in R if using a for-loop.

I was thinking initially to do something like this:

infiles <- dir(pattern=".RData")
for(i in length(infiles))
         {
         load(infiles[i])
         paste("kalle", i, sep="") <- saveLoadReference
         }

But the line """paste("kalle", i, sep="")""" does not do it for me. I get 
the error message "Error: Target of assignment expands to non-language object"

The thing that I do not master is how to create a name in a for-loop that I 
can assign something to. And I want to be able to change that name as the 
loop goes on. I want to create in this case
kalle1
kalle2
kalle3
...
kalle100

and they should all represent the objects that I opened with load(infiles[i])


Best regards

/ Johan



*******************************************************************************************
Johan Lindberg
Royal Institute of Technology
AlbaNova University Center
Stockholm Center for Physics, Astronomy and Biotechnology
Department of Molecular Biotechnology
106 91 Stockholm, Sweden

Phone (office): +46 8 553 783 45
Fax: + 46 8 553 784 81
Visiting adress: Roslagstullsbacken 21, Floor 3
Delivery adress: Roslagsv?gen 30B



From ligges at statistik.uni-dortmund.de  Thu Jan 15 14:49:14 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 15 Jan 2004 14:49:14 +0100
Subject: [R] A language technical question.
In-Reply-To: <5.2.0.9.0.20040115142509.00bafce8@kiev.biotech.kth.se>
References: <5.2.0.9.0.20040115142509.00bafce8@kiev.biotech.kth.se>
Message-ID: <40069A5A.9020009@statistik.uni-dortmund.de>

Johan Lindberg wrote:

> If I have 100 objekts in a folder and I prefer not to load them manually 
> I wonder how I do this in R if using a for-loop.
> 
> I was thinking initially to do something like this:
> 
> infiles <- dir(pattern=".RData")

For sure you mean
   infiles <- dir(pattern = "\\.RData")


> for(i in length(infiles))

This won't work. I'd try
   for(i in 1:length(infiles))
or much better:
   for(i in seq(along = infiles))


>         {
>         load(infiles[i])
>         paste("kalle", i, sep="") <- saveLoadReference

Whatever saveLoadReference is ... try
   assign(paste("kalle", i, sep=""), saveLoadReference)

Please note that it might be a good idea to use a list "kalle" with 
elements corresponding to the different "saveLoadReference" objects. So 
that you don't mess up you workspace with many objects ....

Uwe Ligges


>         }
> 
> But the line """paste("kalle", i, sep="")""" does not do it for me. I 
> get the error message "Error: Target of assignment expands to 
> non-language object"
> 
> The thing that I do not master is how to create a name in a for-loop 
> that I can assign something to. And I want to be able to change that 
> name as the loop goes on. I want to create in this case
> kalle1
> kalle2
> kalle3
> ...
> kalle100
> 
> and they should all represent the objects that I opened with 
> load(infiles[i])
> 
> 
> Best regards
> 
> / Johan
> 
> 
> 
> ******************************************************************************************* 
> 
> Johan Lindberg
> Royal Institute of Technology
> AlbaNova University Center
> Stockholm Center for Physics, Astronomy and Biotechnology
> Department of Molecular Biotechnology
> 106 91 Stockholm, Sweden
> 
> Phone (office): +46 8 553 783 45
> Fax: + 46 8 553 784 81
> Visiting adress: Roslagstullsbacken 21, Floor 3
> Delivery adress: Roslagsv?gen 30B
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From christoph.lehmann at gmx.ch  Thu Jan 15 14:53:56 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Thu, 15 Jan 2004 14:53:56 +0100
Subject: [R] nlme vs aov with Error() for an ANCOVA
Message-ID: <1074174835.1487.58.camel@christophl>

Hi 
I compouted a multiple linear regression with repeated measures on one
explanatory variable:
BOLD peak (blood oxygenation) as dependent variable,

and as independent variables I have:
-age.group (binaray:young(0)/old(1)) 
-and task-difficulty measured by means of the reaction-time 'rt'. For
'rt' I have repeated measurements, since each subject did 12 different
tasks.
-> so it can be seen as an ANCOVA

subject  age.group bold    rt

subj1    0         0.08    0.234   
subj1    0         0.05    0.124 
..  
subj1    0         0.07    0.743  
    
subj2    0         0.06    0.234     
subj2    0         0.02    0.183 
..    
subj2    0         0.05    0.532 
     
subjn    1         0.09    0.234    
subjn    1         0.06    0.155
..    
subjn    1         0.07    0.632      

I decided to use the nlme library:

patrizia.lme <- lme(bold ~ rt*age.group, data=patrizia.data1, random= ~
rt |subject)
> summary(patrizia.lme)
Linear mixed-effects model fit by REML
 Data: patrizia.data1
       AIC      BIC    logLik
  272.2949 308.3650 -128.1474
 
Random effects:
 Formula: ~rt | subject
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.2740019518 (Intr)
rt          0.0004756026 -0.762
Residual    0.2450787149
 
Fixed effects: bold ~ rt + age.group + rt:age.group
                   Value  Std.Error  DF   t-value p-value
(Intercept)   0.06109373 0.11725208 628  0.521046  0.6025
rt            0.00110117 0.00015732 628  6.999501  0.0000
age.group    -0.03750787 0.13732793  43 -0.273126  0.7861
rt:age.group -0.00031919 0.00018259 628 -1.748115  0.0809
 Correlation:
             (Intr) rt     ag.grp
rt           -0.818
age.group    -0.854  0.698
rt:age.group  0.705 -0.862 -0.805
 
Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-3.6110596 -0.5982741 -0.0408144  0.5617381  4.8648242
 
Number of Observations: 675
Number of Groups: 45

--end output
#-> if the model assumptions hold this means, we don't have a
significant age effect but a highly significant task-effect and the
interaction is significant on the 0.1 niveau. 

I am now interested, if one could do the analysis also using aov and the
Error() option.

e.g. may I do:
> l <- aov(bold ~ rt*age.group + Error(subject/rt),data=patrizia.data1)
> summary(l)
 
Error: subject
   Df    Sum Sq   Mean Sq
rt  1 0.0022087 0.0022087
 
Error: subject:rt
   Df Sum Sq Mean Sq
rt  1 40.706  40.706
 
Error: Within
              Df  Sum Sq Mean Sq F value    Pr(>F)
rt             1   2.422   2.422 10.0508  0.001592 **
age.group      1   8.722   8.722 36.2022 2.929e-09 ***
rt:age.group   1   0.277   0.277  1.1494  0.284060
Residuals    669 161.187   0.241
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1


which looks weird

or what would you recommend?

thanks a lot

Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From ripley at stats.ox.ac.uk  Thu Jan 15 14:59:39 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2004 13:59:39 +0000 (GMT)
Subject: [R] A language technical question.
In-Reply-To: <5.2.0.9.0.20040115142509.00bafce8@kiev.biotech.kth.se>
Message-ID: <Pine.LNX.4.44.0401151348510.19440-100000@gannet.stats>

You have two problems.

1) You want to use

assign(paste("kalle", i, sep=""), saveLoadReference)

to create the name.

That one is discussed frequently enough to be an FAQ, and it is Q7.23.

2) You need to keep the return value of load to assign to the object.

So I think you want

for(i in length(infiles)) 
    assign(paste("kalle", i, sep=""), load(infiles[i]))

However, that assigns to kalle{n} the names(s) of the objects you loaded.
Is that what you actually wanted?  Or did you want the actual objects, not 
their `representation'.

If you want the actual objects, I suggest you use .readRDS instead.


On Thu, 15 Jan 2004, Johan Lindberg wrote:

> If I have 100 objekts in a folder and I prefer not to load them manually I 
> wonder how I do this in R if using a for-loop.
> 
> I was thinking initially to do something like this:
> 
> infiles <- dir(pattern=".RData")
> for(i in length(infiles))
>          {
>          load(infiles[i])
>          paste("kalle", i, sep="") <- saveLoadReference
>          }
> 
> But the line """paste("kalle", i, sep="")""" does not do it for me. I get 
> the error message "Error: Target of assignment expands to non-language object"
> 
> The thing that I do not master is how to create a name in a for-loop that I 
> can assign something to. And I want to be able to change that name as the 
> loop goes on. I want to create in this case
> kalle1
> kalle2
> kalle3
> ...
> kalle100
> 
> and they should all represent the objects that I opened with load(infiles[i])

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Jan 15 15:33:11 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2004 14:33:11 +0000 (GMT)
Subject: [R] nlme vs aov with Error() for an ANCOVA
In-Reply-To: <1074174835.1487.58.camel@christophl>
Message-ID: <Pine.LNX.4.44.0401151405580.3832-100000@gannet.stats>

Well, I don't think this is ANCOVA as you seem to want to specify a random 
slope for a covariate.  aov() is not designed for that.  It is also not 
designed for assessing the size of fixed effects which seems the question 
here.

As I understand it, you have only one observation for each value of `rt'
for each subject, and `rt' is an explanatory variable.  For lme you have
specified a subject-dependent intercept and coefficient of `rt'.  You
cannot do that in aov, where the argument of Error is supposed to be a
factor or a combination of factors.  This is in the reference given by
help for aov or Error (on pp 157-9).


On Thu, 15 Jan 2004, Christoph Lehmann wrote:

> Hi 
> I compouted a multiple linear regression with repeated measures on one
> explanatory variable:
> BOLD peak (blood oxygenation) as dependent variable,
> 
> and as independent variables I have:
> -age.group (binaray:young(0)/old(1)) 
> -and task-difficulty measured by means of the reaction-time 'rt'. For
> 'rt' I have repeated measurements, since each subject did 12 different
> tasks.
> -> so it can be seen as an ANCOVA
> 
> subject  age.group bold    rt
> 
> subj1    0         0.08    0.234   
> subj1    0         0.05    0.124 
> ..  
> subj1    0         0.07    0.743  
>     
> subj2    0         0.06    0.234     
> subj2    0         0.02    0.183 
> ..    
> subj2    0         0.05    0.532 
>      
> subjn    1         0.09    0.234    
> subjn    1         0.06    0.155
> ..    
> subjn    1         0.07    0.632      
> 
> I decided to use the nlme library:
> 
> patrizia.lme <- lme(bold ~ rt*age.group, data=patrizia.data1, random= ~
> rt |subject)
> > summary(patrizia.lme)
> Linear mixed-effects model fit by REML
>  Data: patrizia.data1
>        AIC      BIC    logLik
>   272.2949 308.3650 -128.1474
>  
> Random effects:
>  Formula: ~rt | subject
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 0.2740019518 (Intr)
> rt          0.0004756026 -0.762
> Residual    0.2450787149
>  
> Fixed effects: bold ~ rt + age.group + rt:age.group
>                    Value  Std.Error  DF   t-value p-value
> (Intercept)   0.06109373 0.11725208 628  0.521046  0.6025
> rt            0.00110117 0.00015732 628  6.999501  0.0000
> age.group    -0.03750787 0.13732793  43 -0.273126  0.7861
> rt:age.group -0.00031919 0.00018259 628 -1.748115  0.0809
>  Correlation:
>              (Intr) rt     ag.grp
> rt           -0.818
> age.group    -0.854  0.698
> rt:age.group  0.705 -0.862 -0.805
>  
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max
> -3.6110596 -0.5982741 -0.0408144  0.5617381  4.8648242
>  
> Number of Observations: 675
> Number of Groups: 45
> 
> --end output
> #-> if the model assumptions hold this means, we don't have a
> significant age effect but a highly significant task-effect and the
> interaction is significant on the 0.1 niveau. 

Nope.  It means that you have two lines with a common non-zero intercept
and probably different slopes for the two age groups.  However, as I 
understand it rt=0 is an extraplolation to an physically impossible value, 
so interpreting the intercept makes little sense.

> I am now interested, if one could do the analysis also using aov and the
> Error() option.
> 
> e.g. may I do:
> > l <- aov(bold ~ rt*age.group + Error(subject/rt),data=patrizia.data1)
> > summary(l)
>  
> Error: subject
>    Df    Sum Sq   Mean Sq
> rt  1 0.0022087 0.0022087
>  
> Error: subject:rt
>    Df Sum Sq Mean Sq
> rt  1 40.706  40.706
>  
> Error: Within
>               Df  Sum Sq Mean Sq F value    Pr(>F)
> rt             1   2.422   2.422 10.0508  0.001592 **
> age.group      1   8.722   8.722 36.2022 2.929e-09 ***
> rt:age.group   1   0.277   0.277  1.1494  0.284060
> Residuals    669 161.187   0.241
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> 
> 
> which looks weird
> 
> or what would you recommend?
> 
> thanks a lot
> 
> Christoph
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Thu Jan 15 16:05:44 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 15 Jan 2004 16:05:44 +0100
Subject: [R] Using pam, agnes or clara as prediction models?
In-Reply-To: <20040115112218.GA6050@infinite.fsw.leidenuniv.nl>
References: <20040115084647.GA5188@infinite.fsw.leidenuniv.nl>
	<Pine.LNX.4.44.0401150849440.2181-100000@gannet.stats>
	<20040115112218.GA6050@infinite.fsw.leidenuniv.nl>
Message-ID: <16390.44104.939856.110680@gargle.gargle.HOWL>

>>>>> "Renald" == Renald Buter <buter at cwts.leidenuniv.nl>
>>>>>     on Thu, 15 Jan 2004 12:22:18 +0100 writes:

  <....>

    Renald> Thank you *very* much for your help. I thought I'd let the list know
    Renald> what I did to get it right:

    >> # create a seed vector
    >> seed<-rank(runif(75))

S has a function for this :
     seed <- sample(75)

     ## (and "seed" is not very sensical name here)

    >> train<-ruspini[seed[1:60],]
    >> test<-ruspini[seed[61:75],]
    >> pamx<-pam(train,4)
    >> knnx<-knn(pamx$medoids,test,factor(c("a","b","c","d")),k=1)

Note on style:

  Using " " (space) in S statements is very much recommended for
  readability, particularly
  space around "<-", i.e. " <- " 
	 (and this is provided with one key stroke by ESS and R-WinEdt)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From bbonsu at columbus.rr.com  Thu Jan 15 16:01:12 2004
From: bbonsu at columbus.rr.com (Bema Bonsu)
Date: Thu, 15 Jan 2004 10:01:12 -0500
Subject: [R] Resend: help with Hmisc/ Design installation in R-aqua (apple).
In-Reply-To: <BC28146F.4E1%bbonsu@columbus.rr.com>
Message-ID: <BC2C1568.52D%bbonsu@columbus.rr.com>


Hello again. This is a resend (first sent on the 12th of January);

I would truly appreciate a response.

"I have tried, unsuccessfully, to install the Hmisc and Design libraries
(Harrell FE Jr) in R-aqua (Apple). These libraries are in source code only
(i.e. not yet in ready-to-use binary format). Unfortunately, when I download
the libraries in source format and attempt to install them directly or
manually, I get an error message that states the following:

Warning messages: 
1: Installation of package Design had non-zero exit status in:
install.packages(ui.pkgs, CRAN = getOption(where), lib = .libPaths()[1])
2: Installation of package Hmisc had non-zero exit status in:
install.packages(ui.pkgs, CRAN = getOption(where), lib = .libPaths()[1])"

Again, grateful for any assistance in resolving this problem.

Thanks

Bema Bonsu
Ohio State University."

------ End of Forwarded Message



From nortonsm at verizon.net  Thu Jan 15 16:19:36 2004
From: nortonsm at verizon.net (Scott Norton)
Date: Thu, 15 Jan 2004 10:19:36 -0500
Subject: [R] Ordering bars in barplots
Message-ID: <002001c3db7a$fcec3f20$6901a8c0@scott>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040115/ca4abc11/attachment.pl

From tlumley at u.washington.edu  Thu Jan 15 16:45:20 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 15 Jan 2004 07:45:20 -0800 (PST)
Subject: [R] Resend: help with Hmisc/ Design installation in R-aqua
	(apple).
In-Reply-To: <BC2C1568.52D%bbonsu@columbus.rr.com>
References: <BC2C1568.52D%bbonsu@columbus.rr.com>
Message-ID: <Pine.A41.4.58.0401150742340.77942@homer40.u.washington.edu>

On Thu, 15 Jan 2004, Bema Bonsu wrote:

>
> Hello again. This is a resend (first sent on the 12th of January);
>
> I would truly appreciate a response.
>
> "I have tried, unsuccessfully, to install the Hmisc and Design libraries
> (Harrell FE Jr) in R-aqua (Apple). These libraries are in source code only
> (i.e. not yet in ready-to-use binary format). Unfortunately, when I download
> the libraries in source format and attempt to install them directly or
> manually, I get an error message that states the following:
>
> Warning messages:
> 1: Installation of package Design had non-zero exit status in:
> install.packages(ui.pkgs, CRAN = getOption(where), lib = .libPaths()[1])
> 2: Installation of package Hmisc had non-zero exit status in:
> install.packages(ui.pkgs, CRAN = getOption(where), lib = .libPaths()[1])"
>

Yes, that's why there aren't binaries -- if it compiled without user
intervention there would be binaries.

You need to look at the output of INSTALL.  One way is to go to
Preferences and select the items that send stdout and stderr to the R
console.  You will then get R INSTALL error messages, which should explain
the problems.

	-thomas



From ripley at stats.ox.ac.uk  Thu Jan 15 16:49:26 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2004 15:49:26 +0000 (GMT)
Subject: [R] Ordering bars in barplots
In-Reply-To: <002001c3db7a$fcec3f20$6901a8c0@scott>
Message-ID: <Pine.LNX.4.44.0401151538490.2019-100000@gannet.stats>

by() will sort on the levels of `class', so I think what you need to do is 
ensure that `class' has its levels sorted numerically.  Try

df$class <- factor(as.numeric(as.character(df$class)))

to do that.  Then to sort the df by numerical class you could use

df <- df[sort.list(unclass(df$class)), ]

It might be easier just to make class a number for some purposes at
least (just omit the factor() above).


On Thu, 15 Jan 2004, Scott Norton wrote:

> 
> I have a dataframe such that when I enter the dataframe name at the R prompt
> and see the data, the order of the data is correct (ie. what I want -
> ordered numerically by the factor, class).  The table is akin to the
> following:
> 
> df: (dataframe = df)
> uniqueID  class	age
> a	   1	32
> b	   1	21
> c	   1	13
> d	   1	11
> e	   3	15
> f	   3	16
> g	   3	31
> h	   3	25
> i	   4	23
> j	   4	32
> k	   4	31
> l	   7	11
> m	   7	6
> n	   7	20
> o	  10	19
> p	  10	25
> q	  10	42
> .
> .
> .
> 
> 
> uniqueID and class are factors. Yesterday I think I managed to figure out
> how to arrange the column "class" in "numerical" order (when it lists) even
> though it's a "character" factor.  (although feel free to pipe in an answer
> on that too - since I was trying a lot of different things!)
> 
> Now, when I execute the following command:
> 
> barplot(by(df[,"age"],df$class,FUN=function(x) quantile(x,0.95)))
> 
> the x-labels or "class" of each bar is in *character* order, not *numerical
> order.
> 
> Is there a way to rearrage this so that each bar label (categorical x-label)
> is in numerical order?
> 
> Thanks in advance!!!
> Best,
> Scott
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From szhan at uoguelph.ca  Thu Jan 15 17:20:17 2004
From: szhan at uoguelph.ca (szhan@uoguelph.ca)
Date: Thu, 15 Jan 2004 11:20:17 -0500
Subject: [R] how to overlap plots
Message-ID: <1074183617.4006bdc1a1e1c@webmail.uoguelph.ca>

Dear R experts:
Can you help me to overlap a histogram and theoretical density curve of poison 
distribution? for example data like this:
The numbers of sanils found in each of 100 sampling quadrats in an area were 
as follows:
number of snails, r 0 1  2 3 4 5 8 15
f=frequency of r   69 18 7 2 1 1 1 1
apparently this is not Poison but near to Poison, How to overlap the 
theoretical desity curve to the histgram of this data?
Thanks in advance!
Josh



From wolski at molgen.mpg.de  Thu Jan 15 17:39:30 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 15 Jan 2004 17:39:30 +0100
Subject: [R] empty string
Message-ID: <200401151739300914.10EC59F6@harry.molgen.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040115/ca7f4410/attachment.pl

From tlumley at u.washington.edu  Thu Jan 15 17:45:16 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 15 Jan 2004 08:45:16 -0800 (PST)
Subject: [R] empty string
In-Reply-To: <200401151739300914.10EC59F6@harry.molgen.mpg.de>
References: <200401151739300914.10EC59F6@harry.molgen.mpg.de>
Message-ID: <Pine.A41.4.58.0401150842400.16268@homer30.u.washington.edu>

On Thu, 15 Jan 2004, Wolski wrote:

> Hi!
>
> How to generate a empty string of a precise length without using a loop?

paste(rep(" ",n), collapse="")

gives a string of n spaces.

	-thomas


>
>
>
> I need a empty string (char **) to pass it with .C function to a c dll.
> The c routine writes the result into the string.
>
>
> Eryk.
>
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics
> Ihnestrasse 73 14195 Berlin          'v'
> tel: 0049-30-84131285               /   \
> mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From rvaradha at jhsph.edu  Thu Jan 15 17:52:29 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Thu, 15 Jan 2004 11:52:29 -0500
Subject: [R] Generalized least squares using "gnls" function
Message-ID: <30177430098b.30098b301774@jhsph.edu>

Dear Christian:

That is not the problem, but thanks for your attempted help. I still 
don't know what the problem is.  Has anyone encountered this while 
using "gnls" function in the package "nlme"?

thanks again for any help,

Ravi.



----- Original Message -----
From: Christian Mora <christian_mora at vtr.net>
Date: Wednesday, January 14, 2004 7:15 pm
Subject: RE: [R] Generalized least squares using "gnls" function

> Have you tried removing tol=1.e-07 or changing the value considering
> that the error is Object "." not found
> 
> -----Original Message-----
> From: r-help-bounces+christian_mora=vtr.net at stat.math.ethz.ch
> [mailto:r-help-bounces+christian_mora=vtr.net at stat.math.ethz.ch] On
> Behalf Of Ravi Varadhan
> Sent: Wednesday, January 14, 2004 6:11 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Generalized least squares using "gnls" function
> 
> 
> Hi:
> 
> I have data from an assay in the form of two vectors, one is 
> response 
> and the other is a predictor. When I attempt to fit a 5 parameter 
> logistic model with "nls", I get converged parameter estimates. I 
> also 
> get the same answers with "gnls" without specifying the "weights" 
> argument.
> 
> However, when I attempt to use the "gnls" function and try to 
> estimate 
> the variance function, as a power function, I get the following 
> error 
> message:
> 
> > ans51g <- gnls(log(b51) ~ p0 + p1/(1 + exp(-(log(dose)-
> p2)/p3))^p4, 
> start=list(p0=3,p1=1,p2=4,p3=2,p4=1.5),control=gnlsControl(tol=1.e-
> 07),weights=varPower())
> Error in eval(expr, envir, enclos) : Object "." not found
> > 
> 
> What am I doing wrong here and how can I do a GLS analysis with a 
> variance function that is estimated from the data?
> 
> Here is my data:
> 
> > b51 <- c(17447.60674, 7060.37234, 2872.53012,  796.40426,  
> 454.47222,  260.22340,  120.11905,    83.40196,  51.45745,    
> 36.87912,  26.73256,    25.18681, 17.97674)
> > dose <- c( 1.000000e+04, 1.000000e+03, 2.500000e+02, 
> 6.250000e+01, 
> 3.125000e+01,  1.562500e+01, 7.812500e+00, 3.906250e+00, 
> 1.953125e+00, 9.765625e-01, 4.882813e-01, 2.441406e-01, 1.000000e-03)
> 
> thanks for the help,
> Ravi.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
>



From B.Rowlingson at lancaster.ac.uk  Thu Jan 15 17:59:32 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 15 Jan 2004 16:59:32 +0000
Subject: [R] empty string
In-Reply-To: <Pine.A41.4.58.0401150842400.16268@homer30.u.washington.edu>
References: <200401151739300914.10EC59F6@harry.molgen.mpg.de>
	<Pine.A41.4.58.0401150842400.16268@homer30.u.washington.edu>
Message-ID: <4006C6F4.5010506@lancaster.ac.uk>

Thomas Lumley wrote:

> paste(rep(" ",n), collapse="")
> 
> gives a string of n spaces.
> 

  Is that more or less efficient/faster or slower than using sprintf:

sprintf(paste("%",n,"s",sep='')," ")

  A quick test shows it to take about two-thirds the CPU time of the 
paste(rep()) solution.

  Not that it matters - I cant see something like this ever being a 
significant part of any calculation!

Baz



From ripley at stats.ox.ac.uk  Thu Jan 15 18:07:23 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2004 17:07:23 +0000 (GMT)
Subject: [R] Generalized least squares using "gnls" function
In-Reply-To: <30177430098b.30098b301774@jhsph.edu>
Message-ID: <Pine.LNX.4.44.0401151701300.17083-100000@gannet.stats>

The default argument for varPower's `form' arg is form = ~fitted(.)
I am pretty sure that is the `.' that is not found, and I guess it is an 
S/R difference.

I've always had trouble with this form of varPower (even in S).  I just 
wonder if form = ~fitted(".") might work.


On Thu, 15 Jan 2004, Ravi Varadhan wrote:

> Dear Christian:
> 
> That is not the problem, but thanks for your attempted help. I still 
> don't know what the problem is.  Has anyone encountered this while 
> using "gnls" function in the package "nlme"?
> 
> thanks again for any help,
> 
> Ravi.
> 
> 
> 
> ----- Original Message -----
> From: Christian Mora <christian_mora at vtr.net>
> Date: Wednesday, January 14, 2004 7:15 pm
> Subject: RE: [R] Generalized least squares using "gnls" function
> 
> > Have you tried removing tol=1.e-07 or changing the value considering
> > that the error is Object "." not found
> > 
> > -----Original Message-----
> > From: r-help-bounces+christian_mora=vtr.net at stat.math.ethz.ch
> > [mailto:r-help-bounces+christian_mora=vtr.net at stat.math.ethz.ch] On
> > Behalf Of Ravi Varadhan
> > Sent: Wednesday, January 14, 2004 6:11 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Generalized least squares using "gnls" function
> > 
> > 
> > Hi:
> > 
> > I have data from an assay in the form of two vectors, one is 
> > response 
> > and the other is a predictor. When I attempt to fit a 5 parameter 
> > logistic model with "nls", I get converged parameter estimates. I 
> > also 
> > get the same answers with "gnls" without specifying the "weights" 
> > argument.
> > 
> > However, when I attempt to use the "gnls" function and try to 
> > estimate 
> > the variance function, as a power function, I get the following 
> > error 
> > message:
> > 
> > > ans51g <- gnls(log(b51) ~ p0 + p1/(1 + exp(-(log(dose)-
> > p2)/p3))^p4, 
> > start=list(p0=3,p1=1,p2=4,p3=2,p4=1.5),control=gnlsControl(tol=1.e-
> > 07),weights=varPower())
> > Error in eval(expr, envir, enclos) : Object "." not found
> > > 
> > 
> > What am I doing wrong here and how can I do a GLS analysis with a 
> > variance function that is estimated from the data?
> > 
> > Here is my data:
> > 
> > > b51 <- c(17447.60674, 7060.37234, 2872.53012,  796.40426,  
> > 454.47222,  260.22340,  120.11905,    83.40196,  51.45745,    
> > 36.87912,  26.73256,    25.18681, 17.97674)
> > > dose <- c( 1.000000e+04, 1.000000e+03, 2.500000e+02, 
> > 6.250000e+01, 
> > 3.125000e+01,  1.562500e+01, 7.812500e+00, 3.906250e+00, 
> > 1.953125e+00, 9.765625e-01, 4.882813e-01, 2.441406e-01, 1.000000e-03)
> > 
> > thanks for the help,
> > Ravi.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rvaradha at jhsph.edu  Thu Jan 15 18:21:25 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Thu, 15 Jan 2004 12:21:25 -0500
Subject: [R] Generalized least squares using "gnls" function
Message-ID: <3097cc309a32.309a323097cc@jhsph.edu>

Hi:

I tried Prof. Ripley's suggestion and I got the following error message:

> ans52g <- gnls(log(b52) ~ p0 + p1/(1 + exp(-(log(dose)-p2)/p3))^p4, 
start=list(p0=3,p1=8,p2=2,p3=2,p4=1.5),control=gnlsControl(tol=1.e-07),
weights=varPower(form=~fitted(".")))
Error in varPower(form = ~fitted(".")) : "form" must have a covariate

I also tried without the quotes for the "form" argument, but it did't 
work either.

I would really like to use this option since I want to model 
heteroscedasticity in my assay response as a power function of the mean 
response, where the exponent in the power function is to be estimated 
by the GLS procedure, along with the paremeters of the logistic 
function. 

thanks,
Ravi.

----- Original Message -----
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
Date: Thursday, January 15, 2004 12:07 pm
Subject: Re: RE: [R] Generalized least squares using "gnls" function

> The default argument for varPower's `form' arg is form = ~fitted(.)
> I am pretty sure that is the `.' that is not found, and I guess it 
> is an 
> S/R difference.
> 
> I've always had trouble with this form of varPower (even in S).  I 
> just 
> wonder if form = ~fitted(".") might work.
> 
> 
> On Thu, 15 Jan 2004, Ravi Varadhan wrote:
> 
> > Dear Christian:
> > 
> > That is not the problem, but thanks for your attempted help. I 
> still 
> > don't know what the problem is.  Has anyone encountered this 
> while 
> > using "gnls" function in the package "nlme"?
> > 
> > thanks again for any help,
> > 
> > Ravi.
> > 
> > 
> > 
> > ----- Original Message -----
> > From: Christian Mora <christian_mora at vtr.net>
> > Date: Wednesday, January 14, 2004 7:15 pm
> > Subject: RE: [R] Generalized least squares using "gnls" function
> > 
> > > Have you tried removing tol=1.e-07 or changing the value 
> considering> > that the error is Object "." not found
> > > 
> > > -----Original Message-----
> > > From: r-help-bounces+christian_mora=vtr.net at stat.math.ethz.ch
> > > [mailto:r-help-
> bounces+christian_mora=vtr.net at stat.math.ethz.ch] On
> > > Behalf Of Ravi Varadhan
> > > Sent: Wednesday, January 14, 2004 6:11 PM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] Generalized least squares using "gnls" function
> > > 
> > > 
> > > Hi:
> > > 
> > > I have data from an assay in the form of two vectors, one is 
> > > response 
> > > and the other is a predictor. When I attempt to fit a 5 
> parameter 
> > > logistic model with "nls", I get converged parameter 
> estimates. I 
> > > also 
> > > get the same answers with "gnls" without specifying the 
> "weights" 
> > > argument.
> > > 
> > > However, when I attempt to use the "gnls" function and try to 
> > > estimate 
> > > the variance function, as a power function, I get the 
> following 
> > > error 
> > > message:
> > > 
> > > > ans51g <- gnls(log(b51) ~ p0 + p1/(1 + exp(-(log(dose)-
> > > p2)/p3))^p4, 
> > > 
> start=list(p0=3,p1=1,p2=4,p3=2,p4=1.5),control=gnlsControl(tol=1.e-
> > > 07),weights=varPower())
> > > Error in eval(expr, envir, enclos) : Object "." not found
> > > > 
> > > 
> > > What am I doing wrong here and how can I do a GLS analysis 
> with a 
> > > variance function that is estimated from the data?
> > > 
> > > Here is my data:
> > > 
> > > > b51 <- c(17447.60674, 7060.37234, 2872.53012,  796.40426,  
> > > 454.47222,  260.22340,  120.11905,    83.40196,  51.45745,    
> > > 36.87912,  26.73256,    25.18681, 17.97674)
> > > > dose <- c( 1.000000e+04, 1.000000e+03, 2.500000e+02, 
> > > 6.250000e+01, 
> > > 3.125000e+01,  1.562500e+01, 7.812500e+00, 3.906250e+00, 
> > > 1.953125e+00, 9.765625e-01, 4.882813e-01, 2.441406e-01, 
> 1.000000e-03)
> > > 
> > > thanks for the help,
> > > Ravi.
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > > 
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-
> project.org/posting-guide.html
> > 
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From Michael.Man at pfizer.com  Thu Jan 15 18:28:12 2004
From: Michael.Man at pfizer.com (Man, Michael)
Date: Thu, 15 Jan 2004 12:28:12 -0500
Subject: [R] old version of R for Windows
Message-ID: <4E2F83D5DEE32C41B4816FE9D634624208C24B44@anagrdexm01.research.aa.wl.com>

I am looking for old version of R for Windows (before 1.5).  Where would I
find them?

Michael


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From RBaskin at ahrq.gov  Thu Jan 15 19:06:39 2004
From: RBaskin at ahrq.gov (RBaskin@ahrq.gov)
Date: Thu, 15 Jan 2004 13:06:39 -0500
Subject: [R] how to overlap plots
Message-ID: <3598558AD728D41183350008C7CF291C0F16BA4A@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040115/aa194768/attachment.pl

From james.lindsey at luc.ac.be  Thu Jan 15 19:47:53 2004
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Thu, 15 Jan 2004 19:47:53 +0100 (MET)
Subject: [R] how to overlap plots
In-Reply-To: <1074183617.4006bdc1a1e1c@webmail.uoguelph.ca> from
	"szhan@uoguelph.ca" at Jan 15, 2004 11:20:17 AM
Message-ID: <200401151847.TAA31352@luc.ac.be>

> 
> Dear R experts:
> Can you help me to overlap a histogram and theoretical density curve of poison 
> distribution? for example data like this:
> The numbers of sanils found in each of 100 sampling quadrats in an area were 
> as follows:
> number of snails, r 0 1  2 3 4 5 8 15
> f=frequency of r   69 18 7 2 1 1 1 1
> apparently this is not Poison but near to Poison, How to overlap the 
> theoretical desity curve to the histgram of this data?
> Thanks in advance!

The fit.dist function in my gnlm library (www.luc.ac.be/~jlindsey/rcode.html)
does that automatically. Jim

> Josh
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Scott.Waichler at pnl.gov  Thu Jan 15 19:50:27 2004
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Thu, 15 Jan 2004 10:50:27 -0800
Subject: [R] Extracting multiple elements from a list
Message-ID: <62AE0CF1D4875C4BBDEC29DB9924ACE87F2177@pnlmse25.pnl.gov>


For a long time I've wanted a way to conveniently extract multiple elements
from a list, which [[ doesn't allow.  Can anyone suggest an efficient
function to do this?  Wouldn't it be a sensible addition to R?

For example,

alist <- list()
alist[[1]] <- list()
alist[[1]]$name <- "first"
alist[[1]]$vec <- 1:4
alist[[2]] <- list()
alist[[2]]$name <- "second"
alist[[2]]$vec <- 5:8
both.vec <- c(alist[[1]]$vec, alist[[2]]$vec)

Can I get both.vec without c() or an explicit loop?

and

new.names <- c("one", "two")
alist[[1]]$name <- new.names[1]
alist[[2]]$name <- new.names[2]

Could I assign the new values in a quasi-vectorized way?

Thanks,
Scott Waichler
Pacific Northwest National Laboratory
Richland, WA   USA



From ripley at stats.ox.ac.uk  Thu Jan 15 19:55:04 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2004 18:55:04 +0000 (GMT)
Subject: [R] old version of R for Windows
In-Reply-To: <4E2F83D5DEE32C41B4816FE9D634624208C24B44@anagrdexm01.research.aa.wl.com>
Message-ID: <Pine.LNX.4.44.0401151853020.3413-100000@gannet.stats>

The sources are on CRAN still, and older compilers (if needed) are 
available via www.mingw.org.  So where is the difficulty?

On Thu, 15 Jan 2004, Man, Michael wrote:

> I am looking for old version of R for Windows (before 1.5).  Where would I
> find them?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Thu Jan 15 19:57:18 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 15 Jan 2004 13:57:18 -0500
Subject: [R] Extracting multiple elements from a list
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7629@usrymx25.merck.com>

Aren't sapply()/lapply() sufficient for this?

> sapply(alist, function(x) x$vec)
     [,1] [,2]
[1,]    1    5
[2,]    2    6
[3,]    3    7
[4,]    4    8
> lapply(alist, function(x) x$vec)
[[1]]
[1] 1 2 3 4

[[2]]
[1] 5 6 7 8

HTH,
Andy

> From: Waichler, Scott R
> 
> For a long time I've wanted a way to conveniently extract 
> multiple elements
> from a list, which [[ doesn't allow.  Can anyone suggest an efficient
> function to do this?  Wouldn't it be a sensible addition to R?
> 
> For example,
> 
> alist <- list()
> alist[[1]] <- list()
> alist[[1]]$name <- "first"
> alist[[1]]$vec <- 1:4
> alist[[2]] <- list()
> alist[[2]]$name <- "second"
> alist[[2]]$vec <- 5:8
> both.vec <- c(alist[[1]]$vec, alist[[2]]$vec)
> 
> Can I get both.vec without c() or an explicit loop?
> 
> and
> 
> new.names <- c("one", "two")
> alist[[1]]$name <- new.names[1]
> alist[[2]]$name <- new.names[2]
> 
> Could I assign the new values in a quasi-vectorized way?
> 
> Thanks,
> Scott Waichler
> Pacific Northwest National Laboratory
> Richland, WA   USA
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From adrienne.mueller at imperial.ac.uk  Thu Jan 15 20:04:32 2004
From: adrienne.mueller at imperial.ac.uk (Mueller, Adrienne)
Date: Thu, 15 Jan 2004 19:04:32 -0000
Subject: [R] Lattices: Cloud: Background
Message-ID: <65544FA95ABA5243975A6930429BD9B0092F85@icex33.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040115/f7612321/attachment.pl

From ripley at stats.ox.ac.uk  Thu Jan 15 20:16:48 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2004 19:16:48 +0000 (GMT)
Subject: [R] Extracting multiple elements from a list
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7629@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0401151910260.31030-100000@gannet.stats>

[] works on a list and extracts multiple elements.  However, that is not 
it seems what you want, rather, unions of elements of elements of lists.
That is a pretty unusual need, and perhaps you could explain you you need 
it.

Andy's solution still need something like

do.call("c",  lapply(alist, function(x) x$vec))

but then it *is* unions of elements of elements of lists.


On Thu, 15 Jan 2004, Liaw, Andy wrote:

> Aren't sapply()/lapply() sufficient for this?
> 
> > sapply(alist, function(x) x$vec)
>      [,1] [,2]
> [1,]    1    5
> [2,]    2    6
> [3,]    3    7
> [4,]    4    8
> > lapply(alist, function(x) x$vec)
> [[1]]
> [1] 1 2 3 4
> 
> [[2]]
> [1] 5 6 7 8
> 
> HTH,
> Andy
> 
> > From: Waichler, Scott R
> > 
> > For a long time I've wanted a way to conveniently extract 
> > multiple elements
> > from a list, which [[ doesn't allow.  Can anyone suggest an efficient
> > function to do this?  Wouldn't it be a sensible addition to R?
> > 
> > For example,
> > 
> > alist <- list()
> > alist[[1]] <- list()
> > alist[[1]]$name <- "first"
> > alist[[1]]$vec <- 1:4
> > alist[[2]] <- list()
> > alist[[2]]$name <- "second"
> > alist[[2]]$vec <- 5:8
> > both.vec <- c(alist[[1]]$vec, alist[[2]]$vec)
> > 
> > Can I get both.vec without c() or an explicit loop?
> > 
> > and
> > 
> > new.names <- c("one", "two")
> > alist[[1]]$name <- new.names[1]
> > alist[[2]]$name <- new.names[2]
> > 
> > Could I assign the new values in a quasi-vectorized way?
> > 
> > Thanks,
> > Scott Waichler
> > Pacific Northwest National Laboratory
> > Richland, WA   USA
> > 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments,...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jeff.hamann at forestinformatics.com  Thu Jan 15 20:17:13 2004
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Thu, 15 Jan 2004 11:17:13 -0800
Subject: [R] hyperlink in the R logo to a/the R homepage?
Message-ID: <000e01c3db9c$31a03570$0a00a8c0@rodan>

Would it be smart to add a hyperlink for the R logo (in the help files) that
would go the, or a, R homepage?

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
(office) 541-754-1428
(cell) 541-740-5988
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From jeff.hamann at forestinformatics.com  Thu Jan 15 20:23:29 2004
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Thu, 15 Jan 2004 11:23:29 -0800
Subject: [R] plotting predicted values (lines) over data?
Message-ID: <000f01c3db9d$0e968600$0a00a8c0@rodan>

I've been trying to plot the predicted values, as a line, over the data for
a simple nonlinear fit with the following commands:

plot( hg ~ ht )
... define some function hg ~ ht + junk ...
... blah, blah, obtain parameter estimates and predicted values, blah...
... then...
lines( sort( $predicted ) ~ sort( ht ) )

which results in a line that isn't smooth (which I knew would happen). I've
checked the FAQ,docs and archives and I'm not sure if there's function that
will so what Heut et. al (2004) do with their plfit(). So, is there already
an R function, or process to do this, or will I have to write one?

Thanks,
Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
(office) 541-754-1428
(cell) 541-740-5988
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From rpeng at jhsph.edu  Thu Jan 15 21:02:55 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 15 Jan 2004 15:02:55 -0500
Subject: [R] Extracting multiple elements from a list
In-Reply-To: <62AE0CF1D4875C4BBDEC29DB9924ACE87F2177@pnlmse25.pnl.gov>
References: <62AE0CF1D4875C4BBDEC29DB9924ACE87F2177@pnlmse25.pnl.gov>
Message-ID: <4006F1EF.2080809@jhsph.edu>

For the first case, I actually do this pretty often and usually use 
something like:

as.vector(sapply(alist, "[[", "vec"))

For the second case, I think you just need to use lapply():

alist <- lapply(seq(along = alist), function(i)
		alist[[i]]$name <- new.names[i])

-roger

Waichler, Scott R wrote:
> For a long time I've wanted a way to conveniently extract multiple elements
> from a list, which [[ doesn't allow.  Can anyone suggest an efficient
> function to do this?  Wouldn't it be a sensible addition to R?
> 
> For example,
> 
> alist <- list()
> alist[[1]] <- list()
> alist[[1]]$name <- "first"
> alist[[1]]$vec <- 1:4
> alist[[2]] <- list()
> alist[[2]]$name <- "second"
> alist[[2]]$vec <- 5:8
> both.vec <- c(alist[[1]]$vec, alist[[2]]$vec)
> 
> Can I get both.vec without c() or an explicit loop?
> 
> and
> 
> new.names <- c("one", "two")
> alist[[1]]$name <- new.names[1]
> alist[[2]]$name <- new.names[2]
> 
> Could I assign the new values in a quasi-vectorized way?
> 
> Thanks,
> Scott Waichler
> Pacific Northwest National Laboratory
> Richland, WA   USA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From rpeng at jhsph.edu  Thu Jan 15 21:24:29 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 15 Jan 2004 15:24:29 -0500
Subject: [R] Extracting multiple elements from a list
In-Reply-To: <4006F1EF.2080809@jhsph.edu>
References: <62AE0CF1D4875C4BBDEC29DB9924ACE87F2177@pnlmse25.pnl.gov>
	<4006F1EF.2080809@jhsph.edu>
Message-ID: <4006F6FD.4010404@jhsph.edu>

Sorry, that second example should be

alist <- lapply(seq(along = alist), function(i) {
                 alist[[i]]$name <- new.names[i])
                 alist
          })

-roger

Roger D. Peng wrote:
> For the first case, I actually do this pretty often and usually use 
> something like:
> 
> as.vector(sapply(alist, "[[", "vec"))
> 
> For the second case, I think you just need to use lapply():
> 
> alist <- lapply(seq(along = alist), function(i)
>         alist[[i]]$name <- new.names[i])
> 
> -roger
> 
> Waichler, Scott R wrote:
> 
>> For a long time I've wanted a way to conveniently extract multiple 
>> elements
>> from a list, which [[ doesn't allow.  Can anyone suggest an efficient
>> function to do this?  Wouldn't it be a sensible addition to R?
>>
>> For example,
>>
>> alist <- list()
>> alist[[1]] <- list()
>> alist[[1]]$name <- "first"
>> alist[[1]]$vec <- 1:4
>> alist[[2]] <- list()
>> alist[[2]]$name <- "second"
>> alist[[2]]$vec <- 5:8
>> both.vec <- c(alist[[1]]$vec, alist[[2]]$vec)
>>
>> Can I get both.vec without c() or an explicit loop?
>>
>> and
>>
>> new.names <- c("one", "two")
>> alist[[1]]$name <- new.names[1]
>> alist[[2]]$name <- new.names[2]
>>
>> Could I assign the new values in a quasi-vectorized way?
>>
>> Thanks,
>> Scott Waichler
>> Pacific Northwest National Laboratory
>> Richland, WA   USA
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Thu Jan 15 21:13:45 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 15 Jan 2004 15:13:45 -0500
Subject: [R] plotting predicted values (lines) over data?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF762C@usrymx25.merck.com>

> From: Jeff D. Hamann
> 
> I've been trying to plot the predicted values, as a line, 
> over the data for
> a simple nonlinear fit with the following commands:
> 
> plot( hg ~ ht )
> ... define some function hg ~ ht + junk ...
> ... blah, blah, obtain parameter estimates and predicted 
> values, blah...
> ... then...
> lines( sort( $predicted ) ~ sort( ht ) )

This doesn't look right to me.  Don't you want something like:

  ord <- order(ht)
  lines(ht[ord], fit$predicted[ord], ...)

???

Andy

 
> which results in a line that isn't smooth (which I knew would 
> happen). I've
> checked the FAQ,docs and archives and I'm not sure if there's 
> function that
> will so what Heut et. al (2004) do with their plfit(). So, is 
> there already
> an R function, or process to do this, or will I have to write one?
> 
> Thanks,
> Jeff.
> 
> ---
> Jeff D. Hamann
> Forest Informatics, Inc.
> PO Box 1421
> Corvallis, Oregon USA 97339-1421
> (office) 541-754-1428
> (cell) 541-740-5988
> jeff.hamann at forestinformatics.com
> www.forestinformatics.com
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From hagric at sbox.tugraz.at  Thu Jan 15 21:56:23 2004
From: hagric at sbox.tugraz.at (hagric)
Date: Thu, 15 Jan 2004 21:56:23 +0100
Subject: [R] SIR
Message-ID: <4006FE77.8050502@sbox.TUGraz.at>

Ich habe in R eine Version von SIR gefunden und ausprobiert. Leider kann 
diese multivariate Responses nicht verarbeiten. Gibt es in R eine 
ausgefeilte Version von SIR?



From vera.hofer at uni-graz.at  Thu Jan 15 21:57:24 2004
From: vera.hofer at uni-graz.at (Vera Hofer)
Date: Thu, 15 Jan 2004 21:57:24 +0100
Subject: [R] SIR
Message-ID: <4006FEB4.4070809@uni-graz.at>

Ich habe in R eine Version von SIR gefunden und ausprobiert. Leider kann 
diese multivariate Responses nicht verarbeiten. Gibt es in R eine 
ausgefeilte Version von SIR?
Danke f?r die Hilfe.
V.H.



From Scott.Waichler at pnl.gov  Thu Jan 15 21:54:35 2004
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Thu, 15 Jan 2004 12:54:35 -0800
Subject: [R] Extracting multiple elements from a list
Message-ID: <62AE0CF1D4875C4BBDEC29DB9924ACE87F2178@pnlmse25.pnl.gov>


Brian described well the operation I would like to do.
I'm not familiar with do.call() but I'll work on that.
Yes, ideally I would like to access values throughout a list object
with fully implict indexing, such as the invalid "alist[[1:2]]$vec[c(2, 4)]".
Notice I was hoping to subset anywhere in the data structure.
Since I can't do this subsetting with indexing directly, I was looking for
handy (and hopefully fast) functions that could be defined
generically and then called with arguments.  The use of sapply()
and lapply() with function(i) seem promising, but do not quite
cover the functionality I was looking for.

The basic application of sapply() suggested by Andy 
is fine but I can't access part of the second-level list, only the whole
vector.  Roger's use of sapply() 

 as.vector(sapply(alist, "[[", "vec"))

is a nice way to get the whole vector also, and I appreciate learning 
that syntax.  The correction by Roger for his use of lapply() still isn't 
right though (see below).

alist <- lapply(seq(along = alist), function(i) {
                 alist[[i]]$name <- new.names[i]
                 alist
          })

I desire:
> alist
[[1]]
[[1]]$name
[1] "one"

[[1]]$vec
[1] 1 2 3 4


[[2]]
[[2]]$name
[1] "two"

[[2]]$vec
[1] 5 6 7 8

Roger's use of lapply() give: 
> alist
[[1]]
[[1]][[1]]
[[1]][[1]]$name
[1] "one"

[[1]][[1]]$vec
[1] 1 2 3 4


[[1]][[2]]
[[1]][[2]]$name
[1] "two"

[[1]][[2]]$vec
[1] 5 6 7 8



[[2]]
[[2]][[1]]
[[2]][[1]]$name
[1] "one"

[[2]][[1]]$vec
[1] 1 2 3 4


[[2]][[2]]
[[2]][[2]]$name
[1] "two"

[[2]][[2]]$vec
[1] 5 6 7 8

> -----Original Message-----
> From: Roger D. Peng [mailto:rpeng at jhsph.edu]
> Sent: Thursday, January 15, 2004 12:24 PM
> To: Waichler, Scott R
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Extracting multiple elements from a list
> 
> 
> Sorry, that second example should be
> 
> alist <- lapply(seq(along = alist), function(i) {
>                  alist[[i]]$name <- new.names[i])
>                  alist
>           })
> 
> -roger
> 
> Roger D. Peng wrote:
> > For the first case, I actually do this pretty often and usually use 
> > something like:
> > 
> > as.vector(sapply(alist, "[[", "vec"))
> > 
> > For the second case, I think you just need to use lapply():
> > 
> > alist <- lapply(seq(along = alist), function(i)
> >         alist[[i]]$name <- new.names[i])
> > 
> > -roger
> > 
> > Waichler, Scott R wrote:
> > 
> >> For a long time I've wanted a way to conveniently extract multiple 
> >> elements
> >> from a list, which [[ doesn't allow.  Can anyone suggest 
> an efficient
> >> function to do this?  Wouldn't it be a sensible addition to R?
> >>
> >> For example,
> >>
> >> alist <- list()
> >> alist[[1]] <- list()
> >> alist[[1]]$name <- "first"
> >> alist[[1]]$vec <- 1:4
> >> alist[[2]] <- list()
> >> alist[[2]]$name <- "second"
> >> alist[[2]]$vec <- 5:8
> >> both.vec <- c(alist[[1]]$vec, alist[[2]]$vec)
> >>
> >> Can I get both.vec without c() or an explicit loop?
> >>
> >> and
> >>
> >> new.names <- c("one", "two")
> >> alist[[1]]$name <- new.names[1]
> >> alist[[2]]$name <- new.names[2]
> >>
> >> Could I assign the new values in a quasi-vectorized way?
> >>
> >> Thanks,
> >> Scott Waichler
> >> Pacific Northwest National Laboratory
> >> Richland, WA   USA
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide! 
> >> http://www.R-project.org/posting-guide.html
> >>
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
>



From patrick.giraudoux at univ-fcomte.fr  Thu Jan 15 23:03:52 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Thu, 15 Jan 2004 23:03:52 +0100
Subject: [R] Multiple comparisons in R;  multicomp
Message-ID: <005301c3dbb3$77fbde90$53bc3151@PC728329681112>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040115/a9c1c140/attachment.pl

From abunn at montana.edu  Thu Jan 15 23:11:48 2004
From: abunn at montana.edu (Andy Bunn)
Date: Thu, 15 Jan 2004 15:11:48 -0700
Subject: [R] Multiple comparisons in R;  multicomp
In-Reply-To: <005301c3dbb3$77fbde90$53bc3151@PC728329681112>
Message-ID: <000201c3dbb4$a3e620f0$78f05a99@msu.montana.edu>

There is now a package in R called multcomp for general multiple
comparisons that does things similar to the Splus library you mentioned.
BTW, a search of the help archives for multicomp or "multiple
comparisons" brings this up.

HTH, Andy



From jfox at mcmaster.ca  Thu Jan 15 23:18:57 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 15 Jan 2004 17:18:57 -0500
Subject: [R] plotting predicted values (lines) over data?
In-Reply-To: <000f01c3db9d$0e968600$0a00a8c0@rodan>
Message-ID: <5.1.0.14.2.20040115171414.0204c4d0@127.0.0.1>

Dear Jeff,

I'm not sure that I follow entirely what you've done, but perhaps the 
following suggestions will help: (1) If the plotted curve isn't smooth 
because it's evaluated at too few x-values or at x-values that are too 
unevenly spaced, what about getting a sufficient number of predicted values 
[via predict()] that are evenly spaced along the range of ht -- i.e., not 
at the observations? (2) Rather than connecting the fitted values with line 
segments, you could use spline() to interpolate.

I hope that this helps,
  John

At 11:23 AM 1/15/2004 -0800, Jeff D. Hamann wrote:
>I've been trying to plot the predicted values, as a line, over the data for
>a simple nonlinear fit with the following commands:
>
>plot( hg ~ ht )
>... define some function hg ~ ht + junk ...
>... blah, blah, obtain parameter estimates and predicted values, blah...
>... then...
>lines( sort( $predicted ) ~ sort( ht ) )
>
>which results in a line that isn't smooth (which I knew would happen). I've
>checked the FAQ,docs and archives and I'm not sure if there's function that
>will so what Heut et. al (2004) do with their plfit(). So, is there already
>an R function, or process to do this, or will I have to write one?
>
>Thanks,
>Jeff.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From jfox at mcmaster.ca  Thu Jan 15 23:28:06 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 15 Jan 2004 17:28:06 -0500
Subject: [R] Lattices: Cloud: Background
In-Reply-To: <65544FA95ABA5243975A6930429BD9B0092F85@icex33.ic.ac.uk>
Message-ID: <5.1.0.14.2.20040115172716.0213e698@127.0.0.1>

Dear Adrienne,

I'm aware of a couple of ways to get a white background in trellis 
graphics. One is lset(col.whitebg()).

I hope that this helps,
  John

At 07:04 PM 1/15/2004 +0000, Mueller, Adrienne wrote:
>Hi,
>There's probably some simple way of doing this, but I'm just not seeing
>it - How do I get the background to be white instead of grey when I have
>a cloud plot (using the lattices package)? par(bg="white") isn't
>working. I'm assuming par commands won't work on lattice plots. What
>should I use instead?
>

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From rpeng at jhsph.edu  Thu Jan 15 23:49:28 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 15 Jan 2004 17:49:28 -0500
Subject: [R] Lattices: Cloud: Background
In-Reply-To: <65544FA95ABA5243975A6930429BD9B0092F85@icex33.ic.ac.uk>
References: <65544FA95ABA5243975A6930429BD9B0092F85@icex33.ic.ac.uk>
Message-ID: <400718F8.1030505@jhsph.edu>

Try

trellis.par.set("background", list(col = 0))

Or you can explicitly launch the trellis device and set `bg = 0'.

-roger

Mueller, Adrienne wrote:
> Hi,
> There's probably some simple way of doing this, but I'm just not seeing
> it - How do I get the background to be white instead of grey when I have
> a cloud plot (using the lattices package)? par(bg="white") isn't
> working. I'm assuming par commands won't work on lattice plots. What
> should I use instead?
>  
> Thanks,
> Adrienne
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From e_curiotto at yahoo.com  Fri Jan 16 00:02:11 2004
From: e_curiotto at yahoo.com (Enrico Curiotto)
Date: Thu, 15 Jan 2004 15:02:11 -0800 (PST)
Subject: [R] invoking R scripts from a linux shell ?
Message-ID: <20040115230211.47800.qmail@web10605.mail.yahoo.com>

Hello,

I have written perl programs that extract data from a
text file, process them, and create other text files,
which I'd like to apply some statistics too (for
example with R).

I'd like to do it all in once , with a single script.
I'm not familiar with R, I'd like to know if this task
could be accomplished by creating a linux shells that
launches the perl scripts and then "R functions" that
maybe pass back some results to the system like in
this schema:

S ---> Perl
H <-----
E ---> R functions
L <-----
L

Is it possible ?
Where can I get information to do that? (to call R
from a shell, in background)

Are other better way to do that?

Thank you very much!

Enrico.



From schoenle at fas.harvard.edu  Fri Jan 16 00:44:18 2004
From: schoenle at fas.harvard.edu (Raphael Schoenle)
Date: Thu, 15 Jan 2004 18:44:18 -0500
Subject: [R] memory in R
Message-ID: <000001c3dbc1$7e620530$268ff78c@acer4jbjp1qwlp>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040115/241f8af3/attachment.pl

From jerome at hivnet.ubc.ca  Fri Jan 16 00:47:44 2004
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Thu, 15 Jan 2004 15:47:44 -0800
Subject: [R] random effects with lme() -- comparison with lm()
Message-ID: <1074210463.5854.123.camel@penguin>


Hi all,

In the (very simple) example below, I have defined a random effect for
the residuals in lme(). So the model is equivalent to a FIXED effect
model. Could someone explain to me why lme() still gives two standard
deviation estimates? I would expect lme() to return either:
a) an error or a warning for having an unidentifiable model;
b) only one standard deviation estimate.

Thank you for your time.
Jerome Asselin

> library(nlme)
> simdat <- data.frame(A=1:4,Y=c(23,43,11,34))
> simdat
  A  Y
1 1 23
2 2 43
3 3 11
4 4 34
> lme(Y~1,data=simdat,random=~1|A)
<...snip...>
Random effects:
 Formula: ~1 | A
        (Intercept) Residual
StdDev:    12.96007 4.860027
<...snip...>
> summary(lm(Y~1,data=simdat))$sigma
[1] 13.84136
> sqrt(12.96007^2+4.860027^2)
[1] 13.84136



From tvandaelen at scitegic.com  Fri Jan 16 01:22:00 2004
From: tvandaelen at scitegic.com (Ton van Daelen)
Date: Thu, 15 Jan 2004 16:22:00 -0800
Subject: [R] adjusted rand index
Message-ID: <830D8D4719112B418ABBC3A0EBA95812315199@webmail.scitegic.com>

Hi there -
Is there a package that computes an "adjusted rand index"?
Thanks a lot - Ton

Ton van Daelen, PhD
Director, Application Support
Tel: (858) 279-8800 ext 217
Fax: (858) 279-8804
Web: www.scitegic.com
 
Register now for the 2004 Pipeline Pilot user group meeting Jan 28-30 in San Diego: http://www.scitegic.com/UGMSD2004/
 



From bates at stat.wisc.edu  Fri Jan 16 01:30:54 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 15 Jan 2004 18:30:54 -0600
Subject: [R] random effects with lme() -- comparison with lm()
In-Reply-To: <1074210463.5854.123.camel@penguin>
References: <1074210463.5854.123.camel@penguin>
Message-ID: <6r8yk8d9a9.fsf@bates4.stat.wisc.edu>

Jerome Asselin <jerome at hivnet.ubc.ca> writes:

> Hi all,
> 
> In the (very simple) example below, I have defined a random effect for
> the residuals in lme(). So the model is equivalent to a FIXED effect
> model. Could someone explain to me why lme() still gives two standard
> deviation estimates? I would expect lme() to return either:
> a) an error or a warning for having an unidentifiable model;
> b) only one standard deviation estimate.
> 
> Thank you for your time.
> Jerome Asselin
> 
> > library(nlme)
> > simdat <- data.frame(A=1:4,Y=c(23,43,11,34))
> > simdat
>   A  Y
> 1 1 23
> 2 2 43
> 3 3 11
> 4 4 34
> > lme(Y~1,data=simdat,random=~1|A)
> <...snip...>
> Random effects:
>  Formula: ~1 | A
>         (Intercept) Residual
> StdDev:    12.96007 4.860027
> <...snip...>
> > summary(lm(Y~1,data=simdat))$sigma
> [1] 13.84136
> > sqrt(12.96007^2+4.860027^2)
> [1] 13.84136

The estimates from lme are REML estimates because, as you have seen,
the sum of the estimated variances is correct and in this case only
the sum is well-defined.  Of course there are an infinite number of
other possible REML estimates and that situation is not flagged.
(BTW, I wouldn't say that this is equivalent to a fixed effects
model.  It is still a random effects model with two variance
components.  It just doesn't have well-defined estimates for those two
variance components.)

What has happened is that lme set up the optimization problem and
passed it off to one of the optimizer functions which came up with
converged estimates according to some convergence criterion.  In a
simple situation like this it is easy to determined that the estimates
are not well defined.  However, lme is designed to handle very general
model specifications and catching situations where estimates are not
well defined in the general case is difficult.  So the way we designed
lme is to take the estimates from the optimizer without doing further
analysis to see if they are consistent.

You should find that intervals() applied to your fitted model produces
huge intervals on the variance components, which is one way of
diagnosing an ill-defined or nearly ill-defined model.



From erich.neuwirth at univie.ac.at  Fri Jan 16 01:53:07 2004
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Fri, 16 Jan 2004 01:53:07 +0100
Subject: [R] fedora and yum
Message-ID: <400735F3.20101@univie.ac.at>

I just installed Fedora in VMWare.
Can somebopdy tell me what lines i have to put in
yum.conf
so R will be automatically integrated in the package system
and updated when a new release is available?

-- 
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386



From jerome at hivnet.ubc.ca  Fri Jan 16 02:20:37 2004
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Thu, 15 Jan 2004 17:20:37 -0800
Subject: [R] random effects with lme() -- comparison with lm()
In-Reply-To: <6r8yk8d9a9.fsf@bates4.stat.wisc.edu>
References: <1074210463.5854.123.camel@penguin>
	<6r8yk8d9a9.fsf@bates4.stat.wisc.edu>
Message-ID: <1074216037.5854.145.camel@penguin>

On Thu, 2004-01-15 at 16:30, Douglas Bates wrote:
<...snip...>
> (BTW, I wouldn't say that this is equivalent to a fixed effects
> model.  It is still a random effects model with two variance
> components.  It just doesn't have well-defined estimates for those two
> variance components.)

Agreed.

<...snip...>
> You should find that intervals() applied to your fitted model produces
> huge intervals on the variance components, which is one way of
> diagnosing an ill-defined or nearly ill-defined model.

Following your suggestion, I got:
> intervals(lme(Y~1,data=simdat,random=~1|A))
Error in intervals.lme(lme(Y ~ 1, data = simdat, random = ~1 | A)) :
        Cannot get confidence intervals on var-cov components:
Non-positive definite approximate variance-covariance

This led me to:
> lme(Y~1,data=simdat,random=~1|A)$apVar
[1] "Non-positive definite approximate variance-covariance"

As a new feature suggestion for lme(), would it be appropriate to use
"apVar" as a warning flag in this case?

Sincerely,
Jerome Asselin



From Eric.Kort at vai.org  Fri Jan 16 02:21:12 2004
From: Eric.Kort at vai.org (Kort, Eric)
Date: Thu, 15 Jan 2004 20:21:12 -0500
Subject: [R] invoking R scripts from a linux shell ?
Message-ID: <74D0F0AB07F2E647A02D839ED79520F920888A@VAIEXCH02.vai.org>

> -----Original Message-----
> From: Enrico Curiotto [mailto:e_curiotto at yahoo.com]
> Hello,
> 
> I have written perl programs that extract data from a
> text file, process them, and create other text files,
> which I'd like to apply some statistics too (for
> example with R).
> 
> I'd like to do it all in once , with a single script.
> I'm not familiar with R, I'd like to know if this task
> could be accomplished by creating a linux shells that
> launches the perl scripts and then "R functions" that
> maybe pass back some results to the system like in
> this schema:
> 
> S ---> Perl
> H <-----
> E ---> R functions
> L <-----
> L
> 

You can run R scripts in batch mode and direct output to file.  That would be by far the simplest.  Or, you could explore RSOAP to run R as a web service which allows creation of R sessions which persist (i.e. the binary data objects stay around) between requests from another application (which could include a Perl script using Perl's soap libraries).  A third option is the Rserve system which allows connection to R sessions using TCP/IP from other software applications.

See the R helpfile on the BATCH command (?BATCH) and/or http:ess.r-project.org/Zope/projects/RSOAP/ and/or http://stats.math.uni-augsburg.de/Rserve/

HTH,
-Eric

> Is it possible ?
> Where can I get information to do that? (to call R
> from a shell, in background)
> 
> Are other better way to do that?
> 
> Thank you very much!
> 
> Enrico.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
This email message, including any attachments, is for the so...{{dropped}}



From julian.taylor at adelaide.edu.au  Fri Jan 16 06:20:45 2004
From: julian.taylor at adelaide.edu.au (Julian Taylor)
Date: Fri, 16 Jan 2004 15:50:45 +1030
Subject: [R] Extracting multiple elements from a list
References: <62AE0CF1D4875C4BBDEC29DB9924ACE87F2178@pnlmse25.pnl.gov>
Message-ID: <400774AD.8EED0FEE@adelaide.edu.au>



"Waichler, Scott R" wrote:
> 
> Brian described well the operation I would like to do.
> I'm not familiar with do.call() but I'll work on that.
> Yes, ideally I would like to access values throughout a list object
> with fully implict indexing, such as the invalid "alist[[1:2]]$vec[c(2, 4)]".
> Notice I was hoping to subset anywhere in the data structure.
> Since I can't do this subsetting with indexing directly, I was looking for
> handy (and hopefully fast) functions that could be defined
> generically and then called with arguments.  The use of sapply()
> and lapply() with function(i) seem promising, but do not quite
> cover the functionality I was looking for.
> 

The functions sapply() and lapply() have more generality that has been
overlooked in this thread.

This will answer your first question.

> unlist(lapply(alist, function(x, ind = c(2,4)) x$vec[ind]))
[1] 2 4 6 8
    
hth,
Julian

-- 
---
Julian Taylor			phone: +61 8 8303 6751
ARC Research Associate            fax: +61 8 8303 6760
BiometricsSA,                  mobile: +61 4 1638 8180  
University of Adelaide/SARDI    email: julian.taylor at adelaide.edu.au
Private Mail Bag 1                www:
http://www.BiometricsSA.adelaide.edu.au
Glen Osmond SA 5064

"There is no spoon."   -- Orphan boy  
---



From itayf at fhcrc.org  Fri Jan 16 06:44:13 2004
From: itayf at fhcrc.org (Itay Furman)
Date: Thu, 15 Jan 2004 21:44:13 -0800 (PST)
Subject: [R] invoking R scripts from a linux shell ?
In-Reply-To: <20040115230211.47800.qmail@web10605.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0401152133440.31344-100000@cezanne.fhcrc.org>

On Thu, 15 Jan 2004, Enrico Curiotto wrote:

> Hello,
> 
> I have written perl programs that extract data from a
> text file, process them, and create other text files,
> which I'd like to apply some statistics too (for
> example with R).
> 
> I'd like to do it all in once , with a single script.
> I'm not familiar with R, I'd like to know if this task
> could be accomplished by creating a linux shells that
> launches the perl scripts and then "R functions" that
> maybe pass back some results to the system like in
> this schema:
> 

You could call R in BATCH mode from the perl script using
one of the system interface operators, e.g., "system", or use the 
'Shell' module.

I have also bumped (but didn't try yet) into R-Perl interface 
called RSPerl which might be much more than you what you need.
I think it is under the "Omega" link in the R website. If not
google for RSPerl.

'R --help' will give you pointers to running R in BATCH mode.

	Itay

--------------------------------------------------------------
itayf at fhcrc.org		Fred Hutchinson Cancer Research Center



From Tom.Mulholland at health.wa.gov.au  Fri Jan 16 07:51:10 2004
From: Tom.Mulholland at health.wa.gov.au (Mulholland, Tom)
Date: Fri, 16 Jan 2004 14:51:10 +0800
Subject: [R] Lattices: Cloud: Background
Message-ID: <74E242B6968AA0469B632C5A3EFC1EFD03D57026@nt207mesep.corporate.h
	dwa.health.wa.gov.au>

When I first started using lattice I found the colour schemes a bit
confusing. So eventually I came up with the colours I wanted.

The code below was one of those attempts. One thing that happened
however was that I kept shutting down the graphics window that pops up
and the colours would revert to their default. So if you run all of the
code the first window will pop up correctly the system will pause for 5
seconds, close the window and run the code again. When the code runs it
reverts to the grey background.

Keep persevering because when it all comes together you can produce some
very good looking graphics.

Note: Not all the colours on the plot are set using lset. The text in
the key is set directly within the xyplot call.

require(lattice)


SetAltColBlue <- function(x=NULL)
{
        lset(list(background = list(col = "transparent"),
        add.text=list(col="yellow",cex=1.3),
        add.line=list(col="navy",cex=1.3),
        bar.fill = list(col = "transparent"),
        box.rectangle = list(col = "grey"),
        box.umbrella = list(col = "grey"),
        box.dot = list(col="grey"),
        dot.line = list(col = "grey"),
        dot.symbol = list(col = "grey"),
        plot.line = list(col = "grey"),
        plot.symbol = list(col = "grey"),
        regions = list(col = heat.colors(100)),
        strip.shingle = list(col = c("steelblue1")),
        strip.background = list(col = c("navy")),
        reference.line = list(col = "navy"),
        axis.text=list(col="navy",cex=0.8),
        axis.line=list(col="grey50"),
        superpose.line = list(col = c("navy", "navy", "navy",
        "navy", "navy", "navy", "navy"), lty =
1:7,lwd=c(1.5,1.5,1.5,1,1,1,1)),
        superpose.symbol =
list(col=c("steelblue1","navy","blue","black")),
        par.xlab.text = list(col="navy",cex=0.9),
        par.ylab.text = list(col="navy",cex=0.9),
        par.main.text = list(col="navy",cex=2),
        par.sub.text = list(col="navy",cex=0.8),
        box.3d=list(col="grey")))
}


SetAltColBlue()
 data(iris)
 xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width |
Species,
        data = iris, allow.multiple = TRUE, scales = "free",
        layout = c(2, 2),
        main="Title",sub="sub text",
        auto.key = list(col="steelblue4",x = .6, y = .7, corner = c(0,
0)))

bringToTop()
Sys.sleep(5)

dev.off()
 data(iris)
 xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width |
Species,
        data = iris, allow.multiple = TRUE, scales = "free",
        layout = c(2, 2),
        auto.key = list(x = .6, y = .7, corner = c(0, 0)))

Ciao, Tom

_________________________________________________
 
Tom Mulholland
Senior Policy Officer
WA Country Health Service
Tel: (08) 9222 4062
 
The contents of this e-mail transmission are confidential and may be
protected by professional privilege. The contents are intended only for
the named recipients of this e-mail. If you are not the intended
recipient, you are hereby notified that any use, reproduction,
disclosure or distribution of the information contained in this e-mail
is prohibited. Please notify the sender immediately.


-----Original Message-----
From: Mueller, Adrienne [mailto:adrienne.mueller at imperial.ac.uk] 
Sent: Friday, 16 January 2004 3:05 AM
To: R-help at stat.math.ethz.ch
Subject: [R] Lattices: Cloud: Background


Hi,
There's probably some simple way of doing this, but I'm just not seeing
it - How do I get the background to be white instead of grey when I have
a cloud plot (using the lattices package)? par(bg="white") isn't
working. I'm assuming par commands won't work on lattice plots. What
should I use instead?
 
Thanks,
Adrienne

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From deepayan at stat.wisc.edu  Fri Jan 16 08:31:09 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 16 Jan 2004 01:31:09 -0600
Subject: [R] Lattices: Cloud: Background
In-Reply-To: <74E242B6968AA0469B632C5A3EFC1EFD03D57026@nt207mesep.corporate.h
	dwa.health.wa.gov.au>
References: <74E242B6968AA0469B632C5A3EFC1EFD03D57026@nt207mesep.corporate.h
	dwa.health.wa.gov.au>
Message-ID: <200401160131.09382.deepayan@stat.wisc.edu>

On Friday 16 January 2004 00:51, Mulholland, Tom wrote:
> When I first started using lattice I found the colour schemes a bit
> confusing. So eventually I came up with the colours I wanted.
>
> The code below was one of those attempts. One thing that happened
> however was that I kept shutting down the graphics window that pops up
> and the colours would revert to their default. So if you run all of the
> code the first window will pop up correctly the system will pause for 5
> seconds, close the window and run the code again. When the code runs it
> reverts to the grey background.

FYI, if you want to avoid resetting the scheme everytime you open a device, 
you could consider using options("lattice.theme"). The help page for 
trellis.device explains this (clearly enough, I hope). Note that 
trellis.device() is called automatically when needed if a device is not 
already open.

Deepayan



From ligges at statistik.uni-dortmund.de  Fri Jan 16 09:54:43 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jan 2004 09:54:43 +0100
Subject: [R] memory in R
In-Reply-To: <000001c3dbc1$7e620530$268ff78c@acer4jbjp1qwlp>
References: <000001c3dbc1$7e620530$268ff78c@acer4jbjp1qwlp>
Message-ID: <4007A6D3.9070003@statistik.uni-dortmund.de>

Raphael Schoenle wrote:

> Hi,
>  
> How can I assign memory in R? My simulations are very slow.

What do you mean with "assign memory in R"?
You might want to optimize your code...

Uwe Ligges


> Thanks!,
>  
> -R
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From almiro.moreira at ine.pt  Fri Jan 16 09:56:19 2004
From: almiro.moreira at ine.pt (Almiro Moreira)
Date: Fri, 16 Jan 2004 08:56:19 -0000
Subject: [R] =?iso-8859-1?q?Na=EFve_Bayes_?=
Message-ID: <62843B8EA57DD71180C900508BFCA9FB15D4E5@rnpobw01.drn.ine.pt>

I would like to know if there is a function to Na?ve Bayes Classifier in R
Almiro Moreira
DRN/N?cleo de Estat?sticas da Ind?stria
Telf. 226072098
Fax.  226058204



From ligges at statistik.uni-dortmund.de  Fri Jan 16 09:58:40 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jan 2004 09:58:40 +0100
Subject: [R] SIR
In-Reply-To: <4006FEB4.4070809@uni-graz.at>
References: <4006FEB4.4070809@uni-graz.at>
Message-ID: <4007A7C0.6070807@statistik.uni-dortmund.de>

Vera Hofer wrote:

> Ich habe in R eine Version von SIR gefunden und ausprobiert. Leider kann 
> diese multivariate Responses nicht verarbeiten. Gibt es in R eine 
> ausgefeilte Version von SIR?
> Danke f?r die Hilfe.
> V.H.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html


This mailinglist's language is english.
I don't know of any functions in R for Sliced Inverse Regression (SIR), 
not even the one you have already found.

Uwe Ligges



From gregory_r_warnes at groton.pfizer.com  Fri Jan 16 09:54:37 2004
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri, 16 Jan 2004 03:54:37 -0500
Subject: [R] [R-pkgs] FW: Announce: RPy version 0.3.3
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20680AD2B@groexmb02.pfizer.com>



>  -----Original Message-----
> From: 	Warnes, Gregory R  
> Sent:	Friday, January 16, 2004 3:52 AM
> To:	'r-packages'; 'python-announce '; 'rsoap-talk'; 'Dan Nathan'; 'RPy
> List'
> Subject:	Announce: RPy version 0.3.3
> 
> 
> RPy Version 0.3.3 is now available from the RPy home page at
> http://rpy.sf.net.   
> 
> What is RPy?
> --------------------
> 
> RPy is a very simple, yet robust, Python (http://www.python.org) interface
> to the R environment for statistical data analysis and graphics
> (http://www.r-project.org).  RPy can manages translation between python
> and R formats for all kinds of R objects and can execute arbitrary R
> functions (including the graphic functions).  All errors from the R
> language are converted to proper Python exceptions.  All module installed
> on the R system are available from Python.
> 
> Consequently, RPy allows Python programmers to easily add advanced
> statistical functionality to Python programs.  It allows R programmers the
> ability to use Python to control R computations and to interface them with
> other systems.  Examples include RSOAP
> (http://www.analytics.washington.edu/Zope/projects/RSOAP),  RSessionDA
> (http://www.analytics.washington.edu/Zope/projects/RSOAP), and RStatServer
> (http://www.analytics.washington.edu/Zope/projects/RStatServer).   These
> products, which make heavy use of RPy have been used in a production
> environments for two years.
> 
> New features in 0.3.3
> -------------------------------
> 
> o Now works with R 1.8.X
> 
> o Windows version merged into the Unix source tree
> 
> o Added lcall() method for calling R functions using a list of (name,
>   value) pairs for the parameters.  This is works around the python
>   (mis-)feature of using unordered python dictionaries for named
>   parameters, resulting in the loss of order for named parameters.
> 
> o All reported bugs have been fixed.
> 
> o New maintainer: Gregory R. Warnes <gregory_r_warnes at groton.pfizer.com>
> 
> 
> For more information visit the RPy home page at http://rpy.sf.net, or the
> RPy SourceForge project page at http://www.sf.net/projects/rpy.


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From hagric at sbox.tugraz.at  Fri Jan 16 10:04:51 2004
From: hagric at sbox.tugraz.at (hagric)
Date: Fri, 16 Jan 2004 10:04:51 +0100
Subject: [R] SIR
Message-ID: <4007A933.7000901@sbox.TUGraz.at>

I have found a version of SIR in R and I have tried it. But the problem 
with this file is the fact that it does not cope with multivariate 
response variables. Is there any version of SIR available that also 
works with multivariate responses?
Thanks for help!



From ozric at web.de  Fri Jan 16 10:53:16 2004
From: ozric at web.de (christian schulz)
Date: Fri, 16 Jan 2004 10:53:16 +0100
Subject: [R] =?iso-8859-1?q?Na=EFve?= Bayes
In-Reply-To: <62843B8EA57DD71180C900508BFCA9FB15D4E5@rnpobw01.drn.ine.pt>
References: <62843B8EA57DD71180C900508BFCA9FB15D4E5@rnpobw01.drn.ine.pt>
Message-ID: <200401161048.12423.ozric@web.de>

Yes,  look at  library(e1071)
christian

Am Freitag, 16. Januar 2004 09:56 schrieb Almiro Moreira:
> I would like to know if there is a function to Na?ve Bayes Classifier in R
> Almiro Moreira
> DRN/N?cleo de Estat?sticas da Ind?stria
> Telf. 226072098
> Fax.  226058204
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From Pascal.Niklaus at unibas.ch  Fri Jan 16 10:48:06 2004
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Fri, 16 Jan 2004 10:48:06 +0100
Subject: [R] error message in plot(aov-object) -- repost
Message-ID: <4007B356.1060107@unibas.ch>

Hi all,

I posted this question several days ago, but did not get any answer 
until now. Since I still have no clue about the source of this error 
message, I repost a description of the problem including some code:

A student at our institute fitted an aov model, and got the following 
error message:

	> plot(p.aov)
	Hit <Return> to see next plot:
	Hit <Return> to see next plot:
	Error in plot.window(xlim, ylim, log, asp, ...) :
	       need finite ylim values

The second plot was not produced. I then tried to produced the plot
manually, which worked, and checked the range of the residuals:

	> qqnorm(resid(p.aov))
	> range(resid(p.aov))
	[1] -0.2428688  0.2020649

Her data set and the model are as follows:

Data:
  http://www.bot.unibas.ch/~pascal/ParzJan.csv

Model (I don't understand the model, but that's not the issue here)
  p <- read.csv("ParzJan.csv",header=T)
  p.aov <-aov(terms(JI~SP+Ex+Neig+pH+K/G+H+D+tN+br+aN:br+tN:D
    +br:D+aN:br:D+br:tN+aN:br:D + aN:br:tN+ K:D+ K:tN+ K:br
    +K:aN:br+ G:K:D+ G:K:tN+ G:K:br+G:K:aN:br+ D:H+ tN:H+ br:H
    + aN:br:H, keep.order=T), data=p)

Any help regarding the source of this plot() error message is appreciated.

Pascal

P.S.: She used R 1.7.1 on a Mac, but the problem was reproducible on R 
1.8.1 under Linux.



From christoph.lange at tuebingen.mpg.de  Fri Jan 16 12:01:44 2004
From: christoph.lange at tuebingen.mpg.de (Christoph Lange)
Date: Fri, 16 Jan 2004 12:01:44 +0100
Subject: [R] Using dates for plotting
Message-ID: <20040116110143.GA15498@sesame.kyb.local>


Dear R-Users!

I have the following data:

> runs
dates kms
1 2004-01-15 12:00:00   9
2 2004-01-16 12:00:00  10
3 2004-01-17 12:00:00   5
> class(runs$dates)
[1] "POSIXt"  "POSIXct"
> 

Is it possible to _easily_ plot these data with real dates shown as
tick marks on the x-axis? Perhaps even when the days are not
continuous but with missing days in between?

Thanks in advance,

  Christoph.

-- 
Christoph Lange
MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|



From sdavis2 at mail.nih.gov  Fri Jan 16 12:38:47 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 16 Jan 2004 06:38:47 -0500
Subject: [R] Multiple comparisons in R;  multicomp
In-Reply-To: <005301c3dbb3$77fbde90$53bc3151@PC728329681112>
Message-ID: <BC2D3777.36B2%sdavis2@mail.nih.gov>

Patrick

I'm not familiar with the multcomp package from s-plus, but there is a
package available through bioconductor (www.bioconductor.org) called
multtest that has some functions for multiple testing procedures and
adjusting p-values and computing false discovery rates.

Sean
-- 
Sean Davis, M.D., Ph.D.

Clinical Fellow
National Institutes of Health
National Cancer Institute
National Human Genome Research Institute

Clinical Fellow, Johns Hopkins
Department of Pediatric Oncology
-- 



On 1/15/04 5:03 PM, "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
wrote:

> Is there a fonction for multiple comparison tests (similar to "multicomp" in
> Splus) in a package of R?
> 
> Thanks in advance for any hint...
> 
> Cheers, 
> 
> Patrick Giraudoux
> 
> 
> University of Franche-Comte
> Department of Environmental Biology
> EA3184 af. INRA
> F-25030 Besancon Cedex
> 
> tel.: +33 381 665 745
> fax.: +33 381 665 797
> http://lbe.univ-fcomte.fr
> 
> 
> 
> [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Fri Jan 16 12:40:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Jan 2004 11:40:55 +0000 (GMT)
Subject: [R] Using dates for plotting
In-Reply-To: <20040116110143.GA15498@sesame.kyb.local>
Message-ID: <Pine.LNX.4.44.0401161139060.29707-100000@gannet.stats>

On Fri, 16 Jan 2004, Christoph Lange wrote:

> 
> Dear R-Users!
> 
> I have the following data:
> 
> > runs
> dates kms
> 1 2004-01-15 12:00:00   9
> 2 2004-01-16 12:00:00  10
> 3 2004-01-17 12:00:00   5
> > class(runs$dates)
> [1] "POSIXt"  "POSIXct"
> > 
> 
> Is it possible to _easily_ plot these data with real dates shown as
> tick marks on the x-axis? Perhaps even when the days are not
> continuous but with missing days in between?

Yes.  ?plot.POSIXct has examples like

     plot(.leap.seconds, 1:22, type="n", yaxt="n",
          xlab="leap seconds", ylab="", bty="n")
     rug(.leap.seconds)

What could be easier?  If you want only the data dates labelled, use
axis.POSIXct.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From marwan.khawaja at aub.edu.lb  Thu Jan 15 19:50:37 2004
From: marwan.khawaja at aub.edu.lb (Marwan Khawaja)
Date: Thu, 15 Jan 2004 13:50:37 -0500
Subject: [R] plot
Message-ID: <CLECJBOEBGOMOKJHJNDAIENIDIAA.marwan.khawaja@aub.edu.lb>

Dear All,
I'd like to 'highlight' say change font size/color 'some' point in a graph.  I
can do this with 'points',

plot(x)
points(x[1], col="red")

Is there a more 'straightforward' way (e.g., option in plot) to do this?
Thanks Marwan


-------------------------------------------------------------------
Marwan Khawaja         http://departments.aub.edu.lb/~mk36



From petr.pikal at precheza.cz  Fri Jan 16 12:57:25 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 16 Jan 2004 12:57:25 +0100
Subject: [R] Using dates for plotting
In-Reply-To: <20040116110143.GA15498@sesame.kyb.local>
Message-ID: <4007DFB5.27124.ED4E1F@localhost>

Hi

On 16 Jan 2004 at 12:01, Christoph Lange wrote:

> 
> Dear R-Users!
> 
> I have the following data:
> 
> > runs
> dates kms
> 1 2004-01-15 12:00:00   9
> 2 2004-01-16 12:00:00  10
> 3 2004-01-17 12:00:00   5
> > class(runs$dates)
> [1] "POSIXt"  "POSIXct"
> > 
> 
> Is it possible to _easily_ plot these data with real dates shown as
> tick marks on the x-axis? Perhaps even when the days are not
> continuous but with missing days in between?

plot(dates,kms)

should work, but you need to do some formating (maybe with 
axes=F and axis())

see ?strptime

and to convert your dates to POSIXct gformat
					 ^^
Beware "dates" is a function name in library chron.

HTH Petr

> 
> Thanks in advance,
> 
>   Christoph.
> 
> -- 
> Christoph Lange
> MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
> Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ligges at statistik.uni-dortmund.de  Fri Jan 16 13:00:53 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jan 2004 13:00:53 +0100
Subject: [R] plot
In-Reply-To: <CLECJBOEBGOMOKJHJNDAIENIDIAA.marwan.khawaja@aub.edu.lb>
References: <CLECJBOEBGOMOKJHJNDAIENIDIAA.marwan.khawaja@aub.edu.lb>
Message-ID: <4007D275.40706@statistik.uni-dortmund.de>

Marwan Khawaja wrote:

> Dear All,
> I'd like to 'highlight' say change font size/color 'some' point in a graph.  I
> can do this with 'points',
> 
> plot(x)
> points(x[1], col="red")
> 
> Is there a more 'straightforward' way (e.g., option in plot) to do this?
> Thanks Marwan


plot(x, col = colorvector)
???

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Fri Jan 16 13:11:05 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 16 Jan 2004 13:11:05 +0100
Subject: [R] error message in plot(aov-object) -- repost
In-Reply-To: <4007B356.1060107@unibas.ch>
References: <4007B356.1060107@unibas.ch>
Message-ID: <4007D4D9.1040602@statistik.uni-dortmund.de>

Pascal A. Niklaus wrote:

> Hi all,
> 
> I posted this question several days ago, but did not get any answer 
> until now. Since I still have no clue about the source of this error 
> message, I repost a description of the problem including some code:
> 
> A student at our institute fitted an aov model, and got the following 
> error message:
> 
>     > plot(p.aov)
>     Hit <Return> to see next plot:
>     Hit <Return> to see next plot:
>     Error in plot.window(xlim, ylim, log, asp, ...) :
>            need finite ylim values
> 
> The second plot was not produced. I then tried to produced the plot
> manually, which worked, and checked the range of the residuals:
> 
>     > qqnorm(resid(p.aov))
>     > range(resid(p.aov))
>     [1] -0.2428688  0.2020649
> 
> Her data set and the model are as follows:
> 
> Data:
>  http://www.bot.unibas.ch/~pascal/ParzJan.csv
> 
> Model (I don't understand the model, but that's not the issue here)
>  p <- read.csv("ParzJan.csv",header=T)
>  p.aov <-aov(terms(JI~SP+Ex+Neig+pH+K/G+H+D+tN+br+aN:br+tN:D
>    +br:D+aN:br:D+br:tN+aN:br:D + aN:br:tN+ K:D+ K:tN+ K:br
>    +K:aN:br+ G:K:D+ G:K:tN+ G:K:br+G:K:aN:br+ D:H+ tN:H+ br:H
>    + aN:br:H, keep.order=T), data=p)
> 
> Any help regarding the source of this plot() error message is appreciated.

Without the data nobody was able to reproduce your problem ..


plot.lm() produces the error message, in particular the lines

    hii <- lm.influence(x, do.coef = FALSE)$hat

which appears to be 1 in some cases, and

    rs <- r.w/(s * sqrt(1 - hii))

(you get a division by zero and the outcome is Inf, hence it's not 
possible to scale the plot any more).


I'd call it a bug, but I don't know what the bug really is. I'll think 
about it...


Uwe Ligges






> Pascal
> 
> P.S.: She used R 1.7.1 on a Mac, but the problem was reproducible on R 
> 1.8.1 under Linux.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Fri Jan 16 13:29:36 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Jan 2004 13:29:36 +0100
Subject: [R] error message in plot(aov-object) -- repost
In-Reply-To: <4007D4D9.1040602@statistik.uni-dortmund.de>
References: <4007B356.1060107@unibas.ch>
	<4007D4D9.1040602@statistik.uni-dortmund.de>
Message-ID: <x2eku0m5zj.fsf@biostat.ku.dk>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

> plot.lm() produces the error message, in particular the lines
> 
>     hii <- lm.influence(x, do.coef = FALSE)$hat
> 
> which appears to be 1 in some cases, and
> 
>     rs <- r.w/(s * sqrt(1 - hii))
> 
> (you get a division by zero and the outcome is Inf, hence it's not
> possible to scale the plot any more).
> 
> 
> I'd call it a bug, but I don't know what the bug really is. I'll think
> about it...

If the $hat is 1, then the residual is theoretically zero and you
should get 0/0 == NA which would be much less trouble. 

Apparently, floating poing arithmetic makes it not quite so and you
get Inf in some cases. I'd expect that rs[hii==1] <- NA would fix
things up, although you might possibly need a fuzz factor (hii >
1-1e-10 or so).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From giampi at speech.kth.se  Fri Jan 16 14:22:10 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Fri, 16 Jan 2004 14:22:10 +0100 (CET)
Subject: [R] reference to objects
Message-ID: <Pine.LNX.4.58.0401161344050.2592@bayes.speech.kth.se>

Hi,
is there a way to reference to a data object without copying it?

For example I have a huge matrix called dist and I want two objects
obj1 and obj2 to have a memeber dist that points to the matrix, but
I don't want, for memory reasons, to copy the matrix twice.

As far as I understand the following code will generate three copies
of my data:

dist <- some_code_that_generates_data
obj1$dist <- dist
obj2$dist <- dist

Thank you!
Giampiero



From maechler at stat.math.ethz.ch  Fri Jan 16 14:27:03 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 16 Jan 2004 14:27:03 +0100
Subject: [R] Exactness of ppois
In-Reply-To: <40069BCA.60109@uni-bayreuth.de>
References: <40069BCA.60109@uni-bayreuth.de>
Message-ID: <16391.59047.650874.65973@gargle.gargle.HOWL>

>>>>> "Matthias" == Matthias Kohl <Matthias.Kohl at uni-bayreuth.de>
>>>>>     on Thu, 15 Jan 2004 13:55:22 +0000 writes:

    Matthias> Hello, by checking the precision of a convolution
    Matthias> algorithm, we found the following "inexactness":
    Matthias> We work with R Version 1.8.1 (2003-11-21) on
    Matthias> Windows systems (NT, 2000, XP).

    Matthias> Try the code:

    Matthias> So for lambda=977.8 and x=1001 we get a distance
    Matthias> of about 5.2e-06.  (This inexactness seems to hold
    Matthias> for all lambda values greater than about 900.)

    Matthias> BUT, summing about 1000 terms of exactness around 1e-16,
    Matthias> we would expect an error of order 1e-13.

    Matthias> We suspect algorithm AS 239 to cause that flaw.

correct.   Namely, because

 ppois(x, lambda, lower_tail, log_p) :=  
    pgamma(lambda, x + 1, 1., !lower_tail, log_p)

and pgamma(x, alph, scale) uses AS 239, currently. 
So this thread is really about the precision of R's current pgamma().

In your example, (x = 977.8, alph = 1002, scale=1) and 
in pgamma.c,
    alphlimit = 1000;
and later

    /* use a normal approximation if alph > alphlimit */
    if (alph > alphlimit) {
	pn1 = sqrt(alph) * 3. * (pow(x/alph, 1./3.) + 1. / (9. * alph) - 1.);
	return pnorm(pn1, 0., 1., lower_tail, log_p);
    }

So, we could conceivably 
improve the situation by increasing `alphlimit'.
Though, I don't see a real need for this (and it will cost CPU
cycles in these cases).

    Matthias> Do you think this could cause other problems apart
    Matthias> from that admittedly extreme example?

no, I don't think.  Look at

  > lam <- 977.8
  > (p1 <- ppois(1001, lam))
  [1] 0.77643705
  > (p2 <- sum(dpois(0:1001, lam)))
  [1] 0.77643187

Can you imagine a situation where this difference matters?

    Matthias> Thanks for your attention!
You're welcome.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From bruno at speech.kth.se  Fri Jan 16 14:29:40 2004
From: bruno at speech.kth.se (Bruno Giordano)
Date: Fri, 16 Jan 2004 14:29:40 +0100
Subject: [R] individual likelihoods
Message-ID: <008501c3dc34$cc9765b0$b943ed82@brungio>

Dear all,
is there a way to extract individual likelihoods from a glm/lrm object?
By individual likelihoods, I mean the likelihoods whose product give the
overall likelihood of the model.
I guess the code in the base package, used to compute the Akaike Information
Criterion may help me.
However, I couldn't figure it out, probably because I'm rather new to
likelihood theory and ML estimation ;-)
Thanks for any help/suggestion/tip,
    Bruno



From andy_liaw at merck.com  Fri Jan 16 14:37:23 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 16 Jan 2004 08:37:23 -0500
Subject: [R] SIR
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7634@usrymx25.merck.com>

SIR and other dimension reduction methods are available in the "dr" package
on CRAN.  (No idea if that's what Vera was referring to.)  From a quick
glance, I don't think it handles multivariate responses.

Cheers,
Andy

> From: Uwe Ligges
> 
> Vera Hofer wrote:
> 
> > Ich habe in R eine Version von SIR gefunden und 
> ausprobiert. Leider kann 
> > diese multivariate Responses nicht verarbeiten. Gibt es in R eine 
> > ausgefeilte Version von SIR?
> > Danke f?r die Hilfe.
> > V.H.
> > 
> 
> This mailinglist's language is english.
> I don't know of any functions in R for Sliced Inverse 
> Regression (SIR), 
> not even the one you have already found.
> 
> Uwe Ligges


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From lecoutre at stat.ucl.ac.be  Fri Jan 16 14:53:25 2004
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Fri, 16 Jan 2004 14:53:25 +0100
Subject: [R] reference to objects
In-Reply-To: <Pine.LNX.4.58.0401161344050.2592@bayes.speech.kth.se>
References: <Pine.LNX.4.58.0401161344050.2592@bayes.speech.kth.se>
Message-ID: <6.0.1.1.2.20040116145120.0217fe18@stat4ux.stat.ucl.ac.be>


Hi,

You will find some pieces of information about the way to handle such 
things at:
http://www.maths.lth.se/help/R/
Programming with references

Note that you will have to download and install the package developped by 
the author, Henrik Bengtsson

HTH,

Eric


At 14:22 16/01/2004, Giampiero Salvi wrote:
>Hi,
>is there a way to reference to a data object without copying it?
>
>For example I have a huge matrix called dist and I want two objects
>obj1 and obj2 to have a memeber dist that points to the matrix, but
>I don't want, for memory reasons, to copy the matrix twice.
>
>As far as I understand the following code will generate three copies
>of my data:
>
>dist <- some_code_that_generates_data
>obj1$dist <- dist
>obj2$dist <- dist
>
>Thank you!
>Giampiero



--------------------------------------------------
L'erreur est certes humaine, mais un vrai d?sastre
n?cessite un ou deux ordinateurs. Citation anonyme
--------------------------------------------------
Eric Lecoutre
Informaticien/Statisticien
Institut de Statistique / UCL

TEL (+32)(0)10473050       lecoutre at stat.ucl.ac.be
URL http://www.stat.ucl.ac.be/ISpersonnel/lecoutre



From giampi at speech.kth.se  Fri Jan 16 14:54:57 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Fri, 16 Jan 2004 14:54:57 +0100 (CET)
Subject: [R] reference to objects
Message-ID: <Pine.LNX.4.58.0401161453580.2592@bayes.speech.kth.se>

Thanks for your answer,

> Yes, that will create two copies.  What is it you want to do with the data?
> Do you want the capability of both of them changing the data?  What type of
> processing are you going to do?

The data should be read only (and all the objects share the same data values).

> One way is to store the 'name' of the object in the location and then use
> 'get/assign' to reference the data:
>
> obj1$dist <- 'dist'
> obj2$dist <- 'dist'
>
> my.sum <- sum(get(obj1$data))
> assign(obj1$data, new.values)

The problem with this solution is that I would like to use those objects with
already existing libraries, and thus I cannot choose how the data is read.
To explain better, I look for a way to reference to the data that is transparent
to the application.

In C this would be done by assigning the pointer to the data structure, for example
if dist is a C structure and obj1/2 contain a pointer called dist to that kind of
structure, I would do:

obj1->dist = &dist;
obj2->dist = &dist;

and then the rest of the code would not even know if obj1->dist is shared among different
objects....

Thanks again,
Giampiero

>
>
> __________________________________________________________
> James Holtman        "What is the problem you are trying to solve?"
> Executive Consultant  --  Office of Technology, Convergys
> james.holtman at convergys.com
> +1 (513) 723-2929
>
>
>
>                       Giampiero Salvi
>                       <giampi at speech.kth.se        To:       r-help at stat.math.ethz.ch
>                       >                            cc:
>                       Sent by:                     Subject:  [R] reference to objects
>                       r-help-bounces at stat.m
>                       ath.ethz.ch
>
>
>                       01/16/2004 08:22
>
>
>
>
>
>
> Hi,
> is there a way to reference to a data object without copying it?
>
> For example I have a huge matrix called dist and I want two objects
> obj1 and obj2 to have a memeber dist that points to the matrix, but
> I don't want, for memory reasons, to copy the matrix twice.
>
> As far as I understand the following code will generate three copies
> of my data:
>
> dist <- some_code_that_generates_data
> obj1$dist <- dist
> obj2$dist <- dist
>
> Thank you!
> Giampiero
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>
>
>
> --
> "NOTICE:  The information contained in this electronic mail transmission is
> intended by Convergys Corporation for the use of the named individual or
> entity to which it is directed and may contain information that is
> privileged or otherwise confidential.  If you have received this electronic
> mail transmission in error, please delete it from your system without
> copying or forwarding it, and notify the sender of the error by reply email
> or by telephone (collect), so that the sender's address records can be
> corrected."
>
>
>



From bates at stat.wisc.edu  Fri Jan 16 14:56:30 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 Jan 2004 07:56:30 -0600
Subject: [R] random effects with lme() -- comparison with lm()
In-Reply-To: <1074216037.5854.145.camel@penguin>
References: <1074210463.5854.123.camel@penguin>
	<6r8yk8d9a9.fsf@bates4.stat.wisc.edu>
	<1074216037.5854.145.camel@penguin>
Message-ID: <6rn08ot2sx.fsf@bates4.stat.wisc.edu>

Jerome Asselin <jerome at hivnet.ubc.ca> writes:

> On Thu, 2004-01-15 at 16:30, Douglas Bates wrote:
> <...snip...>
> > (BTW, I wouldn't say that this is equivalent to a fixed effects
> > model.  It is still a random effects model with two variance
> > components.  It just doesn't have well-defined estimates for those two
> > variance components.)
> 
> Agreed.
> 
> <...snip...>
> > You should find that intervals() applied to your fitted model produces
> > huge intervals on the variance components, which is one way of
> > diagnosing an ill-defined or nearly ill-defined model.
> 
> Following your suggestion, I got:
> > intervals(lme(Y~1,data=simdat,random=~1|A))
> Error in intervals.lme(lme(Y ~ 1, data = simdat, random = ~1 | A)) :
>         Cannot get confidence intervals on var-cov components:
> Non-positive definite approximate variance-covariance
> 
> This led me to:
> > lme(Y~1,data=simdat,random=~1|A)$apVar
> [1] "Non-positive definite approximate variance-covariance"
> 
> As a new feature suggestion for lme(), would it be appropriate to use
> "apVar" as a warning flag in this case?

Certainly.

You may know that we are doing a major revision of the lme
computational methods based on the ability to calculate both the
gradient and the Hessian of the profiled log-likelihood, as described
in
        http://www.stat.wisc.edu/~bates/reports/MixedComp.pdf

I think that when we have both the gradient and the Hessian we will be
in a much better situation to diagnose ill-defined estimates.  The
apVar component in the current lme objects is an approximate
variance-covariance matrix from numerical derivatives.  Working with
an exact Hessian should be much more reliable.



From spencer.graves at pdf.com  Fri Jan 16 15:05:45 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 16 Jan 2004 06:05:45 -0800
Subject: [R] memory in R
In-Reply-To: <4007A6D3.9070003@statistik.uni-dortmund.de>
References: <000001c3dbc1$7e620530$268ff78c@acer4jbjp1qwlp>
	<4007A6D3.9070003@statistik.uni-dortmund.de>
Message-ID: <4007EFB9.9010707@pdf.com>

To expand a bit on Uwe's comments:  R is vectorized and loops are 
notoriously inefficient.  Consider the following: 

start.time <- proc.time()
set.seed(1)
X <- array(rnorm(1000), dim=c(100, 10))
X.1 <- apply(X, 2, mean)
print(var(X.1))
(elapsed.time <- proc.time()-start.time)

start.ttime <- proc.time()
set.seed(1)
X <- array(NA, dim=c(100, 10))
for(j in 1:10)for(i in 1:100)X[i,j] <- rnorm(1)
X. <- rep(0, 10)
X.. <- 0
varX <- 0
for(j in 1:10){
    for(i in 1:100)
        (X.[j] <- X.[j]+X[i,j])
    X.[j] <- X.[j]/100   
    X.. <- X..+X.[j]
    varX <- varX+X.[j]^2
}
X.. <- X../10
varX <- (varX-10*X..^2)/9
print(varX)
(elapsed.time2 <- proc.time()-start.time)

elapsed.time
elapsed.time2

# In R 1.8.1: 
 > elapsed.time
[1] 0.00 0.00 0.54   NA   NA
 > elapsed.time2
[1] 0.05 0.00 1.73   NA   NA
 >
# In S-_lus 8.2: 
 > elapsed.time
[1] 0.04 0.00 0.05 0.00 0.00
 > elapsed.time2
[1] 0.37 0.06 0.44 0.00 0.00

      hope this helps.  spencer graves

Uwe Ligges wrote:

> Raphael Schoenle wrote:
>
>> Hi,
>>  
>> How can I assign memory in R? My simulations are very slow.
>
>
> What do you mean with "assign memory in R"?
> You might want to optimize your code...
>
> Uwe Ligges
>
>
>> Thanks!,
>>  
>> -R
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From giampi at speech.kth.se  Fri Jan 16 15:03:19 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Fri, 16 Jan 2004 15:03:19 +0100 (CET)
Subject: [R] reference to objects
In-Reply-To: <6.0.1.1.2.20040116145120.0217fe18@stat4ux.stat.ucl.ac.be>
References: <Pine.LNX.4.58.0401161344050.2592@bayes.speech.kth.se>
	<6.0.1.1.2.20040116145120.0217fe18@stat4ux.stat.ucl.ac.be>
Message-ID: <Pine.LNX.4.58.0401161502460.2592@bayes.speech.kth.se>

Thank you,
I'll read the documentation...

Giampiero

On Fri, 16 Jan 2004, Eric Lecoutre wrote:

>
> Hi,
>
> You will find some pieces of information about the way to handle such
> things at:
> http://www.maths.lth.se/help/R/
> Programming with references
>
> Note that you will have to download and install the package developped by
> the author, Henrik Bengtsson
>
> HTH,
>
> Eric
>
>
> At 14:22 16/01/2004, Giampiero Salvi wrote:
> >Hi,
> >is there a way to reference to a data object without copying it?
> >
> >For example I have a huge matrix called dist and I want two objects
> >obj1 and obj2 to have a memeber dist that points to the matrix, but
> >I don't want, for memory reasons, to copy the matrix twice.
> >
> >As far as I understand the following code will generate three copies
> >of my data:
> >
> >dist <- some_code_that_generates_data
> >obj1$dist <- dist
> >obj2$dist <- dist
> >
> >Thank you!
> >Giampiero
>
>
>
> --------------------------------------------------
> L'erreur est certes humaine, mais un vrai dsastre
> ncessite un ou deux ordinateurs. Citation anonyme
> --------------------------------------------------
> Eric Lecoutre
> Informaticien/Statisticien
> Institut de Statistique / UCL
>
> TEL (+32)(0)10473050       lecoutre at stat.ucl.ac.be
> URL http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
> --------------------------------------------------
>
>



From jfox at mcmaster.ca  Fri Jan 16 16:02:59 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 16 Jan 2004 10:02:59 -0500
Subject: [R] individual likelihoods
In-Reply-To: <008501c3dc34$cc9765b0$b943ed82@brungio>
Message-ID: <5.1.0.14.2.20040116095623.02043c88@127.0.0.1>

Dear Bruno,

residuals(mod, type="deviance") gives you the deviance residuals for the 
model, so sum(residuals(mod, type="deviance")^2) is the deviance.

I hope that this helps,
  John

At 02:29 PM 1/16/2004 +0100, Bruno Giordano wrote:
>Dear all,
>is there a way to extract individual likelihoods from a glm/lrm object?
>By individual likelihoods, I mean the likelihoods whose product give the
>overall likelihood of the model.
>I guess the code in the base package, used to compute the Akaike Information
>Criterion may help me.
>However, I couldn't figure it out, probably because I'm rather new to
>likelihood theory and ML estimation ;-)
>Thanks for any help/suggestion/tip,
>     Bruno

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From Timur.Elzhov at jinr.ru  Fri Jan 16 16:18:54 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri, 16 Jan 2004 18:18:54 +0300
Subject: [R] analytic derivative of complex function
Message-ID: <20040116151854.GA24289@nf034.jinr.ru>

Dear R experts,

I'd like to take analytic derivative of complex functions through "D"
function. I succeded with simple functions like "sin(x)", but what if
I want to work with function like A(x,y, ...) + i*B(x,y, ...)?

Thank you.

--
WBR,
Timur.



From laura at env.leeds.ac.uk  Fri Jan 16 17:02:17 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Fri, 16 Jan 2004 16:02:17 +0000 (GMT)
Subject: [R] Saving jpg of plot with grid.arrows
Message-ID: <Pine.LNX.4.44.0401161600050.545-100000@env-pc-phd13>

I am having problems exporting a plot to a jpg file. I am first setting up
a basic plot, and then opening up a viewport and overlaying grid.arrows
onto the plot - I don't seem able to save this plot with the overlaid
arrows to a file, can anyone offer any advice?

I am using R-1.8.0 on Debian Linux.

Thank you in advance,
Laura



From tlumley at u.washington.edu  Fri Jan 16 17:09:57 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 16 Jan 2004 08:09:57 -0800 (PST)
Subject: [R] reference to objects
In-Reply-To: <Pine.LNX.4.58.0401161453580.2592@bayes.speech.kth.se>
References: <Pine.LNX.4.58.0401161453580.2592@bayes.speech.kth.se>
Message-ID: <Pine.A41.4.58.0401160801270.39266@homer06.u.washington.edu>

On Fri, 16 Jan 2004, Giampiero Salvi wrote (in reply to some unidentified
helper):

> Thanks for your answer,
>
> > Yes, that will create two copies.  What is it you want to do with the data?
> > Do you want the capability of both of them changing the data?  What type of
> > processing are you going to do?
>
> The data should be read only (and all the objects share the same data values).

If the data are read only it is likely that R will *not* create two
copies, eg try
  a<-list(x=rnorm(1e6))
  gc()
  b<-a$x
  d<-a$x
  gc()
  b<-b+1
  d<-d+1
  gc()

>
> > One way is to store the 'name' of the object in the location and then use
> > 'get/assign' to reference the data:
> >
> > obj1$dist <- 'dist'
> > obj2$dist <- 'dist'
> >
> > my.sum <- sum(get(obj1$data))
> > assign(obj1$data, new.values)
>

This won't work any better.  get(obj1$data) will get the object, and
there's no reason to expect that it's less likely to get a copy than
simple assignment is.

	-thomas



From tbg97 at albany.edu  Fri Jan 16 17:28:30 2004
From: tbg97 at albany.edu (Timothy Gage)
Date: Fri, 16 Jan 2004 11:28:30 -0500
Subject: [R] Nlm
Message-ID: <BC2D7B5E.3D43%tbg97@albany.edu>

Hi

I use both R and Splus to fit miximum likelihood models.  In general these
are Gaussian mixture models of various kinds.

The ms (in Splus) and nlm (in R) generally provide us with the same results
However nlm is not nearly as stable and reliable with respect to finding the
min of a surface.  Nlm on the other hand is faster.  We have played with the
various tol controls but have been unable to increase reliability.  Do you
Have any suggestions?

Thanks

Tim Gage
Professor Anthropology and Epidemiology
University at Albany
Albany NY.

tbg97 at albany.edu



From rdiaz at cnio.es  Fri Jan 16 17:02:22 2004
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Fri, 16 Jan 2004 17:02:22 +0100
Subject: [R] SIR
In-Reply-To: <4007A933.7000901@sbox.TUGraz.at>
References: <4007A933.7000901@sbox.TUGraz.at>
Message-ID: <200401161702.22672.rdiaz@cnio.es>

This is strange; the sir for R I know (in package dr on CRAN, from S. 
Weisberg), last time I checked (about a year ago?) was able to handle 
multivariate responses. In fact, p. 6 of the documentation shows an example 
of SIR with a bivariate response, and I tried it, and it works.

Best,

R.

On Friday 16 January 2004 10:04, hagric wrote:
> I have found a version of SIR in R and I have tried it. But the problem
> with this file is the fact that it does not cope with multivariate
> response variables. Is there any version of SIR available that also
> works with multivariate responses?
> Thanks for help!
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz
PGP KeyID: 0xE89B3462
(http://bioinfo.cnio.es/~rdiaz/0xE89B3462.asc)



From sfalcon at fhcrc.org  Fri Jan 16 18:06:21 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 16 Jan 2004 09:06:21 -0800
Subject: [R] invoking R scripts from a linux shell ?
In-Reply-To: <20040115230211.47800.qmail@web10605.mail.yahoo.com>
References: <20040115230211.47800.qmail@web10605.mail.yahoo.com>
Message-ID: <20040116170621.GA24903@queenbee.fhcrc.org>

Hi Enrico,

As seen by other posts, there are many ways to accomplish this sort of
thing.  For simple tasks I've often found it easiest to call R from my
script (in my case Python).  I've not used BATCH mode and instead
call R like this:

    R --slave --no-save < script.R

A common setup for me is to have a functions.R file with routines I want
to use and then to generate a small R script from within Python that
sources functions.R and calls the functions with the proper variables as
determined by the script.

HTH,

+ seth



From B.Rowlingson at lancaster.ac.uk  Fri Jan 16 18:03:49 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 16 Jan 2004 17:03:49 +0000
Subject: [R] Saving jpg of plot with grid.arrows
In-Reply-To: <Pine.LNX.4.44.0401161600050.545-100000@env-pc-phd13>
References: <Pine.LNX.4.44.0401161600050.545-100000@env-pc-phd13>
Message-ID: <40081975.6060706@lancaster.ac.uk>

Laura Quinn wrote:
> I am having problems exporting a plot to a jpg file. I am first setting up
> a basic plot, and then opening up a viewport and overlaying grid.arrows
> onto the plot - I don't seem able to save this plot with the overlaid
> arrows to a file, can anyone offer any advice?

  Have you got a minimal example of the code that produces this problem? 
Sounds like about six lines tops, so shouldn't exactly flood the mailing 
list...

Baz



From Robert.Espesser at lpl.univ-aix.fr  Fri Jan 16 18:12:22 2004
From: Robert.Espesser at lpl.univ-aix.fr (Robert Espesser)
Date: Fri, 16 Jan 2004 18:12:22 +0100
Subject: [R] anova repeated measure interpretation
Message-ID: <40081B76.6060404@lpl.univ-aix.fr>

Dear all,

I have tried to use R for the repeated measures
experiment design in a phonetic study, and in the
resulting forms I met some problems which perturb the
final interpretation of the results.

I will explain the experiment design first:
the same 7 subjects were answering a question about 25
linguistic stimuli; the stimuli were the same
utterances which were processed in 3 different
ways (3 conditions), ie each subject listened 25*3 stimuli.
I would like to test the
effect of condition and of the stimulus on the
subjects' performance.
My dependent variable is Nboundaries .
I think there is:
one random effect :subject .
2 within-subject fixed effects: stimulus(25 levels)
  and condition (3 levels) .
Following the explanations of J. Baron,
(Notes onthe use of R  for psychology...),
I have run:


 > boundaries.mod<- aov (Nboundaries ~

condition*stimulus +Error(sujet/(condition+stimulus)))

 > summary (boundaries.mod)


Error: sujet
           Df  Sum Sq Mean Sq F value Pr(>F)
condition  1  0.0044  0.0044  0.0011 0.9743
Residuals  5 19.1133  3.8227

Error: sujet:condition
           Df  Sum Sq Mean Sq F value  Pr(>F)
condition  2  6.3134  3.1567  1.7119 0.22528
stimulus   1 11.5549 11.5549  6.2663 0.02934 *  (???)
Residuals 11 20.2838  1.8440
---

Error: sujet:stimulus
                     Df  Sum Sq Mean Sq F value Pr(>F)

stimulus            24 290.522  12.105 20.3986 <2e-16 ***
condition:stimulus   1   0.065   0.065  0.1101 0.7405    (???)
Residuals          143  84.860   0.593

---

Error: Within
                     Df  Sum Sq Mean Sq F value
Pr(>F)
condition:stimulus  48  40.984   0.854  1.9854 0.0003245 ***
Residuals          287 123.429   0.430




I understand that after removing the effect due to individual subject, 
the factor condition has no effect (F: 1.7119).
and that the factor stimulus has a strong  effect (F:20.3986).

But what are the  additional lines
(I have inserted the question marks at the end of these lines),
which are not present in the examples  found in the
litterature (Baron, puzzle example) ?
They seem to appear when the both involved  factors have more than 2 levels.
Consequently, I am not sure
about the rightness and the interpretation of this model.

I will really appreciate your help.


-- 
Robert Espesser
Laboratoire Parole et Langage  UMR 6057, CNRS
29 Av. Robert Schuman  13621 AIX    (FRANCE)
Tel: +33 (0)4 42 95 36 26   Fax: +33 (0)4 42 59 50 96
http://www.lpl.univ-aix.fr/~espesser
mailto:Robert.Espesser at lpl.univ-aix.fr



From friendly at yorku.ca  Fri Jan 16 18:42:26 2004
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 16 Jan 2004 12:42:26 -0500
Subject: [R] how to overlap plots
Message-ID: <40082282.9040203@yorku.ca>

Try the distplot() function in package vcd.

-Michael

-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From deepayan at stat.wisc.edu  Fri Jan 16 19:56:14 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 16 Jan 2004 12:56:14 -0600
Subject: [R] Saving jpg of plot with grid.arrows
In-Reply-To: <Pine.LNX.4.44.0401161600050.545-100000@env-pc-phd13>
References: <Pine.LNX.4.44.0401161600050.545-100000@env-pc-phd13>
Message-ID: <200401161256.14383.deepayan@stat.wisc.edu>

On Friday 16 January 2004 10:02, Laura Quinn wrote:
> I am having problems exporting a plot to a jpg file. I am first setting up
> a basic plot, and then opening up a viewport and overlaying grid.arrows
> onto the plot - I don't seem able to save this plot with the overlaid
> arrows to a file, can anyone offer any advice?
>
> I am using R-1.8.0 on Debian Linux.

Could you give us some specific code that doesn't work ? The simplest case

> jpeg()
> grid.arrows()
> dev.off()

seems to work for me.

Deepayan



From Gerald.Jean at spgdag.ca  Fri Jan 16 20:16:14 2004
From: Gerald.Jean at spgdag.ca (Gerald.Jean@spgdag.ca)
Date: Fri, 16 Jan 2004 14:16:14 -0500
Subject: [R] Summary: Installing the Rcmdr and tcltk
Message-ID: <OF28C4D15A.B83DB425-ON85256E1D.0067A0C6@spgdag.ca>

Hello R-users,

thanks to Brian Ripley, who guided me through this process, the "tcltk"
package is now working and hence the "Rcmdr" package as well.

The secrets were to first rebuild the Tcl and Tk packages from the sources
files, making sure the same C compiler was used as the one used in
subsequent steps to build R and enabling 64bit support.  Prof.  Ripley
reported getting warnings, regarding 64bit support, when using the gcc
compiler.

configure: warning: 64bit mode not supported with GCC on SunOS-5.8
configure: warning: 64bit support being disabled -- don't know magic for
this platform

I used the Forte cc compiler and didn't get these warnings.

I wanted a 64bit built of R under Solaris 8 and setted the compilation
flags as specified in the "R Installation and Admin." manual. Then it was
just a matter of running configure with the "--with-tcl-config=" and "
--with-tk-config=" options pointing to the files "tclConfig.sh" and
"tkConfig.sh" respectively.

Once R built successfully installing the "Rcmdr" and it's required
libraries was a piece of cake.

I still have to learn R, particularly how it is different from Splus, which
I have been using for years.

Thanks again to all who helped and a special thank you to Brian Ripley,

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming



From buter at cwts.leidenuniv.nl  Fri Jan 16 20:36:30 2004
From: buter at cwts.leidenuniv.nl (Renald Buter)
Date: Fri, 16 Jan 2004 20:36:30 +0100
Subject: [R] Sparse matrix row/column access (SparseM)?
Message-ID: <20040116193630.GA21364@infinite.fsw.leidenuniv.nl>

Hello list,

I am creating sparse matrices using the SparseM package. These sparse
structures are to be used as a basis for (a number of) distance
matrices. But in order to create thoses, I must be able to read the
elements/rows/columns of the sparse structures in order to operate on
them.

Thus, how to go from sparse matrix to (sparse) rows, columns? Must I
create the functions myself or am I not reading the obvious in the
documentation?

Thanks in advance,

Renald



From roger at ysidro.econ.uiuc.edu  Fri Jan 16 21:55:05 2004
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Fri, 16 Jan 2004 14:55:05 -0600 (CST)
Subject: [R] Sparse matrix row/column access (SparseM)?
In-Reply-To: <20040116193630.GA21364@infinite.fsw.leidenuniv.nl>
Message-ID: <Pine.SOL.4.30.0401161448110.934-100000@ysidro.econ.uiuc.edu>

Given a matrix in any of the SparseM forms, you can access columns
and rows with the usual R subsetting conventions, e.g. A[,k]
gives the kth column, A[m,] gives the mth row...

As a general principle, questions about packages should probably
be directed first to package maintainers (in this case me) and
only in cases of non-response to r-help.


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Fri, 16 Jan 2004, Renald Buter wrote:

> Hello list,
>
> I am creating sparse matrices using the SparseM package. These sparse
> structures are to be used as a basis for (a number of) distance
> matrices. But in order to create thoses, I must be able to read the
> elements/rows/columns of the sparse structures in order to operate on
> them.
>
> Thus, how to go from sparse matrix to (sparse) rows, columns? Must I
> create the functions myself or am I not reading the obvious in the
> documentation?
>
> Thanks in advance,
>
> Renald
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From flom at ndri.org  Fri Jan 16 22:18:48 2004
From: flom at ndri.org (Peter Flom)
Date: Fri, 16 Jan 2004 16:18:48 -0500
Subject: [R] Weird problem with trying to change a variable
Message-ID: <s0080eff.029@MAIL.NDRI.ORG>

I have a dataframe called cvar, with two variables (among many others)
called MSA and ACTUP.  Both are numeric.  This was working fine.  Then I
found out that for two MSAs, ACTUP should be 1, not 0.

so I tried

cvar$ACTUP[cvar$MSA == 6840] <- 1
cvar$ACTUP[cvar$MSA == 5360] <- 1

but when I try 

table(cvar$MSA, cvar$ACTUP)

the level of ACTUP for those two MSAs has not changed, and is still 0 


When I try

cvar$MSA  or cvar$ACTUP

I get lists, as I expect.  the MSA list includes 6840 and 5360

when I try

cvar$ACTUP[cvar$MSA == 5360]

I get numeric(0)



Any ideas?  What am I missing on a Friday afternoon?

Peter


Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



From maya2006mb at yahoo.com  Fri Jan 16 22:56:01 2004
From: maya2006mb at yahoo.com (Maya Sanders)
Date: Fri, 16 Jan 2004 13:56:01 -0800 (PST)
Subject: [R] ecdf function
Message-ID: <20040116215601.27255.qmail@web20412.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040116/21bc9373/attachment.pl

From ripley at stats.ox.ac.uk  Fri Jan 16 23:01:31 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Jan 2004 22:01:31 +0000 (GMT)
Subject: [R] Weird problem with trying to change a variable
In-Reply-To: <s0080eff.029@MAIL.NDRI.ORG>
Message-ID: <Pine.LNX.4.44.0401162153420.30845-100000@gannet.stats>

On Fri, 16 Jan 2004, Peter Flom wrote:

> I have a dataframe called cvar, with two variables (among many others)
> called MSA and ACTUP.  Both are numeric.  This was working fine.  Then I
> found out that for two MSAs, ACTUP should be 1, not 0.
> 
> so I tried
> 
> cvar$ACTUP[cvar$MSA == 6840] <- 1
> cvar$ACTUP[cvar$MSA == 5360] <- 1
> 
> but when I try 
> 
> table(cvar$MSA, cvar$ACTUP)
> 
> the level of ACTUP for those two MSAs has not changed, and is still 0 

`The level'?  You said they were numeric, and it is factors which have 
levels.

> When I try
> 
> cvar$MSA  or cvar$ACTUP
> 
> I get lists, as I expect.  the MSA list includes 6840 and 5360

Lists?  Do you mean vectors?  Columns of dataframes are not supposed to be 
lists.

> when I try
> 
> cvar$ACTUP[cvar$MSA == 5360]
> 
> I get numeric(0)

So presumably cvar$MSA == 5360 is entirely false, but I would check, and I 
would also check the class of cvar$MSA.

If perchance MSA were a factor, something like the following could be 
happening:

> MSA <- factor(c("10000", " 5360"))
> MSA
[1] 10000  5360
Levels:  5360 10000
> MSA == 5360
[1] FALSE FALSE


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Fri Jan 16 23:11:29 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 16 Jan 2004 14:11:29 -0800 (PST)
Subject: [R] ecdf function
In-Reply-To: <20040116215601.27255.qmail@web20412.mail.yahoo.com>
References: <20040116215601.27255.qmail@web20412.mail.yahoo.com>
Message-ID: <Pine.A41.4.58.0401161410320.81886@homer34.u.washington.edu>

On Fri, 16 Jan 2004, Maya Sanders wrote:

> I am trying to use the ecdf function to find p-values (using a vector of numbers to represent my new distribution and a test specific t-statistic value).  I am using :
> 1-ecdf(vector)(t-stat)
>
> vector<-c(5.386, 3.701717, 3.8289, 3.602, 4.469, 5.2087, 6.1613, 4.71181, 5.07716, 2.3517)
> ecdf(vector)(4.6604)
> [1] 0.5
>
>  R will only give me 1 significant digit after the decimal point and I
> am interested in more significant digits.  How would I be able to do
> this?

Add zeros: 0.5000000000000000000000000000000000000000000000

Your empirical CDF value at that point is 5/10, R just doesn't print
trailing zeroes.

	-thomas



From yanyu at cs.ucla.edu  Fri Jan 16 23:59:17 2004
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Fri, 16 Jan 2004 14:59:17 -0800 (PST)
Subject: [R] generate random number of any given distribution
Message-ID: <Pine.GSO.4.58.0401161451280.12711@panther.cs.ucla.edu>

Hello,
Is there a function in R to generate random number of any given
distribution (its pdf is given), besides uniform and gaussian
distribution?

Thanks,
yan



From andy_liaw at merck.com  Sat Jan 17 00:19:11 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 16 Jan 2004 18:19:11 -0500
Subject: [R] generate random number of any given distribution
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7641@usrymx25.merck.com>

If you can compute the quantile function of the distribution (i.e., the
inverse of the integral of the pdf), then you can use the probability
integral transform:  If U is a U(0,1) random variable and Q is the quantile
function of the distribution F, then Q(U) is a random variable distributed
as F.

This is not necessarily the most efficient way of generating the random
number, but it may be the only way in some cases.

HTH,
Andy 

> From: Yan Yu
> 
> Hello,
> Is there a function in R to generate random number of any given
> distribution (its pdf is given), besides uniform and gaussian
> distribution?
> 
> Thanks,
> yan


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From spencer.graves at pdf.com  Sat Jan 17 01:47:40 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 16 Jan 2004 16:47:40 -0800
Subject: [R] generate random number of any given distribution
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7641@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7641@usrymx25.merck.com>
Message-ID: <4008862C.20305@pdf.com>

Hello, Yan: 

      Are you aware that for all the standard distributions, R provides 
the probability density, the cumulative distribution function, the 
quantile function, and random number generation?  When you said, 
"besides uniform and gaussian", I wondered.  The convention is that the 
first letter of the function is d, p, q, and r, for these 4 functions, 
followed by the name or abbreviation of the distribution.  Thus, rexp = 
random numbers for the exponential distribution, rbeta = beta r.n., rt = 
Student's t, rf = F distribution, etc. 

      hope this helps. 
      spencer graves    

Liaw, Andy wrote:

>If you can compute the quantile function of the distribution (i.e., the
>inverse of the integral of the pdf), then you can use the probability
>integral transform:  If U is a U(0,1) random variable and Q is the quantile
>function of the distribution F, then Q(U) is a random variable distributed
>as F.
>
>This is not necessarily the most efficient way of generating the random
>number, but it may be the only way in some cases.
>
>HTH,
>Andy 
>
>  
>
>>From: Yan Yu
>>
>>Hello,
>>Is there a function in R to generate random number of any given
>>distribution (its pdf is given), besides uniform and gaussian
>>distribution?
>>
>>Thanks,
>>yan
>>    
>>
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments,...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From djw1005 at cam.ac.uk  Sat Jan 17 03:02:22 2004
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Sat, 17 Jan 2004 02:02:22 +0000 (GMT)
Subject: [R] Weird problem with trying to change a variable
In-Reply-To: <Pine.LNX.4.44.0401162153420.30845-100000@gannet.stats>
Message-ID: <Pine.SOL.3.96.1040117014906.3256C-100000@libra.cus.cam.ac.uk>


> Lists?  Do you mean vectors?  Columns of dataframes are not supposed to be 
> lists.

Ah. I've been using commands like

> x <- list(c(1,2,3),c(2,1),c(6,6,1))
> y <- c("A","B","C")
> data.frame(I(x),y)
        x y
1 1, 2, 3 A
2    2, 1 B
3 6, 6, 1 C

This sort of object behaves pretty much as I'd expect it to (using R 1.8.0
for Windows), though I've only made limited use. The x column has mode
list but class AsIs. Is this a legitimate use? 

(The documentation tells me that as.data.frame is a generic method, with
many implementations, including one for AsIs; and that the function I will
accept any object. I haven't looked into the implementation.)

Damon.



From flom at ndri.org  Sat Jan 17 05:28:18 2004
From: flom at ndri.org (Peter Flom)
Date: Fri, 16 Jan 2004 23:28:18 -0500
Subject: [R] Weird problem with trying to change a variable
Message-ID: <s00873b1.088@MAIL.NDRI.ORG>

Thanks for the responses.  Several people suggested I check that the
numbers are exactly what I think they are (ie. that 5360 is not
5360.00001.  I don't think this is the case (the data were entered in
SAS, then I used DBMS copy to get them to SPSS, and then read.spss to
move them to R), but I will check when I get back to the office (not til
Tuesday)

In addition, Dr. Ripley replied


I wrote

> I have a dataframe called cvar, with two variables (among many others)
> called MSA and ACTUP.  Both are numeric.  This was working fine.  Then
I
> found out that for two MSAs, ACTUP should be 1, not 0.
> 
> so I tried
> 
> cvar$ACTUP[cvar$MSA == 6840] <- 1
> cvar$ACTUP[cvar$MSA == 5360] <- 1
> 
> but when I try 
> 
> table(cvar$MSA, cvar$ACTUP)
> 
> the level of ACTUP for those two MSAs has not changed, and is still 0 

Brian Ripley replied
<<<
`The level'?  You said they were numeric, and it is factors which have 
levels.
>>>

Sorry, I misspoke - I didn't create the data set.  ACTUP is, really, a
two level variable, but was coded (originally in SAS) as 0 1.  when I
did mode(ACTUP) I found that it was numeric.
Me
> when I try
> 
> cvar$ACTUP[cvar$MSA == 5360]
> 
> I get numeric(0)

Dr Ripley
So presumably cvar$MSA == 5360 is entirely false, but I would check, and
I 
would also check the class of cvar$MSA.
>>>

when I did mode(MSA) I got that it was numeric


Thanks again

Peter

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



From gomez at hsc.kuniv.edu.kw  Sat Jan 17 10:08:24 2004
From: gomez at hsc.kuniv.edu.kw (Gomez J. Edison)
Date: Sat, 17 Jan 2004 12:08:24 +0300
Subject: [R] Re:GAM with R
Message-ID: <000601c3dcd9$76d6abe0$36468d8b@hscnet.kuniv.edu.kw>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040117/8638ff56/attachment.pl

From ripley at stats.ox.ac.uk  Sat Jan 17 10:21:02 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Jan 2004 09:21:02 +0000 (GMT)
Subject: [R] Weird problem with trying to change a variable
In-Reply-To: <Pine.SOL.3.96.1040117014906.3256C-100000@libra.cus.cam.ac.uk>
Message-ID: <Pine.LNX.4.44.0401170916430.5522-100000@gannet.stats>

On Sat, 17 Jan 2004, Damon Wischik wrote:

[Quoting me in reply to something else without the context not 
attribution.]

> > Lists?  Do you mean vectors?  Columns of dataframes are not supposed to be 
> > lists.
> 
> Ah. I've been using commands like
> 
> > x <- list(c(1,2,3),c(2,1),c(6,6,1))
> > y <- c("A","B","C")
> > data.frame(I(x),y)
>         x y
> 1 1, 2, 3 A
> 2    2, 1 B
> 3 6, 6, 1 C
> 
> This sort of object behaves pretty much as I'd expect it to (using R 1.8.0
> for Windows), though I've only made limited use. The x column has mode
> list but class AsIs. Is this a legitimate use? 

Yes.  That is not a `bare' list, but a class with a specific method.

> (The documentation tells me that as.data.frame is a generic method, with
> many implementations, including one for AsIs; and that the function I will
> accept any object. I haven't looked into the implementation.)

All you need is for the length to match.  It is possible to get bare lists
into data frames, but as.data.frame.list inserts each column separately
and if you do circumvent that (and I don't mean by I()) some strange
things can happen.  We don't guarantee not to break what currently works
in that area, either.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Sat Jan 17 11:47:54 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 17 Jan 2004 11:47:54 +0100
Subject: [R] Re:GAM with R
References: <000601c3dcd9$76d6abe0$36468d8b@hscnet.kuniv.edu.kw>
Message-ID: <400912DA.6DF51921@statistik.uni-dortmund.de>



"Gomez J. Edison" wrote:
> 
> I have a data file in SPSS with about 50 variables and more than 2000 cases. I would like to fit a gam model. I tried with foreign package to read SPSS data file and tried gam with mgcv package. It gave me error. Can anybody help me in this matter.

Nobody!

You need to be *much* _much_ /much/ more precise! What's the error
message? What's the call? Version of R? OS? Version of the packages? ...
and many more questions arise ...

Uwe Ligges


> Thanks a lot.
> Gomez J. Edison
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From kgk at pharm.auth.gr  Sat Jan 17 12:30:08 2004
From: kgk at pharm.auth.gr (Kyriakos Kachrimanis)
Date: Sat, 17 Jan 2004 13:30:08 +0200
Subject: [R] ternary diagrams with contours
Message-ID: <003c01c3dced$4775acc0$5e05cf9b@lakonia>

Dear R-listers,

I would like to ask if it is possible to create ternary diagrams with
contours. I want to plot a property that depends on a ternary mixture
composition, so I think this would be the best way. I found a similar
question in a past R-help list message but there was no answer.

In case it is not possible to create ternary plots with contours, can anyone
suggest an alternative way to plot a property that depends on mixture
composition? Even suggestions for alternative, preferably free, software are
wellcome.

Thank you very much in advance.

Regards,

Kyriakos.



From kgk at pharm.auth.gr  Sat Jan 17 12:30:57 2004
From: kgk at pharm.auth.gr (Kyriakos Kachrimanis)
Date: Sat, 17 Jan 2004 13:30:57 +0200
Subject: [R] ternary diagrams with contours
Message-ID: <003f01c3dced$60f896d0$5e05cf9b@lakonia>

Dear R-listers,

I would like to ask if it is possible to create ternary diagrams with
contours. I want to plot a property that depends on a ternary mixture
composition, so I think this would be the best way. I found a similar
question in a past R-help list message but there was no answer.

In case it is not possible to create ternary plots with contours, can anyone
suggest an alternative way to plot a property that depends on mixture
composition? Even suggestions for alternative, preferably free, software are
wellcome.

Thank you very much in advance.

Regards,

Kyriakos.



From kgk at pharm.auth.gr  Sat Jan 17 12:31:04 2004
From: kgk at pharm.auth.gr (Kyriakos Kachrimanis)
Date: Sat, 17 Jan 2004 13:31:04 +0200
Subject: [R] ternary diagrams with contours
Message-ID: <004001c3dced$64b21c60$5e05cf9b@lakonia>

Dear R-listers,

I would like to ask if it is possible to create ternary diagrams with
contours. I want to plot a property that depends on a ternary mixture
composition, so I think this would be the best way. I found a similar
question in a past R-help list message but there was no answer.

In case it is not possible to create ternary plots with contours, can anyone
suggest an alternative way to plot a property that depends on mixture
composition? Even suggestions for alternative, preferably free, software are
wellcome.

Thank you very much in advance.

Regards,

Kyriakos.



From p.dalgaard at biostat.ku.dk  Sat Jan 17 12:31:33 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Jan 2004 12:31:33 +0100
Subject: [R] Weird problem with trying to change a variable
In-Reply-To: <s00873b1.088@MAIL.NDRI.ORG>
References: <s00873b1.088@MAIL.NDRI.ORG>
Message-ID: <x2hdyu3j6y.fsf@biostat.ku.dk>

"Peter Flom" <flom at ndri.org> writes:

> Thanks for the responses.  Several people suggested I check that the
> numbers are exactly what I think they are (ie. that 5360 is not
> 5360.00001.  I don't think this is the case (the data were entered in
> SAS, then I used DBMS copy to get them to SPSS, and then read.spss to
> move them to R), but I will check when I get back to the office (not til
> Tuesday)

Don't think, check! Calculate min(abs(x-5360)) for instance.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Sat Jan 17 12:43:54 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Jan 2004 11:43:54 +0000 (GMT)
Subject: [R] ternary diagrams with contours
In-Reply-To: <003c01c3dced$4775acc0$5e05cf9b@lakonia>
Message-ID: <Pine.LNX.4.44.0401171140540.5750-100000@gannet.stats>

On Sat, 17 Jan 2004, Kyriakos Kachrimanis wrote:

> I would like to ask if it is possible to create ternary diagrams with
> contours. I want to plot a property that depends on a ternary mixture
> composition, so I think this would be the best way. I found a similar
> question in a past R-help list message but there was no answer.

It is possible.  Just produce a suitable matrix of values, set parts 
outside the triangle to NA and call contour.  I have done it several 
times.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From buter at cwts.leidenuniv.nl  Sat Jan 17 13:31:17 2004
From: buter at cwts.leidenuniv.nl (Renald Buter)
Date: Sat, 17 Jan 2004 13:31:17 +0100
Subject: [R] Sparse matrix row/column access (SparseM)?
In-Reply-To: <Pine.SOL.4.30.0401161448110.934-100000@ysidro.econ.uiuc.edu>
References: <20040116193630.GA21364@infinite.fsw.leidenuniv.nl>
	<Pine.SOL.4.30.0401161448110.934-100000@ysidro.econ.uiuc.edu>
Message-ID: <20040117123117.GA8031@infinite.fsw.leidenuniv.nl>

On Fri, Jan 16, 2004 at 02:55:05PM -0600, Roger Koenker wrote:
> Given a matrix in any of the SparseM forms, you can access columns
> and rows with the usual R subsetting conventions, e.g. A[,k]
> gives the kth column, A[m,] gives the mth row...


*blush* 

Couln't be more simpler. Thank you.

> As a general principle, questions about packages should probably
> be directed first to package maintainers (in this case me) and
> only in cases of non-response to r-help.
> 
> 

My apologies. I was not aware of this convention.

Regards,

Renald



From karlknoblich at yahoo.de  Sat Jan 17 15:58:57 2004
From: karlknoblich at yahoo.de (=?iso-8859-1?q?Karl=20Knoblick?=)
Date: Sat, 17 Jan 2004 15:58:57 +0100 (CET)
Subject: [R] Multiple groupedData plots in a postscript file using a loop
Message-ID: <20040117145857.18200.qmail@web10001.mail.yahoo.com>

Hallo!

I want to plot multiple grouped data in a postscript
file using a loop. As I use a loop no plot (or just
one empty plot) is generated. Here an example:

library(nlme)
data(Loblolly) # example data from nlme
postscript("PSFile.ps")
for (i in 1:1) # just as example
{
	plot(Loblolly)
}
dev.off()

Result: Just an empty PSFile.ps.
(Withoput the loop it works.

May anybody help?

Karl


__________________________________________________________________


From ligges at statistik.uni-dortmund.de  Sat Jan 17 16:20:48 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 17 Jan 2004 16:20:48 +0100
Subject: [R] Multiple groupedData plots in a postscript file using a loop
In-Reply-To: <20040117145857.18200.qmail@web10001.mail.yahoo.com>
References: <20040117145857.18200.qmail@web10001.mail.yahoo.com>
Message-ID: <400952D0.4000106@statistik.uni-dortmund.de>

Karl Knoblick wrote:
> Hallo!
> 
> I want to plot multiple grouped data in a postscript
> file using a loop. As I use a loop no plot (or just
> one empty plot) is generated. Here an example:
> 
> library(nlme)
> data(Loblolly) # example data from nlme
> postscript("PSFile.ps")
> for (i in 1:1) # just as example
> {
> 	plot(Loblolly)
> }
> dev.off()

Note that this is a lattice plot:

  class(Loblolly)
[1] "nfnGroupedData" "nfGroupedData"  "groupedData"    "data.frame"

Thus, the method plot.nfnGroupedData() producing a lattice plot is 
called by the generic plot().

So, you don't want to start postscript(), but
  trellis.device("postscript", file = "PSFile.ps")
  plot(Loblolly)
  dev.off()

Uwe Ligges


> Result: Just an empty PSFile.ps.
> (Withoput the loop it works.
> 
> May anybody help?
> 
> Karl
> 
> 
> __________________________________________________________________
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From deepayan at stat.wisc.edu  Sat Jan 17 16:32:07 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 17 Jan 2004 09:32:07 -0600
Subject: [R] Multiple groupedData plots in a postscript file using a loop
In-Reply-To: <20040117145857.18200.qmail@web10001.mail.yahoo.com>
References: <20040117145857.18200.qmail@web10001.mail.yahoo.com>
Message-ID: <200401170932.07487.deepayan@stat.wisc.edu>

On Saturday 17 January 2004 08:58, Karl Knoblick wrote:
> Hallo!
>
> I want to plot multiple grouped data in a postscript
> file using a loop. As I use a loop no plot (or just
> one empty plot) is generated. Here an example:
>
> library(nlme)
> data(Loblolly) # example data from nlme
> postscript("PSFile.ps")
> for (i in 1:1) # just as example
> {
> 	plot(Loblolly)

replace this line with 

        print(plot(Loblolly))

(plot(Loblolly) produces a ``trellis'' object, which needs to be 'print'-ed 
for anything to be actually plotted. Inside a loop (or a function), this does 
not happen unless you call print() explicitly)

> }
> dev.off()
>
> Result: Just an empty PSFile.ps.
> (Withoput the loop it works.
>
> May anybody help?
>
> Karl



From karlknoblich at yahoo.de  Sat Jan 17 16:34:26 2004
From: karlknoblich at yahoo.de (=?iso-8859-1?q?Karl=20Knoblick?=)
Date: Sat, 17 Jan 2004 16:34:26 +0100 (CET)
Subject: [R] Multiple groupedData plots in a postscript file using a loop
In-Reply-To: <400952D0.4000106@statistik.uni-dortmund.de>
Message-ID: <20040117153426.24265.qmail@web10001.mail.yahoo.com>

Thanks, but it does NOT work using a loop (your
example without loop works):

trellis.device("postscript", file = "PSFile.ps")
for (i in 1:1)
{
  plot(Loblolly)
}
dev.off()

Just an empty postscript file.

Karl.

 --- Uwe Ligges <ligges at statistik.uni-dortmund.de> :> 
> Note that this is a lattice plot:
> 
>   class(Loblolly)
> [1] "nfnGroupedData" "nfGroupedData"  "groupedData" 
>   "data.frame"
> 
> Thus, the method plot.nfnGroupedData() producing a
> lattice plot is 
> called by the generic plot().
> 
> So, you don't want to start postscript(), but
>   trellis.device("postscript", file = "PSFile.ps")
>   plot(Loblolly)
>   dev.off()
> 
> Uwe Ligges
> 


__________________________________________________________________


From ligges at statistik.uni-dortmund.de  Sat Jan 17 16:39:49 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 17 Jan 2004 16:39:49 +0100
Subject: [R] Multiple groupedData plots in a postscript file using a loop
In-Reply-To: <20040117153426.24265.qmail@web10001.mail.yahoo.com>
References: <20040117153426.24265.qmail@web10001.mail.yahoo.com>
Message-ID: <40095745.50203@statistik.uni-dortmund.de>

Karl Knoblick wrote:

> Thanks, but it does NOT work using a loop (your
> example without loop works):
> 
> trellis.device("postscript", file = "PSFile.ps")
> for (i in 1:1)
> {
>   plot(Loblolly)
> }
> dev.off()


Yep, sorry. You need to print() a lattice plot in this case:

trellis.device("postscript", file = "PSFile.ps")
for (i in 1:1)
{
   print(plot(Loblolly))
}
dev.off()


Uwe Ligges


> Just an empty postscript file.
> 
> Karl.
> 
>  --- Uwe Ligges <ligges at statistik.uni-dortmund.de> :> 
> 
>>Note that this is a lattice plot:
>>
>>  class(Loblolly)
>>[1] "nfnGroupedData" "nfGroupedData"  "groupedData" 
>>  "data.frame"
>>
>>Thus, the method plot.nfnGroupedData() producing a
>>lattice plot is 
>>called by the generic plot().
>>
>>So, you don't want to start postscript(), but
>>  trellis.device("postscript", file = "PSFile.ps")
>>  plot(Loblolly)
>>  dev.off()
>>
>>Uwe Ligges
>>
> 
> 
> 
> __________________________________________________________________
> 


From ripley at stats.ox.ac.uk  Sat Jan 17 16:40:28 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Jan 2004 15:40:28 +0000 (GMT)
Subject: [R] Multiple groupedData plots in a postscript file using a loop
In-Reply-To: <400952D0.4000106@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0401171528570.6927-100000@gannet.stats>

On Sat, 17 Jan 2004, Uwe Ligges wrote:

> Karl Knoblick wrote:
> > Hallo!
> > 
> > I want to plot multiple grouped data in a postscript
> > file using a loop. As I use a loop no plot (or just
> > one empty plot) is generated. Here an example:
> > 
> > library(nlme)
> > data(Loblolly) # example data from nlme
> > postscript("PSFile.ps")
> > for (i in 1:1) # just as example
> > {
> > 	plot(Loblolly)
> > }
> > dev.off()
> 
> Note that this is a lattice plot:
> 
>   class(Loblolly)
> [1] "nfnGroupedData" "nfGroupedData"  "groupedData"    "data.frame"
> 
> Thus, the method plot.nfnGroupedData() producing a lattice plot is 
> called by the generic plot().
> 
> So, you don't want to start postscript(), but
>   trellis.device("postscript", file = "PSFile.ps")
>   plot(Loblolly)
>   dev.off()
> 

Or inside a loop

trellis.device("postscript", file = "PSFile.ps")
for (i in 1:1)
  print(plot(Loblolly))
# ^^^^^
dev.off()

Although Uwe is right that trellis.device should be used, recent versions 
of lattice do make correct use of an open postscript() device.

Not that Master Knoblick *is* using recent lattice, as we know from an
earlier posting.  See

https://www.stat.math.ethz.ch/pipermail/r-help/2004-January/042780.html

Once again he has omitted to let us know what versions he is using.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From karlknoblich at yahoo.de  Sat Jan 17 17:08:41 2004
From: karlknoblich at yahoo.de (=?iso-8859-1?q?Karl=20Knoblick?=)
Date: Sat, 17 Jan 2004 17:08:41 +0100 (CET)
Subject: [R] plot in win.metafile in nlme
In-Reply-To: <Pine.LNX.4.44.0401171528570.6927-100000@gannet.stats>
Message-ID: <20040117160841.33357.qmail@web10009.mail.yahoo.com>

My problem was solved by using 
trellis.device(win.metafile,file="Loblolly.wmf",
color=F)
instead of win.metafile("Loblolly.wmf").
(other answers helped also)

(What I found for getting similiar plots as postscript
was color=F in the trellis.device(...) command)

Thanks to all!
Karl.

BTW win.metafile("Loblolly.wmf") does not work for me
with the following versions I updated recently:

R version 1.8.0, 2003-10-08
package.description("lattice")
Package "lattice" 
Version "0.8-7" 
Date "2003/10/17" 
Built "R 1.8.0; i386-pc-mingw32; 2003-10-29 16:36:53;
windows" 

package.description("nlme")
Package "nlme" 
Version "3.1-45" 
Date "2003/08/29" 
Built "R 1.8.0; i386-pc-mingw32; 2003-10-09 00:21:55;
windows" 


__________________________________________________________________


From ripley at stats.ox.ac.uk  Sat Jan 17 17:31:23 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Jan 2004 16:31:23 +0000 (GMT)
Subject: [R] plot in win.metafile in nlme
In-Reply-To: <20040117160841.33357.qmail@web10009.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0401171623380.6990-100000@gannet.stats>

On Sat, 17 Jan 2004, Karl Knoblick wrote:

> My problem was solved by using 
> trellis.device(win.metafile,file="Loblolly.wmf",
> color=F)
> instead of win.metafile("Loblolly.wmf").
> (other answers helped also)
> 
> (What I found for getting similiar plots as postscript
> was color=F in the trellis.device(...) command)
> 
> Thanks to all!
> Karl.
> 
> BTW win.metafile("Loblolly.wmf") does not work for me
> with the following versions I updated recently:

> R version 1.8.0, 2003-10-08

But, the current version is R 1.8.1 and it *does* work in a current
version of R (1.8.1 or R-patched or R-devel).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Saini48 at wmconnect.com  Sat Jan 17 20:39:12 2004
From: Saini48 at wmconnect.com (Saini48@wmconnect.com)
Date: Sat, 17 Jan 2004 14:39:12 EST
Subject: [R] (no subject)
Message-ID: <158.2bba73c6.2d3ae960@wmconnect.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040117/2712eae5/attachment.pl

From spencer.graves at pdf.com  Sat Jan 17 21:52:44 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 17 Jan 2004 12:52:44 -0800
Subject: [R] documentation for "sample" [was "(no subject)"]
In-Reply-To: <158.2bba73c6.2d3ae960@wmconnect.com>
References: <158.2bba73c6.2d3ae960@wmconnect.com>
Message-ID: <4009A09C.4080606@pdf.com>

           Have you tried the posting guide at 
"http://www.R-project.org/posting-guide.html"?  If yes, please be more 
specific regarding what you tried and why you are not satisfied.    

      hope this helps.  spencer graves

Saini48 at wmconnect.com wrote:

>Need the Documentation for R's "sample"command
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From kgk at pharm.auth.gr  Sun Jan 18 11:08:42 2004
From: kgk at pharm.auth.gr (Kyriakos Kachrimanis)
Date: Sun, 18 Jan 2004 12:08:42 +0200
Subject: [R] ternary diagrams with contours
References: <Pine.LNX.4.44.0401171227560.6475-100000@gannet.stats>
Message-ID: <005501c3ddab$0f6c5590$5e05cf9b@lakonia>


> Please stop sending the same message repeatedly: this is the *third* copy.

I am sorry for the repeated messages and the unnecessary mail trafic in the
list. It was not done deliberately. Outlook Express repeatedly crashed when
I tried to send the message and, while I thought it was not sent, I was
surprised to see that there were three copies in my "sent items" folder.

Thank you very much for the reply.



From patrick.giraudoux at univ-fcomte.fr  Sun Jan 18 13:36:15 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 18 Jan 2004 13:36:15 +0100
Subject: [R] email problem
Message-ID: <001401c3ddbf$ac086830$cd823051@PC728329681112>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040118/c3965fb6/attachment.pl

From Lars.Peters at Uni-Konstanz.de  Sun Jan 18 13:52:00 2004
From: Lars.Peters at Uni-Konstanz.de (Lars Peters)
Date: Sun, 18 Jan 2004 13:52:00 +0100
Subject: [R] Syntay-Highlighting  for KDE-Kate
Message-ID: <LBELKNGGJOINKPAFNOOLIEGCCCAA.Lars.Peters@Uni-Konstanz.de>

I'm looking for a plugin for Kate (or any other good text editor for linux)
(KDE 3.x) which will highlight the R syntax.

The link on www.r-project.org is dead!

Any ideas??

Thanks Lars



From baron at psych.upenn.edu  Sun Jan 18 14:06:50 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sun, 18 Jan 2004 08:06:50 -0500
Subject: [R] Syntay-Highlighting  for KDE-Kate
In-Reply-To: <LBELKNGGJOINKPAFNOOLIEGCCCAA.Lars.Peters@Uni-Konstanz.de>
References: <LBELKNGGJOINKPAFNOOLIEGCCCAA.Lars.Peters@Uni-Konstanz.de>
Message-ID: <20040118130650.GA17040@mail1.sas.upenn.edu>

On 01/18/04 13:52, Lars Peters wrote:
>I'm looking for a plugin for Kate (or any other good text editor for linux)
>(KDE 3.x) which will highlight the R syntax.

I think "any other good text editor" would include emacs and
xemacs.  For either of these, you can get ESS:
http://stat.ethz.ch/ESS/
It is now part of the Xemacs "Sumo" rpm (all the packages
together), but you can also install it separately if you want.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From patrick.giraudoux at univ-fcomte.fr  Sun Jan 18 17:36:40 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 18 Jan 2004 17:36:40 +0100
Subject: [R] multcomp, simint, simtest and computation duration
Message-ID: <002901c3dde1$45f1a3f0$e0bc3151@PC728329681112>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040118/e4ac60c7/attachment.pl

From geoff.grimwood at paradise.net.nz  Sun Jan 18 22:00:47 2004
From: geoff.grimwood at paradise.net.nz (Geoff Grimwood)
Date: Mon, 19 Jan 2004 10:00:47 +1300
Subject: [R] RMySQL : Mac : bus error at dbConnect time
In-Reply-To: <7B7CD71E-4685-11D8-B58F-000393AA6416@paradise.net.nz>
Message-ID: <63AD7A8C-49F9-11D8-84F8-000393AA6416@paradise.net.nz>

Any help on this will be greatly appreciated.

Regards

Geoff

Version 1.8.1 Patched (2004-01-15), ISBN 3-900051-00-3

 >   library(RMySQL)
 >   library(DBI)
 >   drv<-dbDriver("MySQL")
 > drv
<MySQLDriver:(5415)>
 > dbConnect(drv,dbname="mysql",user="root",password="******")
Bus error

RMySQL 0.5-3
MySQL is working fine and is 4.0.17
R is fine apart from this
Mac OS 10.2.8, fink, et al (a big et al)

R built using

  ./configure --enable-R-shlib --with-blas=-framework vecLib 
--with-lapack

(It fails to build using ./configure with no options)

RMySQL installed using

setenv PKG_CPPFLAGS '-I/usr/local/mysql/include -I/sw/include/gnugetopt'
setenv PKG_LIBS '-L/usr/local/mysql/lib -lmysqlclient -lgnugetopt'
R CMD INSTALL --configure-args='--with-mysql-dir=/usr/local/mysql' 
RMySQL_0.5-3.tar.gz

[SIDLAW02:~geoff/heaven/src] root# mysql_config
Usage: /usr/local/mysql/bin/mysql_config [OPTIONS]
Options:
         --cflags         [-I/usr/local/mysql/include -O3 
-fno-omit-frame-pointer]
         --include        [-I/usr/local/mysql/include]
         --libs           [-L/usr/local/mysql/lib -lmysqlclient -lz -lm]
         --libs_r         [-L/usr/local/mysql/lib -lmysqlclient_r -lz 
-lm]
         --socket         [/tmp/mysql.sock]
         --port           [3306]
         --version        [4.0.17]
         --libmysqld-libs [-L/usr/local/mysql/lib -lmysqld -lz -lm]



From itayf at fhcrc.org  Mon Jan 19 00:16:33 2004
From: itayf at fhcrc.org (Itay Furman)
Date: Sun, 18 Jan 2004 15:16:33 -0800 (PST)
Subject: [R] Copying a device (former: Legend text -- discrepancy ...)
In-Reply-To: <Pine.LNX.4.44.0401150816030.2085-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0401181410020.15457-100000@cezanne.fhcrc.org>


On Thu, 15 Jan 2004, Prof Brian Ripley wrote:

> The short answer is not to copy the device, but to replot on the new 
> device.  That is the advice given in MASS, for example.
>

But these device-copy functions could have been quite handy -- 
especially after a long sequence of plotting commands that are 
done interactively.


> When you copy a device, you replay the device list and hence the lines and 
> text are placed at the positions calculated using the font metrics of the 
> first device and not the second.  dev.copy2eps does not try to adjust the 
> pointsize of the postscript device, and provided the fonts match you 
> should just be able to adjust the pointsize in this case.
> 

OK, so I tried various things and the best I could come up with 
is replacing [My X11() width and height defaults are 7]
	dev.copy2eps(file="test.eps", paper="letter")
with
	dev.copy2eps(file="test.eps", paper="letter",
			width=8, height=8)

Let's see if I understood what I did above:
the physical size of the X11 and PS fonts is different. 
Therefore, instead of changing the fontsize we re-scale the plot.
(This is what is implied by the various printouts I have made.)
If so, is there a way to reduce the font size, instead of  
increasing the plot size?
(To avoid the plot extending beyond the physical page, for 
example.)

If the only way is to change the EPS device dimensions how could 
I do it in a more robust way?
Is, e.g., 'width=some.factor*par("din")[1]' a sensible way?
Is there a better way?
Could I pre-determine some.factor?


> You do need to be suspicious of on-screen viewers and indeed of 
> ghostscript, for they are often not pixel-perfect and ghostscript does 
> font substitution (it does not have Helvetica).  I would always test by 
> printing on a postscript printer.
> 

Screen and print rendering were the same.

	Many thanks,
	Itay


--
itayf at fhcrc.org



From naumov at buffalo.edu  Mon Jan 19 01:25:28 2004
From: naumov at buffalo.edu (Aleksey Naumov)
Date: Sun, 18 Jan 2004 19:25:28 -0500 (EST)
Subject: [R] Syntay-Highlighting  for KDE-Kate
In-Reply-To: <LBELKNGGJOINKPAFNOOLIEGCCCAA.Lars.Peters@Uni-Konstanz.de>
Message-ID: <Pine.GSO.4.05.10401181919560.23171-100000@callisto.acsu.buffalo.edu>

Lars,

I don't know of an R syntax plugin for Kate, instead I just use Python
highlighting for my R scripts in Kate, and it works quite well. If you
find an R plugin, I would appreciate a note...

Thanks
Aleksey

On Sun, 18 Jan 2004, Lars Peters wrote:

> I'm looking for a plugin for Kate (or any other good text editor for linux)
> (KDE 3.x) which will highlight the R syntax.
> 
> The link on www.r-project.org is dead!
> 
> Any ideas??
> 
> Thanks Lars
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Mon Jan 19 02:13:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 18 Jan 2004 20:13:36 -0500
Subject: [R] Syntay-Highlighting  for KDE-Kate
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7644@usrymx25.merck.com>

I don't use Kate, but is this what you're looking for?

http://www.uni-kiel.de/agrarpol/ahenningsen/app-econ/R.xml

(Found just by googling around...)

Andy

> From: Aleksey Naumov
> 
> Lars,
> 
> I don't know of an R syntax plugin for Kate, instead I just use Python
> highlighting for my R scripts in Kate, and it works quite well. If you
> find an R plugin, I would appreciate a note...
> 
> Thanks
> Aleksey
> 
> On Sun, 18 Jan 2004, Lars Peters wrote:
> 
> > I'm looking for a plugin for Kate (or any other good text 
> editor for linux)
> > (KDE 3.x) which will highlight the R syntax.
> > 
> > The link on www.r-project.org is dead!
> > 
> > Any ideas??
> > 
> > Thanks Lars
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> > 
> >
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From aperrin at socrates.berkeley.edu  Mon Jan 19 02:39:23 2004
From: aperrin at socrates.berkeley.edu (aperrin@socrates.berkeley.edu)
Date: Mon, 19 Jan 2004 11:39:23 +1000
Subject: [R] Hi
Message-ID: <xteiyxhgfywgqwrdmgr@socrates.berkeley.edu>

 Test =)
likcgrsnvmfcvrftoejmw
--
Test, yep.

From petr.pikal at precheza.cz  Mon Jan 19 08:14:25 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 19 Jan 2004 08:14:25 +0100
Subject: [R] ternary diagrams with contours
Message-ID: <400B91E1.28199.24979D@localhost>

Hi

with
help.search("ternary")

I have got

"ternaryplot" in package "vcd"

and below is some code for ternary diagram which was in help 
post several years ago. I do not know if and how it works, I have 
not tried it a long time.

#----------------------------------------------------------------------------
-----
# funkce pro kresleni ternarniho diagramu
# Colin Farrow
# Computing Service, University of Glasgow, Glasgow G12 8QQ
# c.farrow at compserv.gla.ac.uk


tri<-
function(a, f, m, symb = 2, grid = F, ...)
{
 ta <- paste(substitute(a))
 tf <- paste(substitute(f))
 tm <- paste(substitute(m))

 tot <- 100/(a + f +m)
 b <- f * tot
 y <- b * .878
 x <- m * tot + b/2
 par(pty = "s")
 oldcol <- par("col")
 plot(x, y, axes = F, xlab = "", ylab = "", xlim = c(-10, 110), ylim
   = c(-10, 110), type = "n", ...)
        points(x,y,pch=symb)
 par(col = oldcol)
 trigrid(grid)
 text(-5, -5, ta)
 text(105, -5, tm)
 text(50, 93, tf)
 par(pty = "m")
 invisible()
}
"trigrid"<-
function(grid = F)
{
 lines(c(0, 50, 100, 0), c(0, 87.8, 0, 0))	#draw frame
 if(!grid) {
  for(i in 1:4 * 20) {
   lines(c(i, i - 1), c(0, 2 * .878))	#side a-c (base)
   lines(c(i, i + 1), c(0, 2 * .878))
   T.j <- i/2	#side a-b (left)
   lines(c(T.j, T.j + 2), c(i * .878, i * .878))
   lines(c(T.j, T.j + 1), c(i * .878, (i - 2) * .878))
   T.j <- 100 - i/2	#side b-c (right)
   lines(c(T.j, T.j - 2), c(i * .878, i * .878))
   lines(c(T.j, T.j - 1), c(i * .878, (i - 2) * .878))
  }
 }
 else {
  for(i in 1:4 * 20) {
# draw dotted grid
   lines(c(i, i/2), c(0, i * .878), lty = 4, col = 3)	#
   lines(c(i, (50 + i/2)), c(0, .878 * (100 - i)), lty = 4,
    col = 3)	# /
   lines(c(i/2, (100 - i/2)), c(i * .878, i * .878), lty
     = 4, col = 3)	# -
  }
  par(lty = 1, col = 1)
 }
}

Petr Pikal
petr.pikal at precheza.cz



From ripley at stats.ox.ac.uk  Mon Jan 19 08:39:58 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 Jan 2004 07:39:58 +0000 (GMT)
Subject: [R] Re: Copying a device (former: Legend text -- discrepancy ...)
In-Reply-To: <Pine.LNX.4.44.0401181410020.15457-100000@cezanne.fhcrc.org>
Message-ID: <Pine.LNX.4.44.0401190735560.28442-100000@gannet.stats>

On Sun, 18 Jan 2004, Itay Furman wrote:

> 
> On Thu, 15 Jan 2004, Prof Brian Ripley wrote:
> 
> > The short answer is not to copy the device, but to replot on the new 
> > device.  That is the advice given in MASS, for example.
> >
> 
> But these device-copy functions could have been quite handy -- 
> especially after a long sequence of plotting commands that are 
> done interactively.

Yes, and that is part of the statement I pointed you to.

> > When you copy a device, you replay the device list and hence the lines and 
> > text are placed at the positions calculated using the font metrics of the 
> > first device and not the second.  dev.copy2eps does not try to adjust the 
> > pointsize of the postscript device, and provided the fonts match you 
> > should just be able to adjust the pointsize in this case.
> > 
> 
> OK, so I tried various things and the best I could come up with 
> is replacing [My X11() width and height defaults are 7]
> 	dev.copy2eps(file="test.eps", paper="letter")
> with
> 	dev.copy2eps(file="test.eps", paper="letter",
> 			width=8, height=8)

So you ignored the advice I gave about `pointsize'!

> Let's see if I understood what I did above:
> the physical size of the X11 and PS fonts is different. 
> Therefore, instead of changing the fontsize we re-scale the plot.
> (This is what is implied by the various printouts I have made.)
> If so, is there a way to reduce the font size, instead of  
> increasing the plot size?

Yes, and I have already given you a reference to it and told you in the 
email.

> (To avoid the plot extending beyond the physical page, for 
> example.)
> 
> If the only way is to change the EPS device dimensions how could 
> I do it in a more robust way?
> Is, e.g., 'width=some.factor*par("din")[1]' a sensible way?
> Is there a better way?
> Could I pre-determine some.factor?
> 
> 
> > You do need to be suspicious of on-screen viewers and indeed of 
> > ghostscript, for they are often not pixel-perfect and ghostscript does 
> > font substitution (it does not have Helvetica).  I would always test by 
> > printing on a postscript printer.
> > 
> 
> Screen and print rendering were the same.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From a.trapletti at bluewin.ch  Mon Jan 19 09:27:37 2004
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Mon, 19 Jan 2004 09:27:37 +0100
Subject: [R] How can I test if time series residuals' are uncorrelated
	?
Message-ID: <400B94F9.7080101@bluewin.ch>

>
>
>>
>> Ok I made Jarque-Bera test to the residuals (merv.reg$residual)
>>
>> library(tseries)
>> jarque.bera.test(merv.reg$residual)
>> X-squared = 1772.369, df = 2, p-value = < 2.2e-16
>> And I reject the null hypotesis (H0: merv.reg$residual are normally
>> distributed)
>>
>> So I know that:
>> 1 - merv.reg$residual aren't independently distributed (Box-Ljung test)
>> 2 - merv.reg$residual aren't indentically distributed (Breusch-Pagan 
>> test)
>> 3 - merv.reg$residual aren't normally distributed (Jarque-Bera test)
>>
>> My questions is:
>> It is possible merv.reg$residual be uncorrelated ?
>> cov[residual_t, residual_(t+k)] = 0 ?
>> Even when residuals are not independent distributed !
>
>
>
> Yes. E.g., in an ARCH(1) process, cov[y_t, y_(t+k) ] = 0 (k \neq 0), 
> but cov[(y_t)2, (y_(t+k))2 ] \neq 0,


The last equation should be autocov[y_t, y_(t+k)] \neq 0 or equivalently 
cov[(y_t)2, (y_(t+k))2 ] \neq (E[(y_t)2])2

best
Adrian


> hence no independence (and this is typical for financial time series).
>
>>
>> (and we know that they aren't normally distributed and they aren't
>> indentically distributed )
>> And how can I tested it ?
>
>
>
>>
>> Thanks.
>>
>>
>>>> Hint, if a ts is normally distributed then independence and
>>>
>>
>> uncorrelatedness
>>
>>>> are equivalent, hence you can test for normally distributed errors 
>>>> (e.g.
>>>> Jarque-Bera-Test).
>>>>
>>>> HTH,
>>>> Bernhard
>>>>
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>
> Typically, financial time series exhibit fat tails, i.e., are not 
> normally distributed (and in an ARCH setup, financial time series are 
> usually not even conditionally normally distributed. The fat tails are 
> fatter than what we would expect from the clustering of volatility).
>
> best
> Adrian
>
> -- 
> Dr. Adrian Trapletti
> Trapletti Statistical Computing
> Wildsbergstrasse 31, 8610 Uster
> Switzerland
> Phone & Fax : +41 (0) 1 994 5631
> Mobile : +41 (0) 76 370 5631
> Email : mailto:a.trapletti at bluewin.ch
> WWW : http://trapletti.homelinux.com
>
>





From maechler at stat.math.ethz.ch  Mon Jan 19 09:34:49 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 19 Jan 2004 09:34:49 +0100
Subject: [R] email problem
In-Reply-To: <001401c3ddbf$ac086830$cd823051@PC728329681112>
References: <001401c3ddbf$ac086830$cd823051@PC728329681112>
Message-ID: <16395.38569.305616.166577@gargle.gargle.HOWL>

>>>>> "Patrick" == Patrick Giraudoux <patrick.giraudoux at univ-fcomte.fr>
>>>>>     on Sun, 18 Jan 2004 13:36:15 +0100 writes:


    MM> The queue of outgoing e-mails has been emptying since
    MM> 10:30 MET now, and hopefully all mails will have been
    MM> sent within a few more hours.

    Patrick> OK.  May this explain alone the long silence I had
    Patrick> from the list since January 12 nothing (except
    Patrick> today 18 when I receive the daily batch -hope
    Patrick> things will go on smoothly now) -see mail copy
    Patrick> below? I just got the information above
    Patrick> incidentally going through the January archives via
    Patrick> internet to check batches that I did not receive.

The reason is your institution's `high-quality' ;-) virus-scanner:
Most of R-help digests sent to you are bounced as containing a
virus  though it's very clear they do not, e.g.,

 >> Message-Id: <200401171124.MAA24116 at ufc.univ-fcomte.fr>
 >> From: postmaster at univ-fcomte.fr
 >> To: r-help-bounces at stat.math.ethz.ch
 >> Subject: Virus Alert
 >> Date: Sat, 17 Jan 2004 12:24:32 +0100

 >> Le message ?lectronique (fichier: whole-message) que vous avez envoy? ? <patrick.giraudoux at univ-fcomte.fr> le 01/17/2004 12:24:23 (mois/jour/ann?e) contient un virus (Exceed_Decompression_Layer). (sur the network)


    Patrick> Thanks to the list manager for coping with those
    Patrick> troubles (guess this work is not really rewarding
    Patrick> to him...).

indeed!  though I regularly receive ``virtual flowers'' (e-"thank you"s).

Please do not bother  R-help  with these problems in general.
(this is CC'ed to R-help to *close* the thread!)

Bonnes salutations,

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From james.lindsey at luc.ac.be  Mon Jan 19 09:53:05 2004
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Mon, 19 Jan 2004 09:53:05 +0100 (MET)
Subject: [R] individual likelihoods
In-Reply-To: <008501c3dc34$cc9765b0$b943ed82@brungio> from "Bruno Giordano" at
	Jan 16, 2004 02:29:40 PM
Message-ID: <200401190853.JAA04072@luc.ac.be>

> 
> Dear all,
> is there a way to extract individual likelihoods from a glm/lrm object?
> By individual likelihoods, I mean the likelihoods whose product give the
> overall likelihood of the model.
> I guess the code in the base package, used to compute the Akaike Information
> Criterion may help me.
> However, I couldn't figure it out, probably because I'm rather new to
> likelihood theory and ML estimation ;-)

The aic function just sums the corresponding density ("d") function
with log=T (except for the normal and inverse Gauss, where it is written out
explicitly). Note that mle are not available for the dispersion
parameter of the gamma and inverse Gauss, although this makes vary
little difference in almost all cases. Thus, you just need to feed the
fitted values (and, if appropriate, the dispersion estimate) into the
corresponding density function without summing.
  Cheers, Jim

> Thanks for any help/suggestion/tip,
>     Bruno
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 



From gomez at hsc.kuniv.edu.kw  Mon Jan 19 11:30:40 2004
From: gomez at hsc.kuniv.edu.kw (Gomez J. Edison)
Date: Mon, 19 Jan 2004 13:30:40 +0300
Subject: [R] Relative risk using GAM
Message-ID: <000c01c3de77$494e2b40$36468d8b@hscnet.kuniv.edu.kw>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040119/ed5bb491/attachment.pl

From angel_lul at hotmail.com  Mon Jan 19 12:17:48 2004
From: angel_lul at hotmail.com (Angel -)
Date: Mon, 19 Jan 2004 11:17:48 +0000
Subject: [R] png support on R debian sid 1.8.1 binary
Message-ID: <LAW11-F20F4eNuXK5Aj000198cd@hotmail.com>

I have updated my R to the current R version (1.8.1) using apt-get of the R 
binaries for debian sid in cran.
Now, when I do:
png(file="myplot.png")
I get:
Error in X11(paste("png::", filename, sep = ""), width, height, pointsize,  
:
        unable to start device PNG
In addition: Warning message:
No png support in this version of R

what do I have to do to get the png support?
Thanks,
Angel

_________________________________________________________________
Express yourself with cool new emoticons http://www.msn.co.uk/specials/myemo



From Gilles.Guillot at inapg.inra.fr  Mon Jan 19 12:19:06 2004
From: Gilles.Guillot at inapg.inra.fr (Guillot Gilles)
Date: Mon, 19 Jan 2004 12:19:06 +0100
Subject: [R] memory limitation with Fortran interface
Message-ID: <200401191219.06984.Gilles.Guillot@inapg.inra.fr>

Hi,

I'm using R 7.0 under Linux as a programming interface to Fortran (g77 
v0.5.24).
Basically, what I want to do is to call a fortran subroutine of mine 
which performs MCMC computations.
Apparently I'm getting into memory management problems.

To track the problem I wrote  the following small Fortran subroutine 
(saved as test.f) : 

      subroutine test(n,p)
      implicit none
      integer n,p,i,j
      real x(n,p)
      do i=1,n
         do j=1,p
            x(i,j) = 0
            enddo
         enddo
      end

I compiled it by : 
g77 -c test.f

then I called it from R with :

n <- 10000
p <- 1000
system("R CMD SHLIB ~/test.o")
dyn.load("~/test.so")
out.res<- .Fortran("test",
                   as.integer(n),
                   as.integer(p)
                   )

causing R breakdown with the following message : 

Segmentation fault

I don't understand why this subroutine causes segmentartion fault 
as its execution requires much less memory than what is existing  on my 
machine (RAM 512 Mo RAM + swap 512 Mo ).

More generally, it seems that memory limitations are stronger
when calling fortran code from R than when executing 
the same Fortran subroutine from a bash command line.


Gilles



From gb at stat.umu.se  Mon Jan 19 12:48:18 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 19 Jan 2004 12:48:18 +0100
Subject: [R] memory limitation with Fortran interface
In-Reply-To: <200401191219.06984.Gilles.Guillot@inapg.inra.fr>
References: <200401191219.06984.Gilles.Guillot@inapg.inra.fr>
Message-ID: <20040119114818.GA22339@stat.umu.se>

On Mon, Jan 19, 2004 at 12:19:06PM +0100, Guillot Gilles wrote:
> Hi,
> 
> I'm using R 7.0 under Linux as a programming interface to Fortran (g77 
> v0.5.24).
> Basically, what I want to do is to call a fortran subroutine of mine 
> which performs MCMC computations.
> Apparently I'm getting into memory management problems.
> 
> To track the problem I wrote  the following small Fortran subroutine 
> (saved as test.f) : 
> 
>       subroutine test(n,p)
>       implicit none
>       integer n,p,i,j
>       real x(n,p)
        ^^^^^^^^^^^

Two errors here:

1. You must allocate memory for x in the calling R function and have x as
an argument to 'test'

2. Use double precision ('double' in R)

Another recommendation is to write an  R  package for tasks like yours.
It is easier than you may think; see 'Writing R extensions'.

G?ran

>       do i=1,n
>          do j=1,p
>             x(i,j) = 0
>             enddo
>          enddo
>       end
> 
> I compiled it by : 
> g77 -c test.f
> 
> then I called it from R with :
> 
> n <- 10000
> p <- 1000
> system("R CMD SHLIB ~/test.o")
> dyn.load("~/test.so")
> out.res<- .Fortran("test",
>                    as.integer(n),
>                    as.integer(p)
>                    )
> 
> causing R breakdown with the following message : 
> 
> Segmentation fault
> 
> I don't understand why this subroutine causes segmentartion fault 
> as its execution requires much less memory than what is existing  on my 
> machine (RAM 512 Mo RAM + swap 512 Mo ).
> 
> More generally, it seems that memory limitations are stronger
> when calling fortran code from R than when executing 
> the same Fortran subroutine from a bash command line.
> 
> 
> Gilles
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From Torsten.Hothorn at rzmail.uni-erlangen.de  Mon Jan 19 14:57:43 2004
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon, 19 Jan 2004 14:57:43 +0100 (CET)
Subject: [R] multcomp, simint, simtest and computation duration
In-Reply-To: <002901c3dde1$45f1a3f0$e0bc3151@PC728329681112>
References: <002901c3dde1$45f1a3f0$e0bc3151@PC728329681112>
Message-ID: <Pine.LNX.4.51.0401191455430.21733@artemis.imbe.med.uni-erlangen.de>

> Dear R-listers,
>
> I am trying to compute simultaneous confidence intervals with simint from the package multcomp. 230 measures (abundance) have been taken in 23 sites (factor) of a data.frame (donnees: a file can be sent on request, saved with save(donnees,file="donnees")). I would like to get all pairwise comparisons with :
>
> mc<- simint(ren~ID,type="Tukey",data=donnees)
>

you try to solve a (23^2  - 23) = 506 dimensional integration problem via
some form of Monte-Carlo technique. If the sample sizes in are balanced,
you can use the `TukeyHSD' function.

Torsten

> I cannot get a result in a reasonable time (after 2 hours the computer was still working and I interrupted the process).
>
> Can anybody tell me if there is some capacity limitation for simint (as well as for simtest)? Multicomp of Splus handles the problem adequately in a short time, but Splus is practically not accessible for student training...
>
> Kind regards,
>
> Patrick Giraudoux
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From arne.gjuvsland at cigene.no  Mon Jan 19 15:07:39 2004
From: arne.gjuvsland at cigene.no (Arne Gjuvsland)
Date: Mon, 19 Jan 2004 15:07:39 +0100
Subject: [R] Compiling R, cannot open vars.mk
Message-ID: <6.0.1.1.0.20040119142018.025aaa10@iha.nlh.no>


Hi!

I am trying to compile R-1.8.1 on an alphaserver running Tru64 Unix.
I use the compilers cc,cxx and f77. After the compilation
I try: make check
and get the following message:

Make: Cannot open /share/make/vars.mk.  Stop.

Does anyone have any suggestions on why?

Regards
Arne Gjuvsland



From bates at stat.wisc.edu  Mon Jan 19 15:37:37 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 19 Jan 2004 08:37:37 -0600
Subject: [R] multcomp, simint, simtest and computation duration
In-Reply-To: <Pine.LNX.4.51.0401191455430.21733@artemis.imbe.med.uni-erlangen.de>
References: <002901c3dde1$45f1a3f0$e0bc3151@PC728329681112>
	<Pine.LNX.4.51.0401191455430.21733@artemis.imbe.med.uni-erlangen.de>
Message-ID: <6rbrp0ovgu.fsf@bates4.stat.wisc.edu>

Torsten Hothorn <Torsten.Hothorn at rzmail.uni-erlangen.de> writes:

> > I am trying to compute simultaneous confidence intervals with simint from the package multcomp. 230 measures (abundance) have been taken in 23 sites (factor) of a data.frame (donnees: a file can be sent on request, saved with save(donnees,file="donnees")). I would like to get all pairwise comparisons with :
> >
> > mc<- simint(ren~ID,type="Tukey",data=donnees)
> >
> 
> you try to solve a (23^2  - 23) = 506 dimensional integration problem via
> some form of Monte-Carlo technique. If the sample sizes in are balanced,
> you can use the `TukeyHSD' function.

Even without balanced sample sizes you can use TukeyHSD, although it
is most reliable if your sample sizes are close to balanced.



From ripley at stats.ox.ac.uk  Mon Jan 19 16:24:44 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 Jan 2004 15:24:44 +0000 (GMT)
Subject: [R] Compiling R, cannot open vars.mk
In-Reply-To: <6.0.1.1.0.20040119142018.025aaa10@iha.nlh.no>
Message-ID: <Pine.LNX.4.44.0401191519110.4632-100000@gannet.stats>

On Mon, 19 Jan 2004, Arne Gjuvsland wrote:

> 
> Hi!
> 
> I am trying to compile R-1.8.1 on an alphaserver running Tru64 Unix.
> I use the compilers cc,cxx and f77. After the compilation
> I try: make check
> and get the following message:
> 
> Make: Cannot open /share/make/vars.mk.  Stop.

Some context would have been very helpful.

> Does anyone have any suggestions on why?

Do you have R_HOME set (to an empty string)?

Is this GNU make, and if not can you try GNU make?

Otherwise, more information please, including if this is GNU make
(probably not) and what directory make is working in (or at least the
preceding 10 lines of output).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fm3a004 at math.uni-hamburg.de  Mon Jan 19 17:16:16 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Mon, 19 Jan 2004 17:16:16 +0100 (MET)
Subject: [R] qda problem
Message-ID: <Pine.GSO.3.95q.1040119170940.18546C-100000@sun35.math.uni-hamburg.de>

Hi,

the following strange error appears when I use qda:

> qda1 <- qda(as.data.frame(mfilters[cvtrain,]),as.factor(traingroups))
Error: function is not a closure

That's also strange:
> qda1 <- qda(mfilters[cvtrain,],as.factor(traingroups))
Error in qda.default(mfilters[cvtrain, ], as.factor(traingroups)) : 
	length of dimnames must match that of dims

Some backgroud:
> str(mfilters[cvtrain,])
 num [1:12500, 1:12] -0.426  0.937 -1.610 -2.099  0.749 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:12500] "1" "2" "8" "9" ...
  ..$ : NULL
> str(as.factor(traingroups))
 Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
 - attr(*, "names")= chr [1:12500] "1" "2" "8" "9" ...
> str(as.data.frame(mfilters[cvtrain,]))
`data.frame':	12500 obs. of  12 variables:
 $ V1 : num  -0.426  0.937 -1.610 -2.099  0.749 ...
 $ V2 : num   0.7970 -1.9004  0.0443 -1.2074  0.4095 ...
 $ V3 : num  -0.303 -0.636 -0.806  0.639  0.363 ...
 $ V4 : num   0.130 -0.096 -0.644  0.723  0.576 ...
 $ V5 : num  -0.2942  1.4951 -0.0098  0.3253  0.3881 ...
 $ V6 : num  -0.2943 -0.6561 -0.0863 -0.0849 -0.5070 ...
 $ V7 : num   0.512 -0.618 -0.244  0.392  0.346 ...
 $ V8 : num  -0.171  0.677  0.117 -0.113  0.669 ...
 $ V9 : num   0.2289 -0.3934  0.1051  0.1545 -0.0446 ...
 $ V10: num   0.0188  0.5614 -0.2271  0.0340  0.2207 ...
 $ V11: num  -0.152  0.631  0.447  0.696  0.458 ...
 $ V12: num   0.6139 -0.9379 -1.1784  0.0802 -0.6625 ...

...looks proper to me and works without problems with svm...

Even stranger is the fact that my .R file suggests that the first command
qda1 <- qda(as.data.frame(mfilters[cvtrain,]),as.factor(traingroups))
worked in December for the same data (apart from random sampling of 
cvtrain/traingroups, but I tried more than one version), and
even under the same version of R (1.8.0).

Can anybody tell me what goes wrong now?

Best,
Christian

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From ligges at statistik.uni-dortmund.de  Mon Jan 19 17:43:16 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 19 Jan 2004 17:43:16 +0100
Subject: [R] qda problem
In-Reply-To: <Pine.GSO.3.95q.1040119170940.18546C-100000@sun35.math.uni-hamburg.de>
References: <Pine.GSO.3.95q.1040119170940.18546C-100000@sun35.math.uni-hamburg.de>
Message-ID: <400C0924.6040908@statistik.uni-dortmund.de>

Christian,

I have reported a similar problem to Brian a few weeks ago. I think it 
has been fixed in recent versions of MASS (in the VR bundle) and works 
for me with another data.frame.

Run update.packages() and try again.

I owed you an answer (you know why),
Uwe


Christian Hennig wrote:

> Hi,
> 
> the following strange error appears when I use qda:
> 
> 
>>qda1 <- qda(as.data.frame(mfilters[cvtrain,]),as.factor(traingroups))
> 
> Error: function is not a closure
> 
> That's also strange:
> 
>>qda1 <- qda(mfilters[cvtrain,],as.factor(traingroups))
> 
> Error in qda.default(mfilters[cvtrain, ], as.factor(traingroups)) : 
> 	length of dimnames must match that of dims
> 
> Some backgroud:
> 
>>str(mfilters[cvtrain,])
> 
>  num [1:12500, 1:12] -0.426  0.937 -1.610 -2.099  0.749 ...
>  - attr(*, "dimnames")=List of 2
>   ..$ : chr [1:12500] "1" "2" "8" "9" ...
>   ..$ : NULL
> 
>>str(as.factor(traingroups))
> 
>  Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
>  - attr(*, "names")= chr [1:12500] "1" "2" "8" "9" ...
> 
>>str(as.data.frame(mfilters[cvtrain,]))
> 
> `data.frame':	12500 obs. of  12 variables:
>  $ V1 : num  -0.426  0.937 -1.610 -2.099  0.749 ...
>  $ V2 : num   0.7970 -1.9004  0.0443 -1.2074  0.4095 ...
>  $ V3 : num  -0.303 -0.636 -0.806  0.639  0.363 ...
>  $ V4 : num   0.130 -0.096 -0.644  0.723  0.576 ...
>  $ V5 : num  -0.2942  1.4951 -0.0098  0.3253  0.3881 ...
>  $ V6 : num  -0.2943 -0.6561 -0.0863 -0.0849 -0.5070 ...
>  $ V7 : num   0.512 -0.618 -0.244  0.392  0.346 ...
>  $ V8 : num  -0.171  0.677  0.117 -0.113  0.669 ...
>  $ V9 : num   0.2289 -0.3934  0.1051  0.1545 -0.0446 ...
>  $ V10: num   0.0188  0.5614 -0.2271  0.0340  0.2207 ...
>  $ V11: num  -0.152  0.631  0.447  0.696  0.458 ...
>  $ V12: num   0.6139 -0.9379 -1.1784  0.0802 -0.6625 ...
> 
> ...looks proper to me and works without problems with svm...
> 
> Even stranger is the fact that my .R file suggests that the first command
> qda1 <- qda(as.data.frame(mfilters[cvtrain,]),as.factor(traingroups))
> worked in December for the same data (apart from random sampling of 
> cvtrain/traingroups, but I tried more than one version), and
> even under the same version of R (1.8.0).
> 
> Can anybody tell me what goes wrong now?
> 
> Best,
> Christian
> 
> ***********************************************************************
> Christian Hennig
> Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
> hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
> #######################################################################
> ich empfehle www.boag-online.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From edd at debian.org  Mon Jan 19 17:44:25 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 19 Jan 2004 10:44:25 -0600
Subject: [R] png support on R debian sid 1.8.1 binary
In-Reply-To: <LAW11-F20F4eNuXK5Aj000198cd@hotmail.com>
References: <LAW11-F20F4eNuXK5Aj000198cd@hotmail.com>
Message-ID: <20040119164425.GA31278@sonny.eddelbuettel.com>

On Mon, Jan 19, 2004 at 11:17:48AM +0000, Angel - wrote:
> I have updated my R to the current R version (1.8.1) using apt-get of the R 
> binaries for debian sid in cran.
> Now, when I do:
> png(file="myplot.png")
> I get:
> Error in X11(paste("png::", filename, sep = ""), width, height, pointsize,  
> :
>        unable to start device PNG
> In addition: Warning message:
> No png support in this version of R

Confirmed -- it's a bug in the Debian package. I'll upload a new revision. [
Incidentally, my unreleased 1.9.0 snapshots already have the following
changelog entry:

  * debian/control: Added to Build-Depends
     libpaper-utils for paperconf
     libjpeg62-dev for jpeg (thanks to Kurt Hornik for the suggestion)
     libprce3-dev for pcre
     linpng12-dev for png
     zlib1g-dev for zlib 
     
]     
	   
> what do I have to do to get the png support?

Either one of a) wait for 1.8.1-2, b) try the testing build available on
CRAN which may have png support or c) re-build it yourself.

My apologies for the inconvenience.

Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From v.demart at libero.it  Mon Jan 19 17:51:38 2004
From: v.demart at libero.it (v.demart@libero.it)
Date: Mon, 19 Jan 2004 17:51:38 +0100
Subject: [R] Some more help needed...
Message-ID: <HRQXI2$4D5EE15138C9C625E17BC8F363C216EC@libero.it>

As an absolute beginner, still reading  "Modern Applied Statistics with S" and exercising with its examples, I'm frequently stopped by what it looks to be R poor help system (or is it my gigantic ignorance?). I mean that using help many arguments of a command seems to be given for granted like for instance:
...............................
?lines
 lines(x, ...)

     ## Default S3 method:
     lines(x, y = NULL, type = "l", col = par("col"),
           lty = par("lty"), ...)

Arguments:

    x, y: coordinate vectors of points to join.

    type: character indicating the type of plotting; actually any of
          the 'type's as in 'plot'.

     col: color to use. This can be vector of length greater than one,
          but only the first value will be used.

     lty: line type to use.

     ...: Further graphical parameters (see 'par') may also be supplied
          as arguments, particularly, line type, 'lty' and line width,
          'lwd'.
................................

How could I quickly know during an R-session what values should be "col" set to have red, how could I set "lty" etc.?

Vittorio



From merser at image.dk  Mon Jan 19 18:04:40 2004
From: merser at image.dk (=?iso-8859-1?Q?S=F8ren_Merser?=)
Date: Mon, 19 Jan 2004 18:04:40 +0100
Subject: [R] ftable to LaTeX
Message-ID: <000e01c3deae$c9543280$8b00a8c0@IBM>

hi there

is there a way to convert objects of class ftable into LaTex code
preserving the 'look' with row and column infomation?

xtable() {xtable} can't handle such objects and latex() {Hmisc} just texify
the number matrix,
without row/column information

regards soren



From fm3a004 at math.uni-hamburg.de  Mon Jan 19 18:19:13 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Mon, 19 Jan 2004 18:19:13 +0100 (MET)
Subject: [R] Some more help needed...
In-Reply-To: <HRQXI2$4D5EE15138C9C625E17BC8F363C216EC@libero.it>
Message-ID: <Pine.GSO.3.95q.1040119181655.18546D-100000@sun35.math.uni-hamburg.de>

Try help(par).

Christian

On Mon, 19 Jan 2004, v.demart at libero.it wrote:

> As an absolute beginner, still reading  "Modern Applied Statistics with S" and exercising with its examples, I'm frequently stopped by what it looks to be R poor help system (or is it my gigantic ignorance?). I mean that using help many arguments of a command seems to be given for granted like for instance:
> ...............................
> ?lines
>  lines(x, ...)
> 
>      ## Default S3 method:
>      lines(x, y = NULL, type = "l", col = par("col"),
>            lty = par("lty"), ...)
> 
> Arguments:
> 
>     x, y: coordinate vectors of points to join.
> 
>     type: character indicating the type of plotting; actually any of
>           the 'type's as in 'plot'.
> 
>      col: color to use. This can be vector of length greater than one,
>           but only the first value will be used.
> 
>      lty: line type to use.
> 
>      ...: Further graphical parameters (see 'par') may also be supplied
>           as arguments, particularly, line type, 'lty' and line width,
>           'lwd'.
> ................................
> 
> How could I quickly know during an R-session what values should be "col" set to have red, how could I set "lty" etc.?
> 
> Vittorio
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From abunn at montana.edu  Mon Jan 19 18:25:02 2004
From: abunn at montana.edu (Andy Bunn)
Date: Mon, 19 Jan 2004 10:25:02 -0700
Subject: [R] Some more help needed...
In-Reply-To: <HRQXI2$4D5EE15138C9C625E17BC8F363C216EC@libero.it>
Message-ID: <000a01c3deb1$3dc6c400$78f05a99@msu.montana.edu>

The R help is sublime - which can be lost on the beginner (it was on
me). See Chapter 12 Graphical procedures of the introduction to R manual
(http://cran.r-project.org/manuals.html). Then read the rest of the
manual before bed.

As for getting red and a solid line?
plot(1:100, log(1:100), type = "l", col = "red", lty = "solid")

Good luck, Andy



From spencer.graves at pdf.com  Mon Jan 19 18:25:36 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 19 Jan 2004 09:25:36 -0800
Subject: [R] Some more help needed...
In-Reply-To: <HRQXI2$4D5EE15138C9C625E17BC8F363C216EC@libero.it>
References: <HRQXI2$4D5EE15138C9C625E17BC8F363C216EC@libero.it>
Message-ID: <400C1310.1010003@pdf.com>

How about the following: 

 plot(1:11, col=1:11, cex=2, lwd=4)
 plot(1:4, col=c("red","green",'blue', 'orange'), cex=2, lwd=4)

      hope this helps.  spencer graves

v.demart at libero.it wrote:

>As an absolute beginner, still reading  "Modern Applied Statistics with S" and exercising with its examples, I'm frequently stopped by what it looks to be R poor help system (or is it my gigantic ignorance?). I mean that using help many arguments of a command seems to be given for granted like for instance:
>...............................
>?lines
> lines(x, ...)
>
>     ## Default S3 method:
>     lines(x, y = NULL, type = "l", col = par("col"),
>           lty = par("lty"), ...)
>
>Arguments:
>
>    x, y: coordinate vectors of points to join.
>
>    type: character indicating the type of plotting; actually any of
>          the 'type's as in 'plot'.
>
>     col: color to use. This can be vector of length greater than one,
>          but only the first value will be used.
>
>     lty: line type to use.
>
>     ...: Further graphical parameters (see 'par') may also be supplied
>          as arguments, particularly, line type, 'lty' and line width,
>          'lwd'.
>................................
>
>How could I quickly know during an R-session what values should be "col" set to have red, how could I set "lty" etc.?
>
>Vittorio
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From p.dalgaard at biostat.ku.dk  Mon Jan 19 18:36:24 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Jan 2004 18:36:24 +0100
Subject: [R] Some more help needed...
In-Reply-To: <HRQXI2$4D5EE15138C9C625E17BC8F363C216EC@libero.it>
References: <HRQXI2$4D5EE15138C9C625E17BC8F363C216EC@libero.it>
Message-ID: <x2ptdfhmcn.fsf@biostat.ku.dk>

"v.demart at libero.it" <v.demart at libero.it> writes:

> As an absolute beginner, still reading  "Modern Applied Statistics with S" and exercising with its examples, I'm frequently stopped by what it looks to be R poor help system (or is it my gigantic ignorance?). I mean that using help many arguments of a command seems to be given for granted like for instance:
> ...............................
> ?lines
>  lines(x, ...)
> 
>      ## Default S3 method:
>      lines(x, y = NULL, type = "l", col = par("col"),
>            lty = par("lty"), ...)
> 
> Arguments:
> 
>     x, y: coordinate vectors of points to join.
> 
>     type: character indicating the type of plotting; actually any of
>           the 'type's as in 'plot'.
> 
>      col: color to use. This can be vector of length greater than one,
>           but only the first value will be used.
> 
>      lty: line type to use.
> 
>      ...: Further graphical parameters (see 'par') may also be supplied
>           as arguments, particularly, line type, 'lty' and line width,
>           'lwd'.
> ................................
> 
> How could I quickly know during an R-session what values should be "col" set to have red, how could I set "lty" etc.?

Well, you might take a hint and look at ?par, in which this is in fact 
explained. The above text is not saying that very explicitly, I agree. 

However, it could be a good idea if we found a nice way of integrating
this sort of tabular material in the help system. The case that really
annoys me is that to get at the va?ues for 'pch', you need to run
example(points), which is both nonobvious and disruptive if you are in
the middle of constructing a complex plot command.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From eugenedalt at yahoo.com  Mon Jan 19 18:43:46 2004
From: eugenedalt at yahoo.com (eugene dalt)
Date: Mon, 19 Jan 2004 09:43:46 -0800 (PST)
Subject: [R] January advanced R/Splus course in Boston?
Message-ID: <20040119174346.77803.qmail@web10913.mail.yahoo.com>

Hello,

I learnt there's an advanced R/Splus course in Boston
this january. Anyone got the announcement? please
kindly forward it to me.

Best, Eugene



From feh3k at spamcop.net  Mon Jan 19 18:53:30 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Mon, 19 Jan 2004 12:53:30 -0500
Subject: [R] ftable to LaTeX
In-Reply-To: <000e01c3deae$c9543280$8b00a8c0@IBM>
References: <000e01c3deae$c9543280$8b00a8c0@IBM>
Message-ID: <20040119125330.444b34c3.feh3k@spamcop.net>

On Mon, 19 Jan 2004 18:04:40 +0100
S?ren Merser <merser at image.dk> wrote:

> hi there
> 
> is there a way to convert objects of class ftable into LaTex code
> preserving the 'look' with row and column infomation?
> 
> xtable() {xtable} can't handle such objects and latex() {Hmisc} just
> texify the number matrix,
> without row/column information

Please check again.  latex( ) has all kinds of row/column identifier
optionss.

-FH

> 
> regards soren



From timh at insightful.com  Mon Jan 19 18:54:13 2004
From: timh at insightful.com (Tim Hesterberg)
Date: 19 Jan 2004 09:54:13 -0800
Subject: [R] Re: [S] January advanced R/Splus course in Boston?
In-Reply-To: <20040119174346.77803.qmail@web10913.mail.yahoo.com> (message
	from eugene dalt on Mon, 19 Jan 2004 09:43:46 -0800 (PST))
References: <20040119174346.77803.qmail@web10913.mail.yahoo.com>
Message-ID: <SE2KEXCH01b6KZmcK8r00003a40@se2kexch01.insightful.com>

>I learnt there's an advanced R/Splus course in Boston
>this january. Anyone got the announcement? please
>kindly forward it to me.

I'm giving an Advanced Programming in S-PLUS course in Boston and San
Francisco in March.  See:
	http://www.insightful.com/services/training.asp
	http://www.insightful.com/services/schedule.asp
	http://www.insightful.com/services/course.asp?CID=37

I'm also giving a Bootstrap Methods and Permutation Tests course,
same places.

Tim Hesterberg

========================================================
| Tim Hesterberg       Research Scientist              |
| timh at insightful.com  Insightful Corp.                |
| (206)802-2319        1700 Westlake Ave. N, Suite 500 |
| (206)802-2500 (fax)  Seattle, WA 98109-3044, U.S.A.  |
|                      www.insightful.com/Hesterberg   |



From elvis at xlsolutions-corp.com  Mon Jan 19 19:12:06 2004
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Mon, 19 Jan 2004 11:12:06 -0700
Subject: [R] Course***Advanced R/Splus Programming***Boston,
	January 2004 by XLSolutions Corp
Message-ID: <20040119181206.19490.qmail@webmail-2-1.secureserver.net>

Happy New Year
XSolutions Corp (www.xlsolutions-corp.com) is proud to announce
a 2-day "Advanced R/Splus programming" taught by R Development
Core Team Guru.
 
*********Boston ----------  January 29-30, 2004
*********Washington DC ----------  TBD
            Reserve your seat Now  (payment due after the class)
Registration:
www.xlsolutions-corp.com/training.htm
Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578
Course outline:
- Overview of R/S fundamentals: Syntax and Semantics
- Class and Inheritance in R/S-Plus
- Concepts, Construction and good use of language objects
- Coercion and efficiency
- Object-oriented programming in R and S-Plus
- Advanced manipulation tools: Parse, Deparse, Substitute, etc.
- How to fully take advantage of Vectorization
- Generic and Method Functions; S4 (S-Plus 6)
- Search path, databases and frames Visibility
- Working with large objects
- Handling Properly Recursion and iterative calculations
- Managing loops; For (S-Plus) and for() loops
- Consequences of Lazy Evaluation
- Efficient Code practices for large computations
- Memory management and Resource monitoring
- Writing R/S-Plus functions to call compiled code
- Writing and debugging compiled code for R/S-Plus system
- Connecting R/S-Plus to External Data Sources
- Understanding the structure of model fitting functions in R/S-Plus
- Designing and Packaging efficiently 
 Early-bird group research fee: $995!
This course will also deal with lots of S-Plus efficiency issues and
any special topics from participants is welcome.
Please let us know if you and your colleagues are interested in this
class to take advantage of group discount. Over half of the seats in
both classes are currently reserved.  Register now to secure your seat 
in this course!
 
Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com



From tvandaelen at scitegic.com  Mon Jan 19 19:23:52 2004
From: tvandaelen at scitegic.com (Ton van Daelen)
Date: Mon, 19 Jan 2004 10:23:52 -0800
Subject: [R] Persistence for statistical models
Message-ID: <830D8D4719112B418ABBC3A0EBA958123151D5@webmail.scitegic.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040119/82b16440/attachment.pl

From eugenedalt at yahoo.com  Mon Jan 19 19:26:14 2004
From: eugenedalt at yahoo.com (eugene dalt)
Date: Mon, 19 Jan 2004 10:26:14 -0800 (PST)
Subject: [R] Summary***Re: [S] January advanced R/Splus course in Boston?
In-Reply-To: <20040119174346.77803.qmail@web10913.mail.yahoo.com>
Message-ID: <20040119182614.38716.qmail@web10903.mail.yahoo.com>

Wow that was fast. Thank you Tim, Dana and Erin.

I thought I give the summary here..The January
advanced R/Splus course in Boston taught by an R guru
is offered by xlsolutions corp. Cost is $995. Contact
person: sue at xlsolutions-corp.com.   

--- eugene dalt <eugenedalt at yahoo.com> wrote:
> Hello,
> 
> I learnt there's an advanced R/Splus course in
> Boston
> this january. Anyone got the announcement? please
> kindly forward it to me.
> 
> Best, Eugene
> 
> __________________________________
>
--------------------------------------------------------------------
> This message was distributed by
> s-news at lists.biostat.wustl.edu.  To
> unsubscribe send e-mail to
> s-news-request at lists.biostat.wustl.edu with



From andy_liaw at merck.com  Mon Jan 19 19:36:39 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 19 Jan 2004 13:36:39 -0500
Subject: [R] Persistence for statistical models
Message-ID: <3A822319EB35174CA3714066D590DCD504AF764A@usrymx25.merck.com>

You can do that with any R objects by using save(), then load() or attach()
to get them back into R.

HTH,
Andy

> From: Ton van Daelen
> 
> Hi there -
> 
> Is there a way to write statistical models (trees, na?ve 
> Bayes, SVM, etc) to a file and import them again without loss 
> of information? 
> 
> Thanks - Ton
> 
> Ton van Daelen, PhD
> Director, Application Support
> Tel: (858) 279-8800 ext 217
> Fax: (858) 279-8804
> 
> Web: www.scitegic.com
> 
> Register now for the 2004 Pipeline Pilot user group meeting 
> Jan 28-30 in San Diego: http://www.scitegic.com/UGMSD2004/


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From laura at env.leeds.ac.uk  Mon Jan 19 20:27:35 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Mon, 19 Jan 2004 19:27:35 +0000 (GMT)
Subject: [R] Returning data in matrix form
Message-ID: <Pine.LNX.4.44.0401191919250.29307-100000@env-pc-phd13>

I am trying to perform the following calculation for a very
large time series data set:

x<-unit(length*data.frame.a*data.frame.b,"cm")

data.frame.a and data.frame.b are of the same dimension, and I wish to
perform the calculation in one step so that "x" is returned as a
matrix/data.frame of equal dimension.

I have tried a couple of methods for this, (subsetting data.frame.a and
data.frame.b and performing the calculation on a column by column basis
for instance, and trying to loop a function over column data), but each
time I am returned with a list for x rather than a data frame.

Sorry if this is a stupid question, I have looked through some R
literature but don't seem able to find the answer.

Thank you for any help.

Laura



From baron at psych.upenn.edu  Mon Jan 19 20:36:19 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Mon, 19 Jan 2004 14:36:19 -0500
Subject: [R] Returning data in matrix form
In-Reply-To: <Pine.LNX.4.44.0401191919250.29307-100000@env-pc-phd13>
References: <Pine.LNX.4.44.0401191919250.29307-100000@env-pc-phd13>
Message-ID: <20040119193619.GA22194@mail1.sas.upenn.edu>

On 01/19/04 19:27, Laura Quinn wrote:
>I am trying to perform the following calculation for a very
>large time series data set:
>
>x<-unit(length*data.frame.a*data.frame.b,"cm")
>
>data.frame.a and data.frame.b are of the same dimension, and I wish to
>perform the calculation in one step so that "x" is returned as a
>matrix/data.frame of equal dimension.

Sounds like mapply() would be useful.  It works on columns of
data frames.  The default is "simplify=TRUE" so it will try to
return a vector or matrix.

Jon
--
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From p.connolly at hortresearch.co.nz  Mon Jan 19 20:56:29 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 20 Jan 2004 08:56:29 +1300
Subject: [R] Some more help needed...
In-Reply-To: <x2ptdfhmcn.fsf@biostat.ku.dk>;
	from p.dalgaard@biostat.ku.dk on Mon, Jan 19, 2004 at 06:36:24PM
	+0100
References: <HRQXI2$4D5EE15138C9C625E17BC8F363C216EC@libero.it>
	<x2ptdfhmcn.fsf@biostat.ku.dk>
Message-ID: <20040120085629.C935@hortresearch.co.nz>

On Mon, 19-Jan-2004 at 06:36PM +0100, Peter Dalgaard wrote:

|> "v.demart at libero.it" <v.demart at libero.it> writes:
|> 
|> > As an absolute beginner, still reading "Modern Applied Statistics
|> > with S" and exercising with its examples, I'm frequently stopped
|> > by what it looks to be R poor help system (or is it my gigantic
|> > ignorance?). I mean that using help many arguments of a command
|> > seems to be given for granted like for instance:
|> > ...............................
|> > ?lines
|> >  lines(x, ...)
|> > 
|> >      ## Default S3 method:
|> >      lines(x, y = NULL, type = "l", col = par("col"),
|> >            lty = par("lty"), ...)
|> > 
|> > Arguments:
|> > 
|> >     x, y: coordinate vectors of points to join.
|> > 
|> >     type: character indicating the type of plotting; actually any of
|> >           the 'type's as in 'plot'.
|> > 
|> >      col: color to use. This can be vector of length greater than one,
|> >           but only the first value will be used.
|> > 
|> >      lty: line type to use.
|> > 
|> >      ...: Further graphical parameters (see 'par') may also be supplied
|> >           as arguments, particularly, line type, 'lty' and line width,
|> >           'lwd'.
|> > ................................
|> > 
|> > How could I quickly know during an R-session what values should be "col" set to have red, how could I set "lty" etc.?
|> 
|> Well, you might take a hint and look at ?par, in which this is in fact 
|> explained. The above text is not saying that very explicitly, I agree. 

... that hint being given a little further down the help for lines,
where it says:


See Also:

     'points', 'plot', and the underlying "primitive" 'plot.xy'.

     'par' for how to specify colors.


I can't think of a way that makes it easier to get to than that.


|> 
|> However, it could be a good idea if we found a nice way of
|> integrating this sort of tabular material in the help system. The
|> case that really annoys me is that to get at the va?ues for 'pch',
|> you need to run example(points), which is both nonobvious and
|> disruptive if you are in the middle of constructing a complex plot
|> command.

Even in that case, it's not a big deal to run a separate R session in
another workspace (or even better, viewport in the pre-Gnome2 days)
where such ancillary tasks can run.  There are OS limitations, of
course. 


-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From p.dalgaard at biostat.ku.dk  Mon Jan 19 21:23:03 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Jan 2004 21:23:03 +0100
Subject: [R] Returning data in matrix form
In-Reply-To: <20040119193619.GA22194@mail1.sas.upenn.edu>
References: <Pine.LNX.4.44.0401191919250.29307-100000@env-pc-phd13>
	<20040119193619.GA22194@mail1.sas.upenn.edu>
Message-ID: <x2hdyrhemw.fsf@biostat.ku.dk>

Jonathan Baron <baron at psych.upenn.edu> writes:

> On 01/19/04 19:27, Laura Quinn wrote:
> >I am trying to perform the following calculation for a very
> >large time series data set:
> >
> >x<-unit(length*data.frame.a*data.frame.b,"cm")
> >
> >data.frame.a and data.frame.b are of the same dimension, and I wish to
> >perform the calculation in one step so that "x" is returned as a
> >matrix/data.frame of equal dimension.
> 
> Sounds like mapply() would be useful.  It works on columns of
> data frames.  The default is "simplify=TRUE" so it will try to
> return a vector or matrix.

Maybe, but what was ever wrong with

length*as.matrix(data.frame.a)*as.matrix(data.frame.b) 

or, possibly, as.data.frame thereof?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From vasileios_p at yahoo.gr  Mon Jan 19 22:52:11 2004
From: vasileios_p at yahoo.gr (=?iso-8859-7?q?vasilis=20pappas?=)
Date: Mon, 19 Jan 2004 21:52:11 +0000 (GMT)
Subject: [R] about power of tests
Message-ID: <20040119215211.87819.qmail@web12906.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040119/ea60634a/attachment.pl

From rossini at blindglobe.net  Mon Jan 19 23:33:01 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 19 Jan 2004 14:33:01 -0800
Subject: [R] about power of tests
In-Reply-To: <20040119215211.87819.qmail@web12906.mail.yahoo.com> (iso's
	message of "Mon, 19 Jan 2004 21:52:11 +0000 (GMT)")
References: <20040119215211.87819.qmail@web12906.mail.yahoo.com>
Message-ID: <85zncjfu1u.fsf@blindglobe.net>

=?iso-8859-7?q?vasilis=20pappas?= <vasileios_p at yahoo.gr> writes:

> Does anyone know how can I calculate power in wilcoxon.test,
> kruskal. test and oneway.test in an F? I have already found
> power.t.test for calculating power in t.test but it seems that there
> is nothing for the others. Any answer could be useful.  Thanks for
> your interest.

If you can explain exactly how you think power should be computed for
a Wilcoxon, AND it is right (as opposed to a wild ball-park off the
cuff estimate or sensitivity analysis), it'd be a nice journal
article.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From p.dalgaard at biostat.ku.dk  Tue Jan 20 00:51:50 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Jan 2004 00:51:50 +0100
Subject: [R] about power of tests
In-Reply-To: <85zncjfu1u.fsf@blindglobe.net>
References: <20040119215211.87819.qmail@web12906.mail.yahoo.com>
	<85zncjfu1u.fsf@blindglobe.net>
Message-ID: <x2u12r1oq1.fsf@biostat.ku.dk>

rossini at blindglobe.net (A.J. Rossini) writes:

> =?iso-8859-7?q?vasilis=20pappas?= <vasileios_p at yahoo.gr> writes:
> 
> > Does anyone know how can I calculate power in wilcoxon.test,
> > kruskal. test and oneway.test in an F? I have already found
> > power.t.test for calculating power in t.test but it seems that there
> > is nothing for the others. Any answer could be useful.  Thanks for
> > your interest.
> 
> If you can explain exactly how you think power should be computed for
> a Wilcoxon, AND it is right (as opposed to a wild ball-park off the
> cuff estimate or sensitivity analysis), it'd be a nice journal
> article.

Yes.

Of course the ARE (asymp.rel.efficiency) of Wilcoxon is .95 in the
Normal case, so everyones first guesstimate is to do the power
analysis for t and multiply the power by .95 - or divide desired power
by .95 and compute N. However, this is highly dependent on
distributional assumptions, and the fact that A is for asymptotic is
really important even for Normal distributions: for small samples the
RE is nowhere near the ARE, so you'd be wise to back things up with
some simulations.

We do have power.anova.test, though.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rxg218 at psu.edu  Tue Jan 20 01:07:23 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Mon, 19 Jan 2004 19:07:23 -0500
Subject: [R] graph algorithms in R
Message-ID: <1074557243.20237.2.camel@ra.chem.psu.edu>

Hi,
  I was wondering if there are any packages available that can represent
mathematical graphs along with functions to manipulate them? Google
did'nt turn up anything ( I may be asking too much of R :-/ )

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Q: What's yellow, linear, normed and complete?
A: A Bananach space.



From rossini at blindglobe.net  Tue Jan 20 01:37:14 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 19 Jan 2004 16:37:14 -0800
Subject: [R] graph algorithms in R
In-Reply-To: <1074557243.20237.2.camel@ra.chem.psu.edu> (Rajarshi Guha's
	message of "Mon, 19 Jan 2004 19:07:23 -0500")
References: <1074557243.20237.2.camel@ra.chem.psu.edu>
Message-ID: <85llo38ngl.fsf@blindglobe.net>


graph and Rgraphviz in BioConductor; see www.bioconductor.org


Rajarshi Guha <rxg218 at psu.edu> writes:

> Hi,
>   I was wondering if there are any packages available that can represent
> mathematical graphs along with functions to manipulate them? Google
> did'nt turn up anything ( I may be asking too much of R :-/ )
>
> Thanks,
>
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> Q: What's yellow, linear, normed and complete?
> A: A Bananach space.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From tsing at mpi-sb.mpg.de  Tue Jan 20 01:58:20 2004
From: tsing at mpi-sb.mpg.de (Tobias Sing)
Date: Tue, 20 Jan 2004 01:58:20 +0100
Subject: [R] graph algorithms in R
In-Reply-To: <1074557243.20237.2.camel@ra.chem.psu.edu>
References: <1074557243.20237.2.camel@ra.chem.psu.edu>
Message-ID: <200401200158.20341.tsing@mpi-sb.mpg.de>

> I was wondering if there are any packages available that can represent
> mathematical graphs along with functions to manipulate them? Google
> did'nt turn up anything ( I may be asking too much of R :-/ )

I was looking for the same thing the other day, and found that a graph package 
for R is being developed as part of the bioconductor project. However, I 
haven't tried it yet, so I don't know about the status (judging from the 
function list one shouldn't expect a comprehensive collection of graph 
algorithms, but at least the base structures and some random graph stuff seem 
to be implemented already). There is also a package for visualization, 
Rgraphviz.

http://www.bioconductor.org/
http://www.bioconductor.org/repository/release1.3/package/html/graph.html
http://www.bioconductor.org/repository/release1.2/package/html/Rgraphviz.html

Tobias


__________________________________________
Tobias Sing
Diploma Student           

Computational Biology Group
Max-Planck-Institut f?r Informatik
Stuhlsatzenhausweg 85
66123 Saarbr?cken, Germany

Also affiliated with:
Machine Learning and Natural Language Processing Group
Institut f?r Informatik  
Albert-Ludwigs-Universit?t Freiburg, Germany

Phone: +49 681 9325 314
Fax: +49 681 9325 399
E-mail: tsing at mpi-sb.mpg.de
WWW: http://www.mpi-sb.mpg.de/units/ag3/



From rossini at blindglobe.net  Tue Jan 20 02:26:19 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 19 Jan 2004 17:26:19 -0800
Subject: [R] graph algorithms in R
In-Reply-To: <200401200158.20341.tsing@mpi-sb.mpg.de> (Tobias Sing's message
	of "Tue, 20 Jan 2004 01:58:20 +0100")
References: <1074557243.20237.2.camel@ra.chem.psu.edu>
	<200401200158.20341.tsing@mpi-sb.mpg.de>
Message-ID: <85r7xvxves.fsf@blindglobe.net>

Tobias Sing <tsing at mpi-sb.mpg.de> writes:

>> I was wondering if there are any packages available that can represent
>> mathematical graphs along with functions to manipulate them? Google
>> did'nt turn up anything ( I may be asking too much of R :-/ )
>
> I was looking for the same thing the other day, and found that a graph package 
> for R is being developed as part of the bioconductor project. However, I 
> haven't tried it yet, so I don't know about the status (judging from the 
> function list one shouldn't expect a comprehensive collection of graph 
> algorithms, but at least the base structures and some random graph stuff seem 
> to be implemented already). There is also a package for visualization, 
> Rgraphviz.
>
> http://www.bioconductor.org/
> http://www.bioconductor.org/repository/release1.3/package/html/graph.html
> http://www.bioconductor.org/repository/release1.2/package/html/Rgraphviz.html

I almost forgot the wrappers to BOOST-Graph (the BOOST graph
library), RGBL, also in Bioconductor.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From mai at ms.uky.edu  Tue Jan 20 03:20:02 2004
From: mai at ms.uky.edu (Mai Zhou)
Date: Mon, 19 Jan 2004 21:20:02 -0500 (EST)
Subject: [R] Buckley-James censored regression without intercept
Message-ID: <200401200220.i0K2K2An013191@t5.ms.uky.edu>

Hi, dear R-help, I want to fit a Buckley-James censored regression
without intercept.
The function bj() inside the Design library have to have an intercept,
I try  Surv(y,d)~ 0 + x , or -1+x, or x-1,  none works.

Any suggestions? Is there another BJ() code out there that do not
have to have an intercept? Or may be it is easier to modify the bj()?
I need the estimator only, no need of var estimate or plot.

Thanks.

Mai Zhou
mai at ms.uky.edu



From firat.ozdemir at deu.edu.tr  Tue Jan 20 10:49:34 2004
From: firat.ozdemir at deu.edu.tr (=?windows-1254?Q?f=FDrat_=F6zdemir?=)
Date: Tue, 20 Jan 2004 11:49:34 +0200
Subject: [R] avas
Message-ID: <003501c3df3a$d9190a60$50421bc2@frat>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040120/d10c025f/attachment.pl

From fm3a004 at math.uni-hamburg.de  Tue Jan 20 10:59:05 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Tue, 20 Jan 2004 10:59:05 +0100 (MET)
Subject: [R] random forest question
Message-ID: <Pine.GSO.3.95q.1040120105328.20237A-100000@sun35.math.uni-hamburg.de>

Hi,

here are three results of random forest (version 4.0-1).
The results seem to be more or less the same which is strange because I
changed the classwt. 
I hoped that for example classwt=c(0.45,0.1,0.45) would result in fewer
cases classified as class 2. Did I understand something wrong?

Christian

x1rf <- randomForest(x=as.data.frame(mfilters[cvtrain,]),
                     y=as.factor(traingroups),
                     xtest=as.data.frame(mfilters[cvtest,]),
                     ytest=as.factor(testgroups))
> x1rf$test$confusion
     1    2  3 class.error
1 9954   30 19  0.00489853
2  139 1854  0  0.06974410
3  420    0 84  0.83333333
x1rf <- randomForest(x=as.data.frame(mfilters[cvtrain,]),
                     y=as.factor(traingroups),
                     xtest=as.data.frame(mfilters[cvtest,]),
                     ytest=as.factor(testgroups),classwt=c(0.45,0.1,0.45))
> x1rf$test$confusion
     1    2  3 class.error
1 9952   31 20  0.00509847
2  164 1828  1  0.08278976
3  440    0 64  0.87301587
x1rf <- randomForest(x=as.data.frame(mfilters[cvtrain,]),
                     y=as.factor(traingroups),
                     xtest=as.data.frame(mfilters[cvtest,]),

ytest=as.factor(testgroups),classwt=c(0.49,0.02,0.49))
> x1rf$test$confusion
     1    2  3 class.error
1 9948   35 20  0.00549835
2  170 1823  0  0.08529854
3  439    0 65  0.87103175



***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From wolfram at fischer-zim.ch  Tue Jan 20 11:14:50 2004
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Tue, 20 Jan 2004 11:14:50 +0100
Subject: [R] lattice: adding text between grouped panels?
Message-ID: <20040120101450.GA5234@s1x.local>

How one can add a text (e.g. the labels of an axis)
in a space between grouped panels which was created
by using the argument ``between''?

Example:
	data(barley)
	dotplot(variety ~ yield | site * year, data=barley,
		between=list(x=c( 0, 0, 6 ))
How to add labels for the y axis in the space in the middle?


Thanks

Wolfram



From feh3k at spamcop.net  Tue Jan 20 13:01:03 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 20 Jan 2004 07:01:03 -0500
Subject: [R] avas
In-Reply-To: <003501c3df3a$d9190a60$50421bc2@frat>
References: <003501c3df3a$d9190a60$50421bc2@frat>
Message-ID: <20040120070103.57cffe94.feh3k@spamcop.net>

On Tue, 20 Jan 2004 11:49:34 +0200
f?rat ?zdemir <firat.ozdemir at deu.edu.tr> wrote:

> Hi,
> I wanted  to make a transformation with "avas" and "ace" but  saw a
> message " couldn't find function "avas"  "
>  what are the possibble reasons of this case?
> It may be a basic question but unfortunately I am very new in R.
> Thanks for your helps
>  Regards

install.packages('acepack')  # once
library(acepack)

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From ozric at web.de  Tue Jan 20 13:15:28 2004
From: ozric at web.de (Christian Schulz)
Date: Tue, 20 Jan 2004 13:15:28 +0100
Subject: [R] Roracle pre-compile error?
Message-ID: <200401201315.28249.ozric@web.de>

Hi,

trying ROracle failed? I'm using Oracle.8.1.7 which is on another machine.
With Tora i get access to the database what i wish to get with R-Project, too. 

What does the message mean?
"Oracle pre-compiler proc not in /opt/oracle/OraHome1/bin/proc
you may not be able to compile ROracle" 
I'm using linux sue9 and R.1.8.1.

many thanks for any help! 

[snip]
install.packages("ROracle")
trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
....
....
* Installing *source* package 'ROracle' ...
creating cache ./config.cache
checking how to run the C preprocessor... cc -E
ROracle configuration warning:
Oracle pre-compiler proc not in /opt/oracle/OraHome1/bin/proc
you may not be able to compile ROracle

updating cache ./config.cache
creating ./config.status
creating src/Makevars
creating src/Makefile
** libs
R CMD COMPILE RS-DBI.c
make[1]: Entering directory `/tmp/R.INSTALL.2743/ROracle/src'
gcc -I/usr/lib/R/include -I/usr/local/include -I/opt/gnome/include 
-D__NO_MATH_INLINES -mieee-fp -fPIC -c RS-DBI.c -o RS-DBI.o
make[1]: Leaving directory `/tmp/R.INSTALL.2743/ROracle/src'
proc CODE=ANSI_C MODE=ORACLE INCLUDE=/usr/lib/R/include \
PARSE=NONE LINES=false RS-Oracle.pc
make: proc: Kommando nicht gefunden
make: *** [RS-Oracle.c] Fehler 127
ERROR: compilation failed for package 'ROracle'
** Removing '/usr/lib/R/library/ROracle'

Delete downloaded files (y/N)? y

Warning message: 
Installation of package ROracle had non-zero exit status in: 
install.packages("ROracle")



From kamoun_wassim at yahoo.fr  Tue Jan 20 13:15:05 2004
From: kamoun_wassim at yahoo.fr (=?iso-8859-1?q?Wassim=20Kamoum?=)
Date: Tue, 20 Jan 2004 13:15:05 +0100 (CET)
Subject: [R] question
Message-ID: <20040120121505.60695.qmail@web41305.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040120/98c008cd/attachment.pl

From m.mader at gsf.de  Tue Jan 20 13:15:37 2004
From: m.mader at gsf.de (Michael Mader)
Date: Tue, 20 Jan 2004 13:15:37 +0100
Subject: [R] Roracle pre-compile error?
References: <200401201315.28249.ozric@web.de>
Message-ID: <400D1BE9.749C6011@gsf.de>

Hi

as the Error message tells you: proc (the Pro*C precompiler of Oracle)
is not in the $PATH variable. Perhaps you try to compile on a Oracle
Client box w/o the complete development client?

Regards 

Michael
Christian Schulz wrote:
> 
> Hi,
> 
> trying ROracle failed? I'm using Oracle.8.1.7 which is on another machine.
> With Tora i get access to the database what i wish to get with R-Project, too.
> 
> What does the message mean?
> "Oracle pre-compiler proc not in /opt/oracle/OraHome1/bin/proc
> you may not be able to compile ROracle"
> I'm using linux sue9 and R.1.8.1.
> 
> many thanks for any help!
> 
> [snip]
> install.packages("ROracle")
> trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
> ....
> ....
> * Installing *source* package 'ROracle' ...
> creating cache ./config.cache
> checking how to run the C preprocessor... cc -E
> ROracle configuration warning:
> Oracle pre-compiler proc not in /opt/oracle/OraHome1/bin/proc
> you may not be able to compile ROracle
> 
> updating cache ./config.cache
> creating ./config.status
> creating src/Makevars
> creating src/Makefile
> ** libs
> R CMD COMPILE RS-DBI.c
> make[1]: Entering directory `/tmp/R.INSTALL.2743/ROracle/src'
> gcc -I/usr/lib/R/include -I/usr/local/include -I/opt/gnome/include
> -D__NO_MATH_INLINES -mieee-fp -fPIC -c RS-DBI.c -o RS-DBI.o
> make[1]: Leaving directory `/tmp/R.INSTALL.2743/ROracle/src'
> proc CODE=ANSI_C MODE=ORACLE INCLUDE=/usr/lib/R/include \
> PARSE=NONE LINES=false RS-Oracle.pc
> make: proc: Kommando nicht gefunden
> make: *** [RS-Oracle.c] Fehler 127
> ERROR: compilation failed for package 'ROracle'
> ** Removing '/usr/lib/R/library/ROracle'
> 
> Delete downloaded files (y/N)? y
> 
> Warning message:
> Installation of package ROracle had non-zero exit status in:
> install.packages("ROracle")
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Michael T. Mader
Institute for Bioinformatics/MIPS, GSF
Ingolstaedter Landstrasse 1
D-85764 Neuherberg
0049-89-3187-3576

response time (n.) An unbounded, random variable Tr associated with a
given TIMESHARING system and representing the putative time which
elapses between Ts, the time of sending a message, and Te, the time when
the resulting error diagnostic is received.	
	S. Kelly-Bootle, The Devil's DP Dictionary



From petr.pikal at precheza.cz  Tue Jan 20 13:18:19 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 20 Jan 2004 13:18:19 +0100
Subject: [R] avas
In-Reply-To: <003501c3df3a$d9190a60$50421bc2@frat>
Message-ID: <400D2A9B.18523.18703F9@localhost>

Hallo


On 20 Jan 2004 at 11:49, f?rat ?zdemir wrote:

> Hi,
> I wanted  to make a transformation with "avas" and "ace" but  saw a
> message " couldn't find function "avas"  "
>  what are the possibble reasons of this case?

Most probably you did not installed proper library. I assume it is 
acepack.

Go through docummentation how to install and use libraries.


Cheers
Petr


> It may be a basic question but unfortunately I am very new in R.
> Thanks for your helps
>  Regards
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From j.c.ten.holt at student.rug.nl  Tue Jan 20 13:28:36 2004
From: j.c.ten.holt at student.rug.nl (Janke ten Holt)
Date: Tue, 20 Jan 2004 13:28:36 +0100
Subject: [R] evaluation of discriminant functions+multivariate
	homoscedasticity
Message-ID: <400D1EF4.9080204@student.rug.nl>

Hello,

I am switching from SPSS-Windows to R-Linux. My university is very 
SPSS-oriented so maybe that's the cause of my problems. I am a beginner 
in R and my assignments are SPSS-oriented, so I hope I don't annoy 
anyone with my questions...

Right now I've got 2 problems:
-I have to evaluate discriminant functions I have calculated with 
lda(MASS). I can't find a measure that evaluates their significance 
(Wilk's lambda in my textbook (Stevens,(2002),"Applied multivariate 
statistics for the social sciences")and in SPSS). Is there a Wilk's 
lambda for discriminant functions in R? or can I use an alternative 
measure? or am I thinking in the wrong direction? I have searched the 
help-archive to find similar questions to mine but no answer to them.

-My second problem: to check the assumption of multivariate 
homoscedasticity I have to test if the variance-covariance matrices for 
my variables are homogene. My textbook suggests Box's M test. I can't 
find this statistic in R. Again I have found similar questions in the 
help-archives, but no answers. Is there a way to calculate Box's M in R? 
Or is there an alternative way to check for multivariate homoscedasticity?

Any suggestion would be greatly appreciated!

Cheers,
Janke ten Holt



From andy_liaw at merck.com  Tue Jan 20 14:12:28 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 20 Jan 2004 08:12:28 -0500
Subject: [R] random forest question
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7654@usrymx25.merck.com>

The classwt are used in the gini index for splitting nodes.  What we have
found (about two years ago) is that that option does not affect the
prediction as much as one would expect.  I suspect the problem is because
the trees are grown to maximum sizes and not pruned back.  This is why I
implemented the cutoff and sampsize options in randomForest().  Do make use
of them.  The classwt is there just for `old time sake', I guess...

BTW, 4.0-7 is current, and fixes a few bugs in 4.0-1.

BTW #2:  The convention is to direct questions specific to a package to the
package maintainer (me in this case) first, before posting to R-help.

HTH,
Andy

> From: Christian Hennig
> 
> Hi,
> 
> here are three results of random forest (version 4.0-1).
> The results seem to be more or less the same which is strange 
> because I
> changed the classwt. 
> I hoped that for example classwt=c(0.45,0.1,0.45) would 
> result in fewer
> cases classified as class 2. Did I understand something wrong?
> 
> Christian
> 
> x1rf <- randomForest(x=as.data.frame(mfilters[cvtrain,]),
>                      y=as.factor(traingroups),
>                      xtest=as.data.frame(mfilters[cvtest,]),
>                      ytest=as.factor(testgroups))
> > x1rf$test$confusion
>      1    2  3 class.error
> 1 9954   30 19  0.00489853
> 2  139 1854  0  0.06974410
> 3  420    0 84  0.83333333
> x1rf <- randomForest(x=as.data.frame(mfilters[cvtrain,]),
>                      y=as.factor(traingroups),
>                      xtest=as.data.frame(mfilters[cvtest,]),
>                      
> ytest=as.factor(testgroups),classwt=c(0.45,0.1,0.45))
> > x1rf$test$confusion
>      1    2  3 class.error
> 1 9952   31 20  0.00509847
> 2  164 1828  1  0.08278976
> 3  440    0 64  0.87301587
> x1rf <- randomForest(x=as.data.frame(mfilters[cvtrain,]),
>                      y=as.factor(traingroups),
>                      xtest=as.data.frame(mfilters[cvtest,]),
> 
> ytest=as.factor(testgroups),classwt=c(0.49,0.02,0.49))
> > x1rf$test$confusion
>      1    2  3 class.error
> 1 9948   35 20  0.00549835
> 2  170 1823  0  0.08529854
> 3  439    0 65  0.87103175
> 
> 
> 
> **************************************************************
> *********
> Christian Hennig
> Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
> hennig at math.uni-hamburg.de, 
> http://www.math.uni-hamburg.de/home/hennig/
> 
> ##############################################################
> #########
> ich empfehle www.boag-online.de


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From flom at ndri.org  Tue Jan 20 14:39:20 2004
From: flom at ndri.org (Peter Flom)
Date: Tue, 20 Jan 2004 08:39:20 -0500
Subject: [R] Weird problem with trying to change a variable  SOLVED
Message-ID: <s00ce94f.094@MAIL.NDRI.ORG>

Thanks to all who responded.

In particular, thanks to Jim Lemon who pointed out that just because 

mode(MSA)

returned ''numeric', doesn't mean MSA isn't a factor.  It turned out,
indeed,  to be a factor.  

Peter



From debe2000 at gmx.de  Tue Jan 20 15:13:47 2004
From: debe2000 at gmx.de (Derk Bemeleit)
Date: Tue, 20 Jan 2004 15:13:47 +0100
Subject: [R] Sytem Requirements for R for Win XP
Message-ID: <001c01c3df5f$a532e890$a62f548d@derkmobile>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040120/e8967fb0/attachment.pl

From ripley at stats.ox.ac.uk  Tue Jan 20 15:37:36 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Jan 2004 14:37:36 +0000 (GMT)
Subject: [R] evaluation of discriminant functions+multivariate
	homoscedasticity
In-Reply-To: <400D1EF4.9080204@student.rug.nl>
Message-ID: <Pine.LNX.4.44.0401201427280.12095-100000@gannet.stats>

These topics are not much used by trained statisticians.  In particular, 
the tests such as 1) are so sensitive to multivariate normality as to be 
almost no practical use.

Even if the assumptions of multivariate normality hold, the standard
arguments of the robustniks hold here too:  the departure from the
homogeneity assumptions hurts you before statistical signifcance is
reached, and it is better to act as if the homoscedasticity does not hold
(so use QDA or a regularized version of it).  But then multivariate
normality almost never comes close to holding true outside simulation
experiments.  We do teach LDA and QDA, but mainly to point out that
logistic discrimination is a much safer procedure.

If you want to do statistics like SPSS does, I suggest you use SPSS.
R is not a substitute for SPSS -- in particular it lacks a lot of
legacy material that the much older packages have.  But as R is highly 
programmable, you can add these tests if you want to.


On Tue, 20 Jan 2004, Janke ten Holt wrote:

> Hello,
> 
> I am switching from SPSS-Windows to R-Linux. My university is very 
> SPSS-oriented so maybe that's the cause of my problems. I am a beginner 
> in R and my assignments are SPSS-oriented, so I hope I don't annoy 
> anyone with my questions...
> 
> Right now I've got 2 problems:
> -I have to evaluate discriminant functions I have calculated with 
> lda(MASS). I can't find a measure that evaluates their significance 
> (Wilk's lambda in my textbook (Stevens,(2002),"Applied multivariate 
> statistics for the social sciences")and in SPSS). Is there a Wilk's 
> lambda for discriminant functions in R? or can I use an alternative 
> measure? or am I thinking in the wrong direction? I have searched the 
> help-archive to find similar questions to mine but no answer to them.
> 
> -My second problem: to check the assumption of multivariate 
> homoscedasticity I have to test if the variance-covariance matrices for 
> my variables are homogene. My textbook suggests Box's M test. I can't 
> find this statistic in R. Again I have found similar questions in the 
> help-archives, but no answers. Is there a way to calculate Box's M in R? 
> Or is there an alternative way to check for multivariate homoscedasticity?
> 
> Any suggestion would be greatly appreciated!
> 
> Cheers,
> Janke ten Holt

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From hb at maths.lth.se  Tue Jan 20 15:46:23 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 20 Jan 2004 15:46:23 +0100
Subject: [R] Sytem Requirements for R for Win XP
In-Reply-To: <001c01c3df5f$a532e890$a62f548d@derkmobile>
Message-ID: <000401c3df64$2cf197a0$e502eb82@maths.lth.se>

Hi, 

I have a WinXP Pro 1.8GHz 512Mb Pentium 4 laptop machine and do
microarray analysis on it with R. However, it would do better with
more RAM. So, if you're buying a new system then go for >1024Mb. Of
course, this depends totally on what kind of analysis you do and how
many arrays you work with (==have loaded) at the same time and so.
Doing microarray analysis my thumb rule is that you get more bang for
bucks if you put the money on RAM rather than the CPU; swapping takes
time.

About QuantArray tab-delimited output files: Reading a 2.9Mb file
using read.table() with optimized field types (colClasses - integers
for integer fields and so on), object.size() says that the read data
frame is 2.8Mb. So, without knowing your exact fields, maybe you can
calculate with 16Mb per slide in your case.

Henrik Bengtsson
Lund University, Sweden

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Derk Bemeleit
> Sent: den 20 januari 2004 15:14
> To: R-help at stat.math.ethz.ch
> Subject: [R] Sytem Requirements for R for Win XP
> 
> 
> Dear R-Tech Support Team, 
> 
> 
> I was just browsing on your web page and I am curious about 
> R's system requirements. How many MB RAM and what processor 
> speed would you recommend for Win XP if I want to load 
> QuantArray Excel output files of appr. 16 MB each? 
>  
> Thank you very much in advance,
>  
> Derk Bemeleit
>  
> -----------------------------------------------
>  
>  A--------T
>   T-------A  Dipl.-Biol. Derk Bemeleit
>    G-----C    Lab: A 4.65
>      T-A       Gene Center and Institute of Biochemistry
>   A-----T     University of Munich
>  G--------C   Feodor-Lynen-Str. 25
>  C--------G   81377 Munich
>   A-----T     Germany
>     G-C         Tel: +49 (0) 89 2180-76961
>   T-----A     Fax: +49 (0) 89 2180-76999
>  G--------C   e-mail: bemeleit at lmb.uni-muenchen.de
> http://www.lmb.uni-muenchen.de/hopfner/bemeleit.htm
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From arne.gjuvsland at cigene.no  Tue Jan 20 15:56:46 2004
From: arne.gjuvsland at cigene.no (Arne Gjuvsland)
Date: Tue, 20 Jan 2004 15:56:46 +0100
Subject: [R] Compiling R, cannot open vars.mk
In-Reply-To: <Pine.LNX.4.44.0401191519110.4632-100000@gannet.stats>
References: <6.0.1.1.0.20040119142018.025aaa10@iha.nlh.no>
	<Pine.LNX.4.44.0401191519110.4632-100000@gannet.stats>
Message-ID: <6.0.1.1.0.20040120154715.024d75f8@iha.nlh.no>

Using GNU make solved the first problem, but now I got into trouble
with a shared library lapack.so. I found a thread in the mailing list 
concerning this problem where it was suggested that I try dyn.load from R
or the ldd on lapack.so I did that. The results are pasted under.

Arne

 >./configure CC=cc CXX=cxx F77=f77 MAKE=gmake 
SHLIB_CXXLDFLAGS=-L/lib/cmplrs/cxx --prefix=/home/gjuvslan/R-1.8.1 --with-x
 >gmake

Using gmake check I get the following problem:
 >gmake check
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
329640:/home/gjuvslan/R-1.8.1/bin/R.bin: /sbin/loader: Fatal Error: call to 
unresolved symbol from /home/gjuvslan/R-1.8.1/modules/lapack.so 
(pc=0x3ffbfde341c)
gmake[3]: *** [reg-tests-1.Rout] Error 1
gmake[2]: *** [test-Reg] Error 2
gmake[1]: *** [test-all-basics] Error 1
gmake: *** [check] Error 2
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


 > dyn.load("modules/lapack.so")
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Error in dyn.load(x, as.logical(local), as.logical(now)) :
         unable to load shared library 
"/home/gjuvslan/R-1.8.1/bin/modules/lapack.so":
   dlopen: Can't open needed library: 
/home/gjuvslan/R-1.8.1/bin/modules/lapack.so
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------


 >ldd -r lapack.so: (./modules/)
--------------------------------------------------------------------------------------------------------------------------------------------------
345322:lapack.so: ldd: Fatal Error: Cannot generate dynamic dependencies 
for library libRlapack.so
--------------------------------------------------------------------------------------------------------------------------------------------------


 >ldd -r libRlapack.so (./bin og  ./src/modules/lapack)
--------------------------------------------------------------------------------------------------------------------------------------------------
ldd -r libRlapack.so
Unresolved symbol in libRlapack.so: dsymv_
Unresolved symbol in libRlapack.so: dgemm_
Unresolved symbol in libRlapack.so: dtpsv_
Unresolved symbol in libRlapack.so: drot_
Unresolved symbol in libRlapack.so: xerbla_
Unresolved symbol in libRlapack.so: dtrmv_
Unresolved symbol in libRlapack.so: dspr2_
Unresolved symbol in libRlapack.so: dtbsv_
Unresolved symbol in libRlapack.so: daxpy_
Unresolved symbol in libRlapack.so: zgemm_
Unresolved symbol in libRlapack.so: dsyr2_
Unresolved symbol in libRlapack.so: dsyr2k_
Unresolved symbol in libRlapack.so: dnrm2_
Unresolved symbol in libRlapack.so: dsymm_
Unresolved symbol in libRlapack.so: ddot_
Unresolved symbol in libRlapack.so: dtrsm_
Unresolved symbol in libRlapack.so: dtbmv_
Unresolved symbol in libRlapack.so: dasum_
Unresolved symbol in libRlapack.so: dcopy_
Unresolved symbol in libRlapack.so: dgemv_
Unresolved symbol in libRlapack.so: dger_
Unresolved symbol in libRlapack.so: dswap_
Unresolved symbol in libRlapack.so: dscal_
Unresolved symbol in libRlapack.so: idamax_
Unresolved symbol in libRlapack.so: dsbmv_
Unresolved symbol in libRlapack.so: dsyr_
Unresolved symbol in libRlapack.so: dsyrk_
Unresolved symbol in libRlapack.so: dspmv_
Unresolved symbol in libRlapack.so: dspr_
Unresolved symbol in libRlapack.so: dtrmm_
Unresolved symbol in libRlapack.so: dtpmv_
Unresolved symbol in libRlapack.so: dgbmv_
Unresolved symbol in libRlapack.so: dtrsv_
Unresolved symbol in libc.so: __ldr_data
Unresolved symbol in libc.so: __Argc
Unresolved symbol in libc.so: __Argv

         Main  =>   libRlapack.so
         libUfor.so  =>   /usr/shlib/libUfor.so
         libfor.so  =>   /usr/shlib/libfor.so
         libFutil.so  =>   /usr/shlib/libFutil.so
         libm.so  =>   /usr/shlib/libm.so
         libots.so  =>   /usr/shlib/libots.so
         libm_c32.so  =>   /usr/shlib/libm_c32.so
         libexc.so  =>   /usr/shlib/libexc.so
         libc.so  =>   /usr/shlib/libc.so
------------------------------------------------------------------------------------------------------------


At 16:24 19.01.2004, Prof Brian Ripley wrote:
>On Mon, 19 Jan 2004, Arne Gjuvsland wrote:
>
> >
> > Hi!
> >
> > I am trying to compile R-1.8.1 on an alphaserver running Tru64 Unix.
> > I use the compilers cc,cxx and f77. After the compilation
> > I try: make check
> > and get the following message:
> >
> > Make: Cannot open /share/make/vars.mk.  Stop.
>
>Some context would have been very helpful.
>
> > Does anyone have any suggestions on why?
>
>Do you have R_HOME set (to an empty string)?
>
>Is this GNU make, and if not can you try GNU make?
>
>Otherwise, more information please, including if this is GNU make
>(probably not) and what directory make is working in (or at least the
>preceding 10 lines of output).
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rbaer at atsu.edu  Tue Jan 20 16:15:45 2004
From: rbaer at atsu.edu (imap)
Date: Tue, 20 Jan 2004 09:15:45 -0600
Subject: [R] Loading packages at startup
Message-ID: <001601c3df68$6032ca40$2e80010a@BigBaer>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040120/3d3a84dd/attachment.pl

From Timur.Elzhov at jinr.ru  Tue Jan 20 16:20:54 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Tue, 20 Jan 2004 18:20:54 +0300
Subject: [R] analytic derivative of complex function
In-Reply-To: <a06002022bc2db5cd55cb@[139.166.242.29]>
References: <20040116151854.GA24289@nf034.jinr.ru>
	<a06002022bc2db5cd55cb@[139.166.242.29]>
Message-ID: <20040120152054.GA24698@nf034.jinr.ru>

Hello, Robin. Thanks for your reply.

--
On Fri, Jan 16, 2004 at 03:39:48PM +0000, Robin Hankin wrote:

> the differential of sin(z) is cos(z), over the whole complex plane.
> 
> If you have a function in terms of its real and imaginary components, 
> and you know that the function is differentiable, then use the 
> Cauchy-Riemann equations.

Ok, say I have z - _extremely_ long and hard complex _expression_.
What if I'd like to take analytic derivative from Arg(z)?

--
Timur.



From ripley at stats.ox.ac.uk  Tue Jan 20 16:27:44 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Jan 2004 15:27:44 +0000 (GMT)
Subject: [R] Compiling R, cannot open vars.mk
In-Reply-To: <6.0.1.1.0.20040120154715.024d75f8@iha.nlh.no>
Message-ID: <Pine.LNX.4.44.0401201519440.1186-100000@gannet.stats>

On Tue, 20 Jan 2004, Arne Gjuvsland wrote:

> Using GNU make solved the first problem, but now I got into trouble
> with a shared library lapack.so. I found a thread in the mailing list 
> concerning this problem where it was suggested that I try dyn.load from R
> or the ldd on lapack.so I did that. The results are pasted under.

The advice I know of was

R CMD lapack.so

as the R wrapper sets the library paths.  Here is what I get on Linux

gannet% Rdev CMD ldd lapack.so
        libRlapack.so => /users/ripley/R/R-devel/bin/libRlapack.so (0x4000c000)
        libg2c.so.0 => /usr/local/lib/libg2c.so.0 (0x402af000)
        libm.so.6 => /lib/libm.so.6 (0x402dd000)
        libgcc_s.so.1 => /usr/local/lib/libgcc_s.so.1 (0x402ff000)
        libreadline.so.4 => /usr/lib/libreadline.so.4 (0x40307000)
        libdl.so.2 => /lib/libdl.so.2 (0x40333000)
        libncurses.so.5 => /usr/lib/libncurses.so.5 (0x40336000)
        libc.so.6 => /lib/libc.so.6 (0x40376000)
        /lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x80000000)

libRlapack should either contain the BLAS or link to somewhere that does 
(which might be the R executable).  It is possible that Tru64 is unable to 
do the latter -- has anyone else built on Tru64 since 1.7.0?

One possible line is to build a BLAS library yourself and specify it at 
configure time: then libRlapack.so would not need to link against symbols 
in the executable.



> 
> Arne
> 
>  >./configure CC=cc CXX=cxx F77=f77 MAKE=gmake 
> SHLIB_CXXLDFLAGS=-L/lib/cmplrs/cxx --prefix=/home/gjuvslan/R-1.8.1 --with-x
>  >gmake
> 
> Using gmake check I get the following problem:
>  >gmake check
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 329640:/home/gjuvslan/R-1.8.1/bin/R.bin: /sbin/loader: Fatal Error: call to 
> unresolved symbol from /home/gjuvslan/R-1.8.1/modules/lapack.so 
> (pc=0x3ffbfde341c)
> gmake[3]: *** [reg-tests-1.Rout] Error 1
> gmake[2]: *** [test-Reg] Error 2
> gmake[1]: *** [test-all-basics] Error 1
> gmake: *** [check] Error 2
> ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> 
>  > dyn.load("modules/lapack.so")
> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>          unable to load shared library 
> "/home/gjuvslan/R-1.8.1/bin/modules/lapack.so":
>    dlopen: Can't open needed library: 
> /home/gjuvslan/R-1.8.1/bin/modules/lapack.so
> -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> 
>  >ldd -r lapack.so: (./modules/)
> --------------------------------------------------------------------------------------------------------------------------------------------------
> 345322:lapack.so: ldd: Fatal Error: Cannot generate dynamic dependencies 
> for library libRlapack.so
> --------------------------------------------------------------------------------------------------------------------------------------------------
> 
> 
>  >ldd -r libRlapack.so (./bin og  ./src/modules/lapack)
> --------------------------------------------------------------------------------------------------------------------------------------------------
> ldd -r libRlapack.so
> Unresolved symbol in libRlapack.so: dsymv_
> Unresolved symbol in libRlapack.so: dgemm_
> Unresolved symbol in libRlapack.so: dtpsv_
> Unresolved symbol in libRlapack.so: drot_
> Unresolved symbol in libRlapack.so: xerbla_
> Unresolved symbol in libRlapack.so: dtrmv_
> Unresolved symbol in libRlapack.so: dspr2_
> Unresolved symbol in libRlapack.so: dtbsv_
> Unresolved symbol in libRlapack.so: daxpy_
> Unresolved symbol in libRlapack.so: zgemm_
> Unresolved symbol in libRlapack.so: dsyr2_
> Unresolved symbol in libRlapack.so: dsyr2k_
> Unresolved symbol in libRlapack.so: dnrm2_
> Unresolved symbol in libRlapack.so: dsymm_
> Unresolved symbol in libRlapack.so: ddot_
> Unresolved symbol in libRlapack.so: dtrsm_
> Unresolved symbol in libRlapack.so: dtbmv_
> Unresolved symbol in libRlapack.so: dasum_
> Unresolved symbol in libRlapack.so: dcopy_
> Unresolved symbol in libRlapack.so: dgemv_
> Unresolved symbol in libRlapack.so: dger_
> Unresolved symbol in libRlapack.so: dswap_
> Unresolved symbol in libRlapack.so: dscal_
> Unresolved symbol in libRlapack.so: idamax_
> Unresolved symbol in libRlapack.so: dsbmv_
> Unresolved symbol in libRlapack.so: dsyr_
> Unresolved symbol in libRlapack.so: dsyrk_
> Unresolved symbol in libRlapack.so: dspmv_
> Unresolved symbol in libRlapack.so: dspr_
> Unresolved symbol in libRlapack.so: dtrmm_
> Unresolved symbol in libRlapack.so: dtpmv_
> Unresolved symbol in libRlapack.so: dgbmv_
> Unresolved symbol in libRlapack.so: dtrsv_
> Unresolved symbol in libc.so: __ldr_data
> Unresolved symbol in libc.so: __Argc
> Unresolved symbol in libc.so: __Argv
> 
>          Main  =>   libRlapack.so
>          libUfor.so  =>   /usr/shlib/libUfor.so
>          libfor.so  =>   /usr/shlib/libfor.so
>          libFutil.so  =>   /usr/shlib/libFutil.so
>          libm.so  =>   /usr/shlib/libm.so
>          libots.so  =>   /usr/shlib/libots.so
>          libm_c32.so  =>   /usr/shlib/libm_c32.so
>          libexc.so  =>   /usr/shlib/libexc.so
>          libc.so  =>   /usr/shlib/libc.so
> ------------------------------------------------------------------------------------------------------------
> 
> 
> At 16:24 19.01.2004, Prof Brian Ripley wrote:
> >On Mon, 19 Jan 2004, Arne Gjuvsland wrote:
> >
> > >
> > > Hi!
> > >
> > > I am trying to compile R-1.8.1 on an alphaserver running Tru64 Unix.
> > > I use the compilers cc,cxx and f77. After the compilation
> > > I try: make check
> > > and get the following message:
> > >
> > > Make: Cannot open /share/make/vars.mk.  Stop.
> >
> >Some context would have been very helpful.
> >
> > > Does anyone have any suggestions on why?
> >
> >Do you have R_HOME set (to an empty string)?
> >
> >Is this GNU make, and if not can you try GNU make?
> >
> >Otherwise, more information please, including if this is GNU make
> >(probably not) and what directory make is working in (or at least the
> >preceding 10 lines of output).
> >
> >--
> >Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >University of Oxford,             Tel:  +44 1865 272861 (self)
> >1 South Parks Road,                     +44 1865 272866 (PA)
> >Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rpeng at jhsph.edu  Tue Jan 20 16:33:21 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 20 Jan 2004 10:33:21 -0500
Subject: [R] Loading packages at startup
In-Reply-To: <001601c3df68$6032ca40$2e80010a@BigBaer>
References: <001601c3df68$6032ca40$2e80010a@BigBaer>
Message-ID: <400D4A41.4060202@jhsph.edu>

Take a look at ?Startup.  You can create a Rprofile file 
which loads these packages from the start.

-roger

imap wrote:
> Hi,
> 
> I use the Windows R GUI.  I frequently use (or have my students use) foreign and survival packages.  I would like to make them part of the basic start-up package set (like base, ctest, etc.) using something short of recompiling a special Windows version of R.  Is this possible?  I examined the autoload() command but this seems to target a single command of package, and only apply during a single run of R.  Is there an initiation text file I could modify?  I can find no mention in the documentation of how this might be done.
> 
> Thanks,
> Rob
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue Jan 20 16:35:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Jan 2004 15:35:12 +0000 (GMT)
Subject: [R] Loading packages at startup
In-Reply-To: <001601c3df68$6032ca40$2e80010a@BigBaer>
Message-ID: <Pine.LNX.4.44.0401201528290.1186-100000@gannet.stats>

On Tue, 20 Jan 2004, imap wrote:

> Hi,
> 
> I use the Windows R GUI.  I frequently use (or have my students use)
> foreign and survival packages.  I would like to make them part of the
> basic start-up package set (like base, ctest, etc.) using something
> short of recompiling a special Windows version of R.  Is this possible?  
> I examined the autoload() command but this seems to target a single
> command of package, and only apply during a single run of R.  Is there
> an initiation text file I could modify?  I can find no mention in the
> documentation of how this might be done.

There certainly is.  You can use a site profile file, or you can set
R_DEFAULT_PACKAGES.  Both are described in ?Startup (a pretty obvious
place to look, surely).  For example, you might put in 
R_HOME/etc/Rprofile.site

options(defaultPackages=c(getOption("defaultPackages"), "foreign", "survival"))


Please sort out a proper user name for your mail ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From firat.ozdemir at deu.edu.tr  Tue Jan 20 16:34:24 2004
From: firat.ozdemir at deu.edu.tr (=?windows-1254?Q?f=FDrat_=F6zdemir?=)
Date: Tue, 20 Jan 2004 17:34:24 +0200
Subject: [R] avas and ace
Message-ID: <008701c3df6a$f59c6260$50421bc2@frat>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040120/64ebb6af/attachment.pl

From f.calboli at ucl.ac.uk  Tue Jan 20 17:40:07 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 20 Jan 2004 16:40:07 +0000
Subject: [R] matrix exponential: M^0
Message-ID: <1074616806.2958.46.camel@monkey>

Dear All, 

I would like to ask why the zeroeth power of a matrix gives me a matrix
of ones rather than the identity matrix:

> D<-rbind(c(0,0,0),c(0,0,0),c(0,0,0))
> D<-as.matrix(D)
> D
     [,1] [,2] [,3]
[1,]    0    0    0
[2,]    0    0    0
[3,]    0    0    0

> D^0
     [,1] [,2] [,3]
[1,]    1    1    1
[2,]    1    1    1
[3,]    1    1    1

I would have expected the identity matrix here.

I find the same result with every other square matrix I used.
BTW, I am using R 1.8.1 on Linux Mandrake 9.1

Cheers,

Federico Calboli
-- 



=================================

Federico C. F. Calboli

PLEASE NOTE NEW ADDRESS

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 251 208

f.calboli at ucl.ac.uk



From Simon.Fear at synequanon.com  Tue Jan 20 16:36:29 2004
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Tue, 20 Jan 2004 15:36:29 -0000
Subject: [R] Loading packages at startup
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F02194@synequanon01>

See Introduction to R section 10.8 and Appendix B.2.

I searched for `.First` to find it, but then, I knew what
to look for ... searching for `startup` would find it too.

> -----Original Message-----
> From: imap [mailto:rbaer at atsu.edu]
> Sent: 20 January 2004 15:16
> To: r-help at stat.math.ethz.ch
> Subject: [R] Loading packages at startup
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> Hi,
> 
> I use the Windows R GUI.  I frequently use (or have my 
> students use) foreign and survival packages.  I would like to 
> make them part of the basic start-up package set (like base, 
> ctest, etc.) using something short of recompiling a special 
> Windows version of R.  Is this possible?  I examined the 
> autoload() command but this seems to target a single command 
> of package, and only apply during a single run of R.  Is 
> there an initiation text file I could modify?  I can find no 
> mention in the documentation of how this might be done.
> 
> Thanks,
> Rob
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From arv at ono.com  Tue Jan 20 16:49:40 2004
From: arv at ono.com (antonio rodriguez)
Date: Tue, 20 Jan 2004 16:49:40 +0100
Subject: [R] Loading packages at startup
In-Reply-To: <001601c3df68$6032ca40$2e80010a@BigBaer>
Message-ID: <IPEFKICOHOECENGJBAGLIELJCMAA.arv@ono.com>

Hi,

go to your C:/R/rw1080/etc directory and edit the Rprofile file adding
(e.g.):

library(foreign)
library(survival)

cheers,

antonio rodriguez


> -----Mensaje original-----
> De: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]En nombre de imap
> Enviado el: martes, 20 de enero de 2004 16:16
> Para: r-help at stat.math.ethz.ch
> Asunto: [R] Loading packages at startup
>
>
> Hi,
>
> I use the Windows R GUI.  I frequently use (or have my students
> use) foreign and survival packages.  I would like to make them
> part of the basic start-up package set (like base, ctest, etc.)
> using something short of recompiling a special Windows version of
> R.  Is this possible?  I examined the autoload() command but this
> seems to target a single command of package, and only apply
> during a single run of R.  Is there an initiation text file I
> could modify?  I can find no mention in the documentation of how
> this might be done.
>
> Thanks,
> Rob
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> ---
> Incoming mail is certified Virus Free.
> Checked by AVG anti-virus system (http://www.grisoft.com).
> Version: 6.0.564 / Virus Database: 356 - Release Date: 19/01/2004
>
---



From gerald.jean at dgag.ca  Tue Jan 20 16:51:36 2004
From: gerald.jean at dgag.ca (gerald.jean@dgag.ca)
Date: Tue, 20 Jan 2004 10:51:36 -0500
Subject: [R] Changing workspace from within an R session
Message-ID: <OF86BA557E.714B4B9F-ON85256E21.0054753C@spgdag.ca>

Hello R-users,

is it possible to navigate from one workspace to the other from within an R
session or does one has to close R and restart it from the directory where
resides the desired workspace?

For example from Splus I have this little function, see at the end, which I
used all the time to navigate between valid Splus directories.  I find this
particularly usefull when I develop new functions.  Most projects I work on
are large to extremely large, developing a function that takes a data.frame
as input and manipulates it is very time consuming if the input data.frame
is huge hence I have a valid Splus directory holding a few small
data.frames, I move to it while developing the function and when I am happy
with the function I move this function to my personnal library, always
attached at position 2, then move back to the the current project's valid
Splus directory.

I tried a similar approach in R, from the command line --not using a
function yet, and I was a bit surprised by the result.  The objects already
in the workspace, as called in R, stayed there and the objects from the
workspace I wanted to attach were added to the current workspace and the
workspace I was hoping to attach at pos 1 was attach at pos 2 with
seemingly nothing in it?

> attach("/home/jeg002/splus/GlmExamples/.RData", pos = 1)
> search()
 [1] ".GlobalEnv"
 [2] "file:/home/jeg002/splus/GlmExamples/.RData"
 [3] "package:methods"
      ...

> objects(pos = 2)
character(0)

The little function, mentioned above, and used in Splus.

"chdir" <-
function(datadir,  default.path = '/actuaria/jeg002/')
{
# Author  : Gerald Jean
# Date    : May 1999
# Purpose : "newdir" will be attached at position 1, and the S directory,
#           currently at position 1 will be detached.
# Arguments:
#  datadir      : the directory to attach.
#  default.path : the drive on which resides the directory to attach.
#------------------------------------------------------------------------
data.dir.to.detach <- search()[1]
to.attach <- paste(default.path, datadir, "/.Data", sep = "")
attach(to.attach, pos = 1)
detach(what = data.dir.to.detach)
search()
}

Thanks for your insights,

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming



From tlumley at u.washington.edu  Tue Jan 20 16:54:52 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 20 Jan 2004 07:54:52 -0800 (PST)
Subject: [R] matrix exponential: M^0
In-Reply-To: <1074616806.2958.46.camel@monkey>
References: <1074616806.2958.46.camel@monkey>
Message-ID: <Pine.A41.4.58.0401200753420.35688@homer06.u.washington.edu>

On Tue, 20 Jan 2004, Federico Calboli wrote:

> Dear All,
>
> I would like to ask why the zeroeth power of a matrix gives me a matrix
> of ones rather than the identity matrix:

Because ^ is not the matrix power. It's the elementwise power.

	-thomas


> > D<-rbind(c(0,0,0),c(0,0,0),c(0,0,0))
> > D<-as.matrix(D)
> > D
>      [,1] [,2] [,3]
> [1,]    0    0    0
> [2,]    0    0    0
> [3,]    0    0    0
>
> > D^0
>      [,1] [,2] [,3]
> [1,]    1    1    1
> [2,]    1    1    1
> [3,]    1    1    1
>
> I would have expected the identity matrix here.
>
> I find the same result with every other square matrix I used.
> BTW, I am using R 1.8.1 on Linux Mandrake 9.1
>
> Cheers,
>
> Federico Calboli
> --
>
>
>
> =================================
>
> Federico C. F. Calboli
>
> PLEASE NOTE NEW ADDRESS
>
> Dipartimento di Biologia
> Via Selmi 3
> 40126 Bologna
> Italy
>
> tel (+39) 051 209 4187
> fax (+39) 051 251 208
>
> f.calboli at ucl.ac.uk
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From GPetris at uark.edu  Tue Jan 20 16:55:43 2004
From: GPetris at uark.edu (Giovanni Petris)
Date: Tue, 20 Jan 2004 09:55:43 -0600 (CST)
Subject: [R] matrix exponential: M^0
In-Reply-To: <1074616806.2958.46.camel@monkey> (message from Federico Calboli
	on Tue, 20 Jan 2004 16:40:07 +0000)
References: <1074616806.2958.46.camel@monkey>
Message-ID: <200401201555.i0KFth1R028355@definetti.uark.edu>


elementary operations, like taking a power, act elementwise on vectors
and matrices. You may use a spectral decomposition to compute powers
of a matrix - or a for loop if you are interested in small integer
powers. 

HTH
Giovanni

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]

> Date: Tue, 20 Jan 2004 16:40:07 +0000
> From: Federico Calboli <f.calboli at ucl.ac.uk>
> Sender: r-help-bounces at stat.math.ethz.ch
> Organization: 
> Precedence: list
> 
> Dear All, 
> 
> I would like to ask why the zeroeth power of a matrix gives me a matrix
> of ones rather than the identity matrix:
> 
> > D<-rbind(c(0,0,0),c(0,0,0),c(0,0,0))
> > D<-as.matrix(D)
> > D
>      [,1] [,2] [,3]
> [1,]    0    0    0
> [2,]    0    0    0
> [3,]    0    0    0
> 
> > D^0
>      [,1] [,2] [,3]
> [1,]    1    1    1
> [2,]    1    1    1
> [3,]    1    1    1
> 
> I would have expected the identity matrix here.
> 
> I find the same result with every other square matrix I used.
> BTW, I am using R 1.8.1 on Linux Mandrake 9.1
> 
> Cheers,
> 
> Federico Calboli
> -- 
> 
> 
> 
> =================================
> 
> Federico C. F. Calboli
> 
> PLEASE NOTE NEW ADDRESS
> 
> Dipartimento di Biologia
> Via Selmi 3
> 40126 Bologna
> Italy
> 
> tel (+39) 051 209 4187
> fax (+39) 051 251 208
> 
> f.calboli at ucl.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From p.dalgaard at biostat.ku.dk  Tue Jan 20 16:58:35 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Jan 2004 16:58:35 +0100
Subject: [R] matrix exponential: M^0
In-Reply-To: <1074616806.2958.46.camel@monkey>
References: <1074616806.2958.46.camel@monkey>
Message-ID: <x2isj6vcgk.fsf@biostat.ku.dk>

Federico Calboli <f.calboli at ucl.ac.uk> writes:

> Dear All, 
> 
> I would like to ask why the zeroeth power of a matrix gives me a matrix
> of ones rather than the identity matrix:

Because arithmetic on a matrix works element-wise. M^2 is not equal to
M %*% M either (but is equal to  M*M).

(R doesn't have the matrix exponential function. Lifting expm() from
Octave has been on my (virtual) TODO list for some time now...)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From dtrenkler at nts6.oec.uni-osnabrueck.de  Tue Jan 20 17:03:06 2004
From: dtrenkler at nts6.oec.uni-osnabrueck.de (Trenkler, Dietrich)
Date: Tue, 20 Jan 2004 17:03:06 +0100
Subject: [R] matrix exponential: M^0
Message-ID: <FB75CFC167F3D311B11D00A0CC20FB0E8852BE@nts7.oec.Uni-Osnabrueck.DE>



> -----Original Message-----
> From:	Federico Calboli 
> Sent:	Tuesday, January 20, 2004 5:40 PM
> To:	r-help
> Subject:	[R] matrix exponential: M^0
> 
> I would like to ask why the zeroeth power of a matrix gives me a matrix
> of ones rather than the identity matrix:
> 
> > D<-rbind(c(0,0,0),c(0,0,0),c(0,0,0))
> > D<-as.matrix(D)
> > D
>      [,1] [,2] [,3]
> [1,]    0    0    0
> [2,]    0    0    0
> [3,]    0    0    0
> 
> > D^0
>      [,1] [,2] [,3]
> [1,]    1    1    1
> [2,]    1    1    1
> [3,]    1    1    1
> 
> I would have expected the identity matrix here.
> 
> I find the same result with every other square matrix I used.
	[Dietrich Trenkler]  M^0 means appying ^0 to each element of M.
	Matrix multiplication can be achieved by A%*%B. In this way A%*%A
	is not the same as A^2.

	Dietrich



From B.Rowlingson at lancaster.ac.uk  Tue Jan 20 17:08:19 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 20 Jan 2004 16:08:19 +0000
Subject: [R] matrix exponential: M^0
In-Reply-To: <1074616806.2958.46.camel@monkey>
References: <1074616806.2958.46.camel@monkey>
Message-ID: <400D5273.60408@lancaster.ac.uk>

Federico Calboli wrote:
> Dear All, 
> 
> I would like to ask why the zeroeth power of a matrix gives me a matrix
> of ones rather than the identity matrix:
> 

  Because ^0 gives you the zero-th power of the _elements_ of the 
matrix, not the matrix itself. A matrix of 0^0 is all 1s.

  Similary, '*' multiplies the elements together, it doesn't do matrix 
multiplication. For that you need %*%.

  There is no %^% operator for matrix exponentials.

Baz



From dray at biomserv.univ-lyon1.fr  Tue Jan 20 17:09:49 2004
From: dray at biomserv.univ-lyon1.fr (Stephane DRAY)
Date: Tue, 20 Jan 2004 11:09:49 -0500
Subject: [R] matrix exponential: M^0
In-Reply-To: <1074616806.2958.46.camel@monkey>
Message-ID: <5.2.1.1.0.20040120110227.039d7050@biomserv.univ-lyon1.fr>

Hello,
be careful D^0 is not the zeroeth power of a matrix. It is a term power 
:D[i,j]^0=1

To obtain the power of a matrix, you can use a decomposition such as svd:

X = U D V'
the n-th power of X is X = U D^n V'


svd1=svd(D)
Apower0=svd1$u%*%diag(svd1$d^0)%*%t(svd1$v)


At 11:40 20/01/2004, Federico Calboli wrote:
>Dear All,
>
>I would like to ask why the zeroeth power of a matrix gives me a matrix
>of ones rather than the identity matrix:
>
> > D<-rbind(c(0,0,0),c(0,0,0),c(0,0,0))
> > D<-as.matrix(D)
> > D
>      [,1] [,2] [,3]
>[1,]    0    0    0
>[2,]    0    0    0
>[3,]    0    0    0
>
> > D^0
>      [,1] [,2] [,3]
>[1,]    1    1    1
>[2,]    1    1    1
>[3,]    1    1    1
>
>I would have expected the identity matrix here.
>
>I find the same result with every other square matrix I used.
>BTW, I am using R 1.8.1 on Linux Mandrake 9.1
>
>Cheers,
>
>Federico Calboli
>--
>
>
>
>=================================
>
>Federico C. F. Calboli
>
>PLEASE NOTE NEW ADDRESS
>
>Dipartimento di Biologia
>Via Selmi 3
>40126 Bologna
>Italy
>
>tel (+39) 051 209 4187
>fax (+39) 051 251 208
>
>f.calboli at ucl.ac.uk
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

St?phane DRAY
-------------------------------------------------------------------------------------------------- 

D?partement des Sciences Biologiques
Universit? de Montr?al, C.P. 6128, succursale centre-ville
Montr?al, Qu?bec H3C 3J7, Canada

Tel : 514 343 6111 poste 1233
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From baron at psych.upenn.edu  Tue Jan 20 17:18:15 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 20 Jan 2004 11:18:15 -0500
Subject: [R] avas and ace
In-Reply-To: <008701c3df6a$f59c6260$50421bc2@frat>
References: <008701c3df6a$f59c6260$50421bc2@frat>
Message-ID: <20040120161815.GA19206@mail2.sas.upenn.edu>

On 01/20/04 17:34, frat zdemir wrote:
>Hi,
>Does any one know how we can decide on the correct transformation in (avas and ace)
>after having drawn the graphs  y,g(y)   x ,s(x)  and g(y) ,s(x) . Is it possible by
>only looking at patterns the graphs follow for example when
>y ,g(y) shows a logaritmic pattern can we say that log transform on y is suitable?

It seems to me that the point of avas() and ace() is to arrive at
a transform that meets the criteria of each procedure but is not
necessarily based on some simple functional form like the
logarithm.  The lack of restriction to any particular functional
form is what is particularly useful.

You might, however, compare a simple function to the results of
avas or ace.  The output of each function consists of the
transformed values ty (the dependent variable) and a matrix of
predictors tx.  You also get y and x.  You can access these as
follows:

ace1 <- ace(..[all your stuff]..)
ace1$ty
ace1$y
etc.

If you think that ty is the log of y, then plot ty as a function
of log(y) and see if you get a straight line.  Or test for
linearity however you like.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From feh3k at spamcop.net  Tue Jan 20 17:21:31 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 20 Jan 2004 11:21:31 -0500
Subject: [R] avas and ace
In-Reply-To: <008701c3df6a$f59c6260$50421bc2@frat>
References: <008701c3df6a$f59c6260$50421bc2@frat>
Message-ID: <20040120112131.4da851f5.feh3k@spamcop.net>

On Tue, 20 Jan 2004 17:34:24 +0200
f?rat ?zdemir <firat.ozdemir at deu.edu.tr> wrote:

> Hi,
> Does any one know how we can decide on the correct transformation in
> (avas and ace) after having drawn the graphs  y,g(y)   x ,s(x)  and g(y)
> ,s(x) . Is it possible by only looking at patterns the graphs follow for
> example when y ,g(y) shows a logaritmic pattern can we say that log
> transform on y is suitable? Thanks for your help.
> Regards
> 

The strategy I use is to not try to do this.  One reason is that you may
be tempted to fit a parametric model with such simple transformations,
without accounting for the hidden degrees of freedom from the uncertainty
in estimating the transformations.  The areg.boot function in the Hmisc
package will give you bootstrap confidence bands for ace and avas
transformations, taking into account almost all sources of uncertainty.

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From jfox at mcmaster.ca  Tue Jan 20 17:02:26 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 20 Jan 2004 11:02:26 -0500
Subject: [R] matrix exponential: M^0
In-Reply-To: <1074616806.2958.46.camel@monkey>
Message-ID: <5.0.2.1.0.20040120110005.00af84c8@127.0.0.1>

Dear Federico,

The common arithmetic operators such as ^ operate on the elements of 
matrices (or vectors or arrays). Similarly, * gives the element-wise 
product and not the matrix product.

I hope that this helps,
  John

At 04:40 PM 1/20/2004 +0000, Federico Calboli wrote:
>Dear All,
>
>I would like to ask why the zeroeth power of a matrix gives me a matrix
>of ones rather than the identity matrix:
>
> > D<-rbind(c(0,0,0),c(0,0,0),c(0,0,0))
> > D<-as.matrix(D)
> > D
>      [,1] [,2] [,3]
>[1,]    0    0    0
>[2,]    0    0    0
>[3,]    0    0    0
>
> > D^0
>      [,1] [,2] [,3]
>[1,]    1    1    1
>[2,]    1    1    1
>[3,]    1    1    1
>
>I would have expected the identity matrix here.
>
>I find the same result with every other square matrix I used.
>BTW, I am using R 1.8.1 on Linux Mandrake 9.1
>
>Cheers,
>
>Federico Calboli

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From dmurdoch at pair.com  Tue Jan 20 17:37:14 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 20 Jan 2004 11:37:14 -0500
Subject: [R] matrix exponential: M^0
In-Reply-To: <1074616806.2958.46.camel@monkey>
References: <1074616806.2958.46.camel@monkey>
Message-ID: <i3mq00la7a1iobitevsdtq095n8gstbtgu@4ax.com>

On 20 Jan 2004 16:40:07 +0000, Federico Calboli <f.calboli at ucl.ac.uk>
wrote :

>Dear All, 
>
>I would like to ask why the zeroeth power of a matrix gives me a matrix
>of ones rather than the identity matrix:

R doesn't have a power operator that knows it's working on a matrix.
M^x raises each entry of M to the power x, it doesn't raise the matrix
to that power.  E.g.

> x
     [,1] [,2]
[1,]    2    2
[2,]    2    2
> x^2
     [,1] [,2]
[1,]    4    4
[2,]    4    4
> x %*% x
     [,1] [,2]
[1,]    8    8
[2,]    8    8

It's a little funny that 0^0 gives 1, but that's a reasonable
convention, often useful in likelihood calculations.

Duncan Murdoch



From deepayan at stat.wisc.edu  Tue Jan 20 17:40:56 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 20 Jan 2004 10:40:56 -0600
Subject: [R] lattice: adding text between grouped panels?
In-Reply-To: <20040120101450.GA5234@s1x.local>
References: <20040120101450.GA5234@s1x.local>
Message-ID: <200401201040.56262.deepayan@stat.wisc.edu>

On Tuesday 20 January 2004 04:14, Wolfram Fischer wrote:
> How one can add a text (e.g. the labels of an axis)
> in a space between grouped panels which was created
> by using the argument ``between''?
>
> Example:
> 	data(barley)
> 	dotplot(variety ~ yield | site * year, data=barley,
> 		between=list(x=c( 0, 0, 6 ))
> How to add labels for the y axis in the space in the middle?

Formally, there's no mechanism to do that. However, most reasonable usage can 
be achieved by the panel function, e.g. (to add a y-axis tick and label at 
the mean y-value):

panel = function(x, y, ...) {
    panel.xyplot(x, y, ...)
    grid.yaxis(at = mean(y))
}

Normally, this would not work because all graphical output produced by the 
panel function is 'clipped', i.e., anything falling outside the panel is not 
drawn. This can be controlled by the setting

> trellis.par.get("clip")
$panel
[1] TRUE

$strip
[1] TRUE


So you need to do something like 

> lset(list(clip = list(panel = FALSE)))

before calling xyplot (or whatever). Of course, turning clipping off has the 
disadvantage that unintended things can happen. Most panel functions are 
safe, but some are not (like panel.abline).


Just in case you missed it, there's a much safer way to add customized tick 
marks and labels to each panel, using the scales argument. From ?xyplot, 


  scales: list determining how the x- and y-axes (tick marks and

          [...]

          at: location of tick marks along the axis (in native
          coordinates), or a list as long as the number of panels
          describing tick locations for each panel.

          labels: Labels (strings or expressions) to go along with
          'at'. Can be a list like 'at' as well.

But this may not be what you want.

Hth,

Deepayan



From feh3k at spamcop.net  Tue Jan 20 17:42:04 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 20 Jan 2004 11:42:04 -0500
Subject: [R] Changing workspace from within an R session
In-Reply-To: <OF86BA557E.714B4B9F-ON85256E21.0054753C@spgdag.ca>
References: <OF86BA557E.714B4B9F-ON85256E21.0054753C@spgdag.ca>
Message-ID: <20040120114204.7018bcdd.feh3k@spamcop.net>

On Tue, 20 Jan 2004 10:51:36 -0500
gerald.jean at dgag.ca wrote:

> Hello R-users,
> 
> is it possible to navigate from one workspace to the other from within
> an R session or does one has to close R and restart it from the
> directory where resides the desired workspace?

....
> G?rald Jean
> Analyste-conseil (statistiques), Actuariat

Gerald,

I am getting in the habit of explicitly using save(..., compress=TRUE) and
load( ) in R.  Sometimes it adds code but I like the level of control and
the selective saving of only the important objects (usually data frames
and regression fit objects for me).  You could easily make a load2
function that would accept a separate path argument and set the path in a
variable.  Do you have reactions to this approach?  -Frank

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From nbusscher at gmx.de  Tue Jan 20 18:04:03 2004
From: nbusscher at gmx.de (Nicolaas Busscher)
Date: Tue, 20 Jan 2004 18:04:03 +0100
Subject: [R] repeated measurements with R
Message-ID: <20040120180403.0c633b08.nbusscher@gmx.de>

Hello All,
I have a more statistical question, and how this is implemented in R.

The problem is the following:
We have 2 different solutions (samples), which are filtered and then
the concentration of the filtrate is measured.

We want to evaluate how the filter proces and the concentration
measurement influences the detection of the difference of the two
solutions and which step has which influence. So we filter the 2
solutions each 6 times and get 12 filterd solutions. each of this
filtrate is measured 8 times, so we get 12 *8 96 conc. values. i get a
data table of:

solution nr.filter nr.measures conc.
1 or 2    1 till 6  1-till 8    96 values
because the concentrations are "repeated measurements" as i was told
by a statistician (i am not) it is not allowed to make a anova with
the formula: conc~solution+nr.filter+nr.measures.

my question is: 
how can i solve this in R?

thanks
Nicolaas Busscher

-- 
Dr.Nicolaas Busscher Universit?t GH Kassel
Nordbahnhofstrasse: 1a, D-37213 Witzenhausen
Phone: 0049-(0)5542-98-1715, Fax: 0049-(0)5542-98-1713



From rvaradha at jhsph.edu  Tue Jan 20 18:05:08 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Tue, 20 Jan 2004 12:05:08 -0500
Subject: [R] Restoring an S object that was data-dumped
Message-ID: <62f82d62ca45.62ca4562f82d@jhsph.edu>

Hi:

In R, how can I "data.restore" an object that was "data.dump"ed in 
Splus (I am not sure of the exact version, but probably Splus5)? 
When I use data.restore, I get the following error message (I am using 
R 1.7.0 on Windows)

> data.restore("n2.suicide")
Error in ReadSdump(TRUE, " ") : S 
mode "        "Netherlands", "Ireland", "Denmark", "Norway", " 
Sweden", "Finland"," (near byte offset 230) not supported
In addition: Warning message: 
NAs introduced by coercion 
> 

Thanks for any help,
Ravi.



From ripley at stats.ox.ac.uk  Tue Jan 20 18:12:51 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Jan 2004 17:12:51 +0000 (GMT)
Subject: [R] Changing workspace from within an R session
In-Reply-To: <OF86BA557E.714B4B9F-ON85256E21.0054753C@spgdag.ca>
Message-ID: <Pine.LNX.4.44.0401201709320.1345-100000@gannet.stats>

Attaching at position 1 does not work in R, as you have found.  That is in 
?attach, and in the FAQ.

As the FAQ says, using save()d objects (read-only) can do quite a lot of 
this.  You could also save the workspace, clear it, and load another saved 
image ... but it is probably easier to restart R.

On Tue, 20 Jan 2004 gerald.jean at dgag.ca wrote:

> Hello R-users,
> 
> is it possible to navigate from one workspace to the other from within an R
> session or does one has to close R and restart it from the directory where
> resides the desired workspace?
> 
> For example from Splus I have this little function, see at the end, which I
> used all the time to navigate between valid Splus directories.  I find this
> particularly usefull when I develop new functions.  Most projects I work on
> are large to extremely large, developing a function that takes a data.frame
> as input and manipulates it is very time consuming if the input data.frame
> is huge hence I have a valid Splus directory holding a few small
> data.frames, I move to it while developing the function and when I am happy
> with the function I move this function to my personnal library, always
> attached at position 2, then move back to the the current project's valid
> Splus directory.
> 
> I tried a similar approach in R, from the command line --not using a
> function yet, and I was a bit surprised by the result.  The objects already
> in the workspace, as called in R, stayed there and the objects from the
> workspace I wanted to attach were added to the current workspace and the
> workspace I was hoping to attach at pos 1 was attach at pos 2 with
> seemingly nothing in it?
> 
> > attach("/home/jeg002/splus/GlmExamples/.RData", pos = 1)
> > search()
>  [1] ".GlobalEnv"
>  [2] "file:/home/jeg002/splus/GlmExamples/.RData"
>  [3] "package:methods"
>       ...
> 
> > objects(pos = 2)
> character(0)
> 
> The little function, mentioned above, and used in Splus.
> 
> "chdir" <-
> function(datadir,  default.path = '/actuaria/jeg002/')
> {
> # Author  : Gerald Jean
> # Date    : May 1999
> # Purpose : "newdir" will be attached at position 1, and the S directory,
> #           currently at position 1 will be detached.
> # Arguments:
> #  datadir      : the directory to attach.
> #  default.path : the drive on which resides the directory to attach.
> #------------------------------------------------------------------------
> data.dir.to.detach <- search()[1]
> to.attach <- paste(default.path, datadir, "/.Data", sep = "")
> attach(to.attach, pos = 1)
> detach(what = data.dir.to.detach)
> search()
> }
> 
> Thanks for your insights,
> 
> G?rald Jean
> Analyste-conseil (statistiques), Actuariat
> t?lephone            : (418) 835-4900 poste (7639)
> t?lecopieur          : (418) 835-6657
> courrier ?lectronique: gerald.jean at spgdag.ca
> 
> "In God we trust all others must bring data"  W. Edwards Deming
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rexbryan1 at comcast.net  Tue Jan 20 18:16:54 2004
From: rexbryan1 at comcast.net (rex_bryan@urscorp.com)
Date: Tue, 20 Jan 2004 10:16:54 -0700
Subject: [R] Re: Need help on how to list functions from a loaded package...
References: <200401201103.i0KB19Wu016239@hypatia.math.ethz.ch>
Message-ID: <003201c3df79$33a7d5e0$6dd40818@dell1700>

To All
How does one get a list of functions from a loaded package so that one can
then get the appropriate help for each of the functions.  Currently my
method is
based on a lot of trial-and-error.

Here's an example of what I mean...

>From this forum I learn that an interesting package called "multtest" exists
on Bioconductor.
I then use R Console's "Packages" -- "Install package(s)  from Bioconductor"
to
download "multtest".  I then load "multtest" into my session using
"Packages -- Load package..."
I now want to investigate what functions exist in "multtest".
>?package:multtest
Error in "?"(package:multtest) : Object "package" not found
> help("multtest")
Error in help("multtest") : No documentation for `multtest' in specified
packages and libraries:
  you could try `help.search("multtest")'
>help.search("multtest")
------------R Information Window ------------------------------
Help files with alias or title matching 'multtest' using fuzzy matching:

eff.aovlist(base)                 Compute Efficiencies of Multistratum
Analysis of Variance
dataDensityString(Hmisc)          Internal Hmisc functions
.mt.BLIM(multtest)                Internal multtest functions and variables
SSI(spatial)                      Simulates Sequential Spatial Inhibition
Point Process
Strauss(spatial)                  Simulates Strauss Spatial Point Process

Type 'help(FOO, package = PKG)' to inspect entry 'FOO(PKG) TITLE'.
-------------------------------------------------------------------

Oh Oh... I've met this FOO before...and I don't have a clue on how to
interpret this message.  So I'm
at a loss of how to ask about what is in the "multtest" package unless I go
back to the original source
on the Web.  By visiting
http://www.bioconductor.org/repository/release1.3/package/html/graph.html
the multtest package consists of...
--------- snip
multtest     Multiple Testing Procedures 1.3.3
----------snip

      Function Description
      golub Gene expression dataset from Golub et al. (1999)
      mt.maxT Step-down maxT and minP multiple testing procedures
      mt.plot Plotting results from multiple testing procedures
      mt.rawp2adjp Adjusted p-values for simple multiple testing procedures
      mt.reject Identity and number of rejected hypotheses
      mt.sample.teststat Permutation distribution of test statistics and raw
(unadjusted) p-values
      mt.teststat Computing test statistics for each row of a data frame










------------snip

With the information on what the function names are, I can now use the "?"
command on each of these functions.
But I have a feeling that there is a better way ...Oh FOO

REX
--------------------------------------------

Message: 33
Date: Tue, 20 Jan 2004 01:58:20 +0100
From: Tobias Sing <tsing at mpi-sb.mpg.de>
Subject: Re: [R] graph algorithms in R
To: rxg218 at psu.edu
Cc: r-help at stat.math.ethz.ch
Message-ID: <200401200158.20341.tsing at mpi-sb.mpg.de>
Content-Type: text/plain;  charset="iso-8859-1"

> I was wondering if there are any packages available that can represent
> mathematical graphs along with functions to manipulate them? Google
> did'nt turn up anything ( I may be asking too much of R :-/ )

I was looking for the same thing the other day, and found that a graph
package
for R is being developed as part of the bioconductor project. However, I
haven't tried it yet, so I don't know about the status (judging from the
function list one shouldn't expect a comprehensive collection of graph
algorithms, but at least the base structures and some random graph stuff
seem
to be implemented already). There is also a package for visualization,
Rgraphviz.

http://www.bioconductor.org/
http://www.bioconductor.org/repository/release1.3/package/html/graph.html
http://www.bioconductor.org/repository/release1.2/package/html/Rgraphviz.htm
l



From jpedro at mat.ua.pt  Tue Jan 20 18:41:36 2004
From: jpedro at mat.ua.pt (Pedro Cruz)
Date: Tue, 20 Jan 2004 17:41:36 -0000
Subject: [R] programming cycle: file managment
Message-ID: <002701c3df7c$a6f33000$745188c1@mat.ua.pt>

Hi,

the programming cycle in R is
(1) create somefile.R in some ascii editor
(2) use "source(somefile.R)" to read it.
(3) change the file and repeat step (2).

Or there's a better way ?

Which section of which manual explains that ?

Pedro Cruz



From hhr02 at aber.ac.uk  Tue Jan 20 18:59:41 2004
From: hhr02 at aber.ac.uk (Helena Rodnight)
Date: Tue, 20 Jan 2004 17:59:41 -0000
Subject: [R] nlminb function
Message-ID: <006801c3df7f$2db36cc0$c8507c90@pcdcbi>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040120/47f1ce33/attachment.pl

From hodgess at gator.uhd.edu  Tue Jan 20 19:28:26 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Tue, 20 Jan 2004 12:28:26 -0600
Subject: [R] Matrix exponential
Message-ID: <200401201828.i0KISQB12648@gator.dt.uh.edu>

How about this:
	
> expm
function(x,pow=2) 
{
xd <- diag((eigen(x)$values^pow))
xm <- eigen(x)$vector %*% xd %*% t(eigen(x)$vector)
return(xm)
}
> xa
     [,1] [,2]
[1,]    2    1
[2,]    1    3
> expm(xa,pow=3)
     [,1] [,2]
[1,]   15   20
[2,]   20   35
> xa %*% xa %*% xa
     [,1] [,2]
[1,]   15   20
[2,]   20   35
> 


From: Federico Calboli <f.calboli at ucl.ac.uk>
To: r-help <r-help at stat.math.ethz.ch>
Subject: [R] matrix exponential: M^0~~

Dear All, 

I would like to ask why the zeroeth power of a matrix gives me a matrix
of ones rather than the identity matrix:

> D<-rbind(c(0,0,0),c(0,0,0),c(0,0,0))
> D<-as.matrix(D)
> D
     [,1] [,2] [,3]
[1,]    0    0    0
[2,]    0    0    0
[3,]    0    0    0

> D^0
     [,1] [,2] [,3]
[1,]    1    1    1
[2,]    1    1    1
[3,]    1    1    1

I would have expected the identity matrix here.

I find the same result with every other square matrix I used.
BTW, I am using R 1.8.1 on Linux Mandrake 9.1

Cheers,

Federico Calboli
-- 



=================================

Federico C. F. Calboli

PLEASE NOTE NEW ADDRESS

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 251 208

f.calboli at ucl.ac.uk



From sdavis2 at mail.nih.gov  Tue Jan 20 19:14:17 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 20 Jan 2004 13:14:17 -0500
Subject: [R] Re: Need help on how to list functions from a loaded
	package...
References: <200401201103.i0KB19Wu016239@hypatia.math.ethz.ch>
	<003201c3df79$33a7d5e0$6dd40818@dell1700>
Message-ID: <007301c3df81$3828f790$2f643744@WATSON>

help(package=PKGNAME)
library(help=PKGNAME)

where PKGNAME is the name of an installed library.

help(package=multtest)
library(help=multtest)

Note that you can also use:

help.start() to get html help (assuming your browswer is configured).

Sean
----- Original Message -----
From: "rex_bryan at urscorp.com" <rexbryan1 at comcast.net>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, January 20, 2004 12:16 PM
Subject: [R] Re: Need help on how to list functions from a loaded package...


> To All
> How does one get a list of functions from a loaded package so that one can
> then get the appropriate help for each of the functions.  Currently my
> method is
> based on a lot of trial-and-error.
>
> Here's an example of what I mean...
>
> >From this forum I learn that an interesting package called "multtest"
exists
> on Bioconductor.
> I then use R Console's "Packages" -- "Install package(s)  from
Bioconductor"
> to
> download "multtest".  I then load "multtest" into my session using
> "Packages -- Load package..."
> I now want to investigate what functions exist in "multtest".
> >?package:multtest
> Error in "?"(package:multtest) : Object "package" not found
> > help("multtest")
> Error in help("multtest") : No documentation for `multtest' in specified
> packages and libraries:
>   you could try `help.search("multtest")'
> >help.search("multtest")
> ------------R Information Window ------------------------------
> Help files with alias or title matching 'multtest' using fuzzy matching:
>
> eff.aovlist(base)                 Compute Efficiencies of Multistratum
> Analysis of Variance
> dataDensityString(Hmisc)          Internal Hmisc functions
> .mt.BLIM(multtest)                Internal multtest functions and
variables
> SSI(spatial)                      Simulates Sequential Spatial Inhibition
> Point Process
> Strauss(spatial)                  Simulates Strauss Spatial Point Process
>
> Type 'help(FOO, package = PKG)' to inspect entry 'FOO(PKG) TITLE'.
> -------------------------------------------------------------------
>
> Oh Oh... I've met this FOO before...and I don't have a clue on how to
> interpret this message.  So I'm
> at a loss of how to ask about what is in the "multtest" package unless I
go
> back to the original source
> on the Web.  By visiting
> http://www.bioconductor.org/repository/release1.3/package/html/graph.html
> the multtest package consists of...
> --------- snip
> multtest     Multiple Testing Procedures 1.3.3
> ----------snip
>
>       Function Description
>       golub Gene expression dataset from Golub et al. (1999)
>       mt.maxT Step-down maxT and minP multiple testing procedures
>       mt.plot Plotting results from multiple testing procedures
>       mt.rawp2adjp Adjusted p-values for simple multiple testing
procedures
>       mt.reject Identity and number of rejected hypotheses
>       mt.sample.teststat Permutation distribution of test statistics and
raw
> (unadjusted) p-values
>       mt.teststat Computing test statistics for each row of a data frame
>
>
>
>
>
>
>
>
>
>
> ------------snip
>
> With the information on what the function names are, I can now use the "?"
> command on each of these functions.
> But I have a feeling that there is a better way ...Oh FOO
>
> REX
> --------------------------------------------
>
> Message: 33
> Date: Tue, 20 Jan 2004 01:58:20 +0100
> From: Tobias Sing <tsing at mpi-sb.mpg.de>
> Subject: Re: [R] graph algorithms in R
> To: rxg218 at psu.edu
> Cc: r-help at stat.math.ethz.ch
> Message-ID: <200401200158.20341.tsing at mpi-sb.mpg.de>
> Content-Type: text/plain;  charset="iso-8859-1"
>
> > I was wondering if there are any packages available that can represent
> > mathematical graphs along with functions to manipulate them? Google
> > did'nt turn up anything ( I may be asking too much of R :-/ )
>
> I was looking for the same thing the other day, and found that a graph
> package
> for R is being developed as part of the bioconductor project. However, I
> haven't tried it yet, so I don't know about the status (judging from the
> function list one shouldn't expect a comprehensive collection of graph
> algorithms, but at least the base structures and some random graph stuff
> seem
> to be implemented already). There is also a package for visualization,
> Rgraphviz.
>
> http://www.bioconductor.org/
> http://www.bioconductor.org/repository/release1.3/package/html/graph.html
>
http://www.bioconductor.org/repository/release1.2/package/html/Rgraphviz.htm
> l
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From sdavis2 at mail.nih.gov  Tue Jan 20 19:16:56 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 20 Jan 2004 13:16:56 -0500
Subject: [R] programming cycle: file managment
References: <002701c3df7c$a6f33000$745188c1@mat.ua.pt>
Message-ID: <007d01c3df81$969888e0$2f643744@WATSON>

Try using emacs and ess.  It will do what you ask and much, much more.  For
most systems, emacs is available as a binary or debian package; installing
ess can usually be done painlessly from within emacs.

Sean
----- Original Message -----
From: "Pedro Cruz" <jpedro at mat.ua.pt>
To: <R-help at stat.math.ethz.ch>
Sent: Tuesday, January 20, 2004 12:41 PM
Subject: [R] programming cycle: file managment


> Hi,
>
> the programming cycle in R is
> (1) create somefile.R in some ascii editor
> (2) use "source(somefile.R)" to read it.
> (3) change the file and repeat step (2).
>
> Or there's a better way ?
>
> Which section of which manual explains that ?
>
> Pedro Cruz
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Tue Jan 20 19:17:07 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 20 Jan 2004 10:17:07 -0800
Subject: [R] Restoring an S object that was data-dumped
In-Reply-To: <62f82d62ca45.62ca4562f82d@jhsph.edu>
References: <62f82d62ca45.62ca4562f82d@jhsph.edu>
Message-ID: <400D70A3.5090506@pdf.com>

      Have you tried 'help.search("data.restore")' or the "posting 
guide" at "http://www.R-project.org/posting-guide.html"?  I believe the 
object of your desires (at least for this request) is in 
"library(foreign)". 

      hope this helps. 
      spencer graves

Ravi Varadhan wrote:

>Hi:
>
>In R, how can I "data.restore" an object that was "data.dump"ed in 
>Splus (I am not sure of the exact version, but probably Splus5)? 
>When I use data.restore, I get the following error message (I am using 
>R 1.7.0 on Windows)
>
>  
>
>>data.restore("n2.suicide")
>>    
>>
>Error in ReadSdump(TRUE, " ") : S 
>mode "        "Netherlands", "Ireland", "Denmark", "Norway", " 
>Sweden", "Finland"," (near byte offset 230) not supported
>In addition: Warning message: 
>NAs introduced by coercion 
>  
>
>
>Thanks for any help,
>Ravi.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From reid_huntsinger at merck.com  Tue Jan 20 19:18:07 2004
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Tue, 20 Jan 2004 13:18:07 -0500
Subject: [R] Re: Need help on how to list functions from a loaded
	pack age...
Message-ID: <D9A95B4B7B20354992E165EEADA3199901D52A@uswpmx00.merck.com>

You can get help on the whole package by 

> help(package="multtest")

which is likely pretty close to what you want. There's the index etc for the
package on the web as well. You can also just look in the package's
installation directory. If it's loaded you can do an ls(2) say if it loaded
in position 2, to get all objects in the package.

Reid

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of rex_bryan at urscorp.com
Sent: Tuesday, January 20, 2004 12:17 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Re: Need help on how to list functions from a loaded package...


To All
How does one get a list of functions from a loaded package so that one can
then get the appropriate help for each of the functions.  Currently my
method is
based on a lot of trial-and-error.

Here's an example of what I mean...

>From this forum I learn that an interesting package called "multtest"
exists
on Bioconductor.
I then use R Console's "Packages" -- "Install package(s)  from Bioconductor"
to
download "multtest".  I then load "multtest" into my session using
"Packages -- Load package..."
I now want to investigate what functions exist in "multtest".
>?package:multtest
Error in "?"(package:multtest) : Object "package" not found
> help("multtest")
Error in help("multtest") : No documentation for `multtest' in specified
packages and libraries:
  you could try `help.search("multtest")'
>help.search("multtest")
------------R Information Window ------------------------------
Help files with alias or title matching 'multtest' using fuzzy matching:

eff.aovlist(base)                 Compute Efficiencies of Multistratum
Analysis of Variance
dataDensityString(Hmisc)          Internal Hmisc functions
.mt.BLIM(multtest)                Internal multtest functions and variables
SSI(spatial)                      Simulates Sequential Spatial Inhibition
Point Process
Strauss(spatial)                  Simulates Strauss Spatial Point Process

Type 'help(FOO, package = PKG)' to inspect entry 'FOO(PKG) TITLE'.
-------------------------------------------------------------------

Oh Oh... I've met this FOO before...and I don't have a clue on how to
interpret this message.  So I'm
at a loss of how to ask about what is in the "multtest" package unless I go
back to the original source
on the Web.  By visiting
http://www.bioconductor.org/repository/release1.3/package/html/graph.html
the multtest package consists of...
--------- snip
multtest     Multiple Testing Procedures 1.3.3
----------snip

      Function Description
      golub Gene expression dataset from Golub et al. (1999)
      mt.maxT Step-down maxT and minP multiple testing procedures
      mt.plot Plotting results from multiple testing procedures
      mt.rawp2adjp Adjusted p-values for simple multiple testing procedures
      mt.reject Identity and number of rejected hypotheses
      mt.sample.teststat Permutation distribution of test statistics and raw
(unadjusted) p-values
      mt.teststat Computing test statistics for each row of a data frame










------------snip

With the information on what the function names are, I can now use the "?"
command on each of these functions.
But I have a feeling that there is a better way ...Oh FOO

REX
--------------------------------------------

Message: 33
Date: Tue, 20 Jan 2004 01:58:20 +0100
From: Tobias Sing <tsing at mpi-sb.mpg.de>
Subject: Re: [R] graph algorithms in R
To: rxg218 at psu.edu
Cc: r-help at stat.math.ethz.ch
Message-ID: <200401200158.20341.tsing at mpi-sb.mpg.de>
Content-Type: text/plain;  charset="iso-8859-1"

> I was wondering if there are any packages available that can represent
> mathematical graphs along with functions to manipulate them? Google
> did'nt turn up anything ( I may be asking too much of R :-/ )

I was looking for the same thing the other day, and found that a graph
package
for R is being developed as part of the bioconductor project. However, I
haven't tried it yet, so I don't know about the status (judging from the
function list one shouldn't expect a comprehensive collection of graph
algorithms, but at least the base structures and some random graph stuff
seem
to be implemented already). There is also a package for visualization,
Rgraphviz.

http://www.bioconductor.org/
http://www.bioconductor.org/repository/release1.3/package/html/graph.html
http://www.bioconductor.org/repository/release1.2/package/html/Rgraphviz.htm
l

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From sdavis2 at mail.nih.gov  Tue Jan 20 19:22:30 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 20 Jan 2004 13:22:30 -0500
Subject: [R] Changing workspace from within an R session
References: <Pine.LNX.4.44.0401201709320.1345-100000@gannet.stats>
Message-ID: <008301c3df82$5d892f40$2f643744@WATSON>

You might consider using emacs and ess where you can work on a text file
(code) as a file, loading it in as needed while running more than one
instance of R within emacs.  You can then code and debug your code in one R
session (where you have your little objects) and jump over to your big
R-session when you want, loading your code there (but it remains a text file
in emacs), try it, go back to code, reload in small R-session, etc.  The
process is fairly straightforward.  (This assumes that your "data" objects
do not need to be communicated between sessions, only code.)

Sean
----- Original Message -----
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: <gerald.jean at dgag.ca>
Cc: <r-help at stat.math.ethz.ch>
Sent: Tuesday, January 20, 2004 12:12 PM
Subject: Re: [R] Changing workspace from within an R session


Attaching at position 1 does not work in R, as you have found.  That is in
?attach, and in the FAQ.

As the FAQ says, using save()d objects (read-only) can do quite a lot of
this.  You could also save the workspace, clear it, and load another saved
image ... but it is probably easier to restart R.

On Tue, 20 Jan 2004 gerald.jean at dgag.ca wrote:

> Hello R-users,
>
> is it possible to navigate from one workspace to the other from within an
R
> session or does one has to close R and restart it from the directory where
> resides the desired workspace?
>
> For example from Splus I have this little function, see at the end, which
I
> used all the time to navigate between valid Splus directories.  I find
this
> particularly usefull when I develop new functions.  Most projects I work
on
> are large to extremely large, developing a function that takes a
data.frame
> as input and manipulates it is very time consuming if the input data.frame
> is huge hence I have a valid Splus directory holding a few small
> data.frames, I move to it while developing the function and when I am
happy
> with the function I move this function to my personnal library, always
> attached at position 2, then move back to the the current project's valid
> Splus directory.
>
> I tried a similar approach in R, from the command line --not using a
> function yet, and I was a bit surprised by the result.  The objects
already
> in the workspace, as called in R, stayed there and the objects from the
> workspace I wanted to attach were added to the current workspace and the
> workspace I was hoping to attach at pos 1 was attach at pos 2 with
> seemingly nothing in it?
>
> > attach("/home/jeg002/splus/GlmExamples/.RData", pos = 1)
> > search()
>  [1] ".GlobalEnv"
>  [2] "file:/home/jeg002/splus/GlmExamples/.RData"
>  [3] "package:methods"
>       ...
>
> > objects(pos = 2)
> character(0)
>
> The little function, mentioned above, and used in Splus.
>
> "chdir" <-
> function(datadir,  default.path = '/actuaria/jeg002/')
> {
> # Author  : Gerald Jean
> # Date    : May 1999
> # Purpose : "newdir" will be attached at position 1, and the S directory,
> #           currently at position 1 will be detached.
> # Arguments:
> #  datadir      : the directory to attach.
> #  default.path : the drive on which resides the directory to attach.
> #------------------------------------------------------------------------
> data.dir.to.detach <- search()[1]
> to.attach <- paste(default.path, datadir, "/.Data", sep = "")
> attach(to.attach, pos = 1)
> detach(what = data.dir.to.detach)
> search()
> }
>
> Thanks for your insights,
>
> G?rald Jean
> Analyste-conseil (statistiques), Actuariat
> t?lephone            : (418) 835-4900 poste (7639)
> t?lecopieur          : (418) 835-6657
> courrier ?lectronique: gerald.jean at spgdag.ca
>
> "In God we trust all others must bring data"  W. Edwards Deming
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From jahumada at usgs.gov  Tue Jan 20 20:24:31 2004
From: jahumada at usgs.gov (Jorge A Ahumada)
Date: Tue, 20 Jan 2004 13:24:31 -0600
Subject: [R] problems installing odesolve in OS X
Message-ID: <4574C88E-4B7E-11D8-9B83-00039357724C@usgs.gov>

When I try to install odesolve

 > install.packages("odesolve")

I get the following error:

-----------------------
gcc -bundle -flat_namespace -undefined suppress -L/usr/local/lib -o 
odesolve.so bnorm.o call_lsoda.o cfode.o dgbfa.o dgbsl.o dgefa.o 
dgesl.o ewset.o fdump.o fnorm.o i1mach.o intdy.o j4save.o lsoda.o 
odesolve_utils.o prja.o solsy.o stoda.o vmnorm.o xercnt.o xerrwv.o 
xsetf.o -framework vecLib -L/usr/local/lib 
-L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4 
-L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/../../.. -lfrtbegin 
-lg2c -lSystem -lcc_dynamic
ld: warning -L: directory name 
(/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4) does not exist
ld: warning -L: directory name 
(/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/../../..) does not 
exist
ld: can't locate file for: -lfrtbegin
make: *** [odesolve.so] Error 1
ERROR: compilation failed for package 'odesolve'
** Removing 
'/Applications/StartR.app/RAqua.app/Contents/library/odesolve'
----------------------

and sure enough /usr/local/lib/gcc does not exist in my machine! 
Anybody knows how to get around this? I am using OS 10.3.2, R 1.8.1

thx,

Jorge



From rpeng at jhsph.edu  Tue Jan 20 20:27:12 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 20 Jan 2004 14:27:12 -0500
Subject: [R] Restoring an S object that was data-dumped
In-Reply-To: <400D70A3.5090506@pdf.com>
References: <62f82d62ca45.62ca4562f82d@jhsph.edu> <400D70A3.5090506@pdf.com>
Message-ID: <400D8110.8000600@jhsph.edu>

Obviously, it was data.restore() that produced the error 
below.  However, I think S-PLUS 5 might not be supported by 
data.restore() in the `foreign' package since the docs there 
say it can only read objects from S-PLUS versions 3.x and 
4.x (on Unix).

-roger

Spencer Graves wrote:
>      Have you tried 'help.search("data.restore")' or the "posting guide" 
> at "http://www.R-project.org/posting-guide.html"?  I believe the object 
> of your desires (at least for this request) is in "library(foreign)".
>      hope this helps.      spencer graves
> 
> Ravi Varadhan wrote:
> 
>> Hi:
>>
>> In R, how can I "data.restore" an object that was "data.dump"ed in 
>> Splus (I am not sure of the exact version, but probably Splus5)? When 
>> I use data.restore, I get the following error message (I am using R 
>> 1.7.0 on Windows)
>>
>>  
>>
>>> data.restore("n2.suicide")
>>>   
>>
>> Error in ReadSdump(TRUE, " ") : S mode "        "Netherlands", 
>> "Ireland", "Denmark", "Norway", " Sweden", "Finland"," (near byte 
>> offset 230) not supported
>> In addition: Warning message: NAs introduced by coercion  
>>
>>
>> Thanks for any help,
>> Ravi.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>  
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Tue Jan 20 20:41:00 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 20 Jan 2004 11:41:00 -0800
Subject: [R] Restoring an S object that was data-dumped
In-Reply-To: <400D8110.8000600@jhsph.edu>
References: <62f82d62ca45.62ca4562f82d@jhsph.edu> <400D70A3.5090506@pdf.com>
	<400D8110.8000600@jhsph.edu>
Message-ID: <400D844C.8020205@pdf.com>

      1.  Could  you upgrade to the latest version of R (1.8.1)?  I 
don't know if it will help, but it might. 

      2.  I just used Notepad to open a data.dump file created in S-Plus 
6.2.  It started, "## Dump S Version 4 Dump ##".  How does your 
data.dump file begin? 

      3.  If you upgrade and can't solve the problem any other way, you 
could list out the "data.dump" code and step through it one line at a 
time until you identify the problem and a way to fix it -- at least in 
your case.  A "data.dump" file seems to be plain text, which means that 
it can be modified in a text editor, provided you know what to change. 

      hope this helps.  spencer graves

Roger D. Peng wrote:

> Obviously, it was data.restore() that produced the error below.  
> However, I think S-PLUS 5 might not be supported by data.restore() in 
> the `foreign' package since the docs there say it can only read 
> objects from S-PLUS versions 3.x and 4.x (on Unix).
>
> -roger
>
> Spencer Graves wrote:
>
>>      Have you tried 'help.search("data.restore")' or the "posting 
>> guide" at "http://www.R-project.org/posting-guide.html"?  I believe 
>> the object of your desires (at least for this request) is in 
>> "library(foreign)".
>>      hope this helps.      spencer graves
>>
>> Ravi Varadhan wrote:
>>
>>> Hi:
>>>
>>> In R, how can I "data.restore" an object that was "data.dump"ed in 
>>> Splus (I am not sure of the exact version, but probably Splus5)? 
>>> When I use data.restore, I get the following error message (I am 
>>> using R 1.7.0 on Windows)
>>>
>>>  
>>>
>>>> data.restore("n2.suicide")
>>>>   
>>>
>>>
>>> Error in ReadSdump(TRUE, " ") : S mode "        "Netherlands", 
>>> "Ireland", "Denmark", "Norway", " Sweden", "Finland"," (near byte 
>>> offset 230) not supported
>>> In addition: Warning message: NAs introduced by coercion 
>>>
>>> Thanks for any help,
>>> Ravi.
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>>  
>>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>



From ripley at stats.ox.ac.uk  Tue Jan 20 20:42:51 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Jan 2004 19:42:51 +0000 (GMT)
Subject: [R] Restoring an S object that was data-dumped
In-Reply-To: <400D8110.8000600@jhsph.edu>
Message-ID: <Pine.LNX.4.44.0401201938450.1530-100000@gannet.stats>

On Tue, 20 Jan 2004, Roger D. Peng wrote:

> Obviously, it was data.restore() that produced the error 
> below.  However, I think S-PLUS 5 might not be supported by 
> data.restore() in the `foreign' package since the docs there 
> say it can only read objects from S-PLUS versions 3.x and 
> 4.x (on Unix).

Correct.  We don't have a description of the S4 (hence S-PLUS 5.x and 6.x) 
data.dump format.  We recommend using data.dump(oldStyle=T) in those 
versions of S-PLUS if possible.

> Spencer Graves wrote:
> >      Have you tried 'help.search("data.restore")' or the "posting guide" 
> > at "http://www.R-project.org/posting-guide.html"?  I believe the object 
> > of your desires (at least for this request) is in "library(foreign)".
> >      hope this helps.      spencer graves
> > 
> > Ravi Varadhan wrote:
> > 
> >> Hi:
> >>
> >> In R, how can I "data.restore" an object that was "data.dump"ed in 
> >> Splus (I am not sure of the exact version, but probably Splus5)? When 
> >> I use data.restore, I get the following error message (I am using R 
> >> 1.7.0 on Windows)
> >>
> >>  
> >>
> >>> data.restore("n2.suicide")
> >>>   
> >>
> >> Error in ReadSdump(TRUE, " ") : S mode "        "Netherlands", 
> >> "Ireland", "Denmark", "Norway", " Sweden", "Finland"," (near byte 
> >> offset 230) not supported
> >> In addition: Warning message: NAs introduced by coercion  
> >>
> >>
> >> Thanks for any help,
> >> Ravi.
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide! 
> >> http://www.R-project.org/posting-guide.html
> >>  
> >>
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Tue Jan 20 21:22:25 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 20 Jan 2004 15:22:25 -0500
Subject: [R] Restoring an S object that was data-dumped
In-Reply-To: <Pine.LNX.4.44.0401201938450.1530-100000@gannet.stats>
References: <400D8110.8000600@jhsph.edu>
	<Pine.LNX.4.44.0401201938450.1530-100000@gannet.stats>
Message-ID: <fm2r001j728egfn6khavge0qrm0dhqgrvj@4ax.com>

On Tue, 20 Jan 2004 19:42:51 +0000 (GMT), Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote :

>On Tue, 20 Jan 2004, Roger D. Peng wrote:
>
>> Obviously, it was data.restore() that produced the error 
>> below.  However, I think S-PLUS 5 might not be supported by 
>> data.restore() in the `foreign' package since the docs there 
>> say it can only read objects from S-PLUS versions 3.x and 
>> 4.x (on Unix).
>
>Correct.  We don't have a description of the S4 (hence S-PLUS 5.x and 6.x) 
>data.dump format.  We recommend using data.dump(oldStyle=T) in those 
>versions of S-PLUS if possible.

I developed the data.restore code that's there by recognizing that the
data.dump output was closely related to the binary format, which I had
reverse-engineered several years before.

I imagine there are a couple of possibilities to update it to the
newer format:

1.  We could approach Insightful, and find out if they'd give us specs
for the format.  They might be published somewhere, or they might be
willing to let us base our implementation on their data.restore
function.

This would need someone who knows who to contact at Insightful so as
to maximize the probability of a positive response.  

2.  We could reverse engineer the format.  This is probably easier
than you'd think.  It's just a matter of creating instances of all of
the kinds of objects that you want to be able to read, and seeing what
the dump looks like, and then trying out the procedure on a larger
body of data, and iterating a few times.

It's hopeless to think that many complex objects will ever be
recoverable this way (the internals of R are different than S-PLUS),
but it shouldn't be too hard to get vectors and data.frames, and maybe
functions.

Duncan Murdoch



From neileastep at hotmail.com  Tue Jan 20 22:04:53 2004
From: neileastep at hotmail.com (Neil Eastep)
Date: Tue, 20 Jan 2004 16:04:53 -0500
Subject: [R] Ruby & R 
Message-ID: <Law15-F28ssZ8FgcWVG000047b9@hotmail.com>

I see the packages from OmegaHat -- RSPython and RSPerl, however, I don't 
see anything available for Ruby.

Is there a similar package for Ruby?  If, not, is there the possiblility of 
creating one?

Thx, Neil Eastep.


------------
"Try not.  Do, do!  Or do not.  There is no try"
Jedi Master Yoda



From andy_liaw at merck.com  Tue Jan 20 22:55:06 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 20 Jan 2004 16:55:06 -0500
Subject: [R] evaluation of discriminant functions+multivariate
	homosce dasticity
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7669@usrymx25.merck.com>

While I don't know anything about Box's M test, I googled around and found a
Matlab M-file that computes it.  Below is my straight-forward translation of
the code, without knowing Matlab or the formula (and done in a few minutes).
I hope this demonstrates one of Prof. Ripley's point: If you really want to
shoot yourself in the foot, you can probably program R to do that for you.

[BTW: I left the original comments largely intact.  The output I get from R
for the example is the same as what is shown in the comments.]

[BTW #2: I'd imagine the original Matlab code probably could be improved a
bit...]

Andy

=======================================================================
BoxMTest <- function(X, cl, alpha=0.05) {
  ## Multivariate Statistical Testing for the Homogeneity of Covariance
  ## Matrices by the Box's M. 
  ##
  ## Syntax: function [MBox] = BoxMTest(X,alpha) 
  ##      
  ## Inputs:
  ##     X - data matrix (Size of matrix must be n-by-(1+p); sample=column
1,
  ##         variables=column 2:p). 
  ##     alpha - significance level (default = 0.05). 
  ## Output:
  ##     MBox - the Box's M statistic.
  ##     Chi-sqr. or F - the approximation statistic test.
  ##     df's - degrees' of freedom of the approximation statistic test.
  ##     P - observed significance level.
  ##
  ## If the groups sample-size is at least 20 (sufficiently large),
  ## Box's M test takes a Chi-square approximation; otherwise it takes
  ## an F approximation.
  ##
  ## Example: For a two groups (g = 2) with three independent variables
  ##    (p = 3), we are interested in testing the homogeneity of covariances
  ##    matrices with a significance level = 0.05. The two groups have the
  ##    same sample-size n1 = n2 = 5.
  ##                                       Group
  ##                      ---------------------------------------      
  ##                            1                        2
  ##                      ---------------------------------------
  ##                       x1   x2   x3             x1   x2   x3
  ##                      ---------------------------------------
  ##                       23   45   15             277  230   63
  ##                       40   85   18             153   80   29
  ##                      215  307   60             306  440  105
  ##                      110  110   50             252  350  175
  ##                       65  105   24             143  205   42
  ##                      ---------------------------------------
  ##
  ##             Total data matrix must be:
  ##          X=[1 23 45 15;1 40 85 18;1 215 307 60;1 110 110 50;1 65 105
24;
  ##          2 277 230 63;2 153 80 29;2 306 440 105;2 252 350 175;2 143 205
42];
  ##
  ##             Calling on Matlab the function: 
  ##                MBoxtest(X,0.05)
  ##
  ##             Answer is:
  ##
  ##  ------------------------------------------------------------
  ##       MBox         F           df1          df2          P
  ##  ------------------------------------------------------------
  ##     27.1622     2.6293          6           463       0.0162
  ##  ------------------------------------------------------------
  ##  Covariance matrices are significantly different.
  ##
  
  ##  Created by A. Trujillo-Ortiz and R. Hernandez-Walls
  ##             Facultad de Ciencias Marinas
  ##             Universidad Autonoma de Baja California
  ##             Apdo. Postal 453
  ##             Ensenada, Baja California
  ##             Mexico.
  ##             atrujo at uabc.mx
  ##  And the special collaboration of the post-graduate students of the
2002:2
  ##  Multivariate Statistics Course: Karel Castro-Morales,
  ##  Alejandro Espinoza-Tenorio, Andrea Guia-Ramirez, Raquel Muniz-Salazar,
  ##  Jose Luis Sanchez-Osorio and Roberto Carmona-Pina.
  ##  November 2002.
  ##
  ##  To cite this file, this would be an appropriate format:
  ##  Trujillo-Ortiz, A., R. Hernandez-Walls, K. Castro-Morales,
  ##  A. Espinoza-Tenorio, A. Guia-Ramirez and R. Carmona-Pina. (2002).
  ##  MBoxtest: Multivariate Statistical Testing for the Homogeneity of 
  ##  Covariance Matrices by the Box's M. A MATLAB file. [WWW document]. 
  ##  URL
http://www.mathworks.com/matlabcentral/fileexchange/loadFile.do?objectId=273
3&objectType=FILE
  ##
  ##  References:
  ## 
  ##  Stevens, J. (1992), Applied Multivariate Statistics for Social
Sciences.
  ##  2nd. ed., New-Jersey:Lawrance Erlbaum Associates Publishers. pp.
260-269.
  
  if (alpha <= 0 || alpha >= 1)
    stop('significance level must be between 0 and 1')

  g = nlevels(cl)  ## Number of groups.
  n = table(cl)    ## Vector of groups-size.

  N = nrow(X)
  p = ncol(X)

  bandera = 2
  if (any(n >= 20)) bandera = 1

  ## Partition of the group covariance matrices.
  covList <- tapply(X, rep(cl, ncol(X)), function(x, nc) cov(matrix(x,
nc=nc)),
                    ncol(X))

  deno = sum(n) - g
  suma = array(0, dim=dim(covList[[1]]))

  for (k in 1:g) 
    suma = suma + (n[k] - 1) * covList[[k]]

  Sp = suma / deno  ## Pooled covariance matrix.
  Falta=0

  for (k in 1:g) 
    Falta = Falta + ((n[k] - 1) * log(det(covList[[k]])))
  
  MB = (sum(n) - g) * log(det(Sp)) - Falta  ## Box's M statistic.
  suma1 = sum(1 / (n[1:g] - 1))
  suma2 = sum(1 / ((n[1:g] - 1)^2))
  C = (((2 * p^2) + (3 * p) - 1) / (6 * (p + 1) * (g - 1))) *
    (suma1 - (1 / deno))  ## Computing of correction factor.
  if (bandera == 1) {
    X2 = MB * (1 - C)                ## Chi-square approximation.
    v = as.integer((p * (p + 1) * (g - 1)) / 2)  ## Degrees of freedom.
    ## Significance value associated to the observed Chi-square statistic.
    P = pchisq(X2, v, lower=TRUE)   

    cat('------------------------------------------------\n');
    cat('     MBox     Chi-sqr.         df          P\n')
    cat('------------------------------------------------\n')
    cat(sprintf("%10.4f%11.4f%12.i%13.4f\n", MB, X2, v, P))
    cat('------------------------------------------------\n')
    if (P >= alpha) {
      cat('Covariance matrices are not significantly different.\n')
    } else {
      cat('Covariance matrices are significantly different.\n')
    }
    return(list(MBox=MB, ChiSq=X2, df=v, pValue=P))
  } else {
    ## To obtain the F approximation we first define Co, which combined to
    ## the before C value are used to estimate the denominator degrees of
    ## freedom (v2); resulting two possible cases. 
    Co = (((p-1) * (p+2)) / (6 * (g-1))) * (suma2 - (1 / (deno^2)))
    if (Co - (C^2) >= 0) {
      v1 = as.integer((p * (p + 1) * (g - 1)) / 2)  ## Numerator DF.
      v21 = as.integer(trunc((v1 + 2) / (Co - (C^2))))  ## Denominator DF.
      F1 = MB * ((1 - C - (v1 / v21)) / v1) ## F approximation.
      ##  Significance value associated to the observed F statistic.
      P1 = pf(F1, v1, v21, lower=FALSE) 

 
cat('\n------------------------------------------------------------\n')
      cat('     MBox         F           df1          df2          P\n')
      cat('------------------------------------------------------------\n')
      cat(sprintf("%10.4f%11.4f%11.i%14.i%13.4f\n", MB, F1, v1, v21, P1))
      cat('------------------------------------------------------------\n')
      if (P1 >= alpha) {
        cat('Covariance matrices are not significantly different.\n')
      } else {
        cat('Covariance matrices are significantly different.\n')
      }   
      return(list(MBox=MB, F=F1, df1=v1, df2=v21, pValue=P1))
    } else {
      v1 = as.integer((p * (p + 1) * (g - 1)) / 2)     ## Numerator df.
      v22 = as.integer(trunc((v1 + 2) / ((C^2) - Co))) ## Denominator df.
      b = v22 / (1 - C - (2 / v22))
      F2 = (v22 * MB) / (v1 * (b - MB))  ## F approximation.
      ## Significance value associated to the observed F statistic.
      P2 = pf(F2, v1, v22, lower=FALSE)
      
 
cat('\n------------------------------------------------------------\n')
      cat('     MBox         F           df1          df2          P\n')
      cat('------------------------------------------------------------\n')
      cat(sprintf('%10.4f%11.4f%11.i%14.i%13.4f\n', MB, F2, v1, v22, P2))
      cat('------------------------------------------------------------\n')
      
      if (P2 >= alpha) {
        cat('Covariance matrices are not significantly different.\n')
      } else {
        cat('Covariance matrices are significantly different.\n')
      }
      return(list(MBox=MB, F=F2, df1=v1, df2=v22, pValue=P2))
    }
  }
}


> From: Janke ten Holt
> 
> Hello,
> 
> I am switching from SPSS-Windows to R-Linux. My university is very 
> SPSS-oriented so maybe that's the cause of my problems. I am 
> a beginner 
> in R and my assignments are SPSS-oriented, so I hope I don't annoy 
> anyone with my questions...
> 
> Right now I've got 2 problems:
> -I have to evaluate discriminant functions I have calculated with 
> lda(MASS). I can't find a measure that evaluates their significance 
> (Wilk's lambda in my textbook (Stevens,(2002),"Applied multivariate 
> statistics for the social sciences")and in SPSS). Is there a Wilk's 
> lambda for discriminant functions in R? or can I use an alternative 
> measure? or am I thinking in the wrong direction? I have searched the 
> help-archive to find similar questions to mine but no answer to them.
> 
> -My second problem: to check the assumption of multivariate 
> homoscedasticity I have to test if the variance-covariance 
> matrices for 
> my variables are homogene. My textbook suggests Box's M test. I can't 
> find this statistic in R. Again I have found similar questions in the 
> help-archives, but no answers. Is there a way to calculate 
> Box's M in R? 
> Or is there an alternative way to check for multivariate 
> homoscedasticity?
> 
> Any suggestion would be greatly appreciated!
> 
> Cheers,
> Janke ten Holt


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From jmacdon at med.umich.edu  Tue Jan 20 23:04:04 2004
From: jmacdon at med.umich.edu (James MacDonald)
Date: Tue, 20 Jan 2004 17:04:04 -0500
Subject: [R] problem with rcmd build R-devel
Message-ID: <s00d5f9f.064@med-gwia-02a.med.umich.edu>

Hi All,

I am having a problem with Rcmd build using R-devel on WinXP. If I try
to build a package using the --binary flag, I get the following error:

Error: cannot change to directory ' 'c:/TEMP/Rbuild.XXXX'  '

Where XXXX is some number. I can get Rcmd build to work using R-1.7.1
and R-1.8.0, so I don't think it is a permission problem. I looked at
the build file, and the relevant portion appears to be the same in all
versions:

 if($opt_binary) {
	my $libdir = "${R::Vars::TMPDIR}/Rbuild.$$";
	mkdir("$libdir", 0755)
	    or die "Cannot create directory '$libdir'\n";

If I do Rcmd install --build, I get a built .zip file, but it appears
that the temp directory is never used.

Any ideas?

TIA,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623



From armin at xss.de  Tue Jan 20 23:07:32 2004
From: armin at xss.de (Armin Roehrl)
Date: Tue, 20 Jan 2004 23:07:32 +0100
Subject: [R] Ruby & R
In-Reply-To: <Law15-F28ssZ8FgcWVG000047b9@hotmail.com>
References: <Law15-F28ssZ8FgcWVG000047b9@hotmail.com>
Message-ID: <400DA6A4.1000703@xss.de>

Neil Eastep wrote:

> I see the packages from OmegaHat -- RSPython and RSPerl, however, I 
> don't see anything available for Ruby.
>
> Is there a similar package for Ruby?  If, not, is there the 
> possiblility of creating one?
>
Did you already look at: ruby-rmathlib <http://rrb.sourceforge.net/dist/>?
http://www.approximity.com/cgi-bin/blogtari/index.rb/Tools/R at RubybindingsforR.txt

Good luck & yes, Ruby rocks .. like R :-)
    -A

----------------------------------------
Armin Roehrl, http://www.approximity.com
We manage risk

> Thx, Neil Eastep.
>
>
> ------------
> "Try not.  Do, do!  Or do not.  There is no try"
> Jedi Master Yoda
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>



From h.wickham at auckland.ac.nz  Wed Jan 21 00:45:43 2004
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Wed, 21 Jan 2004 12:45:43 +1300
Subject: [R] Combining several regressions
Message-ID: <400DBDA7.8050009@auckland.ac.nz>

I've a situation where I need to perform different regressions on 
different subsets of my data and then combine the resulting fitted 
values back into the original dataset (partly this is because loess 
doesn't do grouping, but I'd also like to approximate the shrinkage 
estimators of mixed models by giving low weights to observations in the 
groups other than the one I'm regressing).

For example, I want to fit separate loess regressions for each value of 
some conditioning value.  I can do the regressions with by(data.frame, 
conditioning.variable, function(subset) { loess(y ~ x, subset) })  but 
I'm at a loss as how to get the fitted values out and match them up with 
the rows in the original dataset.

Any suggestions?

Thanks,

Hadley



From p.dalgaard at biostat.ku.dk  Wed Jan 21 01:09:50 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Jan 2004 01:09:50 +0100
Subject: [R] Combining several regressions
In-Reply-To: <400DBDA7.8050009@auckland.ac.nz>
References: <400DBDA7.8050009@auckland.ac.nz>
Message-ID: <x28yk2cgc1.fsf@biostat.ku.dk>

Hadley Wickham <h.wickham at auckland.ac.nz> writes:

> For example, I want to fit separate loess regressions for each value
> of some conditioning value.  I can do the regressions with
> by(data.frame, conditioning.variable, function(subset) { loess(y ~ x,
> subset) })  but I'm at a loss as how to get the fitted values out and
> match them up with the rows in the original dataset.

> Any suggestions?

[Untested!]

b <- by(data.frame, conditioning.variable, 
        function(subset) { loess(y ~ x, subset) })

unsplit(lapply(b,fitted), conditioning.variable)

You might need to replace the by() by an

  lapply(split(data.frame,cond.var), FUN)

construction, but it doesn't look like it should be necessary.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From h.wickham at auckland.ac.nz  Wed Jan 21 01:43:29 2004
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Wed, 21 Jan 2004 13:43:29 +1300
Subject: [R] Combining several regressions
In-Reply-To: <x28yk2cgc1.fsf@biostat.ku.dk>
References: <400DBDA7.8050009@auckland.ac.nz> <x28yk2cgc1.fsf@biostat.ku.dk>
Message-ID: <400DCB31.6050007@auckland.ac.nz>


>b <- by(data.frame, conditioning.variable, 
>        function(subset) { loess(y ~ x, subset) })
>
>unsplit(lapply(b,fitted), conditioning.variable)
>
>  
>
That does the trick. Thanks!
Hadley



From mfischer at mail.usyd.edu.au  Wed Jan 21 05:37:18 2004
From: mfischer at mail.usyd.edu.au (mfischer@mail.usyd.edu.au)
Date: Wed, 21 Jan 2004 15:37:18 +1100
Subject: [R] MODREG source
Message-ID: <1074659838.400e01fe9af73@www-mail.usyd.edu.au>



Is the fortran source code for the MODREG package available?
If so can someone send me a zip file or point to a web address?

Thanks,

Matt.

-------------------------------------------------
This mail sent through IMP: www-mail.usyd.edu.au



From nuvolab at hotmail.com  Wed Jan 21 06:53:13 2004
From: nuvolab at hotmail.com (nuvo nuvo)
Date: Tue, 20 Jan 2004 21:53:13 -0800
Subject: [R] Better way to find function
Message-ID: <BAY2-F116ym4XeKoOxh000180de@hotmail.com>

To whom it may concern,

1. I would like to know if there is a command in R to choose a function for 
a given dataset. I am facing a difficult question about how to fit the data 
[ please attachment ]

2. Are there any function that will allow users to do the piecewise 
regression?

If not, is it going to be provide in the new updated version? What I am 
using is the piecewise logistic regression, but it doesn't have a continuous 
function though. I hope that R would have a specific command to do the 
piecewise (non)linear regression.

I would apprecaite your suggestion.

Sincerely yours,

Nhum

_________________________________________________________________
Rethink your business approach for the new year with the helpful tips here.



From nuvolab at hotmail.com  Wed Jan 21 06:56:25 2004
From: nuvolab at hotmail.com (nuvo nuvo)
Date: Tue, 20 Jan 2004 21:56:25 -0800
Subject: [R] Any Better way to find function
Message-ID: <BAY2-F55LhmXL3zF6GE0000a41f@hotmail.com>

To whom it may concern,


1. I would like to know if there is a command in R to choose a function for 
a given dataset. I am facing a difficult question about how to fit the data 
[ please attachment ]

2. Are there any function that will allow users to do the piecewise 
regression?

If not, is it going to be provide in the new updated version? What I am 
using is the piecewise logistic regression, but it doesn't have a continuous 
function though. I hope that R would have a specific command to do the 
piecewise (non)linear regression.


I would apprecaite your suggestion.


Sincerely yours,


Nhum

_________________________________________________________________
Let the new MSN Premium Internet Software make the most of your high-speed 
experience. http://join.msn.com/?pgmarket=en-us&page=byoa/prem&ST=1

From ligges at statistik.uni-dortmund.de  Wed Jan 21 08:36:13 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 21 Jan 2004 08:36:13 +0100
Subject: [R] MODREG source
In-Reply-To: <1074659838.400e01fe9af73@www-mail.usyd.edu.au>
References: <1074659838.400e01fe9af73@www-mail.usyd.edu.au>
Message-ID: <400E2BED.9020503@statistik.uni-dortmund.de>

mfischer at mail.usyd.edu.au wrote:

> 
> Is the fortran source code for the MODREG package available?
> If so can someone send me a zip file or point to a web address?
> 

It's one of the "base" packages, hence in the R sources:

PathToR/R/src/library/modreg

Uwe Ligges



From gomez at hsc.kuniv.edu.kw  Wed Jan 21 09:01:11 2004
From: gomez at hsc.kuniv.edu.kw (Gomez J. Edison)
Date: Wed, 21 Jan 2004 11:01:11 +0300
Subject: [R] Relative risk using GAM
Message-ID: <000c01c3dff4$bbcbdd60$36468d8b@hscnet.kuniv.edu.kw>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040121/bfb3b432/attachment.pl

From a.trapletti at bluewin.ch  Wed Jan 21 10:26:50 2004
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Wed, 21 Jan 2004 10:26:50 +0100
Subject: [R] How can I test if time series residuals' are uncorrelated
	?
In-Reply-To: <400B94F9.7080101@bluewin.ch>
References: <400B94F9.7080101@bluewin.ch>
Message-ID: <400E45DA.3040908@bluewin.ch>

Adrian Trapletti wrote:

>>
>>
>>>
>>> Ok I made Jarque-Bera test to the residuals (merv.reg$residual)
>>>
>>> library(tseries)
>>> jarque.bera.test(merv.reg$residual)
>>> X-squared = 1772.369, df = 2, p-value = < 2.2e-16
>>> And I reject the null hypotesis (H0: merv.reg$residual are normally
>>> distributed)
>>>
>>> So I know that:
>>> 1 - merv.reg$residual aren't independently distributed (Box-Ljung test)
>>> 2 - merv.reg$residual aren't indentically distributed (Breusch-Pagan 
>>> test)
>>> 3 - merv.reg$residual aren't normally distributed (Jarque-Bera test)
>>>
>>> My questions is:
>>> It is possible merv.reg$residual be uncorrelated ?
>>> cov[residual_t, residual_(t+k)] = 0 ?
>>> Even when residuals are not independent distributed !
>>
>>
>>
>>
>> Yes. E.g., in an ARCH(1) process, cov[y_t, y_(t+k) ] = 0 (k \neq 0), 
>> but cov[(y_t)2, (y_(t+k))2 ] \neq 0,
>
>
>
> The last equation should be autocov[y_t, y_(t+k)] \neq 0 or 
> equivalently cov[(y_t)2, (y_(t+k))2 ] \neq (E[(y_t)2])2 

I don't know what I was thinking here, but it is a complete nonsense. My 
first remark (The line starting with "Yes.") was just correct.

best
Adrian



From giampi at speech.kth.se  Wed Jan 21 10:38:26 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Wed, 21 Jan 2004 10:38:26 +0100 (CET)
Subject: [R] remote data I/O
In-Reply-To: <000c01c3de77$494e2b40$36468d8b@hscnet.kuniv.edu.kw>
References: <000c01c3de77$494e2b40$36468d8b@hscnet.kuniv.edu.kw>
Message-ID: <Pine.LNX.4.58.0401211023400.6823@bayes.speech.kth.se>

Hi,
I wonder if it is possible to read data on another computer (unix like system)
using ssh (I mean any of ssh, scp, sftp). I saw that R has no problem reading
files across the net (for example read.table(url("http://www...")) ), but what
if the file is on a local disk of another machine? For security reasons we are
not allowed to have the normal ftp (and telnet) running.

I played a bit with url(file://), but I don't know how (if it's possible) to
specify both the address of the computer and the file name. I tried like this
url("file://host_name/path/filename") and url("file://host_name:/path/filename")
but it didn't work.

I want to do this because my data files are big (500Mb) and I don'r want to have
copies on every computer I use.

Thank you!
Giampiero



From giampi at speech.kth.se  Wed Jan 21 11:32:09 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Wed, 21 Jan 2004 11:32:09 +0100 (CET)
Subject: [R] remote data I/O
In-Reply-To: <Pine.LNX.4.58.0401211023400.6823@bayes.speech.kth.se>
References: <000c01c3de77$494e2b40$36468d8b@hscnet.kuniv.edu.kw>
	<Pine.LNX.4.58.0401211023400.6823@bayes.speech.kth.se>
Message-ID: <Pine.LNX.4.58.0401211129530.6823@bayes.speech.kth.se>

I solved my problem this way (if somebody is interested):

pipe("ssh hostname 'cat path/filename'"))

I guess I could even use gzip instead of cat or the ssh option -C to compress
the data that has to be transferred.

R rocks!

Giampiero

On Wed, 21 Jan 2004, Giampiero Salvi wrote:

> Hi,
> I wonder if it is possible to read data on another computer (unix like system)
> using ssh (I mean any of ssh, scp, sftp). I saw that R has no problem reading
> files across the net (for example read.table(url("http://www...")) ), but what
> if the file is on a local disk of another machine? For security reasons we are
> not allowed to have the normal ftp (and telnet) running.
>
> I played a bit with url(file://), but I don't know how (if it's possible) to
> specify both the address of the computer and the file name. I tried like this
> url("file://host_name/path/filename") and url("file://host_name:/path/filename")
> but it didn't work.
>
> I want to do this because my data files are big (500Mb) and I don'r want to have
> copies on every computer I use.
>
> Thank you!
> Giampiero
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Jan 21 12:14:29 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Jan 2004 11:14:29 +0000 (GMT)
Subject: [R] remote data I/O
In-Reply-To: <Pine.LNX.4.58.0401211023400.6823@bayes.speech.kth.se>
Message-ID: <Pine.LNX.4.44.0401210956500.2824-100000@gannet.stats>

On Wed, 21 Jan 2004, Giampiero Salvi wrote:

> Hi,
> I wonder if it is possible to read data on another computer (unix like system)
> using ssh (I mean any of ssh, scp, sftp). I saw that R has no problem reading
> files across the net (for example read.table(url("http://www...")) ), but what
> if the file is on a local disk of another machine? For security reasons we are
> not allowed to have the normal ftp (and telnet) running.
> 
> I played a bit with url(file://), but I don't know how (if it's possible) to
> specify both the address of the computer and the file name. I tried like this
> url("file://host_name/path/filename") and url("file://host_name:/path/filename")
> but it didn't work.

It is not part of the file:// schema.  On some OSes you can transparently
access exported files on other machines, in which case you don't need to 
use url(), as file() will do.  (Windows NT is one.)

> I want to do this because my data files are big (500Mb) and I don'r want to have
> copies on every computer I use.

R has no built-in ssh support.  Nor could it given the diverse variants of 
ssh that are running (and the unfortunate tendency of OpenSSH 
installations to refer to themselves as ssh2, yet be incompatible with 
ssh2 as originally released by the company SSH).

You could use something like pipe("ssh myserver cat myfile"), or you could 
make a copy to a temporary area and read that (which would be better for 
read.table as that needs to re-read parts of the file).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Friedrich.Leisch at ci.tuwien.ac.at  Wed Jan 21 12:23:57 2004
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Wed, 21 Jan 2004 12:23:57 +0100
Subject: [R] R News Volume 3/3
Message-ID: <16398.24909.685006.795255@galadriel.ci.tuwien.ac.at>


We have published the 2003/3 issue of R News on

	http://cran.R-project.org/doc/Rnews

where you can download the newsletter as PDF or Postscript file. It
will propagate to the CRAN mirrors within a day or two.

Contents of this issue:

Dimensional Reduction for Data Mapping
R as a Simulation Platform in Ecological Modelling
Using R for Estimating Longitudinal Student Achievement Models
lmeSplines
Debugging Without (Too Many) Tears
Th R2HTML Package
R Help Desk: Package Management
Programmer's Niche: Regular Expressions
Recent Events
Upcoming Events
Changes in R 1.8.1
Changes on CRAN
R Foundation News


For the editorial board,
Fritz Leisch

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-announce



From ozric at web.de  Wed Jan 21 12:49:44 2004
From: ozric at web.de (Christian Schulz)
Date: Wed, 21 Jan 2004 12:49:44 +0100
Subject: [R] Oracle RODBC/ROracle(W2k)
Message-ID: <200401211249.44182.ozric@web.de>

Hi,

trying the access to  Oracle via ODBC in Win2k/1.8.1 i have only 2 problems.
(1) number(x,y) formats in oracle result in R-Project as a factor with more 
than  20.000 levels for every distinct value.
My coversion attempts until now failed, i.e.  as.numeric(money)  result
in a:
Error in as.double.default(money) : (list) object cannot coerced to double

(2) A attempt to save a  data.frame result in a:
Error in sqlSave(channel,SAVETTEST,colnames=T)
Missing column name 
Check case conversion parameter in odbcConnect

Now i see the table with headers and without rows in oracle.

P.S.
Anyboddy know why this error occur(win2k,1.8.1!)?
Installation and compiling of (DBI) and (ROracle) works
fine. Now i try the example from docs:

library(DBI)
library(ROracle)
ora <- dbDriver("Oracle")
Error in .Call("RS_Ora_init",config.params,reload,Package=.OraPkgName)
.Call function name not in load table

Maybe a missing environment variable?

Many thanks for hints to fix this
problems, 
Christian



From Timur.Elzhov at jinr.ru  Wed Jan 21 12:54:58 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Wed, 21 Jan 2004 14:54:58 +0300
Subject: [R] derivative of atan(x) and similar functions
Message-ID: <20040121115458.GA1885@nf034.jinr.ru>

Dear R experts.

'D()' function recognizes some of the analitical functions, such as
sin, cos, etc. But I'd like to take analytical derivatives from asin,
atan etc. functions. Are there any R packages providing that features?

Thanks.

--
Timur.



From juli at ceam.es  Wed Jan 21 12:56:58 2004
From: juli at ceam.es (juli g. pausas)
Date: Wed, 21 Jan 2004 12:56:58 +0100
Subject: [R] subset select within a function
Message-ID: <400E690A.4010304@ceam.es>

Dear all,
I'd like to subset a df within a function, and use select for choosing 
the variable. Something like (simplified example):

mydf <- data.frame(a= 0:9, b= 10:19)

ttt <- function(vv) {
  tmpdf <- subset(mydf, select= vv)
  mean(tmpdf$vv)
}

ttt(mydf$b)

But this is not the correct way. Any help?
Thanks in advance

Juli



From kamoun_wassim at yahoo.fr  Wed Jan 21 13:06:15 2004
From: kamoun_wassim at yahoo.fr (=?iso-8859-1?q?Wassim=20Kamoum?=)
Date: Wed, 21 Jan 2004 13:06:15 +0100 (CET)
Subject: [R] Hello
Message-ID: <20040121120615.58544.qmail@web41307.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040121/d6041037/attachment.pl

From ripley at stats.ox.ac.uk  Wed Jan 21 13:20:48 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Jan 2004 12:20:48 +0000 (GMT)
Subject: [R] Oracle RODBC/ROracle(W2k)
In-Reply-To: <200401211249.44182.ozric@web.de>
Message-ID: <Pine.LNX.4.44.0401211217410.3800-100000@gannet.stats>

On Wed, 21 Jan 2004, Christian Schulz wrote:

> Hi,
> 
> trying the access to  Oracle via ODBC in Win2k/1.8.1 i have only 2 problems.
> (1) number(x,y) formats in oracle result in R-Project as a factor with more 
> than  20.000 levels for every distinct value.
> My coversion attempts until now failed, i.e.  as.numeric(money)  result
> in a:
> Error in as.double.default(money) : (list) object cannot coerced to double

Presumably money is a data frame.  See the FAQ on how to convert a factor 
to numeric (hint: not by as.numeric).

> (2) A attempt to save a  data.frame result in a:
> Error in sqlSave(channel,SAVETTEST,colnames=T)
> Missing column name 
> Check case conversion parameter in odbcConnect
> 
> Now i see the table with headers and without rows in oracle.

Did you do the check you were asked to?

You have the R code (and indeed the C sources), and we don't have an 
Oracle ODBC client (nor have you told us what you are using).  It really 
isn't hard for an end-user to debug this sort of thing.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pallier at lscp.ehess.fr  Wed Jan 21 13:41:13 2004
From: pallier at lscp.ehess.fr (Pallier Christophe-INSERM U.562)
Date: Wed, 21 Jan 2004 13:41:13 +0100
Subject: [R] repeated measurements with R
Message-ID: <400E7369.5060405@lscp.ehess.fr>

>
>
>The problem is the following:
>We have 2 different solutions (samples), which are filtered and then
>the concentration of the filtrate is measured.
>
>We want to evaluate how the filter proces and the concentration
>measurement influences the detection of the difference of the two
>solutions and which step has which influence. So we filter the 2
>solutions each 6 times and get 12 filterd solutions. each of this
>filtrate is measured 8 times, so we get 12 *8 96 conc. values. i get a
>data table of:
>
>solution nr.filter nr.measures conc.
>1 or 2    1 till 6  1-till 8    96 values
>because the concentrations are "repeated measurements" as i was told
>by a statistician (i am not) it is not allowed to make a anova with
>the formula: conc~solution+nr.filter+nr.measures.
>
>my question is: 
>how can i solve this in R?
>
R can handle some repeated measurements designs with the 'Error' term in 
the formula provided to aov.
(see the section on multistratum models in MASS)
(if you can read French, some examples are provided  in a small tutorial 
about R available at 
http://www.pallier.org/ressources/stats_with_R/stats_with_R.pdf (work in 
progress)).

More complex designs can be analysed with lme (described in the book 
Mixed Effects models in S and S-PLUS by Pinheiro and Bates)
 
But, you should first precise your questions, that is make clear what is 
the unit of analysis, and wether
 'solution', 'nr.filter' and 'nr.measures'  are random or fixed factors.

*Maybe* your problem can be desribed in the following way (?)

you had twelve samples (=filtered solutions) which came from two 
solutions and you applied the same 6 different filtering processes to each
of these samples. Solution and nr.filter are fixed factors, and you are 
interested in assessing their main effects and interaction.

If this is indeed the structure of your problem, then you should define 
a new factor 'sample' with 12 levels equal to 'solution:nr.measure', and 
use the following formula for the anova:

summary(aov(conc~solution*nr.filter+Error(sample/nr.filter)))

Do not use this if you do not understand the hypotheses underlying this 
approach.
For example, if you believe that there is an effect of the time at which 
the samples
were taken from the solution, then this approach is not valid.

If solution and/or filter are  random factors, then the analysis will 
also differ...

Christophe Pallier
www.pallier.org



From sdavis2 at mail.nih.gov  Wed Jan 21 13:49:29 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 21 Jan 2004 07:49:29 -0500
Subject: [R] subset select within a function
In-Reply-To: <400E690A.4010304@ceam.es>
Message-ID: <BC33DF89.38E4%sdavis2@mail.nih.gov>

Juli,

Check again in the help about how to use the select parameter.  You need to
pass the column name for the column of interest, not the actual column.
Also, your tmpdf will already have the column selected, so there is no need
to index the column further, at least in this toy example.  In this case, I
think you could use something like:

> tt
function(vv) {
tmpdf <- subset(mydf,select=vv)
mean(tmpdf)
}
> tt("b")
   b
14.5

Sean


On 1/21/04 6:56 AM, "juli g. pausas" <juli at ceam.es> wrote:

> Dear all,
> I'd like to subset a df within a function, and use select for choosing
> the variable. Something like (simplified example):
> 
> mydf <- data.frame(a= 0:9, b= 10:19)
> 
> ttt <- function(vv) {
> tmpdf <- subset(mydf, select= vv)
> mean(tmpdf$vv)
> }
> 
> ttt(mydf$b)
> 
> But this is not the correct way. Any help?
> Thanks in advance
> 
> Juli
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From s-plus at wiwi.uni-bielefeld.de  Wed Jan 21 14:27:34 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Wed, 21 Jan 2004 14:27:34 +0100
Subject: [R] subset select within a function
References: <400E690A.4010304@ceam.es>
Message-ID: <400E7E46.4050603@wiwi.uni-bielefeld.de>

juli g. pausas wrote:

> Dear all,
> I'd like to subset a df within a function, and use select for choosing 
> the variable. Something like (simplified example):
>
> mydf <- data.frame(a= 0:9, b= 10:19)
>
> ttt <- function(vv) {
>  tmpdf <- subset(mydf, select= vv)
>  mean(tmpdf$vv)
> }
>
> ttt(mydf$b)
>
> But this is not the correct way. Any help?
> Thanks in advance
>
> Juli
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

are you looking for something like:

mydf <- data.frame(a= 0:9, b= 10:19)
ttt <- function(vv) {
 tmpdf <- subset(mydf, select= vv)
 lapply(tmpdf,mean)
}
ttt("b") $b
[1] 14.5
 > ttt(c("a","b"))
$a
[1] 4.5
$b
[1] 14.5

??

Peter



From andy_liaw at merck.com  Wed Jan 21 15:10:06 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 21 Jan 2004 09:10:06 -0500
Subject: [R] Better way to find function
Message-ID: <3A822319EB35174CA3714066D590DCD504AF766F@usrymx25.merck.com>

For #1, could you clarify what you mean by `function', an R function, or a
regression function?

For #2, there are several packages on CRAN (and in the R distribution
itself) that fit regression splines, if that's what you meant by `piecewise
regression'.  For logistic regression, you can either use the bs() term in
glm(), or gam() in the `mgcv' package.

HTH,
Andy

> From: nuvo nuvo
> 
> To whom it may concern,
> 
> 1. I would like to know if there is a command in R to choose 
> a function for 
> a given dataset. I am facing a difficult question about how 
> to fit the data 
> [ please attachment ]
> 
> 2. Are there any function that will allow users to do the piecewise 
> regression?
> 
> If not, is it going to be provide in the new updated version? 
> What I am 
> using is the piecewise logistic regression, but it doesn't 
> have a continuous 
> function though. I hope that R would have a specific command 
> to do the 
> piecewise (non)linear regression.
> 
> I would apprecaite your suggestion.
> 
> Sincerely yours,
> 
> Nhum
> 
> _________________________________________________________________
> Rethink your business approach for the new year with the 
> helpful tips here.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From vfasciani at micron.com  Wed Jan 21 15:53:34 2004
From: vfasciani at micron.com (vfasciani@micron.com)
Date: Wed, 21 Jan 2004 07:53:34 -0700
Subject: [R] invoking R scripts from a linux shell ?
Message-ID: <2831746CECBA4F4C86F6076F4FC4C3C10E5850@ntxavzmbx02.azit.micron.com>

Ciao Enrico,

I think you can skip to use a shell as you described.
There are some ways to include R script in a perl script.
I included below two examples I wrote for better understand.


###### prova1.pl #######

#!/usr/local/bin/perl
open (FILE, ">test.txt");
print FILE "a,b,c,d,e\n1,2,3,4,5";
close FILE;

####### Start R code ####
open (R_FH, "|/usr/local/bin/R --no-save --slave") or die "$!";

print R_FH qq{
data<-read.csv("test.txt")
datamean<-mean(as.numeric(as.character(data[1,])), na.rm=TRUE)
write(datamean, file="out.txt")
quit(save='no',status=0)
};

close R_FH;
##### end R ####

open(FILE, "<out.txt");
while (<FILE>){
$mean= $_;
}
close FILE;

print "Mean= ".$mean;



or

######## prova2.pl ######

#!/usr/local/bin/perl
open (FILE, ">test.txt");
print FILE "a,b,c,d,e\n1,2,3,4,5";
close FILE;

####### Start R code ####
system("/usr/local/bin/R -q --vanilla < rscript.r > debug.out");
##### end R ####

open(FILE, "<out.txt");
while (<FILE>){
$mean= $_;
}
close FILE;

print "Mean= ".$mean;

... in this way you can call the perl script only.

Regards,
Vittorio



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Enrico Curiotto
Sent: Friday, January 16, 2004 12:02 AM
To: r-help at stat.math.ethz.ch
Subject: [R] invoking R scripts from a linux shell ?


Hello,

I have written perl programs that extract data from a
text file, process them, and create other text files,
which I'd like to apply some statistics too (for
example with R).

I'd like to do it all in once , with a single script.
I'm not familiar with R, I'd like to know if this task
could be accomplished by creating a linux shells that
launches the perl scripts and then "R functions" that
maybe pass back some results to the system like in
this schema:

S ---> Perl
H <-----
E ---> R functions
L <-----
L

Is it possible ?
Where can I get information to do that? (to call R
from a shell, in background)

Are other better way to do that?

Thank you very much!

Enrico.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From daandrae at yahoo.com  Wed Jan 21 16:58:02 2004
From: daandrae at yahoo.com (Dave Andrae)
Date: Wed, 21 Jan 2004 07:58:02 -0800 (PST)
Subject: [R] evaluation of discriminant functions+multivariate homosce
	dasticity
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7669@usrymx25.merck.com>
Message-ID: <20040121155802.4542.qmail@web40614.mail.yahoo.com>

I seem to remember, from a course in which I used SPSS for LDA, that
Box's M is an ultra-sensitive test as well and that in almost all
practical applications it's not useful, so Prof. Ripley's comments
apply to that test, too.


HTH,

Dave

--- "Liaw, Andy" <andy_liaw at merck.com> wrote:
> While I don't know anything about Box's M test, I googled around and
> found a
> Matlab M-file that computes it.  Below is my straight-forward
> translation of
> the code, without knowing Matlab or the formula (and done in a few
> minutes).
> I hope this demonstrates one of Prof. Ripley's point: If you really
> want to
> shoot yourself in the foot, you can probably program R to do that for
> you.
> 
> [BTW: I left the original comments largely intact.  The output I get
> from R
> for the example is the same as what is shown in the comments.]
> 
> [BTW #2: I'd imagine the original Matlab code probably could be
> improved a
> bit...]
> 
> Andy
> 
>
=======================================================================
> BoxMTest <- function(X, cl, alpha=0.05) {
>   ## Multivariate Statistical Testing for the Homogeneity of
> Covariance
>   ## Matrices by the Box's M. 
>   ##
>   ## Syntax: function [MBox] = BoxMTest(X,alpha) 
>   ##      
>   ## Inputs:
>   ##     X - data matrix (Size of matrix must be n-by-(1+p);
> sample=column
> 1,
>   ##         variables=column 2:p). 
>   ##     alpha - significance level (default = 0.05). 
>   ## Output:
>   ##     MBox - the Box's M statistic.
>   ##     Chi-sqr. or F - the approximation statistic test.
>   ##     df's - degrees' of freedom of the approximation statistic
> test.
>   ##     P - observed significance level.
>   ##
>   ## If the groups sample-size is at least 20 (sufficiently large),
>   ## Box's M test takes a Chi-square approximation; otherwise it
> takes
>   ## an F approximation.
>   ##
>   ## Example: For a two groups (g = 2) with three independent
> variables
>   ##    (p = 3), we are interested in testing the homogeneity of
> covariances
>   ##    matrices with a significance level = 0.05. The two groups
> have the
>   ##    same sample-size n1 = n2 = 5.
>   ##                                       Group
>   ##                      ---------------------------------------    
>  
>   ##                            1                        2
>   ##                      ---------------------------------------
>   ##                       x1   x2   x3             x1   x2   x3
>   ##                      ---------------------------------------
>   ##                       23   45   15             277  230   63
>   ##                       40   85   18             153   80   29
>   ##                      215  307   60             306  440  105
>   ##                      110  110   50             252  350  175
>   ##                       65  105   24             143  205   42
>   ##                      ---------------------------------------
>   ##
>   ##             Total data matrix must be:
>   ##          X=[1 23 45 15;1 40 85 18;1 215 307 60;1 110 110 50;1 65
> 105
> 24;
>   ##          2 277 230 63;2 153 80 29;2 306 440 105;2 252 350 175;2
> 143 205
> 42];
>   ##
>   ##             Calling on Matlab the function: 
>   ##                MBoxtest(X,0.05)
>   ##
>   ##             Answer is:
>   ##
>   ##  ------------------------------------------------------------
>   ##       MBox         F           df1          df2          P
>   ##  ------------------------------------------------------------
>   ##     27.1622     2.6293          6           463       0.0162
>   ##  ------------------------------------------------------------
>   ##  Covariance matrices are significantly different.
>   ##
>   
>   ##  Created by A. Trujillo-Ortiz and R. Hernandez-Walls
>   ##             Facultad de Ciencias Marinas
>   ##             Universidad Autonoma de Baja California
>   ##             Apdo. Postal 453
>   ##             Ensenada, Baja California
>   ##             Mexico.
>   ##             atrujo at uabc.mx
>   ##  And the special collaboration of the post-graduate students of
> the
> 2002:2
>   ##  Multivariate Statistics Course: Karel Castro-Morales,
>   ##  Alejandro Espinoza-Tenorio, Andrea Guia-Ramirez, Raquel
> Muniz-Salazar,
>   ##  Jose Luis Sanchez-Osorio and Roberto Carmona-Pina.
>   ##  November 2002.
>   ##
>   ##  To cite this file, this would be an appropriate format:
>   ##  Trujillo-Ortiz, A., R. Hernandez-Walls, K. Castro-Morales,
>   ##  A. Espinoza-Tenorio, A. Guia-Ramirez and R. Carmona-Pina.
> (2002).
>   ##  MBoxtest: Multivariate Statistical Testing for the Homogeneity
> of 
>   ##  Covariance Matrices by the Box's M. A MATLAB file. [WWW
> document]. 
>   ##  URL
>
http://www.mathworks.com/matlabcentral/fileexchange/loadFile.do?objectId=273
> 3&objectType=FILE
>   ##
>   ##  References:
>   ## 
>   ##  Stevens, J. (1992), Applied Multivariate Statistics for Social
> Sciences.
>   ##  2nd. ed., New-Jersey:Lawrance Erlbaum Associates Publishers.
> pp.
> 260-269.
>   
>   if (alpha <= 0 || alpha >= 1)
>     stop('significance level must be between 0 and 1')
> 
>   g = nlevels(cl)  ## Number of groups.
>   n = table(cl)    ## Vector of groups-size.
> 
>   N = nrow(X)
>   p = ncol(X)
> 
>   bandera = 2
>   if (any(n >= 20)) bandera = 1
> 
>   ## Partition of the group covariance matrices.
>   covList <- tapply(X, rep(cl, ncol(X)), function(x, nc)
> cov(matrix(x,
> nc=nc)),
>                     ncol(X))
> 
>   deno = sum(n) - g
>   suma = array(0, dim=dim(covList[[1]]))
> 
>   for (k in 1:g) 
>     suma = suma + (n[k] - 1) * covList[[k]]
> 
>   Sp = suma / deno  ## Pooled covariance matrix.
>   Falta=0
> 
>   for (k in 1:g) 
>     Falta = Falta + ((n[k] - 1) * log(det(covList[[k]])))
>   
>   MB = (sum(n) - g) * log(det(Sp)) - Falta  ## Box's M statistic.
>   suma1 = sum(1 / (n[1:g] - 1))
>   suma2 = sum(1 / ((n[1:g] - 1)^2))
>   C = (((2 * p^2) + (3 * p) - 1) / (6 * (p + 1) * (g - 1))) *
>     (suma1 - (1 / deno))  ## Computing of correction factor.
>   if (bandera == 1) {
>     X2 = MB * (1 - C)                ## Chi-square approximation.
>     v = as.integer((p * (p + 1) * (g - 1)) / 2)  ## Degrees of
> freedom.
>     ## Significance value associated to the observed Chi-square
> statistic.
>     P = pchisq(X2, v, lower=TRUE)   
> 
>     cat('------------------------------------------------\n');
>     cat('     MBox     Chi-sqr.         df          P\n')
>     cat('------------------------------------------------\n')
>     cat(sprintf("%10.4f%11.4f%12.i%13.4f\n", MB, X2, v, P))
>     cat('------------------------------------------------\n')
>     if (P >= alpha) {
>       cat('Covariance matrices are not significantly different.\n')
>     } else {
>       cat('Covariance matrices are significantly different.\n')
>     }
>     return(list(MBox=MB, ChiSq=X2, df=v, pValue=P))
>   } else {
>     ## To obtain the F approximation we first define Co, which
> combined to
>     ## the before C value are used to estimate the denominator
> degrees of
>     ## freedom (v2); resulting two possible cases. 
>     Co = (((p-1) * (p+2)) / (6 * (g-1))) * (suma2 - (1 / (deno^2)))
>     if (Co - (C^2) >= 0) {
>       v1 = as.integer((p * (p + 1) * (g - 1)) / 2)  ## Numerator DF.
>       v21 = as.integer(trunc((v1 + 2) / (Co - (C^2))))  ##
> Denominator DF.
>       F1 = MB * ((1 - C - (v1 / v21)) / v1) ## F approximation.
>       ##  Significance value associated to the observed F statistic.
>       P1 = pf(F1, v1, v21, lower=FALSE) 
> 
>  
>
cat('\n------------------------------------------------------------\n')
>       cat('     MBox         F           df1          df2         
> P\n')
>      
> cat('------------------------------------------------------------\n')
>       cat(sprintf("%10.4f%11.4f%11.i%14.i%13.4f\n", MB, F1, v1, v21,
> P1))
> 
=== message truncated ===



From martinol at ensam.inra.fr  Wed Jan 21 16:41:00 2004
From: martinol at ensam.inra.fr (Martin Olvier)
Date: Wed, 21 Jan 2004 16:41:00 +0100
Subject: [R] varimax rotaion
Message-ID: <400E9D8C.2030705@ensam.inra.fr>

Hi all,

Does anyone know where I can find a program to perform a "varimax" (i.e. a maximum variance)
rotation of the principal component vectors?
Thanks in advance.

Olivier



From joehl at gmx.de  Wed Jan 21 17:57:21 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Wed, 21 Jan 2004 17:57:21 +0100 (MET)
Subject: [R] outlier identification: is there a redundancy-invariant
	substitution for mahalanobis distances?
Message-ID: <499.1074704241@www10.gmx.net>



Dear R-experts,

Searching the help archives I found a recommendation to do multivariate
outlier identification by mahalanobis distances based on a robustly estimated
covariance matrix and compare the resulting distances to a chi^2-distribution
with p (number of your variables) degrees of freedom. I understand that
compared to euclidean distances this has the advantage of being scale-invariant.
However, it seems that such mahalanobis distances are not invariant to
redundancies: adding a highly collinear variable changes the mahalanobis distances
(see code below). Isn't also the comparision to chi^2 assuming that all
variables are independent?

Can anyone recommend a procedure to calculate distances and identify
multivariate outliers which is invariant to the degree of collinearity?

Thanks to any advice



Jens Oehlschl?gel



# Example code
library(MASS)

# generate bivariate normal test data
n <- 500
x <- matrix(rnorm(n*2), ncol=2)
# scale, otherwise euclidean fails
x <- scale(x)
cr <- cov.rob(x, method="mcd")
center <- cr$center
# calculate squared euclidean and mahalanobis
d <- rowSums(t(t(x)-center)^2)
m <- as.vector(mahalanobis(x, center, cr$cov))
# euclidean an dmahalanobis basically coincide, mahalanobis slightly biased
by robust covariance underestimation
eqscplot(x=d, y=m); abline(0,1)


# Now I add a highly redundant column in hope the distances between cases
will not change
x2 <- cbind(x, x[,1]+rnorm(n, sd=0.01))
# scale, otherwise euclidean fails
x2 <- scale(x2)
cr2 <- cov.rob(x2, method="mcd")
center2 <- cr2$center
d2 <- rowSums(t(t(x2)-center2)^2)
m2 <- as.vector(mahalanobis(x2, center2, cr2$cov))
# though equally scaled, euclidean and mahalanobis diverge
eqscplot(x=d2, y=m2); abline(0,1)

# mahalanobis distances are obviously not redundancy invariant
eqscplot(x=m, y=m2); abline(0,1)
# especially if rank order of distances is considered
eqscplot(x=rank(m), y=rank(m2)); abline(0,1)
cor(m, m2)
cor(m, m2, method="spearman")

# euclidean distances look better but are also not redundancy invariant
eqscplot(x=d, y=d2); abline(0,1)
eqscplot(x=rank(d), y=rank(d2)); abline(0,1)
cor(d, d2)
cor(d, d2, method="spearman")


-- 

Bis 31.1.: TopMail + Digicam f?r nur 29 EUR http://www.gmx.net/topmail



From feldesmanm at pdx.edu  Wed Jan 21 18:05:12 2004
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Wed, 21 Jan 2004 09:05:12 -0800
Subject: [R] evaluation of discriminant functions+multivariate
	homosce dasticity
In-Reply-To: <20040121155802.4542.qmail@web40614.mail.yahoo.com>
References: <3A822319EB35174CA3714066D590DCD504AF7669@usrymx25.merck.com>
	<20040121155802.4542.qmail@web40614.mail.yahoo.com>
Message-ID: <6.0.1.1.2.20040121085947.02f1bd10@pop4.attglobal.net>

At 07:58 AM 1/21/2004, Dave Andrae wrote:
 >I seem to remember, from a course in which I used SPSS for LDA, that
 >Box's M is an ultra-sensitive test as well and that in almost all
 >practical applications it's not useful, so Prof. Ripley's comments
 >apply to that test, too.

Professor Ripley is quite right about Box's M.  I wrote a crude S-Plus 
script for this years ago to see if I could find a real (i.e. not 
simulated) data set for which Box's M would give a non-significant 
result.  Using data from my field (primate and human functional anatomy), I 
found no instance where my data weren't "non-normal" by Box's 
criterion.  And in many of those instances, lda worked "perfectly" anyway 
(i.e. 95 - 100% of cases correctly classified).

As far as I'm concerned, Box's M is of no use in anything I do.  At the 
same time, if you want the crude script (not guaranteed to work in R since 
I haven't bothered to test it), I'll send it to you b/c.  In my opinion, it 
isn't worth the effort to clean it up or to test it under R.



From spencer.graves at pdf.com  Wed Jan 21 18:13:24 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 21 Jan 2004 09:13:24 -0800
Subject: [R] varimax rotaion
In-Reply-To: <400E9D8C.2030705@ensam.inra.fr>
References: <400E9D8C.2030705@ensam.inra.fr>
Message-ID: <400EB334.5020107@pdf.com>

      Have you read the posting guide! 
"http://www.R-project.org/posting-guide.html"?  From www.r-project.org 
-> search -> R site search -> "varimax" produced 29 hits for me just 
now.  I would expect you should find several ways to approach your 
problem among the results there.  ("help.search('varimax') in R 1.8.1 
also produced something interesting.) 

      hope this helps. 
      spencer graves

Martin Olvier wrote:

> Hi all,
>
> Does anyone know where I can find a program to perform a "varimax" 
> (i.e. a maximum variance)
> rotation of the principal component vectors?
> Thanks in advance.
>
> Olivier
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From plummer at iarc.fr  Wed Jan 21 18:20:11 2004
From: plummer at iarc.fr (Martyn Plummer)
Date: Wed, 21 Jan 2004 18:20:11 +0100
Subject: [R] matrix exponential: M^0
In-Reply-To: <x2isj6vcgk.fsf@biostat.ku.dk>
References: <1074616806.2958.46.camel@monkey> <x2isj6vcgk.fsf@biostat.ku.dk>
Message-ID: <1074705611.13484.23.camel@xena.iarc.fr>

On Tue, 2004-01-20 at 16:58, Peter Dalgaard wrote:
> Federico Calboli <f.calboli at ucl.ac.uk> writes:
> 
> > Dear All, 
> > 
> > I would like to ask why the zeroeth power of a matrix gives me a matrix
> > of ones rather than the identity matrix:
> 
> Because arithmetic on a matrix works element-wise. M^2 is not equal to
> M %*% M either (but is equal to  M*M).
> 
> (R doesn't have the matrix exponential function. Lifting expm() from
> Octave has been on my (virtual) TODO list for some time now...)

There is nothing in base R, but the Christopher Jackson's msm package
and Jim Lindsey's rmutils both have a matrix exponential function
(MatrixExp and mexp, respectively). Neither are particularly
sophisticated, using either the spectral decomposition or series
expansion.

Calculating the matrix exponential is harder than it looks (I'm sure
Peter knows this). In fact there is a classic paper by Moler and Van
Loan from the 1970s called "Nineteen dubious ways to calculate the
exponential of a matrix", which they updated last year in SIAM. 

There is an interesting looking library of Fortran routines for
calculating matrix exponentials called expokit:

http://www.maths.uq.edu.au/expokit

It has "no commercial use" license.  I'm going to use it in my own
software (JAGS) but it might also be useful in R if you can understand
what the license means.

Martyn



From mlennert at club.worldonline.be  Wed Jan 21 18:23:32 2004
From: mlennert at club.worldonline.be (Moritz Lennert)
Date: Wed, 21 Jan 2004 18:23:32 +0100 (CET)
Subject: [R] weighted hierarchical cluster analysis
In-Reply-To: <16398.42941.796039.338781@gargle.gargle.HOWL>
References: <46686.164.15.134.155.1074700086.squirrel@moritz.homelinux.org> 
	<16398.42941.796039.338781@gargle.gargle.HOWL>
Message-ID: <47476.164.15.134.155.1074705812.squirrel@moritz.homelinux.org>

Hello,

After an exchange of mail with Martin Maechler, I turn to the list on hist
demand, trying to reformulate my question to make it clearer.

We are trying to submit data to a hierarchical cluster analysis which
weights each observation by a value given for each observation.

The weighting should occur at two moments in the process:

1) in the calculation of the distance by multiplying (for each pair) the
sum of squares by the product of the respective weights divided by the sum
of the weights (if two pairs of observations are of equal euclidian
distance, the pair with a higher weight should be considered of greater
distance)

2) in the calculation of the ward criterion, by not using just the number
of observations in each cluster, but a weighted sum of observations.

Has anyone implemented such a type of weighted hierarchical clustering
analysis ? If not, does this mean we would have to create new fortran or C
code to implement this ?

Thank you,

Moritz Lennert



From plummer at iarc.fr  Wed Jan 21 18:24:48 2004
From: plummer at iarc.fr (Martyn Plummer)
Date: Wed, 21 Jan 2004 18:24:48 +0100
Subject: [R] fedora and yum
In-Reply-To: <400735F3.20101@univie.ac.at>
References: <400735F3.20101@univie.ac.at>
Message-ID: <1074705888.13484.29.camel@xena.iarc.fr>

On Fri, 2004-01-16 at 01:53, Erich Neuwirth wrote:
> I just installed Fedora in VMWare.
> Can somebopdy tell me what lines i have to put in
> yum.conf
> so R will be automatically integrated in the package system
> and updated when a new release is available?

I don't think this is possible, yet. My understanding is that a yum
repository has a special directory of header files, and CRAN doesn't
have this.

Probably the best bet is for me to contribute R RPMS to the Fedora
project, or rather the project formerly known as the Red Hat Linux
project ( http://www.fedora.us ), which has its own yum repository. 
This hasn't been properly merged with the rest of Fedora, so I haven't
done so. I joined a previous attempt by Red Hat to contribute quality
3rd party RPMS but it fizzled out, so I hope you'll forgive me for not
jumping at this one.

Martyn



From ripley at stats.ox.ac.uk  Wed Jan 21 18:35:22 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Jan 2004 17:35:22 +0000 (GMT)
Subject: [R] outlier identification: is there a redundancy-invariant
	substitution for mahalanobis distances?
In-Reply-To: <499.1074704241@www10.gmx.net>
Message-ID: <Pine.LNX.4.44.0401211730001.4662-100000@gannet.stats>

Your extra column is not redundant: it adds an extra column of 
information, and outliers in that column after removing the effects of the 
other columns are still multivariate outliers.

Effectively you have added one more dimension to the sphered point cloud, 
and mahalanobis distance is Euclidean distance after sphering.

On Wed, 21 Jan 2004, "Jens Oehlschl?gel" wrote:

> 
> 
> Dear R-experts,
> 
> Searching the help archives I found a recommendation to do multivariate
> outlier identification by mahalanobis distances based on a robustly estimated
> covariance matrix and compare the resulting distances to a chi^2-distribution
> with p (number of your variables) degrees of freedom. I understand that
> compared to euclidean distances this has the advantage of being scale-invariant.
> However, it seems that such mahalanobis distances are not invariant to
> redundancies: adding a highly collinear variable changes the mahalanobis distances
> (see code below). Isn't also the comparision to chi^2 assuming that all
> variables are independent?

No.  It assumes that *after sphering* all variables are independent, which 
is true by definition for a joint normal distribution.

> Can anyone recommend a procedure to calculate distances and identify
> multivariate outliers which is invariant to the degree of collinearity?

I don't think that makes any sense, given what is usually meant by
`multivariate outliers', outliers in any direction in the point cloud.

[...]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From nuvolab at hotmail.com  Wed Jan 21 18:42:17 2004
From: nuvolab at hotmail.com (nuvo nuvo)
Date: Wed, 21 Jan 2004 09:42:17 -0800
Subject: [R] Better way to find function
Message-ID: <BAY2-F77xvbHZsb1i6E00008f60@hotmail.com>


   >From: "Liaw, Andy"
   >To: "'nuvo nuvo'" ,r-help at stat.math.ethz.ch
   >Subject: RE: [R] Better way to find function
   >Date: Wed, 21 Jan 2004 09:10:06 -0500
   >
   >For #1, could you clarify what you mean by `function', an R function,
   or a

   >regression function?

   I mean to choose a functional form automatically, e.g. 1/(
   a+exp[b+cx]), a+bx, ... [ I saw some of the commercial software can do
   it ]. 
   >For #2, there are several packages on CRAN (and in the R distribution
   >itself) that fit regression splines, if that's what you meant by
   `piecewise
   >regression'.  For logistic regression, you can either use the bs()
   term in

   >glm(), or gam() in the `mgcv' package.

   I don't want to use Spline, because I need the functional form and
   also parameters. Moreover I have 3 independent variables, not only
   one. 

   I want to do only 2 piecewise regression by using the logistic
   function i.e. c/( 1+exp[a+bx]). Then it will be difficult where to put
   the knot and also it may not be continuous at the knot.
   >
   >HTH,
   >Andy
   >
   > > From: nuvo nuvo
   > >
   > > To whom it may concern,
   > >
   > > 1. I would like to know if there is a command in R to choose
   > > a function for
   > > a given dataset. I am facing a difficult question about how
   > > to fit the data
   > > [ please attachment ]
   > >
   > > 2. Are there any function that will allow users to do the
   piecewise
   > > regression?
   > >
   > > If not, is it going to be provide in the new updated version?
   > > What I am
   > > using is the piecewise logistic regression, but it doesn't
   > > have a continuous
   > > function though. I hope that R would have a specific command
   > > to do the
   > > piecewise (non)linear regression.
   > >
   > > I would apprecaite your suggestion.
   > >
   > > Sincerely yours,
   > >
   > > Nhum
   > >
   > > _________________________________________________________________
   > > Rethink your business approach for the new year with the
   > > helpful tips here.
   > >
   > > ______________________________________________
   > > R-help at stat.math.ethz.ch mailing list
   > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
   > > PLEASE do read the posting guide!
   > > http://www.R-project.org/posting-guide.html
   > >
   > >
   >
   >
   >---------------------------------------------------------------------
   ---------
   >Notice:  This e-mail message, together with any attachments, contains
   >information of Merck & Co., Inc. (One Merck Drive, Whitehouse
   Station, New
   >Jersey, USA 08889), and/or its affiliates (which may be known outside
   the
   >United States as Merck Frosst, Merck Sharp & Dohme or MSD and in
   Japan, as
   >Banyu) that may be confidential, proprietary copyrighted and/or
   legally
   >privileged. It is intended solely for the use of the individual or
   entity
   >named on this message.  If you are not the intended recipient, and
   have
   >received this message in error, please notify us immediately by reply
   e-mail
   >and then delete it from your system.
   >---------------------------------------------------------------------
   ---------
     _________________________________________________________________

   [1]Learn how to choose, serve, and enjoy wine at Wine @ MSN.

References

   1. http://g.msn.com/8HMBENUS/2749??PS=


From p.dalgaard at biostat.ku.dk  Wed Jan 21 19:08:38 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Jan 2004 19:08:38 +0100
Subject: [R] matrix exponential: M^0
In-Reply-To: <1074705611.13484.23.camel@xena.iarc.fr>
References: <1074616806.2958.46.camel@monkey> <x2isj6vcgk.fsf@biostat.ku.dk>
	<1074705611.13484.23.camel@xena.iarc.fr>
Message-ID: <x24qupcgyh.fsf@biostat.ku.dk>

Martyn Plummer <plummer at iarc.fr> writes:

> Calculating the matrix exponential is harder than it looks (I'm sure
> Peter knows this). In fact there is a classic paper by Moler and Van
> Loan from the 1970s called "Nineteen dubious ways to calculate the
> exponential of a matrix", which they updated last year in SIAM. 

Right (magnificent paper by the way), although I actually hadn't heard
about the update. As I remember it, Octave implements what
Moler+v.Loan ends up suggesting in the 1978 paper.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From f.calboli at ucl.ac.uk  Wed Jan 21 20:26:18 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 21 Jan 2004 19:26:18 +0000
Subject: [R] matrix exponential: M^0
Message-ID: <1074713177.2956.109.camel@monkey>

Dear All,

Thanks for all the help. I tried to implement Stephane Dray's suggestion
and Erin Hodgess function with the following matrices:

> A
     [,1] [,2]
[1,]    2    1
[2,]    1    3
> P
     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    4    5    6
[3,]    2    3    4
> D
     [,1] [,2] [,3]
[1,]    0    0    0
[2,]    0    0    0
[3,]    0    0    0

But I run in a number of troubles, probably my fault. I also tried
MatrixExp from the library msm, but I failed to understand how to use
it. 

anyway, as my linear algebra is too poor for any intelligent
decomposition and whatnot, and I wanted a function, I went for the brute
force approach.


mtx.exp<-function(X,n){
if (n==0) {
phi<-diag(rep(1,length(X[1,])))
return(phi)
}
if (n==1) {
phi<-X
return(phi)
}
X1<-X
for (i in 2:n) {
X<-X%*%X1
}
phi<-X
return(phi)
}

I would imagine this approach would be memory inefficient; would it
incurr in other problems? 

Again, many thanks to all for the invaluable help.

Regards,

Federico Calboli






-- 



=================================

Federico C. F. Calboli

PLEASE NOTE NEW ADDRESS

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 251 208

f.calboli at ucl.ac.uk



From cliff at ms.washington.edu  Wed Jan 21 19:42:36 2004
From: cliff at ms.washington.edu (Cliff Lunneborg)
Date: Wed, 21 Jan 2004 10:42:36 -0800
Subject: [R] Changing workspace from within an R session
Message-ID: <002f01c3e04e$578bda80$329f1218@C56909A>

I have found a pair of functions, move and rm.sv, written by my
colleague John Miyamoto very useful in managing one's workspace. They
may be inspected and downloaded from

http://faculty.washington.edu/jmiyamot/psych500.htm


**********************************************************
Cliff Lunneborg, Professor Emeritus, Statistics &
Psychology, University of Washington, Seattle
cliff at ms.washington.edu



From gerald.jean at dgag.ca  Wed Jan 21 20:38:52 2004
From: gerald.jean at dgag.ca (gerald.jean@dgag.ca)
Date: Wed, 21 Jan 2004 14:38:52 -0500
Subject: [R] Summary: Changing workspace from within an R session
Message-ID: <OFD99A092A.D2907270-ON85256E22.006A28D3@spgdag.ca>


Thanks to Frank Harrell, Brian Ripley, Andy Liaw, Jeff Laake and Sean Davis
for their usefull comments regarding "navigation" between valid R
directories.

Jeff recommanded the Mark Bravington package that can be found at:
(ftp://ftp.marine.csiro.au/software/bravington/).  I looked at the package
and found that it can do a lot more than what I asked for.  At this time I
was not prepared to go to the extent of installing the whole package,
reading the manuals, etc. only to accomplish my little task, but the
package seems to have a lot to offer.

I ended up revamping my original Splus function, based on the comments of
responders to my original post.  For those interested here is the little
function, works like a charm.  Note that "options()$Current.Dir" gets setup
at startup, note also that the name of all my temp. objects start by "ttt".

"chdir" <-
function(datadir,  default.path = '/actuaria/jeg002/')
{
# Author  : G?rald Jean, based on ideas from different people on the
R-users mailing  #           list.
# Date    : January 21, 2004
# Purpose : will delete all objects starting with "ttt*" from directory
#           currently at position 1 in the search path, will save the
#           ".GlobalEnv" where it belongs, will cleanup workspace and
finally
#           load "datadir" into the workspace.
# Arguments:
#  datadir      : the directory to attach.
#  default.path : the drive on which resides the directory to attach.
#------------------------------------------------------------------------

### Remove temporary objects from .GlobalEnv, they all start by "ttt".

  remove(list = objects(pattern = "^ttt", pos = 1), pos = 1)

### Save current .GlobalEnv to .RData where it comes from, which is given
### by options()$Current.Dir

  save(list = objects(pos = 1),
       file = paste(options()$Current.Dir, '/.RData', sep = ''))

###  Remove everything from .GlobalEnv but ".whatever" objects.

  remove(list = objects(pos = 1), pos = 1)

### If it exists, load the .RData from "datadir" into workspace.

  path <- paste(default.path, datadir, sep = "")
  to.load <- paste(path, "/.RData", sep = '')
  if (file.exists(to.load)){
    load(to.load, envir = .GlobalEnv)
    options(Current.Dir = path)
  }
  else
    cat(paste("\n\tNothing loaded ", to.load, " doesn't exist!!!", sep
= ''),
        sep = '\n')
  invisible()
}

Thanks again to all respondents,

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming



From peterwickham at mac.com  Wed Jan 21 20:52:44 2004
From: peterwickham at mac.com (Peter Wickham)
Date: Wed, 21 Jan 2004 14:52:44 -0500
Subject: [R] Mac OS X and R
Message-ID: <6138C9FE-4C4B-11D8-9BED-000A9573A118@mac.com>

My Windows machine has gone "kaput" and I am trying to see how R might 
work on my Mac. I am interested in using the contributed packages, 
especially "waveslim" and "wavethresh". Are all packages available 
under either Windows, Mac, or Unix? I can't seem to tell from the 
documentation whether this is so (probably because I am not very 
computer literate!). Any thoughts?



From ripley at stats.ox.ac.uk  Wed Jan 21 21:19:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Jan 2004 20:19:12 +0000 (GMT)
Subject: [R] Mac OS X and R
In-Reply-To: <6138C9FE-4C4B-11D8-9BED-000A9573A118@mac.com>
Message-ID: <Pine.LNX.4.44.0401212011580.4924-100000@gannet.stats>

On Wed, 21 Jan 2004, Peter Wickham wrote:

> My Windows machine has gone "kaput" and I am trying to see how R might 
> work on my Mac. I am interested in using the contributed packages, 
> especially "waveslim" and "wavethresh". Are all packages available 
> under either Windows, Mac, or Unix? I can't seem to tell from the 

Yes, at least one of those!  Not all are available under Windows and fewer 
still under MacOS X.  This is because

- the people who build the binary packages are (rightly) conservative and 
only release packages that clearly pass all the tests.

- the MacOS X platform is a rather (very?) unusual Unix-alike.

Looking on CRAN, both have waveslim but only Windows (and Unix) have 
wavethresh.   The latter does not appear on the status page

http://cran.r-project.org/bin/macosx/1.8/Status

so I don't know why.

> documentation whether this is so (probably because I am not very 
> computer literate!). Any thoughts?

Just look on CRAN to find out.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mn216 at columbia.edu  Wed Jan 21 21:19:28 2004
From: mn216 at columbia.edu (Murad Nayal)
Date: Wed, 21 Jan 2004 15:19:28 -0500
Subject: [R] silhoutte.default bugs
Message-ID: <400EDED0.B40A9BBF@columbia.edu>



Hello all,


This might have been fixed in later versions (I am using R1.7.0), r-help
archive contains messages reporting similar problems but no reports of
codes fixes. I have encountered a couple of problems using the
silhouette function. one occurs when the clustering contains clusters
composed of 1 element (Martin Maechler posted code few months ago that
fixes a similar problem that occurs when clusters have only 2 elements
but not the case with 1 element). the other problem is due to
silhouette's assumption that the clusters are numbered sequentially
starting at 1. one of the clustering programs I use (snob) assigns more
or less arbitrary integer ids to clusters starting from 3! (clusters 1
and 2 have special meaning in snob). the modified code fixing both
problems is included below, changes are commented.

best
Murad

silhouette.default <-
function (x, dist, dmatrix, ...) 
{
    cll <- match.call()
    if (!is.null(cl <- x$clustering)) 
        x <- cl
    n <- length(x)
    if (!all(x == round(x))) 
        stop("`x' must only have integer codes")
    k <- length(clid <- sort(unique(x)))
    if (k <= 1 || k >= n) 
        return(NA)
    if (missing(dist)) {
        if (missing(dmatrix)) 
            stop("Need either a dissimilarity `dist' or diss.matrix
`dmatrix'")
        if (is.null(dm <- dim(dmatrix)) || length(dm) != 2 || 
            !all(n == dm)) 
            stop("`dmatrix' is not a dissimilarity matrix compatible to
`x'")
    }
    else {
        dist <- as.dist(dist)
        if (n != attr(dist, "Size")) 
            stop("clustering `x' and dissimilarity `dist' are
incompatible")
        dmatrix <- as.matrix(dist)
    }
    wds <- matrix(NA, n, 3, dimnames = list(names(x), c("cluster", 
        "neighbor", "sil_width")))
    for (j in 1:k) {
        Nj <- sum(iC <- x == clid[j])
#
# the following line changed from  wds[iC, "cluster"] <- j
#
        wds[iC, "cluster"] <- clid[j]
        a.i <- if (Nj > 1) 
            colSums(dmatrix[iC, iC])/(Nj - 1)
        else 0
#
# the following line changed from 
# diC <- rbind(apply(dmatrix[!iC, iC], 2, function(r) tapply(r,
# x[!iC], mean)))
#
        diC <- rbind(apply(cbind(dmatrix[!iC, iC]), 2, function(r)
tapply(r, 
            x[!iC], mean)))
        minC <- max.col(-t(diC))
        wds[iC, "neighbor"] <- clid[-j][minC]
#
# the following line changed from 
# b.i <- diC[cbind(minC, seq(minC))]
#
        b.i <- diC[cbind(minC, seq(along=minC))]
        s.i <- (b.i - a.i)/pmax(b.i, a.i)
        wds[iC, "sil_width"] <- s.i
    }
    attr(wds, "Ordered") <- FALSE
    attr(wds, "call") <- cll
    class(wds) <- "silhouette"
    wds
}
-- 
Murad Nayal M.D. Ph.D.
Department of Biochemistry and Molecular Biophysics
College of Physicians and Surgeons of Columbia University
630 West 168th Street. New York, NY 10032
Tel: 212-305-6884	Fax: 212-305-6926



From vincent.philion at irda.qc.ca  Wed Jan 21 21:46:59 2004
From: vincent.philion at irda.qc.ca (Vincent Philion)
Date: Wed, 21 Jan 2004 15:46:59 -0500
Subject: [R] Mac OS X and R
In-Reply-To: <Pine.LNX.4.44.0401212011580.4924-100000@gannet.stats>
References: <Pine.LNX.4.44.0401212011580.4924-100000@gannet.stats>
Message-ID: <F53846E4-4C52-11D8-893B-000A95AAA1D6@irda.qc.ca>

Le 21 janv. 2004, ? 15:19, Prof Brian Ripley a ?crit :

> - the MacOS X platform is a rather (very?) unusual Unix-alike.
>

Why is that? Isn't Darwin (the Unix core of OSX) a standard FreeBSD 
Unix system?

Vincent



From d.firth at warwick.ac.uk  Wed Jan 21 21:48:10 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Wed, 21 Jan 2004 20:48:10 +0000
Subject: [R] Mac OS X and R
In-Reply-To: <Pine.LNX.4.44.0401212011580.4924-100000@gannet.stats>
Message-ID: <1FE250FA-4C53-11D8-9E31-0050E4C03977@warwick.ac.uk>

I can confirm that wavethresh doesn't install under (my) Mac OS 10.2.8:

 > install.packages("wavethresh")
...(snip)...
* Installing *source* package 'wavethresh' ...
** libs
gcc -no-cpp-precomp -I/usr/local/lib/R/include  -I/sw/include   
-fno-common  -g -O2 -c ImageDecomposeStep.c -o ImageDecomposeStep.o
ImageDecomposeStep.c:24:20: malloc.h: No such file or directory
make: *** [ImageDecomposeStep.o] Error 1
ERROR: compilation failed for package 'wavethresh'

I use various other R packages (with C/Fortran source code) without 
problem.

David

On Wednesday, Jan 21, 2004, at 20:19 Europe/London, Prof Brian Ripley 
wrote:

> On Wed, 21 Jan 2004, Peter Wickham wrote:
>
>> My Windows machine has gone "kaput" and I am trying to see how R might
>> work on my Mac. I am interested in using the contributed packages,
>> especially "waveslim" and "wavethresh". Are all packages available
>> under either Windows, Mac, or Unix? I can't seem to tell from the
>
> Yes, at least one of those!  Not all are available under Windows and 
> fewer
> still under MacOS X.  This is because
>
> - the people who build the binary packages are (rightly) conservative 
> and
> only release packages that clearly pass all the tests.
>
> - the MacOS X platform is a rather (very?) unusual Unix-alike.
>
> Looking on CRAN, both have waveslim but only Windows (and Unix) have
> wavethresh.   The latter does not appear on the status page
>
> http://cran.r-project.org/bin/macosx/1.8/Status
>
> so I don't know why.
>
>> documentation whether this is so (probably because I am not very
>> computer literate!). Any thoughts?
>
> Just look on CRAN to find out.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From Manuel.A.Morales at williams.edu  Wed Jan 21 21:52:03 2004
From: Manuel.A.Morales at williams.edu (Manuel A. Morales)
Date: Wed, 21 Jan 2004 15:52:03 -0500
Subject: [R] intervals in lme() and ill-defined models
Message-ID: <001501c3e060$6c2badf0$9664a8c0@solidago>

There has been some recent discussion on this list about the value of using
intervals with lme() to check for whether a model is ill-defined. My
question is, what else can drive very large confidence intervals for the
variance components (or cause the error message "Error in
intervals.lme(Object) : Cannot get confidence intervals on var-cov
components: Non-positive definite approximate variance-covariance"). To
illustrate my question, I use examples from the book "Mixed-Effects-Models
in S and S-PLUS" by Pinheiro and Bates, and from an analysis of my own data.

In chapter 1, Pinheiro and Bates show that if you use a model with an
interaction in the random effects term without appropriate replication in
the data, the model will appear to fit but the confidence intervals for the
variance components will be very large. They suggest using intervals() as a
check that the model is appropriately defined:

> test.1 <- lme(effort~Type, data=ergoStool, random=~1|Subject)
> test.2 <- lme(effort~Type, data=ergoStool, random=~1|Subject/Type)
> intervals(test.2)

 Random Effects:
 Within-group standard error:
       lower         est.        upper 
1.054760e-07 4.599834e-01 2.005999e+06 

In fact, using anova() to compare these two models shows that nothing is
gained by adding the interaction:

> anova(test.1,test.2)
       Model df      AIC      BIC    logLik   Test L.Ratio p-value
test.1     1  6 133.1308 141.9252 -60.56539                       
test.2     2  7 135.1308 145.3909 -60.56539 1 vs 2       0       1

HOWEVER, for the example in chapter 5.3 of the book in which an
autoregressive structure is used for the within group errors, I get the
following error:

> test <-
lme(follicles~sin(2*pi*Time)+cos(2*pi*Time),data=Ovary,random=pdDiag(~sin(2*
pi*Time)))
> test.ar1 <-
lme(follicles~sin(2*pi*Time)+cos(2*pi*Time),data=Ovary,random=pdDiag(~sin(2*
pi*Time)),correlation=corAR1())
> intervals(test.ar1)
Error in intervals.lme(test.ar1) : Cannot get confidence intervals on
var-cov components: Non-positive definite approximate variance-covariance

BUT, anova appropriately selects the autoregressive model as best:
> anova(test,test.ar1)
		Model df      AIC      BIC    logLik   Test L.Ratio p-value
test           	1         6 1638.082 1660.404 -813.0409

test.ar1      	2        7  1564.445 1590.487 -775.2224 1 vs 2  75.637
<.0001

In the book, intervals() DOES appear to work, but the authors are using
S-PLUS. My concern is that when I try to fit the following two models to my
own data, I get very large confidence intervals for the within-subject error
even thought AIC selects the autoregressive model as best:

> result <-
lme(log(T1+1)~factor(trt1)*factor(trt2)*factor(Census),data=data,random=~1|B
lock/Subject)
> result.ar1 <-
lme(log(T1+1)~factor(trt1)*factor(trt2)*factor(Census),data=data,random=~1|B
lock/Subject,correlation=corAR1())
> intervals(result.ar1)

 Random Effects:
                       lower       est.     upper
sd((Intercept)) 3.491934e-13 0.01461032 611299013

 Correlation structure:
        lower      est.     upper
Phi 0.6543028 0.7574806 0.8329729


> anova(result,result.ar1)
		Model df      AIC      BIC    logLik   Test  L.Ratio p-value
result		1  19 518.1501 581.5633 -240.0750                        
result.ar1	2  20 475.9776 542.7283 -217.9888 1 vs 2 44.17249  <.0001


Why are my within-subject errors so large, and why doesn't intervals() work
for the autoregressive errors example in the book. I am using R version 1.8
on Windows 2000. Any insight would be greatly appreciated!

Manuel

Manuel A. Morales
Assistant Professor, Biology
Williams College
Williamstown, MA 01267

ph: 413-597-2983 | fax: 413-597-3495
http://mutualism.williams.edu



From rossini at blindglobe.net  Wed Jan 21 22:03:00 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 21 Jan 2004 13:03:00 -0800
Subject: [R] Mac OS X and R
In-Reply-To: <F53846E4-4C52-11D8-893B-000A95AAA1D6@irda.qc.ca> (Vincent
	Philion's message of "Wed, 21 Jan 2004 15:46:59 -0500")
References: <Pine.LNX.4.44.0401212011580.4924-100000@gannet.stats>
	<F53846E4-4C52-11D8-893B-000A95AAA1D6@irda.qc.ca>
Message-ID: <85hdypt3p7.fsf@blindglobe.net>

Vincent Philion <vincent.philion at irda.qc.ca> writes:

> Le 21 janv. 2004, ? 15:19, Prof Brian Ripley a ?crit :
>
>> - the MacOS X platform is a rather (very?) unusual Unix-alike.
>>
>
> Why is that? Isn't Darwin (the Unix core of OSX) a standard FreeBSD
> Unix system?

Sure, but you aren't just using the core, and it starts to morph away
as you get further from the core...

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From pgilbert at bank-banque-canada.ca  Wed Jan 21 22:34:17 2004
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 21 Jan 2004 16:34:17 -0500
Subject: [R] storage.mode and argument duplication
Message-ID: <400EF059.7010706@bankofcanada.ca>

I have a function which passes an element of a fairly large list to a 
fortran call. In a function, when I use storage.mode on an element of a 
list that is in the function argument, does this force the whole list to 
be duplicated? More specifically, which of these should result in less 
extra copying?

foo <- function(x)
   {storage.mode(x$one) <- "double"
    .Fortran("foo", x$one, result=as.double(rep(0,3)))["result"]
   }

or

foo <- function(x)
   {.Fortran("foo", as.double(x$one),
              result=as.double(rep(0,3)))["result"]
   }

Thanks,
Paul Gilbert



From p.dalgaard at biostat.ku.dk  Wed Jan 21 22:38:15 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Jan 2004 22:38:15 +0100
Subject: [R] Mac OS X and R
In-Reply-To: <85hdypt3p7.fsf@blindglobe.net>
References: <Pine.LNX.4.44.0401212011580.4924-100000@gannet.stats>
	<F53846E4-4C52-11D8-893B-000A95AAA1D6@irda.qc.ca>
	<85hdypt3p7.fsf@blindglobe.net>
Message-ID: <x2vfn5asoo.fsf@biostat.ku.dk>

rossini at blindglobe.net (A.J. Rossini) writes:

> Vincent Philion <vincent.philion at irda.qc.ca> writes:
> 
> > Le 21 janv. 2004, ? 15:19, Prof Brian Ripley a ?crit :
> >
> >> - the MacOS X platform is a rather (very?) unusual Unix-alike.
> >>
> >
> > Why is that? Isn't Darwin (the Unix core of OSX) a standard FreeBSD
> > Unix system?
> 
> Sure, but you aren't just using the core, and it starts to morph away
> as you get further from the core...

That's certainly true for the X11/Tcl/Aqua/Carbon/Cocoa/whatever mix,
as well as consequences of having files put into nonstandard
locations. The OS X way of doing dynamic libraries also seems to be
biting a few people though, and I'd call that a core issue. I don't
think it is doing that the FreeBSD way, is it?

Of course, it is not like we haven't had trouble compiling for IRIX,
HP-UX, Digital Unix,....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From h.wickham at auckland.ac.nz  Wed Jan 21 23:00:32 2004
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Thu, 22 Jan 2004 11:00:32 +1300
Subject: [R] Problem with lme, ns and df (variable scoping problem?)
Message-ID: <400EF680.1060309@auckland.ac.nz>

Hi,

I'm experimenting with random effect natural splines, and I've 
encountered an odd problem.

library(nlme); library(splines)
a <- data.frame(x = 1:10, y = 1:10 + runif(10, min=-3, max=3), c = 
rep(c(1,2),5))
df <- 10   
lml <- lmList(y ~ ns(x,df=df) | c, a)

Error in df - 1 : non-numeric argument to binary operator

I presume this is because the formula isn't evaluated until it's deep in 
the bowels of lmList, where a local df exists.  So I try again with a 
variable name that probably doesn't exist elsewhere:

d.f <- 10
lml <- lmList(y ~ ns(x,df=d.f) | c, a)

This works, but now when I calculate the mixed model, I get a different 
error.

lme <- lme(lml, random=pdIdent(~c))
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        variable lengths differ

Neither of these problems occur if I specify df directly (eg. df=10)

Can anyone offer a work around?

Thanks.

Hadley



From Mike.Prager at noaa.gov  Wed Jan 21 23:57:18 2004
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Wed, 21 Jan 2004 17:57:18 -0500
Subject: [R] nonlinear regression and Excel solver
In-Reply-To: <200401142312.00363.ahenningsen@agric-econ.uni-kiel.de>
References: <40059111.3070207@uvm.edu>
	<200401142312.00363.ahenningsen@agric-econ.uni-kiel.de>
Message-ID: <6.0.1.1.2.20040121132238.01d44e60@hermes.nos.noaa.gov>

On Wednesday 14 January 2004 19:57, Kristian Omland wrote:
 >
[snip]
 >
 > Is Excel's Solver an adequate tool for numerical approximation in general
 > and nonlinear regression in particular? Or should I push on writing
 > S-Plus code?

 From what I've heard (and I know some expert users), Excel's solver is 
pretty good. It may need to be restarted several times to come to its final 
resting place.

However, despite their considerable visual appeal and ease of learning, 
there are significant drawbacks, in my opinion, to using spreadsheets for 
this type of work:

(1) You can't easily review your "source code" to see what is 
happening.  The operations are hidden in cell formulas, or even worse, in 
macros. These must be examined one at a time.

(2) There are no inherent loop structures.

(3) It's easy to change a formula when you just mean to change a data value.

(4) Expansion to a different dimensionality can be more bug-prone than with 
a programming language like R (or C or Fortran).

Of course, opinions vary.

 > Is anyone out there interested in assisting me with S-Plus code with the
 > potential payoff of collaboration on a publication in the ecological
 > literature?

I would be interested if not already overcommitted (and by a large factor).

 > Obviously, I would be equally enthused if an R user was interested in a
collaboration.

I do hope you will find someone.  Good luck with your research! (We all 
need it.)



-- 
Michael Prager
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516  USA
http://shrimp.ccfhrb.noaa.gov/~mprager/

NOTE: Opinions expressed are personal, not official. No government
endorsement of any product is made or implied.



From forkusam at yahoo.com  Thu Jan 22 01:32:17 2004
From: forkusam at yahoo.com (forkusam)
Date: Wed, 21 Jan 2004 16:32:17 -0800 (PST)
Subject: [R] error message
Message-ID: <20040122003217.91013.qmail@web10510.mail.yahoo.com>

 Hi,
Can someone please tell me what such an error message
could mean. i.e where a problem must have arised.

Error in uniroot(function(n) eval(p.body) - power,
c(2, 1e+07)) : 
        f() values at end points not of opposite sign


Thank you
cilver

=====
=====================
Sylvie B. Forkusam
Eppelheimer Str.52/A2-5-2
69115 Heidelberg, Germany
Tel: (0049)-06221/346913
Mobile: 0179-6816276



From ripley at stats.ox.ac.uk  Thu Jan 22 02:00:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jan 2004 01:00:19 +0000 (GMT)
Subject: [R] Mac OS X and R
In-Reply-To: <1FE250FA-4C53-11D8-9E31-0050E4C03977@warwick.ac.uk>
Message-ID: <Pine.LNX.4.44.0401220054390.5122-100000@gannet.stats>

malloc.h can normally be replaced by stdlib.h on an ISO C system.  That 
file has

#include <stdio.h>
#ifndef Macintosh
#include <malloc.h>
#endif

and I believe that should be

#include <stdlib.h>
#include <stdio.h>

since the aim appears to be to have malloc() declared.

Martin M (as Maintainer) please note.


On Wed, 21 Jan 2004, David Firth wrote:

> I can confirm that wavethresh doesn't install under (my) Mac OS 10.2.8:
> 
>  > install.packages("wavethresh")
> ...(snip)...
> * Installing *source* package 'wavethresh' ...
> ** libs
> gcc -no-cpp-precomp -I/usr/local/lib/R/include  -I/sw/include   
> -fno-common  -g -O2 -c ImageDecomposeStep.c -o ImageDecomposeStep.o
> ImageDecomposeStep.c:24:20: malloc.h: No such file or directory
> make: *** [ImageDecomposeStep.o] Error 1
> ERROR: compilation failed for package 'wavethresh'
> 
> I use various other R packages (with C/Fortran source code) without 
> problem.
> 
> David


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Jan 22 02:03:34 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jan 2004 01:03:34 +0000 (GMT)
Subject: [R] Problem with lme, ns and df (variable scoping problem?)
In-Reply-To: <400EF680.1060309@auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0401220100550.5122-100000@gannet.stats>

Use substitute, something like

lml <- eval(substitute(lmList(y ~ ns(x,df=d.f) | c, a), list(d.f.=df)))

This sort of thing is in any case necessary to get a sensible call
component recorded in the fitted object.


On Thu, 22 Jan 2004, Hadley Wickham wrote:

> Hi,
> 
> I'm experimenting with random effect natural splines, and I've 
> encountered an odd problem.
> 
> library(nlme); library(splines)
> a <- data.frame(x = 1:10, y = 1:10 + runif(10, min=-3, max=3), c = 
> rep(c(1,2),5))
> df <- 10   
> lml <- lmList(y ~ ns(x,df=df) | c, a)
> 
> Error in df - 1 : non-numeric argument to binary operator
> 
> I presume this is because the formula isn't evaluated until it's deep in 
> the bowels of lmList, where a local df exists.  So I try again with a 
> variable name that probably doesn't exist elsewhere:
> 
> d.f <- 10
> lml <- lmList(y ~ ns(x,df=d.f) | c, a)
> 
> This works, but now when I calculate the mixed model, I get a different 
> error.
> 
> lme <- lme(lml, random=pdIdent(~c))
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>         variable lengths differ
> 
> Neither of these problems occur if I specify df directly (eg. df=10)
> 
> Can anyone offer a work around?
> 
> Thanks.
> 
> Hadley
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From h.wickham at auckland.ac.nz  Thu Jan 22 02:21:39 2004
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Thu, 22 Jan 2004 14:21:39 +1300
Subject: [R] Problem with lme, ns and df (variable scoping problem?)
In-Reply-To: <Pine.LNX.4.44.0401220100550.5122-100000@gannet.stats>
References: <Pine.LNX.4.44.0401220100550.5122-100000@gannet.stats>
Message-ID: <400F25A3.6070302@auckland.ac.nz>

That makes sense - obviously when I used this formulation in the past 
(eg. with lm) I've been lucky enough not to run into problems, but it 
makes sense that the formula needs some help to determine that df comes 
from a different environment from the other variables.

Thanks for your help,

Hadley


Prof Brian Ripley wrote:

>Use substitute, something like
>
>lml <- eval(substitute(lmList(y ~ ns(x,df=d.f) | c, a), list(d.f.=df)))
>
>This sort of thing is in any case necessary to get a sensible call
>component recorded in the fitted object.
>  
>



From paul.boutros at utoronto.ca  Thu Jan 22 02:27:04 2004
From: paul.boutros at utoronto.ca (paul.boutros@utoronto.ca)
Date: Wed, 21 Jan 2004 20:27:04 -0500
Subject: [R] Combining Factors in model.matrix
Message-ID: <1074734824.400f26e8530bc@webmail.utoronto.ca>

Hello,

I want to be able to create a design matrix with two factors.  For instance, if 
I have:

> t1 <- factor(c(1,1,2,2));
> t2 <- factor(c(1,2,1,2));
> design <- model.matrix(~ -1 + (t1+t2));
> design;
  t11 t12 t22
1   1   0   0
2   1   0   1
3   0   1   0
4   0   1   1

But the design matrix I want is:
   t1 t2
1   1  0
2   1  1
3   0  0
4   0  1

Actually, in general I'm struggling with the syntax for formulating a design 
matrix I can write down on paper.  Is there a reference for this beyond the R 
documentation?

Thanks,
Paul



From p.dalgaard at biostat.ku.dk  Thu Jan 22 02:36:38 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Jan 2004 02:36:38 +0100
Subject: [R] error message
In-Reply-To: <20040122003217.91013.qmail@web10510.mail.yahoo.com>
References: <20040122003217.91013.qmail@web10510.mail.yahoo.com>
Message-ID: <x2llo0bw7t.fsf@biostat.ku.dk>

forkusam <forkusam at yahoo.com> writes:

>  Hi,
> Can someone please tell me what such an error message
> could mean. i.e where a problem must have arised.
> 
> Error in uniroot(function(n) eval(p.body) - power,
> c(2, 1e+07)) : 
>         f() values at end points not of opposite sign

Looks like the innards of one of the power calculations, finding n to
achieve a given power. You'd likely get an error like that if the
power is not between 0 and 1, but how about telling us what you were
trying to do?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From maechler at stat.math.ethz.ch  Thu Jan 22 09:05:39 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Jan 2004 09:05:39 +0100
Subject: [R] derivative of atan(x) and similar functions
In-Reply-To: <20040121115458.GA1885@nf034.jinr.ru>
References: <20040121115458.GA1885@nf034.jinr.ru>
Message-ID: <16399.33875.287060.214681@gargle.gargle.HOWL>

>>>>> "Timur" == Timur Elzhov <Timur.Elzhov at jinr.ru>
>>>>>     on Wed, 21 Jan 2004 14:54:58 +0300 writes:

    Timur> Dear R experts.  'D()' function recognizes some of
    Timur> the analitical functions, such as sin, cos, etc. But
    Timur> I'd like to take analytical derivatives from asin,
    Timur> atan etc. functions. Are there any R packages
    Timur> providing that features?
 
Not that I know of.

We know that it is one deficiency of D() {and deriv() ...} that
it's not user-extendable.
For the asin/acos/atan , I think we would gladly incorporate
them into the current list --- IF someone volunteers to send us
the patch.  Since sqrt() and basic arithmetic is already
supported, this is only a matter of diligency..
It's the file  <Rsource>/src/main/deriv.c  {and mainly (but not
only) the  D(SEXP expr, SEXP var) function starting at line 268
that needs to be extended.  If know some Lisp, it might be
easier to get started... ;-)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From wolfram at fischer-zim.ch  Thu Jan 22 09:39:38 2004
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Thu, 22 Jan 2004 09:39:38 +0100
Subject: [R] lattice: adding text between grouped panels?
In-Reply-To: <200401201040.56262.deepayan@stat.wisc.edu>
References: <20040120101450.GA5234@s1x.local>
	<200401201040.56262.deepayan@stat.wisc.edu>
Message-ID: <20040122083938.GA2578@s1x.local>

--- In reply to Deepayan Sarkar: ---
>Date:    20.01.04 10:40 (-0600)

Thank you again for your very helpful and inspiring answer!
Some additional questions will follow below.

> On Tuesday 20 January 2004 04:14, Wolfram Fischer wrote:
> > How one can add a text (e.g. the labels of an axis)
> > in a space between grouped panels which was created
> > by using the argument ``between''?
> >
> > Example:
> > 	data(barley)
> > 	dotplot(variety ~ yield | site * year, data=barley,
> > 		between=list(x=c( 0, 0, 6 ))
> > How to add labels for the y axis in the space in the middle?
> 
> Formally, there's no mechanism to do that. However, most reasonable usage can 
> be achieved by the panel function, e.g. (to add a y-axis tick and label at 
> the mean y-value):
> 
> panel = function(x, y, ...) {
>     panel.xyplot(x, y, ...)
>     grid.yaxis(at = mean(y))
> }
> 
> Normally, this would not work because all graphical output produced by the 
> panel function is 'clipped', i.e., anything falling outside the panel is not 
> drawn. This can be controlled by the setting
> 
> > trellis.par.get("clip")
> $panel
> [1] TRUE
> 
> $strip
> [1] TRUE
> 
> 
> So you need to do something like 
> 
> > lset(list(clip = list(panel = FALSE)))
> 
> before calling xyplot (or whatever). Of course, turning clipping off has the 
> disadvantage that unintended things can happen. Most panel functions are 
> safe, but some are not (like panel.abline).

This good idea seams to work. But:

- How can I determine in which panel I am?
  Principally I could to that by using a strip function.
  But the presence of a strip function allways (?) allocates
  space for the strip(s). How can I determine the panel
  when I don't want to display strips?


> Just in case you missed it, there's a much safer way to add customized tick 
> marks and labels to each panel, using the scales argument. From ?xyplot, 
> 
> 
>   scales: list determining how the x- and y-axes (tick marks and
> 
>           [...]
> 
>           at: location of tick marks along the axis (in native
>           coordinates), or a list as long as the number of panels
>           describing tick locations for each panel.
> 
>           labels: Labels (strings or expressions) to go along with
>           'at'. Can be a list like 'at' as well.
> 
> But this may not be what you want.

Thanks for this hint!

When I wanted add labels to each panel group of:

	my.barley <- subset( barley, ! ( site == "Grand Rapids" & year == "1932" ) )

	with( my.barley, dotplot(variety ~ yield | year * site, layout=c(6,2)
		, between=list(x=c(0,6))))


I tried:
	with( my.barley, dotplot(variety ~ yield | year * site, layout=c(6,2)
		, scales=list( rot=0, y=list( relation='sliced'
		, at = rep( list( 1: nlevels( variety ), NULL ), 6 )))))

I used:
- ``sliced'' because there was an error when I did not use it:
	"the at and labels components of scales may not be
	lists when relation = same".
- the at-option to eliminate the yaxis-labels within the panel groups.

I received:
- Several warning messages.
- No axis labels for panel groups with an empty first panel.
- Gigant scales in the second panels of each panel group.

What can I do to:
- Have normal scales in the second panels of each panel group?
- Eliminate the space between the first and the second panel
  in each group.

> Hth,
> 
> Deepayan

Thanks! Wolfram



From maechler at stat.math.ethz.ch  Thu Jan 22 10:33:21 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Jan 2004 10:33:21 +0100
Subject: [R] matrix exponential: M^0
In-Reply-To: <x24qupcgyh.fsf@biostat.ku.dk>
References: <1074616806.2958.46.camel@monkey> <x2isj6vcgk.fsf@biostat.ku.dk>
	<1074705611.13484.23.camel@xena.iarc.fr>
	<x24qupcgyh.fsf@biostat.ku.dk>
Message-ID: <16399.39137.457957.656354@gargle.gargle.HOWL>

>>>>> "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>>>>>     on 21 Jan 2004 19:08:38 +0100 writes:

    PD> Martyn Plummer <plummer at iarc.fr> writes:
    >> Calculating the matrix exponential is harder than it
    >> looks (I'm sure Peter knows this). In fact there is a
    >> classic paper by Moler and Van Loan from the 1970s called
    >> "Nineteen dubious ways to calculate the exponential of a
    >> matrix", which they updated last year in SIAM.

    PD> Right (magnificent paper by the way), although I
    PD> actually hadn't heard about the update. As I remember
    PD> it, Octave implements what Moler+v.Loan ends up
    PD> suggesting in the 1978 paper.

The update is actually available online
from http://epubs.siam.org/sam-bin/dbq/article/41801
with the extended title "...., 25 Years Later" .

The extension is 8 pages of text + 1.2 pages of references,
in which (p.42) they say
``The matrix exponential is an important computational tool in
  control theory, so availability of  expm(A)  in early versions
  of Matlab quite possibily contributed to the system's technical
  and commercial success.''

and they also tell how expm() is implemented in Matlab
(scaling, squaring, Pad? approximation) which is presumably what
octave does too?

-----

But -- going back to our original subject --
Isn't

  expm(A) =  ``e ^ A'' := sum_{n=0}^\Inf  A^n / n!

definitely a bit harder than  A^n for (non-negative) integer n ?

Martin



From maechler at stat.math.ethz.ch  Thu Jan 22 10:51:24 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Jan 2004 10:51:24 +0100
Subject: [R] silhoutte.default bugs
In-Reply-To: <400EDED0.B40A9BBF@columbia.edu>
References: <400EDED0.B40A9BBF@columbia.edu>
Message-ID: <16399.40220.518344.52826@gargle.gargle.HOWL>

>>>>> "Murad" == Murad Nayal <mn216 at columbia.edu>
>>>>>     on Wed, 21 Jan 2004 15:19:28 -0500 writes:

    Murad> This might have been fixed in later versions (I am
    Murad> using R1.7.0),

yes, the bug has been fixed "long ago", 
from my ChangeLog (!), it was 2003-07-18.

    Murad>  r-help archive contains messages reporting similar
    Murad> problems but no reports of codes fixes. I have
    Murad> encountered a couple of problems using the silhouette
    Murad> function. one occurs when the clustering contains
    Murad> clusters composed of 1 element (Martin Maechler
    Murad> posted code few months ago that fixes a similar
    Murad> problem that occurs when clusters have only 2
    Murad> elements but not the case with 1 element). the other
    Murad> problem is due to silhouette's assumption that the
    Murad> clusters are numbered sequentially starting at 1. 

which is what  ?silhouette  tells you as well:

>> Arguments:
>> 
>>        x: an object of appropriate class; for the 'default' method an
>>           integer vector with cluster codes in '1:k' or a list with
>>           such an 'x$clustering' component.

So, definitely not a bug, 
but it's your problem of using silhouette() on an object that is
not of appropriate structure.

    Murad> one of the clustering programs I use (snob) assigns
    Murad> more or less arbitrary integer ids to clusters
    Murad> starting from 3! (clusters 1 and 2 have special
    Murad> meaning in snob). the modified code fixing both
    Murad> problems is included below, changes are commented.

Thank you for the good attempt,
but really you should work from the source where
silhouette.default does also contain comments, and as said, has
long been fixed for the case of 1-element clusters
{a better fix is not to use cbind() but to use the ominous 
 ", drop = FALSE" when  subsetting matrices!}

I'm still willing to consider your *feature request* (as opposed
to bug fix) of allowing inputs where the grouping vector does
contain other than "1:g" .

I'll send you the current source of silhouette.default in a
private mail.

Thanks for your collaboration on improving R!
Regards,

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ernesto at ipimar.pt  Thu Jan 22 11:56:59 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu, 22 Jan 2004 10:56:59 +0000
Subject: [R] Packages debug and mvbutils
Message-ID: <1074769019.21848.54.camel@gandalf.local>

Hi,

The article "Debugging Without (Too Many) Tears" (Rnews 3/3) describes
the packages debug and mvbutils but it has no reference to where one can
find those packages and they are not in CRAN.

I've searched google but I can not find it :( 

A reference will be welcome.

Thanks

EJ



From hrust at pik-potsdam.de  Thu Jan 22 12:06:37 2004
From: hrust at pik-potsdam.de (Henning Rust)
Date: Thu, 22 Jan 2004 12:06:37 +0100
Subject: [R] Packages debug and mvbutils
Message-ID: <400FAEBD.6010802@pik-potsdam.de>

Hi,
I read about packages debug and mvbutils in the R news but I cannot find 
them on CRAN in the Package Sources. Does anyone know where to look?
Thanks,
	Henning

-- 
Henning Rust
Potsdam Institute for Climate Impact Research
Dept. Integrated Systems Analysis
Tel.: #49/331/288-2596	
Fax.: #49/331/288-2640
PGP : pgp.mit.edu

Please avoid sending me Word or PowerPoint attachments,
send plain text or PDF instead.
See http://www.fsf.org/philosophy/no-word-attachments.html



From ozric at web.de  Thu Jan 22 12:16:55 2004
From: ozric at web.de (Christian Schulz)
Date: Thu, 22 Jan 2004 12:16:55 +0100
Subject: [R] queing theory and R
Message-ID: <200401221216.56299.ozric@web.de>

Hi,

have got anybody experience with queing theory
and R or exist some material. Searching in archive  i found nothing.
For first i search a function (..or have mysellf to write)  which calculates
the frequency of parallel events. I have the  starting time and duartion_time
of the events.

Many thanks for a starting point
regards,christian



From joan.valls at iconcologia.catsalut.net  Thu Jan 22 12:29:45 2004
From: joan.valls at iconcologia.catsalut.net (Joan Valls)
Date: Thu, 22 Jan 2004 12:29:45 +0100
Subject: [R] problem fitting linear mixed models
Message-ID: <400FB429.5000208@iconcologia.catsalut.net>

Hello,

I'm fitting linear mixed models to gene-expression data from 
microarrays, in a data set where 4608 genes are studied.
For a sample of 5 subjects and for each gene we observe the expression 
level (Intensity) in four different tissues: N, Tp, Tx and M.
I want to test whether the expression level is different accross 
tissues. Between-subject variability is modeled with a random intercept, 
and the within-subject by allowing heteroscedastic and correlated errors 
accross tissues. The proposed model can then be fitted by

lme(Intensity~Tissue-1, 
weights=varIdent(form=~1|Tissue),correlation=corSymm(),random=~1|Subject)

I have fitted this model for each gene. As a consequence of balanced 
data, fixed-effects estimates are exactly the sample mean for each gene.
But I have found one particular gene for which this does not happen: the 
fixed-effects estimates are completely no-sense.

Finally, I haved found a solution for that: rounding data.  (see the 
code below)

I have no explanation. Is it a numerical problem?

Thank you for your time.

Joan Valls
Catalan Institute of Oncology
Barcelona


#data set for the gene
Subject<-c(rep("C4",4),rep("HM1",4),rep("C1",4),rep("997",4),rep("C3",4))
Tissue<-rep(c("N","Tp","Tx","M"),5)
IntensityA<-c(10.6720000000000010,10.564,10.6080000000000010,10.8673333333333350,10.9430000000000000,10.8910000000000000, 

11.1260000000000010,10.9693333333333330,10.7690000000000000,10.8110000000000000,10.8739999999999990,10.8890000000000010, 

11.6679999999999990,11.5320000000000000,11.7100000000000010,11.3519999999999990,11.0000000000000000,10.6300000000000010, 

10.8720000000000020,10.6133333333333350)
Gene<-data.frame(Subject=as.factor(as.character(Subject)),Tissue=as.factor(as.character(Tissue)),Intensity=IntensityA) 


# fitted model (does not work!)
mlmA<-lme(Intensity ~ 
Tissue-1,weights=varIdent(form=~1|Tissue),correlation=corSymm(),data=Gene,random=~1|Subject); 

summary(mlmA)

#sample means
lapply(split(Gene$Intensity,Gene$Tissue),mean)    


#fitted model with rounded data (it works)
Gene$Intensity<-round(Gene$Intensity,4)
mlmA<-lme(Intensity ~ 
Tissue-1,weights=varIdent(form=~1|Tissue),correlation=corSymm(),data=Gene,random=~1|Subject); 

summary(mlmA)



From simon at stats.gla.ac.uk  Thu Jan 22 12:40:40 2004
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Thu, 22 Jan 2004 11:40:40 +0000 (GMT)
Subject: [R] Packages debug and mvbutils
In-Reply-To: <400FAEBD.6010802@pik-potsdam.de>
References: <400FAEBD.6010802@pik-potsdam.de>
Message-ID: <Pine.SOL.4.58.0401221138530.26525@moon.stats.gla.ac.uk>

> I read about packages debug and mvbutils in the R news but I cannot find
> them on CRAN in the Package Sources. Does anyone know where to look?
Since it's the middle of the night in Tasmania.... I asked Mark yesterday
and he said they'd be on CRAN in the next day or two.

_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814



From CMiller at PICR.man.ac.uk  Thu Jan 22 13:08:01 2004
From: CMiller at PICR.man.ac.uk (Crispin Miller)
Date: Thu, 22 Jan 2004 12:08:01 -0000
Subject: [R] File permissions and packages, openVignette
Message-ID: <BAA35444B19AD940997ED02A6996AAE0B5C439@sanmail.picr.man.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040122/98d18d4e/attachment.pl

From binita.dutta at vib.be  Thu Jan 22 13:47:19 2004
From: binita.dutta at vib.be (Binita Dutta)
Date: Thu, 22 Jan 2004 13:47:19 +0100
Subject: [R] Calculation of normalised red and green intensities
Message-ID: <6.0.0.22.1.20040122134258.01d6dc18@194.78.28.203>

Dear Sir/Madam,

I could succesfully normalise my microarray data using marrayNorm package. 
However, i have not been able to get normalised red and green channel 
intensities through R package.  Is there a possibility to write a formula 
to calculate back the red and green channel intensities after normalisation 
of the data. Do I need to incorporate this formula in my R script?  I am 
biologist ans would seek your help to write this formula.

Thanking you,

Binita



Dr. Binita Dutta
MicroArray Facility(MAF)
UZ Gasthuisberg
Onderwijs en Navorsing
Herestraat 49
3000 Leuven
Belgium



From hb at maths.lth.se  Thu Jan 22 14:34:36 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 22 Jan 2004 14:34:36 +0100
Subject: [R] Calculation of normalised red and green intensities
In-Reply-To: <6.0.0.22.1.20040122134258.01d6dc18@194.78.28.203>
Message-ID: <000701c3e0ec$7b0b7d00$e502eb82@maths.lth.se>

Hi, here's the calculations

  M = log2(R/G)     = [log rules] = log2(R)-log2(G)     (1)
  A = 1/2*log2(R*G) = [log rules] = (log2(R)+log2(G))/2 (2)

where log2(x) is the logarithm of x with base 2. If R,G > 0, there is
a one-to-one relationship between (A,M) and (G,R) as follows

  R = (2^(2A+M))^(1/2) = sqrt(2^(2A+M))   (3)
  G = (2^(2A-M))^(1/2) = sqrt(2^(2A-M))   (4)

It's a good exercise to verify the correctness, by replacing R and G
in (1) and (2) with the expressions for R and G in (3) and (4).

I believe there are methods in the marray packages for calculating R
and G from M and A like the above, but I don't know the exact name of
them.

BTW: I think it's better to ask these type of questions to the
Bioconductor (of which marrayNorm is part of) mailing list instead.

Best wishes

Henrik Bengtsson
Lund University, Sweden

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Binita Dutta
> Sent: den 22 januari 2004 13:47
> To: R-help at stat.math.ethz.ch
> Subject: [R] Calculation of normalised red and green intensities
> 
> 
> Dear Sir/Madam,
> 
> I could succesfully normalise my microarray data using 
> marrayNorm package. 
> However, i have not been able to get normalised red and green
channel 
> intensities through R package.  Is there a possibility to 
> write a formula 
> to calculate back the red and green channel intensities after 
> normalisation 
> of the data. Do I need to incorporate this formula in my R 
> script?  I am 
> biologist ans would seek your help to write this formula.
> 
> Thanking you,
> 
> Binita
> 
> 
> 
> Dr. Binita Dutta
> MicroArray Facility(MAF)
> UZ Gasthuisberg
> Onderwijs en Navorsing
> Herestraat 49
> 3000 Leuven
> Belgium
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From vicented.canto.ext at juntadeandalucia.es  Thu Jan 22 14:34:01 2004
From: vicented.canto.ext at juntadeandalucia.es (Vicente Canto Casasola)
Date: Thu, 22 Jan 2004 14:34:01 +0100
Subject: [R] Re: matrix exponential: M0
References: <200401221111.i0MB3w69009488@hypatia.math.ethz.ch>
Message-ID: <400FD149.10600@juntadeandalucia.es>

H i, all!

First of all, I'd like to apologize for my poor English. It's for years 
I don't use it.

This is a R-version of a function I wrote a long ago for my HP48 calculator.
It works with the binary expression of the power and just need to 
duplicate the mem used by X.


Hope this helps.

mtx.exp<-function(X,n)
#Function to calculate the n-th power of a matrix X;
{
phi <- diag(rep(1,length(X[1,])))
pot <- X #This is the first power of the matrix.

while (n > 0)
  {
  if (n%%2)
    {
    phi <- phi%*%pot;
    }
    n <- n%/%2;
    pot <- pot %*% pot;
  }
return(phi);
}



#Here is some output:

 > xx <- matrix(c(1,0,1,1),2,2)
 > xx
     [,1] [,2]
[1,]    1    1
[2,]    0    1
 > mtx.exp(xx,3)
     [,1] [,2]
[1,]    1    3
[2,]    0    1
 > mtx.exp(xx,4)
     [,1] [,2]
[1,]    1    4
[2,]    0    1
 > mtx.exp(xx,6)
     [,1] [,2]
[1,]    1    6
[2,]    0    1
 > mtx.exp(xx,10)
     [,1] [,2]
[1,]    1   10
[2,]    0    1
 > mtx.exp(xx,1000)
     [,1] [,2]
[1,]    1 1000
[2,]    0    1


Vicente D. Canto Casasola



From s.henderson at ucl.ac.uk  Thu Jan 22 14:47:07 2004
From: s.henderson at ucl.ac.uk (Stephen Henderson)
Date: Thu, 22 Jan 2004 13:47:07 -0000
Subject: [R] customising installed libraries
Message-ID: <E7CF6BC2744CBE41AE4E87635C7C893C1C6698@exc.wibr.ucl.ac.uk>

hello

I am returning to some libraries that I had previously customised by amongst
other things adding additional functions. I had simply typed these new
functions into the file in library/R/thelibrary. These however do not seem
to be loaded now as they previously were under older versions of R. 

What's changed and what do i need to do?

Thanks
Stephen


**********************************************************************
This email and any files transmitted with it are confidentia...{{dropped}}



From wolski at molgen.mpg.de  Thu Jan 22 14:58:03 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 22 Jan 2004 14:58:03 +0100
Subject: [R] customising installed libraries
In-Reply-To: <E7CF6BC2744CBE41AE4E87635C7C893C1C6698@exc.wibr.ucl.ac.uk>
References: <E7CF6BC2744CBE41AE4E87635C7C893C1C6698@exc.wibr.ucl.ac.uk>
Message-ID: <200401221458030411.1092DF0A@harry.molgen.mpg.de>

Have you executed first
detach(package:library)
before loading the library again?

Eryk
*********** REPLY SEPARATOR  ***********

On 1/22/2004 at 1:47 PM Stephen Henderson wrote:

>hello
>
>I am returning to some libraries that I had previously customised by
>amongst
>other things adding additional functions. I had simply typed these new
>functions into the file in library/R/thelibrary. These however do not seem
>to be loaded now as they previously were under older versions of R. 
>
>What's changed and what do i need to do?
>
>Thanks
>Stephen
>
>
>**********************************************************************
>This email and any files transmitted with it are confidentia...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics   
Ihnestrasse 73 14195 Berlin          'v'    
tel: 0049-30-84131285               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From gerald.jean at dgag.ca  Thu Jan 22 15:06:02 2004
From: gerald.jean at dgag.ca (gerald.jean@dgag.ca)
Date: Thu, 22 Jan 2004 09:06:02 -0500
Subject: =?iso-8859-1?Q?R=E9f=2E_=3A_[R]_Packages_debug_and_mvbutils?=
Message-ID: <OF3C5A138C.AC6E9D2C-ON85256E23.004D34AA@spgdag.ca>


If you want to access these utilities before M.Bravington post them on CRAN
they are available on his site:

(ftp://ftp.marine.csiro.au/software/bravington/)

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming



From s.henderson at ucl.ac.uk  Thu Jan 22 15:08:42 2004
From: s.henderson at ucl.ac.uk (Stephen Henderson)
Date: Thu, 22 Jan 2004 14:08:42 -0000
Subject: [R] customising installed libraries
Message-ID: <E7CF6BC2744CBE41AE4E87635C7C893C1C6699@exc.wibr.ucl.ac.uk>

 I had quit q() R, reloaded and loaded ipred anew. Trying
detach(package:ipred) makes no difference. I added a few pointless lines to
one existing function and can see these when I call the function, passing no
parameters. thats why i was assuming it was an R thing.

is this just some mysterious problem with my computer/ setup/ files?? not
R??

-----Original Message-----
From: Wolski
To: Stephen Henderson
Cc: 'r-help at stat.math.ethz.ch'
Sent: 1/22/04 1:58 PM
Subject: Re: [R] customising installed libraries

Have you executed first
detach(package:library)
before loading the library again?

Eryk
*********** REPLY SEPARATOR  ***********

On 1/22/2004 at 1:47 PM Stephen Henderson wrote:

>hello
>
>I am returning to some libraries that I had previously customised by
>amongst
>other things adding additional functions. I had simply typed these new
>functions into the file in library/R/thelibrary. These however do not
seem
>to be loaded now as they previously were under older versions of R. 
>
>What's changed and what do i need to do?
>
>Thanks
>Stephen
>
>
>**********************************************************************
>This email and any files transmitted with it are
confidentia...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate
Genomics   
Ihnestrasse 73 14195 Berlin          'v'    
tel: 0049-30-84131285               /   \    
mail: wolski at molgen.mpg.de        ---W-W----
http://www.molgen.mpg.de/~wolski 


**********************************************************************
This email and any files transmitted with it are confidentia...{{dropped}}



From wolski at molgen.mpg.de  Thu Jan 22 15:16:42 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 22 Jan 2004 15:16:42 +0100
Subject: [R] customising installed libraries
In-Reply-To: <E7CF6BC2744CBE41AE4E87635C7C893C1C6699@exc.wibr.ucl.ac.uk>
References: <E7CF6BC2744CBE41AE4E87635C7C893C1C6699@exc.wibr.ucl.ac.uk>
Message-ID: <200401221516420260.10A3F18B@harry.molgen.mpg.de>

There are the concept of private and public functions in the new version.
There are a file in the root directory of the lib where public functions can be entered.
I by myself do not know much more. There are more info in the R-ext.pdf (R extensions).
Probably you have to add your new function name to this file.
Eryk

*********** REPLY SEPARATOR  ***********

On 1/22/2004 at 2:08 PM Stephen Henderson wrote:

>I had quit q() R, reloaded and loaded ipred anew. Trying
>detach(package:ipred) makes no difference. I added a few pointless lines to
>one existing function and can see these when I call the function, passing
>no
>parameters. thats why i was assuming it was an R thing.
>
>is this just some mysterious problem with my computer/ setup/ files?? not
>R??
>
>-----Original Message-----
>From: Wolski
>To: Stephen Henderson
>Cc: 'r-help at stat.math.ethz.ch'
>Sent: 1/22/04 1:58 PM
>Subject: Re: [R] customising installed libraries
>
>Have you executed first
>detach(package:library)
>before loading the library again?
>
>Eryk
>*********** REPLY SEPARATOR  ***********
>
>On 1/22/2004 at 1:47 PM Stephen Henderson wrote:
>
>>hello
>>
>>I am returning to some libraries that I had previously customised by
>>amongst
>>other things adding additional functions. I had simply typed these new
>>functions into the file in library/R/thelibrary. These however do not
>seem
>>to be loaded now as they previously were under older versions of R. 
>>
>>What's changed and what do i need to do?
>>
>>Thanks
>>Stephen
>>
>>
>>**********************************************************************
>>This email and any files transmitted with it are
>confidentia...{{dropped}}
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>
>
>
>Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate
>Genomics   
>Ihnestrasse 73 14195 Berlin          'v'    
>tel: 0049-30-84131285               /   \    
>mail: wolski at molgen.mpg.de        ---W-W----
>http://www.molgen.mpg.de/~wolski 
>
>
>**********************************************************************
>This email and any files transmitted with it are confidential and
>intended solely for the use of the individual or entity to whom they
>are addressed. If you have received this email in error please notify
>the system manager (wibr.mail at ucl.ac.uk). All files are scanned for
>viruses.
>**********************************************************************



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics   
Ihnestrasse 73 14195 Berlin          'v'    
tel: 0049-30-84131285               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From andy_liaw at merck.com  Thu Jan 22 15:17:32 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 22 Jan 2004 09:17:32 -0500
Subject: [R] customising installed libraries
Message-ID: <3A822319EB35174CA3714066D590DCD504AF767F@usrymx25.merck.com>

The ipred package has a namespace.  Do follow the instruction in the R-exts
manual if you want functions available via a package.

Andy

> From: Stephen Henderson
> 
>  I had quit q() R, reloaded and loaded ipred anew. Trying
> detach(package:ipred) makes no difference. I added a few 
> pointless lines to
> one existing function and can see these when I call the 
> function, passing no
> parameters. thats why i was assuming it was an R thing.
> 
> is this just some mysterious problem with my computer/ setup/ 
> files?? not
> R??
> 
> -----Original Message-----
> From: Wolski
> To: Stephen Henderson
> Cc: 'r-help at stat.math.ethz.ch'
> Sent: 1/22/04 1:58 PM
> Subject: Re: [R] customising installed libraries
> 
> Have you executed first
> detach(package:library)
> before loading the library again?
> 
> Eryk
> *********** REPLY SEPARATOR  ***********
> 
> On 1/22/2004 at 1:47 PM Stephen Henderson wrote:
> 
> >hello
> >
> >I am returning to some libraries that I had previously customised by
> >amongst
> >other things adding additional functions. I had simply typed 
> these new
> >functions into the file in library/R/thelibrary. These however do not
> seem
> >to be loaded now as they previously were under older versions of R. 
> >
> >What's changed and what do i need to do?
> >
> >Thanks
> >Stephen
> >
> >
> >*************************************************************
> *********
> >This email and any files transmitted with it are
> confidentia...{{dropped}}
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> 
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate
> Genomics   
> Ihnestrasse 73 14195 Berlin          'v'    
> tel: 0049-30-84131285               /   \    
> mail: wolski at molgen.mpg.de        ---W-W----
> http://www.molgen.mpg.de/~wolski 
> 
> 
> **********************************************************************
> This email and any files transmitted with it are 
> confidentia...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ripley at stats.ox.ac.uk  Thu Jan 22 15:51:42 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jan 2004 14:51:42 +0000 (GMT)
Subject: [R] customising installed libraries
In-Reply-To: <E7CF6BC2744CBE41AE4E87635C7C893C1C6699@exc.wibr.ucl.ac.uk>
Message-ID: <Pine.LNX.4.44.0401221446580.15191-100000@gannet.stats>

ipred has a NAMESPACE: you cannot do this to packages that have 
namespaces without changing the NAMESPACE file (and from the next release, 
you will need to reinstall as well).

You can read about this in `Writing R Extensions', but is it a good idea 
to be altering a package that uses concepts you do not understand?

I believe you mean `installed packages'.

On Thu, 22 Jan 2004, Stephen Henderson wrote:

>  I had quit q() R, reloaded and loaded ipred anew. Trying
> detach(package:ipred) makes no difference. I added a few pointless lines to
> one existing function and can see these when I call the function, passing no
> parameters. thats why i was assuming it was an R thing.
> 
> is this just some mysterious problem with my computer/ setup/ files?? not
> R??
> 
> -----Original Message-----
> From: Wolski
> To: Stephen Henderson
> Cc: 'r-help at stat.math.ethz.ch'
> Sent: 1/22/04 1:58 PM
> Subject: Re: [R] customising installed libraries
> 
> Have you executed first
> detach(package:library)
> before loading the library again?
> 
> Eryk
> *********** REPLY SEPARATOR  ***********
> 
> On 1/22/2004 at 1:47 PM Stephen Henderson wrote:
> 
> >hello
> >
> >I am returning to some libraries that I had previously customised by
> >amongst
> >other things adding additional functions. I had simply typed these new
> >functions into the file in library/R/thelibrary. These however do not
> seem
> >to be loaded now as they previously were under older versions of R. 
> >
> >What's changed and what do i need to do?
> >
> >Thanks
> >Stephen
> >
> >
> >**********************************************************************
> >This email and any files transmitted with it are
> confidentia...{{dropped}}
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> 
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate
> Genomics   
> Ihnestrasse 73 14195 Berlin          'v'    
> tel: 0049-30-84131285               /   \    
> mail: wolski at molgen.mpg.de        ---W-W----
> http://www.molgen.mpg.de/~wolski 
> 
> 
> **********************************************************************
> This email and any files transmitted with it are confidentia...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kkr at dfu.min.dk  Thu Jan 22 15:52:32 2004
From: kkr at dfu.min.dk (Kasper Kristensen)
Date: Thu, 22 Jan 2004 15:52:32 +0100
Subject: [R] derivative of atan(x) and similar functions
Message-ID: <200401221552.32057.kkr@dfu.min.dk>

I have added the differentiation rules for asin, acos and atan to the file 
deriv.c.
Please let me know where to send it.

 Date: Thu, 22 Jan 2004 09:05:39 +0100
 From: Martin Maechler <maechler at stat.math.ethz.ch>
 Subject: Re: [R] derivative of atan(x) and similar functions
 To: Timur Elzhov <Timur.Elzhov at jinr.ru>
 Cc: R-help <R-help at stat.math.ethz.ch>
 Message-ID: <16399.33875.287060.214681 at gargle.gargle.HOWL>
 Content-Type: text/plain; charset=us-ascii
 
 >>>>> "Timur" == Timur Elzhov <Timur.Elzhov at jinr.ru>
 >>>>>     on Wed, 21 Jan 2004 14:54:58 +0300 writes:
 
     Timur> Dear R experts.  'D()' function recognizes some of
     Timur> the analitical functions, such as sin, cos, etc. But
     Timur> I'd like to take analytical derivatives from asin,
     Timur> atan etc. functions. Are there any R packages
     Timur> providing that features?
 
 Not that I know of.
 
 We know that it is one deficiency of D() {and deriv() ...} that
 it's not user-extendable.
 For the asin/acos/atan , I think we would gladly incorporate
 them into the current list --- IF someone volunteers to send us
 the patch.  Since sqrt() and basic arithmetic is already
 supported, this is only a matter of diligency..
 It's the file  <Rsource>/src/main/deriv.c  {and mainly (but not
 only) the  D(SEXP expr, SEXP var) function starting at line 268
 that needs to be extended.  If know some Lisp, it might be
 easier to get started... ;-)
 
 Martin Maechler <maechler at stat.math.ethz.ch>    
http://stat.ethz.ch/~maechler/
 Seminar fuer Statistik, ETH-Zentrum  LEO C16    Leonhardstr. 27
 ETH (Federal Inst. Technology)  8092 Zurich     SWITZERLAND
 phone: x-41-1-632-3408          fax: ...-1228                   <><
 
 
 
 ------------------------------



From s.henderson at ucl.ac.uk  Thu Jan 22 16:20:03 2004
From: s.henderson at ucl.ac.uk (Stephen Henderson)
Date: Thu, 22 Jan 2004 15:20:03 -0000
Subject: [R] customising installed libraries
Message-ID: <E7CF6BC2744CBE41AE4E87635C7C893C1C669E@exc.wibr.ucl.ac.uk>

 ha ha ha ha..hmmm.

Well although I don't follow the developments and deprecations of R
religiously that doesn't mean I'm innumerate. Thanks for the advice
nonetheless-- its working now.


-----Original Message-----
From: Prof Brian Ripley
To: Stephen Henderson
Cc: ''r-help at stat.math.ethz.ch' '
Sent: 1/22/04 2:51 PM
Subject: RE: [R] customising installed libraries

ipred has a NAMESPACE: you cannot do this to packages that have 
namespaces without changing the NAMESPACE file (and from the next
release, 
you will need to reinstall as well).

You can read about this in `Writing R Extensions', but is it a good idea

to be altering a package that uses concepts you do not understand?

I believe you mean `installed packages'.

On Thu, 22 Jan 2004, Stephen Henderson wrote:

>  I had quit q() R, reloaded and loaded ipred anew. Trying
> detach(package:ipred) makes no difference. I added a few pointless
lines to
> one existing function and can see these when I call the function,
passing no
> parameters. thats why i was assuming it was an R thing.
> 
> is this just some mysterious problem with my computer/ setup/ files??
not
> R??
> 
> -----Original Message-----
> From: Wolski
> To: Stephen Henderson
> Cc: 'r-help at stat.math.ethz.ch'
> Sent: 1/22/04 1:58 PM
> Subject: Re: [R] customising installed libraries
> 
> Have you executed first
> detach(package:library)
> before loading the library again?
> 
> Eryk
> *********** REPLY SEPARATOR  ***********
> 
> On 1/22/2004 at 1:47 PM Stephen Henderson wrote:
> 
> >hello
> >
> >I am returning to some libraries that I had previously customised by
> >amongst
> >other things adding additional functions. I had simply typed these
new
> >functions into the file in library/R/thelibrary. These however do not
> seem
> >to be loaded now as they previously were under older versions of R. 
> >
> >What's changed and what do i need to do?
> >
> >Thanks
> >Stephen
> >
> >
>
>**********************************************************************
> >This email and any files transmitted with it are
> confidentia...{{dropped}}
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> 
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate
> Genomics   
> Ihnestrasse 73 14195 Berlin          'v'    
> tel: 0049-30-84131285               /   \    
> mail: wolski at molgen.mpg.de        ---W-W----
> http://www.molgen.mpg.de/~wolski 
> 
> 
> **********************************************************************
> This email and any files transmitted with it are
confidentia...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


**********************************************************************
This email and any files transmitted with it are confidentia...{{dropped}}



From eesteves at ualg.pt  Thu Jan 22 16:42:19 2004
From: eesteves at ualg.pt (eesteves@ualg.pt)
Date: Thu, 22 Jan 2004 15:42:19 +0000
Subject: [R] help repeated measures factoial design
Message-ID: <1074786139.400fef5b74b62@wmail.ualg.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040122/afa117b0/attachment.pl

From ligges at statistik.uni-dortmund.de  Thu Jan 22 16:45:36 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 22 Jan 2004 16:45:36 +0100
Subject: [R] customising installed libraries
In-Reply-To: <200401221516420260.10A3F18B@harry.molgen.mpg.de>
References: <E7CF6BC2744CBE41AE4E87635C7C893C1C6699@exc.wibr.ucl.ac.uk>
	<200401221516420260.10A3F18B@harry.molgen.mpg.de>
Message-ID: <400FF020.3010801@statistik.uni-dortmund.de>

Wolski wrote:
> There are the concept of private and public functions in the new version.
> There are a file in the root directory of the lib

Dear all,

it's called a *package* which is installed within a library.

The "file" you are talking about is called NAMESPACE. It is used to 
configure whether a package has a namespace and which functions are 
exported etc.


 > where public functions can be entered.
> I by myself do not know much more. There are more info in the R-ext.pdf (R extensions).

Right, that manual is called "Writing R Extensions".


> Probably you have to add your new function name to this file.
> Eryk


Why do you edit code in a binary version of a package?

Either use your own pacakges to add functionality or, if really 
required, change the code of other packages in the packages' sources and 
install from sources again (preferably under a different name in order 
not to mess up with the original package).

Uwe Ligges



> *********** REPLY SEPARATOR  ***********
> 
> On 1/22/2004 at 2:08 PM Stephen Henderson wrote:
> 
> 
>>I had quit q() R, reloaded and loaded ipred anew. Trying
>>detach(package:ipred) makes no difference. I added a few pointless lines to
>>one existing function and can see these when I call the function, passing
>>no
>>parameters. thats why i was assuming it was an R thing.
>>
>>is this just some mysterious problem with my computer/ setup/ files?? not
>>R??
>>
>>-----Original Message-----
>>From: Wolski
>>To: Stephen Henderson
>>Cc: 'r-help at stat.math.ethz.ch'
>>Sent: 1/22/04 1:58 PM
>>Subject: Re: [R] customising installed libraries
>>
>>Have you executed first
>>detach(package:library)
>>before loading the library again?
>>
>>Eryk
>>*********** REPLY SEPARATOR  ***********
>>
>>On 1/22/2004 at 1:47 PM Stephen Henderson wrote:
>>
>>
>>>hello
>>>
>>>I am returning to some libraries that I had previously customised by
>>>amongst
>>>other things adding additional functions. I had simply typed these new
>>>functions into the file in library/R/thelibrary. These however do not
>>
>>seem
>>
>>>to be loaded now as they previously were under older versions of R. 
>>>
>>>What's changed and what do i need to do?
>>>
>>>Thanks
>>>Stephen
>>>
>>>
>>>**********************************************************************
>>>This email and any files transmitted with it are
>>
>>confidentia...{{dropped}}
>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>
>>http://www.R-project.org/posting-guide.html
>>
>>
>>
>>Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate
>>Genomics   
>>Ihnestrasse 73 14195 Berlin          'v'    
>>tel: 0049-30-84131285               /   \    
>>mail: wolski at molgen.mpg.de        ---W-W----
>>http://www.molgen.mpg.de/~wolski 
>>
>>
>>**********************************************************************
>>This email and any files transmitted with it are confidential and
>>intended solely for the use of the individual or entity to whom they
>>are addressed. If you have received this email in error please notify
>>the system manager (wibr.mail at ucl.ac.uk). All files are scanned for
>>viruses.
>>**********************************************************************
> 
> 
> 
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics   
> Ihnestrasse 73 14195 Berlin          'v'    
> tel: 0049-30-84131285               /   \    
> mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Thu Jan 22 17:03:18 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Jan 2004 17:03:18 +0100
Subject: [R] derivative of atan(x) and similar functions
In-Reply-To: <200401221552.32057.kkr@dfu.min.dk>
References: <200401221552.32057.kkr@dfu.min.dk>
Message-ID: <16399.62534.950210.629904@gargle.gargle.HOWL>

>>>>> "Kasper" == Kasper Kristensen <kkr at dfu.min.dk>
>>>>>     on Thu, 22 Jan 2004 15:52:32 +0100 writes:

    Kasper> I have added the differentiation rules for asin,
    Kasper> acos and atan to the file deriv.c.  Please let me
    Kasper> know where to send it.

Wow, that's a quick response,
thank you very much!

(Kasper has sent the file to me in the mean time).
I'll try to merge it into R-devel (where it deriv.c has been
improved in the initialization part).

Martin



From d.firth at warwick.ac.uk  Thu Jan 22 17:12:24 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Thu, 22 Jan 2004 16:12:24 +0000
Subject: [R] matrix exponential: M^0
In-Reply-To: <16399.39137.457957.656354@gargle.gargle.HOWL>
Message-ID: <C3CBB2B5-4CF5-11D8-8FE0-0050E4C03977@warwick.ac.uk>

Prompted by this thread, I have tidied up a Fortran program I wrote 
with Marina Shapira.  We would be happy for this ("mexp") to become 
part of R, either as a contributed package or as part of the base 
distribution if it's good enough.  I have packaged it and put it at
   http://www.warwick.ac.uk/go/dfirth/software/mexp

The examples in the help file show results on some "difficult" (but 
small) test matrices from the literature.  I would welcome any feedback 
on accuracy in other test cases.

This mexp function provides a choice of methods, Taylor series and Pad? 
approximation, both with the usual "squaring and scaling" for increased 
accuracy.

I have not tested it on any platform other than my own (Mac OS X).  
Until I know that it compiles and works on other platforms there seems 
little point in submitting it as a CRAN package.

David


On Thursday, Jan 22, 2004, at 09:33 Europe/London, Martin Maechler 
wrote:

>>>>>> "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>>>>>>     on 21 Jan 2004 19:08:38 +0100 writes:
>
>     PD> Martyn Plummer <plummer at iarc.fr> writes:
>>> Calculating the matrix exponential is harder than it
>>> looks (I'm sure Peter knows this). In fact there is a
>>> classic paper by Moler and Van Loan from the 1970s called
>>> "Nineteen dubious ways to calculate the exponential of a
>>> matrix", which they updated last year in SIAM.
>
>     PD> Right (magnificent paper by the way), although I
>     PD> actually hadn't heard about the update. As I remember
>     PD> it, Octave implements what Moler+v.Loan ends up
>     PD> suggesting in the 1978 paper.
>
> The update is actually available online
> from http://epubs.siam.org/sam-bin/dbq/article/41801
> with the extended title "...., 25 Years Later" .
>
> The extension is 8 pages of text + 1.2 pages of references,
> in which (p.42) they say
> ``The matrix exponential is an important computational tool in
>   control theory, so availability of  expm(A)  in early versions
>   of Matlab quite possibily contributed to the system's technical
>   and commercial success.''
>
> and they also tell how expm() is implemented in Matlab
> (scaling, squaring, Pad? approximation) which is presumably what
> octave does too?
>
> -----
>
> But -- going back to our original subject --
> Isn't
>
>   expm(A) =  ``e ^ A'' := sum_{n=0}^\Inf  A^n / n!
>
> definitely a bit harder than  A^n for (non-negative) integer n ?
>
> Martin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Thu Jan 22 17:30:17 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 22 Jan 2004 08:30:17 -0800
Subject: [R] help repeated measures factoial design
In-Reply-To: <1074786139.400fef5b74b62@wmail.ualg.pt>
References: <1074786139.400fef5b74b62@wmail.ualg.pt>
Message-ID: <400FFA99.3060900@pdf.com>

      I don't remember your original post, but I doubt if the 
nonresponse was due to the quality of the English prose;  English is a 
second language for a substantial porportion of the people who subscribe 
to this list, and most of the rest of us are sensitive to that issue and 
appreciate any efforts to meet us in English. 

      Have you studiend the posting guide at 
"http://www.R-project.org/posting-guide.html"?  I'm guessing that you 
may want "lme" in library(nlme), described by Pinhiero and Bates (2000) 
Mixed-Effects Models in S and S-Plus (Springer). 

      hope this helps. 
      spencer graves    

eesteves at ualg.pt wrote:

>Dear All,
>
>A few weeks ago I posted a question to this list but unfortunately got no 
>answer! A friend warned me of my english.
>
>Again, the problem is: 
>
>A 2-level 5-factors completely randomized design was used to investigate the 
>potential effects of those factors on a solution's characters (several response 
>variables). 
>Each response-variable was measured repeatedly (13 times) during a 30-day 
>period.
>We are insterested in studying each response at-a-time.
>
>Is there a R-package suitable for this kind of analysis?
>
>Thanks, 
>
>Eduardo Esteves
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From joehl at gmx.de  Thu Jan 22 17:40:14 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Thu, 22 Jan 2004 17:40:14 +0100 (MET)
Subject: [R] Please help with \usage{} for [.S3Class in Rd-Format
Message-ID: <7234.1074789614@www50.gmx.net>


Dear all,

I try to submit a library to CRAN but can't overcome the last R CMD CHECK. 

Can someone enlighten me how to put the \usage{} section for an S3-Method
extractor defined as

> args(get("[.refdata"))
function (x, i = NULL, j = NULL, drop = FALSE, ref = FALSE) 
NULL

I read the "Writing R Extensions" manual and know about
\methods{generic}{class}, however I don't get it right. 

Please help


Jens

-- 

Bis 31.1.: TopMail + Digicam f?r nur 29 EUR http://www.gmx.net/topmail



From maechler at stat.math.ethz.ch  Thu Jan 22 17:59:54 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Jan 2004 17:59:54 +0100
Subject: [R] File permissions and packages, openVignette
In-Reply-To: <BAA35444B19AD940997ED02A6996AAE0B5C439@sanmail.picr.man.ac.uk>
References: <BAA35444B19AD940997ED02A6996AAE0B5C439@sanmail.picr.man.ac.uk>
Message-ID: <16400.394.283300.509663@gargle.gargle.HOWL>

>>>>> "Crispin" == Crispin Miller <CMiller at picr.man.ac.uk>
>>>>>     on Thu, 22 Jan 2004 12:08:01 -0000 writes:

    Crispin> Hi,
    Crispin> I've got a quick question about file permissions and packages...

    Crispin> I'm creating my own package, and am having problems
    Crispin> with its vignette not being seen when I install it
    Crispin> into R...

    Crispin> As I understand it, the permissions of the source tree should be as
    Crispin> follows:
    Crispin> o Directories -   drwxrwxr-- 
    Crispin> o Files -         -rw-r--r--

No.  Directories (most of the time) need the 'x' bit everywhere
(and typically shouldn't be group writable) hence:

o  Directories -   drwxr-xr-x  (aka 755) 
o  Files       -   -rw-r--r--  (aka 644)

I don't know if this solves your problem.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From pauling at giub.unibe.ch  Thu Jan 22 18:00:44 2004
From: pauling at giub.unibe.ch (Andreas Pauling)
Date: Thu, 22 Jan 2004 18:00:44 +0100
Subject: [R] spectrum
Message-ID: <1074790844.401001bc1852b@www.cx.unibe.ch>


Dear R users

I have two questions about estimating the spectral power of a
time series:

1) I came across a funny thing with the following code:

data(co2)
par(mfrow=c(2,1))
co2.sp1<-spectrum(co2,detrend=T,demean=T,span=3)
co2.sp2<-spectrum(co2[1:468],detrend=T,demean=T,span=3)

The first plot displays the frequencies ranging from 0 to 6
whearas the second plot displays the same curve but with
frequencies between 0 and .5 although it is based on the same
data (length(co2)=468). Why does the selection (co2[1:468])
determine the vector of frequencies and plot it obviously
incorrectly?

Generally, is it possible to choose the vector of frequencies at
which the spectral density is estimated and plotted?

2) How can the significance of the peaks be tested?


Thanks for any help!!


Andreas


------------------------------------------------------
This mail was sent through IMP at http://mail.unibe.ch



From p.dalgaard at biostat.ku.dk  Thu Jan 22 18:14:56 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Jan 2004 18:14:56 +0100
Subject: [R] matrix exponential: M^0
In-Reply-To: <16399.39137.457957.656354@gargle.gargle.HOWL>
References: <1074616806.2958.46.camel@monkey> <x2isj6vcgk.fsf@biostat.ku.dk>
	<1074705611.13484.23.camel@xena.iarc.fr>
	<x24qupcgyh.fsf@biostat.ku.dk>
	<16399.39137.457957.656354@gargle.gargle.HOWL>
Message-ID: <x2zncfaorz.fsf@biostat.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> The update is actually available online
> from http://epubs.siam.org/sam-bin/dbq/article/41801
> with the extended title "...., 25 Years Later" .

To some, that is. I can download it to the work machine, but if I do
it from home, all I get is a 

...
                        <h1><br>
                          Please Login with Username and Password<br>
                        </h1>

thingie. I.e. you need to be affiliated with someone who paid their
subscription fees.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From maechler at stat.math.ethz.ch  Thu Jan 22 18:22:27 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Jan 2004 18:22:27 +0100
Subject: [R] Re: matrix __power__ (was "exponential")
In-Reply-To: <400FD149.10600@juntadeandalucia.es>
References: <1074713177.2956.109.camel@monkey>
	<400FD149.10600@juntadeandalucia.es>
Message-ID: <16400.1747.101241.439215@gargle.gargle.HOWL>

>>>>> "Vicente" == Vicente Canto Casasola <vicented.canto.ext at juntadeandalucia.es>
>>>>>     on Thu, 22 Jan 2004 14:34:01 +0100 writes:

    Vicente> H i, all!  First of all, I'd like to apologize for
    Vicente> my poor English. It's for years I don't use it.

no problem at all.

    Vicente> This is a R-version of a function I wrote a long
    Vicente> ago for my HP48 calculator.  It works with the
    Vicente> binary expression of the power and just need to
    Vicente> duplicate the mem used by X.

excellent. This is really the way to solve the problem 
I think. 

As I've mentioned earlier in this thread,
computing a matrix "power" is really much easier than the
matrix exponential.

Hence I wouldn't use exponential in the function name.
Also note that trailing ";" are considered as `dirty' (they are
completely superfluous).

These slight modifications (+ initial "test") 
give

matPower <- function(X,n)
## Function to calculate the n-th power of a matrix X
{
    if(n != round(n)) {
        n <- round(n)
        warning("rounding exponent `n' to", n)
    }
    phi <- diag(nrow = nrow(X))
    pot <- X # the first power of the matrix.

    while (n > 0)
    {
        if (n %% 2)
            phi <- phi %*% pot

        n <- n %/% 2
        pot <- pot %*% pot
    }
    return(phi)
}


Regards,

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ripley at stats.ox.ac.uk  Thu Jan 22 18:38:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jan 2004 17:38:12 +0000 (GMT)
Subject: [R] Please help with \usage{} for [.S3Class in Rd-Format
In-Reply-To: <7234.1074789614@www50.gmx.net>
Message-ID: <Pine.LNX.4.44.0401221732450.15485-100000@gannet.stats>

I think you may be trying too hard.  Look at Extract.data.frame.Rd and 
Extract.factor.Rd.  I would just have an Extract.refdata.Rd.

You only need the  \methods{generic}{class} notation when you want to 
document a generic and a method, or more than one method, in the same help 
file.  And at present the Perl conversion does not cope with regexp 
characters in function names ....

On Thu, 22 Jan 2004, "Jens Oehlschl?gel" wrote:

> 
> Dear all,
> 
> I try to submit a library to CRAN but can't overcome the last R CMD CHECK. 
> 
> Can someone enlighten me how to put the \usage{} section for an S3-Method
> extractor defined as
> 
> > args(get("[.refdata"))
> function (x, i = NULL, j = NULL, drop = FALSE, ref = FALSE) 
> NULL
> 
> I read the "Writing R Extensions" manual and know about
> \methods{generic}{class}, however I don't get it right. 
> 
> Please help
> 
> 
> Jens
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Jan 22 19:07:20 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jan 2004 18:07:20 +0000 (GMT)
Subject: [R] storage.mode and argument duplication
In-Reply-To: <400EF059.7010706@bankofcanada.ca>
Message-ID: <Pine.LNX.4.44.0401221758090.15534-100000@gannet.stats>

In R, storage.mode<- is an interpreted function that calls as.double (in 
your case) and copies attributes across so it is definitely worse than the 
second.

Is x$one usually double?  If so then

.Fortran("foo", if(is.double(x$one)) x$one else as.double(x$one), ...)

would save a copy.

Does your Fortran code change that argument?  As is .Fortran will make a
copy on the way in and on the way out. I think you should be able to use
DUP=FALSE, but if x$one is changed you need the as.double to make a copy.
I would not be worrying about anything up I had avoided the copies from
.Fortran.  My inclination would be to write a .Call wrapper to get full
control.

On Wed, 21 Jan 2004, Paul Gilbert wrote:

> I have a function which passes an element of a fairly large list to a 
> fortran call. In a function, when I use storage.mode on an element of a 
> list that is in the function argument, does this force the whole list to 
> be duplicated? More specifically, which of these should result in less 
> extra copying?
> 
> foo <- function(x)
>    {storage.mode(x$one) <- "double"
>     .Fortran("foo", x$one, result=as.double(rep(0,3)))["result"]
>    }
> 
> or
> 
> foo <- function(x)
>    {.Fortran("foo", as.double(x$one),
>               result=as.double(rep(0,3)))["result"]
>    }
> 
> Thanks,
> Paul Gilbert
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mn216 at columbia.edu  Thu Jan 22 19:03:03 2004
From: mn216 at columbia.edu (Murad Nayal)
Date: Thu, 22 Jan 2004 13:03:03 -0500
Subject: [R] silhoutte.default bugs
References: <400EDED0.B40A9BBF@columbia.edu>
	<16399.40220.518344.52826@gargle.gargle.HOWL>
Message-ID: <40101057.F9CDEDFC@columbia.edu>


Martin Maechler wrote:
> 
> >>>>> "Murad" == Murad Nayal <mn216 at columbia.edu>
> >>>>>     on Wed, 21 Jan 2004 15:19:28 -0500 writes:
> 
>     Murad> This might have been fixed in later versions (I am
>     Murad> using R1.7.0),
> 
> yes, the bug has been fixed "long ago",
> from my ChangeLog (!), it was 2003-07-18.

sorry about that. I have been reluctant to upgrade recently for fear of
disrupting my environment while in the middle of a project. as I
mentioned I searched the archive and found posts citing this problem but
no replies stating that it has been fixed (the Nj=1 case).


> 
> I'm still willing to consider your *feature request* (as opposed
> to bug fix) of allowing inputs where the grouping vector does
> contain other than "1:g" .

that would be great. it is straightforward to do and will broaden the
utility of silhouette. I'll send you the suggested patch privately.

best regards,
Murad



From ullrichj at mailer.uni-marburg.de  Thu Jan 22 19:11:08 2004
From: ullrichj at mailer.uni-marburg.de (Johannes Ullrich)
Date: Thu, 22 Jan 2004 19:11:08 +0100
Subject: [R] adding mean to boxplot
Message-ID: <1074795068.4010123c99310@home.staff.uni-marburg.de>

I am a new and unexperienced user of R and got so far as to know how to produce 
boxplots. I have no experience of messing with function code, so presently I do 
not know how to create a boxplot with group means instead of group medians. If 
somebody could help me either replace the median with the mean or superimpose 
the mean onto the existing boxplot, it would be appreciated.



From ripley at stats.ox.ac.uk  Thu Jan 22 19:20:24 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jan 2004 18:20:24 +0000 (GMT)
Subject: [R] spectrum
In-Reply-To: <1074790844.401001bc1852b@www.cx.unibe.ch>
Message-ID: <Pine.LNX.4.44.0401221808380.15534-100000@gannet.stats>

On Thu, 22 Jan 2004, Andreas Pauling wrote:

> I have two questions about estimating the spectral power of a
> time series:
> 
> 1) I came across a funny thing with the following code:
> 
> data(co2)
> par(mfrow=c(2,1))
> co2.sp1<-spectrum(co2,detrend=T,demean=T,span=3)
> co2.sp2<-spectrum(co2[1:468],detrend=T,demean=T,span=3)
> 
> The first plot displays the frequencies ranging from 0 to 6
> whearas the second plot displays the same curve but with
> frequencies between 0 and .5 although it is based on the same
> data (length(co2)=468). Why does the selection (co2[1:468])
> determine the vector of frequencies and plot it obviously
> incorrectly?

It is correct!  co2[1:468] is not a time series: you should be using 
window() to subset time series.  So you supplied a vector which does not 
have a frequency (or a start or an end) and default values are used.

Did you consider actually looking at co2[1:468]?


> Generally, is it possible to choose the vector of frequencies at
> which the spectral density is estimated and plotted?

Wait a minute: spectrum() does not estimate a spectral density but calls 
helper functions to do so.  Please consult their help pages.  The answer 
is a qualified `yes'.

> 2) How can the significance of the peaks be tested?

Not an R question, and not well enough defined for a short answer.  See 
any good book on time series.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ivo.welch at yale.edu  Thu Jan 22 19:32:29 2004
From: ivo.welch at yale.edu (ivo welch)
Date: Thu, 22 Jan 2004 13:32:29 -0500
Subject: [R] Axes Ticks
Message-ID: <4010173D.9040509@yale.edu>


Apologies, basic question on plot.

	y <- c(-4,3,-2,1);
	x <- c("time 1", "time 2", "time 3", "time 4");
	plot(x,y, type="b");

of course fails.
	x <- 1:4
makes it succeed, but then I have too many ticks on my X axis.  I want 
exactly 4 tickmarks.  It would also be nicer if I could name the ticks.

I looked at ?par and Venables&Ripley, and tried the lab and xaxp 
parameters.  I could not figure out how to use them productively.  could 
someone please let me know?  help appreciated.  /iaw



From abunn at montana.edu  Thu Jan 22 19:33:20 2004
From: abunn at montana.edu (Andy Bunn)
Date: Thu, 22 Jan 2004 11:33:20 -0700
Subject: [R] adding mean to boxplot
In-Reply-To: <1074795068.4010123c99310@home.staff.uni-marburg.de>
Message-ID: <000101c3e116$47c5c7a0$78f05a99@msu.montana.edu>

This will add triangles at the mean value. To change the behavior of
boxplot() to draw means instead of medians would involve rewriting the
bxp() code I believe. You could change the points in the code below to
segments. See ?segments. The archives have quite a few examples of
people modifying the bxp() code so look there and see ?bxp.

     # Load some data
     data(OrchardSprays)
     # Make the boxplot and save the boxplot object
     rb <- boxplot(decrease ~ treatment, data = OrchardSprays)
     # Compute the means
     mean.value <- tapply(OrchardSprays$decrease,
OrchardSprays$treatment, mean)
     # Add them as triangles.
     points(seq(rb$n), mean.value, pch = 17)

HTH, Andy



From MSchwartz at medanalytics.com  Thu Jan 22 19:47:56 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 22 Jan 2004 12:47:56 -0600
Subject: [R] adding mean to boxplot
In-Reply-To: <1074795068.4010123c99310@home.staff.uni-marburg.de>
References: <1074795068.4010123c99310@home.staff.uni-marburg.de>
Message-ID: <1074797275.5099.85.camel@localhost.localdomain>

On Thu, 2004-01-22 at 12:11, Johannes Ullrich wrote:
> I am a new and unexperienced user of R and got so far as to know how to produce 
> boxplots. I have no experience of messing with function code, so presently I do 
> not know how to create a boxplot with group means instead of group medians. If 
> somebody could help me either replace the median with the mean or superimpose 
> the mean onto the existing boxplot, it would be appreciated.


You are probably better doing the second option, since boxplots are
premised on the visual display of quantiles.

Here is a quick example of adding means:

# Create two groups of continuous data
# and bind them together
A <- data.frame(Group = "A", 
                Measure = rnorm(50, 5))

B <- data.frame(Group = "B", 
                Measure = rnorm(50, 7.5))
Data <- rbind(A, B)
attach(Data)

# Now create a boxplot with two groups using
# the formula method
boxplot(Measure ~ Group)

# Get the group means
means <- by(Measure, Group, mean)                        

# Plot symbols for each mean, centered on
# x = 1 and x = 2, which are the default center
# values.
points(1:2, means, pch = 23, cex = 0.75,
       bg = "red")

# Now label the means, formatting the values
# to one decimal place. Place the values to the
# left of each group plot.
text(1:2 - 0.4, means, 
     labels = formatC(means, format = "f", 
                      digits = 1),
     pos = 2, cex = 0.9, col = "red")

# Clean up
detach(Data)

See ?boxplot, ?par, ?points, ?text and ?formatC for more information.

You might want to review R News (http://cran.r-project.org/doc/Rnews/)
Vol 3  Number 2 (October 2003), where there is an article providing an
introduction to R's base graphics.

HTH,

Marc Schwartz



From feh3k at spamcop.net  Thu Jan 22 19:58:36 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Thu, 22 Jan 2004 12:58:36 -0600
Subject: [R] adding mean to boxplot
In-Reply-To: <1074795068.4010123c99310@home.staff.uni-marburg.de>
References: <1074795068.4010123c99310@home.staff.uni-marburg.de>
Message-ID: <20040122125836.536e6b6a.feh3k@spamcop.net>

On Thu, 22 Jan 2004 19:11:08 +0100
Johannes Ullrich <ullrichj at mailer.uni-marburg.de> wrote:

> I am a new and unexperienced user of R and got so far as to know how to
> produce boxplots. I have no experience of messing with function code, so
> presently I do not know how to create a boxplot with group means instead
> of group medians. If somebody could help me either replace the median
> with the mean or superimpose the mean onto the existing boxplot, it
> would be appreciated.

You might want to also consider extended box plots or box-percentile plots
to show more information, plus the mean.  See the panel.bpplot function in
the Hmisc package.  There are many examples in the help file.
---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From MSchwartz at medanalytics.com  Thu Jan 22 20:05:41 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 22 Jan 2004 13:05:41 -0600
Subject: [R] Axes Ticks
In-Reply-To: <4010173D.9040509@yale.edu>
References: <4010173D.9040509@yale.edu>
Message-ID: <1074798341.5099.94.camel@localhost.localdomain>

On Thu, 2004-01-22 at 12:32, ivo welch wrote:
> Apologies, basic question on plot.
> 
> 	y <- c(-4,3,-2,1);
> 	x <- c("time 1", "time 2", "time 3", "time 4");
> 	plot(x,y, type="b");
> 
> of course fails.
> 	x <- 1:4
> makes it succeed, but then I have too many ticks on my X axis.  I want 
> exactly 4 tickmarks.  It would also be nicer if I could name the ticks.
> 
> I looked at ?par and Venables&Ripley, and tried the lab and xaxp 
> parameters.  I could not figure out how to use them productively.  could 
> someone please let me know?  help appreciated.  /iaw


Use 'xaxt' in the call to plot() and then use axis() to control the axis
tick marks and labels:

y <- c(-4, 3, -2, 1)
x <- c(1:4)

# Do not plot the x axis
plot(x, y, type = "b", xaxt = "n")

# Now draw the x axis with text labels
axis(1, at = 1:4, labels = paste("Time", 1:4, sep = " "))

See ?par (xaxt) and ?axis for more information.

You can also use:

plot(x, y, axes = FALSE)

and then use axis(1, ...) and axis(2, ...) if you want to control both
the x and y axes, respectively.

HTH,

Marc Schwartz



From edd at debian.org  Thu Jan 22 20:12:40 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 22 Jan 2004 13:12:40 -0600
Subject: [R] Axes Ticks
In-Reply-To: <4010173D.9040509@yale.edu>
References: <4010173D.9040509@yale.edu>
Message-ID: <20040122191240.GA1815@sonny.eddelbuettel.com>

On Thu, Jan 22, 2004 at 01:32:29PM -0500, ivo welch wrote:
> 
> Apologies, basic question on plot.
> 
> 	y <- c(-4,3,-2,1);
> 	x <- c("time 1", "time 2", "time 3", "time 4");
> 	plot(x,y, type="b");
> 
> of course fails.
> 	x <- 1:4
> makes it succeed, but then I have too many ticks on my X axis.  I want 
> exactly 4 tickmarks.  It would also be nicer if I could name the ticks.
> 
> I looked at ?par and Venables&Ripley, and tried the lab and xaxp 
> parameters.  I could not figure out how to use them productively.  could 
> someone please let me know?  help appreciated.  /iaw

y <- c(-4,3,-2,1)
xlab <- c("time 1", "time 2", "time 3", "time 4")
x <-1:4
plot(x,y, type="b", axes=FALSE)
axis(2)
axis(1, at=x, labels=xlab) 
box()				     

If you use 'axis(1, at=x)' you can do without xlab, but get only the bare
numbers. box() is needed to frame the whole thing as the default axes=TRUE
for plot() does.

Gruss,  Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From abunn at montana.edu  Thu Jan 22 20:13:31 2004
From: abunn at montana.edu (Andy Bunn)
Date: Thu, 22 Jan 2004 12:13:31 -0700
Subject: [R] Axes Ticks
In-Reply-To: <4010173D.9040509@yale.edu>
Message-ID: <000601c3e11b$e4ae9880$78f05a99@msu.montana.edu>

You need to look at ?axis. Try this:

y <- c(-4,3,-2,1)
x <- c("time 1", "time 2", "time 3", "time 4")
plot(seq(1,length(x), by = 1), y, type = "b", axes = FALSE, xlab =
"Times", ylab = "Stuff")
axis(1, at = seq(1,length(x), by = 1), labels = x)
axis(2)

HTH, Andy



From hagric at sbox.tugraz.at  Thu Jan 22 20:34:52 2004
From: hagric at sbox.tugraz.at (hagric)
Date: Thu, 22 Jan 2004 20:34:52 +0100
Subject: [R] wavelet toolbox
Message-ID: <401025DC.4030002@sbox.TUGraz.at>

Is there a wavelet toolbox in R available that can be compared to the 
Matlab toolbox for wavelets. Does this toolbox offer the possibility to 
calculated approximations with different wavelets such as Daubechies 2, 
Daubechies 3, etc, Symmlet 3, Symmlets 5, etc, Coiflets and so on. I 
have tried to proceed in this way but I was only able to use one sort of 
wavelets with a pre-fixed order (i.e.  pre-fixed vanishing moments).
Thank you for help!
Vera Hofer



From Simon.Wotherspoon at utas.edu.au  Thu Jan 22 07:06:27 2004
From: Simon.Wotherspoon at utas.edu.au (Simon Wotherspoon)
Date: Thu, 22 Jan 2004 17:06:27 +1100
Subject: [R] Bug in termplot?
Message-ID: <JPEJIEHCLCCMMBFGMPDGMELICGAA.Simon.Wotherspoon@utas.edu.au>

Hi,
	Is this a bug in termplot, or (once again) do I just not understand what R
is really doing?


I am using termplot to contruct partial residual plots,
  1. For all terms at once
  2. One term at a time
but I get different results from these two methods.  To give a concrete
example, I would have thought the top and bottom rows of the plot
constructed with the following code would be identical.

Grateful for any clues

Simon.



## Term plot example

n <- 50
x1 <- 2*runif(n)
x2 <- 2*runif(n)
y <- x1+sin(x2)+0.1*rnorm(n)

fit <- lm(y ~ x1 +x2)
par(mfrow=c(2,2))
termplot(fit,partial=T)
termplot(fit,terms="x1",partial=T)
termplot(fit,terms="x2",partial=T)



--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status =
 major = 1
 minor = 8.1
 year = 2003
 month = 11
 day = 21
 language = R

Windows ME 4.90 (build 3000)

Search Path:
 .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg,
package:nls, package:ts, Autoloads, package:base
---



From gr3k at virginia.edu  Thu Jan 22 20:58:20 2004
From: gr3k at virginia.edu (Greg Riddick)
Date: Thu, 22 Jan 2004 14:58:20 -0500
Subject: [R] scan() Bug?
Message-ID: <000801c3e122$15c956c0$0400a8c0@ghandi>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040122/4e49aa81/attachment.pl

From jennysmith551 at yahoo.com  Thu Jan 22 21:35:39 2004
From: jennysmith551 at yahoo.com (jenny smith)
Date: Thu, 22 Jan 2004 12:35:39 -0800 (PST)
Subject: [R] lm function
Message-ID: <20040122203539.74269.qmail@web21502.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040122/0f514a56/attachment.pl

From mmiller3 at iupui.edu  Thu Jan 22 22:01:35 2004
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Thu, 22 Jan 2004 16:01:35 -0500
Subject: [R] Fitting compartmental model with nls and lsoda?
References: <x2of4o2uan.fsf@biostat.ku.dk>
Message-ID: <87isj31yvk.fsf@lumen.indyrad.iupui.edu>

A while back I started looking into using R to fit kinetic models
and I'm finally getting back to it.  It was suggested that I use
lsoda (thanks Peter Dalgaard).  So I've tried that, even though
Peter warned me that it'd be tricky.  I've put the following
example together from the lsoda help pages, but I'm not sure that
this is the correct/best way to fit a model like this.  Or maybe
this is just what Peter warned me about?  When I run the
following code, I get this error message:

  Error in qr.qty(QR, resid) : qr and y must have the same number of rows

I'm not sure where to go from there...

Regards, Mike


##====================================================
require(odesolve)

## Simple one compartment blood flow model:
one.compartment.model <- function(t, x, parms) {
  C1 <- x[1] # compartment
  with(as.list(parms),{
    input <- approx(signal$time, signal$input, t)$y
    dC1 <- K1 * input - k2 * C1
    list(c(dC1))
  })
}

## vector of timesteps
time <- seq(0, 100)

## external signal with rectangle impulse
signal <- as.data.frame(list(time=time,
                             input=rep(0,length(time))))
signal$input[signal$time >= 10 & signal$time <=40] <- 0.2

## Parameters for steady state conditions
parms <- c(K1=0.5, k2=0.5)

## Start values for steady state
xstart <- c(C1=0)

## calculate C1 with lsoda:
C1.lsoda <- as.data.frame(lsoda(xstart, time, one.compartment.model, parms))

## Add some noise to the output curve so I can try to fit it...
C1.lsoda$noisy <- C1.lsoda$C1 + rnorm(nrow(C1.lsoda), sd=0.05*C1.lsoda$C1)

## Plot what I've got so far:
plot(input ~ time, data=signal, type='b')
points(C1.lsoda, type='b', pch=16)
points(noisy ~ time, data=C1.lsoda, col='forestgreen')

## See if I can run a fit to find the parameters that I started with...
require(nls)
fit <- nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1=0.5, k2=0.5)),
           data=C1.lsoda,
           start=list(K1=0.3, k2=0.7),
           trace=T
           )
##====================================================


> R.version
         _                
platform i386-pc-linux-gnu
arch     i386             
os       linux-gnu        
system   i386, linux-gnu  
status                    
major    1                
minor    8.1              
year     2003             
month    11               
day      21               
language R   

Package: nls
Version: 1.8.1

Package: odesolve
Version: 0.5-8



-- 

Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine



From tlumley at u.washington.edu  Thu Jan 22 22:05:52 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 22 Jan 2004 13:05:52 -0800 (PST)
Subject: [R] lm function
In-Reply-To: <20040122203539.74269.qmail@web21502.mail.yahoo.com>
References: <20040122203539.74269.qmail@web21502.mail.yahoo.com>
Message-ID: <Pine.A41.4.58.0401221305000.12616@homer33.u.washington.edu>

On Thu, 22 Jan 2004, jenny smith wrote:

> Hi, How can I extract the standard deviation of the coefficients when
> using the lm function.  I know ____$coefficient gives me the individual
> betas.  thank you

$coefficient is not the recommended way to get the coefficients.

use coef(your.model) for the coefficients and vcov(your.model) for their
variance matrix, so that sqrt(diag(vcov(your.model))) are the standard
errors.

	-thomas



>
>
> ---------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From sebastiendurand at videotron.ca  Thu Jan 22 22:11:52 2004
From: sebastiendurand at videotron.ca (Sebastien Durand)
Date: Thu, 22 Jan 2004 16:11:52 -0500
Subject: [R] Graphical Windows
Message-ID: <a06020401bc35eb54dddd@[192.168.2.3]>

Hello,

Here is my problem.  I am trying to run and learn R trough the 
terminal application of my Mac (it runs on Panther).

So here it goes I just recently installed R, in unix mode (terminal) 
by following the attached web page.  The trouble is when I try to run 
either demo(graphics), demo(image) or even just a plot(x,y) of random 
values, no windows opens.  I get nada...

Could you please give me a hand!

I don't know any one who can give me a hand on this!

From mendigo at netcabo.pt  Thu Jan 22 22:14:45 2004
From: mendigo at netcabo.pt (M. M. Palhoto N. Rodrigues)
Date: Thu, 22 Jan 2004 21:14:45 -0000
Subject: [R] help repeated measures factoial design
References: <1074786139.400fef5b74b62@wmail.ualg.pt>
Message-ID: <002c01c3e12c$c86cf3e0$7ea616d5@galactic>

If you are interested in study each response isolated and because you have a
temporal time-series it could be a possibility for your study to modelize
that
time-serie with ARMA or GARCH process. For that you have ts  and tseries
packages.

Palhoto.


>
> Dear All,
>
> A few weeks ago I posted a question to this list but unfortunately got no
> answer! A friend warned me of my english.
>
> Again, the problem is:
>
> A 2-level 5-factors completely randomized design was used to investigate
the
> potential effects of those factors on a solution's characters (several
response
> variables).
> Each response-variable was measured repeatedly (13 times) during a 30-day
> period.
> We are insterested in studying each response at-a-time.
>
> Is there a R-package suitable for this kind of analysis?
>
> Thanks,
>
> Eduardo Esteves
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From d.firth at warwick.ac.uk  Thu Jan 22 22:27:39 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Thu, 22 Jan 2004 21:27:39 +0000
Subject: [R] lm function
In-Reply-To: <20040122203539.74269.qmail@web21502.mail.yahoo.com>
Message-ID: <CE3AB751-4D21-11D8-88D4-0050E4C03977@warwick.ac.uk>

If the model is called "mymodel", you could do

   summary(mymodel)$coefficients[,2]

or

   sqrt(diag(vcov(mymodel)))

This gives the estimated standard errors of the coefficients, which I 
think is what you wanted.

David

On Thursday, Jan 22, 2004, at 20:35 Europe/London, jenny smith wrote:

> Hi,
> How can I extract the standard deviation of the coefficients when 
> using the lm function.  I know ____$coefficient gives me the 
> individual betas.  thank you
>
>
> ---------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From sam.kemp2 at ntlworld.com  Thu Jan 22 22:49:13 2004
From: sam.kemp2 at ntlworld.com (Samuel Kemp)
Date: Thu, 22 Jan 2004 21:49:13 +0000
Subject: [R] Interfacing with Java
Message-ID: <40104559.7000002@ntlworld.com>

Hi,

Is there a hack to get R talking with Java?

Is any one out there working on interfacing R with Java? If so can I be 
of service???

Cheers,

Sam.



From ripley at stats.ox.ac.uk  Thu Jan 22 22:52:14 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jan 2004 21:52:14 +0000 (GMT)
Subject: [R] scan() Bug?
In-Reply-To: <000801c3e122$15c956c0$0400a8c0@ghandi>
Message-ID: <Pine.LNX.4.44.0401222150200.20473-100000@gannet.stats>

On Thu, 22 Jan 2004, Greg Riddick wrote:

> I'm reading a file into a list by:
> PDF = scan("file",what="character",sep="\10")
> 
> "\10" is the newline character in this file, also tried "\n" originally
> 
> On lines that are ended by "\13\10", both are dropped from the list entry
> I want scan to keep the "\13" in the list entry.
> 
> Is this a bug or just a strange feature?

Not a strange feature, but the documented behaviour (and useful, too).  
You have opened the file in text mode.  If you want to keep CRs, open and
read in binary mode.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu Jan 22 22:59:28 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Jan 2004 22:59:28 +0100
Subject: [R] Fitting compartmental model with nls and lsoda?
In-Reply-To: <87isj31yvk.fsf@lumen.indyrad.iupui.edu>
References: <x2of4o2uan.fsf@biostat.ku.dk>
	<87isj31yvk.fsf@lumen.indyrad.iupui.edu>
Message-ID: <x2ektrablr.fsf@biostat.ku.dk>

mmiller3 at iupui.edu (Michael A. Miller) writes:

> A while back I started looking into using R to fit kinetic models
> and I'm finally getting back to it.  It was suggested that I use
> lsoda (thanks Peter Dalgaard).  So I've tried that, even though
> Peter warned me that it'd be tricky.  I've put the following
> example together from the lsoda help pages, but I'm not sure that
> this is the correct/best way to fit a model like this.  Or maybe
> this is just what Peter warned me about?  When I run the
> following code, I get this error message:
> 
>   Error in qr.qty(QR, resid) : qr and y must have the same number of rows
> 
> I'm not sure where to go from there...
....
> fit <- nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1=0.5, k2=0.5)),
>            data=C1.lsoda,
>            start=list(K1=0.3, k2=0.7),
>            trace=T
>            )

Well, for a start, 

nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1=K1, k2=k2))[,2],
etc.

works better. Notice that lsoda returns a matrix, not just the vector
of means. Also, you were supplying parameters both held constant at
0.5. If you do that, the thing at least moves:

0.3746248 :  0.3 0.7
0.007367827 :  0.3530283 0.3598175
0.007210442 :  0.3556961 0.3510272
0.002582476 :  0.4579374 0.4585350
0.002476932 :  0.4774264 0.4775360
0.002476923 :  0.4773889 0.4775243
0.002476915 :  0.4773416 0.4775221
0.002476910 :  0.4773417 0.4775218
0.00247685 :  0.4773748 0.4775564
0.002476846 :  0.4773745 0.4775566
0.002476845 :  0.4773744 0.4775566

Error in nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1 = K1,  :
        step factor 0.000488281 reduced below `minFactor' of 0.000976562

...but now you run into a problem which is probably of the kind I
warned you against before. Be careful about those
singularities in the input function! 

Things that I know of which might help:

A. Split the region into pieces where the input is continuous to at
least 2nd order (meaning that I don't know if that is enough in
general, but first-order continuity is clearly not enough). You have 3
piecewise constant regions, so that should be easy.

B. Use a less intelligent integrator, e.g. rk4 (on a finer grid!)

C. Modify the RHS to supply a gradient with respect to the parameters
(easy, by implicit differentiation).

D. Adjust tolerances in both lsoda and nls.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From hana at stat.washington.edu  Thu Jan 22 23:19:17 2004
From: hana at stat.washington.edu (Hana Sevcikova)
Date: Thu, 22 Jan 2004 14:19:17 -0800 (PST)
Subject: [R] help on rgdal package
Message-ID: <Pine.LNX.4.53.0401221358380.7054@spc16.stat.washington.edu>

I started to use the rgdal package in order to work with DEM files. Since
these files are based on non-rectangular quads, there are lots of
NA-values in the corresponding datasets. Does anybody know how to remove
the NA-values from an object of class GDALDataset in order to get a
rectangular dataset?

Also, the function saveDataset doesn't seem to work for these kind of data
(or at least for me). I get the following error:

> x <- new("GDALDataset", "xxx.dem")
> getDriverLongName(getDriver(x))
[1] "USGS Optional ASCII DEM"

> saveDataset(x,"xxx.data")
Error in .local(.Object, ...) :
        GDAL Error 6: GDALDriver::Create() ... no create method implemented for this format.

Or should the dataset be raster data? Then I get:

> rd<-getRasterData(x)
> saveDataset(rd,"test.data")
Error in .assertClass(dataset, "GDALReadOnlyDataset") :
        Object is not a member of class GDALReadOnlyDataset

Does anybody see what am I doing wrong? Thanks.

Hana Sevcikova



From gr3k at virginia.edu  Thu Jan 22 23:24:53 2004
From: gr3k at virginia.edu (Greg Riddick)
Date: Thu, 22 Jan 2004 17:24:53 -0500
Subject: [R] scan() Bug?
References: <OFC58EB649.CC86C9A5-ON85256E23.00790DA4@nd.convergys.com>
Message-ID: <004901c3e136$8ec9f6b0$0400a8c0@ghandi>

Thanks,

Right, I can see why sep="\n" might grab the entire "\13\10"  but it seems
like sep="\10" should not strip the "\13" also.

I need to read in this file (PDF file) and create a list of lines defined by
the "\10" delimiter.
Any suggestions how I could use ReadBin to do that?




>Not a strange feature, but the documented behaviour (and useful, too).
>You have opened the file in text mode.  If you want to keep CRs, open and
>read in binary mode.

>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595





>
> Try opening the file as a connection using the 'read binary' mode.  If you
> are running on a Windows system, the operating system is taking \10\13 and
> mapping that to just '\n' since that is the normal sequence that Windows
> uses on text files.
> __________________________________________________________
> James Holtman        "What is the problem you are trying to solve?"
> Executive Consultant  --  Office of Technology, Convergys
> james.holtman at convergys.com
> +1 (513) 723-2929
>
>


>
>                       "Greg Riddick"
>                       <gr3k at virginia.edu>          To:
<r-help at stat.math.ethz.ch>
>                  >
>
>
> I'm reading a file into a list by:
> PDF = scan("file",what="character",sep="\10")
>
> "\10" is the newline character in this file, also tried "\n" originally
>
> On lines that are ended by "\13\10", both are dropped from the list entry
> I want scan to keep the "\13" in the list entry.
>
> Is this a bug or just a strange feature?
>



From ripley at stats.ox.ac.uk  Thu Jan 22 23:35:56 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Jan 2004 22:35:56 +0000 (GMT)
Subject: [R] scan() Bug?
In-Reply-To: <004901c3e136$8ec9f6b0$0400a8c0@ghandi>
Message-ID: <Pine.LNX.4.44.0401222229300.20663-100000@gannet.stats>

On Thu, 22 Jan 2004, Greg Riddick wrote:

> Thanks,
> 
> Right, I can see why sep="\n" might grab the entire "\13\10"  but it seems
> like sep="\10" should not strip the "\13" also.

Why do you claim so?  Text mode is *documented* to use any of CR, CRLF or
LF as the line delimiter.  Please don't keep telling us R `should not' do 
things that are fully intentional and documented.

> I need to read in this file (PDF file) and create a list of lines defined by
> the "\10" delimiter.
> Any suggestions how I could use ReadBin to do that?

R is not really set up to deal with bytes in binary files (and a PDF file 
*is* a binary file).  You can however just read in the whole file and 
split it using strsplit, for example.

> >Not a strange feature, but the documented behaviour (and useful, too).
> >You have opened the file in text mode.  If you want to keep CRs, open and
> >read in binary mode.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Mark.Bravington at csiro.au  Fri Jan 23 00:05:09 2004
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Fri, 23 Jan 2004 10:05:09 +1100
Subject: =?iso-8859-1?Q?FW=3A_R=E9f=2E_=3A_=5BR=5D_Packages_debug_and_mvbutils?=
Message-ID: <C4178DC99E08604EA5E2BDB989F09380090C3E@extas2-hba.tas.csiro.au>

Please use the CRAN versions, not the ftp versions which are now out-of-date. Both packages are on base CRAN now, but may not have propagated to all mirrors yet. (But thanks to Gerald for responding-- I had de-subscribed from R-help.)

For anyone using the HANDY package (a Windows-specific package which includes a non-C DLL, so I can't CRAN it): I'll post an updated version on the ftp site later today.

Bye
Mark

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington at csiro.au


-----Original Message-----
From: gerald.jean at dgag.ca [mailto:gerald.jean at dgag.ca] 
Sent: Friday, January 23, 2004 1:06 AM
To: ernesto at ipimar.pt; hrust at pik-potsdam.de
Cc: Mailing List R
Subject: R?f. : [R] Packages debug and mvbutils



If you want to access these utilities before M.Bravington post them on CRAN they are available on his site:

(ftp://ftp.marine.csiro.au/software/bravington/)

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From hodgess at gator.uhd.edu  Fri Jan 23 00:41:42 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Thu, 22 Jan 2004 17:41:42 -0600
Subject: [R] data.entry question
Message-ID: <200401222341.i0MNfge30654@gator.dt.uh.edu>

Dear R People:

When I use data.entry for a new variable, the first entry is a NA

The function works all right, but then I get a Warning message:
> data.entry("xb",Modes="numeric")
Warning message:
NAs introduced by coercion

Since the function works acceptably, should I just ignore the 
warning message, please?

By the way, when I use data.entry on an existing variable, it
works just fine.  No warnings.

R 1.8.1 for Windows.

Thanks in advance for any help!
Sincerely
Erin
mailto: hodgess at gator.uhd.edu



From tlumley at u.washington.edu  Fri Jan 23 00:33:16 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 22 Jan 2004 15:33:16 -0800 (PST)
Subject: [R] Graphical Windows
In-Reply-To: <a06020401bc35eb54dddd@[192.168.2.3]>
References: <a06020401bc35eb54dddd@[192.168.2.3]>
Message-ID: <Pine.A41.4.58.0401221529420.12616@homer33.u.washington.edu>

On Thu, 22 Jan 2004, Sebastien Durand wrote:

> Hello,
>
> Here is my problem.  I am trying to run and learn R trough the
> terminal application of my Mac (it runs on Panther).
>
> So here it goes I just recently installed R, in unix mode (terminal)
> by following the attached web page.  The trouble is when I try to run
> either demo(graphics), demo(image) or even just a plot(x,y) of random
> values, no windows opens.  I get nada...
>

Your graphs are going to the file Rplots.ps, which you can view with
Preview after closing the file in R with
> dev.off()

In terminal mode the way to get displays on the screen is with the X11
driver, for which you need an X11 server (such as the one Apple supplies
with Panther).

Start X11 and then in your R session do
>  x11(display=":0")

to open a display device.

The RAqua GUI has a Quartz display device that is run by default, but
getting it to work outside the GUI is still under development.


	-thomas



From yunfang at yahoo-inc.com  Fri Jan 23 00:33:02 2004
From: yunfang at yahoo-inc.com (Yun-Fang Juan)
Date: Thu, 22 Jan 2004 15:33:02 -0800
Subject: [R] getting confidence intervals after lm fitting
References: <OFC58EB649.CC86C9A5-ON85256E23.00790DA4@nd.convergys.com>
	<004901c3e136$8ec9f6b0$0400a8c0@ghandi>
Message-ID: <019d01c3e140$13bdd3b0$983991d8@jungdm>

Hi,
After fitting with lm, I want to get the 95 % confidence intervals of  the
expected predicted value.
I know in S-plus I can use pointwise() to get the confidence intervals .
But in R, I couldn't find such a function.
Is there any R package available for such functionalities.

Please advise.


thanks,


Yun-Fang



From DivineSAAM at aol.com  Fri Jan 23 00:56:02 2004
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Thu, 22 Jan 2004 18:56:02 -0500
Subject: [R] Fitting compartmental model with nls and lsoda?
Message-ID: <0E27DEC3.3CA874F1.0B088159@aol.com>

Dear Colleagues,

Our group is also working on implementing the use of R for pharmacokinetic compartmental analysis. Perhaps I have missed something, but

> fit <- nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1=0.5, k2=0.5)),
+            data=C1.lsoda,
+            start=list(K1=0.3, k2=0.7),
+            trace=T
+            )
Error in eval(as.name(varName), data) : Object "C1.lsoda" not found

What part of the e-mail did I miss? I would like to get this problem up an running.

Now, I am including Richar Upton's 2 cm model implementation and Christoffer Tornoe's nls solution (I recommend Christoffer's nlmeODE package for these problems also if multi-response data is available) The code follows:
--------------------------------------------------------------
# Simulation of a 2 compartment pharmacokinetic model using "R"
# Richard N. Upton, 11/3/02, richard.upton at adelaide.edu.au

# The "R" home page is at http://www.R-project.org/

# I make no representations about being an "R" guru.  My contribution here
# is hopefully to provide a starting point in "R" for people who
# have a pharmacokinetic modelling background.

# This text can  be "cut and pasted" into R, or read in as a "source" file

# There are two differential equations in the system:

# V*dC/dt = Doserate - C*Cl + k21*A2 - k12*V*C
# dA2/dt = k12*V*C - k21*A2

# C is a dependent variable (Concentration in the central compartment)
# A is a dependent variable (Amount in the second compartment)
# t is the independent variable (time)

# V is the volume of the central compartment
# Cl is the clearance from the central compartment
# k12 is the rate constant between the central and second compartment
# k21 is the rate constant between the second and central compartment

# Dose is the total amount of drug given
# tau is the time over which this amount is given
# The doserate (amount/time) is therefore Dose/tau
# A bolus dose should be thought of as a short infusion

# The lsoda function is very fussy about names for variables
# C[1] = C, meaning the first dependent variable ; Cd1 is its derivative wrt time
# C[2] = A2, meaning the second dependent variable ; Cd2 is its derivative wrt time
# You can change C to another name, but must keep these conventions
# The output from Cprime (its last line) must be a list of the derivative of C wrt time

# You must install the "odesolve" package in R.  See the website for details.

# This example gave results similar (within 6 sig. fig.) to the same problem
# solved in an independent differential equation solving package.


#Load the odesolve package
require(odesolve)

#Specify parameters
times <- c(0:180)
tau  <- 4
Dose <- 30
V    <- 23.1
Cl   <- 1
k12  <- 0.197118
k21  <- 0.022665

#A quick check - compare these steady-state values with values after a long infusion
Css <- (Dose/tau)/Cl
A2ss <- V*Css*(k12/k21)

#lsoda requires the parameters as an object (p) with names
p <- c(V=V, Cl=Cl, k12=k12, k21=k21)


#Differential equations are declared in a function
Cprime <- function(t, C, p)
 
          {
          if (t < tau) Doserate <- (Dose/tau) else Doserate <- 0
          Cd1 <- (Doserate - C[1]*p["Cl"] + p["k21"]*C[2] - p["V"]*p["k12"]*C[1])/p["V"]
          Cd2 <- (p["V"]*p["k12"]*C[1] - p["k21"]*C[2])
          list(c(Cd1, Cd2))
          }
      
 
#Solve the system of differential equations, including initial values
result <- lsoda( c(0,0), times, Cprime, p)

#Reformat the result
result <- data.frame(result)
names(result) <- c("time","Conc", "Amount2")

#Have a look at the result
print(result)
plot(result$Conc ~ result$time, type="b", main="Central compartment", xlab="time", ylab="Conc")
plot(result$Amount2 ~ result$time, type="b", main="Second compartment", xlab = "time", ylab = "Amount")
--------------------------------------------------------------

Our group is also working on implementing a ODE solvers suite for R for small to medium size problems.

Thanks! for bringing this type of discussion to the R-news.

olinares at med.umich.edu

Oscar A. Linares, MD, PhD              ///////
Michigan Diabetes Institute S c I S O F T ///=20=03
Molecular Medicine Unit       ______////////=20=04
SciSoft Group                  \_\_\_\/////
Ann Arbor, MI                   \_\_\_\///
Tel. (734) 637-7997              \_\_\_\/
Fax. (734) 453-7019



From dbabinea at fe01.math.uwaterloo.ca  Fri Jan 23 01:33:19 2004
From: dbabinea at fe01.math.uwaterloo.ca (Denise)
Date: Thu, 22 Jan 2004 19:33:19 -0500 (EST)
Subject: [R] Turnbull estimate
Message-ID: <Pine.GSO.4.58.0401221926180.26227@fe01.math.uwaterloo.ca>

Hi everyone,

I've been looking for a function that calculates the Turnbull estimate
for left, right and interval censored data. None of the data that I am
using has exact failure times. The only function I seem to find can handle
data that has no left censoring. It seems that I will have to program
this myself. In your opinion, is it advisable to start with the
function, kaplanMeier, in Splus and try to get it compatible with R?
I'm not sure if this is possible but I'm willing to try.

Any advice would be greatly appreciated!

Thanks in advance!

Denise



From olinares at med.umich.edu  Fri Jan 23 01:36:54 2004
From: olinares at med.umich.edu (Oscar Linares)
Date: Thu, 22 Jan 2004 19:36:54 -0500
Subject: [R] cmptl_analy.R
Message-ID: <s010266d.057@med-gwia-02a.med.umich.edu>

Dear Michael,

One key is adjustment of nls optimizer tolerance. I notice it has to be
higher than usual, but, I recovered your noisy "known" parameter values
with an error of K1 (-7%) and k1 (-6%):

#### Miller problem with Dalgaard modifications
##   Linares 1/22/2004

## Solution 1
nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1=K1,
k2=k2))[,2],
          data=C1.lsoda,
          start=list(K1=0.3, k2=0.7),
          control=nls.control(maxiter=50,tol=1),
          trace=T
          )
          
0.3594355 :  0.3 0.7 
0.006118908 :  0.3456684 0.3518834 
0.002828044 :  0.4057868 0.4081200 
Nonlinear regression model
  model:  noisy ~ lsoda(xstart, time, one.compartment.model, c(K1 = K1, 
    k2 = k2))[, 2] 
   data:  C1.lsoda 
       K1        k2 
0.4057868 0.4081200
(-19%)    (-18%)   
 residual sum-of-squares:  0.002828044

## Solution 2 (lower nls optimizer tolerance)
nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1=K1,
k2=k2))[,2],
          data=C1.lsoda,
          start=list(K1=0.3, k2=0.7),
          control=nls.control(maxiter=50,tol=0.01),
          trace=T
          )
> nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1=K1,
k2=k2))[,2],
+           data=C1.lsoda,
+           start=list(K1=0.3, k2=0.7),
+           control=nls.control(maxiter=50,tol=0.01),
+           trace=T
+           )
0.3594355 :  0.3 0.7 
0.006118908 :  0.3456684 0.3518834 
0.002828044 :  0.4057868 0.4081200 
0.002775223 :  0.4092802 0.4104112 
0.002729966 :  0.4085296 0.4114600 
0.001975772 :  0.4628794 0.4688428 
0.001973953 :  0.4628974 0.4682051 
0.001973698 :  0.4631627 0.4686185 
0.001973422 :  0.4673921 0.4729379 
0.001973413 :  0.4673957 0.4729418 
Error in nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1 =
K1,  : 
        step factor 0.000488281 reduced below `minFactor' of 0.000976563

#### Solution 3 (increase nls optimizer tolerance a notch)
nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1=K1,
k2=k2))[,2],
          data=C1.lsoda,
          start=list(K1=0.3, k2=0.7),
          control=nls.control(maxiter=50,tol=0.1),
          trace=T
          )
> nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1=K1,
k2=k2))[,2],
+           data=C1.lsoda,
+           start=list(K1=0.3, k2=0.7),
+           control=nls.control(maxiter=50,tol=0.1),
+           trace=T
+           )
0.3594355 :  0.3 0.7 
0.006118908 :  0.3456684 0.3518834 
0.002828044 :  0.4057868 0.4081200 
0.002775223 :  0.4092802 0.4104112 
0.002729966 :  0.4085296 0.4114600 
0.001975772 :  0.4628794 0.4688428 
0.001973953 :  0.4628974 0.4682051 
Nonlinear regression model
  model:  noisy ~ lsoda(xstart, time, one.compartment.model, c(K1 = K1, 
    k2 = k2))[, 2] 
   data:  C1.lsoda 
       K1        k2 
0.4628974 0.4682051 
(-7%)     (-6%)
 residual sum-of-squares:  0.001973953 

> errK1=(0.4628974-0.5)/0.5
> errK1
[1] -0.0742052
> errk1=(0.4682051-0.5)/0.5
> errk1
[1] -0.0635898

Oscar
Oscar A. Linares, MD, PhD
Prof. Experimental Medicine
Michigan Diabetes Institute 
olinares at med.umich.edu

Oscar A. Linares, MD, PhD              ///////
Michigan Diabetes Institute S c I S O F T ///=20=03
Molecular Medicine Unit       ______////////=20=04
SciSoft Working Group          \_\_\_\/////
Ann Arbor, MI                   \_\_\_\///
Tel. (734) 637-7997              \_\_\_\/
Fax. (734) 453-7019
***************************************************************************
IMPORTANT CONFIDENTIALITY NOTICE: The documents and/or accom...{{dropped}}



From hodgess at gator.uhd.edu  Fri Jan 23 02:21:42 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Thu, 22 Jan 2004 19:21:42 -0600
Subject: [R] confidence intervals
Message-ID: <200401230121.i0N1Lgt10132@gator.dt.uh.edu>

Hi Yun Fan!

Have you looked at "predict.lm"?

It can give you confidence and prediction intervals.

Hope this helps!

Sincerely,
Erin Hodgess
mailto: hodgess at gator.uhd.edu



From Meredith.Briggs at team.telstra.com  Fri Jan 23 02:05:22 2004
From: Meredith.Briggs at team.telstra.com (Briggs, Meredith M)
Date: Fri, 23 Jan 2004 12:05:22 +1100
Subject: [R] BVLS
Message-ID: <3B5823541A25D311B3B90008C7F9056410E35270@ntmsg0092.corpmail.telstra.com.au>


Hi

Is there an R package that solves linear least squares with upper and lower bounds on the variables. Something like the Parker and Stark algorithm written in Fortran.

thanks



From tlumley at u.washington.edu  Fri Jan 23 02:17:31 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 22 Jan 2004 17:17:31 -0800 (PST)
Subject: [R] Bug in termplot?
In-Reply-To: <JPEJIEHCLCCMMBFGMPDGMELICGAA.Simon.Wotherspoon@utas.edu.au>
References: <JPEJIEHCLCCMMBFGMPDGMELICGAA.Simon.Wotherspoon@utas.edu.au>
Message-ID: <Pine.A41.4.58.0401221716160.12616@homer33.u.washington.edu>

On Thu, 22 Jan 2004, Simon Wotherspoon wrote:

> Hi,
> 	Is this a bug in termplot, or (once again) do I just not
> understand what R is really doing?

Yes, it's a bug.  The lower right plot has the partial residuals for x1
not for x2. The fitted line is correct.

	-thomas

>
> I am using termplot to contruct partial residual plots,
>   1. For all terms at once
>   2. One term at a time
> but I get different results from these two methods.  To give a concrete
> example, I would have thought the top and bottom rows of the plot
> constructed with the following code would be identical.
>
> Grateful for any clues
>
> Simon.
>
>
>
> ## Term plot example
>
> n <- 50
> x1 <- 2*runif(n)
> x2 <- 2*runif(n)
> y <- x1+sin(x2)+0.1*rnorm(n)
>
> fit <- lm(y ~ x1 +x2)
> par(mfrow=c(2,2))
> termplot(fit,partial=T)
> termplot(fit,terms="x1",partial=T)
> termplot(fit,terms="x2",partial=T)
>
>
>
> --please do not edit the information below--
>
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status =
>  major = 1
>  minor = 8.1
>  year = 2003
>  month = 11
>  day = 21
>  language = R
>
> Windows ME 4.90 (build 3000)
>
> Search Path:
>  .GlobalEnv, package:methods, package:ctest, package:mva, package:modreg,
> package:nls, package:ts, Autoloads, package:base
> ---
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From r-eugenesalinas at comcast.net  Fri Jan 23 05:54:19 2004
From: r-eugenesalinas at comcast.net (Eugene Salinas (R))
Date: Thu, 22 Jan 2004 23:54:19 -0500
Subject: [R] how to take derivatives of a step function
Message-ID: <4010A8FB.7010808@comcast.net>

Hi,

I have estimated a step function and need to take the derivatives of 
this function at all points in the range. Does anyone know of any clever 
ways to do this?

(I have already tried to fit a polynomial through the points in order to 
obtain a smooth representation and then take derivatives of this. Also 
tried to smooth it, and used an SG differentiator. Results are rather 
poor so far, in the sense that you can see from the graph that the 
derivative function is a straight line but I am getting pretty wavy 
things back.)

thanks for any advice, eugene.



From Bill.Venables at csiro.au  Fri Jan 23 07:09:53 2004
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Fri, 23 Jan 2004 16:09:53 +1000
Subject: [R] how to take derivatives of a step function
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A92767C9@roper-cv.qld.cmis.csiro.au>

It might be helpful to know just why you want to do this.  Just because one
function is a smooth approximation to another doesn't imply anything about
the derivatives approximating each other, (well, not much).

The GENERALIZED derivative of a step function can be written down explicitly
as the weighted sum of dirac delta functions - in other words it's zero
'almost everywhere' but goes crazy at the steps.

Bill Venables.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Eugene Salinas (R)
Sent: Friday, 23 January 2004 2:54 PM
To: r-help at stat.math.ethz.ch
Subject: [R] how to take derivatives of a step function


Hi,

I have estimated a step function and need to take the derivatives of 
this function at all points in the range. Does anyone know of any clever 
ways to do this?

(I have already tried to fit a polynomial through the points in order to 
obtain a smooth representation and then take derivatives of this. Also 
tried to smooth it, and used an SG differentiator. Results are rather 
poor so far, in the sense that you can see from the graph that the 
derivative function is a straight line but I am getting pretty wavy 
things back.)

thanks for any advice, eugene.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Fri Jan 23 08:19:48 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Jan 2004 07:19:48 +0000 (GMT)
Subject: [R] getting confidence intervals after lm fitting
In-Reply-To: <019d01c3e140$13bdd3b0$983991d8@jungdm>
Message-ID: <Pine.LNX.4.44.0401230715540.24629-100000@gannet.stats>

On Thu, 22 Jan 2004, Yun-Fang Juan wrote:

> After fitting with lm, I want to get the 95 % confidence intervals of  the
> expected predicted value.

Of the predicted expected value, I assume?

> I know in S-plus I can use pointwise() to get the confidence intervals .
> But in R, I couldn't find such a function.
> Is there any R package available for such functionalities.

No, but predict() in R does this for you.  See ?predict.lm .


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan 23 08:26:33 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Jan 2004 07:26:33 +0000 (GMT)
Subject: [R] BVLS
In-Reply-To: <3B5823541A25D311B3B90008C7F9056410E35270@ntmsg0092.corpmail.telstra.com.au>
Message-ID: <Pine.LNX.4.44.0401230720560.24629-100000@gannet.stats>

On Fri, 23 Jan 2004, Briggs, Meredith M wrote:

> Is there an R package that solves linear least squares with upper and
> lower bounds on the variables. Something like the Parker and Stark
> algorithm written in Fortran.

Probably not, but this is an easy application of optim(method="L-BFGS")
or of solve.QP() in package quadprog.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ahenningsen at agric-econ.uni-kiel.de  Fri Jan 23 10:58:03 2004
From: ahenningsen at agric-econ.uni-kiel.de (Arne Henningsen)
Date: Fri, 23 Jan 2004 10:58:03 +0100
Subject: [R] Syntay-Highlighting  for KDE-Kate
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7644@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7644@usrymx25.merck.com>
Message-ID: <200401231058.03056.ahenningsen@agric-econ.uni-kiel.de>

Hi, 

I am the new maintainer of the R syntax highlighting plugin for kate. (The 
initial author, Egon, stopped maintaining it, because he does not use kate 
anymore.)

@ Andy: Thanks for providing the link to this file. (I was very busy this week 
and did not look at the R mailing list until today)

@ Lars: Where is the dead link on www.r-project.org?

@  Philippe: Can you please mention the R syntax highlighting file for kate 
(KDE advanced text editor) on
   http://www.sciviews.org/_rgui/projects/Editors.html
including a link to the file
   http://www.uni-kiel.de/agrarpol/ahenningsen/app-econ/R.xml

@ all: Are there other locations where this should be mentioned?

Have a nice weekend,
Arne


On Monday 19 January 2004 02:13, Liaw, Andy wrote:
> I don't use Kate, but is this what you're looking for?
>
> http://www.uni-kiel.de/agrarpol/ahenningsen/app-econ/R.xml
>
> (Found just by googling around...)
>
> Andy
>
> > From: Aleksey Naumov
> >
> > Lars,
> >
> > I don't know of an R syntax plugin for Kate, instead I just use Python
> > highlighting for my R scripts in Kate, and it works quite well. If you
> > find an R plugin, I would appreciate a note...
> >
> > Thanks
> > Aleksey
> >
> > On Sun, 18 Jan 2004, Lars Peters wrote:
> > > I'm looking for a plugin for Kate (or any other good text
> >
> > editor for linux)
> >
> > > (KDE 3.x) which will highlight the R syntax.
> > >
> > > The link on www.r-project.org is dead!
> > >
> > > Any ideas??
> > >
> > > Thanks Lars
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> >
> > http://www.R-project.org/posting-guide.html
> >
> >
> >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
>
> ---------------------------------------------------------------------------
>--- Notice:  This e-mail message, together with any
> attachments,...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From plummer at iarc.fr  Fri Jan 23 11:07:20 2004
From: plummer at iarc.fr (Martyn Plummer)
Date: Fri, 23 Jan 2004 11:07:20 +0100
Subject: [R] Turnbull estimate
In-Reply-To: <Pine.GSO.4.58.0401221926180.26227@fe01.math.uwaterloo.ca>
References: <Pine.GSO.4.58.0401221926180.26227@fe01.math.uwaterloo.ca>
Message-ID: <1074852440.3299.13.camel@xena.iarc.fr>

On Fri, 2004-01-23 at 01:33, Denise wrote:
> Hi everyone,
> 
> I've been looking for a function that calculates the Turnbull estimate
> for left, right and interval censored data. None of the data that I am
> using has exact failure times. The only function I seem to find can handle
> data that has no left censoring. It seems that I will have to program
> this myself. In your opinion, is it advisable to start with the
> function, kaplanMeier, in Splus and try to get it compatible with R?
> I'm not sure if this is possible but I'm willing to try.
> 
> Any advice would be greatly appreciated!

A couple of years ago, I wrote some functions for analyzing interval
censored survival data. I put them in a package for convenience, but
they are by no means user friendly. I put a copy for you on

http://www-fis.iarc.fr/~martyn/software/interval/

Your mileage may vary. Quite possibly down to zero. 

Here is an example that plots the non-parametric maximum likelihood
estimate of the survival curve for the famous cosmesis data

package(interval)
data(cosmesis)
attach(cosmesis)
plot.surv(start, end, treat)

I hope this helps. Tidying it up and using the interface provided by
Terry Therneau's survival package are on my TODO list, but a long way
down.

Martyn



From Jesus.Frias at dit.ie  Fri Jan 23 12:29:07 2004
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Fri, 23 Jan 2004 11:29:07 +0000
Subject: [R] Fitting compartmental model with nls and lsoda?
In-Reply-To: <0E27DEC3.3CA874F1.0B088159@aol.com>
Message-ID: <LGECJJCANFBOOHCMGPJEIEPPCOAA.Jesus.Frias@dit.ie>


> Now, I am including Richar Upton's 2 cm model implementation and
> Christoffer Tornoe's nls solution (I recommend Christoffer's
> nlmeODE package for these problems also if multi-response data is
> available) The code follows:

Multi-response data?, Is there a way of dealing with those multiresponse
nonlinear regression problems in R (a la Chapter 4 of Bates and Watts, if
possible)?, the only alternative I heard of was in a mail from Douglas
Bates, using optim() and the definition of the Box-Drapper criterion,

 prod(svd(y-f(p1,p2,p3), nu=0, nv=0)$d)^2

if you wish to minimize a matrix of y's in respect to p1,p2 and p3.


best regards,

Jesus

--------------------------------------------------------------
Jes?s Mar?a Fr?as Celayeta
School of Food Sci. and Env. Health.
Faculty of Tourism and Food
Dublin Institute of Technology
Cathal Brugha St., Dublin 1. Ireland
Phone: +353 1 4024459 Fax: +353 1 4024495
http://www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------


-- 
This message has been scanned for content and 
viruses by the DIT Information Services MailScanner 
Service, and is believed to be clean.
http://www.dit.ie



From kamoun_wassim at yahoo.fr  Fri Jan 23 12:54:18 2004
From: kamoun_wassim at yahoo.fr (=?iso-8859-1?q?Wassim=20Kamoum?=)
Date: Fri, 23 Jan 2004 12:54:18 +0100 (CET)
Subject: [R] Question 
Message-ID: <20040123115418.16264.qmail@web41312.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040123/40c717e0/attachment.pl

From tam_a_ra at hotmail.com  Fri Jan 23 13:08:31 2004
From: tam_a_ra at hotmail.com (Tamara Porter)
Date: Fri, 23 Jan 2004 12:08:31 +0000
Subject: [R] (no subject)
Message-ID: <BAY99-F102H67yRLVbN0000bb7f@hotmail.com>


   I downloaded R onto my computer using Windows XP
   The program itself works fine, but my problem occurs when I type
   help.start() and enter the search engine.  Whenever I type anything
   into
   it, nothing happens.  I've tried reinstalling it a few times, but the
   same
   thing keeps happening.  I've done the full installation, with all the
   boxes
   checked.

   Thanks for your help


From mikewhite.diu at tiscali.co.uk  Fri Jan 23 13:23:27 2004
From: mikewhite.diu at tiscali.co.uk (Mike White)
Date: Fri, 23 Jan 2004 12:23:27 -0000
Subject: [R] predict.lda problem with posterior probabilities
Message-ID: <001201c3e1ab$b51efcf0$0e5de150@FSSFQCV7BGDVED>

With predict.lda the posterior probabilities only relate to the existing
Class definitions.  This is fine for Class definitions like gender but it is
a problem when new data does not necessarily belong to an existing Class.
Is there a classification method that gives posterior probabilities for
Class membership and does not assume the new data must belong to one of the
existing Classes?  A new class would then be indicated by low posterior
probabilities for all the existing Classes.

Thanks
Mike White



From feldesmanm at pdx.edu  Fri Jan 23 14:49:52 2004
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Fri, 23 Jan 2004 05:49:52 -0800
Subject: [R] predict.lda problem with posterior probabilities
In-Reply-To: <001201c3e1ab$b51efcf0$0e5de150@FSSFQCV7BGDVED>
References: <001201c3e1ab$b51efcf0$0e5de150@FSSFQCV7BGDVED>
Message-ID: <6.0.1.1.2.20040123054215.02ebcb08@pop4.attglobal.net>

At 04:23 AM 1/23/2004, Mike White wrote:
 >With predict.lda the posterior probabilities only relate to the existing
 >Class definitions.  This is fine for Class definitions like gender but it is
 >a problem when new data does not necessarily belong to an existing Class.
 >Is there a classification method that gives posterior probabilities for
 >Class membership and does not assume the new data must belong to one of the
 >existing Classes?  A new class would then be indicated by low posterior
 >probabilities for all the existing Classes.


For discriminant analysis, one of of doing this would be to use "typicality 
probabilities", sometimes called "inverse probabilities".  This is 
discussed in Huberty's Applied Discriminant Analysis, Wiley 1994 (and other 
sources), and is used relatively commonly in the paleoanthropological 
literature where researchers try to "classify" a fossil into a matrix of 
modern forms to which it is already known that the fossil does not 
belong.  The question is whether the fossil has a modern analog or whether 
it really is dissimilar from any modern form.



From l.houdusse at cerep.fr  Fri Jan 23 15:24:21 2004
From: l.houdusse at cerep.fr (Laurent Houdusse)
Date: Fri, 23 Jan 2004 15:24:21 +0100
Subject: [R] Levels number of a factor object
Message-ID: <BA420EFAAC96D311A7A0006097D37BDB045159FA@EOLE>


Hi all!

    How to retrieve the levels number of a factor object?
    See this code:
    groups<-gl(4,10)
    I want to retrieve the number of levels (4) of my object "groups"
    I tried groups.levels but this don't work

    Thanks


Laurent Houdusse 
Analyste Programmeur



From kamoun_wassim at yahoo.fr  Fri Jan 23 15:24:42 2004
From: kamoun_wassim at yahoo.fr (=?iso-8859-1?q?Wassim=20Kamoum?=)
Date: Fri, 23 Jan 2004 15:24:42 +0100 (CET)
Subject: [R] question
Message-ID: <20040123142442.6134.qmail@web41308.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040123/d5ceb1cb/attachment.pl

From MSchwartz at medanalytics.com  Fri Jan 23 15:33:23 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 23 Jan 2004 08:33:23 -0600
Subject: [R] Levels number of a factor object
In-Reply-To: <BA420EFAAC96D311A7A0006097D37BDB045159FA@EOLE>
References: <BA420EFAAC96D311A7A0006097D37BDB045159FA@EOLE>
Message-ID: <1074868403.5657.26.camel@localhost.localdomain>

On Fri, 2004-01-23 at 08:24, Laurent Houdusse wrote:
> Hi all!
> 
>     How to retrieve the levels number of a factor object?
>     See this code:
>     groups<-gl(4,10)
>     I want to retrieve the number of levels (4) of my object "groups"
>     I tried groups.levels but this don't work
> 
>     Thanks
> 
> 
> Laurent Houdusse 
> Analyste Programmeur


Use nlevels() for the number of levels and levels() to get the actual
level values:

> groups <- gl(4, 10)
> groups
 [1] 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4
[35] 4 4 4 4 4 4
Levels: 1 2 3 4

> nlevels(groups)
[1] 4

> levels(groups)
[1] "1" "2" "3" "4"

See ?nlevels and ?levels for more information.

HTH,

Marc Schwartz



From ivo.welch at yale.edu  Fri Jan 23 15:37:07 2004
From: ivo.welch at yale.edu (ivo welch)
Date: Fri, 23 Jan 2004 09:37:07 -0500
Subject: [R] Axes Ticks
Message-ID: <40113193.6060102@yale.edu>


thanks to everyone for their help.  easy now.  best regards, /iaw



From Siegfried.Macho at unifr.ch  Sat Jan 24 00:41:45 2004
From: Siegfried.Macho at unifr.ch (Siegfried.Macho)
Date: Fri, 23 Jan 2004 15:41:45 -0800
Subject: [R] Problem with hasArg() using R-files
Message-ID: <5.1.0.14.0.20040123152758.027cccb0@MAIL.UNIFR.CH>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040123/0ebd82c3/attachment.pl

From tobias.verbeke at bivv.be  Fri Jan 23 15:42:43 2004
From: tobias.verbeke at bivv.be (tobias.verbeke@bivv.be)
Date: Fri, 23 Jan 2004 15:42:43 +0100
Subject: Betr.: [R] Levels number of a factor object
In-Reply-To: <BA420EFAAC96D311A7A0006097D37BDB045159FA@EOLE>
Message-ID: <OF8F557257.6F2F3F87-ONC1256E24.0050C7F5-C1256E24.0050CC55@BIVV.BE>





r-help-bounces at stat.math.ethz.ch wrote on 23/01/2004 15:24:21:

>
> Hi all!
>
>     How to retrieve the levels number of a factor object?
>     See this code:
>     groups<-gl(4,10)
>     I want to retrieve the number of levels (4) of my object "groups"
>     I tried groups.levels but this don't work

Is

length(levels(groups))


what you were looking for ?


HTH,

Tobias



From r-eugenesalinas at comcast.net  Fri Jan 23 15:43:08 2004
From: r-eugenesalinas at comcast.net (Eugene Salinas (R))
Date: Fri, 23 Jan 2004 09:43:08 -0500
Subject: [R] how to take derivatives of a step function
In-Reply-To: <E09E527B56BE2D438A3D6A246DDD27A92767C9@roper-cv.qld.cmis.csiro.au>
References: <E09E527B56BE2D438A3D6A246DDD27A92767C9@roper-cv.qld.cmis.csiro.au>
Message-ID: <401132FC.6030407@comcast.net>

Thanks. Here is some more info that may help:

I am estimating a transformation model H(Y)=Xb+e and have obtained (up 
to a location parameter) an estimated of H(T), call it H_est(T). (Its a 
new estimator I am trying out that works with unspecified functional 
forms etc). Now if the model is a proportional hazard model then the 
integrated hazard is given by exp(H_est(T)) and hence the estimated 
hazard is d/dt(exp(H_est(T))).

Thus, I need to figure out how to evaluate this last expression which is 
based on a step function.

thank a lot, matt.


Bill.Venables at csiro.au wrote:

>It might be helpful to know just why you want to do this.  Just because one
>function is a smooth approximation to another doesn't imply anything about
>the derivatives approximating each other, (well, not much).
>
>The GENERALIZED derivative of a step function can be written down explicitly
>as the weighted sum of dirac delta functions - in other words it's zero
>'almost everywhere' but goes crazy at the steps.
>
>Bill Venables.
>
>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Eugene Salinas (R)
>Sent: Friday, 23 January 2004 2:54 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] how to take derivatives of a step function
>
>
>Hi,
>
>I have estimated a step function and need to take the derivatives of 
>this function at all points in the range. Does anyone know of any clever 
>ways to do this?
>
>(I have already tried to fit a polynomial through the points in order to 
>obtain a smooth representation and then take derivatives of this. Also 
>tried to smooth it, and used an SG differentiator. Results are rather 
>poor so far, in the sense that you can see from the graph that the 
>derivative function is a straight line but I am getting pretty wavy 
>things back.)
>
>thanks for any advice, eugene.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>
>  
>



From spencer.graves at pdf.com  Fri Jan 23 15:49:35 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 23 Jan 2004 06:49:35 -0800
Subject: [R] Levels number of a factor object
In-Reply-To: <BA420EFAAC96D311A7A0006097D37BDB045159FA@EOLE>
References: <BA420EFAAC96D311A7A0006097D37BDB045159FA@EOLE>
Message-ID: <4011347F.7050209@pdf.com>

 > groups<-gl(4,10)
 > levels(groups)
[1] "1" "2" "3" "4"
 > length(levels(groups))
[1] 4

      Is this what you want? 
      spencer graves

Laurent Houdusse wrote:

>Hi all!
>
>    How to retrieve the levels number of a factor object?
>    See this code:
>    groups<-gl(4,10)
>    I want to retrieve the number of levels (4) of my object "groups"
>    I tried groups.levels but this don't work
>
>    Thanks
>
>
>Laurent Houdusse 
>Analyste Programmeur
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From p.dalgaard at biostat.ku.dk  Fri Jan 23 15:50:08 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Jan 2004 15:50:08 +0100
Subject: [R] Levels number of a factor object
In-Reply-To: <BA420EFAAC96D311A7A0006097D37BDB045159FA@EOLE>
References: <BA420EFAAC96D311A7A0006097D37BDB045159FA@EOLE>
Message-ID: <x2isj2bty7.fsf@biostat.ku.dk>

Laurent Houdusse <l.houdusse at cerep.fr> writes:

> Hi all!
> 
>     How to retrieve the levels number of a factor object?
>     See this code:
>     groups<-gl(4,10)
>     I want to retrieve the number of levels (4) of my object "groups"
>     I tried groups.levels but this don't work
> 
>     Thanks

Do you mean just

length(levels(groups))

?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From thpe at hhbio.wasser.tu-dresden.de  Fri Jan 23 16:05:34 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 23 Jan 2004 16:05:34 +0100
Subject: [R] Levels number of a factor object
In-Reply-To: <BA420EFAAC96D311A7A0006097D37BDB045159FA@EOLE>
References: <BA420EFAAC96D311A7A0006097D37BDB045159FA@EOLE>
Message-ID: <4011383E.4070004@hhbio.wasser.tu-dresden.de>

Laurent Houdusse schrieb:

> Hi all!
> 
>     How to retrieve the levels number of a factor object?
>     See this code:
>     groups<-gl(4,10)
>     I want to retrieve the number of levels (4) of my object "groups"
>     I tried groups.levels but this don't work

Simply try:

length(levels(groups))

Thomas P.



From lxiaolei at cs.wisc.edu  Fri Jan 23 16:08:53 2004
From: lxiaolei at cs.wisc.edu (Li Xiaolei)
Date: Fri, 23 Jan 2004 09:08:53 -0600 (CST)
Subject: [R] Response Surface
Message-ID: <Pine.LNX.4.58.0401230906070.20290@gstat305.stat.wisc.edu>


Hi,

Is there any existing way in R of doing response surface analyses and
plotting the response surface, like what minitab can do?

Thanks

Xiaolei



From p.dalgaard at biostat.ku.dk  Fri Jan 23 16:09:08 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Jan 2004 16:09:08 +0100
Subject: [R] question
In-Reply-To: <20040123142442.6134.qmail@web41308.mail.yahoo.com>
References: <20040123142442.6134.qmail@web41308.mail.yahoo.com>
Message-ID: <x2ektqbt2j.fsf@biostat.ku.dk>

Wassim Kamoum <kamoun_wassim at yahoo.fr> writes:

> Hello
>  
> I was looking for the source code for the new arima procedure the STARMA model (Space-Time ARMA) 
>  
> If somebody have the source code of this model please send me them 
>  
> I'm student and in my research for my master I'm appling the STARMA model for modelling the pollutant particules.
> It's very important 
> Thank you.

R is Open Source software. All source code is available. In this
case the code is part of the R sources which you can get at

http://cran.r-project.org/src/base/R-1.8.1.tgz

or if you just need to look at a single file, use the viewcvs feature
as in

http://cvs.r-project.org/cgi-bin/viewcvs.cgi/R/src/library/stats/src/starma.c
 
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Fri Jan 23 16:07:25 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Jan 2004 15:07:25 +0000 (GMT)
Subject: [R] (no subject): really about search in HTML help under Windows
In-Reply-To: <BAY99-F102H67yRLVbN0000bb7f@hotmail.com>
Message-ID: <Pine.LNX.4.44.0401231504590.28237-100000@gannet.stats>

See the rw-FAQ, which explains this (as you have already been told 
privately).

The problem is in your browser configuration, not in R.  You need Java and 
Javascript installed and enabled.

On Fri, 23 Jan 2004, Tamara Porter wrote:

> 
>    I downloaded R onto my computer using Windows XP
>    The program itself works fine, but my problem occurs when I type
>    help.start() and enter the search engine.  Whenever I type anything
>    into
>    it, nothing happens.  I've tried reinstalling it a few times, but the
>    same
>    thing keeps happening.  I've done the full installation, with all the
>    boxes
>    checked.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kamoun_wassim at yahoo.fr  Fri Jan 23 16:11:32 2004
From: kamoun_wassim at yahoo.fr (=?iso-8859-1?q?Wassim=20Kamoum?=)
Date: Fri, 23 Jan 2004 16:11:32 +0100 (CET)
Subject: [R] STARMA model (Space-Time ARMA) 
Message-ID: <20040123151132.8011.qmail@web41309.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040123/df3c1c1c/attachment.pl

From p.dalgaard at biostat.ku.dk  Fri Jan 23 16:27:59 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Jan 2004 16:27:59 +0100
Subject: [R] how to take derivatives of a step function
In-Reply-To: <401132FC.6030407@comcast.net>
References: <E09E527B56BE2D438A3D6A246DDD27A92767C9@roper-cv.qld.cmis.csiro.au>
	<401132FC.6030407@comcast.net>
Message-ID: <x2ad4ebs74.fsf@biostat.ku.dk>

"Eugene Salinas (R)" <r-eugenesalinas at comcast.net> writes:

> Thanks. Here is some more info that may help:
> 
> I am estimating a transformation model H(Y)=Xb+e and have obtained (up
> to a location parameter) an estimated of H(T), call it H_est(T). (Its
> a new estimator I am trying out that works with unspecified functional
> forms etc). Now if the model is a proportional hazard model then the
> integrated hazard is given by exp(H_est(T)) and hence the estimated
> hazard is d/dt(exp(H_est(T))).
> 
> Thus, I need to figure out how to evaluate this last expression which
> is based on a step function.

Kernel smoothing. Look in e.g. Andersen,Borgan,Gill,Keiding:
Statistical Models Based on Counting Processes (1992, Springer), p.
230++ 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Roger.Bivand at nhh.no  Fri Jan 23 16:57:45 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 Jan 2004 16:57:45 +0100 (CET)
Subject: [R] question - STARMA model (Space-Time ARMA)
In-Reply-To: <x2ektqbt2j.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0401231648020.16952-100000@reclus.nhh.no>

On 23 Jan 2004, Peter Dalgaard wrote:

> Wassim Kamoum <kamoun_wassim at yahoo.fr> writes:
> 
> > Hello
> >  
> > I was looking for the source code for the new arima procedure the STARMA model (Space-Time ARMA) 
> >  
> > If somebody have the source code of this model please send me them 
> >  
> > I'm student and in my research for my master I'm appling the STARMA model for modelling the pollutant particules.
> > It's very important 
> > Thank you.
> 
> R is Open Source software. All source code is available. In this
> case the code is part of the R sources which you can get at
> 
> http://cran.r-project.org/src/base/R-1.8.1.tgz
> 
> or if you just need to look at a single file, use the viewcvs feature
> as in
> 
> http://cvs.r-project.org/cgi-bin/viewcvs.cgi/R/src/library/stats/src/starma.c
>  

Although looking at sources is necessary and usually helpful, I think the
"s" here is seasonal not spatial, unfortunately. I'm not aware of any
implementation of the Pfeiffer/Deutsch spatiotemporal ARMA in
Technometrics.

> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From jzhao at unity.ncsu.edu  Fri Jan 23 17:21:31 2004
From: jzhao at unity.ncsu.edu (Jieping)
Date: Fri, 23 Jan 2004 11:21:31 -0500
Subject: [R] correlation between two time serials
Message-ID: <DHENIKLIEHEFHIDGEABNIEADCBAA.jzhao@unity.ncsu.edu>

Hi, there,
   I'd like to get a statistics to reflect the correlation of two time
serials observations. for example, one time serials over time 1 to 20, and
another one from same time points from 1 to 20. I need one scalar satistics
as a correlation of these two observations.

Thank you and have a good weekend!

Jieping Zhao
PhD student in Bioinformatics, NCSU
Lab homepage: http://coltrane.gnets.ncsu.edu/index.html



From andy_liaw at merck.com  Fri Jan 23 17:18:49 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 23 Jan 2004 11:18:49 -0500
Subject: [R] Problem with hasArg() using R-files
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7686@usrymx25.merck.com>

Please do give reproducible example.  The code you gave, which you claimed
`works correctly' doesn't:

> SDT.Optim <- function(crit = NULL, Hess = F)
+                  {
+                   q <- length(par); x <- data
+                   if(hasArg(crit))
+                           cat("\n Crit present\n")
+                   else
+                           cat("\n Crit not present\n")
+                  }
> 
> Gauss.Obj <- SDT.Optim(Par0, Freq, crit, T)
Error in SDT.Optim(Par0, Freq, crit, T) : unused argument(s) ( ...)

The reason is that the function definition says SDT.Optim should only accept
two arguments, but is called with four.

Please also provide the error messages (if any), instead of just saying that
it doesn't `work'.  Whatever does that mean?

Andy

> From: Siegfried.Macho
> 
> Dear R-helpers,
> 
> I got the following problem with the function hasArg()
> 
> I would like to use the function to check whether the 
> argument "crit" is 
> present as an argument of the function (here is the 
> simplified version of 
> the function):
> 
> SDT.Optim <- function(crit = NULL, Hess = F)
>                  {
>                   q <- length(par); x <- data
>                   if(hasArg(crit))
>                           cat("\n Crit present\n")
>                   else
>                           cat("\n Crit not present\n")
>                  }
> 
> 
> if I call the function:
> 
> Gauss.Obj <- SDT.Optim(Par0, Freq, crit, T)
> 
> from the command device the function hasArg() works 
> correctly. However, if 
> I use the same call within a R-file, loaded via the function 
> source(), the 
> function hasArg() always retuns FALSE.
> 
> Q.1:  What is the reason of this behavior and how can I change it?
> Q.2:  Before using hasArg() I tried to test whether the value 
> of crit is 
> NULL using the function is.null(crit) This did not work 
> either (at least 
> with command files). Why not?
> Q.3: What is the best way to check whether crit was transferred as an 
> argument to the function (that works with R-files called via 
> source())?
> 
> Thank you in advance for your help,
> S.M.
> 
> 
> 
> 
> 
> ==============================================
> Dr. Siegfried Macho
> Department of Psychology
> University of Fribourg
> Rue de Faucigny 2
> CH-1700 Fribourg
> 
> Tel.: +41-26-3007635
> Fax.: +41-26-3009712
> http://www.unifr.ch/psycho/general/macho.htm
> ==============================================
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ivo.welch at yale.edu  Fri Jan 23 17:21:47 2004
From: ivo.welch at yale.edu (ivo welch)
Date: Fri, 23 Jan 2004 11:21:47 -0500
Subject: [R] graphical book suggestion
Message-ID: <40114A1B.2030409@yale.edu>


as I am playing around with parameters to graphics, it seems to me that 
there would be a market for a book written that is the equivalent of the 
perl cookbook, but for graphics creation in R/S.  just demonstrating how 
each parameter works, how one can make complex graphics, some graphics 
programming, etc.  lots of pictures.  would probably be fun to create, 
too...  just a suggestion...



From andrewr at uidaho.edu  Fri Jan 23 18:43:47 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Fri, 23 Jan 2004 09:43:47 -0800 (PST)
Subject: [R] Fast ARMA
Message-ID: <Pine.GSO.4.56.0401230939170.29290@hurricane.csrv.uidaho.edu>

Greetings R-friends,

I'm looking for some code to fit an ARMA, up to (3,3), preferably with ML.
I'm doing a simulation experiment, so I need to fit it to the order of
millions of times. I'm using Professor Ripley's arima() command right now,
but I hope to find soemthing faster in c. Does anyone know of any
inexpensive c library that performs this?

Andrew

Andrew Robinson			     Ph: 208 885 7115
Department of Forest Resources	     Fa: 208 885 6226
University of Idaho		     E : andrewr at uidaho.edu
PO Box 441133			     W : http://www.uidaho.edu/~andrewr
Moscow ID 83843			     Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From t.muhlhofer at lse.ac.uk  Fri Jan 23 18:58:19 2004
From: t.muhlhofer at lse.ac.uk (=?ISO-8859-1?Q?Tobias_M=FChlhofer?=)
Date: Fri, 23 Jan 2004 17:58:19 +0000
Subject: [R] lags in regressions
Message-ID: <401160BB.6040305@lse.ac.uk>

Hi!

I am trying to get R to run regressions for me of a variable on lagged 
differences of itself.

Specifically:

x-x(-1) = a + b1(x(-1)-rx(-2))+b2(x(-4)-rx(-5))+e

I need to do this a lot of times, altering the value of r.

What I've been trying to do was to use the lag() command to create 
lagged versions of these variables and then constructing these 
differences by hand (i.e. creating new variables containing these 
differences).

When I put all of those into the lm() command I get a singularity 
problem: it seems that R is unlagging the time series as it constructs 
the object matrix, instead of simply truncating away observations that 
don't exist for all the series due to the "pushing over" that is 
happening in the lagging.

What do I do? Do I need to truncate these by hand and if yes how? Or is 
there a different way?

Thanks,
	TM
-- 
**************************************************************************
When Thomas Edison invented the light bulb he tried over 2000 experiments
before he got it to work. A young reporter asked him how it felt to have
failed so many times. He said "I never failed once. I invented the light
bulb. It just happened to be a 2000-step process."



From ripley at stats.ox.ac.uk  Fri Jan 23 20:41:29 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Jan 2004 19:41:29 +0000 (GMT)
Subject: [R] lags in regressions
In-Reply-To: <401160BB.6040305@lse.ac.uk>
Message-ID: <Pine.LNX.4.44.0401231938530.1081-100000@gannet.stats>

You need to do tsunion (or something like it) on the time series.  lm()  
does not know about time series and you are merely supplying vectors as
far as it is concerned.

On Fri, 23 Jan 2004, Tobias M?hlhofer wrote:

> Hi!
> 
> I am trying to get R to run regressions for me of a variable on lagged 
> differences of itself.
> 
> Specifically:
> 
> x-x(-1) = a + b1(x(-1)-rx(-2))+b2(x(-4)-rx(-5))+e
> 
> I need to do this a lot of times, altering the value of r.
> 
> What I've been trying to do was to use the lag() command to create 
> lagged versions of these variables and then constructing these 
> differences by hand (i.e. creating new variables containing these 
> differences).
> 
> When I put all of those into the lm() command I get a singularity 
> problem: it seems that R is unlagging the time series as it constructs 
> the object matrix, instead of simply truncating away observations that 
> don't exist for all the series due to the "pushing over" that is 
> happening in the lagging.
> 
> What do I do? Do I need to truncate these by hand and if yes how? Or is 
> there a different way?
> 
> Thanks,
> 	TM
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From vicented.canto.ext at juntadeandalucia.es  Fri Jan 23 21:22:13 2004
From: vicented.canto.ext at juntadeandalucia.es (VICENTED.CANTO.EXT)
Date: Fri, 23 Jan 2004 21:22:13 +0100 (GMT+01:00)
Subject: [R] Re: matrix __power__ (was "exponential")
Message-ID: <19218891.1074889333075.JavaMail.oracle@jaen>


   Sorry I didn't answer before.

   Martin, thanks very much for your notes and for tidying the function
   up!
   About matPower, I didn't realise that where it says "pot <- pot %*% p   ot", consumption of memory was higer than it was on the original
   algorithm,
   And about the other function in this thread, matExp, I can remember I
   us   look to m
   >Message: 27
   >Date: Thu, 22 Jan 2004 18:22:27 +0100
   >   >Subject: [R   >To: Vicente Canto Casasol   >Cc: r-help at stat.mat   >Message-ID: <16400.1747.101241.439215 at gargle.gargle.HOW   >Content-Type: text/plain; charset=us-ascii
   >
   >&g   to.ext at juntadeandalucia.es>
   >>>>>>   &nbs   >
   > &nb   r
   >   Vicente> my poor English. It's for years I do   >
   >no problem at all.

   Well, that is because I'm not speaking!! ;)

   >
   >   Vicente> This is a R-version of a funct   >   Vicente> ago for my HP48 cal   >   Vicente> binar   >   Vicente   >
   >excellent. This is really    >I think.
   >
   >As I've menti   >computing a matrix "power" is really mu   >matrix exponential.

   I do agree. It did sound strange to me, but I followed the thread!

   >
   >Hence I wouldn't use exponential in the function name.
   &g   >co
   A C++ tic I have to correct!! Thank you, Martin.

   >
   >These slight modifications (+ initial "test")
   >give>
   >matPower <- function(X,n)
   >## Function to calculate    >{
   >   if(n != ro   >       n <- round(n)   >       warning("rounding exponen   >   }
   >   phi <-   >   pot <- X # the first po   >
    >  while (n > 0)
   >   >       if (n   >          &   >
   >     &nb   >       p   >   }
   >   return(   >}
   


From Kristian.Omland at uvm.edu  Fri Jan 23 22:14:32 2004
From: Kristian.Omland at uvm.edu (Kristian Omland)
Date: Fri, 23 Jan 2004 16:14:32 -0500
Subject: [R] Re: nonlinear regression and Excel solver
In-Reply-To: <40057BE5.2060600@uvm.edu>
References: <40057BE5.2060600@uvm.edu>
Message-ID: <40118EB8.9080804@uvm.edu>

Hi all,

Here is a summary of substantive replies to my posts (on both s-news and 
r-help) regarding use of Excel's Solver for a nonlinear regression problem.

A number of people replied that Solver performs well as an optimizer 
based on experience, particularly if given reasonable starting values. A 
number of other people replied that it performs poorly based on experience.

Whether or not it arrives at a bona fide solution, several people 
pointed out limitations to using Solver associated with lack of 
diagnostics and related statistical output. When using Solver, you 
cannot "trace the internals" of the solving process, and you cannot 
obtain the Hessian matrix or variance-covariance matrix.

One user stated that he sometimes uses Excel's Solver to analyze the 
same problem he has previously done in S+ or R; if it arrives at the 
same answer, he's happy.

I was also reminded of several general advantages of using a command 
line language (ease of debugging, portability to other problems or other 
users, etc.). Adding my own comment, that general issue applies to using 
Solver in that it is impossible (I think) to tell after the fact what 
options were selected for the optimization.

The consensus was that someone in my shoes would do well to learn S+/R, 
or AD Model Builder ... but then you're all proficient in S+/R already :-)

Thanks for your input,
Kristian
-- 
Kristian Omland
Postdoctoral Research Associate
Vermont Cooperative Fish & Wildlife Research Unit
Rubenstein School of Environment & Natural Resources
University of Vermont
Burlington VT 05405
voice: (802)656-2496 fax: (802)656-8683
web page: http://www.uvm.edu/~komland



From DivineSAAM at aol.com  Fri Jan 23 22:24:03 2004
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Fri, 23 Jan 2004 16:24:03 -0500
Subject: [R] Fitting compartmental model with nls and lsoda?
Message-ID: <4ABA3629.76FBC296.0B088159@aol.com>

Dear Jesus,

Yes there is a way and it is via Christoffer Torn\{o}e's package nlmeODE. I checked Chapter 4 of Bates and Watts. As usual, a little work involved, but doable and quite powerful.

Thanks,
olinares



From naumov at acsu.buffalo.edu  Sat Jan 24 01:45:21 2004
From: naumov at acsu.buffalo.edu (Aleksey Naumov)
Date: Fri, 23 Jan 2004 19:45:21 -0500
Subject: [R] "ylab" argument to plot.stepfun
Message-ID: <200401231945.21151.naumov@acsu.buffalo.edu>

Dear R Users,

Does anyone know how to specify Y-label in plot.stepfun()? I do:

> library(stepfun)
> x = ecdf(rnorm(30))
> plot(x, ylab='CDF')

and I get:

Error in plot.stepfun(ylab = "Fn(x)", ..., verticals = verticals) :
  formal argument "ylab" matched by multiple actual arguments

Thanks,
Aleksey

-- 
Aleksey Naumov
GIS Analyst
Center for Health and Social Research
Buffalo State College



From yunfang at yahoo-inc.com  Sat Jan 24 01:48:47 2004
From: yunfang at yahoo-inc.com (Yun-Fang Juan)
Date: Fri, 23 Jan 2004 16:48:47 -0800
Subject: [R] regression to get non-negative parameters
Message-ID: <016601c3e213$d3725f90$983991d8@jungdm>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040123/64c99482/attachment.pl

From dmurdoch at pair.com  Sat Jan 24 02:38:13 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 23 Jan 2004 20:38:13 -0500
Subject: [R] (no subject)
In-Reply-To: <BAY99-F102H67yRLVbN0000bb7f@hotmail.com>
References: <BAY99-F102H67yRLVbN0000bb7f@hotmail.com>
Message-ID: <ahi310502gd8i91oi5i9mmihfned6t4sb0@4ax.com>

On Fri, 23 Jan 2004 12:08:31 +0000, you wrote:

>
>   I downloaded R onto my computer using Windows XP
>   The program itself works fine, but my problem occurs when I type
>   help.start() and enter the search engine.  Whenever I type anything
>   into
>   it, nothing happens.  I've tried reinstalling it a few times, but the
>   same
>   thing keeps happening.  I've done the full installation, with all the
>   boxes
>   checked.

What browser are you using?  Have you modified the security settings?
The search engine uses Javascript; if you have disabled that, it won't
work.

Duncan Murdoch



From paul.boutros at utoronto.ca  Sat Jan 24 08:31:19 2004
From: paul.boutros at utoronto.ca (paul.boutros@utoronto.ca)
Date: Sat, 24 Jan 2004 02:31:19 -0500
Subject: [R] Re-Post: Combining Factors in model.matrix
Message-ID: <1074929479.40121f4790125@webmail.utoronto.ca>

Hello,

I didn't get any response on this before, leading me to believe I've missed 
something fundamental.  Can anybody guide me in the correct direction for more 
help on this?

Paul

=================================================
I want to be able to create a design matrix with two factors.  For instance, if 
I have:

> t1 <- factor(c(1,1,2,2));
> t2 <- factor(c(1,2,1,2));
> design <- model.matrix(~ -1 + (t1+t2));
> design;
  t11 t12 t22
1   1   0   0
2   1   0   1
3   0   1   0
4   0   1   1

But the design matrix I want is:
   t1 t2
1   1  0
2   1  1
3   0  0
4   0  1

Actually, in general I'm struggling with the syntax for formulating a design 
matrix I can write down on paper.  Is there a reference for this beyond the R 
documentation?

Thanks,
Paul



From forkusam at yahoo.com  Sat Jan 24 09:56:46 2004
From: forkusam at yahoo.com (forkusam)
Date: Sat, 24 Jan 2004 00:56:46 -0800 (PST)
Subject: [R] error message
In-Reply-To: <x2llo0bw7t.fsf@biostat.ku.dk>
Message-ID: <20040124085646.71716.qmail@web10510.mail.yahoo.com>


 I am trying to calculate n, using power.t.test

power.t.test(n=NULL,delta=delta, sd=sigmaEins,
sig.level= alpha, power=power, type=c("two.sample"),
alternative=c("two.sided"))

The values of the parameter are read in from a file.
 I have no idea what the error message means.

--- Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> forkusam <forkusam at yahoo.com> writes:
> 
> >  Hi,
> > Can someone please tell me what such an error
> message
> > could mean. i.e where a problem must have arised.
> > 
> > Error in uniroot(function(n) eval(p.body) - power,
> > c(2, 1e+07)) : 
> >         f() values at end points not of opposite
> sign
> 
> Looks like the innards of one of the power
> calculations, finding n to
> achieve a given power. You'd likely get an error
> like that if the
> power is not between 0 and 1, but how about telling
> us what you were
> trying to do?
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej
> 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N 
>  
>  (*) \(*) -- University of Copenhagen   Denmark     
> Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)            
> FAX: (+45) 35327907


=====
=====================
Sylvie B. Forkusam
Eppelheimer Str.52/A2-5-2
69115 Heidelberg, Germany
Tel: (0049)-06221/346913
Mobile: 0179-6816276



From christoffer.tornoe at ferring.com  Sat Jan 24 12:28:04 2004
From: christoffer.tornoe at ferring.com (christoffer.tornoe@ferring.com)
Date: Sat, 24 Jan 2004 12:28:04 +0100
Subject: [R] RE: Fitting compartmental model with nls and lsoda?
Message-ID: <924BFF6804049043980D90E6D47A4F210381FC77@fedk0014.ferringworld.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040124/e9468766/attachment.pl

From dmurdoch at pair.com  Sat Jan 24 12:46:53 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 24 Jan 2004 06:46:53 -0500
Subject: [R] Re-Post: Combining Factors in model.matrix
In-Reply-To: <1074929479.40121f4790125@webmail.utoronto.ca>
References: <1074929479.40121f4790125@webmail.utoronto.ca>
Message-ID: <r8m410p9uen6u2hnf55oqnrad5cq28cmps@4ax.com>

On Sat, 24 Jan 2004 02:31:19 -0500, you wrote:

>Hello,
>
>I didn't get any response on this before, leading me to believe I've missed 
>something fundamental.  Can anybody guide me in the correct direction for more 
>help on this?

I didn't see the earlier posting, but nothing seems to be wrong with
this one.

>I want to be able to create a design matrix with two factors.  For instance, if 
>I have:
>
>> t1 <- factor(c(1,1,2,2));
>> t2 <- factor(c(1,2,1,2));
>> design <- model.matrix(~ -1 + (t1+t2));
>> design;
>  t11 t12 t22
>1   1   0   0
>2   1   0   1
>3   0   1   0
>4   0   1   1
>
>But the design matrix I want is:
>   t1 t2
>1   1  0
>2   1  1
>3   0  0
>4   0  1

You seem to want something like 

> model.matrix(~ t1+t2 )[,-1]
  t12 t22
1   0   0
2   0   1
3   1   0
4   1   1

(i.e. leave the intercept in the model, but delete it from the
result).  This doesn't give the exact encoding you asked for; the
"contrasts" options might be able to fix this (see ?contr.poly, or
maybe ?contrasts, and experiment a bit.)
>
>Actually, in general I'm struggling with the syntax for formulating a design 
>matrix I can write down on paper.  Is there a reference for this beyond the R 
>documentation?

I don't know.

Duncan Murdoch



From patrick.giraudoux at univ-fcomte.fr  Sat Jan 24 13:36:29 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 24 Jan 2004 13:36:29 +0100
Subject: [R] loop variable passage and lists
Message-ID: <027101c3e276$bf233600$1ccb3351@PC728329681112>

I cannot understand why the following expression is accepted (and gives the expected result: to set column 3 and 4 of the first
element of list1 -a data.frame list- as first element of list2):

> list2[[1]]<-list1[[1]][3:4]

...while this one is not (to do the same iteratively from the first to the eleventh element of list1):

> for (i in 1:11){list2[[i]]<-list1[[i]][3:4]}
Error in "[.data.frame"(list1[[i]], 3:4) :
        undefined columns selected

It looks like if the loop variable "i" could not be passed into the loop.

Any hint?

Patrick Giraudoux



From ripley at stats.ox.ac.uk  Sat Jan 24 13:37:46 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 24 Jan 2004 12:37:46 +0000 (GMT)
Subject: [R] Re-Post: Combining Factors in model.matrix
In-Reply-To: <1074929479.40121f4790125@webmail.utoronto.ca>
Message-ID: <Pine.LNX.4.44.0401241230000.11089-100000@gannet.stats>

On Sat, 24 Jan 2004 paul.boutros at utoronto.ca wrote:

> I didn't get any response on this before, leading me to believe I've missed 
> something fundamental.  Can anybody guide me in the correct direction for more 
> help on this?

You will need to explain to us why the object you list is `the design 
matrix': have *you* a reference for that?  R is doing the conventional 
thing, and I at least have no idea where your example comes from.

You seem to have coded variables t1 and t2 the opposite ways (the
reference level is 2 for t1 and 1 for t2), and your model has the fit at
levels t1=2,t1=1 constrained to pass through the origin.  I don't think R
has a simple syntax for that (although you can fake anything), and I find
it hard to believe that is actually what you want.

> 
> Paul
> 
> =================================================
> I want to be able to create a design matrix with two factors.  For instance, if 
> I have:
> 
> > t1 <- factor(c(1,1,2,2));
> > t2 <- factor(c(1,2,1,2));
> > design <- model.matrix(~ -1 + (t1+t2));
> > design;
>   t11 t12 t22
> 1   1   0   0
> 2   1   0   1
> 3   0   1   0
> 4   0   1   1
> 
> But the design matrix I want is:
>    t1 t2
> 1   1  0
> 2   1  1
> 3   0  0
> 4   0  1
> 
> Actually, in general I'm struggling with the syntax for formulating a design 
> matrix I can write down on paper.  Is there a reference for this beyond the R 
> documentation?

Chapter 6 of MASS has the most complete exposition (by Bill Venables) that 
I know of, and the White Book (Chambers & Hastie, 1992) goes well beyind 
the R documentation (which uses it as the reference).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Jan 24 14:07:33 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 24 Jan 2004 13:07:33 +0000 (GMT)
Subject: [R] loop variable passage and lists
In-Reply-To: <027101c3e276$bf233600$1ccb3351@PC728329681112>
Message-ID: <Pine.LNX.4.44.0401241303090.11155-100000@gannet.stats>

On Sat, 24 Jan 2004, Patrick Giraudoux wrote:

> I cannot understand why the following expression is accepted (and gives the expected result: to set column 3 and 4 of the first
> element of list1 -a data.frame list- as first element of list2):
> 
> > list2[[1]]<-list1[[1]][3:4]
> 
> ...while this one is not (to do the same iteratively from the first to the eleventh element of list1):
> 
> > for (i in 1:11){list2[[i]]<-list1[[i]][3:4]}
> Error in "[.data.frame"(list1[[i]], 3:4) :
>         undefined columns selected
> 
> It looks like if the loop variable "i" could not be passed into the loop.
> 
> Any hint?

Note, it says `columns'.  Do all the data frames in your list have 4 
columns?  The message most likely means that one does not.

Hint as requested: using

options(error=dump.frames)
...
debugger()

allows you to debug your code for yourself much more easily than we can
try to debug it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Sat Jan 24 17:53:08 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 24 Jan 2004 17:53:08 +0100 (MET)
Subject: [R] error message
In-Reply-To: <20040124085646.71716.qmail@web10510.mail.yahoo.com>
Message-ID: <Pine.GSO.4.21.0401241750370.11826-100000@amadeus.statistik.uni-dortmund.de>



On Sat, 24 Jan 2004, forkusam wrote:

> 
>  I am trying to calculate n, using power.t.test
> 
> power.t.test(n=NULL,delta=delta, sd=sigmaEins,
> sig.level= alpha, power=power, type=c("two.sample"),
> alternative=c("two.sided"))
> 
> The values of the parameter are read in from a file.
>  I have no idea what the error message means.

Peter Dalgaard asked you to specify a *reproducible* example.
So, please specify some values for delta, sigmaEins, alpha, power.

Uwe Ligges

 
> --- Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> > forkusam <forkusam at yahoo.com> writes:
> > 
> > >  Hi,
> > > Can someone please tell me what such an error
> > message
> > > could mean. i.e where a problem must have arised.
> > > 
> > > Error in uniroot(function(n) eval(p.body) - power,
> > > c(2, 1e+07)) : 
> > >         f() values at end points not of opposite
> > sign
> > 
> > Looks like the innards of one of the power
> > calculations, finding n to
> > achieve a given power. You'd likely get an error
> > like that if the
> > power is not between 0 and 1, but how about telling
> > us what you were
> > trying to do?
> > 
> > -- 
> >    O__  ---- Peter Dalgaard             Blegdamsvej
> > 3  
> >   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N 
> >  
> >  (*) \(*) -- University of Copenhagen   Denmark     
> > Ph: (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)            
> > FAX: (+45) 35327907
> 
> 
> =====
> =====================
> Sylvie B. Forkusam
> Eppelheimer Str.52/A2-5-2
> 69115 Heidelberg, Germany
> Tel: (0049)-06221/346913
> Mobile: 0179-6816276
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Sat Jan 24 17:56:50 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 24 Jan 2004 17:56:50 +0100 (MET)
Subject: [R] "ylab" argument to plot.stepfun
In-Reply-To: <200401231945.21151.naumov@acsu.buffalo.edu>
Message-ID: <Pine.GSO.4.21.0401241755350.11826-100000@amadeus.statistik.uni-dortmund.de>



On Fri, 23 Jan 2004, Aleksey Naumov wrote:

> Dear R Users,
> 
> Does anyone know how to specify Y-label in plot.stepfun()? I do:
> 
> > library(stepfun)
> > x = ecdf(rnorm(30))
> > plot(x, ylab='CDF')
> 
> and I get:
> 
> Error in plot.stepfun(ylab = "Fn(x)", ..., verticals = verticals) :
>   formal argument "ylab" matched by multiple actual arguments

Well, get a recent version of R (R-1.8.1 is recent) and try again (it
works!).

Uwe Ligges

 
> Thanks,
> Aleksey
> 
>



From ligges at statistik.uni-dortmund.de  Sat Jan 24 18:17:37 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 24 Jan 2004 18:17:37 +0100 (MET)
Subject: [R] Interfacing with Java
In-Reply-To: <40104559.7000002@ntlworld.com>
Message-ID: <Pine.GSO.4.21.0401241815380.12072-100000@amadeus.statistik.uni-dortmund.de>



On Thu, 22 Jan 2004, Samuel Kemp wrote:

> Hi,
> 
> Is there a hack to get R talking with Java?
> 
> Is any one out there working on interfacing R with Java? If so can I be 
> of service???

See the package SJava from the Omegahat project, http://www.omegahat.org.

Uwe Ligges


> Cheers,
> 
> Sam.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From f.calboli at ucl.ac.uk  Sat Jan 24 19:47:24 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 24 Jan 2004 18:47:24 +0000
Subject: [R] logical comparison of two matrices
Message-ID: <1074970044.5629.16.camel@monkey>

Dear All,

how can I get a logical comparison between matrices (or vectors) in a if
statement?

Whenever I try I get the following:


> S<-rbind(c(.25,0,0),c(0,.2,0),c(0,0,.1))
> P<-rbind(c(.75,.15,.01),c(.2,.8,.09),c(.05,.05,.9))
>
>
> aa<-function(S,P){
+ if (S == P){
+ return("OK")
+ }
+ else {
+ return("No match")
+ }
+ }
>
>
> aa(S,P)
[1] "No match"
Warning message:
the condition has length > 1 and only the first element will be used in:
if (S == P) {

The warning clearly states that only the first element was used, and
this would not be good enough.

If comparing the whole matrices is not possible I could be happy just
comparing the two diagonals.

regards,

Federico Calboli



-- 



=================================

Federico C. F. Calboli

PLEASE NOTE NEW ADDRESS

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 251 208

f.calboli at ucl.ac.uk



From ripley at stats.ox.ac.uk  Sat Jan 24 19:14:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 24 Jan 2004 18:14:38 +0000 (GMT)
Subject: [R] logical comparison of two matrices
In-Reply-To: <1074970044.5629.16.camel@monkey>
Message-ID: <Pine.LNX.4.44.0401241811260.11641-100000@gannet.stats>

Use all() or any() to reduce your comparison to a single logical value.
In your case all(S == P) appears to be what you intended, although maybe 
not what you wanted (see the next para).

Also check out ?identical and the comments in ?"==" (which BTW contains 
the answer to your question).

On 24 Jan 2004, Federico Calboli wrote:

> Dear All,
> 
> how can I get a logical comparison between matrices (or vectors) in a if
> statement?
> 
> Whenever I try I get the following:
> 
> 
> > S<-rbind(c(.25,0,0),c(0,.2,0),c(0,0,.1))
> > P<-rbind(c(.75,.15,.01),c(.2,.8,.09),c(.05,.05,.9))
> >
> >
> > aa<-function(S,P){
> + if (S == P){
> + return("OK")
> + }
> + else {
> + return("No match")
> + }
> + }
> >
> >
> > aa(S,P)
> [1] "No match"
> Warning message:
> the condition has length > 1 and only the first element will be used in:
> if (S == P) {
> 
> The warning clearly states that only the first element was used, and
> this would not be good enough.
> 
> If comparing the whole matrices is not possible I could be happy just
> comparing the two diagonals.
> 
> regards,
> 
> Federico Calboli
> 
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From JeromeSwartz at woolworths.co.za  Sun Jan 25 03:39:07 2004
From: JeromeSwartz at woolworths.co.za (Jerome Swartz)
Date: Sun, 25 Jan 2004 04:39:07 +0200
Subject: [R] Error Loading r
Message-ID: <096A444A7DA9E44B85671A7109333F0E5DD283@EXCHANGE01.woolworths.co.za>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040125/3195cde2/attachment.pl

From wang at galton.uchicago.edu  Sun Jan 25 04:47:23 2004
From: wang at galton.uchicago.edu (Yong Wang)
Date: Sat, 24 Jan 2004 21:47:23 -0600 (CST)
Subject: [R] how to keep functions while remove all other commands
In-Reply-To: <200401111106.i0BB52kr019805@hypatia.math.ethz.ch>
References: <200401111106.i0BB52kr019805@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0401242143280.15008@galton.uchicago.edu>

Dear all:
a quick question:
I am used to apply  rm(list=()) regularly to remove all old codes in 
preventing them creeping in current analysis.however, with that 
application, functions I wrote are also removed. please let me know how to
keep the thing you want while remove those you don't.

thank you

best 
yong



From christianlederer at t-online.de  Sun Jan 25 05:44:23 2004
From: christianlederer at t-online.de (Christian Lederer)
Date: Sun, 25 Jan 2004 05:44:23 +0100
Subject: [R] package question
Message-ID: <401349A7.8040605@t-online.de>


Dear R-Gurus,

is it possible, to define variables, which are only
visible to functions belonging to a certain package?
(For a certain package i would like to have something
similar to static variables in C, which are only visible
to functions defined in the same source file.)

In the documentation (``Writing R Extensions") i found
nothing appropriate.

Christian :-)



From hodgess at gator.uhd.edu  Sun Jan 25 07:10:42 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Sun, 25 Jan 2004 00:10:42 -0600
Subject: [R] boot vs. bootstrap
Message-ID: <200401250610.i0P6AgO18239@gator.dt.uh.edu>

Dear R People:

There is a library boot and another one bootstrap.

When is it preferable to use one or the other, please?

In particular, I was wondering about the function boot in the boot
library and the function bootstrap in the bootstrap library.

Those are the main bootstrap functions.

R Version 1.8.1 for Windows.

Thank you for your help in advance!

Sincerely,
Erin Hodgess
mailto: hodgess at gator.uhd.edu



From ripley at stats.ox.ac.uk  Sun Jan 25 09:23:21 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 25 Jan 2004 08:23:21 +0000 (GMT)
Subject: [R] package question
In-Reply-To: <401349A7.8040605@t-online.de>
Message-ID: <Pine.LNX.4.44.0401250812320.25999-100000@gannet.stats>

Look more closely at the section on `Package name spaces'.

  R has a name space management system for packages. This system allows
  the package writer to specify which variables in the package should be
  exported to make them available to package users ....

Alternatively, you can manage this yourself by using lexical scope:
if you define variables and functions in a local() block (and make sure 
the functions are visible) the variables will be visible only to those 
functions.  There are examples of that in the source file 
src/library/base/R/zdynvars.R (and elsewhere).


On Sun, 25 Jan 2004, Christian Lederer wrote:

> is it possible, to define variables, which are only
> visible to functions belonging to a certain package?
> (For a certain package i would like to have something
> similar to static variables in C, which are only visible
> to functions defined in the same source file.)
> 
> In the documentation (``Writing R Extensions") i found
> nothing appropriate.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Jan 25 09:25:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 25 Jan 2004 08:25:38 +0000 (GMT)
Subject: [R] boot vs. bootstrap
In-Reply-To: <200401250610.i0P6AgO18239@gator.dt.uh.edu>
Message-ID: <Pine.LNX.4.44.0401250823321.25999-100000@gannet.stats>

Package bootstrap is orphaned, that is no longer maintained.

Package boot is much more comprehensive, and a recommended package.

That suggests to me that you always use boot: I do.


On Sun, 25 Jan 2004, Erin Hodgess wrote:

> There is a library boot and another one bootstrap.
> 
> When is it preferable to use one or the other, please?
> 
> In particular, I was wondering about the function boot in the boot
> library and the function bootstrap in the bootstrap library.
> 
> Those are the main bootstrap functions.
> 
> R Version 1.8.1 for Windows.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From hb at maths.lth.se  Sun Jan 25 10:21:21 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sun, 25 Jan 2004 10:21:21 +0100
Subject: [R] how to keep functions while remove all other commands
In-Reply-To: <Pine.LNX.4.58.0401242143280.15008@galton.uchicago.edu>
Message-ID: <001701c3e324$998e8d50$1c0040d5@maths.lth.se>

Hi, it's not clear what you asking for, but if you want to remove all
object except functions here's the shortest one-line solution that I
can think of

 rm(list=ls()[!sapply(ls(), FUN=exists, mode="function")])

Henrik Bengtsson
Lund University, Sweden

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yong Wang
> Sent: den 25 januari 2004 04:47
> To: r-help-request at stat.math.ethz.ch
> Cc: r-help at stat.math.ethz.ch
> Subject: [R] how to keep functions while remove all other commands
> 
> 
> Dear all:
> a quick question:
> I am used to apply  rm(list=()) regularly to remove all old codes in

> preventing them creeping in current analysis.however, with that 
> application, functions I wrote are also removed. please let 
> me know how to keep the thing you want while remove those you don't.
> 
> thank you
> 
> best 
> yong
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From chust at cict.fr  Sun Jan 25 14:59:07 2004
From: chust at cict.fr (Guillem Chust)
Date: Sun, 25 Jan 2004 14:59:07 +0100
Subject: [R] warning associated with Logistic Regression
Message-ID: <LNEAJDHFINNCHGIDAMNHCEHCCDAA.chust@cict.fr>

Hi All,

When I tried to do logistic regression (with high maximum number of
iterations) I got the following warning message

Warning message:
fitted probabilities numerically 0 or 1 occurred in: (if
(is.empty.model(mt)) glm.fit.null else glm.fit)(x = X, y = Y,

As I checked from the Archive R-Help mails, it seems that this happens when
the dataset exhibits complete separation. However, p-values tend to 1, and
residual deviance tends to 0. My questions then is:
-Is the converged model correct? or
-Can I limit the number of iterations in order to avoid this warning? If I
do so, I?ve checked that the model selected by step can diverge in some
cases (I use 10 different presence-absence datasets and 18 explanatory
variables), and when I validate the model with independent data, the new
model is slightly more powerful (in the most part of cases).

Thanks in advance,

Guillem Chust

------------------------------------------------------------------
Guillem Chust 				       chust at cict.fr

Laboratoire Evolution et Diversit? Biologique, UMR 5174 CNRS/UPS
UPS Toulouse III, batiment IVR3
118, route de Narbonne  - 31062 Toulouse Cedex 4, France
Tel 33 (0)5 61 55 67 58          Fax 33 (0)5 61 55 73 27
http://www.edb.ups-tlse.fr/



From d.firth at warwick.ac.uk  Sun Jan 25 18:02:57 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Sun, 25 Jan 2004 17:02:57 +0000
Subject: [R] warning associated with Logistic Regression
In-Reply-To: <LNEAJDHFINNCHGIDAMNHCEHCCDAA.chust@cict.fr>
Message-ID: <530CB542-4F58-11D8-99AA-0050E4C03977@warwick.ac.uk>

On Sunday, Jan 25, 2004, at 13:59 Europe/London, Guillem Chust wrote:

> Hi All,
>
> When I tried to do logistic regression (with high maximum number of
> iterations) I got the following warning message
>
> Warning message:
> fitted probabilities numerically 0 or 1 occurred in: (if
> (is.empty.model(mt)) glm.fit.null else glm.fit)(x = X, y = Y,
>
> As I checked from the Archive R-Help mails, it seems that this happens 
> when
> the dataset exhibits complete separation.

Yes.  correct.

> However, p-values tend to 1

The reported p-values cannot be trusted: the asymptotic theory on which 
they are based is not valid in such circumstances.

> , and
> residual deviance tends to 0.

Yes, this happens under complete separation: the model fits the 
observed 0/1 data perfectly.

> My questions then is:
> -Is the converged model correct?

Well, "converged" is not really the right word to use -- the iterative 
algorithm has diverged.  At least one of the coefficients has its MLE 
at infinity (or minus infinity).  In that sense what you see reported 
(ie large values of estimated log odds-ratios, which approximate 
infinity) is correct.  Still more correct would be estimates reported 
as Inf or -Inf: but the algorithm is not programmed to detect such 
divergence.

> or
> -Can I limit the number of iterations in order to avoid this warning?

Yes, probably, but this is not a sensible course of action.  The 
iterations are iterations of an algorithm to compute the MLE.  The MLE 
is not finite-valued, and the warning is a clue to that.

If you *really* want finite parameter estimates, the answer is not to 
use maximum likelihood as the method of estimation.  Various 
alternatives exist, mostly based on penalizing the likelihood [one such 
is in the brlr package, but there are others].  As a general principle 
surely it's better to maximize a different criterion (eg a penalized 
likelihood, with a purposefully chosen penalty function) rather than 
stop the MLE algorithm prematurely and arbitrarily?

I hope this helps!

David

Professor David Firth
Dept of Statistics
University of Warwick
Coventry CV4 7AL
United Kingdom

Email: d.firth at warwick.ac.uk
Voice: +44 (0)247 657 2581
Fax:   +44 (0)247 652 4532



From p.dalgaard at biostat.ku.dk  Sun Jan 25 18:24:23 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 25 Jan 2004 18:24:23 +0100
Subject: [R] warning associated with Logistic Regression
In-Reply-To: <530CB542-4F58-11D8-99AA-0050E4C03977@warwick.ac.uk>
References: <530CB542-4F58-11D8-99AA-0050E4C03977@warwick.ac.uk>
Message-ID: <x265f09c1k.fsf@biostat.ku.dk>

David Firth <d.firth at warwick.ac.uk> writes:

> On Sunday, Jan 25, 2004, at 13:59 Europe/London, Guillem Chust wrote:
> 
> > Hi All,
> >
> > When I tried to do logistic regression (with high maximum number of
> > iterations) I got the following warning message
> >
> > Warning message:
> > fitted probabilities numerically 0 or 1 occurred in: (if
> > (is.empty.model(mt)) glm.fit.null else glm.fit)(x = X, y = Y,
> >
> > As I checked from the Archive R-Help mails, it seems that this
> > happens when
> > the dataset exhibits complete separation.
> 
> Yes.  correct.

Sufficient but not necessary. It can happen just by numerical roundoff
if the effect is strong enough. (I have an example with age and
prevalent menarche: for nearly all women this happens between the age
of 10 and 18, so if you have a couple of 40-year olds in your data
set, they'll get a fitted p of 1. Happens even more easily if you
throw in a cubic term.)
 
> > However, p-values tend to 1
> 
> The reported p-values cannot be trusted: the asymptotic theory on
> which they are based is not valid in such circumstances.
> 
> > , and
> > residual deviance tends to 0.

This, however, is a clear sign that the fit has diverged, and in that
case (but not necessarily otherwise) the asymptotic theory is invalid.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Sun Jan 25 18:48:06 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 25 Jan 2004 17:48:06 +0000 (GMT)
Subject: [R] warning associated with Logistic Regression
In-Reply-To: <x265f09c1k.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0401251738500.27167-100000@gannet.stats>

On 25 Jan 2004, Peter Dalgaard wrote:

> David Firth <d.firth at warwick.ac.uk> writes:
> 
> > On Sunday, Jan 25, 2004, at 13:59 Europe/London, Guillem Chust wrote:
> > 
> > > Hi All,
> > >
> > > When I tried to do logistic regression (with high maximum number of
> > > iterations) I got the following warning message
> > >
> > > Warning message:
> > > fitted probabilities numerically 0 or 1 occurred in: (if
> > > (is.empty.model(mt)) glm.fit.null else glm.fit)(x = X, y = Y,
> > >
> > > As I checked from the Archive R-Help mails, it seems that this
> > > happens when
> > > the dataset exhibits complete separation.
> > 
> > Yes.  correct.
> 
> Sufficient but not necessary. It can happen just by numerical roundoff
> if the effect is strong enough. (I have an example with age and
> prevalent menarche: for nearly all women this happens between the age
> of 10 and 18, so if you have a couple of 40-year olds in your data
> set, they'll get a fitted p of 1. Happens even more easily if you
> throw in a cubic term.)

It also happens with partial separation (when some but not all of the
fitted values go to 0/1).  A common case is where only one case occurs for 
some cell in an interaction of factors, and so can be fitted exactly.

Another example is a dataset of say 8,000 people with complete separation
but one got recorded incorrectly -- then the MLE occurs at large but
finite parameter values and cases dissimilar to the erroneous one will
have fitted probabilities very near (but not exactly) 0/1. The asymptotic
theory is valid but practically useless (the Hauck-Donner effect) in such
problems since 8,000 is a small sample.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Ted.Harding at nessie.mcc.ac.uk  Sun Jan 25 19:06:16 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sun, 25 Jan 2004 18:06:16 -0000 (GMT)
Subject: [R] warning associated with Logistic Regression
In-Reply-To: <LNEAJDHFINNCHGIDAMNHCEHCCDAA.chust@cict.fr>
Message-ID: <XFMail.040125180616.Ted.Harding@nessie.mcc.ac.uk>

On 25-Jan-04 Guillem Chust wrote:
> Hi All,
> 
> When I tried to do logistic regression (with high maximum number of
> iterations) I got the following warning message
> 
> Warning message:
> fitted probabilities numerically 0 or 1 occurred in: (if
> (is.empty.model(mt)) glm.fit.null else glm.fit)(x = X, y = Y,
> 
> As I checked from the Archive R-Help mails, it seems that this happens
> when the dataset exhibits complete separation.

This is so. Indeed, there is a sense in which you are experiencing
unusually good fortune, since for values of your predictors in one
region you are perfectly predicting the 0s in your reponse, and for
values in another region your a perfectly predicting the 1s. What
better could you hope for?

However, you would respond that this is not realistic: your variables
are not (in real life) such that P(Y=1|X=x) is ever exactly 1 or
exactly 0, so this perfect prediction is not realistic.

In that case, you are somewhat stuck. The plain fact is that your
data (in particular the way the values of the X variables are distributed)
are not adequate to tell you what is happening.

There may be manipulative tricks (like penalised regression) which
would inhibit the logistic regression from going all the way to a
perfect fit; but, then, how would you know how far to let it go
(because it will certainly go as far in that direction as you allow
it to).

The key parameter in this situation the dispersion parameter (sigma
in the usual notation). When you get perfect fit in a "completely
separated" situation, this corresponds to sigma=0. If you don't like
this, then there must be reasons why you want sigma>0 and this may
imply that you have reasons for wanting sigma to be at least s0 (say),
or, if you are prepared to be Bayesian about it, you may be satisfied
that there is a prior distribution for sigma which would not allow
sigma=0, and would attach high probability to a range of sigma values
which you condisder to be realistic.

Unless you have a fairly firm idea of what sort of values sigma is
likely to havem then you are indeed stuck because you have no reason
to prefer one positive value of sigma to a different positive value
of sigma. In that case you cannot really object if the logistic
regression tries to make it as small as possible!

In the absence of such reasons, you may consider exploring the
effect of fixing sigma at some positive value, and then varying this
value. For each such value, look at the estimates of the coefficients
of the X variables, the goodness of fit, and so on. This may help you
to form an idea of what sort of estimate you should hope for, and
would enable you to design a better dataset (i.e. placement of X values)
which would be capable of supporting a fit which was both realistic
and estimated with adequate precision.

Another approach you should consider, if you have several X variables,
is to look at subsets of these variables, retaining in the first
instance only those few (the fewer the better) which on substantive
grounds you considered to be the most important in the application
to which the data refer. Also look at the multivariate distribution
of the X values and in particular carry out a linear discriminant
anaysis on them.

If, however, you have only 1 X variable, then you have a situation
equivalent to the following (pairs of (x,y)):

  (-2,0), (-1,9), (0,0), (1,1), (2,1), (3,1).

clearly you are not going to get anything out of this unless you
either repeat the experiment many times (so that you have several
Y responses at each value of X, and probabilities between 0 and 1
at each X then have a better chance to express themselves, as so
many 0s and also so many 1s at each X), or you fill in the range
over which P(Y=1|X=x) increases from low to high, e.g. by observing
Y for X = -1.0, -0.9, -0.8, ... , 0.0, 0.1, ... 1.9, 2.0 (say).

I hope these suggestions help.
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 25-Jan-04                                       Time: 18:06:16
------------------------------ XFMail ------------------------------



From wolski at molgen.mpg.de  Sun Jan 25 23:58:41 2004
From: wolski at molgen.mpg.de (Eryk Wolski)
Date: Sun, 25 Jan 2004 23:58:41 +0100 (MET)
Subject: [R] 'Math' group generic functions. Cant explain behaviour of 'log'.
Message-ID: <Pine.OSF.4.31.0401252356550.6135-100000@harry.molgen.mpg.de>

Hi!

Out of all 'Math' group generic functions(?Math) the log function has
a different behaviour. See example bellow.
Whats the reason?

Platfom Windows 2000.

R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

>setClass("track",representation(x="numeric",y="numeric"))
>setMethod("Math","track",function(x)
+          {
+            x at y=callGeneric(x at y)
+            x
+          }
+          )
>xx<-new("track",x=1:10,y=-(1:10))
>xx<-abs(xx)
>sqrt(xx)
An object of class "track"
Slot "x":
 [1]  1  2  3  4  5  6  7  8  9 10

Slot "y":
 [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751
2.828427
 [9] 3.000000 3.162278
>log(xx)
Error in log(x) : Non-numeric argument to mathematical function

Sincerely Eryk



From jh80 at cornell.edu  Mon Jan 26 00:07:30 2004
From: jh80 at cornell.edu (Jean  Hu)
Date: Sun, 25 Jan 2004 18:07:30 -0500 (EST)
Subject: [R] Reading in .csv Files in R 1081
Message-ID: <2373.128.253.217.223.1075072050.squirrel@webmail.cornell.edu>



Hi,

I uninstalled my R's 1071, and installed R1081.  But now, it appears that
I cannot read in files using the same commands that I used previously.

The command I type is

m<-read.csv("E:/T6.25.8.02.StdDates.csv", header=TRUE,
sep=",",quote="\"",dec=".",fill=TRUE)

The error gives me is
Error in file(file, "r") : unable to open connection

Look forward to your insight.

Best regards,
Jean
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Jean Hu
Masters Candidate in Applied Statistics
301 Malott Hall
Cornell University
Ithaca, NY 14853
Mobile:646-554-6893
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From neileastep at hotmail.com  Mon Jan 26 00:17:01 2004
From: neileastep at hotmail.com (Neil Eastep)
Date: Sun, 25 Jan 2004 18:17:01 -0500
Subject: [R] orphaned packages 
Message-ID: <Law15-F3055K9v7xA0000041a91@hotmail.com>

Are there many packages that are orphaned, and have a better "half" much 
like bootstrap?

Is there a listing, or directory of "recommended" packages (other than the 
packages downloaded with the initial R install)?

Thanks,

Neil Eastep.
An "R" newbie

-----------
Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
>>Package bootstrap is orphaned, that is no longer maintained.
>>Package boot is much more comprehensive, and a recommended
package.
>>That suggests to me that you always use boot: I do.



From sdavis2 at mail.nih.gov  Mon Jan 26 00:30:18 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Sun, 25 Jan 2004 18:30:18 -0500
Subject: [R] orphaned packages 
References: <Law15-F3055K9v7xA0000041a91@hotmail.com>
Message-ID: <000001c3e39b$4aac0790$2f643744@WATSON>

The cran package sources page contains a list of orphaned packages.  Also,
note that the full source listing contains a "priority" category that points
out what packages are recommended.  (For example, see the listing for the
boot package--priority: recommended.).

Sean
----- Original Message -----
From: "Neil Eastep" <neileastep at hotmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Sunday, January 25, 2004 6:17 PM
Subject: [R] orphaned packages


> Are there many packages that are orphaned, and have a better "half" much
> like bootstrap?
>
> Is there a listing, or directory of "recommended" packages (other than the
> packages downloaded with the initial R install)?
>
> Thanks,
>
> Neil Eastep.
> An "R" newbie
>
> -----------
> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> >>Package bootstrap is orphaned, that is no longer maintained.
> >>Package boot is much more comprehensive, and a recommended
> package.
> >>That suggests to me that you always use boot: I do.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From dmurdoch at pair.com  Mon Jan 26 01:27:43 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 25 Jan 2004 19:27:43 -0500
Subject: [R] orphaned packages 
In-Reply-To: <Law15-F3055K9v7xA0000041a91@hotmail.com>
References: <Law15-F3055K9v7xA0000041a91@hotmail.com>
Message-ID: <lmn8101a1nt4j70qrkkea70482h0mgij2r@4ax.com>

On Sun, 25 Jan 2004 18:17:01 -0500, you wrote:

>Is there a listing, or directory of "recommended" packages (other than the 
>packages downloaded with the initial R install)?

The recommended packages are included with (most) binary compilations
of R.

Duncan Murdoch



From extropy at paradise.net.nz  Mon Jan 26 05:43:55 2004
From: extropy at paradise.net.nz (Joel Pitt)
Date: Mon, 26 Jan 2004 17:43:55 +1300
Subject: [R] D(COM) with Excel
Message-ID: <003101c3e3c7$054f5c70$2a01a8c0@extropy>

Hi there,

I'm currently trying to use R in an automated
macro with Excel, and to this effect I've been
using the D(COM) server.

However I've been having alot of problems with
it, because it seems to be limited to only recieving
and sending arrays. I've been struggling
trying to find a way to receive model summaries
from R to put in Excel. I also seem to have
some strange errors coming up...
I've tried doing everything I want directly in R
by hand, and it has been fine, but excel seems to
complicate everything :(

Any people have suggestions?

Thanks,
joel



From ripley at stats.ox.ac.uk  Mon Jan 26 08:29:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jan 2004 07:29:59 +0000 (GMT)
Subject: [R] orphaned packages 
In-Reply-To: <Law15-F3055K9v7xA0000041a91@hotmail.com>
Message-ID: <Pine.LNX.4.44.0401260719410.27955-100000@gannet.stats>

On Sun, 25 Jan 2004, Neil Eastep wrote:

> Are there many packages that are orphaned, and have a better "half" much 
> like bootstrap?

Not many are orphaned -- currently precisely two although one previously
orphaned has acquired a new maintainer recently.   I suspect a few more 
have non-responsive maintainers.

> Is there a listing, or directory of "recommended" packages (other than the 
> packages downloaded with the initial R install)?

It is precisely the set that come with the R distribution.

The CRAN packages page lists both the priority (possibly "recommended") 
and maintainer (possibly ORPHANED).  The daily check page

http://cran.r-project.org/src/contrib/checkSummary.html

lists those as well as the result of the latest checks (although today's 
list seems missing results for the last few packages).

> 
> Thanks,
> 
> Neil Eastep.
> An "R" newbie
> 
> -----------
> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> >>Package bootstrap is orphaned, that is no longer maintained.
> >>Package boot is much more comprehensive, and a recommended
> package.
> >>That suggests to me that you always use boot: I do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Paul.Boutros at utoronto.ca  Mon Jan 26 08:30:57 2004
From: Paul.Boutros at utoronto.ca (Paul Boutros)
Date: Mon, 26 Jan 2004 02:30:57 -0500
Subject: [R] Re-Post: Combining Factors in model.matrix
In-Reply-To: <Pine.LNX.4.44.0401241230000.11089-100000@gannet.stats>
Message-ID: <CPEAKHBKLBNIKJDIELLCCEAHCHAA.Paul.Boutros@utoronto.ca>

> On Sat, 24 Jan 2004 paul.boutros at utoronto.ca wrote:
>
> > I didn't get any response on this before, leading me to believe
> > I've missed
> > something fundamental.  Can anybody guide me in the correct
> > direction for more help on this?

Thanks for your reply:

> You will need to explain to us why the object you list is `the design
> matrix': have *you* a reference for that?  R is doing the conventional
> thing, and I at least have no idea where your example comes from.

Perhaps I have used the wrong terminology?  My understanding of a design
matrix is that it identifies the factors are present for a given experiment.

Here, I have a two factor experiment, where each factor has two levels.
In the case I gave:
   t1 t2
1   1  0
2   1  1
3   0  0
4   0  1

I had expected this to represent four distinct experiments where
factor one is present in the first two and absent in the second two.

> You seem to have coded variables t1 and t2 the opposite ways (the
> reference level is 2 for t1 and 1 for t2), and your model has the fit at
> levels t1=2,t1=1 constrained to pass through the origin.  I don't think R
> has a simple syntax for that (although you can fake anything), and I find
> it hard to believe that is actually what you want.

That wasn't my intention, I want to retain the intercept term and
not constrain it to pass through the origin.

Paul

> >
> > Paul
> >
> > =================================================
> > I want to be able to create a design matrix with two factors.
> For instance, if
> > I have:
> >
> > > t1 <- factor(c(1,1,2,2));
> > > t2 <- factor(c(1,2,1,2));
> > > design <- model.matrix(~ -1 + (t1+t2));
> > > design;
> >   t11 t12 t22
> > 1   1   0   0
> > 2   1   0   1
> > 3   0   1   0
> > 4   0   1   1
> >
> > But the design matrix I want is:
> >    t1 t2
> > 1   1  0
> > 2   1  1
> > 3   0  0
> > 4   0  1
> >
> > Actually, in general I'm struggling with the syntax for
> formulating a design
> > matrix I can write down on paper.  Is there a reference for
> this beyond the R
> > documentation?
>
> Chapter 6 of MASS has the most complete exposition (by Bill
> Venables) that
> I know of, and the White Book (Chambers & Hastie, 1992) goes well beyind
> the R documentation (which uses it as the reference).
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From ripley at stats.ox.ac.uk  Mon Jan 26 08:41:37 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jan 2004 07:41:37 +0000 (GMT)
Subject: [R] D(COM) with Excel
In-Reply-To: <003101c3e3c7$054f5c70$2a01a8c0@extropy>
Message-ID: <Pine.LNX.4.44.0401260731090.27955-100000@gannet.stats>

On Mon, 26 Jan 2004, Joel Pitt wrote:

> Hi there,
> 
> I'm currently trying to use R in an automated
> macro with Excel, and to this effect I've been
> using the D(COM) server.
> 
> However I've been having alot of problems with
> it, because it seems to be limited to only recieving
> and sending arrays. I've been struggling
> trying to find a way to receive model summaries
> from R to put in Excel. I also seem to have
> some strange errors coming up...
> I've tried doing everything I want directly in R
> by hand, and it has been fine, but excel seems to
> complicate everything :(
> 
> Any people have suggestions?

There are two (D)COM servers for R, on by Thomas Baier that has its own 
mailing list, and one by Duncan Temple Lang (at www.omegahat.org and in 
the Omegahat area on CRAN).

It is impossible for us to help with a message as vague as `some strange
errors coming up', so I suggest you read

http://www.chiark.greenend.org.uk/~sgtatham/bugs.html

and then post on the appropriate mailing list for whichever server you are 
using.

[The Baier-version list is listed at the bottom of its readme.txt file.]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Jan 26 09:06:45 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jan 2004 08:06:45 +0000 (GMT)
Subject: [R] Re-Post: Combining Factors in model.matrix
In-Reply-To: <CPEAKHBKLBNIKJDIELLCCEAHCHAA.Paul.Boutros@utoronto.ca>
Message-ID: <Pine.LNX.4.44.0401260800340.28012-100000@gannet.stats>

On Mon, 26 Jan 2004, Paul Boutros wrote:

> > On Sat, 24 Jan 2004 paul.boutros at utoronto.ca wrote:
> >
> > > I didn't get any response on this before, leading me to believe
> > > I've missed
> > > something fundamental.  Can anybody guide me in the correct
> > > direction for more help on this?
> 
> Thanks for your reply:
> 
> > You will need to explain to us why the object you list is `the design
> > matrix': have *you* a reference for that?  R is doing the conventional
> > thing, and I at least have no idea where your example comes from.
> 
> Perhaps I have used the wrong terminology?  My understanding of a design
> matrix is that it identifies the factors are present for a given experiment.

The design matrix is X in the regression usually represented by

y = Xb + e

and is called a model matrix in S/R.

> Here, I have a two factor experiment, where each factor has two levels.
> In the case I gave:
>    t1 t2
> 1   1  0
> 2   1  1
> 3   0  0
> 4   0  1
> 
> I had expected this to represent four distinct experiments where
> factor one is present in the first two and absent in the second two.

You can't have factors that are present/absent.  (You can have levels of
treatments which are present/absent.)  We understand the rows to represent
the individuals runs of a single experiment, but what do the columns
represent?

> > You seem to have coded variables t1 and t2 the opposite ways (the
> > reference level is 2 for t1 and 1 for t2), and your model has the fit at
> > levels t1=2,t1=1 constrained to pass through the origin.  I don't think R
> > has a simple syntax for that (although you can fake anything), and I find
> > it hard to believe that is actually what you want.
> 
> That wasn't my intention, I want to retain the intercept term and
> not constrain it to pass through the origin.

So why did you use ~ -1 + (t1+t2) ?  That explicitly removes the 
intercept.


> Paul
> 
> > >
> > > Paul
> > >
> > > =================================================
> > > I want to be able to create a design matrix with two factors.
> > For instance, if
> > > I have:
> > >
> > > > t1 <- factor(c(1,1,2,2));
> > > > t2 <- factor(c(1,2,1,2));
> > > > design <- model.matrix(~ -1 + (t1+t2));
> > > > design;
> > >   t11 t12 t22
> > > 1   1   0   0
> > > 2   1   0   1
> > > 3   0   1   0
> > > 4   0   1   1
> > >
> > > But the design matrix I want is:
> > >    t1 t2
> > > 1   1  0
> > > 2   1  1
> > > 3   0  0
> > > 4   0  1
> > >
> > > Actually, in general I'm struggling with the syntax for
> > formulating a design
> > > matrix I can write down on paper.  Is there a reference for
> > this beyond the R
> > > documentation?
> >
> > Chapter 6 of MASS has the most complete exposition (by Bill
> > Venables) that
> > I know of, and the White Book (Chambers & Hastie, 1992) goes well beyind
> > the R documentation (which uses it as the reference).
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Paul.Boutros at utoronto.ca  Mon Jan 26 09:51:17 2004
From: Paul.Boutros at utoronto.ca (Paul Boutros)
Date: Mon, 26 Jan 2004 03:51:17 -0500
Subject: [R] Re-Post: Combining Factors in model.matrix
In-Reply-To: <Pine.LNX.4.44.0401260800340.28012-100000@gannet.stats>
Message-ID: <CPEAKHBKLBNIKJDIELLCOEAICHAA.Paul.Boutros@utoronto.ca>

> > > You will need to explain to us why the object you list is `the design
> > > matrix': have *you* a reference for that?  R is doing the conventional
> > > thing, and I at least have no idea where your example comes from.
> >
> > Perhaps I have used the wrong terminology?  My understanding of a design
> > matrix is that it identifies the factors are present for a
> > given experiment.
>
> The design matrix is X in the regression usually represented by
>
> y = Xb + e
>
> and is called a model matrix in S/R.

Right, that's how I understood it.

> > Here, I have a two factor experiment, where each factor has two levels.
> > In the case I gave:
> >    t1 t2
> > 1   1  0
> > 2   1  1
> > 3   0  0
> > 4   0  1
> >
> > I had expected this to represent four distinct experiments where
> > factor one is present in the first two and absent in the second two.
>
> You can't have factors that are present/absent.  (You can have levels of
> treatments which are present/absent.)  We understand the rows to represent
> the individuals runs of a single experiment, but what do the columns
> represent?

Yes, I mis-spoke.  I thought the columns represent individual factors, with
a
0 = level 1 for this factor
1 = level 2 for this factor
Hence the encoding I gave above would indicate that factor 1 is at level 1
for
the first pair of experiments, but at level 0 for the second pair.

> > > You seem to have coded variables t1 and t2 the opposite ways (the
> > > reference level is 2 for t1 and 1 for t2), and your model has
> the fit at
> > > levels t1=2,t1=1 constrained to pass through the origin.  I
> don't think R
> > > has a simple syntax for that (although you can fake
> anything), and I find
> > > it hard to believe that is actually what you want.
> >
> > That wasn't my intention, I want to retain the intercept term and
> > not constrain it to pass through the origin.
>
> So why did you use ~ -1 + (t1+t2) ?  That explicitly removes the
> intercept.

Ahh, I had misunderstood the -1 as explicitly specifying an intercept.
So now:

> t1 <- factor(c(1,1,2,2));
> t2 <- factor(c(1,2,1,2));
> design <- model.matrix(~ t1+t2);
> design;
  (Intercept) t12 t22
1           1   0   0
2           1   0   1
3           1   1   0
4           1   1   1

Which is what I had been looking for!

Thank you for your patient help,
Paul



From ligges at statistik.uni-dortmund.de  Mon Jan 26 10:07:35 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 26 Jan 2004 10:07:35 +0100 (MET)
Subject: [R] Error Loading r
In-Reply-To: <096A444A7DA9E44B85671A7109333F0E5DD283@EXCHANGE01.woolworths.co.za>
Message-ID: <Pine.GSO.4.21.0401261005590.26800-100000@amadeus.statistik.uni-dortmund.de>



On Sun, 25 Jan 2004, Jerome Swartz wrote:

> 
> Hi there,
> 
> This is the first time I have encountered such an error. Error loading
> r.  I did forward the call to our desktop services, but I am just a bit
> curious on what the actual problem could be and how I could have
> resolved myself.  OS is unix version 4. 
> 
> Not sure of the version of R... As its my first encounter.

It's hard to guess without more information.
I'd suggest either to ask your IT staff or to try (re)installing a recent
version of R.

Uwe Ligges


> 
> Kind regards
> 
> Jerome Swartz
> 
> 
> --------------------------------------------------------------------------------
> Please note: This e-mail and its contents are subject to a disclaimer 
> which can be viewed at http://www.woolworths.co.za/disclaimer. Should
> you be unable to access the link please e-mail disclaimer at woolworths.co.za 
> and a copy of the disclaimer will be e-mailed to you.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From petr.pikal at precheza.cz  Mon Jan 26 10:32:04 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 26 Jan 2004 10:32:04 +0100
Subject: [R] how to keep functions while remove all other commands
In-Reply-To: <Pine.LNX.4.58.0401242143280.15008@galton.uchicago.edu>
References: <200401111106.i0BB52kr019805@hypatia.math.ethz.ch>
Message-ID: <4014ECA4.568.5A814F@localhost>

Hi

On 24 Jan 2004 at 21:47, Yong Wang wrote:

> Dear all:
> a quick question:
> I am used to apply  rm(list=()) regularly to remove all old codes in
> preventing them creeping in current analysis.however, with that
> application, functions I wrote are also removed. please let me know
> how to keep the thing you want while remove those you don't.

I usually work in some separate home directory (e.g. D:\data\stat\standard) and I 
store my functions I want to keep in another directory 
(D:\prog\R\......\library\fun), which can be attached as any other library in the 
same way like other libraries can. You just have to use some files (I think at least 
INDEX and DESCRIPTION).

More in "R-exts" manual.

Cheers
Petr

> 
> thank you
> 
> best 
> yong
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From d.firth at warwick.ac.uk  Mon Jan 26 11:28:48 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Mon, 26 Jan 2004 10:28:48 +0000
Subject: [R] warning associated with Logistic Regression
In-Reply-To: <XFMail.040125180616.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <6D49F846-4FEA-11D8-8CBE-0050E4C03977@warwick.ac.uk>

On Sunday, Jan 25, 2004, at 18:06 Europe/London, (Ted Harding) wrote:

> On 25-Jan-04 Guillem Chust wrote:
>> Hi All,
>>
>> When I tried to do logistic regression (with high maximum number of
>> iterations) I got the following warning message
>>
>> Warning message:
>> fitted probabilities numerically 0 or 1 occurred in: (if
>> (is.empty.model(mt)) glm.fit.null else glm.fit)(x = X, y = Y,
>>
>> As I checked from the Archive R-Help mails, it seems that this happens
>> when the dataset exhibits complete separation.
>
> This is so. Indeed, there is a sense in which you are experiencing
> unusually good fortune, since for values of your predictors in one
> region you are perfectly predicting the 0s in your reponse, and for
> values in another region your a perfectly predicting the 1s. What
> better could you hope for?
>
> However, you would respond that this is not realistic: your variables
> are not (in real life) such that P(Y=1|X=x) is ever exactly 1 or
> exactly 0, so this perfect prediction is not realistic.
>
> In that case, you are somewhat stuck. The plain fact is that your
> data (in particular the way the values of the X variables are 
> distributed)
> are not adequate to tell you what is happening.
>
> There may be manipulative tricks (like penalised regression) which
> would inhibit the logistic regression from going all the way to a
> perfect fit; but, then, how would you know how far to let it go
> (because it will certainly go as far in that direction as you allow
> it to).
>
> The key parameter in this situation the dispersion parameter (sigma
> in the usual notation). When you get perfect fit in a "completely
> separated" situation, this corresponds to sigma=0. If you don't like
> this, then there must be reasons why you want sigma>0 and this may
> imply that you have reasons for wanting sigma to be at least s0 (say),
> or, if you are prepared to be Bayesian about it, you may be satisfied
> that there is a prior distribution for sigma which would not allow
> sigma=0, and would attach high probability to a range of sigma values
> which you condisder to be realistic.
>
> Unless you have a fairly firm idea of what sort of values sigma is
> likely to havem then you are indeed stuck because you have no reason
> to prefer one positive value of sigma to a different positive value
> of sigma. In that case you cannot really object if the logistic
> regression tries to make it as small as possible!

This seems arguable.  Accepting that we are talking about point 
estimation (the desirability of which is of course open to question!!), 
then old-fashioned criteria like bias, variance and mean squared error 
can be used as a guide.  For example, we might desire to use an 
estimation method for which the MSE of the estimated logistic 
regression coefficients (suitably standardized) is as small as 
possible; or some other such thing.

The simplest case is estimation of log(pi/(1-pi)) given an observation 
r from binomial(n,pi).  Suppose we find that r=n -- what then can we 
say about pi?  Clearly not much if n is small, rather more if n is 
large.  Better in terms of MSE than the MLE (whose MSE is infinite) is 
to use log(p/(1-p)), with p = (r+0.5)/(n+1).  See for example Cox & 
Snell's book on binary data.  This corresponds to penalizing the 
likelihood by the Jeffreys prior, a penalty function which has good 
frequentist properties also in the more general logistic regression 
context.  References given in the brlr package give the theory and some 
empirical evidence.  The logistf package, also on CRAN, is another 
implementation.

I do not mean to imply that the Jeffreys-prior penalty will be the 
right thing for all applications -- it will not.  (eg if you really do 
have prior information, it would be better to use it.)

In general I agree wholeheartedly that it is best to get more/better 
data!

> In the absence of such reasons,
(cut)

All good wishes,
David



From petr.pikal at precheza.cz  Mon Jan 26 11:44:09 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 26 Jan 2004 11:44:09 +0100
Subject: [R] Response Surface
In-Reply-To: <Pine.LNX.4.58.0401230906070.20290@gstat305.stat.wisc.edu>
Message-ID: <4014FD89.8272.9C7ECE@localhost>

Hallo

On 23 Jan 2004 at 9:08, Li Xiaolei wrote:

> 
> Hi,
> 
> Is there any existing way in R of doing response surface analyses and
> plotting the response surface, like what minitab can do?

Well, I do not know about any package doing response surface 
design, but if you already made experiments according to design 
you elaborated by yourself, 

function 

contour 

maybe with help of 

interp 

from akima package can do the plotting.

Cheers

Petr

> 
> Thanks
> 
> Xiaolei
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From dj at research.bell-labs.com  Mon Jan 26 15:08:10 2004
From: dj at research.bell-labs.com (David James)
Date: Mon, 26 Jan 2004 09:08:10 -0500
Subject: [R] D(COM) with Excel
In-Reply-To: <003101c3e3c7$054f5c70$2a01a8c0@extropy>;
	from extropy@paradise.net.nz on Mon, Jan 26, 2004 at 05:43:55PM
	+1300
References: <003101c3e3c7$054f5c70$2a01a8c0@extropy>
Message-ID: <20040126090810.A21457@jessie.research.bell-labs.com>

Hi Joel,

You may want to take a look at the RDCOM implementation at
http://www.omegahat.org/RDCOMServer.  We've had very good
experience with it.

--
David

Joel Pitt wrote:
> Hi there,
> 
> I'm currently trying to use R in an automated
> macro with Excel, and to this effect I've been
> using the D(COM) server.
> 
> However I've been having alot of problems with
> it, because it seems to be limited to only recieving
> and sending arrays. I've been struggling
> trying to find a way to receive model summaries
> from R to put in Excel. I also seem to have
> some strange errors coming up...
> I've tried doing everything I want directly in R
> by hand, and it has been fine, but excel seems to
> complicate everything :(
> 
> Any people have suggestions?
> 
> Thanks,
> joel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jcm68 at cam.ac.uk  Mon Jan 26 15:14:32 2004
From: jcm68 at cam.ac.uk (J-C. Marioni)
Date: 26 Jan 2004 14:14:32 +0000
Subject: [R] correlation/random effects when using nlme 
Message-ID: <E1Al7VY-0005Hw-5X.--66ac6f520c01e2a4982c3f80cd4326f790f2147e@maroon.csi.cam.ac.uk>

Hi,

I'm trying to use nlme to program a model where, as well as a number of 
fixed effects, I have a random effect for each subject in my model.

I would also like to include a correlation statement in my model, where the 
grouping factor for the correlation is a subset of the observations on a 
particular subject.

However, when I try and program this, R will not let me use a different 
grouping structure for the random effects and the correlation structure. I 
can't seem to solve this problem myself and so I would be grateful for any 
help!

Thanks,

John Marioni
University of Cambridge



From stievie at utanet.at  Mon Jan 26 15:29:49 2004
From: stievie at utanet.at (Stefan Ascher)
Date: Mon, 26 Jan 2004 15:29:49 +0100
Subject: [R] Significances of Korrelations and Sweave
Message-ID: <200401261529490964.00DFBD3E@127.0.0.1>

Hi,

1. I've written a function to obtain significances of correlations (there
is probably already a function for this, but I'm still not very familar
with all the functions). This function works just fine, but there are some
differences with e.g. SPSS, not large though. Maybe some floating point
calculation issues [1]?

Maybe someone has time to have a look, I've uploaded a working example to
http://web.utanet.at/ascherst/rtest.zip (4 KB), just run test.r.

2. About Sweave, I love it! But one thing annoys me: Is it possible that it
doesn't insert \begin{Schunk}...\end{Schunk}? Some of my code reads like:
\ctable[ caption={Deskriptive Statistik},
label=tab:ErgebnisseDeskriptiveStatistik, pos=!tbp ]{lrrrddd}
{}
{
	\FL
	\multicolumn{1}{l}{}         &
	\multicolumn{1}{r}{$N$}      &
	\multicolumn{1}{r}{Min}      &
	\multicolumn{1}{r}{Max}      &
	\multicolumn{1}{r}{$M$}      &
	\multicolumn{1}{r}{$SD$}     &
	\multicolumn{1}{r}{Varianz}
	\ML
<<echo=false,results=tex>>=
for (i in 3:ncol(scales)) {
...
}
@
	\LL
}
LaTeX gives me an Error when there is an environment inside ctable.

Thanks in advance.

[1] http://docs.sun.com/source/806-3568/ncg_goldberg.html
Stefan



From mmiller3 at iupui.edu  Mon Jan 26 15:37:40 2004
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Mon, 26 Jan 2004 09:37:40 -0500
Subject: [R] Fitting compartmental model with nls and lsoda?
References: <0E27DEC3.3CA874F1.0B088159@aol.com>
Message-ID: <87ad4a3he3.fsf@lumen.indyrad.iupui.edu>

>>>>> "DivineSAAM" == DivineSAAM  <DivineSAAM at aol.com> writes:

    > Dear Colleagues,
    > Our group is also working on implementing the use of R for
    > pharmacokinetic compartmental analysis. Perhaps I have
    > missed something, but 

    > > fit <- nls(noisy ~ lsoda(xstart, time,
    > one.compartment.model, c(K1=0.5, k2=0.5)), 
    > +            data=C1.lsoda,
    > +            start=list(K1=0.3, k2=0.7),
    > +            trace=T
    > +            )
    > Error in eval(as.name(varName), data) : Object "C1.lsoda" not found

    > What part of the e-mail did I miss? I would like to get
    > this problem up an running. 

Oscar,

There were several problems with the code in my previous posting.
I'll append an example that does work.  While this example often
works, there are cases when nls fails by reducing the step factor
below minFactor.  It is even less stable for fitting less trivial
examples with real data sets.  I'll be very interested to keep in
touch as we make progress on this problem.

Regards, Mike


Here's my (more) correct example:

require(odesolve)

## Simple one compartment blood flow model:
one.compartment.model <- function(t, x, parms) {
  C1 <- x[1] # compartment
  with(as.list(parms),{
    input <- approx(signal$time, signal$input, t)$y
    dC1 <- K1 * input - k2 * C1
    list(c(dC1))
  })
}

## vector of timesteps
time <- seq(0, 100, 1)

## external signal with rectangle impulse
signal <- as.data.frame(list(time=time,
                             input=rep(0,length(time))))
signal$input[signal$time >= 10 & signal$time <=40] <- 0.2

## Parameters for steady state conditions
parms <- c(K1=0.5, k2=0.5)

## Start values for steady state
xstart <- c(C1=0)

## calculate C1 with lsoda:
C1.lsoda <- as.data.frame(lsoda(xstart, time, one.compartment.model, parms))

## Add some noise to the output curve
C1.lsoda$noisy <- C1.lsoda$C1 + rnorm(nrow(C1.lsoda), sd=0.15*C1.lsoda$C1)

## See if I can run a fit to find the parameters that I started with...
require(nls)
fit <- nls(noisy ~ lsoda(xstart, time, one.compartment.model, c(K1=K1, k2=k2))[,2],
           data=C1.lsoda,
           start=list(K1=0.3, k2=0.7),
           trace=T,
           control=list(tol=1e-2,
             minFactor=1/1024/1024)
           )

fit.rk4 <- nls(noisy ~ rk4(xstart, time, one.compartment.model, c(K1=K1, k2=k2))[,2],
               data=C1.lsoda,
               start=list(K1=0.3, k2=0.7),
               trace=T,
               control=list(tol=1e-2,
                 minFactor=1/1024/1024)
               )

## Plot what I've got so far:
par(mfrow=c(2,2))
plot(noisy ~ time, data=C1.lsoda, main='Input, C1, C1+noise', col='forestgreen')
points(input ~ time, data=signal, type='b')
points(C1 ~ time, data=C1.lsoda, type='b', pch=16)

t <- seq(0,100,0.1)
plot(noisy ~ time, data=C1.lsoda, main='Input, C1+noise, lsoda',
     col='forestgreen')
lines(t, predict(fit, list(time=t)), col='red',type='l')

plot(noisy ~ time, data=C1.lsoda, main='Input, C1+noise, rk4',
     col='forestgreen')
lines(t, predict(fit.rk4, list(time=t)), col='blue', type='l')

plot(t, predict(fit.rk4, list(time=t))-predict(fit, list(time=t)),
     type='l')
abline(h=0)


print('Coefficients for lsoda solution:')
print(coef(fit))
print(vcov(fit))

print('Coefficients for rk4 solution:')
print(coef(fit.rk4))
print(vcov(fit.rk4))

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine



From ddimascio at mba05.rsm.nl  Mon Jan 26 16:17:46 2004
From: ddimascio at mba05.rsm.nl (Dennis Di Mascio)
Date: Mon, 26 Jan 2004 16:17:46 +0100
Subject: [R] Openin a file from spss
Message-ID: <ILENLCCNCLLBDMGKMCOACEDLCBAA.ddimascio@mba05.rsm.nl>

Hello everybody,
I'm trying to open an SPSS (version 11.5) file with R (1.8.1 for windows)
and I have some problems. I already used the following syntax to open other
files ant it worked fine. (I loaded the foreign package).
Would be very nice to understand what happened because I'm going to work a
lot on this file and it is a good opportunity to learn R instead of spss and
to confrontate results with my group mates.
I apologize if I'm asking something that is well know to the entire list,
but I browsed briefly through the past articles and I didn't find anything
and I am short in time
Thanks a lot.

dennis.

data <- read.spss("C:/a.sav", use.value.labels=TRUE, max.value.labels=Inf,
to.data.frame=TRUE)
Error in read.spss("C:/a.sav", use.value.labels = TRUE, max.value.labels =
Inf,  :
        Error reading system-file header.
In addition: Warning message:
C:/a.sav: File layout code has unexpected value 50331648.  Value should be
2, in big-endian or little-endian format.



From gr3k at virginia.edu  Mon Jan 26 16:45:51 2004
From: gr3k at virginia.edu (Greg Riddick)
Date: Mon, 26 Jan 2004 10:45:51 -0500
Subject: [R] scan() Bug?
References: <Pine.LNX.4.44.0401222150200.20473-100000@gannet.stats>
Message-ID: <001901c3e423$819af3f0$0400a8c0@ghandi>

Thanks for your suggestions on dealing with binary files, Prof Ripley

I ended up using this method:


PDF = file("file.pdf","a+b")
PDFlines = readLines(PDF)
.
.
.
(Extract Some Information From PDFlines and create some objects to add back
to the PDF file)
.
.
.
writeLines(newobjects, PDF, sep = "\12")
close(PDF)


So I opened the file as binary in read/append mode.
Works fine now...though I have noticed that the sep character that actually
gets written to the file is -2 the value specified.
So I wanted \10 and needed to specify \12 to get it. Am I doing something
wrong here?

I'm working on an R package to add annotations(hyperlinks, popups etc.) to
PDF files that I should release in about 2 weeks.  Should be useful
especially to the bioinformatics
people who use R. Incidentally, the uncompressed PDF files that I have seen
R produce are actually just plain text files---human-readable ascii
characters delimited by CR or CR/LF.  They are binary only in the sense that
a cross-reference table at the end of the file records byte offsets of
individual objects in the file. So insertions and deletions cannot be made
without updating the
cross-reference table.




----- Original Message ----- 
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Greg Riddick" <gr3k at virginia.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Thursday, January 22, 2004 4:52 PM
Subject: Re: [R] scan() Bug?


> On Thu, 22 Jan 2004, Greg Riddick wrote:
>
> > I'm reading a file into a list by:
> > PDF = scan("file",what="character",sep="\10")
> >
> > "\10" is the newline character in this file, also tried "\n" originally
> >
> > On lines that are ended by "\13\10", both are dropped from the list
entry
> > I want scan to keep the "\13" in the list entry.
> >
> > Is this a bug or just a strange feature?
>
> Not a strange feature, but the documented behaviour (and useful, too).
> You have opened the file in text mode.  If you want to keep CRs, open and
> read in binary mode.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Mon Jan 26 17:14:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jan 2004 16:14:12 +0000 (GMT)
Subject: [R] scan() Bug
In-Reply-To: <001901c3e423$819af3f0$0400a8c0@ghandi>
Message-ID: <Pine.LNX.4.44.0401261608520.28808-100000@gannet.stats>

The \zzz notation is octal (just like C)!  I presume you want ASCII
character 10, that is LF, not 8 (BS), although using \n would be much
easier to remember.

On Mon, 26 Jan 2004, Greg Riddick wrote:

> Thanks for your suggestions on dealing with binary files, Prof Ripley
> 
> I ended up using this method:
> 
> 
> PDF = file("file.pdf","a+b")
> PDFlines = readLines(PDF)
> .
> .
> .
> (Extract Some Information From PDFlines and create some objects to add back
> to the PDF file)
> .
> .
> .
> writeLines(newobjects, PDF, sep = "\12")
> close(PDF)
> 
> 
> So I opened the file as binary in read/append mode.
> Works fine now...though I have noticed that the sep character that actually
> gets written to the file is -2 the value specified.
> So I wanted \10 and needed to specify \12 to get it. Am I doing something
> wrong here?
> 
> I'm working on an R package to add annotations(hyperlinks, popups etc.) to
> PDF files that I should release in about 2 weeks.  Should be useful
> especially to the bioinformatics
> people who use R. Incidentally, the uncompressed PDF files that I have seen
> R produce are actually just plain text files---human-readable ascii
> characters delimited by CR or CR/LF.  They are binary only in the sense that
> a cross-reference table at the end of the file records byte offsets of
> individual objects in the file. So insertions and deletions cannot be made
> without updating the
> cross-reference table.
> 
> 
> 
> 
> ----- Original Message ----- 
> From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> To: "Greg Riddick" <gr3k at virginia.edu>
> Cc: <r-help at stat.math.ethz.ch>
> Sent: Thursday, January 22, 2004 4:52 PM
> Subject: Re: [R] scan() Bug?
> 
> 
> > On Thu, 22 Jan 2004, Greg Riddick wrote:
> >
> > > I'm reading a file into a list by:
> > > PDF = scan("file",what="character",sep="\10")
> > >
> > > "\10" is the newline character in this file, also tried "\n" originally
> > >
> > > On lines that are ended by "\13\10", both are dropped from the list
> entry
> > > I want scan to keep the "\13" in the list entry.
> > >
> > > Is this a bug or just a strange feature?
> >
> > Not a strange feature, but the documented behaviour (and useful, too).
> > You have opened the file in text mode.  If you want to keep CRs, open and
> > read in binary mode.
> >
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Mon Jan 26 17:15:29 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 Jan 2004 17:15:29 +0100
Subject: [R] scan() Bug?
In-Reply-To: <001901c3e423$819af3f0$0400a8c0@ghandi>
References: <Pine.LNX.4.44.0401222150200.20473-100000@gannet.stats>
	<001901c3e423$819af3f0$0400a8c0@ghandi>
Message-ID: <x2fze2u1ni.fsf@biostat.ku.dk>

"Greg Riddick" <gr3k at virginia.edu> writes:

> Works fine now...though I have noticed that the sep character that actually
> gets written to the file is -2 the value specified.
> So I wanted \10 and needed to specify \12 to get it. Am I doing something
> wrong here?

Just overlooking that such codes are specified in octal notation, I
think. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rvaradha at jhsph.edu  Mon Jan 26 17:40:13 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Mon, 26 Jan 2004 11:40:13 -0500
Subject: [R] warning associated with Logistic Regression
Message-ID: <106e6110635f.10635f106e61@jhsph.edu>

Hi All:

I am really fascinated by the content and the depth of discussion of 
this thread.  This really exemplifies what I have come to love and 
enjoy about the R user group - that it is not JUST an answering service 
for getting help on programming issues, but also a forum for some 
critical and deep thinking on fundamental statistical issues.  

Kudos to the group!

Best,
Ravi.

----- Original Message -----
From: David Firth <d.firth at warwick.ac.uk>
Date: Monday, January 26, 2004 5:28 am
Subject: Re: [R] warning associated with Logistic Regression

> On Sunday, Jan 25, 2004, at 18:06 Europe/London, (Ted Harding) wrote:
> 
> > On 25-Jan-04 Guillem Chust wrote:
> >> Hi All,
> >>
> >> When I tried to do logistic regression (with high maximum 
> number of
> >> iterations) I got the following warning message
> >>
> >> Warning message:
> >> fitted probabilities numerically 0 or 1 occurred in: (if
> >> (is.empty.model(mt)) glm.fit.null else glm.fit)(x = X, y = Y,
> >>
> >> As I checked from the Archive R-Help mails, it seems that this 
> happens>> when the dataset exhibits complete separation.
> >
> > This is so. Indeed, there is a sense in which you are experiencing
> > unusually good fortune, since for values of your predictors in one
> > region you are perfectly predicting the 0s in your reponse, and for
> > values in another region your a perfectly predicting the 1s. What
> > better could you hope for?
> >
> > However, you would respond that this is not realistic: your 
> variables> are not (in real life) such that P(Y=1|X=x) is ever 
> exactly 1 or
> > exactly 0, so this perfect prediction is not realistic.
> >
> > In that case, you are somewhat stuck. The plain fact is that your
> > data (in particular the way the values of the X variables are 
> > distributed)
> > are not adequate to tell you what is happening.
> >
> > There may be manipulative tricks (like penalised regression) which
> > would inhibit the logistic regression from going all the way to a
> > perfect fit; but, then, how would you know how far to let it go
> > (because it will certainly go as far in that direction as you allow
> > it to).
> >
> > The key parameter in this situation the dispersion parameter (sigma
> > in the usual notation). When you get perfect fit in a "completely
> > separated" situation, this corresponds to sigma=0. If you don't like
> > this, then there must be reasons why you want sigma>0 and this may
> > imply that you have reasons for wanting sigma to be at least s0 
> (say),> or, if you are prepared to be Bayesian about it, you may 
> be satisfied
> > that there is a prior distribution for sigma which would not allow
> > sigma=0, and would attach high probability to a range of sigma 
> values> which you condisder to be realistic.
> >
> > Unless you have a fairly firm idea of what sort of values sigma is
> > likely to havem then you are indeed stuck because you have no reason
> > to prefer one positive value of sigma to a different positive value
> > of sigma. In that case you cannot really object if the logistic
> > regression tries to make it as small as possible!
> 
> This seems arguable.  Accepting that we are talking about point 
> estimation (the desirability of which is of course open to 
> question!!), 
> then old-fashioned criteria like bias, variance and mean squared 
> error 
> can be used as a guide.  For example, we might desire to use an 
> estimation method for which the MSE of the estimated logistic 
> regression coefficients (suitably standardized) is as small as 
> possible; or some other such thing.
> 
> The simplest case is estimation of log(pi/(1-pi)) given an 
> observation 
> r from binomial(n,pi).  Suppose we find that r=n -- what then can 
> we 
> say about pi?  Clearly not much if n is small, rather more if n is 
> large.  Better in terms of MSE than the MLE (whose MSE is 
> infinite) is 
> to use log(p/(1-p)), with p = (r+0.5)/(n+1).  See for example Cox 
> & 
> Snell's book on binary data.  This corresponds to penalizing the 
> likelihood by the Jeffreys prior, a penalty function which has 
> good 
> frequentist properties also in the more general logistic 
> regression 
> context.  References given in the brlr package give the theory and 
> some 
> empirical evidence.  The logistf package, also on CRAN, is another 
> implementation.
> 
> I do not mean to imply that the Jeffreys-prior penalty will be the 
> right thing for all applications -- it will not.  (eg if you 
> really do 
> have prior information, it would be better to use it.)
> 
> In general I agree wholeheartedly that it is best to get 
> more/better 
> data!
> 
> > In the absence of such reasons,
> (cut)
> 
> All good wishes,
> David
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From v.demart at libero.it  Mon Jan 26 17:42:04 2004
From: v.demart at libero.it (v.demart@libero.it)
Date: Mon, 26 Jan 2004 17:42:04 +0100
Subject: [R] Learning to use survey package
Message-ID: <HS3VQ4$32707B75F7FA5BB970ABA55F584F00FA@libero.it>

Being an  electrical engineer "lent" to statistics, I'm now studying the stratified sampling techniques using the survey package and its documentation. 

I've found somewhat complex the example in the package also for the magnitude of the dataset used and the not-clearly-exposed purposes of the sampling, and my attempts to find something in the net through Google ended up with a flood of useless info.

What I would find extremely helpful would be having a very simple example developped step by step, starting from an **easy** dataset, setting the aims of the sampling, and showing in a straightforward way the actions to be taken (of course, better, but not necessarely, using survey).

Do you know if there is anything of this kind available in the Internet?

Thanks for your help    

Vittorio



From djw1005 at cam.ac.uk  Mon Jan 26 17:56:59 2004
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Mon, 26 Jan 2004 16:56:59 +0000 (GMT)
Subject: [R] Trouble with HTML search engine & Mozilla Firebird
Message-ID: <Pine.SOL.3.96.1040126163759.24209A-100000@draco.cus.cam.ac.uk>


I'm having trouble with the HTML-based search engine, and I'd be grateful
for any advice. I am using Mozilla Firebird 0.7 on Debian 3.0 with R
1.8.0. (I've also had the trouble with Mozilla Firebird 0.6 on Debian 3.0.
I also use Mozilla Firebird 0.6 on Windows XP, and I have no trouble with
the HTML-based search engine.)

When I type help.start() in R, it brings up the proper search page. 
I follow the link to "Search engine & keywords", type some text into the
search box, and click "search". It wipes the text in the search box, and
leaves me at the search page. The URL changes, to something like
file:///tmp/Rtmp27053/.R/doc/html/search/SearchEngine.html?SEARCHTERM=MySearchTerm&TITLES=1&KEYWORDS=1&ALIASES=1

I've looked through the help on the R web site. There are plenty of
messages which say to check that Java is correctly installed and that
Javascript is turned on, but this does not seem to be my problem...

I have installed Java 1.4.2_03. Java is installed in my browser, according
to the test applet at http://www.java.com/en/download/help/testvm.jsp
Javascript works in my browser, as far as I can test it. I tried modifying
the search page, to put in various debugging messages, and they showed up
as I expected.

When I execute the search, the Mozilla Firebird javascript console comes
up with an error message: "Error: document.SearchEngine.search is not a
function". The line of the web page which causes this error is

line = line + document.SearchEngine.search(...)

I tried putting in some debugging messages before this, to show me what's
going on:

alert("I found "+document.SearchEngine)
alert("I found "+document.SearchEngine.search)

The first shows me that javascript can find the object
document.SearchEngine, and the second suggests that it can't find the
method search() from within that object.

This suggests there is some trouble in the interface between Java and
Javascript in this browser. I looked through all the security settings,
but (as far as I can see) I've enabled everything to do with Java and
Javascript. 

Does anyone have any advice?

Damon.



From kayee at u.washington.edu  Mon Jan 26 18:44:54 2004
From: kayee at u.washington.edu (Ka Yee Yeung)
Date: Mon, 26 Jan 2004 09:44:54 -0800 (PST)
Subject: [R] Fortran source code
Message-ID: <Pine.A41.4.58.0401260940250.27242@homer13.u.washington.edu>

Hi,

I am wondering if it is possible to view the Fortran source code called by
R functions.

In particular, I am interested in the "leaps.setup" function in a
package called "leaps", which calls Fortran functions "ssleaps", "initr"
etc.

Any help would be greatly appreciated.

Ka Yee Yeung
Bioinformatics Scientist
Dept of Microbiology
University of Washington



From p.dalgaard at biostat.ku.dk  Mon Jan 26 19:07:17 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 Jan 2004 19:07:17 +0100
Subject: [R] Fortran source code
In-Reply-To: <Pine.A41.4.58.0401260940250.27242@homer13.u.washington.edu>
References: <Pine.A41.4.58.0401260940250.27242@homer13.u.washington.edu>
Message-ID: <x2n08ashwq.fsf@biostat.ku.dk>

Ka Yee Yeung <kayee at u.washington.edu> writes:

> Hi,
> 
> I am wondering if it is possible to view the Fortran source code called by
> R functions.

R is Open Source, and so are most of the packages developed for it.
Would be a rare case if the source code was not available. 
 
> In particular, I am interested in the "leaps.setup" function in a
> package called "leaps", which calls Fortran functions "ssleaps", "initr"
> etc.
> 
> Any help would be greatly appreciated.

Look inside

http://cran.r-project.org/src/contrib/leaps_2.6.tar.gz

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From chun.49 at osu.edu  Mon Jan 26 19:15:18 2004
From: chun.49 at osu.edu (Yongwan Chun)
Date: Mon, 26 Jan 2004 13:15:18 -0500
Subject: [R] Question about design matrix
Message-ID: <000301c3e438$5e20b850$80c29280@ywchun>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040126/9b73c5bf/attachment.pl

From erich.neuwirth at univie.ac.at  Mon Jan 26 19:54:56 2004
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Mon, 26 Jan 2004 19:54:56 +0100
Subject: [R] D(COM) with Excel
In-Reply-To: <20040126090810.A21457@jessie.research.bell-labs.com>
References: <003101c3e3c7$054f5c70$2a01a8c0@extropy>
	<20040126090810.A21457@jessie.research.bell-labs.com>
Message-ID: <40156280.6090109@univie.ac.at>

Hi,

as the one who wrote the RExcel package let me add something to the 
discussion.

Thomas Baier's R (D)COM package tries to use "native" Windows
data types to be as fast as possible.
My RExcel package has the following philosophy:
Offer R functions to people who "think spreadsheet".
One way of describing it is:
You can have an R process living in each cell of the spreadsheet,
and the output of R we want to deal with hast to be compatible with the
spreadsheet structure. That is the reason for the restriction to
arrays.
Spreadsheets (NOT the embedded programming language)
do not know about objects.

Somewhat oversimplifying one might say:
RExcel brings R computation to the spreadsheet,
and RDCOM brings R objects to VBA.

Erich Neuwirth






David James wrote:

>Hi Joel,
>
>You may want to take a look at the RDCOM implementation at
>http://www.omegahat.org/RDCOMServer.  We've had very good
>experience with it.
>
>--
>David
>
>Joel Pitt wrote:
>  
>
>>Hi there,
>>
>>I'm currently trying to use R in an automated
>>macro with Excel, and to this effect I've been
>>using the D(COM) server.
>>
>>However I've been having alot of problems with
>>it, because it seems to be limited to only recieving
>>and sending arrays. I've been struggling
>>trying to find a way to receive model summaries
>>from R to put in Excel. I also seem to have
>>some strange errors coming up...
>>I've tried doing everything I want directly in R
>>by hand, and it has been fine, but excel seems to
>>complicate everything :(
>>
>>Any people have suggestions?
>>
>>Thanks,
>>joel
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>


-- 
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386



From uaca at alumni.uv.es  Mon Jan 26 20:15:51 2004
From: uaca at alumni.uv.es (uaca@alumni.uv.es)
Date: Mon, 26 Jan 2004 20:15:51 +0100
Subject: [R] conditional assignment
Message-ID: <20040126191551.GA14785@pusa.informat.uv.es>


Hi all

I want to conditionally operate on certain elements of a matrix, let me
explain it with a simple vector example


> z<- c(1, 2, 3)
> zz <- c(0,0,0)
> null <- (z > 2) & ( zz <- z)
> zz
[1] 1 2 3

why zz is not (0, 0, 3) ?????


the null <- assignment is to keep the console silent

in the other hand, it curious that null has reasonable values

> null
[1] FALSE FALSE  TRUE

Thanks in advance

	Ulisses

                Debian GNU/Linux: a dream come true
-----------------------------------------------------------------------------
"Computers are useless. They can only give answers."            Pablo Picasso

Humans are slow, innaccurate, and brilliant.
Computers are fast, acurrate, and dumb. 
Together they are unbeatable

--->	Visita http://www.valux.org/ para saber acerca de la	<---
--->	Asociaci?n Valenciana de Usuarios de Linux		<---



From ripley at stats.ox.ac.uk  Mon Jan 26 20:33:09 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jan 2004 19:33:09 +0000 (GMT)
Subject: [R] Fortran source code
In-Reply-To: <Pine.A41.4.58.0401260940250.27242@homer13.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0401261931450.29280-100000@gannet.stats>

They are part of the package leaps_2.6.tar.gz on CRAN.  Just look at the 
source package and not (I assume) a binary installation.

On Mon, 26 Jan 2004, Ka Yee Yeung wrote:

> I am wondering if it is possible to view the Fortran source code called by
> R functions.
> 
> In particular, I am interested in the "leaps.setup" function in a
> package called "leaps", which calls Fortran functions "ssleaps", "initr"
> etc.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Jan 26 20:34:35 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jan 2004 19:34:35 +0000 (GMT)
Subject: [R] Question about design matrix
In-Reply-To: <000301c3e438$5e20b850$80c29280@ywchun>
Message-ID: <Pine.LNX.4.44.0401261933300.29280-100000@gannet.stats>

On Mon, 26 Jan 2004, Yongwan Chun wrote:

> Now, I am working with some design matrices. My problem is to set
> "contrasts" option. Now I want to use "contr.sum" as the option, and it
> works properly. However, this option sets the last element of a factor
> as -1. For example, if I have a factor which has 5 elements and want to
> use the "contr.sum" option, the 5th elements is always set to -1. I want
> set -1 to other element such as 1st or 2nd. Is it possible? 

Yes, just recode the factor so the level you want is the last one.
Or, write your own contrast function to replace contr.sum.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Roger.Bivand at nhh.no  Mon Jan 26 20:36:05 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 26 Jan 2004 20:36:05 +0100 (CET)
Subject: [R] conditional assignment
In-Reply-To: <20040126191551.GA14785@pusa.informat.uv.es>
Message-ID: <Pine.LNX.4.44.0401262032360.30442-100000@reclus.nhh.no>

On Mon, 26 Jan 2004 uaca at alumni.uv.es wrote:

> 
> Hi all
> 
> I want to conditionally operate on certain elements of a matrix, let me
> explain it with a simple vector example
> 
> 
> > z<- c(1, 2, 3)
> > zz <- c(0,0,0)
> > null <- (z > 2) & ( zz <- z)
> > zz
> [1] 1 2 3
> 
> why zz is not (0, 0, 3) ?????
> 

Break it down into bits:

> z<- c(1, 2, 3)
> (z > 2)
[1] FALSE FALSE  TRUE
> ( zz <- z)
[1] 1 2 3
> (z > 2) & ( zz <- z)
[1] FALSE FALSE  TRUE
> TRUE & ( zz <- z)
[1] TRUE TRUE TRUE
> rep(TRUE,4) & ( zz <- z)
[1] TRUE TRUE TRUE TRUE
Warning message: 
longer object length
        is not a multiple of shorter object length in: rep(TRUE, 4) & (zz <- z) 

The first part is a logical vector, the second is the result of assigning 
z to zz, & of them isn't terribly meaningful?

Try:

> zz <- ifelse(z > 2, z, 0)
> zz
[1] 0 0 3

if that's what you want.

> 
> the null <- assignment is to keep the console silent
> 
> in the other hand, it curious that null has reasonable values
> 
> > null
> [1] FALSE FALSE  TRUE
> 
> Thanks in advance
> 
> 	Ulisses
> 
>                 Debian GNU/Linux: a dream come true
> -----------------------------------------------------------------------------
> "Computers are useless. They can only give answers."            Pablo Picasso
> 
> Humans are slow, innaccurate, and brilliant.
> Computers are fast, acurrate, and dumb. 
> Together they are unbeatable
> 
> --->	Visita http://www.valux.org/ para saber acerca de la	<---
> --->	Asociaci?n Valenciana de Usuarios de Linux		<---
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From cullens at tcd.ie  Mon Jan 26 20:46:44 2004
From: cullens at tcd.ie (Simon Cullen)
Date: Mon, 26 Jan 2004 19:46:44 -0000
Subject: [R] conditional assignment
In-Reply-To: <20040126191551.GA14785@pusa.informat.uv.es>
References: <20040126191551.GA14785@pusa.informat.uv.es>
Message-ID: <opr2eej6f01pelvz@smtp.tcd.ie>

On Mon, 26 Jan 2004 20:15:51 +0100, <uaca at alumni.uv.es> wrote:

> I want to conditionally operate on certain elements of a matrix, let me
> explain it with a simple vector example
>
>
>> z<- c(1, 2, 3)
>> zz <- c(0,0,0)
>> null <- (z > 2) & ( zz <- z)
>> zz
> [1] 1 2 3
>
> why zz is not (0, 0, 3) ?????
<snip>
>
> in the other hand, it curious that null has reasonable values
>
>> null
> [1] FALSE FALSE  TRUE

What you have done there is create a boolean vector, null, of the same  
length as z (and zz).

For instance:
(z > 2) & (zz <- z)
=(F F T) & (T T T) (as assignment - presumably - returns T)
=(F F T).

What will work is:
z <- c(1, 2, 3)
index <- z>2
zz <- z * index


-- 
SC

Simon Cullen
Room 3030
Dept. Of Economics
Trinity College Dublin

Ph. (608)3477
Email cullens at tcd.ie



From andy_liaw at merck.com  Mon Jan 26 21:10:44 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 26 Jan 2004 15:10:44 -0500
Subject: [R] conditional assignment
Message-ID: <3A822319EB35174CA3714066D590DCD504AF769B@usrymx25.merck.com>

> From: Simon Cullen
> On Mon, 26 Jan 2004 20:15:51 +0100, <uaca at alumni.uv.es> wrote:
> 
> > I want to conditionally operate on certain elements of a 
> matrix, let me
> > explain it with a simple vector example
> >
> >
> >> z<- c(1, 2, 3)
> >> zz <- c(0,0,0)
> >> null <- (z > 2) & ( zz <- z)
> >> zz
> > [1] 1 2 3
> >
> > why zz is not (0, 0, 3) ?????
> <snip>
> >
> > in the other hand, it curious that null has reasonable values
> >
> >> null
> > [1] FALSE FALSE  TRUE
> 
> What you have done there is create a boolean vector, null, of 
> the same  
> length as z (and zz).
> 
> For instance:
> (z > 2) & (zz <- z)
> =(F F T) & (T T T) (as assignment - presumably - returns T)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Don't think so.  zz <- z has the value z; i.e., c(1, 2, 3).  When evaluated
as logicals, non-zero values are treated as true (as in C), I believe.  For
example:

> z <- rep(0, 3)
> ifelse(zz <- z, 1, 0)
[1] 0 0 0
>  (zz <- z) == TRUE
[1] FALSE FALSE FALSE

However, what tripped me is the fact that even though non-zero is logically
`true', it's not necessarily equal to TRUE (which is numerically equal to
1):

> z <- 0:2
>  (zz <- z) == TRUE
[1] FALSE  TRUE FALSE
> ifelse(zz <- z, 1, 0)
[1] 0 1 1
> if(3) TRUE else FALSE
[1] TRUE

Andy




> =(F F T).
> 
> What will work is:
> z <- c(1, 2, 3)
> index <- z>2
> zz <- z * index
> 
> 
> -- 
> SC
> 
> Simon Cullen
> Room 3030
> Dept. Of Economics
> Trinity College Dublin
> 
> Ph. (608)3477
> Email cullens at tcd.ie


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ripley at stats.ox.ac.uk  Mon Jan 26 21:34:46 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jan 2004 20:34:46 +0000 (GMT)
Subject: [R] conditional assignment
In-Reply-To: <opr2eej6f01pelvz@smtp.tcd.ie>
Message-ID: <Pine.LNX.4.44.0401262031320.29456-100000@gannet.stats>

On Mon, 26 Jan 2004, Simon Cullen wrote:

> On Mon, 26 Jan 2004 20:15:51 +0100, <uaca at alumni.uv.es> wrote:
> 
> > I want to conditionally operate on certain elements of a matrix, let me
> > explain it with a simple vector example
> >
> >
> >> z<- c(1, 2, 3)
> >> zz <- c(0,0,0)
> >> null <- (z > 2) & ( zz <- z)
> >> zz
> > [1] 1 2 3
> >
> > why zz is not (0, 0, 3) ?????
> <snip>
> >
> > in the other hand, it curious that null has reasonable values
> >
> >> null
> > [1] FALSE FALSE  TRUE
> 
> What you have done there is create a boolean vector, null, of the same  
> length as z (and zz).
> 
> For instance:
> (z > 2) & (zz <- z)
> =(F F T) & (T T T) (as assignment - presumably - returns T)

assignment returns the new value of zz, which as it is all non-zero
coerces to the logical vector T T T

> =(F F T).
> 
> What will work is:
> z <- c(1, 2, 3)
> index <- z>2
> zz <- z * index

Rather better I think is

zz <- ifelse(z > 2, z, zz)

or even

ind <- z > 2
zz[ind] <- z[ind]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ffdsj at uaf.edu  Mon Jan 26 22:38:03 2004
From: ffdsj at uaf.edu (Devin Johnson)
Date: Mon, 26 Jan 2004 12:38:03 -0900
Subject: [R] HTML help pages
Message-ID: <401588BB.1020703@uaf.edu>

I am having trouble getting the HTML help pages to work. When I try the 
search engine I get an error on page response and nothing happens. When 
I try to click on the listed topics nothing happens. I am using both 
Mozilla and IE6 on XP and the same thing happens on each. Is there 
something I'm missing?

Thanks
-Devin Johnson



From rolf at math.unb.ca  Mon Jan 26 22:58:06 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 26 Jan 2004 17:58:06 -0400 (AST)
Subject: [R] HTML help pages
Message-ID: <200401262158.i0QLw6tY023106@erdos.math.unb.ca>

Devin Johnson wrote:

> I am having trouble getting the HTML help pages to work. When I try
> the search engine I get an error on page response and nothing
> happens. When I try to click on the listed topics nothing happens. I
> am using both Mozilla and IE6 on XP and the same thing happens on
> each. Is there something I'm missing?

I have (almost exactly) the same problem.

If I start an R session, do help.start(), and then say, e.g.

	?plot

the help comes up in the Mozilla window as it should.  But if I
attempt a search using the search engine in the window provided by
help.start(), nothing happens.

I don't any error from clicking on a topic, just a total lack
of response.

I'm using Mozilla and R 1.8.1 under Linux:

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    8.1              
year     2003             
month    11               
day      21               
language R                
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

I've no idea what the solution is.  This is contributed just to point
out that the problem is not unique.

					cheers,

						Rolf Turner
						rolf at math.unb.ca



From MSchwartz at medanalytics.com  Mon Jan 26 23:37:27 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 26 Jan 2004 16:37:27 -0600
Subject: [R] HTML help pages
In-Reply-To: <200401262158.i0QLw6tY023106@erdos.math.unb.ca>
References: <200401262158.i0QLw6tY023106@erdos.math.unb.ca>
Message-ID: <1075156646.16760.75.camel@localhost.localdomain>

On Mon, 2004-01-26 at 15:58, Rolf Turner wrote:
> Devin Johnson wrote:
> 
> > I am having trouble getting the HTML help pages to work. When I try
> > the search engine I get an error on page response and nothing
> > happens. When I try to click on the listed topics nothing happens. I
> > am using both Mozilla and IE6 on XP and the same thing happens on
> > each. Is there something I'm missing?
> 
> I have (almost exactly) the same problem.
> 
> If I start an R session, do help.start(), and then say, e.g.
> 
> 	?plot
> 
> the help comes up in the Mozilla window as it should.  But if I
> attempt a search using the search engine in the window provided by
> help.start(), nothing happens.
> 
> I don't any error from clicking on a topic, just a total lack
> of response.
> 
> I'm using Mozilla and R 1.8.1 under Linux:
> 
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
>          _                
> platform i686-pc-linux-gnu
> arch     i686             
> os       linux-gnu        
> system   i686, linux-gnu  
> status                    
> major    1                
> minor    8.1              
> year     2003             
> month    11               
> day      21               
> language R                
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
> 
> I've no idea what the solution is.  This is contributed just to point
> out that the problem is not unique.


In general, one key thing to check is when you click on the link for
"Search Engine & Keywords" after the help.start() page comes up, look at
the status line in Mozilla in the lower left hand corner.

It should indicate something to the effect of "Applet SearchEngine
Started".

If you do not see this message, then the Java applet has not been
initialized and the queries from the search page will not work. It takes
both Java and JavaScript to be functioning properly for the search
applet to work. If you do not see that message, it is a good indication
that there is a problem with your Java installation, which might include
Java and/or browser version conflict issues. Be sure to check the
browser release notes and/or Java installation notes as appropriate.

It has been a while since I have used IE (or even Windows for that
matter), but I am guessing that there should be a similar indication
there.

I am running R 1.8.1 Patched along with Firebird 0.7 and Mozilla 1.6
under Fedora Core 1 and have had no problems using the help.search()
mechanism with either browser.

FWIW, after the previously discussed issues with the installation of
Java and Mozilla, I stopped putting the oft discussed symlink to Java in
the Mozilla version specific folders (/usr/lib/mozilla-version/plugins)
and now put it in ~/.mozilla/plugins. While this makes the Java
installation user specific, I am the only user of my laptop. This does
however remove the need to redo the symlink everytime I upgrade Mozilla
and it also works for Firebird. The same goes for Flash, Helix and other
plugins.

HTH,

Marc Schwartz



From knicodem at jhsph.edu  Mon Jan 26 23:49:04 2004
From: knicodem at jhsph.edu (Kristin Kay Nicodemus)
Date: Mon, 26 Jan 2004 17:49:04 -0500
Subject: [R] write.table file="file.txt" help
Message-ID: <18f7e6192756.19275618f7e6@jhsph.edu>

Hi all,

I have a R script that creates several input files for an analysis 
program.  It loops through the matrix read into R and picks out 
submatrices and then creates a separate output file for each 
submatrix.  The loop works great, but I am having trouble getting all 
the separate output files written.

The line I have is:

write.table(ch1d, file="C:/WINDOWS/Desktop/SNPs/haplo.txt", 
row.names=F, col.names=F, append=F, quote=F)

Which works just fine if I just wanted to create a single file from the 
loop.  However, I need to somehow get it to change the name of the 
output file ("haplo.txt") each time it goes through the loop so it 
doesn't overwrite each time.  In perl, I'd create $n=1 and increment up 
each loop, and call the file something like "haplo.txt.$n"  

I tried to do something like that but R doesn't recognize the variable 
that would be $n in perl (because it's part of the quoted name of the 
output file).  Adding it after the ending " just gave me an error, as I 
thought it would.

I also tried to use system(copy ...) to change the name of the file in 
dos, but my knowledge of dos is abysmal, so I was unable to do it.

Any ideas on how to go about doing this would be most appreciated!

Thanks in advance,
KK Nicodemus



From abunn at montana.edu  Mon Jan 26 23:57:42 2004
From: abunn at montana.edu (Andy Bunn)
Date: Mon, 26 Jan 2004 15:57:42 -0700
Subject: [R] write.table file="file.txt" help
In-Reply-To: <18f7e6192756.19275618f7e6@jhsph.edu>
Message-ID: <001901c3e45f$dff6def0$78f05a99@msu.montana.edu>

Look at ?paste

for (j in 1:10) { 
   write.table(j, file=paste("haplo.txt", j, sep="."), 
               row.names=F, col.names=F, append=F, quote=F)
}

BTW, there have been many similar posts like this in the past. They are
easily found using the search function at 
http://cran.r-project.org/search.html 

HTH, Andy



From mcoquejr at yahoo.com.br  Tue Jan 27 00:34:57 2004
From: mcoquejr at yahoo.com.br (Marcos)
Date: Mon, 26 Jan 2004 21:34:57 -0200
Subject: [R] Function R
Message-ID: <MHEJLGKFDEGDDBJPNEKGIEPCCEAA.mcoquejr@yahoo.com.br>

Hello,

Please, I need a R function to optimize a function (maximizer ou minimizer)
under restriction.
What function do this?

Thank you.

Marcos



From knicodem at jhsph.edu  Tue Jan 27 00:34:42 2004
From: knicodem at jhsph.edu (Kristin Kay Nicodemus)
Date: Mon, 26 Jan 2004 18:34:42 -0500
Subject: [R] write.table file="file.txt" help
Message-ID: <19f20719d180.19d18019f207@jhsph.edu>

Thanks to Andy Bunn and Patrick Connolly for their help!

Kristin Nicodemus



From r-announce-bounces at stat.math.ethz.ch  Tue Jan 27 02:35:06 2004
From: r-announce-bounces at stat.math.ethz.ch (r-announce-bounces@stat.math.ethz.ch)
Date: Tue, 27 Jan 2004 02:35:06 +0100
Subject: [R] The results of your email commands
Message-ID: <mailman.782.1075167306.2313.r-announce@stat.math.ethz.ch>

The results of your email command are provided below. Attached is your
original message.

- Results:
    Ignoring non-text/plain MIME parts

- Done.

-------------- next part --------------
An embedded message was scrubbed...
From: r-help at stat.math.ethz.ch
Subject: HI
Date: Mon, 26 Jan 2004 20:34:25 -0500
Size: 913
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040127/469d74cf/attachment.mht

From sundar.dorai-raj at pdf.com  Tue Jan 27 00:04:16 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 26 Jan 2004 17:04:16 -0600
Subject: [R] write.table file="file.txt" help
In-Reply-To: <18f7e6192756.19275618f7e6@jhsph.edu>
References: <18f7e6192756.19275618f7e6@jhsph.edu>
Message-ID: <40159CF0.1000809@pdf.com>



Kristin Kay Nicodemus wrote:

> Hi all,
> 
> I have a R script that creates several input files for an analysis 
> program.  It loops through the matrix read into R and picks out 
> submatrices and then creates a separate output file for each 
> submatrix.  The loop works great, but I am having trouble getting all 
> the separate output files written.
> 
> The line I have is:
> 
> write.table(ch1d, file="C:/WINDOWS/Desktop/SNPs/haplo.txt", 
> row.names=F, col.names=F, append=F, quote=F)
> 
> Which works just fine if I just wanted to create a single file from the 
> loop.  However, I need to somehow get it to change the name of the 
> output file ("haplo.txt") each time it goes through the loop so it 
> doesn't overwrite each time.  In perl, I'd create $n=1 and increment up 
> each loop, and call the file something like "haplo.txt.$n"  
> 
> I tried to do something like that but R doesn't recognize the variable 
> that would be $n in perl (because it's part of the quoted name of the 
> output file).  Adding it after the ending " just gave me an error, as I 
> thought it would.
> 
> I also tried to use system(copy ...) to change the name of the file in 
> dos, but my knowledge of dos is abysmal, so I was unable to do it.
> 
> Any ideas on how to go about doing this would be most appreciated!
> 
> Thanks in advance,
> KK Nicodemus
> 

Use paste().

for(i in 1:n) {
   file <- paste("C:/WINDOWS/Desktop/SNPs/haplo", i, "txt", sep = ".")
   cat("Writing data to", file, "\n")
   write.table(ch1d, file=file,
             row.names=F, col.names=F, append=F, quote=F)
}

-sundar



From ripley at stats.ox.ac.uk  Tue Jan 27 08:50:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Jan 2004 07:50:19 +0000 (GMT)
Subject: [R] Fortran source code
In-Reply-To: <3E9F0ADC.358724CD.0B088159@aol.com>
Message-ID: <Pine.LNX.4.44.0401270747360.12264-100000@gannet.stats>

On Tue, 27 Jan 2004 DivineSAAM at aol.com wrote:

> 
> After spending 3 long days attempting to interface Fortran with
> R--having spent 1 week sifting through R-help and the horrific official
> documentation--I cannot emphasize in words the importance of consulting
> 1 and-only 1 reference:
> 
> Venables, W.N., B.D. Ripley, S Programming. Springer, New York, 2000.
> 
> My goodness gracious, I should have started with that book first, I
> would have saved an incredible amount of time. My interface to a rather
> long library subroutine was done and tested in less than 30 minutes!
> 
> My experience is posted in the hope that it will save someone TIME (the
> most precious of anything in the universe)
> 
> I hope an up-to-date and expanded version of that fabulous book is also
> in the works.

We have started work on a second edition but don't expect to see it until 
2005.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From DivineSAAM at aol.com  Tue Jan 27 06:33:37 2004
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Tue, 27 Jan 2004 00:33:37 -0500
Subject: [R] Fortran source code
Message-ID: <3E9F0ADC.358724CD.0B088159@aol.com>

Dear All,

After spending 3 long days attempting to interface Fortran with R--having spent 1 week sifting through R-help and the horrific official documentation--I cannot emphasize in words the importance of consulting 1 and-only 1 reference:

Venables, W.N., B.D. Ripley, S Programming. Springer, New York, 2000.

My goodness gracious, I should have started with that book first, I would have saved an incredible amount of time. My interface to a rather long library subroutine was done and tested in less than 30 minutes! 

My experience is posted in the hope that it will save someone TIME (the most precious of anything in the universe)

I hope an up-to-date and expanded version of that fabulous book is also in the works.

/Livin La Vida Loca



From grassi at psico.univ.trieste.it  Tue Jan 27 09:44:55 2004
From: grassi at psico.univ.trieste.it (Michele Grassi)
Date: Tue, 27 Jan 2004 09:44:55 +0100 (MET)
Subject: [R] psychology and logistic regression
Message-ID: <200401270844.JAA23035@server.psico.univ.trieste.it>

Hi.
I'm searching for information about logistic regression 
applyed on psychological data. Do you know any article 
in which this model has improve the analysis (e.g. 
unexpected significant results)?
Thanks a lot.
Michele



From paola.distefano at libero.it  Tue Jan 27 10:40:12 2004
From: paola.distefano at libero.it (paola.distefano@libero.it)
Date: Tue, 27 Jan 2004 10:40:12 +0100
Subject: [R] help help help
Message-ID: <HS56V0$8D19F038A72AE821614206966D3C0E2E@libero.it>

Hi,
I have a problem....
I need help about Generalized Estimating Equation. The response variable is "efficacy" (numeric) and the predictors are "eziology" (categoric) and "terapy" (string).
After downloaded the gee from CRAN I tried to use this procedure for example:

summary(gee(efficacy~eziology+terapy, id=?, data=pippo, corstr="exchangeable"))

Could you send me an example of application of GEE with two variables?
Thank you very much

Paola Di Stefano



From ripley at stats.ox.ac.uk  Tue Jan 27 11:19:34 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Jan 2004 10:19:34 +0000 (GMT)
Subject: [R] HTML help pages
In-Reply-To: <401588BB.1020703@uaf.edu>
Message-ID: <Pine.LNX.4.44.0401271002530.20871-100000@gannet.stats>

On Mon, 26 Jan 2004, Devin Johnson wrote:

> I am having trouble getting the HTML help pages to work. When I try the 
> search engine I get an error on page response and nothing happens. When 
> I try to click on the listed topics nothing happens. I am using both 
> Mozilla and IE6 on XP and the same thing happens on each. Is there 
> something I'm missing?

Did you check the rw-FAQ?  It says

 If the help search system does not work _at all_, this probably
 indicates that Java support is either not installed or not enabled in
 your browser.  Recent versions of browsers have made Java support
 optional: for example it is optional in Netscape 6/7 and in Opera, and
 may not be installed for IE6 on Windows XP.  You also need JavaScript
 enabled.

Marc Schwartz has already given a comprehensive Linux-oriented answer.  
In my recent experience on Windows (and I have set up XP boxes three times
recently) it will work provided

Java is installed and enabled
No one has altered the default security settings.

It is unlikely that Mozilla has Java enabled unless you took steps to
install a Sun Java JRE.  You can configure XP to use the Sun JRE, (in `set
Program Access and Defaults' on the start menu) but it will expect to use
the Microsoft Java VM.

As Marc says, Mozilla (and Netscape and Firebird) will show `Applet
SearchEngine started' in the bottom left corner.  I didn't see such a
message in IE6.  On the box I am writing this on I have just checked IE6
(fully patched), Netscape 7.1, Mozilla 1.6 and MozillaFirebird 0.7: they 
all work.


My experience with Linux and Solaris is that they are much harder to set 
up, and only some JRE versions work with some browsers.  (For example, I 
had Netscape 7.01 and Mozilla 1.4 working, but 7.1 and 1.6 required a JRE 
upgrade and that did not then work with 7.01 and 1.4.  Next thing the 
link to the required JRE on Sun's site got broken ....)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From christoph.lange at tuebingen.mpg.de  Tue Jan 27 11:42:47 2004
From: christoph.lange at tuebingen.mpg.de (Christoph Lange)
Date: Tue, 27 Jan 2004 11:42:47 +0100
Subject: [R] Directory-like data organisation w/ environments?
Message-ID: <20040127104247.GB20243@sesame.kyb.local>


Dear r-users!

I wonder if there is a way of designing a directory like structure for
holding my data using environments?

It would be nice if I could implement a kind of 'cd' command to change
to a differend environment etc.

Can anybody give me a hint?

-cl

-- 
Christoph Lange
MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|



From binita.dutta at vib.be  Tue Jan 27 13:12:31 2004
From: binita.dutta at vib.be (Binita Dutta)
Date: Tue, 27 Jan 2004 13:12:31 +0100
Subject: [R] Gene identification
Message-ID: <6.0.0.22.1.20040127130604.01af22e0@194.78.28.203>

Hi All,

I have done a very simple cDNA microarray experiment (Wild type -Cy5 Vs 
Mutant variety-Cy3 and color flip expriment on our mouse arrays). This 
experiment was repeated and i have results of all these four experiment. 
Using Marray norm i could normalise the data and have expoted M and A 
values on excel sheet. However, I need your suggestions to interpret the 
result using  R package (Genes  which are differentialyy expressed in 
mutant type compared to the wild type). I wanted to use multtest package 
but have not been able to get anything out from it yet.

Binita
Dr. Binita Dutta
MicroArray Facility(MAF)
UZ Gasthuisberg
Onderwijs en Navorsing
Herestraat 49
3000 Leuven
Belgium



From djw1005 at cam.ac.uk  Tue Jan 27 13:11:33 2004
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Tue, 27 Jan 2004 12:11:33 +0000 (GMT)
Subject: [R] HTML help pages
In-Reply-To: <Pine.LNX.4.44.0401271002530.20871-100000@gannet.stats>
Message-ID: <Pine.SOL.3.96.1040127120350.54A-100000@virgo.cus.cam.ac.uk>


On Tue, 27 Jan 2004, Prof Brian Ripley wrote:
> Did you check the rw-FAQ?  It says
>  If the help search system does not work _at all_, this probably
>  indicates that Java support is either not installed or not enabled in
>  your browser.  Recent versions of browsers have made Java support
>  optional: for example it is optional in Netscape 6/7 and in Opera, and
>  may not be installed for IE6 on Windows XP.  You also need JavaScript
>  enabled.

I might add one can test if Java support is installed+enabled by going to
  http://www.java.com/en/download/help/testvm.jsp
This is Sun's java test page.

My situation is that Java support is installed+enabled, but R help is
still not working. This indicates some issue to do with the
Javascript/Java interface. It might be paranoid security settings, though
I've turned of all the security options I can find.

Is there anyone running Mozilla Firebird 0.6 or 0.7 on Debian 3.0 who has
got HTML searching to work?

Damon.



From feh3k at spamcop.net  Tue Jan 27 13:46:12 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 27 Jan 2004 07:46:12 -0500
Subject: [R] HTML help pages
In-Reply-To: <Pine.SOL.3.96.1040127120350.54A-100000@virgo.cus.cam.ac.uk>
References: <Pine.LNX.4.44.0401271002530.20871-100000@gannet.stats>
	<Pine.SOL.3.96.1040127120350.54A-100000@virgo.cus.cam.ac.uk>
Message-ID: <20040127074612.292cb7d2.feh3k@spamcop.net>

On Tue, 27 Jan 2004 12:11:33 +0000 (GMT)
Damon Wischik <djw1005 at cam.ac.uk> wrote:

> 
> On Tue, 27 Jan 2004, Prof Brian Ripley wrote:
> > Did you check the rw-FAQ?  It says
> >  If the help search system does not work _at all_, this probably
> >  indicates that Java support is either not installed or not enabled in
> >  your browser.  Recent versions of browsers have made Java support
> >  optional: for example it is optional in Netscape 6/7 and in Opera,
> >  and may not be installed for IE6 on Windows XP.  You also need
> >  JavaScript enabled.
> 
> I might add one can test if Java support is installed+enabled by going
> to
>   http://www.java.com/en/download/help/testvm.jsp
> This is Sun's java test page.
> 
> My situation is that Java support is installed+enabled, but R help is
> still not working. This indicates some issue to do with the
> Javascript/Java interface. It might be paranoid security settings,
> though I've turned of all the security options I can find.
> 
> Is there anyone running Mozilla Firebird 0.6 or 0.7 on Debian 3.0 who
> has got HTML searching to work?

mozilla-firebird on Debian 3 does not work for me by default, even with
java and javascript activated.  I've always wondered whether there is a
way to implement this without java since the java approach has caused so
many problems for users and it seems to entail some overhead.

I routinely do options(browser='dillo'); help.start(); ?functionname.  The
menus do not work but html help file displays are fine, and extremely
quick.

Frank

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From andy_liaw at merck.com  Tue Jan 27 14:18:55 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 27 Jan 2004 08:18:55 -0500
Subject: [R] Directory-like data organisation w/ environments?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76A4@usrymx25.merck.com>

Would attaching a nested list be close to what you want?  E.g.,

> x <- list(y1 = list(z = matrix(1:4, 2, 2)), y2=matrix(0, 3, 2))
> attach(x)
> y2
     [,1] [,2]
[1,]    0    0
[2,]    0    0
[3,]    0    0
> attach(y1)
> z
     [,1] [,2]
[1,]    1    3
[2,]    2    4

You should be aware that the global environment is #1 on the search list,
and you can't attach anything else at position 1.  So if you have something
in the workspace that has the same name as in what you attach()'ed, the one
in the workspace is seen.

HTH,
Andy


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Christoph Lange
> Sent: Tuesday, January 27, 2004 5:43 AM
> To: R Help List
> Subject: [R] Directory-like data organisation w/ environments?
> 
> 
> 
> Dear r-users!
> 
> I wonder if there is a way of designing a directory like structure for
> holding my data using environments?
> 
> It would be nice if I could implement a kind of 'cd' command to change
> to a differend environment etc.
> 
> Can anybody give me a hint?
> 
> -cl
> 
> -- 
> Christoph Lange
> MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
> Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ripley at stats.ox.ac.uk  Tue Jan 27 14:26:31 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Jan 2004 13:26:31 +0000 (GMT)
Subject: [R] HTML help pages
In-Reply-To: <20040127074612.292cb7d2.feh3k@spamcop.net>
Message-ID: <Pine.LNX.4.44.0401271314470.21392-100000@gannet.stats>

On Tue, 27 Jan 2004, Frank E Harrell Jr wrote:

> On Tue, 27 Jan 2004 12:11:33 +0000 (GMT)
> Damon Wischik <djw1005 at cam.ac.uk> wrote:
> 
> > 
> > On Tue, 27 Jan 2004, Prof Brian Ripley wrote:
> > > Did you check the rw-FAQ?  It says
> > >  If the help search system does not work _at all_, this probably
> > >  indicates that Java support is either not installed or not enabled in
> > >  your browser.  Recent versions of browsers have made Java support
> > >  optional: for example it is optional in Netscape 6/7 and in Opera,
> > >  and may not be installed for IE6 on Windows XP.  You also need
> > >  JavaScript enabled.
> > 
> > I might add one can test if Java support is installed+enabled by going
> > to
> >   http://www.java.com/en/download/help/testvm.jsp
> > This is Sun's java test page.
> > 
> > My situation is that Java support is installed+enabled, but R help is
> > still not working. This indicates some issue to do with the
> > Javascript/Java interface. It might be paranoid security settings,
> > though I've turned of all the security options I can find.
> > 
> > Is there anyone running Mozilla Firebird 0.6 or 0.7 on Debian 3.0 who
> > has got HTML searching to work?
> 
> mozilla-firebird on Debian 3 does not work for me by default, even with
> java and javascript activated.  I've always wondered whether there is a
> way to implement this without java since the java approach has caused so
> many problems for users and it seems to entail some overhead.

Unfortunately, not that we have found.  What you can do with HTML in a
browser is limited.  We could either supply our own HTML-rendering widget,
or run our own HTTP server to talk to a standard browser.  Neither are
small enterprises.

It used not to cause many problems, and I think it rarely does on OSes
with Java support built-in.  There has been a rash of problems with
little-documented security changes and incorrect instructions.

My preferred option is to scale down people's expectations, and perhaps
say on the search page that this will only work if your system is set up
properly, but help.search() will always work.

How to manage help is one of a number of issues facing R (another is the 
introduction of UTF-8 locales and other internationalization issues) where 
a lot of work is needed that is not statistics and is of little benefit to 
developers.  They may not be deemed high enough priority.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From christoph.lange at tuebingen.mpg.de  Tue Jan 27 14:22:46 2004
From: christoph.lange at tuebingen.mpg.de (Christoph Lange)
Date: Tue, 27 Jan 2004 14:22:46 +0100
Subject: [R] Directory-like data organisation w/ environments?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF76A4@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF76A4@usrymx25.merck.com>
Message-ID: <20040127132246.GA23052@sesame.kyb.local>

(Reply to Liaw, Andy)

> Would attaching a nested list be close to what you want?  E.g.,
> 
> > x <- list(y1 = list(z = matrix(1:4, 2, 2)), y2=matrix(0, 3, 2))
> > attach(x)
> > y2
>      [,1] [,2]
> [1,]    0    0
> [2,]    0    0
> [3,]    0    0
> > attach(y1)
> > z
>      [,1] [,2]
> [1,]    1    3
> [2,]    2    4
> 
> [...]

Well, near to what I want. But I dream of a way to organize my data in
this tree-like structure as e.g. in Mathlab. - I'm just getting lost
in my data :-(

-cl

-- 
Christoph Lange
MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|



From kamoun_wassim at yahoo.fr  Tue Jan 27 15:32:04 2004
From: kamoun_wassim at yahoo.fr (=?iso-8859-1?q?Wassim=20Kamoum?=)
Date: Tue, 27 Jan 2004 15:32:04 +0100 (CET)
Subject: [R] package.
Message-ID: <20040127143204.95260.qmail@web41310.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040127/b20e57d6/attachment.pl

From djw1005 at cam.ac.uk  Tue Jan 27 15:33:08 2004
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Tue, 27 Jan 2004 14:33:08 +0000 (GMT)
Subject: [R] HTML help pages
In-Reply-To: <20040127074612.292cb7d2.feh3k@spamcop.net>
Message-ID: <Pine.SOL.3.96.1040127141430.7203A-100000@virgo.cus.cam.ac.uk>


On Tue, 27 Jan 2004, Frank E Harrell Jr wrote:
> I've always wondered whether there is a
> way to implement this without java since the java approach has caused so
> many problems for users and it seems to entail some overhead.

On my own pages, I've used Javascript for search rather than Java. You can
see how it works at
  http://www.wischik.com/damon/Recipe/index/search.html
The idea is to embed all of the index into the html page in XML-like
markup, and to have Javascript trawl through this list. Page download time
should be much the same (with the current R solution, the index file has
to be downloaded; with the Javascript, the index is downloaded as part of
the search page.) Searching will be a bit slower; whether that is
acceptable depends on the size of the index.

I'm glad to say I've finally got the searching to work in Mozilla Firebird
0.7. I think the problem is to do with this:
* Mozilla Firebird 0.7 requires Java 1.4 or later
* Java 1.4 from Sun does not properly support the Applet tag.

The solution (really a dirty non-standard hack), according to the Sun
documentation, is to use code like the following: 

<embed type="application/x-java-applet"
       code="SearchEngine.class"
       width="0" height="0"
       id="SearchEngine" 
       scriptable="true"
       INDEXFILE="index.txt">
</embed>

instead of the current

<applet
    code=SearchEngine.class
    name=SearchEngine
    width=0
    height=0 >
    <param name="INDEXFILE" value="index.txt">
</applet>

The official W3C position is that APPLET is deprecated in favour of
OBJECT, and EMBED is not even mentioned.

Damon.



From l.houdusse at cerep.fr  Tue Jan 27 15:43:40 2004
From: l.houdusse at cerep.fr (Laurent Houdusse)
Date: Tue, 27 Jan 2004 15:43:40 +0100
Subject: [R] Probability for ANOVA
Message-ID: <BA420EFAAC96D311A7A0006097D37BDB04515A02@EOLE>

Hi all!

I have  4 treatments on 5 animals
           Treat1   Treat2    Treat3    Treat4
Animal1      36       37        35       39
Animal2      33       34        36       37
Animal3      37       35        33       38
Animal4      34       36        34       35
Animal5      35       36        33       36

I use an Anova and i try to verify calcul
So i retrieve:
                    DF      SS       MS      F       P
Between Groups       3    20.950   6.983   3.492
Residual            16    32.000   2.000
Total               19    52.950   2.787

How can i calcul the p-Value? Is there a function to do this?


Laurent Houdusse 
Analyste Programmeur



From andy_liaw at merck.com  Tue Jan 27 15:55:27 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 27 Jan 2004 09:55:27 -0500
Subject: [R] Probability for ANOVA
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76A6@usrymx25.merck.com>

One way is:

> dat = read.table("clipboard", head=T, row=1)
> dat
        Treat1 Treat2 Treat3 Treat4
Animal1     36     37     35     39
Animal2     33     34     36     37
Animal3     37     35     33     38
Animal4     34     36     34     35
Animal5     35     36     33     36
> y <- unlist(dat)
> y
Treat11 Treat12 Treat13 Treat14 Treat15 Treat21 Treat22 Treat23 Treat24
Treat25 
     36      33      37      34      35      37      34      35      36
36 
Treat31 Treat32 Treat33 Treat34 Treat35 Treat41 Treat42 Treat43 Treat44
Treat45 
     35      36      33      34      33      39      37      38      35
36 
> trt = gl(4,5)
> trt
 [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4
Levels: 1 2 3 4
> summary(aov(y~trt))
            Df Sum Sq Mean Sq F value  Pr(>F)  
trt          3 20.950   6.983  3.4917 0.04033 *
Residuals   16 32.000   2.000                  
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

If you just want the p-value, given the ANOVA table, then you can do:

> pf(3.492, 3, 16, lower.tail=FALSE)
[1] 0.04032243



Andy
 

> From: Laurent Houdusse
> 
> Hi all!
> 
> I have  4 treatments on 5 animals
>            Treat1   Treat2    Treat3    Treat4
> Animal1      36       37        35       39
> Animal2      33       34        36       37
> Animal3      37       35        33       38
> Animal4      34       36        34       35
> Animal5      35       36        33       36
> 
> I use an Anova and i try to verify calcul
> So i retrieve:
>                     DF      SS       MS      F       P
> Between Groups       3    20.950   6.983   3.492
> Residual            16    32.000   2.000
> Total               19    52.950   2.787
> 
> How can i calcul the p-Value? Is there a function to do this?
> 
> 
> Laurent Houdusse 
> Analyste Programmeur
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From confirm-bounce-00365cf1f657196e5e3f7dbe393bcbff-r-help=lists.r-project.org at lists.mysql.com  Tue Jan 27 15:54:32 2004
From: confirm-bounce-00365cf1f657196e5e3f7dbe393bcbff-r-help=lists.r-project.org at lists.mysql.com (MySQL Lists Automoderator)
Date: 27 Jan 2004 14:54:32 -0000
Subject: [R] MySQL posting confirmation for r-help@lists.r-project.org
Message-ID: <20040127145432.9783.qmail@lists.mysql.com>

This is an automatic reply to an email you sent to a MySQL mailing address
protected by our 'self-moderation' system. To reduce the amount of spam
received at these addresses, we require you to confirm that you're a real
person before your email will be allowed through.

All you have to do in order to have your original message sent is click
on the following link (or cut-and-paste it to a browser):

 http://lists.mysql.com/c/00365cf1f657196e5e3f7dbe393bcbff/r-help at lists.r-project.org

After we have received your confirmation, "r-help at lists.r-project.org"
will be added to the list of pre-approved mail addresses for all of
the MySQL mailing lists, your original message will be delivered,
and future emails from that address will be delivered without
delay automatically.

You will not receive an emailed confirmation of your confirmation --
your original message (and any other messages you have sent since then)
will simply be sent to its original destination (possibly after a short
delay).

Sorry for the hassle, but the volume of unsolicited commercial email
sent to these addresses has made this step necessary.

--- Your original email is below.



From p.dalgaard at biostat.ku.dk  Tue Jan 27 16:20:13 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Jan 2004 16:20:13 +0100
Subject: [R] Probability for ANOVA
In-Reply-To: <BA420EFAAC96D311A7A0006097D37BDB04515A02@EOLE>
References: <BA420EFAAC96D311A7A0006097D37BDB04515A02@EOLE>
Message-ID: <x2u12h2zbm.fsf@biostat.ku.dk>

Laurent Houdusse <l.houdusse at cerep.fr> writes:

> Hi all!
> 
> I have  4 treatments on 5 animals
>            Treat1   Treat2    Treat3    Treat4
> Animal1      36       37        35       39
> Animal2      33       34        36       37
> Animal3      37       35        33       38
> Animal4      34       36        34       35
> Animal5      35       36        33       36
> 
> I use an Anova and i try to verify calcul
> So i retrieve:
>                     DF      SS       MS      F       P
> Between Groups       3    20.950   6.983   3.492
> Residual            16    32.000   2.000
> Total               19    52.950   2.787
> 
> How can i calcul the p-Value? Is there a function to do this?

Yes:

> 1-pf(3.492,3,16)
[1] 0.04032243

However, this might not be the appropriate analysis if the animals are
the same across treatments (not that it matters much in this case):

> summary(aov(y ~ treat, data=dd))
            Df Sum Sq Mean Sq F value  Pr(>F)
treat        3 20.950   6.983  3.4917 0.04033 *
Residuals   16 32.000   2.000
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> summary(aov(y ~ treat+animal, data=dd))
            Df  Sum Sq Mean Sq F value  Pr(>F)
treat        3 20.9500  6.9833  3.9343 0.03623 *
animal       4 10.7000  2.6750  1.5070 0.26146
Residuals   12 21.3000  1.7750
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From kasia at darwin.epbi.cwru.edu  Tue Jan 27 16:35:58 2004
From: kasia at darwin.epbi.cwru.edu (Catherine Stein)
Date: Tue, 27 Jan 2004 10:35:58 -0500 (EST)
Subject: [R] editing matrices (duh?)
Message-ID: <Pine.OSF.4.30.0401271034490.261769-100000@darwin.epbi.cwru.edu>


Hello all,

Sorry for the dumb question... Is there a way to edit matrices, like
delete a row and add a few new ones, without retyping the whole thing?

Thanks,
cathy


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Catherine M. Stein
Research Assistant, Tuberculosis Research Unit
Doctoral Candidate in Genetic Epidemiology
Department of Epidemiology and Biostatistics
Case Western Reserve University
office: (216)368-0875 or (216)778-1378
e-mail: kasia at darwin.cwru.edu, or cmstein at cwru.edu
http://darwin.cwru.edu/~kasia

EPBI Student Resources Page:
http://hal.epbi.cwru.edu/stures/
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From confirm-bounce-00365cf1f657196e5e3f7dbe393bcbff-r-help=lists.r-project.org at lists.mysql.com  Tue Jan 27 16:36:20 2004
From: confirm-bounce-00365cf1f657196e5e3f7dbe393bcbff-r-help=lists.r-project.org at lists.mysql.com (MySQL Lists Automoderator)
Date: 27 Jan 2004 15:36:20 -0000
Subject: [R] MySQL posting confirmation for r-help@lists.r-project.org
Message-ID: <20040127153620.25879.qmail@lists.mysql.com>

This is an automatic reply to an email you sent to a MySQL mailing address
protected by our 'self-moderation' system. To reduce the amount of spam
received at these addresses, we require you to confirm that you're a real
person before your email will be allowed through.

Unfortunately, we got a bounce for one of the confirmation emails we
already sent, so you've been added to the list of addresses which will
get bounced immediately.

In order to have yourself added to the list of real email addresses, and
removed from the list of those who have bounced, you need to click on the
following link (or cut-and-paste it to a browser):

 http://lists.mysql.com/c/00365cf1f657196e5e3f7dbe393bcbff/r-help at lists.r-project.org

After we have received your confirmation, "r-help at lists.r-project.org"
will be added to the list of pre-approved mail addresses for all of
the MySQL mail addresses and future emails from that address will be
delivered without delay automatically.

You will not receive an email confirmation of your confirmation -- future
messages will simply be sent along without delay.

Sorry for the hassle, but the volume of unsolicited commercial email
sent to these addresses has made this step necessary.

--- Your original email is below.



From r-eugenesalinas at comcast.net  Tue Jan 27 23:40:42 2004
From: r-eugenesalinas at comcast.net (Eugene Salinas (R))
Date: Tue, 27 Jan 2004 17:40:42 -0500
Subject: [R] asymptotic convergence of savitzky-golay? 
Message-ID: <4016E8EA.3060408@comcast.net>

Dear all,

Sorry if this is slightly off the track as far as R is concerned, but I 
have been using the Savitzky-Golay filter to estimate some derivatives 
of interest. I am wondering however, if anyone has seen anything in the 
literature (or has any ideas) of how these estimates perform 
asymptotically. Does anyone know what the rate of convergence is for these?

Thanks, matt.



From marie-pierre.sylvestre at mail.mcgill.ca  Tue Jan 27 22:10:28 2004
From: marie-pierre.sylvestre at mail.mcgill.ca (Marie-Pierre Sylvestre)
Date: Tue, 27 Jan 2004 16:10:28 -0500
Subject: [R] 'Cbinding' a variable number of vectors
Message-ID: <004801c3e519$ffb6d0a0$1392a8c0@epimgh.mcgill.ca>

I have a list of vectors named S11, S12, S13, etc. Vectors are of equal
length but the number of them may vary. I want to make a matrix S1 out of
them. I think 'cbind' is the best way to go. However, I would rather avoid
writing cbind(S11, S12, S13, etc) but instead use the 'sequential' nature of
the vector names to create my matrix S1. Say I have m vectors. Is there a
way to write something like:
L=1
while (L<=m) {
S1=cbind(S1,S1''L'')
}
Thanks in advance,
M-P Sylvestre



From ivo.welch at yale.edu  Wed Jan 28 01:02:00 2004
From: ivo.welch at yale.edu (ivo welch)
Date: Tue, 27 Jan 2004 19:02:00 -0500
Subject: [R] more graphics questions
Message-ID: <4016FBF8.3020104@yale.edu>


hi:  I think I have finally reached some tough(er) graphics questions, 
so help would be appreciated.


* In an ordinary log xy plot, I have two lines

lines( poslowess( x1, y1, f=0.11 ) );
lines( poslowess( x1, y2, f=0.11 ) );

y1 and "y2" are actually a "best" and "worst" scenario.  So, I am 
wondering whether it is tough/easy to shade the area between the two lines.


* I have a historical rate of stock return series (yes, I teach 
finance).  I would like to make a ts plot on the left 
(plot(date,returns,type="h")), and a plot(density(returns)) on the 
right.  works nicely with par(mfrow=c(1,2)), but it would be even nicer 
if I could rotate the density plot 90 degrees, so that it is more 
apparent that the density plot is an aggregation of the points at the 
same y coordinates.  (if need be, a histogram could replace the density 
plot.)  Is it possible to rotate an entire figure.  the "horizontal" 
parameter to ps.options is not an option for plot afaik.


* on an easier question, I got beat:  how do I make the tickmarks appear 
*inside* the graph, and shrink the distance between the tick text and 
the tick axis?


help appreciated.  apologies for imposing on everyone's time.

regards, /iaw



From a0108661 at unet.univie.ac.at  Tue Jan 27 19:50:39 2004
From: a0108661 at unet.univie.ac.at (Wilhelm Dollmann)
Date: Tue, 27 Jan 2004 19:50:39 +0100
Subject: [R] Membership
Message-ID: <4016B2FF.3020305@unet.univie.ac.at>

I'd like to be a member at the R-help List.
Name Wilhelm Dollmann



From giampi at speech.kth.se  Tue Jan 27 18:02:53 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Tue, 27 Jan 2004 18:02:53 +0100 (CET)
Subject: [R] R and unix tool 'screen'
In-Reply-To: <001901c3e45f$dff6def0$78f05a99@msu.montana.edu>
References: <001901c3e45f$dff6def0$78f05a99@msu.montana.edu>
Message-ID: <Pine.LNX.4.58.0401271751170.5117@bayes.speech.kth.se>

I have problems running R with screen. For those who don't know,
screen is a unix tool that is quite handy if you want to leave
a process (that outputs to tty) running when you logout, and
then recover the session later on.

It works like this:
1) run 'screen': you get a normal prompt as if you were in a normal
shell.
2) run whatever command you like
3) press 'C-a d' to detach the session. Now you can logoff if you like
4) when you want to recover the session type 'screen -r'

The problem is that R seems to catch the 'C-a' signal, and nothing happens.
Since there is no way to detach the screen, there is no use to it either.

Is there a way around this problem?

Giampiero
_________________________________________________________
Giampiero Salvi, M.Sc.          www.speech.kth.se/~giampi
Speech, Music and Hearing       Tel:      +46-8-790 75 62
Royal Institute of Technology   Fax:      +46-8-790 78 54
Drottning Kristinasv. 31,  SE-100 44,  Stockholm,  Sweden



From jennysmith551 at yahoo.com  Wed Jan 28 07:10:36 2004
From: jennysmith551 at yahoo.com (jenny smith)
Date: Tue, 27 Jan 2004 22:10:36 -0800 (PST)
Subject: [R] 'subscript out of bounds'
Message-ID: <20040128061036.43565.qmail@web21504.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040127/092dcc1c/attachment.pl

From r-eugenesalinas at comcast.net  Wed Jan 28 00:46:28 2004
From: r-eugenesalinas at comcast.net (Eugene Salinas (R))
Date: Tue, 27 Jan 2004 18:46:28 -0500
Subject: [R] asymptotic convergence of savitzky-golay?
Message-ID: <4016F854.60207@comcast.net>

Dear all,

Sorry if this is slightly off the track as far as R is concerned, but I 
have been using the Savitzky-Golay filter to estimate some derivatives 
of interest. I am wondering however, if anyone has seen anything in the 
literature (or has any ideas) of how these estimates perform 
asymptotically. Does anyone know what the rate of convergence is for these?

Thanks.



From p.connolly at hortresearch.co.nz  Tue Jan 27 21:29:21 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Wed, 28 Jan 2004 09:29:21 +1300
Subject: [R] HTML help pages
In-Reply-To: <Pine.LNX.4.44.0401271314470.21392-100000@gannet.stats>;
	from ripley@stats.ox.ac.uk on Tue, Jan 27, 2004 at 01:26:31PM
	+0000
References: <20040127074612.292cb7d2.feh3k@spamcop.net>
	<Pine.LNX.4.44.0401271314470.21392-100000@gannet.stats>
Message-ID: <20040128092921.Q935@hortresearch.co.nz>

On Tue, 27-Jan-2004 at 01:26PM +0000, Prof Brian Ripley wrote:


|> My preferred option is to scale down people's expectations, and
|> perhaps say on the search page that this will only work if your
|> system is set up properly, but help.search() will always work.

Java doesn't seem to present a problem with clunky old Netscape 4.7x
if anyone still has one hanging around.  That could be considered
scaling down expectations.

Simpler and more satisfactory, IMHO, is to use ? or C-c C-v in ESS
sometimes in conjunction with help.search().  Links to other help
files require a 'h' and <Enter>.  Does everything I need and I'm yet
to be convinced that's a scaling down.

Just in case anyone didn't know:  ESS is brilliant!

HTH

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From sundar.dorai-raj at pdf.com  Tue Jan 27 21:00:59 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 27 Jan 2004 14:00:59 -0600
Subject: [R] distance between two matrices
Message-ID: <4016C37B.9010203@pdf.com>

Hi all,
   Say I have a matrix A with dimension m x 2 and matrix B with 
dimension n x 2. I would like to find the row in A that is closest to 
the each row in B. Here's an example (using a loop):

set.seed(1)
A <- matrix(runif(12), 6, 2) # 6 x 2
B <- matrix(runif(6), 3, 2)  # 3 x 2
m <- vector("numeric", nrow(B))
for(j in 1:nrow(B)) {
   d <- (A[, 1] - B[j, 1])^2 + (A[, 2] - B[j, 2])^2
   m[j] <- which.min(d)
}

All I need is m[]. I would like to accomplish this without using the 
loop if possible, since for my real data n > 140K and m > 1K. I hope 
this makes sense.

Thanks,
Sundar



From jfox at mcmaster.ca  Tue Jan 27 16:32:47 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 27 Jan 2004 10:32:47 -0500
Subject: [R] Directory-like data organisation w/ environments?
In-Reply-To: <20040127104247.GB20243@sesame.kyb.local>
Message-ID: <5.0.2.1.0.20040127103137.02455ca8@127.0.0.1>

Dear Christoph,

Take a look at the cd function (and others) in the mvbutils package.

I hope that this helps,
  John

At 11:42 AM 1/27/2004 +0100, Christoph Lange wrote:

>Dear r-users!
>
>I wonder if there is a way of designing a directory like structure for
>holding my data using environments?
>
>It would be nice if I could implement a kind of 'cd' command to change
>to a differend environment etc.
>
>Can anybody give me a hint?
>
>-cl

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From jun at galton.uchicago.edu  Tue Jan 27 17:52:13 2004
From: jun at galton.uchicago.edu (Mikyoung Jun)
Date: Tue, 27 Jan 2004 10:52:13 -0600 (CST)
Subject: [R] subplot command?
Message-ID: <Pine.LNX.4.44.0401271050001.5247-100000@paolu.uchicago.edu>

Hello,

I am wondering whether there is a command in R which does similar things
as "subplot" command in S. I am trawing a map of USA and parts of Canada
and I want to add two subplots in the same plot which show some parts of
the states. Thank you very much in advance.

Mikyoung Jun



From jbdunsmo at utmb.edu  Tue Jan 27 22:50:00 2004
From: jbdunsmo at utmb.edu (Jason Dunsmore)
Date: Tue, 27 Jan 2004 15:50:00 -0600
Subject: [R] modified bonferroni correction
Message-ID: <4016DD08.7060804@utmb.edu>

hi, is there a good way of doing a modified (less stringent) bonferroni 
correction in R?  if so could you give an example?

thanks,
jason dunsmore



From eTrust_InoculateIT_Lotus_Notes_Domino_Option at copesa.cl  Wed Jan 28 09:24:21 2004
From: eTrust_InoculateIT_Lotus_Notes_Domino_Option at copesa.cl (eTrust_InoculateIT_Lotus_Notes_Domino_Option@copesa.cl)
Date: Wed, 28 Jan 2004 04:24:21 -0400
Subject: [R] eTrust InoculateIT Lotus Notes Domino Option detected virus!
Message-ID: <OFE9421F29.C9B07054-ON04256E29.000FD693@copesa.cl>


eTrust InoculateIT Lotus Notes Domino Option detected a virus infection in
an e-mail from [r-help at lists.r-project.org] to [cdisegni at mapocho.copesa.cl]
with subject [SERVER REPORT].  Infected attachment(s):  [message.cmd]
Action taken:  File Cured



From christian.hoffmann at wsl.ch  Tue Jan 27 16:51:18 2004
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Tue, 27 Jan 2004 16:51:18 +0100
Subject: [R] refman.pdf broken?
Message-ID: <401688F6.8060203@wsl.ch>

Hi,

Here at WSL we installed R-1.8.1 from the sources. We got, however, 
errors when compiling refman.pdf. The resulting file was not readable in 
Acrobat's reader. We then did

dvips -o refman.ps -ta4 refman.dvi
ps2pdf refman.ps refman.pdf

Now the .pdf is readable, but has no internal hyperlinks. It is not 
possible to search for strings inside the pdf.

Is this intentional, or did we miss a switch?

Is there a file refman.html? We did not find it per Google.

Thanks
Christian
-- 
Dr.sc.math.Christian W. Hoffmann, 
http://www.wsl.ch/staff/christian.hoffmann
Mathematics + Statistical Computing   e-mail: hoffmacw at wsl.ch
Swiss Federal Research Institute WSL  Tel: ++41-1-73922..  ..77  (self)
CH-8903 Birmensdorf, Switzerland           ..11(exchange), ..15  (Fax)
Zuercherstrasse 111



From giampi at speech.kth.se  Wed Jan 28 10:21:56 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Wed, 28 Jan 2004 10:21:56 +0100 (CET)
Subject: [R] R and unix tool 'screen'
In-Reply-To: <Pine.LNX.4.44.0401280836370.23392-100000@gannet.stats>
References: <Pine.LNX.4.44.0401280836370.23392-100000@gannet.stats>
Message-ID: <Pine.LNX.4.58.0401281014180.8778@bayes.speech.kth.se>

Hi,

On Wed, 28 Jan 2004, Prof Brian Ripley wrote:

> C-a is not a `signal' but a normal key sequence, and one used by
> readline.  However,

Sorry for the wrong terminology.

I tried it again and it works now (even with readline, on RH9.0).
The only way I can explain the problem I got yesterday is that the
computer reacted very slowly (possibly for high load). Strangely
enough, I had tried it on four different computers with the same
result...

Thank you for your help.
Giampiero

>
> screen R
> ctrl-a d
> [detached]
> screen -r
>
> works for me apart from not having the usual meaning of crtl-a.  I don't
> think R is doing anything special, but some versions of readline could
> conceivably be.
>
> I used RH8.0 Linux for this test.  I would suggest trying R --no-readline
> in case your version of readline is setting the terminal in a way that
> conflicts with your version of `screen'.
>
> On Tue, 27 Jan 2004, Giampiero Salvi wrote:
>
> > I have problems running R with screen. For those who don't know,
> > screen is a unix tool that is quite handy if you want to leave
> > a process (that outputs to tty) running when you logout, and
> > then recover the session later on.
> >
> > It works like this:
> > 1) run 'screen': you get a normal prompt as if you were in a normal
> > shell.
> > 2) run whatever command you like
> > 3) press 'C-a d' to detach the session. Now you can logoff if you like
> > 4) when you want to recover the session type 'screen -r'
> >
> > The problem is that R seems to catch the 'C-a' signal, and nothing happens.
> > Since there is no way to detach the screen, there is no use to it either.
> >
> > Is there a way around this problem?
> >
> > Giampiero
> > _________________________________________________________
> > Giampiero Salvi, M.Sc.          www.speech.kth.se/~giampi
> > Speech, Music and Hearing       Tel:      +46-8-790 75 62
> > Royal Institute of Technology   Fax:      +46-8-790 78 54
> > Drottning Kristinasv. 31,  SE-100 44,  Stockholm,  Sweden
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From ripley at stats.ox.ac.uk  Wed Jan 28 09:34:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jan 2004 08:34:55 +0000 (GMT)
Subject: [R] distance between two matrices
In-Reply-To: <4016C37B.9010203@pdf.com>
Message-ID: <Pine.LNX.4.44.0401280828440.23392-100000@gannet.stats>

Sounds like knn classification.  See function knn1 in package class.

> knn(A, B, 1:nrow(A))

gives the same answers as your loop code, and is just a carefully tuned C 
equivalent.

There are faster ways to do this by preprocessing set A discussed e.g. in 
my PRNN book but your numbers took only 11s on my PC.

On Tue, 27 Jan 2004, Sundar Dorai-Raj wrote:

> Hi all,
>    Say I have a matrix A with dimension m x 2 and matrix B with 
> dimension n x 2. I would like to find the row in A that is closest to 
> the each row in B. Here's an example (using a loop):
> 
> set.seed(1)
> A <- matrix(runif(12), 6, 2) # 6 x 2
> B <- matrix(runif(6), 3, 2)  # 3 x 2
> m <- vector("numeric", nrow(B))
> for(j in 1:nrow(B)) {
>    d <- (A[, 1] - B[j, 1])^2 + (A[, 2] - B[j, 2])^2
>    m[j] <- which.min(d)
> }
> 
> All I need is m[]. I would like to accomplish this without using the 
> loop if possible, since for my real data n > 140K and m > 1K. I hope 
> this makes sense.
> 
> Thanks,
> Sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Jan 28 09:50:16 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jan 2004 08:50:16 +0000 (GMT)
Subject: [R] R and unix tool 'screen'
In-Reply-To: <Pine.LNX.4.58.0401271751170.5117@bayes.speech.kth.se>
Message-ID: <Pine.LNX.4.44.0401280836370.23392-100000@gannet.stats>

C-a is not a `signal' but a normal key sequence, and one used by 
readline.  However,

screen R
ctrl-a d
[detached]
screen -r

works for me apart from not having the usual meaning of crtl-a.  I don't
think R is doing anything special, but some versions of readline could 
conceivably be.

I used RH8.0 Linux for this test.  I would suggest trying R --no-readline
in case your version of readline is setting the terminal in a way that 
conflicts with your version of `screen'.

On Tue, 27 Jan 2004, Giampiero Salvi wrote:

> I have problems running R with screen. For those who don't know,
> screen is a unix tool that is quite handy if you want to leave
> a process (that outputs to tty) running when you logout, and
> then recover the session later on.
> 
> It works like this:
> 1) run 'screen': you get a normal prompt as if you were in a normal
> shell.
> 2) run whatever command you like
> 3) press 'C-a d' to detach the session. Now you can logoff if you like
> 4) when you want to recover the session type 'screen -r'
> 
> The problem is that R seems to catch the 'C-a' signal, and nothing happens.
> Since there is no way to detach the screen, there is no use to it either.
> 
> Is there a way around this problem?
> 
> Giampiero
> _________________________________________________________
> Giampiero Salvi, M.Sc.          www.speech.kth.se/~giampi
> Speech, Music and Hearing       Tel:      +46-8-790 75 62
> Royal Institute of Technology   Fax:      +46-8-790 78 54
> Drottning Kristinasv. 31,  SE-100 44,  Stockholm,  Sweden
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fredrik.karlsson at ling.umu.se  Wed Jan 28 09:46:04 2004
From: fredrik.karlsson at ling.umu.se (Fredrik Karlsson)
Date: Wed, 28 Jan 2004 09:46:04 +0100
Subject: [R] R and unix tool 'screen'
In-Reply-To: <Pine.LNX.4.58.0401271751170.5117@bayes.speech.kth.se>
References: <001901c3e45f$dff6def0$78f05a99@msu.montana.edu>
	<Pine.LNX.4.58.0401271751170.5117@bayes.speech.kth.se>
Message-ID: <20040128084604.GA11354@ling.umu.se>

Hej Giampiero!

Odd. Using Screen version 3.09.11 and R-1.8.0 on a
Debian system, R does not trap C-a. I can fire up R in a screen, create
a new screen with C-a c and even detach/reattach the screen session.
The terminal emulator is xterm.

Perhaps you are using a terminal that traps the C-a? (just a wild 
guess..).

Mvh,

/Fredrik Karlsson

On Tue, Jan 27, 2004 at 06:02:53PM +0100, Giampiero Salvi wrote:
> I have problems running R with screen. For those who don't know,
> screen is a unix tool that is quite handy if you want to leave
> a process (that outputs to tty) running when you logout, and
> then recover the session later on.
> 
> It works like this:
> 1) run 'screen': you get a normal prompt as if you were in a normal
> shell.
> 2) run whatever command you like
> 3) press 'C-a d' to detach the session. Now you can logoff if you like
> 4) when you want to recover the session type 'screen -r'
> 
> The problem is that R seems to catch the 'C-a' signal, and nothing happens.
> Since there is no way to detach the screen, there is no use to it either.
> 
> Is there a way around this problem?
> 
> Giampiero



From Detlef.Steuer at unibw-hamburg.de  Wed Jan 28 09:25:21 2004
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Wed, 28 Jan 2004 09:25:21 +0100
Subject: [R] R and unix tool 'screen'
In-Reply-To: <Pine.LNX.4.58.0401271751170.5117@bayes.speech.kth.se>
References: <001901c3e45f$dff6def0$78f05a99@msu.montana.edu>
	<Pine.LNX.4.58.0401271751170.5117@bayes.speech.kth.se>
Message-ID: <20040128092521.54687c6f@gaia.unibw-hamburg.de>

Hi!

No such problem here. SuSE 9.0, R-1.8.1, screen 4.0.1
Everything works as intended.

If C-a d doesn't work, you can always try screen -D as described in 
the man page.

Hej da

detlef

On Tue, 27 Jan 2004 18:02:53 +0100 (CET)
Giampiero Salvi <giampi at speech.kth.se> wrote:

> I have problems running R with screen. For those who don't know,
> screen is a unix tool that is quite handy if you want to leave
> a process (that outputs to tty) running when you logout, and
> then recover the session later on.
> 
> It works like this:
> 1) run 'screen': you get a normal prompt as if you were in a normal
> shell.
> 2) run whatever command you like
> 3) press 'C-a d' to detach the session. Now you can logoff if you like
> 4) when you want to recover the session type 'screen -r'
> 
> The problem is that R seems to catch the 'C-a' signal, and nothing happens.
> Since there is no way to detach the screen, there is no use to it either.
> 
> Is there a way around this problem?
> 
> Giampiero
> _________________________________________________________
> Giampiero Salvi, M.Sc.          www.speech.kth.se/~giampi
> Speech, Music and Hearing       Tel:      +46-8-790 75 62
> Royal Institute of Technology   Fax:      +46-8-790 78 54
> Drottning Kristinasv. 31,  SE-100 44,  Stockholm,  Sweden
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****

"Die herrschenden Ideen sind die Ideen der Herrschenden."
--- K. Marx



From l.houdusse at cerep.fr  Wed Jan 28 11:48:12 2004
From: l.houdusse at cerep.fr (Laurent Houdusse)
Date: Wed, 28 Jan 2004 11:48:12 +0100
Subject: [R] Install R connector Server
Message-ID: <BA420EFAAC96D311A7A0006097D37BDB04515A07@EOLE>

Hi all!
 
I use the R-(D)COM Interface in a Visual Basic program.
I added a refrerence in my project to StatConnectorSrv 1.1 Type Library
(StatConnectorSrv.exe)
How to deploy my program? I added StatConnectorSrv.exe but it's not
enought...
What are the dependences?
 
Thanks



Laurent Houdusse 
Analyste Programmeur



From l.houdusse at cerep.fr  Wed Jan 28 11:48:12 2004
From: l.houdusse at cerep.fr (Laurent Houdusse)
Date: Wed, 28 Jan 2004 11:48:12 +0100
Subject: [R] Install R connector Server
Message-ID: <BA420EFAAC96D311A7A0006097D37BDB04515A07@EOLE>

Hi all!
 
I use the R-(D)COM Interface in a Visual Basic program.
I added a refrerence in my project to StatConnectorSrv 1.1 Type Library
(StatConnectorSrv.exe)
How to deploy my program? I added StatConnectorSrv.exe but it's not
enought...
What are the dependences?
 
Thanks



Laurent Houdusse 
Analyste Programmeur



From sekemp at glam.ac.uk  Wed Jan 28 11:27:39 2004
From: sekemp at glam.ac.uk (Samuel Kemp (Comp))
Date: Wed, 28 Jan 2004 10:27:39 +0000
Subject: [R] plotting ARIMA fit
Message-ID: <40178E9B.8050704@glam.ac.uk>

Hi,

The tsdiag function is good to check the residuals but does anyone know 
of a function to plot a fitted ARIMA model against the actual time 
series to check the fit of the model? I have been googling around and 
can't find anything.

Cheers,

Sam.



From tripoli at med.unibs.it  Wed Jan 28 11:31:52 2004
From: tripoli at med.unibs.it (Massimiliano Tripoli)
Date: Wed, 28 Jan 2004 11:31:52 +0100
Subject: [R] dates function
Message-ID: <006d01c3e589$f220ec30$5a1aa7c0@pc2690>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040128/56c8e525/attachment.pl

From tripoli at med.unibs.it  Wed Jan 28 11:50:11 2004
From: tripoli at med.unibs.it (Massimiliano Tripoli)
Date: Wed, 28 Jan 2004 11:50:11 +0100
Subject: [R] Julian dates
Message-ID: <00a401c3e58c$80a70f00$5a1aa7c0@pc2690>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040128/1d860b5e/attachment.pl

From mcoquejr at yahoo.com.br  Tue Jan 27 17:22:59 2004
From: mcoquejr at yahoo.com.br (Marcos)
Date: Tue, 27 Jan 2004 14:22:59 -0200
Subject: [R] GRAPH
Message-ID: <MHEJLGKFDEGDDBJPNEKGGEPJCEAA.mcoquejr@yahoo.com.br>

How do to make a plot() and contour() in the same Graph sheet?

Marcos



From tripoli at med.unibs.it  Wed Jan 28 13:13:30 2004
From: tripoli at med.unibs.it (Massimiliano Tripoli)
Date: Wed, 28 Jan 2004 13:13:30 +0100
Subject: [R] Julian Dates
Message-ID: <00fa01c3e598$24ae0580$5a1aa7c0@pc2690>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040128/9bddef20/attachment.pl

From Roger.Bivand at nhh.no  Wed Jan 28 11:08:33 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 28 Jan 2004 11:08:33 +0100 (CET)
Subject: [R] distance between two matrices
In-Reply-To: <4016C37B.9010203@pdf.com>
Message-ID: <Pine.LNX.4.44.0401281100070.32017-100000@reclus.nhh.no>

On Tue, 27 Jan 2004, Sundar Dorai-Raj wrote:

> Hi all,
>    Say I have a matrix A with dimension m x 2 and matrix B with 
> dimension n x 2. I would like to find the row in A that is closest to 
> the each row in B. Here's an example (using a loop):
> 
> set.seed(1)
> A <- matrix(runif(12), 6, 2) # 6 x 2
> B <- matrix(runif(6), 3, 2)  # 3 x 2
> m <- vector("numeric", nrow(B))
> for(j in 1:nrow(B)) {
>    d <- (A[, 1] - B[j, 1])^2 + (A[, 2] - B[j, 2])^2
>    m[j] <- which.min(d)
> }
> 
> All I need is m[]. I would like to accomplish this without using the 
> loop if possible, since for my real data n > 140K and m > 1K. I hope 
> this makes sense.

I think you need a quadtree of the larger set of points, the do lookup for 
buckets of the smaller one. There is a good deal of information on

http://www.cs.umd.edu/~brabec/quadtree/

This isn't an answer within R, the functionality in the gstat contributed
package doesn't seem to be at the user level, but it does point to the
same site at UMD. 

Roger


> 
> Thanks,
> Sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From sdavis2 at mail.nih.gov  Wed Jan 28 11:52:59 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 28 Jan 2004 05:52:59 -0500
Subject: [R] modified bonferroni correction
References: <4016DD08.7060804@utmb.edu>
Message-ID: <002501c3e58c$e539abd0$2f643744@WATSON>

Jason

See ?p.adjust.

Sean

----- Original Message -----
From: "Jason Dunsmore" <jbdunsmo at utmb.edu>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, January 27, 2004 4:50 PM
Subject: [R] modified bonferroni correction


> hi, is there a good way of doing a modified (less stringent) bonferroni
> correction in R?  if so could you give an example?
>
> thanks,
> jason dunsmore
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From sdavis2 at mail.nih.gov  Wed Jan 28 12:16:51 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 28 Jan 2004 06:16:51 -0500
Subject: [R] distance between two matrices
References: <4016C37B.9010203@pdf.com>
Message-ID: <004901c3e590$3a5f6ed0$2f643744@WATSON>

Sundar,

I'm not sure how much faster (or slower) this might be (perhaps Professor
Ripley will help on this one), but one can "trick" a function from the class
package called knn1 into doing this for you, I think.  From your example:

> set.seed(1)
> A <- matrix(runif(12), 6, 2) # 6 x 2
> B <- matrix(runif(6), 3, 2)  # 3 x 2
> m <- vector("numeric", nrow(B))
> for(j in 1:nrow(B)) {
+    d <- (A[, 1] - B[j, 1])^2 + (A[, 2] - B[j, 2])^2
+    m[j] <- which.min(d)
+ }
> m
[1] 3 2 3

Now using knn1:

 > knn1(A,B,seq(1,nrow(A),1))
[1] 3 2 3
Levels: 1 2 3 4 5 6

Sean

----- Original Message -----
From: "Sundar Dorai-Raj" <sundar.dorai-raj at pdf.com>
To: "R-help" <r-help at stat.math.ethz.ch>
Sent: Tuesday, January 27, 2004 3:00 PM
Subject: [R] distance between two matrices


> Hi all,
>    Say I have a matrix A with dimension m x 2 and matrix B with
> dimension n x 2. I would like to find the row in A that is closest to
> the each row in B. Here's an example (using a loop):
>
> set.seed(1)
> A <- matrix(runif(12), 6, 2) # 6 x 2
> B <- matrix(runif(6), 3, 2)  # 3 x 2
> m <- vector("numeric", nrow(B))
> for(j in 1:nrow(B)) {
>    d <- (A[, 1] - B[j, 1])^2 + (A[, 2] - B[j, 2])^2
>    m[j] <- which.min(d)
> }
>
> All I need is m[]. I would like to accomplish this without using the
> loop if possible, since for my real data n > 140K and m > 1K. I hope
> this makes sense.
>
> Thanks,
> Sundar
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From stecalza at tiscali.it  Wed Jan 28 13:41:27 2004
From: stecalza at tiscali.it (Stefano Calza)
Date: Wed, 28 Jan 2004 13:41:27 +0100
Subject: [R] Julian dates
In-Reply-To: <00a401c3e58c$80a70f00$5a1aa7c0@pc2690>
References: <00a401c3e58c$80a70f00$5a1aa7c0@pc2690>
Message-ID: <20040128124126.GA1504@med.unibs.it>

I guess there's a "bug" in chron as you cannot pass the argument cut.off to year.expand. Adding ,... in chron arguments and along the code ,... to convert.dates does the trick.

HIH,

Stefano

On Wed, Jan 28, 2004 at 11:50:11AM +0100, Massimiliano Tripoli wrote:
> Hi all,
> I have problems with years of dates using "chron" package.
> I don't understand why R by this istruction:
> > dates("01/02/29",out.format="d/m/year")
> [1] 02/Jan/2029
> 
> > dates("01/02/30",out.format="d/m/year")
> [1] 02/Jan/1930
> 
> reads "29" as 2029
> and "30" as 1930. How could I change to read "00" to "05" like 2000 to 2005 and "06" to "99" like 1906 to 1999 ?
> Thank you
>  
> Massimiliano
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From johannes.huesing at medizin.uni-essen.de  Wed Jan 28 13:42:58 2004
From: johannes.huesing at medizin.uni-essen.de (=?iso-8859-1?Q?=22H=FCsing=2C_Johannes=22?=)
Date: Wed, 28 Jan 2004 13:42:58 +0100
Subject: [R] distance between two matrices
Message-ID: <B3A80C9C13928B45B2FCE4C43656363A0194E3EE@mail-srv02.master.medizin.uni-essen.de>

> Hi all,
>    Say I have a matrix A with dimension m x 2 and matrix B with 
> dimension n x 2. I would like to find the row in A that is closest to 
> the each row in B. Here's an example (using a loop):
> 
> set.seed(1)
> A <- matrix(runif(12), 6, 2) # 6 x 2
> B <- matrix(runif(6), 3, 2)  # 3 x 2
> m <- vector("numeric", nrow(B))

make the lines below a function of a vector argument and 
apply it over the rows of B.

?apply for more info. You'll want to know about apply if
you want to avoid loops (which is a good approach).

> for(j in 1:nrow(B)) {
>    d <- (A[, 1] - B[j, 1])^2 + (A[, 2] - B[j, 2])^2
>    m[j] <- which.min(d)
> }
> 
> All I need is m[]. I would like to accomplish this without using the 
> loop if possible, since for my real data n > 140K and m > 1K. I hope 
> this makes sense.

Thing is, the above approach requires all data to be in main memory.
i hope this is not a problem.



From joehl at gmx.de  Wed Jan 28 11:05:12 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Wed, 28 Jan 2004 11:05:12 +0100 (MET)
Subject: [R] distance between two matrices
Message-ID: <1452.1075284312@www14.gmx.net>


Sundar,

Have a look at "knn1" from package "class".

As I understand what you want is

as.integer( knn1(train=A, test=B, cl=1:nrow(A)) )


Best regards


Jens Oehlschl?gel


>   Say I have a matrix A with dimension m x 2 and matrix B with 
> dimension n x 2. I would like to find the row in A that is closest to 
> the each row in B. Here's an example (using a loop):

> set.seed(1)
> A <- matrix(runif(12), 6, 2) # 6 x 2
> B <- matrix(runif(6), 3, 2)  # 3 x 2
> m <- vector("numeric", nrow(B))
> for(j in 1:nrow(B)) {
>    d <- (A[, 1] - B[j, 1])^2 + (A[, 2] - B[j, 2])^2
>    m[j] <- which.min(d)
> }

> All I need is m[]. I would like to accomplish this without using the 
> loop if possible, since for my real data n > 140K and m > 1K. I hope 
> this makes sense.



--



From andy_liaw at merck.com  Wed Jan 28 14:10:41 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 28 Jan 2004 08:10:41 -0500
Subject: [R] distance between two matrices
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76AD@usrymx25.merck.com>

You can try and see if knn1() in the `class' package (part of the VR bundle)
can handle the job in one shot.  If not, just do it in chunks of B.  For
your example:

> id <- 1:nrow(A)
> knn1(A, B, id)
[1] 3 2 3
Levels: 1 2 3 4 5 6

(I believe it returns factor, but that can easily be converted back to
numeric.)

HTH,
Andy

> From: Sundar Dorai-Raj
> 
> Hi all,
>    Say I have a matrix A with dimension m x 2 and matrix B with 
> dimension n x 2. I would like to find the row in A that is closest to 
> the each row in B. Here's an example (using a loop):
> 
> set.seed(1)
> A <- matrix(runif(12), 6, 2) # 6 x 2
> B <- matrix(runif(6), 3, 2)  # 3 x 2
> m <- vector("numeric", nrow(B))
> for(j in 1:nrow(B)) {
>    d <- (A[, 1] - B[j, 1])^2 + (A[, 2] - B[j, 2])^2
>    m[j] <- which.min(d)
> }
> 
> All I need is m[]. I would like to accomplish this without using the 
> loop if possible, since for my real data n > 140K and m > 1K. I hope 
> this makes sense.
> 
> Thanks,
> Sundar
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From jarrod.hadfield at imperial.ac.uk  Wed Jan 28 14:13:47 2004
From: jarrod.hadfield at imperial.ac.uk (Hadfield, Jarrod)
Date: Wed, 28 Jan 2004 13:13:47 -0000
Subject: [R] detecting non-singular square sub-matrices in rectangular
	matrice s.
Message-ID: <a06010201bc3d64ae709d@[129.31.3.147]>

Dear All,

I was wondering whether anyone knew of an efficient way of testing 
whether a non-singular square sub matrix of dimensions p X p exists 
within a rectangular matrix of dimensions p x m.  Typically, p will 
be about 4, and m several thousand so an exhaustive test of all 
possible sub matrices would be prohibitive when dealing with a large 
number of rectangular matrices.

Thanks for any suggestions,

Jarrod.



From andy_liaw at merck.com  Wed Jan 28 14:13:35 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 28 Jan 2004 08:13:35 -0500
Subject: [R] GRAPH
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76AE@usrymx25.merck.com>

If you want to overlay contour on an existing plot, use the add=TRUE option
in contour().

HTH,
Andy

> From: Marcos
> 
> How do to make a plot() and contour() in the same Graph sheet?
> 
> Marcos


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ripley at stats.ox.ac.uk  Wed Jan 28 14:15:44 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jan 2004 13:15:44 +0000 (GMT)
Subject: [R] dates function
In-Reply-To: <006d01c3e589$f220ec30$5a1aa7c0@pc2690>
Message-ID: <Pine.GSO.4.31.0401281311530.836-100000@toucan.stats>

On Wed, 28 Jan 2004, Massimiliano Tripoli wrote:

> I have problems with years of dates using "chron" package.
> I don't understand why R by this istruction:

It's not R, it is package chron.  R has its own date-time functions.

> > dates("01/02/29",out.format="d/m/year")
> [1] 02/Jan/2029
>
> > dates("01/02/30",out.format="d/m/year")
> [1] 02/Jan/1930
>
> reads "29" as 2029
> and "30" as 1930. How could I change to read "00" to "05" like 2000 to 2005 and "06" to "99" like 1906 to 1999 ?

Read the code for convert.dates.  You need to set
option("chron.year.expand") to a suitable function, the prototype being
year.expand and it will be easy to achieve what you want.

This answers your message under the misleading subject `Julian dates' too.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sundar.dorai-raj at pdf.com  Wed Jan 28 13:38:38 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 28 Jan 2004 06:38:38 -0600
Subject: [R] distance between two matrices
In-Reply-To: <Pine.LNX.4.44.0401280828440.23392-100000@gannet.stats>
References: <Pine.LNX.4.44.0401280828440.23392-100000@gannet.stats>
Message-ID: <4017AD4E.20607@pdf.com>

Thanks to Prof. Ripley, Jens, Roger, and Sean. knn1 is exactly what I'm 
looking for.

Thanks again,
Sundar


Prof Brian Ripley wrote:
> Sounds like knn classification.  See function knn1 in package class.
> 
> 
>>knn(A, B, 1:nrow(A))
> 
> 
> gives the same answers as your loop code, and is just a carefully tuned C 
> equivalent.
> 
> There are faster ways to do this by preprocessing set A discussed e.g. in 
> my PRNN book but your numbers took only 11s on my PC.
> 
> On Tue, 27 Jan 2004, Sundar Dorai-Raj wrote:
> 
> 
>>Hi all,
>>   Say I have a matrix A with dimension m x 2 and matrix B with 
>>dimension n x 2. I would like to find the row in A that is closest to 
>>the each row in B. Here's an example (using a loop):
>>
>>set.seed(1)
>>A <- matrix(runif(12), 6, 2) # 6 x 2
>>B <- matrix(runif(6), 3, 2)  # 3 x 2
>>m <- vector("numeric", nrow(B))
>>for(j in 1:nrow(B)) {
>>   d <- (A[, 1] - B[j, 1])^2 + (A[, 2] - B[j, 2])^2
>>   m[j] <- which.min(d)
>>}
>>
>>All I need is m[]. I would like to accomplish this without using the 
>>loop if possible, since for my real data n > 140K and m > 1K. I hope 
>>this makes sense.
>>
>>Thanks,
>>Sundar
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>
> 
>



From dave at evocapital.com  Wed Jan 28 14:28:24 2004
From: dave at evocapital.com (David Khabie-Zeitoune)
Date: Wed, 28 Jan 2004 13:28:24 -0000
Subject: [R] distance between two matrices
Message-ID: <8D0F30FE2EB3314182D4A33F738BB19D1793B6@sqlsrvr.evocapital.com>

A bit cumbersome, but (somewhat) vectorised.

dist = apply(B, 1, FUN = function(x, M) {rowSums(sweep(M, 2, x, "-")^2)
}, A)
m = row(t(dist))[t(dist==apply(dist,1,min))]

-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: 28 January 2004 10:09
To: Sundar Dorai-Raj
Cc: R-help
Subject: Re: [R] distance between two matrices


On Tue, 27 Jan 2004, Sundar Dorai-Raj wrote:

> Hi all,
>    Say I have a matrix A with dimension m x 2 and matrix B with
> dimension n x 2. I would like to find the row in A that is closest to 
> the each row in B. Here's an example (using a loop):
> 
> set.seed(1)
> A <- matrix(runif(12), 6, 2) # 6 x 2
> B <- matrix(runif(6), 3, 2)  # 3 x 2
> m <- vector("numeric", nrow(B))
> for(j in 1:nrow(B)) {
>    d <- (A[, 1] - B[j, 1])^2 + (A[, 2] - B[j, 2])^2
>    m[j] <- which.min(d)
> }
> 
> All I need is m[]. I would like to accomplish this without using the
> loop if possible, since for my real data n > 140K and m > 1K. I hope 
> this makes sense.

I think you need a quadtree of the larger set of points, the do lookup
for 
buckets of the smaller one. There is a good deal of information on

http://www.cs.umd.edu/~brabec/quadtree/

This isn't an answer within R, the functionality in the gstat
contributed package doesn't seem to be at the user level, but it does
point to the same site at UMD. 

Roger


> 
> Thanks,
> Sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of

Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From kasia at darwin.epbi.cwru.edu  Wed Jan 28 14:29:53 2004
From: kasia at darwin.epbi.cwru.edu (Catherine Stein)
Date: Wed, 28 Jan 2004 08:29:53 -0500 (EST)
Subject: [R] editing matrices (duh)
Message-ID: <Pine.OSF.4.30.0401280828570.389067-100000@darwin.epbi.cwru.edu>


Hello all,

Sorry for the dumb question... Is there a way to edit matrices, like
delete a row and add a few new ones, without retyping the whole thing?

Thanks,
cathy

My apologies if anyone receives this twice - I haven't seen it posted yet.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Catherine M. Stein
Research Assistant, Tuberculosis Research Unit
Doctoral Candidate in Genetic Epidemiology
Department of Epidemiology and Biostatistics
Case Western Reserve University
office: (216)368-0875 or (216)778-1378
e-mail: kasia at darwin.cwru.edu, or cmstein at cwru.edu
http://darwin.cwru.edu/~kasia

EPBI Student Resources Page:
http://hal.epbi.cwru.edu/stures/
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From r-eugenesalinas at comcast.net  Wed Jan 28 15:33:18 2004
From: r-eugenesalinas at comcast.net (Eugene Salinas (R))
Date: Wed, 28 Jan 2004 09:33:18 -0500
Subject: [R] savitzky-golay derivatives?
Message-ID: <4017C82E.8020703@comcast.net>

Dear all,

Sorry if this is slightly off the track as far as R is concerned, but I 
have been using the Savitzky-Golay filter to estimate some derivatives 
of interest. I am wondering however, if anyone has seen anything in the 
literature (or has any ideas) of how these estimates perform 
asymptotically. Does anyone know what the rate of convergence is for 
these as the sample size increases?

Thanks.



From sburke at cpan.org  Wed Jan 28 15:55:25 2004
From: sburke at cpan.org (sburke@cpan.org)
Date: Wed, 28 Jan 2004 09:55:25 -0500
Subject: [R] Hi
Message-ID: <200401281454.i0SEsUYH025242@hypatia.math.ethz.ch>

The message contains Unicode characters and has been sent as a binary attachment.


From petr.pikal at precheza.cz  Wed Jan 28 15:57:21 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 28 Jan 2004 15:57:21 +0100
Subject: [R] Julian Dates
In-Reply-To: <00fa01c3e598$24ae0580$5a1aa7c0@pc2690>
Message-ID: <4017DBE1.20912.1C63CE9@localhost>

Hallo

On 28 Jan 2004 at 13:13, Massimiliano Tripoli wrote:

> Hi all,
> I have problems with dates format  using "chron" package.
> I don't understand why R by this istruction:
> 
> > dates("01/02/29",out.format="d/m/year")
> [1] 02/Jan/2029

Well, the result probably depends on your system and locale setting.
I would use 4 digit year.

You can use ifelse construction to compute 4 digit years and then you have to 
reconstruct your dates vector probably with paste and as.character.

ifelse(as.numeric(substr("01/02/06",7,8))>5, 
as.numeric(substr("01/02/06",7,8))+1900, 
as.numeric(substr("01/02/06",7,8))+2000)

Cheers
Petr

> 
> > dates("01/02/30",out.format="d/m/year")
> [1] 02/Jan/1930
> 
> 
> reads "29" as 2029
> and "30" as 1930. How could I set the istruction in order to read
> years from "00" to "05" as 2000 to 2005 and "06" to "99" as 1906 to
> 1999 ? Thank you
> 
> Dott. Massimiliano Tripoli
> Dipartimento di Scienze Biomediche e Biotecnologie
> Sezione di Statistica Medica e Biometria
> Universit? di Brescia
> tel. +39-030-3717467
> fax +39-030-3701157
> 
> 
> 
> 
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ripley at stats.ox.ac.uk  Wed Jan 28 16:08:47 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jan 2004 15:08:47 +0000 (GMT)
Subject: [R] distance between two matrices
In-Reply-To: <B3A80C9C13928B45B2FCE4C43656363A0194E3EE@mail-srv02.master.medizin.uni-essen.de>
Message-ID: <Pine.LNX.4.44.0401281445210.1437-100000@gannet.stats>

On Wed, 28 Jan 2004, "H?sing, Johannes" wrote:

> > Hi all,
> >    Say I have a matrix A with dimension m x 2 and matrix B with 
> > dimension n x 2. I would like to find the row in A that is closest to 
> > the each row in B. Here's an example (using a loop):
> > 
> > set.seed(1)
> > A <- matrix(runif(12), 6, 2) # 6 x 2
> > B <- matrix(runif(6), 3, 2)  # 3 x 2
> > m <- vector("numeric", nrow(B))
> 
> make the lines below a function of a vector argument and 
> apply it over the rows of B.
> 
> ?apply for more info. You'll want to know about apply if
> you want to avoid loops (which is a good approach).

Unfortunately apply() is a wrapper for a for() loop, so will not help much 
(if at all).

> > for(j in 1:nrow(B)) {
> >    d <- (A[, 1] - B[j, 1])^2 + (A[, 2] - B[j, 2])^2
> >    m[j] <- which.min(d)
> > }

You can improve this a bit: see predict.qda.

> > All I need is m[]. I would like to accomplish this without using the 
> > loop if possible, since for my real data n > 140K and m > 1K. I hope 
> > this makes sense.
> 
> Thing is, the above approach requires all data to be in main memory.
> i hope this is not a problem.

A 140K x 2 array takes up 1.6Mb, and R needs 10x that to run at all.

Several people have mentioned knn1 as a C-level equivalent of the loops
(and I timed it as probably fast enough).  Roger Bivand mentioned
quadtrees, and that is one of a class of possible solutions if you need
extra speed.  Which member of that class is suitable depends on the
spatial distribution of A and B (viewing the rows as 2D points), but it is
hard to do very much better for only around a 1000 reference points.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bbonsu at columbus.rr.com  Wed Jan 28 16:14:03 2004
From: bbonsu at columbus.rr.com (Bema Bonsu)
Date: Wed, 28 Jan 2004 10:14:03 -0500
Subject: [R] Re: Help with Hmisc/Design installation in R-aqua (apple).
Message-ID: <9B669176-51A4-11D8-8C79-000393831644@columbus.rr.com>

Thanks, all, for your responses to my earlier email about installing 
the Hmisc and Design libraries created by Harrell FE Jr.

This was the body of my email requesting help:

"I have tried, unsuccessfully, to install the Hmisc and Design libraries
(Harrell FE Jr) in R-aqua (Apple). These libraries are in source code 
only
(i.e. not yet in ready-to-use binary format). Unfortunately, when I 
download
the libraries in source format and attempt to install them directly or
manually, I get an error message that states the following:

Warning messages:
1: Installation of package Design had non-zero exit status in:
install.packages(ui.pkgs, CRAN = getOption(where), lib = .libPaths()[1])
2: Installation of package Hmisc had non-zero exit status in:
install.packages(ui.pkgs, CRAN = getOption(where), lib = 
.libPaths()[1])"

These are the responses that I got:

"You need to look at the output of INSTALL.  One way is to go to
Preferences and select the items that send stdout and stderr to the R
console.  You will then get R INSTALL error messages, which should 
explain
the problems.

-thomas"


"I bet you don't have all the fortran and c compilers installed that 
Hmisc is looking for.  It also needs a LaTex distribution.

in linux, I'd open a terminal, su to root, then run R, and then

 > install.packages("Hmisc")

Usually there are messages that follow saying that it tried to get the 
source code and then it wil ltry to build. To figure out what's wrong, 
we need to see the output of the attempted build.

pj"


Thanks thomas and pj. As requested I am attaching the generated error 
message when I attempt to install the Hmisc and Design packages. What 
do I do next?

* Installing *source* package 'Hmisc' ...
** libs
g77   -fno-common  -g -O2 -c cidxcn.f -o cidxcn.o
ERROR: compilation failed for package 'Hmisc'
** Removing '/Users/bema/Library/RAqua/library/Hmisc'

make: g77: Command not found
make: *** [cidxcn.o] Error 127


Once again many many thanks for your help.

Sincerely,

Bema Bonsu



From bbonsu at columbus.rr.com  Wed Jan 28 16:19:10 2004
From: bbonsu at columbus.rr.com (Bema Bonsu)
Date: Wed, 28 Jan 2004 10:19:10 -0500
Subject: [R] Re: Help with Hmisc/Design installation in R-aqua (apple)
In-Reply-To: <200401131109.i0DB4nl4025656@hypatia.math.ethz.ch>
Message-ID: <BC3D3D1E.571%bbonsu@columbus.rr.com>

Thanks, all, for your responses to my earlier email about installing the
Hmisc and Design libraries created by Harrell FE Jr.

This was the body of my email requesting help:

"I have tried, unsuccessfully, to install the Hmisc and Design libraries
(Harrell FE Jr) in R-aqua (Apple). These libraries are in source code only
(i.e. not yet in ready-to-use binary format). Unfortunately, when I download
the libraries in source format and attempt to install them directly or
manually, I get an error message that states the following:

Warning messages:
1: Installation of package Design had non-zero exit status in:
install.packages(ui.pkgs, CRAN = getOption(where), lib = .libPaths()[1])
2: Installation of package Hmisc had non-zero exit status in:
install.packages(ui.pkgs, CRAN = getOption(where), lib = .libPaths()[1])"

These are the responses that I got:

"You need to look at the output of INSTALL.  One way is to go to
Preferences and select the items that send stdout and stderr to the R
console.  You will then get R INSTALL error messages, which should explain
the problems.

-thomas"


"I bet you don't have all the fortran and c compilers installed that Hmisc
is looking for.  It also needs a LaTex distribution.

in linux, I'd open a terminal, su to root, then run R, and then

> install.packages("Hmisc")

Usually there are messages that follow saying that it tried to get the
source code and then it wil ltry to build. To figure out what's wrong, we
need to see the output of the attempted build.

pj"


Thanks thomas and pj. As requested I am attaching the generated error
message when I attempt to install the Hmisc and Design packages. What do I
do next?

* Installing *source* package 'Hmisc' ...
** libs
g77   -fno-common  -g -O2 -c cidxcn.f -o cidxcn.o
ERROR: compilation failed for package 'Hmisc'
** Removing '/Users/bema/Library/RAqua/library/Hmisc'

make: g77: Command not found
make: *** [cidxcn.o] Error 127


Once again many many thanks for your help.

Sincerely,

Bema Bonsu



From johannes.huesing at medizin.uni-essen.de  Wed Jan 28 16:25:22 2004
From: johannes.huesing at medizin.uni-essen.de (=?iso-8859-1?Q?=22H=FCsing=2C_Johannes=22?=)
Date: Wed, 28 Jan 2004 16:25:22 +0100
Subject: [R] distance between two matrices
Message-ID: <B3A80C9C13928B45B2FCE4C43656363A0194E3F6@mail-srv02.master.medizin.uni-essen.de>

> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> On Wed, 28 Jan 2004, "H?sing, Johannes" wrote:
> > ?apply for more info. You'll want to know about apply if
> > you want to avoid loops (which is a good approach).
> 
> Unfortunately apply() is a wrapper for a for() loop, so will 
> not help much 
> (if at all).

whoops; so is the choice between both a matter of style? Or is
it implementation-specific for R, and not generally true for S?

(I know from LISP that if using map, roughly the equivalent to
S' apply instead of the do loop, you cannot rely on the elements 
being executed in their original order, which might buy you 
efficiency depending on the implementation.)



From ggrothendieck at myway.com  Wed Jan 28 17:20:12 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 28 Jan 2004 11:20:12 -0500 (EST)
Subject: [R] Julian dates
Message-ID: <20040128162012.69D043973@mprdmxin.myway.com>


Prof. Riley has already answered this but I thought I would add
a bit more detail.

> # define a function chron.year.expand.0 with a different cutoff.
> # You can choose other cutoffs too but here we have chosen 0.
> chron.year.expand.0 <- function(x) year.expand(x,cut=0)

> # run chron -- we have not yet set the new year expansion
> chron("01/02/29", out.format="year-month-day")
[1] 2029-January-02

> # change the year expansion option to point to the new function
> options(chron.year.expand = "chron.year.expand.0")
> chron("01/02/29", out.format="year-month-day")
[1] 1929-January-02

> # now change it back
> options(chron.year.expand = "year.expand")
> chron("01/02/29", out.format="year-month-day")
[1] 2029-January-02



Date:   Wed, 28 Jan 2004 11:50:11 +0100 
From:   Massimiliano Tripoli <tripoli at med.unibs.it>
To:   <R-help at stat.math.ethz.ch> 
Subject:   [R] Julian dates 

 
Hi all,
I have problems with years of dates using "chron" package.
I don't understand why R by this istruction:
> dates("01/02/29",out.format="d/m/year")
[1] 02/Jan/2029

> dates("01/02/30",out.format="d/m/year")
[1] 02/Jan/1930

reads "29" as 2029
and "30" as 1930. How could I change to read "00" to "05" like 2000 to 2005 and "06" to "99" like 1906 to 1999 ?
Thank you

Massimiliano



From tlumley at u.washington.edu  Wed Jan 28 17:34:38 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 28 Jan 2004 08:34:38 -0800 (PST)
Subject: [R] Re: Help with Hmisc/Design installation in R-aqua (apple)
In-Reply-To: <BC3D3D1E.571%bbonsu@columbus.rr.com>
References: <BC3D3D1E.571%bbonsu@columbus.rr.com>
Message-ID: <Pine.A41.4.58.0401280831350.44844@homer29.u.washington.edu>

On Wed, 28 Jan 2004, Bema Bonsu wrote:
>
> Thanks thomas and pj. As requested I am attaching the generated error
> message when I attempt to install the Hmisc and Design packages. What do I
> do next?
>
> * Installing *source* package 'Hmisc' ...
> ** libs
> g77   -fno-common  -g -O2 -c cidxcn.f -o cidxcn.o
> ERROR: compilation failed for package 'Hmisc'
> ** Removing '/Users/bema/Library/RAqua/library/Hmisc'
>
> make: g77: Command not found
> make: *** [cidxcn.o] Error 127
>

Either you don't have the g77 Fortran compiler or it isn't where R expects
to find it. Many packages don't need Fortran, but it appears Hmisc does.
The RAqua web page has information on where to find the Fortran compilers.

	-thomas



From Ted.Harding at nessie.mcc.ac.uk  Wed Jan 28 17:38:37 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 28 Jan 2004 16:38:37 -0000 (GMT)
Subject: [R] Julian dates
In-Reply-To: <00a401c3e58c$80a70f00$5a1aa7c0@pc2690>
Message-ID: <XFMail.040128163837.Ted.Harding@nessie.mcc.ac.uk>

On 28-Jan-04 Massimiliano Tripoli wrote:
> Hi all,
> I have problems with years of dates using "chron" package.
> I don't understand why R by this istruction:
>> dates("01/02/29",out.format="d/m/year")
> [1] 02/Jan/2029
> 
>> dates("01/02/30",out.format="d/m/year")
> [1] 02/Jan/1930
> 
> reads "29" as 2029
> and "30" as 1930. How could I change to read "00" to "05" like 2000 to
> 2005 and "06" to "99" like 1906 to 1999 ?

I'm puzzled by the above:

> dates("01/02/29",out.format="d/m/year")
[1] 02/Jan/2029
> dates("01/02/30",out.format="d/m/year")
[1] 02/Jan/1930

so chron apparently acts as though time began at 01/01/1930.

However:

> ?chron
-->
 origin.: a vector specifying the date with respect to which Julian
          dates are computed.  Default is 'c(month = 1, day = 1,
          year = 1970)'

(which is the orthodox origin of time according to Unix) and, indeed,

> origin(dates("01/02/29",out.format="d/m/year"))
month   day  year 
    1     1  1970 

So why does Massimiliano's example behave as though the origin
were 01/01/1930?

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 28-Jan-04                                       Time: 16:38:37
------------------------------ XFMail ------------------------------



From ripley at stats.ox.ac.uk  Wed Jan 28 18:50:13 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jan 2004 17:50:13 +0000 (GMT)
Subject: [R] distance between two matrices
In-Reply-To: <B3A80C9C13928B45B2FCE4C43656363A0194E3F6@mail-srv02.master.medizin.uni-essen.de>
Message-ID: <Pine.LNX.4.44.0401281745370.2029-100000@gannet.stats>

On Wed, 28 Jan 2004, "H?sing, Johannes" wrote:

> > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > On Wed, 28 Jan 2004, "H?sing, Johannes" wrote:
> > > ?apply for more info. You'll want to know about apply if
> > > you want to avoid loops (which is a good approach).
> > 
> > Unfortunately apply() is a wrapper for a for() loop, so will 
> > not help much 
> > (if at all).
> 
> whoops; so is the choice between both a matter of style? Or is
> it implementation-specific for R, and not generally true for S?

It is not generally true for S.  The case studies in chapter 7 of `S 
Programming' show that efficient ways are implementation-dependent.

In some versions of S-PLUS (e.g. 3.4) apply was much faster and in some
(5.0) it was much slower.  Using lapply() (which has a C-level loop) is
sometimes rather faster in R.

In this particular example garbage collection is taking about 50% of time
of the pure R solution, so exactly what is done in what order can matter.  
knn1 is 20-30x faster since it works in place with space allocated just
once.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Jan 28 19:33:14 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jan 2004 18:33:14 +0000 (GMT)
Subject: [R] Julian dates
In-Reply-To: <XFMail.040128163837.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0401281823340.2209-100000@gannet.stats>

On Wed, 28 Jan 2004 Ted.Harding at nessie.mcc.ac.uk wrote:

> > origin(dates("01/02/29",out.format="d/m/year"))
> month   day  year 
>     1     1  1970 
> 
> So why does Massimiliano's example behave as though the origin
> were 01/01/1930?

It doesn't.  It behaves as if he wrote "01/02/2029" and he intended
"01/02/1929" (but chron failed to read his mind).  That is an undocumented
`feature' of the auxiliary function year.expand(), whose use is an
undocumented `feature' of convert.dates() (whose use is ..., well it gets
boring).

You will find all date-conversion routines do something like this with 
incompletely specified years.  Read the help on %y in ?strptime.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From smelov at mac.com  Wed Jan 28 20:05:19 2004
From: smelov at mac.com (Simon Melov)
Date: Wed, 28 Jan 2004 11:05:19 -0800
Subject: [R] multiple plots..again
Message-ID: <EA5CA73A-51C4-11D8-9D94-000A956F2984@mac.com>

Hi,
I realize many posts have been written about this, but I have gone 
through the archives and cannot find an example/solution particular to 
my problem.

I have two Df's as follows

Df-1
Time V1 V2 V3...V100
9 0.5 1.8 -0.3 ..
14 2 -0.4 0.003..
19 -4 3 0.1..

Df-2 is the same but has different values for the variables

I would like to plot the individual variables against time for both 
Df-1 and Df-2 (i.e. time along the x axis, "V" along the yaxis) in the 
same plot. I need to do this for all 100 variables as separate graphs. 
I would like 10 plots/page (Ive tried various combinations of mfrow - 
but cant get the result I want). Each plot should be labeled with the 
appropriate Variable name (it would also be nice to have the lines on 
the plot differentiated by color, and the respective Df they are from).

I realize this is pretty straightforward, but for the life of me, I 
cant seem to get it right!

please help!

simon.



From abunn at montana.edu  Wed Jan 28 20:23:16 2004
From: abunn at montana.edu (Andy Bunn)
Date: Wed, 28 Jan 2004 12:23:16 -0700
Subject: [R] multiple plots..again
In-Reply-To: <EA5CA73A-51C4-11D8-9D94-000A956F2984@mac.com>
Message-ID: <003a01c3e5d4$3ff90e20$78f05a99@msu.montana.edu>

Have you tried layout?

layout(matrix(1:10, 5, 2, byrow = TRUE))
for(i in 1:10){
    plot(rnorm(100), type = "l", col = "red", main = paste("Your
Variable Number", i, sep = " "))
    lines(runif(100), col = "blue")
}

Does this get you started?

-A



From hbar at micropat.com  Wed Jan 28 20:29:36 2004
From: hbar at micropat.com (Haim Bar)
Date: Wed, 28 Jan 2004 14:29:36 -0500
Subject: [R] how to set R_GSCMD
Message-ID: <001d01c3e5d5$12c94180$0200a8c0@micropat.com>

I have R installed on a windows box, and I need to get a better resolution.
I understand I need to set R_GSCMD.  Which file has to contain this
variable?

Thanks!
Haim



From gerald.jean at dgag.ca  Wed Jan 28 21:11:33 2004
From: gerald.jean at dgag.ca (gerald.jean@dgag.ca)
Date: Wed, 28 Jan 2004 15:11:33 -0500
Subject: [R] Large data sets and memory management in R.
Message-ID: <OF11A5CF84.1669DBC9-ON85256E29.006A3677@spgdag.ca>

Hello R-users,

First my settings: R-1.8.1, compiled as a 64bit application for a Solaris
5.8, 64 bit.  The OS has 8Gb of RAM available and I am the sole user of the
machine, hence pretty much all the 8Gb are available to R.

I am pretty new to R and I am having a hard time to work with large data
sets, which make up over 90% of the anlyses done here.  The data set I
imported in R, from S+, has a little over 2,000,000 rows by somewhere
around 60 variables, most of them factors, but a few continuous.  The data
set is in fact a subset of a larger data set used for analysis in S+.  I
know that some of you will think that I should sample, but it is not an
option in the present settings.

After first reading the data set into R -- which had its challenges on its
own -- when I quit R and save the work space it takes over 5 minutes, when
I start a new session and load the data set it takes around 15 minutes.

I am trying to build a model that I have already built in S+, so I can make
sure I am doing the right thing and can compare resources usage, but so far
I have no luck!  After 45 minutes or so R has used up all the available
memory and is swapping, which brings CPU usage close to nothing.

I am convinced there are settings I could use to optimize memory management
for such problems.  I tried help(Memory) which tells me about the options "
--min-vsize=vl --max-vsize=vu --min-nsize=nl --max-nsize=nu", but it is not
clear if they should be used and when.  Further down the pages it
says:"..., and since setting larger values of the minima will make R
slightly more efficient on large tasks."  But on the other hand, searching
the R-site, for memory management clues I found, from Brian Ripley, dated
13 Nov. 2003:
"But had you actually read the documentation you would know it did not do
that. That needs --max-memory-size set.", that was in response to someone
who had increased the value of "min-vsize= "; furthermore I don't find any
"--max-memory-size" option?

I am wondering if someone having experience working with large data sets
would share the configurations and options he is using.  If that matters
here is the model I was trying to fit.

library(package = "statmod", pos = 2,
        lib.loc = "/home/jeg002/R-1.8.1/lib/R/R_LIBS")

qc.B3.tweedie <- glm(formula = pp20B3 ~ ageveh + anpol +
                     categveh + champion + cie + dossiera +
                     faq13c + faq5a + kmaff + kmprom + nbvt +
                     rabprof + sexeprin + newage,
                     family = tweedie(var.power = 1.577,
                       link.power = 0),
                     etastart = log(rep(mean(qc.b3.sans.occ[,
                        'pp20B3']), nrow(qc.b3.sans.occ))),
                     weights = unsb3t1,
                     trace = T,
                     data = qc.b3.sans.occ)

After one iteration (45+ minutes) R is trashing through over 10Gb of
memory.

Thanks for any insights,

G?rald Jean
Analyste-conseil (statistiques), Actuariat
t?lephone            : (418) 835-4900 poste (7639)
t?lecopieur          : (418) 835-6657
courrier ?lectronique: gerald.jean at spgdag.ca

"In God we trust all others must bring data"  W. Edwards Deming



From brad at post.tamu.edu  Wed Jan 28 21:19:28 2004
From: brad at post.tamu.edu (Brad Holmes)
Date: Wed, 28 Jan 2004 14:19:28 -0600
Subject: [R] Read In and Output Postscript file
Message-ID: <46784484-51CF-11D8-BFBA-000393A37A1A@post.tamu.edu>

Hi,

I am only a few months old at R and I have encountered an interesting 
issue.

Would it be possible to read in a pre-existing postscript file, and 
output it "as is" through R?

I have five plots, and I am placing them in a layout that is 2 X 3. I 
was hoping to "insert" the pre-existing postscript file made from 
Molscript in the last spot.

Thanks for your time!

~Brad Holmes
Research Assistant
Texas A&M University



From ripley at stats.ox.ac.uk  Wed Jan 28 22:03:37 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Jan 2004 21:03:37 +0000 (GMT)
Subject: [R] how to set R_GSCMD
In-Reply-To: <001d01c3e5d5$12c94180$0200a8c0@micropat.com>
Message-ID: <Pine.LNX.4.44.0401282100380.2489-100000@gannet.stats>

On Wed, 28 Jan 2004, Haim Bar wrote:

> I have R installed on a windows box, and I need to get a better resolution.

A better resolution of what, please?

> I understand I need to set R_GSCMD.  Which file has to contain this
> variable?

That appears to refer to the bitmap device, and the help says

  the full path to the executable can be set by the environment variable 
  'R_GSCMD'.

Please read the rw-FAQ about how to set an environment variable: it is 
described there.

However, that sets the path and not the resolution, which is an argument.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From obuerger at ginko.de  Wed Jan 28 22:01:05 2004
From: obuerger at ginko.de (=?ISO-8859-1?Q?Olaf_B=FCrger?=)
Date: Wed, 28 Jan 2004 22:01:05 +0100
Subject: [R] How to generate a report with graphics and tables?
Message-ID: <40182311.2010800@ginko.de>

Hello R-Users,

I have some data sets which change on a daily bases. So far I have 
imported  these sets into R, done all my evaluations resulting in a 
couple of plots, charts and tables of numbers which I copy&pasted via 
clipboard into Powerpoint.
The procedure is always the same and I wonder, whether there is no 
easier way for doing so. Is there some type of "report generator" 
available or some HowTo on this.

Can anybody give me a hint on where to look for?

Regards,

Olaf B?rger



From p.dalgaard at biostat.ku.dk  Wed Jan 28 22:18:39 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 Jan 2004 22:18:39 +0100
Subject: [R] Large data sets and memory management in R.
In-Reply-To: <OF11A5CF84.1669DBC9-ON85256E29.006A3677@spgdag.ca>
References: <OF11A5CF84.1669DBC9-ON85256E29.006A3677@spgdag.ca>
Message-ID: <x2k73bydow.fsf@biostat.ku.dk>

gerald.jean at dgag.ca writes:

> library(package = "statmod", pos = 2,
>         lib.loc = "/home/jeg002/R-1.8.1/lib/R/R_LIBS")
> 
> qc.B3.tweedie <- glm(formula = pp20B3 ~ ageveh + anpol +
>                      categveh + champion + cie + dossiera +
>                      faq13c + faq5a + kmaff + kmprom + nbvt +
>                      rabprof + sexeprin + newage,
>                      family = tweedie(var.power = 1.577,
>                        link.power = 0),
>                      etastart = log(rep(mean(qc.b3.sans.occ[,
>                         'pp20B3']), nrow(qc.b3.sans.occ))),
>                      weights = unsb3t1,
>                      trace = T,
>                      data = qc.b3.sans.occ)
> 
> After one iteration (45+ minutes) R is trashing through over 10Gb of
> memory.
> 
> Thanks for any insights,

Well, I don't know how much it helps; you are in somewhat uncharted
territory there. I suppose the dataset comes to 0.5-1GB all by itself?

One thing that I note is that you have 60 variables, but use only 15.
Perhaps it helps to remove some of them before the run? 

How large does the designmatrix get? If some of those variables have a
lot of levels, it could explain the phenomenon. Any chance that a
continuous variable got recorded as a factor?

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From andy_liaw at merck.com  Wed Jan 28 22:34:26 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 28 Jan 2004 16:34:26 -0500
Subject: [R] How to generate a report with graphics and tables?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76B4@usrymx25.merck.com>

If you don't mind pdf report generated from LaTeX, Sweave would probably
work nicely for you.  See the two articles on it in R News, which you can
find on the R web site.

One other possibility is to use the R2HTML package (and maybe the xtable
package, too) to write the `report' in HTML.

HTH,
Andy

> From: Olaf B?rger
> 
> Hello R-Users,
> 
> I have some data sets which change on a daily bases. So far I have 
> imported  these sets into R, done all my evaluations resulting in a 
> couple of plots, charts and tables of numbers which I copy&pasted via 
> clipboard into Powerpoint.
> The procedure is always the same and I wonder, whether there is no 
> easier way for doing so. Is there some type of "report generator" 
> available or some HowTo on this.
> 
> Can anybody give me a hint on where to look for?
> 
> Regards,
> 
> Olaf B?rger
> 
 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From feh3k at spamcop.net  Wed Jan 28 22:44:23 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Wed, 28 Jan 2004 15:44:23 -0600
Subject: [R] How to generate a report with graphics and tables?
In-Reply-To: <40182311.2010800@ginko.de>
References: <40182311.2010800@ginko.de>
Message-ID: <20040128154423.43d06231.feh3k@spamcop.net>

On Wed, 28 Jan 2004 22:01:05 +0100
Olaf B?rger <obuerger at ginko.de> wrote:

> Hello R-Users,
> 
> I have some data sets which change on a daily bases. So far I have 
> imported  these sets into R, done all my evaluations resulting in a 
> couple of plots, charts and tables of numbers which I copy&pasted via 
> clipboard into Powerpoint.
> The procedure is always the same and I wonder, whether there is no 
> easier way for doing so. Is there some type of "report generator" 
> available or some HowTo on this.
> 
> Can anybody give me a hint on where to look for?
> 
> Regards,
> 
> Olaf B?rger
>

For many reports Sweave (part of the tools package in R) is what you want,
in conjunction with LaTeX.  For customized reports see
http://hesweb1.med.virginia.edu/biostat/s/LiveDoc.html

LaTeX is necessary to do the job right, in my opinion.
---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From paulojus at est.ufpr.br  Wed Jan 28 22:49:04 2004
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Wed, 28 Jan 2004 19:49:04 -0200 (BRST)
Subject: [R] How to generate a report with graphics and tables?
In-Reply-To: <40182311.2010800@ginko.de>
References: <40182311.2010800@ginko.de>
Message-ID: <Pine.LNX.4.58L0.0401281948490.17835@est.ufpr.br>

You may want to have a look at Sweave at
http://www.ci.tuwien.ac.at/~leisch/Sweave/
and R-NEWS

P.J.


On Wed, 28 Jan 2004, Olaf B?rger wrote:

> Hello R-Users,
>
> I have some data sets which change on a daily bases. So far I have
> imported  these sets into R, done all my evaluations resulting in a
> couple of plots, charts and tables of numbers which I copy&pasted via
> clipboard into Powerpoint.
> The procedure is always the same and I wonder, whether there is no
> easier way for doing so. Is there some type of "report generator"
> available or some HowTo on this.
>
> Can anybody give me a hint on where to look for?
>
> Regards,
>
> Olaf B?rger
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From MSchwartz at medanalytics.com  Wed Jan 28 22:51:12 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 28 Jan 2004 15:51:12 -0600
Subject: [R] How to generate a report with graphics and tables?
In-Reply-To: <40182311.2010800@ginko.de>
References: <40182311.2010800@ginko.de>
Message-ID: <1075326672.31290.15.camel@localhost.localdomain>

On Wed, 2004-01-28 at 15:01, Olaf B?rger wrote:
> Hello R-Users,
> 
> I have some data sets which change on a daily bases. So far I have 
> imported  these sets into R, done all my evaluations resulting in a 
> couple of plots, charts and tables of numbers which I copy&pasted via 
> clipboard into Powerpoint.
> The procedure is always the same and I wonder, whether there is no 
> easier way for doing so. Is there some type of "report generator" 
> available or some HowTo on this.
> 
> Can anybody give me a hint on where to look for?
> 
> Regards,
> 
> Olaf B?rger


You might want to look at Sweave, which is perfect where you have
standardized output formats, based upon changing datasets.

More information is available here:

http://www.ci.tuwien.ac.at/~leisch/Sweave/

and you can search the r-help archives for additional information.

HTH,

Marc Schwartz



From wviechtb at cyrus.psych.uiuc.edu  Wed Jan 28 23:21:07 2004
From: wviechtb at cyrus.psych.uiuc.edu (Wolfgang Viechtbauer)
Date: Wed, 28 Jan 2004 16:21:07 -0600 (CST)
Subject: [R] Math Expression and Variable Value in Title
Message-ID: <Pine.SOL.4.58.0401281605270.12830@stat.psych.uiuc.edu>

Hello All,

I am trying to put a math expression into a plot title and at the same
time, I want a value in the title to depend on a variable that I set
earlier.

Simple Example:

n <- 20
plot(0, 0)
title(expression(paste(n[i], " = ", n)))

Obviously, I want "n_i = 20". How can I get that?

Thanks in advance,

-- 
Wolfgang Viechtbauer



From tplate at acm.org  Wed Jan 28 23:55:27 2004
From: tplate at acm.org (Tony Plate)
Date: Wed, 28 Jan 2004 15:55:27 -0700
Subject: [R] Read In and Output Postscript file
In-Reply-To: <46784484-51CF-11D8-BFBA-000393A37A1A@post.tamu.edu>
Message-ID: <5.2.1.1.2.20040128155319.03c1c778@mailhost.blackmesacapital.com>

One way to approach this from within R would be to use gs to convert the 
preexisting postscript file to some sort of bitmap, and then read that into 
R and plot it.

Another way to do this, outside of R, would be to use the capabilities of 
gs to combine multiple ps files (for example, I often generate multiple 
single-page postscript files, and then use gs to wrap them up in a pdf).

hope this helps,

Tony Plate

At Wednesday 02:19 PM 1/28/2004 -0600, Brad Holmes wrote:
>Hi,
>
>I am only a few months old at R and I have encountered an interesting issue.
>
>Would it be possible to read in a pre-existing postscript file, and output 
>it "as is" through R?
>
>I have five plots, and I am placing them in a layout that is 2 X 3. I was 
>hoping to "insert" the pre-existing postscript file made from Molscript in 
>the last spot.
>
>Thanks for your time!
>
>~Brad Holmes
>Research Assistant
>Texas A&M University
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Tony Plate   tplate at acm.org



From hbar at micropat.com  Thu Jan 29 00:18:09 2004
From: hbar at micropat.com (Haim Bar)
Date: Wed, 28 Jan 2004 18:18:09 -0500
Subject: [R] how to set R_GSCMD
References: <Pine.LNX.4.44.0401282100380.2489-100000@gannet.stats>
Message-ID: <005701c3e5f4$fef92e70$0200a8c0@micropat.com>

Thanks!

----- Original Message -----
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Haim Bar" <hbar at micropat.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Wednesday, January 28, 2004 4:03 PM
Subject: Re: [R] how to set R_GSCMD


> On Wed, 28 Jan 2004, Haim Bar wrote:
>
> > I have R installed on a windows box, and I need to get a better
resolution.
>
> A better resolution of what, please?
>
> > I understand I need to set R_GSCMD.  Which file has to contain this
> > variable?
>
> That appears to refer to the bitmap device, and the help says
>
>   the full path to the executable can be set by the environment variable
>   'R_GSCMD'.
>
> Please read the rw-FAQ about how to set an environment variable: it is
> described there.
>
> However, that sets the path and not the resolution, which is an argument.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From MSchwartz at medanalytics.com  Thu Jan 29 00:31:11 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 28 Jan 2004 17:31:11 -0600
Subject: [R] Read In and Output Postscript file
In-Reply-To: <46784484-51CF-11D8-BFBA-000393A37A1A@post.tamu.edu>
References: <46784484-51CF-11D8-BFBA-000393A37A1A@post.tamu.edu>
Message-ID: <1075332671.31290.50.camel@localhost.localdomain>

On Wed, 2004-01-28 at 14:19, Brad Holmes wrote:
> Hi,
> 
> I am only a few months old at R and I have encountered an interesting 
> issue.
> 
> Would it be possible to read in a pre-existing postscript file, and 
> output it "as is" through R?
> 
> I have five plots, and I am placing them in a layout that is 2 X 3. I 
> was hoping to "insert" the pre-existing postscript file made from 
> Molscript in the last spot.
> 
> Thanks for your time!
> 
> ~Brad Holmes
> Research Assistant
> Texas A&M University


If the final goal is a single PS file with all 6 graphics in a 2 x 3
matrix, your best bet might be to generate the five R graphics
separately as PS or EPS files. Then import each of the six PS/EPS files
into a document layout program.

Your e-mail header suggests that you are on a Mac. If you have access to
MS Word or an alternate document processing program like OpenOffice or a
functional equivalent, you can import EPS files into a table, with each
graphic going into a cell in the table. You can then "print" the
document to a PS file, using a PS printer driver.

Others may have alternate ideas.

HTH,

Marc Schwartz



From rpeng at jhsph.edu  Thu Jan 29 01:35:28 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 28 Jan 2004 19:35:28 -0500
Subject: [R] Math Expression and Variable Value in Title
In-Reply-To: <Pine.SOL.4.58.0401281605270.12830@stat.psych.uiuc.edu>
References: <Pine.SOL.4.58.0401281605270.12830@stat.psych.uiuc.edu>
Message-ID: <40185550.6060806@jhsph.edu>

Use substitute()

n <- 20
plot(0, 0, main = substitute(paste(n[i], " = ", k), list(k = n)))

-roger

Wolfgang Viechtbauer wrote:

> Hello All,
> 
> I am trying to put a math expression into a plot title and at the same
> time, I want a value in the title to depend on a variable that I set
> earlier.
> 
> Simple Example:
> 
> n <- 20
> plot(0, 0)
> title(expression(paste(n[i], " = ", n)))
> 
> Obviously, I want "n_i = 20". How can I get that?
> 
> Thanks in advance,
>



From JGPorzak at loyaltymatrix.com  Thu Jan 29 01:35:23 2004
From: JGPorzak at loyaltymatrix.com (Jim Porzak)
Date: Wed, 28 Jan 2004 16:35:23 -0800
Subject: [R]Running R remotely in Windows Environment?
Message-ID: <5.1.1.6.0.20040128162138.02997310@pop3.norton.antivirus>

We are considering setting up a fast, RAM loaded machine as an "R-server" 
to handle the big problems not suitable for individual desktops and, also, 
to process ad hoc analysis requests via our portal. We are 99% a Windows 
shop, so first choice is a windows server. We'll use (D)COM for the portal 
interface and understand that.

What has me stumped is how to easily interface individual analyst's Windows 
desktops to the R-server. I haven't seen anything in the archives, but I 
can't imagine this hasn't been done. What am I missing?

TIA!

Jim Porzak
Director of Analytics
Loyalty Matrix, Inc.
www.LoyaltyMatrix.com



From arnab at myrealbox.com  Thu Jan 29 02:21:57 2004
From: arnab at myrealbox.com (Arnab mukherji)
Date: Thu, 29 Jan 2004 01:21:57 +0000
Subject: [R] Confirmatory Factor Analysis in R? SEM?
Message-ID: <1075339317.58c7f100arnab@myrealbox.com>

Hi 

Has anyone used R to conduct confirmatory factor analysis?  This email pertains to use of SEM.

For context consider an example: the basic idea is that there are a bunch of observables variables (say study habbits, amount of time reading in the bus, doing homework, helping other do homework, doing follow-up on errors etc.) and one believes that all these variables maybe measured by two or more unobservable constructs... say ability to work hard and ability to follow instructions. If one has empirical evidence from earlier studies which relates similar observable to similar unobservables one wants to do a confirmatory factor analysis to check if the posited relationship holds in the current data being analyzed.

I thought the way out would be to use SEM - the structural equation model library. However, i am not sure how to estimate SEM objects where factors are unobservable. The only discussion pertian to the case of endogenously detemined observable variables.

here is a test case of what i'd like to implement

#example Measurement Model

x1<-runif(200)
x2<-rbinom(200, 20, 0.75)
x3<-runif(200)
x4<-runif(200)
dat<-as.data.frame(x1 =x1, x2 = x2, x3 = x3, x4 = x4)

v.c<-cor(dat,use = "complete.obs")
ind<-upper.tri(v.c)
v.c[ind]<-0 
model.dhp<-matrix (c(
                       "x1 -> HWK", "gam11", NA,
                       "x2 -> HWK", "gam21", NA,
                       "x2 -> FI",  "gam22", NA,
                       "x3 -> HWK", "gam31", NA,
                       "x3 -> F1", "gam32", NA,
                       "x4 -> F1", "gam42", NA),
                       ncol = 3, byrow = TRUE)
These are the Factor loadings i'd like to test for: 
 variable   HWK     FI
 x1         0.75    0
 x2         0.20    0.68
 x3         0.2     0.5
 x4         0       0.24


thanks for any help on this.

Arnab



From karlknoblich at yahoo.de  Thu Jan 29 02:34:27 2004
From: karlknoblich at yahoo.de (=?iso-8859-1?q?Karl=20Knoblick?=)
Date: Thu, 29 Jan 2004 02:34:27 +0100 (CET)
Subject: [R] Calculating/understanding variance-covariance matrix of
	logistic regression (lrm $var)
Message-ID: <20040129013427.34751.qmail@web10003.mail.yahoo.com>

Hallo!

I want to understand / recalculate what is done to get
the CI of the logistic regression evaluated with lrm.
As far as I came back, my problem is the
variance-covariance matrix fit$var of the fit
(fit<-lrm(...), fit$var). Here what I found and where
I stucked:

-----------------
library(Design)
# data
D<-c(rep("a", 20), rep("b", 20))
V<-0.25*(1:40)
V[1]<-25
V[40]<-15
data<-data.frame(D, V)
d<-datadist(data)
options(datadist="d")

# Fit
fit<-lrm(D ~ V, data=data, x=TRUE, se.fit=TRUE)
plot(fit, conf.int=0.95) # same as plot(fit)

# calculation of upper and lower CI (pred$lower,
pred$upper)
pred<-predict(fit, data.frame(V=V), conf.int=0.95,
se.fit=TRUE)
points(V, pred$upper, col=2, pch=3) # to check

# looking in function predict, the CI are calculated
with the se
# using fit$var:
X<-cbind(rep(1, length(fit$x)), fit$x) # fit$x are the
V
cov<-fit$var # <- THIS I DO NOT UNDERSTAND (***) s.
below
se <- drop(sqrt(((X %*% cov) * X) %*% rep(1,
ncol(X))))

# check if it is the same
min(se - pred$se.fit) # result: 0
max(se - pred$se.fit) # result: 0

# looking at the problem:
cov
-----------------
Result:
           Intercept           V
Intercept  0.7759040 -0.12038969
V         -0.1203897  0.02274177


(***)
fit$var is the estimated variance-covariance matrix.
How is it calculated? (Meaning of intercept and x?)

Does anybody know how calculationg this "by hand" or
can give me a reference (preferable in the internet)?

Thanks!
Karl.



From ggrothendieck at myway.com  Thu Jan 29 02:44:02 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 28 Jan 2004 20:44:02 -0500 (EST)
Subject: [R] How to generate a report with graphics and tables?
Message-ID: <20040129014402.4603D39E3@mprdmxin.myway.com>



On Windows you could use a macro recorder/playback program to automate your session.

There is a free script interpreter called autoit at:

   http://www.hiddensoft.com/AutoIt/

that can handle about 90 different commands.  This may seem complex
but you may be able to use it without much of a learning curve 
by using the AutoScriptWriter recorder program found in the Files section of

   http://groups.yahoo.com/group/autoit/

to record key and mouse actions to create the script and then, if desired, make changes to the script it produces using a text editor.  

You startup autoscriptwriter and then press record and perform your actions.  The actions could startup R, perform various 
commands, start up powerpoint, do various activities, etc.  
Then press stop and press save to save the script.  You can then 
edit the script as desired in a text editor.   At this point 
the commands in the script will mostly be obvious and you
might be able to edit them even without reference to the documentation.  You  can run the script using autoit itself.

I have used it a bit but not extensively; however, if you have
questions there is a yahoo group on it at the link cited above.

There are also numerous shareware and commercial keystroke and macro 
recorders that you can find using google.

On Wed, 28 Jan 2004 22:01:05 +0100
Olaf Brger <obuerger at ginko.de> wrote:

> Hello R-Users,
> 
> I have some data sets which change on a daily bases. So far I have 
> imported these sets into R, done all my evaluations resulting in a 
> couple of plots, charts and tables of numbers which I copy&pasted via 
> clipboard into Powerpoint.
> The procedure is always the same and I wonder, whether there is no 
> easier way for doing so. Is there some type of "report generator" 
> available or some HowTo on this.
> 
> Can anybody give me a hint on where to look for?
> 
> Regards,
> 
> Olaf Brger
>



From maj at stats.waikato.ac.nz  Thu Jan 29 05:13:49 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu, 29 Jan 2004 17:13:49 +1300
Subject: [R] Finding Sweave.sty and other problems
Message-ID: <4018887D.502@stats.waikato.ac.nz>

Hi,

I've just tried to run example-3 from Friedrich Leish. I'm using R 1.8.1 
and MiKTeX 2.2 on Windows XP.

I go
===
 > library(tools)
 > Sweave("example-3.Snw")
Writing to file example-3.tex
Processing code chunks ...
  1 : term hide
  2 : echo term verbatim
  3 : term tex
  4 : term verbatim eps pdf

You can now run LaTeX on example-3.tex
===
The file example-3.tex looks OK, it starts off
===
\documentclass[a4paper]{article}

\usepackage{C:/PROGRA~1/R/rw1081/share/texmf/Sweave}
\begin{document}


\section*{The Cats Data}
..........
===
but my LaTeX log file tells a sad story:
===
This is TeX, Version 3.141592 (MiKTeX 2.2) (preloaded format=latex 
2000.11.28)  29 JAN 2004 16:36
**example-3.tex
(example-3.tex
LaTeX2e <2001/06/01>
Babel <v3.7h> and hyphenation patterns for english, french, german, 
ngerman, du
mylang, nohyphenation, loaded.
(C:\texmf\tex\latex\base\article.cls
Document Class: article 2001/04/21 v1.4e Standard LaTeX document class
(C:\texmf\tex\latex\base\size10.clo
File: size10.clo 2001/04/21 v1.4e Standard LaTeX file (size option)
)
\c at part=\count79
\c at section=\count80
\c at subsection=\count81
\c at subsubsection=\count82
\c at paragraph=\count83
\c at subparagraph=\count84
\c at figure=\count85
\c at table=\count86
\abovecaptionskip=\skip41
\belowcaptionskip=\skip42
\bibindent=\dimen102
)
! Missing \endcsname inserted.
<to be read again>
                    \protect
l.4 \begin
           {document}
? s
OK, entering \scrollmode...

! LaTeX Error: Missing \begin{document}.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
  ...

l.4 \begin
           {document}
You're in trouble here.  Try typing  <return>  to proceed.
If that doesn't work, type  X <return>  to quit.

! Extra \endcsname.
\@onefilewithoptions ...\@currext -h@@k\endcsname
                                                   \@empty \let 
\CurrentOptio...
l.4 \begin
           {document}
I'm ignoring this, since I wasn't doing a \csname.

! Missing \endcsname inserted.
<to be read again>
                    \protect
l.4 \begin
           {document}
The control sequence marked <to be read again> should
not appear between \csname and \endcsname.

! Extra \endcsname.
\@ifl at aded ...er \ifx \csname ver@#2.#1\endcsname
                                                   \relax \expandafter 
\@seco...
l.4 \begin
           {document}
I'm ignoring this, since I wasn't doing a \csname.

! Missing \endcsname inserted.
<to be read again>
                    \protect
l.4 \begin
           {document}
The control sequence marked <to be read again> should
not appear between \csname and \endcsname.

! Extra \endcsname.
\@pass at ptions ...xdef \csname opt@#3.#1\endcsname
                                                   {\@ifundefined 
{opt@#3.#1}...
l.4 \begin
           {document}
I'm ignoring this, since I wasn't doing a \csname.

! Missing \endcsname inserted.
<to be read again>
                    \protect
l.4 \begin
           {document}
The control sequence marked <to be read again> should
not appear between \csname and \endcsname.

! Missing \endcsname inserted.
<to be read again>
                    \protect
l.4 \begin
           {document}
The control sequence marked <to be read again> should
not appear between \csname and \endcsname.

! Extra \endcsname.
<argument> ...e/texmf/Sweave.\@currext \endcsname
                                                   ,
l.4 \begin
           {document}
I'm ignoring this, since I wasn't doing a \csname.

! Missing \endcsname inserted.
<to be read again>
                    \protect
l.4 \begin
           {document}
The control sequence marked <to be read again> should
not appear between \csname and \endcsname.

! Extra \endcsname.
<argument> ...er@\@currname .\@currext \endcsname
                                                   \@empty 
\InputIfFileExists...
l.4 \begin
           {document}
I'm ignoring this, since I wasn't doing a \csname.


! LaTeX Error: File `C:/PROGRA\unhbox\voidb at x \penalty \@M \ 
{}1/R/rw1081/share
/texmf/Sweave.sty' not found.

Type X to quit or <RETURN> to proceed,
or enter new name. (Default extension: sty)

Enter file name: x


Overfull \hbox (689.89102pt too wide) in paragraph at lines 4--4
[][] \OT1/cmr/m/n/10 1/R/rw1081/share/texmf/Sweave.sty-h@@k 
1/R/rw1081/share/te
xmf/Sweave.sty1/R/rw1081/share/texmf/Sweave.sty1/R/rw1081/share/texmf/Sweave.st
y, 1/R/rw1081/share/texmf/Sweave.sty 1/R/rw1081/share/texmf/Sweave.sty
  []

  )
(\end occurred when \ifx on line 4 was incomplete)
(\end occurred when \ifx on line 4 was incomplete)
Here is how much of TeX's memory you used:
  205 strings out of 96052
  1946 string characters out of 1197190
  46593 words of memory out of 1050795
  3221 multiletter control sequences out of 35000
  3640 words of font info for 14 fonts, out of 500000 for 1000
  14 hyphenation exceptions out of 607
  23i,1n,17p,117b,40s stack positions out of 1500i,500n,5000p,200000b,32768s

No pages of output.
===

Any comments welcome!

Murray


-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From jfox at mcmaster.ca  Thu Jan 29 05:19:47 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 28 Jan 2004 23:19:47 -0500
Subject: [R] Confirmatory Factor Analysis in R? SEM?
In-Reply-To: <1075339317.58c7f100arnab@myrealbox.com>
Message-ID: <5.1.0.14.2.20040128231235.0204adc0@127.0.0.1>

Dear Arnab,

You can indeed fit confirmatory factor analysis models with the sem 
package, and ?sem includes an example of a second-order CFI (though I'm not 
sure I see the point of factor-analyzing uncorrelated variables). In factor 
analysis, moreover, the observed variables are functions of the factors, 
not vice-versa (which is how you've specified it). As well, you have to 
define variances and possibly covariances for the factors.

You'll find a simpler example in some lecture notes at 
<http://socserv.socsci.mcmaster.ca/jfox/Courses/soc761/index.html#lecture-notes>, 
along with the corresponding sem commands.

I hope that this helps,
  John


At 01:21 AM 1/29/2004 +0000, Arnab mukherji wrote:
>Hi
>
>Has anyone used R to conduct confirmatory factor analysis?  This email 
>pertains to use of SEM.
>
>For context consider an example: the basic idea is that there are a bunch 
>of observables variables (say study habbits, amount of time reading in the 
>bus, doing homework, helping other do homework, doing follow-up on errors 
>etc.) and one believes that all these variables maybe measured by two or 
>more unobservable constructs... say ability to work hard and ability to 
>follow instructions. If one has empirical evidence from earlier studies 
>which relates similar observable to similar unobservables one wants to do 
>a confirmatory factor analysis to check if the posited relationship holds 
>in the current data being analyzed.
>
>I thought the way out would be to use SEM - the structural equation model 
>library. However, i am not sure how to estimate SEM objects where factors 
>are unobservable. The only discussion pertian to the case of endogenously 
>detemined observable variables.
>
>here is a test case of what i'd like to implement
>
>#example Measurement Model
>
>x1<-runif(200)
>x2<-rbinom(200, 20, 0.75)
>x3<-runif(200)
>x4<-runif(200)
>dat<-as.data.frame(x1 =x1, x2 = x2, x3 = x3, x4 = x4)
>
>v.c<-cor(dat,use = "complete.obs")
>ind<-upper.tri(v.c)
>v.c[ind]<-0
>model.dhp<-matrix (c(
>                        "x1 -> HWK", "gam11", NA,
>                        "x2 -> HWK", "gam21", NA,
>                        "x2 -> FI",  "gam22", NA,
>                        "x3 -> HWK", "gam31", NA,
>                        "x3 -> F1", "gam32", NA,
>                        "x4 -> F1", "gam42", NA),
>                        ncol = 3, byrow = TRUE)
>These are the Factor loadings i'd like to test for:
>  variable   HWK     FI
>  x1         0.75    0
>  x2         0.20    0.68
>  x3         0.2     0.5
>  x4         0       0.24
>
>
>thanks for any help on this.
>
>Arnab

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From p.pagel at gsf.de  Thu Jan 29 08:07:15 2004
From: p.pagel at gsf.de (Philipp Pagel)
Date: Thu, 29 Jan 2004 08:07:15 +0100
Subject: [R] Read In and Output Postscript file
In-Reply-To: <1075332671.31290.50.camel@localhost.localdomain>
References: <46784484-51CF-11D8-BFBA-000393A37A1A@post.tamu.edu>
	<1075332671.31290.50.camel@localhost.localdomain>
Message-ID: <20040129070714.GA1598@porcupine.gsf.de>

On Wed, Jan 28, 2004 at 05:31:11PM -0600, Marc Schwartz wrote:
> On Wed, 2004-01-28 at 14:19, Brad Holmes wrote:
> > 
> > Would it be possible to read in a pre-existing postscript file, and 
> > output it "as is" through R?
> > 
> > I have five plots, and I am placing them in a layout that is 2 X 3. I 
> > was hoping to "insert" the pre-existing postscript file made from 
> > Molscript in the last spot.
> 
> Your e-mail header suggests that you are on a Mac. If you have access to
> MS Word or an alternate document processing program like OpenOffice or a
> functional equivalent, you can import EPS files into a table, with each
> graphic going into a cell in the table. You can then "print" the
> document to a PS file, using a PS printer driver.
> 
> Others may have alternate ideas.

Yes: I'd recommend Illustrator rather than Word/OOo for this. 

But actually, the original question got me curious. How difficult would
it be to add EPS import to the postscript device? Other devices could
just ignore it or simply read the bounding box and insert the usual
empty box which says "EPS file". I guess I'll go for a litte walk in the
source code when I have a little spare time to burn. ;-)

I mean - this could be really usefull: Finally R would be capable of
producing the wealth of chartjunk other software has offered for
decades! Imagine using your corporate logo instead of boring circles or
dots for plotting! (OK ok - ouch - don't beat me, please...) ;-)


cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From ripley at stats.ox.ac.uk  Thu Jan 29 08:53:33 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Jan 2004 07:53:33 +0000 (GMT)
Subject: [R]Running R remotely in Windows Environment?
In-Reply-To: <5.1.1.6.0.20040128162138.02997310@pop3.norton.antivirus>
Message-ID: <Pine.LNX.4.44.0401290745590.3479-100000@gannet.stats>

On Wed, 28 Jan 2004, Jim Porzak wrote:

> We are considering setting up a fast, RAM loaded machine as an "R-server" 
> to handle the big problems not suitable for individual desktops and, also, 
> to process ad hoc analysis requests via our portal. We are 99% a Windows 
> shop, so first choice is a windows server. We'll use (D)COM for the portal 
> interface and understand that.
> 
> What has me stumped is how to easily interface individual analyst's Windows 
> desktops to the R-server. I haven't seen anything in the archives, but I 
> can't imagine this hasn't been done. What am I missing?

R is not designed to be client-server on Windows.  People I know who do
this use Windows Terminal Server or Citrix.

I would question the value of this approach.  Unless you propose to run
64-bit Windows, a `RAM loaded' machine isn't `loaded', and R under Windows
handles large amounts of memory much less effectively than under Linux.  
64-bit Windows is uncharted territory for R, whereas 64-bit Unix/Linux is
well trodden.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Jan 29 08:59:40 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Jan 2004 07:59:40 +0000 (GMT)
Subject: [R] Finding Sweave.sty and other problems
In-Reply-To: <4018887D.502@stats.waikato.ac.nz>
Message-ID: <Pine.LNX.4.44.0401290756290.3479-100000@gannet.stats>

~ is an active character in TeX, so it assumes it is not in a filename.
You will need to escape it.

It would be better to have
\usepackage{Sweave}
there and the path in your TEXINPUTS.  TeX is not really designed to work 
with file paths.

On Thu, 29 Jan 2004, Murray Jorgensen wrote:

> Hi,
> 
> I've just tried to run example-3 from Friedrich Leish. I'm using R 1.8.1 
> and MiKTeX 2.2 on Windows XP.
> 
> I go
> ===
>  > library(tools)
>  > Sweave("example-3.Snw")
> Writing to file example-3.tex
> Processing code chunks ...
>   1 : term hide
>   2 : echo term verbatim
>   3 : term tex
>   4 : term verbatim eps pdf
> 
> You can now run LaTeX on example-3.tex
> ===
> The file example-3.tex looks OK, it starts off
> ===
> \documentclass[a4paper]{article}
> 
> \usepackage{C:/PROGRA~1/R/rw1081/share/texmf/Sweave}
> \begin{document}
> 
> 
> \section*{The Cats Data}
> ..........
> ===
> but my LaTeX log file tells a sad story:
> ===
> This is TeX, Version 3.141592 (MiKTeX 2.2) (preloaded format=latex 
> 2000.11.28)  29 JAN 2004 16:36
> **example-3.tex
> (example-3.tex
> LaTeX2e <2001/06/01>
> Babel <v3.7h> and hyphenation patterns for english, french, german, 
> ngerman, du
> mylang, nohyphenation, loaded.
> (C:\texmf\tex\latex\base\article.cls
> Document Class: article 2001/04/21 v1.4e Standard LaTeX document class
> (C:\texmf\tex\latex\base\size10.clo
> File: size10.clo 2001/04/21 v1.4e Standard LaTeX file (size option)
> )
> \c at part=\count79
> \c at section=\count80
> \c at subsection=\count81
> \c at subsubsection=\count82
> \c at paragraph=\count83
> \c at subparagraph=\count84
> \c at figure=\count85
> \c at table=\count86
> \abovecaptionskip=\skip41
> \belowcaptionskip=\skip42
> \bibindent=\dimen102
> )
> ! Missing \endcsname inserted.
> <to be read again>
>                     \protect
> l.4 \begin
>            {document}
> ? s
> OK, entering \scrollmode...
> 
> ! LaTeX Error: Missing \begin{document}.
> 
> See the LaTeX manual or LaTeX Companion for explanation.
> Type  H <return>  for immediate help.
>   ...
> 
> l.4 \begin
>            {document}
> You're in trouble here.  Try typing  <return>  to proceed.
> If that doesn't work, type  X <return>  to quit.
> 
> ! Extra \endcsname.
> \@onefilewithoptions ...\@currext -h@@k\endcsname
>                                                    \@empty \let 
> \CurrentOptio...
> l.4 \begin
>            {document}
> I'm ignoring this, since I wasn't doing a \csname.
> 
> ! Missing \endcsname inserted.
> <to be read again>
>                     \protect
> l.4 \begin
>            {document}
> The control sequence marked <to be read again> should
> not appear between \csname and \endcsname.
> 
> ! Extra \endcsname.
> \@ifl at aded ...er \ifx \csname ver@#2.#1\endcsname
>                                                    \relax \expandafter 
> \@seco...
> l.4 \begin
>            {document}
> I'm ignoring this, since I wasn't doing a \csname.
> 
> ! Missing \endcsname inserted.
> <to be read again>
>                     \protect
> l.4 \begin
>            {document}
> The control sequence marked <to be read again> should
> not appear between \csname and \endcsname.
> 
> ! Extra \endcsname.
> \@pass at ptions ...xdef \csname opt@#3.#1\endcsname
>                                                    {\@ifundefined 
> {opt@#3.#1}...
> l.4 \begin
>            {document}
> I'm ignoring this, since I wasn't doing a \csname.
> 
> ! Missing \endcsname inserted.
> <to be read again>
>                     \protect
> l.4 \begin
>            {document}
> The control sequence marked <to be read again> should
> not appear between \csname and \endcsname.
> 
> ! Missing \endcsname inserted.
> <to be read again>
>                     \protect
> l.4 \begin
>            {document}
> The control sequence marked <to be read again> should
> not appear between \csname and \endcsname.
> 
> ! Extra \endcsname.
> <argument> ...e/texmf/Sweave.\@currext \endcsname
>                                                    ,
> l.4 \begin
>            {document}
> I'm ignoring this, since I wasn't doing a \csname.
> 
> ! Missing \endcsname inserted.
> <to be read again>
>                     \protect
> l.4 \begin
>            {document}
> The control sequence marked <to be read again> should
> not appear between \csname and \endcsname.
> 
> ! Extra \endcsname.
> <argument> ...er@\@currname .\@currext \endcsname
>                                                    \@empty 
> \InputIfFileExists...
> l.4 \begin
>            {document}
> I'm ignoring this, since I wasn't doing a \csname.
> 
> 
> ! LaTeX Error: File `C:/PROGRA\unhbox\voidb at x \penalty \@M \ 
> {}1/R/rw1081/share
> /texmf/Sweave.sty' not found.
> 
> Type X to quit or <RETURN> to proceed,
> or enter new name. (Default extension: sty)
> 
> Enter file name: x
> 
> 
> Overfull \hbox (689.89102pt too wide) in paragraph at lines 4--4
> [][] \OT1/cmr/m/n/10 1/R/rw1081/share/texmf/Sweave.sty-h@@k 
> 1/R/rw1081/share/te
> xmf/Sweave.sty1/R/rw1081/share/texmf/Sweave.sty1/R/rw1081/share/texmf/Sweave.st
> y, 1/R/rw1081/share/texmf/Sweave.sty 1/R/rw1081/share/texmf/Sweave.sty
>   []
> 
>   )
> (\end occurred when \ifx on line 4 was incomplete)
> (\end occurred when \ifx on line 4 was incomplete)
> Here is how much of TeX's memory you used:
>   205 strings out of 96052
>   1946 string characters out of 1197190
>   46593 words of memory out of 1050795
>   3221 multiletter control sequences out of 35000
>   3640 words of font info for 14 fonts, out of 500000 for 1000
>   14 hyphenation exceptions out of 607
>   23i,1n,17p,117b,40s stack positions out of 1500i,500n,5000p,200000b,32768s
> 
> No pages of output.
> ===
> 
> Any comments welcome!
> 
> Murray
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From s-plus at wiwi.uni-bielefeld.de  Thu Jan 29 09:14:08 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Thu, 29 Jan 2004 09:14:08 +0100
Subject: [R] How to generate a report with graphics and tables?
References: <3A822319EB35174CA3714066D590DCD504AF76B4@usrymx25.merck.com>
Message-ID: <4018C0D0.4000404@wiwi.uni-bielefeld.de>

Liaw, Andy wrote:

>If you don't mind pdf report generated from LaTeX, Sweave would probably
>work nicely for you.  See the two articles on it in R News, which you can
>find on the R web site.
>
>One other possibility is to use the R2HTML package (and maybe the xtable
>package, too) to write the `report' in HTML.
>
>HTH,
>Andy
>
>  
>
>>From: Olaf B?rger
>>
>>Hello R-Users,
>>
>>I have some data sets which change on a daily bases. So far I have 
>>imported  these sets into R, done all my evaluations resulting in a 
>>couple of plots, charts and tables of numbers which I copy&pasted via 
>>clipboard into Powerpoint.
>>The procedure is always the same and I wonder, whether there is no 
>>easier way for doing so. Is there some type of "report generator" 
>>available or some HowTo on this.
>>
>>Can anybody give me a hint on where to look for?
>>
>>Regards,
>>
>>Olaf B?rger
>>    
>>
A third way is to use the R function ff:

Step 1: define a raw latex-report with R expressions (e.g. report.tex)
Step 2: modify some expressions in the raw report according the local 
situation (data sets, etc.)
Step 3: start R and evaluate ff("report.tex")
Step 4: latex report
Step 5: repeat 2-4 for the different data sets

Here is the link to the rd file:

See: 
http://www.wiwi.uni-bielefeld.de/~wolf/software/R-wtools/formfill/ff.html
or http://www.wiwi.uni-bielefeld.de/~wolf/software/R-wtools/formfill/ff.rd

Peter Wolf



From maechler at stat.math.ethz.ch  Thu Jan 29 09:15:07 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 29 Jan 2004 09:15:07 +0100
Subject: [R] Math Expression and Variable Value in Title
In-Reply-To: <40185550.6060806@jhsph.edu>
References: <Pine.SOL.4.58.0401281605270.12830@stat.psych.uiuc.edu>
	<40185550.6060806@jhsph.edu>
Message-ID: <16408.49419.637798.858707@gargle.gargle.HOWL>

>>>>> "Roger" == Roger D Peng <rpeng at jhsph.edu>
>>>>>     on Wed, 28 Jan 2004 19:35:28 -0500 writes:

    Roger> Use substitute()
Yes!

    Roger> n <- 20
    Roger> plot(0, 0, main = substitute(paste(n[i], " = ", k), list(k = n)))

but even better is

           plot(0, 0, main = substitute(n[i] == k, list(k = n)))

(note the "==" !)

Martin



From maechler at stat.math.ethz.ch  Thu Jan 29 09:22:31 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 29 Jan 2004 09:22:31 +0100
Subject: [R] Calculating/understanding variance-covariance matrix of
	logistic regression (lrm $var)
In-Reply-To: <20040129013427.34751.qmail@web10003.mail.yahoo.com>
References: <20040129013427.34751.qmail@web10003.mail.yahoo.com>
Message-ID: <16408.49863.180455.872626@gargle.gargle.HOWL>

>>>>> "Karl" == Karl Knoblick <karlknoblich at yahoo.de>
>>>>>     on Thu, 29 Jan 2004 02:34:27 +0100 (CET) writes:

    Karl> Hallo!
    Karl> I want to understand / recalculate what is done to get
    Karl> the CI of the logistic regression evaluated with lrm.
    Karl> As far as I came back, my problem is the
    Karl> variance-covariance matrix fit$var of the fit
    Karl> (fit<-lrm(...), fit$var). Here what I found and where
    Karl> I stucked:

    Karl> -----------------
    Karl> library(Design)

    .....

The usual ("official") R (and S) way for this is using  
    r <- glm(..., family = binomial)
with  predict(r, .., se.fit=TRUE) 
and   vcov(r)
giving the variance-covariance matrix,
calling the vcov.glm(.) method in this case, which it self
mainly relies on summary.glm(.).

---

As you see yourself,  lrm() is from a particular CRAN package by
Prof Frank Harrell and if you really want that, you should ask
the package author -- as you are told in the posting guide
(you should read! -- see the last line of every R-help message).

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ahenningsen at agric-econ.uni-kiel.de  Thu Jan 29 09:44:52 2004
From: ahenningsen at agric-econ.uni-kiel.de (Arne Henningsen)
Date: Thu, 29 Jan 2004 09:44:52 +0100
Subject: [R]Running R remotely in Windows Environment?
In-Reply-To: <Pine.LNX.4.44.0401290745590.3479-100000@gannet.stats>
References: <Pine.LNX.4.44.0401290745590.3479-100000@gannet.stats>
Message-ID: <200401290944.52721.ahenningsen@agric-econ.uni-kiel.de>

Hi, 

I also suggest to use a Linux Server. You can work on this machine via ssh 
(e.g. with PuTTY) and transfer the input and output files with scp or a samba 
server (which is easy to install and very convenient to use for windows 
users).

Arne

On Thursday 29 January 2004 08:53, Prof Brian Ripley wrote:
> On Wed, 28 Jan 2004, Jim Porzak wrote:
> > We are considering setting up a fast, RAM loaded machine as an "R-server"
> > to handle the big problems not suitable for individual desktops and,
> > also, to process ad hoc analysis requests via our portal. We are 99% a
> > Windows shop, so first choice is a windows server. We'll use (D)COM for
> > the portal interface and understand that.
> >
> > What has me stumped is how to easily interface individual analyst's
> > Windows desktops to the R-server. I haven't seen anything in the
> > archives, but I can't imagine this hasn't been done. What am I missing?
>
> R is not designed to be client-server on Windows.  People I know who do
> this use Windows Terminal Server or Citrix.
>
> I would question the value of this approach.  Unless you propose to run
> 64-bit Windows, a `RAM loaded' machine isn't `loaded', and R under Windows
> handles large amounts of memory much less effectively than under Linux.
> 64-bit Windows is uncharted territory for R, whereas 64-bit Unix/Linux is
> well trodden.

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From uaca at alumni.uv.es  Thu Jan 29 09:50:45 2004
From: uaca at alumni.uv.es (uaca@alumni.uv.es)
Date: Thu, 29 Jan 2004 09:50:45 +0100
Subject: [R] Re: conditional assignment
In-Reply-To: <20040126191551.GA14785@pusa.informat.uv.es>
References: <20040126191551.GA14785@pusa.informat.uv.es>
Message-ID: <20040129085045.GA24235@pusa.informat.uv.es>



Hi all again

I could not reply before because I was/am very busy

ifthenelse() is what I wanted, I have to read more carefully your
explanations to better understand it

Thanks everybody

	Ulisses
	


On Mon, Jan 26, 2004 at 08:15:51PM +0100, uaca at alumni.uv.es wrote:
> 
> Hi all
> 
> I want to conditionally operate on certain elements of a matrix, let me
> explain it with a simple vector example
> 
> 
> > z<- c(1, 2, 3)
> > zz <- c(0,0,0)
> > null <- (z > 2) & ( zz <- z)
> > zz
> [1] 1 2 3
> 
> why zz is not (0, 0, 3) ?????
> 
> 
> the null <- assignment is to keep the console silent
> 
> in the other hand, it curious that null has reasonable values
> 
> > null
> [1] FALSE FALSE  TRUE
> 
> Thanks in advance
> 
> 	Ulisses
> 
>                 Debian GNU/Linux: a dream come true
> -----------------------------------------------------------------------------
> "Computers are useless. They can only give answers."            Pablo Picasso
> 
> Humans are slow, innaccurate, and brilliant.
> Computers are fast, acurrate, and dumb. 
> Together they are unbeatable
> 
> --->	Visita http://www.valux.org/ para saber acerca de la	<---
> --->	Asociaci?n Valenciana de Usuarios de Linux		<---
>  

-- 
                Debian GNU/Linux: a dream come true
-----------------------------------------------------------------------------
"Computers are useless. They can only give answers."            Pablo Picasso

Humans are slow, innaccurate, and brilliant.
Computers are fast, acurrate, and dumb. 
Together they are unbeatable

--->	Visita http://www.valux.org/ para saber acerca de la	<---
--->	Asociaci?n Valenciana de Usuarios de Linux		<---



From siewlengteng at yahoo.com  Thu Jan 29 10:03:56 2004
From: siewlengteng at yahoo.com (Siew Leng TENG)
Date: Thu, 29 Jan 2004 01:03:56 -0800 (PST)
Subject: [R] Help in error : SAM function in library siggenes
Message-ID: <20040129090356.86302.qmail@web60509.mail.yahoo.com>

Hi,

I had the following situation and I greatly appreciate
any advice.

SAM gave the following error  :

"Error in var(v) : missing observations in cov/cor"

when applied on a dataset. The error was traced to a
variance computation of a vector containing NA in
fudge() [a subroutine called by SAM()]. This vector is
a computational output in fudge() :

"cv[i] <- sqrt(var(v))/mean(v)"

The same error was encountered when SAM was applied to
other similar datasets. Would modifying the statement
to "var(v, na.rm=TRUE)" be a possibility?

Many thanks,
Siew Leng
R-1.8.1 on Windows XP Home Edition

Code snippets :
data <- matrix(runif(25, 0,1), nrow=5)
x <- 1 : 5
sam(data, x)



From Bernhard.Pfaff at drkw.com  Thu Jan 29 10:07:09 2004
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Thu, 29 Jan 2004 10:07:09 +0100
Subject: [R] How to generate a report with graphics and tables?
Message-ID: <18D602BD42B7E24EB810D6454A58DB900473080A@ibfftce505.is.de.dresdnerkb.com>

> 
> Hello R-Users,
> 
> I have some data sets which change on a daily bases. So far I have 
> imported  these sets into R, done all my evaluations resulting in a 
> couple of plots, charts and tables of numbers which I copy&pasted via 
> clipboard into Powerpoint.
                 ^^^^^^^^^^
Hello Olaf,

if you follow the previously given advices, i.e using Sweave/LaTeX, you
might consider the package "pdfscreen" and/or an utility program "ppower",
to enhance your "LaTeX-presentation".

HTH,
Bernhard

http://www.tp4.ruhr-uni-bochum.de/SoftwareDocs/pdfsc/pdfscr-doc.html

http://www.ctan.org/tex-archive/support/ppower4/?action=/tex-archive/support
/  


> The procedure is always the same and I wonder, whether there is no 
> easier way for doing so. Is there some type of "report generator" 
> available or some HowTo on this.
> 
> Can anybody give me a hint on where to look for?
> 
> Regards,
> 
> Olaf B?rger
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html


--------------------------------------------------------------------------------
The information contained herein is confidential and is intended solely for the
addressee. Access by any other party is unauthorised without the express 
written permission of the sender. If you are not the intended recipient, please 
contact the sender either via the company switchboard on +44 (0)20 7623 8000, or
via e-mail return. If you have received this e-mail in error or wish to read our
e-mail disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.



From maj at stats.waikato.ac.nz  Thu Jan 29 10:05:44 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu, 29 Jan 2004 22:05:44 +1300
Subject: [R] Finding Sweave.sty and other problems
In-Reply-To: <Pine.LNX.4.44.0401290756290.3479-100000@gannet.stats>
References: <4018887D.502@stats.waikato.ac.nz>
Message-ID: <E1Am89i-0006Vv-00@newton.math.waikato.ac.nz>

Hmmm, I can certainly remove the path from the \usepackage command. (Now
that I come to think of it, I have never seen that in LaTeX before.) I
wonder why Sweave put it there in the first place? I thought that I was
just running it "straight out of the box". Don't tell me though: I will
read the manual some more.

Murray

At 07:59 29/01/2004 +0000, Prof Brian Ripley wrote:
>~ is an active character in TeX, so it assumes it is not in a filename.
>You will need to escape it.
>
>It would be better to have
>\usepackage{Sweave}
>there and the path in your TEXINPUTS.  TeX is not really designed to work 
>with file paths.
>
>On Thu, 29 Jan 2004, Murray Jorgensen wrote:
>
>> Hi,
>> 
>> I've just tried to run example-3 from Friedrich Leish. I'm using R 1.8.1 
>> and MiKTeX 2.2 on Windows XP.
>> 
>> I go
>> ===
>>  > library(tools)
>>  > Sweave("example-3.Snw")
>> Writing to file example-3.tex
>> Processing code chunks ...
>>   1 : term hide
>>   2 : echo term verbatim
>>   3 : term tex
>>   4 : term verbatim eps pdf
>> 
>> You can now run LaTeX on example-3.tex
>> ===
>> The file example-3.tex looks OK, it starts off
>> ===
>> \documentclass[a4paper]{article}
>> 
>> \usepackage{C:/PROGRA~1/R/rw1081/share/texmf/Sweave}
>> \begin{document}
>> 
>> 
>> \section*{The Cats Data}
>> ..........
>> ===
>> but my LaTeX log file tells a sad story:
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From ripley at stats.ox.ac.uk  Thu Jan 29 10:23:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Jan 2004 09:23:19 +0000 (GMT)
Subject: [R] Math Expression and Variable Value in Title
In-Reply-To: <4018C9A6.5070703@uni-goettingen.de>
Message-ID: <Pine.LNX.4.44.0401290918440.5962-100000@gannet.stats>

Note that this will circumvent all the careful work in R to align the 
plotmath text correctly.  In your case that includes having space for the 
subscript.  It may not matter for main titles, but it certainly does for 
ylab or axis annotation or ....

People might be producing PDF or Windows metafiles.  I often produce PDF 
figures for inclusion in my PDF lecture slides.


On Thu, 29 Jan 2004, Salvatore Barbaro wrote:

> An alternative but also higly recommendable way is the use of the 
> psfrag-package in your LaTeX-file. It is furthermore very simple in use.
> 
> Type
> 
> plot(1:10, main="test")
> 
> in your LaTeX-file you insert in your figure-environment the command
> \psfrag{test}{$n_i=20$}
> before you call the \includegraphics{}
> 
> best regards
> 
> yours
> 
> s.
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> Wolfgang Viechtbauer wrote:
> > Hello All,
> > 
> > I am trying to put a math expression into a plot title and at the same
> > time, I want a value in the title to depend on a variable that I set
> > earlier.
> > 
> > Simple Example:
> > 
> > n <- 20
> > plot(0, 0)
> > title(expression(paste(n[i], " = ", n)))
> > 
> > Obviously, I want "n_i = 20". How can I get that?
> > 
> > Thanks in advance,
> > 
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sbarbar at uni-goettingen.de  Thu Jan 29 09:51:50 2004
From: sbarbar at uni-goettingen.de (Salvatore Barbaro)
Date: Thu, 29 Jan 2004 09:51:50 +0100
Subject: [R] Math Expression and Variable Value in Title
In-Reply-To: <Pine.SOL.4.58.0401281605270.12830@stat.psych.uiuc.edu>
References: <Pine.SOL.4.58.0401281605270.12830@stat.psych.uiuc.edu>
Message-ID: <4018C9A6.5070703@uni-goettingen.de>

An alternative but also higly recommendable way is the use of the 
psfrag-package in your LaTeX-file. It is furthermore very simple in use.

Type

plot(1:10, main="test")

in your LaTeX-file you insert in your figure-environment the command
\psfrag{test}{$n_i=20$}
before you call the \includegraphics{}

best regards

yours

s.













Wolfgang Viechtbauer wrote:
> Hello All,
> 
> I am trying to put a math expression into a plot title and at the same
> time, I want a value in the title to depend on a variable that I set
> earlier.
> 
> Simple Example:
> 
> n <- 20
> plot(0, 0)
> title(expression(paste(n[i], " = ", n)))
> 
> Obviously, I want "n_i = 20". How can I get that?
> 
> Thanks in advance,
> 


-- 
Salvatore Barbaro
University of Goettingen
Department of Public Economics
Platz der Goettinger Sieben 3
D-37073 Goettingen
Phone: +49 551 3919704



From hb at maths.lth.se  Thu Jan 29 11:24:44 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 29 Jan 2004 11:24:44 +0100
Subject: [R] Math Expression and Variable Value in Title
In-Reply-To: <40185550.6060806@jhsph.edu>
Message-ID: <000001c3e652$1dfe7cf0$e502eb82@maths.lth.se>

A quick comment. paste() is not needed here; you can get "=" using
'==' as follows

 substitute(n[i]==k, list=list(k=n))

Cheers

Henrik

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Roger D. Peng
> Sent: den 29 januari 2004 01:35
> To: Wolfgang Viechtbauer
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Math Expression and Variable Value in Title
> 
> 
> Use substitute()
> 
> n <- 20
> plot(0, 0, main = substitute(paste(n[i], " = ", k), list(k = n)))
> 
> -roger
> 
> Wolfgang Viechtbauer wrote:
> 
> > Hello All,
> > 
> > I am trying to put a math expression into a plot title and 
> at the same 
> > time, I want a value in the title to depend on a variable 
> that I set 
> > earlier.
> > 
> > Simple Example:
> > 
> > n <- 20
> > plot(0, 0)
> > title(expression(paste(n[i], " = ", n)))
> > 
> > Obviously, I want "n_i = 20". How can I get that?
> > 
> > Thanks in advance,
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From dmurdoch at pair.com  Thu Jan 29 12:54:33 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 29 Jan 2004 06:54:33 -0500
Subject: [R] Help in error : SAM function in library siggenes
In-Reply-To: <20040129090356.86302.qmail@web60509.mail.yahoo.com>
References: <20040129090356.86302.qmail@web60509.mail.yahoo.com>
Message-ID: <3ksh10p6s8lcjlg1jlp9b5nu66lj07j8ea@4ax.com>

On Thu, 29 Jan 2004 01:03:56 -0800 (PST), you wrote:

>Hi,
>
>I had the following situation and I greatly appreciate
>any advice.
>
>SAM gave the following error  :
>
>"Error in var(v) : missing observations in cov/cor"
>
>when applied on a dataset. The error was traced to a
>variance computation of a vector containing NA in
>fudge() [a subroutine called by SAM()]. This vector is
>a computational output in fudge() :
>
>"cv[i] <- sqrt(var(v))/mean(v)"
>
>The same error was encountered when SAM was applied to
>other similar datasets. Would modifying the statement
>to "var(v, na.rm=TRUE)" be a possibility?

SAM() and sam() are different names in R, but neither of them is in
the base packages.  Which package did you find sam() in?  You probably
want to ask the author of the package if this modification would be
safe.

Duncan Murdoch



From andy_liaw at merck.com  Thu Jan 29 14:34:47 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 29 Jan 2004 08:34:47 -0500
Subject: [R] How to generate a report with graphics and tables?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76BA@usrymx25.merck.com>

> From: Pfaff, Bernhard
> > 
> > Hello R-Users,
> > 
> > I have some data sets which change on a daily bases. So far I have 
> > imported  these sets into R, done all my evaluations resulting in a 
> > couple of plots, charts and tables of numbers which I 
> copy&pasted via 
> > clipboard into Powerpoint.
>                  ^^^^^^^^^^
> Hello Olaf,
> 
> if you follow the previously given advices, i.e using 
> Sweave/LaTeX, you
> might consider the package "pdfscreen" and/or an utility 
> program "ppower",
> to enhance your "LaTeX-presentation".

or even prosper:  http://prosper.sourceforge.net/

Andy
 
> HTH,
> Bernhard
> 
http://www.tp4.ruhr-uni-bochum.de/SoftwareDocs/pdfsc/pdfscr-doc.html

http://www.ctan.org/tex-archive/support/ppower4/?action=/tex-archive/support


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From andy_liaw at merck.com  Thu Jan 29 14:42:19 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 29 Jan 2004 08:42:19 -0500
Subject: [R]Running R remotely in Windows Environment?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76BB@usrymx25.merck.com>

I would also give my votes to Linux.  That's essentially the main function
of our Linux boxes, and some of the boxes are `RAM loaded'.  We just use VNC
to connect from the Windoze desktop to the Linux boxes.  We can mount the
Windows shared drives on the Linux boxes for file sharing.  One of my former
interns ran all her R sessions from a Windows shared drive on a Linux box.

Andy

> From: Jim Porzak
> 
> We are considering setting up a fast, RAM loaded machine as 
> an "R-server" 
> to handle the big problems not suitable for individual 
> desktops and, also, 
> to process ad hoc analysis requests via our portal. We are 
> 99% a Windows 
> shop, so first choice is a windows server. We'll use (D)COM 
> for the portal 
> interface and understand that.
> 
> What has me stumped is how to easily interface individual 
> analyst's Windows 
> desktops to the R-server. I haven't seen anything in the 
> archives, but I 
> can't imagine this hasn't been done. What am I missing?
> 
> TIA!
> 
> Jim Porzak
> Director of Analytics
> Loyalty Matrix, Inc.
> www.LoyaltyMatrix.com


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From mlaia at fcav.unesp.br  Thu Jan 29 15:33:25 2004
From: mlaia at fcav.unesp.br (Marcelo Luiz de Laia)
Date: Thu, 29 Jan 2004 11:33:25 -0300
Subject: [R] Doubt about pattern
Message-ID: <20040129113325.00004242@lbmsala4>

Hi All,

I have a very simple problem. I have several files in a same directory. I would like to send for an object only the files that finish in ".sens.". I execute the command below,

files <- dir(pattern="*.sens")

but it includes all of the files that have "sens", independent of they be in the end or in the middle of the name of the file. How could I solve this? I sought in the html_help but I didn't find similar to this.

My files

"script_sens.txt", "Sen_155_01_R1.sens", "Sen_155_01_R2.sens", "Sen_155_01_R3.sens", "Sen_155_02_R1.sens", "Sen_155_02_R2.sens", "Sen_155_02_R3.sens", "Sen_155_03_R1.sens", "Sen_155_03_R2.sens", "Sen_155_03_R3.sens", "tome2sens_time1sens.txt"

Tahnks very much

-- 
Marcelo Luiz de Laia, M.Sc.
Dep. de Tecnologia, Lab. Bioqu?mica e de Biologia Molecular
Universidade Estadual Paulista - UNESP
Via de Acesso Prof. Paulo Donato Castelane, Km 05
14.884-900 - Jaboticabal, SP, Brazil
PhoneFax: 16 3209-2675/2676/2677 R. 202/208/203 (trab.)
HomePhone: 16 3203 2328 - www.lbm.fcav.unesp.br - mlaia at yahoo.com



From jmacdon at med.umich.edu  Thu Jan 29 14:54:41 2004
From: jmacdon at med.umich.edu (James MacDonald)
Date: Thu, 29 Jan 2004 08:54:41 -0500
Subject: [R] Help in error : SAM function in library siggenes
Message-ID: <s018ca58.047@med-gwia-02a.med.umich.edu>

siggenes is part of Bioconductor, and the author is Holger Schwender.
You should ask Holger first (holger.schw at gmx.de), and the BioC list
second.

Best,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> Duncan Murdoch <dmurdoch at pair.com> 01/29/04 06:54AM >>>
On Thu, 29 Jan 2004 01:03:56 -0800 (PST), you wrote:

>Hi,
>
>I had the following situation and I greatly appreciate
>any advice.
>
>SAM gave the following error  :
>
>"Error in var(v) : missing observations in cov/cor"
>
>when applied on a dataset. The error was traced to a
>variance computation of a vector containing NA in
>fudge() [a subroutine called by SAM()]. This vector is
>a computational output in fudge() :
>
>"cv[i] <- sqrt(var(v))/mean(v)"
>
>The same error was encountered when SAM was applied to
>other similar datasets. Would modifying the statement
>to "var(v, na.rm=TRUE)" be a possibility?

SAM() and sam() are different names in R, but neither of them is in
the base packages.  Which package did you find sam() in?  You probably
want to ask the author of the package if this modification would be
safe.

Duncan Murdoch

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From wolski at molgen.mpg.de  Thu Jan 29 14:56:42 2004
From: wolski at molgen.mpg.de (wolski)
Date: Thu, 29 Jan 2004 14:56:42 +0100
Subject: [R] setMethodReplace.. Help!
Message-ID: <200401291456420552.04CDEFD8@harry.molgen.mpg.de>

Hi!

Trying to reproduce some examples from "Programming with Data" page 341.
Can not reproduce it neither on R1.8.1. nor R1.9.0devel?


library(methods)
setClass("track",representation(x="numeric",y="numeric"))

setMethod("["
          ,"track"
          ,function(x,...,drop=T){
            track(x at x[...],y at y[...])
          }
          )

In method for function "[": Expanding the signature to
include omitted arguments in definition: i = "missing",
j = "missing"
Error in .MakeSignature(new("signature"), def, signature) :
        The names in signature for method (x, , ) don't match function's arguments (x, i, j, drop)

The same....
setReplaceMethod("[","track"
                 ,function(x,...,value)
                 {
                  x at y[...]=as(value,"numeric") 
                 }
                 )


Please Help.
Eryk.



From harry.khamis at wright.edu  Thu Jan 29 14:58:37 2004
From: harry.khamis at wright.edu (Harry Khamis)
Date: Thu, 29 Jan 2004 08:58:37 -0500
Subject: [R] Loglienar models
Message-ID: <4019118D.2000702@wright.edu>

Hello,

    I'm planning to start using R.  Before getting into it, I'd like to 
ask a couple of questions.  Does R carry out loglinear model analysis? 
 That is, will it provide the chi-squared goodness of fit test statistic 
for a given hierarchical loglinear model?  Maybe even do a model 
selection procedure (like Brown's two-step procedure, or 
forward/backward selection)?  Thanks for your help.  
---Harry Khamis

-- 
Harry Khamis
Statistical Consulting Center
Wright State University
Dayton, OH  45435
USA

Phone: (937) 775-2433
Fax:   (937) 775-2081

Homepage: www.math.wright.edu/People/Harry_Khamis/index.html



From v_bill_pikounis at merck.com  Thu Jan 29 15:24:52 2004
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Thu, 29 Jan 2004 09:24:52 -0500
Subject: [R]Running R remotely in Windows Environment?
Message-ID: <CFBD404F5E0C9547B4E10B7BDC3DFA2F04156035@usrymx18.merck.com>

Jim,
I would really like to reiterate Professor Ripley's and Arne Henningsen
comments. The problem goes for any analytic software or system you might
want to use, not just R. My impression is that at least for part of it, you
want the individual users to use R as they would on their own desktops.  (If
that is not the case, much of the rest of this note is pure FYI.) Even in
its most advanced 2003 Server edition, Windows is simply not designed to be
a multi-user system.  Sure, it can reliably host a web server that may need
to run quick bursts of R batch-type jobs ("analytics") and return results to
a client (e.g. web browser), but that does not sound like what you are
looking for (at least in part). And beyond the technical limitations, use of
Windows Terminal Server (Remote Desktop) / Citrix, etc. will cost much money
and implementation hassle and probably even legal headaches.  We have had
colleagues here at Merck (over my and Andy Liaw's disbelief) that have tried
to shoehorn Windows this way, and even the speed of single, small jobs by 1
logged-on took longer on the server than on their much less powerful
laptops. 

A Linux solution is very flexible, in our experiences (we have Windows XP as
corporate desktop standard).  As stated, with Samba, you can map directories
that look like just another drive in Windows Explorer.  Printing is just as
transparent in either direction.  VNC (Virtual Network Computing) is very,
very nice to provide the individual user's Linux environment as just another
window on their Windows desktop. With the free utility of "autocutsel",
clipboards can be synchronized for ease of cutting and pasting. And KDE, one
of several window manager analogues to Windows, is very sophisticated and
shares a lot in common with the Windows GUI from a user operations
standpoint. While it may sound like a hassle to get up and running now if
your shop is currently "99% Windows", the benefit will absolutely be clear
later.

Hope that helps,
Bill
----------------------------------------
Bill Pikounis, Ph.D.

Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY33-300  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

Phone: 732 594 3913
Fax: 732 594 1565


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Arne Henningsen
> Sent: Thursday, January 29, 2004 3:45 AM
> To: Jim Porzak
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R]Running R remotely in Windows Environment?
> 
> 
> Hi, 
> 
> I also suggest to use a Linux Server. You can work on this 
> machine via ssh 
> (e.g. with PuTTY) and transfer the input and output files 
> with scp or a samba 
> server (which is easy to install and very convenient to use 
> for windows 
> users).
> 
> Arne
> 
> On Thursday 29 January 2004 08:53, Prof Brian Ripley wrote:
> > On Wed, 28 Jan 2004, Jim Porzak wrote:
> > > We are considering setting up a fast, RAM loaded machine 
> as an "R-server"
> > > to handle the big problems not suitable for individual 
> desktops and,
> > > also, to process ad hoc analysis requests via our portal. 
> We are 99% a
> > > Windows shop, so first choice is a windows server. We'll 
> use (D)COM for
> > > the portal interface and understand that.
> > >
> > > What has me stumped is how to easily interface individual 
> analyst's
> > > Windows desktops to the R-server. I haven't seen anything in the
> > > archives, but I can't imagine this hasn't been done. What 
> am I missing?
> >
> > R is not designed to be client-server on Windows.  People I 
> know who do
> > this use Windows Terminal Server or Citrix.
> >
> > I would question the value of this approach.  Unless you 
> propose to run
> > 64-bit Windows, a `RAM loaded' machine isn't `loaded', and 
> R under Windows
> > handles large amounts of memory much less effectively than 
> under Linux.
> > 64-bit Windows is uncharted territory for R, whereas 64-bit 
> Unix/Linux is
> > well trodden.
> 
> -- 
> Arne Henningsen
> Department of Agricultural Economics
> University of Kiel
> Olshausenstr. 40
> D-24098 Kiel (Germany)
> Tel: +49-431-880 4445
> Fax: +49-431-880 1397
> ahenningsen at agric-econ.uni-kiel.de
> http://www.uni-kiel.de/agrarpol/ahenningsen/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From m.mader at gsf.de  Thu Jan 29 15:44:38 2004
From: m.mader at gsf.de (Michael Mader)
Date: Thu, 29 Jan 2004 15:44:38 +0100
Subject: [R] Doubt about pattern
References: <20040129113325.00004242@lbmsala4>
Message-ID: <40191C56.B778FD9E@gsf.de>

Marcelo Luiz de Laia wrote:
>[...] only the files that finish in ".sens.". I execute the command below,
> files <- dir(pattern="*.sens")

files <- list.files("./", "\.sens$")
> 

-- 
Michael T. Mader
Institute for Bioinformatics/MIPS, GSF
Ingolstaedter Landstrasse 1
D-85764 Neuherberg
0049-89-3187-3576

response time (n.) An unbounded, random variable Tr associated with a
given TIMESHARING system and representing the putative time which
elapses between Ts, the time of sending a message, and Te, the time when
the resulting error diagnostic is received.	
	S. Kelly-Bootle, The Devil's DP Dictionary



From dmurdoch at pair.com  Thu Jan 29 15:49:02 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 29 Jan 2004 09:49:02 -0500
Subject: [R] Doubt about pattern
In-Reply-To: <20040129113325.00004242@lbmsala4>
References: <20040129113325.00004242@lbmsala4>
Message-ID: <tt6i10lsl4s0gmmi5ugaplv7ivuangfqpg@4ax.com>

On Thu, 29 Jan 2004 11:33:25 -0300, Marcelo Luiz de Laia
<mlaia at fcav.unesp.br> wrote :

>Hi All,
>
>I have a very simple problem. I have several files in a same directory. I would like to send for an object only the files that finish in ".sens.". I execute the command below,
>
>files <- dir(pattern="*.sens")
>
>but it includes all of the files that have "sens", independent of they be in the end or in the middle of the name of the file. How could I solve this? I sought in the html_help but I didn't find similar to this.
>
>My files
>
>"script_sens.txt", "Sen_155_01_R1.sens", "Sen_155_01_R2.sens", "Sen_155_01_R3.sens", "Sen_155_02_R1.sens", "Sen_155_02_R2.sens", "Sen_155_02_R3.sens", "Sen_155_03_R1.sens", "Sen_155_03_R2.sens", "Sen_155_03_R3.sens", "tome2sens_time1sens.txt"


The pattern in dir() is a regular expression pattern, not a filename
wildcard.  You want dir(pattern="\\.sens$").  (The double backslash
comes because the regular expression you want contains a backslash
before the dot.)

If you're using Windows, the choose.files() interactive function is
probably more friendly.  There 

 choose.files('*.sens')
 
works the way you're expecting (except it's interactive).

Duncan Murdoch



From Roger.Bivand at nhh.no  Thu Jan 29 16:02:29 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 29 Jan 2004 16:02:29 +0100 (CET)
Subject: [R] Doubt about pattern
In-Reply-To: <20040129113325.00004242@lbmsala4>
Message-ID: <Pine.LNX.4.44.0401291555490.32748-100000@reclus.nhh.no>

On Thu, 29 Jan 2004, Marcelo Luiz de Laia wrote:

> Hi All,
> 
> I have a very simple problem. I have several files in a same directory.
> I would like to send for an object only the files that finish in
> ".sens.". I execute the command below,
> 
> files <- dir(pattern="*.sens")

see help(regexp) - "period '.' matches any single character" - I think you 
need to escape the '.' possibly as "\\.sens$".


> 
> but it includes all of the files that have "sens", independent of they
> be in the end or in the middle of the name of the file. How could I
> solve this? I sought in the html_help but I didn't find similar to this.
> 
> My files
> 
> "script_sens.txt", "Sen_155_01_R1.sens", "Sen_155_01_R2.sens",
> "Sen_155_01_R3.sens", "Sen_155_02_R1.sens", "Sen_155_02_R2.sens",
> "Sen_155_02_R3.sens", "Sen_155_03_R1.sens", "Sen_155_03_R2.sens",
> "Sen_155_03_R3.sens", "tome2sens_time1sens.txt"
> 
> Tahnks very much
> 
> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From hb at maths.lth.se  Thu Jan 29 16:19:39 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 29 Jan 2004 16:19:39 +0100
Subject: [R] Doubt about pattern
In-Reply-To: <20040129113325.00004242@lbmsala4>
Message-ID: <000301c3e67b$5067c650$e502eb82@maths.lth.se>

Hi. 

1. A period in a pattern (as you wrote) means that you want to match
*any* character. You need to escape the period, i.e. "\\.", or
alternatively use the "[<set>]" indicator where <set> is all the
characters you allow at that position, i.e. "[.]". (I prefer the
latter because in is more readable and you don't have the \\ or \
problem when cut'n'pasting.)

2. To match the end of string use "$".

Thus, you want to do

 files <- dir(pattern="*[.]sens$")

To match filenames that ends with ".sens". 

This is how regexpr(), gsub() and friends all work.

Cheers

Henrik Bengtsson

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Marcelo Luiz de Laia
> Sent: den 29 januari 2004 15:33
> To: r-help at stat.math.ethz.ch
> Subject: [R] Doubt about pattern
> 
> 
> Hi All,
> 
> I have a very simple problem. I have several files in a same 
> directory. I would like to send for an object only the files 
> that finish in ".sens.". I execute the command below,
> 
> files <- dir(pattern="*.sens")
> 
> but it includes all of the files that have "sens", 
> independent of they be in the end or in the middle of the 
> name of the file. How could I solve this? I sought in the 
> html_help but I didn't find similar to this.
> 
> My files
> 
> "script_sens.txt", "Sen_155_01_R1.sens", 
> "Sen_155_01_R2.sens", "Sen_155_01_R3.sens", 
> "Sen_155_02_R1.sens", "Sen_155_02_R2.sens", 
> "Sen_155_02_R3.sens", "Sen_155_03_R1.sens", 
> "Sen_155_03_R2.sens", "Sen_155_03_R3.sens",
"tome2sens_time1sens.txt"
> 
> Tahnks very much
> 
> -- 
> Marcelo Luiz de Laia, M.Sc.
> Dep. de Tecnologia, Lab. Bioqu?mica e de Biologia Molecular 
> Universidade Estadual Paulista - UNESP Via de Acesso Prof. 
> Paulo Donato Castelane, Km 05 14.884-900 - Jaboticabal, SP, Brazil
> PhoneFax: 16 3209-2675/2676/2677 R. 202/208/203 (trab.)
> HomePhone: 16 3203 2328 - www.lbm.fcav.unesp.br - mlaia at yahoo.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From P.Lemmens at nici.kun.nl  Thu Jan 29 16:19:56 2004
From: P.Lemmens at nici.kun.nl (Paul Lemmens)
Date: Thu, 29 Jan 2004 16:19:56 +0100
Subject: [R] Doubt about pattern
In-Reply-To: <20040129113325.00004242@lbmsala4>
References: <20040129113325.00004242@lbmsala4>
Message-ID: <30211312.1075393196@lemmens.socsci.kun.nl>

Hoi Marcelo,

--On donderdag 29 januari 2004 11:33 -0300 Marcelo Luiz de Laia 
<mlaia at fcav.unesp.br> wrote:
>
> files <- dir(pattern="*.sens")
>
> but it includes all of the files that have "sens", independent of they be
> in the end or in the middle of the name of the file.
>
That's because your pattern is a regular expression and not a Windows/DOS 
wildcard. You'll need something like

files <- dir(pattern="\.sens$")

\. matches the dot itself (without the slash it's a wildcard for any 
character) and the dollar sign $ matches the end of the filename. So this 
way you'll get every file that has 'sens' as its extension


regards,
Paul




-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.03)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066



From feh3k at spamcop.net  Thu Jan 29 05:00:41 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Wed, 28 Jan 2004 23:00:41 -0500
Subject: [R] Calculating/understanding variance-covariance matrix of
	logistic regression (lrm $var)
In-Reply-To: <20040129013427.34751.qmail@web10003.mail.yahoo.com>
References: <20040129013427.34751.qmail@web10003.mail.yahoo.com>
Message-ID: <20040128230041.0d6f8cac.feh3k@spamcop.net>

On Thu, 29 Jan 2004 02:34:27 +0100 (CET)
Karl Knoblick <karlknoblich at yahoo.de> wrote:

> Hallo!
> 
> I want to understand / recalculate what is done to get
> the CI of the logistic regression evaluated with lrm.
> As far as I came back, my problem is the
> variance-covariance matrix fit$var of the fit
> (fit<-lrm(...), fit$var). Here what I found and where
> I stucked:
> 
> -----------------
> library(Design)
> # data
> D<-c(rep("a", 20), rep("b", 20))
> V<-0.25*(1:40)
> V[1]<-25
> V[40]<-15
> data<-data.frame(D, V)
> d<-datadist(data)
> options(datadist="d")
> 
> # Fit
> fit<-lrm(D ~ V, data=data, x=TRUE, se.fit=TRUE)
> plot(fit, conf.int=0.95) # same as plot(fit)
> 
> # calculation of upper and lower CI (pred$lower,
> pred$upper)
> pred<-predict(fit, data.frame(V=V), conf.int=0.95,
> se.fit=TRUE)
> points(V, pred$upper, col=2, pch=3) # to check
> 
> # looking in function predict, the CI are calculated
> with the se
> # using fit$var:
> X<-cbind(rep(1, length(fit$x)), fit$x) # fit$x are the
> V
> cov<-fit$var # <- THIS I DO NOT UNDERSTAND (***) s.
> below
> se <- drop(sqrt(((X %*% cov) * X) %*% rep(1,
> ncol(X))))
> 
> # check if it is the same
> min(se - pred$se.fit) # result: 0
> max(se - pred$se.fit) # result: 0
> 
> # looking at the problem:
> cov
> -----------------
> Result:
>            Intercept           V
> Intercept  0.7759040 -0.12038969
> V         -0.1203897  0.02274177
> 
> 
> (***)
> fit$var is the estimated variance-covariance matrix.
> How is it calculated? (Meaning of intercept and x?)
> 
> Does anybody know how calculationg this "by hand" or
> can give me a reference (preferable in the internet)?
> 
> Thanks!
> Karl.

Karl:

I'm not clear why you quoted the other code as your entire question is
about the basic quantity fit$var.  fit$var is the inverse of the observed
information matrix at the final regression coefficient estimates.  This is
a very standard approach and is detailed in most books on logistic
regression or glms.  It is related to the Newton-Raphson iterative
algorithm for maximizing the likelihood.  The information matrix is like
the sums of squares and cross-product matrix in ordinary regression except
for a weigh of the form P*(1-P) where P is a row's estimated probability
of even from the final iteration.

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From jfox at mcmaster.ca  Thu Jan 29 16:25:14 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 29 Jan 2004 10:25:14 -0500
Subject: [R] Loglienar models
In-Reply-To: <4019118D.2000702@wright.edu>
Message-ID: <5.1.0.14.2.20040129102106.0204bd08@127.0.0.1>

Dear Harry,

There are two ways to fit loglinear models of which I'm aware and probably 
more that I don't know: The loglin() function fits loglinear models by IPF; 
there's a convenient front end, loglm(), in the MASS package (one of the 
recommended packages). As well, you can fit loglinear models as Poisson 
generalised linear models using the glm() function. At least in the latter 
case, you can do model selection via step().

I hope that this helps,
  John

At 08:58 AM 1/29/2004 -0500, Harry Khamis wrote:
>Hello,
>
>    I'm planning to start using R.  Before getting into it, I'd like to 
> ask a couple of questions.  Does R carry out loglinear model analysis? 
> That is, will it provide the chi-squared goodness of fit test statistic 
> for a given hierarchical loglinear model?  Maybe even do a model 
> selection procedure (like Brown's two-step procedure, or forward/backward 
> selection)?  Thanks for your help.
>---Harry Khamis
>
>--

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From partha_bagchi at hgsi.com  Thu Jan 29 16:07:52 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Thu, 29 Jan 2004 10:07:52 -0500
Subject: [R] Doubt about pattern
Message-ID: <OF23EC795E.5B470799-ON85256E2A.0053114A-85256E2A.00531E65@hgsi.com>

Terminate the sens with a $ as in dir(pattern = "*.sens$")





Marcelo Luiz de Laia <mlaia at fcav.unesp.br>
Sent by: r-help-bounces at stat.math.ethz.ch
01/29/2004 11:33 AM

 
        To:     r-help at stat.math.ethz.ch
        cc: 
        Subject:        [R] Doubt about pattern


Hi All,

I have a very simple problem. I have several files in a same directory. I 
would like to send for an object only the files that finish in ".sens.". I 
execute the command below,

files <- dir(pattern="*.sens")

but it includes all of the files that have "sens", independent of they be 
in the end or in the middle of the name of the file. How could I solve 
this? I sought in the html_help but I didn't find similar to this.

My files

"script_sens.txt", "Sen_155_01_R1.sens", "Sen_155_01_R2.sens", 
"Sen_155_01_R3.sens", "Sen_155_02_R1.sens", "Sen_155_02_R2.sens", 
"Sen_155_02_R3.sens", "Sen_155_03_R1.sens", "Sen_155_03_R2.sens", 
"Sen_155_03_R3.sens", "tome2sens_time1sens.txt"

Tahnks very much

--
Marcelo Luiz de Laia, M.Sc.
Dep. de Tecnologia, Lab. Bioqu?mica e de Biologia Molecular
Universidade Estadual Paulista - UNESP
Via de Acesso Prof. Paulo Donato Castelane, Km 05
14.884-900 - Jaboticabal, SP, Brazil
PhoneFax: 16 3209-2675/2676/2677 R. 202/208/203 (trab.)
HomePhone: 16 3203 2328 - www.lbm.fcav.unesp.br - mlaia at yahoo.com

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

--
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From macq at llnl.gov  Thu Jan 29 16:53:31 2004
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 29 Jan 2004 07:53:31 -0800
Subject: [R] How to generate a report with graphics and tables?
In-Reply-To: <40182311.2010800@ginko.de>
References: <40182311.2010800@ginko.de>
Message-ID: <p06002001bc3edbd6cb44@[128.115.153.6]>

Depending on how much post-processing you do in 
Powerpoint, you might try importing the chart 
using a "link".

Have R save the chart in a file. Then go into 
Powerpoint, use the Insert Picture from File menu 
item, and in the dialog box that comes up select 
"Link to File".

-Don

At 10:01 PM +0100 1/28/04, Olaf B?rger wrote:
>Hello R-Users,
>
>I have some data sets which change on a daily 
>bases. So far I have imported  these sets into 
>R, done all my evaluations resulting in a couple 
>of plots, charts and tables of numbers which I 
>copy&pasted via clipboard into Powerpoint.
>The procedure is always the same and I wonder, 
>whether there is no easier way for doing so. Is 
>there some type of "report generator" available 
>or some HowTo on this.
>
>Can anybody give me a hint on where to look for?
>
>Regards,
>
>Olaf B?rger
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From s-news-owner at lists.biostat.wustl.edu  Thu Jan 29 16:55:05 2004
From: s-news-owner at lists.biostat.wustl.edu (s-news-owner@lists.biostat.wustl.edu)
Date: Thu, 29 Jan 2004 09:55:05 -0600
Subject: [R] Denied post to s-news
Message-ID: <20040129155505.4E914404445@smtp.biostat.wustl.edu>

Your message to the s-news list has been denied
for the following reason(s):

The address from which you posted is not subscribed to the s-news list.
Duplicate Message Checksum (Mon Jan 26 14:49:54 2004)
Duplicate Partial Message Checksum (Mon Jan 26 14:49:54 2004)

-------------- next part --------------
An embedded message was scrubbed...
From: r-help at lists.r-project.org
Subject: *****SPAM***** Hi
Date: Thu, 29 Jan 2004 10:52:05 -0500
Size: 2618
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040129/05f28528/attachment.mht

From wolfgangpauli at web.de  Thu Jan 29 16:59:40 2004
From: wolfgangpauli at web.de (Wolfgang Pauli)
Date: Thu, 29 Jan 2004 16:59:40 +0100
Subject: [R] newbie question on contrasts and aov
In-Reply-To: <Pine.LNX.4.44.0401111656250.18224-100000@gannet.stats>
References: <Pine.LNX.4.44.0401111656250.18224-100000@gannet.stats>
Message-ID: <200401291659.40721.wolfgangpauli@web.de>

In the meantime I figured out that the Difference-contrast is not quite what I 
was looking for. But I still have two questions

1) Why do I get different results for Helmert contrasts in SPSS and R. I guess 
the contrast matrixes of Helmert are about the same in SPSS and R. I probably 
make a mistake as i am a newbie to R. I thought that it might be, because I 
have a repaeted measures design. That's why I put the Error(sub) in the 
formula of aov. 

2)
I tried to make my own contrast matrix, to compute comparisons between 
adjacent factor levels, i.e. 1-2, 2-3 and 3-4. My matrix looks like this:
     [,1] [,2] [,3]
[1,]    1    0    0
[2,]   -1    1    0
[3,]    0   -1    1
[4,]    0    0   -1

But then I get the same result as with contr.helmert(4). What is wrong I 
really don't get it!

Thank you,

Wolfgang Pauli

On Sunday January 11 2004 18:07, you wrote:
> Notice  `SPKType III Sum of Squares'.  I don't believe your contrasts are
> orthogonal, and R's are sequential sum of squares.
>
> Also, are you sure these are the same contrasts?  I presume this is
> contr.sdif from MASS (in which case it is churlish not to credit it), and
> SPSS's contrasts look more like Helmert contrasts from their labelling.
>
> Since it appears all your treatments are within subjects you do seem to be
> making life difficult for yourself. Although I would have done a simple
> fixed-effects analysis, applying summary.lm to the bottom stratum would
> give you simple t-tests for each contrast, including actual estimates of
> the magnitudes.
>
> On Sun, 11 Jan 2004, Wolfgang Pauli wrote:
> > I try to move from SPSS to R/S and am trying to reproduce the results of
> > SPSS in R. I calculated a one-way anova with "spk" as experimental factor
> > and erp as depended variable.
> > The result of the Anova are the same concearning the mean square, F and p
> > values. But I also wanted to caculate the contr.sdif(4) contrast on spk.
> > The results are completely different now. I hope anybody can help me.
> >
> > Thanks, Wolfgang
> >
> > This is what I get in SPSS:
> > Tests of Within-Subjects Contrasts
> > Measure: MEASURE_1
> > Source		SPKType III Sum of Squares	df	Mean Square	F	Sig.
> > SPK		Level 2 vs. Level 1	3,493	1	3,493	2,026	,178
> > 			Level 3 vs. Previous	20,358	1	20,358	10,168	,007
> > 			Level 4 vs. Previous	18,808	1	18,808	15,368	,002
> > Error(SPK)	Level 2 vs. Level 1	22,414	13	1,724
> > 			Level 3 vs. Previous	26,030	13	2,002
> > 			Level 4 vs. Previous	15,911	13	1,224
> >
> > This is the result in R:
> > Error: sub
> >           Df Sum Sq Mean Sq F value Pr(>F)
> > Residuals 13 205.79   15.83
> >
> > Error: Within
> >           Df Sum Sq Mean Sq F value    Pr(>F)
> > spk        3 29.425   9.808  9.4467 8.055e-05 ***
> > spk: p   1  1.747   1.747  1.6821 0.2022649
> > spk: q   1 13.572  13.572 13.0719 0.0008479 ***
> > spk: r   1 14.106  14.106 13.5861 0.0006915 ***
> > Residuals 39 40.493   1.038
> > ---
> > Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> >
> >
> >
> > Spk.df <- data.frame(sub,spk,erp)
> > subset(Spk.df, subset=(sub!="14oddball" & sub!="18odd" & sub!="19odd" &
> > sub!="20oddball")) -> Spk.selected.df
> > contrasts(Spk.selected.df$spk) <- contr.sdif(4)
> > aov(erp ~ spk + Error(sub), data=Spk.selected.df) -> Spk.aov
> > summary(Spk.aov,data=Spk.selected.df,split=list(spk=list(p=1,q=2,r=3)))
> >
> > this is the the beginning of the dataframe, which I use:
> >          sub  spk    erp
> > 1  10oddball spk1  2.587
> > 2  11oddball spk1 -0.335
> > 3  12oddball spk1  5.564
> > 5  15oddball spk1  0.691
> > 6  17oddball spk1 -1.846
> > 10 21oddball spk1  1.825
> > 11 22oddball spk1  0.370
> > 12  2oddball spk1  3.234
> > 13  3oddball spk1  1.462
> > 14  5oddball spk1  2.535
> > 15  6oddball spk1  9.373
> > 16  7oddball spk1  2.132
> > 17  8oddball spk1 -0.518
> > 18  9oddball spk1  2.450
> > 19 10oddball spk2  2.909
> > 20 11oddball spk2  0.708
> > 21 12oddball spk2  4.684
> > 23 15oddball spk2  3.599
> > ...
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html



From Maarten.van.der.Hoeven at knmi.nl  Thu Jan 29 17:00:05 2004
From: Maarten.van.der.Hoeven at knmi.nl (Hoeven, Maarten van der)
Date: Thu, 29 Jan 2004 17:00:05 +0100
Subject: [R] RMySQL for R1.8.1 on Windows
Message-ID: <1F8990C21AC73945BE6AAC5AD6D4CAE9064036@BCSXAC.knmi.nl>

Hi all,

I'm looking for a way to install the RMySQL-package into my
Windows-version of R (1.8.1). 

I did successfully install this package into my Linux-version of R
(RedHat9), but now I want to do this in my Windows-version too.

How to?

Regards,
Maarten
--------------------------------------------------------------
Zie ook/see also: http://www.knmi.nl/maildisclaimer.html



From ripley at stats.ox.ac.uk  Thu Jan 29 17:04:16 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Jan 2004 16:04:16 +0000 (GMT)
Subject: [R] Loglienar models
In-Reply-To: <4019118D.2000702@wright.edu>
Message-ID: <Pine.LNX.4.44.0401291558260.28747-100000@gannet.stats>

On Thu, 29 Jan 2004, Harry Khamis wrote:

>     I'm planning to start using R.  Before getting into it, I'd like to 
> ask a couple of questions.  Does R carry out loglinear model analysis? 

Yes.  (It has several functions to do so, including glm, loglin, 
loglm and multinom).  Putting `loglinear' into the help search found 
all of those.

>  That is, will it provide the chi-squared goodness of fit test statistic 
> for a given hierarchical loglinear model?  

Yes (although there are two, sometimes known as G^2 and X^2, so you will 
need to be careful).

> Maybe even do a model selection procedure (like Brown's two-step
> procedure, or forward/backward selection)?

Yes.

R is currently been used here on a course on log-linear models for social 
scientists, at their suggestion.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mpalmier at mines.edu  Thu Jan 29 17:19:23 2004
From: mpalmier at mines.edu (mpalmier@mines.edu)
Date: Thu, 29 Jan 2004 09:19:23 -0700
Subject: [R] please help me!
Message-ID: <1075393163.4019328b670a7@webmail.mines.edu>

hello there, 
   I'm a new user to R and I am having difficulty reading a file into the 
program.  Here's the error I keep getting, I bet there's a simple solution, 
but I cant find any...

Error in file(file, "r") : unable to open connection
In addition: Warning message: 
cannot open file `c:MikeWeather2.txt' 

I have made sure that my working directory is the same as the place where the 
file is.  I have also tried using the full path name of the file.  read.table, 
read.delim, read.csv, and scan have all been attempted with no result.  What 
causes this message, and how can I fix it.  Thanks in advance for your help,

Mike



From Whit.Armstrong at tudor.com  Thu Jan 29 17:39:53 2004
From: Whit.Armstrong at tudor.com (Whit Armstrong)
Date: Thu, 29 Jan 2004 11:39:53 -0500
Subject: [R] Repeated regressions
Message-ID: <CD9BF92D5B1AD611ABEB00065B386FB0031F7330@tudor.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040129/2338a519/attachment.pl

From sfalcon at fhcrc.org  Thu Jan 29 18:25:10 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 29 Jan 2004 09:25:10 -0800
Subject: [R] build fails to build help for nlme
Message-ID: <20040129172510.GE13695@queenbee.fhcrc.org>

Hi all,

I'm trying to build R-1.8.1 from source on Linux and getting the
following error when the makefile gets to the step of building the help
for 'nlme':

<snip>
ranef.lme                         text    html    latex   example
reStruct                          text    html    latex   example
/home/sfalcon/sw/R-related/R-1.8.1/bin/INSTALL: line 1:  8133 Segmentation fault      ${R_CMD} perl "${R_HOME}/share/perl/build-help.pl" ${build_help_opts} "${pkg_dir}" "${lib}" "${R_PACKAGE_DIR}" "${pkg_name}"
ERROR: building help failed for package 'nlme'
** Removing '/home/sfalcon/sw/R-related/R-1.8.1/library/nlme'
make[2]: *** [nlme.ts] Error 1
make[2]: Leaving directory
`/home/sfalcon/sw/R-related/R-1.8.1/src/library/Recommended'
make[1]: *** [recommended-packages] Error 2
make[1]: Leaving directory
`/home/sfalcon/sw/R-related/R-1.8.1/src/library/Recommended'
make: *** [stamp-recommended] Error 2
</snip>

Has anyone else encountered this?

I've had no difficulties compiling previous versions of R on this
machine.


Thanks,

+ seth



From gimli at email.it  Thu Jan 29 20:07:05 2004
From: gimli at email.it (Alberto Fornasier)
Date: Thu, 29 Jan 2004 19:07:05 +0000
Subject: [R] Variable substitution in grep pattern
Message-ID: <20040129190705.4993a720.gimli@email.it>

Hi everibody.
I'm working with a dataframe with many character vector in which each
observation is made of one or more unique values.
Example:

> Licenza[56:58]
[1] BSD License, GNU Library or Lesser General Public License (LGPL)
[2] Qt Public License (QPL)
[3] GNU General Public License (GPL)
66 Levels:  ... Zope Public License

As you can see, the observation can have one or more Licenses associated
with them.
I want to build a vector with the number of times every element (e.g.
"BSD License") occurs in the vector, by itself or in association with
others (i.e. I want to count the elements containing "BSD License" as
well as those containing "BSD License, GNU Library or Lesser General
Public License (LGPL)", and so on).

I've tried to use a "for" loop as follows:

> for(i in Licenza.elenco) {
+ Licenza.elenco.prova[Licenza.elenco==i] <-
  length(grep(".*i.*",as.character(Licenza)))}

In which Licenza.elenco is a character vector containing all unique
values I need to match (e.g. BSD License, Qt Public License (QPL), GNU
General Public License (GPL)).
However R handles as I expect only the first variable substitution (the
index), but grep matches all strings containing the letter "i", that is
100% of the vector, except NAs of course.
After running the above code I get:

> Licenza.elenco.prova
[1] 2235 2235 2235

I've tried escaping the variable name, enclosing it in brackets, but
nothing works as I want.
I'm sure I'm doing something wrong, but what?

Thaks in advance

Alberto Fornasier



From sue at xlsolutions-corp.com  Thu Jan 29 19:13:38 2004
From: sue at xlsolutions-corp.com (sue@xlsolutions-corp.com)
Date: Thu, 29 Jan 2004 11:13:38 -0700
Subject: [R] Course***R/Splus Fundamentals and Programming Techniques,
	February-March 2004 @ 5 locations near you! (Raleigh, New York,
	Washington DC, Boston, San Francisco)
Message-ID: <20040129181338.26321.qmail@webmail4.mesa1.secureserver.net>


   XLSolutions Corporation ([1]www.xlsolutions-corp.com) is proud
   to announce February-March 2004 2-day "R/S-plus Fundamentals and
   Programming
   Techniques".
   ****Boston, MA ---------------------> February, 19-20
   ****New York, NY -------------------> February, 19,20
   ****San Francisco, CA --------------> February, 26-27
   ****Raleigh, NC --------------------> February, 26,27

   ****Washington, DC -----------------> March, 4-5
   Reserve your seat now at the early bird rates! Payment due AFTER the
   class.

   Course Description:
   This two-day beginner to intermediate R/S-plus course focuses
    on a broad spectrum of topics,
   from reading raw data to a comparison of R and S. We will learn
   the essentials of data manipulation, graphical visualization
   and R/S-plus programming. We will explore statistical data analysis
   tools,including graphics with data sets. How to enhance your plots.
   We will perform basic statistics and fit linear regression models.
   Participants are encouraged to bring data for interactive sessions

   With the following outline:
   - An Overview of R
   - Data Manipulation and Graphics
   - Using Lattice Graphics
   - A Comparison of R and S-Plus
   - How can R Complement SAS?
   - Writing Functions
   - Avoiding Loops
   - Vectorization
   - Statistical Modeling
   - Project Management
   - Techniques for Effective use of R and S
   - Enhancing Plots
   - Using High-level Plotting Functions
   - Building and Distributing Packages (libraries)

   Early Bird Research: $995 (Includes course materials and snacks);
   Email us for group discounts.
   Email Sue Turner: [2]sue at xlsolutions-corp.com
   Phone: 206-686-1578
   Visit us: [3]www.xlsolutions-corp.com/training.htm
   Please let us know if you and your colleagues are interested in this
   classto take advantage of group discount. Register now to secure your
   seat!
   Interested in R/Splus Advanced course? email us.

   Cheers,
   Elvis Miller, PhD
   Manager Training.
   XLSolutions Corporation
   206 686 1578
   [4]www.xlsolutions-corp.com
   [5]elvis at xlsolutions-corp.com

References

   1. http://www.xlsolutions-corp.com/
   2. mailto:sue at xlsolutions-corp.com
   3. http://www.xlsolutions- corp.com/training.htm
   4. http://www.xlsolutions-corp.com/
   5. mailto:elvis at xlsolutions-corp.com


From ripley at stats.ox.ac.uk  Thu Jan 29 20:07:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Jan 2004 19:07:01 +0000 (GMT)
Subject: [R] RMySQL for R1.8.1 on Windows
In-Reply-To: <1F8990C21AC73945BE6AAC5AD6D4CAE9064036@BCSXAC.knmi.nl>
Message-ID: <Pine.LNX.4.44.0401291859320.32255-100000@gannet.stats>

Where is the problem?  It installs from the sources under Windows too, and 
even comes with notes for Windows.

Please consult the rw-FAQ for how to install packages.

We have provided binary builds in the past (and David James may still do 
so), but discovered that there was little tolerance for version 
mismatches, of both R and MySQL.  So building from the sources is better,

On Thu, 29 Jan 2004, Hoeven, Maarten van der wrote:

> I'm looking for a way to install the RMySQL-package into my
> Windows-version of R (1.8.1). 
> 
> I did successfully install this package into my Linux-version of R
> (RedHat9), but now I want to do this in my Windows-version too.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sfalcon at fhcrc.org  Thu Jan 29 20:23:19 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 29 Jan 2004 11:23:19 -0800
Subject: [R] please help me!
In-Reply-To: <1075393163.4019328b670a7@webmail.mines.edu>
References: <1075393163.4019328b670a7@webmail.mines.edu>
Message-ID: <20040129192318.GG13695@queenbee.fhcrc.org>

If your working directory contains a file you want to read then the
following should work:

  dat <- read.table("filename.txt")

If you want to use absolute paths, you have to be careful with the '\'
because that is an escape character... so try:

  dat <- read.table("c:/some/path/notice/forward/slashes/data.txt")
  # or
  dat <- read.table("c:\\double\\back\\should\\work\\data.txt")


On Thu, Jan 29, 2004 at 09:19:23AM -0700, mpalmier at mines.edu wrote:
> hello there, 
>    I'm a new user to R and I am having difficulty reading a file into the 
> program.  Here's the error I keep getting, I bet there's a simple solution, 
> but I cant find any...
> 
> Error in file(file, "r") : unable to open connection
> In addition: Warning message: 
> cannot open file `c:MikeWeather2.txt' 
> 
> I have made sure that my working directory is the same as the place where the 
> file is.  I have also tried using the full path name of the file.  read.table, 
> read.delim, read.csv, and scan have all been attempted with no result.  What 
> causes this message, and how can I fix it.  Thanks in advance for your help,
> 
> Mike
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jmc at lucent.com  Thu Jan 29 20:27:31 2004
From: jmc at lucent.com (John Chambers)
Date: Thu, 29 Jan 2004 14:27:31 -0500
Subject: [R] setMethodReplace.. Help!
References: <200401291456420552.04CDEFD8@harry.molgen.mpg.de>
Message-ID: <40195EA3.1030101@lucent.com>

The error message says it:  in R, the arguments for the generic function 
"[" include i and j; the method definition must include those as well. 
Do getGeneric("[") or ?"[" to see the arguments.

As has been said on the R mailing lists in the past, R is generally 
compatible with the published books, but not when there is a better 
approach.  Having the extra arguments allows methods to be based on the 
class of the row or column indices.


wolski wrote:

> Hi!
> 
> Trying to reproduce some examples from "Programming with Data" page 341.
> Can not reproduce it neither on R1.8.1. nor R1.9.0devel?
> 
> 
> library(methods)
> setClass("track",representation(x="numeric",y="numeric"))
> 
> setMethod("["
>           ,"track"
>           ,function(x,...,drop=T){
>             track(x at x[...],y at y[...])
>           }
>           )
> 
> In method for function "[": Expanding the signature to
> include omitted arguments in definition: i = "missing",
> j = "missing"
> Error in .MakeSignature(new("signature"), def, signature) :
>         The names in signature for method (x, , ) don't match function's arguments (x, i, j, drop)
> 
> The same....
> setReplaceMethod("[","track"
>                  ,function(x,...,value)
>                  {
>                   x at y[...]=as(value,"numeric") 
>                  }
>                  )
> 
> 
> Please Help.
> Eryk.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 


-- 
John M. Chambers                  jmc at bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc



From jgentry at jimmy.harvard.edu  Thu Jan 29 20:37:39 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu, 29 Jan 2004 14:37:39 -0500 (EST)
Subject: [R] please help me!
In-Reply-To: <1075393163.4019328b670a7@webmail.mines.edu>
Message-ID: <Pine.SOL.4.20.0401291435580.2032-100000@santiam.dfci.harvard.edu>

>    I'm a new user to R and I am having difficulty reading a file into the 
> program.  Here's the error I keep getting, I bet there's a simple solution, 
> but I cant find any...
> Error in file(file, "r") : unable to open connection
> In addition: Warning message: 
> cannot open file `c:MikeWeather2.txt' 

I am guessing that you didn't escape the backslash in the filename
'c:\MikeWeather2.txt', so you would have to refer to it as
'c:\\MikeWeather2.txt' in R.  But, since you didn't show what you did to
spawn the error, I could be wrong



From ripley at stats.ox.ac.uk  Thu Jan 29 20:40:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Jan 2004 19:40:38 +0000 (GMT)
Subject: [R] please help me!
In-Reply-To: <1075393163.4019328b670a7@webmail.mines.edu>
Message-ID: <Pine.LNX.4.44.0401291934550.32406-100000@gannet.stats>

See the rw-FAQ Q2.14 R can't find my file, but I know it is there!

I'd be interested to know why you didn't find that -- the posting guide 
does ask you to read the rw-FAQ, so I presume there is connection that is 
not obvious to you.


On Thu, 29 Jan 2004 mpalmier at mines.edu wrote:

> hello there, 
>    I'm a new user to R and I am having difficulty reading a file into the 
> program.  Here's the error I keep getting, I bet there's a simple solution, 
> but I cant find any...
> 
> Error in file(file, "r") : unable to open connection
> In addition: Warning message: 
> cannot open file `c:MikeWeather2.txt' 

I guess a \ is missing there, as addressed in Q2.14.

> I have made sure that my working directory is the same as the place
> where the file is.

In that case you don't need c:, do you?

> I have also tried using the full path name of the file.  read.table,
> read.delim, read.csv, and scan have all been attempted with no result.  
> What causes this message, and how can I fix it.  Thanks in advance for
> your help,

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Thu Jan 29 20:47:34 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 29 Jan 2004 14:47:34 -0500
Subject: [R] please help me!
In-Reply-To: <1075393163.4019328b670a7@webmail.mines.edu>
References: <1075393163.4019328b670a7@webmail.mines.edu>
Message-ID: <snoi10dolelvh6lejrlpt6035mngjrjg0b@4ax.com>

On Thu, 29 Jan 2004 09:19:23 -0700, mpalmier at mines.edu wrote :

>hello there, 
>   I'm a new user to R and I am having difficulty reading a file into the 
>program.  Here's the error I keep getting, I bet there's a simple solution, 
>but I cant find any...
>
>Error in file(file, "r") : unable to open connection
>In addition: Warning message: 
>cannot open file `c:MikeWeather2.txt' 
>
>I have made sure that my working directory is the same as the place where the 
>file is.  I have also tried using the full path name of the file.  read.table, 
>read.delim, read.csv, and scan have all been attempted with no result.  What 
>causes this message, and how can I fix it.  Thanks in advance for your help,
>
>Mike
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

You don't give enough detail to diagnose the problem.  What command
did you use?  How did you make sure your working directory was right?
What version of R and what operating system are you using?

Please read the posting guide mentioned at the bottom of your message.

Duncan Murdoch



From k.wang at auckland.ac.nz  Thu Jan 29 20:58:56 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 30 Jan 2004 08:58:56 +1300
Subject: [R] please help me!
In-Reply-To: <1075393163.4019328b670a7@webmail.mines.edu>
Message-ID: <000001c3e6a2$542028b0$6633d882@stat.auckland.ac.nz>


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> mpalmier at mines.edu
> Sent: Friday, January 30, 2004 5:19 AM
> To: R-help at lists.R-project.org
> Subject: [R] please help me!
> 
> 
> hello there, 
>    I'm a new user to R and I am having difficulty reading a 
> file into the 
> program.  Here's the error I keep getting, I bet there's a 
> simple solution, 
> but I cant find any...
> 
> Error in file(file, "r") : unable to open connection
> In addition: Warning message: 
> cannot open file `c:MikeWeather2.txt' 
> 

How did you get this error message?  It would help if you put your codes
here.

But I'm guessing it is because you typed something like:
  foo = read.table("C:\MikeWeather2.txt")

Try to use "C:/MikeWeather2.txt" or "C:\\MikeWeather2.txt".

HTH.

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
Statistics Workshops Co-ordinator
Student Learning Centre
University of Auckland
New Zealand



From ripley at stats.ox.ac.uk  Thu Jan 29 21:18:41 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Jan 2004 20:18:41 +0000 (GMT)
Subject: [R] build fails to build help for nlme
In-Reply-To: <20040129172510.GE13695@queenbee.fhcrc.org>
Message-ID: <Pine.LNX.4.44.0401292018250.32496-100000@gannet.stats>

I have once seen this when a disc became full.

On Thu, 29 Jan 2004, Seth Falcon wrote:

> Hi all,
> 
> I'm trying to build R-1.8.1 from source on Linux and getting the
> following error when the makefile gets to the step of building the help
> for 'nlme':
> 
> <snip>
> ranef.lme                         text    html    latex   example
> reStruct                          text    html    latex   example
> /home/sfalcon/sw/R-related/R-1.8.1/bin/INSTALL: line 1:  8133 Segmentation fault      ${R_CMD} perl "${R_HOME}/share/perl/build-help.pl" ${build_help_opts} "${pkg_dir}" "${lib}" "${R_PACKAGE_DIR}" "${pkg_name}"
> ERROR: building help failed for package 'nlme'
> ** Removing '/home/sfalcon/sw/R-related/R-1.8.1/library/nlme'
> make[2]: *** [nlme.ts] Error 1
> make[2]: Leaving directory
> `/home/sfalcon/sw/R-related/R-1.8.1/src/library/Recommended'
> make[1]: *** [recommended-packages] Error 2
> make[1]: Leaving directory
> `/home/sfalcon/sw/R-related/R-1.8.1/src/library/Recommended'
> make: *** [stamp-recommended] Error 2
> </snip>
> 
> Has anyone else encountered this?
> 
> I've had no difficulties compiling previous versions of R on this
> machine.
> 
> 
> Thanks,
> 
> + seth
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Thu Jan 29 21:20:26 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 29 Jan 2004 14:20:26 -0600
Subject: file names under Windows [was: [R] please help me!]
In-Reply-To: <1075393163.4019328b670a7@webmail.mines.edu>
References: <1075393163.4019328b670a7@webmail.mines.edu>
Message-ID: <6r1xpi7bhx.fsf@bates4.stat.wisc.edu>

If I may make a suggestion, it helps if you use informative subject
lines in your email to a high-traffic list like this.

mpalmier at mines.edu writes:

> hello there, 
>    I'm a new user to R and I am having difficulty reading a file into the 
> program.  Here's the error I keep getting, I bet there's a simple solution, 
> but I cant find any...
> 
> Error in file(file, "r") : unable to open connection
> In addition: Warning message: 
> cannot open file `c:MikeWeather2.txt' 
> 
> I have made sure that my working directory is the same as the place where the 
> file is.  I have also tried using the full path name of the file.  read.table, 
> read.delim, read.csv, and scan have all been attempted with no result.  What 
> causes this message, and how can I fix it.  Thanks in advance for your help,

I always find it tedious to remember how to write file names in
Windows (there are rules about '\' and '/' characters) so I use the
file.choose() function, which brings up a chooser panel.  Although you
haven't said what you want to do with the file, let's assume you are
going to source some R code in the file.  Then you could use

source(file.choose())



From Torsten.Steuernagel at gmx.de  Thu Jan 29 21:30:19 2004
From: Torsten.Steuernagel at gmx.de (Torsten Steuernagel)
Date: Thu, 29 Jan 2004 21:30:19 +0100
Subject: [R] Object validation and formal classes
Message-ID: <40197B6B.23259.1B24BAFF@localhost>

I'm using R 1.8.1 (Win32, Linux) and have some difficulties using 
validation functions for S4 classes. The problem is if I specify a 
validation function with setValidity("myclass", validate.myclass) object 
validation is only performed when I create an instance using 
new("myclass"), or when I explicitly call validObject(x) where x is of 
class "myclass", of course. 

According to the reference docs, I would expect that validation always 
takes place implicitly when I manipulate an object of "myclass". This 
especially includes implicit validation if I change slots directly, i.e. 
x at myslot <- 1:50 should call my validation function. Unfortunately, it 
isn't called and instead of raising an error and leaving the object 
unchanged in case validation fails, the object is always changed no 
matter what I assign to the slot.

I'm not sure if I'm missing something here or if I just didn't get the point 
of validation functions, but I believe there must be a way to assure that 
an object is in a consistent state.

Thanks for your help,

Torsten



From sfalcon at fhcrc.org  Thu Jan 29 21:48:41 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 29 Jan 2004 12:48:41 -0800
Subject: [R] build fails to build help for nlme
In-Reply-To: <Pine.LNX.4.44.0401292018250.32496-100000@gannet.stats>
References: <20040129172510.GE13695@queenbee.fhcrc.org>
	<Pine.LNX.4.44.0401292018250.32496-100000@gannet.stats>
Message-ID: <20040129204838.GH13695@queenbee.fhcrc.org>

Thanks for the response.  Disk space was not the issue (over 90G avail).
However, today I tried a "make clean && make" and everything went fine.
Wish I had an explanation, but I'll settle for the clean build ;-)


On Thu, Jan 29, 2004 at 08:18:41PM +0000, Prof Brian Ripley wrote:
> I have once seen this when a disc became full.



From p.dalgaard at biostat.ku.dk  Thu Jan 29 22:43:22 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Jan 2004 22:43:22 +0100
Subject: [R] build fails to build help for nlme
In-Reply-To: <Pine.LNX.4.44.0401292018250.32496-100000@gannet.stats>
References: <Pine.LNX.4.44.0401292018250.32496-100000@gannet.stats>
Message-ID: <x23c9yxwg5.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> I have once seen this when a disc became full.

Flaky RAM chips and overheating might do it too. Also, running the
system near memory full condition (a runaway Mozilla or Java process
perchance?). Is the crash point reproducible?

> On Thu, 29 Jan 2004, Seth Falcon wrote:
> 
> > Hi all,
> > 
> > I'm trying to build R-1.8.1 from source on Linux and getting the
> > following error when the makefile gets to the step of building the help
> > for 'nlme':
> > 
> > <snip>
> > ranef.lme                         text    html    latex   example
> > reStruct                          text    html    latex   example
> > /home/sfalcon/sw/R-related/R-1.8.1/bin/INSTALL: line 1:  8133 Segmentation fault      ${R_CMD} perl "${R_HOME}/share/perl/build-help.pl" ${build_help_opts} "${pkg_dir}" "${lib}" "${R_PACKAGE_DIR}" "${pkg_name}"
> > ERROR: building help failed for package 'nlme'
> > ** Removing '/home/sfalcon/sw/R-related/R-1.8.1/library/nlme'
> > make[2]: *** [nlme.ts] Error 1
> > make[2]: Leaving directory
> > `/home/sfalcon/sw/R-related/R-1.8.1/src/library/Recommended'
> > make[1]: *** [recommended-packages] Error 2
> > make[1]: Leaving directory
> > `/home/sfalcon/sw/R-related/R-1.8.1/src/library/Recommended'
> > make: *** [stamp-recommended] Error 2
> > </snip>
> > 
> > Has anyone else encountered this?
> > 
> > I've had no difficulties compiling previous versions of R on this
> > machine.
> > 
> > 
> > Thanks,
> > 
> > + seth
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ozric at web.de  Thu Jan 29 22:57:48 2004
From: ozric at web.de (Christian Schulz)
Date: Thu, 29 Jan 2004 22:57:48 +0100
Subject: [R] RMySQL for R1.8.1 on Windows
In-Reply-To: <1F8990C21AC73945BE6AAC5AD6D4CAE9064036@BCSXAC.knmi.nl>
References: <1F8990C21AC73945BE6AAC5AD6D4CAE9064036@BCSXAC.knmi.nl>
Message-ID: <200401292112.56195.ozric@web.de>

Hi,

you have to install RMySQL-0.5.3 from
source with Rcmd INSTALL RMySQL*.tgz but before this works you have to 
reimp the  lib/opt/libmysql.lib
You find reimp in Mingw Installation.

hope this helps,
regards,christian




Am Donnerstag, 29. Januar 2004 17:00 schrieb Hoeven, Maarten van der:
> Hi all,
>
> I'm looking for a way to install the RMySQL-package into my
> Windows-version of R (1.8.1).
>
> I did successfully install this package into my Linux-version of R
> (RedHat9), but now I want to do this in my Windows-version too.
>
> How to?
>
> Regards,
> Maarten
> --------------------------------------------------------------
> Zie ook/see also: http://www.knmi.nl/maildisclaimer.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From dmurdoch at pair.com  Thu Jan 29 23:33:43 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 29 Jan 2004 17:33:43 -0500
Subject: file names under Windows [was: [R] please help me!]
In-Reply-To: <6r1xpi7bhx.fsf@bates4.stat.wisc.edu>
References: <1075393163.4019328b670a7@webmail.mines.edu>
	<6r1xpi7bhx.fsf@bates4.stat.wisc.edu>
Message-ID: <i02j10djcb4e2lftkgi1qnrjbl6o5aap4j@4ax.com>

On 29 Jan 2004 14:20:26 -0600, you wrote:

>I always find it tedious to remember how to write file names in
>Windows (there are rules about '\' and '/' characters) so I use the
>file.choose() function, which brings up a chooser panel.  Although you
>haven't said what you want to do with the file, let's assume you are
>going to source some R code in the file.  Then you could use
>
>source(file.choose())

I've occasionally thought that "file = file.choose()" would be better
than no default in a lot of functions that take filenames as
arguments, e.g. file, the read* and write* functions, the bitmap
device, Sweave, etc.

Duncan Murdoch



From sfalcon at fhcrc.org  Thu Jan 29 23:45:56 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 29 Jan 2004 14:45:56 -0800
Subject: [R] build fails to build help for nlme
In-Reply-To: <x23c9yxwg5.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0401292018250.32496-100000@gannet.stats>
	<x23c9yxwg5.fsf@biostat.ku.dk>
Message-ID: <20040129224555.GJ13695@queenbee.fhcrc.org>

On Thu, Jan 29, 2004 at 10:43:22PM +0100, Peter Dalgaard wrote:
> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> 
> > I have once seen this when a disc became full.
> 
> Flaky RAM chips and overheating might do it too. Also, running the
> system near memory full condition (a runaway Mozilla or Java process
> perchance?). Is the crash point reproducible?

Per my previous reply, I waited a day and tried "make clean && make" and
got a clean build.

Yesterday, I tried repeating the make command (I didn't clean first),
and I did get the crash in what looked to be the same point when
building the help for the nlme package.

Given this, flaky RAM or high mem load seem more likely.  If I run into
it again I will be sure to make note of the current system load and
such.

Thanks,

+ seth



From rxg218 at psu.edu  Fri Jan 30 00:43:22 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Thu, 29 Jan 2004 18:43:22 -0500
Subject: [R] a question regarding leaps
Message-ID: <1075419802.2002.15.camel@ra.chem.psu.edu>

Hi,
  I'm using regsubsets from the leaps package to select subsets of
variables. I'm calling the function as

 lp <- regsubsets(x,y,nbest=5,nvmax=9)

Then I call plot to see which variables turned up in the models. I use
the R^2 scale and see my best model had a R^2 of 0.62.

However when I make a linear model using lm() with the same x my R^2 is
0.45. Should'nt I be seeing the same value of R^2?

I must be making a mistake somewhere but I'm not sure where - could
anybody provide a pointer as to what I'm doing wrong?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
If you believe in telekinesis, raise my hand.



From vograno at evafunds.com  Fri Jan 30 01:17:48 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Thu, 29 Jan 2004 16:17:48 -0800
Subject: [R] Running R remotely in Windows Environment? - Xemacs and ssh
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A50C3A2E@phost015.intermedia.net>

Hi,

While we are on the topic of "Running R remotely in Windows Environment"
maybe someone could help with the following specific problem. I run R on
a Linux box from my WindowsXP laptop. I do so via Exceed, which for some
reasons is inconvenient for me.
As an alternative I tried to ssh into the linux machine and then run R.
This worked fine from Cygwin's bash window, but not from under XEmacs
(native Windows port). After starting ssh Xemacs complained:
"Pseudo-terminal will not be allocated because stdin is not a terminal"
and didn't show the prompt. Did anyone figure out how to remotely run R
from under (X)Emacs on Windows using ssh?

Thanks,
Vadim



From sfalcon at fhcrc.org  Wed Jan 28 21:30:03 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 28 Jan 2004 12:30:03 -0800
Subject: [R] build fails to build help for nlme
Message-ID: <20040128203002.GB10749@queenbee.fhcrc.org>

Hi all,

I'm trying to build from source on Linux and getting the following error
when it tries to build the help for 'nlme':

<snip>
ranef.lme                         text    html    latex   example
reStruct                          text    html    latex   example
/home/sfalcon/sw/R-related/R-1.8.1/bin/INSTALL: line 1:  8133 Segmentation fault      ${R_CMD} perl "${R_HOME}/share/perl/build-help.pl" ${build_help_opts} "${pkg_dir}" "${lib}" "${R_PACKAGE_DIR}" "${pkg_name}"
ERROR: building help failed for package 'nlme'
** Removing '/home/sfalcon/sw/R-related/R-1.8.1/library/nlme'
make[2]: *** [nlme.ts] Error 1
make[2]: Leaving directory
`/home/sfalcon/sw/R-related/R-1.8.1/src/library/Recommended'
make[1]: *** [recommended-packages] Error 2
make[1]: Leaving directory
`/home/sfalcon/sw/R-related/R-1.8.1/src/library/Recommended'
make: *** [stamp-recommended] Error 2
</snip>

Has anyone else encountered this?  


Thanks,

+ seth



From edd at debian.org  Fri Jan 30 02:02:57 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 29 Jan 2004 19:02:57 -0600
Subject: [R] Running R remotely in Windows Environment? - Xemacs and ssh
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A50C3A2E@phost015.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A50C3A2E@phost015.intermedia.net>
Message-ID: <20040130010257.GA16835@sonny.eddelbuettel.com>

On Thu, Jan 29, 2004 at 04:17:48PM -0800, Vadim Ogranovich wrote:
> Hi,
> 
> While we are on the topic of "Running R remotely in Windows Environment"
> maybe someone could help with the following specific problem. I run R on
> a Linux box from my WindowsXP laptop. I do so via Exceed, which for some
> reasons is inconvenient for me.
> As an alternative I tried to ssh into the linux machine and then run R.
> This worked fine from Cygwin's bash window, but not from under XEmacs
> (native Windows port). After starting ssh Xemacs complained:
> "Pseudo-terminal will not be allocated because stdin is not a terminal"
> and didn't show the prompt. Did anyone figure out how to remotely run R
> from under (X)Emacs on Windows using ssh?

Cygwin can now run an X11 server for you, and it can do it such that the
normal win2k/xp/... window manager controls things -- you need a special
switch the name of which I cannot recall right now (and the windoze system
is at work). Look into the supplied startxin.{bat,sh} which has the line
commented.

So with X11 running on windows machine, you can get via 'ssh -X host' and
get any X11-compliant app back to your windows system.  

Hth, Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From rgentlem at jimmy.harvard.edu  Fri Jan 30 02:04:32 2004
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Thu, 29 Jan 2004 20:04:32 -0500
Subject: [R] Object validation and formal classes
In-Reply-To: <40197B6B.23259.1B24BAFF@localhost>;
	from Torsten.Steuernagel@gmx.de on Thu, Jan 29, 2004 at
	09:30:19PM +0100
References: <40197B6B.23259.1B24BAFF@localhost>
Message-ID: <20040129200432.M12832@jimmy.harvard.edu>

On Thu, Jan 29, 2004 at 09:30:19PM +0100, Torsten Steuernagel wrote:
> I'm using R 1.8.1 (Win32, Linux) and have some difficulties using 
> validation functions for S4 classes. The problem is if I specify a 
> validation function with setValidity("myclass", validate.myclass) object 
> validation is only performed when I create an instance using 
> new("myclass"), or when I explicitly call validObject(x) where x is of 
> class "myclass", of course. 
> 
> According to the reference docs, I would expect that validation always 
> takes place implicitly when I manipulate an object of "myclass". This 
> especially includes implicit validation if I change slots directly, i.e. 
> x at myslot <- 1:50 should call my validation function. Unfortunately, it 
> isn't called and instead of raising an error and leaving the object 
> unchanged in case validation fails, the object is always changed no 
> matter what I assign to the slot.

  There are some efficiency issues that prevent constant checking (at
  least at the present time). There are also some other issues that
  need to be adequately addressed too. For example, suppose I had an
  object with two slots
   a - a character string 
   b - the number of characters

  and I set my validity checker to make sure that the length of the
  string is the number in b. Now that basically means that I can never
  change the string (except to other strings of the same length) if
  validity checking happened after every change. I somehow need
  changing both a and b to be instantaneous (which they currently are
  not). We have not really gone far enough down that path yet to know
  what the right thing is, but we  are working on it. So for now
  validity checking occurs at a   few specific points and if/when you
  ask for it. 

  Robert


> 
> I'm not sure if I'm missing something here or if I just didn't get the point 
> of validation functions, but I believe there must be a way to assure that 
> an object is in a consistent state.
> 
> Thanks for your help,
> 
> Torsten
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20                            |
| Harvard School of Public Health  email: rgentlem at jimmy.harvard.edu        |
+---------------------------------------------------------------------------+



From SuzieBlatt at netscape.net  Fri Jan 30 03:45:55 2004
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Thu, 29 Jan 2004 21:45:55 -0500
Subject: [R] Memory clear problem
Message-ID: <37A7B001.56B0B38E.0D1322AF@netscape.net>


Hello.

I think this is a simple problem.  I have R running a program which generates variables that it 'remembers'.  The trouble is that I've modified the file that it's generating these variables from but doesn't seem to realize that.  When I type 'trees' - I get the same data set produced.

I tried shutting R down and not saving the workspace, but when I open 'er up again and type 'trees', there is that same data set.  I saw a memory clear command somewhere in one of the help files but I'll be danged if I can locate it now.

Please tell me this is a simple problem with a nice(one-line) solution.

Thanks,
Suzanne



From tlumley at u.washington.edu  Fri Jan 30 03:55:22 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 29 Jan 2004 18:55:22 -0800 (PST)
Subject: [R] Variable substitution in grep pattern
In-Reply-To: <20040129190705.4993a720.gimli@email.it>
References: <20040129190705.4993a720.gimli@email.it>
Message-ID: <Pine.A41.4.58.0401291852330.179122@homer01.u.washington.edu>

On Thu, 29 Jan 2004, Alberto Fornasier wrote:
>
> I've tried to use a "for" loop as follows:
>
> > for(i in Licenza.elenco) {
> + Licenza.elenco.prova[Licenza.elenco==i] <-
>   length(grep(".*i.*",as.character(Licenza)))}
>
> In which Licenza.elenco is a character vector containing all unique
> values I need to match (e.g. BSD License, Qt Public License (QPL), GNU
> General Public License (GPL)).
> However R handles as I expect only the first variable substitution (the
> index), but grep matches all strings containing the letter "i", that is
> 100% of the vector, except NAs of course.


You can't do that.  If you could , how would you search for all strings
containing the letter "i"?

You need to use something like paste() to construct the pattern

length(grep(paste(".*",i,".*",sep=""),as.character(Licenza)))}

	-thomas



From yunfang at yahoo-inc.com  Fri Jan 30 04:03:32 2004
From: yunfang at yahoo-inc.com (Yun-Fang Juan)
Date: Thu, 29 Jan 2004 19:03:32 -0800
Subject: [R] memory problem for R 
Message-ID: <029001c3e6dd$a50eb030$90ea7ecf@YUNFANG2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040129/3f4736f1/attachment.pl

From jfox at mcmaster.ca  Fri Jan 30 04:24:51 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 29 Jan 2004 22:24:51 -0500
Subject: [R] a question regarding leaps
In-Reply-To: <1075419802.2002.15.camel@ra.chem.psu.edu>
Message-ID: <5.1.0.14.2.20040129221417.0204c050@127.0.0.1>

Dear Rajarshi,

At 06:43 PM 1/29/2004 -0500, Rajarshi Guha wrote:
>Hi,
>   I'm using regsubsets from the leaps package to select subsets of
>variables. I'm calling the function as
>
>  lp <- regsubsets(x,y,nbest=5,nvmax=9)
>
>Then I call plot to see which variables turned up in the models. I use
>the R^2 scale and see my best model had a R^2 of 0.62.
>
>However when I make a linear model using lm() with the same x my R^2 is
>0.45. Should'nt I be seeing the same value of R^2?
>
>I must be making a mistake somewhere but I'm not sure where - could
>anybody provide a pointer as to what I'm doing wrong?


It's hard to know exactly from your description what the source of the 
problem is, but I'd guess that it's due to missing data: That is, the 
models fit by regsubsets() likely removed observations that were present 
when you fit the model by lm(). If this is the case, then you could make 
the two results consistent by filtering the missing data before using lm().

I hope that this helps,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From andy_liaw at merck.com  Fri Jan 30 04:22:23 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 29 Jan 2004 22:22:23 -0500
Subject: [R] memory problem for R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76C3@usrymx25.merck.com>

Have you read the posting guide for R-help?  

You need to tell us more: What hardware/OS/version of R are you using?

A rough calculation on storage needed:
> 6e5 * 70 * 8 / 1024^2
[1] 320.4346

So you need 320+ MB of RAM just to store the data as a matrix of doubles in
R.  You need enough RAM to make a couple of copies of this.  If any of the
variables are factors, the requirement goes up even more, as the design
matrix used to fit the model will expand the factors into columns of
contrasts.  How much physical RAM do you have on the computer?

There are more efficient ways to fit the model to data of this size, but you
need to be able to at least fit the data into memory.  There have been a few
suggestions on R-help before on how to do this, so do search the archive.
(I believe Prof. Koenker had a web page describing how to do this with mySQL
and updating the X'X matrix by reading in data in chunks.)

Andy

> From: Yun-Fang Juan
> 
> Hi, 
> I try to use lm to fit a linear model with 600k rows and 70 
> attributes.
> But I can't even load the data into the R environment. 
> The error message says the vector memory is used up. 
> 
> Is there anyone having experience with large datasets in R? (I bet)
> 
> Please advise. 
> 
> thanks,
> 
> Yun-Fang 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From yunfang at yahoo-inc.com  Fri Jan 30 05:07:00 2004
From: yunfang at yahoo-inc.com (Yun-Fang Juan)
Date: Thu, 29 Jan 2004 20:07:00 -0800
Subject: [R] memory problem for R 
References: <029001c3e6dd$a50eb030$90ea7ecf@YUNFANG2>
Message-ID: <02d601c3e6e6$82c17950$90ea7ecf@YUNFANG2>


Here is the exact error I got
----------------------
Read 73 items
Error: cannot allocate vector of size 1953 Kb
Execution halted
-----------------------
I am running R on Freebsd 4.3
with double CPU and 2 GB memory
Is that sufficient?

hw.model: Pentium III/Pentium III Xeon/Celeron
hw.ncpu: 2
hw.byteorder: 1234
hw.physmem: 2144411648
hw.usermem: 2009980928

thanks for your advice in advance,


Yun-Fang
----- Original Message -----
From: "Yun-Fang Juan" <yunfang at yahoo-inc.com>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, January 29, 2004 7:03 PM
Subject: [R] memory problem for R


> Hi,
> I try to use lm to fit a linear model with 600k rows and 70 attributes.
> But I can't even load the data into the R environment.
> The error message says the vector memory is used up.
>
> Is there anyone having experience with large datasets in R? (I bet)
>
> Please advise.
>
>
> thanks,
>
>
> Yun-Fang
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>



From nusbj at hotmail.com  Fri Jan 30 08:33:45 2004
From: nusbj at hotmail.com (Z P)
Date: Fri, 30 Jan 2004 15:33:45 +0800
Subject: [R] estimating mode
Message-ID: <Sea2-F48kTgbLYluLCT00002879@hotmail.com>

Dear all,

I am considering a problem related to density regression. After we got the 
estimation of probability density function f(x), how can we estimate the 
mode of that population?

Does the sm package support mode estimation? If not, is there any other 
function in R can estimate the mode according to the estimation of pdf f(x)? 
Univariate case is ok. If the function further support higher dimensions, it 
is perfect.

Thanks.

_________________________________________________________________
Take a break! Find destinations on MSN Travel. http://www.msn.com.sg/travel/



From ripley at stats.ox.ac.uk  Fri Jan 30 08:52:15 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 Jan 2004 07:52:15 +0000 (GMT)
Subject: [R] Running R remotely in Windows Environment? - Xemacs and ssh
In-Reply-To: <20040130010257.GA16835@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.44.0401300741270.974-100000@gannet.stats>

You can do that with Exceed too (we have been doing so for years).

The issue is running ssh inside Xemacs under Windows (in a shell buffer?  
As part of ESS commands?).  I don't know what is meant by `ssh' here.  If
it is Cygwin ssh, you can only mix Cygwin and Windows to some extent.

BTW, the same thing used to happen with rterm under ESS, until I added the
--ess flag.

I think you need to ask this on an more appropriate list for XEmacs 
expertise, specifying more exactly what you are trying to do.

On Thu, 29 Jan 2004, Dirk Eddelbuettel wrote:

> On Thu, Jan 29, 2004 at 04:17:48PM -0800, Vadim Ogranovich wrote:
> > Hi,
> > 
> > While we are on the topic of "Running R remotely in Windows Environment"
> > maybe someone could help with the following specific problem. I run R on
> > a Linux box from my WindowsXP laptop. I do so via Exceed, which for some
> > reasons is inconvenient for me.
> > As an alternative I tried to ssh into the linux machine and then run R.
> > This worked fine from Cygwin's bash window, but not from under XEmacs
> > (native Windows port). After starting ssh Xemacs complained:
> > "Pseudo-terminal will not be allocated because stdin is not a terminal"
> > and didn't show the prompt. Did anyone figure out how to remotely run R
> > from under (X)Emacs on Windows using ssh?
> 
> Cygwin can now run an X11 server for you, and it can do it such that the
> normal win2k/xp/... window manager controls things -- you need a special
> switch the name of which I cannot recall right now (and the windoze system
> is at work). Look into the supplied startxin.{bat,sh} which has the line
> commented.
> 
> So with X11 running on windows machine, you can get via 'ssh -X host' and
> get any X11-compliant app back to your windows system.  
> 
> Hth, Dirk
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Fri Jan 30 08:58:54 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 Jan 2004 08:58:54 +0100
Subject: [R] RMySQL for R1.8.1 on Windows
In-Reply-To: <Pine.LNX.4.44.0401291859320.32255-100000@gannet.stats>
References: <Pine.LNX.4.44.0401291859320.32255-100000@gannet.stats>
Message-ID: <401A0EBE.4080503@statistik.uni-dortmund.de>

Prof Brian Ripley wrote:

> Where is the problem?  It installs from the sources under Windows too, and 
> even comes with notes for Windows.
> 
> Please consult the rw-FAQ for how to install packages.
> 
> We have provided binary builds in the past (and David James may still do 
> so), 

Let me add that http://cran.r-project.org/bin/windows/contrib/1.8/ReadMe 
tells us:

"Although the packages
   RMySQL, ROracle, and snow
pass make check, it seems to be dangerous to distribute them:
I do not have the software available these packages depend on.
RMySQL is available at http://stat.bell-labs.com/RS-DBI/download,
provided by its maintainer, David A. James."

Uwe Ligges



 > but discovered that there was little tolerance for version
> mismatches, of both R and MySQL.  So building from the sources is better,
> 
> On Thu, 29 Jan 2004, Hoeven, Maarten van der wrote:
> 
> 
>>I'm looking for a way to install the RMySQL-package into my
>>Windows-version of R (1.8.1). 
>>
>>I did successfully install this package into my Linux-version of R
>>(RedHat9), but now I want to do this in my Windows-version too.
> 
> 
>



From ligges at statistik.uni-dortmund.de  Fri Jan 30 09:00:53 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 Jan 2004 09:00:53 +0100
Subject: [R] Memory clear problem
In-Reply-To: <37A7B001.56B0B38E.0D1322AF@netscape.net>
References: <37A7B001.56B0B38E.0D1322AF@netscape.net>
Message-ID: <401A0F35.7050003@statistik.uni-dortmund.de>

Suzanne E. Blatt wrote:

> Hello.
> 
> I think this is a simple problem.  I have R running a program which generates variables that it 'remembers'.  The trouble is that I've modified the file that it's generating these variables from but doesn't seem to realize that.  When I type 'trees' - I get the same data set produced.
> 
> I tried shutting R down and not saving the workspace, but when I open 'er up again and type 'trees', there is that same data set.  I saw a memory clear command somewhere in one of the help files but I'll be danged if I can locate it now.
> 
> Please tell me this is a simple problem with a nice(one-line) solution.
> 
> Thanks,
> Suzanne
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

 From ?rm:
## remove (almost) everything in the working environment.
## You will get no warning, so don't do this unless you are really sure.
rm(list = ls())

Uwe Ligges



From ripley at stats.ox.ac.uk  Fri Jan 30 09:38:05 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 Jan 2004 08:38:05 +0000 (GMT)
Subject: [R] memory problem for R 
In-Reply-To: <02d601c3e6e6$82c17950$90ea7ecf@YUNFANG2>
Message-ID: <Pine.LNX.4.44.0401300830130.974-100000@gannet.stats>

On Thu, 29 Jan 2004, Yun-Fang Juan wrote:

> 
> Here is the exact error I got
> ----------------------
> Read 73 items
> Error: cannot allocate vector of size 1953 Kb
> Execution halted
> -----------------------
> I am running R on Freebsd 4.3
> with double CPU and 2 GB memory
> Is that sufficient?

Clearly not.  What is the structure of your `attributes'?  As Andy Liaw
said, the design matrix may be bigger than that if there are factors
involved.  (And you need several copies of the design matrix.)

I would try a 10% sample of the rows to get a measure of what will fit
into your memory.  I have never seen a regression problem for which 600k
cases were needed, and would be interested to know the context.  (It is
hard to imagine that the cases are from a single homogeneous population
and that a linear model fits so well that the random error is not 
dominated by systematic error.)

> 
> Yun-Fang
> ----- Original Message -----
> From: "Yun-Fang Juan" <yunfang at yahoo-inc.com>
> To: <r-help at stat.math.ethz.ch>
> Sent: Thursday, January 29, 2004 7:03 PM
> Subject: [R] memory problem for R
> 
> 
> > Hi,
> > I try to use lm to fit a linear model with 600k rows and 70 attributes.
> > But I can't even load the data into the R environment.
> > The error message says the vector memory is used up.
> >
> > Is there anyone having experience with large datasets in R? (I bet)
> >
> > Please advise.
> >
> >
> > thanks,
> >
> >
> > Yun-Fang
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dieter.menne at menne-biomed.de  Fri Jan 30 10:20:13 2004
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 30 Jan 2004 10:20:13 +0100
Subject: [R] GLMM (lme4) vs. glmmPQL output (summary with lme4 revised)
Message-ID: <JLEPLGAANFCEAEDCAGJNAEGACHAA.dieter.menne@menne-biomed.de>

This is a summary and extension of the thread
"GLMM (lme4) vs. glmmPQL output"

http://maths.newcastle.edu.au/~rking/R/help/04/01/0180.html

In the new revision (#Version: 0.4-7) of lme4 the standard
errors are close to those of the 4 other methods. Thanks to Douglas Bates,
Saikat DebRoy for the revision, and to G?ran Brostr?m who run a
simulation.

In response to my first posting, Prof. B. Ripley wrote:
___
Although it has not been stated nor credited, this is very close to an
example in MASS4 (there seems a difference in coding).  Both the dataset
and much of the alternative analyses are from the work of my student James
McBroom (and other students have contributed).
____

Well, I thought having repeated "MASS" four times in the header of
my submitted test programm was enough credit for the r-help audience,
but he certainly is right: the base example glmmPQL is from MASS,
http://www.stats.ox.ac.uk/pub/MASS4/



#Package: lme4
#Version: 0.4-7
#Date: 2004/01/26  !!!!!! Revised

--- GLMM/lme4/Pinheiro/Bates
                 Estimate Std. Error  DF z value  Pr(>|z|)
(Intercept)       3.41202    0.65874 169  5.1796 2.223e-07
trtdrug          -1.24736    0.81824  47 -1.5244 0.1273995
trtdrug+         -0.75433    0.81993  47 -0.9200 0.3575758
I(week > 2)TRUE  -1.60726    0.45525 169 -3.5305 0.0004148

--- glmmPQL/MASS/Venables&Ripley
                Value Std.Error  DF t-value p-value
(Intercept)      3.41     0.519 169    6.58  0.0000
trtdrug         -1.25     0.644  47   -1.94  0.0588
trtdrug+        -0.75     0.645  47   -1.17  0.2484
I(week > 2)TRUE -1.61     0.358 169   -4.49  0.0000

--- glmmML/glmmML/Brostr?m
                  coef se(coef)     z Pr(>|z|)
(Intercept)      3.579    0.701  5.10  3.3e-07
trtdrug         -1.369    0.694 -1.97  4.8e-02
trtdrug+        -0.789    0.700 -1.13  2.6e-01
I(week > 2)TRUE -1.627    0.482 -3.38  7.3e-04

--- geese/geepack/Jun Yan
                estimate san.se  wald        p
(Intercept)        2.844  0.529 28.92 7.56e-08
trtdrug           -1.113  0.586  3.61 5.76e-02
trtdrug+          -0.634  0.544  1.36 2.44e-01
I(week > 2)TRUE   -1.325  0.368 12.96 3.18e-04

--- glmm/repeated/J.K.Lindsey
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   -3.569      0.549   -6.51  7.8e-11 ***
trtdrug        1.367      0.486    2.81  0.00490 **
trtdrug+       0.786      0.498    1.58  0.11408
week2TRUE      1.623      0.459    3.53  0.00041 ***
sd             1.294      0.250    5.17  2.3e-07 ***
---

---------------------------------------------------------------

data(bacteria,package="MASS")
UseMASS<-T # must restart R after changing because of nlme/lme4 clash
if (UseMASS){
  library(MASS) # required for bacteria
  options(digits=3)
  cat("--- glmmPQL/MASS/Venables&Ripley\n")
  print(summary(glmmPQL(y ~ trt + I(week > 2), random = ~ 1 | ID,
                  family = binomial, data = bacteria)))
  cat("--- glmmML/glmmML/Brostr?m\n")
  library(glmmML)
  print(glmmML(y=="y"~trt+I(week>2), data=bacteria,cluster=bacteria$ID))
  cat("--- geese/geepack/Jun Yan\n")
  library(geepack)
  print(summary(geese(y == "y" ~ trt + I(week > 2), family = binomial,
     id = ID, corstr = "exchangeable",data=bacteria)))
  library(repeated)
  cat("--- glmm/repeated/J.K.Lindsey\n")
  # reformat data as required by glmm. reshape should be safer...

  bac<-as.data.frame(xtabs(~ID+trt+I(week>2)+y,data=bacteria))
  names(bac,)[3]<-"week2"
  nr<-nrow(bac)
  bac<-cbind(bac[1:(nr/2),-4],bac$Freq[(nr/2+1):nr])
  names(bac,)[4]<-"Freq.n"
  names(bac,)[5]<-"Freq.y"
  attach(bac) # couldn't find the right sytax without this
  print(summary(glmm(cbind(Freq.n,Freq.y)~trt+week2, data=bac, nest=ID,
          family=binomial)))

} else
{
  cat("--- GLMM/lme4/Pinheiro/Bates\n")
  library(lme4)
  bac.GLMM<-GLMM(y ~ trt + I(week > 2), random = ~ 1 | ID,
                  family = binomial, data = bacteria,method="PQL")
  print(bac.GLMM)
 }



From stecalza at tiscali.it  Thu Jan 29 17:17:49 2004
From: stecalza at tiscali.it (Stefano Calza)
Date: Thu, 29 Jan 2004 17:17:49 +0100
Subject: [R] Doubt about pattern
In-Reply-To: <20040129113325.00004242@lbmsala4>
References: <20040129113325.00004242@lbmsala4>
Message-ID: <20040129161749.GA4061@med.unibs.it>

what about
dir(pattern="\\.sens+$")

HIH

Ste

On Thu, Jan 29, 2004 at 11:33:25AM -0300, Marcelo Luiz de Laia wrote:
> Hi All,
> 
> I have a very simple problem. I have several files in a same directory. I would like to send for an object only the files that finish in ".sens.". I execute the command below,
> 
> files <- dir(pattern="*.sens")
> 
> but it includes all of the files that have "sens", independent of they be in the end or in the middle of the name of the file. How could I solve this? I sought in the html_help but I didn't find similar to this.
> 
> My files
> 
> "script_sens.txt", "Sen_155_01_R1.sens", "Sen_155_01_R2.sens", "Sen_155_01_R3.sens", "Sen_155_02_R1.sens", "Sen_155_02_R2.sens", "Sen_155_02_R3.sens", "Sen_155_03_R1.sens", "Sen_155_03_R2.sens", "Sen_155_03_R3.sens", "tome2sens_time1sens.txt"
> 
> Tahnks very much
> 
> -- 
> Marcelo Luiz de Laia, M.Sc.
> Dep. de Tecnologia, Lab. Bioqu?mica e de Biologia Molecular
> Universidade Estadual Paulista - UNESP
> Via de Acesso Prof. Paulo Donato Castelane, Km 05
> 14.884-900 - Jaboticabal, SP, Brazil
> PhoneFax: 16 3209-2675/2676/2677 R. 202/208/203 (trab.)
> HomePhone: 16 3203 2328 - www.lbm.fcav.unesp.br - mlaia at yahoo.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From stecalza at tiscali.it  Thu Jan 29 11:49:58 2004
From: stecalza at tiscali.it (Stefano Calza)
Date: Thu, 29 Jan 2004 11:49:58 +0100
Subject: [R] Re: Julian dates
In-Reply-To: <20040129104726.GB837@med.unibs.it>
References: <00a401c3e58c$80a70f00$5a1aa7c0@pc2690>
	<XFMail.040128163837.Ted.Harding@nessie.mcc.ac.uk>
	<20040129104726.GB837@med.unibs.it>
Message-ID: <20040129104958.GC837@med.unibs.it>

origin is a different matter than cut.off. That happens as in chron there's a call to convert.dates and here to expand.year. If you look into the code you see that this function 
convert 2 digits years (e.g. 30 to 1930). The cut of is set to 30. So 27 -> 20027, 31 -> 1931. origin is just needed as dates actually are numbers (seconds if I remenber right) from 
some fixed day, default to 01/01/1970.

 
HIH,
Stefano

> 
> On Wed, Jan 28, 2004 at 04:38:37PM -0000, Ted Harding wrote:
> > On 28-Jan-04 Massimiliano Tripoli wrote:
> > > Hi all,
> > > I have problems with years of dates using "chron" package.
> > > I don't understand why R by this istruction:
> > >> dates("01/02/29",out.format="d/m/year")
> > > [1] 02/Jan/2029
> > > 
> > >> dates("01/02/30",out.format="d/m/year")
> > > [1] 02/Jan/1930
> > > 
> > > reads "29" as 2029
> > > and "30" as 1930. How could I change to read "00" to "05" like 2000 to
> > > 2005 and "06" to "99" like 1906 to 1999 ?
> > 
> > I'm puzzled by the above:
> > 
> > > dates("01/02/29",out.format="d/m/year")
> > [1] 02/Jan/2029
> > > dates("01/02/30",out.format="d/m/year")
> > [1] 02/Jan/1930
> > 
> > so chron apparently acts as though time began at 01/01/1930.
> > 
> > However:
> > 
> > > ?chron
> > -->
> >  origin.: a vector specifying the date with respect to which Julian
> >           dates are computed.  Default is 'c(month = 1, day = 1,
> >           year = 1970)'
> > 
> > (which is the orthodox origin of time according to Unix) and, indeed,
> > 
> > > origin(dates("01/02/29",out.format="d/m/year"))
> > month   day  year 
> >     1     1  1970 
> > 
> > So why does Massimiliano's example behave as though the origin
> > were 01/01/1930?
> > 
> > Best wishes,
> > Ted.
> > 
> > 
> > --------------------------------------------------------------------
> > E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> > Fax-to-email: +44 (0)870 167 1972
> > Date: 28-Jan-04                                       Time: 16:38:37
> > ------------------------------ XFMail ------------------------------
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From pjacklam at online.no  Fri Jan 30 12:46:44 2004
From: pjacklam at online.no (Peter J. Acklam)
Date: Fri, 30 Jan 2004 12:46:44 +0100
Subject: [R] Doubt about pattern
Message-ID: <401C9D83@epostleser.online.no>

Marcelo Luiz de Laia wrote:

> I have a very simple problem. I have several files in a same
> directory. I would like to send for an object only the files
> that finish in ".sens.". I execute the command below,
>
> > files <- dir(pattern="*.sens")

That's not even a valid regular expression in most applications,
but "dir" does allow it, for some reason.  Anyway, I think you
are mixing globs and regular expressions.  If "*.sens" is a glob,
then it will find all files ending with ".sens", which is not
the same as ".sens." which you said above.

Stefano Calza <stecalza at tiscali.it> wrote:
>
> dir(pattern="\\.sens+$")

That will find files ending with ".sens", ".senss", ".sensss",
etc.

To find files ending with ".sens.", the regex is

    dir(pattern = "\\.sens\\.$")

If there is a file called just ".sens.", you have to use
"all.files = TRUE", since files beginning with a "." are
invisible.

Peter

-- 
Peter J. Acklam - pjacklam at online.no - http://home.online.no/~pjacklam



From calza at med.unibs.it  Fri Jan 30 12:55:22 2004
From: calza at med.unibs.it (Stefano Calza)
Date: Fri, 30 Jan 2004 12:55:22 +0100
Subject: [R] Doubt about pattern
In-Reply-To: <401C9D83@epostleser.online.no>
References: <401C9D83@epostleser.online.no>
Message-ID: <20040130115522.GA2370@med.unibs.it>

On Fri, Jan 30, 2004 at 12:46:44PM +0100, Peter J. Acklam wrote:

...cut...
> 
> Stefano Calza <stecalza at tiscali.it> wrote:
> >
> > dir(pattern="\\.sens+$")
> 
> That will find files ending with ".sens", ".senss", ".sensss",
> etc.
> 
> To find files ending with ".sens.", the regex is
> 
>     dir(pattern = "\\.sens\\.$")
> 
> If there is a file called just ".sens.", you have to use
> "all.files = TRUE", since files beginning with a "." are
> invisible.

Ops you're perfectly right. Should not put +!!

Thanks,

Ste

> Peter
> 
> -- 
> Peter J. Acklam - pjacklam at online.no - http://home.online.no/~pjacklam

-- 
Stefano Calza,
Sezione di Statistica Medica
Dip. di Scienze Biomediche e Biotecnologie
Universit? degli Studi di Brescia - Italy
Viale Europa, 11 25123 Brescia
email: calza at med.unibs.it
Telefono/Phone: +390303717532
Fax: +390303701157



From Pascal.Niklaus at unibas.ch  Fri Jan 30 13:13:51 2004
From: Pascal.Niklaus at unibas.ch (Pascal A. Niklaus)
Date: Fri, 30 Jan 2004 13:13:51 +0100
Subject: [R] lines in 3d-cloud plot (lattice)
Message-ID: <401A4A7F.1050301@unibas.ch>

Hi all,

I'd like to plot a set of data (x,y,z) as 3D-cloud, and add several line 
plots to the same 3D graph:

Two questions:

1) How do I connect points to get a line?

> cloud(z~x*y,data=d,zlim=c(0,1))        # works
> cloud(z~x*predict(l),data=d,zlim=c(0,1),type="l")   # type="l" doesn't
Warning message:
type = l not implemented, consider using 'panel.3d.cloud = panel.3dscatter.old' in: panel.3d.cloud(x = x, y = y, z = z, rot.mat = rot.mat, za = za,

help.search("panel.3d.cloud") also didn't report any hits.

2) How do I superimpose a second data set onto the same graph?

(something equivalent to the sequence plot(), followed by points() or lines() in the base plotting functions)

Thanks for any help

Pascal



From Torsten.Steuernagel at gmx.de  Fri Jan 30 13:19:02 2004
From: Torsten.Steuernagel at gmx.de (Torsten Steuernagel)
Date: Fri, 30 Jan 2004 13:19:02 +0100
Subject: [R] Object validation and formal classes
In-Reply-To: <20040129200432.M12832@jimmy.harvard.edu>
References: <40197B6B.23259.1B24BAFF@localhost>;
	from Torsten.Steuernagel@gmx.de on Thu, Jan 29, 2004 at 09:30:19PM
	+0100
Message-ID: <401A59C6.2728.1E894EC8@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040130/4d847476/attachment.pl

From spencer.graves at pdf.com  Fri Jan 30 13:28:04 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 30 Jan 2004 04:28:04 -0800
Subject: [R] memory problem for R
In-Reply-To: <Pine.LNX.4.44.0401300830130.974-100000@gannet.stats>
References: <Pine.LNX.4.44.0401300830130.974-100000@gannet.stats>
Message-ID: <401A4DD4.4030004@pdf.com>

      Hello, Yun-Fan: 

      Prof. Ripley's comments will get you started.  Part of the key is 
finding informative ways to subset and summarize the data so you don't 
try to read it all into R at once.  You can read segments using 
arguments "skip" and "nrows" in "read.table".  You can then analyze a 
portion, save a summary, discard the bulk of the data and read another 
portion. 
    
      Beyond this, you may know that Kalman filtering is essentially 
linear regression performed one observation or one group of observations 
at a time, downweighting "older" observations gracefully.  It 
essentially assumes that the regression parameters follow a random walk 
between observations or groups of observations.  I've done ordinary 
least squares with Kalman filtering software one observation at a time, 
just by setting the migration variance to zero.  R software for Kalman 
filtering was discussed recently in this list;  to find it, I would use 
the search facilities described in the posting guide at the end of every 
r-help email. 

      hope this helps. 
      spencer graves

Prof Brian Ripley wrote:

>On Thu, 29 Jan 2004, Yun-Fang Juan wrote:
>
>  
>
>>Here is the exact error I got
>>----------------------
>>Read 73 items
>>Error: cannot allocate vector of size 1953 Kb
>>Execution halted
>>-----------------------
>>I am running R on Freebsd 4.3
>>with double CPU and 2 GB memory
>>Is that sufficient?
>>    
>>
>
>Clearly not.  What is the structure of your `attributes'?  As Andy Liaw
>said, the design matrix may be bigger than that if there are factors
>involved.  (And you need several copies of the design matrix.)
>
>I would try a 10% sample of the rows to get a measure of what will fit
>into your memory.  I have never seen a regression problem for which 600k
>cases were needed, and would be interested to know the context.  (It is
>hard to imagine that the cases are from a single homogeneous population
>and that a linear model fits so well that the random error is not 
>dominated by systematic error.)
>
>  
>
>>Yun-Fang
>>----- Original Message -----
>>From: "Yun-Fang Juan" <yunfang at yahoo-inc.com>
>>To: <r-help at stat.math.ethz.ch>
>>Sent: Thursday, January 29, 2004 7:03 PM
>>Subject: [R] memory problem for R
>>
>>
>>    
>>
>>>Hi,
>>>I try to use lm to fit a linear model with 600k rows and 70 attributes.
>>>But I can't even load the data into the R environment.
>>>The error message says the vector memory is used up.
>>>
>>>Is there anyone having experience with large datasets in R? (I bet)
>>>
>>>Please advise.
>>>
>>>
>>>thanks,
>>>
>>>
>>>Yun-Fang
>>>
>>>[[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>>      
>>>
>>http://www.R-project.org/posting-guide.html
>>    
>>
>>>      
>>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>
>>    
>>
>
>  
>



From ripley at stats.ox.ac.uk  Fri Jan 30 13:29:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 Jan 2004 12:29:59 +0000 (GMT)
Subject: [R] Doubt about pattern
In-Reply-To: <401C9D83@epostleser.online.no>
Message-ID: <Pine.LNX.4.44.0401301220460.2476-100000@gannet.stats>

On Fri, 30 Jan 2004, Peter J. Acklam wrote:

> Marcelo Luiz de Laia wrote:
> 
> > I have a very simple problem. I have several files in a same
> > directory. I would like to send for an object only the files
> > that finish in ".sens.". I execute the command below,
> >
> > > files <- dir(pattern="*.sens")
> 
> That's not even a valid regular expression in most applications,
> but "dir" does allow it, for some reason.  Anyway, I think you

It is a valid regex in GNU's regex code as used by R, and all the GNU and
non-GNU applications I tried accepted it.  `*' matches itself when not
used as a repetition qualifier.  (I tried several greps, including those
claiming strict POSIX compliance.)

So, can you please list the `most applications' you tried or give a 
reference for your assertion?

> are mixing globs and regular expressions.  If "*.sens" is a glob,
> then it will find all files ending with ".sens", which is not
> the same as ".sens." which you said above.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Fri Jan 30 13:30:40 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 30 Jan 2004 04:30:40 -0800
Subject: [R] Memory clear problem
In-Reply-To: <401A0F35.7050003@statistik.uni-dortmund.de>
References: <37A7B001.56B0B38E.0D1322AF@netscape.net>
	<401A0F35.7050003@statistik.uni-dortmund.de>
Message-ID: <401A4E70.4090203@pdf.com>

Hi, Suzanne: 

      R makes a copy of the file and does not operate on the original 
file.  If you want R to see and process the changes, you must reread the 
file and rerun the script to recompute whatever you want. 

      hope this helps. 
      spencer graves

Uwe Ligges wrote:

> Suzanne E. Blatt wrote:
>
>> Hello.
>>
>> I think this is a simple problem.  I have R running a program which 
>> generates variables that it 'remembers'.  The trouble is that I've 
>> modified the file that it's generating these variables from but 
>> doesn't seem to realize that.  When I type 'trees' - I get the same 
>> data set produced.
>>
>> I tried shutting R down and not saving the workspace, but when I open 
>> 'er up again and type 'trees', there is that same data set.  I saw a 
>> memory clear command somewhere in one of the help files but I'll be 
>> danged if I can locate it now.
>>
>> Please tell me this is a simple problem with a nice(one-line) solution.
>>
>> Thanks,
>> Suzanne
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
> From ?rm:
> ## remove (almost) everything in the working environment.
> ## You will get no warning, so don't do this unless you are really sure.
> rm(list = ls())
>
> Uwe Ligges
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Fri Jan 30 14:30:04 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 30 Jan 2004 08:30:04 -0500
Subject: [R] estimating mode
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76CE@usrymx25.merck.com>

You can find some Splus code on Prof. Minnotte's web page:
http://math.usu.edu/~minnotte/research/pubs.html.  You can try and see if
those can be use directly in R.  If not, porting may not be too hard.

Prof. Marron's `SiZer' might also be of interest, but I only know of the
Matlab code that are provided by Steve.

HTH,
Andy

> From: Z P
> 
> Dear all,
> 
> I am considering a problem related to density regression. 
> After we got the 
> estimation of probability density function f(x), how can we 
> estimate the 
> mode of that population?
> 
> Does the sm package support mode estimation? If not, is there 
> any other 
> function in R can estimate the mode according to the 
> estimation of pdf f(x)? 
> Univariate case is ok. If the function further support higher 
> dimensions, it 
> is perfect.
> 
> Thanks.
> 
> _________________________________________________________________
> Take a break! Find destinations on MSN Travel. 
> http://www.msn.com.sg/travel/


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From pjacklam at online.no  Fri Jan 30 14:34:43 2004
From: pjacklam at online.no (Peter J. Acklam)
Date: Fri, 30 Jan 2004 14:34:43 +0100
Subject: [R] Doubt about pattern
Message-ID: <401AEF67@epostleser.online.no>

Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

>Peter J. Acklam wrote:
>
> > Marcelo Luiz de Laia wrote:
> >
> > > > files <- dir(pattern="*.sens")
> >
> > That's not even a valid regular expression in most applications,
> > but "dir" does allow it, for some reason.  Anyway, I think you
>
> It is a valid regex in GNU's regex code as used by R, and all the GNU
> and non-GNU applications I tried accepted it.  `*' matches itself when
> not used as a repetition qualifier.  (I tried several greps, including
> those claiming strict POSIX compliance.)
>
> So, can you please list the `most applications' you tried or give a
> reference for your assertion?

I should have said "many applications", not "most applications."
I use Solaris, and I don't know one Solaris application which allows
it, including egrep, oawk, and nawk.  And no version of Perl allows it.

GNU-tools allow it, but in an inconsistent way.  GNU Emacs treats `*x' as
`\*x' (match a literal star and a literal x), but GNU grep (version 2.5)
treats `*x' as `.*x' (match anything up to and including the first x),
which is something quite different.

It's a mess, it's inconsistent, and it's not portable.  I suggest people
stop using "*..." and use "\*..." or ".*..." depending on what is wanted.

Peter

-- 
Peter J. Acklam - pjacklam at online.no - http://home.online.no/~pjacklam



From rvencio at ime.usp.br  Fri Jan 30 14:46:43 2004
From: rvencio at ime.usp.br (Ricardo Zorzetto Nicoliello Vencio)
Date: Fri, 30 Jan 2004 11:46:43 -0200 (BRST)
Subject: [R] How to create own distance measure in cluster ?
Message-ID: <Pine.LNX.4.44.0401301136150.17763-100000@kevlar.ime.usp.br>

Hi everyone,

I want to create my own distance measure, other than 'euclidean' or
'manhatan', to use in cluster pckgs. To do this I think that I need to
change dist(), in mva pckg, or daisy(), in cluster pckg. (or is there a
cleaver way ?)


But this functions are in fact things like: .Fortran( "daisy", ... ) or
.C("dist",...).

I tried unsuccessfully to find source code of .Fortran or .C function to
lear how R calculate dissimilarity matrix and then modify source to add my
own distance metrix.

Could someone help me ? Help me to find .Fortran(...) source or helpe me
with better idea to implement my own distance metrix ?



From ggrothendieck at myway.com  Fri Jan 30 14:56:59 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 30 Jan 2004 08:56:59 -0500 (EST)
Subject: [R] Doubt about pattern
Message-ID: <20040130135659.889D93960@mprdmxin.myway.com>


Your question has by now been answered but I thought
I would add that if you want to do it via file globbing on Windows
rather than regular expressions then this function would help:


list.files.glob <- function( spec ) {
   # returns list of files or NULL if none: spec uses globbing and can
   # use either forward or backward slashes. 
   # e.g list.files.glob( "c:/a*.*" )
   # e.g. list.files.glob( "c:/myfolder/my*.dat")
   # only works on Windows
   if ( substring(spec,2,2) != ":" ) spec <- paste( "C", spec, sep= ":" )
   z <- system( paste("cmd /c attrib", spec), intern = T, invisible = T)
   if ( !pmatch("File not found - ", z[1], nomatch = 0) )  substring(z,12)
}


For example:

   list.files.glob( "*.sens" )


On Thu, Jan 29, 2004 at 11:33:25AM -0300, Marcelo Luiz de Laia 
(mlaia at fcav.unesp.br) wrote:
> Hi All,
> 
> I have a very simple problem. I have several files in a same directory. I would like to send for an object only the files that finish in ".sens.". I execute the command below,
> 
> files <- dir(pattern="*.sens")
> 
> but it includes all of the files that have "sens", independent of they be in the end or in the middle of the name of the file. How could I solve this? I sought in the html_help but I didn't find similar to this.
> 
> My files
> 
> "script_sens.txt", "Sen_155_01_R1.sens", "Sen_155_01_R2.sens", "Sen_155_01_R3.sens", "Sen_155_02_R1.sens", "Sen_155_02_R2.sens", "Sen_155_02_R3.sens", "Sen_155_03_R1.sens", "Sen_155_03_R2.sens", "Sen_155_03_R3.sens", "tome2sens_time1sens.txt"
> 
> Tahnks very much
> 
> -- 
> Marcelo Luiz de Laia, M.Sc.
> Dep. de Tecnologia, Lab. Bioqumica e de Biologia Molecular
> Universidade Estadual Paulista - UNESP
> Via de Acesso Prof. Paulo Donato Castelane, Km 05
> 14.884-900 - Jaboticabal, SP, Brazil
> PhoneFax: 16 3209-2675/2676/2677 R. 202/208/203 (trab.)
> HomePhone: 16 3203 2328 - www.lbm.fcav.unesp.br - mlaia at yahoo.com
>



From James_A_Rogers at groton.pfizer.com  Fri Jan 30 15:57:36 2004
From: James_A_Rogers at groton.pfizer.com (Rogers, James A [PGRD Groton])
Date: Fri, 30 Jan 2004 09:57:36 -0500
Subject: [R] How to generate a report with graphics and tables?
Message-ID: <C735670CCC69D61193DA0002A58EE9900AEB74A8@groexmb07.pfizer.com>

Just to expand on an earlier suggestion:

> > I have some data sets which change on a daily bases. So far I have 
> > imported these sets into R, done all my evaluations resulting in a 
> > couple of plots, charts and tables of numbers which I copy&pasted via>
  > clipboard into Powerpoint. 
> > The procedure is always the same and I wonder, whether there is no 
> > easier way for doing so. Is there some type of "report generator" 
> > available or some HowTo on this. 
> > 
> > Can anybody give me a hint on where to look for? 
> > 
> > Regards, 
> > 
> > Olaf B?rger 

...

> One other possibility is to use the R2HTML package (and maybe the xtable>
  package, too) to write the `report' in HTML. 
> 
> 
> HTH, 
> Andy 
> 
> 

R2HTML is not (yet) as far along as Sweave, but depending on how much
sympathy you have for your clients, html can be a very nice solution. An
important requirement for many reports is that computer-naive clients be
able to edit and copy from the reports to an MS application, preferably
without severe font and formatting problems and without needing to
install/understand <foo>2<bar> type applications. See comments to this
effect in the recent R2HTML article by the package author, Eric Lecoutre in
the most recent R News (vol 3/3). As Andy noted, xtable is nice to use in
conjunction with R2HTML (just write a little xtable method like the one
following this message):

In particular, a naive user viewing the html file with Internet Explorer (I
know v. 5.5 or greater will work) will have an option, under the File menu
to "Edit with Microsoft Word for Windows". This assumes they have set MS
Word as their HTML editor within IE. It also assumes some minimal formatting
requirements for the HTML file (but you can worry about this, the client
won't have to). 

I find this solution keeps everyone happy:
1. I can auto-generate text source for my documents;
2. clients without proprietary software can view the report; 
3. clients with standard MS software but without a clue can easily edit and
copy. 

Cheers,
Jim 

HTML.xtable <- function(x, file = .HTML.file, append = TRUE) {
  sink(file = file, append = append)
  print(x, type = "html")
  sink()
}

James A. Rogers 
Manager, Nonclinical Statistics
PGR&D Groton Labs
Eastern Point Road (MS 8260-1331)
Groton, CT 06340
office: (860) 686-0786
fax: (860) 715-5445
 










LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From jzhang10 at uic.edu  Fri Jan 30 16:13:39 2004
From: jzhang10 at uic.edu (jzhang10)
Date: Fri, 30 Jan 2004 09:13:39 -0600
Subject: [R] How to plot a small figure in a bigger one???
Message-ID: <401D555F@webmail.uic.edu>

Hi,
I want to insert a small figure into a bigger plot. I saw people are doing 
this all the time, but I just could not figure out how to do it in R.
Thanks for your help!
Jinfeng Zhang



From andy_liaw at merck.com  Fri Jan 30 16:42:03 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 30 Jan 2004 10:42:03 -0500
Subject: [R] How to create own distance measure in cluster ?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76CF@usrymx25.merck.com>

The simplest way, if you have a function that returns the distance matrix,
is to use as.dist().  E.g.,

myDist <- function(...) {
    ## compute distance matrix dmat.
    ...
    return(as.dist(dmat))
}

I believe most clustering algorithms in R will accept dist objects.

If that doesn't do it, you can download the source for the `cluster' package
from CRAN.

Andy

> From: Ricardo Zorzetto Nicoliello Vencio
> 
> Hi everyone,
> 
> I want to create my own distance measure, other than 'euclidean' or
> 'manhatan', to use in cluster pckgs. To do this I think that I need to
> change dist(), in mva pckg, or daisy(), in cluster pckg. (or 
> is there a
> cleaver way ?)
> 
> 
> But this functions are in fact things like: .Fortran( 
> "daisy", ... ) or
> .C("dist",...).
> 
> I tried unsuccessfully to find source code of .Fortran or .C 
> function to
> lear how R calculate dissimilarity matrix and then modify 
> source to add my
> own distance metrix.
> 
> Could someone help me ? Help me to find .Fortran(...) source 
> or helpe me
> with better idea to implement my own distance metrix ?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From JGPorzak at loyaltymatrix.com  Fri Jan 30 02:14:23 2004
From: JGPorzak at loyaltymatrix.com (Jim Porzak)
Date: Thu, 29 Jan 2004 17:14:23 -0800
Subject: [R]Running R remotely in Windows Environment? Thanks!
In-Reply-To: <CFBD404F5E0C9547B4E10B7BDC3DFA2F04156035@usrymx18.merck.co
 m>
Message-ID: <5.1.1.6.0.20040129170617.02a59008@mail.loyaltymatrix.com>

Thanks to Prof Ripley, Arne, Andy & Bill for unambiguous suggestions!
Linux box is on order.
I'll take notes on our experience & post a follow-up
in a few weeks. May be useful to other folks stuck in the Windows world.

-Jim

At 06:24 AM 1/29/2004, Pikounis, Bill wrote:
>Jim,
>I would really like to reiterate Professor Ripley's and Arne Henningsen
>comments. The problem goes for any analytic software or system you might
>want to use, not just R. My impression is that at least for part of it, you
>want the individual users to use R as they would on their own desktops.  (If
>that is not the case, much of the rest of this note is pure FYI.) Even in
>its most advanced 2003 Server edition, Windows is simply not designed to be
>a multi-user system.  Sure, it can reliably host a web server that may need
>to run quick bursts of R batch-type jobs ("analytics") and return results to
>a client (e.g. web browser), but that does not sound like what you are
>looking for (at least in part). And beyond the technical limitations, use of
>Windows Terminal Server (Remote Desktop) / Citrix, etc. will cost much money
>and implementation hassle and probably even legal headaches.  We have had
>colleagues here at Merck (over my and Andy Liaw's disbelief) that have tried
>to shoehorn Windows this way, and even the speed of single, small jobs by 1
>logged-on took longer on the server than on their much less powerful
>laptops.
>
>A Linux solution is very flexible, in our experiences (we have Windows XP as
>corporate desktop standard).  As stated, with Samba, you can map directories
>that look like just another drive in Windows Explorer.  Printing is just as
>transparent in either direction.  VNC (Virtual Network Computing) is very,
>very nice to provide the individual user's Linux environment as just another
>window on their Windows desktop. With the free utility of "autocutsel",
>clipboards can be synchronized for ease of cutting and pasting. And KDE, one
>of several window manager analogues to Windows, is very sophisticated and
>shares a lot in common with the Windows GUI from a user operations
>standpoint. While it may sound like a hassle to get up and running now if
>your shop is currently "99% Windows", the benefit will absolutely be clear
>later.
>
>Hope that helps,
>Bill
>----------------------------------------
>Bill Pikounis, Ph.D.
>
>Biometrics Research Department
>Merck Research Laboratories
>PO Box 2000, MailDrop RY33-300
>126 E. Lincoln Avenue
>Rahway, New Jersey 07065-0900
>USA
>
>Phone: 732 594 3913
>Fax: 732 594 1565
>
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Arne Henningsen
> > Sent: Thursday, January 29, 2004 3:45 AM
> > To: Jim Porzak
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R]Running R remotely in Windows Environment?
> >
> >
> > Hi,
> >
> > I also suggest to use a Linux Server. You can work on this
> > machine via ssh
> > (e.g. with PuTTY) and transfer the input and output files
> > with scp or a samba
> > server (which is easy to install and very convenient to use
> > for windows
> > users).
> >
> > Arne
> >
> > On Thursday 29 January 2004 08:53, Prof Brian Ripley wrote:
> > > On Wed, 28 Jan 2004, Jim Porzak wrote:
> > > > We are considering setting up a fast, RAM loaded machine
> > as an "R-server"
> > > > to handle the big problems not suitable for individual
> > desktops and,
> > > > also, to process ad hoc analysis requests via our portal.
> > We are 99% a
> > > > Windows shop, so first choice is a windows server. We'll
> > use (D)COM for
> > > > the portal interface and understand that.
> > > >
> > > > What has me stumped is how to easily interface individual
> > analyst's
> > > > Windows desktops to the R-server. I haven't seen anything in the
> > > > archives, but I can't imagine this hasn't been done. What
> > am I missing?
> > >
> > > R is not designed to be client-server on Windows.  People I
> > know who do
> > > this use Windows Terminal Server or Citrix.
> > >
> > > I would question the value of this approach.  Unless you
> > propose to run
> > > 64-bit Windows, a `RAM loaded' machine isn't `loaded', and
> > R under Windows
> > > handles large amounts of memory much less effectively than
> > under Linux.
> > > 64-bit Windows is uncharted territory for R, whereas 64-bit
> > Unix/Linux is
> > > well trodden.
> >
> > --
> > Arne Henningsen
> > Department of Agricultural Economics
> > University of Kiel
> > Olshausenstr. 40
> > D-24098 Kiel (Germany)
> > Tel: +49-431-880 4445
> > Fax: +49-431-880 1397
> > ahenningsen at agric-econ.uni-kiel.de
> > http://www.uni-kiel.de/agrarpol/ahenningsen/
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments,...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From paulojus at est.ufpr.br  Fri Jan 30 18:06:05 2004
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Fri, 30 Jan 2004 15:06:05 -0200 (BRST)
Subject: [R] How to plot a small figure in a bigger one???
In-Reply-To: <401D555F@webmail.uic.edu>
References: <401D555F@webmail.uic.edu>
Message-ID: <Pine.LNX.4.58L0.0401301456010.3441@est.ufpr.br>

Hi Zhang

I've just done some "naive" things like that in geoR from which
you may borrow some ideas

Please have a look at examples in the documentation of the function
coods2coords() and data gambia.

Try:
data(gambia)
gambia.map()
gambia.map

You will need  the geoR under development version 1.4-4 from:
www.est.ufpr.br/geoR

Cheers
P.J.


On Fri, 30 Jan 2004, jzhang10 wrote:

> Hi,
> I want to insert a small figure into a bigger plot. I saw people are doing
> this all the time, but I just could not figure out how to do it in R.
> Thanks for your help!
> Jinfeng Zhang
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From maechler at stat.math.ethz.ch  Fri Jan 30 19:11:28 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 30 Jan 2004 19:11:28 +0100
Subject: [R] Doubt about pattern
In-Reply-To: <20040130135659.889D93960@mprdmxin.myway.com>
References: <20040130135659.889D93960@mprdmxin.myway.com>
Message-ID: <16410.40528.925661.245928@gargle.gargle.HOWL>

>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at myway.com>
>>>>>     on Fri, 30 Jan 2004 08:56:59 -0500 (EST) writes:

    Gabor> Your question has by now been answered but I thought
    Gabor> I would add that if you want to do it via file globbing on Windows
    Gabor> rather than regular expressions then this function would help:


    Gabor> list.files.glob <- function( spec ) {
    Gabor> # returns list of files or NULL if none: spec uses globbing and can
    Gabor> # use either forward or backward slashes. 
    Gabor> # e.g list.files.glob( "c:/a*.*" )
    Gabor> # e.g. list.files.glob( "c:/myfolder/my*.dat")
	     =====================
    Gabor> # only works on Windows
	     =====================
    Gabor> if ( substring(spec,2,2) != ":" ) spec <- paste( "C", spec, sep= ":" )
    Gabor> z <- system( paste("cmd /c attrib", spec), intern = T, invisible = T)
    Gabor> if ( !pmatch("File not found - ", z[1], nomatch = 0) )  substring(z,12)
    Gabor> }


    Gabor> For example:

    Gabor> list.files.glob( "*.sens" )

Since we are diverting, here is my 12 year old (back then, 
  using "unix(..)" and 'sed' inside Unix all for S-plus)
"solution" to this problem -- yes, the function _name_ is a misnomer --

which is platform independent

pat2grep <- function(pattern)
{
  ## Purpose: Change "ls" aka "wildcard" aka "globbing" _pattern_ to
  ## 	      Regular Expression (as in grep, perl, emacs, ...)
  ## -------------------------------------------------------------------------
  ## Author: Martin Maechler ETH Zurich, ~ 1991
  ##         New version using [g]sub() : 2004
    p <- gsub('\\.','\\\\.', paste('^', pattern, '$', sep=''))
    sub('\\.\\*\\$$','', gsub('\\?',  '.',  gsub('\\*',  '.*', p)))
}


and now you can use, e.g.

  list.files(pat2grep("*.R")) 

and get what you expect.
Beginners in regular expressions
now can also use

  pat2grep( <my favorite wildcard expression> )

and see the correct (I hope; the tests were not realy extended)
regular expression for this.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From deepayan at stat.wisc.edu  Fri Jan 30 19:38:17 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 30 Jan 2004 12:38:17 -0600
Subject: [R] lines in 3d-cloud plot (lattice)
In-Reply-To: <401A4A7F.1050301@unibas.ch>
References: <401A4A7F.1050301@unibas.ch>
Message-ID: <200401301238.17940.deepayan@stat.wisc.edu>

On Friday 30 January 2004 06:13, Pascal A. Niklaus wrote:
> Hi all,
>
> I'd like to plot a set of data (x,y,z) as 3D-cloud, and add several line
> plots to the same 3D graph:
>
> Two questions:
>
> 1) How do I connect points to get a line?
>
> > cloud(z~x*y,data=d,zlim=c(0,1))        # works
> > cloud(z~x*predict(l),data=d,zlim=c(0,1),type="l")   # type="l" doesn't
>
> Warning message:
> type = l not implemented, consider using 'panel.3d.cloud =
> panel.3dscatter.old' in: panel.3d.cloud(x = x, y = y, z = z, rot.mat =
> rot.mat, za = za,

Well, have you considered taking the hint and try

cloud(z~x*predict(l),data=d,zlim=c(0,1),type="l",
      panel.3d.cloud = panel.3dscatter.old)

?

> help.search("panel.3d.cloud") also didn't report any hits.

panel.3d.cloud is the name of an argument to the panel.cloud function. 
See ?panel.cloud for details. (Unfortunately, the docs are a bit outdated).


Briefly, panel.3dscatter.old is a very simple function, that calculates the 2D 
projections of the given 3D points and then calls panel.xyplot with those. 
Any 'type' argument which works with panel.xyplot would also work here, 
including 'p' and 'l'. But no consideration is made of the fact that these 
are 3D data. For instance, type = 'h' would not give you what you would 
expect.


panel.3dscatter (the newer version) is a bit more sophisticated. For type = 
'p', it draws the points in order of increasing depth, so that closer points 
overwrite distant ones. Unfortunately, a collection of line segments is not 
well ordered, and I haven't decided yet what to do in that case (which is why 
the older version is still retained).


> 2) How do I superimpose a second data set onto the same graph?
>
> (something equivalent to the sequence plot(), followed by points() or
> lines() in the base plotting functions)


I'm not sure what you mean. Trellis plots are not supposed to be used for two 
unrelated data sets, they are typically very much dependent on the structure 
of the data set. Maybe we could help if you give more details of what exactly 
you want to do, but before that you should read the ?panel.cloud help page 
carefully, since anything 'special' would almost invariably involve playing 
with things documented there.

Hth,

Deepayan



From cstrato at aon.at  Fri Jan 30 19:50:45 2004
From: cstrato at aon.at (cstrato)
Date: Fri, 30 Jan 2004 19:50:45 +0100
Subject: [R] Robust nonlinear regression
In-Reply-To: <3FC51AB5.6020806@aon.at>
References: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>
	<3FC51AB5.6020806@aon.at>
Message-ID: <401AA785.5010609@aon.at>

Dear R experts

This is a general question:
Does R have functions for nonlinear robust regression,
analogous to e.g. LTS?

Searching google I have found
1, an abstract to generalize LTS for nonlinear regression
models, see: http://smealsearch.psu.edu/1509.html
2, an AD-model builder, see: http://otter-rsch.com/admodel/cc1.html
but no mention of R/S

Thank you in advance
Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._



From tblackw at umich.edu  Fri Jan 30 19:55:36 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Fri, 30 Jan 2004 13:55:36 -0500 (EST)
Subject: [R] lines in 3d-cloud plot (lattice)
In-Reply-To: <200401301238.17940.deepayan@stat.wisc.edu>
References: <401A4A7F.1050301@unibas.ch>
	<200401301238.17940.deepayan@stat.wisc.edu>
Message-ID: <Pine.SOL.4.58.0401301353340.2982@tetris.gpcc.itd.umich.edu>

Pascal  -

Getting away from Trellis graphics, you might consider using
persp() with regular graphics.  Look at example # 2 under
help("persp").

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 30 Jan 2004, Deepayan Sarkar wrote:

> On Friday 30 January 2004 06:13, Pascal A. Niklaus wrote:
> > Hi all,
> >
> > I'd like to plot a set of data (x,y,z) as 3D-cloud, and add several line
> > plots to the same 3D graph:
> >
> > Two questions:
> >
> > 1) How do I connect points to get a line?
> >
> > > cloud(z~x*y,data=d,zlim=c(0,1))        # works
> > > cloud(z~x*predict(l),data=d,zlim=c(0,1),type="l")   # type="l" doesn't
> >
> > Warning message:
> > type = l not implemented, consider using 'panel.3d.cloud =
> > panel.3dscatter.old' in: panel.3d.cloud(x = x, y = y, z = z, rot.mat =
> > rot.mat, za = za,
>
> Well, have you considered taking the hint and try
>
> cloud(z~x*predict(l),data=d,zlim=c(0,1),type="l",
>       panel.3d.cloud = panel.3dscatter.old)
>
> ?
>
> > help.search("panel.3d.cloud") also didn't report any hits.
>
> panel.3d.cloud is the name of an argument to the panel.cloud function.
> See ?panel.cloud for details. (Unfortunately, the docs are a bit outdated).
>
>
> Briefly, panel.3dscatter.old is a very simple function, that calculates the 2D
> projections of the given 3D points and then calls panel.xyplot with those.
> Any 'type' argument which works with panel.xyplot would also work here,
> including 'p' and 'l'. But no consideration is made of the fact that these
> are 3D data. For instance, type = 'h' would not give you what you would
> expect.
>
>
> panel.3dscatter (the newer version) is a bit more sophisticated. For type =
> 'p', it draws the points in order of increasing depth, so that closer points
> overwrite distant ones. Unfortunately, a collection of line segments is not
> well ordered, and I haven't decided yet what to do in that case (which is why
> the older version is still retained).
>
>
> > 2) How do I superimpose a second data set onto the same graph?
> >
> > (something equivalent to the sequence plot(), followed by points() or
> > lines() in the base plotting functions)
>
>
> I'm not sure what you mean. Trellis plots are not supposed to be used for two
> unrelated data sets, they are typically very much dependent on the structure
> of the data set. Maybe we could help if you give more details of what exactly
> you want to do, but before that you should read the ?panel.cloud help page
> carefully, since anything 'special' would almost invariably involve playing
> with things documented there.
>
> Hth,
>
> Deepayan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From yunfang at yahoo-inc.com  Fri Jan 30 19:59:24 2004
From: yunfang at yahoo-inc.com (Yun-Fang Juan)
Date: Fri, 30 Jan 2004 10:59:24 -0800
Subject: [R] memory problem for R 
References: <Pine.LNX.4.44.0401300830130.974-100000@gannet.stats>
Message-ID: <009201c3e763$2d91bc10$90ea7ecf@YUNFANG2>

Pleaase see the comments below.
> > Here is the exact error I got
> > ----------------------
> > Read 73 items
> > Error: cannot allocate vector of size 1953 Kb
> > Execution halted
> > -----------------------
> > I am running R on Freebsd 4.3
> > with double CPU and 2 GB memory
> > Is that sufficient?
>
> Clearly not.  What is the structure of your `attributes'?  As Andy Liaw
> said, the design matrix may be bigger than that if there are factors
> involved.  (And you need several copies of the design matrix.)
>
> I would try a 10% sample of the rows to get a measure of what will fit
> into your memory.  I have never seen a regression problem for which 600k
> cases were needed, and would be interested to know the context.  (It is
> hard to imagine that the cases are from a single homogeneous population
> and that a linear model fits so well that the random error is not
> dominated by systematic error.)
I tried 10% sample and it turned out the matrix became singular after I did
that.
Ther reason is some of the attributes only have zero values most of the
time.
The data i am using is web log data and after some transformation, they are
all numeric.
Can we specify some parameters in read.table so that the program will treat
all the vars as numeric
(with this context, hopefully that will reduce the memory consumption)  ?

thanks a lot,

Yun-Fang
>
> >
> > Yun-Fang
> > ----- Original Message -----
> > From: "Yun-Fang Juan" <yunfang at yahoo-inc.com>
> > To: <r-help at stat.math.ethz.ch>
> > Sent: Thursday, January 29, 2004 7:03 PM
> > Subject: [R] memory problem for R
> >
> >
> > > Hi,
> > > I try to use lm to fit a linear model with 600k rows and 70
attributes.
> > > But I can't even load the data into the R environment.
> > > The error message says the vector memory is used up.
> > >
> > > Is there anyone having experience with large datasets in R? (I bet)
> > >
> > > Please advise.
> > >
> > >
> > > thanks,
> > >
> > >
> > > Yun-Fang
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From jmc at lucent.com  Fri Jan 30 20:05:45 2004
From: jmc at lucent.com (John Chambers)
Date: Fri, 30 Jan 2004 14:05:45 -0500
Subject: [R] Object validation and formal classes
References: <40197B6B.23259.1B24BAFF@localhost>;
	from Torsten.Steuernagel@gmx.de on Thu, Jan 29, 2004 at
	09:30:19PM	+0100 <401A59C6.2728.1E894EC8@localhost>
Message-ID: <401AAB09.2070201@lucent.com>

It was never the intention that validity checking happen automatically 
on _every_ assignment of an object from the class--since those 
assignments take place frequently during evaluation of functions, the 
overhead would be unacceptable.  And as Robert points out, one needs to 
postpone validity checking until a set of mutually dependent changes is 
finished.

The "Programming with Data" description says that validity checking 
takes place on "permanent assignment".  But this was not written with R 
in mind, and the idea of permanent assignment is ambiguous in R.  It 
could mean all assignments into the Global environment, or it could mean 
on serializing (saving the workspace, e.g.).  If we agree on a useful 
interpretation, automatic validity checking might be reasonable in that 
sense in the future.


Torsten Steuernagel wrote:

> On 29 Jan 2004 at 20:04, Robert Gentleman wrote:
> 
> 
>>  There are some efficiency issues that prevent constant checking (at
>>  least at the present time). There are also some other issues that
>>  need to be adequately addressed too. For example, suppose I had an
>>  object with two slots
>>   a - a character string 
>>   b - the number of characters
>>
> 
> Yes, efficiency was also a concern I had with my original understanding 
> of what the validation function is supposed to do. Reading the docs I 
> got the impression that 
> 
> 1) during an assignment the validation function will be called with a 
> copy of the object that already has the new value assigned 
> 
> 2) if it returns TRUE that copy is returned as the result of the assigment 
> 
> 3) otherwise, an error is raised.
> 
> That would be pretty inefficient for large objects. What does actually 
> happen when I call "slot<-" ? I suppose that this always operates on the 
> object in sys.parent() of "slot<-" and never creates a copy of the 
> specified object.
>  
> 
>>  and I set my validity checker to make sure that the length of the
>>  string is the number in b. Now that basically means that I can never
>>  change the string (except to other strings of the same length) if
>>  validity checking happened after every change. I somehow need
>>  changing both a and b to be instantaneous (which they currently are
>>  not). We have not really gone far enough down that path yet to know
>>  what the right thing is, but we  are working on it. So for now
>>  validity checking occurs at a   few specific points and if/when you
>>  ask for it. 
>>
> 
> What about access control ? The docs state it isn't implemented yet. If 
> there was something similar to C++ one could set critical slots to 
> "private" and only allow access and assignment via (replacement) 
> methods. At first sight, this seems feasible and shouldn't cost much 
> performance.
> 
> Another approach might be an (optional) validation function for each 
> individual slot or for groups of slots that doesn't need to validate the 
> whole object but only changes that may occur in conjunction with a 
> single slot or group of slots. Of course, efficiency issues are more likely 
> to occur in this scenario. The "@<-" operator seems to call "slot<-" by 
> default, maybe I can overload "slot<-" for my class and implement this 
> kind of validation on my own ? I guess some tricks will be necessary 
> here to prevent that "slot<-" is called recursively if the validation 
> function for one slot attempts to make an assignemt to another slot.
> 
> So if I don't find a feasible solution in the meantime, the best way 
> would be writing wrappers for those slots that need validation and tell 
> the users to use those instead of changing the object directly ?
> 
> Thanks again,
> 
> Torsten
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From FWS4 at CDRH.FDA.GOV  Fri Jan 30 20:08:26 2004
From: FWS4 at CDRH.FDA.GOV (Samuelson, Frank*)
Date: Fri, 30 Jan 2004 14:08:26 -0500
Subject: [R] looping over factors
Message-ID: <644D9337A02FC24689647BF9E48EC39E08ABB742@drm556>

How does one loop over factors?  Perhaps this is a newbie question.
I tried:

> b
[1] caseX caseY caseZ
Levels: caseX caseY caseZ
> length(b)
[1] 3
>
> for (i in b) {
+   print (b == i) ;
+   print (i);
+ }
[1] FALSE FALSE FALSE
[1] 1
[1] FALSE FALSE FALSE
[1] 2
[1] FALSE FALSE FALSE
[1] 3
>

But that strangely doesn't work.  I must protest
the implications of the above.  i , as an iterator,
is supposed take on values from b, but never is it equivalent
to any of the values in b.  The above works correctly for 
numbers or arrays of character strings.   What's up with factors?

Thanks for any help.

-Frank



From Carlisle.Thacker at noaa.gov  Fri Jan 30 20:11:37 2004
From: Carlisle.Thacker at noaa.gov (W. C. Thacker)
Date: Fri, 30 Jan 2004 14:11:37 -0500
Subject: [R] coupled statistical models
Message-ID: <401AAC69.466F941@noaa.gov>

Can someone point me to the appropriate functions for 
fitting multiple statistical models that are coupled 
to each other.

The data are measurements of salinity s and temperature t 
at stations id and pressures at p as well as surface elevations h 
at stations id.  The problem is, for any new station, to estimate 
s at all p, given t at all p and given h.

If h is ignored, the for each p, there would be an 
independent model like rlm(s~t+I(t^2)).  No problem.  

(I have been using a loop, but I think they can be computed 
simultaneously using lm(s~as.factor(p)/(t+I(t^2))-1).
However, rlm(s~as.factor(p)/(t+I(t^2))-1) does not converge!)

The h data couple the models.  Surface elevation reflects the
water's specific volume at each depth (pressure).  The volume vp 
(p to indicate pressure) depends on s,t, and p, and h is essentially
a sum over the volume at each p.  When the individual models are
computed, coefficients should be chosen so that this is satisfied.
How to do this in R?

Without the coupling the least-squares formulation would seek 
coefficients a_p and b_p to minimize:
   sum_p(sum_p((s_id,p - a_p t_id,p + b_k)^2)).
Minimization at each p is independent.
With coupling, there would be an additional term:
   sum_id((sum_p(vp)-h_id)^2)
where vp is a function of a_p t_id,p + b_k and of t_id.

The functions for vp are nonlinear, but if necessary with some work 
it should be possible to get a linear function that is good enough.

Also, not all stations have values at all pressures.

Thanks,

Carlisle

-- 

William Carlisle Thacker                            
                                                    
Atlantic Oceanographic and Meteorological Laboratory
4301 Rickenbacker Causeway, Miami, Florida 33149 USA
Office: (305) 361-4323           Fax: (305) 361-4392

"Too many have dispensed with generosity 
     in order to practice charity."     Albert Camus



From spencer.graves at pdf.com  Fri Jan 30 20:36:50 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 30 Jan 2004 11:36:50 -0800
Subject: [R] memory problem for R
In-Reply-To: <009201c3e763$2d91bc10$90ea7ecf@YUNFANG2>
References: <Pine.LNX.4.44.0401300830130.974-100000@gannet.stats>
	<009201c3e763$2d91bc10$90ea7ecf@YUNFANG2>
Message-ID: <401AB252.2030608@pdf.com>

      Was your 10% sample contiguous or randomly selected from the 
entire file?  If contiguous, you might get something from, say, 
processing the file in 100 contiguous blocks, computing something like 
the mean of each 1% block (or summarizing in some other way within 
blocks), then combining the summaries and do regression on block 
summaries. 

      If it was an honest random sample (e.g., selecting approximately 
10% from each 10%), then the block averaging won't work:  You have an 
inherent singularity in the structure of the data that will likely not 
permit you to estimate everything you want to estimate.  You need to 
understand that singularity / lack of estimability and decide what to do 
about it. 

      In either case, "lm(..., singular.ok=T)" will at least give you an 
answer even when the model is not fully estimable. 

      hope this helps. 
      spencer graves

Yun-Fang Juan wrote:

>Pleaase see the comments below.
>  
>
>>>Here is the exact error I got
>>>----------------------
>>>Read 73 items
>>>Error: cannot allocate vector of size 1953 Kb
>>>Execution halted
>>>-----------------------
>>>I am running R on Freebsd 4.3
>>>with double CPU and 2 GB memory
>>>Is that sufficient?
>>>      
>>>
>>Clearly not.  What is the structure of your `attributes'?  As Andy Liaw
>>said, the design matrix may be bigger than that if there are factors
>>involved.  (And you need several copies of the design matrix.)
>>
>>I would try a 10% sample of the rows to get a measure of what will fit
>>into your memory.  I have never seen a regression problem for which 600k
>>cases were needed, and would be interested to know the context.  (It is
>>hard to imagine that the cases are from a single homogeneous population
>>and that a linear model fits so well that the random error is not
>>dominated by systematic error.)
>>    
>>
>I tried 10% sample and it turned out the matrix became singular after I did
>that.
>Ther reason is some of the attributes only have zero values most of the
>time.
>The data i am using is web log data and after some transformation, they are
>all numeric.
>Can we specify some parameters in read.table so that the program will treat
>all the vars as numeric
>(with this context, hopefully that will reduce the memory consumption)  ?
>
>thanks a lot,
>
>Yun-Fang
>  
>
>>>Yun-Fang
>>>----- Original Message -----
>>>From: "Yun-Fang Juan" <yunfang at yahoo-inc.com>
>>>To: <r-help at stat.math.ethz.ch>
>>>Sent: Thursday, January 29, 2004 7:03 PM
>>>Subject: [R] memory problem for R
>>>
>>>
>>>      
>>>
>>>>Hi,
>>>>I try to use lm to fit a linear model with 600k rows and 70
>>>>        
>>>>
>attributes.
>  
>
>>>>But I can't even load the data into the R environment.
>>>>The error message says the vector memory is used up.
>>>>
>>>>Is there anyone having experience with large datasets in R? (I bet)
>>>>
>>>>Please advise.
>>>>
>>>>
>>>>thanks,
>>>>
>>>>
>>>>Yun-Fang
>>>>
>>>>[[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide!
>>>>        
>>>>
>>>http://www.R-project.org/posting-guide.html
>>>      
>>>
>>>>        
>>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>>      
>>>
>http://www.R-project.org/posting-guide.html
>  
>
>>>      
>>>
>>--
>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>1 South Parks Road,                     +44 1865 272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From andy_liaw at merck.com  Fri Jan 30 20:44:48 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 30 Jan 2004 14:44:48 -0500
Subject: [R] memory problem for R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76D6@usrymx25.merck.com>

You still have not read the posting guide, have you?

See more below.

> From: Yun-Fang Juan

[...]

> I tried 10% sample and it turned out the matrix became 
> singular after I did that.
> Ther reason is some of the attributes only have zero values 
> most of the time.
> The data i am using is web log data and after some 
> transformation, they are all numeric.
> Can we specify some parameters in read.table so that the 
> program will treat all the vars as numeric
> (with this context, hopefully that will reduce the memory 
> consumption)  ?

and you clearly have not read my (private) reply, either, in which I told
you *exactly* how to do that, via the colClasses argument to read.table().

Please take the help given to you seriously.  If you want attention, you
have to pay attention.

Andy
 
> thanks a lot,
> 
> Yun-Fang


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From rxg218 at psu.edu  Fri Jan 30 21:29:49 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Fri, 30 Jan 2004 15:29:49 -0500
Subject: [R] a problem loading package 'subselect'
Message-ID: <1075494588.6114.16.camel@ra.chem.psu.edu>

Hi,
  I downloaded the subselect package from CRAN and installed it in the
system wide R library path. During installation the package compiled the
fortran sources with no errors. 

However, when loading the library gives me an error:

> library(subselect)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"/usr/lib/R/library/subselect/libs/subselect.so":
  /usr/lib/R/library/subselect/libs/subselect.so: undefined symbol:
f_iob
Error in library(subselect) : .First.lib failed

I would had expected that if it could'nt find a symbol, that would have
shown up during compilation. But there were no compile time errors. I
also tried R CMD check on the package directory and compilation occurs
with no errors but I get the errors below:

* checking S3 generic/method consistency ... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :
        .First.lib failed
Execution halted

(And more such errors)

I have contacted the author of the package and he sent me few postings
regarding the f_iob symbol and it appears to be a problem resulting from
a LAPACK compiled with the Intel fortran compiler (ifc). However in this
case, ifc is not installed on my system and during compilation it uses
the Rlapack library.

I installed R from rpm's and am running on Fedora Core 1. The output of
R.version is:

platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    8.1
year     2003
month    11
day      21
language R

It appears I am missing some library that contains f_iob (though why the
error did'nt show up at compile time I dont know).

Has anybody faced this problem or have any suggestions as to how to fix
it?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
All syllogisms have three parts, therefore this is not a syllogism.



From fjmolina at ams.ucsc.edu  Fri Jan 30 21:58:37 2004
From: fjmolina at ams.ucsc.edu (Francisco J Molina)
Date: Fri, 30 Jan 2004 12:58:37 -0800
Subject: [R] Detect the presence of an object
Message-ID: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>


Is there a  function like "is.there" such that 

is.there ( a ) returns TRUE is object 'a' is in the current environment and
FALSE otherwise?

Thank you.
Francisco J. Molina



From pem at theriver.com  Fri Jan 30 21:55:19 2004
From: pem at theriver.com (Patrick E. McKnight)
Date: Fri, 30 Jan 2004 13:55:19 -0700
Subject: [R] Measures of central tendency - mode
Message-ID: <20040130135519.507b86ae@copernicus>

Greetings,

This seems too rudimentary to ask but for the life of me I cannot locate a readily easy method to compute the univariate mode.  I know "mode" is not correct and "table" provides a reasonable count but I figured there would be an easy way to extract the value from the table after I do something like:

max(table(mydadat$myvar))

unfortunately it only returns the max count and not the value that is observed most.  Would some kind soul help me out with this seemingly trivial problem?

Thanks in advance.

Cheers,

Patrick



From umarckma at biologie.uni-erlangen.de  Fri Jan 30 22:11:29 2004
From: umarckma at biologie.uni-erlangen.de (Ulrich Marckmann)
Date: Fri, 30 Jan 2004 22:11:29 +0100
Subject: [R] Using fda - bruto
Message-ID: <401AC881.3040409@biologie.uni-erlangen.de>

Dear All,

I would like to use the "fda"-function in combination with 
"method=bruto" in the mda library. But all my attempts failed. I tried 
several syntaxes but only got nonsense or a computer-crash. So I don't 
know, if I'm totally on the wrong trip or if it's bug. Can anyone give 
me a working syntax example for a simple data-package like "iris"?

Thanks in advance for any hint!

ciao,

Ulrich Marckmann



From pauljohn at ku.edu  Fri Jan 30 22:04:07 2004
From: pauljohn at ku.edu (Paul Johnson)
Date: Fri, 30 Jan 2004 15:04:07 -0600
Subject: [R] Trouble plotting  with factor
Message-ID: <401AC6C7.3090909@ku.edu>

With R 1.8.1 running in Fedora Core 1 Linux, I am having some trouble 
recoding and ploting some factor variables. 

First, can I give you some example data?
Here is a column of names for age groups:

agegroups <- c(   "15-19", "20-24", "25-29","30-34", "35-39", 
"40-44","45-49","50-54","55-59","60-64",  "65-69", "70-74", "75-79",  
"80-84", "OVER")

Here is an index for driver's license ownership in each age group:

  fracld            
0.4914204
0.9752746
1.0864465
1.0555984
1.0631969
1.0738725
1.0971969
1.0657212
1.0217373
0.9761226
0.9043233
0.9045744
0.8573243
0.7889182
0.5217992

I want to take several similar columns of numbers and put them into a 
single line plot, one line for each column. 

I can get a graph with the inside part that looks roughly like I want if 
I just do:

plot(fracld,type="l")

The horizontal axis, of course, is just the sequence from 1:15, not the 
age labels. That's no good.

But, If I try

plot(as.factor(agegroup), fracld, type="l")

the plot does not have the line I want, but rather only flat "steps" 
showing the values.  It does  have a nice looking horizontal axis, 
though, showing the age groups.

So I think to myself "I'll outsmart them by adding the lines after 
creating the plot", but if I do this

plot(agegroup,fracld,type="n")

The step markers still appear. 

So if I want the tick marks and value lables on the horzontal axis, 
there is apparently  no way to plot lines?

What to do?



From DivineSAAM at aol.com  Fri Jan 30 22:04:52 2004
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Fri, 30 Jan 2004 16:04:52 -0500
Subject: [R] MATLAB to R
Message-ID: <4368A860.211D5ACA.0B088159@aol.com>

Ladies and Gentlemen,

In MATLAB, I can write:

for J=1:M
Y(J+1)=Y(J)+ h * feval(f,T(J),Y(J));
...

In R, I can write above as:

for (J in 2:M)
{
 y = y + h * f(t,y)
...
}
----
In MATLAB, I can write:

for J=1:M
k1 = feval(f,T(J),Y(J));
k2 = feval(f,T(J+1),Y(J)+ h * k1

How do I write k2 in R?
k1 = f(t,y)
k2 = ?

Thanks,
/oal



From mmiller3 at iupui.edu  Fri Jan 30 22:34:00 2004
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Fri, 30 Jan 2004 16:34:00 -0500
Subject: [R] looping over factors
In-Reply-To: <644D9337A02FC24689647BF9E48EC39E08ABB742@drm556> (Frank
	Samuelson's message of "Fri, 30 Jan 2004 14:08:26 -0500")
References: <644D9337A02FC24689647BF9E48EC39E08ABB742@drm556>
Message-ID: <87vfmt3yuv.fsf@lumen.indyrad.iupui.edu>

>>>>> "Samuelson," == Samuelson, Frank* <Samuelson> writes:

    > How does one loop over factors? 

You can loop on the levels of your factor:

> b<-factor(c('caseX','caseY', 'caseZ', 'caseX'))
> b
[1] caseX caseY caseZ caseX
Levels: caseX caseY caseZ
> for ( i in levels(b) ) { print(i) }
[1] "caseX"
[1] "caseY"
[1] "caseZ"
> 


Mike



From Torsten.Steuernagel at gmx.de  Fri Jan 30 22:41:36 2004
From: Torsten.Steuernagel at gmx.de (Torsten Steuernagel)
Date: Fri, 30 Jan 2004 22:41:36 +0100
Subject: [R] Object validation and formal classes
In-Reply-To: <401AAB09.2070201@lucent.com>
Message-ID: <401ADDA0.28906.208C5B8A@localhost>

On 30 Jan 2004 at 14:05, John Chambers wrote:

> It was never the intention that validity checking happen automatically
> on _every_ assignment of an object from the class--since those
> assignments take place frequently during evaluation of functions, the
> overhead would be unacceptable.  And as Robert points out, one needs
> to postpone validity checking until a set of mutually dependent
> changes is finished.

Thank's for this clarification. I'll try to find another solution. Could you 
comment on the "access" argument in "setClass()" ? From the 
"setClass()" reference I can only guess what that might be:

"access: Access list for the class.  Saved in the definition, but not
          currently used."

Is this intended to implement an access control mechanism similar to 
C++ like I stated in my previous message ? If that's the case I'll simply 
provide access/assign methods for the slots that need validation. Once 
access control is available I could hide those slots.

> The "Programming with Data" description says that validity checking
> takes place on "permanent assignment".  But this was not written with
> R in mind, and the idea of permanent assignment is ambiguous in R.  It
> could mean all assignments into the Global environment, or it could
> mean on serializing (saving the workspace, e.g.).  If we agree on a
> useful interpretation, automatic validity checking might be reasonable
> in that sense in the future.

I must admit that I didn't look into "Programming with Data", which I 
don't have available right now, but I believe "S Programming" says the 
same. I think the example code in the reference for "setValidity()" in R 
is misleading here, especially the last four lines:

## Now we do something bad
t1 at x <- 1:20
## This should generate an error
## Not run: try(validObject(t1))

- Torsten



From jgentry at jimmy.harvard.edu  Fri Jan 30 22:43:20 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Fri, 30 Jan 2004 16:43:20 -0500 (EST)
Subject: [R] Detect the presence of an object
In-Reply-To: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
Message-ID: <Pine.SOL.4.20.0401301642480.4132-100000@santiam.dfci.harvard.edu>

> Is there a  function like "is.there" such that 
> is.there ( a ) returns TRUE is object 'a' is in the current environment and
> FALSE otherwise?

exists()



From MSchwartz at medanalytics.com  Fri Jan 30 22:42:19 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 30 Jan 2004 15:42:19 -0600
Subject: [R] Detect the presence of an object
In-Reply-To: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
References: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
Message-ID: <1075498939.31290.499.camel@localhost.localdomain>

On Fri, 2004-01-30 at 14:58, Francisco J Molina wrote:
> Is there a  function like "is.there" such that 
> 
> is.there ( a ) returns TRUE is object 'a' is in the current environment and
> FALSE otherwise?
> 
> Thank you.
> Francisco J. Molina


See ?exists

This requires that the object of interest is quoted:

> a <- "I am here"
> exists(a)
[1] FALSE
> exists("a")
[1] TRUE

There are other arguments to the function to indicate where to search,
etc.

HTH,

Marc Schwartz



From paulojus at est.ufpr.br  Fri Jan 30 22:48:30 2004
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Fri, 30 Jan 2004 19:48:30 -0200 (BRST)
Subject: [R] Detect the presence of an object
In-Reply-To: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
References: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
Message-ID: <Pine.LNX.4.58L0.0401301948200.22712@est.ufpr.br>


try the function exists()

On Fri, 30 Jan 2004, Francisco J Molina wrote:

>
> Is there a  function like "is.there" such that
>
> is.there ( a ) returns TRUE is object 'a' is in the current environment and
> FALSE otherwise?
>
> Thank you.
> Francisco J. Molina
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From spencer.graves at pdf.com  Fri Jan 30 22:50:21 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 30 Jan 2004 13:50:21 -0800
Subject: [R] Detect the presence of an object
In-Reply-To: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
References: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
Message-ID: <401AD19D.8090107@pdf.com>

      Have you considered "exists" or "missing"? 

      hope this helps.  spencer graves

Francisco J Molina wrote:

>Is there a  function like "is.there" such that 
>
>is.there ( a ) returns TRUE is object 'a' is in the current environment and
>FALSE otherwise?
>
>Thank you.
>Francisco J. Molina
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From andy_liaw at merck.com  Fri Jan 30 22:54:47 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 30 Jan 2004 16:54:47 -0500
Subject: [R] looping over factors
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76DA@usrymx25.merck.com>

The problem is this: 

> b <- factor(letters[1:3])
> str(b[1])
 Factor w/ 3 levels "a","b","c": 1
> for (i in b) str(i)
 int 1
 int 2
 int 3

So seems like the for loop had drop the factor attribute for `i'.  This
doesn't happen when one simply subset `b':

> for (i in b) str(b[i])
 Factor w/ 3 levels "a","b","c": 1
 Factor w/ 3 levels "a","b","c": 2
 Factor w/ 3 levels "a","b","c": 3

Andy

> From: Samuelson, Frank*
> 
> How does one loop over factors?  Perhaps this is a newbie question.
> I tried:
> 
> > b
> [1] caseX caseY caseZ
> Levels: caseX caseY caseZ
> > length(b)
> [1] 3
> >
> > for (i in b) {
> +   print (b == i) ;
> +   print (i);
> + }
> [1] FALSE FALSE FALSE
> [1] 1
> [1] FALSE FALSE FALSE
> [1] 2
> [1] FALSE FALSE FALSE
> [1] 3
> >
> 
> But that strangely doesn't work.  I must protest
> the implications of the above.  i , as an iterator,
> is supposed take on values from b, but never is it equivalent
> to any of the values in b.  The above works correctly for 
> numbers or arrays of character strings.   What's up with factors?
> 
> Thanks for any help.
> 
> -Frank
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ccleland at optonline.net  Fri Jan 30 22:56:28 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 30 Jan 2004 16:56:28 -0500
Subject: [R] Detect the presence of an object
In-Reply-To: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
References: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
Message-ID: <401AD30C.2020501@optonline.net>

Francisco J Molina wrote:
> Is there a  function like "is.there" such that 
> 
> is.there ( a ) returns TRUE is object 'a' is in the current environment and
> FALSE otherwise?

?exists

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From Torsten.Steuernagel at gmx.de  Fri Jan 30 22:57:57 2004
From: Torsten.Steuernagel at gmx.de (Torsten Steuernagel)
Date: Fri, 30 Jan 2004 22:57:57 +0100
Subject: [R] Detect the presence of an object
In-Reply-To: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
Message-ID: <401AE175.21770.209B534C@localhost>

On 30 Jan 2004 at 12:58, Francisco J Molina wrote:

> 
> Is there a  function like "is.there" such that 
> 
> is.there ( a ) returns TRUE is object 'a' is in the current
> environment and FALSE otherwise?

Have you tried exists("a", inherits=FALSE) ?

- Torsten



From pem at theriver.com  Fri Jan 30 23:11:00 2004
From: pem at theriver.com (Patrick E. McKnight)
Date: Fri, 30 Jan 2004 15:11:00 -0700
Subject: [R] Measures of central tendency - mode
In-Reply-To: <Pine.LNX.4.33.0401301646570.353-100000@penguin.rand.org>
References: <20040130135519.507b86ae@copernicus>
	<Pine.LNX.4.33.0401301646570.353-100000@penguin.rand.org>
Message-ID: <20040130151100.06b559ff@copernicus>

Thanks to Andy Liaw and J.R. Lockwood for your suggestions.  The which.max() worked great along with the rownames.  The complete solution for me was:

a <- table(varname)
> my.mode <- rownames(a)[which.max(a)]
> my.mode
[1] "1"

Amazing how a simple concept such as mode can present problems for us.  Thanks again.

To reply to Spencer Graves' question, I didn't find the disucssion via search.  I guess I might have overlooked the thread if it were titled kernel density since that seemed far too technical for this basic topic.  Sorry if I cluttered up the list though.

Cheers,

Patrick


On Fri, 30 Jan 2004 16:47:54 -0500 (EST)
"J.R. Lockwood" <lockwood at rand.org> wrote:

> it is an annoyance that table() provides the values being tables as
> the rownames of the resultant vector.  you can do something like:
> 
> a<-table(x)
> rownames(a)[which.max(a)]
> 
> On Fri, 30 Jan 2004, Patrick E. McKnight wrote:
> 
> > Date: Fri, 30 Jan 2004 13:55:19 -0700
> > From: Patrick E. McKnight <pem at theriver.com>
> > To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
> > Subject: [R] Measures of central tendency - mode
> > 
> > Greetings,
> > 
> > This seems too rudimentary to ask but for the life of me I cannot locate a readily easy method to compute the univariate mode.  I know "mode" is not correct and "table" provides a reasonable count but I figured there would be an easy way to extract the value from the table after I do something like:
> > 
> > max(table(mydadat$myvar))
> > 
> > unfortunately it only returns the max count and not the value that is observed most.  Would some kind soul help me out with this seemingly trivial problem?
> > 
> > Thanks in advance.
> > 
> > Cheers,
> > 
> > Patrick
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
> 
> J.R. Lockwood
> 412-683-2300 x4941
> lockwood at rand.org
> http://www.rand.org/methodology/stat/members/lockwood/
>



From rbaer at atsu.edu  Fri Jan 30 23:21:10 2004
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Fri, 30 Jan 2004 16:21:10 -0600
Subject: [R] looping over factors
References: <644D9337A02FC24689647BF9E48EC39E08ABB742@drm556>
Message-ID: <010701c3e77f$5cfcf390$2e80010a@BigBaer>

> But that strangely doesn't work.  I must protest
> the implications of the above.  i , as an iterator,
> is supposed take on values from b, but never is it equivalent
> to any of the values in b.

It looks to me like your problem is that your b is a factor, try coercing
it"

b=c("CaseX","CaseY","CaseZ")
b=as.factor(b)
for (i in as.numeric(b)) {print(as.numeric(b)==i);print(i);print(b);}

Rob Baer



From spencer.graves at pdf.com  Fri Jan 30 23:56:42 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 30 Jan 2004 14:56:42 -0800
Subject: [R] Measures of central tendency - mode
In-Reply-To: <20040130151100.06b559ff@copernicus>
References: <20040130135519.507b86ae@copernicus>	<Pine.LNX.4.33.0401301646570.353-100000@penguin.rand.org>
	<20040130151100.06b559ff@copernicus>
Message-ID: <401AE12A.4000307@pdf.com>

      Evidently, I didn't read your question carefully enough.  If you 
want the mode of continuous data, that is not well defined, though there 
are devices to estimate such assuming, e.g., a specific distribution or 
a general unimodal distribution or ... .  This was discussed last Dec. 
12-13  by Ted Harding, Brian Ripley and others.  If you are interested, 
you can go www.r-project.org -> search -> "R site search" -> "harding 
mode".  When I did this just now, the first hit was an email on how to 
find the mode using a kernel density estimator.  Clicking "next in 
thread" a couple of times led me to a comment by Brian Ripley with a 
pointer to a document discussing this. 

      ... in case you are interested in more than what you already have. 

      spencer graves

Patrick E. McKnight wrote:

>Thanks to Andy Liaw and J.R. Lockwood for your suggestions.  The which.max() worked great along with the rownames.  The complete solution for me was:
>
>a <- table(varname)
>  
>
>>my.mode <- rownames(a)[which.max(a)]
>>my.mode
>>    
>>
>[1] "1"
>
>Amazing how a simple concept such as mode can present problems for us.  Thanks again.
>
>To reply to Spencer Graves' question, I didn't find the disucssion via search.  I guess I might have overlooked the thread if it were titled kernel density since that seemed far too technical for this basic topic.  Sorry if I cluttered up the list though.
>
>Cheers,
>
>Patrick
>
>
>On Fri, 30 Jan 2004 16:47:54 -0500 (EST)
>"J.R. Lockwood" <lockwood at rand.org> wrote:
>
>  
>
>>it is an annoyance that table() provides the values being tables as
>>the rownames of the resultant vector.  you can do something like:
>>
>>a<-table(x)
>>rownames(a)[which.max(a)]
>>
>>On Fri, 30 Jan 2004, Patrick E. McKnight wrote:
>>
>>    
>>
>>>Date: Fri, 30 Jan 2004 13:55:19 -0700
>>>From: Patrick E. McKnight <pem at theriver.com>
>>>To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
>>>Subject: [R] Measures of central tendency - mode
>>>
>>>Greetings,
>>>
>>>This seems too rudimentary to ask but for the life of me I cannot locate a readily easy method to compute the univariate mode.  I know "mode" is not correct and "table" provides a reasonable count but I figured there would be an easy way to extract the value from the table after I do something like:
>>>
>>>max(table(mydadat$myvar))
>>>
>>>unfortunately it only returns the max count and not the value that is observed most.  Would some kind soul help me out with this seemingly trivial problem?
>>>
>>>Thanks in advance.
>>>
>>>Cheers,
>>>
>>>Patrick
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>>      
>>>
>>J.R. Lockwood
>>412-683-2300 x4941
>>lockwood at rand.org
>>http://www.rand.org/methodology/stat/members/lockwood/
>>
>>    
>>



From pem at theriver.com  Sat Jan 31 00:05:37 2004
From: pem at theriver.com (Patrick E. McKnight)
Date: Fri, 30 Jan 2004 16:05:37 -0700
Subject: [R] Measures of central tendency - mode
In-Reply-To: <401AE12A.4000307@pdf.com>
References: <20040130135519.507b86ae@copernicus>
	<Pine.LNX.4.33.0401301646570.353-100000@penguin.rand.org>
	<20040130151100.06b559ff@copernicus> <401AE12A.4000307@pdf.com>
Message-ID: <20040130160537.3a12600b@copernicus>

On Fri, 30 Jan 2004 14:56:42 -0800
Spencer Graves <spencer.graves at pdf.com> wrote:

>       Evidently, I didn't read your question carefully enough.  If you 
> want the mode of continuous data, that is not well defined, though there 
> are devices to estimate such assuming, e.g., a specific distribution or 
> a general unimodal distribution or ... .  This was discussed last Dec. 
> 12-13  by Ted Harding, Brian Ripley and others.  If you are interested, 
> you can go www.r-project.org -> search -> "R site search" -> "harding 
> mode".  When I did this just now, the first hit was an email on how to 
> find the mode using a kernel density estimator.  Clicking "next in 
> thread" a couple of times led me to a comment by Brian Ripley with a 
> pointer to a document discussing this. 
> 
>       ... in case you are interested in more than what you already have. 
> 
>       spencer graves


Thanks greatly for the extended tip.  Yes the data are continuous in a sense but there are discrete values that can be counted and tabled.  The kernel density estimator shows up on my search as well.  

<snip rest of thread that followed>

Cheers,

Patrick



From Benjamin.STABLER at odot.state.or.us  Sat Jan 31 00:18:39 2004
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Fri, 30 Jan 2004 15:18:39 -0800
Subject: [R] RGui Buffered Output
Message-ID: <76A000A82289D411952F001083F9DD06047FE457@exsalem4-bu.odot.state.or.us>

Using RGui on Windows NT, I want no buffered output as my default setting.
It seems like a natural place to do this would be under the GUI Preferences
window, but it is not there.  Is there a way to save my setting?  If not,
could it possibly be added to the next version of RGui?  Thanks.

Benjamin Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
555 13th Street NE, Suite 2
Salem, OR 97301  Ph: 503-986-4104



From clandry at fas.harvard.edu  Sat Jan 31 00:25:57 2004
From: clandry at fas.harvard.edu (Christian Landry)
Date: Fri, 30 Jan 2004 18:25:57 -0500
Subject: [R] exporting directly to a file
Message-ID: <5.1.0.14.2.20040130181812.00b47f98@fas.harvard.edu>

Hi,

I would like to know what is the function in R that allows exporting 
results of an operation directly to a file as the analysis is running. I am 
performing an analysis on a large matrix and the resulting object takes too 
much memory to be exported as a file.

Thanks,

Christian



From p.dalgaard at biostat.ku.dk  Sat Jan 31 00:28:46 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 31 Jan 2004 00:28:46 +0100
Subject: [R] Detect the presence of an object
In-Reply-To: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
References: <16410.50557.738399.755782@dhcp-63-193.cse.ucsc.edu>
Message-ID: <x2oeslj9sh.fsf@biostat.ku.dk>

Francisco J Molina <fjmolina at ams.ucsc.edu> writes:

> Is there a  function like "is.there" such that 
> 
> is.there ( a ) returns TRUE is object 'a' is in the current environment and
> FALSE otherwise?

exists("a",inherits=FALSE)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From MSchwartz at medanalytics.com  Sat Jan 31 03:19:52 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 30 Jan 2004 20:19:52 -0600
Subject: [R] Trouble plotting  with factor
In-Reply-To: <401AC6C7.3090909@ku.edu>
References: <401AC6C7.3090909@ku.edu>
Message-ID: <1075515592.31290.528.camel@localhost.localdomain>

On Fri, 2004-01-30 at 15:04, Paul Johnson wrote:
> With R 1.8.1 running in Fedora Core 1 Linux, I am having some trouble 
> recoding and ploting some factor variables. 
> 
> First, can I give you some example data?
> Here is a column of names for age groups:
> 
> agegroups <- c(   "15-19", "20-24", "25-29","30-34", "35-39", 
> "40-44","45-49","50-54","55-59","60-64",  "65-69", "70-74", "75-79",  
> "80-84", "OVER")
> 
> Here is an index for driver's license ownership in each age group:
> 
>   fracld            
> 0.4914204
> 0.9752746
> 1.0864465
> 1.0555984
> 1.0631969
> 1.0738725
> 1.0971969
> 1.0657212
> 1.0217373
> 0.9761226
> 0.9043233
> 0.9045744
> 0.8573243
> 0.7889182
> 0.5217992
> 
> I want to take several similar columns of numbers and put them into a 
> single line plot, one line for each column. 
> 
> I can get a graph with the inside part that looks roughly like I want if 
> I just do:
> 
> plot(fracld,type="l")
> 
> The horizontal axis, of course, is just the sequence from 1:15, not the 
> age labels. That's no good.
> 
> But, If I try
> 
> plot(as.factor(agegroup), fracld, type="l")
> 
> the plot does not have the line I want, but rather only flat "steps" 
> showing the values.  It does  have a nice looking horizontal axis, 
> though, showing the age groups.
> 
> So I think to myself "I'll outsmart them by adding the lines after 
> creating the plot", but if I do this
> 
> plot(agegroup,fracld,type="n")
> 
> The step markers still appear. 
> 
> So if I want the tick marks and value lables on the horzontal axis, 
> there is apparently  no way to plot lines?
> 
> What to do?

Paul,

I did not see any responses come through yet on this, so I don't know if
you got anything offlist.

I do not know how your data is structured, but one approach, if your
data is in a matrix, with the numbers being the columns and the
agegroups being the rownames, is the following:

# Create the agegroups
agegroups <- c("15-19", "20-24", "25-29","30-34", "35-39",
               "40-44","45-49","50-54","55-59","60-64",
               "65-69", "70-74", "75-79", "80-84", "OVER")

# Create the first column
fracld <- c(0.4914204, 0.9752746, 1.0864465, 1.0555984, 1.0631969,
            1.0738725, 1.0971969, 1.0657212, 1.0217373, 0.9761226,
            0.9043233, 0.9045744, 0.8573243, 0.7889182, 0.5217992)

# Now create two additional columns for the example
# 'fracld2' won't make sense "real world" since many vals
# will be > 1.0
fracld1 <- fracld - 0.25
fracld2 <- fracld + 0.25

# Create the matrix
df <- cbind(fracld, fracld1, fracld2)

# Set the rownames
rownames(df) <- agegroups

> df
         fracld   fracld1   fracld2
15-19 0.4914204 0.2414204 0.7414204
20-24 0.9752746 0.7252746 1.2252746
25-29 1.0864465 0.8364465 1.3364465
30-34 1.0555984 0.8055984 1.3055984
35-39 1.0631969 0.8131969 1.3131969
40-44 1.0738725 0.8238725 1.3238725
45-49 1.0971969 0.8471969 1.3471969
50-54 1.0657212 0.8157212 1.3157212
55-59 1.0217373 0.7717373 1.2717373
60-64 0.9761226 0.7261226 1.2261226
65-69 0.9043233 0.6543233 1.1543233
70-74 0.9045744 0.6545744 1.1545744
75-79 0.8573243 0.6073243 1.1073243
80-84 0.7889182 0.5389182 1.0389182
OVER  0.5217992 0.2717992 0.7717992


# Now use matplot() to plot each column
# Do not plot the axes
matplot(df, type = "l", axes = FALSE,
        xlab = "Age Group", ylab = "Proportion DL Ownership")

# Create the X axis, specifying 15 tick marks 
# and using rownames(df) as the labels
axis(1, at = 1:nrow(df), labels = rownames(df))

# Now draw the Y axis with defaults
axis(2)

# Put a box around the whole thing
box()


BTW, this is also using FC1 and R 1.8.1 Patched.

HTH,

Marc Schwartz



From spencer.graves at pdf.com  Sat Jan 31 03:40:07 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 30 Jan 2004 18:40:07 -0800
Subject: [R] exporting directly to a file
In-Reply-To: <5.1.0.14.2.20040130181812.00b47f98@fas.harvard.edu>
References: <5.1.0.14.2.20040130181812.00b47f98@fas.harvard.edu>
Message-ID: <401B1587.4050905@pdf.com>

      Have you considered "sink"? 

      hope this helps. 
      spencer graves

Christian Landry wrote:

> Hi,
>
> I would like to know what is the function in R that allows exporting 
> results of an operation directly to a file as the analysis is running. 
> I am performing an analysis on a large matrix and the resulting object 
> takes too much memory to be exported as a file.
>
> Thanks,
>
> Christian
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Sat Jan 31 09:10:46 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 31 Jan 2004 08:10:46 +0000 (GMT)
Subject: [R] a problem loading package 'subselect'
In-Reply-To: <1075494588.6114.16.camel@ra.chem.psu.edu>
Message-ID: <Pine.LNX.4.44.0401310755160.2350-100000@gannet.stats>

On Fri, 30 Jan 2004, Rajarshi Guha wrote:

> Hi,
>   I downloaded the subselect package from CRAN and installed it in the
> system wide R library path. During installation the package compiled the
> fortran sources with no errors. 

No _reported_ errors.

> However, when loading the library gives me an error:
> 
> > library(subselect)
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library
> "/usr/lib/R/library/subselect/libs/subselect.so":
>   /usr/lib/R/library/subselect/libs/subselect.so: undefined symbol:
> f_iob
> Error in library(subselect) : .First.lib failed
> 
> I would had expected that if it could'nt find a symbol, that would have
> shown up during compilation. But there were no compile time errors. I

All you did was create a shared object.  It does not need to be complete.

> also tried R CMD check on the package directory and compilation occurs
> with no errors but I get the errors below:
> 
> * checking S3 generic/method consistency ... WARNING
> Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc,
> character.only = TRUE, verbose = FALSE) :
>         .First.lib failed
> Execution halted
> 
> (And more such errors)
> 
> I have contacted the author of the package and he sent me few postings
> regarding the f_iob symbol and it appears to be a problem resulting from
> a LAPACK compiled with the Intel fortran compiler (ifc). However in this
> case, ifc is not installed on my system and during compilation it uses
> the Rlapack library.

The problem is to do with a Fortran run-time, and AFAICS not that in gcc 
3.3.2.

> I installed R from rpm's and am running on Fedora Core 1.

...

> It appears I am missing some library that contains f_iob (though why the
> error did'nt show up at compile time I dont know).

As I said above ....

> Has anybody faced this problem or have any suggestions as to how to fix
> it?

Compile R from the sources: works for me on FC1.  My subselect.so does not 
have a reference to f_iob.

Or look with nm to see which of the components which made up subselect.so
contains the reference, and check its compilation line.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From patrick.giraudoux at univ-fcomte.fr  Sat Jan 31 10:50:53 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 31 Jan 2004 10:50:53 +0100
Subject: [R] about contour - get contour coordinates - exclude area display
Message-ID: <001101c3e7df$bd765d00$0e55fb51@PC728329681112>

Dear all,

I wonder about what could actually be possible with the function "contour":

1/ - the definition of contour lines is most often meaningless when the contours are drawn in areas where no real data points exist.
It can however happen that irregular distributions lead to more or less  irregular clouds of data points. Interpolations (eg: loess
regression, GLM, etc...) are however generally made on regular grids passed to the function contour and thus can cover areas with
no/few data points to some extent. It would be most useful to display the contours with a polygon argument allowing the exclusion of
those areas (this is possible, for instance, with controur.krige of the package GeoR).  Is there a way to exclude the display of
contour lines out of polygon coordinates passed to the contour function (or another function in a package doing this) ?

2/ - it would also be most useful to get the contour lines coordinates (for instance, for importation in a GIS). Is there a way to
get them?

Thanks in advance for any hint,

Patrick Giraudoux



From bates at stat.wisc.edu  Sat Jan 31 14:22:39 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 31 Jan 2004 07:22:39 -0600
Subject: [R] looping over factors
In-Reply-To: <87vfmt3yuv.fsf@lumen.indyrad.iupui.edu>
References: <644D9337A02FC24689647BF9E48EC39E08ABB742@drm556>
	<87vfmt3yuv.fsf@lumen.indyrad.iupui.edu>
Message-ID: <6roeskmew0.fsf@bates4.stat.wisc.edu>

mmiller3 at iupui.edu (Michael A. Miller) writes:

> >>>>> "Samuelson," == Samuelson, Frank* <Samuelson> writes:
> 
>     > How does one loop over factors? 
> 
> You can loop on the levels of your factor:
> 
> > b<-factor(c('caseX','caseY', 'caseZ', 'caseX'))
> > b
> [1] caseX caseY caseZ caseX
> Levels: caseX caseY caseZ
> > for ( i in levels(b) ) { print(i) }
> [1] "caseX"
> [1] "caseY"
> [1] "caseZ"

I don't think that will be what is intended.  The levels attribute is
the distinct character representations of values in the factor.  It
need not be the same length as the factor itself.

> myfac = factor(sample(LETTERS, 100, replace = TRUE))
> table(myfac)
myfac
A B C D E F G H I J K L M N O P Q R S T U V W X Y Z 
6 2 4 5 2 3 7 6 3 7 6 3 8 3 1 3 3 5 2 4 2 2 5 4 2 2 
> length(levels(myfac))
[1] 26

By default the levels attribute is sorted lexicographically.

> for (ch in levels(myfac)) print(ch)
[1] "A"
[1] "B"
[1] "C"
[1] "D"
...
[1] "Y"
[1] "Z"

To iterate over the elements of myfac as character strings, use
as.character

> for (ch in as.character(myfac)) print(ch)
[1] "X"
[1] "L"
[1] "M"
[1] "W"
[1] "W"
...
[1] "E"
[1] "G"
[1] "H"

Hope this helps.



From maechler at stat.math.ethz.ch  Sat Jan 31 14:34:33 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 31 Jan 2004 14:34:33 +0100
Subject: [R] Trouble plotting  with factor
In-Reply-To: <1075515592.31290.528.camel@localhost.localdomain>
References: <401AC6C7.3090909@ku.edu>
	<1075515592.31290.528.camel@localhost.localdomain>
Message-ID: <16411.44777.144608.186713@gargle.gargle.HOWL>

>>>>> "Marc" == Marc Schwartz <MSchwartz at medanalytics.com>
>>>>>     on Fri, 30 Jan 2004 20:19:52 -0600 writes:

  <<excellent nicely told help text for Paul Johnson>>


I want to comment on the following because it's 
"not quite optimal", and still is recommended on-and-on ....

    Marc> # Now use matplot() to plot each column

    Marc> # Do not plot the axes
    Marc> matplot(df, type = "l", axes = FALSE,
    Marc>         xlab = "Age Group", ylab = "Proportion DL Ownership")

    Marc> # Create the X axis, specifying 15 tick marks 
    Marc> # and using rownames(df) as the labels
    Marc> axis(1, at = 1:nrow(df), labels = rownames(df))

    Marc> # Now draw the Y axis with defaults
    Marc> axis(2)

    Marc> # Put a box around the whole thing
    Marc> box()

More elegant is not to set axes = FALSE (and having to add
axis(2) and box() later) but to use  xaxt = 'n'  {only
suppressing x-axis}, i.e., instead of the above 4 statements,
only two :

 matplot(df, type = "l", xaxt = "n", # do not plot the 'x' axis
         xlab = "Age Group", ylab = "Proportion DL Ownership")

 # Create the X axis, specifying 15 tick marks 
 # and using rownames(df) as the labels
 axis(1, at = 1:nrow(df), labels = rownames(df))


Martin



From ripley at stats.ox.ac.uk  Sat Jan 31 15:23:10 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 31 Jan 2004 14:23:10 +0000 (GMT)
Subject: [R] about contour - get contour coordinates - exclude area display
In-Reply-To: <001101c3e7df$bd765d00$0e55fb51@PC728329681112>
Message-ID: <Pine.LNX.4.44.0401311415400.6436-100000@gannet.stats>

On Sat, 31 Jan 2004, Patrick Giraudoux wrote:

> Dear all,
> 
> I wonder about what could actually be possible with the function "contour":
> 
> 1/ - the definition of contour lines is most often meaningless when the
> contours are drawn in areas where no real data points exist. It can
> however happen that irregular distributions lead to more or less
> irregular clouds of data points. Interpolations (eg: loess regression,
> GLM, etc...) are however generally made on regular grids passed to the
> function contour and thus can cover areas with no/few data points to
> some extent. It would be most useful to display the contours with a
> polygon argument allowing the exclusion of those areas (this is
> possible, for instance, with controur.krige of the package GeoR).  Is

There is no function cont(r)our.krige in geoR. There is a function
`contour.kriging', and that just calls contour, so you too can do whatever
you think that does (and the help page does not tally with your
description).

> there a way to exclude the display of contour lines out of polygon
> coordinates passed to the contour function (or another function in a
> package doing this) ?

Contour works on a rectangular grid.  Set to NA those cells where you have
no data, and you will not get contours there.  Simple!

> 2/ - it would also be most useful to get the contour lines coordinates
> (for instance, for importation in a GIS). Is there a way to get them?


Paul Murrell has fulfilled that request a while back.  See the clines
package on CRAN, or contourLines in the development version of R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ozric at web.de  Sat Jan 31 16:43:16 2004
From: ozric at web.de (Christian Schulz)
Date: Sat, 31 Jan 2004 16:43:16 +0100
Subject: [R] in which column is an entry?
Message-ID: <200401311643.16719.ozric@web.de>

Hi,

df  is a data.frame with 43 colums and 29877 rows with lot of NA.
I want the column number for all respondendts in one column 
where is the first entry >=0 as columnnumber.

my first step:
 time <- function(df)
+     {        for (i in 1:length(df [,1])) {    
+     which(df[i,1]:df[i,43] >= 0)
+     }
+            }

> 
> t1 <-  time(YS)
Error in df[i, 1]:df[i, 43] : NA/NaN argument

Many thanks for help , regards christian



From ccleland at optonline.net  Sat Jan 31 16:57:08 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Sat, 31 Jan 2004 10:57:08 -0500
Subject: [R] in which column is an entry?
In-Reply-To: <200401311643.16719.ozric@web.de>
References: <200401311643.16719.ozric@web.de>
Message-ID: <401BD054.5030001@optonline.net>

Christian Schulz wrote:
> df  is a data.frame with 43 colums and 29877 rows with lot of NA.
> I want the column number for all respondendts in one column 
> where is the first entry >=0 as columnnumber.
> 
> my first step:
>  time <- function(df)
> +     {        for (i in 1:length(df [,1])) {    
> +     which(df[i,1]:df[i,43] >= 0)
> +     }
> +            }
> 
> 
>>t1 <-  time(YS)
> 
> Error in df[i, 1]:df[i, 43] : NA/NaN argument

   I am not sure, but I think you might want something like this:

t1 <- apply(df, 1, function(x){
             ifelse(all(is.na(x)) | all(na.omit(x) < 0),
             NA, which(x >= 0))})

hope this helps,

Chuck Cleland

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ozric at web.de  Sat Jan 31 18:04:12 2004
From: ozric at web.de (Christian Schulz)
Date: Sat, 31 Jan 2004 18:04:12 +0100
Subject: [R] in which column is an entry?
In-Reply-To: <401BD054.5030001@optonline.net>
References: <200401311643.16719.ozric@web.de> <401BD054.5030001@optonline.net>
Message-ID: <200401311804.12884.ozric@web.de>

Yes, many thanks i have really to  avoid think in loops  :-)
christian


Am Samstag, 31. Januar 2004 16:57 schrieb Chuck Cleland:
> Christian Schulz wrote:
> > df  is a data.frame with 43 colums and 29877 rows with lot of NA.
> > I want the column number for all respondendts in one column
> > where is the first entry >=0 as columnnumber.
> >
> > my first step:
> >  time <- function(df)
> > +     {        for (i in 1:length(df [,1])) {
> > +     which(df[i,1]:df[i,43] >= 0)
> > +     }
> > +            }
> >
> >>t1 <-  time(YS)
> >
> > Error in df[i, 1]:df[i, 43] : NA/NaN argument
>
>    I am not sure, but I think you might want something like this:
>
> t1 <- apply(df, 1, function(x){
>              ifelse(all(is.na(x)) | all(na.omit(x) < 0),
>              NA, which(x >= 0))})
>
> hope this helps,
>
> Chuck Cleland



From MSchwartz at medanalytics.com  Sat Jan 31 18:20:18 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sat, 31 Jan 2004 11:20:18 -0600
Subject: [R] Trouble plotting  with factor
In-Reply-To: <16411.44777.144608.186713@gargle.gargle.HOWL>
References: <401AC6C7.3090909@ku.edu>
	<1075515592.31290.528.camel@localhost.localdomain>
	<16411.44777.144608.186713@gargle.gargle.HOWL>
Message-ID: <1075569618.31290.542.camel@localhost.localdomain>

On Sat, 2004-01-31 at 07:34, Martin Maechler wrote:
> >>>>> "Marc" == Marc Schwartz <MSchwartz at medanalytics.com>
> >>>>>     on Fri, 30 Jan 2004 20:19:52 -0600 writes:
> 
>   <<excellent nicely told help text for Paul Johnson>>

Thanks Martin.

> I want to comment on the following because it's 
> "not quite optimal", and still is recommended on-and-on ....
> 
>     Marc> # Now use matplot() to plot each column
> 
>     Marc> # Do not plot the axes
>     Marc> matplot(df, type = "l", axes = FALSE,
>     Marc>         xlab = "Age Group", ylab = "Proportion DL Ownership")
> 
>     Marc> # Create the X axis, specifying 15 tick marks 
>     Marc> # and using rownames(df) as the labels
>     Marc> axis(1, at = 1:nrow(df), labels = rownames(df))
> 
>     Marc> # Now draw the Y axis with defaults
>     Marc> axis(2)
> 
>     Marc> # Put a box around the whole thing
>     Marc> box()
> 
> More elegant is not to set axes = FALSE (and having to add
> axis(2) and box() later) but to use  xaxt = 'n'  {only
> suppressing x-axis}, i.e., instead of the above 4 statements,
> only two :
> 
>  matplot(df, type = "l", xaxt = "n", # do not plot the 'x' axis
>          xlab = "Age Group", ylab = "Proportion DL Ownership")
> 
>  # Create the X axis, specifying 15 tick marks 
>  # and using rownames(df) as the labels
>  axis(1, at = 1:nrow(df), labels = rownames(df))


Right. I had actually started to use that approach (which I have used in
the past for plot(), etc.). I must have had a transient loss of blood
flow to the brain, as I for some reason (uncommented in my code), I
decided to use 'axes = FALSE'.  Either that, or I was asleep at the
keyboard and my fingers were on autopilot....  :-)

Thanks for pointing that out Martin.

Best regards,

Marc



From ripley at stats.ox.ac.uk  Sat Jan 31 18:54:40 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 31 Jan 2004 17:54:40 +0000 (GMT)
Subject: [R] in which column is an entry?
In-Reply-To: <200401311804.12884.ozric@web.de>
Message-ID: <Pine.LNX.4.44.0401311730400.30054-100000@gannet.stats>

On Sat, 31 Jan 2004, Christian Schulz wrote:

> Yes, many thanks i have really to  avoid think in loops  :-)

Unfortunately Chuck's solution is a loop over rows, disguised by the use 
of apply.

Let us assume that the dataframe has all numeric entries and coerce to a 
matrix (as apply will, BTW).

tmp <- as.matrix(df)
tmp[is.na(tmp)] <- -1   # get rid of the NAs
tmp <- tmp >= 0         # a logical matrix
tmp <- cbind(tmp, TRUE) # add a fence column

I am happy to loop over 43 columns, though, so

for(i in 2:44) tmp[, i] <- tmp[, i] | tmp[, i-1]
for(i in 44:2) tmp[, i] <- tmp[, i] & !tmp[, i-1]
rtmp <- t(tmp)
z <- row(rtmp)[rtmp]
z[z==44] <- NA
z

is what you want.  It's a lot faster (about 12x).



> christian
> 
> 
> Am Samstag, 31. Januar 2004 16:57 schrieb Chuck Cleland:
> > Christian Schulz wrote:
> > > df  is a data.frame with 43 colums and 29877 rows with lot of NA.
> > > I want the column number for all respondendts in one column
> > > where is the first entry >=0 as columnnumber.
> > >
> > > my first step:
> > >  time <- function(df)
> > > +     {        for (i in 1:length(df [,1])) {
> > > +     which(df[i,1]:df[i,43] >= 0)
> > > +     }
> > > +            }
> > >
> > >>t1 <-  time(YS)
> > >
> > > Error in df[i, 1]:df[i, 43] : NA/NaN argument
> >
> >    I am not sure, but I think you might want something like this:
> >
> > t1 <- apply(df, 1, function(x){
> >              ifelse(all(is.na(x)) | all(na.omit(x) < 0),
> >              NA, which(x >= 0))})
> >
> > hope this helps,
> >
> > Chuck Cleland
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From cbotts1 at cox.net  Sat Jan 31 21:46:01 2004
From: cbotts1 at cox.net (cbotts1@cox.net)
Date: Sat, 31 Jan 2004 15:46:01 -0500
Subject: [R] lme help
Message-ID: <20040131204601.EEBN13731.lakemtao01.cox.net@smtp.east.cox.net>

Does anyone know how to fit a linear mixed effects model when the within-group covariance is known!    I know how to fit an lme model when the within-group covariance STRUCTURE is known, but that doesn't help.    

Any help would be greatly appreciated!



From ozric at web.de  Sat Jan 31 23:38:01 2004
From: ozric at web.de (Christian Schulz)
Date: Sat, 31 Jan 2004 23:38:01 +0100
Subject: [R] in which column is an entry?
In-Reply-To: <Pine.LNX.4.44.0401311730400.30054-100000@gannet.stats>
References: <Pine.LNX.4.44.0401311730400.30054-100000@gannet.stats>
Message-ID: <200401312338.02537.ozric@web.de>

Thanks, speed is sometimes reaaly important , but
to understand in a advanced practice guide about  loops.
i'm always not sure when indexing is necessary for the objects in the loop:
Different versions accept as function but didn'T run without error.

many thanks & regards,
christian

special <-  function(const,modeldat,YS) {
                  for(i in 1:10) {
const[i]=const[i]+1   #i'know  only here indexing make no sense!?
t1 <-  apply(YS,1, function(x) {  ifelse(all(is.na(x)) | all(na.omit(x)<0),
                                NA, which( x > const[i]))})
t1[is.na(t1)] <-  13
t2 <-  sapply(t1,function(x) { ifelse(x ==13,0,1)})
modeldat$MONTH <- t1
modeldat$ACTIVE <- t2
modeldats <- na.omit(modeldat)
mod1<-  coxph(Surv(MONTH,ACTIVE)  ~ ALTER+LEISTUNG,data=modeldats)
pdf(file = "~/Survival.pdf",    width = 6, height = 6, onefile = TRUE, family 
= "Helvetica",title = "R Graphics Output")
plot(survfit(mod1),ylim=c(.7,1),xlab='Month',ylab='Proportion not Active') }
                dev.off() }

Error in fitter(X, Y, strats, offset, init, control, weights = weights,  : 
	NA/NaN/Inf in foreign function call (arg 6)
In addition: Warning message: 
Ran out of iterations and did not converge in: fitter(X, Y, strats, offset, 
init, control, weights = weights,  



Am Samstag, 31. Januar 2004 18:54 schrieben Sie:
> On Sat, 31 Jan 2004, Christian Schulz wrote:
> > Yes, many thanks i have really to  avoid think in loops  :-)
>
> Unfortunately Chuck's solution is a loop over rows, disguised by the use
> of apply.
>
> Let us assume that the dataframe has all numeric entries and coerce to a
> matrix (as apply will, BTW).
>
> tmp <- as.matrix(df)
> tmp[is.na(tmp)] <- -1   # get rid of the NAs
> tmp <- tmp >= 0         # a logical matrix
> tmp <- cbind(tmp, TRUE) # add a fence column
>
> I am happy to loop over 43 columns, though, so
>
> for(i in 2:44) tmp[, i] <- tmp[, i] | tmp[, i-1]
> for(i in 44:2) tmp[, i] <- tmp[, i] & !tmp[, i-1]
> rtmp <- t(tmp)
> z <- row(rtmp)[rtmp]
> z[z==44] <- NA
> z
>
> is what you want.  It's a lot faster (about 12x).
>
> > christian
> >
> > Am Samstag, 31. Januar 2004 16:57 schrieb Chuck Cleland:
> > > Christian Schulz wrote:
> > > > df  is a data.frame with 43 colums and 29877 rows with lot of NA.
> > > > I want the column number for all respondendts in one column
> > > > where is the first entry >=0 as columnnumber.
> > > >
> > > > my first step:
> > > >  time <- function(df)
> > > > +     {        for (i in 1:length(df [,1])) {
> > > > +     which(df[i,1]:df[i,43] >= 0)
> > > > +     }
> > > > +            }
> > > >
> > > >>t1 <-  time(YS)
> > > >
> > > > Error in df[i, 1]:df[i, 43] : NA/NaN argument
> > >
> > >    I am not sure, but I think you might want something like this:
> > >
> > > t1 <- apply(df, 1, function(x){
> > >              ifelse(all(is.na(x)) | all(na.omit(x) < 0),
> > >              NA, which(x >= 0))})
> > >
> > > hope this helps,
> > >
> > > Chuck Cleland
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html



