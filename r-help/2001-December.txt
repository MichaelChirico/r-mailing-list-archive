From jfox at mcmaster.ca  Sat Dec  1 19:28:37 2001
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 01 Dec 2001 13:28:37 -0500
Subject: [R] mosaic.by(): vectorizing args passed by apply()?
In-Reply-To: <3C0800A7.794318D4@yorku.ca>
Message-ID: <5.1.0.14.2.20011201132239.01d717c8@mcmail.cis.mcmaster.ca>

Dear Mike,

There might be a  more elegant solution, but one way is slice the table 
into a list of tables corresponding to the panels of the display, and to 
use a for loop to index panels and titles:

     mosaic.by <-
     function(table, by=NULL, ...)
     {
         n <- length(dim(table))
         if(n == 0)
             stop("invalid table `table'")
         if(length(by)>1)
             stop("Sorry, cannot handle >1 by variable yet.")

         np <- dim(table)[by]
         name <- names(dimnames(table))[by]
         titles <- paste(name, ":", dimnames(table)[[by]])

         opar <- par( mfrow=c(np, np), usr=c(1,1000,1,1000), mar=rep(1,4)) 
# why np x np?
         on.exit(par(opar))
         panels <- apply(table, by, list)
         for (i in 1:np) mosaicplot(panels[[i]][[1]], main=titles[i], 
shade=T, ...)
     }

Does that do what you want?

Regards,
  John

At 04:56 PM 11/30/2001 -0500, Michael Friendly wrote:
>I've just started learning R, so I'm still on the steep part of the
>learning curve, but my enthusiasm was heightened by learning that
>there's a very nice implementation of mosaicplot().
>
>As a learning project, I've already done a basic implementation
>of a pairs.table() function which does a mosaic scatterplot matrix,
>and now I'm trying to do conditional mosaic plots (discrete analog
>of a coplot).
>
>I found that
>    apply(table, by, mosaicplot,...)
>worked quite nicely, but I want to label each mosaic with the
>combination of the factor name and level value, e.g., Sex: Male,
>and I can't figure out how to get just one element of a list
>passed by apply as an argument.
>
>In the function below, titles is a list like:
> > paste("Sex: ", dimnames(Titanic)[[2]])
>[1] "Sex:  Male"   "Sex:  Female"
>and I want each element passed as the main= value for the corresponding
>slice of the table.
>Can someone help?
>
>Try the function below with
>
>data(HairEyeColor)
>mosaic.by(HairEyeColor, 3)
>
>## Conditional mosaics, one for each level of the by-variable(s)
>##   -- how to add factor levels as main= ?
>##   -- how to do for more than one by-variable?
>mosaic.by <-
>function(table, by=NULL, ...)
>{
>     n <- length(dim(table))
>     if(n == 0)
>         stop("invalid table `table'")
>     if(length(by)>1)
>         stop("Sorry, cannot handle >1 by variable yet.")
>
>     np <- dim(table)[by]
>     name <- names(dimnames(table))[by]
>     titles <- paste(name, ":", dimnames(table)[[by]])
>
>     opar <- par( mfrow=c(np, np), usr=c(1,1000,1,1000), mar=rep(1/2,4))
>     on.exit(par(opar))
>
>     apply(table, by, mosaicplot, main=titles, shade=T, legend=F, ...)
>}
>
>thx,
>-Michael
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Dec  2 08:51:24 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 Dec 2001 07:51:24 +0000 (GMT)
Subject: [R] mosaic.by(): vectorizing args passed by apply()?
In-Reply-To: <5.1.0.14.2.20011201132239.01d717c8@mcmail.cis.mcmaster.ca>
Message-ID: <Pine.LNX.4.31.0112020743320.8815-100000@gannet.stats>

In R, using for as John Fox has done is almost certainly as good as
anything.  That's what apply does internally.

Think of the *apply of splitting data by some grouping, apolying a
function to each subgroup and combining the results.  That means which
subgroup it was was not known.  So you do need to have all the
information split: you could that by taking the titles onto the original
object or splitting the indices of a vector or array (rather than the
object itself).

Using lapply() rather than a for() loop used to be very worthwhile in
S-PLUS 3.4.  It was worse in 5.0, and is somewhat better in 6.0.  R has
never had the (extreme) memory problems with for() loops that some
versions of S have had, so it's only worth avoiding solutions with
explicit loops if they prove to be too slow.


On Sat, 1 Dec 2001, John Fox wrote:

> Dear Mike,
>
> There might be a  more elegant solution, but one way is slice the table
> into a list of tables corresponding to the panels of the display, and to
> use a for loop to index panels and titles:
>
>      mosaic.by <-
>      function(table, by=NULL, ...)
>      {
>          n <- length(dim(table))
>          if(n == 0)
>              stop("invalid table `table'")
>          if(length(by)>1)
>              stop("Sorry, cannot handle >1 by variable yet.")
>
>          np <- dim(table)[by]
>          name <- names(dimnames(table))[by]
>          titles <- paste(name, ":", dimnames(table)[[by]])
>
>          opar <- par( mfrow=c(np, np), usr=c(1,1000,1,1000), mar=rep(1,4))
> # why np x np?
>          on.exit(par(opar))
>          panels <- apply(table, by, list)
>          for (i in 1:np) mosaicplot(panels[[i]][[1]], main=titles[i],
> shade=T, ...)
>      }
>
> Does that do what you want?
>
> Regards,
>   John
>
> At 04:56 PM 11/30/2001 -0500, Michael Friendly wrote:
> >I've just started learning R, so I'm still on the steep part of the
> >learning curve, but my enthusiasm was heightened by learning that
> >there's a very nice implementation of mosaicplot().
> >
> >As a learning project, I've already done a basic implementation
> >of a pairs.table() function which does a mosaic scatterplot matrix,
> >and now I'm trying to do conditional mosaic plots (discrete analog
> >of a coplot).
> >
> >I found that
> >    apply(table, by, mosaicplot,...)
> >worked quite nicely, but I want to label each mosaic with the
> >combination of the factor name and level value, e.g., Sex: Male,
> >and I can't figure out how to get just one element of a list
> >passed by apply as an argument.
> >
> >In the function below, titles is a list like:
> > > paste("Sex: ", dimnames(Titanic)[[2]])
> >[1] "Sex:  Male"   "Sex:  Female"
> >and I want each element passed as the main= value for the corresponding
> >slice of the table.
> >Can someone help?
> >
> >Try the function below with
> >
> >data(HairEyeColor)
> >mosaic.by(HairEyeColor, 3)
> >
> >## Conditional mosaics, one for each level of the by-variable(s)
> >##   -- how to add factor levels as main= ?
> >##   -- how to do for more than one by-variable?
> >mosaic.by <-
> >function(table, by=NULL, ...)
> >{
> >     n <- length(dim(table))
> >     if(n == 0)
> >         stop("invalid table `table'")
> >     if(length(by)>1)
> >         stop("Sorry, cannot handle >1 by variable yet.")
> >
> >     np <- dim(table)[by]
> >     name <- names(dimnames(table))[by]
> >     titles <- paste(name, ":", dimnames(table)[[by]])
> >
> >     opar <- par( mfrow=c(np, np), usr=c(1,1000,1,1000), mar=rep(1/2,4))
> >     on.exit(par(opar))
> >
> >     apply(table, by, mosaicplot, main=titles, shade=T, legend=F, ...)
> >}
> >
> >thx,
> >-Michael
> >-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> >r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> >Send "info", "help", or "[un]subscribe"
> >(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> >_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From c.schulz at metafacts.de  Sun Dec  2 16:37:25 2001
From: c.schulz at metafacts.de (Christian Schulz)
Date: Sun, 02 Dec 2001 16:37:25 +0100
Subject: [R] decision tree C4.5
Message-ID: <3C0A4AB5.5010901@metafacts.de>

Hello,
exist an implementation of DecisionTree Algorithms
C4.5 from Quinlan in R which extract ruleSets for Classification Problems?

I found "only" the  packages tree and rpart which use other algorithms !

thanks & regards,
christian


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dieter.menne at menne-biomed.de  Sun Dec  2 17:31:45 2001
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sun, 2 Dec 2001 17:31:45 +0100
Subject: [R] GLM with ranks as response variable
Message-ID: <JLEPLGAANFCEAEDCAGJNGENDCAAA.dieter.menne@menne-biomed.de>

Dear R's,

I have a survey where customers rank a set of 5 packages for a product,
so the response variable looks like

a d b c
a c d b
d b a c

Predictors variables are 4 socio-economic parameters. I have modelled the FIRST
choice of each subject as a multinomial model, similar to the housing example in
MASS ch7.3, , but I would prefer to use the whole rank-set instead.

Can someone give me a hint if a R-package exists for this type of analysis?

Dieter Menne


---------------------------------------
Dr. Dieter Menne
Biomed Software
72074 T?bingen
Tel (49) (7071) 52176
FAX (49) (7071) 55 10 46
dieter.menne at menne-biomed.de
www.menne-biomed.de

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Sun Dec  2 20:35:31 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sun, 2 Dec 2001 14:35:31 -0500 (EST)
Subject: [R] GLM with ranks as response variable
Message-ID: <200112021935.fB2JZVn00381@cattell.psych.upenn.edu>

>From owner-r-help at stat.math.ethz.ch Sun Dec  2 14:25:42 2001
>I have a survey where customers rank a set of 5 packages for a product,
>so the response variable looks like
>
>a d b c
>a c d b
>d b a c
>
>Predictors variables are 4 socio-economic parameters. I have modelled the FIRST
>choice of each subject as a multinomial model, similar to the housing example in
>MASS ch7.3, , but I would prefer to use the whole rank-set instead.
>
>Can someone give me a hint if a R-package exists for this type of analysis?

I've dealt with data like this, and I think the answer depends a
log on what the packages are, whether you have some prior
hypothesis about the effects of the independent variables, etc.

One way to go is just to translate this into five variables, the
rank of each package, and predict it from a Manova.  I think that
will even work in lm(), but of course the ranks aren't
independent of each other.  Still, I seem to recall being able to
get an overall test of predictability (but I'm not going to try
this again unless I know that this is what you really need).  It
is true that a 1-5 scale will be grainy and violate some
distributional assumptions, but not too badly.

Another way is to reduce the ranks, either by factor analysis or
cluster analysis (both in mva, I think) - or just looking at
their correlations - so that you can devise one or two dependent
measures based on some composite of them.

And of course the best is to have some hypothesis about which
items should be affected by which variables, and then make a
composite of the ranks that is explicitly designed to test your
hypothesis.  Presumably this would not use all of the packages.

Still another approach is something like canonical correlation -
again, blindly empirical.  I think the sem package does this but
I haven't tried it.

Jon Baron

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From xiao.gang.fan1 at libertysurf.fr  Sun Dec  2 23:52:13 2001
From: xiao.gang.fan1 at libertysurf.fr (Fan)
Date: Sun, 02 Dec 2001 23:52:13 +0100
Subject: [R] Financial Numerical Recipes in R
Message-ID: <3C0AB09D.C4AD5BD6@libertysurf.fr>

Hi,

Does anyone know whether the "Financial Numerical Recipes" in C++
of Bernt Arne ?degaard has been ported in R ? I know a portage to Ox,
it should be relatively easy to translate from Ox to R, but
if somebody has already done the exercice, I'll be happy for the time saved.

Thanks in advance
--
Fan

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maj at waikato.ac.nz  Mon Dec  3 01:52:16 2001
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Mon, 03 Dec 2001 13:52:16 +1300
Subject: [R] Complex nonlinear model
Message-ID: <200112030050.NAA27118@gosset.stats.waikato.ac.nz>

I am running 1.3.1 on a Windows (NT 4.0) machine.

I am trying to fit a nonlinear model intended to predict crop yield from
nutrient information.

I am troubled by an error message:

> library(nls)
> simparj.fm <- nls(Y ~ Y.model(gN, MnmN, OptN, DIs,  beta, eta1, eta2,
+       Popn, Dmax, AWC, SumEp, PotYield3, Nsupply),
+       start = simparj.st, trace =T)
Error in numericDeriv(form[[3]], names(ind), env) : 
        theta should be of type character

I suspect that I am doing something stupid. My code in full is

# parameter assignments
Nmin      <- 0.8852
Nopt1     <- 16.78
gN <- 0.5511
E.nfert1 <- 0.3271
E.nfert2 <- 0.6132
Beta <- 0.8902
Dls <- 0.5378
eta1 <- 0.3791
eta2 <- 0.6332
PopStd <- 90468
beta <- Beta
DIs <- Dls
MnmN <- Nmin
OptN <- Nopt1

# simulate experimental data for predictors
nsim <- 70
Popn <- rnorm(nsim,PopStd,0.1*PopStd)
Dmax <- rnorm(nsim,140.68,47.45)
AWC <- rnorm(nsim,186.86,47.41)
SumEp <- rnorm(nsim,318.54,32.53)
PotYield3 <- rnorm(nsim,0.16180,0.01167)
Nsoil <- rnorm(nsim,94.07,34.06)
Bdfield <- rnorm(nsim,1.0590,0.1420)
Bdlab <- rnorm(nsim,0.7876,0.1169)

Nfert.broad <- runif(nsim,95.3,576.5)
Nfert.band <- runif(nsim,122,250)
broad <- rbinom(nsim,1,0.2)
Nfert.broad <- Nfert.broad*broad
Nfert.band <- Nfert.band*(1 - broad)
Nsupply<-Nsoil*Bdfield/Bdlab + Nfert.broad*E.nfert1 + Nfert.band*E.nfert2

# define model function

Y.model <- function(gN, MnmN, OptN, DIs,  beta, eta1, eta2,
      Popn, Dmax, AWC, SumEp, PotYield3, Nsupply)
      {
      Ymax<- 1-ifelse(Popn<=PopStd, eta1, eta2)*log(Popn/PopStd)
      Ymax <- Ymax*PotYield3*Popn/1000
      Ymax <- Ymax*ifelse(Dmax<=DIs*AWC, 1, 1 - beta*(Dmax -DIs*AWC)/SumEp)
      Nstar <- (Nsupply- MnmN*Ymax) / (OptN*Ymax - MnmN*Ymax)
      Nstar<-pmax ( 0,Nstar)
      Ystar<-ifelse(Nstar<1, (1 + gN*(1 - Nstar))* Nstar^(1+gN ), 1)
      Ystar<-pmax ( 0, Ystar)
      Y.model <- Ystar*Ymax
      }

# generate response variable from model

Y <- Y.model(gN, MnmN, OptN, DIs,  beta, eta1, eta2,
      Popn, Dmax, AWC, SumEp, PotYield3, Nsupply)
Y <- Y + rnorm(nsim,0,1)

# attempt to fit starting from true parameters
library(nls)
simparj.st <- c(gN, MnmN, OptN, DIs,  beta, eta1, eta2)
simparj.fm <- nls(Y ~ Y.model(gN, MnmN, OptN, DIs,  beta, eta1, eta2,
      Popn, Dmax, AWC, SumEp, PotYield3, Nsupply),
      start = simparj.st, trace =T)




Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html 
Department of Statistics, University of Waikato, Hamilton, New Zealand 
Email: maj at waikato.ac.nz                            Fax +64-7 838 4155
Phone +64-7 838 4773 home phone +64-7 856 6705  Mobile +64-21 139 5862

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gindo.tampubolon at man.ac.uk  Mon Dec  3 10:58:00 2001
From: gindo.tampubolon at man.ac.uk (Gindo Tampubolon)
Date: Mon, 3 Dec 2001 09:58:00 GMT
Subject: [R] Summary on R script editor
Message-ID: <E16Aps8-0006I4-01@probity.mcc.ac.uk>

Thanks for the advice, folks!

Shravan Vasishth <vasishth at ling.ohio-state.edu>
Try pico.
There's no substitute for/comparison with emacs, though, IMHO. 
but just to be sure: you don't have to have ESS to use (x)emacs for 
editing R scripts.

Sven Garbade <garbade at psy.uni-muenchen.de>
ESS can be installed via rpm on Mandrake.

baron at cattell.psych.upenn.edu (Jonathan Baron)
ESS is the real answer to your question, and anything else has got 
to be more difficult.

Nels Tomlinson <tomlinso at purdue.edu>
Installing ESS on debian was as simple as apt-get install ess. 

David Lucy <dlucy at maths.ed.ac.uk> & "Stuart Leask" 
<stuart.leask at nottingham.ac.uk>:
Nedit - quick, easy, supports X (ie. mouse-click) pasting. 
I use Nedit - http://nedit.org/
For pasting bits in a Linux environment use gpm which is brilliant. 

S David White <dwhite at ling.ohio-state.edu>
I have good luck just using gedit in RH 7.1&2.

Toby.Patterson at csiro.au
Being similarly effected by emacs I find glimmer an OK text editor 
(linux version of textpad).


Gindo Tampubolon
University of Manchester
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From poizot at intechmer.cnam.fr  Mon Dec  3 11:15:08 2001
From: poizot at intechmer.cnam.fr (Emmanuel POIZOT)
Date: Mon, 03 Dec 2001 11:15:08 +0100
Subject: [R] Plotting in a traingle
Message-ID: <3C0B50AC.748C3620@intechmer.cnam.fr>

Hello,
I want to print points having value on 3 variables in a triangle
(ternary diagram).
How can I di this with R ?

--

Cordialement
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~ Emmanuel POIZOT
~ CNAM/INTECHMER
~ B.P. 324
~ 50103 CHERBOURG CEDEX
~ T?l : (33) 233 887 342
~ Fax : (33) 233 887 339
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec  3 11:30:32 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Dec 2001 10:30:32 +0000 (GMT)
Subject: [R] Plotting in a traingle
In-Reply-To: <3C0B50AC.748C3620@intechmer.cnam.fr>
Message-ID: <Pine.LNX.4.31.0112031028001.22150-100000@gannet.stats>

On Mon, 3 Dec 2001, Emmanuel POIZOT wrote:

> Hello,
> I want to print points having value on 3 variables in a triangle
> (ternary diagram).
> How can I di this with R ?

See the ternary() function in the on-line exercises (and answers) to
Venables & Ripley's MASS, at

http://www.stats.ox.ac.uk/pub/MASS3/


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Mon Dec  3 12:08:06 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Mon, 3 Dec 2001 06:08:06 -0500 (EST)
Subject: [R] beginner's questions about lme, fixed and random effects
Message-ID: <200112031108.fB3B86o25617@cattell.psych.upenn.edu>

I'm trying to understand better the differences between fixed and
random effects by running very simple examples in the nlme
package.  My first attempt was to try doing a t-test in lme.
This is very similar to the Rail example that comes with nlme,
but it has two groups instead of five.

So I try

a1 <- 1:10
a2 <- 7:16
t.test(a2,a1)

getting t(18)=4.43, p=.0003224.  Then I try to do it with lme:

a12 <- c(a1,a2)
grp <- factor(rep(1:2,c(10,10)))

Now, at this point, I think I should be able to do something like
this:
lme(a12~grp)
or
lme(a12~1|grp)
but I keep getting an error message, "Invalid formula for
groups."  So I tried making a groupedData object:

data1 <- as.data.frame(cbind(a12,grp))
gd1 <- groupedData(a12~1|grp,data=as.data.frame(cbind(a12,grp)))

Now I can do
lme(gd1)
or
lme(gd1,random=1|grp)
or many other things, but nothing seems to yield anything like
the t test, and I'm not even sure what the fixed effect test
(with a p of .011 with summary(lme(gd1))) is testing.  (It
doesn't seem to be about whether the grand mean of a12 is greater
than zero.)  I've been studying the relevant documentaion,
including Pinheiro and Bates's book, but I'm still stumped.  I'm
sure I'm being very dense about something very simple, like,
"This doesn't make any sense."  But why not?

All this is leading up to a real application to a much more
complicated problem, but I think I need to understand the simple
stuff first.

Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vito.muggeo at giustizia.it  Mon Dec  3 13:08:51 2001
From: vito.muggeo at giustizia.it (MUGGEO VITO)
Date: Mon, 3 Dec 2001 13:08:51 +0100
Subject: [R] fitting models with the subset argument
Message-ID: <005101c17bf3$49710ea0$5c13070a@it.giustizia.it>

Hi all,
I'd like to fit model where the terms both are in the data.frame, mydata
say, and are vectors *not in the data.frame*.
>obj<-glm(y~x, data=mydata) #works
>Z<-pmax(mydata$x-20,0)
>(length(Z)==length(obj$y))
>[1] TRUE
>update(obj,.~.+Z) #works

However for some subset it doesn't works:
>obj<-glm(y~x, data=mydata, subset=f==1) #works
>Z<-pmax(mydata$x[mydata$f==1]-20,0)
>(length(Z)==length(obj$y))
>[1] TRUE
>update(obj,.~.+Z)  #DOESN'T WORK!!!
Error in model.frame(formula, rownames, variables, varnames, extras,
extranames, :
            variable lengths differ

Of course also the following doesn't work
>glm(y~x +Z, mydata, subset=f==1) #doesn't work

but the following works
>glm(y[mydata$f==1]~x[mydata$f==1] +Z, mydata)

How can I solve this problem?
Thank you very much for your attention!
vito




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec  3 13:17:12 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Dec 2001 12:17:12 +0000 (GMT)
Subject: [R] beginner's questions about lme, fixed and random effects
In-Reply-To: <200112031108.fB3B86o25617@cattell.psych.upenn.edu>
Message-ID: <Pine.LNX.4.31.0112031206050.22338-100000@gannet.stats>

On Mon, 3 Dec 2001, Jonathan Baron wrote:

> I'm trying to understand better the differences between fixed and
> random effects by running very simple examples in the nlme
> package.  My first attempt was to try doing a t-test in lme.
> This is very similar to the Rail example that comes with nlme,
> but it has two groups instead of five.
>
> So I try
>
> a1 <- 1:10
> a2 <- 7:16
> t.test(a2,a1)
>
> getting t(18)=4.43, p=.0003224.  Then I try to do it with lme:
>
> a12 <- c(a1,a2)
> grp <- factor(rep(1:2,c(10,10)))
>
> Now, at this point, I think I should be able to do something like
> this:
> lme(a12~grp)
> or
> lme(a12~1|grp)
> but I keep getting an error message, "Invalid formula for
> groups."  So I tried making a groupedData object:
>
> data1 <- as.data.frame(cbind(a12,grp))
> gd1 <- groupedData(a12~1|grp,data=as.data.frame(cbind(a12,grp)))
>
> Now I can do
> lme(gd1)
> or
> lme(gd1,random=1|grp)
> or many other things, but nothing seems to yield anything like
> the t test, and I'm not even sure what the fixed effect test
> (with a p of .011 with summary(lme(gd1))) is testing.  (It
> doesn't seem to be about whether the grand mean of a12 is greater
> than zero.)  I've been studying the relevant documentaion,
> including Pinheiro and Bates's book, but I'm still stumped.  I'm
> sure I'm being very dense about something very simple, like,
> "This doesn't make any sense."  But why not?

Right, "This doesn't make any sense.".  To have a random effect you need a
set of randomly selected groups.  You don't have one.

You can do a paired t test this way, as then the pairs are a randomly
selected group (or could be in principle).

y <- rnorm(20)
pairs <- factor(rep(1:10, 2), labels=LETTERS[1:10])
treat <- factor(rep(c("Y", "N"), rep(10, 2)))
t.test(y ~ treat, paired=T)
data:  y by treat
t = 0.9827, df = 9, p-value = 0.3514

sample estimates:
mean of the differences
              0.3775932


You do need to specify random to lme:

> lme(y ~ treat, random = ~1 | pairs)
Linear mixed-effects model fit by REML
  Data: NULL
  Log-restricted-likelihood: -25.97613
  Fixed: y ~ treat
(Intercept)      treatY
  0.2533409  -0.3775932

Random effects:
 Formula: ~1 | pairs
        (Intercept)  Residual
StdDev:   0.2794975 0.8592174

Number of Observations: 20
Number of Groups: 10
> summary(.Last.value)
Linear mixed-effects model fit by REML
 Data: NULL
       AIC      BIC    logLik
  59.95227 63.51375 -25.97613

Random effects:
 Formula: ~1 | pairs
        (Intercept)  Residual
StdDev:   0.2794975 0.8592174

Fixed effects: y ~ treat
                 Value Std.Error DF    t-value p-value
(Intercept)  0.2533409 0.2857225  9  0.8866678  0.3983
treatY      -0.3775932 0.3842537  9 -0.9826665  0.3514
....


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Dec  3 14:00:25 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Dec 2001 14:00:25 +0100
Subject: [R] fitting models with the subset argument
In-Reply-To: <005101c17bf3$49710ea0$5c13070a@it.giustizia.it>
References: <005101c17bf3$49710ea0$5c13070a@it.giustizia.it>
Message-ID: <x28zckihlh.fsf@blueberry.kubism.ku.dk>

"MUGGEO VITO" <vito.muggeo at giustizia.it> writes:

> Hi all,
> I'd like to fit model where the terms both are in the data.frame, mydata
> say, and are vectors *not in the data.frame*.
> >obj<-glm(y~x, data=mydata) #works
> >Z<-pmax(mydata$x-20,0)
> >(length(Z)==length(obj$y))
> >[1] TRUE
> >update(obj,.~.+Z) #works
> 
> However for some subset it doesn't works:
> >obj<-glm(y~x, data=mydata, subset=f==1) #works
> >Z<-pmax(mydata$x[mydata$f==1]-20,0)
> >(length(Z)==length(obj$y))
> >[1] TRUE
> >update(obj,.~.+Z)  #DOESN'T WORK!!!
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames, :
>             variable lengths differ
> 
> Of course also the following doesn't work
> >glm(y~x +Z, mydata, subset=f==1) #doesn't work
> 
> but the following works
> >glm(y[mydata$f==1]~x[mydata$f==1] +Z, mydata)
> 
> How can I solve this problem?

The problem is that subsetting assumes that the variables have the
same length *before* subsetting, but Z is already subsetted. I would
expect that it worked if you just let 

Z<-pmax(mydata$x-20,0)
obj<-glm(y~x, data=mydata, subset=f==1)
update(obj,.~.+Z)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rdiaz at inner.es  Mon Dec  3 16:27:40 2001
From: rdiaz at inner.es (rdiaz@inner.es)
Date: Mon, 3 Dec 2001 15:27:40 -0000
Subject: [R] beginner's questions about lme, fixed and random effects
In-Reply-To: <200112031108.fB3B86o25617@cattell.psych.upenn.edu>
Message-ID: <20011203154019.5CBFA12EB@correo.inner.es>

Jonathan,

I don't think it makes a lof ot sense to try to use lme for a two-sample
t-test, since there is no random effect there. Maybe a comparison more in line
with what you were trying to do is to compare the results from lme with those
from a split-plot anova. Here is a silly example (where the value of the.data
is the sum of the treatment effects, the subject effects, and "an.error"):


## Silly example
subject.effects <- rep(seq(1:5),rep(2,5))
subjects.ids <- as.factor(rep(c("a","b","c","d","e"),rep(2,5)))
treatment.effects <- rep(c(0,4), 5)
treatment.ids <- as.factor(rep(c("trt1", "trt2"), 5))
an.error <- c(1,2,0,1,3,2,0,1,2,0)
the.data <- subject.effects + treatment.effects + an.error

summary(aov(the.data ~ Error(subjects.ids) + treatment.ids))
summary(lme(the.data ~ treatment.ids, random = ~1|subjects.ids))

## Of course, with this setup, those tests are equivalent to a paired-t:
t.test(the.data[treatment.ids == "trt1"], the.data[treatment.ids == "trt2"],
paired=TRUE)


Ramón

Jonathan Baron <baron at cattell.psych.upenn.edu> dijo:

> I'm trying to understand better the differences between fixed and
> random effects by running very simple examples in the nlme
> package.  My first attempt was to try doing a t-test in lme.
> This is very similar to the Rail example that comes with nlme,
> but it has two groups instead of five.
> 
> So I try
> 
> a1 <- 1:10
> a2 <- 7:16
> t.test(a2,a1)
> 
> getting t(18)=4.43, p=.0003224.  Then I try to do it with lme:
> 
> a12 <- c(a1,a2)
> grp <- factor(rep(1:2,c(10,10)))
> 
> Now, at this point, I think I should be able to do something like
> this:
> lme(a12~grp)
> or
> lme(a12~1|grp)
> but I keep getting an error message, "Invalid formula for
> groups."  So I tried making a groupedData object:
> 
> data1 <- as.data.frame(cbind(a12,grp))
> gd1 <- groupedData(a12~1|grp,data=as.data.frame(cbind(a12,grp)))
> 
> Now I can do
> lme(gd1)
> or
> lme(gd1,random=1|grp)
> or many other things, but nothing seems to yield anything like
> the t test, and I'm not even sure what the fixed effect test
> (with a p of .011 with summary(lme(gd1))) is testing.  (It
> doesn't seem to be about whether the grand mean of a12 is greater
> than zero.)  I've been studying the relevant documentaion,
> including Pinheiro and Bates's book, but I'm still stumped.  I'm
> sure I'm being very dense about something very simple, like,
> "This doesn't make any sense."  But why not?
> 
> All this is leading up to a real application to a much more
> complicated problem, but I think I need to understand the simple
> stuff first.
> 
> Jon Baron
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 



-- 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Dec  3 17:00:00 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Dec 2001 17:00:00 +0100
Subject: [R] beginner's questions about lme, fixed and random effects
In-Reply-To: <200112031108.fB3B86o25617@cattell.psych.upenn.edu>
References: <200112031108.fB3B86o25617@cattell.psych.upenn.edu>
Message-ID: <x2vgfogupr.fsf@blueberry.kubism.ku.dk>

baron at cattell.psych.upenn.edu (Jonathan Baron) writes:

> I'm trying to understand better the differences between fixed and
> random effects by running very simple examples in the nlme
> package.  My first attempt was to try doing a t-test in lme.
> This is very similar to the Rail example that comes with nlme,
> but it has two groups instead of five.
> 
> So I try
> 
> a1 <- 1:10
> a2 <- 7:16
> t.test(a2,a1)
> 
> getting t(18)=4.43, p=.0003224.  Then I try to do it with lme:
> 
> a12 <- c(a1,a2)
> grp <- factor(rep(1:2,c(10,10)))
> 
> Now, at this point, I think I should be able to do something like
> this:
> lme(a12~grp)
> or
> lme(a12~1|grp)
> but I keep getting an error message, "Invalid formula for
> groups."  So I tried making a groupedData object:
> 
> data1 <- as.data.frame(cbind(a12,grp))
> gd1 <- groupedData(a12~1|grp,data=as.data.frame(cbind(a12,grp)))
> 
> Now I can do
> lme(gd1)
> or
> lme(gd1,random=1|grp)
> or many other things, but nothing seems to yield anything like
> the t test, and I'm not even sure what the fixed effect test
> (with a p of .011 with summary(lme(gd1))) is testing.  (It
> doesn't seem to be about whether the grand mean of a12 is greater
> than zero.)  I've been studying the relevant documentaion,
> including Pinheiro and Bates's book, but I'm still stumped.  I'm
> sure I'm being very dense about something very simple, like,
> "This doesn't make any sense."  But why not?
> 
> All this is leading up to a real application to a much more
> complicated problem, but I think I need to understand the simple
> stuff first.

I think I have to disagree a little with previous correspondents. It
would be useful to have lme fit a model with no random effects, but it
currently will not. You can fool it in two ways to produce the t-test:

 indiv <- 1:20
 summary(lme(a12~grp,random=~1|indiv))
 one <- rep(1,20)
 summary(lme(a12~grp,random=~-1|one))

Notice that lme in the first version doesn't notice the aliasing of
the individual and the residual variance:

        (Intercept) Residual
StdDev:    2.834877 1.063079

where only the total variance (2.834877^2 + 1.063079^2) is really
identifiable. The fixed effect analysis is similar to lm():

Fixed effects: a12 ~ grp 
            Value Std.Error DF  t-value p-value
(Intercept)   5.5 0.9574271 18 5.744563  <.0001
grp2          6.0 1.3540064 18 4.431294   3e-04


In the other case, you get an essentially arbitrary random component
for the overall level:

        (Intercept) Residual
StdDev:    1.805342 3.027650

whereas the residual is correct. The random component causes the
intercept to have an increased variance:

Fixed effects: a12 ~ grp 
            Value Std.Error DF  t-value p-value
(Intercept)   5.5  2.043508 18 2.691450  0.0149
grp2          6.0  1.354006 18 4.431294  0.0003

I think this is wrong. The random level is unidentifiable, so you
should probably get an infinite SE for the intercept. 
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec  3 17:09:30 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Dec 2001 16:09:30 +0000 (GMT)
Subject: [R] beginner's questions about lme, fixed and random effects
In-Reply-To: <x2vgfogupr.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.4.31.0112031608340.31978-100000@gannet.stats>

On 3 Dec 2001, Peter Dalgaard BSA wrote:

> I think I have to disagree a little with previous correspondents. It
> would be useful to have lme fit a model with no random effects, but it
> currently will not. You can fool it in two ways to produce the t-test:

But gls() will, in ways that are compatible enough with lme().

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Dec  3 18:53:01 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 3 Dec 2001 18:53:01 +0100 (CET)
Subject: [R] Writing functions
In-Reply-To: <Pine.LNX.4.31.0112031608340.31978-100000@gannet.stats>
Message-ID: <Pine.LNX.4.33.0112031836470.12272-100000@tal.stat.umu.se>

I want to rewrite my function(s) so that they get the elegance of
lm, coxph, etc, with formulas. Where can I find a document that
describes, in one place, how to do it? I am now reading the code
of 'coxph' and 'lm', which gives me lots of functions to look up,
like match.call, match.arg, terms, eval, and so on, but I don't get 
the overview I need from that.

What I need to know is how formulas are 'decoded', and everything 
related to that.

Thanks for any hints.

G?ran 
-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Dec  3 20:28:00 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 3 Dec 2001 11:28:00 -0800 (PST)
Subject: [R] Writing functions
In-Reply-To: <Pine.LNX.4.33.0112031836470.12272-100000@tal.stat.umu.se>
Message-ID: <Pine.A41.4.33.0112031101140.70328-100000@homer01.u.washington.edu>

On Mon, 3 Dec 2001, [iso-8859-1] Göran Broström wrote:

> I want to rewrite my function(s) so that they get the elegance of
> lm, coxph, etc, with formulas. Where can I find a document that
> describes, in one place, how to do it? I am now reading the code
> of 'coxph' and 'lm', which gives me lots of functions to look up,
> like match.call, match.arg, terms, eval, and so on, but I don't get
> the overview I need from that.
>

Some of us have found that it's best to start using formulas without
waiting to understand how everything works.  For most purposes there is a
standard set of incantations to be uttered that give everything you need.
It's easier to understand after you have it working and can step through
to see what each piece does.  There's some explanation in
`S Programming' and in `Statistical Models in S'.

The hard work is done by model.frame() and model.matrix(), and the main
problem is that model.frame() really needs to be run in the calling
environment rather than inside your function (since that's where all the
variables are).


Let's start with

myfunction<-function(formula,data,someotheroption,
			na.action=getOption("na.action"))

You want to construct a model frame with all the variables needed for the
formula, and probably a design matrix.

    mf<-match.call() # get a copy of the call
    mf[[1]]<-as.name("model.frame") #turn into a call to model.frame
    mf$someotheroption<-NULL #remove options that don't go to model.frame
    mf<-eval(mf,parent.frame()) # run model.frame

Now you have a model frame you can make a model matrix.

    mt<-terms(formula, data=data)
    mm<-model.matrix(mt, mf)

The explicit terms() call is only necessary to handle the notation '.' in
a formula, meaning `all the other variables'; otherwise you could just do
    mm<-model.matrix(formula, mf)


Notes:
* You can define extra terms for your formulas (like strata() and
cluster() in coxph, Error() in aov, offset() in glm) but that is more complicated.
It usually requires a two-step process where you extract those special
terms and then rewrite the formula and re-run model.frame ()  [for
offset(), all this is handled internally by model.frame()]. Read those
functions to see ways of doing it.

* An alternative to evaluating in parent.frame() is to evaluate in
environment(formula), the place where the formula was defined.  This will
usually be the same and when it isn't will often be better. However, it
isn't compatible with S and might not be compatible with other functions.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mmiller3 at iupui.edu  Mon Dec  3 20:35:54 2001
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: 03 Dec 2001 14:35:54 -0500
Subject: [R] appending similar data frames?
Message-ID: <87adx06qqt.fsf@lumen.med.iupui.edu>

Dear R gang,

Can anyone help me sort out how to append one data frame to
another while adding a factor to distinguish which was the
original frame?

For example, I have two frames, x and y

> x
  exp size
1   a   10
2   b    9
3   c   10
4   d   12
5   e   11
 
> y 
  exp size
1   a   13
2   b   15
3   c   12
4   d   20
5   e   15

and I'd like to create a new frame that looks like

   exp size set
1    a   10   x
2    b    9   x
3    c   10   x
4    d   12   x
5    e   11   x
6    a   13   y
7    b   15   y
8    c   12   y
9    d   20   y
10   e   15   y

I know that I can do something like

> new.frame <- data.frame(c(as.vector(x$exp), as.vector(y$exp)))
> new.frame$size <- c(as.vector(x$size), as.vector(y$size))
> new.frame$set <- c(rep('x',times=length(x$exp)), rep('y',times=length(y$exp)))
> names(new.frame) <- c('exp','size','set')

Is there any generalized code out there that will do this sort of
thing for more complex data frames (still with the same structure
though)?  Or is there a simpler R idiom that does the same thing?

Mike
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Dec  3 20:41:31 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 3 Dec 2001 11:41:31 -0800 (PST)
Subject: [R] appending similar data frames?
In-Reply-To: <87adx06qqt.fsf@lumen.med.iupui.edu>
Message-ID: <Pine.A41.4.33.0112031139180.70328-100000@homer01.u.washington.edu>

On 3 Dec 2001, Michael A. Miller wrote:

> Dear R gang,
>
> Can anyone help me sort out how to append one data frame to
> another while adding a factor to distinguish which was the
> original frame?
>
> For example, I have two frames, x and y
>
> > x
>   exp size
> 1   a   10
> 2   b    9
> 3   c   10
> 4   d   12
> 5   e   11
>
> > y
>   exp size
> 1   a   13
> 2   b   15
> 3   c   12
> 4   d   20
> 5   e   15
>
> and I'd like to create a new frame that looks like
>
>    exp size set
> 1    a   10   x
> 2    b    9   x
> 3    c   10   x
> 4    d   12   x
> 5    e   11   x
> 6    a   13   y
> 7    b   15   y
> 8    c   12   y
> 9    d   20   y
> 10   e   15   y
>

rbind(cbind(x,set=rep("x",NROW(x))),
      cbind(y,set=rep("y",NROW(x)))
      )

will do it.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From murdoch at stats.uwo.ca  Mon Dec  3 22:29:53 2001
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 03 Dec 2001 16:29:53 -0500
Subject: [R] appending similar data frames?
In-Reply-To: <87adx06qqt.fsf@lumen.med.iupui.edu>
References: <87adx06qqt.fsf@lumen.med.iupui.edu>
Message-ID: <b0qn0uoourcor9a0hbmdqvcgknfbsedieh@4ax.com>

On 03 Dec 2001 14:35:54 -0500, you wrote in message
<87adx06qqt.fsf at lumen.med.iupui.edu>:

>Dear R gang,
>
>Can anyone help me sort out how to append one data frame to
>another while adding a factor to distinguish which was the
>original frame?

As long as the names match exactly in the two original frames, you
should be able to do it using "rbind" and "cbind":

Specifically:

 rbind( cbind(x, 'x'), cbind(y, 'y') )

What the cbind's are doing is adding a column to the original
dataframes giving their name.  Then the rbind glues the two dataframes
together.

If the names don't match exactly, then you should rename things so
they do.

Duncan Murdoch
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Mon Dec  3 23:08:34 2001
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Mon, 03 Dec 2001 18:08:34 -0400
Subject: [R] problems with nmle
Message-ID: <3C0BF7E2.A4756B83@umsanet.edu.bo>

Following the Indomethicin example in Pinheiro & Bates, chapter 6, 
page 277 etc, coming to the following comand:


fm2Indom.nlme <- update( fm1Indom.nlme,
  random = pdDiag(A1 + lrc1 + A2 ~ 1) )

debugging nlme gives the following output:

Browse[1]> n
debug: modelResid <- ~eval(model, data.frame(data, getParsNlme(plist, 
    fmap, rmapRel, bmap, groups, beta, bvec, b, level, N)))[naPat]
Browse[1]> n
debug: ww <- eval(modelExpression[[2]], envir = nlEnv)
Browse[1]> n
Error: subscript out of bounds


Here the fm1Indom.nlme object is calculated with a formula somewhat
different from the one given
in the text, because that gives convergence problems: 


 fm1Indom.nlme <- nlme(fm1Indom.lis, random=pdDiag(A1+lrc1+A2+lrc2 ~ 1)
,
                 control=list(msMaxIter=1000,
msVerbose=TRUE,niterEM=100, 
                       returnObject=TRUE))

The algorithm says it has not converged, although the tracing output
multiple
times indicate that the current solution is probably a solution. The
summary
of the obtained object is very close to that given in the book.

Kjetil Halvorsen
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Mon Dec  3 23:24:27 2001
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Mon, 3 Dec 2001 17:24:27 -0500 
Subject: [R] appending similar data frames?
Message-ID: <5429125E11E4D411AF7300805FE603A8014CF051@groexmbcr02.pfizer.com>

 >  From: mmiller3 at iupui.edu [mailto:mmiller3 at iupui.edu]
 >
 >  Dear R gang,
 >  
 >  Can anyone help me sort out how to append one data frame to
 >  another while adding a factor to distinguish which was the
 >  original frame?
 >  

Here is the function that I wrote to accomplish this task.  It will appear
in the next version of the gregmisc library (due sometime January).

concat  <-  function(..., names=NULL)
  {
    tmp  <-  list(...)
    if(is.null(names)) names  <- names(tmp)
    if(is.null(names)) names  <- sapply( as.list(match.call()), deparse)[-1]

    if( any(
            sapply(tmp, is.matrix)
            |
            sapply(tmp, is.data.frame) ) )
      { 
        len  <-  sapply(tmp, function(x) c(dim(x),1)[1] )
        len[is.null(len)]  <-  1
        data <-  rbind( ... )
      }
    else
      {
        len  <- sapply(tmp,length)
        data  <-  unlist(tmp)
        
      }

    namelist  <- factor(rep(names, len), levels=names)
        
    return( data.frame( data, source=namelist) )
  }

You use it like:

> x
  exp size
1   a   10
2   b    9
3   c   10
4   d   12
5   e   11
> y
  exp size
1   a   13
2   b   15
3   c   12
4   d   20
5   e   15
> concat(x,y)
   exp size source
1    a   10      x
2    b    9      x
3    c   10      x
4    d   12      x
5    e   11      x
6    a   13      y
7    b   15      y
8    c   12      y
9    d   20      y
10   e   15      y


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec  3 23:41:40 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Dec 2001 22:41:40 +0000 (GMT)
Subject: [R] appending similar data frames?
In-Reply-To: <5429125E11E4D411AF7300805FE603A8014CF051@groexmbcr02.pfizer.com>
Message-ID: <Pine.LNX.4.31.0112032240290.579-100000@gannet.stats>

As S-PLUS has a function concat() which does something different (like c,
strips names) could you use a different name?

B

On Mon, 3 Dec 2001, Warnes, Gregory R wrote:

>  >  From: mmiller3 at iupui.edu [mailto:mmiller3 at iupui.edu]
>  >
>  >  Dear R gang,
>  >
>  >  Can anyone help me sort out how to append one data frame to
>  >  another while adding a factor to distinguish which was the
>  >  original frame?
>  >
>
> Here is the function that I wrote to accomplish this task.  It will appear
> in the next version of the gregmisc library (due sometime January).
>
> concat  <-  function(..., names=NULL)
>   {
>     tmp  <-  list(...)
>     if(is.null(names)) names  <- names(tmp)
>     if(is.null(names)) names  <- sapply( as.list(match.call()), deparse)[-1]
>
>     if( any(
>             sapply(tmp, is.matrix)
>             |
>             sapply(tmp, is.data.frame) ) )
>       {
>         len  <-  sapply(tmp, function(x) c(dim(x),1)[1] )
>         len[is.null(len)]  <-  1
>         data <-  rbind( ... )
>       }
>     else
>       {
>         len  <- sapply(tmp,length)
>         data  <-  unlist(tmp)
>
>       }
>
>     namelist  <- factor(rep(names, len), levels=names)
>
>     return( data.frame( data, source=namelist) )
>   }
>
> You use it like:
>
> > x
>   exp size
> 1   a   10
> 2   b    9
> 3   c   10
> 4   d   12
> 5   e   11
> > y
>   exp size
> 1   a   13
> 2   b   15
> 3   c   12
> 4   d   20
> 5   e   15
> > concat(x,y)
>    exp size source
> 1    a   10      x
> 2    b    9      x
> 3    c   10      x
> 4    d   12      x
> 5    e   11      x
> 6    a   13      y
> 7    b   15      y
> 8    c   12      y
> 9    d   20      y
> 10   e   15      y
>
>
> LEGAL NOTICE
> Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From amaitour at pasteur.fr  Tue Dec  4 10:32:07 2001
From: amaitour at pasteur.fr (Aboubakar Maitournam)
Date: Tue, 04 Dec 2001 10:32:07 +0100
Subject: [R] memory issue trying to solve too large a problem using hclust
References: <7C4F091F6140D411A29300508B5C73B905BDEE83@usrymx04.merck.com> <3C07E637.9ECBAA58@EUnet.at>
Message-ID: <3C0C9817.5C7D3EE@pasteur.fr>

"cstrato at EUnet.at" wrote:

> Hi all, hi Matthew
>
> I would like to extend this question and take the opportunity
> to ask all the famous statisticians in this group for advice.
>
> First a personal comment :-)
> I am quite amused, how easy it is sometimes to find out on
> which project someone writing to this group is working:
> You mention that you want to cluster 12,500 objects. If I am
> correct, you are trying to cluster the 12,500 genes on the
> human Affymetrix GeneChip HgU95A, correct?
> (At least this is what  I am just trying to do)
>
> Now to the questions, which I wanted to ask for quite some time:
>
> Since the time of the paper:
> Eisen MB, Spellman PT, Brown PO, Botstein D.
> Cluster analysis and display of genome-wide expression patterns.
> Proc Natl Acad Sci U S A. 1998 Dec 8;95(25):14863-8.
> most biologists working on gene expression use hierarchical
> clustering to cluster all genes they have on their DNA-chips.
> Next year we will see chips containing more than 20,000 genes
> on one chip.
>
> Thus the question is:
> 1, What is the best way to cluster this amount of genes?
> Sometimes, I have heard, you should first use k-means to
> divide the genes into few subclusters, and use hierarchical
> clustering for the subclusters only. Is this correct?
>
> 2, When you do hierarchical clustering, what metric would
> be best to use?
> M.Eisen?s paper describes Pearson correlation as metric.
> Is there a way to implement this metric for use in hclust?
> Sorrowly, hclust supports only euclid and manhattan.
>
> 3, R/S contain some other cluster algorithms such as CLARA,
> PAM, FANNY, AGNES. However, I have never seen any paper on
> expression profiling using these algorithms. Is there a special
> reason, why these functions are not used?
>
> 4, Meanwhile, new methods for cluster analysis have been
> developed. For example, the book "Data Mining" of Han&Kamber
> mentions BIRCH, CURE, DBSCAN, OPTICS, DENCLUE, STINGS
> as some of these new algorithms.
> Would it make sense to use one of these methods?
> Does someone know if implementations of these functions
> do exist?
>
> 5, As I understand, there does not exist a single "best" cluster
> algorithm for this purpose, but you have to try different methods,
> and try to find out which one describes the data best.
> This is often easy when you cluster samples, but is hard to
> find out when trying to cluster 20,000 or even more genes.
>
> 6, Do there exist better methods other than clustering, which
> could group genes with similar behavior?
> PCA may be one method, but is based on dimensionality reduction,
> which may not be applicable in many cases?
>
> I know, that in this group questions to cluster many data have
> partly been answered, but I have the feeling, that many of these
> questions remain open, especially, when applied to expression
> profiling.
>
> I also know that many people working in this field use R/S
> as their main tool, so any help would be appreciated not only
> from me.
>
> Best regards
> Christian Stratowa
> ----------------------------------
> C.h.r.i.s.t.i.a.n  S.t.r.a.t.o.w.a
> V.i.e.n.n.a,  A.u.s.t.r.i.a
>
> "Wiener, Matthew" wrote:
>
> > Hi, all.
> >
> > I'm trying to cluster 12,500 objects using hclust from package mva.  The
> > distance matrix takes up nearly 600 MB.  The distance matrix also needs to
> > be copied when being passed to the fortran routine that actually does the
> > clustering (it's modified during the clustering), so that's 1200 MB.  I'm
> > actually on a machine with 2.5 GB of memory (and nothing else running), so I
> > thought I could pull this off.  The routine quits with the error "cannot
> > allocate a vector of size 609131 KB", which by its size seems to be another
> > copy of the distance matrix, I think the one needed by the fortran routine.
> > As far as I can tell from looking at the code, no additional objects of the
> > size of the distance matrix are used.
> >
> > After the error gc() says that the garbage collection threshold is 1433 MB.
> >
> > I'm wondering whether some additional copies of the distance matrix are
> > being made, and whether I could somehow stop them from being made.  Any
> > other suggestions for how I could get around the memory problem would also
> > be appreciated.  (I know of clara in the "cluster" package, but would like
> > to use hierarchical methods.)
> >
> > The function hierclust in multiv seems to demand even more memory, even when
> > bign = T.
> >
> > I am running R-1.3.1 on Sun OS 5.6.
> >
> > Thanks for any help.
> >
> > Matthew Wiener
> > Applied Computer Science and Mathematics Department
> > Merck Research Labs
> > Rahway, NJ  07065-0900
> > 732-594-5303
> >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

I m not famous statistician (so I will walk on eggs) but I know that the clustering
problem is not a trivial task and is not
completely solved. The most used technique in the clustering of genes expression
data is based
on hierarchical clustering which is depending of the choice of distance. There is
some consensus
about the distance based on correlation (take care because sometimes it's not the
distance is the
strict topological sense, in the sense of metric space). In addition the
hierarchical clustering is noise
depending. But related to the phylogenetic practices and the pioneer work of Eisen,
the hierarchical clustering is
the wide technique used in the area of the genes expression data analysis (for the
clustering).
The k-means as hierarchical clustering has arbitrary choices and can give many
solutions.
The methods which are in theoretical developments, which give the number of
clustering in data and determine the corresponding
classes are based on mixture models as the package mclust or some published work
base of simulated annealing.
But naturally it's difficult to change "les habitudes" (the usual practices) and
perhaps the stochastic background which is not  poetic on which these methods
are based , is explaining why they are not used.
Finally if you want to use the classical methods (pca, k-means, hierarchical
clustering) the best methods is to try at least two methods.
Notes there is also non classical methods based on graphs theory or neural networks
but the objective methods remains
pca  and stochastic methods.

Aboubakar Maitournam.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Tue Dec  4 18:28:48 2001
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Tue, 4 Dec 2001 12:28:48 -0500 
Subject: [R] appending similar data frames?
Message-ID: <5429125E11E4D411AF7300805FE603A8014CF060@groexmbcr02.pfizer.com>


I wasn't aware of the S-plus function 'concat'.  I'll rename my function
'combine' (unless someone else has a better suggestion).

-Greg


 >  -----Original Message-----
 >  From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
 >  Sent: Monday, December 03, 2001 5:42 PM
 >  To: Warnes, Gregory R
 >  Cc: 'mmiller3 at iupui.edu'; r-help at stat.math.ethz.ch
 >  Subject: RE: [R] appending similar data frames?
 >  
 >  
 >  As S-PLUS has a function concat() which does something 
 >  different (like c,
 >  strips names) could you use a different name?
 >  
 >  B
 >  
 >  On Mon, 3 Dec 2001, Warnes, Gregory R wrote:
 >  
 >  >  >  From: mmiller3 at iupui.edu [mailto:mmiller3 at iupui.edu]
 >  >  >
 >  >  >  Dear R gang,
 >  >  >
 >  >  >  Can anyone help me sort out how to append one data frame to
 >  >  >  another while adding a factor to distinguish which was the
 >  >  >  original frame?
 >  >  >
 >  >
 >  > Here is the function that I wrote to accomplish this 
 >  task.  It will appear
 >  > in the next version of the gregmisc library (due sometime 
 >  January).
 >  >
 >  > concat  <-  function(..., names=NULL)
 >  >   {
 >  >     tmp  <-  list(...)
 >  >     if(is.null(names)) names  <- names(tmp)
 >  >     if(is.null(names)) names  <- sapply( 
 >  as.list(match.call()), deparse)[-1]
 >  >
 >  >     if( any(
 >  >             sapply(tmp, is.matrix)
 >  >             |
 >  >             sapply(tmp, is.data.frame) ) )
 >  >       {
 >  >         len  <-  sapply(tmp, function(x) c(dim(x),1)[1] )
 >  >         len[is.null(len)]  <-  1
 >  >         data <-  rbind( ... )
 >  >       }
 >  >     else
 >  >       {
 >  >         len  <- sapply(tmp,length)
 >  >         data  <-  unlist(tmp)
 >  >
 >  >       }
 >  >
 >  >     namelist  <- factor(rep(names, len), levels=names)
 >  >
 >  >     return( data.frame( data, source=namelist) )
 >  >   }
 >  >
 >  > You use it like:
 >  >
 >  > > x
 >  >   exp size
 >  > 1   a   10
 >  > 2   b    9
 >  > 3   c   10
 >  > 4   d   12
 >  > 5   e   11
 >  > > y
 >  >   exp size
 >  > 1   a   13
 >  > 2   b   15
 >  > 3   c   12
 >  > 4   d   20
 >  > 5   e   15
 >  > > concat(x,y)
 >  >    exp size source
 >  > 1    a   10      x
 >  > 2    b    9      x
 >  > 3    c   10      x
 >  > 4    d   12      x
 >  > 5    e   11      x
 >  > 6    a   13      y
 >  > 7    b   15      y
 >  > 8    c   12      y
 >  > 9    d   20      y
 >  > 10   e   15      y
 >  >
 >  >
 >  > LEGAL NOTICE
 >  > Unless expressly stated otherwise, this message is 
 >  confidential and may be privileged. It is intended for the 
 >  addressee(s) only. Access to this E-mail by anyone else is 
 >  unauthorized. If you are not an addressee, any disclosure 
 >  or copying of the contents of this E-mail or any action 
 >  taken (or not taken) in reliance on it is unauthorized and 
 >  may be unlawful. If you are not an addressee, please inform 
 >  the sender immediately.
 >  > 
 >  -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
 >  -.-.-.-.-.-.-.-.-.-
 >  > r-help mailing list -- Read 
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cstrato at EUnet.at  Tue Dec  4 21:19:43 2001
From: cstrato at EUnet.at (cstrato@EUnet.at)
Date: Tue, 04 Dec 2001 21:19:43 +0100
Subject: [R] memory issue trying to solve too large a problem using hclust
References: <7C4F091F6140D411A29300508B5C73B905BDEE83@usrymx04.merck.com> <3C07E637.9ECBAA58@EUnet.at> <3C0C9817.5C7D3EE@pasteur.fr>
Message-ID: <3C0D2FD1.4FE44295@EUnet.at>

Dear Aboubakar

Thank you for your reply. I know that clustering is not a trivial
issue, this was the reason I thought that I could start a discussion.
It may not seem to belong to r-help but since many people (including
me) use R/S for expression profiling, I thought I will try it anyhow.

Since you mention  distance based on correlation, this was my
question #2: Is it possible, that R/S can also support it for hclust?
Since I use S/R as my main packages, it it a severe limitation to
have a limited choice of metrices.

You mention that k-means can have many solutions, but as far, as
I know, the results of agglomerative hierarchical clustering
depend on  the order of the data? For this reason, one company
(Applied Maths) does even calculate the significance of the branches
of a tree using bootstrap techniques. Could this possibly be done
also with R/S?

Furthermore, if I remember correctly, someone has mentioned that
divisive hierarchical clustering would be preferrable to agglomerative
clustering, but there exist no algorithms to calculate it in a reasonable
time. (Could it be that this was mentioned by Prof. Ripley?)

Quite some time ago I have tried the different cluster algorithms
and metrices available in S/R and at that time, DIANA  seemed to give
the best results. I think it is sorry, that more recent cluster algorithms
such as CURE etc (see question #4) are not implemented so that
it is not possible to try them and compare them with the currently
used ones.

(BTW, mclust seems to give especially bad results, but I do not
know why?)

Personally, I would prefer to have a function, which would cluster
data using a couple of different cluster algorithms, then identify those
branches in a tree which always turn up to be in the same sub-cluster,
which could then be considered as "stable".

Best regards
Christian Stratowa

Aboubakar Maitournam wrote:

>
> I m not famous statistician (so I will walk on eggs) but I know that the clustering
> problem is not a trivial task and is not
> completely solved. The most used technique in the clustering of genes expression
> data is based
> on hierarchical clustering which is depending of the choice of distance. There is
> some consensus
> about the distance based on correlation (take care because sometimes it's not the
> distance is the
> strict topological sense, in the sense of metric space). In addition the
> hierarchical clustering is noise
> depending. But related to the phylogenetic practices and the pioneer work of Eisen,
> the hierarchical clustering is
> the wide technique used in the area of the genes expression data analysis (for the
> clustering).
> The k-means as hierarchical clustering has arbitrary choices and can give many
> solutions.
> The methods which are in theoretical developments, which give the number of
> clustering in data and determine the corresponding
> classes are based on mixture models as the package mclust or some published work
> base of simulated annealing.
> But naturally it's difficult to change "les habitudes" (the usual practices) and
> perhaps the stochastic background which is not  poetic on which these methods
> are based , is explaining why they are not used.
> Finally if you want to use the classical methods (pca, k-means, hierarchical
> clustering) the best methods is to try at least two methods.
> Notes there is also non classical methods based on graphs theory or neural networks
> but the objective methods remains
> pca  and stochastic methods.
>
> Aboubakar Maitournam.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tdlong at uci.edu  Tue Dec  4 23:53:48 2001
From: tdlong at uci.edu (Tony Long)
Date: Tue, 4 Dec 2001 14:53:48 -0800
Subject: [R] mclust package and modelid = VEE
Message-ID: <p05001914b83303751b81@[128.200.28.179]>

All:

	Is the VEE option not implemented for programming reasons or 
does it not make statistical sense?  It is described in the Celeux 
and Govaert reference.  I am interested in holding orientation and 
shape constant but varying volume.  Tony
-- 

Tony Long

Ecology and Evolutionary Biology
Steinhaus Hall
University of California at Irvine
Irvine, CA
92697-2525

Tel:  (949) 824-2562   (office)
Tel:  (949) 824-5994   (lab)
Fax: (949) 824-2181

email:  tdlong at uci.edu
http://hjmuller.bio.uci.edu/~labhome/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From duncan at research.bell-labs.com  Wed Dec  5 00:12:31 2001
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Tue, 4 Dec 2001 18:12:31 -0500
Subject: [R] Re: New package: g.data
In-Reply-To: <15371.42846.422155.287658@gargle.gargle.HOWL>; from brahm@alum.mit.edu on Mon, Dec 03, 2001 at 11:25:02AM -0500
References: <15371.42846.422155.287658@gargle.gargle.HOWL>
Message-ID: <20011204181231.F16986@jessie.research.bell-labs.com>


Hi David.

 The idea of your package is very nice. It is something that I have
been thinking about, and generally accessing data from sources other
than R, including different formats, different applications
(databases, Java, Perl, Python, etc.)  and so on.

 I am sorry I didn't see follow up on your original post because I
might have been able to make your life simpler.  As of today, I
committed code to allow one to extend the way R resolves variables in
the search path. This is now in the R-1.4.0 code base which will be
released in 2 weeks time.

I created a package - RObjectTables - that exploits this change to the
way R looks for data in elements of the search path. This allows one
to define a class of search path element much like what you have done
and have R query it using functions. The package is available
at 
  http://www.omegahat.org/RObjectTables
and will be moved into the R source after the upcoming release.

I believe it will allow your code to avoid the g.data.save() and also
for users to use a regular attach() call.  In this sense, it would be
nice to have a single interface that we can extend.

If you have any interest in using this, I'd be happy to help.

Thanks for the good work.
 D.

David Brahm wrote:
> 
> A new package "g.data" is available on CRAN, to create and maintain databases
> that work more like the S-Plus model.
> 
> Here's the official Description for g.data (v1.2):
>   Create and maintain delayed-data packages (DDP's).  Data stored in
>   a DDP are available on demand, but do not take up memory until requested.
>   You attach a DDP with g.data.attach(), then read from it and assign to it in
>   a manner similar to S-Plus, except that you must run g.data.save() to
>   actually commit to disk.
> 
> Here's a very abbreviated (Unix) example:
>   g.data.attach("/tmp/mydir")             # Open package:mydir in pos=2
>   assign("x1", matrix(1, 1000, 1000), 2)  # Put data there
>   g.data.save()                           # Commit to disk
>   detach(2)                               # Detach package:mydir
>   g.data.attach("/tmp/mydir")             # Re-attach it, no resources used
>   dim(x1)                                 # x1 is loaded only when needed!
>   find("x1")                              # It still lives in package:mydir
> 
> g.data is the end result of my post "Reading and writing to S-like databases",
> sent to R-help on Sep 28, 2001.  Thanks to all who responded, especially
> Dr. Agustin Lobo <alobo at ija.csic.es> and (by reference) Ray Brownrigg
> <Ray.Brownrigg at mcs.vuw.ac.nz>, who suggested using delay(); Martin Maechler
> <maechler at stat.math.ethz.ch>, Thomas Lumley <tlumley at u.washington.edu>, Brian
> D. Ripley <ripley at stats.ox.ac.uk>, and Peter Dalgaard
> <p.dalgaard at biostat.ku.dk>, who helped me with platform independence issues;
> and Kurt Hornik <Kurt.Hornik at ci.tuwien.ac.at>, who cleaned it up for CRAN.
> 
> I have one concern: g.data relies heavily on delay(), whose documentation says:
>   This is an experimental feature and its addition is purely for
>   evaluation purposes.
> Is there any plan to deprecate delay()?
> 
> Feedback is welcome!
> -- 
>                               -- David Brahm (brahm at alum.mit.edu)
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-announce mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From duncan at research.bell-labs.com  Wed Dec  5 01:25:03 2001
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Tue, 4 Dec 2001 19:25:03 -0500
Subject: [R] is auto-save possible?
In-Reply-To: <51F9C42DA15CD311BD220008C707D81903DC839A@usrymx10.merck.com>; from andy_liaw@merck.com on Mon, Nov 12, 2001 at 03:52:45PM -0500
References: <51F9C42DA15CD311BD220008C707D81903DC839A@usrymx10.merck.com>
Message-ID: <20011204192503.G16986@jessie.research.bell-labs.com>


The question of performing auto-saves every n commands goes back
several weeks, but hopefully the delay in responding is worthwhile.
The upcoming version 1.4.0 of R has a facility (addTaskCallback()q) by
which one can register a collection of functions that are invoked at
the end of each (successful) top-level expression.  This can be used
perform auto-saves, and other things such as updating GUI displays,
commiting changes to databases (i.e. transactions), validation of
objects, etc. One can even examine the expression that was just
evaluated and check if it was an assignment, or if it changed an important
variable that should be saved.

 There is a description of the mechanism at
  http://developer.r-project.org/TaskHandlers.pdf

Unlike other suggestions, I think doing auto-saves on the basis of
time is not the ideal approach. As others have pointed out, it relies
on the nature of the event loop which is neither portable or likely to
remain exactly the same.  After 1.4.0 is released, I plan to add
timers and readers/callbacks for connections and that will give
different features and also characteristics.

I hope the addTaskCallback() does what you want. 
 D.


Liaw, Andy wrote:
> Dear R-help,
> 
> This is just a wishlist item:  Is it possible at all to make R (optionally)
> automagically do save.image() periodically (e.g., every fixed number of
> commands or >= fixed amount of time)?  
> 
> The reason I asked is that I frequently run R-1.3.1 inside XEmacs 21.4.5/ESS
> 5.1.19 under WinNT, and had seen Rterm.exe crashed a few times for no
> apparent reason (and not reproducible).  When that happens, I lost all the
> objects created in that R session and had to re-run the script (which could
> be time consuming).  At one time R crashed right in the middle of quitting,
> which corrupted the .Rdata file.  Luckily I had a backup that was fairly
> recent that I didn't loose everything.  (Admittedly, auto-save wouldn't help
> this last problem though.)
> 
> Cheers,
> Andy
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jonqli at labs.agilent.com  Wed Dec  5 03:20:14 2001
From: jonqli at labs.agilent.com (Jonathan Li)
Date: Tue, 04 Dec 2001 18:20:14 -0800
Subject: [R] trouble with R CMD INSTALL for building my own library
Message-ID: <3C0D845E.D71CE9E4@labs.agilent.com>

Hi,

I have built a library that consists of a piece of C code and some R
functions.
To build it into a library that I can load using library() command, I
have followed "Writing R Extensions"
and made sub-directories such as mylib/R and mylib/src. But when I run R
CMD INSTALL mylib, nothing seems to
be happening with src directory, i.e., no C compiling. I have probably
missed
some key steps. But after reading very carefully "Writing R Extension",
I conclude that I don't need to
write my own Makefile in src since R CMD INSTALL will use the default in
/usr/lib/R/etc/Makeconf
Here is a copy of Makeconf file. In addition, R CMD check and R CMD
build all ran without running "make". Is this 
the way it is supposed to be?  (no error messages encountered).

Where is the problem? Thanks in advance!

BLAS_LIBS = -L. -lblas
CC = gcc
CFLAGS = -g -O2
CPICFLAGS = -fPIC
CPPFLAGS = -I/usr/local/include
CXX = c++
CXXCPP = c++ -E
CXXFLAGS = -g -O2
CXXPICFLAGS = -fPIC
ECHO_C = 
ECHO_N = -n
ECHO_T = 
FC = g77
FFLAGS = -g -O2
FLIBS =  -lg2c -lm -L/usr/lib/gcc-lib/i386-linux/2.95.4 -lm
FPICFLAGS = -fPIC
F2C = 
F2CFLAGS = 
LIBM = -lm
LIBR = -L$(R_HOME)/bin -lR
LIBS =  -L/usr/local/lib  -lz -lreadline -ldl -lncurses -lm
LIBPATHS =  -L/usr/local/lib
LIBTOOL = $(SHELL) $(R_HOME)/bin/libtool
SHELL = /bin/sh
SHLIB_CFLAGS = 
SHLIB_CXXFLAGS = 
SHLIB_CXXLD = c++
SHLIB_CXXLDFLAGS = -shared
SHLIB_EXT = so
SHLIB_FFLAGS = 
SHLIB_LD = gcc
SHLIB_LDFLAGS = -shared
SHLIB_LIBADD = 
SHLIB_LINK = $(SHLIB_LD) $(SHLIB_LDFLAGS) $(LDFLAGS)

-- 
Jonathan Q. Li, PhD
Agilent Technologies Laboratory
Palo Alto, California, USA
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gumpleon at hotmail.com  Wed Dec  5 07:05:34 2001
From: gumpleon at hotmail.com (Gang Liang)
Date: Tue, 04 Dec 2001 22:05:34 -0800
Subject: [R] Questions about piecewise spline fitting
Message-ID: <F144mGvweQaWGckg0pr0002056c@hotmail.com>

Hi All,

I want to fit a piecewise spline of degree 1, i.e. a spline consisting of a 
straight line over each piece. I downloaded the R package pspline, then I 
have following questions:

1. in the program, the degree of the spline is specified by 2*norder-1. Why 
do they adopt such scheme that we can only fit a spline with odd degree?

2. norder cannot be set to 1. Is there any specific reason for doing so?

Maybe I need to code this by myself. So I'd like to hear your advices.

Thanks in advance,
Gang


_________________________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Kurt.Hornik at ci.tuwien.ac.at  Wed Dec  5 08:22:21 2001
From: Kurt.Hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Wed, 5 Dec 2001 08:22:21 +0100
Subject: [R] trouble with R CMD INSTALL for building my own library
In-Reply-To: <3C0D845E.D71CE9E4@labs.agilent.com>
References: <3C0D845E.D71CE9E4@labs.agilent.com>
Message-ID: <15373.52013.609315.404375@mithrandir.hornik.net>

>>>>> Jonathan Li writes:

> Hi,

> I have built a library that consists of a piece of C code and some R
> functions.  To build it into a library that I can load using library()
> command, I have followed "Writing R Extensions" and made
> sub-directories such as mylib/R and mylib/src.

It actually is 'package' and not 'library'.

> But when I run R CMD INSTALL mylib, nothing seems to be happening with
> src directory, i.e., no C compiling. I have probably missed some key
> steps. But after reading very carefully "Writing R Extension", I
> conclude that I don't need to write my own Makefile in src since R CMD
> INSTALL will use the default in /usr/lib/R/etc/Makeconf Here is a copy
> of Makeconf file. In addition, R CMD check and R CMD build all ran
> without running "make". Is this the way it is supposed to be?  (no
> error messages encountered).

Sounds strange.  You really have

	mylib/src/foo.c

(note the extension!) and nothing happens?

-k
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vito.muggeo at giustizia.it  Wed Dec  5 10:39:45 2001
From: vito.muggeo at giustizia.it (MUGGEO VITO)
Date: Wed, 5 Dec 2001 10:39:45 +0100
Subject: [R] Questions about piecewise spline fitting
References: <F144mGvweQaWGckg0pr0002056c@hotmail.com>
Message-ID: <002001c17d70$d1780f00$5c13070a@it.giustizia.it>

Hi,
What you need is just the bs() or ns() functions in the library splines in
the R-software. You have to specify the knots and can specify the degree.
For instance:

library(splines)
bs(1:20, knots=c(5,11), degree=1) #performs three #straight lines with
break-point at x=5 and 11 for the variable 1:20
lm(y~bs(1:20, knots=c(5,11), degree=1)) #piecewise linear regression

Common "problem" is that the beta parameters for the pseudo-variables
inducted by bs() are not interpretable (i.e. in linear case they don't
represents the slopes in each piece).
best,
vito


----- Original Message -----
From: "Gang Liang" <gumpleon at hotmail.com>
To: <r-help at hypatia.math.ethz.ch>
Sent: Wednesday, December 05, 2001 7:05 AM
Subject: [R] Questions about piecewise spline fitting


> Hi All,
>
> I want to fit a piecewise spline of degree 1, i.e. a spline consisting of
a
> straight line over each piece. I downloaded the R package pspline, then I
> have following questions:
>
> 1. in the program, the degree of the spline is specified by 2*norder-1.
Why
> do they adopt such scheme that we can only fit a spline with odd degree?
>
> 2. norder cannot be set to 1. Is there any specific reason for doing so?
>
> Maybe I need to code this by myself. So I'd like to hear your advices.
>
> Thanks in advance,
> Gang
>
>
> _________________________________________________________________
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From amaitour at pasteur.fr  Wed Dec  5 11:14:50 2001
From: amaitour at pasteur.fr (Aboubakar Maitournam)
Date: Wed, 05 Dec 2001 11:14:50 +0100
Subject: [R] memory issue trying to solve too large a problem using hclust
References: <7C4F091F6140D411A29300508B5C73B905BDEE83@usrymx04.merck.com> <3C07E637.9ECBAA58@EUnet.at> <3C0C9817.5C7D3EE@pasteur.fr> <3C0D2FD1.4FE44295@EUnet.at>
Message-ID: <3C0DF39A.7A300B95@pasteur.fr>

"cstrato at EUnet.at" wrote:

> Dear Aboubakar
>
> Thank you for your reply. I know that clustering is not a trivial
> issue, this was the reason I thought that I could start a discussion.
> It may not seem to belong to r-help but since many people (including
> me) use R/S for expression profiling, I thought I will try it anyhow.
>
> Since you mention  distance based on correlation, this was my
> question #2: Is it possible, that R/S can also support it for hclust?
> Since I use S/R as my main packages, it it a severe limitation to
> have a limited choice of metrices.
>
> You mention that k-means can have many solutions, but as far, as
> I know, the results of agglomerative hierarchical clustering
> depend on  the order of the data? For this reason, one company
> (Applied Maths) does even calculate the significance of the branches
> of a tree using bootstrap techniques. Could this possibly be done
> also with R/S?
>
> Furthermore, if I remember correctly, someone has mentioned that
> divisive hierarchical clustering would be preferrable to agglomerative
> clustering, but there exist no algorithms to calculate it in a reasonable
> time. (Could it be that this was mentioned by Prof. Ripley?)
>
> Quite some time ago I have tried the different cluster algorithms
> and metrices available in S/R and at that time, DIANA  seemed to give
> the best results. I think it is sorry, that more recent cluster algorithms
> such as CURE etc (see question #4) are not implemented so that
> it is not possible to try them and compare them with the currently
> used ones.
>
> (BTW, mclust seems to give especially bad results, but I do not
> know why?)
>
> Personally, I would prefer to have a function, which would cluster
> data using a couple of different cluster algorithms, then identify those
> branches in a tree which always turn up to be in the same sub-cluster,
> which could then be considered as "stable".
>
> Best regards
> Christian Stratowa
>
> Aboubakar Maitournam wrote:
>
> >
> > I m not famous statistician (so I will walk on eggs) but I know that the clustering
> > problem is not a trivial task and is not
> > completely solved. The most used technique in the clustering of genes expression
> > data is based
> > on hierarchical clustering which is depending of the choice of distance. There is
> > some consensus
> > about the distance based on correlation (take care because sometimes it's not the
> > distance is the
> > strict topological sense, in the sense of metric space). In addition the
> > hierarchical clustering is noise
> > depending. But related to the phylogenetic practices and the pioneer work of Eisen,
> > the hierarchical clustering is
> > the wide technique used in the area of the genes expression data analysis (for the
> > clustering).
> > The k-means as hierarchical clustering has arbitrary choices and can give many
> > solutions.
> > The methods which are in theoretical developments, which give the number of
> > clustering in data and determine the corresponding
> > classes are based on mixture models as the package mclust or some published work
> > base of simulated annealing.
> > But naturally it's difficult to change "les habitudes" (the usual practices) and
> > perhaps the stochastic background which is not  poetic on which these methods
> > are based , is explaining why they are not used.
> > Finally if you want to use the classical methods (pca, k-means, hierarchical
> > clustering) the best methods is to try at least two methods.
> > Notes there is also non classical methods based on graphs theory or neural networks
> > but the objective methods remains
> > pca  and stochastic methods.
> >
> > Aboubakar Maitournam.
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

Effectively there are many problems related to clustering which are not solved by R,
for the analysis of expression profiling.  However some packages dedicated to that task
as GeneSom are beginning to be released in R. The commercial softwares solve some
clustering problems
not all.  The mclust package related to paper published in Bioinformatics have some
restrictions (number of classes,.....).


Aboubakar Maitournam.




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Wed Dec  5 10:37:33 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 5 Dec 2001 10:37:33 +0100 (CET)
Subject: [R] rbind and data.frame
In-Reply-To: <Pine.LNX.4.31.0112032240290.579-100000@gannet.stats>
Message-ID: <Pine.LNX.4.33.0112051032270.15341-100000@tal.stat.umu.se>

Version 1.3.1  (2001-08-31) (RH 7.2):

> dat <- data.frame(x = 1, y = 2)
> x <- matrix(0, ncol = 2, nrow = 2)
> x
     [,1] [,2]
[1,]    0    0
[2,]    0    0
> dat
  x y
1 1 2
> rbind(dat, x)
  x y
1 1 2
2 0 0

I expected

> rbind(dat, x)
  x y
1 1 2
2 0 0
3 0 0

Is my expectation wrong?

G?ran Brostr?m

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec  5 11:50:50 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 05 Dec 2001 11:50:50 +0100
Subject: [R] rbind and data.frame
In-Reply-To: <Pine.LNX.4.33.0112051032270.15341-100000@tal.stat.umu.se>
References: <Pine.LNX.4.33.0112051032270.15341-100000@tal.stat.umu.se>
Message-ID: <x24rn62b5h.fsf@blueberry.kubism.ku.dk>

G?ran Brostr?m <gb at stat.umu.se> writes:

> Version 1.3.1  (2001-08-31) (RH 7.2):
> 
> > dat <- data.frame(x = 1, y = 2)
> > x <- matrix(0, ncol = 2, nrow = 2)
> > x
>      [,1] [,2]
> [1,]    0    0
> [2,]    0    0
> > dat
>   x y
> 1 1 2
> > rbind(dat, x)
>   x y
> 1 1 2
> 2 0 0
> 
> I expected
> 
> > rbind(dat, x)
>   x y
> 1 1 2
> 2 0 0
> 3 0 0
> 
> Is my expectation wrong?

Maybe and maybe not... The help page has

     If you want to combine other objects with data frames, it may be
     necessary to coerce them to data frames first.

and the internal logic in rbind.data.frame is that everything that is
not a data frame or a list is a vector. I'm slightly puzzled as to why
we don't check the lengths but quietly truncate or recycle (whereas
the corresponding cbind code does protest even though we don't always
want it to...)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Wed Dec  5 12:41:51 2001
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed, 5 Dec 2001 06:41:51 -0500
Subject: [R] Questions about piecewise spline fitting
In-Reply-To: <F144mGvweQaWGckg0pr0002056c@hotmail.com>
References: <F144mGvweQaWGckg0pr0002056c@hotmail.com>
Message-ID: <20011205064151.074a6fe2.fharrell@virginia.edu>

If all you want is a linear spline do something like

   x + pmax(x-a,0) + pmax(x-b,0)

in a model, where knots are a and b.

Frank Harrell


On Tue, 04 Dec 2001 22:05:34 -0800
Gang Liang <gumpleon at hotmail.com> wrote:

> Hi All,
> 
> I want to fit a piecewise spline of degree 1, i.e. a spline consisting of a 
> straight line over each piece. I downloaded the R package pspline, then I 
> have following questions:
> 
> 1. in the program, the degree of the spline is specified by 2*norder-1. Why 
> do they adopt such scheme that we can only fit a spline with odd degree?
> 
> 2. norder cannot be set to 1. Is there any specific reason for doing so?
> 
> Maybe I need to code this by myself. So I'd like to hear your advices.
> 
> Thanks in advance,
> Gang
> 
> 
> _________________________________________________________________
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ajsmit at botzoo.uct.ac.za  Wed Dec  5 12:49:08 2001
From: ajsmit at botzoo.uct.ac.za (Smit, A, Albertus, Dr)
Date: Wed, 5 Dec 2001 13:49:08 +0200
Subject: [R] Histograms per coding variable
Message-ID: <E16BaY1-0000cm-00@mail2.uct.ac.za>

Dear all

I have a dataset that looks like:

	fr.wt		site
1	4400		glen
2	235		glen
3	225		glen
'	'		'
'	'		'
'	'		'
82	550		glen
83	550		kom
84	550		kom
'	'		'
'	'		'
'	'		'
191	820		kom
192	2000		soet
'	'		'
'	'		'

I need to do a series of histograms for each of the codes, levels or 
factors in 'site'.  For the first one, 'glen', I would do:

>hist(fr.wt[1:82], nclass = 20)

for the second, 'kom':

>hist(fr.wt[83:191], nclass = 20)

and so on.

Is there are more elegant way to do this without having to use the 
fr.wt[1:82] bit?  I.e., how else can one extract the fr.wt data 
relevant to each code in the 'site' column?  If there is, say, 20 
codes in the 'site' column, how can one produce a histogram for each 
without having the retype the hist() bit for each code individually?

I am sure there is an easy solution which I am overlooking.

Thanks for the help,
Albertus


Dr Albertus J. Smit
Department of Botany
University of Cape Town
PO Box Rondebosch
7700
SOUTH AFRICA
Tel. 689 3032
Fax. 650 4041

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Wed Dec  5 12:05:41 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 5 Dec 2001 12:05:41 +0100 (CET)
Subject: [R] rbind and data.frame
In-Reply-To: <x24rn62b5h.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.4.33.0112051146250.15421-100000@tal.stat.umu.se>

On 5 Dec 2001, Peter Dalgaard BSA wrote:

> G?ran Brostr?m <gb at stat.umu.se> writes:
> 
> > Version 1.3.1  (2001-08-31) (RH 7.2):
> > 
> > > dat <- data.frame(x = 1, y = 2)
> > > x <- matrix(0, ncol = 2, nrow = 2)
> > > x
> >      [,1] [,2]
> > [1,]    0    0
> > [2,]    0    0
> > > dat
> >   x y
> > 1 1 2
> > > rbind(dat, x)
> >   x y
> > 1 1 2
> > 2 0 0
> > 
> > I expected
> > 
> > > rbind(dat, x)
> >   x y
> > 1 1 2
> > 2 0 0
> > 3 0 0
> > 
> > Is my expectation wrong?
> 
> Maybe and maybe not... The help page has
> 
>      If you want to combine other objects with data frames, it may be
>      necessary to coerce them to data frames first.
> 
> and the internal logic in rbind.data.frame is that everything that is
> not a data frame or a list is a vector. I'm slightly puzzled as to why
> we don't check the lengths but quietly truncate or recycle (whereas
> the corresponding cbind code does protest even though we don't always
> want it to...)

The help page also have:

     The functions `cbind' and `rbind' are generic, with methods for
     data frames.  The data frame method will be used if an argument is
     a data frame and the rest are vectors or matrices. 
                                           ^^^^^^^^^^^
Maybe somewhat misleading? However, this is the way to do it:

> dat <- data.frame(x = 1, y = 2)
> x <- matrix(NA, ncol = 2, nrow = 2)
> x <- data.frame(x)     ## Why no 'names =' arg?
> names(x) <- names(dat) ## Necessary 
> rbind(dat, x)
   x  y
1  1  2
2 NA NA
3 NA NA

My real problem is how to create a data frame in a sequentially growing
manner, when I know the final size (no of cases). I want to avoid to
call 'rbind' many times, and instead create an 'empty' data frame in
one call, and then fill it. Are there better ways of doing this?

G?ran
-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Wed Dec  5 13:22:22 2001
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Wed, 5 Dec 2001 07:22:22 -0500 (EST)
Subject: [R] Histograms per coding variable
In-Reply-To: <E16BaY1-0000cm-00@mail2.uct.ac.za>
Message-ID: <Pine.LNX.4.30.0112050719300.17651-100000@bolker.zoo.ufl.edu>


 Something like

tapply(fr.wt,site,hist,nclass=20)

e.g.:

a <- runif(100)
f <- factor(rep(1:10,rep(10,10)))
par(mfrow=c(3,4))
tapply(a,f,hist)

On Wed, 5 Dec 2001, Smit, A, Albertus, Dr wrote:

> Dear all
>
> I have a dataset that looks like:
>
> 	fr.wt		site
> 1	4400		glen
> 2	235		glen
> 3	225		glen
> '	'		'
> '	'		'
> '	'		'
> 82	550		glen
> 83	550		kom
> 84	550		kom
> '	'		'
> '	'		'
> '	'		'
> 191	820		kom
> 192	2000		soet
> '	'		'
> '	'		'
>
> I need to do a series of histograms for each of the codes, levels or
> factors in 'site'.  For the first one, 'glen', I would do:
>
> >hist(fr.wt[1:82], nclass = 20)
>
> for the second, 'kom':
>
> >hist(fr.wt[83:191], nclass = 20)
>
> and so on.
>
> Is there are more elegant way to do this without having to use the
> fr.wt[1:82] bit?  I.e., how else can one extract the fr.wt data
> relevant to each code in the 'site' column?  If there is, say, 20
> codes in the 'site' column, how can one produce a histogram for each
> without having the retype the hist() bit for each code individually?
>
> I am sure there is an easy solution which I am overlooking.
>
> Thanks for the help,
> Albertus
>
>
> Dr Albertus J. Smit
> Department of Botany
> University of Cape Town
> PO Box Rondebosch
> 7700
> SOUTH AFRICA
> Tel. 689 3032
> Fax. 650 4041
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Wed Dec  5 12:32:26 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 5 Dec 2001 12:32:26 +0100 (CET)
Subject: [R] rbind and data.frame
In-Reply-To: <a05010404b833c0fc7774@[134.214.32.69]>
Message-ID: <Pine.LNX.4.33.0112051229250.15483-100000@tal.stat.umu.se>

On Wed, 5 Dec 2001, Stephane Dray wrote:

> I think that the problem  is that you want to bind a matrix and a
> data frame. You must transform your dataframe in a matrix (or the
> matrix in dataframe) :
> >  rbind(as.matrix(dat),x)
>    V1 V2
> 1  1  2
> 2  0  0
> 3  0  0
> >  xdat_as.data.frame(x)
> >  names(x)_names(dat)
> >  rbind(dat,x)
>    x y
> 1 1 2
> 2 0 0
> 3 0 0
> 
> If you bind the matrix and the dataframe, only the first column of
> the matrix is added as a row ... and i don't know (and understand)
> why !!

That's because, as Peter explained, the matrix is viewed as a vector
by rbind, and the rule is 'columnwise' (ala Fortran).

[...]

G?ran

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From emmanuel.charpentier at sap.ap-hop-paris.fr  Wed Dec  5 13:47:54 2001
From: emmanuel.charpentier at sap.ap-hop-paris.fr (Emmanuel Charpentier)
Date: Wed, 05 Dec 2001 13:47:54 +0100
Subject: [R] (Meta-analysis) How to build|fake a [n]lm[e] object ?
Message-ID: <3C0E177A.C43C9B83@sap.ap-hop-paris.fr>

Dear all,

I recently had to review the current litterature about some medical treatment
with two possible variants (let's call them A and B). I collected all available
prospective randomized trials about this treatment : I got four trials for the
A variant and three for the B variant, all studies comparing one variant to a
"suitably choosen" placebo.

Two classes of variables are of interest here :
	a) the net effect of the treatment, which is assessed by some (set of)
numerical
	   values, with distributions not too far from the normal ;
	b) the side effects of the treatment, assessed by the number of occurences of
	   (a set of) undesirable events.

The papers report :
	a) for the numerical variables : sample size, mean and SD (or SE, which allows
to 	   recompute SD) of each group, plus some test statistic (usually Student's
T) ;
	b) for events : the sample size and number of events in each group, plus some
	   test statistic (usually chi-square, sometimes incorrectly used : the
	   continuity correction is often forgotten, an the exact Fisher test is
almost
	   unheard of ...).

It made medical sense to consider the "variant" factor ancillary to the
treatment factor (that is, to *postulate* that the difference in treatment
effects between variant is much smaller that the treatment effect itself);
therefore, it is not a big problem to exclude it in the analysis. So I used the
rmeta package to assess the treatment effects. The results, as far as I can
tell, are not unreasonable.

However, I have two problems with this approach :

A) Assessing the "variant" effect : how ?
=========================================

My main problem is that I can't assess formally the (quite possibly null)
effect of the "variant" factor (i. e. checking, at least a posteriori, that the
"variant" effect is indeed much smaller that the treatment effect). In other
words, if I had had the trials' raw data, what I would have used would have
been, for numerical variables, something along the lines of :

meta.lme<-lme(Variable~Treatment*Variant/Trial, data=xxx, random=~1|Trial)

for a "random trial effect" (? la Der Simonian), and

meta.lm<-lm(Variable~Treatment*Variant/Trial, data=xxx)

for a "fixed trial effect" model, "treatment" and "variant" being of course
fixed effects of interest, the Treatment*Variant interaction being the variable
of interest for the verification of the homogeneity of treatment effect between
variants. (In my case, the trials are somewhat heterogenous (due tio not having
the same inclusion criteria), therefore the "random effect" model makes more
sense).

However, I do *not* have the raw data. Of course, I can trivially rebuild the
"sum-of-data" and "sum-of-squares" in each "cell" of the potential
"experimental plan". But I'm not able to analyse this. I looked in old books
(some dating back from the '50s, wher computers were not readily available for
biostatistics) and saw that all algorithms used back then supposed a *balanced*
experimental plan. Some approximations were used (such as using the harmonic
means of sample sizes to compute the expectations of "between-rows",
"between-columns", "between-cells" and "within-cells" variances under the null
hypothesis, but those approximations can only be used for *mild* unbalances. In
my case, this won't do : Per-group sample size varies between 10 and 244, and
there is always some unbalance between treatment groups (mainly due to
stratification effects). That's *not* "mild" ...

I tried to follow Winer's explanation of what he calls "least-squares
estimation" (that's what all modern ANOVA software, including lm and friends,
do) to see if I could build an algorithm from this ... and got lost (I'm pretty
bad at linear algebra).

However, it appears that a lm object contains just the kind of data one can
extract from a pile of papers : one can build such an object with each group of
each paper a line, with a "residual" computed from the published SD, a "value"
computed from the published mean and a "weight" computed from te sample size.
Given that drop, anova and related functions do not have to re-fit the model to
assess effects, one could then analyse this artificially-reconstructed lm
object.

Hence my questions :
	a) Am I totally wrong ?
	b) If not, how would you build such an object ?
	c) What cautions should be used in interpreting the results ?
	d) Would this approach work with a lme object ? with a (suitably built) nlme
	   object (in order to assess "variant" effect on event data) ?
	e) Would such an approach allow to assess treatment effects for trials with
more
	   than 2 groups (e. g. placebo vs. drug vs. surgery) ?

B) Alternatives to the odds-ration for event data ?
===================================================

The usual way to assess effects for categorical variables is to compute the
log(odds-ratio) for each study and to pool them using inverse variance as
weights (that's what meta.DSL and meta.MH do, respectively for random and fixed
effect model).

However, in some trials, some event have a frequency of zero in one or both
groups. In the first case, one can neglect the said trial for the assessment of
the treatment effect, on the basis that it is not informative. In the second
case, however, the data cannot be used (because the OR is either zero or
infinite, with infine asymptotic variance). The treatment assessment by OR
pooling dismisses these trials (see meta.DSL source, for example ; and this is
also the case in other meta-analysis packages, such as Cochrane's RevMan).

But the asymetry (some events in one group and none in the other) is indeed an
information, and I do not feel at ease with discarding it. The best I can think
of is the ordinary test of independance (Fisher's test, in this case) on a
contingency table "summing" the individual trials' contingency tables. This
analysis confirms the results iof the meta-analysis. But it does not account
for trials' heterogeneity, which is a large part of the point of a
meta-analysis.

Someone suggested to me to add a "small" quantity (say 1, or 0.5, as in the
case of Yate's correction for continuity) to the event counts in these groups,
ant to see if the inclusion of these study would entail a modification of the
results, but I'm "isntinctively" not satisfied with this approach.

In my case, the meta-analysis exhibits an excess of some undesirable events in
one of the treatment groups, while this excess does not reach the sacro-sanctus
"statistical significance threshold" in any of the papers I analysed
(physicians are sometimes bloody p-value worshippers ...). Therefore, I'd like
to be damn sure to *correctly* use *all* available information.

Any suggestions or pointers to litterature ?

Sincerely yours,

						Emmanuel Charpentier

--
Emmanuel Charpentier			Tel :		+33-01 40 27 35 98
Secr?tariat scientifique du CEDIT	Fax :		+33-01 40 27 55 65
Direction de la Politique M?dicale // Assistance Publique - H?pitaux de Paris
3, Avenue Victoria // F-75004 Paris /// France

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From amaitour at pasteur.fr  Wed Dec  5 13:56:49 2001
From: amaitour at pasteur.fr (Aboubakar Maitournam)
Date: Wed, 05 Dec 2001 13:56:49 +0100
Subject: [R] mclust package and modelid = VEE
References: <p05001914b83303751b81@[128.200.28.179]>
Message-ID: <3C0E1991.FDBC94D9@pasteur.fr>

Tony Long wrote:

> All:
>
>         Is the VEE option not implemented for programming reasons or
> does it not make statistical sense?  It is described in the Celeux
> and Govaert reference.  I am interested in holding orientation and
> shape constant but varying volume.  Tony
> --
>
> Tony Long
>
> Ecology and Evolutionary Biology
> Steinhaus Hall
> University of California at Irvine
> Irvine, CA
> 92697-2525
>
> Tel:  (949) 824-2562   (office)
> Tel:  (949) 824-5994   (lab)
> Fax: (949) 824-2181
>
> email:  tdlong at uci.edu
> http://hjmuller.bio.uci.edu/~labhome/
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

I have previously mee t that problem.
I think that there is some problem in
instruction  modelid=c("VVV",,"VEV", "VEE") because when
I removed VEE, the program run and I  remember it will able to find solutions
(included VEE).

Aboubakar Maitournam.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Wed Dec  5 14:50:34 2001
From: alobo at ija.csic.es (Agustin Lobo)
Date: Wed, 5 Dec 2001 14:50:34 +0100 (MET)
Subject: [R] rbind and data.frame
In-Reply-To: <Pine.LNX.4.33.0112051032270.15341-100000@tal.stat.umu.se>
Message-ID: <Pine.OSF.3.96.1011205144817.28007G-100000@ija.csic.es>


Don't mix diffferent types of objects. Use:

> colnames(x) <- names(dat)
> rbind(dat,as.data.frame(x))
  x y
1 1 2
2 0 0
3 0 0

Note that 
> as.matrix(dat)
  x y
1 1 2

hence your result.

Also note that if you do not give to x
the names of dat, you get an error because
of the names of dat:

> x <- matrix(0, ncol = 2, nrow = 2)
> rbind(dat,as.data.frame(x))
Error in match.names(clabs, names(xi)) : names don't match previous names:
         V1, V2

Agus


Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es


On Wed, 5 Dec 2001, [iso-8859-1] Göran Broström wrote:

> Version 1.3.1  (2001-08-31) (RH 7.2):
> 
> > dat <- data.frame(x = 1, y = 2)
> > x <- matrix(0, ncol = 2, nrow = 2)
> > x
>      [,1] [,2]
> [1,]    0    0
> [2,]    0    0
> > dat
>   x y
> 1 1 2
> > rbind(dat, x)
>   x y
> 1 1 2
> 2 0 0
> 
> I expected
> 
> > rbind(dat, x)
>   x y
> 1 1 2
> 2 0 0
> 3 0 0
> 
> Is my expectation wrong?
> 
> Göran Broström
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Hyon-Jung.Kim at oulu.fi  Wed Dec  5 15:01:37 2001
From: Hyon-Jung.Kim at oulu.fi (Hyon-Jung Kim)
Date: Wed, 05 Dec 2001 16:01:37 +0200
Subject: [R] R spatial package for lattice type data
Message-ID: <5.1.0.14.0.20011205160051.00a0ce90@127.0.0.1>

Hello.

Could you let me know if there is any R package written for spatial lattice
type data? I found several useful ones for Geostatistics and for spatial point
patterns but was not able to find one for lattice data.

Thank you for your help in advance.

Hyon

Dept. of Math Sciences/Statistics
POBOX 3000
Univ. of Oulu
FIN-90014, Univ. of Oulu
Finland

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mmiller3 at iupui.edu  Wed Dec  5 15:17:59 2001
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: 05 Dec 2001 09:17:59 -0500
Subject: [R] Histograms per coding variable
References: <E16BaY1-0000cm-00@mail2.uct.ac.za>
Message-ID: <87pu5tiwdk.fsf@lumen.med.iupui.edu>

>>>>> "Smit," == Smit, A, Albertus, Dr <ajsmit at botzoo.uct.ac.za> writes:

    > I need to do a series of histograms for each of the codes,
    > levels or factors in 'site'.  

[...]

    > Is there are more elegant way to do this without having to
    > use the fr.wt[1:82] bit? 

One way you can do it is to use tapply, as in
   
 > tapply( ft.wt, site, hist )

An alternative that is even better, IMHO, is to use the lattice
package, which is very slick :-)

Mike
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dray at biomserv.univ-lyon1.fr  Wed Dec  5 13:26:20 2001
From: dray at biomserv.univ-lyon1.fr (Stephane Dray)
Date: Wed, 5 Dec 2001 13:26:20 +0100
Subject: [R] rbind and data.frame
In-Reply-To: <Pine.LNX.4.33.0112051032270.15341-100000@tal.stat.umu.se>
References: <Pine.LNX.4.33.0112051032270.15341-100000@tal.stat.umu.se>
Message-ID: <a05010404b833c0fc7774@[134.214.32.69]>

I think that the problem  is that you want to bind a matrix and a 
data frame. You must transform your dataframe in a matrix (or the 
matrix in dataframe) :
>  rbind(as.matrix(dat),x)
   V1 V2
1  1  2
2  0  0
3  0  0
>  xdat_as.data.frame(x)
>  names(x)_names(dat)
>  rbind(dat,x)
   x y
1 1 2
2 0 0
3 0 0

If you bind the matrix and the dataframe, only the first column of 
the matrix is added as a row ... and i don't know (and understand) 
why !!

>  y_matrix(c(3,4,5,6),2,2)
>  y
      [,1] [,2]
[1,]    3    5
[2,]    4    6
>  rbind(dat,y)
   x y
1 1 2
2 3 4
>

>Version 1.3.1  (2001-08-31) (RH 7.2):
>
>  > dat <- data.frame(x = 1, y = 2)
>>  x <- matrix(0, ncol = 2, nrow = 2)
>  > x
>      [,1] [,2]
>[1,]    0    0
>[2,]    0    0
>>  dat
>   x y
>1 1 2
>>  rbind(dat, x)
>   x y
>1 1 2
>2 0 0
>
>I expected
>
>>  rbind(dat, x)
>   x y
>1 1 2
>2 0 0
>3 0 0
>
>Is my expectation wrong?
>
>G?ran Brostr?m
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
St?phane DRAY
---------------------------------------------------------------
Biom?trie et Biologie ?volutive - Equipe "?cologie Statistique"
Universite Lyon 1 - Bat 711 - 69622 Villeurbanne CEDEX - France

Tel : 04 72 43 27 56			   Fax : 04 78 89 27 19
       04 72 43 27 57 	   E-mail : dray at biomserv.univ-lyon1.fr 
---------------------------------------------------------------
ADE-4               http://pbil.univ-lyon1.fr/ADE-4/ADE-4F.html
---------------------------------------------------------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011205/fe10b8ce/attachment.html

From nikolai at eri.u-tokyo.ac.jp  Wed Dec  5 15:20:49 2001
From: nikolai at eri.u-tokyo.ac.jp (Nick Kostrov)
Date: Wed, 5 Dec 2001 23:20:49 +0900
Subject: [R] How to change font size?
Message-ID: <01120523204900.05791@nick-pc>


Hello!


Does anybody know how to change the font size of  axis labels in the graphic 
window? I found that it is possible to change  font to "bold"  but labels are 
very tiny.

Thanks in advance,

Nick
 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec  5 15:28:00 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Dec 2001 14:28:00 +0000 (GMT)
Subject: [R] How to change font size?
In-Reply-To: <01120523204900.05791@nick-pc>
Message-ID: <Pine.LNX.4.31.0112051424270.23186-100000@gannet.stats>

On Wed, 5 Dec 2001, Nick Kostrov wrote:

> Does anybody know how to change the font size of  axis labels in the graphic
> window? I found that it is possible to change  font to "bold"  but labels are
> very tiny.

Using some variation on graphics parameter cex, depending if the `axis
labels' are the numbers or the x/ylab= labels.

However, more likely your device is set up wrongly.  Take a look at
its parameters, which may include pointsize, for example.

To help more we need to know

1) the details of your system

2) what you used to get the plot

3) what exactly is the problem.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nikolai at eri.u-tokyo.ac.jp  Wed Dec  5 15:30:37 2001
From: nikolai at eri.u-tokyo.ac.jp (Nick Kostrov)
Date: Wed, 5 Dec 2001 23:30:37 +0900
Subject: [R] one command on several lines
Message-ID: <01120523303700.05944@nick-pc>

Hello!

Is it possible to continue expand one command on several lines in R ?

An attempt to write

a=c(1990," ",1991,
      1992, 
      1993,1994,1995,1996,1997,1998,
     1999)

in a file and then 

source('file')

results in 

Error in parse(file, n, text, prompt) : syntax error on line 55 



Thanks.

Nick
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec  5 15:32:59 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 05 Dec 2001 15:32:59 +0100
Subject: [R] one command on several lines
In-Reply-To: <01120523303700.05944@nick-pc>
References: <01120523303700.05944@nick-pc>
Message-ID: <x2her520v8.fsf@blueberry.kubism.ku.dk>

Nick Kostrov <nikolai at eri.u-tokyo.ac.jp> writes:

> Hello!
> 
> Is it possible to continue expand one command on several lines in R ?
> 
> An attempt to write
> 
> a=c(1990," ",1991,
>       1992, 
>       1993,1994,1995,1996,1997,1998,
>      1999)
> 
> in a file and then 
> 
> source('file')
> 
> results in 
> 
> Error in parse(file, n, text, prompt) : syntax error on line 55 

Shouldn't be a problem if you just make sure that the preceding line
is incomplete, but if that "=" was meant as an assignment, then you'll
get the parse error even on one line.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From david.barron at jesus.ox.ac.uk  Wed Dec  5 15:36:28 2001
From: david.barron at jesus.ox.ac.uk (David Barron)
Date: Wed, 5 Dec 2001 14:36:28 -0000
Subject: [R] one command on several lines
References: <01120523303700.05944@nick-pc>
Message-ID: <00fc01c17d9a$392d7300$cb8801a3@sbs.ox.ac.uk>

The problem with this is the use of the equals sign, not continuing over
more than one line.  It should be
a <- c(1990," ",1991,...)

David

----- Original Message -----
From: "Nick Kostrov" <nikolai at eri.u-tokyo.ac.jp>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, December 05, 2001 2:30 PM
Subject: [R] one command on several lines


> Hello!
>
> Is it possible to continue expand one command on several lines in R ?
>
> An attempt to write
>
> a=c(1990," ",1991,
>       1992,
>       1993,1994,1995,1996,1997,1998,
>      1999)
>
> in a file and then
>
> source('file')
>
> results in
>
> Error in parse(file, n, text, prompt) : syntax error on line 55
>
>
>
> Thanks.
>
> Nick
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Wed Dec  5 15:41:47 2001
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 05 Dec 2001 09:41:47 -0500
Subject: [R] problem loading quantreg on WinNT
Message-ID: <51F9C42DA15CD311BD220008C707D81903DC83EB@usrymx10.merck.com>

Dear R-help,

Has anyone been able to use the quantreg package on Windows successfully?  I
tried to load it and get the following:

> library(quantreg)
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library
"C:/PROGRA~1/R/rw1031/library/quantreg/libs/quantreg.dll":
  LoadLibrary failure:  The specified procedure could not be found.
Error in library(quantreg) : .First.lib failed

platform i386-pc-mingw32
arch     x86            
os       Win32          
system   x86, Win32     
status                  
major    1              
minor    3.1            
year     2001           
month    08             
day      31             
language R              

(This is compiled from source, linked against ATLAS.)

Does anyone have any idea what's wrong?  I'd appreciate any hints!

Regards,
Andy


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Wed Dec  5 15:44:45 2001
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 05 Dec 2001 15:44:45 +0100
Subject: [R] How to change font size?
References: <01120523204900.05791@nick-pc>
Message-ID: <3C0E32DD.61C7A69B@statistik.uni-dortmund.de>

Nick Kostrov wrote:
> 
> Hello!
> 
> Does anybody know how to change the font size of  axis labels in the graphic
> window? I found that it is possible to change  font to "bold"  but labels are
> very tiny.

Have a look at ?par.

You can use the argument cex.axis for the size of tickmark labels and
cex.lab for axis annotation, e.g.:

Example:
 plot(1:10, cex.axis=2, cex.lab=3)

Uwe
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Wed Dec  5 16:31:04 2001
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 05 Dec 2001 10:31:04 -0500
Subject: [R] problem loading quantreg on WinNT
Message-ID: <51F9C42DA15CD311BD220008C707D81903DC83ED@usrymx10.merck.com>

Prof. Koenker,

I've managed to solve the problem.  As you suspected, it's the ATLAS link.
I downloaded the source from CRAN and compiled with link to ATLAS, and
everything seems fine.  Thanks a lot!

Regards,
Andy

> -----Original Message-----
> From: Roger Koenker [mailto:roger at ysidro.econ.uiuc.edu]
> Sent: Wednesday, December 05, 2001 10:30 AM
> To: Liaw, Andy
> Subject: Re: [R] problem loading quantreg on WinNT
> 
> 
> As maintainer, I should have some suggestion, but I don't 
> have a windows
> box, so I'm quite useless.  There are quite a few windows users though
> so I wonder whether it may be some problem with the atlas linking...
> 
> 
> url:	http://www.econ.uiuc.edu		Roger Koenker
> email	roger at ysidro.econ.uiuc.edu		Department of Economics
> vox: 	217-333-4558				University of Illinois
> fax:   	217-244-6678				
> Champaign, IL 61820
> 
> On Wed, 5 Dec 2001, Liaw, Andy wrote:
> 
> > Dear R-help,
> >
> > Has anyone been able to use the quantreg package on Windows 
> successfully?  I
> > tried to load it and get the following:
> >
> > > library(quantreg)
> > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> >         unable to load shared library
> > "C:/PROGRA~1/R/rw1031/library/quantreg/libs/quantreg.dll":
> >   LoadLibrary failure:  The specified procedure could not be found.
> > Error in library(quantreg) : .First.lib failed
> >
> > platform i386-pc-mingw32
> > arch     x86
> > os       Win32
> > system   x86, Win32
> > status
> > major    1
> > minor    3.1
> > year     2001
> > month    08
> > day      31
> > language R
> >
> > (This is compiled from source, linked against ATLAS.)
> >
> > Does anyone have any idea what's wrong?  I'd appreciate any hints!
> >
> > Regards,
> > Andy
> >
> >
> > 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> > 
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> >
> 
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From MSchwartz at medanalytics.com  Wed Dec  5 16:30:37 2001
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 5 Dec 2001 09:30:37 -0600
Subject: [R] Histograms per coding variable
In-Reply-To: <Pine.LNX.4.30.0112050719300.17651-100000@bolker.zoo.ufl.edu>
Message-ID: <000501c17da1$cf3be460$0201a8c0@Marc>

In addition, you can use something like:

hist(fr.wt[site == "glen"],nclass = 20)

if you wish to access just one of the subsets at a time within 'site'.

-----Original Message-----
From: owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch]On Behalf Of Ben Bolker
Sent: Wednesday, December 05, 2001 6:22 AM
To: Smit, A, Albertus, Dr
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Histograms per coding variable



 Something like

tapply(fr.wt,site,hist,nclass=20)

e.g.:

a <- runif(100)
f <- factor(rep(1:10,rep(10,10)))
par(mfrow=c(3,4))
tapply(a,f,hist)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From carlos.ortega at minorplanet.com  Wed Dec  5 16:39:24 2001
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Wed, 5 Dec 2001 16:39:24 +0100
Subject: [R] memory issue trying to solve too large a problem using hclust
In-Reply-To: <3C0DF39A.7A300B95@pasteur.fr>
Message-ID: <001301c17da3$04cbc950$1e00a8c0@MinorplanetDev>

Hello,

I am wondering if the "dna library 0.2" that Proffesor Jim Landsey made
available on March 2000 (www.luc.ac.be/~jlindsey/rcode.html ) as well as his
papers ("An Introduction to Markov Models in Molecular Biology. (2000)
available at http://alpha.luc.ac.be/~lucp0753/manuscripts.html ) are useful
for your purposes.

Thanks,
Carlos Ortega.


-----Mensaje original-----
De: owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch]En nombre de Aboubakar Maitournam
Enviado el: miercoles, 05 de diciembre de 2001 11:15
Para: cstrato at EUnet.at; r-help at stat.math.ethz.ch
Asunto: Re: [R] memory issue trying to solve too large a problem using
hclust


"cstrato at EUnet.at" wrote:

> Dear Aboubakar
>
> Thank you for your reply. I know that clustering is not a trivial
> issue, this was the reason I thought that I could start a discussion.
> It may not seem to belong to r-help but since many people (including
> me) use R/S for expression profiling, I thought I will try it anyhow.
>
> Since you mention  distance based on correlation, this was my
> question #2: Is it possible, that R/S can also support it for hclust?
> Since I use S/R as my main packages, it it a severe limitation to
> have a limited choice of metrices.
>
> You mention that k-means can have many solutions, but as far, as
> I know, the results of agglomerative hierarchical clustering
> depend on  the order of the data? For this reason, one company
> (Applied Maths) does even calculate the significance of the branches
> of a tree using bootstrap techniques. Could this possibly be done
> also with R/S?
>
> Furthermore, if I remember correctly, someone has mentioned that
> divisive hierarchical clustering would be preferrable to agglomerative
> clustering, but there exist no algorithms to calculate it in a reasonable
> time. (Could it be that this was mentioned by Prof. Ripley?)
>
> Quite some time ago I have tried the different cluster algorithms
> and metrices available in S/R and at that time, DIANA  seemed to give
> the best results. I think it is sorry, that more recent cluster algorithms
> such as CURE etc (see question #4) are not implemented so that
> it is not possible to try them and compare them with the currently
> used ones.
>
> (BTW, mclust seems to give especially bad results, but I do not
> know why?)
>
> Personally, I would prefer to have a function, which would cluster
> data using a couple of different cluster algorithms, then identify those
> branches in a tree which always turn up to be in the same sub-cluster,
> which could then be considered as "stable".
>
> Best regards
> Christian Stratowa
>
> Aboubakar Maitournam wrote:
>
> >
> > I m not famous statistician (so I will walk on eggs) but I know that the
clustering
> > problem is not a trivial task and is not
> > completely solved. The most used technique in the clustering of genes
expression
> > data is based
> > on hierarchical clustering which is depending of the choice of distance.
There is
> > some consensus
> > about the distance based on correlation (take care because sometimes
it's not the
> > distance is the
> > strict topological sense, in the sense of metric space). In addition the
> > hierarchical clustering is noise
> > depending. But related to the phylogenetic practices and the pioneer
work of Eisen,
> > the hierarchical clustering is
> > the wide technique used in the area of the genes expression data
analysis (for the
> > clustering).
> > The k-means as hierarchical clustering has arbitrary choices and can
give many
> > solutions.
> > The methods which are in theoretical developments, which give the number
of
> > clustering in data and determine the corresponding
> > classes are based on mixture models as the package mclust or some
published work
> > base of simulated annealing.
> > But naturally it's difficult to change "les habitudes" (the usual
practices) and
> > perhaps the stochastic background which is not  poetic on which these
methods
> > are based , is explaining why they are not used.
> > Finally if you want to use the classical methods (pca, k-means,
hierarchical
> > clustering) the best methods is to try at least two methods.
> > Notes there is also non classical methods based on graphs theory or
neural networks
> > but the objective methods remains
> > pca  and stochastic methods.
> >
> > Aboubakar Maitournam.
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

Effectively there are many problems related to clustering which are not
solved by R,
for the analysis of expression profiling.  However some packages dedicated
to that task
as GeneSom are beginning to be released in R. The commercial softwares solve
some
clustering problems
not all.  The mclust package related to paper published in Bioinformatics
have some
restrictions (number of classes,.....).


Aboubakar Maitournam.




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec  5 16:50:49 2001
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 5 Dec 2001 15:50:49 +0000 (GMT Standard Time)
Subject: [R] problem loading quantreg on WinNT
In-Reply-To: <51F9C42DA15CD311BD220008C707D81903DC83ED@usrymx10.merck.com>
Message-ID: <Pine.WNT.4.31.0112051547200.708-100000@gannet>

That's a general point: I took your email to read that quantreg was
compiled from sources.

You can't mix and match: if you built with ATLAS then you should build all
addons from the sources yourself, as then R.dll no longer contains blas
routines.


On Wed, 5 Dec 2001, Liaw, Andy wrote:

> Prof. Koenker,
>
> I've managed to solve the problem.  As you suspected, it's the ATLAS link.
> I downloaded the source from CRAN and compiled with link to ATLAS, and
> everything seems fine.  Thanks a lot!
>
> Regards,
> Andy
>
> > -----Original Message-----
> > From: Roger Koenker [mailto:roger at ysidro.econ.uiuc.edu]
> > Sent: Wednesday, December 05, 2001 10:30 AM
> > To: Liaw, Andy
> > Subject: Re: [R] problem loading quantreg on WinNT
> >
> >
> > As maintainer, I should have some suggestion, but I don't
> > have a windows
> > box, so I'm quite useless.  There are quite a few windows users though
> > so I wonder whether it may be some problem with the atlas linking...
> >
> >
> > url:	http://www.econ.uiuc.edu		Roger Koenker
> > email	roger at ysidro.econ.uiuc.edu		Department of Economics
> > vox: 	217-333-4558				University of Illinois
> > fax:   	217-244-6678
> > Champaign, IL 61820
> >
> > On Wed, 5 Dec 2001, Liaw, Andy wrote:
> >
> > > Dear R-help,
> > >
> > > Has anyone been able to use the quantreg package on Windows
> > successfully?  I
> > > tried to load it and get the following:
> > >
> > > > library(quantreg)
> > > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> > >         unable to load shared library
> > > "C:/PROGRA~1/R/rw1031/library/quantreg/libs/quantreg.dll":
> > >   LoadLibrary failure:  The specified procedure could not be found.
> > > Error in library(quantreg) : .First.lib failed
> > >
> > > platform i386-pc-mingw32
> > > arch     x86
> > > os       Win32
> > > system   x86, Win32
> > > status
> > > major    1
> > > minor    3.1
> > > year     2001
> > > month    08
> > > day      31
> > > language R
> > >
> > > (This is compiled from source, linked against ATLAS.)
> > >
> > > Does anyone have any idea what's wrong?  I'd appreciate any hints!
> > >
> > > Regards,
> > > Andy
> > >
> > >
> > >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> > -.-.-.-.-.-.-.-.-
> > > r-help mailing list -- Read
> > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > > Send "info", "help", or "[un]subscribe"
> > > (in the "body", not the subject !)  To:
> > r-help-request at stat.math.ethz.ch
> > >
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> > _._._._._._._._._
> > >
> >
> >
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Dec  5 17:51:48 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 5 Dec 2001 08:51:48 -0800 (PST)
Subject: [R] Questions about piecewise spline fitting
In-Reply-To: <F144mGvweQaWGckg0pr0002056c@hotmail.com>
Message-ID: <Pine.A41.4.33.0112050844450.50106-100000@homer34.u.washington.edu>

On Tue, 4 Dec 2001, Gang Liang wrote:

> Hi All,
>
> I want to fit a piecewise spline of degree 1, i.e. a spline consisting of a
> straight line over each piece. I downloaded the R package pspline, then I
> have following questions:
>
> 1. in the program, the degree of the spline is specified by 2*norder-1. Why
> do they adopt such scheme that we can only fit a spline with odd degree?
>
> 2. norder cannot be set to 1. Is there any specific reason for doing so?
>
> Maybe I need to code this by myself. So I'd like to hear your advices.
>

There is a splines package in the R base distribution. You want to use the
bs() function in the splines package. The pspline package fits smoothing
splines, which are not what you want.

For linear splines it may be easier to code them yourself in any case, as
there are at least two different codings where the parameter estimates and
tests are of interest in themselves. What bs() gives is yet another coding
that is more numerically stable but has less interesting coefficients.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Dec  5 18:11:05 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 5 Dec 2001 09:11:05 -0800 (PST)
Subject: [R] (Meta-analysis) How to build|fake a [n]lm[e] object ?
In-Reply-To: <3C0E177A.C43C9B83@sap.ap-hop-paris.fr>
Message-ID: <Pine.A41.4.33.0112050901390.50106-100000@homer34.u.washington.edu>

On Wed, 5 Dec 2001, Emmanuel Charpentier wrote:

>
> B) Alternatives to the odds-ration for event data ?
> ===================================================
>
> The usual way to assess effects for categorical variables is to compute the
> log(odds-ratio) for each study and to pool them using inverse variance as
> weights (that's what meta.DSL and meta.MH do, respectively for random and fixed
> effect model).
>
> However, in some trials, some event have a frequency of zero in one or both
> groups. In the first case, one can neglect the said trial for the assessment of
> the treatment effect, on the basis that it is not informative. In the second
> case, however, the data cannot be used (because the OR is either zero or
> infinite, with infine asymptotic variance). The treatment assessment by OR
> pooling dismisses these trials (see meta.DSL source, for example ; and this is
> also the case in other meta-analysis packages, such as Cochrane's RevMan).

meta.MH doesn't have this problem -- it's quite happy with zero cells.

> But the asymetry (some events in one group and none in the other) is indeed an
> information, and I do not feel at ease with discarding it. The best I can think
> of is the ordinary test of independance (Fisher's test, in this case) on a
> contingency table "summing" the individual trials' contingency tables. This
> analysis confirms the results iof the meta-analysis. But it does not account
> for trials' heterogeneity, which is a large part of the point of a
> meta-analysis.

Either meta.MH or conditional logistic regression (clogit in the
survival package) would fix this

> Someone suggested to me to add a "small" quantity (say 1, or 0.5, as in the
> case of Yate's correction for continuity) to the event counts in these groups,
> ant to see if the inclusion of these study would entail a modification of the
> results, but I'm "isntinctively" not satisfied with this approach.
>

If you want a fixed effect of treatment there's no problem (and I
personally don't like meta-analyses where a random-effects model makes a
difference)

If you need a random effects model that doesn't object to zero cells then
lme() and variants aren't going to work, and you need a real generalized
linear mixed model with random intercept and random treatment effect.
Logistic mixed models are a hard problem.  Jim Lindsey's 'repeated'
package may handle this, though.

A little simulation would tell you what the properties of the `continuity
correction' approach are.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From friendly at hotspur.psych.yorku.ca  Wed Dec  5 18:38:20 2001
From: friendly at hotspur.psych.yorku.ca (friendly@hotspur.psych.yorku.ca)
Date: 5 Dec 2001 17:38:20 -0000
Subject: [R] (Meta-analysis) How to build|fake a [n]lm[e] object ?
Message-ID: <20011205173820.2965.qmail@hotspur.psych.yorku.ca>

Emmanuel-

Perhaps I can help with one thing:

! However, I do *not* have the raw data. Of course, I can trivially rebuild  
the
! "sum-of-data" and "sum-of-squares" in each "cell" of the potential
! "experimental plan". But I'm not able to analyse this. I looked in old  
books
! (some dating back from the '50s, wher computers were not readily available  
for
! biostatistics) and saw that all algorithms used back then supposed a  
*balanced*

There is a simple solution to the problem of going from summary statistics
to an lm() analysis which gives equivalent results, described by Larsen,
and implemented by me as a SAS macro, stat2dat.  The freq= variable
would become the weight= in lm().

/*= 

 name: STAT2DAT
title: Transform a summary data set to pseudo-observations
  Doc: http://www.math.yorku.ca/SCS/sasmac/stat2dat.html
Version: 1.1
Revised: 2 Apr 1999 


=Description:

Take a dataset containing summary statistics (N, mean, std dev) for
a between groups design and produce a dataset from which PROC GLM
can be run to produce equivalent results.

=Usage:
   %stat2dat(data=inputdataset, out=outputdataset, ..., 

      depvar=Y, freq=freq)

      The input dataset contains one observation for each group.
      Supply the names of variables containing the N, MEAN, and standard
      deviation (STD) for each group (see argument list below);  The
      mean square error (MSE) for a reported ANOVA can be supplied instead
      of individual STD values.  The sample size per cell can be supplied
      as a constant rather than a dataset variable if all groups are of the
      same size.  


      The output dataset can then be used with PROC GLM or PROC ANOVA
      (balanced designs).  It contains all variables from the input dataset
      plus a constructed dependent variable ('Y' by default) and
      a constructed frequency variable ('freq' by default).
      

   proc glm data=outputdataset;
      class classvars;
      freq freq;
      model Y = modelterms;
      

Based on:  David Larsen, Analysis of Variance With Just Summary Statistics
   as Input,  The American Statistician, May 1992, Vol. 46(2), 151-152.
   (David Larson:   dalef at uno.edu)


Michael Friendly	<friendly at yorku.ca>
Psychology Department, York University
Toronto, ONT  M3J 1P3 CANADA
=*/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tklistaddr at keittlab.bio.sunysb.edu  Wed Dec  5 18:48:22 2001
From: tklistaddr at keittlab.bio.sunysb.edu (Timothy H. Keitt)
Date: Wed, 05 Dec 2001 12:48:22 -0500
Subject: [R] trouble with R CMD INSTALL for building my own library
References: <3C0D845E.D71CE9E4@labs.agilent.com> <15373.52013.609315.404375@mithrandir.hornik.net>
Message-ID: <3C0E5DE6.5040609@keittlab.bio.sunysb.edu>

Actually, I've noticed the same thing (v. 1.3.1) I created a new package 
and added a 'src' dir and put a C source file in there; 'make' was never 
called by 'R CMD INSTALL'. I thought I had simply forgotten something, 
but it looks like this may be a bug (either with 'INSTALL' or something 
about the Debian packages?)

Tim

Kurt Hornik wrote:

>>>>>>Jonathan Li writes:
>>>>>>
>
>>Hi,
>>
>
>>I have built a library that consists of a piece of C code and some R
>>functions.  To build it into a library that I can load using library()
>>command, I have followed "Writing R Extensions" and made
>>sub-directories such as mylib/R and mylib/src.
>>
>
>It actually is 'package' and not 'library'.
>
>>But when I run R CMD INSTALL mylib, nothing seems to be happening with
>>src directory, i.e., no C compiling. I have probably missed some key
>>steps. But after reading very carefully "Writing R Extension", I
>>conclude that I don't need to write my own Makefile in src since R CMD
>>INSTALL will use the default in /usr/lib/R/etc/Makeconf Here is a copy
>>of Makeconf file. In addition, R CMD check and R CMD build all ran
>>without running "make". Is this the way it is supposed to be?  (no
>>error messages encountered).
>>
>
>Sounds strange.  You really have
>
>	mylib/src/foo.c
>
>(note the extension!) and nothing happens?
>
>-k
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Timothy H. Keitt
Department of Ecology and Evolution
State University of New York at Stony Brook
Stony Brook, New York 11794 USA
Phone: 631-632-1101, FAX: 631-632-7626
http://life.bio.sunysb.edu/ee/keitt/



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Wed Dec  5 18:49:25 2001
From: rossini at blindglobe.net (A.J. Rossini)
Date: 05 Dec 2001 09:49:25 -0800
Subject: [R] memory issue trying to solve too large a problem using hclust
In-Reply-To: <001301c17da3$04cbc950$1e00a8c0@MinorplanetDev>
References: <001301c17da3$04cbc950$1e00a8c0@MinorplanetDev>
Message-ID: <87elm9blqy.fsf@jeeves.blindglobe.net>

>>>>> "CO" == Carlos Ortega <carlos.ortega at minorplanet.com> writes:

    CO> Hello,

    CO> I am wondering if the "dna library 0.2" that Proffesor Jim
    CO> Landsey made available on March 2000
    CO> (www.luc.ac.be/~jlindsey/rcode.html ) as well as his papers
    CO> ("An Introduction to Markov Models in Molecular
    CO> Biology. (2000) available at
    CO> http://alpha.luc.ac.be/~lucp0753/manuscripts.html ) are useful
    CO> for your purposes.

No it probably won't.  That package solves a different set of
(interesting) problems.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   T-Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
Rosen: (Mullins' Lab) Fridays, and I'm unreachable except by email.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cstrato at EUnet.at  Wed Dec  5 19:37:24 2001
From: cstrato at EUnet.at (cstrato@EUnet.at)
Date: Wed, 05 Dec 2001 19:37:24 +0100
Subject: [R] memory issue trying to solve too large a problem using hclust
References: <001301c17da3$04cbc950$1e00a8c0@MinorplanetDev>
Message-ID: <3C0E6961.708CA691@EUnet.at>

Dear all

I would like to thank all people who have responded (Carlos Ortega,
Aboubakar Maitournam, Ron Wherens, Christian Henning and Andy Liaw).
Some have sent their answers to my mail-address only, so I am never
quite sure if they want me to foreward their answers to r-help or
not. In contrast to S-news, at R most people respond to r-help,
which I find preferable.

I am especially greatful to Andy Liaw ,who mentioned the following
possibility to use correlation in hclust:
  d <- 1-cor(x)^2
  hc <- hclust(as.dist(d))
Sorrowly, I did not have time to try it, but it seems that I would
have to start using more R and less S-Plus, since "as.dist()" does
not exist in S-Plus (maybe it works with dist, I have to try)

Best regards
Christian Stratowa

Carlos Ortega wrote:

> Hello,
>
> I am wondering if the "dna library 0.2" that Proffesor Jim Landsey made
> available on March 2000 (www.luc.ac.be/~jlindsey/rcode.html ) as well as his
> papers ("An Introduction to Markov Models in Molecular Biology. (2000)
> available at http://alpha.luc.ac.be/~lucp0753/manuscripts.html ) are useful
> for your purposes.
>
> Thanks,
> Carlos Ortega.
>
> -----Mensaje original-----
> De: owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch]En nombre de Aboubakar Maitournam
> Enviado el: miercoles, 05 de diciembre de 2001 11:15
> Para: cstrato at EUnet.at; r-help at stat.math.ethz.ch
> Asunto: Re: [R] memory issue trying to solve too large a problem using
> hclust

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jonqli at labs.agilent.com  Wed Dec  5 20:06:10 2001
From: jonqli at labs.agilent.com (Jonathan Li)
Date: Wed, 05 Dec 2001 11:06:10 -0800
Subject: [R] trouble with R CMD INSTALL for building my own library
References: <3C0D845E.D71CE9E4@labs.agilent.com> <15373.52013.609315.404375@mithrandir.hornik.net>
Message-ID: <3C0E7022.E4946287@labs.agilent.com>

Kurt Hornik wrote:
> 
> >>>>> Jonathan Li writes:
> 
> > Hi,
> 
> > I have built a library that consists of a piece of C code and some R
> > functions.  To build it into a library that I can load using library()
> > command, I have followed "Writing R Extensions" and made
> > sub-directories such as mylib/R and mylib/src.
> 
> It actually is 'package' and not 'library'.
> 
> > But when I run R CMD INSTALL mylib, nothing seems to be happening with
> > src directory, i.e., no C compiling. I have probably missed some key
> > steps. But after reading very carefully "Writing R Extension", I
> > conclude that I don't need to write my own Makefile in src since R CMD
> > INSTALL will use the default in /usr/lib/R/etc/Makeconf Here is a copy
> > of Makeconf file. In addition, R CMD check and R CMD build all ran
> > without running "make". Is this the way it is supposed to be?  (no
> > error messages encountered).
> 
> Sounds strange.  You really have
> 
>         mylib/src/foo.c
> 
> (note the extension!) and nothing happens?
> 
> -k

Yes. I actually made an extra dummy c file called foo.c in mylib/src :)
still nothing happens.
Here are more messages when running R CMD check/install/build

$R CMD check mylib
* checking for working latex ... OK
* using log directory `/mydir/mylib.Rcheck'
 
Installing binary package `mylib' ...
 DONE (mylib)
 
DONE (INSTALL)
 
* checking for file `mylib/DESCRIPTION' ... OK
* checking package directory ... OK
* checking for sufficient file permissions ... OK
* checking DESCRIPTION Package field ... OK
* checking DESCRIPTION Version field ... OK
* checking DESCRIPTION License field ... OK
* checking DESCRIPTION Description field ... OK
* checking DESCRIPTION Title field ... OK
* checking DESCRIPTION Author field ... OK
* checking DESCRIPTION Maintainer field ... OK
* checking R files for library.dynam ... OK

$R CMD build mylib
* checking for file `mylib/DESCRIPTION' ... OK
* preparing `mylib':
* cleaning src
* checking whether `INDEX' is up-to-date ...open(man): No such file or
directory at /usr/lib/R/bin/Rdindex line 117
 NO
* use `--force' to overwrite the existing `INDEX'
* removing junk files
* building `mylib_0.1.tar.gz'

After becoming super user, I ran

$R CMD INSTALL boosttree
Installing binary package `mylib' ...
 DONE (boosttree)
 
DONE (INSTALL)

As you can see, R CMD build tries to "clearning src". I am not sure if
this means that something went wrong in my
setup. 

Thanks plenty again for any insights!

-- 
Jonathan Q. Li, PhD
Agilent Technologies Laboratory
Palo Alto, California, USA
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wu at math.sc.edu  Wed Dec  5 20:41:17 2001
From: wu at math.sc.edu (Wu Shuyuan)
Date: Wed, 5 Dec 2001 14:41:17 -0500 (EST)
Subject: [R] install R-1.3.1 on Solaris 8
Message-ID: <Pine.SOL.3.93.1011205141550.4713A-100000@mushroom.math.sc.edu>

Dear All:

I tried to compile and install R-1.3.1 on Solaris 8,but never 
succeeded, Can you give me any suggestion?
I used 
./configure --with-x --x-includes=/usr/openwin/share/include/X11 \
--x-libraries=/usr/openwin/lib --with-f77 \
--with-tcl-config=/usr/local/lib --with-tk-config=/usr/local/lib
I noticed that ld used /usr/ccs/bin/ld(ld: Software Generation 
Utilities-Solaris-ELF (4. 0)). I changed in config.site
MAIN_LD=/usr/local/bin/ld(GNU ld version 2.9.1 (with BFD 2.9.1)
  Supported emulations:
   elf32_sparc)
but R always use /usr/ccs/bin/ld.

I put the log files of configure, make,make check on the 
http://www.math.sc.edu/~wu/, click R compile problem on Solaris 8.

Any suggestion are highly appreciated.

Thank you!

Shuyuan Wu
Tel: 803-777-9312(o)    
                     


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hlai at whsun1.wh.whoi.edu  Wed Dec  5 23:37:49 2001
From: hlai at whsun1.wh.whoi.edu (Han Lai)
Date: Wed, 05 Dec 2001 14:37:49 -0800
Subject: [R] how to obtain EM-estimates of cov(b) and var(e) from lme
Message-ID: <3C0EA1BD.B5B328F2@whsun1.wh.whoi.edu>

Hi,

I have a simple random-coefficients model for m subjects:

    y = b0 + b1 x + r0 + r1  x + e

where b0 and b1 are fixed parameters, r0 and r1 are random,
e ~ N(0,s2 I) and R' = [r0, r1] ~ N(0,T).

I try to obtain the EM-estimates of s2 and the elements of T by

    lme(y~x,data=mydata,random= list(group=~x),
          control=lmeControl(maxIter = 0, niterEM=100,msVerbose = TRUE))

Does this statement do the job?

Thank you very much.

Cheers!
Han-Lin Lai, Ph.D
Han-Lin.Lai at noaa.gov
508-495-2312



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec  5 20:52:11 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 05 Dec 2001 20:52:11 +0100
Subject: [R] install R-1.3.1 on Solaris 8
In-Reply-To: <Pine.SOL.3.93.1011205141550.4713A-100000@mushroom.math.sc.edu>
References: <Pine.SOL.3.93.1011205141550.4713A-100000@mushroom.math.sc.edu>
Message-ID: <x28zchzbpw.fsf@blueberry.kubism.ku.dk>

Wu Shuyuan <wu at math.sc.edu> writes:

> Dear All:
> 
> I tried to compile and install R-1.3.1 on Solaris 8,but never 
> succeeded, Can you give me any suggestion?
> I used 
> ./configure --with-x --x-includes=/usr/openwin/share/include/X11 \
> --x-libraries=/usr/openwin/lib --with-f77 \
> --with-tcl-config=/usr/local/lib --with-tk-config=/usr/local/lib
> I noticed that ld used /usr/ccs/bin/ld(ld: Software Generation 
> Utilities-Solaris-ELF (4. 0)). I changed in config.site
> MAIN_LD=/usr/local/bin/ld(GNU ld version 2.9.1 (with BFD 2.9.1)
>   Supported emulations:
>    elf32_sparc)
> but R always use /usr/ccs/bin/ld.
> 
> I put the log files of configure, make,make check on the 
> http://www.math.sc.edu/~wu/, click R compile problem on Solaris 8.
> 
> Any suggestion are highly appreciated.

You might want to exchange f77 with g77 there. Try that first.

Did you build the documentation? Without that, you are not likely to
make the checks succeed.

What you're seeing is a make check error, not a build error, so it
would be nice to know where it went wrong. The easiest way to do that
is to 

cd tests/Examples
../bin/R --vanilla < base-Ex.R

and then report the last few lines. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jonathan_li at agilent.com  Wed Dec  5 21:38:11 2001
From: jonathan_li at agilent.com (jonathan_li@agilent.com)
Date: Wed, 5 Dec 2001 12:38:11 -0800 
Subject: [R] trouble with R CMD INSTALL for building my own library
Message-ID: <FC0B9DA2600ED4118F76009027AA5DDD02B27B30@ALEX2>

Hi all,

Problem solved!

Thanks to a suggestion by Robert Gentleman, I realized that there may be
something that makes R think that mylib is a binary rather than source
package. I downloaded Brian Ripley's tree source package and basically
copied each directory. As it turns out, I have not put in a mylib/man
subdirectory (I thought I could add it any time later.) and R was then
tricked to believe that mylib is a binary! Once I add an empty mylib/man
subdirectory, things become normal with compiling etc. Timothy, I think that
your problem is likely to be the same source then. 

Regards,
Jonathan


-----Original Message-----
From: Kurt Hornik [mailto:Kurt.Hornik at ci.tuwien.ac.at]
Sent: Tuesday, December 04, 2001 11:22 PM
To: Jonathan Li
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] trouble with R CMD INSTALL for building my own library


>>>>> Jonathan Li writes:

> Hi,

> I have built a library that consists of a piece of C code and some R
> functions.  To build it into a library that I can load using library()
> command, I have followed "Writing R Extensions" and made
> sub-directories such as mylib/R and mylib/src.

It actually is 'package' and not 'library'.

> But when I run R CMD INSTALL mylib, nothing seems to be happening with
> src directory, i.e., no C compiling. I have probably missed some key
> steps. But after reading very carefully "Writing R Extension", I
> conclude that I don't need to write my own Makefile in src since R CMD
> INSTALL will use the default in /usr/lib/R/etc/Makeconf Here is a copy
> of Makeconf file. In addition, R CMD check and R CMD build all ran
> without running "make". Is this the way it is supposed to be?  (no
> error messages encountered).

Sounds strange.  You really have

	mylib/src/foo.c

(note the extension!) and nothing happens?

-k
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chrysopa at terra.com.br  Wed Dec  5 21:45:07 2001
From: chrysopa at terra.com.br (Ronaldo Reis Jr.)
Date: Wed, 5 Dec 2001 18:45:07 -0200
Subject: [R] SAS to R convert
Message-ID: <20011205205024.99829C87A0@srv9-sao.terra.com.br>

Hi,
anybody know an program that convert SAS program in R program?
Thanks
Ronaldo
-- 
You cannot see the wood for the trees.
		-- John Heywood
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][SO: CL 7.0 (2.2.19)]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Conectiva Linux 7.0 D+:) | Lxuser#: 205366
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pols1oh at bestweb.net  Wed Dec  5 21:51:38 2001
From: pols1oh at bestweb.net (Michaell Taylor)
Date: Wed, 5 Dec 2001 15:51:38 -0500
Subject: [R] paste doesn't appear to paste?
Message-ID: <200112052051.VAA16076@stat.math.ethz.ch>


Sorry to be posting another question, but my learning curve is starting to 
flatten some now.

What am I missing here?  

> temp _ name[reis==toupper(location[order(Vgrablow2)][N])]
> temp
[1] "Lawton"
> paste(temp,g)
[1] "Lawton"                    # WHERE IS THE SECOND ELEMENT?
> g
[1] 0.29
> a _ "Lawton"
> paste(a,g)
[1] "Lawton 0.29"           # THIS WORKS (SECOND ELEMENT EXISTS ALSO)
> mode(a)
[1] "character"
> mode(temp)
[1] "character"  		# TEMP AND A ARE BOTH CHARACTERS
>  paste(temp,g,sep="---")
[1] "Lawton"		# DOESN'T EVEN GIVE THE SEPERATOR
>  paste(a,g,sep="---")
[1] "Lawton---0.29"



extraneous info:

> mode(reis)
[1] "character"
> mode(location)
[1] "character"


Michaell Taylor
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Nick.Davis at treasury.govt.nz  Wed Dec  5 22:14:49 2001
From: Nick.Davis at treasury.govt.nz (Nick Davis)
Date: Thu, 6 Dec 2001 10:14:49 +1300 
Subject: [R] Code for Hodrick-Prescott Filter
Message-ID: <E1DB1E4A1D092145AE6D0F1FD6EFD0F502926B99@gertrude.hamlet.treasury.govt.nz>

Has anyone written any code for the Hodrick-Prescott filter?  I have a some
uncompiled FORTRAN code from Ed Prescott but I'd like to save myself some
programming time if possible.  Thanks for your help.
 
Nick Davis
Crown Financial Policy
Asset and Liability Management Branch
The New Zealand Treasury

Direct:         +64-4-471-5924
Fax:            +64-4-499-0143
Email:          mailto:nick.davis at treasury.govt.nz 
Web:            www.treasury.govt.nz
Research:       www.treasury.govt.nz/workingpapers


Caution: The content of this email is the property of The New Zealand
Treasury. If you have received this message in error please notify the
sender immediately and delete.  The content of this email does not
necessarily reflect the views of The New Zealand Treasury.  If the recipient
has any concerns about the content of this email they should seek
alternative confirmation from The New Zealand Treasury.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011206/02f9367e/attachment.html

From dsmith at insightful.com  Wed Dec  5 22:18:16 2001
From: dsmith at insightful.com (David Smith)
Date: Wed, 5 Dec 2001 13:18:16 -0800
Subject: [R] memory issue trying to solve too large a problem using hclust
In-Reply-To: <3C0E6961.708CA691@EUnet.at>
Message-ID: <LFEOLJDPHEIPIBEOGDDBCEJNEBAA.dsmith@insightful.com>

> Sorrowly, I did not have time to try it, but it seems that I would
> have to start using more R and less S-Plus, since "as.dist()" does
> not exist in S-Plus (maybe it works with dist, I have to try)

With S-PLUS's hclust, you can just pass in the correlation matrix:

  d <- 1-cor(x)^2
  hc <- hclust(d)

You could always do as.dist <- I in S-PLUS if you want a cross-system
script.

# David

--
David M Smith <dsmith at insightful.com>
S-PLUS Product Marketing Manager, Insightful Corp, Seattle WA
Tel: +1 (206) 283 8802 x360
Fax: +1 (206) 283 0347

Insightful Corporation provides analytical solutions leveraging
S-PLUS, StatServer, S-PLUS Analytic Server and consulting services.
See www.insightful.com for details.

> -----Original Message-----
> From: owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch]On Behalf Of cstrato at EUnet.at
> Sent: Wednesday, December 05, 2001 10:37
> To: carlos.ortega at minorplanet.com; 'Aboubakar Maitournam';
> r-help at stat.math.ethz.ch
> Subject: Re: [R] memory issue trying to solve too large a problem using
> hclust
>
>
> Dear all
>
> I would like to thank all people who have responded (Carlos Ortega,
> Aboubakar Maitournam, Ron Wherens, Christian Henning and Andy Liaw).
> Some have sent their answers to my mail-address only, so I am never
> quite sure if they want me to foreward their answers to r-help or
> not. In contrast to S-news, at R most people respond to r-help,
> which I find preferable.
>
> I am especially greatful to Andy Liaw ,who mentioned the following
> possibility to use correlation in hclust:
>   d <- 1-cor(x)^2
>   hc <- hclust(as.dist(d))
> Sorrowly, I did not have time to try it, but it seems that I would
> have to start using more R and less S-Plus, since "as.dist()" does
> not exist in S-Plus (maybe it works with dist, I have to try)
>
> Best regards
> Christian Stratowa
>
> Carlos Ortega wrote:
>
> > Hello,
> >
> > I am wondering if the "dna library 0.2" that Proffesor Jim Landsey made
> > available on March 2000 (www.luc.ac.be/~jlindsey/rcode.html )
> as well as his
> > papers ("An Introduction to Markov Models in Molecular Biology. (2000)
> > available at http://alpha.luc.ac.be/~lucp0753/manuscripts.html
> ) are useful
> > for your purposes.
> >
> > Thanks,
> > Carlos Ortega.
> >
> > -----Mensaje original-----
> > De: owner-r-help at stat.math.ethz.ch
> > [mailto:owner-r-help at stat.math.ethz.ch]En nombre de Aboubakar Maitournam
> > Enviado el: miercoles, 05 de diciembre de 2001 11:15
> > Para: cstrato at EUnet.at; r-help at stat.math.ethz.ch
> > Asunto: Re: [R] memory issue trying to solve too large a problem using
> > hclust
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jameson at monumental.com  Wed Dec  5 23:00:45 2001
From: jameson at monumental.com (Jameson C . Burt)
Date: Wed, 5 Dec 2001 17:00:45 -0500
Subject: [R] Detecting numerical value in character variable
Message-ID: <20011205170045.A15700@rabbit.burtnet>

I have a variable that can have either numeric or character values.
When numeric, I take one action; when not-numeric, I take another action.
Unfortunately, my approaches are awkward, so I look for others' approaches.

To detect a numeric value, I have semi-successfully used two appoaches.
I somewhat simplify here using direct character values like "123" rather than a variable.
1. !is.na(as.numeric("123"))
   which responds "TRUE", but
      !is.na(as.numeric("abc"))
   responds
      FALSE    #so I know it is not numeric
      Warning message:
      NAs introduced by coercion
   This all works well enough except the error message looks bad 
   when printed, and hints that I use the wrong appoach.

2. !as.logical(gsub("1","T",gsub("-1","F",as.character(regexpr("[^0-9]","123")))))
   This responds "TRUE" for the string "123" having only numeric characters.
   However, notice how harsh this is on the reader.
   
   Unfortunately, "regexpr" here responds in -1 and 1 rather than FALSE and TRUE, 
   so this becomes an extra verbose appoach.

My question: CAN ONE BETTER DETECT NUMERIC DATA IN A CHARACTER VARIABLE?
One first imagines trying,
   is.numeric("123")
but this responds FALSE, telling us merely that this is a character string.


This problem arises in an R program I have used for years to balance my checkbook,
producing 5 lines identical to my bank's statement.
I input my checkbook data from a file with one natural column having entries like
(excluding # comments),
   3117             #check number
   SALARY:10-1-01   #salary deposited on 10/1/2001
   TRANSF:10-23-01  #transfer between accounts on 10/23/2001
These non-numerical descriptive entries speed balancing my checkbook,
especially when I error.



-- 
Jameson C. Burt, NJ9L   Fairfax, Virginia, USA
jameson at coost.com       http://www.coost.com
(202) 690-0380 (work)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From roger at ysidro.econ.uiuc.edu  Wed Dec  5 23:03:02 2001
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Wed, 5 Dec 2001 16:03:02 -0600 (CST)
Subject: [R] Code for Hodrick-Prescott Filter
In-Reply-To: <E1DB1E4A1D092145AE6D0F1FD6EFD0F502926B99@gertrude.hamlet.treasury.govt.nz>
Message-ID: <Pine.GSO.4.33.0112051602280.26481-100000@ysidro.econ.uiuc.edu>

This is a special case of smooth.spline in modreg.


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Thu, 6 Dec 2001, Nick Davis wrote:

> Has anyone written any code for the Hodrick-Prescott filter?  I have a some
> uncompiled FORTRAN code from Ed Prescott but I'd like to save myself some
> programming time if possible.  Thanks for your help.
>
> Nick Davis
> Crown Financial Policy
> Asset and Liability Management Branch
> The New Zealand Treasury
>
> Direct:         +64-4-471-5924
> Fax:            +64-4-499-0143
> Email:          mailto:nick.davis at treasury.govt.nz
> Web:            www.treasury.govt.nz
> Research:       www.treasury.govt.nz/workingpapers
>
>
> Caution: The content of this email is the property of The New Zealand
> Treasury. If you have received this message in error please notify the
> sender immediately and delete.  The content of this email does not
> necessarily reflect the views of The New Zealand Treasury.  If the recipient
> has any concerns about the content of this email they should seek
> alternative confirmation from The New Zealand Treasury.
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From coleh at quasarintl.com  Wed Dec  5 23:58:30 2001
From: coleh at quasarintl.com (Cole Harris)
Date: Wed, 05 Dec 2001 15:58:30 -0700
Subject: [R] write.table very slow
Message-ID: <sc0e442f.012@quasarintl.com>

When writing tables with a large number of columns, write.table() seems to take way too much time - e.g. a table with ~80 rows and ~6000 columns takes ~30 min cpu on my 900 MHz pc.
I would appreciate any explainations or advice.

Thanks,
Cole
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec  5 23:56:11 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 05 Dec 2001 23:56:11 +0100
Subject: [R] paste doesn't appear to paste?
In-Reply-To: <200112052051.VAA16076@stat.math.ethz.ch>
References: <200112052051.VAA16076@stat.math.ethz.ch>
Message-ID: <x27ks19sz8.fsf@blueberry.kubism.ku.dk>

Michaell Taylor <pols1oh at bestweb.net> writes:

> Sorry to be posting another question, but my learning curve is starting to 
> flatten some now.
> 
> What am I missing here?  
> 
> > temp _ name[reis==toupper(location[order(Vgrablow2)][N])]
> > temp
> [1] "Lawton"
> > paste(temp,g)
> [1] "Lawton"                    # WHERE IS THE SECOND ELEMENT?
> > g
> [1] 0.29
> > a _ "Lawton"
> > paste(a,g)
> [1] "Lawton 0.29"           # THIS WORKS (SECOND ELEMENT EXISTS ALSO)
> > mode(a)
> [1] "character"
> > mode(temp)
> [1] "character"  		# TEMP AND A ARE BOTH CHARACTERS
> >  paste(temp,g,sep="---")
> [1] "Lawton"		# DOESN'T EVEN GIVE THE SEPERATOR
> >  paste(a,g,sep="---")
> [1] "Lawton---0.29"
> 
> 
> 
> extraneous info:
> 
> > mode(reis)
> [1] "character"
> > mode(location)
> [1] "character"

Nothing obvious. We may have a bug and/or something odd sneaked into
the "name" vector. What's the version info, btw?

You could try

dput(temp)
a==temp

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Norman.Good at dpi.qld.gov.au  Thu Dec  6 00:53:00 2001
From: Norman.Good at dpi.qld.gov.au (Good, Norman)
Date: Thu, 6 Dec 2001 09:53:00 +1000 
Subject: [R] Non-linear random variables
Message-ID: <A3D56E56D0CED311A23300A0C9FC21FACBB40C@SFCCRMNT001>

I have a fisheries Ricker stock-recruitment non-linear model which I am
trying to code up in R (after failing in MATLAB). There are two fixed
parameters and a random environmental effect that is linked to a first order
lagged correlation fixed parameter.

Are there any examples of fitting this model I could follow?


Cheers 

Norm Good

Fisheries Biologist (Mathematician)
Southern Fisheries Centre
PO Box 76, Deception Bay Q 4508
telephone 3817 9588, fascimile 3817 9555




********************************DISCLAIMER****************************
The information contained in the above e-mail message or messages 
(which includes any attachments) is confidential and may be legally 
privileged.  It is intended only for the use of the person or entity 
to which it is addressed.  If you are not the addressee any form of 
disclosure, copying, modification, distribution or any action taken 
or omitted in reliance on the information is unauthorised.  Opinions 
contained in the message(s) do not necessarily reflect the opinions 
of the Queensland Government and its authorities.  If you received 
this communication in error, please notify the sender immediately and 
delete it from your computer system network.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From GPetris at uark.edu  Thu Dec  6 01:28:09 2001
From: GPetris at uark.edu (Giovanni Petris)
Date: Wed, 5 Dec 2001 18:28:09 -0600 (CST)
Subject: [R] Building R on Solaris with SUNperf 
Message-ID: <200112060028.SAA26713@definetti.uark.edu>


Dear All,

I am building R-1.3.1 on Solaris 2.7 and I am trying to use the native
SUNperf BLAS/LAPACK. I have added the flags ("-dalign
-xlic_lib=sunperf") for the compilers in the config.site file. 
What is not clear to me is what I have to do with the "--with-blas"
flag for ./configure. It seems to me that omitting it is not enough. 
Any suggestions? 

Another question, I guess about how to organize directories and get
rid of obsolete versions of R, is the following. A directory listing
of /export/home/share/R on my machine gives:

Wed<18:17>R[85]#ls /export/home/share/R
library/      R-1.2.0/      R-1.2.2/      R-1.3.1/      R-1.3.1.tgz
 
I keep in "library/" all the packages, and I build each version of R in
the directory with the same name. My question is: can I safely nuke
R-1.2.0/ and R-1.2.2/ once I have a working R-1.3.1?

Thank you in advance.
Best,
Giovanni

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (501) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nikolai at eri.u-tokyo.ac.jp  Thu Dec  6 03:18:56 2001
From: nikolai at eri.u-tokyo.ac.jp (Nick Kostrov)
Date: Thu, 6 Dec 2001 11:18:56 +0900
Subject: [R] How to change font size?
In-Reply-To: <Pine.LNX.4.31.0112051424270.23186-100000@gannet.stats>
References: <Pine.LNX.4.31.0112051424270.23186-100000@gannet.stats>
Message-ID: <01120611185601.05944@nick-pc>

On  5 December 2001 23:28, you wrote:
> On Wed, 5 Dec 2001, Nick Kostrov wrote:
> > Does anybody know how to change the font size of  axis labels in the
> > graphic window? I found that it is possible to change  font to "bold" 
> > but labels are very tiny.
>
> Using some variation on graphics parameter cex, depending if the `axis
> labels' are the numbers or the x/ylab= labels.
>
> However, more likely your device is set up wrongly.  Take a look at
> its parameters, which may include pointsize, for example.
>
> To help more we need to know
>
> 1) the details of your system
I use Linux Slackware 8.0 with X11 Window system and R-1.3.1
> 2) what you used to get the plot
>
> 3) what exactly is the problem.
Actually, I draw the multiple plot and I'd like to put  the axis under the 
bottom of the last one with big labels. Labels are numbers. Here is my code:

"plotizu"<-function(name,tl,ot,to){
t<-"l"
at3<-floor(max(na.exclude(name)))
at1<-ceiling(min(na.exclude(name)))
plot(ot:to,name,main=tl,axes=F,xlab="",ylab="",type=t);
axis(2,at=c(at1,at3),font=2)
}


"plotst2"<-function(izu.stkwz,izu.stkwz.recon,izu.stkwz.recon2){


#
#plotst2(izu.stkwz,izu.stkwz.recon,izu.stkwz.recon2)
#
#postscript('PS/ysd.ps')
#par(mfrow=c(3,1));plot(izu.stkwz$ysd,xlab="ysd original");
#plot(izu.stkwz.recon$ysd,xlab="ysd mb8 
max.level=2");plot(izu.stkwz.recon2$ysd,xlab="ysd mb4 max.level=2" )
#dev.off() 

#t<-"s"
# Raw data
#load('Rdata.la8/izu.stkwz.Rdata')
# Denoised
#load('Rdata2/izu.stkwz.recon2.Rdata')
#plot name
source('plotizu.R')  
# plotizu(nm,title)
#X11(pointsize = 16)
par(mfrow=c(6,1));

#6940 correspons to 1998/12/31
#3654 correspons to 1990/01/01 
ot<-3654
otd<-1990

to<-6940
tod<-1998

#1
nm<-izu.stkwz.recon2$ar2[ot:to]
tl<-"AR2-KWZ"
plotizu(nm,tl,ot,to)
#2
nm<-izu.stkwz.recon2$ara[ot:to]
tl<-"ARA-KWZ"
plotizu(nm,tl,ot,to)
#3
nm<-izu.stkwz.recon2$ik2[ot:to]
tl<-"IK2-KWZ"
plotizu(nm,tl,ot,to)
#4
nm<-izu.stkwz.recon2$kwn[ot:to]
tl<-"KWN-KWZ"
plotizu(nm,tl,ot,to) 
#5
nm<-izu.stkwz.recon2$mk2[ot:to]
tl<-"MK2-KWZ"
plotizu(nm,tl,ot,to)
#6
nm<-izu.stkwz.recon2$mkw[ot:to]
tl<-"MKW-KWZ"
plotizu(nm,tl,ot,to)



#now plot X axis
a<-seq(ISOdate(otd,1,1,tz="GMT"), ISOdate(tod+1,12,31,tz="GMT"),"years")
lla<-length(a);
a<-format(a, format="%Y", tz="GMT") 
#a1<-strptime(as.character(a),format="%m/%Y")

a<-c(1990,"","","","","","","","","","","",1991,"","","","","","","","","","","",1992,"","","","","","","","","","","",1993,"","","","","","","","","","","",1994,"","","","","","","","","","","",1995,"","","","","","","","","","","",1996,"","","","","","","","","","","",1997,"","","","","","","","","","","",1998,"","","","","","","","","","","",1999)
axis(side=1,at=seq(ot,to,by=(to-ot)/(9*12)),labels=a,font=2)
a<-c(1990,1991,1992,1993,1994,1995,1996,1997,1998,1999)
axis(side=1,at=seq(ot,to,by=(to-ot)/9),labels=a,font=2)

}

"plotst3"<-function(izu.stkwz,izu.stkwz.recon,izu.stkwz.recon2){


#
#plotst3(izu.stkwz,izu.stkwz.recon,izu.stkwz.recon2)
#
#postscript('PS/ysd.ps')
#par(mfrow=c(3,1));plot(izu.stkwz$ysd,xlab="ysd original");
#plot(izu.stkwz.recon$ysd,xlab="ysd mb8 
max.level=2");plot(izu.stkwz.recon2$ysd,xlab="ysd mb4 max.level=2" )
#dev.off() 

#t<-"s"
# Raw data
#load('Rdata.la8/izu.stkwz.Rdata')
# Denoised
#load('Rdata2/izu.stkwz.recon2.Rdata')
#plot name
source('plotizu.R')  
# plotizu(nm,title)
#X11(pointsize = 16)
par(mfrow=c(7,1));

#6940 correspons to 1998/12/31
#3654 correspons to 1990/01/01 
ot<-3654
otd<-1990

to<-6940
tod<-1998

#1
nm<-izu.stkwz.recon2$ois[ot:to]
tl<-"OIS-KWZ"
plotizu(nm,tl,ot,to)
#2
nm<-izu.stkwz.recon2$sgh[ot:to]
tl<-"SGH-KWZ"
plotizu(nm,tl,ot,to)
#3
nm<-izu.stkwz.recon2$swg[ot:to]
tl<-"SWG-KWZ"
plotizu(nm,tl,ot,to)
#4
nm<-izu.stkwz.recon2$tgs[ot:to]
tl<-"TGS-KWZ"
plotizu(nm,tl,ot,to) 
#5
nm<-izu.stkwz.recon2$ykw[ot:to]
tl<-"YKW-KWZ"
plotizu(nm,tl,ot,to)
#6
nm<-izu.stkwz.recon2$ysd[ot:to]
tl<-"YSD-KWZ"
plotizu(nm,tl,ot,to)
#7
nm<-izu.stkwz.recon2$ytn[ot:to]
tl<-"YTN-KWZ"
plotizu(nm,tl,ot,to)


#now plot X axis
a<-seq(ISOdate(otd,1,1,tz="GMT"), ISOdate(tod+1,12,31,tz="GMT"),"years")
lla<-length(a);
a<-format(a, format="%Y", tz="GMT") 
#a1<-strptime(as.character(a),format="%m/%Y")

a<-c(1990,"","","","","","","","","","","",1991,"","","","","","","","","","","",1992,"","","","","","","","","","","",1993,"","","","","","","","","","","",1994,"","","","","","","","","","","",1995,"","","","","","","","","","","",1996,"","","","","","","","","","","",1997,"","","","","","","","","","","",1998,"","","","","","","","","","","",1999)
axis(side=1,at=seq(ot,to,by=(to-ot)/(9*12)),labels=a,font=2)
a<-c(1990,1991,1992,1993,1994,1995,1996,1997,1998,1999)
axis(side=1,at=seq(ot,to,by=(to-ot)/9),labels=a,font=2)

}


Thanks,

Nick

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gumpleon at hotmail.com  Thu Dec  6 06:22:58 2001
From: gumpleon at hotmail.com (Gang Liang)
Date: Wed, 5 Dec 2001 21:22:58 -0800
Subject: [R] Questions about piecewise spline fitting
References: <F144mGvweQaWGckg0pr0002056c@hotmail.com> <002001c17d70$d1780f00$5c13070a@it.giustizia.it>
Message-ID: <OE15DEJmGzrLCCtgx8V00004268@hotmail.com>

Thanks a lot for your advices.

My real problem is that the knot positions are not predetermined,  so I have
to deal with this part by myself, :(.

----- Original Message -----
From: "MUGGEO VITO" <vito.muggeo at giustizia.it>
To: "Gang Liang" <gumpleon at hotmail.com>; <r-help at hypatia.math.ethz.ch>
Sent: Wednesday, December 05, 2001 1:39 AM
Subject: Re: [R] Questions about piecewise spline fitting


> Hi,
> What you need is just the bs() or ns() functions in the library splines in
> the R-software. You have to specify the knots and can specify the degree.
> For instance:
>
> library(splines)
> bs(1:20, knots=c(5,11), degree=1) #performs three #straight lines with
> break-point at x=5 and 11 for the variable 1:20
> lm(y~bs(1:20, knots=c(5,11), degree=1)) #piecewise linear regression
>
> Common "problem" is that the beta parameters for the pseudo-variables
> inducted by bs() are not interpretable (i.e. in linear case they don't
> represents the slopes in each piece).
> best,
> vito
>
>
> ----- Original Message -----
> From: "Gang Liang" <gumpleon at hotmail.com>
> To: <r-help at hypatia.math.ethz.ch>
> Sent: Wednesday, December 05, 2001 7:05 AM
> Subject: [R] Questions about piecewise spline fitting
>
>
> > Hi All,
> >
> > I want to fit a piecewise spline of degree 1, i.e. a spline consisting
of
> a
> > straight line over each piece. I downloaded the R package pspline, then
I
> > have following questions:
> >
> > 1. in the program, the degree of the spline is specified by 2*norder-1.
> Why
> > do they adopt such scheme that we can only fit a spline with odd degree?
> >
> > 2. norder cannot be set to 1. Is there any specific reason for doing so?
> >
> > Maybe I need to code this by myself. So I'd like to hear your advices.
> >
> > Thanks in advance,
> > Gang
> >
> >
> > _________________________________________________________________
> >
> >
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-
> > r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> >
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Thu Dec  6 08:24:12 2001
From: siim at obs.ee (Ott Toomet)
Date: Thu, 6 Dec 2001 08:24:12 +0100 (CET)
Subject: [R] paste doesn't appear to paste?
In-Reply-To: <200112052051.VAA16076@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.33.0112060817520.10059-100000@ecopc64.eco.au.dk>

Hi,

My knowledge about R is somewhat limited but I had a bit similar problem
with paste a month or so ago (you can search the topic ,,bug and paste'' or
something similar in the archive).

That time the problem seemed to be that I had read my data in as stata-file using
read.dta, and seemed that it was a kind of bug in that function.  The
result was that the variables was stored into memory not correctly, an error
which did not affect print() but did affect paste() (or have I
misunderstood something?).  The problem vanished if I saved the data with
save() and read it again with load().

You did not explained how did you get your data but perhaps it helps.

Sincerely,

Ott Toomet
---------------------------------------------------
On Wed, 5 Dec 2001, Michaell Taylor wrote:

>
> Sorry to be posting another question, but my learning curve is starting to
> flatten some now.
>
> What am I missing here?
>
> > temp _ name[reis==toupper(location[order(Vgrablow2)][N])]
> > temp
> [1] "Lawton"
> > paste(temp,g)
> [1] "Lawton"                    # WHERE IS THE SECOND ELEMENT?
> > g
> [1] 0.29
> > a _ "Lawton"
> > paste(a,g)
> [1] "Lawton 0.29"           # THIS WORKS (SECOND ELEMENT EXISTS ALSO)
> > mode(a)
> [1] "character"
> > mode(temp)
> [1] "character"  		# TEMP AND A ARE BOTH CHARACTERS
> >  paste(temp,g,sep="---")
> [1] "Lawton"		# DOESN'T EVEN GIVE THE SEPERATOR
> >  paste(a,g,sep="---")
> [1] "Lawton---0.29"
>
>
>
> extraneous info:
>
> > mode(reis)
> [1] "character"
> > mode(location)
> [1] "character"
>
>
> Michaell Taylor
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Thu Dec  6 08:31:52 2001
From: siim at obs.ee (Ott Toomet)
Date: Thu, 6 Dec 2001 08:31:52 +0100 (CET)
Subject: [R] write.table very slow
In-Reply-To: <sc0e442f.012@quasarintl.com>
Message-ID: <Pine.LNX.4.33.0112060824450.10059-100000@ecopc64.eco.au.dk>

Hi,

I think the problem lies in the code of write.table().  It is essentially a
paste() function, which pastes all the data in the table into a long
character string and thereafter writes the string into file.  I was not able
to write a dataset of 7500 obs times 1200 variables at all, I had to split
it up into smaller units and write those separately.  In addition caused it
much swapping on my 128MB system.

I think (I have not tried) it could work faster in your case if you just
save the observatons separately into separate files and thereafter merge the
files (but it is worth of doing only if you have to write the table
repeatedly, of course).  In long run I think a rewrite of the write.table()
in C in such a way that it do not store the whole file in memory may be a
solution.

Regards,

Ott Toomet
-------------------------------
On Wed, 5 Dec 2001, Cole Harris wrote:

> When writing tables with a large number of columns, write.table() seems to take way too much time - e.g. a table with ~80 rows and ~6000 columns takes ~30 min cpu on my 900 MHz pc.
> I would appreciate any explainations or advice.
>
> Thanks,
> Cole
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec  6 08:51:48 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Dec 2001 07:51:48 +0000 (GMT)
Subject: [R] install R-1.3.1 on Solaris 8
In-Reply-To: <Pine.SOL.3.93.1011205141550.4713A-100000@mushroom.math.sc.edu>
Message-ID: <Pine.LNX.4.31.0112060750280.1743-100000@gannet.stats>

On Wed, 5 Dec 2001, Wu Shuyuan wrote:

> Dear All:
>
> I tried to compile and install R-1.3.1 on Solaris 8,but never
> succeeded, Can you give me any suggestion?
> I used
> ./configure --with-x --x-includes=/usr/openwin/share/include/X11 \
> --x-libraries=/usr/openwin/lib --with-f77 \
> --with-tcl-config=/usr/local/lib --with-tk-config=/usr/local/lib
> I noticed that ld used /usr/ccs/bin/ld(ld: Software Generation
> Utilities-Solaris-ELF (4. 0)). I changed in config.site
> MAIN_LD=/usr/local/bin/ld(GNU ld version 2.9.1 (with BFD 2.9.1)
>   Supported emulations:
>    elf32_sparc)
> but R always use /usr/ccs/bin/ld.

It should.  GNU ld is not recommended on Solaris, AFAIK, and certainly
not with Sun's compiler (f77).


>
> I put the log files of configure, make,make check on the
> http://www.math.sc.edu/~wu/, click R compile problem on Solaris 8.
>
> Any suggestion are highly appreciated.
>
> Thank you!
>
> Shuyuan Wu
> Tel: 803-777-9312(o)
>
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec  6 08:55:58 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Dec 2001 07:55:58 +0000 (GMT)
Subject: [R] Building R on Solaris with SUNperf 
In-Reply-To: <200112060028.SAA26713@definetti.uark.edu>
Message-ID: <Pine.LNX.4.31.0112060752520.1743-100000@gannet.stats>

The short answer is read the R-admin.html manual.  You need to use f95 to
get the right libraries, and then the configure script automatically uses
sunperf.  It won't work with f77 (or g77).

Also, R will not make use of all external LAPACK, because it needs a
bug-fixed LAPACK 3, and there is no way to guarantee that.

On Wed, 5 Dec 2001, Giovanni Petris wrote:

>
> Dear All,
>
> I am building R-1.3.1 on Solaris 2.7 and I am trying to use the native
> SUNperf BLAS/LAPACK. I have added the flags ("-dalign
> -xlic_lib=sunperf") for the compilers in the config.site file.
> What is not clear to me is what I have to do with the "--with-blas"
> flag for ./configure. It seems to me that omitting it is not enough.
> Any suggestions?
>
> Another question, I guess about how to organize directories and get
> rid of obsolete versions of R, is the following. A directory listing
> of /export/home/share/R on my machine gives:
>
> Wed<18:17>R[85]#ls /export/home/share/R
> library/      R-1.2.0/      R-1.2.2/      R-1.3.1/      R-1.3.1.tgz
>
> I keep in "library/" all the packages, and I build each version of R in
> the directory with the same name. My question is: can I safely nuke
> R-1.2.0/ and R-1.2.2/ once I have a working R-1.3.1?
>
> Thank you in advance.
> Best,
> Giovanni
>
> --
>
>  __________________________________________________
> [                                                  ]
> [ Giovanni Petris                 GPetris at uark.edu ]
> [ Department of Mathematical Sciences              ]
> [ University of Arkansas - Fayetteville, AR 72701  ]
> [ Ph: (501) 575-6324, 575-8630 (fax)               ]
> [ http://definetti.uark.edu/~gpetris/              ]
> [__________________________________________________]
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec  6 09:22:16 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Dec 2001 08:22:16 +0000 (GMT)
Subject: [R] Detecting numerical value in character variable
In-Reply-To: <20011205170045.A15700@rabbit.burtnet>
Message-ID: <Pine.LNX.4.31.0112060815210.1743-100000@gannet.stats>

On Wed, 5 Dec 2001, Jameson C . Burt wrote:

> I have a variable that can have either numeric or character values.
> When numeric, I take one action; when not-numeric, I take another action.
> Unfortunately, my approaches are awkward, so I look for others' approaches.
>
> To detect a numeric value, I have semi-successfully used two appoaches.
> I somewhat simplify here using direct character values like "123" rather than a variable.
> 1. !is.na(as.numeric("123"))
>    which responds "TRUE", but
>       !is.na(as.numeric("abc"))
>    responds
>       FALSE    #so I know it is not numeric
>       Warning message:
>       NAs introduced by coercion
>    This all works well enough except the error message looks bad
>    when printed, and hints that I use the wrong appoach.

That is the best current approach.  Set options(warn=-1) around the piece
of code using it.

Another approach in 1.4.0 (real soon now) is to use type.convert, and
check if the answer is mode "numeric").

>
> 2. !as.logical(gsub("1","T",gsub("-1","F",as.character(regexpr("[^0-9]","123")))))
>    This responds "TRUE" for the string "123" having only numeric characters.
>    However, notice how harsh this is on the reader.

Well, numbers can have decimal points in, and you are only testing if
any character is non-numeric.

regexpr("[^\.0-9]","123") == -1

would be pretty good.  This would not allow exponential notation nor Inf
or -Inf, though.

>    Unfortunately, "regexpr" here responds in -1 and 1 rather than FALSE and TRUE,
>    so this becomes an extra verbose appoach.

See above.

> My question: CAN ONE BETTER DETECT NUMERIC DATA IN A CHARACTER VARIABLE?
> One first imagines trying,
>    is.numeric("123")
> but this responds FALSE, telling us merely that this is a character string.

Correct, as documented.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jefferis at stanford.edu  Thu Dec  6 09:52:34 2001
From: jefferis at stanford.edu (Greg Jefferis)
Date: Thu, 06 Dec 2001 00:52:34 -0800
Subject: [R] 3D spatial statistics
Message-ID: <B83471CF.370B%jefferis@stanford.edu>

Dear R Users,

This is only partly an R question, but I would be very grateful if anyone
could offer some suggestions for approaches or packages I could use in R.  I
have 11 sets of points in 3D (synapses in a region of a fly's brain for 11
different kinds of neurons as it happens); each set has between 80-250
points distributed in an irregularly shaped cloud.  I would like to
calculate 

a) a measure of similarity of the distributions of points between pairwise
combinations of the 11 groups; i.e. using colour to represent the 11 groups,
how similar are the distributions of 'red' and 'green' points - is this more
or less than red and blue points.

b) using some kind of thresholding to remove outliers, a volume occupied by
these points; a convex hull would be not be appropriate as some of these
clouds look like a 3D boomerang.

I am aware that there are some spatial stats packages which might be useful
in 2D situations.  Are there any functions which might be applicable for
these three dimensional cases.  If anyone could suggest an appropriate
textbook for a non-specialist in this general area of statistics that would
also be much appreciated.  Very many thanks,

Greg Jefferis.


Incidentally I have approached (a) rather crudely by making use of the knn
function in package = class for each pairwise combination of the 11 groups.
Briefly for every single point I figure out the proportion of its k nearest
neighbours that are of the same 'colour' and divide that by the proportion
of all points that are of that 'colour'.  I then average over all the points
presently under consideration, to get an index of how homogeneously
distributed the two sets of points are with respect to each other.



__________________________________________________________________________
Greg Jefferis,                          Lab Address: Liqun Luo, Herrin 144
Neurosciences PhD Programme &                e-mail: jefferis at stanford.edu
Dept Biological Sciences,                       Lab: (650) 725 5809
Gilbert Biology Building,                       Fax: (650) 723 0589
371 Serra Mall,
Stanford, CA 94305-5020.                       Home: (650) 497 1135

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Soren.Hojsgaard at agrsci.dk  Thu Dec  6 10:13:13 2001
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Thu, 6 Dec 2001 10:13:13 +0100 
Subject: [R] Contrasts in lm
Message-ID: <5166A14C6887D111991100805F8BB749072C43AD@foulum01.agrsci.dk>

Dear all,

In SAS (GLM and MIXED) estimable functions (linear functions of the
parameters) can be specified in the ESTIMATE and CONTRAST statements.

Has anyone written a similar "utility" for use in connection with lm?

Thanks in advance

S?ren H?jsgaard 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec  6 10:19:39 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Dec 2001 09:19:39 +0000 (GMT)
Subject: [R] Contrasts in lm
In-Reply-To: <5166A14C6887D111991100805F8BB749072C43AD@foulum01.agrsci.dk>
Message-ID: <Pine.LNX.4.31.0112060917170.9789-100000@gannet.stats>

On Thu, 6 Dec 2001, [iso-8859-1] Søren Højsgaard wrote:

> Dear all,
>
> In SAS (GLM and MIXED) estimable functions (linear functions of the
> parameters) can be specified in the ESTIMATE and CONTRAST statements.
>
> Has anyone written a similar "utility" for use in connection with lm?

?contrast, ?contrasts

This is a very general facility in S, and you may need to read up on it
(I recommend Bill Venables' account in MASS).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bxc at novonordisk.com  Thu Dec  6 11:36:32 2001
From: bxc at novonordisk.com (BXC (Bendix Carstensen))
Date: Thu, 6 Dec 2001 11:36:32 +0100 
Subject: [R] More function arguments meaning the same.
Message-ID: <D5A7D734C9C5D211B9E30008C78923020E95B062@exdkba03.novo.dk>

Sometimes when I write a function, I would like 
be able to have two or more names for an argument 
(you can never remember whether it is called "breaks", 
"Brk", "cuts" or "Cut".)

Is there a smart way of doing this, in the case where 
1) a default value for the argument should be supplied AND
2) the deparse( substitute( arg ) ) should work for graph annotation etc.

Bendix Carstensen

----------------------
Bendix Carstensen
Senior Statistician
Steno Diabetes Centre
Niels Steensens Vej 2
DK-2820 Gentofte
Denmark
tel: +45 44 43 87 38
mob: +45 28 25 87 38
fax: +45 44 43 73 13
bxc at novonordisk.com
www.biostat.ku.dk/~bxc
----------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bxc at novonordisk.com  Thu Dec  6 11:52:19 2001
From: bxc at novonordisk.com (BXC (Bendix Carstensen))
Date: Thu, 6 Dec 2001 11:52:19 +0100 
Subject: [R] Contrasts in lm
Message-ID: <D5A7D734C9C5D211B9E30008C78923020E95B063@exdkba03.novo.dk>

Just yesterday I wrote the following function. But you have to set up the 
contrast matrix for yourself and make sure it is sensible.

ci.mat <- 
function( alpha = 0.05 ) 
{
# Gives 1 2 x 3 matrix to multiply onto the first two
# colums of coefficients to give c.i.s
# BxC, 10/00
rbind( c(1,1,1), qnorm(1-alpha/2)*c(0,-1,1) )
}  

contr <- 
function( obj, cm, alpha=0.05 )
{
# Function to compute arbitrary contrasts with c.i.
# from a linear model ( lm, glm or nlme )
# BxC, 12/01.
if ( "lme" %in% class( obj ) ) 
  {
  cf  <- summary(obj)$tTable
  rho <- summary(obj)$cor  
  vcv <- rho * outer(cf[,2],cf[,2])
  }
if ( "lm" %in% class( obj ) )
  {
  cf  <- summary(obj)$coefficients
  vcv <- summary(obj)$cov.unscaled  
  }
if ( !dim( cm )[2]==dim( cf )[1] ) stop(  
   paste( "\n Dimension of ",
          deparse( substitute( cm ) ), ": ", paste( dim(cm), collapse="x" ),
          ", not compatible with no of parameters in ",
          deparse( substitute( obj ) ), ": ", dim(cf)[1], sep="" ) )
ct <- cm %*% cf[,1]
vc <- sqrt( diag( cm %*% vcv %*% t(cm) ) )
cbind( ct, vc ) %*% ci.mat( alpha=alpha )
}

----------------------
Bendix Carstensen
Senior Statistician
Steno Diabetes Centre
Niels Steensens Vej 2
DK-2820 Gentofte
Denmark
tel: +45 44 43 87 38
mob: +45 28 25 87 38
fax: +45 44 43 73 13
bxc at novonordisk.com
www.biostat.ku.dk/~bxc
----------------------



> -----Original Message-----
> From: S?ren H?jsgaard [mailto:Soren.Hojsgaard at agrsci.dk]
> Sent: 6. december 2001 10:13
> To: r-help at stat.math.ethz.ch
> Subject: [R] Contrasts in lm
> 
> 
> Dear all,
> 
> In SAS (GLM and MIXED) estimable functions (linear functions of the
> parameters) can be specified in the ESTIMATE and CONTRAST statements.
> 
> Has anyone written a similar "utility" for use in connection with lm?
> 
> Thanks in advance
> 
> S?ren H?jsgaard 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Thu Dec  6 12:08:38 2001
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Thu, 6 Dec 2001 11:08:38 +0000
Subject: [R] one command on several lines
In-Reply-To: <01120523303700.05944@nick-pc>
References: <01120523303700.05944@nick-pc>
Message-ID: <vJrzqMA2G1D8EwEL@myatt.demon.co.uk>

Nick Kostrov <nikolai at eri.u-tokyo.ac.jp> writes:
>Hello!
>
>Is it possible to continue expand one command on several lines in R ?
>
>An attempt to write
>
>a=c(1990," ",1991,
>      1992, 
>      1993,1994,1995,1996,1997,1998,
>     1999)
>
>in a file and then 
>
>source('file')
>
>results in 
>
>Error in parse(file, n, text, prompt) : syntax error on line 55 
>

'=' is used to give a function parameter a value when calling a
function, You want '<-'.

Mark


--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Thu Dec  6 12:18:47 2001
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Thu, 6 Dec 2001 11:18:47 +0000
Subject: [R] Detecting numerical value in character variable
In-Reply-To: <20011205170045.A15700@rabbit.burtnet>
References: <20011205170045.A15700@rabbit.burtnet>
Message-ID: <+Zz3uSAXQ1D8EwH5@myatt.demon.co.uk>

Jameson C . Burt <jameson at monumental.com> writes:
>I have a variable that can have either numeric or character values.
>When numeric, I take one action; when not-numeric, I take another action.
>Unfortunately, my approaches are awkward, so I look for others' approaches.
>
>To detect a numeric value, I have semi-successfully used two appoaches.
>I somewhat simplify here using direct character values like "123" rather than a 
>variable.
>1. !is.na(as.numeric("123"))
>   which responds "TRUE", but
>      !is.na(as.numeric("abc"))
>   responds
>      FALSE    #so I know it is not numeric
>      Warning message:
>      NAs introduced by coercion
>   This all works well enough except the error message looks bad 
>   when printed, and hints that I use the wrong appoach.
>
>2. !as.logical(gsub("1","T",gsub("-1","F",as.character(regexpr("[^0-9]","123")))
>))
>   This responds "TRUE" for the string "123" having only numeric characters.
>   However, notice how harsh this is on the reader.
>   
>   Unfortunately, "regexpr" here responds in -1 and 1 rather than FALSE and 
>TRUE, 
>   so this becomes an extra verbose appoach.
>
>My question: CAN ONE BETTER DETECT NUMERIC DATA IN A CHARACTER VARIABLE?
>One first imagines trying,
>   is.numeric("123")
>but this responds FALSE, telling us merely that this is a character string.
>
>
>This problem arises in an R program I have used for years to balance my 
>checkbook,
>producing 5 lines identical to my bank's statement.
>I input my checkbook data from a file with one natural column having entries 
>like
>(excluding # comments),
>   3117             #check number
>   SALARY:10-1-01   #salary deposited on 10/1/2001
>   TRANSF:10-23-01  #transfer between accounts on 10/23/2001
>These non-numerical descriptive entries speed balancing my checkbook,
>especially when I error.

Your first solution is fine:

        a <- c("a", "b", 3, 4, "f")
        b <- as.numeric(a)
        a[!is.na(b)]


but gives warnings. Suppress them with options():

        a <- c("a", "b", 3, 4, "f")
        options(warn = -1)
        b <- as.numeric(a)
        a[!is.na(b)]
        
Remember to reinstate warnings:

        options(warn = 1)

When you are finished. See help(options).

Mark

--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Thu Dec  6 12:07:00 2001
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Thu, 6 Dec 2001 11:07:00 +0000
Subject: [R] How to change font size?
In-Reply-To: <01120523204900.05791@nick-pc>
References: <01120523204900.05791@nick-pc>
Message-ID: <tpDziKAUF1D8Ewnw@myatt.demon.co.uk>

Nick Kostrov <nikolai at eri.u-tokyo.ac.jp> writes:
>
>Hello!
>
>
>Does anybody know how to change the font size of  axis labels in the graphic 
>window? I found that it is possible to change  font to "bold"  but labels are 
>very tiny.
>
>Thanks in advance,

par(cex), par(cex.axis), par(cex.lab), par(cex.main), par(cex.sub). See
help(par) for details.

Mark

--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vito.muggeo at giustizia.it  Thu Dec  6 14:40:11 2001
From: vito.muggeo at giustizia.it (MUGGEO VITO)
Date: Thu, 6 Dec 2001 14:40:11 +0100
Subject: [R] Extended Quasi Lik
Message-ID: <00c401c17e5b$9c719e20$5c13070a@it.giustizia.it>

Hi all,
I'm looking for some expert and/or volunteer which is intersted in
discussing with me about Extended-Quasi-Likelihood methods and relevant
implemantation in R.
The aim is conjoint modelling of mean and dispersion.
in GLM.
It should be not difficult, but there are some issue to be discussed.
Please, contact me and I replay to the list later.
best,
vito
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pols1oh at bestweb.net  Thu Dec  6 14:48:21 2001
From: pols1oh at bestweb.net (Michaell Taylor)
Date: Thu, 6 Dec 2001 08:48:21 -0500
Subject: [R] [bug] Follow up: paste doesn't...
In-Reply-To: <Pine.LNX.4.33.0112060817520.10059-100000@ecopc64.eco.au.dk>
References: <Pine.LNX.4.33.0112060817520.10059-100000@ecopc64.eco.au.dk>
Message-ID: <20011206134823.E343F62E1D@clavin.bestweb.net>


Bingo.  The object did come from a stata dataset originally, though it was 
transformed a few ways since being read in.

Saving it as an R object and reloading fixed the problem.  There must be a 
glitch in the foreign library.

Thanks to Ott Toomet and Peter Dalgaard for the assistance.

Ott Toomet wrote:
> Hi,
>
> My knowledge about R is somewhat limited but I had a bit similar problem
> with paste a month or so ago (you can search the topic ,,bug and paste'' or
> something similar in the archive).
>
> That time the problem seemed to be that I had read my data in as stata-file
> using read.dta, and seemed that it was a kind of bug in that function.  The
> result was that the variables was stored into memory not correctly, an
> error which did not affect print() but did affect paste() (or have I
> misunderstood something?).  The problem vanished if I saved the data with
> save() and read it again with load().
>
> You did not explained how did you get your data but perhaps it helps.
>
> Sincerely,
>
> Ott Toomet
> ---------------------------------------------------
>
> On Wed, 5 Dec 2001, Michaell Taylor wrote:
> > Sorry to be posting another question, but my learning curve is starting
> > to flatten some now.
> >
> > What am I missing here?
> >
> > > temp _ name[reis==toupper(location[order(Vgrablow2)][N])]
> > > temp
> >
> > [1] "Lawton"
> >
> > > paste(temp,g)
> >
> > [1] "Lawton"                    # WHERE IS THE SECOND ELEMENT?
> >
> > > g
> >
> > [1] 0.29
> >
> > > a _ "Lawton"
> > > paste(a,g)
> >
> > [1] "Lawton 0.29"           # THIS WORKS (SECOND ELEMENT EXISTS ALSO)
> >
> > > mode(a)
> >
> > [1] "character"
> >
> > > mode(temp)
> >
> > [1] "character"  		# TEMP AND A ARE BOTH CHARACTERS
> >
> > >  paste(temp,g,sep="---")
> >
> > [1] "Lawton"		# DOESN'T EVEN GIVE THE SEPERATOR
> >
> > >  paste(a,g,sep="---")
> >
> > [1] "Lawton---0.29"
> >
> > extraneous info:
> > > mode(reis)
> >
> > [1] "character"
> >
> > > mode(location)
> >
> > [1] "character"
> >
> >
> > Michaell Taylor
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> >.-.-.- r-help mailing list -- Read
> > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help", or
> > "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> >._._._

-- 
=========================================
Michaell Taylor, PhD
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vito.muggeo at giustizia.it  Thu Dec  6 15:08:09 2001
From: vito.muggeo at giustizia.it (MUGGEO VITO)
Date: Thu, 6 Dec 2001 15:08:09 +0100
Subject: [R] Questions about piecewise spline fitting
References: <F144mGvweQaWGckg0pr0002056c@hotmail.com> <002001c17d70$d1780f00$5c13070a@it.giustizia.it> <OE15DEJmGzrLCCtgx8V00004268@hotmail.com>
Message-ID: <00c501c17e5f$82b24a80$5c13070a@it.giustizia.it>

> Thanks a lot for your advices.
>
> My real problem is that the knot positions are not predetermined,  so I
have
> to deal with this part by myself, :(.

This isn't a simple question:
Likelihood model with linear predictor
b1*X+ b2*pmax(X-th,0)
i.e. depending on (b1, b2, th) is just *piecewise differenziable* and so the
classical regularity condition (large sample first order approx) are not
met.
Several approach have been discussed in literature:
see, for instance,
-Kuchenoff (1997), Computational Statistics, vol12, 249
-Gossl (2001) , Stat in Med, vol20, pg 3109 for a bayesian approach and the
references inside.

However fixed th, the model is a classical [G]LM. So a "grid-search-type"
algorithm can be carried out on the profile [log]Lik for th

#profile [log]Lik for th:
fn(th,yourdata){
....write the obj function ....
}

#maximize it
th<-optimize(fn,th,range(x)...,maximum=T)$max

#Fit classical [G]LM *assuming known the estimate*
[g]lm(y~x+pmax(x-th,0)....)
#or
[g]lm(y~bs(x, knots=th, degree=1)....)

Alternatively you can get a smoothing estimate of the non-linear relation
(by smoothspline() for instance), and looking at the plot to "estimate" the
break-point.

Best,
vito



----- Original Message -----
From: "Gang Liang" <gumpleon at hotmail.com>
To: "MUGGEO VITO" <vito.muggeo at giustizia.it>; <r-help at hypatia.math.ethz.ch>
Sent: Thursday, December 06, 2001 6:22 AM
Subject: Re: [R] Questions about piecewise spline fitting


> Thanks a lot for your advices.
>
> My real problem is that the knot positions are not predetermined,  so I
have
> to deal with this part by myself, :(.
>
> ----- Original Message -----
> From: "MUGGEO VITO" <vito.muggeo at giustizia.it>
> To: "Gang Liang" <gumpleon at hotmail.com>; <r-help at hypatia.math.ethz.ch>
> Sent: Wednesday, December 05, 2001 1:39 AM
> Subject: Re: [R] Questions about piecewise spline fitting
>
>
> > Hi,
> > What you need is just the bs() or ns() functions in the library splines
in
> > the R-software. You have to specify the knots and can specify the
degree.
> > For instance:
> >
> > library(splines)
> > bs(1:20, knots=c(5,11), degree=1) #performs three #straight lines with
> > break-point at x=5 and 11 for the variable 1:20
> > lm(y~bs(1:20, knots=c(5,11), degree=1)) #piecewise linear regression
> >
> > Common "problem" is that the beta parameters for the pseudo-variables
> > inducted by bs() are not interpretable (i.e. in linear case they don't
> > represents the slopes in each piece).
> > best,
> > vito
> >
> >
> > ----- Original Message -----
> > From: "Gang Liang" <gumpleon at hotmail.com>
> > To: <r-help at hypatia.math.ethz.ch>
> > Sent: Wednesday, December 05, 2001 7:05 AM
> > Subject: [R] Questions about piecewise spline fitting
> >
> >
> > > Hi All,
> > >
> > > I want to fit a piecewise spline of degree 1, i.e. a spline consisting
> of
> > a
> > > straight line over each piece. I downloaded the R package pspline,
then
> I
> > > have following questions:
> > >
> > > 1. in the program, the degree of the spline is specified by
2*norder-1.
> > Why
> > > do they adopt such scheme that we can only fit a spline with odd
degree?
> > >
> > > 2. norder cannot be set to 1. Is there any specific reason for doing
so?
> > >
> > > Maybe I need to code this by myself. So I'd like to hear your advices.
> > >
> > > Thanks in advance,
> > > Gang
> > >
> > >
> > > _________________________________________________________________
> > >
> > >
> >
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> > -.-.-
> > > r-help mailing list -- Read
> > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > > Send "info", "help", or "[un]subscribe"
> > > (in the "body", not the subject !)  To:
r-help-request at stat.math.ethz.ch
> > >
> >
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> > _._
> >
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Thu Dec  6 16:09:33 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Thu, 6 Dec 2001 10:09:33 -0500 (EST)
Subject: [R] Questions about piecewise spline fitting
Message-ID: <200112061509.fB6F9Xq26837@cattell.psych.upenn.edu>

Another approach to this problem - probably not as good as those
already proposed - is to use nls, for example,

nls(st1~pmin(A,A+B-C*wc),start=list(A=.5,B=1.5,C=.0020))

This was something I did for a data set with a flat initial
segment followed by a rougly linear decline.  The dependent
measure was st1 and the predictor was wc.  It was hard to find
the right starting list, though.  An advantage of this is that
it finds the knot by itself.

Jon Baron


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Thu Dec  6 16:15:12 2001
From: brahm at alum.mit.edu (David Brahm)
Date: Thu, 6 Dec 2001 10:15:12 -0500
Subject: [R] write.table very slow
In-Reply-To: <79323303@toto.iv>
Message-ID: <15375.35712.11530.433604@gargle.gargle.HOWL>

Cole Harris <coleh at quasarintl.com> writes:
> When writing tables with a large number of columns, write.table() seems to
> take way too much time...

I tackled this problem once in S-Plus, but I have not tested the following code
thoroughly in R.  Please give it a try and let me know if it helps!  It mimics
the behavior of:
      write.table(tbl, file, quote=F, sep="\t", row.names=T)
but writes the output in "blocks", where the block size (in rows) is set by
parameter "bsize".  Try bsize=1 to write one row at a time, and set verbose=T
to watch its progress.


g.output <- function(tbl, file="", append=F, hdr=T, sep="\t",
                     digits=NULL, verbose=F, bsize=7e4/length(tbl)) {
  if (is.numeric(digits))
    digits <- structure(as.list(rep(digits, , length(tbl))), names=names(tbl))
  for (i in names(digits)) if (is.numeric(tbl[[i]]))
    tbl[[i]] <- as.character(round(tbl[[i]], digits[[i]]))
  if (!append) unlink(file)
  if (hdr && (!append || !file.exists(file)))                     # Header line
    cat(paste(names(tbl), collapse=sep), sep="\n", file=file)

  if (!(nt <- length(tbl[[1]]))) return(invisible())
  ix <- c(seq(1, nt, by=round(bsize)), nt+1)
  cfun <- function(tbl, i1, i2, nt, file, sep, verbose) {
    if (verbose) cat("From", i1, "to", i2, date(), "\n")
    if (i1 != 1 || i2 != nt) tbl <- g.subset(tbl, i1:i2)    # g.subset is below
    y <- do.call("paste", c(tbl, list(sep=sep)))
    cat(y, sep="\n", file=file, append=(file != ""))
  }
  for (i in seq(ix)[-1]) cfun(tbl, ix[i-1], ix[i]-1, nt, file, sep, verbose)
}

g.subset <- function(x, q=T, reverse=F) {
  y <- list()
  test <- is.na(seq(along=x[[1]])[q])  # give "" for NA subsets of char vectors
  f <- function(z) if (is.character(z)) ifelse(test,"",z[q]) else z[q]
  for (j in seq(x)) y[[j]] <- if (reverse) rev(f(x[[j]])) else f(x[[j]])
  names(y) <- names(x)
  if (is.data.frame(x)) data.frame(y) else y
}

-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Thu Dec  6 16:23:40 2001
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Thu, 06 Dec 2001 16:23:40 +0100
Subject: [R] reading file names for R batch process 
Message-ID: <3C0F8D7C.458AE83F@psy.uni-muenchen.de>

Hi all,

I've written a function that takes several filenames as arguments, does
some calculations and write new files. Now I want to write a shell
script (under Linux) that determines the files for the R process and
starts R with the filenames as arguments. But how can I commit the
filenames to the R process?

Thanks, Sven
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ajsmit at botzoo.uct.ac.za  Thu Dec  6 16:22:16 2001
From: ajsmit at botzoo.uct.ac.za (Smit, A, Albertus, Dr)
Date: Thu, 6 Dec 2001 17:22:16 +0200
Subject: [R] Histograms per coding variable - labelling the plots
In-Reply-To: <B833D2C4.54B1%pflugshaupt@geobot.umnw.ethz.ch>
References: <E16BaY1-0000cm-00@mail2.uct.ac.za>
Message-ID: <E16C0Lx-0003fO-00@mail3.uct.ac.za>

Dear all

Thank you to all who replied to the question regarding plotting 
histograms for a series of coding variables.  The tapply() function 
seems to work well, and so does the lattice package.

Kaspar Pflugshaupt also pointed out the following: 

> With some tricks, you can even have a title with the respective label over
> each plot... but I forgot how I did this.

Does anyone know how to do this?

Thank you again,
Albertus
Dr Albertus J. Smit
Department of Botany
University of Cape Town
PO Box Rondebosch
7700
SOUTH AFRICA
Tel. 689 3032
Fax. 650 4041

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tklistaddr at keittlab.bio.sunysb.edu  Thu Dec  6 16:20:32 2001
From: tklistaddr at keittlab.bio.sunysb.edu (Timothy H. Keitt)
Date: Thu, 06 Dec 2001 10:20:32 -0500
Subject: [R] trouble with R CMD INSTALL for building my own library
References: <FC0B9DA2600ED4118F76009027AA5DDD02B27B30@ALEX2>
Message-ID: <3C0F8CC0.50304@keittlab.bio.sunysb.edu>

Yup. that was it. I looked at the INSTALL code and it checks for a 'man' 
directory to determine whether or not its a binary package. Perhaps the 
make process could put a '.binary' file in the package root and the 
INSTALL code could check for that instead?

Tim

jonathan_li at agilent.com wrote:

>Hi all,
>
>Problem solved!
>
>Thanks to a suggestion by Robert Gentleman, I realized that there may be
>something that makes R think that mylib is a binary rather than source
>package. I downloaded Brian Ripley's tree source package and basically
>copied each directory. As it turns out, I have not put in a mylib/man
>subdirectory (I thought I could add it any time later.) and R was then
>tricked to believe that mylib is a binary! Once I add an empty mylib/man
>subdirectory, things become normal with compiling etc. Timothy, I think that
>your problem is likely to be the same source then. 
>
>Regards,
>Jonathan
>
>
>-----Original Message-----
>From: Kurt Hornik [mailto:Kurt.Hornik at ci.tuwien.ac.at]
>Sent: Tuesday, December 04, 2001 11:22 PM
>To: Jonathan Li
>Cc: r-help at stat.math.ethz.ch
>Subject: Re: [R] trouble with R CMD INSTALL for building my own library
>
>
>>>>>>Jonathan Li writes:
>>>>>>
>
>>Hi,
>>
>
>>I have built a library that consists of a piece of C code and some R
>>functions.  To build it into a library that I can load using library()
>>command, I have followed "Writing R Extensions" and made
>>sub-directories such as mylib/R and mylib/src.
>>
>
>It actually is 'package' and not 'library'.
>
>>But when I run R CMD INSTALL mylib, nothing seems to be happening with
>>src directory, i.e., no C compiling. I have probably missed some key
>>steps. But after reading very carefully "Writing R Extension", I
>>conclude that I don't need to write my own Makefile in src since R CMD
>>INSTALL will use the default in /usr/lib/R/etc/Makeconf Here is a copy
>>of Makeconf file. In addition, R CMD check and R CMD build all ran
>>without running "make". Is this the way it is supposed to be?  (no
>>error messages encountered).
>>
>
>Sounds strange.  You really have
>
>	mylib/src/foo.c
>
>(note the extension!) and nothing happens?
>
>-k
>

-- 
Timothy H. Keitt
Department of Ecology and Evolution
State University of New York at Stony Brook
Stony Brook, New York 11794 USA
Phone: 631-632-1101, FAX: 631-632-7626
http://life.bio.sunysb.edu/ee/keitt/



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hlai at whsun1.wh.whoi.edu  Thu Dec  6 19:31:37 2001
From: hlai at whsun1.wh.whoi.edu (Han Lai)
Date: Thu, 06 Dec 2001 10:31:37 -0800
Subject: [R] Non-linear random variables
References: <A3D56E56D0CED311A23300A0C9FC21FACBB40C@SFCCRMNT001>
Message-ID: <3C0FB989.EF90C892@whsun1.wh.whoi.edu>

Hi, Norm

Although I have not done it for Ricker's SR curves, I did logistic curves (for
selectivity) and von Bertalanffy growth curves.  You can find the examples in the
book

Pinherio, J.C., and Bates, D.M.  2000.  Mixed-effects models in S and S-Plus.
Springer, N.Y.

The sec. 8.2, p.354 (actually p.356), there is an example on growth of orange trees
I believe that you can modify the program there.  I use the similar approach for my
work.  It works sometimes but not always.  Convergence is a major problem because
our fisheries data are often very noise.  Be careful to check you have enough
degrees of freedom to fit the model.  Let me know if you have other questions.

Good Luck!

Cheers!
Han-Lin Lai, Ph.D
Northeast Fisheries Science Center
Woods Hole, MA 02543
Han-Lin.Lai at noaa.gov
508-495-2312


"Good, Norman" wrote:

> I have a fisheries Ricker stock-recruitment non-linear model which I am
> trying to code up in R (after failing in MATLAB). There are two fixed
> parameters and a random environmental effect that is linked to a first order
> lagged correlation fixed parameter.
>
> Are there any examples of fitting this model I could follow?
>
> Cheers
>
> Norm Good
>
> Fisheries Biologist (Mathematician)
> Southern Fisheries Centre
> PO Box 76, Deception Bay Q 4508
> telephone 3817 9588, fascimile 3817 9555
>
> ********************************DISCLAIMER****************************
> The information contained in the above e-mail message or messages
> (which includes any attachments) is confidential and may be legally
> privileged.  It is intended only for the use of the person or entity
> to which it is addressed.  If you are not the addressee any form of
> disclosure, copying, modification, distribution or any action taken
> or omitted in reliance on the information is unauthorised.  Opinions
> contained in the message(s) do not necessarily reflect the opinions
> of the Queensland Government and its authorities.  If you received
> this communication in error, please notify the sender immediately and
> delete it from your computer system network.
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec  6 16:37:32 2001
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 6 Dec 2001 15:37:32 +0000 (GMT)
Subject: [R] reading file names for R batch process 
In-Reply-To: <3C0F8D7C.458AE83F@psy.uni-muenchen.de>
Message-ID: <Pine.GSO.4.31.0112061537010.29584-100000@auk.stats>

On Thu, 6 Dec 2001, Sven Garbade wrote:

> Hi all,
>
> I've written a function that takes several filenames as arguments, does
> some calculations and write new files. Now I want to write a shell
> script (under Linux) that determines the files for the R process and
> starts R with the filenames as arguments. But how can I commit the
> filenames to the R process?

via enviroment variables, most easily.

Read by Sys.getenv.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Thu Dec  6 17:12:49 2001
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Thu, 06 Dec 2001 17:12:49 +0100
Subject: [R] reading file names for R batch process
References: <Pine.GSO.4.31.0112061537010.29584-100000@auk.stats>
Message-ID: <3C0F9901.EEC08EFF@psy.uni-muenchen.de>

Prof Brian D Ripley wrote:
> 
> On Thu, 6 Dec 2001, Sven Garbade wrote:
> 
> > Hi all,
> >
> > I've written a function that takes several filenames as arguments, does
> > some calculations and write new files. Now I want to write a shell
> > script (under Linux) that determines the files for the R process and
> > starts R with the filenames as arguments. But how can I commit the
> > filenames to the R process?
> 
> via enviroment variables, most easily.
> 
> Read by Sys.getenv.

Ah, this is very easy and works! Thanks, Sven
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From GPetris at uark.edu  Thu Dec  6 17:11:25 2001
From: GPetris at uark.edu (Giovanni Petris)
Date: Thu, 6 Dec 2001 10:11:25 -0600 (CST)
Subject: [R] Building R on Solaris with SUNperf
In-Reply-To: <Pine.LNX.4.31.0112060752520.1743-100000@gannet.stats> (message
	from Prof Brian Ripley on Thu, 6 Dec 2001 07:55:58 +0000 (GMT))
References: <Pine.LNX.4.31.0112060752520.1743-100000@gannet.stats>
Message-ID: <200112061611.KAA18604@definetti.uark.edu>


Thank you, Professor Ripley. 

I had to add the option --with-blas=libsunperf to the configure
script. Re-reading R-admin.html in the morning helped, too...

Best,
Giovanni 


-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (501) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]

> X-Authentication-Warning: gannet.stats: ripley owned process doing -bs
> Date: Thu, 6 Dec 2001 07:55:58 +0000 (GMT)
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> X-X-Sender: <ripley at gannet.stats>
> cc: <r-help at stat.math.ethz.ch>
> Content-Type: TEXT/PLAIN; charset=US-ASCII
> Content-Length: 2409
> 
> The short answer is read the R-admin.html manual.  You need to use f95 to
> get the right libraries, and then the configure script automatically uses
> sunperf.  It won't work with f77 (or g77).
> 
> Also, R will not make use of all external LAPACK, because it needs a
> bug-fixed LAPACK 3, and there is no way to guarantee that.
> 
> On Wed, 5 Dec 2001, Giovanni Petris wrote:
> 
> >
> > Dear All,
> >
> > I am building R-1.3.1 on Solaris 2.7 and I am trying to use the native
> > SUNperf BLAS/LAPACK. I have added the flags ("-dalign
> > -xlic_lib=sunperf") for the compilers in the config.site file.
> > What is not clear to me is what I have to do with the "--with-blas"
> > flag for ./configure. It seems to me that omitting it is not enough.
> > Any suggestions?
> >
> > Another question, I guess about how to organize directories and get
> > rid of obsolete versions of R, is the following. A directory listing
> > of /export/home/share/R on my machine gives:
> >
> > Wed<18:17>R[85]#ls /export/home/share/R
> > library/      R-1.2.0/      R-1.2.2/      R-1.3.1/      R-1.3.1.tgz
> >
> > I keep in "library/" all the packages, and I build each version of R in
> > the directory with the same name. My question is: can I safely nuke
> > R-1.2.0/ and R-1.2.2/ once I have a working R-1.3.1?
> >
> > Thank you in advance.
> > Best,
> > Giovanni
> >
> > --
> >
> >  __________________________________________________
> > [                                                  ]
> > [ Giovanni Petris                 GPetris at uark.edu ]
> > [ Department of Mathematical Sciences              ]
> > [ University of Arkansas - Fayetteville, AR 72701  ]
> > [ Ph: (501) 575-6324, 575-8630 (fax)               ]
> > [ http://definetti.uark.edu/~gpetris/              ]
> > [__________________________________________________]
> >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Dec  6 17:34:01 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 6 Dec 2001 08:34:01 -0800 (PST)
Subject: [R] [bug] Follow up: paste doesn't...
In-Reply-To: <20011206134823.E343F62E1D@clavin.bestweb.net>
Message-ID: <Pine.A41.4.33.0112060829130.47158-100000@homer31.u.washington.edu>

On Thu, 6 Dec 2001, Michaell Taylor wrote:

>
> Bingo.  The object did come from a stata dataset originally, though it was
> transformed a few ways since being read in.
>
> Saving it as an R object and reloading fixed the problem.  There must be a
> glitch in the foreign library.
>

There was. There isn't any more (well, there isn't *that* particular
glitch).  In principle an internal routine could use either Rf_length() or
strlen() to work out the length of a string. read.dta was giving strings
where Rf_length was the field width and strlen was the actual string
length, so things got confused.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Dec  6 17:37:21 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 6 Dec 2001 08:37:21 -0800 (PST)
Subject: [R] reading file names for R batch process
In-Reply-To: <3C0F9901.EEC08EFF@psy.uni-muenchen.de>
Message-ID: <Pine.A41.4.33.0112060836480.47158-100000@homer31.u.washington.edu>

On Thu, 6 Dec 2001, Sven Garbade wrote:

> Prof Brian D Ripley wrote:
> >
> > On Thu, 6 Dec 2001, Sven Garbade wrote:
> >
> > > Hi all,
> > >
> > > I've written a function that takes several filenames as arguments, does
> > > some calculations and write new files. Now I want to write a shell
> > > script (under Linux) that determines the files for the R process and
> > > starts R with the filenames as arguments. But how can I commit the
> > > filenames to the R process?
> >
> > via enviroment variables, most easily.
> >
> > Read by Sys.getenv.
>
> Ah, this is very easy and works! Thanks, Sven

I believe you could also use the commandArgs() function.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Thu Dec  6 17:53:46 2001
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Thu, 06 Dec 2001 17:53:46 +0100
Subject: [R] reading file names for R batch process
References: <Pine.A41.4.33.0112060836480.47158-100000@homer31.u.washington.edu>
Message-ID: <3C0FA29A.926BA3DB@psy.uni-muenchen.de>

Thomas Lumley wrote:
> 
> On Thu, 6 Dec 2001, Sven Garbade wrote:
> 
> > Prof Brian D Ripley wrote:
> > >
> > > On Thu, 6 Dec 2001, Sven Garbade wrote:
> > >
> > > > Hi all,
> > > >
> > > > I've written a function that takes several filenames as arguments, does
> > > > some calculations and write new files. Now I want to write a shell
> > > > script (under Linux) that determines the files for the R process and
> > > > starts R with the filenames as arguments. But how can I commit the
> > > > filenames to the R process?
> > >
> > > via enviroment variables, most easily.
> > >
> > > Read by Sys.getenv.
> >
> > Ah, this is very easy and works! Thanks, Sven
> 
> I believe you could also use the commandArgs() function.

I've tried this before I wrote to the list. It didn't work for me, but
maybe I've missed something: R CMD BATCH *.data myfunc.R, but
commandArgs() listed only the R command line switches.

By, Sven
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Thu Dec  6 18:01:07 2001
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Thu, 6 Dec 2001 12:01:07 -0500 (EST)
Subject: [R] Histograms per coding variable - labelling the plots
In-Reply-To: <E16C0Lx-0003fO-00@mail3.uct.ac.za>
Message-ID: <Pine.LNX.4.30.0112061158340.18586-100000@bolker.zoo.ufl.edu>


  The best I can do is a bit of a hack, really a for loop in disguise:

f <- factor(rep(LETTERS[1:10],rep(10,10)))
tmp <- split(a,f)

par(mfrow=c(3,4))
sapply(1:length(tmp),function(i)hist(tmp[[i]],main=names(tmp)[i]))

  If anyone has a better idea ...
  I've often wished for a "MapThread" (cf. Mathematica) or "zip" function
or something similar that would apply a two- (or more-) parameter function
to parallel lists/vectors.  One could write one's own in R code, but I
don't know that there would be any real advantage beyond elegance.



On Thu, 6 Dec 2001, Smit, A, Albertus, Dr wrote:

> Dear all
>
> Thank you to all who replied to the question regarding plotting
> histograms for a series of coding variables.  The tapply() function
> seems to work well, and so does the lattice package.
>
> Kaspar Pflugshaupt also pointed out the following:
>
> > With some tricks, you can even have a title with the respective label over
> > each plot... but I forgot how I did this.
>
> Does anyone know how to do this?
>
> Thank you again,
> Albertus
> Dr Albertus J. Smit
> Department of Botany
> University of Cape Town
> PO Box Rondebosch
> 7700
> SOUTH AFRICA
> Tel. 689 3032
> Fax. 650 4041
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From duncan at research.bell-labs.com  Thu Dec  6 18:04:16 2001
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Thu, 6 Dec 2001 12:04:16 -0500
Subject: [R] reading file names for R batch process
In-Reply-To: <Pine.A41.4.33.0112060836480.47158-100000@homer31.u.washington.edu>; from tlumley@u.washington.edu on Thu, Dec 06, 2001 at 08:37:21AM -0800
References: <3C0F9901.EEC08EFF@psy.uni-muenchen.de> <Pine.A41.4.33.0112060836480.47158-100000@homer31.u.washington.edu>
Message-ID: <20011206120416.L21871@jessie.research.bell-labs.com>

Thomas Lumley wrote:
> On Thu, 6 Dec 2001, Sven Garbade wrote:
> 
> > Prof Brian D Ripley wrote:
> > >
> > > On Thu, 6 Dec 2001, Sven Garbade wrote:
> > >
> > > > Hi all,
> > > >
> > > > I've written a function that takes several filenames as arguments, does
> > > > some calculations and write new files. Now I want to write a shell
> > > > script (under Linux) that determines the files for the R process and
> > > > starts R with the filenames as arguments. But how can I commit the
> > > > filenames to the R process?
> > >
> > > via enviroment variables, most easily.
> > >
> > > Read by Sys.getenv.
> >
> > Ah, this is very easy and works! Thanks, Sven
> 
> I believe you could also use the commandArgs() function.
> 
> 	-thomas


Using commandArgs() would, in theory, be both a better and simpler
mechanism. It doesn't require you to come up with names for the
environment variables and agree on those in both the shell script and
the R code.  Additionally, the values will not be passed on to any
applications run from within the R session and so avoid any potential
conflicts between the use of environment variables by different
applications.

For your application, since file names are typically single words,
this should work.

  echo 'print(commandArgs())' | R --save file1 file2

However, the way the R script is set up at present, the commandArgs()
doesn't work in general, at least with the obvious usage. For example,

  echo 'print(commandArgs())' | R --save 'my first argument' argument2
 
produces 
ARGUMENT 'my' __ignored__
ARGUMENT 'first' __ignored__
ARGUMENT 'argument' __ignored__
ARGUMENT 'argument2' __ignored__
[1] "/home3/duncan/R/R-cvs/bin/R.bin" "--slave"
[3] "my"                              "first"
[5] "argument"                        "argument2"

So we get warning messages from the R executable (not script) and also
it breaks the single argument 'my first argument' into 3 distinct arguments.

In the future, this might be fixed by a) using a -- separator for
arguments that leaves anything past that uninterpreted by R.
and b) preserving the quotes around arguments.

So a command like
  echo 'print(commandArgs())' | R --save -- 'my first argument' argument2
would print 
[1] "/home3/duncan/R/R-cvs/bin/R.bin" "--slave"
[3] "my first argument"               "argument2"


But that will have to wait.

 D.


-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From john.marsland at CommerzbankIB.com  Thu Dec  6 18:23:51 2001
From: john.marsland at CommerzbankIB.com (Marsland, John)
Date: Thu, 6 Dec 2001 17:23:51 -0000 
Subject: [R] BATCH mode executes much slow than an interactive session
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF18678A@xmx8lonib.lonib.commerzbank.com>

We are running R 1.3.0 for Unix on Solaris 8 and when we run a batch job is
takes about 6 times longer to excute than an interactive session -- in the
case of this program around 10 minutes.... anybody any ideas why? Is there
an implicit low priority on batch jobs?

Regards, 

John Marsland 




********************************************************************** 
This communication is confidential and is intended only for 
the person to whom it is addressed.  If you are not that person you
are not permitted to make use of the information and you are requested 
to notify <mailto:LONIB.Postmaster at commerzbankib.com> immediately that 
you have received it and then destroy the copy in your possession.
Commerzbank AG is regulated by the FSA for the conduct of investment
business in the UK.
**********************************************************************

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Coleh at quasarintl.com  Thu Dec  6 18:49:29 2001
From: Coleh at quasarintl.com (Cole Harris)
Date: Thu, 06 Dec 2001 10:49:29 -0700
Subject: [R] write.table very slow
Message-ID: <sc0f4d47.059@quasarintl.com>

Thanks to the responders,

I found that cat is suitable for my purposes - the following function is ~100x
faster than write.table for my particular problem - writing gene expression csv files.

makecsv<-function(nms,cls,incl,dat,file=""){

	nrow<-length(cls)
	for(i in 1:nrow){
		cat(nms[i],cls[i],incl[i],dat[i,],sep=", ",append=TRUE,file=file)
		write("",file=file,append=TRUE)
		print(i)}
	}

Cole

>>> David Brahm  <brahm at alum.mit.edu> 12/06/01 08:15AM >>>
Cole Harris <coleh at quasarintl.com> writes:
> When writing tables with a large number of columns, write.table() seems to
> take way too much time...

I tackled this problem once in S-Plus, but I have not tested the following code
thoroughly in R.  Please give it a try and let me know if it helps!  It mimics
the behavior of:
      write.table(tbl, file, quote=F, sep="\t", row.names=T)
but writes the output in "blocks", where the block size (in rows) is set by
parameter "bsize".  Try bsize=1 to write one row at a time, and set verbose=T
to watch its progress.


g.output <- function(tbl, file="", append=F, hdr=T, sep="\t",
                     digits=NULL, verbose=F, bsize=7e4/length(tbl)) {
  if (is.numeric(digits))
    digits <- structure(as.list(rep(digits, , length(tbl))), names=names(tbl))
  for (i in names(digits)) if (is.numeric(tbl[[i]]))
    tbl[[i]] <- as.character(round(tbl[[i]], digits[[i]]))
  if (!append) unlink(file)
  if (hdr && (!append || !file.exists(file)))                     # Header line
    cat(paste(names(tbl), collapse=sep), sep="\n", file=file)

  if (!(nt <- length(tbl[[1]]))) return(invisible())
  ix <- c(seq(1, nt, by=round(bsize)), nt+1)
  cfun <- function(tbl, i1, i2, nt, file, sep, verbose) {
    if (verbose) cat("From", i1, "to", i2, date(), "\n")
    if (i1 != 1 || i2 != nt) tbl <- g.subset(tbl, i1:i2)    # g.subset is below
    y <- do.call("paste", c(tbl, list(sep=sep)))
    cat(y, sep="\n", file=file, append=(file != ""))
  }
  for (i in seq(ix)[-1]) cfun(tbl, ix[i-1], ix[i]-1, nt, file, sep, verbose)
}

g.subset <- function(x, q=T, reverse=F) {
  y <- list()
  test <- is.na(seq(along=x[[1]])[q])  # give "" for NA subsets of char vectors
  f <- function(z) if (is.character(z)) ifelse(test,"",z[q]) else z[q]
  for (j in seq(x)) y[[j]] <- if (reverse) rev(f(x[[j]])) else f(x[[j]])
  names(y) <- names(x)
  if (is.data.frame(x)) data.frame(y) else y
}

-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html 
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mmiller3 at iupui.edu  Thu Dec  6 20:23:27 2001
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: 06 Dec 2001 14:23:27 -0500
Subject: [R] Histograms per coding variable - labelling the plots
In-Reply-To: <E16C0Lx-0003fO-00@mail3.uct.ac.za>
References: <E16BaY1-0000cm-00@mail2.uct.ac.za>
	<E16C0Lx-0003fO-00@mail3.uct.ac.za>
Message-ID: <87itbkdufk.fsf@lumen.med.iupui.edu>

>>>>> "Smit," == Smit, A, Albertus, Dr <ajsmit at botzoo.uct.ac.za> writes:

    >>>>> Kaspar Pflugshaupt also pointed out the following: 

    >> With some tricks, you can even have a title with the
    >> respective label over each plot... but I forgot how I did
    >> this.

    > Does anyone know how to do this?

If your data looks, for example, like this

score activity
low   22.2
low   97.8
low   29.1
...
med   19.0
med   19.8
med   9.1
med   30.1
med   15.5
med   10.3
med   11.0
...
high  10.2
high  11.3
high  11.4
high  5.3
high  14.5

you could do something like this:

par( mfrow=c(2,2) )
for ( level in levels(score) ) {
  hist( activity, main=paste('score : ', level ))
}

If you use lattice, you can produce slightly different labels by
using strip.default, as in:

library(lattice)
histogram( ~ activity | score, data=nk, 
  strip = function(...) strip.default(style=2,...) 
)

or

histogram( ~ activity | score, data=nk, 
  strip = function(...) strip.default(style=1,strip.names=T,...) 
)

Mike
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hodgess at uhddx01.dt.uh.edu  Thu Dec  6 21:16:02 2001
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Thu, 6 Dec 2001 14:16:02 -0600 (CST)
Subject: [R] R and Feller
Message-ID: <200112062016.OAA25339@uhddx01.dt.uh.edu>

Dear R People:

In Feller's article, "The Asymptotic Distribution of 
the Range of Sums of Independent Random Variables", he
demonstrates how the range and normalized range of the 
sum of n independent variables can be derived via Brownian motion.

ok. fine.

He has a section in which he uses a Bernoulli random variable
with options of -1 and 1 to get exact values and then demonstrates his
Brown motion approx.  He then shows the expected value and
variance.  

I was using R to duplicate the exact process.  When I get my values,
they are somewhat different than Feller's.  For n=6, I'm ok,
but for values larger than 6, my function is off slightly:

Example
Feller	Me
4.1523	4.1679
2.0872  2.0850

Is this just due to rounding, or (probably) a mistake in my
function?

Thanks in advance for your help!
Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
1 Main Street 
Houston, TX 77002
mailto: hodgess at uhddx01.dt.uh.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kademan at phz.com  Thu Dec  6 22:04:55 2001
From: kademan at phz.com (Ed Kademan)
Date: 06 Dec 2001 16:04:55 -0500
Subject: [R] Scheme in R
Message-ID: <ulgn10wnjpk.fsf@phz.com>

The initial authors of R said?, "...we implemented the language by
first writing an interpreter for a Scheme subset and then
progressively mutating it to resemble S."  Further on in that article
they elaborated that their strategy was to create a parser that would
take expressions in S-like syntax and translate them to Scheme
S-expressions.

Does R still work that way?  Can R be made to accept Scheme syntax
directly?  Can you build it in such a way that when you start it up
you get a Scheme read-eval-print-loop instead of the S-like
interactive environment?  I ask simply because I happen to like
Scheme/Lisp syntax.  But it also occurred to me that---considering the
ease with which you can implement specialized little languages in
Scheme---such an interface might make it easier to experiment with
things like extensions to model and graphics formulae.

-----------------------------------------------------------------
1. @article{ig,
     author  = "Ihaka, Ross and Gentleman, Robert",
     title   = "R: A Language for Data Analysis and Graphics",
     journal = "Journal of Computational and Graphical Statistics",
     year    = 1996,
     volume  = 5,
     number  = 3,
     page    = 299,
     month   = sep}

-- 
Ed Kademan              508.651.3700
PHZ Capital Partners    508.653.1745 (fax)
321 Commonwealth Road   <kademan at phz.com>
Wayland, MA 01778
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thoar at cgd.ucar.edu  Thu Dec  6 22:43:36 2001
From: thoar at cgd.ucar.edu (Tim Hoar)
Date: Thu, 6 Dec 2001 14:43:36 -0700 (MST)
Subject: [R] Solaris install problem ... mcount
Message-ID: <Pine.GSO.4.30.0112061438200.22825-100000@sunray2>

Hmnnn...

This is the third version of R I have installed and I am stumped on this one.

There is some unresolved external I cannot find...


/opt/SUNWspro/bin/cc -v   -o R.bin  CConverters.o Rdynload.o RNG.o apply.o
arithmetic.o array.o attrib.o bind.o builtin.o character.o coerce.o colors.o
complex.o connections.o context.o cov.o cum.o dcf.o datetime.o debug.o devPS.o
devPicTeX.o deparse.o deriv.o devices.o dotcode.o dstruct.o duplicate.o
envir.o errors.o eval.o format.o fourier.o gram.o gram-ex.o graphics.o
internet.o iosupport.o lapack.o list.o logic.o main.o match.o memory.o model.o
names.o objects.o optim.o optimize.o options.o par.o paste.o platform.o plot.o
plot3d.o plotmath.o print.o printarray.o printvector.o printutils.o random.o
regex.o relop.o saveload.o scan.o seq.o size.o sort.o source.o split.o
subassign.o subscript.o subset.o summary.o unique.o util.o version.o vfonts.o
xxxpr.o ../unix/libunix.a ../appl/libappl.a ../nmath/libnmath.a
-xlic_lib=sunperf -lsunmath -R/opt/SUNWspro/lib  -L/opt/SUNWspro/lib
-L/opt/SUNWspro/WS6U1/lib -L/usr/ccs/lib -L/usr/lib -lfui -lfai -lfai2
-lfsumai -lfprodai -lfminlai -lfmaxlai -lfminvai -lfmaxvai -lfsu -lsunmath -lm
-lz -lnsl -lsocket -lreadline -ldl -ltermcap -lm -xlic_lib=sunperf
Undefined                       first referenced
 symbol                             in file
_mcount                             CConverters.o
ld: fatal: Symbol referencing errors. No output written to R.bin
gmake[3]: *** [R.bin] Error 1
gmake[3]: Leaving directory `/contrib/R-1.3.1/src/main'
gmake[2]: *** [R] Error 2
gmake[2]: Leaving directory `/contrib/R-1.3.1/src/main'
gmake[1]: *** [R] Error 1
gmake[1]: Leaving directory `/contrib/R-1.3.1/src'
gmake: *** [R] Error 1

I cannot find the object requiring "mcount", so I am having a hard time
trying to figure out where mcount might be hiding.

2[214]0 nightingale:/contrib/R-1.3.1 > cd src/main
0[215]0 nightingale:/<1>R-1.3.1/src/main > grep -i mcount *
list.c:static int       ItemCounts;
list.c: if(ItemCounts < MaxCount) {
list.c:             for(j = 0 ; j < ItemCounts ; j++) {
list.c:         SET_STRING_ELT(ans, ItemCounts, name);
list.c:     ItemCounts += 1;
list.c:    ItemCounts = 0;
list.c:    savecount = ItemCounts;
list.c:    ans = allocVector(STRSXP, ItemCounts);
list.c:    ItemCounts = 0;
list.c:    if(ItemCounts != savecount) {
list.c: ans = allocVector(STRSXP, ItemCounts);
list.c: for(i = 0 ; i < ItemCounts ; i++)
0[216]0 nightingale:/<1>R-1.3.1/src/main >

Any help?

Thanks -- Tim

## Tim Hoar, Associate Scientist              email: thoar at ucar.edu     ##
## Geophysical Statistics Project             phone: 303-497-1708       ##
## National Center for Atmospheric Research   FAX  : 303-497-1333       ##
## Boulder, CO  80307                    http://www.cgd.ucar.edu/~thoar ##

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec  6 23:17:31 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Dec 2001 22:17:31 +0000 (GMT)
Subject: [R] Solaris install problem ... mcount
In-Reply-To: <Pine.GSO.4.30.0112061438200.22825-100000@sunray2>
Message-ID: <Pine.LNX.4.31.0112062213180.14602-100000@gannet.stats>

On Thu, 6 Dec 2001, Tim Hoar wrote:

> Hmnnn...
>
> This is the third version of R I have installed and I am stumped on this one.
>
> There is some unresolved external I cannot find...

Compiler version and flags?  I don't have this in CConverters.o on Solaris
2.7 with

markov% cc -V
cc: Sun WorkShop 6 update 1 C 5.2 2000/09/11

  -xO5 -xlibmil -dalign -g -xarch=v8plusa

and suspect it's related to coverage or profiling.

>
>
> /opt/SUNWspro/bin/cc -v   -o R.bin  CConverters.o Rdynload.o RNG.o apply.o
> arithmetic.o array.o attrib.o bind.o builtin.o character.o coerce.o colors.o
> complex.o connections.o context.o cov.o cum.o dcf.o datetime.o debug.o devPS.o
> devPicTeX.o deparse.o deriv.o devices.o dotcode.o dstruct.o duplicate.o
> envir.o errors.o eval.o format.o fourier.o gram.o gram-ex.o graphics.o
> internet.o iosupport.o lapack.o list.o logic.o main.o match.o memory.o model.o
> names.o objects.o optim.o optimize.o options.o par.o paste.o platform.o plot.o
> plot3d.o plotmath.o print.o printarray.o printvector.o printutils.o random.o
> regex.o relop.o saveload.o scan.o seq.o size.o sort.o source.o split.o
> subassign.o subscript.o subset.o summary.o unique.o util.o version.o vfonts.o
> xxxpr.o ../unix/libunix.a ../appl/libappl.a ../nmath/libnmath.a
> -xlic_lib=sunperf -lsunmath -R/opt/SUNWspro/lib  -L/opt/SUNWspro/lib
> -L/opt/SUNWspro/WS6U1/lib -L/usr/ccs/lib -L/usr/lib -lfui -lfai -lfai2
> -lfsumai -lfprodai -lfminlai -lfmaxlai -lfminvai -lfmaxvai -lfsu -lsunmath -lm
> -lz -lnsl -lsocket -lreadline -ldl -ltermcap -lm -xlic_lib=sunperf
> Undefined                       first referenced
>  symbol                             in file
> _mcount                             CConverters.o
> ld: fatal: Symbol referencing errors. No output written to R.bin
> gmake[3]: *** [R.bin] Error 1
> gmake[3]: Leaving directory `/contrib/R-1.3.1/src/main'
> gmake[2]: *** [R] Error 2
> gmake[2]: Leaving directory `/contrib/R-1.3.1/src/main'
> gmake[1]: *** [R] Error 1
> gmake[1]: Leaving directory `/contrib/R-1.3.1/src'
> gmake: *** [R] Error 1
>
> I cannot find the object requiring "mcount", so I am having a hard time
> trying to figure out where mcount might be hiding.
>
> 2[214]0 nightingale:/contrib/R-1.3.1 > cd src/main
> 0[215]0 nightingale:/<1>R-1.3.1/src/main > grep -i mcount *
> list.c:static int       ItemCounts;
> list.c: if(ItemCounts < MaxCount) {
> list.c:             for(j = 0 ; j < ItemCounts ; j++) {
> list.c:         SET_STRING_ELT(ans, ItemCounts, name);
> list.c:     ItemCounts += 1;
> list.c:    ItemCounts = 0;
> list.c:    savecount = ItemCounts;
> list.c:    ans = allocVector(STRSXP, ItemCounts);
> list.c:    ItemCounts = 0;
> list.c:    if(ItemCounts != savecount) {
> list.c: ans = allocVector(STRSXP, ItemCounts);
> list.c: for(i = 0 ; i < ItemCounts ; i++)
> 0[216]0 nightingale:/<1>R-1.3.1/src/main >
>
> Any help?
>
> Thanks -- Tim
>
> ## Tim Hoar, Associate Scientist              email: thoar at ucar.edu     ##
> ## Geophysical Statistics Project             phone: 303-497-1708       ##
> ## National Center for Atmospheric Research   FAX  : 303-497-1333       ##
> ## Boulder, CO  80307                    http://www.cgd.ucar.edu/~thoar ##
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec  6 23:29:19 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 06 Dec 2001 23:29:19 +0100
Subject: [R] Scheme in R
In-Reply-To: <ulgn10wnjpk.fsf@phz.com>
References: <ulgn10wnjpk.fsf@phz.com>
Message-ID: <x27ks0rni8.fsf@blueberry.kubism.ku.dk>

Ed Kademan <kademan at phz.com> writes:

> The initial authors of R said?, "...we implemented the language by
> first writing an interpreter for a Scheme subset and then
> progressively mutating it to resemble S."  Further on in that article
> they elaborated that their strategy was to create a parser that would
> take expressions in S-like syntax and translate them to Scheme
> S-expressions.
> 
> Does R still work that way?  Can R be made to accept Scheme syntax
> directly?  Can you build it in such a way that when you start it up
> you get a Scheme read-eval-print-loop instead of the S-like
> interactive environment?  I ask simply because I happen to like
> Scheme/Lisp syntax.  But it also occurred to me that---considering the
> ease with which you can implement specialized little languages in
> Scheme---such an interface might make it easier to experiment with
> things like extensions to model and graphics formulae.
> 

Well, ... where do I start? The R (and to some extent also S)
internals are still very Lisp/Scheme like. The parser/evaluator hasn't
changed that much since the early versions of R. Perhaps the most
notable change is that a list object is not a dotted-pair list as in
Lisp anymore but a generic vector. (The pairlist object type still
exists, but is hardly ever used.) If you try picking apart an
expression using [[...]] you will see that almost everything maps to a
Lisp-like syntax, e.g.

 quote(x <- 2 + 3)

is essentially (<- x (+ 2 3)). Some slightly peculiar cases involve
for loops and expressions with non-local returns like break, and
return(). The evaluation model is somewhat non-Scheme because of the
lazy evaluation and substitute() aspects.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thoar at cgd.ucar.edu  Thu Dec  6 23:56:28 2001
From: thoar at cgd.ucar.edu (Tim Hoar)
Date: Thu, 6 Dec 2001 15:56:28 -0700 (MST)
Subject: [R] Solaris install problem ... mcount
In-Reply-To: <Pine.LNX.4.31.0112062213180.14602-100000@gannet.stats>
Message-ID: <Pine.GSO.4.30.0112061542580.22825-100000@sunray2>

Turns out you're right (imagine my surprise ;) -- a colleague of mine
also pointed this out. In my config.site I had

MAIN_CFLAGS="-pg -v"   and
MAIN_FFLAGS="-pg -v"   but NOT

MAIN_LDFLAGS="-pg -v"

The MAIN_CFLAGS and MAIN_FFLAGS comment blocks mention using the -pg
flag, but the comment block for MAIN_LDFLAGS does not. It might
be clearer to newbies like me if there was a similar comment in the
MAIN_LDFLAGS block.

Having said that:

I assume all responsibility for tinkering with the config.site file.
I should have known better.

Thanks for the always-prompt reply.

Tim

If I might make a suggestion; it would also be nice to have a comment
in the config.site file about using the png and jpeg libraries as well
as any "high-performance" libraries.


> Date: Thu, 6 Dec 2001 22:17:31 +0000 (GMT)
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> To: Tim Hoar <thoar at ucar.edu>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Solaris install problem ... mcount
>
> On Thu, 6 Dec 2001, Tim Hoar wrote:
>
> > Hmnnn...
> >
> > This is the third version of R I have installed and I am stumped on this one.
> >
> > There is some unresolved external I cannot find...
>
> Compiler version and flags?  I don't have this in CConverters.o on Solaris
> 2.7 with
>
> markov% cc -V
> cc: Sun WorkShop 6 update 1 C 5.2 2000/09/11
>
>   -xO5 -xlibmil -dalign -g -xarch=v8plusa
>
> and suspect it's related to coverage or profiling.
>
> >
> >
> > /opt/SUNWspro/bin/cc -v   -o R.bin  CConverters.o Rdynload.o RNG.o apply.o
> > arithmetic.o array.o attrib.o bind.o builtin.o character.o coerce.o colors.o
> > complex.o connections.o context.o cov.o cum.o dcf.o datetime.o debug.o devPS.o
> > devPicTeX.o deparse.o deriv.o devices.o dotcode.o dstruct.o duplicate.o
> > envir.o errors.o eval.o format.o fourier.o gram.o gram-ex.o graphics.o
> > internet.o iosupport.o lapack.o list.o logic.o main.o match.o memory.o model.o
> > names.o objects.o optim.o optimize.o options.o par.o paste.o platform.o plot.o
> > plot3d.o plotmath.o print.o printarray.o printvector.o printutils.o random.o
> > regex.o relop.o saveload.o scan.o seq.o size.o sort.o source.o split.o
> > subassign.o subscript.o subset.o summary.o unique.o util.o version.o vfonts.o
> > xxxpr.o ../unix/libunix.a ../appl/libappl.a ../nmath/libnmath.a
> > -xlic_lib=sunperf -lsunmath -R/opt/SUNWspro/lib  -L/opt/SUNWspro/lib
> > -L/opt/SUNWspro/WS6U1/lib -L/usr/ccs/lib -L/usr/lib -lfui -lfai -lfai2
> > -lfsumai -lfprodai -lfminlai -lfmaxlai -lfminvai -lfmaxvai -lfsu -lsunmath -lm
> > -lz -lnsl -lsocket -lreadline -ldl -ltermcap -lm -xlic_lib=sunperf
> > Undefined                       first referenced
> >  symbol                             in file
> > _mcount                             CConverters.o
> > ld: fatal: Symbol referencing errors. No output written to R.bin
> > gmake[3]: *** [R.bin] Error 1
> > gmake[3]: Leaving directory `/contrib/R-1.3.1/src/main'
> > gmake[2]: *** [R] Error 2
> > gmake[2]: Leaving directory `/contrib/R-1.3.1/src/main'
> > gmake[1]: *** [R] Error 1
> > gmake[1]: Leaving directory `/contrib/R-1.3.1/src'
> > gmake: *** [R] Error 1
> >
> > I cannot find the object requiring "mcount", so I am having a hard time
> > trying to figure out where mcount might be hiding.
> >
> > 2[214]0 nightingale:/contrib/R-1.3.1 > cd src/main
> > 0[215]0 nightingale:/<1>R-1.3.1/src/main > grep -i mcount *
> > list.c:static int       ItemCounts;
> > list.c: if(ItemCounts < MaxCount) {
> > list.c:             for(j = 0 ; j < ItemCounts ; j++) {
> > list.c:         SET_STRING_ELT(ans, ItemCounts, name);
> > list.c:     ItemCounts += 1;
> > list.c:    ItemCounts = 0;
> > list.c:    savecount = ItemCounts;
> > list.c:    ans = allocVector(STRSXP, ItemCounts);
> > list.c:    ItemCounts = 0;
> > list.c:    if(ItemCounts != savecount) {
> > list.c: ans = allocVector(STRSXP, ItemCounts);
> > list.c: for(i = 0 ; i < ItemCounts ; i++)
> > 0[216]0 nightingale:/<1>R-1.3.1/src/main >
> >
> > Any help?
> >
> > Thanks -- Tim
> >
> > ## Tim Hoar, Associate Scientist              email: thoar at ucar.edu     ##
> > ## Geophysical Statistics Project             phone: 303-497-1708       ##
> > ## National Center for Atmospheric Research   FAX  : 303-497-1333       ##
> > ## Boulder, CO  80307                    http://www.cgd.ucar.edu/~thoar ##
> >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

## Tim Hoar, Associate Scientist              email: thoar at ucar.edu     ##
## Geophysical Statistics Project             phone: 303-497-1708       ##
## National Center for Atmospheric Research   FAX  : 303-497-1333       ##
## Boulder, CO  80307                    http://www.cgd.ucar.edu/~thoar ##

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fabian at mybytes.de  Thu Dec  6 22:12:25 2001
From: fabian at mybytes.de (Fabian Moerchen)
Date: 06 Dec 2001 22:12:25 +0100
Subject: [R] constrained arima0 model
Message-ID: <1007673174.536.0.camel@pilgrimage.fragile>

hi

i want to fit a rather large model (p=12) with arima0.
some of the resulting AR parameters are very small,
in the order of their standard errors so i would like 
to force them to 0.

how can i do this?

bye
fabian



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec  7 07:41:14 2001
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 7 Dec 2001 06:41:14 +0000 (GMT)
Subject: [R] constrained arima0 model
In-Reply-To: <1007673174.536.0.camel@pilgrimage.fragile>
Message-ID: <Pine.GSO.4.31.0112070640100.4068-100000@auk.stats>

On 6 Dec 2001, Fabian Moerchen wrote:

> hi
>
> i want to fit a rather large model (p=12) with arima0.
> some of the resulting AR parameters are very small,
> in the order of their standard errors so i would like
> to force them to 0.
>
> how can i do this?

By modifying the code.

This is something planned for arima(), and that is planned for 1.5.0.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brianscholl1973 at yahoo.com  Fri Dec  7 04:57:25 2001
From: brianscholl1973 at yahoo.com (Brian Scholl)
Date: Thu, 6 Dec 2001 19:57:25 -0800 (PST)
Subject: [R] Latex Question
In-Reply-To: <Pine.GSO.4.30.0112061438200.22825-100000@sunray2>
Message-ID: <20011207035725.16162.qmail@web12205.mail.yahoo.com>

Sorry this is more of a Latex than an R question. I'd
like to be able to insert figures created in R in a
Latex document.  I'm a bit new to Latex so please
speak slowly.   I'm using winedt/miktex (great
programs incidentally).  

Thanks, 

Brian 

__________________________________________________
Do You Yahoo!?
Send your FREE holiday greetings online!
http://greetings.yahoo.com

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ko-Kang at xtra.co.nz  Fri Dec  7 11:17:24 2001
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Fri, 7 Dec 2001 23:17:24 +1300
Subject: [R] Latex Question
References: <20011207035725.16162.qmail@web12205.mail.yahoo.com>
Message-ID: <003c01c17f08$5df22220$585037d2@KoKang>

There are many ways.  Depending on the type of the graph (*.ps, *.pdf,
*.png...).  MiKTeX/WinEdt combination suggests to me that you are using
Windows.  To save your R graph in R for Windows is extremely easy, provided
you are using the GUI version.  Under the File menu there is a Save as
option, simply choose the format you want.

Normally, if you are not using pdflatex command to compile your tex file
(say if you use latex to compile it, both appears as buttons in WinEdt),
then (personally I'd prefer to) use *.ps format when you save your R graph.

The latex command you will need is \includegraphics{filename.ps}.  Normally
I'd use a block of statements as follows:

\begin{figure}[h!]  % Begin to insert a figure, h! means here.  You can
append a t (top) or a b (bottom) in front of h
\begin{center}      % center align your figure/graph
\resizebox{\textwidth}{!}{\includegraphics{Test.ps}}  % Resize it to fit
with the width of your texts, include the graph name
\end{center}  % End the center environment
\caption{Simulation of M/M/1 Queue with $\lambda = 2, \mu = 3$}  % put a
caption under the graph
\label{fig:Q1i} % Give the graph a label, which can be used as a reference
later
\end{figure} % end the figure

I think doing it this way you need to put \usepackage{graphics}in your
premble.  Note that anything after the % is a comment and will be ignored by
the latex compiler.

The above block of codes is complicated enough.  You can of course simply it
down (say only use \includegraphics{Test.ps}, without resizing it).

It is not possible to explain the whole detail of how to do this, please
refer to the LaTeX Companion or the Not so Short Introduction to LaTeX
(Which can be viewed under MikTeX, search for lshort).

Hope this helps,

Ko-Kang Wang
-------------------------------------------------
Ko-Kang Kevin Wang
Head of Statistical Analysis Division
Software Developers' Klub (SDK)
University of Auckland
New Zealand
----- Original Message -----
From: "Brian Scholl" <brianscholl1973 at yahoo.com>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, December 07, 2001 4:57 PM
Subject: [R] Latex Question


> Sorry this is more of a Latex than an R question. I'd
> like to be able to insert figures created in R in a
> Latex document.  I'm a bit new to Latex so please
> speak slowly.   I'm using winedt/miktex (great
> programs incidentally).
>
> Thanks,
>
> Brian
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cdeclercq at nordnet.fr  Fri Dec  7 11:35:02 2001
From: cdeclercq at nordnet.fr (Christophe Declercq)
Date: Fri, 7 Dec 2001 11:35:02 +0100
Subject: [R] Latex Question
In-Reply-To: <20011207035725.16162.qmail@web12205.mail.yahoo.com>
Message-ID: <NEBBLCMFGLNFBEBKHFCEAEDLCEAA.cdeclercq@nordnet.fr>

Hi, Brian

> De : owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch]De la part de Brian Scholl
> Envoy? : vendredi 7 d?cembre 2001 04:57
> ? : r-help at stat.math.ethz.ch
> Objet : [R] Latex Question
>
>
> Sorry this is more of a Latex than an R question. I'd
> like to be able to insert figures created in R in a
> Latex document.  I'm a bit new to Latex so please
> speak slowly.   I'm using winedt/miktex (great
> programs incidentally).

You need the 'graphicx' package with different options if you use LaTeX
or pdfLaTeX.
A short (and dummy) example:

1) LaTeX

Use the postscript device in R:

> postscript("fig1.eps", horizontal=FALSE, onefile=FALSE, width=8,
height=8)
> plot(1:10, rnorm(10))
> dev.off()

Put in your LaTeX document preamble something as:

\usepackage[dvips]{graphicx}

and where in the document you want the figure:

\includegraphics[width=\textwidth]{fig1.eps}

2)pdfLaTeX

Use the pdf device in R:

> pdf("fig1.pdf", width=8, height=8)
> plot(1:10, rnorm(10))
> dev.off()

Put in your LaTeX document preamble something as:

\usepackage[pdftex]{graphicx}

and where in the document you want the figure:

\includegraphics[width=\textwidth]{fig1.pdf}

To know more,  you could read:
- '?postscript 'and '?pdf' in R
- 'The not so Short Introduction to LaTeX2e'
(http://www.ctan.org/tex-archive/info/lshort/english/lshort.pdf).

Hope it helps.

Christophe
--
Christophe DECLERCQ, MD
Observatoire R?gional de la Sant? Nord-Pas-de-Calais
13, rue Faidherbe 59046 LILLE Cedex FRANCE
Phone +33 3 20 15 49 24
Fax   +33 3 20 55 92 30
E-mail c.declercq at orsnpdc.org

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Fri Dec  7 11:32:13 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Fri, 7 Dec 2001 05:32:13 -0500 (EST)
Subject: [R] Latex Question
Message-ID: <200112071032.fB7AWDP12305@cattell.psych.upenn.edu>

Here is how to print graphs for inclusion in Latex.

First make sure you've got the graph you want.  Do this by
repeating and editing the command to make the graph, in the usual
way.  (Yes, I know Miktex is good, but it isn't as good as Emacs
with ESS, although I admit that I could never configure Emacs
properly on Windows - which was reason #23.5 for giving up
Windows.)

Second, say
postscript("foo.eps")
where foo.eps is the file name.  I discovered this by
saying
apropos(postscript)
and then I looked at
?postscript

Then run the command again, and say
dev.off()

To include the graph in Latex, make sure you have something like
\usepackage[dvips]{graphicx}
in your header.  Then, where you want the graph, say something
like
\includegraphics[width=4in]{foo.eps}

Jon Baron


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Fri Dec  7 11:04:28 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 7 Dec 2001 11:04:28 +0100 (CET)
Subject: [R] rbind and data.frame
In-Reply-To: <Pine.LNX.4.33.0112051146250.15421-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.33.0112071052590.19059-100000@tal.stat.umu.se>

On Wed, 5 Dec 2001, G?ran Brostr?m wrote:

[...]
 
> My real problem is how to create a data frame in a sequentially growing
> manner, when I know the final size (no of cases). I want to avoid to
> call 'rbind' many times, and instead create an 'empty' data frame in
> one call, and then fill it. Are there better ways of doing this?

Got no answer to this one, so I provide one myself:

The answer is: Yes, definitely. I did this, with pure  R  code, and 
created a new data frame with around 58000 records. It took 7 hours to 
run. I then did it with compiled code (Fortran), and that made a slight
difference:  It took 4.8 seconds(!).

G?ran

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Fri Dec  7 12:40:01 2001
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Fri, 07 Dec 2001 12:40:01 +0100
Subject: [R] Histograms per coding variable - labelling the plots
In-Reply-To: <E16C0Lx-0003fO-00@mail3.uct.ac.za>
Message-ID: <B8366921.5612%pflugshaupt@geobot.umnw.ethz.ch>

On 06.12.2001 16:22 Uhr, Smit, A, Albertus, Dr wrote:

>> With some tricks, you can even have a title with the respective label over
>> each plot... but I forgot how I did this.
> 
> Does anyone know how to do this?

Well, i dug it up again. At that time, I really tried to avoid for() loops,
no matter how complicated the resulting code :-) .
Here goes (a simplified example):

par(mfrow=c(2, 1))
d.f <- data.frame(l=rep(c("A", "B"), 4), a=1:8)
labels <- levels(d.f$l)
nlab <- length(labels)
# and the "piece de resistance":
sapply(1:nlab, function(x) hist(d.f$a[d.f$l==labels[x]], main=labels[x]))

This also prints out hist()'s textual output. If you don't want that, put
invisible() around the whole line.

On the whole, the solution with for() that Michael Miller posted is more
readable...

Cheers

Kaspar 

-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec  7 12:45:57 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Dec 2001 11:45:57 +0000 (GMT)
Subject: [R] Latex Question
In-Reply-To: <200112071032.fB7AWDP12305@cattell.psych.upenn.edu>
Message-ID: <Pine.LNX.4.31.0112071141110.18476-100000@gannet.stats>

On Fri, 7 Dec 2001, Jonathan Baron wrote:

> Here is how to print graphs for inclusion in Latex.
>
> First make sure you've got the graph you want.  Do this by
> repeating and editing the command to make the graph, in the usual
> way.  (Yes, I know Miktex is good, but it isn't as good as Emacs
> with ESS, although I admit that I could never configure Emacs
> properly on Windows - which was reason #23.5 for giving up
> Windows.)
>
> Second, say
> postscript("foo.eps")
> where foo.eps is the file name.  I discovered this by
> saying
> apropos(postscript)
> and then I looked at
> ?postscript

Please look it up again.  That's not all you need to get proper EPSF, and
you also need to worry about aspect ratios and pointsizes.  E.g.

     The postscript produced by R is EPS (Encapsulated PostScript)
     compatible, and can be included into other documents, e.g. into
     LaTeX, using `\includegraphics{<filename>}'.  For use in this way
     you will probably want to set `horizontal=FALSE, onefile=FALSE,
     paper="special"'.

It is usually *much* easier to use dev.copy2eps() or, on Windows, the
`Save as' on the File menu.

> Then run the command again, and say
> dev.off()
>
> To include the graph in Latex, make sure you have something like
> \usepackage[dvips]{graphicx}
> in your header.  Then, where you want the graph, say something
> like
> \includegraphics[width=4in]{foo.eps}

You'll need to set a bounding box if you do that, and quite possibly
rotate the figure.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paradis at isem.univ-montp2.fr  Fri Dec  7 12:54:49 2001
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Fri, 07 Dec 2001 12:54:49 +0100
Subject: [R] Latex Question
Message-ID: <3.0.32.20011207125449.008f3880@162.38.183.200>

At 19:57 06/12/01 -0800, Brian Scholl wrote:
>Sorry this is more of a Latex than an R question. I'd
>like to be able to insert figures created in R in a
>Latex document.  I'm a bit new to Latex so please
>speak slowly.   I'm using winedt/miktex (great
>programs incidentally).  
>
>Thanks, 
>
>Brian 

Hi Brian,

I found two ways to nicely produce figures for inclusion in LaTeX:

1) use the postscript device, eg:

postscript(file="myfig1.ps", width=..., height=..., horizontal=FALSE)
plot(...)
....
dev.off()

I think you need to specify horizontal=FALSE (the default is TRUE) to have
something ok when inseting in LaTeX.

2) use the function dev.copy2eps() from the R command line, eg you do your
figure on your windows device and when you are happy with it, type the
command:

dev.copy2eps(file="myfig1.eps")


I found that both ways produce files that can be inserted "as is" in LaTeX
documents (ie, no need to edit/modify them with Illustrator,
GhostScript...). If you use the menu File|Save as|Postscript from the
windows device, the resulting PS file does not include nicely in LaTeX.

I use Emacs with RefTeX and AucTeX to edit my .tex files, and this great as
well.

Hope this helps

Emmanuel Paradis
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hb at maths.lth.se  Fri Dec  7 13:15:22 2001
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 7 Dec 2001 13:15:22 +0100 (MET)
Subject: [R] Latex Question
In-Reply-To: <20011207035725.16162.qmail@web12205.mail.yahoo.com>
Message-ID: <Pine.GSO.4.10.10112071306400.12792-100000@speed.maths.lth.se>

You have to save your plots/figures in EPS format. EPS is basically 
the same as PS (postscript), but it is a one-page document with a
"BoundingBox". 

Example

In [R]:

  ...
  plot(sin(1:10), pch="+")
  dev.print(device=postscript, "myFigure.eps", onefile=FALSE)
  ...

(don't forget the 'onefile' argument that is used by the device driver
'postscript'!).

In LaTeX:

  ...
  Bla bla see Figure~\ref{figMyFigure}.

  \begin{figure}[hbtp]
    \begin{center}
      \resizebox{!}{80mm}{\includegraphics{myFigure.eps}}
    \end{center}
    \caption{The data used...}
    \label{figMyFigure} % <-- NOTE: After \caption!
  \end{figure}
  ...

This requires that you use "\usepackage{graphics}" at the top your LaTeX
document.


Cheers

Henrik Bengtsson

Dept. of Mathematical Statistics @ Centre for Mathematical Sciences 
Lund Institute of Technology/Lund University, Sweden (+2h UTC)
Office: P316, +46 46 222 9611 (phone), +46 46 222 4623 (fax)
h b @ m a t h s . l t h . s e
http://www.maths.lth.se/matstat/staff/hb/



On Thu, 6 Dec 2001, Brian Scholl wrote:

> Sorry this is more of a Latex than an R question. I'd
> like to be able to insert figures created in R in a
> Latex document.  I'm a bit new to Latex so please
> speak slowly.   I'm using winedt/miktex (great
> programs incidentally).  
> 
> Thanks, 
> 
> Brian 
> 
> __________________________________________________
> Do You Yahoo!?

> http://greetings.yahoo.com
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From berndjagla at yahoo.com  Fri Dec  7 19:26:16 2001
From: berndjagla at yahoo.com (Bernd Jagla)
Date: Fri, 7 Dec 2001 13:26:16 -0500
Subject: [R] densityplots
Message-ID: <003801c17f4c$a92b16e0$fb00a8c0@phaseintern.de>

Dear all,

I am new in R so please forgive the "dumb" question...

I am used to work with Mathematica where it is possible to display a 2D array as a collection of shaded squares. The gray level there represents the value of the array element. It is basically a projection of a 2-dimensional histogram.

After a lot of reading I still haven't found that kind of function.

I would be grateful for any kind of help.

Thank you in advance.

Bernd 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011207/73ab1c32/attachment.html

From ripley at stats.ox.ac.uk  Fri Dec  7 13:47:38 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Dec 2001 12:47:38 +0000 (GMT)
Subject: [R] densityplots
In-Reply-To: <003801c17f4c$a92b16e0$fb00a8c0@phaseintern.de>
Message-ID: <Pine.LNX.4.31.0112071246580.18581-100000@gannet.stats>

On Fri, 7 Dec 2001, Bernd Jagla wrote:

> Dear all,
>
> I am new in R so please forgive the "dumb" question...
>
> I am used to work with Mathematica where it is possible to display a 2D array as a collection of shaded squares. The gray level there represents the value of the array element. It is basically a projection of a 2-dimensional histogram.
>
> After a lot of reading I still haven't found that kind of function.

image()


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec  7 13:50:07 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Dec 2001 12:50:07 +0000 (GMT)
Subject: [R] rbind and data.frame
In-Reply-To: <Pine.LNX.4.33.0112071052590.19059-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.31.0112071249020.18581-100000@gannet.stats>

On Fri, 7 Dec 2001, [iso-8859-1] Göran Broström wrote:

> On Wed, 5 Dec 2001, Göran Broström wrote:
>
> [...]
>
> > My real problem is how to create a data frame in a sequentially growing
> > manner, when I know the final size (no of cases). I want to avoid to
> > call 'rbind' many times, and instead create an 'empty' data frame in
> > one call, and then fill it. Are there better ways of doing this?
>
> Got no answer to this one, so I provide one myself:

The usual answer is to create a data frame of the desired size and
populate it via indexing.  That's in some books I know!

>
> The answer is: Yes, definitely. I did this, with pure  R  code, and
> created a new data frame with around 58000 records. It took 7 hours to
> run. I then did it with compiled code (Fortran), and that made a slight
> difference:  It took 4.8 seconds(!).
>
> Göran
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From snoweye at nhri.org.tw  Fri Dec  7 14:10:20 2001
From: snoweye at nhri.org.tw (snoweye@nhri.org.tw)
Date: Fri, 7 Dec 2001 21:10:20 +0800
Subject: [R] Trouble about RSJava for Win32
Message-ID: <002801c17f20$85f9b4a0$454c3ed2@812snoweye>

Hi, Sir

I have some trouble about omegahat package, please tell me how to do, Thank
you!!

Now, I have install the package RSJava for R and also install JDK 1.3
on win32-intel platform. When I click into the RGui environment, I want
to load the RSJava library,

> library("SJava")
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"C:/PROGRA~1/R/RW1030/library/SJava/libs/SJava.dll":
  LoadLibrary failure:  §ä¤£¨ì°õ¦æ¦¹À³¥Îµ{¦¡©Ò»Ýªºµ{¦¡®wÀÉ®×¡C
Error in library("SJava") : .First.lib failed

but I have some error message above. Where is wrong?







-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Fri Dec  7 13:24:38 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 7 Dec 2001 13:24:38 +0100 (CET)
Subject: [R] rbind and data.frame
In-Reply-To: <Pine.LNX.4.31.0112071249020.18581-100000@gannet.stats>
Message-ID: <Pine.LNX.4.33.0112071320360.19234-100000@tal.stat.umu.se>

On Fri, 7 Dec 2001, Prof Brian Ripley wrote:

> On Fri, 7 Dec 2001, [iso-8859-1] G?ran Brostr?m wrote:
> 
> > On Wed, 5 Dec 2001, G?ran Brostr?m wrote:
> >
> > [...]
> >
> > > My real problem is how to create a data frame in a sequentially growing
> > > manner, when I know the final size (no of cases). I want to avoid to
> > > call 'rbind' many times, and instead create an 'empty' data frame in
> > > one call, and then fill it. Are there better ways of doing this?
> >
> > Got no answer to this one, so I provide one myself:
> 
> The usual answer is to create a data frame of the desired size and
> populate it via indexing.  That's in some books I know!

I know that book too (thanks!). I did what you suggest, and that took 7 
hours to run. Definitely.

G?ran

> >
> > The answer is: Yes, definitely. I did this, with pure  R  code, and
> > created a new data frame with around 58000 records. It took 7 hours to
> > run. I then did it with compiled code (Fortran), and that made a slight
> > difference:  It took 4.8 seconds(!).
> >
> > G?ran
> >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> >
> 
> 

-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paradis at isem.univ-montp2.fr  Fri Dec  7 15:08:24 2001
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Fri, 7 Dec 2001 15:08:24 +0100
Subject: [R] rbind and data.frame
Message-ID: <3.0.32.19700101010000.008f8cd0@162.38.183.200>

G=F6ran,

At 11:04 07/12/01 +0100, G=F6ran Brostr=F6m wrote:
>On Wed, 5 Dec 2001, G=F6ran Brostr=F6m wrote:
>
>[...]
>=20
>> My real problem is how to create a data frame in a sequentially growing
>> manner, when I know the final size (no of cases). I want to avoid to
>> call 'rbind' many times, and instead create an 'empty' data frame in
>> one call, and then fill it. Are there better ways of doing this?
>
>Got no answer to this one, so I provide one myself:
>
>The answer is: Yes, definitely. I did this, with pure  R  code, and=20
>created a new data frame with around 58000 records. It took 7 hours to=20
>run. I then did it with compiled code (Fortran), and that made a slight
>difference:  It took 4.8 seconds(!).
>
>G=F6ran

I seem to remember that R is not very efficient at creating/manipulating
large data frames. Did you consider doing it with a matrix with 58000 rows?
In that case, of course, all your columns *must* be of the same mode.

Emmanuel Paradis
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Fri Dec  7 16:32:31 2001
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 07 Dec 2001 10:32:31 -0500
Subject: [R] rbind and data.frame
Message-ID: <51F9C42DA15CD311BD220008C707D81903DC8400@usrymx10.merck.com>

Are you sure that the time difference is *only* in creating the data frame,
rather than other computations in the loop?

Andy

> -----Original Message-----
> From: G?ran Brostr?m [mailto:gb at stat.umu.se]
> Sent: Friday, December 07, 2001 7:25 AM
> To: Prof Brian Ripley
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] rbind and data.frame
> 
> 
> On Fri, 7 Dec 2001, Prof Brian Ripley wrote:
> 
> > On Fri, 7 Dec 2001, [iso-8859-1] G?ran Brostr?m wrote:
> > 
> > > On Wed, 5 Dec 2001, G?ran Brostr?m wrote:
> > >
> > > [...]
> > >
> > > > My real problem is how to create a data frame in a 
> sequentially growing
> > > > manner, when I know the final size (no of cases). I 
> want to avoid to
> > > > call 'rbind' many times, and instead create an 'empty' 
> data frame in
> > > > one call, and then fill it. Are there better ways of doing this?
> > >
> > > Got no answer to this one, so I provide one myself:
> > 
> > The usual answer is to create a data frame of the desired size and
> > populate it via indexing.  That's in some books I know!
> 
> I know that book too (thanks!). I did what you suggest, and 
> that took 7 
> hours to run. Definitely.
> 
> G?ran
> 
> > >
> > > The answer is: Yes, definitely. I did this, with pure  R  
> code, and
> > > created a new data frame with around 58000 records. It 
> took 7 hours to
> > > run. I then did it with compiled code (Fortran), and that 
> made a slight
> > > difference:  It took 4.8 seconds(!).
> > >
> > > G?ran
> > >
> > > 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> > > r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > > Send "info", "help", or "[un]subscribe"
> > > (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> > > 
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> > >
> > 
> > 
> 
> -- 
>  G?ran Brostr?m                      tel: +46 90 786 5223
>  professor                           fax: +46 90 786 6614
>  Department of Statistics            http://www.stat.umu.se/egna/gb/
>  Ume? University
>  SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lek at cict.fr  Fri Dec  7 16:48:03 2001
From: lek at cict.fr (Sovan Lek)
Date: Fri, 7 Dec 2001 16:48:03 +0100
Subject: [R] Help for Linear Discriminant Analysis
Message-ID: <013d01c17f36$8eac42a0$0f697882@upstlse.fr>

Dear colleague,

I'd like to compute linear discriminant analysis, using R. In the book Modern applied statistic with Splus (Venables & Ripley, p. 396),  lda function is used. Could you tell me where I can find this function? At what site, can I download this library ?

Thank for your help.
Best Regards
Sovan

----------------------------------------------------------------
Prof. Sovan LEK,   E-mail: lek at cict.fr
Address:
CNRS - UMR 5576    Tel. : (33) 5 61 55 86 87
CESAC - Bat. 4R3   Fax  : (33) 5 61 55 60 96
Uuniv. Paul Sabatier 
118 route de Narbonne
31062 Toulouse cedex
France
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011207/7ca36484/attachment.html

From jniesch at gwdg.de  Fri Dec  7 17:21:21 2001
From: jniesch at gwdg.de (Jens Nieschulze)
Date: Fri, 7 Dec 2001 17:21:21 +0100 (MET)
Subject: [R] Help for Linear Discriminant Analysis
In-Reply-To: <013d01c17f36$8eac42a0$0f697882@upstlse.fr>
Message-ID: <Pine.SO4.4.10.10112071720270.13508-100000@ufobi7.uni-forst.gwdg.de>

On Fri, 7 Dec 2001, Sovan Lek wrote:

%Dear colleague,
%
%%I'd like to compute linear discriminant analysis, using R. In the book Modern
%applied statistic with Splus (Venables & Ripley, p. 396),  lda function is
%used. Could you tell me where I can find this function? At what site, can I
%download this library ?

package VR from 
http://cran.r-project.org/

%Thank for your help.
%Best Regards
%Sovan
%
%----------------------------------------------------------------
%Prof. Sovan LEK,   E-mail: lek at cict.fr
%Address:
%CNRS - UMR 5576    Tel. : (33) 5 61 55 86 87
%CESAC - Bat. 4R3   Fax  : (33) 5 61 55 60 96
%Uuniv. Paul Sabatier 
%118 route de Narbonne
%31062 Toulouse cedex
%France
%

***********************************************************************
Jens Nieschulze

Institute for Forest Biometrics &	Phone: ++49-551-39-12107
Applied Computer Science		Fax  : ++49-551-39-3465
Buesgenweg 4
37077 Goettingen		E-mail: jniesch at uni-forst.gwdg.de
GERMANY				http://www.uni-forst.gwdg.de/~jniesch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Fri Dec  7 16:47:24 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 7 Dec 2001 16:47:24 +0100 (CET)
Subject: [R] rbind and data.frame
In-Reply-To: <3.0.32.19700101010000.008f8cd0@162.38.183.200>
Message-ID: <Pine.LNX.4.33.0112071624150.19448-100000@tal.stat.umu.se>

On 7 xxx -1, Emmanuel Paradis wrote:

[...]
 
> I seem to remember that R is not very efficient at creating/manipulating
> large data frames. Did you consider doing it with a matrix with 58000 rows?
> In that case, of course, all your columns *must* be of the same mode.

Yes, I tried reading from a data.frame, doing some calculations,
and writing to rows of a matrix. It is definitely faster than writing to
a data frame, but _much_ slower than compiled code. We also have to 
convert the matrix to a data frame of a given type. It is not quite 
trivial, because variable types and names have  to be 'read' from the 
input data frame, but I think I know how to do that.

I think the _real_ problem is that I have to do this in a loop, row by 
row, because the input rows produce a variable number of output rows.

G?ran

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Fri Dec  7 17:30:35 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 7 Dec 2001 17:30:35 +0100 (CET)
Subject: [R] rbind and data.frame
In-Reply-To: <51F9C42DA15CD311BD220008C707D81903DC8400@usrymx10.merck.com>
Message-ID: <Pine.LNX.4.33.0112071720550.19573-100000@tal.stat.umu.se>

On Fri, 7 Dec 2001, Liaw, Andy wrote:

> Are you sure that the time difference is *only* in creating the data frame,
> rather than other computations in the loop?

Of course it depends on all the calculations. And that is a lot (of code).
Here it is. Suggestions of improvements are most welcome!

G?ran
-----------------------------------------------------------------------
[...]
  ## We now have 'nn.out'. We next create an empty data frame 'dat.out':
  xx <- cbind(dat[1, , drop = FALSE], com.dat[1, , drop = FALSE])
  dat.out <- matrix(NA, ncol = ncol(xx), nrow = nn.out)
  dat.out <- data.frame(dat.out)
  names(dat.out) <- names(xx)
  dat.out <- rbind(xx, dat.out)[-1, ]

  ## And so we fill it!

  cur.row <- 0
  for (j in 1:nn){
    start.ind <- dat$bdate[j] + dat$enter[j]
    stopp.ind <- dat$bdate[j] + dat$exit[j]
    
    if ((start.ind < end.per) &&
        (stopp.ind > beg.per)){   ## We have a case!
      fixed.rec <- dat[j, , drop = FALSE]
      out.rec <- fixed.rec
      if (start.ind < beg.per){      ## start.ind < beg.per  (A)
        
        if (stopp.ind > end.per){    ## stopp.ind > end.per  (A1)
          ##nn.out <- nn.out + n.years
          out.rec$event <- 0
          for (iv in 1:n.years){
            cur.row <- cur.row + 1
            out.rec$enter <- cuts[iv] - fixed.rec$bdate
            out.rec$exit <- cuts[iv + 1] - fixed.rec$bdate
            dat.out[cur.row, ] <-
              cbind(out.rec, com.dat[iv, , drop = FALSE])
          }
        }else{                       ## stopp.ind <= end.per (A2)
          last.iv <- 1
          while ((last.iv <= n.years) &&
                 (stopp.ind > cuts[last.iv + 1])){
            last.iv <- last.iv + 1
          }
          ##nn.out <- nn.out + last.iv
          if (last.iv == 1){
            cur.row <- cur.row + 1
            out.rec$enter <- beg.per - fixed.rec$bdate
            out.rec$exit <- fixed.rec$exit
            out.rec$event <- fixed.rec$event
            dat.out[cur.row, ] <-
              cbind(out.rec, com.dat[1, , drop = FALSE])
          }else{
            out.rec$event <- 0
            for (iv in 1:(last.iv - 1)){
              cur.row <- cur.row + 1
              out.rec$enter <- cuts[iv] - fixed.rec$bdate
              out.rec$exit <- cuts[iv + 1] - fixed.rec$bdate
              dat.out[cur.row, ] <-
                cbind(out.rec, com.dat[iv, , drop = FALSE])
            }
            cur.row <- cur.row + 1            
            out.rec$event <- fixed.rec$event
            out.rec$enter <- cuts[last.iv] - fixed.rec$bdate
            out.rec$exit <- fixed.rec$exit
            dat.out[cur.row, ] <-
              cbind(out.rec, com.dat[last.iv, , drop = FALSE])
          }
        }
      }else{                       ## start.ind >= beg.per  (B)
        first.iv <- 1
        while ((first.iv <= n.years) &&
               (start.ind >= cuts[first.iv + 1])){
          first.iv <- first.iv + 1
        }
        if (stopp.ind > end.per){  ## stopp.ind > end.per   (B1)
          ##nn.out <- nn.out + n.years - first.iv + 1
          cur.row <- cur.row + 1            
          out.rec$event <- 0
          out.rec$enter <- fixed.rec$enter
          out.rec$exit <- cuts[first.iv + 1] - fixed.rec$bdate
          dat.out[cur.row, ] <-
            cbind(out.rec, com.dat[first.iv, , drop = FALSE])
          if (first.iv < n.years){
            for (iv in (first.iv + 1):n.years){
              cur.row <- cur.row + 1
              out.rec$enter <- cuts[iv] - fixed.rec$bdate
              out.rec$exit <- cuts[iv + 1] - fixed.rec$bdate
              dat.out[cur.row, ] <-
                cbind(out.rec, com.dat[iv, , drop = FALSE])
            }
          }
        }else{                     ## stopp.ind <= end.per  (B2)
          last.iv <- first.iv
          while ((last.iv <= n.years) &&
                 (stopp.ind > cuts[last.iv + 1])){
            last.iv <- last.iv + 1
          }
          ##nn.out <- nn.out + last.iv - first.iv + 1
          if (last.iv == first.iv){
            cur.row <- cur.row + 1
            dat.out[cur.row, ] <-
              cbind(out.rec, com.dat[first.iv, , drop = FALSE])
          }else{
            cur.row <- cur.row + 1
            out.rec$event <- 0
            out.rec$exit <- cuts[first.iv + 1] - fixed.rec$bdate
            dat.out[cur.row, ] <-
              cbind(out.rec, com.dat[first.iv, , drop = FALSE])
            if (last.iv > (first.iv + 1)){
              for (iv in (first.iv + 1):(last.iv - 1)){
                cur.row <- cur.row + 1
                out.rec$enter <- cuts[iv] - fixed.rec$bdate
                out.rec$exit <- cuts[iv + 1] - fixed.rec$bdate
                dat.out[cur.row, ] <-
                  cbind(out.rec, com.dat[iv, , drop = FALSE])
              }
            }
            cur.row <- cur.row + 1
            out.rec$event <- fixed.rec$event
            out.rec$enter <- cuts[last.iv] - fixed.rec$bdate
            out.rec$exit <- fixed.rec$exit
            dat.out[cur.row, ] <-
              cbind(out.rec, com.dat[last.iv, , drop = FALSE])
          }
        }
      }
    }
    cat("j = ", j, "cur.row = ", cur.row, "\n")
  }
  
  dat.out
}
-------------------------------------------------------------------------

> 
> Andy
> 
> > -----Original Message-----
> > From: G?ran Brostr?m [mailto:gb at stat.umu.se]
> > Sent: Friday, December 07, 2001 7:25 AM
> > To: Prof Brian Ripley
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] rbind and data.frame
> > 
> > 
> > On Fri, 7 Dec 2001, Prof Brian Ripley wrote:
> > 
> > > On Fri, 7 Dec 2001, [iso-8859-1] G?ran Brostr?m wrote:
> > > 
> > > > On Wed, 5 Dec 2001, G?ran Brostr?m wrote:
> > > >
> > > > [...]
> > > >
> > > > > My real problem is how to create a data frame in a 
> > sequentially growing
> > > > > manner, when I know the final size (no of cases). I 
> > want to avoid to
> > > > > call 'rbind' many times, and instead create an 'empty' 
> > data frame in
> > > > > one call, and then fill it. Are there better ways of doing this?
> > > >
> > > > Got no answer to this one, so I provide one myself:
> > > 
> > > The usual answer is to create a data frame of the desired size and
> > > populate it via indexing.  That's in some books I know!
> > 
> > I know that book too (thanks!). I did what you suggest, and 
> > that took 7 
> > hours to run. Definitely.
> > 
> > G?ran
> > 
> > > >
> > > > The answer is: Yes, definitely. I did this, with pure  R  
> > code, and
> > > > created a new data frame with around 58000 records. It 
> > took 7 hours to
> > > > run. I then did it with compiled code (Fortran), and that 
> > made a slight
> > > > difference:  It took 4.8 seconds(!).
> > > >
> > > > G?ran
> > > >
> > > > 
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> > -.-.-.-.-.-.-.-.-
> > > > r-help mailing list -- Read 
> > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > > > Send "info", "help", or "[un]subscribe"
> > > > (in the "body", not the subject !)  To: 
> > r-help-request at stat.math.ethz.ch
> > > > 
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> > _._._._._._._._._
> > > >
> > > 
> > > 
> > 
> > -- 
> >  G?ran Brostr?m                      tel: +46 90 786 5223
> >  professor                           fax: +46 90 786 6614
> >  Department of Statistics            http://www.stat.umu.se/egna/gb/
> >  Ume? University
> >  SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
> > 
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> > -.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read 
> > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: 
> > r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> > _._._._._._._._._
> > 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maba at ukl.uni-freiburg.de  Fri Dec  7 19:10:11 2001
From: maba at ukl.uni-freiburg.de (Manfred W. Baumstark)
Date: Fri, 07 Dec 2001 19:10:11 +0100
Subject: [R] Memory problem
Message-ID: <3C110602.9BEF3A3E@ukl.uni-freiburg.de>

Dear all,

I have written a little R program to convert images. See below. Within the
loop over j (the filenames) memory consumption grows constantly. rm( ... )
inside the loop did not help. Memory does not grow if I remove the writeBin
statements between the two #-------- marks. But obviously this is not
solution I want... 

Thanks for any advice. 

Manfred Baumstark
P.S. As I'm new to R: what sort of tests can I make to trace the problem?

Configuration: R-gui 1.3.1, WinNT 4.0, the same happens in R under IRIX 6.5
--------------------------------------
# Read list of filenames made by ls -1 <exp> >filelist
cfn <- file("filelist", "rt")
fn <- readLines(cfn, n = -1, ok = TRUE)
close(cfn)
pad <- integer(length = 384)

for (j in 1:length(fn)) { 

  img <- file(fn[j], "rb")  	
  header <- readChar(img,8192)		
		
  imv <- readBin(img, "integer", n=1536*1536, size=2, signed=FALSE,
endian="big")
  close(img)
  imm <- matrix(imv, nrow=1536, ncol=1536)

  imout <- file(paste("test_", fn[j], sep=""), "wb")  	
  writeChar(header, imout, nchars = 512, eos = NULL) 

#--------
  for (i in 1:1536) {  
    writeBin(pad, imout, size=2, endian="big")
    writeBin(imm[,i], imout, size=2, endian="big")
    writeBin(pad, imout, size=2, endian="big")
  }
#--------
  close(imout)
  rm( img, header, imv, imm, imout, i)

}
-------------- next part --------------
A non-text attachment was scrubbed...
Name: maba.vcf
Type: text/x-vcard
Size: 356 bytes
Desc: Card for Manfred W. Baumstark
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20011207/2ae484ae/maba.vcf

From kjetilh at umsanet.edu.bo  Fri Dec  7 19:24:41 2001
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Fri, 07 Dec 2001 14:24:41 -0400
Subject: [R] error in parse
Message-ID: <3C110969.77C2E7B2@umsanet.edu.bo>

I am trying to source a file defining a dataset, giving the full path.
(rw1031 on windows 98)

> source("c:\\kjetil\\audiometria\\data\\audiometria.R")
Error in parse(file, n, text, prompt) : syntax error on line 6

also:

> parse(file="c:\\kjetil\\audiometria\\data\\audiometria.R", n=-1)
Error in parse(file, n, text, prompt) : syntax error on line 6

This seems very strange. Trying to read the file with data()
gives the same error.


Kjetil Halvorsen
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec  7 19:30:24 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Dec 2001 18:30:24 +0000 (GMT)
Subject: [R] error in parse
In-Reply-To: <3C110969.77C2E7B2@umsanet.edu.bo>
Message-ID: <Pine.LNX.4.31.0112071829260.1126-100000@gannet.stats>

What's strange?: there is an error in that file on or before line 6!


On Fri, 7 Dec 2001, kjetil halvorsen wrote:

> I am trying to source a file defining a dataset, giving the full path.
> (rw1031 on windows 98)
>
> > source("c:\\kjetil\\audiometria\\data\\audiometria.R")
> Error in parse(file, n, text, prompt) : syntax error on line 6
>
> also:
>
> > parse(file="c:\\kjetil\\audiometria\\data\\audiometria.R", n=-1)
> Error in parse(file, n, text, prompt) : syntax error on line 6
>
> This seems very strange. Trying to read the file with data()
> gives the same error.
>
>
> Kjetil Halvorsen
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maba at ukl.uni-freiburg.de  Fri Dec  7 19:57:56 2001
From: maba at ukl.uni-freiburg.de (Manfred W. Baumstark)
Date: Fri, 07 Dec 2001 19:57:56 +0100
Subject: [R] Memory problem
Message-ID: <3C111134.D2CC85FA@ukl.uni-freiburg.de>

Dear all,

I have written a little R program to convert images. See below. Within the
loop over j (the filenames) memory consumption grows constantly. rm( ... )
inside the loop did not help. Memory does not grow if I remove the writeBin
statements between the two #-------- marks. But obviously this is not
solution I want... 

Thanks for any advice. 

Manfred Baumstark
P.S. As I'm new to R: what sort of tests can I make to trace the problem?

Configuration: R-gui 1.3.1, WinNT 4.0, the same happens in R under IRIX 6.5
--------------------------------------
# Read list of filenames made by ls -1 <exp> >filelist
cfn <- file("filelist", "rt")
fn <- readLines(cfn, n = -1, ok = TRUE)
close(cfn)
pad <- integer(length = 384)

for (j in 1:length(fn)) { 

  img <- file(fn[j], "rb")  	
  header <- readChar(img,8192)		
		
  imv <- readBin(img, "integer", n=1536*1536, size=2, signed=FALSE,
endian="big")
  close(img)
  imm <- matrix(imv, nrow=1536, ncol=1536)

  imout <- file(paste("test_", fn[j], sep=""), "wb")  	
  writeChar(header, imout, nchars = 512, eos = NULL) 

#--------
  for (i in 1:1536) {  
    writeBin(pad, imout, size=2, endian="big")
    writeBin(imm[,i], imout, size=2, endian="big")
    writeBin(pad, imout, size=2, endian="big")
  }
#--------
  close(imout)
  rm( img, header, imv, imm, imout, i)

}
-------------- next part --------------
A non-text attachment was scrubbed...
Name: maba.vcf
Type: text/x-vcard
Size: 356 bytes
Desc: Card for Manfred W. Baumstark
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20011207/cfee6157/maba.vcf

From kjetilh at umsanet.edu.bo  Fri Dec  7 19:59:05 2001
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Fri, 07 Dec 2001 14:59:05 -0400
Subject: [R] error in parse
References: <Pine.LNX.4.31.0112071829260.1126-100000@gannet.stats>
Message-ID: <3C111179.B2D2A899@umsanet.edu.bo>



Prof Brian Ripley wrote:
> 
> What's strange?: there is an error in that file on or before line 6!

Thats not the error. Even after changing the file,. making it more
reasonable, and removing some blank lines, exactly the same error
occurs. And there is no syntax error in the file, cut and paste work
perfectly.

Kjetil Halvorsen
> 
> On Fri, 7 Dec 2001, kjetil halvorsen wrote:
> 
> > I am trying to source a file defining a dataset, giving the full path.
> > (rw1031 on windows 98)
> >
> > > source("c:\\kjetil\\audiometria\\data\\audiometria.R")
> > Error in parse(file, n, text, prompt) : syntax error on line 6
> >
> > also:
> >
> > > parse(file="c:\\kjetil\\audiometria\\data\\audiometria.R", n=-1)
> > Error in parse(file, n, text, prompt) : syntax error on line 6
> >
> > This seems very strange. Trying to read the file with data()
> > gives the same error.
> >
> >
> > Kjetil Halvorsen
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> >
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Fri Dec  7 20:03:04 2001
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 07 Dec 2001 20:03:04 +0100
Subject: [R] error in parse
References: <3C110969.77C2E7B2@umsanet.edu.bo>
Message-ID: <3C111268.2149CBAD@statistik.uni-dortmund.de>



kjetil halvorsen wrote:
> 
> I am trying to source a file defining a dataset, giving the full path.
> (rw1031 on windows 98)
> 
> > source("c:\\kjetil\\audiometria\\data\\audiometria.R")
> Error in parse(file, n, text, prompt) : syntax error on line 6


Reading the error message I think the following:
Have a closer look at line 6 of the file audiometria.R, there seems to
be a syntax error, as the error message tells us.

Uwe
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fabian at mybytes.de  Fri Dec  7 13:09:57 2001
From: fabian at mybytes.de (Fabian Moerchen)
Date: 07 Dec 2001 13:09:57 +0100
Subject: [R] constrained arima0 model
In-Reply-To: <Pine.GSO.4.31.0112070640100.4068-100000@auk.stats>
References: <Pine.GSO.4.31.0112070640100.4068-100000@auk.stats>
Message-ID: <1007726999.671.2.camel@pilgrimage.fragile>

On Fri, 2001-12-07 at 07:41, Prof Brian D Ripley wrote:
> On 6 Dec 2001, Fabian Moerchen wrote:
> 
> > hi
> >
> > i want to fit a rather large model (p=12) with arima0.
> > some of the resulting AR parameters are very small,
> > in the order of their standard errors so i would like
> > to force them to 0.
> >
> > how can i do this?
> 
> By modifying the code.

too bad.

but if i simplify the model so P and Q for the "in between year" model
are 0, then i could use manual differencing (D) and then the arma method
with the lag= option, right?

bye
fabian 

> 
> This is something planned for arima(), and that is planned for 1.5.0.
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From james.holtman at convergys.com  Fri Dec  7 20:14:58 2001
From: james.holtman at convergys.com (james.holtman@convergys.com)
Date: Fri, 7 Dec 2001 14:14:58 -0500
Subject: [R] rbind and data.frame
Message-ID: <OF29BDE25C.ED1A266D-ON85256B1B.006938FD@cbis.com>


Heres some timings from a 700MHZ laptop running WIN/2000:

> x.1 <- data.frame(a=integer(85000), b=double(85000), c=character(85000))
> str(x.1)
`data.frame':   85000 obs. of  3 variables:
 $ a: int  0 0 0 0 0 0 0 0 0 0 ...
 $ b: num  0 0 0 0 0 0 0 0 0 0 ...
 $ c: Factor w/ 1 level "": 1 1 1 1 1 1 1 1 1 1 ...
#
# loading up a variable with a vector takes very little time
#
> system.time(x.1$a <- 1:85000)
[1] 0.03 0.00 0.03   NA   NA
> str(x.1)
`data.frame':   85000 obs. of  3 variables:
 $ a: int  1 2 3 4 5 6 7 8 9 10 ...
 $ b: num  0 0 0 0 0 0 0 0 0 0 ...
 $ c: Factor w/ 1 level "": 1 1 1 1 1 1 1 1 1 1 ...
#
# a 'for' loop by itself is only 0.3 seconds
#
> system.time(for (i in 1:85000)invisible(1))
[1] 0.30 0.00 0.31   NA   NA
#
# it takes me 5 seconds to initialize 85,000 of a variable, so I would
assume
# it would depend on how many and what type.  If 'factors', I would assume
you would
# declare those as 'character' and then convert to 'factor' at the end.
# so it seems fast; is there something I am missing?
#
> system.time(for (i in 1:85000) x.1$a[i] <- i)
[1] 5.12 0.04 5.22   NA   NA
>




"Liaw, Andy" <andy_liaw at merck.com>@stat.math.ethz.ch on 12/07/2001 10:32:31

Sent by:  owner-r-help at stat.math.ethz.ch


To:   r-help at stat.math.ethz.ch
cc:
Subject:  RE: [R] rbind and data.frame


Are you sure that the time difference is *only* in creating the data frame,
rather than other computations in the loop?

Andy

> -----Original Message-----
> From: G?ran Brostr?m [mailto:gb at stat.umu.se]
> Sent: Friday, December 07, 2001 7:25 AM
> To: Prof Brian Ripley
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] rbind and data.frame
>
>
> On Fri, 7 Dec 2001, Prof Brian Ripley wrote:
>
> > On Fri, 7 Dec 2001, [iso-8859-1] G?ran Brostr?m wrote:
> >
> > > On Wed, 5 Dec 2001, G?ran Brostr?m wrote:
> > >
> > > [...]
> > >
> > > > My real problem is how to create a data frame in a
> sequentially growing
> > > > manner, when I know the final size (no of cases). I
> want to avoid to
> > > > call 'rbind' many times, and instead create an 'empty'
> data frame in
> > > > one call, and then fill it. Are there better ways of doing this?
> > >
> > > Got no answer to this one, so I provide one myself:
> >
> > The usual answer is to create a data frame of the desired size and
> > populate it via indexing.  That's in some books I know!
>
> I know that book too (thanks!). I did what you suggest, and
> that took 7
> hours to run. Definitely.
>
> G?ran
>
> > >
> > > The answer is: Yes, definitely. I did this, with pure  R
> code, and
> > > created a new data frame with around 58000 records. It
> took 7 hours to
> > > run. I then did it with compiled code (Fortran), and that
> made a slight
> > > difference:  It took 4.8 seconds(!).
> > >
> > > G?ran
> > >
> > >
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> > > r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > > Send "info", "help", or "[un]subscribe"
> > > (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> > >
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> > >
> >
> >
>
> --
>  G?ran Brostr?m                      tel: +46 90 786 5223
>  professor                           fax: +46 90 786 6614
>  Department of Statistics            http://www.stat.umu.se/egna/gb/
>  Ume? University
>  SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._



--

NOTICE:  The information contained in this electronic mail transmission is
intended by Convergys Corporation for the use of the named individual or
entity to which it is directed and may contain information that is
privileged or otherwise confidential.  If you have received this electronic
mail transmission in error, please delete it from your system without
copying or forwarding it, and notify the sender of the error by reply email
or by telephone (collect), so that the sender's address records can be
corrected.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec  7 20:15:22 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Dec 2001 19:15:22 +0000 (GMT)
Subject: [R] error in parse
In-Reply-To: <3C111179.B2D2A899@umsanet.edu.bo>
Message-ID: <Pine.LNX.4.31.0112071909380.1544-100000@gannet.stats>

On Fri, 7 Dec 2001, kjetil halvorsen wrote:

> Prof Brian Ripley wrote:
> >
> > What's strange?: there is an error in that file on or before line 6!
>
> Thats not the error. Even after changing the file,. making it more
> reasonable, and removing some blank lines, exactly the same error
> occurs. And there is no syntax error in the file, cut and paste work
> perfectly.

The test of no syntax error is that the parser does not give an error, so
*by definition* there is a syntax error.

Might there be a non-printing (and hence invisible) character in there,
for example?  Have you done an octal dump?  Are all the quote-like
characters the ISO ones and not what Word likes to use? ....


> Kjetil Halvorsen
> >
> > On Fri, 7 Dec 2001, kjetil halvorsen wrote:
> >
> > > I am trying to source a file defining a dataset, giving the full path.
> > > (rw1031 on windows 98)
> > >
> > > > source("c:\\kjetil\\audiometria\\data\\audiometria.R")
> > > Error in parse(file, n, text, prompt) : syntax error on line 6
> > >
> > > also:
> > >
> > > > parse(file="c:\\kjetil\\audiometria\\data\\audiometria.R", n=-1)
> > > Error in parse(file, n, text, prompt) : syntax error on line 6
> > >
> > > This seems very strange. Trying to read the file with data()
> > > gives the same error.
> > >
> > >
> > > Kjetil Halvorsen
> > > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > > Send "info", "help", or "[un]subscribe"
> > > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> > >
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272860 (secr)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Fri Dec  7 20:48:29 2001
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri, 7 Dec 2001 11:48:29 -0800 (PST)
Subject: [R] densityplots
In-Reply-To: <Pine.LNX.4.31.0112071246580.18581-100000@gannet.stats>
Message-ID: <Pine.GSO.4.10.10112071147460.3849-100000@fisher.stat.ucla.edu>

Also, the fields package has some useful image related functions.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Fri, 7 Dec 2001, Prof Brian Ripley wrote:

> On Fri, 7 Dec 2001, Bernd Jagla wrote:
> 
> > Dear all,
> >
> > I am new in R so please forgive the "dumb" question...
> >
> > I am used to work with Mathematica where it is possible to display a 2D array as a collection of shaded squares. The gray level there represents the value of the array element. It is basically a projection of a 2-dimensional histogram.
> >
> > After a lot of reading I still haven't found that kind of function.
> 
> image()
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From murdoch at stats.uwo.ca  Fri Dec  7 21:10:57 2001
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 07 Dec 2001 15:10:57 -0500
Subject: [R] Sorting a matrix?
Message-ID: <se821ug2gdahg26lhiv9ngdolv34h9cviq@4ax.com>

I'd like to sort the rows of a matrix, sorting by the values in the
1st column, breaking ties by the 2nd, etc.  I don't know in advance
how many columns there'll be.

Is there a way to force the unknown number of columns of my matrix to
be the ... arguments of order(), or is there another way to do this
(other than a loop)?

Duncan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Dec  7 21:18:31 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 7 Dec 2001 12:18:31 -0800 (PST)
Subject: [R] Sorting a matrix?
In-Reply-To: <se821ug2gdahg26lhiv9ngdolv34h9cviq@4ax.com>
Message-ID: <Pine.A41.4.33.0112071216060.80098-100000@homer06.u.washington.edu>

On Fri, 7 Dec 2001, Duncan Murdoch wrote:

> I'd like to sort the rows of a matrix, sorting by the values in the
> 1st column, breaking ties by the 2nd, etc.  I don't know in advance
> how many columns there'll be.
>
> Is there a way to force the unknown number of columns of my matrix to
> be the ... arguments of order(), or is there another way to do this
> (other than a loop)?

You should be able to do this with do.call(), which takes a function name
and a list of arguments.  Something like

do.call("order",lapply(1:NCOL(m) function(i) m[,i]))

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From crawford at stat.berkeley.edu  Fri Dec  7 23:29:53 2001
From: crawford at stat.berkeley.edu (Matthew Crawford)
Date: Fri, 07 Dec 2001 14:29:53 -0800
Subject: [R] robust()?
Message-ID: <3C1142E1.B737D599@stat.Berkeley.EDU>

Is there a function like Splus's robust()?  I want to fit a glm with a
robust binomial family,
or something like that.  

Matt
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From feldesmanm at pdx.edu  Fri Dec  7 23:56:25 2001
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Fri, 07 Dec 2001 14:56:25 -0800
Subject: [R] Help for Linear Discriminant Analysis
In-Reply-To: <013d01c17f36$8eac42a0$0f697882@upstlse.fr>
Message-ID: <5.1.0.14.2.20011207145420.00b20640@pop4.attglobal.net>

It is part of the VR package and is specifically contained in the 
"sub-package" MASS.  If you are using a recent (>= 1.3.0) version of R, it 
is on the list of recommended packages.  If you are using Windows, it is 
installed as part of the default installation.

 >library(MASS)
 >?lda



At 07:48 AM 12/7/01, Sovan Lek wrote:
>Dear colleague,
>
>I'd like to compute linear discriminant analysis, using R. In the book 
>Modern applied statistic with Splus (Venables & Ripley, p. 396),  lda 
>function is used. Could you tell me where I can find this function? At 
>what site, can I download this library ?
>
>Thank for your help.
>Best Regards
>Sovan
>
>----------------------------------------------------------------
>Prof. Sovan LEK,   E-mail: <mailto:lek at cict.fr>lek at cict.fr
>Address:
>CNRS - UMR 5576    Tel. : (33) 5 61 55 86 87
>CESAC - Bat. 4R3   Fax  : (33) 5 61 55 60 96
>Uuniv. Paul Sabatier
>118 route de Narbonne
>31062 Toulouse cedex
>France


Dr. Marc R. Feldesman
email:  feldesmanm at pdx.edu
email:  feldesman at attglobal.net
fax:    503-725-3905

"Don't know where I'm going.
Don't like where I've been.
There may be no exit.
But hell, I'm going in."  Jimmy Buffett

Powered by Superchoerus - the 700 MHz Coppermine Box

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fabian at mybytes.de  Fri Dec  7 17:44:51 2001
From: fabian at mybytes.de (Fabian Moerchen)
Date: 07 Dec 2001 17:44:51 +0100
Subject: [R] predicting arma
In-Reply-To: <1007726999.671.2.camel@pilgrimage.fragile>
References: <Pine.GSO.4.31.0112070640100.4068-100000@auk.stats> 
	<1007726999.671.2.camel@pilgrimage.fragile>
Message-ID: <1007743398.2480.1.camel@pilgrimage.fragile>

hi


how can i predict with an arma object? there doesn't seem to be a
predict method for these objects. 

> predict(x.ar13)
Error in predict(x.ar13) : no applicable method for "predict"

bye
fabian

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jeff_hamann at hamanndonald.com  Sat Dec  8 06:53:28 2001
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Fri, 7 Dec 2001 21:53:28 -0800
Subject: [R] no _?
Message-ID: <001101c17fac$a9c4e440$01000001@godzilla>

I see the uderscore "_" is not allowed in R. This make R a real drag when
trying to use with SQL packages and c code. Why is the underscore not
allowed and will it be allowed in a future release?

Jeff.

Jeff D. Hamann
Hamann, Donald and Associates
PO Box 1421
Corvallis, Oregon USA 97339-1421
Bus. 541-753-7333
Cell. 541-740-5988
jeff_hamann at hamanndonald.com
www.hamanndonald.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rolf at maths.uwa.edu.au  Sat Dec  8 09:28:00 2001
From: rolf at maths.uwa.edu.au (Rolf Turner)
Date: Sat, 8 Dec 2001 16:28:00 +0800 (WST)
Subject: [R] no _?
Message-ID: <200112080828.QAA75871@salvia.maths.uwa.edu.au>


Jeff D. Hamann writes:

> I see the uderscore "_" is not allowed in R. This make R a real drag when
> trying to use with SQL packages and c code. Why is the underscore not
> allowed and will it be allowed in a future release?

But the underscore ***is*** allowed in R!!!

E.g.

> x _ 42
> x
[1] 42

    :-)   :-)   :-)   :-)   :-)   :-)   :-)   :-)   :-)   :-)   :-)   


					cheers,

						Rolf Turner
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Sat Dec  8 12:15:17 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sat, 8 Dec 2001 06:15:17 -0500 (EST)
Subject: [R] no _?
Message-ID: <200112081115.fB8BFHn07608@cattell.psych.upenn.edu>

Presumably you want to use the underscore in variable names.
But, as you've seen, it has another meaning, which is <-.
What you _can_ use is a period (".") or, since R is case
sensitive, you can do things like VarName1, VarName2,
VarName1Length.  Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sat Dec  8 12:19:55 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Dec 2001 12:19:55 +0100
Subject: [R] no _?
In-Reply-To: <200112080828.QAA75871@salvia.maths.uwa.edu.au>
References: <200112080828.QAA75871@salvia.maths.uwa.edu.au>
Message-ID: <x2adwu2c2s.fsf@blueberry.kubism.ku.dk>

Rolf Turner <rolf at maths.uwa.edu.au> writes:

> Jeff D. Hamann writes:
> 
> > I see the uderscore "_" is not allowed in R. This make R a real drag when
> > trying to use with SQL packages and c code. Why is the underscore not
> > allowed and will it be allowed in a future release?
> 
> But the underscore ***is*** allowed in R!!!
> 
> E.g.
> 
> > x _ 42
> > x
> [1] 42
> 
>     :-)   :-)   :-)   :-)   :-)   :-)   :-)   :-)   :-)   :-)   :-)   

The underscore *may* be allowed in variable names in some future
release, but first we need to get rid of the use as assignment
operator... 

The main obstacle is S compatibility, both ways. One thing is that
scripts with underscores as assignment might break on R (they're
unreadable to human eyes anyway...), but imagine running an R script
under S-PLUS with

do_list <- function(whatever)whichever()

and creating two objects "do" and "list", one of which is overriding a
fairly important system function...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Sat Dec  8 14:57:45 2001
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 08 Dec 2001 08:57:45 -0500
Subject: [R] no _?
In-Reply-To: <001101c17fac$a9c4e440$01000001@godzilla>
Message-ID: <5.1.0.14.2.20011208085036.01d33dd0@mcmail.cis.mcmaster.ca>

Dear Jeff,

At 09:53 PM 12/7/2001 -0800, Jeff D. Hamann wrote:
>I see the uderscore "_" is not allowed in R. This make R a real drag when
>trying to use with SQL packages and c code. Why is the underscore not
>allowed and will it be allowed in a future release?

As has been pointed out, the underscore is used as a synonym for the 
assignment operator, <-, but non-standard names, including names containing 
underscores, can be used -- if this is really necessary -- by quoting them. 
For example:

         > "x_1" <- 1:5
         > eval(as.name("x_1"))
         [1] 1 2 3 4 5

If you're receiving the offending variable names from another application, 
an alternative is to edit the names, as in

         > gsub("_", ".", c("x_1", "x_2"))
         [1] "x.1" "x.2"
         >

I hope that this helps,
  John


-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Sat Dec  8 15:06:48 2001
From: bates at stat.wisc.edu (Douglas Bates)
Date: 08 Dec 2001 08:06:48 -0600
Subject: [R] Complex nonlinear model
In-Reply-To: <200112030050.NAA27118@gosset.stats.waikato.ac.nz>
References: <200112030050.NAA27118@gosset.stats.waikato.ac.nz>
Message-ID: <6r667hergn.fsf@franz.stat.wisc.edu>

I have been away from email for a week and may be coming late to a
discussion here.  The short answer is that you must have names on
your list or vector of starting estimates so that the arguments and
covariates in Y.model can be distinguished.

Try using
 simparj.st <- c(gN = gN, MnmN = MnmN, OptN = OptN, DIs = DIs,
      beta = beta, eta1 = eta1, eta2 = eta2)

Murray Jorgensen <maj at waikato.ac.nz> writes:

> I am running 1.3.1 on a Windows (NT 4.0) machine.
> 
> I am trying to fit a nonlinear model intended to predict crop yield from
> nutrient information.
> 
> I am troubled by an error message:
> 
> > library(nls)
> > simparj.fm <- nls(Y ~ Y.model(gN, MnmN, OptN, DIs,  beta, eta1, eta2,
> +       Popn, Dmax, AWC, SumEp, PotYield3, Nsupply),
> +       start = simparj.st, trace =T)
> Error in numericDeriv(form[[3]], names(ind), env) : 
>         theta should be of type character
> 
> I suspect that I am doing something stupid. My code in full is
> 
> # parameter assignments
> Nmin      <- 0.8852
> Nopt1     <- 16.78
> gN <- 0.5511
> E.nfert1 <- 0.3271
> E.nfert2 <- 0.6132
> Beta <- 0.8902
> Dls <- 0.5378
> eta1 <- 0.3791
> eta2 <- 0.6332
> PopStd <- 90468
> beta <- Beta
> DIs <- Dls
> MnmN <- Nmin
> OptN <- Nopt1
> 
> # simulate experimental data for predictors
> nsim <- 70
> Popn <- rnorm(nsim,PopStd,0.1*PopStd)
> Dmax <- rnorm(nsim,140.68,47.45)
> AWC <- rnorm(nsim,186.86,47.41)
> SumEp <- rnorm(nsim,318.54,32.53)
> PotYield3 <- rnorm(nsim,0.16180,0.01167)
> Nsoil <- rnorm(nsim,94.07,34.06)
> Bdfield <- rnorm(nsim,1.0590,0.1420)
> Bdlab <- rnorm(nsim,0.7876,0.1169)
> 
> Nfert.broad <- runif(nsim,95.3,576.5)
> Nfert.band <- runif(nsim,122,250)
> broad <- rbinom(nsim,1,0.2)
> Nfert.broad <- Nfert.broad*broad
> Nfert.band <- Nfert.band*(1 - broad)
> Nsupply<-Nsoil*Bdfield/Bdlab + Nfert.broad*E.nfert1 + Nfert.band*E.nfert2
> 
> # define model function
> 
> Y.model <- function(gN, MnmN, OptN, DIs,  beta, eta1, eta2,
>       Popn, Dmax, AWC, SumEp, PotYield3, Nsupply)
>       {
>       Ymax<- 1-ifelse(Popn<=PopStd, eta1, eta2)*log(Popn/PopStd)
>       Ymax <- Ymax*PotYield3*Popn/1000
>       Ymax <- Ymax*ifelse(Dmax<=DIs*AWC, 1, 1 - beta*(Dmax -DIs*AWC)/SumEp)
>       Nstar <- (Nsupply- MnmN*Ymax) / (OptN*Ymax - MnmN*Ymax)
>       Nstar<-pmax ( 0,Nstar)
>       Ystar<-ifelse(Nstar<1, (1 + gN*(1 - Nstar))* Nstar^(1+gN ), 1)
>       Ystar<-pmax ( 0, Ystar)
>       Y.model <- Ystar*Ymax
>       }
> 
> # generate response variable from model
> 
> Y <- Y.model(gN, MnmN, OptN, DIs,  beta, eta1, eta2,
>       Popn, Dmax, AWC, SumEp, PotYield3, Nsupply)
> Y <- Y + rnorm(nsim,0,1)
> 
> # attempt to fit starting from true parameters
> library(nls)
> simparj.st <- c(gN, MnmN, OptN, DIs,  beta, eta1, eta2)
> simparj.fm <- nls(Y ~ Y.model(gN, MnmN, OptN, DIs,  beta, eta1, eta2,
>       Popn, Dmax, AWC, SumEp, PotYield3, Nsupply),
>       start = simparj.st, trace =T)
> 
> 
> 
> 
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html 
> Department of Statistics, University of Waikato, Hamilton, New Zealand 
> Email: maj at waikato.ac.nz                            Fax +64-7 838 4155
> Phone +64-7 838 4773 home phone +64-7 856 6705  Mobile +64-21 139 5862
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Sat Dec  8 15:30:00 2001
From: bates at stat.wisc.edu (Douglas Bates)
Date: 08 Dec 2001 08:30:00 -0600
Subject: [R] trouble with R CMD INSTALL for building my own library
In-Reply-To: <3C0F8CC0.50304@keittlab.bio.sunysb.edu>
References: <FC0B9DA2600ED4118F76009027AA5DDD02B27B30@ALEX2>
	<3C0F8CC0.50304@keittlab.bio.sunysb.edu>
Message-ID: <6r1yi5eqdz.fsf@franz.stat.wisc.edu>

"Timothy H. Keitt" <tklistaddr at keittlab.bio.sunysb.edu> writes:

> Yup. that was it. I looked at the INSTALL code and it checks for a
> 'man' directory to determine whether or not its a binary
> package. Perhaps the make process could put a '.binary' file in the
> package root and the INSTALL code could check for that instead?

Sorry for coming to the discussion late - I have been away from my
email this week.  I just wanted to remind everyone of the
package.skelton function in R-1.3.1.  It works very well.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maba at ukl.uni-freiburg.de  Sat Dec  8 17:00:08 2001
From: maba at ukl.uni-freiburg.de (Manfred W. Baumstark)
Date: Sat, 08 Dec 2001 17:00:08 +0100
Subject: [R] Memory problem
References: <3C110602.9BEF3A3E@ukl.uni-freiburg.de> <3C1211EF.8AA313E6@statistik.uni-dortmund.de>
Message-ID: <3C123908.FD84845B@ukl.uni-freiburg.de>

Uwe Ligges asked me to produce a more simple example. Ok, the problem is as
follows: If I write big files memory utilization grows constantly. Here it
is a little test program, and it's output:

imv <- integer(length = 3000000) 

memory.profile()
round(memory.size()/1048576.0, 2)
for (j in 1:20) { 

  imout <- file(paste("test", j, sep=""), "wb")
  writeBin(1:2, imout, size=2, endian="big") 
  writeBin(imv, imout, size=2, endian="big") # this one makes the problem
  close(imout)
}
 memory.profile()
 round(memory.size()/1048576.0, 2)

Manfred

############ Write 20 big files
> imv <- integer(length = 3000000) 
> 
> memory.profile()
    NILSXP     SYMSXP    LISTSXP     CLOSXP     ENVSXP    PROMSXP   
LANGSXP 
         1       4080     104244       1280          4          0     
53027 
SPECIALSXP BUILTINSXP    CHARSXP     LGLSXP                          
INTSXP 
        59        483      10886       1510          0          0        
24 
   REALSXP    CPLXSXP     STRSXP     DOTSXP     ANYSXP     VECSXP   
EXPRSXP 
      6693          4       6581          0          0          8         
0 
            EXTPTRSXP 
         0          0 
> round(memory.size()/1048576.0, 2)
[1] 20
> for (j in 1:20) { 
+ 
+   imout <- file(paste("test", j, sep=""), "wb")
+   writeBin(1:2, imout, size=2, endian="big") 
+   writeBin(imv, imout, size=2, endian="big") # this one makes the problem
+   close(imout)
+ }
>  memory.profile()
    NILSXP     SYMSXP    LISTSXP     CLOSXP     ENVSXP    PROMSXP   
LANGSXP 
         1       4081     104262       1280          4          0     
53027 
SPECIALSXP BUILTINSXP    CHARSXP     LGLSXP                          
INTSXP 
        59        483      10929       1510          0          0        
26 
   REALSXP    CPLXSXP     STRSXP     DOTSXP     ANYSXP     VECSXP   
EXPRSXP 
      6693          4       6583          0          0          8         
0 
            EXTPTRSXP 
         0          0 
>  round(memory.size()/1048576.0, 2)
[1] 134.44
> 
 
############ Write 20 small files
> imv <- integer(length = 3000000) 
> 
> memory.profile()
    NILSXP     SYMSXP    LISTSXP     CLOSXP     ENVSXP    PROMSXP   
LANGSXP 
         1       4080     104244       1280          4          0     
53027 
SPECIALSXP BUILTINSXP    CHARSXP     LGLSXP                          
INTSXP 
        59        483      10886       1510          0          0        
24 
   REALSXP    CPLXSXP     STRSXP     DOTSXP     ANYSXP     VECSXP   
EXPRSXP 
      6693          4       6581          0          0          8         
0 
            EXTPTRSXP 
         0          0 
> round(memory.size()/1048576.0, 2)
[1] 20
> for (j in 1:20) { 
+ 
+   imout <- file(paste("test", j, sep=""), "wb")
+   writeBin(1:2, imout, size=2, endian="big") 
+ #  writeBin(imv, imout, size=2, endian="big") # this one makes the
problem
+   close(imout)
+ }
>  memory.profile()
    NILSXP     SYMSXP    LISTSXP     CLOSXP     ENVSXP    PROMSXP   
LANGSXP 
         1       4081     104261       1280          4          0     
53027 
SPECIALSXP BUILTINSXP    CHARSXP     LGLSXP                          
INTSXP 
        59        483      10909       1510          0          0        
26 
   REALSXP    CPLXSXP     STRSXP     DOTSXP     ANYSXP     VECSXP   
EXPRSXP 
      6693          4       6583          0          0          8         
0 
            EXTPTRSXP 
         0          0 
>  round(memory.size()/1048576.0, 2)
[1] 20
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: maba.vcf
Type: text/x-vcard
Size: 356 bytes
Desc: Card for Manfred W. Baumstark
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20011208/3307af36/maba.vcf

From ripley at stats.ox.ac.uk  Sat Dec  8 18:30:49 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 Dec 2001 17:30:49 +0000 (GMT)
Subject: [R] Memory problem
In-Reply-To: <3C123908.FD84845B@ukl.uni-freiburg.de>
Message-ID: <Pine.LNX.4.31.0112081726040.11793-100000@gannet.stats>

I know what the problem is: it will be fixed in 1.4.0.  There's a slow
memory leak in the internals of writeBin, and this is exercising it
very hard.

B


On Sat, 8 Dec 2001, Manfred W. Baumstark wrote:

> Uwe Ligges asked me to produce a more simple example. Ok, the problem is as
> follows: If I write big files memory utilization grows constantly. Here it
> is a little test program, and it's output:
>
> imv <- integer(length = 3000000)
>
> memory.profile()
> round(memory.size()/1048576.0, 2)
> for (j in 1:20) {
>
>   imout <- file(paste("test", j, sep=""), "wb")
>   writeBin(1:2, imout, size=2, endian="big")
>   writeBin(imv, imout, size=2, endian="big") # this one makes the problem
>   close(imout)
> }
>  memory.profile()
>  round(memory.size()/1048576.0, 2)
>
> Manfred
>
> ############ Write 20 big files
> > imv <- integer(length = 3000000)
> >
> > memory.profile()
>     NILSXP     SYMSXP    LISTSXP     CLOSXP     ENVSXP    PROMSXP
> LANGSXP
>          1       4080     104244       1280          4          0
> 53027
> SPECIALSXP BUILTINSXP    CHARSXP     LGLSXP
> INTSXP
>         59        483      10886       1510          0          0
> 24
>    REALSXP    CPLXSXP     STRSXP     DOTSXP     ANYSXP     VECSXP
> EXPRSXP
>       6693          4       6581          0          0          8
> 0
>             EXTPTRSXP
>          0          0
> > round(memory.size()/1048576.0, 2)
> [1] 20
> > for (j in 1:20) {
> +
> +   imout <- file(paste("test", j, sep=""), "wb")
> +   writeBin(1:2, imout, size=2, endian="big")
> +   writeBin(imv, imout, size=2, endian="big") # this one makes the problem
> +   close(imout)
> + }
> >  memory.profile()
>     NILSXP     SYMSXP    LISTSXP     CLOSXP     ENVSXP    PROMSXP
> LANGSXP
>          1       4081     104262       1280          4          0
> 53027
> SPECIALSXP BUILTINSXP    CHARSXP     LGLSXP
> INTSXP
>         59        483      10929       1510          0          0
> 26
>    REALSXP    CPLXSXP     STRSXP     DOTSXP     ANYSXP     VECSXP
> EXPRSXP
>       6693          4       6583          0          0          8
> 0
>             EXTPTRSXP
>          0          0
> >  round(memory.size()/1048576.0, 2)
> [1] 134.44
> >
>
> ############ Write 20 small files
> > imv <- integer(length = 3000000)
> >
> > memory.profile()
>     NILSXP     SYMSXP    LISTSXP     CLOSXP     ENVSXP    PROMSXP
> LANGSXP
>          1       4080     104244       1280          4          0
> 53027
> SPECIALSXP BUILTINSXP    CHARSXP     LGLSXP
> INTSXP
>         59        483      10886       1510          0          0
> 24
>    REALSXP    CPLXSXP     STRSXP     DOTSXP     ANYSXP     VECSXP
> EXPRSXP
>       6693          4       6581          0          0          8
> 0
>             EXTPTRSXP
>          0          0
> > round(memory.size()/1048576.0, 2)
> [1] 20
> > for (j in 1:20) {
> +
> +   imout <- file(paste("test", j, sep=""), "wb")
> +   writeBin(1:2, imout, size=2, endian="big")
> + #  writeBin(imv, imout, size=2, endian="big") # this one makes the
> problem
> +   close(imout)
> + }
> >  memory.profile()
>     NILSXP     SYMSXP    LISTSXP     CLOSXP     ENVSXP    PROMSXP
> LANGSXP
>          1       4081     104261       1280          4          0
> 53027
> SPECIALSXP BUILTINSXP    CHARSXP     LGLSXP
> INTSXP
>         59        483      10909       1510          0          0
> 26
>    REALSXP    CPLXSXP     STRSXP     DOTSXP     ANYSXP     VECSXP
> EXPRSXP
>       6693          4       6583          0          0          8
> 0
>             EXTPTRSXP
>          0          0
> >  round(memory.size()/1048576.0, 2)
> [1] 20
> >

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Sat Dec  8 05:41:28 2001
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sat, 8 Dec 2001 17:41:28 +1300
Subject: [R] Latex Question
In-Reply-To: <003c01c17f08$5df22220$585037d2@KoKang>; from Ko-Kang@xtra.co.nz on Fri, Dec 07, 2001 at 11:17:24PM +1300
References: <20011207035725.16162.qmail@web12205.mail.yahoo.com> <003c01c17f08$5df22220$585037d2@KoKang>
Message-ID: <20011208174128.A6085@camille.indigoindustrial.co.nz>

Two minor points; one a fact, the other a personal opionion...

On Fri, Dec 07, 2001 at 11:17:24PM +1300, Ko-Kang Kevin Wang wrote:
> The latex command you will need is \includegraphics{filename.ps}.  Normally
> I'd use a block of statements as follows:

<fact>

To use \includegraphics{} , you need to put a 

\usepackage{graphics}

or

\usepackage{graphicsx}

somewhere in the document preamble (i.e. between \documentclass{} and
\begin{document}).

</fact>

Welcome to LaTeX.  

> \begin{figure}[h!]  % Begin to insert a figure, h! means here.  You can
> append a t (top) or a b (bottom) in front of h

<opinion>
Depending on the document, \begin{figure}[h!] is not usually prefered, 
typographically, to \begin{figure}.   Play with them; [h!] gives results 
more familiar to people used to word processors - the graphic goes where 
you've told it to.  Most serious publications use the convention of putting 
figures at the top of the page, to avoid breaking up the flow of text.  
There are pretty convincing typographical reasons for this.  If you've only 
got a handful of figures (no more than one per two pages), LaTeX does a 
pretty good job of sorting out where things need to go.  

Check out the varioref package for nifty cross references to figures.
</opinion>

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Sat Dec  8 05:52:43 2001
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sat, 8 Dec 2001 17:52:43 +1300
Subject: [R] no _?
In-Reply-To: <001101c17fac$a9c4e440$01000001@godzilla>; from jeff_hamann@hamanndonald.com on Fri, Dec 07, 2001 at 09:53:28PM -0800
References: <001101c17fac$a9c4e440$01000001@godzilla>
Message-ID: <20011208175243.B6085@camille.indigoindustrial.co.nz>

On Fri, Dec 07, 2001 at 09:53:28PM -0800, Jeff D. Hamann wrote:
> I see the uderscore "_" is not allowed in R. This make R a real drag when
> trying to use with SQL packages and c code. 

A work-around I use is make.names(), which converts "illegal" variable
names to legal ones in R.

names(some.data.object)<-make.names(names(some.data.object))

if you've somehow managed to get an illegal name in there.

e.g.
> zz<-data.frame(c(1,2,3),c(4,5,6))
> zz
  c.1..2..3. c.4..5..6.
1          1          4
2          2          5
3          3          6
> names(zz)<-c("age","number_of_feet")
> 
> zz
  age number_of_feet
1   1              4
2   2              5
3   3              6
> names(zz)<-make.names(names(zz))
> zz
  age number.of.feet
1   1              4
2   2              5
3   3              6
> 

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jeff_hamann at hamanndonald.com  Sat Dec  8 19:52:57 2001
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Sat, 8 Dec 2001 10:52:57 -0800
Subject: [R] plotting values "by"
Message-ID: <001501c18019$8e629e50$01000001@godzilla>

I would like to produce a set of values, on the same chart, from an sql
table that is structured like...

species dbh ht expf
DF 1.2 8.9 10.0
DF 2.4 17.3 12.4342
DF 3.1 20.9 56.76
PP 2.3 16.9 100.0
PP 12.8 97.3 40.3
PP 8.2 63.0 98.34
.
.
.
SS blah, blah, blah...

is it possible to, using a single command in the plot command to plot the
different groups on the same plot or will I have to iterate through the data
set (sql select) and use the points() to get this done? Is it possible to do
the same to produce histograms...

Thanks,
Jeff.


Jeff D. Hamann
Hamann, Donald and Associates
PO Box 1421
Corvallis, Oregon USA 97339-1421
Bus. 541-753-7333
Cell. 541-740-5988
jeff_hamann at hamanndonald.com
www.hamanndonald.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maba at ukl.uni-freiburg.de  Sat Dec  8 19:52:32 2001
From: maba at ukl.uni-freiburg.de (Manfred W. Baumstark)
Date: Sat, 08 Dec 2001 19:52:32 +0100
Subject: [R] Building under IRIX 6.5 (report)
Message-ID: <3C126170.7FCCBB1D@ukl.uni-freiburg.de>

On my IRIX system (SGI compilers, gcc not installed) ./configure runs fine,
but there is a problem with make (output below) that can be solved by
changing one line in src/modules/lapack/Makefile. If this line is changed,
make runs without problems. 'make check' still has a problem 
(sh[14]: /usr/sbin/perl: arg list too long), but I assume this is
"cosmetic".

Manfred

----------- The patch:
msm4:/usr/local/src/R-1.3.1/src/modules/lapack% diff -u Makefile.o Makefile
--- Makefile.o  Sat Dec  8 19:23:32 2001
+++ Makefile    Sat Dec  8 19:27:26 2001
@@ -19,7 +19,7 @@
 SOURCES_BLAS = blas2.f  cmplxblas.f
 
 DEPENDS = $(SOURCES_C:.c=.d)
-OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo) \
+OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo) 
   # $(SOURCES_BLAS:.f=.lo)
 HEADERS = Lapack.h


------------ make stops with the following error:
"cmplx.f", line 19283: warning(2290): actual argument is incompatible with
          dummy argument
              CALL ZLARFB( SIDE, TRANS, 'Forward', 'Columnwise', MI, NI,  
                                                   ^

don't know how to make # (bu42).
*** Error code 1 (bu21)
*** Error code 1 (bu21)
*** Error code 1 (bu21)
*** Error code 1 (bu21)


------------ configure:
R is now configured for mips-sgi-irix6.5

  Source directory:          .
  Installation directory:    /usr/local
  C compiler:                cc  -OPT:IEEE_NaN_inf=ON -g
  C++ compiler:              CC  -OPT:IEEE_NaN_inf=ON -g
  FORTRAN compiler:          f77  -OPT:IEEE_NaN_inf=ON -g

  X11 support:               yes
  Gnome support:             no
  Tcl/Tk support:            no

  R profiling support:       yes
  R as a shared library:     no

configure: warning: you cannot build DVI versions of the R manuals
configure: warning: you cannot build info versions of the R manuals
configure: warning: you cannot build PDF versions of the R manuals

------------- make check problem:
msm4:/usr/local/src/R-1.3.1% make check
collecting examples for package `base' ...
 >>> Building/Updating help pages for package `base'
     Formats: text example 
sh[14]: /usr/sbin/perl: arg list too long
*** Error code 1 (bu21)
*** Error code 1 (bu21)
*** Error code 1 (bu21)
*** Error code 1 (bu21)
*** Error code 1 (bu21)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: maba.vcf
Type: text/x-vcard
Size: 356 bytes
Desc: Card for Manfred W. Baumstark
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20011208/46c037f0/maba.vcf

From ripley at stats.ox.ac.uk  Sat Dec  8 20:59:12 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 Dec 2001 19:59:12 +0000 (GMT)
Subject: [R] Building under IRIX 6.5 (report)
In-Reply-To: <3C126170.7FCCBB1D@ukl.uni-freiburg.de>
Message-ID: <Pine.LNX.4.31.0112081946420.16320-100000@gannet.stats>

On Sat, 8 Dec 2001, Manfred W. Baumstark wrote:

> On my IRIX system (SGI compilers, gcc not installed) ./configure runs fine,
> but there is a problem with make (output below) that can be solved by
> changing one line in src/modules/lapack/Makefile. If this line is changed,
> make runs without problems. 'make check' still has a problem
> (sh[14]: /usr/sbin/perl: arg list too long), but I assume this is
> "cosmetic".
>
> Manfred
>
> ----------- The patch:
> msm4:/usr/local/src/R-1.3.1/src/modules/lapack% diff -u Makefile.o Makefile
> --- Makefile.o  Sat Dec  8 19:23:32 2001
> +++ Makefile    Sat Dec  8 19:27:26 2001
> @@ -19,7 +19,7 @@
>  SOURCES_BLAS = blas2.f  cmplxblas.f
>
>  DEPENDS = $(SOURCES_C:.c=.d)
> -OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo) \
> +OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo)
>    # $(SOURCES_BLAS:.f=.lo)
>  HEADERS = Lapack.h

Well, that Makefile is not part of the sources!  Makefile.in in the
near-release 1.4.0 ha

OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo) \
  @USE_EXTERNAL_BLAS_FALSE@ $(SOURCES_BLAS:.f=.lo)

and on my system Makefile has

OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo) \
  # $(SOURCES_BLAS:.f=.lo)

as does 1.3.1.  What make is this?  As R-admin.texi says


To compile @R{}, you will most likely find it easiest to use GNU
@command{make}.  On Solaris 2.6/7/8 in particular, you need a version of
GNU @command{make} different from 3.77; 3.79 works fine, as does the Sun
@command{make}.

I suspect your make is broken.

> ------------ make stops with the following error:
> "cmplx.f", line 19283: warning(2290): actual argument is incompatible with
>           dummy argument
>               CALL ZLARFB( SIDE, TRANS, 'Forward', 'Columnwise', MI, NI,
>               CALL ZLARFB( SIDE, TRANS, 'Forward', 'Columnwise', MI, NI,

That's standard LAPACK 3 code, so the bug report needs to go to LAPACK.
I think your compiler is incorrect, but 'F', 'C' might work.

BDR

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maba at ukl.uni-freiburg.de  Sat Dec  8 23:02:31 2001
From: maba at ukl.uni-freiburg.de (Manfred W. Baumstark)
Date: Sat, 08 Dec 2001 23:02:31 +0100
Subject: [R] Building under IRIX 6.5 (report)
References: <Pine.LNX.4.31.0112081946420.16320-100000@gannet.stats>
Message-ID: <3C128DF7.D3E4E5DE@ukl.uni-freiburg.de>



Prof Brian Ripley wrote:
...
> 
> Well, that Makefile is not part of the sources!  Makefile.in in the
> near-release 1.4.0 ha
> 
> OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo) \
>   @USE_EXTERNAL_BLAS_FALSE@ $(SOURCES_BLAS:.f=.lo)
> 
> and on my system Makefile has
> 
> OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo) \
>   # $(SOURCES_BLAS:.f=.lo)
>

The same on my system. 

> as does 1.3.1.  What make is this?  As R-admin.texi says
> 
> To compile @R{}, you will most likely find it easiest to use GNU
> @command{make}.  On Solaris 2.6/7/8 in particular, you need a version of
> GNU @command{make} different from 3.77; 3.79 works fine, as does the Sun
> @command{make}.
> 
> I suspect your make is broken.

I agree. This is the standard IRIX 6.5.11m make. Ok, next time I use gmake.
For some reason the SGI make does not interpret the # after the escaped
newline character as start of a comment. That's why it stops with
'don't know how to make # (bu42).'

> 
> > ------------ make stops with the following error:
> > "cmplx.f", line 19283: warning(2290): actual argument is incompatible with
> >           dummy argument
> >               CALL ZLARFB( SIDE, TRANS, 'Forward', 'Columnwise', MI, NI,
> >               CALL ZLARFB( SIDE, TRANS, 'Forward', 'Columnwise', MI, NI,
> 
> That's standard LAPACK 3 code, so the bug report needs to go to LAPACK.
> I think your compiler is incorrect, but 'F', 'C' might work.

I did not complain about this warning, there are lots of this kind... I
included this lines only to document at which point the error occurs.

Manfred
-------------- next part --------------
A non-text attachment was scrubbed...
Name: maba.vcf
Type: text/x-vcard
Size: 356 bytes
Desc: Card for Manfred W. Baumstark
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20011208/a8cb3652/maba.vcf

From bates at stat.wisc.edu  Sat Dec  8 23:21:02 2001
From: bates at stat.wisc.edu (Douglas Bates)
Date: 08 Dec 2001 16:21:02 -0600
Subject: [R] how to obtain EM-estimates of cov(b) and var(e) from lme
In-Reply-To: <3C0EA1BD.B5B328F2@whsun1.wh.whoi.edu>
References: <3C0EA1BD.B5B328F2@whsun1.wh.whoi.edu>
Message-ID: <6ru1v11hgx.fsf@franz.stat.wisc.edu>

Han Lai <hlai at whsun1.wh.whoi.edu> writes:

> I have a simple random-coefficients model for m subjects:
> 
>     y = b0 + b1 x + r0 + r1  x + e
> 
> where b0 and b1 are fixed parameters, r0 and r1 are random,
> e ~ N(0,s2 I) and R' = [r0, r1] ~ N(0,T).
> 
> I try to obtain the EM-estimates of s2 and the elements of T by
> 
>     lme(y~x,data=mydata,random= list(group=~x),
>           control=lmeControl(maxIter = 0, niterEM=100,msVerbose = TRUE))
> 
> Does this statement do the job?

The expression "EM-estimates of cov(b) and var(e)" doesn't make sense.
The EM algorithm is one iterative technique to determine the maximum
likelihood (ML) or restricted maximum likelihood (REML) estimates in a
mixed-effects model.  The estimates are the ML or the REML estimates
regardless of whether they were determined by EM iterations or by
other methods.

The EM algorithm tends to be robust to starting values but converges
very slowly near the optimimum.  Convergence is so slow that it is
difficult to determine if the EM algorithm has converged which is why,
in lme, we use EM iterations followed by a general optimization
procedure.  We always check for convergence in the general
optimization procedure.  Setting maxIter = 0 may result in convergence
failure, in which case the fitted model object is not constructed and
you won't be able to apply methods to it.

If for some reason you want to check that the EM iterations converge
you could use what you have above but remove maxIter = 0.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jeff_hamann at hamanndonald.com  Sat Dec  8 23:24:14 2001
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Sat, 8 Dec 2001 14:24:14 -0800
Subject: [R] no_problem_with_underscores
Message-ID: <003d01c18037$11abe880$01000001@godzilla>

I see. I wasn't trying to become flame bait, and the eval( as.name(
"my_value_from_the_sql_select" ) ) works just fine. Thanks for the insight
since using "." in sql field definitions isn't an option.

Jeff.

Jeff D. Hamann
Hamann, Donald and Associates
PO Box 1421
Corvallis, Oregon USA 97339-1421
Bus. 541-753-7333
Cell. 541-740-5988
jeff_hamann at hamanndonald.com
www.hamanndonald.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jefferis at stanford.edu  Sat Dec  8 23:31:37 2001
From: jefferis at stanford.edu (Greg Jefferis)
Date: Sat, 08 Dec 2001 14:31:37 -0800
Subject: [R] Building under IRIX 6.5 (report)
In-Reply-To: <Pine.LNX.4.31.0112081946420.16320-100000@gannet.stats>
Message-ID: <B837D4C8.3916%jefferis@stanford.edu>

There was a short thread on building 1.3.1 under Irix 6.5 a month or two
back.  Laurent Gautier provided the following advice:

> I had (and still have) to deal with SGIs and came across the similar
> error message. I remember going through by setting MAKE=gmake in the
> config.site file and by replacing the 'make ; make test; make install' on
> the command line by 'gmake; gmake test; gmake install'
> (rem: If I remember well, on a SGI the test bit do not go too good... this
> is (was ?) a reported bug).

which works (though gmake test still fails as he notes).  Ciao,

Greg.


On 12/8/01 11:59, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

> On Sat, 8 Dec 2001, Manfred W. Baumstark wrote:
> 
>> On my IRIX system (SGI compilers, gcc not installed) ./configure runs fine,
>> but there is a problem with make (output below) that can be solved by
>> changing one line in src/modules/lapack/Makefile. If this line is changed,
>> make runs without problems. 'make check' still has a problem
>> (sh[14]: /usr/sbin/perl: arg list too long), but I assume this is
>> "cosmetic".
>> 
>> Manfred
>> 
>> ----------- The patch:
>> msm4:/usr/local/src/R-1.3.1/src/modules/lapack% diff -u Makefile.o Makefile
>> --- Makefile.o  Sat Dec  8 19:23:32 2001
>> +++ Makefile    Sat Dec  8 19:27:26 2001
>> @@ -19,7 +19,7 @@
>>  SOURCES_BLAS = blas2.f  cmplxblas.f
>> 
>>  DEPENDS = $(SOURCES_C:.c=.d)
>> -OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo) \
>> +OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo)
>>    # $(SOURCES_BLAS:.f=.lo)
>>  HEADERS = Lapack.h
> 
> Well, that Makefile is not part of the sources!  Makefile.in in the
> near-release 1.4.0 ha
> 
> OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo) \
> @USE_EXTERNAL_BLAS_FALSE@ $(SOURCES_BLAS:.f=.lo)
> 
> and on my system Makefile has
> 
> OBJECTS = $(SOURCES_C:.c=.lo) $(SOURCES_F:.f=.lo) \
> # $(SOURCES_BLAS:.f=.lo)
> 
> as does 1.3.1.  What make is this?  As R-admin.texi says
> 
> 
> To compile @R{}, you will most likely find it easiest to use GNU
> @command{make}.  On Solaris 2.6/7/8 in particular, you need a version of
> GNU @command{make} different from 3.77; 3.79 works fine, as does the Sun
> @command{make}.
> 
> I suspect your make is broken.
> 
>> ------------ make stops with the following error:
>> "cmplx.f", line 19283: warning(2290): actual argument is incompatible with
>>           dummy argument
>>               CALL ZLARFB( SIDE, TRANS, 'Forward', 'Columnwise', MI, NI,
>>               CALL ZLARFB( SIDE, TRANS, 'Forward', 'Columnwise', MI, NI,
> 
> That's standard LAPACK 3 code, so the bug report needs to go to LAPACK.
> I think your compiler is incorrect, but 'F', 'C' might work.
> 
> BDR

__________________________________________________________________________
Greg Jefferis,                          Lab Address: Liqun Luo, Herrin 144
Neurosciences PhD Programme &                e-mail: jefferis at stanford.edu
Dept Biological Sciences,                       Lab: (650) 725 5809
Gilbert Biology Building,                       Fax: (650) 723 0589
371 Serra Mall,
Stanford, CA 94305-5020.                       Home: (650) 497 1135

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kademan at phz.com  Sun Dec  9 16:28:30 2001
From: kademan at phz.com (Ed Kademan)
Date: 09 Dec 2001 10:28:30 -0500
Subject: [R] Scheme in R
In-Reply-To: <x27ks0rni8.fsf@blueberry.kubism.ku.dk>
Message-ID: <ulgadwswgyp.fsf@phz.com>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes in reply to my
question about whether R can be made to behave more like Scheme:
> 
> Well, ... where do I start? The R (and to some extent also S)
> internals are still very Lisp/Scheme like. The parser/evaluator hasn't
> changed that much since the early versions of R. Perhaps the most
> notable change is that a list object is not a dotted-pair list as in
> Lisp anymore but a generic vector. (The pairlist object type still
> exists, but is hardly ever used.) If you try picking apart an
> expression using [[...]] you will see that almost everything maps to a
> Lisp-like syntax, e.g.
> 
>  quote(x <- 2 + 3)
> 
> is essentially (<- x (+ 2 3)). Some slightly peculiar cases involve
> for loops and expressions with non-local returns like break, and
> return(). The evaluation model is somewhat non-Scheme because of the
> lazy evaluation and substitute() aspects.
> 

I didn't expect there to be a simple answer to this question and I am
sure that with lazy evaluation and all the tools available for
computing on the language one can programmatically analyze and
transform R code in at least roughly the same sorts of ways as with
Scheme or Lisp.  (The article? in Rnews by Thomas Lumley about
developing an R macro processor is a good example.)  But I have been
trying to automate the conversion of a large file of C code lately and
that task has made me appreciate the beauty of an utterly simple and
transparent syntax based on s-expressions.

By the way there is a very interesting ongoing discussion about this
general topic and related ones in the lightweight languages workshop
and mailing list?.  That is, there is nothing there about R
specifically but apparently Perl and Python are facing major changes
and some discussants have suggested that it would be a good idea if
those languages moved closer to Scheme internally.

Thank you for your response.

1. http://cran.r-project.org/doc/Rnews/Rnews_2001-3.pdf
2. http://ll1.mit.edu

-- 
Ed Kademan              508.651.3700
PHZ Capital Partners    508.653.1745 (fax)
321 Commonwealth Road   <kademan at phz.com>
Wayland, MA 01778
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From aperrin at email.unc.edu  Sun Dec  9 17:21:10 2001
From: aperrin at email.unc.edu (Andrew Perrin)
Date: Sun, 9 Dec 2001 11:21:10 -0500 (EST)
Subject: [R] plot.design()
Message-ID: <Pine.A41.4.21L1.0112091115551.27460-100000@login4.isis.unc.edu>

Greetings-

I'm working through Pinheiro and Bates' _Mixed Effects Models in S and
S-Plus_ using R (1.3.1 for linux). On page 13 (okay, so I haven't got that
far :)) is:

plot.design( ergoStool)

which returns on my system:

> plot.design(ergoStool)
Error: couldn't find function "plot.design"

any ideas?

Thanks.

---------------------------------------------------------
   Andrew J. Perrin - Assistant Professor of Sociology
        University of North Carolina, Chapel Hill
269 Hamilton Hall CB#3210, Chapel Hill, NC 27599-3210 USA
   andrew_perrin at unc.edu - http://www.unc.edu/~aperrin

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Sun Dec  9 17:35:53 2001
From: bates at stat.wisc.edu (Douglas Bates)
Date: 09 Dec 2001 10:35:53 -0600
Subject: [R] plot.design()
In-Reply-To: <Pine.A41.4.21L1.0112091115551.27460-100000@login4.isis.unc.edu>
References: <Pine.A41.4.21L1.0112091115551.27460-100000@login4.isis.unc.edu>
Message-ID: <6radwscpw6.fsf@franz.stat.wisc.edu>

Andrew Perrin <aperrin at email.unc.edu> writes:

> I'm working through Pinheiro and Bates' _Mixed Effects Models in S and
> S-Plus_ using R (1.3.1 for linux). On page 13 (okay, so I haven't got that
> far :)) is:
> 
> plot.design( ergoStool)
> 
> which returns on my system:
> 
> > plot.design(ergoStool)
> Error: couldn't find function "plot.design"
> 
> any ideas?

plot.design is not currently available in R.

By the way, recent versions of the nlme package for R contain a
directory scripts with R scripts for each chapter in the book.  You
must have the lattice and grid packages from the src/contrib/Devel
section of CRAN installed for the graphics.

nlme_3.1-19 also has a directory mlbook with scripts for some of the
examples in 

  Snijders, Tom and Bosker, Roel (1999), Multilevel Analysis: An
    Introduction to Basic and Advanced Multilevel Modeling, Sage.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jeff_hamann at hamanndonald.com  Sun Dec  9 18:02:33 2001
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Sun, 9 Dec 2001 09:02:33 -0800
Subject: [R] trouble with plotting
Message-ID: <005501c180d3$4be6db80$01000001@godzilla>

I'm trying to use the lattice package (and have run into the message before)
where I will get the following when trying to plot....

Error in clearpage() : Error: X11 cannot allocate additional graphics
colors.
Consider using X11 with colortype="pseudo.cube" or "gray".

What do I need to do to get rid of this so that I can use the graphics
libraries to their fullest potential. Currently, I can't get lattice() to
work.

Thanks,
Jeff.



Jeff D. Hamann
Hamann, Donald and Associates
PO Box 1421
Corvallis, Oregon USA 97339-1421
Bus. 541-753-7333
Cell. 541-740-5988
jeff_hamann at hamanndonald.com
www.hamanndonald.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nikom at kku.ac.th  Sun Dec  9 18:29:12 2001
From: nikom at kku.ac.th (Ass.Prof. Nikom Thanomsieng)
Date: Mon, 10 Dec 2001 00:29:12 +0700
Subject: [R] Help for Power analysis
Message-ID: <3C139F67.CDFC1D30@kku.ac.th>

Dear colleague,
   I not sure this R code  is correctly ?  I would to show
the number of Sample Size at  Sample Size Axis that line
draw from Power Axis (80%) from R code.
   How I show this and select the most appropriate of
this power (.79955687 - 80983575).

Thank for your help and answer.

Best Regards,
Nikom Thanomsieng,
Email: nikom at kku.ac.th

....

#Power analysis: Sample size for Chi-Square 2x2, RxC: R software
#Concept from SAS program to calculate power of ANOVA F-test
#http://www2.tltc.ttu.edu/Westfall/images/5347/power_analysis_of_anova_f_test.htm

# and Cohen,J (1977). Statistical Power Analysis for Behavioral
Sciences.
#New York: Academic Press.
#Asst. Prof. Nikom Thanomsieng. 29/09/2000
#Department of Biostatistics & Demography. Faculty of Public Health.
#Khon Kaen University. Thailand.
#Email: nikom at kku.ac.th

#Modify data value of the first two line
x1 <- c(6,9)
x2 <- c(6,6)
nc <-cbind(x1)
nr  <-rbind(x2)
data1 <- rbind(x1,x2)
chi2<- chisq.test(data1,correct=F)$statistic
Ntotal<-sum(data1)
df<- ncol(nc-1)*nrow(nr-1)
ifelse(df==1,w<- sqrt(chi2/Ntotal), w<-sqrt(chi2/(chi2+Ntotal)))
Ntotal1<-900  #change this if power not enough
alpha  <-0.05  #change this for One tailed =0.05
ncp<-0
chicrit<-NULL
power<-NULL
n<-NULL
samplesize<-NULL
for  (i in 1:Ntotal1){
       ncp[i] <- w^2 * i
       chicrit<-qchisq(1-alpha,df)
power[i] <- 1-(pchisq(chicrit , df, ncp[i]))
n[i]<-i
samplesize<-cbind(n, ncp,power) }
samplesize
plot(n,power,type="l",col="red", lwd=1,
panel.first = grid(10,10),
main="Power as a function of Sample Size",
xlab="Sample Size",
ylab="Power" )
segments(785, .8, 785,   0, col ="pink")
segments(785, .8,    0, 0.8, col ="pink")
mtext("Chi-Square", side = 3, line = 0.35,
    outer = FALSE, at = mean(par("usr")[1:2]), cex = 1, font = 4)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Dec  9 19:16:01 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 9 Dec 2001 18:16:01 +0000 (GMT)
Subject: [R] trouble with plotting
In-Reply-To: <005501c180d3$4be6db80$01000001@godzilla>
Message-ID: <Pine.LNX.4.31.0112091811430.8495-100000@gannet.stats>

On Sun, 9 Dec 2001, Jeff D. Hamann wrote:

> I'm trying to use the lattice package (and have run into the message before)
> where I will get the following when trying to plot....
>
> Error in clearpage() : Error: X11 cannot allocate additional graphics
> colors.
> Consider using X11 with colortype="pseudo.cube" or "gray".
>
> What do I need to do to get rid of this so that I can use the graphics
> libraries to their fullest potential. Currently, I can't get lattice() to
> work.

EITHER

1) Buy a display that uses 24-bit colour, or set your Xserver to make use
of one if you have it.

OR

2) Shutdown all R graphics devices, then launch

X11(colortype="pseudo.cube")

and accept colour approximation to a 6x6x6 cube.
I don't find this a problem with lattice on an 8-bit display, bu ti also
rarely need it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sh340 at cam.ac.uk  Sun Dec  9 19:08:11 2001
From: sh340 at cam.ac.uk (Stephane Hess)
Date: Sun, 9 Dec 2001 19:08:11 +0100
Subject: [R] change layout of legend
Message-ID: <000801c180dc$77612460$7df86f83@quns.cam.ac.uk>

Is it possible to change the layout of a legend in the plot function for a plot that shows 4 variables, so that the legend shows the variables in a row with 4 elements instead of a column, or to have two columns and two rows in the legend. Also I can't seem to be able to change the size of the font used inside the legend.
Any suggestions?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011209/90bfce88/attachment.html

From maba at ukl.uni-freiburg.de  Sun Dec  9 20:03:24 2001
From: maba at ukl.uni-freiburg.de (Manfred W. Baumstark)
Date: Sun, 09 Dec 2001 20:03:24 +0100
Subject: [R] Building under IRIX 6.5 (report)
References: <Pine.LNX.4.31.0112081946420.16320-100000@gannet.stats>
				<3C128DF7.D3E4E5DE@ukl.uni-freiburg.de> <15379.9891.321472.688726@mithrandir.hornik.net>
Message-ID: <3C13B57C.2782AA04@ukl.uni-freiburg.de>

...
> Do you have means to find out whether this is a known bug in SGI make?
> 

Yes, I will do this.

> R is trying not to depend on the GNU tools if possible ...

This was exactly my motivation to post. I was aware of the tread
giving several advices how to build R under IRIX. Anyway I have shown were
the problem is, and gave a workaround how you can build R on an SGI without
gnu tools. It worked for me on my own O2 and on an Origin in the computing
center were I`m not root (but can use gigabytes of RAM :-)). 

I did also look more deeply into the failure of 'make check':

If I run the test individually in directory tests/  
'make test-Specific' and most others I tried are ok,
'make test-Examples' gives the error: 
sh[14]: /usr/sbin/perl: arg list too long
*** Error code 1 (bu21)

Manfred
-------------- next part --------------
A non-text attachment was scrubbed...
Name: maba.vcf
Type: text/x-vcard
Size: 356 bytes
Desc: Card for Manfred W. Baumstark
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20011209/cdd7a041/maba.vcf

From ligges at statistik.uni-dortmund.de  Sun Dec  9 21:02:12 2001
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 09 Dec 2001 21:02:12 +0100
Subject: [R] change layout of legend
References: <000801c180dc$77612460$7df86f83@quns.cam.ac.uk>
Message-ID: <3C13C344.D738ECE0@statistik.uni-dortmund.de>

Stephane Hess wrote:
> 
>    Part 1.1    Type: Plain Text (text/plain)
>            Encoding: quoted-printable


[Manually copied:]

> Is it possible to change the layout of a legend in the 
> plot function for a plot that shows 4 variables, so that 
> the legend shows the variables in a row with 4 elements 
> instead of a column, or to have two columns and two rows 
> in the legend. Also I can't seem to be able to change the 
> size of the font used inside the legend. 
> Any suggestions?

1. Suggestion: Please configure your mailtool.

2. Suggestion: Read the docs for ?legend.


You'll need the following two arguments:

- ncol the number of columns in which to set the legend items 
  (default is 1, a vertical legend). 

- cex character expansion factor relative to current par("cex"). 

Example:
 plot(1:10)
 legend(5,5, pch=1:4, legend=LETTERS[1:4], ncol=2, cex=2)


Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sun Dec  9 23:51:54 2001
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 09 Dec 2001 23:51:54 +0100
Subject: [R] Help for Power analysis
References: <3C139F67.CDFC1D30@kku.ac.th>
Message-ID: <3C13EB0A.8C73F57@statistik.uni-dortmund.de>

"Ass.Prof. Nikom Thanomsieng" wrote:
> 
> Dear colleague,
>    I not sure this R code  is correctly ? 

Given the code you wrote is correct (didn't checked it, but looks OK in
the hurry):

> I would to show the number of Sample Size at  Sample Size Axis that 
> line draw from Power Axis (80%) from R code.
>    How I show this and select the most appropriate of
> this power (.79955687 - 80983575).

What does this (above) line mean?

I changed your code a little bit (loop and several lines are not
neccessary).
I put it into a function and added the lines to automatically draw the
lines it seems you want to be drawn (see below). Hope this helps...

> Thank for your help and answer.
> 
> Best Regards,
> Nikom Thanomsieng,
> Email: nikom at kku.ac.th
> 
> ....
> 
> #Power analysis: Sample size for Chi-Square 2x2, RxC: R software
> #Concept from SAS program to calculate power of ANOVA F-test
> #http://www2.tltc.ttu.edu/Westfall/images/5347/power_analysis_of_anova_f_test.htm
> 
> # and Cohen,J (1977). Statistical Power Analysis for Behavioral
> Sciences.
> #New York: Academic Press.
> #Asst. Prof. Nikom Thanomsieng. 29/09/2000
> #Department of Biostatistics & Demography. Faculty of Public Health.
> #Khon Kaen University. Thailand.
> #Email: nikom at kku.ac.th
> 
> #Modify data value of the first two line
> x1 <- c(6,9)
> x2 <- c(6,6)
> nc <-cbind(x1)
> nr  <-rbind(x2)
> data1 <- rbind(x1,x2)
> chi2<- chisq.test(data1,correct=F)$statistic
> Ntotal<-sum(data1)
> df<- ncol(nc-1)*nrow(nr-1)
> ifelse(df==1,w<- sqrt(chi2/Ntotal), w<-sqrt(chi2/(chi2+Ntotal)))
> Ntotal1<-900  #change this if power not enough
> alpha  <-0.05  #change this for One tailed =0.05
> ncp<-0
> chicrit<-NULL
> power<-NULL
> n<-NULL
> samplesize<-NULL
> for  (i in 1:Ntotal1){
>        ncp[i] <- w^2 * i
>        chicrit<-qchisq(1-alpha,df)
> power[i] <- 1-(pchisq(chicrit , df, ncp[i]))
> n[i]<-i
> samplesize<-cbind(n, ncp,power) }
> samplesize
> plot(n,power,type="l",col="red", lwd=1,
> panel.first = grid(10,10),
> main="Power as a function of Sample Size",
> xlab="Sample Size",
> ylab="Power" )
> segments(785, .8, 785,   0, col ="pink")
> segments(785, .8,    0, 0.8, col ="pink")
> mtext("Chi-Square", side = 3, line = 0.35,
>     outer = FALSE, at = mean(par("usr")[1:2]), cex = 1, font = 4)


power.analysis <- function(x1, x2, my.power = 0.8, 
    Ntotal1 = 900, alpha = 0.05){
  nc <- cbind(x1)
  nr <- rbind(x2)
  data1 <- rbind(x1, x2)
  chi2 <- chisq.test(data1, correct=FALSE)$statistic
  Ntotal <- sum(data1)
  df <- ncol(nc-1) * nrow(nr-1)
  w <- ifelse(df == 1, sqrt(chi2 / Ntotal), sqrt(chi2 / (chi2+Ntotal)))
  chicrit <- qchisq(1-alpha, df)
  n <- 1:Ntotal1
  ncp <- w^2 * n
  power <- 1 - (pchisq(chicrit , df, ncp))
  plot(n, power, type = "l", col = "red", lwd = 1, panel.first =
grid(10,10), 
    main = "Power as a function of Sample Size", xlab = "Sample Size", 
    ylab = "Power")
  min.samp <- which(power >= my.power)[1]
  segments(min.samp, my.power, min.samp,   0, col = "pink")
  segments(min.samp, my.power,   0, my.power, col = "pink")
  mtext("Chi-Square", side = 3, line = 0.35,
    outer = FALSE, at = mean(par("usr")[1:2]), cex = 1, font = 4)
  samplesize <- cbind(n, ncp, power)
  return(samplesize)
}

power.analysis(c(9, 6), c(6, 6))


Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mj.manning at niwa.cri.nz  Mon Dec 10 01:15:43 2001
From: mj.manning at niwa.cri.nz (Michael J. Manning)
Date: Mon, 10 Dec 2001 13:15:43 +1300
Subject: [R] Postscript resolution
Message-ID: <3C14B57F.26801.11C4DD7@localhost>

Hi all

I have some plots that I wish to write out to postcript files.  I open 
the postscript device as suggested [postscript(file="foo.eps",...)], run 
my plotting commands, and close the device as suggested [dev.off()].  
However, when I open the eps files in a postscript viewer such as the 
gimp, the resolution of the postscript images is *really* bad, very 
"blocky" and "chunky", without the crisp lines and text that I 
expected.  I seem to remember that specifying the resolution of the 
image to be written to the eps file somewhere gets around this.  

Suggestions?

Am running R 1.3.0 on a Mandrake 8.0 system.

MJM

Michael J. Manning
Stock Monitoring and Data Services
National Institute of Water and Atmospheric Research Ltd (NIWA)
PO Box 14901, Kilbirnie
Wellington, New Zealand
Tel. 64 4 386 0300
Fax. 64 4 386 0574
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Dec 10 01:31:19 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Dec 2001 01:31:19 +0100
Subject: [R] Postscript resolution
In-Reply-To: <3C14B57F.26801.11C4DD7@localhost>
References: <3C14B57F.26801.11C4DD7@localhost>
Message-ID: <x27krvlxuw.fsf@blueberry.kubism.ku.dk>

"Michael J. Manning" <mj.manning at niwa.cri.nz> writes:

> Hi all
> 
> I have some plots that I wish to write out to postcript files.  I open 
> the postscript device as suggested [postscript(file="foo.eps",...)], run 
> my plotting commands, and close the device as suggested [dev.off()].  
> However, when I open the eps files in a postscript viewer such as the 
> gimp, the resolution of the postscript images is *really* bad, very 
> "blocky" and "chunky", without the crisp lines and text that I 
> expected.  I seem to remember that specifying the resolution of the 
> image to be written to the eps file somewhere gets around this.  
> 
> Suggestions?
> 
> Am running R 1.3.0 on a Mandrake 8.0 system.

Try another viewer, e.g. gv. I don't think R is involved in this.
Postscript and EPS should be smoothly scalable, but the viewer might
create blockiness. My version of the gimp sets 100dpi when loading
postscript files, e.g.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tarantoga at elbacsb.com.pl  Mon Dec 10 09:28:36 2001
From: tarantoga at elbacsb.com.pl (Wojciech Czaplinski)
Date: Mon, 10 Dec 2001 09:28:36 +0100
Subject: [R] newbie question - R programs in Windows
Message-ID: <001201c18154$a9cc50a0$5402070a@elbacsb.com.pl>

Hello All,
I've browsed through 'An introduction to R' and it seemed, I didn't find the answers to following questions:
1) does R provide widgets and other stuff to provide nice windows-native-like applications look and feel?
2) if not, how to do that?

greetings - Wojtek

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec 10 09:47:28 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Dec 2001 08:47:28 +0000 (GMT)
Subject: [R] newbie question - R programs in Windows
In-Reply-To: <001201c18154$a9cc50a0$5402070a@elbacsb.com.pl>
Message-ID: <Pine.LNX.4.31.0112100843240.9246-100000@gannet.stats>

On Mon, 10 Dec 2001, Wojciech Czaplinski wrote:

> Hello All,
> I've browsed through 'An introduction to R' and it seemed, I didn't find the answers to following questions:
> 1) does R provide widgets and other stuff to provide nice windows-native-like applications look and feel?

Yes.  Hardly a question for an introduction to R, though, since I assume
you are talking about Windows (R).

> 2) if not, how to do that?

(or even if yes?)

Look at the package windlgs in the Windows source packages distribution,
and (rather less native but easier to program) the package tcltk.

Note that quite a few things (menus, simple dialogs) are already available
on Windows only.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Dec 10 09:01:17 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 10 Dec 2001 09:01:17 +0100 (CET)
Subject: [R] rbind and data.frame [simplified]
In-Reply-To: <OF29BDE25C.ED1A266D-ON85256B1B.006938FD@cbis.com>
Message-ID: <Pine.LNX.4.33.0112100806320.1692-100000@tal.stat.umu.se>

Thanks for the interest in my timing problem. I have scaled off all 
calculations in order to purify it, and it is obvious that size 
matters a lot. Also that 'matrices are faster than data frames'.

I give you the full listing here, but it is 
really the last few lines that are interesting (= slow):

The test function koll ('koll' ~ 'check', Swedish):
--------------------------------------------------------------------
koll <- function(dat, com.dat, com.ins, no.of.outrows = 1000){
  ## 'dat' is a data frame with variables:
  ## bdate = birth date
  ## enter = left truncation time
  ## exit  = right censoring/event time
  ## event = event indicator (0 if no event).
  ## other covariates.

  ## com.dat is a data frame with columns communal covariates
  ## com.ins is a description of com.dat: (Is a vector for now!)
  ## start year, period (length == 2)

  ## NOTE: any names(com.dat) must be != any names(dat) !!!

  nn <- nrow(dat)
  n.years <- nrow(com.dat)
  n.com <- ncol(com.dat) ## No. of communal covariates.
##  if (nrow(com.ins) != n.com) stop("Error in com.ins: wrong no of rows")

  iv.length <- com.ins[2]
  cuts <- com.ins[1] + c(0, (1:n.years) * iv.length)
  beg.per <- cuts[1]
  n.yearsp1 <- n.years + 1
  end.per <- cuts[n.years + 1]

  get.iv <- function(dates)
    cbind(pmin(pmax(1, ceiling((dates[, 1] - beg.per) / iv.length)),
               n.years),
          pmin(pmax(1, ceiling((dates[, 2] - beg.per) / iv.length)),
               n.years))

  
  ## First, find the size of the new data frame (nn.out):
  nn.out <- 0

  ind.date <- cbind(dat$bdate + dat$enter, dat$bdate + dat$exit)
  cases <- ( (ind.date[, 1] < end.per) && (ind.date[, 2] > beg.per) )
  ind.iv <- get.iv(ind.date)
  ##return(ind.iv)
  nn.out <- sum(ind.iv[cases, 2] - ind.iv[cases, 1] + 1)
  ##return(nn.out)


  ## We now have 'nn.out'. We next create an empty data frame 'dat.out':
  xx <- cbind(dat[1, , drop = FALSE], com.dat[1, , drop = FALSE])
  dat.out <- matrix(NA, ncol = ncol(xx), nrow = nn.out)
  dat.out <- data.frame(dat.out)
  names(dat.out) <- names(xx)
  dat.out <- rbind(xx, dat.out)[-1, ]
  ##return(dat.out)

  ## And so we fill it!

  cat("Loop starting:\n")

  fixed.rec <- cbind(dat[1, , drop = FALSE], com.dat[1, , drop = FALSE])

  ## This part is the slow one (and simplified here) :

  for (cur.row in (1:no.of.outrows)){
    dat.out[cur.row, ] <- fixed.rec
      ## cbind(fixed.rec, com.dat[1, , drop = FALSE])
    ## cat("row = ", cur.row, "\n")
  }
  ## return(dat.out)
}
------------------------------------------------------------------------
> str(com.dat)
`data.frame':	215 obs. of  7 variables:
 $ V1: num  0.0000 0.0000 0.0807 0.0987 0.1801 ...
 $ V2: num  0.0277 0.0467 0.0654 0.0831 0.0992 ...
 $ V3: num  -0.0277 -0.0467  0.0153  0.0156  0.0809 ...
 $ V4: num  0.0000 0.0000 0.0000 0.0000 0.0162 ...
 $ V5: num  0.00083 0.00132 0.00180 0.00224 0.00262 ...
 $ V6: num  -0.00083 -0.00132 -0.00180 -0.00224  0.01360 ...
 $ V7: num   0.1905  0.0447 -0.4172 -0.1982  0.7761 ...

> str(dat)
`data.frame':	19848 obs. of  15 variables:
 $ enter    : num  57 58 59 60 63 ...
 $ exit     : num  58 59 60 63 64 ...
 $ stdod2   : num  0 0 0 0 0 0 0 0 1 0 ...
 $ stdod    : num  0 0 0 0 0 0 0 0 29 0 ...
 $ bdate    : num  1754 1754 1754 1754 1754 ...
 $ birthdate: num  1754 1754 1754 1754 1754 ...
 $ sex      : num  1 1 1 1 1 1 1 1 1 0 ...
 $ stparity : num  0 0 0 0 0 0 0 0 0 0 ...
 $ bthq     : num  4 4 4 4 4 4 4 4 4 3 ...
 $ bthpar   : num  1 1 1 1 1 1 1 1 1 1 ...
 $ socc     : Factor w/ 4 levels "1","2","3","4": 4 4 4 4 4 4 4 4 4 1 ...
 $ parish   : Factor w/ 4 levels "1","2","3","4": 1 1 1 1 1 1 1 1 1 1 ...
 $ indiv    : num  1e+08 1e+08 1e+08 1e+08 1e+08 ...
 $ famil    : num  1e+05 1e+05 1e+05 1e+05 1e+05 ...
 $ familnu  : num  1e+05 1e+05 1e+05 1e+05 1e+05 ...

Now some timings: In the first two examples (identical) the output data 
frame is of order 55000 cases times 22 variables, but we only fill 100
of these cases:

> unix.time(koll(dat, com.dat, com.info[1, 1:2], 100))
[1] 48.70 23.86 74.00  0.00  0.00

Note that  R  seems to be 'learning':
> unix.time(koll(dat, com.dat, com.info[1, 1:2], 100))
[1] 33.00 23.28 57.69  0.00  0.0

In this example the output data frame is of size only around 300 x 22,
while exactly the same amount of information is written to it as above:
> unix.time(koll(dat[1:100, ], com.dat, com.info[1, 1:2], 100))
[1] 0.44 0.13 0.74 0.00 0.00
  
According to 'top' (I'm on Linux), no swapping is involved ( I have 
1.2 GB memory).
> gc()
           used (Mb) gc trigger  (Mb)
Ncells  1346357 36.0    2251281  60.2
Vcells 12622828 96.4   23650735 180.5

So size matters! Note that the full scale function will take a couple 
of hours even without any calulations at all.

Now the good part. If I rewrite 'koll' so that data are matrices instead 
of data frames:

> unix.time(hej <- koll(haag, com.dat, com.info[1, 1:2], 50000))
[1] 1.67 0.22 1.89 0.00 0.00                             ^^^^^
                                                          NOTE!
This is only ~3 times the compiled code. That's great!!
(Of course, some will be added with the real calculations.)

Sens moral: Avoid data frames for manipulations of this kind.
(Am I right?)

G?ran

On Fri, 7 Dec 2001 james.holtman at convergys.com wrote:

> 
> Heres some timings from a 700MHZ laptop running WIN/2000:
> 
> > x.1 <- data.frame(a=integer(85000), b=double(85000), c=character(85000))
> > str(x.1)
> `data.frame':   85000 obs. of  3 variables:
>  $ a: int  0 0 0 0 0 0 0 0 0 0 ...
>  $ b: num  0 0 0 0 0 0 0 0 0 0 ...
>  $ c: Factor w/ 1 level "": 1 1 1 1 1 1 1 1 1 1 ...
> #
> # loading up a variable with a vector takes very little time
> #
> > system.time(x.1$a <- 1:85000)
> [1] 0.03 0.00 0.03   NA   NA
> > str(x.1)
> `data.frame':   85000 obs. of  3 variables:
>  $ a: int  1 2 3 4 5 6 7 8 9 10 ...
>  $ b: num  0 0 0 0 0 0 0 0 0 0 ...
>  $ c: Factor w/ 1 level "": 1 1 1 1 1 1 1 1 1 1 ...
> #
> # a 'for' loop by itself is only 0.3 seconds
> #
> > system.time(for (i in 1:85000)invisible(1))
> [1] 0.30 0.00 0.31   NA   NA
> #
> # it takes me 5 seconds to initialize 85,000 of a variable, so I would
> assume
> # it would depend on how many and what type.  If 'factors', I would assume
> you would
> # declare those as 'character' and then convert to 'factor' at the end.
> # so it seems fast; is there something I am missing?
> #
> > system.time(for (i in 1:85000) x.1$a[i] <- i)
> [1] 5.12 0.04 5.22   NA   NA
> >
> 
> 
> 
> 
> "Liaw, Andy" <andy_liaw at merck.com>@stat.math.ethz.ch on 12/07/2001 10:32:31
> 
> Sent by:  owner-r-help at stat.math.ethz.ch
> 
> 
> To:   r-help at stat.math.ethz.ch
> cc:
> Subject:  RE: [R] rbind and data.frame
> 
> 
> Are you sure that the time difference is *only* in creating the data frame,
> rather than other computations in the loop?
> 
> Andy
> 
> > -----Original Message-----
> > From: G?ran Brostr?m [mailto:gb at stat.umu.se]
> > Sent: Friday, December 07, 2001 7:25 AM
> > To: Prof Brian Ripley
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] rbind and data.frame
> >
> >
> > On Fri, 7 Dec 2001, Prof Brian Ripley wrote:
> >
> > > On Fri, 7 Dec 2001, [iso-8859-1] G?ran Brostr?m wrote:
> > >
> > > > On Wed, 5 Dec 2001, G?ran Brostr?m wrote:
> > > >
> > > > [...]
> > > >
> > > > > My real problem is how to create a data frame in a
> > sequentially growing
> > > > > manner, when I know the final size (no of cases). I
> > want to avoid to
> > > > > call 'rbind' many times, and instead create an 'empty'
> > data frame in
> > > > > one call, and then fill it. Are there better ways of doing this?
> > > >
> > > > Got no answer to this one, so I provide one myself:
> > >
> > > The usual answer is to create a data frame of the desired size and
> > > populate it via indexing.  That's in some books I know!
> >
> > I know that book too (thanks!). I did what you suggest, and
> > that took 7
> > hours to run. Definitely.
> >
> > G?ran
> >
> > > >
> > > > The answer is: Yes, definitely. I did this, with pure  R
> > code, and
> > > > created a new data frame with around 58000 records. It
> > took 7 hours to
> > > > run. I then did it with compiled code (Fortran), and that
> > made a slight
> > > > difference:  It took 4.8 seconds(!).
> > > >
> > > > G?ran
> > > >
> > > >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> > -.-.-.-.-.-.-.-.-
> > > > r-help mailing list -- Read
> > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > > > Send "info", "help", or "[un]subscribe"
> > > > (in the "body", not the subject !)  To:
> > r-help-request at stat.math.ethz.ch
> > > >
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> > _._._._._._._._._
> > > >
> > >
> > >
> >
> > --
> >  G?ran Brostr?m                      tel: +46 90 786 5223
> >  professor                           fax: +46 90 786 6614
> >  Department of Statistics            http://www.stat.umu.se/egna/gb/
> >  Ume? University
> >  SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
> >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> > -.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read
> > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To:
> > r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> > _._._._._._._._._
> >
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._
> 
> 
> 
> --
> 
> NOTICE:  The information contained in this electronic mail transmission is
> intended by Convergys Corporation for the use of the named individual or
> entity to which it is directed and may contain information that is
> privileged or otherwise confidential.  If you have received this electronic
> mail transmission in error, please delete it from your system without
> copying or forwarding it, and notify the sender of the error by reply email
> or by telephone (collect), so that the sender's address records can be
> corrected.
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Mon Dec 10 10:02:37 2001
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 10 Dec 2001 22:02:37 +1300
Subject: [R] trouble with plotting
In-Reply-To: <Pine.LNX.4.31.0112091811430.8495-100000@gannet.stats>; from ripley@stats.ox.ac.uk on Sun, Dec 09, 2001 at 06:16:01PM +0000
References: <005501c180d3$4be6db80$01000001@godzilla> <Pine.LNX.4.31.0112091811430.8495-100000@gannet.stats>
Message-ID: <20011210220237.A1377@camille.indigoindustrial.co.nz>

On Sun, Dec 09, 2001 at 06:16:01PM +0000, Prof Brian Ripley wrote:
> On Sun, 9 Dec 2001, Jeff D. Hamann wrote:
> 
> > I'm trying to use the lattice package (and have run into the message before)
> > where I will get the following when trying to plot....
> >
> > Error in clearpage() : Error: X11 cannot allocate additional graphics
> > colors.
> > Consider using X11 with colortype="pseudo.cube" or "gray".
> >
> > What do I need to do to get rid of this so that I can use the graphics
> > libraries to their fullest potential. Currently, I can't get lattice() to
> > work.
> 
> EITHER
> 
> 1) Buy a display that uses 24-bit colour, or set your Xserver to make use
> of one if you have it.
> 
> OR
> 
> 2) Shutdown all R graphics devices, then launch
> 
> X11(colortype="pseudo.cube")
> 

Or....

Shut down Netscape, The Gimp, your desktop backgrounds, Gnome (if you're 
using it), and anything else that shows colour pictures, and try again.    
;)

Your colours for X have been sucked dry.

I'm not an X programmer at all, so this might be a dumb question.  Netscape
for Un*x has the option of using a private colour map ("netscape -install",
IIRC).  With this, the colours go very psychadelic on other apps when 
netscape has the focus, and vice-versa, but netscape gets all the colours
it needs.  Is this possible under R?  If not, has anyone considered it?
It seems like yesteryear's problem, as hardware gets cheaper, but
I'm curious.

Needless to say, (1) above is the prefed option, but sometimes I have
to work on a clunky laptop with an LCD screen that's so old, it's
coal-fired.  Gives me something to wish for next fiscal year....  ;)

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Dec 10 10:27:11 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Dec 2001 10:27:11 +0100
Subject: [R] rbind and data.frame [simplified]
In-Reply-To: <Pine.LNX.4.33.0112100806320.1692-100000@tal.stat.umu.se>
References: <Pine.LNX.4.33.0112100806320.1692-100000@tal.stat.umu.se>
Message-ID: <x2667fzaq8.fsf@blueberry.kubism.ku.dk>

G?ran Brostr?m <gb at stat.umu.se> writes:

> Thanks for the interest in my timing problem. I have scaled off all 
> calculations in order to purify it, and it is obvious that size 
> matters a lot. Also that 'matrices are faster than data frames'.
> 
> I give you the full listing here, but it is 
> really the last few lines that are interesting (= slow):

...
>   for (cur.row in (1:no.of.outrows)){
>     dat.out[cur.row, ] <- fixed.rec
>       ## cbind(fixed.rec, com.dat[1, , drop = FALSE])
>     ## cat("row = ", cur.row, "\n")
>   }
>   ## return(dat.out)
> }
> ------------------------------------------------------------------------
...,
> Sens moral: Avoid data frames for manipulations of this kind.
> (Am I right?)

Hmm. With 1.4.0 on the immediate horizon I don't want to go into
actually trying to run this stuff, but it wouldn't be the first time
that data frame code caused slowness by ensuring that the
result of operations is a data frame every single step of the way.

What happens if you do do something like this?: Replace the
  dat.out[cur.row, ] <- fixed.rec
with 
  for (i in 1:ncol) dat.out[[i]][cur.row] <- fixed.rec[[i]]

bypassing "[<-.data.frame"
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From eger.m at gmx.de  Mon Dec 10 11:22:19 2001
From: eger.m at gmx.de (Marcus Eger)
Date: Mon, 10 Dec 2001 11:22:19 +0100
Subject: [R] behaviour of Sys.getenv changed after upgrade from 1.3.0 to R1.3.1 debian
Message-ID: <E16DNZj-0007IR-00@ernie.physik.uni-marburg.de>

Hi, 
both environment variables exist:

> system("echo $hostname")
ernie
> system("echo $HOSTNAME")
ernie

but Sys.getenv reports only one of them:

> Sys.getenv("HOSTNAME")
HOSTNAME
      ""

> Sys.getenv("hostname")
hostname
 "ernie"

What has changed?
  M. Eger


platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    1
minor    3.1
year     2001
month    08
day      31
language R
-- 

+-------- ><> -------------------------------------------
| E-Mail: eger.m at gmx.de (NEW)
|         marcus.eger at physik.uni-marburg.de (OLD)
| WWW:    http://neuro.physik.uni-marburg.de/~eger (NEW)
+--------------------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From a.trapletti at bluewin.ch  Mon Dec 10 12:08:41 2001
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Mon, 10 Dec 2001 12:08:41 +0100
Subject: [R] Re: constrained arima0 model
References: <200112080301.EAA17612@stat.math.ethz.ch>
Message-ID: <3C1497B9.CA1425B1@bluewin.ch>

> Date: 06 Dec 2001 22:12:25 +0100
> From: Fabian Moerchen <fabian at mybytes.de>
> Subject: [R] constrained arima0 model
>
> hi
>
> i want to fit a rather large model (p=12) with arima0.
> some of the resulting AR parameters are very small,
> in the order of their standard errors so i would like
> to force them to 0.
>
> how can i do this?
>
> bye
> fabian
>

You can use arma from the tseries package to do this:

run the command example(arma) and see the second example

best
Adrian

--
Dr. Adrian Trapletti        Phone:     +41 (0)1 994 56 31
Wildsbergstrasse 31         Fax  :     +41 (0)1 994 56 33
CH-8610 Uster               Email: a.trapletti at bluewin.ch
Switzerland                 WWW  :   trapletti.homeip.net



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Dec 10 11:09:48 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 10 Dec 2001 11:09:48 +0100 (CET)
Subject: [R] rbind and data.frame [simplified]
In-Reply-To: <x2667fzaq8.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.4.33.0112101105240.1936-100000@tal.stat.umu.se>

On 10 Dec 2001, Peter Dalgaard BSA wrote:

> G?ran Brostr?m <gb at stat.umu.se> writes:
> 
> > Thanks for the interest in my timing problem. I have scaled off all 
> > calculations in order to purify it, and it is obvious that size 
> > matters a lot. Also that 'matrices are faster than data frames'.
> > 
> > I give you the full listing here, but it is 
> > really the last few lines that are interesting (= slow):
> 
> ...
> >   for (cur.row in (1:no.of.outrows)){
> >     dat.out[cur.row, ] <- fixed.rec
> >       ## cbind(fixed.rec, com.dat[1, , drop = FALSE])
> >     ## cat("row = ", cur.row, "\n")
> >   }
> >   ## return(dat.out)
> > }
> > ------------------------------------------------------------------------
> ...,
> > Sens moral: Avoid data frames for manipulations of this kind.
> > (Am I right?)
> 
> Hmm. With 1.4.0 on the immediate horizon I don't want to go into
> actually trying to run this stuff, but it wouldn't be the first time
> that data frame code caused slowness by ensuring that the
> result of operations is a data frame every single step of the way.
> 
> What happens if you do do something like this?: Replace the
>   dat.out[cur.row, ] <- fixed.rec
> with 
>   for (i in 1:ncol) dat.out[[i]][cur.row] <- fixed.rec[[i]]
> 
> bypassing "[<-.data.frame"
> 

Timing stopped at: 529.27 122.76 668.1 0 0

i.e. catastrophic! I hadn't time to wait; this was with writing 100
records.

G?ran
-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Dec 10 12:16:48 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Dec 2001 12:16:48 +0100
Subject: [R] rbind and data.frame [simplified]
In-Reply-To: <Pine.LNX.4.33.0112101105240.1936-100000@tal.stat.umu.se>
References: <Pine.LNX.4.33.0112101105240.1936-100000@tal.stat.umu.se>
Message-ID: <x2vgffz5nj.fsf@blueberry.kubism.ku.dk>

G?ran Brostr?m <gb at stat.umu.se> writes:


> > 
> > What happens if you do do something like this?: Replace the
> >   dat.out[cur.row, ] <- fixed.rec
> > with 
> >   for (i in 1:ncol) dat.out[[i]][cur.row] <- fixed.rec[[i]]
> > 
> > bypassing "[<-.data.frame"
> > 
> 
> Timing stopped at: 529.27 122.76 668.1 0 0
> 
> i.e. catastrophic! I hadn't time to wait; this was with writing 100
> records.

Oh. Yes, replacing [<-.data.frame with [[<-.data.frame is not going to
work... 

Suppose you precede that with dat.out <- unclass(dat.out) ?
(and end with dat.out <- as.data.frame(dat.out))
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Dec 10 13:21:00 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 10 Dec 2001 13:21:00 +0100 (CET)
Subject: [R] rbind and data.frame [simplified]
In-Reply-To: <x2vgffz5nj.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.4.33.0112101314110.2270-100000@tal.stat.umu.se>

On 10 Dec 2001, Peter Dalgaard BSA wrote:

> G?ran Brostr?m <gb at stat.umu.se> writes:
> 
> 
> > > 
> > > What happens if you do do something like this?: Replace the
> > >   dat.out[cur.row, ] <- fixed.rec
> > > with 
> > >   for (i in 1:ncol) dat.out[[i]][cur.row] <- fixed.rec[[i]]
> > > 
> > > bypassing "[<-.data.frame"
> > > 
> > 
> > Timing stopped at: 529.27 122.76 668.1 0 0
> > 
> > i.e. catastrophic! I hadn't time to wait; this was with writing 100
> > records.
> 
> Oh. Yes, replacing [<-.data.frame with [[<-.data.frame is not going to
> work... 
> 
> Suppose you precede that with dat.out <- unclass(dat.out) ?
> (and end with dat.out <- as.data.frame(dat.out))

Yes, that's better:

> unix.time(koll(dat, com.dat, com.info[1, 1:2], 100)) 
[1] 6.75 2.23 9.14 0.00 0.00

but far from 'matrix behaviour'.

G?ran
-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Robert.Espesser at lpl.univ-aix.fr  Mon Dec 10 14:19:20 2001
From: Robert.Espesser at lpl.univ-aix.fr (Robert Espesser)
Date: Mon, 10 Dec 2001 14:19:20 +0100
Subject: [R] trouble with plotting
References: <005501c180d3$4be6db80$01000001@godzilla> <Pine.LNX.4.31.0112091811430.8495-100000@gannet.stats> <20011210220237.A1377@camille.indigoindustrial.co.nz>
Message-ID: <3C14B658.ECADB851@lpl.univ-aix.fr>

Jason Turner wrote:
> 
> On Sun, Dec 09, 2001 at 06:16:01PM +0000, Prof Brian Ripley wrote:
> > On Sun, 9 Dec 2001, Jeff D. Hamann wrote:
> >
> > > I'm trying to use the lattice package (and have run into the message before)
> > > where I will get the following when trying to plot....
> > >
> > > Error in clearpage() : Error: X11 cannot allocate additional graphics
> > > colors.
> > > Consider using X11 with colortype="pseudo.cube" or "gray".
> > >
> > > What do I need to do to get rid of this so that I can use the graphics
> > > libraries to their fullest potential. Currently, I can't get lattice() to
> > > work.
> >
> > EITHER
> >
> > 1) Buy a display that uses 24-bit colour, or set your Xserver to make use
> > of one if you have it.
> >
> > OR
> >
> > 2) Shutdown all R graphics devices, then launch
> >
> > X11(colortype="pseudo.cube")
> >
> 
> Or....
> 
> Shut down Netscape, The Gimp, your desktop backgrounds, Gnome (if you're
> using it), and anything else that shows colour pictures, and try again.
> ;)
> 
> Your colours for X have been sucked dry.
> 
> I'm not an X programmer at all, so this might be a dumb question.  Netscape
> for Un*x has the option of using a private colour map ("netscape -install",
> IIRC).  With this, the colours go very psychadelic on other apps when
> netscape has the focus, and vice-versa, but netscape gets all the colours
> it needs.  
This may be  very tiring for eyes.

Or ...
Because netscape is very "color-consuming", you may run netscape as:
 netscape -ncols 128
which allows 128 colors at most for netscape. (see netscape -help)


-- 
Robert Espesser     
Laboratoire Parole et Langage  ESA 6057, CNRS
29 Av. Robert Schuman  13621 AIX    (FRANCE)
Tel: +33 (0)4 42 95 36 26   Fax: +33 (0)4 42 59 50 96
http://www.lpl.univ-aix.fr/~espesser
mailto:Robert.Espesser at lpl.univ-aix.fr
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ploner at stat.boku.ac.at  Mon Dec 10 15:14:39 2001
From: ploner at stat.boku.ac.at (Alex Ploner)
Date: Mon, 10 Dec 2001 15:14:39 +0100 (MET)
Subject: [R] Corrupt .RData
Message-ID: <200112101414.PAA26261@stat.boku.ac.at>

I'm using R 1.3.1 on a Windows NT 4.0 machine. As you might
guess my machine crashes on me from time to time :-| So far,
forcing a reboot via the Taskmanager has worked reasonably
well: any open R session would enquire politely whether to
save, and do so if requested.

This time, it has not worked out. I get a 'Fatal Error:
unable to restore saved data in .RData' message and
R terminates. Trying to load the file via load() yields 
'Error in load: NewReadItem: unknown type 0' 

Apparently, the system shutdown has hurt the .RData file
somehow. Is there a way of restoring the information at
least partially without too much trouble? As is common
under these circumstances, I have been both working
extensively and not saving sufficiently on this .RData
recently. Any help would be gratefully appreciated.

alexander


--
Alexander Ploner
Applied Statistics
Univ. f. Agricultural Sciences
Gregor Mendel Str. 33
1180 Vienna, Austria, Europe
Tel.: +43-1-47654-5063
E-Mail: ploner at stat.boku.ac.at

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fboeris at discoveryworld.it  Mon Dec 10 15:43:46 2001
From: fboeris at discoveryworld.it (Flavio Boeris)
Date: Mon, 10 Dec 2001 15:43:46 +0100
Subject: [R] Informazioni sui servizi internet a basso costo presenti sul mercato
Message-ID: <SERVERG3jbhFU8wO9Wa0000216e@server>

Egregio Signore,

mi permetto di disturbarLa per fornirLe alcune
informazioni riguardanti
i servizi internet oggi presenti sul mercato.

Navigando sulla rete mi sono accorto che i costi, per pubblicare e
mantenere un sito aziendale o personale, sono ancora molto elevati
rispetto alla qualita' offerta.
Inoltre moltissimi siti già presenti sulla rete sono sviluppati in modo
poco attrattivo e professionale e, nella maggior parte dei casi, vi è
una
notevole difficolta' nella navigazione.

Ho così pensato ad una serie di servizi, sia per le imprese che hanno
già
un sito e vogliono migliorarne in modo innovativo la struttura e la
grafica (restyle solutions), sia per quelle che vogliono pubblicarne uno
(Costruzione Siti); il tutto a prezzi molto ridotti.

Le scrivo pertanto per invitarLa a prendere visione delle nostre offerte
di costruzione siti, mantenimento e  restyle grafici.

Le consiglio quindi di visitare il nostro sito web al fine di conoscere
nel dettaglio tutte le nostre proposte  ed i relativi  prezzi:
http://www.discoveryworld.it

Vorrei anche informarLa che Le ho riservato il codice provvisorio 1333
nel
caso intendesse acquistare i nostri servizi direttamente nell'area
"acquista servizi".
Tale codice Le offre un servizio gratuito di statistiche riguardanti il
Suo sito per ogni tipo di acquisto effettuato.
Le ricordo infine che potra scaricare, nella prossima denuncia dei
redditi, qualsiasi costo relativo a servizi acquistati presso di noi.

Per qualsiasi informazione aggiuntiva non esiti a contattarmi al mio
indirizzo di posta elettronica.
Scusandomi ancora per il disturbo arrecato Le porgo distinti saluti.


Boeris Flavio
DISCOVERYWORLD
C.so Dante 41
10126 Torino
mailto:fboeris at discoveryworld.it

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From GPetris at uark.edu  Mon Dec 10 16:07:12 2001
From: GPetris at uark.edu (Giovanni Petris)
Date: Mon, 10 Dec 2001 09:07:12 -0600 (CST)
Subject: [R] predicting arma
In-Reply-To: <1007743398.2480.1.camel@pilgrimage.fragile> (message from Fabian
	Moerchen on 07 Dec 2001 17:44:51 +0100)
References: <Pine.GSO.4.31.0112070640100.4068-100000@auk.stats> 
	<1007726999.671.2.camel@pilgrimage.fragile> <1007743398.2480.1.camel@pilgrimage.fragile>
Message-ID: <200112101507.JAA22370@definetti.uark.edu>


arima0.forecast()

Giovanni

> From: Fabian Moerchen <fabian at mybytes.de>
> Date: 07 Dec 2001 17:44:51 +0100
> Sender: owner-r-help at stat.math.ethz.ch
> Precedence: SfS-bulk
> Content-Type: text/plain
> Content-Length: 549
> 
> hi
> 
> 
> how can i predict with an arma object? there doesn't seem to be a
> predict method for these objects. 
> 
> > predict(x.ar13)
> Error in predict(x.ar13) : no applicable method for "predict"
> 
> bye
> fabian
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (501) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sten.willemsen at lycos.com  Mon Dec 10 17:13:18 2001
From: sten.willemsen at lycos.com (Sten Willemsen)
Date: Mon, 10 Dec 2001 17:13:18 +0100
Subject: [R] (No Subject)
Message-ID: <EICNPFDOJNINKAAA@mailcity.com>

Dear group,

I am trying to work with the package ESS. It works fine with Emacs but I cannot get it to work under XEmacs. I get the following error: Symbol's function definition is void: w32-using-nt. Can anabody help me?
I am using Windows NT and XEmacs 21.4.

Regards,

Sten

Sten Willemsen


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Mon Dec 10 10:58:14 2001
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Mon, 10 Dec 2001 09:58:14 +0000
Subject: [R] newbie question - R programs in Windows
In-Reply-To: <001201c18154$a9cc50a0$5402070a@elbacsb.com.pl>
References: <001201c18154$a9cc50a0$5402070a@elbacsb.com.pl>
Message-ID: <w0dkFZA2cIF8EwlV@myatt.demon.co.uk>

Wojciech Czaplinski <tarantoga at elbacsb.com.pl> writes:
>Hello All,
>I've browsed through 'An introduction to R' and it seemed, I didn't find the 
>answers to following questions:
>1) does R provide widgets and other stuff to provide nice windows-native-like 
>applications look and feel?

Yes it does through the tcltk library. This requires you to install the
Tcl/TK library on your machine and set some paths. Tcl/Tk has the
advantage of being cross-platform. It really works between Windows and
Linux as long as you take care with file system pathnames. I have not
checked it on the Mac but I have heard that code works with the very
occasional need for minor modification. Tcl/Tk creates widgets with the
same look & feel of the local operating system.

Mark

--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Mon Dec 10 10:51:56 2001
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Mon, 10 Dec 2001 09:51:56 +0000
Subject: [R] no _?
In-Reply-To: <001101c17fac$a9c4e440$01000001@godzilla>
References: <001101c17fac$a9c4e440$01000001@godzilla>
Message-ID: <5UPmtVA8WIF8EwmK@myatt.demon.co.uk>

Jeff D. Hamann <jeff_hamann at hamanndonald.com> writes:
>I see the uderscore "_" is not allowed in R. This make R a real drag when
>trying to use with SQL packages and c code. Why is the underscore not
>allowed and will it be allowed in a future release?

Underscore is allowed but is a 'special' character meaning assign to the
LHS (i.e. it is equivalent to <-). I believe that it is not common or
recommended usage but remains in R for backward compatibility and for
compatibility with S/S+. I assume that you want to sue it a a separator
in variable names (e.g. my_variable. R convention is to use the period
(e.g. my.variable) but this may be a little confusing as the period
tends to be used as a a delimiter between table and variable names
rather like $ in R. You can use the underscore in variable names if you
quote the name (e.g. "my_variable") wherever you use it. This might
prove tediously prone to error. My suggestion is to convert all variable
names to standard R names (i.e. by replacing _ with .) before soing
anything with the data ... see help(make.names) for details on how to do
this simply.

Mark

--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Mon Dec 10 17:19:49 2001
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 10 Dec 2001 11:19:49 -0500
Subject: [R] Corrupt .RData
Message-ID: <51F9C42DA15CD311BD220008C707D81903DC8405@usrymx10.merck.com>

None, AFAIK.  Seems like you could also use the "auto-save" feature that I
asked about a while ago.  According to Duncan Temple Lang (Thanks a lot,
Duncan!), he's adding some new features in the development version of R that
will let one do something like running an R command automatically after
every fixed number of top level commands (so you can do a save.image(), say
every 20 commands, for example.

One other preventitive meaure (other than back up often) could be, e.g.,
saving "valuable" objects (large data, or objects that takes a long time to
reproduce) that will only be referenced rather than modified in separate
files that can be load() or attach().

HTH,
Andy

> -----Original Message-----
> From: Alex Ploner [mailto:ploner at stat.boku.ac.at]
> Sent: Monday, December 10, 2001 9:15 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Corrupt .RData
> 
> 
> I'm using R 1.3.1 on a Windows NT 4.0 machine. As you might
> guess my machine crashes on me from time to time :-| So far,
> forcing a reboot via the Taskmanager has worked reasonably
> well: any open R session would enquire politely whether to
> save, and do so if requested.
> 
> This time, it has not worked out. I get a 'Fatal Error:
> unable to restore saved data in .RData' message and
> R terminates. Trying to load the file via load() yields 
> 'Error in load: NewReadItem: unknown type 0' 
> 
> Apparently, the system shutdown has hurt the .RData file
> somehow. Is there a way of restoring the information at
> least partially without too much trouble? As is common
> under these circumstances, I have been both working
> extensively and not saving sufficiently on this .RData
> recently. Any help would be gratefully appreciated.
> 
> alexander
> 
> 
> --
> Alexander Ploner
> Applied Statistics
> Univ. f. Agricultural Sciences
> Gregor Mendel Str. 33
> 1180 Vienna, Austria, Europe
> Tel.: +43-1-47654-5063
> E-Mail: ploner at stat.boku.ac.at
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Dec 10 17:23:02 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Dec 2001 17:23:02 +0100
Subject: [R] Corrupt .RData
In-Reply-To: <51F9C42DA15CD311BD220008C707D81903DC8405@usrymx10.merck.com>
References: <51F9C42DA15CD311BD220008C707D81903DC8405@usrymx10.merck.com>
Message-ID: <x2itbfyrh5.fsf@blueberry.kubism.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> None, AFAIK.  Seems like you could also use the "auto-save" feature that I
> asked about a while ago.  According to Duncan Temple Lang (Thanks a lot,
> Duncan!), he's adding some new features in the development version of R that
> will let one do something like running an R command automatically after
> every fixed number of top level commands (so you can do a save.image(), say
> every 20 commands, for example.
> 
> One other preventitive meaure (other than back up often) could be, e.g.,
> saving "valuable" objects (large data, or objects that takes a long time to
> reproduce) that will only be referenced rather than modified in separate
> files that can be load() or attach().

R 1.4.0 will also have a safe-save feature (first write the workspace
to a temporary file, then destructively move it over the original.)

However, if anyone is looking for a project to do in their copious
free time, a .Rdata debug/fix utility would be very welcome...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From b.stapley at umist.ac.uk  Mon Dec 10 18:16:53 2001
From: b.stapley at umist.ac.uk (Ben Stapley)
Date: Mon, 10 Dec 2001 17:16:53 +0000
Subject: [R] high dimensional convex hull
Message-ID: <3C14EE05.946B21C@umist.ac.uk>

Does anyone know of a R package that will determine the convex hull of a
high-dimensional dataset (say 4-10 dimensions).  I know chull works for
2D data.  

I'm neophyte to R and convex hulls so please keep it simple.
Many thanks

Ben

-- 
Ben Stapley.
Biomolecular Sciences, UMIST, PO Box 88, Manchester M60 1QD.
Tel 0161 200 5818
Fax 0161 236 0409
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From GPetris at uark.edu  Mon Dec 10 18:53:50 2001
From: GPetris at uark.edu (Giovanni Petris)
Date: Mon, 10 Dec 2001 11:53:50 -0600 (CST)
Subject: [R] predicting arma
In-Reply-To: <200112101507.JAA22370@definetti.uark.edu> (message from Giovanni
	Petris on Mon, 10 Dec 2001 09:07:12 -0600 (CST))
References: <Pine.GSO.4.31.0112070640100.4068-100000@auk.stats> 
	<1007726999.671.2.camel@pilgrimage.fragile> <1007743398.2480.1.camel@pilgrimage.fragile> <200112101507.JAA22370@definetti.uark.edu>
Message-ID: <200112101753.LAA22535@definetti.uark.edu>


Ooops,

I meant predict(). I got confused with Splus, that has arima.forecast().

Sorry,
Giovanni

> Date: Mon, 10 Dec 2001 09:07:12 -0600 (CST)
> X-Authentication-Warning: definetti.uark.edu: gpetris set sender to gpetris at definetti.uark.edu using -f
> CC: r-help at stat.math.ethz.ch
> From: Giovanni Petris <GPetris at uark.edu>
> Reply-to: Giovanni Petris <GPetris at uark.edu>
> Sender: owner-r-help at stat.math.ethz.ch
> Precedence: SfS-bulk
> Content-Type: text
> Content-Length: 1590
> 
> 
> arima0.forecast()
> 
> Giovanni
> 
> > From: Fabian Moerchen <fabian at mybytes.de>
> > Date: 07 Dec 2001 17:44:51 +0100
> > Sender: owner-r-help at stat.math.ethz.ch
> > Precedence: SfS-bulk
> > Content-Type: text/plain
> > Content-Length: 549
> > 
> > hi
> > 
> > 
> > how can i predict with an arma object? there doesn't seem to be a
> > predict method for these objects. 
> > 
> > > predict(x.ar13)
> > Error in predict(x.ar13) : no applicable method for "predict"
> > 
> > bye
> > fabian
> > 
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> > 
> 
> -- 
> 
>  __________________________________________________
> [                                                  ]
> [ Giovanni Petris                 GPetris at uark.edu ]
> [ Department of Mathematical Sciences              ]
> [ University of Arkansas - Fayetteville, AR 72701  ]
> [ Ph: (501) 575-6324, 575-8630 (fax)               ]
> [ http://definetti.uark.edu/~gpetris/              ]
> [__________________________________________________]
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (501) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetil.kjernsmo at astro.uio.no  Mon Dec 10 19:02:28 2001
From: kjetil.kjernsmo at astro.uio.no (Kjetil Kjernsmo)
Date: Mon, 10 Dec 2001 19:02:28 +0100
Subject: SIGTERM action (was Re: [R] Corrupt .RData)
In-Reply-To: <x2itbfyrh5.fsf@blueberry.kubism.ku.dk>
References: <51F9C42DA15CD311BD220008C707D81903DC8405@usrymx10.merck.com>
	<x2itbfyrh5.fsf@blueberry.kubism.ku.dk>
Message-ID: <15380.63668.166330.95322@localhost.localdomain>

Peter Dalgaard BSA writes:
 
> R 1.4.0 will also have a safe-save feature (first write the workspace
> to a temporary file, then destructively move it over the original.)
> 
> However, if anyone is looking for a project to do in their copious
> free time, a .Rdata debug/fix utility would be very welcome...

Hehe, I'm not volunteering, but since I lost some data to a power
loss (actually, it was just a fuse that blew, power was restored 20
seconds after) and subsequently researching UPSes, I did some thinking
about what R should do when sent a TERM signal. 

A TERM signal will typically be sent by init to all processes when the
battery on the UPS is low. In most cases, the KILL signal will be sent
a few seconds later (though I would personally prefer to write the
takedown script to allow the process more time to respond to TERM in
case it had to save large data sets).

I guess TERM shouldn't write .RData like SIGUSRn does, since the user
may have saved something else in .RData, and didn't want to have it
overwritten. But it might write to e.g. core.RData or something. Then,
the workspace should be written first, in case it gets a KILL signal
shortly after, but I would also like some feature that saves the
objects that only exists within the scope of the function that is
evaluated (I've been running R function for a couple of weeks, keeping
everything in RAM. Not fun to loose all that. Yes, I'm terribly
lazy... :-) ).

Well, those are just loose thoughts... :-) 

Best,

Kjetil
-- 
Kjetil Kjernsmo
Graduate astronomy-student                    Problems worthy of attack
University of Oslo, Norway            Prove their worth by hitting back
E-mail: kjetikj at astro.uio.no                                - Piet Hein
Homepage <URL:http://folk.uio.no/kjetikj/>
Webmaster at skepsis.no                            OpenPGP KeyID: 6A6A0BBC
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec 10 19:08:17 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Dec 2001 18:08:17 +0000 (GMT)
Subject: [R] predicting arma
In-Reply-To: <200112101753.LAA22535@definetti.uark.edu>
Message-ID: <Pine.LNX.4.31.0112101806430.17863-100000@gannet.stats>

On Mon, 10 Dec 2001, Giovanni Petris wrote:

>
> Ooops,
>
> I meant predict(). I got confused with Splus, that has arima.forecast().

One of you confused arima0 in package ts with arma in package tseries ...

> Sorry,
> Giovanni
>
> > Date: Mon, 10 Dec 2001 09:07:12 -0600 (CST)
> > From: Giovanni Petris <GPetris at uark.edu>
> > arima0.forecast()
> >
> > Giovanni
> >
> > > From: Fabian Moerchen <fabian at mybytes.de>
> > > Date: 07 Dec 2001 17:44:51 +0100
> > >
> > > how can i predict with an arma object? there doesn't seem to be a
> > > predict method for these objects.
> > >
> > > > predict(x.ar13)
> > > Error in predict(x.ar13) : no applicable method for "predict"
> > >
> > > bye
> > > fabian
> > >

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cafa at ime.unicamp.br  Mon Dec 10 19:19:26 2001
From: cafa at ime.unicamp.br (Cezar Augusto de Freitas Anselmo)
Date: Mon, 10 Dec 2001 16:19:26 -0200 (EDT)
Subject: [R] GAM models (fwd)
Message-ID: <Pine.GSO.4.10.10112101619140.11908-100000@athenas.ime.unicamp.br>

Hi, all!
I read the faq number 7.17, but I saw the book Statistical Models in S and
I'm trying lead with GAM models in R. Are the only packages that lead with
this mgcv, gss and mda?
Thanks,
 
========================================
Cezar Freitas (ICQ 109128967)
IMECC - UNICAMP
Campinas, SP - Brasil



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From greiff at mitre.org  Mon Dec 10 20:50:45 2001
From: greiff at mitre.org (Warren R. Greiff)
Date: Mon, 10 Dec 2001 14:50:45 -0500
Subject: [R] distributions w. skewness & kurtosis
Message-ID: <3C151215.5AC1DEE@mitre.org>

Is there some reasonable way to generate random data from a
distribution that has some degree of skewness and/or kurtosis, but
would otherwise be normal?

thanks,
-------------- next part --------------
A non-text attachment was scrubbed...
Name: greiff.vcf
Type: text/x-vcard
Size: 398 bytes
Desc: Card for Warren R. Greiff
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20011210/2170bc6f/greiff.vcf

From fabian at mybytes.de  Mon Dec 10 15:03:02 2001
From: fabian at mybytes.de (Fabian Moerchen)
Date: 10 Dec 2001 15:03:02 +0100
Subject: [R] predicting arma
In-Reply-To: <Pine.LNX.4.31.0112101806430.17863-100000@gannet.stats>
References: <Pine.LNX.4.31.0112101806430.17863-100000@gannet.stats>
Message-ID: <1007992984.629.9.camel@pilgrimage.fragile>

if was referring to arma from tseries. it has neither predict nor
forecast.

arima0 has predict but is missing the possibility to constrain models.

On Mon, 2001-12-10 at 19:08, Prof Brian Ripley wrote:
> On Mon, 10 Dec 2001, Giovanni Petris wrote:
> 
> >
> > Ooops,
> >
> > I meant predict(). I got confused with Splus, that has arima.forecast().
> 
> One of you confused arima0 in package ts with arma in package tseries ...
> 
> > Sorry,
> > Giovanni
> >
> > > Date: Mon, 10 Dec 2001 09:07:12 -0600 (CST)
> > > From: Giovanni Petris <GPetris at uark.edu>
> > > arima0.forecast()
> > >
> > > Giovanni
> > >
> > > > From: Fabian Moerchen <fabian at mybytes.de>
> > > > Date: 07 Dec 2001 17:44:51 +0100
> > > >
> > > > how can i predict with an arma object? there doesn't seem to be a
> > > > predict method for these objects.
> > > >
> > > > > predict(x.ar13)
> > > > Error in predict(x.ar13) : no applicable method for "predict"
> > > >
> > > > bye
> > > > fabian
> > > >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From murray.frank at commerce.ubc.ca  Mon Dec 10 22:04:43 2001
From: murray.frank at commerce.ubc.ca (Frank, Murray)
Date: Mon, 10 Dec 2001 13:04:43 -0800
Subject: [R] Graphics with moderately large amounts of data
Message-ID: <6158D207D4D4D311B16700508B44026AFCD5B1@exchange.commerce.ubc.ca>

Hi,

A major attraction to R and to S-plus are the graphics. (Up to now my
experience is with 
STATA and SAS.) Most of the graphical examples that I have seen in the
documentation 
are for relatively small size data sets. I am working with a moderately
large data set -- 
the order of magnitude is 180,000 observations by 50 variables. There seem
to be standard 
problems that I keep bumping into in the graphics: eg. the graphics work
hard to accomodate 
outliers leaving the main action area a thick cloud, very slow operations by
R, etc. I have 
been doing some obvious things to deal with these issues, eg. trimming,
restricting attention 
to data subsamples, etc. But these must be pretty standard issues. I would
like to take 
advantage of what is already known. What should I be reading that explains
how best to
do graphics with a somewhat larger data set? (Pointers to an appropriate FAQ
would be 
great since I have looked but not managed to find it.)

Thanks in advance for any advice.

Thanks.
Murray.

Murray Z. Frank
Faculty of Commerce
University of British Columbia
Vancouver, B.C.
Canada V6T 1Z2

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mj.manning at niwa.cri.nz  Mon Dec 10 22:18:06 2001
From: mj.manning at niwa.cri.nz (Michael J. Manning)
Date: Tue, 11 Dec 2001 10:18:06 +1300
Subject: [R] Box around legends (and postscript?)
Message-ID: <3C15DD5E.3805.290260@localhost>

Hi all

Humbly begging forgiveness for bothering the list with yesterday's 
lame--arsed question.  Postscript, being a vector graphics file format, 
is, um, resolution independant.  The problem as Peter pointed out was 
with the gimp, which defaults to 100dpi resolution when viewing 
postscript files.

I have another (lame?) question.  I have noted that when I produce a 
graph with multiple plots (e.g. 2x2 plots on the graphics device) 
where each plot has multiple series and a legend with reasonable 
amounts of text describing the series, the right hand side of the box 
surrounding the legend always seems to be drawn through the legend 
text when I write the output to a postscript file.  The image 
displayed by the x11 device on screen seems fine, with the legend 
box drawn neatly around the legend text.  I have tried altering the 
character size and location of the legend text inside the legend 
function (cex options etc) without success, i.e. although the legend 
box may be drawn neatly on the x11 device on screen, it cuts the 
legend text when the output is written to a postscript file whatever I 
try.

Suggestions?

MJM


Michael J. Manning
Stock Monitoring and Data Services
National Institute of Water and Atmospheric Research Ltd (NIWA)
PO Box 14901, Kilbirnie
Wellington, New Zealand
Tel. 64 4 386 0300
Fax. 64 4 386 0574
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Dec 10 22:49:18 2001
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Dec 2001 22:49:18 +0100
Subject: [R] Box around legends (and postscript?)
References: <3C15DD5E.3805.290260@localhost>
Message-ID: <3C152DDE.FE9C543B@statistik.uni-dortmund.de>



"Michael J. Manning" wrote:
> 
> Hi all
> 
> Humbly begging forgiveness for bothering the list with yesterday's
> lame--arsed question.  Postscript, being a vector graphics file format,
> is, um, resolution independant.  The problem as Peter pointed out was
> with the gimp, which defaults to 100dpi resolution when viewing
> postscript files.
> 
> I have another (lame?) question.  I have noted that when I produce a
> graph with multiple plots (e.g. 2x2 plots on the graphics device)
> where each plot has multiple series and a legend with reasonable
> amounts of text describing the series, the right hand side of the box
> surrounding the legend always seems to be drawn through the legend
> text when I write the output to a postscript file.  The image
> displayed by the x11 device on screen seems fine, with the legend
> box drawn neatly around the legend text.  I have tried altering the
> character size and location of the legend text inside the legend
> function (cex options etc) without success, i.e. although the legend
> box may be drawn neatly on the x11 device on screen, it cuts the
> legend text when the output is written to a postscript file whatever I
> try.

Use the argument text.width, e.g.

 plot(1:10)
 legend(1, 10 , legend="anything") # now more space:
 legend(1, 8, legend="anything", text.width = strwidth("else") * 2)

Uwe
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ajm6q at virginia.edu  Mon Dec 10 23:25:15 2001
From: ajm6q at virginia.edu (Aaron J Mackey)
Date: Mon, 10 Dec 2001 17:25:15 -0500 (EST)
Subject: [R] Box around legends (and postscript?)
In-Reply-To: <3C15DD5E.3805.290260@localhost>
Message-ID: <Pine.OSF.4.33.0112101724040.29926-100000@alpha10.bioch.virginia.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


You might want to check that paper="letter" (the default seems
to be "a4", which, for me, has the same behavior you see: find graphics
X11 windows, truncated paper output).

- -Aaron

On Tue, 11 Dec 2001, Michael J. Manning wrote:

> Hi all
>
> Humbly begging forgiveness for bothering the list with yesterday's
> lame--arsed question.  Postscript, being a vector graphics file format,
> is, um, resolution independant.  The problem as Peter pointed out was
> with the gimp, which defaults to 100dpi resolution when viewing
> postscript files.
>
> I have another (lame?) question.  I have noted that when I produce a
> graph with multiple plots (e.g. 2x2 plots on the graphics device)
> where each plot has multiple series and a legend with reasonable
> amounts of text describing the series, the right hand side of the box
> surrounding the legend always seems to be drawn through the legend
> text when I write the output to a postscript file.  The image
> displayed by the x11 device on screen seems fine, with the legend
> box drawn neatly around the legend text.  I have tried altering the
> character size and location of the legend text inside the legend
> function (cex options etc) without success, i.e. although the legend
> box may be drawn neatly on the x11 device on screen, it cuts the
> legend text when the output is written to a postscript file whatever I
> try.
>
> Suggestions?
>
> MJM
>
>
> Michael J. Manning
> Stock Monitoring and Data Services
> National Institute of Water and Atmospheric Research Ltd (NIWA)
> PO Box 14901, Kilbirnie
> Wellington, New Zealand
> Tel. 64 4 386 0300
> Fax. 64 4 386 0574
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.6 (OSF1)
Comment: For info see http://www.gnupg.org

iD8DBQE8FTZOt6Sp9Om+GYMRAmzMAJ9YLK9Ay/Jy73Zbf9KiACCw7XBClQCaAutR
iF6QS9p3d8Lfm4y9Sety7TQ=
=mZmA
-----END PGP SIGNATURE-----

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From daven at llnl.gov  Tue Dec 11 00:04:14 2001
From: daven at llnl.gov (David O. Nelson)
Date: Mon, 10 Dec 2001 15:04:14 -0800
Subject: [R] Difference in lexical analysis of strings in R and S-PLUS?
Message-ID: <JNEHLMNIMMBNCHOBOGLIIEAPCIAA.daven@llnl.gov>

It appears that R (1.3.1, Solaris and Windows) tokenizes strings differently
than S-PLUS (6 on Solaris and Windows).

S-PLUS:

> foo <- "abc
Continue string: def"
> cat(foo)
abc
def>

R:


> foo <- "abc
Error: syntax error
>

This difference occurs in source'd files as well. Is there a way to get the
S-PLUS's (and perl's, lisp's, etc.) view of strings, or am I going to have
to go thru my many, many files and escape multi-line strings with
backslashes? What am I missing here?

David O Nelson, Ph.D. (daven at llnl.gov)
Lawrence Livermore National Laboratory
Box 808, L-441
Livermore CA 94551

ph:  +1.925.423.8898
fax: +1.925.422.2282


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mj.manning at niwa.cri.nz  Tue Dec 11 01:37:08 2001
From: mj.manning at niwa.cri.nz (Michael J. Manning)
Date: Tue, 11 Dec 2001 13:37:08 +1300
Subject: [R] Box around legends (and postscript?)
In-Reply-To: <3C152DDE.FE9C543B@statistik.uni-dortmund.de>
Message-ID: <3C160C04.27633.DF392D@localhost>

Hello Uwe

On 10 Dec 2001, at 22:49, Uwe Ligges wrote:
> 
> Use the argument text.width, e.g.
> 

where text.width is set to the largest (i.e. longest) text string in a 
vector of strings to be drawn on the legend, in combination with 
tweaking cex works fine, e.g.

plot(...)

legend(30,0.375,legend=c("Male (n=162)","Female (n=976)"), 
col=c("blue","red"),lty=1,cex=0.8,text.width=strwidth("Female 
(n=976)"))

Thanks muchly

MJM

Michael J. Manning
Stock Monitoring and Data Services
National Institute of Water and Atmospheric Research Ltd (NIWA)
PO Box 14901, Kilbirnie
Wellington, New Zealand
Tel. 64 4 386 0300
Fax. 64 4 386 0574
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jefferis at stanford.edu  Tue Dec 11 02:32:17 2001
From: jefferis at stanford.edu (Greg Jefferis)
Date: Mon, 10 Dec 2001 17:32:17 -0800
Subject: [R] high dimensional convex hull
In-Reply-To: <3C14EE05.946B21C@umist.ac.uk>
Message-ID: <B83AA220.3A0D%jefferis@stanford.edu>

Dear Ben,

There is no R package, however you can use the program qhull available at:

    http://www.geom.umn.edu/software/qhull/

Unfortunately this site seems to be down a lot of the time.  An earlier
version of the program - which probably has all the functionality you need
is available at:

    http://www.cs.sunysb.edu/~algorith/implement/qhull/implement.shtml

Assuming you can compile the software ok, you can then run it as a standard
command line application if you are in a unix environment.  David Marquette
provided me with some R code to handle calling from R - it writes out a
temporary file containing the data matrix you want to find a hull for and
then calls qhull.  Let me know if this would be of use to you.  Best wishes,

Greg.


On 12/10/01 09:16, "Ben Stapley" <b.stapley at umist.ac.uk> wrote:

> Does anyone know of a R package that will determine the convex hull of a
> high-dimensional dataset (say 4-10 dimensions).  I know chull works for
> 2D data.  
> 
> I'm neophyte to R and convex hulls so please keep it simple.
> Many thanks
> 
> Ben

__________________________________________________________________________
Greg Jefferis,                          Lab Address: Liqun Luo, Herrin 144
Neurosciences PhD Programme &                e-mail: jefferis at stanford.edu
Dept Biological Sciences,                       Lab: (650) 725 5809
Gilbert Biology Building,                       Fax: (650) 723 0589
371 Serra Mall,
Stanford, CA 94305-5020.                       Home: (650) 497 1135

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Tue Dec 11 03:28:43 2001
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 10 Dec 2001 21:28:43 -0500
Subject: [R] Rcmd SHLIB problem
Message-ID: <51F9C42DA15CD311BD220008C707D81903DC840B@usrymx10.merck.com>

Dear R-help,

I'm having problem creating a dll using Rcmd SHLIB with R-1.3.1 on WinNT4:

C:\TEMP>Rcmd SHLIB tryf.o
make[1]: `libR.a' is up to date.
make: *** No rule to make target `'tryf.o', needed by `tryf.a'.  Stop.

C:\TEMP>Rcmd SHLIB tryf.f
make[1]: `libR.a' is up to date.
make: *** No rule to make target `'tryf.o', needed by `tryf.a'.  Stop.

I compiled R from source, so I'm quite sure I've got all the right tools.
Can anyone explain what I'm missing?  The FAQ only mentioned compiling C
code.  I'd imagine that Fortran code works the same way, no?

Any help/hint are much appreciated!

Cheers,
Andy
Andy I. Liaw
Biometrics Research          Phone: (732) 594-0820
Merck & Co., Inc.              Fax: (732) 594-1565
P.O. Box 2000, RY70-38            Rahway, NJ 07065
mailto:andy_liaw at merck.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From eger.m at gmx.de  Tue Dec 11 09:07:54 2001
From: eger.m at gmx.de (Marcus Eger)
Date: Tue, 11 Dec 2001 09:07:54 +0100
Subject: [R] behaviour of Sys.getenv changed after upgrade from 1.3.0 to R1.3.1 debian
In-Reply-To: <6r3d2jx7m6.fsf@franz.stat.wisc.edu>
References: <E16DNZj-0007IR-00@ernie.physik.uni-marburg.de> <6r3d2jx7m6.fsf@franz.stat.wisc.edu>
Message-ID: <E16DhxC-0004Mw-00@ernie.physik.uni-marburg.de>

Sorry - -
there seems to have been a change from debian 2.2 to 3.0 (unstable): 
HOSTNAME used to be an environment variable, but has changed to be a shell 
variable now....
Thanks for the hint.
  M. Eger

> Are you sure they are both environment variables?  The echo command
> will echo either an environment variable or a shell variable.
>
> Try
>
> system("export")
>
> to see what is in the environment.

-- 
+-------- ><> -------------------------------------------
| E-Mail: eger.m at gmx.de (NEW)
|         marcus.eger at physik.uni-marburg.de (OLD)
| WWW:    http://neuro.physik.uni-marburg.de/~eger (NEW)
+--------------------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ltorgo at liacc.up.pt  Tue Dec 11 11:14:49 2001
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Tue, 11 Dec 2001 10:14:49 +0000
Subject: [R] Locale problems with strptime to convert dates
Message-ID: <3C15DC98.85E71ABF@liacc.up.pt>

Hi. I've already posted this question 2 months ago but as I've got no
answer I've decided to try again :-)

I'm using R1.3.1 on a x86 machine running Win 2000.

My problem: I want to convert a string to a date format using strptime.

As I'm from Portugal my locale information is the following:

> Sys.getlocale()
[1]
"LC_COLLATE=Portuguese_Portugal.1252;LC_CTYPE=Portuguese_Portugal.1252;LC_MO

NETARY=C;LC_NUMERIC=C;LC_TIME=Portuguese_Portugal.1252"

If I do the following everything works fine :

> k <- "25-Set-01"
> strptime(k,"%d-%b-%y")
[1] "2001-09-25"

because the month September in Portuguese is named "Setembro" and thus
is
abbreviated as "set" and not "sep" as in English.

However, I'm interested in reading English dates. I was hoping that the
following would solve my problem:

> Sys.setlocale("LC_TIME", locale="USA")
[1] "English_United States.1252"

However, I get the following error :

> k <- "25-Sep-01"
> strptime(k,"%d-%b-%y")
[1] "NA"

Thank you in advance for any help with this,
Luis Torgo

--
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
    Machine Learning Group           Fax   : (+351) 22 600 36 54
    R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
    4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Tue Dec 11 11:30:00 2001
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Tue, 11 Dec 2001 11:30:00 +0100
Subject: [R] Using lib Rstreams and gzfile()
Message-ID: <3C15E028.E91E8791@psy.uni-muenchen.de>

Hi all,

in the last time I've intensively used Rstreams to read and write from
binary files. Now I'm wondering if it is possible to use Rsteams
functions with gzipped files. But I haven't found the trick:

> p1c.gzip <- gzfile("daten/p1c_all.mea.gz", open="rb")
> readBin(p1c.gzip, integer(), n=64,size=2)
 [1]    84     1   400     1   749     0     0     0     0     0    
0     0
[13]     0     0     0     0     0     0     0     0     0     0    
0     0
[25]     0     0     0     0     0     0     0     0 11884 25888 25977
11552
[37] 22560     0     0     0     0     0     0     0     0     0    
0     0
[49]     0     0     0     0     0     0     0     0     0     0    
0     0
[61]     0     0     0     0

this is ok, but then with readint from Rstreams:

> seek(p1c.gzip, 0, "start")
[1] 128
> readint(p1c.gzip, 64,2)
 [1] -25620 -17287  21838 -16137  -8489   3835  13806 -28067 -30452
-24244
[11]  11464  18547   5320 -24287 -13180 -14761  13486  -2902  18582  
8798
[21]  29513  21369 -27830  10578  29509 -13015 -23255 -13784  25643 
11960
[31]  -4233  -8515  -2123  -6311  -4455  28531  -1163  -2077   -775
-25282
[41]  -6161  -2242 -12679  -2128  27610 -16977  24278 -25369     61 
11268
[51]    532 -27778 -21424 -17619 -29359 -19503 -10426  22632  28771
-20751
[61] -23825 -25437 -24301  -4469
> 

Is it impossilble to use Rsteams function with the connection functions
from the base package or have I missed something? System R 1.3.1 on
Debian Linux.

Thanks, Sven
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec 11 12:00:10 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Dec 2001 11:00:10 +0000 (GMT)
Subject: [R] Locale problems with strptime to convert dates
In-Reply-To: <3C15DC98.85E71ABF@liacc.up.pt>
Message-ID: <Pine.LNX.4.31.0112111050460.21154-100000@gannet.stats>

On Tue, 11 Dec 2001, Luis Torgo wrote:

> Hi. I've already posted this question 2 months ago but as I've got no
> answer I've decided to try again :-)

That's because we have no answer: we can't reproduce it (nor something
similar involving a Finnish locale).  But on many other machines
locale-switching does work correctly: the likely problem is in
language-specific Microsoft DLLs.

`R is a collaborative project with many contributors.' and patches
are likely to be accepted.

Remember that R has no staff to offer free advice: it does not even have
an active Windows maintainer.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec 11 12:02:01 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Dec 2001 11:02:01 +0000 (GMT)
Subject: [R] Using lib Rstreams and gzfile()
In-Reply-To: <3C15E028.E91E8791@psy.uni-muenchen.de>
Message-ID: <Pine.LNX.4.31.0112111100280.21154-100000@gannet.stats>

Rstreams has been withdrawn (as has been presaged for several months).
You don't need it any longer.


On Tue, 11 Dec 2001, Sven Garbade wrote:

> Hi all,
>
> in the last time I've intensively used Rstreams to read and write from
> binary files. Now I'm wondering if it is possible to use Rsteams
> functions with gzipped files. But I haven't found the trick:
>
> > p1c.gzip <- gzfile("daten/p1c_all.mea.gz", open="rb")
> > readBin(p1c.gzip, integer(), n=64,size=2)
>  [1]    84     1   400     1   749     0     0     0     0     0
> 0     0
> [13]     0     0     0     0     0     0     0     0     0     0
> 0     0
> [25]     0     0     0     0     0     0     0     0 11884 25888 25977
> 11552
> [37] 22560     0     0     0     0     0     0     0     0     0
> 0     0
> [49]     0     0     0     0     0     0     0     0     0     0
> 0     0
> [61]     0     0     0     0
>
> this is ok, but then with readint from Rstreams:
>
> > seek(p1c.gzip, 0, "start")
> [1] 128
> > readint(p1c.gzip, 64,2)
>  [1] -25620 -17287  21838 -16137  -8489   3835  13806 -28067 -30452
> -24244
> [11]  11464  18547   5320 -24287 -13180 -14761  13486  -2902  18582
> 8798
> [21]  29513  21369 -27830  10578  29509 -13015 -23255 -13784  25643
> 11960
> [31]  -4233  -8515  -2123  -6311  -4455  28531  -1163  -2077   -775
> -25282
> [41]  -6161  -2242 -12679  -2128  27610 -16977  24278 -25369     61
> 11268
> [51]    532 -27778 -21424 -17619 -29359 -19503 -10426  22632  28771
> -20751
> [61] -23825 -25437 -24301  -4469
> >
>
> Is it impossilble to use Rsteams function with the connection functions
> from the base package or have I missed something? System R 1.3.1 on
> Debian Linux.
>
> Thanks, Sven
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From danilo.maurizio at venetolavoro.it  Tue Dec 11 12:54:08 2001
From: danilo.maurizio at venetolavoro.it (Danilo Maurizio)
Date: Tue, 11 Dec 2001 12:54:08 +0100
Subject: [R] how can i have the total for each level using table,ftable,xtabs etc. etc. ?
Message-ID: <F6B1718EBAE00E4FB5472D5D0698F3FA021852@comunicazione.venetolavoro.it>

I have a list with four fields and 3500 records, from a MySQL table.
How can i have the total for each level using table, ftable, xtabs?

ex:
print(ftable(table[,"field1"]~table[,"field2"]))

thanks 
Danilo Maurizio
Veneto Lavoro - Area Osservatorio -


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bitwrit at ozemail.com.au  Tue Dec 11 13:11:33 2001
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Tue, 11 Dec 2001 23:11:33 +1100
Subject: [R] Box around legends (and postscript?)
Message-ID: <3C15F7F5.C581AF73@ozemail.com.au>

"Michael J. Manning" wrote:
>
> ...I have another (lame?) question.  I have noted that when I produce
a
> graph with multiple plots (e.g. 2x2 plots on the graphics device)
> where each plot has multiple series and a legend with reasonable
> amounts of text describing the series, the right hand side of the box
> surrounding the legend always seems to be drawn through the legend
> text when I write the output to a postscript file.

I've noticed the same problem when using dev.print() to produce a
postscript file. Interestingly, using postscript() directly seems to
avoid it, although I haven't had the time to discover why.

Jim

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec 11 13:22:22 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Dec 2001 12:22:22 +0000 (GMT)
Subject: [R] Box around legends (and postscript?)
In-Reply-To: <3C15F7F5.C581AF73@ozemail.com.au>
Message-ID: <Pine.LNX.4.31.0112111219470.23115-100000@gannet.stats>

On Tue, 11 Dec 2001, Jim Lemon wrote:

> "Michael J. Manning" wrote:
> >
> > ...I have another (lame?) question.  I have noted that when I produce
> a
> > graph with multiple plots (e.g. 2x2 plots on the graphics device)
> > where each plot has multiple series and a legend with reasonable
> > amounts of text describing the series, the right hand side of the box
> > surrounding the legend always seems to be drawn through the legend
> > text when I write the output to a postscript file.
>
> I've noticed the same problem when using dev.print() to produce a
> postscript file. Interestingly, using postscript() directly seems to
> avoid it, although I haven't had the time to discover why.

Well, dev.print copies a display list from device to device, and doesn't
always get the fonts set up the same way (although it tries).  Trying set
pointsize in the call to dev.print.

It's normally better to remake the plot than copy it if you want precise
control.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Tue Dec 11 13:25:46 2001
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Tue, 11 Dec 2001 13:25:46 +0100
Subject: [R] how can i have the total for each level using
	table,ftable,xtabs etc. etc. ?
In-Reply-To: <F6B1718EBAE00E4FB5472D5D0698F3FA021852@comunicazione.venetolavoro.it>
Message-ID: <B83BB9DA.57C4%pflugshaupt@geobot.umnw.ethz.ch>

On 11.12.2001 12:54 Uhr, Danilo Maurizio wrote:

> I have a list with four fields and 3500 records, from a MySQL table.
> How can i have the total for each level using table, ftable, xtabs?

I'm not sure I've understood how your data is organized. If you have it
within a dataframe (which I recommend), you could use tapply():

tapply(mydata$datafield, list(mydata$field1, mydata$field2), sum)

The first argument is the column containing the data to be summed up. The
second argument lists all the factors (1..n) for whose levels you want the
sum calculated. You will get a sum for each combination of levels. For
details, see help(tapply).

A similar function is by(), but I haven't used it yet. I think it gives
nicer output.

Cheers

Kaspar Pflugshaupt



-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Dec 11 13:35:41 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 11 Dec 2001 13:35:41 +0100
Subject: [R] Box around legends (and postscript?)
In-Reply-To: <Pine.LNX.4.31.0112111219470.23115-100000@gannet.stats>
References: <Pine.LNX.4.31.0112111219470.23115-100000@gannet.stats>
Message-ID: <x2ofl62aua.fsf@blueberry.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Tue, 11 Dec 2001, Jim Lemon wrote:
> 
> > "Michael J. Manning" wrote:
> > >
> > > ...I have another (lame?) question.  I have noted that when I produce
> > a
> > > graph with multiple plots (e.g. 2x2 plots on the graphics device)
> > > where each plot has multiple series and a legend with reasonable
> > > amounts of text describing the series, the right hand side of the box
> > > surrounding the legend always seems to be drawn through the legend
> > > text when I write the output to a postscript file.
> >
> > I've noticed the same problem when using dev.print() to produce a
> > postscript file. Interestingly, using postscript() directly seems to
> > avoid it, although I haven't had the time to discover why.
> 
> Well, dev.print copies a display list from device to device, and doesn't
> always get the fonts set up the same way (although it tries).  Trying set
> pointsize in the call to dev.print.
> 
> It's normally better to remake the plot than copy it if you want precise
> control.

..although it often helps considerably to make sure that the display
device and the print device have the same dimensions and pointsize.
(Usually what happens with text strings is that they get placed at the
same *relative* position, but at a different *absolute* distance from
one of the edges, whereas the stringwidth is roughly constant. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Tue Dec 11 14:19:28 2001
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue, 11 Dec 2001 08:19:28 -0500 (EST)
Subject: [R] distributions w. skewness & kurtosis
In-Reply-To: <3C151215.5AC1DEE@mitre.org>
Message-ID: <Pine.LNX.4.30.0112110812370.21785-100000@bolker.zoo.ufl.edu>


  A similar question came up recently on the list (you can search the
archives for keywords like "kurtosis" at www.r-project.org, or more easily
at Jonathan Baron's site, http://finzi.psych.upenn.edu/search.html).

http://www.r-project.org/nocvs/mail/r-help/2001/5320.html

  This query was about distributions with zero skewness and positive
kurtosis, but I think some of the answers may be helpful if you follow
them up.  Just to caution you, it's not clear what "would otherwise be
normal" means in this context -- I suppose you could say you want a
parametric family of distributions that includes the normal distribution
when some parameters are set to special values, but allow other
possibilities with non-zero higher cumulants ... (the gamma, t, and
possibly weibull distributions spring to mind).

http://www.r-project.org/nocvs/mail/r-help/2001/5320.html


On Mon, 10 Dec 2001, Warren R. Greiff wrote:

> Is there some reasonable way to generate random data from a
> distribution that has some degree of skewness and/or kurtosis, but
> would otherwise be normal?
>
> thanks,

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Tue Dec 11 16:30:15 2001
From: brahm at alum.mit.edu (David Brahm)
Date: Tue, 11 Dec 2001 10:30:15 -0500
Subject: [R] Corrupt .RData
Message-ID: <15382.9863.854401.594106@gargle.gargle.HOWL>

In response to Alex Ploner's <ploner at stat.boku.ac.at> question about lost data
from a corrupted .RData, Andy Liaw <andy_liaw at merck.com> wrote:
> One other preventitive meaure (other than back up often) could be, e.g.,
> saving "valuable" objects (large data, or objects that takes a long time to
> reproduce) that will only be referenced rather than modified in separate
> files that can be load() or attach().

I can't resist plugging my CRAN package "g.data", which does this sort of thing
for you, especially if you have many large objects to store but only expect to
use a few at a time.  Essentially:
   R> g.data.attach("/my/storage/area")
to access existing objects (in position 2), and then:
   R> assign("a.valuable.object", big.object, 2)
   R> g.data.save()
to put new ones there.  Better than hundreds of save()'s and load()'s, IMHO.
-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jeff_hamann at hamanndonald.com  Tue Dec 11 17:44:51 2001
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Tue, 11 Dec 2001 08:44:51 -0800
Subject: [R] plotting values "by"
References: <001501c18019$8e629e50$01000001@godzilla> <20011212020855.A3462@camille.indigoindustrial.co.nz>
Message-ID: <001401c18263$27c5c450$01000001@godzilla>

> 1) what kind of plot? What plotted against what?
> 2) same plot, or same page (i.e. same axes, or lots of little plots
> on the one page)?

well both actually. I would like to plot may (scatterplots or functions) in
one plot using color to separate the different species or fits, and I would
like to plot lots of little histograms over time in lots of little plots on
the page.

I've been able to plot lots of histograms in a page, although I need to
figure out how to use expf as a weight. basically I need to plot lots of
little bar charts, which I can do using par( mfcol=c(y,x)).

I've also had some trouble using the lattice package in a R script. when I
type the command xyplot( ht ~ dbh | species ) i get the plots i'm looking
for, when I try to produce the plots (to the screen) I get nothing. I need
to try to produce an eps file though.

thanks,
jeff.


----- Original Message -----
From: "Jason Turner" <jasont at indigoindustrial.co.nz>
To: "Jeff D. Hamann" <jeff_hamann at hamanndonald.com>
Sent: Tuesday, December 11, 2001 5:08 AM
Subject: Re: [R] plotting values "by"


> Don't know if this has been answered or not...
>
> On Sat, Dec 08, 2001 at 10:52:57AM -0800, Jeff D. Hamann wrote:
> > I would like to produce a set of values, on the same chart, from an sql
> > table that is structured like...
> >
> > species dbh ht expf
> > DF 1.2 8.9 10.0
> > DF 2.4 17.3 12.4342
> > DF 3.1 20.9 56.76
> > PP 2.3 16.9 100.0
> > PP 12.8 97.3 40.3
> > PP 8.2 63.0 98.34
> > .
> > .
> > .
> > SS blah, blah, blah...
> >
> > is it possible to, using a single command in the plot command to plot
the
> > different groups on the same plot or will I have to iterate through the
data
> > set (sql select) and use the points() to get this done? Is it possible
to do
> > the same to produce histograms...
> >
>
> 1) what kind of plot? What plotted against what?
> 2) same plot, or same page (i.e. same axes, or lots of little plots
> on the one page)?
>
> Jason
> --
> Indigo Industrial Controls Ltd.
> 64-21-343-545
> jasont at indigoindustrial.co.nz
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jeff_hamann at hamanndonald.com  Tue Dec 11 17:55:38 2001
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Tue, 11 Dec 2001 08:55:38 -0800
Subject: [R] journal form?
Message-ID: <006401c18264$a8e9ce40$01000001@godzilla>

Are these posts available in journal form so I could get only one message a
day? I really enjoy getting the lowdown on R and I'm really putting it to
work and have almost stopped using that other package whose initials are
"SAS", but I' like to unclutter the inbox. Or are these archived at the end
of the day, week, or month? I wouldn't want to go for a week without
learning something new though.

Thanks,
Jeff.

Jeff D. Hamann
Hamann, Donald and Associates
PO Box 1421
Corvallis, Oregon USA 97339-1421
Bus. 541-753-7333
Cell. 541-740-5988
jeff_hamann at hamanndonald.com
www.hamanndonald.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Dec 11 18:35:01 2001
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 11 Dec 2001 18:35:01 +0100
Subject: [R] journal form?
In-Reply-To: <006401c18264$a8e9ce40$01000001@godzilla>
References: <006401c18264$a8e9ce40$01000001@godzilla>
Message-ID: <15382.17349.461726.969890@gargle.gargle.HOWL>

>>>>> "Jeff" == Jeff D Hamann <jeff_hamann at hamanndonald.com> writes:

    Jeff> Are these posts available in journal form so I could
    Jeff> get only one message a day? I really enjoy getting the
    Jeff> lowdown on R and I'm really putting it to work and
    Jeff> have almost stopped using that other package whose
    Jeff> initials are "SAS", but I' like to unclutter the
    Jeff> inbox. Or are these archived at the end of the day,
    Jeff> week, or month? I wouldn't want to go for a week
    Jeff> without learning something new though.

Yes, 2 x :

- you can subscribe to R-help-digest instead of R-help
- there are archives nicely available

---> Read  http://www.R-project.org/mail.html

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Dec 11 18:38:46 2001
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 11 Dec 2001 18:38:46 +0100
Subject: [R] journal form?
References: <006401c18264$a8e9ce40$01000001@godzilla>
Message-ID: <3C1644A6.DC022C48@statistik.uni-dortmund.de>

"Jeff D. Hamann" wrote:
> 
> Are these posts available in journal form so I could get only one message a
> day? I really enjoy getting the lowdown on R and I'm really putting it to
> work and have almost stopped using that other package whose initials are
> "SAS", but I' like to unclutter the inbox. Or are these archived at the end
> of the day, week, or month? I wouldn't want to go for a week without
> learning something new though.

In   http://www.R-project.org/mail.html   you'll find a chapter "List
Digests" ...

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Tue Dec 11 19:08:15 2001
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Tue, 11 Dec 2001 10:08:15 -0800 (PST)
Subject: [R] plotting values "by"
In-Reply-To: <001401c18263$27c5c450$01000001@godzilla>
Message-ID: <20011211180815.11243.qmail@web13902.mail.yahoo.com>



The lattice package is probably the best way to get most of the plots you want.
Could you give some more details on what problems you are having with it?

>From what you've written, it might help you to know that 

1. the functions xyplot() etc don't draw the plots themselves, they produce
   "trellis" objects which need to be `print'ed to get the actual plots. This
   is done by default when you call the functions interactively, but not when
   you call it within a function, say.

2. You need to use the trellis.device() function (see doc) to get postscript
   output.



--- "Jeff D. Hamann" <jeff_hamann at hamanndonald.com> wrote:
> > 1) what kind of plot? What plotted against what?
> > 2) same plot, or same page (i.e. same axes, or lots of little plots
> > on the one page)?
> 
> well both actually. I would like to plot may (scatterplots or functions) in
> one plot using color to separate the different species or fits, and I would
> like to plot lots of little histograms over time in lots of little plots on
> the page.
> 
> I've been able to plot lots of histograms in a page, although I need to
> figure out how to use expf as a weight. basically I need to plot lots of
> little bar charts, which I can do using par( mfcol=c(y,x)).
> 
> I've also had some trouble using the lattice package in a R script. when I
> type the command xyplot( ht ~ dbh | species ) i get the plots i'm looking
> for, when I try to produce the plots (to the screen) I get nothing. I need
> to try to produce an eps file though.
> 
> thanks,
> jeff.
> 
> 
> ----- Original Message -----
> From: "Jason Turner" <jasont at indigoindustrial.co.nz>
> To: "Jeff D. Hamann" <jeff_hamann at hamanndonald.com>
> Sent: Tuesday, December 11, 2001 5:08 AM
> Subject: Re: [R] plotting values "by"
> 
> 
> > Don't know if this has been answered or not...
> >
> > On Sat, Dec 08, 2001 at 10:52:57AM -0800, Jeff D. Hamann wrote:
> > > I would like to produce a set of values, on the same chart, from an sql
> > > table that is structured like...
> > >
> > > species dbh ht expf
> > > DF 1.2 8.9 10.0
> > > DF 2.4 17.3 12.4342
> > > DF 3.1 20.9 56.76
> > > PP 2.3 16.9 100.0
> > > PP 12.8 97.3 40.3
> > > PP 8.2 63.0 98.34
> > > .
> > > .
> > > .
> > > SS blah, blah, blah...
> > >
> > > is it possible to, using a single command in the plot command to plot
> the
> > > different groups on the same plot or will I have to iterate through the
> data
> > > set (sql select) and use the points() to get this done? Is it possible
> to do
> > > the same to produce histograms...
> > >
> >
> > 1) what kind of plot? What plotted against what?
> > 2) same plot, or same page (i.e. same axes, or lots of little plots
> > on the one page)?
> >
> > Jason
> > --
> > Indigo Industrial Controls Ltd.
> > 64-21-343-545
> > jasont at indigoindustrial.co.nz
> >
> 
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

__________________________________________________

Check out Yahoo! Shopping and Yahoo! Auctions for all of
your unique holiday gifts! Buy at http://shopping.yahoo.com
or bid at http://auctions.yahoo.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Tue Dec 11 19:53:40 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue, 11 Dec 2001 13:53:40 -0500 (EST)
Subject: [R] journal form?
Message-ID: <200112111853.fBBIrew26629@cattell.psych.upenn.edu>

And the archives are at
http://finzi.psych.upenn.edu/
in searchable form (along with other stuff).

Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From greiff at mitre.org  Tue Dec 11 20:05:11 2001
From: greiff at mitre.org (Warren R. Greiff)
Date: Tue, 11 Dec 2001 14:05:11 -0500
Subject: [R] distributions w. skewness & kurtosis
References: <3C151215.5AC1DEE@mitre.org> <3C15427E.E84D15B2@echip.com>
Message-ID: <3C1658E7.A905A287@mitre.org>

Many people pointed out that it wasn't clear what I meant by
"otherwise be normal?". To be frank, I wasn't quite sure what I meant
myself, which was why I wrote "some reasonable way".  One condition I
had in mind was that if the parameters for skewness, and kurtosis were
set to 0, I'd be left with the normal distributions.  

Seems to me a number of responses may point me to solutions for my
problem.  Bob Wheeler's suggestion to look at the Johnson family of
distributions in SuppDists looks particularly promising, so I'll start
there.

The generalized lambda approach mentioned by Michaell Taylor looks
more complicated, but I found R code for it in the gld Package and
will look into that possibility too, when I get a chance.

thanks all,
-------------- next part --------------
A non-text attachment was scrubbed...
Name: greiff.vcf
Type: text/x-vcard
Size: 398 bytes
Desc: Card for Warren R. Greiff
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20011211/df273c9e/greiff.vcf

From MSchwartz at medanalytics.com  Tue Dec 11 20:26:03 2001
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 11 Dec 2001 13:26:03 -0600
Subject: [R] journal form?
Message-ID: <000801c18279$acb23b60$0201a8c0@Marc>

> Are these posts available in journal form so I could get only
> one message a
> day? I really enjoy getting the lowdown on R and I'm really
> putting it to
> work and have almost stopped using that other package whose
> initials are
> "SAS", but I' like to unclutter the inbox. Or are these
> archived at the end
> of the day, week, or month? I wouldn't want to go for a week without
> learning something new though.

The list is available as a "digest".

>From the R web site:

"Subscriptions to `r-help' and `r-devel' are also available in digest
format. With this option, several messages are compiled into a single
message for convenient reading by those who do not prefer immediate receipt
of individual messages. To get messages in digest format, subscribe to the
separate digest lists `r-help-digest' and `r-devel-digest', respectively.
You do not need to be subscribed to the regular lists if you subscribe the
digest lists (and vice versa). E.g., to subscribe to r-help in digest
format, send an email with the word ``subscribe'' in the body of the message
(not in the subject!) to r-help-digest-request at lists.R-project.org."

You can unsubscribe to the regular list and subscribe to the digest version.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From s195404 at student.uq.edu.au  Tue Dec 11 23:16:21 2001
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Wed, 12 Dec 2001 08:16:21 +1000 (EST)
Subject: [R] Paid support for R?
Message-ID: <1008108981.3c1685b52047f@my.uq.edu.au>

Dear R users,

Sorry if this has been discussed before.

I was recently looking at the MySQL site and saw that they offer various levels 
of paid support. The support options range from basic email support (USD200) 
through to extensive telephone support from the development team (USD10000). 
These are annual prices.

This is something I would be happy to see available with R (maybe it is?). My 
experiences with the mailing list have been excellent - I've received a host of 
very helpful responses in no time at all. Novices like I am can't hope to help 
others to the extent that the present contributors do, but something we could 
do is help support those who do offer expert help.

This is what appears at http://www.mysql.org/support/original/basic.html:

"Basic e-mail support is a very inexpensive support option and should be 
thought of more as a way to support our development of MySQL than as a real 
support option. We at MySQL do give a lot of free support in all the different 
MySQL lists, and the money we get from basic e-mail support is largely used to 
make this possible."

I don't know about the mechanics of implementing this, but I presume it has 
worked for MySQL. I would be very interested in the opinions of users and 
developers alike about the merits of this idea. Thank you!


Regards,


Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rik.bradt at cropdesign.com  Wed Dec 12 01:09:15 2001
From: rik.bradt at cropdesign.com (Rik Bradt)
Date: Wed, 12 Dec 2001 01:09:15 +0100
Subject: [R] f-test
Message-ID: <3C16A02B.8020204@cropdesign.com>

Hello,

I'm using R to do statistics on datasets, and now I need an f-test, 
which I can't find in R.
Is there such a thing as an f-test. T-test seems to work fine, but ..

Regards,

Rik


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Richard.Rowe at jcu.edu.au  Wed Dec 12 02:12:08 2001
From: Richard.Rowe at jcu.edu.au (Richard Rowe)
Date: Wed, 12 Dec 2001 11:12:08 +1000
Subject: [R] Paid support for R?
In-Reply-To: <1008108981.3c1685b52047f@my.uq.edu.au>
Message-ID: <5.0.0.25.1.20011212104719.040ba890@pop.jcu.edu.au>

At 08:16 12/12/01 +1000, "Andrew C. Ward" <s195404 at student.uq.edu.au> wrote:
>Dear R users,
>
>Sorry if this has been discussed before.
>
>I was recently looking at the MySQL site and saw that they offer various 
>levels
>of paid support. The support options range from basic email support (USD200)
>through to extensive telephone support from the development team (USD10000).
>These are annual prices.
>
>This is something I would be happy to see available with R (maybe it is?).

I think this proposal is at odds with what I understood to be the 
fundamental theme behind the development of R - a community of scientists 
sharing knowledge without attempts to shut up 'intellectual property' 
behind walls, lawyers etc.  If people feel grateful perhaps they could give 
time, build something, and contribute it to the community.  I expect the 
'consultancy rates' for many of those who freely give advice on R-help 
would make anyone on an academic budget wince ... and that is the rate they 
should charge if they are providing service for a fee.

The structure of 'open source' and the use of the academic and scientific 
community is a good one, set up with considerable hindsight over ways in 
which short-term greed, proprietary methods and intellectual property law 
had done a disservice to the community which generated the ideas and 
methods.  If ever income is derived from R then I expect the system will 
collapse as people will soon come to spend that income, then they will 
spend it in anticipation, at which point they will need to generate the 
income ... and collegiality will disappear,


Richard Rowe
Senior Lecturer
Department of Zoology and Tropical Ecology, James Cook University
Townsville, Queensland 4811, Australia
fax (61)7 47 25 1570
phone (61)7 47 81 4851
e-mail: Richard.Rowe at jcu.edu.au
http://www.jcu.edu.au/school/tbiol/zoology/homepage.html

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Wed Dec 12 03:05:14 2001
From: rossini at blindglobe.net (A.J. Rossini)
Date: 11 Dec 2001 18:05:14 -0800
Subject: [R] Paid support for R?
In-Reply-To: <5.0.0.25.1.20011212104719.040ba890@pop.jcu.edu.au>
References: <5.0.0.25.1.20011212104719.040ba890@pop.jcu.edu.au>
Message-ID: <87667djiqt.fsf@jeeves.blindglobe.net>

>>>>> "RR" == Richard Rowe <Richard.Rowe at jcu.edu.au> writes:

    >> I was recently looking at the MySQL site and saw that they
    >> offer various levels

    >> of paid support. The support options range from basic email
    >> support (USD200) through to extensive telephone support from
    >> the development team (USD10000).  These are annual prices.
    >> 
    >> This is something I would be happy to see available with R
    >> (maybe it is?).

    RR> I think this proposal is at odds with what I understood to be
    RR> the fundamental theme behind the development of R - a
    RR> community of scientists sharing knowledge without attempts to
    RR> shut up 'intellectual property' behind walls, lawyers etc.  If
    RR> people feel grateful perhaps they could give time, build
    RR> something, and contribute it to the community.  I expect the
    RR> 'consultancy rates' for many of those who freely give advice
    RR> on R-help would make anyone on an academic budget wince
    RR> ... and that is the rate they should charge if they are
    RR> providing service for a fee.


    RR> The structure of 'open source' and the use of the academic and
    RR> scientific community is a good one, set up with considerable
    RR> hindsight over ways in which short-term greed, proprietary
    RR> methods and intellectual property law had done a disservice to
    RR> the community which generated the ideas and methods.  If ever
    RR> income is derived from R then I expect the system will
    RR> collapse as people will soon come to spend that income, then
    RR> they will spend it in anticipation, at which point they will
    RR> need to generate the income ... and collegiality will
    RR> disappear,

I might expect just the opposite (and still be wrong, thank you!) --
after all, the GNU manifesto explicitly suggests the initial proposal
as a model for free software (but paid consulting).

I'd personally like to see a few of the authors get paid in some form,
since I enjoy the fruits of their labor.  Not that I've got the cash
readily available, but I try (to a limited extent) by supporting
software that some of them use, somewhat in reciprocation.

Now, problems might arise with strict commercialization, but that
would be difficult (though not insurmountable) given the license
currently employed.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   T-Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
Rosen: (Mullins' Lab) Fridays, and I'm unreachable except by email.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Wed Dec 12 03:21:06 2001
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 11 Dec 2001 18:21:06 -0800 (PST)
Subject: [R] Paid support for R?
In-Reply-To: <5.0.0.25.1.20011212104719.040ba890@pop.jcu.edu.au>
Message-ID: <Pine.GSO.4.10.10112111814160.6141-100000@fisher.stat.ucla.edu>

It's perhaps a bit strong to say that "this proposal is at odds with...the
fundamental theme behind the development of R." As far as I know, no where
is it stated that you can't make money off of R.  The fundamental problem
in the world of proprietary software is the lack of sharing ---
improvements are made to software which are NOT shared with the community.  
I'm assuming that the GNU GPL was chosen for R in order to prevent this
kind of non-sharing anti-social behavior.  The GPL forces developers to
share their improvements with the community.

I don't think there's anything inherently wrong with people making a few
bucks off of R, especially if that encourages them to make improvements
from which we can all benefit.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 12 Dec 2001, Richard Rowe wrote:

> At 08:16 12/12/01 +1000, "Andrew C. Ward" <s195404 at student.uq.edu.au> wrote:
> >Dear R users,
> >
> >Sorry if this has been discussed before.
> >
> >I was recently looking at the MySQL site and saw that they offer various 
> >levels
> >of paid support. The support options range from basic email support (USD200)
> >through to extensive telephone support from the development team (USD10000).
> >These are annual prices.
> >
> >This is something I would be happy to see available with R (maybe it is?).
> 
> I think this proposal is at odds with what I understood to be the 
> fundamental theme behind the development of R - a community of scientists 
> sharing knowledge without attempts to shut up 'intellectual property' 
> behind walls, lawyers etc.  If people feel grateful perhaps they could give 
> time, build something, and contribute it to the community.  I expect the 
> 'consultancy rates' for many of those who freely give advice on R-help 
> would make anyone on an academic budget wince ... and that is the rate they 
> should charge if they are providing service for a fee.
> 
> The structure of 'open source' and the use of the academic and scientific 
> community is a good one, set up with considerable hindsight over ways in 
> which short-term greed, proprietary methods and intellectual property law 
> had done a disservice to the community which generated the ideas and 
> methods.  If ever income is derived from R then I expect the system will 
> collapse as people will soon come to spend that income, then they will 
> spend it in anticipation, at which point they will need to generate the 
> income ... and collegiality will disappear,
> 
> 
> Richard Rowe
> Senior Lecturer
> Department of Zoology and Tropical Ecology, James Cook University
> Townsville, Queensland 4811, Australia
> fax (61)7 47 25 1570
> phone (61)7 47 81 4851
> e-mail: Richard.Rowe at jcu.edu.au
> http://www.jcu.edu.au/school/tbiol/zoology/homepage.html
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From MSchwartz at medanalytics.com  Wed Dec 12 03:26:05 2001
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 11 Dec 2001 20:26:05 -0600
Subject: [R] f-test
In-Reply-To: <3C16A02B.8020204@cropdesign.com>
Message-ID: <000e01c182b4$5a3c25e0$0201a8c0@Marc>

> Hello,
> 
> I'm using R to do statistics on datasets, and now I need an f-test, 
> which I can't find in R.
> Is there such a thing as an f-test. T-test seems to work fine, but ..
> 
> Regards,
> 
> Rik
> 

Rik,

Type in "help(var.test)" in the R console.

That will bring up information on performing an F test.

Marc




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From catherine at research.bell-labs.com  Wed Dec 12 04:26:04 2001
From: catherine at research.bell-labs.com (Catherine Loader)
Date: Tue, 11 Dec 2001 22:26:04 -0500 (EST)
Subject: [R] passing lists through .C
Message-ID: <200112120326.WAA15192@jessie.research.bell-labs.com>

I have a list,

> rb
$t
[1] "tree"
 
$x
[1] 0
 
$cut
[1] 0.8
 
$l
 [1] 0 0
 
and pass it through .C("fn",rb) to

void fn(ev)
int **ev;
{ double cut;
  cut = *(double *)ev[2][0];
  printf("%8.5f\n",cut);
}

in S-4, it produces 0.8, as I want.
But R (version 1.3.1, linux) produces a segmentation fault.
Is it possible to access list elements in R? The manual seems
to suggest writing .Call interfaces, which I want to avoid.

Thanks,
Catherine.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ross at turing.une.edu.au  Wed Dec 12 04:50:07 2001
From: ross at turing.une.edu.au (Ross Darnell)
Date: 12 Dec 2001 14:50:07 +1100
Subject: [R] Paid support for R?
In-Reply-To: Richard Rowe's message of "Wed, 12 Dec 2001 11:12:08 +1000"
References: <5.0.0.25.1.20011212104719.040ba890@pop.jcu.edu.au>
Message-ID: <x85adwprtao.fsf@turing.une.edu.au>

Richard Rowe <Richard.Rowe at jcu.edu.au> writes:

> At 08:16 12/12/01 +1000, "Andrew C. Ward" <s195404 at student.uq.edu.au> wrote:
> >Dear R users,
> >
> >Sorry if this has been discussed before.
> >
> > I was recently looking at the MySQL site and saw that they offer
> > various levels
> 
> >of paid support. The support options range from basic email support (USD200)
> >through to extensive telephone support from the development team (USD10000).
> >These are annual prices.
> >
> >This is something I would be happy to see available with R (maybe it is?).
> 
> I think this proposal is at odds with what I understood to be the
> fundamental theme behind the development of R - a community of
> scientists sharing knowledge without attempts to shut up 'intellectual
> property' behind walls, lawyers etc.  If people feel grateful perhaps
> they could give time, build something, and contribute it to the
> community.  I expect the 'consultancy rates' for many of those who
> freely give advice on R-help would make anyone on an academic budget
> wince ... and that is the rate they should charge if they are
> providing service for a fee.
> 
> 
> The structure of 'open source' and the use of the academic and
> scientific community is a good one, set up with considerable hindsight
> over ways in which short-term greed, proprietary methods and
> intellectual property law had done a disservice to the community which
> generated the ideas and methods.  If ever income is derived from R
> then I expect the system will collapse as people will soon come to
> spend that income, then they will spend it in anticipation, at which
> point they will need to generate the income ... and collegiality will
> disappear,
> 

Is this an attempt by the original poster to find a job?

But I don't quite agree that people shouldn't get paid for giving advice.

I have taught and given advice about R to students and colleagues and
get paid for it as a lecturer and statistical consultant. And I may
have actually asked this list for advice on a question asked to me.
Is this any different?

I am sure there are a people who are TeX consultants.

Regards
Ross Darnell

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r.hankin at auckland.ac.nz  Wed Dec 12 04:44:22 2001
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Wed, 12 Dec 2001 16:44:22 +1300
Subject: [R] can't vectorize an expression 
Message-ID: <200112120344.fBC3iMr21935@r.hankin.sems.auckland.ac.nz>

Dear R support network

I have a problem that is driving me crazy.

I have a dataframe with about 74000 landscapes which I call "land".  A
landscape is a 2km -by- 2km square.

Land has three columns: land$lat, land$long, and land$description.
The last one holds a NON-unique (integer) description of each
landscape.  There are maybe 100 distinct descriptions.  Identifying
landscapes that have identical descriptions gives equivalence classes.

I am interested in the largest few equivalence classes (that is, a
*large* set of landscapes with identical descriptions).  The largest
equivalence class holds around 1500 landscapes.


Thus:

top <- rev(sort(table(land$description)))
top.values  <- as.numeric(names(top))

So far so good: top.values holds the descriptions of the largest
equivalence classes first.

Now things turn to custard; the following lines show the only way I
could think of to extract the six largest equivalence classes:

which(land$description == top.values[1]) -> biggest1
which(land$description == top.values[2]) -> biggest2
which(land$description == top.values[3]) -> biggest3
which(land$description == top.values[4]) -> biggest4
which(land$description == top.values[5]) -> biggest5
which(land$description == top.values[6]) -> biggest6 

plotting them is relatively easy:

plot(b[,1:2],pch=16,cex=0.2)
matplot(land$lat[biggest1],land$long[biggest1], col="red",   type="p",pch=16,add=TRUE)
matplot(land$lat[biggest2],land$long[biggest2], col="blue",  type="p",pch=16,add=TRUE)
matplot(land$lat[biggest3],land$long[biggest3], col="yellow",type="p",pch=16,add=TRUE)
matplot(land$lat[biggest4],land$long[biggest4], col="green", type="p",pch=16,add=TRUE)
matplot(land$lat[biggest5],land$long[biggest5], col="purple",type="p",pch=16,add=TRUE)
matplot(land$lat[biggest6],land$long[biggest6], col="cyan",  type="p",pch=16,add=TRUE)


QUESTION: How do I vectorize this?

--


A test dataset might look like


lat long description
 172.1100 -34.1500 8
 172.1300 -34.1500 8
 172.1500 -34.1500 8
 172.1300 -34.1700 8
 172.1500 -34.1700 7
 173.0100 -34.3900 7
 173.0300 -34.3900 6
 172.8700 -34.4100 7
 172.8900 -34.4100 7
 172.9700 -34.4100 6
 172.9900 -34.4100 8
 173.0100 -34.4100 8
 173.0300 -34.4100 8
 173.0500 -34.4100 8
 172.6700 -34.4300 8
 172.6900 -34.4300 6
 172.7100 -34.4300 6
 172.7300 -34.4300 6
 172.7500 -34.4300 6
		   

-- 

Robin Hankin, Lecturer,
School of Environmental and Marine Science
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Dec 12 09:02:05 2001
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 12 Dec 2001 09:02:05 +0100
Subject: [R] Re: R-Help List Transmit Time
In-Reply-To: <000501c182ca$640776e0$0201a8c0@Marc>
References: <000501c182ca$640776e0$0201a8c0@Marc>
Message-ID: <15383.3837.740775.293817@gargle.gargle.HOWL>

I answer publicly, since this is something like a moderatly FAQ

>>>>> "Marc" == Marc Schwartz <MSchwartz at medanalytics.com> writes:

    Marc> Question: Is it typical for messages posted to the R
    Marc> help list to take on the order of 2.5 hours to be
    Marc> transmitted to some subscribers after being sent?

yes, it is.

    Marc> The reason that I ask is that I have posted to the
    Marc> list twice today and it seems to take some time for my
    Marc> post to get e-mailed back to me.  In fact, I got a
    Marc> reply tonight to one of my posts (on the F test query)
    Marc> before I got a copy of my original post. This tells me
    Marc> that at least some folks are getting my posts within a
    Marc> reasonable period of time.

that's true: Those at the beginning of the list (and some others
with identical mail server) are getting things quickly; this
includes all of R-core on purpose.

    Marc> I have noted other posts that I have gotten where the
    Marc> time received is consistently some 2+ hours after the time sent.

other people have even longer delays...  Note that there are
currently about 870 subscribers to R-help (plus ~170 to R-help-digest). 

I still hope that this will be improved ``real soon now'' when
our mail server will get much more "power" dedicated to sendmail
and/or also by using a version of bulkmail.. 
on the other hand, it's not so bad if people get time to think
sometimes even before posting .. :-)

Your list maintainer,
Martin Maechler
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec 12 09:14:04 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Dec 2001 08:14:04 +0000 (GMT)
Subject: [R] passing lists through .C
In-Reply-To: <200112120326.WAA15192@jessie.research.bell-labs.com>
Message-ID: <Pine.LNX.4.31.0112120802110.2864-100000@gannet.stats>

On Tue, 11 Dec 2001, Catherine Loader wrote:

> I have a list,
>
> > rb
> $t
> [1] "tree"
>
> $x
> [1] 0
>
> $cut
> [1] 0.8
>
> $l
>  [1] 0 0
>
> and pass it through .C("fn",rb) to
>
> void fn(ev)
> int **ev;
> { double cut;
>   cut = *(double *)ev[2][0];
>   printf("%8.5f\n",cut);
> }
>
> in S-4, it produces 0.8, as I want.
> But R (version 1.3.1, linux) produces a segmentation fault.
> Is it possible to access list elements in R? The manual seems
> to suggest writing .Call interfaces, which I want to avoid.

Yes, but it would be no easier than using .Call.  ?Foreign says

Lists are passed as C arrays of `SEXP' and can be declared as `void *' or
`SEXP *'.

so you do need to mess with SEXPs.  Something like (minimally tested)

#include <R.h>
#include <Rinternals.h>

void fn(SEXP *ev)
{
   SEXP cut = ev[2];
   printf("%8.5f\n", REAL(cut)[0]);
}

Note that using printf is not portable, but presumably this was just a
test.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Dec 12 09:19:59 2001
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 12 Dec 2001 09:19:59 +0100
Subject: [R] passing lists through .C
In-Reply-To: <200112120326.WAA15192@jessie.research.bell-labs.com>
References: <200112120326.WAA15192@jessie.research.bell-labs.com>
Message-ID: <15383.4911.308595.842571@gargle.gargle.HOWL>

>>>>> "CL" == Catherine Loader <catherine at research.bell-labs.com> writes:

    CL> I have a list,
    >> rb
    CL> $t [1] "tree"
    CL> $x [1] 0
    CL> $cut [1] 0.8
    CL> $l [1] 0 0

    CL> and pass it through .C("fn",rb) to

    CL> void fn(ev)
    CL> int **ev;
    CL> { double cut;
    CL>  cut = *(double *)ev[2][0];
    CL>  printf("%8.5f\n",cut);
    CL> }

    CL> in S-4, it produces 0.8, as I want.

which is astonishing, and AFAIK not at all to be relied on.

    CL> But R (version 1.3.1, linux) produces a segmentation fault.
    CL> Is it possible to access list elements in R? 
yes, via .Call()

    CL> The manual seems to suggest writing .Call
    CL> interfaces, which I want to avoid.

no way (to avoid this)!
It's also the (only?) way publicized for S4 (based versions of
S-PLUS).

Regards,
Martin
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Roger.Bivand at nhh.no  Wed Dec 12 10:25:02 2001
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 12 Dec 2001 10:25:02 +0100 (CET)
Subject: [R] can't vectorize an expression 
In-Reply-To: <200112120344.fBC3iMr21935@r.hankin.sems.auckland.ac.nz>
Message-ID: <Pine.LNX.4.21.0112121011220.15135-100000@reclus.nhh.no>

On Wed, 12 Dec 2001, Robin Hankin wrote:

> Dear R support network
> 
> I have a problem that is driving me crazy.
> 
> I have a dataframe with about 74000 landscapes which I call "land".  A
> landscape is a 2km -by- 2km square.
> 
> Land has three columns: land$lat, land$long, and land$description.
> The last one holds a NON-unique (integer) description of each
> landscape.  There are maybe 100 distinct descriptions.  Identifying
> landscapes that have identical descriptions gives equivalence classes.
> 
> I am interested in the largest few equivalence classes (that is, a
> *large* set of landscapes with identical descriptions).  The largest
> equivalence class holds around 1500 landscapes.
> 
> 
> Thus:
> 
> top <- rev(sort(table(land$description)))
> top.values  <- as.numeric(names(top))
> 
> So far so good: top.values holds the descriptions of the largest
> equivalence classes first.
> 

Using a similar setup, for land cover classes for a raster map layer:

> table(z)
z
    1     2     3     4     5     6     7     8 
 1671  6632   555  1749 22913 16816  6558   706 
> top <- rev(sort(table(z)))
> top
    5     6     2     7     4     1     8     3 
22913 16816  6632  6558  1749  1671   706   555 
> top.values  <- as.integer(names(top))
> ztop <- apply(matrix(z, ncol=1), 1, function(x) which(top.values == x))

Apply takes a bit of time, but certainly less than keying in all the
commands. To drop the classes over the sixth:

> ztop[ztop > 6] <- NA
> summary(as.ordered(ztop))
    1     2     3     4     5     6  NA's 
22913 16816  6632  6558  1749  1671  1261 

Since I'm using the GRASS GIS interface here (in Devel), I can retrieve
the position data:

> summary(G)
Data from GRASS 5.0 LOCATION leics with 240 columns and 240 rows;
The west-east range is: 444000, 456000, and the south-north: 310000,
322000;
West-east cell sizes are 50 units, and south-north 50 units.

Given that, and knowing the sequences of cell centres in x and y:

> image(G$xseq, G$yseq, t(matrix(ztop, nrow=240, ncol=240,
byrow=T))[,240:1], asp=1, breaks=seq(0.5,6.5,1),
col=c("red","blue","yellow","green","purple","cyan")

gives the plot (asp=1 to keep aspect ratio). Looking at the code in the
pixmap package, you'll also see some ways to get the image out.


> Now things turn to custard; the following lines show the only way I
> could think of to extract the six largest equivalence classes:
> 
> which(land$description == top.values[1]) -> biggest1
> which(land$description == top.values[2]) -> biggest2
> which(land$description == top.values[3]) -> biggest3
> which(land$description == top.values[4]) -> biggest4
> which(land$description == top.values[5]) -> biggest5
> which(land$description == top.values[6]) -> biggest6 
> 
> plotting them is relatively easy:
> 
> plot(b[,1:2],pch=16,cex=0.2)
> matplot(land$lat[biggest1],land$long[biggest1], col="red",   type="p",pch=16,add=TRUE)
> matplot(land$lat[biggest2],land$long[biggest2], col="blue",  type="p",pch=16,add=TRUE)
> matplot(land$lat[biggest3],land$long[biggest3], col="yellow",type="p",pch=16,add=TRUE)
> matplot(land$lat[biggest4],land$long[biggest4], col="green", type="p",pch=16,add=TRUE)
> matplot(land$lat[biggest5],land$long[biggest5], col="purple",type="p",pch=16,add=TRUE)
> matplot(land$lat[biggest6],land$long[biggest6], col="cyan",  type="p",pch=16,add=TRUE)
> 
> 
> QUESTION: How do I vectorize this?
> 
> --
> 
> 
> A test dataset might look like
> 
> 
> lat long description
>  172.1100 -34.1500 8
>  172.1300 -34.1500 8
>  172.1500 -34.1500 8
>  172.1300 -34.1700 8
>  172.1500 -34.1700 7
>  173.0100 -34.3900 7
>  173.0300 -34.3900 6
>  172.8700 -34.4100 7
>  172.8900 -34.4100 7
>  172.9700 -34.4100 6
>  172.9900 -34.4100 8
>  173.0100 -34.4100 8
>  173.0300 -34.4100 8
>  173.0500 -34.4100 8
>  172.6700 -34.4300 8
>  172.6900 -34.4300 6
>  172.7100 -34.4300 6
>  172.7300 -34.4300 6
>  172.7500 -34.4300 6
> 		   
> 
> 

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no
and: Department of Geography and Regional Development, University of
Gdansk, al. Mar. J. Pilsudskiego 46, PL-81 378 Gdynia, Poland.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec 12 11:23:45 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Dec 2001 10:23:45 +0000 (GMT)
Subject: [R] Rcmd SHLIB problem
In-Reply-To: <51F9C42DA15CD311BD220008C707D81903DC840B@usrymx10.merck.com>
Message-ID: <Pine.LNX.4.31.0112121021250.3547-100000@gannet.stats>

it should and does work with Fortran (and C++) files.  The right format is

Rcmd SHLIB tryf.f

I've just tested that under rw1031 and the pretest of 1.4.0, so I've
no idea what's up for you.

B

On Mon, 10 Dec 2001, Liaw, Andy wrote:

> Dear R-help,
>
> I'm having problem creating a dll using Rcmd SHLIB with R-1.3.1 on WinNT4:
>
> C:\TEMP>Rcmd SHLIB tryf.o
> make[1]: `libR.a' is up to date.
> make: *** No rule to make target `'tryf.o', needed by `tryf.a'.  Stop.
>
> C:\TEMP>Rcmd SHLIB tryf.f
> make[1]: `libR.a' is up to date.
> make: *** No rule to make target `'tryf.o', needed by `tryf.a'.  Stop.
>
> I compiled R from source, so I'm quite sure I've got all the right tools.
> Can anyone explain what I'm missing?  The FAQ only mentioned compiling C
> code.  I'd imagine that Fortran code works the same way, no?
>
> Any help/hint are much appreciated!
>
> Cheers,
> Andy
> Andy I. Liaw
> Biometrics Research          Phone: (732) 594-0820
> Merck & Co., Inc.              Fax: (732) 594-1565
> P.O. Box 2000, RY70-38            Rahway, NJ 07065
> mailto:andy_liaw at merck.
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zupidupi at yahoo.com  Wed Dec 12 11:58:49 2001
From: zupidupi at yahoo.com (Hoodoo Gooroo)
Date: Wed, 12 Dec 2001 02:58:49 -0800 (PST)
Subject: [R] Output from the multinom-function
Message-ID: <20011212105849.77631.qmail@web20504.mail.yahoo.com>

Hello folks,

Let me first apologize: I'm not a professional nor a
mathematician, just an ordinary guy, fooling around
with the excellent R-package. I know the basic
principles behind statistics, but haven't read
anything more advanced than the ordinary first
probability and statistics courses.

Enough disclaimers? Good! I was examining the
multinom-function (in the nnet-package) the other day
and run a couple of tests. This is part of an output I
got.

multinom(formula = result ~., data = info)

Coefficients:
   (Intercept) PH          WH         
1  -0.3974387  0.02201908 -0.0009618038 
2   2.5183566 -0.07076967 -0.0596189836 

The variable result I was trying to predict is a
nominal variable, taking the values 0, 1 and 2. The
independent variables are quite a few, some of them
nominal, some not. I know about regression
coefficients, intercepts, and all that jazz. I'm not
sure, though, how I should use the coefficients and
intercepts I got in the output. Why are there two
different coefficients per variable? When should I use
which? How should I interpret the output of the
regression function? Should the output be rounded to
the nearest integer, which would happen to be <=0, 1
or >=2 -> I can decide which the prediction is? Or am
I missing some fine points in this particular field of
math I'm (admittedly somewhat blindfolded) messing
around in?

I'm grateful for any help, or any pointers to good
sources on the web. I don't have any problems with
reading theory - it's just that I don't have any
theory to read!

Thanks a lot in advance,

   Mike

__________________________________________________

Check out Yahoo! Shopping and Yahoo! Auctions for all of
your unique holiday gifts! Buy at http://shopping.yahoo.com
or bid at http://auctions.yahoo.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Wed Dec 12 12:07:42 2001
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Wed, 12 Dec 2001 11:07:42 +0000
Subject: [R] Next step after multiple GoF tests
Message-ID: <BPPYrJA+pzF8Eww5@myatt.demon.co.uk>

All,

This may be a bit off topic so feel free to flame me ... my defence is
that I am using R.

I have data with case counts per family. I arrange the data in a simple
table of frequency classes (e.g. how many families with 0 cases, how
many with 1 case, &c.) and then GoF to Poisson and negative binomial. I
treat each family as a natural sampling unit but families are of
different size. I can do the above analysis for each family size but
would like to pool the results. Which way forward ... I am guessing that
I could use some extension of Mantel-Haenszel methods or maybe a GLM.
Any pointers gratefully received.

Mark


--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Wed Dec 12 11:00:18 2001
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Wed, 12 Dec 2001 10:00:18 +0000
Subject: [R] f-test
In-Reply-To: <3C16A02B.8020204@cropdesign.com>
References: <3C16A02B.8020204@cropdesign.com>
Message-ID: <AOcIbBAyqyF8EwA0@myatt.demon.co.uk>

Rik Bradt <rik.bradt at cropdesign.com> writes:
>Hello,
>
>I'm using R to do statistics on datasets, and now I need an f-test, 
>which I can't find in R.
>Is there such a thing as an f-test. T-test seems to work fine, but ..

It all depends on what you mean by an 'F test' since there are numerous
tests for all sorts of things that share that name. The function
var.test() compares variances as an F test. The aov() function also does
an F test on the significance of individual variables in an analysis of
variance model. See help(var.test) and help(aov) for more details.

Mark


--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec 12 12:23:37 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Dec 2001 11:23:37 +0000 (GMT)
Subject: [R] Output from the multinom-function
In-Reply-To: <20011212105849.77631.qmail@web20504.mail.yahoo.com>
Message-ID: <Pine.LNX.4.31.0112121120590.3676-100000@gannet.stats>

multinom is support software for a book, Moderan Applied Statistics with
S-PLUS by Venables & Ripley.  You have read it and understood its
examples, haven't you?

On Wed, 12 Dec 2001, Hoodoo Gooroo wrote:

> Hello folks,
>
> Let me first apologize: I'm not a professional nor a
> mathematician, just an ordinary guy, fooling around
> with the excellent R-package. I know the basic
> principles behind statistics, but haven't read
> anything more advanced than the ordinary first
> probability and statistics courses.
>
> Enough disclaimers? Good! I was examining the
> multinom-function (in the nnet-package) the other day
> and run a couple of tests. This is part of an output I
> got.
>
> multinom(formula = result ~., data = info)
>
> Coefficients:
>    (Intercept) PH          WH
> 1  -0.3974387  0.02201908 -0.0009618038
> 2   2.5183566 -0.07076967 -0.0596189836
>
> The variable result I was trying to predict is a
> nominal variable, taking the values 0, 1 and 2. The
> independent variables are quite a few, some of them
> nominal, some not. I know about regression
> coefficients, intercepts, and all that jazz. I'm not
> sure, though, how I should use the coefficients and
> intercepts I got in the output. Why are there two
> different coefficients per variable? When should I use
> which? How should I interpret the output of the
> regression function? Should the output be rounded to
> the nearest integer, which would happen to be <=0, 1
> or >=2 -> I can decide which the prediction is? Or am
> I missing some fine points in this particular field of
> math I'm (admittedly somewhat blindfolded) messing
> around in?
>
> I'm grateful for any help, or any pointers to good
> sources on the web. I don't have any problems with
> reading theory - it's just that I don't have any
> theory to read!
>
> Thanks a lot in advance,
>
>    Mike
>
> __________________________________________________
>
> Check out Yahoo! Shopping and Yahoo! Auctions for all of
> your unique holiday gifts! Buy at http://shopping.yahoo.com
> or bid at http://auctions.yahoo.com
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec 12 12:44:02 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 12 Dec 2001 12:44:02 +0100
Subject: [R] f-test
In-Reply-To: <AOcIbBAyqyF8EwA0@myatt.demon.co.uk>
References: <3C16A02B.8020204@cropdesign.com>
	<AOcIbBAyqyF8EwA0@myatt.demon.co.uk>
Message-ID: <x27krs3bp9.fsf@blueberry.kubism.ku.dk>

Mark Myatt <mark at myatt.demon.co.uk> writes:

> Rik Bradt <rik.bradt at cropdesign.com> writes:
> >Hello,
> >
> >I'm using R to do statistics on datasets, and now I need an f-test, 
> >which I can't find in R.
> >Is there such a thing as an f-test. T-test seems to work fine, but ..
> 
> It all depends on what you mean by an 'F test' since there are numerous
> tests for all sorts of things that share that name. The function
> var.test() compares variances as an F test. The aov() function also does
> an F test on the significance of individual variables in an analysis of
> variance model. See help(var.test) and help(aov) for more details.

I think help(oneway.test) is likely to be more on target. Also
help(lm) for linear models and help(anova.lm) for F testing between
them. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From MSchwartz at medanalytics.com  Wed Dec 12 14:27:57 2001
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 12 Dec 2001 07:27:57 -0600
Subject: [R] Re: R-Help List Transmit Time
In-Reply-To: <15383.3837.740775.293817@gargle.gargle.HOWL>
Message-ID: <000901c18310$d0d4b1c0$0201a8c0@Marc>

> on the other hand, it's not so bad if people get time to think
> sometimes even before posting .. :-)
> 
> Your list maintainer,
> Martin Maechler

Quite true.  Thanks for the reply.

Marc

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Wed Dec 12 14:36:39 2001
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 12 Dec 2001 08:36:39 -0500
Subject: [R] Output from the multinom-function
In-Reply-To: <20011212105849.77631.qmail@web20504.mail.yahoo.com>
Message-ID: <5.1.0.14.2.20011212083252.01d7b230@mcmail.cis.mcmaster.ca>

Dear Mike,

I have some lecture notes on logistic regression, available at 
<http://socserv.socsci.mcmaster.ca/jfox/Courses/soc740/chap15-overheads.pdf>, 
which briefly describe the multinomial logit model; look in the section on 
modeling polytomous data. You'd probably do well to read a text that covers 
the subject; J. Long, Regression Models for Categorical and Limited 
Dependent Variables (Sage, 1997) is quite accessible.

John

At 02:58 AM 12/12/2001 -0800, Hoodoo Gooroo wrote:
>Hello folks,
>
>Let me first apologize: I'm not a professional nor a
>mathematician, just an ordinary guy, fooling around
>with the excellent R-package. I know the basic
>principles behind statistics, but haven't read
>anything more advanced than the ordinary first
>probability and statistics courses.
>
>Enough disclaimers? Good! I was examining the
>multinom-function (in the nnet-package) the other day
>and run a couple of tests. This is part of an output I
>got.
>
>multinom(formula = result ~., data = info)
>
>Coefficients:
>    (Intercept) PH          WH
>1  -0.3974387  0.02201908 -0.0009618038
>2   2.5183566 -0.07076967 -0.0596189836
>
>The variable result I was trying to predict is a
>nominal variable, taking the values 0, 1 and 2. The
>independent variables are quite a few, some of them
>nominal, some not. I know about regression
>coefficients, intercepts, and all that jazz. I'm not
>sure, though, how I should use the coefficients and
>intercepts I got in the output. Why are there two
>different coefficients per variable? When should I use
>which? How should I interpret the output of the
>regression function? Should the output be rounded to
>the nearest integer, which would happen to be <=0, 1
>or >=2 -> I can decide which the prediction is? Or am
>I missing some fine points in this particular field of
>math I'm (admittedly somewhat blindfolded) messing
>around in?
>
>I'm grateful for any help, or any pointers to good
>sources on the web. I don't have any problems with
>reading theory - it's just that I don't have any
>theory to read!
>
>Thanks a lot in advance,
>
>    Mike

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mmiller3 at iupui.edu  Wed Dec 12 16:27:38 2001
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: 12 Dec 2001 10:27:38 -0500
Subject: [R] Graphics with moderately large amounts of data
In-Reply-To: <6158D207D4D4D311B16700508B44026AFCD5B1@exchange.commerce.ubc.ca>
References: <6158D207D4D4D311B16700508B44026AFCD5B1@exchange.commerce.ubc.ca>
Message-ID: <871yi0cvbp.fsf@lumen.med.iupui.edu>

>>>>> "Frank," == Frank, Murray <murray.frank at commerce.ubc.ca> writes:

    > I am working with a moderately large data set -- the order
    > of magnitude is 180,000 observations by 50 variables. There
    > seem to be standard problems that I keep bumping into in
    > the graphics: eg. the graphics work hard to accomodate
    > outliers leaving the main action area a thick cloud, very
    > slow operations by R, etc. I have been doing some obvious
    > things to deal with these issues, eg. trimming, restricting
    > attention to data subsamples, etc.

I don't know of an appropriate FAQ to refer you to.  The issue of
outliers can be dealt with by setting the plotting limits with
xlim and ylim.  This might be faster than trimming the data set.

As far as graphics speed goes, a non-R possibility for faster
plotting of large data sets is root (http://root.cern.ch).
(Caveat: I've used root for large data sets (~10^6 measurements
of many parameters) and I have not used R for data sets larger
than several thousand measurements of a dozen or so parameters.
I have not made a direct comparison with large data sets - YMMV.)

Mike
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Matthias.Fischer at wiso.uni-erlangen.de  Wed Dec 12 18:22:15 2001
From: Matthias.Fischer at wiso.uni-erlangen.de (Matthias Fischer)
Date: Wed, 12 Dec 2001 18:22:15 +0100
Subject: [R] dos 
Message-ID: <3C17A057.27145.22BFCE7@localhost>

Dear all,

is there a R-command similar to "dos" in S-Plus?

Thanks,

M. Fischer
Dr. Matthias Fischer
Friedrich-Alexander-Universit?t Erlangen-N?rnberg
Lehrstuhl f?r Statistik und ?konometrie
Lange Gasse 20
90403 N?rnberg
Telefon: 0911 / 5302-271
Telefax: 0911 / 5302-277
E-Mail: Matthias.Fischer at wiso.uni-erlangen.de
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec 12 18:37:39 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Dec 2001 17:37:39 +0000 (GMT)
Subject: [R] dos 
In-Reply-To: <3C17A057.27145.22BFCE7@localhost>
Message-ID: <Pine.LNX.4.31.0112121735020.4306-100000@gannet.stats>

On Wed, 12 Dec 2001, Matthias Fischer wrote:

> is there a R-command similar to "dos" in S-Plus?

On Windows, I presume?

Try ?shell.  That's a nearer equivalent than ?system.

For what it is worth, dos() in S-PLUS has been superseded for quite a
while.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From heberto.ghezzo at mcgill.ca  Wed Dec 12 19:39:02 2001
From: heberto.ghezzo at mcgill.ca (Heberto Ghezzo)
Date: Wed, 12 Dec 2001 13:39:02 -0500
Subject: [R] again evaluations
Message-ID: <3C17A446.600D5783@mcgill.ca>

Hello, I wrote the following function to compute multiple comparisons in
a one way anova and randomized blocks anova.

aov1 <- function(y,g,s=NULL,comp="mca",meth="Sidak") {
#
  fun <- function(x)
    c(mean(x,na.rm=T),sd(x,na.rm=T),length(x[!is.na(x)]))
#
  li <- length(unique(g))
  cat("   Analysis of Variance with Multiple comparisons\n\n")
  cat(" Groups : ",li,"\n")
  t <- tapply(y,g,fun)

  a <- array(c(t,recursive=T),c(3,li))
  dimnames(a) <- list(c("Mean","S.Dev","n"),1:li)
  df <- length(y)-li
  cat(" Means : ",a[1,],"\n")
  cat(" S.Dev : ",a[2,],"\n")
  cat("  n    : ",a[3,],"\n\n")
#
  if(is.null(s)) {
    b <- aov(y ~ as.factor(g))
    d <- summary(b)
    df <- b$df
    e <- d[[1]][3]
    sig <- e[[1]][2]
  }
  if(!is.null(s)) {
    b <- aov(y ~ as.factor(g) + Error(as.factor(s)))
    d <- summary(b)
    df <- b$Within[8]
    e <- sqrt(d[[2]][[1]][3])
    sig <- unlist(e[[1]][2])
  }
  cat("   Anova \n")
  print(d)
  cat("\n")
  b <- multicmp(a[1,],a[3,],sig,df.residual=df,method=meth)
  print(b$table)
}
If I call "aov1(x,g)" everything works as expected but with
"aov1(x,g,s=s)" or "aov1(x,g,s)" I get the error

Error in eval(expr, envir, enclos) : Object "y" not found
>
I am using R 1.3.1 on Win98. Can somebody explain why adding a parameter
makes the first parameter invisible?
Thanks

Heberto Ghezzo
Meakins-Christie Labs
McGill University
Montreal - Canada


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matthew.norton at UMontreal.CA  Wed Dec 12 20:51:13 2001
From: matthew.norton at UMontreal.CA (Matthew Norton)
Date: Wed, 12 Dec 2001 14:51:13 -0500
Subject: [R] question about performance on different operating systems
Message-ID: <200112121949.fBCJnv223615189@jason.MAGELLAN.UMontreal.CA>

I have  a quick question for the gang.

I'm running a batch of simulations on a number of different computers, and 
have noticed that certain systems seem to run much more slowly than others. A 
rough calculation leads me to think that R for the Macintosh is running at 
_least_ 10 times more slowly than under linux.

To give you an idea, to run a small number of simulations takes around 80 
seconds on my laptop (running Debian linux, 200MHz processor, 112 megs RAM) 
while the same batch takes upwards of 10 minutes on a powermacintosh G4 
(350MHz and 128 megs of RAM).

Out of curiosity, is this unexpected, or can that sort of performance hit be 
normal when changing operating systems.

Matthew Norton
Dept. Biological Sciences
Universite de Montreal
Canada.

p.s. I'll run the same check on my windows desktop at home, and let you all 
know its speed.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From MSchwartz at medanalytics.com  Wed Dec 12 20:50:37 2001
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 12 Dec 2001 13:50:37 -0600
Subject: [R] dos 
In-Reply-To: <3C17A057.27145.22BFCE7@localhost>
Message-ID: <000b01c18346$46103060$0201a8c0@Marc>

> Dear all,
> 
> is there a R-command similar to "dos" in S-Plus?
> 
> Thanks,
> 
> M. Fischer

I believe that "shell.exec()" is the command that you are looking for.

Marc

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec 12 21:29:52 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Dec 2001 20:29:52 +0000 (GMT)
Subject: [R] question about performance on different operating systems
In-Reply-To: <200112121949.fBCJnv223615189@jason.MAGELLAN.UMontreal.CA>
Message-ID: <Pine.LNX.4.31.0112122024020.4440-100000@gannet.stats>

On Wed, 12 Dec 2001, Matthew Norton wrote:

> I have  a quick question for the gang.
>
> I'm running a batch of simulations on a number of different computers, and
> have noticed that certain systems seem to run much more slowly than others. A
> rough calculation leads me to think that R for the Macintosh is running at
> _least_ 10 times more slowly than under linux.
>
> To give you an idea, to run a small number of simulations takes around 80
> seconds on my laptop (running Debian linux, 200MHz processor, 112 megs RAM)
> while the same batch takes upwards of 10 minutes on a powermacintosh G4
> (350MHz and 128 megs of RAM).
>
> Out of curiosity, is this unexpected, or can that sort of performance hit be
> normal when changing operating systems.
>
> Matthew Norton
> Dept. Biological Sciences
> Universite de Montreal
> Canada.
>
> p.s. I'll run the same check on my windows desktop at home, and let you all
> know its speed.

In my experience R under Windows is about 10-20% slower than Linux on the
same box. We know about 5% of the difference (polling vs interrupts) and
th rest seems to be down to compiler quality (yes, they are both i686 gcc,
but still not too similar compilers often giving different answers).

A lot of this is down to the performance of the memory manager, which R
uses hard, and we had to replace on Windows at 1.2.0 not to take a big hit
(ca 3x).  Is this classic MacOS or MacOS X, and if the latter, which port?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matthew.norton at UMontreal.CA  Wed Dec 12 21:40:44 2001
From: matthew.norton at UMontreal.CA (Matthew Norton)
Date: Wed, 12 Dec 2001 15:40:44 -0500
Subject: [R] question about performance on different operating systems
In-Reply-To: <Pine.LNX.4.31.0112122024020.4440-100000@gannet.stats>
References: <Pine.LNX.4.31.0112122024020.4440-100000@gannet.stats>
Message-ID: <200112122039.fBCKdS223697421@jason.MAGELLAN.UMontreal.CA>

On Wednesday 12 December 2001 15:29, Prof Brian Ripley wrote:
> On Wed, 12 Dec 2001, Matthew Norton wrote:
> > I have  a quick question for the gang.
> >
> > I'm running a batch of simulations on a number of different computers,
> > and have noticed that certain systems seem to run much more slowly than
> > others. A rough calculation leads me to think that R for the Macintosh is
> > running at _least_ 10 times more slowly than under linux.
> >
> > To give you an idea, to run a small number of simulations takes around 80
> > seconds on my laptop (running Debian linux, 200MHz processor, 112 megs
> > RAM) while the same batch takes upwards of 10 minutes on a powermacintosh
> > G4 (350MHz and 128 megs of RAM).
> >
> > Out of curiosity, is this unexpected, or can that sort of performance hit
> > be normal when changing operating systems.
> >
> > Matthew Norton
> > Dept. Biological Sciences
> > Universite de Montreal
> > Canada.
> >
> > p.s. I'll run the same check on my windows desktop at home, and let you
> > all know its speed.
>
> In my experience R under Windows is about 10-20% slower than Linux on the
> same box. We know about 5% of the difference (polling vs interrupts) and
> th rest seems to be down to compiler quality (yes, they are both i686 gcc,
> but still not too similar compilers often giving different answers).
>
> A lot of this is down to the performance of the memory manager, which R
> uses hard, and we had to replace on Windows at 1.2.0 not to take a big hit
> (ca 3x).  Is this classic MacOS or MacOS X, and if the latter, which port?


This is MacOS 9.1. As to the windows machine, it did seem a little more 
sluggish than my linux machine, but it is much more powerful and thus a 
little perfomance hit is unnoticeable to me.  I'll test out the speed of the 
windows machine at home this evening, and let you know about relative 
performance (should you care to; if not, feel free to aggresively delete the 
email).

Matthew
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec 12 22:52:14 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 12 Dec 2001 22:52:14 +0100
Subject: [R] question about performance on different operating systems
In-Reply-To: <Pine.LNX.4.31.0112122024020.4440-100000@gannet.stats>
References: <Pine.LNX.4.31.0112122024020.4440-100000@gannet.stats>
Message-ID: <x2667cp0mp.fsf@blueberry.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> In my experience R under Windows is about 10-20% slower than Linux on the
> same box. We know about 5% of the difference (polling vs interrupts) and
> th rest seems to be down to compiler quality (yes, they are both i686 gcc,
> but still not too similar compilers often giving different answers).

More likely library differences, I'd say. The actual compiled
instructions should be pretty much identical. Plus whatever weird
things are going on behind the scenes on Windows (and context switches
are extremely slow, at least on Win9x, so any amount of background
processing will detract from overall performance).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From s.mcclatchie at niwa.cri.nz  Wed Dec 12 23:19:42 2001
From: s.mcclatchie at niwa.cri.nz (S.McClatchie)
Date: Thu, 13 Dec 2001 11:19:42 +1300
Subject: [R] corrupted data/ naive fix that worked
Message-ID: <3C188ECE.23924.4704CA3@localhost>

System info:
R Version 1.3.1  (2001-08-31) on Windows 2000
ESS v. 5.1.18 using emacs ver. 20.7.1

Colleagues,

On 11 Dec 2001,, R-help Digest wrote (re: R-help Digest V2 #598): 

> Apparently, the system shutdown has hurt the .RData file
> somehow. Is there a way of restoring the information at
> least partially without too much trouble? 

I have occassionally had a corrupted .RData file which initially seemed 
disastrous, but was fairly easily (if tediously) fixed.

(1) I renamed the .RData and .Rhistory files (old.RData etc.)

(2) in the R-src subdirectory I found the scripts I needed to reload (e.g 
smc.multiple.regression.Hg.weight.3.R or 
smc.multiple.regression.Hg.weight.3.R~). They are ascii so you can just 
use a text editor to find what you need.

(3)  I loaded the R-objects back into the workspace one by one (using 
Control C-D under ESS). Strip the filename (smc. 
multiple.regression.Hg.weight.3.R) of the prefix and suffix (smc. and the 
.R) (i.e. Ctrl C-D multiple.regression.Hg.weight.3). Then submit the file 
(using CTRL C-L).
You will now have that object in the workspace:
> objects()
[1] "multiple.regression.Hg.weight.3"
> 

(4)  When I exited R or do a save.image() the .RData was recreated.

This is far from elegant, but when I had done something foolish, it saved 
my bacon.

Best wishes

Sam

Sam McClatchie, 
Research scientist (fisheries acoustics))))))))))

NIWA (National Institute of Water & Atmospheric Research Ltd)
Postal address: PO Box 14 901, Kilbirnie, Wellington, New Zealand. 

Street address: 301 Evans Bay Parade, Greta Point, 6003 Wellington, New Zealand.

Email: s.mcclatchie at niwa.cri.nz, 
phone 64-04-386-0574, FAX: 64-4-386 0574. 

                    /\
...>><xX(?> // \\
                 /// \\\   
                //// \\\\
               ///  <?)Xx><<
              /////  \\\\\\
        ><(((?>   
  >><(((?>   ...>><xX(?>O<?)Xx><<

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From phgrosje at ulb.ac.be  Thu Dec 13 08:58:12 2001
From: phgrosje at ulb.ac.be (Philippe Grosjean)
Date: Thu, 13 Dec 2001 08:58:12 +0100
Subject: [R] question about performance on different operating systems
In-Reply-To: <x2667cp0mp.fsf@blueberry.kubism.ku.dk>
Message-ID: <MABBLJDICACNFOLGIHJOIEPGCHAA.phgrosje@ulb.ac.be>

Objet : Re: [R] question about performance on different operating
systems


>Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> In my experience R under Windows is about 10-20% slower than Linux on the
> same box. We know about 5% of the difference (polling vs interrupts) and
> th rest seems to be down to compiler quality (yes, they are both i686 gcc,
> but still not too similar compilers often giving different answers).


It depends of course also which tasks are running behind the scene, and
Windows is installing a lot of stupid utilities to "make thinks easier". For
instance, by default, the system regularly checks the CD-rom drive(s) (every
second or so) to detect if a new CD-rom is inserted and to possibly run an
autoexecutable on it. In comparison, on Linux, you have to explicitly mount
the CD. If someone install Adapted DirectCD to write directly on CD-R(W), it
further look at the CD-writer at regular intervals. The same for Iomega
utilities for the Zip/Jaz drives, etc, etc, etc.

Anyway, it is a fact that Linux is faster than Windows on the same box.
However, a 10-20% difference between systems seems acceptable to me. On the
other hand, if R is 10 times slower under MacOS 9.1, it is important to
know. In this case, there are chances that its performances are quite
similar to Linux under MacOS X. If this is the case, I believe it is
critical to warn the user and avise him to install R under MacOS X
preferrably on a Mac box.

Philippe Grosjean


..........]<(({?<...............<?}))><...............................
 ) ) ) ) )	 __               	 __
( ( ( ( ( 	|__)              	|  _
 ) ) ) ) )	|   hilippe       	|__)rosjean
( ( ( ( ( 	Marine Biol. Lab., ULB, Belgium
 ) ) ) ) )	                  	 __
( ( ( ( ( 	|\  /|            	|__)
 ) ) ) ) )	| \/ |ariculture &	|__)iostatistics
( ( ( ( (
 ) ) ) ) )	e-mail: phgrosje at ulb.ac.be or phgrosjean at sciviews.org
( ( ( ( ( 	SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )      tel: 00-32-2-650.29.70 (lab), 00-32-2-673.31.33 (home)
( ( ( ( (
 ) ) ) ) )      "I'm 100% confident that p is between 0 and 1"
( ( ( ( (                                  L. Gonick & W. Smith (1993)
 ) ) ) ) )
.......................................................................


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 13 09:22:27 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Dec 2001 08:22:27 +0000 (GMT)
Subject: [R] question about performance on different operating systems
In-Reply-To: <MABBLJDICACNFOLGIHJOIEPGCHAA.phgrosje@ulb.ac.be>
Message-ID: <Pine.LNX.4.31.0112130803240.6352-100000@gannet.stats>

On Thu, 13 Dec 2001, Philippe Grosjean wrote:

> Objet : Re: [R] question about performance on different operating
> systems
>
>
> >Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
>
> > In my experience R under Windows is about 10-20% slower than Linux on the
> > same box. We know about 5% of the difference (polling vs interrupts) and
> > th rest seems to be down to compiler quality (yes, they are both i686 gcc,
> > but still not too similar compilers often giving different answers).
>
>
> It depends of course also which tasks are running behind the scene, and
> Windows is installing a lot of stupid utilities to "make thinks easier". For
> instance, by default, the system regularly checks the CD-rom drive(s) (every
> second or so) to detect if a new CD-rom is inserted and to possibly run an
> autoexecutable on it. In comparison, on Linux, you have to explicitly mount
> the CD. If someone install Adapted DirectCD to write directly on CD-R(W), it
> further look at the CD-writer at regular intervals. The same for Iomega
> utilities for the Zip/Jaz drives, etc, etc, etc.

I was comparing CPU time for the R process, not elapsed time (but the R
process does manage to use practically 100%).  Linux has considerably more
system processes running than Windows, and AFAIK on current Windows (that
is, NT-based)  the things you describe are driven by interrupts and not by
polling.  Certainly I see no significant resources going on system
activities, even less so than on Linux.  (Most of my timings are on
a dual-CPU machine where the other CPU can do the system tasks, anyway.)

Peter was right to raise the issue of the run-time system (`library').
That is a difference, but Visual C++ definitely creates faster code using
the same run-time as i586-mingw-gcc, so there is room for improvement.
(I choose to build DLLs for S+6 using VC++ after quite a bit of
performance testing.)


> Anyway, it is a fact that Linux is faster than Windows on the same box.

It is at best an empirically supported observation.

> However, a 10-20% difference between systems seems acceptable to me. On the
> other hand, if R is 10 times slower under MacOS 9.1, it is important to
> know. In this case, there are chances that its performances are quite
> similar to Linux under MacOS X. If this is the case, I believe it is
> critical to warn the user and avise him to install R under MacOS X
> preferrably on a Mac box.

That's only likely to be true for the MacOS X port of R.  One of my recent
visitors was using Stefano's port under MacOS X, and it did seem to be
slow and have memory management problems on quite modest tasks.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From amaitour at pasteur.fr  Thu Dec 13 11:42:40 2001
From: amaitour at pasteur.fr (Aboubakar Maitournam)
Date: Thu, 13 Dec 2001 11:42:40 +0100
Subject: [R] R workspace
Message-ID: <3C188620.E77B255B@pasteur.fr>


Dear all,

I m using  R version 1.3.1 under linux (Red Hat).
When i left my session, naturally i have the question
Save workspace image? [y/n/c]?
I said n because I want to remove all the contain of my workspace.
Then I left R with q().

When I open new session I have the R welcome message and
[previously save workspace restored]. By typing ls() I find
what I have normally removed and I want to remove.
I have try rm(" "). But every time I open R session I find the objects.

Thanks in advance.

Aboubakar Maitournam.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plummer at iarc.fr  Thu Dec 13 12:23:51 2001
From: plummer at iarc.fr (Martyn Plummer)
Date: Thu, 13 Dec 2001 12:23:51 +0100 (CET)
Subject: [R] R workspace
In-Reply-To: <3C188620.E77B255B@pasteur.fr>
Message-ID: <XFMail.20011213122351.plummer@iarc.fr>

On 13-Dec-2001 Aboubakar Maitournam wrote:
> 
> Dear all,
> 
> I m using  R version 1.3.1 under linux (Red Hat).
> When i left my session, naturally i have the question
> Save workspace image? [y/n/c]?
> I said n because I want to remove all the contain of my workspace.
> Then I left R with q().

Answering "y" will save the changes you have made to your
workspace in the current session.  Answering "n" will not
save them, but any previously saved workspace will still be
there on disk, and will be loaded in the next session.
 
> When I open new session I have the R welcome message and
> [previously save workspace restored]. By typing ls() I find
> what I have normally removed and I want to remove.
> I have try rm(" "). But every time I open R session I find the objects.

This in the FAQ. Type

rm(list=ls(all=TRUE))

When you quit, answer "y" when asked if you want to save your workspace!
Martyn
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jniesch at gwdg.de  Thu Dec 13 12:33:54 2001
From: jniesch at gwdg.de (Jens Nieschulze)
Date: Thu, 13 Dec 2001 12:33:54 +0100 (MET)
Subject: [R] R workspace
In-Reply-To: <3C188620.E77B255B@pasteur.fr>
Message-ID: <Pine.SO4.4.10.10112131230330.11571-100000@ufobi7.uni-forst.gwdg.de>

On Thu, 13 Dec 2001, Aboubakar Maitournam wrote:

%
%Dear all,
%
%I m using  R version 1.3.1 under linux (Red Hat).
%When i left my session, naturally i have the question
%Save workspace image? [y/n/c]?
%I said n because I want to remove all the contain of my workspace.
%Then I left R with q().
%
%When I open new session I have the R welcome message and
%[previously save workspace restored]. By typing ls() I find
%what I have normally removed and I want to remove.

the question Save workspace [y/n/c]
pertains only to objects created from the last save.image() on
or created after starting the last session
"old" objects are not affected

%I have try rm(" "). But every time I open R session I find the objects.

rm(list=ls(all=TRUE))
should remove all antries

	JN
%
%Thanks in advance.
%
%Aboubakar Maitournam.
%
%-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
%r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
%Send "info", "help", or "[un]subscribe"
%(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
%_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
%

***********************************************************************
Jens Nieschulze


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From amaitour at pasteur.fr  Thu Dec 13 12:34:43 2001
From: amaitour at pasteur.fr (Aboubakar Maitournam)
Date: Thu, 13 Dec 2001 12:34:43 +0100
Subject: [R] R workspace
References: <3C188620.E77B255B@pasteur.fr> <3C188E10.1704E921@ozemail.com.au>
Message-ID: <3C189253.5843FFE3@pasteur.fr>

>

> Dear all,

thank you for your answers.

Aboubakar Maitournam.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec 13 13:28:12 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 13 Dec 2001 13:28:12 +0100
Subject: [R] R workspace
In-Reply-To: <3C189253.5843FFE3@pasteur.fr>
References: <3C188620.E77B255B@pasteur.fr> <3C188E10.1704E921@ozemail.com.au>
	<3C189253.5843FFE3@pasteur.fr>
Message-ID: <x2wuzrticj.fsf@blueberry.kubism.ku.dk>

Aboubakar Maitournam <amaitour at pasteur.fr> writes:

> thank you for your answers.

I'm slightly surprised though that noone suggested removing (or
renaming) the .RData file before starting R.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Thu Dec 13 14:31:16 2001
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Thu, 13 Dec 2001 14:31:16 +0100
Subject: [R] R workspace
References: <3C188620.E77B255B@pasteur.fr>
Message-ID: <3C18ADA4.E0AC35FC@psy.uni-muenchen.de>

Aboubakar Maitournam wrote:
> 
> Dear all,
> 
> I m using  R version 1.3.1 under linux (Red Hat).
> When i left my session, naturally i have the question
> Save workspace image? [y/n/c]?
> I said n because I want to remove all the contain of my workspace.
> Then I left R with q().
> 
> When I open new session I have the R welcome message and
> [previously save workspace restored]. By typing ls() I find
> what I have normally removed and I want to remove.
> I have try rm(" "). But every time I open R session I find the objects.

Try rm(list=ls()), that should delete all objects in your workspace.
When you quit R, you should save your workspace, because otherwise the
old image saved from the last session will be loaded (where your old
objects are stored). 

By, Sven
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Setzer.Woodrow at epamail.epa.gov  Thu Dec 13 14:49:42 2001
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Thu, 13 Dec 2001 08:49:42 -0500
Subject: [R] R-1.4.0: how to use getSymbolInfo()?
Message-ID: <OFADB8BEAA.D5EEFB53-ON85256B21.004A4F54@rtp.epa.gov>

I have a package that solves systems of ordinary differential equations
coded as an R function (odesolve, on CRAN).  The function is passed to R
code, and c and Fortran code called by it uses lang4() and eval() to
evaluate the R function inside a compiled c function to use in a
compiled ODE solver.  This works quite well, but can be slow.

I'd like to be able to supply the name of a compiled function,
dynamically loaded into the current session, and pass either the name of
the function or a pointer to it to my R code, which would then pass it
down to the compiled code to use in the ode solver directly.

Since getSymbolInfo() (new in 1.4.0) returns a pointer to the requested
loaded function, it would seem to be part of the answer to my problem
(when I asked this question some time ago, I was warned away from using
the internal R_FindSymbol() (declared in Rdynload.h) as being
potentially unstable).  However, I cannot figure out how to pass the
pointer through .Call or .External.  Is this possible, or should I pass
a string through to the compiled code, and find the pointer on that side
(and how to do that)?

Thanks.


R. Woodrow Setzer, Jr.                                            Phone:
(919) 541-0128
Experimental Toxicology Division                       Fax:  (919)
541-5394
Pharmacokinetics Branch
NHEERL MD-74; US EPA; RTP, NC 27711

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From poizot at intechmer.cnam.fr  Thu Dec 13 15:51:20 2001
From: poizot at intechmer.cnam.fr (Emmanuel POIZOT)
Date: Thu, 13 Dec 2001 15:51:20 +0100
Subject: [R] Problem to interpret wilcox.test
Message-ID: <3C18C068.5050206@intechmer.cnam.fr>

I've got two set of data :
22.45 21.56 20.48 19.59 21.52 = A
and
22.15 21.98 20.42 20.58 19.61 = B
I perform a wilcox.test on this two set
wilcox.test(A, B) and I'd this answer:

        Wilcoxon rank sum test

data:  A and B
W = 12, p-value = 1
alternative hypothesis: true mu is not equal to 0

Should I interpret that there is no difference between the two sets ?

-- 

Cordialement
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~ Emmanuel POIZOT
~ CNAM/INTECHMER
~ B.P. 324
~ 50103 CHERBOURG CEDEX
~ T?l : (33) 233 887 342
~ Fax : (33) 233 887 339
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec 13 16:01:36 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 13 Dec 2001 16:01:36 +0100
Subject: [R] Problem to interpret wilcox.test
In-Reply-To: <3C18C068.5050206@intechmer.cnam.fr>
References: <3C18C068.5050206@intechmer.cnam.fr>
Message-ID: <x2k7vrtb8v.fsf@blueberry.kubism.ku.dk>

Emmanuel POIZOT <poizot at intechmer.cnam.fr> writes:

> I've got two set of data :
> 22.45 21.56 20.48 19.59 21.52 = A
> and
> 22.15 21.98 20.42 20.58 19.61 = B
> I perform a wilcox.test on this two set
> wilcox.test(A, B) and I'd this answer:
> 
>         Wilcoxon rank sum test
> 
> data:  A and B
> W = 12, p-value = 1
> alternative hypothesis: true mu is not equal to 0
> 
> Should I interpret that there is no difference between the two sets ?

In a word, yes. No *detectable* difference that is. What the p-value
is saying is that there is no way of getting a W closer to the value
expected under the hypothesis of no difference (which is 12.5 in this
case).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Thu Dec 13 16:07:05 2001
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 Dec 2001 16:07:05 +0100
Subject: [R] Problem to interpret wilcox.test
References: <3C18C068.5050206@intechmer.cnam.fr>
Message-ID: <3C18C419.CE16D95C@statistik.uni-dortmund.de>

Emmanuel POIZOT wrote:
> 
> I've got two set of data :
> 22.45 21.56 20.48 19.59 21.52 = A
> and
> 22.15 21.98 20.42 20.58 19.61 = B
> I perform a wilcox.test on this two set
> wilcox.test(A, B) and I'd this answer:
> 
>         Wilcoxon rank sum test
> 
> data:  A and B
> W = 12, p-value = 1
> alternative hypothesis: true mu is not equal to 0
> 
> Should I interpret that there is no difference between the two sets ?

Not really.
At least there is no significant difference - that's what you have
tested.

Uwe
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec 13 16:19:05 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 13 Dec 2001 16:19:05 +0100
Subject: [R] R-1.4.0: how to use getSymbolInfo()?
In-Reply-To: <OFADB8BEAA.D5EEFB53-ON85256B21.004A4F54@rtp.epa.gov>
References: <OFADB8BEAA.D5EEFB53-ON85256B21.004A4F54@rtp.epa.gov>
Message-ID: <x2g06ftafq.fsf@blueberry.kubism.ku.dk>

Setzer.Woodrow at epamail.epa.gov writes:

> I have a package that solves systems of ordinary differential equations
> coded as an R function (odesolve, on CRAN).  The function is passed to R
> code, and c and Fortran code called by it uses lang4() and eval() to
> evaluate the R function inside a compiled c function to use in a
> compiled ODE solver.  This works quite well, but can be slow.
> 
> I'd like to be able to supply the name of a compiled function,
> dynamically loaded into the current session, and pass either the name of
> the function or a pointer to it to my R code, which would then pass it
> down to the compiled code to use in the ode solver directly.
> 
> Since getSymbolInfo() (new in 1.4.0) returns a pointer to the requested
> loaded function, it would seem to be part of the answer to my problem
> (when I asked this question some time ago, I was warned away from using
> the internal R_FindSymbol() (declared in Rdynload.h) as being
> potentially unstable).  However, I cannot figure out how to pass the
> pointer through .Call or .External.  Is this possible, or should I pass
> a string through to the compiled code, and find the pointer on that side
> (and how to do that)?

We might want to take a more abstract view of this. Suppose, as part
of your dyn.loadable module, you also have a small wrapper function
that returns one of Luke's external pointer objects
(http://www.stat.umn.edu/~luke/R/references.html). That should be easy
to do via a .Call interface. Then in odesolve, if you get passed a
pointer object,  you unwrap it and then you can do (*f)(x) to your
heart's content.

Does this sound right?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Setzer.Woodrow at epamail.epa.gov  Thu Dec 13 17:19:21 2001
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Thu, 13 Dec 2001 11:19:21 -0500
Subject: [R] R-1.4.0: how to use getSymbolInfo()?
Message-ID: <OFB307A3E9.7FC6813B-ON85256B21.0055B93C@rtp.epa.gov>


Welll, getSymbolInfo() returns a list that includes an external pointer
object.  I guess my question is, how to unwrap it in the c code so that
I can use it as (*f)()?

R. Woodrow Setzer, Jr.                                            Phone:
(919) 541-0128
Experimental Toxicology Division                       Fax:  (919)
541-5394
Pharmacokinetics Branch
NHEERL MD-74; US EPA; RTP, NC 27711

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pauljohn at ku.edu  Thu Dec 13 18:14:03 2001
From: pauljohn at ku.edu (Paul E Johnson)
Date: Thu, 13 Dec 2001 11:14:03 -0600
Subject: [R] emacs 21.1, R-1.3.1, and ESS
Message-ID: <3C18E1DB.4050608@ku.edu>

On RedHat linux 7.2, I upgraded (?) Emacs and R at the same time and now 
I'm getting some funny business with R and ESS. I reinstalled ESS from 
the tarball and re-byte-compiled.  In particular, help.start() does 
work, and ESS works to send text regions to the R process, but ?function 
does not return anything, and the status line says

"ESS process not ready.  Finish your command before trying again."

Is this more likely a 1) known problem or 2) result of my poor 
installation of Emacs, R, or ESS?
-- 
Paul E. Johnson                       email: pauljohn at ukans.edu
Dept. of Political Science            http://lark.cc.ukans.edu/~pauljohn
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66045                FAX: (785) 864-5700

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Thu Dec 13 18:41:00 2001
From: rossini at blindglobe.net (A.J. Rossini)
Date: 13 Dec 2001 09:41:00 -0800
Subject: [R] question about performance on different operating systems
In-Reply-To: <MABBLJDICACNFOLGIHJOIEPGCHAA.phgrosje@ulb.ac.be>
References: <MABBLJDICACNFOLGIHJOIEPGCHAA.phgrosje@ulb.ac.be>
Message-ID: <877krrqaqb.fsf@jeeves.blindglobe.net>

>>>>> "PG" == Philippe Grosjean <phgrosje at ulb.ac.be> writes:

    PG> Anyway, it is a fact that Linux is faster than Windows on the
    PG> same box. 

As much as I dislike using Microsoft OSs for development and
simulation work, this is just flat out wrong.  It is a fact that for
particular situations and contexts, Linux might be faster, but not
universally, not even in a general context such as "working with R".
It should be a bit more specific than that.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   T-Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
Rosen: (Mullins' Lab) Fridays, and I'm unreachable except by email.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Thu Dec 13 18:44:21 2001
From: rossini at blindglobe.net (A.J. Rossini)
Date: 13 Dec 2001 09:44:21 -0800
Subject: [R] emacs 21.1, R-1.3.1, and ESS
In-Reply-To: <3C18E1DB.4050608@ku.edu>
References: <3C18E1DB.4050608@ku.edu>
Message-ID: <873d2fqakq.fsf@jeeves.blindglobe.net>

>>>>> "PEJ" == Paul E Johnson <Paul> writes:

    PEJ> Is this more likely a 1) known problem or 2) result of my
    PEJ> poor installation of Emacs, R, or ESS?

Known problem with Emacs 21.1.  Silly incompatible comint changes in
21.1 that weren't in the last beta-test release.  We need to rewrite
some process handling code for it.  I would suggest XEmacs at this
point, or backing down to Emacs 20.

Bad move, upgrading to it when most of the ESS developers are on
paternity leave (myself), fighting to release the new version of R
(Kurt/Martin), or closing out teaching or projects (Rich/Rodney).

We need to release the current set of fixes sometime, but not sure
when... 

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   T-Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
Rosen: (Mullins' Lab) Fridays, and I'm unreachable except by email.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Thu Dec 13 18:50:25 2001
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 13 Dec 2001 18:50:25 +0100
Subject: [R] again evaluations
In-Reply-To: <3C17A446.600D5783@mcgill.ca>
References: <3C17A446.600D5783@mcgill.ca>
Message-ID: <15384.60001.192076.651562@gargle.gargle.HOWL>

>>>>> "Heberto" == Heberto Ghezzo <heberto.ghezzo at mcgill.ca> writes:

    Heberto> Hello, I wrote the following function to compute
    Heberto> multiple comparisons in a one way anova and
    Heberto> randomized blocks anova.

    Heberto> aov1 <-
    Heberto>   function(y,g,s=NULL,comp="mca",meth="Sidak") { #
      .....
    Heberto> b <- multicmp(a[1,],a[3,],sig,df.residual=df,method=meth)
      ......

    Heberto> If I call "aov1(x,g)" everything
    Heberto> works as expected but with "aov1(x,g,s=s)" or
    Heberto> "aov1(x,g,s)" I get the error

    Heberto> Error in eval(expr, envir, enclos) : Object "y" not
    Heberto> found

we have no real chance of reproducing your problem.
you use `data' -- your "x" and "g" and "s" that we don't have
available and you use a function multicmp() which is not part of R
(which might be not called before the error though).

Typing  
      traceback()
after the error message would help potentially.

    Heberto> I am using R 1.3.1 on Win98. Can somebody explain
    Heberto> why adding a parameter makes the first parameter
    Heberto> invisible?  Thanks

well, it's a different model you are fitting,...

maybe you could use a data frame to pass to  aov(*, data = <data frame>)

    Heberto> Heberto Ghezzo Meakins-Christie Labs McGill
    Heberto> University Montreal - Canada
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Thu Dec 13 19:29:43 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Thu, 13 Dec 2001 13:29:43 -0500 (EST)
Subject: [R] emacs 21.1, R-1.3.1, and ESS
Message-ID: <200112131829.fBDITh621583@cattell.psych.upenn.edu>

Emacs 21.1 has other problems.  It may be good to wait for the
next version.  I tried setting it up, and gave up and went back
to version 20.7.

The trouble I had was with the icon bar.  Ugh.  Well, you can
remove it, but the geometry is set before the bar is removed, so
you need to make the geometry bigger to compensate.  But this
means that, if you like things big (as I do), the little window
at the bottom which asks you what directory you want, when you do
 emacs -f R,
is off the screen.

And the SGML mode - which I use a lot - wouldn't work for me.

[Don't tell me how to fix it.  I really am happy with 20.7.]

At that point I figured, "Well, I'll get this to work by reading
the manual."  BUT THERE IS NO MANUAL.   That is the real killer.
(There is on-line help, but it is too hard to go through it
looking for things.  What I want is something like
http://www.gnu.org/manual/emacs/ but for 21.1.)

In sum, I would not be the least upset if the ESS team said, "If
you want to use ESS, stick with Emacs 20.7 for a while."

Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Nick.Davis at treasury.govt.nz  Thu Dec 13 21:28:38 2001
From: Nick.Davis at treasury.govt.nz (Nick Davis)
Date: Fri, 14 Dec 2001 09:28:38 +1300
Subject: [R] Code for Hodrick-Prescott Filter: Special Case of smooth.
	spline?
Message-ID: <E1DB1E4A1D092145AE6D0F1FD6EFD0F502926BC4@gertrude.hamlet.treasury.govt.nz>

I've had a play with this and, due to my own short-comings, remain none the
wiser.

In particular, I'm not sure what value of 'spar' is consistent with the
magic lambda=1/1600 for quarterly data. 

I initially interpreted spar as lambda and tried setting spar=1/1600.  This
results in almost no smoothing while spar=1600 causes an error.  The
smooth.spline function seems to want something in the region of 0 to 1.  The
closer spar is to 1, the greater the smoothing.  A closer look at the R
documentation revealed that:

The computational lambda used (as a function of `spar') is lambda = r *
256^(3*spar - 1) where r = tr(X' W^2 X) / tr(Sigma), Sigma is the matrix
given by Sigma[i,j] = Integral B''[i](t) B''[j](t) dt, X is given by X[i,j]
= B[j](x[i]), W^2 is the diagonal matrix of scaled weights, `W = diag(w)/n'
(i.e., the identity for default weights), and B[k](.) is the k-th B-spline.

I admit to being a bit confused by the matrix algebra.  It appears to come
down to knowing 'r' so that 'spar' can be derived by imposing a constraint
on lambda.

If anyone can shed some light on this it would be much appreciated.  A
general answer would be nice as I don't always work with quarterly data.

Thanks & Regards,

Nick Davis

-----Original Message-----
From: Roger Koenker [mailto:roger at ysidro.econ.uiuc.edu]
Sent: Thursday, 6 December 2001 11:03 a.m.
To: Nick Davis
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Code for Hodrick-Prescott Filter


This is a special case of smooth.spline in modreg.


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Thu, 6 Dec 2001, Nick Davis wrote:

> Has anyone written any code for the Hodrick-Prescott filter?  I have a
some
> uncompiled FORTRAN code from Ed Prescott but I'd like to save myself some
> programming time if possible.  Thanks for your help.
>
> Nick Davis
> Crown Financial Policy
> Asset and Liability Management Branch
> The New Zealand Treasury
>
> Direct:         +64-4-471-5924
> Fax:            +64-4-499-0143
> Email:          mailto:nick.davis at treasury.govt.nz
> Web:            www.treasury.govt.nz
> Research:       www.treasury.govt.nz/workingpapers
>
>
> Caution: The content of this email is the property of The New Zealand
> Treasury. If you have received this message in error please notify the
> sender immediately and delete.  The content of this email does not
> necessarily reflect the views of The New Zealand Treasury.  If the
recipient
> has any concerns about the content of this email they should seek
> alternative confirmation from The New Zealand Treasury.
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011214/545123ae/attachment.html

From lakeland at atlas.otago.ac.nz  Thu Dec 13 21:42:37 2001
From: lakeland at atlas.otago.ac.nz (Corrin Lakeland)
Date: Fri, 14 Dec 2001 09:42:37 +1300 (NZDT)
Subject: [R] k-means with euclidian distance but no coordinates
Message-ID: <Pine.OSF.4.21.0112140846460.521655-100000@atlas.otago.ac.nz>

Hi,

I'm trying to build a thesaurus that will sensible values for rare words.  
I suspect the best algorithm to use is k-means although I'm not sure about
that -- I would have preferred a k dimensional space with a binary cluster
in each dimension so a word can belong to 0..k clusters, but I digress...

I can measure the strength of correlation between words fairly easily by
counting cooccurance divided by frequency of each word, giving a euclidian
distance, although this doesn't work especially well for rare words.  
However I don't have coordinates as such, and deriving them given distance
is non-trivial.

Now, as I understand k-means, it uses euclidian distance rather than
coordiantes, the first step given in texts is to derive the distance given
the coordinates. But I can't find a way to call the built in function
without coordinates.  I had a look at R-1.3.1/src/library/mva/src/kmns.f
but my Fortran isn't good and I had enough trouble following the code, so
I'm not up to making major changes.

Any help or ideas would be appreciated

Corrin
--
Corrin Lakeland <lakeland at cs.otago.ac.nz> 
Department of Computer Science
University of Otago, New Zealand


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 13 22:39:58 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Dec 2001 21:39:58 +0000 (GMT)
Subject: [R] k-means with euclidian distance but no coordinates
In-Reply-To: <Pine.OSF.4.21.0112140846460.521655-100000@atlas.otago.ac.nz>
Message-ID: <Pine.LNX.4.31.0112132136200.9828-100000@gannet.stats>

On Fri, 14 Dec 2001, Corrin Lakeland wrote:

> Hi,
>
> I'm trying to build a thesaurus that will sensible values for rare words.
> I suspect the best algorithm to use is k-means although I'm not sure about
> that -- I would have preferred a k dimensional space with a binary cluster
> in each dimension so a word can belong to 0..k clusters, but I digress...
>
> I can measure the strength of correlation between words fairly easily by
> counting cooccurance divided by frequency of each word, giving a euclidian
> distance, although this doesn't work especially well for rare words.
> However I don't have coordinates as such, and deriving them given distance
> is non-trivial.
>
> Now, as I understand k-means, it uses euclidian distance rather than
> coordiantes, the first step given in texts is to derive the distance given
> the coordinates. But I can't find a way to call the built in function
> without coordinates.  I had a look at R-1.3.1/src/library/mva/src/kmns.f
> but my Fortran isn't good and I had enough trouble following the code, so
> I'm not up to making major changes.

By definition K-means needs coordinates!  Try pam/clara in library
cluster.

I think you have a distance, but not a Euclidean (sic) one.  If you did
have a Euclidean distance, cmdscale would (easily) give you coordinates.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From roger at ysidro.econ.uiuc.edu  Thu Dec 13 23:09:58 2001
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Thu, 13 Dec 2001 16:09:58 -0600 (CST)
Subject: [R] Code for Hodrick-Prescott Filter: Special Case of smooth.
 spline?
In-Reply-To: <E1DB1E4A1D092145AE6D0F1FD6EFD0F502926BC4@gertrude.hamlet.treasury.govt.nz>
Message-ID: <Pine.GSO.4.33.0112131547220.2006-100000@ysidro.econ.uiuc.edu>

A general answer would be to forget the Hodrick-Prescott numerology for
lambda=1600, and use the spar parameter produced by smooth.spline's
GCV functionality.  Nevertheless, it would be nice for reproducibility
(comparison) reasons to be able to get the actual lambda corresponding
to spar.  My quick look at the code didn't yield an easy way to extract the
ratio: r = tr(X' W^2 X) / tr(Sigma), and thereby get back to lambda.
Maybe Brian could suggest something for this.

I might also note that the Hodrick Prescott setup would require that
you set all.knots=TRUE, since the default in smooth.spline
is to chose fewer knots.  The HP penalty assumes equally spaced x's
so the penalty is just the sum of the second differences of ghat.

For those of you (if any) who are wondering what the Hodrick-Prescott
filter is:  in effect it is the special case of the (Reinsch) cubic
smoothing spline for an equally spaced time series.  HP claim that
for (typical quarterly economic time-series) lambda can be chosen
to be 1600, and (amazingly) this has become a default smoother in some
circles of macroeconometrics.


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Fri, 14 Dec 2001, Nick Davis wrote:

> I've had a play with this and, due to my own short-comings, remain none the
> wiser.
>
> In particular, I'm not sure what value of 'spar' is consistent with the
> magic lambda=1/1600 for quarterly data.
>
> I initially interpreted spar as lambda and tried setting spar=1/1600.  This
> results in almost no smoothing while spar=1600 causes an error.  The
> smooth.spline function seems to want something in the region of 0 to 1.  The
> closer spar is to 1, the greater the smoothing.  A closer look at the R
> documentation revealed that:
>
> The computational lambda used (as a function of `spar') is lambda = r *
> 256^(3*spar - 1) where r = tr(X' W^2 X) / tr(Sigma), Sigma is the matrix
> given by Sigma[i,j] = Integral B''[i](t) B''[j](t) dt, X is given by X[i,j]
> = B[j](x[i]), W^2 is the diagonal matrix of scaled weights, `W = diag(w)/n'
> (i.e., the identity for default weights), and B[k](.) is the k-th B-spline.
>
> I admit to being a bit confused by the matrix algebra.  It appears to come
> down to knowing 'r' so that 'spar' can be derived by imposing a constraint
> on lambda.
>
> If anyone can shed some light on this it would be much appreciated.  A
> general answer would be nice as I don't always work with quarterly data.
>
> Thanks & Regards,
>
> Nick Davis
>
> -----Original Message-----
> From: Roger Koenker [mailto:roger at ysidro.econ.uiuc.edu]
> Sent: Thursday, 6 December 2001 11:03 a.m.
> To: Nick Davis
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Code for Hodrick-Prescott Filter
>
>
> This is a special case of smooth.spline in modreg.
>
>
> url:	http://www.econ.uiuc.edu		Roger Koenker
> email	roger at ysidro.econ.uiuc.edu		Department of Economics
> vox: 	217-333-4558				University of Illinois
> fax:   	217-244-6678				Champaign, IL 61820
>
> On Thu, 6 Dec 2001, Nick Davis wrote:
>
> > Has anyone written any code for the Hodrick-Prescott filter?  I have a
> some
> > uncompiled FORTRAN code from Ed Prescott but I'd like to save myself some
> > programming time if possible.  Thanks for your help.
> >
> > Nick Davis
> > Crown Financial Policy
> > Asset and Liability Management Branch
> > The New Zealand Treasury
> >
> > Direct:         +64-4-471-5924
> > Fax:            +64-4-499-0143
> > Email:          mailto:nick.davis at treasury.govt.nz
> > Web:            www.treasury.govt.nz
> > Research:       www.treasury.govt.nz/workingpapers
> >
> >
> > Caution: The content of this email is the property of The New Zealand
> > Treasury. If you have received this message in error please notify the
> > sender immediately and delete.  The content of this email does not
> > necessarily reflect the views of The New Zealand Treasury.  If the
> recipient
> > has any concerns about the content of this email they should seek
> > alternative confirmation from The New Zealand Treasury.
> >
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From P.S.Cowpertwait at massey.ac.nz  Thu Dec 13 23:38:11 2001
From: P.S.Cowpertwait at massey.ac.nz (Cowpertwait, Paul)
Date: Fri, 14 Dec 2001 11:38:11 +1300
Subject: [R] inconsistency between gamma and choose functions
Message-ID: <98B01D2717B9D411B38F0008C7840931070B55EF@its-xchg2.massey.ac.nz>

Please can someone explain why I seem to get these contradictory results?

choose(5,2)
[1] 10
gamma(6)/(gamma(3)*gamma(4))
[1] 10
gamma(6)/(gamma(3)*gamma(4)) == choose(5,2)
[1] TRUE
# all's well so far.

# now look what happens:
gamma(21)/(gamma(6)*gamma(16)) == choose(20,5)
[1] FALSE

# check individual terms:
gamma(21)/(gamma(6)*gamma(16))
[1] 15504
choose(20,5)
[1] 15504
# so they are the same, BUT we get FALSE when comparing - a contradiction!
gamma(21)/(gamma(6)*gamma(16)) == choose(20,5)
[1] FALSE

# the problem seems to have root in the gamma function, because:
choose(20,5)
[1] 15504
choose(20,5) == 15504
[1] TRUE
# but,
gamma(21)/(gamma(6)*gamma(16)) == 15504
[1] FALSE
# and yet ..
gamma(21)/(gamma(6)*gamma(16))
[1] 15504


# a function to 'compare' shows FALSE starts to appear when n >= 10. Why the
inconsistency?

compare <- function (n, k) choose(n,k) ==
gamma(n+1)/(gamma(k+1)*gamma(n-k+1))
compare(5,2)
[1] TRUE
compare(10,2)
[1] FALSE
compare(9,2)
[1] TRUE
compare(9,3)
[1] TRUE
#etc. 

_____________________________________

Paul S.P. Cowpertwait
IIMS, Massey University, Albany, 
Private Bag 102 904 
North Shore Mail Centre
Auckland, NZ
Tel (+64) (9) 443 9799 ext 9488

http://www.massey.ac.nz/~pscowper
_____________________________________
 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From P.S.Cowpertwait at massey.ac.nz  Thu Dec 13 23:48:38 2001
From: P.S.Cowpertwait at massey.ac.nz (Cowpertwait, Paul)
Date: Fri, 14 Dec 2001 11:48:38 +1300
Subject: [R] further to my last email
Message-ID: <98B01D2717B9D411B38F0008C7840931070B55F0@its-xchg2.massey.ac.nz>

.. the round function seems to get round it (excuse the pun):

> round(gamma(21)/(gamma(6)*gamma(16))) == round(choose(20,5))
[1] TRUE

So I presume the problem is related to gamma being a real function.
However, I'm still not sure why there's a break from TRUE to FALSE for
certain values.  Any comments would be appreciated!

_____________________________________

Paul S.P. Cowpertwait
IIMS, Massey University, Albany, 
Private Bag 102 904 
North Shore Mail Centre
Auckland, NZ
Tel (+64) (9) 443 9799 ext 9488

http://www.massey.ac.nz/~pscowper
_____________________________________
 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Dec 14 00:05:54 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 13 Dec 2001 15:05:54 -0800 (PST)
Subject: [R] inconsistency between gamma and choose functions
In-Reply-To: <98B01D2717B9D411B38F0008C7840931070B55EF@its-xchg2.massey.ac.nz>
Message-ID: <Pine.A41.4.33.0112131447240.120016-100000@homer04.u.washington.edu>

On Fri, 14 Dec 2001, Cowpertwait, Paul wrote:

> Please can someone explain why I seem to get these contradictory results?
>
> choose(5,2)
> [1] 10
> gamma(6)/(gamma(3)*gamma(4))
> [1] 10
> gamma(6)/(gamma(3)*gamma(4)) == choose(5,2)
> [1] TRUE
> # all's well so far.
>
> # now look what happens:
> gamma(21)/(gamma(6)*gamma(16)) == choose(20,5)
> [1] FALSE
>
> # check individual terms:
> gamma(21)/(gamma(6)*gamma(16))
> [1] 15504
> choose(20,5)
> [1] 15504
> # so they are the same, BUT we get FALSE when comparing - a contradiction!
> gamma(21)/(gamma(6)*gamma(16)) == choose(20,5)
> [1] FALSE

If you look at
> choose(20,5)-gamma(21)/(gamma(6)*gamma(16))
[1] -2.182787e-11
you see what is happening.

choose(20,5) is exactly 15504 -- eg check that
> choose(20,5)-15504==0
[1] TRUE
but the ratio of gamma functions involves some slight rounding error
> gamma(21)/(gamma(6)*gamma(16))-15504
[1] 2.182787e-11

Now if you look at the precision of double precision arithmetic
> Machine()$double.eps*15504
[1] 3.442580e-12

so the error is about 7 times machine resolution. This is pretty good, as
the numerator and denominator are both quite large.
> gamma(21)
[1] 2.432902e+18

Even given full 16-digit accuracy for gamma(x) the division would cause
some error. Furthermore in computing choose() we know that the result is
an integer, and so we round it (see src/nmath/choose.c). We can't do
this for the gamma function as it can be used for non-integer
arguments.

In fact there's another source of difference because choose() actually
uses the logarithm of the gamma function and exponentiates the result.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Fri Dec 14 02:37:16 2001
From: siim at obs.ee (Ott Toomet)
Date: Fri, 14 Dec 2001 02:37:16 +0100 (CET)
Subject: [R] inconsistency between gamma and choose functions
In-Reply-To: <98B01D2717B9D411B38F0008C7840931070B55EF@its-xchg2.massey.ac.nz>
Message-ID: <Pine.LNX.4.33.0112140222200.9851-100000@ecopc64.eco.au.dk>

Hi,

the problem is much more general than R and gamma().  There are two ways to
store numbers in computers -- as integers and as reals.  The integer
calculations are exact (so long you do not receive overflow), calculations
with real numbers generally isn't (gamma() works with real numbers).  The
precision is always finite and many of the nice mathematical formulas fail
to work.  You should never expect that sin(x)^2 + cos(x)^2 == 1 or
sqrt(x)^2 == x although it sometimes happens.  Rather than writing

if( real1 == real2) {

one should always consider

if( abs( real1 - real2) < very.small.number) {

This is a fundamental problem with digital computing but at least I do not
see any other efficent ways how the computers could work (I do not know much
about quantum computing, however).


Regards,

Ott Toomet




On Fri, 14 Dec 2001, Cowpertwait, Paul wrote:

> Please can someone explain why I seem to get these contradictory results?
>
> choose(5,2)
> [1] 10
> gamma(6)/(gamma(3)*gamma(4))
> [1] 10
> gamma(6)/(gamma(3)*gamma(4)) == choose(5,2)
> [1] TRUE
> # all's well so far.
>
> # now look what happens:
> gamma(21)/(gamma(6)*gamma(16)) == choose(20,5)
> [1] FALSE
>
> # check individual terms:
> gamma(21)/(gamma(6)*gamma(16))
> [1] 15504
> choose(20,5)
> [1] 15504
> # so they are the same, BUT we get FALSE when comparing - a contradiction!
> gamma(21)/(gamma(6)*gamma(16)) == choose(20,5)
> [1] FALSE
>
> # the problem seems to have root in the gamma function, because:
> choose(20,5)
> [1] 15504
> choose(20,5) == 15504
> [1] TRUE
> # but,
> gamma(21)/(gamma(6)*gamma(16)) == 15504
> [1] FALSE
> # and yet ..
> gamma(21)/(gamma(6)*gamma(16))
> [1] 15504
>
>
> # a function to 'compare' shows FALSE starts to appear when n >= 10. Why the
> inconsistency?
>
> compare <- function (n, k) choose(n,k) ==
> gamma(n+1)/(gamma(k+1)*gamma(n-k+1))
> compare(5,2)
> [1] TRUE
> compare(10,2)
> [1] FALSE
> compare(9,2)
> [1] TRUE
> compare(9,3)
> [1] TRUE
> #etc.
>
> _____________________________________
>
> Paul S.P. Cowpertwait
> IIMS, Massey University, Albany,
> Private Bag 102 904
> North Shore Mail Centre
> Auckland, NZ
> Tel (+64) (9) 443 9799 ext 9488
>
> http://www.massey.ac.nz/~pscowper
> _____________________________________
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec 14 07:15:30 2001
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 14 Dec 2001 06:15:30 +0000 (GMT)
Subject: [R] further to my last email
In-Reply-To: <98B01D2717B9D411B38F0008C7840931070B55F0@its-xchg2.massey.ac.nz>
Message-ID: <Pine.GSO.4.31.0112140613230.2243-100000@auk.stats>

On Fri, 14 Dec 2001, Cowpertwait, Paul wrote:

> .. the round function seems to get round it (excuse the pun):
>
> > round(gamma(21)/(gamma(6)*gamma(16))) == round(choose(20,5))
> [1] TRUE
>
> So I presume the problem is related to gamma being a real function.
> However, I'm still not sure why there's a break from TRUE to FALSE for
> certain values.  Any comments would be appreciated!

It's rounding error:  == is *not* a sensible way to compare real numbers.
Use all.equal(), for example.

BTW, these numbers get large quite rapidly.  Use lgamma to do the
calculations on log scale is safer.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jarioksa at cc.oulu.fi  Fri Dec 14 07:29:25 2001
From: jarioksa at cc.oulu.fi (Jari Oksanen)
Date: Fri, 14 Dec 2001 08:29:25 +0200
Subject: [R] inconsistency between gamma and choose functions 
In-Reply-To: Message from Ott Toomet <siim@obs.ee> 
   of "Fri, 14 Dec 2001 02:37:16 +0100." <Pine.LNX.4.33.0112140222200.9851-100000@ecopc64.eco.au.dk> 
Message-ID: <200112140629.fBE6TRG28935@pc112145.oulu.fi>


siim at obs.ee said:
> one should always consider
> if( abs( real1 - real2) < very.small.number)

And then one could be surprised after finding that a == b and b == c, 
but a != c. I guess this is the reason why R refuses to have a `fuzz 
factor' in comparisons (like Peter Dalgaard wrote earlier in another 
thread with the same question). Of course, the way Ott Toomet suggested 
above is the normal way of doing things.

I hope nobody dealing with Italian Lira will sue R for financial 
damages due to following:

> data(euro)
> (1/euro)*euro == 1
  ATS   BEF   DEM   ESP   FIM   FRF   IEP   ITL   LUF   NLG   PTE 
 TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE 

(Putting `signif( , 6) helps in this case, but not necessarily -- or 
even usually -- in comparisons.)
cheers, jari oksanen

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Fri Dec 14 09:54:11 2001
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 14 Dec 2001 09:54:11 +0100
Subject: [R] Hodrick-Prescott Filter: Special Case of smooth.spline()
In-Reply-To: <Pine.GSO.4.33.0112131547220.2006-100000@ysidro.econ.uiuc.edu>
References: <E1DB1E4A1D092145AE6D0F1FD6EFD0F502926BC4@gertrude.hamlet.treasury.govt.nz>
	<Pine.GSO.4.33.0112131547220.2006-100000@ysidro.econ.uiuc.edu>
Message-ID: <15385.48691.40050.808622@gargle.gargle.HOWL>

>>>>> "Roger" == Roger Koenker <roger at ysidro.econ.uiuc.edu> writes:

    Roger> A general answer would be to forget the
    Roger> Hodrick-Prescott numerology for lambda=1600, and use
    Roger> the spar parameter produced by smooth.spline's GCV
    Roger> functionality.  Nevertheless, it would be nice for
    Roger> reproducibility (comparison) reasons to be able to
    Roger> get the actual lambda corresponding to spar.  My
    Roger> quick look at the code didn't yield an easy way to
    Roger> extract the ratio: r = tr(X' W^2 X) / tr(Sigma), and
    Roger> thereby get back to lambda.  Maybe Brian could
    Roger> suggest something for this.

and Brian privately mentioned that I had most recently worked on
this.  Exactly because I found I did want to get at the lambda
used, in R 1.4 (to be released in a few days) `lambda' at least
is returned as well as spar and the details section contains
even more details about the relation of `spar' and `lambda'
((and `spar' is no longer restricted strictly to [0,1]; "0" particularly
  came from an S ``pseudo-compatibility'' which does not make
  much sense for our spar which is on a LOG scale)).

    Roger> I might also note that the Hodrick Prescott setup
    Roger> would require that you set all.knots=TRUE, since the
    Roger> default in smooth.spline is to chose fewer knots.
    Roger> The HP penalty assumes equally spaced x's so the
    Roger> penalty is just the sum of the second differences of
    Roger> ghat.

    Roger> For those of you (if any) who are wondering what the
    Roger> Hodrick-Prescott filter is: in effect it is the
    Roger> special case of the (Reinsch) cubic smoothing spline
    Roger> for an equally spaced time series.  HP claim that for
    Roger> (typical quarterly economic time-series) lambda can
    Roger> be chosen to be 1600, and (amazingly) this has become
    Roger> a default smoother in some circles of
    Roger> macroeconometrics.

interesting... this means that one uses the same (kernel-) equivalent
smoothing window for all quartely time series?  Wouldn't this
mean that (a combination of) the smoothness of the true
underlying function m(x) and the (local) variance sigma(x) was
assumed to be (almost) a universal constant?
interesting, indeed...

    Roger> url: http://www.econ.uiuc.edu Roger Koenker email
    Roger> roger at ysidro.econ.uiuc.edu Department of Economics
    Roger> vox: 217-333-4558 University of Illinois fax:
    Roger> 217-244-6678 Champaign, IL 61820

    Roger> On Fri, 14 Dec 2001, Nick Davis wrote:

    >> I've had a play with this and, due to my own
    >> short-comings, remain none the wiser.
    >> 
    >> In particular, I'm not sure what value of 'spar' is
    >> consistent with the magic lambda=1/1600 for quarterly
    >> data.
    >> 
    >> I initially interpreted spar as lambda and tried setting
    >> spar=1/1600.  This results in almost no smoothing while
    >> spar=1600 causes an error.  The smooth.spline function
    >> seems to want something in the region of 0 to 1.  The
    >> closer spar is to 1, the greater the smoothing.  A closer
    >> look at the R documentation revealed that:
    >> 
    >> The computational lambda used (as a function of `spar')
    >> is lambda = r * 256^(3*spar - 1) where r = tr(X' W^2 X) /
    >> tr(Sigma), Sigma is the matrix given by Sigma[i,j] =
    >> Integral B''[i](t) B''[j](t) dt, X is given by X[i,j] =
    >> B[j](x[i]), W^2 is the diagonal matrix of scaled weights,
    >> `W = diag(w)/n' (i.e., the identity for default weights),
    >> and B[k](.) is the k-th B-spline.
    >> 
    >> I admit to being a bit confused by the matrix algebra.
    >> It appears to come down to knowing 'r' so that 'spar' can
    >> be derived by imposing a constraint on lambda.

yes;  as `r' only depends on the design (i.e. x[] and weights[]),
in R 1.4 you can use one value of spar, and from the result of
smooth.spline compute r from spar and lambda.
As Brian mentioned (in a private mail), we could allow `lambda'
as an alternative argument to `spar' directly.  
Not for 1.4 though since that's in deep feature freeze.


    >> If anyone can shed some light on this it would be much
    >> appreciated.  A general answer would be nice as I don't
    >> always work with quarterly data.
    >> 
    >> Thanks & Regards,
    >> 
    >> Nick Davis


  < .............. >


Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From roger at ysidro.econ.uiuc.edu  Fri Dec 14 15:12:02 2001
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Fri, 14 Dec 2001 08:12:02 -0600 (CST)
Subject: [R] Hodrick-Prescott Filter: Special Case of smooth.spline()
In-Reply-To: <15385.48691.40050.808622@gargle.gargle.HOWL>
Message-ID: <Pine.GSO.4.33.0112140804510.3288-100000@ysidro.econ.uiuc.edu>

On Fri, 14 Dec 2001, Martin Maechler wrote:

> Exactly because I found I did want to get at the lambda
> used, in R 1.4 (to be released in a few days) `lambda' at least
> is returned as well as spar and the details section contains
> even more details about the relation of `spar' and `lambda'
>
This one of the more charming features of R...the psychic powers
of the core group to anticipate questions and resolve problems never
ceases to amaze.

>     Roger> For those of you (if any) who are wondering what the
>     Roger> Hodrick-Prescott filter is: in effect it is the
>     Roger> special case of the (Reinsch) cubic smoothing spline
>     Roger> for an equally spaced time series.  HP claim that for
>     Roger> (typical quarterly economic time-series) lambda can
>     Roger> be chosen to be 1600, and (amazingly) this has become
>     Roger> a default smoother in some circles of
>     Roger> macroeconometrics.
>
> interesting... this means that one uses the same (kernel-) equivalent
> smoothing window for all quartely time series?  Wouldn't this
> mean that (a combination of) the smoothness of the true
> underlying function m(x) and the (local) variance sigma(x) was
> assumed to be (almost) a universal constant?

Precisely, but some people believe in the tooth fairy too.  Or for
that matter in the existence of that "true underlying function" ... ;-).


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Fri Dec 14 15:22:10 2001
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Fri, 14 Dec 2001 15:22:10 +0100
Subject: [R] Greenhouse-Geisser epsilon correction 
Message-ID: <3C1A0B12.56AC688E@psy.uni-muenchen.de>

Hi,

I've looked in the mailing list archives and found some questions
related to Greenhouse-Geisser epsilon correction. Are there any packages
providing that?

Thanks, Sven
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From reid_huntsinger at merck.com  Fri Dec 14 16:15:21 2001
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri, 14 Dec 2001 10:15:21 -0500
Subject: [R] k-means with euclidian distance but no coordinates
Message-ID: <B9A894093554D511941700508B5C76DB23D181@uswpmx08.merck.com>

K-means uses coordinates to actually calculate the k within-cluster means
after classifying points based on distance to the previous iteration's means
(centroids). The mean is used as it minimizes the sum of squared distances
to cluster points. You could try to find this minimizer another way. You
would probably restrict to minimizers from your data set as you can't
calculate distance for other words...

You could also try to get a low-dimensional representation with
multidimensional scaling (MDS). It takes a distance matrix as input and
provides for each input point a point in a low-dimensional Euclidean space.
One option is to do this for a sample, then approximate the mapping eg with
a flexible regression approach. I've seen this work well in some perhaps
similar cases.

There are a lot of approaches to mapping into a low-dimensional Euclidean
space based essentially on principal components of the co-occurrence matrix.
Are you looking for alternatives to these? These or the MDS approach above
would let you use stock k-means, and both can be done in R.

Reid Huntsinger





-----Original Message-----
From: Corrin Lakeland [mailto:lakeland at atlas.otago.ac.nz]
Sent: Thursday, December 13, 2001 3:43 PM
To: r-help at stat.math.ethz.ch
Subject: [R] k-means with euclidian distance but no coordinates


Hi,

I'm trying to build a thesaurus that will sensible values for rare words.  
I suspect the best algorithm to use is k-means although I'm not sure about
that -- I would have preferred a k dimensional space with a binary cluster
in each dimension so a word can belong to 0..k clusters, but I digress...

I can measure the strength of correlation between words fairly easily by
counting cooccurance divided by frequency of each word, giving a euclidian
distance, although this doesn't work especially well for rare words.  
However I don't have coordinates as such, and deriving them given distance
is non-trivial.

Now, as I understand k-means, it uses euclidian distance rather than
coordiantes, the first step given in texts is to derive the distance given
the coordinates. But I can't find a way to call the built in function
without coordinates.  I had a look at R-1.3.1/src/library/mva/src/kmns.f
but my Fortran isn't good and I had enough trouble following the code, so
I'm not up to making major changes.

Any help or ideas would be appreciated

Corrin
--
Corrin Lakeland <lakeland at cs.otago.ac.nz> 
Department of Computer Science
University of Otago, New Zealand


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From charpent at bacbuc.dyndns.org  Fri Dec 14 16:47:14 2001
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Fri, 14 Dec 2001 16:47:14 +0100
Subject: [R] Logistic regression : dicrepancies between glm and nls ?
Message-ID: <3C1A1F02.5080204@bacbuc.dyndns.org>

Dear list,

I'm trying to learn how to use nlme to be able to fit ad analyse 
mixed-model logistic regressions. In order to keep things simple, I 
started by the simplest possible model : a one (fixed-effect ...) 
continuous variable. This problem is, of course, solved by glm, but I 
wanted to look at a  "hand-made" nls fit, in order to be able to 
"generalize" to nlme fits.

 > ## Let's start with the simplest model : one fixed-effect continuous 
variable
 >
 > ## Dummy data
 >
 > size<-500
 >
 > logdata<-data.frame(x=20*runif(size)-10) # A U([-10,10]) variable
 >
 > alpha<-0.5
 >
 > beta<-2
 >
 > ## Simulate a response
 > ## y : a boolean (0|1) with probability e^(a+bx)/(1+e^(a+bx))
 >
 > logdata$y<-as.numeric(runif(size)<(exp(alpha+beta*logdata$x)/
+                                   (1+exp(alpha+beta*logdata$x))))
 >
 > ## Realty check : are the data "reasonably random" ?
 >
 > table(logdata$y)

  0   1
251 249
 >
 > by(logdata$x,logdata$y,summary)
INDICES: 0
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
 -9.993  -7.243  -4.594  -4.873  -2.678   1.081
------------------------------------------------------------
INDICES: 1
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
 -1.526   1.791   5.008   4.663   7.235   9.983


So far, no reason to wail ...
 
 > ## another reality check : what's the "classical" logistic regression ?
 >
 > logdata.glm<-glm(y~x, data=logdata, family=binomial(link=logit))
 >
 > ## nls should give the same estimates, up to convergence discrepancies
 >
 > logdata.nls<-nls(y~exp(a+b*x)/(1+exp(a+b*x)), data=logdata,
+                  start=list(a=0,b=1))
 >
 > ## let's see ...
 >
 > summary(logdata.glm)

Call:
glm(formula = y ~ x, family = binomial(link = logit), data = logdata)

Deviance Residuals:
       Min          1Q      Median          3Q         Max  
-2.4394149  -0.0308105  -0.0001991   0.0082031   2.0389572  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   0.9044     0.2849   3.174  0.00150 **
x             1.8675     0.2739   6.818  9.2e-12 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 693.14  on 499  degrees of freedom
Residual deviance: 100.76  on 498  degrees of freedom
AIC: 104.76

Number of Fisher Scoring iterations: 8

 >
 > summary(logdata.nls)

Formula: y ~ exp(a + b * x)/(1 + exp(a + b * x))

Parameters:
  Estimate Std. Error t value Pr(>|t|)    
a   0.8979     0.1285    6.99 8.86e-12 ***
b   1.5806     0.1474   10.73  < 2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 0.1811 on 498 degrees of freedom

Correlation of Parameter Estimates:
       a
b 0.5964


Hmmm ... the alpha estimators are quite close to each other, but the 
beta estimators are quite different. Furthermore, the standard errors 
are quite different.

Further simulation work showed that :
a) the alpha estimators can be much more different than they are in the 
present example ;
b) the "biases" (differences between estimators) do *not* depend of 
initial values choosen for the nls estimation ;
c) they depend on the size of the sample (the larger the sample, the 
spaller the "biases") ;
d) the standard error estimates given by glm are lrger than those given 
by nls.

Can someone explain to me why those two methods of fitting a (quite) 
simple model give so different results ?

I *think* that two methods should end um with the same estimators (at 
least asymptotically). Where an why am I wrong ?

Sincerely,

                            Emmanuel Charpentier

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec 14 17:13:16 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 Dec 2001 16:13:16 +0000 (GMT)
Subject: [R] Logistic regression : dicrepancies between glm and nls ?
In-Reply-To: <3C1A1F02.5080204@bacbuc.dyndns.org>
Message-ID: <Pine.LNX.4.31.0112141611210.18874-100000@gannet.stats>

Your call to nls fits by least squares, whereas glm fits by maximum
likelihood.  Not the same thing: ml gives more weights to values with
fitted values near zero or one.


On Fri, 14 Dec 2001, Emmanuel Charpentier wrote:

> Dear list,
>
> I'm trying to learn how to use nlme to be able to fit ad analyse
> mixed-model logistic regressions. In order to keep things simple, I
> started by the simplest possible model : a one (fixed-effect ...)
> continuous variable. This problem is, of course, solved by glm, but I
> wanted to look at a  "hand-made" nls fit, in order to be able to
> "generalize" to nlme fits.
>
>  > ## Let's start with the simplest model : one fixed-effect continuous
> variable
>  >
>  > ## Dummy data
>  >
>  > size<-500
>  >
>  > logdata<-data.frame(x=20*runif(size)-10) # A U([-10,10]) variable
>  >
>  > alpha<-0.5
>  >
>  > beta<-2
>  >
>  > ## Simulate a response
>  > ## y : a boolean (0|1) with probability e^(a+bx)/(1+e^(a+bx))
>  >
>  > logdata$y<-as.numeric(runif(size)<(exp(alpha+beta*logdata$x)/
> +                                   (1+exp(alpha+beta*logdata$x))))
>  >
>  > ## Realty check : are the data "reasonably random" ?
>  >
>  > table(logdata$y)
>
>   0   1
> 251 249
>  >
>  > by(logdata$x,logdata$y,summary)
> INDICES: 0
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>  -9.993  -7.243  -4.594  -4.873  -2.678   1.081
> ------------------------------------------------------------
> INDICES: 1
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>  -1.526   1.791   5.008   4.663   7.235   9.983
>
>
> So far, no reason to wail ...
>
>  > ## another reality check : what's the "classical" logistic regression ?
>  >
>  > logdata.glm<-glm(y~x, data=logdata, family=binomial(link=logit))
>  >
>  > ## nls should give the same estimates, up to convergence discrepancies
>  >
>  > logdata.nls<-nls(y~exp(a+b*x)/(1+exp(a+b*x)), data=logdata,
> +                  start=list(a=0,b=1))
>  >
>  > ## let's see ...
>  >
>  > summary(logdata.glm)
>
> Call:
> glm(formula = y ~ x, family = binomial(link = logit), data = logdata)
>
> Deviance Residuals:
>        Min          1Q      Median          3Q         Max
> -2.4394149  -0.0308105  -0.0001991   0.0082031   2.0389572
>
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)   0.9044     0.2849   3.174  0.00150 **
> x             1.8675     0.2739   6.818  9.2e-12 ***
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
> (Dispersion parameter for binomial family taken to be 1)
>
>     Null deviance: 693.14  on 499  degrees of freedom
> Residual deviance: 100.76  on 498  degrees of freedom
> AIC: 104.76
>
> Number of Fisher Scoring iterations: 8
>
>  >
>  > summary(logdata.nls)
>
> Formula: y ~ exp(a + b * x)/(1 + exp(a + b * x))
>
> Parameters:
>   Estimate Std. Error t value Pr(>|t|)
> a   0.8979     0.1285    6.99 8.86e-12 ***
> b   1.5806     0.1474   10.73  < 2e-16 ***
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
> Residual standard error: 0.1811 on 498 degrees of freedom
>
> Correlation of Parameter Estimates:
>        a
> b 0.5964
>
>
> Hmmm ... the alpha estimators are quite close to each other, but the
> beta estimators are quite different. Furthermore, the standard errors
> are quite different.
>
> Further simulation work showed that :
> a) the alpha estimators can be much more different than they are in the
> present example ;
> b) the "biases" (differences between estimators) do *not* depend of
> initial values choosen for the nls estimation ;
> c) they depend on the size of the sample (the larger the sample, the
> spaller the "biases") ;
> d) the standard error estimates given by glm are lrger than those given
> by nls.
>
> Can someone explain to me why those two methods of fitting a (quite)
> simple model give so different results ?
>
> I *think* that two methods should end um with the same estimators (at
> least asymptotically). Where an why am I wrong ?
>
> Sincerely,
>
>                             Emmanuel Charpentier
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From charpent at bacbuc.dyndns.org  Fri Dec 14 17:56:23 2001
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Fri, 14 Dec 2001 17:56:23 +0100
Subject: [R] Logistic regression : dicrepancies between glm and nls ?
References: <Pine.LNX.4.31.0112141611210.18874-100000@gannet.stats>
Message-ID: <3C1A2F37.5050502@bacbuc.dyndns.org>

Prof Brian Ripley wrote:

>Your call to nls fits by least squares, whereas glm fits by maximum
>likelihood.  Not the same thing: ml gives more weights to values with
>fitted values near zero or one.
>
[ Feeling *very* dumb ... ] Quite right !

So my only hope is to embark on ML-estimations and likelihood ratio (or 
Akaike IC) tests ...

What would you recommend for this task ? I am not aware of a R package 
directly built to do that, except GLMM, which I do not yet know how to 
use (but I'll have a serious look at it).

Or should I bite the bullet and write my own functions ?

Thak you for your insight !

>
>On Fri, 14 Dec 2001, Emmanuel Charpentier wrote:
>
[ some silly question he shoudn't have posed ih he had had more sense ... ]
 
                                Emmanuel Charpentier


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec 14 18:45:16 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 Dec 2001 17:45:16 +0000 (GMT)
Subject: [R] Logistic regression : dicrepancies between glm and nls ?
In-Reply-To: <3C1A2F37.5050502@bacbuc.dyndns.org>
Message-ID: <Pine.LNX.4.31.0112141735440.20821-100000@gannet.stats>

On Fri, 14 Dec 2001, Emmanuel Charpentier wrote:

> Prof Brian Ripley wrote:
>
> >Your call to nls fits by least squares, whereas glm fits by maximum
> >likelihood.  Not the same thing: ml gives more weights to values with
> >fitted values near zero or one.
> >
> [ Feeling *very* dumb ... ] Quite right !
>
> So my only hope is to embark on ML-estimations and likelihood ratio (or
> Akaike IC) tests ...
>
> What would you recommend for this task ? I am not aware of a R package
> directly built to do that, except GLMM, which I do not yet know how to
> use (but I'll have a serious look at it).

For binomial GLMMs?  Well Lindsey's glmm() function only does the (very)
special case of a single random intercept, and the glmm() in GLMMgibbs
does more but is slow and often fails with binomial GLMMs, especially
binary ones.

The next version of the MASS package (on test for 1.4.0) has glmmPQL, a
wrapper around lme that does a reasonable job of estimation.  But just as
nlme is not good for testing (the likelihoods are very approximate)
so does glmmPQL.  We have better methods under development but not ready
for release yet.

As for writing your own code: deciding what to implement is hard enough.
I had a Masters' student last summer investigate a number of packages,
including R ones, and about half the answers were not credible!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From charpent at bacbuc.dyndns.org  Fri Dec 14 18:56:22 2001
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Fri, 14 Dec 2001 18:56:22 +0100
Subject: [R] Logistic regression : dicrepancies between glm and nls ?
References: <Pine.LNX.4.31.0112141735440.20821-100000@gannet.stats>
Message-ID: <3C1A3D46.6000004@bacbuc.dyndns.org>

Prof Brian Ripley wrote:

>[ ... ]
>
>>So my only hope is to embark on ML-estimations and likelihood ratio (or
>>Akaike IC) tests ...
>>
>>What would you recommend for this task ? I am not aware of a R package
>>directly built to do that, except GLMM, which I do not yet know how to
>>use (but I'll have a serious look at it).
>>
>
>For binomial GLMMs?  Well Lindsey's glmm() function only does the (very)
>special case of a single random intercept, and the glmm() in GLMMgibbs
>does more but is slow and often fails with binomial GLMMs, especially
>binary ones.
>
Well ... I was considering GLMMGibbs. But, since I'm already (for other 
reasons :see the answers to mu question las week about meta-analyses) 
trying to get some knowledge of Bayesian fundamentals, I'll also have a 
look at what WinBUGS has to say about this.

>
>The next version of the MASS package (on test for 1.4.0) has glmmPQL, a
>wrapper around lme that does a reasonable job of estimation.  But just as
>nlme is not good for testing (the likelihoods are very approximate)
>so does glmmPQL.  We have better methods under development but not ready
>for release yet.
>
>As for writing your own code: deciding what to implement is hard enough.
>I had a Masters' student last summer investigate a number of packages,
>including R ones, and about half the answers were not credible!
>
Hmmm ... I will therefore abstain to pursue.

                                    Emmanuel Charpentier



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From merithew at ccmr.cornell.edu  Fri Dec 14 20:06:43 2001
From: merithew at ccmr.cornell.edu (Robert D. Merithew)
Date: Fri, 14 Dec 2001 14:06:43 -0500 (EST)
Subject: [R] nls fit to exponential decay with unknown time origin
Message-ID: <Pine.LNX.4.10.10112141346260.11415-100000@magic.ccmr.cornell.edu>



I'm trying to use nls() to fit an exponential decay with an unknown offset
in the time (independent variable).  (Perhaps this is inherently very
difficult?).


> decay.pl <- nls (amp ~ expn(b0,b1,tau,t0,t), data = decay,
+                  start = c(b0=1, b1=7.5, tau=3.5, t0=0.1), trace=T)
Error in nlsModel(formula, mf, start) : singular gradient matrix at
initial parameter estimates
> 
> expn(1, 7.5, 3.5, 0.1, decay$t)
[1] 6.636080 5.259657 4.164661 2.797383 1.760584 1.250300
attr(,"gradient")
     b0         b1        tau         t0
[1,]  1 0.75147729 -0.4600881 1.61030849
[2,]  1 0.56795432 -0.6884997 1.21704497
[3,]  1 0.42195477 -0.7801858 0.90418880
[4,]  1 0.23965104 -0.7336256 0.51353794
[5,]  1 0.10141123 -0.4973290 0.21730978
[6,]  1 0.03337327 -0.2431481 0.07151415
> 


Is the gradient matrix really singular?  It works without the t0
parameter.


Code follows (after MASS 2nd ed. p. 271):

----------

require(nls)

t <- c(1.1,2.08,3.12,5.1,8.11,12)
amp <- c(7.4, 6.1, 4.95, 3.5, 2.3, 1.5)
decay <- data.frame (t = t, amp = amp)

expn <- function (b0, b1, tau, t0, t) {
  temp <- exp((t0-t)/tau)
  model.func <- b0 + b1 * temp
  Z <- cbind(1, temp, (b1 * (t0-t) * temp) / tau^2, b1 * temp / tau)
  dimnames(Z) <- list(NULL, c("b0","b1","tau","t0"))
  attr(model.func, "gradient") <- Z
  model.func
}

decay.pl <- nls (amp ~ expn(b0,b1,tau,t0,t), data = decay,
                 start = c(b0=1, b1=7.5, tau=3.5, t0=0.1), trace=T)

----------

thanks,
--
Robert Merithew
Laboratory of Atomic and Solid State Physics, Clark Hall
Cornell University, Ithaca, NY

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Dec 14 20:23:17 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Dec 2001 20:23:17 +0100
Subject: [R] nls fit to exponential decay with unknown time origin
In-Reply-To: <Pine.LNX.4.10.10112141346260.11415-100000@magic.ccmr.cornell.edu>
References: <Pine.LNX.4.10.10112141346260.11415-100000@magic.ccmr.cornell.edu>
Message-ID: <x2adwlip22.fsf@blueberry.kubism.ku.dk>

"Robert D. Merithew" <merithew at ccmr.cornell.edu> writes:

> I'm trying to use nls() to fit an exponential decay with an unknown offset
> in the time (independent variable).  (Perhaps this is inherently very
> difficult?).
> 
> 
> > decay.pl <- nls (amp ~ expn(b0,b1,tau,t0,t), data = decay,
> +                  start = c(b0=1, b1=7.5, tau=3.5, t0=0.1), trace=T)
> Error in nlsModel(formula, mf, start) : singular gradient matrix at
> initial parameter estimates
> > 
> > expn(1, 7.5, 3.5, 0.1, decay$t)
> [1] 6.636080 5.259657 4.164661 2.797383 1.760584 1.250300
> attr(,"gradient")
>      b0         b1        tau         t0
> [1,]  1 0.75147729 -0.4600881 1.61030849
> [2,]  1 0.56795432 -0.6884997 1.21704497
> [3,]  1 0.42195477 -0.7801858 0.90418880
> [4,]  1 0.23965104 -0.7336256 0.51353794
> [5,]  1 0.10141123 -0.4973290 0.21730978
> [6,]  1 0.03337327 -0.2431481 0.07151415
> > 
> 
> 
> Is the gradient matrix really singular?  It works without the t0
> parameter.
> 

Yes. b1 and t0 are not simultaneously identifiable.  Shifting an
exponential curve in time is the same as multiplying by a constant.

Try calculating the ratio of the t0 and b1 columns above.
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richmond at saintmarys.edu  Fri Dec 14 20:25:16 2001
From: richmond at saintmarys.edu (David A Richmond)
Date: Fri, 14 Dec 2001 14:25:16 -0500 (EST)
Subject: [R] polylog
Message-ID: <Pine.GSO.4.20.0112141420410.17572-100000@jade.saintmarys.edu>

Hi,
	Does R do the "PolyLog" function, also know as Jonquiere's
function: Li-n(z) = sum over k= 1 to inf. of (z^k)/(k^n) ?

dave

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|David Richmond                It works on a          |      
+ Dept. of Sociology          complex scientific      + 
|Saint Mary's College          principle, known as    |  
+ Notre Dame, IN 46556               "pot luck."      +
|219-284-4517                    - The Doctor         |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From merithew at ccmr.cornell.edu  Fri Dec 14 21:03:17 2001
From: merithew at ccmr.cornell.edu (Robert D. Merithew)
Date: Fri, 14 Dec 2001 15:03:17 -0500 (EST)
Subject: [R] nls fit to exponential decay with unknown time origin
In-Reply-To: <x2adwlip22.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.4.10.10112141459310.11575-100000@magic.ccmr.cornell.edu>


doh!  Boy, do I feel stupid.

sorry, it's been a long day.

thanks,
--
Robert



On 14 Dec 2001, Peter Dalgaard BSA wrote:

> "Robert D. Merithew" <merithew at ccmr.cornell.edu> writes:
> 
> > I'm trying to use nls() to fit an exponential decay with an unknown offset
> > in the time (independent variable).  (Perhaps this is inherently very
> > difficult?).
> > 
> > 
> > > decay.pl <- nls (amp ~ expn(b0,b1,tau,t0,t), data = decay,
> > +                  start = c(b0=1, b1=7.5, tau=3.5, t0=0.1), trace=T)
> > Error in nlsModel(formula, mf, start) : singular gradient matrix at
> > initial parameter estimates
> > > 
> > > expn(1, 7.5, 3.5, 0.1, decay$t)
> > [1] 6.636080 5.259657 4.164661 2.797383 1.760584 1.250300
> > attr(,"gradient")
> >      b0         b1        tau         t0
> > [1,]  1 0.75147729 -0.4600881 1.61030849
> > [2,]  1 0.56795432 -0.6884997 1.21704497
> > [3,]  1 0.42195477 -0.7801858 0.90418880
> > [4,]  1 0.23965104 -0.7336256 0.51353794
> > [5,]  1 0.10141123 -0.4973290 0.21730978
> > [6,]  1 0.03337327 -0.2431481 0.07151415
> > > 
> > 
> > 
> > Is the gradient matrix really singular?  It works without the t0
> > parameter.
> > 
> 
> Yes. b1 and t0 are not simultaneously identifiable.  Shifting an
> exponential curve in time is the same as multiplying by a constant.
> 
> Try calculating the ratio of the t0 and b1 columns above.
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Sat Dec 15 00:25:31 2001
From: brahm at alum.mit.edu (David Brahm)
Date: Fri, 14 Dec 2001 18:25:31 -0500
Subject: [R] colSums in C
Message-ID: <15386.35435.13721.387225@gargle.gargle.HOWL>

Hi, all!

   My project today is to write a speedy colSums(), which is a function
available in S-Plus to add the columns of a matrix.  Here are 4 ways to do it,
with the time it took (elapsed, best of 3 trials) in both R and S-Plus:

m <- matrix(1, 400, 40000)
x1 <- apply(m, 2, sum)                  ## R=16.55   S=52.39
x2 <- as.vector(rep(1,nrow(m)) %*% m)   ## R= 2.39   S= 8.52
x3 <- g.apply.sum(m,2,F)                ## R= 5.72   S=11.25
x4 <- colSums(m,F)                      ##           S= 0.48

Method 1 is the naive "apply", and is significantly faster in R than S-Plus.
Method 2 is a matrix operation I learned from Bill Venables; also faster in R.
Method 3 is my C code, given below.
Method 4 is the S-Plus built-in function, the bogey to beat!

My question is, can anyone suggest how to speed up my C code to get results
comparable to colSums, or even to method 2?  Is it stupid code, a bad compiler,
non-optimal optimizer options, or ???

Here's my interface function and simple C code (compiled with gcc via R
SHLIB, no Makevars file):

g.apply.sum <- function(x, MARGIN=1, na.rm=T) {
  dx <- dim(x)
  if (na.rm) x[is.na(x)] <- 0
  .C("applysum", as.real(x), dx, as.integer(MARGIN), z=real(dx[MARGIN]),
     DUP=FALSE)$z
}

void applysum(double *x, long *dx, long *mar, double *z) {
  long i, j;
  if (*mar==1)
    for(i=0; i<dx[0]; i++) for(j=0; j<dx[1]; j++) z[i] += x[i + dx[0]*j];
  else
    for(j=0; j<dx[1]; j++) for(i=0; i<dx[0]; i++) z[j] += x[i + dx[0]*j];
}

Possibly useful audit trail:

agate|Rpkg> R SHLIB g.colSums/src/*.c
/res/local/bin/gcc -I/res/local/lib/R/include  -I/res/local/include   -fPIC  -g -O2 -c g.colSums/src/applyfilt.c -o g.colSums/src/applyfilt.o
/res/local/bin/gcc -I/res/local/lib/R/include  -I/res/local/include   -fPIC  -g -O2 -c g.colSums/src/applysum.c -o g.colSums/src/applysum.o
/res/local/bin/gcc -shared  -o g.colSums/src/applyfilt.so g.colSums/src/applyfilt.o g.colSums/src/applysum.o  -L/res/local/include  

Version:
 platform = sparc-sun-solaris2.6
 arch = sparc
 os = solaris2.6
 system = sparc, solaris2.6
 status = 
 major = 1
 minor = 3.1
 year = 2001
 month = 08
 day = 31
 language = R

-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sat Dec 15 01:08:59 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Dec 2001 01:08:59 +0100
Subject: [R] colSums in C
In-Reply-To: <15386.35435.13721.387225@gargle.gargle.HOWL>
References: <15386.35435.13721.387225@gargle.gargle.HOWL>
Message-ID: <x2zo4lz6n8.fsf@blueberry.kubism.ku.dk>

David Brahm  <brahm at alum.mit.edu> writes:

> My question is, can anyone suggest how to speed up my C code to get results
> comparable to colSums, or even to method 2?  Is it stupid code, a bad compiler,
> non-optimal optimizer options, or ???

Your code is not very efficiently written, but the compiler ought to
be able to catch the common subexpressions etc. On the other hand,
especially on Sparc there are some pretty tricky pipelining and
parallelism issues that can be really hard to get right and can mean
quite a lot. And there are some optimizations that a compiler cannot
really do without making assumptions that might be wrong.
(Prototypically: what if z and x have overlapping storage? *You* know
they don't, but the compiler really can't be sure.)
 
> Here's my interface function and simple C code (compiled with gcc via R
> SHLIB, no Makevars file):
> 
> g.apply.sum <- function(x, MARGIN=1, na.rm=T) {
>   dx <- dim(x)
>   if (na.rm) x[is.na(x)] <- 0
>   .C("applysum", as.real(x), dx, as.integer(MARGIN), z=real(dx[MARGIN]),
>      DUP=FALSE)$z
> }
> 
> void applysum(double *x, long *dx, long *mar, double *z) {
>   long i, j;
>   if (*mar==1)
>     for(i=0; i<dx[0]; i++) for(j=0; j<dx[1]; j++) z[i] += x[i + dx[0]*j];
>   else
>     for(j=0; j<dx[1]; j++) for(i=0; i<dx[0]; i++) z[j] += x[i + dx[0]*j];
> }

Hmm. What happens if you rewrite the "else" case as something like

register long i;
register double s, *p; 

p = x;
for(j=0; j<dx[1]; j++) {
        i = dx[0];
        s = 0.;
        while (i--)
                s += *p++;
        z[j] = s;
}          

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From merithew at ccmr.cornell.edu  Sat Dec 15 04:53:52 2001
From: merithew at ccmr.cornell.edu (Robert D. Merithew)
Date: Fri, 14 Dec 2001 22:53:52 -0500 (EST)
Subject: [R] fit to spike with exponential decay : optim() question
Message-ID: <Pine.LNX.4.10.10112141625001.11714-100000@magic.ccmr.cornell.edu>


I finally got (mostly) what I wanted.  In an attempt to figure out how to
get nls to deal with a non-differentiable function, I had (stupidly)
'simplified' the problem until it became singular.

Can I do something to make optim() less sensitive to my initial guess? For
this example, I get a lousy solution if I make the initial guess for t0 =
min(t) = 0.05.

Thanks again,
--
Robert Merithew
LASSP, Clark Hall
Cornell University, Ithaca NY


-----------

t <- c(0.05,0.9,1.4,2.38,3.42,5.4,8.31,12.4)
amp <- c(1.0,0.85,7.4, 6.1, 4.95, 3.5, 2.3, 1.5)

spike <- function (x, t) {
  b0 <- x[1]
  b1 <- x[2]
  tau <- x[3]
  t0 <- x[4]
  
  temp <- exp((-t+t0)/tau)
  (b0 + (b1 * temp)  * (t > t0))
}

spike.sos <- function (x) {
  sum((amp - spike(x, t))^2)
}

guess <- c(min(amp), max(amp)-min(amp), (max(t)-min(t))/3, 0)

decay.opt <- optim(guess, spike.sos, control=list(trace=T))

xr <- (0:140)/10
plot (xr, spike(decay.opt$par, xr), type="l", col="blue")
points (t, amp)

--------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Dec 15 08:30:33 2001
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sat, 15 Dec 2001 07:30:33 +0000 (GMT)
Subject: [R] fit to spike with exponential decay : optim() question
In-Reply-To: <Pine.LNX.4.10.10112141625001.11714-100000@magic.ccmr.cornell.edu>
Message-ID: <Pine.GSO.4.31.0112150726430.27974-100000@auk.stats>

On Fri, 14 Dec 2001, Robert D. Merithew wrote:

>
> I finally got (mostly) what I wanted.  In an attempt to figure out how to
> get nls to deal with a non-differentiable function, I had (stupidly)
> 'simplified' the problem until it became singular.
>
> Can I do something to make optim() less sensitive to my initial guess? For
> this example, I get a lousy solution if I make the initial guess for t0 =
> min(t) = 0.05.

1) Give it derivatives
2) Use a different method, such as BFGS.
3) Scale the problem as described in help(optim): not that yours seems
   badly scaled, but I would optimize the mean square in larger problems.

Recovering from lousy information is not what optimizers are designed for,
though.

>
> Thanks again,
> --
> Robert Merithew
> LASSP, Clark Hall
> Cornell University, Ithaca NY
>
>
> -----------
>
> t <- c(0.05,0.9,1.4,2.38,3.42,5.4,8.31,12.4)
> amp <- c(1.0,0.85,7.4, 6.1, 4.95, 3.5, 2.3, 1.5)
>
> spike <- function (x, t) {
>   b0 <- x[1]
>   b1 <- x[2]
>   tau <- x[3]
>   t0 <- x[4]
>
>   temp <- exp((-t+t0)/tau)
>   (b0 + (b1 * temp)  * (t > t0))
> }
>
> spike.sos <- function (x) {
>   sum((amp - spike(x, t))^2)
> }
>
> guess <- c(min(amp), max(amp)-min(amp), (max(t)-min(t))/3, 0)
>
> decay.opt <- optim(guess, spike.sos, control=list(trace=T))
>
> xr <- (0:140)/10
> plot (xr, spike(decay.opt$par, xr), type="l", col="blue")
> points (t, amp)
>
> --------
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tsumi at leo.auric.ne.jp  Sat Dec 15 17:13:21 2001
From: tsumi at leo.auric.ne.jp (Tsumiyama Isao)
Date: Sun, 16 Dec 2001 01:13:21 +0900
Subject: [R] Any header needed for COM interface?
Message-ID: <200112151632.RAA09574@stat.math.ethz.ch>

Hi, all.

 Now I am trying to embed R in C++ code with COM
interface.
 Which header file should be included (specially in case of
using Borland C++ compiler)?  
 And are there any library files to be linked when compiling?

Thanks in advance from Japan.

##################################
#  Tsumiyama Isao   
#  e-mail:tsumi at leo.auric.ne.jp
##################################
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vasishth at ling.ohio-state.edu  Sat Dec 15 21:58:38 2001
From: vasishth at ling.ohio-state.edu (Shravan Vasishth)
Date: Sat, 15 Dec 2001 15:58:38 -0500 (EST)
Subject: [R] subset error message
Message-ID: <Pine.SOL.4.33.0112151544200.27972-100000@julius.ling.ohio-state.edu>

Hello everybody,

I'm trying to subset a data frame "foo", which looks like this:

    sent cond  raw V1
10     2    A  614  7
11     2    A  724  6
12     2    A  641  5
13     2    A  665  9
33     5    B  510  7
34     5    B  659  7
35     5    B  607  6
37     5    B  467  8
38     5    B  586  9
39     5    B  523 10
57     8    C  858  8
58     8    C  513  9
59     8    C  739  7
60     8    C  699  7
61     8    C  585  4
79    11    D  485  8
80    11    D  704  8
81    11    D  544  7
82    11    D  461  7
83    11    D  838  8
84    11    D  655 13
85    11    D  568  6
107   15    A  467  7
108   15    A  680  7
110   15    A  741  8
130   19    B  686  7
131   19    B  717  6
132   19    B  495  8
133   19    B  480  4
134   19    B  376  7
135   19    B  470  9
148   21    C  443  6
149   21    C  771  8
150   21    C  790  8
151   21    C  653  8
152   21    C  547  7
173   25    D  550  7
174   25    D  444  7
175   25    D  491  8
176   25    D 1038  7
177   25    D 1003  9
178   25    D  661 13
179   25    D  645 10
193   28    A  652  7
194   28    A  846  6
195   28    A  571  5
196   28    A  467  8
197   28    A  597 10
206   31    B  474  7
207   31    B  534  7
208   31    B  545  7
209   31    B  610  5
210   31    B  443  8
211   31    B  454 12
212   31    B  420 10
231   35    C  549  7
232   35    C  527  6
233   35    C  408  7
234   35    C  394  8
235   35    C  396 10
244   37    D  574  8
245   37    D  711  8
246   37    D  457  8
247   37    D  556  6
248   37    D  399  8
249   37    D  425 13
250   37    D  371  7
259   39    A  644  6
260   39    A  872  8
262   39    A 1685  9
278   42    B  551  6
279   42    B  611  7
280   42    B  672  8
281   42    B  650  4
282   42    B  576  9
283   42    B  559 14
305   46    C  566  9
306   46    C  433  6
307   46    C  315  6
308   46    C 1088  9
309   46    C  463  6
320   48    D  481  6
321   48    D  642  8
322   48    D  548  8
323   48    D  507  7
324   48    D  406  9
325   48    D  380 13

When I do

>subset(foo, V1 > 5)

(I.e., when I try to remove all rows with values 5 or less in column V1)
I get this error message:

Warning message:
">" not meaningful for factors in: Ops.factor(V1, 5)

I have the same problem with ">".

However, it works fine if I do:

>subset(foo, V1 != 1 & V1 != 2 & V1 != 3 & V1 != 4 & V1 != 5)

If I try the same thing with the airquality example in the help (?subset),
the inequality works fine:

>subset(airquality, Temp > 80)

...

Thanks in advance,

-- 
Shravan Vasishth
Dept. of Linguistics, OSU
222 Oxley Hall, 1712 Neil Ave.
Columbus, OH 43210-1298
USA

URL: http://ling.ohio-state.edu/~vasishth

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zeileis at ci.tuwien.ac.at  Sat Dec 15 22:19:31 2001
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Sat, 15 Dec 2001 22:19:31 +0100
Subject: [R] subset error message
References: <Pine.SOL.4.33.0112151544200.27972-100000@julius.ling.ohio-state.edu>
Message-ID: <3C1BBE63.8F977395@ci.tuwien.ac.at>

Shravan Vasishth wrote:
> 
> Hello everybody,
> 
> I'm trying to subset a data frame "foo", which looks like this:
> 
>     sent cond  raw V1
> 10     2    A  614  7
> 11     2    A  724  6
> 12     2    A  641  5
> 13     2    A  665  9
> 33     5    B  510  7
> 34     5    B  659  7
> 35     5    B  607  6
> 37     5    B  467  8
> 38     5    B  586  9
> 39     5    B  523 10
> 57     8    C  858  8
> 58     8    C  513  9
> 59     8    C  739  7
> 60     8    C  699  7
> 61     8    C  585  4
> 79    11    D  485  8
> 80    11    D  704  8
> 81    11    D  544  7
> 82    11    D  461  7
> 83    11    D  838  8
> 84    11    D  655 13
> 85    11    D  568  6
> 107   15    A  467  7
> 108   15    A  680  7
> 110   15    A  741  8
> 130   19    B  686  7
> 131   19    B  717  6
> 132   19    B  495  8
> 133   19    B  480  4
> 134   19    B  376  7
> 135   19    B  470  9
> 148   21    C  443  6
> 149   21    C  771  8
> 150   21    C  790  8
> 151   21    C  653  8
> 152   21    C  547  7
> 173   25    D  550  7
> 174   25    D  444  7
> 175   25    D  491  8
> 176   25    D 1038  7
> 177   25    D 1003  9
> 178   25    D  661 13
> 179   25    D  645 10
> 193   28    A  652  7
> 194   28    A  846  6
> 195   28    A  571  5
> 196   28    A  467  8
> 197   28    A  597 10
> 206   31    B  474  7
> 207   31    B  534  7
> 208   31    B  545  7
> 209   31    B  610  5
> 210   31    B  443  8
> 211   31    B  454 12
> 212   31    B  420 10
> 231   35    C  549  7
> 232   35    C  527  6
> 233   35    C  408  7
> 234   35    C  394  8
> 235   35    C  396 10
> 244   37    D  574  8
> 245   37    D  711  8
> 246   37    D  457  8
> 247   37    D  556  6
> 248   37    D  399  8
> 249   37    D  425 13
> 250   37    D  371  7
> 259   39    A  644  6
> 260   39    A  872  8
> 262   39    A 1685  9
> 278   42    B  551  6
> 279   42    B  611  7
> 280   42    B  672  8
> 281   42    B  650  4
> 282   42    B  576  9
> 283   42    B  559 14
> 305   46    C  566  9
> 306   46    C  433  6
> 307   46    C  315  6
> 308   46    C 1088  9
> 309   46    C  463  6
> 320   48    D  481  6
> 321   48    D  642  8
> 322   48    D  548  8
> 323   48    D  507  7
> 324   48    D  406  9
> 325   48    D  380 13
> 
> When I do
> 
> >subset(foo, V1 > 5)
> 
> (I.e., when I try to remove all rows with values 5 or less in column V1)
> I get this error message:
> 
> Warning message:
> ">" not meaningful for factors in: Ops.factor(V1, 5)

The reason for the error is what R tells you: V1 is a factor (and not
numeric) and therefore ">" is not meaningful.
If V1 is not a factor you should change it to a numeric vector and use
the command above. Or you could do something like
  subset(foo, levels(V1) > 5)
which should give the desired result.
Z

> I have the same problem with ">".
> 
> However, it works fine if I do:
> 
> >subset(foo, V1 != 1 & V1 != 2 & V1 != 3 & V1 != 4 & V1 != 5)
> 
> If I try the same thing with the airquality example in the help (?subset),
> the inequality works fine:
> 
> >subset(airquality, Temp > 80)
> 
> ...
> 
> Thanks in advance,
> 
> --
> Shravan Vasishth
> Dept. of Linguistics, OSU
> 222 Oxley Hall, 1712 Neil Ave.
> Columbus, OH 43210-1298
> USA
> 
> URL: http://ling.ohio-state.edu/~vasishth
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dmurdoch at pair.com  Sat Dec 15 22:36:14 2001
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 15 Dec 2001 16:36:14 -0500
Subject: [R] R workspace
In-Reply-To: <3C188620.E77B255B@pasteur.fr>
References: <3C188620.E77B255B@pasteur.fr>
Message-ID: <t8gn1uc0uds0cjefl8tjhrbjc2ig4amftg@4ax.com>

On Thu, 13 Dec 2001 11:42:40 +0100, you wrote:

>
>Dear all,
>
>I m using  R version 1.3.1 under linux (Red Hat).
>When i left my session, naturally i have the question
>Save workspace image? [y/n/c]?
>I said n because I want to remove all the contain of my workspace.
>Then I left R with q().

This means it won't save the current workspace, but if you already
have a saved one, it will be left there.

>
>When I open new session I have the R welcome message and
>[previously save workspace restored]. By typing ls() I find
>what I have normally removed and I want to remove.
>I have try rm(" "). But every time I open R session I find the objects.

There are several ways to get rid of the old saved workspace, for
example:

 unlink(".RData")
 q("no")

or

 rm(list=ls())
 q("yes")

Duncan Murdoch
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rhskelto at atm.ox.ac.uk  Sun Dec 16 17:19:21 2001
From: rhskelto at atm.ox.ac.uk (Randall Skelton)
Date: Sun, 16 Dec 2001 16:19:21 +0000 (GMT)
Subject: [R] Reading/writing XDR files
Message-ID: <Pine.LNX.4.33.0112161612470.15777-100000@mulligan.atm.ox.ac.uk>

Hi all,

I am writing relatively large data files from some simulation code that
runs on a variety of different platforms.  I just migrated from my own
(broken) file format that was not particularly platform independent to the
XDR format.  Is it possible to read these XDR files directly into R?

Cheers,
Randall

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From stephanehess at hotmail.com  Sun Dec 16 18:10:31 2001
From: stephanehess at hotmail.com (Stephane Hess)
Date: Sun, 16 Dec 2001 18:10:31 +0100
Subject: [R] R equivalent to rts
Message-ID: <OE25cGgejfPDRhxbR7y0000346b@hotmail.com>

Is there an equivalent in R to the Splus command rts?
eg. in Splus you can use:
x_rts(scan(n=...),start=...,frequency=....,units="months").

I want to use it to declare a time series.
Or can anybody suggest an alternative way of declaring it.
Thanks,
Stephane Hess,
Statistical Laboratory, Cambridge University.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011216/01b757e1/attachment.html

From ripley at stats.ox.ac.uk  Sun Dec 16 18:12:08 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Dec 2001 17:12:08 +0000 (GMT)
Subject: [R] R equivalent to rts
In-Reply-To: <OE25cGgejfPDRhxbR7y0000346b@hotmail.com>
Message-ID: <Pine.LNX.4.31.0112161710570.7224-100000@gannet.stats>

ts()

You want library(ts) to make good use of it.

Any of the search mechanisms would have found this for you, I hope.

On Sun, 16 Dec 2001, Stephane Hess wrote:

> Is there an equivalent in R to the Splus command rts?
> eg. in Splus you can use:
> x_rts(scan(n=...),start=...,frequency=....,units="months").
>
> I want to use it to declare a time series.
> Or can anybody suggest an alternative way of declaring it.
> Thanks,
> Stephane Hess,
> Statistical Laboratory, Cambridge University.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Dec 16 18:19:23 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Dec 2001 17:19:23 +0000 (GMT)
Subject: [R] Reading/writing XDR files
In-Reply-To: <Pine.LNX.4.33.0112161612470.15777-100000@mulligan.atm.ox.ac.uk>
Message-ID: <Pine.LNX.4.31.0112161713240.7224-100000@gannet.stats>

On Sun, 16 Dec 2001, Randall Skelton wrote:

> Hi all,
>
> I am writing relatively large data files from some simulation code that
> runs on a variety of different platforms.  I just migrated from my own
> (broken) file format that was not particularly platform independent to the
> XDR format.  Is it possible to read these XDR files directly into R?

Possibly!  Most of the time XDR is just Sun's native format, so try using
readBin with endian="big".  That's true for ints, longs, float and
doubles, at least.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgrandeau at free.fr  Sun Dec 16 20:07:03 2001
From: pgrandeau at free.fr (Pascal Grandeau)
Date: Sun, 16 Dec 2001 20:07:03 +0100
Subject: [R] Arima
Message-ID: <BOECJIPDBPNKIFOLLIKIOEAHCCAA.pgrandeau@free.fr>

I did a regression with ARMA errors using arima0 with
   ari<-arima0(y,order=c(2,0,2),xreg=reg1,delta=-1)
or
   ari<-arima0(y,order=c(2,0,2),xreg=reg1)
where reg1 is the matrix of the regressors and when I see diag(ari$var.coef)
I get negative terms. Do you know what this mean ?

I try to change transform.pars to 0 or 1 but this crash R on Windows.

Is it possible to test the significativity of the estimators obtained by
arima0 and how ?

I use arima0 because I have regressors and it seems it is impossible to uses
arma() in tseries with regressors.

Does anyone make a routine for regression with ARMA errors with least
squares ?

Another question : how can I handle missing values in regression with ARMA
errors with R ?

Thank you very much.

Pascal GRANDEAU

PS : do you know if there exist companies making formations on R in France ?

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Dec 16 22:45:11 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Dec 2001 21:45:11 +0000 (GMT)
Subject: [R] Arima
In-Reply-To: <BOECJIPDBPNKIFOLLIKIOEAHCCAA.pgrandeau@free.fr>
Message-ID: <Pine.LNX.4.31.0112162128260.8684-100000@gannet.stats>

On Sun, 16 Dec 2001, Pascal Grandeau wrote:

> I did a regression with ARMA errors using arima0 with
>    ari<-arima0(y,order=c(2,0,2),xreg=reg1,delta=-1)
> or
>    ari<-arima0(y,order=c(2,0,2),xreg=reg1)
> where reg1 is the matrix of the regressors and when I see diag(ari$var.coef)
> I get negative terms. Do you know what this mean ?

The optimizer failed to converge, probably. You did check the
convergence value in the fitted object, didn't you?

> I try to change transform.pars to 0 or 1 but this crash R on Windows.

Well, transform.pars=2 first runs transform.pars=1, so this is strange.
But probably your model is inappropriate.

> Is it possible to test the significativity of the estimators obtained by
> arima0 and how ?

Well, first you need to get it to converge. Then you can use Wald tests or
(better) likelihood ratio tests.  The log-likelihood is in the fitted
object.

> I use arima0 because I have regressors and it seems it is impossible to uses
> arma() in tseries with regressors.
>
> Does anyone make a routine for regression with ARMA errors with least
> squares ?

What does that mean? `with least squares' implies independent errors.
arma() fits by so-called *conditional* least squares: that leaves out
terms in the log-likelihood which can be important, especially near
non-stationarity. I've never understood why anyone would want to do that,
except as a poor man's computational approximation.

> Another question : how can I handle missing values in regression with ARMA
> errors with R ?

As yet there are very limited possibilties: see e.g. na.contiguous.

You might want to investigate the dse bundle.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From h_m_ at po.harenet.ne.jp  Mon Dec 17 09:47:03 2001
From: h_m_ at po.harenet.ne.jp (Hiroto Miyoshi)
Date: Mon, 17 Dec 2001 17:47:03 +0900
Subject: [R] drawing a cluster tree with variable labels
Message-ID: <000701c186d7$67073220$0400a8c0@miyoshi>

Hello, R users

I like to draw a cluster tree with a hclust command and 
plot.hclust command.  But, when the tree is drawn,
I like to see variable labels at the bottom of the tree, 
instead of variable names.  That is, each variable has
a bit lenghty label which expresses the meaning of the variable.
and variable names and labels are stored in a data.frame.
And I want the variable labels to appear at the bottom of 
the tree.
What commands and/or options should I use?
Could anyone tell me ?
Thank you.
-----------------------
Hiroto Miyoshi
????
h_m_ at po.harenet.ne.jp


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Gerard.Keogh at cso.ie  Mon Dec 17 11:10:24 2001
From: Gerard.Keogh at cso.ie (Gerard.Keogh@cso.ie)
Date: Mon, 17 Dec 2001 10:10:24 +0000
Subject: [R] Arima
Message-ID: <OF225F9B6E.F38CE996-ON80256B25.0034B1B3@cso.ie>

                                                                                                                      
                    Prof Brian Ripley                                                                                 
                    <ripley at stats.ox.ac.        To:     Pascal Grandeau <pgrandeau at free.fr>                           
                    uk>                         cc:     r-help at stat.math.ethz.ch                                      
                    Sent by:                    Subject:     Re: [R] Arima                                            
                    owner-r-help at stat.ma                                                                              
                    th.ethz.ch                                                                                        
                                                                                                                      
                                                                                                                      
                    16/12/01 21:45                                                                                    
                                                                                                                      
                                                                                                                      










On Sun, 16 Dec 2001, Pascal Grandeau wrote:
>
> Does anyone make a routine for regression with ARMA errors with least
> squares ?

Prof Brian Ripley replies:

What does that mean? `with least squares' implies independent errors.
arma() fits by so-called *conditional* least squares: that leaves out
terms in the log-likelihood which can be important, especially near
non-stationarity. I've never understood why anyone would want to do that,
except as a poor man's computational approximation.

When considering the MA(1) model Harvey in "Time Series Models p60" says
that assuming the initial disturbance to be fixed and equal to zero makes
the problem of maximising the likelihood function equivalent to minimising
the sum of squares of the errors - the result is then called the
conditional sum of squares (CSS) estimate. The calculation of this
"conditional likelihood function" is therefore simplified considerably and
the resulting equations which are still nonlinear in the parameters are
more readily optimised because analytic derivatives are available.

Of course the exact likelihood function of any ARMA(p,q) model can be
generated from Kalman recursions via the prediction error decomposition.
Harvey's main argument for using the CSS estimate relies on the fact that
maximising the likelihood is time consuming for large p+q (for myself, I
take time consuming to mean that it's often very hard to find a solution to
a nonlinear problem!). However, I suspect that with the computing power now
available the time issue may be far less relevant.

One final point though is that the CSS estimate may provide reasonable
starting values for the optimisation of the exact likelihood.

Gerard Keogh


The information in this email, and any attachments transmitted with it, are confidential 
and are for the intended recipient only. If you receive this message in error, please 
notify us via postmaster at cso.ie.

To see the latest figures from the CSO go to http://www.cso.ie
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec 17 14:42:16 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Dec 2001 13:42:16 +0000 (GMT)
Subject: [R] Arima
In-Reply-To: <OF225F9B6E.F38CE996-ON80256B25.0034B1B3@cso.ie>
Message-ID: <Pine.LNX.4.31.0112171335470.9474-100000@gannet.stats>

On Mon, 17 Dec 2001 Gerard.Keogh at cso.ie wrote:

> On Sun, 16 Dec 2001, Pascal Grandeau wrote:
> >
> > Does anyone make a routine for regression with ARMA errors with least
> > squares ?
>
> Prof Brian Ripley replies:
>
> What does that mean? `with least squares' implies independent errors.
> arma() fits by so-called *conditional* least squares: that leaves out
> terms in the log-likelihood which can be important, especially near
> non-stationarity. I've never understood why anyone would want to do that,
> except as a poor man's computational approximation.

[End of quote]


> When considering the MA(1) model Harvey in "Time Series Models p60" says
> that assuming the initial disturbance to be fixed and equal to zero makes
> the problem of maximising the likelihood function equivalent to minimising
> the sum of squares of the errors - the result is then called the
> conditional sum of squares (CSS) estimate. The calculation of this
> "conditional likelihood function" is therefore simplified considerably and
> the resulting equations which are still nonlinear in the parameters are
> more readily optimised because analytic derivatives are available.
>
> Of course the exact likelihood function of any ARMA(p,q) model can be
> generated from Kalman recursions via the prediction error decomposition.
> Harvey's main argument for using the CSS estimate relies on the fact that
> maximising the likelihood is time consuming for large p+q (for myself, I
> take time consuming to mean that it's often very hard to find a solution to
> a nonlinear problem!). However, I suspect that with the computing power now
> available the time issue may be far less relevant.

Exactly, as I said.

> One final point though is that the CSS estimate may provide reasonable
> starting values for the optimisation of the exact likelihood.

Given that arima0() does the exact likelihood, and I've never had to wait
more than a few seconds for it to do so, I still don't see why
anyone would ask for conditional least squares instead, which was the
request.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Setzer.Woodrow at epamail.epa.gov  Mon Dec 17 15:34:52 2001
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Mon, 17 Dec 2001 09:34:52 -0500
Subject: [R] R-1.4.0: how to use getSymbolInfo()?
Message-ID: <OF2E656630.38768534-ON85256B25.004FDD5C@rtp.epa.gov>


Thanks, Duncan.  That is exactly what I was looking for!  and yes, it is
getNativeSymbolInfo(); sorry for the confusion.

R. Woodrow Setzer, Jr.                                            Phone:
(919) 541-0128
Experimental Toxicology Division                       Fax:  (919)
541-5394
Pharmacokinetics Branch
NHEERL MD-74; US EPA; RTP, NC 27711


                                                                                                                              
                    Duncan Temple Lang                                                                                        
                    <duncan at research.bell        To:     Woodrow Setzer/RTP/USEPA/US at EPA                                      
                    -labs.com>                   cc:     r-help at stat.math.ethz.ch                                             
                                                 Subject:     Re: [R] R-1.4.0: how to use getSymbolInfo()?                    
                    12/15/01 11:10 AM                                                                                         
                                                                                                                              
                                                                                                                              




Setzer.Woodrow at epamail.epa.gov wrote:
>
> Welll, getSymbolInfo() returns a list that includes an external
pointer
> object.  I guess my question is, how to unwrap it in the c code so
that
> I can use it as (*f)()?

Hi Woodrow,

  I have been away from the office for the past few days, so didn't
get your mail until now. Just in case you haven't got an answer, here
is one.

  As you correctly point out, what you need is a way to unwrap the
external pointer. The C routine R_ExternalPtrAddr() will do this
for you.

  Your situation is one of the contexts that motivated adding the
reflectance information about native symbols. We can pass R functions
or "NativeSymbol" objects and have C code handle them appropriately.
I put together two examples of the mechanism and they are available
at
  http://cm.bell-labs.com/stat/duncan/RSymbolInfo.tar.gz

The file basic.c shows what you need to do.  chandler.c shows how to
handle either an R function or a NativeSymbol object.

BTW, it is getNativeSymbolInfo() rather than getSymbolInfo(), isn't it?

 Duncan.

>
> R. Woodrow Setzer, Jr.
Phone:
> (919) 541-0128
> Experimental Toxicology Division                       Fax:  (919)
> 541-5394
> Pharmacokinetics Branch
> NHEERL MD-74; US EPA; RTP, NC 27711
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:
r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._._._

--
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070
         http://cm.bell-labs.com/stat/duncan




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From yiping.fan at syngenta.com  Mon Dec 17 17:49:13 2001
From: yiping.fan at syngenta.com (yiping.fan@syngenta.com)
Date: Mon, 17 Dec 2001 17:49:13 +0100
Subject: [R] help for input 
Message-ID: <AF84AD19B4A8D411B18500508BAF0E0EC2987C@se-excur01-uslj.nadi.uslj>

Hello, all,
    I have a question regarding data input.  For example: I have a file like
this
       Group exp value
 001 1  1   5
002   1  2  4
003   1  3  4
004  2   1  4
005 2    1  4
006  3    2  3
007  3   4 5
008  3  4  5
009   3  5  6
I read it using 
f<-read.table("infile")
we have 3 groups here,
group1 have 3 exps
group 2 havs 2 exps
group 3 has 4 exps
After I read the file,  how can I get the data for each group?   Thanks!

Yiping

   



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From White.Denis at epamail.epa.gov  Mon Dec 17 18:20:10 2001
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Mon, 17 Dec 2001 09:20:10 -0800
Subject: [R] drawing a cluster tree with variable labels
Message-ID: <OF152C3C26.F2F56455-ON88256B25.005EBAB8@rtp.epa.gov>


> Hello, R users
>
> I like to draw a cluster tree with a hclust command and
> plot.hclust command.  But, when the tree is drawn,
> I like to see variable labels at the bottom of the tree,
> instead of variable names.  That is, each variable has
> a bit lenghty label which expresses the meaning of the variable.
> and variable names and labels are stored in a data.frame.
> And I want the variable labels to appear at the bottom of
> the tree.
> What commands and/or options should I use?
> Could anyone tell me ?
> Thank you.
> -----------------------
> Hiroto Miyoshi
> ????
> h_m_ at po.harenet.ne.jp

You can look at the R script for "draw.tree" in package "maptree" to see
if you can modify it for your purposes.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Dec 17 18:40:11 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 17 Dec 2001 18:40:11 +0100 (CET)
Subject: [R] Correct file permissions?
In-Reply-To: <Pine.LNX.4.31.0112171335470.9474-100000@gannet.stats>
Message-ID: <Pine.LNX.4.33.0112171821160.8879-100000@tal.stat.umu.se>

I'm running 'R cmd CHECK' (on Linux) and get a WARNING:

-----------------------------------------------------------------
*   Found the following text files with incorrect permissions:
.
.
.
*   Please fix permissions.
-----------------------------------------------------------------
What is 'correct permissions'?

G?ran
-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From niels.waller at vanderbilt.edu  Mon Dec 17 18:54:00 2001
From: niels.waller at vanderbilt.edu (Niels Waller)
Date: Mon, 17 Dec 2001 11:54:00 -0600
Subject: [R] strsplit behavior
Message-ID: <NDBBLLOPOEMNNHONCHBFCEBLCIAA.niels.waller@vanderbilt.edu>



I am trying (with no success) to split a string at a period. Should I be
using a different function?


This is my string
> x<-"a6502.1"


This works fine.
> strsplit(x,"2")
[[1]]
[1] "a650" ".1"

This also works fine.
> strsplit(x,"1")
[[1]]
[1] "a6502."


But this seems strange
> strsplit(x,".")
[[1]]
[1] "" "" "" "" "" "" ""


Niels


0=================================================0
Dr. Niels G. Waller
Quantitative Methods
Department of Psychology and Human Development
Box 512 Peabody College
Vanderbilt University
Nashville TN 37203
email:  niels.waller at vanderbilt.edu
fax:    615 343-9494
QME home page: http://www.vanderbilt.edu/quantmetheval
http://peabody.vanderbilt.edu/depts/psych_and_hd/faculty/wallern/
0=================================================0

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Dec 17 18:57:19 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 17 Dec 2001 09:57:19 -0800 (PST)
Subject: [R] Correct file permissions?
In-Reply-To: <Pine.LNX.4.33.0112171821160.8879-100000@tal.stat.umu.se>
Message-ID: <Pine.A41.4.33.0112170952070.61002-100000@homer40.u.washington.edu>

On Mon, 17 Dec 2001, [iso-8859-1] Göran Broström wrote:

> I'm running 'R cmd CHECK' (on Linux) and get a WARNING:
>
> -----------------------------------------------------------------
> *   Found the following text files with incorrect permissions:
> .
> .
> .
> *   Please fix permissions.
> -----------------------------------------------------------------
> What is 'correct permissions'?

A package needs to have enough permission to be used by users and written
without errors by root (for installation).

The current check is that permissions are at least 644 (rw-r--r--) for
files and 755 (rwxr-xr-x) for directories, which is a little stronger than
necessary, but is usually reasonable.


	-thomas




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Dec 17 18:59:26 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 17 Dec 2001 09:59:26 -0800 (PST)
Subject: [R] strsplit behavior
In-Reply-To: <NDBBLLOPOEMNNHONCHBFCEBLCIAA.niels.waller@vanderbilt.edu>
Message-ID: <Pine.A41.4.33.0112170957390.61002-100000@homer40.u.washington.edu>

On Mon, 17 Dec 2001, Niels Waller wrote:
> I am trying (with no success) to split a string at a period. Should I be
> using a different function?
<snip>
> > strsplit(x,".")
> [[1]]
> [1] "" "" "" "" "" "" ""

No, the problem is that the split argument is a regular expression, not a
character string. "." is a regular expression that matches any single
character.

You want strsplit(x,"\\."), a regular expression that matches only the "."
character.  This *is* one of the examples in help(strsplit)


	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From YZhu at golder.com  Mon Dec 17 18:58:09 2001
From: YZhu at golder.com (Zhu, Yi)
Date: Mon, 17 Dec 2001 09:58:09 -0800
Subject: [R] smoothing line and a pair of confidence intervals
Message-ID: <2BDFE2BD9829D31191E3009027729D60CB0828@atlexchange.golder.com>


Hi R Users,

I am very new to R and would like to do something quick if possible, please
help!

Suppose I have a data set of y versus x, how can I generate a smoothing line
of y versus x (for example, using loess)
and at the same time, generate a pair of confidence intervals for the
smoothing or mean plus/minus standard deviation?

Yi Zhu
Golder Associates Inc.
USA



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Mon Dec 17 19:21:51 2001
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Mon, 17 Dec 2001 14:21:51 -0400
Subject: [R] help for input
References: <AF84AD19B4A8D411B18500508BAF0E0EC2987C@se-excur01-uslj.nadi.uslj>
Message-ID: <3C1E37BF.4AC0E94C@umsanet.edu.bo>

You should probably convert Group to factor like
data$Group <- factor(data$Group)

the you can subset using 

data[data$Group == "1", ]

or you can use tapply


Kjetil Halvorsen

yiping.fan at syngenta.com wrote:
> 
> Hello, all,
>     I have a question regarding data input.  For example: I have a file like
> this
>        Group exp value
>  001 1  1   5
> 002   1  2  4
> 003   1  3  4
> 004  2   1  4
> 005 2    1  4
> 006  3    2  3
> 007  3   4 5
> 008  3  4  5
> 009   3  5  6
> I read it using
> f<-read.table("infile")
> we have 3 groups here,
> group1 have 3 exps
> group 2 havs 2 exps
> group 3 has 4 exps
> After I read the file,  how can I get the data for each group?   Thanks!
> 
> Yiping
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From heberto.ghezzo at mcgill.ca  Mon Dec 17 19:28:31 2001
From: heberto.ghezzo at mcgill.ca (Heberto Ghezzo)
Date: Mon, 17 Dec 2001 13:28:31 -0500
Subject: [R] environments again
Message-ID: <3C1E394F.C09C6682@mcgill.ca>

In a previous message I was not clear enough in my querry.
I have the following program:

tst<- function() {
 x <- c(32.7,32.3,31.5,32.1,29.7,29.1,35.7,35.9,33.1,
         36.0,34.2,31.2,31.8,28.0,29.2,38.2,37.8,31.9,
         32.5,31.1,29.7)
 g <- rep(1:7,rep(3,7))
 s <- rep(1:3,7)
 cat(" Only x and g \n")
 aov1(x,g)
 cat("\n\n  Now x, g and s \n")
 aov1(x,g,s=s)
}

aov1 <- function(y,g,s=NULL,comp="mca",meth="Sidak") {
#
  fun <- function(x)
    c(mean(x,na.rm=T),sd(x,na.rm=T),length(x[!is.na(x)]))
#
  li <- length(unique(g))
  cat("   Analysis of Variance with Multiple comparisons\n\n")
  cat(" Groups : ",li,"\n")
  t <- tapply(y,g,fun)

  a <- array(c(t,recursive=T),c(3,li))
  dimnames(a) <- list(c("Mean","S.Dev","n"),1:li)
  df <- length(y)-li
  cat(" Means : ",a[1,],"\n")
  cat(" S.Dev : ",a[2,],"\n")
  cat("  n    : ",a[3,],"\n\n")
#
  if(is.null(s)) {
    b <- aov(y ~ as.factor(g))
    d <- summary(b)
    df <- b$df
    e <- d[[1]][3]
    sig <- e[[1]][2]
  }
  if(!is.null(s)) {
    b <- aov(y ~ as.factor(g) + Error(as.factor(s)))
    d <- summary(b)
    df <- b$Within[8]
    e <- sqrt(d[[2]][[1]][3])
    sig <- unlist(e[[1]][2])
  }
  cat("   Anova \n")
  print(d)
  cat("\n")
}

now aov1 after printing d normally call a function to compute multiple
comparisos that I wrote. I do not have S.
I need to call aov in order to get the residual errors for the test
under the 1 way anova case 1 or the randomized block design case 2.
If I run the program I get with R 1.23 on Win98

tst()
 Only x and g
   Analysis of Variance with Multiple comparisons

 Groups :  7
 Means :  32.16667 30.3 34.9 33.8 29.66667 35.96667 31.1
 S.Dev :  0.6110101 1.587451 1.56205 2.424871 1.942507 3.527511 1.4
  n    :  3 3 3 3 3 3 3

   Anova
             Df  Sum Sq Mean Sq F value  Pr(>F)
as.factor(g)  6 103.151  17.192  4.0947 0.01397 *
Residuals    14  58.780   4.199
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1



  Now x, g and s
   Analysis of Variance with Multiple comparisons

 Groups :  7
 Means :  32.16667 30.3 34.9 33.8 29.66667 35.96667 31.1
 S.Dev :  0.6110101 1.587451 1.56205 2.424871 1.942507 3.527511 1.4
  n    :  3 3 3 3 3 3 3

Error in eval(expr, envir, enclos) : Object "y" not found
>
Querry: Why do I get the Error?
aov1 runs the first time calling aov(y~x) and does not complain of y not
being found
> traceback()
12: eval(expr, envir, enclos)
11: eval(attr(formula, "variables"), data, env)
10: model.frame.default(formula = y ~ as.factor(s), drop.unused.levels =
TRUE)
9: model.frame(formula = y ~ as.factor(s), drop.unused.levels = TRUE)
8: eval(expr, envir, enclos)
7: eval(mf, parent.frame())
6: lm(formula = y ~ as.factor(s), singular.ok = TRUE, method = "qr",
       qr = TRUE)
5: eval(expr, envir, enclos)
4: eval(ecall, parent.frame())
3: aov(y ~ as.factor(g) + Error(as.factor(s)))
2: aov1(x, g, s = s)
1: tst()
>
Sorry but I do not have a clue as to which environment is active when
the error was called
Help anyone?
Thanks
.
Heberto Ghezzo
Meakins-Christie Labs
McGill University
Montreal Canada


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rod.chav at hsoft.es  Mon Dec 17 23:03:38 2001
From: rod.chav at hsoft.es (antonio)
Date: Mon, 17 Dec 2001 23:03:38 +0100
Subject: [R] help with library(tcltk)
Message-ID: <01121723033900.01164@Yerupaja>

Hi All,

I have tried several times to run this library and I get the following 
message:

> library(tcltk) 
Error in firstlib(which.lib.loc, package) :  
       invalid command name "tcl_findLibrary" 
Error in library(tcltk) : 
.First.lib failed 
>

I have checked either the tcl and tk libraries and they are correctly 
installed (/usr/lib/). I have other program (Grass) that make use of them and 
it works correctly.

System:

Intel Pentium MMX
Linux Mandrake 8.0
Tcl/Tk 8.3

Thanks in advance,

Antonio

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From YZhu at golder.com  Mon Dec 17 23:18:27 2001
From: YZhu at golder.com (Zhu, Yi)
Date: Mon, 17 Dec 2001 14:18:27 -0800
Subject: [R] smoothing line and a pair of confidence intervals
Message-ID: <2BDFE2BD9829D31191E3009027729D60CB082A@atlexchange.golder.com>


Hello R Users,

I am very new to R and would like to do something quick if possible, please
help!

Suppose I have a data set of y versus x, how can I generate a smoothing line
of y versus x (for example, using loess)
and at the same time, generate a pair of confidence intervals for the
smoothing or mean plus/minus standard deviation?

Best regards,

Yi Zhu


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From edd at debian.org  Mon Dec 17 23:34:03 2001
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 17 Dec 2001 16:34:03 -0600
Subject: [R] help with library(tcltk)
In-Reply-To: <01121723033900.01164@Yerupaja>
References: <01121723033900.01164@Yerupaja>
Message-ID: <20011217223403.GA11005@sonny.eddelbuettel.com>

On Mon, Dec 17, 2001 at 11:03:38PM +0100, antonio wrote:
> I have tried several times to run this library and I get the following 
> message:
> 
> > library(tcltk) 
> Error in firstlib(which.lib.loc, package) :  
>        invalid command name "tcl_findLibrary" 
> Error in library(tcltk) : 
> .First.lib failed 
> >
> 
> I have checked either the tcl and tk libraries and they are correctly 
> installed (/usr/lib/). I have other program (Grass) that make use of them and 
> it works correctly.

That alone is not meaningful. More important is whether tcl/tk was found
when R was compiled. You can look at

> capabilities("tcltk")

if you R binary has been built with tcl/tk support.  

Having said that, the snippet above suggest that tcltk was compiled in, but
might have broken later. Try to locate the tcltk.so [ my system has it at
/usr/lib/R/library/tcltk/libs/tcltk.so as R lives below /usr/lib/R here ]
and run ldd on it as in

ldd /usr/lib/R/library/tcltk/libs/tcltk.so 

You need to see the libtcl and libtk libraries resolved for tcltk to work.

Hope this helps, Dirk

-- 
Good judgment comes from experience; experience comes from bad judgment. 
							    -- F. Brooks
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Mon Dec 17 23:46:44 2001
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Mon, 17 Dec 2001 17:46:44 -0500 (EST)
Subject: [R] smoothing line and a pair of confidence intervals
In-Reply-To: <2BDFE2BD9829D31191E3009027729D60CB082A@atlexchange.golder.com>
Message-ID: <Pine.LNX.4.30.0112171742570.580-100000@bolker.zoo.ufl.edu>


help.search("loess")

points you to the loess() and predict.loess() functions in the modreg
library.  You'll have to first do

library(modreg)

to get access to these functions.  Then see the help pages

?loess
?predict.loess

which among other things says that predict.loess() can be asked for
standard errors.
  To plot points and add lines to a graph, see

?plot
?lines

  I think this is the second time you've sent this message to the list --
just a polite reminder that the folks on the list are helping out
completely out of some sense of public spirit and have no real obligation
to answer questions quickly (or at all, for that matter) ...

  cheers,
    Ben Bolker


On Mon, 17 Dec 2001, Zhu, Yi wrote:

>
> Hello R Users,
>
> I am very new to R and would like to do something quick if possible,
> please help!
>
> Suppose I have a data set of y versus x, how can I generate a
> smoothing line of y versus x (for example, using loess) and at the
> same time, generate a pair of confidence intervals for the smoothing
> or mean plus/minus standard deviation?
>
> Best regards,
>
> Yi Zhu
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Dec 17 23:43:58 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Dec 2001 23:43:58 +0100
Subject: [R] help with library(tcltk)
In-Reply-To: <01121723033900.01164@Yerupaja>
References: <01121723033900.01164@Yerupaja>
Message-ID: <x27krlbh75.fsf@blueberry.kubism.ku.dk>

antonio <rod.chav at hsoft.es> writes:

> Hi All,
> 
> I have tried several times to run this library and I get the following 
> message:
> 
> > library(tcltk) 
> Error in firstlib(which.lib.loc, package) :  
>        invalid command name "tcl_findLibrary" 
> Error in library(tcltk) : 
> .First.lib failed 
> >
> 
> I have checked either the tcl and tk libraries and they are correctly 
> installed (/usr/lib/). I have other program (Grass) that make use of them and 
> it works correctly.
> 
> System:
> 
> Intel Pentium MMX
> Linux Mandrake 8.0
> Tcl/Tk 8.3

Which version of R, and did you compile it yourself? If so, did tcl/tk
support get enabled?

I get a sense of deja vu from this, so you might want to check the
archives. 

Nothing in R is messing with tcl_findLibrary but that command is
generally known to Tcl interpreters, including the one that R starts:

> library(tcltk)
> .Tcl("tcl_findLibrary")
Error in .Tcl("tcl_findLibrary") : [tcl] no value given for parameter
"basename" to "tcl_findLibrary".

It appears that it is generally defined in /usr/lib/tcl8.3/auto.tcl.
Your error comes from the Tcl interpreter, so it seems that you're
loading the library OK, but then initialization fails somehow. Might
it be that you have multiple versions installed or that the
LD_LIBRARY_PATH got somehow messed up?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Dec 17 23:55:34 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 17 Dec 2001 14:55:34 -0800 (PST)
Subject: [R] environments again
In-Reply-To: <3C1E394F.C09C6682@mcgill.ca>
Message-ID: <Pine.A41.4.33.0112171430180.61002-100000@homer40.u.washington.edu>


Yes, there's a bug. It's not as simple as your email suggests -- and it
provides a nice illustration of why a reproducible example is much more
helpful than  a hypothesis ("adding an extra argument makes it unable to
find the first argument")

 Also note that the problem doesn't happen if the variables are in a
data= argument, which is a simple way to stop this happening and is
generally a Good Thing.


Read on for more detail than you probably want. Here's a simpler version
that shows the problem and doesn't use common variable names -- with your
functions and the internals of aov there were too many things called `y'
for my taste.

ff<-function(){
  why<-1:10
  ex<-rep(0:1,5)
  ess<-rep(1:5,2)

  print(aov(why~ex)) 		# works
  print(aov(why~ex+Error(ess))) # doesn't
}

So the problem has something to do with Error() terms.

The traceback() shows that the error occurs inside aov, when it is creates
a new lm(why~ess) call to handle the Error(). At this point we have

  Browse[1]> ecall
  lm(formula = why ~ ess, singular.ok = TRUE, method = "qr", qr = TRUE)
  Browse[1]> eval(ecall,parent.frame())
  Error in eval(expr, envir, enclos) : Object "why" not found

but evaluating seemly the same explicit formula works

  Browse[1]> eval(quote(lm(formula = why ~ ess, singular.ok = TRUE, method =
  "qr", qr = TRUE)),parent.frame())

  Call:
  lm(formula = why ~ ess, method = "qr", qr = TRUE, singular.ok = TRUE)

  Coefficients:
  (Intercept)          ess
          2.5          1.0


This suggests that we have a problem with formula environments, and indeed
 Browse[1]> ls(env=environment(formula(ecall)))
  [1] "Call"        "Terms"       "allTerms"    "contrasts"   "data"
  [6] "eTerm"       "ecall"       "errorterm"   "formula"     "indError"
 [11] "intercept"   "lmcall"      "opcons"      "projections" "qr"
where the original formula argument has
 Browse[1]> ls(env=environment(formula))
 [1] "ess" "ex"  "why"
agreeing with
 Browse[1]> ls(env=parent.frame())
 [1] "ess" "ex"  "why"

So it's a bug in aov() caused by the relatively new scoping rules for
formulas, where variables that aren't found in a specified data frame are
now sought in the environment of the formula.

In most cases this is an improvement over the previous rules, but it
causes problems for functions that do surgery on formulas, like aov() and
coxph().

I think a fix should be simple but it may be too late for 1.4.0, which is
due nearly tomorrow.

	-thomas




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Tue Dec 18 00:57:48 2001
From: brahm at alum.mit.edu (David Brahm)
Date: Mon, 17 Dec 2001 18:57:48 -0500
Subject: [R] colSums in C
Message-ID: <15390.34428.317569.814689@gargle.gargle.HOWL>

I asked how to write speedy C code to implement colSums().  My original version
on a 400x40000 matrix took 5.72s.

Peter Dalgaard <p.dalgaard at biostat.ku.dk> suggested some more efficient coding,
which sped my example up to 3.90s.  Douglas Bates <bates at stat.wisc.edu>
suggested using .Call() instead of .C, and I was amazed to see the time went
down to 0.69s!  Doug had actually posted his code (a package called "MatUtils")
to R-help on July 19, 2001.

I've taken Doug's code, added names to the result, and included an na.rm flag.
Unfortunately, my na.rm option makes it really slow again! (12.15s).  That's no
faster than pre-processing the matrix with "m[is.na(m)] <- 0".  Can anyone help
me understand why the ISNA conditional is taking so much time?  The C code is
below.  Thanks!

---- begin "colSums.c" (90% due to Doug Bates) ----
#include <R.h>
#include <Rdefines.h>

SEXP colSums(SEXP m, SEXP NaRm) {
    int i, j, *mdims, n, p, narm;
    double *mm, sum;
    SEXP val, nms;

    if (!isMatrix(m)) error("m must be a matrix");
    mdims = INTEGER(GET_DIM(m));
    narm  = asLogical(NaRm);
    n = mdims[0]; p = mdims[1];
    PROTECT(val  = NEW_NUMERIC(p));
    PROTECT(nms  = GET_COLNAMES(GET_DIMNAMES(m)));
    PROTECT(  m  = AS_NUMERIC(m));
    mm = REAL(m);
    if (narm) for (j = 0; j < p; j++) {
      for (sum = 0., i = 0; i < n; i++) if (!ISNA(mm[i])) sum += mm[i];
      REAL(val)[j] = sum;
      mm += n;
    } else for (j = 0; j < p; j++) {
      for (sum = 0., i = 0; i < n; i++) sum += mm[i];
      REAL(val)[j] = sum;
      mm += n;
    }
    namesgets(val, nms);
    UNPROTECT(3);
    return val;
}
---- end "colSums.c" ----

-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Tue Dec 18 01:07:26 2001
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 17 Dec 2001 16:07:26 -0800 (PST)
Subject: [R] smoothing line and a pair of confidence intervals
Message-ID: <Pine.GSO.4.10.10112171605360.18903-100000@quetelet.stat.ucla.edu>

Also, the sm library has a nice function for doing a kernel smooth:

sm.regression(x, y, h = <bandwidth>, display="se")

does three things:  plot the points, draw the smooth line, draw the
confidence intervals (dotted lines).  You supply the bandwidth, of course.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Mon, 17 Dec 2001, Zhu, Yi wrote:

> 
> Hello R Users,
> 
> I am very new to R and would like to do something quick if possible, please
> help!
> 
> Suppose I have a data set of y versus x, how can I generate a smoothing line
> of y versus x (for example, using loess)
> and at the same time, generate a pair of confidence intervals for the
> smoothing or mean plus/minus standard deviation?
> 
> Best regards,
> 
> Yi Zhu
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Dec 18 01:32:29 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 18 Dec 2001 01:32:29 +0100
Subject: [R] colSums in C
In-Reply-To: <15390.34428.317569.814689@gargle.gargle.HOWL>
References: <15390.34428.317569.814689@gargle.gargle.HOWL>
Message-ID: <x2pu5d1i76.fsf@blueberry.kubism.ku.dk>

David Brahm  <brahm at alum.mit.edu> writes:

> I asked how to write speedy C code to implement colSums().  My original version
> on a 400x40000 matrix took 5.72s.
> 
> Peter Dalgaard <p.dalgaard at biostat.ku.dk> suggested some more efficient coding,
> which sped my example up to 3.90s.  Douglas Bates <bates at stat.wisc.edu>
> suggested using .Call() instead of .C, and I was amazed to see the time went
> down to 0.69s!  Doug had actually posted his code (a package called "MatUtils")
> to R-help on July 19, 2001.
> 
> I've taken Doug's code, added names to the result, and included an na.rm flag.
> Unfortunately, my na.rm option makes it really slow again! (12.15s).  That's no
> faster than pre-processing the matrix with "m[is.na(m)] <- 0".  Can anyone help
> me understand why the ISNA conditional is taking so much time?  The C code is
> below.  Thanks!


>     if (narm) for (j = 0; j < p; j++) {
>       for (sum = 0., i = 0; i < n; i++) if (!ISNA(mm[i])) sum += mm[i];

ISNA maps to the *function* R_IsNA and function calls are expensive.
Also, you are probably breaking some pipelining with the extra
conditional. Just for testing, what happens if you use isnan()
instead? 

We could potentially set things up so that the compiler gets a chance
to inline R_IsNA and friends, so I wonder how much we might gain.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Dec 18 01:32:34 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 17 Dec 2001 16:32:34 -0800 (PST)
Subject: [R] colSums in C
In-Reply-To: <15390.34428.317569.814689@gargle.gargle.HOWL>
Message-ID: <Pine.A41.4.33.0112171616060.61002-100000@homer40.u.washington.edu>

On Mon, 17 Dec 2001, David Brahm wrote:

> I asked how to write speedy C code to implement colSums().  My original version
> on a 400x40000 matrix took 5.72s.
>
> Peter Dalgaard <p.dalgaard at biostat.ku.dk> suggested some more efficient coding,
> which sped my example up to 3.90s.  Douglas Bates <bates at stat.wisc.edu>
> suggested using .Call() instead of .C, and I was amazed to see the time went
> down to 0.69s!  Doug had actually posted his code (a package called "MatUtils")
> to R-help on July 19, 2001.
>
> I've taken Doug's code, added names to the result, and included an na.rm flag.
> Unfortunately, my na.rm option makes it really slow again! (12.15s).  That's no
> faster than pre-processing the matrix with "m[is.na(m)] <- 0".  Can anyone help
> me understand why the ISNA conditional is taking so much time?  The C code is
> below.  Thanks!

I don't find as much slow-down as you do.  I also get about 0.6s with
na.rm=FALSE but only about 2.3s with na.rm=TRUE, which is more reasonable
(this is Linux, Pentium III).

The ISNA() macro does expand to two function calls, which you would expect
to be quite a bit slower than a single addition.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From juli at ceam.es  Tue Dec 18 10:41:12 2001
From: juli at ceam.es (juli g. pausas)
Date: Tue, 18 Dec 2001 09:41:12 +0000
Subject: [R] chi-squared test
Message-ID: <3C1F0F38.A86702A0@ceam.es>

I don't quite understand the difference between the two methods for
performing a chi-squared test on contingency tables:  summary(table())
and   chisq.test()
They may different results. E.g.:

aa <- gl(2, 10)
bb <- as.factor(c(1,2,2,2,1,2,1,2,2,2,1,2,2,2,1,1,1,2,1,1))
aa <- c(aa, aa)
bb <- c(bb, bb)
table(aa, bb)
summary(table(aa, bb))
chisq.test(aa, bb)

Could somebody give me some clues?
Thanks in advance

Juli

--
Juli G. Pausas
Centro de Estudios Ambientales del Mediterraneo (CEAM)
C/ C.R. Darwin 14, Parc Tecnologic,
46980 Paterna, Valencia, SPAIN
Tel: (+ 34) 96 131 8227; Fax: (+ 34) 96 131 8190
mailto:juli at ceam.es
http://www.gva.es/ceam

GCTE Fire Network - http://www.gva.es/ceam/FireNetwork


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From a.trapletti at bluewin.ch  Tue Dec 18 09:49:19 2001
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Tue, 18 Dec 2001 09:49:19 +0100
Subject: [R] Re: Arima
References: <200112180301.EAA28505@stat.math.ethz.ch>
Message-ID: <3C1F030E.9D089FC7@bluewin.ch>

> Date: Mon, 17 Dec 2001 13:42:16 +0000 (GMT)
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Subject: Re: [R] Arima
>
> On Mon, 17 Dec 2001 Gerard.Keogh at cso.ie wrote:
>
> > On Sun, 16 Dec 2001, Pascal Grandeau wrote:
> > >
> > > Does anyone make a routine for regression with ARMA errors with least
> > > squares ?
> >
> > Prof Brian Ripley replies:
> >
> > What does that mean? `with least squares' implies independent errors.
> > arma() fits by so-called *conditional* least squares: that leaves out
> > terms in the log-likelihood which can be important, especially near
> > non-stationarity. I've never understood why anyone would want to do that,
> > except as a poor man's computational approximation.
>
> [End of quote]
>
> > When considering the MA(1) model Harvey in "Time Series Models p60" says
> > that assuming the initial disturbance to be fixed and equal to zero makes
> > the problem of maximising the likelihood function equivalent to minimising
> > the sum of squares of the errors - the result is then called the
> > conditional sum of squares (CSS) estimate. The calculation of this
> > "conditional likelihood function" is therefore simplified considerably and
> > the resulting equations which are still nonlinear in the parameters are
> > more readily optimised because analytic derivatives are available.
> >
> > Of course the exact likelihood function of any ARMA(p,q) model can be
> > generated from Kalman recursions via the prediction error decomposition.
> > Harvey's main argument for using the CSS estimate relies on the fact that
> > maximising the likelihood is time consuming for large p+q (for myself, I
> > take time consuming to mean that it's often very hard to find a solution to
> > a nonlinear problem!). However, I suspect that with the computing power now
> > available the time issue may be far less relevant.
>
> Exactly, as I said.
>
> > One final point though is that the CSS estimate may provide reasonable
> > starting values for the optimisation of the exact likelihood.
>
> Given that arima0() does the exact likelihood, and I've never had to wait
> more than a few seconds for it to do so, I still don't see why
> anyone would ask for conditional least squares instead, which was the
> request.

Let me just say a few words why I believe that optimizing the CSS might still be useful in some cases (or at
least have the possibility to choose between the CSS and the exact likelihood). As we all know arima models
are at best good approximations to "real" data. Therefore, from my point of view a discussion about
optimizing exact likelihood or not is rather academic. Except in a simulation setup, both the CSS and the
exact likelihood are only approximations to the "real" likelihood. And it is not at all clear which of both
provides a better approximation to the "real world". An example:

On the intraday level financial price time series may be approximated rather well by the random walk plus
noise model. However, the innovations are far from being Gaussian (have much much fatter tails, ARCH effects,
structural breaks etc). Hence, an MA(1) model with non-Gaussian (and maybe non iid) innovations is a good
candidate model for the return time series. However, explicitely modelling the innovation process is often
not a good idea (too complex, still missspecified due to structural breaks, etc). Therefore, just using a
Gaussian MA(1) model might be the first choice. The results from a small MC simulation:

DGP: MA(1) with a coefficient of -0.5, rt innovations with df = 2, number of Obs. = 100, number of simulated
paths = 5000:
Model: Gaussian MA(1)

> sqrt(mean((ma1+0.5)^2))
[1] 0.09509874
> sqrt(mean((ma2+0.5)^2))
[1] 0.09313703
> mean(ma1)
[1] -0.5223137
> mean(ma2)
[1] -0.5196037
> sd(ma1)
[1] 0.0924531
> sd(ma2)
[1] 0.09105966

where ma1 is the vector containing the estimated MA(1) coefficients from arima0 (exact likelihood) and ma2
from arma (CSS). Hence, it seems that the CSS provides in this example a marginally better estimator.

best
Adrian

--
Dr. Adrian Trapletti        Phone:     +41 (0)1 994 56 31
Wildsbergstrasse 31         Fax  :     +41 (0)1 994 56 33
CH-8610 Uster               Email: a.trapletti at bluewin.ch
Switzerland                 WWW  :   trapletti.homeip.net



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From slb at math.auc.dk  Tue Dec 18 09:54:40 2001
From: slb at math.auc.dk (=?iso-8859-1?Q?S=F8ren?= Buhl)
Date: Tue, 18 Dec 2001 09:54:40 +0100
Subject: [R] Re: new versions of grid and lattice
References: <011d01c18777$6e5c5f50$7632d882@stat.auckland.ac.nz>
Message-ID: <3C1F0450.C28B207@math.auc.dk>

Paul Murrell wrote:
> 
> Hi
> 
> New versions of the grid and lattice packages will be available with the
> release of R 1.4 (in a couple of days):
> 
>     grid_0.5
>     lattice_0.3-1
> 
> These packages will no longer be in the "development" directory (i.e., they
> will be in CRAN/src/contrib).
> 
> The changes in this release are mostly to grid, with lattice modified just
> to take account of those changes.
> 
> Some important points about the grid changes are ...
> 
> (i)  grid_0.5 will only work with R version 1.4 or later.
> 
> (ii)  The main new features are support for clipping to viewports and
> support for multiple devices.  See the file grid/doc/changes_0.5.txt for
> other changes.
> 
> (iii)  There is a known bug on Windows;  turning on plot history recording
> while producing grid graphics will crash R.  Adding individual plots to the
> plot history seems to work ok.
> 
> (iv)  Some things still missing are:  vector fonts, mathematical annotation,
> compatibility with base graphics, and many helpful suggestions from users
> that I still haven't found time to get to! :)
> 
> Paul Murrell
> Deepayan Sarkar
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-announce mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From snw at mcs.st-and.ac.uk  Tue Dec 18 10:04:49 2001
From: snw at mcs.st-and.ac.uk (Simon Wood)
Date: Tue, 18 Dec 2001 09:04:49 +0000 (GMT)
Subject: [R] smoothing line and a pair of confidence intervals
In-Reply-To: <2BDFE2BD9829D31191E3009027729D60CB082A@atlexchange.golder.com>
Message-ID: <Pine.GSO.4.21.0112180843490.21060-100000@dolphin>


> Suppose I have a data set of y versus x, how can I generate a smoothing line
> of y versus x (for example, using loess)
> and at the same time, generate a pair of confidence intervals for the
> smoothing or mean plus/minus standard deviation?

- You could use library mgcv:

library(mgcv)
g.m<-gam(y~s(x))
plot(g.m) # plot of centred smooth
# or alternatively.....
p.d<-data.frame(x=seq(min(x),max(x),length=100))
b<-predict.gam(g.m,p.d,se=TRUE)
range<-c(min(b$fit-2*b$se.fit),max(b$fit+2*b$se.fit))
plot(p.d$x,b$fit,ylim=range,xlab="x",ylab="y",type="l")
lines(p.d$x,b$fit+b$se.fit*2,col=2)
lines(p.d$x,b$fit-b$se.fit*2,col=2)

cheers,
Simon

  ______________________________________________________________________
> Simon Wood  snw at st-and.ac.uk  http://www.ruwpa.st-and.ac.uk/simon.html
> The Mathematical Institute, North Haugh, St. Andrews, Fife KY16 9SS UK
> Direct telephone: (0)1334 463799          Indirect fax: (0)1334 463748 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sharon at math.chalmers.se  Tue Dec 18 10:23:37 2001
From: sharon at math.chalmers.se (Sharon Kuhlmann-Berenzon)
Date: Tue, 18 Dec 2001 10:23:37 +0100 (MET)
Subject: [R] Aranda-Ornaz links for binary data
Message-ID: <Pine.SOL.4.30.0112181003400.22472-100000@lobachevsky.math.chalmers.se>


Hi,

I would like apply different link functions from Aranda-Ordaz (1981)
family to large binary dataset (n = 2000). The existing links in glm for
binomial data (logit, probit, cloglog) are not adequate for my data, and I
need to test some other transformations.

Is it possible to do this in R? And how?

Thank you for your help,

/Sharon


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
SHARON K?HLMANN-BERENZON

Tel. +46-31-772 53 60			Dept. Mathematical Statistics
Fax. +46-31-772 35 08			Chalmers University of Tech.
e-mail: sharon at math.chalmers.se		Eklandagatan 86
					412 96 G?teborg, Sweden


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec 18 10:31:43 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Dec 2001 09:31:43 +0000 (GMT)
Subject: [R] Aranda-Ornaz links for binary data
In-Reply-To: <Pine.SOL.4.30.0112181003400.22472-100000@lobachevsky.math.chalmers.se>
Message-ID: <Pine.LNX.4.31.0112180929500.19963-100000@gannet.stats>

You need to do two things:

1) in binomial, add to

    if (any(linktemp == c("logit", "probit", "cloglog", "log")))
        stats <- make.link(linktemp)

2) in make.link, add code for the links you want.

(Not tested recently, mark you.)

On Tue, 18 Dec 2001, Sharon Kuhlmann-Berenzon wrote:

> I would like apply different link functions from Aranda-Ordaz (1981)
> family to large binary dataset (n = 2000). The existing links in glm for
> binomial data (logit, probit, cloglog) are not adequate for my data, and I
> need to test some other transformations.
>
> Is it possible to do this in R? And how?
>
> Thank you for your help,
>
> /Sharon

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Dec 18 10:44:45 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 18 Dec 2001 10:44:45 +0100
Subject: [R] chi-squared test
In-Reply-To: <3C1F0F38.A86702A0@ceam.es>
References: <3C1F0F38.A86702A0@ceam.es>
Message-ID: <x2adwgg8vm.fsf@blueberry.kubism.ku.dk>

"juli g. pausas" <juli at ceam.es> writes:

> I don't quite understand the difference between the two methods for
> performing a chi-squared test on contingency tables:  summary(table())
> and   chisq.test()
> They may different results. E.g.:
> 
> aa <- gl(2, 10)
> bb <- as.factor(c(1,2,2,2,1,2,1,2,2,2,1,2,2,2,1,1,1,2,1,1))
> aa <- c(aa, aa)
> bb <- c(bb, bb)
> table(aa, bb)
> summary(table(aa, bb))
> chisq.test(aa, bb)
> 
> Could somebody give me some clues?
> Thanks in advance

The summary method is not doing Yates' correction.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From orp at intras.es  Tue Dec 18 11:35:31 2001
From: orp at intras.es (Oscar Rueda)
Date: Tue, 18 Dec 2001 11:35:31 +0100
Subject: [R] chi-squared test
In-Reply-To: <3C1F0F38.A86702A0@ceam.es>
Message-ID: <ZTGETSVU6JHPOONNMNH9484PK06HC31.3c1f1bf3@ides3>

chisq.test() uses Yates correction
Use instead 
chisq.test(aa, bb,correct=F)

and you'll get the same results

Oscar 



18/12/01 10:41:12, "juli g. pausas" <juli at ceam.es> escribió:

>I don't quite understand the difference between the two methods for
>performing a chi-squared test on contingency tables:  summary(table())
>and   chisq.test()
>They may different results. E.g.:
>
>aa <- gl(2, 10)
>bb <- as.factor(c(1,2,2,2,1,2,1,2,2,2,1,2,2,2,1,1,1,2,1,1))
>aa <- c(aa, aa)
>bb <- c(bb, bb)
>table(aa, bb)
>summary(table(aa, bb))
>chisq.test(aa, bb)
>
>Could somebody give me some clues?
>Thanks in advance
>
>Juli
>
>--
>Juli G. Pausas
>Centro de Estudios Ambientales del Mediterraneo (CEAM)
>C/ C.R. Darwin 14, Parc Tecnologic,
>46980 Paterna, Valencia, SPAIN
>Tel: (+ 34) 96 131 8227; Fax: (+ 34) 96 131 8190
>mailto:juli at ceam.es
>http://www.gva.es/ceam
>
>GCTE Fire Network - http://www.gva.es/ceam/FireNetwork
>
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
>



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bxc at novonordisk.com  Tue Dec 18 11:54:31 2001
From: bxc at novonordisk.com (BXC (Bendix Carstensen))
Date: Tue, 18 Dec 2001 11:54:31 +0100
Subject: [R] Aranda-Ornaz links for binary data
Message-ID: <D5A7D734C9C5D211B9E30008C78923020E95B073@exdkba03.novo.dk>

Here is a dirty trick I once learned from Peter Dalgaard:
Take a copy of the binomial family and then change the relevant bits.

Clumsy, because you have to fiddle with the rho in a loop or
something similar. But it works:

boxcox <- binomial()
boxcox$link    <- "Box-Cox link family"
boxcox$linkfun <- function(mu) log((1-mu)^(-rho)-1) - log(rho)
boxcox$linkinv <- function(eta) 1-(1+rho*exp(eta))^(-1/rho)
boxcox$mu.eta  <- function(eta) exp(eta)*(1+rho*exp(eta))^(-1/rho-1)
x1 <- rnorm(300)
x2 <- rnorm(300)
eta <- 0.2 + 0.5*x1 + 0.7*x2 + rnorm(300)/5
tigol <- function(x) exp(x)/(1+exp(x))  #inverse of logit
y <- rbinom(300,1,tigol(eta))
rho <- 0.7
glm( y~x1+x2,family=boxcox)

Good luck,
Bendix Carstensen
----------------------
Bendix Carstensen
Senior Statistician
Steno Diabetes Centre
Niels Steensens Vej 2
DK-2820 Gentofte
Denmark
tel: +45 44 43 87 38
mob: +45 28 25 87 38
fax: +45 44 43 73 13
bxc at novonordisk.com
www.biostat.ku.dk/~bxc
----------------------

> -----Original Message-----
> From: Sharon Kuhlmann-Berenzon [mailto:sharon at math.chalmers.se] 
> Sent: 18. december 2001 10:24
> To: r-help at lists.R-project.org
> Subject: [R] Aranda-Ornaz links for binary data
> 
> 
> 
> Hi,
> 
> I would like apply different link functions from Aranda-Ordaz 
> (1981) family to large binary dataset (n = 2000). The 
> existing links in glm for binomial data (logit, probit, 
> cloglog) are not adequate for my data, and I need to test 
> some other transformations.
> 
> Is it possible to do this in R? And how?
> 
> Thank you for your help,
> 
> /Sharon
> 
> 
> +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
> SHARON K?HLMANN-BERENZON
> 
> Tel. +46-31-772 53 60			Dept. Mathematical Statistics
> Fax. +46-31-772 35 08			Chalmers University of Tech.
> e-mail: sharon at math.chalmers.se		Eklandagatan 86
> 					412 96 G?teborg, Sweden
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-> FAQ.html
> Send "info", 
> "help", or "[un]subscribe"
> (in the 
> "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch 
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Tue Dec 18 13:13:12 2001
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 18 Dec 2001 07:13:12 -0500
Subject: [R] chi-squared test
In-Reply-To: <3C1F0F38.A86702A0@ceam.es>
Message-ID: <5.1.0.14.2.20011218070807.01d298b0@mcmail.cis.mcmaster.ca>

Dear Juli,

As the output from chisq.test (and the help for this function) indicates, 
chisq.test by default applies a Yates continuity correction. Using 
chisq.test(aa, bb, correct=F) produces the same result as the summary 
function for table objects.

John

At 09:41 AM 12/18/2001 +0000, juli g. pausas wrote:
>I don't quite understand the difference between the two methods for
>performing a chi-squared test on contingency tables:  summary(table())
>and   chisq.test()
>They may different results. E.g.:
>
>aa <- gl(2, 10)
>bb <- as.factor(c(1,2,2,2,1,2,1,2,2,2,1,2,2,2,1,1,1,2,1,1))
>aa <- c(aa, aa)
>bb <- c(bb, bb)
>table(aa, bb)
>summary(table(aa, bb))
>chisq.test(aa, bb)
>
>Could somebody give me some clues?
>Thanks in advance

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From use at eio.uva.es  Tue Dec 18 13:21:02 2001
From: use at eio.uva.es (=?Windows-1252?Q?Eusebio_Arenal_Guti=E9rrez?=)
Date: Tue, 18 Dec 2001 13:21:02 +0100
Subject: [R] Newbie problems with R and compiled C
Message-ID: <000d01c187be$759acda0$2a27589d@paquito>

I'm a beginer programming C and I have the following problem:

I have the following C-code file

#include <stdlib.h>

void gen(int *n,  int *a, int *c, int *m, int *x0, int *x);

main(){
  int nn = 31;
  int aa = 3;
  int cc = 0;
  int mm = 31;
  int xx0 = 9;
  int xx[nn];
  int i;
  gen(&nn,&aa,&cc,&mm,&xx0,xx);
  for (i = 0; i <= nn-1; i++)
    printf("%d ,",xx[i]);
  printf("\n %d",nn);
  printf("\n %d",aa);
  printf("\n %d",cc);
  printf("\n %d",mm);
  printf("\n %d",xx0);
}

void gen(int *n,  int *a, int *c, int *m, int *x0, int *x){
  int i;
  x[0]=*x0;
  for (i = 1; i <= *n-1; i++)
    x[i] = (*a * x[i-1] + *c) % *m;
}

I compile it with:

gcc gen2.c -o gen2.exe (Within emacs in W2000)

and executing gen2.exe the result is the correct one:

9 ,27 ,19 ,26 ,16 ,17 ,20 ,29 ,25 ,13 ,8 ,24 ,10 ,30 ,28 ,22 ,4 ,12 ,5 ,15
,14 ,
11 ,2 ,6 ,18 ,23 ,7 ,21 ,1 ,3 ,9 ,
 31
 3
 0
 31
 9

Then I put in a library with files:

#include <stdlib.h>

void gen(int *n,  int *a, int *c, int *m, int *x0, int *x){
  int i;
  x[0] = *x0;
  for (i = 1; i <= *n-1; i++)
    x[i] = (*a * x[i-1] + *c) % *m;
}

for the code and the wrapper function:

gen <- function(n, a, c, m, x0){
  .C("gen", x=integer(n),
          n=as.integer(n),
          a=as.integer(a),
          c=as.integer(c),
          m=as.integer(m),
          x0=as.integer(x0))
}

and the result is not the desired one:

> gen(n=31, a=3, c=0, m=31, x0=9)
$x
 [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

$n
[1] 31

$a
[1] 3

$c
[1] 0

$m
[1] 31

$x0
[1] 31

In fact $x shouldn't be 0 and $x0 should be 9.

I think I'm missing something obvious with C and R.

Thanks for any hint,

Eusebio Arenal




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec 18 13:47:14 2001
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 18 Dec 2001 12:47:14 +0000 (GMT Standard Time)
Subject: [R] Newbie problems with R and compiled C
In-Reply-To: <000d01c187be$759acda0$2a27589d@paquito>
Message-ID: <Pine.WNT.4.31.0112181244330.1060-100000@gannet>

On Tue, 18 Dec 2001, [Windows-1252] Eusebio Arenal Gutiérrez wrote:

> I'm a beginer programming C and I have the following problem:
>
> I have the following C-code file
>
> #include <stdlib.h>
>
> void gen(int *n,  int *a, int *c, int *m, int *x0, int *x);
>
> main(){
>   int nn = 31;
>   int aa = 3;
>   int cc = 0;
>   int mm = 31;
>   int xx0 = 9;
>   int xx[nn];
>   int i;
>   gen(&nn,&aa,&cc,&mm,&xx0,xx);
>   for (i = 0; i <= nn-1; i++)
>     printf("%d ,",xx[i]);
>   printf("\n %d",nn);
>   printf("\n %d",aa);
>   printf("\n %d",cc);
>   printf("\n %d",mm);
>   printf("\n %d",xx0);
> }
>
> void gen(int *n,  int *a, int *c, int *m, int *x0, int *x){
>   int i;
>   x[0]=*x0;
>   for (i = 1; i <= *n-1; i++)
>     x[i] = (*a * x[i-1] + *c) % *m;
> }
>
> I compile it with:
>
> gcc gen2.c -o gen2.exe (Within emacs in W2000)
>
> and executing gen2.exe the result is the correct one:
>
> 9 ,27 ,19 ,26 ,16 ,17 ,20 ,29 ,25 ,13 ,8 ,24 ,10 ,30 ,28 ,22 ,4 ,12 ,5 ,15
> ,14 ,
> 11 ,2 ,6 ,18 ,23 ,7 ,21 ,1 ,3 ,9 ,
>  31
>  3
>  0
>  31
>  9
>
> Then I put in a library with files:
>
> #include <stdlib.h>
>
> void gen(int *n,  int *a, int *c, int *m, int *x0, int *x){
>   int i;
>   x[0] = *x0;
>   for (i = 1; i <= *n-1; i++)
>     x[i] = (*a * x[i-1] + *c) % *m;
> }
>
> for the code and the wrapper function:
>
> gen <- function(n, a, c, m, x0){
>   .C("gen", x=integer(n),
>           n=as.integer(n),
>           a=as.integer(a),
>           c=as.integer(c),
>           m=as.integer(m),
>           x0=as.integer(x0))
> }

The order of the args is wrong: it needs to be

.C("gen", as,integer(n), as.integer(a), as.integer(c), as.integer(m),
   as.integer(x0), x = integer(n)$n

I think.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From doraiss at auburn.edu  Tue Dec 18 14:04:41 2001
From: doraiss at auburn.edu (Sundardas Dorai-raj)
Date: Tue, 18 Dec 2001 07:04:41 -0600
Subject: [R] chi-squared test
Message-ID: <sc1eea96.020@groupwise1.duc.auburn.edu>

>>> "juli g. pausas" <juli at ceam.es> 12/18/01 05:52 AM >>>
> I don't quite understand the difference between the 
> two methods for
> performing a chi-squared test on contingency 
> tables:  summary(table())
> and   chisq.test()
> They may different results. E.g.:
> 
> aa <- gl(2, 10)
> bb <- as.factor(c
> (1,2,2,2,1,2,1,2,2,2,1,2,2,2,1,1,1,2,1,1))
> aa <- c(aa, aa)
> bb <- c(bb, bb)
> table(aa, bb)
> summary(table(aa, bb))
> chisq.test(aa, bb)
> 
> Could somebody give me some clues?
> Thanks in advance
> 
> Juli

>From help(chisq.test):

correct: a logical indicating whether to apply continuity correction
when computing the test statistic.

Setting correct=F gives the same answer as summary.table.

Sundar
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From heberto at meakins.lan.mcgill.ca  Tue Dec 18 16:29:09 2001
From: heberto at meakins.lan.mcgill.ca (R. Heberto Ghezzo)
Date: Tue, 18 Dec 2001 11:29:09 -0400
Subject: [R] environments again 2
Message-ID: <3C1F60C4.57D97FE3@meakins.lan.mcgill.ca>

Hello,
First thanks to T.Lumley for his prompt and detailed response to
my previous problem with aov, since he send a copy to r-help
I will not repeat it here. Suffice to say that adding
data=data.frame(x,g,s)
works well and no more problems. Thanks Thomas.
Now
here there is another problem with my program to compute
multiple comparisons. From App.Stat I have a fortran program to compute
the probability for Dunnett tests. I compiled it to a dll and it works
well, no problems there. Now I need the inverse 'qdunnett' and I
decided that an easy way |:-)) was to use nls to find the point.
something similar to:

>  alpha<-0.05
>  df<-10
>  nls.control()
$maxiter
[1] 50

$tol
[1] 1e-05

$minFactor
[1] 0.0009765625

>  b<- nls(d~pt(x,a),start=list(x=1),trace=T)
0.6077036 :  1
0.0009502682 :  -2.384037
5.820193e-05 :  -1.913299
4.509105e-07 :  -1.804280
1.659796e-11 :  -1.812411
2.335228e-20 :  -1.812461
4.814825e-33 :  -1.812461
4.333342e-34 :  -1.812461
......
4.333342e-34 :  -1.812461
Error in nls(d ~ pt(x, a), start = list(x = 1), trace = T) :
        number of iterations exceeded maximum of 5.32952e-306
>
which I naively assume will give me a qt in a round about way, so
it could provide me with the qdunnett that I needed, but although it
converges in 3 iterations it does not exit!
Trying with a simple function:
>  fun<-function(x,a) x*x-a
>  b<- nls(d~fun(x,a),start=list(x=1),trace=T)
81.9025 :  1
0.3527249 :  3.2625
6.863586e-05 :  3.17148
2.910360e-12 :  3.170174
6.503427e-27 :  3.170173
1.141884e-30 :  3.170173
.....
1.141884e-30 :  3.170173
Error in nls(d ~ fun(x, a), start = list(x = 1), trace = T) :
        number of iterations exceeded maximum of 5.32952e-306

same error and no exit.
Using R 1.3.1 on Win98. What am I doing wrong this time? there is
no data= here. Is this a bug in nls?
Thanks for any help


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Tue Dec 18 17:22:38 2001
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 18 Dec 2001 08:22:38 -0800 (PST)
Subject: [R] Newbie problems with R and compiled C
In-Reply-To: <Pine.WNT.4.31.0112181244330.1060-100000@gannet>
Message-ID: <Pine.GSO.4.10.10112180820110.7828-100000@quetelet.stat.ucla.edu>



-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Tue, 18 Dec 2001, Prof Brian D Ripley wrote:

> > Then I put in a library with files:
> >
> > #include <stdlib.h>
> >
> > void gen(int *n,  int *a, int *c, int *m, int *x0, int *x){
> >   int i;
> >   x[0] = *x0;
> >   for (i = 1; i <= *n-1; i++)
> >     x[i] = (*a * x[i-1] + *c) % *m;
> > }
> >
> > for the code and the wrapper function:
> >
> > gen <- function(n, a, c, m, x0){
> >   .C("gen", x=integer(n),
> >           n=as.integer(n),
> >           a=as.integer(a),
> >           c=as.integer(c),
> >           m=as.integer(m),
> >           x0=as.integer(x0))
> > }
> 
> The order of the args is wrong: it needs to be
> 
> .C("gen", as,integer(n), as.integer(a), as.integer(c), as.integer(m),
>    as.integer(x0), x = integer(n)$n
> 
> I think.

Prof. Ripley is right, the order of the arguments is incorrect.  But I
think, what you want is:

.C("gen", as,integer(n), as.integer(a), as.integer(c), as.integer(m),
   as.integer(x0), x = integer(n)$x

since x is where you're storing the random numbers, no?

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Dec 18 17:44:36 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 18 Dec 2001 08:44:36 -0800 (PST)
Subject: [R] environments again 2
In-Reply-To: <3C1F60C4.57D97FE3@meakins.lan.mcgill.ca>
Message-ID: <Pine.A41.4.33.0112180841060.117158-100000@homer41.u.washington.edu>

On Tue, 18 Dec 2001, R. Heberto Ghezzo wrote:
> Now
> here there is another problem with my program to compute
> multiple comparisons. From App.Stat I have a fortran program to compute
> the probability for Dunnett tests. I compiled it to a dll and it works
> well, no problems there. Now I need the inverse 'qdunnett' and I
> decided that an easy way |:-)) was to use nls to find the point.
> something similar to:
>

nls() doesn't work well for noise-free problems like this (almost a FAQ).

For a simple case like this you should use uniroot.
See {p,q}birthday or power.t.test for an example

Incidentally, this doesn't seem to be an environments problem.
Descriptive subject lines on r-help messages really do help.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Tue Dec 18 18:31:53 2001
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Tue, 18 Dec 2001 13:31:53 -0400
Subject: [R] nlme: problems with gls
Message-ID: <3C1F7D89.221CA0CC@umsanet.edu.bo>

Hola!

> library(nlme)
Loading required package: nls 
> presion.gls <- gls( I(despues-antes) ~ 1 + I(antes-mean(antes)), 
+                     correlation=corSymm(value=0.5, form= ~ 1 |
subject) )
> summary(presion.gls)
Generalized least squares fit by REML
  Model: I(despues - antes) ~ 1 + I(antes - mean(antes)) 
  Data: NULL 
       AIC      BIC    logLik
  213.1707 218.4995 -102.5853

Correlation Structure: General
 Formula: ~1 | subject 
 Parameter estimate(s):
Error in "[<-"(*tmp*, lower.tri(val), value = aux) : 
        incompatible types
> presion.gls
Generalized least squares fit by REML
  Model: I(despues - antes) ~ 1 + I(antes - mean(antes)) 
  Data: NULL 
  Log-restricted-likelihood: -102.5853

Coefficients:
           (Intercept) I(antes - mean(antes)) 
           -14.1000000             -0.1485486 

Correlation Structure: General
 Formula: ~1 | subject 
 Parameter estimate(s):
Error in "[<-"(*tmp*, lower.tri(val), value = aux) : 
        incompatible types


What is the error?

Kjetil Halvorsen
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Tue Dec 18 18:45:28 2001
From: bates at stat.wisc.edu (Douglas Bates)
Date: 18 Dec 2001 11:45:28 -0600
Subject: [R] nlme: problems with gls
In-Reply-To: <3C1F7D89.221CA0CC@umsanet.edu.bo>
References: <3C1F7D89.221CA0CC@umsanet.edu.bo>
Message-ID: <6rheqoa0cn.fsf@franz.stat.wisc.edu>

kjetil halvorsen <kjetilh at umsanet.edu.bo> writes:

> Hola!
> 
> > library(nlme)
> Loading required package: nls 
> > presion.gls <- gls( I(despues-antes) ~ 1 + I(antes-mean(antes)), 
> +                     correlation=corSymm(value=0.5, form= ~ 1 |
> subject) )
> > summary(presion.gls)
> Generalized least squares fit by REML
>   Model: I(despues - antes) ~ 1 + I(antes - mean(antes)) 
>   Data: NULL 
>        AIC      BIC    logLik
>   213.1707 218.4995 -102.5853
> 
> Correlation Structure: General
>  Formula: ~1 | subject 
>  Parameter estimate(s):
> Error in "[<-"(*tmp*, lower.tri(val), value = aux) : 
>         incompatible types
> > presion.gls
> Generalized least squares fit by REML
>   Model: I(despues - antes) ~ 1 + I(antes - mean(antes)) 
>   Data: NULL 
>   Log-restricted-likelihood: -102.5853
> 
> Coefficients:
>            (Intercept) I(antes - mean(antes)) 
>            -14.1000000             -0.1485486 
> 
> Correlation Structure: General
>  Formula: ~1 | subject 
>  Parameter estimate(s):
> Error in "[<-"(*tmp*, lower.tri(val), value = aux) : 
>         incompatible types
> 
> 
> What is the error?

I imagine it is in the print.summary.gls method.

Can you send me a copy of the data set that generated this problem so
I can check the problem?
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Tue Dec 18 19:58:21 2001
From: brahm at alum.mit.edu (David Brahm)
Date: Tue, 18 Dec 2001 13:58:21 -0500
Subject: [R] colSums in C
In-Reply-To: <x2pu5d1i76.fsf@blueberry.kubism.ku.dk>
References: <15390.34428.317569.814689@gargle.gargle.HOWL>
	<x2pu5d1i76.fsf@blueberry.kubism.ku.dk>
Message-ID: <15391.37325.304358.482236@gargle.gargle.HOWL>

I wrote:
> I asked how to write speedy C code to implement colSums()...
> I've taken Doug [Bates]'s code, added names to the result, and included an
> na.rm flag.  Unfortunately, my na.rm option makes it really slow again
> ... no faster than pre-processing the matrix with "m[is.na(m)] <- 0".

Well, I'm an idiot.  I had forgotten to remove the R code that does that
pre-processing, so no wonder it wasn't any faster!  After fixing that, I got
results closer to those reported by Thomas Lumley, about 2.18s with ISNA, and
even faster (1.41s) with isnan (Peter Dalgaard's suggestion).  Is there any
reason to distrust isnan()?

Current colSums code is included below, and there's a rowSums too.  I'm still
prettying it up, but I'd like to open discussion on what to do with it when
it's ready for prime time:
  1) I can just use it locally and be perfectly happy,
  2) I can upload to CRAN (with Doug's permission, of course),
  3) I believe Doug Bates and Kurt Hornik once discussed modifying apply() to
     catch these special cases and use the optimized code.  Dangerous?

Thanks, everyone!

---- begin "colSums.R" ----
colSums <- function(x, na.rm=F) .Call("colSums", x, na.rm)
---- end "colSums.R" ----

---- begin "colSums.c" (90% due to Doug Bates) ----
#include <R.h>
#include <Rdefines.h>

SEXP colSums(SEXP m, SEXP narm) {
  register int i, j, NaRm;
  int *mdims, n, p;
  double *mm, sum;
  SEXP val, nms;

  if (!isMatrix(m)) error("m must be a matrix");
  mdims = INTEGER(GET_DIM(m));
  n = mdims[0]; p = mdims[1];
  PROTECT(val  = NEW_NUMERIC(p));
  PROTECT(nms  = GET_COLNAMES(GET_DIMNAMES(m)));
  PROTECT(  m  = AS_NUMERIC(m));
  NaRm = asLogical(narm);
  mm = REAL(m);
  for (j = 0; j < p; j++) {
    for (sum = 0., i = 0; i < n; i++) if (!NaRm || !isnan(mm[i])) sum += mm[i];
    REAL(val)[j] = sum;
    mm += n;
  }
  if (!isNull(nms)) namesgets(val, nms);
  UNPROTECT(3);
  return val;
}
---- end "colSums.c" ----

-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec 18 20:19:32 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Dec 2001 19:19:32 +0000 (GMT)
Subject: [R] colSums in C
In-Reply-To: <15391.37325.304358.482236@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.31.0112181908300.3211-100000@gannet.stats>

On Tue, 18 Dec 2001, David Brahm wrote:

> I wrote:
> > I asked how to write speedy C code to implement colSums()...
> > I've taken Doug [Bates]'s code, added names to the result, and included an
> > na.rm flag.  Unfortunately, my na.rm option makes it really slow again
> > ... no faster than pre-processing the matrix with "m[is.na(m)] <- 0".
>
> Well, I'm an idiot.  I had forgotten to remove the R code that does that
> pre-processing, so no wonder it wasn't any faster!  After fixing that, I got
> results closer to those reported by Thomas Lumley, about 2.18s with ISNA, and
> even faster (1.41s) with isnan (Peter Dalgaard's suggestion).  Is there any
> reason to distrust isnan()?

Portability.  Not all possible ports of R have it, and R can be built
without it.  But there are macros to cover that.

> Current colSums code is included below, and there's a rowSums too.  I'm still
> prettying it up, but I'd like to open discussion on what to do with it when
> it's ready for prime time:
>   1) I can just use it locally and be perfectly happy,
>   2) I can upload to CRAN (with Doug's permission, of course),
>   3) I believe Doug Bates and Kurt Hornik once discussed modifying apply() to
>      catch these special cases and use the optimized code.  Dangerous?

Yes. You coerce the summands to be numeric: you want at least to handle
the complex case, and it is probably worth handling separately the
integer/logical case too.

colSums is an S-PLUS function (somewhat more general than this one), and
one of a family {cols,rows}{Means,Sums,Vars,Stdev}.  My guess is that
it is worth including at least the Means and Vars version is a future R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Dec 18 23:53:50 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 18 Dec 2001 23:53:50 +0100
Subject: [R] colSums in C
In-Reply-To: <15391.37325.304358.482236@gargle.gargle.HOWL>
References: <15390.34428.317569.814689@gargle.gargle.HOWL>
	<x2pu5d1i76.fsf@blueberry.kubism.ku.dk>
	<15391.37325.304358.482236@gargle.gargle.HOWL>
Message-ID: <x2adwg87i9.fsf@blueberry.kubism.ku.dk>

David Brahm  <brahm at alum.mit.edu> writes:

> I wrote:
> > I asked how to write speedy C code to implement colSums()...
> > I've taken Doug [Bates]'s code, added names to the result, and included an
> > na.rm flag.  Unfortunately, my na.rm option makes it really slow again
> > ... no faster than pre-processing the matrix with "m[is.na(m)] <- 0".
> 
> Well, I'm an idiot.  I had forgotten to remove the R code that does that
> pre-processing, so no wonder it wasn't any faster!  After fixing that, I got
> results closer to those reported by Thomas Lumley, about 2.18s with ISNA, and
> even faster (1.41s) with isnan (Peter Dalgaard's suggestion).  Is there any
> reason to distrust isnan()?

It's not logically doing the same thing. NA is an NaN, but you can
also get NaN from 0/0 like construction, and you way want the sum to
be NaN in that case. By definition, an NA is a NaN with a special code
(1954, as I recall it) in an otherwise unspecified area. 

There is also a portability issue in the availability of isnan(). R
jumps through a few hoops to ensure that R_IsNA does sensible things
on as many systems as possible, although we may be running out of IEEE
non-compatible systems these days.

It is probably possible to do per-architecture optimizing and inlining
of R_IsNA, and that might be worth looking into.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Wed Dec 19 01:06:17 2001
From: brahm at alum.mit.edu (David Brahm)
Date: Tue, 18 Dec 2001 19:06:17 -0500
Subject: [R] colSums in C
In-Reply-To: <x2adwg87i9.fsf@blueberry.kubism.ku.dk>
References: <15390.34428.317569.814689@gargle.gargle.HOWL>
	<x2pu5d1i76.fsf@blueberry.kubism.ku.dk>
	<15391.37325.304358.482236@gargle.gargle.HOWL>
	<x2adwg87i9.fsf@blueberry.kubism.ku.dk>
Message-ID: <15391.55801.340546.224022@gargle.gargle.HOWL>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:
> [isnan() is] not logically doing the same thing [as ISNA].
> NA is an NaN, but you can also get NaN from 0/0 like construction, and you
> may want the sum to be NaN in that case.

Luckily, isnan() seems to give nearly S-Plus-compatible results.  Here's an
S-Plus session:

S> x <- matrix(1:15, 3,5, dimnames=list(letters[1:3], LETTERS[1:5]))
S> x[1,1] <- x[1,3] <- x[ ,4] <- NA
S> x[2,2] <- x[2,3] <- 0/0
S> print(y <- colSums(x))
    A  B  C  D  E 
   NA NA NA NA 42
S> is.na(y)
   A B C D E 
   T T T T F
S> is.nan(y)
  [1] F T F F F
S> colSums(x, na.rm=T)
   A  B C D  E 
   5 10 9 0 42

and in R I get the same results (different printing) except for this line:
R> is.nan(y)
      A     B     C     D     E 
  FALSE  TRUE  TRUE FALSE FALSE   # (Note column C is different!)

Three points about colSums to glean from this:
1) In S-Plus, na.rm=T removes (sets to 0) NaN's as well as NA's.
2) A column full of NA's sums to 0 when na.rm=T.
3) In S-Plus, NaN + NA = NA,  but in R (as I've written it) NaN + NA = NaN.

I'm OK with that, so I think I'll keep isnan() (or its portable equivalent).


> There is also a portability issue in the availability of isnan(). R
> jumps through a few hoops to ensure that R_IsNA does sensible things
> on as many systems as possible, although we may be running out of IEEE
> non-compatible systems these days.

Brian Ripley <ripley at stats.ox.ac.uk> also mentioned portability:
> Portability.  Not all possible ports of R have [isnan()], and R can be built
> without it.  But there are macros to cover that.

Is there a macro that is equivalent to (as fast as) isnan() when it exists?
ISNAN is definitely slower.

-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Dec 19 01:35:44 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 18 Dec 2001 16:35:44 -0800 (PST)
Subject: [R] colSums in C
In-Reply-To: <15391.55801.340546.224022@gargle.gargle.HOWL>
Message-ID: <Pine.A41.4.33.0112181633040.117158-100000@homer41.u.washington.edu>

On Tue, 18 Dec 2001, David Brahm wrote:
>
> Is there a macro that is equivalent to (as fast as) isnan() when it exists?
> ISNAN is definitely slower.
>

You should be able to test for NA or NaN pretty efficiently with
    x!=x
This doesn't work on systems without IEEE754 arithmetic, but more
importantly some compilers don't realise that it's a real test and
optimise it away.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brianscholl1973 at yahoo.com  Wed Dec 19 02:17:41 2001
From: brianscholl1973 at yahoo.com (Brian Scholl)
Date: Tue, 18 Dec 2001 17:17:41 -0800 (PST)
Subject: [R] % out of Conf interval
In-Reply-To: <20011130180127.1CEA1189C10@virtual.bignet.com.br>
Message-ID: <20011219011741.95303.qmail@web12207.mail.yahoo.com>

I'd like to evaluate the fit of say an AR/VAR/ARMA
model by examining the spectrum of the residuals. One
observation I'd like to make is that with a certain
model, 8% of the periodogram or smoothed periodogram
values are outside the CI bound for white noise.  How
can I do this easily in R?  

thanks, 
Brian

__________________________________________________




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brianscholl1973 at yahoo.com  Wed Dec 19 02:17:43 2001
From: brianscholl1973 at yahoo.com (Brian Scholl)
Date: Tue, 18 Dec 2001 17:17:43 -0800 (PST)
Subject: [R] % out of Conf interval
In-Reply-To: <20011130180127.1CEA1189C10@virtual.bignet.com.br>
Message-ID: <20011219011743.4966.qmail@web12201.mail.yahoo.com>

I'd like to evaluate the fit of say an AR/VAR/ARMA
model by examining the spectrum of the residuals. One
observation I'd like to make is that with a certain
model, 8% of the periodogram or smoothed periodogram
values are outside the CI bound for white noise.  How
can I do this easily in R?  

thanks, 
Brian

__________________________________________________




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From foppa at giub.unibe.ch  Wed Dec 19 09:26:09 2001
From: foppa at giub.unibe.ch (Nando Foppa)
Date: Wed, 19 Dec 2001 09:26:09 +0100
Subject: [R] combine
Message-ID: <3C204F21.F1913ACE@giub.unibe.ch>

hello there,

I ` m a newbie in R so please excuse my maybe simple question!

I have several (the number of the files changes) textfiles. Each
textfile contains one column with 3 rows (3 numerical values). I want to
combine each file with another file and create new textfiles which then
contain  2 columns with 3 rows. How can I do this in R? Do I have to
use  cbind? How Do I use cbind for my problem?
Instead of having several textfiles with one column and 3 rows I could
use one textfile with n columns with 3 rows. I don`t know which way is
better.

Thanks a lot for your help!
cheers,
Nando


_________________________________________________

   Nando Foppa  -  Remote Sensing Research Group

   Department of Geography

   University of Bern   Tel :  +41 (0)31 631 8020
   Hallerstr. 12            Fax :  +49 (0)89 2443 43780
   CH - 3012 Bern       Mail: foppa at giub.unibe.ch
   Switzerland
_________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Wed Dec 19 09:59:50 2001
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Wed, 19 Dec 2001 09:59:50 +0100
Subject: [R] combine
In-Reply-To: <3C204F21.F1913ACE@giub.unibe.ch>
Message-ID: <B8461596.5AA6%pflugshaupt@geobot.umnw.ethz.ch>

On 19.12.2001 9:26 Uhr, Nando Foppa wrote:

> I have several (the number of the files changes) textfiles. Each
> textfile contains one column with 3 rows (3 numerical values). I want to
> combine each file with another file and create new textfiles which then
> contain  2 columns with 3 rows. How can I do this in R? Do I have to
> use  cbind? How Do I use cbind for my problem?

Yes, use cbind() or data.frame(). You can e.g. do this (should work for most
well-behaved text files):

col1 <- scan("filename1")
col2 <- scan("filename2")
mydata <- data.frame(col1, col2)  # or the same with cbind(...)
write.table(mydata, file="filename3")

For more information on reading files into/from R, read the "R Data
Import/Export" manual which gets installed by default. See also
help(write.table), help(read.table), help(scan) for details on the functions
(such as specifying header rows, separators, N/A coding...).

> Instead of having several textfiles with one column and 3 rows I could
> use one textfile with n columns with 3 rows. I don`t know which way is
> better.

Depends on what you want to do with the data. For reading into R, both ways
work (for multi-column files, you'll want to use read.table() instead of
scan()).

Cheers

Kaspar



-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vito.muggeo at giustizia.it  Wed Dec 19 10:34:55 2001
From: vito.muggeo at giustizia.it (MUGGEO VITO)
Date: Wed, 19 Dec 2001 10:34:55 +0100
Subject: [R] Pearson residuals in quasi family
Message-ID: <00bd01c18870$6ebbca40$5c13070a@it.giustizia.it>

Hi all,
This is a very silly question or something escapes me:
Let obj a simple gam poisson model. Let

>obj<-gam(....,family=poisson)
>obj1<-update(obj, family=quasi(link="log", var="mu"))

>From summary.glm(obj1) the dispersion parameter is estimated 1.165; In fact
it is:

> (predict(obj1, se.fit=T)$se.fit[1:5]/predict(obj, se.fit=T)$se.fit[1:5])^2
        4        5        6        7        8
 1.165767 1.165767 1.165767 1.165767 1.165767

The standard errors of the fitted values are greater in the quasi-Lik
approach, of course.
Because of this, it's expected that the pearson residuals are smaller in the
quasi-Lik, approach; but

> residuals(obj, type="pearson")[1:5]-residuals(obj1, type="pearson")[1:5]
 4 5 6 7 8
 0 0 0 0 0

That is
resid(obj1, type="pearson")!=resid(obj1, "response")/(predict(obj1,
se.fit=T)$se.fit

Am I wrong or is there any problem?

Thanks for your attention,
best,
vito

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Wed Dec 19 12:08:44 2001
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Wed, 19 Dec 2001 12:08:44 +0100
Subject: [R] How to create a data.frame "like" another, but longer?
Message-ID: <B84633CC.5AAC%pflugshaupt@geobot.umnw.ethz.ch>

Hello,

does anyone know of a quick way to create a data frame "like" another, but
with more rows?

What I'd like to do is this:

if mydata is a data.frame like

a   b       c
1   TRUE    yes
2   FALSE   no
3   TRUE    yes

I'd like to get mydata2 with the same column names and column types, but
without the values and with more rows.

All I could think of was to manually do mydata2 <- maydata, then repeat
mydata2 <- rbind(mydata2, mydata2) until mydata2 is long enough, then cut to
desired length and overwrite with new data. Not exactly elegant...

Is there a R function or some handy trick to achieve this?


Cheers

Kaspar

-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Wed Dec 19 15:22:09 2001
From: siim at obs.ee (Ott Toomet)
Date: Wed, 19 Dec 2001 15:22:09 +0100 (CET)
Subject: [R] How to create a data.frame "like" another, but longer?
In-Reply-To: <B84633CC.5AAC%pflugshaupt@geobot.umnw.ethz.ch>
Message-ID: <Pine.LNX.4.33.0112191513510.10581-100000@ecopc64.eco.au.dk>

Hi,

How you have thought to input your data into the new dataframe?  The
following assumes you have new data in the form of vectors.

A (slightly) more elegant way to do it is through lists.  Remember that
data.frame is actually a list with components with similar length.

So you could do something as:

> mylist <- mydata
> mylist$a <- c(1,2,3,4,5)
> mylist$b <- c(TRUE,TRUE,TRUE,TRUE,FALSE)
...
> mydata2 <- as.data.frame(mylist)

Here you have to ensure that the data vectors have equal length, the new
dataframe will automatically have that many rows.  Basically here you are
manually making the new dataframe, the only thing which is kept is the order
of the variables.  The new types are created automatically unless you coerce
the new vectors into the old form (using something like as.factor( ...,
levels=...)).


Perhaps it helps.

Ott Toomet


On Wed, 19 Dec 2001, Kaspar Pflugshaupt wrote:

> Hello,
>
> does anyone know of a quick way to create a data frame "like" another, but
> with more rows?
>
> What I'd like to do is this:
>
> if mydata is a data.frame like
>
> a   b       c
> 1   TRUE    yes
> 2   FALSE   no
> 3   TRUE    yes
>
> I'd like to get mydata2 with the same column names and column types, but
> without the values and with more rows.
>
> All I could think of was to manually do mydata2 <- maydata, then repeat
> mydata2 <- rbind(mydata2, mydata2) until mydata2 is long enough, then cut to
> desired length and overwrite with new data. Not exactly elegant...
>
> Is there a R function or some handy trick to achieve this?
>
>
> Cheers
>
> Kaspar
>
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Wed Dec 19 15:33:25 2001
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Wed, 19 Dec 2001 15:33:25 +0100
Subject: [R] How to create a data.frame "like" another, but longer?
In-Reply-To: <6rwuzjcnnr.fsf@franz.stat.wisc.edu>
Message-ID: <B84663C5.5ABD%pflugshaupt@geobot.umnw.ethz.ch>

On 19.12.2001 15:03 Uhr, Douglas Bates wrote:

> Use indexing.  A surprising result in the S language is that a
> `subset' can be longer than the original set.
> 
> In your case
> 
> ind <- c(1:nrow(mydata), rep(1, n - nrow(mydata)))
> mydata2 <- mydata[ind, ]
> # overwrite the data here
> 
> The reason for making the indices of the form 1, 2, 3, 1, 1, 1, ..., 1
> is to ensure that all levels of factors get represented in the
> extracted data.  That may be unnecessary.  You could experiment with
> 
> mydata2 <- mydata[rep(1, n), ]
> 
> and see if that works properly.

Thanks! I guessed there would be something simple like this... There seems
to be no end to the surprisingly elegant indexing solutions in R!

I tried it out and ended up with

f.expand.df <- function(df, newrows)
  {
    oldrows <- nrow(df)
    new.index <- rep(1:oldrows, newrows/oldrows+1)[1:newrows]
    df[new.index,]
  }

which just recycles the dataframe's rows enough times and cuts off the
excess.

Thanks again for the tip


Kaspar


-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Dec 19 17:19:45 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 19 Dec 2001 08:19:45 -0800 (PST)
Subject: [R] Pearson residuals in quasi family
In-Reply-To: <00bd01c18870$6ebbca40$5c13070a@it.giustizia.it>
Message-ID: <Pine.A41.4.33.0112190815490.100846-100000@homer10.u.washington.edu>

On Wed, 19 Dec 2001, MUGGEO VITO wrote:

> Hi all,
> This is a very silly question or something escapes me:
> Let obj a simple gam poisson model. Let
>
> >obj<-gam(....,family=poisson)
> >obj1<-update(obj, family=quasi(link="log", var="mu"))
>
<snip>
> That is
> resid(obj1, type="pearson")!=resid(obj1, "response")/(predict(obj1,
> se.fit=T)$se.fit
>
> Am I wrong or is there any problem?

I don't know about gam() (is this the one in mgcv?) but certainly for
glm() the pearson residuals are the same for quasilikelihood fits.

The Pearson residuals are typically defined as (Y-mu)/sqrt(V(mu))
and the variance function V(mu) doesn't include a scale factor for
quasilikelihood fits since the scale factor doesn't affect the fitting.

If Pearson residuals were rescaled by the estimated dispersion parameter
then for a Gaussian linear model they wouldn't agree with the other
flavours of residual.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Wed Dec 19 21:18:09 2001
From: siim at obs.ee (Ott Toomet)
Date: Wed, 19 Dec 2001 21:18:09 +0100 (CET)
Subject: [R] R strings from C
Message-ID: <Pine.LNX.4.33.0112192116490.11040-100000@ecopc64.eco.au.dk>

Hi,

I am trying to study R internal behaviour.  So long, I have not
succeeded to access the value of R strings from C.

I use:

void salvesta_tabel(
		    SEXP data_frame,
		    SEXP file
		    )
{
  printf( "nimi %d\n", (R_CHAR)( file));
}

and from the R side:

salvesta.tabel <-
  function (x, file = "") {
    .Call( "salvesta_tabel", x, file)
  }

When calling from R as

salvesta.tabel( x, "file")

R always crashes while printing the %d part.  So I assume that the
function R_CHAR is not the right one to access the value of the
variable file, I have experimented several other ways but so long
unsuccessfully, both Venables & Ripley ,S-programming' and ,Writing R
extensions' seem not to touch that issue.

Any suggestions?

And thanks in advance,

Ott Toomet

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From duncan at jessie.research.bell-labs.com  Wed Dec 19 21:54:54 2001
From: duncan at jessie.research.bell-labs.com (Duncan Temple Lang)
Date: Wed, 19 Dec 2001 15:54:54 -0500
Subject: [R] R strings from C
In-Reply-To: <Pine.LNX.4.33.0112192116490.11040-100000@ecopc64.eco.au.dk>; from siim@obs.ee on Wed, Dec 19, 2001 at 09:18:09PM +0100
References: <Pine.LNX.4.33.0112192116490.11040-100000@ecopc64.eco.au.dk>
Message-ID: <20011219155454.G18806@jessie.research.bell-labs.com>

Hi,

R does not have scalar/individual values but vectors.
So, in a call to an R function,
  foo("x", "abc")
both arguments are "character vectors" rather than strings.
So they may actually be a collection of strings.

In C code, the elements of the  character vectors are accessed 
via 
 STRING_ELT(vector, elementIndex)
and
 SET_STRING_ELT(vector, elementIndex)
for getting and setting the value.

There is one more layer. Each element is itself yet another SEXP, this
time of type CHARSXP. And you can fetch the low-level C char * from this
using the macro CHAR() (or R_CHAR()).
So to get the C string for the first element in the character vector
you would use

  CHAR(STRING_ELT(file, 0))

Of course, when printing it in C, you need to use %s, not %d
as you have in your code.

R_CHAR is in fact a routine/macro, and not a type.

BTW, character vectors are stored very differently in S4/S-Plus.  (I
write code that runs in both systems so I have a collection of macros,
some of which are in Rdefines.h, that hide the differences.)

 D.

Ott Toomet wrote:
> Hi,
> 
> I am trying to study R internal behaviour.  So long, I have not
> succeeded to access the value of R strings from C.
> 
> I use:
> 
> void salvesta_tabel(
> 		    SEXP data_frame,
> 		    SEXP file
> 		    )
> {
>   printf( "nimi %d\n", (R_CHAR)( file));
> }
> 
> and from the R side:
> 
> salvesta.tabel <-
>   function (x, file = "") {
>     .Call( "salvesta_tabel", x, file)
>   }
> 
> When calling from R as
> 
> salvesta.tabel( x, "file")
> 
> R always crashes while printing the %d part.  So I assume that the
> function R_CHAR is not the right one to access the value of the
> variable file, I have experimented several other ways but so long
> unsuccessfully, both Venables & Ripley ,S-programming' and ,Writing R
> extensions' seem not to touch that issue.
> 
> Any suggestions?
> 
> And thanks in advance,
> 
> Ott Toomet
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec 19 22:15:01 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Dec 2001 21:15:01 +0000 (GMT)
Subject: [R] R strings from C
In-Reply-To: <Pine.LNX.4.33.0112192116490.11040-100000@ecopc64.eco.au.dk>
Message-ID: <Pine.LNX.4.31.0112192102010.1814-100000@gannet.stats>

On Wed, 19 Dec 2001, Ott Toomet wrote:

> Hi,
>
> I am trying to study R internal behaviour.  So long, I have not
> succeeded to access the value of R strings from C.

What you are passing is a character vector, not a string. So you need
(untested)

#include <R.h>
#include <Rinternals.h>

SEXP salvesta_tabel(SEXP data_frame, SEXP file)
{
   printf( "nimi %s\n", CHAR(STRING_ELT(file, 0)));
}

to print the first element of a character vector.

Note, you have to return a SEXP, and I use %s to print a string, not %d.
I would add some testing (isString(file) && length(file) >= 1 would be a
good start).

>
> I use:
>
> void salvesta_tabel(
> 		    SEXP data_frame,
> 		    SEXP file
> 		    )
> {
>   printf( "nimi %d\n", (R_CHAR)( file));
> }
>
> and from the R side:
>
> salvesta.tabel <-
>   function (x, file = "") {
>     .Call( "salvesta_tabel", x, file)
>   }
>
> When calling from R as
>
> salvesta.tabel( x, "file")
>
> R always crashes while printing the %d part.  So I assume that the
> function R_CHAR is not the right one to access the value of the
> variable file, I have experimented several other ways but so long
> unsuccessfully, both Venables & Ripley ,S-programming' and ,Writing R
> extensions' seem not to touch that issue.

There *are* examples in `Writing R Extensions': search for STRING_ELT.

Fortunately there are not in `S-programming' since the way to do this has
changed since that was written.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brianscholl1973 at yahoo.com  Wed Dec 19 22:47:16 2001
From: brianscholl1973 at yahoo.com (Brian Scholl)
Date: Wed, 19 Dec 2001 13:47:16 -0800 (PST)
Subject: [R] ARIMA0 with xreg, 
In-Reply-To: <Pine.LNX.4.31.0112111219470.23115-100000@gannet.stats>
Message-ID: <20011219214716.27668.qmail@web12201.mail.yahoo.com>

Hi all,

Using ar(), I fit a VAR to my time series that has a
reasonably 'nice' error spectrum and aic determines
p=7.   But the output for ar isn't quite as convenient
as arima0, namely in that it takes me an extra step to
get the s.e.'s of parameters and it doesn't produce an
estimate of the log-likelihood for comparison to other
models. So I thought I'd use arimia0, with xreg=x, my
matrix of data and order=(7,0,0).  

When I do this, the results are funny.  The residuals
look - well, just like the original series on a
readjusted scale.  The spectrum for the residuals
looks slightly different from the spectrum of x and
bears no resemblance to the nice spectrum I got before
(this one looks like a long memory process, while the
earlier was closer to white noise).  Certainly I don't
expect the spectra and residuals to look exactly alike
because of the different solution methods, but these
bear little resemblance to each other.

I assume, of course that the error is on my part,
perhaps something I've overlooked, but I'm not able to
find it.  

Thanks, 

Brian 



__________________________________________________




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jg_liao at yahoo.com  Wed Dec 19 22:53:31 2001
From: jg_liao at yahoo.com (Jason Liao)
Date: Wed, 19 Dec 2001 13:53:31 -0800 (PST)
Subject: [R] how to get unique vectors
Message-ID: <20011219215331.31310.qmail@web10508.mail.yahoo.com>

First, happy holidays, everyone! Thanks to the R team for bringing out
1.4 before the new year.

I have 10000 integer triplets stored in A[1:10000, 1:3]. I would like
to find the unique triplets among the 10000 ones with possible
duplications. What is the easiest way for this. I know the function
unique(), which apply to a vector, not the 10000*3 array in my problem.

Thanks in advance.

Jason 

=====
Jason G. Liao, Ph.D.
Division of Biometrics
UMDNJ School of Public Health
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-9748, fax (732) 235-9777
http://www.geocities.com/jg_liao

__________________________________________________




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From William_Fitchen at oxy.com  Wed Dec 19 22:56:30 2001
From: William_Fitchen at oxy.com (William_Fitchen@oxy.com)
Date: Wed, 19 Dec 2001 15:56:30 -0600
Subject: [R] Interpolating variables into quoted strings
Message-ID: <5E89D6BFEAC95C40A12841EF270398EF2487F6@ohow2km3>

Hello

I am new to R and am coming from a Perl background.  I have had trouble
figuring out from the documentation how to interpolate a variable into a
quoted string (if it's possible).  This seems to be necessary when writing a
script that must print out strings (for example plot legends) whose content
is calculated during the execution of the script.  

In perl I could write:
	
	$name = "John";
	print STDOUT "Hi $name, how's it going";

which would output the following:

	Hi John, how's it going?

Is there a function that allows a variable containing a character string or
numeric to be interpolated into a quoted character string?  Any help would
be greatly appreciated!

------------------------
William M. Fitchen
Occidental Permian Ltd.
580 Westlake Park Blvd.
Westlake 2, Rm. 431A
Houston, TX  77079
281-552-1225 (voice)
william_fitchen at oxy.com
------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec 19 23:13:01 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Dec 2001 22:13:01 +0000 (GMT)
Subject: [R] ARIMA0 with xreg, 
In-Reply-To: <20011219214716.27668.qmail@web12201.mail.yahoo.com>
Message-ID: <Pine.LNX.4.31.0112192210170.1965-100000@gannet.stats>

You need to define some terms.  But from `VAR' and `matrix of data' I
guess that you have a multiple time series.  If so, it just isn't valid
to use arima0, which is univariate.  You also did not say what `x' is,
but the `x' in `xreg' means eXogenous.

On Wed, 19 Dec 2001, Brian Scholl wrote:

> Hi all,
>
> Using ar(), I fit a VAR to my time series that has a
> reasonably 'nice' error spectrum and aic determines
> p=7.   But the output for ar isn't quite as convenient
> as arima0, namely in that it takes me an extra step to
> get the s.e.'s of parameters and it doesn't produce an
> estimate of the log-likelihood for comparison to other
> models. So I thought I'd use arimia0, with xreg=x, my
> matrix of data and order=(7,0,0).
>
> When I do this, the results are funny.  The residuals
> look - well, just like the original series on a
> readjusted scale.  The spectrum for the residuals
> looks slightly different from the spectrum of x and
> bears no resemblance to the nice spectrum I got before
> (this one looks like a long memory process, while the
> earlier was closer to white noise).  Certainly I don't
> expect the spectra and residuals to look exactly alike
> because of the different solution methods, but these
> bear little resemblance to each other.
>
> I assume, of course that the error is on my part,
> perhaps something I've overlooked, but I'm not able to
> find it.
>
> Thanks,
>
> Brian
>
>
>
> __________________________________________________
>
>
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec 19 23:17:49 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Dec 2001 22:17:49 +0000 (GMT)
Subject: [R] how to get unique vectors
In-Reply-To: <20011219215331.31310.qmail@web10508.mail.yahoo.com>
Message-ID: <Pine.LNX.4.31.0112192216330.1965-100000@gannet.stats>

On Wed, 19 Dec 2001, Jason Liao wrote:

> First, happy holidays, everyone! Thanks to the R team for bringing out
> 1.4 before the new year.
>
> I have 10000 integer triplets stored in A[1:10000, 1:3]. I would like
> to find the unique triplets among the 10000 ones with possible
> duplications. What is the easiest way for this. I know the function
> unique(), which apply to a vector, not the 10000*3 array in my problem.

Well, new in 1.4.0 is unique.data.frame(), so you could either use that or
copy its idea.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec 19 23:31:46 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 19 Dec 2001 23:31:46 +0100
Subject: [R] Interpolating variables into quoted strings
In-Reply-To: <5E89D6BFEAC95C40A12841EF270398EF2487F6@ohow2km3>
References: <5E89D6BFEAC95C40A12841EF270398EF2487F6@ohow2km3>
Message-ID: <x2d71a4zal.fsf@blueberry.kubism.ku.dk>

William_Fitchen at oxy.com writes:

> I am new to R and am coming from a Perl background.  I have had trouble
> figuring out from the documentation how to interpolate a variable into a
> quoted string (if it's possible).  This seems to be necessary when writing a
> script that must print out strings (for example plot legends) whose content
> is calculated during the execution of the script.  
> 
> In perl I could write:
> 	
> 	$name = "John";
> 	print STDOUT "Hi $name, how's it going";
> 
> which would output the following:
> 
> 	Hi John, how's it going?
> 
> Is there a function that allows a variable containing a character string or
> numeric to be interpolated into a quoted character string?  Any help would
> be greatly appreciated!

Generally paste() or cat() is used for this:

name <- "John"
cat("Hi ", name, ", how's it going\n", sep="")

or 

out <- paste("Hi ", name, ", how's it going", sep="")
print(out)

You could also try stuff like

sub("NAME", name, "Hi, NAME, how's it going")

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec 19 23:36:33 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 19 Dec 2001 23:36:33 +0100
Subject: [R] how to get unique vectors
In-Reply-To: <20011219215331.31310.qmail@web10508.mail.yahoo.com>
References: <20011219215331.31310.qmail@web10508.mail.yahoo.com>
Message-ID: <x27kri4z2m.fsf@blueberry.kubism.ku.dk>

Jason Liao <jg_liao at yahoo.com> writes:

> First, happy holidays, everyone! Thanks to the R team for bringing out
> 1.4 before the new year.
> 
> I have 10000 integer triplets stored in A[1:10000, 1:3]. I would like
> to find the unique triplets among the 10000 ones with possible
> duplications. What is the easiest way for this. I know the function
> unique(), which apply to a vector, not the 10000*3 array in my problem.

As of 1.4.0 (!):

unique(as.data.frame(A))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From edd at debian.org  Thu Dec 20 00:39:54 2001
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 19 Dec 2001 17:39:54 -0600
Subject: [R] Interpolating variables into quoted strings
In-Reply-To: <5E89D6BFEAC95C40A12841EF270398EF2487F6@ohow2km3>
References: <5E89D6BFEAC95C40A12841EF270398EF2487F6@ohow2km3>
Message-ID: <20011219233954.GA4936@sonny.eddelbuettel.com>

On Wed, Dec 19, 2001 at 03:56:30PM -0600, William_Fitchen at oxy.com wrote:
> In perl I could write:
> 	
> 	$name = "John";
> 	print STDOUT "Hi $name, how's it going";
> 
> which would output the following:
> 
> 	Hi John, how's it going?
> 
> Is there a function that allows a variable containing a character string or
> numeric to be interpolated into a quoted character string?  Any help would
> be greatly appreciated!

name <- "John"
cat(paste("Hi", name, "how's it going\n"))


You might want to look at the "An Introduction to R" manual shipped with R,
it covers paste() in the "Character vectors" section.

Dirk

-- 
Good judgment comes from experience; experience comes from bad judgment. 
							    -- F. Brooks
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From apjaworski at mmm.com  Thu Dec 20 00:38:28 2001
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Wed, 19 Dec 2001 17:38:28 -0600
Subject: [R] readline with R-1.4.0
Message-ID: <OF7A89DD5D.ADFC3A36-ON86256B27.007F549F@mmm.com>

Hi,

I am not sure if this is a bug, so I am posting it here.  I also searched
the FAQ file for the readline string and did not find anything about the
behavior below.

I just successfully rsync'ed, compiled and tested R-1.4.0 on my RH 7.2
Linux machine.  I encountered one problem though.  When running ./configure
I noticed that I was getting errors from the readline library.  Although
configure detected readline, the internal test it runs failed.  Now, my RH
distribution has readline version 4.2-2 (both dynamic and static).  It also
contains the older version for compatibility purposes.  In /usr/lib I have

     libreadline.a                       (static 4.2-2)
     libreadline.so.4.2            (dynamic 4.2-2)
     libreadline.so.3.0            (dynamic 2.2.1 !?)
     libreadline.so -> libreadline.so.4.2     (symbolic link)

This setup created the failure I just mentioned.  However, when I changed
the link to

     libreadline.so -> libreadline.so.3.0

everything went fine with configure and compilation.  The odd thing is that
after compilation finished I changed the above symbolic link back to
libreadline.so.4.2 and all tests ran with no problem.  Readline also seems
to work in interactive mode.

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From apjaworski at mmm.com  Thu Dec 20 01:55:42 2001
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Wed, 19 Dec 2001 18:55:42 -0600
Subject: [R] readline with R-1.4.0
Message-ID: <OFE8DBAAAD.387944F5-ON86256B28.0004BC56@mmm.com>


The header files are a part of the readline-devel RPM (as is the static
library) and they are 4.2-2.

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


                                                                                                                                               
                    Dirk                                                                                                                       
                    Eddelbuettel         To:     Andrzej P. Jaworski/US-Corporate/3M/US at 3M-Corporate                                           
                    <edd at debian.org      cc:                                                                                                   
                    >                    Subject:     Re: [R] readline with R-1.4.0                                                            
                                                                                                                                               
                    12/19/2001                                                                                                                 
                    06:35 PM                                                                                                                   
                                                                                                                                               
                                                                                                                                               





On Wed, Dec 19, 2001 at 05:38:28PM -0600, apjaworski at mmm.com wrote:
> configure detected readline, the internal test it runs failed.  Now, my
RH
> distribution has readline version 4.2-2 (both dynamic and static).  It
also
> contains the older version for compatibility purposes.  In /usr/lib I
have

What matters for recompilation are the header files. Which header package
do
you have?

--
Good judgment comes from experience; experience comes from bad judgment.
                                       -- F. Brooks




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From s-luppescu at uchicago.edu  Thu Dec 20 03:12:26 2001
From: s-luppescu at uchicago.edu (Stuart Luppescu)
Date: 19 Dec 2001 20:12:26 -0600
Subject: [R] emacs 21.1, R-1.3.1, and ESS
In-Reply-To: <200112131829.fBDITh621583@cattell.psych.upenn.edu>
References: <200112131829.fBDITh621583@cattell.psych.upenn.edu>
Message-ID: <1008814347.1703.4.camel@musume.snl.home>

On ?, 2001-12-13 at 12:29, Jonathan Baron wrote:
> Emacs 21.1 has other problems.  It may be good to wait for the
> next version.  I tried setting it up, and gave up and went back
> to version 20.7.
[snip]
> In sum, I would not be the least upset if the ESS team said, "If
> you want to use ESS, stick with Emacs 20.7 for a while."

Well, what I really like about the new emacs is that you get syntax
highlighting when running in the console. Big thumb up for that one.
-- 
Stuart Luppescu       -=- s-luppescu at uchicago.edu
University of Chicago -=- CCSR 
????????    -=- Kernel 2.4.14-xfs              
Half a mind is a terrible thing to waste! 
 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 240 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20011219/4a3fb7ad/attachment.bin

From rpeng at stat.ucla.edu  Thu Dec 20 03:28:30 2001
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 19 Dec 2001 18:28:30 -0800 (PST)
Subject: [R] readline with R-1.4.0
In-Reply-To: <OF7A89DD5D.ADFC3A36-ON86256B27.007F549F@mmm.com>
Message-ID: <Pine.GSO.4.10.10112191826290.16111-100000@quetelet.stat.ucla.edu>

This was from a previous post to this list:

-- CLIP ---

This was discussed a few days ago on this very list. The correct
answer for redhat 7.2 is to install

readline41-4.1-10.i386.rpm

By definition, symbolic libraries with different "sonames" (like
/usr/lib/libreadline.so.4.1 and ...4.2) may be incompatible, so
programs compiled for one of them shouldn't try to use the other. (Some
packages insist on letting the soname follow the release name whether
or not versions are binary compatible so there's no guarantee it would
break either.)

Empirically it seems to work for R if you make the .4.1 lib a symlink
to the .4.2 lib, but there is no telling what that might do to other
programs.

Trying "rpm -i --force ...." will most likely crash R on startup.

-- CLIP --

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 19 Dec 2001, apjaworski at mmm.com wrote:

> Hi,
> 
> I am not sure if this is a bug, so I am posting it here.  I also searched
> the FAQ file for the readline string and did not find anything about the
> behavior below.
> 
> I just successfully rsync'ed, compiled and tested R-1.4.0 on my RH 7.2
> Linux machine.  I encountered one problem though.  When running ./configure
> I noticed that I was getting errors from the readline library.  Although
> configure detected readline, the internal test it runs failed.  Now, my RH
> distribution has readline version 4.2-2 (both dynamic and static).  It also
> contains the older version for compatibility purposes.  In /usr/lib I have
> 
>      libreadline.a                       (static 4.2-2)
>      libreadline.so.4.2            (dynamic 4.2-2)
>      libreadline.so.3.0            (dynamic 2.2.1 !?)
>      libreadline.so -> libreadline.so.4.2     (symbolic link)
> 
> This setup created the failure I just mentioned.  However, when I changed
> the link to
> 
>      libreadline.so -> libreadline.so.3.0
> 
> everything went fine with configure and compilation.  The odd thing is that
> after compilation finished I changed the above symbolic link back to
> libreadline.so.4.2 and all tests ran with no problem.  Readline also seems
> to work in interactive mode.
> 
> Andy
> 
> __________________________________
> Andy Jaworski
> Engineering Systems Technology Center
> 3M Center, 518-1-01
> St. Paul, MN 55144-1000
> -----
> E-mail: apjaworski at mmm.com
> Tel:  (651) 733-6092
> Fax:  (651) 736-3122
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Thu Dec 20 04:44:53 2001
From: rossini at blindglobe.net (A.J. Rossini)
Date: 19 Dec 2001 19:44:53 -0800
Subject: [R] emacs 21.1, R-1.3.1, and ESS
In-Reply-To: <1008814347.1703.4.camel@musume.snl.home>
References: <200112131829.fBDITh621583@cattell.psych.upenn.edu>
	<1008814347.1703.4.camel@musume.snl.home>
Message-ID: <871yhqsgga.fsf@jeeves.blindglobe.net>

>>>>> "SL" == Stuart Luppescu <s-luppescu at uchicago.edu> writes:

    SL> On ?, 2001-12-13 at 12:29, Jonathan Baron wrote:
    >> Emacs 21.1 has other problems.  It may be good to wait for the
    >> next version.  I tried setting it up, and gave up and went back
    >> to version 20.7.
    SL> [snip]
    >> In sum, I would not be the least upset if the ESS team said,
    >> "If you want to use ESS, stick with Emacs 20.7 for a while."

    SL> Well, what I really like about the new emacs is that you get
    SL> syntax highlighting when running in the console. Big thumb up
    SL> for that one.

XEmacs has done that for a while, sigh...


 



-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   T-Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
Rosen: (Mullins' Lab) Fridays, and I'm unreachable except by email.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From poizot at intechmer.cnam.fr  Thu Dec 20 10:04:05 2001
From: poizot at intechmer.cnam.fr (Emmanuel POIZOT)
Date: Thu, 20 Dec 2001 10:04:05 +0100
Subject: [R] Modifying a function
Message-ID: <3C21A985.60107@intechmer.cnam.fr>

Hello,
I'd writen a function in R composed of multiples lines.
How can I do to modify or delete on of the line of my function ?

-- 

Sincerely
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~ Emmanuel POIZOT
~ CNAM/INTECHMER
~ B.P. 324
~ 50103 CHERBOURG CEDEX
~ T?l : (33) 233 887 342
~ Fax : (33) 233 887 339
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec 20 10:35:36 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 20 Dec 2001 10:35:36 +0100
Subject: [R] readline with R-1.4.0
In-Reply-To: <Pine.GSO.4.10.10112191826290.16111-100000@quetelet.stat.ucla.edu>
References: <Pine.GSO.4.10.10112191826290.16111-100000@quetelet.stat.ucla.edu>
Message-ID: <x2ofkumdxz.fsf@blueberry.kubism.ku.dk>

Roger Peng <rpeng at stat.ucla.edu> writes:

> This was from a previous post to this list:
> 
> -- CLIP ---
> 
> This was discussed a few days ago on this very list. The correct
> answer for redhat 7.2 is to install
> 
> readline41-4.1-10.i386.rpm

(Please keep the attribution on such things. Took the author (me) a
while to recognize it...)

That refers to binary installs because the 1.3.1 RPM was linked
against 4.1, apjaworski's case is a source build. I can't offhand see
what is going wrong there. I have built successfully on 7.2 a couple
of times, readline and all, and repeated it just now. One possibility
is that there is a mismatch between the -devel package and
libreadline. What I have is

$ rpm -qa | grep readline
readline2.2.1-2.2.1-4
readline-devel-4.2-2
readline-4.2-2

If apjaworski has readline-devel-2.2* then that might explain things.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec 20 10:38:35 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 20 Dec 2001 10:38:35 +0100
Subject: [R] Modifying a function
In-Reply-To: <3C21A985.60107@intechmer.cnam.fr>
References: <3C21A985.60107@intechmer.cnam.fr>
Message-ID: <x2k7vimdt0.fsf@blueberry.kubism.ku.dk>

Emmanuel POIZOT <poizot at intechmer.cnam.fr> writes:

> Hello,
> I'd writen a function in R composed of multiples lines.
> How can I do to modify or delete on of the line of my function ?

fix(f) or g <- edit(f) should bring up an editor.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Thu Dec 20 11:22:22 2001
From: alobo at ija.csic.es (Agustin Lobo)
Date: Thu, 20 Dec 2001 11:22:22 +0100 (MET)
Subject: [R] conflicting results on NA in a qda predicted object:
Message-ID: <Pine.OSF.3.96.1011220111222.13471A-100000@ija.csic.es>


Dear list,

(I've not upgraded to R1.4 yet)

I have the following $class component in a predict.qda object:
> unique(mod23S.qda.pred$class)
 [1] 12 17 8  10 4  9  5  13 14 19 20 15 6  3  7  1  23 11 18 21 16 2  22 NA
Levels:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

Nevertheless, when I try to identify the individual(s) with NA, I get:
> any(is.na(mod23S.qda.pred$class))
[1] FALSE

and

> mod23S.qda.pred$class[is.na(mod23S.qda.pred$class)]
factor(0)
Levels:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 

So, actually, is there a NA value in mod23S.qda.pred$class or not?

(screening by eye it`s impossible:
length(mod23S.qda.pred$class) is 26375 )

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 20 11:29:07 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Dec 2001 10:29:07 +0000 (GMT)
Subject: [R] conflicting results on NA in a qda predicted object:
In-Reply-To: <Pine.OSF.3.96.1011220111222.13471A-100000@ija.csic.es>
Message-ID: <Pine.GSO.4.31.0112201022490.7216-100000@toucan.stats>

This is a factor.  You have to be careful with NAs in factors (and 1.4.0
is different there as it happens).

Nevertheless, there is no way to reproduce this from what you have given.
Check that the class really is "factor", and then unclass it to see what
the codes actually are.  One or more of them should be NA from what you
have given.


On Thu, 20 Dec 2001, Agustin Lobo wrote:

>
> Dear list,
>
> (I've not upgraded to R1.4 yet)
>
> I have the following $class component in a predict.qda object:
> > unique(mod23S.qda.pred$class)
>  [1] 12 17 8  10 4  9  5  13 14 19 20 15 6  3  7  1  23 11 18 21 16 2  22 NA
> Levels:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
>
> Nevertheless, when I try to identify the individual(s) with NA, I get:
> > any(is.na(mod23S.qda.pred$class))
> [1] FALSE
>
> and
>
> > mod23S.qda.pred$class[is.na(mod23S.qda.pred$class)]
> factor(0)
> Levels:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
>
> So, actually, is there a NA value in mod23S.qda.pred$class or not?
>
> (screening by eye it`s impossible:
> length(mod23S.qda.pred$class) is 26375 )
>
> Agus
>
> Dr. Agustin Lobo
> Instituto de Ciencias de la Tierra (CSIC)
> Lluis Sole Sabaris s/n
> 08028 Barcelona SPAIN
> tel 34 93409 5410
> fax 34 93411 0012
> alobo at ija.csic.es
>
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From parrinel at med.unibs.it  Thu Dec 20 11:50:53 2001
From: parrinel at med.unibs.it (Giovanni Parrinello)
Date: Thu, 20 Dec 2001 11:50:53 +0100
Subject: [R] Survival analysis using a scale change random effects
Message-ID: <5.0.2.1.1.20011220114634.01db1640@pop3.norton.antivirus>

Dear All,
I am looking for implementations of the model described in the article
  Anderson-Louis: " Survival Analysis using a scale random effects model"- 
JASA 1995 pg.669-679.
TIA
Giovanni Parrinello

dr. Giovanni Parrinello
Medical Statistics Unit
Department of Medical Sciences
University of Brescia
Via Valsabbina, 19
25127 Brescia
Italy
tel.: +39303717528
fax:+39303701157
E-mail: parrinel at med.inibs.it
url: http://www.med.unibs.it/dip/stat/index.html

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Thu Dec 20 12:25:32 2001
From: alobo at ija.csic.es (Agustin Lobo)
Date: Thu, 20 Dec 2001 12:25:32 +0100 (MET)
Subject: [R] conflicting results on NA in a qda predicted object:
In-Reply-To: <Pine.GSO.4.31.0112201022490.7216-100000@toucan.stats>
Message-ID: <Pine.OSF.3.96.1011220120901.13471G-100000@ija.csic.es>

Using unclass I'm still very confused:

> unique(mod23S.qda.pred$class) 
 [1] 12 17 8  10 4  9  5  13 14 19 20 15 6  3  7  1  23 11 18 21 16 2  22  NA
Levels:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 

> unique(unclass(mod23S.qda.pred$class))
 [1]  12  17   8  10   4   9   5  13  14  19  20  15   6   3   7   1  23 11  18
[20]  21  16   2  22 262

I think that the NA is related to the 262, as there should be
only 23 classes.

The data used in predict.qda seem correct (only cols X2 to X5
are used, col X1 are the individual labels):

> summary(liss.seg.medias)
       X1              X2               X3               X4        
 Min.   :    1   Min.   : 57.80   Min.   : 17.00   Min.   : 34.94  
 1st Qu.: 6594   1st Qu.: 78.50   1st Qu.: 26.50   1st Qu.: 83.50  
 Median :13188   Median : 89.72   Median : 33.40   Median : 91.43  
 Mean   :13188   Mean   : 95.18   Mean   : 37.01   Mean   : 92.47  
 3rd Qu.:19782   3rd Qu.:106.47   3rd Qu.: 44.50   3rd Qu.:100.50  
 Max.   :26375   Max.   :245.29   Max.   :125.25   Max.   :156.82  
       X5       
 Min.   : 65.0  
 1st Qu.:108.4  
 Median :128.4  
 Mean   :134.2  
 3rd Qu.:155.7  
 Max.   :254.3 


Also, the qda object semms correct:

> str(mod23.qda)
List of 8
 $ prior  : Named num [1:23] 0.0842 0.0485 0.0357 0.0332 0.0357 ...
  ..- attr(*, "names")= chr [1:23] "1" "2" "3" "4" ...
 $ counts : Named int [1:23] 33 19 14 13 14 41 33 8 11 14 ...
  ..- attr(*, "names")= chr [1:23] "1" "2" "3" "4" ...
 $ means  : num [1:23, 1:4] 71.4 68.9 72.9 81.5 92.6 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:23] "1" "2" "3" "4" ...
  .. ..$ : chr [1:4] "lissb2" "lissb3" "lissb4" "lissb5"
 $ scaling: num [1:4, 1:4, 1:23] 0.463 0.000 0.000 0.000 1.149 ...
  ..- attr(*, "dimnames")=List of 3
  .. ..$ : chr [1:4] "lissb2" "lissb3" "lissb4" "lissb5"
  .. ..$ : chr [1:4] "1" "2" "3" "4"
  .. ..$ : chr [1:23] "1" "2" "3" "4" ...
 $ ldet   : num [1:23]  4.38  4.28  7.03  5.77 10.48 ...
 $ lev    : chr [1:23] "1" "2" "3" "4" ...
 $ N      : int 392
 $ call   : language qda.matrix(x = mod23[, 2:5], grouping = mod23[, 6])
 - attr(*, "class")= chr "qda"

Finally, I can detect the individual, but don't think
it's a rare one:

> b <- unclass(mod23S.qda.pred$class)
> b[b==262]
[1] 262
> liss.seg.medias[b==262,1]
[1] 11385
> liss.seg.medias[liss.seg.medias[,1]==11385,]
[1] 11385.0000    70.7619    22.8095    78.0476    90.6667

11385 is actually similar to its
neighbors:

> liss.seg.medias[liss.seg.medias[,1]==11384,]
[1] 11384.0000    74.8462    24.8462    89.3077    97.0000
> liss.seg.medias[liss.seg.medias[,1]==11386,]
[1] 11386.0000    71.2857    22.4286    88.8571    95.9286


Why does predict.qda assign a non-existent class (262 or NA)
to individual 11385 ?

Thanks for the help and sorry for the length
of the message.

Agus


On Thu, 20 Dec 2001, Prof Brian Ripley wrote:

> This is a factor.  You have to be careful with NAs in factors (and 1.4.0
> is different there as it happens).
> 
> Nevertheless, there is no way to reproduce this from what you have given.
> Check that the class really is "factor", and then unclass it to see what
> the codes actually are.  One or more of them should be NA from what you
> have given.
> 
> 
> On Thu, 20 Dec 2001, Agustin Lobo wrote:
> 
> >
> > Dear list,
> >
> > (I've not upgraded to R1.4 yet)
> >
> > I have the following $class component in a predict.qda object:
> > > unique(mod23S.qda.pred$class)
> >  [1] 12 17 8  10 4  9  5  13 14 19 20 15 6  3  7  1  23 11 18 21 16 2  22 NA
> > Levels:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
> >
> > Nevertheless, when I try to identify the individual(s) with NA, I get:
> > > any(is.na(mod23S.qda.pred$class))
> > [1] FALSE
> >
> > and
> >
> > > mod23S.qda.pred$class[is.na(mod23S.qda.pred$class)]
> > factor(0)
> > Levels:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
> >
> > So, actually, is there a NA value in mod23S.qda.pred$class or not?
> >
> > (screening by eye it`s impossible:
> > length(mod23S.qda.pred$class) is 26375 )
> >
> > Agus
> >
> > Dr. Agustin Lobo
> > Instituto de Ciencias de la Tierra (CSIC)
> > Lluis Sole Sabaris s/n
> > 08028 Barcelona SPAIN
> > tel 34 93409 5410
> > fax 34 93411 0012
> > alobo at ija.csic.es
> >
> >
> >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From askom at obninsk.com  Thu Dec 20 12:54:40 2001
From: askom at obninsk.com (Alexander Skomorokhov)
Date: Thu, 20 Dec 2001 14:54:40 +0300
Subject: [R] e1071/svm?
In-Reply-To: <Pine.OSF.3.96.1011220111222.13471A-100000@ija.csic.es>
Message-ID: <MJEOJIPNHGCIHJIEEMNOGEMICLAA.askom@obninsk.com>

Hello,

I use function "svm" (interface to libsvm) from package e1071. It works just
fine.
And I may predict with function "predict" and svm model trained by function
"svm".
What I need is moving results of svm training to another application (non-R)
and
perform prediction there. But function "svm" returns list of support vectors
only
and doesn't return coefficients of separating hyperplane (w).

So, the question is how to use results of svm training to write (in other
language)
prediction function for linear and nonlinear cases?

Thanks,
Alexander.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From david.meyer at ci.tuwien.ac.at  Thu Dec 20 13:02:58 2001
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Thu, 20 Dec 2001 13:02:58 +0100
Subject: [R] e1071/svm?
References: <MJEOJIPNHGCIHJIEEMNOGEMICLAA.askom@obninsk.com>
Message-ID: <3C21D372.23805BE6@ci.tuwien.ac.at>

Alexander Skomorokhov wrote:
> 
> Hello,
> 
> I use function "svm" (interface to libsvm) from package e1071. It works just
> fine.
> And I may predict with function "predict" and svm model trained by function
> "svm".
> What I need is moving results of svm training to another application (non-R)
> and
> perform prediction there. But function "svm" returns list of support vectors
> only
> and doesn't return coefficients of separating hyperplane (w).

It does (element ``coefs'' of the returned object).

g.
-d

> 
> So, the question is how to use results of svm training to write (in other
> language)
> prediction function for linear and nonlinear cases?
> 
> Thanks,
> Alexander.
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
	Mag. David Meyer		Wiedner Hauptstrasse 8-10
Vienna University of Technology		A-1040 Vienna/AUSTRIA
       Department for			Tel.: (+431) 58801/10772
Statistics and Probability Theory	mail: david.meyer at ci.tuwien.ac.at
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krcabrer at perseus.unalmed.edu.co  Thu Dec 20 15:11:00 2001
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Thu, 20 Dec 2001 08:11:00 -0600
Subject: [R] Problems with update.packages() in V 1.4.0 on W2K
References: <MJEOJIPNHGCIHJIEEMNOGEMICLAA.askom@obninsk.com>
Message-ID: <3C21F174.B13C739D@perseus.unalmed.edu.co>

Hello dear R fans!

I got a trouble with update.packages() with the version 1.4.0 on
windows 2000.

I make already the change in ..\modules directory.

I rename internet.dll to internetold.dll and I
rename   internet2.dll to internet.dll

My internet conexion has a proxy.

In the version 1.3.1 works everything fine!

Thank you for your help.

Kenneth

P.S. I download the a precompiled version of R 1.4.0 for windows from

http://www.stats.ox.ac.uk/pub/bdr/RWin/Rpre/rw1040*.zip



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Friedrich.Leisch at ci.tuwien.ac.at  Thu Dec 20 14:35:00 2001
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu, 20 Dec 2001 14:35:00 +0100
Subject: [R] Problems with update.packages() in V 1.4.0 on W2K
In-Reply-To: <3C21F174.B13C739D@perseus.unalmed.edu.co>
References: <MJEOJIPNHGCIHJIEEMNOGEMICLAA.askom@obninsk.com>
	<3C21F174.B13C739D@perseus.unalmed.edu.co>
Message-ID: <15393.59652.771392.344453@galadriel.ci.tuwien.ac.at>


Hmm, if you tell us WHAT KIND OF TROUBLES you experience it might be
easier for us to help you ...

fritz

>>>>> On Thu, 20 Dec 2001 08:11:00 -0600,
>>>>> Kenneth Cabrera (KC) wrote:

  > Hello dear R fans!
  > I got a trouble with update.packages() with the version 1.4.0 on
  > windows 2000.

  > I make already the change in ..\modules directory.

  > I rename internet.dll to internetold.dll and I
  > rename   internet2.dll to internet.dll

  > My internet conexion has a proxy.

  > In the version 1.3.1 works everything fine!

  > Thank you for your help.

  > Kenneth

  > P.S. I download the a precompiled version of R 1.4.0 for windows from

  > http://www.stats.ox.ac.uk/pub/bdr/RWin/Rpre/rw1040*.zip



  > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
  > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
  > Send "info", "help", or "[un]subscribe"
  > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
  > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec 20 14:43:24 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 20 Dec 2001 14:43:24 +0100
Subject: [R] Problems with update.packages() in V 1.4.0 on W2K
In-Reply-To: <3C21F174.B13C739D@perseus.unalmed.edu.co>
References: <MJEOJIPNHGCIHJIEEMNOGEMICLAA.askom@obninsk.com>
	<3C21F174.B13C739D@perseus.unalmed.edu.co>
Message-ID: <x2bsguatxf.fsf@blueberry.kubism.ku.dk>

Kenneth Cabrera <krcabrer at perseus.unalmed.edu.co> writes:

> Hello dear R fans!
> 
> I got a trouble with update.packages() with the version 1.4.0 on
> windows 2000.
> 
> I make already the change in ..\modules directory.
> 
> I rename internet.dll to internetold.dll and I
> rename   internet2.dll to internet.dll
> 
> My internet conexion has a proxy.
> 
> In the version 1.3.1 works everything fine!
> 
> Thank you for your help.
> 
> Kenneth
> 
> P.S. I download the a precompiled version of R 1.4.0 for windows from
> 
> http://www.stats.ox.ac.uk/pub/bdr/RWin/Rpre/rw1040*.zip

That may be precompiled, but the pre is for pre*release*. There is no
official 1.4.0 for Windows yet. Even when that appears, you have to
allow the Windows non-maintainer some time to update the binary
packages which update.packages() is attempting to update. Otherwise
you'll just have to build them from source (although Windows is not
the most friendly platform to do that on, as you're surely already
aware).

I.e. you cannot assume update.packages() to work at this stage.
However, listings like CRAN.packages() should work. Do they? If not,
what are the symptoms.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 20 14:47:06 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Dec 2001 13:47:06 +0000 (GMT)
Subject: [R] Problems with update.packages() in V 1.4.0 on W2K
In-Reply-To: <3C21F174.B13C739D@perseus.unalmed.edu.co>
Message-ID: <Pine.LNX.4.31.0112201345460.6079-100000@gannet.stats>

On Thu, 20 Dec 2001, Kenneth Cabrera wrote:

> Hello dear R fans!
>
> I got a trouble with update.packages() with the version 1.4.0 on
> windows 2000.
>
> I make already the change in ..\modules directory.
>
> I rename internet.dll to internetold.dll and I
> rename   internet2.dll to internet.dll
>
> My internet conexion has a proxy.
>
> In the version 1.3.1 works everything fine!

Well, do read the CHANGES file.  There are no internal changes, though.

> Thank you for your help.
>
> Kenneth
>
> P.S. I download the a precompiled version of R 1.4.0 for windows from
>
> http://www.stats.ox.ac.uk/pub/bdr/RWin/Rpre/rw1040*.zip

That's not 1.4.0 ...

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krcabrer at perseus.unalmed.edu.co  Thu Dec 20 15:53:43 2001
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Thu, 20 Dec 2001 08:53:43 -0600
Subject: [R] Problems with update.packages() in V 1.4.0 on W2K
References: <MJEOJIPNHGCIHJIEEMNOGEMICLAA.askom@obninsk.com>
		<3C21F174.B13C739D@perseus.unalmed.edu.co> <15393.59652.771392.344453@galadriel.ci.tuwien.ac.at>
Message-ID: <3C21FB76.6AA31D1A@perseus.unalmed.edu.co>



Friedrich.Leisch at ci.tuwien.ac.at wrote:

> Hmm, if you tell us WHAT KIND OF TROUBLES you experience it might be
> easier for us to help you ...

I got a window Application Error with the following message:

The instruction in "0x00000000" makes reference to the memory "0x0000000".
The memory can't "read".

Click on accept to end this program
Click on CANCEL to debug this program


When I click on accept the program ends!!

And if I click on CANCEL the visual C++ debuger got me to a window
with the following message:

Unhandled exception in Rgui.exe: 0x0C0000005: Access Violation.

And it shows me in a window only a list of address with out any thing:

00000000  ???
00000001  ???
00000002  ???


etc...





>
>
> fritz
>
> >>>>> On Thu, 20 Dec 2001 08:11:00 -0600,
> >>>>> Kenneth Cabrera (KC) wrote:
>
>   > Hello dear R fans!
>   > I got a trouble with update.packages() with the version 1.4.0 on
>   > windows 2000.
>
>   > I make already the change in ..\modules directory.
>
>   > I rename internet.dll to internetold.dll and I
>   > rename   internet2.dll to internet.dll
>
>   > My internet conexion has a proxy.
>
>   > In the version 1.3.1 works everything fine!
>
>   > Thank you for your help.
>
>   > Kenneth
>
>   > P.S. I download the a precompiled version of R 1.4.0 for windows from
>
>   > http://www.stats.ox.ac.uk/pub/bdr/RWin/Rpre/rw1040*.zip
>
>   > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>   > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>   > Send "info", "help", or "[un]subscribe"
>   > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>   > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Thu Dec 20 15:05:17 2001
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Thu, 20 Dec 2001 14:05:17 +0000
Subject: [R] Using sample() twice (bootstrapping from > 1 vector)
Message-ID: <rTqS8EAdAfI8Ew9I@myatt.demon.co.uk>


All,

I am using sample() to take bootstrap replicates and want to be able to
take replicates from multiple columns in a data.frame. I have done this
by using set.seed() to set the seed to the replicate number:

        for(i in i:10) {
          set.seed(i)
          x <- sample(...
          set.seed(i)
          y <- sample(...
          }                       
 
prior to the call to sample(). Is there a better way of doing this? Any
way of getting rid of the for() loop?

Mark

--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Thu Dec 20 15:08:49 2001
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Thu, 20 Dec 2001 14:08:49 +0000
Subject: [R] Modifying a function
In-Reply-To: <3C21A985.60107@intechmer.cnam.fr>
References: <3C21A985.60107@intechmer.cnam.fr>
Message-ID: <pTBSMCAxDfI8Ewcd@myatt.demon.co.uk>

Emmanuel POIZOT <poizot at intechmer.cnam.fr> writes:
>Hello,
>I'd writen a function in R composed of multiples lines.
>How can I do to modify or delete on of the line of my function ?
>
fix()

--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 20 15:11:20 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Dec 2001 14:11:20 +0000 (GMT)
Subject: [R] Problems with update.packages() in V 1.4.0 on W2K
In-Reply-To: <3C21FB76.6AA31D1A@perseus.unalmed.edu.co>
Message-ID: <Pine.LNX.4.31.0112201407150.6079-100000@gannet.stats>

Still, you didn't tell us what you did to get this.

However, I am fairly sure that the surgery you did without reading the
CHANGES file is the problem.  internet2.dll can no longer replace
internet.dll *by renaming it*.

On Thu, 20 Dec 2001, Kenneth Cabrera wrote:

>
>
> Friedrich.Leisch at ci.tuwien.ac.at wrote:
>
> > Hmm, if you tell us WHAT KIND OF TROUBLES you experience it might be
> > easier for us to help you ...
>
> I got a window Application Error with the following message:
>
> The instruction in "0x00000000" makes reference to the memory "0x0000000".
> The memory can't "read".
>
> Click on accept to end this program
> Click on CANCEL to debug this program
>
>
> When I click on accept the program ends!!
>
> And if I click on CANCEL the visual C++ debuger got me to a window
> with the following message:
>
> Unhandled exception in Rgui.exe: 0x0C0000005: Access Violation.
>
> And it shows me in a window only a list of address with out any thing:
>
> 00000000  ???
> 00000001  ???
> 00000002  ???
>
>
> etc...
>
>
>
>
>
> >
> >
> > fritz
> >
> > >>>>> On Thu, 20 Dec 2001 08:11:00 -0600,
> > >>>>> Kenneth Cabrera (KC) wrote:
> >
> >   > Hello dear R fans!
> >   > I got a trouble with update.packages() with the version 1.4.0 on
> >   > windows 2000.
> >
> >   > I make already the change in ..\modules directory.
> >
> >   > I rename internet.dll to internetold.dll and I
> >   > rename   internet2.dll to internet.dll
> >
> >   > My internet conexion has a proxy.
> >
> >   > In the version 1.3.1 works everything fine!
> >
> >   > Thank you for your help.
> >
> >   > Kenneth
> >
> >   > P.S. I download the a precompiled version of R 1.4.0 for windows from
> >
> >   > http://www.stats.ox.ac.uk/pub/bdr/RWin/Rpre/rw1040*.zip
> >
> >   > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> >   > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> >   > Send "info", "help", or "[un]subscribe"
> >   > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> >   > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vasishth at julius.ling.ohio-state.edu  Thu Dec 20 16:16:41 2001
From: vasishth at julius.ling.ohio-state.edu (Shravan Vasishth)
Date: Thu, 20 Dec 2001 10:16:41 -0500 (EST)
Subject: [R] error message: "Error in model.frame"
Message-ID: <Pine.SOL.4.33.0112200959160.22295-100000@julius.ling.ohio-state.edu>

Hi all,

All the files related to the question below are in

http://ling.ohio-state.edu/~vasishth/TempRdir/

I've been using a script (called newresiduals.R, the code is in the above
directory; I wanted to avoid cluttering up this message) that is run in
the following manner at the command prompt:

R --vanilla "wordlen-2-01-g1" < newresiduals.R

What it does is: it goes through a bunch of files with extension .dmp, and
(a) calculates residuals by doing residuals(lm(...)), using the vector
version of wordlen-2-01-g1 as the independent variable, and the vector
version of the third column of each .dmp file as the dependent variable,
(b) adds a new column to the original .dmp file, containing the residuals.

The above command is called from a shell script.

This code has worked fine all these days on hundreds of files, but with
the particular set I'm working with now, when I run the above command,
I get the error message:

> for (i in list.files(pattern = "*.dmp")) {
    currentfile <- read.table(i)
    vecrawrts <- as.vector(currentfile$V3)
    residuals <- residuals(lm(v .... [TRUNCATED]
Error in model.frame(formula, rownames, variables, varnames, extras,
extranames,
:
        invalid variable type
> traceback()
9: model.frame.default(formula = vecrawrts ~ vecwordlen,
drop.unused.levels = TRUE)
8: model.frame(formula = vecrawrts ~ vecwordlen, drop.unused.levels =
TRUE)
7: eval(expr, envir, enclos)
6: eval(mf, parent.frame())
5: lm(vecrawrts ~ vecwordlen)
4: residuals(lm(vecrawrts ~ vecwordlen))
3: eval.with.vis(expr, envir, enclos)
2: eval.with.vis(ei, envir)
1: source("newresiduals.R", echo = TRUE)
> ?model.frame.default

Can anyone help me figure out what's going wrong? The really odd thing is,
the output of the script appears to be perfectly OK, even though it halts
with this error message.

Here's my system configuration, in case this is relevant:

> version
         _
platform powerpc-unknown-linux-gnu
arch     powerpc
os       linux-gnu
system   powerpc, linux-gnu
status
major    1
minor    3.1
year     2001
month    08
day      31
language R

Thanks very much in advance,

-- 
Shravan Vasishth
Dept. of Linguistics, OSU
222 Oxley Hall, 1712 Neil Ave.
Columbus, OH 43210-1298
USA

URL: http://ling.ohio-state.edu/~vasishth



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hjm at holos.pt  Thu Dec 20 16:35:20 2001
From: hjm at holos.pt (Hugo Morganho)
Date: Thu, 20 Dec 2001 15:35:20 +0000
Subject: [R] Memory.limit
In-Reply-To: <F101ZnxV9j1TWCKis9n0000187d@hotmail.com>
Message-ID: <5.0.2.1.0.20011220153237.00afdec0@127.0.0.1>

         Hi.
         I tryed to make available more memory to R, and use the 
--max-mem-size on the shortcut (ki'm running R131 on WinNT), but i can't 
set the memory limit to the size that i want, but just 2147483647 (bytes?).
         I have +- 1GB of virtual memory, so it's not possible to use that?

         Thanks
         Hugo Morganho

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jafarfan at tunku.uady.mx  Thu Dec 20 17:16:34 2001
From: jafarfan at tunku.uady.mx (=?ISO-8859-1?Q?Jos=E9=20Farf=E1n?= Ale)
Date: Thu, 20 Dec 2001 10:16:34 -0600
Subject: [R] R for solaris
Message-ID: <3C220EE2.1080802@tunku.uady.mx>

    Dear members in the group. I am trying to start using R. The unix 
systme we have in my university is solaris 7. Is there a version of R 
for Solaris 7?. If afirmative where could I get it?
Thanks in advance.

Jose A. Farfan

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 20 17:16:04 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Dec 2001 16:16:04 +0000 (GMT)
Subject: [R] Memory.limit
In-Reply-To: <5.0.2.1.0.20011220153237.00afdec0@127.0.0.1>
Message-ID: <Pine.LNX.4.31.0112201607331.6337-100000@gannet.stats>

On Thu, 20 Dec 2001, Hugo Morganho wrote:

>          Hi.
>          I tryed to make available more memory to R, and use the
> --max-mem-size on the shortcut (ki'm running R131 on WinNT), but i can't
> set the memory limit to the size that i want, but just 2147483647 (bytes?).
>          I have +- 1GB of virtual memory, so it's not possible to use that?

You didn't tell us what did not work.  But

Rgui.exe --max-mem-size=1000M

has worked for me.  I really don't think you will find it works well
using virtual memory though: R uses memory allocation pretty actively
and VM is hardly likely to be fast enough.

R 1.4.0 has some tweaks to make better use of large amounts of (real)
memory under Windows.  There are still address space limits: users get 2Gb
on NT4 (so the book says), and that includes for some parts of the OS.  I
managed to allocate 1.75Gb under Windows 2000, no more.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 20 17:19:06 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Dec 2001 16:19:06 +0000 (GMT)
Subject: [R] R for solaris
In-Reply-To: <3C220EE2.1080802@tunku.uady.mx>
Message-ID: <Pine.LNX.4.31.0112201617110.6337-100000@gannet.stats>

On Thu, 20 Dec 2001, [ISO-8859-1] José Farfán Ale wrote:

>     Dear members in the group. I am trying to start using R. The unix
> systme we have in my university is solaris 7. Is there a version of R
> for Solaris 7?. If afirmative where could I get it?

You just need to compile it.  Solairs 2.7 aka 7 is one of the standard
test platforms (mine), so it should compile out of the box.  There is a
section it the R-admin.html file about Solaris too.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec 20 17:34:33 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 20 Dec 2001 17:34:33 +0100
Subject: [R] R for solaris
In-Reply-To: <3C220EE2.1080802@tunku.uady.mx>
References: <3C220EE2.1080802@tunku.uady.mx>
Message-ID: <x2lmfxg89y.fsf@blueberry.kubism.ku.dk>

Jos? Farf?n Ale <jafarfan at tunku.uady.mx> writes:

>     Dear members in the group. I am trying to start using R. The unix
> systme we have in my university is solaris 7. Is there a version of R
> for Solaris 7?. If afirmative where could I get it?
> Thanks in advance.

If you have the relevant build tools (C compiler, perl, etc.) then the
regular sources should build easily on that platform.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Dec 20 17:49:52 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 20 Dec 2001 08:49:52 -0800 (PST)
Subject: [R] Survival analysis using a scale change random effects
In-Reply-To: <5.0.2.1.1.20011220114634.01db1640@pop3.norton.antivirus>
Message-ID: <Pine.A41.4.33.0112200847560.44944-100000@homer28.u.washington.edu>

On Thu, 20 Dec 2001, Giovanni Parrinello wrote:

> Dear All,
> I am looking for implementations of the model described in the article
>   Anderson-Louis: " Survival Analysis using a scale random effects model"-
> JASA 1995 pg.669-679.

I have no specific knowledge of this article, but from the title it looks
as though the model is similar to the frailty models implemented in the
survival package, using either survreg for parametric models or coxph for
semiparametric ones.

Try help(frailty) after loading the survival package.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gardar at stat.ohio-state.edu  Thu Dec 20 17:54:08 2001
From: gardar at stat.ohio-state.edu (Gardar Johannesson)
Date: Thu, 20 Dec 2001 11:54:08 -0500 (EST)
Subject: [R] optimizing R-1.4.0 build on Solaris; a show-and-tell storry
Message-ID: <Pine.SOL.4.33.0112201101020.10307-100000@spatial.stat.ohio-state.edu>

This is a little success story about the benefits of changing
the defaults in config.site when I was building R-1.4.0 for Solaris
(on a Sun Sparc that I'm currently using).

For previous versions of R, I had just used the default config.site and
not given it any thought.  Since the Sun machine that I'm using
is not getting any faster, I decided I would give config.site a look
when building R-1.4.0.

By default, doing './configure' and then 'make' in building R-1.4.0 from
source, results in the following (short summary list) of compiling flags:

BLAS = blas.o
BLAS_LIBS =
CC = cc
CFLAGS = -g
FC = f77
FFLAGS = -g

Following suggestions given in R-admin.html, I also build R-1.4.0
with:

BLAS =
BLAS_LIBS = -xlic_lib=sunperf -lsunmath
CC = cc -xarch=v9
CFLAGS = -xO5 -xlibmil -dalign
FC = f95 -xarch=v9
FFLAGS = -xO5 -xlibmil -dalign

I did few tests comparing the speed of these two builds.  In short, I
saw about 65% speed improvement for general use, slightly more for
regression problems (2-3 times), and considerable more in matrix
multiplication (50 times).

Here are the tests.

1) Timing the tests/Examples/base-Ex.R script.  I did the following for
   the two builds:
     time ./bin/R --vanilla < tests/Examples/base-Ex.R > tmp.out
   resulting in the following times:
     R-1.4.0-def: 227.70u 26.88s 4:20.34 97.7%
     R-1.4.0-opt: 138.75u 30.90s 2:57.62 95.5%
   for the default and optimized version, where 227.70u and 138.75u are
   the users CPU time.  That is, the default is about 65% slower.

2) A little MCMC example that I have using a for-loop to generate 10,000
   samples from the posterior:
     R-1.4.0-def: 14.45 sec user CPU
     R-1.4.0-opt:  8.96 sec user CPU
     S-6.0      : 34.19 sec user CPU
   where the last line is from S-plus 6.0 on the same machine.

3) A regression,
     lm(ozone ~ ns(lat.band,df=15) +
                ns(lat.band,df=10):ns(lon.band,df=15),
                weights=1/var, data=data, na.action=na.omit))
   where data has in one case 3240 rows and in a other case 12960 rows.
   The number of estimated parameters is 166 in both cases.
   For data with 3240 rows:
     R-1.4.0-def: 7.12 sec user CPU time
     R-1.4.0-opt: 2.90 sec user CPU time
     S-6.0      : 3.78 sec user CPU time
   For data with 12960 rows:
     R-1.4.0-def: 28.34 sec user CPU time
     R-1.4.0-opt: 14.97 sec user CPU time
     S-6.0      : 13.70 sec user CPU time

4) The result of system.time(B <- A %*% A) where A is 500x500 matrix.
     R-1.4.0-def: 18.83 sec user CPU time
     R-1.4.0-opt:  0.37 sec user CPU time


I hope this will be of use to somebody... cheers, Gardar


_________________________________________________________
Gardar Johannesson
 Department of Statistics
Ohio State University
304E Cockins Hall, 1958 Neil Av.
Columbus, OH 43210

Tel: 614-292-1567
Fax: 614-292-2096
e-mail: gardar at stat.ohio-state.edu
WWW: www.stat.ohio-state.edu
_________________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From askom at obninsk.com  Thu Dec 20 18:06:17 2001
From: askom at obninsk.com (Alexander Skomorokhov)
Date: Thu, 20 Dec 2001 20:06:17 +0300
Subject: [R] e1071/svm?
In-Reply-To: <3C21D372.23805BE6@ci.tuwien.ac.at>
Message-ID: <MJEOJIPNHGCIHJIEEMNOKEMMCLAA.askom@obninsk.com>

Thank you fot your reply. Sorry, but I still haven't got the problem.
Here is a trivial example (cpy from R session):
----------------------------------------------------------------------------
------------------
> x
     [,1] [,2]
[1,]    0    0
[2,]    0    1
[3,]    1    0
[4,]    1    1
[5,]    2    2
[6,]    2    3
[7,]    3    2
[8,]    3    3
> y
[1] 1 1 1 1 2 2 2 2
Levels:  1 2
> is.factor(y)
[1] TRUE
> library(e1071)
> m<-svm(x,y,kernel='linear')
*
optimization finished, #iter = 3
nu = 0.250000
obj = -1.000000, rho = -3.000000
nSV = 2, nBSV = 2
Total nSV = 2

> summary(m)
Call:
 svm.default(x = x, y = y, kernel = "linear")
Parameters:
   SVM-Type:  C-classification
 SVM-Kernel:  linear
       cost:  1
     degree:  3
      gamma:  0.5
     coef.0:  0
         nu:  0.5
    epsilon:  0.5
       cost:  1
Number of Support Vectors:  2  ( 1 1 )
Number of Classes:  2
Levels:
 1 2
Rho:
 -3
Support Vectors:
     [,1] [,2]
[1,]    1    1
[2,]    2    2
Coefficiants:
     [,1]
[1,]    1
[2,]   -1
----------------------------------------------------------------------------
----------
I see Coefficiants, but can't guess how to use them (only them?) for
prediction???
I may guess that the question sounds like a stupid one, but it is that:-(

Thanks,
Alexander.





> -----Original Message-----
> From: meyer at ci.tuwien.ac.at [mailto:meyer at ci.tuwien.ac.at]On
> Behalf Of David Meyer
> Sent: Thursday, December 20, 2001 3:03 PM
> To: askom at obninsk.com
> Cc: r-help
> Subject: Re: [R] e1071/svm?
>
>
> Alexander Skomorokhov wrote:
> >
> > Hello,
> >
> > I use function "svm" (interface to libsvm) from package e1071.
> It works just
> > fine.
> > And I may predict with function "predict" and svm model trained
> by function
> > "svm".
> > What I need is moving results of svm training to another
> application (non-R)
> > and
> > perform prediction there. But function "svm" returns list of
> support vectors
> > only
> > and doesn't return coefficients of separating hyperplane (w).
>
> It does (element ``coefs'' of the returned object).
>
> g.
> -d
>
> >
> > So, the question is how to use results of svm training to write
> (in other
> > language)
> > prediction function for linear and nonlinear cases?
> >
> > Thanks,
> > Alexander.
> >
> >
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-
> > r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

--
	Mag. David Meyer		Wiedner Hauptstrasse 8-10
Vienna University of Technology		A-1040 Vienna/AUSTRIA
       Department for			Tel.: (+431) 58801/10772
Statistics and Probability Theory	mail: david.meyer at ci.tuwien.ac.at



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rolf at math.unb.ca  Thu Dec 20 18:28:45 2001
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 20 Dec 2001 13:28:45 -0400 (AST)
Subject: [R] library()
Message-ID: <200112201728.NAA20139@gelfand.math.unb.ca>


I've just installed version 1.4.0 of R, and am experiencing
a puzzling phenomenon with the library() function.

I have .lib.loc set as follows:

> .lib.loc
[1] "/usr/local/lib/R/library"      "/home/faculty/rolf/Rlib"

If I invoke

> library(melvin)

I get the error message

   Error in library(melvin) : There is no package called `melvin'

but if I invoke

> library(melvin,lib.loc="/home/faculty/rolf/Rlib")

the package ``melvin'' gets loaded with no problems.

What gives?  Is the .lib.loc object not being used in 1.4.0 the way
it was used in 1.3.1?  (I can't see anything about this in the
``USER-VISIBLE CHANGES'' in Peter Dalgaard's posting to this list
yesterday.)  Or have I done something silly?

				cheers,

					Rolf Turner
					rolf at math.unb.ca

Details:

> version
         _                   
platform sparc-sun-solaris2.7
arch     sparc               
os       solaris2.7          
system   sparc, solaris2.7   
status                       
major    1                   
minor    4.0                 
year     2001                
month    12                  
day      19                  
language R
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 20 19:17:14 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Dec 2001 18:17:14 +0000 (GMT)
Subject: [R] optimizing R-1.4.0 build on Solaris; a show-and-tell storry
In-Reply-To: <Pine.SOL.4.33.0112201101020.10307-100000@spatial.stat.ohio-state.edu>
Message-ID: <Pine.LNX.4.31.0112201815430.6505-100000@gannet.stats>

That's a 64-bit build.  Unless you really need it, -xarch=v8 (or omit it
altogether) will be faster (about 10% on my tests).

Most of the difference is turning optimization on (and debugging off)


On Thu, 20 Dec 2001, Gardar Johannesson wrote:

> This is a little success story about the benefits of changing
> the defaults in config.site when I was building R-1.4.0 for Solaris
> (on a Sun Sparc that I'm currently using).
>
> For previous versions of R, I had just used the default config.site and
> not given it any thought.  Since the Sun machine that I'm using
> is not getting any faster, I decided I would give config.site a look
> when building R-1.4.0.
>
> By default, doing './configure' and then 'make' in building R-1.4.0 from
> source, results in the following (short summary list) of compiling flags:
>
> BLAS = blas.o
> BLAS_LIBS =
> CC = cc
> CFLAGS = -g
> FC = f77
> FFLAGS = -g
>
> Following suggestions given in R-admin.html, I also build R-1.4.0
> with:
>
> BLAS =
> BLAS_LIBS = -xlic_lib=sunperf -lsunmath
> CC = cc -xarch=v9
> CFLAGS = -xO5 -xlibmil -dalign
> FC = f95 -xarch=v9
> FFLAGS = -xO5 -xlibmil -dalign
>
> I did few tests comparing the speed of these two builds.  In short, I
> saw about 65% speed improvement for general use, slightly more for
> regression problems (2-3 times), and considerable more in matrix
> multiplication (50 times).
>
> Here are the tests.
>
> 1) Timing the tests/Examples/base-Ex.R script.  I did the following for
>    the two builds:
>      time ./bin/R --vanilla < tests/Examples/base-Ex.R > tmp.out
>    resulting in the following times:
>      R-1.4.0-def: 227.70u 26.88s 4:20.34 97.7%
>      R-1.4.0-opt: 138.75u 30.90s 2:57.62 95.5%
>    for the default and optimized version, where 227.70u and 138.75u are
>    the users CPU time.  That is, the default is about 65% slower.
>
> 2) A little MCMC example that I have using a for-loop to generate 10,000
>    samples from the posterior:
>      R-1.4.0-def: 14.45 sec user CPU
>      R-1.4.0-opt:  8.96 sec user CPU
>      S-6.0      : 34.19 sec user CPU
>    where the last line is from S-plus 6.0 on the same machine.
>
> 3) A regression,
>      lm(ozone ~ ns(lat.band,df=15) +
>                 ns(lat.band,df=10):ns(lon.band,df=15),
>                 weights=1/var, data=data, na.action=na.omit))
>    where data has in one case 3240 rows and in a other case 12960 rows.
>    The number of estimated parameters is 166 in both cases.
>    For data with 3240 rows:
>      R-1.4.0-def: 7.12 sec user CPU time
>      R-1.4.0-opt: 2.90 sec user CPU time
>      S-6.0      : 3.78 sec user CPU time
>    For data with 12960 rows:
>      R-1.4.0-def: 28.34 sec user CPU time
>      R-1.4.0-opt: 14.97 sec user CPU time
>      S-6.0      : 13.70 sec user CPU time
>
> 4) The result of system.time(B <- A %*% A) where A is 500x500 matrix.
>      R-1.4.0-def: 18.83 sec user CPU time
>      R-1.4.0-opt:  0.37 sec user CPU time
>
>
> I hope this will be of use to somebody... cheers, Gardar
>
>
> _________________________________________________________
> Gardar Johannesson
>  Department of Statistics
> Ohio State University
> 304E Cockins Hall, 1958 Neil Av.
> Columbus, OH 43210
>
> Tel: 614-292-1567
> Fax: 614-292-2096
> e-mail: gardar at stat.ohio-state.edu
> WWW: www.stat.ohio-state.edu
> _________________________________________________________
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 20 19:25:26 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Dec 2001 18:25:26 +0000 (GMT)
Subject: [R] library()
In-Reply-To: <200112201728.NAA20139@gelfand.math.unb.ca>
Message-ID: <Pine.LNX.4.31.0112201820020.6505-100000@gannet.stats>

On Thu, 20 Dec 2001, Rolf Turner wrote:

>
> I've just installed version 1.4.0 of R, and am experiencing
> a puzzling phenomenon with the library() function.
>
> I have .lib.loc set as follows:
>
> > .lib.loc
> [1] "/usr/local/lib/R/library"      "/home/faculty/rolf/Rlib"
>
> If I invoke
>
> > library(melvin)
>
> I get the error message
>
>    Error in library(melvin) : There is no package called `melvin'
>
> but if I invoke
>
> > library(melvin,lib.loc="/home/faculty/rolf/Rlib")
>
> the package ``melvin'' gets loaded with no problems.
>
> What gives?  Is the .lib.loc object not being used in 1.4.0 the way
> it was used in 1.3.1?  (I can't see anything about this in the
> ``USER-VISIBLE CHANGES'' in Peter Dalgaard's posting to this list
> yesterday.)  Or have I done something silly?

There was a late change you will see down the list

    o   New function .libPaths() for getting or setting the paths to the
        library trees R knows about.  This is still stored in .lib.loc,
        which however should no longer be accessed directly.

so you might like to try that.

`USER-VISIBLE CHANGES' was an idea (of mine) to highlight import ones:
there may well be others. The person who changed this one obviously did
not think it important enough: the point is that .lib.loc from
package:base is used now, not one you set in the workspace.

Thanks for bringing this up: I was unaware of the change. It confirms that
the recommended way (set R_LIBS or use .libPaths()) should be adhered to!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brianscholl1973 at yahoo.com  Thu Dec 20 21:08:59 2001
From: brianscholl1973 at yahoo.com (Brian Scholl)
Date: Thu, 20 Dec 2001 12:08:59 -0800 (PST)
Subject: [R] ARIMA0 with xreg, 
In-Reply-To: <Pine.LNX.4.31.0112192210170.1965-100000@gannet.stats>
Message-ID: <20011220200859.91260.qmail@web12201.mail.yahoo.com>

Fair enough.  I won't bother to define things since I
think what you are saying is that if X is my Txr
matrix of time series data, make xreg=X[,2:r] for the
regression on X[,1], which means I misunderstood the
function specifications.  Sorry, and thanks.

  

--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> You need to define some terms.  But from `VAR' and
> `matrix of data' I
> guess that you have a multiple time series.  If so,
> it just isn't valid
> to use arima0, which is univariate.  You also did
> not say what `x' is,
> but the `x' in `xreg' means eXogenous.
> 
> On Wed, 19 Dec 2001, Brian Scholl wrote:
> 
> > Hi all,
> >
> > Using ar(), I fit a VAR to my time series that has
> a
> > reasonably 'nice' error spectrum and aic
> determines
> > p=7.   But the output for ar isn't quite as
> convenient
> > as arima0, namely in that it takes me an extra
> step to
> > get the s.e.'s of parameters and it doesn't
> produce an
> > estimate of the log-likelihood for comparison to
> other
> > models. So I thought I'd use arimia0, with xreg=x,
> my
> > matrix of data and order=(7,0,0).
> >
> > When I do this, the results are funny.  The
> residuals
> > look - well, just like the original series on a
> > readjusted scale.  The spectrum for the residuals
> > looks slightly different from the spectrum of x
> and
> > bears no resemblance to the nice spectrum I got
> before
> > (this one looks like a long memory process, while
> the
> > earlier was closer to white noise).  Certainly I
> don't
> > expect the spectra and residuals to look exactly
> alike
> > because of the different solution methods, but
> these
> > bear little resemblance to each other.
> >
> > I assume, of course that the error is on my part,
> > perhaps something I've overlooked, but I'm not
> able to
> > find it.
> >
> > Thanks,
> >
> > Brian
> >
> >
> >
> > __________________________________________________
> >
> >
> >
> >
> >
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> >
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> >
> 
> -- 
> Brian D. Ripley,                 
> ripley at stats.ox.ac.uk
> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865
> 272861 (self)
> 1 South Parks Road,                     +44 1865
> 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865
> 272595
> 
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


__________________________________________________




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Thu Dec 20 21:21:03 2001
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 20 Dec 2001 15:21:03 -0500
Subject: [R] Any interest in ATLAS-enabled R-1.4.0 for MSWin?
Message-ID: <51F9C42DA15CD311BD220008C707D81903DC843B@usrymx10.merck.com>

Hi all,

I've compiled R-1.4.0 on my NT box with link against ATLAS.  It has passed
all the Rcmd CHECK that I could run.  If there's sufficient interest, I can
make the SetupR.exe available (on CRAN?).  Just drop me a note if you're
interested.  Note the following:

o  I can only connect thru 56K dial-up until Jan. 2, 2002, so unless there's
overwhelming demand, I won't attempt the upload until then.

o  The ATLAS is optimized for the Pentium III with SSE1 architecture, so you
need at least that (e.g., P4 probably works, but not PII).

o  The pre-compiled packages made available by Prof. Ripley may not work (if
they contain calls to BLAS).  Thus update.packages() may not work for such
packages.  I can also provide ATLAS-enabled packages, if there's sufficient
interest.

Now, question:  Is it possble (perhaps by adding options to
update.packages()) to get update.packages() to download the source and
compile, like other platforms, on Windoze?

Happy holidays!
Andy
Andy I. Liaw, PhD
Biometrics Research          Phone: (732) 594-0820
Merck & Co., Inc.              Fax: (732) 594-1565
P.O. Box 2000, RY70-38            Rahway, NJ 07065
mailto:andy_liaw at merck.com



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ihaka at stat.auckland.ac.nz  Thu Dec 20 21:34:51 2001
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Fri, 21 Dec 2001 09:34:51 +1300
Subject: [R] Jobs at the University of Auckland
Message-ID: <3C224B6B.C34A0A3F@stat.auckland.ac.nz>

We have two lectureship positions advertised at the moment.
One (or both) of these is intended for a specialist in statistical
computation.  The salary doesn't look great by international standards
but there are compensations:  housing is cheap, the air is clean,
and the worlds problems are far away.  We also have a track record
of getting tenure for computing people.

	http://www.stat.auckland.ac.nz/vacancies.shtml

(We can also possibly wrangle a senior position for special
 candidates ;-)

-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 5054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 20 21:35:55 2001
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 20 Dec 2001 20:35:55 +0000 (GMT Standard Time)
Subject: [R] Any interest in ATLAS-enabled R-1.4.0 for MSWin?
In-Reply-To: <51F9C42DA15CD311BD220008C707D81903DC843B@usrymx10.merck.com>
Message-ID: <Pine.WNT.4.31.0112202031150.1364-100000@gannet>

On Thu, 20 Dec 2001, Liaw, Andy wrote:

> Hi all,
>
> I've compiled R-1.4.0 on my NT box with link against ATLAS.  It has passed
> all the Rcmd CHECK that I could run.  If there's sufficient interest, I can
> make the SetupR.exe available (on CRAN?).  Just drop me a note if you're
> interested.  Note the following:
>
> o  I can only connect thru 56K dial-up until Jan. 2, 2002, so unless there's
> overwhelming demand, I won't attempt the upload until then.
>
> o  The ATLAS is optimized for the Pentium III with SSE1 architecture, so you
> need at least that (e.g., P4 probably works, but not PII).
>
> o  The pre-compiled packages made available by Prof. Ripley may not work (if
> they contain calls to BLAS).  Thus update.packages() may not work for such
> packages.  I can also provide ATLAS-enabled packages, if there's sufficient
> interest.

There are only 5 exceptions at present (KernSmooth, bqtl, fracdiff, gss,
quadprog and quantreg) that need rebuilding.

This should be much easier come R 1.5.0, when all that needs to be done is
to replace a single DLL, and then we can make various versions of that DLL
available.  For those who are interested, it might be better to use the
current R-devel, which is already set up for this.

> Now, question:  Is it possble (perhaps by adding options to
> update.packages()) to get update.packages() to download the source and
> compile, like other platforms, on Windoze?

No, it's not.  People have enough problems doing it manually!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rolf at math.unb.ca  Thu Dec 20 21:44:50 2001
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 20 Dec 2001 16:44:50 -0400 (AST)
Subject: [R] library()
Message-ID: <200112202044.QAA17286@tanner.math.unb.ca>


Many thanks to Prof. Brian Ripley for quickly solving my problem.  As
you will have already seen from his posting, what I should have done,
INSTEAD OF

	> .lib.loc <- c("/usr/local/lib/R/library","/home/faculty/rolf/Rlib")

was

	> .libPaths("/home/faculty/rolf/Rlib")

which appends the named library to the existing set of paths to
library trees.

I could also issue the command

	setenv R_LIBS /home/faculty/rolf/Rlib

(say by putting this line in my .cshrc file) which ensures that my
personal library gets included in the search tree whenever R is
started.  (Notice that it is not necessary to include the ``system
library'', i.e.  /usr/local/lib/R/library, in the setenv command ---
the system library is always available, willy-nilly.  If you want to
have your local library searched ***before*** the system library you
could set R_LIBS by (the analogue of)

	setenv R_LIBS /home/faculty/rolf/Rlib:/usr/local/lib/R/library

The important thing to remember is that the local object ``.lib.loc''
gets ignored in R-1.4.0; you can assign it a value, but doing so
will have no useful effect whatever.

					cheers,

						Rolf Turner
						rolf at math.unb.ca
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From carlm at demog.berkeley.edu  Fri Dec 21 01:20:36 2001
From: carlm at demog.berkeley.edu (Carl Mason --- Director Demography Lab)
Date: Thu, 20 Dec 2001 16:20:36 -0800 (PST)
Subject: [R] proportional hazard with parametric baseline function: can it be
 estimated in R
Message-ID: <Pine.LNX.4.33.0112201602410.7344-100000@normal.DEMOG.Berkeley.EDU>


Greetings --

I would like to estimate a proportional hazard model with a weibull or
lognormal baseline.  I have looked at both the coxph() and survreg()
functions and neither appear (to me ) to do it.  Am I missing something in
the docs or is there another terrific package out there that will do this.

Many Thanks.

Carl Mason

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Dec 21 01:48:00 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 20 Dec 2001 16:48:00 -0800 (PST)
Subject: [R] proportional hazard with parametric baseline function: can
 it be estimated in R
In-Reply-To: <Pine.LNX.4.33.0112201602410.7344-100000@normal.DEMOG.Berkeley.EDU>
Message-ID: <Pine.A41.4.33.0112201635230.115586-100000@homer01.u.washington.edu>

On Thu, 20 Dec 2001, Carl Mason --- Director Demography Lab wrote:

>
> Greetings --
>
> I would like to estimate a proportional hazard model with a weibull or
> lognormal baseline.  I have looked at both the coxph() and survreg()
> functions and neither appear (to me ) to do it.  Am I missing something in
> the docs or is there another terrific package out there that will do this.
>

survreg() will fit accelerated failure models with Weibull or lognormal
baselines. For the Weibull case these are equivalent to proportional
hazards models.  To convert the accelerated failure coefficients into
proportional hazards coefficients one just divides by -estimated scale,
which is given in the standard output.

Lognormal proportional hazards models are an unusual choice as the
lognormal family is not a proportional hazards family. If the distribution
is lognormal for all covariates=0 it will not be lognormal at any other
covariate value. This means that eg centering the covariates changes the
model.

Unless censoring is strongly related to your covariates or you want to use
the model for extrapolation to longer followup than you observed there is
no real advantage to a parametric proportional hazards model, so you might
as well use coxph().

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vasishth at ling.ohio-state.edu  Fri Dec 21 05:04:42 2001
From: vasishth at ling.ohio-state.edu (Shravan Vasishth)
Date: Thu, 20 Dec 2001 23:04:42 -0500 (EST)
Subject: [R] read.table and as.vector (Was error message: "Error in model.frame")
Message-ID: <Pine.SOL.4.33.0112201636330.15818-100000@julius.ling.ohio-state.edu>

Hi all,

I figured out some things about an earlier question I posted today; this
is a new question:

I have a for-loop in which I have the following lines

 for (i in list.files(pattern = "*.dmp")) {
    currentfile <- read.table(i)
    vecrawrts <- as.vector(currentfile$V3)
...
}

Now, vecrawrts is numeric, but if I run the script on all the files with
extension .dmp, I get the error message

> for (i in list.files(pattern = "*.dmp")) {
    currentfile <- read.table(i)
    vecrawrts <- as.vector(currentfile$V3)
    residuals <- residuals(lm(v .... [TRUNCATED]
Error in model.frame(formula, rownames, variables, varnames, extras,
extranames,
        invalid variable type

But if I do something like

 for (i in list.files(pattern = "*.dmp")) {
currentfile <- read.table(i)
n <- currentfile$V3
numn<-as.numeric(n)
residuals <- residuals(lm(numn ~ vecwordlen))
...
}

everything works fine.

Why should this happen?

Here is the full script containing the above loop:

#-----------------------------------------------------

foobar <- commandArgs()[3] # read in third command line argument
                           # from shell script
                           # (contains the wordlen file name)

# read in word length as table;

wordlen <- read.table(foobar)

# convert it to a vector:

vecwordlen <- as.vector(t(wordlen))

# for each file with extension .dmp

for (i in list.files(pattern="*.dmp")){

# read in the file

currentfile <- read.table(i)

# convert 3rd column to a vector:

n <- currentfile$V3

numn<-as.numeric(n)

# compute residuals

residuals <- residuals(lm(numn ~ vecwordlen))

# convert currentfile to matrix format

matcurrentfile <- as.matrix(currentfile)

# convert residuals to matrix format:

matres <- as.matrix(residuals)

# combine the original file with the residuals

bound <- cbind(matcurrentfile,matres)

# append to the output file:

write(t(bound),file="rawresidualsoutput",ncolumns=4,append=TRUE)

# clean up and start loop again

rm(residuals,matres,currentfile,matcurrentfile,bound)
}

# after all files are done, remove the other objects

rm(wordlen, vecwordlen)

#---------------------------------------------------

Thanks,

--
Shravan Vasishth
Dept. of Linguistics, OSU
222 Oxley Hall, 1712 Neil Ave.
Columbus, OH 43210-1298
USA

URL: http://ling.ohio-state.edu/~vasishth

---------- Forwarded message ----------
Date: Thu, 20 Dec 2001 10:16:41 -0500 (EST)
From: Shravan Vasishth <vasishth at julius.ling.ohio-state.edu>
To: r-help at lists.R-project.org
Subject: error message: "Error in model.frame"

Hi all,

All the files related to the question below are in

http://ling.ohio-state.edu/~vasishth/TempRdir/

I've been using a script (called newresiduals.R, the code is in the above
directory; I wanted to avoid cluttering up this message) that is run in
the following manner at the command prompt:

R --vanilla "wordlen-2-01-g1" < newresiduals.R

What it does is: it goes through a bunch of files with extension .dmp, and
(a) calculates residuals by doing residuals(lm(...)), using the vector
version of wordlen-2-01-g1 as the independent variable, and the vector
version of the third column of each .dmp file as the dependent variable,
(b) adds a new column to the original .dmp file, containing the residuals.

The above command is called from a shell script.

This code has worked fine all these days on hundreds of files, but with
the particular set I'm working with now, when I run the above command,
I get the error message:

> for (i in list.files(pattern = "*.dmp")) {
    currentfile <- read.table(i)
    vecrawrts <- as.vector(currentfile$V3)
    residuals <- residuals(lm(v .... [TRUNCATED]
Error in model.frame(formula, rownames, variables, varnames, extras,
extranames,
:

> traceback()
9: model.frame.default(formula = vecrawrts ~ vecwordlen,
drop.unused.levels = TRUE)
8: model.frame(formula = vecrawrts ~ vecwordlen, drop.unused.levels =
TRUE)
7: eval(expr, envir, enclos)
6: eval(mf, parent.frame())
5: lm(vecrawrts ~ vecwordlen)
4: residuals(lm(vecrawrts ~ vecwordlen))
3: eval.with.vis(expr, envir, enclos)
2: eval.with.vis(ei, envir)
1: source("newresiduals.R", echo = TRUE)
> ?model.frame.default

Can anyone help me figure out what's going wrong? The really odd thing is,
the output of the script appears to be perfectly OK, even though it halts
with this error message.

Here's my system configuration, in case this is relevant:

> version
         _
platform powerpc-unknown-linux-gnu
arch     powerpc
os       linux-gnu
system   powerpc, linux-gnu
status
major    1
minor    3.1
year     2001
month    08
day      31
language R

Thanks very much in advance,

-- 
Shravan Vasishth
Dept. of Linguistics, OSU
222 Oxley Hall, 1712 Neil Ave.
Columbus, OH 43210-1298
USA

URL: http://ling.ohio-state.edu/~vasishth






-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From znmeb at aracnet.com  Fri Dec 21 06:03:04 2001
From: znmeb at aracnet.com (M. Edward Borasky)
Date: Thu, 20 Dec 2001 21:03:04 -0800
Subject: [R] RE: Any interest in ATLAS-enabled R-1.4.0 for MSWin?
In-Reply-To: <200112210301.EAA28295@stat.math.ethz.ch>
Message-ID: <HBEHIIBBKKNOBLMPKCBBCEHIEEAA.znmeb@aracnet.com>

> Date: Thu, 20 Dec 2001 15:21:03 -0500
> From: "Liaw, Andy" <andy_liaw at merck.com>
> Subject: [R] Any interest in ATLAS-enabled R-1.4.0 for MSWin?
>
> Hi all,
>
> I've compiled R-1.4.0 on my NT box with link against ATLAS.  It has passed
> all the Rcmd CHECK that I could run.  If there's sufficient
> interest, I can
> make the SetupR.exe available (on CRAN?).  Just drop me a note if you're
> interested.  Note the following:

Yes, I am interested, although I am probably going to duplicate this effort
and at least one other. I have a number of PIIIs available where I work --
and a few PIIs :( -- as well as a Celeron at home, all running Windows 2000.
IIRC PIII Atlas == Celeron Atlas. If Celeron Atlas != PIII Atlas, I will be
building Celeron Atlas and then Windows R 1.4.0 at home, and PIII Atlas/R at
work.

Because of the unavailability of sound card drivers on my Athlon / Linux
box, I was forced to dual-boot that machine Windows 2000 and Red Hat 7.2. I
am, even as we speak, building the latest development version of Atlas
(3.3.13) on the Linux side and will be testing it with R 1.4.0 once that is
done. Assuming all goes well, I can probably make the results available as
binary RPMs, although Atlas is BSD licensed and Atlas 3.3.13 is a developer
("unstable") release. Athlon Atlas builds best with gcc 2.95.3, I'm told, so
it will take me a while to test all of this.

Once I have all *that* magic debugged, I'm planning on building Athlon
Windows Atlas (3.3.13) and R 1.4.0, using whatever the recommended tools are
these days -- most likely using the same Windows tools to build Atlas that I
am using to build R. That's a lower-priority item; since the machine is
dual-booted, when I need R/Atlas I can reboot and run against data in a
shared partition.
--
Take Your Trading to the Next Level!
M. Edward Borasky, Meta-Trading Coach

znmeb at borasky-research.net
http://www.meta-trading-coach.com
http://groups.yahoo.com/group/meta-trading-coach

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From znmeb at aracnet.com  Fri Dec 21 07:35:55 2001
From: znmeb at aracnet.com (M. Edward Borasky)
Date: Thu, 20 Dec 2001 22:35:55 -0800
Subject: [R] R-1.4.0 / Atlas 3.3.13 / gcc 2.95.3 / RH 7.2 / Athlon build appears successful
In-Reply-To: <HBEHIIBBKKNOBLMPKCBBAEHHEEAA.znmeb@aracnet.com>
Message-ID: <HBEHIIBBKKNOBLMPKCBBKEHJEEAA.znmeb@aracnet.com>

The build of R-1.4.0 with Atlas 3.3.13, both compiled with gcc 2.95.3 on an
Athlon Thunderbird (1.333 GHz) running otherwise stock Red Hat Linux 7.2,
appears to have been successful. R passed all its built-in checks. This is
the first time I've been able to get all of this to work together; the last
few times I tried this (late June or early July IIRC), R did not pass its
checks when linked with Atlas, but I never had a chance to investigate.

If anyone has any tests they want me to run beyond that, or wants to see any
log files, please e-mail me off-list. I'm going to run some of my simple
computational finance stuff and possibly some computer performance data
analysis with this setup over the weekend. I don't have anything
particularly challenging at the moment, but if I spot anything broken I'll
post it to the list.

My next step is to repeat this on a Windows 2000 system, probably a Celeron.
That may happen this weekend, but most likely it will have to wait till the
next weekend.
--
Take Your Trading to the Next Level!
M. Edward Borasky, Meta-Trading Coach

znmeb at borasky-research.net
http://www.meta-trading-coach.com
http://groups.yahoo.com/group/meta-trading-coach

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From valdentro at yahoo.es  Fri Dec 21 11:01:33 2001
From: valdentro at yahoo.es (=?iso-8859-1?q?juan=20p=E9rez?=)
Date: Fri, 21 Dec 2001 11:01:33 +0100 (CET)
Subject: No subject
Message-ID: <20011221100133.32932.qmail@web12604.mail.yahoo.com>


Can anybody explain me why do not runs the up-arrow
access to the previous commands in the 1.3.0 version
of R?
Before installing it, I work with the version included
in Suse 7.0 and there, there was no problem!

Thank?s

JUAN PABLO from Spain

_______________________________________________________________

Yahoo! Messenger
Comunicaci?n instant?nea gratis con tu gente.
http://messenger.yahoo.es
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Dec 21 11:18:36 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 21 Dec 2001 11:18:36 +0100
Subject: [R] Re: none
In-Reply-To: <20011221100133.32932.qmail@web12604.mail.yahoo.com>
References: <20011221100133.32932.qmail@web12604.mail.yahoo.com>
Message-ID: <x2wuzg98qr.fsf@blueberry.kubism.ku.dk>

juan p?rez <valdentro at yahoo.es> writes:

> Can anybody explain me why do not runs the up-arrow
> access to the previous commands in the 1.3.0 version
> of R?
> Before installing it, I work with the version included
> in Suse 7.0 and there, there was no problem!

Self-compiled? I bet you forgot to install the readline-devel package
(or whatever SuSE calls it). 

BTW:

a) Current version is 1.4.0
b) RPM's for SuSE are available on CRAN (those for 1.4.0 not quite
   there yet).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From segramm.pg.lecce at giustizia.it  Fri Dec 21 13:55:26 2001
From: segramm.pg.lecce at giustizia.it (MUGGEO VITO)
Date: Fri, 21 Dec 2001 13:55:26 +0100
Subject: [R] pure statistical question
Message-ID: <008b01c18a1e$c6f3c140$5c13070a@it.giustizia.it>

Dear all,
This is a pure statistical question, not necessarly related to R.
I could not find it in literature.

Suppose I'm intersted in a parameter rho, say, equal to:
r=beta1/beta2,
where beta1 and beta2 come from a linear model y=beta0+beta1X1+beta2X2+....
Fitting the model I can get the (biased) estimate of r=b1/b2, where b1 and
b2 are the estimates in the regression model; I can get the unbiased
estimate of rho as well as its SE using the delta method.
I'm interested in confidence interval for r.
A simple method could be (I suppose) the classical one, i.e. using the
standard gaussian quantiles: r +/- 1.96*SE.
However because the ratio of two independent normal distribution is a Chaucy
distribution I was thinking about an "exact methods". But the Chaucy
distribution has not mean!!!
My question is
1)If b1 and b2 are independent (X1 and X2 orthogonal) which is the sense of
r and SE if the Chaucy distribution has not moments?
2) b1 and b2 are normal but not independent, their exact distribution is
even Chaucy?
3)After all, is it correct use gaussian quantiles: r +/- 1.96*SE (as n goes
inf, of course)

hope to have been clear, hope in some your advice
best
vito
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From indra_calisto at yahoo.com  Fri Dec 21 14:09:16 2001
From: indra_calisto at yahoo.com (Indrajit SenGupta)
Date: Fri, 21 Dec 2001 18:39:16 +0530
Subject: [R]Installing Packages
Message-ID: <MABBJPBLPNLDIFMIAAOJEEMICCAA.indra_calisto@yahoo.com>

My Mail StationeryDear R Users,
I am a novice R user and have recently joined the list. I am using R 1.3 in
Windows 98. In one of the FAQ's I read that to install the available
packages I need to have several tools could someone tell me what are those
and what do I have to do.
Thanks in advance,

______________________
Indrajit SenGupta
Department Of Statistics
St. Xavier's College
Calcutta University
indra_calisto at yahoo.com
indrajit_sg at rediffmail.com

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011221/f83bb280/attachment.html

From p.ribeiro at lancaster.ac.uk  Fri Dec 21 14:31:43 2001
From: p.ribeiro at lancaster.ac.uk (Paulo Justiniano Ribeiro Jr)
Date: Fri, 21 Dec 2001 13:31:43 +0000 (GMT)
Subject: [R]Installing Packages (fwd)
Message-ID: <Pine.GSO.4.21.0112211330520.23703-100000@unixb.lancs.ac.uk>

This depends whether you want to compile the packages yourself (here you
need the extra tools) or just
install the pre-compiled versions (here you don't need them).

I would guess that most of the Windows users just do the latter and the
installation is then straighforward by using the option "Packages" on the
top menu.
You can donload/install from CRAN or from a local zip file.

More details abou windows installation in a article by Brian Ripley in the 
RNEWS-2.

On Fri, 21 Dec 2001, Indrajit SenGupta wrote:

> My Mail StationeryDear R Users,
> I am a novice R user and have recently joined the list. I am using R 1.3 in
> Windows 98. In one of the FAQ's I read that to install the available
> packages I need to have several tools could someone tell me what are those
> and what do I have to do.
> Thanks in advance,
> 
> ______________________
> Indrajit SenGupta
> Department Of Statistics
> St. Xavier's College
> Calcutta University
> indra_calisto at yahoo.com
> indrajit_sg at rediffmail.com
> 
> 

Paulo Justiniano Ribeiro Jr
Dept Maths & Stats  -  Fylde College
Lancaster University
Lancaster LA1 4YF   -  U.K.

e-mail: Paulo.Ribeiro at est.ufpr.br
http://www.maths.lancs.ac.uk/~ribeiro



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From smalladi at lexgen.com  Fri Dec 21 16:55:39 2001
From: smalladi at lexgen.com (Sukhaswami Malladi)
Date: Fri, 21 Dec 2001 09:55:39 -0600
Subject: [R] shapiro-wilks test
Message-ID: <80A38867B1DBD511A8C9009027764C8C379596@lexchange.lexgen.com>

Hello,

I am a newbie to R. I would like to test my data for normality using the
Shapiro-Wilks
test. How do I go about it ?

My data is in form of a table with 2 columns - colA, colB and I want to know
if
colB values are a normal distribution.

First I read the data into R using 
d <- read.table("tab.dat",header=T)

Then if I type 
shapiro.test(d)

I get the error message: 

Error in "[.data.frame"(x, complete.cases(x)) : 
        undefined columns selected

and if I type 
shapiro.test(d.colB)

I get message:

Error in inherits(x, "factor") : Object "d.colB" not found

What is the correct syntax and how do I obtain this syntax from any help
documentation ?

Any suggestion is greatly appreciated.

Thanks

Sukhaswami Malladi



*************************************************************************** 
 The contents of this communication are intended only for the addressee and
may contain confidential and/or privileged material. If you are not the
intended recipient, please do not read, copy, use or disclose this
communication and notify the sender.  Opinions, conclusions and other
information in this communication that do not relate to the official
business of my company shall be understood as neither given nor endorsed by
it.  
*************************************************************************** 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From loesljrg at accucom.net  Fri Dec 21 16:56:34 2001
From: loesljrg at accucom.net (JRG)
Date: Fri, 21 Dec 2001 10:56:34 -0500
Subject: [R] pure statistical question
In-Reply-To: <008b01c18a1e$c6f3c140$5c13070a@it.giustizia.it>
Message-ID: <B0003616613@netserv1.accucom.net>

On 21 Dec 01, at 13:55, MUGGEO VITO wrote:

> Dear all,
> This is a pure statistical question, not necessarly related to R.
> I could not find it in literature.

<<<SNIP>>>

> However because the ratio of two independent normal distribution is a Chaucy
> distribution I was thinking about an "exact methods". But the Chaucy
> distribution has not mean!!!

Well, the ratio of two independent -standard- normals  --- i.e., 
N(0,1) variables --- is distributed as Cauchy.  But the heavy tails of 
the Cauchy arise from dividing by numbers close to 0.  So, if the 
denominator of your ratio is distributed as, say, N(100, 1), then the 
ratio isn't going to look much like a Cauchy.

---JRG



John R. Gleason

Syracuse University
430 Huntington Hall                      Voice:   315-443-3107
Syracuse, NY 13244-2340  USA             FAX:     315-443-4085

PGP public key at keyservers
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From MSchwartz at medanalytics.com  Fri Dec 21 21:11:05 2001
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 21 Dec 2001 14:11:05 -0600
Subject: [R] shapiro-wilks test
In-Reply-To: <80A38867B1DBD511A8C9009027764C8C379596@lexchange.lexgen.com>
Message-ID: <000401c18a5b$9f25dbc0$0201a8c0@Marc>

> My data is in form of a table with 2 columns - colA, colB and
> I want to know if colB values are a normal distribution.
>
> First I read the data into R using
> d <- read.table("tab.dat",header=T)
>
> Then if I type
> shapiro.test(d)
>
> I get the error message:
>
> Error in "[.data.frame"(x, complete.cases(x)) :
>         undefined columns selected
>
> and if I type
> shapiro.test(d.colB)
>
> I get message:
>
> Error in inherits(x, "factor") : Object "d.colB" not found
>
> What is the correct syntax and how do I obtain this syntax
> from any help
> documentation ?

I believe that the problem that you are having is that in the first example,
you are trying to have the test performed on a data frame (data in the form
of rows and columns) rather than a data vector (a single column of data),
which is what the function requires.

In the second example, you need a different syntax to refer specifically to
"colB" as a data vector within your frame.

If you use the format:

shapiro.test(d$colB)

it should work.

Note the use of the "$" to refer to the column within the frame.

You can type "help(shapiro.test)" to access the help for this particular
function.  You will note that the "x" argument in the function syntax is
defined as a numeric vector.

You can also access the general documentation via the Help menu or by typing
"help.start()". These options will provide you with access to the .PDF and
.HTML manuals and associated documentation to review some of the basic R
concepts and examples. You may wish to start with the "Introduction to R",
which covers the basics.

Regards,

Marc

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec 21 22:29:23 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 21 Dec 2001 21:29:23 +0000 (GMT)
Subject: [R] colSums in C
In-Reply-To: <15391.55801.340546.224022@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.31.0112212125100.10000-100000@gannet.stats>

I've put a first version of colSums etc in R-devel.  At present I have
concentrated on getting the details right (like handing NAs correctly,
handling integer and complex input ...) as well as full S+ compatibility.

I suspect that for speed one should be using BLAS routines, but so far
I've done no optimization.  Indeed, not even of the C code since in my
experience compilers are better at that than humans.

As I said, just a first pass!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rother at gfz-potsdam.de  Sat Dec 22 00:57:54 2001
From: rother at gfz-potsdam.de (Martin Rother)
Date: Sat, 22 Dec 2001 00:57:54 +0100
Subject: [R] {R} 1.4.0 compiling failed on sun sparc solaris 2.6
Message-ID: <20011221235754.GB13364@mt11>


          Hi!

      I tried to configure and compile R 1.4.0 on a
      sun sparc solaris 2.6 box using the sun compiler (workshop 6?);
      but:

-------------------------------------------------------------------------------------------------
(mt100): ./configure --x-includes=/usr/openwin/include --x-libraries=/usr/openwin/lib --with-f77

[...]

R is now configured for sparc-sun-solaris2.6

  Source directory:          .
  Installation directory:    /usr/local
  C compiler:                cc  -g
  C++ compiler:              CC  -g
  FORTRAN compiler:          f77  -g

  X11 support:               yes
  Gnome support:             no
  Tcl/Tk support:            yes

  R profiling support:       yes
  R as a shared library:     no

(mt100): gmake

[...]

gmake[4]: Leaving directory `/home/mt/rother/info/ftp/R/R-1.4.0/src/library/methods/src'
gmake[4]: Entering directory `/home/mt/rother/info/ftp/R/R-1.4.0/src/library/methods'
dumping R code in package `methods'
initializing class and method definitions now
Bus Error
gmake[4]: *** [../../../library/methods/R/all.rda] Error 138
gmake[4]: Leaving directory `/home/mt/rother/info/ftp/R/R-1.4.0/src/library/methods'
gmake[3]: *** [all] Error 2
gmake[3]: Leaving directory `/home/mt/rother/info/ftp/R/R-1.4.0/src/library/methods'
gmake[2]: *** [R] Error 1
gmake[2]: Leaving directory `/home/mt/rother/info/ftp/R/R-1.4.0/src/library'
gmake[1]: *** [R] Error 1
gmake[1]: Leaving directory `/home/mt/rother/info/ftp/R/R-1.4.0/src'
gmake: *** [R] Error 1

-------------------------------------------------------------------------------------------------

   explicit call in subdirectory:

-------------------------------------------------------------------------------------------------

(mt100): cd src/library/methods
/home/mt/rother/info/ftp/R/R-1.4.0/src/library/methods

(mt100): limit coredumpsize unlimited

(mt100): ../../../bin/R --vanilla --slave < all.R 
initializing class and method definitions now
Bus Error (core dumped)

(mt100): dbx ../../../bin/R.bin core

Reading R.bin
[...]

program terminated by signal BUS (invalid address alignment)
Current function is gzfile_open
  750       fp = gzopen(R_ExpandFileName(con->description), con->mode);
(dbx) where
  [1] deflateEnd(0xaf0e18, 0xef429758, 0x115f188, 0x11700e0, 0xef423138, 0xef3c5b3c), at 0xef6b4be0
  [2] destroy(0xaf0e18, 0x6, 0x8, 0xfffffff1, 0x8, 0x0), at 0xef6b2e48
  [3] gz_open(0xaf0e18, 0x1122734, 0xffffffff, 0x0, 0x0, 0x0), at 0xef6b25a8
  [4] gzopen(0xaf8138, 0x1122730, 0x6, 0x77, 0x81010100, 0x1122730), at 0xef6b3ba0
=>[5] gzfile_open(con = 0x1122728), line 750 in "connections.c"
  [6] do_gzfile(call = 0x46eb54, op = 0x329d1c, args = 0xb3d650, env = 0xb3d554), line 886 in "connections.c"
  [7] do_internal(call = 0x46eac8, op = 0x31b07c, args = 0xb3d650, env = 0xb3d554), line 1011 in "names.c"
  [8] Rf_eval(e = 0x46eac8, rho = 0xb3d554), line 400 in "eval.c"
  [9] Rf_applyClosure(call = 0x777da4, op = 0x46e9e8, arglist = 0xb3ddd4, rho = 0xb47598, suppliedenv = 0x30a888), line 591 in "eval.c"
  [10] Rf_eval(e = 0x777da4, rho = 0xb47598), line 435 in "eval.c"
  [11] do_set(call = 0x777d50, op = 0x31b5d8, args = 0x777d6c, rho = 0xb47598), line 1097 in "eval.c"
  [12] Rf_eval(e = 0x777d50, rho = 0xb47598), line 400 in "eval.c"
  [13] do_if(call = 0x777bac, op = 0x30a2d8, args = 0x777bc8, rho = 0xb47598), line 690 in "eval.c"
  [14] Rf_eval(e = 0x777bac, rho = 0xb47598), line 400 in "eval.c"
  [15] do_begin(call = 0x777f80, op = 0x31b514, args = 0x777b90, rho = 0xb47598), line 887 in "eval.c"
  [16] Rf_eval(e = 0x777f80, rho = 0xb47598), line 400 in "eval.c"
  [17] do_if(call = 0x778758, op = 0x30a2d8, args = 0x778774, rho = 0xb47598), line 690 in "eval.c"
  [18] Rf_eval(e = 0x778758, rho = 0xb47598), line 400 in "eval.c"
  [19] do_begin(call = 0x77873c, op = 0x31b514, args = 0x778720, rho = 0xb47598), line 887 in "eval.c"
  [20] Rf_eval(e = 0x77873c, rho = 0xb47598), line 400 in "eval.c"
  [21] do_if(call = 0x7783a0, op = 0x30a2d8, args = 0x7783bc, rho = 0xb47598), line 692 in "eval.c"
  [22] Rf_eval(e = 0x7783a0, rho = 0xb47598), line 400 in "eval.c"
  [23] do_begin(call = 0x77778c, op = 0x31b514, args = 0x778384, rho = 0xb47598), line 887 in "eval.c"
  [24] Rf_eval(e = 0x77778c, rho = 0xb47598), line 400 in "eval.c"
  [25] Rf_applyClosure(call = 0x77a610, op = 0x7782a4, arglist = 0xb48564, rho = 0xb54188, suppliedenv = 0x30a888), line 591 in "eval.c"
  [26] Rf_eval(e = 0x77a610, rho = 0xb54188), line 435 in "eval.c"
  [27] do_begin(call = 0x778e88, op = 0x31b514, args = 0x77a5f4, rho = 0xb54188), line 887 in "eval.c"
  [28] Rf_eval(e = 0x778e88, rho = 0xb54188), line 400 in "eval.c"
  [29] Rf_applyClosure(call = 0xb54b04, op = 0x77afe0, arglist = 0xb53cf0, rho = 0x32a4bc, suppliedenv = 0x30a888), line 591 in "eval.c"
  [30] Rf_eval(e = 0xb54b04, rho = 0x32a4bc), line 435 in "eval.c"
  [31] R_ReplConsole(rho = 0x32a4bc, savestack = 0, browselevel = 0), line 187 in "main.c"
  [32] run_Rmainloop(), line 499 in "main.c"
  [33] Rf_mainloop(), line 506 in "main.c"
  [34] main(ac = 3, av = 0xeffff51c), line 90 in "system.c"
(dbx) 
-------------------------------------------------------------------------------------------------

       same settings (in config.site) 
       configures and compiles without problems for
       a sun sparc solaris 2.7 box. odd.
       but I need the solaris 2.6 version...

       if I tried something stupid,
       any hint is welcome!

       best regards.
       martin rother.
-- 
Martin Rother (rother at gfz-potsdam.de)   0331/ 288-1272           Division 2.3
                                        GeoForschungsZentrum Potsdam, Germany
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From psolomon at maths.adelaide.edu.au  Sat Dec 22 06:17:57 2001
From: psolomon at maths.adelaide.edu.au (Patty Solomon)
Date: Sat, 22 Dec 2001 15:47:57 +1030
Subject: [R] gam plots
Message-ID: <p05101005b849c078053c@[10.0.1.11]>

Dear R users,

Using the library(mgcv) and running R under MacOSX, I have fitted a 
generalised additive model with binomial errors in order to check the 
linearity of two continuous variables ap2mm and diffdaysm in a glm:


>  mymodel.gam <- gam(diedhos~ s(ap2mm) + Dweekm + s(diffdaysm) +
  Dweekm:diffdaysm + ap2mm:Dweekm, binomial)

I would like postscript gam plots for the two smoothed terms to be 
produced on separate pages, but am having trouble getting these.  I 
can get the two plots output to a single page using

>  postscript("gams.ps")
>  plot(mymodel.gam, pages=1, se=T)
>  dev.off()

I don't want this, but when I try replacing pages=1 with pages=2, I 
still get only one page in the postscript file with the second plot 
overlaid on the first one:

>  plot(mymodel.gam, pages=2, se=T)
Press return for next page....


	I wondered if anyone knows of a way to get each plot on a 
separate page, i.e. two postscript files?

I also noticed that the plot gives tick marks for the values of the 
variable along the horizontal axis, but I would like a rug of *all* 
the values (Splus5 produces a rug using jittering to show the density 
of the observations, but the version of R that I have doesn't do 
this, as far as I can tell).

I would be very grateful if anyone has any suggestions that would 
help sort this out.

Many thanks,
Patty
-- 
--------------------------------------------------------------------------------

Assoc Prof Patty Solomon                            phone:  (08) 8303 3033
Department of Applied Mathematics and               fax:    (08) 8303 3696
Centre for the Molecular Genetics of Development
Adelaide University
Adelaide SA 5005
AUSTRALIA.

email: patty.solomon at adelaide.edu.au
http://www.maths.adelaide.edu.au/people/psolomon
--------------------------------------------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jago at mclink.it  Sat Dec 22 11:03:04 2001
From: jago at mclink.it (Stefano Iacus)
Date: Sat, 22 Dec 2001 11:03:04 +0100 (CET)
Subject: [R] Re: R-1.4.0 for MacOS X 
Message-ID: <1.0.2.200112221102.5864@mclink.it>


Hy Jan,

I'll put a copy on cran today. Thanks.

stefano

> 
> Get it from ftp://gifi.stat.ucla.edu in pub.
> 
> This contains the base files plus the recommended packages (except 
> rpart,
> which does not compile yet).
> 
> It is compiled under MacOS X 10.1.2 with the December 2001 version 
> of
> the Developer Tools, and with g77 from fink.sourceforge net. 
> It has
> support
> for gnome, X11R6, and tcl/tk, and it uses the newest ATLAS from 
> fink. It
> has two-level namespaces and has a libR.dylib included.
> 
> For R,bin you need on your system (remember to set DYLD_LIBRARY_PATH,
> or --better-- install fink and compile these things yourself)
> 
>         /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, 
> current
> version 55.0.0)
>          /sw/lib/libz.1.dylib (compatibility version 1.1.3, current
> version 1.1.3)
>          /sw/lib/libreadline.4.dylib (compatibility version 4.2.0,
> current version 4.2.0)
>          /sw/lib/libdl.dylib (compatibility version 0.0.0, current
> version 0.0.0)
>          /sw/lib/libncurses.dylib.5 (compatibility version 5.0.0, 
> current
> version 5.2.0)
> 
> and for the two main modules
> 
> R_X11.so:
>          /usr/X11R6/lib/libSM.6.dylib (compatibility version 
> 6.0.0,
> current version 6.0.0)
>          /usr/X11R6/lib/libICE.6.dylib (compatibility version 
> 6.3.0,
> current version 6.3.0)
>          /usr/X11R6/lib/libX11.6.dylib (compatibility version 
> 6.2.0,
> current version 6.2.0)
>          /sw/lib/libjpeg.62.dylib (compatibility version 63.0.0, 
> current
> version 63.0.0)
>          /sw/lib/libpng.2.dylib (compatibility version 1.0.12, 
> current
> version 1.0.12)
>          /sw/lib/libz.1.dylib (compatibility version 1.1.3, current
> version 1.1.3)
>          libR.dylib (compatibility version 0.0.0, current version 
> 0.0.0)
>          /sw/lib/libreadline.4.dylib (compatibility version 4.2.0,
> current version 4.2.0)
>          /sw/lib/libdl.dylib (compatibility version 0.0.0, current
> version 0.0.0)
>          /sw/lib/libncurses.dylib.5 (compatibility version 5.0.0, 
> current
> version 5.2.0)
>          /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, 
> current
> version 55.0.0)
> R_gnome.so:
>          /sw/lib/libgnomeui.32.dylib (compatibility version 47.0.0,
> current version 47.1.0)
>          /sw/lib/libart_lgpl.2.dylib (compatibility version 5.0.0,
> current version 5.0.0)
>          /sw/lib/libgdk_imlib.1.dylib (compatibility version 
> 11.0.0,
> current version 11.10.0)
>          /usr/X11R6/lib/libSM.6.dylib (compatibility version 
> 6.0.0,
> current version 6.0.0)
>          /usr/X11R6/lib/libICE.6.dylib (compatibility version 
> 6.3.0,
> current version 6.3.0)
>          /sw/lib/libgtk-1.2.0.dylib (compatibility version 10.0.0,
> current version 10.1.0)
>          /sw/lib/libgdk-1.2.0.dylib (compatibility version 10.0.0,
> current version 10.1.0)
>          /sw/lib/libgmodule-1.2.0.dylib (compatibility version 
> 1.0.0,
> current version 1.10.0)
>          /sw/lib/libdl.dylib (compatibility version 0.0.0, current
> version 0.0.0)
>          /sw/lib/libintl.1.dylib (compatibility version 2.0.0, 
> current
> version 2.1.0)
>          /usr/X11R6/lib/libXext.6.dylib (compatibility version 
> 6.4.0,
> current version 6.4.0)
>          /usr/X11R6/lib/libX11.6.dylib (compatibility version 
> 6.2.0,
> current version 6.2.0)
>          /sw/lib/libgnome.32.dylib (compatibility version 37.0.0, 
> current
> version 37.3.0)
>          /sw/lib/libgnomesupport.0.dylib (compatibility version 
> 1.0.0,
> current version 1.0.0)
>          /sw/lib/libesd.0.dylib (compatibility version 3.0.0, 
> current
> version 3.22.0)
>          /sw/lib/libaudiofile.0.dylib (compatibility version 
> 1.0.0,
> current version 1.1.0)
>          /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, 
> current
> version 55.0.0)
>          /sw/lib/libglib-1.2.0.dylib (compatibility version 1.0.0,
> current version 1.10.0)
>          /sw/lib/libglade-gnome.0.dylib (compatibility version 
> 5.0.0,
> current version 5.2.0)
>          /sw/lib/libglade.0.dylib (compatibility version 5.0.0, 
> current
> version 5.2.0)
>          /sw/lib/libxml.1.dylib (compatibility version 10.0.0, 
> current
> version 10.16.0)
>          /sw/lib/libz.1.dylib (compatibility version 1.1.3, current
> version 1.1.3)
>          libR.dylib (compatibility version 0.0.0, current version 
> 0.0.0)
>          /sw/lib/libreadline.4.dylib (compatibility version 4.2.0,
> current version 4.2.0)
>          /sw/lib/libncurses.dylib.5 (compatibility version 5.0.0, 
> current
> version 5.2.0)
> 
> tcl/tk support uses
> 
>         /sw/lib/libtcl8.3.dylib (compatibility version 8.0.0, 
> current
> version 8.3.0)
>          /sw/lib/libtk8.3.dylib (compatibility version 8.0.0, 
> current
> version 8.3.0)
> 
> Everything in /usr/X11R6 comes from Xfree86 (Xtools would also 
> be OK),
> everything
> in /sw/lib comes from fink.
> 
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
> homepage: http://www.stat.ucla.edu/~deleeuw
> ========================================================
>            No matter where you go, there you are. --- Buckaroo 
> Banzai
>                     http://www.stat.ucla.edu/~deleeuw/sounds/nomatter.au
> ========================================================
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-announce mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From indra_calisto at yahoo.com  Sat Dec 22 14:09:07 2001
From: indra_calisto at yahoo.com (Indrajit SenGupta)
Date: Sat, 22 Dec 2001 18:39:07 +0530
Subject: [R] A small question
Message-ID: <MABBJPBLPNLDIFMIAAOJGEMOCCAA.indra_calisto@yahoo.com>

My Mail StationeryDear R- users,
I have a small question on R. The other day I was using R when I decided to
quit and when I was prompted with the question whether I would like to save
the workspace image, I accidently pressed yes and after that every time
start R the previous work space gets loaded. How do I avoid this?
Thanks in advance,

______________________
Indrajit SenGupta
Department Of Statistics
St. Xavier's College
Calcutta University
indra_calisto at yahoo.com
indrajit_sg at rediffmail.com

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011222/c161da68/attachment.html

From zeileis at ci.tuwien.ac.at  Sat Dec 22 14:41:39 2001
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Sat, 22 Dec 2001 14:41:39 +0100
Subject: [R] A small question
Message-ID: <3C248D93.941ADA0B@ci.tuwien.ac.at>

> Dear R- users,
> I have a small question on R. The other day I was using R when I decided to quit > and when I was prompted with the
> question whether I would like to save the workspace image, I accidently pressed > yes and after that every time start
> R the previous work space gets loaded. How do I avoid this?

Just delete the .RData and .Rhistory file in that directory (if you
don't need them anymore).
Z
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Sat Dec 22 15:00:37 2001
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sat, 22 Dec 2001 09:00:37 -0500
Subject: [R] A small question
In-Reply-To: <3C248D93.941ADA0B@ci.tuwien.ac.at>
References: <3C248D93.941ADA0B@ci.tuwien.ac.at>
Message-ID: <20011222090037.76989f30.fharrell@virginia.edu>

Please pardon my grumpiness but questions of this type make me wonder why r-help uses an E-mail list rather than an interactive chat room.  There seems to be no memory of questions and answers which were covered in detail even as recently as two weeks ago.  Perhaps some way should be found to force the visability of the e-mail archive onto new users.  

Frank
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bved01 at hia.net  Sat Dec 22 15:17:53 2001
From: bved01 at hia.net (Bill Vedder)
Date: Sat, 22 Dec 2001 08:17:53 -0600
Subject: [R] Saving Newly Created Functions
Message-ID: <3C249611.73CE0C2E@hia.net>

Greetings R-Listers,

Using R1.2.1 (yes, I know...)

I am writing my own functions and would like to know how save these for
use in subsequent R sessions.  How does one do this?

Best,
Bill Vedder

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Sat Dec 22 15:07:49 2001
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Sat, 22 Dec 2001 14:07:49 +0000
Subject: [R] shapiro-wilks test
In-Reply-To: <80A38867B1DBD511A8C9009027764C8C379596@lexchange.lexgen.com>
References: <80A38867B1DBD511A8C9009027764C8C379596@lexchange.lexgen.com>
Message-ID: <kFRxJCA1OJJ8EwUC@myatt.demon.co.uk>

Sukhaswami Malladi <smalladi at lexgen.com> writes:
>Hello,
>
>I am a newbie to R. I would like to test my data for normality using the
>Shapiro-Wilks
>test. How do I go about it ?
>
>My data is in form of a table with 2 columns - colA, colB and I want to know
>if
>colB values are a normal distribution.
>
>First I read the data into R using 
>d <- read.table("tab.dat",header=T)
>
>Then if I type 
>shapiro.test(d)
>
>I get the error message: 
>
>Error in "[.data.frame"(x, complete.cases(x)) : 
>        undefined columns selected
>
>and if I type 
>shapiro.test(d.colB)
>
>I get message:

I think you mean:

        shapiro.test(d$colB)

Mark

--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From snw at mcs.st-and.ac.uk  Sat Dec 22 16:29:28 2001
From: snw at mcs.st-and.ac.uk (Simon Wood)
Date: Sat, 22 Dec 2001 15:29:28 +0000 (GMT)
Subject: [R] gam plots
In-Reply-To: <p05101005b849c078053c@[10.0.1.11]>
Message-ID: <Pine.GSO.4.21.0112221511570.9151-100000@dolphin>

> I would like postscript gam plots for the two smoothed terms to be 
> produced on separate pages, but am having trouble getting these.  I 
> can get the two plots output to a single page using
> 
> >  postscript("gams.ps")
> >  plot(mymodel.gam, pages=1, se=T)
> >  dev.off()
> 
> I don't want this, but when I try replacing pages=1 with pages=2, I 
> still get only one page in the postscript file with the second plot 
> overlaid on the first one:
> 
> >  plot(mymodel.gam, pages=2, se=T)
> Press return for next page....
> 
.... I can't get this to happen, but i don't have access to a mac at the
moment [I tried it using R 1.4.0 / mgcv 0.6.* under unix]. I wonder if the
problem is Mac specific?

> I also noticed that the plot gives tick marks for the values of the 
> variable along the horizontal axis, but I would like a rug of *all* 
> the values (Splus5 produces a rug using jittering to show the density 
> of the observations, but the version of R that I have doesn't do 
> this, as far as I can tell).

- sorry, jittering's not implemented, but it should be easy to get a
jittered plot. Your model object will contain all the raw data in
mymodel.gam$x (in addition to any dummy variables implied by the model
formula). You can jitter these yourself before calling plot.gam(). e.g. to
jitter the second covariate:

mymodel.gam$x[2,]<-jitter(mymodel.gam$x[2,])

[although you probably want to control the amount of jittering using the
`amount' argument]. I'll add adding a jitter option to the mgcv "to
do" list. 

Simon

  ______________________________________________________________________
> Simon Wood  snw at st-and.ac.uk  http://www.ruwpa.st-and.ac.uk/simon.html
> The Mathematical Institute, North Haugh, St. Andrews, Fife KY16 9SS UK
> Direct telephone: (0)1334 463799          Indirect fax: (0)1334 463748 




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From umusus at net.nagasaki-u.ac.jp  Sat Dec 22 18:38:22 2001
From: umusus at net.nagasaki-u.ac.jp (Susumu =?ISO-2022-JP?B?VEFOSU1VUkEvGyRCQytCPBsoQiAbJEI/OBsoQg==?=)
Date: Sun, 23 Dec 2001 02:38:22 +0900
Subject: [R] Cannot rebuild srpm
Message-ID: <20011223023822.364670cd.umusus@net.nagasaki-u.ac.jp>

Dear R-users,

When rebuilding R-base-1.4.0-1.src.rpm, it stopped and give message as follow:
(Some words is Japanese)

>>> Building/Updating help pages for package `base'
     Formats: text example 
make[5]: ??? ?????? `/home/umusus/rpm/BUILD/R-1.4.0/src/library'
running code in `base-Ex.R' ...make[4]: *** [base-Ex.Rout] ??? 1
make[4]: ??? ?????? `/home/umusus/rpm/BUILD/R-1.4.0/tests/Examples'
make[3]: *** [test-Examples] ??? 2
make[3]: ??? ?????? `/home/umusus/rpm/BUILD/R-1.4.0/tests/Examples'
make[2]: *** [test-Examples] ??? 2
make[2]: ??? ?????? `/home/umusus/rpm/BUILD/R-1.4.0/tests'
make[1]: *** [test-all-basics] ??? 1
make[1]: ??? ?????? `/home/umusus/rpm/BUILD/R-1.4.0/tests'
make: *** [check] ??? 2
???: Bad exit status from /var/tmp/rpm-tmp.95916 (%build)

I tried in RedHat7.2(ja) and VineLinux2.1.5, which is developed from
RedHat6.2.  In both of them, the same message was given.

Does anyone know how to solve this?


 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chrysopa at insecta.ufv.br  Sat Dec 22 19:06:58 2001
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Sat, 22 Dec 2001 16:06:58 -0200
Subject: [R] new.packages function for new packages
Message-ID: <20011222180659.97B1279F@localhost.localdomain>

Hi all,

I use a function update.packages to update all packages in my R instalation.

But I need compare one by one packages to discovery new packages. 

My question is: Exist in R any function that compare all installed packages 
in my R and all packages available in CRAN and return a list of the new 
packages (ie packages that I dont have im my installation) and automatic 
download and install this packages?

Thanks

Ronaldo
-- 
Success is a journey, not a destination.
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][SO: CL 7.0 (2.2.19)]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Conectiva Linux 7.0 D+:) | Lxuser#: 205366
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Dec 22 19:27:48 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 Dec 2001 18:27:48 +0000 (GMT)
Subject: [R] new.packages function for new packages
In-Reply-To: <20011222180659.97B1279F@localhost.localdomain>
Message-ID: <Pine.LNX.4.31.0112221820020.17103-100000@gannet.stats>

On Sat, 22 Dec 2001, Ronaldo Reis Jr. wrote:

> Hi all,
>
> I use a function update.packages to update all packages in my R instalation.
>
> But I need compare one by one packages to discovery new packages.
>
> My question is: Exist in R any function that compare all installed packages
> in my R and all packages available in CRAN and return a list of the new
> packages (ie packages that I dont have im my installation) and automatic
> download and install this packages?

packageStatus()

For example:

> summary(packageStatus())
...
Available packages:
-------------------
(each package appears only once)

*** Repository http://cran.r-project.org/src/contrib
$installed
  [1] "AnalyzeFMRI"    "CoCoAn"         "Devore5"        "EMV"
...

$"not installed"
[1] "RMySQL"  "ROracle" "RSQLite" "RmSQL"   "XML"     "netCDF"  "rpvm"


It's not totally automatic, not least because you will be unable to
install some packages automatically unless you have lots of addons in
(what the package authors thought were) standard places (e.g. all the
supported databases installed, lapack, libxml in a version that XML
actually works with, ...).

BTW, packageStatus is new in 1.4.0, and still under development so
sparsely documented.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From MSchwartz at medanalytics.com  Sat Dec 22 19:39:42 2001
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sat, 22 Dec 2001 12:39:42 -0600
Subject: [R] A small question
In-Reply-To: <20011222090037.76989f30.fharrell@virginia.edu>
Message-ID: <002001c18b18$060129a0$0201a8c0@Marc>

> -----Original Message-----
> From: owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch]On Behalf Of Frank E Harrell Jr
> Subject: Re: [R] A small question
>
> Please pardon my grumpiness but questions of this type make
> me wonder why r-help uses an E-mail list rather than an
> interactive chat room.  There seems to be no memory of
> questions and answers which were covered in detail even as
> recently as two weeks ago..  Perhaps some way should be found
> to force the visability of the e-mail archive onto new users.
>
> Frank

Dr. Harrell,

If I may, respectfully as a new user, I do not find your query unreasonable.

Speaking for myself, I start out with the assumption that someone else
already asked the same question and that the answer is likely to be found.
That assumption is generally validated by using the various offline and
online resources available. In most cases, the answers to my queries can be
found if I I take the time to find it by searching and reading.  Perhaps it
is also the well documented male genetic trait in me that resists asking for
help <vbg>.

I typically do this, because even though there are many folks who have
graciously offered their time to respond to such queries, such as those on
this list, I both want to be sensitive to their time and I prefer to find
the answer on my own or at least attempt to do so, because as I do, I
usually find other useful information during the search.

I do want to also compliment the core group and the contributors for the
documentation that is provided as it has been extremely helpful.

Perhaps two suggestions to help at least raise awareness, since I am a firm
believer in "incrementalism", before the consideration of more complex
approaches:

1. To the footer on the R-Help e-mail, perhaps URL links to both the R-Help
archive page and the search page would at least make the online resources
better known for some and more easily accessible to folks. If embedded in
appropriate reminder text to suggest that a user review/search the archive
before posting, this may be helpful.

2. To the Help menu in R, the addition of these two links would help to
further raise the awareness of these resources.  This is based upon the
presumption that the first place most folks will go for assistance is the
built-in help system.

In both cases, if folks see these links, they will hopefully be tempted to
review or search the archive for past similar posts, rather than generate a
new one.

Regards,

Marc

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jdamon at noos.fr  Sat Dec 22 20:14:52 2001
From: jdamon at noos.fr (julien Damon)
Date: Sat, 22 Dec 2001 20:14:52 +0100
Subject: [R] Re: test
References: <SAK.2001.12.22.hmaktena@damonj>
Message-ID: <3C24DBAC.6010301@noos.fr>

Julien Damon wrote:

>test
>



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikalzet at libero.it  Sat Dec 22 20:40:41 2001
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Sat, 22 Dec 2001 20:40:41 +0100 (CET)
Subject: [R] Cannot rebuild srpm
In-Reply-To: <20011223023822.364670cd.umusus@net.nagasaki-u.ac.jp>
Message-ID: <Pine.LNX.4.33L2.0112222035430.2765-100000@localhost.localdomain>

On Sun, 23 Dec 2001, Susumu [ISO-2022-JP]
TANIMURA/$BC+B<(B $B?8(B wrote:

> When rebuilding R-base-1.4.0-1.src.rpm, it stopped and give message as follow:
> make: *** [check] $B%(%i!<(B 2
> $B%(%i!<(B: Bad exit status from /var/tmp/rpm-tmp.95916 (%build)

I'm not sure what the error message is, it's totally illegible.
It seems not to be passing make check ?
I had that problem from the very first time I tried to compile the srpm's
on mandrake systems which have a default -ffast-math optimization. The
solution in my case is compiling with the -fno-fast-math flag. So if the
binary is built but doesn't pass make check try looking at your opt flags.

-- 
Michele Alzetta

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Sun Dec 23 00:56:00 2001
From: rossini at blindglobe.net (A.J. Rossini)
Date: 22 Dec 2001 15:56:00 -0800
Subject: [R] Jobs at the University of Auckland
In-Reply-To: <3C224B6B.C34A0A3F@stat.auckland.ac.nz>
References: <3C224B6B.C34A0A3F@stat.auckland.ac.nz>
Message-ID: <874rmibyi7.fsf@jeeves.blindglobe.net>

>>>>> "RI" == Ross Ihaka <ihaka at stat.auckland.ac.nz> writes:

    RI> We have two lectureship positions advertised at the moment.
    RI> One (or both) of these is intended for a specialist in
    RI> statistical computation.  The salary doesn't look great by
    RI> international standards but there are compensations: housing
    RI> is cheap, the air is clean, and the worlds problems are far
    RI> away.  We also have a track record of getting tenure for
    RI> computing people.

    RI> 	http://www.stat.auckland.ac.nz/vacancies.shtml

    RI> (We can also possibly wrangle a senior position for special
    RI> candidates ;-)

Ross -

What would be the chance that I could get a position there?
(i.e. would it be worth my again investigating positions for my wife,
which would be the first step before actually sending in an
application?)

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   T-Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
Rosen: (Mullins' Lab) Fridays, and I'm unreachable except by email.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From xiejun at powertong.com.cn  Sun Dec 23 07:29:27 2001
From: xiejun at powertong.com.cn (Xie Jun)
Date: Sun, 23 Dec 2001 14:29:27 +0800
Subject: [R] How to Change output language?
Message-ID: <NBEKKJFLKKBIOPJIADKFOEOLCEAA.xiejun@powertong.com.cn>

In Windows programing, output string may be compiled as resource so we can let a program support multi-language application. How R can support this?

Julian
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011223/d8e02e9c/attachment.html

From ripley at stats.ox.ac.uk  Sun Dec 23 08:25:19 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Dec 2001 07:25:19 +0000 (GMT)
Subject: [R] How to Change output language?
In-Reply-To: <NBEKKJFLKKBIOPJIADKFOEOLCEAA.xiejun@powertong.com.cn>
Message-ID: <Pine.LNX.4.31.0112230721030.22992-100000@gannet.stats>

On Sun, 23 Dec 2001, Xie Jun wrote:

> In Windows programing, output string may be compiled as resource so we can let a program support multi-language application. How R can support this?

No, but that's only true of GUI elements. What use would it be to have the
menus in some other language when R itself (and all the help) is in
English?

However, R is a collaborative project, so feel free to program this and
contribute as much of multi-language support as you feel helpful.  You
would probably need to add support for wide characters too.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Dec 23 10:08:00 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Dec 2001 09:08:00 +0000 (GMT)
Subject: [R] write.table very slow
In-Reply-To: <Pine.LNX.4.33.0112060824450.10059-100000@ecopc64.eco.au.dk>
Message-ID: <Pine.LNX.4.31.0112230835330.23093-100000@gannet.stats>

[Sorry for the belated reply: we've been busy getting 1.4.0 out.]

On Thu, 6 Dec 2001, Ott Toomet wrote:

> Hi,
>
> I think the problem lies in the code of write.table().  It is essentially a
> paste() function, which pastes all the data in the table into a long
> character string and thereafter writes the string into file.  I was not able
> to write a dataset of 7500 obs times 1200 variables at all, I had to split
> it up into smaller units and write those separately.  In addition caused it
> much swapping on my 128MB system.

R has profiling, and if you run profiling you will see this is just not
true.  I ran tests of 600 columns.  1/3 of the time was spent adding
quotes, and 1/2 of the time on finding the NAs!

I do wonder if write.table is the appropriate tool.  It is designed for
data frames, and each of those 6000 columns could in principle be a
different class of R object.  So almost inevitably it is going to be slow
even for 1 row.  If what you really have is a matrix, write.matrix in
package MASS is about 10x faster.  (It also uses format and so makes a
better job of the output for numeric matrices.)

As for 7500 x 1200, that would benefit by being written in blocks of rows.
However, unfortunately that's not in general possible for a data frame, as
the conversion to a character matrix (in one of as.matrix, quoting or
paste) may well depend on all the rows.  (Think about the equivalent of
printing to `digits' significant places.)  And one has no control over
as.character methods for all possible constituents of data frames.

In any case, as the dataset is about 70Mb, you are inevitably going to
have problems in R on a 128Mb system, and writing a data file that size
will be slow on many file systems. I failed on a 512Mb system too.  But
writing 750 rows at a time was quite feasible (20 secs with write.matrix,
125 secs with write.table, on a 1GHz machine).  Just conversion to
character took 200 secs and 350Mb for the whole matrix.

It would be worth producing a blocked version of write.matrix, but it
seems not possible to do much about write.table without reducing its
generality, which is needed for some smaller problems.

> I think (I have not tried) it could work faster in your case if you just
> save the observatons separately into separate files and thereafter merge the
> files (but it is worth of doing only if you have to write the table
> repeatedly, of course).  In long run I think a rewrite of the write.table()
> in C in such a way that it do not store the whole file in memory may be a
> solution.

(Not in principle feasible.)

> Regards,
>
> Ott Toomet
> -------------------------------
> On Wed, 5 Dec 2001, Cole Harris wrote:
>
> > When writing tables with a large number of columns, write.table() seems to take way too much time - e.g. a table with ~80 rows and ~6000 columns takes ~30 min cpu on my 900 MHz pc.
> > I would appreciate any explainations or advice.
> >
> > Thanks,
> > Cole

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Sun Dec 23 18:26:28 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sun, 23 Dec 2001 12:26:28 -0500 (EST)
Subject: [R] aov for mixed model (fixed and random)?
Message-ID: <200112231726.fBNHQSn13814@cattell.psych.upenn.edu>

I'm starting to understand fixed and random effects, but I'm
puzzled a bit.  Here is an example from Hays's textbook (which is
great at explaining fixed vs. random effects, at least to dummies
like me), from the section on mixed models.  You need
library(nlme) in order to run it.
------
task <- gl(3,2,36) # Three tasks, a fixed effect.
subj <- gl(6,6,36) # Six subjects, a random effect.

h1 <- c(7.8,8.7,  11.1,12.0, 11.7,10.0, # Each S does each task twice.
        8.0,9.2,  11.3,10.6, 9.8,11.9,
        4.0,6.9,   9.8,10.1, 11.7,12.6,
        10.3,9.4, 11.4,10.5, 7.9,8.1,
        9.3,10.6, 13.0,11.7, 8.3,7.9,
        9.5,9.8,  12.2,12.3, 8.6,10.5)

aov1 <- aov(h1~task*subj)
anova(aov1) # See note below.

lme1 <- lme(h1~task,random=~1|subj)
lme2 <- lme(h1~task,random=~1|subj/task)
anova(lme1,lme2) # for interaction
anova(lme2) # for effect of task
-------

The anova gives very close to the correct F values for subj
(1.68, according to Hays) and for the interaction (7.19), but the
wrong F values for task, because it treats task as a random
effect, using the wrong error term.  Specifically, it gives
F=27.27, instead of 3.78 (Hays's figure).  This is because it
uses the within-cell error as the denominator for F instead of
the interaction term.  (The interaction ms is 5.82.)

The lme results give approximately the same results as Hays, but
they are different, presumably because of using a different
method (REML).  (I still don't understand why I can't just say
anova(lme2) and get everything all at once, but that's another
matter, and at least I've finally gotten this far.)

Now my question: Can I reproduce the results in Hays exactly?
Presumably this will involve instructing aov to use the
interaction as the error term for the denominator of F.  I've
tried everything I can think of.  If you can answer this, it
might go a long way toward helping me understand the (still
somewhat mysterious) "Error()" component of aov, if that turns
out to be part of the answer.

Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Dec 23 18:26:49 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Dec 2001 17:26:49 +0000 (GMT)
Subject: [R] XDR support
Message-ID: <Pine.LNX.4.31.0112231721030.26469-100000@gannet.stats>

We are considering make XDR support obligatory for 1.5.x.  Does anyone
have a system which builds without XDR support?   That is the configure
lines

checking for library containing xdr_string... (cached) none required

fails to find it, and config.h has

/* Define if you have the XDR headers and library routines. */
#define HAVE_XDR 1

undefined.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bved01 at hia.net  Sun Dec 23 20:40:30 2001
From: bved01 at hia.net (Bill Vedder)
Date: Sun, 23 Dec 2001 13:40:30 -0600
Subject: [R] Time Series Data
Message-ID: <3C26332E.1AE48E0D@hia.net>


Happy Holidays All,

I'm trying to use stl() to extract a seasonal component from a time
series. I believe the root cause of my problem lies in how I imported
the data into R.

In Excel (csv), the data look like:
            Jan     Feb    Mar    ....
1949    12.2    9.0    7.9     ....
1950    17.2    16.9  9.9    ....
1951    8.2       7.0    7.7    ....

I import to R using:
a<-read.csv("d:/programs/r/airpass.csv",header=TRUE, sep = ",")

then I try to coerce a to a .ts object using:
> a.ts<- as.ts(a)

but get the following error:
Error in dimnames<-.data.frame(*tmp*, value = list(NULL, names)) :
        invalid dimnames given for data frame

I have tried everything (except what works).  When I do:

> mode(a)

R returns:
[1] "list"

Other things I've done show me that R is treating the columns as
separate variables.

How do I specify to R that I want the csv data read as a single,
univariate times series sampled once/month over many years?

Any  help is much appreciated.

Best,
Bill Vedder





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Sun Dec 23 20:34:00 2001
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sun, 23 Dec 2001 14:34:00 -0500
Subject: [R] R 1.4 on Mandrake Linux 8.1
Message-ID: <20011223143400.3828af06.fharrell@virginia.edu>

I installed the new rpm from CRAN for R 1.4 for Mandrake Linux 8.1, after getting blas and libgcc from rpmfind.net.  When I do update.packages() the system goes to update grid, lattice, and mgcv.  I get compile errors for two of them.  Apparently R is looking for gcc 3.0.1 or later but 8.1 uses 2.9x which is required for other Mandrake applications (i.e., I get a dependency error when trying to install the latest gcc*.rpm from rpmfind.net; there are no Mandrake 8.1 updates yet for gcc).  I would appreciate a pointer.  Thanks -Frank

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Dec 23 22:24:08 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Dec 2001 21:24:08 +0000 (GMT)
Subject: [R] Time Series Data
In-Reply-To: <3C26332E.1AE48E0D@hia.net>
Message-ID: <Pine.LNX.4.31.0112232121150.30244-100000@gannet.stats>

On Sun, 23 Dec 2001, Bill Vedder wrote:

>
> Happy Holidays All,
>
> I'm trying to use stl() to extract a seasonal component from a time
> series. I believe the root cause of my problem lies in how I imported
> the data into R.
>
> In Excel (csv), the data look like:
>             Jan     Feb    Mar    ....
> 1949    12.2    9.0    7.9     ....
> 1950    17.2    16.9  9.9    ....
> 1951    8.2       7.0    7.7    ....
>
> I import to R using:
> a<-read.csv("d:/programs/r/airpass.csv",header=TRUE, sep = ",")
>
> then I try to coerce a to a .ts object using:
> > a.ts<- as.ts(a)
>
> but get the following error:
> Error in dimnames<-.data.frame(*tmp*, value = list(NULL, names)) :
>         invalid dimnames given for data frame
>
> I have tried everything (except what works).  When I do:
>
> > mode(a)
>
> R returns:
> [1] "list"
>
> Other things I've done show me that R is treating the columns as
> separate variables.
>
> How do I specify to R that I want the csv data read as a single,
> univariate times series sampled once/month over many years?

With some difficulty!  Try

a <- ts(as.vector(t(as.matrix(a))), start=c(1949, 1), freq = 12)

That takes the data frame, makes a matrix, reads it by row and turns it
into a time series (if I got it right).



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sun Dec 23 23:14:17 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 23 Dec 2001 23:14:17 +0100
Subject: [R] R 1.4 on Mandrake Linux 8.1
In-Reply-To: <20011223143400.3828af06.fharrell@virginia.edu>
References: <20011223143400.3828af06.fharrell@virginia.edu>
Message-ID: <x2g061inye.fsf@blueberry.kubism.ku.dk>

Frank E Harrell Jr <fharrell at virginia.edu> writes:

> I installed the new rpm from CRAN for R 1.4 for Mandrake Linux 8.1,
> after getting blas and libgcc from rpmfind.net. When I do
> update.packages() the system goes to update grid, lattice, and mgcv.
> I get compile errors for two of them. Apparently R is looking for
> gcc 3.0.1 or later but 8.1 uses 2.9x which is required for other
> Mandrake applications (i.e., I get a dependency error when trying to
> install the latest gcc*.rpm from rpmfind.net; there are no Mandrake
> 8.1 updates yet for gcc). I would appreciate a pointer. Thanks
> -Frank

Um, what makes you think it wants 3.0.1? Nothing in R itself requires
that, but the rpm may have been compiled with 3.0.1 and that might
carry into the package-building. AFAIR, RedHat 7.2 has both a gcc and
a gcc3 rpm which can be installed in parallel, and Mandrake usually
follows RedHat..

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikalzet at libero.it  Sun Dec 23 23:16:16 2001
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Sun, 23 Dec 2001 23:16:16 +0100 (CET)
Subject: [R] R 1.4 on Mandrake Linux 8.1
In-Reply-To: <20011223143400.3828af06.fharrell@virginia.edu>
Message-ID: <Pine.LNX.4.33L2.0112232252420.3854-100000@localhost.localdomain>

On Sun, 23 Dec 2001, Frank E Harrell Jr wrote:

> I installed the new rpm from CRAN for R 1.4 for Mandrake Linux 8.1,
> after getting blas and libgcc from rpmfind.net.

Why did you do that ?

> When I do
> update.packages() the system goes to update grid, lattice, and mgcv.  I
> get compile errors for two of them.

> Apparently R is looking for gcc
> 3.0.1 or later but 8.1 uses 2.9x which is required for other Mandrake
> applications (i.e., I get a dependency error when trying to install the
> latest gcc*.rpm from rpmfind.net; there are no Mandrake 8.1 updates yet
> for gcc).

gcc-3.0.1 is included in standard Mandrake 8.1; you should have it already
installed or on your CD's, as I have.

Else download:

lftp ftp.edisontel.it/pub/Mandrake_Mirror/Mandrake/8.1/i586/Mandrake
/RPMS/
get gcc3.0-3.0.1-1md.i586.rpm

On my system (with no extraneous rpm's added) it is under
/usr/bin/gcc-3.0.1

There is an /etc/alternatives directory in which a link is found between
gcc and the gcc you wish to use, you can change that if you like, or you
can simply do

export CC="gcc-3.0.1"
export GCC="gcc-3.0.1"

in your shell before compiling.

When I do update.packages() the only package it updates is mgcv, which it
then proceeds to compile and install with gcc-3.0.1 (even though my
'default' gcc in the alternatives directory is 2.96) (it seemed a clever
idea at the time to compile with gcc 3.0.1 rather than an earlier version
- not so sure it was now).

Guess you just have to install the

gcc3.0-3.0.1-1mdk.i586.rpm

RPM package from mandrake (your old gcc won't be touched) or else
recompile the RPM from source with your gcc-2.96.

-- 
Dr. Michele Alzetta

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikalzet at libero.it  Mon Dec 24 06:57:23 2001
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Mon, 24 Dec 2001 06:57:23 +0100 (CET)
Subject: [R] R 1.4 on Mandrake Linux 8.1
In-Reply-To: <20011223143400.3828af06.fharrell@virginia.edu>
Message-ID: <Pine.LNX.4.33L2.0112240648300.2091-100000@localhost.localdomain>

On Sun, 23 Dec 2001, Frank E Harrell Jr wrote:

> after getting blas and libgcc from rpmfind.net

Please note that many libs in Mandrake have slightly different names to
allow for backwards compatibility I suppose. On my system

rpm -qa libgc*

gives:

libgcj-devel-2.96-4mdk
libgcj-2.96-4mdk
libgcc3.0-3.0.1-1mdk

locate blas gives me

/usr/lib/libblas.so.3.0

and

rpm -qf /usr/lib/libblas.so.3.0

gives me

liblapack3-3.0-3mdk.

I suggest you install these and uninstall the extraneous packages from RPM
find. I have never trusted updates myself; I keep my /home /usr/local and
/opt partitions and do a clean install after having saved my /etc
directory too.

-- 
Michele Alzetta

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sat Dec 22 19:28:32 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 22 Dec 2001 19:28:32 +0100
Subject: [R] Cannot rebuild srpm
In-Reply-To: <20011223023822.364670cd.umusus@net.nagasaki-u.ac.jp>
References: <20011223023822.364670cd.umusus@net.nagasaki-u.ac.jp>
Message-ID: <x2g063xg6n.fsf@blueberry.kubism.ku.dk>

Susumu TANIMURA/?? ? <umusus at net.nagasaki-u.ac.jp> writes:

> Dear R-users,
> 
> When rebuilding R-base-1.4.0-1.src.rpm, it stopped and give message as follow:
> (Some words is Japanese)
> 
> >>> Building/Updating help pages for package `base'
>      Formats: text example 
> make[5]: ??? ?????? `/home/umusus/rpm/BUILD/R-1.4.0/src/library'
> running code in `base-Ex.R' ...make[4]: *** [base-Ex.Rout] ??? 1
> make[4]: ??? ?????? `/home/umusus/rpm/BUILD/R-1.4.0/tests/Examples'
> make[3]: *** [test-Examples] ??? 2
> make[3]: ??? ?????? `/home/umusus/rpm/BUILD/R-1.4.0/tests/Examples'
> make[2]: *** [test-Examples] ??? 2
> make[2]: ??? ?????? `/home/umusus/rpm/BUILD/R-1.4.0/tests'
> make[1]: *** [test-all-basics] ??? 1
> make[1]: ??? ?????? `/home/umusus/rpm/BUILD/R-1.4.0/tests'
> make: *** [check] ??? 2
> ???: Bad exit status from /var/tmp/rpm-tmp.95916 (%build)
> 
> I tried in RedHat7.2(ja) and VineLinux2.1.5, which is developed from
> RedHat6.2.  In both of them, the same message was given.
> 
> Does anyone know how to solve this?

Looks like it didn't build the documentation. Is perl installed?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From amaitour at pasteur.fr  Mon Dec 24 10:34:33 2001
From: amaitour at pasteur.fr (Aboubakar Maitournam)
Date: Mon, 24 Dec 2001 10:34:33 +0100
Subject: [R] A small question
References: <MABBJPBLPNLDIFMIAAOJGEMOCCAA.indra_calisto@yahoo.com>
Message-ID: <3C26F6A9.1E8B319D@pasteur.fr>

Indrajit SenGupta wrote:

>  Dear R- users,I have a small question on R. The other day I was using
> R when I decided to quit and when I was prompted with the question
> whether I would like to save the workspace image, I accidently pressed
> yes and after that every time start R the previous work space gets
> loaded. How do I avoid this?Thanks in
> advance,______________________Indrajit SenGuptaDepartment Of
> StatisticsSt. Xavier's CollegeCalcutta
> Universityindra_calisto at yahoo.comindrajit_sg@rediffmail.com

I have had that kind of problem and among a lot responses I have
received, here are solutions :

Subject:
           Re: [R] R workspace
      Date:
           Sat, 15 Dec 2001 16:36:14 -0500
      From:
           Duncan Murdoch <dmurdoch at pair.com>
        To:
           Aboubakar Maitournam <amaitour at pasteur.fr>,
r-help at stat.math.ethz.ch
 References:
           1




On Thu, 13 Dec 2001 11:42:40 +0100, you wrote:

>
>Dear all,
>
>I m using  R version 1.3.1 under linux (Red Hat).
>When i left my session, naturally i have the question
>Save workspace image? [y/n/c]?
>I said n because I want to remove all the contain of my workspace.
>Then I left R with q().

This means it won't save the current workspace, but if you already
have a saved one, it will be left there.

>
>When I open new session I have the R welcome message and
>[previously save workspace restored]. By typing ls() I find
>what I have normally removed and I want to remove.
>I have try rm(" "). But every time I open R session I find the objects.

There are several ways to get rid of the old saved workspace, for
example:

 unlink(".RData")
 q("no")

or

 rm(list=ls())
 q("yes")

Duncan Murdoch
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011224/2e6dd9e9/attachment.html

From tlumley at u.washington.edu  Mon Dec 24 17:36:37 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 24 Dec 2001 08:36:37 -0800 (PST)
Subject: [R] gam plots
In-Reply-To: <p05101005b849c078053c@[10.0.1.11]>
Message-ID: <Pine.A41.4.33.0112240825290.65956-100000@homer30.u.washington.edu>

On Sat, 22 Dec 2001, Patty Solomon wrote:

> Dear R users,
>
> Using the library(mgcv) and running R under MacOSX, I have fitted a
> generalised additive model with binomial errors in order to check the
> linearity of two continuous variables ap2mm and diffdaysm in a glm:
>
>
> >  mymodel.gam <- gam(diedhos~ s(ap2mm) + Dweekm + s(diffdaysm) +
>   Dweekm:diffdaysm + ap2mm:Dweekm, binomial)
>
> I would like postscript gam plots for the two smoothed terms to be
> produced on separate pages, but am having trouble getting these.  I
> can get the two plots output to a single page using
>
> >  postscript("gams.ps")
> >  plot(mymodel.gam, pages=1, se=T)
> >  dev.off()
>
> I don't want this, but when I try replacing pages=1 with pages=2, I
> still get only one page in the postscript file with the second plot
> overlaid on the first one:
>
> >  plot(mymodel.gam, pages=2, se=T)
> Press return for next page....
>
>
> 	I wondered if anyone knows of a way to get each plot on a
> separate page, i.e. two postscript files?

This needs options to postscript(), not to plot() eg
    postscript("gams%d.ps",onefile=FALSE)
You will end up with files gams1.ps and gams2.ps.

> I also noticed that the plot gives tick marks for the values of the
> variable along the horizontal axis, but I would like a rug of *all*
> the values (Splus5 produces a rug using jittering to show the density
> of the observations, but the version of R that I have doesn't do
> this, as far as I can tell).

You can edit plot.gam fairly easily to do this (either with
  fix(plot.gam)
or by saving the code to a file and editing it)

There are two calls to rug() in plot.gam() and you want to insert jitter()
in each one: ie change
          rug(as.numeric(x$x[x$nsdf + i, ]))
to
          rug(jitter(as.numeric(x$x[x$nsdf + i, ])))


If you could live with regression splines instead of smoothing splines you
could fit a glm() and use termplot(), which does jitter.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Dec 24 17:45:26 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 24 Dec 2001 08:45:26 -0800 (PST)
Subject: [R] Saving Newly Created Functions
In-Reply-To: <3C249611.73CE0C2E@hia.net>
Message-ID: <Pine.A41.4.33.0112240842010.65956-100000@homer30.u.washington.edu>

On Sat, 22 Dec 2001, Bill Vedder wrote:

> Greetings R-Listers,
>
> Using R1.2.1 (yes, I know...)
>
> I am writing my own functions and would like to know how save these for
> use in subsequent R sessions.  How does one do this?

The easiest way is to write them in text files and source() these files.
If  you want to do it every time you run R, put the functions or the
source() command in your .Rprofile.

Another possibility is to use save() to put your functions in an Rdata
file. You can then use attach() to make the functions available.

Finally, you can put the functions and their documentation into a package
(following the instructions in 'Writing R Extensions').

The second and third methods mean that the functions won't be part of the
workspace if you save it, and it's easy to unload the functions if you
want to, with detach().

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ozric at web.de  Tue Dec 25 11:46:02 2001
From: ozric at web.de (ozric@web.de)
Date: Tue, 25 Dec 2001 11:46:02 +0100
Subject: [R] tseries object
Message-ID: <200112251046.fBPAk1C03978@mailgate5.cinetic.de>

Hello,
what's the problem with the dimnames - i get no solution ? 
thanks for advance, regards
christian

> file <- read.table("c:/rw1040/data/timeSeries.txt",header=T)
> file
     DATE   AQ  EUMS
1   Jan92  7.6  98.4
2   Feb92  7.5  98.5
3   Mrz92  7.5  97.0
....................
117 Sep01  9.4 105.3
118 Okt01  9.5 102.6

> file.ts <- ts(file,start=c(1992,1),end=c(2001,10),frequency=12)
Error in "dimnames<-.data.frame"(*tmp*, value = list(NULL, names)) : 
        invalid dimnames given for data frame
> file.ts <- ts(file,start=c(1992,1),frequency=12)
Error in "dimnames<-.data.frame"(*tmp*, value = list(NULL, names)) : 
        invalid dimnames given for data frame







______________________________________________________________________________
DSL-Stichtag ist der 31.12.2001 - Sie sparen jetzt noch 135 Euro!
Highspeed-Surfen beim Testsieger + Exklusiv-Pr?mien: http://dsl.web.de

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Dec 25 14:00:14 2001
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 25 Dec 2001 14:00:14 +0100
Subject: [R] tseries object
References: <200112251046.fBPAk1C03978@mailgate5.cinetic.de>
Message-ID: <3C28785E.D2CFE8E8@statistik.uni-dortmund.de>

ozric at web.de wrote:
> 
> Hello,
> what's the problem with the dimnames - i get no solution ?
> thanks for advance, regards
> christian
> 
> > file <- read.table("c:/rw1040/data/timeSeries.txt",header=T)
> > file
>      DATE   AQ  EUMS
> 1   Jan92  7.6  98.4
> 2   Feb92  7.5  98.5
> 3   Mrz92  7.5  97.0
> ....................
> 117 Sep01  9.4 105.3
> 118 Okt01  9.5 102.6
> 
> > file.ts <- ts(file,start=c(1992,1),end=c(2001,10),frequency=12)
> Error in "dimnames<-.data.frame"(*tmp*, value = list(NULL, names)) :
>         invalid dimnames given for data frame
> > file.ts <- ts(file,start=c(1992,1),frequency=12)
> Error in "dimnames<-.data.frame"(*tmp*, value = list(NULL, names)) :
>         invalid dimnames given for data frame


>From ?ts:
data 	a vector or matrix of the observed time-series values. 

So it is not documented that a dataframe will work as data argument for
ts().
Turning the dataframe into a matrix(as.matrix()) should work:

file.ts <- ts(as.matrix(file), start=c(1992,1), frequency=12)

Uwe
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From feldesmanm at pdx.edu  Wed Dec 26 05:45:55 2001
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Tue, 25 Dec 2001 20:45:55 -0800
Subject: [R] ESS 5.1.19 w/Xemacs 21.4.6
Message-ID: <5.1.0.14.2.20011225204133.02613ec0@pop4.attglobal.net>

Probably wrong group for this, but a quick question.  I've just switched 
from emacs to Xemacs.  In reinstalling ESS 5.1.19 I keep getting the 
following error when loading Xemacs:

"Error in init file:  Symbol's function definition is void:  w32-using-nt"

I've debugged the ess-site.el file, which is where the error originates 
from.  The line causing the difficulty is:

(load "f:/xemacs/xemacs-21.4.6/lisp/ess-5.1.19/lisp/ess-site.el")

This is precisely where the ess-site.el file is located.  If I do M-x-R, R 
is loaded correctly even though the error occurs.

If I change the line to:

(load-file  "f:/xemacs/xemacs-21.4.6/lisp/ess-5.1.19/lisp/ess-site.el"), I 
get the same error.

What stupid error have I made in configuring Xemacs?  Emacs ran fine with 
no errors.

Thanks,




Dr. Marc R. Feldesman
email:  feldesmanm at pdx.edu
email:  feldesman at attglobal.net
fax:    503-725-3905

"Don't know where I'm going.
Don't like where I've been.
There may be no exit.
But hell, I'm going in."  Jimmy Buffett

Powered by Superchoerus - the 700 MHz Coppermine Box

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From feldesmanm at pdx.edu  Wed Dec 26 05:45:55 2001
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Tue, 25 Dec 2001 20:45:55 -0800
Subject: [R] ESS 5.1.19 w/Xemacs 21.4.6
Message-ID: <5.1.0.14.2.20011225204133.02613ec0@pop4.attglobal.net>

Probably wrong group for this, but a quick question.  I've just switched 
from emacs to Xemacs.  In reinstalling ESS 5.1.19 I keep getting the 
following error when loading Xemacs:

"Error in init file:  Symbol's function definition is void:  w32-using-nt"

I've debugged the ess-site.el file, which is where the error originates 
from.  The line causing the difficulty is:

(load "f:/xemacs/xemacs-21.4.6/lisp/ess-5.1.19/lisp/ess-site.el")

This is precisely where the ess-site.el file is located.  If I do M-x-R, R 
is loaded correctly even though the error occurs.

If I change the line to:

(load-file  "f:/xemacs/xemacs-21.4.6/lisp/ess-5.1.19/lisp/ess-site.el"), I 
get the same error.

What stupid error have I made in configuring Xemacs?  Emacs ran fine with 
no errors.

Thanks,




Dr. Marc R. Feldesman
email:  feldesmanm at pdx.edu
email:  feldesman at attglobal.net
fax:    503-725-3905

"Don't know where I'm going.
Don't like where I've been.
There may be no exit.
But hell, I'm going in."  Jimmy Buffett

Powered by Superchoerus - the 700 MHz Coppermine Box

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Wed Dec 26 06:15:29 2001
From: rossini at blindglobe.net (A.J. Rossini)
Date: 25 Dec 2001 21:15:29 -0800
Subject: [R] ESS 5.1.19 w/Xemacs 21.4.6
In-Reply-To: <5.1.0.14.2.20011225204133.02613ec0@pop4.attglobal.net>
References: <5.1.0.14.2.20011225204133.02613ec0@pop4.attglobal.net>
Message-ID: <871yhiwoi6.fsf@jeeves.blindglobe.net>

>>>>> "MRF" == Marc R Feldesman <feldesmanm at pdx.edu> writes:

    MRF> Probably wrong group for this, but a quick question.  I've
    MRF> just switched

Much the wrong group.

Fixes are in 5.2.20; you are suffering from being ahead of the ESS
development team, sigh...


    >> From emacs to Xemacs.  In reinstalling ESS 5.1.19 I keep
    >> getting the

    MRF> following error when loading Xemacs:

    MRF> "Error in init file: Symbol's function definition is void:
    MRF> w32-using-nt"

    MRF> I've debugged the ess-site.el file, which is where the error
    MRF> originates from.  The line causing the difficulty is:


    MRF> (load
    MRF> "f:/xemacs/xemacs-21.4.6/lisp/ess-5.1.19/lisp/ess-site.el")

    MRF> This is precisely where the ess-site.el file is located.  If
    MRF> I do M-x-R, R is loaded correctly even though the error
    MRF> occurs.


    MRF> If I change the line to:

    MRF> (load-file
    MRF> "f:/xemacs/xemacs-21.4.6/lisp/ess-5.1.19/lisp/ess-site.el"),
    MRF> I get the same error.


    MRF> What stupid error have I made in configuring Xemacs?  Emacs
    MRF> ran fine with no errors.


    MRF> Thanks,




    MRF> Dr. Marc R. Feldesman email: feldesmanm at pdx.edu email:
    MRF> feldesman at attglobal.net fax: 503-725-3905

    MRF> "Don't know where I'm going.  Don't like where I've been.
    MRF> There may be no exit.  But hell, I'm going in."  Jimmy
    MRF> Buffett

    MRF> Powered by Superchoerus - the 700 MHz Coppermine Box

    MRF> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
    MRF> r-help mailing list -- Read
    MRF> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info",
    MRF> "help", or "[un]subscribe" (in the "body", not the subject !)
    MRF> To: r-help-request at stat.math.ethz.ch
    MRF> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._




-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   T-Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
Rosen: (Mullins' Lab) Fridays, and I'm unreachable except by email.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ozric at web.de  Wed Dec 26 11:57:46 2001
From: ozric at web.de (ozric@web.de)
Date: Wed, 26 Dec 2001 11:57:46 +0100
Subject: [R] install java (Setting env. variable)
Message-ID: <200112261057.fBQAvkC08477@mailgate5.cinetic.de>

Hello,
sorry but i found no solution in which way
i have to set the evironment var. for Windows for the OmegaheatPackage!

..it must be something similar like:
Sys.putenv("LD_LIBRARY_PATH"="c:/rw1040/R/library/SJava/libs") 

but i get the errorMessage:

.Alias is deprecated; there is no replacement 
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library "C:/RW1040/library/SJava/libs/SJava.dll":
  LoadLibrary failure:  Ein der f?r die Ausf?hrung dieser Anwendung notwendige Bibliothekdateien kann nicht gefunden werden.
Error in library(SJava) : .First.lib failed

P.S. jdk1.3.1 is installed and the Classpath to that library exist.

best thanks
regards,christian 

______________________________________________________________________________
Darf es ein bisschen mehr sein? Mehr Speicher, mehr Mail, mehr Erlebnis, 
mehr Pr?mie, mehr WEB.DE.  Der WEB.DE Club - http://club.web.de

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Wed Dec 26 16:47:25 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Wed, 26 Dec 2001 10:47:25 -0500 (EST)
Subject: [R] aov for mixed model (fixed and random)?
Message-ID: <200112261547.fBQFlPd29266@cattell.psych.upenn.edu>

Robert Espesser (Robert.Espesser at lpl.univ-aix.fr) answered the
following question, asking me to post to the list if the answer
worked.  It did.  But ... [see below]

My original message:
----------
I'm starting to understand fixed and random effects, but I'm
puzzled a bit.  Here is an example from Hays's textbook (which is
great at explaining fixed vs. random effects, at least to dummies
like me), from the section on mixed models.  You need
library(nlme) in order to run it.
------
task <- gl(3,2,36) # Three tasks, a fixed effect.
subj <- gl(6,6,36) # Six subjects, a random effect.

h1 <- c(7.8,8.7,  11.1,12.0, 11.7,10.0, # Each S does each task twice.
        8.0,9.2,  11.3,10.6, 9.8,11.9,
        4.0,6.9,   9.8,10.1, 11.7,12.6,
        10.3,9.4, 11.4,10.5, 7.9,8.1,
        9.3,10.6, 13.0,11.7, 8.3,7.9,
        9.5,9.8,  12.2,12.3, 8.6,10.5)

aov1 <- aov(h1~task*subj)
anova(aov1) # See note below.

lme1 <- lme(h1~task,random=~1|subj)
lme2 <- lme(h1~task,random=~1|subj/task)
anova(lme1,lme2) # for interaction
anova(lme2) # for effect of task
-------

The anova gives very close to the correct F values for subj
(1.68, according to Hays) and for the interaction (7.19), but the
wrong F values for task, because it treats task as a random
effect, using the wrong error term.  Specifically, it gives
F=27.27, instead of 3.78 (Hays's figure).  This is because it
uses the within-cell error as the denominator for F instead of
the interaction term.  (The interaction ms is 5.82.)

The lme results give approximately the same results as Hays, but
they are different, presumably because of using a different
method (REML).  (I still don't understand why I can't just say
anova(lme2) and get everything all at once, but that's another
matter, and at least I've finally gotten this far.)

Now my question: Can I reproduce the results in Hays exactly?
Presumably this will involve instructing aov to use the
interaction as the error term for the denominator of F.  I've
tried everything I can think of.  If you can answer this, it
might go a long way toward helping me understand the (still
somewhat mysterious) "Error()" component of aov, if that turns
out to be part of the answer.

---------------

The answer that works:
aov2 <- aov( hl ~ task +Error(subject/task) )
summary(aov2)

yields the correct F test for task.  Presumably this is because
task is a within-subject variable, so task is "nested" (I guess
that is the term) within subject.

But ...

1. It does not work with anova(aov2), just with summary(aov2).

2. I still can't figure out how to get get this to give the
   interaction effect.

Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec 26 18:26:03 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 26 Dec 2001 18:26:03 +0100
Subject: [R] aov for mixed model (fixed and random)?
In-Reply-To: <200112261547.fBQFlPd29266@cattell.psych.upenn.edu>
References: <200112261547.fBQFlPd29266@cattell.psych.upenn.edu>
Message-ID: <x2r8phriz8.fsf@blueberry.kubism.ku.dk>

baron at cattell.psych.upenn.edu (Jonathan Baron) writes:

> The answer that works:
> aov2 <- aov( hl ~ task +Error(subject/task) )
> summary(aov2)

It doesn't, but aov2 <- aov( h1 ~ task +Error(subj/task) )
does...

> yields the correct F test for task.  Presumably this is because
> task is a within-subject variable, so task is "nested" (I guess
> that is the term) within subject.

The advice from the good ol' Genstat manual was to consider the error
model a thing in itself, separate from the fixed effects. So you're
having  a model in which there are different means for each task, and
on top of that you add random effects from three sources

(a) subj: add i.i.d terms that are common for all measurements on
the same subject.

(b) subj:task add i.i.d terms that are common for all measurements on
the same combination of task and subject. 

(c) residual: i.i.d terms different for all measurements

The interpretation of (b) is the tricky bit. You can either take it to
mean that subjects really do respond differently to different tasks,
and that that variation is what you model, or more simply as an
indication that the replications on each subj:task combination are
correlated, e.g. because they are insufficiently separated in time.

> But ...
> 
> 1. It does not work with anova(aov2), just with summary(aov2).

Why should it? summary() gives the correctly stratified ANOVA table.
anova() doesn't know how to deal with objects of class "aovlist".

> 2. I still can't figure out how to get get this to give the
>    interaction effect.

It's the residual MS in the subj:task stratum. You don't get the 
test for it though. In this particular case, it is trivial to
calculate as F = MSres(subj:task)/MSres(Within), but with other
designs it is not so simple (notably when you have both row and column
random effects) so you have to know what you are doing.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hsiung at interchange.ubc.ca  Thu Dec 27 07:18:16 2001
From: hsiung at interchange.ubc.ca (Dr. Robin Hsiung)
Date: Wed, 26 Dec 2001 22:18:16 -0800
Subject: [R] Re: R-1.4.0 RPM's
In-Reply-To: <Pine.LNX.4.33L2.0112210947020.2233-100000@localhost.localdomain>
References: <Pine.LNX.4.33L2.0112210947020.2233-100000@localhost.localdomain>
Message-ID: <0GOZ00AKGNUA67@l-daemon>


I have been using R-1.3.1-0 on Mandrake linux 8.1, and I just downloaded the 
R-1.4.0 RPM. However, I have problem updating because of dependency 
problems missing libblas.so.3 - what type of lib is it, and how should I 
upgrade it?
Thank you for your info.
Robin

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Thu Dec 27 11:26:11 2001
From: siim at obs.ee (Ott Toomet)
Date: Thu, 27 Dec 2001 11:26:11 +0100 (CET)
Subject: [R] write.table and large datasets
Message-ID: <Pine.LNX.4.33.0112271108560.6682-100000@ecopc64.eco.au.dk>

Hi,

I'll continue the discussion about the write.table() and problems with large
datasets.

The databases I have to work with are quite huge, 7500 obs x 1200 vars were
on of the smallest of them.  I usually write a perl script to preprocess
them line-by-line and extract only the variables which I need later.  This
results into quite a manageable size but I have to have the dataset in ASCII
form.

As it appears, R could easily read in a dataset of that size (it was in
STATA format) but the conversion to ascii was quite complicated.  I
remember, I have done it with a larger dataset, using SPSS and a rougly
equal computer (128M memory).  It did not took much time, perhaps a minute
or so.  That's why I was surprised that apparently similar function in R was
unable to save the dataset at all.

I still think that it would be a good idea to be able to transform big
datasets to ascii, it is perhaps the most simple and open standard which I
think everybody else can use too.  Perhaps it is more meaningful to make a
less-general function (in package external) which can save at least numeric
and character variables?  I have made some attempts myself but these are
still in very early stage.

So, what is the general opinion -- is such kind of a conversion utility
needed in R?

Regards,

Ott Toomet


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 27 12:14:20 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Dec 2001 11:14:20 +0000 (GMT)
Subject: [R] write.table and large datasets
In-Reply-To: <Pine.LNX.4.33.0112271108560.6682-100000@ecopc64.eco.au.dk>
Message-ID: <Pine.LNX.4.31.0112271112160.13457-100000@gannet.stats>

There already is such a function, write.matrix in package MASS. As from
the next release it can work in blocks of rows as well.  It's already
cross-referenced in R-patched and R-devel.

BDR

On Thu, 27 Dec 2001, Ott Toomet wrote:

> Hi,
>
> I'll continue the discussion about the write.table() and problems with large
> datasets.
>
> The databases I have to work with are quite huge, 7500 obs x 1200 vars were
> on of the smallest of them.  I usually write a perl script to preprocess
> them line-by-line and extract only the variables which I need later.  This
> results into quite a manageable size but I have to have the dataset in ASCII
> form.
>
> As it appears, R could easily read in a dataset of that size (it was in
> STATA format) but the conversion to ascii was quite complicated.  I
> remember, I have done it with a larger dataset, using SPSS and a rougly
> equal computer (128M memory).  It did not took much time, perhaps a minute
> or so.  That's why I was surprised that apparently similar function in R was
> unable to save the dataset at all.
>
> I still think that it would be a good idea to be able to transform big
> datasets to ascii, it is perhaps the most simple and open standard which I
> think everybody else can use too.  Perhaps it is more meaningful to make a
> less-general function (in package external) which can save at least numeric
> and character variables?  I have made some attempts myself but these are
> still in very early stage.
>
> So, what is the general opinion -- is such kind of a conversion utility
> needed in R?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Thu Dec 27 14:20:22 2001
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 27 Dec 2001 08:20:22 -0500
Subject: [R] Re: R-1.4.0 RPM's
In-Reply-To: <0GOZ00AKGNUA67@l-daemon>
References: <Pine.LNX.4.33L2.0112210947020.2233-100000@localhost.localdomain>
	<0GOZ00AKGNUA67@l-daemon>
Message-ID: <20011227082022.2dd051cf.fharrell@virginia.edu>

I had the same problem and Michele Alzetta was kind enough to help.  My problem in updating to R-1.4 was due solely to programs that didn't get installed when I updated from Mandrake 7.2 to Mandrake 8.1.  For those having the same problem here is what I did to solve it, with information from Michele:

1. Installed libgcc3.0-3.0.1-1mdk from Mandrake installation disk # 2

2. Installed liblapack3-3.0-3mdk from Mandrake disk # 3 (this will fix your blas problem)

3. I also had to install gcc3.0-3.0.1-1md.i586.rpm so that update.packages() would run, but most people will already have this installed

Frank

On Wed, 26 Dec 2001 22:18:16 -0800
"Dr. Robin Hsiung" <hsiung at interchange.ubc.ca> wrote:

> 
> I have been using R-1.3.1-0 on Mandrake linux 8.1, and I just downloaded the 
> R-1.4.0 RPM. However, I have problem updating because of dependency 
> problems missing libblas.so.3 - what type of lib is it, and how should I 
> upgrade it?
> Thank you for your info.
> Robin
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hb at maths.lth.se  Thu Dec 27 17:34:27 2001
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 27 Dec 2001 17:34:27 +0100
Subject: [R] RE: Binaries of R-1.4.0 for Windows
In-Reply-To: <20011227115746.59141@hal.stat.unipd.it>
Message-ID: <KKEGJOGBELBHDIKPINBMCEPJCIAA.hb@maths.lth.se>

Thanks! Just a minor comment: It seems you've forgotten to run a precompiler
or something on the http://sirio.stat.unipd.it/RWin/ReadMe.rw1040 file; I
see @RVER@ and @RWVER@ where I believe it should say "1.4.0" and "rw1040",
respectively. I guess this will be the same when mirrored.

Happy New Year!

Henrik Bengtsson

Dept. of Mathematical Statistics @ Centre for Mathematical Sciences
Lund Institute of Technology/Lund University, Sweden (+2h UTC)
Office: P316, +46 46 222 9611 (phone), +46 46 222 4623 (fax)
hb at maths.lth.se, http://www.maths.lth.se/matstat/staff/hb/


> -----Original Message-----
> From: owner-r-announce at stat.math.ethz.ch
> [mailto:owner-r-announce at stat.math.ethz.ch]On Behalf Of Guido Masarotto
> Sent: Thursday, December 27, 2001 11:58 AM
> To: r-announce at stat.math.ethz.ch
> Subject: Binaries of R-1.4.0 for Windows
>
>
>
> A binary distribution of R-1.4.0 to run on Windows 95, 98, NT4.0, 2000
> and XP on Intel/clone chips is available at
>        http://sirio.stat.unipd.it/RWin
>
> It will be mirrored at a CRAN site near you in a couple of days.
>
> See http://sirio.stat.unipd.it/RWin/CHANGES for a list of
> Windows-specific changes.
>
> guido masarotto
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-
> r-announce mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:
> r-announce-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._
>
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chrysopa at insecta.ufv.br  Thu Dec 27 16:50:41 2001
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Thu, 27 Dec 2001 13:50:41 -0200
Subject: [R] [Off topic] time's statistic
Message-ID: <20011227155216.BCF6076E@localhost.localdomain>

Hi all,
I have a little doubt.

Is correct to make a regression when the independent variate is the time? 
If not, why and how to analyse my data.

I dont want to know about time series or survival analysis.

For exemple:

Y(growing) X(days)
1	     1
3 	     2
5            3
6            4
7            5

Thanks
Ronaldo
-- 
Mind your own business, then you don't mind mine.
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][SO: CL 7.0 (2.2.19)]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Conectiva Linux 7.0 D+:) | Lxuser#: 205366
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dthompson at whgrp.com  Thu Dec 27 20:46:22 2001
From: dthompson at whgrp.com (Dave Thompson)
Date: Thu, 27 Dec 2001 14:46:22 -0500
Subject: [R] gls
Message-ID: <3C2B7A8E.8412EBEC@whgrp.com>

A couple of questions:
How to be sure that gls allowes errors to be correlated and/or have
unequal
variances?  (is this on auto or is there a switch?)

How to calculate confidence limits for a linear regresssion?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: dthompson.vcf
Type: text/x-vcard
Size: 303 bytes
Desc: Card for David Thompson
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20011227/680f2687/dthompson.vcf

From apjaworski at mmm.com  Thu Dec 27 21:04:23 2001
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Thu, 27 Dec 2001 14:04:23 -0600
Subject: [R] new lattice/grid
Message-ID: <OF4CF9FAD4.68E4559C-ON86256B2F.006D2EE7@mmm.com>

I just installed R-1.4.0 on my Win2k machine from SetupR.exe.  Everything
seems to be fine with the base and recommended packages.  However, when I
install the lattice and grid packages they do not seem to work.  Everything
I try results in something like this:

     Instruction 0x00543f06 refernced memory 0x00000000.  The memory cannot
be "read".

and I am getting kicked out of R.

Has anyone experienced this or is it just me?

Andy

PS.    I used install.packages menu item to install lattice and grid from
the main CRAN site.

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikalzet at libero.it  Thu Dec 27 21:08:11 2001
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Thu, 27 Dec 2001 21:08:11 +0100 (CET)
Subject: [R] Re: R-1.4.0 RPM's
In-Reply-To: <0GOZ00AKGNUA67@l-daemon>
Message-ID: <Pine.LNX.4.33L2.0112272107120.1950-100000@localhost.localdomain>

On Wed, 26 Dec 2001, Dr. Robin Hsiung wrote:

>
> I have been using R-1.3.1-0 on Mandrake linux 8.1, and I just downloaded the
> R-1.4.0 RPM. However, I have problem updating because of dependency
> problems missing libblas.so.3 - what type of lib is it, and how should I
> upgrade it?

Just take your installation disk number 3 and install

liblapack3-3.0-3mdk.i586.rpm

-- 
Dr. Michele Alzetta

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From yiping.fan at syngenta.com  Thu Dec 27 21:35:29 2001
From: yiping.fan at syngenta.com (yiping.fan@syngenta.com)
Date: Thu, 27 Dec 2001 21:35:29 +0100
Subject: [R] read input from STDIN
Message-ID: <AF84AD19B4A8D411B18500508BAF0E0EC29893@se-excur01-uslj.nadi.uslj>

Hello,
   I have a perl program which produces the input. Instead of print it to a
file then let R read the file,
I want to let R to read the input directly from the perl output, 

I am using  a PERL IPC::open2 module for this, 

local (*Read,*Writer);
$pid = open2(\*Read, \*Writer, "R --no-save --slave< my.R")

#input to R
for(){
  print Writer data;
}
close Writer;

#R output
@result = <Read>;


How can "my.R"  read the stdin and figure out the relationship in the data?
I tried realLines(), does not work.  Thank you very much for your help!!

Yiping


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Thu Dec 27 22:12:17 2001
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Thu, 27 Dec 2001 13:12:17 -0800 (PST)
Subject: [R] new lattice/grid
In-Reply-To: <OF4CF9FAD4.68E4559C-ON86256B2F.006D2EE7@mmm.com>
Message-ID: <20011227211217.50608.qmail@web13908.mail.yahoo.com>



Someone else might be able to give a better answer, but this might be the
reason:
--------------
[snipped from Paul Murrell's r-announce mail]

(iii) There is a known bug on Windows; turning on plot history recording 
while producing grid graphics will crash R. Adding individual plots to the 
plot history seems to work ok. 
----------------

I'm not sure what that means, and I don't have Windows. Paul, AFAIK is on
holiday (but probably due back soon).

Deepayan



--- apjaworski at mmm.com wrote:
> I just installed R-1.4.0 on my Win2k machine from SetupR.exe.  Everything
> seems to be fine with the base and recommended packages.  However, when I
> install the lattice and grid packages they do not seem to work.  Everything
> I try results in something like this:
> 
>      Instruction 0x00543f06 refernced memory 0x00000000.  The memory cannot
> be "read".
> 
> and I am getting kicked out of R.
> 
> Has anyone experienced this or is it just me?
> 
> Andy
> 
> PS.    I used install.packages menu item to install lattice and grid from
> the main CRAN site.
> 
> __________________________________
> Andy Jaworski
> Engineering Systems Technology Center
> 3M Center, 518-1-01
> St. Paul, MN 55144-1000
> -----
> E-mail: apjaworski at mmm.com
> Tel:  (651) 733-6092
> Fax:  (651) 736-3122
> 
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Thu Dec 27 22:21:32 2001
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 27 Dec 2001 22:21:32 +0100
Subject: [R] gls
References: <3C2B7A8E.8412EBEC@whgrp.com>
Message-ID: <3C2B90DC.6FE56B4A@statistik.uni-dortmund.de>

Dave Thompson wrote:
> 
> A couple of questions:
> How to be sure that gls allowes errors to be correlated and/or have
> unequal variances?  (is this on auto or is there a switch?)

It's in the help of ?gls (package nlme), details in the description of
the arguments "correlation" and "weights":

correlation 
        an optional corStruct object describing the within-group
correlation
structure. See the documentation of corClasses for a description of the
available corStruct classes. If a grouping variable is to be used, it
must be specified in the form argument to the corStruct constructor.
Defaults to NULL, corresponding to uncorrelated errors. 

weights 
        an optional varFunc object or one-sided formula describing the
within-group heteroscedasticity structure. If given as a formula, it is
used as the argument to varFixed, corresponding to fixed variance
weights. See the documentation on varClasses for a description of the
available varFunc classes. Defaults to NULL, corresponding to
homoscesdatic errors. 



> How to calculate confidence limits for a linear regresssion?

You might want to use predict(.... , interval="confidence"), see
?predict.lm.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Thu Dec 27 22:33:52 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Thu, 27 Dec 2001 16:33:52 -0500 (EST)
Subject: [R] read input from STDIN
Message-ID: <200112272133.fBRLXqH26568@cattell.psych.upenn.edu>

>From: yiping.fan at syngenta.com
>Hello,
>   I have a perl program which produces the input. Instead of print it to a
>file then let R read the file,
>I want to let R to read the input directly from the perl output, 
>
>I am using  a PERL IPC::open2 module for this, 
>
>local (*Read,*Writer);
>$pid = open2(\*Read, \*Writer, "R --no-save --slave< my.R")
>
>#input to R
>for(){
>  print Writer data;
>}
>close Writer;
>
>#R output
>@result = <Read>;
>
>
>How can "my.R"  read the stdin and figure out the relationship in the data?
>I tried realLines(), does not work.  Thank you very much for your help!!
>
>Yiping

I haven't tried this from within Perl, however, you can use R
from a Unix command line like this:
R --vanilla < my.R

To see what the --vanilla switch does that your commands do not
do, see the man page for R.  (I'm not sure which parts are the
important ones, but this works.)

To get the output from R, I write to a file from R itself, using
write() or whatever.  I'm sure there are other ways, but it seems
you have no objection to using files.

See pay.R at the end of http://finzi.psych.upenn.edu/~baron/
for an unnecessarily complex example, in which R is used to
write checks!  (You can also use it to wash the dishes :) )
I used to do this sort of thing with Perl, but, really, R is
just a better language, even for text processing, IMHO.

Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bdavies at intel.com  Thu Dec 27 23:19:57 2001
From: bdavies at intel.com (Davies, Bob)
Date: Thu, 27 Dec 2001 14:19:57 -0800
Subject: [R] www.R-project.org is not working
Message-ID: <25A36276A29AD5119FB000508BB26843012C8D01@fmsmsx101.fm.intel.com>

Somebody went away on vacation!  The main site for r:

http://www.R-project.org/

is just a generic index page (nothing there about R.)  I was able to get
info at the Austrian site, tho.

Bob Davies
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Dec 27 23:30:56 2001
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 27 Dec 2001 14:30:56 -0800 (PST)
Subject: [R] www.R-project.org is not working
In-Reply-To: <25A36276A29AD5119FB000508BB26843012C8D01@fmsmsx101.fm.intel.com>
Message-ID: <Pine.A41.4.33.0112271427260.79082-100000@homer09.u.washington.edu>

On Thu, 27 Dec 2001, Davies, Bob wrote:

> Somebody went away on vacation!  The main site for r:
>
> http://www.R-project.org/
>
> is just a generic index page (nothing there about R.)  I was able to get
> info at the Austrian site, tho.

I don't have any trouble accessing http://www.R-project.org/
which  *is* the Austrian site:

  www.r-project.org       canonical name = isildur.ci.tuwien.ac.at.
  Name:   isildur.ci.tuwien.ac.at
  Address: 128.131.51.43

Perhaps there's a nameserver problem somewhere

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Fri Dec 28 01:01:19 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Thu, 27 Dec 2001 19:01:19 -0500 (EST)
Subject: [R] read input from STDIN
Message-ID: <200112280001.fBS01Jx02439@cattell.psych.upenn.edu>

Sorry, I think I misread this.  I'll try to read more carefully
in the future.  Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From White.Denis at epamail.epa.gov  Fri Dec 28 01:25:24 2001
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Thu, 27 Dec 2001 16:25:24 -0800
Subject: [R] www.R-project.org is not working
Message-ID: <OFF97B47E0.A0D94544-ON88256B30.0001F2A2@rtp.epa.gov>


> Somebody went away on vacation!  The main site for r:
>
> http://www.R-project.org/
>
> is just a generic index page (nothing there about R.)  I was able to
get
> info at the Austrian site, tho.
>
> Bob Davies

Just went through that here.  The proxy on my organization's intranet
server had not been updated since the break-in to the R server last
Thursday.  Ask your systems administrator to update the proxy.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec 28 09:15:02 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Dec 2001 08:15:02 +0000 (GMT)
Subject: [R] new lattice/grid
In-Reply-To: <OF4CF9FAD4.68E4559C-ON86256B2F.006D2EE7@mmm.com>
Message-ID: <Pine.LNX.4.31.0112280810190.14954-100000@gannet.stats>

On Thu, 27 Dec 2001 apjaworski at mmm.com wrote:

> I just installed R-1.4.0 on my Win2k machine from SetupR.exe.  Everything
> seems to be fine with the base and recommended packages.  However, when I
> install the lattice and grid packages they do not seem to work.  Everything
> I try results in something like this:
>
>      Instruction 0x00543f06 refernced memory 0x00000000.  The memory cannot
> be "read".
>
> and I am getting kicked out of R.
>
> Has anyone experienced this or is it just me?
>
> Andy
>
> PS.    I used install.packages menu item to install lattice and grid from
> the main CRAN site.

I see that on the version compiled by Guido Masarotto, but not on the one
I compiled, which works correctly.  You didn't of course tell us where you
got SetupR.exe from!

I suggest you compile from the sources yourself.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec 28 09:25:49 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Dec 2001 08:25:49 +0000 (GMT)
Subject: [R] read input from STDIN
In-Reply-To: <AF84AD19B4A8D411B18500508BAF0E0EC29893@se-excur01-uslj.nadi.uslj>
Message-ID: <Pine.LNX.4.31.0112280820330.14954-100000@gannet.stats>

On Thu, 27 Dec 2001 yiping.fan at syngenta.com wrote:

> Hello,
>    I have a perl program which produces the input. Instead of print it to a
> file then let R read the file,
> I want to let R to read the input directly from the perl output,
>
> I am using  a PERL IPC::open2 module for this,
>
> local (*Read,*Writer);
> $pid = open2(\*Read, \*Writer, "R --no-save --slave< my.R")
>
> #input to R
> for(){
>   print Writer data;
> }
> close Writer;
>
> #R output
> @result = <Read>;
>
>
> How can "my.R"  read the stdin and figure out the relationship in the data?
> I tried realLines(), does not work.  Thank you very much for your help!!

It can't. You redirected the stdin of R to be the file my.R, and in any
Unix-alike OS that leaves the previous stdin unused.

You would do better to use the connections functions in R to read from a
fifo, and write your perl output to that fifo.


Next time please tell us your OS, R version and what exactly you did and
how it does not work.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lancelot at sentoo.sn  Fri Dec 28 09:42:52 2001
From: lancelot at sentoo.sn (Renaud Lancelot)
Date: Fri, 28 Dec 2001 08:42:52 +0000
Subject: [R] new lattice/grid
References: <OF4CF9FAD4.68E4559C-ON86256B2F.006D2EE7@mmm.com>
Message-ID: <3C2C308C.3ABF6537@sentoo.sn>

No problem for me:

>   version
         _              
platform i386-pc-mingw32
arch     x86            
os       Win32          
system   x86, Win32     
status                  
major    1              
minor    4.0            
year     2001           
month    12             
day      19             
language R              
>

I installed R from Pr Ripley's website following his message last week.

Renaud

apjaworski at mmm.com wrote:
> 
> I just installed R-1.4.0 on my Win2k machine from SetupR.exe.  Everything
> seems to be fine with the base and recommended packages.  However, when I
> install the lattice and grid packages they do not seem to work.  Everything
> I try results in something like this:
> 
>      Instruction 0x00543f06 refernced memory 0x00000000.  The memory cannot
> be "read".
> 
> and I am getting kicked out of R.
> 
> Has anyone experienced this or is it just me?
> 
> Andy
> 
> PS.    I used install.packages menu item to install lattice and grid from
> the main CRAN site.
> 
> __________________________________
> Andy Jaworski
> Engineering Systems Technology Center
> 3M Center, 518-1-01
> St. Paul, MN 55144-1000
> -----
> E-mail: apjaworski at mmm.com
> Tel:  (651) 733-6092
> Fax:  (651) 736-3122
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Dr Renaud Lancelot, v?t?rinaire
CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
Programme Productions Animales
http://www.cirad.fr/presentation/programmes/prod-ani.shtml (Fran?ais)
http://www.cirad.fr/presentation/en/program-eng/prod-ani.shtml (English)

ISRA-LNERV                      tel    (221) 832 49 02
BP 2057 Dakar-Hann              fax    (221) 821 18 79 (CIRAD)
Senegal                         e-mail renaud.lancelot at cirad.fr
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgrandeau at free.fr  Fri Dec 28 13:58:06 2001
From: pgrandeau at free.fr (Pascal Grandeau)
Date: Fri, 28 Dec 2001 13:58:06 +0100
Subject: [R] Problems with arima0
Message-ID: <BOECJIPDBPNKIFOLLIKIOECJCCAA.pgrandeau@free.fr>

I use R 1.3.1 and now R 1.4.0 under Windows 98 and 2000 and I have some
problems with arima0.

I made an example : it is just for test (it is zipped in the attached file
modelfr2.zip. The file is in the french csv format with sep= ";" and
dec=".", so I use read.csv2).

I want to do a regression with ARMA (p=1; q=3) errors of the first column
(sendout) on the other (the second column which is the constant is useless),
so this is what I do with R :

> dd<-read.csv2("c:/modelfr2.csv")
> names(dd)     # Just to verify !
 [1] "sendout"         "cste"            "TempLT17"        "lag2"
 [5] "We"              "hivergaz"        "lag7"            "octobre"
 [9] "vendredi"        "Tmoycarre"       "Tmaxi"           "avril"
[13] "TempGT17"        "vacances"        "Lineartrend"     "TempLT171"
[17] "feriesemaine"    "vacoct"          "MoistransT17"    "jeudi"
[21] "mercredi"        "Tmoycarre1"      "WET17"           "vacdec"
[25] "MoistransTnx"    "septembre"       "MoistransDeltaT" "MoistransDTmax"
[29] "Rechauffement"   "samedi"          "janvier"         "automne"
[33] "periode"         "quadratrend"     "aout"            "tempeff"
[37] "MoistransDTmin"  "MoistransTmin"   "hiver"           "juin"

> ari<-arima0(dd[,1],xreg=as.matrix(dd[,-1:-2]),order=c(1,0,3))

> ari$coef
            ar1             ma1             ma2             ma3
intercept
   2.201316e-01    3.206251e-01    3.500737e-02
 2.473141e-02   -5.018293e+06
       TempLT17            lag2              We        hivergaz
lag7
   1.028222e+06    2.917059e-01   -1.566802e+06    2.566452e+06
9.574060e-02
        octobre        vendredi       Tmoycarre           Tmaxi
avril
  -2.295546e+06   -8.999837e+05
 2.736549e+04   -1.100721e+05   -2.612360e+06
       TempGT17        vacances     Lineartrend       TempLT171
feriesemaine
  -1.010776e+06   -1.454308e+05   -1.081656e+07
 2.542789e+05   -9.502527e+05
         vacoct    MoistransT17           jeudi        mercredi
Tmoycarre1
   4.843674e+05
 3.627698e+05   -5.517601e+05   -4.267915e+05   -6.751992e+03
          WET17          vacdec    MoistransTnx       septembre
MoistransDeltaT
  -3.878577e+04   -5.872619e+05    6.298442e+03   -3.339184e+06
3.031612e+05
 MoistransDTmax   Rechauffement          samedi         janvier
automne
  -1.019058e+05    1.479148e+05   -2.047690e+05   -1.078147e+06
4.288875e+05
        periode     quadratrend            aout         tempeff
MoistransDTmin
  -3.476783e+04    1.109006e+07   -2.105259e+05
 3.437851e+05   -6.411536e+04
  MoistransTmin           hiver            juin
   1.043679e+05   -2.434158e+05    1.215601e+05

> ari$code
[1] 0

> diag(ari$var.coef)
            ar1             ma1             ma2             ma3
intercept
   3.132705e-01    3.117503e-01    8.869646e-02
 6.965824e-03   -1.046849e+06
       TempLT17            lag2              We        hivergaz
lag7
   1.171641e+07    9.928982e-05    1.214256e+07    3.898401e+06
9.109221e-05
        octobre        vendredi       Tmoycarre           Tmaxi
avril
   3.532436e+07    3.095100e+06    1.722773e+05    7.896726e+05
2.289079e+07
       TempGT17        vacances     Lineartrend       TempLT171
feriesemaine
   5.674179e+06   -5.124374e+05    9.341290e+05
 4.346287e+06   -4.689245e+06
         vacoct    MoistransT17           jeudi        mercredi
Tmoycarre1
   5.112234e+05    6.510381e+05   -6.286289e+05    2.762435e+06
2.200297e+05
          WET17          vacdec    MoistransTnx       septembre
MoistransDeltaT
   1.511598e+06    1.423986e+06    1.284414e+05    3.616154e+07
6.749349e+05
 MoistransDTmax   Rechauffement          samedi         janvier
automne
   3.733944e+06    4.233166e+06   -1.137565e+06   -1.455328e+06
4.870733e+06
        periode     quadratrend            aout         tempeff
MoistransDTmin
   1.214202e+05   -6.837660e+05   -1.292829e+06    1.243424e+07
2.729197e+07
  MoistransTmin           hiver            juin
   5.775706e+06    6.265115e+06   -9.041021e+06

> ari<-arima0(dd[,1],xreg=as.matrix(dd[,-1:-2]),order=c(1,0,3),delta=-1)

> ari$coef
            ar1             ma1             ma2             ma3
intercept
   2.209774e-01    3.197254e-01    3.456447e-02
 2.639046e-02   -5.018293e+06
       TempLT17            lag2              We        hivergaz
lag7
   1.028222e+06    2.916751e-01   -1.566802e+06    2.566452e+06
9.576419e-02
        octobre        vendredi       Tmoycarre           Tmaxi
avril
  -2.295546e+06   -8.999837e+05
 2.736549e+04   -1.100721e+05   -2.612360e+06
       TempGT17        vacances     Lineartrend       TempLT171
feriesemaine
  -1.010776e+06   -1.454308e+05   -1.081656e+07
 2.542789e+05   -9.502527e+05
         vacoct    MoistransT17           jeudi        mercredi
Tmoycarre1
   4.843674e+05
 3.627698e+05   -5.517601e+05   -4.267915e+05   -6.751992e+03
          WET17          vacdec    MoistransTnx       septembre
MoistransDeltaT
  -3.878577e+04   -5.872619e+05    6.298442e+03   -3.339184e+06
3.031612e+05
 MoistransDTmax   Rechauffement          samedi         janvier
automne
  -1.019058e+05    1.479148e+05   -2.047690e+05   -1.078147e+06
4.288875e+05
        periode     quadratrend            aout         tempeff
MoistransDTmin
  -3.476783e+04    1.109006e+07   -2.105259e+05
 3.437851e+05   -6.411536e+04
  MoistransTmin           hiver            juin
   1.043679e+05   -2.434158e+05    1.215601e+05

> ari$code
[1] 0

> diag(ari$var.coef)
            ar1             ma1             ma2             ma3
intercept
   2.984138e-01    2.971397e-01    8.488563e-02    6.717204e-03
1.976934e+06
       TempLT17            lag2              We        hivergaz
lag7
   7.650781e+05    9.506931e-05    2.345793e+06    9.386527e+05
8.919501e-05
        octobre        vendredi       Tmoycarre           Tmaxi
avril
  -7.568479e+05    3.492818e+05    1.299257e+05   -2.127121e+05
3.733916e+06
       TempGT17        vacances     Lineartrend       TempLT171
feriesemaine
  -9.460373e+05    1.194900e+06    4.093315e+05    9.296041e+05
2.080155e+06
         vacoct    MoistransT17           jeudi        mercredi
Tmoycarre1
   2.358321e+06    1.698256e+06    9.177695e+05    1.282622e+06
1.686617e+05
          WET17          vacdec    MoistransTnx       septembre
MoistransDeltaT
  -4.289835e+04    2.335913e+06    1.251494e+05
 1.733809e+06   -9.864234e+05
 MoistransDTmax   Rechauffement          samedi         janvier
automne
   1.854713e+06    2.666766e+05    4.113436e+04    4.021349e+05
6.950620e+04
        periode     quadratrend            aout         tempeff
MoistransDTmin
   1.000572e+05    1.266920e+06    1.743747e+04    1.754632e+06
2.770144e+06
  MoistransTmin           hiver            juin
   6.929513e+05    6.794158e+05    2.348674e+05
>


So, I get negatives values for diag(ari$var.coef) but the convergence seems
good : ari$code=0 !

I try the same thing with SAS, with the procedure :

PROC ARIMA DATA=WORK._egtemp_;
	IDENTIFY
		VAR=sendout crosscor=(TempLT17 lag2 We hivergaz lag7 octobre vendredi
Tmoycarre Tmaxi avril TempGT17 vacances Lineartrend TempLT171 feriesemaine
vacoct MoistransT17 jeudi mercredi Tmoycarre1 WET17 vacdec MoistransTnx
septembre MoistransDeltaT MoistransDTmax Rechauffement samedi janvier
automne periode quadratrend aout tempeff MoistransDTmin MoistransTmin hiver
juin)
		;
	ESTIMATE
	    	METHOD=ML
		MAXITER=150
		P=(1)
		Q=(1,2,3)
		input=(TempLT17 lag2 We hivergaz lag7 octobre vendredi Tmoycarre Tmaxi
avril TempGT17 vacances Lineartrend TempLT171 feriesemaine vacoct
MoistransT17 jeudi mercredi Tmoycarre1 WET17 vacdec MoistransTnx septembre
MoistransDeltaT MoistransDTmax Rechauffement samedi janvier automne periode
quadratrend aout tempeff MoistransDTmin MoistransTmin hiver juin)
		;
	FORECAST
		ID=Date
		INTERVAL = DAY
		;
RUN;


and here are the results :


Maximum Likelihood Estimation
Parameter	Estimate	Standard Error	t Value	Approx	Lag	Variable	Shift
							Pr>|t|
MU		5677704.9	4178966.3	1.36	0.1743	0	sendout		0
MA1,1		0.13339	0.04068	3.28	0.0010	1	sendout		0
MA1,2		0.31361	0.04518	6.94	<.0001	2	sendout		0
MA1,3		0.12087	0.03985	3.03	0.0024	3	sendout		0
AR1,1		0.98183	0.0090420	108.59	<.0001	1	sendout		0
Intercept	914801.6	31603.0	28.95	<.0001	0	TempLT17	0
NUM2		0.08117	0.02464	3.29	0.0010	0	lag2		0
NUM3		-1260988.9	82649.5	-15.26	<.0001	0	We		0
NUM4		1883728.1	444508.7	4.24	<.0001	0	hivergaz	0
NUM5		0.04916	0.01524	3.23	0.0013	0	lag7		0
NUM6		-1291028.7	678103.9	-1.90	0.0569	0	octobre		0
NUM7		-537376.7	86014.1	-6.25	<.0001	0	vendredi	0
NUM8		20164.3	1676.0	12.03	<.0001	0	Tmoycarre	0
NUM9		-72794.9	14816.2	-4.91	<.0001	0	Tmaxi		0
NUM10		-1735412.6	550555.1	-3.15	0.0016	0	avril		0
NUM11		-777787.6	74365.4	-10.46	<.0001	0	TempGT17	0
NUM12		-176589.8	146977.0	-1.20	0.2296	0	vacances	0
NUM13		-21270415	5072492.7	-4.19	<.0001	0	Lineartrend	0
NUM14		144286.3	29856.4	4.83	<.0001	0	TempLT171	0
NUM15		-746670.3	101013.5	-7.39	<.0001	0	feriesemaine	0
NUM16		143734.4	291312.3	0.49	0.6217	0	vacoct		0
NUM17		197695.0	45790.1	4.32	<.0001	0	MoistransT17	0
NUM18		-180919.2	83234.9	-2.17	0.0297	0	jeudi		0
NUM19		-104867.0	67638.4	-1.55	0.1210	0	mercredi	0
NUM20		2414.5	1067.0	2.26	0.0236	0	Tmoycarre1	0
NUM21		-38796.3	8825.9	-4.40	<.0001	0	WET17		0
NUM22		-890757.8	322913.6	-2.76	0.0058	0	vacdec		0
NUM23		2390.4	1859.2	1.29	0.1985	0	MoistransTnx	0
NUM24		-1688542.1	680933.2	-2.48	0.0131	0	septembre	0
NUM25		193932.8	41955.6	4.62	<.0001	0	MoistransDeltaT	0
NUM26		-59055.8	18549.9	-3.18	0.0015	0	MoistransDTmax	0
NUM27		108044.1	43874.8	2.46	0.0138	0	Rechauffement	0
NUM28		-163420.7	54042.0	-3.02	0.0025	0	samedi		0
NUM29		-231656.4	350368.4	-0.66	0.5085	0	janvier		0
NUM30		662353.6	285263.7	2.32	0.0202	0	automne		0
NUM31		-59281.8	14180.1	-4.18	<.0001	0	periode		0
NUM32		21225993	5095024.2	4.17	<.0001	0	quadratrend	0
NUM33		-120509.9	315387.3	-0.38	0.7024	0	aout		0
NUM34		-65665.9	54566.7	-1.20	0.2288	0	tempeff		0
NUM35		-26494.1	17907.6	-1.48	0.1390	0	MoistransDTmin	0
NUM36		45824.8	46569.2	0.98	0.3251	0	MoistransTmin	0
NUM37		480699.1	289296.2	1.66	0.0966	0	hiver		0
NUM38		210529.4	248285.9	0.85	0.3965	0	juin		0

and the results seems good but are very differents.

I try then another tool which is Matrixer and I got almost the same results
than with SAS.

Finally, with S-Plus 4.5 and arima.mle, I got also almost the same results
than with SAS.

Certainly I did not understood the use of arima0 because something seems to
go wrong.

Another problem is if I put transform.pars=1 then R crash under Windows :
error in ts.dll.

Please can you explain me how I can make a regression with ARMA errors with
R and get
the coefficientd and the estimations of standard errors for the
coefficients.

Maybe I can do this with dse but I did not well understood how to define the
problem with dse.

Thank you very much.

Pascal Grandeau
-------------- next part --------------
A non-text attachment was scrubbed...
Name: modelfr2.zip
Type: application/x-compressed
Size: 31602 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20011228/137ffbf6/modelfr2.bin

From brianscholl1973 at yahoo.com  Fri Dec 28 16:45:14 2001
From: brianscholl1973 at yahoo.com (Brian Scholl)
Date: Fri, 28 Dec 2001 07:45:14 -0800 (PST)
Subject: [R] TS code anyone?
In-Reply-To: <Pine.LNX.4.31.0112232121150.30244-100000@gannet.stats>
Message-ID: <20011228154514.74647.qmail@web12207.mail.yahoo.com>

Hi, 

I'm looking for some time series code that I imagine
someone has already coded at some point - I looked
through the available packages on CRAN and couldn't
find any of these (so I apologize in advance if I've
overlooked something).  Even if you might have some
code that isn't necessarily package-ready, it could be
helpful to have.

I'm looking for the following:

1. Bispectrum, and tests for linearity and
non-centrality as per Subba Rao and Gabr (1984,
p120-130) (or some way of doing an analysis of series
linearity, along with some measure of uncertainty).

2. Pre-whitened Autoregressive spectrum estimator as
per Brillinger (1981, p266).  I'm looking to do this
in the case of multiple series and I'm hoping to get
confidence intervals or some sort of measure of
uncertainty. 

3. Computing and plotting gain of a filter.   I tried
altering the code of spec.pgram and plot.spec.phase to
compute and plot the gain of a filter, and it seems to
work correctly.  But my confidence intervals (from
Koopmans 1974) don't seem to be working properly so
I'm pretty sure I've coded something wrong (the CI's
are basically the same as the gain estimate).  This is
my code for the CI's 

coh <-x$coh[,ind]
fkk<-x$pgram[,j,j]
fjj<-x$pgram[,i,i]
frac<-(fkk*(1-coh))/((spans-1)*fjj)
Fstat<-qf(ci,2,2*spans-2)
cl<-sqrt(frac*Fstat)	

where spans is the width of the smoothing window and
pgram is the cross periodogram estimate, both being
passed (along with the gain) in my altered code as
part of the list in my version of spec.pgram.  

Any help would be appreciated on these matters.  

Brian

__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From apjaworski at mmm.com  Fri Dec 28 17:08:45 2001
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Fri, 28 Dec 2001 10:08:45 -0600
Subject: [R] new lattice/grid
Message-ID: <OF8F5AE8F1.52442A28-ON86256B30.00578ECE@mmm.com>

On Fri, 28 Dec 2001 ripley at stats.ox.ac.uk wrote:

>On Thu, 27 Dec 2001 apjaworski at mmm.com wrote:
>
>> I just installed R-1.4.0 on my Win2k machine from SetupR.exe.
Everything
>> seems to be fine with the base and recommended packages.  However, when
I
>> install the lattice and grid packages they do not seem to work.
Everything
>> I try results in something like this:
>>
>>      Instruction 0x00543f06 refernced memory 0x00000000.  The memory
cannot
>> be "read".
>>
>> and I am getting kicked out of R.
>>
>> Has anyone experienced this or is it just me?
>>
>> Andy
>>
>> PS.    I used install.packages menu item to install lattice and grid
from
>> the main CRAN site.
>
> I see that on the version compiled by Guido Masarotto, but not on the one
> I compiled, which works correctly.  You didn't of course tell us where
you
> got SetupR.exe from!
>
> I suggest you compile from the sources yourself.
>
I am sorry for the confusion.  When in my PS I said the main CRAN site I
really meant  the site Guido Masarotto pointed to in his recent
announcement (sirio.stat.unipd.it/RWin).

I just reinstalled R-1.4.0 from Professor Ripley's binaries and indeed
lattice/grid now work.

Thanks again,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgrandeau at free.fr  Fri Dec 28 17:22:08 2001
From: pgrandeau at free.fr (Pascal Grandeau)
Date: Fri, 28 Dec 2001 17:22:08 +0100
Subject: [R] Problems with arima0 (almost solved)
Message-ID: <BOECJIPDBPNKIFOLLIKIMECKCCAA.pgrandeau@free.fr>

I think I found what was wrong : if I do scaling on the matices y and xreg,
all seems good. Here is what I do :

> dd<-read.csv2("c:/modelfr2.csv")
> y<-dd[,1]
> x<-dd[,-1:-2]
> x1<-scale(x)
> y1<-scale(as.matrix(as.double(y)))
> ari<-arima0(y1,xreg=as.matrix(x1),order=c(1,0,3))

and I got :

> ari$coef
            ar1             ma1             ma2             ma3
intercept

0.981959774    -0.133513133    -0.313765424    -0.120906582    -0.014087163
       TempLT17            lag2              We        hivergaz
lag7
    0.595713158     0.081242497    -0.074302282     0.121198338
0.049151266
        octobre        vendredi       Tmoycarre           Tmaxi
avril
   -0.046997365    -0.024616056
 0.401650456    -0.067899417    -0.062226297
       TempGT17        vacances     Lineartrend       TempLT171
feriesemaine
   -0.174204375    -0.010849255    -1.593994601
 0.094049181    -0.015111721
         vacoct    MoistransT17           jeudi        mercredi
Tmoycarre1
    0.002894903     0.066673677    -0.008290431    -0.004808032
0.048113321
          WET17          vacdec    MoistransTnx       septembre
MoistransDeltaT
   -0.018610689    -0.021541452     0.028866118    -0.060574403
0.024856178
 MoistransDTmax   Rechauffement          samedi         janvier
automne
   -0.011687046     0.004914881    -0.007455964    -0.008352493
0.037430983
        periode     quadratrend            aout         tempeff
MoistransDTmin
   -0.812194507
 1.614215908    -0.004387879    -0.050769121    -0.005031441
  MoistransTmin           hiver            juin
    0.026752595     0.027127835     0.007552805


> sqrt(diag(ari$var.coef))
            ar1             ma1             ma2             ma3
intercept
    0.010172128     0.042899460     0.051893431     0.039494948
0.057324206
       TempLT17            lag2              We        hivergaz
lag7
    0.020040066     0.027233295     0.004830991     0.028450063
0.015719575
        octobre        vendredi       Tmoycarre           Tmaxi
avril
    0.023873606     0.003941548     0.033016873     0.013613845
0.019573895
       TempGT17        vacances     Lineartrend       TempLT171
feriesemaine
    0.016457262     0.008907412     0.401197993     0.020490511
0.002024213
         vacoct    MoistransT17           jeudi        mercredi
Tmoycarre1
    0.005764023     0.015146301     0.003811101     0.003136478
0.021529475
          WET17          vacdec    MoistransTnx       septembre
MoistransDeltaT
    0.004133053     0.007681165     0.021842469     0.023770587
0.005238365
 MoistransDTmax   Rechauffement          samedi         janvier
automne
    0.003566694     0.001953077     0.002418192     0.012942518
0.015704967
        periode     quadratrend            aout         tempeff
MoistransDTmin
    0.208897607     0.413539315     0.011196934     0.043177465
0.003314960
  MoistransTmin           hiver            juin
    0.026484594     0.016473332     0.008654350

The only problem now is : how can I retrieve now the true coefficients and
the true se for the non scaled regressors and intercept ?

Can anyone help me ?

Thank you very much.

Pascal Grandeau

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kevin.wright at pioneer.com  Fri Dec 28 18:08:40 2001
From: kevin.wright at pioneer.com (Wright, Kevin)
Date: Fri, 28 Dec 2001 11:08:40 -0600
Subject: [R] Re: new lattice/grid
Message-ID: <C71CB7425639D311A7A40008C7286AB0037EA983@carina.phibred.com>


I'm using Windows 95.  When I installed the version of R compiled by Guido
Masarotto, I was unable to use lattice functions *at all*.  (I don't think
that plot history was correlated to my crashes.)  When I installed the
version compiled by Brian Ripley, I was able to use the lattice library
again.

Here are a few clues for the curious:

1. I created a plot(1:2,1:2) and then typed library(grid) - this caused a
crash.
2. I re-started R, typed "library(lattice)" and then issued an xyplot
command - this caused a crash.

Kevin Wright, Research Scientist
Pioneer Hi-Bred Int'l, x4054.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From smalladi at lexgen.com  Fri Dec 28 21:45:34 2001
From: smalladi at lexgen.com (Sukhaswami Malladi)
Date: Fri, 28 Dec 2001 14:45:34 -0600
Subject: [R] Testing for a Regression Model
Message-ID: <80A38867B1DBD511A8C9009027764C8C3795A2@lexchange.lexgen.com>

Hello again,

The question this time is using R how does one run a regression model and
plot residuals on 
tabular data having columns x, G, A, S where x is the independent variable.
The model is of the form 
y = b + G + A + S + GA + GS + AS + epsilon

Thanks in advance
swami


*************************************************************************** 
 The contents of this communication are intended only for the addressee and
may contain confidential and/or privileged material. If you are not the
intended recipient, please do not read, copy, use or disclose this
communication and notify the sender.  Opinions, conclusions and other
information in this communication that do not relate to the official
business of my company shall be understood as neither given nor endorsed by
it.  
*************************************************************************** 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Liu.Chunhua at epamail.epa.gov  Fri Dec 28 23:18:53 2001
From: Liu.Chunhua at epamail.epa.gov (Liu.Chunhua@epamail.epa.gov)
Date: Fri, 28 Dec 2001 17:18:53 -0500
Subject: [R] bug in the new version R1040
Message-ID: <OF327D0624.FABF9BD8-ON85256B30.0079E842@rtp.epa.gov>

Hi,

I just downloaded the latest version of R - 1040. I'm doing the project
of converting CATREG - a statistical software writen in S Plus to R.
However, when I copied my R codes to the 1040 bin directory and resource
my codes, I got the following error message, this never happened in my
1030 or 1010 versions of R. Anyone one know what's wrong with 1040?

THanks

CHarlie Liu
EPA/ECO Associate.


source("C:/Program Files/R/rw1040/bin/Winstall.R")
Error in file(file, "r") : cannot open file `winplot.R'
>

in my Winstall.R, I source 'winplot.R'

#source("plot.R")
source("winplot.R")

 BTW, all my R source codes files are in the same directory - bin.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vograno at arbitrade.com  Sat Dec 29 00:10:34 2001
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Fri, 28 Dec 2001 17:10:34 -0600
Subject: [R] flattening return value of tapply
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23D6DF@jupiter.arbitrade.com>

Dear R-Users,

Does anyone know how to flatten, i.e. convert to a table, a return value of
tapply when its INDEX argument is a list? Here is an example of what I need

> x <- rnorm(100)
> f1 <- rep(c(T,F),50)
> f2 <- c(rep(T,50), rep(F,50))
> y <- tapply(x, list(f1=f1,f2=f2), summary)
> y
       f2
f1      FALSE       TRUE       
  FALSE "Numeric,6" "Numeric,6"
  TRUE  "Numeric,6" "Numeric,6"

# I'd like 'y' to be printed as a table with rows corresponding to factor
combinations.
# The closest I could get to it is this
> t(sapply(y, I))
       Min. 1st Qu.  Median     Mean 3rd Qu.  Max.
[1,] -1.616 -0.5475 0.17450  0.26030  0.9742 2.117
[2,] -2.038 -0.8990 0.02546 -0.13390  0.2461 1.874
[3,] -2.344 -0.5494 0.07578  0.02965  0.5424 1.974
[4,] -1.660 -0.4915 0.41760  0.17750  0.9652 1.629

but this doesn't produce meaningful row names.

Any suggestion?

Thank you,
Vadim

-------------------------------------------------- 
DISCLAIMER 
This e-mail, and any attachments thereto, is intended only for use by the
addressee(s) named herein and may contain legally privileged and/or
confidential information.  If you are not the intended recipient of this
e-mail, you are hereby notified that any dissemination, distribution or
copying of this e-mail, and any attachments thereto, is strictly prohibited.
If you have received this e-mail in error, please immediately notify me and
permanently delete the original and any copy of any e-mail and any printout
thereof. 

E-mail transmission cannot be guaranteed to be secure or error-free.  The
sender therefore does not accept liability for any errors or omissions in
the contents of this message which arise as a result of e-mail transmission.

NOTICE REGARDING PRIVACY AND CONFIDENTIALITY 

Knight Trading Group may, at its discretion, monitor and review the content
of all e-mail communications. 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From adavis at saipan.com  Sat Dec 29 00:57:24 2001
From: adavis at saipan.com (Alan Davis)
Date: Sat, 29 Dec 2001 09:57:24 +1000
Subject: [R] Simple:: usage of stem() and hist()?
Message-ID: <20011229095724.15fd65d9.adavis@saipan.com>

I must apologize in advance for asking a simple question.  I am sure that a clue will be sufficient to get this show on the road.  I am trying to graph tide prediction data in various ways.  I haven't been able to answer this question after pouring over TFM.  

I read the datafile
      theight <- read.table("tides",header=TRUE)

I do get a summary() or fivenum() 
      summary(theight)
      fivenum(theight)

But when I run
      stem(theight), I receive CONSISTENTLY the following message, no matter when I have done: 

      > stem(theight)
      Error in stem(theight) : stem: x must be numeric

The file looks like this:
 Height
 0.225970
 0.141066
 0.058758
 -0.020346
 -0.095795
 -0.167275
 -0.234242
 -0.296408
 -0.353290
 -0.404554
 -0.450036
 -0.489219
 -0.521996
 -0.548133
 -0.567431
 ... 
 etc

Perhaps there is some manipulation necessary to make the data into a vector, but it isn't obvious to me what to do. 

Thank you for any clue whatsoever.  

Alan Davis
Marianas High School
-- 
adavis at saipan.com                                     1-670-322-6580
    Alan E. Davis,  PMB 30, Box 10006, Saipan, MP 96950-8906, CNMI

I have steadily endeavored to keep my mind free, so as to give up any
hypothesis, however much beloved -- and I cannot resist forming one 
on every subject -- as soon as facts are shown to be opposed to it.  
                                  -- Charles Darwin (1809-1882)

  
 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sat Dec 29 01:16:18 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Dec 2001 01:16:18 +0100
Subject: [R] Simple:: usage of stem() and hist()?
In-Reply-To: <20011229095724.15fd65d9.adavis@saipan.com>
References: <20011229095724.15fd65d9.adavis@saipan.com>
Message-ID: <x2n102c23x.fsf@blueberry.kubism.ku.dk>

Alan Davis <adavis at saipan.com> writes:

> I must apologize in advance for asking a simple question.  I am sure that a clue will be sufficient to get this show on the road.  I am trying to graph tide prediction data in various ways.  I haven't been able to answer this question after pouring over TFM.  
> 
> I read the datafile
>       theight <- read.table("tides",header=TRUE)
> 
> I do get a summary() or fivenum() 
>       summary(theight)
>       fivenum(theight)
> 
> But when I run
>       stem(theight), I receive CONSISTENTLY the following message, no matter when I have done: 
> 
>       > stem(theight)
>       Error in stem(theight) : stem: x must be numeric
> 
> The file looks like this:
>  Height
>  0.225970
>  0.141066
>  0.058758
>  -0.020346
>  -0.095795
>  -0.167275
>  -0.234242
>  -0.296408
>  -0.353290
>  -0.404554
>  -0.450036
>  -0.489219
>  -0.521996
>  -0.548133
>  -0.567431
>  ... 
>  etc
> 
> Perhaps there is some manipulation necessary to make the data into a vector, but it isn't obvious to me what to do. 
> 
> Thank you for any clue whatsoever.  


Try stem(theight$Height)

(read.table() returns a data frame. It could have multiple columns.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From marimont at nxpdata.com  Sat Dec 29 04:56:33 2001
From: marimont at nxpdata.com (David Marimont)
Date: Fri, 28 Dec 2001 19:56:33 -0800
Subject: [R] load in 1.4.0 not working for me
Message-ID: <3C2D3EF1.8050007@nxpdata.com>

I'm having trouble with save and load in R 1.4.0 (on RH 7.2) I originally
noticed this with a large R object, but it happens with a tiny one as well:

   > a <- c(1,2,3)
   > save(a,file="test.RData")
   > a1 <- load("test.RData")
   > print(a1)
   NULL

The file "test.RData" is created, and it does have something in it.  When
I tried saving a large object, I watched what was happening with xosview,
and there is some serious disk-writing happening.  When I tried loading,
there is some serious disk-reading happening.  But no object is returned.
Am I missing something obvious here?  Thanks.

   David Marimont


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Dec 29 09:18:57 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 29 Dec 2001 08:18:57 +0000 (GMT)
Subject: [R] bug in the new version R1040
In-Reply-To: <OF327D0624.FABF9BD8-ON85256B30.0079E842@rtp.epa.gov>
Message-ID: <Pine.LNX.4.31.0112290811410.17691-100000@gannet.stats>

1) There is no version R1040.  It is 1.4.0.

2) Don't use the bin directory, set the working directory as described
in the rw-FAQ.  You can find it inside R by getwd().

3) Please read the section in the FAQ about reporting bugs. There is no
way we can reproduce your problem, even if it were a bug in R as you
assert.

On Fri, 28 Dec 2001 Liu.Chunhua at epamail.epa.gov wrote:

> Hi,
>
> I just downloaded the latest version of R - 1040. I'm doing the project
> of converting CATREG - a statistical software writen in S Plus to R.
> However, when I copied my R codes to the 1040 bin directory and resource
> my codes, I got the following error message, this never happened in my
> 1030 or 1010 versions of R. Anyone one know what's wrong with 1040?
>
> THanks
>
> CHarlie Liu
> EPA/ECO Associate.
>
>
> source("C:/Program Files/R/rw1040/bin/Winstall.R")
> Error in file(file, "r") : cannot open file `winplot.R'
> >
>
> in my Winstall.R, I source 'winplot.R'
>
> #source("plot.R")
> source("winplot.R")
>
>  BTW, all my R source codes files are in the same directory - bin.
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Sat Dec 29 10:49:46 2001
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sat, 29 Dec 2001 10:49:46 +0100 (CET)
Subject: [R] load in 1.4.0 not working for me
In-Reply-To: <3C2D3EF1.8050007@nxpdata.com>
Message-ID: <Pine.LNX.4.33.0112291045310.25653-100000@tal.stat.umu.se>

On Fri, 28 Dec 2001, David Marimont wrote:

> I'm having trouble with save and load in R 1.4.0 (on RH 7.2) I originally
> noticed this with a large R object, but it happens with a tiny one as well:
> 
>    > a <- c(1,2,3)
>    > save(a,file="test.RData")
>    > a1 <- load("test.RData")
>    > print(a1)
>    NULL

If you try

> a <- c(1,2,3)
> save(a, file="test.RData")
> rm(a)
> load("test.RData")
> a
[1] 1 2 3

it works. It seems as if 'load' has no return value (NULL), but we use it
for its side effect, i.e. reloading datasets. See ?load; no return value 
is specified there.

G?ran 
> 
> The file "test.RData" is created, and it does have something in it.  When
> I tried saving a large object, I watched what was happening with xosview,
> and there is some serious disk-writing happening.  When I tried loading,
> there is some serious disk-reading happening.  But no object is returned.
> Am I missing something obvious here?  Thanks.
> 
>    David Marimont
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From indra_calisto at yahoo.com  Sat Dec 29 19:46:55 2001
From: indra_calisto at yahoo.com (Indrajit SenGupta)
Date: Sun, 30 Dec 2001 00:16:55 +0530
Subject: [R] A question on plotting
Message-ID: <MABBJPBLPNLDIFMIAAOJCEPACCAA.indra_calisto@yahoo.com>

My Mail StationeryI have a question on plotting. Suppose I have two vectors
x and y consisting of equal number of elements. Say x be the observed values
of a time series and y be the fitted values. I would like to plot the two
sets of data on the same graph. How would I go about doing this? If they are
plotted on different graphs but in the same window like one would get if one
used the command scatter.smooth with times series data, that would do too.

Indrajit

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20011230/e65ddbe3/attachment.html

From baron at cattell.psych.upenn.edu  Sat Dec 29 21:05:03 2001
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sat, 29 Dec 2001 15:05:03 -0500 (EST)
Subject: [R] A question on plotting
Message-ID: <200112292005.fBTK53Z18216@cattell.psych.upenn.edu>

>From: "Indrajit SenGupta" <indra_calisto at yahoo.com>
>Subject: [R] A question on plotting
>My Mail StationeryI have a question on plotting. Suppose I have two vectors
>x and y consisting of equal number of elements. Say x be the observed values
>of a time series and y be the fitted values. I would like to plot the two
>sets of data on the same graph. How would I go about doing this? If they are
>plotted on different graphs but in the same window like one would get if one
>used the command scatter.smooth with times series data, that would do too.

To do the two in the same graph:

plot(x)
lines(y)
or
points(y)

or

matplot(cbind(x,y),type="l")

To do separate graphs one above the other:

par(mfrow=c(2,1))
plot(x)
plot(y)

In general, see
?plot
?matplot
?lines
?par

You can do other things like set colors, ranges, axis labels, etc.

Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sat Dec 29 21:50:51 2001
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 29 Dec 2001 21:50:51 +0100
Subject: [R] A question on plotting
References: <MABBJPBLPNLDIFMIAAOJCEPACCAA.indra_calisto@yahoo.com>
Message-ID: <3C2E2CAB.C0AF1D70@statistik.uni-dortmund.de>

> I have a question on plotting. Suppose I have two vectors x and y 
> consisting of equal number of elements.
> Say x be the observed values of a time series and y be the fitted 
> values. I would like to plot the two sets of data on the same graph. 
> How would I go about doing this? If they are plotted on different 
> graphs but in the same window like one would get if one used the 
> command scatter.smooth with times series data, that would do too.

Please, could you specify your question more precisely?

Do you mean two plots (with seperate coordinate systems) or just two
kinds of symbols (colors representing different types of values) in the
same plot? Or .... ?

Nevertheless, whatever you are asking right now, I guess your question
(any kind of multiple plots in one window, if I understand right) is
already answered in

a) An Introduction to R,
b) the FAQs, or
c) the mailing list archives.

But if you want to reproduce the behaviour of the function
scatter.smooth(), simply look into its code, which is really simple to
understand! --- and mainly consists of i)   a call to loess.smooth()
ii)  the plot()
iii) and adding some lines()

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Sun Dec 30 16:43:34 2001
From: kjetilh at umsanet.edu.bo (Kjetilh Halvorsen)
Date: Sun, 30 Dec 2001 11:43:34 -0400 (BOT)
Subject: [R] nlme, grid, lattice: Time mistery
Message-ID: <1259.65.119.23.188.1009727014.squirrel@www.umsanet.edu.bo>

Hola!

This is rw140 on windows 98 (version compiled by Prof Ripley), grid and 
lattice
precompiled from CRAN and nlme compiled by me, all latests versions.

I have a groupedData object papas, and want a summary plot.

plot(papas) is fast but rather uninteresting.
plot(papas, outer=TRUE, aspect="fill") takes about 45 minutes (if it 
doesnt  hang R)
plot(papas, outer=TRUE, key=FALSE, aspect="fill") is again fast.

Why the immense time difference apparently caused by the 
key= argument? (this is a 64MB ram pentium III)


Kjetil Halvorsen


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fenner at cs.pitt.edu  Mon Dec 31 01:02:23 2001
From: fenner at cs.pitt.edu (Mark E. Fenner)
Date: Sun, 30 Dec 2001 19:02:23 -0500 (EST)
Subject: [R] Maximum recursion depth and unique()
Message-ID: <Pine.LNX.4.21.0112301853390.5813-100000@oxygen.cs.pitt.edu>

Two questions:

First, what is R's maximum recursion depth (for function evaluations)?  Is
the value stored in a variable?  Can the value be modified?

Second, I've hacked out a function to take a matrix (array) of data and
return another that is the same except it removes any duplicate
columns.  After doing this I discovered the unique() function and I tried
to use it via apply() to do the same thing my function
"removeduplicates" did.

The closest I came to something that worked was "apply(t, 1, unique)" and
taking the transpose of this result (t is an 2D array).  This
didn't make sense at first; then I realized that the duplication I 
was looking for was a "row by row" duplication.  I don't
think what I have there will work in the general case.  So, does anyone
know how to use "unique" to remove duplicate columns from a 2D data
object?

Regards,
Mark

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec 31 08:23:29 2001
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 31 Dec 2001 07:23:29 +0000 (GMT)
Subject: [R] Maximum recursion depth and unique()
In-Reply-To: <Pine.LNX.4.21.0112301853390.5813-100000@oxygen.cs.pitt.edu>
Message-ID: <Pine.LNX.4.31.0112310719380.26825-100000@gannet.stats>

On Sun, 30 Dec 2001, Mark E. Fenner wrote:

> Two questions:
>
> First, what is R's maximum recursion depth (for function evaluations)?  Is
> the value stored in a variable?  Can the value be modified?

?options says

expressions: sets a limit on the number of nested expressions that will
          be evaluated.  This is especially important on the Macintosh
          since stack overflow is likely if this is set too high. Valid
          values are 25...100000 with default 500.


It is unlikely that you need to increase it if you are using R
efficiently, though.

> Second, I've hacked out a function to take a matrix (array) of data and
> return another that is the same except it removes any duplicate
> columns.  After doing this I discovered the unique() function and I tried
> to use it via apply() to do the same thing my function
> "removeduplicates" did.
>
> The closest I came to something that worked was "apply(t, 1, unique)" and
> taking the transpose of this result (t is an 2D array).  This
> didn't make sense at first; then I realized that the duplication I
> was looking for was a "row by row" duplication.  I don't
> think what I have there will work in the general case.  So, does anyone
> know how to use "unique" to remove duplicate columns from a 2D data
> object?

See unique.data.frame (new in 1.4.0)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at genome.cbs.dtu.dk  Mon Dec 31 14:28:18 2001
From: laurent at genome.cbs.dtu.dk (Laurent Gautier)
Date: Mon, 31 Dec 2001 14:28:18 +0100 (MET)
Subject: [R] Extracting/setting elements from/in a matrix/array
Message-ID: <Pine.SGI.3.95.1011231140943.1405699B-100000@genome.cbs.dtu.dk>


Dear all,


I had to extracts/set elements from/in a matrix. Let say I have two
vectors dim1 and dim2 of indices in the respective two dimensions of a
matrix: I want to extract all the corresponding elements. I the case of a
nxn matrix, dim1 <- 1:n and dim2 <- 1:n would extract the diagonal.

I know one way would be to use the functions 'row' and 'col', but the
matrixes I have are can be rather large. This is probably a detail but
I was looking for something that would avoid be bit more memory
friendly... I have made functions for that purpose but I suspect somebody
already did something (which would be in R, but I could not find it...).
For the sake of avoiding duplication of similar things (hence making code 
more readable), I would be happy to replace it in my code.

Does anybody knows if such things already exists ?


Laurent



Laurent Gautier			CBS, Building 208, DTU
PhD. Student			D-2800 Lyngby,Denmark	
tel: +45 45 25 24 85		http://www.cbs.dtu.dk/laurent

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Mon Dec 31 14:48:51 2001
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 31 Dec 2001 14:48:51 +0100
Subject: [R] Extracting/setting elements from/in a matrix/array
In-Reply-To: <Pine.SGI.3.95.1011231140943.1405699B-100000@genome.cbs.dtu.dk>
References: <Pine.SGI.3.95.1011231140943.1405699B-100000@genome.cbs.dtu.dk>
Message-ID: <15408.27843.303853.578534@gargle.gargle.HOWL>

>>>>> "Laurent" == Laurent Gautier <laurent at genome.cbs.dtu.dk> writes:

    Laurent> Dear all,


    Laurent> I had to extracts/set elements from/in a
    Laurent> matrix. Let say I have two vectors dim1 and dim2 of
    Laurent> indices in the respective two dimensions of a
    Laurent> matrix: I want to extract all the corresponding
    Laurent> elements. I the case of a nxn matrix, dim1 <- 1:n
    Laurent> and dim2 <- 1:n would extract the diagonal.

The solution to your problem has been part of the   S language
for ever :

    mat[ cbind(dim1, dim2) ]

Note that this is mentioned in help("[") and MASS and ...

    Laurent> I know one way would be to use the functions 'row'
    Laurent> and 'col', but the matrixes I have are can be
    Laurent> rather large. This is probably a detail but I was
    Laurent> looking for something that would avoid be bit more
    Laurent> memory friendly... I have made functions for that
    Laurent> purpose but I suspect somebody already did
    Laurent> something (which would be in R, but I could not
    Laurent> find it...).  For the sake of avoiding duplication
    Laurent> of similar things (hence making code more
    Laurent> readable), I would be happy to replace it in my
    Laurent> code.

    Laurent> Does anybody knows if such things already exists ?


    Laurent> Laurent Gautier CBS, Building 208, DTU PhD. Student
    Laurent> D-2800 Lyngby,Denmark tel: +45 45 25 24 85
    Laurent> http://www.cbs.dtu.dk/laurent
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Dec 31 14:51:02 2001
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 31 Dec 2001 14:51:02 +0100
Subject: [R] Extracting/setting elements from/in a matrix/array
In-Reply-To: <Pine.SGI.3.95.1011231140943.1405699B-100000@genome.cbs.dtu.dk>
References: <Pine.SGI.3.95.1011231140943.1405699B-100000@genome.cbs.dtu.dk>
Message-ID: <x2heq7fqgp.fsf@blueberry.kubism.ku.dk>

Laurent Gautier <laurent at genome.cbs.dtu.dk> writes:

> Dear all,
> 
> 
> I had to extracts/set elements from/in a matrix. Let say I have two
> vectors dim1 and dim2 of indices in the respective two dimensions of a
> matrix: I want to extract all the corresponding elements. I the case of a
> nxn matrix, dim1 <- 1:n and dim2 <- 1:n would extract the diagonal.
> 
> I know one way would be to use the functions 'row' and 'col', but the
> matrixes I have are can be rather large. This is probably a detail but
> I was looking for something that would avoid be bit more memory
> friendly... I have made functions for that purpose but I suspect somebody
> already did something (which would be in R, but I could not find it...).
> For the sake of avoiding duplication of similar things (hence making code 
> more readable), I would be happy to replace it in my code.
> 
> Does anybody knows if such things already exists ?

It does:  A[cbind(dim1,dim2)]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hb at maths.lth.se  Mon Dec 31 16:41:33 2001
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Mon, 31 Dec 2001 16:41:33 +0100
Subject: [R] Thanks everyone
Message-ID: <KKEGJOGBELBHDIKPINBMIEAGCJAA.hb@maths.lth.se>

I just would like to say thanks to all the developers and all the people
answering questions posted through this mailinglist. You're doing a great
job!

Happy New Year!

Henrik Bengtsson

Dept. of Mathematical Statistics @ Centre for Mathematical Sciences
Lund Institute of Technology/Lund University, Sweden (+2h UTC)
Office: P316, +46 46 222 9611 (phone), +46 46 222 4623 (fax)
h b @ m a t h s . l t h . s e

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


