From Ngayee.Law at celeradiagnostics.com  Wed Jan  1 00:19:02 2003
From: Ngayee.Law at celeradiagnostics.com (Ngayee J Law)
Date: Wed Jan  1 00:19:02 2003
Subject: [R] Probit Analysis
Message-ID: <OFE917B3FE.7EA90487-ON88256CA0.007FCBEA@pe-c.com>

Hi Andy,

Thanks! glm and dose.p can do exaclty what I want to do. Just a quick
question,
how can I extract the numbers in the glm.dose object created by the dose.p?
My
goal is to calculate a 95% CI for the 'LD50'.

- Jacqueline




                                                                                                                
                    apjaworski at mm                                                                               
                    m.com                To:     "Ngayee J Law" <Ngayee.Law at celeradiagnostics.com>              
                                         cc:     r-help at stat.math.ethz.ch                                       
                    12/31/2002           Subject:     Re: [R] Probit Analysis                                   
                    02:47 PM                                                                                    
                                                                                                                
                                                                                                                





Jacqueline,

This should be a simple application of GLM.  Check the help pages for glm,
family and dose.p in library MASS.  Look at the example at the bottom of
the dose.p help page - it does almost exactly what you need.

Hope this helps,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+---------------------------------->
|         |           "Ngayee J Law"         |
|         |           <Ngayee.Law at celeradiagn|
|         |           ostics.com>            |
|         |           Sent by:               |
|         |           r-help-admin at stat.math.|
|         |           ethz.ch                |
|         |                                  |
|         |                                  |
|         |           12/31/2002 16:17       |
|         |                                  |
|---------+---------------------------------->
  >
-----------------------------------------------------------------------------------------------------------------------------|

  |
|
  |      To:       r-help at stat.math.ethz.ch
|
  |      cc:
|
  |      Subject:  [R] Probit Analysis
|
  >
-----------------------------------------------------------------------------------------------------------------------------|




Hello all,

I have a very simple set of data and I would like to analyze them with
probit analysis.
The data are:

X    Event          Trial
100  8         8
75   8         8
50   6         8
25   4         8
10   2         8
0    0         8

I want to estimate the value of X that will give a 95% hit rate
(Event/Trial) and the corresponding
95% CI. Anyone can offer some help? Thanks!!

- Jacqueline

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From apjaworski at mmm.com  Wed Jan  1 01:38:02 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Wed Jan  1 01:38:02 2003
Subject: [R] Probit Analysis
Message-ID: <OFF6F29251.377B5E75-ON86256CA1.0000B093@mmm.com>

Jacquelin,

Here is an answer to your question wrapped in much longer question of my
own.

Cheers,

Andy

-----------------------------------------------------------------------------------------

Extracting components from complex objects is, in my opinion, not easy to
do unless I am missing something very obvious.  Take the glm.dose object as
an example.  Following the example on the dose.p help page I ran

      zz <- dose.p(budworm.lg0, cf = c(1,3), p = 1:3/4)

Typing zz applies print method to the zz object and shows

                          Dose        SE
      p = 0.25: 2.231264 0.2498235
      p = 0.50: 3.263587 0.2297039
      p = 0.75: 4.295910 0.2746190

If I now want to extract some of the numbers from zz, I have to go through
some hoops.  What I usually do first is

      str(zz)

This gives me

      Class 'glm.dose'  atomic [1:3] 2.23 3.26 4.30
        ..- attr(*, "SE")= num [1:3, 1] 0.250 0.230 0.275
        .. ..- attr(*, "dimnames")=List of 2
       .. .. ..$ : chr [1:3] "p = 0.25:" "p = 0.50:" "p = 0.75:"
        .. .. ..$ : NULL
        ..- attr(*, "p")= num [1:3] 0.25 0.5 0.75

The format of this output is not really described on the str help page, so
I am guessing that what this means is that the "basic" object is a vector
of length 3 with a couple of attributes called SE and p, the SE attribute
having additional nested attribute called dimnames.  We can onfirm that by

      attributes(zz)

giving

      $names
      [1] "p = 0.25:" "p = 0.50:" "p = 0.75:"

      $SE

                   [,1]
       p = 0.25: 0.2498235
       p = 0.50: 0.2297039
       p = 0.75: 0.2746190

      $p
      [1] 0.25 0.50 0.75

      $class
      [1] "glm.dose"

So, If I want to extract the actual dose value from zz I just need

      zz[1]

geting

      p = 0.25:
      2.231264

but if I want to get the first standard error I have to do

      attributes(zz)$SE[1]

getting

      p = 0.25:
      0.2498235


Is this a correct general method of extracting components from complex
objects?  Is there a simpler way?

Thanks in advance and sorry for this longish post, but this is something I
have been having problems with for a long time and it seems that every time
I run into this "extraction problem" I have to reinvent the wheel.

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+---------------------------------->
|         |           "Ngayee J Law"         |
|         |           <Ngayee.Law at celeradiagn|
|         |           ostics.com>            |
|         |                                  |
|         |           12/31/2002 17:18       |
|         |                                  |
|---------+---------------------------------->
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       apjaworski at mmm.com                                                                                           |
  |      cc:       r-help at stat.math.ethz.ch                                                                                     |
  |      Subject:  Re: [R] Probit Analysis                                                                                      |
  >-----------------------------------------------------------------------------------------------------------------------------|




Hi Andy,

Thanks! glm and dose.p can do exaclty what I want to do. Just a quick
question,
how can I extract the numbers in the glm.dose object created by the dose.p?
My
goal is to calculate a 95% CI for the 'LD50'.

- Jacqueline





                    apjaworski at mm

                    m.com                To:     "Ngayee J Law"
<Ngayee.Law at celeradiagnostics.com>
                                         cc:     r-help at stat.math.ethz.ch

                    12/31/2002           Subject:     Re: [R] Probit
Analysis
                    02:47 PM








Jacqueline,

This should be a simple application of GLM.  Check the help pages for glm,
family and dose.p in library MASS.  Look at the example at the bottom of
the dose.p help page - it does almost exactly what you need.

Hope this helps,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+---------------------------------->
|         |           "Ngayee J Law"         |
|         |           <Ngayee.Law at celeradiagn|
|         |           ostics.com>            |
|         |           Sent by:               |
|         |           r-help-admin at stat.math.|
|         |           ethz.ch                |
|         |                                  |
|         |                                  |
|         |           12/31/2002 16:17       |
|         |                                  |
|---------+---------------------------------->
  >
-----------------------------------------------------------------------------------------------------------------------------|


  |
|
  |      To:       r-help at stat.math.ethz.ch
|
  |      cc:
|
  |      Subject:  [R] Probit Analysis
|
  >
-----------------------------------------------------------------------------------------------------------------------------|





Hello all,

I have a very simple set of data and I would like to analyze them with
probit analysis.
The data are:

X    Event          Trial
100  8         8
75   8         8
50   6         8
25   4         8
10   2         8
0    0         8

I want to estimate the value of X that will give a 95% hit rate
(Event/Trial) and the corresponding
95% CI. Anyone can offer some help? Thanks!!

- Jacqueline

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From fharrell at virginia.edu  Wed Jan  1 05:13:09 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed Jan  1 05:13:09 2003
Subject: [R] Updates to Hmisc and Design Libraries
Message-ID: <20021231231409.316635e3.fharrell@virginia.edu>

The Hmisc and Design libraries have been updated respectively to versions 1.4-2 and 1.1-1.  New versions for Linux/Unix/Windows may be obtained from http://hesweb1.med.virginia.edu/biostat/s/library/r .  Web sites for the libraries are http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html and http://hesweb1.med.virginia.edu/biostat/s/Design.html .

Thanks to Xiao Gang Fan for porting the libraries to Windows once again.

I still have not had time to fix details in the documentation that will allow R CMD check to be passed, which would allow me to submit the libraries to CRAN.

Change logs may be obtained from http://hesweb1.med.virginia.edu/biostat/s/library/common

Several bugs have been fixed, and new features added.  In Hmisc, better use as been made of "units" attributes of variables, and units are incorporated into tables and plots produced by summary.formula.  For plots, plotmath is used, especially for annotating plots with test statistics produced by summary(..., test=TRUE).  A "matrix tapply" function (mApply) has been added.  A new LaTeX table formatting option, ctable, has been added to latex.default.  A new function getHdata makes it easy to download and import datasets and their descriptions from our web site.  latex functions were changed to allow file="" to be specified, for inline inclusion of LaTeX code in Sweave.  Problems with sas.get and [.factor have been fixed.  fit.mult.impute was enhanced to compute Rubin's degrees of freedom for t-statistics for scalar parameter tests, as well as to compute a missing information index.

In Design, glmD works much more reliably.  plotmath is now used by plot.Design. Bill Pikounis' <v_bill_pikounis at merck.com> improvements have been incorporated in bootcov to allow both cluster and group to be specified.   offsets now work in lrm when NAs are present, and predict.Design now works with offsets.  bootcov now works with glmD, and  summary and print work for glmD (thanks: Fredrik Lundgren <fredrik.lundgren at norrkoping.mail.telia.com>).  validate.tree had a bug fix.

Extended documentation for the libraries, and an introduction to the S language have been updated also (http://hesweb1.med.virginia.edu/biostat/s/doc/splus.pdf) and now include more R-specific information.

Thanks to those who have reported bugs and fixes, and Happy New Year to all.
---- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From ripley at stats.ox.ac.uk  Wed Jan  1 08:55:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan  1 08:55:04 2003
Subject: [R] Probit Analysis
In-Reply-To: <OFF6F29251.377B5E75-ON86256CA1.0000B093@mmm.com>
Message-ID: <Pine.LNX.4.31.0301010751460.25291-100000@gannet.stats>

I find it easier to

1) Use unclass(zz) rather than str(zz)

and

2) read the appropriate print method, here print.glm.dose, to see how it
extracts the information.

On Tue, 31 Dec 2002 apjaworski at mmm.com wrote:

>
> Jacquelin,
>
> Here is an answer to your question wrapped in much longer question of my
> own.
>
> Cheers,
>
> Andy
>
> -----------------------------------------------------------------------------------------
>
> Extracting components from complex objects is, in my opinion, not easy to
> do unless I am missing something very obvious.  Take the glm.dose object as
> an example.  Following the example on the dose.p help page I ran
>
>       zz <- dose.p(budworm.lg0, cf = c(1,3), p = 1:3/4)
>
> Typing zz applies print method to the zz object and shows
>
>                           Dose        SE
>       p = 0.25: 2.231264 0.2498235
>       p = 0.50: 3.263587 0.2297039
>       p = 0.75: 4.295910 0.2746190
>
> If I now want to extract some of the numbers from zz, I have to go through
> some hoops.  What I usually do first is
>
>       str(zz)
>
> This gives me
>
>       Class 'glm.dose'  atomic [1:3] 2.23 3.26 4.30
>         ..- attr(*, "SE")= num [1:3, 1] 0.250 0.230 0.275
>         .. ..- attr(*, "dimnames")=List of 2
>        .. .. ..$ : chr [1:3] "p = 0.25:" "p = 0.50:" "p = 0.75:"
>         .. .. ..$ : NULL
>         ..- attr(*, "p")= num [1:3] 0.25 0.5 0.75
>
> The format of this output is not really described on the str help page, so
> I am guessing that what this means is that the "basic" object is a vector
> of length 3 with a couple of attributes called SE and p, the SE attribute
> having additional nested attribute called dimnames.  We can onfirm that by
>
>       attributes(zz)
>
> giving
>
>       $names
>       [1] "p = 0.25:" "p = 0.50:" "p = 0.75:"
>
>       $SE
>
>                    [,1]
>        p = 0.25: 0.2498235
>        p = 0.50: 0.2297039
>        p = 0.75: 0.2746190
>
>       $p
>       [1] 0.25 0.50 0.75
>
>       $class
>       [1] "glm.dose"
>
> So, If I want to extract the actual dose value from zz I just need
>
>       zz[1]
>
> geting
>
>       p = 0.25:
>       2.231264
>
> but if I want to get the first standard error I have to do
>
>       attributes(zz)$SE[1]
>
> getting
>
>       p = 0.25:
>       0.2498235
>
>
> Is this a correct general method of extracting components from complex
> objects?  Is there a simpler way?
>
> Thanks in advance and sorry for this longish post, but this is something I
> have been having problems with for a long time and it seems that every time
> I run into this "extraction problem" I have to reinvent the wheel.
>
> Andy
>
> __________________________________
> Andy Jaworski
> Engineering Systems Technology Center
> 3M Center, 518-1-01
> St. Paul, MN 55144-1000
> -----
> E-mail: apjaworski at mmm.com
> Tel:  (651) 733-6092
> Fax:  (651) 736-3122
>
>
> |---------+---------------------------------->
> |         |           "Ngayee J Law"         |
> |         |           <Ngayee.Law at celeradiagn|
> |         |           ostics.com>            |
> |         |                                  |
> |         |           12/31/2002 17:18       |
> |         |                                  |
> |---------+---------------------------------->
>   >-----------------------------------------------------------------------------------------------------------------------------|
>   |                                                                                                                             |
>   |      To:       apjaworski at mmm.com                                                                                           |
>   |      cc:       r-help at stat.math.ethz.ch                                                                                     |
>   |      Subject:  Re: [R] Probit Analysis                                                                                      |
>   >-----------------------------------------------------------------------------------------------------------------------------|
>
>
>
>
> Hi Andy,
>
> Thanks! glm and dose.p can do exaclty what I want to do. Just a quick
> question,
> how can I extract the numbers in the glm.dose object created by the dose.p?
> My
> goal is to calculate a 95% CI for the 'LD50'.
>
> - Jacqueline
>
>
>
>
>
>                     apjaworski at mm
>
>                     m.com                To:     "Ngayee J Law"
> <Ngayee.Law at celeradiagnostics.com>
>                                          cc:     r-help at stat.math.ethz.ch
>
>                     12/31/2002           Subject:     Re: [R] Probit
> Analysis
>                     02:47 PM
>
>
>
>
>
>
>
>
> Jacqueline,
>
> This should be a simple application of GLM.  Check the help pages for glm,
> family and dose.p in library MASS.  Look at the example at the bottom of
> the dose.p help page - it does almost exactly what you need.
>
> Hope this helps,
>
> Andy
>
> __________________________________
> Andy Jaworski
> Engineering Systems Technology Center
> 3M Center, 518-1-01
> St. Paul, MN 55144-1000
> -----
> E-mail: apjaworski at mmm.com
> Tel:  (651) 733-6092
> Fax:  (651) 736-3122
>
>
> |---------+---------------------------------->
> |         |           "Ngayee J Law"         |
> |         |           <Ngayee.Law at celeradiagn|
> |         |           ostics.com>            |
> |         |           Sent by:               |
> |         |           r-help-admin at stat.math.|
> |         |           ethz.ch                |
> |         |                                  |
> |         |                                  |
> |         |           12/31/2002 16:17       |
> |         |                                  |
> |---------+---------------------------------->
>   >
> -----------------------------------------------------------------------------------------------------------------------------|
>
>
>   |
> |
>   |      To:       r-help at stat.math.ethz.ch
> |
>   |      cc:
> |
>   |      Subject:  [R] Probit Analysis
> |
>   >
> -----------------------------------------------------------------------------------------------------------------------------|
>
>
>
>
>
> Hello all,
>
> I have a very simple set of data and I would like to analyze them with
> probit analysis.
> The data are:
>
> X    Event          Trial
> 100  8         8
> 75   8         8
> 50   6         8
> 25   4         8
> 10   2         8
> 0    0         8
>
> I want to estimate the value of X that will give a 95% hit rate
> (Event/Trial) and the corresponding
> 95% CI. Anyone can offer some help? Thanks!!
>
> - Jacqueline
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kjetil at entelnet.bo  Wed Jan  1 13:09:03 2003
From: kjetil at entelnet.bo (Kjetil Brinchmann Halvorsen)
Date: Wed Jan  1 13:09:03 2003
Subject: [R] Probit Analysis
References: <OFE917B3FE.7EA90487-ON88256CA0.007FCBEA@pe-c.com>
Message-ID: <3E123282.000003.02356@personal-apzxmv>

A better option for a confidence interval for LD50
might be Fiellers method. 

To see how to get the numbers from the object returned from dose.p, use for
example
str(object) or names(object).

Kjetil Halvorsen

-------Original Message-------

From: Ngayee J Law
Date: Tuesday, December 31, 2002 7:17:39 PM
To: apjaworski at mmm.com
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Probit Analysis

Hi Andy,

Thanks! glm and dose.p can do exaclty what I want to do. Just a quick
question,
how can I extract the numbers in the glm.dose object created by the dose.p?
My
goal is to calculate a 95% CI for the 'LD50'.

- Jacqueline





apjaworski at mm 
m.com To: "Ngayee J Law" <Ngayee.Law at celeradiagnostics.com> 
cc: r-help at stat.math.ethz.ch 
12/31/2002 Subject: Re: [R] Probit Analysis 
02:47 PM 







Jacqueline,

This should be a simple application of GLM. Check the help pages for glm,
family and dose.p in library MASS. Look at the example at the bottom of
the dose.p help page - it does almost exactly what you need.

Hope this helps,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel: (651) 733-6092
Fax: (651) 736-3122


|---------+---------------------------------->
| | "Ngayee J Law" |
| | <Ngayee.Law at celeradiagn|
| | ostics.com> |
| | Sent by: |
| | r-help-admin at stat.math.|
| | ethz.ch |
| | |
| | |
| | 12/31/2002 16:17 |
| | |
|---------+---------------------------------->
>
-----------------------------------------------------------------------------
-----------------------------------------------|

|
|
| To: r-help at stat.math.ethz.ch
|
| cc:
|
| Subject: [R] Probit Analysis
|
>
-----------------------------------------------------------------------------
-----------------------------------------------|




Hello all,

I have a very simple set of data and I would like to analyze them with
probit analysis.
The data are:

X Event Trial
100 8 8
75 8 8
50 6 8
25 4 8
10 2 8
0 0 8

I want to estimate the value of X that will give a 95% hit rate
(Event/Trial) and the corresponding
95% CI. Anyone can offer some help? Thanks!!

- Jacqueline

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help
.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20030101/a3a7fab6/attachment.html
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 494 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030101/a3a7fab6/attachment.gif
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 1431 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030101/a3a7fab6/attachment.jpe

From stat at estadao.com.br  Thu Jan  2 00:58:02 2003
From: stat at estadao.com.br (Rafael Bertola)
Date: Thu Jan  2 00:58:02 2003
Subject: [R] nonparametrics databank for analisys
Message-ID: <1638.200.205.216.17.1041465421.squirrel@webmail.estadao.com.br>

I'm looking for data to use with nonparametrics exploration technics.
I'm a undergraduate student in statistics at the Unicamp (Brazil), and
i've to make a project (with orientation of a professor). I choose
nonparametrics statistics to make the project. But in this project i must
have to use a databank and present analisys.
So, if somebody give me indications where i can find databanks for
nonparametric statistics analisys (on the internet or other sources), i
will thank you.

Rafael Bertola
Unicamp
www.ime.unicamp.br
rafaelbertola at yahoo.com.br


--------------------------------------------------
               Email PLus Estad?o 
Agora voc? pode ter mais ferramentas e espa?o para 
armazenar seus emails. 
http://www.estadao.com.br/webmail/pago/ 
--------------------------------------------------



From hubert at telus.net  Thu Jan  2 13:40:03 2003
From: hubert at telus.net (Hubert)
Date: Thu Jan  2 13:40:03 2003
Subject: [R] unable to install redhat 8.0 rpm
Message-ID: <3E143301.6010506@telus.net>

I've just installed Redhat 8.0 + latest updates on a Intel PC and am 
trying to install the R 1.6.1-2 rpm but get the following:

# rpm -i R-1.6.1-2.i386.rpm
warning: R-1.6.1-2.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
error: Failed dependencies:
         libtcl.so.0 is needed by R-1.6.1-2
         libtk.so.0 is needed by R-1.6.1-2

What am I missing?

Hubert

--
Hubert Wong, PhD

Email: hubert at telus.net



From tord.snall at ebc.uu.se  Thu Jan  2 13:49:02 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Thu Jan  2 13:49:02 2003
Subject: [R] replace NA with factor class
Message-ID: <3.0.6.32.20030102133541.00af8920@mail.anst.uu.se>

Dear all,

I have a tree data matrix. For some trees I lack info about tree species,
but I want to set them to be spruce. For some reason the tree species names
on the remaining (non-NA) rows are changed into numbers (that I do not
recognise).

I guess that ifelse is not the correct function to use, but I have not
found any better one in my searches.

Thanks in advance!

Sincerely,
Tord


> test
      ObjektID tree.sp Diameter
2030 S.2001.S5    <NA>        2
2034 S.2001.S5    <NA>        2
1          S.1   spruce       2
2          S.1    birch      12
3          S.1   spruce       7
4          S.1   spruce       5
5          S.1    birch       8

> test$tree.sp6<- ifelse(is.na(test$tree.sp) == T, "spruce", test$tree.sp)

> test
      ObjektID tree.sp Diameter tree.sp6
2030 S.2001.S5     <NA>        2      spruce
2034 S.2001.S5     <NA>        2      spruce
1          S.1   spruce        2         8
2          S.1    birch       12         3
3          S.1   spruce        7         8
4          S.1   spruce        5         8
5          S.1    birch        8         3


-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From phgrosjean at sciviews.org  Thu Jan  2 13:51:41 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu Jan  2 13:51:41 2003
Subject: [R] lowess + turnpoints = doubling integers?
In-Reply-To: <00ad01c2b0c6$53a79520$6501a8c0@HydePark>
Message-ID: <MABBLJDICACNFOLGIHJOCEDIDCAA.phgrosjean@sciviews.org>

Hello Bob,

It seems that onsets and offsets are always a multiple of a number A (when
it is a multiple of 11, as in your example, you got 11, 22, 33, 44,..., thus
"double numbers"). Since changing either the length of the series, or f
argument in lowess changes A, it is an artifact introduced by lowess().
Lowess is a local regression method within a given window, and A appears to
be a portion of this window. You should use a different regression method
(depending on your actual data).

Here is a vectorized version of your calculation, with some examples.
Playing with it, I found a bug in turnpoints(), which behave strangely when
successive observations are very close from each other, for instance,
22.12367, 22.12371, ... It sometimes happens after using a lowess, as in the
example. I spotted the problem in the max.col() function that turnpoints()
uses. Probably rounding errors. The Splus version of the function works as
expected (see example here under). I'll correct this as soon as possible,
but in the meantime, you can use turnpoints2() provided hereunder.

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................

# A vectorized version of your calculation
onset.offset <- function(tp){
	if (is.null(class(tp)) || class(tp) != "turnpoints")
		stop("tp must be a 'turnpoints' object!")
	require(pastecs)
	peaks <- tp$pos[tp$peaks]
	pits <- tp$pos[tp$pits]
	if (tp$firstispeak)
		peaks <- peaks[-1]	# Start with a pit
	npks <- length(peaks)
	npts <- length(pits)
	if (npks == npts) {
		onsets <- peaks - pits
		offsets <- pits[-1] - peaks[-npks]
	} else {
		onsets <- peaks - pits[-npts]
		offsets <- pits[-1] - peaks
	}
	list(peaks=peaks, onsets=onsets, offsets=offsets)
}

# turnpoints is in the PASTECS library
library(pastecs)

# an example that yields multiples of 11
set.seed(c(1,1))
foo <- rnorm(n=1500,mean=23.02, sd=34.14)
xx <- lowess(foo,f=.04)
yy <- turnpoints(xx$y)
onset.offset(yy)
# changing either the length of the series (n), or the window of LOWESS (f)
changes the "periodicity" of onsets/offsets

# A bug is detected in turnpoints (indeed, probably rounding errors in
max.col used by the R version of turnpoints)
set.seed(c(1,1))
foo <- rnorm(n=1800,mean=23.02, sd=34.14)
xx <- lowess(foo,f=.08)
yy <- turnpoints(xx$y)
onset.offset(yy)

# Using Splus version (without max.col) gives correct results:
library(ts)
is.R <- function() FALSE	# To use Splus version of the function
set.seed(c(1,1))
foo <- rnorm(n=1800,mean=23.02, sd=34.14)
xx <- lowess(foo,f=.08)
yy <- turnpoints(xx$y)
onset.offset(yy)

remove(is.R)	# This is dangerous to keep!

# A temporary workaround for the bug in turnpoints:
turnpoints2 <- function(x){
    data <- deparse(substitute(x))
    if (is.null(ncol(x)) == FALSE)
        stop("Only one series can be treated at a time")
    if (exists("is.R") && is.function(is.R) && is.R())
        require(ts)
    x <- as.vector(x)
    n <- length(x)
    diffs <- c(x[1] - 1, x[1:(n - 1)]) != x
    uniques <- x[diffs]
    n2 <- length(uniques)
    poss <- (1:n)[diffs]
    exaequos <- c(poss[2:n2], n + 1) - poss - 1
    if (n2 < 3) {
        warning("Less than 3 unique values, no calculation!")
        nturns <- NA
        firstispeak <- FALSE
        peaks <- rep(FALSE, n2)
        pits <- rep(FALSE, n2)
        tppos <- NA
        proba <- NA
        info <- NA
    }
    else {
        m <- n2 - 2
        ex <- matrix(uniques[1:m + rep(3:1, rep(m, 3)) - 1], m)
        peaks <- c(FALSE, apply(ex, 1, max, na.rm = TRUE) == ex[, 2], FALSE)
        pits <- c(FALSE, apply(ex, 1, min, na.rm = TRUE) == ex[, 2], FALSE)

        tpts <- peaks | pits
        if (sum(tpts) == 0) {
            nturns <- 0
            firstispeak <- FALSE
            peaks <- rep(FALSE, n2)
            pits <- rep(FALSE, n2)
            tppos <- NA
            proba <- NA
            info <- NA
        }
        else {
            tppos <- (poss + exaequos)[tpts]
            tptspos <- (1:n2)[tpts]
            firstispeak <- tptspos[1] == (1:n2)[peaks][1]
            nturns <- length(tptspos)
            if (nturns < 2) {
                inter <- n2 + 1
                posinter1 <- tptspos[1]
            }
            else {
                inter <- c(tptspos[2:nturns], n2) - c(1, tptspos[1:(nturns -
                  1)]) + 1
                posinter1 <- tptspos - c(1, tptspos[1:(nturns -
                  1)])
            }
            posinter2 <- inter - posinter1
            posinter <- pmax(posinter1, posinter2)
            proba <- 2/(inter * gamma(posinter) * gamma(inter -
                posinter + 1))
            info <- -log(proba, base = 2)
        }
    }
    res <- list(data = data, n = n, points = uniques, pos = (poss +
        exaequos), exaequos = exaequos, nturns = nturns, firstispeak =
firstispeak,
        peaks = peaks, pits = pits, tppos = tppos, proba = proba,
        info = info)
    class(res) <- "turnpoints"
    res
}

-----Original Message-----
From: Bob Porter [mailto:rjporter at mindspring.com]
Sent: mardi 31 d?cembre 2002 1:16
To: phgrosjean at sciviews.org
Subject: Re: [R] lowess + turnpoints = doubling integers?


Hello Philippe:

Thank you for your interest.  I have explored this and it appears to happen
with
sequences in which small differences between successive occurances,
somewhere in
turnpoints, but I have not tracked it down exactly.  The following is a
cobbled
together demo based on the original code.  m b, Bob

***********************************************
foo<-rnorm(n=1200,mean=23.02, sd=34.14) #based on stat of actual data
xx<-lowess(foo,f=.04) #note that changing f or length of foo (equivalent,
actually) changes the result
yy<- turnpoints(xx$y)

onsets<-seq(1:yy$nturns)
peaks<-seq(1:yy$nturns)
offsets<-seq(1:yy$nturns)
ievent<-1


istart<-1
if(yy$firstispeak) istart<-2 #always start with a pit
i<-istart
adj<-1 #dummy adjustment, means something in original code

while(i<=yy$nturns-istart-adj)
    {
            # points are processed in sets of three pit-peak-pit events,
starting with a pit

        onsets[ievent]<-yy$tppos[i+1]-yy$tppos[i]#i is the onset point for
this
event, this calculates its duration
        peaks[ievent]<-yy$tppos[i+1] #i+1 is the location of the peak point
        offsets[ievent]<-yy$tppos[i+2]-yy$tppos[i+1] #calculate the offset
duration but subtracting peak point from offset point
        i<-i+2 #set i to the offset point WHICH IS ALSO THE ONSET POINT FOR
THE
NEXT EVENT
        ievent<-ievent+1
        #cat(i,"  ",ievent,"// ")
    }

events<-onsets+offsets

cat("\n",events,"events n=", nevents,"\n")
cat(onsets,"onsets\n")
cat(offsets,"offsets\n","\n")
*****************************************

----- Original Message -----
From: "Philippe Grosjean" <phgrosjean at sciviews.org>
To: "Bob Porter" <rjporter at mindspring.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Tuesday, December 31, 2002 4:55 AM
Subject: RE: [R] lowess + turnpoints = doubling integers?


> Bob,
> Happy New Year. Could you, please, cook an example so as we could spot the
> problem?
> Best,
>
> Philippe Grosjean
>
> ...........]<(({?<...............<?}))><...............................
>  ) ) ) ) )
> ( ( ( ( (       Dr. Philippe Grosjean
>  ) ) ) ) )
> ( ( ( ( (       LOV, UMR 7093
>  ) ) ) ) )      Station Zoologique
> ( ( ( ( (       Observatoire Oc?anologique
>  ) ) ) ) )      BP 28
> ( ( ( ( (       06234 Villefranche sur mer cedex
>  ) ) ) ) )      France
> ( ( ( ( (
>  ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
> ( ( ( ( (
>  ) ) ) ) )      e-mail: phgrosjean at sciviews.org
> ( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
>  ) ) ) ) )
> .......................................................................
>
>
>
> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch
> [mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of Bob Porter
> Sent: dimanche 29 d?cembre 2002 8:52
> To: r-help at stat.math.ethz.ch
> Subject: [R] lowess + turnpoints = doubling integers?
>
>
> Happy New Year, r-helpers!
>
> I am using lowess to smooth a scatter plot,
> xx<-lowess(xinput,f=.04)  #defaults for other args
>  followed by
> turnpoints(xx$y) #defaults for other args
>
> I plot the smoothed result as well as turnpoints (using yy$tppos) on top
of
> raw
> data plot.
> Result is exactly as expected, graphically.
>
> For another purpose, I calcuate the difference between turnpoints
> (representing
> time intervals between turnspoints in my applicaiton), e.g.
>
> aduration[j]<-yy$tppos[i+1]-yytppos[i]
>
> This also appears to work as expected, HOWEVER, a typical list of such
> differences looks like:
> 22,33,22,11,33,44,33,33,11,33,44,66,33,22,.........
> there are, in some instances, three digit measure such as 110 or 106, etc.
> but
> the double-digit measures, although of the proper magnitude, seem to
always
> be
> double integers 11 to 99.
>
> The double-integer results are found with f=.04 and total length of vector
> of
> 1200.  With vector of length 1100 (same input data), the results are NOT
> double-integer but are ALWAYS (?) of the form x0, e.g.
> 70,50,50,70,100,40............  The magnitude of these latter results (22
vs
> 70,
> for example) is evidently due to the change in the smoothing span from
> .04*1200
> to .04*1100, but I am mystified why the results have double-integers in
the
> first case, and terminal zeros in the second.
>
> My project involves applying these functions in a batch run for dozens of
> data
> sets so I want to understand more about what is going on that yeilds these
> strange double-integers or zero-terminating values.
>
> Thanks,
>
> Bob Porter, Tampa
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>
>



From baron at cattell.psych.upenn.edu  Thu Jan  2 14:00:03 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Thu Jan  2 14:00:03 2003
Subject: [R] unable to install redhat 8.0 rpm
In-Reply-To: <3E143301.6010506@telus.net>; from hubert@telus.net on Thu, Jan 02, 2003 at 04:39:29AM -0800
References: <3E143301.6010506@telus.net>
Message-ID: <20030102075855.B22603@cattell.psych.upenn.edu>

On 01/02/03 04:39, Hubert wrote:
>I've just installed Redhat 8.0 + latest updates on a Intel PC and am 
>trying to install the R 1.6.1-2 rpm but get the following:
>
># rpm -i R-1.6.1-2.i386.rpm
>warning: R-1.6.1-2.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
>error: Failed dependencies:
>         libtcl.so.0 is needed by R-1.6.1-2
>         libtk.so.0 is needed by R-1.6.1-2
>
>What am I missing?

Some programs.  (Why they did not get installed when you
installed RH 8 is something I do not know.)  One way to
find such things is to go to http://rpmfind.net/linux/RPM/ and
type the name of what you are missing into the search box.  In
this case, you will see that you need the rpm for tcl, and the
one for tk, both of which have versions for RH 8.0.  Download
them and install them (as root) in the usual way, e.g.:
rpm -Uvh tcl* tk*
(or use the tab key to complete the names).

Jon Baron



From Jan_Svatos at eurotel.cz  Thu Jan  2 14:02:47 2003
From: Jan_Svatos at eurotel.cz (Jan_Svatos@eurotel.cz)
Date: Thu Jan  2 14:02:47 2003
Subject: [R] unable to install redhat 8.0 rpm
Message-ID: <OF2477E17D.6A2C33D3-ONC1256CA2.0046C622@eurotel.cz>

Hi Hubert,

AFAIK, the warning is just warning, but the error is, that
the two libraries for Tcl/Tk   libtcl.so.0 , libtk.so.0 seem to be missing
in your system.
Try to find out, which RPMs  provide these libraries and install them.
Or try rpm with --nodeps flag, but this may be little bit risky.

Jan



- - - Original message: - - -
From: r-help-admin at stat.math.ethz.ch
Send: 2.1.2003 13:48:23
To: r-help at stat.math.ethz.ch
Subject: [R] unable to install redhat 8.0 rpm

I've just installed Redhat 8.0 + latest updates on a Intel PC and am
trying to install the R 1.6.1-2 rpm but get the following:

# rpm -i R-1.6.1-2.i386.rpm
warning: R-1.6.1-2.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
error: Failed dependencies:
         libtcl.so.0 is needed by R-1.6.1-2
         libtk.so.0 is needed by R-1.6.1-2

What am I missing?

Hubert

--
Hubert Wong, PhD

Email: hubert at telus.net

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From hubert at telus.net  Thu Jan  2 14:18:06 2003
From: hubert at telus.net (Hubert)
Date: Thu Jan  2 14:18:06 2003
Subject: [R] unable to install redhat 8.0 rpm
References: <3E143301.6010506@telus.net> <20030102075855.B22603@cattell.psych.upenn.edu>
Message-ID: <3E143BB3.1070705@telus.net>

Many thanks.  I found them on rpmfind and all seems well now.

Hubert

Jonathan Baron wrote:
> On 01/02/03 04:39, Hubert wrote:
> 
>>I've just installed Redhat 8.0 + latest updates on a Intel PC and am 
>>trying to install the R 1.6.1-2 rpm but get the following:
>>
>># rpm -i R-1.6.1-2.i386.rpm
>>warning: R-1.6.1-2.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
>>error: Failed dependencies:
>>        libtcl.so.0 is needed by R-1.6.1-2
>>        libtk.so.0 is needed by R-1.6.1-2
>>
>>What am I missing?
> 
> 
> Some programs.  (Why they did not get installed when you
> installed RH 8 is something I do not know.)  One way to
> find such things is to go to http://rpmfind.net/linux/RPM/ and
> type the name of what you are missing into the search box.  In
> this case, you will see that you need the rpm for tcl, and the
> one for tk, both of which have versions for RH 8.0.  Download
> them and install them (as root) in the usual way, e.g.:
> rpm -Uvh tcl* tk*
> (or use the tab key to complete the names).
> 
> Jon Baron
> 
> 



-- 
Hubert Wong, PhD

Email: hubert at telus.net



From tord.snall at ebc.uu.se  Thu Jan  2 14:45:03 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Thu Jan  2 14:45:03 2003
Subject: [R] aggregate: "sum" not meaningful for factors
Message-ID: <3.0.6.32.20030102143847.00a68bf0@mail.anst.uu.se>

Dear all,
I try to summarise my data per category using aggregate, but for some
reason I get the error message "sum" not meaningful for factors even though
my vector is numeric. The data set is shown below.

Could someone please give a hint.

Thanks in advance!

Sincerely,
Tord

> names(test)
[1] "ObjektID"     "tallstubbyta"

> is.factor(test$ObjektID); is.factor(test$tallstubbyta)
[1] TRUE
[1] FALSE

> is.numeric(test$ObjektID); is.numeric(test$tallstubbyta)
[1] FALSE
[1] TRUE

> mean(test$tallstubbyta)
[1] 0.01142584

> aggregate(test, list(test$ObjektID), length)[, c("Group.1", "tallstubbyta")]
  Group.1 tallstubbyta
1     S.1           19
2    S.10            4

> aggregate(test, list(test$ObjektID), mean)[, c("Group.1", "tallstubbyta")]
  Group.1 tallstubbyta
1     S.1   0.01383128
2    S.10   0.00000000
Warning messages: 
1: argument is not numeric or logical: returning NA in:
mean.default(X[[1]], ...) 
2: argument is not numeric or logical: returning NA in:
mean.default(X[[2]], ...) 

> aggregate(test, list(test$ObjektID), sum)[, c("Group.1", "tallstubbyta")]
Error in Summary.factor(..., na.rm = na.rm) : 
        "sum" not meaningful for factors

> aggregate
function (x, ...) 
UseMethod("aggregate")

> test
   ObjektID tallstubbyta
1       S.1 0.0000000000
2       S.1 0.0000000000
3       S.1 0.0000000000
4       S.1 0.0000000000
5       S.1 0.0000000000
6       S.1 0.1320254313
8       S.1 0.0003141593
9       S.1 0.0000000000
10      S.1 0.0003141593
11      S.1 0.0003141593
12      S.1 0.0530929158
13      S.1 0.0000000000
14      S.1 0.0000000000
15      S.1 0.0003141593
16      S.1 0.0000000000
17      S.1 0.0226980069
18      S.1 0.0003141593
19      S.1 0.0003141593
20      S.1 0.0530929158
21     S.10 0.0000000000
22     S.10 0.0000000000
26     S.10 0.0000000000
27     S.10 0.0000000000
> 
> 


-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From ripley at stats.ox.ac.uk  Thu Jan  2 14:50:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan  2 14:50:03 2003
Subject: [R] replace NA with factor class
In-Reply-To: <3.0.6.32.20030102133541.00af8920@mail.anst.uu.se>
Message-ID: <Pine.LNX.4.31.0301021341540.21240-100000@gannet.stats>

On Thu, 2 Jan 2003, Tord Snall wrote:

> I have a tree data matrix.

Don't think so: you appear to have a data frame, which is not at all the
same thing.

> For some trees I lack info about tree species,
> but I want to set them to be spruce. For some reason the tree species names
> on the remaining (non-NA) rows are changed into numbers (that I do not
> recognise).

You should do so.  They are the code of the factor in your data frame.

> I guess that ifelse is not the correct function to use, but I have not
> found any better one in my searches.

Your two arguments to ifelse are a character vector and a factor. You
will get coercion of the factor to an atomic type, and that's where the
codes come from.


test$tree.sp[is.na(test$tree.sp)] <- "spruce"

is probably what you wanted.

>
> Thanks in advance!
>
> Sincerely,
> Tord
>
>
> > test
>       ObjektID tree.sp Diameter
> 2030 S.2001.S5    <NA>        2
> 2034 S.2001.S5    <NA>        2
> 1          S.1   spruce       2
> 2          S.1    birch      12
> 3          S.1   spruce       7
> 4          S.1   spruce       5
> 5          S.1    birch       8
>
> > test$tree.sp6<- ifelse(is.na(test$tree.sp) == T, "spruce", test$tree.sp)
>
> > test
>       ObjektID tree.sp Diameter tree.sp6
> 2030 S.2001.S5     <NA>        2      spruce
> 2034 S.2001.S5     <NA>        2      spruce
> 1          S.1   spruce        2         8
> 2          S.1    birch       12         3
> 3          S.1   spruce        7         8
> 4          S.1   spruce        5         8
> 5          S.1    birch        8         3
>
>
> -----------------------------------------------------------------------
> Tord Snäll
> Avd. f växtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
> Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
> Villavägen 14
> SE-752 36 Uppsala, Sweden
> Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
> Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
> Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
> E-mail: Tord.Snall at ebc.uu.se
> Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sundar.dorai-raj at pdf.com  Thu Jan  2 15:00:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu Jan  2 15:00:03 2003
Subject: [R] aggregate: "sum" not meaningful for factors
References: <3.0.6.32.20030102143847.00a68bf0@mail.anst.uu.se>
Message-ID: <3E144582.7050004@pdf.com>

Tord,

Tord Snall wrote:
> Dear all,
> I try to summarise my data per category using aggregate, but for some
> reason I get the error message "sum" not meaningful for factors even though
> my vector is numeric. The data set is shown below.
> 
> Could someone please give a hint.
> 
> Thanks in advance!
> 
> Sincerely,
> Tord
> 
> 

aggregate requires the first argument to be numeric if you're using sum 
  or mean. The way you had it, aggregate was trying to sum your 
classification variable as well which is of class `factor'. Try the 
following instead.

> aggregate(list(tallstubbyta = test$tallstubbyta,
             list(ObjektID = test$ObjektID), sum)

Regards,
Sundar



From v_bill_pikounis at merck.com  Thu Jan  2 15:55:03 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Thu Jan  2 15:55:03 2003
Subject: [R] Summer Internship at Merck (Domestic USA)
Message-ID: <E827328028C66044B4998F2EC353CD3003185077@usrymx12.merck.com>

(Apologies for cross-posting this job announcement to those on both R-help
and S-news.)

2003 SUMMER INTERNSHIP POSITION
Domestic United States residents / visitors only.

Merck Research Laboratories
Rahway, NJ, USA (approx. 30 miles from New York City)

1 position, Ph.D. or Masters student
Deadline for Applications: February 14, 2003.

Brief Description:

Help provide data analytic & statistical support to scientists in basic drug
research within an environment that is like a small open consulting
business.  Roles include data analysis (summary and presentation);
experimental design; document preparation; data management; statistical
research; and the promotion of statistical thinking.  MS-Windows and Linux
platforms used; S Language ( R / S-PLUS) facility needed.  SAS will **not**
be used.  Emphasis will be on the use of modern statistical approaches for
analysis of animal pharmacology data -- graphs, resampling, resistant /
robust methods, etc. There may be opportunities for work with molecular
profiling data as well.

Ideal candidates will have experience (and/or the strong desire to learn
skills) in statistics, computing, and communications.  The intern position
typically runs 10-12 weeks somewhere inside the period of Mid-May to
Mid-August, depending on school term schedules -- this is flexible according
to the student's needs. The median pay scale is approximately $3500 per
month, with other expenses and benefits provided by Merck.

More details below.

######################
Contact Information:

Bill Pikounis, Ph.D.
Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

E-mail: v_bill_pikounis at merck.com

Fax: 732.594.1565

Deadline: February 14, 2003.
* Send resume and cover letter by email (PDF or MS-Word format) or regular
mail
to above contact address. No phone calls please. *
######################

More details:

The group here at Merck Research Labs (MRL) consists of ten statisticians.
We provide broad data analytic support to scientists at the lab site of
Rahway, New Jersey, in the areas of pre-clinical and non-clinical research.
While we are based in New Jersey, we also serve Merck research sites in
Montreal, San Diego, Seattle, Spain, and England by occasional visits and
the use of web-based software tools that we have built to enable researchers
to do good data analysis themselves. 

Pre-clinical / Non-clinical means that we work with basic researchers in a
variety of human-health product areas in the long-term Research &
Development (R & D) process that occurs before a drug is ever even tested in
the first human.  The many years of R & D starts with Discovery of
biological targets believed important in a disease, and involves the
screening of compounds to affect those targets.  Once promising compounds
have been identified, much study and refinement are done in animal models
that hopefully approximate how the drug candidate would work in humans. What
we do NOT do is provide direct support to human clinical trials; Phases
I--III and beyond. That support is the responsibility of other statistics
departments at Merck.

The primary roles and expectations for a statistician in the department,
which is officially called Biometrics Research, are data analysis (summary
and presentation); experimental design; document
preparation; data management; statistical research; and the promotion and
education of statistical thinking.  Our projects range from short-to-long
term, i.e. days to months.  As an intern, one would work on a variety of
projects, with an excellent chance of being involved with them from
start-to-finish during an approximately 3 month stay.

We most often deal with data that comes from experiments where we were
**not** involved in the design phase.  Scientists here at MRL are encouraged
to be creative in their research, and that provides us with constantly
challenging data sets. We use Windows and Linux platforms for computing, R
and S-PLUS primarily for data analyses, and Microsoft Word for
documentation.  Data sets are often provided in Excel spreadsheets.
Building web-based software tools that our research customers can use is an
essential part of our operations, so that we can serve the thousands of
researchers (biologists, chemists, etc.) within Merck at its various
international research sites.


------------------------------------------------------------------------------



From luke at inpharmatica.co.uk  Thu Jan  2 16:02:06 2003
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Thu Jan  2 16:02:06 2003
Subject: [R] Re: R-help digest, Vol 1 #34 - 2 msgs
In-Reply-To: <20030102110006.7884.64328.Mailman@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.21.0301021442000.31267-100000@dollis-hill.inpharmatica.co.uk>

Hello,

I would like to access an Oracle database running on Solaris from
R on my linux desktop. I have had a look at the R Data Import/Export
manual, and downloaded RODBC and unixODBC, but I am still quite confused
about how to proceed. It appears to me that I still need to get an Oracle
ODBC driver, and the only one I can find is from Easysoft for 880 euros,
which is not available for this project.

Is there any free software which will enable R on linux to talk to Oracle
on Solaris (both reading and writing data) ? 

My R setup is as follows:

platform i386-pc-linux-gnu
arch     i386             
os       linux-gnu        
system   i386, linux-gnu  
status                    
major    1                
minor    5.1              
year     2002             
month    06               
day      17               
language R                

Thanks,

Luke Whitaker.



From petr.pikal at precheza.cz  Thu Jan  2 16:12:02 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu Jan  2 16:12:02 2003
Subject: [R] aggregate: "sum" not meaningful for factors
In-Reply-To: <3E144582.7050004@pdf.com>
Message-ID: <3E146490.30866.1D1F820@localhost>


On 2 Jan 2003 at 7:58, Sundar Dorai-Raj wrote:

> Tord,
> 
> Tord Snall wrote:
> > Dear all,
> > I try to summarise my data per category using aggregate, but for
> > some reason I get the error message "sum" not meaningful for factors
> > even though my vector is numeric. The data set is shown below.
> > 
> > Could someone please give a hint.
> > 
> > Thanks in advance!
> > 
> > Sincerely,
> > Tord
> > 
> > 
> 
> aggregate requires the first argument to be numeric if you're using
> sum 
>   or mean. The way you had it, aggregate was trying to sum your 
> classification variable as well which is of class `factor'. Try the
> following instead.
> 
> > aggregate(list(tallstubbyta = test$tallstubbyta,
>              list(ObjektID = test$ObjektID), sum)

Or

aggregate(test$tallstubbyta,list(test$ObjectID),sum)




> 
> Regards,
> Sundar


Cheers
Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From jgramlich at piocon.com  Thu Jan  2 22:59:05 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Thu Jan  2 22:59:05 2003
Subject: [R] random number generation
Message-ID: <014b01c2b2aa$1a2c98f0$cc3ac341@ginworks.com>

Can a single random number be generated in R?  I have an exercise that wants
to simulate coin tosses, and I cannot seem to find a good example of the use
of random number generation in R.  Any help?


Joshua Gramlich
Chicago, IL



From jgramlich at piocon.com  Thu Jan  2 23:18:05 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Thu Jan  2 23:18:05 2003
Subject: [R] random number generation
References: <Pine.LNX.4.33.0301021700350.6193-100000@penguin.rand.org>
Message-ID: <016801c2b2ac$af778580$cc3ac341@ginworks.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030102/36ae041f/attachment.pl

From fnj at cin.ufpe.br  Thu Jan  2 23:21:03 2003
From: fnj at cin.ufpe.br (Francisco Junior)
Date: Thu Jan  2 23:21:03 2003
Subject: [R] Images: array of RBG codes
In-Reply-To: <014b01c2b2aa$1a2c98f0$cc3ac341@ginworks.com>
Message-ID: <Pine.GSO.4.32.0301021909260.3860-100000@goiana>

People,

I need to read a figure (JPEG, BMP or PNG) and to transform it into
integer´s array with RBG code.
Are there some library with method for this purpose?

Thanks,
Francisco.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco Júnior,
Computer Science-UFPE-Brazil
"One life is valid more than world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From fharrell at virginia.edu  Fri Jan  3 02:55:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri Jan  3 02:55:03 2003
Subject: [R] as.POSIXct problem?
Message-ID: <20030102205628.3141f54d.fharrell@virginia.edu>

Under

platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.1              
year     2002             
month    11               
day      01               
language R                

> x <- strptime(c('10/10/1969','12/31/2002'),format='%m/%d/%Y')
> x
[1] "1969-10-10" "2002-12-31"
> as.POSIXct(x)
[1] NA               "2002-12-31 EST"

Why the NA?  If this is not the preferred way to convert a character string to POSIXct what is?  On a more minor note why the EST if no time is printed?

Thanks,

Frank
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From gisar at nus.edu.sg  Fri Jan  3 03:12:03 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Fri Jan  3 03:12:03 2003
Subject: [R] random number generation
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F1E2@MBXSRV03.stf.nus.edu.sg>

Many ways of doing this. Try rbinom(n=1, size=1, prob=0.5) and you can
adjust the 'prob' argument if you have an unfair coin. The other one is
sample( c(0,1), 1 ) which is a sampling method and also has a 'prob'
argument. Other functions include rnorm, runif, rpois ....

-----Original Message-----
From: Joshua Gramlich [mailto:jgramlich at piocon.com] 
Sent: Friday, January 03, 2003 5:59 AM
To: r-help at stat.math.ethz.ch
Subject: [R] random number generation


Can a single random number be generated in R?  I have an exercise that
wants to simulate coin tosses, and I cannot seem to find a good example
of the use of random number generation in R.  Any help?


Joshua Gramlich
Chicago, IL

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From edd at debian.org  Fri Jan  3 04:40:03 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri Jan  3 04:40:03 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <20030102205628.3141f54d.fharrell@virginia.edu>
References: <20030102205628.3141f54d.fharrell@virginia.edu>
Message-ID: <20030103033831.GA3329@sonny.eddelbuettel.com>

On Thu, Jan 02, 2003 at 08:56:28PM -0500, Frank E Harrell Jr wrote:
> Under
> 
> platform i686-pc-linux-gnu
> arch     i686             
> os       linux-gnu        
> system   i686, linux-gnu  
> status                    
> major    1                
> minor    6.1              
> year     2002             
> month    11               
> day      01               
> language R                
> 
> > x <- strptime(c('10/10/1969','12/31/2002'),format='%m/%d/%Y')
> > x
> [1] "1969-10-10" "2002-12-31"
> > as.POSIXct(x)
> [1] NA               "2002-12-31 EST"
> 
> Why the NA?  If this is not the preferred way to convert a character string to POSIXct what is?  On a more minor note why the EST if no time is printed?

Quick guess:  Unix time does start by convention on 1/1/1970 at GMT. Going
before it is not within the specs, or safe. 

Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr



From hb at maths.lth.se  Fri Jan  3 05:11:02 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri Jan  3 05:11:02 2003
Subject: [R] Images: array of RBG codes
In-Reply-To: <Pine.GSO.4.32.0301021909260.3860-100000@goiana>
Message-ID: <000001c2b2dd$f9675310$7341a8c0@alpha.wehi.edu.au>

The core distribution of R does not provide means for reading image
files. However, the 'pixmap' package on CRAN can read Portable PixMap
images, which commonly have extensions PBM (monochrome images), PGM
(grayscale images) and PPM (color/RGB images). You can install the
pixmap package by

  install.packages("pixmap")

If you have images of other formats, e.g. JPEG, BMP, PNG, GIF etc, I
recommend that you use ImageMagick's command line command 'convert' to
convert your images into PPM. ImageMagick exists for many platforms and
can be downloaded from http://www.imagemagick.org/. Say you install a
Windows version of ImageMagick under C:/Program Files/ImageMagick/" then
you can call it from within R by doing:

 system("\"C:/Program Files/ImageMagick/convert.exe\" foo.jpg foo.png")

Note that you need to put any command containing spaces within quotation
marks, thereby the \". You can of course write your own wrapper
function, e.g. readJPG(), which will convert the jpg file to ppm and the
use pixmap to read it in.

Finally, the pixmap package provides methods for getting the red, the
green and the blue channels as matrices.

In other words, it is not to hard to get what you want!

Cheers

Henrik Bengtsson


> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Francisco Junior
> Sent: den 3 januari 2003 09:21
> To: r-help at stat.math.ethz.ch
> Subject: [R] Images: array of RBG codes
> 
> 
> People,
> 
> I need to read a figure (JPEG, BMP or PNG) and to transform
> it into integer?s array with RBG code. Are there some library 
> with method for this purpose?
> 
> Thanks,
> Francisco.
> 
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Francisco J?nior,
> Computer Science-UFPE-Brazil
> "One life is valid more than world whole"
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From LindnerW at t-online.de  Fri Jan  3 07:57:03 2003
From: LindnerW at t-online.de (Wolfgang Lindner)
Date: Fri Jan  3 07:57:03 2003
Subject: [R]  factor analysis (pca): how to get the 'communalities'?
Message-ID: <18ULl2-1CitzUC@fwd01.sul.t-online.com>

Dear expe-R-ts,

I try some test data for a factorAnalysis (resp. pca) in the sense of Prof. 
Ripley's MASS ? 11.1, p. 330 ff., just to prepare myself for an analysis of my 
own empirical data using R (instead of SPSS).

1. the data.

## The test data is (from the book of Backhaus et al.: Multivariate ## 
Analysemethoden. Springer 2000 [9th ed.], p. 300 ff):

a<-c(4.5,5.167,5.059,3.8,3.444,3.5,5.25,5.857,5.083,5.273,4.5)
b<-c(4.0,4.25,3.824,5.4,5.056,3.5,3.417,4.429,4.083,3.6,4.0)
c<-c(4.375,3.833,4.765,3.8,3.778,3.875,4.583,4.929,4.667,3.909,4.2)
d<-c(3.875,3.833,3.438,2.4,3.765,4.0,3.917,3.857,4.0,4.091,3.9)
e<-c(3.25,2.167,4.235,5.0,3.944,4.625,4.333,4.071,4.0,4.091,3.7)
f<-c(3.75,3.75,4.471,5.0,5.389,5.250,4.417,5.071,4.25,4.091,3.9)
g<-c(4.0,3.273,3.765,5.0,5.056,5.5,4.667,2.929,3.818,4.545,3.6)
h<-c(2.0,1.857,1.923,4.0,5.615,6.0,3.25,2.091,1.545,1.6,1.5)
i<-c(4.625,3.75,3.529,4.0,4.222,4.75,4.5,4.571,3.75,3.909,3.5)
j<-c(4.125,3.417,3.529,4.6,5.278,5.375,3.583,3.786,4.167,3.818,3.7)

m<-data.frame(a,b,c,d,e,f,g,h,i,j)

2. My try of a pca with R.

## My R input was:

m
cor(m)
library(mva)
m.pca<-princomp(m,cor=T)
m.pca
summary(m.pca)
loadings(m.pca)
m.pca$scores
m.FA <- factanal(factors = 3, covmat=cov(m))
m.FA

3. Here are my questions. 

Q1. 
The cor(m)-Matrix is the same as reported by using SPSS (or OpenStats2). 
But in R I get other eigenvalues compared with the following SPSS output:

Original matrix trace =  10,00
Roots (Eigenvalues) Extracted:
   1  5,052
   2  1,771
   3  1,427
   4  0,819
   5  0,430
   6  0,247
   7  0,159
   8  0,062
   9  0,029
  10  0,003

- What is going behind the scene? 
- Or what I am doing wrong in my use of R?
- If I am doing the pca correct, can I use the R results as equally aceptable 
  without further discussion? 
  Maybe a different 'hidden' algorithm is the reason for different results?

Q2. How to get the so called 'Communality Estimates' with R?

Here the values reported by SPSS for the above test data.frame m:
Communality Estimates as percentages:
  1 88,619
  2 76,855
  3 89,167
  4 85,324
  5 76,043
  6 84,012
  7 80,223
  8 92,668
  9 63,297
 10 88,786

Any help, suggestions or hints are very welcome.
Best regards and happy new year for you and R

Wolfgang

--
Wolfgang Lindner                           Lindner at math.uni-duisburg.de
   Gerhard-Mercator-Universitaet Duisburg  Tel: +49 0203 379-1326
   Fakultaet 4 - Naturwissenschaften       Fax: +49 0203 379-2528
   Institut fuer Mathematik,  LE 424
   Lotharstr. 65
   D 47048  Duisburg (Germany)



From rpeng at stat.ucla.edu  Fri Jan  3 08:26:03 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri Jan  3 08:26:03 2003
Subject: [R] Writing packages with `methods' package
In-Reply-To: <3E121F78.FF2BEEAF@research.bell-labs.com>
Message-ID: <Pine.GSO.4.10.10301022312100.7870-100000@quetelet.stat.ucla.edu>

Hello, thanks for the tip.  I tried creating the `install.R' file in the
root level of the package directory and the build/installation went fine.
However, I when I load the package after doing this type of build, all my
methods work fine except of the method I define for "[".  When I try to
use the "[" on my own object, it seems to be resorting to the default "["
method (if I understand that correctly) rather than the one I defined.  Is
this a problem of where my method gets defined in the search path?  I
figured that since my method is higher up in the search path, it should
get called before the one in the `base' package.

If it helps, here are the class and method definitions.  What I find
strange is that all of my other methods get called correctly except this
one.

setClass("gpc.poly",
         representation(pts = "list"),
         prototype(pts = NULL)
         )

setMethod("[", signature(x = "gpc.poly", j = "missing"),
          function(x, i, ..., drop = FALSE) {
              x at pts <- x at pts[i]
              x
          })

Thanks,

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Tue, 31 Dec 2002, John Chambers wrote:

> The problem here is that the standard R way of attaching a package is to
> source in the R code; when the code contains setMethod() calls and the
> like, the result is to store the resulting definitions in the global
> environment.
> 
> When you're writing packages using methods, you essentially always want
> to use an alternative installation for the package, which creates a
> binary image when R INSTALL runs.   This image is loaded when the
> package is attached by calling library(), and the objects for methods,
> etc. are in the package database,as you would like.
> 
> There's a paragraph in the online documentation for INSTALL that
> describes what to do.  (if you want a quick fix, just touch an empty
> file install.R in the package's top level directory.)
> 
> When you run INSTALL, you should see a line:
> 
> ** save image
> 
> in the printout.  And no files generated in the global environment from
> calling library()
> 
> Regards,
>  John Chambers
> 
> Roger Peng wrote:
> > 
> > I'm trying to write a package which uses classes/methods as defined in the
> > `methods' package.  I have a single .R file which defines the class and
> > various methods for that class.  At the top of the file I have
> > 
> > require(methods)
> > 
> > and then
> > 
> > setClass("myclass", ...)
> > setGeneric("intersect")
> > setMethod("intersect", "myclass", function(x,y) ...)
> > 
> > I noticed that when I build the package and subsequently load it via
> > library(), the methods show up in the global workspace, which is not quite
> > what I wanted.
> > 
> > In general, is there any documentation on building packages with the
> > `methods' package (i.e. is it any different from building packages without
> > `methods'?) or perhaps an R-help thread I should look for?
> > 
> > In short, how should I setup my package so that my methods do not show up
> > in the global workspace?
> > 
> > Thanks,
> > 
> > -roger
> > _______________________________
> > UCLA Department of Statistics
> > rpeng at stat.ucla.edu
> > http://www.stat.ucla.edu/~rpeng
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> -- 
> John M. Chambers                  jmc at bell-labs.com
> Bell Labs, Lucent Technologies    office: (908)582-2681
> 700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
> Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc
>



From ripley at stats.ox.ac.uk  Fri Jan  3 08:49:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan  3 08:49:02 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <20030102205628.3141f54d.fharrell@virginia.edu>
Message-ID: <Pine.LNX.4.31.0301030738280.27001-100000@gannet.stats>

On Thu, 2 Jan 2003, Frank E Harrell Jr wrote:

> Under
>
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    6.1
> year     2002
> month    11
> day      01
> language R
>
> > x <- strptime(c('10/10/1969','12/31/2002'),format='%m/%d/%Y')
> > x
> [1] "1969-10-10" "2002-12-31"
> > as.POSIXct(x)
> [1] NA               "2002-12-31 EST"
>
> Why the NA?  If this is not the preferred way to convert a character
string to POSIXct what is?

It's a function of your system, which is telling you that is an invalid
*time* (it is midnight, BTW). I get

> as.POSIXct(x)
[1] "1969-10-10 GMT" "2002-12-31 GMT"

Did by any chance your locale change time zones that day?  Trying giving a
valid time as well.

> On a more minor note why the EST if no time is printed?

Because it has to be in some time zone, and it uses the current one if you
did not specify it (there is a tz argument, and it is described on the
help page!).  As far as I can see from your email headers you are in EST.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan  3 09:14:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan  3 09:14:03 2003
Subject: [R]  factor analysis (pca): how to get the 'communalities'?
In-Reply-To: <18ULl2-1CitzUC@fwd01.sul.t-online.com>
Message-ID: <Pine.LNX.4.31.0301030746580.27001-100000@gannet.stats>

On Fri, 3 Jan 2003, Wolfgang Lindner wrote:

> I try some test data for a factorAnalysis (resp. pca) in the sense of Prof.

Well, factor analysis and pca are different things, and only one
is appropriate in a given problem.

> Ripley's MASS § 11.1, p. 330 ff.,

Eh?  Would that be *Venables & Ripley's* MASS, and if so which edition (it
is not the current one).  Those editions which cover factor analysis do
explain the difference.

>just to prepare myself for an analysis of my
> own empirical data using R (instead of SPSS).
>
> 1. the data.
>
> ## The test data is (from the book of Backhaus et al.: Multivariate ##
> Analysemethoden. Springer 2000 [9th ed.], p. 300 ff):
>
> a<-c(4.5,5.167,5.059,3.8,3.444,3.5,5.25,5.857,5.083,5.273,4.5)
> b<-c(4.0,4.25,3.824,5.4,5.056,3.5,3.417,4.429,4.083,3.6,4.0)
> c<-c(4.375,3.833,4.765,3.8,3.778,3.875,4.583,4.929,4.667,3.909,4.2)
> d<-c(3.875,3.833,3.438,2.4,3.765,4.0,3.917,3.857,4.0,4.091,3.9)
> e<-c(3.25,2.167,4.235,5.0,3.944,4.625,4.333,4.071,4.0,4.091,3.7)
> f<-c(3.75,3.75,4.471,5.0,5.389,5.250,4.417,5.071,4.25,4.091,3.9)
> g<-c(4.0,3.273,3.765,5.0,5.056,5.5,4.667,2.929,3.818,4.545,3.6)
> h<-c(2.0,1.857,1.923,4.0,5.615,6.0,3.25,2.091,1.545,1.6,1.5)
> i<-c(4.625,3.75,3.529,4.0,4.222,4.75,4.5,4.571,3.75,3.909,3.5)
> j<-c(4.125,3.417,3.529,4.6,5.278,5.375,3.583,3.786,4.167,3.818,3.7)
>
> m<-data.frame(a,b,c,d,e,f,g,h,i,j)
>
> 2. My try of a pca with R.
>
> ## My R input was:
>
> m
> cor(m)
> library(mva)
> m.pca<-princomp(m,cor=T)
> m.pca
> summary(m.pca)
> loadings(m.pca)
> m.pca$scores
> m.FA <- factanal(factors = 3, covmat=cov(m))
> m.FA
>
> 3. Here are my questions.
>
> Q1.
> The cor(m)-Matrix is the same as reported by using SPSS (or OpenStats2).
> But in R I get other eigenvalues compared with the following SPSS output:

You don't get eigenvalues at all in R.  You do get `Proportion of
Variance' which are these numbers divided by their total.

> Original matrix trace =  10,00
> Roots (Eigenvalues) Extracted:
>    1  5,052
>    2  1,771
>    3  1,427
>    4  0,819
>    5  0,430
>    6  0,247
>    7  0,159
>    8  0,062
>    9  0,029
>   10  0,003
>
> - What is going behind the scene?

Why don't you ask the SPSS people that?  R at least gives you sensible
labels on the output.

> - Or what I am doing wrong in my use of R?
> - If I am doing the pca correct, can I use the R results as equally aceptable
>   without further discussion?

No, as more acceptable: at least they have meaningful labels.

>   Maybe a different 'hidden' algorithm is the reason for different results?

Ask SPSS that.  R's code is open, and nothing is hidden.  You have not
demonstrated that the results are different, anyway!

> Q2. How to get the so called 'Communality Estimates' with R?

First, use the data as in

> (m.FA <- factanal(m, factors=3))

and where did the number of factors come from?

100*(1 - m.FA$uniquenesses) gives the communalities.  They are different
from SPSS, because (1) R uses maximum likelihood FA and (2) tries a lot
harder to find a maximum and there are many local maxima in most FA
problems.

In this case you have fitted too many factors, and just one suffices.

> Here the values reported by SPSS for the above test data.frame m:
> Communality Estimates as percentages:
>   1 88,619
>   2 76,855
>   3 89,167
>   4 85,324
>   5 76,043
>   6 84,012
>   7 80,223
>   8 92,668
>   9 63,297
>  10 88,786
>
> Any help, suggestions or hints are very welcome.

1) Be a lot more accurate.
2) Read the help pages to find out what the output means.  In the case of
R the information is there, but you may well have to post on an SPSS help
list to find out why SPSS gives different output from R.
3) Don't believe SPSS knows what it is doing.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From LindnerW at t-online.de  Fri Jan  3 09:53:03 2003
From: LindnerW at t-online.de (Wolfgang Lindner)
Date: Fri Jan  3 09:53:03 2003
Subject: [R]  factor analysis (pca): how to get the 'communalities'?
Message-ID: <18UNZ7-09cR4zC@fwd07.sul.t-online.com>

Dear Prof. Ripley,

many thanks for your prompt answer and the valuable hints and pointers, I will 
study them and try it again.

1.
Sorry, for not giving the full quote; my book is:

Venables & Ripley: MASS. Springer 1999, 3rd Ed. (Corr. 3rd printing 2001); 
           ? 11.1, p. 330 ff.                   (?11 written by B.D.R.)

> Those editions which cover factor analysis do explain the difference.
So I will look for the latest edition ..

2.
> 3) Don't believe SPSS knows what it is doing.
o.k. I see ;-) 

Best regards
Wolfgang

--
Wolfgang Lindner                           Lindner at math.uni-duisburg.de
   Gerhard-Mercator-Universitaet Duisburg  Tel: +49 0203 379-1326
   Fakultaet 4 - Naturwissenschaften       Fax: +49 0203 379-2528
   Institut fuer Mathematik,  LE 424
   Lotharstr. 65
   D 47048  Duisburg (Germany)



From allende at gredos.cnb.uam.es  Fri Jan  3 10:54:03 2003
From: allende at gredos.cnb.uam.es (allende@gredos.cnb.uam.es)
Date: Fri Jan  3 10:54:03 2003
Subject: [R] type of representation
Message-ID: <200301030946.h039kEZC016353@chico.rediris.es>

Hi

I have some data that i want to plot but i don't find how to do it. I have car
types (bmw,renault,mercedes,seat ...), colors and a number for each car
type-color relation.I want to come up with a matrix representation of cars vs
colors where in each intersection i could set a dot proportional in size to my
third variable.


Can anybody give me a clue of hoe to come up with such representation.

Thanks

Ramon



From alobo at ija.csic.es  Fri Jan  3 13:00:04 2003
From: alobo at ija.csic.es (Agustin Lobo)
Date: Fri Jan  3 13:00:04 2003
Subject: [R] 3D array display with (x,g)gobi from R
Message-ID: <Pine.OSF.3.96.1030103130537.8868F-100000@paleo.ija.csic.es>

Does anyone know if it is possible to display
an R 3D array with ggobi or xgobi?
For example, if I try 
ggobi(cubo) 
where cubo is  an
array with dimensions (100,100,22)
I get
"Error in as.data.frame.default(data) : can't coerce array into a
data.frame"

Should I transform the array
into a dataframe with columns
x,y,x,value 

?

Is there any other way?
My goal is to visualize an slice,
select a cell, and plot
the values in the z axis
for that cell.

Thanks

Agus 

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es



From luke at inpharmatica.co.uk  Fri Jan  3 14:11:02 2003
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Fri Jan  3 14:11:02 2003
Subject: [R] R talking to Oracle, ODBC drivers available ?
In-Reply-To: <20030103110006.26765.7217.Mailman@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.21.0301031305310.2799-100000@dollis-hill.inpharmatica.co.uk>

[sorry, but this is a re-post - I forgot to set the subject line 
 the first time around]

Hello,

I would like to access an Oracle database running on Solaris from
R on my linux desktop. I have had a look at the R Data Import/Export
manual, and downloaded RODBC and unixODBC, but I am still quite confused
about how to proceed. It appears to me that I still need to get an Oracle
ODBC driver, and the only one I can find is from Easysoft for 880 euros,
which is not available for this project.

Is there any free software which will enable R on linux to talk to Oracle
on Solaris (both reading and writing data) ? 

My R setup is as follows:

platform i386-pc-linux-gnu
arch     i386             
os       linux-gnu        
system   i386, linux-gnu  
status                    
major    1                
minor    5.1              
year     2002             
month    06               
day      17               
language R                

Thanks,

Luke Whitaker.



From ripley at stats.ox.ac.uk  Fri Jan  3 14:39:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan  3 14:39:03 2003
Subject: [R] R talking to Oracle, ODBC drivers available ?
In-Reply-To: <Pine.LNX.4.21.0301031305310.2799-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <Pine.LNX.4.31.0301031337490.1408-100000@gannet.stats>

Have you looked at ROracle on CRAN?  I don't know if it will work to a
remote Solaris database, as we have no need of that.

On Fri, 3 Jan 2003, Luke Whitaker wrote:

>
> [sorry, but this is a re-post - I forgot to set the subject line
>  the first time around]
>
> Hello,
>
> I would like to access an Oracle database running on Solaris from
> R on my linux desktop. I have had a look at the R Data Import/Export
> manual, and downloaded RODBC and unixODBC, but I am still quite confused
> about how to proceed. It appears to me that I still need to get an Oracle
> ODBC driver, and the only one I can find is from Easysoft for 880 euros,
> which is not available for this project.
>
> Is there any free software which will enable R on linux to talk to Oracle
> on Solaris (both reading and writing data) ?
>
> My R setup is as follows:
>
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status
> major    1
> minor    5.1
> year     2002
> month    06
> day      17
> language R
>
> Thanks,
>
> Luke Whitaker.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pvirketis at hbk.com  Fri Jan  3 14:52:02 2003
From: pvirketis at hbk.com (Pijus Virketis)
Date: Fri Jan  3 14:52:02 2003
Subject: [R] Interfacing R and C++ under Windows
Message-ID: <BFC55A5E0CBD26488EF3EE2E162FFA7F063E6A@nycdc1.hbk.com>

Dear all, 

My colleague, who has been helping me with wrapping some older C++ code for use in R, has been running into some issues, which he asked me to post here:

- ERROR is defined in RS.h which is included in Rdefines.h which conflicts with Visual Studio's ERROR
- TRACE is defined in Rinternals.h which conflicts with Visual Studio's TRACE
- math.h is included within extern "C" linkage in R.h, however Visual Studio's math.h includes templates which are only valid in C++

Basically, he feels that there are some clear conflicts between what R expects of C++ and what Visual C++ does. So, while the simpler .C technique can be used, the .Call approach does not work. What are we missing here? 


Thank you!

Pijus



From phgrosjean at sciviews.org  Fri Jan  3 15:04:03 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri Jan  3 15:04:03 2003
Subject: [R] RE: stange behavior of subset [] (was: lowess + turnpoints = doubling integers?)
In-Reply-To: <200301022057.PAA20085@rygar.gpcc.itd.umich.edu>
Message-ID: <MABBLJDICACNFOLGIHJOGEEBDCAA.phgrosjean@sciviews.org>

Tom Blackwell wrote:
>...
>I summarized this to myself as "computed subscripts need explicit
>rounding in R, but not in S".  Here's the sample code which gave
>me different results with R than with Splus.  I no longer have
>Splus available, so I can't check it again.

>look <- (10 * seq(14)) - 76
>chk.1 <- seq(1420)[ 10 * (73.1 + look) ]             #  NOT what I expected
>chk.2 <- seq(1420)[ round(10 * (73.1 + look), 0) ]   #  much better.
>...

Hum, hum,... It reminds me a "bug" that was very difficult to track in a
function! This is a very interesting point. Actually, it works exactly the
same in Splus 6.1 for Windows and in R 1.6.1. Look also at the following:

> look <- (10 * seq(14)) - 76
> 10 * (73.1 + look)
 [1]   71  171  271  371  491  586  681  791  886  981 1101 1201 1301 1401
> as.integer(10 * (73.1 + look))
 [1]   70  170  270  370  490  586  681  791  886  981 1101 1201 1301 1401

as.integer() does not round doubles, but truncates them toward zero... and
[] coerces doubles to integers using as.integer(). This is not a bug, since
it is fully documented in Splus:

In help("["):

...
The expressions may also be logical, numeric, or character. Numeric
subscripts should be integers, such as the output from : (the sequence
operator).

...
Subscripting coerces non-integer numeric subscripts to integers using
as.integer . Because as.integer creates integers by truncating the numeric
representation, this coercion can lead to unexpected results.

and in help(as.integer):
...
The numbers are truncated (moved to the closest integer the original number
that is towards zero). Attributes are deleted.

However, this could be vicious! Why not to round double in as.integer()?
Perhaps for performance questions?
Yet, this is not documented at all in R (neither in help("["), nor in
help(as.integer)!!!). Any other comment on this?

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



From ripley at stats.ox.ac.uk  Fri Jan  3 15:09:13 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan  3 15:09:13 2003
Subject: [R] Interfacing R and C++ under Windows
In-Reply-To: <BFC55A5E0CBD26488EF3EE2E162FFA7F063E6A@nycdc1.hbk.com>
Message-ID: <Pine.LNX.4.31.0301031356070.1501-100000@gannet.stats>

On Fri, 3 Jan 2003, Pijus Virketis wrote:

> My colleague, who has been helping me with wrapping some older C++ code for use in R, has been running into some issues, which he asked me to post here:
>
> - ERROR is defined in RS.h which is included in Rdefines.h which conflicts with Visual Studio's ERROR
> - TRACE is defined in Rinternals.h which conflicts with Visual Studio's TRACE
> - math.h is included within extern "C" linkage in R.h, however Visual Studio's math.h includes templates which are only valid in C++
>
> Basically, he feels that there are some clear conflicts between what
R expects of C++ and what Visual C++ does. So, while the simpler .C
technique can be used, the .Call approach does not work. What are we missing
here?

A real C++ compiler (and enough netiquette to wrap your lines).

Why are you using VC++ with R: it is most definitely not the recommended C
compiler?  Using standard C++ and the recommended compiler usually works,
modulo undefining symbols defined in windows.h or its dependencies.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mmiller3 at iupui.edu  Fri Jan  3 15:18:02 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Fri Jan  3 15:18:02 2003
Subject: [R] help.start() directory?
Message-ID: <8765t6wc7z.fsf@lumen.indyrad.iupui.edu>

The help for help.start says that 

  "All the packages in the known library trees are linked to
  directory `.R' in the per-session temporary directory. The
  links are re-made each time help.start is run, which should be
  done after packages are installed, updated or removed."

It used to be the case that this was the temporary directory was
the .R directory in my home directory, but since I've upgraded to
R 6.1, the help files are stored in /tmp/Rtmpxxx/.R, where
Rtmpxxx is the result of a call to tempdir.  A side effect of
this is that they are removed when ever I exit R and recreated
when I start R and run help.start again.  I like to be able to
have a couple book marks to my favorite parts of the help pages,
but since the tempdir is different for each instance of R, that
no longer works.  Is there a way to configure R to leave the help
pages in a static location such as ~/.R?  Even if they get
recreated each time I run help.start, I'd rather they always
showed up in the same place.

Thanks, Mike


> R.version
         _                
platform i386-pc-linux-gnu
arch     i386             
os       linux-gnu        
system   i386, linux-gnu  
status                    
major    1                
minor    6.1              
year     2002             
month    11               
day      01               
language R



From William.Simpson at drdc-rddc.gc.ca  Fri Jan  3 15:43:03 2003
From: William.Simpson at drdc-rddc.gc.ca (Simpson, William)
Date: Fri Jan  3 15:43:03 2003
Subject: [R] number plot symbol in scatterplot?
Message-ID: <73D42D02E332D61197F80002A541D13F98AFE8@torex.toronto.drdc-rddc.gc.ca>

If I make a scatterplot and several (e.g. 5) points lie on top of each other
at a given x,y location I would like the plot symbol to be the number of
superimposed points (e.g. "5"). Could someone please tell me how to do this
in R? Thanks!

Bill Simpson



From maechler at stat.math.ethz.ch  Fri Jan  3 16:30:03 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Jan  3 16:30:03 2003
Subject: [R] number plot symbol in scatterplot?
In-Reply-To: <73D42D02E332D61197F80002A541D13F98AFE8@torex.toronto.drdc-rddc.gc.ca>
References: <73D42D02E332D61197F80002A541D13F98AFE8@torex.toronto.drdc-rddc.gc.ca>
Message-ID: <15893.44129.364025.643212@gargle.gargle.HOWL>

>>>>> "BillS" == Simpson, William <William.Simpson at drdc-rddc.gc.ca>
>>>>>     on Fri, 3 Jan 2003 09:41:32 -0500 writes:

    BillS> If I make a scatterplot and several (e.g. 5) points
    BillS> lie on top of each other at a given x,y location I
    BillS> would like the plot symbol to be the number of
    BillS> superimposed points (e.g. "5"). Could someone please
    BillS> tell me how to do this in R? Thanks!

(typical Martin's answer:  ``You don't want what you are asking for'').

No, seriously, I think using sunflowerplot() {as recommended by
Chambers et al (1983) see help} is a bit better {-> ?sunflowerplot and examples}

Other solutions to the same problem:
 b. use jittering   jitter()

 c. use a ``2d density estimate'' and plot that
  1) e.g. use image on a 2d histog
  2) better use the "hexbin" package from bioconductor,
    this uses Dan Carr's Hexagons instead of squares and (some
     more ideas).

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From tblackw at umich.edu  Fri Jan  3 16:36:02 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri Jan  3 16:36:02 2003
Subject: [R] number plot symbol in scatterplot?
In-Reply-To: <73D42D02E332D61197F80002A541D13F98AFE8@torex.toronto.drdc-rddc.gc.ca>
Message-ID: <Pine.SOL.4.44.0301031017050.23132-100000@mspacman.gpcc.itd.umich.edu>

Bill  -

The behavior of the old-S function  printer()  was to count overstrikes
in the way you describe.  This was a non-graphics output device which
would make a crude scatterplot using ascii characters (spaces and
asterisks, for example) in response to  "plot()" commands.

I've looked for "printer" in  help(Devices)  and I don't find it.
Non-graphics scatterplots probably haven't been implemented for R
yet, and probably aren't a high priority.  I think you'll have to
count the overstrikes at each location yourself (hash the x-y
coordinates), and then use the function  text()  to plot the
appropriate symbol at each x-y location.

-  tom blackwell  -  university of michigan medical  -  ann arbor  -


On Fri, 3 Jan 2003, Simpson, William wrote:

> If I make a scatterplot and several (e.g. 5) points lie on top of each other
> at a given x,y location I would like the plot symbol to be the number of
> superimposed points (e.g. "5"). Could someone please tell me how to do this
> in R? Thanks!
>
> Bill Simpson
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From macq at llnl.gov  Fri Jan  3 16:53:03 2003
From: macq at llnl.gov (Don MacQueen)
Date: Fri Jan  3 16:53:03 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <20030102205628.3141f54d.fharrell@virginia.edu>
References: <20030102205628.3141f54d.fharrell@virginia.edu>
Message-ID: <p05200f0aba3b5b38bb8e@[128.115.153.6]>

No problem on a couple of systems here, one Solaris and one Mac OS X. 
See below.

The conversion of a character string to a POSIXct is taking place in 
two steps--character string to POSIXlt, then POSIXlt to POSIXct. 
Which step has the problem?

Compare your unclass(x) with my unclass(x). If it's different, the 
problem would appear to be in converting text to POSIXlt.

My guess would be a bug in the underlying Linux code, since, as Dr. 
Ripley said, your system thinks it's an invalid time--yet the time is 
not invalid.

Does it fail only on that particular day? If there was a EDT to EST 
change that day, does it fail on other EDT to EST change days? If 
there was an EDT to EST change that day, did it occur at the usual 
2:00 AM? What about EST to EDT changes?

If your character strings were in the ISO standard format, it would 
be simpler to use as.POSIXct() directly, as in

>  as.POSIXct(c('1969-10-10','2002-12-31'))
[1] "1969-10-10 PDT" "2002-12-31 PST"
>  class(as.POSIXct(c('1969-10-10','2002-12-31')))
[1] "POSIXt"  "POSIXct"

But you probably don't have that luxury. Even so, it would be 
interesting to find out if it succeeds on your system.

-Don

>  version
          _                  
platform sparc-sun-solaris2.7
arch     sparc              
os       solaris2.7         
system   sparc, solaris2.7  
status                      
major    1                  
minor    6.1                
year     2002               
month    11                 
day      01                 
language R
>  x <- strptime(c('10/10/1969','12/31/2002'),format='%m/%d/%Y')
>  x
[1] "1969-10-10" "2002-12-31"
>  as.POSIXct(x)
[1] "1969-10-10 PDT" "2002-12-31 PST"
>  class(x)
[1] "POSIXt"  "POSIXlt"
>  unclass(x)
$sec
[1] 0 0

$min
[1] 0 0

$hour
[1] 0 0

$mday
[1] 10 31

$mon
[1]  9 11

$year
[1]  69 102

$wday
[1] 5 2

$yday
[1] 282 364

$isdst
[1] 1 0

>

-------- OS X ----------
>  version
          _                     
platform powerpc-apple-darwin6.2
arch     powerpc               
os       darwin6.2             
system   powerpc, darwin6.2    
status                         
major    1                     
minor    6.1                   
year     2002                  
month    11                    
day      01                    
language R

>  x <- strptime(c('10/10/1969','12/31/2002'),format='%m/%d/%Y')
>  x
[1] "1969-10-10" "2002-12-31"
>  as.POSIXct(x)
[1] "1969-10-10 PDT" "2002-12-31 PST"
>  unclass(x)
$sec
[1] 0 0

$min
[1] 0 0

$hour
[1] 0 0

$mday
[1] 10 31

$mon
[1]  9 11

$year
[1]  69 102

$wday
[1] 5 2

$yday
[1] 282 364

$isdst
[1] 1 0


At 8:56 PM -0500 1/2/03, Frank E Harrell Jr wrote:
>Under
>
>platform i686-pc-linux-gnu
>arch     i686            
>os       linux-gnu       
>system   i686, linux-gnu 
>status                   
>major    1               
>minor    6.1             
>year     2002            
>month    11              
>day      01              
>language R               
>
>>  x <- strptime(c('10/10/1969','12/31/2002'),format='%m/%d/%Y')
>>  x
>[1] "1969-10-10" "2002-12-31"
>>  as.POSIXct(x)
>[1] NA               "2002-12-31 EST"
>
>Why the NA?  If this is not the preferred way to convert a character 
>string to POSIXct what is?  On a more minor note why the EST if no 
>time is printed?
>
>Thanks,
>
>Frank
>--
>Frank E Harrell Jr              Prof. of Biostatistics & Statistics
>Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
>U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------



From jgentry at jimmy.harvard.edu  Fri Jan  3 16:56:03 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Fri Jan  3 16:56:03 2003
Subject: [R] Packages w/ S4 classes in C?
Message-ID: <Pine.SOL.4.20.0301031051180.19871-100000@santiam.dfci.harvard.edu>

Hello ...

Does anyone know of a package (or other code) out there which has handled
S4 classes in C?  I realize that a lot of this stuff is fairly new in
R-devel, so my assumption is no - but there seems to be some deviation
from the green book that is really throwing me off, and I'm looking for
some sort of front-to-back example.

Thanks
-Jeff



From macq at llnl.gov  Fri Jan  3 17:01:02 2003
From: macq at llnl.gov (Don MacQueen)
Date: Fri Jan  3 17:01:02 2003
Subject: [R] R talking to Oracle, ODBC drivers available ?
In-Reply-To: 
 <Pine.LNX.4.21.0301031305310.2799-100000@dollis-hill.inpharmatica.co.uk>
References: 
 <Pine.LNX.4.21.0301031305310.2799-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <p05200f0bba3b624762f3@[128.115.153.6]>

I believe that Oracle provides ODBC drivers for the server 
side--provided you have an Oracle administrator who can figure out 
how to install them. I couldn't find much documentation.

For another commercial source see www.openlink.com (don't know if 
they have client drivers for Linux).

-Don

At 1:10 PM +0000 1/3/03, Luke Whitaker wrote:
>[sorry, but this is a re-post - I forgot to set the subject line
>  the first time around]
>
>Hello,
>
>I would like to access an Oracle database running on Solaris from
>R on my linux desktop. I have had a look at the R Data Import/Export
>manual, and downloaded RODBC and unixODBC, but I am still quite confused
>about how to proceed. It appears to me that I still need to get an Oracle
>ODBC driver, and the only one I can find is from Easysoft for 880 euros,
>which is not available for this project.
>
>Is there any free software which will enable R on linux to talk to Oracle
>on Solaris (both reading and writing data) ?
>
>My R setup is as follows:
>
>platform i386-pc-linux-gnu
>arch     i386            
>os       linux-gnu       
>system   i386, linux-gnu 
>status                   
>major    1               
>minor    5.1             
>year     2002            
>month    06              
>day      17              
>language R               
>
>Thanks,
>
>Luke Whitaker.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------



From jgramlich at piocon.com  Fri Jan  3 17:13:02 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Fri Jan  3 17:13:02 2003
Subject: [R] Tutorials?
References: <Pine.SOL.4.20.0301031051180.19871-100000@santiam.dfci.harvard.edu>
Message-ID: <00a001c2b342$ec57b6a0$cc3ac341@ginworks.com>

Are there any tutorials or books for learning R?  Of course, I have the
manual, but that seems more of a reference than a teaching tool.

Joshua Gramlich
Chicago, IL



From edd at debian.org  Fri Jan  3 17:23:02 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri Jan  3 17:23:02 2003
Subject: [R] Tutorials?
In-Reply-To: <00a001c2b342$ec57b6a0$cc3ac341@ginworks.com>
References: <Pine.SOL.4.20.0301031051180.19871-100000@santiam.dfci.harvard.edu> <00a001c2b342$ec57b6a0$cc3ac341@ginworks.com>
Message-ID: <20030103162253.GA14611@sonny.eddelbuettel.com>

On Fri, Jan 03, 2003 at 10:12:28AM -0600, Joshua Gramlich wrote:
> Are there any tutorials or books for learning R?  Of course, I have the
> manual, but that seems more of a reference than a teaching tool.

There are lots of fine contributed manuals at 
      http://cran.us.r-project.org/other-docs.html
      
Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr



From feldesmanm at pdx.edu  Fri Jan  3 17:26:06 2003
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Fri Jan  3 17:26:06 2003
Subject: [R] Tutorials?
In-Reply-To: <00a001c2b342$ec57b6a0$cc3ac341@ginworks.com>
References: <Pine.SOL.4.20.0301031051180.19871-100000@santiam.dfci.harvard.edu>
Message-ID: <5.1.1.5.2.20030103082059.0157eb68@pop4.attglobal.net>

An Introduction to R, The R Core Team
An Introduction to Statistics with R, Peter Dalgaard
Modern Applied Statistics with S, W.N. Venables and B.D. Ripley, 4th Edition.

And many others with links on http://cran.r-project.org/ under 
"Contributed|Documentation"



From William.Simpson at drdc-rddc.gc.ca  Fri Jan  3 17:30:10 2003
From: William.Simpson at drdc-rddc.gc.ca (Simpson, William)
Date: Fri Jan  3 17:30:10 2003
Subject: [R] number plot symbol in scatterplot?
Message-ID: <73D42D02E332D61197F80002A541D13F98AFE9@torex.toronto.drdc-rddc.gc.ca>

OK Thanks Martin and Thomas I'll check sunflowerplot()

Bill



From p.dalgaard at biostat.ku.dk  Fri Jan  3 17:34:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan  3 17:34:02 2003
Subject: [R] Tutorials?
In-Reply-To: <00a001c2b342$ec57b6a0$cc3ac341@ginworks.com>
References: <Pine.SOL.4.20.0301031051180.19871-100000@santiam.dfci.harvard.edu>
	<00a001c2b342$ec57b6a0$cc3ac341@ginworks.com>
Message-ID: <x28yy2qjp5.fsf@biostat.ku.dk>

"Joshua Gramlich" <jgramlich at piocon.com> writes:

> Are there any tutorials or books for learning R?  Of course, I have the
> manual, but that seems more of a reference than a teaching tool.

There's more than one manual shipping with R, and a couple of books
(including one by yours truly). Have a look at section 2.7 in the R
FAQ:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#What%20documentation%20exists%20for%20R%3f

and as Dirk mentioned, the contributed docs on CRAN too.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jgramlich at piocon.com  Fri Jan  3 17:40:03 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Fri Jan  3 17:40:03 2003
Subject: [R] tutorials...thanks
Message-ID: <00c701c2b346$9e9da790$cc3ac341@ginworks.com>

Thanks for the info folks.  This mailing list is unbelievably helpful,
responsive and polite!


Joshua Gramlich
Chicago, IL



From ripley at stats.ox.ac.uk  Fri Jan  3 17:49:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan  3 17:49:02 2003
Subject: [R] help.start() directory?
In-Reply-To: <8765t6wc7z.fsf@lumen.indyrad.iupui.edu>
Message-ID: <Pine.LNX.4.31.0301031646240.1694-100000@gannet.stats>

No, but as these are links you can bookmark the places they link to.

On 3 Jan 2003, Michael A. Miller wrote:

> The help for help.start says that
>
>   "All the packages in the known library trees are linked to
>   directory `.R' in the per-session temporary directory. The
>   links are re-made each time help.start is run, which should be
>   done after packages are installed, updated or removed."
>
> It used to be the case that this was the temporary directory was
> the .R directory in my home directory, but since I've upgraded to
> R 6.1, the help files are stored in /tmp/Rtmpxxx/.R, where
> Rtmpxxx is the result of a call to tempdir.  A side effect of
> this is that they are removed when ever I exit R and recreated
> when I start R and run help.start again.  I like to be able to
> have a couple book marks to my favorite parts of the help pages,
> but since the tempdir is different for each instance of R, that
> no longer works.  Is there a way to configure R to leave the help
> pages in a static location such as ~/.R?  Even if they get
> recreated each time I run help.start, I'd rather they always
> showed up in the same place.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan  3 18:02:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan  3 18:02:02 2003
Subject: [R] help.start() directory?
In-Reply-To: <Pine.LNX.4.31.0301031646240.1694-100000@gannet.stats>
Message-ID: <Pine.LNX.4.31.0301031659210.1694-100000@gannet.stats>

On Fri, 3 Jan 2003 ripley at stats.ox.ac.uk wrote:

> No, but as these are links you can bookmark the places they link to.

Oh, and the reason we now do it this way is that you can have two
simultaneous R sessions with quite different library trees, possibly
different versions of R running on different machines.

> On 3 Jan 2003, Michael A. Miller wrote:
>
> > The help for help.start says that
> >
> >   "All the packages in the known library trees are linked to
> >   directory `.R' in the per-session temporary directory. The
> >   links are re-made each time help.start is run, which should be
> >   done after packages are installed, updated or removed."
> >
> > It used to be the case that this was the temporary directory was
> > the .R directory in my home directory, but since I've upgraded to
> > R 6.1, the help files are stored in /tmp/Rtmpxxx/.R, where
> > Rtmpxxx is the result of a call to tempdir.  A side effect of
> > this is that they are removed when ever I exit R and recreated
> > when I start R and run help.start again.  I like to be able to
> > have a couple book marks to my favorite parts of the help pages,
> > but since the tempdir is different for each instance of R, that
> > no longer works.  Is there a way to configure R to leave the help
> > pages in a static location such as ~/.R?  Even if they get
> > recreated each time I run help.start, I'd rather they always
> > showed up in the same place.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gregory_r_warnes at groton.pfizer.com  Fri Jan  3 18:54:05 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri Jan  3 18:54:05 2003
Subject: [R] type of representation
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C40F@groexmb02.pfizer.com>

How about this snippet:

# Create an Example Data Frame Containing Car x Color data
carnames <- c("bmw","renault","mercedes","seat")
carcolors <- c("red","white","silver","green")
datavals <- round(rnorm(16, mean=10, sd=4),1)
data <- data.frame(Car=rep(carnames,4),
                   Color=rep(carcolors, c(4,4,4,4) ),
                   Value=datavals )
# show the data
data

# plot the Car x Color combinations, using 'cex' to specify the dot size
plot(x=codes(data$Car),     # codes give numeric values
     y=codes(data$Color), 
     cex=data$Value/max(data$Value)*12,  # standardize size to (0,12)
     pch=19,  # filled circle
     col="skyblue", # dot color
     xlab="Car", # x axis label
     ylab="Color", # y axis label
     xaxt="n", # no x axis lables
     yaxt="n", # no y axis lables
     bty="n",  # no box around the plot
     xlim=c(0,nlevels(data$Car  )+0.5), # extra space on either end of plot
     ylim=c(0.5,nlevels(data$Color)+1.5)  # so dots don't cross into margins
     )

# add text labels
text(x=1:nlevels(data$Car), y=nlevels(data$Car)+1, labels=levels(data$Car))
text(x=0, y=1:nlevels(data$Color), labels=levels(data$Color) )

# add borders between cells
abline(v=(0:nlevels(data$Car)+0.5))
abline(h=(0:nlevels(data$Color)+0.5))

# annotate with actual values
text(x=codes(data$Car),     # codes give numeric values
     y=codes(data$Color), 
     labels=format(data$Value),       # label value
     col="black", # textt color
     )

# put a nice title
title(main="Car by Color Popularity\n(Dot size proportional to popularity)")


-Greg

> -----Original Message-----
> From: allende at gredos.cnb.uam.es [mailto:allende at gredos.cnb.uam.es]
> Sent: Friday, January 03, 2003 4:46 AM
> To: r-help at stat.math.ethz.ch
> Cc: allende at gredos.cnb.uam.es
> Subject: [R] type of representation
> 
> 
> Hi
> 
> I have some data that i want to plot but i don't find how to 
> do it. I have car
> types (bmw,renault,mercedes,seat ...), colors and a number 
> for each car
> type-color relation.I want to come up with a matrix 
> representation of cars vs
> colors where in each intersection i could set a dot 
> proportional in size to my
> third variable.
> 
> 
> Can anybody give me a clue of hoe to come up with such representation.
> 
> Thanks
> 
> Ramon
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From fharrell at virginia.edu  Fri Jan  3 19:06:02 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri Jan  3 19:06:02 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <p05200f0aba3b5b38bb8e@[128.115.153.6]>
References: <20030102205628.3141f54d.fharrell@virginia.edu>
	<p05200f0aba3b5b38bb8e@[128.115.153.6]>
Message-ID: <20030103130546.732763a5.fharrell@virginia.edu>

Thanks very much for all the helpful responses.  In response to Don MacQueen's note,

On Fri, 3 Jan 2003 07:51:42 -0800
Don MacQueen <macq at llnl.gov> wrote:

> No problem on a couple of systems here, one Solaris and one Mac OS X. 
> See below.
> 
> The conversion of a character string to a POSIXct is taking place in 
> two steps--character string to POSIXlt, then POSIXlt to POSIXct. 
> Which step has the problem?
> 
> Compare your unclass(x) with my unclass(x). If it's different, the 
> problem would appear to be in converting text to POSIXlt.

My unclass(x) has one small difference from yours.  The $isdst element is c(-1,0) instead of c(1,0).

> 
> My guess would be a bug in the underlying Linux code, since, as Dr. 
> Ripley said, your system thinks it's an invalid time--yet the time is 
> not invalid.
> 
> Does it fail only on that particular day? If there was a EDT to EST 
> change that day, does it fail on other EDT to EST change days? If 
> there was an EDT to EST change that day, did it occur at the usual 
> 2:00 AM? What about EST to EDT changes?

I get NA for any day in 1969 or earlier.  Using a time other than midnight did not help.  So it's not a problem with time zone changes on a given day (thanks, Brian and Don for suggesting I look at that).

Doing as.POSIXlt works fine, but I want POSIXct variables for storage in data frames.

I am at a loss on how to proceed but thanks to all for the help.

Frank
-----------------
> 
> If your character strings were in the ISO standard format, it would 
> be simpler to use as.POSIXct() directly, as in
> 
> >  as.POSIXct(c('1969-10-10','2002-12-31'))
> [1] "1969-10-10 PDT" "2002-12-31 PST"
> >  class(as.POSIXct(c('1969-10-10','2002-12-31')))
> [1] "POSIXt"  "POSIXct"
> 
> But you probably don't have that luxury. Even so, it would be 
> interesting to find out if it succeeds on your system.
> 
> -Don
> 
> >  version
>           _                  
> platform sparc-sun-solaris2.7
> arch     sparc              
> os       solaris2.7         
> system   sparc, solaris2.7  
> status                      
> major    1                  
> minor    6.1                
> year     2002               
> month    11                 
> day      01                 
> language R
> >  x <- strptime(c('10/10/1969','12/31/2002'),format='%m/%d/%Y')
> >  x
> [1] "1969-10-10" "2002-12-31"
> >  as.POSIXct(x)
> [1] "1969-10-10 PDT" "2002-12-31 PST"
> >  class(x)
> [1] "POSIXt"  "POSIXlt"
> >  unclass(x)
> $sec
> [1] 0 0
> 
> $min
> [1] 0 0
> 
> $hour
> [1] 0 0
> 
> $mday
> [1] 10 31
> 
> $mon
> [1]  9 11
> 
> $year
> [1]  69 102
> 
> $wday
> [1] 5 2
> 
> $yday
> [1] 282 364
> 
> $isdst
> [1] 1 0
> 
> >
> 
> -------- OS X ----------
> >  version
>           _                     
> platform powerpc-apple-darwin6.2
> arch     powerpc               
> os       darwin6.2             
> system   powerpc, darwin6.2    
> status                         
> major    1                     
> minor    6.1                   
> year     2002                  
> month    11                    
> day      01                    
> language R
> 
> >  x <- strptime(c('10/10/1969','12/31/2002'),format='%m/%d/%Y')
> >  x
> [1] "1969-10-10" "2002-12-31"
> >  as.POSIXct(x)
> [1] "1969-10-10 PDT" "2002-12-31 PST"
> >  unclass(x)
> $sec
> [1] 0 0
> 
> $min
> [1] 0 0
> 
> $hour
> [1] 0 0
> 
> $mday
> [1] 10 31
> 
> $mon
> [1]  9 11
> 
> $year
> [1]  69 102
> 
> $wday
> [1] 5 2
> 
> $yday
> [1] 282 364
> 
> $isdst
> [1] 1 0
> 
> 
> At 8:56 PM -0500 1/2/03, Frank E Harrell Jr wrote:
> >Under
> >
> >platform i686-pc-linux-gnu
> >arch     i686            
> >os       linux-gnu       
> >system   i686, linux-gnu 
> >status                   
> >major    1               
> >minor    6.1             
> >year     2002            
> >month    11              
> >day      01              
> >language R               
> >
> >>  x <- strptime(c('10/10/1969','12/31/2002'),format='%m/%d/%Y')
> >>  x
> >[1] "1969-10-10" "2002-12-31"
> >>  as.POSIXct(x)
> >[1] NA               "2002-12-31 EST"
> >
> >Why the NA?  If this is not the preferred way to convert a character 
> >string to POSIXct what is?  On a more minor note why the EST if no 
> >time is printed?
> >
> >Thanks,
> >
> >Frank
> --------------------------------------
> Don MacQueen
> Environmental Protection Department
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> --------------------------------------


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From gregory_r_warnes at groton.pfizer.com  Fri Jan  3 19:15:05 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri Jan  3 19:15:05 2003
Subject: [R] number plot symbol in scatterplot?
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C410@groexmb02.pfizer.com>

Another is to use the function 'space' in the gregmisc package.  It is used
like 'jitter', but it determistically spreads (nearly) overlapping points
out in either the x dimension so they don't overlap.   See ?space in the
gregmisc package for details.

I've found this useful for situations where the the x and y data is
discrete.

FTIW, the gregmisc package also contains the function hist2d, which will
create and plot a 2-dimensional histogram.

-Greg


> -----Original Message-----
> From: Simpson, William [mailto:William.Simpson at drdc-rddc.gc.ca]
> Sent: Friday, January 03, 2003 11:27 AM
> To: 'r-help at stat.math.ethz.ch'
> Subject: RE: [R] number plot symbol in scatterplot?
> 
> 
> OK Thanks Martin and Thomas I'll check sunflowerplot()
> 
> Bill
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From ripley at stats.ox.ac.uk  Fri Jan  3 19:45:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan  3 19:45:02 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <20030103130546.732763a5.fharrell@virginia.edu>
Message-ID: <Pine.LNX.4.31.0301031829400.1852-100000@gannet.stats>

On Fri, 3 Jan 2003, Frank E Harrell Jr wrote:

> Thanks very much for all the helpful responses.  In response to Don MacQueen's note,
>
> On Fri, 3 Jan 2003 07:51:42 -0800
> Don MacQueen <macq at llnl.gov> wrote:
>
> > No problem on a couple of systems here, one Solaris and one Mac OS X.
> > See below.
> >
> > The conversion of a character string to a POSIXct is taking place in
> > two steps--character string to POSIXlt, then POSIXlt to POSIXct.
> > Which step has the problem?
> >
> > Compare your unclass(x) with my unclass(x). If it's different, the
> > problem would appear to be in converting text to POSIXlt.
>
> My unclass(x) has one small difference from yours.  The $isdst element is c(-1,0) instead of c(1,0).

-1 means unknown, and 1 means in DST.  That's not a surprising difference.

> > My guess would be a bug in the underlying Linux code, since, as Dr.
> > Ripley said, your system thinks it's an invalid time--yet the time is
> > not invalid.
> >
> > Does it fail only on that particular day? If there was a EDT to EST
> > change that day, does it fail on other EDT to EST change days? If
> > there was an EDT to EST change that day, did it occur at the usual
> > 2:00 AM? What about EST to EDT changes?
>
> I get NA for any day in 1969 or earlier.  Using a time other than midnight did not help.  So it's not a problem with time zone changes on a given day (thanks, Brian and Don for suggesting I look at that).

Ahah, so Dirk's guess was right for your machine!  That's a new bug in
some version of glibc, I suppose.  Exactly what OS are you running, and
version of glibc (if you can tell)?

> Doing as.POSIXlt works fine, but I want POSIXct variables for storage in data frames.
>
> I am at a loss on how to proceed but thanks to all for the help.

Dirk had a Linux machine in (I believe) the same time zone which
gave the right answer.  So does mine if I set it to EST.

Try setting tz="GMT" is as.POSIXct if you don't care about times. It looks
from reading the code that this will work.  If you are compiling from
source, about line 220 of src/main/datetime.c reads

#ifdef Win32
       tm->tm_year >= 70)
#else
       tm->tm_year > 02)
#endif

and your machine seems to need the Win32 branch.  You might also need it
in localtime0 a few lines later.


We will probably need a configure test for this particular type of
brokenness.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan  3 20:01:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan  3 20:01:02 2003
Subject: Take care with codes()! (was [R] type of representation)
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C202F2C40F@groexmb02.pfizer.com>
Message-ID: <Pine.LNX.4.31.0301031846420.1852-100000@gannet.stats>


From p.dalgaard at biostat.ku.dk  Fri Jan  3 20:13:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan  3 20:13:02 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <20030103130546.732763a5.fharrell@virginia.edu>
References: <20030102205628.3141f54d.fharrell@virginia.edu>
	<p05200f0aba3b5b38bb8e@[128.115.153.6]>
	<20030103130546.732763a5.fharrell@virginia.edu>
Message-ID: <x2wulmgi8d.fsf@biostat.ku.dk>

Frank E Harrell Jr <fharrell at virginia.edu> writes:

 
> I get NA for any day in 1969 or earlier.  Using a time other than midnight did not help.  So it's not a problem with time zone changes on a given day (thanks, Brian and Don for suggesting I look at that).
> 
> Doing as.POSIXlt works fine, but I want POSIXct variables for storage in data frames.
> 
> I am at a loss on how to proceed but thanks to all for the help.

Not much consolation, I know, but I can confirm this with RedHat 8.0.
Also:

> as.POSIXct(as.POSIXlt(ISOdate(1969,10,10)))
[1] NA

However, with SuSE and 1.6.0, I see

> as.POSIXct(as.POSIXlt(ISOdate(1969,10,10)))
[1] "1969-10-10 13:00:00 CET"

So it looks like a difference between glibc 2.2.5 and 2.2.93. Sigh...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Fri Jan  3 20:26:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan  3 20:26:03 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <x2wulmgi8d.fsf@biostat.ku.dk>
References: <20030102205628.3141f54d.fharrell@virginia.edu>
	<p05200f0aba3b5b38bb8e@[128.115.153.6]>
	<20030103130546.732763a5.fharrell@virginia.edu>
	<x2wulmgi8d.fsf@biostat.ku.dk>
Message-ID: <x2smwaghld.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> Not much consolation, I know, but I can confirm this with RedHat 8.0.
> Also:
> 
> > as.POSIXct(as.POSIXlt(ISOdate(1969,10,10)))
> [1] NA
> 
> However, with SuSE and 1.6.0, I see
> 
> > as.POSIXct(as.POSIXlt(ISOdate(1969,10,10)))
> [1] "1969-10-10 13:00:00 CET"
> 
> So it looks like a difference between glibc 2.2.5 and 2.2.93. Sigh...

...and RedHat7.2 (glibc 2.2.4) doesn't have the problem either.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jzhang at jimmy.harvard.edu  Fri Jan  3 20:33:03 2003
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Fri Jan  3 20:33:03 2003
Subject: [R] Re: Embedding windows in a text widget
Message-ID: <200301031932.OAA06325@blaise.dfci.harvard.edu>

Could someone tell me how to embed windows in a text box using "tkcreate" 
command of R tcltk package? I tried the following and was not successful;

base <- tktoplevel()
text <- tktext(base, width = 30, height = 10)
tkpack(text)
button <- tkbutton(text, text = "try")
tkcreate(text, "window", "end", window = button)

Thanks.

JZ



From s-thapa-11 at alumni.uchicago.edu  Fri Jan  3 20:37:18 2003
From: s-thapa-11 at alumni.uchicago.edu (Suchandra Thapa)
Date: Fri Jan  3 20:37:18 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <Pine.LNX.4.31.0301031829400.1852-100000@gannet.stats>
References: <Pine.LNX.4.31.0301031829400.1852-100000@gannet.stats>
Message-ID: <1041622614.2034.21.camel@hepcat>

On Fri, 2003-01-03 at 12:44, ripley at stats.ox.ac.uk wrote:
    On Fri, 3 Jan 2003, Frank E Harrell Jr wrote:
    > I get NA for any day in 1969 or earlier.  Using a time other than midnight did not help.  So it's not a problem with time zone changes on a given day (thanks, Brian and Don for suggesting I look at that).
    
    Ahah, so Dirk's guess was right for your machine!  That's a new bug in
    some version of glibc, I suppose.  Exactly what OS are you running, and
    version of glibc (if you can tell)?
    
I believe the problem is that the glibc developers recently changed
mktime to return an error for any date before Jan 1, 1970.  The
rationale for this was to make the mktime function more compliant with
the ISO C standard so I believe the the new behavior is here to stay
barring a large amount of complaints. Unfortunately, this means that all
linux distributions will have this problem as they upgrade to newer
versions of glibc.
    
-- 
------------------------------------------------------------------

Suchandra S. Thapa 
s-thapa-11 at alumni.uchicago.edu

------------------------------------------------------------------



From hack at pedos.hr  Fri Jan  3 20:41:22 2003
From: hack at pedos.hr (Branimir K. Hackenberger)
Date: Fri Jan  3 20:41:22 2003
Subject: [R] [R]cmeans visualisation
Message-ID: <1132.195.29.38.148.1041624394.squirrel@wmail.pedos.hr>

Hi all R-helpers!!!

I have only one small question: Which visualisation method would you 
suggest for results of function cmeans {e1071}?

Thanks!

Branimir K. Hackenberger



From gregory_r_warnes at groton.pfizer.com  Fri Jan  3 20:46:43 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri Jan  3 20:46:43 2003
Subject: Take care with codes()! (was [R] type of representation)
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C414@groexmb02.pfizer.com>

Ahh yes, sorry about that.

Here's the corrected snippet:

# Create an Example Data Frame Containing Car x Color data
carnames <- c("bmw","renault","mercedes","seat")
carcolors <- c("red","white","silver","green")
datavals <- round(rnorm(16, mean=10, sd=4),1)
data <- data.frame(Car=rep(carnames,4),
                   Color=rep(carcolors, c(4,4,4,4) ),
                   Value=datavals )
# show the data
data

# plot the Car x Color combinations, using 'cex' to specify the dot size
plot(x=as.numeric(data$Car),     # as.numeric give numeric values
     y=as.numeric(data$Color), 
     cex=data$Value/max(data$Value)*12,  # standardize size to (0,12)
     pch=19,  # filled circle
     col="skyblue", # dot color
     xlab="Car", # x axis label
     ylab="Color", # y axis label
     xaxt="n", # no x axis lables
     yaxt="n", # no y axis lables
     bty="n",  # no box around the plot
     xlim=c(0,nlevels(data$Car  )+0.5), # extra space on either end of plot
     ylim=c(0.5,nlevels(data$Color)+1.5)  # so dots don't cross into margins
     )

# add text labels
text(x=1:nlevels(data$Car), y=nlevels(data$Car)+1, labels=levels(data$Car))
text(x=0, y=1:nlevels(data$Color), labels=levels(data$Color) )

# add borders between cells
abline(v=(0:nlevels(data$Car)+0.5))
abline(h=(0:nlevels(data$Color)+0.5))

# annotate with actual values
text(x=as.numeric(data$Car),     # as.numeric give numeric values
     y=as.numeric(data$Color), 
     labels=format(data$Value),       # label value
     col="black", # textt color
     )

# put a nice title
title(main="Car by Color Popularity\n(Dot size proportional to popularity)")


-Greg

> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Friday, January 03, 2003 1:53 PM
> To: Warnes, Gregory R
> Cc: 'allende at gredos.cnb.uam.es'; 'r-help at stat.math.ethz.ch'
> Subject: RE: Take care with codes()! (was [R] type of representation)
> 
> 
> From the help page of codes():
> 
>      Normally `codes' is not the appropriate function to use with an
>      unordered factor.  Use `unclass' or `as.numeric' to extract the
>      codes used in the internal representation of the factor, as these
>      do not assume that the codes are sorted.
> 
> and this is one of the `normally' cases.  Your code will only work
> correctly if the levels are in alphabetical order (in the 
> locale in use).
> 
> On Fri, 3 Jan 2003, Warnes, Gregory R wrote:
> 
> > How about this snippet:
> >
> > # Create an Example Data Frame Containing Car x Color data
> > carnames <- c("bmw","renault","mercedes","seat")
> > carcolors <- c("red","white","silver","green")
> > datavals <- round(rnorm(16, mean=10, sd=4),1)
> > data <- data.frame(Car=rep(carnames,4),
> >                    Color=rep(carcolors, c(4,4,4,4) ),
> >                    Value=datavals )
> > # show the data
> > data
> >
> > # plot the Car x Color combinations, using 'cex' to specify 
> the dot size
> > plot(x=codes(data$Car),     # codes give numeric values
> >      y=codes(data$Color),
> >      cex=data$Value/max(data$Value)*12,  # standardize size 
> to (0,12)
> >      pch=19,  # filled circle
> >      col="skyblue", # dot color
> >      xlab="Car", # x axis label
> >      ylab="Color", # y axis label
> >      xaxt="n", # no x axis lables
> >      yaxt="n", # no y axis lables
> >      bty="n",  # no box around the plot
> >      xlim=c(0,nlevels(data$Car  )+0.5), # extra space on 
> either end of plot
> >      ylim=c(0.5,nlevels(data$Color)+1.5)  # so dots don't 
> cross into margins
> >      )
> >
> > # add text labels
> > text(x=1:nlevels(data$Car), y=nlevels(data$Car)+1, 
> labels=levels(data$Car))
> > text(x=0, y=1:nlevels(data$Color), labels=levels(data$Color) )
> >
> > # add borders between cells
> > abline(v=(0:nlevels(data$Car)+0.5))
> > abline(h=(0:nlevels(data$Color)+0.5))
> >
> > # annotate with actual values
> > text(x=codes(data$Car),     # codes give numeric values
> >      y=codes(data$Color),
> >      labels=format(data$Value),       # label value
> >      col="black", # textt color
> >      )
> >
> > # put a nice title
> > title(main="Car by Color Popularity\n(Dot size proportional 
> to popularity)")
> >
> >
> > -Greg
> >
> > > -----Original Message-----
> > > From: allende at gredos.cnb.uam.es [mailto:allende at gredos.cnb.uam.es]
> > > Sent: Friday, January 03, 2003 4:46 AM
> > > To: r-help at stat.math.ethz.ch
> > > Cc: allende at gredos.cnb.uam.es
> > > Subject: [R] type of representation
> > >
> > >
> > > Hi
> > >
> > > I have some data that i want to plot but i don't find how to
> > > do it. I have car
> > > types (bmw,renault,mercedes,seat ...), colors and a number
> > > for each car
> > > type-color relation.I want to come up with a matrix
> > > representation of cars vs
> > > colors where in each intersection i could set a dot
> > > proportional in size to my
> > > third variable.
> > >
> > >
> > > Can anybody give me a clue of hoe to come up with such 
> representation.
> > >
> > > Thanks
> > >
> > > Ramon
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> >
> >
> > LEGAL NOTICE\ Unless expressly stated otherwise, this 
> message is ... [[dropped]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From fharrell at virginia.edu  Fri Jan  3 20:52:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri Jan  3 20:52:03 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <Pine.LNX.4.31.0301031829400.1852-100000@gannet.stats>
References: <20030103130546.732763a5.fharrell@virginia.edu>
	<Pine.LNX.4.31.0301031829400.1852-100000@gannet.stats>
Message-ID: <20030103145209.625638c6.fharrell@virginia.edu>

On Fri, 3 Jan 2003 18:44:25 +0000 (GMT)
ripley at stats.ox.ac.uk wrote:

>
> > I get NA for any day in 1969 or earlier.  Using a time other than midnight did not help.  So it's not a problem with time zone changes on a given day (thanks, Brian and Don for suggesting I look at that).
> 
> Ahah, so Dirk's guess was right for your machine!  That's a new bug in
> some version of glibc, I suppose.  Exactly what OS are you running, and
> version of glibc (if you can tell)?

I'm running RedHat 8.0 with glibc 2.2.93-5

> 
> > Doing as.POSIXlt works fine, but I want POSIXct variables for storage in data frames.
> >
> > I am at a loss on how to proceed but thanks to all for the help.
> 
> Dirk had a Linux machine in (I believe) the same time zone which
> gave the right answer.  So does mine if I set it to EST.
> 
> Try setting tz="GMT" is as.POSIXct if you don't care about times. It looks
> from reading the code that this will work.  If you are compiling from
> source, about line 220 of src/main/datetime.c reads

Setting tz='GMT' as you suggested did indeed work, seemingly back 2000 years, except for a shift of one day due I suppose to time zone differences.

> x <- strptime(c('10/15/1969','12/31/2002'),format='%m/%d/%Y')
> as.POSIXct(x,tz='GMT')
[1] "1969-10-14 20:00:00 EDT" "2002-12-30 19:00:00 EST"

Thanks very much for the workaround Brian.   Oddly enough, 10/15/1203 works without tz='GMT' (but with a day shift) but 10/15/1969 will not (gives NA). 
 - Frank

> 
> #ifdef Win32
>        tm->tm_year >= 70)
> #else
>        tm->tm_year > 02)
> #endif
> 
> and your machine seems to need the Win32 branch.  You might also need it
> in localtime0 a few lines later.
> 
> 
> We will probably need a configure test for this particular type of
> brokenness.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From ripley at stats.ox.ac.uk  Fri Jan  3 20:55:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan  3 20:55:03 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <1041622614.2034.21.camel@hepcat>
Message-ID: <Pine.LNX.4.31.0301031945220.2175-100000@gannet.stats>

Can you supply us with details?  For the ISO C99 standard actually says

The mktime function returns the specified calendar time encoded as a value
of type time_t. If the calendar time cannot be represented, the function
returns the value (time_t)-1.

and that is the behaviour that R expects.  Note that POSIX specifies what
time_t is, but ISO C does not, so I am at a loss as to how this can be
`more compliant with the ISO C standard'.


On 3 Jan 2003, Suchandra Thapa wrote:

> On Fri, 2003-01-03 at 12:44, ripley at stats.ox.ac.uk wrote:
>     On Fri, 3 Jan 2003, Frank E Harrell Jr wrote:
>     > I get NA for any day in 1969 or earlier.  Using a time other than midnight did not help.  So it's not a problem with time zone changes on a given day (thanks, Brian and Don for suggesting I look at that).
>
>     Ahah, so Dirk's guess was right for your machine!  That's a new bug in
>     some version of glibc, I suppose.  Exactly what OS are you running, and
>     version of glibc (if you can tell)?
>
> I believe the problem is that the glibc developers recently changed
> mktime to return an error for any date before Jan 1, 1970.  The
> rationale for this was to make the mktime function more compliant with
> the ISO C standard so I believe the the new behavior is here to stay
> barring a large amount of complaints. Unfortunately, this means that all
> linux distributions will have this problem as they upgrade to newer
> versions of glibc.
>
> --
> ------------------------------------------------------------------
>
> Suchandra S. Thapa
> s-thapa-11 at alumni.uchicago.edu
>
> ------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Benjamin.STABLER at odot.state.or.us  Fri Jan  3 20:58:10 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Fri Jan  3 20:58:10 2003
Subject: [R] Re: Embedding windows in a text widget
Message-ID: <76A000A82289D411952F001083F9DD06039AC9A2@exsalem4-bu.odot.state.or.us>

Try 

tkwindow.create(text, "end", window = button)

instead of 

tkcreate(text, "window", "end", window = button)

-Ben

-----Original Message-----
From: John Zhang [mailto:jzhang at jimmy.harvard.edu]
Sent: Friday, January 03, 2003 11:32 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Re: Embedding windows in a text widget


Could someone tell me how to embed windows in a text box using "tkcreate" 
command of R tcltk package? I tried the following and was not successful;

base <- tktoplevel()
text <- tktext(base, width = 30, height = 10)
tkpack(text)
button <- tkbutton(text, text = "try")
tkcreate(text, "window", "end", window = button)

Thanks.

JZ

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From LindnerW at t-online.de  Fri Jan  3 21:05:03 2003
From: LindnerW at t-online.de (Wolfgang Lindner)
Date: Fri Jan  3 21:05:03 2003
Subject: [R]  factor analysis (pca): how to get the 'communalities'?
References: <20030103113951.N18906-100000@fellspt.charm.net>
Message-ID: <18UY3J-0vyZJgC@fwd09.sul.t-online.com>

Scot,

thank you very much for your wonderful clear and short fix of my first problem: 
seeing your solution as one-liner in the impressive insightful syntax of R is 
really an aesthetic experience for me:

|  I ran your example and found that you can get the eigenvalues SPSS by [..]
|    m.pca$sdev^2
|  So squaring the standard deviations (sdev) of the components gives you the
|  eigenvalues SPSS reports.

I am a little sorrow of not having seen it for myself ;-) - but I think that's 
live in becoming a friend of R and making the first steps with pca, fa, ca & co. 
R is indeed a first choice tool in doing understandable statistics and Prof 
Ripley's indication to R's open code points definitive in the same direction for 
me. Now the two worlds become reconciled and the fog gets thinner for me.
Thank you both.

Wolfgang
--
Wolfgang Lindner                           Lindner at math.uni-duisburg.de
   Gerhard-Mercator-Universitaet Duisburg  Tel: +49 0203 379-1326



From LindnerW at t-online.de  Fri Jan  3 21:41:03 2003
From: LindnerW at t-online.de (Wolfgang Lindner)
Date: Fri Jan  3 21:41:03 2003
Subject: [R] Tutorials?
Message-ID: <18UYbl-1lxMVkC@fwd02.sul.t-online.com>

Joshua,

it's is always risky to give recommendations, but I have also learned much from

[1] Myatt: Open Source Solutions - R. 
(a free brief introduction to using the R environment in Rich Text (.RTF) and 
Acrobat (PDF) formats and including sample data written by Mark Myatt 
<mark at myatt.demon.co.uk>, available at
http://www.myatt.demon.co.uk/Rex1031.zip )

[2] P. Dalgaard: Introductory Statistics with R. Springer 2002. 
    ISBN 0-387-95475-9

[3] J. Fox: An R and S-plus Companion to Applied Regression. Sage 2002.
    ISBN 0-7619-2280-6

Take a look and happy R'ing

Wolfgang

--
Wolfgang Lindner                           Lindner at math.uni-duisburg.de
   Gerhard-Mercator-Universitaet Duisburg  Tel: +49 0203 379-1326



From bmagill at earthlink.net  Fri Jan  3 21:53:03 2003
From: bmagill at earthlink.net ( Brett Magill)
Date: Fri Jan  3 21:53:03 2003
Subject: [R]  factor analysis (pca): how to get the 'communalities'?
Message-ID: <Springmail.0994.1041627168.0.83412300@webmail.pas.earthlink.net>

If interested, on my web site I have code to do factor analysis by PC.  Does
exactly as below, but a nice wrapper to print methods, rotations, sorting, and
other conveniences.

  home.earthlink.net/~bmagill/MyMisc.html 

The relevant code snipets are "prinfact", "plot.pfa", and "print.pfa", along
with the other required functions as indiciated on the web site.


On Fri, 3 Jan 2003 21:04:21 +0100 Wolfgang Lindner <LindnerW at t-online.de>
wrote:

> Scot,
> 
> thank you very much for your wonderful clear
> and short fix of my first problem: 
> seeing your solution as one-liner in the
> impressive insightful syntax of R is 
> really an aesthetic experience for me:
> 
> |  I ran your example and found that you can
> get the eigenvalues SPSS by [..]
> |    m.pca$sdev^2
> |  So squaring the standard deviations (sdev)
> of the components gives you the
> |  eigenvalues SPSS reports.
> 
> I am a little sorrow of not having seen it for
> myself ;-) - but I think that's 
> live in becoming a friend of R and making the
> first steps with pca, fa, ca & co. 
> R is indeed a first choice tool in doing
> understandable statistics and Prof 
> Ripley's indication to R's open code points
> definitive in the same direction for 
> me. Now the two worlds become reconciled and
> the fog gets thinner for me.
> Thank you both.
> 
> Wolfgang
> --
> Wolfgang Lindner                          
> Lindner at math.uni-duisburg.de
>    Gerhard-Mercator-Universitaet Duisburg  Tel:
> +49 0203 379-1326
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From p.dalgaard at biostat.ku.dk  Sat Jan  4 00:53:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sat Jan  4 00:53:03 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <Pine.LNX.4.31.0301031945220.2175-100000@gannet.stats>
References: <Pine.LNX.4.31.0301031945220.2175-100000@gannet.stats>
Message-ID: <x2of6xhju7.fsf@biostat.ku.dk>

<ripley at stats.ox.ac.uk> writes:

> Can you supply us with details?  For the ISO C99 standard actually says
> 
> The mktime function returns the specified calendar time encoded as a value
> of type time_t. If the calendar time cannot be represented, the function
> returns the value (time_t)-1.
> 
> and that is the behaviour that R expects.  Note that POSIX specifies what
> time_t is, but ISO C does not, so I am at a loss as to how this can be
> `more compliant with the ISO C standard'.

Just do a Google groups search for "mktime glibc" and the whole mess
turns up, including some pretty irate postgresql developers...

The spec in question appears to be

http://www.opengroup.org/onlinepubs/007904975/basedefs/xbd_chap04.html#tag_04_14 

although that doesn't actually mention mktime(), it just talks about
the definition of "Seconds Since the Epoch". The actual definition is
in

http://www.opengroup.org/onlinepubs/007904975/functions/mktime.html

One particular piece of sillyness with mktime() is that it uses a
return value of -1 to signal error, leaving you with a problem for
1969-12-31 23:59:59 UTC if you allow extension to times before the
Epoch.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From s-thapa-11 at alumni.uchicago.edu  Sat Jan  4 01:00:04 2003
From: s-thapa-11 at alumni.uchicago.edu (Suchandra Thapa)
Date: Sat Jan  4 01:00:04 2003
Subject: [R] as.POSIXct problem?
In-Reply-To: <Pine.LNX.4.31.0301031945220.2175-100000@gannet.stats>
References: <Pine.LNX.4.31.0301031945220.2175-100000@gannet.stats>
Message-ID: <1041638162.2036.38.camel@hepcat>

On Fri, 2003-01-03 at 13:52, ripley at stats.ox.ac.uk wrote:
    Can you supply us with details?  For the ISO C99 standard actually says
    
    The mktime function returns the specified calendar time encoded as a value
    of type time_t. If the calendar time cannot be represented, the function
    returns the value (time_t)-1.
    
    and that is the behaviour that R expects.  Note that POSIX specifies what
    time_t is, but ISO C does not, so I am at a loss as to how this can be
    `more compliant with the ISO C standard'.
    
There was a discussion of the problem and possible workarounds on the
postgresql-hackers list.  If you do a search for glibc and mktime on
the  postgresql developer's website or use the following link
http://archives.postgresql.org/search.php?ps=10&q=glibc+mktime&ps=10&wm=wrd&o=0&ul=%2Fpgsql-hackers%2F&m=all&wf=222211&cat=
then you should be able to read the discussion.  The short of it seemed
to have been to document the problem and try to fix the problem in next
release.

Also there is a related bug report in redhat's bug database
(bugzilla.redhat.com) as bug 65227.  

The relevant section in the IEEE standard is
http://www.opengroup.org/onlinepubs/007904975/basedefs/xbd_chap04.html#tag_04_14
Basically, it defines the seconds since the epoch as being undefined
before 1970.  Since mktime returns the calendar time, the glibc
maintainers seem to have decided to change the return value for dates
earlier than 1970.

-- 
------------------------------------------------------------------

Suchandra S. Thapa 
s-thapa-11 at alumni.uchicago.edu

------------------------------------------------------------------



From LindnerW at t-online.de  Sat Jan  4 12:52:03 2003
From: LindnerW at t-online.de (Wolfgang Lindner)
Date: Sat Jan  4 12:52:03 2003
Subject: [R]  factor analysis (pca): how to get the 'communalities'?
References: <Springmail.0994.1041627168.0.83412300@webmail.pas.earthlink.net>
Message-ID: <18Umpd-1hN1wOC@fwd07.sul.t-online.com>

Brett Magill schrieb:
| If interested, on my web site I have code to do factor analysis by PC.  Does
| exactly as below, but a nice wrapper to print methods, rotations, sorting, and
| other conveniences.
|
|   home.earthlink.net/~bmagill/MyMisc.html 
|
| The relevant code snipets are "prinfact", "plot.pfa", and "print.pfa", along
| with the other required functions as indiciated on the web site.

Dear Brett,

thanks very much for supplying your code. It's really illuminating.
Now, let me quote you
 'When I have time, I will document them and wrap them up into a package that
  can be installed.'
I hope you will find some time to prepare 'Your'Misc-1.0.R ;-) ..
Helpful could be to give some examples of calling your functions. 

Please excuse me, if the following questions are *too* off-topic, but I found it 
interesting. In inspecting your code I came across an R feature, I could not 
find in the online manuals:

Q1. Looking at the left-handside in your function def:

"cov.cor" <- function ( covmat ) {
                        sdev <- diag ( sqrt ( diag ( covmat ) ) ) 
                        solve(sdev) %*% covmat %*% t(solve(sdev))  }
^       ^
|       |
?       ?

- *Why* is the (identifier) function name cov.cor included in question marks? 
- How is "cov.cor" then called?  "cov.cor"(..) or cov.cor(..) or ?

Q2. Please, can someone give me a pointer where this feature is described.

Finally I want to thank the list for this thread.

Wolfgang
--
Wolfgang Lindner                           Lindner at math.uni-duisburg.de
   Gerhard-Mercator-Universitaet Duisburg  Tel: +49 0203 379-1326
   Fakultaet 4 - Naturwissenschaften       Fax: +49 0203 379-2528
   Institut fuer Mathematik,  LE 424
   Lotharstr. 65
   D 47048  Duisburg (Germany)



From ligges at statistik.uni-dortmund.de  Sat Jan  4 14:48:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Jan  4 14:48:03 2003
Subject: [R]  factor analysis (pca): how to get the 'communalities'?
References: <Springmail.0994.1041627168.0.83412300@webmail.pas.earthlink.net> <18Umpd-1hN1wOC@fwd07.sul.t-online.com>
Message-ID: <3E16E63E.914497D7@statistik.uni-dortmund.de>

Wolfgang Lindner wrote:
> 
> Brett Magill schrieb:
> | If interested, on my web site I have code to do factor analysis by PC.  Does
> | exactly as below, but a nice wrapper to print methods, rotations, sorting, and
> | other conveniences.
> |
> |   home.earthlink.net/~bmagill/MyMisc.html
> |
> | The relevant code snipets are "prinfact", "plot.pfa", and "print.pfa", along
> | with the other required functions as indiciated on the web site.
> 
> Dear Brett,
> 
> thanks very much for supplying your code. It's really illuminating.
> Now, let me quote you
>  'When I have time, I will document them and wrap them up into a package that
>   can be installed.'
> I hope you will find some time to prepare 'Your'Misc-1.0.R ;-) ..
> Helpful could be to give some examples of calling your functions.
> 
> Please excuse me, if the following questions are *too* off-topic, but I found it
> interesting. In inspecting your code I came across an R feature, I could not
> find in the online manuals:
> 
> Q1. Looking at the left-handside in your function def:
> 
> "cov.cor" <- function ( covmat ) {
>                         sdev <- diag ( sqrt ( diag ( covmat ) ) )
>                         solve(sdev) %*% covmat %*% t(solve(sdev))  }
> ^       ^
> |       |
> ?       ?
> 
> - *Why* is the (identifier) function name cov.cor included in question marks?

It's not necessary for this particular name to put in in quotes, but you
can put any name in quotes:

 "x" <- 5
 x

Here you must quote (BAD idea to choose such names!, NOT
recommended!!!):
 "x 1" <- 5
 get("x 1")


> - How is "cov.cor" then called?  "cov.cor"(..) or cov.cor(..) or ?

Both ways are possible in this case.


> Q2. Please, can someone give me a pointer where this feature is described.

R FAQ 7.16 - 2. item in the enumeration.

 
> Finally I want to thank the list for this thread.

Uwe Ligges



From bmagill at earthlink.net  Sat Jan  4 18:05:05 2003
From: bmagill at earthlink.net (bmagill@earthlink.net)
Date: Sat Jan  4 18:05:05 2003
Subject: [R]  factor analysis (pca): how to get the 'communalities'?
In-Reply-To: <18Umpd-1hN1wOC@fwd07.sul.t-online.com>
Message-ID: <3E16BDEC.17322.8EB4897@localhost>

On 4 Jan 2003 at 12:51, Wolfgang Lindner wrote:


> Please excuse me, if the following questions are *too* off-topic, but I found it 
> interesting. In inspecting your code I came across an R feature, I could not 
> find in the online manuals:
> 
> Q1. Looking at the left-handside in your function def:
> 
> "cov.cor" <- function ( covmat ) {
>                         sdev <- diag ( sqrt ( diag ( covmat ) ) ) 
>                         solve(sdev) %*% covmat %*% t(solve(sdev))  }
> ^       ^
> |       |
> ?       ?
> 
> - *Why* is the (identifier) function name cov.cor included in question marks? 
> - How is "cov.cor" then called?  "cov.cor"(..) or cov.cor(..) or ?

The quotation marks are the result of using dump() to write the set of functions to a 
file.  As was pointed out, it is not necessary to use quotation marks when calling any 
of these  functions.

As far as documentation, I simply have not done it yet.  In the meantime, if you have 
specific questions about how to use some of the functions, I can provide some 
examples and some on the fly documentation, let me know, specifically, what you 
want to use/know.  That, we should probably take off-list however.

In generall, you can source() the .R file in.  After doing that the entire set of functions 
will be available in your workspace for you to see using ls() and examine by calling 
the function name.

Regards, Brett



From bmagill at earthlink.net  Sat Jan  4 18:13:02 2003
From: bmagill at earthlink.net (bmagill@earthlink.net)
Date: Sat Jan  4 18:13:02 2003
Subject: [R]  factor analysis (pca): how to get the 'communal
Message-ID: <3E16BF0F.8630.8EFB933@localhost>

On 4 Jan 2003 at 12:51, Wolfgang Lindner wrote:


> Please excuse me, if the following questions are *too* off-topic, but I found it 
> interesting. In inspecting your code I came across an R feature, I could not 
> find in the online manuals:
> 
> Q1. Looking at the left-handside in your function def:
> 
> "cov.cor" <- function ( covmat ) {
>                         sdev <- diag ( sqrt ( diag ( covmat ) ) ) 
>                         solve(sdev) %*% covmat %*% t(solve(sdev))  }
> ^       ^
> |       |
> ?       ?
> 
> - *Why* is the (identifier) function name cov.cor included in question marks? 
> - How is "cov.cor" then called?  "cov.cor"(..) or cov.cor(..) or ?

The quotation marks are the result of using dump() to write the set of functions to a 
file.  As was pointed out, it is not necessary to use quotation marks when calling any 
of these  functions.

As far as documentation, I simply have not done it yet.  In the meantime, if you have 
specific questions about how to use some of the functions, I can provide some 
examples and some on the fly documentation, let me know, specifically, what you 
want to use/know.  That, we should probably take off-list however.

In generall, you can source() the .R file in.  After doing that the entire set of functions 
will be available in your workspace for you to see using ls() and examine by calling 
the function name.

Regards, Brett










------- End of forwarded message -------



From mabramso at gmu.edu  Sat Jan  4 23:50:03 2003
From: mabramso at gmu.edu (Myriam Abramson)
Date: Sat Jan  4 23:50:03 2003
Subject: [R] easy graphics question
Message-ID: <m3u1golehi.fsf@home.sweet.home>

What's the pch code for drawing an arrow in a plot? 

                                   myriam



From sundar.dorai-raj at pdf.com  Sun Jan  5 01:39:02 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sun Jan  5 01:39:02 2003
Subject: [R] easy graphics question
References: <m3u1golehi.fsf@home.sweet.home>
Message-ID: <3E177E32.10001@pdf.com>

Myriam,
Here's a simple script that lists the pch symbols:

plot(x=0,type="n",xlim=c(0,1),ylim=c(0,1))
for(i in 1:100) {
   j = i - 1
   x = j%%10/10
   y = j%/%10/10
   cat("(",x,",",y,",",i,")\n")
   points(x,y,pch=i)
}

No arrow that I see. Look up ?arrows instead.

 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.1
year     2002
month    11
day      01
language R

Regards,
Sundar

Myriam Abramson wrote:
> What's the pch code for drawing an arrow in a plot? 
> 
>                                    myriam
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From hodgess at uhddx01.dt.uh.edu  Sun Jan  5 01:46:03 2003
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Sun Jan  5 01:46:03 2003
Subject: [R] Long memory ts
Message-ID: <200301050045.SAA10756@uhddx01.dt.uh.edu>

Dear R People:

Where is the command for long memory time series, please?

In S, it's arima.fracdiff

Is there something like that in R?  If so, which library has it, please?

Version 1.5.1 for Windows

Happy new year

Thanks so much!

Sincerely,
Erin Hodgess
mailto: hodgess at uhddx01.dt.uh.edu



From fredrik.lundgren at norrkoping.mail.telia.com  Sun Jan  5 18:39:03 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Sun Jan  5 18:39:03 2003
Subject: [R] .Rprofile problems
Message-ID: <001701c2b4e1$0b8063c0$2d0ffea9@oemcomputer>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030105/c1756f73/attachment.pl

From ozric at web.de  Sun Jan  5 19:11:02 2003
From: ozric at web.de (Christian Schulz)
Date: Sun Jan  5 19:11:02 2003
Subject: [R] .Rprofile problems
References: <001701c2b4e1$0b8063c0$2d0ffea9@oemcomputer>
Message-ID: <000901c2b4e5$29b05e50$a54007d5@c5c9i0>

...your .Rprofile is "automatic integrated" when
you starts R. You don't need to load it
in your workspace !
You can modify the settings  in    /etc/Rprofile

regards,christian



----- Original Message -----
From: "Fredrik Lundgren" <fredrik.lundgren at norrkoping.mail.telia.com>
To: "R-news" <R-help at stat.math.ethz.ch>
Sent: Sunday, January 05, 2003 6:36 PM
Subject: [R] .Rprofile problems


Hello,

I'm using
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.1
year     2002
month    11
day      01
language R

and can't get a .Rprofile file into my workspaces.
The system doesn't accept the name .Rprofile
How do I get such a file into my workspaces?

Sincerly F Lundgren
Norrk?ping
Sweden



[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sun Jan  5 23:50:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Jan  5 23:50:03 2003
Subject: [R] .Rprofile problems
In-Reply-To: <000901c2b4e5$29b05e50$a54007d5@c5c9i0>
Message-ID: <Pine.LNX.4.31.0301052244520.26646-100000@gannet.stats>

I think the problem may be that Windows Explorer does not allow a name
starting with `.'.   However, the command-line and decent editors do.

On Sun, 5 Jan 2003, Christian Schulz wrote:

> ...your .Rprofile is "automatic integrated" when
> you starts R. You don't need to load it
> in your workspace !
> You can modify the settings  in    /etc/Rprofile

I assume you mean ...\rw1061\etc\Rprofile.  That's not the same though, as
it is executed into package base and not the user workspace.

See ?Startup for a fuller explanation.

> ----- Original Message -----
> From: "Fredrik Lundgren" <fredrik.lundgren at norrkoping.mail.telia.com>
> Sent: Sunday, January 05, 2003 6:36 PM
>
> I'm using
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.1
> year     2002
> month    11
> day      01
> language R
>
> and can't get a .Rprofile file into my workspaces.
> The system doesn't accept the name .Rprofile
> How do I get such a file into my workspaces?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From isaia at econ.unito.it  Mon Jan  6 06:23:03 2003
From: isaia at econ.unito.it (E. D. Isaia)
Date: Mon Jan  6 06:23:03 2003
Subject: [R] On nlm
Message-ID: <3E1912D7.9000406@econ.unito.it>

Dear all, I have to minimize a (real) function in a loop (say i in 
(1:1000)) and store its ``$estimate'', via 

l2estim<-nlm(f.minimo,c(-.01,0.1))$estimate

into a vector for further analisys.
Since the function's behaviour is quite  peculiar (in the sense that in 
the simulation study it may not have a minumum), sometimes I get the the 
warning

Error in nlm(minimo, c(-0.01, 0.1), check.analyticals = FALSE) : 
	non-finite value supplied by nlm
In addition: There were 50 or more warnings (use warnings() to see the first 50)

and the cicle stops. How can I avoid this and tell R that if so then l2estim<-0, for example.

Thanks to all, isaia.

-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~ Ennio D. Isaia
~ Dep. of Statistics & Mathematics, University of Torino
~ Piazza Arbarello, 8 - 10128 Torino (Italy)
~ Phone: +39 011 670 62 51 ~~ Fax: +39 011 670 62 39
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From tibs at stat.stanford.edu  Mon Jan  6 07:09:03 2003
From: tibs at stat.stanford.edu (Rob Tibshirani)
Date: Mon Jan  6 07:09:03 2003
Subject: [R] Statistical Learning and Data Mining short course
Message-ID: <200301060608.WAA17767@rgmiller.Stanford.EDU>

I thought this might be of interest to R users:


Short course: Statistical Learning and Data Mining

Trevor Hastie and Robert Tibshirani
Stanford University

Sheraton Hotel,
Palo Alto, California
February 27-28, 2003

This two-day course gives a detailed overview of statistical
models for data mining, inference and prediction.

This sequel to our popular Modern Regression and Classification course
covers many new areas of unsupervised learning and data mining,
and  gives an in-depth treatment of some of the hottest tools
in supervised learning. Applications to genomics, marketing
and engineering are discussed.

The first course is not a pre-requisite for this new course.

Much of the material is based on our recent book:

Elements of Statistical Learning: Data Mining, Inference and Prediction,
Hastie, Tibshirani & Friedman, Springer-Verlag, 2001.
http://www-stat.stanford.edu/ElemStatLearn

A copy of this book will be given to all attendees.

For more information on the course, and registration information,
go to the site
http://www-stat.stanford.edu/~hastie/mrc.html
**********************************************
Rob Tibshirani, Dept of Health Research & Policy
 and Dept of Statistics
HRP Redwood Bldg
Stanford University
Stanford, California 94305-5405

phone: HRP: 650-723-7264 (Voice mail),  Statistics 650-723-1185
FAX 650-725-8977
tibs at stat.stanford.edu
http://www-stat.stanford.edu/~tibs



From maechler at stat.math.ethz.ch  Mon Jan  6 09:52:03 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Jan  6 09:52:03 2003
Subject: [R] Long memory ts
In-Reply-To: <200301050045.SAA10756@uhddx01.dt.uh.edu>
References: <200301050045.SAA10756@uhddx01.dt.uh.edu>
Message-ID: <15897.17297.751598.391735@gargle.gargle.HOWL>

>>>>> "Erin" == Erin Hodgess <hodgess at uhddx01.dt.uh.edu>
>>>>>     on Sat, 4 Jan 2003 18:45:43 -0600 (CST) writes:

    Erin> Dear R People:
    Erin> Where is the command for long memory time series, please?

    Erin> In S, it's arima.fracdiff

    Erin> Is there something like that in R?  If so, which
    Erin> library has it, please?

it's  "package" not "library" --- and guess what! --- the
package is called fracdiff...  :-)

Martin



From Roger.Bivand at nhh.no  Mon Jan  6 10:00:03 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon Jan  6 10:00:03 2003
Subject: [R] On nlm
In-Reply-To: <3E1912D7.9000406@econ.unito.it>
Message-ID: <Pine.LNX.4.44.0301060958580.28706-100000@reclus.nhh.no>

On Mon, 6 Jan 2003, E. D. Isaia wrote:

> Dear all, I have to minimize a (real) function in a loop (say i in 
> (1:1000)) and store its ``$estimate'', via 
> 
> l2estim<-nlm(f.minimo,c(-.01,0.1))$estimate
> 
> into a vector for further analisys.
> Since the function's behaviour is quite  peculiar (in the sense that in 
> the simulation study it may not have a minumum), sometimes I get the the 
> warning
> 
> Error in nlm(minimo, c(-0.01, 0.1), check.analyticals = FALSE) : 
> 	non-finite value supplied by nlm In addition: There were 50 or
> more warnings (use warnings() to see the first 50)
> 
> and the cicle stops. How can I avoid this and tell R that if so then
> l2estim<-0, for example.
> 
> Thanks to all, isaia.
> 

try() will probably be the best way to handle this - see ?try

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From John.Gavin at ubsw.com  Mon Jan  6 10:10:03 2003
From: John.Gavin at ubsw.com (John.Gavin@ubsw.com)
Date: Mon Jan  6 10:10:03 2003
Subject: [R] segments within a lattice graph
Message-ID: <8C2B4A87FC7E0147A65DC17BF4BDDC31010D0113@NLDNC006PEX1.ubsgs.ubsgroup.net>

Hi,

I would like to use the segments command 
within a lattice graph. 
Is this allowed in R in the same way as in SPlus?
If not, what is the alternative?

For example, the following produces vertical
line segments between points in SPlus
but in R the line segments are not shown.
(I want to replicate in R what I see in SPlus.)
What is my mistake?

library(lattice)
set.seed(123)
dat <- data.frame(
aa = runif(10),
bb = runif(10),
cc = runif(10)
)
dat <- dat[order(dat$aa),]
dat
xyplot(cc ~ aa, data = dat,
 panel = function(x, y, ...)
 { # no line segements and no error is printed.
   segments(dat$aa, dat$bb, dat$aa, dat$cc)
   panel.xyplot(dat$aa, dat$cc, col = 1, pch = 1, type = "b")
   panel.xyplot(dat$aa, dat$bb, col = 2, pch = 2, type = "b")
   # no arrows but errors are printed.
   # arrows(dat$aa, dat$bb, dat$aa, dat$cc)
 }, ylim = range(dat$bb, dat$cc)
)

SPlus 6.0.5 R4 for MS Windows NT4 SP5
R 
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.1            
year     2002           
month    11             
day      01             
language R        

Regards,

John.

John Gavin <john.gavin at ubsw.com>,
Quantitative Risk Models and Statistics,
UBS Warburg, 6th floor, 100 Liverpool St.,
London EC2M 2RH, UK.
Phone +44 (0) 207 567 4289
Fax   +44 (0) 207 568 5352

Visit our website at http://www.ubswarburg.com

This message contains confidential information and is intended only 
for the individual named.  If you are not the named addressee you 
should not disseminate, distribute or copy this e-mail.  Please 
notify the sender immediately by e-mail if you have received this 
e-mail by mistake and delete this e-mail from your system.

E-mail transmission cannot be guaranteed to be secure or error-free 
as information could be intercepted, corrupted, lost, destroyed, 
arrive late or incomplete, or contain viruses.  The sender therefore 
does not accept liability for any errors or omissions in the contents 
of this message which arise as a result of e-mail transmission.  If 
verification is required please request a hard-copy version.  This 
message is provided for informational purposes and should not be 
construed as a solicitation or offer to buy or sell any securities or 
related financial instruments.



From eia018 at comp.lancs.ac.uk  Mon Jan  6 10:18:02 2003
From: eia018 at comp.lancs.ac.uk (Dr Andrew Wilson)
Date: Mon Jan  6 10:18:02 2003
Subject: [R] Removing autocorrelations
Message-ID: <Pine.GSO.4.21.0301060913440.7371-100000@austin>

Could anyone tell me whether there is an R function for removing
autocorrelations from a series of observations before performing a linear
or nonlinear regression analysis on them?

Many thanks,
Andrew Wilson



From sbarbar at uni-goettingen.de  Mon Jan  6 10:21:04 2003
From: sbarbar at uni-goettingen.de (salvatore barbaro)
Date: Mon Jan  6 10:21:04 2003
Subject: [R] Greek Letters for labeling persp-axis
In-Reply-To: <8C2B4A87FC7E0147A65DC17BF4BDDC31010D0113@NLDNC006PEX1.ubsgs.ubsgroup.net>
Message-ID: <3E19585C.14919.2713F6@localhost>

Hi everybody,

on ?plotmath it can be seen that mathematical expressions like a
greek letter could not be used for x- and y-axis labels in 'persp'
plots. Unfortunately, this is exactly what I want to do: I need an
expression(rho) to label the y-axes. Does anybody know a way to
solve the problem. Further, Latex works very well by using the
command tilde{y}^{[dip]} but I have some troubles in R (for
instance, as a 'main' argument in a simple plot), probably due to
the square brackets. The command expression(tilde(y)^(dip)) works,
but what I want to get are indeed the square brackets.

Thanks in advance.

Yours

Salvatore Barbaro




salvatore barbaro
department of public economics
platz der g?ttinger sieben 3
37073 g?ttingen
tel.: +49 551 3919704
fax:  +49 551 39 7353
http://www.gwdg.de/~sbarbar



From ligges at statistik.uni-dortmund.de  Mon Jan  6 10:57:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Jan  6 10:57:03 2003
Subject: [R] Greek Letters for labeling persp-axis
In-Reply-To: <3E19585C.14919.2713F6@localhost>
References: <3E19585C.14919.2713F6@localhost>
Message-ID: <3E195292.7060607@statistik.uni-dortmund.de>

salvatore barbaro wrote:
> Hi everybody,
> 
> on ?plotmath it can be seen that mathematical expressions like a
> greek letter could not be used for x- and y-axis labels in 'persp'
> plots. Unfortunately, this is exactly what I want to do: I need an
> expression(rho) to label the y-axes. Does anybody know a way to
> solve the problem. 

 From ?persp:
"xlab, ylab, zlab
  titles for the axes. N.B. These must be character strings; expressions 
are not accepted. Numbers will be coerced to character strings."

What you can do is to work around with text() (or mtext()) and the 
trans3d() function given in the examples in persp().


 > Further, Latex works very well by using the
> command tilde{y}^{[dip]} but I have some troubles in R (for
> instance, as a 'main' argument in a simple plot), probably due to
> the square brackets. The command expression(tilde(y)^(dip)) works,
> but what I want to get are indeed the square brackets.

See ?plotmath and look for "group" and "bgroup":
plot(1:10, main=expression(tilde(y)^group("[",dip,"]")))

Uwe Ligges



From ripley at stats.ox.ac.uk  Mon Jan  6 11:06:06 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan  6 11:06:06 2003
Subject: [R] Removing autocorrelations
In-Reply-To: <Pine.GSO.4.21.0301060913440.7371-100000@austin>
Message-ID: <Pine.LNX.4.31.0301060958530.11272-100000@gannet.stats>

This makes no statistical sense.  If you are going to perform a regression
on a time series (and if it has any point so there is a significant
regression) then if the regressor is autocorrelated the response will be
too even with independent errors.  You need to do the regression and the
modelling of the autocorrelation simultaneously (function arima in package
ts for linear regression) or at least alternately (the Corchane-Orcutt
procedure, DIY).

As is often the case, please tell us what you want really to do (in your
substantive application) rather than for a vague statistical procedure,
and we may be able to point you to appropriate tools.

On Mon, 6 Jan 2003, Dr Andrew Wilson wrote:

> Could anyone tell me whether there is an R function for removing
> autocorrelations from a series of observations before performing a linear
> or nonlinear regression analysis on them?

(This would seem to suggest fitting an AR process and looking at the
residuals, a procedure sometimes known as `pre-whitening'.  But it needs
to be applied to residuals from a regression, not the original series.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Jan  6 12:34:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan  6 12:34:02 2003
Subject: [R] as.POSIXct problem -- summary
In-Reply-To: <20030102205628.3141f54d.fharrell@virginia.edu>
Message-ID: <Pine.LNX.4.31.0301061123080.14809-100000@gannet.stats>

A summary on this:

1) RedHat 8.0 contains an unreleased version of glibc between the released
versions 2.2.5 and 2.3.  That version (and >=2.3) have been modified to
make dates prior to 1970-01-01 invalid in some cases but not others.

We've put a workaround for this in R 1.6.2 (due on Friday), and that
checks at run-time for the broken version of glibc.  Because of the
internal inconsistencies in glibc, you will see inconsistencies in the
reporting of DST prior to 1970 (but as POSIXct times they are always
valid).

This makes it important for users of RH8.0 and other recent Linux distros
to update to 1.6.2 when released (or even R-patched now).  We used a
run-time test to allow for installations which are updated to a `better'
glibc.

2) The immediate workaround is

as.POSIXct(x, tz="GMT")

which avoids the OS's routines altogether.


On Thu, 2 Jan 2003, Frank E Harrell Jr wrote:

> > x <- strptime(c('10/10/1969','12/31/2002'),format='%m/%d/%Y')
> > x
> [1] "1969-10-10" "2002-12-31"
> > as.POSIXct(x)
> [1] NA               "2002-12-31 EST"
>
> Why the NA?  If this is not the preferred way to convert a character string to POSIXct what is?  On a more minor note why the EST if no time is printed?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From John.Gavin at ubsw.com  Mon Jan  6 12:54:02 2003
From: John.Gavin at ubsw.com (John.Gavin@ubsw.com)
Date: Mon Jan  6 12:54:02 2003
Subject: [R] Re - segments within a lattice graph
Message-ID: <8C2B4A87FC7E0147A65DC17BF4BDDC31010D0118@NLDNC006PEX1.ubsgs.ubsgroup.net>

Hi,

The solution to my problem is to use
'lsegments' instead of 'segments' within lattice commands.

(Although I wont forget again, 
a comment in the segments help file referring to 'lsegments' 
might help others not to make the same mistake in the future.)

My thanks to Renaud Lancelot.

Regards,

John.

John Gavin <john.gavin at ubsw.com>,
Quantitative Risk Models and Statistics,
UBS Warburg, 6th floor, 100 Liverpool St.,
London EC2M 2RH, UK.
Phone +44 (0) 207 567 4289
Fax   +44 (0) 207 568 5352


From: John.Gavin at ubsw.com
Date: Mon, 6 Jan 2003 09:08:28 -0000
To: <r-help at stat.math.ethz.ch>
Subject: [R] segments within a lattice graph

Hi,

I would like to use the segments command 
within a lattice graph. 
Is this allowed in R in the same way as in SPlus?
If not, what is the alternative?

For example, the following produces vertical
line segments between points in SPlus
but in R the line segments are not shown.
(I want to replicate in R what I see in SPlus.)
What is my mistake?

library(lattice)
set.seed(123)
dat <- data.frame(
aa = runif(10),
bb = runif(10),
cc = runif(10)
)
dat <- dat[order(dat$aa),]
dat
xyplot(cc ~ aa, data = dat,
 panel = function(x, y, ...)
 { # no line segements and no error is printed.
   segments(dat$aa, dat$bb, dat$aa, dat$cc)
   panel.xyplot(dat$aa, dat$cc, col = 1, pch = 1, type = "b")
   panel.xyplot(dat$aa, dat$bb, col = 2, pch = 2, type = "b")
   # no arrows but errors are printed.
   # arrows(dat$aa, dat$bb, dat$aa, dat$cc)
 }, ylim = range(dat$bb, dat$cc)
)

Visit our website at http://www.ubswarburg.com

This message contains confidential information and is intended only 
for the individual named.  If you are not the named addressee you 
should not disseminate, distribute or copy this e-mail.  Please 
notify the sender immediately by e-mail if you have received this 
e-mail by mistake and delete this e-mail from your system.

E-mail transmission cannot be guaranteed to be secure or error-free 
as information could be intercepted, corrupted, lost, destroyed, 
arrive late or incomplete, or contain viruses.  The sender therefore 
does not accept liability for any errors or omissions in the contents 
of this message which arise as a result of e-mail transmission.  If 
verification is required please request a hard-copy version.  This 
message is provided for informational purposes and should not be 
construed as a solicitation or offer to buy or sell any securities or 
related financial instruments.



From ripley at stats.ox.ac.uk  Mon Jan  6 13:19:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan  6 13:19:02 2003
Subject: [R] Re - segments within a lattice graph
In-Reply-To: <8C2B4A87FC7E0147A65DC17BF4BDDC31010D0118@NLDNC006PEX1.ubsgs.ubsgroup.net>
Message-ID: <Pine.LNX.4.31.0301061211310.14876-100000@gannet.stats>

On Mon, 6 Jan 2003 John.Gavin at ubsw.com wrote:

> The solution to my problem is to use
> 'lsegments' instead of 'segments' within lattice commands.
>
> (Although I wont forget again,
> a comment in the segments help file referring to 'lsegments'
> might help others not to make the same mistake in the future.)

*But* the segments help file is part of base R graphics, and xyplot and
lsegments are part of the recommended addon package lattice.  To be
consistent you would want us to document in base R all the places where
there are limitations of usage with addons (or recommended addons).
There would be an awful lot of those (including on all of the
graphics-related help pages).

Surely the answer is to read the documentation of the package you are
using to see *its* restrictions.  In your case you were using a panel
function in xyplot, and ?xyplot's panel argument does explicitly tell you

       There are also some grid-compatible replacements of base R graphics
       functions useful for this purpose, such as `llines'. (Note
       that the corresponding base R graphics functions like `lines'
       would not work.) These are usually sufficient to convert
       existing custom panel functions written for S-Plus.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Mon Jan  6 13:52:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon Jan  6 13:52:03 2003
Subject: [R] Removing autocorrelations
In-Reply-To: <Pine.GSO.4.21.0301060913440.7371-100000@austin>
Message-ID: <5.1.0.14.2.20030106075038.01de5750@mcmail.cis.mcmaster.ca>

Dear Andrew,

I'm not sure whether this is what you're looking for, but the gls function 
in the nlme package will fit *linear* models with a variety of 
correlated-error structures.

I hope that this helps,
  John

At 09:17 AM 1/6/2003 +0000, Dr Andrew Wilson wrote:
>Could anyone tell me whether there is an R function for removing
>autocorrelations from a series of observations before performing a linear
>or nonlinear regression analysis on them?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From hodgess at uhddx01.dt.uh.edu  Mon Jan  6 14:51:02 2003
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Mon Jan  6 14:51:02 2003
Subject: [R] Long memory ts answer
Message-ID: <200301061350.HAA04296@uhddx01.dt.uh.edu>

fracdiff has its own package called fracdiff.

thank you for your great forbearance.

Sincerely,
Erin



From alessandro.agresti at unifi.it  Mon Jan  6 17:43:02 2003
From: alessandro.agresti at unifi.it (Alessandro Agresti)
Date: Mon Jan  6 17:43:02 2003
Subject: [R] info please
Message-ID: <002801c2b5a3$1ff45c40$d40f8b95@ieq.fi.cnr.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030106/57ba377d/attachment.pl

From vograno at arbitrade.com  Mon Jan  6 19:36:03 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Mon Jan  6 19:36:03 2003
Subject: [R] how to save envir. when batch is halted
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DC89@jupiter.arbitrade.com>

Dear R-users,

If for whatever reason a batch execution of my script halts I want R to save
my current environment, along with .Traceback var, in the .RData file (in
other words I need something like core dump).

It seems however that if execution is halted via stop() no .RData file is
dumped. So my question is how do produce the "core dump" or something to
that effect?

Thank you,
Vadim

-------------------------------------------------- 
DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]



From ripley at stats.ox.ac.uk  Mon Jan  6 20:19:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan  6 20:19:05 2003
Subject: [R] how to save envir. when batch is halted
In-Reply-To: <AFD78192EC49D311BFAE00902798AB8F23DC89@jupiter.arbitrade.com>
Message-ID: <Pine.LNX.4.31.0301061918100.15745-100000@gannet.stats>

?dump.frames has a worked example.

On Mon, 6 Jan 2003, Vadim Ogranovich wrote:

> Dear R-users,
>
> If for whatever reason a batch execution of my script halts I want R to save
> my current environment, along with .Traceback var, in the .RData file (in
> other words I need something like core dump).
>
> It seems however that if execution is halted via stop() no .RData file is
> dumped. So my question is how do produce the "core dump" or something to
> that effect?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From GBLEVINS at marketsolutionsgroup.com  Mon Jan  6 22:49:03 2003
From: GBLEVINS at marketsolutionsgroup.com (Greg Blevins)
Date: Mon Jan  6 22:49:03 2003
Subject: [R] R and file size
Message-ID: <se19a531.018@mail.marketsolutionsgroup.com>

I will be involved with an analysis based on a file that will be roughly 25 meg.  Assuming I have enough memory, is their any limitations to using R on a file this large.

Thank you,



Gregory L. Blevins
Vice President, Partner
The Market Solutions Group, Inc.
gblevins at marketsolutionsgroup.com
Office phone: 612 392-3163
Cell phone: 612 251-0232



From mpalopol at bowdoin.edu  Tue Jan  7 02:52:03 2003
From: mpalopol at bowdoin.edu (Michael F. Palopoli)
Date: Tue Jan  7 02:52:03 2003
Subject: [R] help interpreting output?
Message-ID: <3E1A3286.7080307@bowdoin.edu>

Dear R experts,

I'm hoping someone can help me to interpret the results of building 
gam's with mgcv in R.

Below are summaries of two gam's based on the same dataset.  The first 
gam (named "gam.mod") has six predictor variables.  The second gam 
(named "gam.mod2") is exactly the same except it is missing one of the 
predictor variables.  What is confusing me is the estimated defrees of 
freedom for each of the splines in the second model....

________________

 > summary.gam(mod.gam)

Family: gaussian
Link function: identity

Formula:
INT ~ s(IGS) + s(L2E) + s(TED) + s(PSD) + s(OPD) + s(GED)

Parametric coefficients:
           Estimate  std. err.    t ratio    Pr(>|t|)
constant     302.32      5.192      58.23    < 2.22e-16

Approximate significance of smooth terms:
              edf       chi.sq     p-value
s(IGS)      4.254       58.308     9.5524e-12
s(L2E)          1       8.7673     0.0030668
s(TED)          1       8.3915     0.0037697
s(PSD)          1       6.0234     0.014118
s(OPD)      2.289       12.745     0.0024349
s(GED)      3.791       152.68     < 2.22e-16

R-sq.(adj) = 0.885   Deviance explained = 91.1%
GCV score = 2124.9   Scale est. = 1617.3    n = 60

________________

 >summary.gam(mod.gam2)

Family: gaussian
Link function: identity

Formula:
INT ~ s(IGS) + s(L2E) + s(TED) + s(PSD) + s(OPD)

Parametric coefficients:
           Estimate  std. err.    t ratio    Pr(>|t|)
constant     302.32  4.736e-14  6.384e+15    < 2.22e-16

Approximate significance of smooth terms:
              edf       chi.sq     p-value
s(IGS)  1.757e-05   1.3524e+09     < 2.22e-16
s(L2E)   0.009991      0.21394     0.6437
s(TED)  2.945e-05   1.4913e+07     < 2.22e-16
s(PSD)  2.566e-05   6.5495e+06     < 2.22e-16
s(OPD)  5.023e-05   3.2332e+07     < 2.22e-16

R-sq.(adj) = 0.645   Deviance explained = 64.5%
GCV score = 7489.7   Scale est. = 6069.7    n = 60


________________


Any suggestions about either (1) what went wrong with the second model? 
 or (2) how the heck do I interpet these results?

Thanks,

Mike.



From n_ravishankar at yahoo.com  Tue Jan  7 05:21:03 2003
From: n_ravishankar at yahoo.com (Nirmala Ravishankar)
Date: Tue Jan  7 05:21:03 2003
Subject: [R] plot()
Message-ID: <20030107041958.9491.qmail@web11708.mail.yahoo.com>

I am an R novice trying to figure out plot(). 
Specifically, I am trying to plot the values of a
numeric variable V for a set of years (1970, 1974,
1976, 1978, 1980).  How do I get R to label the years
I am plotting on the x-axis rather then some general
levels (1970, 1975, 1980.)  Using as.character(year)
doesn't seem to help, and using as.factor(year)
generates steps insteads of dots.

Help will be most appreciated.  I have listed the code
I have been using below:

> plot(y$year, y$V, type = "b")
> plot(as.character(y$year), y$V, type = "b")
> plot(as.character(y$year), y$V, type = "b")


Thanks,
NR



From yuelin at mail.med.upenn.edu  Tue Jan  7 05:37:04 2003
From: yuelin at mail.med.upenn.edu (Yuelin Li)
Date: Tue Jan  7 05:37:04 2003
Subject: [R] plot()
Message-ID: <200301070436.h074ais01418@pandora.outcomes.chop.edu>

try text(c("1970", "1978", "1990"), x=1:3, y=1:3) after you first 
call plot(c(1, 3), c(1, 3), axes=F, type="n", xlab="", ylab="") 
to set the plotting area.

Yuelin.


--  From: Nirmala Ravishankar <n_ravishankar at yahoo.com>
  To: r-help at stat.math.ethz.ch
  Subject: [R] plot()
  Date: Mon, 6 Jan 2003 20:19:58 -0800 (PST)
  
  I am an R novice trying to figure out plot(). 
  Specifically, I am trying to plot the values of a
  numeric variable V for a set of years (1970, 1974,
  1976, 1978, 1980).  How do I get R to label the years
  I am plotting on the x-axis rather then some general
  levels (1970, 1975, 1980.)  Using as.character(year)
  doesn't seem to help, and using as.factor(year)
  generates steps insteads of dots.
  
  Help will be most appreciated.  I have listed the code
  I have been using below:
  
  > plot(y$year, y$V, type = "b")
  > plot(as.character(y$year), y$V, type = "b")
  > plot(as.character(y$year), y$V, type = "b")
  
  
  Thanks,
  NR
  
  ______________________________________________
  R-help at stat.math.ethz.ch mailing list
  http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Tue Jan  7 08:54:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan  7 08:54:03 2003
Subject: [R] plot()
In-Reply-To: <20030107041958.9491.qmail@web11708.mail.yahoo.com>
Message-ID: <Pine.LNX.4.31.0301070748120.16497-100000@gannet.stats>

First, it is usual to make plots with generic scales rather than label
each of the x values used, especially when they are irregularly spaced (as
here).  But if you want to do that, use axis() to create your own axis.
Here's a test

y <- data.frame(year=c(1970, 1974, 1976, 1978, 1980), V=rnorm(5))
attach(y)
plot(year, V, type = "b", xaxt="n")
axis(1, year, year)
detach()



On Mon, 6 Jan 2003, Nirmala Ravishankar wrote:

> I am an R novice trying to figure out plot().
> Specifically, I am trying to plot the values of a
> numeric variable V for a set of years (1970, 1974,
> 1976, 1978, 1980).  How do I get R to label the years
> I am plotting on the x-axis rather then some general
> levels (1970, 1975, 1980.)  Using as.character(year)
> doesn't seem to help, and using as.factor(year)
> generates steps insteads of dots.
>
> Help will be most appreciated.  I have listed the code
> I have been using below:
>
> > plot(y$year, y$V, type = "b")
> > plot(as.character(y$year), y$V, type = "b")
> > plot(as.character(y$year), y$V, type = "b")

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Jan  7 11:53:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan  7 11:53:05 2003
Subject: [R] R and file size
In-Reply-To: <se19a531.018@mail.marketsolutionsgroup.com>
Message-ID: <Pine.LNX.4.31.0301071049490.17764-100000@gannet.stats>

On Mon, 6 Jan 2003, Greg Blevins wrote:

> I will be involved with an analysis based on a file that will be roughly 25 meg.  Assuming I have enough memory, is their any limitations to using R on a file this large.

That's a small file!

Seriously, people work on datasets of 100Mb or so in 1Gb (or even 512Mb)
machines.  However, some care is needed to select a good way to read the
data in (if read.table, do follow the advice on the help page), and it
would probably be better to use a database interface (see the Data
Import/Export manual).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From M.GRUM at CGIAR.ORG  Tue Jan  7 12:54:03 2003
From: M.GRUM at CGIAR.ORG (Grum, Mikkel [IPGRI-SSA-Nairobi])
Date: Tue Jan  7 12:54:03 2003
Subject: [R] Extracting means for given strata from dissimilarity object
Message-ID: 
 <FC788AB9771FD6118E6F0002A5AD7B8FF7854B@icrafnttrain.icraf.cgiar.org>

Is there a way of extracting mean distance or dissimilarity for a given
strata from a 'dist' or 'dissimilarity' object, e.g. extract mean distances
for each species in Anderson's iris data? 

data(iris)
iris.dist<-dist(iris[,1:4])

then what?




Mikkel Grum, PhD
Genetic Diversity Scientist
International Plant Genetic Resources Institute (IPGRI)
Sub-Saharan Africa Group
***
PO Box 30677
Nairobi, Kenya
Tel: +254 2 524505(direct)/524500(IPGRI)
Fax: +254 2 524501(IPGRI)/524001(ICRAF)
m.grum at cgiar.org
www.ipgri.org



From armin at xss.de  Tue Jan  7 13:56:06 2003
From: armin at xss.de (Armin Roehrl)
Date: Tue Jan  7 13:56:06 2003
Subject: [R] R and file size
In-Reply-To: <Pine.LNX.4.31.0301071049490.17764-100000@gannet.stats>
References: <Pine.LNX.4.31.0301071049490.17764-100000@gannet.stats>
Message-ID: <200301071355.28273.armin@xss.de>

Am Dienstag, 7. Januar 2003 11:52 schrieb ripley at stats.ox.ac.uk:
> On Mon, 6 Jan 2003, Greg Blevins wrote:
> > I will be involved with an analysis based on a file that will be roughly
> > 25 meg.  Assuming I have enough memory, is their any limitations to using
> > R on a file this large.
>
> That's a small file!
We look at files and databases in the order of 100 gigabytes and more.
The art is to "read in" only what you need and maybe go over the
data several times.

Cheers,
	-A.

----------------------------------------
Armin Roehrl, http://www.approximity.com
We manage risk



From murdoch at stats.uwo.ca  Tue Jan  7 14:02:03 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue Jan  7 14:02:03 2003
Subject: Pie in the sky suggestion (was: [R] Re - segments within a lattice graph)
In-Reply-To: <Pine.LNX.4.31.0301061211310.14876-100000@gannet.stats>
References: <8C2B4A87FC7E0147A65DC17BF4BDDC31010D0118@NLDNC006PEX1.ubsgs.ubsgroup.net> <Pine.LNX.4.31.0301061211310.14876-100000@gannet.stats>
Message-ID: <d4jl1vciccjuapl012dls7ugqotfcg5noh@4ax.com>

On Mon, 6 Jan 2003 12:18:09 +0000 (GMT), you wrote in message
<Pine.LNX.4.31.0301061211310.14876-100000 at gannet.stats>:

>*But* the segments help file is part of base R graphics, and xyplot and
>lsegments are part of the recommended addon package lattice.  To be
>consistent you would want us to document in base R all the places where
>there are limitations of usage with addons (or recommended addons).

Here's a suggestion that would not be at all practical to implement
within the current help system, but something to keep in mind for any
future major revision:    this problem (and many others like it) could
be solved if there were a way for the lsegments help file to ask to be
cross-referenced from the segments help file.  Now we have \seealso,
what we would need would be \referfrom.

This would be relatively easy to do if the help were kept in a
database, and each time it was displayed a new search was done, but
would be really hard with the current system where help pages are
static.

A major benefit of this is that packages often have routines that
don't exactly fall within their nominal scope.  For example, the boot
package has linear programming routines.  If boot could add
cross-references to those routines in appropriate places (e.g. optim),
then more people would know about them.

Duncan Murdoch



From enzmann at kfn.uni-hannover.de  Tue Jan  7 15:47:05 2003
From: enzmann at kfn.uni-hannover.de (Dirk Enzmann)
Date: Tue Jan  7 15:47:05 2003
Subject: [R] subscription of R-help digest
Message-ID: <3E1AE825.174FEAD@kfn.uni-hannover.de>

Although I subscribed to R-help (digest)  I did not receive any R-help
digest mails since December 31, 2002.
If I try to renew the subscription I receive the message "You are
already subscribed!", thus, this does not solve the problem.

What can I do to continue the subscription?

--
*************************************************
Dr. Dirk Enzmann
Criminological Research Institute of Lower Saxony
Luetzerodestr. 9
D-30161 Hannover
Germany

phone: +49-511-348.36.32
fax:   +49-511-348.36.10
email: ENZMANN at KFN.uni-hannover.de

http://www.kfn.de
*************************************************



From bhx2 at mevik.net  Tue Jan  7 16:03:02 2003
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge?= Mevik)
Date: Tue Jan  7 16:03:02 2003
Subject: [R] Generating .R and .Rd files with Sweave/noweb?
Message-ID: <7o8yxxvw8x.fsf@foo.nemo-project.org>

I'm writing a couple of related functions, and I'd like to generate a
(single) .R file (containing the function definitions), and separate .Rd
files (documenting each function).

Would this be possible with Sweave/noewb?  Has anyone tried something
along this idea?

-- 
Regards,
Bj?rn-Helge Mevik



From tblackw at umich.edu  Tue Jan  7 16:44:03 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue Jan  7 16:44:03 2003
Subject: [R] help interpreting output?
In-Reply-To: <3E1A3286.7080307@bowdoin.edu>
Message-ID: <Pine.SOL.4.44.0301071030160.22621-100000@timepilot.gpcc.itd.umich.edu>

Mike  -

I observe that you have dropped by far the most significant single
predictor in going from the first to the second model.  If I had
to guess, I would guess that the remaining predictor variables are
either binary indicator variables or else have only a handful of
distinct values.  Can't dignose much more than that in the absence
of the actual data.

If it were my problem, I would plot the response against each
predictor, also residuals vs. fitted values for each model, and
do some graphical data analysis to diagnose what's going on.
I encourage you to do this for yourself.

						-  tom blackwell  -



On Mon, 6 Jan 2003, Michael F. Palopoli wrote:

> Dear R experts,
>
> I'm hoping someone can help me to interpret the results of building
> gam's with mgcv in R.
>
> Below are summaries of two gam's based on the same dataset.  The first
> gam (named "gam.mod") has six predictor variables.  The second gam
> (named "gam.mod2") is exactly the same except it is missing one of the
> predictor variables.  What is confusing me is the estimated defrees of
> freedom for each of the splines in the second model....
>
> ________________
>
>  > summary.gam(mod.gam)
>
> Family: gaussian
> Link function: identity
>
> Formula:
> INT ~ s(IGS) + s(L2E) + s(TED) + s(PSD) + s(OPD) + s(GED)
>
> Parametric coefficients:
>            Estimate  std. err.    t ratio    Pr(>|t|)
> constant     302.32      5.192      58.23    < 2.22e-16
>
> Approximate significance of smooth terms:
>               edf       chi.sq     p-value
> s(IGS)      4.254       58.308     9.5524e-12
> s(L2E)          1       8.7673     0.0030668
> s(TED)          1       8.3915     0.0037697
> s(PSD)          1       6.0234     0.014118
> s(OPD)      2.289       12.745     0.0024349
> s(GED)      3.791       152.68     < 2.22e-16
>
> R-sq.(adj) = 0.885   Deviance explained = 91.1%
> GCV score = 2124.9   Scale est. = 1617.3    n = 60
>
> ________________
>
>  >summary.gam(mod.gam2)
>
> Family: gaussian
> Link function: identity
>
> Formula:
> INT ~ s(IGS) + s(L2E) + s(TED) + s(PSD) + s(OPD)
>
> Parametric coefficients:
>            Estimate  std. err.    t ratio    Pr(>|t|)
> constant     302.32  4.736e-14  6.384e+15    < 2.22e-16
>
> Approximate significance of smooth terms:
>               edf       chi.sq     p-value
> s(IGS)  1.757e-05   1.3524e+09     < 2.22e-16
> s(L2E)   0.009991      0.21394     0.6437
> s(TED)  2.945e-05   1.4913e+07     < 2.22e-16
> s(PSD)  2.566e-05   6.5495e+06     < 2.22e-16
> s(OPD)  5.023e-05   3.2332e+07     < 2.22e-16
>
> R-sq.(adj) = 0.645   Deviance explained = 64.5%
> GCV score = 7489.7   Scale est. = 6069.7    n = 60
>
>
> ________________
>
>
> Any suggestions about either (1) what went wrong with the second model?
>  or (2) how the heck do I interpet these results?
>
> Thanks,
>
> Mike.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From chrysopa at insecta.ufv.br  Tue Jan  7 17:28:08 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Tue Jan  7 17:28:08 2003
Subject: [R] [off-topic] The better analysis
Message-ID: <200301071420.07453.chrysopa@insecta.ufv.br>

Hi all,
Firstly excuse-me by this off-topic question.

I'm very confused to decide what is the better analysis to use.
Whem the experiments is a tradicional design of manipulative experiments, it 
is easy to decide. But in natural observations is too complicated.

I have 6 farms, each farm cultives some sugarcane's varieties (maybe or not 
the same varieties by farm). For each farm I make 3 transects (lines) 
(replicates) crossing all varieties, and I make one collect point in each 
variety. 

Example:
In farm "A" I have 3 varieties and I make 3 transect, so I have 3*3 = 9 
points. In each collect point all data are obtained independently.

The data are:

* production (my response)

My explanatory variables are:

* sugarcane's variety (categorical, not necessarily the same on all farms)
* age of sugarcane (continuous, not necessarily the same on all farms)
* name of farm (block ??)
* topography (categorical, not necessarily the same on all farms)
* infestation (continuous, the main explanatory variable)

I think make a modelo like this:

lm(production~variety*age*farm*topography*infestation)

My doubt is about the errors, I dont get to know if this is nested, mixed etc.

Anybody can help-me.

Thanks for all
Ronaldo
-- 
Short people get rained on last.
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Gnu/Debian Woody D+:) | Lxuser#: 205366



From simon at stats.gla.ac.uk  Tue Jan  7 17:41:02 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Tue Jan  7 17:41:02 2003
Subject: [R] help interpreting output?
In-Reply-To: <Pine.SOL.4.44.0301071030160.22621-100000@timepilot.gpcc.itd.umich.edu>
Message-ID: <Pine.SOL.3.96.1030107160312.28247A-100000@moon.stats.gla.ac.uk>

The second model has encountered numerical problems, but I guess
you didn't need me to tell you that! Usually this results from model
identifiability problems, for example if one predictor variable is a
simple transformation of another (or in the *generalized* case if the
linear predictor ceases to uniquely determine the fitted values, as can
happen if the fitted values are essentially zero over a wide region of
the covariate space and a log link is used). mgcv does some simple checks
to try and catch the most usual ways in which models can run into these
difficulties (for example by specifing a higher smoothing basis dimension 
than can be supported by the number of unique covariate combinations), but
there's no way of catching all such problems.      

I assume that the second model came with warnings that the termwise edf's
are unreliable - the calculation of the estimated degrees of freedom for
each smooth is not as numerically stable as the actual model fitting, so
models which are somewhat unstable can fit without problems but then cause
problems when calculating diagnostics.... 

More generally I'd be a bit nervous about trying to estimate 5 or 6 smooth
terms and their degrees of freedom from 60 data (but I don't think that
this is the cause of the numerical problems).

If you can't spot an obvious identifiability issue, please let me know in
case it's a bug.

Simon Wood



> 
> > Dear R experts,
> >
> > I'm hoping someone can help me to interpret the results of building
> > gam's with mgcv in R.
> >
> > Below are summaries of two gam's based on the same dataset.  The first
> > gam (named "gam.mod") has six predictor variables.  The second gam
> > (named "gam.mod2") is exactly the same except it is missing one of the
> > predictor variables.  What is confusing me is the estimated defrees of
> > freedom for each of the splines in the second model....
> >
> > ________________
> >
> >  > summary.gam(mod.gam)
> >
> > Family: gaussian
> > Link function: identity
> >
> > Formula:
> > INT ~ s(IGS) + s(L2E) + s(TED) + s(PSD) + s(OPD) + s(GED)
> >
> > Parametric coefficients:
> >            Estimate  std. err.    t ratio    Pr(>|t|)
> > constant     302.32      5.192      58.23    < 2.22e-16
> >
> > Approximate significance of smooth terms:
> >               edf       chi.sq     p-value
> > s(IGS)      4.254       58.308     9.5524e-12
> > s(L2E)          1       8.7673     0.0030668
> > s(TED)          1       8.3915     0.0037697
> > s(PSD)          1       6.0234     0.014118
> > s(OPD)      2.289       12.745     0.0024349
> > s(GED)      3.791       152.68     < 2.22e-16
> >
> > R-sq.(adj) = 0.885   Deviance explained = 91.1%
> > GCV score = 2124.9   Scale est. = 1617.3    n = 60
> >
> > ________________
> >
> >  >summary.gam(mod.gam2)
> >
> > Family: gaussian
> > Link function: identity
> >
> > Formula:
> > INT ~ s(IGS) + s(L2E) + s(TED) + s(PSD) + s(OPD)
> >
> > Parametric coefficients:
> >            Estimate  std. err.    t ratio    Pr(>|t|)
> > constant     302.32  4.736e-14  6.384e+15    < 2.22e-16
> >
> > Approximate significance of smooth terms:
> >               edf       chi.sq     p-value
> > s(IGS)  1.757e-05   1.3524e+09     < 2.22e-16
> > s(L2E)   0.009991      0.21394     0.6437
> > s(TED)  2.945e-05   1.4913e+07     < 2.22e-16
> > s(PSD)  2.566e-05   6.5495e+06     < 2.22e-16
> > s(OPD)  5.023e-05   3.2332e+07     < 2.22e-16
> >
> > R-sq.(adj) = 0.645   Deviance explained = 64.5%
> > GCV score = 7489.7   Scale est. = 6069.7    n = 60
> >
> >
> > ________________
> >
> >
> > Any suggestions about either (1) what went wrong with the second model?
> >  or (2) how the heck do I interpet these results?
> >
> > Thanks,
> >
> > Mike.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From vograno at arbitrade.com  Tue Jan  7 19:50:03 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Tue Jan  7 19:50:03 2003
Subject: [R] interaction of options(error=) and try()
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DC96@jupiter.arbitrade.com>

Dear R-Users,

I am somewhat confused by the interplay between options(error=) and try(). I
set my error handler to an expression that dumps the frames and quits. Yet,
I thought that this handler would NOT be invoked if an error happens within
try(). Apparently it was. Here is the code that I ran as R BATCH:

options(error=quote({dump.frames("t.dump", to.file=TRUE); q()}))
try({ stop("error in try") })
cat("OK\n")


And this is the log:

> options(error=quote({dump.frames("t.dump", to.file=TRUE); q()}))
> 
> 
> try({ stop("error in try") })
Error in try({ : error in try


So my question is why the error handler was invoked within try() and what do
I need to do to avoid this?

Thank you,
Vadim

-------------------------------------------------- 
DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]



From luke at stat.uiowa.edu  Tue Jan  7 20:06:03 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue Jan  7 20:06:03 2003
Subject: [R] interaction of options(error=) and try()
In-Reply-To: <AFD78192EC49D311BFAE00902798AB8F23DC96@jupiter.arbitrade.com>
Message-ID: <Pine.LNX.4.44.0301071301580.32276-100000@nokomis2.stat.umn.edu>

On Tue, 7 Jan 2003, Vadim Ogranovich wrote:

> Dear R-Users,
> 
> I am somewhat confused by the interplay between options(error=) and try(). I
> set my error handler to an expression that dumps the frames and quits. Yet,
> I thought that this handler would NOT be invoked if an error happens within
> try(). Apparently it was. Here is the code that I ran as R BATCH:

The current implementation of try does not override the error handler
setting provided in options.  This will change when a more
sophisticated error handling mechanism currently under development is
released.  For now I thnk your only option is to disable your error
handler around the try.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From jmc at research.bell-labs.com  Tue Jan  7 20:13:03 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue Jan  7 20:13:03 2003
Subject: [R] interaction of options(error=) and try()
References: <Pine.LNX.4.44.0301071301580.32276-100000@nokomis2.stat.umn.edu>
Message-ID: <3E1B269A.8B918E0A@research.bell-labs.com>

Luke Tierney wrote:
> 
> On Tue, 7 Jan 2003, Vadim Ogranovich wrote:
> 
> > Dear R-Users,
> >
> > I am somewhat confused by the interplay between options(error=) and try(). I
> > set my error handler to an expression that dumps the frames and quits. Yet,
> > I thought that this handler would NOT be invoked if an error happens within
> > try(). Apparently it was. Here is the code that I ran as R BATCH:
> 
> The current implementation of try does not override the error handler
> setting provided in options.  This will change when a more
> sophisticated error handling mechanism currently under development is
> released.  For now I thnk your only option is to disable your error
> handler around the try.

The methods package has a function, trySilent(expr), that turns off the
error option while doing the try, basically what Luke is suggesting. 
(It's only in that package because it was needed there; it doesn't
involve methods.)

John Chambers


> 
> luke
> 
> --
> Luke Tierney
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
John M. Chambers                  jmc at bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc



From rossini at blindglobe.net  Tue Jan  7 20:22:05 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue Jan  7 20:22:05 2003
Subject: [R] Generating .R and .Rd files with Sweave/noweb?
In-Reply-To: <7o8yxxvw8x.fsf@foo.nemo-project.org> (bhx2@mevik.net's message
 of "07 Jan 2003 16:02:22 +0100")
References: <7o8yxxvw8x.fsf@foo.nemo-project.org>
Message-ID: <87of6s4vmi.fsf@jeeves.blindglobe.net>

>>>>> "bj?rn-helge" == Bj?rn-Helge Mevik <bhx2 at mevik.net> writes:

    bj?rn-helge> I'm writing a couple of related functions, and I'd like to generate a
    bj?rn-helge> (single) .R file (containing the function definitions), and separate .Rd
    bj?rn-helge> files (documenting each function).

    bj?rn-helge> Would this be possible with Sweave/noewb?  Has anyone tried something
    bj?rn-helge> along this idea?

Yes, but it isn't as automated as one might want.  Doug Bates
suggested a possibly better format/processing system recently to me
(which might be alternatively useful as a post-noweb/sweave processor,
instead of on its own): doxygen, which uses javadoc-style comments,
and whose resulting documentation COULD be converted to *.Rd style
results.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From partha_bagchi at hgsi.com  Tue Jan  7 23:05:03 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue Jan  7 23:05:03 2003
Subject: [R] axis() color from 1.5.1 to 1.6.1
Message-ID: <OFF77B37CE.815B9D37-ON85256CA7.007881BB@hgsi.com>

I see that the definition of axis() has changed from 1.5.1 to 1.6.1 (as 
mentioned in the news file for 1.6.0). Axis now has a color argument to 
change it's color. However, the following command worked in 1.5.1:

> axis(1, at = c(0.1, 0.2, 1, 5, 10), fg= gray(0.7), cex.axis = 0.8, 
col.axis= "red") #plot the axis in gray with annotations in red.

The command no longer works in 1.6.1. I am aware that using a col argument 
in axis would work. However, this does break code written currently (for 
1.5.1) and thus the danger of code being specific to the version of R that 
one is using. 

I am interested in knowing why it does not work.

Thanks,
Partha.



From Paa.K.Nunoo at FMR.COM  Tue Jan  7 23:24:03 2003
From: Paa.K.Nunoo at FMR.COM (Nunoo, Paa K)
Date: Tue Jan  7 23:24:03 2003
Subject: [R] Namespace support?
Message-ID: <763C275E6A1C2248AFD475237AD6135B02DC5CD1@MSGBOS576NTS.fmr.com>

Hi,
I have created an R package in which I implement my own version of the
"as.dataframe" function. However when I load up my package into R, it seems
to mask the original version of "as.data.frame". Is there to limit/control
the scope of the "as.data.frame" function defined in the my package so that
it does not interfere with the original function? Maybe by using namespaces
in R?

thanks
PK



From jeff_hamann at hamanndonald.com  Wed Jan  8 01:48:02 2003
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Wed Jan  8 01:48:02 2003
Subject: [R] ack! my package is broken in win32
Message-ID: <001501c2b6af$98c38e40$0400a8c0@toastman>

I was trying to talk someone through downloading R and running my package
and they kept getting the following error message:

>      ## perform OLS on each of the equations in the system
>      fit1sls <- ols.systemfit( system, inst, labels, kmenta )
Error in model.frame(formula, rownames, variables, varnames, extras,
extranames,  :
        invalid variable type

I tried to reproduce this error by entering the commands by hand and found
that that lots of things are "broken" in the version that was downloaded
from the CRAN. I have a version on my laptop (win32) that I used and I never
see this...

I thought, hummmmm, and updated the package and ran the examples in a
FreeBSD machine and the exampled work fine. Is there something goofy with
the version of R 1.6.1 on windows?



From jeff_hamann at hamanndonald.com  Wed Jan  8 01:54:05 2003
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Wed Jan  8 01:54:05 2003
Subject: [R] even stranger...
Message-ID: <003701c2b6b0$411c0590$0400a8c0@toastman>

I just wrote a note about finding some strange things in R 1.6.1 and thought
my package was broken. I ran the package examples in FreeBSD, from emacs in
Win32 and rterm in Win32 and the package run just fine. When I ran the
package from the RGUI, I got lots of problems. Is this common and is there a
fix yet?

Jeff.



From Duncan.Mackay at flinders.edu.au  Wed Jan  8 02:48:02 2003
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Wed Jan  8 02:48:02 2003
Subject: [R] update.packages through proxy failing
Message-ID: <LKEKIOMKIBNKJOPKIKOOOEJMDBAA.Duncan.Mackay@flinders.edu.au>

Hi all,

my uni has recently switched to using a proxy (with password) for accessing
Web pages outside the uni. I have since found that "update packages" etc no
longer seem to work from R.

I have tried to fix this problem in two ways:-

1) renaming internet2.dll to internet.dll in the "Modeules" folder and
proceeding as usual. When I tried "update packages" from the menu in R, I
got an "Rgui.exe has prodeced errors and is generating an error log" message
and crash.

2) I used the following code

 print(Sys.putenv("HTTP_PROXY"="http://www.flinders.edu.au/proxy.pac/",
password="mypassword"))
[1] TRUE TRUE
> Sys.getenv("HTTP_PROXY")
                             HTTP_PROXY
"http://www.flinders.edu.au/proxy.pac/"
> update.packages()
trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
unable to connect to 'cran.r-project.org'.
Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  :
        cannot open URL
`http://cran.r-project.org/bin/windows/contrib/PACKAGES'


I am using R1.6.1 for Windows under Win2000 Professional and Internet
Explorer 6.0.

Any help gratefully appreciated,
Duncan

*******************************************
Dr. Duncan Mackay
Biology
Flinders University
GPO Box 2100
Adelaide
S.A.    5001
AUSTRALIA

Ph (08) 8201 2627    FAX (08) 8201 3015

http://www.bio.flinders.edu.au/dam/damres.htm



From Duncan.Mackay at flinders.edu.au  Wed Jan  8 03:21:03 2003
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Wed Jan  8 03:21:03 2003
Subject: FW: [R] update.packages through proxy failing
Message-ID: <000a01c2b6bd$03eb4660$cae66081@duncanoffice>

Hi all,
I have tried the helpful suggestion below from Andrew Ward, but I now get
the following error:-

> update.packages()
trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  :
        cannot open: HTTP status was `407 Proxy Authentication Required'


From hb at maths.lth.se  Wed Jan  8 04:36:03 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed Jan  8 04:36:03 2003
Subject: [R] Namespace support?
In-Reply-To: <763C275E6A1C2248AFD475237AD6135B02DC5CD1@MSGBOS576NTS.fmr.com>
Message-ID: <000101c2b6c7$09b83710$7341a8c0@alpha.wehi.edu.au>

I don't know why you are writing your own as.data.frame(), but if you
are using it only on certain types of objects, then I would recommend
you to define a *class specific* function. Using the S3/UseMethod
approach (different from S4/methods) this could look like:

  x <- list(a=..., b=..., c=...)  # Your data structure
  class(x) <- c("MyClass")        # Specifies that x is of class
"MyClass"
  
Then you can define an as.data.frame() that is only used on this class
and will leave all other data types unaffected:

  as.data.frame.MyClass <- function(x, row.names=NULL, optional=FALSE) {
    ...  # Do what you want here
  }

Note the naming rule: <function>.<Class> <- function(<object>, ...)

When calling as.data.frame(x), the generic function as.data.frame() (the
one you've currently overwritten) will call the correct as.data.frame()
depending on the class of x, i.e. in this case as.data.frame.MyClass(x).
This method dispatching is done by the UseMethod() call.

Cheers

Henrik Bengtsson


> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Nunoo, Paa K
> Sent: den 8 januari 2003 09:23
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] Namespace support?
> 
> 
> Hi,
> I have created an R package in which I implement my own version of the

> "as.dataframe" function. However when I load up my package into R, it 
> seems to mask the original version of "as.data.frame". Is there to 
> limit/control the scope of the "as.data.frame" function defined in the

> my package so that it does not interfere with the original function? 
> Maybe by using namespaces in R?
> 
> thanks
> PK
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From olau at fas.harvard.edu  Wed Jan  8 04:46:02 2003
From: olau at fas.harvard.edu (Olivia Lau)
Date: Wed Jan  8 04:46:02 2003
Subject: [R] Lattice: Plotting two densities on the same plot(s)?
Message-ID: <Pine.OSF.4.44.0301072142020.19835-100000@is05.fas.harvard.edu>

I am trying to plot two density lines on the same graph.  Using the
functions on the base package, I would go:

plot(density(x), col = 1)
lines(density(y), col = 2)

And I get two distinct (one-bump) density lines.  When I try to do it
using lattice, I get two two-humped lines.  (In other words, I think the
smoothing function is taking the next set of data points and smoothing them
in the same function as the prior set.)

Using:

library(nlme)
library(grid)

Let:

democrat <- rnorm(100, 0.3, 0.1)
republican <- rnorm(100, 0.5, 0.1)
state <- c("Delaware")
temp1 <- as.data.frame(cbind(state, democrat, republican))

democrat <- rnorm(100, 0.5, 0.1)
republican <- rnorm(100, 0.7, 0.1)
state <- c("Pennsylvania")
temp2 <- as.data.frame(cbind(state, democrat, republican))

data1 <- rbind(temp1, temp2)

What I'm doing right now is:

densityplot(~ democrat | state, data = data1,
  xlim = c(0, 1), ylim = c(0, 10),
  panel = function(x) {
  panel.densityplot(republican,  col = "red")
  panel.densityplot(democrat, col = "black")
  })

What should I do to draw two separate density plots on the same lattice
device?

Thanks,

Olivia Lau



From ravishan at fas.harvard.edu  Wed Jan  8 05:36:02 2003
From: ravishan at fas.harvard.edu (Nirmala Ravishankar)
Date: Wed Jan  8 05:36:02 2003
Subject: [R] Maps in R
Message-ID: <Pine.OSF.4.44.0301072333270.30071-100000@is08.fas.harvard.edu>

Is there a way to generate maps in R.  Specifically, I have calculated
estimates of intra-regional inequality for US states, and would like to
project that information onto a map.

Thanks,
Nirmala



From deepayan at stat.wisc.edu  Wed Jan  8 05:56:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed Jan  8 05:56:03 2003
Subject: [R] Lattice: Plotting two densities on the same plot(s)?
In-Reply-To: <Pine.OSF.4.44.0301072142020.19835-100000@is05.fas.harvard.edu>
References: <Pine.OSF.4.44.0301072142020.19835-100000@is05.fas.harvard.edu>
Message-ID: <200301072256.54394.deepayan@stat.wisc.edu>

On Tuesday 07 January 2003 09:45 pm, Olivia Lau wrote:
> I am trying to plot two density lines on the same graph.  Using the
> functions on the base package, I would go:
>
> plot(density(x), col = 1)
> lines(density(y), col = 2)
>
> And I get two distinct (one-bump) density lines.  When I try to do it
> using lattice, I get two two-humped lines.  (In other words, I think the
> smoothing function is taking the next set of data points and smoothing them
> in the same function as the prior set.)
>
> Using:
>
> library(nlme)
> library(grid)

You don't seem to be using nlme anywhere. And 

library(lattice) 

would automatically load grid.

> Let:
>
> democrat <- rnorm(100, 0.3, 0.1)
> republican <- rnorm(100, 0.5, 0.1)
> state <- c("Delaware")
> temp1 <- as.data.frame(cbind(state, democrat, republican))
>
> democrat <- rnorm(100, 0.5, 0.1)
> republican <- rnorm(100, 0.7, 0.1)
> state <- c("Pennsylvania")
> temp2 <- as.data.frame(cbind(state, democrat, republican))
>
> data1 <- rbind(temp1, temp2)

This is probably not what you wanted, since the varibles 'republican' and 
'democrat' in data1 have now become factors. (When you use them in 
panel.densityplot below, you are using not the ones in the data frame, but 
rather the ones in your global environment.)

> What I'm doing right now is:
>
> densityplot(~ democrat | state, data = data1,
>   xlim = c(0, 1), ylim = c(0, 10),
>   panel = function(x) {
>   panel.densityplot(republican,  col = "red")
>   panel.densityplot(democrat, col = "black")
>   })
>
> What should I do to draw two separate density plots on the same lattice
> device?

The recommended way needs the data frame to structured differently. Let's say 
you have the 4 sets of numbers 

del.democrat <- rnorm(100, 0.3, 0.1)
del.republican <- rnorm(100, 0.5, 0.1)
penn.democrat <- rnorm(100, 0.5, 0.1)
penn.republican <- rnorm(100, 0.7, 0.1)

Create the data frame as 

data1 <- expand.grid(replication = 1:100, 
                     party = c("democrat", "republican"), 
                     state = c("Delaware", "Pennsylvania"))

data1$x <- c(del.democrat, del.republican, 
             penn.democrat, penn.republican)

Then,

densityplot(~ x | state, data1, groups = party, panel = "panel.superpose")

should give you what you want.

Deepayan



From otoomet at econ.dk  Wed Jan  8 08:09:03 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Wed Jan  8 08:09:03 2003
Subject: [R] Maps in R
Message-ID: <200301080709.h0879f709068@punik.econ.au.dk>

 | From: Nirmala Ravishankar <ravishan at fas.harvard.edu>
 | Date: Tue, 7 Jan 2003 23:35:19 -0500 (EST)
 | 
 | Is there a way to generate maps in R.  Specifically, I have calculated
 | estimates of intra-regional inequality for US states, and would like to
 | project that information onto a map.
 | 
 | Thanks,
 | Nirmala

There is a package called maps at

ftp://ftp.mcs.vuw.ac.nz/pub/statistics/map/

(maps_0.1-4.tar.gz worked well for me at linux, I am not quite sure
about windows).

There are not many different countries present but US is, both on
state and county level.  However, I have noticed problems with US maps
when experimenting with color codes.  

There seem not to a function to plot each state with a given color,
the main function map() draws different polygons with different color
but a state may contain many polygons.  I have written my own, I
include it below, it is made for Danish counties but should be easy to
change for e.g. US states.  

BTW, I have made a low-resolution map for Danish counties, if anybody
has interest.  

Best,

Ott

--------------------------------------------
This function plots Danish map with color codes as given by vector x.
x is a vector with names equal to county names.  The function finds
itself maximum and minimum value of x, sets the colors accordingly,
and draws a legend.

mapPlot.default <- function(x, main=NULL, ...) {
### plot a vector on the map using names of the vector
  mkPlot <- function(name, col) {
    map("danmark", name, col=col, fill=T, add=T)
   }
  mkCol <- function(val) {
    i <- as.integer(99*(val - x0)/(x1 - x0))
    i <- ifelse(i < 1, 1, i)
    i <- ifelse(i > 100, 100, i)
    col[i]
  }
  if(!any(search() == "package:maps")) {
    cat("Loading maps library...")
    library(maps, lib.loc="/home/otoomet/proge/R")
    cat("done\n")
  }
  x <- unlist(x)
  opar <- par(xpd=TRUE,
              las=0)
  on.exit(par(opar), add=TRUE)
  regionNames <- map("danmark", plot=FALSE, namesonly=TRUE)
  r <- map("danmark", ...)$range
  mtext(main, line=1, cex=1.5)
  col <- topo.colors(100)
  iRegions <- sapply(names(x), function(y) length(grep(y, regionNames)) > 0)
                                        # which regions exist on the map
  x <- x[iRegions]
  x0 <- range(x)[1]
  x1 <- range(x)[2]
  sapply(seq(along=x),
                   FUN=function(i) mkPlot(names(x[i]), mkCol(x[i])))
  lev <- zapsmall(pretty(x, n=10))
  legx <- r[2]
  legy <- r[4]
  legend(legx, legy, legend=as.character(lev), fill=mkCol(lev),
         bty="n")
}



From r.darnell at shrs.uq.edu.au  Wed Jan  8 08:22:03 2003
From: r.darnell at shrs.uq.edu.au (Ross Darnell)
Date: Wed Jan  8 08:22:03 2003
Subject: [R] Searching for glmmNQ
Message-ID: <lm1wrtrr.fsf@shrs.uq.edu.au>

I cannot find the glmmNQ function in the MASS package (or anywhere else I have tried) mentioned on page 296 of MASS4.

I would appreciate directions.
Thanks
-- 
Ross Darnell



From ripley at stats.ox.ac.uk  Wed Jan  8 08:57:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan  8 08:57:03 2003
Subject: [R] Searching for glmmNQ
In-Reply-To: <lm1wrtrr.fsf@shrs.uq.edu.au>
Message-ID: <Pine.LNX.4.31.0301080755440.2811-100000@gannet.stats>

You could ask the authors rather than broadcast to a help list!

It is not yet released, but versions do exist.

On 8 Jan 2003, Ross Darnell wrote:

>
> I cannot find the glmmNQ function in the MASS package (or anywhere else I have tried) mentioned on page 296 of MASS4.
>
> I would appreciate directions.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Jan  8 09:04:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan  8 09:04:05 2003
Subject: [R] update.packages through proxy failing
In-Reply-To: <LKEKIOMKIBNKJOPKIKOOOEJMDBAA.Duncan.Mackay@flinders.edu.au>
Message-ID: <Pine.LNX.4.31.0301080757240.2811-100000@gannet.stats>

On Wed, 8 Jan 2003, Duncan Mackay wrote:

> my uni has recently switched to using a proxy (with password) for accessing
> Web pages outside the uni. I have since found that "update packages" etc no
> longer seem to work from R.
>
> I have tried to fix this problem in two ways:-
>
> 1) renaming internet2.dll to internet.dll in the "Modeules" folder and
> proceeding as usual. When I tried "update packages" from the menu in R, I
> got an "Rgui.exe has prodeced errors and is generating an error log" message
> and crash.

No wonder.  Try looking *carefully* at the CHANGES file, undoing the
criminal damage you caused and using the --internet2.dll flag.

Or just read ?download.file (linked from ?update.packages).

> 2) I used the following code
>
>  print(Sys.putenv("HTTP_PROXY"="http://www.flinders.edu.au/proxy.pac/",
> password="mypassword"))
> [1] TRUE TRUE
> > Sys.getenv("HTTP_PROXY")
>                              HTTP_PROXY
> "http://www.flinders.edu.au/proxy.pac/"
> > update.packages()
> trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
> unable to connect to 'cran.r-project.org'.
> Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  :
>         cannot open URL
> `http://cran.r-project.org/bin/windows/contrib/PACKAGES'

You've already damaged your system, *and* the help page says you cannot
set the variables that way!  And it also says that is not the format for
proxies.

> Any help gratefully appreciated,

Read and follow the instructions?  I do suggest you reinstall R, then
use the --internet2 flag *as documented*.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dvumani at hotmail.com  Wed Jan  8 09:50:04 2003
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Wed Jan  8 09:50:04 2003
Subject: [R] negatively correlated binary data
Message-ID: <F76dTyj6iZkxUWZoIpk00007f82@hotmail.com>

Dear R users:


Is there a way to create negatively correlated binary data in R. I have 
looked at bindata, but it seems it only works with positively correlated 
data.


Thanks.


Vumani Dlamini
Swaziland



From phgrosjean at sciviews.org  Wed Jan  8 10:43:02 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed Jan  8 10:43:02 2003
Subject: [R] Tools for tree naviguation
Message-ID: <MABBLJDICACNFOLGIHJOMEFPDCAA.phgrosjean@sciviews.org>

Sorry for this out-of-topic message. A while ago, somebody mentioned a
software (an R interface xas in development at that time) to graphically
look inside classification/regression trees and calculate various statistics
on their nodes. Unfortunatelly, I lost the link and do not remember at all
the name of the software. Could someone refresh my poor memory,... or
perhaps point me on other interesting stuff in this field (no mention of R
packages available in CRAN because I know them, of course).
Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



From james.lindsey at luc.ac.be  Wed Jan  8 10:47:28 2003
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Wed Jan  8 10:47:28 2003
Subject: [R] negatively correlated binary data
In-Reply-To: <F76dTyj6iZkxUWZoIpk00007f82@hotmail.com> from "Vumani Dlamini" at Jan 08, 2003 08:45:07 AM
Message-ID: <200301080942.KAA08915@luc.ac.be>

> 
> 
> Dear R users:
> 
> 
> Is there a way to create negatively correlated binary data in R. I have 
> looked at bindata, but it seems it only works with positively correlated 
> data.

Take a look at

?rdoublebinom
?rmultbinom

after loading my rmutil library.

As well, gnlr in my gnlm library will fit linear and nonlinear
regression models using these distributions.

www.luc.ac.be/~jlindsey/rcode.html

  Jim

> 
> 
> Thanks.
> 
> 
> Vumani Dlamini
> Swaziland
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From laura at bayesian-bay.freeserve.co.uk  Wed Jan  8 12:19:02 2003
From: laura at bayesian-bay.freeserve.co.uk (Laura Gross)
Date: Wed Jan  8 12:19:02 2003
Subject: [R] Fixed Correlation Matrices in gee package
Message-ID: <l6LNDIABjAH+Ewfb@toastyhamster.karoo.co.uk>

Dear List

I am using the gee package and want to specify my own correlation
structure using the corstr(fixed) option.

Can anybody advise me how exactly I need to define the structure I want?
Do I create a matrix myself? How can I get the command to realise it
needs to use my own matrix?

Many thanks
Lauar



From Virgilio.Gomez at uv.es  Wed Jan  8 12:26:03 2003
From: Virgilio.Gomez at uv.es (Virgilio =?ISO-8859-1?Q?G=F3mez?= Rubio)
Date: Wed Jan  8 12:26:03 2003
Subject: [R] Maps in R
Message-ID: <1042025170.729.8.camel@chomsky>

Hi,

There a package called RArcInfo (which I've written) which can import
data maps in ESRI E00 files and Arc/Info V 7.x binary coverages.
Besides, it provides several functions to plot maps. One of them allows
polygons to be filled with different colors.

Please, visit http://matheron.uv.es/~virgil/Rpackages/RArcInfo and take
a look at the draft tutorial and to the screenshots.

By the way, I think you can get all the US states maps for free in E00
format from the web of the Census (www.census.gov).

Hope this helps. Regards,

-- 
             Virgilio G?mez Rubio

Dpto. Estad?stica e I. O. - Facultat de Matem?tiques
Avda. Vicent A. Estell?s, 1 - 46100 Burjassot
Valencia - SPAIN

http://matheron.uv.es/~virgil

TLF: 00 34 96 354 43 62 - FAX: 00 34 96 354 47 35



From B.Rowlingson at lancaster.ac.uk  Wed Jan  8 14:01:17 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed Jan  8 14:01:17 2003
Subject: [R] Maps in R - Rmap library announcement
In-Reply-To: <1042025170.729.8.camel@chomsky>
References: <1042025170.729.8.camel@chomsky>
Message-ID: <3E1C2106.7030801@lancaster.ac.uk>

Its a shame that there exists several map packages that all use 
different data file formats.

So I started writing a package that will be independent of any file 
format, once we've written methods for each file format, that is.

My Rmap project is now available in a rather buggy but hey it works version:

http://www.maths.lancs.ac.uk/Software/Rmap

What does it do? Well at the moment it can only handle ESRI shapefiles, 
but I'm working on an OGR driver that will open the window to many file 
formats for zero effort. OGR is included in GDAL - see my web page for 
links.

The basic idea is to present the map layer as a data frame. Columns of 
the data frame represent attributes of the entities (polygons, lines, 
points) and rows represent each entity. So you can do this:

africa <- shapefile("/u/data/africa.shp")

mapplot(africa)

mapplot(africa[africa$name=="KENYA",])

  and even:

myFit <- lm(pop~area,data=africa)

  Isn't that neat? How about something like:

mapplot(africa,fill=popcolour(africa$population))

  and if you have the PROJ4 library installed, it can even do map 
projections if your data is lat-long:

mapplot(africa, proj="+proj=ortho")   # orthographic projection
mapplot(africa, proj="+proj=merc")    # mercator projection

  And you can use the inverse projection to get lat-long back from a 
locator() on the graphics device.

I'm going to look at the RArcInfo and the map libraries and see what I 
can borrow from them to solve some of the current problems with my Rmap. 
Please feel (GPL) free to download and play with Rmap, but beware the 
dreaded segmentation fault. Remember to save.image() early and 
save.image() often. Its a bit awkward to install at the moment because 
of its reliance on Shapelib and PROJ4, but we can fix that...

Enjoy!

Baz Rowlingson
Maths and Stats
Lancaster University
Lancaster, UK



From maechler at stat.math.ethz.ch  Wed Jan  8 14:08:58 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Jan  8 14:08:58 2003
Subject: [R] Extracting means for given strata from dissimilarity object
In-Reply-To: <FC788AB9771FD6118E6F0002A5AD7B8FF7854B@icrafnttrain.icraf.cgiar.org>
References: <FC788AB9771FD6118E6F0002A5AD7B8FF7854B@icrafnttrain.icraf.cgiar.org>
Message-ID: <15900.8804.630950.684307@gargle.gargle.HOWL>

>>>>> "MGrum" == Grum, Mikkel [IPGRI-SSA-Nairobi] <Grum>
>>>>>     on Tue, 07 Jan 2003 03:51:38 -0800 writes:

    MGrum> Is there a way of extracting mean distance or
    MGrum> dissimilarity for a given strata from a 'dist' or
    MGrum> 'dissimilarity' object, e.g. extract mean distances
    MGrum> for each species in Anderson's iris data?

    MGrum> data(iris)
    MGrum> iris.dist<-dist(iris[,1:4])

    MGrum> then what?

mean(iris.dist)   # or
summary(iris.dist)

give the overall statistics; 
for "individual ones", use as.matrix() and apply(), as

## e.g.,
am <- apply(as.matrix(iris.dist), 2, mean)
identical(am, 
          apply(as.matrix(iris.dist), 1, mean) ## -> TRUE


Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ligges at statistik.uni-dortmund.de  Wed Jan  8 14:59:06 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Jan  8 14:59:06 2003
Subject: [R] Tools for tree naviguation
References: <MABBLJDICACNFOLGIHJOMEFPDCAA.phgrosjean@sciviews.org>
Message-ID: <3E1C2EF0.78059910@statistik.uni-dortmund.de>

Philippe Grosjean wrote:
> 
> Sorry for this out-of-topic message. A while ago, somebody mentioned a
> software (an R interface xas in development at that time) to graphically
> look inside classification/regression trees and calculate various statistics
> on their nodes. Unfortunatelly, I lost the link and do not remember at all
> the name of the software. Could someone refresh my poor memory,... or
> perhaps point me on other interesting stuff in this field (no mention of R
> packages available in CRAN because I know them, of course).
> Best,

Maybe KLIMT at http://stats.math.uni-augsburg.de/Klimt by Simon Urbanek?

Uwe Ligges



From Marcus.Riether at sesi.org.br  Wed Jan  8 15:06:02 2003
From: Marcus.Riether at sesi.org.br (Marcus Mattos  Riether)
Date: Wed Jan  8 15:06:02 2003
Subject: [R] Overplotting two series of observations in R
Message-ID: <OFA9BF5F99.52E2A7F4-ON83256CA8.004D1FC9@sesi.org.br>

Hi all.

Could anyone help me find how to overplot two series of observations in the
same window?

Thanks.

Marcus M. Riether
---------------------------------------------
marcus.riether at sesi.org.br
SESI Departamento Nacional
Tecnologia da Educa??o
tel.: (61) 317 9914

"Not everything that can be counted counts
 and not everything that counts can be counted."

                                            Einstein



From tona at stat.math.ethz.ch  Wed Jan  8 15:12:03 2003
From: tona at stat.math.ethz.ch (Bruno Tona)
Date: Wed Jan  8 15:12:03 2003
Subject: [R] problem with 'gnls'
Message-ID: <15900.12432.623856.466342@gargle.gargle.HOWL>

I am working with data measured in a tunnel to estimate the
emission factor of heavy & light vehicles.

I tried to use 'gnls' and I get the following Error:
>> Error in "coef<-.corARMA"(*tmp*, value = c(174.267493382104, 173.412740072763
>> Coefficient matrix not invertible


Here is my R-code:  (You can paste it directly into R)

 data <- read.table('http://www.stat.math.ethz.ch/~tona/Data/d.plabutsch.neu')
 
 # calculating the starting coeficients:
 library("MASS")
 library("lqs")
 r.CO2.rlm <- rlm(EF.CO2 ~ pLKW.total + Sat + Sun + Fz.total,
                  data = data, method = "MM", na.action = na.exclude)
 START <- coef(r.CO2.rlm); names(START) <- letters[1:5]; START
 ##           a           b           c           d           e 
 ## 192.6353049 796.3362315 -35.3434214 -58.8489047  -0.1085019 

 # 'gnls':
 library("nlme")
 r.CO2.gnls <- gnls(log(EF.CO2) ~ log(a + b * pLKW.total) + c * Sat +
                    d * Sun + e * Fz.total,start = START, data = data,
                    correlation=corARMA(p=2,q=0), na.action = na.exclude)
 ## Error in "coef<-.corARMA"(*tmp*, value = c(174.267494204742, 173.41274089312
 ##	Coefficient matrix not invertible




I also tried with an AR(3) and an AR(1). The AR(3) gives the same
error like above and the AR(1) gives the error:
>> Error in optim(fn = function(gnlsPars) -logLik(gnlsSt, gnlsPars), par = c(coef(gnlsSt)),  : 
>>      initial value in vmmin is not finite
>> In addition: There were 14 warnings (use warnings() to see them)


Thanks for any help

regards
Bruno Tona



From daniel.hoppe at em.uni-karlsruhe.de  Wed Jan  8 15:16:05 2003
From: daniel.hoppe at em.uni-karlsruhe.de (Daniel Hoppe)
Date: Wed Jan  8 15:16:05 2003
Subject: [R] Problem with fontsize of pie-chart in postscript file
Message-ID: <000001c2b71e$6b670250$0200a8c0@chiloe>

Hi all,

I've a problem with the size of the labels of my pie-charts when I try to
write them to a postscript file. I need to increase the default size, so I
change cex (see below). On screen this works fine, but cex doesn't seem to
affect the postscript-file. Any suggestions?

Thanks a lot,

Daniel

Copy/Past-example (will try to write to c:/temp!):

labels <- c("I", "H", "G", "K", "V")
lineItems <- c(6252,943605,271207,517764,44108)
orders <- c(2084,226894,49218,164056,15809)
value <- c(1380425,87743481,35212459,76346384,10403599)
count <- c(52,17571,261,53270,843)

col = gray(seq(0.2,.8,length=6))

oldpar <- par()
par(cex=2)

#postscript("c:/temp/1.eps", onefile = FALSE)
pie(lineItems, labels=labels, col=col, density=15, angle = 15 + 10 * 1:6)
#dev.off()

postscript("c:/temp/2.eps", onefile = FALSE)
pie(orders, labels=labels, col=col, density=15, angle = 15 + 10 * 1:6)
dev.off()

postscript("c:/temp/3.eps", onefile = FALSE)
pie(value, labels=labels, col=col, density=15, angle = 15 + 10 * 1:6)
dev.off()
par(oldpar)



From wscherr at itc-world.com  Wed Jan  8 15:19:27 2003
From: wscherr at itc-world.com (Wolfgang Scherr)
Date: Wed Jan  8 15:19:27 2003
Subject: [R] Errors running R in Batch mode under Win2000
Message-ID: <GDEBIOHLIGJIMKMGJELHGEOOCKAA.wscherr@itc-world.com>

I have made many different attempts to run a R program in Batch mode. I run a DOS command like:

C:\Progra~1\R\rw1061\bin\rterm.exe  -q --no-restore --no-save   myprogram.R  out.txt

What happens:
1. DOS Shell starts up well
2. R starts
3. I get the messages:
    "ARGUMENT 'myprogram.R' __ignored__"
    "ARGUMENT 'out.txt' __ignored__"
4. R Shell is ready to roll (which is nice, but not what I intended to get)

Help is greatly appreciated: how can I start myprogram.R?

--
Wolfgang Scherr
Innovative Transportation Concepts, Inc.
302-654-4384 phone
wscherr at itc-world.com
www.itc-world.com



From ligges at statistik.uni-dortmund.de  Wed Jan  8 15:32:06 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Jan  8 15:32:06 2003
Subject: [R] Errors running R in Batch mode under Win2000
References: <GDEBIOHLIGJIMKMGJELHGEOOCKAA.wscherr@itc-world.com>
Message-ID: <3E1C36B8.27B6CCCA@statistik.uni-dortmund.de>


Wolfgang Scherr wrote:
> 
> I have made many different attempts to run a R program in Batch mode. I run a DOS command like:
> 
> C:\Progra~1\R\rw1061\bin\rterm.exe  -q --no-restore --no-save   myprogram.R  out.txt
> 
> What happens:
> 1. DOS Shell starts up well
> 2. R starts
> 3. I get the messages:
>     "ARGUMENT 'myprogram.R' __ignored__"
>     "ARGUMENT 'out.txt' __ignored__"
> 4. R Shell is ready to roll (which is nice, but not what I intended to get)
> 
> Help is greatly appreciated: how can I start myprogram.R?

See the R for Windows FAQs, Section 2.9: "Can I use R BATCH?"

Uwe Ligges



From ripley at stats.ox.ac.uk  Wed Jan  8 15:38:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan  8 15:38:03 2003
Subject: [R] Errors running R in Batch mode under Win2000
In-Reply-To: <GDEBIOHLIGJIMKMGJELHGEOOCKAA.wscherr@itc-world.com>
Message-ID: <Pine.LNX.4.31.0301081431230.9891-100000@gannet.stats>

See the rw-FAQ.  Please do check the FAQs before posting.

This is not how you start any C program in batch mode under any OS I am
aware of, and certainly not under Windows.  You need to learn about
redirection (< and >).

On Wed, 8 Jan 2003, Wolfgang Scherr wrote:

> I have made many different attempts to run a R program in Batch mode. I run a DOS command like:
>
> C:\Progra~1\R\rw1061\bin\rterm.exe  -q --no-restore --no-save   myprogram.R  out.txt
>
> What happens:
> 1. DOS Shell starts up well
> 2. R starts
> 3. I get the messages:
>     "ARGUMENT 'myprogram.R' __ignored__"
>     "ARGUMENT 'out.txt' __ignored__"
> 4. R Shell is ready to roll (which is nice, but not what I intended to get)
>
> Help is greatly appreciated: how can I start myprogram.R?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Wed Jan  8 15:44:05 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Jan  8 15:44:05 2003
Subject: [R] Problem with fontsize of pie-chart in postscript file
References: <000001c2b71e$6b670250$0200a8c0@chiloe>
Message-ID: <3E1C39CB.579EC8D8@statistik.uni-dortmund.de>


Daniel Hoppe wrote:
> 
> Hi all,
> 
> I've a problem with the size of the labels of my pie-charts when I try to
> write them to a postscript file. I need to increase the default size, so I
> change cex (see below). On screen this works fine, but cex doesn't seem to
> affect the postscript-file. Any suggestions?
> 
> Thanks a lot,
> 
> Daniel
> 
> Copy/Past-example (will try to write to c:/temp!):
> 
> labels <- c("I", "H", "G", "K", "V")
> lineItems <- c(6252,943605,271207,517764,44108)
> orders <- c(2084,226894,49218,164056,15809)
> value <- c(1380425,87743481,35212459,76346384,10403599)
> count <- c(52,17571,261,53270,843)
> 
> col = gray(seq(0.2,.8,length=6))
> 
> oldpar <- par()
> par(cex=2)
> #postscript("c:/temp/1.eps", onefile = FALSE)
> pie(lineItems, labels=labels, col=col, density=15, angle = 15 + 10 * 1:6)
> #dev.off()
> 
> postscript("c:/temp/2.eps", onefile = FALSE)
> pie(orders, labels=labels, col=col, density=15, angle = 15 + 10 * 1:6)
> dev.off()
> 
> postscript("c:/temp/3.eps", onefile = FALSE)
> pie(value, labels=labels, col=col, density=15, angle = 15 + 10 * 1:6)
> dev.off()
> par(oldpar)
> 

You have to set par() for the current device, i.e. after you invoked:

 postscript("c:/temp/1.eps", onefile = FALSE)
 par(cex=2)
 pie(lineItems, labels=labels, col=col, density=15, angle = 15 + 10 *
1:6)
 dev.off()

Uwe Ligges



From ripley at stats.ox.ac.uk  Wed Jan  8 15:49:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan  8 15:49:04 2003
Subject: [R] Problem with fontsize of pie-chart in postscript file
In-Reply-To: <000001c2b71e$6b670250$0200a8c0@chiloe>
Message-ID: <Pine.LNX.4.31.0301081445200.9891-100000@gannet.stats>

par(cex=2) affects the currently open device, not ones you open in the
future.

So call it *after* opening the desired device.

On Wed, 8 Jan 2003, Daniel Hoppe wrote:

> Hi all,
>
> I've a problem with the size of the labels of my pie-charts when I try to
> write them to a postscript file. I need to increase the default size, so I
> change cex (see below). On screen this works fine, but cex doesn't seem to
> affect the postscript-file. Any suggestions?
>
> Thanks a lot,
>
> Daniel
>
> Copy/Past-example (will try to write to c:/temp!):
>
> labels <- c("I", "H", "G", "K", "V")
> lineItems <- c(6252,943605,271207,517764,44108)
> orders <- c(2084,226894,49218,164056,15809)
> value <- c(1380425,87743481,35212459,76346384,10403599)
> count <- c(52,17571,261,53270,843)
>
> col = gray(seq(0.2,.8,length=6))
>
> oldpar <- par()
> par(cex=2)
>
> #postscript("c:/temp/1.eps", onefile = FALSE)
> pie(lineItems, labels=labels, col=col, density=15, angle = 15 + 10 * 1:6)
> #dev.off()
>
> postscript("c:/temp/2.eps", onefile = FALSE)
> pie(orders, labels=labels, col=col, density=15, angle = 15 + 10 * 1:6)
> dev.off()
>
> postscript("c:/temp/3.eps", onefile = FALSE)
> pie(value, labels=labels, col=col, density=15, angle = 15 + 10 * 1:6)
> dev.off()
> par(oldpar)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Wed Jan  8 16:02:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Jan  8 16:02:03 2003
Subject: [R] Overplotting two series of observations in R
References: <OFA9BF5F99.52E2A7F4-ON83256CA8.004D1FC9@sesi.org.br>
Message-ID: <3E1C3DF2.8AFE7745@statistik.uni-dortmund.de>

Marcus Mattos Riether wrote:
> 
> Hi all.
> 
> Could anyone help me find how to overplot two series of observations in the
> same window?
> 
> Thanks.
> 
> Marcus M. Riether


This question was already frequently asked (and answered!) on R-Help.
Please check the mail archives for a couple of more detailed answers!
The required tools are described in the graphics part of "An
Introduction to R".

In an outburst of kindness, let's demonstrate the principle again.
Consider you want to plot y1 against x1 and y2 against x2 in the same
plot:

 plot(x1, y1, xlim = range(x1, x2), ylim = range(y1, y2))
 points(x2, y2, col = "red")

Uwe Ligges



From Frederic.Darboux at orleans.inra.fr  Wed Jan  8 16:20:03 2003
From: Frederic.Darboux at orleans.inra.fr (=?ISO-8859-1?Q?Fr=E9d=E9ric_Darboux?=)
Date: Wed Jan  8 16:20:03 2003
Subject: [R] Rcmd.exe in R 1.6.1 for windows?
Message-ID: <3E1C4185.8040908@orleans.inra.fr>

Hello all.

I have just installed R version 1.6.1 for Windows on a XP machine.
I would like to use R in batch mode. For this, I looked for Rcmd.exe, 
but did not find it.
Any hint where it could be?
(in version 1.4.1, it was in the bin directory...)

Fr?d?ric Darboux

.......................................................
INRA Orl?ans - Science du Sol
Avenue de la Pomme de Pin
BP 20619
F-45166 Olivet Cedex
France
Ph:  +33 2 38 41 48 23
Fax: +33 2 38 41 78 69
Email: <Frederic.Darboux at orleans.inra.fr>
Web: <http://soils.ecn.purdue.edu/~darboux>



From ripley at stats.ox.ac.uk  Wed Jan  8 16:29:33 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan  8 16:29:33 2003
Subject: [R] Rcmd.exe in R 1.6.1 for windows?
In-Reply-To: <3E1C4185.8040908@orleans.inra.fr>
Message-ID: <Pine.LNX.4.31.0301081527430.16172-100000@gannet.stats>

Same place.  Did you install with the options needed, that is
`source packages' was ticked?

On Wed, 8 Jan 2003, [ISO-8859-1] Frédéric Darboux wrote:

> Hello all.
>
> I have just installed R version 1.6.1 for Windows on a XP machine.
> I would like to use R in batch mode. For this, I looked for Rcmd.exe,
> but did not find it.
> Any hint where it could be?
> (in version 1.4.1, it was in the bin directory...)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From djw1005 at cam.ac.uk  Wed Jan  8 16:34:04 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Wed Jan  8 16:34:04 2003
Subject: [R] Sweep for data frames?
In-Reply-To: <Pine.LNX.4.31.0301081431230.9891-100000@gannet.stats>
Message-ID: <Pine.SOL.3.96.1030108151700.27169A-100000@libra.cus.cam.ac.uk>

I am trying (I think) to achieve something like "sweep" for data frames.

I have a data frame. Two columns are factors, say with L and M levels; one
is numeric. Within each of L*M classes of observations, I would like to
normalize the numerical value by its mean.

Here is an example of what I mean.

data <- data.frame(
   fac1=c("A","A","B","B","B"),
   fac2=c("a","b","a","a","b"),
   x=rnorm(5))
split.names <- c("fac1","fac2")
t <- tapply(data$x, data[split.names], mean)
# now t is an array, and I can index it like this:
t["A","b"]
# I want to do something like
data$xnorm <- data$x / t[data[split.names]]
# but I am told: Error: invalid subscript type

I would like to retrieve a vector of the values of the t-array, one item
in the vector for each row of the data frame. I would be grateful for
instructions.

I think I could also achieve this by creating a data frame instead of the
table t, as in Venables+Ripley MASS (4th ed) p. 39, and then merging the
tables, as on p. 35. Is this the most effective way to achieve what I
want, or is there a more direct way?

Damon.



From Frederic.Darboux at orleans.inra.fr  Wed Jan  8 16:39:04 2003
From: Frederic.Darboux at orleans.inra.fr (=?ISO-8859-1?Q?Fr=E9d=E9ric_Darboux?=)
Date: Wed Jan  8 16:39:04 2003
Subject: [R] Rcmd.exe in R 1.6.1 for windows?
In-Reply-To: <Pine.LNX.4.31.0301081527430.16172-100000@gannet.stats>
References: <Pine.LNX.4.31.0301081527430.16172-100000@gannet.stats>
Message-ID: <3E1C452C.4010509@orleans.inra.fr>


ripley at stats.ox.ac.uk wrote:
> Same place.  Did you install with the options needed, that is
> `source packages' was ticked?

No it wasn't.
I have just re-installed R with this option ticked and it is here now...
Thank you.

Fr?d?ric


> 
> On Wed, 8 Jan 2003, [ISO-8859-1] Fr?d?ric Darboux wrote:
> 
> 
>>Hello all.
>>
>>I have just installed R version 1.6.1 for Windows on a XP machine.
>>I would like to use R in batch mode. For this, I looked for Rcmd.exe,
>>but did not find it.
>>Any hint where it could be?
>>(in version 1.4.1, it was in the bin directory...)
> 
> 

-- 
.......................................................
INRA Orl?ans - Science du Sol
Avenue de la Pomme de Pin
BP 20619
F-45166 Olivet Cedex
France
Ph:  +33 2 38 41 48 23
Fax: +33 2 38 41 78 69
Email: <Frederic.Darboux at orleans.inra.fr>
Web: <http://soils.ecn.purdue.edu/~darboux>



From ligges at statistik.uni-dortmund.de  Wed Jan  8 16:42:18 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Jan  8 16:42:18 2003
Subject: [R] Rcmd.exe in R 1.6.1 for windows?
References: <3E1C4185.8040908@orleans.inra.fr>
Message-ID: <3E1C4613.7A86178D@statistik.uni-dortmund.de>


Fr?d?ric Darboux wrote:
> 
> Hello all.
> 
> I have just installed R version 1.6.1 for Windows on a XP machine.
> I would like to use R in batch mode. For this, I looked for Rcmd.exe,
> but did not find it.
> Any hint where it could be?
> (in version 1.4.1, it was in the bin directory...)
> 
> Fr?d?ric Darboux

You have to choose the option that installs the files for making
*source* packages as well - and Rcmd.exe will be in the bin directory.

Uwe Ligges



From p.dalgaard at biostat.ku.dk  Wed Jan  8 16:46:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Jan  8 16:46:04 2003
Subject: [R] Rcmd.exe in R 1.6.1 for windows?
In-Reply-To: <Pine.LNX.4.31.0301081527430.16172-100000@gannet.stats>
References: <Pine.LNX.4.31.0301081527430.16172-100000@gannet.stats>
Message-ID: <x24r8jzm05.fsf@biostat.ku.dk>

<ripley at stats.ox.ac.uk> writes:

> Same place.  Did you install with the options needed, that is
> `source packages' was ticked?

This seems to happen to people quite frequently.

Should we perhaps twiddle the defaults and/or change the wording in
the installer? It's very little extra baggage and there are usages not
really related to source packages (Rcmd BATCH, e.g.).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From frederic.jean at univ-brest.fr  Wed Jan  8 17:17:06 2003
From: frederic.jean at univ-brest.fr (Fred Jean)
Date: Wed Jan  8 17:17:06 2003
Subject: [R] plotting multivariate data and lm()
Message-ID: <200301081616.RAA26965@cassis-gw.univ-brest.fr>

Dear list,

I have a problem with plotting multivariate data and models. 
I suppose the answer is obvious for experienced users but I didn't find it
looking in usual documentation or in the mail archive...

Let's say I use a dataset like :

a <- sort(round(rnorm(90),3))
niv <- factor(c(rep('B',30), rep('E', 30), rep('H',30)),labels=c('B','E','H'))
cl3 <- factor(rep(sequence(1:3),15))
mat <- cbind(a,niv,cl3)

let's say I want a model like :
mod <- lm(a~niv*cl3)        #silly, just for example

I want to obtain a scatterplot of 'a' vs. 'cl3', taking into account the 
value of 'niv' so I use :
plot(a~as.integer(cl3), col=as.integer(niv))

NB : I don't use lm(a~cl3) because the output is a boxplot in this case.

Is there a simple way to obtain the 3 regression lines for the 3 levels 
of 'niv' on this scatterplot ?

I tried a solution using lines() or abline() and expressions with
mod$coefficients[n], but it becomes very complicated as the number
of levels and interactions increase.

Maybe my plotting method is totally wrong ?

Many thanks for taking time for a newbie.


-- 
C'est curieux chez les marins, ce besoin de faire des phrases (M.A.)
----------------------------------------------------
Fred JEAN - UMR CNRS 6539 / LEMAR
Univ. Bretagne Occidentale - Inst. Univ. Europ?en de la Mer
Place Nicolas Copernic F-29280 PLOUZANE
Pho:+33 (0)2 98 49 86 38 // Fax:+33 (0)2 98 49 86 45



From rpeng at stat.ucla.edu  Wed Jan  8 17:36:08 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed Jan  8 17:36:08 2003
Subject: [R] New package:  gpclib
Message-ID: <Pine.GSO.4.10.10301061914380.11148-100000@fisher.stat.ucla.edu>

I have just uploaded a package to CRAN called `gpclib' for clipping large
and complex polygons.  This package provides an R interface to Alan
Murta's very fast General Polygon Clipper library (written in C), which
has an optimized version of the Vatti algorithm. Not all features of
Murta's library are implemented -- right now you can do intersections,
differences, and unions.  There are also functions for reading/writing
from/to files and coercing between various data types.

For some more details about the package see
http://department.stat.ucla.edu/~rpeng/R/gpclib.

Please send any comments, complaints, and bug reports to
rpeng at stat.ucla.edu.

Here is the DESCRIPTION file for the package:

Package:  gpclib
Version:  1.0
Date:  1/6/2003
Depends:  R (>= 1.6.1)
Title:  General Polygon Clipping Library for R
Author:  R interface by Roger D. Peng <rpeng at stat.ucla.edu>; GPC library
	 by Alan Murta
Maintainer:  Roger D. Peng <rpeng at stat.ucla.edu>
Description:  General polygon clipping routines for R based on Alan
	      Murta's C library
License:  Code written by R. D. Peng is available under the LGPL; the C
	  code for the GPC library is free for non-commercial use (see the
	  files `gpc.c' and `gpc.h' for details)
URL:  http://department.stat.ucla.edu/~rpeng/R/gpclib;
      http://www.cs.man.ac.uk/aig/staff/alan/software

Happy clipping!

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng



From Paa.K.Nunoo at FMR.COM  Wed Jan  8 17:57:24 2003
From: Paa.K.Nunoo at FMR.COM (Nunoo, Paa K)
Date: Wed Jan  8 17:57:24 2003
Subject: [R] "methods" package changes class types?
Message-ID: <763C275E6A1C2248AFD475237AD6135B02DC5CD7@MSGBOS576NTS.fmr.com>

Hi,

Loading the "methods" package into R seems to change the class of a
character vector from NULL to "character":

> class("abcd")
NULL
> library("methods")
> class("abcd")
[1] "character"

This can lead to problems. For example the "as.string" function in the
"xtable" package 
assumes that the class of a character vector is NULL. However this changes
when the methods 
package is loaded.

Here is a code snippet of the as.string function in the xtable package:
> library(xtable)
> as.string
function (x, file = "", append = FALSE) 
{
    if (is.null(class(x))) 
        switch(data.class(x), character = return(string(x, file, 
            append)), numeric = return(string(as.character(x), 
            file, append)), stop("Cannot coerse argument to a string"))
    if (class(x) == "string") 
        return(x)
    stop("Cannot coerse argument to a string")
}

Why does the methods package change the class of character vectors?
Is there a way around this behavior?

Thanks,
PK



From drhosini at hotmail.com  Wed Jan  8 18:00:47 2003
From: drhosini at hotmail.com (Moustafa ElHousinie)
Date: Wed Jan  8 18:00:47 2003
Subject: [R] (no subject)
Message-ID: <F131N0vBJ4GfyzQ8Kgi00015abc@hotmail.com>

Dear Listers
This is not a straight R inquiry.  I am using R for quite a period and I 
wish to analyse a study with it. I am doing a survey of hepatitis C in a 
village.  Tha unit of sampling is the house (or the family living in that 
house), so when a house is chosen, all the members are tested for hepatitis 
C antigen and viremia.  How can I prove familial clustering of that 
infectious disease?  and how to adjust for that clustering in the logistic 
regression? Can these be done in R?? Any help from R experts will be 
appreciated and any reference will be of great value.
Thanks in advance.
Dr Mostafa El houssinie



From parkhurs at indiana.edu  Wed Jan  8 18:03:59 2003
From: parkhurs at indiana.edu (David Parkhurst)
Date: Wed Jan  8 18:03:59 2003
Subject: [R] parameter estimates from nls
Message-ID: <001301c2b736$eddfcf60$b7414842@spea.indiana.edu>

How can I get at the estimated parameter values from a non-linear model fitted by
nls in R, so as to plot the fitted curve?  If I have
f.t <- nls(f~a*exp(b*t), ...)
then type names(f.t), all that shows up is m for model, data, and call.  I don't see
how to get at a and b, other than to print them.

Thanks.

Dave Parkhurst (coming from splus to R)



From mmiller3 at iupui.edu  Wed Jan  8 18:18:02 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Wed Jan  8 18:18:02 2003
Subject: [R] parameter estimates from nls
In-Reply-To: <001301c2b736$eddfcf60$b7414842@spea.indiana.edu>
References: <001301c2b736$eddfcf60$b7414842@spea.indiana.edu>
Message-ID: <878yxvr27t.fsf@lumen.indyrad.iupui.edu>

>>>>> "David" == David Parkhurst <parkhurs at indiana.edu> writes:

    > How can I get at the estimated parameter values from a
    > non-linear model fitted by nls in R, so as to plot the
    > fitted curve?  If I have f.t <- nls(f~a*exp(b*t), ...)
    > then type names(f.t), all that shows up is m for model,
    > data, and call.  I don't see how to get at a and b, other
    > than to print them.

They can be gotten with a coef (or coefficients) call to the fit
result: coef(f.t)['a']

Mike



From ripley at stats.ox.ac.uk  Wed Jan  8 18:24:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan  8 18:24:03 2003
Subject: [R] "methods" package changes class types?
In-Reply-To: <763C275E6A1C2248AFD475237AD6135B02DC5CD7@MSGBOS576NTS.fmr.com>
Message-ID: <Pine.LNX.4.31.0301081717210.16534-100000@gannet.stats>

Well, the xtable package is at fault.  One really should not assume an
object has no class, and should only check inheritance.

That function should have

if(is.null(class(x))) class(x) <- data.class(x)
switch(class(x), ....)

On Wed, 8 Jan 2003, Nunoo, Paa K wrote:

> Hi,
>
> Loading the "methods" package into R seems to change the class of a
> character vector from NULL to "character":
>
> > class("abcd")
> NULL
> > library("methods")
> > class("abcd")
> [1] "character"
>
> This can lead to problems. For example the "as.string" function in the
> "xtable" package
> assumes that the class of a character vector is NULL. However this changes
> when the methods
> package is loaded.
>
> Here is a code snippet of the as.string function in the xtable package:
> > library(xtable)
> > as.string
> function (x, file = "", append = FALSE)
> {
>     if (is.null(class(x)))
>         switch(data.class(x), character = return(string(x, file,
>             append)), numeric = return(string(as.character(x),
>             file, append)), stop("Cannot coerse argument to a string"))
>     if (class(x) == "string")
>         return(x)
>     stop("Cannot coerse argument to a string")
                   ^^^^^^
(sic)

> }
>
> Why does the methods package change the class of character vectors?

Because it implements the Green Book (JMC, 1998) where every object has a
class.  It just ensures that: it does not change the class of objects
which already have a class (as far as I know).

> Is there a way around this behavior?

Don't use the methods package?  More seriously, write and use correct
code which handles classing properly.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From apjaworski at mmm.com  Wed Jan  8 18:28:03 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Wed Jan  8 18:28:03 2003
Subject: [R] lattice default theme
Message-ID: <OFB5BAE82D.17A7F2A6-ON86256CA8.005D9CFE@mmm.com>

I have a feeling that this was already discussed here, but I cannot
remember the outcome of the discussion.

I would like to have the col.whitebg theme as a default and I cannot figure
out how to do it.  Functions like lset or trellis.par.set require that the
device be active, so how does one set a different default for all
invocations of trellis.device?

Thanks in advance,

Andy


__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122



From apjaworski at mmm.com  Wed Jan  8 18:52:03 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Wed Jan  8 18:52:03 2003
Subject: [R] minor bug in lattice documentation?
Message-ID: <OFBD5D9898.CFD37B1E-ON86256CA8.00618ED1@mmm.com>

I have been going through Lattice documentation and I just noticed that at
the bottom of the panel.functions help page there was a link called
lowess.smooth pointing to .../library/modreg/html/loess.smooth.html.  This
file does not seem to exist in R-1.6.1 or in 1.7.0 (dev) - there are only
loess.html and loess.control.htlm.

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122



From ripley at stats.ox.ac.uk  Wed Jan  8 19:06:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan  8 19:06:03 2003
Subject: [R] minor bug in lattice documentation?
In-Reply-To: <OFBD5D9898.CFD37B1E-ON86256CA8.00618ED1@mmm.com>
Message-ID: <Pine.LNX.4.31.0301081803320.23724-100000@gannet.stats>

The original has \code{\link[modreg]{loess.smooth}}.  That should be
either \code{\link{loess.smooth}} or
\code{\link[modreg:scatter.smooth]{loess.smooth}}

On Wed, 8 Jan 2003 apjaworski at mmm.com wrote:

> I have been going through Lattice documentation and I just noticed that at
> the bottom of the panel.functions help page there was a link called
> lowess.smooth pointing to .../library/modreg/html/loess.smooth.html.  This
> file does not seem to exist in R-1.6.1 or in 1.7.0 (dev) - there are only
> loess.html and loess.control.htlm.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Wed Jan  8 20:04:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed Jan  8 20:04:03 2003
Subject: [R] parameter estimates from nls
In-Reply-To: <878yxvr27t.fsf@lumen.indyrad.iupui.edu>
References: <001301c2b736$eddfcf60$b7414842@spea.indiana.edu>
	<878yxvr27t.fsf@lumen.indyrad.iupui.edu>
Message-ID: <6ru1gjo458.fsf@bates4.stat.wisc.edu>

mmiller3 at iupui.edu (Michael A. Miller) writes:

> >>>>> "David" == David Parkhurst <parkhurs at indiana.edu> writes:
> 
>     > How can I get at the estimated parameter values from a
>     > non-linear model fitted by nls in R, so as to plot the
>     > fitted curve?  If I have f.t <- nls(f~a*exp(b*t), ...)
>     > then type names(f.t), all that shows up is m for model,
>     > data, and call.  I don't see how to get at a and b, other
>     > than to print them.
> 
> They can be gotten with a coef (or coefficients) call to the fit
> result: coef(f.t)['a']

Exactly - the general rule is to use the extractor functions like
coef() rather than relying on specific names in the fitted model
objects.  In this particular case you don't even need to extract the
fitted parameter values.  The easiest way to plot the fitted curve is
to use the predict method for the nls object as shown in the last part
of example(Puromycin)

Prmycn> conc <- seq(0, 1.2, len = 101)

Prmycn> lines(conc, predict(fm1, list(conc = conc)), lty = 1, 
    col = 1)

In your case just establish a vector of values of t, say tvals, then
use

plot(tvals, predict(f.t, list(t = tvals)))

or 

lines(tvals, predict(f.t, list(t = tvals)))



From jzhu at stanford.edu  Wed Jan  8 20:22:02 2003
From: jzhu at stanford.edu (Ji Zhu)
Date: Wed Jan  8 20:22:02 2003
Subject: [R] convex optimization
Message-ID: <MAECKJNMEMLCBDKPAPKLMEGLCAAA.jzhu@stanford.edu>

Dear R users,

Is there a convex optimizatin package for R?  Could any one kindly point me
to some reference?  Thanks a lot!

Regards,

-Ji



From ripley at stats.ox.ac.uk  Wed Jan  8 20:37:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan  8 20:37:02 2003
Subject: [R] convex optimization
In-Reply-To: <MAECKJNMEMLCBDKPAPKLMEGLCAAA.jzhu@stanford.edu>
Message-ID: <Pine.LNX.4.31.0301081933340.25113-100000@gannet.stats>

That is not a well-defined request, but optim() does general-nonlinear
optimization over box subsets, and r-devel (1.7.0 to be) has a new
function constrOptim for more general polygonal domains.

On Wed, 8 Jan 2003, Ji Zhu wrote:

> Is there a convex optimizatin package for R?  Could any one kindly point me
> to some reference?  Thanks a lot!

I think it is up to you to give a reference to what *you* have in mind
when asking for help.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jzhu at stanford.edu  Wed Jan  8 20:53:03 2003
From: jzhu at stanford.edu (Ji Zhu)
Date: Wed Jan  8 20:53:03 2003
Subject: [R] convex optimization
In-Reply-To: <Pine.LNX.4.31.0301081933340.25113-100000@gannet.stats>
Message-ID: <MAECKJNMEMLCBDKPAPKLMEGOCAAA.jzhu@stanford.edu>

Thank you for your immediate reply and pointing out the lackness of
preciseness in my previous email.  Really sorry about that.

What I have in mind is to minimize a continuous convex piece-wise quadratic
(including piece-wise linear) objection function under general linear
constraints.  Does optim() or r-devel handle such problem?  Thanks.

-Ji


> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Wednesday, January 08, 2003 11:37 AM
> To: Ji Zhu
> Cc: R-Help
> Subject: Re: [R] convex optimization
>
>
> That is not a well-defined request, but optim() does general-nonlinear
> optimization over box subsets, and r-devel (1.7.0 to be) has a new
> function constrOptim for more general polygonal domains.
>
> On Wed, 8 Jan 2003, Ji Zhu wrote:
>
> > Is there a convex optimizatin package for R?  Could any one
> kindly point me
> > to some reference?  Thanks a lot!
>
> I think it is up to you to give a reference to what *you* have in mind
> when asking for help.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From jeremybutler at paradise.net.nz  Thu Jan  9 00:51:02 2003
From: jeremybutler at paradise.net.nz (Jeremy Z Butler)
Date: Thu Jan  9 00:51:02 2003
Subject: [R] substitution list for graphs
Message-ID: <1042069810.3e1cb93222206@www.paradise.net.nz>

Hi,
Is there any facility in R to use text strings from a different object in a
graphical output. For example, I have a simple bargraph but instead of using the 
row names as the x axis labels I would rather use the text strings from a
different object (there are the same amount of text strings in that other object
as rows in the matrix used to create the barplot). 

I have to do this kind of operation in a number of different situations so I'm
wondering whether there is an elegant way to make a reference, within my
function, to the names in the other object, rather than simply replacing the row
names. In essence, I want to be able to tell R to substitute the row names for
the test strings in the other object when it constructs the graph.

Hope this makes sense,
Thanks for any help,
Jeremy



From PLauren at genelogic.com  Thu Jan  9 02:34:03 2003
From: PLauren at genelogic.com (PLauren@genelogic.com)
Date: Thu Jan  9 02:34:03 2003
Subject: [R] fft(x, inv=TRUE)
Message-ID: <OF04A734DC.7C7D4EF6-ON85256CA8.007A3CD1@genelogic.com>

I started out with a real vector b and then obtained its Fourier transform
thus
B<-fft(b)
When I did
F<-fft(B, inv=TRUE)
I expected that F would be the inverse FT of B but it still has imaginary
components.

Should the inverse FT not be purely real? Am I missing something?

Thanks,
Peter.



From ben at zoo.ufl.edu  Thu Jan  9 03:23:03 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Thu Jan  9 03:23:03 2003
Subject: [R] fft(x, inv=TRUE)
In-Reply-To: <OF04A734DC.7C7D4EF6-ON85256CA8.007A3CD1@genelogic.com>
Message-ID: <Pine.LNX.4.44.0301082126580.13569-100000@bolker.zoo.ufl.edu>

  I would guess that the imaginary parts are very small -- essentially 
numeric error.  I sometimes use the following function to get rid of these 
tiny, spurious imaginary parts.

chop <- function (x, fuzz = 1e-10) 
{
    if (is.numeric(x)) {
        x
    }
    else if (is.complex(x)) {
        ifelse(abs(Im(x)) < fuzz, Re(x), x)
    }
}


On Wed, 8 Jan 2003 PLauren at genelogic.com wrote:

> I started out with a real vector b and then obtained its Fourier transform
> thus
> B<-fft(b)
> When I did
> F<-fft(B, inv=TRUE)
> I expected that F would be the inverse FT of B but it still has imaginary
> components.
> 
> Should the inverse FT not be purely real? Am I missing something?
> 
> Thanks,
> Peter.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From jeanhee.chung at yale.edu  Thu Jan  9 07:09:03 2003
From: jeanhee.chung at yale.edu (J C)
Date: Thu Jan  9 07:09:03 2003
Subject: [R] pairs
In-Reply-To: <20030108173303.4995.96316.Mailman@hypatia.math.ethz.ch>
Message-ID: <4.1.20030109032512.0095be40@jc363.mail.yale.edu>

Hello, 

I'm fairly new to R so please excuse me if I am asking something obvious.
I have looked in the FAQ, Introduction, and help pages, and searched the
archives, but I don't know much about graphics yet.  

I'm running Red Hat Linux 2.14.18  on a machine blessed with dual 1.5 Xeon
processors and 3.7GB of RAM. I have a very large dataset with 27 variables,
and in exploring the data I want to take snapshots using pairs(). The lower
matrix and diagonal are filled with other graphics. (Please don't suggest
that I cut down the variable number! This is in fact the trimmed-down,
must-have set of variables.)

Of course, even with all that memory, I get a crash about 2/3 of the way
through. This is one of those cases where it's hard to troubleshoot since
everything works fine for small datasets.  It is tantalizing because the
process takes over two hours to display most of the figure before the
freeze happens.

However, it seems to me that the crash is more related to the kind of
graphics device that I'm using and the size of the device.For instance, if
I'm using X11 it crashes slower than using png, and right now I'm trying
bitmap to produce a png file (it hasn't crashed after a half hour now, but
there's always time for that later.)  The plot also gets further along if I
set a small area for the device, but of course then the plots are
ridiculously tiny and hard to interpret.  I have 729 little plots, and I'd
be satisfied if they were at least .75 inches on each side... about 21 in.
square altogether.

What can I do to increase the chances that I'll be able to produce a
viewable, printable image?
Suppose that bitmap works-- can I raise the resolution up from 72 without
fear? 
 
Thanks,
Jean



From ripley at stats.ox.ac.uk  Thu Jan  9 09:45:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu Jan  9 09:45:03 2003
Subject: [R] pairs
In-Reply-To: <4.1.20030109032512.0095be40@jc363.mail.yale.edu>
Message-ID: <Pine.GSO.4.31.0301090837480.2025-100000@toucan.stats>

Sounds like the problem is in your X server and not in R.  I've seen this
with Xfree (and don't use that myself on Linux).

1) I suggest you try a postscript() device, and convert later if you need
to.  Expect a very large file size.

2) Don't plot all the points.  You say you have a `very large dataset'. In
statistics, we give numbers, not vague descriptions.  However, with what
that means to me (many millions of rows) a scatterplot of a very large
dataset is going to be mainly black at least in places.  (We've
experienced that with 1.4 million points, for example.) That's not a good
way to display the data.  Either use a density plot, or if you are
interested in outliers, thin the centre.  We did this by estimating a
density phat, then randomly selecting points with probability min(1,
const/phat(x))  for a suitable `const'.

On Thu, 9 Jan 2003, J C wrote:

> Hello,
>
> I'm fairly new to R so please excuse me if I am asking something obvious.
> I have looked in the FAQ, Introduction, and help pages, and searched the
> archives, but I don't know much about graphics yet.
>
> I'm running Red Hat Linux 2.14.18  on a machine blessed with dual 1.5 Xeon
> processors and 3.7GB of RAM. I have a very large dataset with 27 variables,
> and in exploring the data I want to take snapshots using pairs(). The lower
> matrix and diagonal are filled with other graphics. (Please don't suggest
> that I cut down the variable number! This is in fact the trimmed-down,
> must-have set of variables.)
>
> Of course, even with all that memory, I get a crash about 2/3 of the way
> through. This is one of those cases where it's hard to troubleshoot since
> everything works fine for small datasets.  It is tantalizing because the
> process takes over two hours to display most of the figure before the
> freeze happens.
>
> However, it seems to me that the crash is more related to the kind of
> graphics device that I'm using and the size of the device.For instance, if
> I'm using X11 it crashes slower than using png, and right now I'm trying
> bitmap to produce a png file (it hasn't crashed after a half hour now, but
> there's always time for that later.)  The plot also gets further along if I
> set a small area for the device, but of course then the plots are
> ridiculously tiny and hard to interpret.  I have 729 little plots, and I'd
> be satisfied if they were at least .75 inches on each side... about 21 in.
> square altogether.
>
> What can I do to increase the chances that I'll be able to produce a
> viewable, printable image?
> Suppose that bitmap works-- can I raise the resolution up from 72 without
> fear?
>
> Thanks,
> Jean
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rkales at edu.uni-klu.ac.at  Thu Jan  9 09:51:21 2003
From: rkales at edu.uni-klu.ac.at (rkales@edu.uni-klu.ac.at)
Date: Thu Jan  9 09:51:21 2003
Subject: [R] GAM with Thin plate splines
Message-ID: <twig.1042102175.2422@edu.uni-klu.ac.at>

Hello, I'm a student at the University of Klagenfurt / Austria and I 
need some help !
I have to predict 24 daily load-values.
Therefor I got a dataset with following colums:
24 past daily load-values
6  past daily temperature-values

My goal is to find a model (GAM with thin plate splines) in R.
I found the function "gam" in the R-library "mgcv", but it just fits 
one-dimensial splines.

So my question is, either if it's possible to modify this function, if yes
how, or if there is another function that gives me a solution ?

Please send me a mail, if you can help me !
Thanks



From bhx2 at mevik.net  Thu Jan  9 10:06:05 2003
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge?= Mevik)
Date: Thu Jan  9 10:06:05 2003
Subject: [R] Generating .R and .Rd files with Sweave/noweb?
In-Reply-To: <3E1C715C.CAD9C792@bank-banque-canada.ca>
References: <7o8yxxvw8x.fsf@foo.nemo-project.org>
	<87of6s4vmi.fsf@jeeves.blindglobe.net>
	<3E1C715C.CAD9C792@bank-banque-canada.ca>
Message-ID: <7oznqawv4y.fsf@foo.nemo-project.org>

Paul

You're right.  My primary goal was to write all the code and
documentation in one file, and split this into one .R file and
multiple .Rd files.  I got the idea of using Sweave/noweb because I'm
using Emacs with ESS, and I'd like to be in R-mode when I'm in a code
part of the file, and in Rd-mode in a documentation part.  I guess
using two files and a shell script, as you do, might be the best
solution.

-- 
Bj?rn-Helge Mevik



From ernesto at ipimar.pt  Thu Jan  9 11:08:02 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu Jan  9 11:08:02 2003
Subject: [R] GAM with Thin plate splines
In-Reply-To: <twig.1042102175.2422@edu.uni-klu.ac.at>
References: <twig.1042102175.2422@edu.uni-klu.ac.at>
Message-ID: <1042106944.31779.12.camel@gandalf.ipimar.pt>

Hi

Im package gss there are functions for tps, see "ssanova".

Regards

EJ 

On Thu, 2003-01-09 at 08:49, rkales at edu.uni-klu.ac.at wrote:
> Hello, I'm a student at the University of Klagenfurt / Austria and I 
> need some help !
> I have to predict 24 daily load-values.
> Therefor I got a dataset with following colums:
> 24 past daily load-values
> 6  past daily temperature-values
> 
> My goal is to find a model (GAM with thin plate splines) in R.
> I found the function "gam" in the R-library "mgcv", but it just fits 
> one-dimensial splines.
> 
> So my question is, either if it's possible to modify this function, if yes
> how, or if there is another function that gives me a solution ?
> 
> Please send me a mail, if you can help me !
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
Research Institute for Agriculture and Fisheries
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948



From p.dalgaard at biostat.ku.dk  Thu Jan  9 11:55:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Jan  9 11:55:03 2003
Subject: [R] GAM with Thin plate splines
In-Reply-To: <1042106944.31779.12.camel@gandalf.ipimar.pt>
References: <twig.1042102175.2422@edu.uni-klu.ac.at>
	<1042106944.31779.12.camel@gandalf.ipimar.pt>
Message-ID: <x2vg0yr3sb.fsf@biostat.ku.dk>

Ernesto Jardim <ernesto at ipimar.pt> writes:

> Hi
> 
> Im package gss there are functions for tps, see "ssanova".

gam in mgcv fits thin plate splines, where was the problem???

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From maechler at stat.math.ethz.ch  Thu Jan  9 12:16:03 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Jan  9 12:16:03 2003
Subject: [R] axis() color from 1.5.1 to 1.6.1
In-Reply-To: <OFF77B37CE.815B9D37-ON85256CA7.007881BB@hgsi.com>
References: <OFF77B37CE.815B9D37-ON85256CA7.007881BB@hgsi.com>
Message-ID: <15901.22998.583432.74491@gargle.gargle.HOWL>

>>>>> "partha" == partha bagchi <partha_bagchi at hgsi.com>
>>>>>     on Tue, 7 Jan 2003 17:02:31 -0500 writes:

    partha> I see that the definition of axis() has changed from
    partha> 1.5.1 to 1.6.1 (as mentioned in the news file for
    partha> 1.6.0). Axis now has a color argument to change it's
    partha> color. However, the following command worked in 1.5.1:

    >> axis(1, at = c(0.1, 0.2, 1, 5, 10), fg= gray(0.7), cex.axis = 0.8, 
    >>      col.axis= "red") #plot the axis in gray with annotations in red.

(yes, "fg" worked, but this was not (explicitly) documented to work.
 I agree though that the "..." vagueness could have lead you to
 use "fg" --- and I think several people including the original
 R authors might have used axis() that way
)

    partha> The command no longer works in 1.6.1. 

(yes it does work; but differently than in 1.x (x <= 5), and not
 as you'd expected I agree.)

    partha> I am aware that using a col argument in axis would
    partha> work. However, this does break code written
    partha> currently (for 1.5.1) and thus the danger of code
    partha> being specific to the version of R that one is
    partha> using.

    partha> I am interested in knowing why it does not work.

short answer: ``because "col=" now works''.

I see that this is not entirely satisfying for you (and your
older code).  It was really a ``design bug'' that using "fg"
instead of "col" did work (and "col" didn't) in older versions of axis().

However, we could have done the change more back-compatibly,
e.g. still allowing "fg" as `alias' of "col" (when col is not specified)
and give a warning to have users change their code to the new
behavior.
I'm considering to apply this (R code) patch.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From Herbert_Desson at jltgroup.com  Thu Jan  9 13:20:03 2003
From: Herbert_Desson at jltgroup.com (Herbert_Desson@jltgroup.com)
Date: Thu Jan  9 13:20:03 2003
Subject: [R] Installing R-Excel Interface - Help requested (long)
Message-ID: <09253863F113D111A55200805F19B9350E43DF5B@SERVER3>

Dear All,
I have attempted to install the R-Excel Interface with poor results.  

The version of R is 1.6.1, the version of R-Excel is 1.0, the version of COM
is 0.99.  All of these were downloaded Monday, 6 January 2003.  R (version
1.6.1) is installed on the machine and appears to run correctly on its own. 

The computer is a Compaq Pentium 4 machine with 128 meg of RAM running
Windows 2000 and Excel 2000 (9.0.4402 SR-1).

After installing DCOM and the R-Excel Interface as per the instructions (I
believe), I get one of two errors upon attempting to invoke the R-Excel
interface within Excel.

	1.	If the Rserver box is ticked within Tools / Addins upon
launching Excel, I get  "invalid picture error (error 481)".  If I click OK
within the error dialog box it takes me to 
RserverVBAlib (Rserver.xla)
	Modules
		Rinterface

	and highlights the statement:
	Dim My_R As StatConnector

	2.	If I open Excel without the Rserver box ticked within Tools
/ Addins, Excel opens normally, but then when I tick the R Interface box
within Toos / Addins I get "error in loading DLL (error 48)".

The vbtest.exe utility seemed to run correctly after installing DCOM. 

Details of all the error messages and the vbtest output can be found below.

I would be most grateful if someone can show me how to make this work
properly.

Thank you for your help.

Best regards,
Herb

Herbert G. Desson, ACAS, MAAA

Actuary
Capital Risk Group
JLT Risk Solutions
6 Crutched Friars
London EC3N 2PH

phone:  +44 (0)20 7528 4702
fax:       +44 (0)20 7558 3785


If the Rserver box is ticked within Tools / Addins upon launching Excel, I
get "invalid picture error (error 481)".
Invalid picture (Error 481)

An invalid graphics format was assigned to the Picture property. This error
has the following cause and solution: 
	*	You tried to assign a graphics format other than a bitmap,
icon, or Windows metafile to the Picture property of a form or control. 
		Ensure that the file you are trying to load into the Picture
property is a valid graphics file supported by Visual Basic. 



	If I click OK within the error dialog box it takes me to 

	
RserverVBAlib (Rserver.xla)
	Modules
		Rinterface


and highlights the statement:
	Dim My_R As StatConnector


The entire beginning of Rinterface is below.

Option Base 1

Public Const RExcelVersion = "Version 0.73"

Dim myitem As Object

Dim FlatMenus As Boolean

Dim My_R As StatConnector





	If I open Excel without the Rserver box ticked within Tools /
Addins, Excel opens normally, but then when I tick the R Interface box
within Toos / Addins I get "error in loading DLL (error 48)".

	The entire error message is below.

Error in loading DLL (Error 48)
    
A dynamic link library (DLL) <JavaScript:hhobj_3.Click()> is a library
specified in the Lib clause of a Declare statement. This error has the
following causes and solutions: 
	*	The file isn't DLL-executable. 
		If the file is a source-text file, it must be compiled and
linked to DLL executable form. 
	*	The file isn't a Microsoft Windows DLL. 
		Obtain the Microsoft Windows DLL equivalent of the file. 
	*	The file is an early Microsoft Windows DLL that is
incompatible with Microsoft Windows protect mode. 
		Obtain an updated version of the DLL. 
	*	The DLL references another DLL that isn't present. 
		Obtain the referenced DLL and make it available to the other
DLL. 
	*	The DLL or one of the referenced DLLs isn't in a directory
specified by your path. 
		Move the DLL to a referenced directory or place its current
directory on the path. 
For additional information, select the item in question and press F1 (in
Windows) or HELP (on the Macintosh).




Selected sections of the output of the vbatest utility are below.


Loading StatConnector Server... Done
Initializing R...Done

Server information:
  Name:        COM Statistics Interpreter Interface
  Description: Connector beetween a client application (e.g. a spread-sheet)
and an interpreted language (e.g. R)
  Copyright:   (C) 1999-2001, Thomas Baier
  License:     GNU General Public License version 2 or greater
  Version:     0.99

Connector information:
  Name:        R
  Description: A Computer Language for Statistical Data Analysis
  Copyright:   (C) R Development Core Team
  License:     GNU General Public License version 2 or greater
  Version:     1.6.1

Interpreter information:
  Name:        R Statistics Interpreter Connector
  Description: Implements abstract connector interface to R
  Copyright:   (C) 1999-2001, Thomas Baier
  License:     GNU General Public License version 2 or greater
  Version:     1.0

Testing Evaluate
  creating variable... Done
Testing SetSymbol
  setting integer i1... Done
  setting double r1... Done
  setting string s1... Done
  setting integer array i3... Done
  setting double array r3... Done
  setting string array s3...   setting integer array i5... Done
  setting double array r5... Done
  setting string array s5... Done
Testing GetSymbol
  getting integer i1... Done (4)
  getting double r1... Done (3.14)
  getting string s1... Done (String 1)
  getting integer array i3... Done (5,...,1)
  getting double array r3... Done (1.25,...,6.25)
  getting string array s3... Done (Array1,Array2)
  getting multi-dim integer array i5... 
    i6(1,1,1) = 1, should be 1
    
<Snip>

    i6(3,5,7) = 105, should be 105
Done
  getting multi-dim double array r5... 
    r6(1,1,1) = 1,should be 1

<Snip>

    
    r6(6,3,8) = 2.25,should be 2.25
Done
  getting multi-dim string array s5... 
    s6(1,1,1) = 'String 1, 1, 1' ,should be 'String 1, 1, 1'
    
<Snip>

    s6(3,2,4) = 'String 3, 2, 4' ,should be 'String 3, 2, 4'
Done
Dumping R symbol space

<Snip>

Done
Shutting down R...Done
Releasing StatConnector Server...Done



************************************************************
JLT Risk Solutions Ltd
6 Crutched Friars, London EC3N 2PH. Co Reg No 1536540
Tel: (44) (0)20 7528 4000   Fax: (44) (0)20 7528 4500
http://www.jltgroup.com
Lloyd's Broker.  Regulated by the General Insurance
Standards Council
------------------------------------------------------------
The content of this e-mail (including any attachments) as 
received may not be the same as sent. If you consider that 
the content is material to the formation or performance of 
a contract or you are otherwise relying upon its accuracy, 
you should consider requesting a copy be sent by facsimile 
or normal mail.  The information in this e-mail is 
confidential and may be legally privileged. If you are not 
the intended recipient, please notify the sender immediately 
and then delete this e-mail entirely - you must not retain, 
copy, distribute or use this e-mail for any purpose or 
disclose any of its content to others.

Opinions, conclusions and other information in this e-mail 
that do not relate to the official business of JLT Risk 
Solutions Ltd shall be understood as neither given nor 
endorsed by it.  Please note we intercept and monitor 
incoming / outgoing e-mail and therefore you should neither 
expect nor intend any e-mail to be private in nature.

We have checked this e-mail for viruses and other harmful 
components and believe but not guarantee it virus-free prior 
to leaving our computer system.  However, you should satisfy 
yourself that it is free from harmful components, as we do 
not accept responsibility for any loss or damage it may 
cause to your computer systems.
************************************************************



From ernesto at ipimar.pt  Thu Jan  9 13:41:03 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu Jan  9 13:41:03 2003
Subject: [R] GAM with Thin plate splines
In-Reply-To: <x2vg0yr3sb.fsf@biostat.ku.dk>
References: <twig.1042102175.2422@edu.uni-klu.ac.at>
	 <1042106944.31779.12.camel@gandalf.ipimar.pt>
	 <x2vg0yr3sb.fsf@biostat.ku.dk>
Message-ID: <1042116102.1985.3.camel@gandalf.ipimar.pt>

Hi

Last time I worked with it (last year) there was no tps. And rkales is
not finding it also.

EJ

On Thu, 2003-01-09 at 10:55, Peter Dalgaard BSA wrote:
> Ernesto Jardim <ernesto at ipimar.pt> writes:
> 
> > Hi
> > 
> > Im package gss there are functions for tps, see "ssanova".
> 
> gam in mgcv fits thin plate splines, where was the problem???
-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
Research Institute for Agriculture and Fisheries
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948



From jesus.fernandez at eez.csic.es  Thu Jan  9 14:33:03 2003
From: jesus.fernandez at eez.csic.es (=?iso-8859-1?Q?Jes=FAs=20Fern=E1ndez=20G=E1lvez?=)
Date: Thu Jan  9 14:33:03 2003
Subject: [R] exporting graphs
Message-ID: <3E1D7BBE.48193801@eez.csic.es>

Dear all,

Could you please give me an idea of how to export graphs from R to a
word processor? I normally use Microsoft Word for writing but when
trying to put graphs from R on the documents the quality get very low. I

have tried both, copy and paste into Word (bitmap and metafile), and
save the graph (I have tried all different formats) and then import the
file into the text document, but the quality in both case is too low.
How can I keep the quality of my R graphs?
I am currently using R 1.6.1.

Many thanks,

Jesus
--
Jes?s Fern?ndez G?lvez
Dpto. Ciencias de la Tierra y Qu?mica Ambiental
Estaci?n Experimental del Zaid?n, CSIC
c/ Prof. Albareda 1; 18008 GRANADA, Spain
Tel:  958 181600
Fax: 958 129600



From ripley at stats.ox.ac.uk  Thu Jan  9 14:49:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan  9 14:49:03 2003
Subject: [R] exporting graphs
In-Reply-To: <3E1D7BBE.48193801@eez.csic.es>
Message-ID: <Pine.LNX.4.31.0301091345420.3262-100000@gannet.stats>

I suspect the problem is with Word, not R.  Exporting as a metafile (or
even cut-and-paste) and including in Word works well *provided* your
printer is capable of high quality (e.g. a postscript printer).

Avoid the bitmap options, and use wmf, postscript or pdf for inclusion in
other documents.

On Thu, 9 Jan 2003, [iso-8859-1] Jesús Fernández Gálvez wrote:

> Could you please give me an idea of how to export graphs from R to a
> word processor? I normally use Microsoft Word for writing but when
> trying to put graphs from R on the documents the quality get very low. I
>
> have tried both, copy and paste into Word (bitmap and metafile), and
> save the graph (I have tried all different formats) and then import the
> file into the text document, but the quality in both case is too low.
> How can I keep the quality of my R graphs?
> I am currently using R 1.6.1.

On Windows, evidently!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at medanalytics.com  Thu Jan  9 15:17:02 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu Jan  9 15:17:02 2003
Subject: [R] exporting graphs
In-Reply-To: <3E1D7BBE.48193801@eez.csic.es>
References: <3E1D7BBE.48193801@eez.csic.es>
Message-ID: <3E1D8425.3030904@MedAnalytics.com>

Jes?s Fern?ndez G?lvez wrote:
> Dear all,
> 
> Could you please give me an idea of how to export graphs from R to a
> word processor? I normally use Microsoft Word for writing but when
> trying to put graphs from R on the documents the quality get very low. I
> 
> have tried both, copy and paste into Word (bitmap and metafile), and
> save the graph (I have tried all different formats) and then import the
> file into the text document, but the quality in both case is too low.
> How can I keep the quality of my R graphs?
> I am currently using R 1.6.1.
> 
> Many thanks,
> 
> Jesus

I have had consistent success in copying R graphics as a metafile (right 
mouse click over the plot window) and pasting into both Word and Power 
Point when under Windows XP.  I use R 1.6.1 under both Windows and RH 8.

The bitmap option of course tends to not resize well if you need to do 
this in your document, so the metafile format tends to be a better choice.

When you say that the quality is low, are you referring to what you see 
on the screen or what you get from a printer as output?

If the latter, you may need a better printer.

I use an Okidata 7400n color LED, which does 1200 x 1200 and get great 
results when printing R graphics under both Windows and Linux configured 
as a PostScript device.

Not sure if that helps, but I can vouch for getting high quality 
graphics from R.

Regards,

Marc Schwartz



From simon at stats.gla.ac.uk  Thu Jan  9 15:32:03 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Thu Jan  9 15:32:03 2003
Subject: [R] GAM with Thin plate splines
In-Reply-To: <twig.1042102175.2422@edu.uni-klu.ac.at>
Message-ID: <Pine.SOL.3.96.1030109142625.18377A-100000@moon.stats.gla.ac.uk>

> My goal is to find a model (GAM with thin plate splines) in R.
> I found the function "gam" in the R-library "mgcv", but it just fits 
> one-dimensial splines.
- Unless you have an exceedingly ancient version of mgcv (<0.6), it
*does* allow spline smooths of more than one variable. ?gam contains a
couple of examples as does ?gam.side.conditions. 
Simon



From simon at stats.gla.ac.uk  Thu Jan  9 15:42:02 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Thu Jan  9 15:42:02 2003
Subject: [R] GAM with Thin plate splines
In-Reply-To: <1042116102.1985.3.camel@gandalf.ipimar.pt>
Message-ID: <Pine.SOL.3.96.1030109143704.18377B-100000@moon.stats.gla.ac.uk>

The default basis for smooth terms in mgcv is a truncated thin plate
spline basis, and has been since the later part of 2001. Including terms
like `s(x,z)', `s(x0,x1,x2)' in the model formula is the way to include
such terms (see help files, and examples therin). 
best, Simon

> Last time I worked with it (last year) there was no tps. And rkales is
> not finding it also.
> 
> EJ
> 
> On Thu, 2003-01-09 at 10:55, Peter Dalgaard BSA wrote:
> > Ernesto Jardim <ernesto at ipimar.pt> writes:
> > 
> > > Hi
> > > 
> > > Im package gss there are functions for tps, see "ssanova".
> > 
> > gam in mgcv fits thin plate splines, where was the problem???
> -- 
> Ernesto Jardim <ernesto at ipimar.pt>
> Marine Biologist
> Research Institute for Agriculture and Fisheries
> Lisboa, Portugal
> Tel: +351 213 027 000
> Fax: +351 213 015 948
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Bernhard.Pfaff at drkw.com  Thu Jan  9 16:23:03 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Thu Jan  9 16:23:03 2003
Subject: [R] Elements of a character vector in different colours?
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9001CAE155@ibfftce505.is.de.dresdnerkb.com>

Dear R-List,

is it possible to format elements of a character vector in different colors
and how would this be achieved?

Problem:
Suppose, you have a model for forecasting purposes. Beside the forecast
[variable: 'forecast' in the example below] a forecast interval is also
computed [variable: 'int' in the example below. The forecast should now be
translated in verbal terms if the forecast interval is below or above a
certain threshold value [in the example below, this value is set to 50]. 
After evaluation the object text should be formatted in either "green", or
"red", or "black".
 
outcome <- c("positive","negative","neutral")
forecast <- 60
int <- c(55,65)
#
text <- outcome[3]
text[forecast > 50 & int[1] > 50] <- outcome[1]
text[forecast < 50 & int[2] < 50] <- outcome[2]
text

I tried the following

outcome <- c("positive","negative","neutral")[col=c("green","red","black"]

without success, i.e. three times "na" formatted in green is returned. I did
also check the former help-emails without finding any pointers to solve my
problem.
As a side note: the object 'text' will be used in the supplementary package
R2HTML. I want to avoid programming the conditional colouring with ASP by
reading in an ascii-file that holds the value of 'text' and hence not using
R2HTML at all.

R: 1.61
OS: Windows NT
i386

Any help or hints are warmly appreciated.

Bernhard




----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------



From tord.snall at ebc.uu.se  Thu Jan  9 17:27:03 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Thu Jan  9 17:27:03 2003
Subject: [R] aggregate() nlevels()
Message-ID: <3.0.6.32.20030109172057.00afacc0@mail.anst.uu.se>

Dear all,

I try to calculate the number of occurring levels, per ObjektID, of
cpy.busk$TradArt,
but this line returns the TOTAL number of levels occurring in
cpy.busk$TradArt for each ObjektID. 

This was difficult to say in English! Did you get it?

Is there any function for doing what I want. I have tried searching the
archives without success.

buskartant<- aggregate(list(buskartant = cpy.busk$TradArt), list(ObjektID =
cpy.busk$ObjektID), nlevels)


Thanks in advance!

Sincerely,
Tord

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From deepayan at stat.wisc.edu  Thu Jan  9 17:55:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu Jan  9 17:55:03 2003
Subject: [R] lattice default theme
In-Reply-To: <OFB5BAE82D.17A7F2A6-ON86256CA8.005D9CFE@mmm.com>
References: <OFB5BAE82D.17A7F2A6-ON86256CA8.005D9CFE@mmm.com>
Message-ID: <200301091055.00194.deepayan@stat.wisc.edu>

On Wednesday 08 January 2003 11:27 am, apjaworski at mmm.com wrote:
> I have a feeling that this was already discussed here, but I cannot
> remember the outcome of the discussion.
>
> I would like to have the col.whitebg theme as a default and I cannot figure
> out how to do it.  Functions like lset or trellis.par.set require that the
> device be active, so how does one set a different default for all
> invocations of trellis.device?

No good way that I can think of, other than replacing all calls to 
trellis.device() by trellis.device(theme = col.whitebg()).

A hack is perhaps possible, which involves the global variable lattice.theme, 
which stores the settings. If you have that variable in your global 
environment (as part of your saved workspace, for example) with components 
for all the devices you want to use, lattice will use it. This will work if 
you start devices with x11(), postscript() etc. Unfortunately, any call to 
trellis.device() to start a new device will overwrite this unless retain = 
TRUE is specified. This includes the default invocation when print.trellis is 
called without any device open. 

Deepayan



From calza at med.unibs.it  Thu Jan  9 18:49:05 2003
From: calza at med.unibs.it (Stefano Calza)
Date: Thu Jan  9 18:49:05 2003
Subject: [R] Maps in R
In-Reply-To: <1042025170.729.8.camel@chomsky>
Message-ID: <3E1DC45B.21489.66385D@localhost>

Hi,
is anyone aware of a website where I can download the italian maps for free?

TIA,

Stefano

> Hi,
> 
> There a package called RArcInfo (which I've written) which can import
> data maps in ESRI E00 files and Arc/Info V 7.x binary coverages.
> Besides, it provides several functions to plot maps. One of them allows
> polygons to be filled with different colors.
> 
> Please, visit http://matheron.uv.es/~virgil/Rpackages/RArcInfo and take
> a look at the draft tutorial and to the screenshots.
> 
> By the way, I think you can get all the US states maps for free in E00
> format from the web of the Census (www.census.gov).
> 
> Hope this helps. Regards,
> 
> -- 
>              Virgilio G?mez Rubio
> 
> Dpto. Estad?stica e I. O. - Facultat de Matem?tiques
> Avda. Vicent A. Estell?s, 1 - 46100 Burjassot
> Valencia - SPAIN
> 
> http://matheron.uv.es/~virgil
> 
> TLF: 00 34 96 354 43 62 - FAX: 00 34 96 354 47 35
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help


Stefano Calza
Sezione di Statistica Medica
Dip. di Scienze Biomediche e Biotecnologie
Universit? degli Studi di Brescia- Italy
Via Valsabbina, 19 25100 BRESCIA
email: calza at med.unibs.it
           stefano.calza at unimi.it
Telefono/Phone: +390303717532
Fax: +390303701157



From edwardeb at unos.org  Thu Jan  9 19:13:02 2003
From: edwardeb at unos.org (Erick Edwards)
Date: Thu Jan  9 19:13:02 2003
Subject: [R] Access to R from a remote location
Message-ID: <8469235A83CC5C49907B3F75303F96BE0FB8B8@EXCHANGE1.Corp.Unos.Local>

Currently, our organization grants some employees remote access to SAS
and other software through a secure Citrix-based network server.  We
would like to install R on a dedicated network server and enable remote
access through Citrix.  Is this possible?  If so, what additional
software would we need?  Any advice would be greatly appreciated.

Erick Edwards



From baron at cattell.psych.upenn.edu  Thu Jan  9 19:18:03 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Thu Jan  9 19:18:03 2003
Subject: [R] Access to R from a remote location
In-Reply-To: <8469235A83CC5C49907B3F75303F96BE0FB8B8@EXCHANGE1.Corp.Unos.Local>; from edwardeb@unos.org on Thu, Jan 09, 2003 at 01:12:48PM -0500
References: <8469235A83CC5C49907B3F75303F96BE0FB8B8@EXCHANGE1.Corp.Unos.Local>
Message-ID: <20030109131741.A12660@cattell.psych.upenn.edu>

On 01/09/03 13:12, Erick Edwards wrote:
>Currently, our organization grants some employees remote access to SAS
>and other software through a secure Citrix-based network server.  We
>would like to install R on a dedicated network server and enable remote
>access through Citrix.  Is this possible?  If so, what additional
>software would we need?  Any advice would be greatly appreciated.

I don't know about Citrix, but I have had success running R with
VNC (http://realvnc.com).  Of course, since R is free, everyone
who uses it can install it.  But for occasional users, like
students doing an assignment, this works well.  Jon

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From rossini at blindglobe.net  Thu Jan  9 19:31:03 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu Jan  9 19:31:03 2003
Subject: [R] Access to R from a remote location
In-Reply-To: <8469235A83CC5C49907B3F75303F96BE0FB8B8@EXCHANGE1.Corp.Unos.Local> ("Erick
 Edwards"'s message of "Thu, 9 Jan 2003 13:12:48 -0500")
References: <8469235A83CC5C49907B3F75303F96BE0FB8B8@EXCHANGE1.Corp.Unos.Local>
Message-ID: <87bs2q5gcc.fsf@jeeves.blindglobe.net>

>>>>> "erick" == Erick Edwards <edwardeb at unos.org> writes:

    erick> Currently, our organization grants some employees remote access to SAS
    erick> and other software through a secure Citrix-based network server.  We
    erick> would like to install R on a dedicated network server and enable remote
    erick> access through Citrix.  Is this possible?  If so, what additional
    erick> software would we need?  Any advice would be greatly appreciated.

Should be simple.  

No licensing for R, and I'm assuming you mean the Citrix metaframe
"winterm" product on top of Terminal Server (i.e. use RDP (remote
desktop protocol) with rdesktop, winterms, or similar clients).

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From pgilbert at bank-banque-canada.ca  Thu Jan  9 19:55:03 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu Jan  9 19:55:03 2003
Subject: [R] Access to R from a remote location
References: <8469235A83CC5C49907B3F75303F96BE0FB8B8@EXCHANGE1.Corp.Unos.Local>
Message-ID: <3E1DC446.63F33384@bank-banque-canada.ca>

Erick Edwards wrote:
> 
> Currently, our organization grants some employees remote access to SAS
> and other software through a secure Citrix-based network server.  We
> would like to install R on a dedicated network server and enable remote
> access through Citrix.  Is this possible?  If so, what additional
> software would we need?  Any advice would be greatly appreciated.
> 
> Erick Edwards

Yes it is possible, I do it often (from a Windows based Citrix client to
a Unix based Citrix server). I don't think you need anything extra. 

Paul Gilbert



From yanyu at lecs.cs.ucla.edu  Thu Jan  9 21:52:03 2003
From: yanyu at lecs.cs.ucla.edu (Yan Yu)
Date: Thu Jan  9 21:52:03 2003
Subject: [R] using arima() function
Message-ID: <Pine.LNX.4.44.0301091249550.31439-100000@wren.lecs.cs.ucla.edu>

HI, there, 
     When i use R, i tried to use function arima(), it complains:
Error: couldn't find function "arima"

But when I type "help.search("arima") ",
I got arima() poped up..

arima(ts)               ARIMA Modelling of Time Series
arima.sim(ts)           Simulate from an ARIMA Model
arima0(ts)              ARIMA Modelling of Time Series -- Preliminary
                        Version

Do i need to include some path? 
THANKS a lot for any hints!
yan



From sundar.dorai-raj at pdf.com  Thu Jan  9 22:01:10 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu Jan  9 22:01:10 2003
Subject: [R] using arima() function
References: <Pine.LNX.4.44.0301091249550.31439-100000@wren.lecs.cs.ucla.edu>
Message-ID: <3E1DE21C.70508@pdf.com>

Hi Yan,

Yan Yu wrote:
> HI, there, 
>      When i use R, i tried to use function arima(), it complains:
> Error: couldn't find function "arima"
> 
> But when I type "help.search("arima") ",
> I got arima() poped up..
> 
> arima(ts)               ARIMA Modelling of Time Series
> arima.sim(ts)           Simulate from an ARIMA Model
> arima0(ts)              ARIMA Modelling of Time Series -- Preliminary
>                         Version
> 
> Do i need to include some path? 

Try library(ts) before calling arima.

Regards,
Sundar



From ripley at stats.ox.ac.uk  Thu Jan  9 22:05:07 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan  9 22:05:07 2003
Subject: [R] using arima() function
In-Reply-To: <Pine.LNX.4.44.0301091249550.31439-100000@wren.lecs.cs.ucla.edu>
Message-ID: <Pine.LNX.4.31.0301092100540.30409-100000@gannet.stats>

library(ts) is needed.

On Thu, 9 Jan 2003, Yan Yu wrote:

> HI, there,
>      When i use R, i tried to use function arima(), it complains:
> Error: couldn't find function "arima"
>
> But when I type "help.search("arima") ",
> I got arima() poped up..
>
> arima(ts)               ARIMA Modelling of Time Series
> arima.sim(ts)           Simulate from an ARIMA Model
> arima0(ts)              ARIMA Modelling of Time Series -- Preliminary
>                         Version
>
> Do i need to include some path?
> THANKS a lot for any hints!
> yan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From a296180 at arbres1a.fmr.com  Thu Jan  9 22:08:15 2003
From: a296180 at arbres1a.fmr.com (David Kane  <David Kane)
Date: Thu Jan  9 22:08:15 2003
Subject: [R] Warnings with no INDEX file in a package.
Message-ID: <15901.58128.106565.628205@gargle.gargle.HOWL>

In previous versions of R (at least in 1.5.1, I think), my practice was not to
include an INDEX file in the package. R CMD check did not complain and an INDEX
was created for me when I use R CMD build.

At least, this is how I remember it. I thought that this was a good way to
behave since it ensured that my INDEX was automatically kept up to date by R,
without me having to worry about what functions I had added to the package. I
can understand why other people might want to maintain an INDEX themselves
(mainly because it allows one to avoid listing functions that aren't that
interesting and/or are meant for internal use by the package only).

In 1.6.1, however, runing R CMD check on a package with no INDEX gives me:

* checking index files ... WARNING
The following index files are missing or have zero length:
  INDEX
See the information on INDEX files and package subdirectories in section
'Creating R packages' of the 'Writing R Extensions' manual.
* checking R files for syntax errors ... OK

I have read the suggested sections of the manual. It would seem to me that I
should be able to continue to follow my prior practice by turning off the
warning for missing INDEX. Certainly, the fact that R CMD build creates an
INDEX for you if one is not present would suggest that this is an acceptable
practice.

Or am I missing something? I just hate to ignore a warning each time I build a
package . . .

Thanks,

Dave Kane

> R.version
         _                   
platform sparc-sun-solaris2.6
arch     sparc               
os       solaris2.6          
system   sparc, solaris2.6   
status                       
major    1                   
minor    6.1                 
year     2002                
month    11                  
day      01                  
language R                   
> 

-- 
David Kane
Geode Capital Management
617-563-0122
david.d.kane at fmr.com
Please avoid sending me Word or PowerPoint attachments.
See http://www.fsf.org/philosophy/no-word-attachments.html



From h95mr at mun.ca  Thu Jan  9 22:11:25 2003
From: h95mr at mun.ca (Martin Renner)
Date: Thu Jan  9 22:11:25 2003
Subject: [R] Access to R from a remote location - follow up
In-Reply-To: 
 <8469235A83CC5C49907B3F75303F96BE0FB8B8@EXCHANGE1.Corp.Unos.Local>
References: 
 <8469235A83CC5C49907B3F75303F96BE0FB8B8@EXCHANGE1.Corp.Unos.Local>
Message-ID: <p05200f0fba4391bdd301@[192.168.2.16]>

Following up on Erick's post, does anybody know whether it is 
possible to start a lengthy batch-job in R, then log-out/break a 
dial-up connection (while R is still running) and later pick-up the R 
outfile?

Martin Renner


At 1:12 PM -0500 1/9/03, Erick Edwards wrote:
>Currently, our organization grants some employees remote access to SAS
>and other software through a secure Citrix-based network server.  We
>would like to install R on a dedicated network server and enable remote
>access through Citrix.  Is this possible?  If so, what additional
>software would we need?  Any advice would be greatly appreciated.
>
>Erick Edwards
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jgentry at jimmy.harvard.edu  Thu Jan  9 22:15:16 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu Jan  9 22:15:16 2003
Subject: [R] Warnings with no INDEX file in a package.
In-Reply-To: <15901.58128.106565.628205@gargle.gargle.HOWL>
Message-ID: <Pine.SOL.4.20.0301091610520.10681-100000@santiam.dfci.harvard.edu>

On Thu, 9 Jan 2003, David Kane  <David Kane wrote:
> I have read the suggested sections of the manual. It would seem to me that I
> should be able to continue to follow my prior practice by turning off the
> warning for missing INDEX. Certainly, the fact that R CMD build creates an
> INDEX for you if one is not present would suggest that this is an acceptable
> practice.
> Or am I missing something? I just hate to ignore a warning each time I build a
> package . . .

R CMD build --force <pkg> should build all of the appropriate index files
for you.

-J



From mmiller3 at iupui.edu  Thu Jan  9 22:49:03 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Thu Jan  9 22:49:03 2003
Subject: [R] Access to R from a remote location - follow up
In-Reply-To: <p05200f0fba4391bdd301@[192.168.2.16]>
References: <8469235A83CC5C49907B3F75303F96BE0FB8B8@EXCHANGE1.Corp.Unos.Local>
	<p05200f0fba4391bdd301@[192.168.2.16]>
Message-ID: <878yxunget.fsf@lumen.indyrad.iupui.edu>

>>>>> "Martin" == Martin Renner <h95mr at mun.ca> writes:

    > Following up on Erick's post, does anybody know whether it
    > is possible to start a lengthy batch-job in R, then
    > log-out/break a dial-up connection (while R is still
    > running) and later pick-up the R outfile?

I have regular jobs that I run with scripts like this:

R --no-save > normalization_stats.log <<EOF 
source('normalization_stats.R',echo=T)
EOF

R output goes to the log file and, if you use --save instead of
--no-save, an .Rdata file will be saved and you could look at
that in the morning, or after coffee, or whenever.

Mike



From jasont at indigoindustrial.co.nz  Thu Jan  9 22:53:03 2003
From: jasont at indigoindustrial.co.nz (jasont@indigoindustrial.co.nz)
Date: Thu Jan  9 22:53:03 2003
Subject: [R] Elements of a character vector in different colours?
Message-ID: <E18WkXl-0002FU-00@grunt4.ihug.co.nz>

> is it possible to format elements of a character vector in different colors
> and how would this be achieved?

On graphs, with the text() command.  Colour isn't an inherient property
of a character vector.

..

> outcome <- c("positive","negative","neutral")
> forecast <- 60
> int <- c(55,65)
> #
> text <- outcome[3]
> text[forecast > 50 & int[1] > 50] <- outcome[1]
> text[forecast < 50 & int[2] < 50] <- outcome[2]
> text

By the way, it's a good idea to check if your variable names conflict 
with function names - after you've done the above, try 

> conflicts(text)

> I tried the following
> 
> outcome <- c("positive","negative","neutral")[col=c("green","red","black"]
> 
> without success, i.e. three times "na" formatted in green is returned.

Nope.  A syntax error is returned.  Cut-and-paste error?  ;)

I think you'll find the word "green" in the above, and the colour green
in the NA printout is a coincidence.  Try for yourself, and use "purple", 
or "volvo", or "fish" instead of "green".

Looks like you're a bit shaky on R's vector indexing syntax, and what 
that means.

Text in R is just a vector of characters - there is no formatting, font,
colour, weight, or hyperlink information stored in it.  If you want to supply
colour information, you'll have to provide it some other way.  I've never
used R2HTML, so I can't help you there.

Hope that clears a few things up.

Jason



From rpeng at stat.ucla.edu  Thu Jan  9 23:15:05 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu Jan  9 23:15:05 2003
Subject: [R] Access to R from a remote location - follow up
In-Reply-To: <p05200f0fba4391bdd301@[192.168.2.16]>
Message-ID: <Pine.GSO.4.10.10301091410560.18811-100000@fisher.stat.ucla.edu>

This is possible because I've done it many times.  But I think whether or
not your job gets killed when you log out depends on your shell/operating
system.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Thu, 9 Jan 2003, Martin Renner wrote:

> Following up on Erick's post, does anybody know whether it is 
> possible to start a lengthy batch-job in R, then log-out/break a 
> dial-up connection (while R is still running) and later pick-up the R 
> outfile?
> 
> Martin Renner
> 
> 
> At 1:12 PM -0500 1/9/03, Erick Edwards wrote:
> >Currently, our organization grants some employees remote access to SAS
> >and other software through a secure Citrix-based network server.  We
> >would like to install R on a dedicated network server and enable remote
> >access through Citrix.  Is this possible?  If so, what additional
> >software would we need?  Any advice would be greatly appreciated.
> >
> >Erick Edwards
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From stormplot at hotmail.com  Fri Jan 10 01:07:03 2003
From: stormplot at hotmail.com (Jason Fisher)
Date: Fri Jan 10 01:07:03 2003
Subject: [R] tclVar Question
Message-ID: <F180ZX15eUy7yUZyvjn0002a66f@hotmail.com>

Hi All...

In an attempt to read data from a file and feed it into a tcltk entry box, 
I've run into difficulties.  The following hopefully describes my dilemma:

tclvalue(x.var) <- 5
Works fine.

tclvalue("x.var") <- 5
Does not work.  [Error: Target of assignment expands to non-language object]

tclvalue(eval(parse(text="x.var"))) <- 5
Also, does not work.

Any ideas on how to get this to work?

Thanks in advance!

J

***************************************
Jason C. Fisher
UCLA Graduate Student
Civil & Environmental Engineering Dept.
5731 Boelter Hall
Box 951593
Los Angeles, CA 90095-1593
Phone Number: (310) 825-2292
Email: stormplot at hotmail.com
***************************************



From yanyu at cs.ucla.edu  Fri Jan 10 01:19:02 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Fri Jan 10 01:19:02 2003
Subject: [R] using arima() function
In-Reply-To: <Pine.LNX.4.31.0301092100540.30409-100000@gannet.stats>
Message-ID: <Pine.SOL.4.33.0301091617220.25811-100000@panther.cs.ucla.edu>

Thank you all for the info.
It works:)
yan

On Thu, 9 Jan 2003 ripley at stats.ox.ac.uk wrote:

> library(ts) is needed.
>
> On Thu, 9 Jan 2003, Yan Yu wrote:
>
> > HI, there,
> >      When i use R, i tried to use function arima(), it complains:
> > Error: couldn't find function "arima"
> >
> > But when I type "help.search("arima") ",
> > I got arima() poped up..
> >
> > arima(ts)               ARIMA Modelling of Time Series
> > arima.sim(ts)           Simulate from an ARIMA Model
> > arima0(ts)              ARIMA Modelling of Time Series -- Preliminary
> >                         Version
> >
> > Do i need to include some path?
> > THANKS a lot for any hints!
> > yan
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>



From hb at maths.lth.se  Fri Jan 10 01:28:02 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri Jan 10 01:28:02 2003
Subject: [R] Warnings with no INDEX file in a package.
In-Reply-To: <15901.58128.106565.628205@gargle.gargle.HOWL>
Message-ID: <001901c2b83f$04af4140$7341a8c0@alpha.wehi.edu.au>

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of David 
> Kane <David Kane
> Sent: den 10 januari 2003 08:01
> To: r-help at stat.math.ethz.ch
> Subject: [R] Warnings with no INDEX file in a package.
> 
> 
> In previous versions of R (at least in 1.5.1, I think), my 
> practice was not to include an INDEX file in the package. R 
> CMD check did not complain and an INDEX was created for me 
> when I use R CMD build.
> 
> At least, this is how I remember it. I thought that this was 
> a good way to behave since it ensured that my INDEX was 
> automatically kept up to date by R, without me having to 
> worry about what functions I had added to the package. I can 
> understand why other people might want to maintain an INDEX 
> themselves (mainly because it allows one to avoid listing 
> functions that aren't that interesting and/or are meant for 
> internal use by the package only).

Just a comment: To make a function "private/hidden" in the table of
contents pages, but still existing, add "\keyword{internal}" to the Rd
file. From Writing R Extensions:

"The special keyword internal marks a page of internal objects that are
not part of the packages' API. If the help page for object foo has
keyword internal, then help(foo) gives this help page, but foo is
excluded from several object indices, like the alphabetical list of
objects in the HTML help system."

Using this is much better than doing something like \title{Internal
function}. Note that "\keyword{internal}" functions will still show up
in the INDEX file, but most people tend to look at the HTML ToC
(00Index.html) by running help.start() and there it will be excluded.

> In 1.6.1, however, runing R CMD check on a package with no 
> INDEX gives me:
> 
> * checking index files ... WARNING
> The following index files are missing or have zero length:
>   INDEX
> See the information on INDEX files and package subdirectories 
> in section 'Creating R packages' of the 'Writing R Extensions' manual.
> * checking R files for syntax errors ... OK
> 
> I have read the suggested sections of the manual. It would 
> seem to me that I should be able to continue to follow my 
> prior practice by turning off the warning for missing INDEX. 
> Certainly, the fact that R CMD build creates an INDEX for you 
> if one is not present would suggest that this is an 
> acceptable practice.
> 
> Or am I missing something? I just hate to ignore a warning 
> each time I build a package . . .
> 
> Thanks,
> 
> Dave Kane
> 
> > R.version
>          _                   
> platform sparc-sun-solaris2.6
> arch     sparc               
> os       solaris2.6          
> system   sparc, solaris2.6   
> status                       
> major    1                   
> minor    6.1                 
> year     2002                
> month    11                  
> day      01                  
> language R                   
> > 
> 
> -- 
> David Kane
> Geode Capital Management
> 617-563-0122
> david.d.kane at fmr.com
> Please avoid sending me Word or PowerPoint attachments.
> See http://www.fsf.org/philosophy/no-word-attachments.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From p.dalgaard at biostat.ku.dk  Fri Jan 10 01:46:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 10 01:46:03 2003
Subject: [R] tclVar Question
In-Reply-To: <F180ZX15eUy7yUZyvjn0002a66f@hotmail.com>
References: <F180ZX15eUy7yUZyvjn0002a66f@hotmail.com>
Message-ID: <x2fzs196ib.fsf@biostat.ku.dk>

"Jason Fisher" <stormplot at hotmail.com> writes:

> Hi All...
> 
> In an attempt to read data from a file and feed it into a tcltk entry
> box, I've run into difficulties.  The following hopefully describes my
> dilemma:
> 
> tclvalue(x.var) <- 5
> Works fine.
> 
> tclvalue("x.var") <- 5
> Does not work.  [Error: Target of assignment expands to non-language object]
> 
> tclvalue(eval(parse(text="x.var"))) <- 5
> Also, does not work.
> 
> Any ideas on how to get this to work?

Um, getting what to work? I see two interpretations: 

If you want to assign to a variable with a specified Tcl name, you
bump into the issue that the semantics of foo(x)<-whatever will try to
modify x and that won't do if x is a literal constant, so

"tclvalue<-"("x.var", 5) 
works and so does
z <- "x.var"; tclvalue(z) <- 5

or just tkcmd("set","x.var",5) and be gone with it...

On the other hand, if you have the name of a tclVar object as a
character string and you want to modify the object, then the recipe
would be something along the lines of

eval(substitute(tclvalue(foo) <- 5, list(foo=as.name("x.var"))))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From elvis at xlsolutions-corp.com  Fri Jan 10 02:08:02 2003
From: elvis at xlsolutions-corp.com (Elvis Miller, PhD)
Date: Fri Jan 10 02:08:02 2003
Subject: [R] Course***R/Splus programming III ***February 2003
Message-ID: <APEHLKCMHHAKBGLAPKPCMECJCBAA.elvis@xlsolutions-corp.com>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud
to announce a 2-day "R/S-plus Programming III" course:

****Boston -----------------> February 17-18   
****Philadelphia -----------> February 20-21
****Irvine -----------------> February 24-25
****San Francisco-----------> February 27-28

Course Description:

This intermediate level course is recommended for
statisticians/analysts who have some previous experience
using R/S-plus and wish to hone their skills.
Casual users can "fill in the gaps" of their knowledge
to make better use of R/S-PLus.

This course will focus on advanced topics and graphics, Vectorization,
resource management, connecting to C++, 
classes and methods (including S4 classes)  and macros.


Course Outline:

- Overview of R/S-Plus
- Using Advanced Lattice/Trellis Graphics
- Using High-level Plotting Functions
- Taking advantage of fast objects and fast functions
- Avoiding Loops
- Vectorization
- Resource Management
- Techniques for Effective use of R and S
- Connecting to C++
- Classes (S4/S-Plus) and Methods
- Macros in R
- Building and Distributing Packages (libraries)


Payments are due AFTER the course and early-bird ends January 31st.
Special group accademia fee: $985 Includes course materials, snacks
and light lunch (SF).

Registration:

Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578 x221
Visit us: www.xlsolutions-corp.com/training.htm


Course Format:

This course consists of a series of short lectures thought
by R developper gurus with demonstrations and interactive 
sessions for the participants.
Each student is provided with bound copies of the notes and
a CD-ROM containing all examples, exercises and software used
on the course.



Share Your Thoughts:

Are there any additional topics you would like for this course to address?
Would you like for this course to be offered in another city?

Please let us know by contributing to our recommendation list:
training at xlsolutions-corp.com.

========================================================================

R/S-Plus Programming III / February 2003
Pre-registration Form (Please email or print and fax: 206-686-1578)
XLsolutions Corporation: For your Solutions needs, Consulting and Training.
www.xlsolutions-corp.com



Title...... First Name ................. Last Name....................

Organization..........................................................

Mailing Address.......................................................

.....................................................................

.....................................................................

Zip Code...................... Country.............................

Telephone........................... Fax ...............................

E-mail................................................................

Payment will be made by: (1) check (2) invoice (3) Credit Card



Elvis Miller, PhD
Manager Training and Technical Support
North American Division
XLSolutions Corporation
Email: elvis at xlsolutions-corp.com
Web: www.xlsolutions-corp.com



From cmao at statserv.ucr.edu  Fri Jan 10 05:16:02 2003
From: cmao at statserv.ucr.edu (Changxuan Mao)
Date: Fri Jan 10 05:16:02 2003
Subject: [R] The options for device
Message-ID: <Pine.GSO.4.44.0301092008190.20897-100000@mao1.ucr.edu>

Hi,

I complied the R-1.6.1 source file on my 386 debian linux system.
However, I cannot get graphical output from the screen.
The options(device) is set to postscript

> getOption("device")
[1] "postscript"

After I change it to X11 ( as shown in my R 1.5.1 version on the same
system) it says  that X11 device is not loaded.

> options(device="X11")
> getOption("device")
[1] "X11"
> plot(rnorm(10))
Error in X11() : the x11 device has not been loaded
>

After I quit the R session and invoke it again, the options() changes
back.


> getOption("device")
[1] "postscript"
>


This problem does not occur for R1.5.1 in the same machine, under the same
system. Anyone has an idea to help me eliminate the problem?

Best

Changxuan



From Chris.Mellen at gmf.com.au  Fri Jan 10 05:25:03 2003
From: Chris.Mellen at gmf.com.au (Chris Mellen)
Date: Fri Jan 10 05:25:03 2003
Subject: [R] Mutual Information, Transfer Entropy etc
Message-ID: <00a101c2b860$93845650$0e80a8c0@researchws01>

Hi All,

I am searching for a package/code which will let me undertake "Information
Theoretic"- type analyses of (a) timeseries. Specifically, functions for
calculating (Auto) Mutual Information, Transfer Entropy & the like are
required. The "tseries" package used to have an "amif" function which did
Auto Mutual Information estimates, but the recent versions of this package
have had the function removed. Does anybody know of a suitable replacement ?

Thanks in advance ...

--
Christopher Mellen
Grinham Managed Funds,
55 Hume Street, Crows Nest, NSW, 2065, Australia.
phone : +61-2-9906 2600



From M.GRUM at CGIAR.ORG  Fri Jan 10 08:37:03 2003
From: M.GRUM at CGIAR.ORG (Grum, Mikkel [IPGRI-SSA-Nairobi])
Date: Fri Jan 10 08:37:03 2003
Subject: [R] Extracting means for given strata from dissimilarity object
Message-ID: 
 <FC788AB9771FD6118E6F0002A5AD7B8FFA7164@icrafnttrain.icraf.cgiar.org>

Thanks Martin. This gives me some ideas, but doesn't quite solve my problem
of getting the mean within-species distances (perhaps I hadn't expressed
that clearly enough).  I'm thinking in lines of something like:

tapply(as.matrix(iris.dist), iris$Species, mean)

except that that doesn't work, because the arguments don't have the same
length and I don't really want to include the dissimilarities of an
individual on to itself (always zero) in the calculation. In real examples I
would often use geographical units as the group that I want the within-group
mean for, as a measure of morphological diversity within the unit.

Any ideas on how to solve this would be greatly appreciated.

Mikkel

-----Original Message-----
From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
Sent: 08 January 2003 16:07
To: Grum, Mikkel [IPGRI-SSA-Nairobi]
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Extracting means for given strata from dissimilarity
object


>>>>> "MGrum" == Grum, Mikkel [IPGRI-SSA-Nairobi] <Grum>
>>>>>     on Tue, 07 Jan 2003 03:51:38 -0800 writes:

    MGrum> Is there a way of extracting mean distance or
    MGrum> dissimilarity for a given strata from a 'dist' or
    MGrum> 'dissimilarity' object, e.g. extract mean distances
    MGrum> for each species in Anderson's iris data?

    MGrum> data(iris)
    MGrum> iris.dist<-dist(iris[,1:4])

    MGrum> then what?

mean(iris.dist)   # or
summary(iris.dist)

give the overall statistics; 
for "individual ones", use as.matrix() and apply(), as

## e.g.,
am <- apply(as.matrix(iris.dist), 2, mean)
identical(am, 
          apply(as.matrix(iris.dist), 1, mean) ## -> TRUE


Martin Maechler <maechler at stat.math.ethz.ch>
http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From maechler at stat.math.ethz.ch  Fri Jan 10 09:02:03 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Jan 10 09:02:03 2003
Subject: [R] Access to R from a remote location - follow up
In-Reply-To: <Pine.GSO.4.10.10301091410560.18811-100000@fisher.stat.ucla.edu>
References: <p05200f0fba4391bdd301@[192.168.2.16]>
	<Pine.GSO.4.10.10301091410560.18811-100000@fisher.stat.ucla.edu>
Message-ID: <15902.32205.532412.317127@gargle.gargle.HOWL>

>>>>> "Roger" == Roger Peng <rpeng at stat.ucla.edu>
>>>>>     on Thu, 9 Jan 2003 14:11:47 -0800 (PST) writes:

    Roger> This is possible because I've done it many times.
    Roger> But I think whether or not your job gets killed when
    Roger> you log out depends on your shell/operating system.

yes.
For R on Unix alikes the easiest way probably is

    R BATCH myscript.R &

where the final "&" is absolutely crucial and mentioned on the
help(BATCH) page. 
Since "R BATCH" does a "--save" automatically and since I never
work with .RData (but rather with explicit save()s and load()s
when needed), my "myscript.R" would end with  

 q("no")

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

    Roger> On Thu, 9 Jan 2003, Martin Renner wrote:

    >> Following up on Erick's post, does anybody know whether it is 
    >> possible to start a lengthy batch-job in R, then log-out/break a 
    >> dial-up connection (while R is still running) and later pick-up the R 
    >> outfile?
    >> 
    >> Martin Renner
    >> 
    >> 
    >> At 1:12 PM -0500 1/9/03, Erick Edwards wrote:
    >> >Currently, our organization grants some employees remote access to SAS
    >> >and other software through a secure Citrix-based network server.  We
    >> >would like to install R on a dedicated network server and enable remote
    >> >access through Citrix.  Is this possible?  If so, what additional
    >> >software would we need?  Any advice would be greatly appreciated.
    >> >
    >> >Erick Edwards



From ripley at stats.ox.ac.uk  Fri Jan 10 09:28:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 10 09:28:03 2003
Subject: [R] The options for device
In-Reply-To: <Pine.GSO.4.44.0301092008190.20897-100000@mao1.ucr.edu>
Message-ID: <Pine.LNX.4.31.0301100821490.31264-100000@gannet.stats>

Look like when you compiled 1.6.1 the X11 files were not found.
This option is set in the .../library/base/R/Rprofile file as

if(interactive() && Sys.getenv("DISPLAY") != "") {
    options(device = switch(.Platform$GUI,
            "X11" = "X11", "GNOME" = "gtk", "postscript"))
} else options(device = "postscript")

and if the X11 device is available (see capabilities()) then you should
get X11 unless you invoke R with  R --gui="something", e.g. --gui=none
or --gui=GNOME.

On Thu, 9 Jan 2003, Changxuan Mao wrote:

> Hi,
>
> I complied the R-1.6.1 source file on my 386 debian linux system.
> However, I cannot get graphical output from the screen.
> The options(device) is set to postscript
>
> > getOption("device")
> [1] "postscript"
>
> After I change it to X11 ( as shown in my R 1.5.1 version on the same
> system) it says  that X11 device is not loaded.
>
> > options(device="X11")
> > getOption("device")
> [1] "X11"
> > plot(rnorm(10))
> Error in X11() : the x11 device has not been loaded
> >
>
> After I quit the R session and invoke it again, the options() changes
> back.
>
>
> > getOption("device")
> [1] "postscript"
> >
>
>
> This problem does not occur for R1.5.1 in the same machine, under the same
> system. Anyone has an idea to help me eliminate the problem?
>
> Best
>
> Changxuan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Fri Jan 10 09:46:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Jan 10 09:46:02 2003
Subject: [R] Warnings with no INDEX file in a package.
In-Reply-To: <001901c2b83f$04af4140$7341a8c0@alpha.wehi.edu.au>
References: <15901.58128.106565.628205@gargle.gargle.HOWL>
	<001901c2b83f$04af4140$7341a8c0@alpha.wehi.edu.au>
Message-ID: <15902.34828.350868.429605@gargle.gargle.HOWL>

>>>>> "HenrikB" == Henrik Bengtsson <hb at maths.lth.se>
>>>>>     on Fri, 10 Jan 2003 11:27:09 +1100 writes:

    >> -----Original Message-----
    >> From: r-help-admin at stat.math.ethz.ch 
    >> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of David 
    >> Kane <David Kane
    >> Sent: den 10 januari 2003 08:01
    >> To: r-help at stat.math.ethz.ch
    >> Subject: [R] Warnings with no INDEX file in a package.
    >> 
    >> 
    >> In previous versions of R (at least in 1.5.1, I think), my 
    >> practice was not to include an INDEX file in the package. R 
    >> CMD check did not complain and an INDEX was created for me 
    >> when I use R CMD build.
    >> 
    >> At least, this is how I remember it. I thought that this was 
    >> a good way to behave since it ensured that my INDEX was 
    >> automatically kept up to date by R, without me having to 
    >> worry about what functions I had added to the package. I can 
    >> understand why other people might want to maintain an INDEX 
    >> themselves (mainly because it allows one to avoid listing 
    >> functions that aren't that interesting and/or are meant for 
    >> internal use by the package only).

    HenrikB> Just a comment: To make a function "private/hidden"
    HenrikB> in the table of contents pages, but still existing,
    HenrikB> add "\keyword{internal}" to the Rd file. From
    HenrikB> Writing R Extensions:

    HenrikB> "The special keyword internal marks a page of
    HenrikB> internal objects that are not part of the packages'
    HenrikB> API. If the help page for object foo has keyword
    HenrikB> internal, then help(foo) gives this help page, but
    HenrikB> foo is excluded from several object indices, like
    HenrikB> the alphabetical list of objects in the HTML help
    HenrikB> system."

    HenrikB> Using this is much better than doing something like
    HenrikB> \title{Internal function}. 

Indeed.  Thanks a lot, Henrik!

    HenrikB> Note that "\keyword{internal}" functions will still show up
    HenrikB> in the INDEX file, 
if this is still true, I think it's conceptually a bug.  Kurt?

    HenrikB> but most people tend to look at the HTML ToC
		 ^^^^^^^^^^^
well, not the ESS users AFAIK, most of the time, and also many
Windows users would rather just use ?funcname with the popup
window...  but it might be interesting to collect statistics
here (but *please* not via sending e-mail to R-help now!!).

    HenrikB> (00Index.html) by running help.start() and there it
    HenrikB> will be excluded.

    >> In 1.6.1, however, runing R CMD check on a package with no 
    >> INDEX gives me:
    >> 
    >> * checking index files ... WARNING
    >> The following index files are missing or have zero length:
    >> INDEX
    >> See the information on INDEX files and package subdirectories 
    >> in section 'Creating R packages' of the 'Writing R Extensions' manual.

(as indicated by Jeff Gentry, you must use "R CMD build" once at least
 and later "R CMD build --force" if you want to update INDEX everytime).

One could argue that R CMD check should just build it if there's
none instead of complaining... but (I think) the concept is
rather that  ``check'' should not change anything in your
package source...

    >> * checking R files for syntax errors ... OK
    >> 
    >> I have read the suggested sections of the manual. It would 
    >> seem to me that I should be able to continue to follow my 
    >> prior practice by turning off the warning for missing INDEX. 
    >> Certainly, the fact that R CMD build creates an INDEX for you 
    >> if one is not present would suggest that this is an 
    >> acceptable practice.
    >> 
    >> Or am I missing something? I just hate to ignore a warning 
    >> each time I build a package . . .
    >> 
    >> Thanks,
    >> 
    >> Dave Kane
    >> 
    >> > R.version
    >> _                   
    >> platform sparc-sun-solaris2.6
    >> arch     sparc               
    >> os       solaris2.6          
    >> system   sparc, solaris2.6   
    >> status                       
    >> major    1                   
    >> minor    6.1                 
    >> year     2002                
    >> month    11                  
    >> day      01                  
    >> language R                   
    >> > 
    >> 
    >> -- 
    >> David Kane
    >> Geode Capital Management
    >> 617-563-0122
    >> david.d.kane at fmr.com
    >> Please avoid sending me Word or PowerPoint attachments.
    >> See http://www.fsf.org/philosophy/no-word-attachments.html



From ripley at stats.ox.ac.uk  Fri Jan 10 10:00:08 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 10 10:00:08 2003
Subject: [R] Warnings with no INDEX file in a package.
In-Reply-To: <15902.34828.350868.429605@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.31.0301100852040.31264-100000@gannet.stats>

Another comment: this is going to change a lot soon!

The handling of indices in R-devel (1.7.0-to-be, probably) is very
different (thanks to Kurt Hornik), and INDEX files will no longer be
required.  The relevant NEWS entry is

    o	Index generation now happens when installing source packages
	using R code in package tools.	An existing 'INDEX' file is used
	as is; otherwise, it is automatically generated from the \name
	and \title entries in the Rd files.  Data, demo and vignette
	indices are computed from all available files of the respective
	kind, and the corresponding index information (in the Rd files,
	the 'demo/00Index' file, and the \VignetteIndexEntry{} entries,
	respectively).	These index files, as well as the package Rd
	contents data base, are serialized as R objects, allowing for
	faster and more reliable index-based computations (e.g., in
	help.search()).

The new code does drop \keyword{internal} help topics from the indices.

I suspect CRAN already runs its checks under the new regime.


On Fri, 10 Jan 2003, Martin Maechler wrote:

> >>>>> "HenrikB" == Henrik Bengtsson <hb at maths.lth.se>
> >>>>>     on Fri, 10 Jan 2003 11:27:09 +1100 writes:
>
>     >> -----Original Message-----
>     >> From: r-help-admin at stat.math.ethz.ch
>     >> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of David
>     >> Kane <David Kane
>     >> Sent: den 10 januari 2003 08:01
>     >> To: r-help at stat.math.ethz.ch
>     >> Subject: [R] Warnings with no INDEX file in a package.
>     >>
>     >>
>     >> In previous versions of R (at least in 1.5.1, I think), my
>     >> practice was not to include an INDEX file in the package. R
>     >> CMD check did not complain and an INDEX was created for me
>     >> when I use R CMD build.
>     >>
>     >> At least, this is how I remember it. I thought that this was
>     >> a good way to behave since it ensured that my INDEX was
>     >> automatically kept up to date by R, without me having to
>     >> worry about what functions I had added to the package. I can
>     >> understand why other people might want to maintain an INDEX
>     >> themselves (mainly because it allows one to avoid listing
>     >> functions that aren't that interesting and/or are meant for
>     >> internal use by the package only).
>
>     HenrikB> Just a comment: To make a function "private/hidden"
>     HenrikB> in the table of contents pages, but still existing,
>     HenrikB> add "\keyword{internal}" to the Rd file. From
>     HenrikB> Writing R Extensions:
>
>     HenrikB> "The special keyword internal marks a page of
>     HenrikB> internal objects that are not part of the packages'
>     HenrikB> API. If the help page for object foo has keyword
>     HenrikB> internal, then help(foo) gives this help page, but
>     HenrikB> foo is excluded from several object indices, like
>     HenrikB> the alphabetical list of objects in the HTML help
>     HenrikB> system."
>
>     HenrikB> Using this is much better than doing something like
>     HenrikB> \title{Internal function}.
>
> Indeed.  Thanks a lot, Henrik!
>
>     HenrikB> Note that "\keyword{internal}" functions will still show up
>     HenrikB> in the INDEX file,
> if this is still true, I think it's conceptually a bug.  Kurt?
>
>     HenrikB> but most people tend to look at the HTML ToC
> 		 ^^^^^^^^^^^
> well, not the ESS users AFAIK, most of the time, and also many
> Windows users would rather just use ?funcname with the popup
> window...  but it might be interesting to collect statistics
> here (but *please* not via sending e-mail to R-help now!!).
>
>     HenrikB> (00Index.html) by running help.start() and there it
>     HenrikB> will be excluded.
>
>     >> In 1.6.1, however, runing R CMD check on a package with no
>     >> INDEX gives me:
>     >>
>     >> * checking index files ... WARNING
>     >> The following index files are missing or have zero length:
>     >> INDEX
>     >> See the information on INDEX files and package subdirectories
>     >> in section 'Creating R packages' of the 'Writing R Extensions' manual.
>
> (as indicated by Jeff Gentry, you must use "R CMD build" once at least
>  and later "R CMD build --force" if you want to update INDEX everytime).
>
> One could argue that R CMD check should just build it if there's
> none instead of complaining... but (I think) the concept is
> rather that  ``check'' should not change anything in your
> package source...

My concept is that you should R CMD build, then check the distribution tar
file.

>     >> * checking R files for syntax errors ... OK
>     >>
>     >> I have read the suggested sections of the manual. It would
>     >> seem to me that I should be able to continue to follow my
>     >> prior practice by turning off the warning for missing INDEX.
>     >> Certainly, the fact that R CMD build creates an INDEX for you
>     >> if one is not present would suggest that this is an
>     >> acceptable practice.
>     >>
>     >> Or am I missing something? I just hate to ignore a warning
>     >> each time I build a package . . .

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ozric at web.de  Fri Jan 10 10:25:03 2003
From: ozric at web.de (Christian Schulz)
Date: Fri Jan 10 10:25:03 2003
Subject: [R] manipulate all files in folder
Message-ID: <003501c2b889$868c7ee0$64b107d5@c5c9i0>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030110/fb3578d8/attachment.pl

From arv at ono.com  Fri Jan 10 10:31:04 2003
From: arv at ono.com (antonio rodriguez)
Date: Fri Jan 10 10:31:04 2003
Subject: [R] overlay a filled contour on world()
Message-ID: <001301c2b88a$cbf00e60$0300a8c0@ono>

Hi,

Is it possible to overlay over a world region drawn by function world(),
a filled.contour for that specific region?

I've managed to do the inverse, add world to a filled.contour, but the
appearence of the map is not the one I would like. With contour() is
easy to do the task, but with filled.contour...

Any hints aprreciated

Cheers,

Antonio Rodr?guez


---



From phgrosjean at sciviews.org  Fri Jan 10 10:37:02 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri Jan 10 10:37:02 2003
Subject: [R] manipulate all files in folder
In-Reply-To: <003501c2b889$868c7ee0$64b107d5@c5c9i0>
Message-ID: <MABBLJDICACNFOLGIHJOMEHHDCAA.phgrosjean@sciviews.org>

read:

?paste

and use:

paste(path, file, sep="")

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................


-----Original Message-----
From: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of Christian Schulz
Sent: vendredi 10 janvier 2003 10:21
To: r-help at stat.math.ethz.ch
Subject: [R] manipulate all files in folder


Im just attempt writing a function
which import manipulate and export spss data, my
basic problem  when i use the cat command
that their is a space to much ?

Perhaps here exist a better solution ?

cat(paste(path),paste(file))
c:/Project/Allbus/ aprioriTotal.sav

test <- function(dir) {
for (i in 1:length(list.files))
path <- "c:/Project/Allbus/"
file <- list.files()[4]
tmpdata <-
read.spss(cat(paste(path),paste(file)),use.value.labels=F,to.data.frame=T)

thanks for advance
& regards,christian


	[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Fri Jan 10 10:43:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 10 10:43:03 2003
Subject: [R] tclVar Question
In-Reply-To: <x2fzs196ib.fsf@biostat.ku.dk>
References: <F180ZX15eUy7yUZyvjn0002a66f@hotmail.com>
	<x2fzs196ib.fsf@biostat.ku.dk>
Message-ID: <x2ptr5s5r6.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> On the other hand, if you have the name of a tclVar object as a
> character string and you want to modify the object, then the recipe
> would be something along the lines of
> 
> eval(substitute(tclvalue(foo) <- 5, list(foo=as.name("x.var"))))

...or -- doh! -- noting that tclVar objects are *references* to Tcl
variables, 

z <- get("x.var")
tclvalue(z) <- 5

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Fri Jan 10 10:49:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 10 10:49:02 2003
Subject: [R] manipulate all files in folder
In-Reply-To: <MABBLJDICACNFOLGIHJOMEHHDCAA.phgrosjean@sciviews.org>
Message-ID: <Pine.LNX.4.31.0301100942190.31601-100000@gannet.stats>

There is also file.path() for this purpose (and that allows you to write
paths without trailing separators, a good idea as Windows does not like
them).

But there is probably a yet easier way, as I suspect you intended
something like

test <- function(dir) {
  for(fn in list.files(dir, full.names = TRUE)) {
    tmpdata <- read.spss(fn, use.value.labels=F, to.data.frame=T)
    ....
  }
}

On Fri, 10 Jan 2003, Philippe Grosjean wrote:

> read:
>
> ?paste
>
> and use:
>
> paste(path, file, sep="")
>
> -----Original Message-----
> [mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of Christian Schulz
>
> Im just attempt writing a function
> which import manipulate and export spss data, my
> basic problem  when i use the cat command
> that their is a space to much ?
>
> Perhaps here exist a better solution ?
>
> cat(paste(path),paste(file))
> c:/Project/Allbus/ aprioriTotal.sav
>
> test <- function(dir) {
> for (i in 1:length(list.files))
> path <- "c:/Project/Allbus/"
> file <- list.files()[4]
> tmpdata <-
> read.spss(cat(paste(path),paste(file)),use.value.labels=F,to.data.frame=T)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From djw1005 at cam.ac.uk  Fri Jan 10 11:42:03 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Fri Jan 10 11:42:03 2003
Subject: [R] Superposed histograms
Message-ID: <Pine.SOL.3.96.1030110102635.12064A-100000@libra.cus.cam.ac.uk>

I woud like to plot cumulative histograms. Specifically,
I have data like
    Sex     M   M   F   M   F   F   M   F
    Height  6   6.3 6.1 5.5 7.2 6.2 5.9 6.0  ....
and I want to plot a histogram of the distribution of all heights,
colouring the histogram bars according to sex, for example
   
  |    o   
  |   oo  o  
  | o oo ** o   o = observations of women
  | o o*o***o   * = observations of men
  | *o*******
  |----------

(And I want this in a Trellis plot, and with more than two groups of
observations.) How should I do this? I tried looking for imaginitive
combinations of panel.superpose and panel.histogram. I suppose if I called
panel.histogram for the cumulative data first, then panel.histogram for
just the data on men, with a different colour, I could achieve the effect. 
But I'd need to superpose the accumulated data, and panel.superpose seems
to only separate the data by group, not accumulate data by group.

Damon Wischik.



From eia018 at comp.lancs.ac.uk  Fri Jan 10 12:43:03 2003
From: eia018 at comp.lancs.ac.uk (Dr Andrew Wilson)
Date: Fri Jan 10 12:43:03 2003
Subject: [R] Removing autocorrelations
In-Reply-To: <Pine.LNX.4.31.0301060958530.11272-100000@gannet.stats>
Message-ID: <Pine.GSO.4.21.0301101134100.18105-100000@austin>

On Mon, 6 Jan 2003 ripley at stats.ox.ac.uk wrote:
> As is often the case, please tell us what you want really to do (in your
> substantive application) rather than for a vague statistical procedure,
> and we may be able to point you to appropriate tools.

Thanks - happy to oblige.  Sorry if my original question was a bit vague.

I have a set of narrative texts and want to carry out a "narrative pattern
analysis" for each text.  I divide each text into consecutive segments of
N (usually ca.200) running words each and count for each segment the
overall frequency of words that populate the conceptual category that I'm
interested in, giving me a frequency count of, say, "emotion" for each
segment.  I then want to see whether this category shows a significant
linear or nonlinear development through the narrative, or whether its
occurrence is random.  However, other people who have done this have
suggested that autocorrelation within the series can amplify or diminish
actual differences between segments and therefore that autocorrelations
should be removed, even if they are not statistically significant.  I know
how to fit a basic linear or nonlinear curve, but I don't know how to
go about getting rid of these autocorrelations.

Many thanks,
Andrew Wilson



From ozric at web.de  Fri Jan 10 12:52:03 2003
From: ozric at web.de (Christian Schulz)
Date: Fri Jan 10 12:52:03 2003
Subject: [R] manipulate all files in folder
References: <Pine.LNX.4.31.0301100942190.31601-100000@gannet.stats>
Message-ID: <001901c2b89d$7b20ab30$74b107d5@c5c9i0>

many thanks, but how  it's
possible set my data.frames to get
this as
tmpdata[1]  etc.

regards,christian


test <- function(dir) {
+        tmpdata <- data.frame(##here's the problem?##)
+         for(fn in list.files(dir, full.names = TRUE)) {
+           tmpdata[fn] <- read.spss(fn, use.value.labels=F,
to.data.frame=T)
+                 }
+               return(tmpdata)
+           }
>>test("c:/Project/allbus/Data")
[1] c:/Project/allbus/Data/fuzzyHermes.sav
[2] c:/Project/allbus/Data/hermesKunden.sav
[3] c:/Project/allbus/Data/hermesTertius.sav
[4] c:/Project/allbus/Data/hermesWettbewerb.sav
<0 rows> (or 0-length row.names)
Warning messages:
1: replacement data has 2297 rows to replace 0 rows in:
"[<-.data.frame"(*tmp*, fn, value = read.spss(fn, use.value.labels = F,
2: provided 8 variables to replace 1 variables in: "[<-.data.frame"(*tmp*,
fn, value = read.spss(fn, use.value.labels = F,
3: replacement data has 2297 rows to replace 0 rows in:
"[<-.data.frame"(*tmp*, fn, value = read.spss(fn, use.value.labels = F,
4: provided 192 variables to replace 1 variables in: "[<-.data.frame"(*tmp*,
fn, value = read.spss(fn, use.value.labels = F,
5: replacement data has 2297 rows to replace 0 rows in:
"[<-.data.frame"(*tmp*, fn, value = read.spss(fn, use.value.labels = F,
6: provided 25 variables to replace 1 variables in: "[<-.data.frame"(*tmp*,
fn, value = read.spss(fn, use.value.labels = F,
7: replacement data has 430 rows to replace 0 rows in:
"[<-.data.frame"(*tmp*, fn, value = read.spss(fn, use.value.labels = F,
8: provided 191 variables to replace 1 variables in: "[<-.data.frame"(*tmp*,
fn, value = read.spss(fn, use.value.labels = F,
>>ls()
[1] "last.warning" "test"

> test <- function(dir) {
>   for(fn in list.files(dir, full.names = TRUE)) {
>     tmpdata <- read.spss(fn, use.value.labels=F, to.data.frame=T)
>     ....
>   }
> }



From fharrell at virginia.edu  Fri Jan 10 12:58:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri Jan 10 12:58:03 2003
Subject: [R] Superposed histograms
In-Reply-To: <Pine.SOL.3.96.1030110102635.12064A-100000@libra.cus.cam.ac.uk>
References: <Pine.SOL.3.96.1030110102635.12064A-100000@libra.cus.cam.ac.uk>
Message-ID: <20030110065947.21d00b25.fharrell@virginia.edu>

On Fri, 10 Jan 2003 10:41:31 +0000 (GMT)
Damon Wischik <djw1005 at cam.ac.uk> wrote:

> 
> I woud like to plot cumulative histograms. Specifically,
> I have data like
>     Sex     M   M   F   M   F   F   M   F
>     Height  6   6.3 6.1 5.5 7.2 6.2 5.9 6.0  ....
> and I want to plot a histogram of the distribution of all heights,
> colouring the histogram bars according to sex, for example
>    
>   |    o   
>   |   oo  o  
>   | o oo ** o   o = observations of women
>   | o o*o***o   * = observations of men
>   | *o*******
>   |----------
> 
> (And I want this in a Trellis plot, and with more than two groups of
> observations.) How should I do this? I tried looking for imaginitive
> combinations of panel.superpose and panel.histogram. I suppose if I called
> panel.histogram for the cumulative data first, then panel.histogram for
> just the data on men, with a different colour, I could achieve the effect. 
> But I'd need to superpose the accumulated data, and panel.superpose seems
> to only separate the data by group, not accumulate data by group.
> 
> Damon Wischik.

I don't think this will be effective from a graphical perception point of view.  One problem is that the perception of the bottom symbols will be different than that of the symbols assigned to the upper region, because the upper symbols are not bottom-aligned.  I suggest usual multi-panel histograms or back-to-back histograms (see e.g. histbackback in the Hmisc library).  But better still would be superposed ECDFs (e.g., ecdf() in Hmisc or in Martin Maechler's package).  ECDFs are much better for showing distribution differences in my view.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From ripley at stats.ox.ac.uk  Fri Jan 10 13:03:07 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 10 13:03:07 2003
Subject: [R] manipulate all files in folder
In-Reply-To: <001901c2b89d$7b20ab30$74b107d5@c5c9i0>
Message-ID: <Pine.LNX.4.31.0301101159260.31932-100000@gannet.stats>

You want a list of data frames, and tmpdata[[fn]].

You cannot put multiple data frames in one data frame (sensibly).

On Fri, 10 Jan 2003, Christian Schulz wrote:

> many thanks, but how  it's
> possible set my data.frames to get
> this as
> tmpdata[1]  etc.
>
> regards,christian
>
>
> test <- function(dir) {
> +        tmpdata <- data.frame(##here's the problem?##)
> +         for(fn in list.files(dir, full.names = TRUE)) {
> +           tmpdata[fn] <- read.spss(fn, use.value.labels=F,
> to.data.frame=T)
> +                 }
> +               return(tmpdata)
> +           }
> >>test("c:/Project/allbus/Data")
> [1] c:/Project/allbus/Data/fuzzyHermes.sav
> [2] c:/Project/allbus/Data/hermesKunden.sav
> [3] c:/Project/allbus/Data/hermesTertius.sav
> [4] c:/Project/allbus/Data/hermesWettbewerb.sav
> <0 rows> (or 0-length row.names)
> Warning messages:
> 1: replacement data has 2297 rows to replace 0 rows in:
> "[<-.data.frame"(*tmp*, fn, value = read.spss(fn, use.value.labels = F,
> 2: provided 8 variables to replace 1 variables in: "[<-.data.frame"(*tmp*,
> fn, value = read.spss(fn, use.value.labels = F,
> 3: replacement data has 2297 rows to replace 0 rows in:
> "[<-.data.frame"(*tmp*, fn, value = read.spss(fn, use.value.labels = F,
> 4: provided 192 variables to replace 1 variables in: "[<-.data.frame"(*tmp*,
> fn, value = read.spss(fn, use.value.labels = F,
> 5: replacement data has 2297 rows to replace 0 rows in:
> "[<-.data.frame"(*tmp*, fn, value = read.spss(fn, use.value.labels = F,
> 6: provided 25 variables to replace 1 variables in: "[<-.data.frame"(*tmp*,
> fn, value = read.spss(fn, use.value.labels = F,
> 7: replacement data has 430 rows to replace 0 rows in:
> "[<-.data.frame"(*tmp*, fn, value = read.spss(fn, use.value.labels = F,
> 8: provided 191 variables to replace 1 variables in: "[<-.data.frame"(*tmp*,
> fn, value = read.spss(fn, use.value.labels = F,
> >>ls()
> [1] "last.warning" "test"
>
> > test <- function(dir) {
> >   for(fn in list.files(dir, full.names = TRUE)) {
> >     tmpdata <- read.spss(fn, use.value.labels=F, to.data.frame=T)
> >     ....
> >   }
> > }
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From djw1005 at cam.ac.uk  Fri Jan 10 13:30:03 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Fri Jan 10 13:30:03 2003
Subject: [R] Superposed histograms
In-Reply-To: <20030110065947.21d00b25.fharrell@virginia.edu>
Message-ID: <Pine.SOL.3.96.1030110122355.19483A-100000@libra.cus.cam.ac.uk>

>> I woud like to plot cumulative histograms....
>
> I don't think this will be effective from a graphical perception point
> of view.  One problem is that the perception of the bottom symbols will
> be different than that of the symbols assigned to the upper region,
> because the upper symbols are not bottom-aligned.

I _want_ the perception to be different! I gave a toy example, not my real
application. My real application is this: I have some samples from a
distribution. Some of the samples I know with high accuracy, some I know
with low accuracy. I wanted a histogram of the high-accuracy samples drawn
in a dark colour, and a histogram of the low-accuracy samples plotted on
top in a different colour. That way my impression would be dominated by
the part of the plot I am confident about, but I would still see a little
of the part I am less confident about.

Do you have any recommendations on how to show graphically a distribution,
indicating at the same time which parts of the distribution I know with
confidence?

Damon Wischik.



From mihastaut at hotmail.com  Fri Jan 10 13:50:06 2003
From: mihastaut at hotmail.com (Miha STAUT)
Date: Fri Jan 10 13:50:06 2003
Subject: [R] GRASS/R interface problem
Message-ID: <F12qLxbzQ3jcnXGmUk9000156a8@hotmail.com>

Hi all,

In my version of the R package GRASS (pre-4) I only manage to export an R 
object to GRASS with the name "akspl" which, if I am not wrong, is only a 
sample name in the example(). It goes that way:

rast.obj->akspl
rast.put(G, akspl, lname="rast.obj", ...)

Is that a known problem or have I done something wrong anywhere?

Miha Staut



From fharrell at virginia.edu  Fri Jan 10 13:55:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri Jan 10 13:55:03 2003
Subject: [R] Superposed histograms
In-Reply-To: <Pine.SOL.3.96.1030110122355.19483A-100000@libra.cus.cam.ac.uk>
References: <20030110065947.21d00b25.fharrell@virginia.edu>
	<Pine.SOL.3.96.1030110122355.19483A-100000@libra.cus.cam.ac.uk>
Message-ID: <20030110075310.77247fd2.fharrell@virginia.edu>

On Fri, 10 Jan 2003 12:29:13 +0000 (GMT)
Damon Wischik <djw1005 at cam.ac.uk> wrote:

> 
> >> I woud like to plot cumulative histograms....
> >
> > I don't think this will be effective from a graphical perception point
> > of view.  One problem is that the perception of the bottom symbols will
> > be different than that of the symbols assigned to the upper region,
> > because the upper symbols are not bottom-aligned.
> 
> I _want_ the perception to be different! I gave a toy example, not my real
> application. My real application is this: I have some samples from a
> distribution. Some of the samples I know with high accuracy, some I know
> with low accuracy. I wanted a histogram of the high-accuracy samples drawn
> in a dark colour, and a histogram of the low-accuracy samples plotted on
> top in a different colour. That way my impression would be dominated by
> the part of the plot I am confident about, but I would still see a little
> of the part I am less confident about.
> 
> Do you have any recommendations on how to show graphically a distribution,
> indicating at the same time which parts of the distribution I know with
> confidence?
> 
> Damon Wischik.
> 
> 
My advice would be to plot superposed ECDFs with the one you want to deemphasize shown in light gray scale.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From ozric at web.de  Fri Jan 10 14:00:03 2003
From: ozric at web.de (Christian Schulz)
Date: Fri Jan 10 14:00:03 2003
Subject: [R] manipulate all files in folder
References: <Pine.LNX.4.31.0301100942190.31601-100000@gannet.stats> <5.1.1.5.2.20030110130211.01f2e008@stat4ux.stat.ucl.ac.be>
Message-ID: <006501c2b8a7$199a3160$74b107d5@c5c9i0>

> See help for assign function for details.
many thanks for all helps + this suggestion.
christian



From adrian.trapletti at lmttrading.com  Fri Jan 10 14:05:03 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Fri Jan 10 14:05:03 2003
Subject: [R] Mutual Information, Transfer Entropy etc
References: <20030110110006.10309.31355.Mailman@hypatia.math.ethz.ch>
Message-ID: <3E1EC4DB.A734FC79@lmttrading.com>

> Subject: [R] Mutual Information, Transfer Entropy etc
> Date: Fri, 10 Jan 2003 15:27:10 +1100
> From: "Chris Mellen" <Chris.Mellen at gmf.com.au>
> To: <r-help at stat.math.ethz.ch>
>
> Hi All,
>
> I am searching for a package/code which will let me undertake "Information
> Theoretic"- type analyses of (a) timeseries. Specifically, functions for
> calculating (Auto) Mutual Information, Transfer Entropy & the like are
> required. The "tseries" package used to have an "amif" function which did
> Auto Mutual Information estimates, but the recent versions of this package
> have had the function removed. Does anybody know of a suitable replacement ?

Dear Chris

I had to remove amif due to a license problem with the underlying code. However, if you would like to use the
old amif function (under a non-GPL license) I can provide you with the code.

best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com



From Roger.Bivand at nhh.no  Fri Jan 10 14:10:03 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri Jan 10 14:10:03 2003
Subject: [R] GRASS/R interface problem
In-Reply-To: <F12qLxbzQ3jcnXGmUk9000156a8@hotmail.com>
Message-ID: <Pine.LNX.4.44.0301101359530.973-100000@reclus.nhh.no>

On Fri, 10 Jan 2003, Miha STAUT wrote:

> Hi all,
> 
> In my version of the R package GRASS (pre-4) I only manage to export an R 
> object to GRASS with the name "akspl" which, if I am not wrong, is only a 
> sample name in the example(). It goes that way:

First, the current package is GRASS_0.1-11, so maybe update, and see if 
that makes a difference.

> 
> rast.obj->akspl
> rast.put(G, akspl, lname="rast.obj", ...)
> 

Your question is whether rast.put() only works with a single R object 
name? No, definitely not, but it isn't always easy to remember which bugs 
existed in versions dating back several years. The *pre* tarfile name 
suggests that you do not have a proper released package anyway.

> Is that a known problem or have I done something wrong anywhere?
> 
Finally, it is usual to ask package maintainers questions like this, 
rather than this list - there is also a limited volume mailing list 
specifically for this too: http://grass.itc.it/statsgrass/index.html

> Miha Staut
> 

Roger Bivand

Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From d.scott at auckland.ac.nz  Fri Jan 10 14:14:24 2003
From: d.scott at auckland.ac.nz (David Scott)
Date: Fri Jan 10 14:14:24 2003
Subject: [R] Creating packages
Message-ID: <Pine.SOL.4.21.0301110137001.958-100000@stat1.stat.auckland.ac.nz>

I am trying to create a package. I have succeeded in running R CMD check
and R CMD build on an Intel box running Redhat. I would now like to
build it on Windows as well. There is no compiled code in the package at
all.

I have downloaded the tools from Brian Ripley's Building R for Windows
page, and installed Active Perl 5.8.0. I have set paths, and Rcmd and the
tools are being found ok. I am having trouble though as follows:

C:\dscott\Temp>ls
hyperb  hyperbtemp

C:\dscott\Temp>set TMPDIR=hyperbtemp

C:\dscott\Temp>Rcmd build hyperb
* checking for file 'hyperb/DESCRIPTION' ... OK
* preparing 'hyperb':
Error: cannot write to 'hyperbtemp/Rutils113288500'

I get a similar cannot write error if I try and run check. 

System details are

platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.1            
year     2002           
month    11             
day      01             
language R     

David Scott

_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
		The University of Auckland, PB 92019
		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz 

Webmaster, New Zealand Statistical Association:
        http://www.stat.auckland.ac.nz/nzsa/



From ripley at stats.ox.ac.uk  Fri Jan 10 14:25:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 10 14:25:04 2003
Subject: [R] Creating packages
In-Reply-To: <Pine.SOL.4.21.0301110137001.958-100000@stat1.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.31.0301101320490.2363-100000@gannet.stats>

On Sat, 11 Jan 2003, David Scott wrote:

>
> I am trying to create a package. I have succeeded in running R CMD check
> and R CMD build on an Intel box running Redhat. I would now like to
> build it on Windows as well. There is no compiled code in the package at
> all.
>
> I have downloaded the tools from Brian Ripley's Building R for Windows
> page, and installed Active Perl 5.8.0. I have set paths, and Rcmd and the
> tools are being found ok. I am having trouble though as follows:
>
> C:\dscott\Temp>ls
> hyperb  hyperbtemp
>
> C:\dscott\Temp>set TMPDIR=hyperbtemp

That needs to be an absolute path, as given in the example in
readme.packages.  I think you may mean c:/dscott/Temp/hyperbtemp.  The
code does not check that it is absolute (nor do I see how one can actually
ensure it).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jesus.fernandez at eez.csic.es  Fri Jan 10 14:30:09 2003
From: jesus.fernandez at eez.csic.es (=?iso-8859-1?Q?Jes=FAs=20Fern=E1ndez=20G=E1lvez?=)
Date: Fri Jan 10 14:30:09 2003
Subject: [R] exporting graphs
Message-ID: <3E1ECA27.76E51E2E@eez.csic.es>

I am sending the solution to my question in case someone has the same
problem.


Finally I manage to get good results with "metafile" but my error was
that I did not choose the higher quality
option for my printer.

--
Jes?s Fern?ndez G?lvez
Dpto. Ciencias de la Tierra y Qu?mica Ambiental
Estaci?n Experimental del Zaid?n, CSIC
c/ Prof. Albareda 1; 18008 GRANADA, Spain
Tel:  958 181600
Fax: 958 129600



From fnj at cin.ufpe.br  Fri Jan 10 14:38:02 2003
From: fnj at cin.ufpe.br (Francisco Junior)
Date: Fri Jan 10 14:38:02 2003
Subject: [R] Package cluster
Message-ID: <Pine.LNX.4.44.0301101019450.20394-100000@buique.cin.ufpe.br>

Hello,
Someone use this package?
I would like to know if this package has some method to classify
images?
Tks,
Chico.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco Júnior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From bates at stat.wisc.edu  Fri Jan 10 15:15:04 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Jan 10 15:15:04 2003
Subject: [R] The options for device
In-Reply-To: <Pine.GSO.4.44.0301092008190.20897-100000@mao1.ucr.edu>
References: <Pine.GSO.4.44.0301092008190.20897-100000@mao1.ucr.edu>
Message-ID: <6riswx2itj.fsf@bates4.stat.wisc.edu>

Changxuan Mao <cmao at statserv.ucr.edu> writes:

> I complied the R-1.6.1 source file on my 386 debian linux system.

Is there a reason that you want to compile R from sources on a Debian
Linux system?  You can install from the Debian packages for R-1.6.1
for the stable and the testing Debian distributions that are available
on the Debian archives and on CRAN.

Dirk Eddelbuettel expects to have Debian packages of R-1.6.2,
scheduled for release today, uploaded by tomorrow.  Test builds of
Debian packages for R-1.6.2 have been on the Debian archives for two
weeks.

The versions of R in the Debian packages have full support for the X11
device driver.  A separate Debian package called r-gnome provides the
gnome device driver

r-doc-html - GNU R html manuals for statistical computing system
r-doc-pdf - GNU R pdf manuals for statistical computing system
r-base-dev - GNU R installation of auxiliary GNU R packages
r-base-html - GNU R html docs for statistical computing system functions
r-doc-info - GNU R info manuals statistical computing system
r-gnome - GNU R Gnome gui for statistical computing system
r-base - GNU R statistical computing language and environment
r-base-core - GNU R core of statistical computing language and environment
r-mathlib - GNU R standalone mathematics library
r-base-latex - GNU R LaTeX docs for statistical computing system functions
r-recommended - GNU R collection of recommended packages



From tord.snall at ebc.uu.se  Fri Jan 10 15:26:02 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Fri Jan 10 15:26:02 2003
Subject: [R] count levels per factor level
Message-ID: <3.0.6.32.20030110151918.00b56910@mail.anst.uu.se>

Dear all,

I would be really happy for help with the following because I will treat
many columns the same way.

nlevels per ObjektID is what I want, but nlevels returns all levels
occurring in cpy.busk$TradArt:

buskartant<- aggregate(list(trash = cpy.busk$TradArt), list(ObjektID =
cpy.busk$ObjektID), nlevels) 

But as you can see I use it below anyway. I could use any function instaed
of nlevels beacuse now I just want the ObjektID in the right order.

Greg Warnes kindly helped me with this solution: 
group.list <- split(cpy.busk$TradArt, cpy.busk$ObjektID)
buskartant$buskartant <- sapply( group.list, function(x) length(unique(x)) )

But the probelm is that unique considers NA as a category, and there is no
na.rm argument in unique().

Please give a hint.

Thanks a lot in advance!

Sincerely,
Tord

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From bates at stat.wisc.edu  Fri Jan 10 15:41:02 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Jan 10 15:41:02 2003
Subject: [R] Access to R from a remote location - follow up
In-Reply-To: <15902.32205.532412.317127@gargle.gargle.HOWL>
References: <p05200f0fba4391bdd301@[192.168.2.16]>
	<Pine.GSO.4.10.10301091410560.18811-100000@fisher.stat.ucla.edu>
	<15902.32205.532412.317127@gargle.gargle.HOWL>
Message-ID: <6rd6n52hm2.fsf@bates4.stat.wisc.edu>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> >>>>> "Roger" == Roger Peng <rpeng at stat.ucla.edu>
> >>>>>     on Thu, 9 Jan 2003 14:11:47 -0800 (PST) writes:
> 
>     Roger> This is possible because I've done it many times.
>     Roger> But I think whether or not your job gets killed when
>     Roger> you log out depends on your shell/operating system.
> 
> yes.
> For R on Unix alikes the easiest way probably is
> 
>     R BATCH myscript.R &
> 
> where the final "&" is absolutely crucial and mentioned on the
> help(BATCH) page. 
> Since "R BATCH" does a "--save" automatically and since I never
> work with .RData (but rather with explicit save()s and load()s
> when needed), my "myscript.R" would end with  
> 
>  q("no")

In some shells you may find it works better to use

 nohup R BATCH myscript.R &

so that you can log out without killing background jobs.  (The nohup
command name indicates that the program will not respond to the HUP or
"hangup" signal.)

I agree with Martin that it is a good idea to end such scripts with
 q("no")
if you do not want the workspace saved.  Another variation is to use
the --no-save flag.

 nohup R BATCH myscript.R --no-save &

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From tord.snall at ebc.uu.se  Fri Jan 10 16:19:03 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Fri Jan 10 16:19:03 2003
Subject: Thanks: Re: [R] count levels per factor level
In-Reply-To: <Pine.LNX.4.33.0301100928010.28347-100000@penguin.rand.org>
References: <Pine.LNX.4.33.0301100928010.28347-100000@penguin.rand.org>
Message-ID: <1042211886.3e1ee42eec07d@webmail.anst.uu.se>

Dear Lockwood,

As you can see, I'm a beginner...

But thank you very much! 

Sincerely,
Tord

Quoting "J.R. Lockwood" <lockwood at rand.org>:

> how about
> 
> buskartant$buskartant <- sapply( group.list, function(x)
> sum(!is.na(unique(x))) )
> 
> OR
> 
> buskartant$buskartant <- sapply( group.list, function(x)
> length(unique(x[!is.na(x)])) )
> 
> 
> On Fri, 10 Jan 2003, Tord Snall wrote:
> 
> > Date: Fri, 10 Jan 2003 15:19:18 +0100
> > From: Tord Snall <tord.snall at ebc.uu.se>
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] count levels per factor level
> > 
> > Dear all,
> > 
> > I would be really happy for help with the following because I will
> treat
> > many columns the same way.
> > 
> > nlevels per ObjektID is what I want, but nlevels returns all levels
> > occurring in cpy.busk$TradArt:
> > 
> > buskartant<- aggregate(list(trash = cpy.busk$TradArt), list(ObjektID
> =
> > cpy.busk$ObjektID), nlevels) 
> > 
> > But as you can see I use it below anyway. I could use any function
> instaed
> > of nlevels beacuse now I just want the ObjektID in the right order.
> > 
> > Greg Warnes kindly helped me with this solution: 
> > group.list <- split(cpy.busk$TradArt, cpy.busk$ObjektID)
> > buskartant$buskartant <- sapply( group.list, function(x)
> length(unique(x)) )
> > 
> > But the probelm is that unique considers NA as a category, and there
> is no
> > na.rm argument in unique().
> > 
> > Please give a hint.
> > 
> > Thanks a lot in advance!
> > 
> > Sincerely,
> > Tord
> > 
> >
> -----------------------------------------------------------------------
> > Tord Sn?ll
> > Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
> > Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala
> University
> > Villav?gen 14			
> > SE-752 36 Uppsala, Sweden
> > Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
> > Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
> > Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
> > E-mail: Tord.Snall at ebc.uu.se
> > Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
> >
> ------------------------------------------------------------------------
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> J.R. Lockwood
> 412-683-2300 x4941
> lockwood at rand.org
> http://www.rand.org/methodology/stat/members/lockwood/
> 
>



From maechler at stat.math.ethz.ch  Fri Jan 10 16:40:07 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Jan 10 16:40:07 2003
Subject: [R] Package cluster
In-Reply-To: <Pine.LNX.4.44.0301101019450.20394-100000@buique.cin.ufpe.br>
References: <Pine.LNX.4.44.0301101019450.20394-100000@buique.cin.ufpe.br>
Message-ID: <15902.59721.592795.806837@gargle.gargle.HOWL>

>>>>> "Francisco" == Francisco Junior <fnj at cin.ufpe.br>
>>>>>     on Fri, 10 Jan 2003 10:37:02 -0300 (BRST) writes:

    Francisco> Hello,
    Francisco> Someone use this package?

(I hope, it's a recommended package for a reason).

    Francisco> I would like to know if this package has some method to classify
    Francisco> images?

you mean "cluster" or "classify" ?
For many of us "classify" is `supervised' where as
"clustering" is `unsupervised'.

If the second:  
- About how many clusters do you want?
- about how many images do you have?
- what's their format?

In (supervised) classification, this has been quite a hot topic.
In any case, many things depend on your goal and data.
For clustering, you have to think about a (dis)similarity
measure between images.  There are *many* possibilities and that
measure will be crucial.  I've heard of situations where only
the color distribution histogram was used of each image (and
similarity ~= some kind correlation).  
You should also read a bit about cluster analysis in a
textbook (on "clustering" or "multivariate analysis").
For the cluster package, the obvious textbook is
Kaufman & Rousseeuw (1990).
help(agnes) has a "BACKGROUND" and "References" section.

    Francisco> Tks,
yrwlcm,

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From p.dalgaard at biostat.ku.dk  Fri Jan 10 16:59:15 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 10 16:59:15 2003
Subject: [R] R-1.6.2 is released
Message-ID: <x2adi9rogm.fsf@biostat.ku.dk>

I've rolled up R-1.6.2.tgz a short while ago. This is a minor upgrade,
fixing an assortment of bugs.

You can get it from the developer site at

http://cvs.r-project.org/pub/CRAN/src/base/R-1.6.2.tgz

or wait for it to be mirrored at a CRAN site near you. Binaries for
various platforms will appear in due course.
 
There is also a version split for floppies, but due to the inclusion
of recommended packages as binary .tar.gz files, we are no longer
providing a patch file.

These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

174e6280aa2f2102388ca9c7930b1843  R-1.6.2.tgz
8d202e80aa52e3fc877994f1a76fc198  R-1.6.2.tgz-split.aa
8153444a5c0bea85ede04e0ced76b7de  R-1.6.2.tgz-split.ab
b1d88962c538ab9fccc81161c2a81a02  R-1.6.2.tgz-split.ac
90fb143e6a3289d472817e5218d2423d  R-1.6.2.tgz-split.ad
0e55aacd637415053f18651ecdc73c3a  R-1.6.2.tgz-split.ae
1c910fa9fe45fd5a15d6b3893c99f7fc  R-1.6.2.tgz-split.af
8706e736541bf60b717e0b56e8a405a0  R-1.6.2.tgz-split.ag

        For the R Core Team,

        Peter D.


Here's the relevant part of the NEWS file:


                CHANGES IN R VERSION 1.6.2


BUG FIXES

    o   plot.stepfun() now obeys a `ylim=.' specification.

    o   removeClass() does a better job of removing inheritance
        information.

    o   setIs() will not allow mismatched representations between two
        classes (without an explicit coerce method).

    o   The code underlying polygon drawing contained a memory leak.
        This showed up in persp, but did not affect other graphics
        functions.  It is now possible to draw big DEMs.

    o   logLik.nls() gave wrong df. (PR#2295)

    o   rbind() with a mixture of data frames and matrices treated the
        matrices as vectors. (PR#2266)

    o   stripchart(method="stack") was not handling missing values. (PR#2018)

    o   Arithmetic functions such as log() lost the object bit from
        classed objects if coercion was needed. (PR#2315)

    o   exp_rand would go into an infinite loop if unif_rand returned 0.

    o   formatC(x, format="fg") could return exponential format if
        rounding pushed x over a positive power of 10. (PR#2299)

    o   attr(x, foo) used partial matching for `foo' (even though not
        documented to do so), and failed to find `foo' if there were
        two or more partial matches before the exact match in the list
        of attributes.

    o   Rdconv now creates direct HTML hyperlinks when linking to
        documentation in the same package.  The code now ensures that
        links which can be resolved within the package are so resolved,
        even when there are possible resolutions in other packages.

    o   If readBin(what=character()) is used incorrectly on a file which
        does not contain C-style character strings, warnings (usually
        many) are now given.

    o   Building libR.so with the zlib in the R sources was not
        finding the local zlib headers.

    o   system(intern=TRUE) has an undocumented line length limit of
        119 chars both on Unix and Windows.  The limit is now 8096 and
        documented.  On Unix (only) every 120th character used to be
        discarded.

    o   plot.POSIX[cl]t were not passing graphics parameters on to
        axis.POSIXct.

    o   On some HP-UX systems, installed scripts were not executable
        when using the BSD-compatible install system program found by
        configure.  We now always use install-sh on HP-UX. (PR#2091)

    o   c() was converting NA names to "NA": now proper NA strings are
        used wherever possible. (PR#2358)

    o   A typo was causing segfaults when using data.entry under SuSE.



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Fri Jan 10 17:21:08 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 10 17:21:08 2003
Subject: [R] R-1.6.2 is released
In-Reply-To: <x2adi9rogm.fsf@biostat.ku.dk>
References: <x2adi9rogm.fsf@biostat.ku.dk>
Message-ID: <x2wuldq8rv.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:


> Here's the relevant part of the NEWS file:
> 
> 
>                 CHANGES IN R VERSION 1.6.2

Sorry, not quite... This is it:


                CHANGES IN R VERSION 1.6.2


BUG FIXES

    o   plot.stepfun() now obeys a `ylim=.' specification.

    o   removeClass() does a better job of removing inheritance
        information.

    o   setIs() will not allow mismatched representations between two
        classes (without an explicit coerce method).

    o   The code underlying polygon drawing contained a memory leak.
        This showed up in persp, but did not affect other graphics
        functions.  It is now possible to draw big DEMs.

    o   logLik.nls() gave wrong df. (PR#2295)

    o   rbind() with a mixture of data frames and matrices treated the
        matrices as vectors. (PR#2266)

    o   stripchart(method="stack") was not handling missing values. (PR#2018)

    o   Arithmetic functions such as log() lost the object bit from
        classed objects if coercion was needed. (PR#2315)

    o   exp_rand would go into an infinite loop if unif_rand returned 0.

    o   formatC(x, format="fg") could return exponential format if
        rounding pushed x over a positive power of 10. (PR#2299)

    o   attr(x, foo) used partial matching for `foo' (even though not
        documented to do so), and failed to find `foo' if there were
        two or more partial matches before the exact match in the list
        of attributes.

    o   Rdconv now creates direct HTML hyperlinks when linking to
        documentation in the same package.  The code now ensures that
        links which can be resolved within the package are so resolved,
        even when there are possible resolutions in other packages.

    o   If readBin(what=character()) is used incorrectly on a file which
        does not contain C-style character strings, warnings (usually
        many) are now given.

    o   Building libR.so with the zlib in the R sources was not
        finding the local zlib headers.

    o   system(intern=TRUE) has an undocumented line length limit of
        119 chars both on Unix and Windows.  The limit is now 8096 and
        documented.  On Unix (only) every 120th character used to be
        discarded.

    o   plot.POSIX[cl]t were not passing graphics parameters on to
        axis.POSIXct.

    o   On some HP-UX systems, installed scripts were not executable
        when using the BSD-compatible install system program found by
        configure.  We now always use install-sh on HP-UX. (PR#2091)

    o   c() was converting NA names to "NA": now proper NA strings are
        used wherever possible. (PR#2358)

    o   A typo was causing segfaults when using data.entry under SuSE.

    o   mostattributes<-() was failing to copy across dimnames when
        one component was NULL, affecting pmax() and pmin() when the
        first argument was a matrix.  (root cause of PR#2357)

    o   The pdf() device now initialises graphical parameters
        properly.  (PR#2281)

    o   Checks in the C code prevent possible memory faults when
        standardGeneric is called invalidly.

    o   Macros NEW_OBJECT (aka NEW) and MAKE_CLASS added; required by
        the .Call interface to generate arbitrary objects.

    o   Problem that prevented package tcltk from working with Tcl/Tk
        8.4 (crash on initialization) resolved.  (Notice that binaries
        may still require an older Tcl/Tk, for example on Windows).

    o   type.convert() was not getting the levels right if passed a
        character vector containing <NA>s, and `na.strings' did not
        contain "NA".  This affected read.table().

    o   Internal match function did not check for nor handle 0-length
        vectors.  (The R function match() did.)  This could cause
        type.convert() to segfault.

    o   The line length limit in output text connections has been
        raised to 8095 chars.

    o   Sweave now uses anonymous file rather than text connections
        to avoid the limits of the latter (see previous item).

    o   parsing did not work on connections when pushback was used (as
        it had never been implemented).  (PR#2396)

    o   max.col() only found NAs in the first column (typo).

    o   Added a workaround for recent versions of glibc (e.g. RedHat 8.0)
        with inconsistent mktime/localtime functions which caused
        conversion to/from POSIXct times prior to 1970-01-01 to be
        inconsistent.  On such platforms this is a run-time test to
        allow e.g. R compiled on RH7.2 to run on RH8.0.

    o   Clipping was not being reset properly between plots on the gtk()
        device (the default under the GNOME interface). (PR#2366)

    o   axis(*, fg= cc) now works (again) the same as axis(*, col = cc).


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From frederic.jean at univ-brest.fr  Fri Jan 10 17:45:03 2003
From: frederic.jean at univ-brest.fr (Fred Jean)
Date: Fri Jan 10 17:45:03 2003
Subject: [R] plot() and lines() multivariate problem
Message-ID: <200301101644.RAA03508@cassis-gw.univ-brest.fr>

Dear list

I'm trying to solve the following problem since 2 days with no success. 
Could someone help a newbie, please ?

I have a  dependant variable which is diameter of shell, and two factors
which are level on the beach (3 levels 'B', 'E' and 'H') and a hydrodynamics
indice (3 levels 1, 2 and 3)

To study diameter variations according to these factors, I may use something
like :
> mod <- lm(diameter  ~ level * hydro)

When I want to look at the graphical results of such a model on a 
scatterplot, I use

> plot(diameter ~ as.integer(hydro), col = as.integer(level))

and to draw the model lines :

> lines(as.integer(hydro)[lev=='B'], predict(mod)[lev=='B'], col = 1)
> lines(as.integer(hydro)[lev=='E'], predict(mod)[lev=='E'], col = 1)
> lines(as.integer(hydro)[lev=='H'], predict(mod)[lev=='H'], col = 1)

But sometimes, the lines are not drawn in the order of the levels of hydro but
as a *zigzag* and lines() commands seem to draw lines going from level 1
to level 3 and then back to level 2 of the x axis (hydro)

I hope this description is comprehensible. Could someone explain me how to
avoid this ?

Many thanks for giving me some of your time.

-- 
C'est curieux chez les marins, ce besoin de faire des phrases (M.A.)
----------------------------------------------------
Fred JEAN - UMR CNRS 6539 / LEMAR
Univ. Bretagne Occidentale - Inst. Univ. Europ?en de la Mer
Place Nicolas Copernic F-29280 PLOUZANE
Pho:+33 (0)2 98 49 86 38 // Fax:+33 (0)2 98 49 86 45



From bates at stat.wisc.edu  Fri Jan 10 17:57:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Jan 10 17:57:03 2003
Subject: [R] R-1.6.2 is available via rsync
In-Reply-To: <x2adi9rogm.fsf@biostat.ku.dk>
References: <x2adi9rogm.fsf@biostat.ku.dk>
Message-ID: <6rr8blhrro.fsf@bates4.stat.wisc.edu>

Sources for R-1.6.2 are now available via rsync at rsync.r-project.org

$ rsync rsync.r-project.org::
r-release      	R-1.6.2 sources (current released version - approx 30 MB)
r-patched      	R sources (patched released version - approx 30 MB)
r-devel        	R sources (development version)
r-manuals      	Development sources for manuals for R
r-recommended  	Sources for recommended R packages
xlispstat      	xlispstat sources (development version) CVS tree (approx 12 MB)
CRAN           	Complete CRAN ftp area
Bioc-release   	Bioconductor sources (current release version)
Bioc-devel     	Bioconductor sources (development version)
GGobi          	GGobi sources (devel version)
omega-cvs      	Omega Project for Statistical Computing CVS tree
r-project-web  	Web pages for www.r-project.org and mirrors
Omegahat       	Complete ftp archive for Omegahat



From sway at tanox.com  Fri Jan 10 18:01:02 2003
From: sway at tanox.com (Shawn Way)
Date: Fri Jan 10 18:01:02 2003
Subject: [R] Normal Distribution Moments
Message-ID: <2F3262756375D411B0CC00B0D049775DAFB251@exchange.tanox.com>

I'm generally beating my head against the wall in attempting to determine
the Mean and Standard deviation for the distribution of ranges in normal
samples.

Any hints or thoughts?


Shawn Way



From p.dalgaard at biostat.ku.dk  Fri Jan 10 18:17:35 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 10 18:17:35 2003
Subject: [R] R-1.6.2 is released
In-Reply-To: <3E1EF8A0.F010C41F@bank-banque-canada.ca>
References: <x2adi9rogm.fsf@biostat.ku.dk>
	<3E1EF8A0.F010C41F@bank-banque-canada.ca>
Message-ID: <x2k7hdq670.fsf@biostat.ku.dk>

Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:

> Peter
> 
> When I the URL in your message I am getting:
> 
> <H1>Not Found</H1>
> The requested URL /pub/CRAN/src/base/R-1.6.2.tgz was not found on this
> server.<P>
> <HR>
> <ADDRESS>Apache/1.3.26 Server at franz.stat.wisc.edu Port 80</ADDRESS>
> 

Something got changed, it seems. Try

http://cran.us.r-project.org/src/base/R-1.6.2.tgz

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Fri Jan 10 18:26:02 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Jan 10 18:26:02 2003
Subject: [R] plot() and lines() multivariate problem
References: <200301101644.RAA03508@cassis-gw.univ-brest.fr>
Message-ID: <3E1F02B7.65BA0A89@statistik.uni-dortmund.de>


Fred Jean wrote:
> 
> Dear list
> 
> I'm trying to solve the following problem since 2 days with no success.
> Could someone help a newbie, please ?
> 
> I have a  dependant variable which is diameter of shell, and two factors
> which are level on the beach (3 levels 'B', 'E' and 'H') and a hydrodynamics
> indice (3 levels 1, 2 and 3)
> 
> To study diameter variations according to these factors, I may use something
> like :
> > mod <- lm(diameter  ~ level * hydro)
> 
> When I want to look at the graphical results of such a model on a
> scatterplot, I use
> 
> > plot(diameter ~ as.integer(hydro), col = as.integer(level))
> 
> and to draw the model lines :
> 
> > lines(as.integer(hydro)[lev=='B'], predict(mod)[lev=='B'], col = 1)
> > lines(as.integer(hydro)[lev=='E'], predict(mod)[lev=='E'], col = 1)
> > lines(as.integer(hydro)[lev=='H'], predict(mod)[lev=='H'], col = 1)
> 
> But sometimes, the lines are not drawn in the order of the levels of hydro but
> as a *zigzag* and lines() commands seem to draw lines going from level 1
> to level 3 and then back to level 2 of the x axis (hydro)

All data must be sorted according to the hydro variable.


> I hope this description is comprehensible. Could someone explain me how to
> avoid this ?
> 
> Many thanks for giving me some of your time.

You are looking for interaction.plot(), I think, see ?interaction.plot
for details.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Fri Jan 10 18:31:04 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Jan 10 18:31:04 2003
Subject: [R] Normal Distribution Moments
References: <2F3262756375D411B0CC00B0D049775DAFB251@exchange.tanox.com>
Message-ID: <3E1F034B.BC1655AF@statistik.uni-dortmund.de>


Shawn Way wrote:
> 
> I'm generally beating my head against the wall in attempting to determine
> the Mean and Standard deviation for the distribution of ranges in normal
> samples.
> 
> Any hints or thoughts?

What's R related here?
Is this an exercise?

Uwe Ligges



From erich.neuwirth at univie.ac.at  Fri Jan 10 18:34:05 2003
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Fri Jan 10 18:34:05 2003
Subject: [R] Access to R from a remote location - follow up
References: <Pine.GSO.4.10.10301091410560.18811-100000@fisher.stat.ucla.edu>
Message-ID: <3E1ECDB4.5080900@univie.ac.at>

for keeping a job running when i log out on a unix system
i use the gnu tool
screen

it has many functions,
one being able to disconnect from a running (even interactive)
terminal session and making the process believe that you are still
connected. next time you log in, you connect to the "old" session.

so it definitely would support what you want to do.




Roger Peng wrote:

>This is possible because I've done it many times.  But I think whether or
>not your job gets killed when you log out depends on your shell/operating
>system.
>
>-roger
>_______________________________
>UCLA Department of Statistics
>rpeng at stat.ucla.edu
>http://www.stat.ucla.edu/~rpeng
>
>On Thu, 9 Jan 2003, Martin Renner wrote:
>
>  
>
>>Following up on Erick's post, does anybody know whether it is 
>>possible to start a lengthy batch-job in R, then log-out/break a 
>>dial-up connection (while R is still running) and later pick-up the R 
>>outfile?
>>    
>>



From erich.neuwirth at univie.ac.at  Fri Jan 10 18:37:32 2003
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Fri Jan 10 18:37:32 2003
Subject: [R] Access to R from a remote location
References: <8469235A83CC5C49907B3F75303F96BE0FB8B8@EXCHANGE1.Corp.Unos.Local> <20030109131741.A12660@cattell.psych.upenn.edu>
Message-ID: <3E1ED54D.2040804@univie.ac.at>

instead of realvnc you might also consider
eSVNC, available from
http://perso.wanadoo.fr/samfd/esvnc

it has one additional feature:
file transfer.

so if you need to transfer data to r from your local machine,
it might be the better solution.

Jonathan Baron wrote:

>On 01/09/03 13:12, Erick Edwards wrote:
>  
>
>>Currently, our organization grants some employees remote access to SAS
>>and other software through a secure Citrix-based network server.  We
>>would like to install R on a dedicated network server and enable remote
>>access through Citrix.  Is this possible?  If so, what additional
>>software would we need?  Any advice would be greatly appreciated.
>>    
>>
>
>I don't know about Citrix, but I have had success running R with
>VNC (http://realvnc.com).  Of course, since R is free, everyone
>who uses it can install it.  But for occasional users, like
>students doing an assignment, this works well.  Jon
>
>  
>



From bates at stat.wisc.edu  Fri Jan 10 20:37:06 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Jan 10 20:37:06 2003
Subject: [R] R-1.6.2 is released
In-Reply-To: <x2k7hdq670.fsf@biostat.ku.dk>
References: <x2adi9rogm.fsf@biostat.ku.dk>
	<3E1EF8A0.F010C41F@bank-banque-canada.ca>
	<x2k7hdq670.fsf@biostat.ku.dk>
Message-ID: <6r4r8giyqt.fsf@bates4.stat.wisc.edu>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:
> 
> > Peter
> > 
> > When I the URL in your message I am getting:
> > 
> > <H1>Not Found</H1>
> > The requested URL /pub/CRAN/src/base/R-1.6.2.tgz was not found on this
> > server.<P>
> > <HR>
> > <ADDRESS>Apache/1.3.26 Server at franz.stat.wisc.edu Port 80</ADDRESS>
> > 
> 
> Something got changed, it seems. Try
> 
> http://cran.us.r-project.org/src/base/R-1.6.2.tgzw

Ah yes, remnants of the disk crash.  Now fixed.  The URL's 

http://cran.us.r-project.org/src/base/R-1.6.2.tgz

and 

http://cvs.r-project.org/src/base/R-1.6.2.tgz

should both work.



From jgramlich at piocon.com  Fri Jan 10 20:43:03 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Fri Jan 10 20:43:03 2003
Subject: [R] Access to R from a remote location - follow up....background processes and such...
Message-ID: <009201c2b8e0$28a65650$cb3ac341@ginworks.com>

Aye, you can use the ampersand, but depending on how your shell is set up,
you're likely to kill the batch job if you log out of the shell while it is
still running.

Microsoft Terminal services, and I suspect citrix as well, has the option of
logging out but leaving the session open (for jobs to run, for instance.)

In unix, you'll want to use the ampersand (&) in your command to run a
process in the background, but you'll also want to redirect stdout and
stderr to files and then disown the process.

Have a look at this mailing list message:

http://sources.redhat.com/ml/cygwin/1998-04/msg00413.html

Another option is to run the process in a cron job...
http://www.superscripts.com/tutorial/crontab.html



From kjetil at entelnet.bo  Fri Jan 10 23:05:11 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri Jan 10 23:05:11 2003
Subject: [R] count levels per factor level
In-Reply-To: <3.0.6.32.20030110151918.00b56910@mail.anst.uu.se>
Message-ID: <3E1F0B25.21950.294186@localhost>

On 10 Jan 2003 at 15:19, Tord Snall wrote:

> Dear all,
> 
> I would be really happy for help with the following because I will treat
> many columns the same way.
> 
> nlevels per ObjektID is what I want, but nlevels returns all levels
> occurring in cpy.busk$TradArt:
> 
> buskartant<- aggregate(list(trash = cpy.busk$TradArt), list(ObjektID =
> cpy.busk$ObjektID), nlevels) 
> 
> But as you can see I use it below anyway. I could use any function instaed
> of nlevels beacuse now I just want the ObjektID in the right order.
> 
> Greg Warnes kindly helped me with this solution: 
> group.list <- split(cpy.busk$TradArt, cpy.busk$ObjektID)
> buskartant$buskartant <- sapply( group.list, function(x) length(unique(x)) )
> 
> But the probelm is that unique considers NA as a category, and there is no
> na.rm argument in unique().

What about wrapping unique in na.omit:

na.omit(unique(x))

Kjetil Halvorsen

> 
> Please give a hint.
> 
> Thanks a lot in advance!
> 
> Sincerely,
> Tord
> 
> -----------------------------------------------------------------------
> Tord Sn?ll
> Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
> Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
> Villav?gen 14			
> SE-752 36 Uppsala, Sweden
> Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
> Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
> Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
> E-mail: Tord.Snall at ebc.uu.se
> Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From edd at debian.org  Sat Jan 11 05:04:03 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat Jan 11 05:04:03 2003
Subject: [R] Debian packages for R-1.6.2 released
In-Reply-To: <x2adi9rogm.fsf@biostat.ku.dk>
References: <x2adi9rogm.fsf@biostat.ku.dk>
Message-ID: <20030111040248.GA13518@sonny.eddelbuettel.com>

Debian packages for the Intel i386 platform have been uploaded to Debian's
master archive server. These packages have been built on Debian's 'testing'
release and will install and run on any 'testing' or 'unstable' system.

Debian 'unstable' packages for most of the other eleven hardware platforms
should be built during the night. 

Intel i386 packages for the more recent Debian 3.0 ('stable') release will
be built over the weekend.  

Regards,  Dirk

Files:
 096452016de9240288b2d21bed604012 1048 math optional r-base_1.6.2-1.dsc
 174e6280aa2f2102388ca9c7930b1843 8659106 math optional r-base_1.6.2.orig.tar.gz 
 8055e3bdfa65d531828dcd5f14300af9 6798 math optional r-base_1.6.2-1.diff.gz
 4f5c91a25dc2f17a78c6045921745ce0 4893338 math optional r-base-core_1.6.2-1_i386.deb
 dae9b95d99ab90c70226ea9ba600bbbd 43134 math optional r-gnome_1.6.2-1_i386.deb
 9ea88b758856bf4a1d43e17cdc064031 119940 math optional r-mathlib_1.6.2-1_i386.deb
 be5cb07b6d462240303eb06cffdc119c 3935108 math optional r-recommended_1.6.2-1_i386.deb
 3300604817c35b1fce7bf18e20584d58 14046 math optional r-base_1.6.2-1_all.deb
 2a903d1d11835881bc76b79f38ef8904 1442 devel optional r-base-dev_1.6.2-1_all.deb 
 e3fc89a5f49e5f1288d71edee6c7ad30 779396 math extra r-base-html_1.6.2-1_all.deb
 48a031ba1725ef57c89670ee717316e6 722702 math extra r-base-latex_1.6.2-1_all.deb 
 234c77226c5906253fafd12badc5bedb 4980892 doc optional r-doc-pdf_1.6.2-1_all.deb 
 d29587c5a22993172222f729bafb752f 299764  doc optional r-doc-html_1.6.2-1_all.deb 
 ce0008a4426938064c7bbc471b182415 310398 doc optional r-doc-info_1.6.2-1_all.deb

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr



From jeanhee.chung at yale.edu  Sat Jan 11 06:33:03 2003
From: jeanhee.chung at yale.edu (J C)
Date: Sat Jan 11 06:33:03 2003
Subject: [R] pairs
In-Reply-To: <Pine.GSO.4.31.0301090837480.2025-100000@toucan.stats>
References: <4.1.20030109032512.0095be40@jc363.mail.yale.edu>
Message-ID: <4.1.20030110042518.00960810@jc363.mail.yale.edu>


>1) I suggest you try a postscript() device, and convert later if you need
>to.  Expect a very large file size.

Dear Dr. Ripley,

Thank you!  Postscript was able to finish the job (bitmap killed itself.)
The filesizes are indeed large: 1.4G and requiring over two hours to
display by gv, but ultimately viewable.  I'm new to manipulating ps files
but hopefully I can find a fast way to convert the files into a small
format. I found an archived message of yours that suggested not to use
pch="." as a symbol  for graphing large datasets, and upon experimentation
I found that the default symbol, pch=21, seemed to produce the smallest
files for some sets of test data when compared with some other symbols.
Running "pch=21, cex=0.35" produced a fairly small point but consumed much
less space than pch="."   Is this the best solution for producing plot
symbols that take up little room both on the plot and the hard drive?

>Sounds like the problem is in your X server and not in R.  I've seen this
>with Xfree (and don't use that myself on Linux).
It's possible... however, I wouldn't know how to fix it from that end,
either...

>2) Don't plot all the points. You say you have a `very large dataset'. In 
>statistics, we give numbers, not vague descriptions. However, with what 
>that means to me (many millions of rows) a scatterplot of a very large 
>dataset is going to be mainly black at least in places. (We've 
>experienced that with 1.4 million points, for example.) That's not a good 
>way to display the data. Either use a density plot, or if you are 
>interested in outliers, thin the centre. We did this by estimating a 
>density phat, then randomly selecting points with probability min(1, 
>const/phat(x)) for a suitable `const'

I have a set of textfiles, each containing a  450,000 x 41 matrix (1.845
million datapoints)  and roughly 300M. Indeed, the scatterplots are
overprinted, but I am interested in getting a "feel" for the data before
charging ahead. The data (measurements on artificial phylogenetic trees)
were produced by simulation and although I have been running checks all
along I wanted to make sure that my simulations weren't producing any
strange outliers or oddly shaped distributions. On the other hand, I had no
real guess as to what the data would look like or even what variables would
show strong correlations. Since many of these datapoints are from repeats,
I was in fact able to discern a lot of pattern, rather than getting
all-black plots.   

Using both a density plot and a thinned plot may be the way to go, if I
don't find a way to shrink down the graphs.  I hoped that "pairs" would be
a fast, one-line way to take in all my data at once, but of course nothing
has been that easy with all this data. 

Jean



From Hicham.Zmarrou at student.uva.nl  Sat Jan 11 12:23:02 2003
From: Hicham.Zmarrou at student.uva.nl (H. Zmarrou)
Date: Sat Jan 11 12:23:02 2003
Subject: [R] any plot ?
Message-ID: <790f527913f0.7913f0790f52@student.uva.nl>

Dear R-ers:
I'm sorry to disturb you, I want just ask if R can plot a given  
complicated density function. I mean if we have the expression of the 
density en we want to see how it's look like? and this is a density 
with two variables thus it's a 3D plot  

Thank you very much
Hicham Amsterdam



From nusbj at hotmail.com  Sat Jan 11 13:21:02 2003
From: nusbj at hotmail.com (Zhen Pang)
Date: Sat Jan 11 13:21:02 2003
Subject: [R] beta-binomial
Message-ID: <F54yrYrZuvbUCwBp9ev00002100@hotmail.com>


Does anyone have R functions or library to fit a beta-binomial distribution 
with glm? Thanks.




From kjetil at entelnet.bo  Sat Jan 11 14:40:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat Jan 11 14:40:03 2003
Subject: [R] any plot ?
In-Reply-To: <790f527913f0.7913f0790f52@student.uva.nl>
Message-ID: <3E1FE64E.24305.248C81@localhost>

On 11 Jan 2003 at 12:22, H. Zmarrou wrote:

Hola!

You need persp, and for the following example, library(mvtnorm) (from 
CRAN)

> x <- seq(-3,3, length=200)
> y <- seq(-3,3,length=200)
> z <- matrix(0, 200, 200)
> for (i in 1:200) for (j in 1:200) {
+    z[i,j] <- dmvnorm(c(x[i],y[j]), c(0,0), 
matrix(c(1,0.5,0.5,1),2,2)) }
> persp(x,y,z)


Kjetil Halvorsen

> 
> Dear R-ers:
> I'm sorry to disturb you, I want just ask if R can plot a given  
> complicated density function. I mean if we have the expression of the 
> density en we want to see how it's look like? and this is a density 
> with two variables thus it's a 3D plot  
> 
> Thank you very much
> Hicham Amsterdam
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Sat Jan 11 14:45:32 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat Jan 11 14:45:32 2003
Subject: [R] beta-binomial
In-Reply-To: <F54yrYrZuvbUCwBp9ev00002100@hotmail.com>
Message-ID: <3E1FE64E.11297.248C23@localhost>

On 11 Jan 2003 at 20:20, Zhen Pang wrote:

You can finf the beta-binomila distribution in one of Jim Lindsay's 
libraries, in rmutil (dbetabinom      Density of Beta Binomial 
Distribution) and in repeated (biv.betab       Bivariate Beta-
binomial Regression). If you don't want to fit a regression model, 
just a distribution, you could combine with fitdistr in package MASS. 
An example:

> x <- rbetabinom(100, 10, 0.3,3)
> fitdistr(x, dbetabinom, list(m=0.5, s=4), size=10, method="L-BFGS-B",
     lower=c(0,0), upper=c(1,Inf) )
       m            s     
  0.22454182   4.39593104 
 (0.02145044) (1.01358666)

Kjetil Halvorsen


> 
> 
> Does anyone have R functions or library to fit a beta-binomial distribution 
> with glm? Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rrsilva at ib.usp.br  Sat Jan 11 17:16:02 2003
From: rrsilva at ib.usp.br (Rogerio Rosa da Silva)
Date: Sat Jan 11 17:16:02 2003
Subject: [R] data import
Message-ID: <20030111140614.49zzhu@mosca.ib.usp.br.ib.usp.br>

 Hello,

I'm a new user of R, and unsure of why I'm getting an

error reading external files on my Mac OS 8.6 machine.

I've read through posts that would seem related (and 'R

Import/Export' and 'Introduction to R') but to no avail.

If anyone has any  suggestions, I'd be very grateful. Here's the problem:

When I enter the command:

> guilds <- read.table(file = "/untitled.teste.txt")

I get the message:

> Error in file(file, "r") : unable to open connection

I'm sure this is just a simple matter but I'm perplexed.

Thanks for any suggestions,

Rog?rio R. Silva


--
Rogerio Rosa da Silva



From rpeng at stat.ucla.edu  Sat Jan 11 18:16:02 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Sat Jan 11 18:16:02 2003
Subject: [R] data import
In-Reply-To: <20030111140614.49zzhu@mosca.ib.usp.br.ib.usp.br>
Message-ID: <Pine.GSO.4.10.10301110909120.3727-100000@quetelet.stat.ucla.edu>

If you're using Mac OS 8.6 then you can't use / as a path separator
(unless that is part of the filename?).  Maybe try specifying the full
path to the file using the file.path() function.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Sat, 11 Jan 2003, Rogerio Rosa da Silva wrote:

> 
>  Hello,
> 
> I'm a new user of R, and unsure of why I'm getting an
> 
> error reading external files on my Mac OS 8.6 machine.
> 
> I've read through posts that would seem related (and 'R
> 
> Import/Export' and 'Introduction to R') but to no avail.
> 
> If anyone has any  suggestions, I'd be very grateful. Here's the problem:
> 
> When I enter the command:
> 
> > guilds <- read.table(file = "/untitled.teste.txt")
> 
> I get the message:
> 
> > Error in file(file, "r") : unable to open connection
> 
> I'm sure this is just a simple matter but I'm perplexed.
> 
> Thanks for any suggestions,
> 
> Rogério R. Silva
> 
> 
> --
> Rogerio Rosa da Silva
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From dmurdoch at pair.com  Sat Jan 11 20:02:12 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat Jan 11 20:02:12 2003
Subject: [R] Windows build of 1.6.2 uploaded to CRAN
Message-ID: <u5p02vk98pd6ak9c74g9bnalfaksh2g9k3@4ax.com>

I've just uploaded the build of the new R 1.6.2 release to CRAN.  It
will soon be visible there in 

 http://www.cran.r-project.org/bin/windows/base

and by Monday should be available on all the mirrors.

See the CHANGES file for windows-specific news about this release.  A
number of minor bugs have been fixed.

One change should help in debugging external code:  dyn.load now
checks whether or not the DLL it just loaded has messed with the
floating point control word.  This may turn up bugs in old code that
have been hidden for a long time, since the effects of an FPU control
word change are fairly subtle. 

It is also likely to turn up cases where video drivers are messing
with the FPU control word.  

If you see messages like

>Warning message: 
>DLL attempted to change FPU control word from 8001f to 9001f

look at the dyn.load help file, and if you still don't know how to fix
it, feel free to write to me for help.

Duncan Murdoch



From james.lindsey at luc.ac.be  Sat Jan 11 20:12:02 2003
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Sat Jan 11 20:12:02 2003
Subject: [R] beta-binomial
In-Reply-To: <F54yrYrZuvbUCwBp9ev00002100@hotmail.com> from "Zhen Pang" at Jan 11, 2003 08:20:23 PM
Message-ID: <200301111911.UAA14136@luc.ac.be>

> 
> 
> 
> Does anyone have R functions or library to fit a beta-binomial distribution 
> with glm? Thanks.

You can fit it exactly, instead of the approximate glm way, using my
gnlr function in my gnlm library at

www.luc.ac.be/~jlindsey/rcode.html

Jim



From langensk at fas.harvard.edu  Sat Jan 11 21:31:03 2003
From: langensk at fas.harvard.edu (langensk@fas.harvard.edu)
Date: Sat Jan 11 21:31:03 2003
Subject: [R] Matching with the function "matchCases"
Message-ID: <1042317015.3e207ed71790d@webmail.fas.harvard.edu>

Dear all,

I would like to perform a simple matching. The few cases should be matched 
with one or several controls that are similar to the cases with respect to one 
variable. I have tried to use the function "matchCases" without success; my 
program does not recognize this function. The function matchCases does not 
seem to be downloadable from CRAN, and my version has been resently updated. I 
would be very happy if someone knows the answer to my problem.

Thanks in advance,
Sophie



From rexbryan1 at attbi.com  Sat Jan 11 22:08:03 2003
From: rexbryan1 at attbi.com (RexBryan)
Date: Sat Jan 11 22:08:03 2003
Subject: [R] plotting and unplotting lines in  R
Message-ID: <000001c2b9b6$033470b0$3182fd0c@dell1700>

I would like to plot and unplot a line to a graph using R's line
command.    This would allow for sequentially trying different plotted
functions for a visual fit.  Is there a way to do this?

Rex



From fharrell at virginia.edu  Sun Jan 12 03:19:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sun Jan 12 03:19:03 2003
Subject: [R] Matching with the function "matchCases"
In-Reply-To: <1042317015.3e207ed71790d@webmail.fas.harvard.edu>
References: <1042317015.3e207ed71790d@webmail.fas.harvard.edu>
Message-ID: <20030111211802.1b377594.fharrell@virginia.edu>

On Sat, 11 Jan 2003 15:30:15 -0500
langensk at fas.harvard.edu wrote:

> 
> Dear all,
> 
> I would like to perform a simple matching. The few cases should be matched 
> with one or several controls that are similar to the cases with respect to one 
> variable. I have tried to use the function "matchCases" without success; my 
> program does not recognize this function. The function matchCases does not 
> seem to be downloadable from CRAN, and my version has been resently updated. I 
> would be very happy if someone knows the answer to my problem.
> 
> Thanks in advance,
> Sophie

matchCases is in the Hmisc package.  See
http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html

Hmisc is not on CRAN yet.

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From sway at tanox.com  Sun Jan 12 03:56:03 2003
From: sway at tanox.com (Shawn Way)
Date: Sun Jan 12 03:56:03 2003
Subject: FW: [R] Normal Distribution Moments
Message-ID: <2F3262756375D411B0CC00B0D049775DAFB255@exchange.tanox.com>

A little more information - I'm trying to write an SPC package for R.  I
havemost of the calculations determined for the package but for the Xbar
upper and lower limits, I need to calculate mean and variance for sample
size using the normal distribution.

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: Friday, January 10, 2003 11:31 AM
To: Shawn Way
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Normal Distribution Moments




Shawn Way wrote:
> 
> I'm generally beating my head against the wall in attempting to 
> determine the Mean and Standard deviation for the distribution of 
> ranges in normal samples.
> 
> Any hints or thoughts?

What's R related here?
Is this an exercise?

Uwe Ligges



From maj at stats.waikato.ac.nz  Sun Jan 12 04:13:02 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Sun Jan 12 04:13:02 2003
Subject: [R] likelihood and score interval estimates for glms
Message-ID: <3E20DD16.9060808@stats.waikato.ac.nz>

G'day list!

I'm thinking about programming likelihood and score intervals for 
generalized linear models in R based on the paper "On the computation of 
likelihood ratio and score test based confidence intervals in 
generalized linear models" by Juha Alho (1992) (Statistics in Medicine, 
11, 923-930).

Being lazy, I thought that I would ask if anyone else on the list has 
already done this? (or something equivalent)

Cheers,

Murray Jorgensen

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From barano_s at molgen.mpg.de  Sun Jan 12 05:46:03 2003
From: barano_s at molgen.mpg.de (Serguei)
Date: Sun Jan 12 05:46:03 2003
Subject: [R] Loops Sweave and Many Figures
Message-ID: <000b01c2b9f7$fa44d1b0$e4130e8d@molgen.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030112/6ff79f79/attachment.pl

From asone at latte.harvard.edu  Sun Jan 12 09:10:03 2003
From: asone at latte.harvard.edu (asone@latte.harvard.edu)
Date: Sun Jan 12 09:10:03 2003
Subject: [R] Problem about Rprof()  (Windows build  1.6.2)
Message-ID: <000001c2ba11$fa2e8bc0$0f21da18@hmdcvdcas>

Dear R users:

I have a problem about Rprof() on R for windows (Version 1.6.2
(2003-01-10)). 

When I tried to run an R program, which yields non-empty profiling
results with Rcmd Rprof on R (windows: Version 1.5.0 Patched
(2002-06-12)),  I got the following empty result:


Each sample represents 0.01 seconds.
Total run time:  seconds.

Total seconds: time spent in function and callees.
Self seconds: time spent in function alone.

   %       total       %       self
 total    seconds     self    seconds    name

   %       self        %       total
 self     seconds    total    seconds    name


summaryRprof() was also tried, but what I got is the following message: 

> summaryRprof(filename = "Rprof_xtab_none.out")
Error in summaryRprof(filename = "Rprof_xtab_none.out") : 
        no events were recorded
>

I noticed this problem when I tested the same R program on R (windows)
Version 1.6.1 last year.

Did I miss some important announcement concerning Rprof() between R 1.5.
0 and 1.6.1?


My platform-R_version information is as follows:

sysname=Windows
release=NT 5.0
version=(build 2195) Service Pack 3
machine=x86

platform=i386-pc-mingw32
arch=i386
os=mingw32
system=i386, mingw32
status=
major=1
minor=6.2
year=2003
month=01
day=10
language=R


Akio Sone
HU-MIT data center



From kjetil at entelnet.bo  Sun Jan 12 12:32:02 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sun Jan 12 12:32:02 2003
Subject: [R] likelihood and score interval estimates for glms
In-Reply-To: <3E20DD16.9060808@stats.waikato.ac.nz>
Message-ID: <3E2119B0.15228.A88C7@localhost>

On 12 Jan 2003 at 16:12, Murray Jorgensen wrote:

I believe that confint() in the MASS package does likelihood based 
confidence intervals, among others for models of class glm.
I don't know about score intervals.

Kjetil Halvorsen

> G'day list!
> 
> I'm thinking about programming likelihood and score intervals for 
> generalized linear models in R based on the paper "On the computation of 
> likelihood ratio and score test based confidence intervals in 
> generalized linear models" by Juha Alho (1992) (Statistics in Medicine, 
> 11, 923-930).
> 
> Being lazy, I thought that I would ask if anyone else on the list has 
> already done this? (or something equivalent)
> 
> Cheers,
> 
> Murray Jorgensen
> 
> -- 
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz                                Fax 7 838 4155
> Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Sun Jan 12 12:45:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sun Jan 12 12:45:03 2003
Subject: [R] plotting and unplotting lines in  R
In-Reply-To: <000001c2b9b6$033470b0$3182fd0c@dell1700>
Message-ID: <3E211CBB.26161.166C7A@localhost>

On 11 Jan 2003 at 14:11, RexBryan wrote:

plot(1:10, 1:10, type="n")
lines(1:10, 1:10)
lines(1:10, 1:10, color="white")

Kjetil Halvorsen

> I would like to plot and unplot a line to a graph using R's line
> command.    This would allow for sequentially trying different plotted
> functions for a visual fit.  Is there a way to do this?
> 
> Rex
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ghosh at science.unitn.it  Sun Jan 12 13:54:03 2003
From: ghosh at science.unitn.it (Ghosh Mini)
Date: Sun Jan 12 13:54:03 2003
Subject: [R] Request
Message-ID: <Pine.OSF.4.44.0301121352320.21317-100000@omega.science.unitn.it>

Dear Sir/Madam,

I am opening emacs in red hat linux, it is giving message at the bottom

'Error in init file: end of file during parsing'

i am not getting why this message.

Actually i am trying to run R through emacs and when i am giving command
M-x R it is saying 'No match'.

So not getting where is the problem, in emacs or in R???

If possible pl. help me.

Regards,
mini



From baron at cattell.psych.upenn.edu  Sun Jan 12 14:30:03 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sun Jan 12 14:30:03 2003
Subject: [R] Request
In-Reply-To: <Pine.OSF.4.44.0301121352320.21317-100000@omega.science.unitn.it>; from ghosh@science.unitn.it on Sun, Jan 12, 2003 at 01:53:14PM +0100
References: <Pine.OSF.4.44.0301121352320.21317-100000@omega.science.unitn.it>
Message-ID: <20030112082910.A9935@cattell.psych.upenn.edu>

On 01/12/03 13:53, Ghosh Mini wrote:
>
>Dear Sir/Madam,
>
>I am opening emacs in red hat linux, it is giving message at the bottom
>
>'Error in init file: end of file during parsing'
>
>i am not getting why this message.
>
>Actually i am trying to run R through emacs and when i am giving command
>M-x R it is saying 'No match'.
>
>So not getting where is the problem, in emacs or in R???

Looks like emacs, not R.

One problem is what it says, in your emacs init file, which is
called .emacs.  Look at it.

Another problem - or possibly the same - is that you need ESS in
order to run R this way.  You need to install ESS, and you need a
line in your .emacs file like
(load "/usr/share/emacs/ess-5.1.24/lisp/ess-site")
You may already have this, but, if so, some other error in the
.emacs file is preventing this from working.

If you do not have ESS, get it from
http://software.biostat.washington.edu/ess/
(But see also http://stat.ethz.ch/ESS/ for more information.)
Of course, the "load" line above assumes that ESS is installed in
/usr/share/emacs.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From Jmshttn at aol.com  Sun Jan 12 14:57:03 2003
From: Jmshttn at aol.com (Jmshttn@aol.com)
Date: Sun Jan 12 14:57:03 2003
Subject: [R] Help with Program
Message-ID: <7d.3395bd21.2b52ce0b@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030112/14ab40d1/attachment.pl

From Friedrich.Leisch at ci.tuwien.ac.at  Sun Jan 12 17:15:03 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Sun Jan 12 17:15:03 2003
Subject: [R] Loops Sweave and Many Figures
In-Reply-To: <000b01c2b9f7$fa44d1b0$e4130e8d@molgen.mpg.de>
References: <000b01c2b9f7$fa44d1b0$e4130e8d@molgen.mpg.de>
Message-ID: <15905.38317.561589.899169@celeborn.leisch.at>

>>>>> On Sun, 12 Jan 2003 06:03:41 +0100,
>>>>> Serguei  (S) wrote:

  > Is it any way?
  > This code doesn't work:
  > %%%%%%%%%%%%%%%
  > \multido{}{10}{
  > <<fig=T>>=
  > ...
  > @
  > }


\multido{}{10}{
<<fig=T,echo=F>>=
plot(1:10)
@ 
}


works while the samle with "echo=T" does not ... seems like multido
cannot hande verbatim enveronments, but that's hardly Sweave's fault.


> %%%%%%%%%%%%%%%
  > Or:
  > %%%%%%%%%%%%%%%
  > <<1, fig=T>>=
  > ...
  > @
  > <<>>=
  > <<1>>
  > @
  > %%%%%%%%%%%%%%%

what is that supposed to do? if you want a figure also resulting from
the second chunk you need

<<1, fig=T>>=
...
@
<<fig=T>>=
<<1>>
@

or

\SweaveOpts{fig=T}

<<1>>=
...
@
<<fig=T>>=
<<1>>
@



Hope this helps,

-- 
-------------------------------------------------------------------
                        Friedrich  Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------



From carstens at verticalsolutions.com  Sun Jan 12 19:21:03 2003
From: carstens at verticalsolutions.com (Henry Carstens)
Date: Sun Jan 12 19:21:03 2003
Subject: [R] data import
In-Reply-To: <20030111140614.49zzhu@mosca.ib.usp.br.ib.usp.br>
Message-ID: <BA46F119.22EAA%carstens@verticalsolutions.com>

on 1/11/03 9:10 AM, Roger Peng wrote:

> Maybe try specifying the full
> path to the file using the file.path() function.

Or use the Change Directory menu command to change the directory to match
the file location and omit all 'path' items.


--h



From kjetil at entelnet.bo  Sun Jan 12 23:51:02 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sun Jan 12 23:51:02 2003
Subject: [R] Rcmd check on windows (XP)
Message-ID: <3E21B8E1.18319.E0F357@localhost>

Hola!

This is windows XP, rw1062. When running 
Rcmd check 
on a package, I get (among others) the message:

ERROR: Environment text <enclosed in {}> found in
\title{...}. The title must be plain text!

but it does not mention in which .Rd file this error was found, 
so it was necessry to look through about 50 files.

It would be usefull if the error message mentioned the file name.

Kjetil Halvorsen



From RexBryan1 at attbi.com  Mon Jan 13 00:02:02 2003
From: RexBryan1 at attbi.com (Rex_Bryan@urscorp.com)
Date: Mon Jan 13 00:02:02 2003
Subject: [R] Ideas needed on automation of R
Message-ID: <001201c2ba8f$1ff2f120$3182fd0c@dell1700>

 I need some guidance on what is the best way to automate R  I am aware of
Rterm.

First question:  Is it true that R is not currently OLE accessible under
Windows 2000?
Second question: Is there an R command that echoes all R Console results to
a run log system file?

My first attempt to write a run log file is the example from the R Data
Inport/Export documentation.

> zz<- "textConnection("ex.lm.out","w")
> example(lm, prompt.echo = ">")
> sink()
> close(zz)

 I can't find the file "ex.lm.out" anywhere on my system's drive.  But the
file exists in R as confirmed by the next command:

> cat(ex.lm.out, sep="\n")

Rex



From p.connolly at hortresearch.co.nz  Mon Jan 13 01:15:03 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Mon Jan 13 01:15:03 2003
Subject: [R] R and file size
In-Reply-To: <Pine.LNX.4.31.0301071049490.17764-100000@gannet.stats>
References: <se19a531.018@mail.marketsolutionsgroup.com> <Pine.LNX.4.31.0301071049490.17764-100000@gannet.stats>
Message-ID: <20030113001343.GB13861@hortresearch.co.nz>

On Tue, 07-Jan-2003 at 10:52AM +0000, ripley at stats.ox.ac.uk wrote:

|> On Mon, 6 Jan 2003, Greg Blevins wrote:
|> 
|> > I will be involved with an analysis based on a file that will be roughly 25 meg.  Assuming I have enough memory, is their any limitations to using R on a file this large.
|> 
|> That's a small file!
|> 
|> Seriously, people work on datasets of 100Mb or so in 1Gb (or even 512Mb)
|> machines.  However, some care is needed to select a good way to read the
|> data in (if read.table, do follow the advice on the help page), and it

My attention was drawn to said help page and noticed something rather
odd.

Usage:

     read.table(file, header = FALSE, sep = "", quote = "\"'", dec = ".",
                row.names, col.names, as.is = FALSE, na.strings = "NA",
                colClasses = NA, nrows = -1,
                skip = 0, check.names = TRUE, fill = !blank.lines.skip,
                strip.white = FALSE, blank.lines.skip = TRUE,
                comment.char = "#")

However, when I check out the function itself:

> args(read.table)
function (file, header = FALSE, sep = "", quote = "\"'", dec = ".", 
    row.names, col.names, as.is = FALSE, na.strings = "NA", skip = 0, 
    check.names = TRUE, fill = !blank.lines.skip, strip.white = FALSE, 
    blank.lines.skip = TRUE) 



Consequently, I can't set nrows to see if it would be an improvement.

> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.1              
year     2002             
month    11               
day      01               
language R   


Something simple, no doubt, but nothing I can see.

Ideas welcome.


-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From rpeng at stat.ucla.edu  Mon Jan 13 01:30:03 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon Jan 13 01:30:03 2003
Subject: [R] Ideas needed on automation of R
In-Reply-To: <001201c2ba8f$1ff2f120$3182fd0c@dell1700>
Message-ID: <Pine.GSO.4.10.10301121623360.26001-100000@quetelet.stat.ucla.edu>

Not sure about your first question.

Regarding your second question, maybe you should just sink to a file:

sink("ex.lm.out")
example(lm)
sink()

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Sun, 12 Jan 2003, Rex_Bryan at urscorp.com wrote:

>  I need some guidance on what is the best way to automate R  I am aware of
> Rterm.
> 
> First question:  Is it true that R is not currently OLE accessible under
> Windows 2000?
> Second question: Is there an R command that echoes all R Console results to
> a run log system file?
> 
> My first attempt to write a run log file is the example from the R Data
> Inport/Export documentation.
> 
> > zz<- "textConnection("ex.lm.out","w")
> > example(lm, prompt.echo = ">")
> > sink()
> > close(zz)
> 
>  I can't find the file "ex.lm.out" anywhere on my system's drive.  But the
> file exists in R as confirmed by the next command:
> 
> > cat(ex.lm.out, sep="\n")
> 
> Rex
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From RexBryan1 at attbi.com  Mon Jan 13 02:16:02 2003
From: RexBryan1 at attbi.com (Rex_Bryan@urscorp.com)
Date: Mon Jan 13 02:16:02 2003
Subject: [R] Fw: Plotting text-string real_date names at excel_date positions.
Message-ID: <011f01c2baa1$d875e060$3182fd0c@dell1700>

How do I post text-string dates along the x-axis instead of the excel_date
position values?

I would like to plot a time-series of chemical values changing with time
The first column is the internal date from excel.  This should be the x-axis
position of a graph
of the plotted data.

The second column is a text-string of date.  This should be what is posted
(instead of the excel_date).
The third column is the chemical data and this should be the position of a
point on the y-axis.
A line needs to connect the points but should break at the NA.

excel_date    real_date        chemical
36234        15-Mar-99        1.6
36302        22-May-99        0.195
36395        23-Aug-99        4.9
36475        11-Nov-99        NA
36593        8-Mar-00          3.58

Rex



From p.connolly at hortresearch.co.nz  Mon Jan 13 02:28:02 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Mon Jan 13 02:28:02 2003
Subject: [R] R and file size
Message-ID: <20030113012743.GA19993@hortresearch.co.nz>

On Mon, 13-Jan-2003 at 01:13PM +1300, Patrick Connolly wrote:

|> On Tue, 07-Jan-2003 at 10:52AM +0000, ripley at stats.ox.ac.uk wrote:
|>
|> |> On Mon, 6 Jan 2003, Greg Blevins wrote:
|> |>

|>
|> Something simple, no doubt, but nothing I can see.

Simple alright.  For some unexplained reason, I had another version of
read.table in with my local functions.  (Evidently, the nrows parameter
has been added in the last two years, from my limited investigations.)

Sorry if I alarmed anyone.

Now, if I could just imagine how that happened......

Thanks to James Holtman for a suggestion.


-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From rpeng at stat.ucla.edu  Mon Jan 13 04:18:03 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon Jan 13 04:18:03 2003
Subject: [R] Fw: Plotting text-string real_date names at excel_date
 positions.
In-Reply-To: <011f01c2baa1$d875e060$3182fd0c@dell1700>
Message-ID: <Pine.GSO.4.10.10301121907560.6567-100000@quetelet.stat.ucla.edu>

You probably want to use the `axes = FALSE' argument to plot and then
construct the axes yourself with the axis() function.  Perhaps something
like (using the real variable names, of course):

attach("mydataset")
plot(exceldate, chemical, axes = FALSE, frame.plot = TRUE, type = "l")
axis(2)
axis(1, exceldate, realdate)

This may produce an x-axis that's too crammed so you'll have to fiddle
with it so that the labels are nicely spaced.  Maybe something like

idx <- seq(1, length(exceldate), by = 2)
axis(1, exceldate[idx], realdate[idx])

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Sun, 12 Jan 2003, Rex_Bryan at urscorp.com wrote:

> How do I post text-string dates along the x-axis instead of the excel_date
> position values?
> 
> I would like to plot a time-series of chemical values changing with time
> The first column is the internal date from excel.  This should be the x-axis
> position of a graph
> of the plotted data.
> 
> The second column is a text-string of date.  This should be what is posted
> (instead of the excel_date).
> The third column is the chemical data and this should be the position of a
> point on the y-axis.
> A line needs to connect the points but should break at the NA.
> 
> excel_date    real_date        chemical
> 36234        15-Mar-99        1.6
> 36302        22-May-99        0.195
> 36395        23-Aug-99        4.9
> 36475        11-Nov-99        NA
> 36593        8-Mar-00          3.58
> 
> Rex
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From rpeng at stat.ucla.edu  Mon Jan 13 04:28:03 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon Jan 13 04:28:03 2003
Subject: [R] any plot ?
In-Reply-To: <790f527913f0.7913f0790f52@student.uva.nl>
Message-ID: <Pine.GSO.4.10.10301121916570.6567-100000@quetelet.stat.ucla.edu>

You can use a few functions:  persp, contour, filled.contour, image.  Say
dens() is your density function of two variables, for example,

dens <- function(x, y) { dnorm(x) * dnorm(y) }

then you could do:

x <- seq(-3, 3, len = 40)
y <- seq(-3, 3, len = 30)
g <- expand.grid(x, y)
mat <- matrix(dens(g[,1], g[,2]), nrow = 40, ncol = 30)
image(x,y,mat)
persp(x,y,mat)
filled.contour(x,y,mat)
contour(x,y,mat)


-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Sat, 11 Jan 2003, H. Zmarrou wrote:

> 
> Dear R-ers:
> I'm sorry to disturb you, I want just ask if R can plot a given  
> complicated density function. I mean if we have the expression of the 
> density en we want to see how it's look like? and this is a density 
> with two variables thus it's a 3D plot  
> 
> Thank you very much
> Hicham Amsterdam
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Alexander.Herr at csiro.au  Mon Jan 13 05:23:02 2003
From: Alexander.Herr at csiro.au (Alexander.Herr@csiro.au)
Date: Mon Jan 13 05:23:02 2003
Subject: [R] summarizing dataframe
Message-ID: <2FE6D3D02CCDD211B80600902745F56C018D1204@exchange-tv.tvl.qld.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030113/f7f1211c/attachment.pl

From ripley at stats.ox.ac.uk  Mon Jan 13 08:50:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 13 08:50:03 2003
Subject: [R] Ideas needed on automation of R
In-Reply-To: <001201c2ba8f$1ff2f120$3182fd0c@dell1700>
Message-ID: <Pine.WNT.4.44.0301130746140.3304-100000@Reeve>

On Sun, 12 Jan 2003, Rex_Bryan at urscorp.com wrote:

>  I need some guidance on what is the best way to automate R  I am aware of
> Rterm.
>
> First question:  Is it true that R is not currently OLE accessible under
> Windows 2000?

True.  No one has announced an intention to contribute such functionality,
either.

> Second question: Is there an R command that echoes all R Console results to
> a run log system file?

No.  Why do you want to use the `R console' (presumably RGui) to do that?
Rterms is provided.

> My first attempt to write a run log file is the example from the R Data
> Inport/Export documentation.
>
> > zz<- "textConnection("ex.lm.out","w")
         ^ is an error
> > example(lm, prompt.echo = ">")
> > sink()
> > close(zz)
>
>  I can't find the file "ex.lm.out" anywhere on my system's drive.  But the
> file exists in R as confirmed by the next command:
>
> > cat(ex.lm.out, sep="\n")

No, ex.lm.out is an R object: please do read the help for textConnection().

You can sink directly to a file.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Jan 13 08:58:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon Jan 13 08:58:03 2003
Subject: [R] R and file size
In-Reply-To: <20030113001343.GB13861@hortresearch.co.nz>
Message-ID: <Pine.WNT.4.44.0301130750310.3304-100000@Reeve>

On Mon, 13 Jan 2003, Patrick Connolly wrote:

> On Tue, 07-Jan-2003 at 10:52AM +0000, ripley at stats.ox.ac.uk wrote:
>
> |> On Mon, 6 Jan 2003, Greg Blevins wrote:
> |>
> |> > I will be involved with an analysis based on a file that will be roughly 25 meg.  Assuming I have enough memory, is their any limitations to using R on a file this large.
> |>
> |> That's a small file!
> |>
> |> Seriously, people work on datasets of 100Mb or so in 1Gb (or even 512Mb)
> |> machines.  However, some care is needed to select a good way to read the
> |> data in (if read.table, do follow the advice on the help page), and it
>
> My attention was drawn to said help page and noticed something rather
> odd.
>
> Usage:
>
>      read.table(file, header = FALSE, sep = "", quote = "\"'", dec = ".",
>                 row.names, col.names, as.is = FALSE, na.strings = "NA",
>                 colClasses = NA, nrows = -1,
>                 skip = 0, check.names = TRUE, fill = !blank.lines.skip,
>                 strip.white = FALSE, blank.lines.skip = TRUE,
>                 comment.char = "#")
>
> However, when I check out the function itself:
>
> > args(read.table)
> function (file, header = FALSE, sep = "", quote = "\"'", dec = ".",
>     row.names, col.names, as.is = FALSE, na.strings = "NA", skip = 0,
>     check.names = TRUE, fill = !blank.lines.skip, strip.white = FALSE,
>     blank.lines.skip = TRUE)

That is odd, as it should give

> args(read.table)
function (file, header = FALSE, sep = "", quote = "\"'", dec = ".",
    row.names, col.names, as.is = FALSE, na.strings = "NA", colClasses = NA,
    nrows = -1, skip = 0, check.names = TRUE, fill = !blank.lines.skip,
    strip.white = FALSE, blank.lines.skip = TRUE, comment.char = "#")
NULL

I think you have a very old private version masking the real one!

> Something simple, no doubt, but nothing I can see.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From amund.tveit at idi.ntnu.no  Mon Jan 13 09:11:02 2003
From: amund.tveit at idi.ntnu.no (Amund Tveit)
Date: Mon Jan 13 09:11:02 2003
Subject: [R] Ideas needed on automation of R
References: <001201c2ba8f$1ff2f120$3182fd0c@dell1700>
Message-ID: <0a4001c2badb$331fa030$a26ef181@idi.ntnu.no>

Rex,

Maybe RPy (Python interface to R) could be of help in automating R? Logging
is then made very flexible using Python.

- http://rpy.sourceforge.net/
- http://gestalt-system.sourceforge.net/rpy_demo.html

If you combine it with py2exe you could possibly create an
windows-executable file that controls R. Then you can also use Win2K's
(scheduled) service functionality for running the application. (This is
untried though, but assumed to work).

- http://starship.python.net/crew/theller/py2exe/

Hope this helps.

Best regards,
Amund Tveit
http://www.idi.ntnu.no/~amundt/ - http://gamemining.net/

----- Original Message -----
From: "Rex_Bryan at urscorp.com" <RexBryan1 at attbi.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, January 13, 2003 12:05 AM
Subject: [R] Ideas needed on automation of R


> I need some guidance on what is the best way to automate R  I am aware of
> Rterm.
>
> First question:  Is it true that R is not currently OLE accessible under
> Windows 2000?
> Second question: Is there an R command that echoes all R Console results
to
> a run log system file?
>
> My first attempt to write a run log file is the example from the R Data
> Inport/Export documentation.
>
> > zz<- "textConnection("ex.lm.out","w")
> > example(lm, prompt.echo = ">")
> > sink()
> > close(zz)
>
>  I can't find the file "ex.lm.out" anywhere on my system's drive.  But the
> file exists in R as confirmed by the next command:
>
> > cat(ex.lm.out, sep="\n")
>
> Rex
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Tuomas.Kallunki at sofi.fi  Mon Jan 13 09:20:03 2003
From: Tuomas.Kallunki at sofi.fi (Kallunki, Tuomas)
Date: Mon Jan 13 09:20:03 2003
Subject: [R] Extensively slowing for(i in 1:400) statement
Message-ID: <21D277B0B79DD311A46700600854994B4B35D1@NTSERVER2>

Hello!

Here is what I have tried to do:

1. I have 400 time series
2. pull one serie at a time from ODBC
3. calculate some descriptives and regressions (about 50 statistic per
serie)
4. store the results in the data frame

The problem:

The time consumed in each loop seems to grow linearly. I used the date()
function for timing each loop and time spent in loop seems to grow at the
speed of 0.6 * i (seconds), which implies that the last loop takes 245
seconds (first loop: 5 seconds). For the first 40 loop the ODBC down load
took 0-1 seconds, so I don't belive that ODBC connection is the problem. I
am running it in a computer with AMD 800Mhz/512 000 KB which should be
enough capacity. For example simple for(i in 1:100 000) statement runs very
smoothly? I will probably have to do several runs and I don't have the time
to wait half a day per run.

Can anyone tell what is the problem? 
Is it hardware related? 
Can the for() statement too long?
Do I have use rm() statement after each object becomes useless?
...?

Thanks,

Tuomas Kallunki



From phgrosjean at sciviews.org  Mon Jan 13 10:19:03 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Mon Jan 13 10:19:03 2003
Subject: [R] Ideas needed on automation of R
In-Reply-To: <Pine.WNT.4.44.0301130746140.3304-100000@Reeve>
Message-ID: <MABBLJDICACNFOLGIHJOIEIGDCAA.phgrosjean@sciviews.org>

Rex_Bryan at urscorp.com wrote:

>  I need some guidance on what is the best way to automate R  I am aware of
> Rterm.
>
> First question:  Is it true that R is not currently OLE accessible under
> Windows 2000?

You will find a (D)Com server for R at
http://cran.r-project.org/contrib/extra/dcom. Otherwise, there will be a
sligthly more complex (asynchronous communication, time out management,...)
OLE server in SciViews, http://www.sciviews.org. It is not distributed yet,
but I plan to release it before mid-March or so.

>...

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oceanologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



From Timur.Elzhov at jinr.ru  Mon Jan 13 11:03:02 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Mon Jan 13 11:03:02 2003
Subject: [R] Evaluating expressions from within C code
Message-ID: <20030113094251.GA432@pcf004.jinr.ru>

Dear R experts!

I want to evaluate expressions from within C code. For instance,
I want this code:

    /* ============ -- C code -- ============== */
    
    #include <R.h>
    #include <Rinternals.h>
    
    SEXP foo(SEXP expr, SEXP rho)
    {
        SEXP x;
    
        PROTECT(x = allocVector(REALSXP, 1));
        REAL(x)[0] = 1;
    
        UNPROTECT(1);
    
        return eval(expr, rho);
    }
    /* ======================================== */


    .Call("foo", quote(x + 1), new.env())

to return 1 + 1 == 2. But it certainly does not work:

    .Call("foo", quote(x + 1), new.env())
    Error: Object "x" not found

and if I define x in R, it works:

    x <- 1
    .Call("foo", quote(x + 1), new.env())
    [1] 2

So, is there a way to solve my problem, namely to
find and evaluate expressions that appears in C code?

Thank you very much.

--
WBR,
Timur.



From ripley at stats.ox.ac.uk  Mon Jan 13 11:15:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan 13 11:15:03 2003
Subject: [R] Evaluating expressions from within C code
In-Reply-To: <20030113094251.GA432@pcf004.jinr.ru>
Message-ID: <Pine.LNX.4.31.0301131010150.29101-100000@gannet.stats>

You need to define x as a variable known to R in environment rho.
Hint: look at install() in R-exts.texi.  I guess you want

defineVar(install("x"), x, rho)

but please read about the alternatives.


On Mon, 13 Jan 2003, Timur Elzhov wrote:

> Dear R experts!
>
> I want to evaluate expressions from within C code. For instance,
> I want this code:
>
>     /* ============ -- C code -- ============== */
>
>     #include <R.h>
>     #include <Rinternals.h>
>
>     SEXP foo(SEXP expr, SEXP rho)
>     {
>         SEXP x;
>
>         PROTECT(x = allocVector(REALSXP, 1));
>         REAL(x)[0] = 1;
>
>         UNPROTECT(1);
>
>         return eval(expr, rho);

I'd watch where you unprotect here.  You have unprotected x before
attempting to use it.

>     }
>     /* ======================================== */
>
>
>     .Call("foo", quote(x + 1), new.env())
>
> to return 1 + 1 == 2. But it certainly does not work:
>
>     .Call("foo", quote(x + 1), new.env())
>     Error: Object "x" not found
>
> and if I define x in R, it works:
>
>     x <- 1
>     .Call("foo", quote(x + 1), new.env())
>     [1] 2
>
> So, is there a way to solve my problem, namely to
> find and evaluate expressions that appears in C code?
>
> Thank you very much.
>
> --
> WBR,
> Timur.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bitwrit at ozemail.com.au  Mon Jan 13 12:15:05 2003
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Mon Jan 13 12:15:05 2003
Subject: [R] summarizing dataframe
In-Reply-To: <2FE6D3D02CCDD211B80600902745F56C018D1204@exchange-tv.tvl.qld.csiro.au>
References: <2FE6D3D02CCDD211B80600902745F56C018D1204@exchange-tv.tvl.qld.csiro.au>
Message-ID: <20030113111407.KWFO15953.mta02.mail.mel.aone.net.au@there>

Alexander.Herr at csiro.au wrote:

Hi Listers,

> Surely, I just have a mental block and there is a more elegant way of
> creating a summary count (other than extracing it from ftable). I'd like
> to create a new data.frame containing counts of spell by loc ie have 
> three columns showing spell,loc,count. Below the data.frame...
>
> Any help appreciated
> Thanks Herry
>
>     spell loc
> 101   Parts   1
> 102 Overall   2
...

It's a bit hard to tell exactly what you want from the example. If the 
assumptions that "spell" is the name of the second column and "loc" is the 
name of the third are correct:

1) add a name for the first field
2) Use a single comma (or other separator) between your data fields

herr.df<-read.table("herr.dat",header=T,sep=",")

boggle<-as.data.frame.table(table(herr.df$spell,herr.df$loc))
Freq2<-as.numeric(boggle$Var2)*as.numeric(boggle$Freq)
aggregate(Freq2,by=list(Var1=boggle$Var1),FUN=sum)

Jim



From uth at zhwin.ch  Mon Jan 13 12:24:03 2003
From: uth at zhwin.ch (=?utf-8?Q?=22Untern=C3=A4hrer_Thomas=2C_uth=22?=)
Date: Mon Jan 13 12:24:03 2003
Subject: [R] (no subject)
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B9023E9053@lobster.zhwin.ch>

Dear experienced "users"
 
The following question arose in the context of a project : we were searching for an example how to use (interface) VC++-Code in R. We were looking for the example file  
 
cxx_0.0-x.tar.gz
 
in 
 
src\contrib\devel
 
but didn't find it. In particular our interest goes to the "windows-version" of an example  in section 4.5 (page 27) of the "writing R-extensions"-manual (which is linux-based).
 
Thanks a lot
 
tu & mw

Content Security by MailMarshal



From ripley at stats.ox.ac.uk  Mon Jan 13 14:23:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon Jan 13 14:23:03 2003
Subject: [R] Problem about Rprof()  (Windows build  1.6.2)
In-Reply-To: <000001c2ba11$fa2e8bc0$0f21da18@hmdcvdcas>
Message-ID: <Pine.WNT.4.44.0301131320010.3744-100000@gannet.stats.ox.ac.uk>

Rprof()
example(lm)
Rprof(NULL)
summaryRprof()

works perfectly here on the build I installed an hour ago.

Did you perchance forget to turn profiling off as in the third line, so the
file was not closed?


On Sun, 12 Jan 2003 asone at latte.harvard.edu wrote:

> Dear R users:
>
> I have a problem about Rprof() on R for windows (Version 1.6.2
> (2003-01-10)).
>
> When I tried to run an R program, which yields non-empty profiling
> results with Rcmd Rprof on R (windows: Version 1.5.0 Patched
> (2002-06-12)),  I got the following empty result:

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From otoomet at econ.dk  Mon Jan 13 14:31:12 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Mon Jan 13 14:31:12 2003
Subject: [R] Extensively slowing for(i in 1:400) statement
Message-ID: <200301131331.h0DDVD008170@punik.econ.au.dk>

Hi,

It sounds like a memory-related issue.  There are several caveats
which you should be aware about.


First, as you probably know, for cycles are not specially efficient in
R.  But if the calculations in the cycle are slow, then IMHO they help
to keep the code clear.  You may still consider e.g.

sapply(1:400, FUN=function(i) {s <- get.series(i); analyse.series(s) })



Second, are you making your data frame?  Perhaps the right way to do
it is

df <- vector("list", 400)
for(i in 1:400) {
 ...
 df[[i]] <- analyse.series(...)
 }
df <- as.data.frame(df)

Note, that you should define your list length before you use it.
Otherwise, I guess, if you are adding components as 
df <- data.frame(df, analyse.series...), R makes a copy of it and
thereafter deletes the old one.  It may be slow, particularily if your
objects are long.


In generaly, you need not to rm() objects after the use.  But if you
are creating many of them in the cycle, or if they are large, it may
be an advantage.  Try to understand which objects you are creating,
how big they are, how big is their memory consumption, and where
exactly your program is spending the time.  Look
system.time()  (better than date)
gc()
object.size()


There may some OS-related issues, Win95 and 98 have significantly less
capable memory management than the recent versions and Unices, AFAIK.

Have a luck!

Ott


 | From: "Kallunki, Tuomas" <Tuomas.Kallunki at sofi.fi>
 | 
 | Hello!
 | 
 | Here is what I have tried to do:
 | 
 | 1. I have 400 time series
 | 2. pull one serie at a time from ODBC
 | 3. calculate some descriptives and regressions (about 50 statistic per
 | serie)
 | 4. store the results in the data frame
 | 
 | The problem:
 | 
 | The time consumed in each loop seems to grow linearly. I used the date()
 | function for timing each loop and time spent in loop seems to grow at the
 | speed of 0.6 * i (seconds), which implies that the last loop takes 245
 | seconds (first loop: 5 seconds). For the first 40 loop the ODBC down load
 | took 0-1 seconds, so I don't belive that ODBC connection is the problem. I
 | am running it in a computer with AMD 800Mhz/512 000 KB which should be
 | enough capacity. For example simple for(i in 1:100 000) statement runs very
 | smoothly? I will probably have to do several runs and I don't have the time
 | to wait half a day per run.
 | 
 | Can anyone tell what is the problem? 
 | Is it hardware related? 
 | Can the for() statement too long?
 | Do I have use rm() statement after each object becomes useless?
 | ...?
 | 
 | Thanks,
 | 
 | Tuomas Kallunki



From jrogers at cantatapharm.com  Mon Jan 13 14:44:03 2003
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Mon Jan 13 14:44:03 2003
Subject: [R] Re: summarizing dataframe
Message-ID: <99A12772DCDEEB458B996332957B0D53011726@mercury.cantatapharm.com>

The options I know of are:

1. aggregate (in the base package), with FUN = length. But this converts
character vectors to factors, which is sometimes annoying and sometimes
dangerous.
2. summarize, in the Hmisc package (again, with FUN = length). I find
summarize to be a very useful function in general, but it has a lot of
overhead if all you want is counts. Very slow with a large data frame. 
3. Some wrapper that calls tabulate directly. I use:

table.mat <- function(x) {
  uid <- do.call("paste", as.list(x))
  count <- tabulate(factor(uid))
  x <- x[order(uid), ]
  i <- !duplicated(sort(uid))
  out <- x[i, ]
  out$Count <- count
  last <- length(out)
  o <- do.call("order", as.list(out[-last]))
  out <- out[o, ]
  dimnames(out) <- list(1:(dim(out)[1]), names(out))
  out
}

This is based on my memory of a function that I think Scott Chasalow
wrote and often used. My memory is only of what the function did, not on
the code, so Scott may have something a bit better? (I am cc'ing Scott)

 
> Message: 16
> From: Alexander.Herr at csiro.au
> To: r-help at stat.math.ethz.ch
> Date: Mon, 13 Jan 2003 14:22:23 +1000
> Subject: [R] summarizing dataframe
> 
> Hi Listers,
> 
> Surely, I just have a mental block and there is a more elegant way of
creating a 
> summary count (other than extracing it from ftable). I'd like to
create a new
> data.frame containing counts of spell by loc ie have three columns
showing
> spell,loc,count. Below the data.frame...
> 
> Any help appreciated
> Thanks Herry

Jim  

James A. Rogers, Ph.D. <rogers at cantatapharm.com>
Statistical Scientist
Cantata Pharmaceuticals
3-G Gill St
Woburn, MA  01801
617.225.9009
Fax 617.225.9010



From asone at latte.harvard.edu  Mon Jan 13 15:19:02 2003
From: asone at latte.harvard.edu (asone@latte.harvard.edu)
Date: Mon Jan 13 15:19:02 2003
Subject: [R] Problem about Rprof()  (Windows build  1.6.2)
In-Reply-To: <Pine.WNT.4.44.0301131320010.3744-100000@gannet.stats.ox.ac.uk>
Message-ID: <000101c2bb0e$bd073e60$0f21da18@hmdcvdcas>

Thank you for your advice, Prof. Ripley.

What I found after your e-mail is as follows:

when the following 4 command lines are typed in R Console one by one on
R (windows) Version 1.6.2  (2003-01-10), 

Rprof()
example(lm)
Rprof(NULL)
summaryRprof()

I got profiling results.

However, when I typed the following line in the R console,

	Rprof(); example(lm); Rprof(NULL); summaryRprof()

or 

the above 4 command lines were saved as a program file, "testRprof.R",
and it was executed as:

	>source("C:/asone/R/testRprof.R")

then I got the following error:

	Error in summaryRprof() : no events were recorded


When I tried the last two approaches, i.e., 

	Rprof(); example(lm); Rprof(NULL); summaryRprof()
	source("C:/asone/R/testRprof.R")

with R (windows) Version 1.5.0 Patched (2002-06-12) with "Rcmd Rprof
Rprof.out",

I could get profiling results. 

So is this a problem concerning not Rprof but the command interpreter?


Akio Sone
HU-MIT data center










> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Prof 
> Brian D Ripley
> Sent: Monday, January 13, 2003 8:23 AM
> To: asone at latte.harvard.edu
> Cc: r-help at stat.math.ethz.ch; dmurdoch at pair.com
> Subject: Re: [R] Problem about Rprof() (Windows build 1.6.2)
> 
> 
> Rprof()
> example(lm)
> Rprof(NULL)
> summaryRprof()
> 
> works perfectly here on the build I installed an hour ago.
> 
> Did you perchance forget to turn profiling off as in the 
> third line, so the file was not closed?
> 
> 
> On Sun, 12 Jan 2003 asone at latte.harvard.edu wrote:
> 
> > Dear R users:
> >
> > I have a problem about Rprof() on R for windows (Version 1.6.2 
> > (2003-01-10)).
> >
> > When I tried to run an R program, which yields non-empty profiling 
> > results with Rcmd Rprof on R (windows: Version 1.5.0 Patched 
> > (2002-06-12)),  I got the following empty result:
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listin> fo/r-help
>



From Burkhard.Kloss at kbcfp.com  Mon Jan 13 16:03:02 2003
From: Burkhard.Kloss at kbcfp.com (Kloss, Burkhard)
Date: Mon Jan 13 16:03:02 2003
Subject: [R] density estimation
Message-ID: <7C92FFD84C6DA94C8A8693EC976B8DFB57A223@msln2.london.kbcfp.com>

I've been trying to figure this out for a while, but my knowledge of R is obviously still too limited.

The context is as follows:  I have some time series, and I would like to estimate their densities, and then use the actual densities in a monte carlo simulation.  Now, I can easily estimate the density using density(); I can write a random number generator to fit an arbitrary density function (using the rejection method), but I can't figure out how to get a density function from the estimator.

Any idea how I can go about that?  

Thanks in advance, 

	Burkhard Kloss



From roger at ysidro.econ.uiuc.edu  Mon Jan 13 16:16:52 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Mon Jan 13 16:16:52 2003
Subject: [R] density estimation
In-Reply-To: <7C92FFD84C6DA94C8A8693EC976B8DFB57A223@msln2.london.kbcfp.com>
Message-ID: <Pine.SOL.4.30.0301130910440.20015-100000@ysidro.econ.uiuc.edu>

....but I can't figure out how to get a density function from the estimator.

I would suggest that you look at the logspline package.  The density estimation
is excellent and simulation methods are provided.


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820



From p.dalgaard at biostat.ku.dk  Mon Jan 13 16:32:05 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Jan 13 16:32:05 2003
Subject: [R] Problem about Rprof()  (Windows build  1.6.2)
In-Reply-To: <000101c2bb0e$bd073e60$0f21da18@hmdcvdcas>
References: <000101c2bb0e$bd073e60$0f21da18@hmdcvdcas>
Message-ID: <x2fzrx6p8g.fsf@biostat.ku.dk>

<asone at latte.harvard.edu> writes:

> Thank you for your advice, Prof. Ripley.
> 
> What I found after your e-mail is as follows:
> 
> when the following 4 command lines are typed in R Console one by one on
> R (windows) Version 1.6.2  (2003-01-10), 
> 
> Rprof()
> example(lm)
> Rprof(NULL)
> summaryRprof()
> 
> I got profiling results.
> 
> However, when I typed the following line in the R console,
> 
> 	Rprof(); example(lm); Rprof(NULL); summaryRprof()
> 
> or 
> 
> the above 4 command lines were saved as a program file, "testRprof.R",
> and it was executed as:
> 
> 	>source("C:/asone/R/testRprof.R")
> 
> then I got the following error:
> 
> 	Error in summaryRprof() : no events were recorded

Interesting. For whatever it is worth, it doesn't seem to happen on
Linux, so it is not the command interpreter per se. What happens if
you turn off the "buffer output" option?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Burkhard.Kloss at kbcfp.com  Mon Jan 13 16:42:02 2003
From: Burkhard.Kloss at kbcfp.com (Kloss, Burkhard)
Date: Mon Jan 13 16:42:02 2003
Subject: [R] density estimation
Message-ID: <7C92FFD84C6DA94C8A8693EC976B8DFB9553C7@msln2.london.kbcfp.com>

Thanks! That seems to be just what I'm after!

-----Original Message-----
From: Roger Koenker [mailto:roger at ysidro.econ.uiuc.edu]
Sent: 13 January 2003 15:14
To: Kloss, Burkhard
Cc: r-help
Subject: Re: [R] density estimation



....but I can't figure out how to get a density function from the estimator.

I would suggest that you look at the logspline package.  The density estimation
is excellent and simulation methods are provided.


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820



From Zhongming.Yang at cchmc.org  Mon Jan 13 17:15:04 2003
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Mon Jan 13 17:15:04 2003
Subject: [R] vectorized compare
Message-ID: <se229f7e.063@mailx.chmcc.org>

R experts:

Is there any vectorized logical comparison in R?

For instance I want stop some iterartion process until the every
component of the error vector all small than 1%.

Thanks,



From sundar.dorai-raj at pdf.com  Mon Jan 13 17:25:21 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon Jan 13 17:25:21 2003
Subject: [R] vectorized compare
References: <se229f7e.063@mailx.chmcc.org>
Message-ID: <3E22E761.4090805@pdf.com>

Zhongming,

Zhongming Yang wrote:
> R experts:
> 
> Is there any vectorized logical comparison in R?
> 
> For instance I want stop some iterartion process until the every
> component of the error vector all small than 1%.
> 

If eps is your vector of errors, use:

all(eps < 0.01)

or

all(abs(eps) < 0.01)

Regards,
Sundar



From munoz at stat.wisc.edu  Mon Jan 13 18:07:06 2003
From: munoz at stat.wisc.edu (Alejandro Munoz del Rio)
Date: Mon Jan 13 18:07:06 2003
Subject: [R] plotting and unplotting lines in  R
References: <20030112110007.8362.99336.Mailman@hypatia.math.ethz.ch>
Message-ID: <01c501c2bb26$0940fac0$2d2b5c90@surgery.wisc.edu>

"RexBryan" <rexbryan1 at attbi.com> writes:
> I would like to plot and unplot a line to a graph using R's line
> command.    This would allow for sequentially trying different plotted
> functions for a visual fit.  Is there a way to do this?

you can try re-plotting the line you want to erase in the color that matches
the bacground, e.g.
x <- rnorm(100)
plot(x)
lines(1:100, cos(1:100))
# assess quality of fit, then erase:
lines(1:100, cos(1:100), col="white")
# draw next fit
lines(1:100, sin(1:100))

the solution isn't "clean" in that erasing the line may also erase some of
the points. to prevent this, use
points(x), or re-plot altogether via plot(x)

hope this helps,

alejandro



From valdentro at hotmail.com  Mon Jan 13 18:21:03 2003
From: valdentro at hotmail.com (juan pablo perez)
Date: Mon Jan 13 18:21:03 2003
Subject: [R] =?iso-8859-1?B?cmVwbGFjZSBOQbRz?=
Message-ID: <F1729xT3lEmFWqbTYP0000034fd@hotmail.com>

hey
what should I do to replace in a data frame NA?s with zeroes?
Thanks in advance
Juan Pablo



From ripley at stats.ox.ac.uk  Mon Jan 13 18:41:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan 13 18:41:04 2003
Subject: [R] test version of RODBC
Message-ID: <Pine.LNX.4.44.0301131538510.1444-100000@gannet.stats>

I've recently done a lot of re-writing of the internals of RODBC, and have
a test version 0.99-6 available.  This is a run-up to the release of 1.0.
Both the source code and a Windows binary (prepared under rw1062) are
available at http:/www.stats.ox.ac.uk/pub/R, and I would appreciate some
real users testing this version.

It should be more efficient as data frames are transferred to and from the
DBMS in binary format (rather via character matrices) where possible.  
Also missing values as database nulls now work on Access and should work
everywhere.  For Windows users there are more general (and interactive)
ways to open ODBC connections.  And so on ... see the ChangeLog.

The main remaining task before RODBC-1.0 is to rationalize the handling of 
error conditions, and to build on David James' work and add a DBI 
interface layer (as an alternative).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From William.Simpson at drdc-rddc.gc.ca  Mon Jan 13 19:00:03 2003
From: William.Simpson at drdc-rddc.gc.ca (Simpson, William)
Date: Mon Jan 13 19:00:03 2003
Subject: [R] sink() & windows printing
Message-ID: <73D42D02E332D61197F80002A541D13F98B004@torex.toronto.drdc-rddc.gc.ca>

I used sink() a lot under linux with no problems.

Under windows 2000 & using R 1.5.1, I do the following:
- use sink() to direct ouput to a file
- use sink() again to direct output to screen
- print the file (to a network printer)

PROBLEM: the file stays spooled infinitely at the printer. Sometimes the
spooling gets translated into a printer error. The only way to get any
printing working again is to shutdown and restart (not even a reboot helps!)

Am I misusing sink() under windows?

I checked the R bugs archive and did not see this one listed.

Thanks for any help

Bill Simpson



From ripley at stats.ox.ac.uk  Mon Jan 13 19:38:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan 13 19:38:03 2003
Subject: [R] sink() & windows printing
In-Reply-To: <73D42D02E332D61197F80002A541D13F98B004@torex.toronto.drdc-rddc.gc.ca>
Message-ID: <Pine.LNX.4.44.0301131832550.2471-100000@gannet.stats>

On Mon, 13 Jan 2003, Simpson, William wrote:

> I used sink() a lot under linux with no problems.
> 
> Under windows 2000 & using R 1.5.1, I do the following:
> - use sink() to direct ouput to a file
> - use sink() again to direct output to screen
> - print the file (to a network printer)

How do you print it?  (I tested this with "foo.txt", right-click to 
print which uses Notepad.  Under current R, of course: I don't have such 
an old version around.)

> PROBLEM: the file stays spooled infinitely at the printer. Sometimes the
> spooling gets translated into a printer error. The only way to get any
> printing working again is to shutdown and restart (not even a reboot helps!)
> 
> Am I misusing sink() under windows?

No.  This is just a file that you can send to the printer: the problem 
appears to be in your print system.

> I checked the R bugs archive and did not see this one listed.

It's for bugs in R, so unsurprisingly does not cover Windows printing.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From William.Simpson at drdc-rddc.gc.ca  Mon Jan 13 19:47:03 2003
From: William.Simpson at drdc-rddc.gc.ca (Simpson, William)
Date: Mon Jan 13 19:47:03 2003
Subject: [R] sink() & windows printing
Message-ID: <73D42D02E332D61197F80002A541D13F98B005@torex.toronto.drdc-rddc.gc.ca>

Thanks Brian for your help.

> > I used sink() a lot under linux with no problems.
> > 
> > Under windows 2000 & using R 1.5.1, I do the following:
> > - use sink() to direct ouput to a file
> > - use sink() again to direct output to screen
> > - print the file (to a network printer)
> 
> How do you print it?  (I tested this with "foo.txt", right-click to 
> print which uses Notepad.
I open the file under Notepad and select print. The job appears in the print
queue (spooled).

>  Under current R, of course: I 
> don't have such 
> an old version around.)
I don't have the proper privileges to install software on this machine so it
is difficult for me to update very often.

> > PROBLEM: the file stays spooled infinitely at the printer. 
> Sometimes the
> > spooling gets translated into a printer error. The only way 
> to get any
> > printing working again is to shutdown and restart (not even 
> a reboot helps!)
> > 
> > Am I misusing sink() under windows?
> 
> No.  This is just a file that you can send to the printer: 
> the problem 
> appears to be in your print system.
This problem only arises after using sink() in R.

> > I checked the R bugs archive and did not see this one listed.
> 
> It's for bugs in R, so unsurprisingly does not cover Windows printing.
The bug would be that R's sink() function screws up Windows's printing
somehow...

Bill Simpson



From ripley at stats.ox.ac.uk  Mon Jan 13 20:00:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan 13 20:00:03 2003
Subject: [R] sink() & windows printing
In-Reply-To: <73D42D02E332D61197F80002A541D13F98B005@torex.toronto.drdc-rddc.gc.ca>
Message-ID: <Pine.LNX.4.44.0301131854280.2551-100000@gannet.stats>

On Mon, 13 Jan 2003, Simpson, William wrote:

> >  Under current R, of course: I 
> > don't have such 
> > an old version around.)
> I don't have the proper privileges to install software on this machine so it
> is difficult for me to update very often.

R needs no privileges to install: our students do it from user accounts 
all the time.

> > > I checked the R bugs archive and did not see this one listed.
> > 
> > It's for bugs in R, so unsurprisingly does not cover Windows printing.
> The bug would be that R's sink() function screws up Windows's printing
> somehow...

But it's *Notepad* that does the printing, not R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Ngayee.Law at celeradiagnostics.com  Mon Jan 13 20:46:03 2003
From: Ngayee.Law at celeradiagnostics.com (Ngayee J Law)
Date: Mon Jan 13 20:46:03 2003
Subject: [R] Cox PH model
Message-ID: <OF36EF76D8.D5D56D57-ON88256CAD.006C6B6E@pe-c.com>

Hello,

Anyone know how to extract the p-values from the output of the coxph
function?
Thanks.

- Jacqueline



From William.Simpson at drdc-rddc.gc.ca  Mon Jan 13 20:55:04 2003
From: William.Simpson at drdc-rddc.gc.ca (Simpson, William)
Date: Mon Jan 13 20:55:04 2003
Subject: [R] sink() & windows printing
Message-ID: <73D42D02E332D61197F80002A541D13F98B007@torex.toronto.drdc-rddc.gc.ca>

Thanks again Brian.
 
> > >  Under current R, of course: I 
> > > don't have such 
> > > an old version around.)
> > I don't have the proper privileges to install software on 
> this machine so it
> > is difficult for me to update very often.
> 
> R needs no privileges to install: our students do it from 
> user accounts 
> all the time.
Perhaps your computers are set up differently.
It was a while ago, but as I recall, the installation did not complete. I
don't remember the exact message but it basically said you need to be
superuser to fiddle with the registry, which is what the r-install wanted to
do.

The only time I can install software is when I just have an .exe file. The
ones that go via "Installation Wizard" always need a superuser in my
experience.

> > > > I checked the R bugs archive and did not see this one listed.
> > > 
> > > It's for bugs in R, so unsurprisingly does not cover 
> Windows printing.
> > The bug would be that R's sink() function screws up 
> Windows's printing
> > somehow...
> 
> But it's *Notepad* that does the printing, not R.
I thought *Windows* does the printing. (I don't know much about how windows
works). Sorry if I wasn't clear. After doing R's sink() I can't print from
*any* program.
I thought R's sink() told *Windows* something about the output file. So for
example a user can't delete it while R has it open for output. I thought
that what R told windows about the file somehow screwed up printing
generally.

Otherwise I don't see why only R's sink() should trigger this printing
problem. There quite definitely is a causal connection.

Bill



From Ngayee.Law at celeradiagnostics.com  Mon Jan 13 21:08:03 2003
From: Ngayee.Law at celeradiagnostics.com (Ngayee J Law)
Date: Mon Jan 13 21:08:03 2003
Subject: [R] log-rank test
Message-ID: <OF25BA690D.F521B055-ON88256CAD.006E6F2B@pe-c.com>

Hello all,

Is there a function to do log-rank test in R? Thanks!

- Jacqueline



From jasont at indigoindustrial.co.nz  Mon Jan 13 21:14:04 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon Jan 13 21:14:04 2003
Subject: [R] Re: =?iso-8859-1?Q?=5BR=5D_replace_NA=B4s?=
In-Reply-To: <F1729xT3lEmFWqbTYP0000034fd@hotmail.com>; from valdentro@hotmail.com on Mon, Jan 13, 2003 at 05:15:02PM +0000
References: <F1729xT3lEmFWqbTYP0000034fd@hotmail.com>
Message-ID: <20030114091126.B23118@camille.indigoindustrial.co.nz>

On Mon, Jan 13, 2003 at 05:15:02PM +0000, juan pablo perez wrote:
> what should I do to replace in a data frame NA?s with zeroes?

I use lapply

> dd <- data.frame(a=c(1,2,NA,4),b=c(NA,2,3,4))
> dd
   a  b
1  1 NA
2  2  2
3 NA  3
4  4  4
> dd2 <- data.frame(lapply(dd,function(x,...){x[is.na(x)] <- 3.14159 ; x}))
> dd2
        a       b
1 1.00000 3.14159
2 2.00000 2.00000
3 3.14159 3.00000
4 4.00000 4.00000

That will generate a warning message for each non-numeric column in
your data frame.  A tidier way is left as an exercise. ;)

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From jfox at mcmaster.ca  Mon Jan 13 22:21:02 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon Jan 13 22:21:02 2003
Subject: [R] =?iso-8859-1?Q?Re:_[R]_Re:_[R]_replace_NA=B4s?=
In-Reply-To: <20030114091126.B23118@camille.indigoindustrial.co.nz>
References: <F1729xT3lEmFWqbTYP0000034fd@hotmail.com>
 <F1729xT3lEmFWqbTYP0000034fd@hotmail.com>
Message-ID: <5.0.2.1.0.20030113160036.00af6858@mcmail.cis.mcmaster.ca>

Dear Jason and Juan,

At 09:11 AM 1/14/2003 +1300, Jason Turner wrote:
>On Mon, Jan 13, 2003 at 05:15:02PM +0000, juan pablo perez wrote:
> > what should I do to replace in a data frame NA?s with zeroes?
>
>I use lapply
>
> > dd <- data.frame(a=c(1,2,NA,4),b=c(NA,2,3,4))
> > dd
>    a  b
>1  1 NA
>2  2  2
>3 NA  3
>4  4  4
> > dd2 <- data.frame(lapply(dd,function(x,...){x[is.na(x)] <- 3.14159 ; x}))
> > dd2
>         a       b
>1 1.00000 3.14159
>2 2.00000 2.00000
>3 3.14159 3.00000
>4 4.00000 4.00000
>
>That will generate a warning message for each non-numeric column in
>your data frame.  A tidier way is left as an exercise. ;)

Here's a pretty simple expression using a for loop over columns (and 
testing for numeric data):

         for(i in 1:ncol(dd)) if(is.numeric(dd[,i])) dd[is.na(dd[,i]), i] <- 0

I hope that this helps,
  John
____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From p.dalgaard at biostat.ku.dk  Mon Jan 13 22:29:12 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Jan 13 22:29:12 2003
Subject: [R] Re: [R] replace =?iso-8859-1?q?NA=B4s?=
In-Reply-To: <20030114091126.B23118@camille.indigoindustrial.co.nz>
References: <F1729xT3lEmFWqbTYP0000034fd@hotmail.com>
	<20030114091126.B23118@camille.indigoindustrial.co.nz>
Message-ID: <x2wul8zqpq.fsf@biostat.ku.dk>

Jason Turner <jasont at indigoindustrial.co.nz> writes:

> On Mon, Jan 13, 2003 at 05:15:02PM +0000, juan pablo perez wrote:
> > what should I do to replace in a data frame NA?s with zeroes?
> 
> I use lapply
> 
> > dd <- data.frame(a=c(1,2,NA,4),b=c(NA,2,3,4))
> > dd
>    a  b
> 1  1 NA
> 2  2  2
> 3 NA  3
> 4  4  4
> > dd2 <- data.frame(lapply(dd,function(x,...){x[is.na(x)] <- 3.14159 ; x}))

Slightly neater:

dd2 <- dd
dd2[] <- lapply(dd2,function(x) replace(x, is.na(x), 3.14159))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From richard_raubertas at merck.com  Mon Jan 13 22:48:02 2003
From: richard_raubertas at merck.com (Raubertas, Richard)
Date: Mon Jan 13 22:48:02 2003
Subject: [R] Bug in boxplot(..., add=TRUE) ?
Message-ID: <2441CCF5E5A4F2409B280091905FA67E05007693@usrymx03.merck.com>

R 1.6.1 on Windows NT4:

The boxplot() function appears to draw its own tick marks
and axis values even when called with add=TRUE.  As a toy
example, try

x <- rnorm(100)
f <- factor(rep(1:4, each=25))
plot(c(0,4), c(-3,3), type="n", xaxt="n", yaxt="n")
boxplot(x ~ f, add=TRUE)

My expectation is that a high-level plotting function will
not mess with the axes when called with add=TRUE.  Is this
a bug or is my expectation wrong?

Richard Raubertas
Biometrics Research, RY84-16
Merck & Co.


------------------------------------------------------------------------------



From saurav at sas.upenn.edu  Tue Jan 14 00:23:02 2003
From: saurav at sas.upenn.edu (Saurav Pathak)
Date: Tue Jan 14 00:23:02 2003
Subject: [R] density plot - beginner's question
Message-ID: <20030113232245.GA8871@mail1.sas.upenn.edu>

Hi,

I am trying to plot densities given on a two dimensional grid.  My
data is in the an external file, and is arranged in three columns:
x, y, density

how may i get a plot of this?  i would like to get (1) a three
dimensional plot and (2) a color coded two dimensional plot.

I have tried using 

	image(x, y, density)

but i am asked to put the data in ascending order.  i am not sure
how i may put grid points in an ascending order.

I would also like to know if i could use any other function, other
than image.

thank you in advance.

-- 
saurav



From smyth at wehi.edu.au  Tue Jan 14 01:56:03 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Tue Jan 14 01:56:03 2003
Subject: [R] a fit method for gls?
Message-ID: <5.1.0.14.1.20030114114213.00af6cd0@imaphost.wehi.edu.au>

Dear all,

I make extensive use of the gls function from the nlme library for 
microarray data analysis (details described 
in 
http://bioinf.wehi.edu.au/smawehi/library/smawehi/html/gls.series.html). A 
typical fit involves running gls about 15000 times with the same formula, 
with different reponses and weights but with the same design matrix. Is 
there a way to avoid parsing the same formula every time gls is called by 
giving gls the response vector, weights and design matrix directly? That 
is, is there some way to call gls which is analogous to lm.fit for lm or to 
glm.fit for glm?

Thanks for any suggestions
Gordon
---------------------------------------------------------------------------------------
Dr Gordon K Smyth, Senior Research Scientist, Bioinformatics,
Walter and Eliza Hall Institute of Medical Research,
1G Royal Parade, Parkville, Vic 3050, Australia
Tel: (03) 9345 2326, Fax (03) 9347 0852,
Email: smyth at wehi.edu.au, www: http://www.statsci.org



From rpeng at stat.ucla.edu  Tue Jan 14 03:28:06 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue Jan 14 03:28:06 2003
Subject: [R] Bug in boxplot(..., add=TRUE) ?
In-Reply-To: <2441CCF5E5A4F2409B280091905FA67E05007693@usrymx03.merck.com>
Message-ID: <Pine.GSO.4.10.10301131812110.24124-100000@fisher.stat.ucla.edu>

This doesn't appear to be a bug, you can use `axes = FALSE' in the call to
boxplot().

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Mon, 13 Jan 2003, Raubertas, Richard wrote:

> R 1.6.1 on Windows NT4:
> 
> The boxplot() function appears to draw its own tick marks
> and axis values even when called with add=TRUE.  As a toy
> example, try
> 
> x <- rnorm(100)
> f <- factor(rep(1:4, each=25))
> plot(c(0,4), c(-3,3), type="n", xaxt="n", yaxt="n")
> boxplot(x ~ f, add=TRUE)
> 
> My expectation is that a high-level plotting function will
> not mess with the axes when called with add=TRUE.  Is this
> a bug or is my expectation wrong?
> 
> Richard Raubertas
> Biometrics Research, RY84-16
> Merck & Co.
> 
> 
> ------------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From fharrell at virginia.edu  Tue Jan 14 03:46:02 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Tue Jan 14 03:46:02 2003
Subject: [R] log-rank test
In-Reply-To: <OF25BA690D.F521B055-ON88256CAD.006E6F2B@pe-c.com>
References: <OF25BA690D.F521B055-ON88256CAD.006E6F2B@pe-c.com>
Message-ID: <20030113214548.1ca4b45d.fharrell@virginia.edu>

On Mon, 13 Jan 2003 12:06:55 -0800
Ngayee J Law <Ngayee.Law at celeradiagnostics.com> wrote:

> Hello all,
> 
> Is there a function to do log-rank test in R? Thanks!
> 
> - Jacqueline
> 

It's a special case of the Cox model (see coxph in the survival package).  If you want the standard logrank test, see the logrank function in the Hmisc package (it does not handle stratification though).  E.g.

library(Hmisc)
logrank(Surv(d.time,death), treatment)  # assumes treatment coded 1,2

See http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From kjetil at entelnet.bo  Tue Jan 14 04:09:05 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Tue Jan 14 04:09:05 2003
Subject: [R] density plot - beginner's question
In-Reply-To: <20030113232245.GA8871@mail1.sas.upenn.edu>
Message-ID: <3E2346D7.12553.3C1AE6@localhost>

On 13 Jan 2003 at 18:22, Saurav Pathak wrote:

> Hi,
> 
> I am trying to plot densities given on a two dimensional grid.  My
> data is in the an external file, and is arranged in three columns:
> x, y, density
> 
> how may i get a plot of this?  i would like to get (1) a three
> dimensional plot and (2) a color coded two dimensional plot.
> 
> I have tried using 
> 
> 	image(x, y, density)

You have here x, y, density vectors of the same length, which is not 
what image expects. The help page for image tells you that x and y 
should be vectors (each in ascending order), and z a matrix with
dimensions length(x) and length(y).  See the example on the help page 
for image. If your data are not a rectangular grid, you must probably 
interpolate before you can use image. 

Kjetil Halvorsen


> 
> but i am asked to put the data in ascending order.  i am not sure
> how i may put grid points in an ascending order.
> 
> I would also like to know if i could use any other function, other
> than image.
> 
> thank you in advance.
> 
> -- 
> saurav
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From hb at maths.lth.se  Tue Jan 14 04:23:03 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue Jan 14 04:23:03 2003
Subject: [R] density plot - beginner's question
In-Reply-To: <3E2346D7.12553.3C1AE6@localhost>
Message-ID: <000101c2bb7c$216919b0$7341a8c0@alpha.wehi.edu.au>

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of kjetil 
> brinchmann halvorsen
> Sent: den 14 januari 2003 14:08
> To: r-help at stat.math.ethz.ch; Saurav Pathak
> Subject: Re: [R] density plot - beginner's question
> 
> 
> On 13 Jan 2003 at 18:22, Saurav Pathak wrote:
> 
> > Hi,
> > 
> > I am trying to plot densities given on a two dimensional grid.  My 
> > data is in the an external file, and is arranged in three 
> columns: x, 
> > y, density
> > 
> > how may i get a plot of this?  i would like to get (1) a three 
> > dimensional plot and (2) a color coded two dimensional plot.
> > 
> > I have tried using
> > 
> > 	image(x, y, density)
> 
> You have here x, y, density vectors of the same length, which is not 
> what image expects. The help page for image tells you that x and y 
> should be vectors (each in ascending order), and z a matrix 
> with dimensions length(x) and length(y).  See the example on 
> the help page 
> for image. If your data are not a rectangular grid, you must probably 
> interpolate before you can use image. 

The code example at http://www.maths.lth.se/help/R/image/ might also
shine some light on the image() function, especially on how the coloring
is done.

Henrik Bengtsson

> Kjetil Halvorsen
> 
> 
> > 
> > but i am asked to put the data in ascending order.  i am 
> not sure how 
> > i may put grid points in an ascending order.
> > 
> > I would also like to know if i could use any other function, other 
> > than image.
> > 
> > thank you in advance.
> > 
> > --
> > saurav
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From deepayan at stat.wisc.edu  Tue Jan 14 07:16:04 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue Jan 14 07:16:04 2003
Subject: [R] density plot - beginner's question
In-Reply-To: <20030113232245.GA8871@mail1.sas.upenn.edu>
References: <20030113232245.GA8871@mail1.sas.upenn.edu>
Message-ID: <200301140015.01753.deepayan@stat.wisc.edu>

On Monday 13 January 2003 05:22 pm, Saurav Pathak wrote:
> Hi,
>
> I am trying to plot densities given on a two dimensional grid.  My
> data is in the an external file, and is arranged in three columns:
> x, y, density
>
> how may i get a plot of this?  i would like to get (1) a three
> dimensional plot and (2) a color coded two dimensional plot.

persp() for (1) and image() or filled.contour() for (2). Both need the density 
in the form of a matrix, as described in their respective help pages. 

Alternately, you could you the 3D functions in the lattice package:

library(lattice)
levelplot(density ~ x * y)

for (2).

wireframe(density ~ x * y)

will give you something similar to persp(), but it will be much slower.

>
> I have tried using
>
> 	image(x, y, density)
>
> but i am asked to put the data in ascending order.  i am not sure
> how i may put grid points in an ascending order.
>
> I would also like to know if i could use any other function, other
> than image.
>
> thank you in advance.



From petr.pikal at precheza.cz  Tue Jan 14 10:01:03 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue Jan 14 10:01:03 2003
Subject: [R] density plot - beginner's question
In-Reply-To: <20030113232245.GA8871@mail1.sas.upenn.edu>
Message-ID: <3E23DFBE.7483.7E03A1@localhost>

Hallo

On 13 Jan 2003 at 18:22, Saurav Pathak wrote:

> Hi,
> 
> I am trying to plot densities given on a two dimensional grid.  My
> data is in the an external file, and is arranged in three columns: x,
> y, density
> 
> how may i get a plot of this?  i would like to get (1) a three
> dimensional plot and (2) a color coded two dimensional plot.
> 
> I have tried using 
> 

try to use
library(akima)
ddd<interp(x,y,density,duplicate="median")
image(ddd)
or
persp(ddd)

>  image(x, y, density)
> 
> but i am asked to put the data in ascending order.  i am not sure how
> i may put grid points in an ascending order.
> 
> I would also like to know if i could use any other function, other
> than image.
> 
> thank you in advance.
> 
> -- 
> saurav
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

Hope it helps

Cheers
Petr
petr.pikal at precheza.cz
p.pik at volny.cz



From ozric at web.de  Tue Jan 14 10:10:04 2003
From: ozric at web.de (Christian Schulz)
Date: Tue Jan 14 10:10:04 2003
Subject: [R] building R1.6.2 from source (windows2k)
Message-ID: <000b01c2bbac$25a89750$293d07d5@c5c9i0>

hi,

what's wrong in my compiling procedure ?

make
make bitmapdll
make tcl
make docs (..first i get the error message for Latex3.0 so that i'm update
my miktex installation, after this doing again i'm getting no error !)

After  "make  docs" i should
change directory to   R-1.6.2/doc  and  type:

C:\Rcompile\R-1.6.2\doc>make -f Makefile.win info
make: Makefile.win: No such file or directory
make: *** No rule to make target `Makefile.win'.  Stop.

P.S.
Rgui.exe works, but the "packages-html-help" files are corrupt !?

many thanks for suggestions
christian



From ripley at stats.ox.ac.uk  Tue Jan 14 10:31:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 14 10:31:02 2003
Subject: [R] building R1.6.2 from source (windows2k)
In-Reply-To: <000b01c2bbac$25a89750$293d07d5@c5c9i0>
Message-ID: <Pine.LNX.4.44.0301140923540.3601-100000@gannet.stats>

On Tue, 14 Jan 2003, Christian Schulz wrote:

> what's wrong in my compiling procedure ?
> 
> make
> make bitmapdll
> make tcl
> make docs (..first i get the error message for Latex3.0 so that i'm update
> my miktex installation, after this doing again i'm getting no error !)

Nope, that message is a texinfo warning for TeX 3.0, which you should 
ignore as that's from the 1980's.

> After  "make  docs" i should
> change directory to   R-1.6.2/doc  and  type:

Do read more carefully.  The file INSTALL says `doc/manual'!

> C:\Rcompile\R-1.6.2\doc>make -f Makefile.win info
> make: Makefile.win: No such file or directory
> make: *** No rule to make target `Makefile.win'.  Stop.

Do you really want info versions of the manuals, on Windows?  If so you 
will need to know how to install them.

> P.S.
> Rgui.exe works, but the "packages-html-help" files are corrupt !?

What are the "packages-html-help" files?   The instructions work, with the 
recommended set of tools and if actually followed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Tue Jan 14 10:39:04 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue Jan 14 10:39:04 2003
Subject: [R] building R1.6.2 from source (windows2k)
In-Reply-To: <000b01c2bbac$25a89750$293d07d5@c5c9i0>
References: <000b01c2bbac$25a89750$293d07d5@c5c9i0>
Message-ID: <3E23D97A.4010000@statistik.uni-dortmund.de>

Christian Schulz wrote:
> hi,
> 
> what's wrong in my compiling procedure ?
> 
> make
> make bitmapdll
> make tcl
> make docs (..first i get the error message for Latex3.0 so that i'm update
> my miktex installation, after this doing again i'm getting no error !)
> 
> After  "make  docs" i should
> change directory to   R-1.6.2/doc  and  type:

No! Change to R-1.6.2/doc/manual as described in 
.../src/gnuwin32/Install !!!


> C:\Rcompile\R-1.6.2\doc>make -f Makefile.win info
> make: Makefile.win: No such file or directory
> make: *** No rule to make target `Makefile.win'.  Stop.
> 
> P.S.
> Rgui.exe works, but the "packages-html-help" files are corrupt !?

No. See above.

Uwe Ligges

> many thanks for suggestions
> christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From alobo at ija.csic.es  Tue Jan 14 10:45:04 2003
From: alobo at ija.csic.es (Agustin Lobo)
Date: Tue Jan 14 10:45:04 2003
Subject: [R] R-release.diff.gz: "patch detected!  Assume -R? [n]"
Message-ID: <Pine.OSF.3.96.1030114104823.11382A-100000@paleo.ija.csic.es>

Hi!

I'm upgrading to 1.6.2. (linux suse7.3). 
I see that there is
a patch in R-release.diff.gz.

1. Is this patch stable? In other words, is
it adviced that I install R-release.diff.gz ?

2. When I do:

zcat R-release.diff.gz | patch -p1 -E

I get many lines such as:

patching file AUTHORS
Reversed (or previously applied) patch detected!  Assume -R? [n]

Should I just accept the default answer?

Thanks

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es



From alobo at ija.csic.es  Tue Jan 14 11:14:02 2003
From: alobo at ija.csic.es (Agustin Lobo)
Date: Tue Jan 14 11:14:02 2003
Subject: [R] make check errors
Message-ID: <Pine.OSF.3.96.1030114112123.11382B-100000@paleo.ija.csic.es>

After make check in a linux suse7.3
with

./configure --enable-R-shlib --with-blas=/usr/lib/libatlas.a --with-gnome
--with-gnome-includes=/opt/gnome/include --with-gnome-libs=/opt/gnome/lib
--with-libglade-config=/opt/gnome/bin/libglade-config


I run make and make check. I get, at the end:

running strict specific tests
make[3]: Entering directory `/usr/local/R-1.6.2/tests'
running code in 'eval-etc.R' ... OK
comparing 'eval-etc.Rout' to './eval-etc.Rout.save' ...1d0
< WARNING: ignoring environment value of R_HOME
make[3]: *** [eval-etc.Rout] Error 1
make[3]: Leaving directory `/usr/local/R-1.6.2/tests'
make[2]: *** [test-Specific] Error 2
make[2]: Leaving directory `/usr/local/R-1.6.2/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/usr/local/R-1.6.2/tests'
make: *** [check] Error 2

What should I do to fix these errors?

Thanks,

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es



From andy_liaw at merck.com  Tue Jan 14 12:07:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Jan 14 12:07:03 2003
Subject: [R] Bug in boxplot(..., add=TRUE) ?
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFCA5E@usrymx10.merck.com>

It may not be a bug, but I wonder if it's an "unintended feature"...  As
Rich said, it seems unintuitive to have a plot function called with add=TRUE
add axes to existing plot.  This is not documented in either help pages for
boxplot and bxp.

Andy

> -----Original Message-----
> From: Roger Peng [mailto:rpeng at stat.ucla.edu]
> Sent: Monday, January 13, 2003 9:26 PM
> To: Raubertas, Richard
> Cc: 'r-help at stat.math.ethz.ch'
> Subject: Re: [R] Bug in boxplot(..., add=TRUE) ?
> 
> 
> This doesn't appear to be a bug, you can use `axes = FALSE' 
> in the call to
> boxplot().
> 
> -roger
> _______________________________
> UCLA Department of Statistics
> rpeng at stat.ucla.edu
> http://www.stat.ucla.edu/~rpeng
> 
> On Mon, 13 Jan 2003, Raubertas, Richard wrote:
> 
> > R 1.6.1 on Windows NT4:
> > 
> > The boxplot() function appears to draw its own tick marks
> > and axis values even when called with add=TRUE.  As a toy
> > example, try
> > 
> > x <- rnorm(100)
> > f <- factor(rep(1:4, each=25))
> > plot(c(0,4), c(-3,3), type="n", xaxt="n", yaxt="n")
> > boxplot(x ~ f, add=TRUE)
> > 
> > My expectation is that a high-level plotting function will
> > not mess with the axes when called with add=TRUE.  Is this
> > a bug or is my expectation wrong?
> > 
> > Richard Raubertas
> > Biometrics Research, RY84-16
> > Merck & Co.
> > 
> > 
> > 
> --------------------------------------------------------------
> ----------------
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From maechler at stat.math.ethz.ch  Tue Jan 14 12:22:03 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue Jan 14 12:22:03 2003
Subject: [R] R-release.diff.gz: "patch detected!  Assume -R? [n]"
In-Reply-To: <Pine.OSF.3.96.1030114104823.11382A-100000@paleo.ija.csic.es>
References: <Pine.OSF.3.96.1030114104823.11382A-100000@paleo.ija.csic.es>
Message-ID: <15907.62130.102948.206793@gargle.gargle.HOWL>

>>>>> "AgusL" == Agustin Lobo <alobo at ija.csic.es>
>>>>>     on Tue, 14 Jan 2003 10:54:21 +0100 (MET) writes:

    AgusL> Hi!  I'm upgrading to 1.6.2. (linux suse7.3).  I see
    AgusL> that there is a patch in R-release.diff.gz.

    AgusL> 1. Is this patch stable? In other words, is it
    AgusL> adviced that I install R-release.diff.gz ?

1)
 The diff file is an old "institution" that started long before
 "rsync" and in times with much smaller net bandwidth.
 Working with them may make sense if you have a slow or
 expensive internet connection and/or if you are interested in R
 development on a low level. 
2) 
 I'm the one responsible for these.
3)
 In principle this file tracks the difference from the last
 released version to the current (non-released!) "R-patched"
 working version.

4) They do NOT contain any changes in the recommended packages.
   ``Hence it is really not the whole story''

As I realize this is not the case currently
(it rather looks like a diff from "1.6.1" or so).
This should be changed soon.

---

Short summary: normal users should use the tar files (if
      compiling from source) or the binary release versions in
      any case!



    AgusL> 2. When I do:

    AgusL> zcat R-release.diff.gz | patch -p1 -E

in which directory?  1.6.2 or 1.6.1 ?
(you can answer privately to me)

    AgusL> I get many lines such as:

    AgusL> patching file AUTHORS Reversed (or previously
    AgusL> applied) patch detected!  Assume -R? [n]

    AgusL> Should I just accept the default answer?

no, don't use that file at all.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From Timur.Elzhov at jinr.ru  Tue Jan 14 13:08:02 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Tue Jan 14 13:08:02 2003
Subject: [R] Arithmetic operator from within C code
Message-ID: <20030114120813.GA5479@pcf004.jinr.ru>

Dear R experts,

I'd like to do some arithmetic operations like "+"(SEXP x, SEXP y),
from within C code.  Are there any predefined functions in R lib
for these?

Thank you very much!


--
WBR,
Timur.



From steinar at math.uio.no  Tue Jan 14 14:24:08 2003
From: steinar at math.uio.no (Steinar Bjerve)
Date: Tue Jan 14 14:24:08 2003
Subject: [R] ineq
Message-ID: <3E240F21.4090606@math.uio.no>

Dear Achim

I am trying again  to install ineq.  I succeeded to install it before by 
simply including the downloaded ineq-folder in the library folder.

Now I get  among other things:
  > library(ineq, help, lib.loc = T , logical.return = T)
[1] FALSE
Warning message:
There is no package called `ineq' in: library(ineq, help, lib.loc = T, 
logical.return = T)

Also:

It says under the Note in ?library, that the  `DESCRIPTION' file should 
contain a
     Built:' field, which it does not.

I hope you can give some advice.

Steinar

-- 
===============================
Steinar Bjerve         www.math.uio.no/~steinar/
===============================
Amor Fati ,



From otab at novozymes.com  Tue Jan 14 15:38:02 2003
From: otab at novozymes.com (OTAB (Olivier Taboureau))
Date: Tue Jan 14 15:38:02 2003
Subject: [R] PLS regression?
Message-ID: <FF503547C1F8D211BD2C0008C7C5640114A66AAB@exdkba06.novo.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030114/33c870ec/attachment.pl

From a.letertre at invs.sante.fr  Tue Jan 14 15:58:03 2003
From: a.letertre at invs.sante.fr (Alain LE TERTRE)
Date: Tue Jan 14 15:58:03 2003
Subject: [R] Random number generator in R compared to S
Message-ID: <000f01c2bbdc$987bbac0$37c9a8c0@ALETERTRE>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030114/9b68a855/attachment.pl

From luke at inpharmatica.co.uk  Tue Jan 14 16:38:07 2003
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Tue Jan 14 16:38:07 2003
Subject: [R] data import (on macintosh)
Message-ID: <Pine.LNX.4.21.0301141517110.9700-100000@dollis-hill.inpharmatica.co.uk>

I think the problem is the way files are named on the Macintosh.

On the Mac, the file separator character, which is "/" on unix
and "\" on dos/windows, is ":". Also, the root directory doesn't
start with the separator character, but instead just starts
with the volume name, which is the name of the hard disk icon
on your desktop, so if your file is in the top level directory
of your hard disk, and your hards disk is called for example
"My Mac HD", then you would want something like

 > guilds <- read.table(file = "My Mac HD:untitled.teste.txt")

If the file was in a sub-folder called "my folder", then you would want:

 > guilds <- read.table(file = "My Mac HD:my folder:untitled.teste.txt")

The "current directory" is probably the directory (folder)
that contains the R application, and if your data file is in
the same folder, then you don't need anything except its name:

 > guilds <- read.table(file = "untitled.teste.txt")

Also, I think from memory, that the "parent directory", which would
be "../" on unix or "..\" on dos/windows, is "::" on the mac, so that

 > guilds <- read.table(file = "::untitled.teste.txt")

would probably be the folder one level above the one containing the R
application.

NB All the above refers to Mac OS 7, 8, or 9. The new Mac OS X
is essentially unix, and I would expect that normal unix file
name conventions should apply, unless there is some backwards
compatibility fix for "carbon" applications, but I'm not sure
about that. There are two different versions of R available on
Mac OS X, one is pure unix running under the X11 window system,
and the other is a carbon application using the native Macintosh
windowing system, so they might behave differently.

I hope this helps,

Luke Whitaker



From rdiaz at cnio.es  Tue Jan 14 16:47:02 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Tue Jan 14 16:47:02 2003
Subject: [R] PLS regression?
In-Reply-To: <FF503547C1F8D211BD2C0008C7C5640114A66AAB@exdkba06.novo.dk>
References: <FF503547C1F8D211BD2C0008C7C5640114A66AAB@exdkba06.novo.dk>
Message-ID: <200301141643.01500.rdiaz@cnio.es>

Dear Olivier,

This issue has been asked a couple of times on the email list before. I am 
attaching a few messages from previous postings that I have kept around, but 
it might be a good idea to search the archives (I am almost sure there were 
more messages). I also have some R code, which is basically a quick and dirty 
R implementation of the matlab code in the paper by de Jong, Wise, Ricker, 
2001, J. Chemometrics, 15: 85-100, plus a few other things; but there is no 
help, etc, though the code is somewhat commented.


Best,

****************************************************
Re: [R] Partial Least Squares
Date: Mon, 4 Nov 2002 11:39:43 +0100
From: Stephane Dray <dray at biomserv.univ-lyon1.fr>
To: r-help at stat.math.ethz.ch

>Hi everybody!
>

>Is there any package or functions to make Partial Least Squares
>analysis with R?



I don't know.. I have a function to perform NIPALS (Nonlinear 
Iterative Partial Least Squares). This is an alternative for PCA 
based on PLS which can be cery useful in the case of missing values.


Sincerely.



**********************************************
Date: Mon, 04 Nov 2002 10:51:45 +0000
From: Peter Ho <peter at esb.ucp.pt>
To: Luis Silva <lm.silva at sapo.pt>
Cc: R help <r-help at stat.math.ethz.ch>

Luis,


You can find  Ron Wehrens chemometrics toolbox for R at 
http://www-cac.sci.kun.nl/people/rwehrens  
It includes PLS and LDA.


Alternatively, you may be interested in checking out Julian Faraway's 
book Practical regression and ANOVA in R  at
http://www.stat.lsa.umich.edu/~faraway/book/
There is a section on PCR and PLS.


Os melhores cumprimentos,


Peter
----------------------------------------------------------------
Doutor Peter Ho
Departamento de Ci?ncias de Engenharia e Tecnologia
Escola Superior de Tecnologia e Gest?o
Instituto Polit?nico de Viana do Castelo
Avenida do Atl?ntico- Apartado 574
4901-908 Viana do Castelo
Email: peter at estg.ipvc.pt

****************************************





On Tuesday 14 January 2003 15:31, OTAB (Olivier Taboureau) wrote:
> Hi all,
> I would like to do some QSAR analysis (quantitative structure activity
> relationship). I need to use some Partial Least Squares (PLS) regression,
> but I have not seen this option on the R-project. Is it possible to do this
> kind of regression on R?
> thank you in advance
> best regards,
> olivier
>
> 	[[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
http://bioinfo.cnio.es/~rdiaz



From pgilbert at bank-banque-canada.ca  Tue Jan 14 16:52:07 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue Jan 14 16:52:07 2003
Subject: [R] Random number generator in R compared to S
References: <000f01c2bbdc$987bbac0$37c9a8c0@ALETERTRE>
Message-ID: <3E24307E.BB185B25@bank-banque-canada.ca>

Alain LE TERTRE wrote:
> 
> I'm doing some simulations for which i need to use both S-plus and R.
> I generate in S+ some random normal distributions to define one dataset by
> iteration.  I need to use the same dataset generated in S-plus in R.
> I was first thinking to generate in R the same dataset by using the same
> random number generator with a fixed seed. But It seems that S-plus and R
> don't use the same random number generator.
> So my question is: Is there a way to pass dynamically dataset generated in
> S-plus to R, run a command, extract results, and pass them back to S-plus?
> Or is it more efficient to generate all the datasets in S-plus and export
> them to R?
> Or anything else?
> 
> Any hints will be greatly appreciated.

I do this in a slightly different way, by implementing one of the R
generators (and normal transformation) in Splus. The generator and
transformation I am using may not be the best choice among those in R,
but I have used it for several years now and it has worked very well for
checking that simulation and estimation code give the same results in
both Splus and R. My code for this is available in the syskern package
in the dse bundle on CRAN, but I am in the process of moving it into a
package called setRNG in a new version of dse which I will put on CRAN
soon.

Paul Gilbert



From jrgonzalez at ico.scs.es  Tue Jan 14 17:02:10 2003
From: jrgonzalez at ico.scs.es (Juan Ramon Gonzalez)
Date: Tue Jan 14 17:02:10 2003
Subject: [R] graphics landscape orientation
Message-ID: <00d801c2bbe4$b144aa00$1100a8c0@ico.scs.es>

Hello listers,

I would like to know how I can get the resulting graphic of the function
plot.hclust (from the package cluster) in landscape orientation. Is it
possible?

Thanks,

Juan



From saurav at sas.upenn.edu  Tue Jan 14 17:15:05 2003
From: saurav at sas.upenn.edu (Saurav Pathak)
Date: Tue Jan 14 17:15:05 2003
Subject: [R] density plot - beginner's question
In-Reply-To: <20030113232245.GA8871@mail1.sas.upenn.edu>
References: <20030113232245.GA8871@mail1.sas.upenn.edu>
Message-ID: <20030114161451.GA311@mail1.sas.upenn.edu>

Thanks to all who have provided me with valuable suggestions.  I am
forging ahead now, and am beginning to enjoy R.   

Thanks,
Saurav


Thus spake Saurav Pathak:

+  Hi,
+  
+  I am trying to plot densities given on a two dimensional grid.  My
+  data is in the an external file, and is arranged in three columns:
+  x, y, density
+  
+  how may i get a plot of this?  i would like to get (1) a three
+  dimensional plot and (2) a color coded two dimensional plot.
+  
+  I have tried using 
+  
+  	image(x, y, density)
+  
+  but i am asked to put the data in ascending order.  i am not sure
+  how i may put grid points in an ascending order.
+  
+  I would also like to know if i could use any other function, other
+  than image.
+  
+  thank you in advance.
+  
+  -- 
+  saurav
+  
+  ______________________________________________
+  R-help at stat.math.ethz.ch mailing list
+  http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tblackw at umich.edu  Tue Jan 14 17:31:03 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue Jan 14 17:31:03 2003
Subject: [R] graphics landscape orientation
In-Reply-To: <00d801c2bbe4$b144aa00$1100a8c0@ico.scs.es>
Message-ID: <Pine.SOL.4.44.0301141113170.4526-100000@rygar.gpcc.itd.umich.edu>

"landscape orientation" only makes sense for hardcopy printout,
so I assume you are using the  postscript()  device driver.
I also assume you are using it from the R command line (which
you probably are not).  Use the command

postscript("filename", horizontal=T)

See the help for postscript().

  -  tom blackwell  -  u michigan medical school  -  ann arbor  -


On Tue, 14 Jan 2003, Juan Ramon Gonzalez wrote:

> Hello listers,
>
> I would like to know how I can get the resulting graphic of the function
> plot.hclust (from the package cluster) in landscape orientation. Is it
> possible?
>
> Thanks,
>
> Juan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From alessandro.valli at amd.com  Tue Jan 14 17:35:31 2003
From: alessandro.valli at amd.com (alessandro.valli@amd.com)
Date: Tue Jan 14 17:35:31 2003
Subject: [R] Problem with pdf()
Message-ID: <D1B7EDF38A7CD311A68C0008C72825DF063D89C2@deexmta5.amd.com>

Hallo,

I noted the PDF format of pdf() beeing PDF-1.1.
I would like to know if it is possible to generate PDF files in PDF-1.2.
For some strange reason it is not possible to visualize certain pdf files generated via R on IE 5.5 (using AR 5.1).
But converting this to PDF-1.2 (using postscript() and gsv), it works.
It would be nice to test with pdf() generating a PDF-1.2 file, just to confine the problem.

Thanks for any help,

Alessandro Valli
Software and Application Engineer
Advanced Process Control Group
AMD Saxony Limited Liability Company & Co, KG
Wilschdorfer Landstra?e 101
D-01109 Dresden
Mail Stop E22-PE
Tel.  +49/351/2774543
Fax. +49/351/27794543
mailto:alessandro.valli at amd.com



From tord.snall at ebc.uu.se  Tue Jan 14 17:39:46 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Tue Jan 14 17:39:46 2003
Subject: [R] more efficient code possible?
Message-ID: <3.0.6.32.20030114172159.00ad24c0@mail.anst.uu.se>

Dear all,

Does anyone have a suggestion on how to make this code more efficient?

I have a large data frame that I want to merge with another data frame 

b.art.temp<- b.art[, c("BalteSFyndID", "RUBINKOD")]

I first add an indicator column for each RUBINKOD:

b.art.temp$anas.hel<- ifelse(b.art.temp$RUBINKOD=="ANAS.HEL", 1, 0)
b.art.temp$ant.pulv<- ifelse(b.art.temp$RUBINKOD=="ANT.PULV", 1, 0)
b.art.temp$anti.cur<- ifelse(b.art.temp$RUBINKOD=="ANTI.CUR", 1, 0)
...

# and then merge
b.substart<- merge(b.subst, b.art.temp[b.art.temp$anas.hel == 1,
c("BalteSFyndID", "anas.hel")], by="BalteSFyndID", all.x=T)

b.substart<- merge(b.substart, b.art.temp[b.art.temp$ant.pulv == 1,
c("BalteSFyndID", "ant.pulv")], by="BalteSFyndID", all.x=T)

b.substart<- merge(b.substart, b.art.temp[b.art.temp$anti.cur == 1,
c("BalteSFyndID", "anti.cur")], by="BalteSFyndID", all.x=T)
...

But there are many levels of RUBINKOD
nlevels(b.art.temp$RUBINKOD)
[1]  61

and I therefore wonder if there is any quicker way of doing it than
repeating the abouve lines 58 more times


Thanks in advance!


Sincerely,
Tord

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From ozric at web.de  Tue Jan 14 17:44:38 2003
From: ozric at web.de (Christian Schulz)
Date: Tue Jan 14 17:44:38 2003
Subject: [R] building R1.6.2 from source (windows2k)
References: <Pine.LNX.4.44.0301140923540.3601-100000@gannet.stats>
Message-ID: <002901c2bbe9$844bf620$203c07d5@c5c9i0>

> Do read more carefully.  The file INSTALL says `doc/manual'!

many thanks !
I work with the very usefuel  manual
"R for Windows Users 2.0" from Ko-Kang Kevin Wang ,
but IMHO here is a small mistake (Page 13!) ?

Sorry for my newbie problems, but why the
"make docs" ends not fine and the "make recomended"
didn't work ?

many thanks for help to enter this adventure
christian


[snip- last output after make docs]

l.10 @documentlanguage en

?
[1{psfonts.map}] [-1] Chapter 1 (R-FAQ.tmp)
Cross reference values unknown; you must run TeX again. Chapter 2 [1] [2]
(R-FAQ.tmp) (R-FAQ.tmp) [3] [4] (R-FAQ.tmp) (R-FAQ.tmp) (R-FAQ.tmp)
(R-FAQ.tmp)
[5] (R-FAQ.tmp) (R-FAQ.tmp) (R-FAQ.tmp) (R-FAQ.tmp) (R-FAQ.tmp) [6]
(R-FAQ.tmp)
[7] [8] Chapter 3 [9] (R-FAQ.tmp) (R-FAQ.tmp) (R-FAQ.tmp) (R-FAQ.tmp)
(R-FAQ.tmp) [10] (R-FAQ.tmp) [11] [12] [13] [14] (R-FAQ.tmp) [15]
(R-FAQ.tmp)
(R-FAQ.tmp) (R-FAQ.tmp) Chapter 4 [16] (R-FAQ.tmp) Chapter 5 [17] [18]
(R-FAQ.tmp) (R-FAQ.tmp) [19] (R-FAQ.tmp) [20] [21] [22] [23] [24] [25]
(R-FAQ.tmp) (R-FAQ.tmp) [26] [27] (R-FAQ.tmp) (R-FAQ.tmp) [28] (R-FAQ.tmp)
(R-FAQ.tmp) [29] (R-FAQ.tmp) (R-FAQ.tmp) (R-FAQ.tmp) (R-FAQ.tmp) (R-FAQ.tmp)
(R-FAQ.tmp) (R-FAQ.tmp) [30] [31] [32] [33]

WARNING: for users of Unix TeX 3.0!
This manual trips a bug in TeX version 3.0 (tex hangs).
If you are running another version of TeX, relax.
If you are running Unix TeX 3.0, kill this TeX process.
 Then upgrade your TeX installation if you can.
 (See ftp://ftp.gnu.org/pub/gnu/TeX.README.)
If you are stuck with version 3.0, run the
 script ``tex3patch'' from the Texinfo distribution
 to use a workaround.

Chapter 6 [34] (R-FAQ.tmp) (R-FAQ.tmp) (R-FAQ.tmp) [35] Chapter 7 [36] [37]
[38] [39] [40] [41] [42] [43] Chapter 8 [44] Chapter 9 [45] [46] Chapter 10
[47]
[48] )<cmr8.pfb><cmsy9.pfb><cmmi10.pfb><cmb10.pfb><cmsltt10.pfb><cmsl10.pf
b><cmti10.pfb><cmtt10.pfb><cmsy10.pfb><cmr10.pfb><cmcsc10.pfb><cmbx12.pfb>
Output written on R-FAQ.pdf (50 pages, 297794 bytes).
Transcript written on R-FAQ.log.
make[1]: *** [R-FAQ.pdf] Error 1
make: *** [docs] Error 2


[snip - output from make recomended ]
C:\Rcompile\R-1.6.2\src\Recomended\
 only with the packed recommended packages exist ???


- C:\Rcompile\R-1.6.2\src\gnuwin32>make recommended
--- Unpacking recommended packages
---- VR

gzip: stdin: unexpected end of file
tar: Child returned status 1
tar: Error exit delayed from previous errors
touch: creating `../library/VR/DESCRIPTION': No such file or directory
make[1]: *** [../library/VR/DESCRIPTION] Error 1
---- KernSmooth

gzip: stdin: unexpected end of file
tar: Child returned status 1
tar: Error exit delayed from previous errors
touch: creating `../library/KernSmooth/DESCRIPTION': No such file or
directory
make[1]: *** [../library/KernSmooth/DESCRIPTION] Error 1
---- survival]
..................



From ripley at stats.ox.ac.uk  Tue Jan 14 17:49:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 14 17:49:04 2003
Subject: [R] Problem with pdf()
In-Reply-To: <D1B7EDF38A7CD311A68C0008C72825DF063D89C2@deexmta5.amd.com>
Message-ID: <Pine.LNX.4.44.0301141642410.8732-100000@gannet.stats>

A PDF-1.1 file is a PDF-1.2 file.  They are backwards compatible 
specifications.

The source code is available to you if you want to re-write the driver to
make use of features in, say, PDF-1.2 or even the current 1.4.


On Tue, 14 Jan 2003 alessandro.valli at amd.com wrote:

> I noted the PDF format of pdf() beeing PDF-1.1.
> I would like to know if it is possible to generate PDF files in PDF-1.2.
> For some strange reason it is not possible to visualize certain pdf files generated via R on IE 5.5 (using AR 5.1).
> But converting this to PDF-1.2 (using postscript() and gsv), it works.
> It would be nice to test with pdf() generating a PDF-1.2 file, just to confine the problem.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Jan 14 17:53:42 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 14 17:53:42 2003
Subject: [R] graphics landscape orientation
In-Reply-To: <00d801c2bbe4$b144aa00$1100a8c0@ico.scs.es>
Message-ID: <Pine.LNX.4.44.0301141623330.8045-100000@gannet.stats>

That's a function of the R graphics driver, e.g. the horizontal arg in 
postscript() or set a landscape format width and height in pdf() or 
win.metafile() or ....

On Tue, 14 Jan 2003, Juan Ramon Gonzalez wrote:

> I would like to know how I can get the resulting graphic of the function
> plot.hclust (from the package cluster) in landscape orientation. Is it
> possible?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From klaus.thul at infineon.com  Tue Jan 14 18:16:02 2003
From: klaus.thul at infineon.com (klaus.thul@infineon.com)
Date: Tue Jan 14 18:16:02 2003
Subject: [R] residuals() with missing data, alignment to original data set
Message-ID: <2B302C161738D611915300300530013F01734B72@drsse109.drs.infineon.com>

Hello, 

I have a data frame and want to do the following.

Do a regression of one variable versus another:

	fit <- lm(a ~ b)

Then I would like to plot the residuals of this fit versus a third variable:

	bwplot(residuals(fit) ~ group)

This fails, if a or b contain NAs, because the data in the residuals() -
vector are not aligned anymore to the data in the original data frame.

Is there a way to solve this issue?

Regards and thanks for your help
Klaus



From ripley at stats.ox.ac.uk  Tue Jan 14 18:41:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 14 18:41:03 2003
Subject: [R] residuals() with missing data, alignment to original data
 set
In-Reply-To: <2B302C161738D611915300300530013F01734B72@drsse109.drs.infineon.com>
Message-ID: <Pine.LNX.4.44.0301141740001.10444-100000@gannet.stats>

na.action=na.exclude does this.

On Tue, 14 Jan 2003 klaus.thul at infineon.com wrote:

> Hello, 
> 
> I have a data frame and want to do the following.
> 
> Do a regression of one variable versus another:
> 
> 	fit <- lm(a ~ b)
> 
> Then I would like to plot the residuals of this fit versus a third variable:
> 
> 	bwplot(residuals(fit) ~ group)
> 
> This fails, if a or b contain NAs, because the data in the residuals() -
> vector are not aligned anymore to the data in the original data frame.
> 
> Is there a way to solve this issue?
> 
> Regards and thanks for your help
> Klaus
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mspeekenbrink at fmg.uva.nl  Tue Jan 14 19:12:03 2003
From: mspeekenbrink at fmg.uva.nl (Maarten Speekenbrink)
Date: Tue Jan 14 19:12:03 2003
Subject: [R] glmmPQL and anova
Message-ID: <21F67EF0AFCF3F449AF94D739A0350352B4D84@rea05.fmg.uva.nl>

Dear R-users,

I have conducted an experiment with a 2*2*2 factorial within-subjects design. All factors are binary and the dependent measure is a frequency of successes between 0 and 4. Treating this as a normally distributed variable, I would perform a repeated-measures ANOVA as follows:

> aov(y ~ A*B*C + Error(subj/(A+B+C)))

but since the distribution of the dependent measure is clearly nonnormal, I would like to fit an analoguous model which is appropriate and I believe this would be a GLMM with a logit link and a random intercept for subjects. I have fitted this model using 'glmmPQL' function in MASS as:

> glmmPQL(cbind(y,4-y) ~ A*B*C, random = ~ 1|subj, family=binomial(),data)

which seemed to do the trick. But I would like to present the results in an ANOVA-type table so that they are easiliy interpretable for the readers. I know the anova(glm, test="Chisq") function for fixed-effect GLM gives a ANOVA-type analysis in terms of the sequential Chi-Square difference tests, but since the glmmPQL function returns an object of the class lme, I wonder if the results of an anova(glmPQL) are appropriate. From an earlier posting I gathered that anova and AIC are inappropriate for model comparisons when the models are estimated by glmmPQL, since the estimation is not maximum likelihood, but does this hold for the anova applied to a single model?

Kind regards,

Maarten Speekenbrink
--------------------------------------------------------------------
 drs. M. Speekenbrink
 Psychological Methodology
 Department of Psychology, Faculty of Social and Behavioral Sciences
 address: Roeterstraat 15, 1018 WB Amsterdam, Netherlands
 tel: +31 20 525 6876 / +31 20 525 6870
 fax: +31 20 639 0026
--------------------------------------------------------------------



From dvumani at hotmail.com  Tue Jan 14 19:20:03 2003
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Tue Jan 14 19:20:03 2003
Subject: [R] Universal legend for graph...
Message-ID: <F30FSZ6FYWcB2KWFYob00005a2e@hotmail.com>

Dear R-Users:

I am trying to create a graph with 6 panels, but would like to have a 
universal legend as each panel merely denotes a separate stratum. The legend 
has to be at the bottom.

I use "par(mfrow=c(2,3))" to get the panels, but am not sure how to put the 
legend below the whole graph.

Thanking you as always.



Vumani Dlamini
Swaziland



From neteler at itc.it  Tue Jan 14 19:36:05 2003
From: neteler at itc.it (Markus Neteler)
Date: Tue Jan 14 19:36:05 2003
Subject: [R] install problem: gpclib
In-Reply-To: <Pine.SOL.4.20.0301141132400.26282-100000@santiam.dfci.harvard.edu>; from jgentry@jimmy.harvard.edu on Tue, Jan 14, 2003 at 11:35:02AM -0500
References: <20030114172704.L23470@itc.it> <Pine.SOL.4.20.0301141132400.26282-100000@santiam.dfci.harvard.edu>
Message-ID: <20030114193521.Y23470@itc.it>

Dear list,

I face some problems installing gpclib_1.0-1.tar.gz:

R-161
R : Copyright 2002, The R Development Core Team
Version 1.6.1  (2002-11-01)
[...]
system("R CMD INSTALL gpclib_1.0-1.tar.gz")
WARNING: ignoring environment value of R_HOME
ERROR: This R is version 1.5.0
       package 'gpclib' depends on R 1.6.1


The same happens with 
http://www.bioconductor.org/getBioC.R
which cannot install the reposTools (same error message).

I was suggested to try above unusal install method as
reposTools from bioconductor is using it. Then I was suggested
to report this error here.

In general our R-161 installation (Linux/i686) works well.
Also running 'R CMD INSTALL ...' in a common shell is ok.
Only above method fails.

Does anyone have a suggestion for me?

Thanks,

Markus Neteler



From andy_liaw at merck.com  Tue Jan 14 20:03:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Jan 14 20:03:03 2003
Subject: [R] PLS regression?
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFCA60@usrymx10.merck.com>

AFAIK Ron's chemometr package no longer passes package check with the
current version of R.  I've made some attempt to update it, but there are
many other functions that needed to be updated...

Andy

> -----Original Message-----
> From: Ramon Diaz [mailto:rdiaz at cnio.es]
> Sent: Tuesday, January 14, 2003 10:43 AM
> To: OTAB (Olivier Taboureau); 'R-help at lists.R-project.org'
> Subject: Re: [R] PLS regression?
> 
> 
> Dear Olivier,
> 
> This issue has been asked a couple of times on the email list 
> before. I am 
> attaching a few messages from previous postings that I have 
> kept around, but 
> it might be a good idea to search the archives (I am almost 
> sure there were 
> more messages). I also have some R code, which is basically a 
> quick and dirty 
> R implementation of the matlab code in the paper by de Jong, 
> Wise, Ricker, 
> 2001, J. Chemometrics, 15: 85-100, plus a few other things; 
> but there is no 
> help, etc, though the code is somewhat commented.
> 
> 
> Best,
> 
> ****************************************************
> Re: [R] Partial Least Squares
> Date: Mon, 4 Nov 2002 11:39:43 +0100
> From: Stephane Dray <dray at biomserv.univ-lyon1.fr>
> To: r-help at stat.math.ethz.ch
> 
> >Hi everybody!
> >
> 
> >Is there any package or functions to make Partial Least Squares
> >analysis with R?
> 
> 
> 
> I don't know.. I have a function to perform NIPALS (Nonlinear 
> Iterative Partial Least Squares). This is an alternative for PCA 
> based on PLS which can be cery useful in the case of missing values.
> 
> 
> Sincerely.
> 
> 
> 
> **********************************************
> Date: Mon, 04 Nov 2002 10:51:45 +0000
> From: Peter Ho <peter at esb.ucp.pt>
> To: Luis Silva <lm.silva at sapo.pt>
> Cc: R help <r-help at stat.math.ethz.ch>
> 
> Luis,
> 
> 
> You can find  Ron Wehrens chemometrics toolbox for R at 
> http://www-cac.sci.kun.nl/people/rwehrens  
> It includes PLS and LDA.
> 
> 
> Alternatively, you may be interested in checking out Julian Faraway's 
> book Practical regression and ANOVA in R  at
> http://www.stat.lsa.umich.edu/~faraway/book/
> There is a section on PCR and PLS.
> 
> 
> Os melhores cumprimentos,
> 
> 
> Peter
> ----------------------------------------------------------------
> Doutor Peter Ho
> Departamento de Ci?ncias de Engenharia e Tecnologia
> Escola Superior de Tecnologia e Gest?o
> Instituto Polit?nico de Viana do Castelo
> Avenida do Atl?ntico- Apartado 574
> 4901-908 Viana do Castelo
> Email: peter at estg.ipvc.pt
> 
> ****************************************
> 
> 
> 
> 
> 
> On Tuesday 14 January 2003 15:31, OTAB (Olivier Taboureau) wrote:
> > Hi all,
> > I would like to do some QSAR analysis (quantitative 
> structure activity
> > relationship). I need to use some Partial Least Squares 
> (PLS) regression,
> > but I have not seen this option on the R-project. Is it 
> possible to do this
> > kind of regression on R?
> > thank you in advance
> > best regards,
> > olivier
> >
> > 	[[alternate HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> -- 
> Ram?n D?az-Uriarte
> Bioinformatics Unit
> Centro Nacional de Investigaciones Oncol?gicas (CNIO)
> (Spanish National Cancer Center)
> Melchor Fern?ndez Almagro, 3
> 28029 Madrid (Spain)
> http://bioinfo.cnio.es/~rdiaz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From Zhongming.Yang at cchmc.org  Tue Jan 14 20:53:02 2003
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Tue Jan 14 20:53:02 2003
Subject: [R] call R form perl
Message-ID: <se242407.068@mailx.chmcc.org>

R exports:

The attached is the program that try to call R function from perl. The
function is in "peak-pick.r", and the function name is peakpick. Can
anyone give me some clue that make it works?

Thanks
-------------- next part --------------
A non-text attachment was scrubbed...
Name: peak-pick.pl
Type: application/octet-stream
Size: 262 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030114/7c0d6baf/peak-pick.obj

From ripley at stats.ox.ac.uk  Tue Jan 14 21:00:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 14 21:00:04 2003
Subject: [R] glmmPQL and anova
In-Reply-To: <21F67EF0AFCF3F449AF94D739A0350352B4D84@rea05.fmg.uva.nl>
Message-ID: <Pine.LNX.4.44.0301141954500.13610-100000@gannet.stats>

Yes.

On Tue, 14 Jan 2003, Maarten Speekenbrink wrote:

> Dear R-users,
> 
> I have conducted an experiment with a 2*2*2 factorial within-subjects design. All factors are binary and the dependent measure is a frequency of successes between 0 and 4. Treating this as a normally distributed variable, I would perform a repeated-measures ANOVA as follows:
> 
> > aov(y ~ A*B*C + Error(subj/(A+B+C)))
> 
> but since the distribution of the dependent measure is clearly nonnormal, I would like to fit an analoguous model which is appropriate and I believe this would be a GLMM with a logit link and a random intercept for subjects. I have fitted this model using 'glmmPQL' function in MASS as:
> 
> > glmmPQL(cbind(y,4-y) ~ A*B*C, random = ~ 1|subj, family=binomial(),data)
> 
> which seemed to do the trick. But I would like to present the results in an ANOVA-type table so that they are easiliy interpretable for the readers. I know the anova(glm, test="Chisq") function for fixed-effect GLM gives a ANOVA-type analysis in terms of the sequential Chi-Square difference tests, but since the glmmPQL function returns an object of the class lme, I wonder if the results of an anova(glmPQL) are appropriate. From an earlier posting I gathered that anova and AIC are inappropriate for model comparisons when the models are estimated by glmmPQL, since the estimation is not maximum likelihood, but does this hold for the anova applied to a single model?
> 
> Kind regards,
> 
> Maarten Speekenbrink
> --------------------------------------------------------------------
>  drs. M. Speekenbrink
>  Psychological Methodology
>  Department of Psychology, Faculty of Social and Behavioral Sciences
>  address: Roeterstraat 15, 1018 WB Amsterdam, Netherlands
>  tel: +31 20 525 6876 / +31 20 525 6870
>  fax: +31 20 639 0026
> --------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From NRaghava at PRDUS.JNJ.COM  Tue Jan 14 21:13:03 2003
From: NRaghava at PRDUS.JNJ.COM (Raghavan, Nandini  [PRDUS Non J&J])
Date: Tue Jan 14 21:13:03 2003
Subject: [R] PLS code for classification
Message-ID: <5C71B3A72770D411BAAF00508B69C35A05DDBBA5@rarusraexs10.prius.jnj.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030114/960b28d1/attachment.pl

From ozric at web.de  Tue Jan 14 21:39:03 2003
From: ozric at web.de (Christian Schulz)
Date: Tue Jan 14 21:39:03 2003
Subject: [R] export result files (loop problem?)
Message-ID: <002701c2bc0c$562e0080$96b007d5@c5c9i0>

i'm experimenting with several possibilities  produce and export
plot/result files.
I attempt a lot of things, the file which i want in most ways written but
empty, i.e. pdf,write,sink.
One exception which works correct for me in the loop is
write.table(data,file=dataname).
The way without a loop works,too.

thanks for advance & regards,christian

    dataImport <- function(dir) {
        i=0
        for(fn in list.files(dir, full.names = TRUE)) {
            tmp <- read.spss(fn, use.value.labels=F,to.data.frame=T)
            i=i+1
            dataname = paste("allbus",i,sep="")
            data <-  assign(dataname, tmp)
            #pdf(paste("allbus",i,sep=""),width = 6, height = 6, onefile
=TRUE, family = "Helvetica", bg="lightblue")
            #sapply((1:ncol(data)),function(x)
hist(data[,x],main=names(data)[x]))
            #dev.off()
            sink(dataname)
            sapply(data,summary)
            sink()
            }}



From RexBryan1 at attbi.com  Tue Jan 14 22:16:03 2003
From: RexBryan1 at attbi.com (Rex_Bryan@urscorp.com)
Date: Tue Jan 14 22:16:03 2003
Subject: [R] comparing class() -- R=NULL  and S+=numeric
Message-ID: <002001c2bc12$a9baa590$3182fd0c@dell1700>

I'm just reading Modern Applied Statistics with S, 4th Ed., Venables and
Ribley
I'm typing in their examples in both R and S+.  I need insight in the
difference
in the class() statement shown in Chap. 2.  Example from book:

> names(powers.of.pi) <- -2:2
> powers.of.pi
       -2        -1         0         1         2
0.1013212 0.3183099 1.0000000 3.1415927 9.8696044

> class(powers.of.pi)
R produces an answer:      NULL
S+ produces the answer:  [1]  "numeric"

Any insight in understanding the difference?

Rex



From mikalzet at libero.it  Tue Jan 14 22:34:09 2003
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Tue Jan 14 22:34:09 2003
Subject: [R] Mandrake packages for  R-1.6.2 uploaded
In-Reply-To: <x2k7hdq670.fsf@biostat.ku.dk>
References: <x2adi9rogm.fsf@biostat.ku.dk> <3E1EF8A0.F010C41F@bank-banque-canada.ca>
 <x2k7hdq670.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.50.0301142231530.3229-100000@macchinetta>

Mandrake packages for R 1.6.2 have been uploaded and will propagate 
through CRAN in due course.

-- 
Michele Alzetta



From p.dalgaard at biostat.ku.dk  Tue Jan 14 22:41:06 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Jan 14 22:41:06 2003
Subject: [R] comparing class() -- R=NULL  and S+=numeric
In-Reply-To: <002001c2bc12$a9baa590$3182fd0c@dell1700>
References: <002001c2bc12$a9baa590$3182fd0c@dell1700>
Message-ID: <x2lm1nz9x5.fsf@biostat.ku.dk>

"Rex_Bryan at urscorp.com" <RexBryan1 at attbi.com> writes:

> I'm just reading Modern Applied Statistics with S, 4th Ed., Venables and
> Ribley
> I'm typing in their examples in both R and S+.  I need insight in the
> difference
> in the class() statement shown in Chap. 2.  Example from book:
> 
> > names(powers.of.pi) <- -2:2
> > powers.of.pi
>        -2        -1         0         1         2
> 0.1013212 0.3183099 1.0000000 3.1415927 9.8696044
> 
> > class(powers.of.pi)
> R produces an answer:      NULL
> S+ produces the answer:  [1]  "numeric"
> 
> Any insight in understanding the difference?

I suspect that the answer is actually somewhere in MASS4, but I don't
have it at hand right now. 

Basically there have been two class systems in S(-PLUS), S3 and S4,
and R is (mostly) compatible with the former as represented by S-PLUS
3.x.

In S3, classes are really just text attributes, and if none is
present, the class is NULL. However, you can ask for data.class(x) and
get - essentially - its mode. E.g.,

> data.class(powers.of.pi)
[1] "numeric"

S4 classes introduce a stricter system where all objects have a class.
This is what is used in current versions of S-PLUS. In R, we have the
"methods" library, which changes the behaviour of R to be like S4:

> library(methods)
> class(powers.of.pi)
[1] "numeric"

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From davidD at qimr.edu.au  Tue Jan 14 22:47:03 2003
From: davidD at qimr.edu.au (David Duffy)
Date: Tue Jan 14 22:47:03 2003
Subject: [R] Re: R-help digest, Vol 1 #45 - 24 msgs
In-Reply-To: <20030113110010.9222.75858.Mailman@hypatia.math.ethz.ch>
References: <20030113110010.9222.75858.Mailman@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.50.0301150745050.26955-100000@orpheus.qimr.edu.au>

Alexander.Herr at csiro.au asked:

> Surely, I just have a mental block and there is a more elegant way of
> creating a summary count (other than extracing it from ftable). I'd like
> to create a new data.frame containing counts of spell by loc ie have
> three columns showing spell,loc,count. Below the data.frame...

perhaps as.data.frame.table(table(spell,loc))

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Liu.Chunhua at epamail.epa.gov  Tue Jan 14 23:36:05 2003
From: Liu.Chunhua at epamail.epa.gov (Liu.Chunhua@epamail.epa.gov)
Date: Tue Jan 14 23:36:05 2003
Subject: [R] How to change the label position in axis() ?
Message-ID: <OFD1109FCB.AA7537AF-ON85256CAE.007B3C1D@rtp.epa.gov>


Dear R People,

I'm working on a plot function to produce the graph shown below. One of
the features my supervisor does not like is that the labels in the Y-
axix are shown vertically. Is there a way to change that to horizontally
?

This is the axix() function I used  :

axis(2,at=seq(nstrat),labels=snames)

The labels (snames)  are: SEV1:HU:C, SEV1:MU:C, SEV1:MU:L, SEV1:RT:C
and SEV1:RT:L, due to space limitation just 3 of the labels are shown in
the axix.
In Splus, I believe the labels are shown horizontally be default. What
we want is to show them horizontally in R too. Is there a way to do it ?

I studied help(axix) document, and did not see a way to do it.

THanks for the help


Charlie Liu
Graduate Intern at US EPA


(Embedded image moved to file: pic08925.pcx)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: pic08925.pcx
Type: application/octet-stream
Size: 24125 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030114/2a5e0b5e/pic08925.obj

From ben at zoo.ufl.edu  Tue Jan 14 23:42:09 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue Jan 14 23:42:09 2003
Subject: [R] How to change the label position in axis() ?
In-Reply-To: <OFD1109FCB.AA7537AF-ON85256CAE.007B3C1D@rtp.epa.gov>
Message-ID: <Pine.LNX.4.44.0301141747360.5660-100000@bolker.zoo.ufl.edu>

  See ?par, the source of all wisdom:

par(las=1)

On Tue, 14 Jan 2003 Liu.Chunhua at epamail.epa.gov wrote:

> 
> Dear R People,
> 
> I'm working on a plot function to produce the graph shown below. One of
> the features my supervisor does not like is that the labels in the Y-
> axix are shown vertically. Is there a way to change that to horizontally
> ?
> 
> This is the axix() function I used  :
> 
> axis(2,at=seq(nstrat),labels=snames)
> 
> The labels (snames)  are: SEV1:HU:C, SEV1:MU:C, SEV1:MU:L, SEV1:RT:C
> and SEV1:RT:L, due to space limitation just 3 of the labels are shown in
> the axix.
> In Splus, I believe the labels are shown horizontally be default. What
> we want is to show them horizontally in R too. Is there a way to do it ?
> 
> I studied help(axix) document, and did not see a way to do it.
> 
> THanks for the help
> 
> 
> Charlie Liu
> Graduate Intern at US EPA
> 
> 
> (Embedded image moved to file: pic08925.pcx)

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From RexBryan1 at attbi.com  Wed Jan 15 00:51:02 2003
From: RexBryan1 at attbi.com (Rex_Bryan@urscorp.com)
Date: Wed Jan 15 00:51:02 2003
Subject: [R] Is R really an open source S+ ?
Message-ID: <001401c2bc28$55a07cd0$3182fd0c@dell1700>

 This is not a criticism.  I'm just curious.  Is there an effort to keep R
comparable to S+?
Or are the two languages diverging?  I am doing what probably legions have
done before me,
and legions will after me...using R on examples from text books written with
S+ code.  Most of the
time everything appears to be equivalent.  And then there are amazing
divergences in commands.  For
instance:
S:  stdev
R:  sd

why this difference?
Other examples...

S:  Bootstrap
R:  Boot

S:  Jackknife
R:  NA

S: T, F
R: TRUE, FALSE

For those who want to use open source R but still use the excellent S+
literature...these differences can be confusing.  I can also appreciate the
stress on authors attempting to express code that works in both languages.

REX



From andy_liaw at merck.com  Wed Jan 15 02:34:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Jan 15 02:34:03 2003
Subject: [R] Is R really an open source S+ ?
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFCA63@usrymx10.merck.com>

> From: Rex_Bryan at urscorp.com [mailto:RexBryan1 at attbi.com]
> 
>  This is not a criticism.  I'm just curious.  Is there an 
> effort to keep R
> comparable to S+?
> Or are the two languages diverging?  I am doing what probably 
> legions have
> done before me,
> and legions will after me...using R on examples from text 
> books written with
> S+ code.  Most of the
> time everything appears to be equivalent.  And then there are amazing
> divergences in commands.  For
> instance:
> S:  stdev
> R:  sd

In older versions of Splus (and R), neither existed.  People simply do
sqrt(var(...)).
 
> why this difference?
> Other examples...
> 
> S:  Bootstrap
> R:  Boot
> 
> S:  Jackknife
> R:  NA

Arguably these are differences in added functionalities, and not in the core
language.  BTW, have you look in the "bootstrap" package for R (ported from
S)?  It does have bootstrap() and jackknife().
 
> S: T, F
> R: TRUE, FALSE

This (and other S/R differences) is covered in the R FAQ.  You *can* use T/F
in R, just not as safe as using TRUE/FALSE.

Andy
 
> For those who want to use open source R but still use the excellent S+
> literature...these differences can be confusing.  I can also 
> appreciate the
> stress on authors attempting to express code that works in 
> both languages.
> 
> REX
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From p.connolly at hortresearch.co.nz  Wed Jan 15 04:21:03 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Wed Jan 15 04:21:03 2003
Subject: [R] Why are default sizes of plotting characters different?
Message-ID: <20030115032039.GE21374@hortresearch.co.nz>

I had occasion to use panel.superpose to draw points in a lattice
plot, and chose to set the size to 1.1 using trellis.par.set().  I
also wished to add some other plotting characters which I did with
grid.points.  To get them looking like the same size as those done
with panel.superpose, I needed to set the size to 0.8 using size =
unit(.8, "char").  Now they end up looking quite similar even if not
identical.

Evidently, the default values have different bases.  What is the
thinking behind those defaults?

thanks



-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From deepayan at stat.wisc.edu  Wed Jan 15 04:48:02 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed Jan 15 04:48:02 2003
Subject: [R] Why are default sizes of plotting characters different?
In-Reply-To: <20030115032039.GE21374@hortresearch.co.nz>
References: <20030115032039.GE21374@hortresearch.co.nz>
Message-ID: <200301142146.47961.deepayan@stat.wisc.edu>

On Tuesday 14 January 2003 09:20 pm, Patrick Connolly wrote:
> I had occasion to use panel.superpose to draw points in a lattice
> plot, and chose to set the size to 1.1 using trellis.par.set().  I
> also wished to add some other plotting characters which I did with
> grid.points.  To get them looking like the same size as those done
> with panel.superpose, I needed to set the size to 0.8 using size =
> unit(.8, "char").  Now they end up looking quite similar even if not
> identical.
>
> Evidently, the default values have different bases.  What is the
> thinking behind those defaults?

The grid defaults are whatever Paul decided :) The defaults in lattice were 
chosen so that things look approximately similar to comparable Trellis plots 
in S-Plus. The precise definition in lattice is 

cex = 1 <==> size = unit(2.5, "mm")



From neteler at itc.it  Wed Jan 15 08:11:03 2003
From: neteler at itc.it (Markus Neteler)
Date: Wed Jan 15 08:11:03 2003
Subject: [R] install problem: gpclib
In-Reply-To: <20030114133903.L11094@jimmy.harvard.edu>; from rgentlem@jimmy.harvard.edu on Tue, Jan 14, 2003 at 01:39:03PM -0500
References: <20030114172704.L23470@itc.it> <Pine.SOL.4.20.0301141132400.26282-100000@santiam.dfci.harvard.edu> <20030114193521.Y23470@itc.it> <20030114133903.L11094@jimmy.harvard.edu>
Message-ID: <20030115080955.A14898@itc.it>

On Tue, Jan 14, 2003 at 01:39:03PM -0500, Robert Gentleman wrote:
> On Tue, Jan 14, 2003 at 07:35:21PM +0100, Markus Neteler wrote:
> > R-161
> > R : Copyright 2002, The R Development Core Team
> > Version 1.6.1  (2002-11-01)
> > [...]
> > system("R CMD INSTALL gpclib_1.0-1.tar.gz")
> > WARNING: ignoring environment value of R_HOME
> > ERROR: This R is version 1.5.0
> >        package 'gpclib' depends on R 1.6.1
> > 
>   Well, something is not right with your installation. The packages
>   believe that you are running 1.5.0 not 1.6.1. Are you sure you are
>   running 1.6.1 -- it does not look like that is true.

My apologize - it was in fact a local install problem.

Excuse me for having taken up your time,
 
 Markus Neteler



From ligges at statistik.uni-dortmund.de  Wed Jan 15 08:28:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Jan 15 08:28:03 2003
Subject: [R] Universal legend for graph...
In-Reply-To: <F30FSZ6FYWcB2KWFYob00005a2e@hotmail.com>
References: <F30FSZ6FYWcB2KWFYob00005a2e@hotmail.com>
Message-ID: <3E250C9A.2090907@statistik.uni-dortmund.de>

Vumani Dlamini wrote:
> 
> Dear R-Users:
> 
> I am trying to create a graph with 6 panels, but would like to have a 
> universal legend as each panel merely denotes a separate stratum. The 
> legend has to be at the bottom.
> 
> I use "par(mfrow=c(2,3))" to get the panels, but am not sure how to put 
> the legend below the whole graph.
> 
> Thanking you as always.


Try layout() for finer adjustments (and some drawbacks).
See ?layout how to set up a 7th figure (legend) of full with below the 
desired six other figures.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Wed Jan 15 08:55:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Jan 15 08:55:03 2003
Subject: [R] building R1.6.2 from source (windows2k)
In-Reply-To: <002901c2bbe9$844bf620$203c07d5@c5c9i0>
References: <Pine.LNX.4.44.0301140923540.3601-100000@gannet.stats> <002901c2bbe9$844bf620$203c07d5@c5c9i0>
Message-ID: <3E251381.9050909@statistik.uni-dortmund.de>

Christian Schulz wrote:
>>Do read more carefully.  The file INSTALL says `doc/manual'!
> 
> 
> many thanks !
> I work with the very usefuel  manual
> "R for Windows Users 2.0" from Ko-Kang Kevin Wang ,
> but IMHO here is a small mistake (Page 13!) ?
> 
> Sorry for my newbie problems, but why the
> "make docs" ends not fine and the "make recomended"
> didn't work ?
> 
> many thanks for help to enter this adventure
> christian
> 
> 
> [snip- last output after make docs]
> 
> l.10 @documentlanguage en
> 
> ?

Hm. I've seen this on solaris - and haven't investigated further. My 
guess is a missing or outdated package. If someone is interested, I'll 
look closer.
Are you sure you have updated MikTeX in a clean manner (including a new 
build of format files and filename databases?).

[many lines of output]


> [snip - output from make recomended ]
> C:\Rcompile\R-1.6.2\src\Recomended\
>  only with the packed recommended packages exist ???
> 
> 
> - C:\Rcompile\R-1.6.2\src\gnuwin32>make recommended
> --- Unpacking recommended packages
> ---- VR
> 
> gzip: stdin: unexpected end of file


I guess you used any windows (un)zip-(un)tar tool to extract the 
archives, which doesn't work very well.
Use
  tar xfz R-1.6.2.tgz
with tar from the tool collection to extract it. Some links in the 
../src/library/Recommended directory are not resolvable having used a 
bad tar tool.

[many lines of output]


Uwe Ligges

BTW: There is a binary build on CRAN.



From bhx2 at mevik.net  Wed Jan 15 09:29:02 2003
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge?= Mevik)
Date: Wed Jan 15 09:29:02 2003
Subject: [R] PLS regression?
In-Reply-To: <FF503547C1F8D211BD2C0008C7C5640114A66AAB@exdkba06.novo.dk>
References: <FF503547C1F8D211BD2C0008C7C5640114A66AAB@exdkba06.novo.dk>
Message-ID: <7o4r8ahl6j.fsf@foo.nemo-project.org>

I'm writing a package for PLSR and PCR.  It is not ready for "release"
yet, but I could email you a copy if you want.

-- 
Bj?rn-Helge Mevik



From maechler at stat.math.ethz.ch  Wed Jan 15 09:43:03 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Jan 15 09:43:03 2003
Subject: [R] Is R really an open source S+ ?
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFCA63@usrymx10.merck.com>
References: <51F9C42DA15CD311BD220008C707D81906FFCA63@usrymx10.merck.com>
Message-ID: <15909.7909.165337.980671@gargle.gargle.HOWL>

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Tue, 14 Jan 2003 20:33:42 -0500 writes:

    >> From: Rex_Bryan at urscorp.com [mailto:RexBryan1 at attbi.com]
    >> 
    >> This is not a criticism.  I'm just curious.  Is there an 
    >> effort to keep R comparable to S+?

{see also below}

First clarification:  
We always made a point of being an open source implementation of S.
S+ , correctly "S-PLUS" (all caps), based on the original
S implementation from Bell Labs, is another implementation.
And as a matter of fact, S+ used to be several quite different
ones, Windows and Unix Versions were quite diverse and even for
the same platform, changes between release numbers were considerable.

    >> Or are the two languages diverging?  

  (``one language, two dialects'' is what the ESS team uses,
   ``one language, two engines'' or ``two implementations'' is
   used in MASS (the book) and other places)

There's a real danger I would regret quite a bit...

Our (R-core) strategy has been to stay compatible with S-plus if
there was no strong reason against it.
Nowadays, it has become quite a bit more important to stay
back-compatible with older versions of R (if there was not a
good reason...).

    >> I am doing what probably legions have done before me,
    >> and legions will after me...using R on examples from text 
    >> books written with S+ code.  

We hope there will be more text books in the future written with
R code ...  there's Peter Dalgaard's good introductory statistics book already,
and MASS (4th ed. in particular) really written for both (or all) engines.

    >> Most of the time everything appears to be equivalent.
    >> And then there are amazing divergences in commands.  For
    >> instance:

    >> S:  stdev
    >> R:  sd

    AndyL> In older versions of Splus (and R), neither existed.
    AndyL> People simply do sqrt(var(...)).
 
    >> why this difference?

Just to add to this particular example:  
sd()    has existed in R since the very beginning (~ 1996).
stdev() was introduced into S-plus for version 6.0 (~ 2001) only.
Guess who is not caring about compatibility..

In the past, we have had good contacts with Insightful staff and
efforts were started to at least stay compatible for *new* developments.
Maybe Insightful costumers using both S+ and R should voice
their opinion towards Insightful.

There's much more to be said on this topic, in particular,
copyright and licence problems.
Just let me emphasize again: 
     R is "GNU S",  *not* an S+ clone]

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From a.letertre at invs.sante.fr  Wed Jan 15 09:47:03 2003
From: a.letertre at invs.sante.fr (Alain LE TERTRE)
Date: Wed Jan 15 09:47:03 2003
Subject: [R] [R]Summary: Random number generator in R compared to S
In-Reply-To: <3E24307E.BB185B25@bank-banque-canada.ca>
Message-ID: <000801c2bc72$3f51bc10$37c9a8c0@ALETERTRE>

Thanks to tom blackwell and Paul Gilbert for the help on my question below.
Tom suggested using a system command in S to run R  (using a batch file),
apply the functions, generate output in a file readable in S.
Paul suggested to use his function to generate random number in S with the
same random number generator used in R (see his syskern package).
thanks again

O__ ---- Alain Le Tertre
 c/ /'_ --- Institut de Veille Sanitaire (InVS)
(*) \(*) -- 12 rue du val d'Osne
~~~~~~~~~~ - 94415 Saint Maurice cedex FRANCE
Voice: 33 1 41 79 67 50 Fax: 33 1 41 79 67 68
email: a.letertre at invs.sante.fr


-----Message d'origine-----
De : r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]De la part de Paul Gilbert
Envoye : mardi 14 janvier 2003 16:45
A : a.letertre at invs.sante.fr
Cc : r-help at stat.math.ethz.ch
Objet : Re: [R] Random number generator in R compared to S


Alain LE TERTRE wrote:
>
> I'm doing some simulations for which i need to use both S-plus and R.
> I generate in S+ some random normal distributions to define one dataset by
> iteration.  I need to use the same dataset generated in S-plus in R.
> I was first thinking to generate in R the same dataset by using the same
> random number generator with a fixed seed. But It seems that S-plus and R
> don't use the same random number generator.
> So my question is: Is there a way to pass dynamically dataset generated in
> S-plus to R, run a command, extract results, and pass them back to S-plus?
> Or is it more efficient to generate all the datasets in S-plus and export
> them to R?
> Or anything else?
>
> Any hints will be greatly appreciated.



From dieter.menne at menne-biomed.de  Wed Jan 15 11:07:02 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed Jan 15 11:07:02 2003
Subject: [R] ts.union and tsp
Message-ID: <JLEPLGAANFCEAEDCAGJNKEAACEAA.dieter.menne@menne-biomed.de>

I don't understand the following behavior of ccf

library(ts)
a<-runif(100)
b<-runif(100)

acf(a) # works
ccf(a,b) # fails

#.. because of the following 
ts.union(a,b)

# which fails on tsp(x) in .cbind.ts 
#tsser <- sapply(sers, function(x) length(tsp(x)) > 0)


(R 1.6.1, Windows)

Dieter Menne



From Roger.Bivand at nhh.no  Wed Jan 15 11:19:05 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed Jan 15 11:19:05 2003
Subject: [R] ts.union and tsp
In-Reply-To: <JLEPLGAANFCEAEDCAGJNKEAACEAA.dieter.menne@menne-biomed.de>
Message-ID: <Pine.LNX.4.44.0301151115290.16768-100000@reclus.nhh.no>

On Wed, 15 Jan 2003, Dieter Menne wrote:

> I don't understand the following behavior of ccf
> 
> library(ts)
> a<-runif(100)
> b<-runif(100)

Maybe:

> a <- ts(runif(100))
> b <- ts(runif(100))

acf() converts the input vector to the needed class, ccf() doesn't.

> 
> acf(a) # works
> ccf(a,b) # fails
> 
> #.. because of the following 
> ts.union(a,b)
> 
> # which fails on tsp(x) in .cbind.ts 
> #tsser <- sapply(sers, function(x) length(tsp(x)) > 0)
> 
> 
> (R 1.6.1, Windows)
> 
> Dieter Menne
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From wolfram at fischer-zim.ch  Wed Jan 15 12:13:05 2003
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Wed Jan 15 12:13:05 2003
Subject: [R] lattice: cloud: aspect ratio, labels, vertical lines
Message-ID: <20030115121510.A3021@s1x.zimnet.ch>

I am interested to know how to make for clouds:
- aspect ratio = 1
- labels attached to points
- vertical lines from the points to the x/y base plane

I tried:
    t = c( 'A', 'B', 'C', 'D' )
    x = c( 100,   0, 200, 100 )
    y = c(   0, 100,   0, 100 )
    z = c(  80,   0,  20,  40 )

    q = data.frame( x, y, z )
    rownames( q ) = t

    print(cloud( z ~ x * y, data = q, type = c( 'p', 'h' )
        , scales = list( arrows=FALSE )
        , aspect = c( max(y)/max(x), max(z)/max(x) )
    ))


My questions:
- Is there an easier way to tell that aspect ratio should be 1
  on all dimensions, especially without the precalculations
  of max(...)?
- "type = 'h'" does not work as I expected. What to do?
- How can I get the labels of t into the graphic?

Thanks

Wolfram



From mbalcilar at manas.kg  Wed Jan 15 13:32:05 2003
From: mbalcilar at manas.kg (Mehmet Balcilar)
Date: Wed Jan 15 13:32:05 2003
Subject: [R] multiply matrix by a scalar
Message-ID: <3E248CBC.3050500@manas.kg>

This is not the correct group to post this question. Sorry, but I 
subscribe nowhere else.

What is the BLAS routine to multiply a matrix by a scalar?

Thanks.

-- 
Mehmet Balcilar, PhD
Assistant Professor
Manas University
College of Economics & Administrative Sciences
Department of Economics
Prospect Tinctik 56
Bishkek
Kyrgyzstan

Tel: +996 (312) 54 19 42
      +996 (312) 54 19 43
      +996 (312) 54 19 45

Fax: +996 (312) 54 19 35

e-mail: mbalcilar at manas.kg

Homepage: http://rifle.manas.kg
Reproducible Research Page: http://rifle.manas.kg/rresearch



From cribari at ufpe.br  Wed Jan 15 14:21:03 2003
From: cribari at ufpe.br (Francisco Cribari)
Date: Wed Jan 15 14:21:03 2003
Subject: [R] Tobit regression
Message-ID: <20030115121828.787464EA8@edgeworth.de.ufpe.br>

Does anyone have an R function for the estimation of Tobit regression 
models (for censored responses), as described, e.g., in Davidson, R. 
and MacKinnon, J.G., 1993, Section 15.7, Estimation and Inference in
Econometrics, Oxford University Press? 

Thanks. FC. 

--
Francisco Cribari-Neto               voice: +55-81-32718420
Departamento de Estatistica          fax:   +55-81-32747425
Universidade Federal de Pernambuco   e-mail: cribari at de.ufpe.br
Recife/PE, 50740-540, Brazil         web: www.de.ufpe.br/~cribari

     Asymptotics is the art of knowing where to be sloppy
     and where to be precise.



From cg.pettersson at evp.slu.se  Wed Jan 15 14:43:04 2003
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Wed Jan 15 14:43:04 2003
Subject: [R] Updating R
Message-ID: <200301151342.OAA31543@mail1.slu.se>

Hi!
The installing and updating functions for packages in R (install.package() , update.package()) really impresses me in behavior.
For the moment I run R 1.5.1 and got warning messages after installing the "multcomp" package, as it is built under R 1.6.1.
Is there any similar smooth ways of updating the R-version as there is for packages? I?ve looked in all places I can think of but can?t find any hints.

Thanks
/CG
CG Pettersson
cg.pettersson at evp.slu.se



From sundar.dorai-raj at pdf.com  Wed Jan 15 14:49:02 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed Jan 15 14:49:02 2003
Subject: [R] Tobit regression
References: <20030115121828.787464EA8@edgeworth.de.ufpe.br>
Message-ID: <3E25667F.1090406@pdf.com>

Francisco,

Francisco Cribari wrote:
> Does anyone have an R function for the estimation of Tobit regression 
> models (for censored responses), as described, e.g., in Davidson, R. 
> and MacKinnon, J.G., 1993, Section 15.7, Estimation and Inference in
> Econometrics, Oxford University Press? 
> 
> Thanks. FC. 
> 


See survreg in library(survival). Choosing dist="gaussian" should give 
the tobit result if I remember correctly. It's been several years since 
I've worked with them.

Sundar



From ripley at stats.ox.ac.uk  Wed Jan 15 15:00:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed Jan 15 15:00:03 2003
Subject: [R] Updating R
In-Reply-To: <200301151342.OAA31543@mail1.slu.se>
Message-ID: <Pine.WNT.4.44.0301151354340.2420-100000@gannet.stats.ox.ac.uk>

On what OS?

On Windows, see the rw-FAQ Q2.5.  As you may need one later than your
ancient version of R possesses, look on CRAN or at

http://www.stats.ox.ac.uk/pub/R/rw-FAQ.html


On Wed, 15 Jan 2003, CG Pettersson wrote:

> Hi!
> The installing and updating functions for packages in R (install.package() , update.package()) really impresses me in behavior.
> For the moment I run R 1.5.1 and got warning messages after installing the
"multcomp" package, as it is built under R 1.6.1.

Is this Windows, then?  If so, no wonder: the ReadMe on CRAN does say that
the precompiled packages are for rw1060 or later.

> Is there any similar smooth ways of updating the R-version as there is for packages?
I´ve looked in all places I can think of but can´t find any hints.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jasont at indigoindustrial.co.nz  Wed Jan 15 15:08:03 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed Jan 15 15:08:03 2003
Subject: [R] Updating R
In-Reply-To: <200301151342.OAA31543@mail1.slu.se>; from cg.pettersson@evp.slu.se on Wed, Jan 15, 2003 at 02:45:10PM +0100
References: <200301151342.OAA31543@mail1.slu.se>
Message-ID: <20030116030626.B27598@camille.indigoindustrial.co.nz>

On Wed, Jan 15, 2003 at 02:45:10PM +0100, CG Pettersson wrote:
> Hi!
> The installing and updating functions for packages in R (install.package() , update.package()) really impresses me in behavior.
...
> Is there any similar smooth ways of updating the R-version as there is for packages? I?ve looked in all places I can think of but can?t find any hints.

No.  You download the latest copy, and install it.  On Windows, just
delete the old directory after the new version is successfully
installed.  In your case, (assuming Windows in an English locale) the
old directory would be  c:\Program Files\R\rw1051

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From bates at stat.wisc.edu  Wed Jan 15 15:14:02 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed Jan 15 15:14:02 2003
Subject: [R] multiply matrix by a scalar
In-Reply-To: <3E248CBC.3050500@manas.kg>
References: <3E248CBC.3050500@manas.kg>
Message-ID: <6rptqyh56f.fsf@bates4.stat.wisc.edu>

Mehmet Balcilar <mbalcilar at manas.kg> writes:

> This is not the correct group to post this question. Sorry, but I
> subscribe nowhere else.
> 
> 
> What is the BLAS routine to multiply a matrix by a scalar?

I suppose you could use dgemm with alpha = 0. and dummy arguments for
A and B.  I don't know if there would be any advantage in doing the
calculation this way.

The C declaration corresponding to the Fortran subroutine is

/* Level 3 BLAS */

/* DGEMM - perform one of the matrix-matrix operations    */
/* C := alpha*op( A )*op( B ) + beta*C,                   */
void F77_NAME(dgemm)(const char *transa, const char *transb,
		     const int *m, const int *n,
		     const int *k, const double *alpha,
		     const double *a, const int *lda,
		     const double *b, const int *ldb,
		     const double *beta, double *c, const int *ldc);



From devinec at sas.upenn.edu  Wed Jan 15 15:19:03 2003
From: devinec at sas.upenn.edu (Colin Devine)
Date: Wed Jan 15 15:19:03 2003
Subject: [R] compile problems on solairs 8
Message-ID: <3E256AE4.AE0DEA0C@sas.upenn.edu>

Hello,

I am having a problem compiling R versions 1.6.1 or .16.2 on a Solaris 8
machine.  It sees to have problems with an X11 module.  Here is the
relevant output:

make[4]: Entering directory `/pkg-ling/src/R-1.6.2/src/modules/X11'
gcc -I. -I../../../src/include -I../../../src/include
-I/pkg/X11R5/include -I/usr/local/include -DHAVE_CONFIG_H  -fPIC  -g -O2
-c dataentry.c -o dataentry.lo
dataentry.c: In function `doSpreadKey':
dataentry.c:1194: `XK_Page_Up' undeclared (first use in this function)
dataentry.c:1194: (Each undeclared identifier is reported only once
dataentry.c:1194: for each function it appears in.)
dataentry.c:1198: `XK_Page_Down' undeclared (first use in this function)
make[4]: *** [dataentry.lo] Error 1
make[4]: Leaving directory `/pkg-ling/src/R-1.6.2/src/modules/X11'
make[3]: *** [R] Error 2
make[3]: Leaving directory `/pkg-ling/src/R-1.6.2/src/modules/X11'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/pkg-ling/src/R-1.6.2/src/modules'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/pkg-ling/src/R-1.6.2/src'
make: *** [R] Error 1
bash-2.02#


I have searched the archives without luck and the X libraries are found:

checking for X... libraries /pkg/X11R5/lib, headers /pkg/X11R5/include

Thanks in advance for your assistance.

--Colin Devine



From paradis at isem.univ-montp2.fr  Wed Jan 15 15:25:48 2003
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Wed Jan 15 15:25:48 2003
Subject: [R] Universal legend for graph...
In-Reply-To: <3E250C9A.2090907@statistik.uni-dortmund.de>
References: <F30FSZ6FYWcB2KWFYob00005a2e@hotmail.com>
 <F30FSZ6FYWcB2KWFYob00005a2e@hotmail.com>
Message-ID: <4.2.0.58.20030115150803.00af2b80@162.38.183.200>

A 08:24 15/01/2003 +0100, Uwe Ligges a ?crit:
>Vumani Dlamini wrote:
>>Dear R-Users:
>>I am trying to create a graph with 6 panels, but would like to have a 
>>universal legend as each panel merely denotes a separate stratum. The 
>>legend has to be at the bottom.
>>I use "par(mfrow=c(2,3))" to get the panels, but am not sure how to put 
>>the legend below the whole graph.
>>Thanking you as always.
>
>
>Try layout() for finer adjustments (and some drawbacks).
>See ?layout how to set up a 7th figure (legend) of full with below the 
>desired six other figures.
>
>Uwe Ligges

It sounds that what Vumani wants is a job for the lattice package. For 
instance, in ?xyplot (and also other functions of this package), look at 
the argument "key".

Hoping this helps.

Emmanuel Paradis



From yuelin at mail.med.upenn.edu  Wed Jan 15 15:46:02 2003
From: yuelin at mail.med.upenn.edu (Yuelin Li)
Date: Wed Jan 15 15:46:02 2003
Subject: [R] compile problems on solairs 8
Message-ID: <200301151445.h0FEjDs15902@pandora.outcomes.chop.edu>

Hi,

I had similar problems but finally successfully compiled R-1.6.2 
on Solaris 8 after changing some variables in config.site.  I 
think R's error messages about X11 come from the compiler, not 
from the libraries within R source.  My customizations may not 
solve your problem, but they may be worth a try.

The biggest difficulty is to tell ./configure where to look for 
compilers, libraries and standard include files.  This is done by 
changing variables in ./config.site before you run ./configure.

I have a standard Solaris 8 installation, which includes 
gcc-2.95.2 under /opt/sfw/bin.  Also found there are gmake, g++, 
etc.  The /usr/ucb/cc compiler should not be used because the 
standard Solaris 8 does not have all the libraries.

There are two steps:

  1. make sure your PATH includes /opt/sfw/bin, mine is:
  
  PATH =/usr/sbin:/usr/bin:/usr/local/bin:\
  /usr/local/sbin:/usr/dt/bin:/usr/openwin/bin:\
  /bin:/usr/ucb:/opt/sfw/bin:/opt/sfw/lib:/opt/teTeX/bin:

  2. comment out and change these variables in ./config.site
  CC=/opt/sfw/bin/gcc
  
  CPPFLAGS="-I/opt/sfw/include -I/opt/sfw/include/readline 
-I/usr/local/include"
  
  LDFLAGS="-L/opt/sfw/lib -L/usr/lib -L/usr/local/lib 
-L/opt/sfw/share/aclocal -L/opt/sfw/share/autoconf 
-L/opt/sfw/share/automake -L/opt/sfw/share/awk
  
   TCLTK_LIBS="-L/opt/sfw/lib -L/usr/local/lib 
-L/opt/sfw/share/aclocal -L/opt/sfw/share/autoconf 
-L/opt/sfw/share/automake -L/opt/sfw/share/awk"
   
   TCLTK_CPPFLAGS="-I/opt/sfw/include -I/opt/sfw/include/readline 
-I/usr/local/include"

   MAKE=/opt/sfw/bin/gmake
  
Some of the paths are redundant but I have not explored which 
ones can be omitted.  These changes work fine since R-1.5.1.

Then you run ./configure and make as usual. 

Please let me know if it works on your machine.  

Yuelin Li.

----------
   
  Hello,
  
  I am having a problem compiling R versions 1.6.1 or .16.2 on a 
Solaris 8
  machine.  It sees to have problems with an X11 module.  Here is 
the
  relevant output:
  
  make[4]: Entering directory 
`/pkg-ling/src/R-1.6.2/src/modules/X11'
  gcc -I. -I../../../src/include -I../../../src/include
  -I/pkg/X11R5/include -I/usr/local/include -DHAVE_CONFIG_H  
-fPIC  -g -O2
  -c dataentry.c -o dataentry.lo
  dataentry.c: In function `doSpreadKey':
  dataentry.c:1194: `XK_Page_Up' undeclared (first use in this 
function)
  dataentry.c:1194: (Each undeclared identifier is reported only 
once
  dataentry.c:1194: for each function it appears in.)
  dataentry.c:1198: `XK_Page_Down' undeclared (first use in this 
function)
  make[4]: *** [dataentry.lo] Error 1
  make[4]: Leaving directory 
`/pkg-ling/src/R-1.6.2/src/modules/X11'
  make[3]: *** [R] Error 2
  make[3]: Leaving directory 
`/pkg-ling/src/R-1.6.2/src/modules/X11'
  make[2]: *** [R] Error 1
  make[2]: Leaving directory `/pkg-ling/src/R-1.6.2/src/modules'
  make[1]: *** [R] Error 1
  make[1]: Leaving directory `/pkg-ling/src/R-1.6.2/src'
  make: *** [R] Error 1
  bash-2.02#
  
  
  I have searched the archives without luck and the X libraries 
are found:
  
  checking for X... libraries /pkg/X11R5/lib, headers 
/pkg/X11R5/include
  
  Thanks in advance for your assistance.
  
  --Colin Devine
  
  ______________________________________________
  R-help at stat.math.ethz.ch mailing list
  http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Wed Jan 15 15:51:08 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 15 15:51:08 2003
Subject: [R] compile problems on solairs 8
In-Reply-To: <3E256AE4.AE0DEA0C@sas.upenn.edu>
Message-ID: <Pine.LNX.4.44.0301151444430.1254-100000@gannet.stats>

You need to use a current X11R6, which on Solaris is under /usr/openwin.

X11R5 is about a decade old, AFAIR, so no wonder R's configure does not 
check for it.

On Wed, 15 Jan 2003, Colin Devine wrote:

> Hello,
> 
> I am having a problem compiling R versions 1.6.1 or .16.2 on a Solaris 8
> machine.  It sees to have problems with an X11 module.  Here is the
> relevant output:
> 
> make[4]: Entering directory `/pkg-ling/src/R-1.6.2/src/modules/X11'
> gcc -I. -I../../../src/include -I../../../src/include
> -I/pkg/X11R5/include -I/usr/local/include -DHAVE_CONFIG_H  -fPIC  -g -O2
> -c dataentry.c -o dataentry.lo
> dataentry.c: In function `doSpreadKey':
> dataentry.c:1194: `XK_Page_Up' undeclared (first use in this function)
> dataentry.c:1194: (Each undeclared identifier is reported only once
> dataentry.c:1194: for each function it appears in.)
> dataentry.c:1198: `XK_Page_Down' undeclared (first use in this function)
> make[4]: *** [dataentry.lo] Error 1
> make[4]: Leaving directory `/pkg-ling/src/R-1.6.2/src/modules/X11'
> make[3]: *** [R] Error 2
> make[3]: Leaving directory `/pkg-ling/src/R-1.6.2/src/modules/X11'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/pkg-ling/src/R-1.6.2/src/modules'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/pkg-ling/src/R-1.6.2/src'
> make: *** [R] Error 1
> bash-2.02#
> 
> 
> I have searched the archives without luck and the X libraries are found:
> 
> checking for X... libraries /pkg/X11R5/lib, headers /pkg/X11R5/include
> 
> Thanks in advance for your assistance.
> 
> --Colin Devine
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From stop4optimal at hotmail.com  Wed Jan 15 15:55:04 2003
From: stop4optimal at hotmail.com (chenwj)
Date: Wed Jan 15 15:55:04 2003
Subject: [R] how to record the CPU time
Message-ID: <OE22uIU1Gj03oHMwVN7000044d6@hotmail.com>

is there any function can record the CPU time when running a paragraph of
code?

if it is, can anyone show me an little example of how-to?

thanks a lot!



From jgentry at jimmy.harvard.edu  Wed Jan 15 15:59:28 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Wed Jan 15 15:59:28 2003
Subject: [R] how to record the CPU time
In-Reply-To: <OE22uIU1Gj03oHMwVN7000044d6@hotmail.com>
Message-ID: <Pine.SOL.4.20.0301150956540.29816-100000@santiam.dfci.harvard.edu>

On Wed, 15 Jan 2003, chenwj wrote:
> is there any function can record the CPU time when running a paragraph of
> code?

system.time() should do what you want, I believe.

> if it is, can anyone show me an little example of how-to?

There are examples of usage in help("system.time")

-J



From ripley at stats.ox.ac.uk  Wed Jan 15 16:03:07 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 15 16:03:07 2003
Subject: [R] how to record the CPU time
In-Reply-To: <OE22uIU1Gj03oHMwVN7000044d6@hotmail.com>
Message-ID: <Pine.LNX.4.44.0301151500060.1254-100000@gannet.stats>

?system.time

as found by help.search("CPU time")!


On Wed, 15 Jan 2003, chenwj wrote:

> is there any function can record the CPU time when running a paragraph of
> code?
> 
> if it is, can anyone show me an little example of how-to?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Jan 15 16:06:26 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 15 16:06:26 2003
Subject: [R] compile problems on solairs 8
In-Reply-To: <200301151445.h0FEjDs15902@pandora.outcomes.chop.edu>
Message-ID: <Pine.LNX.4.44.0301151451590.1254-100000@gannet.stats>

On Wed, 15 Jan 2003, Yuelin Li wrote:

> I had similar problems but finally successfully compiled R-1.6.2 
> on Solaris 8 after changing some variables in config.site.  I 
> think R's error messages about X11 come from the compiler, not 
> from the libraries within R source. 

They clearly come from the use of X11R5 include files!

>  My customizations may not 
> solve your problem, but they may be worth a try.
> 
> The biggest difficulty is to tell ./configure where to look for 
> compilers, libraries and standard include files.  This is done by 
> changing variables in ./config.site before you run ./configure.
> 
> I have a standard Solaris 8 installation, which includes 
> gcc-2.95.2 under /opt/sfw/bin.  Also found there are gmake, g++, 

If that's true (and it is not for our installation) I do advise upgrading
the compiler to at least 2.95.3 and probably 3.2 (3.2.1 generating code
that fails with R on 32-bit Solaris 2.7 at least).
http://www.sunfreeware.com has all three for Solaris 8.

> etc.  The /usr/ucb/cc compiler should not be used because the 
> standard Solaris 8 does not have all the libraries.

It should not be used, period.

> There are two steps:
> 
>   1. make sure your PATH includes /opt/sfw/bin, mine is:
>   
>   PATH =/usr/sbin:/usr/bin:/usr/local/bin:\
>   /usr/local/sbin:/usr/dt/bin:/usr/openwin/bin:\
>   /bin:/usr/ucb:/opt/sfw/bin:/opt/sfw/lib:/opt/teTeX/bin:
> 
>   2. comment out and change these variables in ./config.site
>   CC=/opt/sfw/bin/gcc
>   
>   CPPFLAGS="-I/opt/sfw/include -I/opt/sfw/include/readline 
> -I/usr/local/include"
>   
>   LDFLAGS="-L/opt/sfw/lib -L/usr/lib -L/usr/local/lib 
> -L/opt/sfw/share/aclocal -L/opt/sfw/share/autoconf 
> -L/opt/sfw/share/automake -L/opt/sfw/share/awk
>   
>    TCLTK_LIBS="-L/opt/sfw/lib -L/usr/local/lib 
> -L/opt/sfw/share/aclocal -L/opt/sfw/share/autoconf 
> -L/opt/sfw/share/automake -L/opt/sfw/share/awk"
>    
>    TCLTK_CPPFLAGS="-I/opt/sfw/include -I/opt/sfw/include/readline 
> -I/usr/local/include"
> 
>    MAKE=/opt/sfw/bin/gmake
>   
> Some of the paths are redundant but I have not explored which 
> ones can be omitted.  These changes work fine since R-1.5.1.

All you appear to need are CPPFLAGS and LDFLAGS="-L/opt/sfw/lib
-L/usr/local/lib", as you should be setting the path to yout tclconfig.sh
with the configure flags.



> 
> Then you run ./configure and make as usual. 
> 
> Please let me know if it works on your machine.  
> 
> Yuelin Li.
> 
> ----------
>    
>   Hello,
>   
>   I am having a problem compiling R versions 1.6.1 or .16.2 on a 
> Solaris 8
>   machine.  It sees to have problems with an X11 module.  Here is 
> the
>   relevant output:
>   
>   make[4]: Entering directory 
> `/pkg-ling/src/R-1.6.2/src/modules/X11'
>   gcc -I. -I../../../src/include -I../../../src/include
>   -I/pkg/X11R5/include -I/usr/local/include -DHAVE_CONFIG_H  
> -fPIC  -g -O2
>   -c dataentry.c -o dataentry.lo
>   dataentry.c: In function `doSpreadKey':
>   dataentry.c:1194: `XK_Page_Up' undeclared (first use in this 
> function)
>   dataentry.c:1194: (Each undeclared identifier is reported only 
> once
>   dataentry.c:1194: for each function it appears in.)
>   dataentry.c:1198: `XK_Page_Down' undeclared (first use in this 
> function)
>   make[4]: *** [dataentry.lo] Error 1
>   make[4]: Leaving directory 
> `/pkg-ling/src/R-1.6.2/src/modules/X11'
>   make[3]: *** [R] Error 2
>   make[3]: Leaving directory 
> `/pkg-ling/src/R-1.6.2/src/modules/X11'
>   make[2]: *** [R] Error 1
>   make[2]: Leaving directory `/pkg-ling/src/R-1.6.2/src/modules'
>   make[1]: *** [R] Error 1
>   make[1]: Leaving directory `/pkg-ling/src/R-1.6.2/src'
>   make: *** [R] Error 1
>   bash-2.02#
>   
>   
>   I have searched the archives without luck and the X libraries 
> are found:
>   
>   checking for X... libraries /pkg/X11R5/lib, headers 
> /pkg/X11R5/include
>   
>   Thanks in advance for your assistance.
>   
>   --Colin Devine
>   
>   ______________________________________________
>   R-help at stat.math.ethz.ch mailing list
>   http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Zhongming.Yang at cchmc.org  Wed Jan 15 16:36:03 2003
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Wed Jan 15 16:36:03 2003
Subject: [R] Exception Handling
Message-ID: <se253961.091@mailx.chmcc.org>

R Users:

How can I catch R errors and depend on this error call other R
functions in Perl? 

The foolowing is the error message when I use perl call R. 

Error in nls(modout ~ exp(-b1 * modin)/(b2 + b3 * modin), trace = F,
start = c(b1 = 0.005,  : 
        singular gradient
Segmentation fault



Thanks,

Zhongming



From mmiller3 at iupui.edu  Wed Jan 15 16:43:08 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Wed Jan 15 16:43:08 2003
Subject: [R] [lattice] lines for stripplot (like dotplot) or jitter for dotplot?
Message-ID: <87fzrufmk3.fsf@lumen.indyrad.iupui.edu>

I'd like to use stripplot for some plots because I want to use
the jitter parameter.  On the other hand, I'd like to use dotplot
because I'd like to have the horizontal lines that it includes.
dotplot doesn't have a jitter option and I'm not having any
success with getting panel.grid(h=-1) with stripplot.  Can anyone
show me how to make dotplot-like lines on a stripplot?  Or how to
jitter the vertical plotting position on a dotplot?

Thanks, Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine



From matthew_wiener at merck.com  Wed Jan 15 16:49:03 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Wed Jan 15 16:49:03 2003
Subject: [R] [lattice] lines for stripplot (like dotplot) or jitter for dotplot?
Message-ID: <AEBD81486231A343B1813FE62D335225013175C3@usrymx15.merck.com>

You could jitter your data manually using jitter() (part of the base
package) and then use dotplot.

Hope this helps,

Matt Wiener
-----Original Message-----
From: mmiller3 at iupui.edu [mailto:mmiller3 at iupui.edu]
Sent: Wednesday, January 15, 2003 10:41 AM
To: r-help at stat.math.ethz.ch
Subject: [R] [lattice] lines for stripplot (like dotplot) or jitter for
dotplot?


I'd like to use stripplot for some plots because I want to use
the jitter parameter.  On the other hand, I'd like to use dotplot
because I'd like to have the horizontal lines that it includes.
dotplot doesn't have a jitter option and I'm not having any
success with getting panel.grid(h=-1) with stripplot.  Can anyone
show me how to make dotplot-like lines on a stripplot?  Or how to
jitter the vertical plotting position on a dotplot?

Thanks, Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------



From v_bill_pikounis at merck.com  Wed Jan 15 16:54:05 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Wed Jan 15 16:54:05 2003
Subject: [R] Exception Handling
Message-ID: <E827328028C66044B4998F2EC353CD30031850F7@usrymx12.merck.com>

Zhongming,

> R Users:
> 
> How can I catch R errors and depend on this error call other R
> functions in Perl? 

I am working on similar issues, perhaps. The simple CGI-type approach I am
exploring just involves having Perl check for such a string, such as
"Execution Halted" or the one you saw. Then you can decide what to do with
Perl for reporting the error.  For a more general solution, it may be that
you add a simple cat() string that says your R function/program succeeded
and then have Perl check for that. (I presume you are using Perl's system()
to make the call from Perl to R.)

To get more information from R about the exception/error in your program,
see various related functions, such as options("show.error.messages"),
geterrmessage(), try(), traceback(), etc.  There is a lot of flexibility in
both R and Perl to customize things as specific-to-general as you want them.

Hope this helps.

Best,
Bill

----------------------------------------
Bill Pikounis, Ph.D.
http://biometrics.merck.com/

Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

v_bill_pikounis at merck.com

Phone: 732 594 3913
Fax: 732 594 1565


> -----Original Message-----
> From: Zhongming Yang [mailto:Zhongming.Yang at cchmc.org]
> Sent: Wednesday, January 15, 2003 10:35 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Exception Handling
> 
> 
> R Users:
> 
> How can I catch R errors and depend on this error call other R
> functions in Perl? 
> 
> The foolowing is the error message when I use perl call R. 
> 
> Error in nls(modout ~ exp(-b1 * modin)/(b2 + b3 * modin), trace = F,
> start = c(b1 = 0.005,  : 
>         singular gradient
> Segmentation fault
> 
> 
> 
> Thanks,
> 
> Zhongming
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From fidler at math.utah.edu  Wed Jan 15 16:57:26 2003
From: fidler at math.utah.edu (Matthew L. Fidler)
Date: Wed Jan 15 16:57:26 2003
Subject: [R] Bug or Feature? LogLik.nls and non-central F distribution.
Message-ID: <1042608425.8141.25.camel@pceurp52.pharm.utah.edu>

I have a dataset that I am running non-linear regression on via the
following code:


Hill <- function(E0,Em,C50,g,C){
  #
  # Hill is the hill interaction function.
  #
  # E0 Represents the minimum interaction Effect
  #
  # Em Represents the Maximum Interaction Effect
  #
  # C50 represents the concentration at which 50% of the effect occurs.
  #
  # gamma represents the cooperativity of the interaction curve. 
Somtimes called the hill slope.
  #
  # C is the concentration of drug.
  #
  E0 + (Em-E0)*C^g/(C^g+C50^g)
}

short.alif.data <- read.table("shortAlifentanil.txt",header=TRUE);

short.alif.fit <- nls(
        formula = E ~ Hill(0,1,A50,g,A),
        data = short.alif.data,
        start=list(g=1,A50=0.1)
);

Which gives:

> summary(short.alif.fit);

Formula: E ~ Hill(0, 1, A50, g, A)

Parameters:
    Estimate Std. Error t value Pr(>|t|)    
g   5.689027   1.367207   4.161 0.025247 *  
A50 0.093200   0.004438  21.000 0.000236 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Residual standard error: 0.08848 on 3 degrees of freedom

Correlation of Parameter Estimates:
         g
A50 0.1761

> logLik(short.alif.fit);
`log Lik.' 6.307024 (df=1)

My problem with this number is that exp(logLik) > 1.  If the error
structure is independent, identically distributed normal (which I
assumed was the case), then the Likelihood function should only give a
number from 0 to 1...  I am running R 1.6.1.  Perhaps this is due to
some strange assumption of non-independent normals???  Maybe something
else???  I assumed that the Likelihood function should be

-n/2*log(2*pi)-n/2*log(d)-n/2

Where d=MLE (biased) estimator of the variance

My next bug observation is the non-central F distribution:

pf(qf(0.05,1,6-3,lower.tail=FALSE),1,6-3,ncp=1.92,lower.tail=FALSE)

This gives a power of a certain linear model that I have done.  However,
the tail is wrong.  To get the right answer you should type

pf(qf(0.05,1,6-3,lower.tail=FALSE),1,6-3,ncp=1.92,lower.tail=TRUE)

If one knows the bug, it is easy to get around, but... it shouldn't
return the wrong number.


-- 
Matthew L. Fidler
fidler at math.utah.edu

421 Wakra Way, Suite 318
Salt Lake City, UT 84108
(801) 581-7125
-------------------------------------------------------------------------
It looked like something resembling white marble, which was
probably what it was: something resembling white marble.
		-- Douglas Adams, "The Hitchhikers Guide to the Galaxy"



From mdeasnds at fs1.ser.man.ac.uk  Wed Jan 15 17:06:03 2003
From: mdeasnds at fs1.ser.man.ac.uk (Neil Shephard)
Date: Wed Jan 15 17:06:03 2003
Subject: [R] S-Plus compatability...
Message-ID: <3E25869F.3947.18486B5@localhost>

Dear all,

I was wondering if someone could point me in the right direction to 
solve a problem I've encountered.

I have a set of S-plus scripts which call an external program to 
analyse the data (the external program is called Genehunter and is 
used for genetic analysis).  There are a six scripts in total, five of 
which are called from the main script.  I made a few changes like 
changing unix > system, but I've encountered an error problem I'm 
not sure how to resolve.

The majority of the script appears to run fine, the external program 
is invoked okay, and it runs the analysis, however I get the error 
message...

Error in scan(file = file, what = what, sep = sep, quote = quote, dec 
= dec  :
line 1 did not have 2 elements

Using the traceback() command produces a list of eight 
commands, the eighth being the one that causes the error.

I've used grep -e 'scan' *.SSC to search the files for the scan 
command that might be creating the problem, but there is only one 
instance of scan in any of the six files, but the line it is on does not 
have the same syntax as the eigth line reported by traceback() that 
causes the error.

I can provide the scripts if required, but have not included them 
here as this msg is going to a list.

I'm not much of an expert with S-plus or R, and any help would be 
appreciated.

Thanks in advance,

Neil

Neil Shephard
Genetics Statistician
ARC Epidemiology Unit, University of Manchester
neil.shephard at man.ac.uk
neil.shephard at mindless.com

"Contrariwise, if it was so, it might be; and if it
were so it would be; but as it isn't, it ain't. That's
logic" - Tweedledee (Alice Through the Looking Glass)



From mmiller3 at iupui.edu  Wed Jan 15 17:10:05 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Wed Jan 15 17:10:05 2003
Subject: [R] [lattice] lines for stripplot (like dotplot) or jitter fo	r dotplot?
References: <AEBD81486231A343B1813FE62D335225013175C3@usrymx15.merck.com>
Message-ID: <87iswqcs9s.fsf@lumen.indyrad.iupui.edu>

>>>>> "Wiener," == Wiener, Matthew <matthew_wiener at merck.com> writes:

    > You could jitter your data manually using jitter() (part of
    > the base package) and then use dotplot.

    > Hope this helps,

That works for my horizontal values, which are numeric, but I
want to jitter vertically too, and those values are factor
levels.  

What I'm trying to do is to plot a factor vs time.  The factor is
a measurement type and the time is when the measurement was made.
I'm plotting it like this so that I can visually summarizer how
often different measurements are being made (or not made). 

I tried experimenting with sunflowerplot too, but it doesn't seem
to handle a factor as one of it's coordinate vectors.

Mike



From mhoward at micron.com  Wed Jan 15 17:19:03 2003
From: mhoward at micron.com (mhoward)
Date: Wed Jan 15 17:19:03 2003
Subject: [R] Contour Plots
Message-ID: <D7E178FC91F3D21186A90008C7B9A5B8114847FD@ntexchange09.micron.com>

r-help,

 I can't seem to get the below data organized in such a manner so as to
generate a contour plot
using any of the functions {lattice.contourplot, base.contour,
base.filled.contour}. I was wondering
if anyone could please tell me what I need to do to accomplish this.


X,Y,Level
-31.105,86.911,3843
-3.385,86.911,3896
24.335,86.911,3874
-24.175,79.700,3900
-3.385,79.700,3927
17.405,79.700,3922
-51.895,72.489,3874
52.056,72.489,3898
-44.965,65.278,3914
45.125,65.278,3951
-24.175,58.067,3931
17.405,58.067,3942
-79.615,50.856,3831
72.845,50.856,3914
-72.685,43.645,3891
65.915,43.645,3972
-44.965,36.434,3921
-3.385,36.434,3889
38.195,36.434,3965
-93.475,22.012,3812
86.705,22.012,3913
-86.545,14.801,3876
-65.755,14.801,3927
-24.175,14.801,3861
17.405,14.801,3872
58.985,14.801,3999
79.775,14.801,3970
-93.475,-6.832,3848
-86.545,-6.832,3894
-44.965,-6.832,3905
-3.385,-6.832,3848
38.195,-6.832,3949
79.775,-6.832,3983
86.705,-6.832,3942
-86.545,-21.254,3880
79.775,-21.254,3967
-93.475,-28.465,3839
-65.755,-28.465,3945
-24.175,-28.465,3906
17.405,-28.465,3931
58.985,-28.465,4011
86.705,-28.465,3899
-72.685,-50.098,3906
-44.965,-50.098,3971
-3.385,-50.098,3956
38.195,-50.098,4007
65.915,-50.098,3970
-79.615,-57.309,3894
72.845,-57.309,3896
-58.825,-64.520,3925
52.055,-64.520,3964
-65.755,-71.731,3868
-24.175,-71.731,3972
17.405,-71.731,3989
58.985,-71.731,3894
-17.245,-86.153,3926
-3.385,-86.153,3943
10.475,-86.153,3935
-24.175,-93.364,3855
-3.385,-93.364,3894
17.405,-93.364,3861

Thanks,

Michael R. Howard
Micron Technology, Inc
Fab C Engineering Software (FCES)
Phone368 - 2352 [82352]
Pager 90713



From p.dalgaard at biostat.ku.dk  Wed Jan 15 17:26:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Jan 15 17:26:02 2003
Subject: [R] Bug or Feature? LogLik.nls and non-central F distribution.
In-Reply-To: <1042608425.8141.25.camel@pceurp52.pharm.utah.edu>
References: <1042608425.8141.25.camel@pceurp52.pharm.utah.edu>
Message-ID: <x2of6iv0rh.fsf@biostat.ku.dk>

"Matthew L. Fidler" <fidler at math.utah.edu> writes:

> > logLik(short.alif.fit);
> `log Lik.' 6.307024 (df=1)
> 
> My problem with this number is that exp(logLik) > 1.  If the error
> structure is independent, identically distributed normal (which I
> assumed was the case), then the Likelihood function should only give a
> number from 0 to 1...  

Whatever gave you that idea? Likelihoods can easily be larger than 1
for the same reasons that densitites can. Besides, there is often a
multiplicative factor removed from the calculation when it depends on
data only.

> I am running R 1.6.1.  Perhaps this is due to
> some strange assumption of non-independent normals???  Maybe something
> else???  I assumed that the Likelihood function should be
> 
> -n/2*log(2*pi)-n/2*log(d)-n/2
> 
> Where d=MLE (biased) estimator of the variance

But that's unbounded as d goes to zero and log(d) becomes negative!

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rpeng at stat.ucla.edu  Wed Jan 15 17:30:04 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed Jan 15 17:30:04 2003
Subject: [R] Contour Plots
In-Reply-To: <D7E178FC91F3D21186A90008C7B9A5B8114847FD@ntexchange09.micron.com>
Message-ID: <Pine.GSO.4.10.10301150826030.3212-100000@quetelet.stat.ucla.edu>

I believe this was discussed about two days ago -- check the archives
under the subject "density plot - beginner's question" -- and there were
some good answers.  Basically, the x and y vectors have to be increasing
and response or Level, as you call it, needs to be in the form of a matrix
of dimension length(x) by length(y).  If the response/Level is not in the
form of a matrix, you will need to smoooth or interpolate.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 15 Jan 2003, mhoward wrote:

> r-help,
> 
>  I can't seem to get the below data organized in such a manner so as to
> generate a contour plot
> using any of the functions {lattice.contourplot, base.contour,
> base.filled.contour}. I was wondering
> if anyone could please tell me what I need to do to accomplish this.
> 
> 
> X,Y,Level
> -31.105,86.911,3843
> -3.385,86.911,3896
> 24.335,86.911,3874
> -24.175,79.700,3900
> -3.385,79.700,3927
> 17.405,79.700,3922
> -51.895,72.489,3874
> 52.056,72.489,3898
> -44.965,65.278,3914
> 45.125,65.278,3951
> -24.175,58.067,3931
> 17.405,58.067,3942
> -79.615,50.856,3831
> 72.845,50.856,3914
> -72.685,43.645,3891
> 65.915,43.645,3972
> -44.965,36.434,3921
> -3.385,36.434,3889
> 38.195,36.434,3965
> -93.475,22.012,3812
> 86.705,22.012,3913
> -86.545,14.801,3876
> -65.755,14.801,3927
> -24.175,14.801,3861
> 17.405,14.801,3872
> 58.985,14.801,3999
> 79.775,14.801,3970
> -93.475,-6.832,3848
> -86.545,-6.832,3894
> -44.965,-6.832,3905
> -3.385,-6.832,3848
> 38.195,-6.832,3949
> 79.775,-6.832,3983
> 86.705,-6.832,3942
> -86.545,-21.254,3880
> 79.775,-21.254,3967
> -93.475,-28.465,3839
> -65.755,-28.465,3945
> -24.175,-28.465,3906
> 17.405,-28.465,3931
> 58.985,-28.465,4011
> 86.705,-28.465,3899
> -72.685,-50.098,3906
> -44.965,-50.098,3971
> -3.385,-50.098,3956
> 38.195,-50.098,4007
> 65.915,-50.098,3970
> -79.615,-57.309,3894
> 72.845,-57.309,3896
> -58.825,-64.520,3925
> 52.055,-64.520,3964
> -65.755,-71.731,3868
> -24.175,-71.731,3972
> 17.405,-71.731,3989
> 58.985,-71.731,3894
> -17.245,-86.153,3926
> -3.385,-86.153,3943
> 10.475,-86.153,3935
> -24.175,-93.364,3855
> -3.385,-93.364,3894
> 17.405,-93.364,3861
> 
> Thanks,
> 
> Michael R. Howard
> Micron Technology, Inc
> Fab C Engineering Software (FCES)
> Phone368 - 2352 [82352]
> Pager 90713
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From mounier at lmd.polytechnique.fr  Wed Jan 15 17:35:03 2003
From: mounier at lmd.polytechnique.fr (Flore MOUNIER)
Date: Wed Jan 15 17:35:03 2003
Subject: [R] construction of a 4 dimensions binary file
Message-ID: <200301151734.19974.mounier@lmd.polytechnique.fr>

Dear R users, 
At present I have 22 files with girded data in 3-Dimensions (longitude, 
latitude, time), each file being one level of the atmosphere. I would like to 
compact these 22 levels into a unique and big file.
If you know how to do such an operation please fill free to contact me.
P.S.:	Here is the beginning of my programme:
###########
#Dimension#
##########
nlon<-25; londeb<-1 ; lonfin<-25
nlat<-25; latdeb<-1; latfin<-25
nb<-122; tdeb<-1; tfin<-122
tsel<-tfin-tdeb+1
lonsel<-lonfin-londeb+1
latsel<-latfin-latdeb+1
hgt <- array(0,dim=c(nlon,nlat,nb))
#
#############
#file openning#
############
andeb <- 1 ; anfin <- 22
an <- c("1979","1980","1981","1982","1983","1984","1985","1986","1987","1988"
,"1989","1990","1991","1992","1993","1994","1995","1996","1997","1998","1999","2000")
andeb <- 1 ; anfin <- 4 ;nan<-anfin-andeb+1
path <- "/ws/mounier/Info./Grads/OLR/data"
deb<-"/olr."
ext <- ".dat"
for (o in andeb:anfin)
{a <-file (paste(path,deb,an[o],ext,sep=""),"rb")
hgt[1:nlon,1:nlat,1:nb] <- readBin(a,real(),size=4,nb*nlon*nlat)
#############
#NEW FILE #
###########
c<-file("/ws/mounier/Info./Grads/OLR/data/olr.79_00.test.dat","wb")
for (k in 1:tsel)
for (j in 1:latsel) {
{writeBin(hgt[1:lonsel,j,k],c,size=4, endian="little")}}
close(a)}
close(c)



Than you in advance for any advice.,
Flore

-- 
Flore MOUNIER
Laboratoire de M?t?orologie Dynamique
Ecole Polytechnique
F 91128 Palaiseau Cedex
T?l:  01-69-33-36-19
Fax:  01-69-33-30-49
e-mail : mounier at lmd.polytechnique.fr



From fidler at math.utah.edu  Wed Jan 15 17:38:38 2003
From: fidler at math.utah.edu (Matthew L. Fidler)
Date: Wed Jan 15 17:38:38 2003
Subject: [R] Bug or Feature? LogLik.nls and non-central F distribution.
In-Reply-To: <6rznq2s7y2.fsf@bates4.stat.wisc.edu>
References: <1042608425.8141.25.camel@pceurp52.pharm.utah.edu>
	 <6rznq2s7y2.fsf@bates4.stat.wisc.edu>
Message-ID: <1042648403.11074.11.camel@pceurp52.pharm.utah.edu>


On Wed, 2003-01-15 at 09:18, Douglas Bates wrote:
> "Matthew L. Fidler" <fidler at math.utah.edu> writes:
> 
> ...
> > > logLik(short.alif.fit);
> > `log Lik.' 6.307024 (df=1)
> > 
> > My problem with this number is that exp(logLik) > 1.  If the error
> > structure is independent, identically distributed normal (which I
> > assumed was the case), then the Likelihood function should only give a
> > number from 0 to 1...  
> 
> Why?  The likelihood is the product of the probability densities of
> the observations given the parameters and a probability density can be
> greater than 1.
> 
> The belief that a likelihood must be less than 1 is a common
> misconception

True,  if the variance is small (less than one), it can have that
feature.  I forgot;  thank you for reminding me. However I still cannot
get the non-central F to return the right tail (according to my linear
model's noncentral F distribution tables....)  I thought it wasn't
working because I couldn't get it to produce the log-liklihood function
that I derived.  I forgot to divide the residual sum of squares by N,
however....  sorry.
-- 
Matthew L. Fidler
fidler at math.utah.edu

421 Wakra Way, Suite 318
Salt Lake City, UT 84108
(801) 581-7125
-------------------------------------------------------------------------
Accident, n.:
	A condition in which presence of mind is good, but absence of
	body is better.
		-- Foolish Dictionary
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: This is a digitally signed message part
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030115/6b1bebb0/attachment.bin

From mhoward at micron.com  Wed Jan 15 17:52:02 2003
From: mhoward at micron.com (mhoward)
Date: Wed Jan 15 17:52:02 2003
Subject: [R] Contour Plots
Message-ID: <D7E178FC91F3D21186A90008C7B9A5B8114847FE@ntexchange09.micron.com>

Roger,

  Thanks, that information was exactly what I needed. I searched the
site for info, but spaced the email archives....won't make that mistake 
again.

Mike

-----Original Message-----
From: Roger Peng [mailto:rpeng at stat.ucla.edu]
Sent: Wednesday, January 15, 2003 9:30 AM
To: mhoward
Cc: 'r-help at lists.R-project.org'
Subject: Re: [R] Contour Plots


I believe this was discussed about two days ago -- check the archives
under the subject "density plot - beginner's question" -- and there were
some good answers.  Basically, the x and y vectors have to be increasing
and response or Level, as you call it, needs to be in the form of a matrix
of dimension length(x) by length(y).  If the response/Level is not in the
form of a matrix, you will need to smoooth or interpolate.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 15 Jan 2003, mhoward wrote:

> r-help,
> 
>  I can't seem to get the below data organized in such a manner so as to
> generate a contour plot
> using any of the functions {lattice.contourplot, base.contour,
> base.filled.contour}. I was wondering
> if anyone could please tell me what I need to do to accomplish this.
> 
> 
> X,Y,Level
> -31.105,86.911,3843
> -3.385,86.911,3896
> 24.335,86.911,3874
> -24.175,79.700,3900
> -3.385,79.700,3927
> 17.405,79.700,3922
> -51.895,72.489,3874
> 52.056,72.489,3898
> -44.965,65.278,3914
> 45.125,65.278,3951
> -24.175,58.067,3931
> 17.405,58.067,3942
> -79.615,50.856,3831
> 72.845,50.856,3914
> -72.685,43.645,3891
> 65.915,43.645,3972
> -44.965,36.434,3921
> -3.385,36.434,3889
> 38.195,36.434,3965
> -93.475,22.012,3812
> 86.705,22.012,3913
> -86.545,14.801,3876
> -65.755,14.801,3927
> -24.175,14.801,3861
> 17.405,14.801,3872
> 58.985,14.801,3999
> 79.775,14.801,3970
> -93.475,-6.832,3848
> -86.545,-6.832,3894
> -44.965,-6.832,3905
> -3.385,-6.832,3848
> 38.195,-6.832,3949
> 79.775,-6.832,3983
> 86.705,-6.832,3942
> -86.545,-21.254,3880
> 79.775,-21.254,3967
> -93.475,-28.465,3839
> -65.755,-28.465,3945
> -24.175,-28.465,3906
> 17.405,-28.465,3931
> 58.985,-28.465,4011
> 86.705,-28.465,3899
> -72.685,-50.098,3906
> -44.965,-50.098,3971
> -3.385,-50.098,3956
> 38.195,-50.098,4007
> 65.915,-50.098,3970
> -79.615,-57.309,3894
> 72.845,-57.309,3896
> -58.825,-64.520,3925
> 52.055,-64.520,3964
> -65.755,-71.731,3868
> -24.175,-71.731,3972
> 17.405,-71.731,3989
> 58.985,-71.731,3894
> -17.245,-86.153,3926
> -3.385,-86.153,3943
> 10.475,-86.153,3935
> -24.175,-93.364,3855
> -3.385,-93.364,3894
> 17.405,-93.364,3861
> 
> Thanks,
> 
> Michael R. Howard
> Micron Technology, Inc
> Fab C Engineering Software (FCES)
> Phone368 - 2352 [82352]
> Pager 90713
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From mikalzet at libero.it  Wed Jan 15 17:57:04 2003
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Wed Jan 15 17:57:04 2003
Subject: [R] Mandrake packages for  R-1.6.2
Message-ID: <Pine.LNX.4.50.0301151750120.3668-100000@macchinetta>

Mandrake packages for R 1.6.2 are now available on CRAN.

-- 
Michele Alzetta



From huan.huang at bnpparibas.com  Wed Jan 15 18:20:03 2003
From: huan.huang at bnpparibas.com (huan.huang@bnpparibas.com)
Date: Wed Jan 15 18:20:03 2003
Subject: [R] Least Absolute Deviation
Message-ID: <OF04A1EC52.36AF8040-ON80256CAF.005E3AFE@bnpparibas.com>

Dear all,

I try to fit least absolute deviation  (LAD) regression with R. I couldn't
find any command to carry out LAD. What I am doing now is using nlm() and
setting the function argument to minimize the sum of the absolute
deviation. But for some data it keeps giving out the error message: Error
in nlm(absdev, b.start) : non-finite value supplied by nlm. (there is no na
in my dataset.)

I am wondering if there is some function I can do it directly.

Many thanks.

Huan




This message and any attachments (the "message") is
intended solely for the addressees and is confidential. 
If you receive this message in error, please delete it and 
immediately notify the sender. Any use not in accord with 
its purpose, any dissemination or disclosure, either whole 
or partial, is prohibited except formal approval. The internet
can not guarantee the integrity of this message. 
BNP PARIBAS (and its subsidiaries) shall (will) not 
therefore be liable for the message if modified. 

                ---------------------------------------------

Ce message et toutes les pieces jointes (ci-apres le 
"message") sont etablis a l'intention exclusive de ses 
destinataires et sont confidentiels. Si vous recevez ce 
message par erreur, merci de le detruire et d'en avertir 
immediatement l'expediteur. Toute utilisation de ce 
message non conforme a sa destination, toute diffusion 
ou toute publication, totale ou partielle, est interdite, sauf 
autorisation expresse. L'internet ne permettant pas 
d'assurer l'integrite de ce message, BNP PARIBAS (et ses
filiales) decline(nt) toute responsabilite au titre de ce 
message, dans l'hypothese ou il aurait ete modifie.



From reid_huntsinger at merck.com  Wed Jan 15 19:00:07 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Wed Jan 15 19:00:07 2003
Subject: [R] Least Absolute Deviation
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC2CE@uswpmx11.merck.com>

Try the package "quantreg" on CRAN.

Reid Huntsinger

-----Original Message-----
From: huan.huang at bnpparibas.com [mailto:huan.huang at bnpparibas.com]
Sent: Wednesday, January 15, 2003 12:19 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Least Absolute Deviation



Dear all,

I try to fit least absolute deviation  (LAD) regression with R. I couldn't
find any command to carry out LAD. What I am doing now is using nlm() and
setting the function argument to minimize the sum of the absolute
deviation. But for some data it keeps giving out the error message: Error
in nlm(absdev, b.start) : non-finite value supplied by nlm. (there is no na
in my dataset.)

I am wondering if there is some function I can do it directly.

Many thanks.

Huan




This message and any attachments (the "message") is
intended solely for the addressees and is confidential. 
If you receive this message in error, please delete it and 
immediately notify the sender. Any use not in accord with 
its purpose, any dissemination or disclosure, either whole 
or partial, is prohibited except formal approval. The internet
can not guarantee the integrity of this message. 
BNP PARIBAS (and its subsidiaries) shall (will) not 
therefore be liable for the message if modified. 

                ---------------------------------------------

Ce message et toutes les pieces jointes (ci-apres le 
"message") sont etablis a l'intention exclusive de ses 
destinataires et sont confidentiels. Si vous recevez ce 
message par erreur, merci de le detruire et d'en avertir 
immediatement l'expediteur. Toute utilisation de ce 
message non conforme a sa destination, toute diffusion 
ou toute publication, totale ou partielle, est interdite, sauf 
autorisation expresse. L'internet ne permettant pas 
d'assurer l'integrite de ce message, BNP PARIBAS (et ses
filiales) decline(nt) toute responsabilite au titre de ce 
message, dans l'hypothese ou il aurait ete modifie.

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------



From cg.pettersson at evp.slu.se  Wed Jan 15 19:25:03 2003
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Wed Jan 15 19:25:03 2003
Subject: [R] Random or fixed factors
Message-ID: <200301151824.TAA18396@mail1.slu.se>

Hi!
I work right now with my first real job in R. 
It?s a series of 12 fertilizer trials with three repetations. The treatments can be broken down to 2 x 2 factors (Product and Application).
Experimenting both with lm() and aov() makes me a little confused as I don?t get any differences in the sum of squares.

With aov() I have used a command of this type:   aov(Yield ~ Product * Application + Error(Trial/Block))
With lm() I have used something like: lm(Yield ~ Trial/Block + Product * Application) 

The placing of the term Trial/Block in the lm() statement doesn?t seem to matter. 
How do I tell R that the Trial term should be random in the lm() statement? It?s quite obvious that the Error term in aov() is random, but in the lm()? 
Is that implied of the fact that it has a nested term inside?
If so, and I don?t have plotwise data, how do I mark Trial as Random?

/CG
CG Pettersson
cg.pettersson at evp.slu.se



From phgrosjean at sciviews.org  Wed Jan 15 19:45:03 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed Jan 15 19:45:03 2003
Subject: [R] Least Absolute Deviation
In-Reply-To: <2C23DE2983BE034CB1CB90DB6B813FD6028AC2CE@uswpmx11.merck.com>
Message-ID: <MABBLJDICACNFOLGIHJOIEKCDCAA.phgrosjean@sciviews.org>

You can also look at package nlrq, if you intend to do non linear LAD
regression.

Best,

Philippe Grosjean

-----Original Message-----
From: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of Huntsinger, Reid
Sent: mercredi 15 janvier 2003 6:59
To: 'huan.huang at bnpparibas.com'; r-help at stat.math.ethz.ch
Subject: RE: [R] Least Absolute Deviation


Try the package "quantreg" on CRAN.

Reid Huntsinger

-----Original Message-----
From: huan.huang at bnpparibas.com [mailto:huan.huang at bnpparibas.com]
Sent: Wednesday, January 15, 2003 12:19 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Least Absolute Deviation



Dear all,

I try to fit least absolute deviation  (LAD) regression with R. I couldn't
find any command to carry out LAD. What I am doing now is using nlm() and
setting the function argument to minimize the sum of the absolute
deviation. But for some data it keeps giving out the error message: Error
in nlm(absdev, b.start) : non-finite value supplied by nlm. (there is no na
in my dataset.)

I am wondering if there is some function I can do it directly.

Many thanks.

Huan




This message and any attachments (the "message") is
intended solely for the addressees and is confidential.
If you receive this message in error, please delete it and
immediately notify the sender. Any use not in accord with
its purpose, any dissemination or disclosure, either whole
or partial, is prohibited except formal approval. The internet
can not guarantee the integrity of this message.
BNP PARIBAS (and its subsidiaries) shall (will) not
therefore be liable for the message if modified.

                ---------------------------------------------

Ce message et toutes les pieces jointes (ci-apres le
"message") sont etablis a l'intention exclusive de ses
destinataires et sont confidentiels. Si vous recevez ce
message par erreur, merci de le detruire et d'en avertir
immediatement l'expediteur. Toute utilisation de ce
message non conforme a sa destination, toute diffusion
ou toute publication, totale ou partielle, est interdite, sauf
autorisation expresse. L'internet ne permettant pas
d'assurer l'integrite de ce message, BNP PARIBAS (et ses
filiales) decline(nt) toute responsabilite au titre de ce
message, dans l'hypothese ou il aurait ete modifie.

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------------
--

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From v_bill_pikounis at merck.com  Wed Jan 15 19:57:03 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Wed Jan 15 19:57:03 2003
Subject: [R] S-Plus compatability...
Message-ID: <E827328028C66044B4998F2EC353CD30031850F8@usrymx12.merck.com>

Neil,

You may want to look at the 7th and preceding lines of traceback().  For
instance, the read.table() function calls scan() in its body definition.
You may even have something else calling the functon that called scan (e.g.
read.table()) in the script where the error occurred.  Perhaps you can
provide the traceback() output?

Hope that helps,
Bill

> -----Original Message-----
> From: Neil Shephard [mailto:mdeasnds at fs1.ser.man.ac.uk]
> Sent: Wednesday, January 15, 2003 11:05 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] S-Plus compatability...
> 
> 
> Dear all,
> 
> I was wondering if someone could point me in the right direction to 
> solve a problem I've encountered.
> 
> I have a set of S-plus scripts which call an external program to 
> analyse the data (the external program is called Genehunter and is 
> used for genetic analysis).  There are a six scripts in 
> total, five of 
> which are called from the main script.  I made a few changes like 
> changing unix > system, but I've encountered an error problem I'm 
> not sure how to resolve.
> 
> The majority of the script appears to run fine, the external program 
> is invoked okay, and it runs the analysis, however I get the error 
> message...
> 
> Error in scan(file = file, what = what, sep = sep, quote = quote, dec 
> = dec  :
> line 1 did not have 2 elements
> 
> Using the traceback() command produces a list of eight 
> commands, the eighth being the one that causes the error.
> 
> I've used grep -e 'scan' *.SSC to search the files for the scan 
> command that might be creating the problem, but there is only one 
> instance of scan in any of the six files, but the line it is 
> on does not 
> have the same syntax as the eigth line reported by traceback() that 
> causes the error.
> 
> I can provide the scripts if required, but have not included them 
> here as this msg is going to a list.
> 
> I'm not much of an expert with S-plus or R, and any help would be 
> appreciated.
> 
> Thanks in advance,
> 
> Neil
> 
> Neil Shephard
> Genetics Statistician
> ARC Epidemiology Unit, University of Manchester
> neil.shephard at man.ac.uk
> neil.shephard at mindless.com
> 
> "Contrariwise, if it was so, it might be; and if it
> were so it would be; but as it isn't, it ain't. That's
> logic" - Tweedledee (Alice Through the Looking Glass)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From deepayan at stat.wisc.edu  Wed Jan 15 20:01:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed Jan 15 20:01:03 2003
Subject: [R] [lattice] lines for stripplot (like dotplot) or jitter for dotplot?
In-Reply-To: <87fzrufmk3.fsf@lumen.indyrad.iupui.edu>
References: <87fzrufmk3.fsf@lumen.indyrad.iupui.edu>
Message-ID: <200301151257.38047.deepayan@stat.wisc.edu>

On Wednesday 15 January 2003 09:41 am, Michael A. Miller wrote:
> I'd like to use stripplot for some plots because I want to use
> the jitter parameter.  On the other hand, I'd like to use dotplot
> because I'd like to have the horizontal lines that it includes.
> dotplot doesn't have a jitter option and I'm not having any
> success with getting panel.grid(h=-1) with stripplot.  Can anyone
> show me how to make dotplot-like lines on a stripplot?  Or how to
> jitter the vertical plotting position on a dotplot?

In stripplot, try with something like

  panel = function(x, y, ...) {
      panel.abline(h = unique(as.numeric(y)), col = "grey")
      panel.stripplot(x, y, ...)
  }

(or more generally, with col = trellis.par.get("reference.line")$col etc)

Deepayan



From devinec at sas.upenn.edu  Wed Jan 15 22:11:03 2003
From: devinec at sas.upenn.edu (Colin Devine)
Date: Wed Jan 15 22:11:03 2003
Subject: [R] compile problems on solairs 8
References: <Pine.LNX.4.44.0301151444430.1254-100000@gannet.stats>
Message-ID: <3E25CB79.CFC27AB9@sas.upenn.edu>

Hello,

This was indeed the problem.  Setting --x-includes and --x-libraries to
the correct (in this case nfs mounted) directory allowed R to compile
correctly.  Many thanks for the help.

--Colin Devine 


ripley at stats.ox.ac.uk wrote:
> 
> You need to use a current X11R6, which on Solaris is under /usr/openwin.
> 
> X11R5 is about a decade old, AFAIR, so no wonder R's configure does not
> check for it.
> 
> On Wed, 15 Jan 2003, Colin Devine wrote:
> 
> > Hello,
> >
> > I am having a problem compiling R versions 1.6.1 or .16.2 on a Solaris 8
> > machine.  It sees to have problems with an X11 module.  Here is the
> > relevant output:
> >
> > make[4]: Entering directory `/pkg-ling/src/R-1.6.2/src/modules/X11'
> > gcc -I. -I../../../src/include -I../../../src/include
> > -I/pkg/X11R5/include -I/usr/local/include -DHAVE_CONFIG_H  -fPIC  -g -O2
> > -c dataentry.c -o dataentry.lo
> > dataentry.c: In function `doSpreadKey':
> > dataentry.c:1194: `XK_Page_Up' undeclared (first use in this function)
> > dataentry.c:1194: (Each undeclared identifier is reported only once
> > dataentry.c:1194: for each function it appears in.)
> > dataentry.c:1198: `XK_Page_Down' undeclared (first use in this function)
> > make[4]: *** [dataentry.lo] Error 1
> > make[4]: Leaving directory `/pkg-ling/src/R-1.6.2/src/modules/X11'
> > make[3]: *** [R] Error 2
> > make[3]: Leaving directory `/pkg-ling/src/R-1.6.2/src/modules/X11'
> > make[2]: *** [R] Error 1
> > make[2]: Leaving directory `/pkg-ling/src/R-1.6.2/src/modules'
> > make[1]: *** [R] Error 1
> > make[1]: Leaving directory `/pkg-ling/src/R-1.6.2/src'
> > make: *** [R] Error 1
> > bash-2.02#
> >
> >
> > I have searched the archives without luck and the X libraries are found:
> >
> > checking for X... libraries /pkg/X11R5/lib, headers /pkg/X11R5/include
> >
> > Thanks in advance for your assistance.
> >
> > --Colin Devine
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fharrell at virginia.edu  Wed Jan 15 22:19:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed Jan 15 22:19:03 2003
Subject: [R] Faster way for weighted matching?
Message-ID: <20030115162133.771e5dd6.fharrell@virginia.edu>

For each element in w I want to find a good match (subscript number) of an element in x.  x and w can be long.  Instead of just finding the closest match I want to use weighted multinomial sampling (which I've already figured out once I have the probabilities) where the probabilities come from the tricube function of absolute differences between donor and target values, but normalized to sum to one, and using the maximum absolute difference as the scaling factor.  This is similar to the loess weighting function with f=1.  Here's code that works, to get the probability matrix to use for sampling:

z <- abs(outer(w, x, "-"))
s <- apply(z, 1, max)
z <- (1 - sweep(z, 1, s, FUN='/')^3)^3
sums <- apply(z, 1, sum)
z <- sweep(z, 1, sums, FUN='/')

Example:
w <- c(1,2,3,7)
x <- c(0,1.5,3)
z <- abs(outer(w,x,"-"))
> z
     [,1] [,2] [,3]
[1,]    1  0.5    2
[2,]    2  0.5    1
[3,]    3  1.5    0
[4,]    7  5.5    4
s <- apply(z, 1, max)
z <- (1 - sweep(z, 1, s, FUN='/')^3)^3
z
[1,] 0.6699219 0.9538536 0.0000000
[2,] 0.0000000 0.9538536 0.6699219
[3,] 0.0000000 0.6699219 1.0000000
[4,] 0.0000000 0.1365445 0.5381833
sums <- apply(z, 1, sum)
z <- sweep(z, 1, sums, FUN='/')
z   # each row represents multinomial probabilities summing to 1
[1,] 0.4125705 0.5874295 0.0000000
[2,] 0.0000000 0.5874295 0.4125705
[3,] 0.0000000 0.4011696 0.5988304
[4,] 0.0000000 0.2023697 0.7976303


The code is moderately fast.  Does anyone know of a significantly faster method or have any comments on the choice of weighting function for such sampling?   This will be used in the context of predictive mean matching for multiple imputation.   Thanks - Frank
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From jasont at indigoindustrial.co.nz  Wed Jan 15 22:36:02 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed Jan 15 22:36:02 2003
Subject: [R] Random or fixed factors
In-Reply-To: <200301151824.TAA18396@mail1.slu.se>; from cg.pettersson@evp.slu.se on Wed, Jan 15, 2003 at 07:27:07PM +0100
References: <200301151824.TAA18396@mail1.slu.se>
Message-ID: <20030116103440.A28181@camille.indigoindustrial.co.nz>

On Wed, Jan 15, 2003 at 07:27:07PM +0100, CG Pettersson wrote:
...
> How do I tell R that the Trial term should be random in the lm() statement? It?s quite obvious that the Error term in aov() is random, but in the lm()? 

try

library(nlme)
help(lme)

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From mmiller3 at iupui.edu  Wed Jan 15 22:58:05 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Wed Jan 15 22:58:05 2003
Subject: [R] [lattice] lines for stripplot (like dotplot) or jitter for dotplot?
In-Reply-To: <200301151257.38047.deepayan@stat.wisc.edu>
References: <87fzrufmk3.fsf@lumen.indyrad.iupui.edu>
	<200301151257.38047.deepayan@stat.wisc.edu>
Message-ID: <871y3eaxf3.fsf@lumen.indyrad.iupui.edu>

>>>>> "Deepayan" == Deepayan Sarkar <deepayan at stat.wisc.edu> writes:

    > In stripplot, try with something like

    >   panel = function(x, y, ...) {
    >       panel.abline(h = unique(as.numeric(y)), col = "grey")
    >       panel.stripplot(x, y, ...)
    >   }

    > (or more generally, with col =
    > trellis.par.get("reference.line")$col etc)

That's it!  Thanks!

Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine



From deepayan at stat.wisc.edu  Thu Jan 16 00:04:02 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu Jan 16 00:04:02 2003
Subject: [R] lattice: cloud: aspect ratio, labels, vertical lines
In-Reply-To: <20030115121510.A3021@s1x.zimnet.ch>
References: <20030115121510.A3021@s1x.zimnet.ch>
Message-ID: <200301151703.26226.deepayan@stat.wisc.edu>

On Wednesday 15 January 2003 05:15 am, Wolfram Fischer wrote:
> I am interested to know how to make for clouds:
> - aspect ratio = 1
> - labels attached to points
> - vertical lines from the points to the x/y base plane
>
> I tried:
>     t = c( 'A', 'B', 'C', 'D' )
>     x = c( 100,   0, 200, 100 )
>     y = c(   0, 100,   0, 100 )
>     z = c(  80,   0,  20,  40 )
>
>     q = data.frame( x, y, z )
>     rownames( q ) = t
>
>     print(cloud( z ~ x * y, data = q, type = c( 'p', 'h' )
>         , scales = list( arrows=FALSE )
>         , aspect = c( max(y)/max(x), max(z)/max(x) )
>     ))
>
>
> My questions:
> - Is there an easier way to tell that aspect ratio should be 1
>   on all dimensions, especially without the precalculations
>   of max(...)?

You mean that the aspect ratio should be 1 on the data scale ? This is not 
currently possible, but I have plans to add this, among other things, in the 
next major release.

> - "type = 'h'" does not work as I expected. What to do?

This is partially implemented, but not the default yet (and not widely 
advertised). Try 

print(cloud( z ~ x * y, data = q, type = 'h'
      , panel.3d.cloud = panel.3dscatter.new,
      , scales = list( arrows=FALSE )
      , aspect = c( max(y)/max(x), max(z)/max(x) )
   ))

type cannot be a vector, but that's not a major problem (see below).

> - How can I get the labels of t into the graphic?

Something like:


panel.custom <-
    function(x, y, z, groups, subscripts,
             rot.mat = diag(4), za, zb, zback, zfront, distance, ...)
{
    panel.3dscatter.new(x, y, z, type = 'h',
                        rot.mat = rot.mat, za = za, zb = zb,
                        zback = zback, zfront = zfront,
                        distance = distance, ...)
    m <- ltransform3dto3d(rbind(x, y, z), rot.mat, za, zb, 
                          zback, zfront, distance)
    ltext(x = m[1,], y = m[2,], lab = groups[subscripts])
}


print(cloud( z ~ x * y, data = q, groups = rownames(q),
            xlim = c(-10, 210), ylim = c(-5, 105),
            panel.3d.cloud = panel.custom,
            scales = list( arrows=FALSE ),
            aspect = c( max(y)/max(x), max(z)/max(x) )
            ))

The point being that the ltransform3dto3d() function makes the projection 
easily enough for normal users to use it inside a custom panel.3d.cloud 
function.

Deepayan



From p.connolly at hortresearch.co.nz  Thu Jan 16 02:36:03 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu Jan 16 02:36:03 2003
Subject: [R] X11 device now needs to be explicitly started?
Message-ID: <20030116013500.GG21374@hortresearch.co.nz>

         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.2              
year     2003             
month    01               
day      10               
language R                
> 

Until this version, I've not had to explicitly start the x11 device.
Now, (at least with lattice plots), one is not automatically started
once it's recognised that no device is open.  I notice that lots of
things have changed with x11 with this release.  

Is the current behaviour by design or fault?

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From yanyu at cs.ucla.edu  Thu Jan 16 03:27:04 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Thu Jan 16 03:27:04 2003
Subject: [R] check variables: a Q from a beginner
In-Reply-To: <20030116013500.GG21374@hortresearch.co.nz>
Message-ID: <Pine.SOL.4.33.0301151812230.29757-100000@panther.cs.ucla.edu>

HI, all,
How can i check the variables that is currently being loaded..
ls() only list the variable name, but not the summary of the variable,
like the dimension of the variable etc.. Is there a command in R, which
is equivalent to "whos" in matlab, which let me check the variables
currently loaded in Matlab..
also, Does anyone have recommendation on ~a good reference to R..
I could not find the answer to my Q in the documentation included with R
package..

thanks,
yan



From rpeng at stat.ucla.edu  Thu Jan 16 05:25:03 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu Jan 16 05:25:03 2003
Subject: [R] check variables: a Q from a beginner
In-Reply-To: <Pine.SOL.4.33.0301151812230.29757-100000@panther.cs.ucla.edu>
Message-ID: <Pine.GSO.4.10.10301152022110.26244-100000@quetelet.stat.ucla.edu>

You may want to just try summary(varname) or more likely you want
str(varname).

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 15 Jan 2003, Yan Yu wrote:

> HI, all,
> How can i check the variables that is currently being loaded..
> ls() only list the variable name, but not the summary of the variable,
> like the dimension of the variable etc.. Is there a command in R, which
> is equivalent to "whos" in matlab, which let me check the variables
> currently loaded in Matlab..
> also, Does anyone have recommendation on ~a good reference to R..
> I could not find the answer to my Q in the documentation included with R
> package..
> 
> thanks,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From deepayan at stat.wisc.edu  Thu Jan 16 05:48:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu Jan 16 05:48:03 2003
Subject: [R] X11 device now needs to be explicitly started?
In-Reply-To: <20030116013500.GG21374@hortresearch.co.nz>
References: <20030116013500.GG21374@hortresearch.co.nz>
Message-ID: <200301152247.41729.deepayan@stat.wisc.edu>

On Wednesday 15 January 2003 07:35 pm, Patrick Connolly wrote:
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R
>
>
> Until this version, I've not had to explicitly start the x11 device.
> Now, (at least with lattice plots), one is not automatically started

Could you explain ? There's sometimes a warning, but I haven't seen the device 
not being opened. 

> once it's recognised that no device is open.  I notice that lots of
> things have changed with x11 with this release.
> Is the current behaviour by design or fault?
>
> best



From Alexander.Herr at csiro.au  Thu Jan 16 06:19:06 2003
From: Alexander.Herr at csiro.au (Alexander.Herr@csiro.au)
Date: Thu Jan 16 06:19:06 2003
Subject: [R] extracting data.frame names for list
Message-ID: <2FE6D3D02CCDD211B80600902745F56C018D120A@exchange-tv.tvl.qld.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030116/65325cf3/attachment.pl

From petr.pikal at precheza.cz  Thu Jan 16 09:15:03 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu Jan 16 09:15:03 2003
Subject: [R] check variables: a Q from a beginner
In-Reply-To: <Pine.SOL.4.33.0301151812230.29757-100000@panther.cs.ucla.edu>
References: <20030116013500.GG21374@hortresearch.co.nz>
Message-ID: <3E2677DD.13391.57A561@localhost>

Hallo

you can try this function

#------------------------------------------------------------------------------------------
# listing objektu s udaji
# Posted by Dan Putler At 2002-07-15 16:13 
# As part of the obveRsive GUI project, we've written a function with much of
# the functionality that Patrick Connolly was suggesting (which is a bit more
# compact than the output from ls.str()). Alas, no date capabilities. The
# function is call ls.objects(), and example output appears below:
# modified by me 20.7.2002

ls.objects <- function (pos = 1, pattern, mode = NULL, type = NULL)
{
    	Obj.Name <- ls(pos = pos, envir = as.environment(pos), pattern = pattern)
	nnn.m<-sapply(sapply(Obj.Name,get),mode)
	nnn.c<-sapply(sapply(Obj.Name,get),class)
	nnn.d<-sapply(sapply(Obj.Name,get),dim)

	Obj.length<-length(nnn.m)

	nnn.pok<-rep(0,Obj.length*2)
	dim(nnn.pok)<-c(Obj.length,2)
	for (i in 1:Obj.length) nnn.pok[i,1]<-as.numeric(unlist(nnn.d[i]))[1]
	for (i in 1:Obj.length) nnn.pok[i,2]<-as.numeric(unlist(nnn.d[i]))[2]
	nnn.d<-nnn.pok
	vyber<-is.na(nnn.d)[,1]
	nnn.d[vyber,1]<-sapply(sapply(Obj.Name,get),length)[vyber]

	nnn.pok<-rep("-",Obj.length)
	for (i in 1:Obj.length) nnn.pok[i]<-as.character(unlist(nnn.c[i]))[1]

	vystup<-data.frame(nnn.m,nnn.pok,nnn.d)
	names(vystup)<-c("Object.Mode","Object.Type","Rows","Columns")
	vystup

}




On 15 Jan 2003 at 18:26, Yan Yu wrote:

> HI, all,
> How can i check the variables that is currently being loaded..
> ls() only list the variable name, but not the summary of the variable,
> like the dimension of the variable etc.. Is there a command in R,
> which is equivalent to "whos" in matlab, which let me check the
> variables currently loaded in Matlab.. also, Does anyone have
> recommendation on ~a good reference to R.. I could not find the answer
> to my Q in the documentation included with R package..
> 
> thanks,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

CheersPetr Pikal
Precheza a.s., Nab?.Dr.E.Bene?e 24, 750 62 P?erov
tel: +420581 252 257 ; 724 008 364
petr.pikal at precheza.cz; p.pik at volny.cz
fax +420581 252 561



From maechler at stat.math.ethz.ch  Thu Jan 16 09:38:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Jan 16 09:38:02 2003
Subject: [R] check variables: a Q from a beginner
In-Reply-To: <Pine.GSO.4.10.10301152022110.26244-100000@quetelet.stat.ucla.edu>
References: <Pine.SOL.4.33.0301151812230.29757-100000@panther.cs.ucla.edu>
	<Pine.GSO.4.10.10301152022110.26244-100000@quetelet.stat.ucla.edu>
Message-ID: <15910.28464.307451.731778@gargle.gargle.HOWL>

>>>>> "Roger" == Roger Peng <rpeng at stat.ucla.edu>
>>>>>     on Wed, 15 Jan 2003 20:24:07 -0800 (PST) writes:

    Roger> You may want to just try summary(varname) or more likely you want
    Roger> str(varname).

Or combine  ls() and str()  using   ls.str() !

Martin

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


    Roger> On Wed, 15 Jan 2003, Yan Yu wrote:

    >> HI, all,
    >> How can i check the variables that is currently being loaded..
    >> ls() only list the variable name, but not the summary of the variable,
    >> like the dimension of the variable etc.. Is there a command in R, which
    >> is equivalent to "whos" in matlab, which let me check the variables
    >> currently loaded in Matlab..
    >> also, Does anyone have recommendation on ~a good reference to R..
    >> I could not find the answer to my Q in the documentation included with R
    >> package..
    >> 
    >> thanks,
    >> yan



From paradis at isem.univ-montp2.fr  Thu Jan 16 09:56:02 2003
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Thu Jan 16 09:56:02 2003
Subject: [R] check variables: a Q from a beginner
In-Reply-To: <Pine.GSO.4.10.10301152022110.26244-100000@quetelet.stat.uc
 la.edu>
References: <Pine.SOL.4.33.0301151812230.29757-100000@panther.cs.ucla.edu>
Message-ID: <4.2.0.58.20030116094149.00af2b80@162.38.183.200>

A 20:24 15/01/2003 -0800, Roger Peng a ?crit:
>You may want to just try summary(varname) or more likely you want
>str(varname).

Or even better: ls.str(), which does str() on all objects listed by ls().


>-roger
>_______________________________
>UCLA Department of Statistics
>rpeng at stat.ucla.edu
>http://www.stat.ucla.edu/~rpeng
>
>On Wed, 15 Jan 2003, Yan Yu wrote:
>
> > HI, all,
> > How can i check the variables that is currently being loaded..
> > ls() only list the variable name, but not the summary of the variable,
> > like the dimension of the variable etc.. Is there a command in R, which
> > is equivalent to "whos" in matlab, which let me check the variables
> > currently loaded in Matlab..

If you have highly structured objects, try this: ls.str(max.level = -1).

> > also, Does anyone have recommendation on ~a good reference to R..
> > I could not find the answer to my Q in the documentation included with R
> > package..
> >

You may have a look at my tutorial "R for beginners" though it is far from 
a reference doc it mentions ls.str() among the few things to know before 
starting. You can find it in the contributed docs section on CRAN.

Hope this helps.

Emmanuel Paradis

>
> > thanks,
> > yan
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From hennig at stat.math.ethz.ch  Thu Jan 16 12:14:02 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Thu Jan 16 12:14:02 2003
Subject: [R] help.search("tree")
Message-ID: <Pine.LNX.4.44.0301161210270.6563-100000@florence>

Dear list,

1) Is there an R analog to the Splus function quad.tree (presumably in
   Splus spatial module)?

2) What is going on here?

> help.search("tree")
Error in gsub(firstAliasRegExp, "\\1", db[, "alias"]) : 
	negative length vectors are not allowed
> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.2              
year     2003             
month    01               
day      10               
language R                

Best,
Christian

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de



From ernesto at ipimar.pt  Thu Jan 16 13:43:02 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu Jan 16 13:43:02 2003
Subject: [R] bootstraping lm
Message-ID: <1042721076.18906.23.camel@gandalf.ipimar.pt>

Hi

I'm doing a bootstrap of a linear model using:

boot.fishpower <- function(data, i){

	data <- data[i,]
	fplm <- lm(log(U)~Q+S+P+B+D, data=data)
	fp <- coef(fplm)
	exp(fp)
}


> boot(logglm.data,boot.fishpower,100)
Error in "[<-"(*tmp*, r, , value = statistic(data, i[r, ], ...)) : 
        number of items to replace is not a multiple of replacement
length


I've used debug to look at the process and it seems ok. The "i" are
allways of the same length as the dataframe rows. And it loops for a
while, but at some point it stops and gives this error ... 

Can someone help me with this ?

Thanks

EJ

-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
Research Institute for Agriculture and Fisheries
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948



From humbertc at univ-mlv.fr  Thu Jan 16 14:30:04 2003
From: humbertc at univ-mlv.fr (Cyril Humbert)
Date: Thu Jan 16 14:30:04 2003
Subject: [R] write.table() with "numeric" and "complex" data
Message-ID: <20030116142944.A27915@borneo.univ-mlv.fr>

write.table() seems to write "numeric" data as "complex"
if one column of the data.frame is "complex". Is it a 
way to avoid this ?

For example:

> df <- data.frame(x=c(1,2), z=c(1i+1, 2i+2))
> df
	  x    z
	1 1 1+1i
	2 2 2+2i

> mode(df$x)
	[1] "numeric"

> write.table(df, file="aa.dat") 
> df<-read.table("aa.dat", header=TRUE)
> df
	     x    z
	1 1+0i 1+1i
	2 2+0i 2+2i

> mode(df$x)
	[1] "complex"

> version                  
	platform i386-pc-linux-gnu
	major    1                
	minor    6.2              


Thanks

-- 
Cyril



From ripley at stats.ox.ac.uk  Thu Jan 16 14:40:06 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan 16 14:40:06 2003
Subject: [R] write.table() with "numeric" and "complex" data
In-Reply-To: <20030116142944.A27915@borneo.univ-mlv.fr>
Message-ID: <Pine.LNX.4.31.0301161339060.4743-100000@gannet.stats>

On Thu, 16 Jan 2003, Cyril Humbert wrote:

> write.table() seems to write "numeric" data as "complex"
> if one column of the data.frame is "complex". Is it a
> way to avoid this ?

Comment the line x <- as.matrix(x) in write.table.

>
> For example:
>
> > df <- data.frame(x=c(1,2), z=c(1i+1, 2i+2))
> > df
> 	  x    z
> 	1 1 1+1i
> 	2 2 2+2i
>
> > mode(df$x)
> 	[1] "numeric"
>
> > write.table(df, file="aa.dat")
> > df<-read.table("aa.dat", header=TRUE)
> > df
> 	     x    z
> 	1 1+0i 1+1i
> 	2 2+0i 2+2i
>
> > mode(df$x)
> 	[1] "complex"
>
> > version
> 	platform i386-pc-linux-gnu
> 	major    1
> 	minor    6.2
>
>
> Thanks
>
> --
> Cyril
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bert_gunter at merck.com  Thu Jan 16 14:44:03 2003
From: bert_gunter at merck.com (Gunter, Bert)
Date: Thu Jan 16 14:44:03 2003
Subject: [R] Built-in R GUI type features
Message-ID: <D45BC82E21E16149AC5A3F706350626401953A60@usrymx14.merck.com>

All:

The select.list() command brings up a "modal dialog box with a (scrollable)
list of items ..." etc. -- i.e., a GUI control. I also know about winDialog,
file.choose and the winMenu commands. What other such GUIisms are built into
** base ** R (I know about the tcltk package)? Or, better yet, how can I
search on or list them?

Many thanks.

Bert Gunter
Biometrics Research RY 84-16
Merck & Company
P.O. Box 2000
Rahway, NJ 07065-0900
Phone: (732) 594-7765
mailto: bert_gunter at merck.com

"The business of the statistician is to catalyze the scientific learning
process."      -- George E.P. Box




------------------------------------------------------------------------------



From johns2326 at hotmail.com  Thu Jan 16 15:47:02 2003
From: johns2326 at hotmail.com (John Smith)
Date: Thu Jan 16 15:47:02 2003
Subject: [R] Problem using outer()
Message-ID: <F6WOAUV06a9u0LDpR4z00007f0f@hotmail.com>

Here is a problem I am having. I would sincerely appreciate any help/advice 
from the experts who read this list. I have contrived a simple example, but 
it gives the same result I encountered in a more complicated application.

Given data frame u:

x	y
31	19
32	18
33	17
34	16
35	15
36	14
37	13

I define the function f as follows:

f <- function(a,b) sum(u$x - a) + sum(u$y - b)

One might think of a and b as "mean" values, and the function f totals up 
the deviations.

I wish to generate a table of the value of f given various values of a and b 
along grid points. So I define:

aa <- seq(0.1,1.0,0.1)
bb <- seq(1.0,2.0,0.1)

Unfortunately, when I issue the command

s <- outer(aa,bb,f)

R tells me the following:

Warning messages:
1: longer object length
        is not a multiple of shorter object length in: u$x - a
2: longer object length
        is not a multiple of shorter object length in: u$y - b

Outer() does assign values to s, but they are values that do not make sense. 
I understand why this is happening. Outer() passes the vectors aa and bb to 
function f, where the statement sum(u$x - a) + sum(u$y - b) is encountered 
with u$x and u$y of length 7 and a and b of length 10. R then cannot apply 
the recycle rule.

I can do this simply enough with nested loops and get the correct answer. 
Unfortunately, the "real" problem is much more involved than the simple 
example I show here (data frame u contains hundreds of observations, and the 
function f is many lines long) so the solution takes some time. The R 
documentation stresses in a number of places that loops are inefficient and 
should be eliminated where possible. I thought using outer() would speed the 
application up, but it doesn't work.

Any suggestions? How can I build up the table of values without using nested 
loops?

John Shonder



From jzhang at jimmy.harvard.edu  Thu Jan 16 15:53:05 2003
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Thu Jan 16 15:53:05 2003
Subject: [R] Built-in R GUI type features
Message-ID: <200301161450.JAA16984@blaise.dfci.harvard.edu>

Tow packages (widgetTools and tkWidgets) in www.bioconductor.org web site may be 
of interest to you. widgetTools allows users to build widgets using R (without 
having to know any tcl/tk or R tcltk command). tkWidgets contains widgets for 
data import, file/object selection ....



>All:
>
>The select.list() command brings up a "modal dialog box with a (scrollable)
>list of items ..." etc. -- i.e., a GUI control. I also know about winDialog,
>file.choose and the winMenu commands. What other such GUIisms are built into
>** base ** R (I know about the tcltk package)? Or, better yet, how can I
>search on or list them?
>
>Many thanks.
>
>Bert Gunter
>Biometrics Research RY 84-16
>Merck & Company
>P.O. Box 2000
>Rahway, NJ 07065-0900
>Phone: (732) 594-7765
>mailto: bert_gunter at merck.com
>
>"The business of the statistician is to catalyze the scientific learning
>process."      -- George E.P. Box
>
>
>
>
>------------------------------------------------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ernesto at ipimar.pt  Thu Jan 16 16:00:03 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu Jan 16 16:00:03 2003
Subject: [R] bootstraping lm
In-Reply-To: <1042721076.18906.23.camel@gandalf.ipimar.pt>
References: <1042721076.18906.23.camel@gandalf.ipimar.pt>
Message-ID: <1042729267.18906.60.camel@gandalf.ipimar.pt>

Hi

I found the problem (I hope:).

In "boot" a data.frame with the expected results from "statistic" is
created, "t.star", wich has dim[[1]]=sum(R), the number of replicates,
and dim[[2]]=lt0, the length of the output of statistic using the
original data.

t0 <- statistic(data, original, ...)
lt0 <- length(t0)
t.star <- matrix(NA, sum(R), lt0)

However when fitting the "lm" with different sets of data, it might
happen that the result of "statistic" is not of the same length has with
the original data. That's when 

for (r in 1:sum(R)) t.star[r, ] <- statistic(data, i[r,], ...)

fails, because its not able to replace the complete row of t.star.

So "statistic" shall guarantee that all the outputs are of the same
length. 

Something you might want to had to "boot" documentation.

Regards

EJ 

On Thu, 2003-01-16 at 12:44, Ernesto Jardim wrote:
> Hi
> 
> I'm doing a bootstrap of a linear model using:
> 
> boot.fishpower <- function(data, i){
> 
> 	data <- data[i,]
> 	fplm <- lm(log(U)~Q+S+P+B+D, data=data)
> 	fp <- coef(fplm)
> 	exp(fp)
> }
> 
> 
> > boot(logglm.data,boot.fishpower,100)
> Error in "[<-"(*tmp*, r, , value = statistic(data, i[r, ], ...)) : 
>         number of items to replace is not a multiple of replacement
> length
> 
> 
> I've used debug to look at the process and it seems ok. The "i" are
> allways of the same length as the dataframe rows. And it loops for a
> while, but at some point it stops and gives this error ... 
> 
> Can someone help me with this ?
> 
> Thanks
> 
> EJ
-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
Research Institute for Agriculture and Fisheries
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948



From ripley at stats.ox.ac.uk  Thu Jan 16 16:04:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan 16 16:04:04 2003
Subject: [R] bootstraping lm
In-Reply-To: <1042729267.18906.60.camel@gandalf.ipimar.pt>
Message-ID: <Pine.LNX.4.44.0301161459330.5989-100000@gannet.stats>

That's not a problem in boot, but a problem in your usage of it.

On 16 Jan 2003, Ernesto Jardim wrote:

> Hi
> 
> I found the problem (I hope:).
> 
> In "boot" a data.frame with the expected results from "statistic" is
> created, "t.star", wich has dim[[1]]=sum(R), the number of replicates,
> and dim[[2]]=lt0, the length of the output of statistic using the
> original data.
> 
> t0 <- statistic(data, original, ...)
> lt0 <- length(t0)
> t.star <- matrix(NA, sum(R), lt0)
> 
> However when fitting the "lm" with different sets of data, it might
> happen that the result of "statistic" is not of the same length has with
> the original data. That's when 
> 
> for (r in 1:sum(R)) t.star[r, ] <- statistic(data, i[r,], ...)
> 
> fails, because its not able to replace the complete row of t.star.
> 
> So "statistic" shall guarantee that all the outputs are of the same
> length. 
> 
> Something you might want to had to "boot" documentation.

It's already there:

statistic: A function which when applied to data returns a vector
          containing the statistic(s) of interest.

       t: A matrix with `R' rows each of which is a bootstrap replicate
          of `statistic'. 

Where does it say that the statistic(s) of interest can change by 
replicate?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fharrell at virginia.edu  Thu Jan 16 16:08:06 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu Jan 16 16:08:06 2003
Subject: [R] Summary: Faster way for weighted matching
Message-ID: <20030116100748.3e196312.fharrell@virginia.edu>

I received some great ideas (see below) from a number of people to whom I am grateful.  Here is the code I put together from many of their suggestions:

lx <- length(x)
lw <- length(w)
z <- matrix(abs( rep( x , lw ) - rep( w, each = lx ) ),
            nrow=lw, ncol=lx, byrow=TRUE)
s <- pmax( abs( w - min(x) ), abs( w - max(x) ) )
z <- (1 - (z/rep(s,length=lx*lw))^3)^3
sums <- rowSums(z)
z <- z/rep(sums, length=lx*lw)

This improved the speed roughly 25% over the original code.  Unfortunately I realized (once again) that any solution of this type based on outer( ) or something that generates an lx*lw matrix does not scale well for large problems because of memory usage.  So I'm probably going to resort to a Ratfor/Fortran solution to this problem.

Again thanks to the people mentioned below.
------------------------

Tim Hesterberg <timh at insightful.com>:

z <- abs(outer(w, x, "-"))
>s <- apply(z, 1, max)
>z <- (1 - sweep(z, 1, s, FUN='/')^3)^3

Instead of sweep, use
	z - rep(s, each=nrow(z))


>sums <- apply(z, 1, sum)

rowSums(z)

>z <- sweep(z, 1, sums, FUN='/')

z / rep(sums, each=nrow(z))



Nick.Ellis at csiro.au:

The sweeps could be replaced by simple division using the recycling rule,
but I haven't tested whether it is significantly faster.



Charles Berry <cberry at tajo.ucsd.edu>:

	1) calculate the transpose of z.  If z really is big, that should
		reduce caching in subsequent calcs.

	2) unroll the code in 'outer' and 'sweep' e.g. for 'outer'
		l.w <- length(w)
		l.x <- length(x)
		z <- abs( rep( x , l.w ) - rep( w, each = l.x ) )
		dim( z ) <- c( l.x, l.w )

	3) find s as follows:

		s <- pmax( abs( w - min(x) ), abs( w - max(x) ) )

	4) use colSums() instead of apply(, , sum)



Thomas W Blackwell <tblackw at umich.edu>:

Matrix z is potentially enormous.  On large matrices, it's
a familiar truism that    as.vector(z %*% rep(1, dim(z)[2]))
is MUCH faster than       apply(z, 1, sum).

The equivalent "inline" code for "max" is not so nice.
So here's an alternative version (untested):

 z  <- abs(outer(w, x, "-"))
wid <- seq(along=w)
top <- 1 + round(max(z), 0)   #   we know z is nonnegative by construction
 s  <- z[ sort.list((z / top) + matrix(wid, nrow=dim(z)[1], ncol=dim(z)[2], byrow=F)[wid * dim(z)[2]] ]
 z  <- (1 - (z / matrix(s, nrow=dim(z)[1], ncol=dim(z)[2], byrow=F))^3)^3
sums <- as.vector(z %*% rep(1, dim(z)[2]))
 z  <- z / matrix(sums, nrow=dim(z)[1], ncol=dim(z)[2], byrow=F)

Excruciatingly ugly, but it works.  Depends how much you're
willing to sacrifice transparent code in favor of speed.
(And, clearly I could save eight calls to dim(z) by defining
a couple of temporary variables.)

But surely, you know these hacks from way back. [Not necessary Thomas!  -Frank]

Original post:

> For each element in w I want to find a good match (subscript number) of an element in x.  x and w can be long.  Instead of just finding the closest match I want to use weighted multinomial sampling (which I've already figured out once I have the probabilities) where the probabilities come from the tricube function of absolute differences between donor and target values, but normalized to sum to one, and using the maximum absolute difference as the scaling factor.  This is similar to the loess weighting function with f=1.  Here's code that works, to get the probability matrix to use for sampling:
>
> z <- abs(outer(w, x, "-"))
> s <- apply(z, 1, max)
> z <- (1 - sweep(z, 1, s, FUN='/')^3)^3
> sums <- apply(z, 1, sum)
> z <- sweep(z, 1, sums, FUN='/')
>
> Example:
> w <- c(1,2,3,7)
> x <- c(0,1.5,3)
> z <- abs(outer(w,x,"-"))
> > z
>      [,1] [,2] [,3]
> [1,]    1  0.5    2
> [2,]    2  0.5    1
> [3,]    3  1.5    0
> [4,]    7  5.5    4
> s <- apply(z, 1, max)
> z <- (1 - sweep(z, 1, s, FUN='/')^3)^3
> z
> [1,] 0.6699219 0.9538536 0.0000000
> [2,] 0.0000000 0.9538536 0.6699219
> [3,] 0.0000000 0.6699219 1.0000000
> [4,] 0.0000000 0.1365445 0.5381833
> sums <- apply(z, 1, sum)
> z <- sweep(z, 1, sums, FUN='/')
> z   # each row represents multinomial probabilities summing to 1
> [1,] 0.4125705 0.5874295 0.0000000
> [2,] 0.0000000 0.5874295 0.4125705
> [3,] 0.0000000 0.4011696 0.5988304
> [4,] 0.0000000 0.2023697 0.7976303
>
>
> The code is moderately fast.  Does anyone know of a significantly faster method or have any comments on the choice of weighting function for such sampling?   This will be used in the context of predictive mean matching for multiple imputation.   Thanks - Frank

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From Timur.Elzhov at jinr.ru  Thu Jan 16 16:12:03 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Thu Jan 16 16:12:03 2003
Subject: [R] Calling R function from within C code
Message-ID: <20030116151044.GA9021@pcf004.jinr.ru>

Dear R experts,

I'd like to call R function from within C code.
I looked through the 'R exts' manual, found examples with
lang2(R_fcall, list), and tried it, but it seemed to create
the call, which can accept only a single argument of 'list'
type, when I need to create the call of R functions with
arbitrary numbers of arguments.

How can I do it?

Thanks a lot.


--
WBR,
Timur.



From ernesto at ipimar.pt  Thu Jan 16 16:16:04 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu Jan 16 16:16:04 2003
Subject: [R] bootstraping lm
In-Reply-To: <Pine.LNX.4.44.0301161459330.5989-100000@gannet.stats>
References: <Pine.LNX.4.44.0301161459330.5989-100000@gannet.stats>
Message-ID: <1042730194.18926.71.camel@gandalf.ipimar.pt>

Hi

You're correct. The problem is in "statistic" not in boot.

However it is not clear for me that the definition of t states it must
have allways the same number of dimensions. What it says is that it will
be a bootstrap replicate of statistic. 

In my linear model I use factors and the number of coefficients might
change, if the bootstrap data set omits one or more levels. 

My understandment is that the result of "statistic" is still a bootstrap
replicate no matter the number of dimensions.

Anyway, thanks for being helpfull.

Regards

EJ

On Thu, 2003-01-16 at 15:02, ripley at stats.ox.ac.uk wrote:
> That's not a problem in boot, but a problem in your usage of it.
> 
> On 16 Jan 2003, Ernesto Jardim wrote:
> 
> > Hi
> > 
> > I found the problem (I hope:).
> > 
> > In "boot" a data.frame with the expected results from "statistic" is
> > created, "t.star", wich has dim[[1]]=sum(R), the number of replicates,
> > and dim[[2]]=lt0, the length of the output of statistic using the
> > original data.
> > 
> > t0 <- statistic(data, original, ...)
> > lt0 <- length(t0)
> > t.star <- matrix(NA, sum(R), lt0)
> > 
> > However when fitting the "lm" with different sets of data, it might
> > happen that the result of "statistic" is not of the same length has with
> > the original data. That's when 
> > 
> > for (r in 1:sum(R)) t.star[r, ] <- statistic(data, i[r,], ...)
> > 
> > fails, because its not able to replace the complete row of t.star.
> > 
> > So "statistic" shall guarantee that all the outputs are of the same
> > length. 
> > 
> > Something you might want to had to "boot" documentation.
> 
> It's already there:
> 
> statistic: A function which when applied to data returns a vector
>           containing the statistic(s) of interest.
> 
>        t: A matrix with `R' rows each of which is a bootstrap replicate
>           of `statistic'. 
> 
> Where does it say that the statistic(s) of interest can change by 
> replicate?
-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
Research Institute for Agriculture and Fisheries
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948



From ripley at stats.ox.ac.uk  Thu Jan 16 16:23:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan 16 16:23:02 2003
Subject: [R] Calling R function from within C code
In-Reply-To: <20030116151044.GA9021@pcf004.jinr.ru>
Message-ID: <Pine.LNX.4.44.0301161516440.5989-100000@gannet.stats>

That way.  It's a pairlist of arguments.  As that manual says

Function @code{lang2} creates an executable `list' of two elements, but
this will only be clear to those with a knowledge of a LISP-like
language.

There are examples in optim.c and deriv.c.

On Thu, 16 Jan 2003, Timur Elzhov wrote:

> I'd like to call R function from within C code.
> I looked through the 'R exts' manual, found examples with
> lang2(R_fcall, list), and tried it, but it seemed to create
> the call, which can accept only a single argument of 'list'
> type, when I need to create the call of R functions with
> arbitrary numbers of arguments.
> 
> How can I do it?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Ted.Harding at nessie.mcc.ac.uk  Thu Jan 16 16:27:06 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu Jan 16 16:27:06 2003
Subject: [R] Multivariate regression in R
Message-ID: <XFMail.030116151612.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

I want to do multivariate regression in R, i.e. basically
(but with a complication -- see below):

given an Nxp matrix Y of p-variate responses, and an Nxk
matrix X of covariates, to fit the model

  Y = X*B + e

with estimation of the kxp matrix of coefficients B
and estimation of the pxp matrix of covariances between
the p variates in Y.

I haven't managed to find a function/package in R which
seems to address this problem directly (maybe I'm overlooking
a way of using a standard one). One way, of course, could
be to stack the columns of Y on top of each other, replicate
X vertically accordingly, and try to introduce a suitably
structured covariance matrix; but I would like to think
that there's an easier way ... !

The complication: for each row of Y, each of the p variates
is associated with one level of a p-level factor W (on a
permuted basis, so that y1,...,yp are associated with levels
i1,...,ip of W where (i1,...,ip) is a permutation of levels
(1,...,p) of W).

I'm wondering, too, how to represent this in R. In the univariate
case, for instance, the matrix representation for a factor when
regressing y on r levels of a factor F represents the factor as
an Nxr matrix with zeros except for 1s in col j for rows where
y has the level j of F. In the multivariate case, each row of Y
would by analogy be associated with a matrix of factor levels,
one row for each variate in Y, so as to pick out the factor levels
by columns as in the univariate case for that variate.

Any help/advice would be much appreciated!

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 16-Jan-03                                       Time: 15:16:12
------------------------------ XFMail ------------------------------



From peter.fledelius at wgo.royalsun.com  Thu Jan 16 16:53:02 2003
From: peter.fledelius at wgo.royalsun.com (peter.fledelius@wgo.royalsun.com)
Date: Thu Jan 16 16:53:02 2003
Subject: [R] Overdispersed poisson - negative observation
Message-ID: <OF5C737A53.51A23FF1-ON80256CB0.005279C8@uk.rsa-ins.com>

Dear R users

I have been looking for functions that can deal with overdispersed poisson
models. Some (one) of the observations are negative. According to actuarial
literature (England & Verall, Stochastic Claims Reserving in General
Insurance , Institute of Actiuaries 2002) this can be handled through the
use of quasi likelihoods instead of normal likelihoods. The presence of
negatives is not normal in a poisson model, however, we see them frequently
in this type of data, and we would like to be able to fit the model anyway.

At the moment R is complaining about negative values and the link function
= log.

My code looks like this. Do any of you know if this problem can be solved
in R? Any suggestions are welcomed.

Kind regards,

Peter Fledelius (new R user)

*********** Code ************
paym   <- c(5012, 3257, 2638,  898, 1734, 2642, 1828,  599,   54,  172,
             106, 4179, 1111, 5270, 3116, 1817, -103,  673,  535,
            3410, 5582, 4881, 2268, 2594, 3479,  649,  603,
            5655, 5900, 4211, 5500, 2159, 2658,  984,
            1092, 8473, 6271, 6333, 3786,  225,
            1513, 4932, 5257, 1233, 2917,
             557, 3463, 6956, 1368,
            1351, 5596, 6165,
            3133, 2262,
            2063)
alpha   <- factor(c(1,1,1,1,1,1,1,1,1,1,
             2,2,2,2,2,2,2,2,2,
             3,3,3,3,3,3,3,3,
             4,4,4,4,4,4,4,
             5,5,5,5,5,5,
             6,6,6,6,6,
             7,7,7,7,
             8,8,8,
             9,9,
             10))
beta    <- factor(c(1,2,3,4,5,6,7,8,9,10,
             1,2,3,4,5,6,7,8,9,
             1,2,3,4,5,6,7,8,
             1,2,3,4,5,6,7,
             1,2,3,4,5,6,
             1,2,3,4,5,
             1,2,3,4,
             1,2,3,
             1,2,
             1))
d.AD <- data.frame(paym, alpha, beta)
glm.qD93 <- glm(paym ~ alpha + beta, family=quasipoisson())
glm.qD93
************ Code end ***************



From rggefrm at ucl.ac.uk  Thu Jan 16 17:00:05 2003
From: rggefrm at ucl.ac.uk (Frank Mattes)
Date: Thu Jan 16 17:00:05 2003
Subject: [R] help drawing kaplan-meier plot starting from 0
Message-ID: <5.2.0.9.0.20030116154257.00a6c720@pop-server.ucl.ac.uk>

Dear help news reader,

I'm trying to draw a Kaplan-Meier curve and would like to ask the news 
group for some help
Supposing I have study comapring two drugs, "A", and "B" and I recorde the 
time to get to the clinical endpoint (Time), in my case becommming virus free.

I have setup the following frame:
   Time  c Drug
1    5 1    A
2    7 1    B
3    2 1    A
4   10 1    B
5    6 1    A
6    8 1    B

"c" contains the coding if sucessful or not, but I think at the moment that 
is not important.
I did

fitstudy <- survfit(Surv(Time) ~ Drug, data=study) or
fitstudy <- fitstudy <- survfit(Surv(Time, c) ~ Drug, data=study)

and than

plot(fitstudy)

which gives me a Kaplan-Meier Curve, starting with 1. However I would like 
to the a plot
starting with "0" and than showing the increasing numbers of patients 
becomming "virus negative".

It would be great, if someone could point me in the right direction where I 
can find the answer.

Many thanks in advance
Frank

Frank Mattes, MD
Department of Virology
Royal Free and University Medical School
London



From Timur.Elzhov at jinr.ru  Thu Jan 16 17:03:55 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Thu Jan 16 17:03:55 2003
Subject: [R] Calling R function from within C code
In-Reply-To: <Pine.LNX.4.44.0301161516440.5989-100000@gannet.stats>
References: <20030116151044.GA9021@pcf004.jinr.ru> <Pine.LNX.4.44.0301161516440.5989-100000@gannet.stats>
Message-ID: <20030116155552.GA9238@pcf004.jinr.ru>

On Thu, Jan 16, 2003 at 03:22:42PM +0000, ripley at stats.ox.ac.uk wrote:

> That way.  It's a pairlist of arguments.  As that manual says
Thank you, Mr. Ripley!

But, it was interesing for me for a long - what is a principal
difference between 'pairlist' and a "general" list?
Why to access pairlist elements I need to use the strange macro
like CAR(CDR(x)), and cannot do it by VECTOR_ELT(x, i) ?


Thank you very much again!

--
WBR,
Timur.



From bruce.coate at pfizer.com  Thu Jan 16 17:10:06 2003
From: bruce.coate at pfizer.com (Coate, Bruce)
Date: Thu Jan 16 17:10:06 2003
Subject: [R] Plotting Question
Message-ID: <FB8942EA6DCDD511A43F00508BCF818D07122681@lajgrdexm01.agouron.com>

For a clinical trial I am involved with, I would like a plot (for each
subject) similar to the following which will indicate what drugs that
subject was taking on each day during the study:

Drug 1    [---]           [----------------------]

Drug 2    [-------------------------------------]

Drug 3           [---------]  [----------------------------]
             |--------------------------------------------------|
             0                                                n

                           Study Day

 I have thought about using strip plot, perhaps setting a flag each day the
subject is on study (1 if drug x is taken on that day, NA otherwise). But
that means I would have to create extra records for each subject because my
data looks something like,

Subject   Drug   Start          Stop
------------------------------------------
 1           1         5Jan2002   10Jan2002
 1           1        12Jan2002  30Jan2002
 2           2        15Feb2002  20Mar2002
etc.

Does anyone have a suggestion as to which kind of plotting function is best
suited to this? 
Thanks.



From brahm at alum.mit.edu  Thu Jan 16 17:14:29 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Thu Jan 16 17:14:29 2003
Subject: [R] Exception Handling
Message-ID: <15910.55681.688601.187296@gargle.gargle.HOWL>

Zhongming Yang <Zhongming.Yang at cchmc.org> wrote:
> How can I catch R errors and depend on this error call other R
> functions in Perl? 

Here's a little Perl script that invokes R.  If it is called with a positive
numerical argument, then R exits with that status, and Perl catches it via $?.
Note the script file in /tmp is saved (intentionally) if R exits abnormally.
See also the help pages for q(), stop(), and options("error").


#!/usr/local/bin/perl
(($arg1) = @ARGV) || die "Must pass a numerical argument.\n";
$script = "/tmp/rwrap$$.R";
open(SCRIPT, ">$script");
print SCRIPT <<EOF;
  arg1 <- $arg1
  options(error=expression(q(status=arg1)))
  if (arg1 > 0) log("a")
  q()
EOF
close(SCRIPT);
system("R --vanilla --slave < $script");
($Rstat = $?/256) && die "Aborted in R with status $Rstat.\n";
unlink $script;


-- 
                              -- David Brahm (brahm at alum.mit.edu)



From vito.muggeo at giustizia.it  Thu Jan 16 17:19:58 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Thu Jan 16 17:19:58 2003
Subject: [R] Overdispersed poisson - negative observation
References: <OF5C737A53.51A23FF1-ON80256CB0.005279C8@uk.rsa-ins.com>
Message-ID: <00d001c2bd7a$3bda0980$5c13070a@it.giustizia.it>

Roughtly speaking, your code is correct, but you can not fit your data with
negative value:

> glm.qD93 <- glm(paym ~ alpha + beta, family=quasipoisson())
Error in eval(expr, envir, enclos) : Negative values not allowed for the
quasiPoisson family

Anyway, in general, quasi-likelihood is a way to handle (low) overdispersion
in count data: for modest or large amount of overdispersion you could use
negative binomial models, namely glm.nb() in MASS or gnlr() in the Jim
Lindsey packages.

best,
vito



----- Original Message -----
From: <peter.fledelius at wgo.royalsun.com>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, January 16, 2003 4:45 PM
Subject: [R] Overdispersed poisson - negative observation


> Dear R users
>
> I have been looking for functions that can deal with overdispersed poisson
> models. Some (one) of the observations are negative. According to
actuarial
> literature (England & Verall, Stochastic Claims Reserving in General
> Insurance , Institute of Actiuaries 2002) this can be handled through the
> use of quasi likelihoods instead of normal likelihoods. The presence of
> negatives is not normal in a poisson model, however, we see them
frequently
> in this type of data, and we would like to be able to fit the model
anyway.
>
> At the moment R is complaining about negative values and the link function
> = log.
>
> My code looks like this. Do any of you know if this problem can be solved
> in R? Any suggestions are welcomed.
>
> Kind regards,
>
> Peter Fledelius (new R user)
>
> *********** Code ************
> paym   <- c(5012, 3257, 2638,  898, 1734, 2642, 1828,  599,   54,  172,
>              106, 4179, 1111, 5270, 3116, 1817, -103,  673,  535,
>             3410, 5582, 4881, 2268, 2594, 3479,  649,  603,
>             5655, 5900, 4211, 5500, 2159, 2658,  984,
>             1092, 8473, 6271, 6333, 3786,  225,
>             1513, 4932, 5257, 1233, 2917,
>              557, 3463, 6956, 1368,
>             1351, 5596, 6165,
>             3133, 2262,
>             2063)
> alpha   <- factor(c(1,1,1,1,1,1,1,1,1,1,
>              2,2,2,2,2,2,2,2,2,
>              3,3,3,3,3,3,3,3,
>              4,4,4,4,4,4,4,
>              5,5,5,5,5,5,
>              6,6,6,6,6,
>              7,7,7,7,
>              8,8,8,
>              9,9,
>              10))
> beta    <- factor(c(1,2,3,4,5,6,7,8,9,10,
>              1,2,3,4,5,6,7,8,9,
>              1,2,3,4,5,6,7,8,
>              1,2,3,4,5,6,7,
>              1,2,3,4,5,6,
>              1,2,3,4,5,
>              1,2,3,4,
>              1,2,3,
>              1,2,
>              1))
> d.AD <- data.frame(paym, alpha, beta)
> glm.qD93 <- glm(paym ~ alpha + beta, family=quasipoisson())
> glm.qD93
> ************ Code end ***************
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From shaliniyv at yahoo.co.in  Thu Jan 16 17:28:08 2003
From: shaliniyv at yahoo.co.in (=?iso-8859-1?q?Shalini=20Venkatachar?=)
Date: Thu Jan 16 17:28:08 2003
Subject: [R] hlep needed regarding acf
Message-ID: <20030116162713.11928.qmail@web8007.mail.in.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030116/3314497d/attachment.pl

From petr.pikal at precheza.cz  Thu Jan 16 17:34:03 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu Jan 16 17:34:03 2003
Subject: [R] Problem using outer()
In-Reply-To: <F6WOAUV06a9u0LDpR4z00007f0f@hotmail.com>
Message-ID: <3E26ECF8.7873.2211532@localhost>

Hi

On 16 Jan 2003 at 9:41, John Smith wrote:

> Here is a problem I am having. I would sincerely appreciate any
> help/advice from the experts who read this list. I have contrived a
> simple example, but it gives the same result I encountered in a more
> complicated application.
> 
> Given data frame u:
> 
> x	y
> 31	19
> 32	18
> 33	17
> 34	16
> 35	15
> 36	14
> 37	13
> 
> I define the function f as follows:
> 
> f <- function(a,b) sum(u$x - a) + sum(u$y - b)

try this one

f<-function(a,b) colSums(outer(u$x,a,"-"))+colSums(outer(u$y,b,"-"))

Though I am not sure if it is quicker then for loop :-)

> 
> One might think of a and b as "mean" values, and the function f totals
> up the deviations.
> 
> I wish to generate a table of the value of f given various values of a
> and b along grid points. So I define:
> 
> aa <- seq(0.1,1.0,0.1)
> bb <- seq(1.0,2.0,0.1)
> 
> Unfortunately, when I issue the command
> 
> s <- outer(aa,bb,f)
> 
> R tells me the following:
> 
> Warning messages:
> 1: longer object length
>         is not a multiple of shorter object length in: u$x - a
> 2: longer object length
>         is not a multiple of shorter object length in: u$y - b
> 
> Outer() does assign values to s, but they are values that do not make
> sense. I understand why this is happening. Outer() passes the vectors
> aa and bb to function f, where the statement sum(u$x - a) + sum(u$y -
> b) is encountered with u$x and u$y of length 7 and a and b of length
> 10. R then cannot apply the recycle rule.
> 
> I can do this simply enough with nested loops and get the correct
> answer. Unfortunately, the "real" problem is much more involved than
> the simple example I show here (data frame u contains hundreds of
> observations, and the function f is many lines long) so the solution
> takes some time. The R documentation stresses in a number of places
> that loops are inefficient and should be eliminated where possible. I
> thought using outer() would speed the application up, but it doesn't
> work.
> 
> Any suggestions? How can I build up the table of values without using
> nested loops?
> 
> John Shonder
> 

Petr Pikal
Precheza a.s., Nab?.Dr.E.Bene?e 24, 750 62 P?erov
tel: +420581 252 257 ; 724 008 364
petr.pikal at precheza.cz; p.pik at volny.cz
fax +420581 252 561



From p.dalgaard at biostat.ku.dk  Thu Jan 16 17:38:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Jan 16 17:38:03 2003
Subject: [R] Overdispersed poisson - negative observation
In-Reply-To: <00d001c2bd7a$3bda0980$5c13070a@it.giustizia.it>
References: <OF5C737A53.51A23FF1-ON80256CB0.005279C8@uk.rsa-ins.com>
	<00d001c2bd7a$3bda0980$5c13070a@it.giustizia.it>
Message-ID: <x2smvtjbkz.fsf@biostat.ku.dk>

"vito muggeo" <vito.muggeo at giustizia.it> writes:

> Roughtly speaking, your code is correct, but you can not fit your data with
> negative value:
> 
> > glm.qD93 <- glm(paym ~ alpha + beta, family=quasipoisson())
> Error in eval(expr, envir, enclos) : Negative values not allowed for the
> quasiPoisson family
> 
> Anyway, in general, quasi-likelihood is a way to handle (low) overdispersion
> in count data: for modest or large amount of overdispersion you could use
> negative binomial models, namely glm.nb() in MASS or gnlr() in the Jim
> Lindsey packages.

But they certainly wouldn't want to see negative responses either...

You should (I think) be able to get away with simply deleting the
check inside the quasipoisson family function.

        -p 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From johns2326 at hotmail.com  Thu Jan 16 17:42:05 2003
From: johns2326 at hotmail.com (John Smith)
Date: Thu Jan 16 17:42:05 2003
Subject: [R] Problem using outer()
Message-ID: <F98ciPXkmCJiLyNfHgI00000e36@hotmail.com>

For anyone who may be having a similar problem, here is the solution (thanks 
to Peter Dalgaard and a search of the archives):


g <- function(a,b) sapply(seq(along=a),function(i) f(a[i],b[i]))
s <- outer(aa,bb,g)

Looking at the archives it seems many have had the same problem. At least 
I'm in good company! Many thanks to those who responded.

John Shonder

>
>Here is a problem I am having. I would sincerely appreciate any help/advice
>from the experts who read this list. I have contrived a simple example, but
>it gives the same result I encountered in a more complicated application.
>
>Given data frame u:
>
>x	y
>31	19
>32	18
>33	17
>34	16
>35	15
>36	14
>37	13
>
>I define the function f as follows:
>
>f <- function(a,b) sum(u$x - a) + sum(u$y - b)
>
>One might think of a and b as "mean" values, and the function f totals up
>the deviations.
>
>I wish to generate a table of the value of f given various values of a and 
>b
>
>along grid points. So I define:
>
>aa <- seq(0.1,1.0,0.1)
>bb <- seq(1.0,2.0,0.1)
>
>Unfortunately, when I issue the command
>
>s <- outer(aa,bb,f)
>
>R tells me the following:
>
>Warning messages:
>1: longer object length
>         is not a multiple of shorter object length in: u$x - a
>2: longer object length
>         is not a multiple of shorter object length in: u$y - b
>
>Outer() does assign values to s, but they are values that do not make 
>sense.
>
>I understand why this is happening. Outer() passes the vectors aa and bb to
>function f, where the statement sum(u$x - a) + sum(u$y - b) is encountered
>with u$x and u$y of length 7 and a and b of length 10. R then cannot apply
>the recycle rule.
>
>I can do this simply enough with nested loops and get the correct answer.
>Unfortunately, the "real" problem is much more involved than the simple
>example I show here (data frame u contains hundreds of observations, and 
>the
>
>function f is many lines long) so the solution takes some time. The R
>documentation stresses in a number of places that loops are inefficient and
>should be eliminated where possible. I thought using outer() would speed 
>the
>
>application up, but it doesn't work.
>
>Any suggestions? How can I build up the table of values without using 
>nested
>
>loops?
>
>John Shonder
>


From ripley at stats.ox.ac.uk  Thu Jan 16 17:49:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan 16 17:49:03 2003
Subject: [R] Calling R function from within C code
In-Reply-To: <20030116155552.GA9238@pcf004.jinr.ru>
Message-ID: <Pine.LNX.4.44.0301161644550.1158-100000@gannet.stats>

It's hard to know where to start from.  A pairlist is a linked list of R
objects, a generic vector (of mode list) is an array of pointers to R
objects.  They are just different (and I've simplified by ignoring 
tags/names).  A paired list has sequential access, a generic vector random 
access, but it is less expensive to append to / insert in a pairlist.

On Thu, 16 Jan 2003, Timur Elzhov wrote:

> On Thu, Jan 16, 2003 at 03:22:42PM +0000, ripley at stats.ox.ac.uk wrote:
> 
> > That way.  It's a pairlist of arguments.  As that manual says
> Thank you, Mr. Ripley!
> 
> But, it was interesing for me for a long - what is a principal
> difference between 'pairlist' and a "general" list?
> Why to access pairlist elements I need to use the strange macro
> like CAR(CDR(x)), and cannot do it by VECTOR_ELT(x, i) ?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu Jan 16 18:24:23 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Jan 16 18:24:23 2003
Subject: [R] Calling R function from within C code
In-Reply-To: <Pine.LNX.4.44.0301161644550.1158-100000@gannet.stats>
References: <Pine.LNX.4.44.0301161644550.1158-100000@gannet.stats>
Message-ID: <x2lm1lj9dr.fsf@biostat.ku.dk>

ripley at stats.ox.ac.uk writes:

> It's hard to know where to start from.  A pairlist is a linked list of R
> objects, a generic vector (of mode list) is an array of pointers to R
> objects.  They are just different (and I've simplified by ignoring 
> tags/names).  A paired list has sequential access, a generic vector random 
> access, but it is less expensive to append to / insert in a pairlist.

Or, think Lisp: in Lisp a list is written like

( A B C )

and the internal representation is in terms of the "head" A and the
"tail" ( B C ). All lists are represented as such pairs (single
element lists have a pointer to the value as head and NIL as the
tail).

For historical reasons, Lisp'ers refer to the head bit as CAR and the
tail as CDR. This has to do with the first implementations which were
on an IBM 704 machine which stored the two pointers in the CPU's
Address Register and the Decrement Register, so CAR is "Content of the
Address Register", etc. You'll also see CONS which constructs a list
given its CAR and a CDR and shorthand macros like CADDR which is
CAR(CDR(CDR(x))) (and will give you the "C" in ( A B C )

Notice that this representation is radically different from a vector
of mode "list". Pairlists are extremely flexible for things like
inserting and deleting elements in-place, but accessing the n-th
element requires counting from the head.

R, being a modified Scheme engine, used to have pairlists for its list
structure, but the sequential access became a performance problem
(esp. with ported S code). There are still a few places where
pairlists are visible at the user level if you know where to look...

> On Thu, 16 Jan 2003, Timur Elzhov wrote:
> 
> > On Thu, Jan 16, 2003 at 03:22:42PM +0000, ripley at stats.ox.ac.uk wrote:
> > 
> > > That way.  It's a pairlist of arguments.  As that manual says
> > Thank you, Mr. Ripley!
> > 
> > But, it was interesing for me for a long - what is a principal
> > difference between 'pairlist' and a "general" list?
> > Why to access pairlist elements I need to use the strange macro
> > like CAR(CDR(x)), and cannot do it by VECTOR_ELT(x, i) ?
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From fharrell at virginia.edu  Thu Jan 16 18:37:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu Jan 16 18:37:03 2003
Subject: [R] Plotting Question
In-Reply-To: <FB8942EA6DCDD511A43F00508BCF818D07122681@lajgrdexm01.agouron.com>
References: <FB8942EA6DCDD511A43F00508BCF818D07122681@lajgrdexm01.agouron.com>
Message-ID: <20030116123848.2f2e0e9e.fharrell@virginia.edu>

You might investigate the event.chart function in the Hmisc library (see http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html)

On Thu, 16 Jan 2003 08:10:34 -0800
"Coate, Bruce" <bruce.coate at pfizer.com> wrote:

> For a clinical trial I am involved with, I would like a plot (for each
> subject) similar to the following which will indicate what drugs that
> subject was taking on each day during the study:
> 
> Drug 1    [---]           [----------------------]
> 
> Drug 2    [-------------------------------------]
> 
> Drug 3           [---------]  [----------------------------]
>              |--------------------------------------------------|
>              0                                                n
> 
>                            Study Day
> 
>  I have thought about using strip plot, perhaps setting a flag each day the
> subject is on study (1 if drug x is taken on that day, NA otherwise). But
> that means I would have to create extra records for each subject because my
> data looks something like,
> 
> Subject   Drug   Start          Stop
> ------------------------------------------
>  1           1         5Jan2002   10Jan2002
>  1           1        12Jan2002  30Jan2002
>  2           2        15Feb2002  20Mar2002
> etc.
> 
> Does anyone have a suggestion as to which kind of plotting function is best
> suited to this? 
> Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From tord.snall at ebc.uu.se  Thu Jan 16 18:47:03 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Thu Jan 16 18:47:03 2003
Subject: [R] problem with as.data.frame.table
Message-ID: <3.0.6.32.20030116184022.009c3d30@mail.anst.uu.se>

Dear all, 

I think that what I want is an as.data.frame.table-object, but see error
message below.

I have a data frame with one tree per row, diaclass tells if it is a small,
mid or large tree

> cpy.tradart[1:5, ]
  ObjektID diaclass
1 AX.Grb.1   bigdia
2 AX.Grb.1   middia
3 AX.Grb.1   middia
4 AX.Grb.1 smalldia
5 AX.Grb.1   middia
> 

I want a data frame telling no of trees per diameter class, per ObjektID
 
There are 107 ObjektID
> nlevels(cpy.tradart$ObjektID)
[1] 107
 
and  3 diaclass levels
> levels(cpy.tradart$diaclass)
[1] "bigdia"   "middia"   "smalldia"
 
I first split the data frame
> group <- split(cpy.tradart$diaclass, list(cpy.tradart[, c("ObjektID",
"diaclass")])) # 
> 
and then sapply
> test <- sapply( group, function(x) sum(length(x)))
> 
> # This looks good
> test[1:5]
 AX.Grb.O.bigdia       S.1.bigdia S.1.ominv.bigdia      S.10.bigdia
S.11.bigdia 
               6                3                3               11
       5 
> 
> # But not each diaclass is represented in each ObjektID, because
> length(test)
[1] 313
> # is smaller than 3*107

and I cannot split up the names of each element of the vector "test".

# What I want is a data frame like this:

ObjectID    diaclass  Frequency
AX.Grb.1    smalldia      23
AX.Grb.1    middia        45
AX.Grb.1    bigdia         0
AX.Grb.2    smalldia       2
AX.Grb.2    middia         5
AX.Grb.2    bigdia        10
AX.Grb.3    smalldia       3
AX.Grb.3    middia        45
AX.Grb.3    bigdia         0

Note that there will be zeroes, but that information is lacking in "test".

I have also tried:

> as.data.frame.table(cpy.tradart)
Error in as.table.default(x) : cannot coerce into a table



Could someone please give a hint.


Thanks in advance!!


Sincerely,
Tord



-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From f.calboli at ucl.ac.uk  Thu Jan 16 18:51:03 2003
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: Thu Jan 16 18:51:03 2003
Subject: [R] graphics
Message-ID: <3.0.6.32.20030116175340.00a5a088@pop-server.ucl.ac.uk>

Dear R community,

I need to plot the results of some simulations I did using QTL
Cartographer. I am plotting LOD scores over three chromosomes. The three
plot have to be one next to the other. 

The procedure I am using is:

par(mfrow=c(1,3))
plot(x$x, x$y, ylim=c(0,35), type="l", col="blue", las=1, xaxs="i",
yaxs="i", xlab="X Chromosome", ylab="LOD")
abline(h=3.055)

plot(ch2$x, ch2$y, ylim=c(0,35), type="l", col="blue", yaxt="n", xaxs="i",
yaxs="i", xlab="Chromosome 2", ylab="")
abline(h=3.055)

plot(ch3$x, ch3$y, ylim=c(0,35), type="l", col="blue", yaxt="n", xaxs="i",
yaxs="i", xlab="Chromosome 3", ylab="")
abline(h=3.055)

This works fine but I would like to improve it a bit. I would like the same
scaling along the x axis so that the plot for longer chromosomes and
shorter ones looks "in scale". Second thing, I'd like to have the three
plots much closer together, the space between plots given by mfrow at the
moment is far too much.

Regards,

Federico Calboli
 

=========================

Federico C.F. Calboli

Department of Biology
University College London
Room 327
Darwin Building
Gower Street
London
WClE 6BT

Tel: (+44) 020 7679 4395 
Fax (+44) 020 7679 7096
f.calboli at ucl.ac.uk



From verzani at math.csi.cuny.edu  Thu Jan 16 18:57:03 2003
From: verzani at math.csi.cuny.edu (verzani@math.csi.cuny.edu)
Date: Thu Jan 16 18:57:03 2003
Subject: [R] Announce: pmg -- menu driven GUI using RGtk
Message-ID: <15910.62004.627497.532307@levy.math.csi.cuny.edu>

Hello all,

I've put together a quick and dirty menubar + dialogs + spreadsheet
GUI for R using the RGtk package. Performance is not great (OOP is a
real memory hog?), the design may be worse, but the hope is that it
will be useful in an introductory stats course while we await the
arrival of a real gui with ObveRsive and SciViews.

The package can be found at 

http://www.math.csi.cuny.edu/Statistics/R/pmg/

Feedback welcome.

-- 
o---------------------------------------------------------------------o
|  John Verzani                            verzani at math.csi.cuny.edu  |
|  CUNY/CSI			       www.math.csi.cuny.edu/verzani  |
|  Dept. of Mathematics, 1S-215	                        718 982 3623  |
|  Staten Island, NY 10314	       	          (fax) 718 982 3631  |
o---------------------------------------------------------------------o



From reid_huntsinger at merck.com  Thu Jan 16 19:04:03 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Thu Jan 16 19:04:03 2003
Subject: [R] Multivariate regression in R
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC2D7@uswpmx11.merck.com>


From bates at stat.wisc.edu  Thu Jan 16 19:29:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu Jan 16 19:29:03 2003
Subject: [R] graphics
In-Reply-To: <3.0.6.32.20030116175340.00a5a088@pop-server.ucl.ac.uk>
References: <3.0.6.32.20030116175340.00a5a088@pop-server.ucl.ac.uk>
Message-ID: <6r4r89q78d.fsf@bates4.stat.wisc.edu>

Federico Calboli <f.calboli at ucl.ac.uk> writes:

> Dear R community,
> 
> I need to plot the results of some simulations I did using QTL
> Cartographer. I am plotting LOD scores over three chromosomes. The three
> plot have to be one next to the other. 
> 
> The procedure I am using is:
> 
> par(mfrow=c(1,3))
> plot(x$x, x$y, ylim=c(0,35), type="l", col="blue", las=1, xaxs="i",
> yaxs="i", xlab="X Chromosome", ylab="LOD")
> abline(h=3.055)
> 
> plot(ch2$x, ch2$y, ylim=c(0,35), type="l", col="blue", yaxt="n", xaxs="i",
> yaxs="i", xlab="Chromosome 2", ylab="")
> abline(h=3.055)
> 
> plot(ch3$x, ch3$y, ylim=c(0,35), type="l", col="blue", yaxt="n", xaxs="i",
> yaxs="i", xlab="Chromosome 3", ylab="")
> abline(h=3.055)
> 
> This works fine but I would like to improve it a bit. I would like the same
> scaling along the x axis so that the plot for longer chromosomes and
> shorter ones looks "in scale". Second thing, I'd like to have the three
> plots much closer together, the space between plots given by mfrow at the
> moment is far too much.

xyplot in the lattice package is the natural way of doing this.  There
is a "learning curve" in getting used to lattice but it is worth the
effort.



From Timur.Elzhov at jinr.ru  Thu Jan 16 19:50:03 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Thu Jan 16 19:50:03 2003
Subject: [R] Calling R function from within C code
In-Reply-To: <Pine.LNX.4.44.0301161516440.5989-100000@gannet.stats>
References: <20030116151044.GA9021@pcf004.jinr.ru> <Pine.LNX.4.44.0301161516440.5989-100000@gannet.stats>
Message-ID: <20030116185033.GA9878@pcf004.jinr.ru>

On Thu, Jan 16, 2003 at 03:22:42PM +0000, ripley at stats.ox.ac.uk wrote:
>>    I'd like to call R function from within C code.
>>    I looked through the 'R exts' manual, found examples with
>>    lang2(R_fcall, list), and tried it, but it seemed to create
>>    the call, which can accept only a single argument of 'list'
>>    type, when I need to create the call of R functions with
>>    arbitrary numbers of arguments.
>>
>>    How can I do it?
> That way.  It's a pairlist of arguments.  As that manual says
> 
> Function @code{lang2} creates an executable `list' of two elements, but
> this will only be clear to those with a knowledge of a LISP-like
> language.
> 
> There are examples in optim.c and deriv.c.

Excuse me that I'm so stupid :)
I couldn't find direct instructions how should I use lang2..

This is my C code. I create an empty pairlist of length 2,
and then attach it to R_fcall:

/* ================= R-test.c ================= */

SEXP foo(SEXP fn, SEXP elmt1, SEXP elmt2, SEXP rho)
{
    SEXP R_fcall, args, ans;

    PROTECT( R_fcall = lang2(fn, R_NilValue)   );
    PROTECT( args    = allocVector(LISTSXP, 2) );

    SETCAR ( args, elmt1 );
    SETCADR( args, elmt2 );

    SETCADR( R_fcall, args );

    PROTECT( ans = eval(R_fcall, rho) );


    UNPROTECT(3);

    return ans;

}

/* ============================================ */

Then, I create a simple R function f(x, y) and call it:

  f <- function(x, y) match.call()

  .Call("foo", rnorm, 1, 2, new.env())
    function (x, y) 
    match.call()(x = list(1, 2))

So, the only the _first_ `x' argument is evaluated to _list_..
I'm sorry, where I'm wrong?!

Thank you!


--
WBR,
Timur.



From deleeuw at stat.ucla.edu  Thu Jan 16 19:57:27 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Thu Jan 16 19:57:27 2003
Subject: [R] Announce: pmg -- menu driven GUI using RGtk
In-Reply-To: <15910.62004.627497.532307@levy.math.csi.cuny.edu>
Message-ID: <084D5237-2984-11D7-9B85-000393BB6D36@stat.ucla.edu>

This build and runs fine in the Darwin/X11 version for Mac OS X. It  
does require some
hacking of RGtk. Basically, you need to build RGtk both as the bundle  
RGtk.so
and as the static archive libRGtk.a This is necessary to be able to  
build
RGtkExtras and RGtkGlade and so on. Binaries will be in the next  
archive on
gifi.

On Thursday, January 16, 2003, at 09:56 AM, verzani at math.csi.cuny.edu  
wrote:

> Hello all,
>
> I've put together a quick and dirty menubar + dialogs + spreadsheet
> GUI for R using the RGtk package. Performance is not great (OOP is a
> real memory hog?), the design may be worse, but the hope is that it
> will be useful in an introductory stats course while we await the
> arrival of a real gui with ObveRsive and SciViews.
>
> The package can be found at
>
> http://www.math.csi.cuny.edu/Statistics/R/pmg/
>
> Feedback welcome.
>
> --  
> o---------------------------------------------------------------------o
> |  John Verzani                            verzani at math.csi.cuny.edu  |
> |  CUNY/CSI			       www.math.csi.cuny.edu/verzani  |
> |  Dept. of Mathematics, 1S-215	                        718 982 3623  |
> |  Staten Island, NY 10314	       	          (fax) 718 982 3631  |
> o---------------------------------------------------------------------o
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------



From Timur.Elzhov at jinr.ru  Thu Jan 16 20:11:02 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Thu Jan 16 20:11:02 2003
Subject: [R] Calling R function from within C code
In-Reply-To: <20030116185033.GA9878@pcf004.jinr.ru>
References: <20030116151044.GA9021@pcf004.jinr.ru> <Pine.LNX.4.44.0301161516440.5989-100000@gannet.stats> <20030116185033.GA9878@pcf004.jinr.ru>
Message-ID: <20030116191140.GA9940@pcf004.jinr.ru>

On Thu, Jan 16, 2003 at 09:50:34PM +0300, Timur Elzhov wrote:

>   .Call("foo", rnorm, 1, 2, new.env())
>     function (x, y) 
>     match.call()(x = list(1, 2))
Oh, I'm mistaken. The `.Call("foo", f, 1, 2, new.env())' is
the right string, of course.



From p.dalgaard at biostat.ku.dk  Thu Jan 16 21:05:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Jan 16 21:05:04 2003
Subject: [R] problem with as.data.frame.table
In-Reply-To: <3.0.6.32.20030116184022.009c3d30@mail.anst.uu.se>
References: <3.0.6.32.20030116184022.009c3d30@mail.anst.uu.se>
Message-ID: <x28yxkq2su.fsf@biostat.ku.dk>

Tord Snall <tord.snall at ebc.uu.se> writes:

> Dear all, 
> 
> I think that what I want is an as.data.frame.table-object, but see error
> message below.

(Haven't we been here before??)

There's no such thing as an as.data.frame.table-object.
as.data.frame.table turns table objects into data frames.
 
> I have a data frame with one tree per row, diaclass tells if it is a small,
> mid or large tree
> 
> > cpy.tradart[1:5, ]
>   ObjektID diaclass
> 1 AX.Grb.1   bigdia
> 2 AX.Grb.1   middia
> 3 AX.Grb.1   middia
> 4 AX.Grb.1 smalldia
> 5 AX.Grb.1   middia
> > 
> 
> I want a data frame telling no of trees per diameter class, per ObjektID

What's wrong with as.data.frame(table(ObjektID,diaclass)) then?


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.connolly at hortresearch.co.nz  Thu Jan 16 21:12:03 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu Jan 16 21:12:03 2003
Subject: [R] X11 device now needs to be explicitly started?
In-Reply-To: <200301152247.41729.deepayan@stat.wisc.edu>
References: <20030116013500.GG21374@hortresearch.co.nz> <200301152247.41729.deepayan@stat.wisc.edu>
Message-ID: <20030116201047.GL21374@hortresearch.co.nz>

On Wed, 15-Jan-2003 at 10:47PM -0600, Deepayan Sarkar wrote:

|> On Wednesday 15 January 2003 07:35 pm, Patrick Connolly wrote:
|> >          _
|> > platform i686-pc-linux-gnu
|> > arch     i686
|> > os       linux-gnu
|> > system   i686, linux-gnu
|> > status
|> > major    1
|> > minor    6.2
|> > year     2003
|> > month    01
|> > day      10
|> > language R
|> >
|> >
|> > Until this version, I've not had to explicitly start the x11 device.
|> > Now, (at least with lattice plots), one is not automatically started
|> 
|> Could you explain ? There's sometimes a warning, but I haven't seen
|> the device not being opened.

On closer inspection, I see that it falls over earlier than the
plotting itself.  It arises when I attempt to adjust some trellis
settings.  This is the message:

Error in trellis.par.set(y, x) : No device is currently Active


I notice that trellis.par.set has been changed this time.

"trellis.par.set" <-
  function (name, value, warn = TRUE) 
{
  if (!is.list(value)) 
    stop("value must be a list")
  if (warn && is.null(dev.list())) 
    stop("No device is currently Active")
  lattice.theme[[.Device]][[name]] <<- value
}


Previously, it had been only the last line.

The problem arises because dev.list() returns NULL if no device is
open and thus the call to stop().  

I don't know whether it would be a good idea to have trellis.par.set
start the default device.

Ideas?



-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From Hicham.Zmarrou at student.uva.nl  Thu Jan 16 21:18:02 2003
From: Hicham.Zmarrou at student.uva.nl (H. Zmarrou)
Date: Thu Jan 16 21:18:02 2003
Subject: [R] Help!!
Message-ID: <a82190a85ea8.a85ea8a82190@student.uva.nl>

Dear R-ers:
I'm sorry to disturb you, I want just ask how to work with a sum?
To be more exact I want to work with the function 

f(x)= sum_1^{n}K(x-x_i/h), K is a kernel or any other function
I have a data set (x_i) and I want to compute x for each x or plot 
f(x).
Thank you for your hulp



From tlumley at u.washington.edu  Thu Jan 16 21:24:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Jan 16 21:24:03 2003
Subject: [R] help drawing kaplan-meier plot starting from 0
In-Reply-To: <5.2.0.9.0.20030116154257.00a6c720@pop-server.ucl.ac.uk>
Message-ID: <Pine.A41.4.44.0301161221360.49844-100000@homer05.u.washington.edu>

On Thu, 16 Jan 2003, Frank Mattes wrote:

> Dear help news reader,
>
> I'm trying to draw a Kaplan-Meier curve and would like to ask the news
> group for some help
> Supposing I have study comapring two drugs, "A", and "B" and I recorde the
> time to get to the clinical endpoint (Time), in my case becommming virus free.
>
<various stufff>
> which gives me a Kaplan-Meier Curve, starting with 1. However I would like
> to the a plot
> starting with "0" and than showing the increasing numbers of patients
> becomming "virus negative".

You want the fun="event" option to plot.survfit.  Eg
       data(aml)
      leukemia.surv <- survfit(Surv(time, status) ~ x, data = aml)
# usual plot
      plot(leukemia.surv, lty = 2:3)
# cdf (event) ploot
      plot(leukemia.surv, lty = 2:3,fun="event")

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From Ted.Harding at nessie.mcc.ac.uk  Thu Jan 16 21:37:03 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu Jan 16 21:37:03 2003
Subject: [R] Multivariate regression in R
In-Reply-To: <2C23DE2983BE034CB1CB90DB6B813FD6028AC2D7@uswpmx11.merck.com>
Message-ID: <XFMail.030116202901.Ted.Harding@nessie.mcc.ac.uk>

On 16-Jan-03 Huntsinger, Reid wrote:
>>From the equation you write, I don't see why "lsfit" wouldn't work. 
> To estimate the covariance matrix of e you could use the sample
> covariance matrix of the residuals. If desired, use its cholesky
> decomposition to transform to make the error approximately
> uncorrelated, then refit (and back-transform the coefficient matrix).
> 
> Stacking the columns of Y and replicating X won't do what you write;
> it forces each univariate regression to have the same coefficients.
> To get what you wrote you would replicate X in blocks of a
> block-diagonal
> matrix. 
> 
> I'm not sure I understand the role of W. If what you want is to fit
> equations like
> 
> y(i) = a(w(i)) + xB(i) + e(i)
> 
> for each observation and each response y(1),...,y(p), then I guess you
> could just fit each response separately, treating W as a factor. Then
> estimate the covariance matrix of e via the residuals as before, etc. 

Thanks Reid! To clarify, let me spell out a simple example:

       Y            X         W  

  y11 y12 y13    x11 x12    1 2 3
  y21 y22 y23    x21 x22    1 3 2
  y31 y32 y33    x31 x32    2 1 3
  y41 y42 y43    x41 x42    2 1 3
  y51 y52 y53    x51 x52    3 1 2
  ....

is a matrix representation of the data. Here, Y is the matrix of N
3-variate responses, X is an Nx2 matrix of quantitative covariates,
W is an Nx3 matrix of levels of the 3-level qualitative factor W
where Wij shows which level of W is associated with the jth variate
of Yi (the ith row of Y). After allowing for the effects of X and W,
it is expected that the residuals

       e

  e11 e12 e13
  e21 e22 e23
  e31 e32 e33
  e41 e42 e43
  e51 e52 e53
  ....

will be correlated between columns (in fact reflecting a real mechanism
in the process generating the data), and for modelling it is supposed
that (e1,e2,e3) have a joint Normal distribution with covariance matrix S.

The additive X component of the model can be written as X*B where

  B  =  b11 b12 b13
        b21 b22 b23
and the bij are the regression coefficients of Y on the quantitative
covariates (X1,X2).

The additive W component could be written in matrix form (for the above
"data") as:

         W1               W2             W3

  w1 * 1 0 0   +   w2 * 0 1 0  +  w3 * 0 0 1
       1 0 0            0 0 1          0 1 0
       0 1 0            1 0 0          0 0 1
       0 1 0            1 0 0          0 0 1
       0 1 0            0 0 1          1 0 0
       ...              ...            ...

where
col j of W1 is 1 where the jth variate in Y has level 1 of W (j = 1,2,3),
col j of W2 is 1 where the jth variate in Y has level 2 of W (j = 1,2,3),
col j of W3 is 1 where the jth variate in Y has level 3 of W (j = 1,2,3)

and w1, w2, w3 are the scalar magnitudes of the "effects" of levels
1, 2, 3 of W.

Hence the multivariate regression model for the data could be written in
matrix form as

  Y = X*B + w1*W1 + w2*W2 + w3*W3 + e

where e is 3-dim N(0,S), and B, w1, w2, w3 and S are to be estimated.

What, in R, I can't make out how to do is to give some function (which
function?) a model specification of the form

  Y ~ X + W1 + W2 + W3

but in such a way that it will fit a 2x3 matrix B of coefficients for X,
but scalar coefficients w1, w2, w3 for W1, W2, W3 (and also come up with
the estimated covariance matrix for the residuals e, though this, as you
point out, could be obtained after the fit from the Nx3 residuals;
however, it should be available from the function since it would have
to be used in fitting the model).

Analytically, the log-likelihood can be written (summing over r)

  (-N/2)*log(det(S)) - 0.5*SUM[ e_r' * S^(-1) * e_r ] (e_r = rth row)

where e = Y - B*X - w1*W1 - w2*W2 - w3*W3. After differentiation and
algebra, one could implement the resulting matrix equations in octave
(or matlab) and proceed to a solution. One could even do this, as a
numerical procedure, in R -- but I'd rather not! Indeed, R's richness
in model-fitting resources tempts one to think that this problem may
be solvable using these -- it's just that I can't seem to put my hand
on what's needed.

Your response suggests that the way to go is to fit covariates and
factors to each Y-variate in turn, take the residuals from these fits,
and estimate the covariance matrix S. But thereafter you have to get
into considering them jointly, in order to improve the fit iteratively,
since S is involved in the joint weighting to be applied.
So I'm still not seeing how to do this in R ...

Many thanks for the reply!
Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 16-Jan-03                                       Time: 20:29:01
------------------------------ XFMail ------------------------------



From david.firth at nuffield.oxford.ac.uk  Thu Jan 16 22:06:03 2003
From: david.firth at nuffield.oxford.ac.uk (David Firth)
Date: Thu Jan 16 22:06:03 2003
Subject: [R] Overdispersed poisson - negative observation
In-Reply-To: <OF5C737A53.51A23FF1-ON80256CB0.005279C8@uk.rsa-ins.com>
Message-ID: <3F79A547-2996-11D7-A946-0050E4C03977@nuffield.oxford.ac.uk>

Peter

You are right to suppose that negative observations should not be a 
problem for a quasi-Poisson fit (though negative *fitted* values would 
be, in a log-linear model).

The problem is that the "quasipoisson" function is overly restrictive, 
in requiring non-negativity of the y variable.  (commenting out the 
error trap is not enough to solve the problem).  There are two places 
where "quasipoisson" has problems:

     dev.resids <- function(y, mu, wt) 2 * wt * (y * log(ifelse(y ==
         0, 1, y/mu)) - (y - mu))

fails for negative values of y, while

     initialize <- expression({
         if (any(y < 0)) stop(paste("Negative values not allowed for",
             "the quasiPoisson family"))
         n <- rep(1, nobs)
         mustart <- y + 0.1
     })

would (without the error trap) return negative initial values for 
means, which won't work with a log link.

The first problem is the hard one: the deviance isn't defined when y is 
negative.  But an alternative is to use the Pearson X^2 statistic, 
which is defined for all values of y (and makes more sense anyway for 
quasi-likelhood models -- it's what you use to determine the dispersion 
constant).

The second problem is easy to fix: for example, just take as starting 
values the global mean (corresponding to zero-valued effects in the 
model).  I often find that this is a good starting point anyway -- 
better than the default choice, which typically is not in the model 
space (even when there are no negative values of y).

I give below an amended "quasipoisson" which seems to work, ie it fits 
the model by the quasi-likelihood method with variance proportional to 
mean.  It makes only the two changes just described.  A *slightly* 
unsatisfactory aspect is that quantities reported as "deviance" are in 
fact Pearson X^2 statistics.  But no other choice really makes sense 
there.

David

quasipoisson <- function (link = "log")
## Amended by David Firth, 2003.01.16, at points labelled ###
## to cope with negative y values
##
## Computes Pearson X^2 rather than Poisson deviance
##
## Starting values are all equal to the global mean
{
     linktemp <- substitute(link)
     if (!is.character(linktemp)) {
         linktemp <- deparse(linktemp)
         if (linktemp == "link")
             linktemp <- eval(link)
     }
     if (any(linktemp == c("log", "identity", "sqrt")))
         stats <- make.link(linktemp)
     else stop(paste(linktemp, "link not available for poisson",
         "family; available links are", "\"identity\", \"log\" and 
\"sqrt\""))
     variance <- function(mu) mu
     validmu <- function(mu) all(mu > 0)
     dev.resids <- function(y, mu, wt) wt*(y-mu)^2/mu   ###
     aic <- function(y, n, mu, wt, dev) NA
     initialize <- expression({
         n <- rep(1, nobs)
         mustart <- rep(mean(y), length(y))             ###
     })
     structure(list(family = "quasipoisson", link = linktemp,
         linkfun = stats$linkfun, linkinv = stats$linkinv, variance = 
variance,
         dev.resids = dev.resids, aic = aic, mu.eta = stats$mu.eta,
         initialize = initialize, validmu = validmu, valideta = 
stats$valideta),
         class = "family")
}


On Thursday, Jan 16, 2003, at 15:45 Europe/London, 
peter.fledelius at wgo.royalsun.com wrote:

> Dear R users
>
> I have been looking for functions that can deal with overdispersed 
> poisson
> models. Some (one) of the observations are negative. According to 
> actuarial
> literature (England & Verall, Stochastic Claims Reserving in General
> Insurance , Institute of Actiuaries 2002) this can be handled through 
> the
> use of quasi likelihoods instead of normal likelihoods. The presence of
> negatives is not normal in a poisson model, however, we see them 
> frequently
> in this type of data, and we would like to be able to fit the model 
> anyway.
>
> At the moment R is complaining about negative values and the link 
> function
> = log.
>
> My code looks like this. Do any of you know if this problem can be 
> solved
> in R? Any suggestions are welcomed.
>
> Kind regards,
>
> Peter Fledelius (new R user)
>
> *********** Code ************
> paym   <- c(5012, 3257, 2638,  898, 1734, 2642, 1828,  599,   54,  172,
>              106, 4179, 1111, 5270, 3116, 1817, -103,  673,  535,
>             3410, 5582, 4881, 2268, 2594, 3479,  649,  603,
>             5655, 5900, 4211, 5500, 2159, 2658,  984,
>             1092, 8473, 6271, 6333, 3786,  225,
>             1513, 4932, 5257, 1233, 2917,
>              557, 3463, 6956, 1368,
>             1351, 5596, 6165,
>             3133, 2262,
>             2063)
> alpha   <- factor(c(1,1,1,1,1,1,1,1,1,1,
>              2,2,2,2,2,2,2,2,2,
>              3,3,3,3,3,3,3,3,
>              4,4,4,4,4,4,4,
>              5,5,5,5,5,5,
>              6,6,6,6,6,
>              7,7,7,7,
>              8,8,8,
>              9,9,
>              10))
> beta    <- factor(c(1,2,3,4,5,6,7,8,9,10,
>              1,2,3,4,5,6,7,8,9,
>              1,2,3,4,5,6,7,8,
>              1,2,3,4,5,6,7,
>              1,2,3,4,5,6,
>              1,2,3,4,5,
>              1,2,3,4,
>              1,2,3,
>              1,2,
>              1))
> d.AD <- data.frame(paym, alpha, beta)
> glm.qD93 <- glm(paym ~ alpha + beta, family=quasipoisson())
> glm.qD93
> ************ Code end ***************
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From deepayan at stat.wisc.edu  Thu Jan 16 22:21:02 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu Jan 16 22:21:02 2003
Subject: [R] X11 device now needs to be explicitly started?
In-Reply-To: <20030116201047.GL21374@hortresearch.co.nz>
References: <20030116013500.GG21374@hortresearch.co.nz> <200301152247.41729.deepayan@stat.wisc.edu> <20030116201047.GL21374@hortresearch.co.nz>
Message-ID: <200301161520.20469.deepayan@stat.wisc.edu>

On Thursday 16 January 2003 02:10 pm, Patrick Connolly wrote:
> On Wed, 15-Jan-2003 at 10:47PM -0600, Deepayan Sarkar wrote:
> |> On Wednesday 15 January 2003 07:35 pm, Patrick Connolly wrote:
> |> >          _
> |> > platform i686-pc-linux-gnu
> |> > arch     i686
> |> > os       linux-gnu
> |> > system   i686, linux-gnu
> |> > status
> |> > major    1
> |> > minor    6.2
> |> > year     2003
> |> > month    01
> |> > day      10
> |> > language R
> |> >
> |> >
> |> > Until this version, I've not had to explicitly start the x11 device.
> |> > Now, (at least with lattice plots), one is not automatically started
> |>
> |> Could you explain ? There's sometimes a warning, but I haven't seen
> |> the device not being opened.
>
> On closer inspection, I see that it falls over earlier than the
> plotting itself.  It arises when I attempt to adjust some trellis
> settings.  This is the message:
>
> Error in trellis.par.set(y, x) : No device is currently Active
>
>
> I notice that trellis.par.set has been changed this time.
>
> "trellis.par.set" <-
>   function (name, value, warn = TRUE)
> {
>   if (!is.list(value))
>     stop("value must be a list")
>   if (warn && is.null(dev.list()))
>     stop("No device is currently Active")
>   lattice.theme[[.Device]][[name]] <<- value
> }
>
>
> Previously, it had been only the last line.
>
> The problem arises because dev.list() returns NULL if no device is
> open and thus the call to stop().
>
> I don't know whether it would be a good idea to have trellis.par.set
> start the default device.
>
> Ideas?

Personally, I don't have any strong preferences, other than that the old 
behaviour (which silently did nothing, if I remember correctly) should be 
changed. Maybe we should go with S-PLUS behaviour, which gives an error if 
trellis.par.set() is called without an open device, but DOES start the 
default device if trellis.par.get() is called. This would mean that lset() 
would also start the device.

Does that sound OK ?

Deepayan



From sjmiller at u.arizona.edu  Thu Jan 16 22:26:04 2003
From: sjmiller at u.arizona.edu (Susan J. Miller)
Date: Thu Jan 16 22:26:04 2003
Subject: [R] installing the XML package
Message-ID: <3E271E14.778EAE7F@u.arizona.edu>

I'm trying to install the XML package in R 1.6.1
(>install.packages("XML")).  The download is OK, but during
configuration the file parser.h cannot be found (it looks in libxml/ and
gnome-xml/ then gives up).  What is missing from my system?

-- 
Thanks,
-susan

Susan J. Miller
Biotechnology Computing Facility
Arizona Research Laboratories
Bio West 228
University of Arizona
Tucson, AZ  85721
(520) 626-2597



From jzhang at jimmy.harvard.edu  Thu Jan 16 23:00:03 2003
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Thu Jan 16 23:00:03 2003
Subject: [R] installing the XML package
Message-ID: <200301162159.QAA08262@blaise.dfci.harvard.edu>

You need to install libxml. Read the doc for XML package for more information.

>From: "Susan J. Miller" <sjmiller at u.arizona.edu>
>X-Accept-Language: en
>MIME-Version: 1.0
>To: r-help at stat.math.ethz.ch
>Content-Transfer-Encoding: 7bit
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Spam-Status: No, hits=0.0 required=5.0 
tests=NOSPAM_INC,SIGNATURE_LONG_SPARSE,SPAM_PHRASE_00_01, 
USER_AGENT_MOZILLA_XM,X_ACCEPT_LANG version=2.43
>X-Spam-Level: 
>Subject: [R] installing the XML package
>X-BeenThere: r-help at stat.math.ethz.ch
>X-Mailman-Version: 2.0.13
>List-Help: <mailto:r-help-request at stat.math.ethz.ch?subject=help>
>List-Post: <mailto:r-help at stat.math.ethz.ch>
>List-Subscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>
>List-Id: Main R Mailing List: Primary help <r-help.stat.math.ethz.ch>
>List-Unsubscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
>List-Archive: <http://www.stat.math.ethz.ch/pipermail/r-help/>
>X-Original-Date: Thu, 16 Jan 2003 14:03:16 -0700
>Date: Thu, 16 Jan 2003 14:03:16 -0700
>
>I'm trying to install the XML package in R 1.6.1
>(>install.packages("XML")).  The download is OK, but during
>configuration the file parser.h cannot be found (it looks in libxml/ and
>gnome-xml/ then gives up).  What is missing from my system?
>
>-- 
>Thanks,
>-susan
>
>Susan J. Miller
>Biotechnology Computing Facility
>Arizona Research Laboratories
>Bio West 228
>University of Arizona
>Tucson, AZ  85721
>(520) 626-2597
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From s.mcclatchie at niwa.co.nz  Thu Jan 16 23:08:02 2003
From: s.mcclatchie at niwa.co.nz (Sam McClatchie)
Date: Thu Jan 16 23:08:02 2003
Subject: [R] help.start() setup with netscape
Message-ID: <3E272D19.60209@niwa.cri.nz>

System info:
Mandrake 9.0
R Version 1.6.1
ESS 5.1.21
Emacs 21.2.1
-------------------

Colleagues

I understand that help.start() search function works with netscape and 
although it may also work with latest versions of mazilla it doesn't 
seem to with the one I'm using (Mozilla/5.0 (X11; U; Linux i686; en-US; 
rv:1.1) Gecko/20020826). I thought that there were instructions for 
setting up the browser for help.start() in the Mandrake-Readme.txt at 
<http://www.cran.r-project.org/>, but that seems to be gone now (or 
perhaps I am mistaken that it was ever there?).

Please can you tell me where to find the setup to specify netscape as 
the browser that R uses? I want to keep mozilla as my primary browser.

Best fishes

Sam
-- 
Sam McClatchie, Research scientist (fisheries acoustics))))))))))
NIWA (National Institute of Water & Atmospheric Research Ltd)
PO Box 14 901, Kilbirnie, Wellington, New Zealand
s.mcclatchie at niwa.cri.nz
Research home page <http://www.smcc.150m.com/>
                       /\
            >><xX(&>
                    /// \\\
                   //// \\\\
                  ///  <%)Xx><<
                 /////  \\\\\\
           ><(((@>
     ><(((%>     ..>><xX(?>O<?)Xx><<



From gwgilc at wm.edu  Thu Jan 16 23:20:03 2003
From: gwgilc at wm.edu (George W. Gilchrist)
Date: Thu Jan 16 23:20:03 2003
Subject: [R] polynomial contrasts in R
Message-ID: <NDBBJNBCJEKIFKKLDLNGKEKFEAAA.gwgilc@wm.edu>

In S-Plus, I can obtain polynomial contrasts for an ordered factor with
contr.poly(). The function also exists in R, however is limited to factors
where the levels are equally spaced. In S-Plus, one can obtain the contrasts
for a set of numeric values representing unequally spaced ordered factors.
Has anyone implemented this in R? I see that the S-Plus function calls
another function (poly.raw()) that calls a Fortran routine. Thanks for your
assistance.

Cheers, George

==================================================================
George W. Gilchrist                        Email #1: gwgilc at wm.edu
Department of Biology, Box 8795          Email #2: kitesci at cox.net
College of William & Mary                    Phone: (757) 221-7751
Williamsburg, VA 23187-8795                    Fax: (757) 221-6483



From vograno at arbitrade.com  Thu Jan 16 23:53:03 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Thu Jan 16 23:53:03 2003
Subject: [R] controlling number of iterations in avas
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DCB2@jupiter.arbitrade.com>

Dear R-Users,

Is there a way to directly set a limit to the number of iterations in
avas()? I am aware of delrsq argument, but I've found it difficult to use
since its effect on computation time is hard to predict. For example with
the default delrsq=0.01 a single iteration took ~2min to complete. When I
used delrsq=0.001 it didn't complete in an hour.

Thanks, Vadim

-------------------------------------------------- 
DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]



From liuwensui at hotmail.com  Fri Jan 17 00:12:03 2003
From: liuwensui at hotmail.com (wensui liu)
Date: Fri Jan 17 00:12:03 2003
Subject: [R] (no subject)
Message-ID: <DAV13EBtKarvzr0dSHp00007a6d@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030117/70734877/attachment.pl

From deho at fas.harvard.edu  Fri Jan 17 00:22:03 2003
From: deho at fas.harvard.edu (Daniel En-Wenn Ho)
Date: Fri Jan 17 00:22:03 2003
Subject: [R] (no subject)
In-Reply-To: <DAV13EBtKarvzr0dSHp00007a6d@hotmail.com>
Message-ID: <Pine.OSF.4.44.0301161820160.12256-100000@is08.fas.harvard.edu>

As I was kindly informed some time ago by others, try the xtable package
available at CRAN.

Dan

daniel_ho at harvard.edu


On Thu, 16 Jan 2003, wensui liu wrote:

> Dear R-users,
>
> Is there any method that can transfer the R output to latex?
>
> Thanks.
>
> wensui
>
> 	[[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From forporphyry at hotmail.com  Fri Jan 17 00:31:03 2003
From: forporphyry at hotmail.com (graham lawrence)
Date: Fri Jan 17 00:31:03 2003
Subject: [R] (no subject)
Message-ID: <F171rvDOv5y4FypKsEg00000703@hotmail.com>



Dear R-help,

Why does the second grep reject when the first grep accepts?
Why does regexpr accept what grep rejects?

>eqtn
[1] "(1.2*A%*%B)/2"
>if(grep("A\\%\\*\\%B",eqtn)==1)erind<-1
>if(grep("A\\%\\*\\%A",eqtn)==1)erind<-1
Error in if (grep("A\\%\\*\\%A", eqtn) == 1) erind <- 1 :
        missing value where logical needed
>if(regexpr("A\\%\\*\\%A",eqtn)==1)erind<-1
>

TIA

graham lawrence



From kjetil at entelnet.bo  Fri Jan 17 00:58:46 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri Jan 17 00:58:46 2003
Subject: [R] polynomial contrasts in R
In-Reply-To: <NDBBJNBCJEKIFKKLDLNGKEKFEAAA.gwgilc@wm.edu>
Message-ID: <3E270E95.15599.11B950B@localhost>

On 16 Jan 2003 at 17:19, George W. Gilchrist wrote:

> In S-Plus, I can obtain polynomial contrasts for an ordered factor with
> contr.poly(). The function also exists in R, however is limited to factors
> where the levels are equally spaced. In S-Plus, one can obtain the contrasts
> for a set of numeric values representing unequally spaced ordered factors.
> Has anyone implemented this in R? I see that the S-Plus function calls
> another function (poly.raw()) that calls a Fortran routine. Thanks for your
> assistance.
> 

This can be done "by hand" easily in R. From some notes of mine:

dummy <- poly(c(1,2,3,5), 3)
   dimnames(dummy) <- list(c(1,2,3,5), c(".L", ".Q", ".C"))
    # orthogonal polinomial over the set {1,2,3,5}

   muscles$Ltreat <- C(muscles$Ltreat, dummy, 3)
   
   dummy <- poly(c(1,3,6), 2)
   dimnames(dummy) <- list(c(1,3,6), c(".L", ".Q"))
   muscles$Ntreat <- C(muscles$Ntreat, dummy, 2)

Kjetil Halvorsen



> Cheers, George
> 
> ==================================================================
> George W. Gilchrist                        Email #1: gwgilc at wm.edu
> Department of Biology, Box 8795          Email #2: kitesci at cox.net
> College of William & Mary                    Phone: (757) 221-7751
> Williamsburg, VA 23187-8795                    Fax: (757) 221-6483
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From fjmolina at lbl.gov  Fri Jan 17 01:53:02 2003
From: fjmolina at lbl.gov (Francisco J Molina)
Date: Fri Jan 17 01:53:02 2003
Subject: [R] C++ and R
Message-ID: <15911.21442.166834.45108@0-e0-98-8a-c5-4a.dhcp.lbl.gov>

I am using a C++ routine that is called from R. In this routine I allocate memory
dynamically with new. It is necessary to use delete before the routine returns?

It seems to me that it is not necessary. Anyone knows?



From yanyu at cs.ucla.edu  Fri Jan 17 03:51:03 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Fri Jan 17 03:51:03 2003
Subject: [R] check variables: a Q from a beginner
In-Reply-To: <4.2.0.58.20030116094149.00af2b80@162.38.183.200>
Message-ID: <Pine.SOL.4.33.0301161849220.27316-100000@panther.cs.ucla.edu>

THank you for the infomation.
They all work great!
yan

On Thu, 16 Jan 2003, Emmanuel Paradis wrote:

> A 20:24 15/01/2003 -0800, Roger Peng a écrit:
> >You may want to just try summary(varname) or more likely you want
> >str(varname).
>
> Or even better: ls.str(), which does str() on all objects listed by ls().
>
>
> >-roger
> >_______________________________
> >UCLA Department of Statistics
> >rpeng at stat.ucla.edu
> >http://www.stat.ucla.edu/~rpeng
> >
> >On Wed, 15 Jan 2003, Yan Yu wrote:
> >
> > > HI, all,
> > > How can i check the variables that is currently being loaded..
> > > ls() only list the variable name, but not the summary of the variable,
> > > like the dimension of the variable etc.. Is there a command in R, which
> > > is equivalent to "whos" in matlab, which let me check the variables
> > > currently loaded in Matlab..
>
> If you have highly structured objects, try this: ls.str(max.level = -1).
>
> > > also, Does anyone have recommendation on ~a good reference to R..
> > > I could not find the answer to my Q in the documentation included with R
> > > package..
> > >
>
> You may have a look at my tutorial "R for beginners" though it is far from
> a reference doc it mentions ls.str() among the few things to know before
> starting. You can find it in the contributed docs section on CRAN.
>
> Hope this helps.
>
> Emmanuel Paradis
>
> >
> > > thanks,
> > > yan
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From yanyu at cs.ucla.edu  Fri Jan 17 06:07:03 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Fri Jan 17 06:07:03 2003
Subject: [R] kriging in R
Message-ID: <Pine.SOL.4.33.0301162055240.485-100000@panther.cs.ucla.edu>

Hi, all,
   Have anyone used kringing included in R?  How is it?
Does it handle anisotropy data well?
How does it compare with Kriging in Arc/Info? or other geostatistics
software customized to do kriging or other geostatistics functions?

I tried Easykriging, a geostatistics tool developed for Matlab. It has
very nice GUI, but it does not provide library which i can call in my programs.
so it is good for doing it mannually for small number of data set. but if
i have large number of data set, and i want to automate the kriging
process for those data set, Does anyone have good recommendation on what
software to use?  something that can be called in c/c++ code(or matlab)
and freeware:) is preferred..

Thanks a lot in advance for any input.
yan



From butje612 at student.otago.ac.nz  Fri Jan 17 06:43:03 2003
From: butje612 at student.otago.ac.nz (Jeremy Butler)
Date: Fri Jan 17 06:43:03 2003
Subject: [R] barplot plotting problem
Message-ID: <3.0.1.32.20030117184156.00d81530@studentmail.otago.ac.nz>

Hi,
Is there any equivalent of type="n" when constructing barplots which will
still construct the axes (plot=F, as it says doesn' plot anything at all).
Alternatively I tried setting col="white" and border="white" but the border
command does not seem to be operational. True??

Any other ideas? What I'm actually trying to do is construct vertical
abline()'s _behind_ my plotted data. It seems to me that this requires axes
construction then abline plotting then data plotting. Fine for plot() etc.
but I don't seem to be able to manage it when barplotting. Is there some
other way to do this that I'm missing?
Cheers, Jeremy

***************************************************************************
Jeremy Zachariah Butler BSc(hons)
Department of Geography		phone:	64 3 479 8788
University of Otago		fax:	64 3 479 8706
Te Whare Wananga o Otago	e-mail: butje612 at student.otago.ac.nz
P.O. Box 56, Dunedin			jerrytheshrub at hotmail.com
New Zealand				jeremybutler at paradise.net.nz
***************************************************************************



From yanyu at cs.ucla.edu  Fri Jan 17 07:16:03 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Fri Jan 17 07:16:03 2003
Subject: [R] nls
Message-ID: <Pine.SOL.4.33.0301162210470.485-100000@panther.cs.ucla.edu>

HI,
i have some prob when i try to use nls().
my data is 1D vector, I tried to use a polynomial function(order is 3) to
fit it.
the data series is stored in x.
the a0, a1, a2, a3 below is coefficient, which i  hope i can get from
calls "nls"

> z <-  nls(  ~ a0 + a1 * x + a2 * x * x + a3 * x * x * x, data = x )
Error in match.call(definition, call, expand.dots) :
	.Primitive... is not a function

Any idea on what is the problem?

many thanks,
yan



From ripley at stats.ox.ac.uk  Fri Jan 17 08:54:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 17 08:54:02 2003
Subject: [R] help.start() setup with netscape
In-Reply-To: <3E272D19.60209@niwa.cri.nz>
Message-ID: <Pine.LNX.4.44.0301170747380.2578-100000@gannet.stats>

options(browser="netscape"), e.g. in R_HOME/etc/environ, or just call
help.start(browser="netscape"): this is all in ?help.start.

Note the issue is how you set up the Java plugin: search the archives for
hints (which were to look on the mozilla release notes archive, as I 
recall).  Mozilla 1.1 can I believe be made to work if some link is added.

On Fri, 17 Jan 2003, Sam McClatchie wrote:

> System info:
> Mandrake 9.0
> R Version 1.6.1
> ESS 5.1.21
> Emacs 21.2.1
> -------------------
> 
> Colleagues
> 
> I understand that help.start() search function works with netscape and 
> although it may also work with latest versions of mazilla it doesn't 
> seem to with the one I'm using (Mozilla/5.0 (X11; U; Linux i686; en-US; 
> rv:1.1) Gecko/20020826). I thought that there were instructions for 
> setting up the browser for help.start() in the Mandrake-Readme.txt at 
> <http://www.cran.r-project.org/>, but that seems to be gone now (or 
> perhaps I am mistaken that it was ever there?).
> 
> Please can you tell me where to find the setup to specify netscape as 
> the browser that R uses? I want to keep mozilla as my primary browser.
> 
> Best fishes
> 
> Sam
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan 17 09:00:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 17 09:00:04 2003
Subject: [R] polynomial contrasts in R
In-Reply-To: <NDBBJNBCJEKIFKKLDLNGKEKFEAAA.gwgilc@wm.edu>
Message-ID: <Pine.LNX.4.44.0301170754160.2578-100000@gannet.stats>

You are wrong about S-PLUS!  contr.poly only takes as argument the number 
of levels required (and uses pre-computed sets for up to 12 levels).
You get orthogonal polynomials for equally-space values from contr.poly in 
both systems, as documented.

I don't think you are describing contrasts for an ordered factor, but 
orthogonal polynomials in a numeric variable.  The latter are computed by 
the function poly() in both R and S-PLUS.  You could set them up to give a 
contrasts matrix if you want, but not a contrasts function (as that is 
only passed the number of levels, AFAIR).

On Thu, 16 Jan 2003, George W. Gilchrist wrote:

> In S-Plus, I can obtain polynomial contrasts for an ordered factor with
> contr.poly(). The function also exists in R, however is limited to factors
> where the levels are equally spaced. In S-Plus, one can obtain the contrasts
> for a set of numeric values representing unequally spaced ordered factors.
> Has anyone implemented this in R? I see that the S-Plus function calls
> another function (poly.raw()) that calls a Fortran routine. Thanks for your
> assistance.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan 17 09:07:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 17 09:07:03 2003
Subject: if(grep(...) == 1) was [R] (no subject)
In-Reply-To: <F171rvDOv5y4FypKsEg00000703@hotmail.com>
Message-ID: <Pine.LNX.4.44.0301170801010.2578-100000@gannet.stats>

On Thu, 16 Jan 2003, graham lawrence wrote:

> Why does the second grep reject when the first grep accepts?
> Why does regexpr accept what grep rejects?

It's the if() that is different.  grep returns an integer vector of 
matching indices, and numeric(0) == 1 is logical(0), which gives nothing 
to test (and I guess the error message could be improved),
The idiom often is if(length(grep(...))).

regexpr returns something for each match, but I suspect you want to test 
> 0, not ==1.  See the help page.

> >eqtn
> [1] "(1.2*A%*%B)/2"
> >if(grep("A\\%\\*\\%B",eqtn)==1)erind<-1
> >if(grep("A\\%\\*\\%A",eqtn)==1)erind<-1
> Error in if (grep("A\\%\\*\\%A", eqtn) == 1) erind <- 1 :
>         missing value where logical needed
> >if(regexpr("A\\%\\*\\%A",eqtn)==1)erind<-1

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan 17 09:15:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 17 09:15:04 2003
Subject: [R] kriging in R
In-Reply-To: <Pine.SOL.4.33.0301162055240.485-100000@panther.cs.ucla.edu>
Message-ID: <Pine.LNX.4.44.0301170808440.2578-100000@gannet.stats>

Lots of questions!  Kriging in geostatistics software often uses rather 
peculiar approximations to the exact theory, and `data' cannot be
anisotropic (but models can).

There is kriging in packages spatial, sgeostat and fields, at least, as a 
quick look at the FAQ would have shown you.

It is unlikely that an R package will provide you with C/C++ code that is 
independent, but some are based on such code.  If you want independent 
code, you should look elsewhere (e.g. GSLIB).

On Thu, 16 Jan 2003, Yan Yu wrote:

> Hi, all,
>    Have anyone used kringing included in R?  How is it?
> Does it handle anisotropy data well?
> How does it compare with Kriging in Arc/Info? or other geostatistics
> software customized to do kriging or other geostatistics functions?
> 
> I tried Easykriging, a geostatistics tool developed for Matlab. It has
> very nice GUI, but it does not provide library which i can call in my programs.
> so it is good for doing it mannually for small number of data set. but if
> i have large number of data set, and i want to automate the kriging
> process for those data set, Does anyone have good recommendation on what
> software to use?  something that can be called in c/c++ code(or matlab)
> and freeware:) is preferred..
> 
> Thanks a lot in advance for any input.
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Roger.Bivand at nhh.no  Fri Jan 17 09:22:03 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri Jan 17 09:22:03 2003
Subject: [R] kriging in R
In-Reply-To: <Pine.SOL.4.33.0301162055240.485-100000@panther.cs.ucla.edu>
Message-ID: <Pine.LNX.4.44.0301170909080.19756-100000@reclus.nhh.no>

On Thu, 16 Jan 2003, Yan Yu wrote:

> Hi, all,
>    Have anyone used kringing included in R?  How is it?
> Does it handle anisotropy data well?
> How does it compare with Kriging in Arc/Info? or other geostatistics
> software customized to do kriging or other geostatistics functions?

Maybe help.search(), or the search item at the R-project website? The
following packages (among others) include kriging in some form or other.
The spatial package in the VR bundle is installed by default. The sgeostat
package is interpreted. Both of fields and geoR are compiled - so there's
no lack of choice!

Comparison with recent Arc/Info is more difficult, the work being done
there by Konstantin Krivoruchko and others is impressive. Maybe try
several R packages and AI on the same real data to get a feel for how they
perform in relation to your needs? The resources on 
http://www.ai-geostats.org/ may also help.

> 
> I tried Easykriging, a geostatistics tool developed for Matlab. It has
> very nice GUI, but it does not provide library which i can call in my programs.
> so it is good for doing it mannually for small number of data set. but if
> i have large number of data set, and i want to automate the kriging
> process for those data set, Does anyone have good recommendation on what
> software to use?  something that can be called in c/c++ code(or matlab)
> and freeware:) is preferred..
> 

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From Ted.Harding at nessie.mcc.ac.uk  Fri Jan 17 10:42:03 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri Jan 17 10:42:03 2003
Subject: [R] Multivariate regression in R [followup]
In-Reply-To: <XFMail.030116202901.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.030117090946.Ted.Harding@nessie.mcc.ac.uk>

On 16-Jan-03 Ted Harding wrote:
> Hence the multivariate regression model for the data could be
> written in matrix form as
> 
>   Y = X*B + w1*W1 + w2*W2 + w3*W3 + e
> 
[ Y Nxp ; X Nxk ; W1 W2 W3 Nxp matices of factor level indicators;
  B kxp ; w1, w2, w3 scalars ]

> where e is 3-dim N(0,S), and B, w1, w2, w3 and S are to be estimated.
> 
> What, in R, I can't make out how to do is to give some function
> (which function?) a model specification of the form
> 
>   Y ~ X + W1 + W2 + W3
> 
> but in such a way that it will fit a 2x3 matrix B of coefficients for
> X, but scalar coefficients w1, w2, w3 for W1, W2, W3

I think the thought underlying my query was that, if R would accept
designating a _matrix_ of factor levels as a factor while preserving
its matrix structure, then the above could fit into the model
specification scheme. However, factor(W1), for instance, returns
a linear structure.

Apologies for the typo originally in the formula below (now corrected):

> Analytically, the log-likelihood can be written (summing over r)
> 
>   (-N/2)*log(det(S)) - 0.5*SUM[ e_r * S^(-1) * e_r' ] (e_r = rth row)
> 
> where e = Y - B*X - w1*W1 - w2*W2 - w3*W3. After differentiation and
> algebra, one could implement the resulting matrix equations in octave
> (or matlab) and proceed to a solution. One could even do this, as a
> numerical procedure, in R -- but I'd rather not! Indeed, R's richness
> in model-fitting resources tempts one to think that this problem may
> be solvable using these -- it's just that I can't seem to put my hand
> on what's needed.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 17-Jan-03                                       Time: 09:09:46
------------------------------ XFMail ------------------------------



From ernesto at ipimar.pt  Fri Jan 17 10:59:02 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Fri Jan 17 10:59:02 2003
Subject: [R] kriging in R
In-Reply-To: <Pine.SOL.4.33.0301162055240.485-100000@panther.cs.ucla.edu>
References: <Pine.SOL.4.33.0301162055240.485-100000@panther.cs.ucla.edu>
Message-ID: <1042797650.2511.8.camel@gandalf.ipimar.pt>

Hi

I'm working with geostatistics and I use geoR package, which I find very
good. However it doesn't implement the classic geostatistics but a
"model based geostatistics" as proposed by Peter Diggle and team.

R news of June 2001 has an article about geoR by Paulo Ribeiro, the main
developer, that you might like to take a look at. I find this number of
Rnews a very good source for someone willing to use geostatistics in R.

Regards

EJ
 
On Fri, 2003-01-17 at 05:06, Yan Yu wrote:
> Hi, all,
>    Have anyone used kringing included in R?  How is it?
> Does it handle anisotropy data well?
> How does it compare with Kriging in Arc/Info? or other geostatistics
> software customized to do kriging or other geostatistics functions?
> 
> I tried Easykriging, a geostatistics tool developed for Matlab. It has
> very nice GUI, but it does not provide library which i can call in my programs.
> so it is good for doing it mannually for small number of data set. but if
> i have large number of data set, and i want to automate the kriging
> process for those data set, Does anyone have good recommendation on what
> software to use?  something that can be called in c/c++ code(or matlab)
> and freeware:) is preferred..
> 
> Thanks a lot in advance for any input.
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
Research Institute for Agriculture and Fisheries
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948



From d.orme at imperial.ac.uk  Fri Jan 17 11:05:06 2003
From: d.orme at imperial.ac.uk (David Orme)
Date: Fri Jan 17 11:05:06 2003
Subject: [R] Using R to analyze chromatograms
Message-ID: <1263F994-2A03-11D7-9C47-000393DC1748@ic.ac.uk>

Hi,

I have a large number of high performance liquid chromatography (HPLC) 
datafiles that I was hoping to process using R. I couldn't find 
anything in the mailing list archives or the packages list but before I 
go around reinventing the wheel, has anyone on the list got any 
pointers or code they are willing to share for identifying peaks, 
fitting a baseline and calculating peak areas?

Many thanks,

David Orme

----------------------------------------
Dr. David Orme

Department of Biological Sciences,
Imperial College London,
Silwood Park Campus,
Ascot, Berkshire.
SL5 7PY

Phone: +44 (0)20 759 42358
e-mail: d.orme at imperial.ac.uk



From maechler at stat.math.ethz.ch  Fri Jan 17 11:27:03 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Jan 17 11:27:03 2003
Subject: [R] Trellis device automatism [was "X11 device now needs ..?"]
In-Reply-To: <200301161520.20469.deepayan@stat.wisc.edu>
References: <20030116013500.GG21374@hortresearch.co.nz>
	<200301152247.41729.deepayan@stat.wisc.edu>
	<20030116201047.GL21374@hortresearch.co.nz>
	<200301161520.20469.deepayan@stat.wisc.edu>
Message-ID: <15911.55911.998303.326029@gargle.gargle.HOWL>

>>>>> "Deepayan" == Deepayan Sarkar <deepayan at stat.wisc.edu>
>>>>>     on Thu, 16 Jan 2003 15:20:20 -0600 writes:

    Deepayan> On Thursday 16 January 2003 02:10 pm, Patrick Connolly wrote:
    >> On Wed, 15-Jan-2003 at 10:47PM -0600, Deepayan Sarkar wrote:
    >> |> On Wednesday 15 January 2003 07:35 pm, Patrick Connolly wrote:

    R version 1.6.2

    >> |> > Until this version, I've not had to explicitly start the x11 device.
    >> |> > Now, (at least with lattice plots), one is not automatically started
    >> |>
    >> |> Could you explain ? There's sometimes a warning, but I haven't seen
    >> |> the device not being opened.
    >> 
    >> On closer inspection, I see that it falls over earlier than the
    >> plotting itself.  It arises when I attempt to adjust some trellis
    >> settings.  This is the message:
    >> 
    >> Error in trellis.par.set(y, x) : No device is currently Active
    >> 
    >> 
    >> I notice that trellis.par.set has been changed this time.
    >> 
    >> "trellis.par.set" <-
    >> function (name, value, warn = TRUE)
    >> {
    >>  if (!is.list(value))
    >>     stop("value must be a list")
    >>  if (warn && is.null(dev.list()))
    >>     stop("No device is currently Active")
    >>  lattice.theme[[.Device]][[name]] <<- value
    >> }
    >> 
    >> 
    >> Previously, it had been only the last line.
    >> 
    >> The problem arises because dev.list() returns NULL if no device is
    >> open and thus the call to stop().
    >> 
    >> I don't know whether it would be a good idea to have trellis.par.set
    >> start the default device.
    >> 
    >> Ideas?

    Deepayan> Personally, I don't have any strong preferences,
    Deepayan> other than that the old behaviour (which silently
    Deepayan> did nothing, if I remember correctly) should be
    Deepayan> changed. Maybe we should go with S-PLUS behaviour,
    Deepayan> which gives an error if trellis.par.set() is
    Deepayan> called without an open device, but DOES start the
    Deepayan> default device if trellis.par.get() is
    Deepayan> called. This would mean that lset() would also
    Deepayan> start the device.

    Deepayan> Does that sound OK ?

partially.  I would provide this *at least*

Couldn't you even do more automatism, namely, start the default
device even for trellis.par.set().
This would be "compatible" with a non-lattice graphics call of
both
   par("<name>")    [ ~= trellis.par.get(.) ]    and
   par(<name> = ..) [ ~= trellis.par.set(.) ]    

no?

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From p.dalgaard at biostat.ku.dk  Fri Jan 17 12:25:06 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 17 12:25:06 2003
Subject: [R] polynomial contrasts in R
In-Reply-To: <Pine.LNX.4.44.0301170754160.2578-100000@gannet.stats>
References: <Pine.LNX.4.44.0301170754160.2578-100000@gannet.stats>
Message-ID: <x2of6gqaqx.fsf@biostat.ku.dk>

ripley at stats.ox.ac.uk writes:

> I don't think you are describing contrasts for an ordered factor, but 
> orthogonal polynomials in a numeric variable.  The latter are computed by 
> the function poly() in both R and S-PLUS.  You could set them up to give a 
> contrasts matrix if you want, but not a contrasts function (as that is 
> only passed the number of levels, AFAIR).

[Pet peeve] However, contr.poly *also* treats the factor as a numeric
variable, it just assumes that the levels are equidistant. What other
sense would a (say) linear term make? Helmert contrasts (if they are
useful anywhere...) or successive differences would have been more
relevant for ordered factors, but for some reason S-PLUS chose
differently and R has kept the same convention for ordered factors
although we did depart from S-PLUS's use of Helmert contrasts for
unordered factors.

Contrast functions are called with "..." it seems, but not the object
itself, so if a factor has numeric levels, you could potentially have
something like

f.p <- C(f, contr.xpoly, x=as.numeric(levels(f)))

but you do need the extra argument and it is hardly better than

x <- as.numeric(levels(f))
f.p <- C(f, poly(x, degree=length(x)-1))



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Fri Jan 17 12:43:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 17 12:43:03 2003
Subject: [R] polynomial contrasts in R
In-Reply-To: <x2of6gqaqx.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0301171133080.6001-100000@gannet.stats>

On 17 Jan 2003, Peter Dalgaard BSA wrote:

> ripley at stats.ox.ac.uk writes:
> 
> > I don't think you are describing contrasts for an ordered factor, but 
> > orthogonal polynomials in a numeric variable.  The latter are computed by 
> > the function poly() in both R and S-PLUS.  You could set them up to give a 
> > contrasts matrix if you want, but not a contrasts function (as that is 
> > only passed the number of levels, AFAIR).
> 
> [Pet peeve] However, contr.poly *also* treats the factor as a numeric
> variable, it just assumes that the levels are equidistant. What other
> sense would a (say) linear term make? 

Not quite, it allocates scores to the factor levels, equally spaced 
scores.  The assumption is that is the best scoring you have for ordered 
factors (and nothing else known about them).

> Helmert contrasts (if they are
> useful anywhere...) or successive differences would have been more
> relevant for ordered factors, but for some reason S-PLUS chose
> differently and R has kept the same convention for ordered factors
> although we did depart from S-PLUS's use of Helmert contrasts for
> unordered factors.

Several `by default's are needed in there.

> Contrast functions are called with "..." it seems, but not the object
> itself, so if a factor has numeric levels, you could potentially have
> something like
> 
> f.p <- C(f, contr.xpoly, x=as.numeric(levels(f)))
> 
> but you do need the extra argument and it is hardly better than
> 
> x <- as.numeric(levels(f))
> f.p <- C(f, poly(x, degree=length(x)-1))

That's only relevant to C(), I believe. But contrast functions (as set by
options(contrasts=) or via the constrasts(.arg) argument of model-fitting
functions) are called by model.matrix.default() without such an argument.  
(And in the functions contrasts().)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Fri Jan 17 13:04:02 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri Jan 17 13:04:02 2003
Subject: [R] Built-in R GUI type features
In-Reply-To: <D45BC82E21E16149AC5A3F706350626401953A60@usrymx14.merck.com>
References: <D45BC82E21E16149AC5A3F706350626401953A60@usrymx14.merck.com>
Message-ID: <dvrf2v8nqsais7samegl13cvk2r2q7v7ht@4ax.com>

On Thu, 16 Jan 2003 08:40:14 -0500, you wrote:

>All:
>
>The select.list() command brings up a "modal dialog box with a (scrollable)
>list of items ..." etc. -- i.e., a GUI control. I also know about winDialog,
>file.choose and the winMenu commands. What other such GUIisms are built into
>** base ** R (I know about the tcltk package)? Or, better yet, how can I
>search on or list them?

I think you've found all of them.

There's no keyword that picks out those specifically.  They tend to be
documented under the keyword "utilities", and a search of help for the
word "Windows" will turn them up.

If you want to be sure to find all the Windows-specific functions, I
think the only way is to look at the source:  go to
src/library/base/R/windows for the R code, and
src/library/base/man/windows for the documentation.

Duncan Murdoch



From kjetil at entelnet.bo  Fri Jan 17 13:25:05 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri Jan 17 13:25:05 2003
Subject: [R] nls
In-Reply-To: <Pine.SOL.4.33.0301162210470.485-100000@panther.cs.ucla.edu>
Message-ID: <3E27BD98.18046.1C718E@localhost>

On 16 Jan 2003 at 22:15, Yan Yu wrote:

> HI,
> i have some prob when i try to use nls().
> my data is 1D vector, I tried to use a polynomial function(order is 3) to
> fit it.
> the data series is stored in x.
> the a0, a1, a2, a3 below is coefficient, which i  hope i can get from
> calls "nls"
> 
> > z <-  nls(  ~ a0 + a1 * x + a2 * x * x + a3 * x * x * x, data = x )

You haven't given a response in the formula? nls could possibly give 
a more informative error message.

Kjetil Halvorsen



> Error in match.call(definition, call, expand.dots) :
> 	.Primitive... is not a function
> 
> Any idea on what is the problem?
> 
> many thanks,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dvumani at hotmail.com  Fri Jan 17 13:29:06 2003
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Fri Jan 17 13:29:06 2003
Subject: [R] Re: Universal legend in plot
Message-ID: <F141nGFU7KgX3x1eQP70000fa9e@hotmail.com>

Dear R-users:

I asked a question on how I can have a universal legend in a plot and 
received the following result. I tried using "layout" but I can't seem to 
work on the "empty" plot (where I have to have the legend). I tried "oma" 
but I couldn't improve the quality of the plot, and that I didn't know how 
to specify all the line types using the keyboard, infact it is line type 4 
(I had _._ and it didn't look nice).

#
I am trying to create a graph with 6 panels, but would like to have a 
universal legend as each panel merely denotes a separate stratum. The legend 
has to be at the bottom.

I use "par(mfrow=c(2,3))" to get the panels, but am not sure how to put the 
legend below the whole graph.

Thanking you as always

############
J.R. Lockwood

I don't think you can do this without

layout()

which you can use to create a separate graphical area within the plot
region, where you can put the legend.

i could be wrong though
############
Peter Dalgaard

You need to look at mtext(....,outer=TRUE), plus par(oma=....) to make
room for the text in the outer margins.
############
Try layout() for finer adjustments (and some drawbacks).
See ?layout how to set up a 7th figure (legend) of full with below the 
desired six other figures.

Uwe Ligges



From mdeasnds at fs1.ser.man.ac.uk  Fri Jan 17 13:39:03 2003
From: mdeasnds at fs1.ser.man.ac.uk (Neil Shephard)
Date: Fri Jan 17 13:39:03 2003
Subject: [R] More info - S-Plus compatability
Message-ID: <3E27F92A.28245.C8EDED@localhost>

Dear all,

Thanks to those of you who have replied, the majority of the 
comments pointed out that the error caused by scan may originate 
from another function, and closer inspection of the output from 
traceback() reveals that it is in fact the read.table function where 
the error is originating from the full output of which I have included 
below.

The error msg I recieve is 

Error in scan(file = file, what = what, sep = sep, quote = quote, dec 
= dec, :
line 1 did not have 2 elements
Execution halted.

traceback()

8: scan(file=file, what=what, sep = sep, quote = quote, dec = dec, 
nmax = nrows, skip =0, na.strings, quiet = TRUE, fill = fill, 
strip.white = strip.white, nlak.lines.skip = blank.lines.skip, 
multi.line = FLASE, comment.char = comment.char)
7: read.table("_data\\TempFile, sep = ",", col.names = c("pair1", 
"pair2"))
6:ReadIBD.data("ibd.out")
5:RunGH(dat)
4:Read.Data(dat, x, HRallele)
3:eval.with.vis(expr, envir, enclos)
2:eval.with.vis(ei, envir)
1:source("TrendTest.Main.SSC")

grep -e 'read.table; *.SSC

indicates that the read.table() function is called in ReadIBD.SSC on 
lines seven and  twelve, and that the error is occuring with the 
second read.table() where the file '_Data\\TempFile' is being read 
(see copy of ReadIBD.data.SSC below).

ReadIBD.data_function(file) {
	
### Funtion to read the IBD probability data from GENEHUNTER 
### This data was generated from using "Dump IBD" command in 
GENEHUNTER
### File = ibd.out file from genehunter
	
	temp_read.table(file, skip=1, col.names=c("pos","pedid", "pair", 
		"prior.c0", "prior.c1", "prior.c2", "post.c0", "post.c1", 
"post.c2"), 
		row.names=NULL)

	write.table(temp$pair,file="_Data\\TempFile")		
	pairTemp_read.table("_Data\\TempFile", sep=",", 
col.names=c("pair1","pair2"))
	
	ibd_cbind.data.frame(temp,pairTemp)
	return(ibd)
}


Whilst not overly familiar with R/S-Plus syntax there are a couple 
of things I've noticed, firstly the second file that is trying to be read 
(where the error occurs) is actually called '_Data\TempFile' instead 
of '_Data\\TempFile'.  Secondly the columns do not appear to be 
seperated by "," as indicated in the read.table() statement, the 
numbers are encapsulated by "" and are seperated by blank space 
as shown in the sample below.

"x"
"1" "1,2"
"2" "1,3"
"3" "1,4"
..
..

I now have the problem of trying to workout why the "x" occurs on 
the first row (as this is clearly where the error is occuring as the 
Error statement indicates "line 1 did not have 2 elements").

grep -e '_Data' *.SSC

reveals that the _Data\\TempFile is created on the previous line of 
ReadIBD.Data.SSC after having read the file 'ibd.out'.  So I'm not 
sure why the first line is being created with "x" on the first line as 
the 'ibd.out' file is the correct format (I checked this visually).  It 
may be a problem with the way in which the 'ibd.out' file is being 
read by R that is causing this, but I'm not sure.

Can anyone see any potential problems with the read.table() and 
write.table() functions in the above script file???

Thanks again to all who offered help, and in anticipation of 
responses to this msg,

Regards

Neil

Neil Shephard
Genetics Statistician
ARC Epidemiology Unit, University of Manchester
neil.shephard at man.ac.uk
neil.shephard at mindless.com

"Contrariwise, if it was so, it might be; and if it
were so it would be; but as it isn't, it ain't. That's
logic" - Tweedledee (Alice Through the Looking Glass)



From p.dalgaard at biostat.ku.dk  Fri Jan 17 13:44:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 17 13:44:02 2003
Subject: [R] polynomial contrasts in R
In-Reply-To: <Pine.LNX.4.44.0301171133080.6001-100000@gannet.stats>
References: <Pine.LNX.4.44.0301171133080.6001-100000@gannet.stats>
Message-ID: <x2k7h4q741.fsf@biostat.ku.dk>

ripley at stats.ox.ac.uk writes:

> > [Pet peeve] However, contr.poly *also* treats the factor as a numeric
> > variable, it just assumes that the levels are equidistant. What other
> > sense would a (say) linear term make? 
> 
> Not quite, it allocates scores to the factor levels, equally spaced 
> scores.  The assumption is that is the best scoring you have for ordered 
> factors (and nothing else known about them).

...which is a metaphysical argument at best. The alternative is to say
that you should use contrasts that do not depend on *any* scoring.
 
> > Helmert contrasts (if they are
> > useful anywhere...) or successive differences would have been more
> > relevant for ordered factors, but for some reason S-PLUS chose
> > differently and R has kept the same convention for ordered factors
> > although we did depart from S-PLUS's use of Helmert contrasts for
> > unordered factors.
> 
> Several `by default's are needed in there.

Agreed.

> > Contrast functions are called with "..." it seems, but not the object
> > itself, so if a factor has numeric levels, you could potentially have
> > something like
> > 
> > f.p <- C(f, contr.xpoly, x=as.numeric(levels(f)))
> > 
> > but you do need the extra argument and it is hardly better than
> > 
> > x <- as.numeric(levels(f))
> > f.p <- C(f, poly(x, degree=length(x)-1))
> 
> That's only relevant to C(), I believe. But contrast functions (as set by
> options(contrasts=) or via the constrasts(.arg) argument of model-fitting
> functions) are called by model.matrix.default() without such an argument.  
> (And in the functions contrasts().)

Yes, that leaves a couple of spots where a contr.xpoly wouldn't be
usable. I wasn't arguing for it; the matrix route is much clearer.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From andreww at cheque.uq.edu.au  Fri Jan 17 13:49:03 2003
From: andreww at cheque.uq.edu.au (Andrew C. Ward)
Date: Fri Jan 17 13:49:03 2003
Subject: [R] Re: Universal legend in plot
Message-ID: <01C2BE79.E581E250.andreww@cheque.uq.edu.au>

Is your data such that it can be restructured into a form amenable to a 
lattice plot, such as xyplot()? In that case, the legend (key in lattice) 
can be placed pretty much anywhere.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



On Friday, January 17, 2003 10:22 PM, Vumani Dlamini 
[SMTP:dvumani at hotmail.com] wrote:
> Dear R-users:
>
> I asked a question on how I can have a universal legend in a plot and
> received the following result. I tried using "layout" but I can't seem to 
> work on the "empty" plot (where I have to have the legend). I tried "oma" 
> but I couldn't improve the quality of the plot, and that I didn't know 
how
> to specify all the line types using the keyboard, infact it is line type 
4
> (I had _._ and it didn't look nice).
>
> #
> I am trying to create a graph with 6 panels, but would like to have a
> universal legend as each panel merely denotes a separate stratum. The 
legend
> has to be at the bottom.
>
> I use "par(mfrow=c(2,3))" to get the panels, but am not sure how to put 
the
> legend below the whole graph.
>
> Thanking you as always
>
> ############
> J.R. Lockwood
>
> I don't think you can do this without
>
> layout()
>
> which you can use to create a separate graphical area within the plot
> region, where you can put the legend.
>
> i could be wrong though
> ############
> Peter Dalgaard
>
> You need to look at mtext(....,outer=TRUE), plus par(oma=....) to make
> room for the text in the outer margins.
> ############
> Try layout() for finer adjustments (and some drawbacks).
> See ?layout how to set up a 7th figure (legend) of full with below the
> desired six other figures.
>
> Uwe Ligges
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Krassimir.Vanguelov at CommerzbankIB.com  Fri Jan 17 13:56:03 2003
From: Krassimir.Vanguelov at CommerzbankIB.com (Vanguelov, Krassimir)
Date: Fri Jan 17 13:56:03 2003
Subject: [R] difference between "external pointer" and "weak reference"
Message-ID: <43714D237FD4D611A8680008C75F30E01462AC@xmx1lonib.lonib.commerzbank.com>

Dear R-help,

Could you tell me where can I read more about the difference between
"external pointer"(EXTPTRSXP) and "weak reference"(WEAKREFSXP) in R and what
were they intended for? 

Regards,

Krassimir Vanguelov 


********************************************************************** 
This is a commercial communication from Commerzbank AG.

This communication is confidential and is intended only for the person to
whom it is addressed.  If you are not that person you are not permitted to
make use of the information and you are requested to notify
<mailto:LONIB.Postmaster at commerzbankib.com> immediately that you have
received it and then destroy the copy in your possession.

Commerzbank AG may monitor outgoing and incoming e-mails. By replying to
this e-mail you consent to such monitoring. This e-mail message and any
attached files have been scanned for the presence of computer viruses.
However, you are advised that you open attachments at your own risk.

This email was sent either by Commerzbank AG, London Branch, or by
Commerzbank Securities, a division of Commerzbank.  Commerzbank AG is a
limited liability company incorporated in the Federal Republic of Germany.
Registered Company Number in England BR001025. Our registered address in
the UK is 23 Austin Friars, London, EC2P 2JD. We are regulated by the
Financial Services Authority for the conduct of investment business in the
UK and we appear on the FSA register under number 124920. 

**********************************************************************



From p.dalgaard at biostat.ku.dk  Fri Jan 17 14:02:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 17 14:02:03 2003
Subject: [R] Re: Universal legend in plot
In-Reply-To: <F141nGFU7KgX3x1eQP70000fa9e@hotmail.com>
References: <F141nGFU7KgX3x1eQP70000fa9e@hotmail.com>
Message-ID: <x2fzrsq69s.fsf@biostat.ku.dk>

"Vumani Dlamini" <dvumani at hotmail.com> writes:

> Dear R-users:
> 
> I asked a question on how I can have a universal legend in a plot and
> received the following result. I tried using "layout" but I can't seem
> to work on the "empty" plot (where I have to have the legend). I tried
> "oma" but I couldn't improve the quality of the plot, and that I
> didn't know how to specify all the line types using the keyboard,
> infact it is line type 4 (I had _._ and it didn't look nice).
> 
> #
> I am trying to create a graph with 6 panels, but would like to have a
> universal legend as each panel merely denotes a separate stratum. The
> legend has to be at the bottom.
> 
> I use "par(mfrow=c(2,3))" to get the panels, but am not sure how to
> put the legend below the whole graph.
> 
> Thanking you as always

Ah, I think I misunderstood what you wanted there. You want to have a
2x3 layout with 5 plots and one empty, just for legend()?

Could you not just do a blank plot (e.g. plot(0,0, type="n", axes=F,
xlab="", ylab="")) and place the legend onto that?

The lty settings are described in help(par). Beware that legend() can
do you in rather badly if you mix numeric and character
specifications.

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Fri Jan 17 14:06:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 17 14:06:03 2003
Subject: [R] More info - S-Plus compatability
In-Reply-To: <3E27F92A.28245.C8EDED@localhost>
Message-ID: <Pine.LNX.4.44.0301171252460.6151-100000@gannet.stats>

R's and S-PLUS's write.table functions have different arguments with 
different defaults: discussed in MASS4, for example.  You appear to need 
sep = "," (and FLASE appears to be a typo).  It would be better to use
col.names=FALSE and omit the skip=1.

Three other comments: 

_ is deprecated in both R and S-PLUS, and makes for unreadable code.  
Please don't use it, especially not in postings.

\ needs to be escaped in S/R character strings, hence "\\" is the
character \ (and this *is* in the R FAQ!).

_Data in S-PLUS 4.x (including 2000) is a private directory, and users 
really should not be writing in it like this.  There is a perfectly
good function tempfile() to create temporary files.  Why one needs to 
write out and read back the data is unclear to me.


I would find it much faster to read the FAQs and a good book than to keep
asking for help, but your mileage may vary.  It looks like time would be
better spent learning to do this well rather than learning to replicate
poor S-PLUS code in R.

On Fri, 17 Jan 2003, Neil Shephard wrote:

> Dear all,
> 
> Thanks to those of you who have replied, the majority of the 
> comments pointed out that the error caused by scan may originate 
> from another function, and closer inspection of the output from 
> traceback() reveals that it is in fact the read.table function where 
> the error is originating from the full output of which I have included 
> below.
> 
> The error msg I recieve is 
> 
> Error in scan(file = file, what = what, sep = sep, quote = quote, dec 
> = dec, :
> line 1 did not have 2 elements
> Execution halted.
> 
> traceback()
> 
> 8: scan(file=file, what=what, sep = sep, quote = quote, dec = dec, 
> nmax = nrows, skip =0, na.strings, quiet = TRUE, fill = fill, 
> strip.white = strip.white, nlak.lines.skip = blank.lines.skip, 
> multi.line = FLASE, comment.char = comment.char)
> 7: read.table("_data\\TempFile, sep = ",", col.names = c("pair1", 
> "pair2"))
> 6:ReadIBD.data("ibd.out")
> 5:RunGH(dat)
> 4:Read.Data(dat, x, HRallele)
> 3:eval.with.vis(expr, envir, enclos)
> 2:eval.with.vis(ei, envir)
> 1:source("TrendTest.Main.SSC")
> 
> grep -e 'read.table; *.SSC
> 
> indicates that the read.table() function is called in ReadIBD.SSC on 
> lines seven and  twelve, and that the error is occuring with the 
> second read.table() where the file '_Data\\TempFile' is being read 
> (see copy of ReadIBD.data.SSC below).
> 
> ReadIBD.data_function(file) {
> 	
> ### Funtion to read the IBD probability data from GENEHUNTER 
> ### This data was generated from using "Dump IBD" command in 
> GENEHUNTER
> ### File = ibd.out file from genehunter
> 	
> 	temp_read.table(file, skip=1, col.names=c("pos","pedid", "pair", 
> 		"prior.c0", "prior.c1", "prior.c2", "post.c0", "post.c1", 
> "post.c2"), 
> 		row.names=NULL)
> 
> 	write.table(temp$pair,file="_Data\\TempFile")		
> 	pairTemp_read.table("_Data\\TempFile", sep=",", 
> col.names=c("pair1","pair2"))
> 	
> 	ibd_cbind.data.frame(temp,pairTemp)
> 	return(ibd)
> }
> 
> 
> Whilst not overly familiar with R/S-Plus syntax there are a couple 
> of things I've noticed, firstly the second file that is trying to be read 
> (where the error occurs) is actually called '_Data\TempFile' instead 
> of '_Data\\TempFile'.  Secondly the columns do not appear to be 
> seperated by "," as indicated in the read.table() statement, the 
> numbers are encapsulated by "" and are seperated by blank space 
> as shown in the sample below.
> 
> "x"
> "1" "1,2"
> "2" "1,3"
> "3" "1,4"
> ..
> ..
> 
> I now have the problem of trying to workout why the "x" occurs on 
> the first row (as this is clearly where the error is occuring as the 
> Error statement indicates "line 1 did not have 2 elements").
> 
> grep -e '_Data' *.SSC
> 
> reveals that the _Data\\TempFile is created on the previous line of 
> ReadIBD.Data.SSC after having read the file 'ibd.out'.  So I'm not 
> sure why the first line is being created with "x" on the first line as 
> the 'ibd.out' file is the correct format (I checked this visually).  It 
> may be a problem with the way in which the 'ibd.out' file is being 
> read by R that is causing this, but I'm not sure.
> 
> Can anyone see any potential problems with the read.table() and 
> write.table() functions in the above script file???
> 
> Thanks again to all who offered help, and in anticipation of 
> responses to this msg,
> 
> Regards
> 
> Neil
> 
> Neil Shephard
> Genetics Statistician
> ARC Epidemiology Unit, University of Manchester
> neil.shephard at man.ac.uk
> neil.shephard at mindless.com
> 
> "Contrariwise, if it was so, it might be; and if it
> were so it would be; but as it isn't, it ain't. That's
> logic" - Tweedledee (Alice Through the Looking Glass)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan 17 14:10:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 17 14:10:05 2003
Subject: [R] difference between "external pointer" and "weak reference"
In-Reply-To: <43714D237FD4D611A8680008C75F30E01462AC@xmx1lonib.lonib.commerzbank.com>
Message-ID: <Pine.LNX.4.44.0301171305250.6151-100000@gannet.stats>

http://developer.r-project.org has the background papers.

On Fri, 17 Jan 2003, Vanguelov, Krassimir wrote:

> Could you tell me where can I read more about the difference between
> "external pointer"(EXTPTRSXP) and "weak reference"(WEAKREFSXP) in R and what
> were they intended for? 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Fri Jan 17 14:14:08 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Jan 17 14:14:08 2003
Subject: [R] Re: Universal legend in plot
In-Reply-To: <F141nGFU7KgX3x1eQP70000fa9e@hotmail.com>
References: <F141nGFU7KgX3x1eQP70000fa9e@hotmail.com>
Message-ID: <3E280082.8040902@statistik.uni-dortmund.de>

Vumani Dlamini wrote:
> Dear R-users:
> 
> I asked a question on how I can have a universal legend in a plot and 
> received the following result. I tried using "layout" but I can't seem 
> to work on the "empty" plot (where I have to have the legend). I tried 
> "oma" but I couldn't improve the quality of the plot, and that I didn't 
> know how to specify all the line types using the keyboard, infact it is 
> line type 4 (I had _._ and it didn't look nice).
> 
> #
> I am trying to create a graph with 6 panels, but would like to have a 
> universal legend as each panel merely denotes a separate stratum. The 
> legend has to be at the bottom.
> 
> I use "par(mfrow=c(2,3))" to get the panels, but am not sure how to put 
> the legend below the whole graph.
> 
> Thanking you as always
> 
> ############
> J.R. Lockwood
> 
> I don't think you can do this without
> 
> layout()
> 
> which you can use to create a separate graphical area within the plot
> region, where you can put the legend.
> 
> i could be wrong though
> ############
> Peter Dalgaard
> 
> You need to look at mtext(....,outer=TRUE), plus par(oma=....) to make
> room for the text in the outer margins.
> ############
> Try layout() for finer adjustments (and some drawbacks).
> See ?layout how to set up a 7th figure (legend) of full with below the 
> desired six other figures.
> 
> Uwe Ligges


So let's start with an example for layout():

  layoutmat <- matrix(c(1,2,3,4,5,6,7,7,7), 3, byrow=TRUE)
  fig <- layout(layoutmat, heights = c(1, 1, 0.3))
  layout.show(fig)              # Ah! That's the setup!
  for(i in 1:6) plot(1:10)      # some nonsense plots for example
  opar <- par(mar=c(0,0,0,0))   # don't need margins for the legend
  # set up the a plot without plotting to prepare for legend():
  plot(0, axes=FALSE, type="n", xlim=c(-1, 1), ylim=c(-1, 1))
  # now we can center the legend with:
  legend(0, 0, c("one", "two"), lwd=1, col=c("black", "red"),
    xjust = 0.5, yjust = 0.5)
  par(opar)                     # restore old par settings



Peter's suggestion was to use mtext() instead of legend(), which is 
somewhat simpler. Example:
  par(mfrow = c(2,3), oma = c(4,0,0,0))
  for(i in 1:6) plot(1:10)
  mtext("Blah, blah 1", 1, outer = TRUE)
  mtext("Blah, blah 2", 1, outer = TRUE, line = 2)

Please read the help pages what the different functions (and arguments) 
are doing!

Uwe Ligges



From mschwartz at medanalytics.com  Fri Jan 17 14:21:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri Jan 17 14:21:03 2003
Subject: [R] barplot plotting problem
In-Reply-To: <3.0.1.32.20030117184156.00d81530@studentmail.otago.ac.nz>
Message-ID: <003c01c2be2b$46d7e3a0$0201a8c0@MARC>

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jeremy Butler
> Sent: Thursday, January 16, 2003 11:42 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] barplot plotting problem
> 
> 
> Hi,
> Is there any equivalent of type="n" when constructing 
> barplots which will still construct the axes (plot=F, as it 
> says doesn' plot anything at all). Alternatively I tried 
> setting col="white" and border="white" but the border command 
> does not seem to be operational. True??
> 
> Any other ideas? What I'm actually trying to do is construct 
> vertical abline()'s _behind_ my plotted data. It seems to me 
> that this requires axes construction then abline plotting 
> then data plotting. Fine for plot() etc. but I don't seem to 
> be able to manage it when barplotting. Is there some other 
> way to do this that I'm missing? Cheers, Jeremy

Jeremy,

There is not an equivalent in barplot to "type = n" in plot or "add =
TRUE" in boxplot.  I will look into adding something like that in the
barplot2() function in the gregmisc package.

What you can do is something like:

mp <- barplot(1:5)
abline(v = mp)
par(new = TRUE)
barplot(1:5)

What this does is to draw the initial barplot and store the bar
midpoints in "mp". Using abline, you get vertical lines initially on
top of the bars at their midpoints. Setting par(new = TRUE) tells R to
not clear the plot window before the next call to barplot().  You then
redraw the barplot, such that now the bars are over the vertical lines
drawn by abline.

You can then make any adjustments you need in the axes if you wish.

Hope that helps.

Regards,

Marc



From jrgonzalez at ico.scs.es  Fri Jan 17 14:36:02 2003
From: jrgonzalez at ico.scs.es (Juan Ramon Gonzalez)
Date: Fri Jan 17 14:36:02 2003
Subject: [R] problems writing graphics
Message-ID: <00ed01c2be2c$a3e49420$1100a8c0@ico.scs.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030117/277998a7/attachment.pl

From bates at stat.wisc.edu  Fri Jan 17 14:46:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Jan 17 14:46:03 2003
Subject: [R] nls
In-Reply-To: <3E27BD98.18046.1C718E@localhost>
References: <3E27BD98.18046.1C718E@localhost>
Message-ID: <6ry95jgaao.fsf@bates4.stat.wisc.edu>

"kjetil brinchmann halvorsen" <kjetil at entelnet.bo> writes:

> On 16 Jan 2003 at 22:15, Yan Yu wrote:
> 
> > HI,
> > i have some prob when i try to use nls().
> > my data is 1D vector, I tried to use a polynomial function(order is 3) to
> > fit it.
> > the data series is stored in x.
> > the a0, a1, a2, a3 below is coefficient, which i  hope i can get from
> > calls "nls"
> > 
> > > z <-  nls(  ~ a0 + a1 * x + a2 * x * x + a3 * x * x * x, data = x )
> 
> You haven't given a response in the formula? nls could possibly give 
> a more informative error message.

and you didn't give starting estimates for the parameters and the
model should not be fit with nls in the first place.  A polynomial in
x is a linear model in the coefficients a0, a1, a2, and a3 and should
be fit with lm, not nls.



From luke at inpharmatica.co.uk  Fri Jan 17 15:10:06 2003
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Fri Jan 17 15:10:06 2003
Subject: [R] DBI/ROracle for remote database connection ?
In-Reply-To: <20030117110009.3060.4660.Mailman@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.21.0301171352520.9746-100000@dollis-hill.inpharmatica.co.uk>

Hello,

I have installed the ROracle and DBI packages, and I want to
access an Oracle database that is not on the same machine
as the one I am running R on.

I can access the database remotely with perl DBI and Java JDBC.
Does anyone know if this is possible using R DBI/ROracle ? I
have looked through the documentation and also tried to guess
at things which might work, but with no success.

I have also looked at using ODBC, but apparently there isn't an
inexpensive ODBC oracle driver for linux.

platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.2              
year     2003             
month    01               
day      10               
language R                

Thanks,

Luke Whitaker



From ligges at statistik.uni-dortmund.de  Fri Jan 17 15:27:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Jan 17 15:27:03 2003
Subject: [R] problems writing graphics
In-Reply-To: <00ed01c2be2c$a3e49420$1100a8c0@ico.scs.es>
References: <00ed01c2be2c$a3e49420$1100a8c0@ico.scs.es>
Message-ID: <3E2812A1.6050608@statistik.uni-dortmund.de>

Juan Ramon Gonzalez wrote:
> Hello R-listers,
> 
> I am developing a function which needs to create jpeg files from some plots. To create the jpeg files I use the instruction dev.print(jpeg, file=c://graph.jpg",width=400,height=400). 
[won't work anyway]

Until now everything has been fine, but now I have a special plot which 
is formed by 3 separate plots joined with the instruction "layout":
> 
> nf <- layout(matrix(c(2,0,1,3),2,2,byrow=TRUE), c(3,1), c(1,3), TRUE);
> layout.show(nf);
> 
> 
> The graphic in R is ok, but the problem comes when I try to change the size of the graphic in the function dev.print, as it seems to not expand the layout graphic to the size I have chosen (it creates an image with the right size, but expanding the margins and not the image itself, while with "normal" plots the image is expanded). Anyone could tell me how to change the size of the image? 
> 
> Thank you in advance,
> 
> Juan

Use dev.copy() instead (it redraws the figure, see ?dev.copy), or even 
better use the jpeg() device directly, if you are on Windows.

Uwe Ligges



From dj at research.bell-labs.com  Fri Jan 17 15:32:04 2003
From: dj at research.bell-labs.com (David James)
Date: Fri Jan 17 15:32:04 2003
Subject: [R] DBI/ROracle for remote database connection ?
In-Reply-To: <Pine.LNX.4.21.0301171352520.9746-100000@dollis-hill.inpharmatica.co.uk>; from luke@inpharmatica.co.uk on Fri, Jan 17, 2003 at 02:09:31PM +0000
References: <20030117110009.3060.4660.Mailman@hypatia.math.ethz.ch> <Pine.LNX.4.21.0301171352520.9746-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <20030117092940.B11786@jessie.research.bell-labs.com>

Hi,

You may want to take a look at the file "README.client" under the
main ROracle package directory.  It describes how to access Oracle
from an Oracle-less linux workstation.

--
David

Luke Whitaker wrote:
> 
> Hello,
> 
> I have installed the ROracle and DBI packages, and I want to
> access an Oracle database that is not on the same machine
> as the one I am running R on.
> 
> I can access the database remotely with perl DBI and Java JDBC.
> Does anyone know if this is possible using R DBI/ROracle ? I
> have looked through the documentation and also tried to guess
> at things which might work, but with no success.
> 
> I have also looked at using ODBC, but apparently there isn't an
> inexpensive ODBC oracle driver for linux.
> 
> platform i686-pc-linux-gnu
> arch     i686             
> os       linux-gnu        
> system   i686, linux-gnu  
> status                    
> major    1                
> minor    6.2              
> year     2003             
> month    01               
> day      10               
> language R                
> 
> Thanks,
> 
> Luke Whitaker
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
David A. James
Statistics Research, Room 2C-253            Phone:  (908) 582-3082       
Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
Murray Hill, NJ 09794-0636



From Timur.Elzhov at jinr.ru  Fri Jan 17 16:11:03 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri Jan 17 16:11:03 2003
Subject: [R] Arguments of R- and C-side of internal functions
Message-ID: <20030117151116.GA10835@pcf004.jinr.ru>

Dear R experts,

I looked at the body of, say, `optim' function and found
the call to the `.Internal', C optim function. It looks
like this:

  .Internal(optim(par, fn1, gr1, method, con, lower, upper))

On the other hand, the C prototype of optim is:

  SEXP do_optim(SEXP call, SEXP op, SEXP args, SEXP rho);

So, I guess that all the list of parameters passing in R are assigned
to `args', right?

First, how is that implemented?  I looked at the `.Call()' - as I
  understand, it requires for C-side the same number of parametrs
  (minus the function name to be called); and `.External()' - it
  wants the single list.
Second, who pass the other, `call', `op' and `rho' parameters
  to `do_optim() ?'


Thank you!

  
--
WBR,
Timur



From p.dalgaard at biostat.ku.dk  Fri Jan 17 16:34:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 17 16:34:03 2003
Subject: [R] Arguments of R- and C-side of internal functions
In-Reply-To: <20030117151116.GA10835@pcf004.jinr.ru>
References: <20030117151116.GA10835@pcf004.jinr.ru>
Message-ID: <x27kd3g5ax.fsf@biostat.ku.dk>

Timur Elzhov <Timur.Elzhov at jinr.ru> writes:

> Second, who pass the other, `call', `op' and `rho' parameters
>   to `do_optim() ?'

You mean "why" I suppose.

op: Some functions are mapped into the same C function (do_math2, for
example) so you need to know which one.

call: The whole call is passed mainly for the benefit of error
printouts. It is not always possible to reconstruct it from the other
arguments, since "op" may be computed as in get("+")(2,2).

rho: this is the evaluation environment, and it is crucial for
variable lookup etc.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From djw1005 at cam.ac.uk  Fri Jan 17 17:00:06 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Fri Jan 17 17:00:06 2003
Subject: [R] Negative Binomial modelling
Message-ID: <Pine.SOL.3.96.1030117154416.17379A-100000@virgo.cus.cam.ac.uk>

I have some data which I am trying to fit with a negative binomial
distribution. I have found the glm.nb function from MASS.

I have reason to believe that the mean parameter mu depends on
certain factors, and that the shape parameter theta depends on
others.

If, say, the factors are P and Q, it might be that
  mu ~ P:Q and theta ~ P
(where mu ~ P:Q means that mu is a function of the pair (P,Q))
in which case I could call glm.nb several times, one for each
level of P (though this would be somewhat cumbersome).


From jonathan.williams at pharmacology.oxford.ac.uk  Fri Jan 17 18:31:03 2003
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Fri Jan 17 18:31:03 2003
Subject: [R] Survr error
Message-ID: <NGBBKJEMOMLJFCOIEGCEKEOKCDAA.jonathan.williams@pharm.ox.ac.uk>

I am trying to analyse recurrent failure times using survfitr
from the survrec package. To do this, I need to "Create a survival 
recurrent object" using Survr. But, when I do this, I get an error
"Error in Survr(r1d[, 1], r1d[, 5], r1d[, 6]) : data doesn't match".

Here, r1d[,1] is the identifier for each case, r1d[,5] is the time
of recurrence, r1d[,6] is the status indicator (1=event, 0=censored).
All columns of of r1d are numeric.

I can create a Surv object using Surv(r1d[,5],r1d[,6]), which looks
OK (censored values are followed by a '+'). So, the difficulty would
seem to be with the 'id' argument of Survr. In my program, r1d[,1]
is a simple numeric vector, which I have put into the data frame
r1d.

I would be grateful fi anyone could let me know how to use Survr
so that I can run survfitr.

Thanks,

Jonathan Williams

OPTIMA
Radcliffe Infirmary
Woodstock Road
OXFORD OX2 6HE
Tel +1865 (2)24356



From huan.huang at bnpparibas.com  Fri Jan 17 19:45:03 2003
From: huan.huang at bnpparibas.com (huan.huang@bnpparibas.com)
Date: Fri Jan 17 19:45:03 2003
Subject: [R] contour plot
Message-ID: <OFFC3FBEFC.E2C50FC8-ON80256CB1.0065AE22@bnpparibas.com>

Dear all

I am fighting with contour plot.

I have a continuous response and three factors. The formula argument in
function contourplot() does not like the factors. What I got is really
nonsense, loads of squares in the plot (exactly the same as what the help
page says). I am wondering how I could get some beautiful curves instead of
the ugly squares.

I have really run out all the ideas I can find. Could anybody show me a
way?

Many thanks in advance.

Huan




This message and any attachments (the "message") is\ intended so ... [[dropped]]



From andy_liaw at merck.com  Fri Jan 17 19:53:02 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Jan 17 19:53:02 2003
Subject: [R] contour plot
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFCA7F@usrymx10.merck.com>

When you have numerical "x" variables, rather than factors, you can make
sensible contour plot.  Short of that, nothing in this world will give you
"beautiful curves".

Andy 

> -----Original Message-----
> From: huan.huang at bnpparibas.com [mailto:huan.huang at bnpparibas.com]
> Sent: Friday, January 17, 2003 1:45 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] contour plot
> 
> 
> 
> Dear all
> 
> I am fighting with contour plot.
> 
> I have a continuous response and three factors. The formula 
> argument in
> function contourplot() does not like the factors. What I got is really
> nonsense, loads of squares in the plot (exactly the same as 
> what the help
> page says). I am wondering how I could get some beautiful 
> curves instead of
> the ugly squares.
> 
> I have really run out all the ideas I can find. Could anybody 
> show me a
> way?
> 
> Many thanks in advance.
> 
> Huan
> 
> 
> 
> 
> This message and any attachments (the "message") is\ intended 
> so ... [[dropped]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From jrgonzalez at ico.scs.es  Fri Jan 17 20:47:02 2003
From: jrgonzalez at ico.scs.es (Juan Ramon Gonzalez)
Date: Fri Jan 17 20:47:02 2003
Subject: [R] Survr error
References: <NGBBKJEMOMLJFCOIEGCEKEOKCDAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <20030117203709.CFD6B14103@inet.iconcologia.catsalut.net>

Dear Jonathan,

This error appear when the number of censored time is not equal to different
identifier numbers. E.g. It is possible you have not censored times for all
subjects. In this case you have to add another data with the same identitier
time equal to 0 and censored 0. For example:

If you have

r1d[, 1]  r1d[, 5]  r1d[, 6]
1         23         1
1         34         1
1         2          0
2         67         1
2         23         0
3         17         1

and you execute:

Survr(r1d[, 1], r1d[, 5], r1d[, 6]) : 

It will to appear the error message: 
  "data doesn't match"
       

You have to modifie your data adding the line:

3     0     0


and you will have:

r1d[, 1]  r1d[, 5]  r1d[, 6]
1         23         1
1         34         1
1         2          0
2         67         1
2         23         0
3         17         1
3         0          0

then if you execute 

Survr(r1d[, 1], r1d[, 5], r1d[, 6]) 

with these data it works fine. 


I wrote the Survr in this way because the estimators (PSH, Wang-Chang, FRMLE)
take in to account the censored times and I wanted to force all subjects
(identifiers) had censored time.


Juan R Gonzalez




> I am trying to analyse recurrent failure times using survfitr
> from the survrec package. To do this, I need to "Create a survival 
> recurrent object" using Survr. But, when I do this, I get an error
> "Error in Survr(r1d[, 1], r1d[, 5], r1d[, 6]) : data doesn't match".
> 
> Here, r1d[,1] is the identifier for each case, r1d[,5] is the time
> of recurrence, r1d[,6] is the status indicator (1=event, 0=censored).
> All columns of of r1d are numeric.
> 
> I can create a Surv object using Surv(r1d[,5],r1d[,6]), which looks
> OK (censored values are followed by a '+'). So, the difficulty would
> seem to be with the 'id' argument of Survr. In my program, r1d[,1]
> is a simple numeric vector, which I have put into the data frame
> r1d.
> 
> I would be grateful fi anyone could let me know how to use Survr
> so that I can run survfitr.
> 
> Thanks,
> 
> Jonathan Williams
> 
> OPTIMA
> Radcliffe Infirmary
> Woodstock Road
> OXFORD OX2 6HE
> Tel +1865 (2)24356
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From David_Hinds at perlegen.com  Fri Jan 17 21:58:02 2003
From: David_Hinds at perlegen.com (David Hinds)
Date: Fri Jan 17 21:58:02 2003
Subject: [R] Re: check variables: a Q from a beginner
Message-ID: <5831359258534842BF3496B0794326DBF6697D@mrzip.perlegen.com>

I played around a bit with the ls.objects() code posted by Petr Pikal
yesterday and came up with the following that is a bit faster, shorter,
and adds memory usage information.  It combines an object's mode and 
class information into a "Type" column that seems more parsimonious,
and adds an argument for specifying a sort column.

-- Dave Hinds


ls.obj <- function (pos = 1, pattern, order.by)
{
    napply <- function(names, fn)
        sapply(names, function(x) fn(get(x, pos = pos)))
    names <- ls(pos = pos, pattern = pattern)
    obj.class <- napply(names, function(x) as.character(class(x))[1])
    obj.mode <- napply(names, mode)
    obj.type <- ifelse(is.na(obj.class),obj.mode,obj.class)
    obj.size <- napply(names, object.size)

    obj.dim <- t(napply(names, function(x) as.numeric(dim(x))[1:2]))
    vec <- is.na(obj.dim)[,1] & (obj.type != 'function')
    obj.dim[vec,1] <- napply(names, length)[vec]

    out <- data.frame(obj.type,obj.size,obj.dim)
    names(out) <- c("Type","Size","Rows","Columns")
    if (!missing(order.by)) out <- out[order(out[[order.by]]),]
    out
}

> ls.obj(o=2)
                   Type    Size Rows Columns
db              numeric      36    1      NA
A             character     100    6      NA
U             character     100    6      NA
fetch          function    2924   NA      NA
ls.obj         function    9848   NA      NA
get.snp.data   function   15692   NA      NA
hap.fit        function   16124   NA      NA
get.hap.info   function   22476   NA      NA
bb           data.frame   32676  534       7
snp.data     data.frame  621936 3873      20
hap.data           list 1426080  571      NA
s                  list 1901952  566      NA



From trainor at transborder.org  Fri Jan 17 22:06:58 2003
From: trainor at transborder.org (Douglas Trainor)
Date: Fri Jan 17 22:06:58 2003
Subject: [R] Overdispersed poisson - negative observation
In-Reply-To: <OF5C737A53.51A23FF1-ON80256CB0.005279C8@uk.rsa-ins.com>
References: <OF5C737A53.51A23FF1-ON80256CB0.005279C8@uk.rsa-ins.com>
Message-ID: <3E286CF1.4000504@transborder.org>

Some other techniques for overdispersed and underdispersed count data
are described in:

    COUNT DATA REGRESSION USING SERIES EXPANSIONS: WITH APPLICATIONS
    by A. COLIN CAMERON and PER JOHANSSON
    in JOURNAL OF APPLIED ECONOMETRICS, VOL 12, 203-223 (1997).

    http://www.econ.uiuc.edu/~econ472/cameron97.pdf


peter.fledelius at wgo.royalsun.com wrote:

>Dear R users
>
>I have been looking for functions that can deal with overdispersed poisson
>models. Some (one) of the observations are negative. According to actuarial
>literature (England & Verall, Stochastic Claims Reserving in General
>Insurance , Institute of Actiuaries 2002) this can be handled through the
>use of quasi likelihoods instead of normal likelihoods. The presence of
>negatives is not normal in a poisson model, however, we see them frequently
>in this type of data, and we would like to be able to fit the model anyway.
>[...]
>



From rudy at polisci.wisc.edu  Fri Jan 17 22:57:02 2003
From: rudy at polisci.wisc.edu (Rodolfo Espino III)
Date: Fri Jan 17 22:57:02 2003
Subject: [R] .Fortran error
Message-ID: <3910240DA6E1D411AB4900B0D079A5F2C95734@pswinnt3.polisci.wisc.edu>

I am running R version (1.6.2-1) on Redhat Linux 8.0.
I am unsuccesfully trying to compile Fortran code and then loading the
created object into R.
The following are the basic commands I have used to do this.

#R CMD SHLIB -o file.f
#R
>dyn.load("file.so")

In the above command I have been explicit and unexplicit about directory
paths.
I then go on to enter another command and receive the following error
message:

Error in .Fortran("difp", :
        C/Fortran function name not in load table 

I checked on the shared object as follows but this may not necessarily tell
me anything about loading properly or not:

>is.loaded("file.so")
[1] FALSE

I am certain that the error message I am receiving is due to my inability to
load the object properly but I cannot figure out what I am doing wrong.  Any
help/advice on this would be greatly appreciated.


Thanks,

Rudy Espino



From deepayan at stat.wisc.edu  Sat Jan 18 00:23:02 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat Jan 18 00:23:02 2003
Subject: [R] contour plot
In-Reply-To: <OFFC3FBEFC.E2C50FC8-ON80256CB1.0065AE22@bnpparibas.com>
References: <OFFC3FBEFC.E2C50FC8-ON80256CB1.0065AE22@bnpparibas.com>
Message-ID: <200301171722.08079.deepayan@stat.wisc.edu>

On Friday 17 January 2003 12:44 pm, huan.huang at bnpparibas.com wrote:
> Dear all
>
> I am fighting with contour plot.
>
> I have a continuous response and three factors. The formula argument in
> function contourplot() does not like the factors. What I got is really
> nonsense, loads of squares in the plot (exactly the same as what the help
> page says). I am wondering how I could get some beautiful curves instead of
> the ugly squares.

What does the help page say ? What versions of R and lattice are you using ?

Deepayan



From kjetil at entelnet.bo  Sat Jan 18 00:40:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat Jan 18 00:40:03 2003
Subject: [R] Negative Binomial modelling
In-Reply-To: <Pine.SOL.3.96.1030117154416.17379A-100000@virgo.cus.cam.ac.uk>
Message-ID: <3E285BF4.19565.26F5A2@localhost>

On 17 Jan 2003 at 15:59, Damon Wischik wrote:

It seems like gnlr() in Jim Lindsay's package
gnlm might help you.

Kjetil Halvorsen

> 
> I have some data which I am trying to fit with a negative binomial
> distribution. I have found the glm.nb function from MASS.
> 
> I have reason to believe that the mean parameter mu depends on
> certain factors, and that the shape parameter theta depends on
> others.
> 
> If, say, the factors are P and Q, it might be that
>   mu ~ P:Q and theta ~ P
> (where mu ~ P:Q means that mu is a function of the pair (P,Q))
> in which case I could call glm.nb several times, one for each
> level of P (though this would be somewhat cumbersome).
> 
> From looking at the data, I have reason to believe that
>   mu ~ P and theta ~ Q.
> How can I go about fitting this?
> 
> I expect I will have to write my own likelihood-maximization
> routine, and I am happy to do this (though if there are packages
> that do it for me, so much the better). In fact, my real model
> is a mixture model, and for this I am sure I will have to write
> my own likelihood-maximization routine.
> 
> What I want to learn from this list is if there are helpful
> commands that would do all the tedious work of working out how
> many variables there are etc. I'm hoping for some sort of call like
>   gm( count ~ mydist(mu=p:q, theta=q) )
> where all I need to write the likelihood-maximization routine
> and the function gm does the rest, providing the answer in
> a suitable format for doing chi-squared tests etc.
> 
> Damon Wischik.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From yanyu at cs.ucla.edu  Sat Jan 18 02:52:03 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Sat Jan 18 02:52:03 2003
Subject: [R] nls() and arima()
In-Reply-To: <6ry95jgaao.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.SOL.4.33.0301171732070.19968-100000@panther.cs.ucla.edu>

HI,
Thank you all for the reply to my nls Q.
after i put a variable at the left hand side of "~", and feed initial
values of coefficients, it works now:)
I have a related Q:
I apply arima() and nls() on the same time series. and try to compare
which one fits better.
the result from nls() provides "residual sum-of-squares"
the result from arima() gives "sigma2, var.coef" and residuals at each
points.
My Q is:   what is the meaningful way to compare these two fittings from
the returned value from nls() and arima()?
should I also compute the sum-of-squares residuals for arima() from the
big individual residual array?
Is there any easy way to do this?

thanks a lot,
have a nice weekend,
yan




On 17 Jan 2003, Douglas Bates wrote:

> "kjetil brinchmann halvorsen" <kjetil at entelnet.bo> writes:
>
> > On 16 Jan 2003 at 22:15, Yan Yu wrote:
> >
> > > HI,
> > > i have some prob when i try to use nls().
> > > my data is 1D vector, I tried to use a polynomial function(order is 3) to
> > > fit it.
> > > the data series is stored in x.
> > > the a0, a1, a2, a3 below is coefficient, which i  hope i can get from
> > > calls "nls"
> > >
> > > > z <-  nls(  ~ a0 + a1 * x + a2 * x * x + a3 * x * x * x, data = x )
> >
> > You haven't given a response in the formula? nls could possibly give
> > a more informative error message.
>
> and you didn't give starting estimates for the parameters and the
> model should not be fit with nls in the first place.  A polynomial in
> x is a linear model in the coefficients a0, a1, a2, and a3 and should
> be fit with lm, not nls.
>



From bitwrit at ozemail.com.au  Sat Jan 18 11:27:03 2003
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Sat Jan 18 11:27:03 2003
Subject: [R] barplot plotting problem
In-Reply-To: <3.0.1.32.20030117184156.00d81530@studentmail.otago.ac.nz>
References: <3.0.1.32.20030117184156.00d81530@studentmail.otago.ac.nz>
Message-ID: <20030118102650.KOHZ3007.mta05.mail.mel.aone.net.au@there>

Jeremy Butler wrote:
> Hi,
> Is there any equivalent of type="n" when constructing barplots which
> will still construct the axes (plot=F, as it says doesn' plot anything
> at all). Alternatively I tried setting col="white" and border="white"
> but the border command does not seem to be operational. True??
>
> Any other ideas? What I'm actually trying to do is construct vertical
> abline()'s _behind_ my plotted data. It seems to me that this requires
> axes construction then abline plotting then data plotting. Fine for
> plot() etc. but I don't seem to be able to manage it when barplotting.
> Is there some other way to do this that I'm missing?
> 
This may help.

> xpos<-barplot(c(1.3,2.5,2,2,3.4))
> # there's probably a better way to clear the device...
> plot(1:10,type="n",axes=F,xlab="",ylab="")
> barplot(c(1.3,2.5,2,2,3.4),plot=F)
> abline(v=xpos)
> par(new=T)
> xpos<-barplot(c(1.3,2.5,2,2,3.4))
> par(new=F)

Jim



From Jmshttn at aol.com  Sat Jan 18 15:45:03 2003
From: Jmshttn at aol.com (Jmshttn@aol.com)
Date: Sat Jan 18 15:45:03 2003
Subject: [R] (no subject)
Message-ID: <9c.2c7e4035.2b5abf7f@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030118/45a1a856/attachment.pl

From fharrell at virginia.edu  Sat Jan 18 16:07:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sat Jan 18 16:07:03 2003
Subject: [R] SAS transport files and the foreign package
Message-ID: <20030118100622.28311b28.fharrell@virginia.edu>

Even though the FDA has no policies at all that limit our choices of statistical software, there is one defacto standard in place: reliance of the SAS transport file format for data submission (even though this format is deficient for this purpose, e.g., it does not even document value labels or units of measurement in a self-contained way).  Because of the widespread use of SAS transport files in the pharmaceutical industry, clinical trial data analyses done by statistical centers like ours who receive data from companies often begin with SAS transport files.  I have not had SAS on my machines in about 12 years so it would be nice to be able to read binary transport files instead of having to run the slower sas.get function in the Hmisc library.  sas.get has to launch SAS to do its work.

The foreign package implements a quick way to read such files in its read.xport function.  This function has some significant problems which I have reported to the developers some time ago but fixes do not seem to be forthcoming nor have acknowledgements of the bug report.  The developers have done great work in writing the foreign package (and many other awesome contributions to the community) so I don't fault them at all for being creative, busy people.  I am writing this note to see if any C language-savvy R users have done their own fixes or would be willing to help the developers with these particular fixes.  The specific problems I have found are (1) a worrisome one in which reasonable but invalid data result from importing SAS numeric variables of length 3 bytes; and (2) getting corrupted files when the SAS transport file contains multiple SAS datasets.  In addition, it would be great to have lookup.xport retrieve all SAS variable attributes including PROC FORMAT VALUE names, so that factor variables could be created as is done automatically with read.spss in foreign.  Note there is also a problem with lookup.xport when there are multiple files.  The documentation states that a list with a major element for each dataset will be created.  read.xport is supposed to create a list of data frames for this case.

Here is SAS code I used to create test files, followed by R output.

libname x SASV5XPT "test.xpt";
libname y SASV5XPT "test2.xpt";

PROC FORMAT; VALUE race 1=green 2=blue 3=purple; RUN;
PROC FORMAT CNTLOUT=format;RUN;
data test;
LENGTH race 3 age 4;
age=30; label age="Age at Beginning of Study";
race=2;
d1='3mar2002'd ;
dt1='3mar2002 9:31:02'dt;
t1='11:13:45't;
output;

age=31;
race=4;
d1='3jun2002'd ;
dt1='3jun2002 9:42:07'dt;
t1='11:14:13't;
output;
format d1 mmddyy10. dt1 datetime. t1 time. race race.;
run;
/* PROC CPORT LIB=work FILE='test.xpt';run;  * no; */
PROC COPY IN=work OUT=x;SELECT test;RUN;
PROC COPY IN=work OUT=y;SELECT test format;RUN;


> lookup.xport('test.xpt')
$TEST
$TEST$headpad
[1] 1200

$TEST$type
[1] "numeric" "numeric" "numeric" "numeric" "numeric"

$TEST$width
[1] 3 4 8 8 8

$TEST$index
[1] 1 2 3 4 5

$TEST$position
[1]  0  3  7 15 23

$TEST$name
[1] "RACE" "AGE"  "D1"   "DT1"  "T1"  

$TEST$sexptype
[1] 14 14 14 14 14

$TEST$tailpad
[1] 18

$TEST$length
[1] 2

> lookup.xport('test2.xpt')

Same output except tailpad=76, length=124, second dataset ignored.

> read.xport('test.xpt')
      RACE      AGE    D1        DT1    T1
1 2.000063 30.00000 15402 1330767062 40425
2 4.000063 31.00000 15494 1338716527 40453

> read.xport('test2.xpt')
            RACE           AGE            D1           DT1            T1
1   2.000063e+00  3.000000e+01  1.540200e+04  1.330767e+09  4.042500e+04
2   4.000063e+00  3.100000e+01  1.549400e+04  1.338717e+09  4.045300e+04
. . . .
122 3.687825e-40  3.687825e-40  3.687825e-40  5.868918e-40  3.687825e-40
123 5.904941e-40  2.942346e+63  9.068390e+43            NA -5.524256e-48
124 3.835229e-93  6.434447e-86            NA  3.687825e-40  3.687825e-40


test.xpt and test2.xpt may be retrieved from http://hesweb1.med.virginia.edu/biostat/tmp

They were created on an IBM AIX machine running SAS 8.

Thanks very much for any assistance.  -Frank

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From upton at mitre.org  Sat Jan 18 16:11:03 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Sat Jan 18 16:11:03 2003
Subject: [R] (no subject)
References: <9c.2c7e4035.2b5abf7f@aol.com>
Message-ID: <3E296D86.585F36E2@mitre.org>

James,

I think you want to try using index vectors.
index <- c(1:length(x))
negs <- index[x<0]
nonnegs <- index[x>=0]

Then, if you want the negative values, just use
negativevalues <- x[negs]

HTH
steve

Jmshttn at aol.com wrote:

> Dear Mailing List,
>
> If I wanted a data set of twenty standard normal results, I would type:
>
> x<-rnorm(20)
>
> If I then wanted to make all the negative results in that data set to be
> listed as zero I would then type in:
>
> x[x<0]<-0
>
> However, I now want to discard the values that are zero, but I want to know
> which values out of the original data set which I truncated to zeros I
> discarded. How is the best way of doing this? Do I use match(x,0) /
> (1:length(x))[x==0] ? How do I discard the values as well as wanting the
> original data set values. All suggestions would be greatly appreciated.
>
> Thank you,
>
> James Hutton
>
>         [[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jfox at mcmaster.ca  Sat Jan 18 16:20:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat Jan 18 16:20:03 2003
Subject: [R] (no subject)
In-Reply-To: <9c.2c7e4035.2b5abf7f@aol.com>
Message-ID: <5.1.0.14.2.20030118101741.01ded538@mcmail.cis.mcmaster.ca>

Dear James,

If I understand correctly what you want to do, I can think of several ways 
to do it; here are two:

     > y <- x <- rnorm(20)
     > neg <- x < 0
     > x[neg] <- 0
     > x
     [1] 0.7314066 0.3515410 0.0000000 0.0000000
     [5] 0.0000000 0.0000000 0.0000000 0.0000000
     [9] 0.4341421 0.0000000 0.2766616 0.1823935
     [13] 0.0000000 0.0000000 0.0000000 0.0000000
     [17] 0.0000000 1.3797720 1.2607272 0.6471086
     > x[!neg]
     [1] 0.7314066 0.3515410 0.4341421 0.2766616
     [5] 0.1823935 1.3797720 1.2607272 0.6471086
     > (1:20)[neg]
     [1]  3  4  5  6  7  8 10 13 14 15 16 17
     >
     > neg <- which(y < 0)
     > y[neg] <- 0
     > neg
     [1]  3  4  5  6  7  8 10 13 14 15 16 17
     > y[-neg]
     [1] 0.7314066 0.3515410 0.4341421 0.2766616
     [5] 0.1823935 1.3797720 1.2607272 0.6471086

I hope that this helps,
  John


At 09:32 AM 1/18/2003 -0500, Jmshttn at aol.com wrote:
>Dear Mailing List,
>
>If I wanted a data set of twenty standard normal results, I would type:
>
>x<-rnorm(20)
>
>If I then wanted to make all the negative results in that data set to be
>listed as zero I would then type in:
>
>x[x<0]<-0
>
>However, I now want to discard the values that are zero, but I want to know
>which values out of the original data set which I truncated to zeros I
>discarded. How is the best way of doing this? Do I use match(x,0) /
>(1:length(x))[x==0] ? How do I discard the values as well as wanting the
>original data set values. All suggestions would be greatly appreciated.
>
>Thank you,
>
>James Hutton
>
>         [[alternate HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From edd at debian.org  Sat Jan 18 16:32:02 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat Jan 18 16:32:02 2003
Subject: [R] Debian packages of pmg et al for menu driven GUI using RGtk
In-Reply-To: <15910.62004.627497.532307@levy.math.csi.cuny.edu>
References: <15910.62004.627497.532307@levy.math.csi.cuny.edu>
Message-ID: <20030118153103.GA16236@sonny.eddelbuettel.com>

On Thu, Jan 16, 2003 at 12:56:04PM -0500, verzani at math.csi.cuny.edu wrote:
> I've put together a quick and dirty menubar + dialogs + spreadsheet
> GUI for R using the RGtk package. Performance is not great (OOP is a
> real memory hog?), the design may be worse, but the hope is that it
> will be useful in an introductory stats course while we await the
> arrival of a real gui with ObveRsive and SciViews.
> 
> The package can be found at 
> 
> http://www.math.csi.cuny.edu/Statistics/R/pmg/
> 
> Feedback welcome.

I have Debian packages of all the required pieces available at

  http://dirk.eddelbuettel.com/R/ 	   [ note the trailing /R ]

which allows anyone running Debian testing or unstable to take a peek John's
most interesting code, play with and cleanly uninstall it if need be.

The files are 

    r-cran-pmg_0.1-1_i386.deb
    r-omegahat-oop_0.4.2.R-1_i386.deb
    r-omegahat-rgdkpixbuf_0.1-1_i386.deb
    r-omegahat-rgtk_0.6.0-1_i386.deb
    r-omegahat-rgtkextra_0.1-1_i386.deb

and of these, only r-omegahat-rgtk has thus far been part of the Debian
distributions.  I'd welcome feedback from Debian users to see if there is
interest in having Duncan's other modules be part of the Debian
distribution.

Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr



From bates at stat.wisc.edu  Sat Jan 18 16:59:02 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat Jan 18 16:59:02 2003
Subject: [R] SAS transport files and the foreign package
In-Reply-To: <20030118100622.28311b28.fharrell@virginia.edu>
References: <20030118100622.28311b28.fharrell@virginia.edu>
Message-ID: <6r3cnqwiuk.fsf@bates4.stat.wisc.edu>

Thanks for following up on this, Frank.  I regret that I didn't
respond to you and to the list sooner.

A bit of background - Saikat DebRoy and I developed R and C code for
the lookup.xport and read.xport functions for exactly the type of
application that you describe.  We were working on a project where we
were to receive data in the SAS XPORT file format.  As preparation for
that project we looked up the description of a SAS XPORT data set and
worked out code to read that format.  All testing was done with data
sets generated under SAS version 6 because that is all we had access
to.

When we actually got the data it wasn't in XPORT format so we never
used those functions.  That was several years ago and since then
neither Saikat nor I have used the lookup.xport or read.xport
functions at all.  We do have access to SAS but Saikat never uses it
and I almost never use it.  (Once or twice a year I run an elementary
SAS program to show a class how SAS is used but that is about it.)
The bottom line is that lookup.xport and read.xport were written by
people who don't use SAS, working from the (sometimes incorrect)
documentation on the SAS web site, and using an old version of SAS to
generate test cases.

Your request for someone to step forward to maintain and enhance these
functions is exactly what Saikat and I would like to have happen.  In
the phrase used by Debian GNU/Linux maintainers, we would like to
"orphan" these functions.  That is, we would like to put them up for
adoption by someone else.

If a volunteer will come forward, we will be happy to help such a
person understand our code and what we were trying to accomplish.  It
is not easy to decode that format because the format itself is, shall
we say, "interesting".  You point out that numeric variables of length
3 bytes cause problems.  I'm not surprised - according to the
documentation that we had, such variables cannot exist.  There is only
one numeric form allowed and that is the IBM System/360 double
precision format.

The really fun part of the format is that there is no information in
the headers about the number of rows in the data set.  If you realize
that SAS was designed to read and write data on reels of magnetic
tape, this makes sense, but in today's environment it is bizarre.  When
one data set ends the total length of the data set is padded with
blanks to a multiple of 80 bytes (so it can be conveniently
transferred to a deck of punched cards, naturally) then a magic header
sequence is written onto the next card image.  This means you have to
read all data in 80 byte chunks and look ahead to the next chunk to
decide how to interpret the current chunk.  It also means that the
data format is ambiguous.  When records are, say, 40 bytes in length,
it is impossible to distinguish between n records where n is odd and
n+1 records where the last record happens to be all blanks.  I spent
quite a bit of time thinking that I must have missed something in the
specification because this was such a glaring flaw.  I looked around
the SAS web site and finally found some discussion of this.  SAS
acknowledges the ambiguity and has a simple fix - "don't do that".
They specifically say that you should not put a record that is all
blanks at the end of a data set.

In any case I appreciate your following up on this and echo your
request for a programmer to step forward and adopt these functions.

Frank E Harrell Jr <fharrell at virginia.edu> writes:

> Even though the FDA has no policies at all that limit our choices of
> statistical software, there is one defacto standard in place:
> reliance of the SAS transport file format for data submission (even
> though this format is deficient for this purpose, e.g., it does not
> even document value labels or units of measurement in a
> self-contained way).  Because of the widespread use of SAS transport
> files in the pharmaceutical industry, clinical trial data analyses
> done by statistical centers like ours who receive data from
> companies often begin with SAS transport files.  I have not had SAS
> on my machines in about 12 years so it would be nice to be able to
> read binary transport files instead of having to run the slower
> sas.get function in the Hmisc library.  sas.get has to launch SAS to
> do its work.
> 
> The foreign package implements a quick way to read such files in its
> read.xport function.  This function has some significant problems
> which I have reported to the developers some time ago but fixes do
> not seem to be forthcoming nor have acknowledgements of the bug
> report.  The developers have done great work in writing the foreign
> package (and many other awesome contributions to the community) so I
> don't fault them at all for being creative, busy people.  I am
> writing this note to see if any C language-savvy R users have done
> their own fixes or would be willing to help the developers with
> these particular fixes.  The specific problems I have found are (1)
> a worrisome one in which reasonable but invalid data result from
> importing SAS numeric variables of length 3 bytes; and (2) getting
> corrupted files when the SAS transport file contains multiple SAS
> datasets.  In addition, it would be great to have lookup.xport
> retrieve all SAS variable attributes including PROC FORMAT VALU!  E
> names, so that factor variables could be created as is done
> automatically with read.spss in foreign.  Note there is also a
> problem with lookup.xport when there are multiple files.  The
> documentation states that a list with a major element for each
> dataset will be created.  read.xport is supposed to create a list of
> data frames for this case.
> 
> Here is SAS code I used to create test files, followed by R output.
> 
> libname x SASV5XPT "test.xpt";
> libname y SASV5XPT "test2.xpt";
> 
> PROC FORMAT; VALUE race 1=green 2=blue 3=purple; RUN;
> PROC FORMAT CNTLOUT=format;RUN;
> data test;
> LENGTH race 3 age 4;
> age=30; label age="Age at Beginning of Study";
> race=2;
> d1='3mar2002'd ;
> dt1='3mar2002 9:31:02'dt;
> t1='11:13:45't;
> output;
> 
> age=31;
> race=4;
> d1='3jun2002'd ;
> dt1='3jun2002 9:42:07'dt;
> t1='11:14:13't;
> output;
> format d1 mmddyy10. dt1 datetime. t1 time. race race.;
> run;
> /* PROC CPORT LIB=work FILE='test.xpt';run;  * no; */
> PROC COPY IN=work OUT=x;SELECT test;RUN;
> PROC COPY IN=work OUT=y;SELECT test format;RUN;
> 
> 
> > lookup.xport('test.xpt')
> $TEST
> $TEST$headpad
> [1] 1200
> 
> $TEST$type
> [1] "numeric" "numeric" "numeric" "numeric" "numeric"
> 
> $TEST$width
> [1] 3 4 8 8 8
> 
> $TEST$index
> [1] 1 2 3 4 5
> 
> $TEST$position
> [1]  0  3  7 15 23
> 
> $TEST$name
> [1] "RACE" "AGE"  "D1"   "DT1"  "T1"  
> 
> $TEST$sexptype
> [1] 14 14 14 14 14
> 
> $TEST$tailpad
> [1] 18
> 
> $TEST$length
> [1] 2
> 
> > lookup.xport('test2.xpt')
> 
> Same output except tailpad=76, length=124, second dataset ignored.
> 
> > read.xport('test.xpt')
>       RACE      AGE    D1        DT1    T1
> 1 2.000063 30.00000 15402 1330767062 40425
> 2 4.000063 31.00000 15494 1338716527 40453
> 
> > read.xport('test2.xpt')
>             RACE           AGE            D1           DT1            T1
> 1   2.000063e+00  3.000000e+01  1.540200e+04  1.330767e+09  4.042500e+04
> 2   4.000063e+00  3.100000e+01  1.549400e+04  1.338717e+09  4.045300e+04
> . . . .
> 122 3.687825e-40  3.687825e-40  3.687825e-40  5.868918e-40  3.687825e-40
> 123 5.904941e-40  2.942346e+63  9.068390e+43            NA -5.524256e-48
> 124 3.835229e-93  6.434447e-86            NA  3.687825e-40  3.687825e-40
> 
> 
> test.xpt and test2.xpt may be retrieved from http://hesweb1.med.virginia.edu/biostat/tmp
> 
> They were created on an IBM AIX machine running SAS 8.
> 
> Thanks very much for any assistance.  -Frank
> 
> -- 
> Frank E Harrell Jr              Prof. of Biostatistics & Statistics
> Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
> U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From fharrell at virginia.edu  Sat Jan 18 18:46:02 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sat Jan 18 18:46:02 2003
Subject: [R] SAS transport files and the foreign package
In-Reply-To: <6r3cnqwiuk.fsf@bates4.stat.wisc.edu>
References: <20030118100622.28311b28.fharrell@virginia.edu>
	<6r3cnqwiuk.fsf@bates4.stat.wisc.edu>
Message-ID: <20030118124509.4f0eeba0.fharrell@virginia.edu>

Thanks for your note Doug!

I had no idea how strange the XPORT format really is.  I really hope that someone will step forward to enhance and maintain read.xport and lookup.xport, as it would be of great benefit to many users.

Following Duncan Temple Lang's suggestion I am contacting one of our clients to see what they think about moving towards XML for this.  My guess is that XML will take a while to be used routinely for this and that the sometimes huge datasets involved will cause XML files to be monstrous (compression will help but will tax memory usage of R at least temporarily during processing).  

Again thanks Doug for all your and Saikat DebRoy's work on this and for all of the helpful information and interesting history, which only goes out to reinforce my belief that SAS is used so much in the pharmaceutical industry not for any technological advantages or accuracy of calculations but because of inertia and because of disdain of some statisticians for learning how to use new tools.  On the positive side I have been heartened by increased interest in S at large pharmaceutical companies I have visited recently.  Our statistical center work will profit from the University of Wisconsin Dept. of Biostatistics model and will use only S and LaTeX for statistical reporting.

Frank
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From dbcfmp at unileon.es  Sat Jan 18 19:03:05 2003
From: dbcfmp at unileon.es (Felipe)
Date: Sat Jan 18 19:03:05 2003
Subject: [R] SAS/SPSS - R migration
Message-ID: <FB00F44C-2B0E-11D7-828A-0003936778C4@unileon.es>

Hi! I am starting to use the R system. Till now I have been using SAS 
and SPSS, as my university and department has licences of them.
I would like to know if there is a mail list in Spanish (this is my 
native language), and if there is some kind of tutorial specially 
oriented to people used to work with SAS or SPSS who want to migrate to 
R.
Thank you!

Felipe



From tlumley at u.washington.edu  Sat Jan 18 20:05:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat Jan 18 20:05:03 2003
Subject: [R] Negative Binomial modelling
In-Reply-To: <Pine.SOL.3.96.1030117154416.17379A-100000@virgo.cus.cam.ac.uk>
Message-ID: <Pine.A41.4.44.0301181047130.96526-100000@homer11.u.washington.edu>

On Fri, 17 Jan 2003, Damon Wischik wrote:

>
> I have some data which I am trying to fit with a negative binomial
> distribution. I have found the glm.nb function from MASS.
>
> I have reason to believe that the mean parameter mu depends on
> certain factors, and that the shape parameter theta depends on
> others.
>
> If, say, the factors are P and Q, it might be that
>   mu ~ P:Q and theta ~ P
> (where mu ~ P:Q means that mu is a function of the pair (P,Q))
> in which case I could call glm.nb several times, one for each
> level of P (though this would be somewhat cumbersome).
>
> From looking at the data, I have reason to believe that
>   mu ~ P and theta ~ Q.
> How can I go about fitting this?
>
> I expect I will have to write my own likelihood-maximization
> routine, and I am happy to do this (though if there are packages
> that do it for me, so much the better). In fact, my real model
> is a mixture model, and for this I am sure I will have to write
> my own likelihood-maximization routine.

No, you probably won't.  The built-in optimisers in nlm and optim work
pretty well -- they're sometimes a bit slow but not as slow as writing
your own.

> What I want to learn from this list is if there are helpful
> commands that would do all the tedious work of working out how
> many variables there are etc. I'm hoping for some sort of call like
>   gm( count ~ mydist(mu=p:q, theta=q) )
> where all I need to write the likelihood-maximization routine
> and the function gm does the rest, providing the answer in
> a suitable format for doing chi-squared tests etc.

Jim Lindsey's gnlr in his gnlm package will probably work.  If not, I will
soon be releasing a survey package that among other things fits MLEs by
weighted likelihood.

	-thomas


Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From tchur at optushome.com.au  Sun Jan 19 00:23:03 2003
From: tchur at optushome.com.au (Tim Churches)
Date: Sun Jan 19 00:23:03 2003
Subject: [R] SAS transport files and the foreign package
In-Reply-To: <20030118124509.4f0eeba0.fharrell@virginia.edu>
References: <20030118100622.28311b28.fharrell@virginia.edu>
	<6r3cnqwiuk.fsf@bates4.stat.wisc.edu> 
	<20030118124509.4f0eeba0.fharrell@virginia.edu>
Message-ID: <1043007927.1275.159.camel@emilio>

On Sat, 2003-01-18 at 07:45, Frank E Harrell Jr wrote:
> I had no idea how strange the XPORT format really is.

Like the fact that the IBM double precision representation used in XPORT
uses 7 bits for the exponent and 56 bits for the mantissa, whereas IEEE
format uses 11 bits for the exponent and 52 bits for the mantissa.
  
> Following Duncan Temple Lang's suggestion I am contacting one of our
> clients to see what they think about moving towards XML for this.
> My guess is that XML will take a while to be used routinely for 
> this and that the sometimes huge datasets involved will cause XML 
> files to be monstrous (compression will help but will tax memory
> usage of R at least temporarily during processing).  

The nice things about the SAS XML engine are: 
a) all the metadata associated with a dataset is included in the
generated XML file, including not just the names of the formats
for each variable (column), but the actual format value labels
themselves. 
b) more than one dataset can be included in a single generated XML
export file
c) like the XPORT format, close to foolproof from the SAS user's
point of view, because the SAS XML engine does all the work.

The generated files are indeed huge (relative to the
amount of actual data they contain). For our purposes,
this is not likely to be a huge problem - we select
and/or summarise data in SAS, and then pass the subset or 
summary set to R. At the moment, we are experimenting with 
parsing the SAS XML files with Python and then passing the 
data to R via RPy (the Python-to-R bridge) - mainly because
I am slightly more adept at writing Python than R. However, the
ability of R to read SAS XML files directly, and to set
up categorical SAS variables which have formats as factor
columns in R data.frames, would be fabulous.

Tim C



From nwaltner at attbi.com  Sun Jan 19 02:08:02 2003
From: nwaltner at attbi.com (Nicholas Waltner)
Date: Sun Jan 19 02:08:02 2003
Subject: [R] Question on running tseries::garch on Mac OSX
Message-ID: <BA4F2A3A.2114%nwaltner@attbi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030119/d5ac1ce8/attachment.pl

From rab at nauticom.net  Sun Jan 19 07:07:03 2003
From: rab at nauticom.net (rab)
Date: Sun Jan 19 07:07:03 2003
Subject: [R] MANOVA with within-subject factors
In-Reply-To: <x27kd3g5ax.fsf@biostat.ku.dk>
References: <20030117151116.GA10835@pcf004.jinr.ru> <x27kd3g5ax.fsf@biostat.ku.dk>
Message-ID: <3E2A459D.202@nauticom.net>

Hi. I have a split-plot design where one of the treatment factors is 
between-subjects and the other two factors  are applied within each 
subject in 2x2 design. In addition, the subjects occur in blocks, 2 to a 
block.

In a between-subjects design with repeated measures, it's easy to see 
how to set up the formula. The response matrix consists of columns, each 
column a response variable (or repeated measure at each time point with 
each column a time point). But I don't see how to do the multivariate 
repeated measures analysis with within-subjects factors. The univariate 
analysis is:

my.aov <- aov(y~f*g*d + Error(block/f),data=sm2)

where f is the between-subjects factor and g and d are within-subjects 
factors.

I believe this can also be analyzed as a multivariate design but I don't 
see how to set it up.

Rick B.



From gisar at nus.edu.sg  Sun Jan 19 08:16:03 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Sun Jan 19 08:16:03 2003
Subject: [R] Rearranging subtrees and Eisen Cluster
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053EAD@MBXSRV03.stf.nus.edu.sg>

I am attempting to replicate what Cluster 3.0 and Treeview (both by Mike
Eisen) to cluster both microarray genes and arrays does using R with
hclust. I basically utilized the plot.mat function in sma library with
some layout() and hclust().

1. Can I know if some has already written such a function or available
in some package.

2. If not, would appreciate if someone could take the time to test the
function as I only had time to test on a few datasets. Any feed back is
much appreciated. The function is called ecluster.fn and I have also
attached a simple example on how to use it. 

So far my code works (attached) fine. The only problem is that subtree
are ordered in terms of the 'tightest' leftmost (according to the
details section of hclust) . So sometimes I have blocks of red, green
and then red (again) although the branches can be mannually reorder ed
so that most of the reds are to one side and most of the reds. This gets
a bit more complicated when rows are also to be ordered. I don't time to
manually reorder every dataset and want to automate the process.

3. How do we create a criterion to arrange the subtrees in such a way to
show most visual distinction. Sorry if this is a bit vague.

Thank you very much.

Regards, Adai.

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ecluster.example.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030119/4c029f74/ecluster.example.txt
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ecluster.fn.R.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030119/4c029f74/ecluster.fn.R.txt

From mk36 at aub.edu.lb  Sun Jan 19 12:17:03 2003
From: mk36 at aub.edu.lb (Marwan Khawaja)
Date: Sun Jan 19 12:17:03 2003
Subject: [R] proxy connection
Message-ID: <CLECJBOEBGOMOKJHJNDAOEANCMAA.marwan.khawaja@aub.edu.lb>

Hello,
I a proxy connection to the internet, so I renamed the file 'internet2.dll' to
'internet.dll' in the Module subdirectory as suggested in Changes.
But I still get an error when trying to update packages:  'Rgui.exe has
generated errors and will be closed by Windows'
Any hint would be appreciated.
I know this has been discussed before but I do not seem to find the thread --
TIA Marwan Khawaja


platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.2            
year     2003           
month    01             
day      10             
language R         


--------------------------------------------------------------------------------
----------------------------------------------
Marwan Khawaja 	<http://webfaculty.aub.edu.lb/~mk36  if you have MS Explorer
--------------------------------------------------------------------------------
----------------------------------------------


-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 2080 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030119/6a532218/winmail.bin

From phil at lacertacapital.com  Sun Jan 19 13:03:02 2003
From: phil at lacertacapital.com (Phil Saunders)
Date: Sun Jan 19 13:03:02 2003
Subject: [R] Re: check variables: a Q from a beginner
Message-ID: <A5B74A99C30DBB46B9A819C3BD4A65F11916D2@blsvr-2.bluelizard.org.uk>

I like your ls.obj function - how might I turn it into a standard function for me whenever I launch R?

-----Original Message-----
From: David Hinds [mailto:David_Hinds at perlegen.com] 
Sent: 17 January 2003 20:58
To: r-help at stat.math.ethz.ch
Subject: [R] Re: check variables: a Q from a beginner


I played around a bit with the ls.objects() code posted by Petr Pikal yesterday and came up with the following that is a bit faster, shorter, and adds memory usage information.  It combines an object's mode and 
class information into a "Type" column that seems more parsimonious, and adds an argument for specifying a sort column.

-- Dave Hinds


ls.obj <- function (pos = 1, pattern, order.by)
{
    napply <- function(names, fn)
        sapply(names, function(x) fn(get(x, pos = pos)))
    names <- ls(pos = pos, pattern = pattern)
    obj.class <- napply(names, function(x) as.character(class(x))[1])
    obj.mode <- napply(names, mode)
    obj.type <- ifelse(is.na(obj.class),obj.mode,obj.class)
    obj.size <- napply(names, object.size)

    obj.dim <- t(napply(names, function(x) as.numeric(dim(x))[1:2]))
    vec <- is.na(obj.dim)[,1] & (obj.type != 'function')
    obj.dim[vec,1] <- napply(names, length)[vec]

    out <- data.frame(obj.type,obj.size,obj.dim)
    names(out) <- c("Type","Size","Rows","Columns")
    if (!missing(order.by)) out <- out[order(out[[order.by]]),]
    out
}

> ls.obj(o=2)
                   Type    Size Rows Columns
db              numeric      36    1      NA
A             character     100    6      NA
U             character     100    6      NA
fetch          function    2924   NA      NA
ls.obj         function    9848   NA      NA
get.snp.data   function   15692   NA      NA
hap.fit        function   16124   NA      NA
get.hap.info   function   22476   NA      NA
bb           data.frame   32676  534       7
snp.data     data.frame  621936 3873      20
hap.data           list 1426080  571      NA
s                  list 1901952  566      NA

______________________________________________
R-help at stat.math.ethz.ch mailing list http://www.stat.math.ethz.ch/mailman/listinfo/r-help

________________________________________________________________________
This email has been scanned for all viruses by the MessageLabs SkyScan
service. For more information on a proactive anti-virus service working
around the clock, around the globe, visit http://www.messagelabs.com



From ripley at stats.ox.ac.uk  Sun Jan 19 13:15:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Jan 19 13:15:04 2003
Subject: [R] Re: check variables: a Q from a beginner
In-Reply-To: <A5B74A99C30DBB46B9A819C3BD4A65F11916D2@blsvr-2.bluelizard.org.uk>
Message-ID: <Pine.LNX.4.44.0301191212530.28957-100000@gannet.stats>

On Sun, 19 Jan 2003, Phil Saunders wrote:

> I like your ls.obj function - how might I turn it into a standard function for me whenever I launch R?

1) put it in your .Rprofile, or in the site Rprofile (Unix only).

2) put it in a package, and arrange to load that at startup.

See ?Startup.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Sun Jan 19 15:48:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Jan 19 15:48:03 2003
Subject: [R] proxy connection
References: <CLECJBOEBGOMOKJHJNDAOEANCMAA.marwan.khawaja@aub.edu.lb>
Message-ID: <3E2ABA5A.67AB287C@statistik.uni-dortmund.de>

Marwan Khawaja wrote:
> 
> Hello,
> I a proxy connection to the internet, so I renamed the file 'internet2.dll' to
> 'internet.dll' in the Module subdirectory as suggested in Changes.

That *was* true for for R-1.3.0, but since R-1.4.0 the same file tells
you:

"internet2.dll (see changes for rw1030) must be selected by the
--internet2 flag."

Uwe Ligges

> But I still get an error when trying to update packages:  'Rgui.exe has
> generated errors and will be closed by Windows'
> Any hint would be appreciated.
> I know this has been discussed before but I do not seem to find the thread --
> TIA Marwan Khawaja
> 
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R



From ligges at statistik.uni-dortmund.de  Sun Jan 19 15:56:02 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Jan 19 15:56:02 2003
Subject: [R] proxy connection
References: <CLECJBOEBGOMOKJHJNDAOEANCMAA.marwan.khawaja@aub.edu.lb> <3E2ABA5A.67AB287C@statistik.uni-dortmund.de>
Message-ID: <3E2ABB4A.DE7DCBFD@statistik.uni-dortmund.de>

Uwe Ligges wrote:
> 
> Marwan Khawaja wrote:
> >
> > Hello,
> > I a proxy connection to the internet, so I renamed the file 'internet2.dll' to
> > 'internet.dll' in the Module subdirectory as suggested in Changes.
> 
> That *was* true for for R-1.3.0, but since R-1.4.0 the same file tells
> you:
> 
> "internet2.dll (see changes for rw1030) must be selected by the
> --internet2 flag."
> 
> Uwe Ligges

BTW: See ?download.file for details.

Uwe Ligges

> > But I still get an error when trying to update packages:  'Rgui.exe has
> > generated errors and will be closed by Windows'
> > Any hint would be appreciated.
> > I know this has been discussed before but I do not seem to find the thread --
> > TIA Marwan Khawaja
> >
> > platform i386-pc-mingw32
> > arch     i386
> > os       mingw32
> > system   i386, mingw32
> > status
> > major    1
> > minor    6.2
> > year     2003
> > month    01
> > day      10
> > language R



From tbm at cyrius.com  Mon Jan 20 01:12:02 2003
From: tbm at cyrius.com (Martin Michlmayr)
Date: Mon Jan 20 01:12:02 2003
Subject: [R] quadratic trends and changes in slopes
Message-ID: <20030120001124.GA874@regression.cyrius.com>

I'd like to use linear and quadratic trend analysis in order to find
out a change in slope.  Basically, I need to solve a similar problem as
discussed in http://www.gseis.ucla.edu/courses/ed230bc1/cnotes4/trend1.html

My subjects have counted dots: one dot, two dots, etc. up to 9 dots.
The reaction time increases with increasing dots.  The theory is that
1 up to 3 or 4 points can be counted relatively fast (a process known
as "subiziting") but that is becomes slower at around 5 dots ("counting").
The question is when the slope changes.  Most papers in the literature
determine this by checking when it changes from being a linear trend to
a quadratric trend. i.e deviation from linearity is seen as evidence
that the second, slower process is used.

I'd like to test the ranges 1-2, 1-3, 1-4, 1-5, 1-6, etc and see when
a qudratric trend is significant.  However, although I have read some
literature and done many google searches, I cannot figure out how to
do this with R.  Can anyone show me a simple example of how to do
this. (Either with the method described above or with a different
method -- but please note that I only have 9 data points, tho; 1:9).

Any help is appreciated.

Thanks.


FWIW, here's the description from one paper using this method:

"For both conditions, the subitizing range for each group was established
using quadratic trend tests on the aggregated RT data for numerosities 1-3,
1-4, and so on (Akin and Chase, 1978; Chi and Klahr, 1975; Pylyshyn,
1993). For both groups the first appearance of a quadratic trend was in
the N=1-5 range (t(9) = 7.33, p< .001 for the control group, and t(5) =
5.35, p = .005 for the Turner group). This indicates a subitizing range
of 4 for both groups. This divergence from a linear increase in RT
suggests the deployment of a new process for the last numerosity added."

-- 
Martin Michlmayr
tbm at cyrius.com



From lopezurrutia at hotmail.com  Mon Jan 20 02:09:03 2003
From: lopezurrutia at hotmail.com (Angel Lopez-Urrutia)
Date: Mon Jan 20 02:09:03 2003
Subject: [R] Fortran linking problems
Message-ID: <F90J1aY54OMeH3nxuUJ0000a812@hotmail.com>

In a box running Mandrake 9 with R 1.6.2 I get problems when trying to 
install packages Matrix and Akima.
It seems my gcc compiler and fortran do not talk to each other.

Thanks in advance for any help,
Gelu

The errors are:

* Installing *source* package 'Matrix' ...
checking for gcc... gcc
checking for C compiler default output... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ANSI C... none needed
checking whether we are using the GNU Fortran 77 compiler... yes
checking whether g77 accepts -g... yes
checking how to get verbose linking output from g77... -v
checking for Fortran 77 libraries... -L/usr/local/lib 
-L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2 
-L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../.. -lreadline -ldl 
-lncurses -lfrtbegin -lg2c -lm -lgcc_s
checking for dummy main to link with Fortran 77 libraries... unknown
configure: error: linking to Fortran libraries from C fails
ERROR: configuration failed for package 'Matrix'



# R CMD INSTALL akima_0.3-4.tar.gz
* Installing *source* package 'akima' ...
** libs
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c 
akima.new.f -o akima.new.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c idbvip.f 
-o idbvip.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c idcldp.f 
-o idcldp.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c idgrid.f 
-o idgrid.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c idlctn.f 
-o idlctn.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c idpdrv.f 
-o idpdrv.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c idptip.f 
-o idptip.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c idptli.f 
-o idptli.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c idsfft.f 
-o idsfft.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c idtang.f 
-o idtang.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c idxchg.f 
-o idxchg.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c 
tripack.f -o tripack.o
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 
-fno-fast-math -fno-strength-reduce  -O3 -fomit-frame-pointer -pipe 
-mcpu=pentiumpro -march=i586 -fno-fast-math -fno-strength-reduce -c ttidbs.f 
-o ttidbs.o
gcc -shared -L/usr/local/lib -o akima.so akima.new.o idbvip.o idcldp.o 
idgrid.o idlctn.o idpdrv.o idptip.o idptli.o idsfft.o idtang.o idxchg.o 
tripack.o ttidbs.o  -L/usr/local/lib 
-L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2 
-L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../.. -lreadline -ldl 
-lncurses -lfrtbegin -lg2c -lm -lgcc_s -L/usr/lib/R/bin -lR
/usr/bin/ld: cannot find -lreadline
collect2: ld returned 1 exit status
make: *** [akima.so] Error 1
ERROR: compilation failed for package 'akima'




From laurent at cbs.dtu.dk  Mon Jan 20 06:42:03 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Mon Jan 20 06:42:03 2003
Subject: [R] make check for R-1.6.2 on IBM AIX
Message-ID: <20030120054148.GE305458742@genome.cbs.dtu.dk>

Dear all,

The 'make check' step fails for the pacakge mva on IBM AIX.
The tail of the Rout log file looks like:

> for(factors in 2:4) print(update(Harman23.FA, factors = factors))

Call:
factanal(factors = factors, covmat = Harman23.cor)

Uniquenesses:
        height       arm.span        forearm      lower.leg         weight 
         0.170          0.107          0.166          0.199          0.089 
bitro.diameter    chest.girth    chest.width 
         0.364          0.416          0.537 

Loadings:
               Factor1 Factor2
height         0.865   0.287  
arm.span       0.927   0.181  
forearm        0.895   0.179  
lower.leg      0.859   0.252  
weight         0.233   0.925  
bitro.diameter 0.194   0.774  
chest.girth    0.134   0.752  
chest.width    0.278   0.621  

               Factor1 Factor2
SS loadings      3.335   2.617
Proportion Var   0.417   0.327
Cumulative Var   0.417   0.744

Test of the hypothesis that 2 factors are sufficient.
The chi square statistic is 75.74 on 13 degrees of freedom.
The p-value is 6.94e-11 

Call:
factanal(factors = factors, covmat = Harman23.cor)

Uniquenesses:
        height       arm.span        forearm      lower.leg         weight 
         0.127          0.005          0.193          0.157          0.090 
bitro.diameter    chest.girth    chest.width 
         0.359          0.411          0.490 

Loadings:
               Factor1 Factor2 Factor3
height          0.886   0.267  -0.130 
arm.span        0.937   0.195   0.280 
forearm         0.874   0.188         
lower.leg       0.877   0.230  -0.145 
weight          0.242   0.916  -0.106 
bitro.diameter  0.193   0.777         
chest.girth     0.137   0.755         
chest.width     0.261   0.646   0.159 

               Factor1 Factor2 Factor3
SS loadings      3.379   2.628   0.162
Proportion Var   0.422   0.329   0.020
Cumulative Var   0.422   0.751   0.771

Test of the hypothesis that 3 factors are sufficient.
The chi square statistic is 22.81 on 7 degrees of freedom.
The p-value is 0.00184 
Error in La.svd(B) : error code 3 from Lapack routine dgesdd
Execution halted


Any hint ?



Laurent



From phgrosjean at sciviews.org  Mon Jan 20 08:24:03 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Mon Jan 20 08:24:03 2003
Subject: [R] Announce: pmg -- menu driven GUI using RGtk
Message-ID: <MABBLJDICACNFOLGIHJOOELMDCAA.phgrosjean@sciviews.org>

Hello,

I have added a link to it from http://www.r-project.org/GUI. Thanks.
Best regards,

Philippe

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



From ripley at stats.ox.ac.uk  Mon Jan 20 08:57:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan 20 08:57:03 2003
Subject: [R] Fortran linking problems
In-Reply-To: <F90J1aY54OMeH3nxuUJ0000a812@hotmail.com>
Message-ID: <Pine.LNX.4.44.0301200750440.30040-100000@gannet.stats>

Did you build R yourself, or install an rpm?  It looks like your
installation is missing libreadline, and it was there when R was built.
I'm surprised then that R would run, but maybe it is somewhere that the 
standard LD_LIBRARY_PATH does not find.

You need readline and perhaps readline-devel (if it exists)
installed, and they should have been dependencies of the R rpm (if that
is what you used).

I believe that -lreadline is not needed (and this is solved in R-devel),
so you could just edit R_HOME/etc/Makeconf and remove -lreadline (and
-lnurses) from FLIBS.


On Mon, 20 Jan 2003, Angel Lopez-Urrutia wrote:

> In a box running Mandrake 9 with R 1.6.2 I get problems when trying to 
> install packages Matrix and Akima.
> It seems my gcc compiler and fortran do not talk to each other.

> The errors are:
> 
> * Installing *source* package 'Matrix' ...
> checking for gcc... gcc
> checking for C compiler default output... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ANSI C... none needed
> checking whether we are using the GNU Fortran 77 compiler... yes
> checking whether g77 accepts -g... yes
> checking how to get verbose linking output from g77... -v
> checking for Fortran 77 libraries... -L/usr/local/lib 
> -L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2 
> -L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../.. -lreadline -ldl 
> -lncurses -lfrtbegin -lg2c -lm -lgcc_s
> checking for dummy main to link with Fortran 77 libraries... unknown
> configure: error: linking to Fortran libraries from C fails
> ERROR: configuration failed for package 'Matrix'

In cases like that, look in config.log.  The error message is terse, 
because it is repeating a test done when R was installed.

[...]

> gcc -shared -L/usr/local/lib -o akima.so akima.new.o idbvip.o idcldp.o 
> idgrid.o idlctn.o idpdrv.o idptip.o idptli.o idsfft.o idtang.o idxchg.o 
> tripack.o ttidbs.o  -L/usr/local/lib 
> -L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2 
> -L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../.. -lreadline -ldl 
> -lncurses -lfrtbegin -lg2c -lm -lgcc_s -L/usr/lib/R/bin -lR
> /usr/bin/ld: cannot find -lreadline
> collect2: ld returned 1 exit status
> make: *** [akima.so] Error 1
> ERROR: compilation failed for package 'akima'

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ozric at web.de  Mon Jan 20 09:06:03 2003
From: ozric at web.de (Christian Schulz)
Date: Mon Jan 20 09:06:03 2003
Subject: [R] curious code mistakes
Message-ID: <001701c2c05a$32fa9db0$60b907d5@c5c9i0>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030120/0a2cf480/attachment.pl

From ripley at stats.ox.ac.uk  Mon Jan 20 09:09:31 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan 20 09:09:31 2003
Subject: [R] make check for R-1.6.2 on IBM AIX
In-Reply-To: <20030120054148.GE305458742@genome.cbs.dtu.dk>
Message-ID: <Pine.LNX.4.44.0301200800180.30040-100000@gannet.stats>

Is this a vanilla installation, not using any BLAS routines?  If so, that
error code means that the svd was called with a negative number of columns
(&p in the call).  I don't see how that can happen without some memory
corruption.

The usual ideas apply: run that example on its own, then look at
traceback(), add debugging code etc ....

We have seen similar (but not the same) issues where a BLAS was used that 
contained (broken) parts of LAPACK.

On Mon, 20 Jan 2003, Laurent Gautier wrote:

> Dear all,
> 
> The 'make check' step fails for the pacakge mva on IBM AIX.
> The tail of the Rout log file looks like:
> 
> > for(factors in 2:4) print(update(Harman23.FA, factors = factors))
> 
> Call:
> factanal(factors = factors, covmat = Harman23.cor)
> 
> Uniquenesses:
>         height       arm.span        forearm      lower.leg         weight 
>          0.170          0.107          0.166          0.199          0.089 
> bitro.diameter    chest.girth    chest.width 
>          0.364          0.416          0.537 
> 
> Loadings:
>                Factor1 Factor2
> height         0.865   0.287  
> arm.span       0.927   0.181  
> forearm        0.895   0.179  
> lower.leg      0.859   0.252  
> weight         0.233   0.925  
> bitro.diameter 0.194   0.774  
> chest.girth    0.134   0.752  
> chest.width    0.278   0.621  
> 
>                Factor1 Factor2
> SS loadings      3.335   2.617
> Proportion Var   0.417   0.327
> Cumulative Var   0.417   0.744
> 
> Test of the hypothesis that 2 factors are sufficient.
> The chi square statistic is 75.74 on 13 degrees of freedom.
> The p-value is 6.94e-11 
> 
> Call:
> factanal(factors = factors, covmat = Harman23.cor)
> 
> Uniquenesses:
>         height       arm.span        forearm      lower.leg         weight 
>          0.127          0.005          0.193          0.157          0.090 
> bitro.diameter    chest.girth    chest.width 
>          0.359          0.411          0.490 
> 
> Loadings:
>                Factor1 Factor2 Factor3
> height          0.886   0.267  -0.130 
> arm.span        0.937   0.195   0.280 
> forearm         0.874   0.188         
> lower.leg       0.877   0.230  -0.145 
> weight          0.242   0.916  -0.106 
> bitro.diameter  0.193   0.777         
> chest.girth     0.137   0.755         
> chest.width     0.261   0.646   0.159 
> 
>                Factor1 Factor2 Factor3
> SS loadings      3.379   2.628   0.162
> Proportion Var   0.422   0.329   0.020
> Cumulative Var   0.422   0.751   0.771
> 
> Test of the hypothesis that 3 factors are sufficient.
> The chi square statistic is 22.81 on 7 degrees of freedom.
> The p-value is 0.00184 
> Error in La.svd(B) : error code 3 from Lapack routine dgesdd
> Execution halted
> 
> 
> Any hint ?
> 
> 
> 
> Laurent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From laurent at cbs.dtu.dk  Mon Jan 20 09:47:02 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Mon Jan 20 09:47:02 2003
Subject: [R] make check for R-1.6.2 on IBM AIX
In-Reply-To: <Pine.LNX.4.44.0301200800180.30040-100000@gannet.stats>
References: <20030120054148.GE305458742@genome.cbs.dtu.dk> <Pine.LNX.4.44.0301200800180.30040-100000@gannet.stats>
Message-ID: <20030120084638.GI305458742@genome.cbs.dtu.dk>

On Mon, Jan 20, 2003 at 08:05:53AM +0000, ripley at stats.ox.ac.uk wrote:
> Is this a vanilla installation, not using any BLAS routines?  If so, that
> error code means that the svd was called with a negative number of columns
> (&p in the call).  I don't see how that can happen without some memory
> corruption.

Thanks for fast answer.

This is a vanilla (trial of) install. The funny thing is that it


I tried a 
source("tests/Examples/mva.R")

and get:

Error in optim(start, FAfn, FAgr, method = "L-BFGS-B", lower = lower,  : 
        non-finite value supplied by optim
In addition: Warning messages: 
1: dist(.,"binary"): treating non-finite values as NA 
2: dist(.,"binary"): treating non-finite values as NA 
>
> traceback()
6: optim(start, FAfn, FAgr, method = "L-BFGS-B", lower = lower, 
       upper = 1, control = c(list(fnscale = 1, parscale = rep(0.01, 
           length(start))), control), q = factors, S = cmat)
5: factanal.fit.mle(cv, factors, start[, i], max(cn$lower, 0), cn$opt)
4: factanal(~v1 + v2 + v3 + v4 + v5 + v6, factors = 3, scores = "Bartlett")
3: eval.with.vis(expr, envir, enclos)
2: eval.with.vis(ei, envir)
1: source("tests/Examples/mva-Ex.R")


I tried make check on the 1.6.1 I installed 2 weeks ago (I can't remember
for sure if I did 'make check', but usually I do).. and make check dies
on base (see below)

> ## Keywords: 'math'.
> 
> 
> cleanEx(); ..nameEx <- "kronecker"
> ###--- >>> `kronecker' <<<----- Kronecker products on arrays
> 
>       ## alias         help(kronecker)
>       ## alias         help(\%x\%)
> 
> ##___ Examples ___:
> 
> # simple scalar multiplication
> ( M <- matrix(1:6, ncol=2) )
     [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
> stopifnot(kronecker(4, M)==4 * M)
Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r))) stop(paste(deparse(mc[[i +  : 
        missing value where logical needed
Execution halted


Your hypothesis of 'physical' reasons for the fail seems really worth a look at.
Would anyone know how to check hardware integrity on an IBM AIX ?


Thanks in advance,



L.

> 
> The usual ideas apply: run that example on its own, then look at
> traceback(), add debugging code etc ....
> 
> We have seen similar (but not the same) issues where a BLAS was used that 
> contained (broken) parts of LAPACK.
> 
> On Mon, 20 Jan 2003, Laurent Gautier wrote:
> 
> > Dear all,
> > 
> > The 'make check' step fails for the pacakge mva on IBM AIX.
> > The tail of the Rout log file looks like:
> > 
> > > for(factors in 2:4) print(update(Harman23.FA, factors = factors))
> > 
> > Call:
> > factanal(factors = factors, covmat = Harman23.cor)
> > 
> > Uniquenesses:
> >         height       arm.span        forearm      lower.leg         weight 
> >          0.170          0.107          0.166          0.199          0.089 
> > bitro.diameter    chest.girth    chest.width 
> >          0.364          0.416          0.537 
> > 
> > Loadings:
> >                Factor1 Factor2
> > height         0.865   0.287  
> > arm.span       0.927   0.181  
> > forearm        0.895   0.179  
> > lower.leg      0.859   0.252  
> > weight         0.233   0.925  
> > bitro.diameter 0.194   0.774  
> > chest.girth    0.134   0.752  
> > chest.width    0.278   0.621  
> > 
> >                Factor1 Factor2
> > SS loadings      3.335   2.617
> > Proportion Var   0.417   0.327
> > Cumulative Var   0.417   0.744
> > 
> > Test of the hypothesis that 2 factors are sufficient.
> > The chi square statistic is 75.74 on 13 degrees of freedom.
> > The p-value is 6.94e-11 
> > 
> > Call:
> > factanal(factors = factors, covmat = Harman23.cor)
> > 
> > Uniquenesses:
> >         height       arm.span        forearm      lower.leg         weight 
> >          0.127          0.005          0.193          0.157          0.090 
> > bitro.diameter    chest.girth    chest.width 
> >          0.359          0.411          0.490 
> > 
> > Loadings:
> >                Factor1 Factor2 Factor3
> > height          0.886   0.267  -0.130 
> > arm.span        0.937   0.195   0.280 
> > forearm         0.874   0.188         
> > lower.leg       0.877   0.230  -0.145 
> > weight          0.242   0.916  -0.106 
> > bitro.diameter  0.193   0.777         
> > chest.girth     0.137   0.755         
> > chest.width     0.261   0.646   0.159 
> > 
> >                Factor1 Factor2 Factor3
> > SS loadings      3.379   2.628   0.162
> > Proportion Var   0.422   0.329   0.020
> > Cumulative Var   0.422   0.751   0.771
> > 
> > Test of the hypothesis that 3 factors are sufficient.
> > The chi square statistic is 22.81 on 7 degrees of freedom.
> > The p-value is 0.00184 
> > Error in La.svd(B) : error code 3 from Lapack routine dgesdd
> > Execution halted
> > 
> > 
> > Any hint ?
> > 
> > 
> > 
> > Laurent
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 

-- 
--------------------------------------------------------------
currently at the National Yang-Ming University in Taipei, Taiwan
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent



From ligges at statistik.uni-dortmund.de  Mon Jan 20 10:16:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Jan 20 10:16:03 2003
Subject: [R] curious code mistakes
In-Reply-To: <001701c2c05a$32fa9db0$60b907d5@c5c9i0>
References: <001701c2c05a$32fa9db0$60b907d5@c5c9i0>
Message-ID: <3E2BBE2F.9080401@statistik.uni-dortmund.de>

Christian Schulz wrote:
> hi,
> know anybody why this happen ?
> I'm using winedt , the old code saved in an .R 
> call syntax error's. Curious is, when i'm type below
> the  same code , it works ???
> 
> ...imho a print type problem, what i'm never before observed and 
> can't recognize with my eyes ?
> 
> P.S. R.1.6.1 /w2k
> 
> thanks for advance 
> & regards,christian
> 

So what are you doing? It looks like you didn't use source(), but 
copy&paste for your "old" code?


>>>getfile <- function() {

Where do the *three* ">" come from?


> +               name <- tclvalue(tkgetOpenFile(filetypes="{{SPSS files} {.sav}} {{All files} *}"))
> Error: syntax error

WinEdt is a powerful editor - that includes many ways for 
misconfiguration. You might want to look with an appropriate editor 
(e.g. any hex editor) into what you have produced ...; this can be done 
by WinEdt as well: Open the file in the standard WinEdt in mode "binary" 
- it won't show you exact results, but at least it marks non blanks and 
line endings differently.

Uwe Ligges


>>>       if (name == "") return;
> 
> Error: syntax error
> 
>>>       zz <- read.spss(name, use.value.label=T, to.data.frame=T)
> 
> Error: syntax error
> 
>>>       assign("myData", zz, envir = .GlobalEnv)
> 
> Error: syntax error
> 
>>>}
> 
> Error: syntax error
> 
>>>tt <- tktoplevel()
>>>button.widget <- tkbutton(tt,text="Select SPSSFile", command=getfile)
> 
> Error in .Tcl.args(...) : Object "getfile" not found
> 
>>>tkpack(button.widget)
> 
> Error in .Tcl.args(...) : Object "button.widget" not found
> 
>>>
>>>getfile <- function()  {
> 
> +           name <- tclvalue(tkgetOpenFile(filetypes="{{SPSS Files} {.sav}} {{All files} *}"))
> +           if (name=="") return;
> +           zz <- read.spss(name,use.value.label=T,to.data.frame=T)
> +           assign("myData",zz,envir=.GlobalEnv)
> +       }
> 
>>>tt <- tktoplevel()
>>>button.widget <- tkbutton(tt,text="Select SPSS File",command=getfile)
>>>tkpack(button.widget)
> 
> <Tcl>  
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ozric at web.de  Mon Jan 20 11:12:05 2003
From: ozric at web.de (Christian Schulz)
Date: Mon Jan 20 11:12:05 2003
Subject: [R] curious code mistakes
References: <001701c2c05a$32fa9db0$60b907d5@c5c9i0> <3E2BBE2F.9080401@statistik.uni-dortmund.de>
Message-ID: <000b01c2c06b$c42fb610$483d07d5@c5c9i0>

many Thanks for hex-editor suggestion ,
it's a copy paste problem !
christian


----- Original Message -----
From: "Uwe Ligges" <ligges at statistik.uni-dortmund.de>
To: "Christian Schulz" <ozric at web.de>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, January 20, 2003 10:15 AM
Subject: Re: [R] curious code mistakes


> Christian Schulz wrote:
> > hi,
> > know anybody why this happen ?
> > I'm using winedt , the old code saved in an .R
> > call syntax error's. Curious is, when i'm type below
> > the  same code , it works ???
> >
> > ...imho a print type problem, what i'm never before observed and
> > can't recognize with my eyes ?
> >
> > P.S. R.1.6.1 /w2k
> >
> > thanks for advance
> > & regards,christian
> >
>
> So what are you doing? It looks like you didn't use source(), but
> copy&paste for your "old" code?
>
>
> >>>getfile <- function() {
>
> Where do the *three* ">" come from?
>
>
> > +               name <- tclvalue(tkgetOpenFile(filetypes="{{SPSS files}
{.sav}} {{All files} *}"))
> > Error: syntax error
>
> WinEdt is a powerful editor - that includes many ways for
> misconfiguration. You might want to look with an appropriate editor
> (e.g. any hex editor) into what you have produced ...; this can be done
> by WinEdt as well: Open the file in the standard WinEdt in mode "binary"
> - it won't show you exact results, but at least it marks non blanks and
> line endings differently.
>
> Uwe Ligges
>
>
> >>>       if (name == "") return;
> >
> > Error: syntax error
> >
> >>>       zz <- read.spss(name, use.value.label=T, to.data.frame=T)
> >
> > Error: syntax error
> >
> >>>       assign("myData", zz, envir = .GlobalEnv)
> >
> > Error: syntax error
> >
> >>>}
> >
> > Error: syntax error
> >
> >>>tt <- tktoplevel()
> >>>button.widget <- tkbutton(tt,text="Select SPSSFile", command=getfile)
> >
> > Error in .Tcl.args(...) : Object "getfile" not found
> >
> >>>tkpack(button.widget)
> >
> > Error in .Tcl.args(...) : Object "button.widget" not found
> >
> >>>
> >>>getfile <- function()  {
> >
> > +           name <- tclvalue(tkgetOpenFile(filetypes="{{SPSS Files}
{.sav}} {{All files} *}"))
> > +           if (name=="") return;
> > +           zz <- read.spss(name,use.value.label=T,to.data.frame=T)
> > +           assign("myData",zz,envir=.GlobalEnv)
> > +       }
> >
> >>>tt <- tktoplevel()
> >>>button.widget <- tkbutton(tt,text="Select SPSS File",command=getfile)
> >>>tkpack(button.widget)
> >
> > <Tcl>
> >
> >
> > [[alternate HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From perbak at brunet.bn  Mon Jan 20 11:51:05 2003
From: perbak at brunet.bn (Per Bak)
Date: Mon Jan 20 11:51:05 2003
Subject: [R] Plotting w/multiple y-axes?
Message-ID: <200301201851.34997.perbak@brunet.bn>

How do I plot using multiple(2) y-axes? 
I have two series that use the same x-data, but have very different scales. 

Appreciate any feedback,

Per Bak



From lopezurrutia at hotmail.com  Mon Jan 20 12:26:03 2003
From: lopezurrutia at hotmail.com (Angel Lopez-Urrutia)
Date: Mon Jan 20 12:26:03 2003
Subject: [R] Fortran linking problems
Message-ID: <F90FKmdSklLuBSEpU0e0000bda6@hotmail.com>

Thanks to all,
Once I installed readline-dev (and reinstalled Blas/lapack) it worked!
I don't know it why this wasn't shown as a dependency when I installed the R 
rpm!
Thanks,
Gelu


----Original Message Follows----
From: ripley at stats.ox.ac.uk
To: Angel Lopez-Urrutia <lopezurrutia at hotmail.com>
CC: r-help at stat.math.ethz.ch
Subject: Re: [R] Fortran linking problems
Date: Mon, 20 Jan 2003 07:56:20 +0000 (GMT)

Did you build R yourself, or install an rpm?  It looks like your
installation is missing libreadline, and it was there when R was built.
I'm surprised then that R would run, but maybe it is somewhere that the
standard LD_LIBRARY_PATH does not find.

You need readline and perhaps readline-devel (if it exists)
installed, and they should have been dependencies of the R rpm (if that
is what you used).

I believe that -lreadline is not needed (and this is solved in R-devel),
so you could just edit R_HOME/etc/Makeconf and remove -lreadline (and
-lnurses) from FLIBS.


On Mon, 20 Jan 2003, Angel Lopez-Urrutia wrote:

 > In a box running Mandrake 9 with R 1.6.2 I get problems when trying to
 > install packages Matrix and Akima.
 > It seems my gcc compiler and fortran do not talk to each other.

 > The errors are:
 >
 > * Installing *source* package 'Matrix' ...
 > checking for gcc... gcc
 > checking for C compiler default output... a.out
 > checking whether the C compiler works... yes
 > checking whether we are cross compiling... no
 > checking for suffix of executables...
 > checking for suffix of object files... o
 > checking whether we are using the GNU C compiler... yes
 > checking whether gcc accepts -g... yes
 > checking for gcc option to accept ANSI C... none needed
 > checking whether we are using the GNU Fortran 77 compiler... yes
 > checking whether g77 accepts -g... yes
 > checking how to get verbose linking output from g77... -v
 > checking for Fortran 77 libraries... -L/usr/local/lib
 > -L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2
 > -L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../.. -lreadline -ldl
 > -lncurses -lfrtbegin -lg2c -lm -lgcc_s
 > checking for dummy main to link with Fortran 77 libraries... unknown
 > configure: error: linking to Fortran libraries from C fails
 > ERROR: configuration failed for package 'Matrix'

In cases like that, look in config.log.  The error message is terse,
because it is repeating a test done when R was installed.

[...]

 > gcc -shared -L/usr/local/lib -o akima.so akima.new.o idbvip.o idcldp.o
 > idgrid.o idlctn.o idpdrv.o idptip.o idptli.o idsfft.o idtang.o idxchg.o
 > tripack.o ttidbs.o  -L/usr/local/lib
 > -L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2
 > -L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../.. -lreadline -ldl
 > -lncurses -lfrtbegin -lg2c -lm -lgcc_s -L/usr/lib/R/bin -lR
 > /usr/bin/ld: cannot find -lreadline
 > collect2: ld returned 1 exit status
 > make: *** [akima.so] Error 1
 > ERROR: compilation failed for package 'akima'

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From boiko at demogr.mpg.de  Mon Jan 20 12:44:02 2003
From: boiko at demogr.mpg.de (Serge Boiko)
Date: Mon Jan 20 12:44:02 2003
Subject: [R] getting attributes of graphics objects
Message-ID: <m23cnof150.fsf@boiko_linux.demogr.mpg.de>

Hi there;
Is there a facility to query/get/modify graphics attributes in R? I mean
something similar to Matlab's get/set functions, say in order to get x and
y data in Matlab I use:

h=get(gcf, 'children')
xdata=get(h(1), 'xdata') % get x of the first children

Is there an R's counterpart? 

I'm aware of dev.copy() function, but it is of little help in this
situation. 

Many thanks, 
-Serge



From dvumani at hotmail.com  Mon Jan 20 14:00:04 2003
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Mon Jan 20 14:00:04 2003
Subject: [R] R analogue
Message-ID: <F173CoXsqZQF7GXXbE800013b72@hotmail.com>

Dear R users:

Is there any R analogue for the S+ function "na.gam.replace". I would like 
to make an interaction of a categorical and smooth continuous covariate.

Thanks.



Vumani Dlamini
Central Statistical Office
Swaziland



From pac at Uhb.Fr  Mon Jan 20 14:17:03 2003
From: pac at Uhb.Fr (Pierre-Andre Cornillon)
Date: Mon Jan 20 14:17:03 2003
Subject: [R] R and gdb
Message-ID: <Pine.LNX.4.44.0301201126480.20260-100000@sa2391.rec.uhb.fr>

Hi,

I have some problem with setting breakpoints with gdb in order to debug
some shared library for R.
Classical use of gdb work well
gcc -g -o footest.o footest.c
gdb footest.o
b 2
run
...

but as i tried to use it with R :
$ R -d gdb
GNU gdb 5.2.1
Copyright 2002 Free Software Foundation, Inc.
GDB is free software, covered by the GNU General Public License, and you
are
welcome to change it and/or distribute copies of it under certain
conditions.
Type "show copying" to see the conditions.
There is absolutely no warranty for GDB.  Type "show warranty" for
details.
This GDB was configured as "sparc64-unknown-linux-gnu"...
(gdb) R
Starting program: /usr/local/lib/R/bin/R.bin

R : Copyright 2003, The R Development Core Team
Version 1.6.2  (2003-01-10)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

[Previously saved workspace restored]

> dyn.load("foo.so")
 "I type Control-C here"
Program received signal SIGINT, Interrupt.
0x703346f8 in select () from /lib/libc.so.6
(gdb) b foo.c:44
Breakpoint 1 at 0x705c62a4: file plssvd.c, line 44.
(gdb) signal 0
Continuing with no signal.
foo.r(Xcr,Ycr,2)

gives directly the final result without stopping at the breakpoints.

I tried to update R
from 1.6.1 to 1.62
and I tried to update gdb too (up to  5.2.1, the 5.3 version doesn't
compile smoothly on my platform)
-> nothing change

my system:
Ultrasparc 10, sparc Gnu-Linux Suse 7-3, gcc 2-95-3
kernel 2.4.14 (Suse standard)

Note that setting the same breakpoint with the same program on a
Pentium IV, Gnu-Linux Suse 7-3, gcc 2-95-3
kernel 2.4.14 (Suse standard) works perfectly...

Does anybody have some hints on this topic?

Pierre-Andre Cornillon

PS I do not compile with optimization option as sometimes gdb have some
trouble to set the breakpoints at the chosen line



From ripley at stats.ox.ac.uk  Mon Jan 20 14:21:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan 20 14:21:03 2003
Subject: [R] R analogue
In-Reply-To: <F173CoXsqZQF7GXXbE800013b72@hotmail.com>
Message-ID: <Pine.LNX.4.44.0301201313140.3161-100000@gannet.stats>

On Mon, 20 Jan 2003, Vumani Dlamini wrote:

> Is there any R analogue for the S+ function "na.gam.replace". 

No, for it is tailored for use by S's gam.

Some of the things it does are positively undesirable!  It uses mean
imputation for continuous variables, but for factors it makes NA into
another level, which silently assumes that all missing values are similar
and that they are going to occur with sufficient frequency in the
training data (and they may not occur at all).

> I would like 
> to make an interaction of a categorical and smooth continuous covariate.

You can do that without na.gam.replace: there is an example in the MASS 
scripts for the low-birth-weight data.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pwolf at wiwi.uni-bielefeld.de  Mon Jan 20 14:38:29 2003
From: pwolf at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Mon Jan 20 14:38:29 2003
Subject: [R] Tcl/Tk and mouse
Message-ID: <3E2BFB89.B0CFEA88@wiwi.uni-bielefeld.de>

 Within a loop I tried to draw some things in
 dependency on the position of the mouse.
 This works fine with R-1.5.1 but R-1.6.1
 requires to include some delay by
 Sys.sleep(delay)  with  delay>=0.015.
 For smaller values (e.g. 0.0001) the
 top level tcltk-window does not appear
 and so I am not able to control the elements
 to be plotted using the tcltk-widget.

 Question1: How can I force the tcltk-widget
            to appear / to get the position
            of the mouse within the loop?

 Question2: Why isn't it allowed to use the
            locator function with n=0, with
            the meaning to output the
            coordinates of the mouse?
            ( Then my problem can be
              solved without Tcl/Tk )

 Here is an example:

# Definition of function a:
#
####################################
a<-function(delay=0.015){
  library(tcltk)
  state <-tclVar("relax")
  number<-tclVar("100")
  top   <-tktoplevel()
  show  <-tklabel (top,textvariable=number)
  up    <-tkbutton(top,text="up")
  down  <-tkbutton(top,text="down")
  exit  <-tkbutton(top,text="exit",command=function()
tclvalue(state)<-"exit" )
  tkpack(show,up,down,exit)
  tkbind(up,  "<Enter>",function() tclvalue(state)<-"up" )
  tkbind(up,  "<Leave>",function() tclvalue(state)<-"relax" )
  tkbind(down,"<Enter>",function() tclvalue(state)<-"down" )
  tkbind(down,"<Leave>",function() tclvalue(state)<-"relax" )
  plot(1:400,type="n"); old<-1:2; x<-1; y<-200
  repeat{
    Sys.sleep(delay)
    choice <- tclvalue(state)
    if((x<-x+1)>400) break
    if(choice=="exit")break
    if(choice=="up"  ) y<-y+1
    if(choice=="down") y<-y-1
    if(choice=="relax")y<-y
    points(old[1],old[2],col="red")
    points(x,     y,     col="black")
    tclvalue(number) <- as.character(y)
    old<-c(x,y)
  }
  tkdestroy(top)
}
#
###############################
# a(0.01) is ok, a(0.0001) is not ok by:
#
# version:
# platform hppa2.0-hp-hpux10.20
# arch     hppa2.0
# os       hpux10.20
# system   hppa2.0, hpux10.20
# status
# major    1
# minor    6.1
# year     2002
# month    11
# day      01
# language R
##############################

Peter Wolf

-----------------------------

H.P. Wolf
University of Bielefeld, Germany
pwolf at wiwi.uni-bielefeld.de



From kjetil at entelnet.bo  Mon Jan 20 14:43:07 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon Jan 20 14:43:07 2003
Subject: [R] New package on CRAN
Message-ID: <3E2BC3FE.16655.3567E@localhost>

I have uploaded a new package to CRAN -
SenSrivastava

which contains the data sets for examples and exercices in 
the book (Springer Verlag)
"Regression Analysis
  Theory, Methods and Applications." by
A. Sen and M. Srivastava.


Kjetil Halvorsen



From perbak at brunet.bn  Mon Jan 20 15:03:02 2003
From: perbak at brunet.bn (Per Bak)
Date: Mon Jan 20 15:03:02 2003
Subject: [R] Plotting w/multiple y-axes?
In-Reply-To: <3E2BFDA5.25013.D0FC9A@localhost>
References: <3E2BFDA5.25013.D0FC9A@localhost>
Message-ID: <200301202203.42359.perbak@brunet.bn>

Hi Petr,

Thank you for taking the time to answer! 
I've deciphered your advanced function and cut it down to the bare bones. I 
did not know about the par(new=T) command and it also took me a while to sort 
out the axes. I'll take it from there.

Kind regards,

Per Bak,
Brunei

x <- 0:10
y1 <- x
y2 <- x^2

plot(x, y1, axes=F, ylab="", type="b")
axis(2, pretty(range(y1),10))

par(new=T)

plot(x, y2, axes=F, ylab="", type="b")
axis(4, pretty(range(y2),10))

axis(1,pretty(range(x),10))


On Monday 20 January 2003 12:46, Petr Pikal wrote:
> Hi
>
> On 20 Jan 2003 at 18:51, Per Bak wrote:
> > How do I plot using multiple(2) y-axes?
> > I have two series that use the same x-data, but have very different
> > scales.
>
> This is my function for plotting 2 y axes on the same graph. (not very well
> documented, but not so complicated either :-) Sometimes it gives you a
> warning.
> Requires either library chron (plotting dates on x axis) or  xDatum = F.
>
> plot.yy<-function(x,yright,yleft, xDatum=T, xlab = NULL, yylab=c("",""),
> pch=c(1,2), col=c(1,2), linky=F, smooth=0, lwds=1, ...)
>
> {
>
> par(mar=c(5,4,4,2),oma=c(0,0,0,3))
> plot(x,yright,axes=F,ylab="", xlab=xlab, pch=pch[1],col=col[1], ...)
> axis(4,pretty(range(yright,na.rm=T),10),col=col[1])
>
> if (linky) lines(x,yright,col=col[1], ...)
>
> if (smooth!=0) lines(supsmu(x,yright,span=smooth),col=col[1], lwd=lwds,
> ...)
>
> if(yylab[1]=="")
> mtext(deparse(substitute(yright)),side=4,outer=T,line=1, col=col[1], ...)
> else
> mtext(yylab[1],side=4,outer=T,line=1, col=col[1], ...)
>
> par(new=T)
> plot(x,yleft,ylab="", axes=F ,xlab=xlab, pch=pch[2],col=col[2], ...)
> box()
> axis(2,pretty(range(yleft,na.rm=T),10),col=col[2])
> if (xDatum) axis(1,dates(pretty(range(datum,na.rm=T),10)),
> labels=as.character(chron(pretty(range(datum,na.rm=T),10)),
> format=c("d/m/y"))) else axis(1,pretty(range(x,na.rm=T),10))
>
> if(yylab[2]=="")
> mtext(deparse(substitute(yleft)),side=2,line=2, col=col[2], ...)
> else
> mtext(yylab[2],side=2,line=2, col=col[2], ...)
>
>
> if (linky) lines(x,yleft,col=col[2], lty=2, ...)
> if (smooth!=0) lines(supsmu(x,yleft,span=smooth),col=col[2], lty=2,
> lwd=lwds, ...)
>
> }
>
> > Appreciate any feedback,
> >
> > Per Bak
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> CheersPetr Pikal
> Precheza a.s., Nabx.Dr.E.Bene?e 24, 750 62 Pxerov
> tel: +420581 252 257 ; 724 008 364
> petr.pikal at precheza.cz; p.pik at volny.cz
> fax +420581 252 561



From jonathan.williams at pharmacology.oxford.ac.uk  Mon Jan 20 15:38:05 2003
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Mon Jan 20 15:38:05 2003
Subject: [R] Too many e-mails
Message-ID: <NGBBKJEMOMLJFCOIEGCECEPCCDAA.jonathan.williams@pharm.ox.ac.uk>

Oh dear - I joined the R help mailing list last week,
in order to ask a specific question. I did not realise
that I would start to receive all e-mails to and from
the mailing list. Is there a way of letting me receive
only the answers to my own questions? If not, then can
you remove me from the mailing list?

Thanks,

Jonathan Williams

Jonathan Williams
OPTIMA
Radcliffe Infirmary
Woodstock Road
OXFORD OX2 6HE
Tel +1865 (2)24356



From parkhurs at indiana.edu  Mon Jan 20 15:49:05 2003
From: parkhurs at indiana.edu (David Parkhurst)
Date: Mon Jan 20 15:49:05 2003
Subject: [R] read.table(file="clipboard",...)  for R?
Message-ID: <002501c2c092$fd711500$f4414842@spea.indiana.edu>

I use read.table(file="clipboard",...) a lot in s-plus (under windows 2000), but it
does not seem to work in R (and is not in the help screen for read.table).   Am I
missing something?  Would this ability be hard to add?

Thanks.

Dave Parkhurst



From kjetil at entelnet.bo  Mon Jan 20 15:53:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon Jan 20 15:53:03 2003
Subject: [R] Plotting w/multiple y-axes?
In-Reply-To: <200301201851.34997.perbak@brunet.bn>
Message-ID: <3E2BD407.14732.41FB8A@localhost>

On 20 Jan 2003 at 18:51, Per Bak wrote:

Hola!

I think this have been asked (and answered) many times, so you
could have tried to search the archives!

But, a simple example:

> x <- 1:10
> y1 <- 1:10
> y2<- rev(seq(1,1000, length=10))
> y2
 [1] 1000  889  778  667  556  445  334  223  112    1
> plot(x,y1,ann=FALSE)
> axis(2, at=c(2,4,6,8), labels=as.character(c(2,4,6,8)))

# this gives a mark at 10 also! a bug?

> points(x,y2/100,col="red")
> axis(4, at=c(2,4,6,8), labels=as.character(c(200, 400, 600, 800)))
> 


Kjetil Halvorsen

> How do I plot using multiple(2) y-axes? 
> I have two series that use the same x-data, but have very different scales. 
> 
> Appreciate any feedback,
> 
> Per Bak
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Timur.Elzhov at jinr.ru  Mon Jan 20 16:09:08 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Mon Jan 20 16:09:08 2003
Subject: [R] Too many e-mails
In-Reply-To: <NGBBKJEMOMLJFCOIEGCECEPCCDAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCECEPCCDAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <20030120151001.GA13942@pcf004.jinr.ru>

On Mon, Jan 20, 2003 at 02:50:36PM -0000, Jonathan Williams wrote:

> Oh dear - I joined the R help mailing list last week,
> in order to ask a specific question. I did not realise
> that I would start to receive all e-mails to and from
> the mailing list. Is there a way of letting me receive
> only the answers to my own questions? If not, then can
> you remove me from the mailing list?
Read http://www.r-project.org/mail.html to unsubscribe.
Then, you'll able send you question to <r-help at lists.R-project.org>,
and if one knows the answer, he will reply it to _you_, and copy
to R-help list as well.


--
WBR,
Timur.



From ripley at stats.ox.ac.uk  Mon Jan 20 16:15:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon Jan 20 16:15:05 2003
Subject: [R] read.table(file="clipboard",...)  for R?
In-Reply-To: <002501c2c092$fd711500$f4414842@spea.indiana.edu>
Message-ID: <Pine.WNT.4.44.0301201505160.616-100000@gannet.stats.ox.ac.uk>

On Mon, 20 Jan 2003, David Parkhurst wrote:

> I use read.table(file="clipboard",...) a lot in s-plus (under windows 2000), but it
> does not seem to work in R (and is not in the help screen for read.table).   Am I
> missing something?  Would this ability be hard to add?

Yes, it was hard to add, but it already there in R-devel (to be 1.7.0). In
1.6.2 you can use

read.table(textConnection(readClipboard), ...)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Jan 20 16:27:02 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon Jan 20 16:27:02 2003
Subject: [R] read.table(file="clipboard",...)  for R?
In-Reply-To: <Pine.WNT.4.44.0301201505160.616-100000@gannet.stats.ox.ac.uk>
Message-ID: <Pine.WNT.4.44.0301201525160.2212-100000@gannet.stats.ox.ac.uk>

On Mon, 20 Jan 2003, Prof Brian D Ripley wrote:

> On Mon, 20 Jan 2003, David Parkhurst wrote:
>
> > I use read.table(file="clipboard",...) a lot in s-plus (under windows 2000), but it
> > does not seem to work in R (and is not in the help screen for read.table).   Am I
> > missing something?  Would this ability be hard to add?
>
> Yes, it was hard to add, but it already there in R-devel (to be 1.7.0). In
> 1.6.2 you can use
>
> read.table(textConnection(readClipboard), ...)

Oops, the cut-and-paste failed:

read.table(textConnection(readClipboard()), ...)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From chuck at chuckandmaggi.com  Mon Jan 20 16:35:02 2003
From: chuck at chuckandmaggi.com (Chuck White)
Date: Mon Jan 20 16:35:02 2003
Subject: [R] quadratic trends and changes in slopes (R-help digest, Vol 1 #52 - 16 msgs)
In-Reply-To: <20030120110017.4630.98520.Mailman@hypatia.math.ethz.ch>
Message-ID: <000001c2c099$4da34470$2002a8c0@Enterprise>

-----Original Message-----
 Message: 6
Date: Mon, 20 Jan 2003 01:11:24 +0100
From: Martin Michlmayr <tbm at cyrius.com>
To: r-help at stat.math.ethz.ch
Subject: [R] quadratic trends and changes in slopes

I'd like to use linear and quadratic trend analysis in order to find
out a change in slope.  Basically, I need to solve a similar problem as
discussed in
http://www.gseis.ucla.edu/courses/ed230bc1/cnotes4/trend1.html

....

RESPONSE: Since I'm in the process of switching from SAS to R, this was
a good exercise for me. An R program to work the example you cited is
appended. I hope this meets your needs.

Chuck White

# R program for working example at:
# http://www.gseis.ucla.edu/courses/ed230bc1/cnotes4/trend2.html
#
# Copy and paste the example data from the web to a plain text editor
# and save as 'example.txt'. Read the data as follows:

example<-read.table("example.txt", header = FALSE, 
col.names=c('y','grp','o1','o2','o3'))
example

# Make variable names available to session

attach(example)

# Convert grp from numeric format to factor format for ANOVA

fgrp<-factor(grp)
fgrp

# Conduct ANOVA on grp

GRP<-lm(y~fgrp)
anova(GRP)

# Conduct ANOVA on contrasts

Contrasts<-lm(y~o1+o2+o3)
anova(Contrasts)

# I'm sure that an R veteran would have some slick way to do the
'Nonlinear'
# contrast but I used a pocket calculator to verify that the sum of
squares 
# for quadratic plus the sum of squares for cubic divided by 2 degrees
of 
# freedom and divided again by mean square error did indeed equal 3.28.
I 
# then obtained the p-value for 2,28 degrees of freedom as follows:

1-pf(3.28,2,28)



From bates at stat.wisc.edu  Mon Jan 20 16:57:02 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon Jan 20 16:57:02 2003
Subject: [R] R and gdb
In-Reply-To: <Pine.LNX.4.44.0301201126480.20260-100000@sa2391.rec.uhb.fr>
References: <Pine.LNX.4.44.0301201126480.20260-100000@sa2391.rec.uhb.fr>
Message-ID: <6rlm1f95nw.fsf@bates4.stat.wisc.edu>

An alternative method for using gdb with R is to start R and attach
your package or use dyn.load on your shared object.  Then go into
another window and find out the process id number of this process.  (I
usually use 'ps ux' for this.)  After that start start gdb on the R
executable (usually a file with a name like
/usr/local/lib/R/bin/R.bin) and within gdb issue the command

 attach <pid>

where <pid> is the process id of the current R process, set your
breakpoints and use

 signal 0

to get R running again.

For emacs/ESS users this has the wonderful advantage that you can run
both the R and the gdb process under emacs in ESS and gud modes
respectively.


Pierre-Andre Cornillon <pac at Uhb.Fr> writes:

> Hi,
> 
> I have some problem with setting breakpoints with gdb in order to debug
> some shared library for R.
> Classical use of gdb work well
> gcc -g -o footest.o footest.c
> gdb footest.o
> b 2
> run
> ...
> 
> but as i tried to use it with R :
> $ R -d gdb
> GNU gdb 5.2.1
> Copyright 2002 Free Software Foundation, Inc.
> GDB is free software, covered by the GNU General Public License, and you
> are
> welcome to change it and/or distribute copies of it under certain
> conditions.
> Type "show copying" to see the conditions.
> There is absolutely no warranty for GDB.  Type "show warranty" for
> details.
> This GDB was configured as "sparc64-unknown-linux-gnu"...
> (gdb) R
> Starting program: /usr/local/lib/R/bin/R.bin
> 
> R : Copyright 2003, The R Development Core Team
> Version 1.6.2  (2003-01-10)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type `license()' or `licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type `contributors()' for more information.
> 
> Type `demo()' for some demos, `help()' for on-line help, or
> `help.start()' for a HTML browser interface to help.
> Type `q()' to quit R.
> 
> [Previously saved workspace restored]
> 
> > dyn.load("foo.so")
>  "I type Control-C here"
> Program received signal SIGINT, Interrupt.
> 0x703346f8 in select () from /lib/libc.so.6
> (gdb) b foo.c:44
> Breakpoint 1 at 0x705c62a4: file plssvd.c, line 44.
> (gdb) signal 0
> Continuing with no signal.
> foo.r(Xcr,Ycr,2)
> 
> gives directly the final result without stopping at the breakpoints.
> 
> I tried to update R
> from 1.6.1 to 1.62
> and I tried to update gdb too (up to  5.2.1, the 5.3 version doesn't
> compile smoothly on my platform)
> -> nothing change
> 
> my system:
> Ultrasparc 10, sparc Gnu-Linux Suse 7-3, gcc 2-95-3
> kernel 2.4.14 (Suse standard)
> 
> Note that setting the same breakpoint with the same program on a
> Pentium IV, Gnu-Linux Suse 7-3, gcc 2-95-3
> kernel 2.4.14 (Suse standard) works perfectly...
> 
> Does anybody have some hints on this topic?
> 
> Pierre-Andre Cornillon
> 
> PS I do not compile with optimization option as sometimes gdb have some
> trouble to set the breakpoints at the chosen line
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From gmm at ds.unifi.it  Mon Jan 20 17:20:03 2003
From: gmm at ds.unifi.it (Giovanni Marchetti)
Date: Mon Jan 20 17:20:03 2003
Subject: [R] dimnames and solve
Message-ID: <200301201717.36843.gmm@ds.unifi.it>

If I have a covariance matrix V 
for example 
> V = var(trees)
> V
           Girth   Height    Volume
Girth   9.847914 10.38333  49.88812
Height 10.383333 40.60000  62.66000
Volume 49.888118 62.66000 270.20280

I woul like that the inverse (i.e. the concentration matrix) 
had the same dimnames. But  I get instead 
 > solve(V)
              [,1]        [,2]        [,3]
Girth   1.71516635  0.07801175 -0.33476574
Height  0.07801175  0.04190776 -0.02412188
Volume -0.33476574 -0.02412188  0.07110330

I would like to know if this is a feature or a mistake.

Thank you to all. 

   -- Giovanni
< Giovanni M. Marchetti >
Dipartimento di Statistica, Univ. di Firenze   Phone:  +39 055 4237 204
viale Morgagni, 59                             Fax:    +39 055 4223 560
I 50134 Firenze, Italy                         email:  gmm at ds.unifi.it



From kjetil at entelnet.bo  Mon Jan 20 17:43:05 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon Jan 20 17:43:05 2003
Subject: [R] quadratic trends and changes in slopes
In-Reply-To: <20030120001124.GA874@regression.cyrius.com>
Message-ID: <3E2BEEA6.3138.2846BA@localhost>

On 20 Jan 2003 at 1:11, Martin Michlmayr wrote:

Hola!

below is a (lengthy) response, in form of R code and analysis with 
simulated data.

> # first simulating some example data:
> x <- 1:9
> t <- 0.5 + 0.1*x + 0.4 * (x-4)*ifelse(x>5,1,0)
> plot(x,t)
> test <- data.frame(x,t)
> rm(x,t)
> # We can do a non-linear regression to estimate a change-point:
> library(nls)
> test.nls1 <- nls(t ~ a+b*x+c*(x-change)*I(x>change), data=test, start=c(a=0, b=0.1, 
+                     c=0.4, change=5))
> summary(test.nls1)

Formula: t ~ a + b * x + c * (x - change) * I(x > change)

Parameters:
       Estimate Std. Error t value Pr(>|t|)
a       0.50000    0.13856   3.608 0.015406
b       0.10000    0.05060   1.976 0.105057
c       0.48000    0.06197   7.746 0.000573
change  4.66667    0.32773  14.239 3.08e-05

Residual standard error: 0.1131 on 5 degrees of freedom

Correlation of Parameter Estimates:
             a       b       c
b      -0.9129                
c       0.7454 -0.8165        
change -0.4894  0.6969 -0.2626

> # But you should be aware that the standard errors assume the expectation function
> # is differentiable, which is not the case here!

> # And so to what you asked: quadratic regressions
> models <- vector(length=9, mode="list")

> for (i in 1:9) {
+   try( models[[i]] <- lm(t ~ x + I(x^2), data=test, subset=1:i) ) }
> lapply(models, summary)
[[1]]

Call:
lm(formula = t ~ x + I(x^2), data = test, subset = 1:i)

Residuals:
ALL 1 residuals are 0: no residual degrees of freedom!

Coefficients: (2 not defined because of singularities)
            Estimate Std. Error t value Pr(>|t|)
(Intercept)      0.6                            

Residual standard error: NaN on 0 degrees of freedom


[[2]]

Call:
lm(formula = t ~ x + I(x^2), data = test, subset = 1:i)

Residuals:
ALL 2 residuals are 0: no residual degrees of freedom!

Coefficients: (1 not defined because of singularities)
            Estimate Std. Error t value Pr(>|t|)
(Intercept)      0.5                            
x                0.1                            

Residual standard error: NaN on 0 degrees of freedom
Multiple R-Squared:     1,      Adjusted R-squared:   NaN 
F-statistic:   NaN on 1 and 0 DF,  p-value: NA 


[[3]]

Call:
lm(formula = t ~ x + I(x^2), data = test, subset = 1:i)

Residuals:
ALL 3 residuals are 0: no residual degrees of freedom!

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  5.0e-01                            
x            1.0e-01                            
I(x^2)       1.7e-16                            

Residual standard error: NaN on 0 degrees of freedom
Multiple R-Squared:     1,      Adjusted R-squared:   NaN 
F-statistic:   NaN on 2 and 0 DF,  p-value: NA 


[[4]]

Call:
lm(formula = t ~ x + I(x^2), data = test, subset = 1:i)

Residuals:
         1          2          3          4 
 2.069e-17 -6.206e-17  6.206e-17 -2.069e-17 

Coefficients:
             Estimate Std. Error   t value Pr(>|t|)
(Intercept) 5.000e-01  2.576e-16 1.941e+15 3.28e-16
x           1.000e-01  2.350e-16 4.256e+14 1.50e-15
I(x^2)      4.138e-17  4.626e-17 8.940e-01    0.535

Residual standard error: 9.252e-17 on 1 degrees of freedom
Multiple R-Squared:     1,      Adjusted R-squared:     1 
F-statistic: 2.921e+030 on 2 and 1 DF,  p-value: 4.138e-16 


[[5]]

Call:
lm(formula = t ~ x + I(x^2), data = test, subset = 1:i)

Residuals:
         1          2          3          4          5 
-4.164e-21 -9.710e-19  2.938e-18 -2.946e-18  9.835e-19 

Coefficients:
              Estimate Std. Error    t value Pr(>|t|)
(Intercept)  5.000e-01  6.649e-18  7.520e+16   <2e-16
x            1.000e-01  5.067e-18  1.974e+16   <2e-16
I(x^2)      -1.437e-18  8.285e-19 -1.735e+00    0.225

Residual standard error: 3.1e-18 on 2 degrees of freedom
Multiple R-Squared:     1,      Adjusted R-squared:     1 
F-statistic: 5.203e+033 on 2 and 2 DF,  p-value: < 2.2e-16 


[[6]]

Call:
lm(formula = t ~ x + I(x^2), data = test, subset = 1:i)

Residuals:
         1          2          3          4          5          6 
-8.571e-02  8.571e-02  1.143e-01  6.592e-17 -2.571e-01  1.429e-01 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.90000    0.34915   2.578    0.082
x           -0.28571    0.22842  -1.251    0.300
I(x^2)       0.07143    0.03194   2.236    0.111

Residual standard error: 0.1952 on 3 degrees of freedom
Multiple R-Squared: 0.8969,     Adjusted R-squared: 0.8281 
F-statistic: 13.05 on 2 and 3 DF,  p-value: 0.03311 


[[7]]

Call:
lm(formula = t ~ x + I(x^2), data = test, subset = 1:i)

Residuals:
         1          2          3          4          5          6     
     7 
-8.571e-02  8.571e-02  1.143e-01 -1.284e-16 -2.571e-01  1.429e-01  
1.284e-16 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.90000    0.26342   3.417   0.0269
x           -0.28571    0.15096  -1.893   0.1313
I(x^2)       0.07143    0.01844   3.873   0.0179

Residual standard error: 0.169 on 4 degrees of freedom
Multiple R-Squared: 0.9596,     Adjusted R-squared: 0.9394 
F-statistic:  47.5 on 2 and 4 DF,  p-value: 0.001632 


[[8]]

Call:
lm(formula = t ~ x + I(x^2), data = test, subset = 1:i)

Residuals:
       1        2        3        4        5        6        7        
8 
-0.05000  0.07381  0.07857 -0.03571 -0.26905  0.17857  0.10714 -
0.08333 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.79286    0.23186   3.420  0.01885
x           -0.20238    0.11821  -1.712  0.14757
I(x^2)       0.05952    0.01282   4.642  0.00562

Residual standard error: 0.1662 on 5 degrees of freedom
Multiple R-Squared: 0.9744,     Adjusted R-squared: 0.9642 
F-statistic: 95.26 on 2 and 5 DF,  p-value: 0.0001046 


[[9]]

Call:
lm(formula = t ~ x + I(x^2), data = test, subset = 1:i)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30476 -0.08571  0.03810  0.06667  0.18095 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.66190    0.22671   2.920  0.02665
x           -0.10952    0.10410  -1.052  0.33326
I(x^2)       0.04762    0.01015   4.690  0.00336

Residual standard error: 0.1782 on 6 degrees of freedom
Multiple R-Squared: 0.9787,     Adjusted R-squared: 0.9716 
F-statistic:   138 on 2 and 6 DF,  p-value: 9.622e-06 

# For more models, you would like to extract only part of the summary 
for each model!

Note that the quadratic term is significant (at 5% level) only for 
the last 3 models, that is, for ranges 1-7, 1-8 and 1-9. This method 
can only possibly give a significant result for the x^2 term when we 
use data some *past* the change point, so as I see it, 
will necessarily overestimate the change point. You should consider
if not the first method given is better!

Kjetil Halvorsen



> I'd like to use linear and quadratic trend analysis in order to find
> out a change in slope.  Basically, I need to solve a similar problem as
> discussed in http://www.gseis.ucla.edu/courses/ed230bc1/cnotes4/trend1.html
> 
> My subjects have counted dots: one dot, two dots, etc. up to 9 dots.
> The reaction time increases with increasing dots.  The theory is that
> 1 up to 3 or 4 points can be counted relatively fast (a process known
> as "subiziting") but that is becomes slower at around 5 dots ("counting").
> The question is when the slope changes.  Most papers in the literature
> determine this by checking when it changes from being a linear trend to
> a quadratric trend. i.e deviation from linearity is seen as evidence
> that the second, slower process is used.
> 
> I'd like to test the ranges 1-2, 1-3, 1-4, 1-5, 1-6, etc and see when
> a qudratric trend is significant.  However, although I have read some
> literature and done many google searches, I cannot figure out how to
> do this with R.  Can anyone show me a simple example of how to do
> this. (Either with the method described above or with a different
> method -- but please note that I only have 9 data points, tho; 1:9).
> 
> Any help is appreciated.
> 
> Thanks.
> 
> 
> FWIW, here's the description from one paper using this method:
> 
> "For both conditions, the subitizing range for each group was established
> using quadratic trend tests on the aggregated RT data for numerosities 1-3,
> 1-4, and so on (Akin and Chase, 1978; Chi and Klahr, 1975; Pylyshyn,
> 1993). For both groups the first appearance of a quadratic trend was in
> the N=1-5 range (t(9) = 7.33, p< .001 for the control group, and t(5) =
> 5.35, p = .005 for the Turner group). This indicates a subitizing range
> of 4 for both groups. This divergence from a linear increase in RT
> suggests the deployment of a new process for the last numerosity added."
> 
> -- 
> Martin Michlmayr
> tbm at cyrius.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From chrysopa at insecta.ufv.br  Mon Jan 20 17:48:02 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Mon Jan 20 17:48:02 2003
Subject: [R] warning in binomial analysis
In-Reply-To: <Pine.A41.4.44.0209221329260.165600-100000@homer38.u.washington.edu>
References: <Pine.A41.4.44.0209221329260.165600-100000@homer38.u.washington.edu>
Message-ID: <200301201424.49004.chrysopa@insecta.ufv.br>

Em Thomas Lumley, escreveu:
>
> When you fit logistic regression models to fairly sparse data you can
> often have a situation where for some combination of variables the
> response variable is either all 0 or all 1.  In that case the maximum
> likelihood estimates for at least some of the coefficients will be
> infinite.  That's what R is telling you.
>
> You should be able to tell which coefficients are infinite -- the
> coefficients and their standard errors will be large.
>
> When this happens the standard errors and the p-values reported by
> summary.glm() for those variables are useless.
>
> 	-thomas

Hi Thomas,

I try to understand this problem. It is very common in ecology data using 
binomial or poisson errors.

> summary(abundmod)
       x1            y                x2               n         
 Sp1    : 12   Min.   : 0.000   Min.   : 3.210   Min.   : 13.00  
 Sp10   : 12   1st Qu.: 0.000   1st Qu.: 6.572   1st Qu.: 29.25  
 Sp11   : 12   Median : 1.000   Median : 8.845   Median : 44.50  
 Sp12   : 12   Mean   : 4.011   Mean   :19.417   Mean   : 92.25  
 Sp13   : 12   3rd Qu.: 3.000   3rd Qu.:28.988   3rd Qu.:119.25  
 Sp14   : 12   Max.   :92.000   Max.   :60.530   Max.   :338.00  
 (Other):204                                                     

> m <- glm(y/n~x1*x2,family=binomial,weights=n,maxit=1000)
Warning message: 
fitted probabilities numerically 0 or 1 occurred in: (if (is.empty.model(mt)) 
glm.fit.null else glm.fit)(x = X, y = Y,  


I tell the levels which coefficients are infinite.

x1Sp22      18.9024041 44.4228068   0.426 0.670464    
x1Sp5       22.0655076 42.1371974   0.524 0.600516    

I look the dataset to understand why these two levels are ""wrongs"".

Both appear alone in one value of x2.

but,

some others levels appear alone in some level of x2. Look:

> tapply(y,list(x1,x2),c)
     3.21 4.05 5.56 6.91 7.97 8.56 9.13 16.13 25.58 39.21 46.16 60.53
Sp1     2    0    9    6    6    4    8    21    20    17    60    18
Sp10    4    1    3    1    0    2    2    19    13     7    12     5
Sp11    2    0    0    1    4    0    1     4     8     5    19     6
Sp12    0    1    1    1    5    0    0     1    13     3     7     6
Sp13    0    0    0    1    0    0    0     0     0     1     1     0
Sp14    0    0    0    2    1    0    1     1    13     0     3     3
Sp15    0    0    1    0    0    0    0     0     1     0     0     0
Sp16    2    4    3    6    8    2    8     0    14     4    21     5
Sp17    0    0    0    0    0    0    0     0     0     0     5     0
Sp18    5    4   12    1    9    3    5    36    40    27    92    52
Sp19    0    0    1    1    0    0    2     0     2     0     0     0
Sp2     2    0    1    0    0    0    0     3     1     0     2     1
Sp20    2    2    2    2    5    4    3     2    13    37    77    29
Sp21    0    0    0    0    0    0    1     0     0     0     0     0
Sp22    1    0    0    0    0    0    0     0     0     0     0     0
Sp23    0    0    0    1    0    0    0     0     0     0     0     0
Sp3     2    0    5    6    3    2    6    16    22     7    21     9
Sp4     0    1    0    1    0    0    0     1     3     0     6     1
Sp5     2    0    0    0    0    0    0     0     0     0     0     0
Sp6     0    0    0    0    3    1    2     6    12     0     7     0
Sp7     0    0    0    0    0    0    0     0     6     0     1     0
Sp8     0    0    0    1    0    0    0     1     3     2     3     2
Sp9     0    0    0    0    4    0    2     2     8     3     1     1

sp17, sp21, sp23 appear for some one value of x2. Why the problem is just with 
Sp22 and Sp5?

It is a problem in my dataset? I need to remove these levels? What is the 
correct mean? How to resolve this?

Thanks
Ronaldo

-- 
Windows 98: quanto mais bonito ? o espet?culo, maior ? a confus?o
nos bastidores...
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Gnu/Debian Woody D+:) | Lxuser#: 205366



From p.dalgaard at biostat.ku.dk  Mon Jan 20 17:54:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Jan 20 17:54:02 2003
Subject: [R] Fortran linking problems
In-Reply-To: <F90FKmdSklLuBSEpU0e0000bda6@hotmail.com>
References: <F90FKmdSklLuBSEpU0e0000bda6@hotmail.com>
Message-ID: <x2znpvyd6j.fsf@biostat.ku.dk>

"Angel Lopez-Urrutia" <lopezurrutia at hotmail.com> writes:

> Thanks to all,
> Once I installed readline-dev (and reinstalled Blas/lapack) it worked!
> I don't know it why this wasn't shown as a dependency when I installed
> the R rpm!

This is generic: To use a library you need libfoo, to compile code
that uses libfoo you need libfoo-devel. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Russell.Pierce at legerity.com  Mon Jan 20 18:18:02 2003
From: Russell.Pierce at legerity.com (Russell D. Pierce)
Date: Mon Jan 20 18:18:02 2003
Subject: [R] Command History
Message-ID: <3E2C2F1C.8274176@legerity.com>

I have compiled R under Solaris 7 (SunOS 5.7) with the readline-4.0
library linked.  Command line editing appears to work, but I cannot
access command history.  If I execute several commands in R, then type
"history()", I get the error message "Error in savehistory(file) : no
history available to save".  Also, previous command recall (C-p) does
not seem to work.  I am invoking R directly from a Korn shell prompt.
Can you help?

Russ Pierce
Legerity, Inc.
Reading, PA
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Russell.Pierce.vcf
Type: text/x-vcard
Size: 341 bytes
Desc: Card for Russell D. Pierce
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030120/b68e7fd5/Russell.Pierce.vcf

From ripley at stats.ox.ac.uk  Mon Jan 20 20:14:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan 20 20:14:02 2003
Subject: [R] dimnames and solve
In-Reply-To: <200301201717.36843.gmm@ds.unifi.it>
Message-ID: <Pine.LNX.4.44.0301201910080.1522-100000@gannet.stats>

A feature.  What you really are doing is solve(V, diag(3)), and you get 
the colnames of the RHS.  See the help page!

On Mon, 20 Jan 2003, Giovanni Marchetti wrote:

> If I have a covariance matrix V 
> for example 
> > V = var(trees)
> > V
>            Girth   Height    Volume
> Girth   9.847914 10.38333  49.88812
> Height 10.383333 40.60000  62.66000
> Volume 49.888118 62.66000 270.20280
> 
> I woul like that the inverse (i.e. the concentration matrix) 
> had the same dimnames. But  I get instead 
>  > solve(V)
>               [,1]        [,2]        [,3]
> Girth   1.71516635  0.07801175 -0.33476574
> Height  0.07801175  0.04190776 -0.02412188
> Volume -0.33476574 -0.02412188  0.07110330
> 
> I would like to know if this is a feature or a mistake.
> 
> Thank you to all. 
> 
>    -- Giovanni
> < Giovanni M. Marchetti >
> Dipartimento di Statistica, Univ. di Firenze   Phone:  +39 055 4237 204
> viale Morgagni, 59                             Fax:    +39 055 4223 560
> I 50134 Firenze, Italy                         email:  gmm at ds.unifi.it
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Rob.Balshaw at syreon.com  Mon Jan 20 21:38:03 2003
From: Rob.Balshaw at syreon.com (Rob Balshaw)
Date: Mon Jan 20 21:38:03 2003
Subject: [R] Adding reference lines to xyplot
In-Reply-To: <OF4CCDC6FA.5474246A-ON85256CAD.005ACA2E-85256CAD.005ACA3C@american.edu>
Message-ID: <NFBBIINHNJMJKENFNIIDIEADDFAA.Rob.Balshaw@syreon.com>

I'm trying to add a set of reference lines to a multipanel xyplot

xyplot(y ~ x | Visit,
	panel = function(x, y, ...){
	panel.xyplot(x, y, ...)
	abline(v = c(0.5, 1))
	})

However, the reference lines are different for different visits.  For
example, for the first 2 visits, I'd like vertical lines at x = 0.5 and 1.
For visits 3 and four, I'd like vertical lines at x = 1 and 1.5.  I can use
abline within the panel function, but I haven't found a way to say I want my
reference lines to change for different visits.

I've a feeling that the subscripts arguement is somehow involved, but I've
not found any examples or references to this.

Any suggestions?  Which page of the various manuals did I skim too quickly?

Thanks,

Rob

-- Robert Balshaw, Ph.D.
-- Senior Biostatistician, Syreon Corp.
-- Phone: 604.676.5900x220; Fax: 604.676.5911



From tdt2+ at pitt.edu  Mon Jan 20 22:28:03 2003
From: tdt2+ at pitt.edu (Truc Truong)
Date: Mon Jan 20 22:28:03 2003
Subject: [R] ave across columns
Message-ID: <29060717.1043080070@HL130.fdl.pitt.edu>

Hi:

How do I find average across three columns such as weight1, weight2, 
weight3 (20 people, each person has three different measures)? They have 
NA's also.  Thanks

Tom, Univ of Pittsburgh, ttrut at yahoo.com



From deepayan at stat.wisc.edu  Mon Jan 20 22:33:02 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon Jan 20 22:33:02 2003
Subject: [R] Adding reference lines to xyplot
In-Reply-To: <NFBBIINHNJMJKENFNIIDIEADDFAA.Rob.Balshaw@syreon.com>
References: <NFBBIINHNJMJKENFNIIDIEADDFAA.Rob.Balshaw@syreon.com>
Message-ID: <200301201530.39413.deepayan@stat.wisc.edu>

On Monday 20 January 2003 02:37 pm, Rob Balshaw wrote:
> I'm trying to add a set of reference lines to a multipanel xyplot
>
> xyplot(y ~ x | Visit,
> 	panel = function(x, y, ...){
> 	panel.xyplot(x, y, ...)
> 	abline(v = c(0.5, 1))
> 	})
>
> However, the reference lines are different for different visits.  For
> example, for the first 2 visits, I'd like vertical lines at x = 0.5 and 1.
> For visits 3 and four, I'd like vertical lines at x = 1 and 1.5.  I can use
> abline within the panel function, but I haven't found a way to say I want
> my reference lines to change for different visits.

panel functions are not given any info regarding which panel is being drawn, 
so there is no direct way to do this. One way that works in most cases is 
something like:

panel.index <- 1

xyplot(y ~ x | Visit,
       panel = function(x, y, ...){
           panel.xyplot(x, y, ...)
           panel.abline(v = if (index %in% 1:2) c(0.5, 1) else c(1, 1.5))
           panel.index <<- panel.index + 1
        })

Deepayan



From djw1005 at cam.ac.uk  Mon Jan 20 23:39:03 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Mon Jan 20 23:39:03 2003
Subject: [R] Adding reference lines to xyplot
In-Reply-To: <NFBBIINHNJMJKENFNIIDIEADDFAA.Rob.Balshaw@syreon.com>
Message-ID: <Pine.SOL.3.96.1030120222704.2246A-100000@libra.cus.cam.ac.uk>

> I'm trying to add a set of reference lines to a multipanel xyplot
> xyplot(y ~ x | Visit,
> 	panel = function(x, y, ...){
> 	panel.xyplot(x, y, ...)
> 	abline(v = c(0.5, 1))
> 	})
> However, the reference lines are different for different visits.

I would do it with the groups parameter.

xyplot (y ~ x | Visit,
  groups=Visit,
  panel=function(x,y,subscripts,groups,...) {
    panel.xyplot(x,y,...)
    g <- unique(groups[subscripts])
    # g is the unique value of Visit occuring in this panel
    # so plot whatever lines you like, as a function of g
    }
  )

The groups argument to xyplot is an arbitrary vector of the same length
as the data you are plotting. The function xyplot splits the data into
panels. To each panel function it passes two arguments: group, which
is just the same as the groups argument passed to xyplot; and 
subscripts, a vector of integers indexing the entries that will appear
in this panel.

Since in this case groups=Visit and the plot conditions on Visit,
groups[subscripts] contains identical elements. If you had passed
groups=SomethingElse to xyplot, groups[subscripts] would contain
several values.

> Any suggestions?  Which page of the various manuals did I skim too quickly?

The documentation I worked from is that for xyplot. And I looked
at the definition of panel.superpose.

Damon Wischik.



From hedderik at cmu.edu  Mon Jan 20 23:47:03 2003
From: hedderik at cmu.edu (Hedderik van Rijn)
Date: Mon Jan 20 23:47:03 2003
Subject: [R] ave across columns
In-Reply-To: <29060717.1043080070@HL130.fdl.pitt.edu>
Message-ID: <05DA5D97-2CC9-11D7-AA7B-000393678426@cmu.edu>

x <- matrix(rnorm(60),20)
x[sample(1:60,10)] <- NA
apply(x,1,mean,na.rm=T)

On Monday, January 20, 2003, at 04:27 PM, Truc Truong wrote:

> Hi:
>
> How do I find average across three columns such as weight1, weight2, 
> weight3 (20 people, each person has three different measures)? They 
> have NA's also.  Thanks
>
> Tom, Univ of Pittsburgh, ttrut at yahoo.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
--
http://www.van-rijn.org



From Simon.Wotherspoon at utas.edu.au  Tue Jan 21 00:52:03 2003
From: Simon.Wotherspoon at utas.edu.au (Simon Wotherspoon)
Date: Tue Jan 21 00:52:03 2003
Subject: [R] Orders of terms in formulae
Message-ID: <JPEJIEHCLCCMMBFGMPDGIEBCCCAA.Simon.Wotherspoon@utas.edu.au>

Hi,
	Given that R reports Type I sums of squares, isn't it a bit anachronistic
that it re-orders terms in formulae?

> d <- expand.grid(y=rnorm(8),
+             A=factor(c(1,2)),
+             B=factor(c(1,2)),
+             C=factor(c(1,2)))
> summary(aov(y ~ A+B+A:B+C,data=d))
            Df    Sum Sq   Mean Sq   F value Pr(>F)
A            1 8.294e-34 8.294e-34 1.027e-33      1
B            1 3.961e-33 3.961e-33 4.904e-33      1
C            1 3.980e-34 3.980e-34 4.927e-34      1
A:B          1 1.294e-32 1.294e-32 1.601e-32      1
Residuals   59    47.658     0.808

Or have I missed the point?

Simon.
---



From maj at stats.waikato.ac.nz  Tue Jan 21 01:48:05 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue Jan 21 01:48:05 2003
Subject: [R] Starting values for glm fits
Message-ID: <3E2C9894.2050603@stats.waikato.ac.nz>

I'm fitting some small data sets using a binomial glm with complementary 
log-log link. In some ill-conditioned cases I am getting convergence 
failures. I know how to adjust maxit and epsilon, but that doesn't seem 
to help.

In fact I know some very good starting values for my fits, but I can't 
see how to get them in to glm(). How may I do this?

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From Bill.Venables at CMIS.CSIRO.AU  Tue Jan 21 01:53:03 2003
From: Bill.Venables at CMIS.CSIRO.AU (Bill.Venables@CMIS.CSIRO.AU)
Date: Tue Jan 21 01:53:03 2003
Subject: [R] Orders of terms in formulae
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A91657C9@roper-cv.qld.cmis.CSIRO.AU>

Simon Wotherspoon suggests:

>  -----Original Message-----
> From: 	Simon Wotherspoon [mailto:Simon.Wotherspoon at utas.edu.au] 
> Sent:	Tuesday, January 21, 2003 10:08 AM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] Orders of terms in formulae
> 
> Hi,
> 
> Given that R reports Type I sums of squares, isn't it a bit anachronistic
> that it re-orders terms in formulae?
	[WNV]  R does not purport to report Type I anything.  The anova and
summary.aov functions, by default, report sequential analyses of variance
tables with factor terms ordered by their degree.

> > d <- expand.grid(y=rnorm(8),
> +             A=factor(c(1,2)),
> +             B=factor(c(1,2)),
> +             C=factor(c(1,2)))
> > summary(aov(y ~ A+B+A:B+C,data=d))
>             Df    Sum Sq   Mean Sq   F value Pr(>F)
> A            1 8.294e-34 8.294e-34 1.027e-33      1
> B            1 3.961e-33 3.961e-33 4.904e-33      1
> C            1 3.980e-34 3.980e-34 4.927e-34      1
> A:B          1 1.294e-32 1.294e-32 1.601e-32      1
> Residuals   59    47.658     0.808
	[WNV]  You can change the default, of course.
	> d <- expand.grid(A = factor(1:2), 
		B = factor(1:2), C = factor(1:2))
	> d$y <- rnorm(8) 
	> fm <- aov(terms(y ~ A*B + C, keep.order=T), d)
	> summary(fm)
	            Df  Sum Sq Mean Sq F value  Pr(>F)
	A            1 2.70009 2.70009  5.9045 0.09334
	B            1 2.34018 2.34018  5.1175 0.10871
	A:B          1 0.46492 0.46492  1.0167 0.38758
	C            1 2.33694 2.33694  5.1104 0.10886
	Residuals    3 1.37187 0.45729                
	> anova(fm)
	Analysis of Variance Table

	Response: y
	          Df  Sum Sq Mean Sq F value  Pr(>F)
	A          1 2.70009 2.70009  5.9045 0.09334
	B          1 2.34018 2.34018  5.1175 0.10871
	A:B        1 0.46492 0.46492  1.0167 0.38758
	C          1 2.33694 2.33694  5.1104 0.10886
	Residuals  3 1.37187 0.45729                
	>
	[WNV]  I realise this dodge is a little arcane, but it is important.
>  
> Or have I missed the point?
	[WNV]  I think you have missed the point a bit.  If you did fit a
model of the kind

		aov(y ~ A*B*C + C*D*E, dat)

	and you wanted the main effects to be included first in the model
and then the interactions ordered by degree, (as would be usual), how would
you ensure that happening (without tediously spelling it all out) if your
convention were in force?

	This convention extends far beyond R and S-PLUS, by the way.  It
probably started with Genstat back in the middle ages.

	The FAQ, by the way, has something to say abou these kinds of
issues, but not this one precisely (7.20 comes close).  Perhaps this should
find its way into that august document.

> Simon.
> ---
> 
Bill Venables, 
CMIS, CSIRO Marine Laboratories, 
PO Box 120, Cleveland, Qld. 4163
AUSTRALIA
Phone:  +61 7 3826 7251  
Fax:    +61 7 3826 7304
Mobile: +61 419 634 642
<mailto: Bill.Venables at csiro.au>
http://www.cmis.csiro.au/bill.venables/
>  
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From pankaj at utdallas.edu  Tue Jan 21 03:29:03 2003
From: pankaj at utdallas.edu (Pankaj Choudhary)
Date: Tue Jan 21 03:29:03 2003
Subject: [R] Logistic regression:  At times correlation matrix of coefficients gets messed up
Message-ID: <000e01c2c0f4$c65249b0$eb166e81@campus.ad.utdallas.edu>

Hi,

When I include a categorical variable (RACE with 3 levels - "white",
"black" and "other") in my logistic regression model, the correlation
matrix of the coefficients gets messed up. I get something like:

-----------------------------------------
Correlation of Coefficients:
          ( A L RACEb
AGE       , 1        
LWT       ,   1      
RACEblack       1    
RACEother .     .    
attr(,"legend")
[1] 0 ` ' 0.3 `.' 0.6 `,' 0.8 `+' 0.9 `*' 0.95 `B' 1
-------------------------------------

I couldn't figure out how to interpret it. Here is the sequence of
commands and the complete output. (I am using R 1.6.2)

-----------------------------------------

> lowbwt.alr <- glm(LOW~AGE+LWT+RACE, family=binomial, data=lowbwt) 
> summary(lowbwt.alr, correlation=TRUE)

Call:
glm(formula = LOW ~ AGE + LWT + RACE, family = binomial, data = lowbwt)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.4052  -0.8946  -0.7209   1.2484   2.0982  

Coefficients:
             Estimate Std. Error z value Pr(>|z|)  
(Intercept)  1.306741   1.069558   1.222   0.2218  
AGE         -0.025524   0.033244  -0.768   0.4426  
LWT         -0.014353   0.006521  -2.201   0.0277 *
RACEblack    1.003821   0.497957   2.016   0.0438 *
RACEother    0.443460   0.360184   1.231   0.2182  
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 234.67  on 188  degrees of freedom
Residual deviance: 222.66  on 184  degrees of freedom
AIC: 232.66

Number of Fisher Scoring iterations: 3

Correlation of Coefficients:
          ( A L RACEb
AGE       , 1        
LWT       ,   1      
RACEblack       1    
RACEother .     .    
attr(,"legend")
[1] 0 ` ' 0.3 `.' 0.6 `,' 0.8 `+' 0.9 `*' 0.95 `B' 1

---------------------------------------------------------------------

Strangely enough, when I just use (AGE and RACE) or (LWT and RACE) or
(AGE and LWT) or just RACE as the explanatory variable(s), there is no
problem.

 
Am I doing something wrong? I will greatly appreciate any help.

With best wishes,

Pankaj Choudhary
U. of Texas at Dallas



From chuck at chuckandmaggi.com  Tue Jan 21 03:50:03 2003
From: chuck at chuckandmaggi.com (Chuck White)
Date: Tue Jan 21 03:50:03 2003
Subject: (v2) [R] quadratic trends and changes in slopes (R-help digest, Vol 1 #52 - 16 msgs)
In-Reply-To: <20030120110017.4630.98520.Mailman@hypatia.math.ethz.ch>
Message-ID: <000101c2c0f7$bc2f3260$2002a8c0@Enterprise>

-----Original Message-----
 Message: 6
Date: Mon, 20 Jan 2003 01:11:24 +0100
From: Martin Michlmayr <tbm at cyrius.com>
To: r-help at stat.math.ethz.ch
Subject: [R] quadratic trends and changes in slopes

I'd like to use linear and quadratic trend analysis in order to find
out a change in slope.  Basically, I need to solve a similar problem as
discussed in
http://www.gseis.ucla.edu/courses/ed230bc1/cnotes4/trend1.html

....

RESPONSE: This message updates my earlier response. I just started
programming with R on Friday and I wanted to make my response to you
more general... before starting on a more difficult problem of the same
type at work. The two improvements I've added are: (1) a more general
procedure for more quickly and accurately creating the contrast vectors
and (2) direct program interaction with results in output tables. Access
to results in output tables is so much easier in R than what I've had to
do in SAS that it's incredible. An R program to work the example you
cited is appended. I hope this meets your needs.

Chuck White

# R program for working example at:
# http://www.gseis.ucla.edu/courses/ed230bc1/cnotes4/trend2.html
#
# Copy and paste the example data from the web to a plain text editor
# and save as 'example.txt'. If this program is copied and passted into
# the R Console then the program is expected to run without further
# operator intervention.

#Read the data as follows:

example<-read.table("example.txt", header = FALSE, 
col.names=c('y','grp','o1','o2','o3'))
example

# Make variable names available to session

attach(example)

# Convert grp from numeric format to factor format for ANOVA. If you
don't 
# do this then you get the wrong test (with only 1 degree of freedom).

fgrp<-factor(grp)
fgrp

# Conduct ANOVA on grp

GRP<-lm(y~fgrp)
anova(GRP)

# Conduct ANOVA on contrasts

## The example aready contains the contrast vectors but you'll have to 
## create them yourself when you use real data. A quick and accurate way
to ## set them up is to use the repeat command (rep) as follows:

Linear<-c(rep(-3,8),rep(-1,8),rep(1,8),rep(3,8))
Quadratic<-c(rep(1,8),rep(-1,16),rep(1,8))
Cubic<-c(rep(-1,8),rep(3,8),rep(-3,8),rep(1,8))

Contrasts<-lm(y~Linear+Quadratic+Cubic)
Contrasts.anova<-anova(Contrasts)
Contrasts.anova

# Calculate the F-test and P-value for Nonlinear

SS.Quadratic<-Contrasts.anova$"Sum Sq"[2]
SS.Cubic<-Contrasts.anova$"Sum Sq"[3]
SS.Nonlinear<-SS.Quadratic+SS.Cubic

DF.Quadric<-Contrasts.anova$"Df"[2]
DF.Cubic<-Contrasts.anova$"Df"[3]
DF.Nonlinear<-DF.Quadric+DF.Cubic

SS.Residuals<-Contrasts.anova$"Sum Sq"[4]
DF.Residuals<-Contrasts.anova$"Df"[4]

Nonlinear.test<-(SS.Nonlinear/DF.Nonlinear)/(SS.Residuals/DF.Residuals)

Nonlinear.test

Nonlinear.pvalue<-1-pf(Nonlinear.test,DF.Nonlinear,DF.Residuals)

Nonlinear.pvalue



From mcraec at sympatico.ca  Tue Jan 21 03:56:03 2003
From: mcraec at sympatico.ca (Chris & Laura McRae)
Date: Tue Jan 21 03:56:03 2003
Subject: [R] running R inside of e-macs
Message-ID: <001e01c2c0f8$2b736380$bfbde440@family>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030121/86484f6d/attachment.pl

From jerrytheshrub at hotmail.com  Tue Jan 21 04:20:03 2003
From: jerrytheshrub at hotmail.com (Jeremy Z Butler)
Date: Tue Jan 21 04:20:03 2003
Subject: [R] key in margin area
Message-ID: <F15dvlQsFBL4JcpE9XJ00017a45@hotmail.com>

Hi
Is there any way to position a key (legend) outside the plot area? i.e. in 
the margin between plot area and page margin. I realise I could achieve the 
same effect by creating a larger plot but not printing the axes and then 
draw the smaller axes independantly leaving room for the key. However, that 
wont work very well in my particular case.
Thanks in advance
Jeremy



From gisar at nus.edu.sg  Tue Jan 21 04:45:03 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Tue Jan 21 04:45:03 2003
Subject: [R] key in margin area
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F1F2@MBXSRV03.stf.nus.edu.sg>

Well, if you don't want to play with the margins, then I guess you have
to use the layout() function. You will want something similar to the
following if you want legends at the right:

def.par <- par(no.readonly = TRUE)# save default
nf <- layout( matrix( c(1,2), nrow=1), c(4,1) ) # If you want legend at
bottom, change nrow to ncol
layout.show(nf) #  so the ratio of plot to legend area is 4:1

par(mar=c(1,1,1,1))
plot.new()                 # calls an empty plot
legend( 0, 0.5, "A spot", pch=1, col=1)
par(def.par)   # reset to default

There might be a nicer way of doing this though.


-----Original Message-----
From: Jeremy Z Butler [mailto:jerrytheshrub at hotmail.com] 
Sent: Tuesday, January 21, 2003 11:17 AM
To: r-help at stat.math.ethz.ch
Subject: [R] key in margin area


Hi
Is there any way to position a key (legend) outside the plot area? i.e.
in 
the margin between plot area and page margin. I realise I could achieve
the 
same effect by creating a larger plot but not printing the axes and then

draw the smaller axes independantly leaving room for the key. However,
that 
wont work very well in my particular case.
Thanks in advance
Jeremy
______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rossini at blindglobe.net  Tue Jan 21 07:27:04 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue Jan 21 07:27:04 2003
Subject: [R] bayesian text classification...
Message-ID: <87iswjow5z.fsf@jeeves.blindglobe.net>

for Spam.

In the process of setting up a more effective spam filtering system, I
just noticed that bogofilter, which implements extensions of the (a?) 
"Naive Bayes" text classification approach, will dump out R data
frames; the man page suggests how to "integrate" it with R for
verification.  (sort of, that is).

Anyway, for those of you looking for silly and perhaps interesting
problems/datasets for your engineering or comp-sci statistics classes,
this one looks quite amusing...

Looks like Eric Raymond knows (about) R -- a script is apparently
included in the source according to the man page, though I couldn't
find it in the Debian package.
           
best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From petr.pikal at precheza.cz  Tue Jan 21 07:59:03 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue Jan 21 07:59:03 2003
Subject: [R] ave across columns
In-Reply-To: <05DA5D97-2CC9-11D7-AA7B-000393678426@cmu.edu>
References: <29060717.1043080070@HL130.fdl.pitt.edu>
Message-ID: <3E2CFDB0.13935.DECBC@localhost>


On 20 Jan 2003 at 17:46, Hedderik van Rijn wrote:

> x <- matrix(rnorm(60),20)
> x[sample(1:60,10)] <- NA
> apply(x,1,mean,na.rm=T)
or simply

colMeans(x,na.rm=T)

> 
> On Monday, January 20, 2003, at 04:27 PM, Truc Truong wrote:
> 
> > Hi:
> >
> > How do I find average across three columns such as weight1, weight2,
> > weight3 (20 people, each person has three different measures)? They
> > have NA's also.  Thanks
> >
> > Tom, Univ of Pittsburgh, ttrut at yahoo.com
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
> --
> http://www.van-rijn.org
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

Petr Pikal
Precheza a.s., Nab?.Dr.E.Bene?e 24, 750 62 P?erov
tel: +420581 252 257 ; 724 008 364
petr.pikal at precheza.cz; p.pik at volny.cz
fax +420581 252 561



From ligges at statistik.uni-dortmund.de  Tue Jan 21 08:40:04 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue Jan 21 08:40:04 2003
Subject: [R] key in margin area
In-Reply-To: <F15dvlQsFBL4JcpE9XJ00017a45@hotmail.com>
References: <F15dvlQsFBL4JcpE9XJ00017a45@hotmail.com>
Message-ID: <3E2CF944.8000603@statistik.uni-dortmund.de>

Jeremy Z Butler wrote:
> Hi
> Is there any way to position a key (legend) outside the plot area? i.e. 
> in the margin between plot area and page margin. I realise I could 
> achieve the same effect by creating a larger plot but not printing the 
> axes and then draw the smaller axes independantly leaving room for the 
> key. However, that wont work very well in my particular case.

You might want to extend the margins. See ?par for details, particularly 
look for arguments 'mar' and 'oma'.
After
  par(xpd = TRUE)    # Again, see ?par
you can plot a legend into the margins.

Uwe Ligges



From maechler at stat.math.ethz.ch  Tue Jan 21 09:01:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue Jan 21 09:01:02 2003
Subject: [R] Starting values for glm fits
In-Reply-To: <3E2C9894.2050603@stats.waikato.ac.nz>
References: <3E2C9894.2050603@stats.waikato.ac.nz>
Message-ID: <15916.65052.206570.111519@gargle.gargle.HOWL>

>>>>> "Murray" == Murray Jorgensen <maj at stats.waikato.ac.nz>
>>>>>     on Tue, 21 Jan 2003 13:47:16 +1300 writes:

    Murray> I'm fitting some small data sets using a binomial
    Murray> glm with complementary log-log link. In some
    Murray> ill-conditioned cases I am getting convergence
    Murray> failures. I know how to adjust maxit and epsilon,
    Murray> but that doesn't seem to help.

    Murray> In fact I know some very good starting values for my
    Murray> fits, but I can't see how to get them in to
    Murray> glm(). How may I do this?

?glm aka help(glm) -- tells a quite a bit about this:

Overly terse summary:

   glm(*, start = ..)

or for more possibilities (and less ease of use)
   glm.fit(*, etastart = .)
or
   glm.fit(*, start = .)
or
   glm.fit(*, mustart = .)

-----
Actually I think, glm() could easily be enhanced to also accept
`etastart' and `mustart' since all of these "start" arguments
would just be passed to glm.fit() ...

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From Morten.Sickel at nrpa.no  Tue Jan 21 09:10:03 2003
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Tue Jan 21 09:10:03 2003
Subject: [R] Plotting w/multiple y-axes?
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5D85@postix.nrpa.no>

Per Bak wrote:
>How do I plot using multiple(2) y-axes? 
>I have two series that use the same x-data, but have very different scales.


I don't know, it that is the only, or even the best way to do it, but I plot
with multiple Y-axes using the grid package. The problem I have found is
that you have to start using a completely new syntax for plotting

Morten

example:
# ywtext and yrtext are initialized to the text to be plotted at
# the 1st and 2nd Y axes
grid.newpage()
#1st series, scale 0 - 500:
push.viewport(viewport(yscale=c(0,500),w=.75,h=.75,xscale=xscale))
grid.points(unit(hillesoy$date,"native"),
            unit(hillesoy$value,"native"),size=unit(3,"mm"),gp=gp.sw)

grid.xaxis(at=c(1990:2003),gp=gp.axis)

grid.yaxis(main=FALSE,gp=gp.axis)
grid.text(ywtext,x=unit(2004.8,"native"),rot=270,
gp=gp.text)

#2nd series, scale 0-250
push.viewport(viewport(yscale=c(0,250),xscale=xscale))
grid.lines(unit(sellafield$year,"native"),
	   unit(sellafield$amount,"native"),gp=gp.sella)


grid.yaxis(at=c(0,50,100,150,200,250),main=TRUE,gp=gp.axis)
grid.text(yrtext,x=unit(1988.3,"native"),rot=270,



From arv at ono.com  Tue Jan 21 09:14:31 2003
From: arv at ono.com (arv@ono.com)
Date: Tue Jan 21 09:14:31 2003
Subject: [R] problems when compiling package 'norm'
Message-ID: <10f50911416b.11416b10f509@ono.com>

Dear All,

Trying to install package 'norm' under linux-mandrake8.2 I've got the
following messages:

R CMD INSTALL norm_1.0-9.tar.gz
* Installing *source* package 'norm' ...
** libs
g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro
-march=i586 -fno-fast-math -fno-strength-reduce  -O3
-fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 -fno-fast-math
-fno-strength-reduce -c norm.f -o norm.o
gcc -shared -L/usr/local/lib -o norm.so norm.o  -L/usr/local/lib
-L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/2.96
-L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/2.96/../../..
-lreadline -ldl -lncurses -lg2c -lm -L/usr/lib/R/bin -lR
/usr/bin/ld: cannot find -lreadline
collect2: ld returned 1 exit status
make: *** [norm.so] Error 1
ERROR: compilation failed for package 'norm'

My libreadline's are under /lib. I've tried with: 

R CMD INSTALL --with=/lib norm_1.0-9.tar.gz

but same results

Thanks in advance

Antonio



From AlessandroSemeria at cramont.it  Tue Jan 21 09:20:07 2003
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Tue Jan 21 09:20:07 2003
Subject: [R] running R inside of e-macs
Message-ID: <OF0DE633C9.C1778890-ONC1256CB5.002CA1CA@tomware.it>

Have you installed ESS (Emacs Speak Statistics) ?
If not look at http://www.sciviews.org/_rgui/

Bye!

A. S.

----------------------------

|------------------------------------+------------------------------------|
|Alessandro Semeria                  |Tel. +39 544 536811                 |
|------------------------------------+------------------------------------|
|Models and Simulation Laboratory    |Fax. +39 544 538663                 |
|------------------------------------+------------------------------------|
|The Environment Research Center -   |                                    |
|Montecatini (Edison Group),    Via  |                                    |
|Ciro Menotti 48,                    |E-mail: asemeria at cramont.it         |
|48023 Marina di Ravenna (RA), Italy |                                    |
|------------------------------------+------------------------------------|



From p.dalgaard at biostat.ku.dk  Tue Jan 21 09:25:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Jan 21 09:25:04 2003
Subject: [R] ave across columns
In-Reply-To: <3E2CFDB0.13935.DECBC@localhost>
References: <29060717.1043080070@HL130.fdl.pitt.edu>
	<3E2CFDB0.13935.DECBC@localhost>
Message-ID: <x2of6aap0d.fsf@biostat.ku.dk>

"Petr Pikal" <petr.pikal at precheza.cz> writes:

> On 20 Jan 2003 at 17:46, Hedderik van Rijn wrote:
> 
> > x <- matrix(rnorm(60),20)
> > x[sample(1:60,10)] <- NA
> > apply(x,1,mean,na.rm=T)
> or simply
> 
> colMeans(x,na.rm=T)

rowMeans, you mean.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Tue Jan 21 09:29:25 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue Jan 21 09:29:25 2003
Subject: [R] Logistic regression:  At times correlation matrix of
 coefficients gets messed up
In-Reply-To: <000e01c2c0f4$c65249b0$eb166e81@campus.ad.utdallas.edu>
Message-ID: <Pine.WNT.4.44.0301210800520.3760-100000@petrel>

It's not messed up, just someone's idea of a compact display.

Options are

1) Use vcov(fit) instead

2) Use print(summary(fit), symbolic.cor=FALSE)

Does anyone think that the current arrangement (use this scheme for more
than 4 coefficients) is sensible?  Surely the abbreviations are not
("(" for intercept?), and why is the diagonal being shown but the top row
and last column have been omitted?   If the whole matrix was shown, the
column labels could be omitted.

I'd much prefer symbolic.cor=FALSE to be the default.

On Mon, 20 Jan 2003, Pankaj Choudhary wrote:

>
> Hi,
>
> When I include a categorical variable (RACE with 3 levels - "white",
> "black" and "other") in my logistic regression model, the correlation
> matrix of the coefficients gets messed up. I get something like:
>
> -----------------------------------------
> Correlation of Coefficients:
>           ( A L RACEb
> AGE       , 1
> LWT       ,   1
> RACEblack       1
> RACEother .     .
> attr(,"legend")
> [1] 0 ` ' 0.3 `.' 0.6 `,' 0.8 `+' 0.9 `*' 0.95 `B' 1
> -------------------------------------
>
> I couldn't figure out how to interpret it. Here is the sequence of
> commands and the complete output. (I am using R 1.6.2)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Tue Jan 21 09:35:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Jan 21 09:35:02 2003
Subject: [R] bayesian text classification...
In-Reply-To: <87iswjow5z.fsf@jeeves.blindglobe.net>
References: <87iswjow5z.fsf@jeeves.blindglobe.net>
Message-ID: <x2smvmap58.fsf@biostat.ku.dk>

rossini at blindglobe.net (A.J. Rossini) writes:

> for Spam.
> 
> In the process of setting up a more effective spam filtering system, I
> just noticed that bogofilter, which implements extensions of the (a?) 
> "Naive Bayes" text classification approach, will dump out R data
> frames; the man page suggests how to "integrate" it with R for
> verification.  (sort of, that is).
> 
> Anyway, for those of you looking for silly and perhaps interesting
> problems/datasets for your engineering or comp-sci statistics classes,
> this one looks quite amusing...
> 
> Looks like Eric Raymond knows (about) R -- a script is apparently
> included in the source according to the man page, though I couldn't
> find it in the Debian package.

The text in http://www.bgl.nu/bogofilter/BcrFisher.html certainly has
one. It could be interesting to try and figure out what is actually
going on there - some of it certainly looks weird, and last time I
looked at "Naive Bayes" I got the impression that these people would
label anything returning a probability as "Bayesian"...  

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Tue Jan 21 09:40:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 21 09:40:03 2003
Subject: [R] problems when compiling package 'norm'
In-Reply-To: <10f50911416b.11416b10f509@ono.com>
Message-ID: <Pine.LNX.4.44.0301210823130.6369-100000@gannet.stats>

See the R-help for yesterday.  You need libreadline-dev or 
libreadline-devel installed, and you must have installed from an rpm
or you could never have got here.  You can go to R_HOME/etc/Makeconf and
delete -lreadline and -lncurses from FLIBS to avoid this.

Also, you are using gcc `2.96' and that is known to be broken in various 
ways, notably with g77.

On Tue, 21 Jan 2003 arv at ono.com wrote:

> Dear All,
> 
> Trying to install package 'norm' under linux-mandrake8.2 I've got the
> following messages:
> 
> R CMD INSTALL norm_1.0-9.tar.gz
> * Installing *source* package 'norm' ...
> ** libs
> g77 -mieee-fp  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro
> -march=i586 -fno-fast-math -fno-strength-reduce  -O3
> -fomit-frame-pointer -pipe -mcpu=pentiumpro -march=i586 -fno-fast-math
> -fno-strength-reduce -c norm.f -o norm.o
> gcc -shared -L/usr/local/lib -o norm.so norm.o  -L/usr/local/lib
> -L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/2.96
> -L/usr/lib/gcc-lib/i586-mandrake-linux-gnu/2.96/../../..
> -lreadline -ldl -lncurses -lg2c -lm -L/usr/lib/R/bin -lR
> /usr/bin/ld: cannot find -lreadline
> collect2: ld returned 1 exit status
> make: *** [norm.so] Error 1
> ERROR: compilation failed for package 'norm'
> 
> My libreadline's are under /lib. I've tried with: 
> 
> R CMD INSTALL --with=/lib norm_1.0-9.tar.gz
> 
> but same results
> 
> Thanks in advance
> 
> Antonio
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mk36 at aub.edu.lb  Tue Jan 21 09:44:24 2003
From: mk36 at aub.edu.lb (Marwan Khawaja)
Date: Tue Jan 21 09:44:24 2003
Subject: [R] proxy connection
In-Reply-To: <3E2ABB4A.DE7DCBFD@statistik.uni-dortmund.de>
Message-ID: <CLECJBOEBGOMOKJHJNDACECCCMAA.marwan.khawaja@aub.edu.lb>

Thanks to Uwe Ligges, Peter Dalgaard and Brian Ripley for your prompt reply.

The FAQ says:

We have had several reports of this, although they do work for us on
_all_ of our machines.  There are two known possible fixes.

(a) Use the alternative `internet2.dll' by starting R with the flag
`--internet2' (*note How do I install R for Windows?::) which uses the
Internet Explorer internals (and so needs Internet Explorer 4 or later
installed).

(b) A proxy needs to be set up: see `?download.file'.
.........

I tried the first option -- adding '--internet2' -- but I still get the same
error msg.
I wonder if anyone on the list has instructions re option (b) in English?
TIA Marwan


> >
> > "internet2.dll (see changes for rw1030) must be selected by the
> > --internet2 flag."
> >
> > Uwe Ligges
>
> BTW: See ?download.file for details.
>
> Uwe Ligges
>
> > > But I still get an error when trying to update packages:  'Rgui.exe has
> > > generated errors and will be closed by Windows'
> > > Any hint would be appreciated.
> > > I know this has been discussed before but I do not seem to find
> the thread --
> > > TIA Marwan Khawaja
> > >
> > > platform i386-pc-mingw32
> > > arch     i386
> > > os       mingw32
> > > system   i386, mingw32
> > > status
> > > major    1
> > > minor    6.2
> > > year     2003
> > > month    01
> > > day      10
> > > language R
>



From arv at ono.com  Tue Jan 21 09:51:04 2003
From: arv at ono.com (antonio rodriguez)
Date: Tue Jan 21 09:51:04 2003
Subject: Summary: [R] problems when compiling package 'norm'
References: <17634721EB46D611A35E0002A5424F170600900A@cor-exg1.devon.gov.uk>
Message-ID: <00a701c2c129$b3c139c0$0300a8c0@ono>

Dear All,

Thanks a lot for this quick help. I've managed to solve the issue. The
problem was that I haven't installed the readline-devel and ncurse-devel
packages. It compiled nicely

Cheers,

Antonio


---



From ripley at stats.ox.ac.uk  Tue Jan 21 09:56:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 21 09:56:03 2003
Subject: [R] proxy connection
In-Reply-To: <CLECJBOEBGOMOKJHJNDACECCCMAA.marwan.khawaja@aub.edu.lb>
Message-ID: <Pine.LNX.4.44.0301210850360.6420-100000@gannet.stats>

On Tue, 21 Jan 2003, Marwan Khawaja wrote:

> Thanks to Uwe Ligges, Peter Dalgaard and Brian Ripley for your prompt reply.
> 
> The FAQ says:
> 
> We have had several reports of this, although they do work for us on
> _all_ of our machines.  There are two known possible fixes.
> 
> (a) Use the alternative `internet2.dll' by starting R with the flag
> `--internet2' (*note How do I install R for Windows?::) which uses the
> Internet Explorer internals (and so needs Internet Explorer 4 or later
> installed).
> 
> (b) A proxy needs to be set up: see `?download.file'.
> .........
> 
> I tried the first option -- adding '--internet2' -- but I still get the same
> error msg.

Did you repair the damage you did to your system?  Perhaps try 
re-installing R?

> I wonder if anyone on the list has instructions re option (b) in English?

The help file you mention is in English!

> TIA Marwan
> 
> 
> > >
> > > "internet2.dll (see changes for rw1030) must be selected by the
> > > --internet2 flag."
> > >
> > > Uwe Ligges
> >
> > BTW: See ?download.file for details.
> >
> > Uwe Ligges
> >
> > > > But I still get an error when trying to update packages:  'Rgui.exe has
> > > > generated errors and will be closed by Windows'
> > > > Any hint would be appreciated.
> > > > I know this has been discussed before but I do not seem to find
> > the thread --
> > > > TIA Marwan Khawaja
> > > >
> > > > platform i386-pc-mingw32
> > > > arch     i386
> > > > os       mingw32
> > > > system   i386, mingw32
> > > > status
> > > > major    1
> > > > minor    6.2
> > > > year     2003
> > > > month    01
> > > > day      10
> > > > language R
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jarioksa at sun3.oulu.fi  Tue Jan 21 10:01:07 2003
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Tue Jan 21 10:01:07 2003
Subject: [R] problems when compiling package 'norm'
In-Reply-To: <Pine.LNX.4.44.0301210823130.6369-100000@gannet.stats>
References: <Pine.LNX.4.44.0301210823130.6369-100000@gannet.stats>
Message-ID: <1043139511.5785.5.camel@pc112145.oulu.fi>

On Tue, 2003-01-21 at 10:26, ripley at stats.ox.ac.uk wrote:

> Also, you are using gcc `2.96' and that is known to be broken in various 
> ways, notably with g77.
> 
I don't want to defend Red Hat's unfortunate choice of their own gcc
("2.96") -- and it is even more surprising that other Linux distributors
have followed their design. However, my experience is that g77-2.96 was
the first more or less working Fortran compiler in Linux. The previous
ones simply gave segfaults in R libraries or even crashed R when loading
a library. Well, I don't use gcc 2.96, so this is an academic defence
now...

cheers, jari oksanen



From mk36 at aub.edu.lb  Tue Jan 21 10:15:04 2003
From: mk36 at aub.edu.lb (Marwan Khawaja)
Date: Tue Jan 21 10:15:04 2003
Subject: [R] proxy connection
In-Reply-To: <Pine.LNX.4.44.0301210850360.6420-100000@gannet.stats>
Message-ID: <CLECJBOEBGOMOKJHJNDAIECDCMAA.marwan.khawaja@aub.edu.lb>

Hello again,
It seems I did damage my system -- I re-insalled R and installed it again but I
get the following msg when exiting R.
Application error:
The instructions at "0x005691da" referenced memory at "0x0000118"
The memory could not be written.
Any help on how to proceed would be greatly appreciated!
TIA Marwan

--------------------------------------------------------------------------------
---------------------------------
Marwan Khawaja 		http://webfaculty.aub.edu.lb/~mk36/  if you have MS Explorer
--------------------------------------------------------------------------------
---------------------------------



> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Tuesday, January 21, 2003 12:53 AM
> To: Marwan Khawaja
> Cc: R
> Subject: RE: [R] proxy connection
>
>
> On Tue, 21 Jan 2003, Marwan Khawaja wrote:
>
> > Thanks to Uwe Ligges, Peter Dalgaard and Brian Ripley for your prompt reply.
> >
> > The FAQ says:
> >
> > We have had several reports of this, although they do work for us on
> > _all_ of our machines.  There are two known possible fixes.
> >
> > (a) Use the alternative `internet2.dll' by starting R with the flag
> > `--internet2' (*note How do I install R for Windows?::) which uses the
> > Internet Explorer internals (and so needs Internet Explorer 4 or later
> > installed).
> >
> > (b) A proxy needs to be set up: see `?download.file'.
> > .........
> >
> > I tried the first option -- adding '--internet2' -- but I still get the same
> > error msg.
>
> Did you repair the damage you did to your system?  Perhaps try
> re-installing R?
>
> > I wonder if anyone on the list has instructions re option (b) in English?
>
> The help file you mention is in English!
>
> > TIA Marwan
> >
> >
> > > >
> > > > "internet2.dll (see changes for rw1030) must be selected by the
> > > > --internet2 flag."
> > > >
> > > > Uwe Ligges
> > >
> > > BTW: See ?download.file for details.
> > >
> > > Uwe Ligges
> > >
> > > > > But I still get an error when trying to update packages:
> 'Rgui.exe has
> > > > > generated errors and will be closed by Windows'
> > > > > Any hint would be appreciated.
> > > > > I know this has been discussed before but I do not seem to find
> > > the thread --
> > > > > TIA Marwan Khawaja
> > > > >
> > > > > platform i386-pc-mingw32
> > > > > arch     i386
> > > > > os       mingw32
> > > > > system   i386, mingw32
> > > > > status
> > > > > major    1
> > > > > minor    6.2
> > > > > year     2003
> > > > > month    01
> > > > > day      10
> > > > > language R
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From ripley at stats.ox.ac.uk  Tue Jan 21 10:23:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 21 10:23:02 2003
Subject: [R] problems when compiling package 'norm'
In-Reply-To: <1043139511.5785.5.camel@pc112145.oulu.fi>
Message-ID: <Pine.LNX.4.44.0301210917290.6474-100000@gannet.stats>

2.95.3 was and is fine, and prior to `2.96' the advice was to use it,
to the frequent posters on R-help who had exactly the symptoms you 
described with `2.96'.  Note that Linux distros usually shipped with
obselete versions (e.g. egcs) at that point.

Did you actually use 2.95.3 (or 2.95.2)?

One problem with `2.96' is that it was a snapshot of the development 
version, and there are many different compilers out there under that 
alias.

On 21 Jan 2003, Jari Oksanen wrote:

> On Tue, 2003-01-21 at 10:26, ripley at stats.ox.ac.uk wrote:
> 
> > Also, you are using gcc `2.96' and that is known to be broken in various 
> > ways, notably with g77.
> > 
> I don't want to defend Red Hat's unfortunate choice of their own gcc
> ("2.96") -- and it is even more surprising that other Linux distributors
> have followed their design. However, my experience is that g77-2.96 was
> the first more or less working Fortran compiler in Linux. The previous
> ones simply gave segfaults in R libraries or even crashed R when loading
> a library. Well, I don't use gcc 2.96, so this is an academic defence
> now...

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From impromptu at nifty.com  Tue Jan 21 10:49:03 2003
From: impromptu at nifty.com (impromptu@nifty.com)
Date: Tue Jan 21 10:49:03 2003
Subject: [R] 2-dimensional probability density surface using thin-plate spline
Message-ID: <200301210949.AA00223@impromptu.nifty.com>

R-users
E-mail: r-help at stat.math.ethz.ch

     I have a problem with usage of "gss". I would like to obtain
2-dimensional probability density surface using thin-plate spline.
My object is below:

function()
{
# (1)
    library(gss) 
    set.seed(2523)
    xx1 <- c(rnorm(60, mean=3, sd=2), rnorm(40 , mean=9, sd=1))
    xx2 <- c(rnorm(60, mean=4, sd=2), rnorm(40 , mean=10, sd=1))
# (2)
    br1 <- seq(from = floor(min(xx1)*2)/2, to = ceiling(max(xx1)*2)/2+0.5, by = 0.5)
    br2 <- seq(from = floor(min(xx2)*2)/2, to = ceiling(max(xx2)*2)/2+0.5, by = 0.5)
    quad1_expand.grid(br1, br2)
    wt1_rep(1, nrow(quad1))
    data1 <- data.frame(x1 = xx1, x2 = xx2)
    fit1 <- ssden(~x1:x2, data=data1,  type="tp", quad = list(pt=quad1, wt=wt1), order=2,
     domain=data.frame( x1=c(br1[1], br1[length(br1)] ), x2=c(br2[1], br2[length(br2)] )) )
# (3)
    midp1 <- br1[1:(length(br1)-1)]+(br1[2]-br1[1])*0.5 
    midp2 <- br2[1:(length(br2)-1)]+(br2[2]-br2[1])*0.5 
    midpg_expand.grid(midp1, midp2)   
    data2 <- data.frame(x1=midpg[,1], x2=midpg[,2])
    ey <- dssden(fit1, data2) 
    ey_matrix(ey, ncol=length(midp2))   
    print(ey)
}

The result is:

Error in array(x, c(length(x), 1), if (!is.null(names(x))) list(names(x),  : 
        attempt to set an attribute on NULL

   I am just wondering what causes this.

   *****    Kunio Takezawa, Ph.D. (takezawa at affrc.go.jp)    *****
*****     <http://cse.inada.affrc.go.jp/takezawa/patent-c.html>    *****



From Ted.Harding at nessie.mcc.ac.uk  Tue Jan 21 11:05:06 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue Jan 21 11:05:06 2003
Subject: [R] Logistic regression:  At times correlation matrix of coe
In-Reply-To: <Pine.WNT.4.44.0301210800520.3760-100000@petrel>
Message-ID: <XFMail.030121091922.Ted.Harding@nessie.mcc.ac.uk>

On 21-Jan-03 Prof Brian D Ripley wrote:
> Does anyone think that the current arrangement (use this scheme
> for more than 4 coefficients) is sensible?

Not particularly, I think.

> Surely the abbreviations are not ("(" for intercept?), and why is
> the diagonal being shown but the top row and last column have been
> omitted?   If the whole matrix was shown, the column labels could
> be omitted.

Agreed; and not only is the whole thing ugly, but it is visually
difficult to interpret.

> I'd much prefer symbolic.cor=FALSE to be the default.

Hear, Hear! I stubbed my toe on this myself a while ago, until some
kind souls on the list directed me to this option (lurking not where
I had been groping for it ... ). When one needs this matrix, it is
usually because one wants to get at the numerical values.

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 21-Jan-03                                       Time: 09:19:22
------------------------------ XFMail ------------------------------



From pac at Uhb.Fr  Tue Jan 21 11:49:02 2003
From: pac at Uhb.Fr (Pierre-Andre Cornillon)
Date: Tue Jan 21 11:49:02 2003
Subject: [R] Command History
In-Reply-To: <3E2C2F1C.8274176@legerity.com>
Message-ID: <Pine.LNX.4.44.0301211136350.18090-100000@sa2391.rec.uhb.fr>

Hello,

I had the same problem with Solaris 7 and 8. I just
re-compile readline (I used the readline-4.2) and recompile R
and no problem afterwards. I think it's better
not using the sunfreeware package of readline, it doesn't works properly
(1 year ago).

Good luck

PS
a/ to have static or shared library for readline 4.2 you have
2 different make steps (it is written in README somewhere and not
in the INSTALL file)
./configure
make
make intall
make shared
make install-shared
b/ I had some problem with bash2.05 and readline4.3 (on sparc-linux) so
may be readline4.3 is too new ?

On Mon, 20 Jan 2003, Russell D. Pierce wrote:

> I have compiled R under Solaris 7 (SunOS 5.7) with the readline-4.0
> library linked.  Command line editing appears to work, but I cannot
> access command history.  If I execute several commands in R, then type
> "history()", I get the error message "Error in savehistory(file) : no
> history available to save".  Also, previous command recall (C-p) does
> not seem to work.  I am invoking R directly from a Korn shell prompt.
> Can you help?
>
> Russ Pierce
> Legerity, Inc.
> Reading, PA
>



From Morten.Sickel at nrpa.no  Tue Jan 21 13:25:03 2003
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Tue Jan 21 13:25:03 2003
Subject: [R] Plot using different symbols depending on value.
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5D8C@postix.nrpa.no>

I am making a plot from R indicating an average, min and max value for a
number of sample types. as horizontal lines with the sample types on the
y-axis. (see http://home.newmedia.no/sickel/R.html for the plot and code) In
some cases, the min value is the detection limit, and I would like to
indicate that bu using a <, rather than the usual | I use for indicating the
value.
I am plotting each of the values using:

  points(low[s],s+offset,col=i/3,pch='I')

Is it some kind of inline if, iif(cond,true,false), function in R? I have
looked for it but not found it.

Regards

Moretn



From Roger.Bivand at nhh.no  Tue Jan 21 13:47:03 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue Jan 21 13:47:03 2003
Subject: [R] Plot using different symbols depending on value.
In-Reply-To: <54DE9A561AD20C4D9FF88B116965420E4E5D8C@postix.nrpa.no>
Message-ID: <Pine.LNX.4.44.0301211342270.31918-100000@reclus.nhh.no>

On Tue, 21 Jan 2003, Morten Sickel wrote:

> I am making a plot from R indicating an average, min and max value for a
> number of sample types. as horizontal lines with the sample types on the
> y-axis. (see http://home.newmedia.no/sickel/R.html for the plot and code) In
> some cases, the min value is the detection limit, and I would like to
> indicate that bu using a <, rather than the usual | I use for indicating the
> value.
> I am plotting each of the values using:
> 
>   points(low[s],s+offset,col=i/3,pch='I')
> 
> Is it some kind of inline if, iif(cond,true,false), function in R? I have
> looked for it but not found it.

Maybe ifelse(test, yes, no), for a value of the same shape as test?

pch=ifelse(test, "I", "<") should work for points, I think.

> 
> Regards
> 
> Morten
 
-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From petr.pikal at precheza.cz  Tue Jan 21 14:13:03 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue Jan 21 14:13:03 2003
Subject: [R] Plot using different symbols depending on value.
In-Reply-To: <Pine.LNX.4.44.0301211342270.31918-100000@reclus.nhh.no>
References: <54DE9A561AD20C4D9FF88B116965420E4E5D8C@postix.nrpa.no>
Message-ID: <3E2D5553.20433.1643E5C@localhost>

Hi

On 21 Jan 2003 at 13:46, Roger Bivand wrote:

> On Tue, 21 Jan 2003, Morten Sickel wrote:
> 
> > I am making a plot from R indicating an average, min and max value
> > for a number of sample types. as horizontal lines with the sample
> > types on the y-axis. (see http://home.newmedia.no/sickel/R.html for
> > the plot and code) In some cases, the min value is the detection
> > limit, and I would like to indicate that bu using a <, rather than
> > the usual | I use for indicating the value. I am plotting each of
> > the values using:
> > 
> >   points(low[s],s+offset,col=i/3,pch='I')
> > 
> > Is it some kind of inline if, iif(cond,true,false), function in R? I
> > have looked for it but not found it.
> 
> Maybe ifelse(test, yes, no), for a value of the same shape as test?
> 
> pch=ifelse(test, "I", "<") should work for points, I think.

or you can use vectorised input for pch like

x<-rnorm(10)
psymb<-c("I","<")
plot(1:10,x,type="n")
points(1:10,x,pch=psymb[(x<0)+1])


> 
> > 
> > Regards
> > 
> > Morten
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School
> of Economics and Business Administration, Breiviksveien 40, N-5045
> Bergen, Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93 e-mail:
> Roger.Bivand at nhh.no
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

Cheers

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From jfox at mcmaster.ca  Tue Jan 21 15:43:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue Jan 21 15:43:03 2003
Subject: [R] running R inside of e-macs
In-Reply-To: <001e01c2c0f8$2b736380$bfbde440@family>
Message-ID: <5.1.0.14.2.20030121093943.01def4d0@mcmail.cis.mcmaster.ca>

Dear Chris or Laura,

Not finding .Rhistory on first use is normal. Since you mention Rterm, I 
guess that you're using Windows. I've prepared some instructions for use of 
ESS with Windows (oriented towards XEmacs rather than Emacs), which are at 
<http://socserv.socsci.mcmaster.ca/jfox/Books/Companion/ESS/index.html>.

Maybe these would be of some use to you.

John

At 09:52 PM 1/20/2003 -0500, Chris & Laura McRae wrote:
>I can't start r inside of  emacs. When I try it says that it cannot find 
>.Rhistory and then it says " This program ( pressumably Rterm) has 
>performed an illegal operation and will be shut down.". How can I fix this 
>problem?
>
>         [[alternate HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From dkitch at sdac.harvard.edu  Tue Jan 21 16:25:03 2003
From: dkitch at sdac.harvard.edu (Doug Kitch)
Date: Tue Jan 21 16:25:03 2003
Subject: [R] rpart help
Message-ID: <Pine.GSO.4.05.10301211020020.10103-100000@fellini.harvard.edu>

Hello.  I am not sure if you can help me or not but I have a dataset with
N ~ 4000 with binary response and p ~ 0.08, regardless of how many or
how few variables I offer I get the following message: 'Error in
rpart(formula, method="class"): No splits could be created Dumped.' If I
run tree with the same dataset (no missing data) in S I get results.  Is
there a problem with large datasets in rpart?

Also, do you happen to know the parameter options which
will make rpart and tree act the same.  I am wondering if
this is possible since I have no missing data.
  
Thank you for any help you can offer,
Doug Kitch

Doug Kitch, M.S.
Statistician/COMP RAC
SDAC/Harvard School of Public Health
FXB Bldg. Room 504
651 Huntington Avenue
Boston, MA 02115
Phone: (617) 432-3281
FAX:   (617) 432-3163
Email: dkitch at sdac.harvard.edu



From cmoffet at nwrc.ars.usda.gov  Tue Jan 21 16:35:03 2003
From: cmoffet at nwrc.ars.usda.gov (Corey Moffet)
Date: Tue Jan 21 16:35:03 2003
Subject: [R] Modified F-test for heterogeneous error variances
Message-ID: <3.0.6.32.20030121083417.0103eaa0@nwrc.ars.usda.gov>

Dear R-help:

Does anyone know of a package in R that will do Welch's modified F-test
for heterogeneous error variances?  Are there other statistical techniques
available in R that test the equality of means when homoscedastisity
is violated?  't.test' does this in the pairwise sense when var.equal =
TRUE.
With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Support Scientist

University of Idaho
Northwest Watershed Research Center
800 Park Blvd, Plaza IV, Suite 105
Boise, ID 83712-7716
(208) 422-0718



From ripley at stats.ox.ac.uk  Tue Jan 21 16:40:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 21 16:40:03 2003
Subject: [R] rpart help
In-Reply-To: <Pine.GSO.4.05.10301211020020.10103-100000@fellini.harvard.edu>
Message-ID: <Pine.LNX.4.44.0301211532540.16701-100000@gannet.stats>

On Tue, 21 Jan 2003, Doug Kitch wrote:

> Hello.  I am not sure if you can help me or not but I have a dataset with
> N ~ 4000 with binary response and p ~ 0.08, regardless of how many or
> how few variables I offer I get the following message: 'Error in
> rpart(formula, method="class"): No splits could be created Dumped.' If I
> run tree with the same dataset (no missing data) in S I get results.  Is
> there a problem with large datasets in rpart?

If there were it would not be relevant: 4000 is not close to `large'.

I suspect you ought to be using losses with such a skewed binary 
response, and am not surprised that no single split is effective.

?rpart.control should help you.

> Also, do you happen to know the parameter options which
> will make rpart and tree act the same.  I am wondering if
> this is possible since I have no missing data.

It's not exactly possible, but look in MASS4 for some comparisons.
Given that tree in S does not do what it is documented to do, it would be 
hard to reproduce, but tree in R comes pretty close to tree in S's 
documented behaviour.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mhoward at micron.com  Tue Jan 21 16:45:04 2003
From: mhoward at micron.com (mhoward)
Date: Tue Jan 21 16:45:04 2003
Subject: FW: [R] Contour Plots
Message-ID: <D7E178FC91F3D21186A90008C7B9A5B811484819@ntexchange09.micron.com>

Huan,

  If you have not already received an answer, try this, it helped me
immensely and solved my problem.

Mike

-----Original Message-----
From: Roger Peng [mailto:rpeng at stat.ucla.edu]
Sent: Wednesday, January 15, 2003 9:30 AM
To: mhoward
Cc: 'r-help at lists.R-project.org'
Subject: Re: [R] Contour Plots


I believe this was discussed about two days ago -- check the archives
under the subject "density plot - beginner's question" -- and there were
some good answers.  Basically, the x and y vectors have to be increasing
and response or Level, as you call it, needs to be in the form of a matrix
of dimension length(x) by length(y).  If the response/Level is not in the
form of a matrix, you will need to smoooth or interpolate.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 15 Jan 2003, mhoward wrote:

> r-help,
> 
>  I can't seem to get the below data organized in such a manner so as to
> generate a contour plot
> using any of the functions {lattice.contourplot, base.contour,
> base.filled.contour}. I was wondering
> if anyone could please tell me what I need to do to accomplish this.
> 
> 
> X,Y,Level
> -31.105,86.911,3843
> -3.385,86.911,3896
> 24.335,86.911,3874
> -24.175,79.700,3900
> -3.385,79.700,3927
> 17.405,79.700,3922
> -51.895,72.489,3874
> 52.056,72.489,3898
> -44.965,65.278,3914
> 45.125,65.278,3951
> -24.175,58.067,3931
> 17.405,58.067,3942
> -79.615,50.856,3831
> 72.845,50.856,3914
> -72.685,43.645,3891
> 65.915,43.645,3972
> -44.965,36.434,3921
> -3.385,36.434,3889
> 38.195,36.434,3965
> -93.475,22.012,3812
> 86.705,22.012,3913
> -86.545,14.801,3876
> -65.755,14.801,3927
> -24.175,14.801,3861
> 17.405,14.801,3872
> 58.985,14.801,3999
> 79.775,14.801,3970
> -93.475,-6.832,3848
> -86.545,-6.832,3894
> -44.965,-6.832,3905
> -3.385,-6.832,3848
> 38.195,-6.832,3949
> 79.775,-6.832,3983
> 86.705,-6.832,3942
> -86.545,-21.254,3880
> 79.775,-21.254,3967
> -93.475,-28.465,3839
> -65.755,-28.465,3945
> -24.175,-28.465,3906
> 17.405,-28.465,3931
> 58.985,-28.465,4011
> 86.705,-28.465,3899
> -72.685,-50.098,3906
> -44.965,-50.098,3971
> -3.385,-50.098,3956
> 38.195,-50.098,4007
> 65.915,-50.098,3970
> -79.615,-57.309,3894
> 72.845,-57.309,3896
> -58.825,-64.520,3925
> 52.055,-64.520,3964
> -65.755,-71.731,3868
> -24.175,-71.731,3972
> 17.405,-71.731,3989
> 58.985,-71.731,3894
> -17.245,-86.153,3926
> -3.385,-86.153,3943
> 10.475,-86.153,3935
> -24.175,-93.364,3855
> -3.385,-93.364,3894
> 17.405,-93.364,3861
> 
> Thanks,
> 
> Michael R. Howard
> Micron Technology, Inc
> Fab C Engineering Software (FCES)
> Phone368 - 2352 [82352]
> Pager 90713
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From pac at Uhb.Fr  Tue Jan 21 17:41:08 2003
From: pac at Uhb.Fr (Pierre-Andre Cornillon)
Date: Tue Jan 21 17:41:08 2003
Subject: [R] R and gdb (still)
In-Reply-To: <6rlm1f95nw.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0301211313070.18090-100000@sa2391.rec.uhb.fr>

Hello,

thanks for all your answers,

1) for the method proposed by Mr Douglas Bates, I don't know if I really
understood everything as the detailed sections are not those which give me
problems. Let me recall what i have done :
in window A :
$ R
... R banner ...
> dyn.load("foo.so")
>

in window B :
$ ps -ux pac | grep R.bin ### -> gives me pid.number
$ gdb /usr/local/lib/R/bin/R.bin
.... gdb banner ....
(gdb) attach  pid.number
Attaching to program: /usr/local/lib/R/bin/R.bin, process 20266
Reading symbols from /usr/lib/libblas.so.3...done.
... etc ...
Reading symbols from /home/pac/foo.so...done.
Loaded symbols for /home/pac/foo.so
0x703346f8 in select () from /lib/libc.so.6
(gdb) b foo.c:21
Breakpoint 1 at 0x705c6004: file foo.c, line 21.
(gdb)  signal 0
Continuing with no signal.

I return to window A which is now active
> foo(Xcr)
gives me directly the result without stopping at the breakpoint -> the
same result as
$ R -d gdb
...
But may be I misunderstood your method somewhere (I am not a
programmer nor a native english speaker)

Thanks for recalling me to ess too but as I ran it from within emacs and
it locks from time to time emacs, I stopped using it except for simple
computations. I wonder if it is better within xemacs ?
gud, well I don't know what it is but breakpoints first...
---------------------------

2) for the method proposed by Mr Robert Gentleman,
$ R -d ddd

In ddd windows:
- Menu program / Run in execution windows
- Run (in the toolbar DDD)

In DDD: Execution Window (ie an xterm -e R)
> dyn.load("foo.so")

In ddd windows:
- Interrupt (in the toolbar DDD) - (or C-c in gdb)
(gdb) b foo.c:21  (in gdb subwindow) - (or Source menu / breakpoints)
- Cont - (or signal 0 in gdb subwindows)

In DDD: Execution Window (now active)
> foo(Xcr)
... gives the result without stopping at the breakpoint
But may be I misunderstood your method somewhere (I am not a
programmer nor  a native english speaker)

But as it is a gui of gdb I think this has to give the same result
(but who knows... in computer science sometimes switch off/switch on
gives good results, sometimes). But thanks a lot for introducing me to
ddd, this seems fine and pretty.


3) As the same programs with quite the same operating system (linux
sparc and linux PC) and software
gives different results may be is there any test which I can run on other
program than R to know if it is R-1.6.2 on sparc or gdb 5.2.1 which have some
problems. I just recall that i have already done simple test with gdb.

Thanks for all, and if any (even slight) hints...

Pierre-Andre Cornillon



From rdiaz at cnio.es  Tue Jan 21 18:14:05 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Tue Jan 21 18:14:05 2003
Subject: [R] books on categorical data analyses
Message-ID: <200301211813.14074.rdiaz@cnio.es>

Dear All,

We are about to purchase the second edition of Agresti's "Categorical Data 
Analysis" (my old copy of the first ed. of that wonderful book is falling 
apart). I would appreciate suggestions about other comparable books which, if 
possible, have examples using R/S code (instead of SAS).

Thanks,

Ram?n


-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
http://bioinfo.cnio.es/~rdiaz



From bates at stat.wisc.edu  Tue Jan 21 19:19:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue Jan 21 19:19:03 2003
Subject: [R] Re: R and gdb (still)
In-Reply-To: <Pine.LNX.4.44.0301211313070.18090-100000@sa2391.rec.uhb.fr>
References: <Pine.LNX.4.44.0301211313070.18090-100000@sa2391.rec.uhb.fr>
Message-ID: <6rn0lue58s.fsf@bates4.stat.wisc.edu>

You are setting a breakpoint at an explicit line number

(gdb) b foo.c:21
Breakpoint 1 at 0x705c6004: file foo.c, line 21.

A safer way of setting the breakpoint is on the function name that the
R function "foo" calls through .C or .Call.  That way you are ensured
that the breakpoint will be encountered.  Line numbering within the
debugger can be peculiar and it may happen that the debugger never
gets to a point that it recognizes as being on line 21.



From ravishan at fas.harvard.edu  Tue Jan 21 21:20:03 2003
From: ravishan at fas.harvard.edu (Nirmala Ravishankar)
Date: Tue Jan 21 21:20:03 2003
Subject: [R] Graphics related questions
Message-ID: <Pine.OSF.4.44.0301211459420.16430-100000@is07.fas.harvard.edu>

While using xyplot or barchart, how does on move the x or y axis?  I am
trying to plot ratios ranging from 0.77 to 1.3 in a bargraph, with the y
axis at x = 1.  I want ratios greater than 1 to appear as on the right side of the y-axis
and the ratios less than 1 to appear on the left.


My dataframe US looks like this

State  Ratio

MA     1.3
CT     1.02
TX     0.9
AK     0.77

When I do barchart(formula = State ~ Ratio, data = US), the y axis is
positioned at x = 0.7.  How do I move it to x = 1?

Thanks,
Nirmala



From GBLEVINS at marketsolutionsgroup.com  Tue Jan 21 22:24:05 2003
From: GBLEVINS at marketsolutionsgroup.com (Greg Blevins)
Date: Tue Jan 21 22:24:05 2003
Subject: [R] Question regarding sequencial clustering
Message-ID: <se2d65ef.021@mail.marketsolutionsgroup.com>

Hello R-folks,

I looked through the CRAN site and did not discover an algorithm for performing sequential clustering.  Does such an algorithm exist?


Thanks in advance,

Gregory L. Blevins
Vice President, Partner
The Market Solutions Group, Inc.
gblevins at marketsolutionsgroup.com
Office phone: 612 392-3163
Cell phone: 612 251-0232



From p.connolly at hortresearch.co.nz  Tue Jan 21 22:31:02 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue Jan 21 22:31:02 2003
Subject: [R] problems when compiling package 'norm'
In-Reply-To: <Pine.LNX.4.44.0301210823130.6369-100000@gannet.stats>
References: <10f50911416b.11416b10f509@ono.com> <Pine.LNX.4.44.0301210823130.6369-100000@gannet.stats>
Message-ID: <20030121212715.GC6373@hortresearch.co.nz>

On Tue, 21-Jan-2003 at 08:26AM +0000, ripley at stats.ox.ac.uk wrote:

|> See the R-help for yesterday.  You need libreadline-dev or 
|> libreadline-devel installed, and you must have installed from an rpm
|> or you could never have got here.  You can go to R_HOME/etc/Makeconf and
|> delete -lreadline and -lncurses from FLIBS to avoid this.
|> 
|> Also, you are using gcc `2.96' and that is known to be broken in various 
|> ways, notably with g77.

I don't quite follow this discussion.  I have had no such problems
with gcc 2.96 on Redhat 7.3, even with norm_1.0-9.tar.gz.

On my system:
$ rpm -qf /usr/bin/g77
gcc-g77-2.96-112

There is an update gcc-g77-2.96-113.i386.rpm on the Redhat site but I
don't seem to need that.  Evidently, whatever else is broken in g77,
it is not broken in this way.  Perhaps Mandrake 8.2 uses something
earlier than -112.


best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From peterson at heritage.nv.gov  Tue Jan 21 22:48:03 2003
From: peterson at heritage.nv.gov (Eric Peterson)
Date: Tue Jan 21 22:48:03 2003
Subject: [R] newbie: data frame to vector
Message-ID: <IBEKKKCOHHEDKLEJGFDIIECJCHAA.peterson@heritage.nv.gov>

Sorry, but I'm very new to R.  I'm trying to figure out how to convert a
column from a data frame to a vector.  More specifically, I have read in a
comma separated value table which contains a number of variables in columns,
plots in rows...

t <- read.table("G:/R/table1.txt", sep=",", header=TRUE)

the data comes in just fine.  Now I want to do an XY plot of 2 variables and
will be doing some statistical analyses on them.  But

plot(t["Var1"], t["Var2"])

Gives me the error, "Error in pmatch(x, table, duplicates.ok) :
        argument is not of mode character"

and

v1 <- t["Var1"]
v2 <- t["Var2"]
plot(v1, v2)

gives me the same error (of course) and v1 does not display the same as a
vector; it looks like it is an array(?)

Thanks,
-Eric

---
Eric B. Peterson
Vegetation Ecologist & Lichenologist
Nevada Natural Heritage Program
Department of Conservation and Natural Resources
1550 E. College Pkwy #137
Carson City, NV 89706
775-687-4245 x236
http://heritage.nv.gov/



From ripley at stats.ox.ac.uk  Tue Jan 21 22:52:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 21 22:52:02 2003
Subject: [R] problems when compiling package 'norm'
In-Reply-To: <20030121212715.GC6373@hortresearch.co.nz>
Message-ID: <Pine.LNX.4.44.0301212145001.27065-100000@gannet.stats>

On Wed, 22 Jan 2003, Patrick Connolly wrote:

> On Tue, 21-Jan-2003 at 08:26AM +0000, ripley at stats.ox.ac.uk wrote:
> 
> |> See the R-help for yesterday.  You need libreadline-dev or 
> |> libreadline-devel installed, and you must have installed from an rpm
> |> or you could never have got here.  You can go to R_HOME/etc/Makeconf and
> |> delete -lreadline and -lncurses from FLIBS to avoid this.
> |> 
> |> Also, you are using gcc `2.96' and that is known to be broken in various 
> |> ways, notably with g77.
> 
> I don't quite follow this discussion.  I have had no such problems
> with gcc 2.96 on Redhat 7.3, even with norm_1.0-9.tar.gz.

See gcc.gnu.org!  There is no such version of gcc, but there are several
snapshots called that by people who ought to have been more responsible.  
Your -112 is not an official version number any more than 2.96 is

This is like, but worse, calling R-devel R 1.7.0.

> On my system:
> $ rpm -qf /usr/bin/g77
> gcc-g77-2.96-112
> 
> There is an update gcc-g77-2.96-113.i386.rpm on the Redhat site but I
> don't seem to need that.  Evidently, whatever else is broken in g77,
> it is not broken in this way.  Perhaps Mandrake 8.2 uses something
> earlier than -112.
> 
> 
> best
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From deepayan at stat.wisc.edu  Tue Jan 21 22:55:23 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue Jan 21 22:55:23 2003
Subject: [R] Graphics related questions
In-Reply-To: <Pine.OSF.4.44.0301211459420.16430-100000@is07.fas.harvard.edu>
References: <Pine.OSF.4.44.0301211459420.16430-100000@is07.fas.harvard.edu>
Message-ID: <200301211551.22348.deepayan@stat.wisc.edu>

On Tuesday 21 January 2003 02:19 pm, Nirmala Ravishankar wrote:
> While using xyplot or barchart, how does on move the x or y axis?  I am
> trying to plot ratios ranging from 0.77 to 1.3 in a bargraph, with the y
> axis at x = 1.  I want ratios greater than 1 to appear as on the right side
> of the y-axis and the ratios less than 1 to appear on the left.
>
>
> My dataframe US looks like this
>
> State  Ratio
>
> MA     1.3
> CT     1.02
> TX     0.9
> AK     0.77
>
> When I do barchart(formula = State ~ Ratio, data = US), the y axis is
> positioned at x = 0.7.  How do I move it to x = 1?

This feature is currently missing (but planned for the future). This was 
discussed a while back, and a panel function which does this was posted. Try 
looking at the thread starting with

https://www.stat.math.ethz.ch/pipermail/r-help/2002-December/052506.html

Deepayan



From deepayan at stat.wisc.edu  Tue Jan 21 22:59:04 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue Jan 21 22:59:04 2003
Subject: [R] newbie: data frame to vector
In-Reply-To: <IBEKKKCOHHEDKLEJGFDIIECJCHAA.peterson@heritage.nv.gov>
References: <IBEKKKCOHHEDKLEJGFDIIECJCHAA.peterson@heritage.nv.gov>
Message-ID: <200301211556.56552.deepayan@stat.wisc.edu>

On Tuesday 21 January 2003 03:47 pm, Eric Peterson wrote:
> Sorry, but I'm very new to R.  I'm trying to figure out how to convert a
> column from a data frame to a vector.  More specifically, I have read in a
> comma separated value table which contains a number of variables in
> columns, plots in rows...
>
> t <- read.table("G:/R/table1.txt", sep=",", header=TRUE)
>
> the data comes in just fine.  Now I want to do an XY plot of 2 variables
> and will be doing some statistical analyses on them.  But
>
> plot(t["Var1"], t["Var2"])

You want t$Var1 instead of t["Var1"], etc. 

t, incidentally, is the name of an R function, so you might want to avoid 
using it as a variable name.

Deepayan



From Ko-Kang at xtra.co.nz  Tue Jan 21 23:03:04 2003
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Tue Jan 21 23:03:04 2003
Subject: [R] newbie: data frame to vector
References: <IBEKKKCOHHEDKLEJGFDIIECJCHAA.peterson@heritage.nv.gov>
Message-ID: <006801c2c198$c7d41530$d52758db@kwan022>

Hi,

----- Original Message -----
From: "Eric Peterson" <peterson at heritage.nv.gov>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, January 22, 2003 10:47 AM
Subject: [R] newbie: data frame to vector


> Sorry, but I'm very new to R.  I'm trying to figure out how to convert a
> column from a data frame to a vector.  More specifically, I have read in a
> comma separated value table which contains a number of variables in
columns,
> plots in rows...
>
> t <- read.table("G:/R/table1.txt", sep=",", header=TRUE)
>
> the data comes in just fine.  Now I want to do an XY plot of 2 variables
and
> will be doing some statistical analyses on them.  But
>
> plot(t["Var1"], t["Var2"])


I'm assuming your data frame, t, looks like:
  Var1  Var2  Var3
        1        2        3
        4        5        6
        7        8        9

Then there are (at least) two ways.  The first is type:
  attach(t)
right after your
  > t <- read.table("G:/R/table1.txt", sep=",", header=TRUE)
this will allow you to use the column names directly, i.e. you can do:
  plot(Var1, Var2)

If you do not attach it, you can still achieve your goal.  Remember that the
data frame is two dimensional, to subset a two dimensional object you need a
comma, i.e
  t[1, ]  # give you row 1
  t[, 1]  # give you column 1
  t[1, 1] # give you the first value in row 1, column 1

So to do what you want you need:
  plot(t[, 1], t[, 2])  # Plot Column 1 and 2

Hope this helps,

Kevin Wang


------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022



From kjetil at entelnet.bo  Tue Jan 21 23:08:09 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Tue Jan 21 23:08:09 2003
Subject: [R] Modified F-test for heterogeneous error variances
In-Reply-To: <3.0.6.32.20030121083417.0103eaa0@nwrc.ars.usda.gov>
Message-ID: <3E2D8C0E.9422.503EB9@localhost>

On 21 Jan 2003 at 8:34, Corey Moffet wrote:

oneway.test in package ctest (loaded by default).

Kjetil Halvorsen

> Dear R-help:
> 
> Does anyone know of a package in R that will do Welch's modified F-test
> for heterogeneous error variances?  Are there other statistical techniques
> available in R that test the equality of means when homoscedastisity
> is violated?  't.test' does this in the pairwise sense when var.equal =
> TRUE.
> With best wishes and kind regards I am
> 
> Sincerely,
> 
> Corey A. Moffet
> Support Scientist
> 
> University of Idaho
> Northwest Watershed Research Center
> 800 Park Blvd, Plaza IV, Suite 105
> Boise, ID 83712-7716
> (208) 422-0718
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Tue Jan 21 23:11:45 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Tue Jan 21 23:11:45 2003
Subject: (v2) [R] quadratic trends and changes in slopes (R-help digest, Vol 1 #52 - 16 msgs)
In-Reply-To: <000101c2c0f7$bc2f3260$2002a8c0@Enterprise>
References: <20030120110017.4630.98520.Mailman@hypatia.math.ethz.ch>
Message-ID: <3E2D8C0E.30718.503E7B@localhost>

On 20 Jan 2003 at 21:49, Chuck White wrote:

> 
> I'd like to use linear and quadratic trend analysis in order to find
> out a change in slope.  Basically, I need to solve a similar problem as
> discussed in
> http://www.gseis.ucla.edu/courses/ed230bc1/cnotes4/trend1.html
> 

This response show how to do the test of non-linearity in a 
complicated way, all can be done much easier in R, start to 
look at poly() and contr.poly() (and summary.aov with the argument 
split=). But that is not the point. The original poster did'nt want 
to test for nonlinearity, he assumed there is nonlinearity and wanted
to estimate the change point. He also said that the usual procedure
to do that in his field is to estimate cuadratic models for data
1, 1:2, 1:3, ..., 1:9 (or some similar number) and take the change-
point as the value of i above (in 1:i) where the quadratic term
first is significant. That cannot be sound, as you obviously must go
 somewhat past the changepoint before the quadratic term can become 
significant! So this method cannot possibly give an consistent 
estimator of the change-point. He should use some other method, like 
building a model with an explicit change-point and estimate that.

Kjetil Halvorsen



From chunlou at yahoo.com  Tue Jan 21 23:19:02 2003
From: chunlou at yahoo.com (Chunlou Yung)
Date: Tue Jan 21 23:19:02 2003
Subject: [R] books on categorical data analyses
In-Reply-To: <200301211813.14074.rdiaz@cnio.es>
Message-ID: <NCBBKDNFIKJKKCFELNNMEEJODDAA.chunlou@yahoo.com>

There is a S-PLUS manual (very comprehensive) for Categorical Data Analysis
written by Laura A. Thompson at

http://math.cl.uh.edu/~thompsonla/5537/Splusdiscrete.PDF

and one (briefer) by Brett Presnell at

http://web.stat.ufl.edu/~presnell/Teaching/sta4504-2000sp/R/R-CDA.pdf



> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch
> [mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of Ramon Diaz
> Sent: Tuesday, January 21, 2003 12:13 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] books on categorical data analyses
>
>
> Dear All,
>
> We are about to purchase the second edition of Agresti's
> "Categorical Data
> Analysis" (my old copy of the first ed. of that wonderful book is falling
> apart). I would appreciate suggestions about other comparable
> books which, if
> possible, have examples using R/S code (instead of SAS).
>
> Thanks,
>
> Ram?n
>
>
> --
> Ram?n D?az-Uriarte
> Bioinformatics Unit
> Centro Nacional de Investigaciones Oncol?gicas (CNIO)
> (Spanish National Cancer Center)
> Melchor Fern?ndez Almagro, 3
> 28029 Madrid (Spain)
> http://bioinfo.cnio.es/~rdiaz
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From csillery at selway.umt.edu  Wed Jan 22 01:35:04 2003
From: csillery at selway.umt.edu (Katalin Csillery)
Date: Wed Jan 22 01:35:04 2003
Subject: [R] lists to arrays
Message-ID: <Pine.OSF.4.21.0301211720090.22076-100000@selway.umt.edu>

Does anyone know how to coerce a list to an array? I have a list with
equal sized matrixes and I want to coerce it to a 3D array.
Why is that that I cannot feed in equal sized matrixes as layers to an
array even if I set dim 3?

Thanks!
Katalin
___
Katalin Csillery
Division of Biological Sciences
University of Montana, Missoula MT 59801
Phone: 406 243 6106, E-mail: csillery at selway.umt.edu
----------------------------------------------------



From hmccallum at zen.uq.edu.au  Wed Jan 22 06:11:03 2003
From: hmccallum at zen.uq.edu.au (Hamish McCallum)
Date: Wed Jan 22 06:11:03 2003
Subject: [R] Read.table for macs
Message-ID: <3E2E27C1.9000501@zen.uq.edu.au>

Dear All,

I've been using R for windows for a while, without too many problems. 
However, I'm forced to use the MAC OS system for teaching, because our 
teaching labs are mac only (not my idea!!). I have a very basic problem, 
but one that doesn't appear on the FAQs. I simply want to import data 
from a spreadsheet. I'm using exactly what works fine on Windows, namely:

1    save the file from Excel as tab-delimited, say called "test.txt", 
with the variable names in the first row.
2    Read in into R with
test<-read.table("test.txt", header=T)

It does weird things, especially if any variables are characters. For 
example, it has omitted the 5th observation for the 1st variable, and 
then appended it to the first variable name. I've tried read.csv with 
csv files, read.delim, etc. None seem to work. Am I being really silly, 
and if so, how do you do it? Or is there an easier way to get data into 
the mac port? Or is the mac port entirely useless?

Can anyone out there help?

Thanks

Hamish McCallum

-- 
Dr Hamish McCallum
Department of Zoology and Entomology
The University of Queensland
Brisbane 4072
Australia
Phone (+617) 3365 2450 Fax (+617) 3365 1655



From s195404 at student.uq.edu.au  Wed Jan 22 06:22:10 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Wed Jan 22 06:22:10 2003
Subject: [R] Read.table for macs
In-Reply-To: <3E2E27C1.9000501@zen.uq.edu.au>
References: <3E2E27C1.9000501@zen.uq.edu.au>
Message-ID: <1043212902.3e2e2a6676c36@my.uq.edu.au>

Hamish,

I usually save Excel files as CSV, and then use read.csv() to get them into R. 
Also, there are variants of read.table() that seem more successful at reading 
in delimited files (see read.delim, read.delim2).


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting Hamish McCallum <hmccallum at zen.uq.edu.au>:

> Dear All,
> 
> I've been using R for windows for a while, without too many problems. 
> However, I'm forced to use the MAC OS system for teaching, because our 
> teaching labs are mac only (not my idea!!). I have a very basic problem, 
> but one that doesn't appear on the FAQs. I simply want to import data 
> from a spreadsheet. I'm using exactly what works fine on Windows, namely:
> 
> 1    save the file from Excel as tab-delimited, say called "test.txt", 
> with the variable names in the first row.
> 2    Read in into R with
> test<-read.table("test.txt", header=T)
> 
> It does weird things, especially if any variables are characters. For 
> example, it has omitted the 5th observation for the 1st variable, and 
> then appended it to the first variable name. I've tried read.csv with 
> csv files, read.delim, etc. None seem to work. Am I being really silly, 
> and if so, how do you do it? Or is there an easier way to get data into 
> the mac port? Or is the mac port entirely useless?
> 
> Can anyone out there help?
> 
> Thanks
> 
> Hamish McCallum
> 
> -- 
> Dr Hamish McCallum
> Department of Zoology and Entomology
> The University of Queensland
> Brisbane 4072
> Australia
> Phone (+617) 3365 2450 Fax (+617) 3365 1655
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From hb at maths.lth.se  Wed Jan 22 07:29:03 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed Jan 22 07:29:03 2003
Subject: [R] Read.table for macs
In-Reply-To: <3E2E27C1.9000501@zen.uq.edu.au>
Message-ID: <000001c2c1df$7ce9cc80$7341a8c0@alpha.wehi.edu.au>

It should be the same, but then I know nothing about R or Excel for Mac.
Obvious things to check is if it is Excel or R that is the problem, i.e.
have you tested to save your Excel data on a Mac and then tried to
import it into R on a Windows machine and vice versa?

When Europe wakes up they might be able to help you out if you tell them
what version you are running. What does R.Version() say? 

Henrik Bengtsson

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Hamish McCallum
> Sent: den 22 januari 2003 16:10
> To: R-help at lists.R-project.org
> Subject: [R] Read.table for macs
> 
> 
> Dear All,
> 
> I've been using R for windows for a while, without too many problems. 
> However, I'm forced to use the MAC OS system for teaching, 
> because our 
> teaching labs are mac only (not my idea!!). I have a very 
> basic problem, 
> but one that doesn't appear on the FAQs. I simply want to import data 
> from a spreadsheet. I'm using exactly what works fine on 
> Windows, namely:
> 
> 1    save the file from Excel as tab-delimited, say called 
> "test.txt", 
> with the variable names in the first row.
> 2    Read in into R with
> test<-read.table("test.txt", header=T)
> 
> It does weird things, especially if any variables are characters. For 
> example, it has omitted the 5th observation for the 1st variable, and 
> then appended it to the first variable name. I've tried read.csv with 
> csv files, read.delim, etc. None seem to work. Am I being 
> really silly, 
> and if so, how do you do it? Or is there an easier way to get 
> data into 
> the mac port? Or is the mac port entirely useless?
> 
> Can anyone out there help?
> 
> Thanks
> 
> Hamish McCallum
> 
> -- 
> Dr Hamish McCallum
> Department of Zoology and Entomology
> The University of Queensland
> Brisbane 4072
> Australia
> Phone (+617) 3365 2450 Fax (+617) 3365 1655
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From jasont at indigoindustrial.co.nz  Wed Jan 22 07:35:04 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed Jan 22 07:35:04 2003
Subject: [R] lists to arrays
In-Reply-To: <Pine.OSF.4.21.0301211720090.22076-100000@selway.umt.edu>; from csillery@selway.umt.edu on Tue, Jan 21, 2003 at 05:33:57PM -0700
References: <Pine.OSF.4.21.0301211720090.22076-100000@selway.umt.edu>
Message-ID: <20030122193142.A24198@camille.indigoindustrial.co.nz>

On Tue, Jan 21, 2003 at 05:33:57PM -0700, Katalin Csillery wrote:
> Does anyone know how to coerce a list to an array? I have a list with
> equal sized matrixes and I want to coerce it to a 3D array.

lists are special.  you'll have to unlist() first.  As an example:

zz <- list(a=matrix(1:9,ncol=3),b=matrix(10:18,ncol=3))
aa <- array(unlist(zz),dim=c(3,3,2))

However, useful as arrays are, finding a way to do the same job with
arrays can be very helpful - they're quite flexible.

Cheers

Jason


-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From ozric at web.de  Wed Jan 22 08:08:03 2003
From: ozric at web.de (Christian Schulz)
Date: Wed Jan 22 08:08:03 2003
Subject: [R] Too many e-mails
References: <NGBBKJEMOMLJFCOIEGCECEPCCDAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <004101c2c1e4$63dff0c0$983b07d5@c5c9i0>

..normally people send the answer twice.
One to you (who asked) and one to the mailing list.
An alternaltive is a filter with [R] in the  e-mail subject !

christian


----- Original Message ----- 
From: "Jonathan Williams" <jonathan.williams at pharmacology.oxford.ac.uk>
To: <R-help at stat.math.ethz.ch>
Sent: Monday, January 20, 2003 3:50 PM
Subject: [R] Too many e-mails


> Oh dear - I joined the R help mailing list last week,
> in order to ask a specific question. I did not realise
> that I would start to receive all e-mails to and from
> the mailing list. Is there a way of letting me receive
> only the answers to my own questions? If not, then can
> you remove me from the mailing list?
> 
> Thanks,
> 
> Jonathan Williams
> 
> Jonathan Williams
> OPTIMA
> Radcliffe Infirmary
> Woodstock Road
> OXFORD OX2 6HE
> Tel +1865 (2)24356
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Wed Jan 22 08:49:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 22 08:49:03 2003
Subject: [R] Read.table for macs
In-Reply-To: <000001c2c1df$7ce9cc80$7341a8c0@alpha.wehi.edu.au>
Message-ID: <Pine.LNX.4.44.0301220746490.27744-100000@gannet.stats>

This is a known problem in R 1.6.2, the Darwin port reading MacOS 
CR-delimited files.
Just use the patched version, R-patched, or R 1.6.1.

On Wed, 22 Jan 2003, Henrik Bengtsson wrote:

> It should be the same, but then I know nothing about R or Excel for Mac.
> Obvious things to check is if it is Excel or R that is the problem, i.e.
> have you tested to save your Excel data on a Mac and then tried to
> import it into R on a Windows machine and vice versa?
> 
> When Europe wakes up they might be able to help you out if you tell them
> what version you are running. What does R.Version() say? 
> 
> Henrik Bengtsson
> 
> > -----Original Message-----
> > From: r-help-admin at stat.math.ethz.ch 
> > [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Hamish McCallum
> > Sent: den 22 januari 2003 16:10
> > To: R-help at lists.R-project.org
> > Subject: [R] Read.table for macs
> > 
> > 
> > Dear All,
> > 
> > I've been using R for windows for a while, without too many problems. 
> > However, I'm forced to use the MAC OS system for teaching, 
> > because our 
> > teaching labs are mac only (not my idea!!). I have a very 
> > basic problem, 
> > but one that doesn't appear on the FAQs. I simply want to import data 
> > from a spreadsheet. I'm using exactly what works fine on 
> > Windows, namely:
> > 
> > 1    save the file from Excel as tab-delimited, say called 
> > "test.txt", 
> > with the variable names in the first row.
> > 2    Read in into R with
> > test<-read.table("test.txt", header=T)
> > 
> > It does weird things, especially if any variables are characters. For 
> > example, it has omitted the 5th observation for the 1st variable, and 
> > then appended it to the first variable name. I've tried read.csv with 
> > csv files, read.delim, etc. None seem to work. Am I being 
> > really silly, 
> > and if so, how do you do it? Or is there an easier way to get 
> > data into 
> > the mac port? Or is the mac port entirely useless?
> > 
> > Can anyone out there help?
> > 
> > Thanks
> > 
> > Hamish McCallum
> > 
> > -- 
> > Dr Hamish McCallum
> > Department of Zoology and Entomology
> > The University of Queensland
> > Brisbane 4072
> > Australia
> > Phone (+617) 3365 2450 Fax (+617) 3365 1655
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Jerome.Goudet at ie-zea.unil.ch  Wed Jan 22 09:17:02 2003
From: Jerome.Goudet at ie-zea.unil.ch (Jerome Goudet)
Date: Wed Jan 22 09:17:02 2003
Subject: [R] small bug in binom.test?
Message-ID: <5.1.0.14.2.20030122090744.01b81630@pop-server.unil.ch>

Hi all,

I am wondering whether there is a small bug in the binom.test function of 
the ctest library (I'm using R 1.6.0 on windows 2000, but Splus 2000 seems 
to have the same behaviour). Or perhaps I've misunderstood something.

the command binom.test(11,100,p=0.1) and binom.test(9,100,p=0.1) give 
different p-values (see below).  As 9 and 11 are equidistant from 10, the 
mean of the distribution, I would have thought that the probabilities 
should be the same. For instance, binom.test(49,50,0.5) and 
binom.test(51,100,0.5) do give the same results. Any help wouldbe 
appreciated. Jerome



 > binom.test(11,100,0.1)

         Exact binomial test

data:  11 and 100
number of successes = 11, number of trials = 100, p-value = 0.7377
alternative hypothesis: true probability of success is not equal to 0.1
95 percent confidence interval:
  0.05620702 0.18830113
sample estimates:
probability of success
                   0.11

 > binom.test(9,100,0.1)

         Exact binomial test

data:  9 and 100
number of successes = 9, number of trials = 100, p-value = 0.8681
alternative hypothesis: true probability of success is not equal to 0.1
95 percent confidence interval:
  0.04198360 0.16398226
sample estimates:
probability of success
                   0.09


Jerome GOUDET
Institut d'Ecologie, Bat. Biologie
Uni. Lausanne , CH-1015 Lausanne
Switzerland
Tel: +41 21 692 42 42    Fax: +41 21 692 42 65
Secr:+41 21 692 42 60



From ripley at stats.ox.ac.uk  Wed Jan 22 09:46:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 22 09:46:02 2003
Subject: [R] small bug in binom.test?
In-Reply-To: <5.1.0.14.2.20030122090744.01b81630@pop-server.unil.ch>
Message-ID: <Pine.LNX.4.44.0301220828570.27796-100000@gannet.stats>

Why do you think that?

The problems binom.test(49,50,0.5) and binom.test(51,100,0.5) are
symmetrical, so one would expect the same results for a two-sided test.

The problem I guess is how a two-sided test is defined for a discrete 
distribution.  For one-sided tests one would use the probability of X >=11 
or X <= 9, and those are not equal.  For a two-sided test the code 
attempts to find a point in the opposite tail with at least as large a 
tail probability, and adds on that tail probability.  Thus for
binom.test(11,100,p=0.1) it used P(X < 9 || X >= 11), and for
binom.test(9,100,p=0.1) it used P(X <= 9 || X > 10), if I followed the 
code right.

The great thing about R is that you can do

debug(binom.test)

and follow the calculations.


On Wed, 22 Jan 2003, Jerome Goudet wrote:

> Hi all,
> 
> I am wondering whether there is a small bug in the binom.test function of 
> the ctest library (I'm using R 1.6.0 on windows 2000, but Splus 2000 seems 
> to have the same behaviour). Or perhaps I've misunderstood something.
> 
> the command binom.test(11,100,p=0.1) and binom.test(9,100,p=0.1) give 
> different p-values (see below).  As 9 and 11 are equidistant from 10, the 
> mean of the distribution, I would have thought that the probabilities 
> should be the same. For instance, binom.test(49,50,0.5) and 
> binom.test(51,100,0.5) do give the same results. Any help wouldbe 
> appreciated. Jerome
> 
> 
> 
>  > binom.test(11,100,0.1)
> 
>          Exact binomial test
> 
> data:  11 and 100
> number of successes = 11, number of trials = 100, p-value = 0.7377
> alternative hypothesis: true probability of success is not equal to 0.1
> 95 percent confidence interval:
>   0.05620702 0.18830113
> sample estimates:
> probability of success
>                    0.11
> 
>  > binom.test(9,100,0.1)
> 
>          Exact binomial test
> 
> data:  9 and 100
> number of successes = 9, number of trials = 100, p-value = 0.8681
> alternative hypothesis: true probability of success is not equal to 0.1
> 95 percent confidence interval:
>   0.04198360 0.16398226
> sample estimates:
> probability of success
>                    0.09
> 
> 
> Jerome GOUDET
> Institut d'Ecologie, Bat. Biologie
> Uni. Lausanne , CH-1015 Lausanne
> Switzerland
> Tel: +41 21 692 42 42    Fax: +41 21 692 42 65
> Secr:+41 21 692 42 60
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tord.snall at ebc.uu.se  Wed Jan 22 10:03:03 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Wed Jan 22 10:03:03 2003
Subject: [R] Error when using polr() in MASS
Message-ID: <3.0.6.32.20030122095614.00a8f8c0@mail.anst.uu.se>

Dear all,

I get an error message when I use polr() in MASS. These are my data:

   skugg grupp frekv
4      1   gr3     0
5      2   gr3     3
6      3   gr3     6
10     1   gr5     1
11     2   gr5    12
12     3   gr5     1
> 
> summary(polr(skugg ~ grupp, weights=frekv, data= skugg.cpy1.dat))
Error in optim(start, fmin, gmin, method = "BFGS", hessian = Hess, ...) : 
        non-finite value supplied by optim

Does this depend on the very few observations in skugg 1 - the
proportional-odds assumption doesn't hold (p 231, MASS 3ed)? If so, I would
be happy for a recommendation on another approach.

And I also have a similar data set where only the skugg classes 2 and 3 are
observed. Would you recommend glm, family= binomial for that analysis?

I use R 1.6.2, MASS 7.0-10, Win 2000. 


Thanks in advance!

Please reply also to me because I'm on the once a day-list


Sincerely,
Tord

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From Jerome.Goudet at ie-zea.unil.ch  Wed Jan 22 10:09:06 2003
From: Jerome.Goudet at ie-zea.unil.ch (Jerome Goudet)
Date: Wed Jan 22 10:09:06 2003
Subject: [R] small bug in binom.test?
In-Reply-To: <Pine.LNX.4.44.0301220828570.27796-100000@gannet.stats>
References: <5.1.0.14.2.20030122090744.01b81630@pop-server.unil.ch>
Message-ID: <5.1.0.14.2.20030122100238.01b19e38@pop-server.unil.ch>

At 22.01.2003  08:45 +0000, you wrote:
>Why do you think that?
>
>The problems binom.test(49,50,0.5) and binom.test(51,100,0.5) are
>symmetrical, so one would expect the same results for a two-sided test.
>
>The problem I guess is how a two-sided test is defined for a discrete
>distribution.  For one-sided tests one would use the probability of X >=11
>or X <= 9, and those are not equal.  For a two-sided test the code
>attempts to find a point in the opposite tail with at least as large a
>tail probability, and adds on that tail probability.  Thus for
>binom.test(11,100,p=0.1) it used P(X < 9 || X >= 11), and for
>binom.test(9,100,p=0.1) it used P(X <= 9 || X > 10), if I followed the
>code right.

I would have defined the two sided test as P(X<=9 || X>=11) (checking of 
course that if the two values are equal, the probability is not counted 
twice). Is this wrong? I've got the following code carrying out such a test:


binomial.test<-function(obs,size,p=0.5,alpha=0.05,alternative="two.sided",plotit=T){
#calcule la probabilit? d'obtenir obs succ?s parmi size tirage sous 
l'hypoth?se que la probabilit? de succ?s est p (H0 prob=p)
#On peut sp?cifier si on souhaite un test bilat?ral 
(alternative="two.sided")(H1 prob<>p)
#ou unilat?ral (alternative="greater" pour H1 prob>p ou alternative="less" 
pour H1 prob<p)
#l'intervalle de confiance ? (1-alpha)% n'est donn? que si 
alternative="two.sided"
#exemple: binomial.test(23,257,prob=0.1) #voir poly p 11.2;
         p.hat=obs/size
         cent=floor(p*size) #l'esp?rance de la distribution
         ties=dbinom(cent,size,p)==dbinom(cent+1,size,p) #si 2 valeurs 
partagent la + haute probabilit?
         xl=ifelse(obs<cent,obs,ifelse(ties,cent-(obs-(cent+1)),cent-(obs-cent)))
         xh=ifelse(obs<cent,ifelse(ties,(cent+1)+(cent-obs),cent+(cent-obs)),obs)
         if (plotit){
                 plot(0:size,dbinom(0:size,size,p),type="h")#type="h" 
signifie des barres verticales depuis l'axe des x
                      if (alternative=="greater")
                         points(obs:size,dbinom(obs:size,size,p),type="h",col="red",lwd=3)#col 
pr?cise la couleur et lwd la largeur des traits
                      if (alternative=="less")
                         points(0:obs,dbinom(0:obs,size,p),type="h",col="red",lwd=3)
                      if (alternative=="two.sided")
                         points(c(0:xl,xh:size),dbinom(c(0:xl,xh:size),size,p),type="h",col="red",lwd=3)
         }
         if (alternative=="greater")
            return(list(p.hat=p.hat,pval=pbinom(obs-1,size,p,lower.tail=F)))
         if (alternative=="less")
            return(list(p.hat=p.hat,pval=pbinom(obs,size,p)))
         if (alternative=="two.sided"){
                 pval=ifelse(xl!=xh,
                             pbinom(xl,size,p)+pbinom(xh-1,size,p,lower.tail=F),
                             pbinom(xl,size,p)+pbinom(xh,size,p,lower.tail=F))
                 ic.li=qbinom(alpha/2,size,p.hat)/size
                 ic.ls=qbinom(1-alpha/2,size,p.hat)/size
                 return(list(p.hat=p.hat,pval=pval,ic.li=ic.li,ic.ls=ic.ls))
         }
}

>The great thing about R is that you can do
>
>debug(binom.test)
>
>and follow the calculations.
>
>
>On Wed, 22 Jan 2003, Jerome Goudet wrote:
>
> > Hi all,
> >
> > I am wondering whether there is a small bug in the binom.test function of
> > the ctest library (I'm using R 1.6.0 on windows 2000, but Splus 2000 seems
> > to have the same behaviour). Or perhaps I've misunderstood something.
> >
> > the command binom.test(11,100,p=0.1) and binom.test(9,100,p=0.1) give
> > different p-values (see below).  As 9 and 11 are equidistant from 10, the
> > mean of the distribution, I would have thought that the probabilities
> > should be the same. For instance, binom.test(49,50,0.5) and
> > binom.test(51,100,0.5) do give the same results. Any help wouldbe
> > appreciated. Jerome
> >
> >
> >
> >  > binom.test(11,100,0.1)
> >
> >          Exact binomial test
> >
> > data:  11 and 100
> > number of successes = 11, number of trials = 100, p-value = 0.7377
> > alternative hypothesis: true probability of success is not equal to 0.1
> > 95 percent confidence interval:
> >   0.05620702 0.18830113
> > sample estimates:
> > probability of success
> >                    0.11
> >
> >  > binom.test(9,100,0.1)
> >
> >          Exact binomial test
> >
> > data:  9 and 100
> > number of successes = 9, number of trials = 100, p-value = 0.8681
> > alternative hypothesis: true probability of success is not equal to 0.1
> > 95 percent confidence interval:
> >   0.04198360 0.16398226
> > sample estimates:
> > probability of success
> >                    0.09
> >
> >
> > Jerome GOUDET
> > Institut d'Ecologie, Bat. Biologie
> > Uni. Lausanne , CH-1015 Lausanne
> > Switzerland
> > Tel: +41 21 692 42 42    Fax: +41 21 692 42 65
> > Secr:+41 21 692 42 60
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Jan 22 10:25:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 22 10:25:04 2003
Subject: [R] small bug in binom.test?
In-Reply-To: <5.1.0.14.2.20030122100238.01b19e38@pop-server.unil.ch>
Message-ID: <Pine.LNX.4.44.0301220910040.27896-100000@gannet.stats>

On Wed, 22 Jan 2003, Jerome Goudet wrote:

> At 22.01.2003  08:45 +0000, you wrote:
> >Why do you think that?
> >
> >The problems binom.test(49,50,0.5) and binom.test(51,100,0.5) are
> >symmetrical, so one would expect the same results for a two-sided test.
> >
> >The problem I guess is how a two-sided test is defined for a discrete
> >distribution.  For one-sided tests one would use the probability of X >=11
> >or X <= 9, and those are not equal.  For a two-sided test the code
> >attempts to find a point in the opposite tail with at least as large a
> >tail probability, and adds on that tail probability.  Thus for
> >binom.test(11,100,p=0.1) it used P(X < 9 || X >= 11), and for
> >binom.test(9,100,p=0.1) it used P(X <= 9 || X > 10), if I followed the
> >code right.

(I typed it wrong.  The first omits (9,10), the second (10,11).)

> I would have defined the two sided test as P(X<=9 || X>=11) (checking of 
> course that if the two values are equal, the probability is not counted 
> twice). Is this wrong?

Yes.  Let me repeat: `why do you think that?'.   (R implements standard 
statistical definitions, not Goudet's ones, so I expected you to give me a 
reference.)  Did you look up the references on the help page?

For continuous distributions, two-tailed tests are defined as equi-tailed,
and so your recipe is nothing like what happens for e.g. a gamma
distribution.  For discrete distributions there are complications but
there is a standard definition of an alpha-level test, which can be
converted to a p value via searching for possible alpha-level tests.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rsadler at agric.uwa.edu.au  Wed Jan 22 10:57:03 2003
From: rsadler at agric.uwa.edu.au (rohan sadler)
Date: Wed Jan 22 10:57:03 2003
Subject: [R] re:  box counting method and other landscape ecology measures
Message-ID: <3E2E6C4D.1050202@agric.uwa.edu.au>

Hi all,

I wish to implement various landscape ecology measures through R, such 
as: box counting dimension; twist number statistics; contagion and 
lacuniarity indices; angular second moment; adjacency measures; 
dominance indices; etc ...

Some of the measures can be applied to shape analysis and classification.

Is anyone implementing any of these measures? If so I would like to 
contribute and thereby avoid starting from scratch.

Regards

Rohan Sadler

-- 
Ecosystems Research Group (ERGO)
School of Plant Biology (Botany), Faculty of Natural & Agricultural Sciences,
The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009, Australia

Ph:  +61 8 9380 7914
Fax: +61 8 9380 7925
email: rsadler at agric.uwa.edu.au
ERGO's web site:<http://www.botany.uwa.edu.au/ergo>



From vito.muggeo at giustizia.it  Wed Jan 22 11:01:25 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Wed Jan 22 11:01:25 2003
Subject: (v2) [R] quadratic trends and changes in slopes (R-help digest, Vol 1 #52 - 16 msgs)
References: <20030120110017.4630.98520.Mailman@hypatia.math.ethz.ch> <3E2D8C0E.30718.503E7B@localhost>
Message-ID: <003201c2c1fb$f3077720$5c13070a@it.giustizia.it>

It is well-known that change-point estimation is a non-trivial task.

You could find interesting the followings

Pastor and Guallar 1998. "use of two-segmented logistic regression to
estimate changepoint in epidemiological studies" Am J Epid, 148, 631-642

Goetghebeur and Pocock 1995 "detection and estimation og J-shaped
risk-response relationships" JRSSA,158,107-121

where a quadratic polynomial before or after the change has been used in
order to allow the score function to be continuous at the changepoint.
However the aforementioned papers do not seem to solve the problem in
practice: Goetghebeur and Pocock 1995 use a grid-search-type method to
estimate the break-point and Pastor and Guallar 1998 use a non standard
algorithm to maximize the log-lik.

If you are dealing with time-serie regression models and the changepoint is
a time-point (i.e. on the time-axis) you could see the strucchange package
by Achim Zeleis (see also his paper on R-news 2002, I don't remeber the
issue).

best,
vito


----- Original Message -----
From: "kjetil brinchmann halvorsen" <kjetil at entelnet.bo>
To: <r-help at stat.math.ethz.ch>; "Chuck White" <chuck at chuckandmaggi.com>
Cc: "'Martin Michlmayr'" <tbm at cyrius.com>
Sent: Tuesday, January 21, 2003 11:06 PM
Subject: RE: (v2) [R] quadratic trends and changes in slopes (R-help digest,
Vol 1 #52 - 16 msgs)


> On 20 Jan 2003 at 21:49, Chuck White wrote:
>
> >
> > I'd like to use linear and quadratic trend analysis in order to find
> > out a change in slope.  Basically, I need to solve a similar problem as
> > discussed in
> > http://www.gseis.ucla.edu/courses/ed230bc1/cnotes4/trend1.html
> >
>
> This response show how to do the test of non-linearity in a
> complicated way, all can be done much easier in R, start to
> look at poly() and contr.poly() (and summary.aov with the argument
> split=). But that is not the point. The original poster did'nt want
> to test for nonlinearity, he assumed there is nonlinearity and wanted
> to estimate the change point. He also said that the usual procedure
> to do that in his field is to estimate cuadratic models for data
> 1, 1:2, 1:3, ..., 1:9 (or some similar number) and take the change-
> point as the value of i above (in 1:i) where the quadratic term
> first is significant. That cannot be sound, as you obviously must go
>  somewhat past the changepoint before the quadratic term can become
> significant! So this method cannot possibly give an consistent
> estimator of the change-point. He should use some other method, like
> building a model with an explicit change-point and estimate that.
>
> Kjetil Halvorsen
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From AlessandroSemeria at cramont.it  Wed Jan 22 11:18:02 2003
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Wed Jan 22 11:18:02 2003
Subject: [R] self-split plot on multiple device
Message-ID: <OF9D3DB61F.FDDBF69A-ONC1256CB6.0036C782@tomware.it>

Hello!
I would plot more than 10 (this number is always different)
 graphics on a figure with layout like 'mfrow=c(4,2)'.
There is some existing function able to open the right number of
device if number of graphics is done or I have to build it myself
with some 'IF.....ELSE.....'?

Thanks.
A.S.
----------------------------

|------------------------------------+------------------------------------|
|Alessandro Semeria                  |Tel. +39 544 536811                 |
|------------------------------------+------------------------------------|
|Models and Simulation Laboratory    |Fax. +39 544 538663                 |
|------------------------------------+------------------------------------|
|The Environment Research Center -   |                                    |
|Montecatini (Edison Group),    Via  |                                    |
|Ciro Menotti 48,                    |E-mail: asemeria at cramont.it         |
|48023 Marina di Ravenna (RA), Italy |                                    |
|------------------------------------+------------------------------------|



From maechler at stat.math.ethz.ch  Wed Jan 22 11:43:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Jan 22 11:43:02 2003
Subject: [R] self-split plot on multiple device
In-Reply-To: <OF9D3DB61F.FDDBF69A-ONC1256CB6.0036C782@tomware.it>
References: <OF9D3DB61F.FDDBF69A-ONC1256CB6.0036C782@tomware.it>
Message-ID: <15918.30103.995733.494035@gargle.gargle.HOWL>

>>>>> "AlesSem" == AlessandroSemeria  <AlessandroSemeria at cramont.it>
>>>>>     on Wed, 22 Jan 2003 11:22:35 +0100 writes:

    AlesSem> Hello!  I would plot more than 10 (this number is
    AlesSem> always different) graphics on a figure with layout
    AlesSem> like 'mfrow=c(4,2)'.  There is some existing
    AlesSem> function able to open the right number of device if
    AlesSem> number of graphics is done or I have to build it
    AlesSem> myself with some 'IF.....ELSE.....'?

If you must use the (4,2) layout, you have to do it yourself,
starting a new device {x11() works on Windows and Unix) every 8th plot.
I'm not sure I'd want that for interactive usage.
If you use a non-interactive graphics device such as
postscript()  or pdf() or ...,
a new page is started automatically anyway when the layout is full.

The other approach is to determine the layout automatically from
the number of plots, and there's n2mfrow() since R 1.2.0.
?n2mfrow  starts as

>> Compute Default mfrow From Number of Plots
>> 
>> Description:
>> 
>>      Easy Setup for plotting multiple figures (in a rectangular layout)
>>      on one page.  It allows to specify a main title and uses smart
>>      defaults for several `par' calls.
>> 
>> Usage:
>>      n2mfrow(nr.plots)
>> 
>> Arguments:
>>	nr.plots: integer; the number of plot figures you'll want to draw.

I also attach a utility function  mult.fig() using n2mfrow()
that I've also been using for years.
The main extra thing is the easy way using (... main = ..)
for an overall title.

 [ Yes, this is in a package; no, the package is not yet on CRAN
   since it contains too many other undocumented and partly
   outdated functions ..]

mult.fig <-
function(nr.plots, mfrow, mfcol,
         marP = rep(0, 4), mgp = c(1.5, 0.6, 0),
         mar = marP + 0.1 + c(4,4,2,1), oma = c(0,0, tit.wid, 0),
         main = NULL, tit.wid = if (is.null(main)) 0 else 1 + 1.5*cex.main,
         quiet = .Device == "postscript",
         cex.main = par("cex.main"), line.main = cex.main - 1/2,
         col.main = par("col.main"),
         font.main = par("font.main"),
         ...)
{
  ## Purpose: 'MULTiple FIGures' incl. title and other good defaults
  ## -------------------------------------------------------------------------
  ## Arguments: -- Either ONE of the first 3 arguments --
  ###  =========> help(mult.fig)
  ## -------------------------------------------------------------------------
  ## Author: Martin Maechler, 1990 (UW, Seattle) -- 1995
  ## -------------------------------------------------------------------------

  use.row <- missing(mfcol)
  if (use.row)
    if (missing(mfrow)) {
      if (missing(nr.plots))
        stop("must either specify 'nr.plots', 'mfrow' or 'mfcol' !")
      else  mfrow <- n2mfrow (nr.plots)
    }
  old.par <<-
    if(use.row) par(mfrow = mfrow, oma= oma, mar = mar, mgp= mgp)
    else        par(mfcol = mfcol, oma= oma, mar = mar, mgp= mgp)
  if(!quiet) cat("Execute\n\t par(old.par) \n later to restore graphical par\n")
  ##---- now go ahead :
  if(!is.R())
      frame()
  if (!is.null(main)) {# Do title *before* first plot!
      if(is.R()) plot.new()
      mtext(main, side = 3, outer = TRUE,
            line = line.main,
            cex = cex.main,
            font = font.main, col = col.main, ...)
      if(is.R()) par(new=TRUE)# reverse `plot.new()' above
  }
  invisible(list(new.par = par(c("mfrow","mfcol","oma","mar","mgp")),
                 old.par = old.par))
}



From dvumani at hotmail.com  Wed Jan 22 12:15:08 2003
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Wed Jan 22 12:15:08 2003
Subject: [R] something wrong when using pspline in clogit?
Message-ID: <F114pED894icWMpbpB800014792@hotmail.com>


Dear R users:

I am not entirely convinced that clogit gives me the correct result when I 
use pspline() and maybe you could help correct me here.

When I add a constant to my covariate I expect only the intercept to change, 
but not the coefficients. This is true (in clogit) when I assume a linear in 
the logit model, but the same does not happen when I use pspline().

If I did something similar to what "na.gam.replace" in S+ does, the pspline 
coefficients are the same, leading me to believe that "na.gam.replace" is 
doing the right thing (I may be wrong).
The strange thing here is that even the intercepts are the same. Lastly, 
these coefficients are the same as using clogit before adding the constant, 
but the intercept are different.

I have attached my code for all this, maybe I messed it somewhere.


Vumani

##########################
xvar<-rnorm(100,0,1)
data.mult<-rbinom(100,size=3,prob=(exp(0.5+0.4*xvar)/(1+exp(0.5+0.4*xvar))))
library(Nnet)
mult.fit<-multinom(data.mult~xvar)
coef(mult.fit)
library(survival)
choice<-c(ifelse(data.mult==0,1,0),ifelse(data.mult==1,1,0),ifelse(data.mult==2,1,0),ifelse(data.mult==3,1,0))
temp<-list(time=2-choice,
            status=choice,
            
intercept1=c(rep(0,length(data.mult)),rep(1,length(data.mult)),rep(0,length(data.mult)),rep(0,length(data.mult))),
            
intercept2=c(rep(0,length(data.mult)),rep(0,length(data.mult)),rep(1,length(data.mult)),rep(0,length(data.mult))),
            
intercept3=c(rep(0,length(data.mult)),rep(0,length(data.mult)),rep(0,length(data.mult)),rep(1,length(data.mult))),
            
xvar1=c(rep(0,length(data.mult)),rep(1,length(data.mult)),rep(0,length(data.mult)),rep(0,length(data.mult)))*rep(xvar,4),
            
xvar2=c(rep(0,length(data.mult)),rep(0,length(data.mult)),rep(1,length(data.mult)),rep(0,length(data.mult)))*rep(xvar,4),
            
xvar3=c(rep(0,length(data.mult)),rep(0,length(data.mult)),rep(0,length(data.mult)),rep(1,length(data.mult)))*rep(xvar,4),
            stratum=rep(1:length(data.mult),4))
# Used to check whether my data matrix is setup correctly
# This fits a category one baseline category logit model
# Compare with multinom
totalmodel<-clogit(status~intercept1+intercept2+intercept3+xvar1+xvar2+xvar3+strata(stratum),method="exact",temp)
coef(totalmodel)
# Use smooth term, "pspline"
totalmodel<-clogit(status~intercept1+intercept2+intercept3+pspline(xvar1)+pspline(xvar2)+pspline(xvar3)+strata(stratum),method="exact",temp)
coef(totalmodel)
# Collect indices where variable is not equal to zero
indices<-list(var1=NULL,var2=NULL,var3=NULL)
indices$var1<-temp$xvar1==0
indices$var2<-temp$xvar2==0
indices$var3<-temp$xvar3==0
# Add 10 to covariate
temp$xvar1[!indices$var1]<-xvar+10
temp$xvar2[!indices$var2]<-xvar+10
temp$xvar3[!indices$var3]<-xvar+10
# First fit linear-in-the-logit model, to check what happens to coefficients
totalmodel<-clogit(status~intercept1+intercept2+intercept3+xvar1+xvar2+xvar3+strata(stratum),method="exact",temp)
coef(totalmodel)
# Fit a smooth model, and compare with smooth model above
totalmodel<-clogit(status~intercept1+intercept2+intercept3+pspline(xvar1)+pspline(xvar2)+pspline(xvar3)+strata(stratum),method="exact",temp)
coef(totalmodel)
# Doing something similar to what na.gam.replace() in S+ does
temp$xvar1[indices$var1]<-mean(xvar+10)
temp$xvar2[indices$var2]<-mean(xvar+10)
temp$xvar3[indices$var3]<-mean(xvar+10)
# Fit spline model
totalmodel<-clogit(status~intercept1+intercept2+intercept3+pspline(xvar1)+pspline(xvar2)+pspline(xvar3)+strata(stratum),method="exact",temp)
coef(totalmodel)
# Remove 10 and substitute with mean
# Covariate are like in the beginning
temp$xvar1[!indices$var1]<-xvar
temp$xvar2[!indices$var2]<-xvar
temp$xvar3[!indices$var3]<-xvar
# Doing something like na.gam.replace()
temp$xvar1[indices$var1]<-mean(xvar)
temp$xvar2[indices$var2]<-mean(xvar)
temp$xvar3[indices$var3]<-mean(xvar)
totalmodel<-clogit(status~intercept1+intercept2+intercept3+pspline(xvar1)+pspline(xvar2)+pspline(xvar3)+strata(stratum),method="exact",temp)
coef(totalmodel)







>From: ripley at stats.ox.ac.uk
>To: Vumani Dlamini <dvumani at hotmail.com>
>CC: R-help at stat.math.ethz.ch
>Subject: Re: [R] R analogue
>Date: Mon, 20 Jan 2003 13:17:02 +0000 (GMT)
>
>On Mon, 20 Jan 2003, Vumani Dlamini wrote:
>
> > Is there any R analogue for the S+ function "na.gam.replace".
>
>No, for it is tailored for use by S's gam.
>
>Some of the things it does are positively undesirable!  It uses mean
>imputation for continuous variables, but for factors it makes NA into
>another level, which silently assumes that all missing values are similar
>and that they are going to occur with sufficient frequency in the
>training data (and they may not occur at all).
>
> > I would like
> > to make an interaction of a categorical and smooth continuous covariate.
>
>You can do that without na.gam.replace: there is an example in the MASS
>scripts for the low-birth-weight data.
>
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From simon at stats.gla.ac.uk  Wed Jan 22 13:02:03 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Wed Jan 22 13:02:03 2003
Subject: [R] something wrong when using pspline in clogit?
In-Reply-To: <F114pED894icWMpbpB800014792@hotmail.com>
Message-ID: <Pine.SOL.3.96.1030122112853.16488A-100000@moon.stats.gla.ac.uk>

I'm afraid I missed the start of this due to the rather general subject
line, but I think that you wanted an interaction of a smooth and a factor
variable, is that right? Also, I'm not sure whether my suggestion will be
any use given your survival analysis context, but anyway... 

If I understand your code (below) correctly then you are trying to produce
an interaction of a smooth with a factor by setting the argument of the
smooth to zero if the corresponding factor dummy variables are zero. I
don't think this is quite right since s(0) is not generally zero. If you
want to do this properly, then you can use the `by' variable mechanism
provided in package mgcv. The final example in the ?gam.models help file
produces an interaction of a smooth with a factor correctly. 

I think that package gss also allows interactions of smooths and factors,
but I don't actually know how I'm afraid.

Simon
_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk  www.ruwpa.st-and.ac.uk/simon.html
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814



On Wed, 22 Jan 2003, Vumani Dlamini wrote:

> 
> 
> Dear R users:
> 
> I am not entirely convinced that clogit gives me the correct result when I 
> use pspline() and maybe you could help correct me here.
> 
> When I add a constant to my covariate I expect only the intercept to change, 
> but not the coefficients. This is true (in clogit) when I assume a linear in 
> the logit model, but the same does not happen when I use pspline().
> 
> If I did something similar to what "na.gam.replace" in S+ does, the pspline 
> coefficients are the same, leading me to believe that "na.gam.replace" is 
> doing the right thing (I may be wrong).
> The strange thing here is that even the intercepts are the same. Lastly, 
> these coefficients are the same as using clogit before adding the constant, 
> but the intercept are different.
> 
> I have attached my code for all this, maybe I messed it somewhere.
> 
> 
> Vumani
> 
> ##########################
> xvar<-rnorm(100,0,1)
> data.mult<-rbinom(100,size=3,prob=(exp(0.5+0.4*xvar)/(1+exp(0.5+0.4*xvar))))
> library(Nnet)
> mult.fit<-multinom(data.mult~xvar)
> coef(mult.fit)
> library(survival)
> choice<-c(ifelse(data.mult==0,1,0),ifelse(data.mult==1,1,0),ifelse(data.mult==2,1,0),ifelse(data.mult==3,1,0))
> temp<-list(time=2-choice,
>             status=choice,
>             
> intercept1=c(rep(0,length(data.mult)),rep(1,length(data.mult)),rep(0,length(data.mult)),rep(0,length(data.mult))),
>             
> intercept2=c(rep(0,length(data.mult)),rep(0,length(data.mult)),rep(1,length(data.mult)),rep(0,length(data.mult))),
>             
> intercept3=c(rep(0,length(data.mult)),rep(0,length(data.mult)),rep(0,length(data.mult)),rep(1,length(data.mult))),
>             
> xvar1=c(rep(0,length(data.mult)),rep(1,length(data.mult)),rep(0,length(data.mult)),rep(0,length(data.mult)))*rep(xvar,4),
>             
> xvar2=c(rep(0,length(data.mult)),rep(0,length(data.mult)),rep(1,length(data.mult)),rep(0,length(data.mult)))*rep(xvar,4),
>             
> xvar3=c(rep(0,length(data.mult)),rep(0,length(data.mult)),rep(0,length(data.mult)),rep(1,length(data.mult)))*rep(xvar,4),
>             stratum=rep(1:length(data.mult),4))
> # Used to check whether my data matrix is setup correctly
> # This fits a category one baseline category logit model
> # Compare with multinom
> totalmodel<-clogit(status~intercept1+intercept2+intercept3+xvar1+xvar2+xvar3+strata(stratum),method="exact",temp)
> coef(totalmodel)
> # Use smooth term, "pspline"
> totalmodel<-clogit(status~intercept1+intercept2+intercept3+pspline(xvar1)+pspline(xvar2)+pspline(xvar3)+strata(stratum),method="exact",temp)
> coef(totalmodel)
> # Collect indices where variable is not equal to zero
> indices<-list(var1=NULL,var2=NULL,var3=NULL)
> indices$var1<-temp$xvar1==0
> indices$var2<-temp$xvar2==0
> indices$var3<-temp$xvar3==0
> # Add 10 to covariate
> temp$xvar1[!indices$var1]<-xvar+10
> temp$xvar2[!indices$var2]<-xvar+10
> temp$xvar3[!indices$var3]<-xvar+10
> # First fit linear-in-the-logit model, to check what happens to coefficients
> totalmodel<-clogit(status~intercept1+intercept2+intercept3+xvar1+xvar2+xvar3+strata(stratum),method="exact",temp)
> coef(totalmodel)
> # Fit a smooth model, and compare with smooth model above
> totalmodel<-clogit(status~intercept1+intercept2+intercept3+pspline(xvar1)+pspline(xvar2)+pspline(xvar3)+strata(stratum),method="exact",temp)
> coef(totalmodel)
> # Doing something similar to what na.gam.replace() in S+ does
> temp$xvar1[indices$var1]<-mean(xvar+10)
> temp$xvar2[indices$var2]<-mean(xvar+10)
> temp$xvar3[indices$var3]<-mean(xvar+10)
> # Fit spline model
> totalmodel<-clogit(status~intercept1+intercept2+intercept3+pspline(xvar1)+pspline(xvar2)+pspline(xvar3)+strata(stratum),method="exact",temp)
> coef(totalmodel)
> # Remove 10 and substitute with mean
> # Covariate are like in the beginning
> temp$xvar1[!indices$var1]<-xvar
> temp$xvar2[!indices$var2]<-xvar
> temp$xvar3[!indices$var3]<-xvar
> # Doing something like na.gam.replace()
> temp$xvar1[indices$var1]<-mean(xvar)
> temp$xvar2[indices$var2]<-mean(xvar)
> temp$xvar3[indices$var3]<-mean(xvar)
> totalmodel<-clogit(status~intercept1+intercept2+intercept3+pspline(xvar1)+pspline(xvar2)+pspline(xvar3)+strata(stratum),method="exact",temp)
> coef(totalmodel)
> 
> 
> 
> 
> 
> 
> 
> >From: ripley at stats.ox.ac.uk
> >To: Vumani Dlamini <dvumani at hotmail.com>
> >CC: R-help at stat.math.ethz.ch
> >Subject: Re: [R] R analogue
> >Date: Mon, 20 Jan 2003 13:17:02 +0000 (GMT)
> >
> >On Mon, 20 Jan 2003, Vumani Dlamini wrote:
> >
> > > Is there any R analogue for the S+ function "na.gam.replace".
> >
> >No, for it is tailored for use by S's gam.
> >
> >Some of the things it does are positively undesirable!  It uses mean
> >imputation for continuous variables, but for factors it makes NA into
> >another level, which silently assumes that all missing values are similar
> >and that they are going to occur with sufficient frequency in the
> >training data (and they may not occur at all).
> >
> > > I would like
> > > to make an interaction of a categorical and smooth continuous covariate.
> >
> >You can do that without na.gam.replace: there is an example in the MASS
> >scripts for the low-birth-weight data.
> >
> >
> >--
> >Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >University of Oxford,             Tel:  +44 1865 272861 (self)
> >1 South Parks Road,                     +44 1865 272866 (PA)
> >Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From gregory.benmenzer at gazdefrance.com  Wed Jan 22 13:54:05 2003
From: gregory.benmenzer at gazdefrance.com (gregory.benmenzer@gazdefrance.com)
Date: Wed Jan 22 13:54:05 2003
Subject: [R] date
Message-ID: <OF1EFDA4F5.557DAB9A-ON41256CB6.004651A8@notes.edfgdf.fr>

hello,

I work with the POSIXlt class and when i write ISOdatetime(1970,1,1,0,0,0),
R returns NA

> ISOdatetime(1970,1,1,0,0,0)
[1] NA

Could you mind me how can i create this date ?

Regards,

Gr?gory Benmenzer



From gregory.benmenzer at gazdefrance.com  Wed Jan 22 14:02:03 2003
From: gregory.benmenzer at gazdefrance.com (gregory.benmenzer@gazdefrance.com)
Date: Wed Jan 22 14:02:03 2003
Subject: [R] date
Message-ID: <OFCCD2D2EE.5EB1FDED-ON41256CB6.0046E2EC@notes.edfgdf.fr>

hello,

I work with the POSIXlt class and when i write ISOdatetime(1970,1,1,0,0,0),
R returns NA

> ISOdatetime(1970,1,1,0,0,0)
[1] NA

Could you mind me how can i create this date ?

Regards,

Gr?gory Benmenzer



From ripley at stats.ox.ac.uk  Wed Jan 22 14:08:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 22 14:08:02 2003
Subject: [R] date
In-Reply-To: <OF1EFDA4F5.557DAB9A-ON41256CB6.004651A8@notes.edfgdf.fr>
Message-ID: <Pine.LNX.4.44.0301221306300.1593-100000@gannet.stats>

With what version of R and on what machine?

It works under Windows and under RH7.2 Linux with R 1.6.2.

On Wed, 22 Jan 2003 gregory.benmenzer at gazdefrance.com wrote:

> hello,
> 
> I work with the POSIXlt class and when i write ISOdatetime(1970,1,1,0,0,0),
> R returns NA
> 
> > ISOdatetime(1970,1,1,0,0,0)
> [1] NA

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ivonefig at ipimar.pt  Wed Jan 22 14:12:05 2003
From: ivonefig at ipimar.pt (Ivone Figueiredo)
Date: Wed Jan 22 14:12:05 2003
Subject: [R] Maximum likelihood estimation of a mixture of two weibull distribution
Message-ID: <007201c2c217$de257bb0$c9040a0a@Ivone1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030122/39f329d3/attachment.pl

From kjetil at entelnet.bo  Wed Jan 22 14:38:02 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed Jan 22 14:38:02 2003
Subject: [R] Error when using polr() in MASS
In-Reply-To: <3.0.6.32.20030122095614.00a8f8c0@mail.anst.uu.se>
Message-ID: <3E2E65D7.6017.34D256@localhost>

On 22 Jan 2003 at 9:56, Tord Snall wrote:

You can also try the nordr() function in Jim Lindsay's package
gnlm.

Kjetil Halvorsen


> Dear all,
> 
> I get an error message when I use polr() in MASS. These are my data:
> 
>    skugg grupp frekv
> 4      1   gr3     0
> 5      2   gr3     3
> 6      3   gr3     6
> 10     1   gr5     1
> 11     2   gr5    12
> 12     3   gr5     1
> > 
> > summary(polr(skugg ~ grupp, weights=frekv, data= skugg.cpy1.dat))
> Error in optim(start, fmin, gmin, method = "BFGS", hessian = Hess, ...) : 
>         non-finite value supplied by optim
> 
> Does this depend on the very few observations in skugg 1 - the
> proportional-odds assumption doesn't hold (p 231, MASS 3ed)? If so, I would
> be happy for a recommendation on another approach.
> 
> And I also have a similar data set where only the skugg classes 2 and 3 are
> observed. Would you recommend glm, family= binomial for that analysis?
> 
> I use R 1.6.2, MASS 7.0-10, Win 2000. 
> 
> 
> Thanks in advance!
> 
> Please reply also to me because I'm on the once a day-list
> 
> 
> Sincerely,
> Tord
> 
> -----------------------------------------------------------------------
> Tord Sn?ll
> Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
> Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
> Villav?gen 14			
> SE-752 36 Uppsala, Sweden
> Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
> Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
> Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
> E-mail: Tord.Snall at ebc.uu.se
> Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.b.pynsent at bham.ac.uk  Wed Jan 22 16:08:02 2003
From: p.b.pynsent at bham.ac.uk (Paul Pynsent)
Date: Wed Jan 22 16:08:02 2003
Subject: [R] Read.table for macs
In-Reply-To: <3E2E27C1.9000501@zen.uq.edu.au>
Message-ID: <3508EBC0-2E1B-11D7-9564-003065F42152@bham.ac.uk>

I detect an anti Mac theme, I do not wish to attribute blame but 
suggest that Excel does funny things when it dumps tab separated text 
files, like adding unprintable characters and trailing spaces.
My approach is to use BBedit (which is free) to:
1) zap gremlins
2) globally substitute \ \t for \t (ie remove trailing spaces which R 
does not ignore).
3) convert DOS new lines to Mac new lines.
Equally you could use awk etc. on a Mac to do this.  In general it is 
not safe to do this cleaning operation on a DOS/Windows system as 
conversions may still take place on transmission to an Apple.

On Wednesday, January 22, 2003, at 05:10  am, Hamish McCallum wrote:

> Dear All,
>
> I've been using R for windows for a while, without too many problems. 
> However, I'm forced to use the MAC OS system for teaching, because our 
> teaching labs are mac only (not my idea!!). I have a very basic 
> problem, but one that doesn't appear on the FAQs. I simply want to 
> import data from a spreadsheet. I'm using exactly what works fine on 
> Windows, namely:
>
> 1    save the file from Excel as tab-delimited, say called "test.txt", 
> with the variable names in the first row.
> 2    Read in into R with
> test<-read.table("test.txt", header=T)
>
> It does weird things, especially if any variables are characters. For 
> example, it has omitted the 5th observation for the 1st variable, and 
> then appended it to the first variable name. I've tried read.csv with 
> csv files, read.delim, etc. None seem to work. Am I being really 
> silly, and if so, how do you do it? Or is there an easier way to get 
> data into the mac port? Or is the mac port entirely useless?
>
> Can anyone out there help?
>
> Thanks
>
> Hamish McCallum
>
> -- 
> Dr Hamish McCallum
> Department of Zoology and Entomology
> The University of Queensland
> Brisbane 4072
> Australia
> Phone (+617) 3365 2450 Fax (+617) 3365 1655
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
Dr. P. B. Pynsent,
Research and Teaching Centre,
Royal Orthopaedic Hospital,
Birmingham, B31 2AP, U.K.



From fnj at cin.ufpe.br  Wed Jan 22 16:30:03 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Wed Jan 22 16:30:03 2003
Subject: [R] Performance
Message-ID: <Pine.LNX.4.44.0301221156500.27338-100000@jurema.cin.ufpe.br>

Hello,
I'm applying an arithmetical function the color (R,G,B) of each
pixel of a figure and it's very slow. This is common?
Other thing, are there some library to make modification in figures, eg,
to alter size?
If not, somebody knows some software that makes this, or either, to
resize figures automatically, therefore I go to need to apply to a bank.

Tks,
Francisco.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco J?nior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From ivonefig at ipimar.pt  Wed Jan 22 16:34:05 2003
From: ivonefig at ipimar.pt (Ivone Figueiredo)
Date: Wed Jan 22 16:34:05 2003
Subject: [R] Maximum likelihood estimation of a mixture of two weibull distribution
Message-ID: <01e001c2c22b$36b1cf00$c9040a0a@Ivone1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030122/6843bb2f/attachment.pl

From e.corda at oncfs.gouv.fr  Wed Jan 22 16:37:55 2003
From: e.corda at oncfs.gouv.fr (E. Corda)
Date: Wed Jan 22 16:37:55 2003
Subject: [R] [R]: Trellis plot
Message-ID: <3.0.1.32.20030122162813.00709dd0@mail.sky.fr>

Hi all,

I would be grateful if anyone could help me with the following. I am using
nlme library and I am trying to do a trellis plot with an outer factor, but
I have an error message which I can't understand.

Here is the code :

> mydata <- groupedData(y ~ x | warren/rabbit, outer= ~ treatment,
data=mydata)
> plot(mydata)
# I obtain a plot with all rabbits displayed individually and no outer factor.
> plot(mydata, outer = ~ treatment)
Error in order(na.last, decreasing, ...) : 
        Argument lengths differ

I use R 1.5.1 with Windows 2000.

I hope I've given enough information. Thanks a lot for your time.

Eve CORDA 
Office national de la chasse et de la faune sauvage
5, rue de Saint Thibault
SAINT-BENOIST
78610 AUFFARGIS
BP 20 - 78612 LE PERRAY EN YVELINES Cedex
FRANCE
Tel : +33 (0)1.30.46.60.64
Fax : +33 (0)1.30.46.60.99
Email : e.corda at oncfs.gouv.fr



From pac at Uhb.Fr  Wed Jan 22 16:42:34 2003
From: pac at Uhb.Fr (Pierre-Andre Cornillon)
Date: Wed Jan 22 16:42:34 2003
Subject: [R] Re: R and gdb (still)
In-Reply-To: <6rn0lue58s.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0301221624050.23022-100000@sa2391.rec.uhb.fr>

Hello,

I (tried to) follow your advice and set as gdb-doc explain a breakpoint
on the C function which have also the same name foo and it doesn't work.
I tried to change the name of the file (in case of some mess between
file's name and function's name) but, as I expected, nothing change (that
was the last chance attempt).

I just give up and this R-debugger problem on sparc-linux will wait until
I change/upgrade the whole operating system (in the next millenium ?).

Thanks a lot for all your ideas

Pierre-Andre Cornillon

On 21 Jan 2003, Douglas Bates wrote:

> You are setting a breakpoint at an explicit line number
>
> (gdb) b foo.c:21
> Breakpoint 1 at 0x705c6004: file foo.c, line 21.
>
> A safer way of setting the breakpoint is on the function name that the
> R function "foo" calls through .C or .Call.  That way you are ensured
> that the breakpoint will be encountered.  Line numbering within the
> debugger can be peculiar and it may happen that the debugger never
> gets to a point that it recognizes as being on line 21.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From p.dalgaard at biostat.ku.dk  Wed Jan 22 16:47:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Jan 22 16:47:03 2003
Subject: [R] Maximum likelihood estimation of a mixture of two weibull distribution
In-Reply-To: <01e001c2c22b$36b1cf00$c9040a0a@Ivone1>
References: <01e001c2c22b$36b1cf00$c9040a0a@Ivone1>
Message-ID: <x2el75w5ke.fsf@biostat.ku.dk>

"Ivone Figueiredo" <ivonefig at ipimar.pt> writes:

> Hi,
> 
> I would like to estimate the parameters of a mixture of two Weibull
> distributions by the maximum likelihood method. Is it possible to do it with
> fitdist?

Yes (in principle at least). Just define your mixture density as
something like 

mixt <- function(x,p,sh1,sc1,sh2,sc2)
        p*dweibull(x,sh1,scale1)+
        (1-p)*dweibull(x,sh2,scale2)+

and apply fitdistr to that.
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From sadok at ensam.inra.fr  Wed Jan 22 18:25:03 2003
From: sadok at ensam.inra.fr (sadok walid)
Date: Wed Jan 22 18:25:03 2003
Subject: [R] [R]Intercept in model formulae
Message-ID: <3.0.1.32.20030122182145.006958f0@ensam.inra.fr>

Hi, 
I'm a new user of R and I'm trying to make a linear model from this kind of
dataset 
 x
 [1] 16.87 19.93 25.85 20.94 17.06 19.49 19.93 25.45 27.74 20.15 25.81
21.06 17.17 20.03 25.50 27.79 20.44 16.88 19.93 25.79

z<-x-10
 y
 [1] 0.80 1.27 2.22 1.32 0.90 1.18 1.84 2.41 2.97 1.25 2.07 1.41 1.14 1.66
2.59 3.51 1.53 0.81 1.26 2.30 

plot(x,y)

I want to be able to force the line of the model(mymodel<-lm(y~z)) to pass
through the origin (zero) and the line of the model(mymodel<-lm(y~x)) to
pass through 10 as an x-intercept.
For the first case i have used the (y~x-1) syntax, but the linear model
returned a regresssion that didn't pass trough the points (with a higher
Rsq than expected).
For the second case, i did not find a solution yet..

Could somone help me please?
Thanks in avance

Walid SADOK



From mmasliah at itransconsulting.com  Wed Jan 22 19:07:03 2003
From: mmasliah at itransconsulting.com (Maurice Masliah)
Date: Wed Jan 22 19:07:03 2003
Subject: [R] negative multinomial regression models
Message-ID: <37B88260B86ED3118E2200104BCC58CCA67990@fe0-0-0.core05.40nr.tor.int.futureway.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030122/aec22311/attachment.pl

From ripley at stats.ox.ac.uk  Wed Jan 22 19:23:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 22 19:23:02 2003
Subject: [R] negative multinomial regression models
In-Reply-To: <37B88260B86ED3118E2200104BCC58CCA67990@fe0-0-0.core05.40nr.tor.int.futureway.com>
Message-ID: <Pine.LNX.4.44.0301221818040.5054-100000@gannet.stats>

A multinomial regression model is not a glm.  As it name implies, glm.nb 
uses generalized linear models.  If it had been as simple as you suggest, 
I am sure the authors of glm.nb would already have done it.

One clue is that multinomial logistic regression models are not 
implemented (nor can they be) by extending glm.  The best idea is to 
follow what was done there, namely to define a log-likelihood and maximize 
it.  That's actually not a bad way to fit negative binomial glms, also.

On Wed, 22 Jan 2003, Maurice Masliah wrote:

> Hello,
> 
> I've spent a lot of time during the past month trying to get negative
> multinomial regression models for clustered event counts as described in
> (Guang Guo. 1996. "Negative Multinomial Regression Models For Clustered
> Event Counts." Sociological Methodology 26: 113-132., abstract at
> http://depts.washington.edu/socmeth2/4abst96.htm) implemented in R. A
> FORTRAN version of the method described in the Guo paper is available at
> http://www.stat.unipg.it/stat/statlib/general/negmul.
> 
> I've been approaching this problem by modifying the loglik glm.nb function
> as such:
> 
> ## original loglik function in glm.nb
> ##    loglik <- function(n, th, mu, y) {
> ##        sum(lgamma(th + y) - lgamma(th) - lgamma(y + 1) + th * 
> ##            log(th) + y * log(mu + (y == 0)) - (th + y) * log(th + 
> ##            mu))
> ##   }
> 
>       loglik <- function(n, th, mu, y, mu.grouped, y.grouped) {	
> 	sum( th*log(th))*length(y.grouped) + 
> 		sum(y*log(mu+ (y == 0)))+ 
> 		sum(lgamma(y.grouped+ th) -lgamma(th) -
> (y.grouped+th)*log(mu.grouped+ th))
>         }
> 
> where y.grouped and mu.grouped are the sums of the clusters, as in
> 
>     y.grouped <- tapply(Y,group,sum)	
>     mu.grouped <- tapply(mu,group,sum)
> 
> where group represents the level used to identify the clusters.
> 
> I've made some other small changes to glm.nb on the calls to theta.ml such
> that 
> 
> ##original call to theta.ml
> ##    th <- as.vector(theta.ml(Y, mu, n, limit = control$maxit, 
> ##        trace = control$trace > 2))
> 
>     th <- as.vector(theta.ml(y.grouped, mu.grouped, length(y.grouped), limit
> = control$maxit, 
>         trace = control$trace > 2))
> 
> 
> At first I thought all I needed was to make some small changes and modify
> the loglik function in glm.nb but implementation now appears to be more
> complex than just that.
> 
> I'm looking for any help/advice in what I should do in order to implement
> negative multinomial regression models in R. What more needs to be done
> after modifying the loglik function in glm.nb?
> 
> Of course, if it has already been done that would be nice too (though I
> don't think so).
> 
> I have not been able to use the web interface to log on to the mailing lists
> (I keep getting an error message) and can only review the archives, so it
> would be much appreciated if you would cc any response to my email address
> below.
> 
> Sincerely,
> 
> Maurice Masliah
> Senior Researcher
> iTRANS Consulting Inc.
> 100 York Boulevard
> Suite 300, Richmond Hill
> L4B 1J8, Ontario
> CANADA
> Tel:905-882-4100 ext.5295
> Fax:905-882-1557
> e-mail: mmasliah at itransconsulting.com
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Wed Jan 22 19:46:06 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Jan 22 19:46:06 2003
Subject: [R] [R]Intercept in model formulae
In-Reply-To: <3.0.1.32.20030122182145.006958f0@ensam.inra.fr>
Message-ID: <Pine.A41.4.44.0301221043120.159068-100000@homer07.u.washington.edu>

On Wed, 22 Jan 2003, sadok walid wrote:

>
> Hi,
> I'm a new user of R and I'm trying to make a linear model from this kind of
> dataset
>  x
>  [1] 16.87 19.93 25.85 20.94 17.06 19.49 19.93 25.45 27.74 20.15 25.81
> 21.06 17.17 20.03 25.50 27.79 20.44 16.88 19.93 25.79
>
> z<-x-10
>  y
>  [1] 0.80 1.27 2.22 1.32 0.90 1.18 1.84 2.41 2.97 1.25 2.07 1.41 1.14 1.66
> 2.59 3.51 1.53 0.81 1.26 2.30
>
> plot(x,y)
>
> I want to be able to force the line of the model(mymodel<-lm(y~z)) to pass
> through the origin (zero) and the line of the model(mymodel<-lm(y~x)) to
> pass through 10 as an x-intercept.
> For the first case i have used the (y~x-1) syntax, but the linear model
> returned a regresssion that didn't pass trough the points (with a higher
> Rsq than expected).

It works for me
  plot(z,y,xlim=range(c(0,z)),ylim=range(c(0,y)))
  abline(lm(y~z-1))

gives a line nicely through the points. The fact that the Rsq is higher
than expected may be a defect of the expectations. Rsq is often high
 for models with no intercept because the null model is that the mean of y
is zero.


> For the second case, i did not find a solution yet..

It's the same as the first case, and that's about the only way to do it.

  lm(y~I(x-10)-1)
though I think it looks neater written as
  lm(y~I(x-10)+0)


	-thomas



From ripley at stats.ox.ac.uk  Wed Jan 22 20:08:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 22 20:08:02 2003
Subject: [R] Using Internet proxies
Message-ID: <Pine.LNX.4.44.0301221849360.7211-100000@gannet.stats>

There have been quite a few questions recently about this, so I have 
tried to gather experience.  I set up a proxy using Apache2 (a very common 
server) behind our firewall and tried various authentication approaches.

One comment: all the methods return error messages when they fail.  Please 
don't report `it doesn't work' without the full details.

1) For a proxy that authenticates at most by hostname/IP address, and for
Windows users, just set up IE6 to work, and use the --internet2
command-line flag.  This worked for me (despite various claims here).

2) For a proxy that authenticates at most by hostname/IP address, the
internal download.file method works, provided you set the environment
variable http_proxy or HTTP_PROXY correctly, e.g. in ~/.Renviron.
This is almost of the same form as used by wget, but is less tolerant,
and note that setting `no_proxy' disables the proxy for all sites (unlike 
for wget).

3) If you have a proxy that demands that you enter a username/password 
combination, you can use the internal download method in R-devel: see
?download.file.

4) Installing wget and using the options(download.file.method="wget")
provides a highly tunable approach.  For Windows users, wget is still
available on http://www.stats.ox.ac.uk/pub/Rtools.

Note that none of these methods support proxies that want more advanced 
methods of authentication, e.g. Digest under HTTP/1.1.  If there are
any such proxies, please can a user provide us with a proven method.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From reid_huntsinger at merck.com  Wed Jan 22 22:56:04 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Wed Jan 22 22:56:04 2003
Subject: [R] Performance
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC2F1@uswpmx11.merck.com>

How are your figures (images?) represented in R? If you use an
efficiently vectorized function on an image represented as a
triple of matrices or a 3xnxm array, I wouldn't expect things
to be too slow. 

You can resize easily using R's indexing for arrays. E.g.,
centerOfImage <- wholeImage[,251:750,251:750] 
using a 3x1000x1000 array wholeImage.

Certain operations you'd like to do on images are best done as C code
called from R's .Call interface. For example, local median filters. 
Depending on the representation of images you're using, it might be
easy to use libraries like ImageMagick or vigra for example in this way. 

Reid Huntsinger

-----Original Message-----
From: Francisco do Nascimento Junior [mailto:fnj at cin.ufpe.br]
Sent: Wednesday, January 22, 2003 9:10 AM
To: R-help
Subject: [R] Performance


Hello,
I'm applying an arithmetical function the color (R,G,B) of each
pixel of a figure and it's very slow. This is common?
Other thing, are there some library to make modification in figures, eg,
to alter size?
If not, somebody knows some software that makes this, or either, to
resize figures automatically, therefore I go to need to apply to a bank.

Tks,
Francisco.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco J?nior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------



From dgrove at fhcrc.org  Wed Jan 22 23:06:16 2003
From: dgrove at fhcrc.org (Douglas Grove)
Date: Wed Jan 22 23:06:16 2003
Subject: [R] dataframe subsetting behaviour
Message-ID: <Pine.LNX.4.44.0301221334140.14529-100000@emu.fhcrc.org>

Hi,

I'm trying to understand a behaviour that I have encountered
and can't fathom.


Here's some code I will use to illustrate the behaviour:

# start with some data frame "a" having some named columns
a <- data.frame(a=rep(1,3),c=rep(2,3),d=rep(3,3),e=rep(4,3))

# create a subset of the original data frame, but include a
# name "b" that is not present in my original data frame
b <- a[,c("a","b","c")]


## Up until now no errors are issued, but the following commands
## will give the error shown:

b[1,]     ## "Error in x[[j]] : subscript out of bounds"
b[1,2]    ## "Error in "names<-.default"(*tmp*, value = cols) : 
          ##  names attribute must be the same length as the vector"


Can anyone explain to me the meaning of these error messages in terms
of R is actually doing?  These error messages had me baffled and 
it took me hours to track down that the source of the error was an 
incorrect column name in my data frame subsetting.

Thanks,
Doug Grove
Statistical Research Associate
Fred Hutchinson Cancer Research Center
Seattle, WA



From pocernic at rap.ucar.edu  Wed Jan 22 23:56:03 2003
From: pocernic at rap.ucar.edu (Matt Pocernich)
Date: Wed Jan 22 23:56:03 2003
Subject: [R] Convert numeric value to POSIXct
Message-ID: <Pine.LNX.4.44.0301221549070.12813-100000@markov.rap.ucar.edu>

Hi,

How do I convert a numeric value indicating the time since 1970, back into
a POSIXct class object?  I have tried format.POSIXct and as.POSIXct
without success.

For example
> ccc
[1] "1945-01-01 15:00:00 MDT"
> ddd<- as.numeric(ccc);
> ddd
[1] -788842800
> format.POSIXct(ddd)
Error in format.POSIXct(ddd) : wrong class
> as.POSIXct(ddd)
Error in as.POSIXct.default(ddd) : Don't know how to convert `ddd' to
class "POSIXct"
>

Thanks,

Matt

Matt Pocernich
NCAR - Research Applications Program
303-497-8312



From p.dalgaard at biostat.ku.dk  Thu Jan 23 00:15:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Jan 23 00:15:04 2003
Subject: [R] dataframe subsetting behaviour
In-Reply-To: <Pine.LNX.4.44.0301221334140.14529-100000@emu.fhcrc.org>
References: <Pine.LNX.4.44.0301221334140.14529-100000@emu.fhcrc.org>
Message-ID: <x2wukwn5ds.fsf@biostat.ku.dk>

Douglas Grove <dgrove at fhcrc.org> writes:

> Hi,
> 
> I'm trying to understand a behaviour that I have encountered
> and can't fathom.
> 
> 
> Here's some code I will use to illustrate the behaviour:
> 
> # start with some data frame "a" having some named columns
> a <- data.frame(a=rep(1,3),c=rep(2,3),d=rep(3,3),e=rep(4,3))
> 
> # create a subset of the original data frame, but include a
> # name "b" that is not present in my original data frame
> b <- a[,c("a","b","c")]
> 
> 
> ## Up until now no errors are issued, but the following commands
> ## will give the error shown:
> 
> b[1,]     ## "Error in x[[j]] : subscript out of bounds"
> b[1,2]    ## "Error in "names<-.default"(*tmp*, value = cols) : 
>           ##  names attribute must be the same length as the vector"
> 
> 
> Can anyone explain to me the meaning of these error messages in terms
> of R is actually doing?  These error messages had me baffled and 
> it took me hours to track down that the source of the error was an 
> incorrect column name in my data frame subsetting.

Looks like a (semi-)bug. Indexing outside of the data frame creates a
"column" which is really the single value NULL, e.g. 

> dput(a[,4:5])
structure(list(e = c(4, 4, 4), "NA" = NULL), .Names = c("e",
NA), row.names = c("1", "2", "3"), class = "data.frame")

This will print because the format.data.frame called inside
print.data.frame will recycle the NULL and give you

> a[,4:5]
  e   NA
1 4 NULL
2 4 NULL
3 4 NULL

However, it confuses the h*ck out of "[.data.frame"

> (a[,4:5])[2]
Error in "[.data.frame"((a[, 4:5]), 2) : undefined columns selected
> (a[,4:5])[,2]
NULL
> (a[,4:5])[,1]
[1] 4 4 4

and also the examples you found. However, the main issue is that you
have managed to construct a corrupt data frame. So indexing outside
the array should probably either give an error or return a column of
NA.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Thu Jan 23 00:23:06 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan 23 00:23:06 2003
Subject: [R] Convert numeric value to POSIXct
In-Reply-To: <Pine.LNX.4.44.0301221549070.12813-100000@markov.rap.ucar.edu>
Message-ID: <Pine.LNX.4.44.0301222320200.12915-100000@gannet.stats>

You can't safely.  Why do you want to do this?

If there is a good reason,

   structure(ddd, class=c("POSIXt", "POSIXct"))

will work currently, with no guarantees for the future.

On Wed, 22 Jan 2003, Matt Pocernich wrote:

> How do I convert a numeric value indicating the time since 1970, back into
> a POSIXct class object?  I have tried format.POSIXct and as.POSIXct
> without success.
> 
> For example
> > ccc
> [1] "1945-01-01 15:00:00 MDT"
> > ddd<- as.numeric(ccc);
> > ddd
> [1] -788842800
> > format.POSIXct(ddd)
> Error in format.POSIXct(ddd) : wrong class
> > as.POSIXct(ddd)
> Error in as.POSIXct.default(ddd) : Don't know how to convert `ddd' to
> class "POSIXct"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dgrove at fhcrc.org  Thu Jan 23 00:29:03 2003
From: dgrove at fhcrc.org (Douglas Grove)
Date: Thu Jan 23 00:29:03 2003
Subject: [R] dataframe subsetting behaviour
In-Reply-To: <x2wukwn5ds.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0301221525390.14648-100000@emu.fhcrc.org>

> Douglas Grove <dgrove at fhcrc.org> writes:
> 
> > Hi,
> > 
> > I'm trying to understand a behaviour that I have encountered
> > and can't fathom.
> > 
> > 
> > Here's some code I will use to illustrate the behaviour:
> > 
> > # start with some data frame "a" having some named columns
> > a <- data.frame(a=rep(1,3),c=rep(2,3),d=rep(3,3),e=rep(4,3))
> > 
> > # create a subset of the original data frame, but include a
> > # name "b" that is not present in my original data frame
> > b <- a[,c("a","b","c")]
> > 
> > 
> > ## Up until now no errors are issued, but the following commands
> > ## will give the error shown:
> > 
> > b[1,]     ## "Error in x[[j]] : subscript out of bounds"
> > b[1,2]    ## "Error in "names<-.default"(*tmp*, value = cols) : 
> >           ##  names attribute must be the same length as the vector"
> > 
> > 
> > Can anyone explain to me the meaning of these error messages in terms
> > of R is actually doing?  These error messages had me baffled and 
> > it took me hours to track down that the source of the error was an 
> > incorrect column name in my data frame subsetting.
> 
> Looks like a (semi-)bug. Indexing outside of the data frame creates a
> "column" which is really the single value NULL, e.g. 
> 
> > dput(a[,4:5])
> structure(list(e = c(4, 4, 4), "NA" = NULL), .Names = c("e",
> NA), row.names = c("1", "2", "3"), class = "data.frame")
> 
> This will print because the format.data.frame called inside
> print.data.frame will recycle the NULL and give you
> 
> > a[,4:5]
>   e   NA
> 1 4 NULL
> 2 4 NULL
> 3 4 NULL
> 
> However, it confuses the h*ck out of "[.data.frame"
> 
> > (a[,4:5])[2]
> Error in "[.data.frame"((a[, 4:5]), 2) : undefined columns selected
> > (a[,4:5])[,2]
> NULL
> > (a[,4:5])[,1]
> [1] 4 4 4
> 
> and also the examples you found. However, the main issue is that you
> have managed to construct a corrupt data frame. So indexing outside
> the array should probably either give an error or return a column of
> NA.


Yes, it would be nice if trying to index outside the data frame generated
an error, that is what happens in Splus (at least the version I have
access to: 6.0 Release 1 for Linux 2.2.12)


> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>



From pocernic at rap.ucar.edu  Thu Jan 23 00:42:03 2003
From: pocernic at rap.ucar.edu (Matt Pocernich)
Date: Thu Jan 23 00:42:03 2003
Subject: [R] Convert numeric value to POSIXct
In-Reply-To: <Pine.LNX.4.44.0301222320200.12915-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0301221638180.12813-100000@markov.rap.ucar.edu>

I found my error.  I was using cbind to connect a vector of POSIXct values
and numeric values.  Doing this caused the POSIXct format of the date
vector to be lost.  By correctly connecting them with data.frame, this was
not a problem.

Thanks,

Matt Pocernich
NCAR - Research Applications Program
303-497-8312

On Wed, 22 Jan 2003 ripley at stats.ox.ac.uk wrote:

> You can't safely.  Why do you want to do this?
>
> If there is a good reason,
>
>    structure(ddd, class=c("POSIXt", "POSIXct"))
>
> will work currently, with no guarantees for the future.
>
> On Wed, 22 Jan 2003, Matt Pocernich wrote:
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From quivering at optusnet.com.au  Thu Jan 23 01:29:03 2003
From: quivering at optusnet.com.au (David Alexander)
Date: Thu Jan 23 01:29:03 2003
Subject: [R] spearman rank correlation
Message-ID: <002c01c2c276$4211d6b0$89fdfea9@agnosticjihad>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030123/75465d15/attachment.pl

From quivering at optusnet.com.au  Thu Jan 23 03:14:02 2003
From: quivering at optusnet.com.au (David Alexander)
Date: Thu Jan 23 03:14:02 2003
Subject: [R] thanks!
Message-ID: <00dc01c2c284$f6a86d60$89fdfea9@agnosticjihad>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030123/a00ffed3/attachment.pl

From maj at stats.waikato.ac.nz  Thu Jan 23 03:24:03 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu Jan 23 03:24:03 2003
Subject: [R] order() on vector with Inf's
Message-ID: <3E2F520D.1030905@stats.waikato.ac.nz>

I have a parameter vector, ibeta, and a corresponding vector of 
loglikelihoods, llbet. If llbet contains no NAs or Inf's then I can 
extract the best parameter by

index <- order(-llbet)[1]
beta <- ibeta[index]

or similar. The argument na.last of order() allows me to fix this up 
even if llbet contains some NAs which I wish to ignore.

Unfortunately my llbet contains Inf's, which are not points of infinite 
likelihood, if anything they should be -Inf's. Anyway na.last does not 
seem to help me with these. What should I do?

Murray
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From kjetil at entelnet.bo  Thu Jan 23 04:29:02 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Thu Jan 23 04:29:02 2003
Subject: [R] spearman rank correlation
In-Reply-To: <002c01c2c276$4211d6b0$89fdfea9@agnosticjihad>
Message-ID: <3E2F28EE.1032.35C08F@localhost>

On 23 Jan 2003 at 11:27, David Alexander wrote:

Did ypu try to use cor.test?

> example(cor.test)

cr.tst> x <- c(44.4, 45.9, 41.9, 53.3, 44.7, 44.1, 50.7, 45.2, 
    60.1)

cr.tst> y <- c(2.6, 3.1, 2.5, 5, 3.6, 4, 5.2, 2.8, 3.8)

cr.tst> cor.test(x, y, method = "kendall", alternative = "greater")

        Kendall's rank correlation tau

data:  x and y 
T = 26, p-value = 0.05972
alternative hypothesis: true tau is greater than 0 
sample estimates:
      tau 
0.4444444 

It seems to be called tau rather than rho, but that should be good 
enough.

Kjetil Halvorsen


> hello help,
> 
> i've searched through the manual pages and the only reference i can find to spearman rank correlation is cor.test, which only seems to give the significance value of the correlation.
> 
> is there any way to get the actual value of rho?
> 
> david.
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Thu Jan 23 08:16:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan 23 08:16:03 2003
Subject: [R] order() on vector with Inf's
In-Reply-To: <3E2F520D.1030905@stats.waikato.ac.nz>
Message-ID: <Pine.LNX.4.44.0301230711230.13542-100000@gannet.stats>

On Thu, 23 Jan 2003, Murray Jorgensen wrote:

> I have a parameter vector, ibeta, and a corresponding vector of 
> loglikelihoods, llbet. If llbet contains no NAs or Inf's then I can 
> extract the best parameter by
> 
> index <- order(-llbet)[1]

sort.list(llbet, decreasing=TRUE)[1]

would be better.

> beta <- ibeta[index]

or just max(beta, na.rm=TRUE).

> or similar. The argument na.last of order() allows me to fix this up 
> even if llbet contains some NAs which I wish to ignore.
> 
> Unfortunately my llbet contains Inf's, which are not points of infinite 
> likelihood, if anything they should be -Inf's. Anyway na.last does not 
> seem to help me with these. What should I do?

llbet[llbet==Inf] <- -Inf

should correct the problem, but why not correct the calculation?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Thu Jan 23 08:37:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Jan 23 08:37:03 2003
Subject: [R] spearman rank correlation
In-Reply-To: <3E2F28EE.1032.35C08F@localhost>
References: <3E2F28EE.1032.35C08F@localhost>
Message-ID: <3E2F9A35.4010408@statistik.uni-dortmund.de>

kjetil brinchmann halvorsen wrote:
> On 23 Jan 2003 at 11:27, David Alexander wrote:
> 
> Did ypu try to use cor.test?
> 
> 
>>example(cor.test)
> 
> 
> cr.tst> x <- c(44.4, 45.9, 41.9, 53.3, 44.7, 44.1, 50.7, 45.2, 
>     60.1)
> 
> cr.tst> y <- c(2.6, 3.1, 2.5, 5, 3.6, 4, 5.2, 2.8, 3.8)
> 
> cr.tst> cor.test(x, y, method = "kendall", alternative = "greater")

[snip]

Almost - David was looking for Spearman's rho.
David should have tried it out with method="spearman" and ?cor.test 
tells us in Section "Value":

'estimate: the estimated measure of association, with name "cor", "tau", 
or "rho" correspoding to the method employed.'



>>hello help,
>>
>>i've searched through the manual pages and the only reference i can find to spearman rank correlation is cor.test, which only seems to give the significance value of the correlation.
>>
>>is there any way to get the actual value of rho?
>>
>>david.



From M.GRUM at CGIAR.ORG  Thu Jan 23 09:58:02 2003
From: M.GRUM at CGIAR.ORG (Grum, Mikkel [IPGRI-SSA-Nairobi])
Date: Thu Jan 23 09:58:02 2003
Subject: [R] Read.table for macs
Message-ID: 
 <FC788AB9771FD6118E6F0002A5AD7B8F01059F82@icrafnttrain.icraf.cgiar.org>

Hamish,

I suspect your problem might be with Excel.  try copying the data (and just
your data) to a clean spreadsheet and then save to a tab-delimited text
file. Removes all sorts of unwanted invisible garbage.

Then import into R with:
	test<-read.table("test.txt", header=T, sep="\t")


Mikkel



Hamish Callum wrote:

Dear All,

I've been using R for windows for a while, without too many problems. 
However, I'm forced to use the MAC OS system for teaching, because our 
teaching labs are mac only (not my idea!!). I have a very basic problem, 
but one that doesn't appear on the FAQs. I simply want to import data 
from a spreadsheet. I'm using exactly what works fine on Windows, namely:

1    save the file from Excel as tab-delimited, say called "test.txt", 
with the variable names in the first row.
2    Read in into R with
Dear All,

I've been using R for windows for a while, without too many problems. 
However, I'm forced to use the MAC OS system for teaching, because our 
teaching labs are mac only (not my idea!!). I have a very basic problem, 
but one that doesn't appear on the FAQs. I simply want to import data 
from a spreadsheet. I'm using exactly what works fine on Windows, namely:

1    save the file from Excel as tab-delimited, say called "test.txt", 
with the variable names in the first row.
2    Read in into R with
test<-read.table("test.txt", header=T)

It does weird things, especially if any variables are characters. For 
example, it has omitted the 5th observation for the 1st variable, and 
then appended it to the first variable name. I've tried read.csv with 
csv files, read.delim, etc. None seem to work. Am I being really silly, 
and if so, how do you do it? Or is there an easier way to get data into 
the mac port? Or is the mac port entirely useless?

Can anyone out there help?

Thanks


It does weird things, especially if any variables are characters. For 
example, it has omitted the 5th observation for the 1st variable, and 
then appended it to the first variable name. I've tried read.csv with 
csv files, read.delim, etc. None seem to work. Am I being really silly, 
and if so, how do you do it? Or is there an easier way to get data into 
the mac port? Or is the mac port entirely useless?

Can anyone out there help?

Thanks



From adrian.trapletti at lmttrading.com  Thu Jan 23 10:19:03 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Thu Jan 23 10:19:03 2003
Subject: [R] Re: R-help digest, Vol 1 #51 - 13 msgs
References: <20030119110006.17256.18960.Mailman@hypatia.math.ethz.ch>
Message-ID: <3E2FB346.F982E045@lmttrading.com>

> Subject: [R] Question on running tseries::garch on Mac OSX
> Date: Sat, 18 Jan 2003 15:58:50 -0800
> From: Nicholas Waltner <nwaltner at attbi.com>
> To: <R-help at stat.math.ethz.ch>
>
> Hello,
>
> When I run the garch examples, I get the following output:
>
> > dax.garch <- garch(dax)
>
>  ***** ESTIMATION WITH ANALYTICAL GRADIENT *****
>  ///  TUNER5.... V(30) =  0.750E+00 SHOULD BE BETWEEN  0.503-314 AND
> NaN
> ///  AFCTOL.... V(31) =  0.100E-19 SHOULD BE BETWEEN  0.518-317 AND
> NaN
> ///  LMAX0..... V(35) =  0.100E+01 SHOULD BE BETWEEN  0.518-317 AND
> NaN
>  ///  LMAXS..... V(36) =  0.100E+01 SHOULD BE BETWEEN  0.518-317 AND
> NaN
>  ///  DINIT..... V(38) = -0.100E+01 SHOULD BE BETWEEN -0.100E+02 AND
> NaN
>  ///  DTINIT.... V(39) =  0.100E-05 SHOULD BE BETWEEN  0.000E+00 AND
> NaN
> ///  D0INIT.... V(40) =  0.100E+01 SHOULD BE BETWEEN  0.000E+00 AND
> NaN
>
> Warning message:
> `Machine' is deprecated.
> Use `.Machine' instead.
> See ?Deprecated.
> >
>
> I can?t figure out what to do about the machine is deprecated issue. It
> seems that the routine is not picking up machine numerical characteristics,
> eps etc. I tried an eps = 0.1 and get slightly better errors (see below).
> So, when it calls dsumsl, the errors above are produced. I have checked
> str(.Machine) and the definitions are all there.
>
> What should I do to get garch to run?

Use the newest version of tseries 0.9-7.

best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com



From wolfram at fischer-zim.ch  Thu Jan 23 10:24:03 2003
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Thu Jan 23 10:24:03 2003
Subject: [R] conversion of a list of matrices into a dataframe
Message-ID: <20030123102223.A1827@s1x.zimnet.ch>

DATA
	I have data from two (or more) locations with ID: 'A' and 'B'
    for three (or more) YEARS: 1999 to 2001
    of two (or more) variables: VAR1, VAR2.

	> x
	  ID YEAR VAR1 VAR2
	1  A 1999    9    2
	2  B 1999    8    9
	3  A 2000    2    3
	4  B 2000    3    4
	5  A 2001    9    5
	6  B 2001    7    2

DESIRED RESULT
	I want to calculate the rank of the values of each variable
    for each location (ID) in every year.
    I want to get the ranks in a dataframe 'x.ranked'
    having the same structure as the original dataframe 'x'
    (which should be ready for the use by lattice functions).
    
	> x.ranked
	  ID YEAR VAR1 VAR2
	1  A 1999    2    1
	2  B 1999    1    2
	3  A 2000    1    1
	4  B 2000    2    2
	5  A 2001    2    2
	6  B 2001    1    1


EXAMPLE CODE
    x <- data.frame(
          ID    = rep( c('A', 'B' ), 3 )
        , YEAR  = rep( c( 1999, 2000, 2001 ), each=2 )
        , VAR1  = c( 9, 8,  2, 3,  9, 7 )
        , VAR2  = c( 2, 9,  3, 4,  5, 2 )
        )
    vars <- c( 'VAR1', 'VAR2' )

    fun <- function( x, group=NULL ){
        if( ! is.null(group) )      by( x, group, fun )
        else if( ! is.vector(x) )   sapply( x, fun )
        else                        rank( x )
    }

    x.ranked <- fun( x[,vars], x$YEAR )


OBTAINED RESULT
	I got the right values by using the function 'fun',
    but the result does not have the desired structure.
	Can anyone help me to get the desired structure?

	> x.ranked
	group: 1999
		 VAR1 VAR2
	[1,]    2    1
	[2,]    1    2
	--------------
	group: 2000
		 VAR1 VAR2
	[1,]    1    1
	[2,]    2    2
	--------------
	group: 2001
		 VAR1 VAR2
	[1,]    2    2
	[2,]    1    1


Wolfram



From david.orlovich at botany.otago.ac.nz  Thu Jan 23 10:34:03 2003
From: david.orlovich at botany.otago.ac.nz (David Orlovich)
Date: Thu Jan 23 10:34:03 2003
Subject: [R] Read.table for macs
In-Reply-To: <FC788AB9771FD6118E6F0002A5AD7B8F01059F82@icrafnttrain.icraf.cgiar.org>
Message-ID: <AF3CE2CA-2EB5-11D7-A964-0030654D9D4A@botany.otago.ac.nz>

Mikkel

As mentioned earlier it's a known, (now fixed) bug.

Last night I compiled a new copy of the R-1.6.2 source with the current 
patch set installed first and it works fine under Darwin/X11 on my 
(excellent) G4/400 Mac.

I just tried reading in a dummy file and it seems to read the file 
fine.  I put mixtures of letters and numbers in the test file as this 
was reported to be a problem.  Anyway it's pasted below and it is 
exactly the same as the dummy file I typed into Excel (v. X 10.1.3).  
So ... as far as I can see the patch works.  See below.  Cheers, David 
Orlovich.

[mushroom:~/R_work] orlovich% R

R : Copyright 2003, The R Development Core Team
Version 1.6.2 Patched (2003-01-21)

<snip>

 > test<-read.table("test.txt", header=T)
 > test
      sp1 sp2 sp3
tr3   43  56  56
tr4   43  58  4r
tr69  44  56  56
f4    45 r44  e3
h65   74  46   t
t65   56 ttw  54
h77   75  t4  45
t44   6r  5t  54




On Thursday, January 23, 2003, at 10:00 PM, Grum, Mikkel 
[IPGRI-SSA-Nairobi] wrote:

> Hamish,
>
> I suspect your problem might be with Excel.  try copying the data (and 
> just
> your data) to a clean spreadsheet and then save to a tab-delimited text
> file. Removes all sorts of unwanted invisible garbage.
>
> Then import into R with:
> 	test<-read.table("test.txt", header=T, sep="\t")
>
>
> Mikkel
>
>
>
> Hamish Callum wrote:
>
> Dear All,
>
> I've been using R for windows for a while, without too many problems.
> However, I'm forced to use the MAC OS system for teaching, because our
> teaching labs are mac only (not my idea!!). I have a very basic 
> problem,
> but one that doesn't appear on the FAQs. I simply want to import data
> from a spreadsheet. I'm using exactly what works fine on Windows, 
> namely:
>
> 1    save the file from Excel as tab-delimited, say called "test.txt",
> with the variable names in the first row.
> 2    Read in into R with
> Dear All,
>
> I've been using R for windows for a while, without too many problems.
> However, I'm forced to use the MAC OS system for teaching, because our
> teaching labs are mac only (not my idea!!). I have a very basic 
> problem,
> but one that doesn't appear on the FAQs. I simply want to import data
> from a spreadsheet. I'm using exactly what works fine on Windows, 
> namely:
>
> 1    save the file from Excel as tab-delimited, say called "test.txt",
> with the variable names in the first row.
> 2    Read in into R with
> test<-read.table("test.txt", header=T)
>
> It does weird things, especially if any variables are characters. For
> example, it has omitted the 5th observation for the 1st variable, and
> then appended it to the first variable name. I've tried read.csv with
> csv files, read.delim, etc. None seem to work. Am I being really silly,
> and if so, how do you do it? Or is there an easier way to get data into
> the mac port? Or is the mac port entirely useless?
>
> Can anyone out there help?
>
> Thanks
>
>
> It does weird things, especially if any variables are characters. For
> example, it has omitted the 5th observation for the 1st variable, and
> then appended it to the first variable name. I've tried read.csv with
> csv files, read.delim, etc. None seem to work. Am I being really silly,
> and if so, how do you do it? Or is there an easier way to get data into
> the mac port? Or is the mac port entirely useless?
>
> Can anyone out there help?
>
> Thanks
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
Dr David Orlovich
Department of Botany,
The University of Otago,
P.O. Box 56,
Dunedin,
New Zealand.

Phone +64 3 479 9060
Fax +64 3 479 7583
david.orlovich at botany.otago.ac.nz
david.orlovich at unix.net
http://www.botany.otago.ac.nz/



From maj at stats.waikato.ac.nz  Thu Jan 23 10:38:13 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu Jan 23 10:38:13 2003
Subject: [R] order() on vector with Inf's
References: <Pine.LNX.4.44.0301230711230.13542-100000@gannet.stats>
Message-ID: <3E2FB6EC.6080503@stats.waikato.ac.nz>

ripley at stats.ox.ac.uk wrote:
On Thu, 23 Jan 2003, Murray Jorgensen wrote:
[useful suggestions omitted]

llbet[llbet==Inf] <- -Inf

should correct the problem, but why not correct the calculation?

Not a bad idea, but the numerical difficulties always occur well away 
from the likelihood maximum, and I'm only looking for reasonable 
starting values.

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From jan.wiener at tuebingen.mpg.de  Thu Jan 23 13:41:03 2003
From: jan.wiener at tuebingen.mpg.de (Jan Malte Wiener)
Date: Thu Jan 23 13:41:03 2003
Subject: [R] mann-whitney u test
Message-ID: <3E2FE28D.8090202@tuebingen.mpg.de>

hi,
i can not find the mann whitney u test in R.
could someone help me with that ?
thanks,
jan



-- 
Jan Malte Wiener
Max-Planck-Institute for Biological Cybernetics
Spemannstr. 38, 72076 Tuebingen, Germany
Tel.: +49 7071 601 631
Email: jan.wiener at tuebingen.mpg.de



From baron at cattell.psych.upenn.edu  Thu Jan 23 13:52:03 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Thu Jan 23 13:52:03 2003
Subject: [R] mann-whitney u test
In-Reply-To: <3E2FE28D.8090202@tuebingen.mpg.de>; from jan.wiener@tuebingen.mpg.de on Thu, Jan 23, 2003 at 01:39:41PM +0100
References: <3E2FE28D.8090202@tuebingen.mpg.de>
Message-ID: <20030123075017.A12060@cattell.psych.upenn.edu>

On 01/23/03 13:39, Jan Malte Wiener wrote:
>hi,
>i can not find the mann whitney u test in R.
>could someone help me with that ?

See wilcox.test in the ctest package (which loads automatically,
so just say ?wilcox.test)

--
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From mschwartz at medanalytics.com  Thu Jan 23 13:57:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu Jan 23 13:57:03 2003
Subject: [R] mann-whitney u test
In-Reply-To: <3E2FE28D.8090202@tuebingen.mpg.de>
Message-ID: <001101c2c2de$4649dfd0$0201a8c0@MARC>

Jan

Take a look at ?wilcox.test

Regards,

Marc


> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jan Malte
Wiener
> Sent: Thursday, January 23, 2003 6:40 AM
> To: R
> Subject: [R] mann-whitney u test
> 
> 
> hi,
> i can not find the mann whitney u test in R.
> could someone help me with that ?
> thanks,
> jan
> 
> 
> 
> -- 
> Jan Malte Wiener
> Max-Planck-Institute for Biological Cybernetics
> Spemannstr. 38, 72076 Tuebingen, Germany
> Tel.: +49 7071 601 631
> Email: jan.wiener at tuebingen.mpg.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From steve.roberts at man.ac.uk  Thu Jan 23 14:13:05 2003
From: steve.roberts at man.ac.uk (Steve Roberts)
Date: Thu Jan 23 14:13:05 2003
Subject: [R] Profile on optim/nlm
Message-ID: <3E2FEA1A.28334.A21C8E5@localhost>

Greetings,

Before I reinvent the wheel has anyone done a profile function for a 
fit using optim (or nlm)?  (like the buggy profile.ms in S+) . It 
seems a bit tricky as the function to be minimised has to have 
arguments corresponding to the variables being fitted - which is one 
less than the function provided to optim()... I guess you can create 
another function on the fly somehow.

Cheers,

Steve.
Dr Steve Roberts 
steve.roberts at man.ac.uk

Biostatistics Group,				
School of Epidemiology and Health Sciences,	
2nd Floor,Stopford Building,			
University of Manchester.			
M13 9PT.					
Tel: 0161 275 5192 FAX: 0161 275 5205



From ripley at stats.ox.ac.uk  Thu Jan 23 14:28:07 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan 23 14:28:07 2003
Subject: [R] Profile on optim/nlm
In-Reply-To: <3E2FEA1A.28334.A21C8E5@localhost>
Message-ID: <Pine.LNX.4.44.0301231322110.1314-100000@gannet.stats>

Ah, you mean a method for profile() for an object fitted by optim or nlm!  
That's not any of the first five or so meanings I envisaged.
(Not that that can be exactly true, as the results from ms, optim and nlm 
are not classed.)

It's not at all difficult to cook one up: you just need to look at the
way arima uses optim with a variable subset of parameters held fixed.
Unlike S-PLUS, you can use lexical scoping (and arima does).  However,
I would rather profile a real fit class using a fit function based on 
optim.

On Thu, 23 Jan 2003, Steve Roberts wrote:

> Greetings,
> 
> Before I reinvent the wheel has anyone done a profile function for a 
> fit using optim (or nlm)?  (like the buggy profile.ms in S+) . It 
> seems a bit tricky as the function to be minimised has to have 
> arguments corresponding to the variables being fitted - which is one 
> less than the function provided to optim()... I guess you can create 
> another function on the fly somehow.
> 
> Cheers,
> 
> Steve.
> Dr Steve Roberts 
> steve.roberts at man.ac.uk
> 
> Biostatistics Group,				
> School of Epidemiology and Health Sciences,	
> 2nd Floor,Stopford Building,			
> University of Manchester.			
> M13 9PT.					
> Tel: 0161 275 5192 FAX: 0161 275 5205
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Jan 23 14:38:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan 23 14:38:02 2003
Subject: [R] Error when using polr() in MASS
In-Reply-To: <3.0.6.32.20030122095614.00a8f8c0@mail.anst.uu.se>
Message-ID: <Pine.LNX.4.44.0301231332370.1314-100000@gannet.stats>

That example works here (once I make skugg an ordered factor):

Call:
polr(formula = skugg ~ grupp, data = dat, weights = frekv)

Coefficients:
     Value Std. Error    t value 
 -3.287802   1.252344  -2.625318 

Intercepts:
    Value   Std. Error t value
1|2 -5.8783  1.5565    -3.7765
2|3 -0.6973  0.7062    -0.9875

Residual Deviance: 25.76504 
AIC: 31.76504 

BTW, there is no point in including points with zero weight.


On Wed, 22 Jan 2003, Tord Snall wrote:

> Dear all,
> 
> I get an error message when I use polr() in MASS. These are my data:
> 
>    skugg grupp frekv
> 4      1   gr3     0
> 5      2   gr3     3
> 6      3   gr3     6
> 10     1   gr5     1
> 11     2   gr5    12
> 12     3   gr5     1
> > 
> > summary(polr(skugg ~ grupp, weights=frekv, data= skugg.cpy1.dat))
> Error in optim(start, fmin, gmin, method = "BFGS", hessian = Hess, ...) : 
>         non-finite value supplied by optim
> 
> Does this depend on the very few observations in skugg 1 - the
> proportional-odds assumption doesn't hold (p 231, MASS 3ed)? If so, I would
> be happy for a recommendation on another approach.
> 
> And I also have a similar data set where only the skugg classes 2 and 3 are
> observed. Would you recommend glm, family= binomial for that analysis?
> 
> I use R 1.6.2, MASS 7.0-10, Win 2000. 
> 
> 
> Thanks in advance!
> 
> Please reply also to me because I'm on the once a day-list
> 
> 
> Sincerely,
> Tord
> 
> -----------------------------------------------------------------------
> Tord Sn?ll
> Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
> Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
> Villav?gen 14			
> SE-752 36 Uppsala, Sweden
> Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
> Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
> Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
> E-mail: Tord.Snall at ebc.uu.se
> Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gisar at nus.edu.sg  Thu Jan 23 14:43:02 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Thu Jan 23 14:43:02 2003
Subject: [R] mann-whitney u test
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053ECF@MBXSRV03.stf.nus.edu.sg>

Look under wilcox.test() with the option paired=FALSE

-----Original Message-----
From: Jan Malte Wiener [mailto:jan.wiener at tuebingen.mpg.de] 
Sent: Thursday, January 23, 2003 8:40 PM
To: R
Subject: [R] mann-whitney u test


hi,
i can not find the mann whitney u test in R.
could someone help me with that ?
thanks,
jan



-- 
Jan Malte Wiener
Max-Planck-Institute for Biological Cybernetics
Spemannstr. 38, 72076 Tuebingen, Germany
Tel.: +49 7071 601 631
Email: jan.wiener at tuebingen.mpg.de

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ben at zoo.ufl.edu  Thu Jan 23 14:49:03 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Thu Jan 23 14:49:03 2003
Subject: [R] Profile on optim/nlm
In-Reply-To: <3E2FEA1A.28334.A21C8E5@localhost>
Message-ID: <Pine.LNX.4.44.0301230849520.26307-100000@bolker.zoo.ufl.edu>

  I have some code to do this; I keep meaning to clean it up and put it 
on CRAN, but it's fairly hard work to do it right.  I also thought I heard 
a rumor that there would be something like that in MASS4.  There should be 
a version on http://www.zoo.ufl.edu/bolker/R (subdirectories src and 
windows), let me know how it goes for you ...

   Ben

On Thu, 23 Jan 2003, Steve Roberts wrote:

> Greetings,
> 
> Before I reinvent the wheel has anyone done a profile function for a 
> fit using optim (or nlm)?  (like the buggy profile.ms in S+) . It 
> seems a bit tricky as the function to be minimised has to have 
> arguments corresponding to the variables being fitted - which is one 
> less than the function provided to optim()... I guess you can create 
> another function on the fly somehow.
> 
> Cheers,
> 
> Steve.
> Dr Steve Roberts 
> steve.roberts at man.ac.uk
> 
> Biostatistics Group,				
> School of Epidemiology and Health Sciences,	
> 2nd Floor,Stopford Building,			
> University of Manchester.			
> M13 9PT.					
> Tel: 0161 275 5192 FAX: 0161 275 5205
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From ernesto at ipimar.pt  Thu Jan 23 15:14:03 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu Jan 23 15:14:03 2003
Subject: [R] Exporting graphics window
Message-ID: <1043331348.11939.13.camel@gandalf.ipimar.pt>

Hi

I'm working on a remote computer with R (SuSE 8.1) and I want to do some
ploting. Does anyone knows if it is possible to export the graphics
window in to my display and how I can do it ? 

Thanks

EJ

-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
Research Institute for Agriculture and Fisheries
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948



From theis at statistik.uni-dortmund.de  Thu Jan 23 15:25:04 2003
From: theis at statistik.uni-dortmund.de (Winfried Theis)
Date: Thu Jan 23 15:25:04 2003
Subject: [R] Exporting graphics window
In-Reply-To: <1043331348.11939.13.camel@gandalf.ipimar.pt>
Message-ID: <XFMail.030123163415.theis@statistik.uni-dortmund.de>

Hi!

This depends on the machine you are working on, on a unix system you need to
allow the remote computer to write on your X-Display and then tell it the
display it should export to. For details see the manual page of X. as you see
this is no R-specific thing...

Cheers,

Winfried


On 23-Jan-03 Ernesto Jardim wrote:
> Hi
> 
> I'm working on a remote computer with R (SuSE 8.1) and I want to do some
> ploting. Does anyone knows if it is possible to export the graphics
> window in to my display and how I can do it ? 
> 
> Thanks
> 
> EJ
> 
> -- 
> Ernesto Jardim <ernesto at ipimar.pt>
> Marine Biologist
> Research Institute for Agriculture and Fisheries
> Lisboa, Portugal
> Tel: +351 213 027 000
> Fax: +351 213 015 948
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

---------------------------------------------------------------------
E-Mail: Winfried Theis <theis at statistik.uni-dortmund.de>
Date: 23-Jan-03

Dipl.-Math. Winfried Theis
SFB 475, Fachbereich Statistik, Universit"at Dortmund, 44221 Dortmund
Tel.: +49-231-755-5903 FAX: +49-231-755-4387
----------------------------------------------------------------------



From mk36 at aub.edu.lb  Thu Jan 23 15:43:03 2003
From: mk36 at aub.edu.lb (Marwan Khawaja)
Date: Thu Jan 23 15:43:03 2003
Subject: [R] Using Internet proxies
Message-ID: <CLECJBOEBGOMOKJHJNDAIEDOCMAA.marwan.khawaja@aub.edu.lb>

Hi,
I want to thank Prof Ripley for his very helpful suggestions re internet
proxies.
This is great -- very useful!
Marwan

--------------------------------------------------------------------------------
----------------------------------------------
Marwan Khawaja 	<http://webfaculty.aub.edu.lb/~mk36  if you have MS Explorer
--------------------------------------------------------------------------------
----------------------------------------------


From: ripley at stats.ox.ac.uk
Date: Wed, 22 Jan 2003 19:07:42 +0000 (GMT)
To: R-help at r-project.org
Subject: [R] Using Internet proxies

There have been quite a few questions recently about this, so I have 
tried to gather experience.  I set up a proxy using Apache2 (a very common 
server) behind our firewall and tried various authentication approaches.

One comment: all the methods return error messages when they fail.  Please 
don't report `it doesn't work' without the full details.

1) For a proxy that authenticates at most by hostname/IP address, and for
Windows users, just set up IE6 to work, and use the --internet2
command-line flag.  This worked for me (despite various claims here).

2) For a proxy that authenticates at most by hostname/IP address, the
internal download.file method works, provided you set the environment
variable http_proxy or HTTP_PROXY correctly, e.g. in ~/.Renviron.
This is almost of the same form as used by wget, but is less tolerant,
and note that setting `no_proxy' disables the proxy for all sites (unlike 
for wget).

3) If you have a proxy that demands that you enter a username/password 
combination, you can use the internal download method in R-devel: see
?download.file.

4) Installing wget and using the options(download.file.method="wget")
provides a highly tunable approach.  For Windows users, wget is still
available on http://www.stats.ox.ac.uk/pub/Rtools.

Note that none of these methods support proxies that want more advanced 
methods of authentication, e.g. Digest under HTTP/1.1.  If there are
any such proxies, please can a user provide us with a proven method.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


--------------------------------------------------------------------------------
----------------------------------------------
Marwan Khawaja 	<http://webfaculty.aub.edu.lb/~mk36  if you have MS Explorer
--------------------------------------------------------------------------------
----------------------------------------------


-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 3028 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030123/c03c62c8/winmail.bin

From ravishan at fas.harvard.edu  Thu Jan 23 17:10:03 2003
From: ravishan at fas.harvard.edu (Nirmala Ravishankar)
Date: Thu Jan 23 17:10:03 2003
Subject: [R] Using ltext
In-Reply-To: <200301211551.22348.deepayan@stat.wisc.edu>
Message-ID: <Pine.OSF.4.44.0301231057560.28976-100000@is06.fas.harvard.edu>

So, I am trying to label the points in a graph, but cannot quite figure
out how to use ltext.  I get an error about the lengths of x and y  not
being the same, when I have defined them as the same.

> a <- data.frame(num = 1:4)
> a$country <- c("A", "B", "C", "D")
> a$p <- c(0.34, .54, .41, .33)
> a$q <- c(.07, .03, .05, .10)

> a
  num country    p    q
1   1       A 0.34 0.07
2   2       B 0.54 0.03
3   3       C 0.41 0.05
4   4       D 0.33 0.10

> xyplot(p ~ q, data = a, ltext(x=x, y=y, label = a$country))
Error in xy.coords(x, y) : x and y lengths differ

> xyplot(p ~ q, data = a, groups = as.character(a$country), ltext(x=x,
y=y, label = groups[subscripts]))
Error in xy.coords(x, y) : x and y lengths differ

- Nirmala



From rpeng at stat.ucla.edu  Thu Jan 23 17:19:03 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu Jan 23 17:19:03 2003
Subject: [R] Exporting graphics window
In-Reply-To: <1043331348.11939.13.camel@gandalf.ipimar.pt>
Message-ID: <Pine.GSO.4.10.10301230809130.12931-100000@quetelet.stat.ucla.edu>

You can set the `display' argument to `x11' to your local computer's
screen (and allow the remote computer to connect via xhost).  Something
like 

x11(display = "mymachine:0.0")

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On 23 Jan 2003, Ernesto Jardim wrote:

> Hi
> 
> I'm working on a remote computer with R (SuSE 8.1) and I want to do some
> ploting. Does anyone knows if it is possible to export the graphics
> window in to my display and how I can do it ? 
> 
> Thanks
> 
> EJ
> 
> -- 
> Ernesto Jardim <ernesto at ipimar.pt>
> Marine Biologist
> Research Institute for Agriculture and Fisheries
> Lisboa, Portugal
> Tel: +351 213 027 000
> Fax: +351 213 015 948
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tord.snall at ebc.uu.se  Thu Jan 23 17:37:06 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Thu Jan 23 17:37:06 2003
Subject: [R] Error when using polr() in MASS
Message-ID: <3.0.6.32.20030123172938.00b6e970@mail.anst.uu.se>

Dear Prof. Ripley,

Thanks for your replies! 

I just want to add this below, which might be helpful to others who get a
similar problem in the future.

Tord


> skuggor<- dat[!is.na(dat$skugg), ] 
> skugg.cpy1<- subset(skuggor, cpy==1)
> skugg.cpy1.dat<- as.data.frame(table(skugg.cpy1$skugg, skugg.cpy1$grupp))
> names(skugg.cpy1.dat)<- c("skugg", "grupp", "frekv")
> skugg.cpy1.dat<- subset(skugg.cpy1.dat, grupp == "gr3" | grupp == "gr5")
> skugg.cpy1.dat
   skugg grupp frekv
4      1   gr3     0
5      2   gr3     3
6      3   gr3     6
10     1   gr5     1
11     2   gr5    12
12     3   gr5     1
> summary(polr(as.ordered(skugg) ~ as.factor(grupp),
weights=as.numeric(frekv), data= as.data.frame(skugg.cpy1.dat)))
Error in optim(start, fmin, gmin, method = "BFGS", hessian = Hess, ...) : 
        non-finite value supplied by optim

I guess it is a matter of data format It seem to be, because the following
works:

> 
> s<- skugg.cpy1.dat[,1]
> g<- skugg.cpy1.dat[,2]
> f<- skugg.cpy1.dat[,3]
> sgf<- as.data.frame(cbind(s,g,f))
> sgf
  s g  f
1 1 2  0
2 2 2  3
3 3 2  6
4 1 4  1
5 2 4 12
6 3 4  1
> summary(polr(as.ordered(s) ~ as.factor(g), weights=as.numeric(f), data=
sgf))

Re-fitting to get Hessian

Call:
polr(formula = as.ordered(s) ~ as.factor(g), data = sgf, weights =
as.numeric(f))

Coefficients:
     Value Std. Error    t value 
 -3.287802   1.252344  -2.625318 

Intercepts:
    Value   Std. Error t value
1|2 -5.8783  1.5565    -3.7765
2|3 -0.6973  0.7062    -0.9875

Residual Deviance: 25.76504 
AIC: 31.76504 




>
>That example works here (once I make skugg an ordered factor):
>
>Call:
>polr(formula = skugg ~ grupp, data = dat, weights = frekv)
>
>Coefficients:
>     Value Std. Error    t value 
> -3.287802   1.252344  -2.625318 
>
>Intercepts:
>    Value   Std. Error t value
>1|2 -5.8783  1.5565    -3.7765
>2|3 -0.6973  0.7062    -0.9875
>
>Residual Deviance: 25.76504 
>AIC: 31.76504 
>
>BTW, there is no point in including points with zero weight.
>
>
>On Wed, 22 Jan 2003, Tord Snall wrote:
>
>> Dear all,
>> 
>> I get an error message when I use polr() in MASS. These are my data:
>> 
>>    skugg grupp frekv
>> 4      1   gr3     0
>> 5      2   gr3     3
>> 6      3   gr3     6
>> 10     1   gr5     1
>> 11     2   gr5    12
>> 12     3   gr5     1
>> > 
>> > summary(polr(skugg ~ grupp, weights=frekv, data= skugg.cpy1.dat))
>> Error in optim(start, fmin, gmin, method = "BFGS", hessian = Hess, ...) : 
>>         non-finite value supplied by optim
>> 
>> Does this depend on the very few observations in skugg 1 - the
>> proportional-odds assumption doesn't hold (p 231, MASS 3ed)? If so, I would
>> be happy for a recommendation on another approach.
>> 
>> And I also have a similar data set where only the skugg classes 2 and 3 are
>> observed. Would you recommend glm, family= binomial for that analysis?
>> 
>> I use R 1.6.2, MASS 7.0-10, Win 2000. 
>> 
>> 
>> Thanks in advance!
>> 
>> Please reply also to me because I'm on the once a day-list
>> 
>> 
>> Sincerely,
>> Tord
>> 
>> -----------------------------------------------------------------------
>> Tord Sn?ll
>> Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
>> Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
>> Villav?gen 14			
>> SE-752 36 Uppsala, Sweden
>> Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
>> Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
>> Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
>> E-mail: Tord.Snall at ebc.uu.se
>> Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
>> ------------------------------------------------------------------------
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> 
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From dieter.menne at menne-biomed.de  Thu Jan 23 18:03:02 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Thu Jan 23 18:03:02 2003
Subject: [R] RLS Algorithm adaptive filtering?
Message-ID: <JLEPLGAANFCEAEDCAGJNGEBCCEAA.dieter.menne@menne-biomed.de>

Does anyone know if there is a R-library that implements adaptive filtering
algorithms (LMS, RLS...)


Dieter Menne



From a296180 at arbres1a.fmr.com  Thu Jan 23 20:18:02 2003
From: a296180 at arbres1a.fmr.com (David Kane  <David Kane)
Date: Thu Jan 23 20:18:02 2003
Subject: [R] Summary: Warnings with no INDEX file in a package
Message-ID: <15920.16288.605535.475002@gargle.gargle.HOWL>

Thanks to Henrik Bengtsson, Martin Maechler, Brian Ripley, Jeff Gentry and
David Brahm for taking the time to answer my questions about INDEX files in R
packages.

My key take-aways were:

1) All of this will be changing a lot in R 1.7.0-to-be, so don't sweat the
   details.

2) Many people run R CMD build before they run R CMD check. I found this quite
   surprising. I did not realize that R CMD build actually *changes* the contents
   of your package by, at least, adding an INDEX file if one is not there. I do
   not see this behavior documented in the help for R CMD build. As a simple
   example:

agate|tmp> ls pyri.check
CVS		DESCRIPTION	R		inst		man
agate|tmp> R CMD build pyri.check
* checking for file 'pyri.check/DESCRIPTION' ... OK
* preparing 'pyri.check':
* checking whether 'INDEX' is up-to-date ... NO
* creating new 'INDEX'
* removing junk files
* building 'pyri.check_1.5.tar.gz'

agate|tmp> ls pyri.check
CVS		INDEX		inst
DESCRIPTION	R		man
agate|tmp>

When I first run R CMD check, I get a warning about the lack of an INDEX. But,
since R CMD build creates the index for me, I can now run R CMD check and get
no warnings.

My mistake was to interpret:

"* creating new 'INDEX'"

to mean:

"Making an INDEX file and putting it in your .gz file while leaving your
original package unchanged."


Thanks to all for clarifying this for me.

Dave Kane

-- 
David Kane
Geode Capital Management
617-563-0122
david.d.kane at fmr.com
Please avoid sending me Word or PowerPoint attachments.
See http://www.fsf.org/philosophy/no-word-attachments.html



From saurav at sas.upenn.edu  Thu Jan 23 20:28:16 2003
From: saurav at sas.upenn.edu (Saurav Pathak)
Date: Thu Jan 23 20:28:16 2003
Subject: [R] loading functions from files
Message-ID: <20030123192136.GA12682@mail2.sas.upenn.edu>

hi,

i think this is a basic question, but i did not find any
documentation.

i have a file, helloworld.R, which has

helloworld <- function() {
  cat("Hello World\n")
}

how may i load this file in R so that i may say at the prompt:

> helloworld()

i am not yet ready to write a package.

thanks,
-- 
saurav



From jgentry at jimmy.harvard.edu  Thu Jan 23 20:35:34 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu Jan 23 20:35:34 2003
Subject: [R] loading functions from files
In-Reply-To: <20030123192136.GA12682@mail2.sas.upenn.edu>
Message-ID: <Pine.SOL.4.20.0301231430280.26749-100000@santiam.dfci.harvard.edu>

On Thu, 23 Jan 2003, Saurav Pathak wrote:
> how may i load this file in R so that i may say at the prompt:

source("filename.R") should do the trick



From f0z6305 at labs.tamu.edu  Thu Jan 23 22:56:02 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu Jan 23 22:56:02 2003
Subject: [R] A stupid question on F-statistics
Message-ID: <010a01c2c32a$2ce14a00$8bd75ba5@IE.TAMU.EDU>

Dear all,
Just a stupid question confused me for a long time.

Now suppose p_dim random vector x (column vector) are from
a multivariate normal N(mu, Sigma).

Given a sample size n, (x1, x2, ....., xn),
and the sample mean is x_bar, sample covariance is S.
I can infer that
n(x_bar - mu)'*inverse(S)*(x_bar - mu) is distributed as F(p, n-p), and for
a new observation vector x,
(x - mu)'*inverse(S)*(x - mu) is distributed as F(p, n-p).

So why the follow statistics T is distributed as
(n+1)(n-1)p/n(n-1)F(p, n-1)?
T = (x - x_bar)'*inverse(S)*(x - x_bar)

Thanks so much for pointing me the way to solve it out.

Fred



From s195404 at student.uq.edu.au  Thu Jan 23 23:04:03 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Thu Jan 23 23:04:03 2003
Subject: [R] Using ltext
In-Reply-To: <Pine.OSF.4.44.0301231057560.28976-100000@is06.fas.harvard.edu>
References: <Pine.OSF.4.44.0301231057560.28976-100000@is06.fas.harvard.edu>
Message-ID: <1043359392.3e3066a029a23@my.uq.edu.au>

Nirmala,

You will need to use a panel function to label the points, I think.
Try the following code. I'm assuming you really want a lattice plot.

xyplot(p ~ q, data=a, country=a$country, subscripts=subscripts, 
       panel=function(x,y,subscripts,country,...) {
          ltext(x,y,country[subscripts])
       })



Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting Nirmala Ravishankar <ravishan at fas.harvard.edu>:

> 
> So, I am trying to label the points in a graph, but cannot quite figure
> out how to use ltext.  I get an error about the lengths of x and y  not
> being the same, when I have defined them as the same.
> 
> > a <- data.frame(num = 1:4)
> > a$country <- c("A", "B", "C", "D")
> > a$p <- c(0.34, .54, .41, .33)
> > a$q <- c(.07, .03, .05, .10)
> 
> > a
>   num country    p    q
> 1   1       A 0.34 0.07
> 2   2       B 0.54 0.03
> 3   3       C 0.41 0.05
> 4   4       D 0.33 0.10
> 
> > xyplot(p ~ q, data = a, ltext(x=x, y=y, label = a$country))
> Error in xy.coords(x, y) : x and y lengths differ
> 
> > xyplot(p ~ q, data = a, groups = as.character(a$country), ltext(x=x,
> y=y, label = groups[subscripts]))
> Error in xy.coords(x, y) : x and y lengths differ
> 
> - Nirmala
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From lj22 at u.washington.edu  Thu Jan 23 23:49:03 2003
From: lj22 at u.washington.edu (Lei Jiang)
Date: Thu Jan 23 23:49:03 2003
Subject: [R] subset dataframe based on rows
Message-ID: <Pine.A41.4.44.0301231435020.30646-100000@homer32.u.washington.edu>

I want to subset the dataframe based on certain values in a row.

for each row in my dataframe
	if ANY one value of a particular set of columns satisfies cond
		append a logical value true at the end of the row
	else
		append a false at the end of the row

in the end I want to be able to subset the whole data based on the
appended true or false value.

I could literally code like this, but I think there must be a better way
to do this. Can someone give me a hint?? thanks.

Lei

Department of Chemsitry
University of Washington
Box 351700
Seattle, WA 98195
Phone: 206-616-6882
Fax: 206-685-8665



From lockwood at rand.org  Fri Jan 24 00:11:02 2003
From: lockwood at rand.org (J.R. Lockwood)
Date: Fri Jan 24 00:11:02 2003
Subject: [R] subset dataframe based on rows
In-Reply-To: <Pine.A41.4.44.0301231435020.30646-100000@homer32.u.washington.edu>
Message-ID: <Pine.LNX.4.33.0301231755560.28691-100000@penguin.rand.org>

> 
> I want to subset the dataframe based on certain values in a row.
> 
> for each row in my dataframe
> 	if ANY one value of a particular set of columns satisfies cond
> 		append a logical value true at the end of the row
> 	else
> 		append a false at the end of the row
> 
> in the end I want to be able to subset the whole data based on the
> appended true or false value.
> 
> I could literally code like this, but I think there must be a better way
> to do this. Can someone give me a hint?? thanks.
> 
> Lei
> 

I'm not sure what you mean by "better", but at the least you don't
need to append the indicator column to your dataframe.  Just use
whatever logical vector results from checking whether the columns
satisfy the condition to subset your data frame, as in:

d[meetsyourconditions,]

As for determining whether the conditions are met, row by row, you
should be able to this as a vector operation, but it could get ugly
depending on the nature of the columns and what you call "cond".  In
the most fortunate case where all the columns are of a single mode and
cond is sufficiently simple, you can apply "function(x){any(x meets
cond)}" to the rows of a matrix defined by your columns of interest.
This will give you the logical vector you need to subset the
dataframe.


J.R. Lockwood
412-683-2300 x4941
lockwood at rand.org
http://www.rand.org/methodology/stat/members/lockwood/



From Simon.Wotherspoon at utas.edu.au  Fri Jan 24 02:00:03 2003
From: Simon.Wotherspoon at utas.edu.au (Simon Wotherspoon)
Date: Fri Jan 24 02:00:03 2003
Subject: [R] model.tables and NA?
Message-ID: <JPEJIEHCLCCMMBFGMPDGKECDCCAA.Simon.Wotherspoon@utas.edu.au>

Hi,
	This might be a minor bug, or it could be that I'm just mis-using the tools
(again).

If you modify the example for model.tables to introduce an NA,

 N <- c(0,1,0,1,1,1,0,0,0,1,1,0,1,1,0,0,1,0,1,0,1,1,0,0)
     P <- c(1,1,0,0,0,1,0,1,1,1,0,0,0,1,0,1,1,0,0,1,0,1,1,0)
     K <- c(1,0,0,1,0,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,1,0)
     yield <- c(49.5,62.8,46.8,57.0,59.8,58.5,55.5,56.0,62.8,55.8,69.5,
     55.0, 62.0,48.8,45.5,44.2,52.0,51.5,49.8,48.8,57.2,59.0,53.2,NA)    #
My change

     npk <- data.frame(block=gl(6,4), N=factor(N), P=factor(P),
                       K=factor(K), yield=yield)
     npk.aov <- aov(yield ~ block + N*P*K, npk)
     model.tables(npk.aov, "means", se=TRUE)


you get the error

>      model.tables(npk.aov, "means", se=TRUE)
Error in replications(paste("~", paste(names(tables), collapse = "+")),  :
        na.action must be a function

and I can't figure how to tell model.tables which na.action to use in a way
it likes.

Simon.
---



From upton at mitre.org  Fri Jan 24 02:52:15 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Fri Jan 24 02:52:15 2003
Subject: [R] subset dataframe based on rows
References: <Pine.LNX.4.33.0301231755560.28691-100000@penguin.rand.org>
Message-ID: <3E309B99.B79BD6A0@mitre.org>

Have you looked at subset?

For example,
> data(airquality)
> subset(airquality,Temp > 80 & Wind > 10 & Solar.R < 100)
    Ozone Solar.R Wind Temp Month Day
88     52      82 12.0   86     7  27
94      9      24 13.8   81     8   2
129    32      92 15.5   84     9   6

HTH
steve

"J.R. Lockwood" wrote:

> >
> > I want to subset the dataframe based on certain values in a row.
> >
> > for each row in my dataframe
> >       if ANY one value of a particular set of columns satisfies cond
> >               append a logical value true at the end of the row
> >       else
> >               append a false at the end of the row
> >
> > in the end I want to be able to subset the whole data based on the
> > appended true or false value.
> >
> > I could literally code like this, but I think there must be a better way
> > to do this. Can someone give me a hint?? thanks.
> >
> > Lei
> >
>
> I'm not sure what you mean by "better", but at the least you don't
> need to append the indicator column to your dataframe.  Just use
> whatever logical vector results from checking whether the columns
> satisfy the condition to subset your data frame, as in:
>
> d[meetsyourconditions,]
>
> As for determining whether the conditions are met, row by row, you
> should be able to this as a vector operation, but it could get ugly
> depending on the nature of the columns and what you call "cond".  In
> the most fortunate case where all the columns are of a single mode and
> cond is sufficiently simple, you can apply "function(x){any(x meets
> cond)}" to the rows of a matrix defined by your columns of interest.
> This will give you the logical vector you need to subset the
> dataframe.
>
> J.R. Lockwood
> 412-683-2300 x4941
> lockwood at rand.org
> http://www.rand.org/methodology/stat/members/lockwood/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From krcabrer at epm.net.co  Fri Jan 24 04:46:03 2003
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Fri Jan 24 04:46:03 2003
Subject: [R] ConTEXT .chl file for R?
References: <18D602BD42B7E24EB810D6454A58DB9001CAE040@ibfftce505.is.de.dresdnerkb.com>
Message-ID: <3E30B7CB.9060800@epm.net.co>

Hi R-Users

Does any body on the list have build a .chl file for R using the ConTEXT 
editor?
Thank you for your help

Kenneth



From s195404 at student.uq.edu.au  Fri Jan 24 05:19:03 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri Jan 24 05:19:03 2003
Subject: [R] ConTEXT .chl file for R?
In-Reply-To: <3E30B7CB.9060800@epm.net.co>
References: <18D602BD42B7E24EB810D6454A58DB9001CAE040@ibfftce505.is.de.dresdnerkb.com> <3E30B7CB.9060800@epm.net.co>
Message-ID: <1043381894.3e30be86b264f@my.uq.edu.au>

I created one of these a little while ago. If anyone would like it, email me 
separately and I will send it to you.

WinEdt is mentioned on CRAN (under Software/Other) and I believe is quite 
popular among users of R for Windows. It is shareware, however, whereas ConTEXT 
is freeware. I don't see much merit in paying for an editor when R itself is 
free. Others may say "Look what I bought with the money I saved on R" :-)


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting Kenneth Cabrera <krcabrer at epm.net.co>:

> Hi R-Users
> 
> Does any body on the list have build a .chl file for R using the ConTEXT 
> editor?
> Thank you for your help
> 
> Kenneth
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From mkazuki at ffpri.affrc.go.jp  Fri Jan 24 06:44:03 2003
From: mkazuki at ffpri.affrc.go.jp (Kazuki Miyamoto)
Date: Fri Jan 24 06:44:03 2003
Subject: [R] link function for gaussian family
Message-ID: <0H9700KK7EK443@mailer1.affrc.go.jp>

Dear All,

Is it possible to apply "log" link to gaussian family in glm?

Help file saids that the gaussian family has only one permissible link,
 "identity".  Similar descriptions are also in "Modern Applied Statistics with 
S-plus".  But the application of log link to gaussian family seems to be valid
in R.

Thanks for any help.

Sincerely,

Kazuki Miyamoto

*****************************************
Kazuki Miyamoto (Ph. D.)

Kansai Research Center, Forestry and Forest
Products Research Institute,
Nagaikyutaro 68, Momoyama, Kyoto 612-0855,
Japan

Tel: +81.75.611.1385
Fax: +81.75.611.1207
E-mail: mkazuki at ffpri.affrc.go.jp
*****************************************



From ripley at stats.ox.ac.uk  Fri Jan 24 08:51:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 24 08:51:03 2003
Subject: [R] model.tables and NA?
In-Reply-To: <JPEJIEHCLCCMMBFGMPDGKECDCCAA.Simon.Wotherspoon@utas.edu.au>
Message-ID: <Pine.LNX.4.44.0301240743390.3213-100000@gannet.stats>

It's not a bug.  It's a case that is not supported, as the error message 
says.  That's because model.tables.aov is intended only for balanced 
designs, and you have unbalanced that one.  (And look at what the help 
page says too.)

Try
npk.aov <- aov(yield ~ block + N*P*K, na.omit(npk))

and you will get an unbalance warning.

If you want to work out to to implement the unsupported cases, please take
a look at the R startup message, and join the contributors.

On Fri, 24 Jan 2003, Simon Wotherspoon wrote:

> Hi,
> 	This might be a minor bug, or it could be that I'm just mis-using the tools
> (again).
> 
> If you modify the example for model.tables to introduce an NA,
> 
>  N <- c(0,1,0,1,1,1,0,0,0,1,1,0,1,1,0,0,1,0,1,0,1,1,0,0)
>      P <- c(1,1,0,0,0,1,0,1,1,1,0,0,0,1,0,1,1,0,0,1,0,1,1,0)
>      K <- c(1,0,0,1,0,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,1,0)
>      yield <- c(49.5,62.8,46.8,57.0,59.8,58.5,55.5,56.0,62.8,55.8,69.5,
>      55.0, 62.0,48.8,45.5,44.2,52.0,51.5,49.8,48.8,57.2,59.0,53.2,NA)    #
> My change
> 
>      npk <- data.frame(block=gl(6,4), N=factor(N), P=factor(P),
>                        K=factor(K), yield=yield)
>      npk.aov <- aov(yield ~ block + N*P*K, npk)
>      model.tables(npk.aov, "means", se=TRUE)
> 
> 
> you get the error
> 
> >      model.tables(npk.aov, "means", se=TRUE)
> Error in replications(paste("~", paste(names(tables), collapse = "+")),  :
>         na.action must be a function
> 
> and I can't figure how to tell model.tables which na.action to use in a way
> it likes.
> 
> Simon.
> ---
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan 24 09:08:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 24 09:08:02 2003
Subject: [R] link function for gaussian family
In-Reply-To: <0H9700KK7EK443@mailer1.affrc.go.jp>
Message-ID: <Pine.LNX.4.44.0301240753060.3213-100000@gannet.stats>

On Fri, 24 Jan 2003, Kazuki Miyamoto wrote:

> Dear All,
> 
> Is it possible to apply "log" link to gaussian family in glm?
> 
> Help file saids that the gaussian family has only one permissible link,
>  "identity".  Similar descriptions are also in "Modern Applied Statistics with 
> S-plus". 

Well, no choice of link is allowed in S-PLUS (sic), the subject of the 
book you mention.

The R help file for gaussian() is wrong, and I will correct it. "inverse", 
"log" and "identity" links are allowed in the R code.  This has been so 
since the current  CVS file started in March 1998.

> But the application of log link to gaussian family seems to be valid
> in R.

Note that it is quite possible for no MLE to exist in that case, so use 
with care: the symptom will be convergence problems, but they can occur 
even if there is a valid solution.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Friedrich.Leisch at univie.ac.at  Fri Jan 24 10:44:02 2003
From: Friedrich.Leisch at univie.ac.at (Friedrich.Leisch@univie.ac.at)
Date: Fri Jan 24 10:44:02 2003
Subject: [R] ConTEXT .chl file for R?
In-Reply-To: <1043381894.3e30be86b264f@my.uq.edu.au>
References: <18D602BD42B7E24EB810D6454A58DB9001CAE040@ibfftce505.is.de.dresdnerkb.com>
	<3E30B7CB.9060800@epm.net.co>
	<1043381894.3e30be86b264f@my.uq.edu.au>
Message-ID: <15921.2730.697266.706493@ci.tuwien.ac.at>

>>>>> On Fri, 24 Jan 2003 04:18:14 +0000,
>>>>> Andrew C Ward (ACW) wrote:

  > I created one of these a little while ago. If anyone would like it, email me 
  > separately and I will send it to you.

  > WinEdt is mentioned on CRAN (under Software/Other) and I believe is quite 
  > popular among users of R for Windows. It is shareware, however, whereas ConTEXT 
  > is freeware. I don't see much merit in paying for an editor when R itself is 
  > free. Others may say "Look what I bought with the money I saved on R" :-)


CRAN carries whatever users submit to it ... the fact that there is a
WinEdt configuration file on CRAN is not because it is "the officially
recommended editor" for R, but because Uwe Ligges submitted his code
to CRAN and actively maintains it.
 
So if you think ConTEXT is a nice and free editor for writing R code on
windows and have already written corresponding configuration maybe you
want to share it with the rest of us? 

I personally use Emacs on Linux ... but would have use for a free and
easy-to-use windows editor for teaching (emacs is free, but not easy
to use).


Best,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik & DSS                Tel: (+43 1) 4277 38613
Universit?t Wien  		            Fax: (+43 1) 4277 38639
Universit?tsstra?e 5                  Friedrich.Leisch at univie.ac.at
A-1010 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------



From ernesto at ipimar.pt  Fri Jan 24 13:00:04 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Fri Jan 24 13:00:04 2003
Subject: [R] memory problems
Message-ID: <1043409690.3184.17.camel@gandalf.ipimar.pt>

Hi

I'm computing a bca interval using bca.ci from the boot package.

When I try to use this I get an error 


> library(boot)
> boot(logglm.data,boot.fishpower,2500,coef.vec=coeflm.vec)->blm8901
> bca.ci(blm8901,index=29)
Error: cannot allocate vector of size 456729 Kb

However my machine has 2GB of memory and without R running I only have
112M of memory used.

Is there something I can do to be able to perform this analysis ? (I can
not by more memory ;-)

Thanks

EJ

-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
IPIMAR - National Research Institute for Agriculture and Fisheries
Av. Brasilia, 1400-006
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948
http://ernesto.freezope.org



From L.E.Gross at maths.hull.ac.uk  Fri Jan 24 13:23:02 2003
From: L.E.Gross at maths.hull.ac.uk (L.E.Gross)
Date: Fri Jan 24 13:23:02 2003
Subject: [R] Multinomial Logit Models
Message-ID: <EXECMAIL.1030124121936.A@muahost.ucc.hull.ac.uk>

Hi

I am wanting to fit some multinomial logit models (multinom command in
package nnet)

Is it possible to do any model checking techniques on these models 
e.g. residual, leverage etc. I cannot seem to find any commands that 
will allow me to do this.

Many thanks


---------------------- 
L.E.Gross
L.E.Gross at maths.hull.ac.uk



From ernesto at ipimar.pt  Fri Jan 24 13:50:03 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Fri Jan 24 13:50:03 2003
Subject: [R] memory problems
In-Reply-To: <01C2C3F7.1440E190.andreww@cheque.uq.edu.au>
References: <01C2C3F7.1440E190.andreww@cheque.uq.edu.au>
Message-ID: <1043412683.3181.22.camel@gandalf.ipimar.pt>

Hi

I'm using SuSE 8.0 and R 1.6.2. The mem.limits are nt set so it should
go to the maximum the machine allows.

My doubt is that I have 2GB and R is complainig about allocating less
then 500MB.

Regards

EJ

On Fri, 2003-01-24 at 22:22, Andrew C. Ward wrote:
> Ernesto,
> 
> I can't tell what version of R you're using and for which platform.
> In any case, there are some start-up options relating to memory
> usage, and you will find discussions of these in the relevant
> FAQ. Under Windows, the amount of memory that R uses is set by the
> command-line flag "--max-mem-size".
> 
> An alternative is to perform your analysis on just a few random
> subsets of data and then aggregate the results. I don't know how
> big your data set actually is so it's hard to provide more
> specific guidance.
> 
> Post again if you're still having trouble.
> 
> 
> 
> Regards,
> 
> Andrew C. Ward
> 
> CAPE Centre
> Department of Chemical Engineering
> The University of Queensland
> Brisbane Qld 4072 Australia
> andreww at cheque.uq.edu.au
> 
> 
> 
> On Friday, January 24, 2003 10:02 PM, Ernesto Jardim [SMTP:ernesto at ipimar.pt] wrote:
> > Hi
> > 
> > I'm computing a bca interval using bca.ci from the boot package.
> > 
> > When I try to use this I get an error 
> > 
> > 
> > > library(boot)
> > > boot(logglm.data,boot.fishpower,2500,coef.vec=coeflm.vec)->blm8901
> > > bca.ci(blm8901,index=29)
> > Error: cannot allocate vector of size 456729 Kb
> > 
> > However my machine has 2GB of memory and without R running I only have
> > 112M of memory used.
> > 
> > Is there something I can do to be able to perform this analysis ? (I can
> > not by more memory ;-)
> > 
> > Thanks
> > 
> > EJ
> > 
> > -- 
> > Ernesto Jardim <ernesto at ipimar.pt>
> > Marine Biologist
> > IPIMAR - National Research Institute for Agriculture and Fisheries
> > Av. Brasilia, 1400-006
> > Lisboa, Portugal
> > Tel: +351 213 027 000
> > Fax: +351 213 015 948
> > http://ernesto.freezope.org
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
Research Institute for Agriculture and Fisheries
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948



From ripley at stats.ox.ac.uk  Fri Jan 24 14:01:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 24 14:01:03 2003
Subject: [R] Multinomial Logit Models
In-Reply-To: <EXECMAIL.1030124121936.A@muahost.ucc.hull.ac.uk>
Message-ID: <Pine.LNX.4.44.0301241256030.12565-100000@gannet.stats>

On Fri, 24 Jan 2003, L.E.Gross wrote:

> I am wanting to fit some multinomial logit models (multinom command in
> package nnet)
> 
> Is it possible to do any model checking techniques on these models 
> e.g. residual, leverage etc. I cannot seem to find any commands that 
> will allow me to do this.

residuals() should work: it does for me.

Leverage is not AFAIK well-defined: remember you have a multivariate
response, and for binomial logit models `leverage' is in the linear
approximation to the glm.  A multinomial logit model is not a glm, and
there is no such linear approximation in use.  Also, I have doubts about
the usefulness of leverage even for binomial logit models: it's a local
approximation when the only possible changes (0 <--> 1) are not local.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan 24 14:07:07 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 24 14:07:07 2003
Subject: [R] memory problems
In-Reply-To: <1043409690.3184.17.camel@gandalf.ipimar.pt>
Message-ID: <Pine.LNX.4.44.0301241300570.12565-100000@gannet.stats>

On 24 Jan 2003, Ernesto Jardim wrote:

> Hi
> 
> I'm computing a bca interval using bca.ci from the boot package.
> 
> When I try to use this I get an error 
> 
> 
> > library(boot)
> > boot(logglm.data,boot.fishpower,2500,coef.vec=coeflm.vec)->blm8901
> > bca.ci(blm8901,index=29)
> Error: cannot allocate vector of size 456729 Kb
> 
> However my machine has 2GB of memory and without R running I only have
> 112M of memory used.

How much memory is it actually using?  It is complaining about allocating
an *additional* 450Mb.  Look at top / Task Manager / whatever.

> Is there something I can do to be able to perform this analysis ? (I can
> not by more memory ;-)

Why are you returning so many results (apparently) when you only want one 
index?  Try returning just one?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at yifan.net  Fri Jan 24 14:32:06 2003
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Fri Jan 24 14:32:06 2003
Subject: [R] Problems for 13 year old
Message-ID: <3e313d94.318a.0@yifan.net>

      
I would like to teach some scientific/statistical computing to my 13 
year old nephew and was considering using R for this.  He has a Mac G3 
OS 9.1.

I am looking for ideas for problems that would be interesting and 
motivating for someone that age.  I recently taught him the basics of 
HTML and noticed that he particularly was intrigued by the ability to 
change colors; thus, perhaps problems that involve flashy color plots 
would keep his attention.

Thanks for any ideas.



-----------------------------------------------------
http://eo.yifan.net
Free POP3/Web Email, File Manager, Calendar and Address Book



From krcabrer at perseus.unalmed.edu.co  Fri Jan 24 14:40:03 2003
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Fri Jan 24 14:40:03 2003
Subject: [R] =?ISO-8859-1?Q?What=B4s_wrong_with_update=2Epackages=28=29?=
References: <01C2C3F7.1440E190.andreww@cheque.uq.edu.au> <1043412683.3181.22.camel@gandalf.ipimar.pt>
Message-ID: <3E314D02.6030606@perseus.unalmed.edu.co>

Hi R users:
I'm using R 1.6.2 version in W2K platform.
When I use update.packages() to update from the CRAN site it shows me
several outdated packages, for example

tseries :
 Version 0.9-6 in C:/rw1062/library
 Version 0.9-7 on CRAN

The system download them without any problem.

When the program ask me:

Delete downloaded files (y/N)?

I answer "n"

But when I use again the same update.packages() function, it appears the
same packages that it was supposed to be updated, with the same messages.

Or if I call a package, for example 'tseries' it appears:

        `tseries' version: 0.9-6
 
        `tseries' is a package for time series analysis
         and computational finance.
         See `library (help=tseries)' for details.

The old package version, not the 0.9-7 new version.

What am I doing wrong?

Thank you for your help

Kenneth Cabrera



From p.dalgaard at biostat.ku.dk  Fri Jan 24 14:49:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 24 14:49:02 2003
Subject: [R] memory problems
In-Reply-To: <Pine.LNX.4.44.0301241300570.12565-100000@gannet.stats>
References: <Pine.LNX.4.44.0301241300570.12565-100000@gannet.stats>
Message-ID: <x21y328xq5.fsf@biostat.ku.dk>

ripley at stats.ox.ac.uk writes:

> > However my machine has 2GB of memory and without R running I only have
> > 112M of memory used.
> 
> How much memory is it actually using?  It is complaining about allocating
> an *additional* 450Mb.  Look at top / Task Manager / whatever.

It's not the first time we're seeing that type of question. I wonder
if we could make the error message more informative. Not that it is
going to make the problem go away, but it could help put the user in
the picture. It's a bit tricky, because there are limits to what you
can make the system do in an out of memory condition. One idea might
be to keep tabs on the total amount of memory allocated and freed.
However, there are issues of counter overruns to deal with, and you'd
still have to explain to people that not all free memory is available
for allocation; you really only need to allocate a handful of *bytes*
sufficiently unfortunately spaced to make it impossible to find a
450MB contiguous block in a 2GB address space.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Ted_Henscheid at jabil.com  Fri Jan 24 14:55:07 2003
From: Ted_Henscheid at jabil.com (Ted Henscheid)
Date: Fri Jan 24 14:55:07 2003
Subject: [R] Recall:
Message-ID: <6EF1671975A4D347941B1B323D9F75CDFAAF27@tismsgn10a.tis.ceu.jabil.com>

Ted Henscheid would like to recall the message, "".



From ligges at statistik.uni-dortmund.de  Fri Jan 24 15:06:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Jan 24 15:06:03 2003
Subject: [R] =?ISO-8859-1?Q?What=B4s_wrong_with_update=2Epackag?=
 =?ISO-8859-1?Q?es=28=29?=
In-Reply-To: <3E314D02.6030606@perseus.unalmed.edu.co>
References: <01C2C3F7.1440E190.andreww@cheque.uq.edu.au> <1043412683.3181.22.camel@gandalf.ipimar.pt> <3E314D02.6030606@perseus.unalmed.edu.co>
Message-ID: <3E31459F.7080403@statistik.uni-dortmund.de>

Kenneth Cabrera wrote:
> Hi R users:
> I'm using R 1.6.2 version in W2K platform.
> When I use update.packages() to update from the CRAN site it shows me
> several outdated packages, for example
> 
> tseries :
> Version 0.9-6 in C:/rw1062/library
> Version 0.9-7 on CRAN
> 
> The system download them without any problem.
> 
> When the program ask me:
> 
> Delete downloaded files (y/N)?
> 
> I answer "n"
> 
> But when I use again the same update.packages() function, it appears the
> same packages that it was supposed to be updated, with the same messages.
> 
> Or if I call a package, for example 'tseries' it appears:
> 
>        `tseries' version: 0.9-6
> 
>        `tseries' is a package for time series analysis
>         and computational finance.
>         See `library (help=tseries)' for details.
> 
> The old package version, not the 0.9-7 new version.
> 
> What am I doing wrong?
> 
> Thank you for your help
> 
> Kenneth Cabrera
> 

Works for me. See the "R for Windows FAQ" 3.8 for details.

Uwe Ligges



From fharrell at virginia.edu  Fri Jan 24 15:12:12 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri Jan 24 15:12:12 2003
Subject: [R] Problems for 13 year old
In-Reply-To: <3e313d94.318a.0@yifan.net>
References: <3e313d94.318a.0@yifan.net>
Message-ID: <20030124085718.54322a5d.fharrell@virginia.edu>

On Fri, 24 Jan 2003 08:20:20 -0500
ggrothendieck at yifan.net wrote:

>       
> I would like to teach some scientific/statistical computing to my 13 
> year old nephew and was considering using R for this.  He has a Mac G3 
> OS 9.1.
> 
> I am looking for ideas for problems that would be interesting and 
> motivating for someone that age.  I recently taught him the basics of 
> HTML and noticed that he particularly was intrigued by the ability to 
> change colors; thus, perhaps problems that involve flashy color plots 
> would keep his attention.
> 
> Thanks for any ideas.
> 
> 
> 
> -----------------------------------------------------
> http://eo.yifan.net
> Free POP3/Web Email, File Manager, Calendar and Address Book

I applaud this effort, and am beginning to teach R to my 13 and 10 year olds.  One thing that really grabs their interest is learning commands such as

   rep('Dad is a task master', 5000)

and paste(c('Joe','Sally','Roger'),'is not playing with a full deck.')

Please post a summary of responses to your note.  I am also considering having my kids go through the book "Computer Programming for Dummies" 2nd edition by Wallace Wang (New York: Hungry Minds, Inc, 2001) which looks pretty good.  It mainly teaches using a free version of Basic but introduces many other languages including Java and has a lot of good background information about computers and what programming entails.

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From ripley at stats.ox.ac.uk  Fri Jan 24 15:17:52 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 24 15:17:52 2003
Subject: [R] =?ISO-8859-1?Q?What=B4s_wrong_with_update=2Epackages=28=29?=
In-Reply-To: <3E314D02.6030606@perseus.unalmed.edu.co>
Message-ID: <Pine.LNX.4.44.0301241356000.12631-100000@gannet.stats>

Please take a look at library/tseries/DESCRIPTION and see what version it 
says.  My guess is that it says 0.9-6.

My guess is that you got a cached copy of the tseries.zip file.
Please try again, perhaps using another CRAN mirror, or get the file 
yourself via ftp.


On Fri, 24 Jan 2003, Kenneth Cabrera wrote:

> Hi R users:
> I'm using R 1.6.2 version in W2K platform.
> When I use update.packages() to update from the CRAN site it shows me
> several outdated packages, for example
> 
> tseries :
>  Version 0.9-6 in C:/rw1062/library
>  Version 0.9-7 on CRAN
> 
> The system download them without any problem.
> 
> When the program ask me:
> 
> Delete downloaded files (y/N)?
> 
> I answer "n"
> 
> But when I use again the same update.packages() function, it appears the
> same packages that it was supposed to be updated, with the same messages.
> 
> Or if I call a package, for example 'tseries' it appears:
> 
>         `tseries' version: 0.9-6
>  
>         `tseries' is a package for time series analysis
>          and computational finance.
>          See `library (help=tseries)' for details.
> 
> The old package version, not the 0.9-7 new version.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Fri Jan 24 15:39:02 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Jan 24 15:39:02 2003
Subject: [R] Problems for 13 year old
In-Reply-To: <20030124085718.54322a5d.fharrell@virginia.edu>
References: <3e313d94.318a.0@yifan.net>
	<20030124085718.54322a5d.fharrell@virginia.edu>
Message-ID: <6rn0lqd34z.fsf@bates4.stat.wisc.edu>

Frank E Harrell Jr <fharrell at virginia.edu> writes:

> On Fri, 24 Jan 2003 08:20:20 -0500
> ggrothendieck at yifan.net wrote:
> 
> >       
> > I would like to teach some scientific/statistical computing to my 13 
> > year old nephew and was considering using R for this.  He has a Mac G3 
> > OS 9.1.
> > 
> > I am looking for ideas for problems that would be interesting and 
> > motivating for someone that age.  I recently taught him the basics of 
> > HTML and noticed that he particularly was intrigued by the ability to 
> > change colors; thus, perhaps problems that involve flashy color plots 
> > would keep his attention.
> > 
> > Thanks for any ideas.
> > 
> > 
> > 
> > -----------------------------------------------------
> > http://eo.yifan.net
> > Free POP3/Web Email, File Manager, Calendar and Address Book
> 
> I applaud this effort, and am beginning to teach R to my 13 and 10 year olds.  One thing that really grabs their interest is learning commands such as
> 
>    rep('Dad is a task master', 5000)
> 
> and paste(c('Joe','Sally','Roger'),'is not playing with a full deck.')

There was an article in Thursday's New York Times about New York
revising its Math and Reading courses.  The article gave an example of
a data analysis problem from the textbook "Everyday Mathematics" by
SRA/McGraw-Hill.  This text will be adopted by all New York elementary
schools.  It may be sources of other such problems.

There was some discussion on python news groups of an introductory
programming course based on python, which is similar in structure to
the S language.  (Note I said "similar" - no flames please.)  That may
also be a source of examples.



From krcabrer at perseus.unalmed.edu.co  Fri Jan 24 15:52:05 2003
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Fri Jan 24 15:52:05 2003
Subject: [R] =?ISO-8859-1?Q?What=B4s_wrong_with_update=2Epackag?=
 =?ISO-8859-1?Q?es=28=29?=
References: <Pine.LNX.4.44.0301241356000.12631-100000@gannet.stats>
Message-ID: <3E3161AA.8030901@perseus.unalmed.edu.co>

Dear Dr. Ripley:

ripley at stats.ox.ac.uk wrote:

>Please take a look at library/tseries/DESCRIPTION and see what version it 
>says.  My guess is that it says 0.9-6.
>
Your are right!

>My guess is that you got a cached copy of the tseries.zip file.
>Please try again, perhaps using another CRAN mirror, or get the file 
>yourself via ftp.
>
I will do that!
Where the file is cached, in the proxy server, maybe?

Thank you again

>On Fri, 24 Jan 2003, Kenneth Cabrera wrote:
>
>>Hi R users:
>>I'm using R 1.6.2 version in W2K platform.
>>When I use update.packages() to update from the CRAN site it shows me
>>several outdated packages, for example
>>
>>tseries :
>> Version 0.9-6 in C:/rw1062/library
>> Version 0.9-7 on CRAN
>>
>>The system download them without any problem.
>>
>>When the program ask me:
>>
>>Delete downloaded files (y/N)?
>>
>>I answer "n"
>>
>>But when I use again the same update.packages() function, it appears the
>>same packages that it was supposed to be updated, with the same messages.
>>
>>Or if I call a package, for example 'tseries' it appears:
>>
>>        `tseries' version: 0.9-6
>> 
>>        `tseries' is a package for time series analysis
>>         and computational finance.
>>         See `library (help=tseries)' for details.
>>
>>The old package version, not the 0.9-7 new version
>>    
>>



From ripley at stats.ox.ac.uk  Fri Jan 24 16:00:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 24 16:00:03 2003
Subject: [R] =?ISO-8859-1?Q?What=B4s_wrong_with_update=2Epackag?=
 =?ISO-8859-1?Q?es=28=29?=
In-Reply-To: <3E3161AA.8030901@perseus.unalmed.edu.co>
Message-ID: <Pine.LNX.4.44.0301241457100.12706-100000@gannet.stats>

On Fri, 24 Jan 2003, Kenneth Cabrera wrote:

> Dear Dr. Ripley:
> 
> ripley at stats.ox.ac.uk wrote:
> 
> >Please take a look at library/tseries/DESCRIPTION and see what version it 
> >says.  My guess is that it says 0.9-6.
> >
> Your are right!
> 
> >My guess is that you got a cached copy of the tseries.zip file.
> >Please try again, perhaps using another CRAN mirror, or get the file 
> >yourself via ftp.
> >
> I will do that!
> Where the file is cached, in the proxy server, maybe?

Yes, in some proxy en route.  There are three layers of caches between me 
and CRAN, and I do find this happens quite often.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pavel at koulikov.com  Fri Jan 24 16:44:05 2003
From: pavel at koulikov.com (pavel koulikov)
Date: Fri Jan 24 16:44:05 2003
Subject: [R] A stepfun question
Message-ID: <200301241041.AA9109546@koulikov.com>

Hi
I have a sample of data  and I need to generate Empirical distribution plot. That's easy 

u=c(1,2,2,3,4,2,1,3,4,5,6,2)
h=ecdf(u)
plot(h,verticals=TRUE,lwd=2)

But i need P axis to be X. (horizontal) instead of Y as it is by default....So basically I need to flip the graph..
Please help



From smalladi at lexgen.com  Fri Jan 24 17:33:03 2003
From: smalladi at lexgen.com (Malladi, Sukhaswami)
Date: Fri Jan 24 17:33:03 2003
Subject: [R] RMySQL performance over RODBC
Message-ID: <80A38867B1DBD511A8C9009027764C8C379B75@lexchange.lexgen.com>

R-help list,

I ported some R code from MS Windows PC to sun-solaris. Both do queries on
the same 
MySQL database.

PC version of R is 1.6.1 and solaris version is 1.6.0. I use RMySQL_0.5-0
(on solaris)
and RODBC 1.0-1 on PC to connect to MySQL. The PC version took about 65
mins. to run
wheras the Solaris (SunOS 5.7) version took 375 mins. (> 6 hrs). R and
RMySQL are 
resident on the same host (solaris) as the MySQL database.

Can experts on the list please throw some light as how to improve the
speed with which RMySQL queries can be processed ? 

RMySQL database access is done as follows:
-------------------------------------------
library(RMySQL) 				# 1
con <- dbConnect( ... )			# 2
...
rs <- dbSendQuery(con,qry)		# 3
rdat <- fetch(rs,n=10000)		# 4
...
dbDisconnect(con) 			# 5
-------------------------------------------

lines #3 and #4 are repeated about 10000 times in the script.

Thanks in advance for any help.
Sukhaswami Malladi


*************************************************************************** 
 The contents of this communication are intended only for the addressee and
may contain confidential and/or privileged material. If you are not the
intended recipient, please do not read, copy, use or disclose this
communication and notify the sender.  Opinions, conclusions and other
information in this communication that do not relate to the official
business of my company shall be understood as neither given nor endorsed by
it.  
***************************************************************************



From ripley at stats.ox.ac.uk  Fri Jan 24 17:44:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 24 17:44:02 2003
Subject: [R] RMySQL performance over RODBC
In-Reply-To: <80A38867B1DBD511A8C9009027764C8C379B75@lexchange.lexgen.com>
Message-ID: <Pine.LNX.4.44.0301241642150.12697-100000@gannet.stats>

Is there any reason why you did not test RMySQL on Windows or RODBC on 
Solaris: the latter seems an obvious test?

On Fri, 24 Jan 2003, Malladi, Sukhaswami wrote:

> R-help list,
> 
> I ported some R code from MS Windows PC to sun-solaris. Both do queries on
> the same 
> MySQL database.
> 
> PC version of R is 1.6.1 and solaris version is 1.6.0. I use RMySQL_0.5-0
> (on solaris)
> and RODBC 1.0-1 on PC to connect to MySQL. The PC version took about 65
> mins. to run
> wheras the Solaris (SunOS 5.7) version took 375 mins. (> 6 hrs). R and
> RMySQL are 
> resident on the same host (solaris) as the MySQL database.
> 
> Can experts on the list please throw some light as how to improve the
> speed with which RMySQL queries can be processed ? 
> 
> RMySQL database access is done as follows:
> -------------------------------------------
> library(RMySQL) 				# 1
> con <- dbConnect( ... )			# 2
> ...
> rs <- dbSendQuery(con,qry)		# 3
> rdat <- fetch(rs,n=10000)		# 4
> ...
> dbDisconnect(con) 			# 5
> -------------------------------------------
> 
> lines #3 and #4 are repeated about 10000 times in the script.
> 
> Thanks in advance for any help.
> Sukhaswami Malladi
> 
> 
> *************************************************************************** 
>  The contents of this communication are intended only for the addressee and
> may contain confidential and/or privileged material. If you are not the
> intended recipient, please do not read, copy, use or disclose this
> communication and notify the sender.  Opinions, conclusions and other
> information in this communication that do not relate to the official
> business of my company shall be understood as neither given nor endorsed by
> it.  
> ***************************************************************************
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wolfram at fischer-zim.ch  Fri Jan 24 18:37:03 2003
From: wolfram at fischer-zim.ch (Wolfram Fischer - Z/I/M)
Date: Fri Jan 24 18:37:03 2003
Subject: [R] problem with srt vector in xyplot {lattice}
Message-ID: <20030124175421.A3439@s1x.zimnet.ch>

[ R 1.6.1 ]

PROBLEM
    The plot of the appended code does produce 
    a postscript file which is not interpretable
    by gv under Linux.

REMARK
    If the srt argument is commented out or set to a constant
	like 45 or 90, the ps file becomes interpretable.

CODE
    xytest <- function( ... ){
        with( airquality, { print( xyplot(
              Ozone ~ Temp | Month
            , panel = function( x, y, subscripts, ... ){
                ltext( x, y, Temp[subscripts]
                    , srt = 45 / max( Solar.R, na.rm=T ) * Solar.R
                    )
                }
            , ...
            )
        )})
    }

    xytest()        ## works!

    trellis.device( 'postscript', file = 'x.ps' )
    xytest()
    dev.off()


QUESTION
    Is there a workaround?


Wolfram



From cstrato at aon.at  Fri Jan 24 18:53:06 2003
From: cstrato at aon.at (cstrato)
Date: Fri Jan 24 18:53:06 2003
Subject: [R] Read.table for macs
References: <3508EBC0-2E1B-11D7-9564-003065F42152@bham.ac.uk>
Message-ID: <3E317D30.4010809@aon.at>

I agree with you. For the same purpose I use Text-Edit Plus,
which is also free and in my opinion is the best all-purpose
text editor on any platform (but sorrowly not for programming).

Best regards
Christian Stratowa


Paul Pynsent wrote:

> I detect an anti Mac theme, I do not wish to attribute blame but suggest 
> that Excel does funny things when it dumps tab separated text files, 
> like adding unprintable characters and trailing spaces.
> My approach is to use BBedit (which is free) to:
> 1) zap gremlins
> 2) globally substitute \ \t for \t (ie remove trailing spaces which R 
> does not ignore).
> 3) convert DOS new lines to Mac new lines.
> Equally you could use awk etc. on a Mac to do this.  In general it is 
> not safe to do this cleaning operation on a DOS/Windows system as 
> conversions may still take place on transmission to an Apple.
> 
> On Wednesday, January 22, 2003, at 05:10  am, Hamish McCallum wrote:
> 
>> Dear All,
>>
>> I've been using R for windows for a while, without too many problems. 
>> However, I'm forced to use the MAC OS system for teaching, because our 
>> teaching labs are mac only (not my idea!!). I have a very basic 
>> problem, but one that doesn't appear on the FAQs. I simply want to 
>> import data from a spreadsheet. I'm using exactly what works fine on 
>> Windows, namely:
>>
>> 1    save the file from Excel as tab-delimited, say called "test.txt", 
>> with the variable names in the first row.
>> 2    Read in into R with
>> test<-read.table("test.txt", header=T)
>>
>> It does weird things, especially if any variables are characters. For 
>> example, it has omitted the 5th observation for the 1st variable, and 
>> then appended it to the first variable name. I've tried read.csv with 
>> csv files, read.delim, etc. None seem to work. Am I being really 
>> silly, and if so, how do you do it? Or is there an easier way to get 
>> data into the mac port? Or is the mac port entirely useless?
>>
>> Can anyone out there help?
>>
>> Thanks
>>
>> Hamish McCallum
>>
>> -- 
>> Dr Hamish McCallum
>> Department of Zoology and Entomology
>> The University of Queensland
>> Brisbane 4072
>> Australia
>> Phone (+617) 3365 2450 Fax (+617) 3365 1655
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
> Dr. P. B. Pynsent,
> Research and Teaching Centre,
> Royal Orthopaedic Hospital,
> Birmingham, B31 2AP, U.K.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From tfliao at essex.ac.uk  Fri Jan 24 20:03:03 2003
From: tfliao at essex.ac.uk (Liao T F)
Date: Fri Jan 24 20:03:03 2003
Subject: [R] multiple series conditioning plot
Message-ID: <Pine.OSF.4.03.10301241859300.17173-100000@seralph15.essex.ac.uk>

Hi!  How would you produce multiple lines for multiple Y data series in a
conditioning plot?  I know how to do this in S-2000 Windows but can't seem
to get it in R.

Many Thanks,

Tim



From RexBryan1 at attbi.com  Fri Jan 24 20:11:17 2003
From: RexBryan1 at attbi.com (Rex_Bryan@urscorp.com)
Date: Fri Jan 24 20:11:17 2003
Subject: [R] The other type of relative frequency for hist()
Message-ID: <013201c2c3dc$8b367aa0$3182fd0c@dell1700>

Hist() can plot histogram bars with a relative frequency scale.  However,
this relative frequency is scaled as a probability density, where the sum of
the bar heights times the bar widths will equal 1.  There is another way to
define relative frequency which is based on the proportion of the count in a
bin to the total count over all bins.  Is  there a way to scale the vertical
axis so as to show this other type?

Example:

v3<-c(0.03155,0.073,0.280,0.285,0.285,0.300,0.035,0.035,0.035,0.035,0.04025)
length(v3)
[1] 11

hist.dump<-hist(v3, freq=FALSE, plot=FALSE)

hist.dump$count
[1] 6 1 0 0 0 4

hist.dump$density
[1] 10.909078  1.818182  0.000000  0.000000  0.000000  7.272727

Now for this histogram 3 bins have bars with widths in this case that happen
to be 0.05 units wide.  If hist.dump$count is multiplied
by hist.dump$density for the first bin a value of 0.5455 is obtained.
This is of course simply the 6 observations in the first bin divided by 11.
Is there a simple way of representing this second type of relative frequency
in the y-axis?

REX



From deepayan at stat.wisc.edu  Fri Jan 24 20:24:05 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Jan 24 20:24:05 2003
Subject: [R] problem with srt vector in xyplot {lattice}
In-Reply-To: <20030124175421.A3439@s1x.zimnet.ch>
References: <20030124175421.A3439@s1x.zimnet.ch>
Message-ID: <200301241323.48194.deepayan@stat.wisc.edu>

On Friday 24 January 2003 10:54 am, Wolfram Fischer - Z/I/M wrote:
> [ R 1.6.1 ]
>
> PROBLEM
>     The plot of the appended code does produce
>     a postscript file which is not interpretable
>     by gv under Linux.

The srt vector has several NA's. x11() does not draw these, which may or may 
not be what you want. You should be able to reproduce that in postscript() 
with an additional subset = !is.na(Solar.R) argument to xyplot().

> REMARK
>     If the srt argument is commented out or set to a constant
> 	like 45 or 90, the ps file becomes interpretable.
>
> CODE
>     xytest <- function( ... ){
>         with( airquality, { print( xyplot(
>               Ozone ~ Temp | Month
>             , panel = function( x, y, subscripts, ... ){
>                 ltext( x, y, Temp[subscripts]
>                     , srt = 45 / max( Solar.R, na.rm=T ) * Solar.R

don't you mean Solar.R[susbscripts] ?

>                     )
>                 }
>             , ...
>             )
>         )})
>     }
>
>     xytest()        ## works!
>
>     trellis.device( 'postscript', file = 'x.ps' )
>     xytest()
>     dev.off()
>
>
> QUESTION
>     Is there a workaround?
>
>
> Wolfram
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From s.chamaille at wanadoo.fr  Fri Jan 24 21:13:03 2003
From: s.chamaille at wanadoo.fr (Simon CHAMAILLE)
Date: Fri Jan 24 21:13:03 2003
Subject: [R] (no subject)
Message-ID: <3E26DAA600530B73@mel-rta10.wanadoo.fr> (added by postmaster@wanadoo.fr)

Dear All
I just want to know if it is easily possible to compute AICc calculation for multiple regression models under R ?
Thanks a lot,
simon chamaill?



From rggefrm at ucl.ac.uk  Fri Jan 24 21:52:03 2003
From: rggefrm at ucl.ac.uk (Frank Mattes)
Date: Fri Jan 24 21:52:03 2003
Subject: [R] different plot symbols according to a factor
Message-ID: <5.2.0.9.0.20030124204315.00a72e90@pop-server.ucl.ac.uk>

Dear R list subscriber,

I'm hoppiing my question didn't come up so far. I try to do somthing simple

  a<-c(1,4,5,2,7,34,56,78,76,54)
b=c(a<-c(1,4,5,2,7,34,56,78,76,54)
c<-c(0,0,0,0,0,1,1,1,1,1)

I would like to get a scatter diagram with different plot symbol for 0 and 
1 in c
I tried

plot(a,b, pch=c(1,2)[c])

which didn't work.

I appreciate if someone from the list could direct me in the right direction

Yours
Frank

Frank Mattes, MD
Department of Virology
Royal Free and University Medical School
London



From deepayan at stat.wisc.edu  Fri Jan 24 21:59:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Jan 24 21:59:03 2003
Subject: [R] different plot symbols according to a factor
In-Reply-To: <5.2.0.9.0.20030124204315.00a72e90@pop-server.ucl.ac.uk>
References: <5.2.0.9.0.20030124204315.00a72e90@pop-server.ucl.ac.uk>
Message-ID: <200301241458.38757.deepayan@stat.wisc.edu>

On Friday 24 January 2003 02:50 pm, Frank Mattes wrote:
> Dear R list subscriber,
>
> I'm hoppiing my question didn't come up so far. I try to do somthing simple
>
>   a<-c(1,4,5,2,7,34,56,78,76,54)
> b=c(a<-c(1,4,5,2,7,34,56,78,76,54)

???

> c<-c(0,0,0,0,0,1,1,1,1,1)
>
> I would like to get a scatter diagram with different plot symbol for 0 and
> 1 in c
> I tried
>
> plot(a,b, pch=c(1,2)[c])

R indexing starts from 1. So, try 

plot(a,b, pch=c(1,2)[c+1])

>
> which didn't work.
>
> I appreciate if someone from the list could direct me in the right
> direction
>
> Yours
> Frank
>
> Frank Mattes, MD
> Department of Virology
> Royal Free and University Medical School
> London
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jmarca at translab.its.uci.edu  Sat Jan 25 00:04:15 2003
From: jmarca at translab.its.uci.edu (James Marca)
Date: Sat Jan 25 00:04:15 2003
Subject: [R] Problems for 13 year old
In-Reply-To: <3e313d94.318a.0@yifan.net>; from ggrothendieck@yifan.net on Fri, Jan 24, 2003 at 08:20:20AM -0500
References: <3e313d94.318a.0@yifan.net>
Message-ID: <20030124150314.I14123@krypton.its.uci.edu>

At that age, I recall trying to program a spaceship fighting game in
basic on the apple ][e (hopeless spaghetti that never ran, aside from
the "hyperspace" effect at the start), and later getting very involved
in programming robots in the game Robot War, which had a maximum
number of instructions and a limited command set, which required
programming in the pseudo assembly language to really milk the most
out of your code.

In short, I enjoyed programming games and moving pixels around.  

As to scientific computing, in a similar vein I can see a teenager
becoming interested in generating fractal images, getting chaotic
behavior from a simple iterated function, or simply plotting 3-d
surfaces of sines and cosines.  These all fall under "changing colored
bits on the screen as a result of some programmatic command."  Some of
the clustering code is also pretty cool, I recall toying with the EM
code and being pretty impressed by its ability to pick out similar
pieces in noisy data.  The inverse of clustering is of course,
generating noisy data, so that could become a game of sorts---try to
stump the clustering code by generating data from more than one
distribution.

I use a GPS a lot with my work, and put that data into R for
analysis.  Perhaps a handheld GPS unit can do the same thing, thus
offering a source of data collection to dump into R for plotting and
analysis.  If of course you have a gps unit.

James
At approximately Fri, Jan 24, 2003 at 08:20:20AM -0500, ggrothendieck at yifan.net wrote:
>       
> I would like to teach some scientific/statistical computing to my 13 
> year old nephew and was considering using R for this.  He has a Mac G3 
> OS 9.1.
> 
> I am looking for ideas for problems that would be interesting and 
> motivating for someone that age.  I recently taught him the basics of 
> HTML and noticed that he particularly was intrigued by the ability to 
> change colors; thus, perhaps problems that involve flashy color plots 
> would keep his attention.
> 
> Thanks for any ideas.
>



From chunlou at yahoo.com  Sat Jan 25 02:06:02 2003
From: chunlou at yahoo.com (Chunlou Yung)
Date: Sat Jan 25 02:06:02 2003
Subject: [R] Problems for 13 year old
In-Reply-To: <20030124150314.I14123@krypton.its.uci.edu>
Message-ID: <NCBBKDNFIKJKKCFELNNMIEKODDAA.chunlou@yahoo.com>

Since we're on Programming For Kids, it's worth checking out StarLogo

http://education.mit.edu/starlogo/

It's a Java-implementation of Logo, geared more towards simulation/modeling
than traditional turtle graph. Intended for kids, 13 and up. Comes with
various projects such as SimCity-like simulation. Interactive.




> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch
> [mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of James Marca
> Sent: Friday, January 24, 2003 06:03 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Problems for 13 year old
>
>
> At that age, I recall trying to program a spaceship fighting game in
> basic on the apple ][e (hopeless spaghetti that never ran, aside from
> the "hyperspace" effect at the start), and later getting very involved
> in programming robots in the game Robot War, which had a maximum
> number of instructions and a limited command set, which required
> programming in the pseudo assembly language to really milk the most
> out of your code.
>
> In short, I enjoyed programming games and moving pixels around.
>
> As to scientific computing, in a similar vein I can see a teenager
> becoming interested in generating fractal images, getting chaotic
> behavior from a simple iterated function, or simply plotting 3-d
> surfaces of sines and cosines.  These all fall under "changing colored
> bits on the screen as a result of some programmatic command."  Some of
> the clustering code is also pretty cool, I recall toying with the EM
> code and being pretty impressed by its ability to pick out similar
> pieces in noisy data.  The inverse of clustering is of course,
> generating noisy data, so that could become a game of sorts---try to
> stump the clustering code by generating data from more than one
> distribution.
>
> I use a GPS a lot with my work, and put that data into R for
> analysis.  Perhaps a handheld GPS unit can do the same thing, thus
> offering a source of data collection to dump into R for plotting and
> analysis.  If of course you have a gps unit.
>
> James
> At approximately Fri, Jan 24, 2003 at 08:20:20AM -0500,
> ggrothendieck at yifan.net wrote:
> >
> > I would like to teach some scientific/statistical computing to my 13
> > year old nephew and was considering using R for this.  He has a Mac G3
> > OS 9.1.
> >
> > I am looking for ideas for problems that would be interesting and
> > motivating for someone that age.  I recently taught him the basics of
> > HTML and noticed that he particularly was intrigued by the ability to
> > change colors; thus, perhaps problems that involve flashy color plots
> > would keep his attention.
> >
> > Thanks for any ideas.
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Burkhard.Kloss at kbcfp.com  Sat Jan 25 04:18:03 2003
From: Burkhard.Kloss at kbcfp.com (Kloss, Burkhard)
Date: Sat Jan 25 04:18:03 2003
Subject: [R] Problems for 13 year old
Message-ID: <7C92FFD84C6DA94C8A8693EC976B8DFB955507@msln2.london.kbcfp.com>

>There was some discussion on python news groups of an introductory
>programming course based on python, which is similar in structure to
>the S language.  (Note I said "similar" - no flames please.)  That may
>also be a source of examples.

Computer Programming for everyone:  http://www.mlab.uiah.fi/~eye/python/

While I think R is a wonderful tool, it may be a bit too specialised for a 13 year old, unless he has a serious mathematical bent.  I'd also recommend Python (both for introducing people to programming and in general), but for quickly getting results with graphics, Logo is unbeatable.

	Burkhard Kloss



From baron at cattell.psych.upenn.edu  Sat Jan 25 04:32:03 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sat Jan 25 04:32:03 2003
Subject: [R] Problems for 13 year old
In-Reply-To: <7C92FFD84C6DA94C8A8693EC976B8DFB955507@msln2.london.kbcfp.com>; from Burkhard.Kloss@kbcfp.com on Sat, Jan 25, 2003 at 03:17:17AM -0000
References: <7C92FFD84C6DA94C8A8693EC976B8DFB955507@msln2.london.kbcfp.com>
Message-ID: <20030124223050.A19797@cattell.psych.upenn.edu>

OK, I lost the original post.  Sorry.  But here is my 2 cents.
One approach to getting a 13-year-old (or 31-year-old) interested
in R is to get him going on what R is good at, data analysis,
with and without graphics.

The data could come from whatever is already of interest, whether
it is weather, sports, movies, or politics. There are interesting
questions all over the place.  And data are easier and easier to
get from the web.

For example, at the time of the U.S. Presidential Election of
2000, people went wild analyzing data from Palm Beach County and
other Florida counties.  Some were real statisticians, and came
to real conclusions, but some where amatuers.
(See the top of http://www.sas.upenn.edu/~baron/policy.html
for a few links, mostly outdated.)

As a tennis fan, I'd love to see someone figure out a better way
to do the rankings than the system now used.  (You can make
progress on this without getting into the full depth of the
problem.)

Now you can't just sit someone down and say "go to it."  You do
have to get him started on it, but, somehow, not do it all
yourself.  That's the trick.

--
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From mohamed at engr.uconn.edu  Sat Jan 25 04:38:03 2003
From: mohamed at engr.uconn.edu (Mohamed A. Kerasha)
Date: Sat Jan 25 04:38:03 2003
Subject: [R] Distributions
Message-ID: <HMEIKDIPDPFALCIDOILHMEFMCAAA.mohamed@engr.uconn.edu>

Hi!
I have a couple of questions:
1) How would you produce Hyper Erlang Distribution in R.
2) How to generate cyclic arrivals in R. For example, arrival patterns that
correlates with time of the day.
I really appreciate your help,

-Mohamed.



From lm.silva at sapo.pt  Sat Jan 25 16:11:39 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Sat Jan 25 16:11:39 2003
Subject: [R] plot/screen
Message-ID: <1043486668.3e3257ccabd28@webmail.sapo.pt>

Dear helpers

I have this code to make 10 plots in the same device

a<-1
split.screen(c(2:5))
for (i in 1:10){
nova.matriz<-a*sigma+(1-a)*S
proj<-calculo.comp(treino,nova.matriz)
print(proj[,1:2])
screen(i)
plot(Re(proj[c(2,3,6,9:11,14,23),1:2]),xlim=range(c(-
15:15)),ylim=range(c(-5:5)),col="black")
points(Re(proj[c(1,4:5,7:8,12:13,15:22,24:27),1:2]),col="red")
points(Re(proj[28:38,1:2]),col="blue")
a<-a-.1
}

Is this the best way to do it? And I have this problem. It only 
plots 6 screens and then gives an error
"Error in plot.new() : Figure margins too large"

The idea is to make 10 plots being a function of parameter a. 
It goes from 1 to zero. I've already started at zero and gone 
to 1 but it happens the same thing.

Any hints?
--
Kit SAPO.ADSL.PT Apenas 50 ?.
Adira j? em http://www.sapo.pt/kitadsl



From RexBryan1 at attbi.com  Sat Jan 25 18:40:03 2003
From: RexBryan1 at attbi.com (Rex_Bryan@urscorp.com)
Date: Sat Jan 25 18:40:03 2003
Subject: [R] plotting primatives, ellipses, dots, radial coordinates etc.
Message-ID: <016801c2c499$54ddaf10$3182fd0c@dell1700>

Is there a library in R that defines plotting primatives such as drawing an
ellipse, drawing a colored dot, or drawing a line with a radius and angle?
More complex figures would be cool too like defining a color-filled polygon
as an object an placing it at any arbitrary position (x,y,scalex, scaled and
rotated).
Rex



From ligges at statistik.uni-dortmund.de  Sat Jan 25 19:36:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Jan 25 19:36:03 2003
Subject: [R] plot/screen
In-Reply-To: <1043486668.3e3257ccabd28@webmail.sapo.pt>
References: <1043486668.3e3257ccabd28@webmail.sapo.pt>
Message-ID: <3E32D904.5030408@statistik.uni-dortmund.de>

Luis Silva wrote:
> Dear helpers
> 
> I have this code to make 10 plots in the same device
> 
> a<-1
> split.screen(c(2:5))

You mean:
   split.screen(c(2, 5))

> for (i in 1:10){
> nova.matriz<-a*sigma+(1-a)*S
> proj<-calculo.comp(treino,nova.matriz)
> print(proj[,1:2])
> screen(i)
> plot(Re(proj[c(2,3,6,9:11,14,23),1:2]),xlim=range(c(-
> 15:15)),ylim=range(c(-5:5)),col="black")
> points(Re(proj[c(1,4:5,7:8,12:13,15:22,24:27),1:2]),col="red")
> points(Re(proj[28:38,1:2]),col="blue")
> a<-a-.1
> }
> 
> Is this the best way to do it? And I have this problem. It only 
> plots 6 screens and then gives an error
> "Error in plot.new() : Figure margins too large"
> 
> The idea is to make 10 plots being a function of parameter a. 
> It goes from 1 to zero. I've already started at zero and gone 
> to 1 but it happens the same thing.
> 
> Any hints?


What about reducing the margins (the obvious idea after reading the 
error message) or enlarging the space for the figures in another way 
(larger device region etc.)?
In order to reduce the margins, e.g. use
  ...
  screen(i)
  par(mar=c(2,2,1,1))
  ...


I think you don't need such a complex thing like split.screen().
Another way is to use
  par(mfrow=c(5, 2))
or see ?layout for a third way.


Uwe Ligges



From ligges at statistik.uni-dortmund.de  Sat Jan 25 20:09:35 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Jan 25 20:09:35 2003
Subject: [R] plotting primatives, ellipses, dots, radial coordinates etc.
In-Reply-To: <016801c2c499$54ddaf10$3182fd0c@dell1700>
References: <016801c2c499$54ddaf10$3182fd0c@dell1700>
Message-ID: <3E32DC19.9000905@statistik.uni-dortmund.de>

Rex_Bryan at urscorp.com wrote:
> Is there a library in R that defines plotting primatives such as drawing an
> ellipse, drawing a colored dot, or drawing a line with a radius and angle?
> More complex figures would be cool too like defining a color-filled polygon
> as an object an placing it at any arbitrary position (x,y,scalex, scaled and
> rotated).

- See the *package* ellipse

- Hint: Ihaka & Gentleman (1996): "R: A Language for Data Analysis and 
_*Graphics*_", JCGS 5 (3), 299-314.
This tells us implicitly: Look in R itself for some plotting mechanisms. 
See ?points, ?polygon, etc.

Uwe Ligges



From tlumley at u.washington.edu  Sat Jan 25 21:33:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat Jan 25 21:33:03 2003
Subject: [R] survey package
Message-ID: <Pine.A41.4.44.0301251146060.188130-100000@homer04.u.washington.edu>

A new package `survey' for analysing complex survey samples is on CRAN.
It handles stratification, clustering, and unequal sampling probabilities
in descriptive statistics, glms, and general maximum likelihood fitting.
The package is still under development:
  - it doesn't do the finite population correction to variances
  - it needs some real life worked examples

Most importantly, though, I don't do this sort of analysis routinely, so
it's possible that some part of the interface is completely insane from
the viewpoint of practising survey statisticians. Now would be an
excellent time to complain.

	-thomas


Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From mentus at gmx.de  Sat Jan 25 22:22:02 2003
From: mentus at gmx.de (Fernando Henrique Ferraz Pereira da Rosa)
Date: Sat Jan 25 22:22:02 2003
Subject: [R] Plotting coloured histograms...
Message-ID: <13981.1043529690@www49.gmx.net>

   Hi, I am having some trouble trying to plot a histogram in more than one
colour. What I want to do is, plot two vectors in the same histogram, but
with different colours, for instance:
       > x <- rnorm(1000,20,4);
       > y <- rnorm(1000,10,2);
    Then I'd like to have x and y ploted on the same hist (I can do that
already doing w <- c(x,y) then hist(w)) but the bars representing the x's should
be in one colour and the bars representing the y should be in another one,
so that I could see the overlaping areas of the two distributions etc.
     Is there any way to do that? I've read through the hist docummentation
(>help(hist)) and also googled for "R colour histogram" but didn't find
anything helpfull.

Thank you for your attention,

--



From rpeng at stat.ucla.edu  Sat Jan 25 23:00:41 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Sat Jan 25 23:00:41 2003
Subject: [R] AIC for regression models (was: (no subject))
In-Reply-To: <3E26DAA600530B73@mel-rta10.wanadoo.fr> (added by postmaster@wanadoo.fr)
Message-ID: <Pine.GSO.4.10.10301251347100.19826-100000@quetelet.stat.ucla.edu>

Yes, you can use the `AIC' function in R:

> set.seed(100)
> x1 <- rnorm(100)
> x2 <- rnorm(100)
> y <- x1 + x2 + rnorm(100)
> AIC(lm(y ~ x1 + x2))
[1] 286.7287

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Fri, 24 Jan 2003, Simon CHAMAILLE wrote:

> Dear All
A> I just want to know if it is easily possible to compute AICc
calculation for multiple regression models under R ?
> Thanks a lot,
> simon chamaillé
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From remigijus.lapinskas at maf.vu.lt  Sun Jan 26 08:28:03 2003
From: remigijus.lapinskas at maf.vu.lt (Remigijus Lapinskas)
Date: Sun Jan 26 08:28:03 2003
Subject: [R] Plotting coloured histograms...
References: <13981.1043529690@www49.gmx.net>
Message-ID: <9393.030126@maf.vu.lt>

Try the H. Bengtsson's function plot.histogram from

http://www.maths.lth.se/matstat/staff/hb/mypackages/R/plot.histogram.R

Remigijus

Saturday, January 25, 2003, 10:21:30 PM, you wrote:

FHFPdR>    Hi, I am having some trouble trying to plot a histogram in more than one
FHFPdR> colour. What I want to do is, plot two vectors in the same histogram, but
FHFPdR> with different colours, for instance:
FHFPdR>        > x <- rnorm(1000,20,4);
FHFPdR>        > y <- rnorm(1000,10,2);
FHFPdR>     Then I'd like to have x and y ploted on the same hist (I can do that
FHFPdR> already doing w <- c(x,y) then hist(w)) but the bars representing the x's should
FHFPdR> be in one colour and the bars representing the y should be in another one,
FHFPdR> so that I could see the overlaping areas of the two distributions etc.
FHFPdR>      Is there any way to do that? I've read through the hist docummentation
(>>help(hist)) and also googled for "R colour histogram" but didn't find
FHFPdR> anything helpfull.

FHFPdR> Thank you for your attention,

FHFPdR> --

FHFPdR> ______________________________________________
FHFPdR> R-help at stat.math.ethz.ch mailing list
FHFPdR> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Lsophir at wisemail.weizmann.ac.il  Sun Jan 26 14:28:08 2003
From: Lsophir at wisemail.weizmann.ac.il (Ron Ophir)
Date: Sun Jan 26 14:28:08 2003
Subject: [R] R2HTML
Message-ID: <se33faae.040@wisemail.weizmann.ac.il>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030126/08efe38b/attachment.pl

From ripley at stats.ox.ac.uk  Sun Jan 26 15:01:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Jan 26 15:01:03 2003
Subject: [R] R2HTML
In-Reply-To: <se33faae.040@wisemail.weizmann.ac.il>
Message-ID: <Pine.LNX.4.44.0301261355550.24084-100000@gannet.stats>

*How* are you trying to install it?  As the message says, you are not
doing it properly ....

Also, what operating system is `PC' running?  If Windows, I just checked
using the RGui menus, and it worked correctly.

On Sun, 26 Jan 2003, Ron Ophir wrote:

> I am trying to install R2HTML on PC, but keep getting the following error message:
> Error in testRversion(descfile) : This package has not been installed properly
>  See the Note in ?library

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Jan 26 17:32:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Jan 26 17:32:02 2003
Subject: [R] Problem about Rprof()  (Windows build  1.6.2)
In-Reply-To: <x2fzrx6p8g.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0301261612270.28371-100000@gannet.stats>

I have no idea what had changed.  The issue appears to be that the timing
thread used under Windows was not being started by _beginthread until the
current timeslice for the main thread finished *on a single-CPU* machine.

That's not what is documented to happen (nor used to happen), but adding
Sleep(wait/2) in the initialization allows the timing thread to start.

I had run some tests on a dual-CPU machine, and they worked as expected.

There is a workaround in R-devel.  Otherwise, add a call to
Sys.sleep(1) after Rprof() in your script, and that should suffice
to get profiling started.  (You may need to experiment with the number, 
which probably needs to be over 0.5secs to ensure that the sleep really 
does happen.)

On 13 Jan 2003, Peter Dalgaard BSA wrote:

> <asone at latte.harvard.edu> writes:
> 
> > Thank you for your advice, Prof. Ripley.
> > 
> > What I found after your e-mail is as follows:
> > 
> > when the following 4 command lines are typed in R Console one by one on
> > R (windows) Version 1.6.2  (2003-01-10), 
> > 
> > Rprof()
> > example(lm)
> > Rprof(NULL)
> > summaryRprof()
> > 
> > I got profiling results.
> > 
> > However, when I typed the following line in the R console,
> > 
> > 	Rprof(); example(lm); Rprof(NULL); summaryRprof()
> > 
> > or 
> > 
> > the above 4 command lines were saved as a program file, "testRprof.R",
> > and it was executed as:
> > 
> > 	>source("C:/asone/R/testRprof.R")
> > 
> > then I got the following error:
> > 
> > 	Error in summaryRprof() : no events were recorded
> 
> Interesting. For whatever it is worth, it doesn't seem to happen on
> Linux, so it is not the command interpreter per se. What happens if
> you turn off the "buffer output" option?
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mohamed at engr.uconn.edu  Sun Jan 26 17:50:02 2003
From: mohamed at engr.uconn.edu (Mohamed A. Kerasha)
Date: Sun Jan 26 17:50:02 2003
Subject: [R] Distributions.
In-Reply-To: <13981.1043529690@www49.gmx.net>
Message-ID: <HMEIKDIPDPFALCIDOILHIEGBCAAA.mohamed@engr.uconn.edu>

Dear R helpers,

What are the supported distributions in R and where to look for them?. Also,
is it possible to generate cyclic arrivals in R. For example, arrival
patterns that
correlates with time of the day.

I really appreciate your help,



From ripley at stats.ox.ac.uk  Sun Jan 26 18:24:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Jan 26 18:24:03 2003
Subject: [R] Distributions.
In-Reply-To: <HMEIKDIPDPFALCIDOILHIEGBCAAA.mohamed@engr.uconn.edu>
Message-ID: <Pine.LNX.4.44.0301261717190.28446-100000@gannet.stats>

On Sun, 26 Jan 2003, Mohamed A. Kerasha wrote:

> What are the supported distributions in R and where to look for them?. 

help.search("distribution")

and look also at packages SuppDists, evd, gld and sn amongst others.

> Also,
> is it possible to generate cyclic arrivals in R. For example, arrival
> patterns that
> correlates with time of the day.

Yes, it is possible, provided you have a complete description.  R is after 
all a fully-fledged programming language.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tim at sulser.com  Sun Jan 26 20:25:03 2003
From: tim at sulser.com (Tim Sulser)
Date: Sun Jan 26 20:25:03 2003
Subject: [R] gradient vector
Message-ID: <5.1.0.14.2.20030126100041.032a22b8@fax.mcdonagh.com>

Greetings R-folk,

I'll greatly appreciate any help you can offer...

I can't figure out how to add the gradient vector of a function f(x,y) 
evaluated at a point (x1,y1) onto a contour() graph.  I see that 
deriv(...,func=TRUE) gives a function that takes (x1,y1) and gives the 
correct gradient (x2,y2) as part of it's output, but I haven't been able to 
feed that info into an arrows(x1,y1,x1+x2,y1+y2) command.  I've tried using 
attr(eval(deriv(...),"gradient"), but can't make it work  Or is there 
something I've completely missed?

Thanks,

Tim



____________________
tim at sulser.com



From qinxin2001 at yahoo.com  Sun Jan 26 21:43:03 2003
From: qinxin2001 at yahoo.com (Qin Xin)
Date: Sun Jan 26 21:43:03 2003
Subject: [R] how could I add legends?
In-Reply-To: <HMEIKDIPDPFALCIDOILHIEGBCAAA.mohamed@engr.uconn.edu>
Message-ID: <20030126204220.95086.qmail@web11406.mail.yahoo.com>

Hi All,

I plotted several distribution curves in one graph but
I do not know how to add legends say which is what
distribution.  Could someone help me?  Thanks,



From Ko-Kang at xtra.co.nz  Sun Jan 26 23:02:02 2003
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Sun Jan 26 23:02:02 2003
Subject: [R] how could I add legends?
References: <20030126204220.95086.qmail@web11406.mail.yahoo.com>
Message-ID: <003a01c2c586$79661d20$f12658db@kwan022>

Hi,

----- Original Message ----- 
From: "Qin Xin" <qinxin2001 at yahoo.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, January 27, 2003 9:42 AM
Subject: [R] how could I add legends?


> Hi All,
> 
> I plotted several distribution curves in one graph but
> I do not know how to add legends say which is what
> distribution.  Could someone help me?  Thanks,


Have a look at
   ?legend

Kevin
------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022



From djw1005 at cam.ac.uk  Mon Jan 27 00:23:02 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Mon Jan 27 00:23:02 2003
Subject: [R] Plotting coloured histograms...
In-Reply-To: <13981.1043529690@www49.gmx.net>
Message-ID: <Pine.SOL.3.96.1030126225744.27633A-100000@libra.cus.cam.ac.uk>

> Hi, I am having some trouble trying to plot a histogram in more than one
> colour. What I want to do is, plot two vectors in the same histogram, but
> with different colours, for instance:
>        > x <- rnorm(1000,20,4);
>        > y <- rnorm(1000,10,2);
>     Then I'd like to have x and y ploted on the same hist (I can do that
> already doing w <- c(x,y) then hist(w)) but the bars representing the x's should
> be in one colour and the bars representing the y should be in another one,
> so that I could see the overlaping areas of the two distributions etc.

You haven't made it clear if you want the histograms on top of each other
(which is what you get from w<-c(x,y) ) or if you want them side-by-side
(so you can see overlapping areas).

I plot histograms on top of each other using my own trellis function
panel.surpose, like this:

x <- rnorm(1000,20,4)
y <- rnorm(1000,10,2)
w <- c(x,y)
f <- ifelse(1:length(z)<=length(x),0,1)
library(lattice)
histogram(~w, groups=f, panel=panel.surpose)

The "groups" argument should be a factor, or some other variable taking
values in a small set. The function panel.surpose takes each panel in
turn, splits the dataset for that panel into groups according to "groups",
and plots a histogram for each group, one on top of another. The
colours can be specified like "bar.col=c(rgb(1,0,0),rgb(0,1,0))", the
first colour being used for the lowest level of "groups". You could
specify a different "panel.groups" function, but I can't see how that
would be useful.

In writing this function, I had trouble with the standard routines
hist and panel.histogram, which deal with the counting. What should
their behaviour be when the data has NA values? It seems to me that
count, percentage and density do not handle NA values in a consistent way.
Anyway, I wrote a replacement for panel.histogram to use with my
panel.surpose.

Damon Wischik.


panel.histogram.partial <- 
function (x, breaks, equal.widths = TRUE, type = "density", col =
bar.fill$col, ...) 
{
    x <- as.numeric(x)
    grid.lines(x = c(0.05, 0.95), y = unit(c(0, 0), "native"), 
        default.units = "npc")
    if (length(x) > 0) {
        bar.fill <- trellis.par.get("bar.fill")
        if (is.null(breaks)) {
            nint <- round(log2(length(x)) + 1)
            breaks <- if (equal.widths) 
                do.breaks(range(x), nint)
            else quantile(x, 0:nint/nint)
        }
        h <- hist(x, breaks = breaks, plot = FALSE, ...)
        y <- if (type == "count") 
            h$counts
        else if (type == "percent") 
            100 * h$counts/length(x)
        else h$intensities * length(which(!is.na(x)))/length(x)
        nb <- length(breaks)
        if (nb != (length(y) + 1)) 
            warning("something is probably wrong")
        if (nb > 1) {
            for (i in 1:(nb - 1)) if (y[i] > 0) {
                grid.rect(gp = gpar(fill = col), x = breaks[i], 
                  y = 0, height = y[i], width = breaks[i + 1] - 
                    breaks[i], just = c("left", "bottom"), default.units="native")
            }
        }
    }
}

rgbmix <- function(p,col1,col2) { # p a vector. pi=0: col1. pi=1: col2
  cm <- (1-p) %o% col2rgb(col1) + p %o% col2rgb(col2)
  rgb(cm[,"red",],cm[,"green",],cm[,"blue",],maxColorValue=255)
  }

panel.surpose <-
function (x, y = NULL, subscripts, groups, panel.groups =
"panel.histogram.partial", 
  bar.col=superpose.line$col, ...)
  {
  x <- as.numeric(x)
  if (!is.null(y)) y <- as.numeric(y)
  superpose.line <- trellis.par.get("superpose.line")
  if (length(subscripts)>0 && length(groups)<max(subscripts))
    groups <- rep(groups, length=max(subscripts))
  vals <- sort(unique(groups))
  nvals <- length(vals)
  bar.col <- if (length(bar.col)>=nvals) bar.col else {
    if (length(bar.col)>2 || length(bar.col)==1) 
      rep(bar.col,length=nvals)
    else # linearly interpolate the colours
      rgbmix((1:nvals-1)/(nvals-1),bar.col[[1]],bar.col[[2]])
    }
  panel.groups <- if(is.function(panel.groups)) 
    panel.groups
  else if (is.character(panel.groups))
    get(panel.groups)
  else
    eval(panel.groups)
  nx <- length(subscripts)
  for (i in nvals:1) {
    id <- (groups[subscripts] %in% vals[1:i])
    if (any(id)) {
      fakex <- rep(NA,times=nx-length(which(id)))
      xandfake <- c(fakex,x[id])
      args <- if (!is.null(y))
        list(x=xandfake,y,col=bar.col[i],...)
      else
        list(x=xandfake, col=bar.col[i], lty=0, ...)
      do.call("panel.groups",args)
      }
    }
  }



From estatistico at fastmail.fm  Mon Jan 27 03:36:03 2003
From: estatistico at fastmail.fm (Rafael B)
Date: Mon Jan 27 03:36:03 2003
Subject: [R] nonparametrics databank for analisys
Message-ID: <20030127023531.CEAE61E58D@www.fastmail.fm>

 I'm looking for data to use with nonparametrics exploration technics.
 I'm a undergraduate student in statistics at the Unicamp (Brazil), and
 i've to make a project (with orientation of a professor). I choose
 nonparametrics statistics to make the project. But in this project i
 must
 have to use a databank and present analisys. The subject can't be
 neither in biological data or social sciences data.
 So, if somebody give me indications where i can find databanks for
 nonparametric statistics analisys (on the internet or other sources), i
 will thank you.
 
 Rafael Bertola
 Unicamp
 www.ime.unicamp.br
 
-- -- -- -- -- -- -- -- -- 
  Rafael Bertola
  Unicamp - Brasil
  estatistico at fastmail.fm

-- 
http://fastmail.fm - Send your email first class



From TyagiAnupam at aol.com  Mon Jan 27 05:49:02 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Mon Jan 27 05:49:02 2003
Subject: [R] nonparametrics databank for analisys
Message-ID: <48.172934e7.2b660e2b@aol.com>

You can find data on climate change at the following url at CDIAC at Oak 
Ridge National Labs. Good luck for your project!
http://cdiac.ornl.gov/pns/pns_main.html



From ririzarr at jhsph.edu  Mon Jan 27 06:57:03 2003
From: ririzarr at jhsph.edu (Rafael A. Irizarry)
Date: Mon Jan 27 06:57:03 2003
Subject: [R] google
Message-ID: <Pine.GSO.4.10.10301270051160.15591-100000@athena.biostat.jhsph.edu>

fyi, I typed "R" in google and hit the "I'm feeling lucky botton"... it
took me to http://www.r-project.org


-rafael
ps - toysrus.com is second.



From mk36 at aub.edu.lb  Mon Jan 27 09:17:02 2003
From: mk36 at aub.edu.lb (Marwan Khawaja)
Date: Mon Jan 27 09:17:02 2003
Subject: [R] survey package
Message-ID: <CLECJBOEBGOMOKJHJNDACEELCMAA.marwan.khawaja@aub.edu.lb>

This is great! Thanks Thomas!
Marwan

-Date: Sat, 25 Jan 2003 11:55:12 -0800 (PST)
-From: Thomas Lumley <tlumley at u.washington.edu>
-To: r-announce at r-project.org
-Subject: [R] survey package


-A new package `survey' for analysing complex survey samples is on CRAN.
I-t handles stratification, clustering, and unequal sampling probabilities
-in descriptive statistics, glms, and general maximum likelihood fitting.
-The package is still under development:
-  - it doesn't do the finite population correction to variances
-  - it needs some real life worked examples

-Most importantly, though, I don't do this sort of analysis routinely, so
-it's possible that some part of the interface is completely insane from
-the viewpoint of practising survey statisticians. Now would be an
-excellent time to complain.

-	-thomas


-Thomas Lumley			Asst. Professor, Biostatistics
-tlumley at u.washington.edu	University of Washington, Seattle

--------------------------------------------------------------------------------
----------------------------------------------
Marwan Khawaja 	<http://webfaculty.aub.edu.lb/~mk36  if you have MS Explorer
--------------------------------------------------------------------------------
----------------------------------------------


-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 2340 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030127/5b8bb282/winmail.bin

From maj at stats.waikato.ac.nz  Mon Jan 27 09:26:07 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Mon Jan 27 09:26:07 2003
Subject: [R] google
References: <Pine.GSO.4.10.10301270051160.15591-100000@athena.biostat.jhsph.edu>
Message-ID: <3E34ECBE.4000401@stats.waikato.ac.nz>

That's good. But it will probably not take you to other pages where 
people mention that they are using R for something, which is a bit of a 
pity.

Rafael A. Irizarry wrote:
> fyi, I typed "R" in google and hit the "I'm feeling lucky botton"... it
> took me to http://www.r-project.org
> 
> 
> -rafael
> ps - toysrus.com is second.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From laura at bayesian-bay.freeserve.co.uk  Mon Jan 27 12:24:05 2003
From: laura at bayesian-bay.freeserve.co.uk (Laura Gross)
Date: Mon Jan 27 12:24:05 2003
Subject: [R] Multinomial Logit Models
In-Reply-To: <Pine.LNX.4.44.0301241256030.12565-100000@gannet.stats>
References: <EXECMAIL.1030124121936.A@muahost.ucc.hull.ac.uk>
 <Pine.LNX.4.44.0301241256030.12565-100000@gannet.stats>
Message-ID: <crRTnKABaRN+Ew5K@toastyhamster.karoo.co.uk>

Hi, Thanks for that help.

In message <Pine.LNX.4.44.0301241256030.12565-100000 at gannet.stats>,
ripley at stats.ox.ac.uk writes
>On Fri, 24 Jan 2003, L.E.Gross wrote:
>
>> I am wanting to fit some multinomial logit models (multinom command in
>> package nnet)
>> 
>> Is it possible to do any model checking techniques on these models 
>> e.g. residual, leverage etc. I cannot seem to find any commands that 
>> will allow me to do this.

>residuals() should work: it does for me.

I have tried using this:
My model is say:

model<-multinom(self~sex, data=self) yet when I try

residuals(model) I simply get the return as NULL?

Am I missing something?

Many thanks


-- 
Laura Gross
laura at bayesian-bay.freeserve.co.uk



From B.Rowlingson at lancaster.ac.uk  Mon Jan 27 12:39:02 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon Jan 27 12:39:02 2003
Subject: [R] google
In-Reply-To: <3E34ECBE.4000401@stats.waikato.ac.nz>
References: <Pine.GSO.4.10.10301270051160.15591-100000@athena.biostat.jhsph.edu> <3E34ECBE.4000401@stats.waikato.ac.nz>
Message-ID: <3E3519BD.1020606@lancaster.ac.uk>

Murray Jorgensen wrote:
> That's good. But it will probably not take you to other pages where 
> people mention that they are using R for something, which is a bit of a 
> pity.

It's very good. One of my worries with R was that googling for 'R' would 
have no chance of finding it. Hooray for google!

 > But it will probably not take you to other pages where
 > people mention that they are using R for something, which is a bit of a
 > pity.

  You can always stick 'statistics' in your Google search with 'R' if 
you want to narrow it down to applications.

Googling for 'S' comes up with the www.gnu.org/home.html web page. I 
dont know why, it doesn't mention S or R at all. I leave '[A-Q][T-Z]' as 
an exercise for the reader.

Baz



From chrysopa at insecta.ufv.br  Mon Jan 27 13:04:03 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Mon Jan 27 13:04:03 2003
Subject: [R] [off] Statistical list
Message-ID: <200301270958.46384.chrysopa@insecta.ufv.br>

Hi all,

Anybody know if exist a good statistical list?

A list for discuss about different means to work in the same dataset. The 
profit and cost of each mean. 

Thanks for all
Inte
Ronaldo
-- 
	O fracasso e a oportunidade de comecar de novo 
	inteligentemente
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Gnu/Debian Woody D+:) | Lxuser#: 205366



From rdiaz at cnio.es  Mon Jan 27 14:30:04 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Mon Jan 27 14:30:04 2003
Subject: Summary: [R] books on categorical data analyses
In-Reply-To: <200301211813.14074.rdiaz@cnio.es>
References: <200301211813.14074.rdiaz@cnio.es>
Message-ID: <200301271425.31296.rdiaz@cnio.es>

Dear All,

I received several helpful replies to my original query (reproduced below); 
thanks to Frank Harrell, Paul Hewson, Pat Althman, and Chunlou Yung. 
Basically, I was directed to Laura Thompsons' S-PLUS manual for Agresti's 
1990 Categorical Data Analysis (available from 

http://math.cl.uh.edu/~thompsonla/5537/Splusdiscrete.PDF), 

to Presnell's briefer document 

(http://web.stat.ufl.edu/~presnell/Teaching/sta4504-2000sp/R/R-CDA.pdf) and to 

the material available from Pat Althman's page:

http://www.statslab.cam.ac.uk/~pat.

I was also reminded that Frnak Harrell's recent "Regresion modeling 
strategies" book has several chapter with plenty of material on binary and 
ordinal logistic regression. (See http://hesweb1.med.virginia.edu/biostat/rms 
for more information.)

Best,




Original query
***********************************
Dear All,

We are about to purchase the second edition of Agresti's "Categorical Data 
Analysis" (my old copy of the first ed. of that wonderful book is falling 
apart). I would appreciate suggestions about other comparable books which, if 
possible, have examples using R/S code (instead of SAS).

Thanks,


Ram?n



-- 

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
http://bioinfo.cnio.es/~rdiaz



From mbalcilar at manas.kg  Mon Jan 27 14:38:24 2003
From: mbalcilar at manas.kg (Mehmet Balcilar)
Date: Mon Jan 27 14:38:24 2003
Subject: [R] google
In-Reply-To: <3E3519BD.1020606@lancaster.ac.uk>
References: <Pine.GSO.4.10.10301270051160.15591-100000@athena.biostat.jhsph.edu> <3E34ECBE.4000401@stats.waikato.ac.nz> <3E3519BD.1020606@lancaster.ac.uk>
Message-ID: <3E35C243.60503@manas.kg>

W takes to White House :)

No I din't try others. W is my daughter's favorite letter!

Mehmet

Barry Rowlingson wrote:

> Murray Jorgensen wrote:
>
>> That's good. But it will probably not take you to other pages where 
>> people mention that they are using R for something, which is a bit of 
>> a pity.
>
>
> It's very good. One of my worries with R was that googling for 'R' 
> would have no chance of finding it. Hooray for google!
>
> > But it will probably not take you to other pages where
> > people mention that they are using R for something, which is a bit of a
> > pity.
>
>  You can always stick 'statistics' in your Google search with 'R' if 
> you want to narrow it down to applications.
>
> Googling for 'S' comes up with the www.gnu.org/home.html web page. I 
> dont know why, it doesn't mention S or R at all. I leave '[A-Q][T-Z]' 
> as an exercise for the reader.
>
> Baz
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


-- 
Mehmet Balcilar, PhD
Assistant Professor
Manas University
College of Economics & Administrative Sciences
Department of Economics
Prospect Tictik 56
Bishkek
Kyrgyzstan

Tel: +996 (312) 54 19 42
     +996 (312) 54 19 43
     +996 (312) 54 19 45
     
Fax: +996 (312) 54 19 35

e-mail: mbalcilar at manas.kg

Homepage: http://rifle.manas.kg
Reproducible Research Page: http://rifle.manas.kg/rresearch



From diemcl at unileon.es  Mon Jan 27 14:48:02 2003
From: diemcl at unileon.es (=?iso-8859-1?Q?Manuel_Castej=F3n_Limas?=)
Date: Mon Jan 27 14:48:02 2003
Subject: [R] re:  box counting method and other landscape ecology measures
References: <3E2E6C4D.1050202@agric.uwa.edu.au>
Message-ID: <001201c2c609$da283a70$bb6192c1@mahalanobis>

Dear Rohan,

Have a look at the fdim library, it may be of interest to you as far as
fractal dimension
(or box counting if you prefer) is concerned.

Best wishes,

Manuel Castejon



From ernesto at ipimar.pt  Mon Jan 27 14:53:03 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon Jan 27 14:53:03 2003
Subject: [R] boot error message
Message-ID: <1043666814.3630.8.camel@gandalf.ipimar.pt>

Hi

I'm using boot.ci to calculate the bca CI. However I'm getting an error
message that I can not understand, can someone help me with this ?

> blm8901.P1.bca <- boot.ci(blm8901,type=c("bca"),index=1)
Error in if (!all(rk > 1 & rk < R)) warning("Extreme Order Statistics
used as Endpoints") : 
        missing value where logical needed

When I plot index 1, the distribution is normal and the qq plot is good,
so I don't understand where the "extreme statistics" come from, neither
the "missing value ..."

Regards

EJ

-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
IPIMAR - National Research Institute for Agriculture and Fisheries
Av. Brasilia, 1400-006
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948
http://ernesto.freezope.org



From ripley at stats.ox.ac.uk  Mon Jan 27 15:12:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan 27 15:12:03 2003
Subject: [R] Multinomial Logit Models
In-Reply-To: <crRTnKABaRN+Ew5K@toastyhamster.karoo.co.uk>
Message-ID: <Pine.LNX.4.44.0301271409450.14262-100000@gannet.stats>

On Mon, 27 Jan 2003, Laura Gross wrote:

> Hi, Thanks for that help.
> 
> In message <Pine.LNX.4.44.0301241256030.12565-100000 at gannet.stats>,
> ripley at stats.ox.ac.uk writes
> >On Fri, 24 Jan 2003, L.E.Gross wrote:
> >
> >> I am wanting to fit some multinomial logit models (multinom command in
> >> package nnet)
> >> 
> >> Is it possible to do any model checking techniques on these models 
> >> e.g. residual, leverage etc. I cannot seem to find any commands that 
> >> will allow me to do this.
> 
> >residuals() should work: it does for me.
> 
> I have tried using this:
> My model is say:
> 
> model<-multinom(self~sex, data=self) yet when I try
> 
> residuals(model) I simply get the return as NULL?

That of course is not reproducible, but

> library(MASS)
> data(housing)
> library(nnet)
> (house.mult <- multinom(Sat ~ Infl + Type + Cont,
+                         weights = Freq, data = housing))
> residuals(house.mult)

is, and it works.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lahh at pubhealth.ku.dk  Mon Jan 27 16:20:03 2003
From: lahh at pubhealth.ku.dk (Lars Hougaard Hansen BSA)
Date: Mon Jan 27 16:20:03 2003
Subject: [R] seMethod for tkpack and tkgrid
Message-ID: <Pine.GSO.3.96.1030127155911.2697C-200000@diamant>


I have a problem, regarding setMethod for "tkpack" and "tkgrid".

Please see attached file.

I am using a Linux-gnu platform and the 1.7.0 version of R.


	Lars Hougaard Hansen
-------------- next part --------------

## problem regarding "setMethod" for "tkpack" and "tkgrid".

library(methods)
library(tcltk)

# a class, "select", is defined, by

setClass("select",representation(listbox="tkwin", listvariable="tclVar"))

# Defining the method "tclvalue" for an object of class "select", by

setMethod("tclvalue","select",
          function(x)
          tclvalue(x at listvariable)
          )

# is accepted as legal R-code. But, when trying to do the same for "tkpack"
# and "tkgrid", R prints an Error.

setMethod("tkpack","select",
          function(x,...)
          tkpack(x at listbox,...)
          )

setMethod("tkgrid","select",
          function(x,...)
          tkgrid(x at listbox,...)
          )

# Error message:
#
# Error in makeGeneric(name, fdef, fdeflt, group = group, valueClass = valueClass,  : 
#	 No suitable arguments to dispatch methods in this function

From Jim_Garrett at bd.com  Mon Jan 27 17:11:03 2003
From: Jim_Garrett at bd.com (Jim_Garrett@bd.com)
Date: Mon Jan 27 17:11:03 2003
Subject: [R] Re: Problems for 13 year old
Message-ID: <OFD908A5F4.FB20B318-ON85256CBB.00556223@bd.com>

How about spam filtering?

Granted, there's some infrastructure involved, which means gratification is
not instant.  But it involves something that most people who use computers
care about:  e-mail, and spam.

I mention this because the following web site sparked some interest in
statistics among some acquaintances who were otherwise very cool to it:

     http://www.paulgraham.com/spam.html

This outlines a "Bayesian" spam filter.  I'm not sure it's wholly Bayesian,
but it comes close, the author's are good, and I hear that it performs
well, in fact better than many commercial spam filters (or so I hear).
Moreover, the web site virtually gushes about the virtues of statistical
methods.  The interesting thing about the filter is that you get to see
what "features" it's discovering.

A quick search also indicated that Mozilla apparently offers a plug-in for
the same spam filter.  That would offer a quick way to get the filter up
and running with real e-mail.  But I don't know if Mozilla offers
interesting diagnostics about which features it's using, which is the
pedagogically interesting part.  Mozilla mentions it here:

     http://www.mozilla.org/mailnews/spam.html

Of course, you can use any number of classification techniques to
distinguish spam from other e-mail, you just need data.  Hastie and
Tibshirani's _The Elements of Statistical Learning_ demonstrates a couple
of types of models applied to the spam problem, and points to data at

     ftp.ics.uci.edu

Ideally, you would do some exploration to design a filter, implement it in
R, and then integrate it with your nephew's e-mail program.  This would be
a long-term project, maybe even a science-fair project, with long-term
benefits (educational and practical).  I know this can be done with Linux,
but I have no idea about Mac OS 9!  It's probably a stretch for typical
13-year-olds, but for the right 13-year-old, it would be a blast.

Good luck!

Jim Garrett
Baltimore, Maryland, USA


*********************************************************************************
This message is intended only for the designated recipient(s).   ... [[dropped]]



From s-luppescu at uchicago.edu  Mon Jan 27 17:46:02 2003
From: s-luppescu at uchicago.edu (Stuart Luppescu)
Date: Mon Jan 27 17:46:02 2003
Subject: [R] Problems for 13 year old
In-Reply-To: <7C92FFD84C6DA94C8A8693EC976B8DFB955507@msln2.london.kbcfp.com>
References: <7C92FFD84C6DA94C8A8693EC976B8DFB955507@msln2.london.kbcfp.com>
Message-ID: <1043685919.9650.17.camel@musuko.uchicago.edu>


On Fri, 2003-01-24 at 21:17, Kloss, Burkhard wrote:
> >There was some discussion on python news groups of an introductory
> >programming course based on python, which is similar in structure to
> >the S language.  (Note I said "similar" - no flames please.)  That may
> >also be a source of examples.
> 
> Computer Programming for everyone:  http://www.mlab.uiah.fi/~eye/python/
> 
> While I think R is a wonderful tool, it may be a bit too specialised for a 13 year old, unless he has a serious mathematical bent.  I'd also recommend Python (both for introducing people to programming and in general), but for quickly getting results with graphics, Logo is unbeatable.

I have to agree with the Python suggestion. Not only is it a useful,
easy-to-learn-and-use language, but there is also the PyGame package
that aids game programming tremendously. This should appeal to
youngsters. My 11-year-old son, who wants to be a game programmer when
he grows up, is working on it, albeit slowly.
-- 
Stuart Luppescu -=- s-luppescu at uchicago.edu        
University of Chicago -=- CCSR 
$B:MJ8$HCRF`H~$NIc(B -=-    Kernel 2.4.19-xfs-r2                
The trouble with opportunity is that it always
 comes disguised as hard work.   -- Herbert V.
 Prochnow 
 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: This is a digitally signed message part
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030127/5a41a88c/attachment.bin

From Robert.Schick at noaa.gov  Mon Jan 27 20:38:02 2003
From: Robert.Schick at noaa.gov (Robert Schick)
Date: Mon Jan 27 20:38:02 2003
Subject: [R] Conditioned file Import?
Message-ID: <3E358A89.8113D2EB@noaa.gov>

I'm using R 1.6.2 on Windows 2000.

I have two similar sets of files in two different directories. One
contains species presence data and environmental measurements; the other
contains species absence data and environmental measurements for the
same variables as the presence data. 

The absence datasets contain many more observations than the presence
datasets, and I'd like to draw a random sample from these larger
datasets upon import of the text files. I would also like to condition
the import so that I only draw rows whose column(s) satisfy a criteria,
e.g. where data$temp <= 0. However, I'm not seeing anyway of doing this. 

I know I can use something like:

> test <- read.table(file="10.06.94ed.txt",header=T)
> test2 <- test[test$temp>15,]
> test2[sort(sample(10)),]

but can I do this as I read in the file? If yes, how could I find the #
of lines in my smaller file, and then pass that number to the sample
call on the larger file? (Is there a wc -l equivalent in R?)

Finally, if yes to either of the above, is there a way to batch this?
-- 
Rob Schick
Ecologist
NOAA Fisheries
Santa Cruz Lab
110 Shaffer Road
Santa Cruz, CA 95060
Phone: 831.420.3960



From ripley at stats.ox.ac.uk  Mon Jan 27 20:55:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Jan 27 20:55:03 2003
Subject: [R] Conditioned file Import?
In-Reply-To: <3E358A89.8113D2EB@noaa.gov>
Message-ID: <Pine.LNX.4.44.0301271953510.21427-100000@gannet.stats>

On Mon, 27 Jan 2003, Robert Schick wrote:

> I'm using R 1.6.2 on Windows 2000.
> 
> I have two similar sets of files in two different directories. One
> contains species presence data and environmental measurements; the other
> contains species absence data and environmental measurements for the
> same variables as the presence data. 
> 
> The absence datasets contain many more observations than the presence
> datasets, and I'd like to draw a random sample from these larger
> datasets upon import of the text files. I would also like to condition
> the import so that I only draw rows whose column(s) satisfy a criteria,
> e.g. where data$temp <= 0. However, I'm not seeing anyway of doing this. 
> 
> I know I can use something like:
> 
> > test <- read.table(file="10.06.94ed.txt",header=T)
> > test2 <- test[test$temp>15,]
> > test2[sort(sample(10)),]
> 
> but can I do this as I read in the file? If yes, how could I find the #
> of lines in my smaller file, and then pass that number to the sample
> call on the larger file? (Is there a wc -l equivalent in R?)

?count.fields

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.connolly at hortresearch.co.nz  Mon Jan 27 22:14:03 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Mon Jan 27 22:14:03 2003
Subject: [R] Please begin a new subject if your post isn't a response to a previous one
Message-ID: <20030127211330.GA20618@hortresearch.co.nz>

Most mornings, I have over a screenful of messages mostly from R-help
and it's very useful to have them threaded.  However, the usefulness
of threading is lost when posters reply to a message and then change
the subject instead of creating a new message.

People who don't have a mail client that can display email in threads
are probably unaware that this sort of thing can happen in ones that do:


    37 N   25 Jan Luis Silva              ( 34) [R] plot/screen
    38 N   25 Jan Uwe Ligges              ( 55) `-> 
    39 N   25 Jan Fernando Henrique Ferra ( 20) [R] Plotting coloured histograms
->  40 N   26 Jan Mohamed A. Kerasha      ( 12) |->[R] Distributions.
    41 N   26 Jan ripley at stats.ox.ac.uk   ( 26) | |->
    42     26 Jan Qin Xin                 (  9) | `->[R] how could I add legends
    43     27 Jan Ko-Kang Kevin Wang      ( 31) |   `->
    44 N   26 Jan Remigijus Lapinskas     ( 32) |->Re: [R] Plotting coloured his
    45 N   26 Jan Damon Wischik           (125) `-> 
    46 N   25 Jan Rex_Bryan at urscorp.com   ( 10) [R] plotting primatives, ellipse
    47 N   25 Jan Uwe Ligges              ( 19) `->   


As Martin Maechler explained a month or so ago, it also screws up the
archives for a similar reason.

This is a request to anyone who starts a new subject to begin with a
new message and NOT reply to an existing one.  If your mail client is
any good, it's very simple to set up an alias (mine is simply 'r') so
that the tedious task of typing 'r-help at stat.math.ethz.ch' is
unnecessary and it's quicker than scrolling through an address book.
It's also quicker than deleting the previous subject.

Your cooperation will be greatly appreciated.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From kjetil at entelnet.bo  Mon Jan 27 22:42:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon Jan 27 22:42:03 2003
Subject: [R] Plotting coloured histograms...
In-Reply-To: <13981.1043529690@www49.gmx.net>
Message-ID: <3E356F13.30752.1E92C8@localhost>

On 25 Jan 2003 at 22:21, Fernando Henrique Ferraz Pereira da Rosa 
wrote:

Hola!

Maybe this may be of help:

> x <- rnorm(100,2,2)
> y <- rnorm(200, 4,3)
> hist(x)
> hist(y, add=TRUE)
> # which gives a confusing result. Better is:
> hist(x, freq=FALSE)
> hist(y, add=TRUE, freq=FALSE)
> # But it is difficult to separate visually the two histograms in
> # the same plot. Trying with colors:
> hist(x, freq=FALSE, col="blue")
> hist(y, add=TRUE, freq=FALSE, col="red")
> # is somewhat better, but it covers part of the blue histogram!
> # Anybody knows of better solutions?

Kjetil Halvorsen


>    Hi, I am having some trouble trying to plot a histogram in more than one
> colour. What I want to do is, plot two vectors in the same histogram, but
> with different colours, for instance:
>        > x <- rnorm(1000,20,4);
>        > y <- rnorm(1000,10,2);
>     Then I'd like to have x and y ploted on the same hist (I can do that
> already doing w <- c(x,y) then hist(w)) but the bars representing the x's should
> be in one colour and the bars representing the y should be in another one,
> so that I could see the overlaping areas of the two distributions etc.
>      Is there any way to do that? I've read through the hist docummentation
> (>help(hist)) and also googled for "R colour histogram" but didn't find
> anything helpfull.
> 
> Thank you for your attention,
> 
> --
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From djw1005 at cam.ac.uk  Mon Jan 27 22:46:08 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Mon Jan 27 22:46:08 2003
Subject: [R] Irregular time series
Message-ID: <Pine.SOL.3.96.1030127213517.1045A-100000@libra.cus.cam.ac.uk>

I have an irregular time series, stored as a data frame, in the form

    Time     Bytes
  57213.191  20
  57213.193  20
  57213.300  23
   ...       ...

How should I convert this into a regularly-spaced time series? 
I have in mind to divide time into equal-sized intervals, and sum the
number of Bytes in each interval. I tried this:
  
its.to.ts <- function(times,values,delta=1) {
  m <- min(times)
  M <- max(times)
  mm <- delta*floor(m/delta)
  MM <- delta*ceiling(M/delta)
  cuts <- seq(from=mm,to=MM,by=delta)
  nullvals <- rep(0,length(cuts)-1)
  nulltimes <- cuts[-1]-delta/2
  time.factor <- cut(c(times,nulltimes),cuts,labels=FALSE)
  dd <- aggregate(c(values,nullvals),by=list(time=time.factor),sum)
  ts(data=dd$x,start=mm,deltat=delta)
  }

but it is very slow (for a data frame of 102,000 lines, converted into a 
time series of 130,000 points). Is there a better way?

Damon Wischik.



From heleenslagter at hotmail.com  Mon Jan 27 23:52:16 2003
From: heleenslagter at hotmail.com (Heleen Slagter)
Date: Mon Jan 27 23:52:16 2003
Subject: [R] Greenhouse-Geisser correction
Message-ID: <F46VMb5UWgP1A83xiDd00015fea@hotmail.com>

Hi all,

I was wondering whether there are any packages that provide for the 
Greenhouse-Geisser correction, an adjustment used in univariate repeated 
measures when the sphericity assumption is violated (both numerator and 
denominator degrees of freedom are multiplied by GG-epsilon, and the 
significance of the F ratio is evaluated with the new degrees of freedom)? I 
have seen a few emails with the same question, to which nobody replied, but 
am hoping that maybe in the mean time somebody has tried to work this out.

Thanks much,
Heleen



From tomlinso at purdue.edu  Tue Jan 28 01:04:03 2003
From: tomlinso at purdue.edu (nels.tomlinson.1)
Date: Tue Jan 28 01:04:03 2003
Subject: [R] iterative proportional fitting in R?
Message-ID: <Pine.SOL.4.51.0301271807360.24772@herald.cc.purdue.edu>

Hi,

We have some sample data from the US census, and we know the marginal
totals for the population.  We need to make the population estimates add
up to the correct sums.

I have two questions:

Is there some package in R which does this adjustment, by any means?

Is there some more modern reference for this problem than Deming's 1943
monograph, ``Statistical Adjustment of Data''?


If you want to reply offlist, please don't use the address that this was
sent from; you can reach me at nels_tomlinson at labor.state.ak.us

Thanks,
Nels



From rsadler at agric.uwa.edu.au  Tue Jan 28 04:23:02 2003
From: rsadler at agric.uwa.edu.au (rohan sadler)
Date: Tue Jan 28 04:23:02 2003
Subject: [R] box counting method and other landscape ecology measures
References: <3E2E6C4D.1050202@agric.uwa.edu.au> <001201c2c609$da283a70$bb6192c1@mahalanobis>
Message-ID: <3E35F91E.5090501@agric.uwa.edu.au>

Hi Manuel and Robert,

My understanding is that the fdim library is orientated towards vector 
data filling a space, as opposed to a raster type image. Importantly, I 
utilise the GRASS library interface with the GRASS GIS to import raster 
images that are spatially referenced into R. Hence methods such as 
box-counting and Minkowsky sausage are perhaps more applicable, and 
certainly found more often in the image-analysis/landscape ecology 
literature than the information or correlation dimension.

I have managed to come up with a primitive implementation of the 
box-counting algorithm in the meantime (i'm pleased with it although I 
am a mediocre programmer), and my next step is an adjacency measure - to 
tell me whether I have one big patch or lots of small patches.

I'm working from a few references, but one of the most useful is:
L da F Costa & R M Cesar 2001 Shape Analysis and Classification: Theory 
and Practice. CRC Press. Boca Raton

Thanks for replying

Rohan Sadler




Manuel Castej?n Limas wrote:

>Dear Rohan,
>
>Have a look at the fdim library, it may be of interest to you as far as
>fractal dimension
>(or box counting if you prefer) is concerned.
>
>Best wishes,
>
>Manuel Castejon
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Ecosystems Research Group (ERGO)
School of Plant Biology (Botany), Faculty of Natural & Agricultural Sciences,
The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009, Australia

Ph:  +61 8 9380 7914
Fax: +61 8 9380 7925
email: rsadler at agric.uwa.edu.au
ERGO's web site:<http://www.botany.uwa.edu.au/ergo>



From ripley at stats.ox.ac.uk  Tue Jan 28 08:23:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 28 08:23:04 2003
Subject: [R] repeated measures: Greenhouse-Geisser correction
In-Reply-To: <F46VMb5UWgP1A83xiDd00015fea@hotmail.com>
Message-ID: <Pine.LNX.4.44.0301280716120.22450-100000@gannet.stats>

That's a kludge.  You can analyse such models in a principled way using
either summary.manova or lme, both of which model the correlation in the 
`repeated measures' rather than wish it away.

Could you try to use a more informative subject?  Although I knew what the
correction was, I have never called it that.

On Mon, 27 Jan 2003, Heleen Slagter wrote:

> I was wondering whether there are any packages that provide for the 
> Greenhouse-Geisser correction, an adjustment used in univariate repeated 
> measures when the sphericity assumption is violated (both numerator and 
> denominator degrees of freedom are multiplied by GG-epsilon, and the 
> significance of the F ratio is evaluated with the new degrees of freedom)? I 
> have seen a few emails with the same question, to which nobody replied, but 
> am hoping that maybe in the mean time somebody has tried to work this out.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From e.corda at oncfs.gouv.fr  Tue Jan 28 09:07:02 2003
From: e.corda at oncfs.gouv.fr (E. Corda)
Date: Tue Jan 28 09:07:02 2003
Subject: [R] [R]: Trellis plot
Message-ID: <3.0.1.32.20030128090446.006df3f4@mail.sky.fr>

Hello everybody,

I have found the solution to my problem. Instead of writing
> plot(mydata, outer = ~ treatment)

I should write 
> plot(mydata, outer = ~ mydata$treatment)


>"E. Corda" <e.corda at oncfs.gouv.fr> writes:
>
>> I would be grateful if anyone could help me with the following. I am using
>> nlme library and I am trying to do a trellis plot with an outer factor, but
>> I have an error message which I can't understand.
>> 
>> Here is the code :
>> 
>> > mydata <- groupedData(y ~ x | warren/rabbit, outer= ~ treatment,
>> data=mydata)
>> > plot(mydata)
>> # I obtain a plot with all rabbits displayed individually and no outer
factor.
>> > plot(mydata, outer = ~ treatment)
>> Error in order(na.last, decreasing, ...) : 
>>         Argument lengths differ
>> 
>> I use R 1.5.1 with Windows 2000.
>
>Could you upgrade to R-1.6.2 and try again?  There were a lot of
>changes to the nlme package since R version 1.5.1.  I'm not sure if
>this specific problem was fixed but it may have been.
>
>
Eve CORDA 
Office national de la chasse et de la faune sauvage
5, rue de Saint Thibault
SAINT-BENOIST
78610 AUFFARGIS
BP 20 - 78612 LE PERRAY EN YVELINES Cedex
FRANCE
Tel : +33 (0)1.30.46.60.64
Fax : +33 (0)1.30.46.60.99
Email : e.corda at oncfs.gouv.fr



From e.corda at oncfs.gouv.fr  Tue Jan 28 09:16:03 2003
From: e.corda at oncfs.gouv.fr (E. Corda)
Date: Tue Jan 28 09:16:03 2003
Subject: [R] [off] Statistical list
Message-ID: <3.0.1.32.20030128091350.006bb8d8@mail.sky.fr>

Ronaldo,

Do you know allstat? This is a statistical list where you receive
informations about seminars, workshops, jobs, courses, and you can also ask
statistical questions. See
http://www.jiscmail.ac.uk/
On this site you will find other lists which might interest you.

Best wishes,

Eve

>
>Hi all,
>
>Anybody know if exist a good statistical list?
>
>A list for discuss about different means to work in the same dataset. The 
>profit and cost of each mean. 
>
>Thanks for all
>Inte
>Ronaldo
>-- 
>	O fracasso e a oportunidade de comecar de novo 
>	inteligentemente
>--
>|   //|\\   [*****************************][*******************]
>|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
>|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
>||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
>|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
>||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
>|/ (linux) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
>||  ( x )   [*****************************][*******************]
>||| _/ \_Powered by Gnu/Debian Woody D+:) | Lxuser#: 205366
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
Eve CORDA 
Office national de la chasse et de la faune sauvage
5, rue de Saint Thibault
SAINT-BENOIST
78610 AUFFARGIS
BP 20 - 78612 LE PERRAY EN YVELINES Cedex
FRANCE
Tel : +33 (0)1.30.46.60.64
Fax : +33 (0)1.30.46.60.99
Email : e.corda at oncfs.gouv.fr



From phgrosjean at sciviews.org  Tue Jan 28 09:45:03 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue Jan 28 09:45:03 2003
Subject: [R] Irregular time series
In-Reply-To: <Pine.SOL.3.96.1030127213517.1045A-100000@libra.cus.cam.ac.uk>
Message-ID: <MABBLJDICACNFOLGIHJOOEPNDCAA.phgrosjean@sciviews.org>

You will find all required tools in the PASTECS library, including
regul.screen() and regul.adj() to determine best time step in the regular
series (with a maximum number of observations matching those in the initial
irregular series), and four different regulation methods: regconst(),
reglin(), regspline() and regarea(), all available in the more general
regul() function.
Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oceanologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



-----Original Message-----
From: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of Damon Wischik
Sent: lundi 27 janvier 2003 10:42
To: r-help at stat.math.ethz.ch
Subject: [R] Irregular time series



I have an irregular time series, stored as a data frame, in the form

    Time     Bytes
  57213.191  20
  57213.193  20
  57213.300  23
   ...       ...

How should I convert this into a regularly-spaced time series?
I have in mind to divide time into equal-sized intervals, and sum the
number of Bytes in each interval. I tried this:

its.to.ts <- function(times,values,delta=1) {
  m <- min(times)
  M <- max(times)
  mm <- delta*floor(m/delta)
  MM <- delta*ceiling(M/delta)
  cuts <- seq(from=mm,to=MM,by=delta)
  nullvals <- rep(0,length(cuts)-1)
  nulltimes <- cuts[-1]-delta/2
  time.factor <- cut(c(times,nulltimes),cuts,labels=FALSE)
  dd <- aggregate(c(values,nullvals),by=list(time=time.factor),sum)
  ts(data=dd$x,start=mm,deltat=delta)
  }

but it is very slow (for a data frame of 102,000 lines, converted into a
time series of 130,000 points). Is there a better way?

Damon Wischik.

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From susanabarbosa at novalis.fc.up.pt  Tue Jan 28 10:07:07 2003
From: susanabarbosa at novalis.fc.up.pt (Susana Barbosa)
Date: Tue Jan 28 10:07:07 2003
Subject: [R] Error from StructTS
Message-ID: <200301280911.56272.susanabarbosa@novalis.fc.up.pt>

Hi,

I used function  StructTS some time ago  to fit a structural model to a time 
series.

Now with R 1.6.2-1 I repeated the analysis with the same series and I get the 
following error:

Error in KalmanLike2(y, Z, -1) : invalid argument type

I tried with other series and I get the same error; I checked the examples in 
the documentation and they work fine. I suspect I am missing something 
here...

Any hints are welcome


Thank you in advance,

Susana Barbosa



From ripley at stats.ox.ac.uk  Tue Jan 28 10:35:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 28 10:35:03 2003
Subject: [R] Error from StructTS
In-Reply-To: <200301280911.56272.susanabarbosa@novalis.fc.up.pt>
Message-ID: <Pine.LNX.4.44.0301280925240.28301-100000@gannet.stats>

On Tue, 28 Jan 2003, Susana Barbosa wrote:

> I used function  StructTS some time ago  to fit a structural model to a time 
> series.
> 
> Now with R 1.6.2-1 I repeated the analysis with the same series and I get the 
> following error:
> 
> Error in KalmanLike2(y, Z, -1) : invalid argument type
> 
> I tried with other series and I get the same error; I checked the examples in 
> the documentation and they work fine. I suspect I am missing something 
> here...
> 
> Any hints are welcome

I don't think we can do anything at that level of information, and
StructTS has not been changed since its introduction!

Could you produce a small reproducible example exhibiting the problem?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From djw1005 at cam.ac.uk  Tue Jan 28 11:25:05 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Tue Jan 28 11:25:05 2003
Subject: [R] Irregular time series
In-Reply-To: <MABBLJDICACNFOLGIHJOOEPNDCAA.phgrosjean@sciviews.org>
Message-ID: <Pine.SOL.3.96.1030128101837.24135A-100000@libra.cus.cam.ac.uk>

>> I have an irregular time series, stored as a data frame, in the form
>>     Time     Bytes
>>   57213.191  20
>>   57213.193  20
>>   57213.300  23
>>    ...       ...
>> How should I convert this into a regularly-spaced time series?
>> I have in mind to divide time into equal-sized intervals, and sum the
>> number of Bytes in each interval. I tried this: ... 

Philippe Grosjean wrote:
> You will find all required tools in the PASTECS library, including
> regul.screen() and regul.adj() to determine best time step in the regular
> series (with a maximum number of observations matching those in the initial
> irregular series), and four different regulation methods: regconst(),
> reglin(), regspline() and regarea(), all available in the more general
> regul() function.

Thank you for the link. As I understand them, none of those regulation
methods achieve what I want. I want to divide time into equal-sized
intervals, and sum the number of bytes arriving in each interval. I do not
want any sort of interpolation of existing values. Those four regulation
methods are all different types of interpolation, if I understand
correctly.

My dataset represents a point arrival process, not a sample of a
continuous process; I want to turn the continuous-time point arrival
process into a discrete-time point arrival process. I am looking for a
function which has the same effect as, but is faster than, this: 

> its.to.ts <- function(times,values,delta=1) {
>   m <- min(times)
>   M <- max(times)
>   mm <- delta*floor(m/delta)
>   MM <- delta*ceiling(M/delta)
>   cuts <- seq(from=mm,to=MM,by=delta)
>   nullvals <- rep(0,length(cuts)-1)
>   nulltimes <- cuts[-1]-delta/2
>   time.factor <- cut(c(times,nulltimes),cuts,labels=FALSE)
>   dd <- aggregate(c(values,nullvals),by=list(time=time.factor),sum)
>   ts(data=dd$x,start=mm,deltat=delta)
>   }

Damon Wischik.



From susanabarbosa at novalis.fc.up.pt  Tue Jan 28 12:20:03 2003
From: susanabarbosa at novalis.fc.up.pt (Susana Barbosa)
Date: Tue Jan 28 12:20:03 2003
Subject: [R] Error from StructTS
In-Reply-To: <Pine.LNX.4.44.0301280925240.28301-100000@gannet.stats>
References: <Pine.LNX.4.44.0301280925240.28301-100000@gannet.stats>
Message-ID: <200301281125.26163.susanabarbosa@novalis.fc.up.pt>


Thank you for your reply.
I am sending  a sample time series (not too long I hope!).

With the input:
load("ts1")
StructTS(ts1, type="BSM")

I get the following error:
Error in KalmanLike2(y, Z, -1) : invalid argument type

Thank you!

Susana Barbosa

(R installed from rpm - Linux Mandrake 9.0)
Details:
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.2
year     2003
month    01
day      10
language R





-------------- next part --------------
A non-text attachment was scrubbed...
Name: ts1
Type: application/octet-stream
Size: 1008 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030128/1f36d547/ts1.obj

From p.dalgaard at biostat.ku.dk  Tue Jan 28 12:26:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Jan 28 12:26:03 2003
Subject: [R] Irregular time series
In-Reply-To: <Pine.SOL.3.96.1030128101837.24135A-100000@libra.cus.cam.ac.uk>
References: <Pine.SOL.3.96.1030128101837.24135A-100000@libra.cus.cam.ac.uk>
Message-ID: <x2wukpo70e.fsf@biostat.ku.dk>

Damon Wischik <djw1005 at cam.ac.uk> writes:

> 
> My dataset represents a point arrival process, not a sample of a
> continuous process; I want to turn the continuous-time point arrival
> process into a discrete-time point arrival process. I am looking for a
> function which has the same effect as, but is faster than, this: 
> 
> > its.to.ts <- function(times,values,delta=1) {
> >   m <- min(times)
> >   M <- max(times)
> >   mm <- delta*floor(m/delta)
> >   MM <- delta*ceiling(M/delta)
> >   cuts <- seq(from=mm,to=MM,by=delta)
> >   nullvals <- rep(0,length(cuts)-1)
> >   nulltimes <- cuts[-1]-delta/2
> >   time.factor <- cut(c(times,nulltimes),cuts,labels=FALSE)
> >   dd <- aggregate(c(values,nullvals),by=list(time=time.factor),sum)
> >   ts(data=dd$x,start=mm,deltat=delta)
> >   }

Hmmm. I'm not going to dig into your code just now, but suppose you used
something like 

diff(approx(times,cumsum(values),xout=cuts, method="constant"))

There are probably some end effects that you need to consider more
carefully. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From dmurdoch at pair.com  Tue Jan 28 12:35:03 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue Jan 28 12:35:03 2003
Subject: [R] google
In-Reply-To: <3E35C243.60503@manas.kg>
References: <Pine.GSO.4.10.10301270051160.15591-100000@athena.biostat.jhsph.edu> <3E34ECBE.4000401@stats.waikato.ac.nz> <3E3519BD.1020606@lancaster.ac.uk> <3E35C243.60503@manas.kg>
Message-ID: <7kqc3v8mjv5rtt3ah3nv9rot8edmqtrql5@4ax.com>

On Mon, 27 Jan 2003 18:35:31 -0500, you wrote:

>W takes to White House :)
>
>No I din't try others. W is my daughter's favorite letter!

C takes you to CNET, not to that other one letter language.  So now
it's official:  R is more popular than C! :-)

Duncan Murdoch



From ripley at stats.ox.ac.uk  Tue Jan 28 13:06:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 28 13:06:03 2003
Subject: [R] Error from StructTS
In-Reply-To: <200301281125.26163.susanabarbosa@novalis.fc.up.pt>
Message-ID: <Pine.LNX.4.44.0301281201230.28718-100000@gannet.stats>

Your series is made up of integers, not doubles.  Try

> storage.mode(ts1) <- "double"

and it will work.  I don't think anything has changed here since 1.5.0.


On Tue, 28 Jan 2003, Susana Barbosa wrote:

> 
> Thank you for your reply.
> I am sending  a sample time series (not too long I hope!).
> 
> With the input:
> load("ts1")
> StructTS(ts1, type="BSM")
> 
> I get the following error:
> Error in KalmanLike2(y, Z, -1) : invalid argument type
> 
> Thank you!
> 
> Susana Barbosa
> 
> (R installed from rpm - Linux Mandrake 9.0)
> Details:
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R
> 
> 
> 
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From susanabarbosa at novalis.fc.up.pt  Tue Jan 28 13:12:06 2003
From: susanabarbosa at novalis.fc.up.pt (Susana Barbosa)
Date: Tue Jan 28 13:12:06 2003
Subject: [R] Error from StructTS: solved
In-Reply-To: <Pine.LNX.4.44.0301281201230.28718-100000@gannet.stats>
References: <Pine.LNX.4.44.0301281201230.28718-100000@gannet.stats>
Message-ID: <200301281217.00577.susanabarbosa@novalis.fc.up.pt>




> Your series is made up of integers, not doubles.  Try
>
> > storage.mode(ts1) <- "double"
>
> and it will work.  I don't think anything has changed here since 1.5.0.
>



From susanabarbosa at novalis.fc.up.pt  Tue Jan 28 13:16:06 2003
From: susanabarbosa at novalis.fc.up.pt (Susana Barbosa)
Date: Tue Jan 28 13:16:06 2003
Subject: [R] Error from StructTS: Solved
In-Reply-To: <Pine.LNX.4.44.0301281201230.28718-100000@gannet.stats>
References: <Pine.LNX.4.44.0301281201230.28718-100000@gannet.stats>
Message-ID: <200301281219.34866.susanabarbosa@novalis.fc.up.pt>

Problem solved.
Thank you!

Susana

(sorry for double posting) :-)


> Your series is made up of integers, not doubles.  Try
>
> > storage.mode(ts1) <- "double"
>
> and it will work.  I don't think anything has changed here since 1.5.0.
>



From a.kraayeveld at imperial.ac.uk  Tue Jan 28 13:53:02 2003
From: a.kraayeveld at imperial.ac.uk (Alex R. Kraaijeveld)
Date: Tue Jan 28 13:53:02 2003
Subject: [R] memory problems
Message-ID: <5.1.0.14.0.20030128124530.01a990c0@icex7.cc.ic.ac.uk>

Hi all

New to R, and to this list, so this may be an old (and hopefully simple to 
solve!) problem.

When running an aov analysis, after fitting two-way interactions, I get an 
error message saying 'can not allocate vector of 8515Kb'. Often other 
programs are then kicked out of memory or the whole computer crashes. I've 
tried bumping up memory by adding max-mem-size, max-vsize, min-vsize, 
max-nsize, min-nsize, etc commands (with parameter values up to 1G)  to the 
start-up line, but that either doesn't work or makes matters worse (i.e 
analysis crashes earlier).

Our computer support officer here has looked at the problem and he does not 
believe it has to do with the actual amount of physical RAM of my machine, 
but more with the way R handles memory. I run R under Windows NT, by the way.

Any suggestions as to what I'm doing wrong?

Thanks for any help!
Lex




~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Dr Alex R. Kraaijeveld

NERC Centre for Population Biology
Imperial College London, Silwood Park Campus
Ascot, Berkshire SL5 7PY
England, UK
tel:  +44-(0)20-75942544
fax: +44-(0)1344-873173
e-mail: a.kraayeveld at imperial.ac.uk
http://www.cpb.bio.ic.ac.uk/staff/kraaijeveld/lkraaijeveld.html

Cloonaughill Celtic Malts
http://www.celticmalts.com/edge.htm
http://www.celticmalts.com/journal.htm
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From bojaniss at poczta.onet.pl  Tue Jan 28 14:27:06 2003
From: bojaniss at poczta.onet.pl (Michal Bojanowski)
Date: Tue Jan 28 14:27:06 2003
Subject: [R] iterative proportional fitting in R?
In-Reply-To: <Pine.SOL.4.51.0301271807360.24772@herald.cc.purdue.edu>
References: <Pine.SOL.4.51.0301271807360.24772@herald.cc.purdue.edu>
Message-ID: <49571478.20030128142052@poczta.onet.pl>

Hello nels.tomlinson,

Tuesday, January 28, 2003, 1:03:12 AM, you wrote:

nt1> Is there some package in R which does this adjustment, by any means?

I guess you could do it via loglinear model:

Look at ?loglin in base package as well as ?loglm in MASS package
for formula interface to loglin().


I hope that this helps.


Michal


~,~`~,~`~,~`~,~`~,~`~,~
Micha? Bojanowski
bojaniss at poczta.onet.pl



***************r-e-k-l-a-m-a**************

Chcesz oszcz?dzi? na kosztach obs?ugi bankowej ?
mBIZNES - konto dla firm
http://epieniadze.onet.pl/mbiznes



From debene at unimc.it  Tue Jan 28 15:58:02 2003
From: debene at unimc.it (Luca De Benedictis)
Date: Tue Jan 28 15:58:02 2003
Subject: [R] gray color in trellis xyplot
Message-ID: <3E369AE6.E73903A3@unimc.it>

Dear all,
if gray is the background collor of a trellis xyplot (in the lattice
library) and  I would like to switch to white, what I have to do?
Why dark gray was chosen as the default color?
Many thanks for the help.
Luca



From Christian.Stratowa at vie.boehringer-ingelheim.com  Tue Jan 28 16:04:06 2003
From: Christian.Stratowa at vie.boehringer-ingelheim.com (Christian.Stratowa@vie.boehringer-ingelheim.com)
Date: Tue Jan 28 16:04:06 2003
Subject: [R] reading non-existent files
Message-ID: <AF7DB4C757D2D2119C080001FA7E56B204944E54@VIEEXCH2.vie.at.bic>

Dear R-experts

I would like to read all files from a directory, the files have names
"myname0001.txt" etc. I paste the directory plus file names and
use "read.delim()".
My problem is that some file names are missing, so I get an error
and my program stops.
Is there a way to check for a null pointer analogous to C, so that
I can simply skip non-existent filenames?

Please do "Reply to all" since in the company I am not subscribed
to the R-help list.

Thank you in advance
Best regards
Christian Stratowa

==============================================
Christian Stratowa, PhD
Boehringer Ingelheim Austria
Dept NCE Lead Discovery - Bioinformatics
Dr. Boehringergasse 5-11
A-1121 Vienna, Austria
Tel.: ++43-1-80105-2470
Fax: ++43-1-80105-2683
email: christian.stratowa at vie.boehringer-ingelheim.com



From ben at zoo.ufl.edu  Tue Jan 28 16:08:03 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue Jan 28 16:08:03 2003
Subject: [R] reading non-existent files
In-Reply-To: <AF7DB4C757D2D2119C080001FA7E56B204944E54@VIEEXCH2.vie.at.bic>
Message-ID: <Pine.LNX.4.44.0301281014260.22133-100000@bolker.zoo.ufl.edu>

  ?file.exists

On Tue, 28 Jan 2003 Christian.Stratowa at vie.boehringer-ingelheim.com wrote:

> Dear R-experts
> 
> I would like to read all files from a directory, the files have names
> "myname0001.txt" etc. I paste the directory plus file names and
> use "read.delim()".
> My problem is that some file names are missing, so I get an error
> and my program stops.
> Is there a way to check for a null pointer analogous to C, so that
> I can simply skip non-existent filenames?
> 
> Please do "Reply to all" since in the company I am not subscribed
> to the R-help list.
> 
> Thank you in advance
> Best regards
> Christian Stratowa
> 
> ==============================================
> Christian Stratowa, PhD
> Boehringer Ingelheim Austria
> Dept NCE Lead Discovery - Bioinformatics
> Dr. Boehringergasse 5-11
> A-1121 Vienna, Austria
> Tel.: ++43-1-80105-2470
> Fax: ++43-1-80105-2683
> email: christian.stratowa at vie.boehringer-ingelheim.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From Christian.Stratowa at vie.boehringer-ingelheim.com  Tue Jan 28 16:12:04 2003
From: Christian.Stratowa at vie.boehringer-ingelheim.com (Christian.Stratowa@vie.boehringer-ingelheim.com)
Date: Tue Jan 28 16:12:04 2003
Subject: [R] reading non-existent files
Message-ID: <AF7DB4C757D2D2119C080001FA7E56B204944E55@VIEEXCH2.vie.at.bic>

Great, thank you for the fast reply

Regards
Christian Stratowa

==============================================
Christian Stratowa, PhD
Boehringer Ingelheim Austria
Dept NCE Lead Discovery - Bioinformatics
Dr. Boehringergasse 5-11
A-1121 Vienna, Austria
Tel.: ++43-1-80105-2470
Fax: ++43-1-80105-2683
email: christian.stratowa at vie.boehringer-ingelheim.com

> -----Original Message-----
> From:	Ben Bolker [SMTP:ben at zoo.ufl.edu]
> Sent:	Tuesday, January 28, 2003 4:15 PM
> To:	Stratowa,Dr,Christian   FEX BIG-AT-V
> Cc:	r-help at stat.math.ethz.ch
> Subject:	Re: [R] reading non-existent files
> 
> 
>   ?file.exists
> 
> On Tue, 28 Jan 2003 Christian.Stratowa at vie.boehringer-ingelheim.com wrote:
> 
> > Dear R-experts
> > 
> > I would like to read all files from a directory, the files have names
> > "myname0001.txt" etc. I paste the directory plus file names and
> > use "read.delim()".
> > My problem is that some file names are missing, so I get an error
> > and my program stops.
> > Is there a way to check for a null pointer analogous to C, so that
> > I can simply skip non-existent filenames?
> > 
> > Please do "Reply to all" since in the company I am not subscribed
> > to the R-help list.
> > 
> > Thank you in advance
> > Best regards
> > Christian Stratowa
> > 
> > ==============================================
> > Christian Stratowa, PhD
> > Boehringer Ingelheim Austria
> > Dept NCE Lead Discovery - Bioinformatics
> > Dr. Boehringergasse 5-11
> > A-1121 Vienna, Austria
> > Tel.: ++43-1-80105-2470
> > Fax: ++43-1-80105-2683
> > email: christian.stratowa at vie.boehringer-ingelheim.com
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> -- 
> 318 Carr Hall                                bolker at zoo.ufl.edu
> Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
> Box 118525                                   (ph)  352-392-5697
> Gainesville, FL 32611-8525                   (fax) 352-392-3704



From Jesus.Frias at dit.ie  Tue Jan 28 16:15:37 2003
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Tue Jan 28 16:15:37 2003
Subject: [R] reading non-existent files
In-Reply-To: <AF7DB4C757D2D2119C080001FA7E56B204944E54@VIEEXCH2.vie.at.bic>
Message-ID: <LGECJJCANFBOOHCMGPJEMEHOCFAA.Jesus.Frias@dit.ie>

Hi Christian,

	I suppose that you are doing this in a loop and is stopping.

	Have a look at the function try()

?try

Try an Expression Allowing Error Recovery.

Description:

     `try' is a wrapper to run an expression that might fail and allow
     the user's code to handle error-recovery.

Usage:

     try(expr, first = TRUE)


regards,

Jesus

--------------------------------------------------------------
Jes?s Mar?a Fr?as Celayeta
School of Food Sci. and Env. Health.
Faculty of Tourism and Food
Dublin Institute of Technology
Cathal Bruha St., Dublin 1. Ireland
Phone: +353 1 4024459 Fax: +353 1 4024495
http://www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch
> [mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of
> Christian.Stratowa at vie.boehringer-ingelheim.com
> Sent: 28 January 2003 14:59
> To: r-help at stat.math.ethz.ch
> Subject: [R] reading non-existent files
>
>
> Dear R-experts
>
> I would like to read all files from a directory, the files have names
> "myname0001.txt" etc. I paste the directory plus file names and
> use "read.delim()".
> My problem is that some file names are missing, so I get an error
> and my program stops.
> Is there a way to check for a null pointer analogous to C, so that
> I can simply skip non-existent filenames?
>
> Please do "Reply to all" since in the company I am not subscribed
> to the R-help list.
>
> Thank you in advance
> Best regards
> Christian Stratowa
>
> ==============================================
> Christian Stratowa, PhD
> Boehringer Ingelheim Austria
> Dept NCE Lead Discovery - Bioinformatics
> Dr. Boehringergasse 5-11
> A-1121 Vienna, Austria
> Tel.: ++43-1-80105-2470
> Fax: ++43-1-80105-2683
> email: christian.stratowa at vie.boehringer-ingelheim.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> --
> This message has been scanned for viruses by
> the DIT Computer Centre MailScanner Service,
> and is believed to be clean.
>


-- 
This message has been scanned for viruses by
the DIT Computer Centre MailScanner Service, 
and is believed to be clean.



From ripley at stats.ox.ac.uk  Tue Jan 28 16:20:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 28 16:20:03 2003
Subject: [R] reading non-existent files
In-Reply-To: <AF7DB4C757D2D2119C080001FA7E56B204944E54@VIEEXCH2.vie.at.bic>
Message-ID: <Pine.LNX.4.44.0301281510060.4212-100000@gannet.stats>

On Tue, 28 Jan 2003 Christian.Stratowa at vie.boehringer-ingelheim.com wrote:

> I would like to read all files from a directory, the files have names
> "myname0001.txt" etc. I paste the directory plus file names and
> use "read.delim()".
> My problem is that some file names are missing, so I get an error
> and my program stops.

How can some of `all files from a directory' be missing?  Why not read 
them via e.g. list.files()?

> Is there a way to check for a null pointer analogous to C, so that
> I can simply skip non-existent filenames?

?file.exists

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mschwartz at medanalytics.com  Tue Jan 28 16:23:38 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue Jan 28 16:23:38 2003
Subject: [R] reading non-existent files
In-Reply-To: <AF7DB4C757D2D2119C080001FA7E56B204944E54@VIEEXCH2.vie.at.bic>
Message-ID: <004e01c2c6df$aeac9db0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of 
>Christian.Stratowa at vie.boehringer-ingelheim.com
>Sent: Tuesday, January 28, 2003 8:59 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] reading non-existent files
>
>
>Dear R-experts
>
>I would like to read all files from a directory, the files 
>have names "myname0001.txt" etc. I paste the directory plus 
>file names and use "read.delim()". My problem is that some 
>file names are missing, so I get an error and my program 
>stops. Is there a way to check for a null pointer analogous to 
>C, so that I can simply skip non-existent filenames?
>
>Please do "Reply to all" since in the company I am not 
>subscribed to the R-help list.
>
>Thank you in advance
>Best regards
>Christian Stratowa

You could use file.exists() which returns a TRUE/FALSE to see if the
file is present or perhaps list.files() which will return a character
vector of existing files based upon a regex pattern matching string.

HTH,

Marc



From Christian.Stratowa at vie.boehringer-ingelheim.com  Tue Jan 28 16:29:03 2003
From: Christian.Stratowa at vie.boehringer-ingelheim.com (Christian.Stratowa@vie.boehringer-ingelheim.com)
Date: Tue Jan 28 16:29:03 2003
Subject: [R] reading non-existent files
Message-ID: <AF7DB4C757D2D2119C080001FA7E56B204944E56@VIEEXCH2.vie.at.bic>

Dear All

Thank you all for your fast help, the solutions that I have received are:
file.exists()
try()
allFiles<-list.files(mydir)

Best regards
Christian Stratowa

==============================================
Christian Stratowa, PhD
Boehringer Ingelheim Austria
Dept NCE Lead Discovery - Bioinformatics
Dr. Boehringergasse 5-11
A-1121 Vienna, Austria
Tel.: ++43-1-80105-2470
Fax: ++43-1-80105-2683
email: christian.stratowa at vie.boehringer-ingelheim.com

> -----Original Message-----
> From:	ripley at stats.ox.ac.uk [SMTP:ripley at stats.ox.ac.uk]
> Sent:	Tuesday, January 28, 2003 4:20 PM
> To:	Stratowa,Dr,Christian   FEX BIG-AT-V
> Cc:	r-help at stat.math.ethz.ch
> Subject:	Re: [R] reading non-existent files
> 
> On Tue, 28 Jan 2003 Christian.Stratowa at vie.boehringer-ingelheim.com wrote:
> 
> > I would like to read all files from a directory, the files have names
> > "myname0001.txt" etc. I paste the directory plus file names and
> > use "read.delim()".
> > My problem is that some file names are missing, so I get an error
> > and my program stops.
> 
> How can some of `all files from a directory' be missing?  Why not read 
> them via e.g. list.files()?
> 
> > Is there a way to check for a null pointer analogous to C, so that
> > I can simply skip non-existent filenames?
> 
> ?file.exists
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From lm.silva at sapo.pt  Tue Jan 28 16:43:02 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Tue Jan 28 16:43:02 2003
Subject: [R] symbol
Message-ID: <1043768547.3e36a4e3e6fba@webmail.sapo.pt>

Dear R helpers

I would like to make a plot where the symbols were the numbers 
of the corresponding classes, i.e, samples of class 1 would the 
symbol 1, samples of class 2 would have symbol 2,....

Is this possible?

Thank you

Luis
--
Kit SAPO.ADSL.PT Apenas 50 ?.
Adira j? em http://www.sapo.pt/kitadsl



From bates at stat.wisc.edu  Tue Jan 28 17:01:06 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue Jan 28 17:01:06 2003
Subject: [R] gray color in trellis xyplot
In-Reply-To: <3E369AE6.E73903A3@unimc.it>
References: <3E369AE6.E73903A3@unimc.it>
Message-ID: <6rvg094633.fsf@bates4.stat.wisc.edu>

Luca De Benedictis <debene at unimc.it> writes:

> Dear all,
> if gray is the background collor of a trellis xyplot (in the lattice
> library) and  I would like to switch to white, what I have to do?

lset(col.whitebg())

> Why dark gray was chosen as the default color?

compatibility with the original trellis graphics implementation.



From lm.silva at sapo.pt  Tue Jan 28 17:06:04 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Tue Jan 28 17:06:04 2003
Subject: [R] symbol
In-Reply-To: <OF50C06312.A48A2835-ON80256CBC.0056CD6E@bnpparibas.com>
References: <OF50C06312.A48A2835-ON80256CBC.0056CD6E@bnpparibas.com>
Message-ID: <1043769895.3e36aa275f882@webmail.sapo.pt>

Ok, this works. But I have this problem. I have a loop to make 
each plot. Like this:

plot(class 1, pch='1',...)
for j (in 2:n)
points(class 2, pch='j',...)
...

of course pch='j' doesn't work. It generates other symbols. I 
accept also different colors instead of numbers


} 
} try this:
} 
} x<- rnorm(100)
} plot(x, pch='1')
} 
} huan
} 
} 
} 
} Internet
} lm.silva at sapo.pt@stat.math.ethz.ch - 01/28/2003 03:42
} PM
} 
} 
} Sent by:    r-help-admin at stat.math.ethz.ch
} 
} To:    r-help
} 
} cc:
} 
} 
} Subject:    [R] symbol
} 
} 
} Dear R helpers
} 
} I would like to make a plot where the symbols were
} the numbers
} of the corresponding classes, i.e, samples of class 1
} would the
} symbol 1, samples of class 2 would have symbol
} 2,....
} 
} Is this possible?
} 
} Thank you
} 
} Luis
} --
} Kit SAPO.ADSL.PT Apenas 50 ?.
} Adira j? em http://www.sapo.pt/kitadsl
} 
} ______________________________________________
} R-help at stat.math.ethz.ch mailing list
}
} http://www.stat.math.ethz.ch/mailman/listinfo/r-help
} 
} 
} 
} 
} 
} 
} This message and any attachments (the "message") is
} intended solely for the addressees and is
} confidential. 
} If you receive this message in error, please delete
} it and 
} immediately notify the sender. Any use not in accord
} with 
} its purpose, any dissemination or disclosure, either
} whole 
} or partial, is prohibited except formal approval. The
} internet
} can not guarantee the integrity of this message. 
} BNP PARIBAS (and its subsidiaries) shall (will) not
} 
} therefore be liable for the message if modified. 
} 
}                
} ---------------------------------------------
} 
} Ce message et toutes les pieces jointes (ci-apres le
} 
} "message") sont etablis a l'intention exclusive de
} ses 
} destinataires et sont confidentiels. Si vous recevez
} ce 
} message par erreur, merci de le detruire et d'en
} avertir 
} immediatement l'expediteur. Toute utilisation de ce
} 
} message non conforme a sa destination, toute
} diffusion 
} ou toute publication, totale ou partielle, est
} interdite, sauf 
} autorisation expresse. L'internet ne permettant pas
} 
} d'assurer l'integrite de ce message, BNP PARIBAS (et
} ses
} filiales) decline(nt) toute responsabilite au titre
} de ce 
} message, dans l'hypothese ou il aurait ete modifie.
} 
} 

--
Kit SAPO.ADSL.PT Apenas 50 ?.
Adira j? em http://www.sapo.pt/kitadsl



From rabaieremon at hotmail.com  Tue Jan 28 17:09:40 2003
From: rabaieremon at hotmail.com (Rabaie Remon)
Date: Tue Jan 28 17:09:40 2003
Subject: [R] Help!!
Message-ID: <F171eRaNgEpTX5V3Gyk00000356@hotmail.com>

Dear R ers, if some can tel me how I can generate a sample from a given 
density. I have a complex  2D density function en I want to genearte
a sample from it? Any package?

Thank you
Remon ,Utrecht




_________________________________________________________________
Tired of spam? Get advanced junk mail protection with MSN 8.



From sundar.dorai-raj at pdf.com  Tue Jan 28 17:14:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue Jan 28 17:14:03 2003
Subject: [R] symbol
References: <OF50C06312.A48A2835-ON80256CBC.0056CD6E@bnpparibas.com> <1043769895.3e36aa275f882@webmail.sapo.pt>
Message-ID: <3E36AC2C.8060404@pdf.com>

use text instead:

plot(x, y, type = "n")
text(x, y, labels = class.label)

Regards,
Sundar

Luis Silva wrote:
> Ok, this works. But I have this problem. I have a loop to make 
> each plot. Like this:
> 
> plot(class 1, pch='1',...)
> for j (in 2:n)
> points(class 2, pch='j',...)
> ...
> 
> of course pch='j' doesn't work. It generates other symbols. I 
> accept also different colors instead of numbers
> 
> 
> } 
> } try this:
> } 
> } x<- rnorm(100)
> } plot(x, pch='1')
> } 
> } huan
> } 
> } 
> } 
> } Internet
> } lm.silva at sapo.pt@stat.math.ethz.ch - 01/28/2003 03:42
> } PM
> } 
> } 
> } Sent by:    r-help-admin at stat.math.ethz.ch
> } 
> } To:    r-help
> } 
> } cc:
> } 
> } 
> } Subject:    [R] symbol
> } 
> } 
> } Dear R helpers
> } 
> } I would like to make a plot where the symbols were
> } the numbers
> } of the corresponding classes, i.e, samples of class 1
> } would the
> } symbol 1, samples of class 2 would have symbol
> } 2,....
> } 
> } Is this possible?
> } 
> } Thank you
> } 
> } Luis
> } --
> } Kit SAPO.ADSL.PT Apenas 50 ?.
> } Adira j? em http://www.sapo.pt/kitadsl
> } 
> } ______________________________________________
> } R-help at stat.math.ethz.ch mailing list
> }
> } http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> } 
> } 
> } 
> } 
> } 
> } 
> } This message and any attachments (the "message") is
> } intended solely for the addressees and is
> } confidential. 
> } If you receive this message in error, please delete
> } it and 
> } immediately notify the sender. Any use not in accord
> } with 
> } its purpose, any dissemination or disclosure, either
> } whole 
> } or partial, is prohibited except formal approval. The
> } internet
> } can not guarantee the integrity of this message. 
> } BNP PARIBAS (and its subsidiaries) shall (will) not
> } 
> } therefore be liable for the message if modified. 
> } 
> }                
> } ---------------------------------------------
> } 
> } Ce message et toutes les pieces jointes (ci-apres le
> } 
> } "message") sont etablis a l'intention exclusive de
> } ses 
> } destinataires et sont confidentiels. Si vous recevez
> } ce 
> } message par erreur, merci de le detruire et d'en
> } avertir 
> } immediatement l'expediteur. Toute utilisation de ce
> } 
> } message non conforme a sa destination, toute
> } diffusion 
> } ou toute publication, totale ou partielle, est
> } interdite, sauf 
> } autorisation expresse. L'internet ne permettant pas
> } 
> } d'assurer l'integrite de ce message, BNP PARIBAS (et
> } ses
> } filiales) decline(nt) toute responsabilite au titre
> } de ce 
> } message, dans l'hypothese ou il aurait ete modifie.
> } 
> } 
> 
> --
> Kit SAPO.ADSL.PT Apenas 50 ?.
> Adira j? em http://www.sapo.pt/kitadsl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jfox at mcmaster.ca  Tue Jan 28 17:21:02 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue Jan 28 17:21:02 2003
Subject: [R] symbol
In-Reply-To: <1043768547.3e36a4e3e6fba@webmail.sapo.pt>
Message-ID: <5.1.0.14.2.20030128111511.01e46a98@mcmail.cis.mcmaster.ca>

Dear Luis,

You can use the pch argument to plot; assuming that class is numeric and 
consists of single-digit integers, you could specify something like plot( 
...., pch=as.character(class)). If class is a factor, you could substitute 
pch=as.character(as.numeric(type)).

I hope that this helps,
  John

At 03:42 PM 1/28/2003 +0000, Luis Silva wrote:
>Dear R helpers
>
>I would like to make a plot where the symbols were the numbers
>of the corresponding classes, i.e, samples of class 1 would the
>symbol 1, samples of class 2 would have symbol 2,....
>
>Is this possible?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From sundar.dorai-raj at pdf.com  Tue Jan 28 17:25:07 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue Jan 28 17:25:07 2003
Subject: [R] symbol
References: <OF50C06312.A48A2835-ON80256CBC.0056CD6E@bnpparibas.com> <1043769895.3e36aa275f882@webmail.sapo.pt> <3E36AC2C.8060404@pdf.com>
Message-ID: <3E36AE60.3010902@pdf.com>

Sorry, misread the question...

Sundar Dorai-Raj wrote:
> use text instead:
> 
> plot(x, y, type = "n")
> text(x, y, labels = class.label)
> 
> Regards,
> Sundar
> 
> Luis Silva wrote:
> 
>> Ok, this works. But I have this problem. I have a loop to make each 
>> plot. Like this:
>>
>> plot(class 1, pch='1',...)
>> for j (in 2:n)
>> points(class 2, pch='j',...)
>> ...
>>
>> of course pch='j' doesn't work. It generates other symbols. I accept 
>> also different colors instead of numbers
>>
>>
>> } } try this:
>> } } x<- rnorm(100)
>> } plot(x, pch='1')
>> } } huan
>> } } } } Internet
>> } lm.silva at sapo.pt@stat.math.ethz.ch - 01/28/2003 03:42
>> } PM
>> } } } Sent by:    r-help-admin at stat.math.ethz.ch
>> } } To:    r-help
>> } } cc:
>> } } } Subject:    [R] symbol
>> } } } Dear R helpers
>> } } I would like to make a plot where the symbols were
>> } the numbers
>> } of the corresponding classes, i.e, samples of class 1
>> } would the
>> } symbol 1, samples of class 2 would have symbol
>> } 2,....
>> } } Is this possible?
>> } } Thank you
>> } } Luis
>> } --
>> } Kit SAPO.ADSL.PT Apenas 50 ?.
>> } Adira j? em http://www.sapo.pt/kitadsl
>> } } ______________________________________________
>> } R-help at stat.math.ethz.ch mailing list
>> }
>> } http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> } } } } } } } This message and any attachments (the "message") is
>> } intended solely for the addressees and is
>> } confidential. } If you receive this message in error, please delete
>> } it and } immediately notify the sender. Any use not in accord
>> } with } its purpose, any dissemination or disclosure, either
>> } whole } or partial, is prohibited except formal approval. The
>> } internet
>> } can not guarantee the integrity of this message. } BNP PARIBAS (and 
>> its subsidiaries) shall (will) not
>> } } therefore be liable for the message if modified. } 
>> }                } ---------------------------------------------
>> } } Ce message et toutes les pieces jointes (ci-apres le
>> } } "message") sont etablis a l'intention exclusive de
>> } ses } destinataires et sont confidentiels. Si vous recevez
>> } ce } message par erreur, merci de le detruire et d'en
>> } avertir } immediatement l'expediteur. Toute utilisation de ce
>> } } message non conforme a sa destination, toute
>> } diffusion } ou toute publication, totale ou partielle, est
>> } interdite, sauf } autorisation expresse. L'internet ne permettant pas
>> } } d'assurer l'integrite de ce message, BNP PARIBAS (et
>> } ses
>> } filiales) decline(nt) toute responsabilite au titre
>> } de ce } message, dans l'hypothese ou il aurait ete modifie.
>> } }
>> -- 
>> Kit SAPO.ADSL.PT Apenas 50 ?.
>> Adira j? em http://www.sapo.pt/kitadsl
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From lm.silva at sapo.pt  Tue Jan 28 17:28:54 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Tue Jan 28 17:28:54 2003
Subject: [R] symbol ok colors?
Message-ID: <1043771023.3e36ae8fe0edb@webmail.sapo.pt>

Thanks to all! as.character solved my problem. And if I wanted 
different colors instead?

Luis
--
Kit SAPO.ADSL.PT Apenas 50 ?.
Adira j? em http://www.sapo.pt/kitadsl



From tlumley at u.washington.edu  Tue Jan 28 17:34:02 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Jan 28 17:34:02 2003
Subject: [R] symbol
In-Reply-To: <1043769895.3e36aa275f882@webmail.sapo.pt>
Message-ID: <Pine.A41.4.44.0301280823450.157244-100000@homer04.u.washington.edu>

On Tue, 28 Jan 2003, Luis Silva wrote:

> Ok, this works. But I have this problem. I have a loop to make
> each plot. Like this:
>
> plot(class 1, pch='1',...)
> for j (in 2:n)
> points(class 2, pch='j',...)
> ...
>
> of course pch='j' doesn't work. It generates other symbols. I
> accept also different colors instead of numbers

pch='j' doesn't do what you want because 'j' is a fixed letter not a
a variable want pch=j or pch=as.character(j).

Also, you can do this in one plot() command. For example, using the iris
dataset

data(iris)
plot(Sepal.Length~Petal.Length,pch=as.numeric(Species),data=iris)
or colours as well
plot(Sepal.Length~Petal.Length,pch=as.numeric(Species),col=as.numeric(Species),data=iris)

	-thomas



From jfox at mcmaster.ca  Tue Jan 28 18:17:02 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue Jan 28 18:17:02 2003
Subject: [R] symbol ok colors?
In-Reply-To: <1043771023.3e36ae8fe0edb@webmail.sapo.pt>
Message-ID: <5.1.0.14.2.20030128121158.01e4b048@mcmail.cis.mcmaster.ca>

Dear Luis,

At 04:23 PM 1/28/2003 +0000, Luis Silva wrote:
>Thanks to all! as.character solved my problem. And if I wanted
>different colors instead?


The argument col is also vectorized, so something like plot( ...., 
col=class) will work if class consists of small intergers. Alternatively, 
use class to index a vector of colors, as in col=c("red", "green", 
"blue")[class].

John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From malbani at fas.harvard.edu  Tue Jan 28 18:25:03 2003
From: malbani at fas.harvard.edu (Marco Albani)
Date: Tue Jan 28 18:25:03 2003
Subject: [R] Plot to postscript in function
Message-ID: <3E36BBB6.7070002@fas.harvard.edu>

Hello,

I am having problems with plotting to a postscript device within a 
function call.

When I do the same thing line by line in the command line interface, I 
have no problems, but the function creates an empty postscript file.
If I remove the dev.off() call at the end of the function, I get one of 
the plots (the last), but not the others.

Is there any way to get around this problem, or a better way to have R 
plot a series of diagnostic graphics from a dataframe with a singe 
command? Sounds like a general enough problem, but I have found no 
answers with my Google searches

R.version:
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    5.0
year     2002
month    04
day      29
language R

the function is

BbEh.graphs2eps <- function(the.data){

#function to plot all sort of information to
#a single eps file for storage and future printing or display
#does not work because of laz evaluation?

filename <- deparse(substitute(the.data))
thefile <- paste(c("../ed/",filename,"/",filename,".eps"),collapse = "")
postscript(file= thefile, paper = "letter")
lset(my.lts)

#plot cohort variables
BbEh.xyplot.dbh(the.data) #these are custom lattice plotting functions
BbEh.xyplot.h(the.data)
BbEh.xyplot.bl(the.data)
BbEh.xyplot.bs(the.data)
BbEh.xyplot.dens(the.data)

#plot allometry checks
BbEh.xyplot.hVSdbh(the.data)
BbEh.xyplot.bdVSdbh(the.data)
BbEh.xyplot.blVSdbh(the.data)
BbEh.xyplot.bdVSh(the.data)

dev.off(dev.cur())


}

-- 
Marco Albani, Ph.D.
Postdoctoral Fellow
Dept. of Organismic and Evolutionary Biology
Harvard University
HUH 22 Divinity Avenue
Cambridge, MA
02138-2094 USA

Tel: +1 617 495 1621
Fax: +1 617 495 9484

http://www.people.fas.harvard.edu/~malbani



From ripley at stats.ox.ac.uk  Tue Jan 28 18:35:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 28 18:35:03 2003
Subject: [R] Plot to postscript in function
In-Reply-To: <3E36BBB6.7070002@fas.harvard.edu>
Message-ID: <Pine.LNX.4.44.0301281730290.10475-100000@gannet.stats>

You appear to be using lattice commands to plot on a postscript device: 
you should be using a trellis.device.

Also, you do need to *print* lattice commands, and I guess you are
not doing so in the custom commands which you are not showing us.
Wre those calls to zyplot, they would not work unless surrounded by 
print().

Please be careful to distinguish the use of lattice from `plotting',
as the details are where I suspect the problem arises.

On Tue, 28 Jan 2003, Marco Albani wrote:

> Hello,
> 
> I am having problems with plotting to a postscript device within a 
> function call.
> 
> When I do the same thing line by line in the command line interface, I 
> have no problems, but the function creates an empty postscript file.
> If I remove the dev.off() call at the end of the function, I get one of 
> the plots (the last), but not the others.
> 
> Is there any way to get around this problem, or a better way to have R 
> plot a series of diagnostic graphics from a dataframe with a singe 
> command? Sounds like a general enough problem, but I have found no 
> answers with my Google searches
> 
> R.version:
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    5.0
> year     2002
> month    04
> day      29
> language R
> 
> the function is
> 
> BbEh.graphs2eps <- function(the.data){
> 
> #function to plot all sort of information to
> #a single eps file for storage and future printing or display
> #does not work because of laz evaluation?
> 
> filename <- deparse(substitute(the.data))
> thefile <- paste(c("../ed/",filename,"/",filename,".eps"),collapse = "")
> postscript(file= thefile, paper = "letter")
> lset(my.lts)
> 
> #plot cohort variables
> BbEh.xyplot.dbh(the.data) #these are custom lattice plotting functions
> BbEh.xyplot.h(the.data)
> BbEh.xyplot.bl(the.data)
> BbEh.xyplot.bs(the.data)
> BbEh.xyplot.dens(the.data)
> 
> #plot allometry checks
> BbEh.xyplot.hVSdbh(the.data)
> BbEh.xyplot.bdVSdbh(the.data)
> BbEh.xyplot.blVSdbh(the.data)
> BbEh.xyplot.bdVSh(the.data)
> 
> dev.off(dev.cur())
> 
> 
> }
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fnj at cin.ufpe.br  Tue Jan 28 18:58:02 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Tue Jan 28 18:58:02 2003
Subject: [R] getChannels(fig, "red")
In-Reply-To: <5.1.0.14.2.20030128121158.01e4b048@mcmail.cis.mcmaster.ca>
Message-ID: <Pine.LNX.4.44.0301281409390.13031-100000@jurema.cin.ufpe.br>

Hello, expeRts,

I'm using the function getChannels for capture the matriz of R,G,B of a
figure. I think that its returns values between 0 and 255, but the matriz
contents values between 0 and 1. Somebody could explain me that values are
these, pls?
Tks,
Francisco.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco J?nior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

On Tue, 28 Jan 2003, John Fox wrote:

> Dear Luis,
>
> At 04:23 PM 1/28/2003 +0000, Luis Silva wrote:
> >Thanks to all! as.character solved my problem. And if I wanted
> >different colors instead?
>
>
> The argument col is also vectorized, so something like plot( ....,
> col=class) will work if class consists of small intergers. Alternatively,
> use class to index a vector of colors, as in col=c("red", "green",
> "blue")[class].
>
> John
>
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From malbani at fas.harvard.edu  Tue Jan 28 19:27:03 2003
From: malbani at fas.harvard.edu (Marco Albani)
Date: Tue Jan 28 19:27:03 2003
Subject: [R] Plot to postscript in function
References: <Pine.LNX.4.44.0301281730290.10475-100000@gannet.stats>
Message-ID: <3E36CABB.7000507@fas.harvard.edu>

Thanks to Prof. Ripley,

this version of the fucntion works as expected

 > BbEh.graphs2eps
function(the.data){
#function to plot all sort of cohort information to
#a single eps for storage and future printing or display

pippo <- deparse(substitute(the.data))
thefile <- paste(c("../ed/",pippo,"/",pippo,".eps"),collapse = "")
postscript(file= thefile, paper = "letter")
lset(my.lts)
#plot cohort variables
print(BbEh.xyplot.dbh(the.data))

#plot allometry checks
print(BbEh.xyplot.hVSdbh(the.data))

dev.off(dev.cur())

}

The use of postscript() instead of trellis.device() to open the device 
doesn't seem to be a problem.

Thanks to everyone who answered me.

Marco




ripley at stats.ox.ac.uk wrote:


> You appear to be using lattice commands to plot on a postscript device: 
> you should be using a trellis.device.
> 
> Also, you do need to *print* lattice commands, and I guess you are
> not doing so in the custom commands which you are not showing us.
> Wre those calls to zyplot, they would not work unless surrounded by 
> print().
> 
> Please be careful to distinguish the use of lattice from `plotting',
> as the details are where I suspect the problem arises.
> 

-- 
Marco Albani, Ph.D.
Postdoctoral Fellow
Dept. of Organismic and Evolutionary Biology
Harvard University
HUH 22 Divinity Avenue
Cambridge, MA
02138-2094 USA

Tel: +1 617 495 1621
Fax: +1 617 495 9484

http://www.people.fas.harvard.edu/~malbani



From Roger.Bivand at nhh.no  Tue Jan 28 20:10:03 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue Jan 28 20:10:03 2003
Subject: [R] getChannels(fig, "red")
In-Reply-To: <Pine.LNX.4.44.0301281409390.13031-100000@jurema.cin.ufpe.br>
Message-ID: <Pine.LNX.4.44.0301281957200.681-100000@reclus.nhh.no>

On Tue, 28 Jan 2003, Francisco do Nascimento Junior wrote:

> Hello, expeRts,
> 
> I'm using the function getChannels for capture the matriz of R,G,B of a
> figure. I think that its returns values between 0 and 255, but the matriz
> contents values between 0 and 1. Somebody could explain me that values are
> these, pls?

You are using library(pixmap) - it would help to say so, perhaps?

The lines of pixmapRGB() that answer your question are:

>    datamax <- max(data)
>    datamin <- min(data)
>    data <- as.numeric(data)
>    if (datamax > 1 || datamin < 0) 
>        data <- (data - datamin)/(datamax - datamin)

that is, the function you have used to make your data into class pixmapRGB 
has converted it to the 0-1 interval, based on the largest and smallest 
values in the combined layers. If you know what these were, you can get 
your data values back.

Roger 

> Tks,
> Francisco.
> 
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Francisco J?nior,
> Computer Science - UFPE-Brazil
> "One life has more value that the
> world whole"
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> On Tue, 28 Jan 2003, John Fox wrote:
> 
> > Dear Luis,
> >
> > At 04:23 PM 1/28/2003 +0000, Luis Silva wrote:
> > >Thanks to all! as.character solved my problem. And if I wanted
> > >different colors instead?
> >
> >
> > The argument col is also vectorized, so something like plot( ....,
> > col=class) will work if class consists of small intergers. Alternatively,
> > use class to index a vector of colors, as in col=c("red", "green",
> > "blue")[class].
> >
> > John
> >
> > -----------------------------------------------------
> > John Fox
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario, Canada L8S 4M4
> > email: jfox at mcmaster.ca
> > phone: 905-525-9140x23604
> > web: www.socsci.mcmaster.ca/jfox
> > -----------------------------------------------------
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From AnnisC at asme.org  Tue Jan 28 20:15:04 2003
From: AnnisC at asme.org (Charles Annis, P.E.)
Date: Tue Jan 28 20:15:04 2003
Subject: [R] random number generator?
Message-ID: <007801c2c701$07e1d2d0$0202a8c0@DHT0TL11>

Dear R-Aficionados:

I realize that no random number generator is perfect, so what I report
below may be a result of that simple fact.  However, if I have made an
error in my thinking I would greatly appreciate being corrected.

I wish to illustrate the behavior of small samples (n=10) and so
generate 100,000 of them.

n.samples <- 1000000
sample.size = 10
p <- 0.0001
z.normal <- qnorm(p)
# generate n.samples of sample.size each from a normal(mean=0, sd=1)
density
#
small.sample <- matrix(rnorm(n=sample.size*n.samples, mean=0, sd=1),
nrow=n.samples, ncol=sample.size)
# Verify that from the entire small.sample matrix, p sampled values are
below, p above.
#
observed.fraction.below <- sum(small.sample <
z.normal)/length(small.sample)
observed.fraction.above <- sum(small.sample >
-z.normal)/length(small.sample)

> observed.fraction.below 
[1] 6.3e-05
> observed.fraction.above 
[1] 0.000142
> 

I've checked the behavior of the entire sample's mean and median and
they seem fine.  The total fraction in both tails is 0.0002, as it
should be.  However in every instance about 1/3 are in the lower tail,
2/3 in the upper.  I also observe the same 1/3:2/3 ratio for one million
samples of ten.

Is this simply because random number generators aren't perfect?  Or have
I stepped in something?

Thank you for your kind counsel.


Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFAX: 503-217-5849
http://www.StatisticalEngineering.com



From kjetil at entelnet.bo  Tue Jan 28 20:19:02 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Tue Jan 28 20:19:02 2003
Subject: [R] (off-topic) Mingwin and cygwin
Message-ID: <3E369E58.8514.24ED4E@localhost>

Hola!

I am about to install a program on my windows XP computer
which seems to require cygwin installed. Will it cause any problems 
to have both cygwin and mingwin installed, I need mingwin to 
compile R packages?

Thanks, 

Kjetil Halvorsen



From p.dalgaard at biostat.ku.dk  Tue Jan 28 20:36:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Jan 28 20:36:03 2003
Subject: [R] random number generator?
In-Reply-To: <007801c2c701$07e1d2d0$0202a8c0@DHT0TL11>
References: <007801c2c701$07e1d2d0$0202a8c0@DHT0TL11>
Message-ID: <x2bs21nk2r.fsf@biostat.ku.dk>

"Charles Annis, P.E." <AnnisC at asme.org> writes:

> Dear R-Aficionados:
> 
> I realize that no random number generator is perfect, so what I report
> below may be a result of that simple fact.  However, if I have made an
> error in my thinking I would greatly appreciate being corrected.
> 
> I wish to illustrate the behavior of small samples (n=10) and so
> generate 100,000 of them.
> 
> n.samples <- 1000000
> sample.size = 10
> p <- 0.0001
> z.normal <- qnorm(p)
> # generate n.samples of sample.size each from a normal(mean=0, sd=1)
> density
> #
> small.sample <- matrix(rnorm(n=sample.size*n.samples, mean=0, sd=1),
> nrow=n.samples, ncol=sample.size)
> # Verify that from the entire small.sample matrix, p sampled values are
> below, p above.
> #
> observed.fraction.below <- sum(small.sample <
> z.normal)/length(small.sample)
> observed.fraction.above <- sum(small.sample >
> -z.normal)/length(small.sample)
> 
> > observed.fraction.below 
> [1] 6.3e-05
> > observed.fraction.above 
> [1] 0.000142
> > 
> 
> I've checked the behavior of the entire sample's mean and median and
> they seem fine.  The total fraction in both tails is 0.0002, as it
> should be.  However in every instance about 1/3 are in the lower tail,
> 2/3 in the upper.  I also observe the same 1/3:2/3 ratio for one million
> samples of ten.
> 
> Is this simply because random number generators aren't perfect?  Or have
> I stepped in something?
> 
> Thank you for your kind counsel.

You stepped in something, I think, but I probably shouldn't elaborate
on the metaphor ... There's an unfortunate interaction between the two
methods that are used for generating uniform and normal variables (the
latter uses the former). This has been reported a couple of times
before and typically gives anomalous tail behaviour. Changing one of
the generators (see help(RNGkind)) usually helps.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jasont at indigoindustrial.co.nz  Tue Jan 28 21:01:02 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue Jan 28 21:01:02 2003
Subject: [R] gray color in trellis xyplot
In-Reply-To: <6rvg094633.fsf@bates4.stat.wisc.edu>; from bates@stat.wisc.edu on Tue, Jan 28, 2003 at 10:00:48AM -0600
References: <3E369AE6.E73903A3@unimc.it> <6rvg094633.fsf@bates4.stat.wisc.edu>
Message-ID: <20030129084206.A11312@camille.indigoindustrial.co.nz>

On Tue, Jan 28, 2003 at 10:00:48AM -0600, Douglas Bates wrote:
> Luca De Benedictis <debene at unimc.it> writes:
...
> > Why dark gray was chosen as the default color?
>
> compatibility with the original trellis graphics implementation.

FWIW, I find that for on-screen graph reading, the cyan on dark
grey is great.  It's quite easy to read and interpret.  I don't
like it on printouts, which is why I'm happy that when printing
to a PDF device, lattice magically picks a white background.

Nice work.

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From tblackw at umich.edu  Tue Jan 28 21:15:04 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue Jan 28 21:15:04 2003
Subject: [R] random number generator?
In-Reply-To: <x2bs21nk2r.fsf@biostat.ku.dk>
Message-ID: <Pine.SOL.4.44.0301281453450.4545-100000@robotron.gpcc.itd.umich.edu>

Peter  -

Your message is cryptic.  I've just re-read  help("RNGkind")  in
R 1.6.1 (linux Redhat rpm) and it doesn't say anything I can see
about "an unfortuante interaction between the two methods that
are used for generating uniform and normal variables".

Are you referring to a thread in R-help that starts with a message
from Robin Hankin, Tuesday Nov 26 2002 ?  On Jonathan Baron's site,
that would be

http://finzi.psych.upenn.edu/R/Rhelp02/archive/9058.html

but even that thread is very vague.  (I don't understand a reference
to "PR#1664" in Thomas Lumleys's email (archive/9064.html).)

Maybe it's high time to put a paragraph describing this issue into
the help files for either rnorm() or RNGkind().

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On 28 Jan 2003, Peter Dalgaard BSA wrote:

> "Charles Annis, P.E." <AnnisC at asme.org> writes:
>
> > Dear R-Aficionados:
> >
> > I realize that no random number generator is perfect, so what I report
> > below may be a result of that simple fact.  However, if I have made an
> > error in my thinking I would greatly appreciate being corrected.
> >
> > I wish to illustrate the behavior of small samples (n=10) and so
> > generate 100,000 of them.
> >
> > n.samples <- 1000000
> > sample.size = 10
> > p <- 0.0001
> > z.normal <- qnorm(p)
> > # generate n.samples of sample.size each from a normal(mean=0, sd=1)
> > density
> > #
> > small.sample <- matrix(rnorm(n=sample.size*n.samples, mean=0, sd=1),
> > nrow=n.samples, ncol=sample.size)
> > # Verify that from the entire small.sample matrix, p sampled values are
> > below, p above.
> > #
> > observed.fraction.below <- sum(small.sample <
> > z.normal)/length(small.sample)
> > observed.fraction.above <- sum(small.sample >
> > -z.normal)/length(small.sample)
> >
> > > observed.fraction.below
> > [1] 6.3e-05
> > > observed.fraction.above
> > [1] 0.000142
> > >
> >
> > I've checked the behavior of the entire sample's mean and median and
> > they seem fine.  The total fraction in both tails is 0.0002, as it
> > should be.  However in every instance about 1/3 are in the lower tail,
> > 2/3 in the upper.  I also observe the same 1/3:2/3 ratio for one million
> > samples of ten.
> >
> > Is this simply because random number generators aren't perfect?  Or have
> > I stepped in something?
> >
> > Thank you for your kind counsel.
>
> You stepped in something, I think, but I probably shouldn't elaborate
> on the metaphor ... There's an unfortunate interaction between the two
> methods that are used for generating uniform and normal variables (the
> latter uses the former). This has been reported a couple of times
> before and typically gives anomalous tail behaviour. Changing one of
> the generators (see help(RNGkind)) usually helps.
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From f0z6305 at labs.tamu.edu  Tue Jan 28 21:34:03 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue Jan 28 21:34:03 2003
Subject: [R] [R]Good advices or books on estimating the SPE?
Message-ID: <00c301c2c70c$8ea70280$8bd75ba5@IE.TAMU.EDU>

Dear R'ers

I am trying to use some distribution to test the hypothesis
on my prediction error.
Given a large numbe of sample data with unknown distribution, I first find
some funtion to make regression.
Now for each new data point, I can calculate the prediction error xi. So how
to represent the SPE = sum_{xi^2}
in a general and reliable way with some statistics, like chi-square, t?
Please give me some advice or reference books on this topic.

Thanks for your time and attention.

Fred



From Charles.Annis at statisticalengineering.com  Tue Jan 28 21:38:04 2003
From: Charles.Annis at statisticalengineering.com (Charles Annis, P.E.)
Date: Tue Jan 28 21:38:04 2003
Subject: [R] random number generator?
In-Reply-To: <x2bs21nk2r.fsf@biostat.ku.dk>
Message-ID: <007b01c2c70c$a5a45320$0202a8c0@DHT0TL11>

Earlier today I reported finding an unbalanced number of observations in
the p=0.0001 tails of rnorm.

Many thanks to Peter Dalgaard who suggested changing the normal.kind
generator.  

Using  RNGkind(kind = NULL, normal.kind ="Box-Muller")
seems to have provided the remedy.  For example:

> observed.fraction.below 
[1] 0.000103
> observed.fraction.above 
[1] 0.000101
>  

Thank you, Peter!


Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFAX: 503-217-5849
http://www.StatisticalEngineering.com


-----Original Message-----
From: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Peter Dalgaard BSA
Sent: Tuesday, January 28, 2003 2:36 PM
To: Charles Annis, P.E.
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] random number generator?

"Charles Annis, P.E." <AnnisC at asme.org> writes:

> Dear R-Aficionados:
> 
> I realize that no random number generator is perfect, so what I report
> below may be a result of that simple fact.  However, if I have made an
> error in my thinking I would greatly appreciate being corrected.
> 
> I wish to illustrate the behavior of small samples (n=10) and so
> generate 100,000 of them.
> 
> n.samples <- 1000000
> sample.size = 10
> p <- 0.0001
> z.normal <- qnorm(p)
> # generate n.samples of sample.size each from a normal(mean=0, sd=1)
> density
> #
> small.sample <- matrix(rnorm(n=sample.size*n.samples, mean=0, sd=1),
> nrow=n.samples, ncol=sample.size)
> # Verify that from the entire small.sample matrix, p sampled values
are
> below, p above.
> #
> observed.fraction.below <- sum(small.sample <
> z.normal)/length(small.sample)
> observed.fraction.above <- sum(small.sample >
> -z.normal)/length(small.sample)
> 
> > observed.fraction.below 
> [1] 6.3e-05
> > observed.fraction.above 
> [1] 0.000142
> > 
> 
> I've checked the behavior of the entire sample's mean and median and
> they seem fine.  The total fraction in both tails is 0.0002, as it
> should be.  However in every instance about 1/3 are in the lower tail,
> 2/3 in the upper.  I also observe the same 1/3:2/3 ratio for one
million
> samples of ten.
> 
> Is this simply because random number generators aren't perfect?  Or
have
> I stepped in something?
> 
> Thank you for your kind counsel.

You stepped in something, I think, but I probably shouldn't elaborate
on the metaphor ... There's an unfortunate interaction between the two
methods that are used for generating uniform and normal variables (the
latter uses the former). This has been reported a couple of times
before and typically gives anomalous tail behaviour. Changing one of
the generators (see help(RNGkind)) usually helps.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.connolly at hortresearch.co.nz  Tue Jan 28 21:42:24 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue Jan 28 21:42:24 2003
Subject: [R] problem with srt vector in xyplot {lattice}
In-Reply-To: <200301241323.48194.deepayan@stat.wisc.edu>
References: <20030124175421.A3439@s1x.zimnet.ch> <200301241323.48194.deepayan@stat.wisc.edu>
Message-ID: <20030128203549.GC22668@hortresearch.co.nz>

On Fri, 24-Jan-2003 at 01:23PM -0600, Deepayan Sarkar wrote:

|> On Friday 24 January 2003 10:54 am, Wolfram Fischer - Z/I/M wrote:
|> > [ R 1.6.1 ]
|> >
|> > PROBLEM
|> >     The plot of the appended code does produce
|> >     a postscript file which is not interpretable
|> >     by gv under Linux.
|> 
|> The srt vector has several NA's. x11() does not draw these, which may or may 
|> not be what you want. You should be able to reproduce that in postscript() 
|> with an additional subset = !is.na(Solar.R) argument to xyplot().

Is there a simple reason why x11 doesn't require the !is.na() whereas
postscript does?  It took me an hour or more to work out what was
happening when I had a similar problem.

best


-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From ripley at stats.ox.ac.uk  Tue Jan 28 21:50:06 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 28 21:50:06 2003
Subject: [R] problem with srt vector in xyplot {lattice}
In-Reply-To: <20030128203549.GC22668@hortresearch.co.nz>
Message-ID: <Pine.LNX.4.44.0301282047580.19337-100000@gannet.stats>

A bug.  The engine should detect NAs, not leave it to vagaries of the 
drivers.  The grid engine will soon.

On Wed, 29 Jan 2003, Patrick Connolly wrote:

> On Fri, 24-Jan-2003 at 01:23PM -0600, Deepayan Sarkar wrote:
> 
> |> The srt vector has several NA's. x11() does not draw these, which may or may 
> |> not be what you want. You should be able to reproduce that in postscript() 
> |> with an additional subset = !is.na(Solar.R) argument to xyplot().
> 
> Is there a simple reason why x11 doesn't require the !is.na() whereas
> postscript does?  It took me an hour or more to work out what was
> happening when I had a similar problem.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Jan 28 21:54:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Jan 28 21:54:03 2003
Subject: [R] random number generator?
In-Reply-To: <007b01c2c70c$a5a45320$0202a8c0@DHT0TL11>
Message-ID: <Pine.LNX.4.44.0301282049320.19337-100000@gannet.stats>

Can I suggest

RNGkind("Mersenne-Twister", "Inversion")

and especially the use of Inversion where tail behaviour of the normal is
important.

Were it not for concerns about reproducibility we would have switched to 
Inversion a while back.

On Tue, 28 Jan 2003, Charles Annis, P.E. wrote:

> 
> Earlier today I reported finding an unbalanced number of observations in
> the p=0.0001 tails of rnorm.
> 
> Many thanks to Peter Dalgaard who suggested changing the normal.kind
> generator.  
> 
> Using  RNGkind(kind = NULL, normal.kind ="Box-Muller")
> seems to have provided the remedy.  For example:
> 
> > observed.fraction.below 
> [1] 0.000103
> > observed.fraction.above 
> [1] 0.000101
> >  
> 
> Thank you, Peter!
> 
> 
> Charles Annis, P.E.
> 
> Charles.Annis at StatisticalEngineering.com
> phone: 561-352-9699
> eFAX: 503-217-5849
> http://www.StatisticalEngineering.com
> 
> 
> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Peter Dalgaard BSA
> Sent: Tuesday, January 28, 2003 2:36 PM
> To: Charles Annis, P.E.
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] random number generator?
> 
> "Charles Annis, P.E." <AnnisC at asme.org> writes:
> 
> > Dear R-Aficionados:
> > 
> > I realize that no random number generator is perfect, so what I report
> > below may be a result of that simple fact.  However, if I have made an
> > error in my thinking I would greatly appreciate being corrected.
> > 
> > I wish to illustrate the behavior of small samples (n=10) and so
> > generate 100,000 of them.
> > 
> > n.samples <- 1000000
> > sample.size = 10
> > p <- 0.0001
> > z.normal <- qnorm(p)
> > # generate n.samples of sample.size each from a normal(mean=0, sd=1)
> > density
> > #
> > small.sample <- matrix(rnorm(n=sample.size*n.samples, mean=0, sd=1),
> > nrow=n.samples, ncol=sample.size)
> > # Verify that from the entire small.sample matrix, p sampled values
> are
> > below, p above.
> > #
> > observed.fraction.below <- sum(small.sample <
> > z.normal)/length(small.sample)
> > observed.fraction.above <- sum(small.sample >
> > -z.normal)/length(small.sample)
> > 
> > > observed.fraction.below 
> > [1] 6.3e-05
> > > observed.fraction.above 
> > [1] 0.000142
> > > 
> > 
> > I've checked the behavior of the entire sample's mean and median and
> > they seem fine.  The total fraction in both tails is 0.0002, as it
> > should be.  However in every instance about 1/3 are in the lower tail,
> > 2/3 in the upper.  I also observe the same 1/3:2/3 ratio for one
> million
> > samples of ten.
> > 
> > Is this simply because random number generators aren't perfect?  Or
> have
> > I stepped in something?
> > 
> > Thank you for your kind counsel.
> 
> You stepped in something, I think, but I probably shouldn't elaborate
> on the metaphor ... There's an unfortunate interaction between the two
> methods that are used for generating uniform and normal variables (the
> latter uses the former). This has been reported a couple of times
> before and typically gives anomalous tail behaviour. Changing one of
> the generators (see help(RNGkind)) usually helps.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Tue Jan 28 22:04:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Jan 28 22:04:03 2003
Subject: [R] random number generator?
Message-ID: <3A822319EB35174CA3714066D590DCD534BBE9@usrymx25.merck.com>

Might I suggest taking a poll (even though unscientific) of how many people
will be affected by a change in default RNG?  My totally arbitrary guess is
very few, if any.

If I'm not mistaken, Python had only recently changed the default RNG to
Mersenne-Twister.  If Python can do it, I should think R can, too, without
too much pain...

Just my $0.02...

Andy

> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Tuesday, January 28, 2003 3:53 PM
> To: Charles Annis, P.E.
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] random number generator?
> 
> 
> Can I suggest
> 
> RNGkind("Mersenne-Twister", "Inversion")
> 
> and especially the use of Inversion where tail behaviour of 
> the normal is
> important.
> 
> Were it not for concerns about reproducibility we would have 
> switched to 
> Inversion a while back.
> 
> On Tue, 28 Jan 2003, Charles Annis, P.E. wrote:
> 
> > 
> > Earlier today I reported finding an unbalanced number of 
> observations in
> > the p=0.0001 tails of rnorm.
> > 
> > Many thanks to Peter Dalgaard who suggested changing the normal.kind
> > generator.  
> > 
> > Using  RNGkind(kind = NULL, normal.kind ="Box-Muller")
> > seems to have provided the remedy.  For example:
> > 
> > > observed.fraction.below 
> > [1] 0.000103
> > > observed.fraction.above 
> > [1] 0.000101
> > >  
> > 
> > Thank you, Peter!
> > 
> > 
> > Charles Annis, P.E.
> > 
> > Charles.Annis at StatisticalEngineering.com
> > phone: 561-352-9699
> > eFAX: 503-217-5849
> > http://www.StatisticalEngineering.com
> > 
> > 
> > -----Original Message-----
> > From: r-help-admin at stat.math.ethz.ch
> > [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Peter 
> Dalgaard BSA
> > Sent: Tuesday, January 28, 2003 2:36 PM
> > To: Charles Annis, P.E.
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] random number generator?
> > 
> > "Charles Annis, P.E." <AnnisC at asme.org> writes:
> > 
> > > Dear R-Aficionados:
> > > 
> > > I realize that no random number generator is perfect, so 
> what I report
> > > below may be a result of that simple fact.  However, if I 
> have made an
> > > error in my thinking I would greatly appreciate being corrected.
> > > 
> > > I wish to illustrate the behavior of small samples (n=10) and so
> > > generate 100,000 of them.
> > > 
> > > n.samples <- 1000000
> > > sample.size = 10
> > > p <- 0.0001
> > > z.normal <- qnorm(p)
> > > # generate n.samples of sample.size each from a 
> normal(mean=0, sd=1)
> > > density
> > > #
> > > small.sample <- matrix(rnorm(n=sample.size*n.samples, 
> mean=0, sd=1),
> > > nrow=n.samples, ncol=sample.size)
> > > # Verify that from the entire small.sample matrix, p 
> sampled values
> > are
> > > below, p above.
> > > #
> > > observed.fraction.below <- sum(small.sample <
> > > z.normal)/length(small.sample)
> > > observed.fraction.above <- sum(small.sample >
> > > -z.normal)/length(small.sample)
> > > 
> > > > observed.fraction.below 
> > > [1] 6.3e-05
> > > > observed.fraction.above 
> > > [1] 0.000142
> > > > 
> > > 
> > > I've checked the behavior of the entire sample's mean and 
> median and
> > > they seem fine.  The total fraction in both tails is 0.0002, as it
> > > should be.  However in every instance about 1/3 are in 
> the lower tail,
> > > 2/3 in the upper.  I also observe the same 1/3:2/3 ratio for one
> > million
> > > samples of ten.
> > > 
> > > Is this simply because random number generators aren't 
> perfect?  Or
> > have
> > > I stepped in something?
> > > 
> > > Thank you for your kind counsel.
> > 
> > You stepped in something, I think, but I probably shouldn't 
> elaborate
> > on the metaphor ... There's an unfortunate interaction 
> between the two
> > methods that are used for generating uniform and normal 
> variables (the
> > latter uses the former). This has been reported a couple of times
> > before and typically gives anomalous tail behaviour. Changing one of
> > the generators (see help(RNGkind)) usually helps.
> > 
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From RUSSELLNORVELL at utah.gov  Tue Jan 28 23:28:02 2003
From: RUSSELLNORVELL at utah.gov (Russell Norvell)
Date: Tue Jan 28 23:28:02 2003
Subject: [R] Newbie graphics question
Message-ID: <se36a14f.033@gwia2.state.ut.us>

Greetings list-

I am a newcomer to R and have tried to resolve my question with the
manuals and the help archives to no avail, though some of this is simply
a lack of familiarity with R and S (BTW I am using R 1.6.1, on Windows98
second edition 4.10.2222A). 

I am trying to create publication quality plots: six figures to a page,
5 cm square plot regions, with 3 cm of horizontal white space and 2 cm
of white space as separators, and 2.5 cm outer (page) margins.  Titles,
tickmarks, and axis labels are to fit into the white space surrounding
each figure.

What I've tried is:

'sixpack <- layout(matrix(c(1,0,2,0,0,0,3,0,4,0,0,0,5,0,6), 5, 3,
byrow=TRUE), widths=lcm(c(5, 3, 5, 5, 3, 5, 5, 3, 5, 5, 3, 5, 5, 3, 5)),
heights=lcm(c(5, 2, 5, 2, 5, 5, 2, 5, 2, 5, 5, 2, 5, 5, 2, 5, 5, 2, 5)),
TRUE)'
'layout.show(sixpack)'

What I get is:

'Error in plot.new() : Figure region too large'

However if I keep the (total) space used by the multiple plot within
~17 cm high by ~11.3 cm wide, I can create a plot within each cell (and
I'll figure out how to fix the axis labeling later I suppose).  My
question is this:  how can I control the margins surrounding the
multiple figures in the layout?  I have tried 'par(omi=c(1,1,1,1))'
ahead of the layout command, with no discernable effect (although
'par(mar=c(2,2,0,0)' does nicely control the figure margins).

Any help, or a point to the right resource, would be greatly
appreciated.

-Russ



From chrysopa at insecta.ufv.br  Tue Jan 28 23:47:06 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Tue Jan 28 23:47:06 2003
Subject: [R] Help to make a function
Message-ID: <200301282045.09923.chrysopa@insecta.ufv.br>

Hi all,

I have a simple code to produce some populations graphics.

10: DIM X(71)
20: INPUT "r=";R
30: INPUT "k=";K
40: INPUT "P(0)=";P(0)
50: FOR T=0 TO 69
60: P(T+1) = P(T) + R*P(T) * (1-P(T)/K)
70: NEXT T
80: GRAPH
90: COLOR 0
100: LINE (0,0)-(0,220)
110: LINE (0,0)-(220,0)
120: LINE (0,K)-(220,K)
130: COLOR 3
140: FOR T= 0 TO 69
150: LINE (3*T,P(T)-(3*(T+1)),P(T+1))
160: NEXT T
170: COLOR 0
180: END

where P = Y, T = X, R and K are constants.

how to make a similar function in R to make this graphic?

Thanks
Ronaldo
-- 
College:
	The fountains of knowledge, where everyone goes to drink.
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Gnu/Debian Woody D+:) | Lxuser#: 205366



From rossini at blindglobe.net  Wed Jan 29 00:00:03 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed Jan 29 00:00:03 2003
Subject: [R] random number generator?
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BBE9@usrymx25.merck.com> ("Liaw,
 Andy"'s message of "Tue, 28 Jan 2003 16:03:24 -0500")
References: <3A822319EB35174CA3714066D590DCD534BBE9@usrymx25.merck.com>
Message-ID: <87n0lkzxxg.fsf@jeeves.blindglobe.net>

>>>>> "AL" == Andy Liaw <Liaw> writes:

    AL> Might I suggest taking a poll (even though unscientific) of how many people
    AL> will be affected by a change in default RNG?  My totally arbitrary guess is
    AL> very few, if any.

But they may tend to be important (i.e. those with large stat software
projects/tools) doing heavy regression testing.  

    AL> If I'm not mistaken, Python had only recently changed the default RNG to
    AL> Mersenne-Twister.  If Python can do it, I should think R can, too, without
    AL> too much pain...

Depends on which L_p norm you measure pain by.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From Rajiv.Prasad at pnl.gov  Wed Jan 29 00:23:05 2003
From: Rajiv.Prasad at pnl.gov (Prasad, Rajiv)
Date: Wed Jan 29 00:23:05 2003
Subject: [R] dyn.load warning message in R1.6.2 on Windows XP
Message-ID: <49F10672DADC2C4F9F6C8BBD1384FFC6064621@pnlmse26.pnl.gov>

Hi folks:

I used to load a DLL fine up until R 1.5.1.  The same DLL dyn.loaded under R
1.6.2 prints the following warning message:

> dyn.load("C:/Rajiv/Bin/rpdate.dll")
Warning message: 
DLL attempted to change FPU control word from 8001f to 9001f 
>

Any indication as to what the warning means, and whether I should be
concerned about it?  The DLL is made from a pure C code, compiled with MS
Visual C++ 6.0.

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.2            
year     2003           
month    01             
day      10             
language R              
>

Thanks.

Rajiv
--------
Rajiv Prasad
Postdoctoral Research Associate, Hydrology Group
Pacific Northwest National Laboratory, P.O. Box 999, MSIN K9-33
Richland, WA 99352
Voice: (509) 375-2096  Fax: (509) 372-6089  Email: rajiv.prasad at pnl.gov



From cgrant02589 at yahoo.com  Wed Jan 29 00:40:03 2003
From: cgrant02589 at yahoo.com (C Grant)
Date: Wed Jan 29 00:40:03 2003
Subject: [R] Curve Fitting Question - Newbie
Message-ID: <20030128233903.53854.qmail@web13309.mail.yahoo.com>

Hello, I have what should be an easy question. I'm a
new r user and making the transition from menus to the
command line so as to do batch processing of tons of
data. One of my data streams needs to be detrended.
It's a vector of numbers that follows a negative
exponential decay. I need to fit a curve to it and use
the residuals as an object. The data looks something
like this:

foo.dat <- (0.83 * exp(-0.017 * 1:1000) + 0.5) +
rnorm(1000,0,0.05)
plot(foo.dat, type = "l")

That is an example the parameters for foo.dat change
slightly. So, I need to fit a neg exponential curve to
that type of data without specifying the parameters
beforehand and save the residuals as an object. It
will have to accomadate being in a loop.

How can I do this?

Regards, CG



From p.dalgaard at biostat.ku.dk  Wed Jan 29 00:45:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Jan 29 00:45:03 2003
Subject: [R] dyn.load warning message in R1.6.2 on Windows XP
In-Reply-To: <49F10672DADC2C4F9F6C8BBD1384FFC6064621@pnlmse26.pnl.gov>
References: <49F10672DADC2C4F9F6C8BBD1384FFC6064621@pnlmse26.pnl.gov>
Message-ID: <x2wukodest.fsf@biostat.ku.dk>

"Prasad, Rajiv" <Rajiv.Prasad at pnl.gov> writes:

> Hi folks:
> 
> I used to load a DLL fine up until R 1.5.1.  The same DLL dyn.loaded under R
> 1.6.2 prints the following warning message:
> 
> > dyn.load("C:/Rajiv/Bin/rpdate.dll")
> Warning message: 
> DLL attempted to change FPU control word from 8001f to 9001f 
> >
> 
> Any indication as to what the warning means, and whether I should be
> concerned about it?  The DLL is made from a pure C code, compiled with MS
> Visual C++ 6.0.

The check is new, but the problem is likely older. Before the check,
it would seem that your DLL was meddling with the FPU and not putting
the settings back as it found them. Now, R detects the change and sets
things back, which is probably better (I think Duncan M. told us that
that particular bit in the control word reduces floating point
precision from 64 to 53 bits), but your DLL shouldn't do that in the
first place. As far as I know, we can only detect the change upon
loading the DLL, not when running the functions inside of it, so you
should be somewhat worried.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From andy_liaw at merck.com  Wed Jan 29 01:51:02 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Jan 29 01:51:02 2003
Subject: [R] Curve Fitting Question - Newbie
Message-ID: <3A822319EB35174CA3714066D590DCD534BBED@usrymx25.merck.com>

If you don't need the parameters in the curve, it seems like

library(modreg)
lines(supsmu(1:1000, foo.dat), lwd=3)

gives a very reasonable result.

HTH,
Andy

> -----Original Message-----
> From: C Grant [mailto:cgrant02589 at yahoo.com]
> Sent: Tuesday, January 28, 2003 6:39 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Curve Fitting Question - Newbie
> 
> 
> Hello, I have what should be an easy question. I'm a
> new r user and making the transition from menus to the
> command line so as to do batch processing of tons of
> data. One of my data streams needs to be detrended.
> It's a vector of numbers that follows a negative
> exponential decay. I need to fit a curve to it and use
> the residuals as an object. The data looks something
> like this:
> 
> foo.dat <- (0.83 * exp(-0.017 * 1:1000) + 0.5) +
> rnorm(1000,0,0.05)
> plot(foo.dat, type = "l")
> 
> That is an example the parameters for foo.dat change
> slightly. So, I need to fit a neg exponential curve to
> that type of data without specifying the parameters
> beforehand and save the residuals as an object. It
> will have to accomadate being in a loop.
> 
> How can I do this?
> 
> Regards, CG
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From Simon.Blomberg at anu.edu.au  Wed Jan 29 01:57:06 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Wed Jan 29 01:57:06 2003
Subject: [R] Curve Fitting Question - Newbie
Message-ID: <7A3A13F416B40842BD2C1753E044B359B13363@CASEVS02.cas.anu.edu.au>

One way would be to use the nls package:

library(nls)

foo.dat <- (0.83 * exp(-0.017 * 1:1000) + 0.5) + rnorm(1000,0,0.05) # your y values
foo.dat <- data.frame(cbind(foo.dat, 0:999)) # create some x values in a data frame
names(foo.dat) <- c("y", "x") # give them names

model <- nls( y ~ N * exp(-r * x) + c, start = list( N = 1, r = .01, c = 0), data = foo.dat) # assume you have reasonable guesses for the starting parameter values

resid(model) # display residuals

Cheers,

Simon.

Simon Blomberg
Consumer Research Unit
Centre for Mental Health Research, Australian National University
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379


-----Original Message-----
From: C Grant [mailto:cgrant02589 at yahoo.com]
Sent: Wednesday, 29 January 2003 10:39 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Curve Fitting Question - Newbie


Hello, I have what should be an easy question. I'm a
new r user and making the transition from menus to the
command line so as to do batch processing of tons of
data. One of my data streams needs to be detrended.
It's a vector of numbers that follows a negative
exponential decay. I need to fit a curve to it and use
the residuals as an object. The data looks something
like this:

foo.dat <- (0.83 * exp(-0.017 * 1:1000) + 0.5) +
rnorm(1000,0,0.05)
plot(foo.dat, type = "l")

That is an example the parameters for foo.dat change
slightly. So, I need to fit a neg exponential curve to
that type of data without specifying the parameters
beforehand and save the residuals as an object. It
will have to accomadate being in a loop.

How can I do this?

Regards, CG

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From s.mcclatchie at niwa.co.nz  Wed Jan 29 02:13:03 2003
From: s.mcclatchie at niwa.co.nz (Sam McClatchie)
Date: Wed Jan 29 02:13:03 2003
Subject: [R] calling sweave function from latex
Message-ID: <3E372A6F.50900@niwa.cri.nz>

System info:
Mandrake 9.0
R Version 1.6.1
ESS 5.1.21
Emacs 21.2.1
-------------------

Colleagues

I've been calling R-code embedded in my LaTex document using Sweave, but 
would like to make things more convenient. At present as I understand it 
  you first process the R chunks of code using the Sweave function 
called from within R to process a "precursor file" e.g. foo.sw to get a 
LaTex file (foo.sw.tex) that you then process with latex foo.sw.tex.
------------------------
example code segment

%\item {\bf Matched trawl and acoustic data} \label{real data}

\item {\bf Results}

%%%% sweave code

<<echo=false,results=hide>>=
average.trawl.spp.composition()
@

%%%% insert figure generated from sweave code
\begin{figure}
\includegraphics[scale=0.6]{../figures/bycatch_by_weight}
\caption{\label{catch by weight} Proportions of selected species (from
     Table \ref{ts length regressions}) in the fish assemblage using
     catch rate ($kg\ km{-1}$) as an approximation for fish density
     (neglecting variable capture efficiencies). Note: there were no
     oblique banded rattails in this dataset, although we have a
     \textit{<TS>-length} regression for them (see Table \ref{ts length
     regressions}). Box plot centre line = meadian, box limits are
     $25^{th}$ and $75^{th}$ quartiles, whiskers represent 1.5 times the
     interquartile range from the median, and points outside the whiskers
     are the tails of the distributions.}
\end{figure}
-----------------------

This works fine, but it is cumbersome for someone who likes to write a 
bit and then latex that additional bit. Of course I can just add the new 
LaTex code chunks to the foo.sw.tex and latex that, but I have to 
remember to copy the foo.sw.tex back to foo.sw or the versions get mixed 
up. Trivial, but annoying.

The question is: can I call the Sweave function from within LaTex so I 
just latex the foo.sw.tex and the Sweave chunks will also get processed. 
This would be much tidier.

One suspects that the short answer is 'no'.

Best fishes

Sam
-- 
Sam McClatchie, Research scientist (fisheries acoustics))))))))))
NIWA (National Institute of Water & Atmospheric Research Ltd)
PO Box 14 901, Kilbirnie, Wellington, New Zealand
s.mcclatchie at niwa.cri.nz
Research home page <http://www.smcc.150m.com/>
                       /\
            >><xX(&>
                    /// \\\
                   //// \\\\
                  ///  <%)Xx><<
                 /////  \\\\\\
           ><(((@>
     ><(((%>     ..>><xX(?>O<?)Xx><<



From gisar at nus.edu.sg  Wed Jan 29 04:09:03 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Wed Jan 29 04:09:03 2003
Subject: [R] Finding inflexion points from data
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F1FA@MBXSRV03.stf.nus.edu.sg>

Dear all, I have a measurements from an experiment. Graphically I can
see there is one inflexion point but would like to automate this process
accurately. I am wondering if someone had written such a code (which I
think is similar to turnpoints() in library pastecs). 
Thank you. 

Regards, Adai.



From ischang at stat.tamu.edu  Wed Jan 29 06:40:04 2003
From: ischang at stat.tamu.edu (Ilsung Chang)
Date: Wed Jan 29 06:40:04 2003
Subject: [R] How to run the simulations in the background
Message-ID: <1030128233910.ZM5815@hartley>

This is a graduate student in Texas A&M university.
I do the computational works usually in the Linux system.
I want to know how to run the R simulation in the background.
I went to the R-FAQ pages but i did not find it.
Thank you.

p.s.) Splus BATCH mysim.s out & is typed in case of Splus simulation.

-- 
Ilsung



From ostrouchovg at ornl.gov  Wed Jan 29 06:52:07 2003
From: ostrouchovg at ornl.gov (George Ostrouchov)
Date: Wed Jan 29 06:52:07 2003
Subject: [R] very large data set: min, max works but range fails
Message-ID: <3E376BD9.6030901@ornl.gov>

I want to do a simple histogram for a very large data set.  I traced the 
problem to the range() function and the storage.mode()<-"double" 
assignment.

Below is a sequence that works for min() and max(), but fails for range().

 > length(evap0)         
[1] 51812400            
 > mode(evap0)           
[1] "numeric"           
 > storage.mode(breaks)  
[1] "double"            
 > min(evap0)            
[1] -2.254886e-05       
 > max(evap0)            
[1] 0.0002331886        
 > range.default(evap0)                            
Error: vector memory exhausted (limit reached?)     
 > Error: vector memory exhausted (limit reached?)   
 > Error: vector memory exhausted (limit reached?)   

I traced it to a parameter recursion in c() within range.default()
x <- c(..., recursive = TRUE)

I am running on a linux box with 8G memory, and
VENDOR=intel  
OSTYPE=linux  
MACHTYPE=i386 
R : Copyright 2002, The R Development Core Team
Version 1.6.1  (2002-11-01)                    

I was able to do the histogram by removing the offending pieces of 
hist.default(). But I do not have an explanation for the above failure. 
I didn't find any plausible explanation in the archives.
Can someone help?

Thanks!
George

---------------------------------------------
George Ostrouchov
Statistics and Data Sciences
Computer Science and Mathematics
Oak Ridge National Laboratory



From hedderik at cmu.edu  Wed Jan 29 07:00:05 2003
From: hedderik at cmu.edu (Hedderik van Rijn)
Date: Wed Jan 29 07:00:05 2003
Subject: [R] How to run the simulations in the background
In-Reply-To: <1030128233910.ZM5815@hartley>
Message-ID: <CF5B9E4A-334E-11D7-83B0-000393678426@cmu.edu>

> I do the computational works usually in the Linux system.
> I want to know how to run the R simulation in the background.
> I went to the R-FAQ pages but i did not find it.
[..]
> p.s.) Splus BATCH mysim.s out & is typed in case of Splus simulation.

R's manual page (man R) gives the list of commands one can invoke R 
with. One of them is "BATCH".

R BATCH mysim.r &

runs the mysim.r script in the background, all output is send to 
mysim.r.Rout.

Another way to do sort of the same is:

R < mysim.r > out &

which is also referred to in the manual page.

  - Hedderik.



From david.whiting at ncl.ac.uk  Wed Jan 29 08:07:04 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Wed Jan 29 08:07:04 2003
Subject: [R] calling sweave function from latex
In-Reply-To: <3E372A6F.50900@niwa.cri.nz>
References: <3E372A6F.50900@niwa.cri.nz>
Message-ID: <20030129053626.GY5892@192.168.57.2>

You say that you call R code embedded in your LaTeX document. I tend to
think of it as LaTeX embedded in my R code.  I think the answer to your
question is 'no', but there might be ways to work around it.

I use AUCTeX in emacs and can select a region of foo.sw and run latex on
that.  This works fine although you won't have access to R objects using
\Sexpr{}.  In practice I tend to use <<eval=FALSE>> to "comment out" R
code chunks that I have run previously if I do not need to update or
recreated their objects. This means that running Sweave on foo.sw then
does not take too long to run the R chunks that do need to be run, i.e.
foo.tex is created pretty quickly.  Running latex does not then usually
take long either.  I use search and replace or the chunk navigation
hotkeys (e.g. M-n g) when I need to change <<eval=FALSE>> to
<<eval=TRUE>>. 

Creating a Makefile to run R with Sweave (as indicated in the FAQ in the
Sweave manual) and then latex the resulting foo.tex should work pretty
well to automate the process. 

I am still new to Sweave, but have had a lot of fun with it so far.  I
use emacs with ESS, Sweave, RefTex mode, LaTeX mode and Prosper - a
presentation class that creates PDF presentations which (can if you
want) look like MS Powerpoint presentations but with the advantage of
LaTeX formatting.  All the tools I need for analysis, writing, and
presentations working together. 

My first serious use of this combination was last week. I had a foo.Rnw
file which produced both my presentation and accompanying notes to
handout. I discovered a mistake in my R code shortly before giving my
presentation, fixed it, Sweave'd the file and updated my presentation
and notes painlessly. A nice way to work.

Dave.


On Wed, Jan 29, 2003 at 02:12:15PM +1300, Sam McClatchie wrote:
> System info:
> Mandrake 9.0
> R Version 1.6.1
> ESS 5.1.21
> Emacs 21.2.1
> -------------------
> 
> Colleagues
> 
> I've been calling R-code embedded in my LaTex document using Sweave, but 
> would like to make things more convenient. At present as I understand it 
>  you first process the R chunks of code using the Sweave function 
> called from within R to process a "precursor file" e.g. foo.sw to get a 
> LaTex file (foo.sw.tex) that you then process with latex foo.sw.tex.
> ------------------------
> example code segment
> 
> %\item {\bf Matched trawl and acoustic data} \label{real data}
> 
> \item {\bf Results}
> 
> %%%% sweave code
> 
> <<echo=false,results=hide>>=
> average.trawl.spp.composition()
> @
> 
> %%%% insert figure generated from sweave code
> \begin{figure}
> \includegraphics[scale=0.6]{../figures/bycatch_by_weight}
> \caption{\label{catch by weight} Proportions of selected species (from
>     Table \ref{ts length regressions}) in the fish assemblage using
>     catch rate ($kg\ km{-1}$) as an approximation for fish density
>     (neglecting variable capture efficiencies). Note: there were no
>     oblique banded rattails in this dataset, although we have a
>     \textit{<TS>-length} regression for them (see Table \ref{ts length
>     regressions}). Box plot centre line = meadian, box limits are
>     $25^{th}$ and $75^{th}$ quartiles, whiskers represent 1.5 times the
>     interquartile range from the median, and points outside the whiskers
>     are the tails of the distributions.}
> \end{figure}
> -----------------------
> 
> This works fine, but it is cumbersome for someone who likes to write a 
> bit and then latex that additional bit. Of course I can just add the new 
> LaTex code chunks to the foo.sw.tex and latex that, but I have to 
> remember to copy the foo.sw.tex back to foo.sw or the versions get mixed 
> up. Trivial, but annoying.
> 
> The question is: can I call the Sweave function from within LaTex so I 
> just latex the foo.sw.tex and the Sweave chunks will also get processed. 
> This would be much tidier.
> 
> One suspects that the short answer is 'no'.
> 
> Best fishes
> 
> Sam
> -- 
> Sam McClatchie, Research scientist (fisheries acoustics))))))))))
> NIWA (National Institute of Water & Atmospheric Research Ltd)
> PO Box 14 901, Kilbirnie, Wellington, New Zealand
> s.mcclatchie at niwa.cri.nz
> Research home page <http://www.smcc.150m.com/>
>                       /\
>            >><xX(&>
>                    /// \\\
>                   //// \\\\
>                  ///  <%)Xx><<
>                 /////  \\\\\\
>           ><(((@>
>     ><(((%>     ..>><xX(?>O<?)Xx><<
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Dave Whiting
Dar es Salaam, Tanzania



From otoomet at econ.dk  Wed Jan 29 09:25:13 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Wed Jan 29 09:25:13 2003
Subject: [R] Re: memory problems
Message-ID: <200301290826.h0T8Q3T08180@punik.econ.au.dk>

Hi,

well, it is always a good bet to start with a small subset of your
data.  Increase it and take a look what happens and how much memory it
takes (object.size() should give the size of the oject in memory, use
OS-tools to check the size of the whole process).

There may also be some OS-related issues.  There are some issues with
memory management under Windows, in particular the memory may become
fragmented.  Try the same under UNIX if you have access to.

And last -- please describe more precisely what exactly are you doing
and what does your data look like.

Best wishes,

Ott



From otoomet at econ.dk  Wed Jan 29 09:31:24 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Wed Jan 29 09:31:24 2003
Subject: [R] printing reals from C with digits
Message-ID: <200301290826.h0T8Qh108186@punik.econ.au.dk>

Hi,

I want to print real numbers in C code with different values for
digits.  How to do that?

As I have understood, what I should do is to call

StringFromReal()

which calls FormatReal(), that one suggests the parameters (width,
decimal places and exponential form).  FormatReal() includes

    eps = pow(10.0, -(double)R_print.digits);

So I guess I have to change the value of R_print.digits.
R_print.digits is defined in include/Print.h in the package source,
but unfortunately the installed version (in /usr/lib/R/include/R_ext) is
quite a different.  I guess that is because the structure is not meant
to be accessible by user, although some system routines alter
R_print.digits directly.

So are there any good way to achieve it?


This R 1.5.0 on an RH 6.2 computer if that matters.

Thanks for help.

Ott



From ripley at stats.ox.ac.uk  Wed Jan 29 10:02:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed Jan 29 10:02:05 2003
Subject: [R] printing reals from C with digits
In-Reply-To: <200301290826.h0T8Qh108186@punik.econ.au.dk>
Message-ID: <Pine.WNT.4.44.0301290849360.4076-100000@petrel>

On Wed, 29 Jan 2003, Ott Toomet wrote:

> I want to print real numbers in C code with different values for
> digits.  How to do that?

Use Rprintf or PrintValue.  You'll need to work hard to convince me that
Rprintf is not adequate.

> As I have understood, what I should do is to call
>
> StringFromReal()

That's a coercion, not a printing routine.

> which calls FormatReal(), that one suggests the parameters (width,
> decimal places and exponential form).  FormatReal() includes
>
>     eps = pow(10.0, -(double)R_print.digits);
>
> So I guess I have to change the value of R_print.digits.
> R_print.digits is defined in include/Print.h in the package source,
> but unfortunately the installed version (in /usr/lib/R/include/R_ext) is
> quite a different.

R_ext/Print.h and Print.h are not the same thing: one is not a version of
the other.  The routines you mention are not documented in R-exts, and are
not part of the API.

> I guess that is because the structure is not meant
> to be accessible by user, although some system routines alter
> R_print.digits directly.

(Only the coercion and print routines!)

> So are there any good way to achieve it?

Temporarily change the options(digits) and call PrintValue().  You are not
meant to (and it is not safe to) mess with R's printing internals, and
these structures change even at patch releases.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From phgrosjean at sciviews.org  Wed Jan 29 10:26:02 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed Jan 29 10:26:02 2003
Subject: [R] (off-topic) Mingwin and cygwin
In-Reply-To: <3E369E58.8514.24ED4E@localhost>
Message-ID: <MABBLJDICACNFOLGIHJOEEAPDDAA.phgrosjean@sciviews.org>

I use both (cygwin for Octave and for compiling ATLAS lib; mingwin for
compiling R) on the same Win XP computer, and there is no problems. Just
place then in different directories.
Best,

Philippe Grosjean

-----Original Message-----
From: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of kjetil brinchmann
halvorsen
Sent: mardi 28 janvier 2003 8:15
To: R-help at stat.math.ethz.ch
Subject: [R] (off-topic) Mingwin and cygwin


Hola!

I am about to install a program on my windows XP computer
which seems to require cygwin installed. Will it cause any problems
to have both cygwin and mingwin installed, I need mingwin to
compile R packages?

Thanks,

Kjetil Halvorsen

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From theis at statistik.uni-dortmund.de  Wed Jan 29 10:55:03 2003
From: theis at statistik.uni-dortmund.de (Winfried Theis)
Date: Wed Jan 29 10:55:03 2003
Subject: [R] Scoping rule problem?!? step does not work in function
Message-ID: <XFMail.030129120511.theis@statistik.uni-dortmund.de>

Hello!

I would like to use step() in a function because I have a list of responses
(independent!) with equal influence and want to apply stepwise regression on
each of them. So the function I just tested is the following:
fitlms <- function(y,infl,formel=NULL){
       if(is.null(formel)){
         var.names <- names(infl)
         dcv <- length(var.names)
         formel <- paste("y~",paste(rep("I(",dcv), var.names,
rep("^2)",dcv),sep="",collapse="+"),"+",paste(var.names,collapse="*"),sep="")
         formel <- as.formula(formel)
       }
       erg <- lm(formel,infl)
       erg <- step(erg)
       return(erg)}

Using this I get the following:

> test <- fitlms(grob.erg[,1],grob.erg[,3:5])
Start:  AIC= -30.84 
 y ~ I(f^2) + I(vS^2) + I(o^2) + f + vS + o + f:vS + f:o + vS:o +  
    f:vS:o 

          Df Sum of Sq     RSS     AIC
- f:vS:o   1     0.060   2.052 -32.188
<none>                   1.992 -30.842
- I(o^2)   1     0.762   2.754 -25.717
- I(f^2)   1     2.581   4.573 -14.558
- I(vS^2)  1     5.341   7.333  -4.170
Error in model.frame.default(formula = y ~ I(f^2) + I(vS^2) + I(o^2) +  : 
        Object "infl" not found


So the first step carried out correctly and then it seems to look into the
wrong environment (presumably the top-level). I checked with the code of step,
but could not spot the cause of this behaviour. At some place it looks
at the parent.frame, which should be the environment created by function fitlms
if I do unserstand things correctly. I checked also whether I can give step an
environment in which to operate, but could not find any such option.

I presume I could just use a for-loop, which might not be much slower than
lapply in this case. I simply would like to understand things better to avoid
similar errors.

Data is given below.

Thanks for your attention and any help appreciated,

Winfried




> grob.erg
           gwRZ      gwRA     f      vS       o
WV 1   3.562667 0.5742667 0.185  90.000 300.000
WV 2   3.585733 0.6028333 0.185  90.000 300.000
WV 3   3.893233 0.7162333 0.185  90.000 300.000
WV 4   4.035933 0.7603667 0.139 111.213 370.711
WV 5   2.250800 0.3411000 0.120  90.000 300.000
WV 6   4.342833 0.8782667 0.231 111.213 370.711
WV 7   2.537000 0.4682333 0.231  68.787 370.711
WV 8   3.058767 0.4457333 0.185  90.000 400.000
WV 9   3.613333 0.6000000 0.139  68.787 370.711
WV 10  4.757700 1.0705333 0.231 111.213 229.289
WV 11  4.491800 0.9555000 0.185  60.000 300.000
WV 12  3.316133 0.5622333 0.139 111.213 229.289
WV 13  3.364567 0.5709333 0.139  68.787 229.289
WV 14  3.834867 0.6982333 0.185  90.000 200.000
WV 15  4.116233 0.6855000 0.231  68.787 229.289
WV 16  3.769800 0.7355333 0.185  90.000 300.000
WV 17  6.631733 1.6468333 0.185 120.000 300.000
WV 18  4.282933 0.7365333 0.185  90.000 300.000
WV 19  3.784633 0.7029000 0.185  90.000 300.000
WV 20  3.669567 0.6854000 0.250  90.000 300.000
WV 21  4.548433 0.7231000 0.185  90.000 300.000
WV 21a 3.387467 0.5558667 0.185  90.000 300.000
 

---------------------------------------------------------------------
E-Mail: Winfried Theis <theis at statistik.uni-dortmund.de>
Date: 29-Jan-03

Dipl.-Math. Winfried Theis
SFB 475, Fachbereich Statistik, Universit"at Dortmund, 44221 Dortmund
Tel.: +49-231-755-5903 FAX: +49-231-755-4387
----------------------------------------------------------------------



From wolfseggerm at gmx.at  Wed Jan 29 11:02:03 2003
From: wolfseggerm at gmx.at (martin wolfsegger)
Date: Wed Jan 29 11:02:03 2003
Subject: [R] Analyzing an unbalanced AB/BA cross-over design
Message-ID: <9668.1043834453@www64.gmx.net>

I am looking for help to analyze an unbalanced AB/BA cross-over design by
requesting the type III SS !

# Example 3.1 from S. Senn (1993). Cross-over Trials in Clinical
Research
outcome<-c(310,310,370,410,250,380,330,270,260,300,390,210,350,365,370,310,380,290,260,90,385,400,410,320,340,220)
subject<-as.factor(c(1,4,6,7,10,11,14,1,4,6,7,10,11,14,2,3,5,9,12,13,2,3,5,9,12,13))
period<-as.factor(c(1,1,1,1,1,1,1,2,2,2,2,2,2,2,1,1,1,1,1,1,2,2,2,2,2,2))
treatment<-as.factor(c('F','F','F','F','F','F','F','S','S','S','S','S','S','S','S','S','S','S','S','S','F','F','F','F','F','F'))
sequence<-as.factor(c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2))
example<-data.frame(outcome,subject,period,treatment,sequence)

The recommended SAS code equals

PROC GLM DATA=example;
CLASS subject period treatment sequence;
MODEL outcome = treatment sequence period subject(sequence);
RANDOM subject(sequence);
RUN;

For PROC GLM, the random effects are treated in a post hoc fashion after the
complete fixed effect model is fit. This distinction affects other features
in the GLM procedure, such as the results of the LSMEANS and ESTIMATE
statements. Looking only on treatment, period, sequence and subject effects, the
random statement can be omitted.

The R code for type I SS equals

example.lm<-lm(outcome~treatment+period+sequence+subject%in%sequence,
data=example)
anova(example.lm)

Response: outcome
                 Df Sum Sq Mean Sq F value    Pr(>F)    
treatment         1  13388   13388 17.8416  0.001427 ** 
period            1   1632    1632  2.1749  0.168314    
sequence          1    335     335  0.4467  0.517697    
sequence:subject 11 114878   10443 13.9171 6.495e-05 ***
Residuals        11   8254     750                     

According to the unbalanced design, I requested the type III SS which
resulted in an error statement

library(car)
Anova(example.lm, type="III")

Error in linear.hypothesis.lm(mod, hyp.matrix, summary.model = sumry,  : 
        One or more terms aliased in model.
 

by using glm I got results with 0 df for the sequence effect !!!!

example.glm<-glm(outcome~treatment+period+sequence+subject%in%sequence,
data=example, family=gaussian)
library(car)
Anova(example.glm,type="III",test.statistic="F")

Anova Table (Type III tests)

Response: outcome
                     SS Df       F    Pr(>F)    
treatment         14036  1 18.7044  0.001205 ** 
period             1632  1  2.1749  0.168314    
sequence              0  0                      
sequence:subject 114878 11 13.9171 6.495e-05 ***
Residuals          8254 11            


The questions based on this output are

1) Why was there an error statement requesting type III SS based on lm ?
2) Why I got a result by using glm with 0 df for the period effect ?
3) How can I get the estimate, the StdError for the constrast (-1,1) of the
treatment effect ?


Thanks

--



From david.firth at nuffield.oxford.ac.uk  Wed Jan 29 11:13:09 2003
From: david.firth at nuffield.oxford.ac.uk (David Firth)
Date: Wed Jan 29 11:13:09 2003
Subject: [R] CGIwithR version 0.40
Message-ID: <196BA4DF-3372-11D7-980E-0050E4C03977@nuffield.oxford.ac.uk>

A new version of the CGIwithR package is now at CRAN.  Version 0.40 has 
the following improvements:

-- more comprehensive decoding of form data
-- images are no longer cached by browsers
-- buffering of the output page to avoid server/browser sync problems

Still for unix-like systems only.


David Firth
Nuffield College
Oxford OX1 1NF
United Kingdom

Phone +44 1865 278544
Fax   +44 1865 278621
http://www.stats.ox.ac.uk/~firth



From Friedrich.Leisch at ci.tuwien.ac.at  Wed Jan 29 11:19:02 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Wed Jan 29 11:19:02 2003
Subject: [R] calling sweave function from latex
In-Reply-To: <3E372A6F.50900@niwa.cri.nz>
References: <3E372A6F.50900@niwa.cri.nz>
Message-ID: <15927.43499.805617.950194@galadriel.ci.tuwien.ac.at>

>>>>> On Wed, 29 Jan 2003 14:12:15 +1300,
>>>>> Sam McClatchie (SM) wrote:

  > System info:
  > Mandrake 9.0
  > R Version 1.6.1
  > ESS 5.1.21
  > Emacs 21.2.1
  > -------------------

  > Colleagues

  > I've been calling R-code embedded in my LaTex document using Sweave, but 
  > would like to make things more convenient. At present as I understand it 
  >   you first process the R chunks of code using the Sweave function 
  > called from within R to process a "precursor file" e.g. foo.sw to get a 
  > LaTex file (foo.sw.tex) that you then process with latex foo.sw.tex.
  > ------------------------
  > example code segment

  > %\item {\bf Matched trawl and acoustic data} \label{real data}

  > \item {\bf Results}

  > %%%% sweave code

  > <<echo=false,results=hide>>=
  > average.trawl.spp.composition()
  > @

  > %%%% insert figure generated from sweave code
  > \begin{figure}
  > \includegraphics[scale=0.6]{../figures/bycatch_by_weight}
  > \caption{\label{catch by weight} Proportions of selected species (from
  >      Table \ref{ts length regressions}) in the fish assemblage using
  >      catch rate ($kg\ km{-1}$) as an approximation for fish density
  >      (neglecting variable capture efficiencies). Note: there were no
  >      oblique banded rattails in this dataset, although we have a
  >      \textit{<TS>-length} regression for them (see Table \ref{ts length
  >      regressions}). Box plot centre line = meadian, box limits are
  >      $25^{th}$ and $75^{th}$ quartiles, whiskers represent 1.5 times the
  >      interquartile range from the median, and points outside the whiskers
  >      are the tails of the distributions.}
  > \end{figure}
  > -----------------------

  > This works fine, but it is cumbersome for someone who likes to write a 
  > bit and then latex that additional bit. Of course I can just add the new 
  > LaTex code chunks to the foo.sw.tex and latex that, but I have to 
  > remember to copy the foo.sw.tex back to foo.sw or the versions get mixed 
  > up. Trivial, but annoying.

  > The question is: can I call the Sweave function from within LaTex so I 
  > just latex the foo.sw.tex and the Sweave chunks will also get processed. 
  > This would be much tidier.

  > One suspects that the short answer is 'no'.



One way to deal with this is to write several Sweave filew and collect
them into the main latex document using \input{} statements. Then you
can Sweave() only those files which have some changes, makefiles can
automate that easily.

I have some ideas on conditional processing of chunks and re-using
previously saved results in case nothing has changed, but that has not
been implemented yet.

Best,
Fritz

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------



From fnj at cin.ufpe.br  Wed Jan 29 12:12:02 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Wed Jan 29 12:12:02 2003
Subject: [R] Array of 3D
Message-ID: <Pine.LNX.4.44.0301290748230.17190-100000@jurema.cin.ufpe.br>

Hi,

Can be created an Array of 3 dimensions in R? How?

Tks,
Francisco.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco J?nior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From theis at statistik.uni-dortmund.de  Wed Jan 29 12:19:02 2003
From: theis at statistik.uni-dortmund.de (Winfried Theis)
Date: Wed Jan 29 12:19:02 2003
Subject: [R] Scoping rule problem -- solved
In-Reply-To: <Pine.LNX.4.44.0301291052160.1593-100000@gannet.stats>
Message-ID: <XFMail.030129132400.theis@statistik.uni-dortmund.de>

Thanks to some comments from Brian D. Ripley, I found my error:
I should not have given a data argument to lm() after creating a
formula-object. This obviously confused things...

Thanks again, I've really learnt again a bit more on R-programming...

Cheers, Winfried 
---------------------------------------------------------------------
E-Mail: Winfried Theis <theis at statistik.uni-dortmund.de>
Date: 29-Jan-03

Dipl.-Math. Winfried Theis
SFB 475, Fachbereich Statistik, Universit"at Dortmund, 44221 Dortmund
Tel.: +49-231-755-5903 FAX: +49-231-755-4387
----------------------------------------------------------------------



From boiko at demogr.mpg.de  Wed Jan 29 12:24:54 2003
From: boiko at demogr.mpg.de (Serge Boiko)
Date: Wed Jan 29 12:24:54 2003
Subject: [R] substitute, eval and hastables
Message-ID: <m2el6wcg6f.fsf@boiko_linux.demogr.mpg.de>

I have the following problem. I have an automatically generated named
list with "stringified" names:

a <- list("A"=..., "B"=..., "C"=..., )

then I want to refer to the elements of the list, stored as an vector
of names:

nn <- c("A", "B", "C"), so that I could get list elements like

a$nn[1], a$nn[2], etc. Obviously it doesn't work. Instead I do:

nn.Exp <- substitute(expression(a$b), list(b=nn[1]))
eval(nn.Exp)

in a result I get
expession(a$"A") but not the value stored in the list.
Meanwhile if I manually construct expression as expression(a$"A") and
then evaluate it, it works fine.

How do I solve that problem? Perhaps using such a list with
"stringified" names are not very good programming style, but this is
convenient to store and retrieve elements if list should be filled
automatically from numerous sources. In this way I'm trying to emulate
a hash-table behavior. Perhaps there is a better way?

Any help is highly appreciated
Thanks, 
-Serge



From p.dalgaard at biostat.ku.dk  Wed Jan 29 12:30:40 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Jan 29 12:30:40 2003
Subject: [R] Analyzing an unbalanced AB/BA cross-over design
In-Reply-To: <9668.1043834453@www64.gmx.net>
References: <9668.1043834453@www64.gmx.net>
Message-ID: <x2n0lkb3zy.fsf@biostat.ku.dk>

martin wolfsegger <wolfseggerm at gmx.at> writes:

> I am looking for help to analyze an unbalanced AB/BA cross-over design by
> requesting the type III SS !
> 
> # Example 3.1 from S. Senn (1993). Cross-over Trials in Clinical
> Research
> outcome<-c(310,310,370,410,250,380,330,270,260,300,390,210,350,365,370,310,380,290,260,90,385,400,410,320,340,220)
> subject<-as.factor(c(1,4,6,7,10,11,14,1,4,6,7,10,11,14,2,3,5,9,12,13,2,3,5,9,12,13))
> period<-as.factor(c(1,1,1,1,1,1,1,2,2,2,2,2,2,2,1,1,1,1,1,1,2,2,2,2,2,2))
> treatment<-as.factor(c('F','F','F','F','F','F','F','S','S','S','S','S','S','S','S','S','S','S','S','S','F','F','F','F','F','F'))
> sequence<-as.factor(c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2))
> example<-data.frame(outcome,subject,period,treatment,sequence)
> 
> The recommended SAS code equals
> 
> PROC GLM DATA=example;
> CLASS subject period treatment sequence;
> MODEL outcome = treatment sequence period subject(sequence);
> RANDOM subject(sequence);
> RUN;
> 
> For PROC GLM, the random effects are treated in a post hoc fashion after the
> complete fixed effect model is fit. This distinction affects other features
> in the GLM procedure, such as the results of the LSMEANS and ESTIMATE
> statements. Looking only on treatment, period, sequence and subject effects, the
> random statement can be omitted.
> 
> The R code for type I SS equals
> 
> example.lm<-lm(outcome~treatment+period+sequence+subject%in%sequence,
> data=example)
> anova(example.lm)
> 
> Response: outcome
>                  Df Sum Sq Mean Sq F value    Pr(>F)    
> treatment         1  13388   13388 17.8416  0.001427 ** 
> period            1   1632    1632  2.1749  0.168314    
> sequence          1    335     335  0.4467  0.517697    
> sequence:subject 11 114878   10443 13.9171 6.495e-05 ***
> Residuals        11   8254     750                     
> 
> According to the unbalanced design, I requested the type III SS which
> resulted in an error statement
> 
> library(car)
> Anova(example.lm, type="III")
> 
> Error in linear.hypothesis.lm(mod, hyp.matrix, summary.model = sumry,  : 
>         One or more terms aliased in model.
>  
> 
> by using glm I got results with 0 df for the sequence effect !!!!
> 
> example.glm<-glm(outcome~treatment+period+sequence+subject%in%sequence,
> data=example, family=gaussian)
> library(car)
> Anova(example.glm,type="III",test.statistic="F")
> 
> Anova Table (Type III tests)
> 
> Response: outcome
>                      SS Df       F    Pr(>F)    
> treatment         14036  1 18.7044  0.001205 ** 
> period             1632  1  2.1749  0.168314    
> sequence              0  0                      
> sequence:subject 114878 11 13.9171 6.495e-05 ***
> Residuals          8254 11            
> 
> 
> The questions based on this output are
> 
> 1) Why was there an error statement requesting type III SS based on lm ?
> 2) Why I got a result by using glm with 0 df for the period effect ?
> 3) How can I get the estimate, the StdError for the constrast (-1,1) of the
> treatment effect ?

The type I/III issues my be better left to people who actually
understand them, but note that sequence is really a embedded in
subject (7 subjects had one sequence and 6 subjects the other) so
sequence:subject is equivalent to just subject, and this is likely
also the reason that sequence is aliased within subject. Basically,
this is a fixed-effects model, and if each subject has his own
parameter, you can't estimate the sequence effect. 

I'd do this kind of design with an explicit mixed-effects model:

> summary(aov(outcome~treatment+period+sequence+Error(subject)))

Error: subject
          Df Sum Sq Mean Sq F value Pr(>F)
sequence   1    335     335  0.0321  0.861
Residuals 11 114878   10443

Error: Within
          Df  Sum Sq Mean Sq F value   Pr(>F)
treatment  1 13388.5 13388.5 17.8416 0.001427 **
period     1  1632.1  1632.1  2.1749 0.168314
Residuals 11  8254.5   750.4

possibly substituting treatment:period for sequence (it's the same
thing). 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From vito.muggeo at giustizia.it  Wed Jan 29 12:37:11 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Wed Jan 29 12:37:11 2003
Subject: [R] Array of 3D
References: <Pine.LNX.4.44.0301290748230.17190-100000@jurema.cin.ufpe.br>
Message-ID: <005101c2c789$86389fa0$5c13070a@it.giustizia.it>

see ?array
best,
vito


----- Original Message -----
From: "Francisco do Nascimento Junior" <fnj at cin.ufpe.br>
To: "R-help" <R-help at stat.math.ethz.ch>
Sent: Wednesday, January 29, 2003 10:50 AM
Subject: [R] Array of 3D


Hi,

Can be created an Array of 3 dimensions in R? How?

Tks,
Francisco.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco J?nior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Wed Jan 29 13:14:02 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Jan 29 13:14:02 2003
Subject: [R] substitute, eval and hastables
In-Reply-To: <m2el6wcg6f.fsf@boiko_linux.demogr.mpg.de>
References: <m2el6wcg6f.fsf@boiko_linux.demogr.mpg.de>
Message-ID: <3E37C577.3010505@statistik.uni-dortmund.de>

Serge Boiko wrote:
> I have the following problem. I have an automatically generated named
> list with "stringified" names:
> 
> a <- list("A"=..., "B"=..., "C"=..., )
> 
> then I want to refer to the elements of the list, stored as an vector
> of names:
> 
> nn <- c("A", "B", "C"), so that I could get list elements like
> 
> a$nn[1], a$nn[2], etc. Obviously it doesn't work. Instead I do:

a$nn is evaluated at first, which looks for a list element called "nn"!
It's the convinient form for a[["nn"]].


> nn.Exp <- substitute(expression(a$b), list(b=nn[1]))
> eval(nn.Exp)

That's an enormous *overhead*. To construct such an expression, I'd try 
(given here just for fun):

   nn.Exp <- substitute(a$b, list(b=nn[1]))
   eval(nn.Exp)


> in a result I get
> expession(a$"A") but not the value stored in the list.
> Meanwhile if I manually construct expression as expression(a$"A") and
> then evaluate it, it works fine.
> 
> How do I solve that problem? Perhaps using such a list with
> "stringified" names are not very good programming style, but this is
> convenient to store and retrieve elements if list should be filled
> automatically from numerous sources. In this way I'm trying to emulate
> a hash-table behavior. Perhaps there is a better way?
> 
> Any help is highly appreciated

Use the more general [[ ]] indexing mechanism for lists as in:

  a[[nn[1]]]
  a[[nn[2]]]

See "An Introduction to R" or any book on the S language for more 
details regarding indexing.

Uwe Ligges



From rgentlem at jimmy.harvard.edu  Wed Jan 29 13:24:00 2003
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Wed Jan 29 13:24:00 2003
Subject: [R] substitute, eval and hastables
In-Reply-To: <m2el6wcg6f.fsf@boiko_linux.demogr.mpg.de>; from boiko@demogr.mpg.de on Wed, Jan 29, 2003 at 01:07:52PM +0100
References: <m2el6wcg6f.fsf@boiko_linux.demogr.mpg.de>
Message-ID: <20030129071924.H8829@jimmy.harvard.edu>

On Wed, Jan 29, 2003 at 01:07:52PM +0100, Serge Boiko wrote:
> 
> I have the following problem. I have an automatically generated named
> list with "stringified" names:
> 
> a <- list("A"=..., "B"=..., "C"=..., )
> 
> then I want to refer to the elements of the list, stored as an vector
> of names:
> 
> nn <- c("A", "B", "C"), so that I could get list elements like
> 
> a$nn[1], a$nn[2], etc. Obviously it doesn't work. Instead I do:
> 
> nn.Exp <- substitute(expression(a$b), list(b=nn[1]))
> eval(nn.Exp)
> 
> in a result I get
> expession(a$"A") but not the value stored in the list.
> Meanwhile if I manually construct expression as expression(a$"A") and
> then evaluate it, it works fine.
> 
> How do I solve that problem? Perhaps using such a list with
> "stringified" names are not very good programming style, but this is
> convenient to store and retrieve elements if list should be filled
> automatically from numerous sources. In this way I'm trying to emulate
> a hash-table behavior. Perhaps there is a better way?

 If you want hash table behavior you could try using environments (as
 that is really about all that they are). I have been spending some
 time thinking (and a little coding) about a hash table class but it
 is unlikely to appear before the summer.
  Robert


> 
> Any help is highly appreciated
> Thanks, 
> -Serge
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20
| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
+---------------------------------------------------------------------------+



From ligges at statistik.uni-dortmund.de  Wed Jan 29 13:29:56 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Jan 29 13:29:56 2003
Subject: [R] Help to make a function
In-Reply-To: <200301282045.09923.chrysopa@insecta.ufv.br>
References: <200301282045.09923.chrysopa@insecta.ufv.br>
Message-ID: <3E37C752.2010209@statistik.uni-dortmund.de>

Ronaldo Reis Jr. wrote:
> Hi all,
> 
> I have a simple code to produce some populations graphics.
> 
> 10: DIM X(71)
> 20: INPUT "r=";R
> 30: INPUT "k=";K
> 40: INPUT "P(0)=";P(0)
> 50: FOR T=0 TO 69
> 60: P(T+1) = P(T) + R*P(T) * (1-P(T)/K)
> 70: NEXT T
> 80: GRAPH
> 90: COLOR 0
> 100: LINE (0,0)-(0,220)
> 110: LINE (0,0)-(220,0)
> 120: LINE (0,K)-(220,K)
> 130: COLOR 3
> 140: FOR T= 0 TO 69
> 150: LINE (3*T,P(T)-(3*(T+1)),P(T+1))
> 160: NEXT T
> 170: COLOR 0
> 180: END
> 
> where P = Y, T = X, R and K are constants.
> 
> how to make a similar function in R to make this graphic?

By porting that Basic code? The details are left as an exercise for the 
reader, since you stated it is "simple".

Uwe Ligges



From jfox at mcmaster.ca  Wed Jan 29 13:53:05 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed Jan 29 13:53:05 2003
Subject: [R] Analyzing an unbalanced AB/BA cross-over design
In-Reply-To: <9668.1043834453@www64.gmx.net>
Message-ID: <5.1.0.14.2.20030129073612.01df34e8@mcmail.cis.mcmaster.ca>

Dear Martin,

As Peter Dalgaard has pointed out, the model you fit has redundant 
parameters, as you can see from its summary (or from the coefficients):

     > summary(example.lm)

     . . .

     Coefficients: (13 not defined because of singularities)

     . . .

     > coef(example.lm)
             (Intercept)          treatmentS             period2 
sequence2  sequence1:subject2
             305.35714           -46.60714            15.89286 
-135.00000                  NA
     sequence2:subject2  sequence1:subject3  sequence2:subject3 
sequence1:subject4  sequence2:subject4
             222.50000                  NA           200.00000 
-5.00000                  NA
     sequence1:subject5  sequence2:subject5  sequence1:subject6 
sequence2:subject6  sequence1:subject7
                     NA           240.00000            45.00000 
      NA           110.00000
     sequence2:subject7  sequence1:subject9  sequence2:subject9 
sequence1:subject10 sequence2:subject10
                     NA                  NA           150.00000 
-60.00000                  NA
     sequence1:subject11 sequence2:subject11 sequence1:subject12 
sequence2:subject12 sequence1:subject13
             75.00000                  NA                  NA 
145.00000                  NA
     sequence2:subject13 sequence1:subject14 sequence2:subject14
                     NA            57.50000                  NA

The computational procedure used by Anova (in the car package) assumes a 
full-rank parametrization of the model. The difference between the Anova 
methods for lm and glm is that the former uses the coefficient estimates 
and their covariance matrix to compute sums of squares while the latter 
refits the model. You got a result from SAS because it works with a 
deficient-rank parametrization. Finally (and more generally), if you really 
want "type-III" sums of squares in R, be careful with the kind of 
contrast-coding that you use. The default "treatment" contrasts won't give 
you what you want.

I'm sorry that you encountered this problem.
  John


At 11:00 AM 1/29/2003 +0100, martin wolfsegger wrote:
>I am looking for help to analyze an unbalanced AB/BA cross-over design by
>requesting the type III SS !
>
># Example 3.1 from S. Senn (1993). Cross-over Trials in Clinical
>Research
>outcome<-c(310,310,370,410,250,380,330,270,260,300,390,210,350,365,370,310,380,290,260,90,385,400,410,320,340,220)
>subject<-as.factor(c(1,4,6,7,10,11,14,1,4,6,7,10,11,14,2,3,5,9,12,13,2,3,5,9,12,13))
>period<-as.factor(c(1,1,1,1,1,1,1,2,2,2,2,2,2,2,1,1,1,1,1,1,2,2,2,2,2,2))
>treatment<-as.factor(c('F','F','F','F','F','F','F','S','S','S','S','S','S','S','S','S','S','S','S','S','F','F','F','F','F','F'))
>sequence<-as.factor(c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2))
>example<-data.frame(outcome,subject,period,treatment,sequence)
>
>The recommended SAS code equals
>
>PROC GLM DATA=example;
>CLASS subject period treatment sequence;
>MODEL outcome = treatment sequence period subject(sequence);
>RANDOM subject(sequence);
>RUN;
>
>For PROC GLM, the random effects are treated in a post hoc fashion after the
>complete fixed effect model is fit. This distinction affects other features
>in the GLM procedure, such as the results of the LSMEANS and ESTIMATE
>statements. Looking only on treatment, period, sequence and subject 
>effects, the
>random statement can be omitted.
>
>The R code for type I SS equals
>
>example.lm<-lm(outcome~treatment+period+sequence+subject%in%sequence,
>data=example)
>anova(example.lm)
>
>Response: outcome
>                  Df Sum Sq Mean Sq F value    Pr(>F)
>treatment         1  13388   13388 17.8416  0.001427 **
>period            1   1632    1632  2.1749  0.168314
>sequence          1    335     335  0.4467  0.517697
>sequence:subject 11 114878   10443 13.9171 6.495e-05 ***
>Residuals        11   8254     750
>
>According to the unbalanced design, I requested the type III SS which
>resulted in an error statement
>
>library(car)
>Anova(example.lm, type="III")
>
>Error in linear.hypothesis.lm(mod, hyp.matrix, summary.model = sumry,  :
>         One or more terms aliased in model.
>
>
>by using glm I got results with 0 df for the sequence effect !!!!
>
>example.glm<-glm(outcome~treatment+period+sequence+subject%in%sequence,
>data=example, family=gaussian)
>library(car)
>Anova(example.glm,type="III",test.statistic="F")
>
>Anova Table (Type III tests)
>
>Response: outcome
>                      SS Df       F    Pr(>F)
>treatment         14036  1 18.7044  0.001205 **
>period             1632  1  2.1749  0.168314
>sequence              0  0
>sequence:subject 114878 11 13.9171 6.495e-05 ***
>Residuals          8254 11
>
>
>The questions based on this output are
>
>1) Why was there an error statement requesting type III SS based on lm ?
>2) Why I got a result by using glm with 0 df for the period effect ?
>3) How can I get the estimate, the StdError for the constrast (-1,1) of the
>treatment effect ?
>
>
>Thanks
>
>--
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From theis at statistik.uni-dortmund.de  Wed Jan 29 14:00:04 2003
From: theis at statistik.uni-dortmund.de (Winfried Theis)
Date: Wed Jan 29 14:00:04 2003
Subject: [R] Array of 3D
In-Reply-To: <Pine.LNX.4.44.0301290748230.17190-100000@jurema.cin.ufpe.br>
Message-ID: <XFMail.030129150552.theis@statistik.uni-dortmund.de>

Hi,

try ?array.

So long, Winfried


On 29-Jan-03 Francisco do Nascimento Junior wrote:
> Hi,
> 
> Can be created an Array of 3 dimensions in R? How?
> 
> Tks,
> Francisco.
> 
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Francisco Júnior,
> Computer Science - UFPE-Brazil
> "One life has more value that the
> world whole"
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

---------------------------------------------------------------------
E-Mail: Winfried Theis <theis at statistik.uni-dortmund.de>
Date: 29-Jan-03

Dipl.-Math. Winfried Theis
SFB 475, Fachbereich Statistik, Universit"at Dortmund, 44221 Dortmund
Tel.: +49-231-755-5903 FAX: +49-231-755-4387
----------------------------------------------------------------------



From boiko at demogr.mpg.de  Wed Jan 29 14:44:02 2003
From: boiko at demogr.mpg.de (Serge Boiko)
Date: Wed Jan 29 14:44:02 2003
Subject: [R] substitute, eval and hastables
In-Reply-To: <3E37C577.3010505@statistik.uni-dortmund.de> (Uwe Ligges's
 message of "Wed, 29 Jan 2003 13:13:43 +0100")
References: <m2el6wcg6f.fsf@boiko_linux.demogr.mpg.de>
	<3E37C577.3010505@statistik.uni-dortmund.de>
Message-ID: <m265s8c99k.fsf@boiko_linux.demogr.mpg.de>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

>    nn.Exp <- substitute(a$b, list(b=nn[1]))
>    eval(nn.Exp)

Thanks, Uwe. It does work, but, surely using brackets is better. 
-Serge



From boiko at demogr.mpg.de  Wed Jan 29 14:53:09 2003
From: boiko at demogr.mpg.de (Serge Boiko)
Date: Wed Jan 29 14:53:09 2003
Subject: [R] substitute, eval and hastables
In-Reply-To: <20030129071924.H8829@jimmy.harvard.edu> (Robert Gentleman's
 message of "Wed, 29 Jan 2003 07:19:24 -0500")
References: <m2el6wcg6f.fsf@boiko_linux.demogr.mpg.de>
	<20030129071924.H8829@jimmy.harvard.edu>
Message-ID: <m2znpkauea.fsf@boiko_linux.demogr.mpg.de>

Robert Gentleman <rgentlem at jimmy.harvard.edu> writes:


>
>  If you want hash table behavior you could try using environments (as
>  that is really about all that they are). I have been spending some
>  time thinking (and a little coding) about a hash table class but it
>  is unlikely to appear before the summer.
>   Robert
>
Thanks for your message.

I started to think about using environments. I think many people (and
I'm one of them) will appreciate hash table data structure. 

-Serge



From bwheeler at echip.com  Wed Jan 29 15:11:05 2003
From: bwheeler at echip.com (Bob Wheeler)
Date: Wed Jan 29 15:11:05 2003
Subject: [R] random number generator?
References: <3A822319EB35174CA3714066D590DCD534BBE9@usrymx25.merck.com>
Message-ID: <3E37E0C5.2C8D1246@echip.com>

Well if the base generator is to be changed, it might be a
good idea to consider implementing one of Marsaglia's really
long period generators. His latest, using titanic primes,
has a period of >2^131086. It is extremely fast. Even more
could be done, by replacing the two phase normal generator
by faster generator using a single phase. 

"Liaw, Andy" wrote:
> 
> Might I suggest taking a poll (even though unscientific) of how many people
> will be affected by a change in default RNG?  My totally arbitrary guess is
> very few, if any.
> 
> If I'm not mistaken, Python had only recently changed the default RNG to
> Mersenne-Twister.  If Python can do it, I should think R can, too, without
> too much pain...
> 
> Just my $0.02...
> 
> Andy
> 
> > -----Original Message-----
> > From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> > Sent: Tuesday, January 28, 2003 3:53 PM
> > To: Charles Annis, P.E.
> > Cc: r-help at stat.math.ethz.ch
> > Subject: RE: [R] random number generator?
> >
> >
> > Can I suggest
> >
> > RNGkind("Mersenne-Twister", "Inversion")
> >
> > and especially the use of Inversion where tail behaviour of
> > the normal is
> > important.
> >
> > Were it not for concerns about reproducibility we would have
> > switched to
> > Inversion a while back.
> >
> > On Tue, 28 Jan 2003, Charles Annis, P.E. wrote:
> >
> > >
> > > Earlier today I reported finding an unbalanced number of
> > observations in
> > > the p=0.0001 tails of rnorm.
> > >
> > > Many thanks to Peter Dalgaard who suggested changing the normal.kind
> > > generator.
> > >
> > > Using  RNGkind(kind = NULL, normal.kind ="Box-Muller")
> > > seems to have provided the remedy.  For example:
> > >
> > > > observed.fraction.below
> > > [1] 0.000103
> > > > observed.fraction.above
> > > [1] 0.000101
> > > >
> > >
> > > Thank you, Peter!
> > >
> > >
> > > Charles Annis, P.E.
> > >
> > > Charles.Annis at StatisticalEngineering.com
> > > phone: 561-352-9699
> > > eFAX: 503-217-5849
> > > http://www.StatisticalEngineering.com
> > >
> > >
> > > -----Original Message-----
> > > From: r-help-admin at stat.math.ethz.ch
> > > [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Peter
> > Dalgaard BSA
> > > Sent: Tuesday, January 28, 2003 2:36 PM
> > > To: Charles Annis, P.E.
> > > Cc: r-help at stat.math.ethz.ch
> > > Subject: Re: [R] random number generator?
> > >
> > > "Charles Annis, P.E." <AnnisC at asme.org> writes:
> > >
> > > > Dear R-Aficionados:
> > > >
> > > > I realize that no random number generator is perfect, so
> > what I report
> > > > below may be a result of that simple fact.  However, if I
> > have made an
> > > > error in my thinking I would greatly appreciate being corrected.
> > > >
> > > > I wish to illustrate the behavior of small samples (n=10) and so
> > > > generate 100,000 of them.
> > > >
> > > > n.samples <- 1000000
> > > > sample.size = 10
> > > > p <- 0.0001
> > > > z.normal <- qnorm(p)
> > > > # generate n.samples of sample.size each from a
> > normal(mean=0, sd=1)
> > > > density
> > > > #
> > > > small.sample <- matrix(rnorm(n=sample.size*n.samples,
> > mean=0, sd=1),
> > > > nrow=n.samples, ncol=sample.size)
> > > > # Verify that from the entire small.sample matrix, p
> > sampled values
> > > are
> > > > below, p above.
> > > > #
> > > > observed.fraction.below <- sum(small.sample <
> > > > z.normal)/length(small.sample)
> > > > observed.fraction.above <- sum(small.sample >
> > > > -z.normal)/length(small.sample)
> > > >
> > > > > observed.fraction.below
> > > > [1] 6.3e-05
> > > > > observed.fraction.above
> > > > [1] 0.000142
> > > > >
> > > >
> > > > I've checked the behavior of the entire sample's mean and
> > median and
> > > > they seem fine.  The total fraction in both tails is 0.0002, as it
> > > > should be.  However in every instance about 1/3 are in
> > the lower tail,
> > > > 2/3 in the upper.  I also observe the same 1/3:2/3 ratio for one
> > > million
> > > > samples of ten.
> > > >
> > > > Is this simply because random number generators aren't
> > perfect?  Or
> > > have
> > > > I stepped in something?
> > > >
> > > > Thank you for your kind counsel.
> > >
> > > You stepped in something, I think, but I probably shouldn't
> > elaborate
> > > on the metaphor ... There's an unfortunate interaction
> > between the two
> > > methods that are used for generating uniform and normal
> > variables (the
> > > latter uses the former). This has been reported a couple of times
> > > before and typically gives anomalous tail behaviour. Changing one of
> > > the generators (see help(RNGkind)) usually helps.
> > >
> > >
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ------------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Bob Wheeler --- http://www.bobwheeler.com/
        ECHIP, Inc. --- (302) 239-6620, voice FAX
           724 Yorklyn Rd., Hockessin, DE 19707
              Randomness comes in bunches



From andy_liaw at merck.com  Wed Jan 29 15:25:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Jan 29 15:25:03 2003
Subject: [R] random number generator?
Message-ID: <3A822319EB35174CA3714066D590DCD534BBF1@usrymx25.merck.com>

> From: rossini at blindglobe.net [mailto:rossini at blindglobe.net]
> 
> >>>>> "AL" == Andy Liaw <Liaw> writes:
> 
>     AL> Might I suggest taking a poll (even though 
> unscientific) of how many people
>     AL> will be affected by a change in default RNG?  My 
> totally arbitrary guess is
>     AL> very few, if any.
> 
> But they may tend to be important (i.e. those with large stat software
> projects/tools) doing heavy regression testing.  
> 

But if those who want to use better RNG in R can now put RNGkind() in their
.Rprofile,  surely those who really need the old generator can do similar,
if the default is changed?  As Prof. Dalgaard said (privately), I don't
think is that painful if the current default generator is kept as an option
in RNGkind().  (I.e., all I'm asking is to change the default RNG, not
getting rid of the current default.)

Cheers,
Andy

>     AL> If I'm not mistaken, Python had only recently changed 
> the default RNG to
>     AL> Mersenne-Twister.  If Python can do it, I should 
> think R can, too, without
>     AL> too much pain...
> 
> Depends on which L_p norm you measure pain by.
> 
> best,
> -tony
> 
> -- 
> A.J. Rossini				Rsrch. Asst. Prof. of 
> Biostatistics
> U. of Washington Biostatistics		
> rossini at u.washington.edu	
> FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
> -------------- http://software.biostat.washington.edu/ 
> ----------------
> FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty 
> sketchy/use Email
> UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
> (my tuesday/wednesday/friday locations are completely unpredictable.)
> 


------------------------------------------------------------------------------



From murdoch at stats.uwo.ca  Wed Jan 29 15:39:47 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed Jan 29 15:39:47 2003
Subject: [R] Help!!
In-Reply-To: <F171eRaNgEpTX5V3Gyk00000356@hotmail.com>
References: <F171eRaNgEpTX5V3Gyk00000356@hotmail.com>
Message-ID: <o9pf3vgsu12hk8ru3pl6s87gorrl1r33h9@4ax.com>

On Tue, 28 Jan 2003 16:01:06 +0000, you wrote in message
<F171eRaNgEpTX5V3Gyk00000356 at hotmail.com>:

>
>Dear R ers, if some can tel me how I can generate a sample from a given 
>density. I have a complex  2D density function en I want to genearte
>a sample from it? Any package?

That's generally a hard problem, and the answer depends a lot on the
particular characteristics of your distribution.  The easiest general
purpose method if you can calculate the density is probably MCMC, in
particular random walk Metropolis; see the book Markov Chain Monte
Carlo in Practice for details.  This will give you a Markov chain that
(hopefully) converges to your target distribution.  If you only want a
small sample, it's quite inefficient, but for a large sample (e.g. for
estimating moments) it can be quite good.

Support in R for MCMC is pretty much non-existent, but it's easy to
write the chains yourself.

Duncan Murdoch



From p.dalgaard at biostat.ku.dk  Wed Jan 29 15:45:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Jan 29 15:45:03 2003
Subject: [R] random number generator?
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BBF1@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD534BBF1@usrymx25.merck.com>
Message-ID: <x2adhkauef.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:


> .... As Prof. Dalgaard said (privately) ....

Whoops. That wasn't really intended as a private response. Must have
mixed up 'F' and 'R' again... Here it goes again:

----
> Might I suggest taking a poll (even though unscientific) of how many people
> will be affected by a change in default RNG?  My totally arbitrary guess is
> very few, if any.
> 
> If I'm not mistaken, Python had only recently changed the default RNG to
> Mersenne-Twister.  If Python can do it, I should think R can, too, without
> too much pain...

Well, Python is not a statistical system... However, I'm inclined to
agree. However, we'd want to get it right this time, and can we be
sure that the other generators are really better?

As long as the old behaviour can be reinstated, I see very few
applications that could get in serious trouble. Those who have sample
output in their books will have greater interest in keeping the
printed output in sync with their script output than in having perfect
distributions, but RNGkind() and set.seed() should take care of that
-- at least until they have to switch compiler or CPU (which BTW would
seem to be a point in favour of the inversion method over the
other normal generators where differences in rounding can change the
*number* of calls to the uniform generator, causing random sequences
to diverge. The uniform generators generally work in integer
arithmetic, so they are more generally reproducible.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From theis at statistik.uni-dortmund.de  Wed Jan 29 16:08:05 2003
From: theis at statistik.uni-dortmund.de (Winfried Theis)
Date: Wed Jan 29 16:08:05 2003
Subject: [R] Scoping rule problem -- solved: Code
In-Reply-To: <XFMail.030129132400.theis@statistik.uni-dortmund.de>
Message-ID: <XFMail.030129171601.theis@statistik.uni-dortmund.de>

Here comes the corrected code of my function, sorry for not posting it in the
earlier message.

 fitlms <- function(y,infl,formel=NULL){
        if(is.null(formel)){
          var.names <- names(infl)
          dcv <- length(var.names)
          formel <- paste("y~",paste(rep("I(",dcv), var.names,
 rep("^2)",dcv),sep="",collapse="+"),"+",paste(var.names,collapse="*"),sep="")
          formel <- as.formula(formel)
        }
        erg <- lm(formel) #<- Here I omit now the data=infl statement.
        erg <- step(erg)
        return(erg)}

This does work if "formel" is a formula-object, one should check for it, to
secure things...

Cheers, Winfried

---------------------------------------------------------------------
E-Mail: Winfried Theis <theis at statistik.uni-dortmund.de>
Date: 29-Jan-03

Dipl.-Math. Winfried Theis
SFB 475, Fachbereich Statistik, Universit"at Dortmund, 44221 Dortmund
Tel.: +49-231-755-5903 FAX: +49-231-755-4387
----------------------------------------------------------------------



From roger at ysidro.econ.uiuc.edu  Wed Jan 29 16:30:07 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Wed Jan 29 16:30:07 2003
Subject: [R] Help!!
In-Reply-To: <o9pf3vgsu12hk8ru3pl6s87gorrl1r33h9@4ax.com>
Message-ID: <Pine.SOL.4.30.0301290907560.4345-100000@ysidro.econ.uiuc.edu>

If you have a dominating density, ie another density, say g, such that cg(x)<f(x) for
some c<oo and all x, then you can easily do this by rejection.  See, e.g. Luc Devroye's
Springer book, which is the bible on this sort of thing....


url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
email	rkoenker at uiuc.edu	Department of Economics Drayton House,
vox: 	217-333-4558		University of Illinois	30 Gorden St,
fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK
							vox:	020-7679-5838

On Wed, 29 Jan 2003, Duncan Murdoch wrote:

> On Tue, 28 Jan 2003 16:01:06 +0000, you wrote in message
> <F171eRaNgEpTX5V3Gyk00000356 at hotmail.com>:
>
> >
> >Dear R ers, if some can tel me how I can generate a sample from a given
> >density. I have a complex  2D density function en I want to genearte
> >a sample from it? Any package?



From p.dalgaard at biostat.ku.dk  Wed Jan 29 16:41:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Jan 29 16:41:04 2003
Subject: [R] Help!!
In-Reply-To: <o9pf3vgsu12hk8ru3pl6s87gorrl1r33h9@4ax.com>
References: <F171eRaNgEpTX5V3Gyk00000356@hotmail.com>
	<o9pf3vgsu12hk8ru3pl6s87gorrl1r33h9@4ax.com>
Message-ID: <x265s8asau.fsf@biostat.ku.dk>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> On Tue, 28 Jan 2003 16:01:06 +0000, you wrote in message
> <F171eRaNgEpTX5V3Gyk00000356 at hotmail.com>:
> 
> >
> >Dear R ers, if some can tel me how I can generate a sample from a given 
> >density. I have a complex  2D density function en I want to genearte
> >a sample from it? Any package?
> 
> That's generally a hard problem, and the answer depends a lot on the
> particular characteristics of your distribution.  The easiest general
> purpose method if you can calculate the density is probably MCMC, in
> particular random walk Metropolis; see the book Markov Chain Monte
> Carlo in Practice for details.  This will give you a Markov chain that
> (hopefully) converges to your target distribution.  If you only want a
> small sample, it's quite inefficient, but for a large sample (e.g. for
> estimating moments) it can be quite good.
> 
> Support in R for MCMC is pretty much non-existent, but it's easy to
> write the chains yourself.

MCMC has big difficulty in generating *independent* samples. An
alternative might be rejection methods. This essentially requires that
you can find an "easy" density that can be scaled to be a majorant for
the target density (which it might take a bit of calculus to achieve).
Lets call the majorant g. Then draw X at random from this distribution
(with density proportional to g) and an additional uniform variable U
and return X if U < f(X)/g(X), else reject X and retry.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From boiko at demogr.mpg.de  Wed Jan 29 16:47:03 2003
From: boiko at demogr.mpg.de (Serge Boiko)
Date: Wed Jan 29 16:47:03 2003
Subject: [R] string to number conversion
Message-ID: <m2n0ljc3kf.fsf@boiko_linux.demogr.mpg.de>

Hi there;
In order to convert sting to number I do:
s <- "22"
mode(s) <- "integer" # "double", etc. will do

Is that a "preferred" way?

Many thanks.
-Serge



From rreeve at liposcience.com  Wed Jan 29 16:50:41 2003
From: rreeve at liposcience.com (Russell Reeve)
Date: Wed Jan 29 16:50:41 2003
Subject: [R] Analyzing an unbalanced AB/BA cross-over design
Message-ID: <30701A6FBB6D7542B664EED3152F982B04042E@LIPOMAIL.lipomed.lipoprofile.com>

For Type III SS, the sequence effect is determined by the subject, since subject is nested within sequence Type III gives the additional reduction in the residual SS after accounting for the other model terms. For Type I SS, you get the reduction in the residual SS after accounting for the model terms before the term in question. Since subject within sequence comes after subject, you get subject Type I SS. Note that you can omit the sequence effect entirely 

lm(outcome~treatment+period+subject, data=example)

The contrast of interest (on treatment) will not be affected. One should also note that sequence is confounded with period by treatment interaction, so beware. Further, the subject that has an observation missing is essentially removed from the analysis (doesn't affect the results). But that is not true if you use a mixed effect modeling engine, i.e.,

library(nlme)
my.lme <- lme(outcome~treatment+period, data=example, random=~1|subject)

In this model, all 8+7 observations affect the likelihood, and are used in fitting the fixed effects: The mixed effect model and the purely fixed effect model will give difference results for unbalanced data, same results for balanced data.

summary(my.lme) give the output:

Linear mixed-effects model fit by REML
 Data: example 
       AIC      BIC    logLik
  265.1293 270.8068 -127.5647

Random effects:
 Formula: ~1 | subject
        (Intercept) Residual
StdDev:    66.52344 27.39351

Fixed effects: outcome ~ treatment + period 
               Value Std.Error DF   t-value p-value
(Intercept) 333.8187  20.56392 12 16.233219  <.0001
treatmentS  -46.6071  10.77655 11 -4.324868  0.0012
period2      15.8929  10.77655 11  1.474763  0.1683
 Correlation: 
           (Intr) trtmnS
treatmentS -0.242       
period2    -0.242 -0.077

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-1.69842428 -0.41583473  0.06268074  0.52314988  1.28230120 

Number of Observations: 26
Number of Groups: 13 

The difference in means of treatment levels is S - F = -46.6, with SE 10.78.

If you add the sequence term to test for period by treatment interaction, you get fixed effects

Fixed effects: outcome ~ treatment + period + sequence 
               Value Std.Error DF   t-value p-value
(Intercept) 337.1429  28.27660 11 11.923035  <.0001
treatmentS  -46.6071  10.77654 11 -4.324871  0.0012
period2      15.8929  10.77654 11  1.474765  0.1683
sequence2    -7.2024  40.20272 11 -0.179152  0.8611

The sequence effect is not statistically significant (P=0.8611), and so one would not worry about treatment by period interaction here. If one had observed significant sequence effect, then one would need to either (a) analyze only the first period data, or (b) explain why the interaction is not real and can be ignored.

The advantages to the lme() analysis over the lm() analysis are: (1) sequence effect automatically gets appropriate denominator (not so for the lm version) (2) all data are actually used in the analysis, (3) We are trying to infer to the population of subjects, hence they should be thought of as random effects, not fixed effects (unless you really are interested in only those particular subjects).

If any of this is confusing, let me know.

Russell Reeve, Ph.D.
Dir of Experimental Design, Analysis, and Quality
rreeve at liposcience.com



From murdoch at stats.uwo.ca  Wed Jan 29 17:00:04 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed Jan 29 17:00:04 2003
Subject: [R] Help!!
In-Reply-To: <x265s8asau.fsf@biostat.ku.dk>
References: <F171eRaNgEpTX5V3Gyk00000356@hotmail.com> <o9pf3vgsu12hk8ru3pl6s87gorrl1r33h9@4ax.com> <x265s8asau.fsf@biostat.ku.dk>
Message-ID: <a4uf3vgkdjubgnegbqn2egn7n5hnp115bu@4ax.com>

On 29 Jan 2003 16:28:57 +0100, Peter Dalgaard BSA
<p.dalgaard at biostat.ku.dk> wrote in message
<x265s8asau.fsf at biostat.ku.dk>:


>MCMC has big difficulty in generating *independent* samples. 

That's true.  For an IID sample, a rejection sampler (if you can do
the calculus) is usually more efficient.  To get a a truly IID sample
from MCMC you need to start chains at independent starting values and
take one observation from each; that's probably too slow. 

Duncan Murdoch



From bdmccullough at drexel.edu  Wed Jan 29 17:19:03 2003
From: bdmccullough at drexel.edu (Bruce D McCullough)
Date: Wed Jan 29 17:19:03 2003
Subject: [R] random number generator?
Message-ID: <03012911143401.00856@mccullough.drexel.edu>

With respect to the method used to produce
normals, Professor Ripley noted:


>Were it not for concerns about reproducibility we would have switched to 
>Inversion a while back.

Presumably this refers to reproducibility across platforms.  

I searched the archive and could find nothing on this point.
Gentle's text on RNGs provided no answer, either.

Might Professor Ripley or someone else briefly explain why the
inversion method is not reproducible but Box-Muller is, or 
perhaps offer a citation?

Thanks,

Bruce



From bates at stat.wisc.edu  Wed Jan 29 17:23:48 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed Jan 29 17:23:48 2003
Subject: [R] Curve Fitting Question - Newbie
In-Reply-To: <7A3A13F416B40842BD2C1753E044B359B13363@CASEVS02.cas.anu.edu.au>
References: <7A3A13F416B40842BD2C1753E044B359B13363@CASEVS02.cas.anu.edu.au>
Message-ID: <6r1y2w7wuw.fsf@bates4.stat.wisc.edu>

"Simon Blomberg" <Simon.Blomberg at anu.edu.au> writes:

> One way would be to use the nls package:
> 
> library(nls)
>   # your y values
> foo.dat <- (0.83 * exp(-0.017 * 1:1000) + 0.5) + rnorm(1000,0,0.05) 
>   # create some x values in a data frame
> foo.dat <- data.frame(cbind(foo.dat, 0:999)) 
> names(foo.dat) <- c("y", "x") # give them names
>   # assume you have reasonable guesses for the starting parameter values
> model <- nls( y ~ N * exp(-r * x) + c,
>               start = list( N = 1, r = .01, c = 0), 
>               data = foo.dat) 
> 
> resid(model) # display residuals

Thanks for your answer Simon.  I would have suggested a similar
approach with two minor modifications:
  - use the logarithm of the rate constant r instead of r itself
  - take advantage of N and c being conditionally linear by using the
    'plinear' algorithm in nls.

The call to nls would be

 model <- nls(y ~ cbind(exp(-exp(lr) * x), 1), start = c(lr = log(.01)),
              data = foo.dat, alg = 'plinear')



From nina at math.uni-bremen.de  Wed Jan 29 17:37:03 2003
From: nina at math.uni-bremen.de (Nina Wawro)
Date: Wed Jan 29 17:37:03 2003
Subject: [R] help on cut?
Message-ID: <00b801c2c7b4$f3c240f0$557c6686@tating>

Dear R-users,

I'm trying to recode a variable.
After using
cut(data.vector,breaks=my.breaks,labels=my.label)
I need the data.vector to have the same values as the labels.


To make it clear:
x<-runif(10)
y<-cut(x,breaks=c(0,0.3,0.7,0.9,1),labels=c(3,6,7,9))
as.numeric(y) returns something like a vector 1 3 3 2 2 1 4 2 3 4 .
I need something like 3 7 7 6 6 3 7 9 6 7 9 for further use.

I might be using the wrong function but a loop seems to be inefficient as I
need to do it about 60 times with varying length of labels
Is there a quick solution?
Thanks for any help in advance!

Nina Wawro

R.1.6.0 on Windows2000



From bates at stat.wisc.edu  Wed Jan 29 17:44:02 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed Jan 29 17:44:02 2003
Subject: [R] string to number conversion
In-Reply-To: <m2n0ljc3kf.fsf@boiko_linux.demogr.mpg.de>
References: <m2n0ljc3kf.fsf@boiko_linux.demogr.mpg.de>
Message-ID: <6rr8av7vr3.fsf@bates4.stat.wisc.edu>

Serge Boiko <boiko at demogr.mpg.de> writes:

> Hi there;
> In order to convert sting to number I do:
> s <- "22"
> mode(s) <- "integer" # "double", etc. will do
> 
> Is that a "preferred" way?

Coersion functions are preferred.

> as.integer("22")
[1] 22
> as.numeric("22")
[1] 22

If you have the methods package attached you can use

> as("22", "numeric")
[1] 22



From matthew_wiener at merck.com  Wed Jan 29 17:48:10 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Wed Jan 29 17:48:10 2003
Subject: [R] help on cut?
Message-ID: <AEBD81486231A343B1813FE62D33522501317613@usrymx15.merck.com>

cut returns a factor.  Try something like 

t1 <- cut(data.vector, breaks = my.breaks, labels = my.label)
as.numeric(as.character(t1))

This is an issue that comes up frequently with factor.  Take a look at the
help page for factor for some warnings.

Hope this helps,

Matt Wiener

-----Original Message-----
From: Nina Wawro [mailto:nina at math.uni-bremen.de]
Sent: Wednesday, January 29, 2003 11:39 AM
To: R-help
Subject: [R] help on cut?


Dear R-users,

I'm trying to recode a variable.
After using
cut(data.vector,breaks=my.breaks,labels=my.label)
I need the data.vector to have the same values as the labels.


To make it clear:
x<-runif(10)
y<-cut(x,breaks=c(0,0.3,0.7,0.9,1),labels=c(3,6,7,9))
as.numeric(y) returns something like a vector 1 3 3 2 2 1 4 2 3 4 .
I need something like 3 7 7 6 6 3 7 9 6 7 9 for further use.

I might be using the wrong function but a loop seems to be inefficient as I
need to do it about 60 times with varying length of labels
Is there a quick solution?
Thanks for any help in advance!

Nina Wawro

R.1.6.0 on Windows2000

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------



From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Jan 29 17:53:03 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed Jan 29 17:53:03 2003
Subject: [R] help on cut?
In-Reply-To: <00b801c2c7b4$f3c240f0$557c6686@tating>
References: <00b801c2c7b4$f3c240f0$557c6686@tating>
Message-ID: <Pine.LNX.4.51.0301291748160.27522@artemis.imbe.med.uni-erlangen.de>

> Dear R-users,
>
> I'm trying to recode a variable.
> After using
> cut(data.vector,breaks=my.breaks,labels=my.label)
> I need the data.vector to have the same values as the labels.
>
>
> To make it clear:
> x<-runif(10)
> y<-cut(x,breaks=c(0,0.3,0.7,0.9,1),labels=c(3,6,7,9))
> as.numeric(y) returns something like a vector 1 3 3 2 2 1 4 2 3 4 .
> I need something like 3 7 7 6 6 3 7 9 6 7 9 for further use.

y is a factor and you want a numeric representing the factor labels, this
is in section 7.12 of the R-FAQ:

R> x<-runif(10)
R> y<-cut(x,breaks=c(0,0.3,0.7,0.9,1),labels=c(3,6,7,9))
R> y
 [1] 3 7 9 3 6 6 7 7 3 6
Levels: 3 6 7 9
R> as.numeric(as.character(y))
 [1] 3 7 9 3 6 6 7 7 3 6

Torsten

>
> I might be using the wrong function but a loop seems to be inefficient as I
> need to do it about 60 times with varying length of labels
> Is there a quick solution?
> Thanks for any help in advance!
>
> Nina Wawro
>
> R.1.6.0 on Windows2000
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From ripley at stats.ox.ac.uk  Wed Jan 29 17:57:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 29 17:57:05 2003
Subject: [R] random number generator?
In-Reply-To: <03012911143401.00856@mccullough.drexel.edu>
Message-ID: <Pine.LNX.4.44.0301291645160.5529-100000@gannet.stats>

Reproducibility of existing R scripts was meant.  Changing the default
behaviour of R is going to surprise a large number of users, who may not
even know which was the default generator when they did their runs.

On Wed, 29 Jan 2003, Bruce D McCullough wrote:

> With respect to the method used to produce
> normals, Professor Ripley noted:
> 
> 
> >Were it not for concerns about reproducibility we would have switched to 
> >Inversion a while back.
> 
> Presumably this refers to reproducibility across platforms.  

Presumption seems rather out of place.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From raf1729 at hotmail.com  Wed Jan 29 18:11:03 2003
From: raf1729 at hotmail.com (R A F)
Date: Wed Jan 29 18:11:03 2003
Subject: [R] Two y-axes for a plot
Message-ID: <F187PKDB2wdMeMs0dt200002365@hotmail.com>

Hi, how would I plot two series in the same plot, but with
two y-axes (one on the left and one on the right)?  Would
this be possible?  [The two series have quite different
y-values, so using the same y-axis for both is not possible.]

Thanks very much!



From fharrell at virginia.edu  Wed Jan 29 18:18:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed Jan 29 18:18:03 2003
Subject: [R] calling sweave function from latex
In-Reply-To: <15927.43499.805617.950194@galadriel.ci.tuwien.ac.at>
References: <3E372A6F.50900@niwa.cri.nz>
	<15927.43499.805617.950194@galadriel.ci.tuwien.ac.at>
Message-ID: <20030129121729.671e9344.fharrell@virginia.edu>

On Wed, 29 Jan 2003 11:16:11 +0100
Friedrich.Leisch at ci.tuwien.ac.at wrote:

> >>>>> On Wed, 29 Jan 2003 14:12:15 +1300,
> >>>>> Sam McClatchie (SM) wrote:
> 
>   > System info:
>   > Mandrake 9.0
>   > R Version 1.6.1
>   > ESS 5.1.21
>   > Emacs 21.2.1
>   > -------------------
> 
>   > Colleagues
> 
>   > I've been calling R-code embedded in my LaTex document using Sweave, but 
>   > would like to make things more convenient. At present as I understand it 
>   >   you first process the R chunks of code using the Sweave function 
>   > called from within R to process a "precursor file" e.g. foo.sw to get a 
>   > LaTex file (foo.sw.tex) that you then process with latex foo.sw.tex.
>   > ------------------------
>   > example code segment
> 
>   > %\item {\bf Matched trawl and acoustic data} \label{real data}
> 
>   > \item {\bf Results}
> 
>   > %%%% sweave code
> 
>   > <<echo=false,results=hide>>=
>   > average.trawl.spp.composition()
>   > @
> 
>   > %%%% insert figure generated from sweave code
>   > \begin{figure}
>   > \includegraphics[scale=0.6]{../figures/bycatch_by_weight}
>   > \caption{\label{catch by weight} Proportions of selected species (from
>   >      Table \ref{ts length regressions}) in the fish assemblage using
>   >      catch rate ($kg\ km{-1}$) as an approximation for fish density
>   >      (neglecting variable capture efficiencies). Note: there were no
>   >      oblique banded rattails in this dataset, although we have a
>   >      \textit{<TS>-length} regression for them (see Table \ref{ts length
>   >      regressions}). Box plot centre line = meadian, box limits are
>   >      $25^{th}$ and $75^{th}$ quartiles, whiskers represent 1.5 times the
>   >      interquartile range from the median, and points outside the whiskers
>   >      are the tails of the distributions.}
>   > \end{figure}
>   > -----------------------
> 
>   > This works fine, but it is cumbersome for someone who likes to write a 
>   > bit and then latex that additional bit. Of course I can just add the new 
>   > LaTex code chunks to the foo.sw.tex and latex that, but I have to 
>   > remember to copy the foo.sw.tex back to foo.sw or the versions get mixed 
>   > up. Trivial, but annoying.
> 
>   > The question is: can I call the Sweave function from within LaTex so I 
>   > just latex the foo.sw.tex and the Sweave chunks will also get processed. 
>   > This would be much tidier.
> 
>   > One suspects that the short answer is 'no'.
> 
> 
> 
> One way to deal with this is to write several Sweave filew and collect
> them into the main latex document using \input{} statements. Then you
> can Sweave() only those files which have some changes, makefiles can
> automate that easily.
> 
> I have some ideas on conditional processing of chunks and re-using
> previously saved results in case nothing has changed, but that has not
> been implemented yet.
> 
> Best,
> Fritz
> 

Before I discovered Sweave, I used methods that are detailed in Chapter 13 of http://hesweb1.med.virginia.edu/biostat/s/doc/splus.pdf for managing large analysis projects.  The do function in the Hmisc library (not yet tested for R) was created to manage code chunks that each create their own series of output listings and postscript graphics files.  For conditional execution of chunks, it helps me to set flags at the start of the document so that I don't have to hunt for any flags or if statements.  I do things like

importdata    <- FALSE
fitmodel      <- FALSE
validatemodel <- TRUE

if(importdata) {
 ...
}
if(fitmodel) {
 ...
}
if(validatemodel) {
 ... time-consuming bootstrap code ...
}

or use

do(importdata, { ... code chunk ...})
do(fitmodel, {... code chunk ...})
do(validatemodel, {... code chunk ...})

where the keys such as 'importdata' are used as root names of files created by that code chunk.  The 'validatemodel' chunk creates by default 'validatemodel.lst' to contain the printed output, and files such as 'validatemodel.ps' for graphics.

It would be nice if Sweave could implement this type of model.  In LaTeX I find it invaluable to set flags for conditional text insertion using \def and \ifnum \fi.  For a report, the text might always be included but S chunks only condionally run, with previous output used when a chunk is bypassed.

Please take a look at Chapter 13 of the above referenced document if you have time, to see if it gives you any ideas worth pursuing.

Sincerely,

Frank
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From heberto.ghezzo at mcgill.ca  Wed Jan 29 19:37:02 2003
From: heberto.ghezzo at mcgill.ca (Heberto Ghezzo)
Date: Wed Jan 29 19:37:02 2003
Subject: [R] na.rm in sd()
Message-ID: <3E381F28.2080607@mcgill.ca>

Hello, I think this qualify as a bug
 > x<-c(1,2,3,4,NA,6,7)
 > mean(x)
[1] NA
 > mean(x,na.rm=T)
[1] 3.833333
 > sd(x)
Error in var(as.vector(x)) : missing observations in cov/cor
 > sd(x,na.rm=T)
Error in sd(x, na.rm = T) : unused argument(s) (na.rm ...)
 > var(x)
Error in var(x) : missing observations in cov/cor
 > var(x,na.rm=T)
[1] 5.366667
 >
why sd() does not recognize the na.rm=T parameter, while var does?

R 1.6.1 on Win98

R.Heberto Ghezzo Ph.D.
Meakins-Christie Labs
McGill University
Montreal - Canada



From bates at stat.wisc.edu  Wed Jan 29 19:46:02 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed Jan 29 19:46:02 2003
Subject: [R] na.rm in sd()
In-Reply-To: <3E381F28.2080607@mcgill.ca>
References: <3E381F28.2080607@mcgill.ca>
Message-ID: <6rd6mf6bhv.fsf@bates4.stat.wisc.edu>

Heberto Ghezzo <heberto.ghezzo at mcgill.ca> writes:

> Hello, I think this qualify as a bug
>  > x<-c(1,2,3,4,NA,6,7)
>  > mean(x)
> [1] NA
>  > mean(x,na.rm=T)
> [1] 3.833333
>  > sd(x)
> Error in var(as.vector(x)) : missing observations in cov/cor
>  > sd(x,na.rm=T)
> Error in sd(x, na.rm = T) : unused argument(s) (na.rm ...)
>  > var(x)
> Error in var(x) : missing observations in cov/cor
>  > var(x,na.rm=T)
> [1] 5.366667
>  >
> why sd() does not recognize the na.rm=T parameter, while var does?

It does, in R-1.6.2

> args(sd)
function (x, na.rm = FALSE)



From tlumley at u.washington.edu  Wed Jan 29 19:49:24 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Jan 29 19:49:24 2003
Subject: [R] na.rm in sd()
In-Reply-To: <3E381F28.2080607@mcgill.ca>
Message-ID: <Pine.A41.4.44.0301291044090.62384-100000@homer21.u.washington.edu>

On Wed, 29 Jan 2003, Heberto Ghezzo wrote:

> Hello, I think this qualify as a bug
>  > x<-c(1,2,3,4,NA,6,7)
>  > mean(x)
> [1] NA
>  > mean(x,na.rm=T)
> [1] 3.833333
>  > sd(x)
> Error in var(as.vector(x)) : missing observations in cov/cor
>  > sd(x,na.rm=T)
> Error in sd(x, na.rm = T) : unused argument(s) (na.rm ...)
>  > var(x)
> Error in var(x) : missing observations in cov/cor
>  > var(x,na.rm=T)
> [1] 5.366667
>  >
> why sd() does not recognize the na.rm=T parameter, while var does?
>
> R 1.6.1 on Win98
>

It works for me in R 1.6.1 on Windows.

 > x<-c(1,2,3,4,NA,6,7)
 > sd(x,na.rm=TRUE)
  [1] 2.316607

and looking at the code for sd it certainly should.  Are you sure you
don't have another defintion of sd() lurking?


	-thomas



From ligges at statistik.uni-dortmund.de  Wed Jan 29 19:54:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Jan 29 19:54:03 2003
Subject: [R] na.rm in sd()
In-Reply-To: <3E381F28.2080607@mcgill.ca>
References: <3E381F28.2080607@mcgill.ca>
Message-ID: <3E382348.2000609@statistik.uni-dortmund.de>

Heberto Ghezzo wrote:
> Hello, I think this qualify as a bug
>  > x<-c(1,2,3,4,NA,6,7)
>  > mean(x)
> [1] NA
>  > mean(x,na.rm=T)
> [1] 3.833333
>  > sd(x)
> Error in var(as.vector(x)) : missing observations in cov/cor
>  > sd(x,na.rm=T)
> Error in sd(x, na.rm = T) : unused argument(s) (na.rm ...)
>  > var(x)
> Error in var(x) : missing observations in cov/cor
>  > var(x,na.rm=T)
> [1] 5.366667
>  >
> why sd() does not recognize the na.rm=T parameter, while var does?


> R 1.6.1 on Win98

It works with R-1.6.2 (!) which is recent.
There was a bug fix regarding NAs and sd() in R-1.6.1, so I guess your 
version is older than the official release of R-1.6.1.

Uwe Ligges


> R.Heberto Ghezzo Ph.D.
> Meakins-Christie Labs
> McGill University
> Montreal - Canada
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From v_bill_pikounis at merck.com  Wed Jan 29 20:09:02 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Wed Jan 29 20:09:02 2003
Subject: [R] browser() misbehavior ?
Message-ID: <E827328028C66044B4998F2EC353CD300318515B@usrymx12.merck.com>

Under v1.6.2, Windows NT4 OS, when a function contains an execution error
and I have placed browser() in inside the function body, the call to browser
is ignored.  A brief example to illustrate:

> foo <- function(x) {
+   y <- x ^ 2
+   browser()
+   foo2(x)  ## Intentional error
+   x ^ 3  
+ }
> 

> foo(30)
Called from: foo(30)
Browse[1]> 
Error in foo(30) : couldn't find function "foo2"

## browser() still seems to be ignored even if a function has no execution
error

> traceback()
1: foo(30)

Has anyone else experienced this?  I am using v1.6.2 on Windows NT 4. 

Under Linux i686 (Mandrake 9.0), the same example works as expected;
execution is stopped and I can usefully browser() as it is designed.

As always, any advice is welcome.

Thanks,
Bill

----------------------------------------
Bill Pikounis, Ph.D.
Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

v_bill_pikounis at merck.com

Phone: 732 594 3913
Fax: 732 594 1565



------------------------------------------------------------------------------



From ripley at stats.ox.ac.uk  Wed Jan 29 20:25:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 29 20:25:03 2003
Subject: [R] browser() misbehavior ?
In-Reply-To: <E827328028C66044B4998F2EC353CD300318515B@usrymx12.merck.com>
Message-ID: <Pine.LNX.4.44.0301291918520.12748-100000@gannet.stats>

If I understand you correctly, the call is not ignored (you get a browser
prompt up), but the browser gets quit immediately, as if return had been
pressed.  Note that no error has occurred at the point when browser() is
called, so whether the next statement will give an error ought to be
immaterial.

I don't have access to NT4, but on XP it works as expected (and I do this
sort of thing all the time).  Puzzling ....

On Wed, 29 Jan 2003, Pikounis, Bill wrote:

> Under v1.6.2, Windows NT4 OS, when a function contains an execution error
> and I have placed browser() in inside the function body, the call to browser
> is ignored.  A brief example to illustrate:
> 
> > foo <- function(x) {
> +   y <- x ^ 2
> +   browser()
> +   foo2(x)  ## Intentional error
> +   x ^ 3  
> + }
> > 
> 
> > foo(30)
> Called from: foo(30)
> Browse[1]> 
> Error in foo(30) : couldn't find function "foo2"
> 
> ## browser() still seems to be ignored even if a function has no execution
> error
> 
> > traceback()
> 1: foo(30)
> 
> Has anyone else experienced this?  I am using v1.6.2 on Windows NT 4. 
> 
> Under Linux i686 (Mandrake 9.0), the same example works as expected;
> execution is stopped and I can usefully browser() as it is designed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fnj at cin.ufpe.br  Wed Jan 29 20:33:02 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Wed Jan 29 20:33:02 2003
Subject: [R] Error
Message-ID: <Pine.GSO.4.32.0301291623060.21900-100000@goiana>

people,

I'm using the pixmap library and method read.pnm() for to read figures and
it's
giving the following error:
Error in substr(inpstr, com1, stop = ns) :
        evaluation is nested too deeply: infinite recursion?

I think that to be because of its size.
Am I correct?

Tks,
Francisco.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco Júnior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From pgilbert at bank-banque-canada.ca  Wed Jan 29 20:37:06 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed Jan 29 20:37:06 2003
Subject: [R] random number generator?
References: <3A822319EB35174CA3714066D590DCD534BBF1@usrymx25.merck.com> <x2adhkauef.fsf@biostat.ku.dk>
Message-ID: <3E382CCF.3D8D9531@bank-banque-canada.ca>

Peter Dalgaard BSA wrote:

> As long as the old behaviour can be reinstated, I see very few
> applications that could get in serious trouble. Those who have sample
> output in their books will have greater interest in keeping the
> printed output in sync with their script output than in having perfect
> distributions, but RNGkind() and set.seed() should take care of that

Reproducibility is an issue for me, but having been bitten a long time ago with
S, I think I am now keeping track of all the appropriate information. Even with
the current system, there is not reproducibility unless users have kept track of
the seed. They can probably determine the RNGkind even if they have not recorded
it (if necessary by loading an old version of R from the archives). So, as long
as the old generators and transformations are available, then users should be
able to reproduce results if they ever took the current precautions necessary to
be able to do that. It is possible that there should be a mechanism for
indicating that a set of old defaults should be used.

If reworking the RNG mechanism is considered seriously (and I am not advocating
that), I suggest:

1/ There should be a simple mechanism for keeping track of and resetting all the
information to generate random numbers, that is, seed, uniform generator, and
transformations. (I have a package, which I intend to distribute shortly, that
does this for normal distributions and might form a basis for this mechanism. It
was previously part of my syskern package in dse, and so the mechanism has been
fairly well tested over several years.)

2/ Perhaps there should not be a default behavior, so that users actually have
to initialize something, and get an indication of information they should record
if they want to reproduce the results. That would make it easier to introduce
new RNGs as they are developed.

> -- at least until they have to switch compiler or CPU 

I've actually had pretty good luck with this, even between Splus and R on
different systems. The biggest differences are not the ones you might expect.

Paul Gilbert



From ripley at stats.ox.ac.uk  Wed Jan 29 20:56:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 29 20:56:03 2003
Subject: [R] random number generator?
In-Reply-To: <3E382CCF.3D8D9531@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.44.0301291950340.12794-100000@gannet.stats>

On Wed, 29 Jan 2003, Paul Gilbert wrote:

> If reworking the RNG mechanism is considered seriously (and I am not advocating
> that), I suggest:
> 
> 1/ There should be a simple mechanism for keeping track of and resetting all the
> information to generate random numbers, that is, seed, uniform generator, and
> transformations. (I have a package, which I intend to distribute shortly, that
> does this for normal distributions and might form a basis for this mechanism. It
> was previously part of my syskern package in dse, and so the mechanism has been
> fairly well tested over several years.)

That's what RNGkind and set.seed do, and have done for a long time.
The information is also stored in .Random.seed, but few users would record 
that (and it does not exist until the first RNG is used).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From john_hendrickx at yahoo.com  Wed Jan 29 21:01:03 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Wed Jan 29 21:01:03 2003
Subject: [R] multinomial conditional logit models
Message-ID: <20030129195720.67695.qmail@web14208.mail.yahoo.com>

A multinomial logit model can be specified as a conditional logit
model after restructuring the data. Doing so gives flexibility in
imposing restrictions on the dependent variable. One application is
to specify a loglinear model for square tables, e.g. quasi-symmetry
or quasi-independence, as a multinomial logit model with covariates.
Further details on this technique and examples with several packages
are on my homepage at http://www.xs4all.nl/~jhckx/mcl/

I've been trying to implement an MCL model in R and have been mostly
succesful. However I'm still stuck on a few points and I'm hoping
someone can point out how to do fix them.

To estimate an MCL model, the data must be restructured into a
person-choice file. 

* Each case must be duplicated "ncat" times ("ncat" is the number of
categories of the dependent variable)
* Each case must be identified by a strata variable (id)
* Each duplicate must be identified by a variable indexing the
choices (newy)
* A dichotomous variable must indicate which duplicate corresponds
with the respondent's choice (didep)

I've done this as follows:

mclgen <- function (datamat,catvar) {
	ncat <- nlevels(catvar)
	id<-1:length(catvar)
	datamat<-cbind(id,datamat)
	perschoice <-NULL
	for (i in 1:ncat) {
		perschoice<-rbind(perschoice,datamat)
	}
	perschoice<-perschoice[sort.list(perschoice$id),]
	perschoice$newy<-gl(ncat,1,length=nrow(perschoice))
	dep<-parse(text=paste("perschoice$",substitute(catvar),sep=""))
	perschoice$depvar<-as.numeric(eval(dep)==perschoice$newy)
	perschoice
}

This works but I wonder if it's the most efficient method. I tried
using "rep" rather than "rbind" in a loop but that replicated the
dataset horizontally, not vertically. Is this the best solution?

I also finally figure out how to include the argument "catvar" in a
transformation involving another dataset but this solution seems very
complicated (eval+parse+substitute). Is there a simpler solution?

What I haven't figured out is how to use "catvar" once again but on
the righthand side of the transformation. In the second to last line,
I'd like to do "perschoice$catvar<-perschoice$newy". I've tried
several possibities but I can't figure out how to let R substitute
the value of "catvar" in that expression. "eval(dep)" doesn't work as
it does for the lefthand side but how should it be done? 

My solution for now is to do it afterward. My program continues as
follows:

pc<-mclgen(logan,occ)
pc$occ<-factor(pc$newy)
library(survival)
cl.lr<-clogit(depvar~occ+occ:educ+occ:black+strata(id),data=pc)
summary(cl.lr)

The dataset "logan" is available from the website. "occ" is the
dependent variable, "educ" and "black" are independents. Once
"mclgen" has transformed the data into a person-choice file, a
multinomial logit model can be estimated using the dichotomous
dependent variable, the main effects of "occ" for the intercept term
and interactions of "educ" and "black" with "occ" for the effects of
these variables. 

This works more or less. What's unexpected though is that the
reference category of "occ" isn't dropped in the interactions with
"educ" and "black". The highest category is dropped due to
collineairity but that's not quite what I want. Could someone explain
why this happens and how to let R drop the first category?

A final problem is that the results of clogit are only approximate (2
digits) whereas in other packages the cl model produces exactly the
same estimates as an mnl model. Is this because terms are dropped due
to collinearity or are there options I should examine. clogit issues
the following warnings which seem to be related to the collinearity
but perhaps point to something else:

Warning messages: 
1: Loglik converged before variable  10 ; beta may be infinite.  in:
fitter(X, Y, strats, offset, init, control, weights = weights,  
2: X matrix deemed to be singular; variable 9 14 in: coxph(formula =
Surv(rep(1, 4190), depvar) ~ occ + occ:educ +  

Apologies for the length of this post. Hopefully someone will have
time to read it through and help me out. As always, advance thanks
for any assistance.

John Hendrickx



From fharrell at virginia.edu  Wed Jan 29 21:14:09 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed Jan 29 21:14:09 2003
Subject: [R] Statistical Tables and Plots using S and LaTeX
Message-ID: <20030129151419.6e90b003.fharrell@virginia.edu>

I am pleased to announce a major revision of the document "Statistical Tables and Plots using S and LaTeX".  It is available at http://hesweb1.med.virginia.edu/biostat/s/doc/summary.pdf (76 pages, 500K).  It should be of interest to those who produce statistical reports or those who use or would be interested in using LaTeX, the greatest productivity tool for document processing in my opinion.

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From p.dalgaard at biostat.ku.dk  Wed Jan 29 21:41:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Jan 29 21:41:03 2003
Subject: [R] random number generator?
In-Reply-To: <Pine.LNX.4.44.0301291950340.12794-100000@gannet.stats>
References: <Pine.LNX.4.44.0301291950340.12794-100000@gannet.stats>
Message-ID: <x2n0ljelji.fsf@biostat.ku.dk>

ripley at stats.ox.ac.uk writes:

> That's what RNGkind and set.seed do, and have done for a long time.
> The information is also stored in .Random.seed, but few users would record 
> that (and it does not exist until the first RNG is used).

.. but if you don't set the seed, you shouldn't expect reproducible
behaviour anyway:

[pd at rasch pd]$ echo "rnorm(2)" | R --vanilla --slave
[1] 2.0281025 0.8735026

[pd at rasch pd]$ echo "rnorm(2)" | R --vanilla --slave
[1] -1.2695122 -0.0448524

I mean, if the prototypical answer to people complaining "I'm not
getting the same results" is simply to ask them to put an 
RNGkind("Marsaglia-Multicarry","Kinderman-Ramage") next to their first
set.seed(), how troublesome could it be?
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From pgilbert at bank-banque-canada.ca  Wed Jan 29 22:14:02 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed Jan 29 22:14:02 2003
Subject: [R] random number generator?
References: <Pine.LNX.4.44.0301291950340.12794-100000@gannet.stats>
Message-ID: <3E3843BE.ECBAA967@bank-banque-canada.ca>

ripley at stats.ox.ac.uk wrote:
> 
> On Wed, 29 Jan 2003, Paul Gilbert wrote:
> 
> > If reworking the RNG mechanism is considered seriously (and I am not advocating
> > that), I suggest:
> >
> > 1/ There should be a simple mechanism for keeping track of and resetting all the
> > information to generate random numbers, that is, seed, uniform generator, and
> > transformations. (I have a package, which I intend to distribute shortly, that
> > does this for normal distributions and might form a basis for this mechanism. It
> > was previously part of my syskern package in dse, and so the mechanism has been
> > fairly well tested over several years.)
> 
> That's what RNGkind and set.seed do, and have done for a long time.
> The information is also stored in .Random.seed, but few users would record
> that (and it does not exist until the first RNG is used).

Yes, basically I use those and put the information together into an object. The
only other thing I record is version, but have never needed to use that yet. I'm
not suggesting this is especially fancy or complicated, just a lot easier to do
when you use it all the time. It also gives a single object that you can pass to
simulation methods when you want to reproduce something; and pass back from
simulations in the object they generate, so that you don't have to remember to
do anything special and will still be able to reproduce results. Probably the
biggest complication is handling the fact that the seed is not initialized until
the RNG is first called, and this too is relatively trivial to handle. 

Paul Gilbert



From elvis at xlsolutions-corp.com  Wed Jan 29 22:24:03 2003
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Wed Jan 29 22:24:03 2003
Subject: [R] Course***R/Splus Fundamentals and Programming Techniques***February 2003
Message-ID: <APEHLKCMHHAKBGLAPKPCMEOGCBAA.elvis@xlsolutions-corp.com>

XLSolutions Corporation (www.xlsolutions-corp.com) is pleased to 
announce a two-day R course, "R Fundamentals and Programming
Techniques":

****Houston, Tx ------------> February 21-22
****Atlanta ----------------> February 24-25
****London, UK -------------> February 27-28  

Early bird registration: 5% off ends January 31st.
 

Payment due 7 days AFTER the class and Includes course materials, 
90 days Technical Support for R, snacks and continental breakfast!)


R is a freely available implementation of the S language and environment, 
for statistical computing and graphics similar to the commercial S-PLUS. 
You can download a copy of R software (Windows, Mac, Unix & Linux) 
from http://cran.r-project.org.

Course Description:

This two-day R course focuses on a broad spectrum of topics, from
reading raw data to a comparison of R, S and SAS. We will learn the 
essentials of data manipulation, graphical visualization and R 
programming. We will explore statistical data analysis tools, including 
graphics with data sets from areas such as Finance, Biopharm, 
manufacturing and E-commerce. However, participants are encouraged to
bring their own data for an interactive session with the trainer.


Registration and more information on outline, fees and trainers: 


Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578 x221

Visit us: www.xlsolutions-corp.com/training.htm


Course Format:

This course consists of a series of short lectures with demonstrations and 
interactive sessions for the participants. Each student is provided with 
bound copies of the notes and a CD-ROM containing all examples, 
exercises and software used on the course.


Share Your Thoughts:

Are there any additional topics you would like for this course to address?
Would you like for this course to be offered in another city? 

Please let us know by contributing to our recommendation list: 
training at xlsolutions-corp.com.


================================================


Two-day R Fundamentals and Programming Techniques  

Pre-registration Form (Please email or print and fax: 206-686-1578)
XLsolutions Corporation: For your Solutions needs, Consulting and 
Training. www.xlsolutions-corp.com



Title...... First Name ................. Last Name....................

Organization..........................................................

Mailing Address....................................................... 

...............................................................

...............................................................

Zip Code...................... Country.............................

Telephone........................... Fax ...............................

E-mail................................................................

Payment will be made by: (1) check (2) invoice

Sincerely

Elvis Miller, PhD
Manager Training and Technical Support
North American Division
XLSolutions Corporation
Email: elvis at xlsolutions-corp.com
Phone: 206-686-1578
Web: www.xlsolutions-corp.com


XLSolutions also offer customized private courses delivered by expert
trainers with a track teaching and training record in their fields.

XLSolutions Consulting Group meets your needs from design to development.



From heberto.ghezzo at mcgill.ca  Wed Jan 29 22:28:05 2003
From: heberto.ghezzo at mcgill.ca (Heberto Ghezzo)
Date: Wed Jan 29 22:28:05 2003
Subject: [R] problems with by()
Message-ID: <3E384689.6050303@mcgill.ca>

Hello, another problem.
 > x<-rep(1,10)
 > y<-rep(c(1,2),c(5,5))
 > z<-seq(1:10)
 > ab<-data.frame(x,y,z)
#
    now I want to do some work by the value of 'y'
 > by(ab,y,mean)
y: 1
x y z
1 1 3
------------------------------------------------------------
y: 2
x y z
1 2 8
#
    I do not want all the means, only the mean of 'z'
 > by(ab,y,function(x) mean(z))
y: 1
[1] 5.5
------------------------------------------------------------
y: 2
[1] 5.5
 > by(ab,y,function(x) mean(z,data=x))
y: 1
[1] 5.5
------------------------------------------------------------
y: 2
[1] 5.5
 >
#
    so, how can I get the function(x) to be applied to each level
of the index variable y.
Actually I use my own function but the same happens, it is applied to all
the data and there is no partition of the data acording to index
Do not tell me that this version of R is completely buggy, I was waiting
for the 1.7 to be out before upgrading

R : Copyright 2002, The R Development Core Team
Version 1.6.1  (2002-11-01)

R.Heberto.Ghezzo Ph.D.
Meakins-Christie Labs
McGill University
Montreal - Canada



From Roger.Bivand at nhh.no  Wed Jan 29 22:32:02 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed Jan 29 22:32:02 2003
Subject: [R] Error
In-Reply-To: <Pine.GSO.4.32.0301291623060.21900-100000@goiana>
Message-ID: <Pine.LNX.4.44.0301292220590.2236-100000@reclus.nhh.no>

(Please use a more informative Subject:, for example naming the package. I
haven't changed the Subject:, but it should be "substr() error in
read.pnm")

On Wed, 29 Jan 2003, Francisco do Nascimento Junior wrote:

> people,
> 
> I'm using the pixmap library and method read.pnm() for to read figures and
> it's
> giving the following error:
> Error in substr(inpstr, com1, stop = ns) :
>         evaluation is nested too deeply: infinite recursion?

If you look at the code of read.pnm() you see that it calls 
read.pnmhead(). Within this is a function called strip.comments(). My 
guess is that someone has written a dissertation instead of a comment. PNM 
files have ASCII headers, so you could try simply shortening any comments 
you see. If you can put the offending file on a website I can take a look 
at it. At present read.pnmhead() assumes that the header is not more than 
350 characters long; if you enter debug(read.pnmhead) before running 
read.pnm(), you will see which line it fails at. Please contact me off the 
list.

Roger Bivand

> 
> I think that to be because of its size.
> Am I correct?
> 
> Tks,
> Francisco.
> 
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Francisco J?nior,
> Computer Science - UFPE-Brazil
> "One life has more value that the
> world whole"
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From bmagill at earthlink.net  Wed Jan 29 22:48:02 2003
From: bmagill at earthlink.net (Brett Magill)
Date: Wed Jan 29 22:48:02 2003
Subject: [R] problems with by()
Message-ID: <2055832.1043876843160.JavaMail.nobody@ernie.psp.pas.earthlink.net>

> x<-rep(1,10)
> y<-rep(c(1,2),c(5,5))
> z<-seq(1:10)
> ab<-data.frame(x,y,z)
> tapply(ab$z,ab$y,mean)
1 2 
3 8 


-------Original Message-------
From: Heberto Ghezzo <heberto.ghezzo at mcgill.ca>
Sent: 01/29/03 03:24 PM
To: r-help <r-help at stat.math.ethz.ch>
Subject: [R] problems with by()

so, how can I get the function(x) to be applied to each level
of the index variable y.

Actually I use my own function but the same happens, it is applied to all the data and there is no partition of the data acording to index



From fnj at cin.ufpe.br  Wed Jan 29 23:03:02 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Wed Jan 29 23:03:02 2003
Subject: [R] Error using read.pnm() of pixmap
Message-ID: <Pine.GSO.4.32.0301291900520.21900-100000@goiana>

people,

I'm using the pixmap library and method read.pnm() for to read figures and
it's
giving the following error:
Error in substr(inpstr, com1, stop = ns) :
        evaluation is nested too deeply: infinite recursion?

I think that to be because of its size.
Am I correct?

Tks,
Francisco.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco Júnior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Wed Jan 29 23:23:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed Jan 29 23:23:03 2003
Subject: [R] Two y-axes for a plot
In-Reply-To: <F187PKDB2wdMeMs0dt200002365@hotmail.com>
Message-ID: <3E381BB1.30100.1ED61A@localhost>

On 29 Jan 2003 at 17:05, R A F wrote:

This has been asked many times, so you should try the mail archives, 
available from the CRAN main page. The short answer is

?par
plot( ...., ann=FALSE)
axis

Kjetil Halvorsen


> Hi, how would I plot two series in the same plot, but with
> two y-axes (one on the left and one on the right)?  Would
> this be possible?  [The two series have quite different
> y-values, so using the same y-axis for both is not possible.]
> 
> Thanks very much!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ozric at web.de  Wed Jan 29 23:34:02 2003
From: ozric at web.de (Christian Schulz)
Date: Wed Jan 29 23:34:02 2003
Subject: [R] RODBC sqlSave Error
Message-ID: <001f01c2c7e5$da6e5fe0$0eb407d5@c5c9i0>

Hi,

i get error after using a data.frame with subset  for "sqlSave".
What can i do ?

It seems that  lines like this in a data.frame structure are after subset
deleted and cause
the error ?

 - attr(*, "variable.labels")= Named chr  "CUSID" "Welle"
"Arbeitgeberfavorit1" "Aktuelle Bewerbungssituation" ...
  ..- attr(*, "names")= chr  "CUSID" "WELLE" "Q21" "BEWERB" ...

sqlSave(channel,mno.x,verbose=T)
Query: CREATE TABLE mno.x  (rownames varchar(255)  ,BEWERB double
,MEDIENPR?SENZ double  ,GESCHLECHT double  )
Error in sqlSave(channel, mno.x, verbose = T) :
        [RODBC] ERROR: Could not SQLExecute
>>str(mno.x)
`data.frame':   583 obs. of  3 variables:
 $ BEWERB       : num  2 2 1 2 1 1 2 2 1 1 ...
 $ MEDIENPR?SENZ: num   73.3  75.0  70.0  60.0 100.0 ...
 $ GESCHLECHT   : num  1 1 1 1 1 1 1 1 1 1 ...


{ RODBC-1-0-1,R-1.6.2,W2k }

many thanks, christian



From ripley at stats.ox.ac.uk  Wed Jan 29 23:47:45 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Jan 29 23:47:45 2003
Subject: [R] RODBC sqlSave Error
In-Reply-To: <001f01c2c7e5$da6e5fe0$0eb407d5@c5c9i0>
Message-ID: <Pine.LNX.4.44.0301292242330.24281-100000@gannet.stats>

The error is quite clear: the SQLexecute command failed.  That's not an R 
error, but an SQL error, so ask your DBMS helpline.  For example, does
whatever DBMS this is support German labels?  Does it support table names 
like mno.x?  Do you have permissions to create tables? ....

On Wed, 29 Jan 2003, Christian Schulz wrote:

> Hi,
> 
> i get error after using a data.frame with subset  for "sqlSave".
> What can i do ?
> 
> It seems that  lines like this in a data.frame structure are after subset
> deleted and cause
> the error ?
> 
>  - attr(*, "variable.labels")= Named chr  "CUSID" "Welle"
> "Arbeitgeberfavorit1" "Aktuelle Bewerbungssituation" ...
>   ..- attr(*, "names")= chr  "CUSID" "WELLE" "Q21" "BEWERB" ...
> 
> sqlSave(channel,mno.x,verbose=T)
> Query: CREATE TABLE mno.x  (rownames varchar(255)  ,BEWERB double
> ,MEDIENPR?SENZ double  ,GESCHLECHT double  )
> Error in sqlSave(channel, mno.x, verbose = T) :
>         [RODBC] ERROR: Could not SQLExecute
> >>str(mno.x)
> `data.frame':   583 obs. of  3 variables:
>  $ BEWERB       : num  2 2 1 2 1 1 2 2 1 1 ...
>  $ MEDIENPR?SENZ: num   73.3  75.0  70.0  60.0 100.0 ...
>  $ GESCHLECHT   : num  1 1 1 1 1 1 1 1 1 1 ...
> 
> 
> { RODBC-1-0-1,R-1.6.2,W2k }
> 
> many thanks, christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mentus at gmx.de  Thu Jan 30 00:29:03 2003
From: mentus at gmx.de (Fernando Henrique Ferraz Pereira da Rosa)
Date: Thu Jan 30 00:29:03 2003
Subject: [R] Weird options(digits=n) behaviour
Message-ID: <30808.1043882921@www59.gmx.net>

     I noticed some very weird behaviour of the function: options(digits=n),
where n is the number of digits you would expect to get in R calculations.
     Let's take a example:

> options(digits=4)
> getdata(caso.pool.k3.r3.e2)
[1]  6.053  2.641 -3.639 14.259  6.082

     Which works fine... now, trying again, with different data:

> options(digits=4)
> getdata(controle.pool.k3.r3.e2)
[1] -0.03091  1.60310 -4.90588  5.07379 -0.04418
>
    Which gives me 6 digits instead of 6. If I try digits=2, it then works
with this data:
> options(digits=2)
> getdata(controle.pool.k3.r3.e2)
[1] -0.031  1.603 -4.906  5.074 -0.044

   But not with the first one:

> getdata(caso.pool.k3.r3.e2)
[1]  6.1  2.6 -3.6 14.3  6.1


   getdata source code is as folllows:

function(v) {
 o <- c(mean(v),sd(v),min(v),max(v),median(v))
 o
}


    What is going on?

  

--



From jfox at mcmaster.ca  Thu Jan 30 00:35:05 2003
From: jfox at mcmaster.ca (John Fox)
Date: Thu Jan 30 00:35:05 2003
Subject: [R] browser() misbehavior ?
In-Reply-To: <E827328028C66044B4998F2EC353CD300318515B@usrymx12.merck.co
 m>
Message-ID: <5.0.2.1.0.20030129165119.00ad80d8@mcmail.cis.mcmaster.ca>

Dear Bill,

Your example works fine for me with R 1.6.2 under Windows 2000. The 
behaviour that you report should occur if you press RETURN at the browser 
prompt, but that seems unlikely.

John

At 02:07 PM 1/29/2003 -0500, Pikounis, Bill wrote:
>Under v1.6.2, Windows NT4 OS, when a function contains an execution error
>and I have placed browser() in inside the function body, the call to browser
>is ignored.  A brief example to illustrate:
>
> > foo <- function(x) {
>+   y <- x ^ 2
>+   browser()
>+   foo2(x)  ## Intentional error
>+   x ^ 3
>+ }
> >
>
> > foo(30)
>Called from: foo(30)
>Browse[1]>
>Error in foo(30) : couldn't find function "foo2"
>
>## browser() still seems to be ignored even if a function has no execution
>error
>
> > traceback()
>1: foo(30)
>
>Has anyone else experienced this?  I am using v1.6.2 on Windows NT 4.
>
>Under Linux i686 (Mandrake 9.0), the same example works as expected;
>execution is stopped and I can usefully browser() as it is designed.
>
>As always, any advice is welcome.
>
>Thanks,
>Bill
>
>----------------------------------------
>Bill Pikounis, Ph.D.
>Biometrics Research Department
>Merck Research Laboratories
>PO Box 2000, MailDrop RY84-16
>126 E. Lincoln Avenue
>Rahway, New Jersey 07065-0900
>USA
>
>v_bill_pikounis at merck.com
>
>Phone: 732 594 3913
>Fax: 732 594 1565
>
>
>
>------------------------------------------------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From bates at stat.wisc.edu  Thu Jan 30 00:48:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu Jan 30 00:48:03 2003
Subject: [R] Weird options(digits=n) behaviour
In-Reply-To: <30808.1043882921@www59.gmx.net>
References: <30808.1043882921@www59.gmx.net>
Message-ID: <6rd6mf34dn.fsf@bates4.stat.wisc.edu>

Fernando Henrique Ferraz Pereira da Rosa <mentus at gmx.de> writes:

>      I noticed some very weird behaviour of the function: options(digits=n),
> where n is the number of digits you would expect to get in R calculations.
>      Let's take a example:
> 
> > options(digits=4)
> > getdata(caso.pool.k3.r3.e2)
> [1]  6.053  2.641 -3.639 14.259  6.082
> 
>      Which works fine... now, trying again, with different data:
> 
> > options(digits=4)
> > getdata(controle.pool.k3.r3.e2)
> [1] -0.03091  1.60310 -4.90588  5.07379 -0.04418
> >
>     Which gives me 6 digits instead of 6. If I try digits=2, it then works
> with this data:

The 'digits' option sets the minimum number of significant digits.
Some values in that array are printed to 6 significant digits but the
first and last have only 4 significant digits.



From p.dalgaard at biostat.ku.dk  Thu Jan 30 01:14:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Jan 30 01:14:03 2003
Subject: [R] Weird options(digits=n) behaviour
In-Reply-To: <30808.1043882921@www59.gmx.net>
References: <30808.1043882921@www59.gmx.net>
Message-ID: <x2el6vebpg.fsf@biostat.ku.dk>

Fernando Henrique Ferraz Pereira da Rosa <mentus at gmx.de> writes:

> > options(digits=4)

> [1]  6.053  2.641 -3.639 14.259  6.082

> [1] -0.03091  1.60310 -4.90588  5.07379 -0.04418

> > options(digits=2)
> [1] -0.031  1.603 -4.906  5.074 -0.044

> [1]  6.1  2.6 -3.6 14.3  6.1

>     What is going on?

This is normal. digits=4 means that you need at least four significant
digits of the result. When you print vectors all values get printed in
the same format. Notice that in the second case -0.03091 has 4
significant digits and -0.04418 ditto and in the 3rd case likewise.
6.1 has two significant digits by the same conventions.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tlumley at u.washington.edu  Thu Jan 30 01:19:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Jan 30 01:19:03 2003
Subject: [R] problems with by()
In-Reply-To: <3E384689.6050303@mcgill.ca>
Message-ID: <Pine.A41.4.44.0301291610160.111520-100000@homer29.u.washington.edu>

On Wed, 29 Jan 2003, Heberto Ghezzo wrote:

> Hello, another problem.
>  > x<-rep(1,10)
>  > y<-rep(c(1,2),c(5,5))
>  > z<-seq(1:10)
>  > ab<-data.frame(x,y,z)
> #
>     now I want to do some work by the value of 'y'
>  > by(ab,y,mean)
> y: 1
> x y z
> 1 1 3
> ------------------------------------------------------------
> y: 2
> x y z
> 1 2 8
> #
>     I do not want all the means, only the mean of 'z'
>  > by(ab,y,function(x) mean(z))
> y: 1
> [1] 5.5
> ------------------------------------------------------------
> y: 2
> [1] 5.5
>  > by(ab,y,function(x) mean(z,data=x))
> y: 1
> [1] 5.5
> ------------------------------------------------------------
> y: 2
> [1] 5.5
>  >
> #
>     so, how can I get the function(x) to be applied to each level
> of the index variable y.
> Actually I use my own function but the same happens, it is applied to all
> the data and there is no partition of the data acording to index

The function you are applying is

	function(x) mean(z)

That is, no matter what x is supplied, it calculates the mean of the
variable z, which is in your global workspace. The mean of z is 5.5

What you want is
	function(x) mean(x$z)
That is, take a supplied data frame and compute the mean of its `z'
column.

I try to use argument names that remind me what is happening in functions
like by()

	by(ab,y, function(df) mean(df$z))
or even
	by(ab, y, function(subset) mean(subset$z))

> Do not tell me that this version of R is completely buggy, I was waiting
> for the 1.7 to be out before upgrading

I think it's fair to characterise this sort of commment as `unhelpful'.

	-thomas



From krcabrer at epm.net.co  Thu Jan 30 01:52:05 2003
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Thu Jan 30 01:52:05 2003
Subject: [R] fptex link?
References: <3F44C651.3060006@arcriswell.com>
Message-ID: <3E3877FF.3080800@epm.net.co>

Hi R developers:

I am collecting the elements to Build R on W2K.
But I found that the www.fptex.org link, lead me to www.dante.de site.
In this site I don't found where to download the fptex software.
And worst:  ich spreche kein Deutch!!!

Danke sehr!



From fharrell at virginia.edu  Thu Jan 30 03:56:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu Jan 30 03:56:03 2003
Subject: [R] fptex link?
In-Reply-To: <3E3877FF.3080800@epm.net.co>
References: <3F44C651.3060006@arcriswell.com>
	<3E3877FF.3080800@epm.net.co>
Message-ID: <20030129215535.23dfb6c1.fharrell@virginia.edu>

Get FPTeX from ctan.org


On Wed, 29 Jan 2003 19:55:27 -0500
Kenneth Cabrera <krcabrer at epm.net.co> wrote:

> Hi R developers:
> 
> I am collecting the elements to Build R on W2K.
> But I found that the www.fptex.org link, lead me to www.dante.de site.
> In this site I don't found where to download the fptex software.
> And worst:  ich spreche kein Deutch!!!
> 
> Danke sehr!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From k_fortino at hotmail.com  Thu Jan 30 04:50:04 2003
From: k_fortino at hotmail.com (kenneth fortino)
Date: Thu Jan 30 04:50:04 2003
Subject: [R] Principal comp. scores in R
Message-ID: <F155i4omRXf2LTrpwAC00000154@hotmail.com>

Hello,  I am trying to run a PCA in R and I cannot get the PC scores for 
each of the values.  Using pcX <- princomp(X) then loadings(pcX) I can get a 
listing of the eigenvectors but not the actual PC scores for each value in 
the dataset.  I greatly appreciate any help anyone can offer

Thanks
Ken



From david.orlovich at botany.otago.ac.nz  Thu Jan 30 04:58:02 2003
From: david.orlovich at botany.otago.ac.nz (David Orlovich)
Date: Thu Jan 30 04:58:02 2003
Subject: [R] Principal comp. scores in R
In-Reply-To: <F155i4omRXf2LTrpwAC00000154@hotmail.com>
Message-ID: <D6E55B80-3406-11D7-908A-0030654D9D4A@botany.otago.ac.nz>

try:

 > pcX$scores

and

 > pcX$loadings

cheers,

David Orlovich.

On Thursday, January 30, 2003, at 04:48 PM, kenneth fortino wrote:

>
> Hello,  I am trying to run a PCA in R and I cannot get the PC scores 
> for each of the values.  Using pcX <- princomp(X) then loadings(pcX) I 
> can get a listing of the eigenvectors but not the actual PC scores for 
> each value in the dataset.  I greatly appreciate any help anyone can 
> offer
>
> Thanks
> Ken
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
Dr David Orlovich
Department of Botany,
The University of Otago,
P.O. Box 56,
Dunedin,
New Zealand.

Phone +64 3 479 9060
Fax +64 3 479 7583
david.orlovich at botany.otago.ac.nz
david.orlovich at unix.net
http://www.botany.otago.ac.nz/



From Simon.Blomberg at anu.edu.au  Thu Jan 30 05:04:03 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Thu Jan 30 05:04:03 2003
Subject: [R] Principal comp. scores in R
Message-ID: <7A3A13F416B40842BD2C1753E044B359B097EF@CASEVS02.cas.anu.edu.au>

Try:

res <- princomp(X, scores = TRUE)
res$scores

Cheers,

Simon.

Simon Blomberg
Depression & Anxiety Consumer Research Unit
Centre for Mental Health Research, Australian National University
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379


-----Original Message-----
From: kenneth fortino [mailto:k_fortino at hotmail.com]
Sent: Thursday, 30 January 2003 2:49 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Principal comp. scores in R



Hello,  I am trying to run a PCA in R and I cannot get the PC scores for 
each of the values.  Using pcX <- princomp(X) then loadings(pcX) I can get a 
listing of the eigenvectors but not the actual PC scores for each value in 
the dataset.  I greatly appreciate any help anyone can offer

Thanks
Ken

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From r.darnell at shrs.uq.edu.au  Thu Jan 30 05:08:03 2003
From: r.darnell at shrs.uq.edu.au (Ross Darnell)
Date: Thu Jan 30 05:08:03 2003
Subject: [R] tkmenu question
Message-ID: <8yx346wg.fsf@shrs.uq.edu.au>

I am learning the tcl/tk package and language and working through an
example (following a Tcl/Tk) tutorial which constructs a menubar and
menu system. My code is below.  I would very much appeciate some help
with two questions.

1. What is the parent for the menus associated with the menubuttons?

2. Why does the toplevel frame shrink if though I define the width of
the menubar frame and set the fill="x"?

Thanks

Ross Darnell


-- 
Email: <r.darnell at shrs.uq.edu.au>


require(tcltk) || stop("tcltk support is absent")
# Generate the main frame
.fr <- tktoplevel(width=800,height=500)
tktitle(.fr) <- "My example"
.menubar <- tkframe(.fr, relief="raised", borderwidth=2,
                    width=500,height=15)
tkpack(.menubar,fill="x") #why does .fr shrink?
# Set up the menu buttons
.menubar.file <- tkmenubutton(.menubar, text="File",
                              underline=0,menu=.menubar.file.menu)
.menubar.edit <- tkmenubutton(.menubar, text="Edit",
                              underline=0,menu=.menubar.edit.menu)
.menubar.graphics <- tkmenubutton(.menubar, text="Graphics",
                                  underline=0,menu=.menubar.graphics.menu)
tkpack(.menubar.file, .menubar.edit, .menubar.graphics,fill="x",
       side="left")
# Help menu to the right
.menubar.help <- tkmenubutton(.menubar, text="Help", underline=0)
tkpack(.menubar.help, side="right",fill="x")
# create pulldown menus  what is the parent?
.menubar.file.menu <- tkmenu(.)
tkadd(.menubar.file.menu,"separator")
tkadd(.menubar.file.menu,"command",label="Quit",command="exit")
.menubar.edit.menu <- tkmenu(.)
tkadd(.menubar.edit.menu,"separator")
.menubar.graphics.menu <- tkmenu(.)
tkadd(.menubar.graphics.menu,"separator")



From Simon.Wotherspoon at utas.edu.au  Thu Jan 30 06:04:03 2003
From: Simon.Wotherspoon at utas.edu.au (Simon Wotherspoon)
Date: Thu Jan 30 06:04:03 2003
Subject: [R] TukeyHSD and BIBD
Message-ID: <JPEJIEHCLCCMMBFGMPDGGECOCCAA.Simon.Wotherspoon@utas.edu.au>

Hi,
	the function TukeyHSD gives incorrect results for balanced incomplete block
designs, as the example below shows, but I can only half fix it.  There are
two problems,
1. It uses model.tables to estimate treatment means,
2. It uses the wrong standard error

The first problem can be fixed using dummy.coef, if the lines

> TukeyHSD.aov
function (x, which = seq(along = tabs), ordered = FALSE, conf.level = 0.95,
    ...)
{
    mm <- model.tables(x, "means")
    tabs <- mm$tables[-1]
    tabs <- tabs[which]
    ...

are altered to

> TukeyHSD.aov
function (x, which = seq(along = tabs), ordered = FALSE, conf.level = 0.95,
    ...)
{
    mm <- model.tables(x, "means")
    tabs <- dummy.coef(x)		## This line changed
    tabs <- tabs[which]
    ...

it calculates the right treatment differences (provided the block term
preceeds the treatment in the model formula).

To solve the second problem, I can manually get the correct se from
summary.lm, but I can't figure out how to extract the right se from
summary.lm programmatically.

I don't think these changes would make TukeyHSD fail on other cases, but I
haven't tested so I'm not sure.  I hope these few observations can help
someone a bit more knowledgable than I fix this problem.

Simon.




---



From Simon.Wotherspoon at utas.edu.au  Thu Jan 30 06:19:03 2003
From: Simon.Wotherspoon at utas.edu.au (Simon Wotherspoon)
Date: Thu Jan 30 06:19:03 2003
Subject: [R] TukeyHSD and BIBD
Message-ID: <JPEJIEHCLCCMMBFGMPDGEECPCCAA.Simon.Wotherspoon@utas.edu.au>

Sorry,
	Forgot to include the example

> d
   Consumer Pillows Comfort
1         1       A      59
2         1       B      26
3         1       C      38
4         2       D      85
5         2       E      92
6         2       F      69
7         3       G      74
8         3       H      52
9         3       I      27
10        4       A      63
11        4       D      70
12        4       G      68
13        5       B      26
14        5       E      98
15        5       H      59
16        6       C      31
17        6       F      60
18        6       I      35
19        7       A      62
20        7       E      85
21        7       I      30
22        8       B      23
23        8       F      73
24        8       G      75
25        9       C      49
26        9       D      74
27        9       H      51
28       10       A      52
29       10       F      76
30       10       H      43
31       11       B      18
32       11       D      79
33       11       I      41
34       12       C      42
35       12       E      84
36       12       G      81


TukeyHSD gives


> fit <- aov(Comfort~ Consumer+Pillow,data=d)
> TukeyHSD(fit,"Pillow")
  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = Comfort ~ Consumer + Pillow, data = d)

$Pillow
      diff         lwr         upr
B-A -31.00 -45.8641937 -16.1358063
C-A -15.50 -30.3641937  -0.6358063
...

But simint from the multcomp library gives

> library(multcomp)
> simint(Comfort~ Consumer+Pillow,data=d,whichf="Pillow",type="Tukey")

        Simultaneous confidence intervals: Tukey contrasts

Call: 
simint.formula(formula = Comfort ~ Consumer + Pillow, data = d, 
    whichf = "Pillow", type = "Tukey")

        95 % confidence intervals

                Estimate lower CI upper CI
PillowB-PillowA  -41.333  -58.498  -24.168
PillowC-PillowA  -20.667  -37.832   -3.502



We get the right diffs from dummy.coef

> pillow <- dummy.coef(fit)$Pillow
> outer(pillow,pillow,"-")
           A        B          C   
A   0.000000 41.33333  20.666667  ...
B -41.333333  0.00000 -20.666667  ...
C -20.666667 20.66667   0.000000  ...


and the right se from summary.lm

> summary.lm(fit)

Call:
aov(formula = Comfort ~ Consumer + Pillow, data = d)

Residuals:
     Min       1Q   Median       3Q      Max 
-6.00000 -3.36111  0.05556  2.94444  9.00000 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   61.667      4.404  14.001 2.14e-10 ***
...
Consumer12     1.111      5.334   0.208  0.83761    
PillowB      -41.333      4.825  -8.567 2.26e-07 ***
PillowC      -20.667      4.825  -4.284  0.00057 ***
PillowD       14.333      4.825   2.971  0.00901 ** 
PillowE       25.333      4.825   5.251 7.92e-05 ***
PillowF        9.333      4.825   1.934  0.07094 .  
PillowG       14.000      4.825   2.902  0.01040 *  
PillowH      -11.333      4.825  -2.349  0.03200 *  
PillowI      -25.667      4.825  -5.320 6.91e-05 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Residual standard error: 5.909 on 16 degrees of freedom
Multiple R-Squared: 0.9669,     Adjusted R-squared: 0.9275 
F-statistic: 24.57 on 19 and 16 DF,  p-value: 2.007e-08 


> qtukey(0.95,9,16)/sqrt(2)*4.825
[1] 17.16474
> -41.333333 + 17.16474
[1] -24.16859
> -41.333333 - 17.16474
[1] -58.49807
---



From ajsmit at botzoo.uct.ac.za  Thu Jan 30 07:44:03 2003
From: ajsmit at botzoo.uct.ac.za (Smit, A, Albertus, Dr)
Date: Thu Jan 30 07:44:03 2003
Subject: [R] Kruskal-Wallis, Friedman tests and Tukey HSD
Message-ID: <3E38E558.26974.4B71B78@localhost>

Dear all

Is there any way of doing a Tukey HSD post-hoc test after a Kruskal-
Wallis or Friedman rank sum test (in the ctest package)?

Thanks in advance,
Albertus


Dr. Albertus J. Smit
Department of Botany
University of Cape Town
Private Bag Rondebosch
7700
South Africa
Tel. +27 21 689 3032



From dieter.menne at menne-biomed.de  Thu Jan 30 09:41:02 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Thu Jan 30 09:41:02 2003
Subject: [R] as.formula(string) and augPred in lme
Message-ID: <JLEPLGAANFCEAEDCAGJNAECGCEAA.dieter.menne@menne-biomed.de>

Using formulas constructed from strings only
partially works for me in lme:

library(nlme)
data(Orthodont)

fm2<-lme(as.formula("distance~age"),data=Orthodont,random=~1|Subject)
summary(fm2) # works
augPred(fm2) # fails
#Error in inherits(object, "formula") : 
#Argument "object" is missing, with no default

I assume that my use of as.formula is wrong, but what's the right way?
Or at least a workaround?


Dieter Menne



From ripley at stats.ox.ac.uk  Thu Jan 30 10:06:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan 30 10:06:02 2003
Subject: [R] as.formula(string) and augPred in lme
In-Reply-To: <JLEPLGAANFCEAEDCAGJNAECGCEAA.dieter.menne@menne-biomed.de>
Message-ID: <Pine.LNX.4.44.0301300856190.27251-100000@gannet.stats>

On Thu, 30 Jan 2003, Dieter Menne wrote:

> Using formulas constructed from strings only
> partially works for me in lme:
> 
> library(nlme)
> data(Orthodont)
> 
> fm2<-lme(as.formula("distance~age"),data=Orthodont,random=~1|Subject)
> summary(fm2) # works
> augPred(fm2) # fails
> #Error in inherits(object, "formula") : 
> #Argument "object" is missing, with no default
> 
> I assume that my use of as.formula is wrong, but what's the right way?
> Or at least a workaround?

The error is in predict.lme, I think.  That has

eval(as.call(mCall[["fixed"]][-2]))

and I think

eval(mCall[["fixed"]])[-2]

may be the intention.

Workaround:  use lme(distance ~ age, data=Orthodont,random=~1|Subject)
or if you need to construct a formula, use

form <- as.formula("distance ~ age")
fm2 <- eval(substitute(lme(form, data=Orthodont, random=~1|Subject), list(form=form)))

or alter predict.lme as indicated).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From otoomet at econ.dk  Thu Jan 30 10:24:03 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Thu Jan 30 10:24:03 2003
Subject: [R] multinomial conditional logit models
Message-ID: <200301300924.h0U9Ovf09019@punik.econ.au.dk>

Hi,

 | I've been trying to implement an MCL model in R and have been mostly
 | succesful. However I'm still stuck on a few points and I'm hoping
 | someone can point out how to do fix them.
 | 
 | To estimate an MCL model, the data must be restructured into a
 | person-choice file. 
 | 
 | * Each case must be duplicated "ncat" times ("ncat" is the number of
 | categories of the dependent variable)
 | * Each case must be identified by a strata variable (id)
 | * Each duplicate must be identified by a variable indexing the
 | choices (newy)
 | * A dichotomous variable must indicate which duplicate corresponds
 | with the respondent's choice (didep)
 | 
 | I've done this as follows:
 | 
 | mclgen <- function (datamat, catvar) {
 | 	ncat <- nlevels(catvar)
 | 	id <- 1:length(catvar)
 | 	datamat <- cbind(id,datamat)
 | 	perschoice <-NULL
 | 	for (i in 1:ncat) {
 | 		perschoice<-rbind(perschoice,datamat)
 | 	}
 | 	perschoice <- perschoice[sort.list(perschoice$id),]
 | 	perschoice$newy <- gl(ncat, 1, length=nrow(perschoice))
 | 	dep <- parse(text=paste("perschoice$", substitute(catvar), sep=""))
 | 	perschoice$depvar <- as.numeric(eval(dep) == perschoice$newy)
 | 	perschoice
 | }
 | 
 | This works but I wonder if it's the most efficient method. I tried
 | using "rep" rather than "rbind" in a loop but that replicated the
 | dataset horizontally, not vertically. Is this the best solution?

Well, in general it is not efficient to add something to a matrix in a
cycle.  You should in either make the datamat in required size and
fill the required parts of it, or in this case you may consider e.g.

> datamat <- matrix(1:4, 2, 2)
> matrix(t(datamat), 4, 2, byrow=T)
     [,1] [,2]
[1,]    1    3
[2,]    2    4
[3,]    1    3
[4,]    2    4

 | I also finally figure out how to include the argument "catvar" in a
 | transformation involving another dataset but this solution seems very
 | complicated (eval+parse+substitute). Is there a simpler solution?

Unfortunately, I was not able to understand quite what are you doing
here.  Where is the dataset logan?  I did not find it on
http://www.xs4all.nl/~jhckx.  If I could get a simple example running,
I can try further.

best wishes,

Ott



From dray at biomserv.univ-lyon1.fr  Thu Jan 30 10:36:03 2003
From: dray at biomserv.univ-lyon1.fr (Stephane Dray)
Date: Thu Jan 30 10:36:03 2003
Subject: [R] Principal comp. scores in R
In-Reply-To: <F155i4omRXf2LTrpwAC00000154@hotmail.com>
References: <F155i4omRXf2LTrpwAC00000154@hotmail.com>
Message-ID: <a05010400ba5ea07b341a@[134.214.32.69]>

The package ade4 is devoted to multivariate analysis. You can have a 
look  at the function dudi.pca of the ade4 package for principal 
component analysis.

>Hello,  I am trying to run a PCA in R and I cannot get the PC scores 
>for each of the values.  Using pcX <- princomp(X) then loadings(pcX) 
>I can get a listing of the eigenvectors but not the actual PC scores 
>for each value in the dataset.  I greatly appreciate any help anyone 
>can offer
>
>Thanks
>Ken
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
St?phane DRAY
---------------------------------------------------------------
Biom?trie et Biologie ?volutive - Equipe "?cologie Statistique"
Universite Lyon 1 - Bat 711 - 69622 Villeurbanne CEDEX - France

Tel : 04 72 43 27 56			   Fax : 04 78 89 27 19
       04 72 43 27 57 	   E-mail : dray at biomserv.univ-lyon1.fr 
---------------------------------------------------------------
ADE-4               http://pbil.univ-lyon1.fr/ADE-4/ADE-4F.html
---------------------------------------------------------------



From Pin.Ng at nau.edu  Thu Jan 30 11:33:03 2003
From: Pin.Ng at nau.edu (Pin Ng)
Date: Thu Jan 30 11:33:03 2003
Subject: [R] S4 method dispatch fails R check
Message-ID: <se386cb2.067@mail.cba.nau.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030130/0ec17693/attachment.pl

From Friedrich.Leisch at univie.ac.at  Thu Jan 30 12:12:03 2003
From: Friedrich.Leisch at univie.ac.at (Friedrich.Leisch@univie.ac.at)
Date: Thu Jan 30 12:12:03 2003
Subject: [R] multinomial conditional logit models
In-Reply-To: <20030129195720.67695.qmail@web14208.mail.yahoo.com>
References: <20030129195720.67695.qmail@web14208.mail.yahoo.com>
Message-ID: <15929.2097.678537.107162@ci.tuwien.ac.at>

>>>>> On Wed, 29 Jan 2003 11:57:20 -0800 (PST),
>>>>> John Hendrickx (JH) wrote:

  > A multinomial logit model can be specified as a conditional logit
  > model after restructuring the data. Doing so gives flexibility in
  > imposing restrictions on the dependent variable. One application is
  > to specify a loglinear model for square tables, e.g. quasi-symmetry
  > or quasi-independence, as a multinomial logit model with covariates.
  > Further details on this technique and examples with several packages
  > are on my homepage at http://www.xs4all.nl/~jhckx/mcl/

  > I've been trying to implement an MCL model in R and have been mostly
  > succesful. However I'm still stuck on a few points and I'm hoping
  > someone can point out how to do fix them.

  > To estimate an MCL model, the data must be restructured into a
  > person-choice file. 

  > * Each case must be duplicated "ncat" times ("ncat" is the number of
  > categories of the dependent variable)
  > * Each case must be identified by a strata variable (id)
  > * Each duplicate must be identified by a variable indexing the
  > choices (newy)
  > * A dichotomous variable must indicate which duplicate corresponds
  > with the respondent's choice (didep)

I'm not completely sure if I understand your target format completely,
but it sounds like reshape() could do all you want:


R> df3
  id age dose1 dose2 dose4
1  1  40     1     2     3
2  2  50     2     1     3
3  3  60     1     2     3
4  4  50     2     1     3



R> reshape(df3, direction = "long", idvar=1,
           varying=list(dose=c("dose1", "dose2", "dose4")))

    id age time dose1
1.1  1  40    1     1
2.1  2  50    1     2
3.1  3  60    1     1
4.1  4  50    1     2
1.2  1  40    2     2
2.2  2  50    2     1
3.2  3  60    2     2
4.2  4  50    2     1
1.3  1  40    3     3
2.3  2  50    3     3
3.3  3  60    3     3
4.3  4  50    3     3


which is a (modified) example from help(reshape) ... there you find
much more examples.

Hope this helps,
Fritz

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik & DSS                Tel: (+43 1) 4277 38613
Universit?t Wien  		            Fax: (+43 1) 4277 38639
Universit?tsstra?e 5                  Friedrich.Leisch at univie.ac.at
A-1010 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------



From vsensae at hotmail.com  Thu Jan 30 12:17:03 2003
From: vsensae at hotmail.com (Vincent Stoliaroff)
Date: Thu Jan 30 12:17:03 2003
Subject: [R] Downloading Package
Message-ID: <F104gkJXrRjbDt3HvoF00005d0b@hotmail.com>

Hello,

I am a beginner in using R so my question could seem very simple. I would 
like to download the package multiv to do multivariate data analysis. The 
package I download seems to be a file meant for UNIX and I am using a Window 
OS. How could I download and install correctly this file?
Thanks a lot





_________________________________________________________________
MSN Messenger : discutez en direct avec vos amis !  
http://www.msn.fr/msger/default.asp



From N.H.Spencer at herts.ac.uk  Thu Jan 30 12:23:03 2003
From: N.H.Spencer at herts.ac.uk (Neil Spencer)
Date: Thu Jan 30 12:23:03 2003
Subject: [R] Short Course in R: University of Hertfordshire
Message-ID: <011201c2c851$c80a0040$de68c593@herts.ac.uk>

           One-day Course in R

       University of Hertfordshire

         Thursday 24th April 2003


http://www.herts.ac.uk/business/centres/sscu/


R is a freely-available computer package for statistics used by
professional statisticians. The command language used by R is very
similar to that used by S-PLUS, and this course also acts as an
introduction to the command language used by this package.

R can carry out standard statistical analyses, and also has powerful
facilities for users to create their own commands for non-standard
analyses or for new statistical methods. Users of R frequently publish
the code for their commands on the internet for others to use.

The main topics covered by the course are:

Obtaining the R package from the internet
Data entry and simple summary statistics
Basic statistical procedures
Obtaining and using commands designed by other researchers
Developing your own commands for non-standard analyses


Course fee: ?295 including zero V.A.T.


For an application form, please go to
http://www.herts.ac.uk/business/centres/sscu/
or contact Denise Pope on 01707 285028,
e-mail D.A.M.Pope at herts.ac.uk.

******************************************************************
Dr Neil H. Spencer
Senior Lecturer in Statistics
Head of Statistical Services and Consultancy Unit

Statistical Services and Consultancy Unit Address:
Lindop Building, University of Hertfordshire, Hatfield Campus,
College Lane, Hatfield, AL10 9AB, U.K.
Telephone: +44 (0) 1707 284366
Fax: +44 (0) 1707 284799
E-mail: statistics at herts.ac.uk
WWW: http://www.herts.ac.uk/business/centres/sscu

Departmental Address:
Dept. of Statistics, Economics, Accounting and Management Systems,
Business School, University of Hertfordshire, Hertford Campus,
Mangrove Road, Hertford, SG13 8QF, U.K.
Telephone: +44 (0) 1707 285529
Fax: +44 (0) 1707 285489
E-mail: N.H.Spencer at herts.ac.uk
WWW: http://www.herts.ac.uk/business/staff_public/nhspencer_public
******************************************************************



From AlessandroSemeria at cramont.it  Thu Jan 30 12:44:06 2003
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Thu Jan 30 12:44:06 2003
Subject: [R] Downloading Package
Message-ID: <OF161777F6.39B3B9A3-ONC1256CBE.0040247A@tomware.it>


From vonrohr at inf.ethz.ch  Thu Jan 30 12:57:02 2003
From: vonrohr at inf.ethz.ch (Peter von Rohr)
Date: Thu Jan 30 12:57:02 2003
Subject: [R] Downloading Package
References: <F104gkJXrRjbDt3HvoF00005d0b@hotmail.com>
Message-ID: <3E3912F2.3FD18946@inf.ethz.ch>

Hello Vincent,
> 
> I am a beginner in using R so my question could seem very simple. I would
> like to download the package multiv to do multivariate data analysis. The
> package I download seems to be a file meant for UNIX and I am using a Window
> OS. How could I download and install correctly this file?

although i am not using R for windows, but there are binaries for
windows available for multiv at:
http://www.stat.math.ethz.ch/CRAN/bin/windows/contrib/multiv.zip

you may want to read the documentation about how to install pakages from 
http://stat.ethz.ch/CRAN/doc/manuals/R-admin.pdf (chapter 5).

depending on where you are physically, you may want to select another
cran mirror for a list of mirrors see:
http://cran.r-project.org/mirrors.html

hth, peter

-- 
Peter von Rohr                       http://www.inf.ethz.ch/~vonrohr
Institute of Scientific Computing                vonrohr at inf.ethz.ch
ETH-Zentrum, HRS H23                           phone: +41 1 632 7473 
CH - 8092 Zurich                                 fax: +41 1 632 1374



From lahh at pubhealth.ku.dk  Thu Jan 30 13:37:06 2003
From: lahh at pubhealth.ku.dk (Lars Hougaard Hansen BSA)
Date: Thu Jan 30 13:37:06 2003
Subject: [R] seMethod for tkpack and tkgrid
Message-ID: <Pine.GSO.3.96.1030130132350.3367B-100000@diamant>

Hi,

I have a problem, regarding setMethod for "tkpack" and "tkgrid". I define
a new class , with one of the slots being of class "tkwin". I would now
naturel to set a method for packing the "tkwin"-slot; but here I run into
trouble. The code is given below.



## problem regarding "setMethod" for "tkpack" and "tkgrid".

library(methods)
library(tcltk)

# a class, "select", is defined, by

setClass("select",representation(listbox="tkwin", listvariable="tclVar"))

# Defining the method "tclvalue" for an object of class "select", by

setMethod("tclvalue","select",
          function(x)
          tclvalue(x at listvariable)
          )

# is accepted as legal R-code. But, when trying to do the same for 
# "tkpack"  and "tkgrid", R prints an Error.

setMethod("tkpack","select",
          function(x,...)
          tkpack(x at listbox,...)
          )

setMethod("tkgrid","select",
          function(x,...)
          tkgrid(x at listbox,...)
          )

# Error message:
#
# Error in makeGeneric(name, fdef, fdeflt, group = group, valueClass =
# valueClass,  : 
#        No suitable arguments to dispatch methods in this function
  
Can anybody see what the problem might bee?

I am using a Linux-gnu platform and the 1.7.0 version of R. 

Regards,

	Lars Hougaard Hansen

From v_bill_pikounis at merck.com  Thu Jan 30 13:41:04 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Thu Jan 30 13:41:04 2003
Subject: My apologies: user caused error (was RE: [R] browser() misbehavior ?)
Message-ID: <E827328028C66044B4998F2EC353CD300318515C@usrymx12.merck.com>

Please accept my apologies...it turns out that my occasional mode of copying
code from an editor to the Rgui console via the clipboard can easily add a
carriage return, and this exactly instructs browser to quit (as Q does).

Thanks to Brian Ripley and Andy Liaw for replying back with helpful advice,
and again, sorry to all for the waste of bandwidth.

Best,
Bill

----------------------------------------
Bill Pikounis, Ph.D.
Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

v_bill_pikounis at merck.com

Phone: 732 594 3913
Fax: 732 594 1565



------------------------------------------------------------------------------



From arte at panix.com  Thu Jan 30 13:45:03 2003
From: arte at panix.com (Arthur Ellen)
Date: Thu Jan 30 13:45:03 2003
Subject: [R] Heckman's method?
Message-ID: <Pine.NEB.4.51.0301300739420.24905@panix3.panix.com>

Are there any functions that include this process?



From fnj at cin.ufpe.br  Thu Jan 30 14:48:02 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Thu Jan 30 14:48:02 2003
Subject: [R] Validation of clustering
Message-ID: <Pine.GSO.4.32.0301301038370.29284-100000@goiana>

Hi,
I'm using the library cluster to cluster a set of figures (method CLARA).
Somebody that it work with clustering would know informs what I make to
evaluate the clustering?

Tks VM,
Francisco.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco Júnior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From kjetil at entelnet.bo  Thu Jan 30 15:06:05 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Thu Jan 30 15:06:05 2003
Subject: [R] mgcv, gam
Message-ID: <3E38F8AF.13862.4A482C@localhost>

Hola!

I have some problems with gam in mgcv. Firts a detail: it would
be nice igf gam would accept an na.action argument, but that not the 
main point.

I want to have a smooth term for time over a year, the same pattern 
repeating in succesive years. It would be natural then to impose 
the condition s(0)=s(12). Is this possible within mgcv?

I tried to obtain this with trigonometric terms, aca:

> Rot.gam2 <- gam(cbind(Rotavirus,Total)~ s( I(sin((MesN/12)*2*pi)), 
bs="cr" )+
+                    s( I(cos((MesN/12)*2*pi)), bs="cr" ), 
data=na.omit(Rot), 
+                    family=binomial)
Warning messages: 
1: Termwise estimate degrees of freedom are unreliable 

but this does not seem to be wholy satisfactory. Especially, the 
result of plot.gam shows smooths with confidence bounds 
which cannot be discriminated visually from the smooth itself!, 
and the warning messages about unreliable estimated
degrees of freedom. 

I would be happy if you could comment some
about this.

Thanks, 

Kjetil Halvorsen



From kjetil at entelnet.bo  Thu Jan 30 15:14:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Thu Jan 30 15:14:03 2003
Subject: [R] Kruskal-Wallis, Friedman tests and Tukey HSD
In-Reply-To: <3E38E558.26974.4B71B78@localhost>
Message-ID: <3E38F8B0.3785.4A48A9@localhost>

On 30 Jan 2003 at 8:41, Smit, A, Albertus, Dr wrote:

I don't know if this solves your problem, but on CRAN
there is a package for non-parametric 
simultaneous comparison:

npmc 
Nonparametric Multiple Comparisons: provides simultaneous rank test 
procedures for the one-way layout without presuming a certain 
distribution. 

Kjetil Halvorsen

> Dear all
> 
> Is there any way of doing a Tukey HSD post-hoc test after a Kruskal-
> Wallis or Friedman rank sum test (in the ctest package)?
> 
> Thanks in advance,
> Albertus
> 
> 
> Dr. Albertus J. Smit
> Department of Botany
> University of Cape Town
> Private Bag Rondebosch
> 7700
> South Africa
> Tel. +27 21 689 3032
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From fnj at cin.ufpe.br  Thu Jan 30 15:39:02 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Thu Jan 30 15:39:02 2003
Subject: [R] Plotting
Message-ID: <Pine.GSO.4.32.0301301130180.871-100000@goiana>

Hi,
How do I do to plot two graphics in the single axes coordenate?
Tks,
Francisco.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco Júnior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From ben at zoo.ufl.edu  Thu Jan 30 15:47:06 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Thu Jan 30 15:47:06 2003
Subject: [R] Plotting
In-Reply-To: <Pine.GSO.4.32.0301301130180.871-100000@goiana>
Message-ID: <Pine.LNX.4.44.0301300949130.25444-100000@bolker.zoo.ufl.edu>

  Depending on what you mean (same x-axis and y-axis), look at 
?points or ?lines OR (same x-axis, different y-axes) plot(...); 
par(new=TRUE); plot(...,ann=FALSE).  (The latter is asked frequently on 
this list.)

  Ben Bolker
  
On Thu, 30 Jan 2003, Francisco do Nascimento Junior wrote:

> Hi,
> How do I do to plot two graphics in the single axes coordenate?
> Tks,
> Francisco.
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Francisco J?nior,
> Computer Science - UFPE-Brazil
> "One life has more value that the
> world whole"
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From oliver at imcs.rutgers.edu  Thu Jan 30 15:55:03 2003
From: oliver at imcs.rutgers.edu (Matthew Oliver)
Date: Thu Jan 30 15:55:03 2003
Subject: [R] nearest neighbour interpolation
Message-ID: <200301301454.h0UEs1wP015641@imcs.rutgers.edu>

Dear Help List,

My name is Matt Oliver. I have been using R for about a year and find it very 
helpful. However, I have a need for a function that I cannot find. I am not very 
good at programming so I thought I would ask the group.

I have an irregular grid of data (x = Longitude, y = Latitude). Each pair of my x,y 
has a categorical value. Obviously linear or any other numerically based 
interpolation on categorical data does not make sense, so I want to use a nearest 
neighbor interpolation so that I can extrapolate my irregular grid to a regular grid 
of Longitude and Latitude.

Please help!

Thanks again

Matt Oliver
Institute of Marine and Coastal Sciences
Rutgers University, New Brunswick, NJ
07728 oliver at imcs.rutgers.edu



From gregory_r_warnes at groton.pfizer.com  Thu Jan 30 16:03:03 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Thu Jan 30 16:03:03 2003
Subject: [R] Downloading Package
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C526@groexmb02.pfizer.com>

If your system is set up appropriately, you should be able to use the menu
"Packages -> Install Packages from Cran" to get a list of packages, then
select the desired package and press OK.

-Greg

> -----Original Message-----
> From: Peter von Rohr [mailto:vonrohr at inf.ethz.ch]
> Sent: Thursday, January 30, 2003 6:57 AM
> To: Vincent Stoliaroff
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Downloading Package
> 
> 
> Hello Vincent,
> > 
> > I am a beginner in using R so my question could seem very 
> simple. I would
> > like to download the package multiv to do multivariate data 
> analysis. The
> > package I download seems to be a file meant for UNIX and I 
> am using a Window
> > OS. How could I download and install correctly this file?
> 
> although i am not using R for windows, but there are binaries for
> windows available for multiv at:
> http://www.stat.math.ethz.ch/CRAN/bin/windows/contrib/multiv.zip
> 
> you may want to read the documentation about how to install 
> pakages from 
> http://stat.ethz.ch/CRAN/doc/manuals/R-admin.pdf (chapter 5).
> 
> depending on where you are physically, you may want to select another
> cran mirror for a list of mirrors see:
> http://cran.r-project.org/mirrors.html
> 
> hth, peter
> 
> -- 
> Peter von Rohr                       http://www.inf.ethz.ch/~vonrohr
> Institute of Scientific Computing                vonrohr at inf.ethz.ch
> ETH-Zentrum, HRS H23                           phone: +41 1 632 7473 
> CH - 8092 Zurich                                 fax: +41 1 632 1374
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From sck2348 at cacs.louisiana.edu  Thu Jan 30 16:36:03 2003
From: sck2348 at cacs.louisiana.edu (Komanduru Sai C)
Date: Thu Jan 30 16:36:03 2003
Subject: [R] Regarding R
Message-ID: <200301301535.h0UFZ6n16452@mailer.cacs.louisiana.edu>

Hi,
 I am a grad student at the university of Louisiana at Lafayette. I have a 
question. I have an equation with 3 unknowns.  f= P/ (r+p) pow(B). I have values 
of f for different r's. Can i use R to find the P,p,B values which are 
constants. The equation is Manderbolts equation. 
 
 
 
Thanks and regards,
Sai Charan Komanduru
Research Assistant, CACS
ULL



From shuangge at stat.wisc.edu  Thu Jan 30 16:44:03 2003
From: shuangge at stat.wisc.edu (Shuangge Ma)
Date: Thu Jan 30 16:44:03 2003
Subject: [R] a question about spline A(ns or bs)
Message-ID: <Pine.LNX.4.21.0301300937520.29626-100000@bootstrap.stat.wisc.edu>

Hello:
I have a question about spline: ns (or bs) in R (library: splines).

What's the exact analytic form of the B splines generated by ns (or bs)?
I need to calculate the penalty (square of second order derivative) of the
basis functions. Is there any shortcut or I need to program myself?

thanks,

Shuangge Ma
*********************
Department of Statistics		Phone: 608-263-4782(O)
University of Wisconsin--Madison



From john_hendrickx at yahoo.com  Thu Jan 30 16:47:33 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Thu Jan 30 16:47:33 2003
Subject: [R] multinomial conditional logit models
In-Reply-To: <15929.2097.678537.107162@ci.tuwien.ac.at>
Message-ID: <20030130154323.16218.qmail@web14207.mail.yahoo.com>

--- Friedrich.Leisch at univie.ac.at wrote:
> >>>>> On Wed, 29 Jan 2003 11:57:20 -0800 (PST),
> >>>>> John Hendrickx (JH) wrote:
> 
[snip]
>   > To estimate an MCL model, the data must be restructured into a
>   > person-choice file. 
> 
>   > * Each case must be duplicated "ncat" times ("ncat" is the
> number of
>   > categories of the dependent variable)
>   > * Each case must be identified by a strata variable (id)
>   > * Each duplicate must be identified by a variable indexing the
>   > choices (newy)
>   > * A dichotomous variable must indicate which duplicate
> corresponds
>   > with the respondent's choice (didep)
> 
> I'm not completely sure if I understand your target format
> completely,
> but it sounds like reshape() could do all you want:
> 
> 
> R> df3
>   id age dose1 dose2 dose4
> 1  1  40     1     2     3
> 2  2  50     2     1     3
> 3  3  60     1     2     3
> 4  4  50     2     1     3
> 
> 
> 
> R> reshape(df3, direction = "long", idvar=1,
>            varying=list(dose=c("dose1", "dose2", "dose4")))
> 
>     id age time dose1
> 1.1  1  40    1     1
> 2.1  2  50    1     2
> 3.1  3  60    1     1
> 4.1  4  50    1     2
> 1.2  1  40    2     2
> 2.2  2  50    2     1
> 3.2  3  60    2     2
> 4.2  4  50    2     1
> 1.3  1  40    3     3
> 2.3  2  50    3     3
> 3.3  3  60    3     3
> 4.3  4  50    3     3
> 
What I want can be done using "reshape" in conjunction with "rep". My
data structure isn't wide but can be made so using "rep". For
example:

> dataset=matrix(1:6,3,2)
> dset<-data.frame(dataset)
> dset
  X1 X2
1  1  4
2  2  5
3  3  6
> c<-as.data.frame(rep(dset,2))
>
reshape(c,direction="long",varying=list(x1=c("X1","X1"),x2=c("X2","X2")))
    time X1 X2 id
1.1    1  1  4  1
2.1    1  2  5  2
3.1    1  3  6  3
1.2    2  1  4  1
2.2    2  2  5  2
3.2    2  3  6  3

This is what I want to do when creating a person-choice file. The
only problem though is the last step, specifying a list of varying
variables. It should be possible to generate this from "names(dset)"
but I can't get it right. "as.list(rep(names(dset),2))" produces a
list with four elements rather than a list with 2 components each
containing two elements. "dim()" gives a matrix as a result. Could
someone show me how to create "list(x1=c("X1","X1"),x2=c("X2","X2"))"
from "names(dset)"?

Advance thanks for any help,
John Hendrickx



From rossini at blindglobe.net  Thu Jan 30 17:14:06 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu Jan 30 17:14:06 2003
Subject: [R] Regarding R
In-Reply-To: <200301301535.h0UFZ6n16452@mailer.cacs.louisiana.edu> (Komanduru
 Sai C's message of "Thu, 30 Jan 2003 09:35:06 -0600 (CST)")
References: <200301301535.h0UFZ6n16452@mailer.cacs.louisiana.edu>
Message-ID: <873cnahb53.fsf@jeeves.blindglobe.net>

>>>>> "KSC" == Komanduru Sai C <Komanduru> writes:


    KSC>  I am a grad student at the university of Louisiana at Lafayette. I have a 
    KSC> question. I have an equation with 3 unknowns.  f= P/ (r+p) pow(B). I have values 
    KSC> of f for different r's. Can i use R to find the P,p,B values which are 
    KSC> constants. The equation is Manderbolts equation. 
 
Yes.  Did you mean "how"?

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From bates at stat.wisc.edu  Thu Jan 30 17:20:04 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu Jan 30 17:20:04 2003
Subject: [R] Regarding R
In-Reply-To: <200301301535.h0UFZ6n16452@mailer.cacs.louisiana.edu>
References: <200301301535.h0UFZ6n16452@mailer.cacs.louisiana.edu>
Message-ID: <6rsmvak3tr.fsf@bates4.stat.wisc.edu>

Komanduru Sai C <sck2348 at cacs.louisiana.edu> writes:

>  I am a grad student at the university of Louisiana at Lafayette. I
>  have a question. I have an equation with 3 unknowns.  f= P/ (r+p)
>  pow(B). I have values of f for different r's. Can i use R to find
>  the P,p,B values which are constants. The equation is Manderbolts
>  equation.

You may want to use nonlinear least squares to fit the parameters in
this model.  To do so you will need starting values for the parameters
p and B.  Suppose that the starting value for p is 0.1 and for B is 2
and that your data are in a data frame called KSC.

fm =  nls(y ~ 1/((r+p)^B), data = KSC, start = c(p=0.1, B=2),
          alg='plinear', trace = TRUE)
coef(fm)

Use of nls assumes that the observations consist of 'signal + noise' and
the 'noise' part has constant variance.  See, for example, Bates and
Watts (1988), "Nonlinear Regression Analysis and Its Applications",
Wiley.



From voda at mac.com  Thu Jan 30 17:53:03 2003
From: voda at mac.com (Heather Good)
Date: Thu Jan 30 17:53:03 2003
Subject: [R] multiple scatterplots
Message-ID: <249246CC-3473-11D7-B483-000393AA29AE@mac.com>

When I create multiple scatterplots on a page using:

 > op = par(mfrow=c(2,2))
plot( x, y, xlab="x", ylab="y", main="plot of x and y")
etc.

I am getting plots that are rectangular, not square. Although, the 
first few times I used this command, it produced square plots. Is there 
a way to ensure that square plots are created?

Heather



From tlumley at u.washington.edu  Thu Jan 30 17:58:58 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Jan 30 17:58:58 2003
Subject: [R] multinomial conditional logit models
In-Reply-To: <20030130154323.16218.qmail@web14207.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0301300853390.51272-100000@homer19.u.washington.edu>

On Thu, 30 Jan 2003, John Hendrickx wrote:

> The only problem though is the last step, specifying a list of varying
> variables. It should be possible to generate this from "names(dset)"
> but I can't get it right. "as.list(rep(names(dset),2))" produces a
> list with four elements rather than a list with 2 components each
> containing two elements. "dim()" gives a matrix as a result. Could
> someone show me how to create "list(x1=c("X1","X1"),x2=c("X2","X2"))"
> from "names(dset)"?

   lapply(names(dset),rep,2)
gives
 [[1]]
[1] "X1" "X1"

[[2]]
[1] "X2" "X2"

	-thomas



From kjetil at entelnet.bo  Thu Jan 30 18:20:06 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Thu Jan 30 18:20:06 2003
Subject: [R] multiple scatterplots
In-Reply-To: <249246CC-3473-11D7-B483-000393AA29AE@mac.com>
Message-ID: <3E392629.27008.FBEBA3@localhost>

On 30 Jan 2003 at 8:51, Heather Good wrote:

Reading 
?par
gives the answer, but that takes some time. An example:

par(mfrow=c(2,2))
> par(pty="s")
> plot(1:10, 1:10)
> 
.
.
.
seems to work

Kjetil Halvorsen

> When I create multiple scatterplots on a page using:
> 
>  > op = par(mfrow=c(2,2))
> plot( x, y, xlab="x", ylab="y", main="plot of x and y")
> etc.
> 
> I am getting plots that are rectangular, not square. Although, the 
> first few times I used this command, it produced square plots. Is there 
> a way to ensure that square plots are created?
> 
> Heather
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ksaicharan at yahoo.com  Thu Jan 30 19:32:05 2003
From: ksaicharan at yahoo.com (saicharan komanduru)
Date: Thu Jan 30 19:32:05 2003
Subject: [R] Regarding Installation of R
Message-ID: <20030130183135.84981.qmail@web12201.mail.yahoo.com>

Hi,
 I am trying to install R on Windows. I copied the set
up binary. But it is corrupted on all the mirror
sites. Please let know an alternative for getting the
software.

Thanks,
Sai



From p.dalgaard at biostat.ku.dk  Thu Jan 30 19:57:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Jan 30 19:57:03 2003
Subject: [R] Regarding Installation of R
In-Reply-To: <20030130183135.84981.qmail@web12201.mail.yahoo.com>
References: <20030130183135.84981.qmail@web12201.mail.yahoo.com>
Message-ID: <x2ptqecvv3.fsf@biostat.ku.dk>

saicharan komanduru <ksaicharan at yahoo.com> writes:

> Hi,
>  I am trying to install R on Windows. I copied the set
> up binary. But it is corrupted on all the mirror
> sites. Please let know an alternative for getting the
> software.

Well, you could compile from sources, but what makes you say that
it is corrupted??

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Ko-Kang at xtra.co.nz  Thu Jan 30 20:12:03 2003
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Thu Jan 30 20:12:03 2003
Subject: [R] Regarding Installation of R
References: <20030130183135.84981.qmail@web12201.mail.yahoo.com>
Message-ID: <007a01c2c893$508b9d70$f12758db@kwan022>

----- Original Message -----
From: "saicharan komanduru" <ksaicharan at yahoo.com>
To: <R-help at stat.math.ethz.ch>
Sent: Friday, January 31, 2003 7:31 AM
Subject: [R] Regarding Installation of R


> Hi,
>  I am trying to install R on Windows. I copied the set
> up binary. But it is corrupted on all the mirror
> sites. Please let know an alternative for getting the
> software.


Which "set up binary" did you downloaded?  It should not be corrupted.  Did
you download the rw1062.exe in, for example,
http://cran.r-project.org/bin/windows/base ?

------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022



From apjaworski at mmm.com  Thu Jan 30 20:32:02 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Thu Jan 30 20:32:02 2003
Subject: [R] Regarding Installation of R
Message-ID: <OF7E451087.3CAAB652-ON86256CBE.006AE1C5@mmm.com>

Yesterday I installed R-1.6.2 on a Win2000 laptop from a binary downloaded
from the Wisconsin mirror.  No problems.

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+------------------------------>
|         |           saicharan komanduru|
|         |           <ksaicharan at yahoo.c|
|         |           om>                |
|         |           Sent by:           |
|         |           r-help-admin at stat.m|
|         |           ath.ethz.ch        |
|         |                              |
|         |                              |
|         |           01/30/2003 12:31   |
|         |                              |
|---------+------------------------------>
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       R-help at stat.math.ethz.ch                                                                                     |
  |      cc:                                                                                                                    |
  |      Subject:  [R] Regarding Installation of R                                                                              |
  >-----------------------------------------------------------------------------------------------------------------------------|



Hi,
 I am trying to install R on Windows. I copied the set
up binary. But it is corrupted on all the mirror
sites. Please let know an alternative for getting the
software.

Thanks,
Sai

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From john_hendrickx at yahoo.com  Thu Jan 30 20:38:03 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Thu Jan 30 20:38:03 2003
Subject: [R] multinomial conditional logit models
In-Reply-To: <Pine.A41.4.44.0301300853390.51272-100000@homer19.u.washington.edu>
Message-ID: <20030130193723.37114.qmail@web14204.mail.yahoo.com>

Thanks, that did the trick. My "mclgen" function can be written as

mclgen <- function (datamat,catvar) {
	ncat <- nlevels(catvar)
	perschoice<-as.data.frame(rep(datamat,ncat))
	perschoice<-reshape(perschoice,direction="long",
	varying=lapply(names(datamat),rep,ncat),
	timevar="newy")
	perschoice<-perschoice[sort.list(perschoice$id),]
	dep<-parse(text=paste("perschoice$",substitute(catvar),sep=""))
	perschoice$depvar<-as.numeric(eval(dep)==perschoice$newy)
	perschoice
}

I'd still appreciate the help of R-listers on how to use the value of
"catvar" on the left-hand side of an expression within a function
(perschoice$"valueof(catvar)"<-perschoice$newy), and how to get R to
drop the reference category of a factor in an interaction effect
without the main effect (in
"clogit(depvar~occ+occ:educ+occ:black+strata(id),data=pc)").

But many thanks for the help so far!

John Hendrickx

--- Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Thu, 30 Jan 2003, John Hendrickx wrote:
> 
> > The only problem though is the last step, specifying a list of
> varying
> > variables. It should be possible to generate this from
> "names(dset)"
> > but I can't get it right. "as.list(rep(names(dset),2))" produces
> a
> > list with four elements rather than a list with 2 components each
> > containing two elements. "dim()" gives a matrix as a result.
> Could
> > someone show me how to create
> "list(x1=c("X1","X1"),x2=c("X2","X2"))"
> > from "names(dset)"?
> 
>    lapply(names(dset),rep,2)
> gives
>  [[1]]
> [1] "X1" "X1"
> 
> [[2]]
> [1] "X2" "X2"
> 
> 	-thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Thu Jan 30 20:58:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan 30 20:58:03 2003
Subject: [R] multinomial conditional logit models
In-Reply-To: <20030130193723.37114.qmail@web14204.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0301301951010.697-100000@gannet.stats>

On Thu, 30 Jan 2003, John Hendrickx wrote:

> Thanks, that did the trick. My "mclgen" function can be written as
> 
> mclgen <- function (datamat,catvar) {
> 	ncat <- nlevels(catvar)
> 	perschoice<-as.data.frame(rep(datamat,ncat))
> 	perschoice<-reshape(perschoice,direction="long",
> 	varying=lapply(names(datamat),rep,ncat),
> 	timevar="newy")
> 	perschoice<-perschoice[sort.list(perschoice$id),]
> 	dep<-parse(text=paste("perschoice$",substitute(catvar),sep=""))
> 	perschoice$depvar<-as.numeric(eval(dep)==perschoice$newy)
> 	perschoice
> }
> 
> I'd still appreciate the help of R-listers on how to use the value of
> "catvar" on the left-hand side of an expression within a function
> (perschoice$"valueof(catvar)"<-perschoice$newy), and how to get R to

Use perschoice[[catvar]], on either side.

> drop the reference category of a factor in an interaction effect
> without the main effect (in
> "clogit(depvar~occ+occ:educ+occ:black+strata(id),data=pc)").

Let me guess a lot what you mean. You are using treatment contrasts (hence 
the `reference category') and you want the model matrix which is
that given by depvar ~ occ + edu + occ:educ + black + occ:black less the 
columns for edu and black?  That's a model that depends on the details of 
the coding, and does not make sense in the Wilkinson-Rogers framework.
Could you spell this out please?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From john_hendrickx at yahoo.com  Thu Jan 30 22:01:03 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Thu Jan 30 22:01:03 2003
Subject: [R] multinomial conditional logit models
In-Reply-To: <Pine.LNX.4.44.0301301951010.697-100000@gannet.stats>
Message-ID: <20030130210009.2835.qmail@web14202.mail.yahoo.com>

--- ripley at stats.ox.ac.uk wrote:
> On Thu, 30 Jan 2003, John Hendrickx wrote:
> 
> > Thanks, that did the trick. My "mclgen" function can be written
> as
> > 
> > mclgen <- function (datamat,catvar) {
> > 	ncat <- nlevels(catvar)
> > 	perschoice<-as.data.frame(rep(datamat,ncat))
> > 	perschoice<-reshape(perschoice,direction="long",
> > 	varying=lapply(names(datamat),rep,ncat),
> > 	timevar="newy")
> > 	perschoice<-perschoice[sort.list(perschoice$id),]
> > 	dep<-parse(text=paste("perschoice$",substitute(catvar),sep=""))
> > 	perschoice$depvar<-as.numeric(eval(dep)==perschoice$newy)
> > 	perschoice
> > }
> > 
> > I'd still appreciate the help of R-listers on how to use the
> value of
> > "catvar" on the left-hand side of an expression within a function
> > (perschoice$"valueof(catvar)"<-perschoice$newy), and how to get R
> to
> 
> Use perschoice[[catvar]], on either side.

Thanks, "perschoice[[substitue(catvar)]])<-perschoice$newy" did the
trick!
> 
> > drop the reference category of a factor in an interaction effect
> > without the main effect (in
> > "clogit(depvar~occ+occ:educ+occ:black+strata(id),data=pc)").
> 
> Let me guess a lot what you mean. You are using treatment contrasts
> (hence 
> the `reference category') and you want the model matrix which is
> that given by depvar ~ occ + edu + occ:educ + black + occ:black
> less the 
> columns for edu and black?  That's a model that depends on the
> details of 
> the coding, and does not make sense in the Wilkinson-Rogers
> framework.
> Could you spell this out please?

I'm trying to use "clogit" to estimate a multinomial logit model
"multinom(occ ~ educ+black)". This can be done by restructing the
data using the "mclgen" function, then estimating a model of the main
effects of "occ" for the intercept of a MNL model and interactions
between "occ" and "educ" and "black" for the effects of these
variables. "occ" is a factor with 5 levels and I expected the first
category to be dropped in all terms containing "occ". However, this
only happens for the main effect of "occ". In the interactions with
"educ" and "black", the highest category of "occ" is dropped due to
collinearity. 

The model makes sense in the context of a conditional logit model and
will produce correct effects using other software packages such as
Stata and SAS. Apparently, R doesn't omit one category of a factor in
an interaction with no main effect. I'd like to know if there's an
option to make it do so nevertheless.

Many thanks for the help,
John Hendrickx



From robert.king at newcastle.edu.au  Thu Jan 30 23:29:03 2003
From: robert.king at newcastle.edu.au (Robert King)
Date: Thu Jan 30 23:29:03 2003
Subject: [R] Re: Regarding Installation
In-Reply-To: <20030130175230.99547.qmail@web12208.mail.yahoo.com>
Message-ID: <Pine.LNX.4.21.0301310927080.12375-100000@tolstoy.newcastle.edu.au>

Its possible to corrupt the binary if you actually open it in a browser,
and the browser tries to display it, and then you save it.

Have you tried right-clicking on the link to download it?

Robert.

On Thu, 30 Jan 2003, saicharan komanduru wrote:
> Hi,
>   I copied the binary setup file for windows. I tried
> to install but it says the binary is corrupted. I
> tried getting the files from many mirror sites but the
> same probelm is repeating. Please let me know if i
> have an alternative.
> 
> Thanks and Regards,
> Sai Charan Komanduru

----
Robert King, Statistics, School of Mathematical & Physical Sciences,
University of Newcastle, Australia
Room V133  ph +61 2 4921 5548
Robert.King at newcastle.edu.au   http://maths.newcastle.edu.au/~rking/

We come to bury DOS, not to praise it.
(Paul Vojta, vojta at math.berkeley.edu, paraphrasing a quote of Shakespeare)



From parcon at stat.wmich.edu  Thu Jan 30 23:37:04 2003
From: parcon at stat.wmich.edu (Jason Parcon)
Date: Thu Jan 30 23:37:04 2003
Subject: [R] Double Exponential
Message-ID: <200301302231.h0UMVWW01274@sagan.stat.wmich.edu>

To whom it may concern:

I just would like to know how can one generate a set of random values from the 
double exponential distribution.  

Thanks.

Jason Parcon



From ripley at stats.ox.ac.uk  Thu Jan 30 23:45:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Jan 30 23:45:04 2003
Subject: [R] Double Exponential
In-Reply-To: <200301302231.h0UMVWW01274@sagan.stat.wmich.edu>
Message-ID: <Pine.LNX.4.44.0301302242490.9663-100000@gannet.stats>

ifelse(runif(n) > 0.5, 1, -1) * rexp(n)

On Thu, 30 Jan 2003, Jason Parcon wrote:

> To whom it may concern:
> 
> I just would like to know how can one generate a set of random values from the 
> double exponential distribution.  

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ben at zoo.ufl.edu  Thu Jan 30 23:51:52 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Thu Jan 30 23:51:52 2003
Subject: [R] Double Exponential
In-Reply-To: <200301302231.h0UMVWW01274@sagan.stat.wmich.edu>
Message-ID: <Pine.LNX.4.44.0301301754110.18352-100000@bolker.zoo.ufl.edu>

  What do you mean by "double exponential"?  Can you give us another more
familiar name (e.g. Laplacian), or a reference, or a more detailed
description, or a formula for the cumulative or probability density
function?

  Ben Bolker

On Thu, 30 Jan 2003, Jason Parcon wrote:

> To whom it may concern:
> 
> I just would like to know how can one generate a set of random values from the 
> double exponential distribution.  
> 
> Thanks.
> 
> Jason Parcon
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From pavel at koulikov.com  Fri Jan 31 00:20:09 2003
From: pavel at koulikov.com (pavel koulikov)
Date: Fri Jan 31 00:20:09 2003
Subject: [R] (no subject)
Message-ID: <200301301817.AA62521500@koulikov.com>

Hi
I have 4 vectors x,y,z,v
I need 2 graphs (x~y,z~v) on the same plot. I mean two lines on the same plot - blue and red.
I wrote:
 
c.pl=xyplot(y~x,
          na.rm="TRUE",type="l",more=TRUE,
          scales = list(cex=3/4,x=list(tick.number=3,alternating = c(0,1)),y=list(tick.number=7)),   
          panel = function(x,y,...) {
          panel.grid(h=-1,v=3,lwd=1/8,col=COLAVG,lty=3)
          panel.xyplot(x,y,...)

        }
   
   )

How can I pu the second x~v graph on the same plot???
   
     
   

  print(c.pl)



From cmorab at bellsouth.net  Fri Jan 31 02:43:02 2003
From: cmorab at bellsouth.net (cmorab@bellsouth.net)
Date: Fri Jan 31 02:43:02 2003
Subject: [R] Question about trellis graphs
Message-ID: <003a01c2c8c9$c06f5a60$6101a8c0@launchmodem.com>

Dear List Members

I'm using R to create a trellis plot using the library of Pinheiro & Bates
(trellis graph for grouped data). Here is my question: How can I change the
format of the axis (x or y) in terms of the number decimal points that
should appear on the plot? In other words, I have that for a set of plots in
the y-axis the values appear as 0.2,0.3, etc and for another set they appear
as 0.20,0.30 etc and I want both to look identical.

Thanks for any hint

Christian

________________________________

Christian R. Mora
MS Student - Department of Forestry
North Carolina State University
e-mail: crmora at unity.ncsu.edu



From s195404 at student.uq.edu.au  Fri Jan 31 02:55:08 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri Jan 31 02:55:08 2003
Subject: [R] (no subject)
In-Reply-To: <200301301817.AA62521500@koulikov.com>
References: <200301301817.AA62521500@koulikov.com>
Message-ID: <1043978054.3e39d746e1b03@my.uq.edu.au>

For this application, you need something like
   plot(dat$x, dat$y, type="n", xlim=range(c(dat$x, dat$z)), 
        ylim=range(c(dat$4, dat$v)))
   points(dat$x, dat$y, col="red")
   points(dat$z, dat$y, col="blue")

Similarly, you can use lines() along with lowess() to put
different coloured lines on the plot.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting pavel koulikov <pavel at koulikov.com>:

> Hi
> I have 4 vectors x,y,z,v
> I need 2 graphs (x~y,z~v) on the same plot. I mean two lines on the same plot
> - blue and red.
> I wrote:
>  
> c.pl=xyplot(y~x,
>           na.rm="TRUE",type="l",more=TRUE,
>           scales = list(cex=3/4,x=list(tick.number=3,alternating =
> c(0,1)),y=list(tick.number=7)),   
>           panel = function(x,y,...) {
>           panel.grid(h=-1,v=3,lwd=1/8,col=COLAVG,lty=3)
>           panel.xyplot(x,y,...)
> 
>         }
>    
>    )
> 
> How can I pu the second x~v graph on the same plot???
>    
>      
>    
> 
>   print(c.pl)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From s195404 at student.uq.edu.au  Fri Jan 31 03:01:03 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri Jan 31 03:01:03 2003
Subject: [R] Question about trellis graphs
In-Reply-To: <003a01c2c8c9$c06f5a60$6101a8c0@launchmodem.com>
References: <003a01c2c8c9$c06f5a60$6101a8c0@launchmodem.com>
Message-ID: <1043978275.3e39d82308a53@my.uq.edu.au>

Christian,

The scales argument of lattice plots achieve this.
For instance you could have
   xyplot(y ~ x, data=my.data, scales=list(x=list(at=c(0, 0.1, 0.2), 
          labels=c("0.0", "0.1", "0.2"))))

Check out ?xyplot for a lot more detail on this
and other arguments to lattice functions.



Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting cmorab at bellsouth.net:

> Dear List Members
> 
> I'm using R to create a trellis plot using the library of Pinheiro & Bates
> (trellis graph for grouped data). Here is my question: How can I change the
> format of the axis (x or y) in terms of the number decimal points that
> should appear on the plot? In other words, I have that for a set of plots in
> the y-axis the values appear as 0.2,0.3, etc and for another set they appear
> as 0.20,0.30 etc and I want both to look identical.
> 
> Thanks for any hint
> 
> Christian
> 
> ________________________________
> 
> Christian R. Mora
> MS Student - Department of Forestry
> North Carolina State University
> e-mail: crmora at unity.ncsu.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From f0z6305 at labs.tamu.edu  Fri Jan 31 03:48:02 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Fri Jan 31 03:48:02 2003
Subject: [R] Help on Scatte Plot Matrix
Message-ID: <003a01c2c8d3$1f1f8810$8bd75ba5@IE.TAMU.EDU>

Hey, All

Now I have a data set which is n-dimensional.
And want to plot the Scatter Plot Matrix which
is n by n.

Does R have such function to achieve this?

Thanks for  your point.

Fred



From s195404 at student.uq.edu.au  Fri Jan 31 04:10:04 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri Jan 31 04:10:04 2003
Subject: [R] Help on Scatte Plot Matrix
In-Reply-To: <003a01c2c8d3$1f1f8810$8bd75ba5@IE.TAMU.EDU>
References: <003a01c2c8d3$1f1f8810$8bd75ba5@IE.TAMU.EDU>
Message-ID: <1043982562.3e39e8e23ff6e@my.uq.edu.au>

I think this is what pairs() does.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting Feng Zhang <f0z6305 at labs.tamu.edu>:

> Hey, All
> 
> Now I have a data set which is n-dimensional.
> And want to plot the Scatter Plot Matrix which
> is n by n.
> 
> Does R have such function to achieve this?
> 
> Thanks for  your point.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From otoomet at econ.dk  Fri Jan 31 08:36:06 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Fri Jan 31 08:36:06 2003
Subject: [R] Heckman's method?
Message-ID: <200301310737.h0V7bQL09575@punik.econ.au.dk>

Hi,

 | 
 | Are there any functions that include this process?
 | 

can you please be more specific?  I have written a function for
calculating Heckman type selection models (Tobit 5 models in Amemiya
(1985)), if that is what you are looking for.

Regards,

Ott



From simon at stats.gla.ac.uk  Fri Jan 31 11:41:03 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Fri Jan 31 11:41:03 2003
Subject: [R] mgcv, gam
In-Reply-To: <3E38F8AF.13862.4A482C@localhost>
Message-ID: <Pine.SOL.3.96.1030131103153.23643C-100000@moon.stats.gla.ac.uk>

> I have some problems with gam in mgcv. Firts a detail: it would
> be nice igf gam would accept an na.action argument, but that not the 
> main point.
- I find it hard to think of a sensible action except dropping the
associated data, but if you've a concrete suggestion I'm happy to add it
to the "to do" list.

> I want to have a smooth term for time over a year, the same pattern 
> repeating in succesive years. It would be natural then to impose 
> the condition s(0)=s(12). Is this possible within mgcv?
- It's possible, but not entirely straightforward - you could impose the
constraint using the pcls() routine, but it means digging around inside
the code a bit - see the ?pcls examples to get an idea of the sort of
thing required.

- It's probably worth checking out whether gss can do this more simply for
you.

> I tried to obtain this with trigonometric terms, aca:
> 
> > Rot.gam2 <- gam(cbind(Rotavirus,Total)~ s( I(sin((MesN/12)*2*pi)), 
> bs="cr" )+
> +                    s( I(cos((MesN/12)*2*pi)), bs="cr" ), 
> data=na.omit(Rot), 
> +                    family=binomial)
> Warning messages: 
> 1: Termwise estimate degrees of freedom are unreliable 
>
The problem here is basically that you have " a smooth function of a
smooth function of MesN " and " a smooth function of another smooth
function of MesN ", i.e. two smooth functions of MesN and hence some
identifiability problems. The error message reflects the numerical
difficulties resulting from these problems (which also explain the
lack of confidence intervals).

best,
Simon

_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk  www.ruwpa.st-and.ac.uk/simon.html
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814



From Roger.Bivand at nhh.no  Fri Jan 31 11:48:03 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri Jan 31 11:48:03 2003
Subject: [R] nearest neighbour interpolation
In-Reply-To: <200301301454.h0UEs1wP015641@imcs.rutgers.edu>
Message-ID: <Pine.LNX.4.44.0301311126160.4187-100000@reclus.nhh.no>

On Thu, 30 Jan 2003, Matthew Oliver wrote:

> Dear Help List,
> 
> My name is Matt Oliver. I have been using R for about a year and find it very 
> helpful. However, I have a need for a function that I cannot find. I am not very 
> good at programming so I thought I would ask the group.
> 
Maybe this is an opportunity to explore things - they are usually feasible
if the motivation is sufficiently strong.

> I have an irregular grid of data (x = Longitude, y = Latitude). Each pair of my x,y 
> has a categorical value. Obviously linear or any other numerically based 
> interpolation on categorical data does not make sense, so I want to use a nearest 
> neighbor interpolation so that I can extrapolate my irregular grid to a regular grid 
> of Longitude and Latitude.
> 
There does not seem to be such a function at present. The pieces are 
there, though. In the tripack package, you will find the functions to make 
a voronoi class, defining the boundaries of the tesselation of neighbours. 
However, plot.voronoi() just draws the lines, I don't think it returns 
polygons, but could. Point-in-polygon functions are in the splancs 
package, but there you need the polygons. It would be sensible to use 
polygon bounding boxes on your regular grid to reduce the number of calls 
to point-in-polygon. For a dense grid, more sophistication would be 
needed. You would also need to watch the open polygons where boundaries 
run to infinity at the edges as far as point-in-polygon is concerned.

There are functions in package spatstat too, for instance 
nearest.raster.point() does the reverse of what you want - which raster 
cells are nearest to point coordinates - not which are closer.

Please contact me off-list if I can help further.

Roger

> Matt Oliver
> Institute of Marine and Coastal Sciences
> Rutgers University, New Brunswick, NJ
> 07728 oliver at imcs.rutgers.edu
> 
-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From ripley at stats.ox.ac.uk  Fri Jan 31 12:10:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 31 12:10:03 2003
Subject: [R] mgcv, gam
In-Reply-To: <Pine.SOL.3.96.1030131103153.23643C-100000@moon.stats.gla.ac.uk>
Message-ID: <Pine.LNX.4.44.0301311105130.15982-100000@gannet.stats>

On Fri, 31 Jan 2003, Simon Wood wrote:

> > I have some problems with gam in mgcv. Firts a detail: it would
> > be nice igf gam would accept an na.action argument, but that not the 
> > main point.
> - I find it hard to think of a sensible action except dropping the
> associated data, but if you've a concrete suggestion I'm happy to add it
> to the "to do" list.

Simon: there's a standard interface here: you call na.action and it
decides what to do.  Basically you need to set up a model frame as e.g.
lm does, and then pass that as `data' to gam.setup.  It would eliminate
some other inconsistencies (e.g. not using environment(formula)) too.

I hope that's clear enough, but please feel to talk to me privately.

Brian

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jarioksa at sun3.oulu.fi  Fri Jan 31 12:17:03 2003
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Fri Jan 31 12:17:03 2003
Subject: [R] nearest neighbour interpolation
In-Reply-To: <Pine.LNX.4.44.0301311126160.4187-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0301311126160.4187-100000@reclus.nhh.no>
Message-ID: <1044011803.5066.4.camel@pc112145.oulu.fi>

On Fri, 2003-01-31 at 12:47, Roger Bivand wrote:
> On Thu, 30 Jan 2003, Matthew Oliver wrote:
> 
> > Dear Help List,
> > 
> > My name is Matt Oliver. I have been using R for about a year and find it very 
> > helpful. However, I have a need for a function that I cannot find. I am not very 
> > good at programming so I thought I would ask the group.
> > 
> Maybe this is an opportunity to explore things - they are usually feasible
> if the motivation is sufficiently strong.
> 
> > I have an irregular grid of data (x = Longitude, y = Latitude). Each pair of my x,y 
> > has a categorical value. Obviously linear or any other numerically based 
> > interpolation on categorical data does not make sense, so I want to use a nearest 
> > neighbor interpolation so that I can extrapolate my irregular grid to a regular grid 
> > of Longitude and Latitude.
> > 
> There does not seem to be such a function at present. 

I am not sure if this is an answer to the original question, but package
akima does the following:

Description: Linear or cubic spline interpolation for irregular
        gridded data

which sounds like something that was asked for.

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From ripley at stats.ox.ac.uk  Fri Jan 31 12:26:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 31 12:26:03 2003
Subject: [R] nearest neighbour interpolation
In-Reply-To: <1044011803.5066.4.camel@pc112145.oulu.fi>
Message-ID: <Pine.LNX.4.44.0301311122280.16075-100000@gannet.stats>

On 31 Jan 2003, Jari Oksanen wrote:

> On Fri, 2003-01-31 at 12:47, Roger Bivand wrote:
> > On Thu, 30 Jan 2003, Matthew Oliver wrote:
> > 
> > > Dear Help List,
> > > 
> > > My name is Matt Oliver. I have been using R for about a year and find it very 
> > > helpful. However, I have a need for a function that I cannot find. I am not very 
> > > good at programming so I thought I would ask the group.
> > > 
> > Maybe this is an opportunity to explore things - they are usually feasible
> > if the motivation is sufficiently strong.
> > 
> > > I have an irregular grid of data (x = Longitude, y = Latitude). Each pair of my x,y 
> > > has a categorical value. Obviously linear or any other numerically based 
> > > interpolation on categorical data does not make sense, so I want to use a nearest 
> > > neighbor interpolation so that I can extrapolate my irregular grid to a regular grid 
> > > of Longitude and Latitude.
> > > 
> > There does not seem to be such a function at present. 
> 
> I am not sure if this is an answer to the original question, but package
> akima does the following:
> 
> Description: Linear or cubic spline interpolation for irregular
>         gridded data
> 
> which sounds like something that was asked for.

That's what was explicitly _not_ asked for: it's numerical.

Categorical nearest-neighbour interpolation can be done (easily) via
knn1 in package class, although it is a bit inefficient for very large 
grids and there are theoretically faster ways (see my 1981 book, for 
example).  You can do the grid in parts, though.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From hennig at stat.math.ethz.ch  Fri Jan 31 12:35:02 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Fri Jan 31 12:35:02 2003
Subject: [R] Validation of clustering
In-Reply-To: <Pine.GSO.4.32.0301301038370.29284-100000@goiana>
Message-ID: <Pine.LNX.4.44.0301311228530.3823-100000@florence>

Hi,

I am not really sure what you want to know. 
If you simply want to know how to find the resulting clustering, consider
help(clara.object). For validation and assessment of the clustering, you
might use a silhouette plot, see help(plot.partition),
help(partition.object). 

For more descriptions consider the book of Kaufman and Rousseeuw; some free
material is on
http://win-www.uia.ac.be/u/statis/index.html
(Programs->Clustering)

Best,
Christian

On Thu, 30 Jan 2003, Francisco do Nascimento Junior wrote:

> Hi,
> I'm using the library cluster to cluster a set of figures (method CLARA).
> Somebody that it work with clustering would know informs what I make to
> evaluate the clustering?
> 
> Tks VM,
> Francisco.
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Francisco J?nior,
> Computer Science - UFPE-Brazil
> "One life has more value that the
> world whole"
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de



From mail-list at linaria.dst.unive.it  Fri Jan 31 13:30:03 2003
From: mail-list at linaria.dst.unive.it (Claudio Agostinelli)
Date: Fri Jan 31 13:30:03 2003
Subject: [R] typo in read.table and count.fields?
In-Reply-To: <Pine.LNX.4.44.0301311105130.15982-100000@gannet.stats>
Message-ID: <Pine.LNX.4.33L2.0301311306380.15149-100000@linaria.dst.unive.it>

It seems that in read.table and count.fields there is a typo in the quote
parameter.

read.table(file, header = FALSE, sep = "", quote = "\"'", dec = ".",
           row.names, col.names, as.is = FALSE, na.strings = "NA",
           colClasses = NA, nrows = -1,
           skip = 0, check.names = TRUE, fill = !blank.lines.skip,
           strip.white = FALSE, blank.lines.skip = TRUE,
           comment.char = "#")

presents in R-devel   .tar.gz file of today and in R-1.6-2

> args(read.table)
function (file, header = FALSE, sep = "", quote = "\"'", dec = ".",
    row.names, col.names, as.is = FALSE, na.strings = "NA", colClasses =
NA,
    nrows = -1, skip = 0, check.names = TRUE, fill = !blank.lines.skip,
    strip.white = FALSE, blank.lines.skip = TRUE, comment.char = "#")
NULL

> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.2
year     2003
month    01
day      10
language R

Bests,
Claudio



From B.Rowlingson at lancaster.ac.uk  Fri Jan 31 13:38:02 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri Jan 31 13:38:02 2003
Subject: [R] nearest neighbour interpolation
In-Reply-To: <Pine.LNX.4.44.0301311126160.4187-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0301311126160.4187-100000@reclus.nhh.no>
Message-ID: <3E3A6E01.6060700@lancaster.ac.uk>

Roger Bivand wrote:
> Point-in-polygon functions are in the splancs 
> package, but there you need the polygons.

  There's also nearest-neighbour functions in Splancs - the nn2d 
function returns the distances and indices of the nearest points in one 
set (the grid) to another set (the data points). 'Interpolation' is then 
just a matter of taking the value of the factor indexed by the result. 
Its easier to do than describe.

  It is inefficient though, since it computes all Npts x Ngrid neighbour 
distances. Horrible if you want to do a large number of simulations, but 
if it takes twenty minutes and you only have to do it once, put the 
kettle on and have a cup of tea while the Computer Scientists tell you 
how to improve the algorithm. The function will be finished and your tea 
drunk by the time they've explained it.

> There are functions in package spatstat too, for instance 
> nearest.raster.point() does the reverse of what you want - which raster 
> cells are nearest to point coordinates - not which are closer.

  Hopefully Rasp will have better point/polygon/nearest-neighbour 
functionality.

> Please contact me off-list if I can help further.

  I've emailed Matt the splancs-based solution.

Baz



From p.dalgaard at biostat.ku.dk  Fri Jan 31 13:51:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 31 13:51:02 2003
Subject: [R] typo in read.table and count.fields?
In-Reply-To: <Pine.LNX.4.33L2.0301311306380.15149-100000@linaria.dst.unive.it>
References: <Pine.LNX.4.33L2.0301311306380.15149-100000@linaria.dst.unive.it>
Message-ID: <x2hebpo53v.fsf@biostat.ku.dk>

Claudio Agostinelli <mail-list at linaria.dst.unive.it> writes:

> It seems that in read.table and count.fields there is a typo in the quote
> parameter.
> 
> read.table(file, header = FALSE, sep = "", quote = "\"'", dec = ".",
>            row.names, col.names, as.is = FALSE, na.strings = "NA",
>            colClasses = NA, nrows = -1,
>            skip = 0, check.names = TRUE, fill = !blank.lines.skip,
>            strip.white = FALSE, blank.lines.skip = TRUE,
>            comment.char = "#")
> 
> presents in R-devel   .tar.gz file of today and in R-1.6-2
> 
> > args(read.table)
> function (file, header = FALSE, sep = "", quote = "\"'", dec = ".",
>     row.names, col.names, as.is = FALSE, na.strings = "NA", colClasses =
> NA,
>     nrows = -1, skip = 0, check.names = TRUE, fill = !blank.lines.skip,
>     strip.white = FALSE, blank.lines.skip = TRUE, comment.char = "#")
> NULL

Ehh.... what typo? quote is a string consisting of the two possible
quoting characters, " and ', and to display such a string, the " needs
to be escaped within "...".

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Morten.Sickel at nrpa.no  Fri Jan 31 14:34:02 2003
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Fri Jan 31 14:34:02 2003
Subject: [R] Varying texts in expression(paste())
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5DB2@postix.nrpa.no>

Hi,

I am using R a lot to make plots relating to radioactivity, I am often using
expression() to label the plots with nuclide names written with
superscripts, e.g. 
	expression(paste("Releases of ", { }^{99},Tc," (TBq/year)"))->ywtext
But, is there any simple way to change the number and name of the nuclide
through a variable? I tried 
	nuccode=expression({ }^{99},Tc)
expression(paste("Releases of ", as.expression(nuccode) ,"
(TBq/year)"))->ywtext

But, obiously, since as.expression does not return a chr, it was used
literally in the text on the figure, i.e. "Releases of
as.expression(nuccode) (TBq/year)" which definiately was not what I
wanted... 

should I use some other wrapper function on the expression, or are there
some other ways of making superscripts in figure texts?

regards

Morten

-- 
Morten Sickel
Norwegian Radiation Protection Authority
http://www.nrpa.no



From bert_gunter at merck.com  Fri Jan 31 14:46:02 2003
From: bert_gunter at merck.com (Gunter, Bert)
Date: Fri Jan 31 14:46:02 2003
Subject: [R] Decreasing my personal entropy ...
Message-ID: <D45BC82E21E16149AC5A3F706350626401953AC3@usrymx14.merck.com>

R-Listers:

A very minor -- and maybe silly -- question just for personal enlightenment.

In S (either R or S-Plus, AFAIK) when one types or pastes a trellis graphics
command into the commands/console window, the graph is automatically
produced:
e.g.,

trellis.device(...)
xyplot(y~x)

If one puts these in a function and calls the function, the same occurs.
However, if one sources in these command from a file (i.e., using source()),
automatic printing does not occur; one must explicitly call
print(xyplot(y~x)) . Why do things work this way?  

Many thanks.

Bert Gunter
Biometrics Research RY 84-16
Merck & Company
P.O. Box 2000
Rahway, NJ 07065-0900
Phone: (732) 594-7765
mailto: bert_gunter at merck.com

"The business of the statistician is to catalyze the scientific learning
process."      -- George E.P. Box


------------------------------------------------------------------------------



From theis at statistik.uni-dortmund.de  Fri Jan 31 14:54:02 2003
From: theis at statistik.uni-dortmund.de (Winfried Theis)
Date: Fri Jan 31 14:54:02 2003
Subject: [R] Varying texts in expression(paste())
In-Reply-To: <54DE9A561AD20C4D9FF88B116965420E4E5DB2@postix.nrpa.no>
Message-ID: <XFMail.030131160430.theis@statistik.uni-dortmund.de>

Hi,

I had a similar problem last year and Thomas Lumley helped me a lot on this. I
needed to replace some variables by their values in a quite complicated text
expression. Here is what Thomas suggested:

<quote Thomas Lumley on>
In your example you wanted b and c to be elements of a vector.  They
actually have to be elements of a list

> c(quote(beta),quote(gamma^3))
[[1]]
beta

[[2]]
gamma^3

So
 expr1<-quote(alpha)
 expr2<-c( quote(beta), quote(gamma^3))
 plot(1:10,main=substitute("Estimated "*a*" for "*b*" vs."*c,
        list(a=expr1,b=expr2[[1]],c=expr2[[2]])))

Finally, you could even make the expressions from text strings if you want
to

str1<-"alpha"
str2<-c("beta","gamma^3")

expr1<-parse(text=str1)[[1]]
expr2<-parse(text=str2)
 plot(1:10,main=substitute("Estimated "*a*" for "*b*" vs."*c,
        list(a=expr1,b=expr2[[1]],c=expr2[[2]])))

<quote Thomas Lumley off>
For full details see (and this is worthwhile!) the thread "[R] Constructing
titles from list of expressions" from August 7, 2002.

Thanks again to Thomas,

Winfried

---------------------------------------------------------------------
E-Mail: Winfried Theis <theis at statistik.uni-dortmund.de>
Date: 31-Jan-03

Dipl.-Math. Winfried Theis
SFB 475, Fachbereich Statistik, Universit"at Dortmund, 44221 Dortmund
Tel.: +49-231-755-5903 FAX: +49-231-755-4387
----------------------------------------------------------------------



From ozric at web.de  Fri Jan 31 15:03:02 2003
From: ozric at web.de (Christian Schulz)
Date: Fri Jan 31 15:03:02 2003
Subject: [R] RODBC & Sys.sleep
Message-ID: <001101c2c930$d46d47e0$eeb907d5@c5c9i0>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030131/e80251f4/attachment.pl

From fnj at cin.ufpe.br  Fri Jan 31 15:07:05 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Fri Jan 31 15:07:05 2003
Subject: [R] Library for GUI?
Message-ID: <Pine.GSO.4.32.0301311100440.10481-100000@goiana>

Are there some library for to make graphic interface with buttons, fields,
menus???
Tks,
Francisco.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco Júnior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From jfox at mcmaster.ca  Fri Jan 31 15:12:02 2003
From: jfox at mcmaster.ca (John Fox)
Date: Fri Jan 31 15:12:02 2003
Subject: [R] Decreasing my personal entropy ...
In-Reply-To: <D45BC82E21E16149AC5A3F706350626401953AC3@usrymx14.merck.co
 m>
Message-ID: <5.1.0.14.2.20030131090552.01e43228@mcmail.cis.mcmaster.ca>

Dear Bert,

At 08:45 AM 1/31/2003 -0500, Gunter, Bert wrote:
>R-Listers:
>
>A very minor -- and maybe silly -- question just for personal enlightenment.
>
>In S (either R or S-Plus, AFAIK) when one types or pastes a trellis graphics
>command into the commands/console window, the graph is automatically
>produced:
>e.g.,
>
>trellis.device(...)
>xyplot(y~x)
>
>If one puts these in a function and calls the function, the same occurs.
>However, if one sources in these command from a file (i.e., using source()),
>automatic printing does not occur; one must explicitly call
>print(xyplot(y~x)) . Why do things work this way?

Actually, a function that calls xyplot() won't necessarily produce a plot 
without an explicit call to print(). Consider the following two functions:

         fun.1 <- function(x,y) {xyplot(y~x); return(NULL)}
         fun.2 <- function(x,y) xyplot(y~x)

fun.1 doesn't plot anything; fun.2 produces a plot when called from the 
command prompt, but only when its result is unassigned, and only because it 
returns an object of class "trellis", which is then automatically printed.

The general point is that the print method for trellis objects plots the 
objects, so when print() gets called implicitly on a trellis object, the 
object is plotted.

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From jfox at mcmaster.ca  Fri Jan 31 15:16:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Fri Jan 31 15:16:03 2003
Subject: [R] Library for GUI?
In-Reply-To: <Pine.GSO.4.32.0301311100440.10481-100000@goiana>
Message-ID: <5.1.0.14.2.20030131091455.01defdb0@mcmail.cis.mcmaster.ca>

Dear Francisco,

See the tcltk package.

John

At 11:02 AM 1/31/2003 -0300, you wrote:
>Are there some library for to make graphic interface with buttons, fields,
>menus???

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From ozric at web.de  Fri Jan 31 15:20:03 2003
From: ozric at web.de (Christian Schulz)
Date: Fri Jan 31 15:20:03 2003
Subject: [R] Library for GUI?
References: <Pine.GSO.4.32.0301311100440.10481-100000@goiana>
Message-ID: <003401c2c932$ca84e510$eeb907d5@c5c9i0>

library(tcltk)
library(RGtk)

christian

----- Original Message -----
From: "Francisco do Nascimento Junior" <fnj at cin.ufpe.br>
To: "R-help" <R-help at stat.math.ethz.ch>
Sent: Friday, January 31, 2003 3:02 PM
Subject: [R] Library for GUI?


Are there some library for to make graphic interface with buttons, fields,
menus???
Tks,
Francisco.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco J?nior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From bates at stat.wisc.edu  Fri Jan 31 15:33:02 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Jan 31 15:33:02 2003
Subject: [R] Decreasing my personal entropy ...
In-Reply-To: <D45BC82E21E16149AC5A3F706350626401953AC3@usrymx14.merck.com>
References: <D45BC82E21E16149AC5A3F706350626401953AC3@usrymx14.merck.com>
Message-ID: <6ru1fpfkz8.fsf@bates4.stat.wisc.edu>

"Gunter, Bert" <bert_gunter at merck.com> writes:

> R-Listers:
> 
> A very minor -- and maybe silly -- question just for personal enlightenment.
> 
> In S (either R or S-Plus, AFAIK) when one types or pastes a trellis graphics
> command into the commands/console window, the graph is automatically
> produced:
> e.g.,
> 
> trellis.device(...)
> xyplot(y~x)
> 
> If one puts these in a function and calls the function, the same occurs.

Only if the trellis/lattice function call is the last function call in
your function.

> However, if one sources in these command from a file (i.e., using source()),
> automatic printing does not occur; one must explicitly call
> print(xyplot(y~x)) . Why do things work this way?  

Trellis/lattice calls return objects.  Plots are produced by the print
method for such objects.  When used interactively R is in a
read-eval-print loop so the value of, for example,

 > xyplot(y ~ x | f, data = mydata)

is equivalent to

 > print(eval(parse(text="xyplot(y ~ x | f, data = mydata)")))

If you have a function that ends in a call to xyplot then the value of
the function is the value of the call to xyplot and it is treated the
same.

The reason that calls to source behave differently is described in the
R FAQ entry "Why is the output not printed when I source() a file?"

> Many thanks.

You're welcome.  Regards from Madison.

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From helma at informatik.uni-freiburg.de  Fri Jan 31 15:39:03 2003
From: helma at informatik.uni-freiburg.de (Christoph Helma)
Date: Fri Jan 31 15:39:03 2003
Subject: [R] svm regression in R
Message-ID: <20030131152811.C19569@helma.informatik.uni-freiburg.de>

Hallo,

I have a question concerning SVM regression in R. I intend to use SVMs for feature selection (and knowledge discovery). For this purpose I will need to extract the weights that are associated with my features. I understand from a previous thread on SVM classification, that predictive models can be derived from SVs, coefficiants and rhos, but it is unclear for me how to transfer this information to the regression problem. Can anyone help in this respect (I am *not* an SVM expert)?

Thanks,
Christoph
--
:: christoph helma
:: computational toxicologist
:: university freiburg
:: georges koehler allee 079, d-79110 freiburg/br
:: phone ++49-761-203-8013, fax -8007
:: helma at informatik.uni-freiburg.de
:: http://www.informatik.uni-freiburg.de/~helma/



From Carl-Goran.Pettersson at evp.slu.se  Fri Jan 31 15:50:03 2003
From: Carl-Goran.Pettersson at evp.slu.se (C-G Pettersson)
Date: Fri Jan 31 15:50:03 2003
Subject: [R] TukeyHSD
Message-ID: <5.2.0.9.0.20030131152942.00a118f0@mail1.slu.se>

Hello everybody!
I?m working with a dataset from eleven field trails on barley 
fertilization. I use R 1.6.2 (Windows)

It is quite easy to fit aov() objects to the dataset.
The call:

 > (l1t4y.aov <- aov(Yield ~ Trial + Treatment, data=led1t4b))
Results in an object with this anova table:

              Df    Sum Sq   Mean Sq F value    Pr(>F)
Trial        10 121423585  12142358  63.499 < 2.2e-16 ***
Treatment     3  15252804   5084268  26.589 3.288e-13 ***
Residuals   118  22564015    191220

which is in line with what I know about the data.

When I then try to look at the treatment contrasts with an approach as near 
as possible to pp178-181 in MASS, the following happens:

 > (l1t4y.tk <- TukeyHSD(l1t4y.aov, which = "Treatment"))
Error in replications(paste("~", paste(names(tables), collapse = "+")),  :
         na.action must be a function

What have I done wrong, and what does the error message mean? There are no 
empty cells in the "Treatment" column. The TukeyHSD call works fine with 
the "immer" and "oats" datasets from MASS.

/CG




CG Pettersson, MSc, PhD-stud
Department of Ecology and Crop Production Science, SLU
P.O. Box 7043
S-750 07 Uppsala, Sweden
Phone: +46 (0)18 67 12 24; Fax: +46 (0)18 67 29 06
        +46 (0)70 330 66 85



From p.dalgaard at biostat.ku.dk  Fri Jan 31 16:07:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 31 16:07:04 2003
Subject: [R] r-bugs web site temporarily down
Message-ID: <x2wuklwe9z.fsf@biostat.ku.dk>

The machine that serves r-bugs.biostat.ku.dk has been taken off the
net. A new machine is planned to replace it, but we need to
reconfigure the DNS, which is not going to happen until Monday. The
mail interface should still work.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Fri Jan 31 16:12:09 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 31 16:12:09 2003
Subject: [R] TukeyHSD
In-Reply-To: <5.2.0.9.0.20030131152942.00a118f0@mail1.slu.se>
Message-ID: <Pine.LNX.4.44.0301311504150.22067-100000@gannet.stats>

You implicitly (probably) used na.omit on your dataset, and it added an
na.action attribute to the data frame.  Try not doing that (e.g. bu using
na.action = na.fail and search the archives for the same question about
model.tables).  Are there any missing values in your dataset? If so, you
should worry about balance (not that the numbers are inconsistent: 11
trials, 4 treatments on each replicated 3 times would seem to fit).

On Fri, 31 Jan 2003, C-G Pettersson wrote:

> Hello everybody!
> I?m working with a dataset from eleven field trails on barley 
> fertilization. I use R 1.6.2 (Windows)
> 
> It is quite easy to fit aov() objects to the dataset.
> The call:
> 
>  > (l1t4y.aov <- aov(Yield ~ Trial + Treatment, data=led1t4b))
> Results in an object with this anova table:
> 
>               Df    Sum Sq   Mean Sq F value    Pr(>F)
> Trial        10 121423585  12142358  63.499 < 2.2e-16 ***
> Treatment     3  15252804   5084268  26.589 3.288e-13 ***
> Residuals   118  22564015    191220
> 
> which is in line with what I know about the data.
> 
> When I then try to look at the treatment contrasts with an approach as near 
> as possible to pp178-181 in MASS, the following happens:
> 
>  > (l1t4y.tk <- TukeyHSD(l1t4y.aov, which = "Treatment"))
> Error in replications(paste("~", paste(names(tables), collapse = "+")),  :
>          na.action must be a function
> 
> What have I done wrong, and what does the error message mean? There are no 
> empty cells in the "Treatment" column. The TukeyHSD call works fine with 
> the "immer" and "oats" datasets from MASS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Morten.Sickel at nrpa.no  Fri Jan 31 16:37:06 2003
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Fri Jan 31 16:37:06 2003
Subject: [R] Varying texts in expression(paste())
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5DB5@postix.nrpa.no>

Gunter Bart wrote:
> You need substitute(). Look at the examples in plotmath().
> x<-3;y<-'foo'
> plot(c(0,1),c(0,1),type='n')
> text(.5,.5,substitute(paste('Releases of ',x^99,' ',y,'
> TBq/year'),list(x=x,y=y)))
> Hope this helps ...

Thanks a lot, it helped indeed!

Morten



From gregory_r_warnes at groton.pfizer.com  Fri Jan 31 17:02:02 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri Jan 31 17:02:02 2003
Subject: [R] Decreasing my personal entropy ...
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C52F@groexmb02.pfizer.com>

Lattice plots and trellice plots are actually displayed by thier 'print'
methods.  So, to get ta plot to be displayed in a non-interactive context,
such as a script, explicitly call print on the results of the plot command.

-Greg

-----Original Message-----
From: Gunter, Bert
To: R-Help (E-mail)
Sent: 1/31/03 8:45 AM
Subject: [R] Decreasing my personal entropy ...

R-Listers:

A very minor -- and maybe silly -- question just for personal
enlightenment.

In S (either R or S-Plus, AFAIK) when one types or pastes a trellis
graphics
command into the commands/console window, the graph is automatically
produced:
e.g.,

trellis.device(...)
xyplot(y~x)

If one puts these in a function and calls the function, the same occurs.
However, if one sources in these command from a file (i.e., using
source()),
automatic printing does not occur; one must explicitly call
print(xyplot(y~x)) . Why do things work this way?  

Many thanks.

Bert Gunter
Biometrics Research RY 84-16
Merck & Company
P.O. Box 2000
Rahway, NJ 07065-0900
Phone: (732) 594-7765
mailto: bert_gunter at merck.com

"The business of the statistician is to catalyze the scientific learning
process."      -- George E.P. Box


------------------------------------------------------------------------
------

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From mihastaut at hotmail.com  Fri Jan 31 17:45:06 2003
From: mihastaut at hotmail.com (Miha STAUT)
Date: Fri Jan 31 17:45:06 2003
Subject: [R] Slavic characters
Message-ID: <BAY2-F41oQgpdiZyBdm00009a96@hotmail.com>

Hi all,

How would I get to print other slavic letters than only the ones present in 
the standard ASCII code as mentioned in Hershey vector fonts?

Miha Staut



From smithq15 at yahoo.com  Fri Jan 31 18:25:03 2003
From: smithq15 at yahoo.com (Suzy Smith)
Date: Fri Jan 31 18:25:03 2003
Subject: [R] Scientific Notation on tick marks
Message-ID: <20030131172402.13972.qmail@web14609.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030131/86fd83c1/attachment.pl

From david.meyer at ci.tuwien.ac.at  Fri Jan 31 18:43:05 2003
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Fri Jan 31 18:43:05 2003
Subject: [R] svm regression in R
References: <20030131152811.C19569@helma.informatik.uni-freiburg.de>
Message-ID: <3E3AB4BE.C15CB5A8@ci.tuwien.ac.at>

Christoph Helma wrote:
> 
> Hallo,
> 
> I have a question concerning SVM regression in R. I intend to use SVMs for feature selection (and knowledge discovery). For this purpose I will need to extract the weights that are associated with my features. I understand from a previous thread on SVM classification, that predictive models can be derived from SVs, coefficiants and rhos, but it is unclear for me how to transfer this information to the regression problem. Can anyone help in this respect (I am *not* an SVM expert)?

That's pretty simple.
The ``decision'' (predictor) function for regression is as follows:

f(x) = \sum_{i=1}^{l} alpha_i * K(x_i, x) - rho

where `alpha_i' are the coefficients of the SVs, `x_i' are the SVs
themselves, and `l' the number of SVs.
Note that `rho' must be *substracted* because libsvm returns -b for some
reasion.

Best,

David.

> 
> Thanks,
> Christoph
> --
> :: christoph helma
> :: computational toxicologist
> :: university freiburg
> :: georges koehler allee 079, d-79110 freiburg/br
> :: phone ++49-761-203-8013, fax -8007
> :: helma at informatik.uni-freiburg.de
> :: http://www.informatik.uni-freiburg.de/~helma/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
        Mag. David Meyer            Wiedner Hauptstrasse 8-10
Vienna University of Technology     A-1040 Vienna/AUSTRIA
         Department of              Tel.: (+431) 58801/10772
Statistics and Probability Theory   Fax.: (+431) 58801/10798



From dyang at nrcan.gc.ca  Fri Jan 31 18:51:05 2003
From: dyang at nrcan.gc.ca (Yang, Richard)
Date: Fri Jan 31 18:51:05 2003
Subject: [R] Multiple xyplot on a page
Message-ID: <F0E0B899CB43D5118D220002A55113CF21BBC9@s2-edm-r1.nofc.cfs.nrcan.gc.ca>

Dear all;

	I have a set of 5 xyplots each with 8 panels and wish to place 2 on
a letter-sized page. I tried using pdf() to specify paper size and plot
size:

>pdf(file = "fig1b.pdf", paper = "letter", onefile = FALSE, width = 5,
height = 5,
 family="Helvetica")
>par(mfrow=c(1,2))

but it did not work. Any suggestions for placing mutiple xyplots to a page?

TIA,

Richard



From SuzieBlatt at netscape.net  Fri Jan 31 18:55:06 2003
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Fri Jan 31 18:55:06 2003
Subject: [R] Fonts in expression(paste)
Message-ID: <7D6D10D6.6B9FD908.0D1322AF@netscape.net>

Hello.

I'm trying to change the fonts of my text.  If I have 'expression(paste)' included (to get scientific symbols), the font= doesn't take effect.  Is there a way around this?

Thanks,
Suzanne

__________________________________________________________________
The NEW Netscape 7.0 browser is now available. Upgrade now! http://channels.netscape.com/ns/browsers/download.jsp



From kjetil at entelnet.bo  Fri Jan 31 19:00:09 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri Jan 31 19:00:09 2003
Subject: [R] (no subject)
In-Reply-To: <200301301817.AA62521500@koulikov.com>
Message-ID: <3E3A7FCC.3139.726AA6@localhost>

On 30 Jan 2003 at 18:17, pavel koulikov wrote:

You should use a subject line. To put to lines on the same plot:

plot(x~y, type="l")
lines(z ~ v)

Kjetil Halvorsen


> Hi
> I have 4 vectors x,y,z,v
> I need 2 graphs (x~y,z~v) on the same plot. I mean two lines on the same plot - blue and red.
> I wrote:
>  
> c.pl=xyplot(y~x,
>           na.rm="TRUE",type="l",more=TRUE,
>           scales = list(cex=3/4,x=list(tick.number=3,alternating = c(0,1)),y=list(tick.number=7)),   
>           panel = function(x,y,...) {
>           panel.grid(h=-1,v=3,lwd=1/8,col=COLAVG,lty=3)
>           panel.xyplot(x,y,...)
> 
>         }
>    
>    )
> 
> How can I pu the second x~v graph on the same plot???
>    
>      
>    
> 
>   print(c.pl)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ernesto at ipimar.pt  Fri Jan 31 19:11:02 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Fri Jan 31 19:11:02 2003
Subject: [R] Problems with boot package (empinf returns NA)
Message-ID: <1044036826.3285.8.camel@gandalf>

Hi

I'm using boot package for some analysis on linear regression
coeficients. My problem is that I can not compute bca intervals, I get
an error message

> bca.ci(blm8901,index=1)
Error in if (!all(rk > 1 & rk < R)) warning("Extreme Order Statistics
used as Endpoints") : 
        missing value where logical needed

The problem is the empinf.reg function that is returning Na when
performing a glm regression, statement

beta <- coefficients(glm(t ~ X))[-1]
  
I don't see anything strange in t or X, but I'm missing something for
sure. 

Can someone give me an hint on this ?

Thanks

EJ



From ligges at statistik.uni-dortmund.de  Fri Jan 31 19:20:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Jan 31 19:20:03 2003
Subject: [R] Fonts in expression(paste)
In-Reply-To: <7D6D10D6.6B9FD908.0D1322AF@netscape.net>
References: <7D6D10D6.6B9FD908.0D1322AF@netscape.net>
Message-ID: <3E3ABE51.8020406@statistik.uni-dortmund.de>

Suzanne E. Blatt wrote:
> Hello.
> 
> I'm trying to change the fonts of my text.  If I have 'expression(paste)' included (to get scientific symbols), the font= doesn't take effect.  Is there a way around this?
> 
> Thanks,
> Suzanne

?plotmath helps:

plain(x)  draw x in normal font
bold(x)  draw x in bold font
italic(x)  draw x in italic font
bolditalic(x)  draw x in bolditalic font

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Fri Jan 31 19:25:01 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Jan 31 19:25:01 2003
Subject: [R] Scientific Notation on tick marks
In-Reply-To: <20030131172402.13972.qmail@web14609.mail.yahoo.com>
References: <20030131172402.13972.qmail@web14609.mail.yahoo.com>
Message-ID: <3E3ABF18.5020203@statistik.uni-dortmund.de>

Suzy Smith wrote:
> Hi, I was working on a project for my class and I am trying to make sure the y-axis numbers NEVER convert automatically to scientific notation.  Is there anything I can set in the plot function to make sure of this?
> 
> I know formatC( ) can be used in the axis function, but it seems to give me an error when using it in the plot function.

You cannot do this in plot() directly, AFAIK.
Instead, you might want to use formatC() in axis() as mentioned, that's 
one reason why these low level functions are available ...

Uwe Ligges



From andy_liaw at merck.com  Fri Jan 31 19:29:06 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Jan 31 19:29:06 2003
Subject: [R] Multiple xyplot on a page
Message-ID: <3A822319EB35174CA3714066D590DCD534BC12@usrymx25.merck.com>

The help page for print.trellis should give you some hints.

Andy

> -----Original Message-----
> From: Yang, Richard [mailto:dyang at nrcan.gc.ca]
> Sent: Friday, January 31, 2003 12:50 PM
> To: R-Help (E-mail)
> Subject: [R] Multiple xyplot on a page
> 
> 
> Dear all;
> 
> 	I have a set of 5 xyplots each with 8 panels and wish 
> to place 2 on
> a letter-sized page. I tried using pdf() to specify paper 
> size and plot
> size:
> 
> >pdf(file = "fig1b.pdf", paper = "letter", onefile = FALSE, width = 5,
> height = 5,
>  family="Helvetica")
> >par(mfrow=c(1,2))
> 
> but it did not work. Any suggestions for placing mutiple 
> xyplots to a page?
> 
> TIA,
> 
> Richard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From deepayan at stat.wisc.edu  Fri Jan 31 19:41:02 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Jan 31 19:41:02 2003
Subject: [R] Multiple xyplot on a page
In-Reply-To: <F0E0B899CB43D5118D220002A55113CF21BBC9@s2-edm-r1.nofc.cfs.nrcan.gc.ca>
References: <F0E0B899CB43D5118D220002A55113CF21BBC9@s2-edm-r1.nofc.cfs.nrcan.gc.ca>
Message-ID: <200301311240.29314.deepayan@stat.wisc.edu>

See ?print.trellis

On Friday 31 January 2003 11:50 am, Yang, Richard wrote:
> Dear all;
>
> 	I have a set of 5 xyplots each with 8 panels and wish to place 2 on
> a letter-sized page. I tried using pdf() to specify paper size and plot
>
> size:
> >pdf(file = "fig1b.pdf", paper = "letter", onefile = FALSE, width = 5,
>
> height = 5,
>  family="Helvetica")
>
> >par(mfrow=c(1,2))
>
> but it did not work. Any suggestions for placing mutiple xyplots to a page?
>
> TIA,
>
> Richard
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gray at jimmy.harvard.edu  Fri Jan 31 20:15:03 2003
From: gray at jimmy.harvard.edu (Bob Gray)
Date: Fri Jan 31 20:15:03 2003
Subject: [R] floating point question
Message-ID: <20030131141438.E1168@jimmy.harvard.edu>

Does anyone know precisely what is different about the arithmetic
and/or storage of double precision floating point to produce the
following differences between the Sun and Windows versions (Splus 6
on the same Windows 2000 machine gives the same results as Solaris)?

R 1.6.1, Sun Solaris, gcc + an old Sun f77
> options(digits=20)
> 1+(1/2^53+1/2^106)
[1] 1
> 1+(1/2^53+1/2^105)
[1] 1.0000000000000002
> 1+(1/2^53+1/2^64)
[1] 1.0000000000000002
> 1+(1/2^53+1/2^63)
[1] 1.0000000000000002

R 1.6.1, Windows 2000, binary downloaded from CRAN
> options(digits=20)
> 1+(1/2^53+1/2^106)
[1] 1
> 1+(1/2^53+1/2^105)
[1] 1
> 1+(1/2^53+1/2^64)
[1] 1
> 1+(1/2^53+1/2^63)
[1] 1.0000000000000002

(This may be frivolous, but I have been using the first 2 lines as an
example in a course.)

Thanks
--
Bob Gray



From deepayan at stat.wisc.edu  Fri Jan 31 20:32:02 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Jan 31 20:32:02 2003
Subject: [R] floating point question
In-Reply-To: <20030131141438.E1168@jimmy.harvard.edu>
References: <20030131141438.E1168@jimmy.harvard.edu>
Message-ID: <200301311331.12081.deepayan@stat.wisc.edu>

Might have something to do with .Machine$double.eps on the respective 
machines.


From ripley at stats.ox.ac.uk  Fri Jan 31 20:44:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri Jan 31 20:44:05 2003
Subject: [R] floating point question
In-Reply-To: <20030131141438.E1168@jimmy.harvard.edu>
Message-ID: <Pine.GSO.4.44.0301311936120.9551-100000@auk.stats>

It's a difference in the `libc'.  Asking for more precision than the
arithmetic has is asking for fairly random results.  The differences are as
likely to be in the *printing* as in the computations.

On Fri, 31 Jan 2003, Bob Gray wrote:

> Does anyone know precisely what is different about the arithmetic
> and/or storage of double precision floating point to produce the
> following differences between the Sun and Windows versions (Splus 6
> on the same Windows 2000 machine gives the same results as Solaris)?
>
> R 1.6.1, Sun Solaris, gcc + an old Sun f77
> > options(digits=20)
> > 1+(1/2^53+1/2^106)
> [1] 1
> > 1+(1/2^53+1/2^105)
> [1] 1.0000000000000002
> > 1+(1/2^53+1/2^64)
> [1] 1.0000000000000002
> > 1+(1/2^53+1/2^63)
> [1] 1.0000000000000002
>
> R 1.6.1, Windows 2000, binary downloaded from CRAN
> > options(digits=20)
> > 1+(1/2^53+1/2^106)
> [1] 1
> > 1+(1/2^53+1/2^105)
> [1] 1
> > 1+(1/2^53+1/2^64)
> [1] 1
> > 1+(1/2^53+1/2^63)
> [1] 1.0000000000000002
>
> (This may be frivolous, but I have been using the first 2 lines as an
> example in a course.)
>
> Thanks
> --
> Bob Gray
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dyang at nrcan.gc.ca  Fri Jan 31 20:51:03 2003
From: dyang at nrcan.gc.ca (Yang, Richard)
Date: Fri Jan 31 20:51:03 2003
Subject: [R] Multiple xyplot on a page
Message-ID: <F0E0B899CB43D5118D220002A55113CF21BBCA@s2-edm-r1.nofc.cfs.nrcan.gc.ca>

Many thanks to Renaud Lancelot, Andy Liaw and Deepayan Sarkar for their
prompt response to my query. They all point me to the print.trellis help
page which indeed solves my problem.

Thank all,

Richard


My original question:


 Dear all;
 
 	I have a set of 5 xyplots each with 8 panels and wish 
 to place 2 on
 a letter-sized page. I tried using pdf() to specify paper 
 size and plot
 size:
 
 >pdf(file = "fig1b.pdf", paper = "letter", onefile = FALSE, width = 5,
 height = 5,
  family="Helvetica")
 >par(mfrow=c(1,2))
 
 but it did not work. Any suggestions for placing mutiple 
 xyplots to a page?
 
 TIA,
 
 Richard



From p.dalgaard at biostat.ku.dk  Fri Jan 31 20:56:05 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 31 20:56:05 2003
Subject: [R] floating point question
In-Reply-To: <200301311331.12081.deepayan@stat.wisc.edu>
References: <20030131141438.E1168@jimmy.harvard.edu>
	<200301311331.12081.deepayan@stat.wisc.edu>
Message-ID: <x2znph14ho.fsf@biostat.ku.dk>

Deepayan Sarkar <deepayan at stat.wisc.edu> writes:

> Might have something to do with .Machine$double.eps on the respective 
> machines.
> 
> From help(.Machine),
> 
> double.eps: the smallest positive floating-point number `x' such that
>           `1 + x != 1'.  It equals `base^ulp.digits' if either `base'
>           is 2 or `rounding' is 0;  otherwise, it is `(base^ulp.digits)
>           / 2'.

No, it's trickier than that. I think it's due to the guard digits that
intel FPUs use. Both intel and Sun have 53bit mantissas in double pr.
but intel stores intermediate results to 64 bit precision, so you get
some double rounding effects. Essentially, during alignment, before
adding to 1, 2^-53(1+2^-52) is getting rounded up to binary

0.0000....0001 (52 bits after the ".")

on Sun but down to 

0.0000....0000100000000000 (63 bits)

on intel. Then, after adding 1, upon storing it you get the rounding
downwards to

1.0000....0000
 
> 
> On Friday 31 January 2003 01:14 pm, Bob Gray wrote:
> > Does anyone know precisely what is different about the arithmetic
> > and/or storage of double precision floating point to produce the
> > following differences between the Sun and Windows versions (Splus 6
> > on the same Windows 2000 machine gives the same results as Solaris)?
> >
> > R 1.6.1, Sun Solaris, gcc + an old Sun f77
> >
> > > options(digits=20)
> > > 1+(1/2^53+1/2^106)
> >
> > [1] 1
> >
> > > 1+(1/2^53+1/2^105)
> >
> > [1] 1.0000000000000002
> >
> > > 1+(1/2^53+1/2^64)
> >
> > [1] 1.0000000000000002
> >
> > > 1+(1/2^53+1/2^63)
> >
> > [1] 1.0000000000000002
> >
> > R 1.6.1, Windows 2000, binary downloaded from CRAN
> >
> > > options(digits=20)
> > > 1+(1/2^53+1/2^106)
> >
> > [1] 1
> >
> > > 1+(1/2^53+1/2^105)
> >
> > [1] 1
> >
> > > 1+(1/2^53+1/2^64)
> >
> > [1] 1
> >
> > > 1+(1/2^53+1/2^63)
> >
> > [1] 1.0000000000000002
> >
> > (This may be frivolous, but I have been using the first 2 lines as an
> > example in a course.)
> >
> > Thanks
> > --
> > Bob Gray
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tlumley at u.washington.edu  Fri Jan 31 21:04:06 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri Jan 31 21:04:06 2003
Subject: [R] floating point question
In-Reply-To: <x2znph14ho.fsf@biostat.ku.dk>
Message-ID: <Pine.A41.4.44.0301311159200.247918-100000@homer07.u.washington.edu>

On 31 Jan 2003, Peter Dalgaard BSA wrote:

> Deepayan Sarkar <deepayan at stat.wisc.edu> writes:
>
> > Might have something to do with .Machine$double.eps on the respective
> > machines.
> >
> > From help(.Machine),
> >
> > double.eps: the smallest positive floating-point number `x' such that
> >           `1 + x != 1'.  It equals `base^ulp.digits' if either `base'
> >           is 2 or `rounding' is 0;  otherwise, it is `(base^ulp.digits)
> >           / 2'.
>
> No, it's trickier than that. I think it's due to the guard digits that
> intel FPUs use. Both intel and Sun have 53bit mantissas in double pr.
> but intel stores intermediate results to 64 bit precision, so you get
> some double rounding effects. Essentially, during alignment, before
> adding to 1, 2^-53(1+2^-52) is getting rounded up to binary
>

There's some discussion of double rounding in a Appendix to David
Goldberg's "What every computer scientist should know about floating point
arithmetic", widely available on the Web.

However, as Brian Ripley points out, we have no control and there isn't
any point worrying about it.

Incidentally, this may well be a reason for the irritating habit of DLLs
in setting the floating point precision to 53 bits (well, the irritating
bit is not changing it back). This makes the results of computations
more nearly independent of where the numbers end up being stored.

	-thomas



From Mark.Wilkinson at stjude.org  Fri Jan 31 21:13:03 2003
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Fri Jan 31 21:13:03 2003
Subject: [R] png()/jpeg()
Message-ID: <A1DAD6685C12D511B20F00034725151380CE4B@sjmemexc3.stjude.org>

When I execute the following code, it works just like I want it to: three
pages of nine (or fewer) plots.  However, when I execute the code with the
first and last lines uncommented, I get three pages (files), but the 2nd &
3rd pages have overlapping plots.  It's like a new page wasn't created.  

I'm pretty sure I've either misplaced or left out a crucial call to some
function, but I'm not sure where. Please help.


#png(width=937, height=703, pointsize=15)
for (i in seq(1, 24, 9)) {
  par(mfrow=c(3, 3))
  
  for (gt in i:min((i+8), 24)) {
    
    plot(density(rnorm(1000)))
    
    for (j in 1:20) { 
      lines(density(rnorm(1000)), lty=4, col="gray")
    }
  }
}
#dev.off()


Thanks,


Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences

The opinions expressed here are my own and do not necessarily represent
those of St. Jude Children's Research Hospital.



From ripley at stats.ox.ac.uk  Fri Jan 31 21:19:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 31 21:19:03 2003
Subject: [R] floating point question
In-Reply-To: <Pine.A41.4.44.0301311159200.247918-100000@homer07.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0301312011210.1512-100000@gannet.stats>

On Fri, 31 Jan 2003, Thomas Lumley wrote:

> On 31 Jan 2003, Peter Dalgaard BSA wrote:
> 
> > Deepayan Sarkar <deepayan at stat.wisc.edu> writes:
> >
> > > Might have something to do with .Machine$double.eps on the respective
> > > machines.
> > >
> > > From help(.Machine),
> > >
> > > double.eps: the smallest positive floating-point number `x' such that
> > >           `1 + x != 1'.  It equals `base^ulp.digits' if either `base'
> > >           is 2 or `rounding' is 0;  otherwise, it is `(base^ulp.digits)
> > >           / 2'.
> >
> > No, it's trickier than that. I think it's due to the guard digits that
> > intel FPUs use. Both intel and Sun have 53bit mantissas in double pr.
> > but intel stores intermediate results to 64 bit precision, so you get
> > some double rounding effects. Essentially, during alignment, before
> > adding to 1, 2^-53(1+2^-52) is getting rounded up to binary

(Sparc FPUs have some guard digits, as far as I recall, and the fine 
details do vary by hardware, or at least they used to and we still have 
some of the machines that varied running.)

> There's some discussion of double rounding in a Appendix to David
> Goldberg's "What every computer scientist should know about floating point
> arithmetic", widely available on the Web.
> 
> However, as Brian Ripley points out, we have no control and there isn't
> any point worrying about it.
> 
> Incidentally, this may well be a reason for the irritating habit of DLLs
> in setting the floating point precision to 53 bits (well, the irritating
> bit is not changing it back). This makes the results of computations
> more nearly independent of where the numbers end up being stored.

I used to think that!  But when it became possible to build R for Windows
not chopping in-FPU calculations to 53 bits, the results were more
consistent, and we changed over.  At that point most of the
inconsistencies were in printing, hence my remark earlier.  The print
routines in Windows `libc' (really msvcrt.dll) does lose a digit or two
quite often, quite possibly to avoid giving meaningless ones (which glibc
is happy to if asked).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Jan 31 21:24:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Jan 31 21:24:03 2003
Subject: [R] png()/jpeg()
In-Reply-To: <A1DAD6685C12D511B20F00034725151380CE4B@sjmemexc3.stjude.org>
Message-ID: <Pine.LNX.4.44.0301312021250.1512-100000@gannet.stats>

It really would help to know the platform here: Windows and Unix have
separate implementations.  On Windows with R 1.6.2 there is no overlap 
that I can see.

Also the version of R, please.

On Fri, 31 Jan 2003, Wilkinson, Mark wrote:

> When I execute the following code, it works just like I want it to: three
> pages of nine (or fewer) plots.  However, when I execute the code with the
> first and last lines uncommented, I get three pages (files), but the 2nd &
> 3rd pages have overlapping plots.  It's like a new page wasn't created.  
> 
> I'm pretty sure I've either misplaced or left out a crucial call to some
> function, but I'm not sure where. Please help.
> 
> 
> #png(width=937, height=703, pointsize=15)
> for (i in seq(1, 24, 9)) {
>   par(mfrow=c(3, 3))
>   
>   for (gt in i:min((i+8), 24)) {
>     
>     plot(density(rnorm(1000)))
>     
>     for (j in 1:20) { 
>       lines(density(rnorm(1000)), lty=4, col="gray")
>     }
>   }
> }
> #dev.off()

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Mark.Wilkinson at stjude.org  Fri Jan 31 21:30:03 2003
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Fri Jan 31 21:30:03 2003
Subject: [R] png()/jpeg()
Message-ID: <A1DAD6685C12D511B20F00034725151380CE4D@sjmemexc3.stjude.org>

Sorry:

         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.1
year     2002
month    11
day      01
language R



Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences

The opinions expressed here are my own and do not necessarily represent
those of St. Jude Children's Research Hospital.


 -----Original Message-----
From: 	ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk] 
Sent:	Friday, January 31, 2003 2:24 PM
To:	Wilkinson, Mark
Cc:	R-help (E-mail)
Subject:	Re: [R] png()/jpeg()

It really would help to know the platform here: Windows and Unix have
separate implementations.  On Windows with R 1.6.2 there is no overlap 
that I can see.

Also the version of R, please.

On Fri, 31 Jan 2003, Wilkinson, Mark wrote:

> When I execute the following code, it works just like I want it to: three
> pages of nine (or fewer) plots.  However, when I execute the code with the
> first and last lines uncommented, I get three pages (files), but the 2nd &
> 3rd pages have overlapping plots.  It's like a new page wasn't created.  
> 
> I'm pretty sure I've either misplaced or left out a crucial call to some
> function, but I'm not sure where. Please help.
> 
> 
> #png(width=937, height=703, pointsize=15)
> for (i in seq(1, 24, 9)) {
>   par(mfrow=c(3, 3))
>   
>   for (gt in i:min((i+8), 24)) {
>     
>     plot(density(rnorm(1000)))
>     
>     for (j in 1:20) { 
>       lines(density(rnorm(1000)), lty=4, col="gray")
>     }
>   }
> }
> #dev.off()

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gregory_r_warnes at groton.pfizer.com  Fri Jan 31 21:53:09 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri Jan 31 21:53:09 2003
Subject: [R] Version 0.8.0 of the gregmisc package is now available
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C539@groexmb02.pfizer.com>

Version 0.8.0 of the gregmisc package is now (or will shortly be) available
on CRAN.  

New in this release:

- Enhanced and bug-fixed 'CrossTable' function (contributed by
  Marc Schwartz)

- Augmented the 'barplot2' function with an 'add' argument to allow for 
  the addition of a barplot to an existing graphic. (contributed by
  Marc Schwartz)

- Added the 'baloonplot' function which creates a visual 2-way table 
  containing circles whose area corresponds to the size of the corresponding

  measurement. 
 
- Renamed 'contrast.lm' to 'fit.contrast'.  This new name is more
  descriptive and makes it easier to create and use methods for other
  classes, eg lme.

- New contrast.lm function which generates a 'depreciated' warning and
  calls fit.contrast.

- Enabled fit.contrast for lme object now that Doug Bates has provided
  the necessary support for contrasts in the nlme package. (Thanks Doug!)
  Requires the newly released nlme 3.1-37.

- 'make.contrasts' has been augmented to check for too many submitted 
   contrast rows

- Updated wapply.R to allow specification of evaluation points when
  method is 'width' or 'range' using the 'pts' argument.

- Updated wapply.Rd to add 'pts' argument

- Fixed typos, spelling errors, grammatical errors and lack of clarity
  in various help pages.

Description of the package:

Package: gregmisc
Description: Misc Functions written/maintained by Gregory R. Warnes
Title: Greg's Miscellaneous Functions
Version: 0.8.0
Date: 2003/01/30
Maintainer: Gregory R. Warnes <Gregory_R_Warnes at groton.pfizer.com>
Author: Gregory R. Warnes.  Includes code provided by Ben Bolker,
        Bendix Carstensen, Don MacQueen, William Venables, Marc
        Schwartz, Ben Bolker, Ian Wilson, and Kjetil Halvorsen
License: GPL (version 2 or later)
Depends: R (>= 1.6.0), MASS, nlme (>= 3.1-37)
Built: R 1.6.1; sparc-sun-solaris2.8; Thu Jan 30 17:13:52 EST 2003

Index:

CrossTable              Cross Tabulation with Tests for Factor
                        Independence
aggregate.table         Create 2-Way Table of Summary Statistics
balloonplot             Plot a graphical matrix where each cell
                        contains a dot whose size reflects the relative
                        magnitude of the corresponding component.
bandplot                Plot x-y Points with Locally Smoothed Mean and
                        Standard Deviation
barplot2                Enhanced Bar Plots
boxplot.n               Produce a Boxplot Annotated with the Number of
                        Observations
ci                      Compute Confidence Intervals
combinations            Enumerate the Combinations or Permutations of
                        the Elements of a Vector
combine                 Combine R Objects With a Column Labeling the
                        Source
contrast.lm             Compute and test arbitrary contrasts for
                        regression objects (Depreciated, use
                        'fit.contrasts' instead.)
rdirichlet              Functions for the Dirichlet Distribution
estimable               Compute and test estimable linear functions of
                        the fitted coefficients (including contrasts)
                        of regression objects
factorial               Compute factorial function
fast.prcomp             Efficient computation of principal components
                        and singular value decompositions.
fit.contrast            Compute and test arbitrary contrasts for
                        regression objects
glh.test                Test a General Linear Hypothesis for a
                        Regression Model 
hist2d                  Compute and Plot a 2-Dimensional Histogram 
interleave              Interleave Rows of Data Frames or Matrices 
lowess                  Scatter Plot Smoothing
make.contrasts          Construct a User-Specified Contrast Matrix
nobs                    Compute the Number of Non-missing Observations 
permute                 Randomly Permute the Elements of a Vector
plotCI                  Plot Error Bars
plotmeans               Plot Group Means and Confidence Intervals
qqnorm.aov              Makes a half or full normal plot for the
                        effects from an aov model 
quantcut                Create a Factor Variable Using the Quantiles of
                        a Continuous Variable
rename.vars             Rename variables in a dataframe 
reorder                 Reorder the Levels of a Factor
running                 Apply a Function Over Adjacent Subsets of a
                        Vector
space                   Space points in an x-y plot so they don't
                        overlap.
undocumented            Undocumented functions
wapply                  Compute the Value of a Function Over a Local
                        Region Of An X-Y Plot




LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From rpeng at stat.ucla.edu  Fri Jan 31 22:17:03 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri Jan 31 22:17:03 2003
Subject: [R] Problems with boot package (empinf returns NA)
In-Reply-To: <1044036826.3285.8.camel@gandalf>
Message-ID: <Pine.GSO.4.10.10301311309350.3652-100000@quetelet.stat.ucla.edu>

How many bootstrap resamples did you use in your original call to `boot'?
I sometimes get this error when the number of resamples is small.  Try
increasing the value for the `R' parameter in `boot' and rerun the bca.ci
function.  For example,

> set.seed(100)
> f <- function(x, i) median(x[i])
> bca.ci(boot(x, f, R = 10))
Error in if (!all(rk > 1 & rk < R)) warning("Extreme Order Statistics used
as Endpoints") : 
        missing value where TRUE/FALSE needed

But the following works,

> set.seed(100)
> bca.ci(boot(x, f, R = 1000))
     conf                                   
[1,] 0.95 20.15 970.16 -0.3172107 0.06934598


-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On 31 Jan 2003, Ernesto Jardim wrote:

> Hi
> 
> I'm using boot package for some analysis on linear regression
> coeficients. My problem is that I can not compute bca intervals, I get
> an error message
> 
> > bca.ci(blm8901,index=1)
> Error in if (!all(rk > 1 & rk < R)) warning("Extreme Order Statistics
> used as Endpoints") : 
>         missing value where logical needed
> 
> The problem is the empinf.reg function that is returning Na when
> performing a glm regression, statement
> 
> beta <- coefficients(glm(t ~ X))[-1]
>   
> I don't see anything strange in t or X, but I'm missing something for
> sure. 
> 
> Can someone give me an hint on this ?
> 
> Thanks
> 
> EJ
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From guti200236 at hotmail.com  Fri Jan 31 22:22:05 2003
From: guti200236 at hotmail.com (Gregorio Gutierrez)
Date: Fri Jan 31 22:22:05 2003
Subject: [R] Lyapunov - time series
Message-ID: <F871U8AVIBsOPd8sIg100001e53@hotmail.com>

Hi,
I wan?t to calculate the Lyapunov exponents of several time series (16 years 
of weekly observations each with a strong seasonal component).
I?ve got a reference that compares three methods: Feedforward Neural 
Networks, Thin-Plate Splines and Response Surface (Ellner & Turchin 1995, 
American Naturalist 145(3),343-375).
How can I estimate Lyapunov exponents (global and local) in R by any or all 
of this techniques?
Thanks for any advice,
Gregorio Fernandez



From mkocherg at students.uiuc.edu  Fri Jan 31 22:43:02 2003
From: mkocherg at students.uiuc.edu (Maria N Kocherginsky)
Date: Fri Jan 31 22:43:02 2003
Subject: [R] Testing ``<=" in R
Message-ID: <3E5D0D36@webmail.uiuc.edu>

Hello,

I've encountered the following:

> n_500
> tau_.95
> (n*(1-tau))
[1] 25
> (n*(1-tau))<=25
[1] FALSE
> (n*(1-tau))==25
[1] FALSE

I'm using UNIX R Version 1.4.0, and also tested in out in Windows 1.6.0. Is 
this a bug?

Masha



From tlumley at u.washington.edu  Fri Jan 31 22:52:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri Jan 31 22:52:03 2003
Subject: [R] Testing ``<=" in R
In-Reply-To: <3E5D0D36@webmail.uiuc.edu>
Message-ID: <Pine.A41.4.44.0301311345460.247920-100000@homer07.u.washington.edu>

On Fri, 31 Jan 2003, Maria N Kocherginsky wrote:

> Hello,
>
> I've encountered the following:
>
> > n_500
> > tau_.95
> > (n*(1-tau))
> [1] 25
> > (n*(1-tau))<=25
> [1] FALSE
> > (n*(1-tau))==25
> [1] FALSE
>
> I'm using UNIX R Version 1.4.0, and also tested in out in Windows 1.6.0. Is
> this a bug?
>

No.

You can't get exact floating point on a computer.
> n <- 500
> tau <- 0.95
> n*(1-tau)-25
[1] 2.1316282072803006e-14

Floating point is only accurate to about 15 decimal digits (53 binary
digits). There are only a few circumstances where it makes sense to ask if
two floating point numbers are equal.

If you care about getting n*(1-tau)==25 then either
1/ you know the numbers are integers, in which case you can round them
2/ you care about the difference between 25 and 25.00000000000002, in
which case you are in trouble


	-thomas



From p.dalgaard at biostat.ku.dk  Fri Jan 31 22:56:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Jan 31 22:56:03 2003
Subject: [R] Testing ``<=" in R
In-Reply-To: <3E5D0D36@webmail.uiuc.edu>
References: <3E5D0D36@webmail.uiuc.edu>
Message-ID: <x2znphasuv.fsf@biostat.ku.dk>

Maria N Kocherginsky <mkocherg at students.uiuc.edu> writes:

> Hello,
> 
> I've encountered the following:
> 
> > n_500
> > tau_.95
> > (n*(1-tau))
> [1] 25
> > (n*(1-tau))<=25
> [1] FALSE
> > (n*(1-tau))==25
> [1] FALSE
> 
> I'm using UNIX R Version 1.4.0, and also tested in out in Windows 1.6.0. Is 
> this a bug?

No. Can 1/20 be represented exactly as a binary number?

>500*(1-tau)-25
[1] 2.131628e-14


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From vograno at arbitrade.com  Fri Jan 31 23:15:05 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Fri Jan 31 23:15:05 2003
Subject: [R] find max of implicit function OR inversion of 2D mappings.
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DCD0@jupiter.arbitrade.com>

Dear R-Users,

I am looking for a help to deal with the following computational problem:

I have a mapping f(x, y) -> (u, v) of [0,1]*[0,1] -> R^2. The mapping is
given by tabulating f(x,y) on a uniform 2D grid and is assumed to be
"interpolatable" in between the grid points (the number of points on each
dimension is rather small, say 5). My ultimate goal is to numerically
maximize v for any given u0, that is find x0(u0), y0(u0) such that v(x0, y0)
= max { v(x,y) : u(x,y)=u0}.

So my broad question is what tools does R have to help out? A narrower
question is whether there is a function that interpolates on a
two-dimensional, but irregular grid? If there is one I could interpolate
fInverse(u,v) -> (x,y) and then restrict u=u0 (does this make sense?).


Another related question deals with efficient tabulation of fInverse(u, v).
In my case it is rather expensive to calculate f(x,y) for any single point
(few hours of computer time). Is there any algorithm that selects next (x,y)
to compute f(x,y) on so that the resulting tabulation of fInverse will be
most efficient? It's probably to much to ask, but just in case.

Thanks,
Vadim

-------------------------------------------------- 
DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]



