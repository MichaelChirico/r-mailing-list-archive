From cys at www.approximity.com  Wed Dec  1 02:25:17 1999
From: cys at www.approximity.com (cys@www.approximity.com)
Date: Tue, 30 Nov 1999 17:25:17 -0800 (PST)
Subject: [R] R and XML -- a near perfect combination?
Message-ID: <Pine.LNX.4.10.9911301721080.3817-100000@www.approximity.com>

Please ignore my ignorance, I'm new to R,
but starting a longish project that will use R a lot.
(a computer scientist learning about stats at the
same time).

Did anybody alreay write a XML parser for R?
XML, as we will have tons of data-interchange with
all sorts of other programs and XML is good for giving
meaning to raw data.

I checked the FAQs and the documentation, but didn't find anything.

Any pointers/comments would be highly appreciated.

Thanks,
	Michelle.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at biostat.washington.edu  Wed Dec  1 00:59:59 1999
From: rossini at biostat.washington.edu (A.J. Rossini)
Date: 30 Nov 1999 15:59:59 -0800
Subject: [R] R and XML -- a near perfect combination?
In-Reply-To: cys@www.approximity.com's message of "Tue, 30 Nov 1999 17:25:17 -0800 (PST)"
References: <Pine.LNX.4.10.9911301721080.3817-100000@www.approximity.com>
Message-ID: <87vh6jwmww.fsf@alpha.cfas.washington.edu>


>>>>> "c" == cys  <cys at www.approximity.com> writes:

    c> Did anybody alreay write a XML parser for R?  XML, as we will
    c> have tons of data-interchange with all sorts of other programs
    c> and XML is good for giving meaning to raw data.

    c> Any pointers/comments would be highly appreciated.

It's a nice format, if you know what you are doing.  The main thought
that I've been having for what you are proposing (data exchange of
datasets) would be to write an converter from your XML format to a
text representation of the corresponding data.frame.  

Reasonably simple, plus you are free to use whatever your choice of
parser language is (C++, Java, Python, whatever).  Plus, you can grow
it (a simple list is easy, adding row/col names isn't too hard,
etc...  Do it using pipes, and you will be fine for Unix and NT.

The only problem with a generic parser is the necessity of doing XML
to XML conversion, since you can't be sure that everyone wants to use
the DTD (or style) that you particularly like.

best,
-tony

-- 
A.J. Rossini			Research Assistant Professor of Biostatistics 
Center for AIDS Research/HMC	Biostatistics/Univ. of Washington
Box 359931			Box 357232
206-731-3647 (3693=fax)		206-543-1044 (3286=fax)
rossini at u.washington.edu	rossini at biostat.washington.edu
http://www.biostat.washington.edu/~rossini/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maj at waikato.ac.nz  Wed Dec  1 01:35:13 1999
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Wed, 01 Dec 1999 13:35:13 +1300
Subject: [R] Installing R on Slackware Linux
Message-ID: <199912010034.NAA13288@gosset.stats.waikato.ac.nz>

I mostly use Windows, but I am slowly learning to use Linux on my second
machine. (It came in handy a couple of weeks ago when I had two files to
sort, each of length about 2 million. Windows sort died after an hour, but
the Linux sorts took 2-3 minutes each.)

Anyway the last time I tried installing R in Linux I found out from a
helpful computer support person that with my distribution (Slackware) it is
better to work from the source files than binaries. In fact he was so
helpful that he did it all for me. This was great, except I didn't learn
how to do it myself. 

Now I'd like to upgrade from 0.65.1 to 0.90.* and add some packages, but
this time I'm all on my own. My linux skills are quite limited, but I have
some books to help me. Is there anything written down somewhere that help
someone compile and install R who has never compiled or installed anything
on Linux before?

Regards,

Murray Jorgensen

Murray Jorgensen,  Department of Statistics,
University of Waikato,  Hamilton,  New Zealand.  [maj at waikato.ac.nz]
______________________________________________________________________
Hey! Look at this! 
The survivors are the ones we had time to get the water to. 
None of the eighteen other variables that we recorded were significant.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bturlach at stats.adelaide.edu.au  Wed Dec  1 02:46:44 1999
From: bturlach at stats.adelaide.edu.au (Berwin Turlach)
Date: Wed, 1 Dec 1999 12:16:44 +1030 (CST)
Subject: [R] model.tables
In-Reply-To: <3.0.1.32.19991201095213.006cf714@anugpo.anu.edu.au>
References: <199911300136.MAA10382@hilbert.maths.utas.edu.au>
	<3.0.1.32.19991201095213.006cf714@anugpo.anu.edu.au>
Message-ID: <14404.32260.515128.721062@amoeba.stats.adelaide.edu.au>

>>>>> "JM" == John Maindonald <john.maindonald at anu.edu.au> writes:

  JM> At 08:02 30/11/99 +0000, Prof Brian D Ripley wrote:
  >> On Tue, 30 Nov 1999, spoon <spoon at hilbert.maths.utas.edu.au> wrote:
  >> 
  >>> Hi,
  >>> Is this a bug or do I just not understand model.tables?
  >>> [...]
  >>> Or am I just completely misinterpreting something basic?
  >> 
  >> Basically, yes. This is an incompletely replicated design, and d and e
  >> occur on different litters.
  >> 
  >> The results are identical to the S-PLUS original. I think you are
  >> probably looking for what dummy.coef gives you.
  >> [...]

  JM> So what is it that model.tables() gives?
Good question, in R (0.65.1) the documentation of model.tables says:

   WARNING:
        The implementation is incomplete, and only the simpler
        cases have been tested thoroughly.

  JM> S-PLUS says they are estimates.  Of what?  These are not the
  JM> marginal means of the fitted values, ignoring other factors.  Do
  JM> they mean anything at all?  The issue of unbalance does not
  JM> arise here.
The documentation in R also states that

    Details:

        For `type = "effects"' give tables of the coefficients
        for each term, optionally with standard errors.

        For `type = "means"' give tables of the mean response
        for each combinations of levels of the factors in a
        term.

Hence, my understanding would be that if `type="means"' is specified
the marginal means of the observations ignoring other factors is
given.  But this doesn't seem to be the case, at least not with an
unbalanced design.  You can use either your dreamed up example or the
data that spoon has posted.

> bdes_data.frame(blk=rep(1:3,rep(2,3)),
+    trt=c(1,2,2,3,3,1), y=c(.4,.6,1,1.4,2,1.2))
> bdes$blk_factor(bdes$blk,labels=LETTERS[1:3])
> bdes$trt_factor(bdes$trt,labels=letters[1:3])
> tapply(bdes$y,bdes$trt,mean)
  a   b   c 
0.8 0.8 1.7 
> bdes.aov_aov(y~blk+trt,data=bdes,projections=T)
> model.tables(bdes.aov,"mean")
Tables of means
Grand mean
    
1.1 

 blk 
  A   B   C 
0.5 1.2 1.6 

 trt 
   a    b    c 
0.85 1.05 1.40

However, model.tables seems to be sensitive regarding the way the
factors have been specified.  If I change the order in the model, I
get the results that I expect.  But note that the results for the
factor blk change. 

> bdes1.aov_aov(y~trt+blk,data=bdes,projections=T)
> model.tables(bdes1.aov,"mean")
Tables of means
Grand mean
    
1.1 

 trt 
  a   b   c 
0.8 0.8 1.7 

 blk 
   A    B    C 
0.80 1.05 1.45 


Note, if I take the data that is on the R help page for model.tables
(which is balanced) then I get the results that I expect:

> N <- c(0,1,0,1,1,1,0,0,0,1,1,0,1,1,0,0,1,0,1,0,1,1,0,0)
> P <- c(1,1,0,0,0,1,0,1,1,1,0,0,0,1,0,1,1,0,0,1,0,1,1,0)
> K <- c(1,0,0,1,0,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,1,0)
> yield <- c(49.5,62.8,46.8,57.0,59.8,58.5,55.5,56.0,62.8,55.8,69.5,
+ 55.0, 62.0,48.8,45.5,44.2,52.0,51.5,49.8,48.8,57.2,59.0,53.2,56.0)
> npk <- data.frame(block=gl(6,4), N=factor(N), P=factor(P),
+ K=factor(K), yield=yield)
> npk.aov <- aov(yield ~ block + N*P*K, npk)
> model.tables(npk.aov, "means")
Tables of means
Grand mean
       
54.875 

 block 
    1     2     3     4     5     6 
54.03 57.45 60.77 50.12 50.52 56.35 

 N 
    0     1 
52.07 57.68 

 P 
    0     1 
55.47 54.28 

 K 
    0     1 
56.87 52.88 

 N:P 
   P
N   0     1    
  0 51.72 52.42
  1 59.22 56.15

 N:K 
   K
N   0     1    
  0 52.88 51.25
  1 60.85 54.52

 P:K 
   K
P   0     1    
  0 57.60 53.33
  1 56.13 52.43
> mean(npk[,"yield"])
[1] 54.875
> tapply(npk$yield,npk$block,"mean")
     1      2      3      4      5      6 
54.025 57.450 60.775 50.125 50.525 56.350 
> tapply(npk$yield,npk$N,"mean")
       0        1 
52.06667 57.68333 
> tapply(npk$yield,npk$P,"mean")
       0        1 
55.46667 54.28333 
> tapply(npk$yield,npk$K,"mean")
       0        1 
56.86667 52.88333 
> tapply(npk$yield,list(npk$N,npk$P),"mean")
         0        1
0 51.71667 52.41667
1 59.21667 56.15000
> tapply(npk$yield,list(npk$N,npk$K),"mean")
         0        1
0 52.88333 51.25000
1 60.85000 54.51667
> tapply(npk$yield,list(npk$P,npk$K),"mean")
         0        1
0 57.60000 53.33333
1 56.13333 52.43333


Cheers,

        Berwin
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From john.maindonald at anu.edu.au  Wed Dec  1 04:21:11 1999
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 1 Dec 1999 14:21:11 +1100 (EST)
Subject: [R] model.tables
Message-ID: <199912010321.OAA11575@leonard.anu.edu.au>

Berwin Turlach wrote -

> > >>>>> "JM" == John Maindonald <john.maindonald at anu.edu.au> writes:
> 
>   JM> At 08:02 30/11/99 +0000, Prof Brian D Ripley wrote:
>   >> On Tue, 30 Nov 1999, spoon <spoon at hilbert.maths.utas.edu.au> wrote:
>   >> 
>   >>> Hi,
>   >>> Is this a bug or do I just not understand model.tables?
>   >>> [...]
>   >>> Or am I just completely misinterpreting something basic?
>   >> 
>   >> Basically, yes. This is an incompletely replicated design, and d and e
>   >> occur on different litters.
>   >> 
>   >> The results are identical to the S-PLUS original. I think you are
>   >> probably looking for what dummy.coef gives you.
>   >> [...]
> 
>   JM> So what is it that model.tables() gives?
> Good question, in R (0.65.1) the documentation of model.tables says:
> 
>    WARNING:
>         The implementation is incomplete, and only the simpler
>         cases have been tested thoroughly.

Simon and I had noted that.  As S-PLUS has no such warning, perhaps
the discussion should be taking place on s-news.

>   JM> S-PLUS says they are estimates.  Of what?  These are not the
>   JM> marginal means of the fitted values, ignoring other factors.  Do
>   JM> they mean anything at all?  The issue of unbalance does not
>   JM> arise here.
> The documentation in R also states that
> 
>     Details:
> 
>         For `type = "effects"' give tables of the coefficients
>         for each term, optionally with standard errors.
> 
>         For `type = "means"' give tables of the mean response
>         for each combinations of levels of the factors in a
>         term.
> 
> Hence, my understanding would be that if `type="means"' is specified
> the marginal means of the observations ignoring other factors is
> given.  But this doesn't seem to be the case, at least not with an
> unbalanced design.  You can use either your dreamed up example or the
> data that spoon has posted.

On the usual definitions of `balance' both in my example and
Simon's example treatments are `balanced" over blocks (or litters).

...

John Maindonald               email : john.maindonald at anu.edu.au        
Statistical Consulting Unit,  phone : (6249)3998        
c/o CMA, SMS,                 fax   : (6249)5549  
John Dedman Mathematical Sciences Building
Australian National University
Canberra ACT 0200
Australia
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Wed Dec  1 11:10:09 1999
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Wed, 1 Dec 1999 10:10:09 +0000 (GMT)
Subject: [R] Installing R on Slackware Linux
In-Reply-To: <199912010034.NAA13288@gosset.stats.waikato.ac.nz>
Message-ID: <Pine.LNX.4.10.9912011007190.4190-100000@localhost.localdomain>

Become root: su -

Put the new *.tgz file the same place as the old one was (something
like /usr/local or /usr/local/src).

Unpack it: tar zxvf Rwhatever.tgz

Then read INSTALL for detailed instructions.

Bill

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hothorn at statistik.uni-dortmund.de  Wed Dec  1 10:34:41 1999
From: hothorn at statistik.uni-dortmund.de (Torsten Hothorn)
Date: Wed, 1 Dec 1999 10:34:41 +0100 (MET)
Subject: [R] Installing R on Slackware Linux
In-Reply-To: <199912010034.NAA13288@gosset.stats.waikato.ac.nz>
Message-ID: <Pine.GSO.4.05.9912011030200.13298-100000@amadeus.statistik.uni-dortmund.de>



On Wed, 1 Dec 1999, Murray Jorgensen wrote:

> I mostly use Windows, but I am slowly learning to use Linux on my second
> machine. (It came in handy a couple of weeks ago when I had two files to
> sort, each of length about 2 million. Windows sort died after an hour, but
> the Linux sorts took 2-3 minutes each.)
> 
> Anyway the last time I tried installing R in Linux I found out from a
> helpful computer support person that with my distribution (Slackware) it is
> better to work from the source files than binaries. In fact he was so
> helpful that he did it all for me. This was great, except I didn't learn
> how to do it myself. 
> 
> Now I'd like to upgrade from 0.65.1 to 0.90.* and add some packages, but
> this time I'm all on my own. My linux skills are quite limited, but I have
> some books to help me. Is there anything written down somewhere that help
> someone compile and install R who has never compiled or installed anything
> on Linux before?

Well,

get R-0.90.0.tgz, copy it to /usr/src  and then type (as root)

$> tar -xzvf R-0.90.0.tgz	# untar the archive
$> cd R-0.90.0			# change to the R dir
$> ./configure			# create your Makefiles
$> make 			# if the output of configure is ok compile
$> make install			# and install the bin's

All those things are well documented in the FAQ and README's as in all GNU
projects ... :-)

Torsten




> 
> Regards,
> 
> Murray Jorgensen
> 
> Murray Jorgensen,  Department of Statistics,
> University of Waikato,  Hamilton,  New Zealand.  [maj at waikato.ac.nz]
> ______________________________________________________________________
> Hey! Look at this! 
> The survivors are the ones we had time to get the water to. 
> None of the eighteen other variables that we recorded were significant.
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.J.Ramalho at bristol.ac.uk  Wed Dec  1 10:33:56 1999
From: J.J.Ramalho at bristol.ac.uk (JJ Dos Santos Ramalho)
Date: Wed, 1 Dec 1999 09:33:56 +0000 (GMT)
Subject: [R] nlmin
Message-ID: <Pine.SOL.3.95q.991201092805.2324B-100000@eis.bris.ac.uk>


I'm a very recent user of R. I have been adapting my Splus programmes
and I found only one (important) problem. There exists no function
"nlmin" in R and its substitute, "nlm", does not work well with my kind
of problems, sometimes no achieving convergence, other tines
"converging" to impossible values. My models are highly nonlinear and
are to be estimated by both GMM and empirical likelihood methods.

Is there any alternative nonlinear optimization command in R? In the
help file it is said that "nlm" is only a preliminary version, is it
expected to replace/improve it soon? Does anyone have any alternative
algorithm?

Thanks for your help,

Joaquim Ramalho
Department of Economics
University of Bristol

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Dec  1 10:59:24 1999
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 1 Dec 1999 10:59:24 +0100 (MET)
Subject: [R] nlmin
In-Reply-To: <Pine.SOL.3.95q.991201092805.2324B-100000@eis.bris.ac.uk> from "JJ Dos Santos Ramalho" at Dec 01, 1999 09:33:56 AM
Message-ID: <199912010959.KAA01810@alpha.luc.ac.be>

> 
> 
> I'm a very recent user of R. I have been adapting my Splus programmes
> and I found only one (important) problem. There exists no function
> "nlmin" in R and its substitute, "nlm", does not work well with my kind
> of problems, sometimes no achieving convergence, other tines
> "converging" to impossible values. My models are highly nonlinear and
> are to be estimated by both GMM and empirical likelihood methods.

I have also been using nlm for the past 4-5 years in R and for another
5-10 years before that as a Fortran program. Most of my problems are
also highly nonlinear and I rarely have had a problem unless the model
is unsuitable for the data. nlm has several arguments that can be
modified to aid in convergence. If you obtain impossible values, then
you appear to have a constrained optimization problem. Often parameter
transformation can fix this (e.g. log for positive values, logit if
between 0 and 1). Constrained optimization is a difficult problem
for which really good algorithms are not available. All of the
numerical analysts that I have spoken to agree that the algorithm in
nlm for unconstrained optimization without supplying analytic
derivatives is about the best available. Note that, as of 0.90, you
can supply the derivatives to nlm, which may also solve your problem
(although my experience is that it makes little difference if the
model is suitable for the data). Jim

> 
> Is there any alternative nonlinear optimization command in R? In the
> help file it is said that "nlm" is only a preliminary version, is it
> expected to replace/improve it soon? Does anyone have any alternative
> algorithm?
> 
> Thanks for your help,
> 
> Joaquim Ramalho
> Department of Economics
> University of Bristol
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec  1 11:16:33 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 1 Dec 1999 10:16:33 +0000 (GMT)
Subject: [R] nlmin
In-Reply-To: <Pine.SOL.3.95q.991201092805.2324B-100000@eis.bris.ac.uk>
Message-ID: <Pine.GSO.4.05.9912011012290.3660-100000@auk.stats>

On Wed, 1 Dec 1999, JJ Dos Santos Ramalho wrote:

> 
> I'm a very recent user of R. I have been adapting my Splus programmes
> and I found only one (important) problem. There exists no function
> "nlmin" in R and its substitute, "nlm", does not work well with my kind
> of problems, sometimes no achieving convergence, other tines
> "converging" to impossible values. My models are highly nonlinear and
> are to be estimated by both GMM and empirical likelihood methods.
> 
> Is there any alternative nonlinear optimization command in R? In the
> help file it is said that "nlm" is only a preliminary version, is it
> expected to replace/improve it soon? Does anyone have any alternative
> algorithm?

Yes, yes. Note, though that nlm was improved for 0.90.0 and can now
make use of gradient information.  Does your application have known
derivatives? (I know nlmin does not use them.)  The aim is to
allow alternative methods within the nlm function fairly soon (a couple
of months).  One issue to allow the methods to be used recursively,
which means basing them on C code not Fortran code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From partha_bagchi at hgsi.com  Wed Dec  1 14:11:08 1999
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Wed, 1 Dec 1999 08:11:08 -0500
Subject: Summary: [R] Wanted: online Introduction to R
Message-ID: <OFE824D2E3.27864B34-ON8525683A.004849B2@hgsi.com>


One interesting page to consider would be John Pezzullo's interactive Stats
page:
http://members.aol.com/johnp71/javastat.html



                                                                                                              
                    Clive Jenkins                                                                             
                    <clive.jenkins at clara        To:     Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>         
                    .net>                       cc:     r-help at stat.math.ethz.ch                              
                    Sent by:                    Subject:     Re: Summary: [R] Wanted: online Introduction to  
                    owner-r-help at stat.ma        R                                                             
                    th.ethz.ch                                                                                
                                                                                                              
                                                                                                              
                    11/24/99 03:53 PM                                                                         
                                                                                                              
                                                                                                              




Peter Dalgaard BSA wrote:
>
> Clive Jenkins <clive.jenkins at clara.net> writes:
>
> > An excellent on-line book for the more advanced reader, especially
> > chapters 14 and 15 that deal with Statistics and Data Modeling:
> > "Numerical Recipes in C: the Art of Scientific Computing" (ISBN
> > 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. A
> > Fortran version is also available, and both exist in PostScript and
PDF.
> > http://www.ulib.org/webRoot/Books/Numerical_Recipes/
>
> Um, not to put too fine a point on it: That is not a book I'd
> recommend, and particularly not for the statistics sections. It's a
> reasonable introductory text to numerical analysis subjects, but
> according to people who really know the stuff, it is not to be trusted
> in the details (there's an online reference to the criticism, but I
> can't remember it offhand), and their software licencing is.... (don't
> get me started!)
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

OK, I stand corrected. What I wrote was not from the point of view of a
reviewer who has thoroughly researched the field. I am no specialist in
statistics and write with no authority. However, out of the limited
amount of material that I did find on the web, this book did provide me
with a lot of useful formulae for various distributions, t-tests,
F-tests, chi^2, regression ... and all the things that are probably
taken
for granted by those whose daily lives are dedicated to Statistics.

If any of you know of better on-line resources, then please spare a
minute and enlighten us.

Clive Jenkins.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetil.kjernsmo at astro.uio.no  Wed Dec  1 15:17:14 1999
From: kjetil.kjernsmo at astro.uio.no (Kjetil Kjernsmo)
Date: Wed, 1 Dec 1999 15:17:14 +0100 (MET)
Subject: [R] Applying a function of several variables to data 
Message-ID: <Pine.OSF.4.05.9912011501070.11013-100000@rasalhague>

Dear all,

After looking at several packages I decided I would use R for my thesis
work (we've even got a site license for S-plus), so I'm learning.

I have run into a problem, and nobody on the house has a solution, so I'm
wondering if anybody out there can help. 
I've got two functions of four variables, one outputs a scalar, the other
an array, and I want to be able to give an array as a parameter for any
(or none) of the variables, and get a multidimensional array of
corresponding dimensions out, with all combinations. In the case of two
variables it is easy to do with outer(), and I have looked if apply() 
could do this, but found only examples where there is a function of one
variable. Obviously, I could do it with a for-loop at some level, but
after reading so many bad things about for-loops, it itches in my
estheticle thinking about it... :-) Is there a nicer way to do this?

Best,

Kjetil
-- 
Kjetil Kjernsmo
Graduate astronomy-student                    Problems worthy of attack
University of Oslo, Norway            Prove their worth by hitting back
E-mail: kjetikj at astro.uio.no                                - Piet Hein
Homepage <URL:http://www.astro.uio.no/~kjetikj/>
Webmaster at skepsis.no 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From duncan at rice.research.bell-labs.com  Wed Dec  1 15:55:41 1999
From: duncan at rice.research.bell-labs.com (Duncan Temple Lang)
Date: Wed, 1 Dec 1999 09:55:41 -0500
Subject: [R] R and XML -- a near perfect combination?
Message-ID: <199912011456.PAA22973@stat.math.ethz.ch>


The great thing about data exchange is that at least two systems have
to be involved in the exchange (for it to be non-trivial!)  John
Chambers, myself and others have been discussing XML _joint_
integration into several projects - Omegahat, R and S.  

The interesting thing from the general perspective (rather than
a particular project and pair of interacting applications)
is in defining some DTDs that people are comfortable using.
This applies not only to data frames but also model specification,
results, etc.

>From the implementation perspective of reading XML, Omegahat has it
automatically. It would be nice to have the one shared by both R and S
and this was on my list of things to do.  Irrespective of the choice
of C/C++ parsing system, one approach I was thinking of in R is to use
a closure that is associated with a DTD. Thinking out aloud, the idea
is to have functions in the closure that correspond to the different
elements in the DTD.  As the parser discovers each element instance,
it calls the associated function in the closure (or a default one)
with the attribute lists and potentially the "identifier" for the
parent node in the resulting tree (although R and S aren't exactly
designed for trees).

(If this doesn't make any sense, it could be attributed to too little
sleep!)

D.



> Cc: r-help at stat.math.ethz.ch
> References: <Pine.LNX.4.10.9911301721080.3817-100000 at www.approximity.com>
> From: rossini at biostat.washington.edu (A.J. Rossini)
> Date: 30 Nov 1999 15:59:59 -0800
> Lines: 33
> Sender: owner-r-help at stat.math.ethz.ch
> Precedence: bulk
> 
> 
> >>>>> "c" == cys  <cys at www.approximity.com> writes:
> 
>     c> Did anybody alreay write a XML parser for R?  XML, as we will
>     c> have tons of data-interchange with all sorts of other programs
>     c> and XML is good for giving meaning to raw data.
> 
>     c> Any pointers/comments would be highly appreciated.
> 
> It's a nice format, if you know what you are doing.  The main thought
> that I've been having for what you are proposing (data exchange of
> datasets) would be to write an converter from your XML format to a
> text representation of the corresponding data.frame.  
> 
> Reasonably simple, plus you are free to use whatever your choice of
> parser language is (C++, Java, Python, whatever).  Plus, you can grow
> it (a simple list is easy, adding row/col names isn't too hard,
> etc...  Do it using pipes, and you will be fine for Unix and NT.
> 
> The only problem with a generic parser is the necessity of doing XML
> to XML conversion, since you can't be sure that everyone wants to use
> the DTD (or style) that you particularly like.
> 
> best,
> -tony
> 
> -- 
> A.J. Rossini			Research Assistant Professor of Biostatistics 
> Center for AIDS Research/HMC	Biostatistics/Univ. of Washington
> Box 359931			Box 357232
> 206-731-3647 (3693=fax)		206-543-1044 (3286=fax)
> rossini at u.washington.edu	rossini at biostat.washington.edu
> http://www.biostat.washington.edu/~rossini/
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan

      "Languages shape the way we think, and determine what 
       we can think about."        
                                      Benjamin Whorf
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mathieu.ros at free.fr  Wed Dec  1 17:09:17 1999
From: mathieu.ros at free.fr (mathieu)
Date: Wed, 01 Dec 1999 17:09:17 +0100
Subject: [R] problem installing R 0.90
Message-ID: <3845482D.A6C2615A@free.fr>

hello all,
when running ./configure in my [new] R-0.90 directory, the process stop
at the following step :

(...)
checking whether g77 and gcc agree on int and double...

can anybody tell me what's the problem (I believe it is due to g77 but
what can I do?)
thanks,
    Mathieu

I'm using Redhat 6.0 on a  Intel P90

--
----------------------------------------------------------------------
 Mathieu Ros - 13 rue b?vi?re - 38000 GRENOBLE - 04 76 491 370
 http://www.multimania.com/mathieuros/index2.html
 DESS ing?nierie math?matique (biostatistiques)
 Universite Joseph Fourier, Grenoble
----------------------------------------------------------------------
La science d?tient la v?rit?, ne vous laissez pas avoir par les faits.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/19991201/64f5c16b/attachment.html

From maechler at stat.math.ethz.ch  Wed Dec  1 17:57:25 1999
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 1 Dec 1999 17:57:25 +0100 (MET)
Subject: [R] graphics
In-Reply-To: <x2aenvpp1x.fsf@blueberry.kubism.ku.dk>
References: <199911300756.IAA23343@alpha.luc.ac.be>
	<x2aenvpp1x.fsf@blueberry.kubism.ku.dk>
Message-ID: <14405.21365.551653.52140@gargle.gargle.HOWL>

 >>>>> Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> adds:

    PD> Jim Lindsey <jlindsey at alpha.luc.ac.be> writes:
    >> I have been receiving complaints that my libraries no longer give
    >> reasonable graphics with R0.90. I have been replying that I have not
    >> changed anything. Among my travels (presently in Umea), I have
    >> finally had a chance to take a look. The best way to describe the
    >> current default graphics is HORRIBLY UGLY. The R core member who
    >> made those changes should buy glasses to see the screen better
    >> instead of imposing his near sightedness on the rest of us. The
    >> worst is that the most important options that have been modified are
    >> RO so we can do nothing. As PS graphics are also knackered, we
    >> currently have no way of viewing a reasonable graph produced by R.

    PD> Well, the font sizes are as I have had them for ages: 12pt on a
    PD> 100dpi assumed resolution. If that's too large, fine, complain and
    PD> if you gain a sufficient following we might reduce it to 10pt. The
    PD> old code would give you 100dpi or 75dpi fonts depending on which
    PD> one came first on your font path and was available at the desired
    PD> size, leading to general madness. If it bothers you enough, use
    PD> fix(X11) and change the default for the pointsize argument.

After a quite a bit discussion (incl. some own thought), I tend to vote
with Jim Lindsey: 
We *should* reduce the default font size:  Because the font size is 
relatively large, the margins (measured in characters via "mar") become
large as well, and (as Jim pointed out to some of us)
now use more than 50% of the device surface.

Fontsize = 10 (pt) looks more reasonable, to me, too.
(However, I propose to make it an option, see below).

    PD> The postscript is truly bug-ridden, but the latest snapshot should
    PD> be much better.

    >> Is there any way to set the default par options, say in Rprofile,
    >> without having a graphics window pop up at startup?

    PD> Nope, but we should probably have something like ps.options there,
    PD> the par() effect is also messing up example(): the code cannot set
    PD> ask=TRUE so multiple graphics in an example just fly by, unless the
    PD> user sets the parameter.
yes, definitely a reasonable feature request! -- see below

BUT, for a first "quick fix" : Why not change X11's argument
     pointsize = 12
to
     pointsize = .Options$X11pointsize
(we already have X11colortype !).

Now back to the feature request:

Do we want  par.defaults() for this?
It would have the same arguments as par()  plus additional
   device = .Options$device
with further possibility   
   device = "all"
i.e., by default,  par.defaults()  would set things only for the default
device, but there'd be a possibility to set these for all devices.

Note that
-  This would lead to considerable side effects.
   [Starting a device and setting par()s would not be portable,
    for complete portability you'd have to first set (or reset) the
    par.defaults()]
-  for  device = "postscript", 
   we could allow further arguments as those of ps.options() and postscript()
   and e.g. for device = "X11" ( = default on non-gnome Unix),
   one should allow arguments of X11/x11() such as pointsize, colortype, ...

-----

When feature requesting: What I have wanted more than once is an
     par(reset = TRUE)
which would set all the par()s back to how they were when the device was
opened.   

     par.defaults(reset = TRUE)

would analogously remove all `site/user specific' par defaults
(effect: as if  par.defaults() was never set).
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Dec  1 18:39:54 1999
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 1 Dec 1999 18:39:54 +0100 (MET)
Subject: [R] graphics
In-Reply-To: <14405.21365.551653.52140@gargle.gargle.HOWL> from "Martin Maechler" at Dec 01, 1999 05:57:25 PM
Message-ID: <199912011739.SAA03777@alpha.luc.ac.be>

> Do we want  par.defaults() for this?
> It would have the same arguments as par()  plus additional
>    device = .Options$device
> with further possibility   
>    device = "all"
> i.e., by default,  par.defaults()  would set things only for the default
> device, but there'd be a possibility to set these for all devices.
> 
> Note that
> -  This would lead to considerable side effects.
>    [Starting a device and setting par()s would not be portable,
>     for complete portability you'd have to first set (or reset) the
>     par.defaults()]
> -  for  device = "postscript", 
>    we could allow further arguments as those of ps.options() and postscript()
>    and e.g. for device = "X11" ( = default on non-gnome Unix),
>    one should allow arguments of X11/x11() such as pointsize, colortype, ...

Is there a strong reason why a call to par with no device active must
open a window? If this 'feature' can easily be removed, then I would
be satisfied as I could then put my default par settings in Rprofile
without a window opening at startup. Of course, the above is a far
better idea but perhaps more difficult to implement.

(By the way, for those on the list who have not had access to all the
discussion about this in the last couple of days, Peter has pointed
out to me that X11 - note capital X - can be redefined in Rprofile so
that pointsize has any desired size. This is now working very well for
me.)

> 
> -----
> 
> When feature requesting: What I have wanted more than once is an
>      par(reset = TRUE)
> which would set all the par()s back to how they were when the device was
> opened.   
> 
>      par.defaults(reset = TRUE)
> 
> would analogously remove all `site/user specific' par defaults
> (effect: as if  par.defaults() was never set).

I'll certainly vote for those.
  Jim
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec  1 19:28:24 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 01 Dec 1999 19:28:24 +0100
Subject: [R] graphics
In-Reply-To: Martin Maechler's message of "Wed, 1 Dec 1999 17:57:25 +0100 (MET)"
References: <199911300756.IAA23343@alpha.luc.ac.be> <x2aenvpp1x.fsf@blueberry.kubism.ku.dk> <14405.21365.551653.52140@gargle.gargle.HOWL>
Message-ID: <x2puwqwm5z.fsf@blueberry.kubism.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> BUT, for a first "quick fix" : Why not change X11's argument
>      pointsize = 12
> to
>      pointsize = .Options$X11pointsize
> (we already have X11colortype !).

Which is a mess! We also have

.PostScript.Options$pointsize

So wouldn't it be more obvious to use

.X11.Options$pointsize

(and set it with X11.options(pointsize=12))?

If we go to 10pt default, we also need to discuss the multiframe
scaling issue. The current rules are that if there is two rows and/or
columns, reduce font size to 80%, if there are three or more reduce to
50% and a 5pt font @100dpi is a tad small. Note that this rule is
*device independent*, so one would have to check that it still looks
reasonable on postscript and windows. I think it works out OK if one sets the
rule to 60% giving a 6pt font, but I'd like someone elses eyes on
that. 

> Now back to the feature request:
> 
> Do we want  par.defaults() for this?
> It would have the same arguments as par()  plus additional
>    device = .Options$device
> with further possibility   
>    device = "all"
> i.e., by default,  par.defaults()  would set things only for the default
> device, but there'd be a possibility to set these for all devices.
> 
> Note that
> -  This would lead to considerable side effects.
>    [Starting a device and setting par()s would not be portable,
>     for complete portability you'd have to first set (or reset) the
>     par.defaults()]
> -  for  device = "postscript", 
>    we could allow further arguments as those of ps.options() and postscript()
>    and e.g. for device = "X11" ( = default on non-gnome Unix),
>    one should allow arguments of X11/x11() such as pointsize, colortype, ...
> 
> -----
> 
> When feature requesting: What I have wanted more than once is an
>      par(reset = TRUE)
> which would set all the par()s back to how they were when the device was
> opened.   
> 
>      par.defaults(reset = TRUE)
> 
> would analogously remove all `site/user specific' par defaults
> (effect: as if  par.defaults() was never set).

Hmm. I'm not so sure we're really gaining much from an elaborate
par.default() function. If one desires, one could do it via the
startup function, simply by a call to par based on the options).

For instance, try changing X11 to

X11<-function (display = "", width = 7, height = 7, pointsize = 12, 
    gamma = 1, colortype = options()$X11colortype, maxcubesize = 256) 
{
    .Internal(X11(display, width, height, pointsize, gamma, colortype, 
    maxcubesize))
    par(ask=T)
}

and then

example(barplot)
dev.off()
par(ask=F)
example(barplot)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec  1 19:41:07 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 01 Dec 1999 19:41:07 +0100
Subject: [R] graphics
In-Reply-To: Jim Lindsey's message of "Wed, 1 Dec 1999 18:39:54 +0100 (MET)"
References: <199912011739.SAA03777@alpha.luc.ac.be>
Message-ID: <x2n1ruwlks.fsf@blueberry.kubism.ku.dk>

Jim Lindsey <jlindsey at alpha.luc.ac.be> writes:

> Is there a strong reason why a call to par with no device active must
> open a window? If this 'feature' can easily be removed, then I would
> be satisfied as I could then put my default par settings in Rprofile
> without a window opening at startup. Of course, the above is a far
> better idea but perhaps more difficult to implement.

I'm sure it can be worked around, but the issue is that the par()
settings must go to a device, so if none is open, we open the default
one, by the default method, which opens the window. The obvious fix,
not to open the window until something is actually drawn would have
the consequence of making a direct X11() call an apparent no-op... And
some of the things that par() can do involves requests to the window
system about the plotting window, I suspect.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lyndon at stat.auckland.ac.nz  Wed Dec  1 20:36:27 1999
From: lyndon at stat.auckland.ac.nz (Lyndon Drake)
Date: Thu, 2 Dec 1999 08:36:27 +1300
Subject: [R] R and XML -- a near perfect combination?
In-Reply-To: <Pine.LNX.4.10.9911301721080.3817-100000@www.approximity.com>; from cys@www.approximity.com on Tue, Nov 30, 1999 at 05:25:17PM -0800
References: <Pine.LNX.4.10.9911301721080.3817-100000@www.approximity.com>
Message-ID: <19991202083627.D4051@stat1.stat.auckland.ac.nz>

On Tue, Nov 30, 1999 at 05:25:17PM -0800, cys at www.approximity.com wrote:
> Did anybody alreay write a XML parser for R?
> XML, as we will have tons of data-interchange with
> all sorts of other programs and XML is good for giving
> meaning to raw data.

A good C XML library is libxml (wierd name, I know :-), at
http://rpmfind.net/veillard/XML/.  It's the one used in GNOME, but it is
supposed to be portable.  I don't know how well it would work on Win32,
but it would be worth looking at.  It is licensed under the LGPL.

-- 
Lyndon Drake                       | Desktop:      http://www.gnome.org
isenguard                          | Mail client:  http://www.mutt.org
ICQ#: 12558803                     | Editor:       http://www.vim.org
http://stat.auckland.ac.nz/~lyndon | OS:           http://www.linux.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ihaka at stat.auckland.ac.nz  Wed Dec  1 20:47:36 1999
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Thu, 2 Dec 1999 08:47:36 +1300
Subject: [R] graphics
In-Reply-To: <14405.21365.551653.52140@gargle.gargle.HOWL>; from Martin Maechler on Wed, Dec 01, 1999 at 05:57:25PM +0100
References: <199911300756.IAA23343@alpha.luc.ac.be> <x2aenvpp1x.fsf@blueberry.kubism.ku.dk> <14405.21365.551653.52140@gargle.gargle.HOWL>
Message-ID: <19991202084736.A2925@stat1.stat.auckland.ac.nz>

I think I mentioned this a while ago ...

The problem I have with the new X11 driver is that it appears to ignore
the actual DPI (dots per inch) of the X server and use 100 DPI.  My machine
is most definitely 75 DPI (I explicitly set it when I start the server).

The fonts I get from R are much too large and do not agree with those
displayed in xfontsel (which I think shows the official story).

	Ross
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From john.maindonald at anu.edu.au  Wed Dec  1 22:51:47 1999
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 02 Dec 1999 08:51:47 +1100
Subject: [R] Plot Character Sizes in rw-0.90.0
Message-ID: <3.0.1.32.19991202085147.006d09fc@anugpo.anu.edu.au>

I have two supposedly identical installations, one under Windows 95,
and the other (at home) under Windows 98.  The puzzle is that under 
my Windows 98 installation, symbols plotted by default or with pch
come out huge, at about 2.2 times the height of the axis labels.
Setting cex=0.5 seems about what is needed to fix the heights.

On the Windows 95 installation, the symbols come out just a little
smaller than the height of the axis labels.

Unless someone has an immediate explanation, maybe I need to send a
bug report from my home machine?

A further point is that, contrary to the documentation of par(),
the
setting of mkh seems to have no effect on the height of symbols 
plotted with pch, e. g.
plot(1:4,1:4,pch=1,mkh=0.2)


John Maindonald               email : john.maindonald at anu.edu.au        
Statistical Consulting Unit,  phone : (6249)3998        
c/o CMA, SMS,                 fax   : (6249)5549  
John Dedman Mathematical Sciences Building
Australian National University
Canberra ACT 0200
Australia

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rcarel at netgenics.com  Wed Dec  1 23:01:33 1999
From: rcarel at netgenics.com (Carel, Roland)
Date: Wed, 1 Dec 1999 17:01:33 -0500 
Subject: [R] R and XML -- a near perfect combination?
Message-ID: <DB52A7625347D211A1D70060B06AB1E2010316A0@exchgcle.dev.netgenics.com>

>On Tue, Nov 30, 1999 at 05:25:17PM -0800, cys at www.approximity.com wrote:
>> Did anybody alreay write a XML parser for R?
>> XML, as we will have tons of data-interchange with
>> all sorts of other programs and XML is good for giving
>> meaning to raw data.

>A good C XML library is libxml (wierd name, I know :-), at
>http://rpmfind.net/veillard/XML/.  It's the one used in GNOME, but it is
>supposed to be portable.  I don't know how well it would work on Win32,
>but it would be worth looking at.  It is licensed under the LGPL.

Why not use the java parser from the IBM Alpha Works:
http://www.alphaworks.ibm.com/tech/dynamicxmlforjava
It should be easily portable to just about any platform.

-Roland Carel
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at biostat.washington.edu  Wed Dec  1 23:18:24 1999
From: rossini at biostat.washington.edu (A.J. Rossini)
Date: 01 Dec 1999 14:18:24 -0800
Subject: [R] R and XML -- a near perfect combination?
In-Reply-To: "Carel, Roland"'s message of "Wed, 1 Dec 1999 17:01:33 -0500"
References: <DB52A7625347D211A1D70060B06AB1E2010316A0@exchgcle.dev.netgenics.com>
Message-ID: <87ogcatidr.fsf@alpha.cfas.washington.edu>


>>>>> "CR" == Carel, Roland <rcarel at netgenics.com> writes:

    >> A good C XML library is libxml (wierd name, I know :-), at
    >> http://rpmfind.net/veillard/XML/.  It's the one used in GNOME,
    >> but it is supposed to be portable.  I don't know how well it
    >> would work on Win32, but it would be worth looking at.  It is
    >> licensed under the LGPL.

    CR> Why not use the java parser from the IBM Alpha Works:
    CR> http://www.alphaworks.ibm.com/tech/dynamicxmlforjava It should
    CR> be easily portable to just about any platform.

Would be fine with Omegahat, but probably not R.  Actually, maybe you
could get to it via RJava, but it would probably require a bit more
thought.  There might be licensing issues wrt to R's GPL, though,
depending which IBM license it's under...

best,
-tony

-- 
A.J. Rossini			Research Assistant Professor of Biostatistics 
Center for AIDS Research/HMC	Biostatistics/Univ. of Washington
Box 359931			Box 357232
206-731-3647 (3693=fax)		206-543-1044 (3286=fax)
rossini at u.washington.edu	rossini at biostat.washington.edu
http://www.biostat.washington.edu/~rossini/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec  1 23:39:18 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 01 Dec 1999 23:39:18 +0100
Subject: [R] Plot Character Sizes in rw-0.90.0
In-Reply-To: John Maindonald's message of "Thu, 02 Dec 1999 08:51:47 +1100"
References: <3.0.1.32.19991202085147.006d09fc@anugpo.anu.edu.au>
Message-ID: <x2u2m2mgkp.fsf@blueberry.kubism.ku.dk>

John Maindonald <john.maindonald at anu.edu.au> writes:

> I have two supposedly identical installations, one under Windows 95,
> and the other (at home) under Windows 98.  The puzzle is that under 
> my Windows 98 installation, symbols plotted by default or with pch
> come out huge, at about 2.2 times the height of the axis labels.
> Setting cex=0.5 seems about what is needed to fix the heights.
> 
> On the Windows 95 installation, the symbols come out just a little
> smaller than the height of the axis labels.

Peculiar. They're supposed to be roughly the width of a "0" in the
base font. The Postscript driver had a bug in the size calculations,
in that it subtracted 18 pixels from the radius, but that wouldn't
seem to be your problem if setting cex fixes things up.

What does par("cra") and par("csi") say on your respective systems?
(par("cra")[2]/par("csi") should be the dpi of your device)

> Unless someone has an immediate explanation, maybe I need to send a
> bug report from my home machine?
> 
> A further point is that, contrary to the documentation of par(),
> the
> setting of mkh seems to have no effect on the height of symbols 
> plotted with pch, e. g.
> plot(1:4,1:4,pch=1,mkh=0.2)

Yes, I believe we already have a bug report to that effect.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Dec  1 23:46:14 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 1 Dec 1999 22:46:14 +0000 (GMT)
Subject: [R] R and XML -- a near perfect combination?
In-Reply-To: <87ogcatidr.fsf@alpha.cfas.washington.edu>
Message-ID: <Pine.GSO.4.05.9912012240240.26237-100000@auk.stats>

On 1 Dec 1999, A.J. Rossini wrote:

> 
> >>>>> "CR" == Carel, Roland <rcarel at netgenics.com> writes:
> 
>     >> A good C XML library is libxml (wierd name, I know :-), at
>     >> http://rpmfind.net/veillard/XML/.  It's the one used in GNOME,
>     >> but it is supposed to be portable.  I don't know how well it
>     >> would work on Win32, but it would be worth looking at.  It is
>     >> licensed under the LGPL.
> 
>     CR> Why not use the java parser from the IBM Alpha Works:
>     CR> http://www.alphaworks.ibm.com/tech/dynamicxmlforjava It should
>     CR> be easily portable to just about any platform.
> 
> Would be fine with Omegahat, but probably not R.  Actually, maybe you
> could get to it via RJava, but it would probably require a bit more
> thought.  There might be licensing issues wrt to R's GPL, though,
> depending which IBM license it's under...

Many users of R do not run Java; for example no one porting R to Windows
does on their Windows machines AFAIK. We really do need something that
compiles on standard C compilers with minimal baggage, as total download
size is a significant issue.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cyg at sympatico.ca  Thu Dec  2 01:37:28 1999
From: cyg at sympatico.ca (Yves Gauvreau)
Date: Wed, 1 Dec 1999 19:37:28 -0500
Subject: [R] Meaning?
Message-ID: <02b801bf3c5d$69bccff0$6328acce@bellglobal.com>

Hi,

Sorry to ask this but what is the meaning of "AFAIK". From a darn Frenchman!

Regards.

Yves

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maj at waikato.ac.nz  Thu Dec  2 01:39:10 1999
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Thu, 02 Dec 1999 13:39:10 +1300
Subject: [R] Installing R on Slackware Linux
In-Reply-To: <199912010034.NAA13288@gosset.stats.waikato.ac.nz>
Message-ID: <199912020038.NAA17832@gosset.stats.waikato.ac.nz>

I'd like to thank Markus Jantti, John Maindonald, Peter Malewski, Mathew
Wiener and Jonathan Yuen for their help. As most pointed out, the .INSTALL
file is quite good. Just the same, for a linux novice like me it did help
to have much the same thing said in several different ways.

I still don't know what to do with the old 0.65.1 directory tree. [ It was
a minor triumph of mine when I figured out how to use the "find" command
properly and by searching for config.status, which one of the replies let
me know was a file in the tree, actually succeeded in finding the R0.65.1
directory tree.]

Now what do I do?

* Delete the old directory tree before installing the new version?
  (and risk ending up with no R at all)
* Leave the old directory tree and install the new version?
   (and possibly still get the old version when I type "R")

Or maybe uninstalling is more complicated than deleting the tree - it
certainly is in Windows!

I truly do hope that there are lurking newbies out there that make my
asking such basic questions worthwhile!


Murray Jorgensen,  Department of Statistics,  U of Waikato, Hamilton, NZ
-----[+64-7-838-4773]---------------------------[maj at waikato.ac.nz]-----
"Doubt everything or believe everything:these are two equally convenient
strategies. With either we dispense with the need to think."
http://www.cs.waikato.ac.nz/stats/Staff/maj.html       - Henri Poincare'

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Thu Dec  2 04:15:42 1999
From: bates at stat.wisc.edu (Douglas Bates)
Date: 01 Dec 1999 21:15:42 -0600
Subject: [R] Meaning?
In-Reply-To: "Yves Gauvreau"'s message of "Wed, 1 Dec 1999 19:37:28 -0500"
References: <02b801bf3c5d$69bccff0$6328acce@bellglobal.com>
Message-ID: <6rk8myt4m9.fsf@franz.stat.wisc.edu>

"Yves Gauvreau" <cyg at sympatico.ca> writes:

> Sorry to ask this but what is the meaning of "AFAIK". From a darn Frenchman!

AFAIK => As far as I know

It is one of those acronyms that is sometimes adopted in e-mail to save typing.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Kurt.Hornik at ci.tuwien.ac.at  Thu Dec  2 08:53:06 1999
From: Kurt.Hornik at ci.tuwien.ac.at (Kurt Hornik)
Date: Thu, 2 Dec 1999 08:53:06 +0100 (CET)
Subject: [R] graphics
In-Reply-To: <x2puwqwm5z.fsf@blueberry.kubism.ku.dk>
References: <199911300756.IAA23343@alpha.luc.ac.be>
	<x2aenvpp1x.fsf@blueberry.kubism.ku.dk>
	<14405.21365.551653.52140@gargle.gargle.HOWL>
	<x2puwqwm5z.fsf@blueberry.kubism.ku.dk>
Message-ID: <14406.9570.28835.949746@fangorn.ci.tuwien.ac.at>

>>>>> Peter Dalgaard BSA writes:

> Martin Maechler <maechler at stat.math.ethz.ch> writes:
>> BUT, for a first "quick fix" : Why not change X11's argument
>> pointsize = 12
>> to
>> pointsize = .Options$X11pointsize
>> (we already have X11colortype !).

> Which is a mess! We also have

> .PostScript.Options$pointsize

> So wouldn't it be more obvious to use

> .X11.Options$pointsize

> (and set it with X11.options(pointsize=12))?

Why would we need a separate options variable anyway?  We might as well
do .Options$PostScript.foo instead ... or .Options$PostScript$foo ...

If we do the above we might also want an X11.options() in analogy to the
ps.options() which already exists, and perhaps also pictex.options()
etc.

???

> If we go to 10pt default, we also need to discuss the multiframe
> scaling issue. The current rules are that if there is two rows and/or
> columns, reduce font size to 80%, if there are three or more reduce to
> 50% and a 5pt font @100dpi is a tad small. Note that this rule is
> *device independent*, so one would have to check that it still looks
> reasonable on postscript and windows. I think it works out OK if one
> sets the rule to 60% giving a 6pt font, but I'd like someone elses
> eyes on that.

>> Now back to the feature request:
>> 
>> Do we want  par.defaults() for this?
>> It would have the same arguments as par()  plus additional
>> device = .Options$device
>> with further possibility   
>> device = "all"
>> i.e., by default,  par.defaults()  would set things only for the default
>> device, but there'd be a possibility to set these for all devices.
>> 
>> Note that
>> -  This would lead to considerable side effects.
>> [Starting a device and setting par()s would not be portable,
>> for complete portability you'd have to first set (or reset) the
>> par.defaults()]
>> -  for  device = "postscript", 
>> we could allow further arguments as those of ps.options() and postscript()
>> and e.g. for device = "X11" ( = default on non-gnome Unix),
>> one should allow arguments of X11/x11() such as pointsize, colortype, ...
>> 
>> -----
>> 
>> When feature requesting: What I have wanted more than once is an
>> par(reset = TRUE)
>> which would set all the par()s back to how they were when the device was
>> opened.   
>> 
>> par.defaults(reset = TRUE)
>> 
>> would analogously remove all `site/user specific' par defaults
>> (effect: as if  par.defaults() was never set).

> Hmm. I'm not so sure we're really gaining much from an elaborate
> par.default() function. If one desires, one could do it via the
> startup function, simply by a call to par based on the options).

> For instance, try changing X11 to

> X11<-function (display = "", width = 7, height = 7, pointsize = 12, 
>     gamma = 1, colortype = options()$X11colortype, maxcubesize = 256) 
> {
>     .Internal(X11(display, width, height, pointsize, gamma, colortype, 
>     maxcubesize))
>     par(ask=T)
> }

> and then

> example(barplot)
> dev.off()
> par(ask=F)
> example(barplot)

Agreed.

-k
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Thu Dec  2 09:38:30 1999
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 2 Dec 1999 09:38:30 +0100 (MET)
Subject: par(mkh) {was [R] Plot Character Sizes in rw-0.90.0}
In-Reply-To: <x2u2m2mgkp.fsf@blueberry.kubism.ku.dk>
References: <3.0.1.32.19991202085147.006d09fc@anugpo.anu.edu.au>
	<x2u2m2mgkp.fsf@blueberry.kubism.ku.dk>
Message-ID: <14406.12294.492211.981566@gargle.gargle.HOWL>


    PD> John Maindonald <john.maindonald at anu.edu.au> writes:

      JM>      <....>

      JM> A further point is that, contrary to the documentation of par(),
      JM> the setting of mkh seems to have no effect on the height of symbols
      JM> plotted with pch, e. g.  plot(1:4,1:4,pch=1,mkh=0.2)

    PD> Yes, I believe we already have a bug report to that effect.

True; question is : What should be fixed?  Documentation or implementation?

Here the Status:

   Contrary to S, in R, we have always been using  par("cex") and the
   <highlevel plot> cex argument  *both* for text and all graphical symbols.
   S uses mkh for  pch=<integer>   symbols and
	  cex for  pch=<character> ones and text
   which is really not what we (R&R, initially) wanted to copy.

   In R, mkh settings have always been completely ignored.  
   In spite of this, par() (and the internal code in  par.c & graphics.c) have
   been set up to allow setting and querying mkh.

Now, there are several possibilities of which I'd advocate mainly 1) or 2) 
[I'm talking about implementation; documentation must be updated in any case]:

1) Implementation unchanged + using  mkh gives a warning saying 
   that mkh is practically ignored.
   
2) setting par(mkh) or  <highlevelplot>(* , mkh = ..)
    
    gives a warning (``mkh : setting cex'')
    and then behaves as if "cex" was used.

3a) Even more S compatibility:
   Setting par(mkh) or  <highlevelplot>(* , mkh = ..)
   changes "cex" accordingly *IF* pch=<numeric> .

3b) Similar but more logical; need some "notation" : 
    The symbol size used in the core function plot.xy()  is
           cexbase * Pcex   (--> plot.c, l.1089)

    where "cexbase" is par("cex") and  Pcex is the "cex" argument of 
    plot(),points(),...

    Now we could change this to
           cexbase * mkh * Pcex
    for the case of numeric pch (internally pch <= 31 or something) where
    mkh is *either* par("mkh") or the mkh arg. of plot.xy().


4) complete S compatibility (cex *not* working for pch=<numeric>)

   This is completely out of question for me!


Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO D10	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Thu Dec  2 10:48:27 1999
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Thu, 2 Dec 1999 09:48:27 +0000 (GMT)
Subject: [R] graphics
In-Reply-To: <19991202084736.A2925@stat1.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.10.9912020940001.5471-100000@localhost.localdomain>

As I understand it, all this discussion is referring to how the graphics
look on the screen. Maybe it is pointless to mention the following, but
here I go:
- what is on the screen (X11) should agree with what is printed
(dev.print)
- the default sizes of letters and symbols are too small in
ouput produced by dev.print. Should be double the size. I always use
cex=2, but numerous things get buggered up. In my opinion, the current
behaviour is a bad legacy from S. Default S plots use labels and symbols
that are too small. Remember that plots submitted to journals
and book publishers always get scaled down, so in the original version
they have to be quite large. Take a look at V&R, pp16-17 for plots whose
axis labels are smaller than surrounding main text.

Bill

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From john.maindonald at anu.edu.au  Thu Dec  2 10:23:20 1999
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 2 Dec 1999 20:23:20 +1100 (EST)
Subject: [R] Large plot symbols (with pch = 1 etc)
Message-ID: <199912020923.UAA17825@leonard.anu.edu.au>

On my home (Windows 98) machine I find:
> par()$cra
[1] 42 16
> par()$csi
[1] 0.1666667
> 

On my work machine I believe I had
par()$cra
[1] 17 16

So it looks as though R is reading the width wrongly,
and that it is the width that is somehow used to
determine the plot character size.

Incidentally I noted Brian's comment that R had misread
his character dimension information wrongly.  I have a
Matrox MM2 board on my Windows 98 (SE) machine.  
I understand he will be using a Matrox G200.  Is there a 
Matrox connection?

Regards

John Maindonald               email : john.maindonald at anu.edu.au        
Statistical Consulting Unit,  phone : (6249)3998        
c/o CMA, SMS,                 fax   : (6249)5549  
John Dedman Mathematical Sciences Building
Australian National University
Canberra ACT 0200
Australia
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec  2 10:39:55 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 2 Dec 1999 09:39:55 +0000 (GMT)
Subject: [R] graphics
In-Reply-To: <Pine.LNX.4.10.9912020940001.5471-100000@localhost.localdomain>
Message-ID: <Pine.GSO.4.05.9912020931530.26617-100000@auk.stats>

On Thu, 2 Dec 1999, Bill Simpson wrote:

> they have to be quite large. Take a look at V&R, pp16-17 for plots whose
> axis labels are smaller than surrounding main text.

There are no plots on those pages! Presumably you have an old edition.

It is quite common in journals to have minor labels smaller than the main
text: after all the footnotes and index are smaller than the main text in
our book. Those plots have been checked and approved (three times) by
professional copy editors.

What you get with dev.print is entirely up to you: it depends on how you
set pointsize and in particular if you like looking at plots with your head
turned through 90^o. (I get very frustrated with students who produce
landscape plots that way: the default pointsize is relative to a much
smaller plot if it is portrait not the default (for some reason that has
always escaped me) landscape.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Thu Dec  2 12:03:09 1999
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Thu, 2 Dec 1999 11:03:09 +0000 (GMT)
Subject: [R] graphics
In-Reply-To: <Pine.GSO.4.05.9912020931530.26617-100000@auk.stats>
Message-ID: <Pine.LNX.4.10.9912021058520.5519-100000@localhost.localdomain>



On Thu, 2 Dec 1999, Prof Brian D Ripley wrote:

> On Thu, 2 Dec 1999, Bill Simpson wrote:
> 
> > they have to be quite large. Take a look at V&R, pp16-17 for plots whose
> > axis labels are smaller than surrounding main text.
> 
> There are no plots on those pages! Presumably you have an old edition.
2nd edition, figs 1.6 and 1.7

> It is quite common in journals to have minor labels smaller than the main
> text: after all the footnotes and index are smaller than the main text in
> our book. Those plots have been checked and approved (three times) by
> professional copy editors.
I know it amounts to taste. My taste is: figure labels should be larger
than surrounding text.

> What you get with dev.print is entirely up to you: it depends on how you
> set pointsize and in particular if you like looking at plots with your head
> turned through 90^o.
I tried setting pointsize in the past without success. Maybe it works now
and I should try again. In the past the only solution was cex=2

> (I get very frustrated with students who produce
> landscape plots that way: the default pointsize is relative to a much
> smaller plot if it is portrait not the default (for some reason that has
> always escaped me) landscape.)
I agree that portrait should be the default. I always set
horizontal=FALSE.

Bill

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec  2 11:33:11 1999
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Dec 1999 10:33:11 +0000 (GMT)
Subject: [R] Large plot symbols (with pch = 1 etc)
Message-ID: <199912021033.KAA11211@toucan.stats.ox.ac.uk>

> Date: Thu, 2 Dec 1999 20:23:20 +1100 (EST)
> From: John Maindonald <john.maindonald at anu.edu.au>
> 
> On my home (Windows 98) machine I find:
> > par()$cra
> [1] 42 16
> > par()$csi
> [1] 0.1666667
> > 
> 
> On my work machine I believe I had
> par()$cra
> [1] 17 16
> 
> So it looks as though R is reading the width wrongly,
> and that it is the width that is somehow used to
> determine the plot character size.
> 
> Incidentally I noted Brian's comment that R had misread
> his character dimension information wrongly.  I have a
> Matrox MM2 board on my Windows 98 (SE) machine.  
> I understand he will be using a Matrox G200.  Is there a 
> Matrox connection?

It was my laptop (our G200's are primarily Linux), and it is a NeoMagic
256. The problem was with Windows, not R: R acts on what it is told by
Windows, and that was nonsense.  I am fairly sure that problem resides
in the graphics drivers, but we need to work around it.  Not long
before the release of 0.90.0 he and I were getting very different
font and symbol sizes on our laptops from identical code.

As far as I can see in the Nov 19th change Guido changed the cra
setting to come from the character metrics.  That is, cra[1] is set to
what Windows reports as the maximum width of a character in the font.
It looks as if that is unreliable.  I think we should ask it for "O".
Incidentally, I am beginning to learn that Window 98SE is not just
a minor upgrade, so we are going to have to test on that too.

Brian

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec  2 12:44:06 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 Dec 1999 12:44:06 +0100
Subject: [R] Installing R on Slackware Linux
In-Reply-To: Murray Jorgensen's message of "Thu, 02 Dec 1999 13:39:10 +1300"
References: <199912020038.NAA17832@gosset.stats.waikato.ac.nz>
Message-ID: <x2bt897ek9.fsf@blueberry.kubism.ku.dk>

Murray Jorgensen <maj at waikato.ac.nz> writes:

> I'd like to thank Markus Jantti, John Maindonald, Peter Malewski, Mathew
> Wiener and Jonathan Yuen for their help. As most pointed out, the .INSTALL
> file is quite good. Just the same, for a linux novice like me it did help
> to have much the same thing said in several different ways.
> 
> I still don't know what to do with the old 0.65.1 directory tree. [ It was
> a minor triumph of mine when I figured out how to use the "find" command
> properly and by searching for config.status, which one of the replies let
> me know was a file in the tree, actually succeeded in finding the R0.65.1
> directory tree.]
> 
> Now what do I do?
> 
> * Delete the old directory tree before installing the new version?
>   (and risk ending up with no R at all)
> * Leave the old directory tree and install the new version?
>    (and possibly still get the old version when I type "R")
> 
> Or maybe uninstalling is more complicated than deleting the tree - it
> certainly is in Windows!
> 
> I truly do hope that there are lurking newbies out there that make my
> asking such basic questions worthwhile!

Well, it will unpack in a separate directory and you can build and
test the new version there, it is only when you enter "make install"
that you'll be overwriting files in system locations. The R-0.65.1
directory can be kept if you wish.

Normally, no harm comes from installing on top of a previous
installation, but if you want to be sure delete /usr/local/bin/R
and  /usr/local/bin/*Rd* (hoping that nothing else matches the
wildcards...) and "rm -rf /usr/local/lib/R" befor installing.

If something goes haywire, it should still be possible to go to
R-0.65.1, type "make install" and have the old version reinstalled.

All assuming that you used "make install" with the standard locations
the last time round.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec  2 14:48:33 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 Dec 1999 14:48:33 +0100
Subject: [R] graphics
In-Reply-To: Bill Simpson's message of "Thu, 2 Dec 1999 09:48:27 +0000 (GMT)"
References: <Pine.LNX.4.10.9912020940001.5471-100000@localhost.localdomain>
Message-ID: <x2903d78su.fsf@blueberry.kubism.ku.dk>

Bill Simpson <wsi at gcal.ac.uk> writes:

> As I understand it, all this discussion is referring to how the graphics
> look on the screen. Maybe it is pointless to mention the following, but
> here I go:
> - what is on the screen (X11) should agree with what is printed
> (dev.print)

This is a bit problematic. I'd say that it should be readable before
anything else. If one wants exact preview, use ghostview & friends.
Also for a pleasant working environment (at least with X11), I like to
use unscaled fonts as far as possible.

> - the default sizes of letters and symbols are too small in
> ouput produced by dev.print. Should be double the size. I always use
> cex=2, but numerous things get buggered up. In my opinion, the current
> behaviour is a bad legacy from S. Default S plots use labels and symbols
> that are too small. Remember that plots submitted to journals
> and book publishers always get scaled down, so in the original version
> they have to be quite large. Take a look at V&R, pp16-17 for plots whose
> axis labels are smaller than surrounding main text.

(As Brian pointed out, pointsize is better than cex for this purpose.
Pardon the pun...)

I do agree that the S defaults are a bit small, but it all depends on
what they are to be used for: 

 - as an intermediate tool in model development &c
 - full-page illustration in book/journal
 - half-page, in-text illustration
 - slide

(with increasing text-to-plot ratios). And it also depends on personal
tastes - e.g. Jim Lindsey pretty squarely want to maximize the plot
area, i.e. minimum legible fonts, if I interpret him correctly.

I think I'm with Brian in saying that the plots in V&R are certainly
not seriously bad, and there's not really any cause for assuming that
the sizes of text on a plot are directly related to those in the
running text (unless one has been foolish enough to use the same
font!) They're readable enough and the whole thing is in reasonable
balance. The labels are a bit too close to the axes and tick marks
though....

Incidentally, I reached out for the nearest stats book from the pre-S
era (Breslow&Day, 1980) and found some pretty ugly clashes between
plots and the surrounding text. It isn't easy...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From syring at email.com  Thu Dec  2 16:36:16 1999
From: syring at email.com (Karl M. Syring)
Date: Thu, 2 Dec 1999 16:36:16 +0100
Subject: [R] Meaning?
In-Reply-To: <02b801bf3c5d$69bccff0$6328acce@bellglobal.com>
Message-ID: <000101bf3cda$f8d8ad30$c1cd9e3e@fenris>

Yves,
there are ancronym finders (of course) on the web. Try
http://www.ucc.ie/cgi-bin/acronym?rotfl

Regards
Karl


> -----Original Message-----
> From: owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch]On Behalf Of Yves Gauvreau
> Sent: Donnerstag, 2. Dezember 1999 01:37
> To: r-help at stat.math.ethz.ch
> Subject: [R] Meaning?
> 
> 
> Hi,
> 
> Sorry to ask this but what is the meaning of "AFAIK". From a darn 
> Frenchman!
> 
> Regards.
> 
> Yves
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec  2 17:08:06 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 Dec 1999 17:08:06 +0100
Subject: par(mkh) {was [R] Plot Character Sizes in rw-0.90.0}
In-Reply-To: Martin Maechler's message of "Thu, 2 Dec 1999 09:38:30 +0100 (MET)"
References: <3.0.1.32.19991202085147.006d09fc@anugpo.anu.edu.au> <x2u2m2mgkp.fsf@blueberry.kubism.ku.dk> <14406.12294.492211.981566@gargle.gargle.HOWL>
Message-ID: <x2wvqx5nrt.fsf@blueberry.kubism.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> 1) Implementation unchanged + using  mkh gives a warning saying 
>    that mkh is practically ignored.
>    
> 2) setting par(mkh) or  <highlevelplot>(* , mkh = ..)
>     
>     gives a warning (``mkh : setting cex'')
>     and then behaves as if "cex" was used.
> 
> 3a) Even more S compatibility:
>    Setting par(mkh) or  <highlevelplot>(* , mkh = ..)
>    changes "cex" accordingly *IF* pch=<numeric> .
> 
> 3b) Similar but more logical; need some "notation" : 
>     The symbol size used in the core function plot.xy()  is
>            cexbase * Pcex   (--> plot.c, l.1089)
> 
>     where "cexbase" is par("cex") and  Pcex is the "cex" argument of 
>     plot(),points(),...
> 
>     Now we could change this to
>            cexbase * mkh * Pcex
>     for the case of numeric pch (internally pch <= 31 or something) where
>     mkh is *either* par("mkh") or the mkh arg. of plot.xy().
> 
> 
> 4) complete S compatibility (cex *not* working for pch=<numeric>)
> 
>    This is completely out of question for me!

Um, as I read my S docs, cex works for numeric pch, but only if mkh=0
which is the default, and mkh works for pch=1 only. That mkh doesn't
work for non-numeric pch is a bit odd, and we could fix that if we
could decide on a reasonable definition of the height of such symbols
(probably, it should depend on the font, not the character). 

But is the real issue not that one will sometimes want to set the size
in "screen-inches", rather than by scaling the defaults? Looks wrong
to me to have it scaling with anything except the pixel resolution.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mathieu.ros at free.fr  Thu Dec  2 19:35:24 1999
From: mathieu.ros at free.fr (mathieu)
Date: Thu, 02 Dec 1999 19:35:24 +0100
Subject: [R] problem with par(fig=value)
Message-ID: <3846BBEB.ED9677AF@free.fr>

hello all,
I want to draw a figure with multiple plot on the same page using the
par(fig=value) parameter but

> par(fig = c(0, 50, 60, 95)/100, adj = 5/10)
> eboulis(iris.acp)
> par(fig = c(45, 100, 60, 95)/100, mgp = c(3, 1/2, 0))
> boites(iris.acp)

draw the graphics on 2 different pages.
what am I doing wrong ?
thanks for your help.
    Mathieu

[using R 0.65 under Linux Redhat 6.0]

--
----------------------------------------------------------------------
 Mathieu Ros - 13 rue b?vi?re - 38000 GRENOBLE - 04 76 491 370
 http://www.multimania.com/mathieuros/index2.html
 DESS ing?nierie math?matique (biostatistiques)
 Universite Joseph Fourier, Grenoble
----------------------------------------------------------------------
La science d?tient la v?rit?, ne vous laissez pas avoir par les faits.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/19991202/08de548c/attachment.html

From cyg at sympatico.ca  Thu Dec  2 18:47:09 1999
From: cyg at sympatico.ca (Yves Gauvreau)
Date: Thu, 2 Dec 1999 12:47:09 -0500
Subject: [R] Meaning?
Message-ID: <036101bf3ced$421ebe50$6328acce@bellglobal.com>

Hi,

Thank you all for your quit an aboundant responses. HAND all of you.

Thanks again.

Yves


-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/19991202/213cd2d7/attachment.html

From mangalam at home.com  Thu Dec  2 19:30:50 1999
From: mangalam at home.com (Harry Mangalam)
Date: Thu, 02 Dec 1999 10:30:50 -0800
Subject: [R] Multi-threaded external routines with R?
References: <3.0.1.32.19991202085147.006d09fc@anugpo.anu.edu.au> <x2u2m2mgkp.fsf@blueberry.kubism.ku.dk> <14406.12294.492211.981566@gargle.gargle.HOWL> <x2wvqx5nrt.fsf@blueberry.kubism.ku.dk>
Message-ID: <3846BADA.36B05E99@home.com>

Hi All,

While R is not multi-threaded, it supports dynamic loading of external
routines writ in C or Fortran.  It seems that it should be possible to link
in multi-threaded code as easily as serial code, as long as the external
routine syncs correctly and returns valid R objects.  

Is this true or ar there R internals that would prevent this?  

If it is true, can anyone point me to examples of this kind of usage?

Thanks very much,
Cheers
Harry
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Thu Dec  2 20:12:54 1999
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Thu, 2 Dec 1999 14:12:54 -0500 (EST)
Subject: [R] problem with par(fig=value)
In-Reply-To: <3846BBEB.ED9677AF@free.fr>
Message-ID: <Pine.LNX.4.10.9912021412370.1309-100000@bolker.zoo.ufl.edu>


  I think you need to look at par(new) ...

On Thu, 2 Dec 1999, mathieu wrote:

> hello all,
> I want to draw a figure with multiple plot on the same page using the
> par(fig=value) parameter but
> 
> > par(fig = c(0, 50, 60, 95)/100, adj = 5/10)
> > eboulis(iris.acp)
> > par(fig = c(45, 100, 60, 95)/100, mgp = c(3, 1/2, 0))
> > boites(iris.acp)
> 
> draw the graphics on 2 different pages.
> what am I doing wrong ?
> thanks for your help.
>     Mathieu
> 
> [using R 0.65 under Linux Redhat 6.0]
> 
> --
> ----------------------------------------------------------------------
>  Mathieu Ros - 13 rue bvire - 38000 GRENOBLE - 04 76 491 370
>  http://www.multimania.com/mathieuros/index2.html
>  DESS ingnierie mathmatique (biostatistiques)
>  Universite Joseph Fourier, Grenoble
> ----------------------------------------------------------------------
> La science dtient la vrit, ne vous laissez pas avoir par les faits.
> 
> 
> 

-- 
--------------------------------------------
Ben Bolker                                  bolker at zoo.ufl.edu
Zoology Department, University of Florida   http://www.zoo.ufl.edu/bolker
318 Carr Hall/Box 118525                    tel: (352) 392-5697
Gainesville, FL 32611-8525                  fax: (352) 392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chris at gfm-mbh.de  Fri Dec  3 13:37:40 1999
From: chris at gfm-mbh.de (Christoph M. Friedrich)
Date: Fri, 03 Dec 1999 13:37:40 +0100
Subject: [R] R as Unix-Filter and Streams for DataMining
Message-ID: <3847B994.2EDA8E35@gfm-mbh.de>

Hi,
i want to use R as a filter in a Unix-like way. So i want to start it
with

producerTool | R --no-save --no-restore --slave < Rscript |
anotherConsumerUnixTool

inside the Script i put the results to stdout, works fine, but how to
read in  
from stdin? Its obvious that i have to source the Rscript in a different
way. Any Hints?

My second question is, if there is a possibility to use something like
the Scheme Streams
(see Abelson/Sussman "Structure and Interpretation of Computer
Programs") for input of Huge Amounts of Data, that do not fit in the
main memory, or to reduce the necessary amount of memory? The
application
i have in mind is: Generate from a training set a linear or other model
and then 
pipe in a file with the test cases (as stream with read.table) and give
the output to stdout. Is there 
any concept in R like this?

Thanks in advance
  Chris 
-- 
Christoph M. Friedrich        | mailto:friedrich at computer.org 
Gesellschaft f?r Modulfermenterbau mbH (GfM mbH) |
http://www.tussy.uni-wh.de/~chris
Alfred-Herrhausen Str. 44 ; D-58455 Witten, Germany
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jbarnett at wi.mit.edu  Fri Dec  3 17:02:48 1999
From: jbarnett at wi.mit.edu (John D. Barnett)
Date: Fri, 03 Dec 1999 11:02:48 -0500
Subject: [R] R as Unix-Filter and Streams for DataMining
References: <3847B994.2EDA8E35@gfm-mbh.de>
Message-ID: <3847E9A8.4173B2CA@wi.mit.edu>

"Christoph M. Friedrich" wrote:

> Hi,
> i want to use R as a filter in a Unix-like way. So i want to start it
> with
>
> producerTool | R --no-save --no-restore --slave < Rscript |
> anotherConsumerUnixTool
>
> inside the Script i put the results to stdout, works fine, but how to
> read in
> from stdin? Its obvious that i have to source the Rscript in a different
> way. Any Hints?

Two (klugey) ideas--

- write a script which reads standard input, and reads a file, and outputs
both of them to standard output.  (Maybe there's a command that does this
already; anyone know?)  You could take this one step further and just make
it a wrapper for R, which would execute any files given on the command
line and then read from standard input.

- put your script (or a command to load your script) into .Rprofile, which
R reads and executes initially.

Sorry, I don't know anything about streams.

-John

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Fri Dec  3 16:01:29 1999
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Fri, 3 Dec 1999 16:01:29 +0100
Subject: [R] R as Unix-Filter and Streams for DataMining
In-Reply-To: <3847B994.2EDA8E35@gfm-mbh.de>
Message-ID: <000501bf3d9f$47ff6ec0$a9021aac@joelschlaegel>


My workaround currently is:

(1) Write the path and name of your input file into a file with a *fixed*
name
    use unix paths //// never windows \\\\, e.g.

  d:/temp/filename.txt

(2) Call R via Batchfile

(3) In the batch file set a temporary user dir for R

  set R_USER=d:/temp

(4) Have an approbriate .Profile in this temporary user dir, which defines
.First
    Do *not* take other actions in .Profile except for setting options and
defining .First

.First <- function(){
  # get filename
  filename <- scan("d:/temp/filename.txt", what=character(0))
  cat("filename is ", filename, "\n")
  # make use of filename
  source(filename)
  # exit from R
  q()
}


If you discover a simpler solution, please give me a note
Best


-----Original Message-----
From: owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch]On Behalf Of Christoph M.
Friedrich
Sent: Friday, December 03, 1999 1:38 PM
To: r-help at stat.math.ethz.ch
Subject: [R] R as Unix-Filter and Streams for DataMining


Hi,
i want to use R as a filter in a Unix-like way. So i want to start it
with

producerTool | R --no-save --no-restore --slave < Rscript |
anotherConsumerUnixTool

inside the Script i put the results to stdout, works fine, but how to
read in
from stdin? Its obvious that i have to source the Rscript in a different
way. Any Hints?

My second question is, if there is a possibility to use something like
the Scheme Streams
(see Abelson/Sussman "Structure and Interpretation of Computer
Programs") for input of Huge Amounts of Data, that do not fit in the
main memory, or to reduce the necessary amount of memory? The
application
i have in mind is: Generate from a training set a linear or other model
and then
pipe in a file with the test cases (as stream with read.table) and give
the output to stdout. Is there
any concept in R like this?

Thanks in advance
  Chris
--
Christoph M. Friedrich        | mailto:friedrich at computer.org
Gesellschaft f?r Modulfermenterbau mbH (GfM mbH) |
http://www.tussy.uni-wh.de/~chris
Alfred-Herrhausen Str. 44 ; D-58455 Witten, Germany
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Fri Dec  3 17:13:41 1999
From: bates at stat.wisc.edu (Douglas Bates)
Date: 03 Dec 1999 10:13:41 -0600
Subject: [R] R as Unix-Filter and Streams for DataMining
In-Reply-To: "John D. Barnett"'s message of "Fri, 03 Dec 1999 11:02:48 -0500"
References: <3847B994.2EDA8E35@gfm-mbh.de> <3847E9A8.4173B2CA@wi.mit.edu>
Message-ID: <6r66yg57ey.fsf@franz.stat.wisc.edu>

"John D. Barnett" <jbarnett at wi.mit.edu> writes:

> Two (klugey) ideas--
> 
> - write a script which reads standard input, and reads a file, and outputs
> both of them to standard output.  (Maybe there's a command that does this
> already; anyone know?)  

Most Unix/Linux systems have a command called "tee", which makes
"T-joints" in pipes.

$ tee --help
Usage: tee [OPTION]... [FILE]...
Copy standard input to each FILE, and also to standard output.

  -a, --append              append to the given FILEs, do not overwrite
  -i, --ignore-interrupts   ignore interrupt signals
      --help                display this help and exit
      --version             output version information and exit
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Fri Dec  3 17:39:53 1999
From: bates at stat.wisc.edu (Douglas Bates)
Date: 03 Dec 1999 10:39:53 -0600
Subject: [R] R as Unix-Filter and Streams for DataMining
In-Reply-To: Douglas Bates's message of "03 Dec 1999 10:13:41 -0600"
References: <3847B994.2EDA8E35@gfm-mbh.de> <3847E9A8.4173B2CA@wi.mit.edu> <6r66yg57ey.fsf@franz.stat.wisc.edu>
Message-ID: <6rzovs3rmu.fsf@franz.stat.wisc.edu>

Douglas Bates <bates at cs.wisc.edu> writes:

> "John D. Barnett" <jbarnett at wi.mit.edu> writes:
> 
> > Two (klugey) ideas--
> > 
> > - write a script which reads standard input, and reads a file, and outputs
> > both of them to standard output.  (Maybe there's a command that does this
> > already; anyone know?)  
> 
> Most Unix/Linux systems have a command called "tee", which makes
> "T-joints" in pipes.
> 
> $ tee --help
> Usage: tee [OPTION]... [FILE]...
> Copy standard input to each FILE, and also to standard output.
> 
>   -a, --append              append to the given FILEs, do not overwrite
>   -i, --ignore-interrupts   ignore interrupt signals
>       --help                display this help and exit
>       --version             output version information and exit

I realize now that I answered the wrong question - you want to know
how to _read_ standard input and a file, not how to write it.  The
answer is to use "cat" in the form
 cmd1 | cat - [FILE] | cmd2

 $ cat --help
 Usage: cat [OPTION] [FILE]...
 Concatenate FILE(s), or standard input, to standard output.

   -A, --show-all           equivalent to -vET
   -b, --number-nonblank    number nonblank output lines
   -e                       equivalent to -vE
   -E, --show-ends          display $ at end of each line
   -n, --number             number all output lines
   -s, --squeeze-blank      never more than one single blank line
   -t                       equivalent to -vT
   -T, --show-tabs          display TAB characters as ^I
   -u                       (ignored)
   -v, --show-nonprinting   use ^ and M- notation, except for LFD and TAB
       --help               display this help and exit
       --version            output version information and exit

 With no FILE, or when FILE is -, read standard input.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Dec  3 17:48:46 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Dec 1999 17:48:46 +0100
Subject: [R] R as Unix-Filter and Streams for DataMining
In-Reply-To: "John D. Barnett"'s message of "Fri, 03 Dec 1999 11:02:48 -0500"
References: <3847B994.2EDA8E35@gfm-mbh.de> <3847E9A8.4173B2CA@wi.mit.edu>
Message-ID: <x21z94otqp.fsf@blueberry.kubism.ku.dk>

"John D. Barnett" <jbarnett at wi.mit.edu> writes:

> - write a script which reads standard input, and reads a file, and outputs
> both of them to standard output.  (Maybe there's a command that does this
> already; anyone know?)  You could take this one step further and just make
> it a wrapper for R, which would execute any files given on the command
> line and then read from standard input.

produce | cat - script | ...

("-" means stdin)

But a really good solution to this kind of task would probably involve
some kind of stream object inside of R.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From owner-r-help-digest at stat.math.ethz.ch  Fri Dec  3 04:01:10 1999
From: owner-r-help-digest at stat.math.ethz.ch (R-help Digest)
Date: Fri, 3 Dec 1999 04:01:10 +0100 (MET)
Subject: [R] R-help Digest V1 #34
Message-ID: <199912030301.EAA08600@stat.math.ethz.ch>


R-help Digest         Friday, December 3 1999         Volume 01 : Number 034



In this issue:

  [R] model.tables
  Re: [R] Installing R on Slackware Linux
  Re: [R] Installing R on Slackware Linux
  [R] nlmin
  Re: [R] nlmin
  Re: [R] nlmin
  Re: Summary: [R] Wanted: online Introduction to R
  [R] Applying a function of several variables to data 
  Re: [R] R and XML -- a near perfect combination?
  [R] problem installing R 0.90
  Re: [R] graphics
  Re: [R] graphics
  Re: [R] graphics
  Re: [R] graphics
  Re: [R] R and XML -- a near perfect combination?
  Re: [R] graphics
  [R] Plot Character Sizes in rw-0.90.0
  RE: [R] R and XML -- a near perfect combination?
  Re: [R] R and XML -- a near perfect combination?
  Re: [R] Plot Character Sizes in rw-0.90.0
  Re: [R] R and XML -- a near perfect combination?
  [R] Meaning?
  Re: [R] Installing R on Slackware Linux
  Re: [R] Meaning?
  Re: [R] graphics
  par(mkh) {was [R] Plot Character Sizes in rw-0.90.0}
  Re: [R] graphics
  [R] Large plot symbols (with pch = 1 etc)
  Re: [R] graphics
  Re: [R] graphics
  Re: [R] Large plot symbols (with pch = 1 etc)
  Re: [R] Installing R on Slackware Linux
  Re: [R] graphics
  RE: [R] Meaning?
  Re: par(mkh) {was [R] Plot Character Sizes in rw-0.90.0}
  [R] problem with par(fig=value)
  [R] Meaning?
  [R] Multi-threaded external routines with R?
  Re: [R] problem with par(fig=value)

See the end of the digest for information about r-help-digest

----------------------------------------------------------------------

Date: Wed, 1 Dec 1999 14:21:11 +1100 (EST)
From: John Maindonald <john.maindonald at anu.edu.au>
Subject: [R] model.tables

Berwin Turlach wrote -

> > >>>>> "JM" == John Maindonald <john.maindonald at anu.edu.au> writes:
> 
>   JM> At 08:02 30/11/99 +0000, Prof Brian D Ripley wrote:
>   >> On Tue, 30 Nov 1999, spoon <spoon at hilbert.maths.utas.edu.au> wrote:
>   >> 
>   >>> Hi,
>   >>> Is this a bug or do I just not understand model.tables?
>   >>> [...]
>   >>> Or am I just completely misinterpreting something basic?
>   >> 
>   >> Basically, yes. This is an incompletely replicated design, and d and e
>   >> occur on different litters.
>   >> 
>   >> The results are identical to the S-PLUS original. I think you are
>   >> probably looking for what dummy.coef gives you.
>   >> [...]
> 
>   JM> So what is it that model.tables() gives?
> Good question, in R (0.65.1) the documentation of model.tables says:
> 
>    WARNING:
>         The implementation is incomplete, and only the simpler
>         cases have been tested thoroughly.

Simon and I had noted that.  As S-PLUS has no such warning, perhaps
the discussion should be taking place on s-news.

>   JM> S-PLUS says they are estimates.  Of what?  These are not the
>   JM> marginal means of the fitted values, ignoring other factors.  Do
>   JM> they mean anything at all?  The issue of unbalance does not
>   JM> arise here.
> The documentation in R also states that
> 
>     Details:
> 
>         For `type = "effects"' give tables of the coefficients
>         for each term, optionally with standard errors.
> 
>         For `type = "means"' give tables of the mean response
>         for each combinations of levels of the factors in a
>         term.
> 
> Hence, my understanding would be that if `type="means"' is specified
> the marginal means of the observations ignoring other factors is
> given.  But this doesn't seem to be the case, at least not with an
> unbalanced design.  You can use either your dreamed up example or the
> data that spoon has posted.

On the usual definitions of `balance' both in my example and
Simon's example treatments are `balanced" over blocks (or litters).

...

John Maindonald               email : john.maindonald at anu.edu.au        
Statistical Consulting Unit,  phone : (6249)3998        
c/o CMA, SMS,                 fax   : (6249)5549  
John Dedman Mathematical Sciences Building
Australian National University
Canberra ACT 0200
Australia
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 10:10:09 +0000 (GMT)
From: Bill Simpson <wsi at gcal.ac.uk>
Subject: Re: [R] Installing R on Slackware Linux

Become root: su -

Put the new *.tgz file the same place as the old one was (something
like /usr/local or /usr/local/src).

Unpack it: tar zxvf Rwhatever.tgz

Then read INSTALL for detailed instructions.

Bill

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 10:34:41 +0100 (MET)
From: Torsten Hothorn <hothorn at statistik.uni-dortmund.de>
Subject: Re: [R] Installing R on Slackware Linux

On Wed, 1 Dec 1999, Murray Jorgensen wrote:

> I mostly use Windows, but I am slowly learning to use Linux on my second
> machine. (It came in handy a couple of weeks ago when I had two files to
> sort, each of length about 2 million. Windows sort died after an hour, but
> the Linux sorts took 2-3 minutes each.)
> 
> Anyway the last time I tried installing R in Linux I found out from a
> helpful computer support person that with my distribution (Slackware) it is
> better to work from the source files than binaries. In fact he was so
> helpful that he did it all for me. This was great, except I didn't learn
> how to do it myself. 
> 
> Now I'd like to upgrade from 0.65.1 to 0.90.* and add some packages, but
> this time I'm all on my own. My linux skills are quite limited, but I have
> some books to help me. Is there anything written down somewhere that help
> someone compile and install R who has never compiled or installed anything
> on Linux before?

Well,

get R-0.90.0.tgz, copy it to /usr/src  and then type (as root)

$> tar -xzvf R-0.90.0.tgz	# untar the archive
$> cd R-0.90.0			# change to the R dir
$> ./configure			# create your Makefiles
$> make 			# if the output of configure is ok compile
$> make install			# and install the bin's

All those things are well documented in the FAQ and README's as in all GNU
projects ... :-)

Torsten




> 
> Regards,
> 
> Murray Jorgensen
> 
> Murray Jorgensen,  Department of Statistics,
> University of Waikato,  Hamilton,  New Zealand.  [maj at waikato.ac.nz]
> ______________________________________________________________________
> Hey! Look at this! 
> The survivors are the ones we had time to get the water to. 
> None of the eighteen other variables that we recorded were significant.
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 09:33:56 +0000 (GMT)
From: JJ Dos Santos Ramalho <J.J.Ramalho at bristol.ac.uk>
Subject: [R] nlmin

I'm a very recent user of R. I have been adapting my Splus programmes
and I found only one (important) problem. There exists no function
"nlmin" in R and its substitute, "nlm", does not work well with my kind
of problems, sometimes no achieving convergence, other tines
"converging" to impossible values. My models are highly nonlinear and
are to be estimated by both GMM and empirical likelihood methods.

Is there any alternative nonlinear optimization command in R? In the
help file it is said that "nlm" is only a preliminary version, is it
expected to replace/improve it soon? Does anyone have any alternative
algorithm?

Thanks for your help,

Joaquim Ramalho
Department of Economics
University of Bristol

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 10:59:24 +0100 (MET)
From: Jim Lindsey <jlindsey at alpha.luc.ac.be>
Subject: Re: [R] nlmin

> 
> 
> I'm a very recent user of R. I have been adapting my Splus programmes
> and I found only one (important) problem. There exists no function
> "nlmin" in R and its substitute, "nlm", does not work well with my kind
> of problems, sometimes no achieving convergence, other tines
> "converging" to impossible values. My models are highly nonlinear and
> are to be estimated by both GMM and empirical likelihood methods.

I have also been using nlm for the past 4-5 years in R and for another
5-10 years before that as a Fortran program. Most of my problems are
also highly nonlinear and I rarely have had a problem unless the model
is unsuitable for the data. nlm has several arguments that can be
modified to aid in convergence. If you obtain impossible values, then
you appear to have a constrained optimization problem. Often parameter
transformation can fix this (e.g. log for positive values, logit if
between 0 and 1). Constrained optimization is a difficult problem
for which really good algorithms are not available. All of the
numerical analysts that I have spoken to agree that the algorithm in
nlm for unconstrained optimization without supplying analytic
derivatives is about the best available. Note that, as of 0.90, you
can supply the derivatives to nlm, which may also solve your problem
(although my experience is that it makes little difference if the
model is suitable for the data). Jim

> 
> Is there any alternative nonlinear optimization command in R? In the
> help file it is said that "nlm" is only a preliminary version, is it
> expected to replace/improve it soon? Does anyone have any alternative
> algorithm?
> 
> Thanks for your help,
> 
> Joaquim Ramalho
> Department of Economics
> University of Bristol
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 10:16:33 +0000 (GMT)
From: Prof Brian D Ripley <ripley at stats.ox.ac.uk>
Subject: Re: [R] nlmin

On Wed, 1 Dec 1999, JJ Dos Santos Ramalho wrote:

> 
> I'm a very recent user of R. I have been adapting my Splus programmes
> and I found only one (important) problem. There exists no function
> "nlmin" in R and its substitute, "nlm", does not work well with my kind
> of problems, sometimes no achieving convergence, other tines
> "converging" to impossible values. My models are highly nonlinear and
> are to be estimated by both GMM and empirical likelihood methods.
> 
> Is there any alternative nonlinear optimization command in R? In the
> help file it is said that "nlm" is only a preliminary version, is it
> expected to replace/improve it soon? Does anyone have any alternative
> algorithm?

Yes, yes. Note, though that nlm was improved for 0.90.0 and can now
make use of gradient information.  Does your application have known
derivatives? (I know nlmin does not use them.)  The aim is to
allow alternative methods within the nlm function fairly soon (a couple
of months).  One issue to allow the methods to be used recursively,
which means basing them on C code not Fortran code.


- -- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 08:11:08 -0500
From: partha_bagchi at hgsi.com
Subject: Re: Summary: [R] Wanted: online Introduction to R

One interesting page to consider would be John Pezzullo's interactive Stats
page:
http://members.aol.com/johnp71/javastat.html



                                                                                                              
                    Clive Jenkins                                                                             
                    <clive.jenkins at clara        To:     Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>         
                    .net>                       cc:     r-help at stat.math.ethz.ch                              
                    Sent by:                    Subject:     Re: Summary: [R] Wanted: online Introduction to  
                    owner-r-help at stat.ma        R                                                             
                    th.ethz.ch                                                                                
                                                                                                              
                                                                                                              
                    11/24/99 03:53 PM                                                                         
                                                                                                              
                                                                                                              




Peter Dalgaard BSA wrote:
>
> Clive Jenkins <clive.jenkins at clara.net> writes:
>
> > An excellent on-line book for the more advanced reader, especially
> > chapters 14 and 15 that deal with Statistics and Data Modeling:
> > "Numerical Recipes in C: the Art of Scientific Computing" (ISBN
> > 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. A
> > Fortran version is also available, and both exist in PostScript and
PDF.
> > http://www.ulib.org/webRoot/Books/Numerical_Recipes/
>
> Um, not to put too fine a point on it: That is not a book I'd
> recommend, and particularly not for the statistics sections. It's a
> reasonable introductory text to numerical analysis subjects, but
> according to people who really know the stuff, it is not to be trusted
> in the details (there's an online reference to the criticism, but I
> can't remember it offhand), and their software licencing is.... (don't
> get me started!)
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

OK, I stand corrected. What I wrote was not from the point of view of a
reviewer who has thoroughly researched the field. I am no specialist in
statistics and write with no authority. However, out of the limited
amount of material that I did find on the web, this book did provide me
with a lot of useful formulae for various distributions, t-tests,
F-tests, chi^2, regression ... and all the things that are probably
taken
for granted by those whose daily lives are dedicated to Statistics.

If any of you know of better on-line resources, then please spare a
minute and enlighten us.

Clive Jenkins.

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
- -.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._



- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 15:17:14 +0100 (MET)
From: Kjetil Kjernsmo <kjetil.kjernsmo at astro.uio.no>
Subject: [R] Applying a function of several variables to data 

Dear all,

After looking at several packages I decided I would use R for my thesis
work (we've even got a site license for S-plus), so I'm learning.

I have run into a problem, and nobody on the house has a solution, so I'm
wondering if anybody out there can help. 
I've got two functions of four variables, one outputs a scalar, the other
an array, and I want to be able to give an array as a parameter for any
(or none) of the variables, and get a multidimensional array of
corresponding dimensions out, with all combinations. In the case of two
variables it is easy to do with outer(), and I have looked if apply() 
could do this, but found only examples where there is a function of one
variable. Obviously, I could do it with a for-loop at some level, but
after reading so many bad things about for-loops, it itches in my
estheticle thinking about it... :-) Is there a nicer way to do this?

Best,

Kjetil
- -- 
Kjetil Kjernsmo
Graduate astronomy-student                    Problems worthy of attack
University of Oslo, Norway            Prove their worth by hitting back
E-mail: kjetikj at astro.uio.no                                - Piet Hein
Homepage <URL:http://www.astro.uio.no/~kjetikj/>
Webmaster at skepsis.no 

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 09:55:41 -0500
From: Duncan Temple Lang <duncan at rice.research.bell-labs.com>
Subject: Re: [R] R and XML -- a near perfect combination?

The great thing about data exchange is that at least two systems have
to be involved in the exchange (for it to be non-trivial!)  John
Chambers, myself and others have been discussing XML _joint_
integration into several projects - Omegahat, R and S.  

The interesting thing from the general perspective (rather than
a particular project and pair of interacting applications)
is in defining some DTDs that people are comfortable using.
This applies not only to data frames but also model specification,
results, etc.

>From the implementation perspective of reading XML, Omegahat has it
automatically. It would be nice to have the one shared by both R and S
and this was on my list of things to do.  Irrespective of the choice
of C/C++ parsing system, one approach I was thinking of in R is to use
a closure that is associated with a DTD. Thinking out aloud, the idea
is to have functions in the closure that correspond to the different
elements in the DTD.  As the parser discovers each element instance,
it calls the associated function in the closure (or a default one)
with the attribute lists and potentially the "identifier" for the
parent node in the resulting tree (although R and S aren't exactly
designed for trees).

(If this doesn't make any sense, it could be attributed to too little
sleep!)

D.



> Cc: r-help at stat.math.ethz.ch
> References: <Pine.LNX.4.10.9911301721080.3817-100000 at www.approximity.com>
> From: rossini at biostat.washington.edu (A.J. Rossini)
> Date: 30 Nov 1999 15:59:59 -0800
> Lines: 33
> Sender: owner-r-help at stat.math.ethz.ch
> Precedence: bulk
> 
> 
> >>>>> "c" == cys  <cys at www.approximity.com> writes:
> 
>     c> Did anybody alreay write a XML parser for R?  XML, as we will
>     c> have tons of data-interchange with all sorts of other programs
>     c> and XML is good for giving meaning to raw data.
> 
>     c> Any pointers/comments would be highly appreciated.
> 
> It's a nice format, if you know what you are doing.  The main thought
> that I've been having for what you are proposing (data exchange of
> datasets) would be to write an converter from your XML format to a
> text representation of the corresponding data.frame.  
> 
> Reasonably simple, plus you are free to use whatever your choice of
> parser language is (C++, Java, Python, whatever).  Plus, you can grow
> it (a simple list is easy, adding row/col names isn't too hard,
> etc...  Do it using pipes, and you will be fine for Unix and NT.
> 
> The only problem with a generic parser is the necessity of doing XML
> to XML conversion, since you can't be sure that everyone wants to use
> the DTD (or style) that you particularly like.
> 
> best,
> -tony
> 
> -- 
> A.J. Rossini			Research Assistant Professor of Biostatistics 
> Center for AIDS Research/HMC	Biostatistics/Univ. of Washington
> Box 359931			Box 357232
> 206-731-3647 (3693=fax)		206-543-1044 (3286=fax)
> rossini at u.washington.edu	rossini at biostat.washington.edu
> http://www.biostat.washington.edu/~rossini/
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


- -- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan

      "Languages shape the way we think, and determine what 
       we can think about."        
                                      Benjamin Whorf
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 01 Dec 1999 17:09:17 +0100
From: mathieu <mathieu.ros at free.fr>
Subject: [R] problem installing R 0.90

- --------------0959452E704C9F02EEB4171F
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: 8bit

hello all,
when running ./configure in my [new] R-0.90 directory, the process stop
at the following step :

(...)
checking whether g77 and gcc agree on int and double...

can anybody tell me what's the problem (I believe it is due to g77 but
what can I do?)
thanks,
    Mathieu

I'm using Redhat 6.0 on a  Intel P90

- --
- ----------------------------------------------------------------------
 Mathieu Ros - 13 rue bvire - 38000 GRENOBLE - 04 76 491 370
 http://www.multimania.com/mathieuros/index2.html
 DESS ingnierie mathmatique (biostatistiques)
 Universite Joseph Fourier, Grenoble
- ----------------------------------------------------------------------
La science dtient la vrit, ne vous laissez pas avoir par les faits.



- --------------0959452E704C9F02EEB4171F
Content-Type: text/html; charset=us-ascii
Content-Transfer-Encoding: 7bit

<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
hello all,
<br>when running ./configure in my [new] R-0.90 directory, the process
stop at the following step :
<p>(...)
<br>checking whether g77 and gcc agree on int and double...
<p>can anybody tell me what's the problem (I believe it is due to g77 but
what can I do?)
<br>thanks,
<br>&nbsp;&nbsp;&nbsp; Mathieu
<p>I'm using Redhat 6.0 on a&nbsp; Intel P90
<pre>--&nbsp;
- ----------------------------------------------------------------------
&nbsp;Mathieu Ros - 13 rue b&eacute;vi&egrave;re - 38000 GRENOBLE - 04 76 491 370
&nbsp;<A HREF="http://www.multimania.com/mathieuros/index2.html">http://www.multimania.com/mathieuros/index2.html</A>
&nbsp;DESS ing&eacute;nierie math&eacute;matique (biostatistiques)
&nbsp;Universite Joseph Fourier, Grenoble
- ----------------------------------------------------------------------
La science d&eacute;tient la v&eacute;rit&eacute;, ne vous laissez pas avoir par les faits.</pre>
&nbsp;</html>

- --------------0959452E704C9F02EEB4171F--

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 17:57:25 +0100 (MET)
From: Martin Maechler <maechler at stat.math.ethz.ch>
Subject: Re: [R] graphics

 >>>>> Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> adds:

    PD> Jim Lindsey <jlindsey at alpha.luc.ac.be> writes:
    >> I have been receiving complaints that my libraries no longer give
    >> reasonable graphics with R0.90. I have been replying that I have not
    >> changed anything. Among my travels (presently in Umea), I have
    >> finally had a chance to take a look. The best way to describe the
    >> current default graphics is HORRIBLY UGLY. The R core member who
    >> made those changes should buy glasses to see the screen better
    >> instead of imposing his near sightedness on the rest of us. The
    >> worst is that the most important options that have been modified are
    >> RO so we can do nothing. As PS graphics are also knackered, we
    >> currently have no way of viewing a reasonable graph produced by R.

    PD> Well, the font sizes are as I have had them for ages: 12pt on a
    PD> 100dpi assumed resolution. If that's too large, fine, complain and
    PD> if you gain a sufficient following we might reduce it to 10pt. The
    PD> old code would give you 100dpi or 75dpi fonts depending on which
    PD> one came first on your font path and was available at the desired
    PD> size, leading to general madness. If it bothers you enough, use
    PD> fix(X11) and change the default for the pointsize argument.

After a quite a bit discussion (incl. some own thought), I tend to vote
with Jim Lindsey: 
We *should* reduce the default font size:  Because the font size is 
relatively large, the margins (measured in characters via "mar") become
large as well, and (as Jim pointed out to some of us)
now use more than 50% of the device surface.

Fontsize = 10 (pt) looks more reasonable, to me, too.
(However, I propose to make it an option, see below).

    PD> The postscript is truly bug-ridden, but the latest snapshot should
    PD> be much better.

    >> Is there any way to set the default par options, say in Rprofile,
    >> without having a graphics window pop up at startup?

    PD> Nope, but we should probably have something like ps.options there,
    PD> the par() effect is also messing up example(): the code cannot set
    PD> ask=TRUE so multiple graphics in an example just fly by, unless the
    PD> user sets the parameter.
yes, definitely a reasonable feature request! -- see below

BUT, for a first "quick fix" : Why not change X11's argument
     pointsize = 12
to
     pointsize = .Options$X11pointsize
(we already have X11colortype !).

Now back to the feature request:

Do we want  par.defaults() for this?
It would have the same arguments as par()  plus additional
   device = .Options$device
with further possibility   
   device = "all"
i.e., by default,  par.defaults()  would set things only for the default
device, but there'd be a possibility to set these for all devices.

Note that
- -  This would lead to considerable side effects.
   [Starting a device and setting par()s would not be portable,
    for complete portability you'd have to first set (or reset) the
    par.defaults()]
- -  for  device = "postscript", 
   we could allow further arguments as those of ps.options() and postscript()
   and e.g. for device = "X11" ( = default on non-gnome Unix),
   one should allow arguments of X11/x11() such as pointsize, colortype, ...

- -----

When feature requesting: What I have wanted more than once is an
     par(reset = TRUE)
which would set all the par()s back to how they were when the device was
opened.   

     par.defaults(reset = TRUE)

would analogously remove all `site/user specific' par defaults
(effect: as if  par.defaults() was never set).
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 18:39:54 +0100 (MET)
From: Jim Lindsey <jlindsey at alpha.luc.ac.be>
Subject: Re: [R] graphics

> Do we want  par.defaults() for this?
> It would have the same arguments as par()  plus additional
>    device = .Options$device
> with further possibility   
>    device = "all"
> i.e., by default,  par.defaults()  would set things only for the default
> device, but there'd be a possibility to set these for all devices.
> 
> Note that
> -  This would lead to considerable side effects.
>    [Starting a device and setting par()s would not be portable,
>     for complete portability you'd have to first set (or reset) the
>     par.defaults()]
> -  for  device = "postscript", 
>    we could allow further arguments as those of ps.options() and postscript()
>    and e.g. for device = "X11" ( = default on non-gnome Unix),
>    one should allow arguments of X11/x11() such as pointsize, colortype, ...

Is there a strong reason why a call to par with no device active must
open a window? If this 'feature' can easily be removed, then I would
be satisfied as I could then put my default par settings in Rprofile
without a window opening at startup. Of course, the above is a far
better idea but perhaps more difficult to implement.

(By the way, for those on the list who have not had access to all the
discussion about this in the last couple of days, Peter has pointed
out to me that X11 - note capital X - can be redefined in Rprofile so
that pointsize has any desired size. This is now working very well for
me.)

> 
> -----
> 
> When feature requesting: What I have wanted more than once is an
>      par(reset = TRUE)
> which would set all the par()s back to how they were when the device was
> opened.   
> 
>      par.defaults(reset = TRUE)
> 
> would analogously remove all `site/user specific' par defaults
> (effect: as if  par.defaults() was never set).

I'll certainly vote for those.
  Jim
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: 01 Dec 1999 19:28:24 +0100
From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
Subject: Re: [R] graphics

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> BUT, for a first "quick fix" : Why not change X11's argument
>      pointsize = 12
> to
>      pointsize = .Options$X11pointsize
> (we already have X11colortype !).

Which is a mess! We also have

.PostScript.Options$pointsize

So wouldn't it be more obvious to use

.X11.Options$pointsize

(and set it with X11.options(pointsize=12))?

If we go to 10pt default, we also need to discuss the multiframe
scaling issue. The current rules are that if there is two rows and/or
columns, reduce font size to 80%, if there are three or more reduce to
50% and a 5pt font @100dpi is a tad small. Note that this rule is
*device independent*, so one would have to check that it still looks
reasonable on postscript and windows. I think it works out OK if one sets the
rule to 60% giving a 6pt font, but I'd like someone elses eyes on
that. 

> Now back to the feature request:
> 
> Do we want  par.defaults() for this?
> It would have the same arguments as par()  plus additional
>    device = .Options$device
> with further possibility   
>    device = "all"
> i.e., by default,  par.defaults()  would set things only for the default
> device, but there'd be a possibility to set these for all devices.
> 
> Note that
> -  This would lead to considerable side effects.
>    [Starting a device and setting par()s would not be portable,
>     for complete portability you'd have to first set (or reset) the
>     par.defaults()]
> -  for  device = "postscript", 
>    we could allow further arguments as those of ps.options() and postscript()
>    and e.g. for device = "X11" ( = default on non-gnome Unix),
>    one should allow arguments of X11/x11() such as pointsize, colortype, ...
> 
> -----
> 
> When feature requesting: What I have wanted more than once is an
>      par(reset = TRUE)
> which would set all the par()s back to how they were when the device was
> opened.   
> 
>      par.defaults(reset = TRUE)
> 
> would analogously remove all `site/user specific' par defaults
> (effect: as if  par.defaults() was never set).

Hmm. I'm not so sure we're really gaining much from an elaborate
par.default() function. If one desires, one could do it via the
startup function, simply by a call to par based on the options).

For instance, try changing X11 to

X11<-function (display = "", width = 7, height = 7, pointsize = 12, 
    gamma = 1, colortype = options()$X11colortype, maxcubesize = 256) 
{
    .Internal(X11(display, width, height, pointsize, gamma, colortype, 
    maxcubesize))
    par(ask=T)
}

and then

example(barplot)
dev.off()
par(ask=F)
example(barplot)

- -- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: 01 Dec 1999 19:41:07 +0100
From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
Subject: Re: [R] graphics

Jim Lindsey <jlindsey at alpha.luc.ac.be> writes:

> Is there a strong reason why a call to par with no device active must
> open a window? If this 'feature' can easily be removed, then I would
> be satisfied as I could then put my default par settings in Rprofile
> without a window opening at startup. Of course, the above is a far
> better idea but perhaps more difficult to implement.

I'm sure it can be worked around, but the issue is that the par()
settings must go to a device, so if none is open, we open the default
one, by the default method, which opens the window. The obvious fix,
not to open the window until something is actually drawn would have
the consequence of making a direct X11() call an apparent no-op... And
some of the things that par() can do involves requests to the window
system about the plotting window, I suspect.

- -- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 08:36:27 +1300
From: Lyndon Drake <lyndon at stat.auckland.ac.nz>
Subject: Re: [R] R and XML -- a near perfect combination?

On Tue, Nov 30, 1999 at 05:25:17PM -0800, cys at www.approximity.com wrote:
> Did anybody alreay write a XML parser for R?
> XML, as we will have tons of data-interchange with
> all sorts of other programs and XML is good for giving
> meaning to raw data.

A good C XML library is libxml (wierd name, I know :-), at
http://rpmfind.net/veillard/XML/.  It's the one used in GNOME, but it is
supposed to be portable.  I don't know how well it would work on Win32,
but it would be worth looking at.  It is licensed under the LGPL.

- -- 
Lyndon Drake                       | Desktop:      http://www.gnome.org
isenguard                          | Mail client:  http://www.mutt.org
ICQ#: 12558803                     | Editor:       http://www.vim.org
http://stat.auckland.ac.nz/~lyndon | OS:           http://www.linux.com
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 08:47:36 +1300
From: Ross Ihaka <ihaka at stat.auckland.ac.nz>
Subject: Re: [R] graphics

I think I mentioned this a while ago ...

The problem I have with the new X11 driver is that it appears to ignore
the actual DPI (dots per inch) of the X server and use 100 DPI.  My machine
is most definitely 75 DPI (I explicitly set it when I start the server).

The fonts I get from R are much too large and do not agree with those
displayed in xfontsel (which I think shows the official story).

	Ross
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 02 Dec 1999 08:51:47 +1100
From: John Maindonald <john.maindonald at anu.edu.au>
Subject: [R] Plot Character Sizes in rw-0.90.0

I have two supposedly identical installations, one under Windows 95,
and the other (at home) under Windows 98.  The puzzle is that under 
my Windows 98 installation, symbols plotted by default or with pch
come out huge, at about 2.2 times the height of the axis labels.
Setting cex=0.5 seems about what is needed to fix the heights.

On the Windows 95 installation, the symbols come out just a little
smaller than the height of the axis labels.

Unless someone has an immediate explanation, maybe I need to send a
bug report from my home machine?

A further point is that, contrary to the documentation of par(),
the
setting of mkh seems to have no effect on the height of symbols 
plotted with pch, e. g.
plot(1:4,1:4,pch=1,mkh=0.2)


John Maindonald               email : john.maindonald at anu.edu.au        
Statistical Consulting Unit,  phone : (6249)3998        
c/o CMA, SMS,                 fax   : (6249)5549  
John Dedman Mathematical Sciences Building
Australian National University
Canberra ACT 0200
Australia

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 17:01:33 -0500 
From: "Carel, Roland" <rcarel at netgenics.com>
Subject: RE: [R] R and XML -- a near perfect combination?

>On Tue, Nov 30, 1999 at 05:25:17PM -0800, cys at www.approximity.com wrote:
>> Did anybody alreay write a XML parser for R?
>> XML, as we will have tons of data-interchange with
>> all sorts of other programs and XML is good for giving
>> meaning to raw data.

>A good C XML library is libxml (wierd name, I know :-), at
>http://rpmfind.net/veillard/XML/.  It's the one used in GNOME, but it is
>supposed to be portable.  I don't know how well it would work on Win32,
>but it would be worth looking at.  It is licensed under the LGPL.

Why not use the java parser from the IBM Alpha Works:
http://www.alphaworks.ibm.com/tech/dynamicxmlforjava
It should be easily portable to just about any platform.

- -Roland Carel
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: 01 Dec 1999 14:18:24 -0800
From: rossini at biostat.washington.edu (A.J. Rossini)
Subject: Re: [R] R and XML -- a near perfect combination?

>>>>> "CR" == Carel, Roland <rcarel at netgenics.com> writes:

    >> A good C XML library is libxml (wierd name, I know :-), at
    >> http://rpmfind.net/veillard/XML/.  It's the one used in GNOME,
    >> but it is supposed to be portable.  I don't know how well it
    >> would work on Win32, but it would be worth looking at.  It is
    >> licensed under the LGPL.

    CR> Why not use the java parser from the IBM Alpha Works:
    CR> http://www.alphaworks.ibm.com/tech/dynamicxmlforjava It should
    CR> be easily portable to just about any platform.

Would be fine with Omegahat, but probably not R.  Actually, maybe you
could get to it via RJava, but it would probably require a bit more
thought.  There might be licensing issues wrt to R's GPL, though,
depending which IBM license it's under...

best,
- -tony

- -- 
A.J. Rossini			Research Assistant Professor of Biostatistics 
Center for AIDS Research/HMC	Biostatistics/Univ. of Washington
Box 359931			Box 357232
206-731-3647 (3693=fax)		206-543-1044 (3286=fax)
rossini at u.washington.edu	rossini at biostat.washington.edu
http://www.biostat.washington.edu/~rossini/

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: 01 Dec 1999 23:39:18 +0100
From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
Subject: Re: [R] Plot Character Sizes in rw-0.90.0

John Maindonald <john.maindonald at anu.edu.au> writes:

> I have two supposedly identical installations, one under Windows 95,
> and the other (at home) under Windows 98.  The puzzle is that under 
> my Windows 98 installation, symbols plotted by default or with pch
> come out huge, at about 2.2 times the height of the axis labels.
> Setting cex=0.5 seems about what is needed to fix the heights.
> 
> On the Windows 95 installation, the symbols come out just a little
> smaller than the height of the axis labels.

Peculiar. They're supposed to be roughly the width of a "0" in the
base font. The Postscript driver had a bug in the size calculations,
in that it subtracted 18 pixels from the radius, but that wouldn't
seem to be your problem if setting cex fixes things up.

What does par("cra") and par("csi") say on your respective systems?
(par("cra")[2]/par("csi") should be the dpi of your device)

> Unless someone has an immediate explanation, maybe I need to send a
> bug report from my home machine?
> 
> A further point is that, contrary to the documentation of par(),
> the
> setting of mkh seems to have no effect on the height of symbols 
> plotted with pch, e. g.
> plot(1:4,1:4,pch=1,mkh=0.2)

Yes, I believe we already have a bug report to that effect.

- -- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 22:46:14 +0000 (GMT)
From: Prof Brian D Ripley <ripley at stats.ox.ac.uk>
Subject: Re: [R] R and XML -- a near perfect combination?

On 1 Dec 1999, A.J. Rossini wrote:

> 
> >>>>> "CR" == Carel, Roland <rcarel at netgenics.com> writes:
> 
>     >> A good C XML library is libxml (wierd name, I know :-), at
>     >> http://rpmfind.net/veillard/XML/.  It's the one used in GNOME,
>     >> but it is supposed to be portable.  I don't know how well it
>     >> would work on Win32, but it would be worth looking at.  It is
>     >> licensed under the LGPL.
> 
>     CR> Why not use the java parser from the IBM Alpha Works:
>     CR> http://www.alphaworks.ibm.com/tech/dynamicxmlforjava It should
>     CR> be easily portable to just about any platform.
> 
> Would be fine with Omegahat, but probably not R.  Actually, maybe you
> could get to it via RJava, but it would probably require a bit more
> thought.  There might be licensing issues wrt to R's GPL, though,
> depending which IBM license it's under...

Many users of R do not run Java; for example no one porting R to Windows
does on their Windows machines AFAIK. We really do need something that
compiles on standard C compilers with minimal baggage, as total download
size is a significant issue.

- -- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Wed, 1 Dec 1999 19:37:28 -0500
From: "Yves Gauvreau" <cyg at sympatico.ca>
Subject: [R] Meaning?

Hi,

Sorry to ask this but what is the meaning of "AFAIK". From a darn Frenchman!

Regards.

Yves

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 02 Dec 1999 13:39:10 +1300
From: Murray Jorgensen <maj at waikato.ac.nz>
Subject: Re: [R] Installing R on Slackware Linux

I'd like to thank Markus Jantti, John Maindonald, Peter Malewski, Mathew
Wiener and Jonathan Yuen for their help. As most pointed out, the .INSTALL
file is quite good. Just the same, for a linux novice like me it did help
to have much the same thing said in several different ways.

I still don't know what to do with the old 0.65.1 directory tree. [ It was
a minor triumph of mine when I figured out how to use the "find" command
properly and by searching for config.status, which one of the replies let
me know was a file in the tree, actually succeeded in finding the R0.65.1
directory tree.]

Now what do I do?

* Delete the old directory tree before installing the new version?
  (and risk ending up with no R at all)
* Leave the old directory tree and install the new version?
   (and possibly still get the old version when I type "R")

Or maybe uninstalling is more complicated than deleting the tree - it
certainly is in Windows!

I truly do hope that there are lurking newbies out there that make my
asking such basic questions worthwhile!


Murray Jorgensen,  Department of Statistics,  U of Waikato, Hamilton, NZ
- -----[+64-7-838-4773]---------------------------[maj at waikato.ac.nz]-----
"Doubt everything or believe everything:these are two equally convenient
strategies. With either we dispense with the need to think."
http://www.cs.waikato.ac.nz/stats/Staff/maj.html       - Henri Poincare'

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: 01 Dec 1999 21:15:42 -0600
From: Douglas Bates <bates at stat.wisc.edu>
Subject: Re: [R] Meaning?

"Yves Gauvreau" <cyg at sympatico.ca> writes:

> Sorry to ask this but what is the meaning of "AFAIK". From a darn Frenchman!

AFAIK => As far as I know

It is one of those acronyms that is sometimes adopted in e-mail to save typing.
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 08:53:06 +0100 (CET)
From: Kurt Hornik <Kurt.Hornik at ci.tuwien.ac.at>
Subject: Re: [R] graphics

>>>>> Peter Dalgaard BSA writes:

> Martin Maechler <maechler at stat.math.ethz.ch> writes:
>> BUT, for a first "quick fix" : Why not change X11's argument
>> pointsize = 12
>> to
>> pointsize = .Options$X11pointsize
>> (we already have X11colortype !).

> Which is a mess! We also have

> .PostScript.Options$pointsize

> So wouldn't it be more obvious to use

> .X11.Options$pointsize

> (and set it with X11.options(pointsize=12))?

Why would we need a separate options variable anyway?  We might as well
do .Options$PostScript.foo instead ... or .Options$PostScript$foo ...

If we do the above we might also want an X11.options() in analogy to the
ps.options() which already exists, and perhaps also pictex.options()
etc.

???

> If we go to 10pt default, we also need to discuss the multiframe
> scaling issue. The current rules are that if there is two rows and/or
> columns, reduce font size to 80%, if there are three or more reduce to
> 50% and a 5pt font @100dpi is a tad small. Note that this rule is
> *device independent*, so one would have to check that it still looks
> reasonable on postscript and windows. I think it works out OK if one
> sets the rule to 60% giving a 6pt font, but I'd like someone elses
> eyes on that.

>> Now back to the feature request:
>> 
>> Do we want  par.defaults() for this?
>> It would have the same arguments as par()  plus additional
>> device = .Options$device
>> with further possibility   
>> device = "all"
>> i.e., by default,  par.defaults()  would set things only for the default
>> device, but there'd be a possibility to set these for all devices.
>> 
>> Note that
>> -  This would lead to considerable side effects.
>> [Starting a device and setting par()s would not be portable,
>> for complete portability you'd have to first set (or reset) the
>> par.defaults()]
>> -  for  device = "postscript", 
>> we could allow further arguments as those of ps.options() and postscript()
>> and e.g. for device = "X11" ( = default on non-gnome Unix),
>> one should allow arguments of X11/x11() such as pointsize, colortype, ...
>> 
>> -----
>> 
>> When feature requesting: What I have wanted more than once is an
>> par(reset = TRUE)
>> which would set all the par()s back to how they were when the device was
>> opened.   
>> 
>> par.defaults(reset = TRUE)
>> 
>> would analogously remove all `site/user specific' par defaults
>> (effect: as if  par.defaults() was never set).

> Hmm. I'm not so sure we're really gaining much from an elaborate
> par.default() function. If one desires, one could do it via the
> startup function, simply by a call to par based on the options).

> For instance, try changing X11 to

> X11<-function (display = "", width = 7, height = 7, pointsize = 12, 
>     gamma = 1, colortype = options()$X11colortype, maxcubesize = 256) 
> {
>     .Internal(X11(display, width, height, pointsize, gamma, colortype, 
>     maxcubesize))
>     par(ask=T)
> }

> and then

> example(barplot)
> dev.off()
> par(ask=F)
> example(barplot)

Agreed.

- -k
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 09:38:30 +0100 (MET)
From: Martin Maechler <maechler at stat.math.ethz.ch>
Subject: par(mkh) {was [R] Plot Character Sizes in rw-0.90.0}

    PD> John Maindonald <john.maindonald at anu.edu.au> writes:

      JM>      <....>

      JM> A further point is that, contrary to the documentation of par(),
      JM> the setting of mkh seems to have no effect on the height of symbols
      JM> plotted with pch, e. g.  plot(1:4,1:4,pch=1,mkh=0.2)

    PD> Yes, I believe we already have a bug report to that effect.

True; question is : What should be fixed?  Documentation or implementation?

Here the Status:

   Contrary to S, in R, we have always been using  par("cex") and the
   <highlevel plot> cex argument  *both* for text and all graphical symbols.
   S uses mkh for  pch=<integer>   symbols and
	  cex for  pch=<character> ones and text
   which is really not what we (R&R, initially) wanted to copy.

   In R, mkh settings have always been completely ignored.  
   In spite of this, par() (and the internal code in  par.c & graphics.c) have
   been set up to allow setting and querying mkh.

Now, there are several possibilities of which I'd advocate mainly 1) or 2) 
[I'm talking about implementation; documentation must be updated in any case]:

1) Implementation unchanged + using  mkh gives a warning saying 
   that mkh is practically ignored.
   
2) setting par(mkh) or  <highlevelplot>(* , mkh = ..)
    
    gives a warning (``mkh : setting cex'')
    and then behaves as if "cex" was used.

3a) Even more S compatibility:
   Setting par(mkh) or  <highlevelplot>(* , mkh = ..)
   changes "cex" accordingly *IF* pch=<numeric> .

3b) Similar but more logical; need some "notation" : 
    The symbol size used in the core function plot.xy()  is
           cexbase * Pcex   (--> plot.c, l.1089)

    where "cexbase" is par("cex") and  Pcex is the "cex" argument of 
    plot(),points(),...

    Now we could change this to
           cexbase * mkh * Pcex
    for the case of numeric pch (internally pch <= 31 or something) where
    mkh is *either* par("mkh") or the mkh arg. of plot.xy().


4) complete S compatibility (cex *not* working for pch=<numeric>)

   This is completely out of question for me!


Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO D10	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 09:48:27 +0000 (GMT)
From: Bill Simpson <wsi at gcal.ac.uk>
Subject: Re: [R] graphics

As I understand it, all this discussion is referring to how the graphics
look on the screen. Maybe it is pointless to mention the following, but
here I go:
- - what is on the screen (X11) should agree with what is printed
(dev.print)
- - the default sizes of letters and symbols are too small in
ouput produced by dev.print. Should be double the size. I always use
cex=2, but numerous things get buggered up. In my opinion, the current
behaviour is a bad legacy from S. Default S plots use labels and symbols
that are too small. Remember that plots submitted to journals
and book publishers always get scaled down, so in the original version
they have to be quite large. Take a look at V&R, pp16-17 for plots whose
axis labels are smaller than surrounding main text.

Bill

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 20:23:20 +1100 (EST)
From: John Maindonald <john.maindonald at anu.edu.au>
Subject: [R] Large plot symbols (with pch = 1 etc)

On my home (Windows 98) machine I find:
> par()$cra
[1] 42 16
> par()$csi
[1] 0.1666667
> 

On my work machine I believe I had
par()$cra
[1] 17 16

So it looks as though R is reading the width wrongly,
and that it is the width that is somehow used to
determine the plot character size.

Incidentally I noted Brian's comment that R had misread
his character dimension information wrongly.  I have a
Matrox MM2 board on my Windows 98 (SE) machine.  
I understand he will be using a Matrox G200.  Is there a 
Matrox connection?

Regards

John Maindonald               email : john.maindonald at anu.edu.au        
Statistical Consulting Unit,  phone : (6249)3998        
c/o CMA, SMS,                 fax   : (6249)5549  
John Dedman Mathematical Sciences Building
Australian National University
Canberra ACT 0200
Australia
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 09:39:55 +0000 (GMT)
From: Prof Brian D Ripley <ripley at stats.ox.ac.uk>
Subject: Re: [R] graphics

On Thu, 2 Dec 1999, Bill Simpson wrote:

> they have to be quite large. Take a look at V&R, pp16-17 for plots whose
> axis labels are smaller than surrounding main text.

There are no plots on those pages! Presumably you have an old edition.

It is quite common in journals to have minor labels smaller than the main
text: after all the footnotes and index are smaller than the main text in
our book. Those plots have been checked and approved (three times) by
professional copy editors.

What you get with dev.print is entirely up to you: it depends on how you
set pointsize and in particular if you like looking at plots with your head
turned through 90^o. (I get very frustrated with students who produce
landscape plots that way: the default pointsize is relative to a much
smaller plot if it is portrait not the default (for some reason that has
always escaped me) landscape.)

- -- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 11:03:09 +0000 (GMT)
From: Bill Simpson <wsi at gcal.ac.uk>
Subject: Re: [R] graphics

On Thu, 2 Dec 1999, Prof Brian D Ripley wrote:

> On Thu, 2 Dec 1999, Bill Simpson wrote:
> 
> > they have to be quite large. Take a look at V&R, pp16-17 for plots whose
> > axis labels are smaller than surrounding main text.
> 
> There are no plots on those pages! Presumably you have an old edition.
2nd edition, figs 1.6 and 1.7

> It is quite common in journals to have minor labels smaller than the main
> text: after all the footnotes and index are smaller than the main text in
> our book. Those plots have been checked and approved (three times) by
> professional copy editors.
I know it amounts to taste. My taste is: figure labels should be larger
than surrounding text.

> What you get with dev.print is entirely up to you: it depends on how you
> set pointsize and in particular if you like looking at plots with your head
> turned through 90^o.
I tried setting pointsize in the past without success. Maybe it works now
and I should try again. In the past the only solution was cex=2

> (I get very frustrated with students who produce
> landscape plots that way: the default pointsize is relative to a much
> smaller plot if it is portrait not the default (for some reason that has
> always escaped me) landscape.)
I agree that portrait should be the default. I always set
horizontal=FALSE.

Bill

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 10:33:11 +0000 (GMT)
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
Subject: Re: [R] Large plot symbols (with pch = 1 etc)

> Date: Thu, 2 Dec 1999 20:23:20 +1100 (EST)
> From: John Maindonald <john.maindonald at anu.edu.au>
> 
> On my home (Windows 98) machine I find:
> > par()$cra
> [1] 42 16
> > par()$csi
> [1] 0.1666667
> > 
> 
> On my work machine I believe I had
> par()$cra
> [1] 17 16
> 
> So it looks as though R is reading the width wrongly,
> and that it is the width that is somehow used to
> determine the plot character size.
> 
> Incidentally I noted Brian's comment that R had misread
> his character dimension information wrongly.  I have a
> Matrox MM2 board on my Windows 98 (SE) machine.  
> I understand he will be using a Matrox G200.  Is there a 
> Matrox connection?

It was my laptop (our G200's are primarily Linux), and it is a NeoMagic
256. The problem was with Windows, not R: R acts on what it is told by
Windows, and that was nonsense.  I am fairly sure that problem resides
in the graphics drivers, but we need to work around it.  Not long
before the release of 0.90.0 he and I were getting very different
font and symbol sizes on our laptops from identical code.

As far as I can see in the Nov 19th change Guido changed the cra
setting to come from the character metrics.  That is, cra[1] is set to
what Windows reports as the maximum width of a character in the font.
It looks as if that is unreliable.  I think we should ask it for "O".
Incidentally, I am beginning to learn that Window 98SE is not just
a minor upgrade, so we are going to have to test on that too.

Brian

- -- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: 02 Dec 1999 12:44:06 +0100
From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
Subject: Re: [R] Installing R on Slackware Linux

Murray Jorgensen <maj at waikato.ac.nz> writes:

> I'd like to thank Markus Jantti, John Maindonald, Peter Malewski, Mathew
> Wiener and Jonathan Yuen for their help. As most pointed out, the .INSTALL
> file is quite good. Just the same, for a linux novice like me it did help
> to have much the same thing said in several different ways.
> 
> I still don't know what to do with the old 0.65.1 directory tree. [ It was
> a minor triumph of mine when I figured out how to use the "find" command
> properly and by searching for config.status, which one of the replies let
> me know was a file in the tree, actually succeeded in finding the R0.65.1
> directory tree.]
> 
> Now what do I do?
> 
> * Delete the old directory tree before installing the new version?
>   (and risk ending up with no R at all)
> * Leave the old directory tree and install the new version?
>    (and possibly still get the old version when I type "R")
> 
> Or maybe uninstalling is more complicated than deleting the tree - it
> certainly is in Windows!
> 
> I truly do hope that there are lurking newbies out there that make my
> asking such basic questions worthwhile!

Well, it will unpack in a separate directory and you can build and
test the new version there, it is only when you enter "make install"
that you'll be overwriting files in system locations. The R-0.65.1
directory can be kept if you wish.

Normally, no harm comes from installing on top of a previous
installation, but if you want to be sure delete /usr/local/bin/R
and  /usr/local/bin/*Rd* (hoping that nothing else matches the
wildcards...) and "rm -rf /usr/local/lib/R" befor installing.

If something goes haywire, it should still be possible to go to
R-0.65.1, type "make install" and have the old version reinstalled.

All assuming that you used "make install" with the standard locations
the last time round.

- -- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: 02 Dec 1999 14:48:33 +0100
From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
Subject: Re: [R] graphics

Bill Simpson <wsi at gcal.ac.uk> writes:

> As I understand it, all this discussion is referring to how the graphics
> look on the screen. Maybe it is pointless to mention the following, but
> here I go:
> - what is on the screen (X11) should agree with what is printed
> (dev.print)

This is a bit problematic. I'd say that it should be readable before
anything else. If one wants exact preview, use ghostview & friends.
Also for a pleasant working environment (at least with X11), I like to
use unscaled fonts as far as possible.

> - the default sizes of letters and symbols are too small in
> ouput produced by dev.print. Should be double the size. I always use
> cex=2, but numerous things get buggered up. In my opinion, the current
> behaviour is a bad legacy from S. Default S plots use labels and symbols
> that are too small. Remember that plots submitted to journals
> and book publishers always get scaled down, so in the original version
> they have to be quite large. Take a look at V&R, pp16-17 for plots whose
> axis labels are smaller than surrounding main text.

(As Brian pointed out, pointsize is better than cex for this purpose.
Pardon the pun...)

I do agree that the S defaults are a bit small, but it all depends on
what they are to be used for: 

 - as an intermediate tool in model development &c
 - full-page illustration in book/journal
 - half-page, in-text illustration
 - slide

(with increasing text-to-plot ratios). And it also depends on personal
tastes - e.g. Jim Lindsey pretty squarely want to maximize the plot
area, i.e. minimum legible fonts, if I interpret him correctly.

I think I'm with Brian in saying that the plots in V&R are certainly
not seriously bad, and there's not really any cause for assuming that
the sizes of text on a plot are directly related to those in the
running text (unless one has been foolish enough to use the same
font!) They're readable enough and the whole thing is in reasonable
balance. The labels are a bit too close to the axes and tick marks
though....

Incidentally, I reached out for the nearest stats book from the pre-S
era (Breslow&Day, 1980) and found some pretty ugly clashes between
plots and the surrounding text. It isn't easy...

- -- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 16:36:16 +0100
From: "Karl M. Syring" <syring at email.com>
Subject: RE: [R] Meaning?

Yves,
there are ancronym finders (of course) on the web. Try
http://www.ucc.ie/cgi-bin/acronym?rotfl

Regards
Karl


> -----Original Message-----
> From: owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch]On Behalf Of Yves Gauvreau
> Sent: Donnerstag, 2. Dezember 1999 01:37
> To: r-help at stat.math.ethz.ch
> Subject: [R] Meaning?
> 
> 
> Hi,
> 
> Sorry to ask this but what is the meaning of "AFAIK". From a darn 
> Frenchman!
> 
> Regards.
> 
> Yves
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._
> 
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: 02 Dec 1999 17:08:06 +0100
From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
Subject: Re: par(mkh) {was [R] Plot Character Sizes in rw-0.90.0}

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> 1) Implementation unchanged + using  mkh gives a warning saying 
>    that mkh is practically ignored.
>    
> 2) setting par(mkh) or  <highlevelplot>(* , mkh = ..)
>     
>     gives a warning (``mkh : setting cex'')
>     and then behaves as if "cex" was used.
> 
> 3a) Even more S compatibility:
>    Setting par(mkh) or  <highlevelplot>(* , mkh = ..)
>    changes "cex" accordingly *IF* pch=<numeric> .
> 
> 3b) Similar but more logical; need some "notation" : 
>     The symbol size used in the core function plot.xy()  is
>            cexbase * Pcex   (--> plot.c, l.1089)
> 
>     where "cexbase" is par("cex") and  Pcex is the "cex" argument of 
>     plot(),points(),...
> 
>     Now we could change this to
>            cexbase * mkh * Pcex
>     for the case of numeric pch (internally pch <= 31 or something) where
>     mkh is *either* par("mkh") or the mkh arg. of plot.xy().
> 
> 
> 4) complete S compatibility (cex *not* working for pch=<numeric>)
> 
>    This is completely out of question for me!

Um, as I read my S docs, cex works for numeric pch, but only if mkh=0
which is the default, and mkh works for pch=1 only. That mkh doesn't
work for non-numeric pch is a bit odd, and we could fix that if we
could decide on a reasonable definition of the height of such symbols
(probably, it should depend on the font, not the character). 

But is the real issue not that one will sometimes want to set the size
in "screen-inches", rather than by scaling the defaults? Looks wrong
to me to have it scaling with anything except the pixel resolution.


- -- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 02 Dec 1999 19:35:24 +0100
From: mathieu <mathieu.ros at free.fr>
Subject: [R] problem with par(fig=value)

- --------------1E8E8E7AB4B0CCCC413712D2
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: 8bit

hello all,
I want to draw a figure with multiple plot on the same page using the
par(fig=value) parameter but

> par(fig = c(0, 50, 60, 95)/100, adj = 5/10)
> eboulis(iris.acp)
> par(fig = c(45, 100, 60, 95)/100, mgp = c(3, 1/2, 0))
> boites(iris.acp)

draw the graphics on 2 different pages.
what am I doing wrong ?
thanks for your help.
    Mathieu

[using R 0.65 under Linux Redhat 6.0]

- --
- ----------------------------------------------------------------------
 Mathieu Ros - 13 rue bvire - 38000 GRENOBLE - 04 76 491 370
 http://www.multimania.com/mathieuros/index2.html
 DESS ingnierie mathmatique (biostatistiques)
 Universite Joseph Fourier, Grenoble
- ----------------------------------------------------------------------
La science dtient la vrit, ne vous laissez pas avoir par les faits.



- --------------1E8E8E7AB4B0CCCC413712D2
Content-Type: text/html; charset=us-ascii
Content-Transfer-Encoding: 7bit

<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
hello all,
<br>I want to draw a figure with multiple plot on the same page using the
par(fig=value) parameter but
<p>> par(fig = c(0, 50, 60, 95)/100, adj = 5/10)
<br>> eboulis(iris.acp)
<br>> par(fig = c(45, 100, 60, 95)/100, mgp = c(3, 1/2, 0))
<br>> boites(iris.acp)
<p>draw the graphics on 2 different pages.
<br>what am I doing wrong ?
<br>thanks for your help.
<br>&nbsp;&nbsp;&nbsp; Mathieu
<p>[using R 0.65 under Linux Redhat 6.0]
<pre>--&nbsp;
- ----------------------------------------------------------------------
&nbsp;Mathieu Ros - 13 rue b&eacute;vi&egrave;re - 38000 GRENOBLE - 04 76 491 370
&nbsp;<A HREF="http://www.multimania.com/mathieuros/index2.html">http://www.multimania.com/mathieuros/index2.html</A>
&nbsp;DESS ing&eacute;nierie math&eacute;matique (biostatistiques)
&nbsp;Universite Joseph Fourier, Grenoble
- ----------------------------------------------------------------------
La science d&eacute;tient la v&eacute;rit&eacute;, ne vous laissez pas avoir par les faits.</pre>
&nbsp;</html>

- --------------1E8E8E7AB4B0CCCC413712D2--

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 12:47:09 -0500
From: "Yves Gauvreau" <cyg at sympatico.ca>
Subject: [R] Meaning?

This is a multi-part message in MIME format.

- ------=_NextPart_000_035E_01BF3CC3.58F31C40
Content-Type: text/plain;
	charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

Hi,

Thank you all for your quit an aboundant responses. HAND all of you.

Thanks again.

Yves



- ------=_NextPart_000_035E_01BF3CC3.58F31C40
Content-Type: text/html;
	charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML><HEAD>
<META content=3D"text/html; charset=3Diso-8859-1" =
http-equiv=3DContent-Type>
<META content=3D"MSHTML 5.00.2314.1000" name=3DGENERATOR>
<STYLE></STYLE>
</HEAD>
<BODY bgColor=3D#ffffff>
<DIV><FONT size=3D2>Hi,</FONT></DIV>
<DIV>&nbsp;</DIV>
<DIV><FONT size=3D2>Thank you all for your quit an aboundant responses. =
HAND all=20
of you.</FONT></DIV>
<DIV>&nbsp;</DIV>
<DIV><FONT size=3D2>Thanks again.</FONT></DIV>
<DIV>&nbsp;</DIV>
<DIV><FONT size=3D2>Yves</FONT></DIV>
<DIV>&nbsp;</DIV>
<DIV>&nbsp;</DIV></BODY></HTML>

- ------=_NextPart_000_035E_01BF3CC3.58F31C40--

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 02 Dec 1999 10:30:50 -0800
From: Harry Mangalam <mangalam at home.com>
Subject: [R] Multi-threaded external routines with R?

Hi All,

While R is not multi-threaded, it supports dynamic loading of external
routines writ in C or Fortran.  It seems that it should be possible to link
in multi-threaded code as easily as serial code, as long as the external
routine syncs correctly and returns valid R objects.  

Is this true or ar there R internals that would prevent this?  

If it is true, can anyone point me to examples of this kind of usage?

Thanks very much,
Cheers
Harry
- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

Date: Thu, 2 Dec 1999 14:12:54 -0500 (EST)
From: Ben Bolker <ben at zoo.ufl.edu>
Subject: Re: [R] problem with par(fig=value)

  I think you need to look at par(new) ...

On Thu, 2 Dec 1999, mathieu wrote:

> hello all,
> I want to draw a figure with multiple plot on the same page using the
> par(fig=value) parameter but
> 
> > par(fig = c(0, 50, 60, 95)/100, adj = 5/10)
> > eboulis(iris.acp)
> > par(fig = c(45, 100, 60, 95)/100, mgp = c(3, 1/2, 0))
> > boites(iris.acp)
> 
> draw the graphics on 2 different pages.
> what am I doing wrong ?
> thanks for your help.
>     Mathieu
> 
> [using R 0.65 under Linux Redhat 6.0]
> 
> --
> ----------------------------------------------------------------------
>  Mathieu Ros - 13 rue bvire - 38000 GRENOBLE - 04 76 491 370
>  http://www.multimania.com/mathieuros/index2.html
>  DESS ingnierie mathmatique (biostatistiques)
>  Universite Joseph Fourier, Grenoble
> ----------------------------------------------------------------------
> La science dtient la vrit, ne vous laissez pas avoir par les faits.
> 
> 
> 

- -- 
- --------------------------------------------
Ben Bolker                                  bolker at zoo.ufl.edu
Zoology Department, University of Florida   http://www.zoo.ufl.edu/bolker
318 Carr Hall/Box 118525                    tel: (352) 392-5697
Gainesville, FL 32611-8525                  fax: (352) 392-3704

- -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

------------------------------

End of R-help Digest V1 #34
***************************

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
Digest of R-help mailing list; About R, see  http://www.ci.tuwien.ac.at/R/
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-digest-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cyg at sympatico.ca  Sat Dec  4 01:54:11 1999
From: cyg at sympatico.ca (Yves Gauvreau)
Date: Fri, 3 Dec 1999 19:54:11 -0500
Subject: [R] Stable package on Windows doesn't work???
Message-ID: <03ab01bf3df2$143e7240$6328acce@bellglobal.com>

Hi everyone,

Can someone tell me who made the port of the package stable (by Philippe
Lambert) on the Windows platform or help me with the package.

I ask Lambert about the problem I have and gave him the data. He tried it on
is Linux box and it works fine. I check the default arguments as he
suggested and they are the same as what he send me.

He told me also that his package uses NLM and I wonder if that could be the
source of the problem? Anyone know about nlm problems on Windows?

I you need the dataset and the detail log of what I'm doing, I'll be please
to give you all the information you may need so we can find the reason why
thing don't work.

Thank you all

Yves Gauvreau

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Dec  4 18:36:40 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sat, 4 Dec 1999 17:36:40 +0000 (GMT)
Subject: [R] Large plot symbols (with pch = 1 etc)
In-Reply-To: <199912020923.UAA17825@leonard.anu.edu.au>
Message-ID: <Pine.GSO.4.05.9912041719090.9692-100000@auk.stats>

On Thu, 2 Dec 1999, John Maindonald wrote:

> On my home (Windows 98) machine I find:
> > par()$cra
> [1] 42 16
> > par()$csi
> [1] 0.1666667
> > 
> 
> On my work machine I believe I had
> par()$cra
> [1] 17 16
> 
> So it looks as though R is reading the width wrongly,
> and that it is the width that is somehow used to
> determine the plot character size.

Indeed, that is precisely the problem.  What the code in rw0900 does is to
ask Windows for the width of the widest character in the font used as the
default plotting font (TrueType Times New Roman in a default installation).  
On Windows 95 that will probably be `M' and you get a sensible answer.
However, the latest TrueType fonts contain a vast range of glyphs, some of
them multi-character ones. The width and (adjusted to remove the leading)
height obtained is used to set cra for the device.

I've rewritten this to ask for the dimensions of `M'. Unfortunately there
is at least a chance that it will not get that correct either, so we need
to do some more testing and probably add a sanity check for width <=
height. (Yes, I know 17 > 16, but the height is about 19 before
adjustment.) The reason I spotted this is that it appears that we have the
problem on NT4 machines only if they have Office 2000 installed.
Hopefully rw0901 will have a better solution than the present one.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mangalam at home.com  Sat Dec  4 19:21:41 1999
From: mangalam at home.com (Harry Mangalam)
Date: Sat, 04 Dec 1999 10:21:41 -0800
Subject: [R] Multi-threaded external routines with R?
References: <3.0.1.32.19991202085147.006d09fc@anugpo.anu.edu.au> <x2u2m2mgkp.fsf@blueberry.kubism.ku.dk> <14406.12294.492211.981566@gargle.gargle.HOWL> <x2wvqx5nrt.fsf@blueberry.kubism.ku.dk> <3846BADA.36B05E99@home.com>
Message-ID: <38495BB5.B312453@home.com>

"Jens Oehlschl?gel-Akiyoshi" <jens.oehlschlaegel-akiyoshi at mdfactory.de>
asked for a summary of what I got in response what I previously wrote:

> While R is not multi-threaded, it supports dynamic loading of external
> routines writ in C or Fortran.  It seems that it should be possible to link
> in multi-threaded code as easily as serial code, as long as the external
> routine syncs correctly and returns valid R objects.
> 
> Is this true or ar there R internals that would prevent this?

from a short corresp with Duncan Temple Lang
<duncan at rice.research.bell-labs.com>,
I learned that it should be possible, but perhaps somewhat tricky as it
depends considerably on what the behavior of the linker/loader and perhaps
makefile that you use to assemble this frankenstein.

Theoretically it shouldn't be too difficult (beyond the usual difficulties
of building and debugging such a routine).  R calls an external function
with .C() or .Call(), waits for the completion of this routine, and it
returns an R object in the correct format.

But...

Duncan wrote:

> > However, one of the real problems you may have is that the R
> > executable itself will probably not have been compiled and linked with
> > threads in mind (i.e -D_REENTRANT, linking with -lpthread or
> > -lthread).  Thus on some systems, the dynamically loaded code may end
> > up calling the non-reentrant versions of the system routines and other
> > libraries linked in to the R executable. If one is lucky, this will be
> > obvious; Unlucky means getting unreproducible incorrect results.

and further, he wrote:

"the problem is that suppose R links in a call to malloc(), which
it does. Then when your code is loaded it will potentiall resolve its
malloc() from the one in the executable into which it is being
loaded. I think this is linker and loader dependent.  But if that does
happen, the malloc you get will not be thread-safe. Hence two of your
threads may call it and get wrong results.  This can happen for any of
the routines that the R executable provides to the dynamically loaded
code. This may not be a problem on your system depending on the linker
and loader but it probably requires a little checking."

so if R has been compiled with a thread-UNSAFE malloc or other memory
allocator, and your linker resolves calls from your THREADED program with
this fn(), you will often/always end up with gibberish.  The safer way, I
guess it to force static linking in your threaded routine at compile time
(gcc -static), so that there are no unresolved symbols at link time.


> If it is true, can anyone point me to examples of this kind of usage?

nothing on this so far, and I haven't attempted this, so I can't be of more
concrete help on this yet.

Hope this was of some help..
-- 
Cheers,
Harry

Harry J Mangalam -- (949) 856 2847 -- mangalam at home.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From duncan at rice.research.bell-labs.com  Mon Dec  6 13:39:54 1999
From: duncan at rice.research.bell-labs.com (Duncan Temple Lang)
Date: Mon, 6 Dec 1999 07:39:54 -0500
Subject: [R] R and XML -- a near perfect combination?
Message-ID: <199912061240.NAA16259@stat.math.ethz.ch>


There is an R package for parsing XML available from
  http://www.omegahat.org/R/download/xml/index.html
(click on the R Package in the top right corned of the page).

I thought it would be useful to have people bang on it before I
announce it generally and also port it to S4/Splus5.  So all comments
would be greatly appreciated.

It has two styles of parsing: event driven and document/tree
construction, both allowing user-level functions to control the
processing of the different XML nodes.

This uses (either or both of) the expat parser from Jim Clark and
libxml from Daniel Veillard. Because of this, the installation is
slightly more involved than a simple call to make.

This is released under the GPL as part of the Omega project.


Duncan

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan

      "Languages shape the way we think, and determine what 
       we can think about."        
                                      Benjamin Whorf



-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan

      "Languages shape the way we think, and determine what 
       we can think about."        
                                      Benjamin Whorf
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From peter at esb.ucp.pt  Mon Dec  6 14:10:20 1999
From: peter at esb.ucp.pt (Peter Ho)
Date: Mon, 06 Dec 1999 13:10:20 +0000
Subject: [R] lda
References: <199911251600.RAA20086@alpha.luc.ac.be>
Message-ID: <384BB5B9.31D5EA05@esb.ucp.pt>

Hi,

This is a problem relating to collinearity of data.
I have tried using lda on a data matrix. Lda computed the predicted classes, but
gave a warning that variables were collinear.
Can anyone comment on this? I am not sure how collinearity of data would affect the
lda analysis.
What would be the correct procedure to tackle this problem?

Thank you.


Peter


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec  6 14:53:35 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 6 Dec 1999 13:53:35 +0000 (GMT Standard Time)
Subject: [R] lda
In-Reply-To: <384BB5B9.31D5EA05@esb.ucp.pt>
Message-ID: <Pine.WNT.4.05.9912061350370.288-100000@tern.stats>

On Mon, 6 Dec 1999, Peter Ho wrote:

> This is a problem relating to collinearity of data.

You are failing to give credit for lda, which is from library MASS.

> I have tried using lda on a data matrix. Lda computed the predicted classes, but
> gave a warning that variables were collinear.
> Can anyone comment on this? I am not sure how collinearity of data would affect the
> lda analysis.

It assumes that the data are from multivariate normal distributions with a
common covariance matrix. Such data cannot be collinear. Or, in the
extension of Fisher's scheme, there are many linear combinations maximizing
the quotient of variances.

> What would be the correct procedure to tackle this problem?

Remove the collinearity.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kgerber at giub.unibe.ch  Mon Dec  6 14:51:48 1999
From: kgerber at giub.unibe.ch (Kurt Gerber)
Date: Mon, 06 Dec 1999 14:51:48 +0100
Subject: [R] Factor labeling in a tree.plot
Message-ID: <384BBF74.AD386CF1@giub.unibe.ch>

Hi all.
I have the problem, that the labels from a factor variable in a tree
object, (more exact, the node - labels) is labeled in a plot with
letters a,b,c... instead of the numerical levels. when I run
>labels(tree.object)
It gives me the correct labels (the problem concerns 'landuse':
 [1] "root"                         "landuse:1,2,3,4,5,6,7,8,9,10"
 [3] "altitude<2883.5"              "landuse:1,4,6"
 [5] "altitude<1909.5"              "altitude>1909.5"
 [7] "landuse:2,3,5,7,8,9,10"       "altitude>2883.5"
 [9] "landuse:1,2,3,5,6,10"         "altitude<3526.5"
[11] "altitude>3526.5"              "landuse:4,7,8,9"
[13] "landuse:11,12"                "altitude<2949.5"
[15] "altitude>2949.5"

But when I run
plot(tree.object)
text(tree.object)
the 'landuse' - nodes are labeled with 'landuse: a, b, c, ... and so on
How can I access the right labels?
In S-Plus its the same, but with post.tree() I get the true labels.

Kurt Gerber

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Mon Dec  6 15:13:55 1999
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Mon, 6 Dec 1999 15:13:55 +0100
Subject: No subject
Message-ID: <000501bf3ff4$2190a180$a9021aac@joelschlaegel>



Hi,

can anyone help with two questions concerning persp?

(1) Is there a function in R to project points onto a persp() plot, as is in
S+ (perspp() I think) ?
(2) How can I label and tickmark axes x,y and z in a persp plot?

(I am still using RW065)

Thanks for any help



--
Dr. Jens Oehlschl?gel-Akiyoshi
MD FACTORY GmbH
Bayerstrasse 21

80335 M?nchen

Tel.: 089 545 28-27
Fax.: 089 545 28-10
http://www.mdfactory.de

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From duncan at rice.research.bell-labs.com  Mon Dec  6 15:20:10 1999
From: duncan at rice.research.bell-labs.com (Duncan Temple Lang)
Date: Mon, 6 Dec 1999 09:20:10 -0500
Subject: [R] R and XML -- a near perfect combination?
Message-ID: <199912061422.PAA19041@stat.math.ethz.ch>


Sorry, the correct URL for the XML package is
  http://www.omegahat.org/download/R/xml/

Thanks, Partha, for pointing this out.

D.

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan

      "Languages shape the way we think, and determine what 
       we can think about."        
                                      Benjamin Whorf
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From peter at esb.ucp.pt  Mon Dec  6 16:16:02 1999
From: peter at esb.ucp.pt (Peter Ho)
Date: Mon, 06 Dec 1999 15:16:02 +0000
Subject: [R] lda
References: <Pine.WNT.4.05.9912061350370.288-100000@tern.stats>
Message-ID: <384BD330.E7BFD7E8@esb.ucp.pt>

Thank you to all who replied to my question.
Collinearity of data is no longer a problem in my lda analysis. I have removed the
redundant variables.


Peter



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Mon Dec  6 18:11:00 1999
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Mon, 6 Dec 1999 17:11:00 +0000 (GMT)
Subject: [R] Re: your mail
In-Reply-To: <000501bf3ff4$2190a180$a9021aac@joelschlaegel>
Message-ID: <Pine.LNX.4.10.9912061707540.10354-100000@localhost.localdomain>

> (2) How can I label and tickmark axes x,y and z in a persp plot?
This is one of the biggest holes in R right now I think.
The way I have been doing it is by manual placement of labels using 
text().

Bill

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sdang at ics.uci.edu  Mon Dec  6 17:32:02 1999
From: sdang at ics.uci.edu (Son Quoc Dang)
Date: Mon, 6 Dec 1999 08:32:02 -0800 (PST)
Subject: [R] Help with table
Message-ID: <Pine.GSO.4.10.9912060825070.13199-100000@godzilla.ics.uci.edu>

Hi,

I am fairly new to R.  Recently, I have been working with data stored in
table format.  I am having problems manipulating the table.  Are there
functions that work with tables?  Here is a list of stuffs that I want to
do with the data:

(1) Move columns or rows around.
(2) Insert or delete certain columns or rows.

I was hoping to find functions that would do these.  But so far, I have
had no luck find these functions.

Any help would be greatly appreciated.

Thank you,

Son Q. Dang

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From csprin at brandybuck.ca.sandia.gov  Mon Dec  6 19:22:32 1999
From: csprin at brandybuck.ca.sandia.gov (Clayton Springer)
Date: Mon, 6 Dec 1999 10:22:32 -0800
Subject: [R] k-NN routines
Message-ID: <19991206102232.B23625@brandybuck.ca.sandia.gov>

Hello All,

I would like to use R for k-NN (nearest neighbor) clustering for pattern recognition. 
However, I don't see it. I don't think 'hclust' or 'kmeans' are what I am looking for.

Thanks for your help,


Clayton Springer

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec  6 19:52:02 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 6 Dec 1999 18:52:02 +0000 (GMT)
Subject: [R] k-NN routines
In-Reply-To: <19991206102232.B23625@brandybuck.ca.sandia.gov>
Message-ID: <Pine.GSO.4.05.9912061851240.29101-100000@auk.stats>

On Mon, 6 Dec 1999, Clayton Springer wrote:

> I would like to use R for k-NN (nearest neighbor) clustering for pattern recognition. 
> However, I don't see it. I don't think 'hclust' or 'kmeans' are what I am looking for.

knn in package class, part of the VR bundle.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jbarnett at wi.mit.edu  Mon Dec  6 23:12:44 1999
From: jbarnett at wi.mit.edu (John D. Barnett)
Date: Mon, 06 Dec 1999 17:12:44 -0500
Subject: [R] perl advice
Message-ID: <384C34DC.C6AF00A2@wi.mit.edu>

Hello-

Does anyone have a recommendation on how to call R from perl?  I'm using
the IPC::Open2 module, and running R with the --slave and --quiet
options.  The problem is that I can't predict how many lines of output I
should try to read for each command-- if any!

The ultimate goal is to use perl to provide a form-driven web interface,
but have R do the underlying calculations.

Thanks for any help!

-John Barnett

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From guido at hal.stat.unipd.it  Mon Dec  6 23:45:08 1999
From: guido at hal.stat.unipd.it (Guido Masarotto)
Date: Mon, 6 Dec 1999 23:45:08 +0100
Subject: [R] perl advice
In-Reply-To: <384C34DC.C6AF00A2@wi.mit.edu>; from John D. Barnett on Mon, Dec 06, 1999 at 05:12:44PM -0500
References: <384C34DC.C6AF00A2@wi.mit.edu>
Message-ID: <19991206234508.34164@hal.stat.unipd.it>

On Mon, Dec 06, 1999 at 05:12:44PM -0500, John D. Barnett wrote:
> Hello-
> 
> Does anyone have a recommendation on how to call R from perl?  I'm using
> the IPC::Open2 module, and running R with the --slave and --quiet
> options.  The problem is that I can't predict how many lines of output I
> should try to read for each command-- if any!
> 
> The ultimate goal is to use perl to provide a form-driven web interface,
> but have R do the underlying calculations.
> 

  A trick that I have used sometimes from tcl/tk is to redefine the
  prompt to some funny string (sending to the controlled process
  a 'option(prompt=...) command at the beginning) and then wait
  for the prompt on the output. If I remember also ESS
  works in a  probably less weaker but similar approach (i.e., it
  waits for a particular regular expression on the standard output
  of the R process).
  Hoping this can help,

  guido
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jimrc at gauss.math.montana.edu  Tue Dec  7 00:06:22 1999
From: jimrc at gauss.math.montana.edu (Jim Robison-Cox)
Date: Mon, 6 Dec 1999 16:06:22 -0700 (MST)
Subject: [R] perl advice
In-Reply-To: <384C34DC.C6AF00A2@wi.mit.edu>
Message-ID: <Pine.GSO.4.02.9912061604180.11752-100000@gauss.math.montana.edu>

On Mon, 6 Dec 1999, John D. Barnett wrote:
> Does anyone have a recommendation on how to call R from perl?  I'm using
> the IPC::Open2 module, and running R with the --slave and --quiet
> options.  The problem is that I can't predict how many lines of output I
> should try to read for each command-- if any!
> 
> The ultimate goal is to use perl to provide a form-driven web interface,
> but have R do the underlying calculations.
> 

 Before you reinvent the wheel, look at Jeff Banfield's Rweb:
http://www.math.montana.edu/Rweb/

  You might contact him directly:  jeff at math.montana.edu 
(I know he doesn't read R-help.) if you have more questions.

 Jim

Jim Robison-Cox               ____________    
Department of Math Sciences  |            |       phone: (406)994-5340
2-214 Wilson Hall             \   BZN, MT |       FAX:   (406)994-1789
Montana State University       |  *_______|
Bozeman, MT 59717-2400          \_|      e-mail: jimrc at math.montana.edu 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec  7 00:25:07 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 6 Dec 1999 23:25:07 +0000 (GMT)
Subject: [R] perl advice
In-Reply-To: <19991206234508.34164@hal.stat.unipd.it>
Message-ID: <Pine.GSO.4.05.9912062309490.3921-100000@auk.stats>

On Mon, 6 Dec 1999, Guido Masarotto wrote:

> On Mon, Dec 06, 1999 at 05:12:44PM -0500, John D. Barnett wrote:
> > Hello-
> > 
> > Does anyone have a recommendation on how to call R from perl?  I'm using
> > the IPC::Open2 module, and running R with the --slave and --quiet
> > options.  The problem is that I can't predict how many lines of output I
> > should try to read for each command-- if any!
> > 
> > The ultimate goal is to use perl to provide a form-driven web interface,
> > but have R do the underlying calculations.
> > 
> 
>   A trick that I have used sometimes from tcl/tk is to redefine the
>   prompt to some funny string (sending to the controlled process
>   a 'option(prompt=...) command at the beginning) and then wait
>   for the prompt on the output. If I remember also ESS
>   works in a  probably less weaker but similar approach (i.e., it
>   waits for a particular regular expression on the standard output
>   of the R process).
>   Hoping this can help,

Yes, ESS uses something like that. But, Programming Perl, p.345, warns you
not to use IPC::Open2 for this purpose, because of buffering, but Comm.pl
(from CPAN) instead.  Emacs does use pseudo-ptys (on Unix, and tricks on
Win32) to overcome the buffering problem. I am not sure that R always
flushes its buffers, as although Rprintf seems to do so if it thinks it has
an output file, R_WriteConsole does not.  (Crashes in batch jobs do
sometimes seem to have incomplete output on the output file.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kgerber at giub.unibe.ch  Tue Dec  7 00:41:29 1999
From: kgerber at giub.unibe.ch (Kurt Gerber)
Date: Tue, 07 Dec 1999 00:41:29 +0100
Subject: [R] Problems with X11 - device
Message-ID: <99120700495200.00405@clandestino>

I started the graphics device with X11(). When I tried to plot a tree object
with
> plot (tree) 
It gives me the error message:

Error in plot.window(xlim, ylim, log, asp, ...) : invalid xlim

I was looking in the manual under "plot", "plot.window", etc. but I didn't
really get the resolution of my problem.....
What's the problem?
 
I'm runnig R on a SuSE 6.0 System.

When I ran the same thing under the R for Windows, it plotted just fine... Is
thre a special problem with the X11 device?

Another thing: the html-help doesn't work (on my Linux again): when I run
help.start(), it starts netscape, but it doesn't find the file "index.html".
The start page with the links to "Search, packages, functions" etc. doesn't
exist in ~/.R/doc.. and also in /usr/local/lib/R... there is no "index.html"

Kurt Gerber

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cyg at sympatico.ca  Tue Dec  7 01:03:03 1999
From: cyg at sympatico.ca (Yves Gauvreau)
Date: Mon, 6 Dec 1999 19:03:03 -0500
Subject: [R] Minimize function of several variables?
Message-ID: <05f901bf4046$6f25a650$6328acce@bellglobal.com>

Hi,

Is there something like the Matlab function FMINS in any R packages? Here is the help file of fmins in case something similar exist under R with a different name.

Thanks in advance.

Yves Gauvreau


***********************
function [x, options] = fmins(funfcn,x,options,grad,varargin)
%FMINS  Minimize function of several variables.
%   X = FMINS('F',X0) attempts to return a vector X which is a local
%   minimizer of F(x) near the starting vector X0.  'F' is a string
%   containing the name of the objective function to be minimized.
%   F(x) should be a scalar valued function of a vector variable.
%
%   X = FMINS('F',X0,OPTIONS) uses a vector of control parameters. If
%   OPTIONS(1) is positive, intermediate steps in the solution are
%   displayed; the default is OPTIONS(1) = 0.  OPTIONS(2) is the
%   termination tolerance for x; the default is 1.e-4.  OPTIONS(3) is
%   the termination tolerance for F(x); the default is 1.e-4.
%   OPTIONS(14) is the maximum number of function evaluations; the 
%   default is OPTIONS(14) = 200*length(x).  The other components of 
%   OPTIONS are not used as input control parameters by FMIN.  
%   For more information, see FOPTIONS.
%
%   X = FMINS('F',X0,OPTIONS,[],P1,P2,...) provides for additional
%   arguments which are passed to the objective function, F(X,P1,P2,...)
%   Pass an empty matrix for OPTIONS to use the default value.
%
%   [X,OPTIONS] = FMINS(...) returns the number of function evaluations
%   in OPTIONS(10).
%
%   FMINS uses a Nelder-Mead type simplex search method.
%
%   See also FMIN, FOPTIONS. 

%   Reference: J. E. Dennis, Jr. and D. J. Woods, New Computing
%   Environments: Microcomputers in Large-Scale Computing,
%   edited by A. Wouk, SIAM, 1987, pp. 116-122.

%   Copyright (c) 1984-96 by The MathWorks, Inc.
%   $Revision: 5.11 $  $Date: 1996/10/28 22:13:21 $


************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/19991206/e03287f9/attachment.html

From p.dalgaard at biostat.ku.dk  Tue Dec  7 10:07:53 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 07 Dec 1999 10:07:53 +0100
Subject: [R] Problems with X11 - device
In-Reply-To: Kurt Gerber's message of "Tue, 07 Dec 1999 00:41:29 +0100"
References: <99120700495200.00405@clandestino>
Message-ID: <x2yab72k5y.fsf@blueberry.kubism.ku.dk>

Kurt Gerber <kgerber at giub.unibe.ch> writes:

> I started the graphics device with X11(). When I tried to plot a tree object
> with
> > plot (tree) 
> It gives me the error message:
> 
> Error in plot.window(xlim, ylim, log, asp, ...) : invalid xlim
> 
> I was looking in the manual under "plot", "plot.window", etc. but I didn't
> really get the resolution of my problem.....
> What's the problem?
>  
> I'm runnig R on a SuSE 6.0 System.
> 
> When I ran the same thing under the R for Windows, it plotted just fine... Is
> thre a special problem with the X11 device?

Ahem. Version numbers are important!

If it's R 0.90.0 the fonts are a bit large... does it help if you start
the plotwindow with an explicit x11(pointsize=10)?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kgerber at giub.unibe.ch  Tue Dec  7 11:11:57 1999
From: kgerber at giub.unibe.ch (Kurt Gerber)
Date: Tue, 07 Dec 1999 11:11:57 +0100
Subject: [R] Problems with X11 - device
In-Reply-To: <x2yab72k5y.fsf@blueberry.kubism.ku.dk>
References: <99120700495200.00405@clandestino>
 <x2yab72k5y.fsf@blueberry.kubism.ku.dk>
Message-ID: <99120711125201.00425@clandestino>

On Tue, 07 Dec 1999, Peter Dalgaard BSA wrote:
>Kurt Gerber <kgerber at giub.unibe.ch> writes:
>
>> I started the graphics device with X11(). When I tried to plot a tree object
>> with
>> > plot (tree) 
>> It gives me the error message:
>> 
>> Error in plot.window(xlim, ylim, log, asp, ...) : invalid xlim
>> 
>> I was looking in the manual under "plot", "plot.window", etc. but I didn't
>> really get the resolution of my problem.....
>> What's the problem?
>>  
>> I'm runnig R on a SuSE 6.0 System.
>> 
>> When I ran the same thing under the R for Windows, it plotted just fine... Is
>> thre a special problem with the X11 device?
>
>Ahem. Version numbers are important!
>
>If it's R 0.90.0 the fonts are a bit large... does it help if you start
>the plotwindow with an explicit x11(pointsize=10)?

No, this doesn't help. R. Version is:

R : Copyright 1999, The R Development Core Team
Version 0.65.1 Release (October 07, 1999)      

Kurt Gerber



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cyg at sympatico.ca  Tue Dec  7 13:52:47 1999
From: cyg at sympatico.ca (Yves Gauvreau)
Date: Tue, 7 Dec 1999 07:52:47 -0500
Subject: [R] Minimize function of several variables?
References: <05f901bf4046$6f25a650$6328acce@bellglobal.com> <6remcyhqcn.fsf@franz.stat.wisc.edu>
Message-ID: <062a01bf40b1$f6a39d10$6328acce@bellglobal.com>

Thank you all.

Nlm will be fine.

Yves

----- Original Message -----
From: Douglas Bates <bates at stat.wisc.edu>
To: Yves Gauvreau <cyg at sympatico.ca>
Sent: Tuesday, December 07, 1999 7:45 AM
Subject: Re: [R] Minimize function of several variables?


> "Yves Gauvreau" <cyg at sympatico.ca> writes:
>
> > Is there something like the Matlab function FMINS in any R packages? =
> > Here is the help file of fmins in case something similar exist under R =
> > with a different name.
>
> There is the nlm function.  It uses a quasi-Newton optimization method
> rather than the Nelder-Mead simplex search.  Was your question just
> whether there is optimization code available or whether there is
> optimization code that implements the Nelder-Mead method?
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From koller2 at fgr.wu-wien.ac.at  Tue Dec  7 15:00:31 1999
From: koller2 at fgr.wu-wien.ac.at (Wolfgang Koller)
Date: Tue, 7 Dec 1999 15:00:31 CET (+0100)
Subject: [R] using weights in lm()
Message-ID: <11A3E51AE@fgr.wu-wien.ac.at>

Hello!

When I know the vector of the variance of the disturbances (i.e. the 
structure of heteroskedasticity), say Var(u_{i})=v_{i},
what is the weights I should use as argument to lm(): 

M <- lm(y~x,weigths=1/v)

  or 

M <- lm(y~x,weights=1/(v^0.5))   ???

In the help pages I did not find a clear answer to this question, so 
please could someone help me!

Thanks,

Wolfgang Koller




----------------------------------------------------------
Wolfgang Koller,  koller2 at fgr.wu-wien.ac.at
Forschungsinstitut fuer Europafragen
Wirtschaftsuniversitaet Wien
Althanstrasse 39-45, 1090 Wien, Austria
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec  7 15:36:55 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 7 Dec 1999 14:36:55 +0000 (GMT)
Subject: [R] using weights in lm()
In-Reply-To: <11A3E51AE@fgr.wu-wien.ac.at>
Message-ID: <Pine.GSO.4.05.9912071429430.10379-100000@auk.stats>

On Tue, 7 Dec 1999, Wolfgang Koller wrote:

> Hello!
> 
> When I know the vector of the variance of the disturbances (i.e. the 
> structure of heteroskedasticity), say Var(u_{i})=v_{i},
> what is the weights I should use as argument to lm(): 
> 
> M <- lm(y~x,weigths=1/v)
> 
>   or 
> 
> M <- lm(y~x,weights=1/(v^0.5))   ???
> 
> In the help pages I did not find a clear answer to this question, so 
> please could someone help me!

?lm says:

 weights: an optional vector of weights to be used in the
          fitting process.

That means it does weighted least-squares with weights w, minimizing
sum(w*e*e) where e = y - X %*% b. I assume that you want weights = 1/v,
as that gives the MLE, but what you use is a modelling decision
(and I am working in fMRI where people deliberately do not use the MLE
weighting).

If it had said it did weighted least squares with weights w, would
that have been clear enough?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Tue Dec  7 18:19:00 1999
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 7 Dec 1999 18:19:00 +0100 (CET)
Subject: [R] Finding indices with a certain property
Message-ID: <Pine.LNX.4.10.9912071753490.2138-100000@localhost.localdomain>


I want the indices  i  for which  x[i] < 0 (say):

> x <- c(1, -1, 3, 3, -2)
> where.negative(x)
[1] 2 5

Surely  where.negative  is something simple, but how?

G?ran
--------------------------------------------------------------
 G?ran Brostr?m
 Department of Statistics              tel: +46 90 786-5223
 Ume? University                       fax: +46 90 786-6614
 S-90187 Ume?, Sweden               e-mail:  gb at stat.umu.se

 http://www.stat.umu.se/~gb          ftp://capa.stat.umu.se
--------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Tue Dec  7 17:31:43 1999
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Tue, 7 Dec 1999 08:31:43 -0800 (PST)
Subject: [R] Finding indices with a certain property
In-Reply-To: <Pine.LNX.4.10.9912071753490.2138-100000@localhost.localdomain>
Message-ID: <Pine.GSO.4.21.9912070831150.8694-100000@wompom.biostat.washington.edu>

On Tue, 7 Dec 1999, [ISO-8859-1] Gran Brostrm wrote:

> 
> I want the indices  i  for which  x[i] < 0 (say):
> 
> > x <- c(1, -1, 3, 3, -2)
> > where.negative(x)
> [1] 2 5
> 
> Surely  where.negative  is something simple, but how?


which(x<0)


	-thomas

Thomas Lumley
Asssistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Dec  7 17:38:50 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 07 Dec 1999 17:38:50 +0100
Subject: [R] Finding indices with a certain property
In-Reply-To: G?ran Brostr?m's message of "Tue, 7 Dec 1999 18:19:00 +0100 (CET)"
References: <Pine.LNX.4.10.9912071753490.2138-100000@localhost.localdomain>
Message-ID: <x2puwiiu3p.fsf@blueberry.kubism.ku.dk>

G?ran Brostr?m <gb at stat.umu.se> writes:

> I want the indices  i  for which  x[i] < 0 (say):
> 
> > x <- c(1, -1, 3, 3, -2)
> > where.negative(x)
> [1] 2 5
> 
> Surely  where.negative  is something simple, but how?

How about something like this?

> indices<-function(x)seq(along=x)[x]
> x <- c(1, -1, 3, 3, -2)
> indices(x<0)
[1] 2 5


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Dec  7 17:48:06 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 07 Dec 1999 17:48:06 +0100
Subject: [R] Finding indices with a certain property
In-Reply-To: Thomas Lumley's message of "Tue, 7 Dec 1999 08:31:43 -0800 (PST)"
References: <Pine.GSO.4.21.9912070831150.8694-100000@wompom.biostat.washington.edu>
Message-ID: <x2n1rmito9.fsf@blueberry.kubism.ku.dk>

Thomas Lumley <thomas at biostat.washington.edu> writes:

> > Surely  where.negative  is something simple, but how?

> which(x<0)

Darn! Forgot about that one....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.C.Rougier at durham.ac.uk  Tue Dec  7 17:46:34 1999
From: J.C.Rougier at durham.ac.uk (Jonathan Rougier)
Date: Tue, 7 Dec 1999 16:46:34 +0000 (GMT)
Subject: [R] Finding indices with a certain property
In-Reply-To: <Pine.LNX.4.10.9912071753490.2138-100000@localhost.localdomain>
Message-ID: <Pine.GSO.4.20.9912071645250.20368-100000@laplace>

On Tue, 7 Dec 1999, [ISO-8859-1] Gran Brostrm wrote:

> 
> I want the indices  i  for which  x[i] < 0 (say):
> 
> > x <- c(1, -1, 3, 3, -2)
> > where.negative(x)
> [1] 2 5

Try "which(x<0)".

Jonathan Rougier                       Science Laboratories
Department of Mathematical Sciences    South Road
University of Durham                   Durham DH1 3LE

"[B]egin upon the precept ... that the things we see are to be 
 weighed in the scale with what we know"  (Meredith, 1879, The Egoist)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Dec  7 17:48:31 1999
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 7 Dec 1999 17:48:31 +0100 (MET)
Subject: [R] Finding indices with a certain property
In-Reply-To: <Pine.LNX.4.10.9912071753490.2138-100000@localhost.localdomain>
References: <Pine.LNX.4.10.9912071753490.2138-100000@localhost.localdomain>
Message-ID: <14413.14943.620076.721493@gargle.gargle.HOWL>

>>>>> "GB" == Goran Brostrom <gb at stat.umu.se> writes:

    GB> I want the indices i for which x[i] < 0 (say):

    >> x <- c(1, -1, 3, 3, -2) where.negative(x)
    GB> [1] 2 5

    GB> Surely where.negative is something simple, but how?

Yes :

which(x < 0)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Tue Dec  7 19:07:58 1999
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 7 Dec 1999 19:07:58 +0100 (CET)
Subject: [R] Finding indices with a certain property
In-Reply-To: <x2puwiiu3p.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.4.10.9912071847420.2180-100000@localhost.localdomain>


Quick answers to my question:

which(x < 0)

but also

> indices<-function(x)seq(along=x)[x]
> x <- c(1, -1, 3, 3, -2)
> indices(x<0)
[1] 2 5

from some.

The last one is essentially the definition of  which, I think.
I had completely forgotten  which  (where?!?) 

Thanks to Thomas Lumley, Jonathan Rougier, Martin Maechler,
Peter Dalgaard, Brian Ripley!

G?ran

Original question:

> > I want the indices  i  for which  x[i] < 0 (say):
> > 
> > > x <- c(1, -1, 3, 3, -2)
> > > where.negative(x)
> > [1] 2 5
> > 
> > Surely  where.negative  is something simple, but how?

--------------------------------------------------------------
 G?ran Brostr?m
 Department of Statistics              tel: +46 90 786-5223
 Ume? University                       fax: +46 90 786-6614
 S-90187 Ume?, Sweden               e-mail:  gb at stat.umu.se

 http://www.stat.umu.se/~gb          ftp://capa.stat.umu.se
--------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plummer at iarc.fr  Tue Dec  7 19:00:32 1999
From: plummer at iarc.fr (Martyn Plummer)
Date: Tue, 07 Dec 1999 19:00:32 +0100 (CET)
Subject: [R] Reply to list policy
Message-ID: <XFMail.991207190032.plummer@iarc.fr>

I wonder if it isn't time to change the reply-to-list policy of R-help
and adopt the alternative convention of replying to the author and asking
him/her to summarize to the list.

Recently R-help has been too busy for me to keep up with.  There were
quite a few identical responses in the "Finding indices with a certain
property" thread, rather than an extended discussion.  I think this 
illustrates the need for a reply to author policy.

Does anybody else feel the same way?

Martyn
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Dec  7 19:15:02 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 07 Dec 1999 19:15:02 +0100
Subject: [R] Reply to list policy
In-Reply-To: Martyn Plummer's message of "Tue, 07 Dec 1999 19:00:32 +0100 (CET)"
References: <XFMail.991207190032.plummer@iarc.fr>
Message-ID: <x2emcyipnd.fsf@blueberry.kubism.ku.dk>

Martyn Plummer <plummer at iarc.fr> writes:

> I wonder if it isn't time to change the reply-to-list policy of R-help
> and adopt the alternative convention of replying to the author and asking
> him/her to summarize to the list.
> 
> Recently R-help has been too busy for me to keep up with.  There were
> quite a few identical responses in the "Finding indices with a certain
> property" thread, rather than an extended discussion.  I think this 
> illustrates the need for a reply to author policy.
> 
> Does anybody else feel the same way?

Not me.

- people often don't get around to summarizing

- you don't see whether anyone else replied, so either people get zero
  responses or responses from everyone. Todays minor storm was an
  exception to that effect: people replying before responses of others
  got in.

- it is manageable with filtering and threading. (e.g. procmail or
  gnus) 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jbarnett at wi.mit.edu  Tue Dec  7 21:00:50 1999
From: jbarnett at wi.mit.edu (John D. Barnett)
Date: Tue, 07 Dec 1999 15:00:50 -0500
Subject: [R] perl advice
References: <Pine.GSO.4.05.9912062309490.3921-100000@auk.stats>
Message-ID: <384D6772.F6514E46@wi.mit.edu>

Thanks; this is all very helpful.

I looked into Comm.pl, but had problems using it.  I found a message somewhere
saying that Comm.pl was fairly specific to SunOS 4/5; there's a newer perl
module
with similar functionality, Expect.pm

I've already written a routine to parse R output produced by dump(), but now
that
I'm able to interact directly, I'd like to parse R's normal output-- unless
there's a
way that I can send dump's output to STDOUT.

Thanks again!

Prof Brian D Ripley wrote:

> On Mon, 6 Dec 1999, Guido Masarotto wrote:
>
> > On Mon, Dec 06, 1999 at 05:12:44PM -0500, John D. Barnett wrote:
> > > Hello-
> > >
> > > Does anyone have a recommendation on how to call R from perl?  I'm using
> > > the IPC::Open2 module, and running R with the --slave and --quiet
> > > options.  The problem is that I can't predict how many lines of output I
> > > should try to read for each command-- if any!
> > >
> > > The ultimate goal is to use perl to provide a form-driven web interface,
> > > but have R do the underlying calculations.
> > >
> >
> >   A trick that I have used sometimes from tcl/tk is to redefine the
> >   prompt to some funny string (sending to the controlled process
> >   a 'option(prompt=...) command at the beginning) and then wait
> >   for the prompt on the output. If I remember also ESS
> >   works in a  probably less weaker but similar approach (i.e., it
> >   waits for a particular regular expression on the standard output
> >   of the R process).
> >   Hoping this can help,
>
> Yes, ESS uses something like that. But, Programming Perl, p.345, warns you
> not to use IPC::Open2 for this purpose, because of buffering, but Comm.pl
> (from CPAN) instead.  Emacs does use pseudo-ptys (on Unix, and tricks on
> Win32) to overcome the buffering problem. I am not sure that R always
> flushes its buffers, as although Rprintf seems to do so if it thinks it has
> an output file, R_WriteConsole does not.  (Crashes in batch jobs do
> sometimes seem to have incomplete output on the output file.)
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Vipul.Devas at rp-rorer.com  Tue Dec  7 20:14:58 1999
From: Vipul.Devas at rp-rorer.com (Devas, Vipul PH/US)
Date: Tue, 7 Dec 1999 14:14:58 -0500 
Subject: [R] R Batch job on Unix system
Message-ID: <CEC354720AC9D111A4670000F84A122602268FC8@clvex01.clv.rpr.rp>

Hi All,
	I execute a R BATCH job on the unix machine. About some days ago I
was able to do a simulations of size 800000.   Now, I am trying to do about
400000 simulations in the batch job.  In this job,  I calculate eigen values
for 3x3 matrix 50 times and iterate it 20 times and repeat this whole thing
400 times.  I checked with our system administrator if the machine was
running OK and it is OK.  We doubled the --vsize and --nsize this time but
it does not help.
Here's the error that I get when I execute the Batch job
****************************************************************
Error in z$vectors[, ord] : incorrect number of dimensions
Execution halted
****************************************************
 
I ran a small job in the interative R and everything works fine.  

Do I have to clean the " .RData " file before I run the batch job ??

Also,the 'ulimit' for our system is the following
***************
time(seconds)        unlimited
file(blocks)         unlimited
data(kbytes)         131072
stack(kbytes)        2048
memory(kbytes)       1021400
coredump(blocks)     unlimited
nofiles(descriptors) 4096
vmemory(kbytes)      1048576
********************
Please help me on this.

Thanks to everyone

  Best Regards

Vipul Devas
Email: vipul.devas at rp-rorer.com
Phone: 610-454-3944 (O)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mcw at ln.nimh.nih.gov  Tue Dec  7 23:30:31 1999
From: mcw at ln.nimh.nih.gov (Matthew Wiener)
Date: Tue, 7 Dec 1999 17:30:31 -0500 (EST)
Subject: [R] problem compiling: alpha/linux: sqrttsu
Message-ID: <Pine.SGI.3.96.991207170624.8724L-100000@ln.nimh.nih.gov>

Hi, all.

In trying to compile R v.0.90 on an alpha running Red Hat Linux 6.0, I'm
getting the following error: 

make[3]: Entering directory `/home/mcw/alpha-R/R-0.90.0/src/appl' 
gcc -I. -I../include -I../../src/include -DHAVE_CONFIG_H -mieee -g -O2 -c cpoly.c
-o cpoly.o 
/tmp/ccPjZNwd.s: Assembler messages: 
/tmp/ccPjZNwd.s:312: Error: unknown opcode `sqrttsu' 
/tmp/ccPjZNwd.s:2631: Error: unknown opcode `sqrttsu'
/tmp/ccPjZNwd.s:4028: Error: unknown opcode `sqrttsu'
/tmp/ccPjZNwd.s:4132: Error: unknown opcode `sqrttsu'
/tmp/ccPjZNwd.s:4141: Error: unknown opcode `sqrttsu'
/tmp/ccPjZNwd.s:4470: Error: unknown opcode `sqrttsu'
/tmp/ccPjZNwd.s:4492: Error: unknown opcode `sqrttsu'
/tmp/ccPjZNwd.s:4516: Error: unknown opcode `sqrttsu' make[3]: ***
[cpoly.o] Error 1

No such files seem to exist in my /tmp directory, nor can I find them
elsewhere.  I can't find any files ending in .s, in fact.

I'm using make version 3.78.1, not the taboo 3.77, and egcs-2.91.66.

Anyone come across this before?

Note that:  1) we have not compiled any earlier version of R;
	    2) the configuration appears to go off without any problems;
	    3) an alpha rpm from cran installs OK, but won't let me
		compile libraries.  Here's an example with ctest:

> R INSTALL ctest_0.9-19.tar.gz 
Installing package `ctest' ... 
libs 
g77 -mieee -fPIC -O2 -c alnorm.f -o alnorm.o 
gcc -I/usr/lib/R/include -DHAVE_CONFIG_H -mieee -fPIC -O2 -c ansari.c -o
ansari.o 
gcc -I/usr/lib/R/include -DHAVE_CONFIG_H -mieee -fPIC -O2 -c
fexact.c -o fexact.o 
gcc -I/usr/lib/R/include -DHAVE_CONFIG_H -mieee -fPIC
-O2 -c kendall.c -o kendall.o 
/tmp/ccYUoygd.s: Assembler messages:
/tmp/ccYUoygd.s:123: Error: unknown opcode `sqrttsu' 
/tmp/ccYUoygd.s:132: Error: unknown opcode `sqrttsu' 

make: *** [kendall.o] Error 1


Any help appreciated.

Thanks,
		Matt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at biostat.washington.edu  Wed Dec  8 00:04:42 1999
From: rossini at biostat.washington.edu (A.J. Rossini)
Date: 07 Dec 1999 15:04:42 -0800
Subject: [R] Reply to list policy
In-Reply-To: Peter Dalgaard BSA's message of "07 Dec 1999 19:15:02 +0100"
References: <XFMail.991207190032.plummer@iarc.fr> <x2emcyipnd.fsf@blueberry.kubism.ku.dk>
Message-ID: <87g0xe2vzp.fsf@alpha.cfas.washington.edu>


>>>>> "PDB" == Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

    PDB> Martyn Plummer <plummer at iarc.fr> writes:
    >> I wonder if it isn't time to change the reply-to-list policy of
    >> R-help and adopt the alternative convention of replying to the
    >> author and asking him/her to summarize to the list.
    >>
    >> Recently R-help has been too busy for me to keep up with.
    >> There were quite a few identical responses in the "Finding
    >> indices with a certain property" thread, rather than an
    >> extended discussion.  I think this illustrates the need for a
    >> reply to author policy.
    >>
    >> Does anybody else feel the same way?

    PDB> Not me.

Not me, either.  Peter summarized my feelings precisely.

    PDB> - people often don't get around to summarizing

    PDB> - you don't see whether anyone else replied, so either people
    PDB>   get zero responses or responses from everyone. Todays minor
    PDB>   storm was an exception to that effect: people replying
    PDB>   before responses of others got in.

    PDB> - it is manageable with filtering and
    PDB>   threading. (e.g. procmail or gnus)

-- 
A.J. Rossini			Research Assistant Professor of Biostatistics 
Center for AIDS Research/HMC	Biostatistics/Univ. of Washington
Box 359931			Box 357232
206-731-3647 (3693=fax)		206-543-1044 (3286=fax)
rossini at u.washington.edu	rossini at biostat.washington.edu
http://www.biostat.washington.edu/~rossini/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec  8 00:13:43 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Dec 1999 00:13:43 +0100
Subject: [R] problem compiling: alpha/linux: sqrttsu
In-Reply-To: Matthew Wiener's message of "Tue, 7 Dec 1999 17:30:31 -0500 (EST)"
References: <Pine.SGI.3.96.991207170624.8724L-100000@ln.nimh.nih.gov>
Message-ID: <x2r9gyfioo.fsf@blueberry.kubism.ku.dk>

Matthew Wiener <mcw at ln.nimh.nih.gov> writes:

> Hi, all.
> 
> In trying to compile R v.0.90 on an alpha running Red Hat Linux 6.0, I'm
> getting the following error: 
> 
> make[3]: Entering directory `/home/mcw/alpha-R/R-0.90.0/src/appl' 
> gcc -I. -I../include -I../../src/include -DHAVE_CONFIG_H -mieee -g -O2 -c cpoly.c
> -o cpoly.o 
> /tmp/ccPjZNwd.s: Assembler messages: 
> /tmp/ccPjZNwd.s:312: Error: unknown opcode `sqrttsu' 
> /tmp/ccPjZNwd.s:2631: Error: unknown opcode `sqrttsu'
> /tmp/ccPjZNwd.s:4028: Error: unknown opcode `sqrttsu'
> /tmp/ccPjZNwd.s:4132: Error: unknown opcode `sqrttsu'
> /tmp/ccPjZNwd.s:4141: Error: unknown opcode `sqrttsu'
> /tmp/ccPjZNwd.s:4470: Error: unknown opcode `sqrttsu'
> /tmp/ccPjZNwd.s:4492: Error: unknown opcode `sqrttsu'
> /tmp/ccPjZNwd.s:4516: Error: unknown opcode `sqrttsu' make[3]: ***
> [cpoly.o] Error 1
> 
> No such files seem to exist in my /tmp directory, nor can I find them
> elsewhere.  I can't find any files ending in .s, in fact.
> 
> I'm using make version 3.78.1, not the taboo 3.77, and egcs-2.91.66.
...
> Any help appreciated.

You can see the actual .s file by adding a -S to the compilation
options. The whole thing looks as if you might need to upgrade the
assembler (gas or as). Take a peek if you care at the minor flame war
at http://egcs.cygnus.com/ml/gcc/1999-08/msg00017.html

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Dec  8 10:30:20 1999
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 8 Dec 1999 10:30:20 +0100 (MET)
Subject: [R] Stable package on Windows doesn't work???
In-Reply-To: <05da01bf3fff$7419c700$6328acce@bellglobal.com> from "Yves Gauvreau" at Dec 06, 1999 10:34:57 AM
Message-ID: <199912080930.KAA22900@alpha.luc.ac.be>

Yves:
  I am completely baffled by this. I include below my output for these
examples from Intel Pentium II RH5.2 Linux with R90. I get exactly the
same results with MS Windows 98 and R65 on the same machine. I also
tried with R90 and MS Windows 95 on an older Pentium and also got the
same results. What machine exactly did you run this on?
  R-help will remember that I have complained before about numerical
problems with MS Windows but this one beats me. Jim

> 
> Hi Jim,
> 
> Troels Ring told me to get Version 0.7 which I did.
> 
> It's probably me that doesn't understand how it works (I'm new to R) but
> stablereg is supposed to find the most appropriate parameters for the stable
> distribution (loc, disp, skew, tail) given some starting values right?
> 
> When I try the examples that are given with the function help file I get the
> following results.
> 
> ************************************************************
> R : Copyright 1999, The R Development Core Team
> Version 0.90.0  (November 22, 1999)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type   "?license" or "?licence" for distribution details.
> 
> R is a collaborative project with many contributors.
> Type   "?contributors" for a list.
> 
> Type   "demo()" for some demos, "help()" for on-line help, or
>         "help.start()" for a HTML browser interface to help.
> Type    "q()" to quit R.
> 
> > library(stable)
> Loading required package: rmutil
> > help(stablereg)
> > ## Share return over a 50 day period (see reference above)
> >         # shares
> >         y <-
> c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
> +
> 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
> +
> 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)
> >
> >         # returns
> >         ret <- (y[2:50]-y[1:49])/y[1:49]
> >         # hist(ret, breaks=seq(-0.035,0.045,0.01))
> >
> >         day <- seq(0,0.48,by=0.01) # time measured in days/100
> >         x <- seq(1,length(ret))-1
> >
> >         # Classic stationary normal model tail=2
> >         print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
> +              iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1,
>     tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0,
>     otail = F, oskew = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  2
> No. of parameters            4
> Degrees of freedom           47
> AIC                          294.4987
> Iterations                   1
> 
> Location parameters
> ~1
>               estimate       se
> (Intercept)  0.0001445  0.07433
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.055
> 
> Correlations:
>          1        2
> 1  1.00000 -0.01525
> 2 -0.01525  1.00000
> >
> >         # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> >         print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
> +              iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1,
>     skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0,
>     iskew = 0, oskew = F, otail = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  3
> No. of parameters            5
> Degrees of freedom           46
> AIC                          295.4987
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate      se
> (Intercept)   1.445e-04  0.1467
> day          -6.053e-06  0.5265
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.063
> 
> Correlations:
>          1        2        3
> 1  1.00000 -0.86207 -0.06098
> 2 -0.86207  1.00000  0.06159
> 3 -0.06098  0.06159  1.00000
> >
> >         # Stable model with loc(ation)=loc.h(b0+b1*day)
> >         print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
> +              iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~
>     1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0,
>     itail = 0)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              291.591
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          296.591
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate       se
> (Intercept)   0.0004749  0.08946
> day          -0.0001862  0.43214
> 
> Dispersion parameters
> ret ~ 1
>              estimate     se
> (Intercept)   -0.9998  3.340
> 
> Skew parameters
> ~1
>                estimate   se
> (Intercept)  -0.0002456  NaN
> 
> Tail parameters
> ~1
>              estimate   se
> (Intercept)  -0.02018  NaN
> 
> Correlations:
>          1        2        3   4   5
> 1  1.00000 -1.15904 -0.06692 NaN NaN
> 2 -1.15904  1.00000  0.06058 NaN NaN
> 3 -0.06692  0.06058  1.00000 NaN NaN
> 4      NaN      NaN      NaN NaN NaN
> 5      NaN      NaN      NaN NaN NaN
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with disp(ersion)=disp.h(b0+b1*day)
> >         print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
> +              iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day,
>     skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2,
>     itail = 1)
> 
> -Log likelihood              132.1774
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          137.1774
> Iterations                   70
> 
> Location parameters
> ret ~ 1
>              estimate        se
> (Intercept)  0.000938  0.001892
> 
> Dispersion parameters
> ~day
>              estimate       se
> (Intercept)   -4.6768  0.06621
> day           -0.6556  0.61348
> 
> Skew parameters
> ~1
>              estimate   se
> (Intercept)    -10.87  NaN
> 
> Tail parameters
> ~1
>              estimate      se
> (Intercept)    0.6575  0.6067
> 
> Correlations:
>         1       2       3   4       5
> 1  1.0000 -1.0000  0.8075 NaN -0.3810
> 2 -1.0000  1.0000 -0.8075 NaN  0.3810
> 3  0.8075 -0.8075  1.0000 NaN -0.2914
> 4     NaN     NaN     NaN NaN     NaN
> 5 -0.3810  0.3810 -0.2914 NaN  1.0000
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with skew(ness)=skew.h(b0+b1*day)
> >         # Evaluation at fixed parameter values (since noopt is set to
> TRUE)
> >         print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
> +              iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
> +              itail = -5.261e-1, noopt=T))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957,
>     iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)
> 
> -Log likelihood              150.2681
> No. of obs                   49
> No. of estimated parameters  0
> No. of parameters            5
> Degrees of freedom           49
> AIC                          150.2681
> >
> >         # Stable model with tail=tail.h(b0+b1*day)
> >         print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
> +              disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
> +              idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3,
>     itail = c(2, -7), hessian = F)
> 
> -Log likelihood              129.4914
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          134.4914
> Iterations                   83
> 
> Location parameters
> ret ~ 1
>              estimate  se
> (Intercept)  0.001841  NA
> 
> Dispersion parameters
> ~1
>              estimate  se
> (Intercept)    -4.785  NA
> 
> Skew parameters
> ~1
>              estimate  se
> (Intercept)    -13.82  NA
> 
> Tail parameters
> ~day
>              estimate  se
> (Intercept)     1.926  NA
> day            -6.716  NA
> >
> >
> ****************************************************************
> 
> Are those result what they're supposed to be?
> 
> If it is so, I find it confusing that there are NA's, NaN's and/or "Warning:
> no convergence - error 5 "  in practically all results. I took a look at the
> source code and there are 2 messages that give an hint that the result are
> probably ok. It kind of looks like these example are counter example if the
> results are correct that is.
> 
> Is there some documentation for the library, I mean more then the help files
> provide?
> 
> Any help you can provide will be appreciated.
> 
> Thanks.
> 
> Yves Gauvreau
> 
> 
> 
> 
> 

-------------------------------------------------------------------------
from Linux, Jim
-------------------------------------------------------------------------
R : Copyright 1999, The R Development Core Team
Version 0.90.0  (November 22, 1999)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type	"?license" or "?licence" for distribution details.

R is a collaborative project with many contributors.
Type	"?contributors" for a list.

Type	"demo()" for some demos, "help()" for on-line help, or
    	"help.start()" for a HTML browser interface to help.
Type	"q()" to quit R.

> library(stable)
Loading required package: rmutil 
> ## Share return over a 50 day period (see reference above)
> # shares
> y <- c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
+ 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
+ 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)  
> 
> # returns
> ret <- (y[2:50]-y[1:49])/y[1:49]
> # hist(ret, breaks=seq(-0.035,0.045,0.01))
> 
> day <- seq(0,0.48,by=0.01) # time measured in days/100
> x <- seq(1,length(ret))-1
> 
> # Classic stationary normal model tail=2
> print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
+ 	iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1, 
    tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0, 
    otail = F, oskew = F)

-Log likelihood              136.0479 
No. of obs                   49 
No. of estimated parameters  2 
No. of parameters            4 
Degrees of freedom           47 
AIC                          138.0479 
Iterations                   12 

Location parameters
~1
              estimate        se
(Intercept)  0.0002892  0.001851

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.693  0.1010

Correlations:
          1         2
1 1.0000000 0.0003176
2 0.0003176 1.0000000
> 
> # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
+ 	iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1, 
    skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0, 
    iskew = 0, oskew = F, otail = F)

-Log likelihood              135.9994 
No. of obs                   49 
No. of estimated parameters  3 
No. of parameters            5 
Degrees of freedom           46 
AIC                          138.9994 
Iterations                   17 

Location parameters
~day
              estimate        se
(Intercept)   0.001266  0.003643
day          -0.004071  0.013077

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.694  0.1010

Correlations:
          1          2          3
1  1.000000 -0.8615643  0.0009260
2 -0.861564  1.0000000 -0.0009084
3  0.000926 -0.0009084  1.0000000
Warning message: 
NaNs produced in: log(x) 
> 
> # Stable model with loc(ation)=loc.h(b0+b1*day)
> print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
+ 	iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~ 
    1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0, 
    itail = 0)

Warning: no convergence - error 5 

-Log likelihood              135.921 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          140.921 
Iterations                   38 

Location parameters
~day
              estimate        se
(Intercept)   0.001297  0.003607
day          -0.004630  0.012963

Dispersion parameters
ret ~ 1
             estimate      se
(Intercept)    -4.704  0.1005

Skew parameters
~1
             estimate     se
(Intercept)     -5.07  41.76

Tail parameters
~1
             estimate   se
(Intercept)     6.408  NaN

Correlations:
          1         2         3         4   5
1  1.000000 -0.860897  0.003654  0.000318 NaN
2 -0.860897  1.000000 -0.003828 -0.002440 NaN
3  0.003654 -0.003828  1.000000 -0.005568 NaN
4  0.000318 -0.002440 -0.005568  1.000000 NaN
5       NaN       NaN       NaN       NaN NaN
Warning message: 
NaNs produced in: sqrt(diag(cov)) 
> 
> # Stable model with disp(ersion)=disp.h(b0+b1*day)
> print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
+ 	iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day, 
    skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2, 
    itail = 1)

-Log likelihood              132.1774 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          137.1774 
Iterations                   70 

Location parameters
ret ~ 1
              estimate        se
(Intercept)  0.0009383  0.002394

Dispersion parameters
~day
             estimate      se
(Intercept)   -4.6768  0.2189
day           -0.6556  0.7402

Skew parameters
~1
             estimate     se
(Intercept)    -10.91  59.32

Tail parameters
~1
             estimate      se
(Intercept)    0.6574  0.7444

Correlations:
          1         2         3         4         5
1  1.000000  0.345026  0.185935 -0.001388 -0.600483
2  0.345026  1.000000 -0.735818  0.002904 -0.458313
3  0.185935 -0.735818  1.000000 -0.006449  0.127329
4 -0.001388  0.002904 -0.006449  1.000000 -0.007393
5 -0.600483 -0.458313  0.127329 -0.007393  1.000000
> 
> # Stable model with skew(ness)=skew.h(b0+b1*day)
> # Evaluation at fixed parameter values (since noopt is set to TRUE)
> print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
+ 	iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
+ 	itail = -5.261e-1, noopt=T))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957, 
    iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)

-Log likelihood              150.2683 
No. of obs                   49 
No. of estimated parameters  0 
No. of parameters            5 
Degrees of freedom           49 
AIC                          150.2683 
> 
> # Stable model with tail=tail.h(b0+b1*day)
> print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
+ 	disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
+ 	idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3, 
    itail = c(2, -7), hessian = F)

Warning: no convergence - error 3 

-Log likelihood              129.4544 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          134.4544 
Iterations                   70 

Location parameters
ret ~ 1
             estimate  se
(Intercept)  0.001694  NA

Dispersion parameters
~1
             estimate  se
(Intercept)    -4.791  NA

Skew parameters
~1
             estimate  se
(Intercept)    -8.805  NA

Tail parameters
~day
             estimate  se
(Intercept)     2.081  NA
day            -7.091  NA
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Dec  8 10:30:20 1999
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 8 Dec 1999 10:30:20 +0100 (MET)
Subject: [R] Stable package on Windows doesn't work???
In-Reply-To: <05da01bf3fff$7419c700$6328acce@bellglobal.com> from "Yves Gauvreau" at Dec 06, 1999 10:34:57 AM
Message-ID: <199912080930.KAA22900@alpha.luc.ac.be>

Yves:
  I am completely baffled by this. I include below my output for these
examples from Intel Pentium II RH5.2 Linux with R90. I get exactly the
same results with MS Windows 98 and R65 on the same machine. I also
tried with R90 and MS Windows 95 on an older Pentium and also got the
same results. What machine exactly did you run this on?
  R-help will remember that I have complained before about numerical
problems with MS Windows but this one beats me. Jim

> 
> Hi Jim,
> 
> Troels Ring told me to get Version 0.7 which I did.
> 
> It's probably me that doesn't understand how it works (I'm new to R) but
> stablereg is supposed to find the most appropriate parameters for the stable
> distribution (loc, disp, skew, tail) given some starting values right?
> 
> When I try the examples that are given with the function help file I get the
> following results.
> 
> ************************************************************
> R : Copyright 1999, The R Development Core Team
> Version 0.90.0  (November 22, 1999)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type   "?license" or "?licence" for distribution details.
> 
> R is a collaborative project with many contributors.
> Type   "?contributors" for a list.
> 
> Type   "demo()" for some demos, "help()" for on-line help, or
>         "help.start()" for a HTML browser interface to help.
> Type    "q()" to quit R.
> 
> > library(stable)
> Loading required package: rmutil
> > help(stablereg)
> > ## Share return over a 50 day period (see reference above)
> >         # shares
> >         y <-
> c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
> +
> 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
> +
> 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)
> >
> >         # returns
> >         ret <- (y[2:50]-y[1:49])/y[1:49]
> >         # hist(ret, breaks=seq(-0.035,0.045,0.01))
> >
> >         day <- seq(0,0.48,by=0.01) # time measured in days/100
> >         x <- seq(1,length(ret))-1
> >
> >         # Classic stationary normal model tail=2
> >         print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
> +              iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1,
>     tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0,
>     otail = F, oskew = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  2
> No. of parameters            4
> Degrees of freedom           47
> AIC                          294.4987
> Iterations                   1
> 
> Location parameters
> ~1
>               estimate       se
> (Intercept)  0.0001445  0.07433
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.055
> 
> Correlations:
>          1        2
> 1  1.00000 -0.01525
> 2 -0.01525  1.00000
> >
> >         # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> >         print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
> +              iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1,
>     skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0,
>     iskew = 0, oskew = F, otail = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  3
> No. of parameters            5
> Degrees of freedom           46
> AIC                          295.4987
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate      se
> (Intercept)   1.445e-04  0.1467
> day          -6.053e-06  0.5265
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.063
> 
> Correlations:
>          1        2        3
> 1  1.00000 -0.86207 -0.06098
> 2 -0.86207  1.00000  0.06159
> 3 -0.06098  0.06159  1.00000
> >
> >         # Stable model with loc(ation)=loc.h(b0+b1*day)
> >         print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
> +              iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~
>     1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0,
>     itail = 0)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              291.591
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          296.591
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate       se
> (Intercept)   0.0004749  0.08946
> day          -0.0001862  0.43214
> 
> Dispersion parameters
> ret ~ 1
>              estimate     se
> (Intercept)   -0.9998  3.340
> 
> Skew parameters
> ~1
>                estimate   se
> (Intercept)  -0.0002456  NaN
> 
> Tail parameters
> ~1
>              estimate   se
> (Intercept)  -0.02018  NaN
> 
> Correlations:
>          1        2        3   4   5
> 1  1.00000 -1.15904 -0.06692 NaN NaN
> 2 -1.15904  1.00000  0.06058 NaN NaN
> 3 -0.06692  0.06058  1.00000 NaN NaN
> 4      NaN      NaN      NaN NaN NaN
> 5      NaN      NaN      NaN NaN NaN
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with disp(ersion)=disp.h(b0+b1*day)
> >         print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
> +              iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day,
>     skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2,
>     itail = 1)
> 
> -Log likelihood              132.1774
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          137.1774
> Iterations                   70
> 
> Location parameters
> ret ~ 1
>              estimate        se
> (Intercept)  0.000938  0.001892
> 
> Dispersion parameters
> ~day
>              estimate       se
> (Intercept)   -4.6768  0.06621
> day           -0.6556  0.61348
> 
> Skew parameters
> ~1
>              estimate   se
> (Intercept)    -10.87  NaN
> 
> Tail parameters
> ~1
>              estimate      se
> (Intercept)    0.6575  0.6067
> 
> Correlations:
>         1       2       3   4       5
> 1  1.0000 -1.0000  0.8075 NaN -0.3810
> 2 -1.0000  1.0000 -0.8075 NaN  0.3810
> 3  0.8075 -0.8075  1.0000 NaN -0.2914
> 4     NaN     NaN     NaN NaN     NaN
> 5 -0.3810  0.3810 -0.2914 NaN  1.0000
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with skew(ness)=skew.h(b0+b1*day)
> >         # Evaluation at fixed parameter values (since noopt is set to
> TRUE)
> >         print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
> +              iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
> +              itail = -5.261e-1, noopt=T))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957,
>     iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)
> 
> -Log likelihood              150.2681
> No. of obs                   49
> No. of estimated parameters  0
> No. of parameters            5
> Degrees of freedom           49
> AIC                          150.2681
> >
> >         # Stable model with tail=tail.h(b0+b1*day)
> >         print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
> +              disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
> +              idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3,
>     itail = c(2, -7), hessian = F)
> 
> -Log likelihood              129.4914
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          134.4914
> Iterations                   83
> 
> Location parameters
> ret ~ 1
>              estimate  se
> (Intercept)  0.001841  NA
> 
> Dispersion parameters
> ~1
>              estimate  se
> (Intercept)    -4.785  NA
> 
> Skew parameters
> ~1
>              estimate  se
> (Intercept)    -13.82  NA
> 
> Tail parameters
> ~day
>              estimate  se
> (Intercept)     1.926  NA
> day            -6.716  NA
> >
> >
> ****************************************************************
> 
> Are those result what they're supposed to be?
> 
> If it is so, I find it confusing that there are NA's, NaN's and/or "Warning:
> no convergence - error 5 "  in practically all results. I took a look at the
> source code and there are 2 messages that give an hint that the result are
> probably ok. It kind of looks like these example are counter example if the
> results are correct that is.
> 
> Is there some documentation for the library, I mean more then the help files
> provide?
> 
> Any help you can provide will be appreciated.
> 
> Thanks.
> 
> Yves Gauvreau
> 
> 
> 
> 
> 

-------------------------------------------------------------------------
from Linux, Jim
-------------------------------------------------------------------------
R : Copyright 1999, The R Development Core Team
Version 0.90.0  (November 22, 1999)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type	"?license" or "?licence" for distribution details.

R is a collaborative project with many contributors.
Type	"?contributors" for a list.

Type	"demo()" for some demos, "help()" for on-line help, or
    	"help.start()" for a HTML browser interface to help.
Type	"q()" to quit R.

> library(stable)
Loading required package: rmutil 
> ## Share return over a 50 day period (see reference above)
> # shares
> y <- c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
+ 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
+ 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)  
> 
> # returns
> ret <- (y[2:50]-y[1:49])/y[1:49]
> # hist(ret, breaks=seq(-0.035,0.045,0.01))
> 
> day <- seq(0,0.48,by=0.01) # time measured in days/100
> x <- seq(1,length(ret))-1
> 
> # Classic stationary normal model tail=2
> print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
+ 	iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1, 
    tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0, 
    otail = F, oskew = F)

-Log likelihood              136.0479 
No. of obs                   49 
No. of estimated parameters  2 
No. of parameters            4 
Degrees of freedom           47 
AIC                          138.0479 
Iterations                   12 

Location parameters
~1
              estimate        se
(Intercept)  0.0002892  0.001851

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.693  0.1010

Correlations:
          1         2
1 1.0000000 0.0003176
2 0.0003176 1.0000000
> 
> # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
+ 	iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1, 
    skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0, 
    iskew = 0, oskew = F, otail = F)

-Log likelihood              135.9994 
No. of obs                   49 
No. of estimated parameters  3 
No. of parameters            5 
Degrees of freedom           46 
AIC                          138.9994 
Iterations                   17 

Location parameters
~day
              estimate        se
(Intercept)   0.001266  0.003643
day          -0.004071  0.013077

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.694  0.1010

Correlations:
          1          2          3
1  1.000000 -0.8615643  0.0009260
2 -0.861564  1.0000000 -0.0009084
3  0.000926 -0.0009084  1.0000000
Warning message: 
NaNs produced in: log(x) 
> 
> # Stable model with loc(ation)=loc.h(b0+b1*day)
> print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
+ 	iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~ 
    1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0, 
    itail = 0)

Warning: no convergence - error 5 

-Log likelihood              135.921 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          140.921 
Iterations                   38 

Location parameters
~day
              estimate        se
(Intercept)   0.001297  0.003607
day          -0.004630  0.012963

Dispersion parameters
ret ~ 1
             estimate      se
(Intercept)    -4.704  0.1005

Skew parameters
~1
             estimate     se
(Intercept)     -5.07  41.76

Tail parameters
~1
             estimate   se
(Intercept)     6.408  NaN

Correlations:
          1         2         3         4   5
1  1.000000 -0.860897  0.003654  0.000318 NaN
2 -0.860897  1.000000 -0.003828 -0.002440 NaN
3  0.003654 -0.003828  1.000000 -0.005568 NaN
4  0.000318 -0.002440 -0.005568  1.000000 NaN
5       NaN       NaN       NaN       NaN NaN
Warning message: 
NaNs produced in: sqrt(diag(cov)) 
> 
> # Stable model with disp(ersion)=disp.h(b0+b1*day)
> print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
+ 	iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day, 
    skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2, 
    itail = 1)

-Log likelihood              132.1774 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          137.1774 
Iterations                   70 

Location parameters
ret ~ 1
              estimate        se
(Intercept)  0.0009383  0.002394

Dispersion parameters
~day
             estimate      se
(Intercept)   -4.6768  0.2189
day           -0.6556  0.7402

Skew parameters
~1
             estimate     se
(Intercept)    -10.91  59.32

Tail parameters
~1
             estimate      se
(Intercept)    0.6574  0.7444

Correlations:
          1         2         3         4         5
1  1.000000  0.345026  0.185935 -0.001388 -0.600483
2  0.345026  1.000000 -0.735818  0.002904 -0.458313
3  0.185935 -0.735818  1.000000 -0.006449  0.127329
4 -0.001388  0.002904 -0.006449  1.000000 -0.007393
5 -0.600483 -0.458313  0.127329 -0.007393  1.000000
> 
> # Stable model with skew(ness)=skew.h(b0+b1*day)
> # Evaluation at fixed parameter values (since noopt is set to TRUE)
> print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
+ 	iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
+ 	itail = -5.261e-1, noopt=T))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957, 
    iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)

-Log likelihood              150.2683 
No. of obs                   49 
No. of estimated parameters  0 
No. of parameters            5 
Degrees of freedom           49 
AIC                          150.2683 
> 
> # Stable model with tail=tail.h(b0+b1*day)
> print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
+ 	disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
+ 	idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3, 
    itail = c(2, -7), hessian = F)

Warning: no convergence - error 3 

-Log likelihood              129.4544 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          134.4544 
Iterations                   70 

Location parameters
ret ~ 1
             estimate  se
(Intercept)  0.001694  NA

Dispersion parameters
~1
             estimate  se
(Intercept)    -4.791  NA

Skew parameters
~1
             estimate  se
(Intercept)    -8.805  NA

Tail parameters
~day
             estimate  se
(Intercept)     2.081  NA
day            -7.091  NA
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Dec  8 10:30:20 1999
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 8 Dec 1999 10:30:20 +0100 (MET)
Subject: [R] Stable package on Windows doesn't work???
In-Reply-To: <05da01bf3fff$7419c700$6328acce@bellglobal.com> from "Yves Gauvreau" at Dec 06, 1999 10:34:57 AM
Message-ID: <199912080930.KAA22900@alpha.luc.ac.be>

Yves:
  I am completely baffled by this. I include below my output for these
examples from Intel Pentium II RH5.2 Linux with R90. I get exactly the
same results with MS Windows 98 and R65 on the same machine. I also
tried with R90 and MS Windows 95 on an older Pentium and also got the
same results. What machine exactly did you run this on?
  R-help will remember that I have complained before about numerical
problems with MS Windows but this one beats me. Jim

> 
> Hi Jim,
> 
> Troels Ring told me to get Version 0.7 which I did.
> 
> It's probably me that doesn't understand how it works (I'm new to R) but
> stablereg is supposed to find the most appropriate parameters for the stable
> distribution (loc, disp, skew, tail) given some starting values right?
> 
> When I try the examples that are given with the function help file I get the
> following results.
> 
> ************************************************************
> R : Copyright 1999, The R Development Core Team
> Version 0.90.0  (November 22, 1999)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type   "?license" or "?licence" for distribution details.
> 
> R is a collaborative project with many contributors.
> Type   "?contributors" for a list.
> 
> Type   "demo()" for some demos, "help()" for on-line help, or
>         "help.start()" for a HTML browser interface to help.
> Type    "q()" to quit R.
> 
> > library(stable)
> Loading required package: rmutil
> > help(stablereg)
> > ## Share return over a 50 day period (see reference above)
> >         # shares
> >         y <-
> c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
> +
> 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
> +
> 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)
> >
> >         # returns
> >         ret <- (y[2:50]-y[1:49])/y[1:49]
> >         # hist(ret, breaks=seq(-0.035,0.045,0.01))
> >
> >         day <- seq(0,0.48,by=0.01) # time measured in days/100
> >         x <- seq(1,length(ret))-1
> >
> >         # Classic stationary normal model tail=2
> >         print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
> +              iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1,
>     tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0,
>     otail = F, oskew = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  2
> No. of parameters            4
> Degrees of freedom           47
> AIC                          294.4987
> Iterations                   1
> 
> Location parameters
> ~1
>               estimate       se
> (Intercept)  0.0001445  0.07433
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.055
> 
> Correlations:
>          1        2
> 1  1.00000 -0.01525
> 2 -0.01525  1.00000
> >
> >         # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> >         print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
> +              iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1,
>     skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0,
>     iskew = 0, oskew = F, otail = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  3
> No. of parameters            5
> Degrees of freedom           46
> AIC                          295.4987
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate      se
> (Intercept)   1.445e-04  0.1467
> day          -6.053e-06  0.5265
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.063
> 
> Correlations:
>          1        2        3
> 1  1.00000 -0.86207 -0.06098
> 2 -0.86207  1.00000  0.06159
> 3 -0.06098  0.06159  1.00000
> >
> >         # Stable model with loc(ation)=loc.h(b0+b1*day)
> >         print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
> +              iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~
>     1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0,
>     itail = 0)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              291.591
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          296.591
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate       se
> (Intercept)   0.0004749  0.08946
> day          -0.0001862  0.43214
> 
> Dispersion parameters
> ret ~ 1
>              estimate     se
> (Intercept)   -0.9998  3.340
> 
> Skew parameters
> ~1
>                estimate   se
> (Intercept)  -0.0002456  NaN
> 
> Tail parameters
> ~1
>              estimate   se
> (Intercept)  -0.02018  NaN
> 
> Correlations:
>          1        2        3   4   5
> 1  1.00000 -1.15904 -0.06692 NaN NaN
> 2 -1.15904  1.00000  0.06058 NaN NaN
> 3 -0.06692  0.06058  1.00000 NaN NaN
> 4      NaN      NaN      NaN NaN NaN
> 5      NaN      NaN      NaN NaN NaN
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with disp(ersion)=disp.h(b0+b1*day)
> >         print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
> +              iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day,
>     skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2,
>     itail = 1)
> 
> -Log likelihood              132.1774
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          137.1774
> Iterations                   70
> 
> Location parameters
> ret ~ 1
>              estimate        se
> (Intercept)  0.000938  0.001892
> 
> Dispersion parameters
> ~day
>              estimate       se
> (Intercept)   -4.6768  0.06621
> day           -0.6556  0.61348
> 
> Skew parameters
> ~1
>              estimate   se
> (Intercept)    -10.87  NaN
> 
> Tail parameters
> ~1
>              estimate      se
> (Intercept)    0.6575  0.6067
> 
> Correlations:
>         1       2       3   4       5
> 1  1.0000 -1.0000  0.8075 NaN -0.3810
> 2 -1.0000  1.0000 -0.8075 NaN  0.3810
> 3  0.8075 -0.8075  1.0000 NaN -0.2914
> 4     NaN     NaN     NaN NaN     NaN
> 5 -0.3810  0.3810 -0.2914 NaN  1.0000
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with skew(ness)=skew.h(b0+b1*day)
> >         # Evaluation at fixed parameter values (since noopt is set to
> TRUE)
> >         print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
> +              iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
> +              itail = -5.261e-1, noopt=T))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957,
>     iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)
> 
> -Log likelihood              150.2681
> No. of obs                   49
> No. of estimated parameters  0
> No. of parameters            5
> Degrees of freedom           49
> AIC                          150.2681
> >
> >         # Stable model with tail=tail.h(b0+b1*day)
> >         print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
> +              disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
> +              idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3,
>     itail = c(2, -7), hessian = F)
> 
> -Log likelihood              129.4914
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          134.4914
> Iterations                   83
> 
> Location parameters
> ret ~ 1
>              estimate  se
> (Intercept)  0.001841  NA
> 
> Dispersion parameters
> ~1
>              estimate  se
> (Intercept)    -4.785  NA
> 
> Skew parameters
> ~1
>              estimate  se
> (Intercept)    -13.82  NA
> 
> Tail parameters
> ~day
>              estimate  se
> (Intercept)     1.926  NA
> day            -6.716  NA
> >
> >
> ****************************************************************
> 
> Are those result what they're supposed to be?
> 
> If it is so, I find it confusing that there are NA's, NaN's and/or "Warning:
> no convergence - error 5 "  in practically all results. I took a look at the
> source code and there are 2 messages that give an hint that the result are
> probably ok. It kind of looks like these example are counter example if the
> results are correct that is.
> 
> Is there some documentation for the library, I mean more then the help files
> provide?
> 
> Any help you can provide will be appreciated.
> 
> Thanks.
> 
> Yves Gauvreau
> 
> 
> 
> 
> 

-------------------------------------------------------------------------
from Linux, Jim
-------------------------------------------------------------------------
R : Copyright 1999, The R Development Core Team
Version 0.90.0  (November 22, 1999)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type	"?license" or "?licence" for distribution details.

R is a collaborative project with many contributors.
Type	"?contributors" for a list.

Type	"demo()" for some demos, "help()" for on-line help, or
    	"help.start()" for a HTML browser interface to help.
Type	"q()" to quit R.

> library(stable)
Loading required package: rmutil 
> ## Share return over a 50 day period (see reference above)
> # shares
> y <- c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
+ 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
+ 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)  
> 
> # returns
> ret <- (y[2:50]-y[1:49])/y[1:49]
> # hist(ret, breaks=seq(-0.035,0.045,0.01))
> 
> day <- seq(0,0.48,by=0.01) # time measured in days/100
> x <- seq(1,length(ret))-1
> 
> # Classic stationary normal model tail=2
> print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
+ 	iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1, 
    tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0, 
    otail = F, oskew = F)

-Log likelihood              136.0479 
No. of obs                   49 
No. of estimated parameters  2 
No. of parameters            4 
Degrees of freedom           47 
AIC                          138.0479 
Iterations                   12 

Location parameters
~1
              estimate        se
(Intercept)  0.0002892  0.001851

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.693  0.1010

Correlations:
          1         2
1 1.0000000 0.0003176
2 0.0003176 1.0000000
> 
> # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
+ 	iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1, 
    skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0, 
    iskew = 0, oskew = F, otail = F)

-Log likelihood              135.9994 
No. of obs                   49 
No. of estimated parameters  3 
No. of parameters            5 
Degrees of freedom           46 
AIC                          138.9994 
Iterations                   17 

Location parameters
~day
              estimate        se
(Intercept)   0.001266  0.003643
day          -0.004071  0.013077

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.694  0.1010

Correlations:
          1          2          3
1  1.000000 -0.8615643  0.0009260
2 -0.861564  1.0000000 -0.0009084
3  0.000926 -0.0009084  1.0000000
Warning message: 
NaNs produced in: log(x) 
> 
> # Stable model with loc(ation)=loc.h(b0+b1*day)
> print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
+ 	iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~ 
    1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0, 
    itail = 0)

Warning: no convergence - error 5 

-Log likelihood              135.921 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          140.921 
Iterations                   38 

Location parameters
~day
              estimate        se
(Intercept)   0.001297  0.003607
day          -0.004630  0.012963

Dispersion parameters
ret ~ 1
             estimate      se
(Intercept)    -4.704  0.1005

Skew parameters
~1
             estimate     se
(Intercept)     -5.07  41.76

Tail parameters
~1
             estimate   se
(Intercept)     6.408  NaN

Correlations:
          1         2         3         4   5
1  1.000000 -0.860897  0.003654  0.000318 NaN
2 -0.860897  1.000000 -0.003828 -0.002440 NaN
3  0.003654 -0.003828  1.000000 -0.005568 NaN
4  0.000318 -0.002440 -0.005568  1.000000 NaN
5       NaN       NaN       NaN       NaN NaN
Warning message: 
NaNs produced in: sqrt(diag(cov)) 
> 
> # Stable model with disp(ersion)=disp.h(b0+b1*day)
> print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
+ 	iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day, 
    skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2, 
    itail = 1)

-Log likelihood              132.1774 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          137.1774 
Iterations                   70 

Location parameters
ret ~ 1
              estimate        se
(Intercept)  0.0009383  0.002394

Dispersion parameters
~day
             estimate      se
(Intercept)   -4.6768  0.2189
day           -0.6556  0.7402

Skew parameters
~1
             estimate     se
(Intercept)    -10.91  59.32

Tail parameters
~1
             estimate      se
(Intercept)    0.6574  0.7444

Correlations:
          1         2         3         4         5
1  1.000000  0.345026  0.185935 -0.001388 -0.600483
2  0.345026  1.000000 -0.735818  0.002904 -0.458313
3  0.185935 -0.735818  1.000000 -0.006449  0.127329
4 -0.001388  0.002904 -0.006449  1.000000 -0.007393
5 -0.600483 -0.458313  0.127329 -0.007393  1.000000
> 
> # Stable model with skew(ness)=skew.h(b0+b1*day)
> # Evaluation at fixed parameter values (since noopt is set to TRUE)
> print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
+ 	iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
+ 	itail = -5.261e-1, noopt=T))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957, 
    iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)

-Log likelihood              150.2683 
No. of obs                   49 
No. of estimated parameters  0 
No. of parameters            5 
Degrees of freedom           49 
AIC                          150.2683 
> 
> # Stable model with tail=tail.h(b0+b1*day)
> print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
+ 	disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
+ 	idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3, 
    itail = c(2, -7), hessian = F)

Warning: no convergence - error 3 

-Log likelihood              129.4544 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          134.4544 
Iterations                   70 

Location parameters
ret ~ 1
             estimate  se
(Intercept)  0.001694  NA

Dispersion parameters
~1
             estimate  se
(Intercept)    -4.791  NA

Skew parameters
~1
             estimate  se
(Intercept)    -8.805  NA

Tail parameters
~day
             estimate  se
(Intercept)     2.081  NA
day            -7.091  NA
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Dec  8 10:30:20 1999
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 8 Dec 1999 10:30:20 +0100 (MET)
Subject: [R] Stable package on Windows doesn't work???
In-Reply-To: <05da01bf3fff$7419c700$6328acce@bellglobal.com> from "Yves Gauvreau" at Dec 06, 1999 10:34:57 AM
Message-ID: <199912080930.KAA22900@alpha.luc.ac.be>

Yves:
  I am completely baffled by this. I include below my output for these
examples from Intel Pentium II RH5.2 Linux with R90. I get exactly the
same results with MS Windows 98 and R65 on the same machine. I also
tried with R90 and MS Windows 95 on an older Pentium and also got the
same results. What machine exactly did you run this on?
  R-help will remember that I have complained before about numerical
problems with MS Windows but this one beats me. Jim

> 
> Hi Jim,
> 
> Troels Ring told me to get Version 0.7 which I did.
> 
> It's probably me that doesn't understand how it works (I'm new to R) but
> stablereg is supposed to find the most appropriate parameters for the stable
> distribution (loc, disp, skew, tail) given some starting values right?
> 
> When I try the examples that are given with the function help file I get the
> following results.
> 
> ************************************************************
> R : Copyright 1999, The R Development Core Team
> Version 0.90.0  (November 22, 1999)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type   "?license" or "?licence" for distribution details.
> 
> R is a collaborative project with many contributors.
> Type   "?contributors" for a list.
> 
> Type   "demo()" for some demos, "help()" for on-line help, or
>         "help.start()" for a HTML browser interface to help.
> Type    "q()" to quit R.
> 
> > library(stable)
> Loading required package: rmutil
> > help(stablereg)
> > ## Share return over a 50 day period (see reference above)
> >         # shares
> >         y <-
> c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
> +
> 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
> +
> 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)
> >
> >         # returns
> >         ret <- (y[2:50]-y[1:49])/y[1:49]
> >         # hist(ret, breaks=seq(-0.035,0.045,0.01))
> >
> >         day <- seq(0,0.48,by=0.01) # time measured in days/100
> >         x <- seq(1,length(ret))-1
> >
> >         # Classic stationary normal model tail=2
> >         print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
> +              iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1,
>     tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0,
>     otail = F, oskew = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  2
> No. of parameters            4
> Degrees of freedom           47
> AIC                          294.4987
> Iterations                   1
> 
> Location parameters
> ~1
>               estimate       se
> (Intercept)  0.0001445  0.07433
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.055
> 
> Correlations:
>          1        2
> 1  1.00000 -0.01525
> 2 -0.01525  1.00000
> >
> >         # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> >         print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
> +              iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1,
>     skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0,
>     iskew = 0, oskew = F, otail = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  3
> No. of parameters            5
> Degrees of freedom           46
> AIC                          295.4987
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate      se
> (Intercept)   1.445e-04  0.1467
> day          -6.053e-06  0.5265
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.063
> 
> Correlations:
>          1        2        3
> 1  1.00000 -0.86207 -0.06098
> 2 -0.86207  1.00000  0.06159
> 3 -0.06098  0.06159  1.00000
> >
> >         # Stable model with loc(ation)=loc.h(b0+b1*day)
> >         print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
> +              iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~
>     1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0,
>     itail = 0)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              291.591
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          296.591
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate       se
> (Intercept)   0.0004749  0.08946
> day          -0.0001862  0.43214
> 
> Dispersion parameters
> ret ~ 1
>              estimate     se
> (Intercept)   -0.9998  3.340
> 
> Skew parameters
> ~1
>                estimate   se
> (Intercept)  -0.0002456  NaN
> 
> Tail parameters
> ~1
>              estimate   se
> (Intercept)  -0.02018  NaN
> 
> Correlations:
>          1        2        3   4   5
> 1  1.00000 -1.15904 -0.06692 NaN NaN
> 2 -1.15904  1.00000  0.06058 NaN NaN
> 3 -0.06692  0.06058  1.00000 NaN NaN
> 4      NaN      NaN      NaN NaN NaN
> 5      NaN      NaN      NaN NaN NaN
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with disp(ersion)=disp.h(b0+b1*day)
> >         print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
> +              iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day,
>     skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2,
>     itail = 1)
> 
> -Log likelihood              132.1774
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          137.1774
> Iterations                   70
> 
> Location parameters
> ret ~ 1
>              estimate        se
> (Intercept)  0.000938  0.001892
> 
> Dispersion parameters
> ~day
>              estimate       se
> (Intercept)   -4.6768  0.06621
> day           -0.6556  0.61348
> 
> Skew parameters
> ~1
>              estimate   se
> (Intercept)    -10.87  NaN
> 
> Tail parameters
> ~1
>              estimate      se
> (Intercept)    0.6575  0.6067
> 
> Correlations:
>         1       2       3   4       5
> 1  1.0000 -1.0000  0.8075 NaN -0.3810
> 2 -1.0000  1.0000 -0.8075 NaN  0.3810
> 3  0.8075 -0.8075  1.0000 NaN -0.2914
> 4     NaN     NaN     NaN NaN     NaN
> 5 -0.3810  0.3810 -0.2914 NaN  1.0000
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with skew(ness)=skew.h(b0+b1*day)
> >         # Evaluation at fixed parameter values (since noopt is set to
> TRUE)
> >         print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
> +              iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
> +              itail = -5.261e-1, noopt=T))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957,
>     iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)
> 
> -Log likelihood              150.2681
> No. of obs                   49
> No. of estimated parameters  0
> No. of parameters            5
> Degrees of freedom           49
> AIC                          150.2681
> >
> >         # Stable model with tail=tail.h(b0+b1*day)
> >         print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
> +              disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
> +              idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3,
>     itail = c(2, -7), hessian = F)
> 
> -Log likelihood              129.4914
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          134.4914
> Iterations                   83
> 
> Location parameters
> ret ~ 1
>              estimate  se
> (Intercept)  0.001841  NA
> 
> Dispersion parameters
> ~1
>              estimate  se
> (Intercept)    -4.785  NA
> 
> Skew parameters
> ~1
>              estimate  se
> (Intercept)    -13.82  NA
> 
> Tail parameters
> ~day
>              estimate  se
> (Intercept)     1.926  NA
> day            -6.716  NA
> >
> >
> ****************************************************************
> 
> Are those result what they're supposed to be?
> 
> If it is so, I find it confusing that there are NA's, NaN's and/or "Warning:
> no convergence - error 5 "  in practically all results. I took a look at the
> source code and there are 2 messages that give an hint that the result are
> probably ok. It kind of looks like these example are counter example if the
> results are correct that is.
> 
> Is there some documentation for the library, I mean more then the help files
> provide?
> 
> Any help you can provide will be appreciated.
> 
> Thanks.
> 
> Yves Gauvreau
> 
> 
> 
> 
> 

-------------------------------------------------------------------------
from Linux, Jim
-------------------------------------------------------------------------
R : Copyright 1999, The R Development Core Team
Version 0.90.0  (November 22, 1999)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type	"?license" or "?licence" for distribution details.

R is a collaborative project with many contributors.
Type	"?contributors" for a list.

Type	"demo()" for some demos, "help()" for on-line help, or
    	"help.start()" for a HTML browser interface to help.
Type	"q()" to quit R.

> library(stable)
Loading required package: rmutil 
> ## Share return over a 50 day period (see reference above)
> # shares
> y <- c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
+ 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
+ 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)  
> 
> # returns
> ret <- (y[2:50]-y[1:49])/y[1:49]
> # hist(ret, breaks=seq(-0.035,0.045,0.01))
> 
> day <- seq(0,0.48,by=0.01) # time measured in days/100
> x <- seq(1,length(ret))-1
> 
> # Classic stationary normal model tail=2
> print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
+ 	iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1, 
    tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0, 
    otail = F, oskew = F)

-Log likelihood              136.0479 
No. of obs                   49 
No. of estimated parameters  2 
No. of parameters            4 
Degrees of freedom           47 
AIC                          138.0479 
Iterations                   12 

Location parameters
~1
              estimate        se
(Intercept)  0.0002892  0.001851

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.693  0.1010

Correlations:
          1         2
1 1.0000000 0.0003176
2 0.0003176 1.0000000
> 
> # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
+ 	iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1, 
    skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0, 
    iskew = 0, oskew = F, otail = F)

-Log likelihood              135.9994 
No. of obs                   49 
No. of estimated parameters  3 
No. of parameters            5 
Degrees of freedom           46 
AIC                          138.9994 
Iterations                   17 

Location parameters
~day
              estimate        se
(Intercept)   0.001266  0.003643
day          -0.004071  0.013077

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.694  0.1010

Correlations:
          1          2          3
1  1.000000 -0.8615643  0.0009260
2 -0.861564  1.0000000 -0.0009084
3  0.000926 -0.0009084  1.0000000
Warning message: 
NaNs produced in: log(x) 
> 
> # Stable model with loc(ation)=loc.h(b0+b1*day)
> print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
+ 	iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~ 
    1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0, 
    itail = 0)

Warning: no convergence - error 5 

-Log likelihood              135.921 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          140.921 
Iterations                   38 

Location parameters
~day
              estimate        se
(Intercept)   0.001297  0.003607
day          -0.004630  0.012963

Dispersion parameters
ret ~ 1
             estimate      se
(Intercept)    -4.704  0.1005

Skew parameters
~1
             estimate     se
(Intercept)     -5.07  41.76

Tail parameters
~1
             estimate   se
(Intercept)     6.408  NaN

Correlations:
          1         2         3         4   5
1  1.000000 -0.860897  0.003654  0.000318 NaN
2 -0.860897  1.000000 -0.003828 -0.002440 NaN
3  0.003654 -0.003828  1.000000 -0.005568 NaN
4  0.000318 -0.002440 -0.005568  1.000000 NaN
5       NaN       NaN       NaN       NaN NaN
Warning message: 
NaNs produced in: sqrt(diag(cov)) 
> 
> # Stable model with disp(ersion)=disp.h(b0+b1*day)
> print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
+ 	iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day, 
    skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2, 
    itail = 1)

-Log likelihood              132.1774 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          137.1774 
Iterations                   70 

Location parameters
ret ~ 1
              estimate        se
(Intercept)  0.0009383  0.002394

Dispersion parameters
~day
             estimate      se
(Intercept)   -4.6768  0.2189
day           -0.6556  0.7402

Skew parameters
~1
             estimate     se
(Intercept)    -10.91  59.32

Tail parameters
~1
             estimate      se
(Intercept)    0.6574  0.7444

Correlations:
          1         2         3         4         5
1  1.000000  0.345026  0.185935 -0.001388 -0.600483
2  0.345026  1.000000 -0.735818  0.002904 -0.458313
3  0.185935 -0.735818  1.000000 -0.006449  0.127329
4 -0.001388  0.002904 -0.006449  1.000000 -0.007393
5 -0.600483 -0.458313  0.127329 -0.007393  1.000000
> 
> # Stable model with skew(ness)=skew.h(b0+b1*day)
> # Evaluation at fixed parameter values (since noopt is set to TRUE)
> print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
+ 	iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
+ 	itail = -5.261e-1, noopt=T))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957, 
    iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)

-Log likelihood              150.2683 
No. of obs                   49 
No. of estimated parameters  0 
No. of parameters            5 
Degrees of freedom           49 
AIC                          150.2683 
> 
> # Stable model with tail=tail.h(b0+b1*day)
> print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
+ 	disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
+ 	idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3, 
    itail = c(2, -7), hessian = F)

Warning: no convergence - error 3 

-Log likelihood              129.4544 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          134.4544 
Iterations                   70 

Location parameters
ret ~ 1
             estimate  se
(Intercept)  0.001694  NA

Dispersion parameters
~1
             estimate  se
(Intercept)    -4.791  NA

Skew parameters
~1
             estimate  se
(Intercept)    -8.805  NA

Tail parameters
~day
             estimate  se
(Intercept)     2.081  NA
day            -7.091  NA
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Dec  8 10:30:20 1999
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 8 Dec 1999 10:30:20 +0100 (MET)
Subject: [R] Stable package on Windows doesn't work???
In-Reply-To: <05da01bf3fff$7419c700$6328acce@bellglobal.com> from "Yves Gauvreau" at Dec 06, 1999 10:34:57 AM
Message-ID: <199912080930.KAA22900@alpha.luc.ac.be>

Yves:
  I am completely baffled by this. I include below my output for these
examples from Intel Pentium II RH5.2 Linux with R90. I get exactly the
same results with MS Windows 98 and R65 on the same machine. I also
tried with R90 and MS Windows 95 on an older Pentium and also got the
same results. What machine exactly did you run this on?
  R-help will remember that I have complained before about numerical
problems with MS Windows but this one beats me. Jim

> 
> Hi Jim,
> 
> Troels Ring told me to get Version 0.7 which I did.
> 
> It's probably me that doesn't understand how it works (I'm new to R) but
> stablereg is supposed to find the most appropriate parameters for the stable
> distribution (loc, disp, skew, tail) given some starting values right?
> 
> When I try the examples that are given with the function help file I get the
> following results.
> 
> ************************************************************
> R : Copyright 1999, The R Development Core Team
> Version 0.90.0  (November 22, 1999)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type   "?license" or "?licence" for distribution details.
> 
> R is a collaborative project with many contributors.
> Type   "?contributors" for a list.
> 
> Type   "demo()" for some demos, "help()" for on-line help, or
>         "help.start()" for a HTML browser interface to help.
> Type    "q()" to quit R.
> 
> > library(stable)
> Loading required package: rmutil
> > help(stablereg)
> > ## Share return over a 50 day period (see reference above)
> >         # shares
> >         y <-
> c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
> +
> 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
> +
> 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)
> >
> >         # returns
> >         ret <- (y[2:50]-y[1:49])/y[1:49]
> >         # hist(ret, breaks=seq(-0.035,0.045,0.01))
> >
> >         day <- seq(0,0.48,by=0.01) # time measured in days/100
> >         x <- seq(1,length(ret))-1
> >
> >         # Classic stationary normal model tail=2
> >         print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
> +              iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1,
>     tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0,
>     otail = F, oskew = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  2
> No. of parameters            4
> Degrees of freedom           47
> AIC                          294.4987
> Iterations                   1
> 
> Location parameters
> ~1
>               estimate       se
> (Intercept)  0.0001445  0.07433
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.055
> 
> Correlations:
>          1        2
> 1  1.00000 -0.01525
> 2 -0.01525  1.00000
> >
> >         # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> >         print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
> +              iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1,
>     skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0,
>     iskew = 0, oskew = F, otail = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  3
> No. of parameters            5
> Degrees of freedom           46
> AIC                          295.4987
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate      se
> (Intercept)   1.445e-04  0.1467
> day          -6.053e-06  0.5265
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.063
> 
> Correlations:
>          1        2        3
> 1  1.00000 -0.86207 -0.06098
> 2 -0.86207  1.00000  0.06159
> 3 -0.06098  0.06159  1.00000
> >
> >         # Stable model with loc(ation)=loc.h(b0+b1*day)
> >         print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
> +              iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~
>     1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0,
>     itail = 0)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              291.591
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          296.591
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate       se
> (Intercept)   0.0004749  0.08946
> day          -0.0001862  0.43214
> 
> Dispersion parameters
> ret ~ 1
>              estimate     se
> (Intercept)   -0.9998  3.340
> 
> Skew parameters
> ~1
>                estimate   se
> (Intercept)  -0.0002456  NaN
> 
> Tail parameters
> ~1
>              estimate   se
> (Intercept)  -0.02018  NaN
> 
> Correlations:
>          1        2        3   4   5
> 1  1.00000 -1.15904 -0.06692 NaN NaN
> 2 -1.15904  1.00000  0.06058 NaN NaN
> 3 -0.06692  0.06058  1.00000 NaN NaN
> 4      NaN      NaN      NaN NaN NaN
> 5      NaN      NaN      NaN NaN NaN
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with disp(ersion)=disp.h(b0+b1*day)
> >         print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
> +              iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day,
>     skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2,
>     itail = 1)
> 
> -Log likelihood              132.1774
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          137.1774
> Iterations                   70
> 
> Location parameters
> ret ~ 1
>              estimate        se
> (Intercept)  0.000938  0.001892
> 
> Dispersion parameters
> ~day
>              estimate       se
> (Intercept)   -4.6768  0.06621
> day           -0.6556  0.61348
> 
> Skew parameters
> ~1
>              estimate   se
> (Intercept)    -10.87  NaN
> 
> Tail parameters
> ~1
>              estimate      se
> (Intercept)    0.6575  0.6067
> 
> Correlations:
>         1       2       3   4       5
> 1  1.0000 -1.0000  0.8075 NaN -0.3810
> 2 -1.0000  1.0000 -0.8075 NaN  0.3810
> 3  0.8075 -0.8075  1.0000 NaN -0.2914
> 4     NaN     NaN     NaN NaN     NaN
> 5 -0.3810  0.3810 -0.2914 NaN  1.0000
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with skew(ness)=skew.h(b0+b1*day)
> >         # Evaluation at fixed parameter values (since noopt is set to
> TRUE)
> >         print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
> +              iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
> +              itail = -5.261e-1, noopt=T))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957,
>     iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)
> 
> -Log likelihood              150.2681
> No. of obs                   49
> No. of estimated parameters  0
> No. of parameters            5
> Degrees of freedom           49
> AIC                          150.2681
> >
> >         # Stable model with tail=tail.h(b0+b1*day)
> >         print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
> +              disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
> +              idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3,
>     itail = c(2, -7), hessian = F)
> 
> -Log likelihood              129.4914
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          134.4914
> Iterations                   83
> 
> Location parameters
> ret ~ 1
>              estimate  se
> (Intercept)  0.001841  NA
> 
> Dispersion parameters
> ~1
>              estimate  se
> (Intercept)    -4.785  NA
> 
> Skew parameters
> ~1
>              estimate  se
> (Intercept)    -13.82  NA
> 
> Tail parameters
> ~day
>              estimate  se
> (Intercept)     1.926  NA
> day            -6.716  NA
> >
> >
> ****************************************************************
> 
> Are those result what they're supposed to be?
> 
> If it is so, I find it confusing that there are NA's, NaN's and/or "Warning:
> no convergence - error 5 "  in practically all results. I took a look at the
> source code and there are 2 messages that give an hint that the result are
> probably ok. It kind of looks like these example are counter example if the
> results are correct that is.
> 
> Is there some documentation for the library, I mean more then the help files
> provide?
> 
> Any help you can provide will be appreciated.
> 
> Thanks.
> 
> Yves Gauvreau
> 
> 
> 
> 
> 

-------------------------------------------------------------------------
from Linux, Jim
-------------------------------------------------------------------------
R : Copyright 1999, The R Development Core Team
Version 0.90.0  (November 22, 1999)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type	"?license" or "?licence" for distribution details.

R is a collaborative project with many contributors.
Type	"?contributors" for a list.

Type	"demo()" for some demos, "help()" for on-line help, or
    	"help.start()" for a HTML browser interface to help.
Type	"q()" to quit R.

> library(stable)
Loading required package: rmutil 
> ## Share return over a 50 day period (see reference above)
> # shares
> y <- c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
+ 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
+ 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)  
> 
> # returns
> ret <- (y[2:50]-y[1:49])/y[1:49]
> # hist(ret, breaks=seq(-0.035,0.045,0.01))
> 
> day <- seq(0,0.48,by=0.01) # time measured in days/100
> x <- seq(1,length(ret))-1
> 
> # Classic stationary normal model tail=2
> print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
+ 	iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1, 
    tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0, 
    otail = F, oskew = F)

-Log likelihood              136.0479 
No. of obs                   49 
No. of estimated parameters  2 
No. of parameters            4 
Degrees of freedom           47 
AIC                          138.0479 
Iterations                   12 

Location parameters
~1
              estimate        se
(Intercept)  0.0002892  0.001851

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.693  0.1010

Correlations:
          1         2
1 1.0000000 0.0003176
2 0.0003176 1.0000000
> 
> # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
+ 	iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1, 
    skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0, 
    iskew = 0, oskew = F, otail = F)

-Log likelihood              135.9994 
No. of obs                   49 
No. of estimated parameters  3 
No. of parameters            5 
Degrees of freedom           46 
AIC                          138.9994 
Iterations                   17 

Location parameters
~day
              estimate        se
(Intercept)   0.001266  0.003643
day          -0.004071  0.013077

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.694  0.1010

Correlations:
          1          2          3
1  1.000000 -0.8615643  0.0009260
2 -0.861564  1.0000000 -0.0009084
3  0.000926 -0.0009084  1.0000000
Warning message: 
NaNs produced in: log(x) 
> 
> # Stable model with loc(ation)=loc.h(b0+b1*day)
> print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
+ 	iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~ 
    1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0, 
    itail = 0)

Warning: no convergence - error 5 

-Log likelihood              135.921 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          140.921 
Iterations                   38 

Location parameters
~day
              estimate        se
(Intercept)   0.001297  0.003607
day          -0.004630  0.012963

Dispersion parameters
ret ~ 1
             estimate      se
(Intercept)    -4.704  0.1005

Skew parameters
~1
             estimate     se
(Intercept)     -5.07  41.76

Tail parameters
~1
             estimate   se
(Intercept)     6.408  NaN

Correlations:
          1         2         3         4   5
1  1.000000 -0.860897  0.003654  0.000318 NaN
2 -0.860897  1.000000 -0.003828 -0.002440 NaN
3  0.003654 -0.003828  1.000000 -0.005568 NaN
4  0.000318 -0.002440 -0.005568  1.000000 NaN
5       NaN       NaN       NaN       NaN NaN
Warning message: 
NaNs produced in: sqrt(diag(cov)) 
> 
> # Stable model with disp(ersion)=disp.h(b0+b1*day)
> print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
+ 	iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day, 
    skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2, 
    itail = 1)

-Log likelihood              132.1774 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          137.1774 
Iterations                   70 

Location parameters
ret ~ 1
              estimate        se
(Intercept)  0.0009383  0.002394

Dispersion parameters
~day
             estimate      se
(Intercept)   -4.6768  0.2189
day           -0.6556  0.7402

Skew parameters
~1
             estimate     se
(Intercept)    -10.91  59.32

Tail parameters
~1
             estimate      se
(Intercept)    0.6574  0.7444

Correlations:
          1         2         3         4         5
1  1.000000  0.345026  0.185935 -0.001388 -0.600483
2  0.345026  1.000000 -0.735818  0.002904 -0.458313
3  0.185935 -0.735818  1.000000 -0.006449  0.127329
4 -0.001388  0.002904 -0.006449  1.000000 -0.007393
5 -0.600483 -0.458313  0.127329 -0.007393  1.000000
> 
> # Stable model with skew(ness)=skew.h(b0+b1*day)
> # Evaluation at fixed parameter values (since noopt is set to TRUE)
> print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
+ 	iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
+ 	itail = -5.261e-1, noopt=T))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957, 
    iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)

-Log likelihood              150.2683 
No. of obs                   49 
No. of estimated parameters  0 
No. of parameters            5 
Degrees of freedom           49 
AIC                          150.2683 
> 
> # Stable model with tail=tail.h(b0+b1*day)
> print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
+ 	disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
+ 	idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3, 
    itail = c(2, -7), hessian = F)

Warning: no convergence - error 3 

-Log likelihood              129.4544 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          134.4544 
Iterations                   70 

Location parameters
ret ~ 1
             estimate  se
(Intercept)  0.001694  NA

Dispersion parameters
~1
             estimate  se
(Intercept)    -4.791  NA

Skew parameters
~1
             estimate  se
(Intercept)    -8.805  NA

Tail parameters
~day
             estimate  se
(Intercept)     2.081  NA
day            -7.091  NA
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.C.Rougier at durham.ac.uk  Wed Dec  8 11:14:33 1999
From: J.C.Rougier at durham.ac.uk (Jonathan Rougier)
Date: Wed, 8 Dec 1999 10:14:33 +0000 (GMT)
Subject: [R] Reply to list policy
In-Reply-To: <XFMail.991207190032.plummer@iarc.fr>
Message-ID: <Pine.GSO.4.20.9912081007520.25011-100000@laplace>

On Tue, 7 Dec 1999, Martyn Plummer wrote:

> Recently R-help has been too busy for me to keep up with.  There were
> quite a few identical responses in the "Finding indices with a certain
> property" thread, rather than an extended discussion.  I think this 
> illustrates the need for a reply to author policy.
> 
> Does anybody else feel the same way?

I do, at least a bit.  I expect many people operate an informal reply to
author policy anyhow.  For example, my response to the which() question
would normally have gone only to the author, but I find which() to be a
very useful function and was myself unaware of it until quite recently.  
Hence I also mailed back to r-help.  I don't think we would need to
formalise such an arrangement, but it is important to encourage posting of
summaries if r-help does not carry a comprehensive answer.

Cheers, Jonathan.

Jonathan Rougier                       Science Laboratories
Department of Mathematical Sciences    South Road
University of Durham                   Durham DH1 3LE

"[B]egin upon the precept ... that the things we see are to be 
 weighed in the scale with what we know"  (Meredith, 1879, The Egoist)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Dec  8 10:30:20 1999
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 8 Dec 1999 10:30:20 +0100 (MET)
Subject: [R] Stable package on Windows doesn't work???
In-Reply-To: <05da01bf3fff$7419c700$6328acce@bellglobal.com> from "Yves Gauvreau" at Dec 06, 1999 10:34:57 AM
Message-ID: <199912080930.KAA22900@alpha.luc.ac.be>

Yves:
  I am completely baffled by this. I include below my output for these
examples from Intel Pentium II RH5.2 Linux with R90. I get exactly the
same results with MS Windows 98 and R65 on the same machine. I also
tried with R90 and MS Windows 95 on an older Pentium and also got the
same results. What machine exactly did you run this on?
  R-help will remember that I have complained before about numerical
problems with MS Windows but this one beats me. Jim

> 
> Hi Jim,
> 
> Troels Ring told me to get Version 0.7 which I did.
> 
> It's probably me that doesn't understand how it works (I'm new to R) but
> stablereg is supposed to find the most appropriate parameters for the stable
> distribution (loc, disp, skew, tail) given some starting values right?
> 
> When I try the examples that are given with the function help file I get the
> following results.
> 
> ************************************************************
> R : Copyright 1999, The R Development Core Team
> Version 0.90.0  (November 22, 1999)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type   "?license" or "?licence" for distribution details.
> 
> R is a collaborative project with many contributors.
> Type   "?contributors" for a list.
> 
> Type   "demo()" for some demos, "help()" for on-line help, or
>         "help.start()" for a HTML browser interface to help.
> Type    "q()" to quit R.
> 
> > library(stable)
> Loading required package: rmutil
> > help(stablereg)
> > ## Share return over a 50 day period (see reference above)
> >         # shares
> >         y <-
> c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
> +
> 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
> +
> 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)
> >
> >         # returns
> >         ret <- (y[2:50]-y[1:49])/y[1:49]
> >         # hist(ret, breaks=seq(-0.035,0.045,0.01))
> >
> >         day <- seq(0,0.48,by=0.01) # time measured in days/100
> >         x <- seq(1,length(ret))-1
> >
> >         # Classic stationary normal model tail=2
> >         print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
> +              iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1,
>     tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0,
>     otail = F, oskew = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  2
> No. of parameters            4
> Degrees of freedom           47
> AIC                          294.4987
> Iterations                   1
> 
> Location parameters
> ~1
>               estimate       se
> (Intercept)  0.0001445  0.07433
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.055
> 
> Correlations:
>          1        2
> 1  1.00000 -0.01525
> 2 -0.01525  1.00000
> >
> >         # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> >         print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
> +              iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1,
>     skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0,
>     iskew = 0, oskew = F, otail = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  3
> No. of parameters            5
> Degrees of freedom           46
> AIC                          295.4987
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate      se
> (Intercept)   1.445e-04  0.1467
> day          -6.053e-06  0.5265
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.063
> 
> Correlations:
>          1        2        3
> 1  1.00000 -0.86207 -0.06098
> 2 -0.86207  1.00000  0.06159
> 3 -0.06098  0.06159  1.00000
> >
> >         # Stable model with loc(ation)=loc.h(b0+b1*day)
> >         print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
> +              iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~
>     1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0,
>     itail = 0)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              291.591
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          296.591
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate       se
> (Intercept)   0.0004749  0.08946
> day          -0.0001862  0.43214
> 
> Dispersion parameters
> ret ~ 1
>              estimate     se
> (Intercept)   -0.9998  3.340
> 
> Skew parameters
> ~1
>                estimate   se
> (Intercept)  -0.0002456  NaN
> 
> Tail parameters
> ~1
>              estimate   se
> (Intercept)  -0.02018  NaN
> 
> Correlations:
>          1        2        3   4   5
> 1  1.00000 -1.15904 -0.06692 NaN NaN
> 2 -1.15904  1.00000  0.06058 NaN NaN
> 3 -0.06692  0.06058  1.00000 NaN NaN
> 4      NaN      NaN      NaN NaN NaN
> 5      NaN      NaN      NaN NaN NaN
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with disp(ersion)=disp.h(b0+b1*day)
> >         print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
> +              iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day,
>     skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2,
>     itail = 1)
> 
> -Log likelihood              132.1774
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          137.1774
> Iterations                   70
> 
> Location parameters
> ret ~ 1
>              estimate        se
> (Intercept)  0.000938  0.001892
> 
> Dispersion parameters
> ~day
>              estimate       se
> (Intercept)   -4.6768  0.06621
> day           -0.6556  0.61348
> 
> Skew parameters
> ~1
>              estimate   se
> (Intercept)    -10.87  NaN
> 
> Tail parameters
> ~1
>              estimate      se
> (Intercept)    0.6575  0.6067
> 
> Correlations:
>         1       2       3   4       5
> 1  1.0000 -1.0000  0.8075 NaN -0.3810
> 2 -1.0000  1.0000 -0.8075 NaN  0.3810
> 3  0.8075 -0.8075  1.0000 NaN -0.2914
> 4     NaN     NaN     NaN NaN     NaN
> 5 -0.3810  0.3810 -0.2914 NaN  1.0000
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with skew(ness)=skew.h(b0+b1*day)
> >         # Evaluation at fixed parameter values (since noopt is set to
> TRUE)
> >         print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
> +              iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
> +              itail = -5.261e-1, noopt=T))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957,
>     iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)
> 
> -Log likelihood              150.2681
> No. of obs                   49
> No. of estimated parameters  0
> No. of parameters            5
> Degrees of freedom           49
> AIC                          150.2681
> >
> >         # Stable model with tail=tail.h(b0+b1*day)
> >         print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
> +              disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
> +              idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3,
>     itail = c(2, -7), hessian = F)
> 
> -Log likelihood              129.4914
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          134.4914
> Iterations                   83
> 
> Location parameters
> ret ~ 1
>              estimate  se
> (Intercept)  0.001841  NA
> 
> Dispersion parameters
> ~1
>              estimate  se
> (Intercept)    -4.785  NA
> 
> Skew parameters
> ~1
>              estimate  se
> (Intercept)    -13.82  NA
> 
> Tail parameters
> ~day
>              estimate  se
> (Intercept)     1.926  NA
> day            -6.716  NA
> >
> >
> ****************************************************************
> 
> Are those result what they're supposed to be?
> 
> If it is so, I find it confusing that there are NA's, NaN's and/or "Warning:
> no convergence - error 5 "  in practically all results. I took a look at the
> source code and there are 2 messages that give an hint that the result are
> probably ok. It kind of looks like these example are counter example if the
> results are correct that is.
> 
> Is there some documentation for the library, I mean more then the help files
> provide?
> 
> Any help you can provide will be appreciated.
> 
> Thanks.
> 
> Yves Gauvreau
> 
> 
> 
> 
> 

-------------------------------------------------------------------------
from Linux, Jim
-------------------------------------------------------------------------
R : Copyright 1999, The R Development Core Team
Version 0.90.0  (November 22, 1999)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type	"?license" or "?licence" for distribution details.

R is a collaborative project with many contributors.
Type	"?contributors" for a list.

Type	"demo()" for some demos, "help()" for on-line help, or
    	"help.start()" for a HTML browser interface to help.
Type	"q()" to quit R.

> library(stable)
Loading required package: rmutil 
> ## Share return over a 50 day period (see reference above)
> # shares
> y <- c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
+ 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
+ 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)  
> 
> # returns
> ret <- (y[2:50]-y[1:49])/y[1:49]
> # hist(ret, breaks=seq(-0.035,0.045,0.01))
> 
> day <- seq(0,0.48,by=0.01) # time measured in days/100
> x <- seq(1,length(ret))-1
> 
> # Classic stationary normal model tail=2
> print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
+ 	iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1, 
    tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0, 
    otail = F, oskew = F)

-Log likelihood              136.0479 
No. of obs                   49 
No. of estimated parameters  2 
No. of parameters            4 
Degrees of freedom           47 
AIC                          138.0479 
Iterations                   12 

Location parameters
~1
              estimate        se
(Intercept)  0.0002892  0.001851

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.693  0.1010

Correlations:
          1         2
1 1.0000000 0.0003176
2 0.0003176 1.0000000
> 
> # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
+ 	iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1, 
    skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0, 
    iskew = 0, oskew = F, otail = F)

-Log likelihood              135.9994 
No. of obs                   49 
No. of estimated parameters  3 
No. of parameters            5 
Degrees of freedom           46 
AIC                          138.9994 
Iterations                   17 

Location parameters
~day
              estimate        se
(Intercept)   0.001266  0.003643
day          -0.004071  0.013077

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.694  0.1010

Correlations:
          1          2          3
1  1.000000 -0.8615643  0.0009260
2 -0.861564  1.0000000 -0.0009084
3  0.000926 -0.0009084  1.0000000
Warning message: 
NaNs produced in: log(x) 
> 
> # Stable model with loc(ation)=loc.h(b0+b1*day)
> print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
+ 	iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~ 
    1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0, 
    itail = 0)

Warning: no convergence - error 5 

-Log likelihood              135.921 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          140.921 
Iterations                   38 

Location parameters
~day
              estimate        se
(Intercept)   0.001297  0.003607
day          -0.004630  0.012963

Dispersion parameters
ret ~ 1
             estimate      se
(Intercept)    -4.704  0.1005

Skew parameters
~1
             estimate     se
(Intercept)     -5.07  41.76

Tail parameters
~1
             estimate   se
(Intercept)     6.408  NaN

Correlations:
          1         2         3         4   5
1  1.000000 -0.860897  0.003654  0.000318 NaN
2 -0.860897  1.000000 -0.003828 -0.002440 NaN
3  0.003654 -0.003828  1.000000 -0.005568 NaN
4  0.000318 -0.002440 -0.005568  1.000000 NaN
5       NaN       NaN       NaN       NaN NaN
Warning message: 
NaNs produced in: sqrt(diag(cov)) 
> 
> # Stable model with disp(ersion)=disp.h(b0+b1*day)
> print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
+ 	iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day, 
    skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2, 
    itail = 1)

-Log likelihood              132.1774 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          137.1774 
Iterations                   70 

Location parameters
ret ~ 1
              estimate        se
(Intercept)  0.0009383  0.002394

Dispersion parameters
~day
             estimate      se
(Intercept)   -4.6768  0.2189
day           -0.6556  0.7402

Skew parameters
~1
             estimate     se
(Intercept)    -10.91  59.32

Tail parameters
~1
             estimate      se
(Intercept)    0.6574  0.7444

Correlations:
          1         2         3         4         5
1  1.000000  0.345026  0.185935 -0.001388 -0.600483
2  0.345026  1.000000 -0.735818  0.002904 -0.458313
3  0.185935 -0.735818  1.000000 -0.006449  0.127329
4 -0.001388  0.002904 -0.006449  1.000000 -0.007393
5 -0.600483 -0.458313  0.127329 -0.007393  1.000000
> 
> # Stable model with skew(ness)=skew.h(b0+b1*day)
> # Evaluation at fixed parameter values (since noopt is set to TRUE)
> print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
+ 	iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
+ 	itail = -5.261e-1, noopt=T))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957, 
    iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)

-Log likelihood              150.2683 
No. of obs                   49 
No. of estimated parameters  0 
No. of parameters            5 
Degrees of freedom           49 
AIC                          150.2683 
> 
> # Stable model with tail=tail.h(b0+b1*day)
> print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
+ 	disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
+ 	idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3, 
    itail = c(2, -7), hessian = F)

Warning: no convergence - error 3 

-Log likelihood              129.4544 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          134.4544 
Iterations                   70 

Location parameters
ret ~ 1
             estimate  se
(Intercept)  0.001694  NA

Dispersion parameters
~1
             estimate  se
(Intercept)    -4.791  NA

Skew parameters
~1
             estimate  se
(Intercept)    -8.805  NA

Tail parameters
~day
             estimate  se
(Intercept)     2.081  NA
day            -7.091  NA
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.C.Rougier at durham.ac.uk  Wed Dec  8 11:14:33 1999
From: J.C.Rougier at durham.ac.uk (Jonathan Rougier)
Date: Wed, 8 Dec 1999 10:14:33 +0000 (GMT)
Subject: [R] Reply to list policy
In-Reply-To: <XFMail.991207190032.plummer@iarc.fr>
Message-ID: <Pine.GSO.4.20.9912081007520.25011-100000@laplace>

On Tue, 7 Dec 1999, Martyn Plummer wrote:

> Recently R-help has been too busy for me to keep up with.  There were
> quite a few identical responses in the "Finding indices with a certain
> property" thread, rather than an extended discussion.  I think this 
> illustrates the need for a reply to author policy.
> 
> Does anybody else feel the same way?

I do, at least a bit.  I expect many people operate an informal reply to
author policy anyhow.  For example, my response to the which() question
would normally have gone only to the author, but I find which() to be a
very useful function and was myself unaware of it until quite recently.  
Hence I also mailed back to r-help.  I don't think we would need to
formalise such an arrangement, but it is important to encourage posting of
summaries if r-help does not carry a comprehensive answer.

Cheers, Jonathan.

Jonathan Rougier                       Science Laboratories
Department of Mathematical Sciences    South Road
University of Durham                   Durham DH1 3LE

"[B]egin upon the precept ... that the things we see are to be 
 weighed in the scale with what we know"  (Meredith, 1879, The Egoist)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Dec  8 10:30:20 1999
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 8 Dec 1999 10:30:20 +0100 (MET)
Subject: [R] Stable package on Windows doesn't work???
In-Reply-To: <05da01bf3fff$7419c700$6328acce@bellglobal.com> from "Yves Gauvreau" at Dec 06, 1999 10:34:57 AM
Message-ID: <199912080930.KAA22900@alpha.luc.ac.be>

Yves:
  I am completely baffled by this. I include below my output for these
examples from Intel Pentium II RH5.2 Linux with R90. I get exactly the
same results with MS Windows 98 and R65 on the same machine. I also
tried with R90 and MS Windows 95 on an older Pentium and also got the
same results. What machine exactly did you run this on?
  R-help will remember that I have complained before about numerical
problems with MS Windows but this one beats me. Jim

> 
> Hi Jim,
> 
> Troels Ring told me to get Version 0.7 which I did.
> 
> It's probably me that doesn't understand how it works (I'm new to R) but
> stablereg is supposed to find the most appropriate parameters for the stable
> distribution (loc, disp, skew, tail) given some starting values right?
> 
> When I try the examples that are given with the function help file I get the
> following results.
> 
> ************************************************************
> R : Copyright 1999, The R Development Core Team
> Version 0.90.0  (November 22, 1999)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type   "?license" or "?licence" for distribution details.
> 
> R is a collaborative project with many contributors.
> Type   "?contributors" for a list.
> 
> Type   "demo()" for some demos, "help()" for on-line help, or
>         "help.start()" for a HTML browser interface to help.
> Type    "q()" to quit R.
> 
> > library(stable)
> Loading required package: rmutil
> > help(stablereg)
> > ## Share return over a 50 day period (see reference above)
> >         # shares
> >         y <-
> c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
> +
> 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
> +
> 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)
> >
> >         # returns
> >         ret <- (y[2:50]-y[1:49])/y[1:49]
> >         # hist(ret, breaks=seq(-0.035,0.045,0.01))
> >
> >         day <- seq(0,0.48,by=0.01) # time measured in days/100
> >         x <- seq(1,length(ret))-1
> >
> >         # Classic stationary normal model tail=2
> >         print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
> +              iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1,
>     tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0,
>     otail = F, oskew = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  2
> No. of parameters            4
> Degrees of freedom           47
> AIC                          294.4987
> Iterations                   1
> 
> Location parameters
> ~1
>               estimate       se
> (Intercept)  0.0001445  0.07433
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.055
> 
> Correlations:
>          1        2
> 1  1.00000 -0.01525
> 2 -0.01525  1.00000
> >
> >         # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> >         print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
> +              iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1,
>     skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0,
>     iskew = 0, oskew = F, otail = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  3
> No. of parameters            5
> Degrees of freedom           46
> AIC                          295.4987
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate      se
> (Intercept)   1.445e-04  0.1467
> day          -6.053e-06  0.5265
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.063
> 
> Correlations:
>          1        2        3
> 1  1.00000 -0.86207 -0.06098
> 2 -0.86207  1.00000  0.06159
> 3 -0.06098  0.06159  1.00000
> >
> >         # Stable model with loc(ation)=loc.h(b0+b1*day)
> >         print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
> +              iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~
>     1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0,
>     itail = 0)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              291.591
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          296.591
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate       se
> (Intercept)   0.0004749  0.08946
> day          -0.0001862  0.43214
> 
> Dispersion parameters
> ret ~ 1
>              estimate     se
> (Intercept)   -0.9998  3.340
> 
> Skew parameters
> ~1
>                estimate   se
> (Intercept)  -0.0002456  NaN
> 
> Tail parameters
> ~1
>              estimate   se
> (Intercept)  -0.02018  NaN
> 
> Correlations:
>          1        2        3   4   5
> 1  1.00000 -1.15904 -0.06692 NaN NaN
> 2 -1.15904  1.00000  0.06058 NaN NaN
> 3 -0.06692  0.06058  1.00000 NaN NaN
> 4      NaN      NaN      NaN NaN NaN
> 5      NaN      NaN      NaN NaN NaN
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with disp(ersion)=disp.h(b0+b1*day)
> >         print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
> +              iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day,
>     skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2,
>     itail = 1)
> 
> -Log likelihood              132.1774
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          137.1774
> Iterations                   70
> 
> Location parameters
> ret ~ 1
>              estimate        se
> (Intercept)  0.000938  0.001892
> 
> Dispersion parameters
> ~day
>              estimate       se
> (Intercept)   -4.6768  0.06621
> day           -0.6556  0.61348
> 
> Skew parameters
> ~1
>              estimate   se
> (Intercept)    -10.87  NaN
> 
> Tail parameters
> ~1
>              estimate      se
> (Intercept)    0.6575  0.6067
> 
> Correlations:
>         1       2       3   4       5
> 1  1.0000 -1.0000  0.8075 NaN -0.3810
> 2 -1.0000  1.0000 -0.8075 NaN  0.3810
> 3  0.8075 -0.8075  1.0000 NaN -0.2914
> 4     NaN     NaN     NaN NaN     NaN
> 5 -0.3810  0.3810 -0.2914 NaN  1.0000
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with skew(ness)=skew.h(b0+b1*day)
> >         # Evaluation at fixed parameter values (since noopt is set to
> TRUE)
> >         print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
> +              iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
> +              itail = -5.261e-1, noopt=T))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957,
>     iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)
> 
> -Log likelihood              150.2681
> No. of obs                   49
> No. of estimated parameters  0
> No. of parameters            5
> Degrees of freedom           49
> AIC                          150.2681
> >
> >         # Stable model with tail=tail.h(b0+b1*day)
> >         print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
> +              disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
> +              idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3,
>     itail = c(2, -7), hessian = F)
> 
> -Log likelihood              129.4914
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          134.4914
> Iterations                   83
> 
> Location parameters
> ret ~ 1
>              estimate  se
> (Intercept)  0.001841  NA
> 
> Dispersion parameters
> ~1
>              estimate  se
> (Intercept)    -4.785  NA
> 
> Skew parameters
> ~1
>              estimate  se
> (Intercept)    -13.82  NA
> 
> Tail parameters
> ~day
>              estimate  se
> (Intercept)     1.926  NA
> day            -6.716  NA
> >
> >
> ****************************************************************
> 
> Are those result what they're supposed to be?
> 
> If it is so, I find it confusing that there are NA's, NaN's and/or "Warning:
> no convergence - error 5 "  in practically all results. I took a look at the
> source code and there are 2 messages that give an hint that the result are
> probably ok. It kind of looks like these example are counter example if the
> results are correct that is.
> 
> Is there some documentation for the library, I mean more then the help files
> provide?
> 
> Any help you can provide will be appreciated.
> 
> Thanks.
> 
> Yves Gauvreau
> 
> 
> 
> 
> 

-------------------------------------------------------------------------
from Linux, Jim
-------------------------------------------------------------------------
R : Copyright 1999, The R Development Core Team
Version 0.90.0  (November 22, 1999)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type	"?license" or "?licence" for distribution details.

R is a collaborative project with many contributors.
Type	"?contributors" for a list.

Type	"demo()" for some demos, "help()" for on-line help, or
    	"help.start()" for a HTML browser interface to help.
Type	"q()" to quit R.

> library(stable)
Loading required package: rmutil 
> ## Share return over a 50 day period (see reference above)
> # shares
> y <- c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
+ 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
+ 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)  
> 
> # returns
> ret <- (y[2:50]-y[1:49])/y[1:49]
> # hist(ret, breaks=seq(-0.035,0.045,0.01))
> 
> day <- seq(0,0.48,by=0.01) # time measured in days/100
> x <- seq(1,length(ret))-1
> 
> # Classic stationary normal model tail=2
> print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
+ 	iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1, 
    tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0, 
    otail = F, oskew = F)

-Log likelihood              136.0479 
No. of obs                   49 
No. of estimated parameters  2 
No. of parameters            4 
Degrees of freedom           47 
AIC                          138.0479 
Iterations                   12 

Location parameters
~1
              estimate        se
(Intercept)  0.0002892  0.001851

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.693  0.1010

Correlations:
          1         2
1 1.0000000 0.0003176
2 0.0003176 1.0000000
> 
> # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
+ 	iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1, 
    skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0, 
    iskew = 0, oskew = F, otail = F)

-Log likelihood              135.9994 
No. of obs                   49 
No. of estimated parameters  3 
No. of parameters            5 
Degrees of freedom           46 
AIC                          138.9994 
Iterations                   17 

Location parameters
~day
              estimate        se
(Intercept)   0.001266  0.003643
day          -0.004071  0.013077

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.694  0.1010

Correlations:
          1          2          3
1  1.000000 -0.8615643  0.0009260
2 -0.861564  1.0000000 -0.0009084
3  0.000926 -0.0009084  1.0000000
Warning message: 
NaNs produced in: log(x) 
> 
> # Stable model with loc(ation)=loc.h(b0+b1*day)
> print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
+ 	iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~ 
    1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0, 
    itail = 0)

Warning: no convergence - error 5 

-Log likelihood              135.921 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          140.921 
Iterations                   38 

Location parameters
~day
              estimate        se
(Intercept)   0.001297  0.003607
day          -0.004630  0.012963

Dispersion parameters
ret ~ 1
             estimate      se
(Intercept)    -4.704  0.1005

Skew parameters
~1
             estimate     se
(Intercept)     -5.07  41.76

Tail parameters
~1
             estimate   se
(Intercept)     6.408  NaN

Correlations:
          1         2         3         4   5
1  1.000000 -0.860897  0.003654  0.000318 NaN
2 -0.860897  1.000000 -0.003828 -0.002440 NaN
3  0.003654 -0.003828  1.000000 -0.005568 NaN
4  0.000318 -0.002440 -0.005568  1.000000 NaN
5       NaN       NaN       NaN       NaN NaN
Warning message: 
NaNs produced in: sqrt(diag(cov)) 
> 
> # Stable model with disp(ersion)=disp.h(b0+b1*day)
> print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
+ 	iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day, 
    skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2, 
    itail = 1)

-Log likelihood              132.1774 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          137.1774 
Iterations                   70 

Location parameters
ret ~ 1
              estimate        se
(Intercept)  0.0009383  0.002394

Dispersion parameters
~day
             estimate      se
(Intercept)   -4.6768  0.2189
day           -0.6556  0.7402

Skew parameters
~1
             estimate     se
(Intercept)    -10.91  59.32

Tail parameters
~1
             estimate      se
(Intercept)    0.6574  0.7444

Correlations:
          1         2         3         4         5
1  1.000000  0.345026  0.185935 -0.001388 -0.600483
2  0.345026  1.000000 -0.735818  0.002904 -0.458313
3  0.185935 -0.735818  1.000000 -0.006449  0.127329
4 -0.001388  0.002904 -0.006449  1.000000 -0.007393
5 -0.600483 -0.458313  0.127329 -0.007393  1.000000
> 
> # Stable model with skew(ness)=skew.h(b0+b1*day)
> # Evaluation at fixed parameter values (since noopt is set to TRUE)
> print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
+ 	iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
+ 	itail = -5.261e-1, noopt=T))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957, 
    iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)

-Log likelihood              150.2683 
No. of obs                   49 
No. of estimated parameters  0 
No. of parameters            5 
Degrees of freedom           49 
AIC                          150.2683 
> 
> # Stable model with tail=tail.h(b0+b1*day)
> print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
+ 	disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
+ 	idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3, 
    itail = c(2, -7), hessian = F)

Warning: no convergence - error 3 

-Log likelihood              129.4544 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          134.4544 
Iterations                   70 

Location parameters
ret ~ 1
             estimate  se
(Intercept)  0.001694  NA

Dispersion parameters
~1
             estimate  se
(Intercept)    -4.791  NA

Skew parameters
~1
             estimate  se
(Intercept)    -8.805  NA

Tail parameters
~day
             estimate  se
(Intercept)     2.081  NA
day            -7.091  NA
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.C.Rougier at durham.ac.uk  Wed Dec  8 11:14:33 1999
From: J.C.Rougier at durham.ac.uk (Jonathan Rougier)
Date: Wed, 8 Dec 1999 10:14:33 +0000 (GMT)
Subject: [R] Reply to list policy
In-Reply-To: <XFMail.991207190032.plummer@iarc.fr>
Message-ID: <Pine.GSO.4.20.9912081007520.25011-100000@laplace>

On Tue, 7 Dec 1999, Martyn Plummer wrote:

> Recently R-help has been too busy for me to keep up with.  There were
> quite a few identical responses in the "Finding indices with a certain
> property" thread, rather than an extended discussion.  I think this 
> illustrates the need for a reply to author policy.
> 
> Does anybody else feel the same way?

I do, at least a bit.  I expect many people operate an informal reply to
author policy anyhow.  For example, my response to the which() question
would normally have gone only to the author, but I find which() to be a
very useful function and was myself unaware of it until quite recently.  
Hence I also mailed back to r-help.  I don't think we would need to
formalise such an arrangement, but it is important to encourage posting of
summaries if r-help does not carry a comprehensive answer.

Cheers, Jonathan.

Jonathan Rougier                       Science Laboratories
Department of Mathematical Sciences    South Road
University of Durham                   Durham DH1 3LE

"[B]egin upon the precept ... that the things we see are to be 
 weighed in the scale with what we know"  (Meredith, 1879, The Egoist)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Dec  8 10:30:20 1999
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 8 Dec 1999 10:30:20 +0100 (MET)
Subject: [R] Stable package on Windows doesn't work???
In-Reply-To: <05da01bf3fff$7419c700$6328acce@bellglobal.com> from "Yves Gauvreau" at Dec 06, 1999 10:34:57 AM
Message-ID: <199912080930.KAA22900@alpha.luc.ac.be>

Yves:
  I am completely baffled by this. I include below my output for these
examples from Intel Pentium II RH5.2 Linux with R90. I get exactly the
same results with MS Windows 98 and R65 on the same machine. I also
tried with R90 and MS Windows 95 on an older Pentium and also got the
same results. What machine exactly did you run this on?
  R-help will remember that I have complained before about numerical
problems with MS Windows but this one beats me. Jim

> 
> Hi Jim,
> 
> Troels Ring told me to get Version 0.7 which I did.
> 
> It's probably me that doesn't understand how it works (I'm new to R) but
> stablereg is supposed to find the most appropriate parameters for the stable
> distribution (loc, disp, skew, tail) given some starting values right?
> 
> When I try the examples that are given with the function help file I get the
> following results.
> 
> ************************************************************
> R : Copyright 1999, The R Development Core Team
> Version 0.90.0  (November 22, 1999)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type   "?license" or "?licence" for distribution details.
> 
> R is a collaborative project with many contributors.
> Type   "?contributors" for a list.
> 
> Type   "demo()" for some demos, "help()" for on-line help, or
>         "help.start()" for a HTML browser interface to help.
> Type    "q()" to quit R.
> 
> > library(stable)
> Loading required package: rmutil
> > help(stablereg)
> > ## Share return over a 50 day period (see reference above)
> >         # shares
> >         y <-
> c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
> +
> 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
> +
> 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)
> >
> >         # returns
> >         ret <- (y[2:50]-y[1:49])/y[1:49]
> >         # hist(ret, breaks=seq(-0.035,0.045,0.01))
> >
> >         day <- seq(0,0.48,by=0.01) # time measured in days/100
> >         x <- seq(1,length(ret))-1
> >
> >         # Classic stationary normal model tail=2
> >         print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
> +              iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1,
>     tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0,
>     otail = F, oskew = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  2
> No. of parameters            4
> Degrees of freedom           47
> AIC                          294.4987
> Iterations                   1
> 
> Location parameters
> ~1
>               estimate       se
> (Intercept)  0.0001445  0.07433
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.055
> 
> Correlations:
>          1        2
> 1  1.00000 -0.01525
> 2 -0.01525  1.00000
> >
> >         # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> >         print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
> +              iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1,
>     skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0,
>     iskew = 0, oskew = F, otail = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  3
> No. of parameters            5
> Degrees of freedom           46
> AIC                          295.4987
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate      se
> (Intercept)   1.445e-04  0.1467
> day          -6.053e-06  0.5265
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.063
> 
> Correlations:
>          1        2        3
> 1  1.00000 -0.86207 -0.06098
> 2 -0.86207  1.00000  0.06159
> 3 -0.06098  0.06159  1.00000
> >
> >         # Stable model with loc(ation)=loc.h(b0+b1*day)
> >         print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
> +              iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~
>     1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0,
>     itail = 0)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              291.591
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          296.591
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate       se
> (Intercept)   0.0004749  0.08946
> day          -0.0001862  0.43214
> 
> Dispersion parameters
> ret ~ 1
>              estimate     se
> (Intercept)   -0.9998  3.340
> 
> Skew parameters
> ~1
>                estimate   se
> (Intercept)  -0.0002456  NaN
> 
> Tail parameters
> ~1
>              estimate   se
> (Intercept)  -0.02018  NaN
> 
> Correlations:
>          1        2        3   4   5
> 1  1.00000 -1.15904 -0.06692 NaN NaN
> 2 -1.15904  1.00000  0.06058 NaN NaN
> 3 -0.06692  0.06058  1.00000 NaN NaN
> 4      NaN      NaN      NaN NaN NaN
> 5      NaN      NaN      NaN NaN NaN
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with disp(ersion)=disp.h(b0+b1*day)
> >         print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
> +              iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day,
>     skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2,
>     itail = 1)
> 
> -Log likelihood              132.1774
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          137.1774
> Iterations                   70
> 
> Location parameters
> ret ~ 1
>              estimate        se
> (Intercept)  0.000938  0.001892
> 
> Dispersion parameters
> ~day
>              estimate       se
> (Intercept)   -4.6768  0.06621
> day           -0.6556  0.61348
> 
> Skew parameters
> ~1
>              estimate   se
> (Intercept)    -10.87  NaN
> 
> Tail parameters
> ~1
>              estimate      se
> (Intercept)    0.6575  0.6067
> 
> Correlations:
>         1       2       3   4       5
> 1  1.0000 -1.0000  0.8075 NaN -0.3810
> 2 -1.0000  1.0000 -0.8075 NaN  0.3810
> 3  0.8075 -0.8075  1.0000 NaN -0.2914
> 4     NaN     NaN     NaN NaN     NaN
> 5 -0.3810  0.3810 -0.2914 NaN  1.0000
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with skew(ness)=skew.h(b0+b1*day)
> >         # Evaluation at fixed parameter values (since noopt is set to
> TRUE)
> >         print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
> +              iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
> +              itail = -5.261e-1, noopt=T))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957,
>     iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)
> 
> -Log likelihood              150.2681
> No. of obs                   49
> No. of estimated parameters  0
> No. of parameters            5
> Degrees of freedom           49
> AIC                          150.2681
> >
> >         # Stable model with tail=tail.h(b0+b1*day)
> >         print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
> +              disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
> +              idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3,
>     itail = c(2, -7), hessian = F)
> 
> -Log likelihood              129.4914
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          134.4914
> Iterations                   83
> 
> Location parameters
> ret ~ 1
>              estimate  se
> (Intercept)  0.001841  NA
> 
> Dispersion parameters
> ~1
>              estimate  se
> (Intercept)    -4.785  NA
> 
> Skew parameters
> ~1
>              estimate  se
> (Intercept)    -13.82  NA
> 
> Tail parameters
> ~day
>              estimate  se
> (Intercept)     1.926  NA
> day            -6.716  NA
> >
> >
> ****************************************************************
> 
> Are those result what they're supposed to be?
> 
> If it is so, I find it confusing that there are NA's, NaN's and/or "Warning:
> no convergence - error 5 "  in practically all results. I took a look at the
> source code and there are 2 messages that give an hint that the result are
> probably ok. It kind of looks like these example are counter example if the
> results are correct that is.
> 
> Is there some documentation for the library, I mean more then the help files
> provide?
> 
> Any help you can provide will be appreciated.
> 
> Thanks.
> 
> Yves Gauvreau
> 
> 
> 
> 
> 

-------------------------------------------------------------------------
from Linux, Jim
-------------------------------------------------------------------------
R : Copyright 1999, The R Development Core Team
Version 0.90.0  (November 22, 1999)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type	"?license" or "?licence" for distribution details.

R is a collaborative project with many contributors.
Type	"?contributors" for a list.

Type	"demo()" for some demos, "help()" for on-line help, or
    	"help.start()" for a HTML browser interface to help.
Type	"q()" to quit R.

> library(stable)
Loading required package: rmutil 
> ## Share return over a 50 day period (see reference above)
> # shares
> y <- c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
+ 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
+ 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)  
> 
> # returns
> ret <- (y[2:50]-y[1:49])/y[1:49]
> # hist(ret, breaks=seq(-0.035,0.045,0.01))
> 
> day <- seq(0,0.48,by=0.01) # time measured in days/100
> x <- seq(1,length(ret))-1
> 
> # Classic stationary normal model tail=2
> print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
+ 	iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1, 
    tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0, 
    otail = F, oskew = F)

-Log likelihood              136.0479 
No. of obs                   49 
No. of estimated parameters  2 
No. of parameters            4 
Degrees of freedom           47 
AIC                          138.0479 
Iterations                   12 

Location parameters
~1
              estimate        se
(Intercept)  0.0002892  0.001851

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.693  0.1010

Correlations:
          1         2
1 1.0000000 0.0003176
2 0.0003176 1.0000000
> 
> # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
+ 	iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1, 
    skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0, 
    iskew = 0, oskew = F, otail = F)

-Log likelihood              135.9994 
No. of obs                   49 
No. of estimated parameters  3 
No. of parameters            5 
Degrees of freedom           46 
AIC                          138.9994 
Iterations                   17 

Location parameters
~day
              estimate        se
(Intercept)   0.001266  0.003643
day          -0.004071  0.013077

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.694  0.1010

Correlations:
          1          2          3
1  1.000000 -0.8615643  0.0009260
2 -0.861564  1.0000000 -0.0009084
3  0.000926 -0.0009084  1.0000000
Warning message: 
NaNs produced in: log(x) 
> 
> # Stable model with loc(ation)=loc.h(b0+b1*day)
> print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
+ 	iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~ 
    1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0, 
    itail = 0)

Warning: no convergence - error 5 

-Log likelihood              135.921 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          140.921 
Iterations                   38 

Location parameters
~day
              estimate        se
(Intercept)   0.001297  0.003607
day          -0.004630  0.012963

Dispersion parameters
ret ~ 1
             estimate      se
(Intercept)    -4.704  0.1005

Skew parameters
~1
             estimate     se
(Intercept)     -5.07  41.76

Tail parameters
~1
             estimate   se
(Intercept)     6.408  NaN

Correlations:
          1         2         3         4   5
1  1.000000 -0.860897  0.003654  0.000318 NaN
2 -0.860897  1.000000 -0.003828 -0.002440 NaN
3  0.003654 -0.003828  1.000000 -0.005568 NaN
4  0.000318 -0.002440 -0.005568  1.000000 NaN
5       NaN       NaN       NaN       NaN NaN
Warning message: 
NaNs produced in: sqrt(diag(cov)) 
> 
> # Stable model with disp(ersion)=disp.h(b0+b1*day)
> print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
+ 	iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day, 
    skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2, 
    itail = 1)

-Log likelihood              132.1774 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          137.1774 
Iterations                   70 

Location parameters
ret ~ 1
              estimate        se
(Intercept)  0.0009383  0.002394

Dispersion parameters
~day
             estimate      se
(Intercept)   -4.6768  0.2189
day           -0.6556  0.7402

Skew parameters
~1
             estimate     se
(Intercept)    -10.91  59.32

Tail parameters
~1
             estimate      se
(Intercept)    0.6574  0.7444

Correlations:
          1         2         3         4         5
1  1.000000  0.345026  0.185935 -0.001388 -0.600483
2  0.345026  1.000000 -0.735818  0.002904 -0.458313
3  0.185935 -0.735818  1.000000 -0.006449  0.127329
4 -0.001388  0.002904 -0.006449  1.000000 -0.007393
5 -0.600483 -0.458313  0.127329 -0.007393  1.000000
> 
> # Stable model with skew(ness)=skew.h(b0+b1*day)
> # Evaluation at fixed parameter values (since noopt is set to TRUE)
> print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
+ 	iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
+ 	itail = -5.261e-1, noopt=T))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957, 
    iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)

-Log likelihood              150.2683 
No. of obs                   49 
No. of estimated parameters  0 
No. of parameters            5 
Degrees of freedom           49 
AIC                          150.2683 
> 
> # Stable model with tail=tail.h(b0+b1*day)
> print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
+ 	disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
+ 	idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3, 
    itail = c(2, -7), hessian = F)

Warning: no convergence - error 3 

-Log likelihood              129.4544 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          134.4544 
Iterations                   70 

Location parameters
ret ~ 1
             estimate  se
(Intercept)  0.001694  NA

Dispersion parameters
~1
             estimate  se
(Intercept)    -4.791  NA

Skew parameters
~1
             estimate  se
(Intercept)    -8.805  NA

Tail parameters
~day
             estimate  se
(Intercept)     2.081  NA
day            -7.091  NA
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.C.Rougier at durham.ac.uk  Wed Dec  8 11:14:33 1999
From: J.C.Rougier at durham.ac.uk (Jonathan Rougier)
Date: Wed, 8 Dec 1999 10:14:33 +0000 (GMT)
Subject: [R] Reply to list policy
In-Reply-To: <XFMail.991207190032.plummer@iarc.fr>
Message-ID: <Pine.GSO.4.20.9912081007520.25011-100000@laplace>

On Tue, 7 Dec 1999, Martyn Plummer wrote:

> Recently R-help has been too busy for me to keep up with.  There were
> quite a few identical responses in the "Finding indices with a certain
> property" thread, rather than an extended discussion.  I think this 
> illustrates the need for a reply to author policy.
> 
> Does anybody else feel the same way?

I do, at least a bit.  I expect many people operate an informal reply to
author policy anyhow.  For example, my response to the which() question
would normally have gone only to the author, but I find which() to be a
very useful function and was myself unaware of it until quite recently.  
Hence I also mailed back to r-help.  I don't think we would need to
formalise such an arrangement, but it is important to encourage posting of
summaries if r-help does not carry a comprehensive answer.

Cheers, Jonathan.

Jonathan Rougier                       Science Laboratories
Department of Mathematical Sciences    South Road
University of Durham                   Durham DH1 3LE

"[B]egin upon the precept ... that the things we see are to be 
 weighed in the scale with what we know"  (Meredith, 1879, The Egoist)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jlindsey at alpha.luc.ac.be  Wed Dec  8 10:30:20 1999
From: jlindsey at alpha.luc.ac.be (Jim Lindsey)
Date: Wed, 8 Dec 1999 10:30:20 +0100 (MET)
Subject: [R] Stable package on Windows doesn't work???
In-Reply-To: <05da01bf3fff$7419c700$6328acce@bellglobal.com> from "Yves Gauvreau" at Dec 06, 1999 10:34:57 AM
Message-ID: <199912080930.KAA22900@alpha.luc.ac.be>

Yves:
  I am completely baffled by this. I include below my output for these
examples from Intel Pentium II RH5.2 Linux with R90. I get exactly the
same results with MS Windows 98 and R65 on the same machine. I also
tried with R90 and MS Windows 95 on an older Pentium and also got the
same results. What machine exactly did you run this on?
  R-help will remember that I have complained before about numerical
problems with MS Windows but this one beats me. Jim

> 
> Hi Jim,
> 
> Troels Ring told me to get Version 0.7 which I did.
> 
> It's probably me that doesn't understand how it works (I'm new to R) but
> stablereg is supposed to find the most appropriate parameters for the stable
> distribution (loc, disp, skew, tail) given some starting values right?
> 
> When I try the examples that are given with the function help file I get the
> following results.
> 
> ************************************************************
> R : Copyright 1999, The R Development Core Team
> Version 0.90.0  (November 22, 1999)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type   "?license" or "?licence" for distribution details.
> 
> R is a collaborative project with many contributors.
> Type   "?contributors" for a list.
> 
> Type   "demo()" for some demos, "help()" for on-line help, or
>         "help.start()" for a HTML browser interface to help.
> Type    "q()" to quit R.
> 
> > library(stable)
> Loading required package: rmutil
> > help(stablereg)
> > ## Share return over a 50 day period (see reference above)
> >         # shares
> >         y <-
> c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
> +
> 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
> +
> 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)
> >
> >         # returns
> >         ret <- (y[2:50]-y[1:49])/y[1:49]
> >         # hist(ret, breaks=seq(-0.035,0.045,0.01))
> >
> >         day <- seq(0,0.48,by=0.01) # time measured in days/100
> >         x <- seq(1,length(ret))-1
> >
> >         # Classic stationary normal model tail=2
> >         print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
> +              iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1,
>     tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0,
>     otail = F, oskew = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  2
> No. of parameters            4
> Degrees of freedom           47
> AIC                          294.4987
> Iterations                   1
> 
> Location parameters
> ~1
>               estimate       se
> (Intercept)  0.0001445  0.07433
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.055
> 
> Correlations:
>          1        2
> 1  1.00000 -0.01525
> 2 -0.01525  1.00000
> >
> >         # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> >         print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
> +              iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1,
>     skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0,
>     iskew = 0, oskew = F, otail = F)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              292.4987
> No. of obs                   49
> No. of estimated parameters  3
> No. of parameters            5
> Degrees of freedom           46
> AIC                          295.4987
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate      se
> (Intercept)   1.445e-04  0.1467
> day          -6.053e-06  0.5265
> 
> Dispersion parameters
> ~1
>              estimate     se
> (Intercept)        -1  4.063
> 
> Correlations:
>          1        2        3
> 1  1.00000 -0.86207 -0.06098
> 2 -0.86207  1.00000  0.06159
> 3 -0.06098  0.06159  1.00000
> >
> >         # Stable model with loc(ation)=loc.h(b0+b1*day)
> >         print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
> +              iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~
>     1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0,
>     itail = 0)
> 
> Warning: no convergence - error 5
> 
> -Log likelihood              291.591
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          296.591
> Iterations                   1
> 
> Location parameters
> ~day
>                estimate       se
> (Intercept)   0.0004749  0.08946
> day          -0.0001862  0.43214
> 
> Dispersion parameters
> ret ~ 1
>              estimate     se
> (Intercept)   -0.9998  3.340
> 
> Skew parameters
> ~1
>                estimate   se
> (Intercept)  -0.0002456  NaN
> 
> Tail parameters
> ~1
>              estimate   se
> (Intercept)  -0.02018  NaN
> 
> Correlations:
>          1        2        3   4   5
> 1  1.00000 -1.15904 -0.06692 NaN NaN
> 2 -1.15904  1.00000  0.06058 NaN NaN
> 3 -0.06692  0.06058  1.00000 NaN NaN
> 4      NaN      NaN      NaN NaN NaN
> 5      NaN      NaN      NaN NaN NaN
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with disp(ersion)=disp.h(b0+b1*day)
> >         print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
> +              iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day,
>     skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2,
>     itail = 1)
> 
> -Log likelihood              132.1774
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          137.1774
> Iterations                   70
> 
> Location parameters
> ret ~ 1
>              estimate        se
> (Intercept)  0.000938  0.001892
> 
> Dispersion parameters
> ~day
>              estimate       se
> (Intercept)   -4.6768  0.06621
> day           -0.6556  0.61348
> 
> Skew parameters
> ~1
>              estimate   se
> (Intercept)    -10.87  NaN
> 
> Tail parameters
> ~1
>              estimate      se
> (Intercept)    0.6575  0.6067
> 
> Correlations:
>         1       2       3   4       5
> 1  1.0000 -1.0000  0.8075 NaN -0.3810
> 2 -1.0000  1.0000 -0.8075 NaN  0.3810
> 3  0.8075 -0.8075  1.0000 NaN -0.2914
> 4     NaN     NaN     NaN NaN     NaN
> 5 -0.3810  0.3810 -0.2914 NaN  1.0000
> Warning message:
> NaNs produced in: sqrt(diag(cov))
> >
> >         # Stable model with skew(ness)=skew.h(b0+b1*day)
> >         # Evaluation at fixed parameter values (since noopt is set to
> TRUE)
> >         print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
> +              loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
> +              iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
> +              itail = -5.261e-1, noopt=T))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957,
>     iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)
> 
> -Log likelihood              150.2681
> No. of obs                   49
> No. of estimated parameters  0
> No. of parameters            5
> Degrees of freedom           49
> AIC                          150.2681
> >
> >         # Stable model with tail=tail.h(b0+b1*day)
> >         print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
> +              disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
> +              idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))
> 
> Call:
> stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1,
>     skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3,
>     itail = c(2, -7), hessian = F)
> 
> -Log likelihood              129.4914
> No. of obs                   49
> No. of estimated parameters  5
> No. of parameters            5
> Degrees of freedom           44
> AIC                          134.4914
> Iterations                   83
> 
> Location parameters
> ret ~ 1
>              estimate  se
> (Intercept)  0.001841  NA
> 
> Dispersion parameters
> ~1
>              estimate  se
> (Intercept)    -4.785  NA
> 
> Skew parameters
> ~1
>              estimate  se
> (Intercept)    -13.82  NA
> 
> Tail parameters
> ~day
>              estimate  se
> (Intercept)     1.926  NA
> day            -6.716  NA
> >
> >
> ****************************************************************
> 
> Are those result what they're supposed to be?
> 
> If it is so, I find it confusing that there are NA's, NaN's and/or "Warning:
> no convergence - error 5 "  in practically all results. I took a look at the
> source code and there are 2 messages that give an hint that the result are
> probably ok. It kind of looks like these example are counter example if the
> results are correct that is.
> 
> Is there some documentation for the library, I mean more then the help files
> provide?
> 
> Any help you can provide will be appreciated.
> 
> Thanks.
> 
> Yves Gauvreau
> 
> 
> 
> 
> 

-------------------------------------------------------------------------
from Linux, Jim
-------------------------------------------------------------------------
R : Copyright 1999, The R Development Core Team
Version 0.90.0  (November 22, 1999)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type	"?license" or "?licence" for distribution details.

R is a collaborative project with many contributors.
Type	"?contributors" for a list.

Type	"demo()" for some demos, "help()" for on-line help, or
    	"help.start()" for a HTML browser interface to help.
Type	"q()" to quit R.

> library(stable)
Loading required package: rmutil 
> ## Share return over a 50 day period (see reference above)
> # shares
> y <- c(296,296,300,302,300,304,303,299,293,294,294,293,295,287,288,297,
+ 305,307,307,304,303,304,304,309,309,309,307,306,304,300,296,301,298,
+ 295,295,293,292,297,294,293,306,303,301,303,308,305,302,301,297,299)  
> 
> # returns
> ret <- (y[2:50]-y[1:49])/y[1:49]
> # hist(ret, breaks=seq(-0.035,0.045,0.01))
> 
> day <- seq(0,0.48,by=0.01) # time measured in days/100
> x <- seq(1,length(ret))-1
> 
> # Classic stationary normal model tail=2
> print(z1 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ 1, disp= ~ 1, skew = ~ 1, tail = tail.g(1.9999999),
+ 	iloc = 0, idisp = 0, iskew = 0, otail = F, oskew = F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~1, disp = ~1, skew = ~1, 
    tail = tail.g(1.9999999), iloc = 0, idisp = 0, iskew = 0, 
    otail = F, oskew = F)

-Log likelihood              136.0479 
No. of obs                   49 
No. of estimated parameters  2 
No. of parameters            4 
Degrees of freedom           47 
AIC                          138.0479 
Iterations                   12 

Location parameters
~1
              estimate        se
(Intercept)  0.0002892  0.001851

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.693  0.1010

Correlations:
          1         2
1 1.0000000 0.0003176
2 0.0003176 1.0000000
> 
> # Normal model (tail=2) with dispersion=disp.h(b0+b1*day)
> print(z2 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ~ 1, skew = ~ 1, tail = tail.g(1.999999),
+ 	iloc = c(0,0), idisp = 0, iskew = 0, oskew = F, otail =F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ~1, 
    skew = ~1, tail = tail.g(1.999999), iloc = c(0, 0), idisp = 0, 
    iskew = 0, oskew = F, otail = F)

-Log likelihood              135.9994 
No. of obs                   49 
No. of estimated parameters  3 
No. of parameters            5 
Degrees of freedom           46 
AIC                          138.9994 
Iterations                   17 

Location parameters
~day
              estimate        se
(Intercept)   0.001266  0.003643
day          -0.004071  0.013077

Dispersion parameters
~1
             estimate      se
(Intercept)    -4.694  0.1010

Correlations:
          1          2          3
1  1.000000 -0.8615643  0.0009260
2 -0.861564  1.0000000 -0.0009084
3  0.000926 -0.0009084  1.0000000
Warning message: 
NaNs produced in: log(x) 
> 
> # Stable model with loc(ation)=loc.h(b0+b1*day)
> print(z3 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ~ day, disp = ret ~ 1, skew = ~ 1, tail = ~ 1,
+ 	iloc = c(0.001,0), idisp = 0, iskew = 0, itail = 0))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ~day, disp = ret ~ 
    1, skew = ~1, tail = ~1, iloc = c(0.001, 0), idisp = 0, iskew = 0, 
    itail = 0)

Warning: no convergence - error 5 

-Log likelihood              135.921 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          140.921 
Iterations                   38 

Location parameters
~day
              estimate        se
(Intercept)   0.001297  0.003607
day          -0.004630  0.012963

Dispersion parameters
ret ~ 1
             estimate      se
(Intercept)    -4.704  0.1005

Skew parameters
~1
             estimate     se
(Intercept)     -5.07  41.76

Tail parameters
~1
             estimate   se
(Intercept)     6.408  NaN

Correlations:
          1         2         3         4   5
1  1.000000 -0.860897  0.003654  0.000318 NaN
2 -0.860897  1.000000 -0.003828 -0.002440 NaN
3  0.003654 -0.003828  1.000000 -0.005568 NaN
4  0.000318 -0.002440 -0.005568  1.000000 NaN
5       NaN       NaN       NaN       NaN NaN
Warning message: 
NaNs produced in: sqrt(diag(cov)) 
> 
> # Stable model with disp(ersion)=disp.h(b0+b1*day)
> print(z4 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ day, skew = ~ 1, tail = ~ 1,
+ 	iloc = 0, idisp = c(-4.5,0), iskew = -2, itail = 1))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~day, 
    skew = ~1, tail = ~1, iloc = 0, idisp = c(-4.5, 0), iskew = -2, 
    itail = 1)

-Log likelihood              132.1774 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          137.1774 
Iterations                   70 

Location parameters
ret ~ 1
              estimate        se
(Intercept)  0.0009383  0.002394

Dispersion parameters
~day
             estimate      se
(Intercept)   -4.6768  0.2189
day           -0.6556  0.7402

Skew parameters
~1
             estimate     se
(Intercept)    -10.91  59.32

Tail parameters
~1
             estimate      se
(Intercept)    0.6574  0.7444

Correlations:
          1         2         3         4         5
1  1.000000  0.345026  0.185935 -0.001388 -0.600483
2  0.345026  1.000000 -0.735818  0.002904 -0.458313
3  0.185935 -0.735818  1.000000 -0.006449  0.127329
4 -0.001388  0.002904 -0.006449  1.000000 -0.007393
5 -0.600483 -0.458313  0.127329 -0.007393  1.000000
> 
> # Stable model with skew(ness)=skew.h(b0+b1*day)
> # Evaluation at fixed parameter values (since noopt is set to TRUE)
> print(z5 <- stablereg(y = ret, delta = 1/y[1:49],
+ 	loc = ret ~ 1, disp = ~ 1, skew = ~ day, tail = ~ 1,
+ 	iloc = 5.557e-04, idisp = -4.957, iskew = c(2.811,-2.158),
+ 	itail = -5.261e-1, noopt=T))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~day, tail = ~1, iloc = 0.0005557, idisp = -4.957, 
    iskew = c(2.811, -2.158), itail = -0.5261, noopt = T)

-Log likelihood              150.2683 
No. of obs                   49 
No. of estimated parameters  0 
No. of parameters            5 
Degrees of freedom           49 
AIC                          150.2683 
> 
> # Stable model with tail=tail.h(b0+b1*day)
> print(z6 <- stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1,
+ 	disp = ~ 1, skew = ~ 1, tail = ~ day, iloc = 0.001,
+ 	idisp = -5, iskew = -3, itail = c(2,-7), hessian=F))

Call:
stablereg(y = ret, delta = 1/y[1:49], loc = ret ~ 1, disp = ~1, 
    skew = ~1, tail = ~day, iloc = 0.001, idisp = -5, iskew = -3, 
    itail = c(2, -7), hessian = F)

Warning: no convergence - error 3 

-Log likelihood              129.4544 
No. of obs                   49 
No. of estimated parameters  5 
No. of parameters            5 
Degrees of freedom           44 
AIC                          134.4544 
Iterations                   70 

Location parameters
ret ~ 1
             estimate  se
(Intercept)  0.001694  NA

Dispersion parameters
~1
             estimate  se
(Intercept)    -4.791  NA

Skew parameters
~1
             estimate  se
(Intercept)    -8.805  NA

Tail parameters
~day
             estimate  se
(Intercept)     2.081  NA
day            -7.091  NA
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rosm at ufrima.imag.fr  Wed Dec  8 12:29:20 1999
From: rosm at ufrima.imag.fr (ros mathieu)
Date: Wed, 08 Dec 1999 12:29:20 +0100
Subject: [R] eps->jpg
Message-ID: <384E410F.6A2AF5AB@ufrima.imag.fr>

hello all,
is there a way to convert R graphics (eps format) to jpg  from a R
function ?
thanks for your help,
    Mathieu

--
----------------------------------------------------------------------
Mathieu Ros - 13 rue b?vi?re - 38000 GRENOBLE - 04 76 491 370
http://www.multimania.com/mathieuros/index2.html
DESS ing?nierie math?matique (biostatistiques)
Universite Joseph Fourier, Grenoble
----------------------------------------------------------------------
Si il n'y a pas de solution, c'est qu'il n'y a pas de probl?me.(devise Shadock)


-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/19991208/08063d97/attachment.html

From ripley at stats.ox.ac.uk  Wed Dec  8 13:10:09 1999
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Dec 1999 12:10:09 +0000 (GMT)
Subject: [R] eps->jpg
Message-ID: <199912081210.MAA13149@toucan.stats.ox.ac.uk>

> Date: Wed, 08 Dec 1999 12:29:20 +0100
> From: ros mathieu <rosm at ufrima.imag.fr>
> 
> is there a way to convert R graphics (eps format) to jpg  from a R
> function ?

If you use dev2bitmap() you can do this (generate eps, convert to bitmap)
within R. Otherwise use a tool such as convert (part of ImageMagick) or
xv, both of which use ghostscript internally, or on Windows use GSView
(again using ghostscript).

I hope that addresses what you want. If not the dev2bitmap function
should provide a good template. If you are producing eps for this,
you do need to set the options on postscript() to get it (as you probably
know, and dev2bitmap shows).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec  8 13:15:14 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Dec 1999 13:15:14 +0100
Subject: [R] Stable package on Windows doesn't work???
In-Reply-To: Jim Lindsey's message of "Wed, 8 Dec 1999 10:30:20 +0100 (MET)"
References: <199912080930.KAA22900@alpha.luc.ac.be>
Message-ID: <x23dtd633h.fsf@blueberry.kubism.ku.dk>

Jim Lindsey <jlindsey at alpha.luc.ac.be> writes:

> Yves:
>   I am completely baffled by this. I include below my output for these
> examples from Intel Pentium II RH5.2 Linux with R90. I get exactly the
> same results with MS Windows 98 and R65 on the same machine. I also
> tried with R90 and MS Windows 95 on an older Pentium and also got the
> same results. What machine exactly did you run this on?
>   R-help will remember that I have complained before about numerical
> problems with MS Windows but this one beats me. Jim
> 

Jim, 

I get exactly the same results as Yves on RedHat6.1 (K6-3, gcc
2.91-66, GNU Fortran 0.5.24-19981002). Installed completely fresh from
your website this morning. Are you sure you compare with the same
versions (of stable and rmutil)?

	-p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec  8 13:15:14 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Dec 1999 13:15:14 +0100
Subject: [R] Stable package on Windows doesn't work???
In-Reply-To: Jim Lindsey's message of "Wed, 8 Dec 1999 10:30:20 +0100 (MET)"
References: <199912080930.KAA22900@alpha.luc.ac.be>
Message-ID: <x23dtd633h.fsf@blueberry.kubism.ku.dk>

Jim Lindsey <jlindsey at alpha.luc.ac.be> writes:

> Yves:
>   I am completely baffled by this. I include below my output for these
> examples from Intel Pentium II RH5.2 Linux with R90. I get exactly the
> same results with MS Windows 98 and R65 on the same machine. I also
> tried with R90 and MS Windows 95 on an older Pentium and also got the
> same results. What machine exactly did you run this on?
>   R-help will remember that I have complained before about numerical
> problems with MS Windows but this one beats me. Jim
> 

Jim, 

I get exactly the same results as Yves on RedHat6.1 (K6-3, gcc
2.91-66, GNU Fortran 0.5.24-19981002). Installed completely fresh from
your website this morning. Are you sure you compare with the same
versions (of stable and rmutil)?

	-p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Dec  8 14:33:25 1999
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 8 Dec 1999 14:33:25 +0100 (MET)
Subject: [R] excuse the repeated mailings..
Message-ID: <14414.24101.787156.91618@gargle.gargle.HOWL>

Our sys.admin fixed one important (NIS) problem and
accidentally simultaneously badly broke part of sendmail's functioning.
Unfortunately, this lasted ~ 40 minutes, and somehow sendmail
just "thought" it had to resend these messages several times (up to 8 x) 
that came in during that 40 minutes' period.

Accept our (math.ethz.ch)'s apologies...

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO D10	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Zdenek.Skala at incoma.cz  Wed Dec  8 16:27:16 1999
From: Zdenek.Skala at incoma.cz (Zdenek Skala)
Date: Wed, 8 Dec 1999 16:27:16 +0100
Subject: [R] barplot
Message-ID: <199912081525.QAA08957@benes.incoma.cz>

Dear all,
do anybody know how to set ylim in barplot() correctly? When I 
write:
> barplot(c(.1,.5,1.0))
the y-axis goes from 0.0 to 0.8. Wheny I type:
> barplot(c(.1,.5,1.0,),ylim=range(0:1))
the y-axis goes from 0.0 to 0.8.
Obviously I am doing something wrong. Are the ylim setting 
standards in barplot() other than in plot() or is this a bug?
Thanks for any hints!
Zdenek

++++++++++++++++++++++
] Zdenek Skala
] e-mail:
] Zdenek.Skala at incoma.cz

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec  8 16:59:00 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Dec 1999 16:59:00 +0100
Subject: [R] barplot
In-Reply-To: "Zdenek Skala"'s message of "Wed, 8 Dec 1999 16:27:16 +0100"
References: <199912081525.QAA08957@benes.incoma.cz>
Message-ID: <x2ogc14e63.fsf@blueberry.kubism.ku.dk>

"Zdenek Skala" <Zdenek.Skala at incoma.cz> writes:

> Dear all,
> do anybody know how to set ylim in barplot() correctly? When I 
> write:
> > barplot(c(.1,.5,1.0))
> the y-axis goes from 0.0 to 0.8. Wheny I type:
> > barplot(c(.1,.5,1.0,),ylim=range(0:1))
> the y-axis goes from 0.0 to 0.8.

0.2 to 0.8, no?

> Obviously I am doing something wrong. Are the ylim setting 
> standards in barplot() other than in plot() or is this a bug?
> Thanks for any hints!
> Zdenek

Yes, and yes. The axis settings use yaxs='i' (or xaxs if horizontal)
which sets the plot boundaries equal to the ylim (stated or computed)
and marks the axes "internally". The endpoints of the axes are not
considered to be internal (this is the bug, they are in Splus).

Quick workaround is: 

barplot(c(.1,.5,1.0),ylim=range(-.01,1.01))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Zdenek.Skala at incoma.cz  Thu Dec  9 08:41:04 1999
From: Zdenek.Skala at incoma.cz (Zdenek Skala)
Date: Thu, 9 Dec 1999 08:41:04 +0100
Subject: [R] Re: Re: barplot
Message-ID: <199912090739.IAA14254@benes.incoma.cz>

Sorry for incomplete posting:
I am using R 0.90.0 for Win95/NT
Hence, the correct workaround is:
> barplot(c(.1,.5,1.0),ylim=c(-0.01,1.01))
as proposed by Prof. Ripley instead of:
> barplot(c(.1,.5,1.0),ylim=range(-0.01:1.01))
which works for lower versions (I suppose).
I have caused all the unclearness by non-citing the R version, so 
sorry again and thanks for the solution!
Zdenek
++++++++++++++++++++++
] Zdenek Skala
] e-mail:
] Zdenek.Skala at incoma.cz

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Adrian.Trapletti at wu-wien.ac.at  Thu Dec  9 10:18:14 1999
From: Adrian.Trapletti at wu-wien.ac.at (Adrian Trapletti)
Date: Thu, 09 Dec 1999 09:18:14 +0000
Subject: [R] tsboot
Message-ID: <384F73D5.6AB242FD@wu-wien.ac.at>

Fritz,

I have slightly adapted (didn't work before) "tsboot" from the "boot"
library to the current time series conventions of R. The following patch
will do that. I suggest to apply this patch to the file
"boot/R/bootfuns.q" of the "boot" library at CRAN.

best
Adrian

--- bootfuns.orig.q Thu Dec  9 10:07:23 1999
+++ bootfuns.q Thu Dec  9 10:06:51 1999
@@ -3267,8 +3267,8 @@
 #  post-blackened), model-based resampling and phase scrambling.
 #
  tscl <- class(tseries)
- if (!is.null(tscl) && (any(tscl == "its")))
-  stop("Irregular time series cannot be bootstrapped")
+# if (!is.null(tscl) && (any(tscl == "its")))
+#  stop("Irregular time series cannot be bootstrapped")
  if (R<=0) stop("R must be positive")
  R <- floor(R)
  call <- match.call()
@@ -3283,29 +3283,32 @@
   ts.orig <- as.matrix(tseries)
  else  ts.orig <- tseries
         n <- nrow(ts.orig)
- class(ts.orig) <- tscl[(tscl!="cts")&(tscl != "rts")]
+# class(ts.orig) <- tscl[(tscl!="cts")&(tscl != "rts")]
+        class(ts.orig) <- tscl  # change, A.Trapletti
  if ((sim=="model") || (sim=="scramble"))
   l <- NULL
  else if ((is.null(l) || (l <= 0) || (l > n)))
   stop("Invalid value of l")
  st <- start(tseries)
  freq <- frequency(tseries)
- un <- units(tseries)
- k.un <- attr(tseries, "tspar")$k.units
+# un <- units(tseries)
+# k.un <- attr(tseries, "tspar")$k.units
  tsnames <- names(tseries)
  if (sim == "geom") endcorr <- T
  if (sim == "scramble") {
 # Phase scrambling
   for (r in 1:R) {
    ts.b <- scramble(tseries,norm)
-   t <- rbind(t, statistic(ts.b, ...))
+                        tmp <- statistic(ts.b, ...) # change,
A.Trapletti
+   t <- rbind(t, tmp) # change, A.Trapletti
   }
  }
  else if (sim == "model") {
 # Model-based resampling
   for (r in 1:R) {
    ts.b <- ran.gen(tseries, n.sim, ran.args)
-   t <- rbind(t, statistic(ts.b, ...))
+                        tmp <- statistic(ts.b, ...) # change,
A.Trapletti
+   t <- rbind(t, tmp) # change, A.Trapletti
   }
  }
  else if ((sim=="fixed") || (sim=="geom")) {
@@ -3327,18 +3330,22 @@
    if (is.null(tscl))
     ts.b <- ts(ts.orig[inds,], start=st,
       frequency=freq,names=tsnames)
-   else if (any(tscl == "cts"))
-    ts.b <- cts(ts.orig[inds,], start=st,
-      units=un, k.units=k.un,
-      frequency=freq,names=tsnames)
-   else if (is.null(un))
-    ts.b <- rts(ts.orig[inds,], start=st,
+#   else if (any(tscl == "cts"))
+#    ts.b <- cts(ts.orig[inds,], start=st,
+#      units=un, k.units=k.un,
+#      frequency=freq,names=tsnames)
+#   else if (is.null(un))
+#                                ts.b <- rts(ts.orig[inds,], start=st,
+#      frequency=freq,names=tsnames)
+                        else  # change, A.Trapletti
+    ts.b <- ts(ts.orig[inds,], start=st,
       frequency=freq,names=tsnames)
-   else ts.b <- rts(ts.orig[inds,], start=st,
-      units=un, frequency=freq,
-      names=tsnames)
+#   else ts.b <- rts(ts.orig[inds,], start=st,
+#      units=un, frequency=freq,
+#      names=tsnames)
    ts.b <- ran.gen(ts.b, n.sim, ran.args)
-                        t <- rbind(t, statistic(ts.b, ...))
+                        tmp <- statistic(ts.b, ...)  # change,
A.Trapletti
+                        t <- rbind(t, tmp)  # change, A.Trapletti
                 }
         }
  else stop("Unrecognized value of sim")



--
Adrian Trapletti, Vienna University of Economics and Business
Administration, Augasse 2-6, A-1090 Vienna, Austria
Phone: ++43 1 31336 4561, Fax: ++43 1 31336 708,
Email: adrian.trapletti at wu-wien.ac.at



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec  9 10:26:50 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 9 Dec 1999 09:26:50 +0000 (GMT)
Subject: [R] Re: tsboot
In-Reply-To: <384F73D5.6AB242FD@wu-wien.ac.at>
Message-ID: <Pine.GSO.4.05.9912090921180.12205-100000@auk.stats>

Adrian,

Thank you for the patches.

You need to send such things to the package maintainer, as mentioned in the
DESCRIPTION, in this case me. I knew tsboot would not work: it is by no
means the only thing in boot that does not work (yet): see PORTING.
I have delayed a serious attempt on those until the optimizer problems
are sorted out.

Brian

On Thu, 9 Dec 1999, Adrian Trapletti wrote:

> Fritz,
> 
> I have slightly adapted (didn't work before) "tsboot" from the "boot"
> library to the current time series conventions of R. The following patch
> will do that. I suggest to apply this patch to the file
> "boot/R/bootfuns.q" of the "boot" library at CRAN.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec  9 10:49:33 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Dec 1999 10:49:33 +0100
Subject: [R] Re: Re: barplot
In-Reply-To: "Zdenek Skala"'s message of "Thu, 9 Dec 1999 08:41:04 +0100"
References: <199912090739.IAA14254@benes.incoma.cz>
Message-ID: <x2so1c30lu.fsf@blueberry.kubism.ku.dk>

"Zdenek Skala" <Zdenek.Skala at incoma.cz> writes:

> Sorry for incomplete posting:
> I am using R 0.90.0 for Win95/NT
> Hence, the correct workaround is:
> > barplot(c(.1,.5,1.0),ylim=c(-0.01,1.01))
> as proposed by Prof. Ripley instead of:
> > barplot(c(.1,.5,1.0),ylim=range(-0.01:1.01))
> which works for lower versions (I suppose).
> I have caused all the unclearness by non-citing the R version, so 
> sorry again and thanks for the solution!

Actually, it's a problem in any version of R since way back:

> range(-0.01:1.01)
[1] -0.01  0.99

(a:b gives sequences in steps of 1, starting from a and stopping
before b is exceeded).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Zdenek.Skala at incoma.cz  Thu Dec  9 12:06:44 1999
From: Zdenek.Skala at incoma.cz (Zdenek Skala)
Date: Thu, 9 Dec 1999 12:06:44 +0100
Subject: [R] Re: Re: barplot
In-Reply-To: <x2so1c30lu.fsf@blueberry.kubism.ku.dk>
References: "Zdenek Skala"'s message of "Thu, 9 Dec 1999 08:41:04 +0100"
Message-ID: <199912091105.MAA15379@benes.incoma.cz>

Peter Dalgaard wrote:
> Actually, it's a problem in any version of R since way back:
> > range(-0.01:1.01)
> [1] -0.01  0.99
> 
> (a:b gives sequences in steps of 1, starting from a and stopping
> before b is exceeded).

Perhaps this could be mentioned in the help to the range(), since the current 
text "range returns a vector containing the minimum and maximum of all the 
given arguments" seems to be a bit confusing to me.
Zdenek

++++++++++++++++++++++
] Zdenek Skala
] e-mail:
] Zdenek.Skala at incoma.cz

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Dec  9 12:31:12 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Dec 1999 12:31:12 +0100
Subject: [R] Re: Re: barplot
In-Reply-To: "Zdenek Skala"'s message of "Thu, 9 Dec 1999 12:06:44 +0100"
References: <199912091105.MAA15379@benes.incoma.cz>
Message-ID: <x29034bbb3.fsf@blueberry.kubism.ku.dk>

"Zdenek Skala" <Zdenek.Skala at incoma.cz> writes:

> Perhaps this could be mentioned in the help to the range(), since the current 
> text "range returns a vector containing the minimum and maximum of all the 
> given arguments" seems to be a bit confusing to me.
> Zdenek

But that's what it does:

> -0.01:1.01
[1] -0.01  0.99


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Thu Dec  9 14:03:27 1999
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Thu, 9 Dec 1999 13:03:27 +0000 (GMT)
Subject: [R] nlm() problem or MLE problem?
Message-ID: <Pine.LNX.4.10.9912091241470.13634-200000@localhost.localdomain>

I am trying to do a MLE fit of the weibull to some data, which I attach.

fitweibull<-function()
{
rt<-scan("r/rt/data2/triam1.dat")
rt<-sort(rt)
plot(rt,ppoints(rt))
a<-9
b<-.27
fn<-function(p) -sum( log(dweibull(rt,p[1],p[2])) )
cat("starting -log like=",fn(c(a,b)),"\n")
out<-nlm(fn,p=c(a,b), hessian=TRUE)
xfit<-seq(min(rt),max(rt),(max(rt)-min(rt))/100)
yfit<-pweibull(xfit,out$estimate[1], out$estimate[2])
lines(xfit,yfit,lty=2)
yfit2<-pweibull(xfit,a, b)
lines(xfit,yfit2)
list(out=out)
}

I got the starting values a=9, b=.27 from fitting the Weibull CDF by eye
to a quantile plot of the data. The final values fitted by nlm() are a=
4.8299357, b= 0.2753897

I plotted both CDFs against the quantile plot of the data. I would have
expected the MLE fit to be the one that lies closer to the data. NO.
The MLE solution (dashed) seems to fit quite badly in comparison with my
starting values (solid).

I wonder if this is just the way MLE is, or is there a problem with nlm()
here? There are numerous warnings from nlm(). But the starting values are
said to give a terrible -log likelihood, which is hard to believe. I am
using R 65.1 under Linux.

Thanks for any help!

Bill
PS when I do  dweibull(rt,9,.27)
the last value is 1.003383e-173
I guess this  one observation in the right-hand tail is dominating the
fit?! It contributes 173 to the -log likelihood
The nlm() fit to this last point gives 1.550882e-10.
What to do?
-------------- next part --------------
0.526431
0.310086
0.222007
0.209077
0.211198
0.222049
0.189770
0.218770
0.209489
0.205987
0.215240
0.273280
0.216011
0.266921
0.221901
0.207630
0.302419
0.271111
0.267090
0.206637
0.257495
0.221931
0.213982
0.249320
0.212692
0.277495
0.266773
0.254769
0.288441
0.281049
0.258157
0.237112
0.286718
0.304359
0.241937
0.247500
0.262666
0.210689
0.279578
0.301593
0.227285
0.244661
0.256363
0.274192
0.290597
0.270520
0.284376
0.259045
0.215456
0.207124
0.241684
0.282749
0.286396
0.277762
0.209074
0.232699
0.286557
0.258815
0.320231
0.266717
0.293170
0.233128
0.232281
0.227134
0.249905
0.258367
0.268534
0.254488
0.265343
0.227485
0.269131
0.273510
0.261441
0.289957
0.274722
0.278432
0.236914
0.234670
0.312916
0.239800
0.247947
0.254326
0.198332
0.232380
0.234817
0.253268
0.260428
0.282009
0.255082
0.287075
0.275064
0.278829
0.281103
0.266035
0.257373
0.300321
0.284854
0.253519
0.277225
0.297887

From Zdenek.Skala at incoma.cz  Thu Dec  9 15:06:37 1999
From: Zdenek.Skala at incoma.cz (Zdenek Skala)
Date: Thu, 9 Dec 1999 15:06:37 +0100
Subject: [R] Re: Re: barplot
In-Reply-To: <000901bf4244$0c4f0da0$a9021aac@joelschlaegel>
References: <199912091105.MAA15379@benes.incoma.cz>
Message-ID: <199912091404.PAA16353@benes.incoma.cz>

> as Peter pointed out, it's not a range() problem. The source of your
> trouble is a misunderstanding about the meaning of the : operator.

Really. Sorry for all this posting.
Zdenek
++++++++++++++++++++++
] Zdenek Skala
] e-mail:
] Zdenek.Skala at incoma.cz

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Thu Dec  9 17:22:51 1999
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Thu, 9 Dec 1999 08:22:51 -0800 (PST)
Subject: [R] nlm() problem or MLE problem?
In-Reply-To: <Pine.LNX.4.10.9912091241470.13634-200000@localhost.localdomain>
Message-ID: <Pine.GSO.4.21.9912090817390.25016-100000@gorn.biostat.washington.edu>

On Thu, 9 Dec 1999, Bill Simpson wrote:

> I am trying to do a MLE fit of the weibull to some data, which I attach.
> 
> 
> I got the starting values a=9, b=.27 from fitting the Weibull CDF by eye
> to a quantile plot of the data. The final values fitted by nlm() are a=
> 4.8299357, b= 0.2753897
> 
> I plotted both CDFs against the quantile plot of the data. I would have
> expected the MLE fit to be the one that lies closer to the data. NO.
> The MLE solution (dashed) seems to fit quite badly in comparison with my
> starting values (solid).
> 
> I wonder if this is just the way MLE is, or is there a problem with nlm()
> here? There are numerous warnings from nlm(). But the starting values are
> said to give a terrible -log likelihood, which is hard to believe. I am
> using R 65.1 under Linux.
> 
> Thanks for any help!
> 
> Bill
> PS when I do  dweibull(rt,9,.27)
> the last value is 1.003383e-173
> I guess this  one observation in the right-hand tail is dominating the
> fit?! It contributes 173 to the -log likelihood
> The nlm() fit to this last point gives 1.550882e-10.


Well, it looks as though the data don't come from a Weibull distribution
(at least that last point).

You can also fit a Weibull with survreg() in survival5, which gives the
same results as nlm without any complaints.

If you drop the last point survreg() gives 9.66 and 0.27 for the MLEs, so
the last point really is the problem.  Either the model is badly wrong or
the point is badly wrong, but nlm() is doing fine.


	-thomas

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle


	

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at biostat.washington.edu  Thu Dec  9 22:22:51 1999
From: rossini at biostat.washington.edu (A.J. Rossini)
Date: 09 Dec 1999 13:22:51 -0800
Subject: [R] MS level position at U. Washington
Message-ID: <87g0xbbyhg.fsf@alpha.cfas.washington.edu>



I know it isn't done often, so apologies if this posting offends.  But
after posting the announcement of the open position to a number of
other software lists, I was thinking, why not to R-help?  (esp since
knowing R is one option for meeting the requirements).

best,
-tony



We are looking for an masters level statistician.  If interested, feel
free to apply.  I am available to answer questions about the position.
More information can be found at:

http://www.washington.edu/admin/employment/1999archive/12-1999archive/99-0990.html

Reference: 99-0990
Department: Department of Biostatistics, Center for Aids Research (CFAR)
Date Available: December 8, 1999
Closing Date: Open until filled.

General Duties/Description: The Research Consultant will be
responsible for creating, documenting, maintaining, and analyzing data
sets for researchers at the Center for AIDS Research (CFAR) and its
affiliates. The CFAR is a world leader in research in the areas of
HIV/AIDS, and the Research Consultant will be exposed to a wide
variety of problems.  Responsibilities also include assisting with the
development of statistical and scientific resources for clinical,
biological, prevention and behavioral AIDS research, and well as
performing statistical analyses of data for manuscripts leading to
publication in peer-reviewed journals.

Requirements: A Master's degree in statistics or biostatistics and
experience in cleaning and analyzing data. Working knowledge of the
analysis of longitudinal data and of generalized linear models such as
logistic or poisson regression required. Previous experience with
medical research data and with consulting is preferred. Familiarity
with S-PLUS, R, or Stata in a Unix-based environment
required. Additional experience with SPSS or SAS, Microsoft Word and
Excel under Microsoft Windows is preferred. The ability to work
independently, as well as responsibly on multiple projects
required. Equivalent education or experience may substitute for stated
requirements.

How to Apply: Send a resume and cover letter to: Sally Weatherford,
Administrator, Center for AIDS and STD / Allergy and Infectious
Diseases, Box 359931, University of Washington, Seattle, WA 98195.


best,
-tony

-- 
A.J. Rossini			Research Assistant Professor of Biostatistics 
Center for AIDS Research/HMC	Biostatistics/Univ. of Washington
Box 359931			Box 357232
206-731-3647 (3693=fax)		206-543-1044 (3286=fax)
rossini at u.washington.edu	rossini at biostat.washington.edu
http://www.biostat.washington.edu/~rossini/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kgerber at gmx.ch  Thu Dec  9 20:38:57 1999
From: kgerber at gmx.ch (Kurt Gerber)
Date: Thu, 9 Dec 1999 20:38:57 +0100
Subject: [R] Problems with X11 - device
In-Reply-To: <99120711125201.00425@clandestino>
References: <99120700495200.00405@clandestino> <x2yab72k5y.fsf@blueberry.kubism.ku.dk> <99120711125201.00425@clandestino>
Message-ID: <99120920425501.00808@clandestino>

On Tue, 07 Dec 1999, Kurt Gerber wrote:
>On Tue, 07 Dec 1999, Peter Dalgaard BSA wrote:
>>Kurt Gerber <kgerber at giub.unibe.ch> writes:
>>
>>> I started the graphics device with X11(). When I tried to plot a tree object
>>> with
>>> > plot (tree) 
>>> It gives me the error message:
>>> 
>>> Error in plot.window(xlim, ylim, log, asp, ...) : invalid xlim
>>> 
>>> I was looking in the manual under "plot", "plot.window", etc. but I didn't
>>> really get the resolution of my problem.....
>>> What's the problem?
>>>  
>>> I'm runnig R on a SuSE 6.0 System.
>>> 
>>> When I ran the same thing under the R for Windows, it plotted just fine... Is
>>> thre a special problem with the X11 device?
>>
>>Ahem. Version numbers are important!
>>
>>If it's R 0.90.0 the fonts are a bit large... does it help if you start
>>the plotwindow with an explicit x11(pointsize=10)?
>
>No, this doesn't help. R. Version is:
>
>R : Copyright 1999, The R Development Core Team
>Version 0.65.1 Release (October 07, 1999)      
>

I still didn' get any answer to  this request, maybe it got lost...
It is a serious problem. Could it be a problem of my older release? Should I
update to R.0.90 ? I wanted not to have to compile it my self and there are
no binaries for SuSE 6.0  for this version.  

Kurt 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Dec 10 09:18:00 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Dec 1999 09:18:00 +0100
Subject: [R] Problems with X11 - device
In-Reply-To: Kurt Gerber's message of "Thu, 9 Dec 1999 20:38:57 +0100"
References: <99120700495200.00405@clandestino> <x2yab72k5y.fsf@blueberry.kubism.ku.dk> <99120711125201.00425@clandestino> <99120920425501.00808@clandestino>
Message-ID: <x2n1rjb45j.fsf@blueberry.kubism.ku.dk>

Kurt Gerber <kgerber at gmx.ch> writes:

> I still didn' get any answer to  this request, maybe it got lost...
> It is a serious problem. Could it be a problem of my older release? Should I
> update to R.0.90 ? I wanted not to have to compile it my self and there are
> no binaries for SuSE 6.0  for this version.  

One problem is that I don't think you provided simple instructions for
reproducing the problem. E.g. I don't normally use tree() for
anything, and I wouldn't have the time to learn now. If I could run a
couple of commands and see where the problem is, I might be able to
debug it at least some of the way, but otherwise no.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From j.logsdon at lancaster.ac.uk  Fri Dec 10 09:54:47 1999
From: j.logsdon at lancaster.ac.uk (John Logsdon)
Date: Fri, 10 Dec 1999 08:54:47 +0000 (GMT)
Subject: [R] Problems with X11 - device
In-Reply-To: <99120920425501.00808@clandestino>
Message-ID: <Pine.LNX.4.10.9912100844120.17538-100000@mercury.quantex>


On Thu, 9 Dec 1999, Kurt Gerber wrote:

[snip]

> >>Kurt Gerber <kgerber at giub.unibe.ch> writes:
> >>
> >>> I started the graphics device with X11(). When I tried to plot a tree object
> >>> with
> >>> > plot (tree) 
> >>> It gives me the error message:
> >>> 
> >>> Error in plot.window(xlim, ylim, log, asp, ...) : invalid xlim
> >>> 
> >>> I was looking in the manual under "plot", "plot.window", etc. but I didn't
> >>> really get the resolution of my problem.....
> >>> What's the problem?
> >>>  

[snip]

> 
> I still didn' get any answer to  this request, maybe it got lost...
> It is a serious problem. Could it be a problem of my older release? Should I
> update to R.0.90 ? I wanted not to have to compile it my self and there are
> no binaries for SuSE 6.0  for this version.  
> 

I have seen this before but it has always been some silly aspect of the
data I was trying to plot.  Is there any data at all (NAs).  For example:

> y<-x<-c(0,1)
> plot(x,y)

Produces a simple plot as expected but making all x's NA:

> x<-c(NA,NA)
> plot(x,y)
Error in plot.window(xlim, ylim, log, asp, ...) : invalid xlim

gives the error message you get.  Is it possible that the Linux and
Windows version set-ups are leading to different vectors for tree to
handle?

I am still using 0.63.3 under RH5.2 which is rock stable so I don't want
to upgrade 'cos there aren't any rpms for later R's under RH5.2!  Very
lazy really!

John

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From marmp at fcu.um.es  Fri Dec 10 17:19:22 1999
From: marmp at fcu.um.es (Marcelo Martinez Palao)
Date: Fri, 10 Dec 1999 17:19:22 +0100
Subject: [R] orthogonal and nested model
Message-ID: <38512809.9FAB677@fcu.um.es>

I'm working with a orthogonal and nested model (mixed).
I have  four factors, A,B,C,D;
A and B are fixed and orthogonal
C is nested in AB interaction
and finally, D is nested in C.
 I would like to model the following
Y_ijklm=Mu+A_i+B_j+AB_ij+C_k(ij)+D_l(k(ij))+Error_m(...)

I used the next command

>summary(aov(abund~A*B + C % in % A:B + D % in % C % in % A:B ,datos))

Is it the correct formula syntax?

Thaks for all.

Marcelo.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Fri Dec 10 17:00:42 1999
From: bates at stat.wisc.edu (Douglas Bates)
Date: 10 Dec 1999 10:00:42 -0600
Subject: [R] orthogonal and nested model
In-Reply-To: Marcelo Martinez Palao's message of "Fri, 10 Dec 1999 17:19:22 +0100"
References: <38512809.9FAB677@fcu.um.es>
Message-ID: <6rd7se6b11.fsf@franz.stat.wisc.edu>

Marcelo Martinez Palao <marmp at fcu.um.es> writes:

> I'm working with a orthogonal and nested model (mixed).
> I have  four factors, A,B,C,D;
> A and B are fixed and orthogonal
> C is nested in AB interaction
> and finally, D is nested in C.
>  I would like to model the following
> Y_ijklm=Mu+A_i+B_j+AB_ij+C_k(ij)+D_l(k(ij))+Error_m(...)
> 
> I used the next command
> 
> >summary(aov(abund~A*B + C % in % A:B + D % in % C % in % A:B ,datos))
> 
> Is it the correct formula syntax?

I would recommend using the lme (linear mixed-effects) function from
the nlme package for this.  Please ensure that you have R version
0.90.0 installed, then use
 install.packages("nlme")
from within R to obtain and install the package.

If I understand your message correctly, your model specification would be
 fm1 <- lme(abund ~ A * B, random = list(C = ~ 1, D = ~ 1), data = datos)
This will fit the restricted maximum likelihood (REML) estimates.

If you prefer to get maximum likelihood (ML) estimates, include the argument
 method = "ML"
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Fri Dec 10 17:07:39 1999
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 10 Dec 1999 17:07:39 +0100 (MET)
Subject: [R] Feature request: add boxplot()s to current plot (given x[i])
Message-ID: <14417.9547.376985.657881@gargle.gargle.HOWL>

(as the subject says)
It makes sense to add (say k) boxplots to a given plot,
using the given coordinate system.

Currently, the calling sequence
	     boxplot -> boxplot.default() -> bxp()
[modeled after S]
doesn't allow this, since  bxp() explicitly
sets up the coordinate system.

One way would be to add an "add = TRUE" argument to boxplot(.) and bxp(.)
and then additionally specify the (k) x-locations to use.

Has anybody already done something like this?

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO D10	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jbarnett at wi.mit.edu  Fri Dec 10 17:58:47 1999
From: jbarnett at wi.mit.edu (John D. Barnett)
Date: Fri, 10 Dec 1999 11:58:47 -0500
Subject: [R] FAQ: 8.2 How can I debug dynamically loaded code?
Message-ID: <38513147.7FA48D17@wi.mit.edu>

I'm having some trouble following the instructions in the FAQ for
debugging.

I can run 'R -d gdb' at the command line and it works; also, I have run
gdb from emacs before.

But I can't figure out how to put the two together: I've tried following
the instructions in the FAQ, but I seem to be missing something.  Can
someone with experience tell me exactly how I should invoke gdb on R
from within emacs?

Thanks.

-John Barnett

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dj at research.bell-labs.com  Fri Dec 10 17:58:52 1999
From: dj at research.bell-labs.com (David James)
Date: Fri, 10 Dec 1999 11:58:52 -0500 (EST)
Subject: [R] Feature request: add boxplot()s to current plot (given x[i])
Message-ID: <199912101658.LAA24131@jessie.research.bell-labs.com>

Hi,

I experimented with a set of S functions to do  "generalized" boxplots 
sometime ago (e.g., "vase" or "violin, "diamond" plots, etc).  There's 
code to draw these gboxplots at arbitrary positions. Please take a look
at the help below and let me know if you'd like either  to port
it R or scavange some of the code.

David A James                        Phone: (908) 582-3082
Bell Labs, Lucent Technologies       Fax:   (908) 582-3340
600 Mountain Ave                     Email: dj at bell-labs.com
Murray Hill, NJ 07974
--------------------------------------------------------------------
Generalized Box Plots

USAGE:
       gboxplot(..., type = "box", range.=,
               width=, varwidth=F, notch=F, names.=, horiz = T,
               fill=F, col=1, old = T, plot.it=TRUE)

       gboxplot(..., type = "vase", from=, to=, kernel.width=, n=,
               width=, varwidth=F, notch=F, names.=, horiz = T,
               fill=F, col=1, plot.it=TRUE)

       gboxplot(..., type = "diamond", width=, varwidth=F,
            names.=, horiz = T, fill=F, col=1, pch, plot.it=TRUE)

       gboxplot(..., type = "pts", jitter.pts = F,
               width=, varwidth=F, notch=F, names.=, horiz = T,
               fill=F, col=1, pch, plot.it=TRUE)
ARGUMENTS:
...:    vectors  or  a list containing a number of numeric compo-
       nents (e.g., the output of split').  Missing values  (NAs)
       are allowed.
type=:    character string (the first letter suffices) specifying
       type of gboxplots, currently "box" for  Tukey's  boxplots,
       "vase"  for vase or violin plots (see Benjamini (1988) and
       Hintze and Nelson (1998)),  "diamond"  for  diamond  plots
       (see,  for  instance, JMP (1995)), or "pts" for one dimen-
       sional histograms (See Chambers et. al. (1983)).  Type may
       also  be the name of a user-written function that computes
       an object for which there exists a draw' method.  For  in-
       stance  type  = cmp.vase' specifies the function that com-
       putes vases and which returns an object of  class  "vase";
       the method draw.vase' (automatically called by the generic
       draw') plots the vases.
range.=:    controls the strategy for the whiskers  and  the  de-
       tached  points  beyond  the whiskers. By default, whiskers
       are drawn to the nearest value not beyond a standard range
       from  the quartiles; points beyond are drawn individually.
       Giving range.=0' forces whiskers to the full  data  range.
       Any  positive  value  of  range.'  multiplies the standard
       range by this amount.  The standard range  is  1.5*(inter-
       quartile range).
width=:    vector of relative box widths.  See also argument var-
       width'.
varwidth=:     if TRUE', box widths will be proportional  to  the
       square-root of the number of observations for the box.
notch=:    if  TRUE', notched boxes are drawn, where non-overlap-
       ping of notches of boxes indicates a difference at a rough
       5% significance level.
names.=:     optional  character  vector of names for the groups.
       If omitted, names used in labeling the plot will be  taken
       from  the  names  of  the arguments and from the names at-
       tribute of lists.
plot.it=:   if TRUE', the box plot will be  produced;  otherwise,
       the calculated summaries of the arguments are returned.
old=:      if  TRUE',  the plot will be produced in the style de-
       scribed in the Tukey (1977) reference; otherwise, the plot
       will  follow  the  more  modern  style introduced in Tukey
       (1990), where the advantages of  the  new  style  are  de-
       scribed.
horiz=:   if TRUE boxes are drawn horizontally.
from:      (vaseplots) lower bound for the percent of data to use
       in fitting density'.  By default 0.25.
to:    (vaseplots) upper bound for the percent of data to use  in
       fitting density'.  By default 0.75.
kernel.width:     (vaseplots)  width of the kernel window, as de-
       fined in the function density'.  Its  default  corresponds
       to  the  width  of  a histogram bar as computed by Doane's
       rule.
n:     (vaseplot) number of equally spaced density estimates. De-
       fault is 25.
jitter.pts:     (pts)  if logical, it specifies whether or not to
       jitter the points inside each group. If numeric it  speci-
       fies  the  amount,  in  data  units, to jitter. Default is
       FALSE.
fill:     should boxes or vases be filled? Default is FALSE.
col:   vector of colors for each group.
pch:   vector of plotting character for each group.

       Graphical parameters may also be supplied as arguments  to
       this function (see par)
VALUE:
       If  plot.it'  is  FALSE',  the  value is a list as long as
       there are data vectors with the components  listed  below.
       Otherwise the generic function draw' is invoked with these
       components, plus optional width', varwidth' and notch', to
       produce  the  plot.   Note  that  draw'  returns a list of
       box/vase centers.

stats:    vector giving the upper extreme, upper quartile,  medi-
       an, lower quartile, and lower extreme for each box.
n:     the number of observations in each group.
conf:     vector giving confidence limits for the median.
out:   vector of outlying points.
names.:   names for each box (see argument names.' above).
dnsty:     a list with x' and y' components as output by density.

NOTES:
       In the case of vase plots, the density is estimated  using
       kernel  smoothing  ---  this  was done for expediency, but
       other density estimates may be easily added  (e.g.,  local
       polynomial  fitting  as in Loader (1996)).  Also note that
       the aspect ratio of the density traces may be such that it
       distorts important features of the data.

REFERENCE:
       Tukey, John W., Exploratory Data Analysis, Addison-Wesley,
       Reading, Mass., 1977.

       Tukey, John W., "Data Based Graphics:  Visual  Display  in
       the  Decades  to  Come", Statistical Science, pp. 327-339,
       1990.

       Benjamini, Yoav "Opening the Box of a Boxplot" The  Ameri-
       can Statistician, pp. 257-262, 1988.

       Chamber, J. M., Cleveland, W. S., Klein, P., and Tukey, P.
       A.  Graphical Methods for Data Analysis, Wadsworth, Pacif-
       ic Grove, CA., 1983.

       Hintze, Jerry L., and Nelson, Ray D., "Violin Plots: A Box
       Plot-Density Trace Synergism", The American  Statistician,
       pp. 181-184, 1998.

       Loader,  Clive, "Local Likelihood Density Estimation", An-
       nals of Statistics, 1996.

       "JMP User's Guide", SAS Institute Inc., 1995.

EXAMPLES:
       gboxplot(group1,group2,group3)

       gboxplot(split(salary,age),varwidth=TRUE,notch=TRUE)

       # the example plot is produced by:
       gboxplot(
             split(lottery.payoff,lottery.number%/%100),
             main=lottery.label,
             sub="Leading Digit of Winning Numbers",
             ylab="Payoff")
       gboxplot( split(Mileage, Type), type = "vase", col=1:6)
       gboxplot( split(Mileage, Type), type = "pts", jitter=3, col=1:6)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Dec 10 18:10:27 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Dec 1999 18:10:27 +0100
Subject: [R] FAQ: 8.2 How can I debug dynamically loaded code?
In-Reply-To: "John D. Barnett"'s message of "Fri, 10 Dec 1999 11:58:47 -0500"
References: <38513147.7FA48D17@wi.mit.edu>
Message-ID: <x2emcusovw.fsf@blueberry.kubism.ku.dk>

"John D. Barnett" <jbarnett at wi.mit.edu> writes:

> I'm having some trouble following the instructions in the FAQ for
> debugging.
> 
> I can run 'R -d gdb' at the command line and it works; also, I have run
> gdb from emacs before.
> 
> But I can't figure out how to put the two together: I've tried following
> the instructions in the FAQ, but I seem to be missing something.  Can
> someone with experience tell me exactly how I should invoke gdb on R
> from within emacs?

Hmm. I don't usually do that, but both of the following seems to be
somewhat in the right direction:

C-u M-x R and then give options -d gdb (requires ESS)

or

M-x gdb and then give R -d gdb as startup command

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Fri Dec 10 19:20:44 1999
From: bates at stat.wisc.edu (Douglas Bates)
Date: 10 Dec 1999 12:20:44 -0600
Subject: [R] FAQ: 8.2 How can I debug dynamically loaded code?
In-Reply-To: Peter Dalgaard BSA's message of "10 Dec 1999 18:10:27 +0100"
References: <38513147.7FA48D17@wi.mit.edu> <x2emcusovw.fsf@blueberry.kubism.ku.dk>
Message-ID: <6rzovi4pz7.fsf@franz.stat.wisc.edu>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> "John D. Barnett" <jbarnett at wi.mit.edu> writes:
> 
> > I'm having some trouble following the instructions in the FAQ for
> > debugging.
> > 
> > I can run 'R -d gdb' at the command line and it works; also, I have run
> > gdb from emacs before.
> > 
> > But I can't figure out how to put the two together: I've tried following
> > the instructions in the FAQ, but I seem to be missing something.  Can
> > someone with experience tell me exactly how I should invoke gdb on R
> > from within emacs?
> 
> Hmm. I don't usually do that, but both of the following seems to be
> somewhat in the right direction:
> 
> C-u M-x R and then give options -d gdb (requires ESS)
> 
> or
> 
> M-x gdb and then give R -d gdb as startup command

A third option is to start R within ESS mode (M-x R) and load whatever
R libraries that you want, then start gdb (M-x gdb) giving
$RHOME/bin/R.X11 as the program to debug.  Use the program "ps" to
find the process number of the currently running R process then use
use the "attach" command in gdb to attach gdb to that process.

One advantage of this method is that you have separate *R* and
*gud-gdb* windows.  Within the *R* window you have all the ESS
facilities, such as object-name completion, that we know and love.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kgerber at gmx.ch  Fri Dec 10 22:47:56 1999
From: kgerber at gmx.ch (Kurt Gerber)
Date: Fri, 10 Dec 1999 22:47:56 +0100
Subject: [R] strange results from tree()
Message-ID: <99121023033200.00588@clandestino>

Does anybody work with the function tree() from the contributed library "tree"?
I used this function first on S-Plus version 3.x on a Sun Solaris Workstation 
and also on Windows S-Plus Version 4.x. 

Now, on my first use, always with the same data, on S-Plus, it was growing a
wonderful tree with many many leaves and nodes. Many of them redundant and I
had to use prune.tree and snip.tree and so on.

Then I found R and thought, that for me I could be useful (because the S-Plus
Licenses are too few..) and I could install it at home on my Linux box and on
Windows where I'm working on University. 
 So I did. 
 Now, first on the Windows Installation of R (I think it is R 0.90) it was
growing a small tree with only few leaves. Only about one node redundant. 
Then on Linux (R. 0.65) : Only  three nodes and no leaves.... And I tried
with every configuration with tree.control an so on.... But I get always
the same result. (That was the cause too for my x11() -display problem. Thanks
to John Logsdon for the hint!).

Which statistical software should I believe, now the results are sooooo
different?

I guess the answer: The most expensive one....

Kurt
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cyg at sympatico.ca  Sat Dec 11 01:43:54 1999
From: cyg at sympatico.ca (Yves Gauvreau)
Date: Fri, 10 Dec 1999 19:43:54 -0500
Subject: [R] Graphics ?
Message-ID: <011201bf4370$cd5e2300$6828acce@bellglobal.com>

Hi,

In the Windows version of R 0.65.1 I'd like to copy the results of a plot to
the clipboard either as a bitmap or as a metafile. The same thing in fact as
does the menu "Copy to the clipboard" provides but from the command line. I
intend to use the DCOM server version of R to do plots, among other things
and copy the results to the clipboard and show these on a picture box in my
own VB application.

Thanks in advance.

Yves

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjhealy at princeton.edu  Sat Dec 11 06:50:28 1999
From: kjhealy at princeton.edu (Kieran Healy)
Date: Sat, 11 Dec 1999 00:50:28 -0500
Subject: [R] make errors while compiling
Message-ID: <3851E624.1A208538@princeton.edu>

Dear R users -

I am a first-time R user trying to compile v.0.90.0 under Caldera
OpenLinux 2.3, on a Dell PII400/128. I've encountered a problem with the
make file. 

First, I run configure, which appears to complete properly. (I had to
download an updated gcc library from caldera for this to happen though.)
At the end of its run, config reports:

> R is now configured for i686-unknown-linux
> 
>  Source directory:         .
>  Installation directory:   /usr/local
>  C compiler:               gcc  -mieee-fp -g -O2
>  FORTRAN compiler:         g77  -g -O2
>  Gnome support:            no                        

Then I run make. It terminates after a few lines as follows:

[ -- some initial lines snipped -- ]
making Rsock.d from Rsock.c
In file included from /usr/include/bits/posix1_lim.h:126,
                 from /usr/include/limits.h:30,
                 from
/usr/lib/gcc-lib/i386-linux/egcs-2.91.66/include/limits.h:117,
                 from
/usr/lib/gcc-lib/i386-linux/egcs-2.91.66/include/syslimits.h:7,
                 from
/usr/lib/gcc-lib/i386-linux/egcs-2.91.66/include/limits.h:11,
                 from Rsock.c:28:
/usr/include/bits/local_lim.h:27: linux/limits.h: No such file or
directory
In file included from /usr/include/errno.h:36,
                 from Rsock.c:32:
/usr/include/bits/errno.h:25: linux/errno.h: No such file or directory
In file included from /usr/include/signal.h:294,
                 from Rsock.c:156:
/usr/include/bits/sigcontext.h:28: asm/sigcontext.h: No such file or
directory
make[3]: *** [Rsock.d] Error 1
make[3]: Leaving directory `/root/R-0.90.0/src/appl'
make[2]: *** [R] Error 2
make[2]: Leaving directory `/root/R-0.90.0/src/appl'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/root/R-0.90.0/src'
make: *** [R] Error 1                                 

[ -- end -- ]

The files make appears to be complaining about do exist on my system. In
each case make seems to find the file (eg, /usr/include/bits/errno.h)
but then complains seems to refer to a different directory --
linux/errno.h --- and says `No such file'. If linux/ and asm/ are meant
to be directories with these files inside, they don't exist on my
system. I've tried several clean installs and get the same result each
time.

RPM says I'm using the following C and Fortran packages:

egcs-2.91.66-5
egcs-c++-2.91.66-5
egcs-objc-2.91.66-5
glib-devel-static-1.2.3-2
glibc-devel-static-2.1.1-1
glibc-devel-2.1.1-1
glibc-localedata-2.1.1-1
g77-2.91.66-6                      

I don't have much experience compiling files of this sort, so I can't
interpret the error messages properly. I'd be very grateful for advice
on what I'm doing wrong, and how to remedy it.

Thanks,

Kieran Healy

-- 
Kieran Healy              email: kjhealy at princeton.edu 
Department of Sociology   
Princeton University      
Princeton, NJ 08544-1010
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Dec 11 08:47:22 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sat, 11 Dec 1999 07:47:22 +0000 (GMT)
Subject: [R] make errors while compiling
In-Reply-To: <3851E624.1A208538@princeton.edu>
Message-ID: <Pine.GSO.4.05.9912110731140.31-100000@auk.stats>

On Sat, 11 Dec 1999, Kieran Healy wrote:

> I am a first-time R user trying to compile v.0.90.0 under Caldera
> OpenLinux 2.3, on a Dell PII400/128. I've encountered a problem with the
> make file. 

Well, not with the make file but with your system. On our RedHat Linux
boxes, both asm/sigcontext.h and linux/limits.h are in the rpm
kernel-headers-*, so I suggest you try installing that. However, again on
our systems, glibc-devel requires kernel-headers.  So either Caldera have
got their dependencies wrong (and we have encountered missing files on
Caldera systems before) or you did not allow dependencies to be installed.
Try

rpm -q --requires glibc-devel

to see if kernel-headers is a dependency.  I vaguely recall there are ways
to check for any missing required packages on RPM-based systems, but as I
have never had need of them, I can't recall the details.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Dec 11 09:16:29 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sat, 11 Dec 1999 08:16:29 +0000 (GMT)
Subject: [R] Re: copying to the clipboard from the command line in Windows (was
 [R] Graphics ?)
In-Reply-To: <011201bf4370$cd5e2300$6828acce@bellglobal.com>
Message-ID: <Pine.GSO.4.05.9912110755260.31-100000@auk.stats>

On Fri, 10 Dec 1999, Yves Gauvreau wrote:

> In the Windows version of R 0.65.1 I'd like to copy the results of a plot to
> the clipboard either as a bitmap or as a metafile. The same thing in fact as
> does the menu "Copy to the clipboard" provides but from the command line. I
> intend to use the DCOM server version of R to do plots, among other things
> and copy the results to the clipboard and show these on a picture box in my
> own VB application.

The answer is in the file gnuwin32/devga.c. Just see what the menu actually
calls. For a bitmap, you need to write some compiled code that calls
copytoclipboard. (Or use savePlot to write a bmp file, in rw0900 and
later.)

For a metafile, I believe you can use savePlot with file name "": you can
certainly use this to write to a file and then read it into your VB
application.

However, why not plot directly to a metafile or bmp file and then display
that?  That avoids writing graphics on a screen somewhere that you don't
want displayed.

If you are doing this sort of thing you really need to keep fully
up-to-date with R versions. Thomas Baier's DCOM server (it is not a version
of R) has been updated, and you will need R 0.90.1 (due next week) to
run with version 0.91 of his server.  Or compile up R-release now.

A more informative subject line would be helpful.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sat Dec 11 12:06:57 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 11 Dec 1999 12:06:57 +0100
Subject: [R] make errors while compiling
In-Reply-To: Prof Brian D Ripley's message of "Sat, 11 Dec 1999 07:47:22 +0000 (GMT)"
References: <Pine.GSO.4.05.9912110731140.31-100000@auk.stats>
Message-ID: <x2so19ag8e.fsf@blueberry.kubism.ku.dk>

Prof Brian D Ripley <ripley at stats.ox.ac.uk> writes:

> On Sat, 11 Dec 1999, Kieran Healy wrote:
> 
> > I am a first-time R user trying to compile v.0.90.0 under Caldera
> > OpenLinux 2.3, on a Dell PII400/128. I've encountered a problem with the
> > make file. 
> 
> Well, not with the make file but with your system. On our RedHat Linux
> boxes, both asm/sigcontext.h and linux/limits.h are in the rpm
> kernel-headers-*, so I suggest you try installing that. However, again on
> our systems, glibc-devel requires kernel-headers.  So either Caldera have
> got their dependencies wrong (and we have encountered missing files on
> Caldera systems before) or you did not allow dependencies to be installed.
> Try
> 
> rpm -q --requires glibc-devel
> 
> to see if kernel-headers is a dependency.  I vaguely recall there are ways
> to check for any missing required packages on RPM-based systems, but as I
> have never had need of them, I can't recall the details.

Yes. On some older versions of RedHat and Slackware, I believe that
the asm and linux directories pointed directly into the kernel
sources, so if there's nothing like kernel-headers on your CD, it
might be the kernel sources themselves that need to be installed.

Let us know if (and how) you get this to work. The OpenLinux systems
seem to be gaining popularity because of its user-friendliness,
although at least in 2.2 it turned out that the
programmer-friendliness wasn't quite up to it...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjhealy at princeton.edu  Sat Dec 11 18:07:54 1999
From: kjhealy at princeton.edu (Kieran Healy)
Date: Sat, 11 Dec 1999 12:07:54 -0500
Subject: [R] Success compiling R on Caldera OL 2.3
Message-ID: <385284EA.9BDF30A7@princeton.edu>

Hello -

thanks to Prof. Ripley and Peter Dalgaard for their helpful responses. I
have now successfully compiled R on my machine. The kernel-headers were
not installed on my machine, but there is a package on the Open Linux
2.3 CD. I believe they weren't installed simply because I didn't choose
to have all the development tools/libraries added when I installed
linux. I didn't realize how soon I'd be compiling things.

Prof Brian Ripley Wrote:
> K> I am a first-time R user trying to compile v.0.90.0 under Caldera
> K> OpenLinux 2.3, on a Dell PII400/128. I've encountered a problem with the
> K> make file. 
> 
> Well, not with the make file but with your system. 

Of course, I didn't mean to suggest the problem was internal to the make
file. As I said at the end of my message, I was wondering what *I* was
doing wrong, not what was wrong with R.

For future reference, the two (system-related) difficulties I
encountered while trying to compile R under Cladera OL2.3 were:

1. An initial error with the fortran compiler g77. This resulted in a
problem at the /.configure stage, when confiugre complained that gcc and
g77 did not agree on the long int format. An updated g77 package for
COL, available at 
ftp://ftp.calderasystems.com/pub/OpenLinux/patches/earlyaccess/g77-2.91.66-6.i386.rpm
solved this problem.

2. The missing package that led to my posting to this list. It can be
found on the COL install CD and is called linux-kernel-include.rpm.

Thanks again for quickly pointing me in the right direction. I'm looking
forward to using R.

Kieran


-- 
Kieran Healy              email: kjhealy at princeton.edu 
Department of Sociology   
Princeton University      
Princeton, NJ 08544-1010  http://www.princeton.edu/~kjhealy
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From uli at biochem.dshs-koeln.de  Mon Dec 13 14:44:03 1999
From: uli at biochem.dshs-koeln.de (Uli Flenker; Raum 704)
Date: Mon, 13 Dec 1999 14:44:03 +0100 (CET)
Subject: [R] Problems with "help(topic,offline=T)"
Message-ID: <Pine.LNX.3.95.991213141502.10183A-100000@pcinternet.biochem.dshs-koeln.de>

Hello everybody,

since I installed R-0.90.0 (Linux 2.0.25) I have problems with generating
printable output with 'help()'.

Default output to the terminal ('echo $PAGER' gives 'less') works o.k..
When invoking 'help(topic,offline=T)' all the usual procedures seem to
start: 'top' reports invocation of latex as well as of dvips. But after
finishing there is no file; neither *.ps nor *.dvi files exist.

I checked for suspicous environment settings but couldn't find anything.
Also my dvips without problems produces files and doesn't send its output
to the printer when being invoked from the shell level. I thought of
problems there because my machine has no local printing device. 

I set 'options(printcmd="")' which didn't help either. 

Any ideas?

Lots of thanks in advance ...


        Uli Flenker
        Institute of Biochemistry
        German Sports University Cologne
        Carl-Diem-Weg 6

        50933 Cologne / Germany

        Phone 0049/0221/4982-493




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Dec 13 15:38:44 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 13 Dec 1999 15:38:44 +0100
Subject: [R] Problems with "help(topic,offline=T)"
In-Reply-To: "Uli Flenker; Raum 704"'s message of "Mon, 13 Dec 1999 14:44:03 +0100 (CET)"
References: <Pine.LNX.3.95.991213141502.10183A-100000@pcinternet.biochem.dshs-koeln.de>
Message-ID: <x2k8misy6j.fsf@blueberry.kubism.ku.dk>

"Uli Flenker; Raum 704" <uli at biochem.dshs-koeln.de> writes:

> Hello everybody,
> 
> since I installed R-0.90.0 (Linux 2.0.25) I have problems with generating
> printable output with 'help()'.
> 
> Default output to the terminal ('echo $PAGER' gives 'less') works o.k..
> When invoking 'help(topic,offline=T)' all the usual procedures seem to
> start: 'top' reports invocation of latex as well as of dvips. But after
> finishing there is no file; neither *.ps nor *.dvi files exist.
> 
> I checked for suspicous environment settings but couldn't find anything.
> Also my dvips without problems produces files and doesn't send its output
> to the printer when being invoked from the shell level. I thought of
> problems there because my machine has no local printing device. 
> 
> I set 'options(printcmd="")' which didn't help either. 
> 
> Any ideas?

Works for me...

The last few lines of the help ($RHOME/bin/help) script say

    ${LATEX} "\\nonstopmode\\input{${1}}" >/dev/null 2>&1
    ${DVIPS} ${1} 2>/dev/null
    if test -f ${1}.ps;
    then
        echo "Saving help page to \`${2}.ps'"
        mv ${1}.ps ${ODIR}/${2}.ps
    fi
    rm -f ${1}.aux ${1}.dvi ${1}.log

So if you're not seeing the "Saving help page to \`${2}.ps'" bit,
chances are that ${DVIPS} sends directly to the printer, or tries to. 

The other option is that ${LATEX} or  ${DVIPS} is failing fatally, for
some reason that you won't see because of the redirections.
Temporarily replacing /dev/null with a real file might reveal the
source of the mystery.

It's not a mystery that the .dvi files are cleaned up, cf the last
line above.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Mon Dec 13 18:24:12 1999
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Mon, 13 Dec 1999 17:24:12 +0000 (GMT)
Subject: [R] pointsize?
Message-ID: <Pine.LNX.4.10.9912131713330.17856-100000@localhost.localdomain>

A while ago there was a thread on graphics. I complained that the plots
produced by dev.print had symbols and fonts that were too small. I said 
I had been using par(cex=2), but the advice was to use pointsize. I have
tried ps, is that what was meant?

par(ps=40)
x<-rnorm(100)
y<-rnorm(100)
dev.print(file="~/junk.ps", horizontal=FALSE)

No matter how big I make ps (40,60...), the biggest size  plotsymbol
I get is a circle with a diameter of 2 mm.

Is there a way to get big axis labels and plot symbols using par(ps=)?
Or was something else meant when I was told to use pointsize?

Thanks very much for any help.

Bill

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From partha_bagchi at hgsi.com  Mon Dec 13 17:24:45 1999
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Mon, 13 Dec 1999 11:24:45 -0500
Subject: [R] Postscript Bug?
Message-ID: <OFF2C40114.04D2517C-ON85256846.00598604@hgsi.com>

I was wondering if there is a "bug" in the postscript driver?
Here is the problem:
postscript(file= "temp.ps", paper= "Letter", horizontal= FALSE)
#In the following statement, pch has no effect:
plot(c(0:10), pch= 15)

It produces a tiny circle when it should be showing filled squares.
However, the following works:
par(pch= 15)
plot(c(0:10))

dev.off()

Note: This was working just fine with R 0.65.1
details:

platform Windows
arch     x86
os       Win32
system   x86, Win32
status
major    0
minor    90.0
year     1999
month    November
day      22
language R
>


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From trade at imsp074.netvigator.com  Mon Dec 13 19:20:13 1999
From: trade at imsp074.netvigator.com (trade@imsp074.netvigator.com)
Date: Tue, 14 Dec 1999 02:20:13 +0800
Subject: [R] Are you ready to busy trade?
Message-ID: <36508.097373148153600.12648@localhost>

Dear All, 

http://www.busytrade.com

Pursuing "trading around the world without boundary", BusyTrade.com aims to enhance global business activities
and deals, by providing the most extensive trade information and efficient tool for manufacturers, importers,
exporters, distributors, agents, wholesalers, retailers, associations, governmental bodies and all other
trade-related parties.


Now BusyTrade.com offers Free Membership and company homepage (freely generated by BusyTrade.com) to all
trade-related parties. Get your trade busy, just register BusyTrade.com.
  
Click to register free membership and obtain more business deal:
http://www.BusyTrade.com/html/signup1.php


Click to visit BusyTrade.com: http://www.BusyTrade.com

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From partha_bagchi at hgsi.com  Mon Dec 13 21:57:58 1999
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Mon, 13 Dec 1999 15:57:58 -0500
Subject: [R] Superscript or subscript on Left hand side of symbol
Message-ID: <OF0B5BC67B.1B50BC97-ON85256846.0072AAFE@hgsi.com>

Is there a way to get subscripts and superscripts on the left hand side of
a symbol? For example, oC or oF (degree Celsius or Fahrenheit)
TIA
Partha


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paul at stat.auckland.ac.nz  Mon Dec 13 23:40:49 1999
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 14 Dec 1999 11:40:49 +1300
Subject: [R] Superscript or subscript on Left hand side of symbol
References: <OF0B5BC67B.1B50BC97-ON85256846.0072AAFE@hgsi.com>
Message-ID: <00d801bf45bb$1ab6ed20$175dd882@stat.auckland.ac.nz>

hi


----- Original Message -----
From: <partha_bagchi at hgsi.com>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, December 14, 1999 9:57 AM
Subject: [R] Superscript or subscript on Left hand side of symbol


> Is there a way to get subscripts and superscripts on the left hand side of
> a symbol? For example, oC or oF (degree Celsius or Fahrenheit)

try one of the following ...

text(6,3, expression({}^o*F))
text(5,3, expression(paste({}^o,F)))

paul


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From philip at sherman.psych.unimelb.edu.au  Tue Dec 14 00:45:21 1999
From: philip at sherman.psych.unimelb.edu.au (Philip L. Smith)
Date: Tue, 14 Dec 1999 10:45:21 +1100 (EST)
Subject: [R] Command History
Message-ID: <199912132345.KAA13262@sherman.psych.unimelb.edu.au>

Venables and Ripley's supplementary notes state that
Unix R provides a command history mechanism in which
previous commands can be recalled using the up and down
arrows.  My version of R (Digital Unix 4.0) doesn't
appear to support this.  Is this an installation issue
and is there a workaround?

Thanks,

Philip Smith
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ihaka at stat.auckland.ac.nz  Tue Dec 14 01:02:02 1999
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Tue, 14 Dec 1999 13:02:02 +1300
Subject: [R] Command History
In-Reply-To: <199912132345.KAA13262@sherman.psych.unimelb.edu.au>; from Philip L. Smith on Tue, Dec 14, 1999 at 10:45:21AM +1100
References: <199912132345.KAA13262@sherman.psych.unimelb.edu.au>
Message-ID: <19991214130202.B9925@stat1.stat.auckland.ac.nz>

On Tue, Dec 14, 1999 at 10:45:21AM +1100, Philip L. Smith wrote:
> Venables and Ripley's supplementary notes state that
> Unix R provides a command history mechanism in which
> previous commands can be recalled using the up and down
> arrows.  My version of R (Digital Unix 4.0) doesn't
> appear to support this.  Is this an installation issue
> and is there a workaround?

Obtain and install a recent version of the GNU readline library
and then reconfigure and make R.

Try:
ftp://mirror.aarnet.edu.au/pub/gnu/readline/readline-2.2.1.tar.gz

Ross
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Tue Dec 14 00:59:00 1999
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Mon, 13 Dec 1999 15:59:00 -0800 (PST)
Subject: [R] Command History
In-Reply-To: <199912132345.KAA13262@sherman.psych.unimelb.edu.au>
Message-ID: <Pine.GSO.4.21.9912131554120.1660-100000@gorn.biostat.washington.edu>

On Tue, 14 Dec 1999, Philip L. Smith wrote:

> Venables and Ripley's supplementary notes state that
> Unix R provides a command history mechanism in which
> previous commands can be recalled using the up and down
> arrows.  My version of R (Digital Unix 4.0) doesn't
> appear to support this.  Is this an installation issue
> and is there a workaround?

This requires the GNU readline library, which is detected at compile time
by configure.  You presumably either don't have GNU readline or have it
somewhere that configure doesn't look. One possibility is
/usr/local/{bin,include}, which isn't searched on some machines.

If you have readline but it isn't being found you will need to edit
config.site in the main R source directory to make sure that 
CPPFLAGS includes the directory containing the readline header files and
LIBS contains the directory containing the library itself.

If you don't have readline get it from ftp.gnu.org


Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Dec 14 01:05:42 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Dec 1999 01:05:42 +0100
Subject: [R] pointsize?
In-Reply-To: Bill Simpson's message of "Mon, 13 Dec 1999 17:24:12 +0000 (GMT)"
References: <Pine.LNX.4.10.9912131713330.17856-100000@localhost.localdomain>
Message-ID: <x2k8mixu7d.fsf@blueberry.kubism.ku.dk>

Bill Simpson <wsi at gcal.ac.uk> writes:

> Is there a way to get big axis labels and plot symbols using par(ps=)?
> Or was something else meant when I was told to use pointsize?

I meant the one that you set on the device driver, e.g. 

X11(pointsize=17)
x<-rnorm(100)
y<-rnorm(100)
plot(x,y)
dev.print(file="/tmp/junk.ps", horizontal=FALSE, pointsize=17)

(If it doesn't work now, it will after Wednesday...)

However, par(ps) doesn't quite work as advertized. It will change the
size of text alright, but not the symbol sizes, and it won't regulate
the margin sizes. At least the former of those is probably more bug
than feature...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Dec 14 01:09:01 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Dec 1999 01:09:01 +0100
Subject: [R] Postscript Bug?
In-Reply-To: partha_bagchi@hgsi.com's message of "Mon, 13 Dec 1999 11:24:45 -0500"
References: <OFF2C40114.04D2517C-ON85256846.00598604@hgsi.com>
Message-ID: <x2hfhmxu1u.fsf@blueberry.kubism.ku.dk>

partha_bagchi at hgsi.com writes:

> I was wondering if there is a "bug" in the postscript driver?
> Here is the problem:
> postscript(file= "temp.ps", paper= "Letter", horizontal= FALSE)
> #In the following statement, pch has no effect:
> plot(c(0:10), pch= 15)
> 
> It produces a tiny circle when it should be showing filled squares.
> However, the following works:
> par(pch= 15)
> plot(c(0:10))
> 
> dev.off()
> 
> Note: This was working just fine with R 0.65.1
> details:

Works OK in the pre0.90.1 snapshot...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From datamanagement at email.com  Mon Dec 13 19:30:40 1999
From: datamanagement at email.com (a s)
Date: Mon, 13 Dec 1999 13:30:40 -0500 (EST)
Subject: [R] Combinations
Message-ID: <385226496.945109840240.JavaMail.root@web07.pub01>

I need some help here.
>From a vector of variable length (say, c(A,B,C,D), I need to obtain all
posible combinations (order doesn't matter) of the elements.
I would like a function such as:
function(x,c(A,B,C,D))
to give a matrix (for x=3) like:
A B C
A B D
A C D
B C D

or for x=2
A B
A C
A D
B C
B D
C D

And so on.
Any ideas??

Thank you,
Alex Ahgarin
Data Management
I.R.W. Co.

-----------------------------------------------
FREE! The World's Best Email Address @email.com
Reserve your name now at http://www.email.com



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wsi at gcal.ac.uk  Tue Dec 14 11:17:13 1999
From: wsi at gcal.ac.uk (Bill Simpson)
Date: Tue, 14 Dec 1999 10:17:13 +0000 (GMT)
Subject: [R] pointsize?
In-Reply-To: <x2k8mixu7d.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.4.10.9912141016490.18435-100000@localhost.localdomain>

Thanks Peter, it works.
Bill


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec 14 12:14:04 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 14 Dec 1999 11:14:04 +0000 (GMT)
Subject: [R] Combinations
In-Reply-To: <385226496.945109840240.JavaMail.root@web07.pub01>
Message-ID: <Pine.GSO.4.05.9912141104540.2268-100000@auk.stats>

On Mon, 13 Dec 1999, a s wrote:

> I need some help here.
> >From a vector of variable length (say, c(A,B,C,D), I need to obtain all
> posible combinations (order doesn't matter) of the elements.
> I would like a function such as:
> function(x,c(A,B,C,D))
> to give a matrix (for x=3) like:
> A B C
> A B D
> A C D
> B C D
> 
> or for x=2
> A B
> A C
> A D
> B C
> B D
> C D
> 
> And so on.
> Any ideas??

There is code to do that in Venables & Ripley, called subsets. Here's
a later version (from our forthcoming `S Programming' book)

subsets <- function(n, r, s = 1:n) {
  if(mode(n) != "numeric" || length(n) != 1
     || n < 1 || (n %% 1) != 0) stop("bad value of n")
  if(mode(r) != "numeric" || length(r) != 1
     || r < 1 || (r %% 1) != 0) stop("bad value of r")
  if(!is.atomic(s) || length(s) < n)
    stop("s is either non-atomic or too short")
  fun <- function(n, r, s)
    if(r <= 0) vector(mode(s), 0) else if(r >= n) s[1:n] else
    rbind(cbind(s[1], Recall(n - 1, r - 1, s[-1])),
          Recall(n - 1, r, s[-1]))
  fun(n, r, s)
}

Use it by

subs <- function(x, string)
  subsets(length(string), x, string)


You will need quotes! Actually, this will work for any (atomic) mode of
vector. If you have long strings,

subs <- function(x, string)
{ 
  z <- subsets(length(string), x)
  zz <- string[as.vector(z)]
  dim(zz) <- dim(z)
  zz
} 

might be better.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From uli at biochem.dshs-koeln.de  Tue Dec 14 11:20:11 1999
From: uli at biochem.dshs-koeln.de (Uli Flenker; Raum 704)
Date: Tue, 14 Dec 1999 11:20:11 +0100 (CET)
Subject: [R] Problems with "help(topic,offline=T)"
In-Reply-To: <x2k8misy6j.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.LNX.3.95.991214105221.3792A-100000@pcinternet.biochem.dshs-koeln.de>

Peter,

first of all thanks for the quick reply! I followed your instructions and
redirected the dvips and latex output to a file. The main problem seems to
be that latex complains about a missing style file ("bm.sty"). I felt my
latex distribution could be out of time and first searched the server of
the german TeX users group for an adequate style. Unfortunately without
success. Is that "bm.sty" shipped with R, or rather should it be?

I searched my R-source tree (0.90.0) and only found "Rd.sty" (and "S.sty" 
in the libraries).

Fault of mine during compilation/installation?

        Uli Flenker
        Institute of Biochemistry
        German Sports University Cologne
        Carl-Diem-Weg 6

        50933 Cologne / Germany

        Phone 0049/0221/4982-493


On 13 Dec 1999, Peter Dalgaard BSA wrote:

> Works for me...
> 
> The last few lines of the help ($RHOME/bin/help) script say
> 
>     ${LATEX} "\\nonstopmode\\input{${1}}" >/dev/null 2>&1
>     ${DVIPS} ${1} 2>/dev/null
>     if test -f ${1}.ps;
>     then
>         echo "Saving help page to \`${2}.ps'"
>         mv ${1}.ps ${ODIR}/${2}.ps
>     fi
>     rm -f ${1}.aux ${1}.dvi ${1}.log
> 
> So if you're not seeing the "Saving help page to \`${2}.ps'" bit,
> chances are that ${DVIPS} sends directly to the printer, or tries to. 
> 
> The other option is that ${LATEX} or  ${DVIPS} is failing fatally, for
> some reason that you won't see because of the redirections.
> Temporarily replacing /dev/null with a real file might reveal the
> source of the mystery.
> 
> It's not a mystery that the .dvi files are cleaned up, cf the last
> line above.
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From clelancm at UMDNJ.EDU  Tue Dec 14 14:00:50 1999
From: clelancm at UMDNJ.EDU (Chuck Cleland)
Date: Tue, 14 Dec 1999 08:00:50 -0500
Subject: [R] Combinations
References: <Pine.GSO.4.05.9912141104540.2268-100000@auk.stats>
Message-ID: <38563F82.E6AE8051@umdnj.edu>

Hello:
  Why not use expand.grid() and subscript away any unwanted rows?

Chuck 

----------------------------------------------
Chuck Cleland
Institute for the Study of Child Development
UMDNJ-Robert Wood Johnson Medical School
97 Paterson Street
New Brunswick, NJ 08903
phone: (732) 235-7699
  fax: (732) 235-6189
http://www2.umdnj.edu/iscdweb/
----------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From partha_bagchi at hgsi.com  Tue Dec 14 14:05:25 1999
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue, 14 Dec 1999 08:05:25 -0500
Subject: [R] Superscript or subscript on Left hand side of symbol
Message-ID: <OF133D658B.91B6CD2F-ON85256847.0047D39C@hgsi.com>


Thanks for the answer Paul. For some reason (probably something I did) this
did not work for me before.



                                                                                                          
                    "Paul Murrell"                                                                        
                    <paul at stat.auckl        To:     <partha_bagchi at hgsi.com>, <r-help at stat.math.ethz.ch>  
                    and.ac.nz>              cc:                                                           
                                            Subject:     Re: [R] Superscript or subscript on Left hand    
                    12/14/99 06:40          side of symbol                                                
                    AM                                                                                    
                                                                                                          
                                                                                                          




hi


----- Original Message -----
From: <partha_bagchi at hgsi.com>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, December 14, 1999 9:57 AM
Subject: [R] Superscript or subscript on Left hand side of symbol


> Is there a way to get subscripts and superscripts on the left hand side
of
> a symbol? For example, oC or oF (degree Celsius or Fahrenheit)

try one of the following ...

text(6,3, expression({}^o*F))
text(5,3, expression(paste({}^o,F)))

paul





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec 14 14:11:00 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 14 Dec 1999 13:11:00 +0000 (GMT)
Subject: [R] Combinations
In-Reply-To: <38563F82.E6AE8051@umdnj.edu>
Message-ID: <Pine.GSO.4.05.9912141305120.25650-100000@auk.stats>

On Tue, 14 Dec 1999, Chuck Cleland wrote:

>   Why not use expand.grid() and subscript away any unwanted rows?

How are you going to work out which ones are unwanted, efficiently? And for
moderately sized problems you will run out of space in expand.grid, as
there are many more k-tuples than combinations. (More than k! times
as many.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From partha_bagchi at hgsi.com  Tue Dec 14 14:06:47 1999
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue, 14 Dec 1999 08:06:47 -0500
Subject: [R] Postscript Bug?
Message-ID: <OFFF09E6A6.4F464E28-ON85256847.0047EF8E@hgsi.com>


Peter, I am assuming you mean that wednesday release of 0.90.1 fixes this?
Thanks.



                                                                                                          
                    Peter Dalgaard                                                                        
                    BSA                     To:     partha_bagchi at hgsi.com                                
                    <p.dalgaard at bios        cc:     r-help at stat.math.ethz.ch                              
                    tat.ku.dk>              Subject:     Re: [R] Postscript Bug?                          
                    Sent by:                                                                              
                    pd at blueberry.kub                                                                      
                    ism.ku.dk                                                                             
                                                                                                          
                                                                                                          
                    12/13/99 07:09                                                                        
                    PM                                                                                    
                                                                                                          
                                                                                                          




partha_bagchi at hgsi.com writes:

> I was wondering if there is a "bug" in the postscript driver?
> Here is the problem:
> postscript(file= "temp.ps", paper= "Letter", horizontal= FALSE)
> #In the following statement, pch has no effect:
> plot(c(0:10), pch= 15)
>
> It produces a tiny circle when it should be showing filled squares.
> However, the following works:
> par(pch= 15)
> plot(c(0:10))
>
> dev.off()
>
> Note: This was working just fine with R 0.65.1
> details:

Works OK in the pre0.90.1 snapshot...

--
   O__  ---- Peter Dalgaard             Blegdamsvej 3
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec 14 14:20:36 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 14 Dec 1999 13:20:36 +0000 (GMT)
Subject: [R] Problems with "help(topic,offline=T)"
In-Reply-To: <Pine.LNX.3.95.991214105221.3792A-100000@pcinternet.biochem.dshs-koeln.de>
Message-ID: <Pine.GSO.4.05.9912141314170.25650-100000@auk.stats>

On Tue, 14 Dec 1999, Uli Flenker; Raum 704 wrote:

> Peter,
> 
> first of all thanks for the quick reply! I followed your instructions and
> redirected the dvips and latex output to a file. The main problem seems to
> be that latex complains about a missing style file ("bm.sty"). I felt my
> latex distribution could be out of time and first searched the server of
> the german TeX users group for an adequate style. Unfortunately without
> success. Is that "bm.sty" shipped with R, or rather should it be?

It is a standard part of latex, and has been since 1996. Try installing a
current latex: it is in the tools bundle. (It replaces amsbsy, which was
non-standard and has been deprecated for a while.)

Latex files are under a difference licence from R, which is one reason not
to distribute them.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mcw at ln.nimh.nih.gov  Tue Dec 14 15:11:32 1999
From: mcw at ln.nimh.nih.gov (Matthew Wiener)
Date: Tue, 14 Dec 1999 09:11:32 -0500 (EST)
Subject: [R] Combinations
In-Reply-To: <385226496.945109840240.JavaMail.root@web07.pub01>
Message-ID: <Pine.SGI.3.96.991214090848.24011F-100000@ln.nimh.nih.gov>

Alex:  Bill Venables sent me these functions in response to a similar
query of mine a few months ago (you can find the full reply by searching
the R archives under the heading "avoiding loops, gaining generality"):


subsets <- function(r, n, v = 1:n) 
  if(r <= 0) NULL else 
if(r >= n) v[1:n] else 
rbind(cbind(v[1], Recall(r - 1, n - 1, v[-1])),      
Recall(r, n - 1, v[-1])) 

permutations <- function(n, v = 1:n) { 
 if(n == 1) 
   return(v[1])   
 X <- NULL 
  for(i in 1:n) 
    X <- rbind(X, 
               cbind(v[i], permutations(n - 1, v[-i]))) 
  X
} 

Hope this helps.

Matt

On Mon, 13 Dec 1999, a s wrote:

> I need some help here.
> >From a vector of variable length (say, c(A,B,C,D), I need to obtain all
> posible combinations (order doesn't matter) of the elements.
> I would like a function such as:
> function(x,c(A,B,C,D))
> to give a matrix (for x=3) like:
> A B C
> A B D
> A C D
> B C D
> 
> or for x=2
> A B
> A C
> A D
> B C
> B D
> C D
> 
> And so on.
> Any ideas??
> 
> Thank you,
> Alex Ahgarin
> Data Management
> I.R.W. Co.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Dec 14 18:27:36 1999
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 14 Dec 1999 18:27:36 +0100 (MET)
Subject: [R] "formula plotting" -> substitute pecularity
Message-ID: <14422.32264.430633.742316@gargle.gargle.HOWL>

This is something between a question and a bug report.
     {sometimes one should first ask on R-help before sending to R-bugs....}

I wanted to plot (.) a formula with "..."

 ## Works :
 e0 <- expression(T(x[1],...x[n])*",  "*N[1] == 101) # works ok
 plot(1, main = e0)

## Now, need substitute, to replace with value of variableThis works

 nn <- 102
 (e1 <- substitute(T(x[1],...x[n])*",  "*N[1] == n1, list(n1=nn)))
 plot(1,main=e1)
 ## this works, but only because of a typo: I forgot one ","

## This ``should'' work, but does not :

 e2 <- substitute(T(x[1],...,x[n])*",  "*N[1] == n1, list(n1=nn))

 ##>>  Error: ... used in an incorrect context

--
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO D10	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Dec 15 00:02:27 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Dec 1999 00:02:27 +0100
Subject: [R] "formula plotting" -> substitute pecularity
In-Reply-To: Martin Maechler's message of "Tue, 14 Dec 1999 18:27:36 +0100 (MET)"
References: <14422.32264.430633.742316@gargle.gargle.HOWL>
Message-ID: <x2d7s96s8s.fsf@blueberry.kubism.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> This is something between a question and a bug report.
>      {sometimes one should first ask on R-help before sending to R-bugs....}
..
> ## This ``should'' work, but does not :
> 
>  e2 <- substitute(T(x[1],...,x[n])*",  "*N[1] == n1, list(n1=nn))
> 
>  ##>>  Error: ... used in an incorrect context

I think that is a bug. Simplest variant:

> substitute(a(...))
Error: ... used in an incorrect context

I think the basic issue is that when you use ... in a function,
substitute will try to match it against the actual parameter list,
e.g.

> f<-function(...)substitute(a(...))
> f(2)
a(2)
> f(2,3,4)
a(2, 3, 4)

However, when there's no ... argument to f, substitute will complain,
as would any other function trying to handle ... but the semantics of
substitute should be different.

Robert?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From scrog at lvcm.com  Thu Dec 16 06:53:35 1999
From: scrog at lvcm.com (Steven Scroggin)
Date: Wed, 15 Dec 1999 21:53:35 -0800
Subject: [R] Durbin-Watson
Message-ID: <006b01bf4789$e90d0720$b926ea18@lvcablemodem.com>

Does R have a function for the Durbin-Watson test?
.........................................................
Steven Scroggin
scrog at lvcm.com



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hothorn at statistik.uni-dortmund.de  Thu Dec 16 11:13:03 1999
From: hothorn at statistik.uni-dortmund.de (Torsten Hothorn)
Date: Thu, 16 Dec 1999 11:13:03 +0100 (MET)
Subject: [R] Durbin-Watson
In-Reply-To: <006b01bf4789$e90d0720$b926ea18@lvcablemodem.com>
Message-ID: <Pine.GSO.4.05.9912161112470.22157-100000@amadeus.statistik.uni-dortmund.de>



On Wed, 15 Dec 1999, Steven Scroggin wrote:

> Does R have a function for the Durbin-Watson test?
> .........................................................

package lmtest

Torsten

> Steven Scroggin
> scrog at lvcm.com
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From venkat at biosta.mskcc.org  Thu Dec 16 16:49:15 1999
From: venkat at biosta.mskcc.org (E. S. Venkatraman)
Date: Thu, 16 Dec 1999 10:49:15 -0500 (EST)
Subject: [R] Barplot in R-0.90.1
In-Reply-To: <x2wvqgbatv.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.OSF.4.05.9912161038270.22838-100000@biosta.mskcc.org>

I am running R-0.90.1 on a Pentium III - Linux (Mandrake 6.1) machine.

The barplot command insists on ignoring the yaxt parameter.  Try 

  barplot(rbind(rep(0.8,5),rep(0.9,5)),beside=T,ylim=c(0,1),yaxt="n")

If I use insteas par(yaxt="n") prior to calling barplot then the axis
command does not produce any axis.

The same problem exists in R-0.90 (I don't know about earlier versions)

Thanks,
Venkat
-----------------------------------------------------------------------
E. S. Venkatraman, Ph.D.     Phone: (212) 639-8520  Fax: (212) 717-3137
Assistant Attending Member     Memorial Sloan-Kettering Cancer Center
-----------------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From faheem at email.unc.edu  Thu Dec 16 20:41:25 1999
From: faheem at email.unc.edu (Faheem Mitha)
Date: Thu, 16 Dec 1999 14:41:25 -0500 (EST)
Subject: [R] R question
Message-ID: <Pine.LNX.4.10.9912161430460.708-100000@Chrestomanci.home.earth>

I have the following question, which is elementary but I am unable to
answer.
In a for(i=10) loop, I am trying to represent the 10 1-dimensional vectors 
l1, l2,... l10 by some expression that will run through these values.
ie. soppose I want to add l1 + ... + l10
I could go

x <- 0
for(i in 1:10){ x <- x+ l(i)} 

This should return x to be the sum of the 10 li's for i from 1 to 10
except of course I'm doing something more complicated. 
But l(i) of course does not serve to represent l1 etc? What should I do?

                                    Faheem Mitha,


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ihaka at stat.auckland.ac.nz  Thu Dec 16 19:49:17 1999
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Fri, 17 Dec 1999 07:49:17 +1300
Subject: [R] R question
In-Reply-To: <Pine.LNX.4.10.9912161430460.708-100000@Chrestomanci.home.earth>; from Faheem Mitha on Thu, Dec 16, 1999 at 02:41:25PM -0500
References: <Pine.LNX.4.10.9912161430460.708-100000@Chrestomanci.home.earth>
Message-ID: <19991217074917.A19111@stat1.stat.auckland.ac.nz>

On Thu, Dec 16, 1999 at 02:41:25PM -0500, Faheem Mitha wrote:
> I have the following question, which is elementary but I am unable to
> answer.
> In a for(i=10) loop, I am trying to represent the 10 1-dimensional vectors 
> l1, l2,... l10 by some expression that will run through these values.
> ie. soppose I want to add l1 + ... + l10
> I could go
> 
> x <- 0
> for(i in 1:10){ x <- x+ l(i)} 
> 
> This should return x to be the sum of the 10 li's for i from 1 to 10
> except of course I'm doing something more complicated. 
> But l(i) of course does not serve to represent l1 etc? What should I do?

Subsetting in S (and hence R) uses [] for subsetting.  What you need is

	x <- 0
	for(i in 1:10) x <- x + l[i]

(If the values are really in a vector, x <- sum(l) is rather faster).

	Ross
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From faheem at email.unc.edu  Thu Dec 16 21:19:21 1999
From: faheem at email.unc.edu (Faheem Mitha)
Date: Thu, 16 Dec 1999 15:19:21 -0500 (EST)
Subject: [R] R question
In-Reply-To: <19991217074917.A19111@stat1.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.10.9912161503370.708-100000@Chrestomanci.home.earth>

Dear Dr. Ihaka, Thank you for your reply. The example below was merely an
example. The reality is more complex. I have a function called h which
takes a scalar argument and returns an lm object. In the loop I was hoping
h(l[i]) would be interpreted as h of the scalar argument, but instead I
get:

Error in h(l[i]) : Object "l" not found

I will probably give up on this method for the time being, and try another
method, since I pressed for time.
 
My failed script is below in case anybody is willing to take a look.
                                       Sincerely, Faheem Mitha.

*************************************************************************************
#I'm regressing the variable sal against some other variables (sallag,fresh,per,yr) 
#This script is to use the method of constructed variables to get a 
#transformation h from a family indexed by a parameter lambda such that 
#the model h(sal) ~ other variables maximises the likelihood over all such 
#h.

salinity <-read.table('salinity1.d')
attach(salinity)

# sal, fresh, per, yr all vectors of same length

yr <- yr - 1971

#saldot geometric mean of elements of sal vector

saldot<- exp((1/length(sal))*log(prod(sal)))

w0 <- saldot*log(sal)*( 0.5*log(sal) - log(saldot) )
h0 <- saldot*log(sal)
  
trans0<-lm(h0 ~ w0+sallag+fresh+per+yr)

summary(trans0)
dffits(trans0)
dfbetas(trans0)

l1 <- - coef(trans0)[2]

#Define functions h and w for recursion (both functions of lambda)

h <- function(l)
  {
    x <- (sal^l - 1)/( l*(saldot)^(l-1) )

    x
  }
    
w <- function(l)
  {
    x <- ( (sal^l)*log(sal) - (sal^l - 1)*( (1/l) + log(saldot) ))/
          ( l*(saldot)^(l-1) )

    x
  }

# Here is the for loop

for(i in 1:8){trans[i]<-lm( h(l[i]) ~ w(l[i])+sallag+fresh+per+yr)

l[i+1] <-  l[i] - coef(trans[i])[2]}


#Trying to make the for loop equivalent to the set of statements below

trans1<-lm( h(l1) ~ w(l1)+sallag+fresh+per+yr)

l2 <-  l1 - coef(trans1)[2]

trans2<-lm( h(l2) ~ w(l2)+sallag+fresh+per+yr)

l3 <- l2 - coef(trans2)[2]

trans3<-lm( h(l3) ~ w(l3)+sallag+fresh+per+yr)

l4 <- l3 - coef(trans3)[2]

trans4<-lm( h(l4) ~ w(l4)+sallag+fresh+per+yr)

l5 <- l4 - coef(trans4)[2]

trans5<-lm( h(l5) ~ w(l5)+sallag+fresh+per+yr)

l6 <- l5 - coef(trans5)[2]

trans6<-lm( h(l6) ~ w(l6)+sallag+fresh+per+yr)

l7 <- l6 - coef(trans6)[2]

trans7<-lm( h(l7) ~ w(l7)+sallag+fresh+per+yr)

l8 <- l7 - coef(trans7)[2]

#Now try usual regression with h_{\lambda}(y) for \lambda = l8

trans <- lm(h(l[10]) ~ sallag+fresh+per+yr)

*************************************************************************************

On Fri, 17 Dec 1999, Ross Ihaka wrote:

> On Thu, Dec 16, 1999 at 02:41:25PM -0500, Faheem Mitha wrote:
> > I have the following question, which is elementary but I am unable to
> > answer.
> > In a for(i=10) loop, I am trying to represent the 10 1-dimensional vectors 
> > l1, l2,... l10 by some expression that will run through these values.
> > ie. soppose I want to add l1 + ... + l10
> > I could go
> > 
> > x <- 0
> > for(i in 1:10){ x <- x+ l(i)} 
> > 
> > This should return x to be the sum of the 10 li's for i from 1 to 10
> > except of course I'm doing something more complicated. 
> > But l(i) of course does not serve to represent l1 etc? What should I do?
> 
> Subsetting in S (and hence R) uses [] for subsetting.  What you need is
> 
> 	x <- 0
> 	for(i in 1:10) x <- x + l[i]
> 
> (If the values are really in a vector, x <- sum(l) is rather faster).
> 
> 	Ross
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From millsje at mscs.dal.ca  Thu Dec 16 20:46:15 1999
From: millsje at mscs.dal.ca (Joanna Mills)
Date: Thu, 16 Dec 1999 15:46:15 -0400 (AST)
Subject: [R] nlm in R version 0.90
Message-ID: <Pine.GSO.3.96.991216153944.15112A-100000@chase>

I am trying to obtain some more detail regarding the nlm function
available in the latest release of R. Specifically, what mimimization
routine is being used... and ... does there exist a fortran or C version
of it?
Thank you,
Joanna

Joanna Elizabeth MILLS, M.Sc.               Ph:  (902) 494-3747
Dalhousie University                        Fax: (902) 494-5130
Department of Mathematics and Statistics    Res: (902) 443-0230
Halifax, N.S. Canada B3H 3J5                millsje at mscs.dal.ca

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Thu Dec 16 21:13:21 1999
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 Dec 1999 14:13:21 -0600
Subject: [R] nlm in R version 0.90
In-Reply-To: Joanna Mills's message of "Thu, 16 Dec 1999 15:46:15 -0400 (AST)"
References: <Pine.GSO.3.96.991216153944.15112A-100000@chase>
Message-ID: <6rzovazlsu.fsf@franz.stat.wisc.edu>

Joanna Mills <millsje at mscs.dal.ca> writes:

> I am trying to obtain some more detail regarding the nlm function
> available in the latest release of R. Specifically, what mimimization
> routine is being used... and ... does there exist a fortran or C version
> of it?

The short answer is that the code is based on that in Dennis and
Schnabel's book on unconstrained optimization and coded in Fortran.

R is an open-source software product so you can always read the code
to see what optimization algorithm is being used.  If you are working
on a Unix/Linux system, obtain the file src/base/R-0.90.1.tgz from one
of the CRAN archives (http://cran.us.r-project.org/ will probably give
the fastest response from your location) and expand it.  The file is in
gzip compressed tar format.  The Fortran sources for the compiled code
called by nlm are in src/appl/uncmin.f.  A "wrapper" function coded in
C is given in src/main/optimize.c
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.malewski at tu-bs.de  Thu Dec 16 21:19:57 1999
From: p.malewski at tu-bs.de (Peter Malewski)
Date: Thu, 16 Dec 1999 21:19:57 +0100
Subject: [R] R question
References: <Pine.LNX.4.10.9912161430460.708-100000@Chrestomanci.home.earth>
Message-ID: <3859496D.829AFFA3@tu-bs.de>

Dear Faheem
Faheem Mitha wrote:

> I have the following question, which is elementary but I am unable to
> answer.
> In a for(i=10) loop, I am trying to represent the 10 1-dimensional vectors
> l1, l2,... l10 by some expression that will run through these values.
> ie. soppose I want to add l1 + ... + l10
> I could go
>
> x <- 0
> for(i in 1:10){ x <- x+ l(i)}

"()" indictes that a function is called.  You can use a expression like
(get(paste( ... ))

> Vec1 <- 1:10
> Vec1 <- 1:10
> Vec2 <- 1:10
> Vec3 <- 1:10
>  x <- 2
> for(i in 1:3) print(x + get(paste("Vec",i,sep="")))
 [1]  3  4  5  6  7  8  9 10 11 12
 [1]  3  4  5  6  7  8  9 10 11 12
 [1]  3  4  5  6  7  8  9 10 11 12


A better way might be a Data.frame / matrix representation:


> xx <- data.frame(Vec1,Vec2,Vec3)
> xx+x
   Vec1 Vec2 Vec3
1     3    3    3
2     4    4    4
3     5    5    5
4     6    6    6
5     7    7    7
6     8    8    8
7     9    9    9
8    10   10   10
9    11   11   11
10   12   12   12



> This should return x to be the sum of the 10 li's for i from 1 to 10
> except of course I'm doing something more complicated.
> But l(i) of course does not serve to represent l1 etc? What should I do?

??? Perhaps this includes a useful idea:

> x + apply(xx , 2 , sum)
Vec1 Vec2 Vec3
  57   57   57

or:

> apply(xx , 2 , function( yy )x + sum(yy))
Vec1 Vec2 Vec3
  57   57   57


Hope this answer will help a bit
Peter


>
>
>                                     Faheem Mitha,
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

--
** To YOU I'm an atheist; to God, I'm the Loyal Opposition. Woody Allen **
P.Malewski                                      Tel.: 0531 500965
Maschplatz 8                                    Email: P.Malewski at tu-bs.de
************************38114 Braunschweig********************************



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From William.Venables at cmis.CSIRO.AU  Fri Dec 17 01:32:05 1999
From: William.Venables at cmis.CSIRO.AU (Bill Venables)
Date: Fri, 17 Dec 1999 10:32:05 +1000
Subject: [R] R question 
Message-ID: <199912170035.LAA03679@snowy.nsw.cmis.CSIRO.AU>

> Dear Dr. Ihaka, Thank you for your reply. The example below was merely an
> example. The reality is more complex. I have a function called h which
> takes a scalar argument and returns an lm object. In the loop I was hoping
> h(l[i]) would be interpreted as h of the scalar argument, but instead I
> get:
> 
> Error in h(l[i]) : Object "l" not found
> 
> I will probably give up on this method for the time being, and try another
> method, since I pressed for time.
>  
> My failed script is below in case anybody is willing to take a look.
>                                        Sincerely, Faheem Mitha.
> 

Normally I bite my tongue and keep going when I see questions
like these but this time let me make a general observation and
offer some downright paternalistic advice (as befits someone like
me - if you have ever seen me you will know I look very much like
Father Christmas...)

SAS, SPSS and other similar systems provide easy ways of handling
sequences of objects with patterned names like L1, L2, ...  The S
languages (like R) do not: they provide ways but they are not
elementary.  This is because the S languages encourage you to
approach the problem in a different way: rather than use a
sequence of objects with structured names, but all the objects
together in a list structure and use the index: so for L2 you use
L[2], but with luck you won't have to single it out yourself at all.

There are good reasons for this.  The S languages discourage
explicit loops and provide features like vectorization and
operators like the lapply()-family that do iterative computations
more efficiently.  In the S languages you are always encouraged
to take the "whole object view", to quote John Chambers, to deal
with the structure as a whole and not to take an iterative view.

I'm willing to bet that most of these questions come from people
who are (usually unwilling) refugees from another system like SAS
or SPSS trying to make an S language system work in a way to
which they have become accustomed.  (The non-working script that
accompanied this note was a very clear example of this philosophy
in action.)  Changing ways of thinking about a problem is always
unappealing and often difficult.  I have no words of comfort, I
regret to say: the only viable option is to learn how to use the
new system properly and to forget the old.  I had to do it with glim, genstat and matlab so I know it can be done.  The only consolation
I can offer is that when you do overcome the initial hurdle life
becomes so much simpler and the feeling you get when you find the
system is working for you at last (and not the other way round)
is an incredible high point!

All the best for the season,
Bill Venables.
-- 
-----------------------------------------------------------------
Bill Venables, Statistician, CMIS Environmetrics Project.

Physical address:                            Postal address:
CSIRO Marine Laboratories,                   PO Box 120,       
233 Middle St, Cleveland, Queensland         Cleveland, Qld, 4163
AUSTRALIA                                    AUSTRALIA

Telephone: +61 7 3826 7251     Email: Bill.Venables at cmis.csiro.au     
      Fax: +61 7 3826 7304


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From j.logsdon at lancaster.ac.uk  Fri Dec 17 10:52:58 1999
From: j.logsdon at lancaster.ac.uk (John Logsdon)
Date: Fri, 17 Dec 1999 09:52:58 +0000 (GMT)
Subject: [R] R question 
In-Reply-To: <199912170035.LAA03679@snowy.nsw.cmis.CSIRO.AU>
Message-ID: <Pine.LNX.4.10.9912170941110.28524-100000@mercury.quantex>

Faheem and others

As another but much more lowly refugee from glim, genstat and octave
(although I still use these from time to time) I can only endorse what
Bill Venables has to say.  Even now, I find myself thinking in glim terms
(particularly when it comes to the - I think superior - indexing in glim,
and I do miss the elegance of glim's glm execution but these are
weaknesses of the S definition, not R) and it costs me time.  

You have to think in terms of structures and tools like the apply() family
to do things. Then they do work out.  Good software like R always promotes
education and thinking about the problem at hand rather than getting into
for-loops and bottom up constructions.

There is one point in your scripts that I want to warn you about - the use
of single characters such as t() or c() as functions.  I think l() gets
away with it but you will end up confusing  the issue.  In particular, you
can get an apparently meanlingless message.

Not that I always follow my own advice of course!!!

John

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From scrog at lvcm.com  Fri Dec 17 15:34:54 1999
From: scrog at lvcm.com (Steven Scroggin)
Date: Fri, 17 Dec 1999 06:34:54 -0800
Subject: [R] Fw: Durbin-Watson
Message-ID: <004701bf489b$e697c4e0$b926ea18@lvcablemodem.com>


> Does R have a function for the Durbin-Watson test?
> .........................................................
Is there a version of package lmtest for Win 9x?

> Steven Scroggin
> scrog at lvcm.com
> 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Fri Dec 17 15:33:02 1999
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Fri, 17 Dec 1999 15:33:02 +0100
Subject: [R] ... and parameter checking
Message-ID: <000901bf489b$a02519e0$a9021aac@joelschlaegel>



Hi,

when writing a wrapper function, I would like to be able to pass additional
arguments to more than one function inside, e.g.

  density.panel <- function(x, na.rm=TRUE, ...){
     usr <- par("usr")
     on.exit(par(usr))
     par(usr = c(usr[1:2], 0, 1) )
     lines( density(x, na.rm=na.rm, ...), ... )
  }

and then call it like

  density.panel(x, col="red",  kernel="rectangular")


However, doing so generates an error from density (col=), which does not
allow ... and a warnings from plot.default(), which does not know about
kernel= .

Obviously I could patch density() to have a ... parameter and ignore
warnings from plot(), but, well ...

Can someone teach me how to solve this properly?

I cannot remember to have had such problems with S+, is this a difference
between R and S+ ?

Regards


--
Dr. Jens Oehlschl?gel-Akiyoshi
MD FACTORY GmbH
Bayerstrasse 21

80335 M?nchen

Tel.: 089 545 28-27
Fax.: 089 545 28-10
http://www.mdfactory.de

Standard Disclaimers: Opinions expressed here are personal
and are not otherwise represented.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cyg at sympatico.ca  Fri Dec 17 16:45:30 1999
From: cyg at sympatico.ca (Yves Gauvreau)
Date: Fri, 17 Dec 1999 10:45:30 -0500
Subject: [R] Re: R 0.90.1 for Windows
References: <19991217104711.64662@hal.stat.unipd.it>
Message-ID: <030201bf48a5$bfb001d0$6828acce@bellglobal.com>

Hi,

Is it possible to zip all R files for Windows in a single package?

Thanks.

Yves

----- Original Message -----
From: Guido Masarotto <guido at hal.stat.unipd.it>
To: <r-announce at stat.math.ethz.ch>
Sent: Friday, December 17, 1999 4:47 AM
Subject: R 0.90.1 for Windows


>
> A binary distribution  of R 0.90.1 is available at
>
>       http://www.r-project.org/bin/windows/windows-NT/base/
>
> Installation instruction are given in the README file at the same
> location.
>
> guido masarotto
>
>
>
> Windows changes since 0.90.0
> ----------------------------
> It is possible to install packages from any directory (set PKGDIR on
> the make command) and to any directory (set RLIB on the make command).
>
> RLIBS is no longer accepted for the library directory: use R_LIBS
> (which has been preferred since 0.65.0).
>
> The code to set the `cra' parameter for a windows() device (and hence
> the base character size of symbols) is more robust.
>
> The code handling Ctrl-like keys has been changed and ought to be more
> robust (AltGr on Danish Windows NT used to misbehave.)
>
> savePlot recognises filename="clipboard" (or "") for wmf plots.
>
> The installer has always been version-specific and now tests it is
> being used for the right version.
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-announce mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:
r-announce-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec 17 16:57:12 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 17 Dec 1999 15:57:12 +0000 (GMT)
Subject: [R] Fw: Durbin-Watson
In-Reply-To: <004701bf489b$e697c4e0$b926ea18@lvcablemodem.com>
Message-ID: <Pine.GSO.4.05.9912171553030.18224-100000@auk.stats>

On Fri, 17 Dec 1999, Steven Scroggin wrote:

> 
> > Does R have a function for the Durbin-Watson test?
> > .........................................................
> Is there a version of package lmtest for Win 9x?

There are no `versions of packages' for Win 9x! There are some pre-compiled
distributions, but lmtest contains no code to compile.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Dec 17 17:12:52 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 17 Dec 1999 16:12:52 +0000 (GMT)
Subject: [R] Re: R 0.90.1 for Windows
In-Reply-To: <030201bf48a5$bfb001d0$6828acce@bellglobal.com>
Message-ID: <Pine.GSO.4.05.9912171607200.18224-100000@auk.stats>

On Fri, 17 Dec 1999, Yves Gauvreau wrote:

> Is it possible to zip all R files for Windows in a single package?

Yes, it is possible.  However, when we asked, people specifically requested
that we parcel it into pieces smaller than one floppy disc.  A month or so
ago I asked if people were interested in a `mega-bundle' with many of the
contibuted packages included, and I received no positive replies.

What is the problem with the present form?  I downloaded it this morning by
about 20 mouse clicks, and you could make a decent ftp client (e.g. ncftp)
grab the whole directory in a single command.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgilbert at bank-banque-canada.ca  Fri Dec 17 17:20:04 1999
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 17 Dec 1999 11:20:04 -0500
Subject: [R] ... and parameter checking
References: <000901bf489b$a02519e0$a9021aac@joelschlaegel>
Message-ID: <385A62B4.1EF9C0D7@bank-banque-canada.ca>

>when writing a wrapper function, I would like to be able to pass additional
>arguments to more than one function inside, e.g.

The only way I know how to do this is something like

  density.panel <- function(x, na.rm=TRUE, density.args=NULL, ...){
     usr <- par("usr")
     on.exit(par(usr))
     par(usr = c(usr[1:2], 0, 1) )
     arglist <- append(list(x, na.rm=na.rm, ), density.args)
     lines( do.call("density", arglist),  ... )
  }

and then call it like

  density.panel(x, col="red",  density.args=list(kernel="rectangular"))

Please note, I haven't tested this example so there may be small errors, but
this approach works generally. If someone know a more elegant approach I would
like to hear about it.

Paul Gilbert


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mcw at ln.nimh.nih.gov  Sat Dec 18 21:32:30 1999
From: mcw at ln.nimh.nih.gov (Matthew Wiener)
Date: Sat, 18 Dec 1999 15:32:30 -0500 (EST)
Subject: [R] compiling on alpha/linux
In-Reply-To: <Pine.GSO.4.05.9912072300510.15224-100000@auk.stats>
Message-ID: <Pine.SGI.3.96.991218152624.15041D-100000@ln.nimh.nih.gov>

Thanks to Brian Ripley, Douglas Bates, and Peter Dalgaard, who all pointed
me towards the assembler (or compiler/assembler conflicts) as the likely
culprit in my earlier "opcode"  errors (most of original question below). 

After a lot of looking around, we found out that the particular alpha
system we bought (from Microway) doesn't like the gnu compilers; it
prefers Compaq's c and fortran compilers.  Once we installed those, we
compiled without difficulty.  So be careful to get details on the
capabilities and software requirements of any alpha system you're looking
into buying.  (I suppose this should be obvious, but perhaps I can save
somebody else learning the hard way ...)

Matt Wiener

-------------------------------------------------------------------------

On Tue, 7 Dec 1999, Matthew Wiener wrote:
> 
> > Hi, all.
> > 
> > In trying to compile R v.0.90 on an alpha running Red Hat Linux 6.0, I'm
> > getting the following error: 
> > 
> > make[3]: Entering directory `/home/mcw/alpha-R/R-0.90.0/src/appl' 
> > gcc -I. -I../include -I../../src/include -DHAVE_CONFIG_H -mieee -g -O2 -c cpoly.c
> > -o cpoly.o 
> > /tmp/ccPjZNwd.s: Assembler messages: 
> > /tmp/ccPjZNwd.s:312: Error: unknown opcode `sqrttsu' 
> > /tmp/ccPjZNwd.s:2631: Error: unknown opcode `sqrttsu'
> > /tmp/ccPjZNwd.s:4028: Error: unknown opcode `sqrttsu'
> > /tmp/ccPjZNwd.s:4132: Error: unknown opcode `sqrttsu'
> > /tmp/ccPjZNwd.s:4141: Error: unknown opcode `sqrttsu'
> > /tmp/ccPjZNwd.s:4470: Error: unknown opcode `sqrttsu'
> > /tmp/ccPjZNwd.s:4492: Error: unknown opcode `sqrttsu'
> > /tmp/ccPjZNwd.s:4516: Error: unknown opcode `sqrttsu' make[3]: ***
> > [cpoly.o] Error 1
> > 
> > Installing package `ctest' ... 
> > libs 
> > g77 -mieee -fPIC -O2 -c alnorm.f -o alnorm.o 
> > gcc -I/usr/lib/R/include -DHAVE_CONFIG_H -mieee -fPIC -O2 -c ansari.c -o
> > ansari.o 
> > gcc -I/usr/lib/R/include -DHAVE_CONFIG_H -mieee -fPIC -O2 -c
> > fexact.c -o fexact.o 
> > gcc -I/usr/lib/R/include -DHAVE_CONFIG_H -mieee -fPIC
> > -O2 -c kendall.c -o kendall.o 
> > /tmp/ccYUoygd.s: Assembler messages:
> > /tmp/ccYUoygd.s:123: Error: unknown opcode `sqrttsu' 
> > /tmp/ccYUoygd.s:132: Error: unknown opcode `sqrttsu' 
> > 
> > make: *** [kendall.o] Error 1
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rbb at nebiometrics.com  Sun Dec 19 05:33:57 1999
From: rbb at nebiometrics.com (Robert Burrows)
Date: Sat, 18 Dec 1999 23:33:57 -0500 (EST)
Subject: [R] preparing *.Rd files
Message-ID: <Pine.LNX.4.20.9912182331460.15516-100000@NEB.nebiometrics.com>


How do you prepare a *.Rd documentation file? What is that format?

TIA,

Robert Burrows
rbb at nebiometrics.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Dec 19 09:28:24 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sun, 19 Dec 1999 08:28:24 +0000 (GMT)
Subject: [R] preparing *.Rd files
In-Reply-To: <Pine.LNX.4.20.9912182331460.15516-100000@NEB.nebiometrics.com>
Message-ID: <Pine.GSO.4.05.9912190826570.15113-100000@auk.stats>

On Sat, 18 Dec 1999, Robert Burrows wrote:

> 
> How do you prepare a *.Rd documentation file? What is that format?

See the Writing R Extensions guide in the doc/manual directory of 0.90.1,
or latex Manual.tex in earlier versions (which is less comprehensive).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From starab at nus.edu.sg  Mon Dec 20 05:47:34 1999
From: starab at nus.edu.sg (Rich Budrevich)
Date: Mon, 20 Dec 1999 12:47:34 +0800 (SGT)
Subject: [R] digital unix linking problem
Message-ID: <Pine.GSO.4.20.9912201243070.2382-100000@tu.statistics.nus.edu.sg>

Greetings.

I'm trying to install R-0.90.1 on our digital 4.0F servers (alphaev6 arch).
Using either the digital cc and f77, or gcc 2.95.2 and g77, R compiles,
but on trying to execute it I get:

11819:./bin/R.X11: /sbin/loader: Fatal Error: cannot map xxxxxxx

I'm used to 'cannot map', but always with a shared library name,
not 'xxxxxxx'. Has anyone else run into this problem?

BTW, here are the results using -trace:

11247:./bin/R.X11: /sbin/loader: Entering RLD through MAIN
11247:./bin/R.X11: /sbin/loader: mapped Main at 0x120000000
11247:./bin/R.X11: /sbin/loader: mapped /usr/shlib/libSM.so at 0x3ff80890000
11247:./bin/R.X11: /sbin/loader: mapped /usr/shlib/libICE.so at 0x3ff808b0000
11247:./bin/R.X11: /sbin/loader: mapped /usr/shlib/libX11.so at 0x3ff80420000
11247:./bin/R.X11: /sbin/loader: mapped /usr/shlib/libdnet_stub.so at 0x3ff80540000
11247:./bin/R.X11: /sbin/loader: Fatal Error: cannot map xxxxxxx

		Thanks for any help,
		Rich Bud <starab at nus.edu.sg>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jonathan.Yuen at evp.slu.se  Mon Dec 20 09:33:52 1999
From: Jonathan.Yuen at evp.slu.se (Jonathan.Yuen@evp.slu.se)
Date: Mon, 20 Dec 1999 09:33:52 +0100 (MET)
Subject: [R] digital unix linking problem
In-Reply-To: <Pine.GSO.4.20.9912201243070.2382-100000@tu.statistics.nus.edu.sg>
Message-ID: <Pine.A41.4.05.9912200932560.28382-100000@kilauea.evp.slu.se>

Hello,

I haven't compiled on my alpha (4.0C) for a while but I've had success
with digital's cc and f2c.

Jonathan 

Jonathan Yuen, Professor in Plant Pathology     phone: 46 18 672369
Dept. of Ecology and Crop Production Sciences   fax:   46 18 672890
Swedish University of Agricultural Sciences     http://www.tvs.slu.se
Box 7043                                        email replies to
S 750 07 Uppsala, SWEDEN                        Jonathan.Yuen at evp.slu.se 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jonathan.Yuen at evp.slu.se  Mon Dec 20 12:07:36 1999
From: Jonathan.Yuen at evp.slu.se (Jonathan.Yuen@evp.slu.se)
Date: Mon, 20 Dec 1999 12:07:36 +0100 (MET)
Subject: [R] f2c and OSF
Message-ID: <Pine.A41.4.05.9912201205400.29586-100000@kilauea.evp.slu.se>

Hello,

I take it all back.  I just tried to comple 0.90.1 on my alpha (with f2c)
and it didn't work.  I'll look into it when I find time (I STILL usually
run on my libretto and linux, even through my RS6000 workstation).

Jonathan

Jonathan Yuen, Professor in Plant Pathology     phone: 46 18 672369
Dept. of Ecology and Crop Production Sciences   fax:   46 18 672890
Swedish University of Agricultural Sciences     http://www.tvs.slu.se
Box 7043                                        email replies to
S 750 07 Uppsala, SWEDEN                        Jonathan.Yuen at evp.slu.se 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From albrecht.gebhardt at uni-klu.ac.at  Mon Dec 20 16:43:23 1999
From: albrecht.gebhardt at uni-klu.ac.at (Albrecht Gebhardt)
Date: Mon, 20 Dec 1999 16:43:23 +0100 (MET)
Subject: [R] digital unix linking problem
In-Reply-To: <Pine.GSO.4.20.9912201243070.2382-100000@tu.statistics.nus.edu.sg>
Message-ID: <Pine.OSF.4.10.9912201618020.29578-100000@zidsrv.sci.uni-klu.ac.at>

On Mon, 20 Dec 1999, Rich Budrevich wrote:

> Greetings.
> 
> I'm trying to install R-0.90.1 on our digital 4.0F servers (alphaev6 arch).
> Using either the digital cc and f77, or gcc 2.95.2 and g77, R compiles,
> but on trying to execute it I get:
> 
> 11819:./bin/R.X11: /sbin/loader: Fatal Error: cannot map xxxxxxx

What says "odump -Dl your_R_install_path/bin/R.X11" ?

> 
> I'm used to 'cannot map', but always with a shared library name,
> not 'xxxxxxx'. Has anyone else run into this problem?
> 

I compiled 0.90.1 with DEC cc (DEC C V5.6-075 on Digital UNIX V4.0
(Rev. 878)) and DEC f77 (DIGITAL Fortran 77 V5.0-138-3678F) without
problems (alpha EV5, 4.0E). 

You may try my binary packages at

  http://www.r-project.org/bin/osf/osf4.0/setld-kit/alpha_ev5

Get rgs901.tar, untar it (creates temporary subdir rgs901), install with
"setld -l rgs901/kit". More details (e.g. how to remove the setld kit) at
  http://www.r-project.org/bin/osf/osf4.0/README

rgs901.tar should be there tomorrow, or get it from
  ftp://ftp-stat.uni-klu.ac.at/pub/R/bin/osf/osf4.0/setld-kit/alpha_ev5/

Up-to-date EV6 binaries are currently only available as RPMs, which would
not help you too much unless you install rpm, and many other needed
packages.


Albrecht
......................................................................
| Albrecht Gebhardt          Tel.: (++43 463) 2700/832               |
| Institut fuer Mathematik   Fax : (++43 463) 2700/834               |
| Universitaet Klagenfurt    mailto:albrecht.gebhardt at uni-klu.ac.at  |
| Villacher Str. 161         http://www-stat.uni-klu.ac.at/~agebhard |
| A-9020 Klagenfurt, Austria                                         |
`--------------------------------------------------------------------'

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Mon Dec 20 21:08:05 1999
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Mon, 20 Dec 1999 21:08:05 +0100
Subject: [R] BUG?
Message-ID: <001601bf4b25$eda48ac0$a9021aac@joelschlaegel>



Hi,

under RW0.651 and RW0.091
I found

> x <- data.frame(char=I(letters[1:3]), num=1:3, log=c(TRUE, FALSE, NA),
fak=factor(letters[24:26]))
> x
  char num   log fak
1    a   1  TRUE   x
2    b   2 FALSE   y
3    c   3    NA   z
>
> x[1,1] <- 'a'
> x[1,1]
[1] "1"
>
> x$char[1] <- 'a'
> x$char[1]
[1] "a"
>
> x[1,"char"] <- 'a'
> x[1,"char"]
[1] "1"


I have no time to go after this tonight, but it looks liks bug, doesn't it?
Regards


--
Dr. Jens Oehlschl?gel-Akiyoshi
MD FACTORY GmbH
Bayerstrasse 21

80335 M?nchen

Tel.: 089 545 28-27
Fax.: 089 545 28-10
http://www.mdfactory.de

Standard Disclaimers: Opinions expressed here are personal
and are not otherwise represented.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zha at merlin.engr.ucf.edu  Mon Dec 20 21:23:52 1999
From: zha at merlin.engr.ucf.edu (Tony Q. Zhang)
Date: Mon, 20 Dec 1999 15:23:52 -0500
Subject: [R] nonlinear least square optimization
Message-ID: <385E9058.E7136B42@merlin.engr.ucf.edu>

Hi,

   I've been using "nlregb" routine in splus3.4, but cannot find it here
in R. Is it hidden in some library?
Or there is a routine equivalent to it but with a different name? I'm
planning to move part of my from S to R so that I can work comfortablely
at home.  Any suggestion is highly appreciated.

regards,
Tony
--

\|||/

Q o o Q
==========================oooQ= ( - )====Qooo========================

"""
Tony Q. Zhang
Micro-electronics Lab. rm422
Electrical and Computer Engineering
University of Central Florida
Orlando, FL 32816
Office: (407)823-5376
Home: (407)273-3502
****************************************************************************

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Mon Dec 20 21:47:24 1999
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Mon, 20 Dec 1999 20:47:24 +0000 (GMT)
Subject: [R] BUG?
In-Reply-To: <001601bf4b25$eda48ac0$a9021aac@joelschlaegel>
Message-ID: <Pine.LNX.4.10.9912202045580.4095-100000@gimel.biostat.washington.edu>

On Mon, 20 Dec 1999, [iso-8859-1] Jens Oehlschlgel-Akiyoshi wrote:

> 
> 
> Hi,
> 
> under RW0.651 and RW0.091
> I found
> 
> > x <- data.frame(char=I(letters[1:3]), num=1:3, log=c(TRUE, FALSE, NA),
> fak=factor(letters[24:26]))
> > x
>   char num   log fak
> 1    a   1  TRUE   x
> 2    b   2 FALSE   y
> 3    c   3    NA   z
> >
> > x[1,1] <- 'a'
> > x[1,1]
> [1] "1"

> 
> I have no time to go after this tonight, but it looks liks bug, doesn't it?


Yes, it's been reported already, but it's a bit tricky to fix.

	-thomas

Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec 20 22:37:00 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 20 Dec 1999 21:37:00 +0000 (GMT)
Subject: [R] nonlinear least square optimization
In-Reply-To: <385E9058.E7136B42@merlin.engr.ucf.edu>
Message-ID: <Pine.GSO.4.05.9912202133210.2242-100000@auk.stats>

On Mon, 20 Dec 1999, Tony Q. Zhang wrote:

> Hi,
> 
>    I've been using "nlregb" routine in splus3.4, but cannot find it here
> in R. Is it hidden in some library?

No. It is proprietary part of S-PLUS (not S). 

> Or there is a routine equivalent to it but with a different name? I'm
> planning to move part of my from S to R so that I can work comfortablely
> at home.  Any suggestion is highly appreciated.

At present your only choice is the general optimizer nlm. However,
general-purpose optimization routines often are as good as specialized
nls routines unless the solution is a near-perfect fit. (R's nls
uses nlm.)

We are working on other options (I have prototypes running) so you may see
more in a month or so.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From starab at nus.edu.sg  Tue Dec 21 00:57:09 1999
From: starab at nus.edu.sg (Rich Budrevich)
Date: Tue, 21 Dec 1999 07:57:09 +0800
Subject: [R] digital unix linking problem
References: <Pine.OSF.4.10.9912201618020.29578-100000@zidsrv.sci.uni-klu.ac.at>
Message-ID: <001d01bf4b45$ed9d9f60$b8218489@stat.nus.edu.sg>

> > 11819:./bin/R.X11: /sbin/loader: Fatal Error: cannot map xxxxxxx
> What says "odump -Dl your_R_install_path/bin/R.X11" ?

Provided below. Hope it sheds some light. I can tell you that Nov 22 is when
I installed the rest of the fortran libraries, so it's definitely a fortran
issue, but
I don't know any more than that...

                            Rich

                        ***LIBRARY LIST SECTION***
        Name             Time-Stamp        CheckSum   Flags Version
./bin/R.X11:
        libSM.so     Apr  2 14:55:43 1999 0xb64c7082     0
        libICE.so    Apr  2 14:55:34 1999 0x1199be32     0
        libX11.so    Apr  2 14:46:46 1999 0xf86afbad     0
        libdnet_stub.so Apr 13 00:18:15 1999 0x9408a36b     0 osf.1
        xxxxxxx      Nov 22 14:27:47 1999 0x3b8a2af6     0
        libUfor.so   Nov 17 08:38:01 1998 0xc6e6aa05     0
        libfor.so    Nov 17 08:37:59 1998 0x1d987a12     0
        libFutil.so  Nov 17 08:37:58 1998 0x896dea97     0
        libm.so      Apr 13 00:27:39 1999 0xf29b0962     0 osf.1
        libots.so    Apr 13 00:16:38 1999 0x0876eb23     0
        libz.so.1.1.3 Nov 10 13:44:35 1999 0x91c64bf3     0
        libc.so      Apr 13 00:14:03 1999 0x59eef91c     0 osf.1


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From spoon at hilbert.maths.utas.edu.au  Tue Dec 21 09:30:40 1999
From: spoon at hilbert.maths.utas.edu.au (spoon)
Date: Tue, 21 Dec 1999 19:30:40 +1100 (EST)
Subject: [R] GLM query
Message-ID: <199912210830.TAA21485@hilbert.maths.utas.edu.au>

A non-text attachment was scrubbed...
Name: not available
Type: text
Size: 3328 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/19991221/6ee2b13a/attachment.pl

From ripley at stats.ox.ac.uk  Tue Dec 21 10:43:08 1999
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Dec 1999 09:43:08 +0000 (GMT)
Subject: [R] GLM query
Message-ID: <199912210943.JAA20948@toucan.stats.ox.ac.uk>

> From: spoon <spoon at hilbert.maths.utas.edu.au>
> Date: Tue, 21 Dec 1999 19:30:40 +1100 (EST)
> 

[...]
AIC: -70.016
 
> But I get a very different AIC to Lindsey (he gets 254.3).  I've
> played around a bit and have no idea how to get his solution.  Any
> clues?

Here's my guess.  Your AIC is based on a log-likelihood regarding log(GDP)
as the data, and his is regarding GDP as the data. The transformation
of the density adds a term to the log-likelihood which is the same for each 
model.

Test:

> 2*sum(log(gdp$GDP))
[1] 324.4009

seems close enough to the difference, although I would have expected it
to be closer.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Robert.King at mailbox.gu.edu.au  Tue Dec 21 11:02:06 1999
From: Robert.King at mailbox.gu.edu.au (Robert.King@mailbox.gu.edu.au)
Date: Tue, 21 Dec 1999 20:02:06 +1000 (EST)
Subject: [R] HTML archives will be down
Message-ID: <Pine.LNX.4.10.9912211956110.29286-100000@solzhenitsyn.ens.gu.edu.au>

Hi,
   As a precaution against all the computers here (Griffith University,
Australia) going down with the Y2K bug, all the computers are going down.
The site that the R archives are on will be down for a number of days over
the new year, and the machine which actually creates the HTML archive
files will be down for longer.

Apologies for the disruption.
----
Robert King, Australian Environmental Studies, Griffith University, Australia
3875 6677   Robert.King at mailbox.gu.edu.au   http://www.ens.gu.edu.au/robertk/



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From karen at gecko.biol.wits.ac.za  Tue Dec 21 14:20:55 1999
From: karen at gecko.biol.wits.ac.za (KAREN KOTSCHY)
Date: Tue, 21 Dec 1999 14:20:55 GMT+2
Subject: [R] generating a sequence
Message-ID: <12293E36886@gecko.biol.wits.ac.za>

Hi everyone

I'm trying to generate a vector of the form
a <- c(1,2,3,4,1,2,3,1,2,1) where n = 5
in a general way, where n can be any positive integer.

I've run out of ideas. Does anyone have any suggestions?

Thanks
Karen
Karen Kotschy
Centre for Water in the Environment
University of the Witwatersrand
Johannesburg

Tel: 011 716-2218
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From albrecht.gebhardt at uni-klu.ac.at  Tue Dec 21 13:56:45 1999
From: albrecht.gebhardt at uni-klu.ac.at (Albrecht Gebhardt)
Date: Tue, 21 Dec 1999 13:56:45 +0100 (MET)
Subject: [R] digital unix linking problem
In-Reply-To: <001d01bf4b45$ed9d9f60$b8218489@stat.nus.edu.sg>
Message-ID: <Pine.OSF.4.10.9912211324240.3440-100000@zidsrv.sci.uni-klu.ac.at>

On Tue, 21 Dec 1999, Rich Budrevich wrote:

> > > 11819:./bin/R.X11: /sbin/loader: Fatal Error: cannot map xxxxxxx
> > What says "odump -Dl your_R_install_path/bin/R.X11" ?
> ...
>                         ***LIBRARY LIST SECTION***
>         Name             Time-Stamp        CheckSum   Flags Version
> ./bin/R.X11:
>         libSM.so     Apr  2 14:55:43 1999 0xb64c7082     0
>         libICE.so    Apr  2 14:55:34 1999 0x1199be32     0
>         libX11.so    Apr  2 14:46:46 1999 0xf86afbad     0
>         libdnet_stub.so Apr 13 00:18:15 1999 0x9408a36b     0 osf.1
>         xxxxxxx      Nov 22 14:27:47 1999 0x3b8a2af6     0
>         libUfor.so   Nov 17 08:38:01 1998 0xc6e6aa05     0
>         libfor.so    Nov 17 08:37:59 1998 0x1d987a12     0
>         libFutil.so  Nov 17 08:37:58 1998 0x896dea97     0
>         libm.so      Apr 13 00:27:39 1999 0xf29b0962     0 osf.1
>         libots.so    Apr 13 00:16:38 1999 0x0876eb23     0
>         libz.so.1.1.3 Nov 10 13:44:35 1999 0x91c64bf3     0
>         libc.so      Apr 13 00:14:03 1999 0x59eef91c     0 osf.1

I get:
			***LIBRARY LIST SECTION***
	Name             Time-Stamp        CheckSum   Flags Version
/usr/local/lib/R/bin/R.X11:
	libSM.so     Dec  9 07:08:11 1997 0xb64c7082     0 
	libICE.so    Dec  9 07:07:52 1997 0x1199be32     0 
	libX11.so    May  3 23:16:42 1998 0xeb5251bf     0 
	libdnet_stub.so Dec 30 00:16:25 1997 0x9408a36b     0 osf.1
	libUfor.so   Jun 13 03:23:27 1996 0x0dca19c3     0 
	libfor.so    Jun 13 03:23:22 1996 0x00f33ff1     0 
	libFutil.so  Jun 13 03:22:24 1996 0xa0418f9e     0 
	libm.so      Dec 30 00:09:53 1997 0xf29b0962     0 osf.1
	libots.so    Dec 30 00:13:40 1997 0x0876eb23     0 
	libreadline.so.3 Feb 23 17:51:59 1999 0x3a7f2031     0 
	libz.so.1.1  Feb 23 18:01:02 1999 0x91c64bf3     0 
	libncurses.so.4 Feb 23 17:55:19 1999 0xf6374558     0 4.2
	libc.so      Jun 26 23:06:44 1998 0xae0dfa23     0 osf.1

These Fortran subsets are installed:

setld -l | grep -i fortran
DFABASE500           installed  DIGITAL Fortran 90 and 77 V5.0 for DIGITAL UNIX Alpha Systems
DFACOM500            installed  DIGITAL Fortran V5.0 Tools & their Man Pages
DFADOC500            installed  DIGITAL Fortran V5.0 Release Notes and Man Page
DFARTL373            installed  Digital Fortran RTL #373 for Digital UNIX Alpha (f77 only)
DFARTL376            installed  DIGITAL Fortran RTL #376 for DIGITAL UNIX Alpha Systems (f90 and f77)
PSESHPF107           installed  High Performance Fortran Scalar Libraries

examining these symlinks
  /usr/shlib/libfor.so -> ../lib/cmplrs/fortrtl/libfor.so
  /lib/cmplrs/fortrtl -> fortrtl_373/
shows that DFARTL373 gets used.

It seems that some library which gets linked into your R.X11 binary has a
broken SONAME, may this could be a "selfmade" curses, ncurses or
readline library? I remember I had some trouble with SONAMEs of
selfcompiled libraries after the switch from OSF 3.2 to 4.0 because 
some default for SONAMEs changed between 3.x and 4.0 (but it was not a
SONAME="xxxxxx" problem!), or was it from 4.0B to 4.0D? It's too long ago,
I don't remember exactly. 

You can watch the SONAME (created during building the library with
-soname=<name> (-Wl,soname=<name> for gcc)) with "odump -D libxyz.so"
e.g.:
odump -D /usr/shlib/libc.so | grep SONAME
                      SONAME: libc.so

May be one of your libraries is broken and has "SONAME: xxxxxxx" ?

Try to find this library (with bash):

for i in `find / -type f -name \*\.so\* 2>/dev/null`; do
   if test ! -z "`odump -D $i | grep SONAME | grep xxxxxxx`"; then
      echo $i;
   fi;
done 

If you get some result, we can search further for the reason of this
strange behaviour, otherwise I have no idea, may be you should try
another version of Fortran compiler / runtime library (e.g. if you have
older versions available). 

But I think we should move further discussion to the  r-devel list.

Best wishes 

Albrecht

......................................................................
| Albrecht Gebhardt          Tel.: (++43 463) 2700/832               |
| Institut fuer Mathematik   Fax : (++43 463) 2700/834               |
| Universitaet Klagenfurt    mailto:albrecht.gebhardt at uni-klu.ac.at  |
| Villacher Str. 161         http://www-stat.uni-klu.ac.at/~agebhard |
| A-9020 Klagenfurt, Austria                                         |
`--------------------------------------------------------------------'

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec 21 13:59:31 1999
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Dec 1999 12:59:31 +0000 (GMT)
Subject: [R] generating a sequence
Message-ID: <199912211259.MAA28451@toucan.stats.ox.ac.uk>


> From: "KAREN KOTSCHY" <karen at gecko.biol.wits.ac.za>
> To: r-help at stat.math.ethz.ch
> Date: Tue, 21 Dec 1999 14:20:55 GMT+2
> Subject: [R] generating a sequence
> 
> Hi everyone
> 
> I'm trying to generate a vector of the form
> a <- c(1,2,3,4,1,2,3,1,2,1) where n = 5
> in a general way, where n can be any positive integer.
> 
> I've run out of ideas. Does anyone have any suggestions?

I am a bit puzzled here. Why is that n=5 not n=4? Anyway, try

A <- matrix(1, n-1, n-1)
rA <- row(A)
rA[rA + col(A) <= n]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From koller2 at fgr.wu-wien.ac.at  Tue Dec 21 15:08:25 1999
From: koller2 at fgr.wu-wien.ac.at (Wolfgang Koller)
Date: Tue, 21 Dec 1999 15:08:25 CET (+0100)
Subject: [R] generating a sequence
In-Reply-To: <12293E36886@gecko.biol.wits.ac.za>
Message-ID: <1258D9456EA@fgr.wu-wien.ac.at>

You could also try the recursive way (surely slower for big n):

> recseq <- function(n) if (n==1) 1 else c(1:n,recseq(n-1)) 
> recseq(5)
 [1] 1 2 3 4 5 1 2 3 4 1 2 3 1 2 1


> Hi everyone
> 
> I'm trying to generate a vector of the form
> a <- c(1,2,3,4,1,2,3,1,2,1) where n = 5
> in a general way, where n can be any positive integer.
> 
> I've run out of ideas. Does anyone have any suggestions?


Wolfgang Koller


----------------------------------------------------------
Wolfgang Koller,  koller2 at fgr.wu-wien.ac.at
Forschungsinstitut fuer Europafragen
Wirtschaftsuniversitaet Wien
Althanstrasse 39-45, 1090 Wien, Austria
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From royle at penguin.irm.r9.fws.gov  Tue Dec 21 16:02:50 1999
From: royle at penguin.irm.r9.fws.gov (royle@penguin.irm.r9.fws.gov)
Date: Tue, 21 Dec 1999 10:02:50 -0500 (EST)
Subject: [R] generating a sequence
In-Reply-To: <12293E36886@gecko.biol.wits.ac.za>
Message-ID: <Pine.LNX.3.96.991221100117.8747V-100000@penguin.fws.gov>

Funny I had this same problem last week.  Use the function "sequence"
like:

sequence(4:1)
 [1] 1 2 3 4 1 2 3 1 2 1

kind regards
andy

---------------------------------------------------------------------
J. Andy Royle, U.S. Fish and Wildlife Service - Office of Migratory 
Bird Management; 11510 American Holly Drive , Laurel, MD 20708-4017; 
phone - 301-497-5673 fax - 301-497-5706 email - royle at penguin.fws.gov
---------------------------------------------------------------------

On Tue, 21 Dec 1999, KAREN KOTSCHY wrote:

> Hi everyone
> 
> I'm trying to generate a vector of the form
> a <- c(1,2,3,4,1,2,3,1,2,1) where n = 5
> in a general way, where n can be any positive integer.
> 
> I've run out of ideas. Does anyone have any suggestions?
> 
> Thanks
> Karen
> Karen Kotschy
> Centre for Water in the Environment
> University of the Witwatersrand
> Johannesburg
> 
> Tel: 011 716-2218
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.C.Rougier at durham.ac.uk  Tue Dec 21 15:54:07 1999
From: J.C.Rougier at durham.ac.uk (Jonathan Rougier)
Date: Tue, 21 Dec 1999 14:54:07 +0000 (GMT)
Subject: [R] generating a sequence
In-Reply-To: <199912211259.MAA28451@toucan.stats.ox.ac.uk>
Message-ID: <Pine.GSO.4.20.9912211449450.5357-100000@laplace>

On Tue, 21 Dec 1999, Prof Brian Ripley wrote:

> I am a bit puzzled here. Why is that n=5 not n=4? Anyway, try
> 
> A <- matrix(1, n-1, n-1)
> rA <- row(A)
> rA[rA + col(A) <= n]

Or, in the festive spirit,

n <- 5
rA <- outer(1:n, 1:n, "-")
rA[rA>=1]

Cheers, Jonathan.

Jonathan Rougier                       Science Laboratories
Department of Mathematical Sciences    South Road
University of Durham                   Durham DH1 3LE

"[B]egin upon the precept ... that the things we see are to be 
 weighed in the scale with what we know"  (Meredith, 1879, The Egoist)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Dec 21 16:23:49 1999
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Dec 1999 15:23:49 +0000 (GMT)
Subject: [R] generating a sequence
Message-ID: <199912211523.PAA14129@toucan.stats.ox.ac.uk>

OK, so we have now seen essentially three solutions:

Me:

A <- matrix(1, n-1, n-1)
rA <- row(A)
rA[rA + col(A) <= n]

Jonathan Rougier:

rA <- outer(1:n, 1:n, "-")
rA[rA>=1]

Andy Royle:

sequence((n-1):1)

Timings for n=500 on a 1994 Sun Sparc 20:

3.29, 4.68 and 23.86 seconds.

I deliberately did not use outer, as it calls apply and 
is normally quite slow.  row and col are internal operations and fast.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Dec 21 17:14:39 1999
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 21 Dec 1999 17:14:39 +0100 (MET)
Subject: [R] generating a sequence --- need fast [lt]apply ()
In-Reply-To: <199912211523.PAA14129@toucan.stats.ox.ac.uk>
References: <199912211523.PAA14129@toucan.stats.ox.ac.uk>
Message-ID: <14431.42863.62537.411008@gargle.gargle.HOWL>

>>>>> On Tue, 21 Dec 1999 15:23:49 +0000 (GMT), Prof Brian Ripley <ripley at stats.ox.ac.uk> said:

    BDR> OK, so we have now seen essentially three solutions:
    BDR> Me:

    BDR> A <- matrix(1, n-1, n-1)
    BDR> rA <- row(A)
    BDR> rA[rA + col(A) <= n]

    BDR> Jonathan Rougier:

    BDR> rA <- outer(1:n, 1:n, "-")
    BDR> rA[rA>=1]

    BDR> Andy Royle:

    BDR> sequence((n-1):1)

    BDR> Timings for n=500 on a 1994 Sun Sparc 20:

    BDR> 3.29, 4.68 and 23.86 seconds.

    BDR> I deliberately did not use outer, as it calls apply and 
    BDR> is normally quite slow.  row and col are internal operations and fast.

Thanks a lot.

I hope this reminds more people than just me
that we (R users) "desperately" need someone who

rewrites  apply(),lapply(), and tapply()  
to become much faster (as they are with S-plus [34].y, but not 5.[12])...

Anyone working on this ?

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Tue Dec 21 18:26:53 1999
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Tue, 21 Dec 1999 18:26:53 +0100
Subject: [R] generating a sequence
In-Reply-To: <199912211523.PAA14129@toucan.stats.ox.ac.uk>
Message-ID: <000c01bf4bd8$9386fe20$a9021aac@joelschlaegel>



As this looks like a funny performance competition, 
here a very tricky algorithm I once received from Angelo Canty

vecseq <- function(x,y=NULL) {
    # x1:y1,x2:y2 ... Angelo Canty 8/97
    # parameter handling (c) JOA 1997
        if (missing(y)) {y <- x; x <- 1}
        if (length(y)==1) y <- rep(y,length(x))
        if (length(x)==1) x <- rep(x,length(y))
        str <- paste("c(",paste(x,y,sep=":",collapse=","),")")
        eval(parse(text=str))
}

> n <- 500
> 
> system.time({
+ vecseq((n-1):1)
+ })
[1] 0.04 0.00 0.04   NA   NA
> 
> system.time({
+ A <- matrix(1, n-1, n-1)
+ rA <- row(A)
+ rA[rA + col(A) <= n]
+ })
[1] 0.33 0.00 0.33   NA   NA
> 
> system.time({
+ rA <- outer(1:n, 1:n, "-")
+ rA[rA>=1]
+ })
[1] 0.62 0.00 0.62   NA   NA
> 
> system.time({
+ sequence((n-1):1)
+ })
[1] 2.18 0.01 2.27   NA   NA

So, vecsec() is more flexible and much faster than R's sequence,
why not redefine sequence ?
(timings on PII 400 NT4.0)

Regards


Jens Oehlschlaegel-Akiyoshi

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Dec 21 23:19:44 1999
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 21 Dec 1999 23:19:44 +0100
Subject: [R] generating a sequence
In-Reply-To: "Jens Oehlschl?gel-Akiyoshi"'s message of "Tue, 21 Dec 1999 18:26:53 +0100"
References: <000c01bf4bd8$9386fe20$a9021aac@joelschlaegel>
Message-ID: <x2aen4uebj.fsf@blueberry.kubism.ku.dk>

"Jens Oehlschl?gel-Akiyoshi" <jens.oehlschlaegel-akiyoshi at mdfactory.de> writes:

> As this looks like a funny performance competition, 
> here a very tricky algorithm I once received from Angelo Canty
> 
> vecseq <- function(x,y=NULL) {
>     # x1:y1,x2:y2 ... Angelo Canty 8/97
>     # parameter handling (c) JOA 1997
>         if (missing(y)) {y <- x; x <- 1}
>         if (length(y)==1) y <- rep(y,length(x))
>         if (length(x)==1) x <- rep(x,length(y))
>         str <- paste("c(",paste(x,y,sep=":",collapse=","),")")
>         eval(parse(text=str))
> }
....
> So, vecsec() is more flexible and much faster than R's sequence,
> why not redefine sequence ?
> (timings on PII 400 NT4.0)

Hmm. vecseq is certainly impressively fast, but I tend to find any
routine that involves parsing suspicious.

sequence<-function(nvec)unlist(lapply(nvec,function(x)1:x))

clocks in at 0.09 (if you gc() first) and would seem to be equivalent
to the current one. Still two times slower than vecseq, though...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Wed Dec 22 00:47:06 1999
From: bates at stat.wisc.edu (Douglas Bates)
Date: 21 Dec 1999 17:47:06 -0600
Subject: [R] Re: PostgreSQL package
In-Reply-To: "Timothy H. Keitt"'s message of "Sat, 04 Dec 1999 19:28:11 -0800"
References: <3849DBCB.C1C4966A@nceas.ucsb.edu>
Message-ID: <6r66xr7t6t.fsf@franz.stat.wisc.edu>

"Timothy H. Keitt" <keitt at nceas.ucsb.edu> writes:

> Version 0.2 is now available at
> 
>     http://www.nceas.ucsb.edu/~keitt/R/
> 
> This version includes a user extensible type conversion system.  By
> defining three functions, you can now store and retrieve arbitrary data
> types in PostgreSQL tables.  Enjoy.

Thanks for making that available, Timothy.

I found when I installed it that I had to change the Makefile in the
src directory.  On my system (Debian GNU/Linux 2.1) the include files
from the postgresql-dev package are installed in
/usr/include/postgresql.  I needed to add
		      -I/usr/include/postgresql
to the compiler command in src/Makefile and change the include
statement in src/rpgsql.c to

#include "libpq-fe.h"

I'll check with Kurt Hornik, our autoconf/Makefile guru, to see if
there is a clean way of specifying the Makefile.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Wed Dec 22 16:27:13 1999
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Wed, 22 Dec 1999 16:27:13 +0100
Subject: [R] different subscripting behaviour using  $<-  or  [<-  for data.frames
Message-ID: <000801bf4c91$06036d40$a9021aac@joelschlaegel>



Before sending to r-bugs, I ask here:

If

> char <- letters[1:2]
> fac <- factor(char)
> dd <- data.frame(char=I(char), fac=fac)

then

> dd[,"char"] <- char
> dd[,"char"]
[1] a b
Levels:  a b

and

> dd$char <- char
> dd$char
[1] "a" "b"

are different.

After the latter operation the data.frame contains a character column, which
neither has attribute "AsIs" nor has been converted to class factor. Is this
intended?


platform Windows
arch     x86
os       Win32
system   x86, Win32
status
major    0
minor    90.1
year     1999
month    December
day      15
language R

--
Dr. Jens Oehlschl?gel-Akiyoshi
MD FACTORY GmbH
Bayerstrasse 21

80335 M?nchen

Tel.: 089 545 28-27
Fax.: 089 545 28-10
http://www.mdfactory.de

Standard Disclaimers: Opinions expressed here are personal
and are not otherwise represented.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jens.oehlschlaegel-akiyoshi at mdfactory.de  Wed Dec 22 16:35:08 1999
From: jens.oehlschlaegel-akiyoshi at mdfactory.de (=?iso-8859-1?Q?Jens_Oehlschl=E4gel-Akiyoshi?=)
Date: Wed, 22 Dec 1999 16:35:08 +0100
Subject: [R] data.frame(I(matrix)) ?
Message-ID: <000901bf4c92$2130dd90$a9021aac@joelschlaegel>



Before sending to r-bugs I ask here:

> mat <- matrix(letters, 2, 2)
> dimnames(mat) <- list(c(1:2), c("x","y"))
> mat
  x   y
1 "a" "c"
2 "b" "d"

> dd <- data.frame(I(mat))
> ddd
  I.mat..x I.mat..y
1        a        a
2        b        b
3        c        c

doesn't look too bad,
but only one column name:

> dimnames(dd)
[[1]]
[1] "1" "2"

[[2]]
[1] "I.mat."

and unexpected structure
> str(ddd)
`data.frame':     3 obs. of  1 variable:
 $ I.mat.: chr [1:3, 1:2] "a" "b" "c" "a" "b" "c"
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : NULL
  .. ..$ : chr  "x" "y"
  ..- attr(*, "class")= chr "AsIs"
>

column 1 is a matrix
> ddd[,1]
     x   y
[1,] "a" "a"
[2,] "b" "b"
[3,] "c" "c"
attr(,"class")
[1] "AsIs"

This dataframe is not a simple list with each element representing one
column.

Consequently, e.g.

> sapply(ddd, FUN=function(x)x)
     I.mat.
[1,] "a"
[2,] "b"
[3,] "c"
[4,] "a"
[5,] "b"
[6,] "c"

is no longer a matrix.

Is this a bug?


--
Dr. Jens Oehlschl?gel-Akiyoshi
MD FACTORY GmbH
Bayerstrasse 21

80335 M?nchen

Tel.: 089 545 28-27
Fax.: 089 545 28-10
http://www.mdfactory.de

Standard Disclaimers: Opinions expressed here are personal
and are not otherwise represented.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tring at mail1.stofanet.dk  Wed Dec 22 21:22:36 1999
From: tring at mail1.stofanet.dk (Troels Ring)
Date: Wed, 22 Dec 1999 21:22:36 +0100
Subject: No subject
Message-ID: <003e01bf4cba$4b5430e0$2c4fa8c0@tring.stofanet.dk>

Dear friends.
I've forgotten how to simulate data with a known correlation, e.g. only two columns. I'd be most pleased to be told.

Thanks in advance

Troels Ring, M.D
Department of Nephrology
Aalborg, Denmark
tring at mail1.stofanet.dk

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Wed Dec 22 21:59:09 1999
From: bates at stat.wisc.edu (Douglas Bates)
Date: 22 Dec 1999 14:59:09 -0600
Subject: [R] Re: none
In-Reply-To: "Troels Ring"'s message of "Wed, 22 Dec 1999 21:22:36 +0100"
References: <003e01bf4cba$4b5430e0$2c4fa8c0@tring.stofanet.dk>
Message-ID: <6rhfhasndu.fsf@franz.stat.wisc.edu>

"Troels Ring" <tring at mail1.stofanet.dk> writes:

> I've forgotten how to simulate data with a known correlation,
> e.g. only two columns. I'd be most pleased to be told.

Assuming that you want data from a multivariate normal distribution
with a given correlation, install the MASS package and use mvrnorm.
 > library(MASS)
 > example(mvrnorm)

 mvrnrm> Sigma <- matrix(c(10, 3, 3, 2), 2, 2)

 mvrnrm> Sigma
      [,1] [,2]
 [1,]   10    3
 [2,]    3    2

 mvrnrm> var(mvrnorm(n = 1000, rep(0, 2), Sigma))
	  [,1]     [,2]
 [1,] 9.870587 2.764234
 [2,] 2.764234 1.840870

Note that as of version 0.90.1 you can get the MASS, nnet, spatial,
and class libraries in a single bundle with
 install.packages("VR")   # packages from the Venables and Ripley bundle
You do need to set the CRAN option to a legitimate CRAN archive site,
have access to the Internet, and have either the wget or lynx programs
on your search path.

The default for options("CRAN") is cran.r-project.org.  You may want
to use cran.dk.r-project.org, the Danish mirror, instead.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tony at asynctechnology.com  Thu Dec 23 06:38:30 1999
From: tony at asynctechnology.com (Tony Fagan)
Date: Wed, 22 Dec 1999 22:38:30 -0700
Subject: [R] Very Large Data Sets
Message-ID: <000801bf4d07$f3441b60$af2c0e3f@hal>

List,

Can R handle very large data sets (say, 100 million records) for data mining applications? My understanding is that Splus can not, but SAS can easily.

Thanks,
Tony Fagan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/19991222/6f333667/attachment.html

From William.Venables at cmis.CSIRO.AU  Thu Dec 23 07:05:23 1999
From: William.Venables at cmis.CSIRO.AU (Bill Venables)
Date: Thu, 23 Dec 1999 16:05:23 +1000
Subject: [R] Very Large Data Sets 
In-Reply-To: Your message of "Wed, 22 Dec 1999 22:38:30 MST."
             <000801bf4d07$f3441b60$af2c0e3f@hal> 
Message-ID: <199912230605.RAA09007@snowy.nsw.cmis.CSIRO.AU>

Tony Fagan asks:

> List,

Sir,

> Can R handle very large data sets (say, 100 million records) for data 
> mining applications? 

The question assumes that the data handling capacity is a
property of the software alone, which is nonsense.  It is partly
a property of the software, partly of what you want to do with
the records, but mostly of the system on which it is run.

> My understanding is that Splus can not, but SAS can easily.

Try handling 100 million records with SAS (or anything else) on a
486 and see how easily it does it.

More seriously, the consensus is that on the same modern system
SAS is usually better able to handle large, dumb calculations
than S-PLUS, which is (generally) better than R.  Horses for
courses.

Bill Venables.
-- 
-----------------------------------------------------------------
Bill Venables, Statistician, CMIS Environmetrics Project.

Physical address:                            Postal address:
CSIRO Marine Laboratories,                   PO Box 120,       
233 Middle St, Cleveland, Queensland         Cleveland, Qld, 4163
AUSTRALIA                                    AUSTRALIA

Telephone: +61 7 3826 7251     Email: Bill.Venables at cmis.csiro.au

      Fax: +61 7 3826 7304


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.malewski at tu-bs.de  Thu Dec 23 08:32:11 1999
From: p.malewski at tu-bs.de (Peter Malewski)
Date: Thu, 23 Dec 1999 08:32:11 +0100
Subject: [R] Very Large Data Sets
References: <000801bf4d07$f3441b60$af2c0e3f@hal>
Message-ID: <3861CFFB.3DACFF84@tu-bs.de>

Tony Fagan wrote:

> List, Can R handle very large data sets (say, 100 million records) for
> data mining applications? My understanding is that Splus can not, but
> SAS can easily. Thanks,Tony Fagan

>From a theoretical point of view yes, but practically:
1) you'll need plenty of memory
2) even than the computation time will be long

In past times I used SPSS to create summarized data file (Mostly there is much more data than really needed). Now I cut the data in a view records, write the syntax, and than run the code in the night.

I think the ++ of R is the flexibility of the analyses not the data preparation of very,very large data-bases.

Merry Xmas & a happy new year

Peter

--
** To YOU I'm an atheist; to God, I'm the Loyal Opposition. Woody Allen **
P.Malewski                                      Tel.: 0531 500965
Maschplatz 8                                    Email: P.Malewski at tu-bs.de
************************38114 Braunschweig********************************



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kmself at ix.netcom.com  Thu Dec 23 11:22:11 1999
From: kmself at ix.netcom.com (kmself@ix.netcom.com)
Date: Thu, 23 Dec 1999 02:22:11 -0800
Subject: [R] Very Large Data Sets
In-Reply-To: <000801bf4d07$f3441b60$af2c0e3f@hal>; from tony@asynctechnology.com on Wed, Dec 22, 1999 at 10:38:30PM -0700
References: <000801bf4d07$f3441b60$af2c0e3f@hal>
Message-ID: <19991223022211.A6798@ix.netcom.com>

There are several components to this answer.  I'm not too well versed in
R, but I've run across the capacity question before.

R has a hard limit of 2 GB total memory, as I understand, and its data
model requires holding an entire set in memory.  This is very fast until
it isn't.  This limit applies even on 64 bit systems.

SAS can "process" a practically infinite data stream, one observation at
a time (or more accurately, one read buffer at a time).  You can
approach this ideal using multiple-volume tape input on a number of OSs.
However, this ability is limited to simple and straightforward
processing -- DATA step and some very simple procedures.

Processing limits for various operations in SAS vary by OS, SAS version,
and operation.  For 32 bit OSs under releases up through 6.8 - 6.12, 2
GB RAM, 2 GB disk, and 32,767 (2^15 - 1) of many things were hard
limits.   For various reasons, the hard limits don't apply in all cases,
and workarounds were provided in several areas.

Under 64 bit OSs, these limits tend to be lifted, though occasionally 32
bit biases sneak through and bite you (there was one such bug in Proc SQL).  
Traditional limits such as the number of levels (and significant bytes
in character variables) treated by PROC FREQ have been greatly increased
in versions 7 and 8 of SAS.

Other limits are imposed more by the shear size of problems.  Many SAS
statistical procedures are based on IML and are limited by memory and
set size.  Even when large memory sets are supported, complex problems
with many levels may still exceed the capacity of any system.  Moreover,
complex statistics may make little sense on such large datasets.


When dealing with large datasets outside of SAS, my suggestion would be
to look to tools such as Perl and MySQL to handle the procedural and
relational processing of data, using R as an analytic tool.  Most simple
statistics (subsetting, aggregation, drilldown) can be accommodated
through these sorts of tools.   Think of the relationship to R as the
division as between the DATA step and SAS/STAT or SAS/GRAPH.

I would be interested to know of any data cube tools which are freely
available or available as free software.


On Wed, Dec 22, 1999 at 10:38:30PM -0700, Tony Fagan wrote:
> List,
> 
> Can R handle very large data sets (say, 100 million records) for data mining applications? My understanding is that Splus can not, but SAS can easily.
> 
> Thanks,
> Tony Fagan

-- 
Karsten M. Self (kmself at ix.netcom.com)
    What part of "Gestalt" don't you understand?

SAS for Linux: http://www.netcom.com/~kmself/SAS/SAS4Linux.html
Mailing list:  "subscribe sas-linux" to mailto:majordomo at cranfield.ac.uk
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 290 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/19991223/86196eaa/attachment.bin

From bates at stat.wisc.edu  Thu Dec 23 15:02:53 1999
From: bates at stat.wisc.edu (Douglas Bates)
Date: 23 Dec 1999 08:02:53 -0600
Subject: [R] Very Large Data Sets
In-Reply-To: kmself@ix.netcom.com's message of "Thu, 23 Dec 1999 02:22:11 -0800"
References: <000801bf4d07$f3441b60$af2c0e3f@hal> <19991223022211.A6798@ix.netcom.com>
Message-ID: <6r66xp7o1e.fsf@franz.stat.wisc.edu>

kmself at ix.netcom.com writes:

> When dealing with large datasets outside of SAS, my suggestion would be
> to look to tools such as Perl and MySQL to handle the procedural and
> relational processing of data, using R as an analytic tool.  Most simple
> statistics (subsetting, aggregation, drilldown) can be accommodated
> through these sorts of tools.   Think of the relationship to R as the
> division as between the DATA step and SAS/STAT or SAS/GRAPH.

> I would be interested to know of any data cube tools which are freely
> available or available as free software.

I am considering this type of approach for an application that will
involve very large data sets.  I will probably use the python
scripting language rather than perl but the general approach is as you describe.

We currently have some code in R packages to read Stata data files and
(in the "foreign" package of the src/contrib/Devel section on CRAN) to
read SAS XPORT format data libraries.  These packages can help to move
data from one format to another they don't help with dealing with
massive numbers of records in R's memory-based model.

When faced with a large data set I first want to determine the
representation of the data and some basic summaries.  After that I
might want to work with a subset of the rows and/or columns when doing
some modeling and only use the entire data set to refine or confirm
the model.

My idea is to take standard data formats for data tables (SAS XPORT
format, SPSS sav files, ...), encapsulate them as python classes, and
provide methods that would summarize the columns and perhaps emulate
Martin Maechler's excellent "str" function from R.  For example, I
would want to know if every value of a numeric variable happened to be
an integer and always in the range from 1 up to 10, or something like
that.  This would indicate to me that it was probably a coding of a
factor and not a numeric variable.  The summary methods should only
require calculations that can be done a row at a time.  Thus
calculating minima and maxima is reasonable but getting medians and
quartiles is not.  The classes would not import all the data into
python - they would simply keep around enough information to read the
data a row at a time on demand.

Each of these classes would include a method to store the data as a
table in a relational database system.  There are python packages for
most common SQL databases, including the freely available PostgreSQL
and mySQL.  The inverse transformation, SQL table to proprietary data
format, would also be provided.

To work on a subset of the data within R we could try to enhance the
functions that read data from foreign formats to allow selection of
rows or columns.  However, as you suggest, that job is probably best
handled using SQL and functions within R that extract tables or views
from the SQL database.  I would note that Timothy Keitt has just
contributed an R package to interface with PostgreSQL.

Trying to write this type of code teaches you interesting things.  As
far as I can tell, you cannot discover the number of rows in a SAS
dataset from the header information.  The number of rows is not
recorded there and, because more than one dataset can be stored in a
library file, you cannot use the length of the file and the length of
the record to calculate the number of records (rows).  If you want to
allocate storage to hold the data in R the simplest thing to do is
is to read the file once to discover the structure then read
it again to import the data.  It shows you that the idea that your
data are sitting on a reel of tape over at the "computing center" is
wired into the SAS system at a very low level.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From etptupaf at bs.ehu.es  Thu Dec 23 15:58:51 1999
From: etptupaf at bs.ehu.es (F.Tusell)
Date: Thu, 23 Dec 1999 15:58:51 +0100
Subject: [R] rpart on Alpha under OSF 
Message-ID: <199912231458.PAA01389@agesi.bs.ehu.es>

Running on an Alpha machine which reports (uname -a)

       OSF1 bsdx01.bs.ehu.es V4.0 878 alpha

and using  the binary distribution  put together by  Albrecht Gebhardt
(in    http://cran.at.r-project.org/bin/osf/osf4.0/tar/alpha_ev5/)   I
obtain  core dumps  whenever I  try  to use  package rpart.  I have  R
REMOVE'd the rpart package, downloaded the source rpart_1.0-7.tar from
CRAN  and attempted  a compilation.  Everything works  fine  until the
linking step, when I get:

f77 -shared  -o /users/etptupaf/R/library/rpart/libs/rpart.so anova.o anovapred.o branch.o bsplit.o choose_surg.o fix_cp.o free_tree.o gini.o graycode.o insert_split.o make_cp_list.o make_cp_table.o mysort.o nodesplit.o partition.o poisson.o poissonpred.o pred_rpart.o rpart.o rpcountup.o rplabel.o rpmatrix.o rundown.o rundown2.o s_to_rp.o s_xpred.o surrogate.o xval.o -lUfor -lfor -lFutil -lm -lots -lm
ld:
Warning: Unresolved:
S_alloc

What is S_alloc? Do  I have to install the full source  for R in order
to compile a package? I do not have root rights on this machine, which
is why I went for the compiled distribution. Compiling the same package 
on my Linux Intel machine works all right, so I guess the problem is
I am missing something that I should have.


ft.
-- 
Fernando TUSELL                                 e-mail:
Departamento de Econometra y Estadstica           etptupaf at bs.ehu.es 
Facultad de CC.EE. y Empresariales              Tel:    (+34)946013733
Avenida Lendakari Aguirre, 83                   Fax:    (+34)946013754
E-48015 BILBAO  (Spain)                         Secr:   (+34)946013740
PGP: finger etptupaf at bsdx01.bs.ehu.es           http://agesi.bs.ehu.es
----------------------------------------------------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 23 16:51:05 1999
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Dec 1999 15:51:05 +0000 (GMT)
Subject: [R] rpart on Alpha under OSF 
Message-ID: <199912231551.PAA01824@toucan.stats.ox.ac.uk>

> Date: Thu, 23 Dec 1999 15:58:51 +0100
> From: "F.Tusell" <etptupaf at bs.ehu.es>
> What is S_alloc? Do  I have to install the full source  for R in order

It is a routine included in R.

> to compile a package? I do not have root rights on this machine, which

No.

> is why I went for the compiled distribution. Compiling the same package 
> on my Linux Intel machine works all right, so I guess the problem is
> I am missing something that I should have.

More likely that  R_HOME/etc/Makeconf is wrong. From memory, you 
need a flag on Alphas for S-PLUS which allows unresolved references
when building shared libraries, and I guess you may also need it here.

In short, rpart is doing exactly what it is expected to, but your
building of a shared library is not.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Thu Dec 23 17:49:06 1999
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Thu, 23 Dec 1999 16:49:06 +0000 (GMT)
Subject: [R] Very Large Data Sets
In-Reply-To: <19991223022211.A6798@ix.netcom.com>
Message-ID: <Pine.LNX.4.10.9912231636190.11937-100000@gimel.biostat.washington.edu>

On Thu, 23 Dec 1999 kmself at ix.netcom.com wrote:
> 
> When dealing with large datasets outside of SAS, my suggestion would be
> to look to tools such as Perl and MySQL to handle the procedural and
> relational processing of data, using R as an analytic tool.  Most simple
> statistics (subsetting, aggregation, drilldown) can be accommodated
> through these sorts of tools.   Think of the relationship to R as the
> division as between the DATA step and SAS/STAT or SAS/GRAPH.
> 
> I would be interested to know of any data cube tools which are freely
> available or available as free software.

The S-PLUS package for the netCDF format, written by Steve Oncley of NCAR,
allows reading of arbitrary "slabs" of a very large data file. At one
point he was planning to write an R version, but I can't remember what
happened and my email records for the relevant time were eaten by a
Microsoft Outlook/Pine disagreement. 

This would allow you to work with large data files one piece at a time (if
they were netCDF files). Something similar could be done with mmap(2) if
your OS allows addressing that much memory (which they mostly will soon). 

	
Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lorenmc at socrates.berkeley.edu  Thu Dec 23 18:33:47 1999
From: lorenmc at socrates.berkeley.edu (Loren M. McCarter)
Date: Thu, 23 Dec 1999 09:33:47 -0800 (PST)
Subject: [R] Very Large Data Sets
In-Reply-To: <000801bf4d07$f3441b60$af2c0e3f@hal>
Message-ID: <Pine.SOL.4.10.9912230844370.4195-100000@socrates.berkeley.edu>

On Wed, 22 Dec 1999, Tony Fagan wrote:

> List,
> 
> Can R handle very large data sets (say, 100 million records) for data mining applications? My understanding is that Splus can not, but SAS can easily.
> 
> Thanks,
> Tony Fagan
> 

There have been a couple of posts about approaching this large-dataset
problem with the MySQL/Python/R combination. I will simply add some
information (a testimonial) about my experiences with this as a possible
solution. This combination has worked very, very well for me. As a former
SAS and Windows user, I decided to perform my dissertation data analyses
using FreeBSD, which does not run SAS. After about a year of tinkering
around with different ways to approach the problem of analyzing my
dissertation data (i.e., moderately large ~1.5 million obs of
psychophysiological data), I have settled on this MySQL/Python/R
combination. In order to get to this stage, I looked into several other
solutions (e.g., Perl Data Language, PostgreSQL, Ox, APL, Perl, etc.), but
this combination met my needs best. 

For my purposes, I find this solution to be better than any other 
(including SAS). MySQL is very, very fast, especially when using
an index. Just last night, I could not believe how quickly it created
an R dataset for me (only 30 seconds on an slow machine---486DX
66Mhz---for a complex join of four tables, each table containing about
500K rows). For most data-analytic purposes, I go directly from (1)
subsetting the data in MySQL to (2) performing more sophisticated data
analyses in R. For some more complex queries, the Python
link is needed, but not for most (Python, of course, is useful for many
other reasons than linking from MySQL to R).

For my dissertation data, there is no reason for me to analyze all 1.5 
million rows at once. Rather, I need to perform the same statistical procedures,
one or two subjects at a time (i.e., 2400 rows), over and over again. I
let the SQL backend do the large, number-crunching work and let R shine
for statistics, and it really does shine...

Testimonially yours,

Loren




-------------------------------

Loren Michael McCarter
Graduate Student-UC Berkeley



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From albrecht.gebhardt at uni-klu.ac.at  Thu Dec 23 19:35:54 1999
From: albrecht.gebhardt at uni-klu.ac.at (Albrecht Gebhardt)
Date: Thu, 23 Dec 1999 19:35:54 +0100 (MET)
Subject: [R] rpart on Alpha under OSF 
In-Reply-To: <199912231458.PAA01389@agesi.bs.ehu.es>
Message-ID: <Pine.OSF.4.10.9912231837090.19575-100000@zidsrv.sci.uni-klu.ac.at>

On Thu, 23 Dec 1999, F.Tusell wrote:

> Running on an Alpha machine which reports (uname -a)
> 
>        OSF1 bsdx01.bs.ehu.es V4.0 878 alpha
> 
> and using  the binary distribution  put together by  Albrecht Gebhardt
> (in    http://cran.at.r-project.org/bin/osf/osf4.0/tar/alpha_ev5/)   
this is a little bit outdated (0.65.0), I should make a new tar snapshot
of 0.90.1, but I guess it wouldn't solve your segfault problem.

Sorry but I have no time to test all parts of this binary package, I guess
there is more then this one alpha specific bug hidden somewhere. 

Anyway you could try to use gdb to locate the error.

First get the R sources + rpart sources somewhere in your homedir.
Start R (could even be in (X)emacs with ESS), type "library(rpart)", 
get its process id (ps axuw| grep R.X11),
start "gdb path_to_/R.X11" (preferably in emacs or Xemacs via alt-x gdb),
type the gdb commands

  cd somewhere_in_your_home_dir 
  dir path_to_Rsrc/src/library/rpart/src 
  dir path_to_Rsrc/src/main
  dir path_to_Rsrc/src/unix
  dir path_to_Rsrc/src/appl
  dir path_to_Rsrc/src/nmath
  sharedlib path_to_R/library/rpart/libs/rpart.so
  attach process_id_of_R.X11

eventually set breakpoints with "break subroutinename" and then 

  continue

Now type your R commands and watch gdb where you are when the crash
occurs. (e.g. with "backtrace", or "list")

When finished: 
  detach

> obtain  core dumps  whenever I  try  to use  package rpart.  I have  R
> REMOVE'd the rpart package, downloaded the source rpart_1.0-7.tar from
> CRAN  and attempted  a compilation.  Everything works  fine  until the
> linking step, when I get:
> 
> f77 -shared  -o /users/etptupaf/R/library/rpart/libs/rpart.so anova.o anovapred.o branch.o bsplit.o choose_surg.o fix_cp.o free_tree.o gini.o graycode.o insert_split.o make_cp_list.o make_cp_table.o mysort.o nodesplit.o partition.o poisson.o poissonpred.o pred_rpart.o rpart.o rpcountup.o rplabel.o rpmatrix.o rundown.o rundown2.o s_to_rp.o s_xpred.o surrogate.o xval.o -lUfor -lfor -lFutil -lm -lots -lm
> ld:
> Warning: Unresolved:
> S_alloc
> 
> What is S_alloc? Do  I have to install the full source  for R in order
> to compile a package? I do not have root rights on this machine, which

This is only a warning, it could be supressed with the linker option
"-expect_unresolved *", but it makes no difference for the result.
It simply indicates that S_alloc (subroutine in R.X11) gets called from
within rpart.so.

You don't need the complete R sources, even for the gdb experiment above.
But may it is better to have them, to be able to "step" through the
complete code within gdb.

A new alpha binary tar file (0.90.1) should appear soon on CRAN.


Albrecht
......................................................................
| Albrecht Gebhardt          Tel.: (++43 463) 2700/832               |
| Institut fuer Mathematik   Fax : (++43 463) 2700/834               |
| Universitaet Klagenfurt    mailto:albrecht.gebhardt at uni-klu.ac.at  |
| Villacher Str. 161         http://www-stat.uni-klu.ac.at/~agebhard |
| A-9020 Klagenfurt, Austria                                         |
`--------------------------------------------------------------------'


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 23 20:12:51 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 23 Dec 1999 19:12:51 +0000 (GMT)
Subject: [R] rpart on Alpha under OSF 
In-Reply-To: <Pine.OSF.4.10.9912231837090.19575-100000@zidsrv.sci.uni-klu.ac.at>
Message-ID: <Pine.GSO.4.05.9912231906070.19793-100000@auk.stats>

On Thu, 23 Dec 1999, Albrecht Gebhardt wrote:

> On Thu, 23 Dec 1999, F.Tusell wrote:
> 
> > Running on an Alpha machine which reports (uname -a)
> > 
> >        OSF1 bsdx01.bs.ehu.es V4.0 878 alpha
> > 
> > and using  the binary distribution  put together by  Albrecht Gebhardt
> > (in    http://cran.at.r-project.org/bin/osf/osf4.0/tar/alpha_ev5/)   
> this is a little bit outdated (0.65.0), I should make a new tar snapshot
> of 0.90.1, but I guess it wouldn't solve your segfault problem.
> 
> Sorry but I have no time to test all parts of this binary package, I guess
> there is more then this one alpha specific bug hidden somewhere. 

Try R CMD check: that tests most things. (Actually, please try it on your
own submissions too, as the recent sgeostat and tripack both fail.)  There
is also a test suite provided in rpart.

To F. Tusell:
This is not my C code, and seems to have lots of long = int assumptions.
Try defining long to be int in rpart.h.

There is a new version of rpart on which I am working on an R port.
I have changed lots of longs to ints there.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gil.hauer at sun.com  Fri Dec 24 16:24:28 1999
From: gil.hauer at sun.com (Gil Hauer)
Date: Fri, 24 Dec 1999 10:24:28 -0500
Subject: [R] find the mode of a dataset
Message-ID: <NBBBJCCMIPMFLDAEJFHPGEAMDBAA.gil.hauer@sun.com>

Hi,

First, a warning: I'm new to this.

I have a data sample which I am displaying with the hist() command; no
problems there. I would like to find three other pieces of information: the
minimum, the maximum and the sample mode (most frequently occurring data
item). The first two are no problem but the last has me stumped. I tried to
browse the documentation to no avail. Is there anyone who knows how to do
this?

Thanks in advance,
Gil

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Fri Dec 24 17:51:57 1999
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Fri, 24 Dec 1999 16:51:57 +0000 (GMT)
Subject: [R] find the mode of a dataset
In-Reply-To: <NBBBJCCMIPMFLDAEJFHPGEAMDBAA.gil.hauer@sun.com>
Message-ID: <Pine.LNX.4.10.9912241645560.30372-100000@gimel.biostat.washington.edu>

On Fri, 24 Dec 1999, Gil Hauer wrote:

> Hi,
> 
> First, a warning: I'm new to this.
> 
> I have a data sample which I am displaying with the hist() command; no
> problems there. I would like to find three other pieces of information: the
> minimum, the maximum and the sample mode (most frequently occurring data
> item). The first two are no problem but the last has me stumped. I tried to
> browse the documentation to no avail. Is there anyone who knows how to do
> this?


If you really want the sample mode of a vector x you can get it with 

  names(sort(-table(x)))[1]

where table(x) creates a table of the frequencies of each value of x,
multipling by -1 and sorting puts the largest frequency first, and
names()[1] extracts the name of the first element, which is the sample
mode (converted to a string).  You may need to then use as.numeric() on
the result if you want a number.

eg
R> x<-rpois(100,4)
R> names(sort(-table(x)))[1]
[1] "3"
R> table(x)
x
 0  1  2  3  4  5  6  7  8  9 10
 2  9 13 21 15 12 15  7  2  2  2



If your data are continuous (even if they have been rounded off to be
discrete)  you might instead want to estimate the density and pick the
mode of that.  Use hist(x) to get a histogram or plot(density(x)) to get a
kernel estimate of the density of x.



Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cyg at sympatico.ca  Sun Dec 26 13:33:15 1999
From: cyg at sympatico.ca (Yves Gauvreau)
Date: Sun, 26 Dec 1999 07:33:15 -0500
Subject: [R] Plotting dates?
Message-ID: <006501bf4f9d$620fb6c0$35c5d1d8@bertha>

Hi,

Is there some easy way to plot some xy data and have date strings like say
"dd/mmm" on the x axis?

Thanks in advance.

Yves

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From decline at bigfoot.com  Mon Dec 27 04:03:02 1999
From: decline at bigfoot.com (decline@bigfoot.com)
Date: 26 Dec 1999 22:03:02 -0500
Subject: [R] For Sale: E-mail Address Databases - International or USA
Message-ID: <0445e0103031bc9MS3@ms3>



We have compiled over 600,000 USA business records which 
include: e-mail address, company name, phone, fax, etc.

We inventory and produce general "International E-mail Addresses
Databases in the country of your choice...

We develop "Opt In" Lists for companies and/or organizations
that want to send out "Newsletters"....

Do you want to get your point across in the USA...Our USA 
delivery list contains in excess of 20,000,000 USA general
addresses cleaned and filtered...

For those who prefer not to do their own in-house mailings...
We also provide contract mailing services...

Please contact us only by way of this address: express20 at bigfoot.com

 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From etptupaf at bs.ehu.es  Mon Dec 27 08:53:31 1999
From: etptupaf at bs.ehu.es (F.Tusell)
Date: Mon, 27 Dec 1999 08:53:31 +0100
Subject: [R] rpart on Alpha under OSF
In-Reply-To: 
	<Pine.OSF.4.10.9912231837090.19575-100000@zidsrv.sci.uni-klu.ac.at>
	(message from Albrecht Gebhardt on Thu, 23 Dec 1999 19:35:54 +0100
	(MET))
References: <Pine.OSF.4.10.9912231837090.19575-100000@zidsrv.sci.uni-klu.ac.at>
Message-ID: <199912270753.IAA00752@agesi.bs.ehu.es>

Thank you to both Albrecht Gebhardt and Brian Ripley for their help. I
will do as advised  in their messages, and report to the  list if I am
successful.

ft.
-- 
Fernando TUSELL                                 e-mail:
Departamento de Econometra y Estadstica           etptupaf at bs.ehu.es 
Facultad de CC.EE. y Empresariales              Tel:    (+34)946013733
Avenida Lendakari Aguirre, 83                   Fax:    (+34)946013754
E-48015 BILBAO  (Spain)                         Secr:   (+34)946013740
PGP: finger etptupaf at bsdx01.bs.ehu.es           http://agesi.bs.ehu.es
----------------------------------------------------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bitwrit at ozemail.com.au  Mon Dec 27 12:03:31 1999
From: bitwrit at ozemail.com.au (bitwrit)
Date: Mon, 27 Dec 1999 22:03:31 +1100
Subject: [R] Plotting dates?
References: <006501bf4f9d$620fb6c0$35c5d1d8@bertha>
Message-ID: <38674783.F8613D@ozemail.com.au>

Yves Gauvreau wrote:
> 
> Hi,
> 
> Is there some easy way to plot some xy data and have date strings like say
> "dd/mmm" on the x axis?

> plot(rnorm(10,5,2),axes=F)
> box()
> axis(2)
> axis(1,1:10,paste(1:10,"Jan",sep="-"))

Not sure if this is exactly what you want, but it might help.

Jim

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mhemberger at csi.com  Mon Dec 27 18:25:17 1999
From: mhemberger at csi.com (Marc Hemberger)
Date: Mon, 27 Dec 1999 18:25:17 +0100
Subject: [R] Anything for fractals ?
Message-ID: <3867A0FD.C8F961C7@csi.com>

Hallo,

I am a newbie to R and desperatley seeking some material about fractal
geometry. I found the great library on wavelet analysis of images and
I'm now also keen on finding a similar package for calculating fractal
parameters for given images.

Does anybody know something about such a package? Every hint is greatly
appreciated!! I searched already the database, but did not find anything
in this direction. Is there something currently under development? I
would also like to work on such a project, but since I'm new to R, I
hesitate.

Thanks in advance for any hint,

Marc

--

Dr. Marc Hemberger

       |\      _,,,---,,         GSI, Abteilung DV&EE    privat:
ZZZzz  /,`.-'`'    -.  ;-;;,_    Planckstr. 1            Duererstr. 20
      |,4-  ) )-,_. ,\ (  `'-'
     '---''(_/--'  `-'\_)        64291 Darmstadt         68723 Plankstadt

M.Hemberger at gsi.de                                       MHemberger at csi.com

** Disclaimer: My views/comments/beliefs, as strange as they are, are my own.**



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From keitt at nceas.ucsb.edu  Tue Dec 28 17:25:48 1999
From: keitt at nceas.ucsb.edu (Tim Keitt)
Date: Tue, 28 Dec 1999 08:25:48 -0800
Subject: [R] Anything for fractals ?
In-Reply-To: <3867A0FD.C8F961C7@csi.com>
Message-ID: <Pine.SGI.4.10.9912280817340.25419-100000@ulysses.nceas.ucsb.edu>

Try plotting the variance of the wavelet coefficients versus their
frequency on log-log scale.  If you get a strait line over several orders
of magnitude, then the  slope of the line is related to the fractal
dimension of the image.
 
Tim

On Mon, 27 Dec 1999, Marc Hemberger wrote:

> Hallo,
> 
> I am a newbie to R and desperatley seeking some material about fractal
> geometry. I found the great library on wavelet analysis of images and
> I'm now also keen on finding a similar package for calculating fractal
> parameters for given images.
> 
> Does anybody know something about such a package? Every hint is greatly
> appreciated!! I searched already the database, but did not find anything
> in this direction. Is there something currently under development? I
> would also like to work on such a project, but since I'm new to R, I
> hesitate.
> 
> Thanks in advance for any hint,
> 
> Marc
> 
> --
> 
> Dr. Marc Hemberger
> 
>        |\      _,,,---,,         GSI, Abteilung DV&EE    privat:
> ZZZzz  /,`.-'`'    -.  ;-;;,_    Planckstr. 1            Duererstr. 20
>       |,4-  ) )-,_. ,\ (  `'-'
>      '---''(_/--'  `-'\_)        64291 Darmstadt         68723 Plankstadt
> 
> M.Hemberger at gsi.de                                       MHemberger at csi.com
> 
> ** Disclaimer: My views/comments/beliefs, as strange as they are, are my own.**
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

Timothy H. Keitt
National Center for Ecological Analysis and Synthesis
735 State Street, Suite 300, Santa Barbara, CA 93101
Phone: 805-892-2529, FAX: 805-892-2510
http://www.nceas.ucsb.edu/~keitt/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From peter at esb.ucp.pt  Wed Dec 29 18:07:24 1999
From: peter at esb.ucp.pt (Peter Ho)
Date: Wed, 29 Dec 1999 17:07:24 +0000
Subject: [R] Stepwise logistic discrimination
References: <199912210943.JAA20948@toucan.stats.ox.ac.uk>
Message-ID: <386A3FCB.CBDC5F81@esb.ucp.pt>

Dear All R users,

Firstly , I would like to wish all R users a Merry Xmas and  a happy New Year.

I have been trying to do stepwise logistic discrimination on a data set of 126
variables and only 99 cases, into 4 groups. I followed Prof. Riply's suggestion of
applying stepAIC after using multinom from nnet, but I got an error and hence I
cannot go any further with the analysis. Does anyone out there have any suggestions
as to where I went wrong? Below is a short summary what I did and the results,
ending with the error message.  I am currently using R 0.64.2 (windows binary).


------------------
> nose126s.mu <- multinom(Spoilage ~ ., nose126s)
# weights:  512 (381 variable)
> nose126s.mu
Call:
multinom(formula = Spoilage ~ ., data = nose126s)

Coefficients:
        (Intercept)        FRAG25        FRAG26       FRAG27        FRAG28
week2  1.219487e-09 -3.195595e-04  4.748949e-05 4.900736e-05 -8.570984e-08
week3 -1.660521e-09 -1.669241e-05 -1.557546e-04 1.422205e-04  1.666224e-06
week4 -3.602248e-10  6.105686e-06  2.218175e-04 6.301120e-06  1.859483e-07

....
            FRAG149       FRAG150
week2 -0.0001381260 -2.165186e-05
week3 -0.0001115298 -1.141151e-04
week4 -0.0001030075  1.792253e-05

Residual Deviance: 19.53574
AIC: 613.5357

> nose126s.step <- stepAIC(nose126s.mu)
Start:  AIC= 613.54
 Spoilage ~ FRAG25 + FRAG26 + FRAG27 + FRAG28 + FRAG29 + FRAG30 +
    FRAG31 + FRAG32 + FRAG33 + FRAG34 + FRAG35 + FRAG36 + FRAG37 +
    FRAG38 + FRAG39 + FRAG40 + FRAG41 + FRAG42 + FRAG43 + FRAG44 +
    FRAG45 + FRAG46 + FRAG47 + FRAG48 + FRAG49 + FRAG50 + FRAG51 +
    FRAG52 + FRAG53 + FRAG54 + FRAG55 + FRAG56 + FRAG57 + FRAG58 +
    FRAG59 + FRAG60 + FRAG61 + FRAG62 + FRAG63 + FRAG64 + FRAG65 +
    FRAG66 + FRAG67 + FRAG68 + FRAG69 + FRAG70 + FRAG71 + FRAG72 +
    FRAG73 + FRAG74 + FRAG75 + FRAG76 + FRAG77 + FRAG78 + FRAG79 +
    FRAG80 + FRAG81 + FRAG82 + FRAG83 + FRAG84 + FRAG85 + FRAG86 +
    FRAG87 + FRAG88 + FRAG89 + FRAG90 + FRAG91 + FRAG92 + FRAG93 +
    FRAG94 + FRAG95 + FRAG96 + FRAG97 + FRAG98 + FRAG99 + FRAG100 +
    FRAG101 + FRAG102 + FRAG103 + FRAG104 + FRAG105 + FRAG106 +
    FRAG107 + FRAG108 + FRAG109 + FRAG110 + FRAG111 + FRAG112 +
    FRAG113 + FRAG114 + FRAG115 + FRAG116 + FRAG117 + FRAG118 +
    FRAG119 + FRAG120 + FRAG121 + FRAG122 + FRAG123 + FRAG124 +
    FRAG125 + FRAG126 + FRAG127 + FRAG128 + FRAG129 + FRAG130 +
    FRAG131 + FRAG132 + FRAG133 + FRAG134 + FRAG135 + FRAG136 +
    FRAG137 + FRAG138 + FRAG139 + FRAG140 + FRAG141 + FRAG142 +
    FRAG143 + FRAG144 + FRAG145 + FRAG146 + FRAG147 + FRAG148 +
    FRAG149 + FRAG150

# weights:  508 (378 variable)
# weights:  508 (378 variable)

......


Error: arguments imply differing number of rows: 1, 126

---------------------------


Please can anyone suggest a way forward?


Thank you


Peter
-------------------
Peter Ho
Escola Superior de Biotecnologia
Rua Dr. Ant?nio Bernardino de Almeida
4200 Porto
Tel: ++351-22-5580043



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cstrato at EUnet.at  Wed Dec 29 21:00:50 1999
From: cstrato at EUnet.at (cstrato@EUnet.at)
Date: Wed, 29 Dec 1999 21:00:50 +0100
Subject: [R] Large data files
Message-ID: <386A686F.B24F1DC0@EUnet.at>

Dear R and S-Plus users:

Currently I am using:
at work: "S-Plus 2000 Pro" on a PC: Pentium II/350MHz, 256 MB RAM,
running Win NT
at home: "R" on my Mac PowerBook G3/292MHz, 128 MB RAM, running LinuxPPC

Currently, at home I am trying to import a table(nrow=302500, ncol=6)
which I have to do
for each column extra because of memory problems. I have partially to
use the columns,
partially I have to convert them in to matrices(550 x 550) for doing
calculations.
Ultimately, I have to import many (ca 20-100) of these tables, which
will be impossible
on my current machines due to memory limitations.

My question now is the following:

At work I have access to the following multiprocessor machines:
a, Compaq Proliant Server: 4 x Pentium II/450MHz, 2 GB RAM, Win NT
b, Sun Enterprise 450 Server: 4 x SPARC/??MHz, 2 GB RAM, Solaris 2.6

For testing purposes I would like to install "R":
1, Can R take advantage of multiprocessor machines?
2, Which machine would be better suited to run R on?

Finally, the question is:
Is R or S-Plus better suited for handling such large data?
Would "S-Plus 2000" for Win NT or "S-Plus 5" for Unix better suited?
Can S-Plus take advantage of multiprocessor machines?

Thank you in advance for your help
and Happy New Year 2000 (hopefully not 1900)
Christian Stratowa, Ph.D., Vienna


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thomas at biostat.washington.edu  Wed Dec 29 21:33:10 1999
From: thomas at biostat.washington.edu (Thomas Lumley)
Date: Wed, 29 Dec 1999 20:33:10 +0000 (GMT)
Subject: [R] Large data files
In-Reply-To: <386A686F.B24F1DC0@EUnet.at>
Message-ID: <Pine.LNX.4.10.9912292012060.3281-100000@gimel.biostat.washington.edu>

On Wed, 29 Dec 1999 cstrato at EUnet.at wrote:

> Dear R and S-Plus users:
> 
> Currently I am using:
> at work: "S-Plus 2000 Pro" on a PC: Pentium II/350MHz, 256 MB RAM,
> running Win NT
> at home: "R" on my Mac PowerBook G3/292MHz, 128 MB RAM, running LinuxPPC
> 
> Currently, at home I am trying to import a table(nrow=302500, ncol=6)
> which I have to do
> for each column extra because of memory problems. I have partially to
> use the columns,
> partially I have to convert them in to matrices(550 x 550) for doing
> calculations.
> Ultimately, I have to import many (ca 20-100) of these tables, which
> will be impossible
> on my current machines due to memory limitations.
> 
> My question now is the following:
> 
> At work I have access to the following multiprocessor machines:
> a, Compaq Proliant Server: 4 x Pentium II/450MHz, 2 GB RAM, Win NT
> b, Sun Enterprise 450 Server: 4 x SPARC/??MHz, 2 GB RAM, Solaris 2.6
> 
> For testing purposes I would like to install "R":
> 1, Can R take advantage of multiprocessor machines?

Not really. You can run multiple copies of R, which lets you get four
things done at once, but R is not multithreaded.

> 2, Which machine would be better suited to run R on?

Either would work. We have done some very limited comparisons of speed on
machines here: the various test suites for the survival5 package run at
about the same speed on a new Sun Enterprise server and on a Pentium
II/400 under Linux, and run faster on a Pentium III/500 under WinNT, and
slower on an eighteen-month old Sun Enterprise 450 server.

The speeds are close enough that other factors are probably more important
(which system you prefer, how many other people you will annoy by taking
over the machine)

If you are doing a lot of simple linear algebra the Sun Workshop compilers
might be expected to have some advantages over gcc: I haven't found any
examples where it matters, but I don't work with very large matrices much.


> Finally, the question is:
> Is R or S-Plus better suited for handling such large data?
> Would "S-Plus 2000" for Win NT or "S-Plus 5" for Unix better suited?
> Can S-Plus take advantage of multiprocessor machines?

Neither R nor S-PLUS is particularly suited to handling large data.  I
believe S-PLUS has some multithreading, but that its main computations are
still done by a single processor. However, this is perhaps not the best
list to get information about S-PLUS.

You would be better off splitting the data into pieces using some other
program.  Either S-PLUS or R will handle 550x550 matrices perfectly
happily if you have that much memory.


Thomas Lumley
Assistant Professor, Biostatistics
University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy.elvey at paradise.net.nz  Wed Dec 29 23:37:50 1999
From: andy.elvey at paradise.net.nz (Andy Elvey)
Date: Thu, 30 Dec 1999 11:37:50 +1300
Subject: [R] Large data files
References: <Pine.LNX.4.10.9912292012060.3281-100000@gimel.biostat.washington.edu>
Message-ID: <386A8D3D.4EFDEB29@paradise.net.nz>



Thomas Lumley wrote:

> Neither R nor S-PLUS is particularly suited to handling large data.  I
> believe S-PLUS has some multithreading, but that its main computations are
> still done by a single processor. However, this is perhaps not the best
> list to get information about S-PLUS.
>
> You would be better off splitting the data into pieces using some other
> program.  Either S-PLUS or R will handle 550x550 matrices perfectly
> happily if you have that much memory.
>
> Thomas Lumley
> Assistant Professor, Biostatistics
> University of Washington, Seattle
>
> ************

  One other possibility that may be worth a try is the language "Yorick" which is
specifically designed with array/matrix processing in mind.  Try the following URL
-

 ftp://ftp-icf.llnl.gov/pub/Yorick/yorick-ad.html

( Hope this suggestion doesn't offend on an R-help mailing list ... I am a keen
(although new) R user but am also aware of a few other ways of solving
problems...:-)




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From munsaka at earthlink.net  Thu Dec 30 06:08:14 1999
From: munsaka at earthlink.net (Melvin S. Munsaka)
Date: Wed, 29 Dec 1999 21:08:14 -0800
Subject: [R] Does R have a function for constrained minimiztion
Message-ID: <386AE8BE.7B07@earthlink.net>

Hi, 

I was wondering if there is a function in R for constrained minimization
that is similar to the nlminb function in Splus. 

Thanks,

Melvin Munsaka
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Dec 30 09:33:00 1999
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 30 Dec 1999 08:33:00 +0000 (GMT)
Subject: [R] Does R have a function for constrained minimiztion
In-Reply-To: <386AE8BE.7B07@earthlink.net>
Message-ID: <Pine.GSO.4.05.9912300831590.14116-100000@auk.stats>

On Wed, 29 Dec 1999, Melvin S. Munsaka wrote:

> I was wondering if there is a function in R for constrained minimization
> that is similar to the nlminb function in Splus. 

Not yet. Hopefully we will have something in a couple of months.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From natov at nato-victims.com  Fri Dec 31 19:21:52 1999
From: natov at nato-victims.com (inf)
Date: Fri, 31 Dec 1999 11:21:52 -0700 (MST)
Subject: [R] Visit www.markojan.co.yu 
Message-ID: <199912311821.LAA29531@nato-victims.com>

Posetite www.markojan.co.yu

[Nickeldon inc. www.nickeldon.com]
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


