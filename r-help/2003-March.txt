From tlumley at u.washington.edu  Sat Mar  1 01:47:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat Mar  1 01:47:03 2003
Subject: [R] Splitting survivor episodes
In-Reply-To: <Pine.GSO.4.33.0302281457100.24482-100000@honoria.la.utexas.edu>
Message-ID: <Pine.A41.4.44.0302281638430.291640-100000@homer01.u.washington.edu>

On Fri, 28 Feb 2003, Daniel A. Powers wrote:

> To R-list --
>
> Does anyone know of an R function that will create split-episode data from
> single spell event/duration data according to user-defined time intervals?
>
> Example: original data
>  t     d  x
> ------------
>  6     0  x1
>  5     1  x2
>
> Split using intervals [0,3) [3,infty) (or cutpoint at 3)
>
>  start end    event
>  _t0    _t     _d   _x  episode
>    0     3      0   x1   1
>    3     6      0   x1   2
>    0     3      0   x2   1
>    3     5      1   x2   2
>

No.

I do something like

   n<-nrow(data)
   data<-rbind(data,data)
   data$episode<-rep(c(1,2),each=n)
   data$start<-rep(c(0,CUT),each=n)
   data$end <- c(rep(CUT,n), data$t)

   ##drop episodes after death
   data<-subset(data, start<t )

   ## define event
   data$event <- with(data, ifelse(t<end, event, 0))

   ## tidy up end times
   data$end <- pmin(data$t, data$end)


	-thomas



From r.hankin at auckland.ac.nz  Sat Mar  1 01:58:03 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Sat Mar  1 01:58:03 2003
Subject: [R] Tabulating
In-Reply-To: <000801c2df19$e2cc6e20$a110a8c0@djingisob7lo8t>
	(Patrik.Waldmann@djingis.se)
References: <000801c2df19$e2cc6e20$a110a8c0@djingisob7lo8t>
Message-ID: <200303010057.h210vdvI016544@r.hankin.sges.auckland.ac.nz>

Hi

I think Andy Liaw's suggestion can be modified to handle my
interpretation of Patrik's question; try:

R> data
 [1] 10 10 11 10 12 11 10 12 11 11 10 11
R> table(c(data,NA),c(NA,data))  -> x.tab
R> c(diag(x.tab), x.tab[upper.tri(x.tab)] + x.tab[lower.tri(x.tab)])
10 11 12 NA NA NA 
 1  1  0  5  2  2 
R> 

so the "5" means that there are five "10 11" or "11 10" pairs 


best


rksh



> 
> Hello,
> 
> I wonder if someone could send me suggestions on how to solve the following problem:
> 
> I have a vector of an arbitrary size (ex. data<-c(10,10,11,10,12,11,10,12,11,11,10,11)) and use the table function, which gives the following result
> 10  11  12
> 5    5     2
> 
> that's fine, but what I would like to do now is: 
> 
> construct new classes based on the number of classes from table, 10 10, 11 11, 12 12, 10 11, 10 12, 11 12. After that I would like to do tabulation on the pairs in data, and positions in pairs should be unimportant: 10 11 should be treated as the same class as 11 10.
> So the following result should be obtained:
> 10 10, 11 11, 12 12, 10 11, 10 12, 11 12
> 1 , 1 , 0 , 2 , 1 , 2
> 
> Remeber that it should be possible to do for an arbitrary number of classes.
> 
> Best regards,
> 
> Patrik.Waldmann at djingis.se


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042



From smyth at wehi.edu.au  Sat Mar  1 02:21:03 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Sat Mar  1 02:21:03 2003
Subject: [R] is.empty for formal class object
Message-ID: <5.2.0.9.1.20030301114401.00ac1250@imaphost.wehi.edu.au>

I'd like to construct a function is.empty(x) which would work on arbitrary 
objects, and would tell me whether the object contains any data. I think 
that I can write a function which will recurse down through all the slots 
of x (and slots of slots) until it reaches objects of elementary type 
(NULL, character, numeric, logical, matrix, function, data.frame and 
possibly others) and then tests for length zero or nullness.

But does such a function already exist? Or is there a cleverer or more 
direct way to do it?

I've looked through the online help for the methods package, and I've done 
a keyword search through the R help for "empty" without finding something 
that looks relevant.

Thanks
Gordon



From hb at maths.lth.se  Sat Mar  1 02:56:02 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sat Mar  1 02:56:02 2003
Subject: [R] R (external ?) reference
In-Reply-To: <Pine.LNX.4.44.0302280829270.11161-100000@itasca.stat.uiowa.edu>
Message-ID: <001701c2df95$ada443e0$7341a8c0@alpha.wehi.edu.au>

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Luke Tierney
> Sent: den 1 mars 2003 01:31
> To: Laurent Gautier
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] R (external ?) reference
> 
> 
> On Fri, 28 Feb 2003, Laurent Gautier wrote:
> 
> > Dear List,
> > 
> > I found a documentation on the web that mentions things like 'R 
> > references' (http://www.stat.uiowa.edu/~luke/R/simpleref.html).
> > 
> > However, I could not find the R_MakeReference and friends 
> in R... Does 
> > anyone knows more about that ?
> > 
> 
> It's not as clear as it could be in that document but that 
> part was just a proposal.  It has not been implemented.  
> Something at the pure R level along these lines can easily be 
> implemented with environments; something a bit more 
> sophisticated may eventually make it into the methods package.

For details on how environments can be used to implement/emulate
references using plain R code (as Luke suggest) see "Implementing
support for references in [R]"
(http://www.maths.lth.se/help/R/ImplementingReferences/). See especially
section 4.1 "Using an environment directly" and 4.2 "Encapsulating an
enviroment in a list or in an attribute", which points out the important
fact that you should wrap up your environment variable in a list to be
able to assign a (S3) class to it.

Cheers

Henrik Bengtsson
Lund University, Sweden
 
> luke
> 
> -- 
> Luke Tierney
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From l12345p2000 at yahoo.com  Sat Mar  1 16:58:02 2003
From: l12345p2000 at yahoo.com (Long Z)
Date: Sat Mar  1 16:58:02 2003
Subject: [R] error message from gls(), unstructured in lower triangle, identical diagonal, help.
Message-ID: <20030301155745.71704.qmail@web21004.mail.yahoo.com>

Hi, nlme users,

I am fitting a model for repeated measures, using
gls(). The var-cov structure is UNSTRUCTURED in lower
triangle and identical for the diagonal, for which I
still have no idea how to fit using PROC MIXED.

The error message is as follows:
Error in "coef<-.corNatural"(*tmp*, value =
log((cStNatPar + 1)/(1 - cStNatPar))) : 
        NA/NaN/Inf in foreign function call (arg 1)

I have no idea why that will happen, since the same
codes work well for other similar data.

The data and the codes are as follows.

I am wondering whether I can get help here.
Thanks a lot!

Peng Liu
------------------------------
Peng Liu                      |
Division of Statistics        |
Northern Illinois University  |
De Kalb, IL 60115, USA        |
E-mail: pliu at math.niu.edu     |
------------------------------


########Here are the codes and data##########
sample <-
cbind(c(1.831573,0.820619,2.081226,1.441899,-1.316942,-0.9153977,-2.615172,0.6244147,-1.384212,0.2537837,-0.008428624,-0.4111116,-0.919574,-1.69364,-0.7349749,-1.608629,-0.03456573,-2.322608,-0.7962107,-1.161889,0.8634877,1.062846,-0.7290675,0.1593192,0.5629082,-0.2773188,-0.8110306,1.516512,0.3191615,2.066002,1.492041,-0.2712102,-0.907483,-1.251194,0.1067267,-1.893993,-0.05563948,0.3225586,0.9530283,-0.9470236,
-1.183466,-0.8254096,0.2745802,-0.09157914,-1.137616,-1.010385,-0.3922027,-1.622668,-0.878803,-0.7586166,0.4662699,-0.3748910,-1.181506,-0.009744484,-0.2503955,-0.167983,0.4440732,0.5867642,1.074624,0.4537496,2.009861,0.1448494,-0.8916145,0.6610586,-1.306448,-1.301082,-0.7900978,-1.809101,-0.5169003,-0.4365317,0.6808186,-0.1231397,-2.118134,-1.166811,-0.9272828,-2.372523,0.1543802,1.369601,0.2327486,1.138620,
-1.519021,-2.049833,0.7442267,-0.7025775,0.04518552,-1.169271,-0.09720012,0.3490697,-1.229996,-1.631016,-3.404595,-2.917325,0.081256,-0.05817446,0.8030733,0.03814584,-0.7191387,0.9275563,-1.138103,-1.531016,0.5430816,1.144775,-0.7662923,0.3517145,2.241299,0.4542238,1.166567,1.269506,-2.063319,-1.661397,-2.112718,-2.168209,-0.01513848,-1.018248,-0.375433,-1.830825,2.301888,1.649184,2.666166,2.497785,
0.3834129,0.5868564,-0.874599,-0.351699,-0.3735526,0.7182726,0.1732434,1.384503,1.377456,1.85285,0.340099,1.549716,-0.3473703,0.8082551,0.3906645,-0.1855657,-1.873152,-1.932688,-2.061348,-0.7435891,-1.465873,-2.190746,-0.4280419,-0.7422656,-0.8705315,-0.4861004,0.414328,-1.606564,1.138383,2.173107,1.099662,0.6287685,-0.9623125,0.4057413,0.2073339,1.087254,0.6524806,-0.3654337,0.2532572,0.0263857),
c(37,37,37,37,19,19,19,19,13,13,13,13,6,6,6,6,9,9,9,9,27,27,27,27,33,33,33,33,36,36,36,36,12,12,12,12,26,26,26,26,
14,14,14,14,8,8,8,8,17,17,17,17,11,11,11,11,28,28,28,28,35,35,35,35,4,4,4,4,21,21,21,21,3,3,3,3,31,31,31,31,
22,22,22,22,15,15,15,15,2,2,2,2,23,23,23,23,25,25,25,25,30,30,30,30,39,39,39,39,1,1,1,1,10,10,10,10,40,40,40,40,
18,18,18,18,32,32,32,32,34,34,34,34,24,24,24,24,5,5,5,5,7,7,7,7,16,16,16,16,38,38,38,38,29,29,29,29,20,20,20,20),
c(1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,
1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,
1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,
1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4))
sample <- as.data.frame(sample)
names(sample) <- c("y", "subj", "time")
sample <- groupedData(y~time | subj, data=sample)

sample.gls <- gls(y ~ 1, sample,
correlation=corSymm(form=~1|subj), weights=NULL)

Error in "coef<-.corNatural"(*tmp*, value =
log((cStNatPar + 1)/(1 - cStNatPar))) : 
        NA/NaN/Inf in foreign function call (arg 1)



From Zhongming.Yang at cchmc.org  Sat Mar  1 17:27:03 2003
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Sat Mar  1 17:27:03 2003
Subject: [R] debug
Message-ID: <se6098df.011@mailx.chmcc.org>

Hi:

I use following code to smooth my data set, and use two command to
calculate the std for predict error. For me, I think the two command
used to calculate mod.std should be exactly the same. But the result is
different. Can anyone give me some clue on this?

mod.model = loess(modout ~ modin, span=0.1, degree=1,
control=loess.control(surface='interpolate', statistics='approximate',
trace.hat='approximate'));
modpre = predict(mod.model);
mod.std = sqrt(var(modout-modpre, na.rm=TRUE));     
(#mod.std = sqrt(var(modout[1:length(modpre)] -
modpre[1:length(modpre)], na.rm=TRUE));)
print(mod.std);


Thanks 
Zhongming



From zynnel at yahoo.com  Sat Mar  1 22:13:03 2003
From: zynnel at yahoo.com (Hi from Zynnel)
Date: Sat Mar  1 22:13:03 2003
Subject: [R] calling R functions from C
In-Reply-To: <3E5C7396.3050209@statistik.uni-dortmund.de>
Message-ID: <20030301211240.63433.qmail@web11802.mail.yahoo.com>

Could anyone point me to a project that uses C as its
main language but invokes R functions/files? I would
like to look at its source code. Thanks!

Elena Zheleva



From zynnel at yahoo.com  Sat Mar  1 22:25:05 2003
From: zynnel at yahoo.com (Hi from Zynnel)
Date: Sat Mar  1 22:25:05 2003
Subject: [R] multiple plot overlay - dataframe
In-Reply-To: <E18nwNV-0001pq-00@smtp2.yaonline.es>
Message-ID: <20030301211852.70450.qmail@web11808.mail.yahoo.com>

Thank you for all the inputs!!! I haven't had the
chance to test them all but I will let you know which
one worked best when I do. 

Elena Zheleva



From mail at joeconway.com  Sun Mar  2 01:36:03 2003
From: mail at joeconway.com (Joe Conway)
Date: Sun Mar  2 01:36:03 2003
Subject: [R] calling R functions from C
In-Reply-To: <20030301211240.63433.qmail@web11802.mail.yahoo.com>
References: <20030301211240.63433.qmail@web11802.mail.yahoo.com>
Message-ID: <3E61514A.70109@joeconway.com>

Hi from Zynnel wrote:
> Could anyone point me to a project that uses C as its
> main language but invokes R functions/files? I would
> like to look at its source code. Thanks!
> 

PL/R (R Procedural Language for PostgreSQL) might give you a start:
   http://www.joeconway.com/plr/

There are several other good examples here:
   http://www.omegahat.org/download/R/packages/

HTH,

Joe



From laurent at cbs.dtu.dk  Sun Mar  2 05:40:04 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Sun Mar  2 05:40:04 2003
Subject: [R] 'methods' and "[<-"
Message-ID: <20030302044040.GA47655487@genome.cbs.dtu.dk>

Dear List,

I am trying to override the replace method "[<-" for
objects of class "matrix"... with little success...

Would anyone know where I am wrong ?

> library(methods)
> setReplaceMethod("[", "matrix", function(x, i, j, ..., value) {cat("I'm here.\n")})
[1] "[<-"
> m <- new("matrix", 0, 5, 2)
> m[1,1] <- 2
> 
# ..did not use my new method it seems



Thanks,


L/


PS: I am using R-1.6.2



From mkondrin at hppi.troitsk.ru  Sun Mar  2 09:10:04 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Sun Mar  2 09:10:04 2003
Subject: [R] Dynamically changing point's symbol in grid.points...
Message-ID: <3E61E6DF.3060101@hppi.troitsk.ru>

...does not work. Do 
k<-grid.points(c(0.1,0.2,0.3),c(0.1,0.2,0.3),pch=3,vp=viewport()) 
(symbol - +). Try to change it grid.edit(k, pch=1) (symbol - open 
circle). Get filled squares. pch from 0 to 25 produces the same output. 
pch="x" - works OK. Device - x11(), gtk() (from GtkDevice). R -1.6.1



From mkondrin at hppi.troitsk.ru  Sun Mar  2 10:32:02 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Sun Mar  2 10:32:02 2003
Subject: [R] optim
References: <Pine.LNX.4.44.0302280926590.23603-100000@gannet.stats>
Message-ID: <3E62687D.8000808@hppi.troitsk.ru>

Hello!
Although I agree that the functions used are a little tricky to deal 
with, it seems to me to be an odd way to use optim(). Wouldn't it be 
better just use uniroot?
What I have in mind is:
THETA[2] may be easily excluded from the equations. So we are left with 
2 functions and 2 unknowns (THETA[1,3]).
Here is simple example of how system with two equations and two unknowns 
can be solved. An idea is to find root along one variable and use this 
value to find root along other.

 > f1 <- function(x,y){
+   return(x*y-1)
+ }
 > f2 <- function(x,y){
+   return(x-y-2)
+ }
 > ff <- function(y,x){
+   Zero <- uniroot(f1,interval=c(-1,3),y=y)
+   return(f2(x=Zero$root,y=y))
+ }
 >
 > uniroot(ff,interval=c(0.4,0.6),x=0.8)
$root # y
[1] 0.4142135

$f.root
[1] 2.670726e-07

$iter
[1] 4

$estim.prec
[1] 6.103516e-05

Although it will take some time to find "right" intervals.

Good luck ...

ripley at stats.ox.ac.uk wrote:
> Do read the help page.  It says:
> 
>      `fnscale' An overall scaling to be applied to the value of `fn'
>           and `gr' during optimization. If negative, turns the problem
>           into a maximization problem. Optimization is performed on
>           `fn(par)/fnscale'.
> 
>      `parscale' A vector of scaling values for the parameters.
>           Optimization is performed on `par/parscale' and these should
>           be comparable in the sense that a unit change in any element
>           produces about a unit change in the scaled value.
> 
> You have not used either, AFAICS.
> 
> Also, I doubt if the function value returned by calls to integrate is a 
> smooth function of the parameters, so scaling is particularly important 
> here, and you may need to supply ndeps too.
> 
> Attempting to optimize blindly without supplying derivatives is asking far 
> too much of a computer program.
> 
> 
> On Fri, 28 Feb 2003, Remigijus Lapinskas wrote:
> 
> 
>>Dear all,
>>
>>I have a function MYFUN which depends on 3 positive parameters TETA[1],
>>TETA[2], and TETA[3]; x belongs to [0,1].
>>I integrate the function over [0,0.1], [0.1,0.2] and
>>[0.2,0.3] and want to choose the three parameters so that
>>these three integrals are as close to, resp., 2300, 4600 and 5800 as
>>possible. As I have three equations with three unknowns, I expect the
>>exact fit, i.e., the SS (see below) to be zero. However, the optim
>>function never gives me what I expect, the minimal SS value(=res$value)
>>never comes close to zero, the estimates of the parameters, res$par,
>>wildly depends on init etc.
>>I would be grateful for any comments on this miserable situation.
>>
>>aa <- c(2300,4600,5800)
>>init <- c(2.5,8000,0.84) # initial values of parameters
>>print(init)
>>###################
>>myfun <- function(x,TETA) TETA[2]*(((1-x)^(-1/TETA[3]))-
>>1)^(1/TETA[1])
>>###################
>>x <- seq(0,0.3,by=0.01)
>>plot(x,myfun(x,init),type="l")
>>###################
>>LSS <- function(teta,aa)
>>{
>>integr <- numeric(3)
>>   for(i in 1:3)
>>   {integr[i] <- 10*integrate(myfun,
>>   lower=(i-1)/10,upper=i/10,TETA=teta)$value
>>   }
>>SS <- sum((integr-aa)^2) # SS=Sum of Squares
>>SS
>>}
>>####################
>>res <- optim(init,LSS,aa=aa,
>>method = "L-BFGS-B",lower=c(0,0,0.5))
>>print(res$par)
>>print(res$value)
>>
>>
>>
>>>source("C:/Program Files/R/integral.R")
>>
>>[1]    2.50      7000.00         0.84        # initial
>>[1]    2.3487221 6999.9999823    0.5623628   # final
>>[1] 75613.05                                 # minSS
>>
>>>source("C:/Program Files/R/integral.R")
>>
>>[1]     2.5      15000            0.84       # initial
>>[1]     2.125804 14999.999747     2.241179   # final
>>[1] 50066.35                                 # minSS
>>
>>
>>
>>Best regards,
>>Remigijus                          mailto:remigijus.lapinskas at maf.vu.lt
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
>



From mkondrin at hppi.troitsk.ru  Sun Mar  2 10:57:03 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Sun Mar  2 10:57:03 2003
Subject: [R] optim
References: <Pine.LNX.4.44.0303020945220.28019-100000@gannet.stats>
Message-ID: <3E626E1A.8050806@hppi.troitsk.ru>

ripley at stats.ox.ac.uk wrote:
> You are not solving the same problem, which is more than a little `odd'.


Why?

 >>> want to choose the three parameters so that
these three integrals are as close to, resp., 2300, 4600 and 5800 as
possible. As I have three equations with three unknowns, I expect the
exact fit, i.e., the SS (see below) to be zero.



From swisdom at techemail.com  Sun Mar  2 15:42:03 2003
From: swisdom at techemail.com (Steve Wisdom)
Date: Sun Mar  2 15:42:03 2003
Subject: [R] A quirk in `transform'?
Message-ID: <20030302141144.9918D3A5E@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030302/e2e089c7/attachment.pl

From darryl at hpli.hpl.hp.com  Sun Mar  2 16:20:04 2003
From: darryl at hpli.hpl.hp.com (Darryl Greig)
Date: Sun Mar  2 16:20:04 2003
Subject: [R] model.frame.default problem in function definition
Message-ID: <001401c2e0cf$9c50ac60$9e09b00f@hpli.hpl.hp.com>

Could someone point me in the right direction for the following issue:

A function is defined as follows:

	tfun <- function(dat)
	  {
	    fmla <- as.formula("y~x+z")
	    dat2 <- dat
	    mdl <- lm(fmla,dat2)
	    mdl <- step(mdl)
	  }

Then the following code

	dat <- data.frame(x=1:10,z=1:10,y=(1:10)^2+10*(1:10))
	tfun(dat)

generates the output

	Start:  AIC= 43.67
	 y ~ x + z

	Error in model.frame.default(formula = y ~ z, data = dat2,
drop.unused.levels = TRUE) :
		Object "dat2" not found

Any help or pointers gratefully accepted.

Thanks,
Darryl Greig (darryl at hpli.hpl.hp.com)



From p.dalgaard at biostat.ku.dk  Sun Mar  2 16:26:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun Mar  2 16:26:03 2003
Subject: [R] A quirk in `transform'?
In-Reply-To: <20030302141144.9918D3A5E@sitemail.everyone.net>
References: <20030302141144.9918D3A5E@sitemail.everyone.net>
Message-ID: <x2d6l9sshz.fsf@biostat.ku.dk>

Steve Wisdom <swisdom at techemail.com> writes:

> A quirk in `transform'? 
..
> > transform(df,x=x)
> Error in transform(df, x = x) : Object "x" not found

Yes (or in argument matching). "x" names the object and thus cannot be
used again as a tag. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Sun Mar  2 17:18:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Mar  2 17:18:02 2003
Subject: [R] model.frame.default problem in function definition
In-Reply-To: <001401c2e0cf$9c50ac60$9e09b00f@hpli.hpl.hp.com>
Message-ID: <Pine.LNX.4.44.0303021604020.28217-100000@gannet.stats>

This works in R-devel, for which NEWS says

    o   step(), add1.default() and drop1.default() now work somewhat
        better if called from a function.

It's mainly a scoping problem, related to changes made way back in 1.2.x.

However, it is also an bad example, as z is really excluded in the fit.
stepAIC in the latest MASS (VR_7.0-11) will work, but warns about this.
I hope that this is just an over-simplification of the real problem.

On Sun, 2 Mar 2003, Darryl Greig wrote:

> Could someone point me in the right direction for the following issue:
> 
> A function is defined as follows:
> 
> 	tfun <- function(dat)
> 	  {
> 	    fmla <- as.formula("y~x+z")
> 	    dat2 <- dat
> 	    mdl <- lm(fmla,dat2)
> 	    mdl <- step(mdl)
> 	  }
> 
> Then the following code
> 
> 	dat <- data.frame(x=1:10,z=1:10,y=(1:10)^2+10*(1:10))
> 	tfun(dat)
> 
> generates the output
> 
> 	Start:  AIC= 43.67
> 	 y ~ x + z
> 
> 	Error in model.frame.default(formula = y ~ z, data = dat2,
> drop.unused.levels = TRUE) :
> 		Object "dat2" not found
> 
> Any help or pointers gratefully accepted.
> 
> Thanks,
> Darryl Greig (darryl at hpli.hpl.hp.com)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From remigijus.lapinskas at maf.vu.lt  Sun Mar  2 17:49:03 2003
From: remigijus.lapinskas at maf.vu.lt (Remigijus Lapinskas)
Date: Sun Mar  2 17:49:03 2003
Subject: [R] optim
References: <3E626E1A.8050806@hppi.troitsk.ru>
Message-ID: <19783.030302@maf.vu.lt>

Sunday, March 02, 2003, 9:48:26 PM, you wrote:

MK> ripley at stats.ox.ac.uk wrote:
>> You are not solving the same problem, which is more than a little `odd'.

MK> Why?

MK>  >>> want to choose the three parameters so that
MK> these three integrals are as close to, resp., 2300, 4600 and 5800 as
MK> possible. As I have three equations with three unknowns, I expect the
MK> exact fit, i.e., the SS (see below) to be zero.

Good evening to all!

In fact, I want to estimate three unknown parameters TETA[1],TETA[2]
(the scale parameter) and TETA[3]. What I know is 10 numbers
aa <- c(2300,4600,5800,
7100,...,37700) and these are the empirical counterparts of
the integrals over [0,0.1],...[0.9,1]. I don't know whether this is
correct but in order to find the parameters I minimize the
sum((integr-aa)^2) (kind of the "moment method"). As I had problems
with optim, I reduced the problem to three intervals.

I have to admit, I'm still fighting with optim. Following Prof
Ripley's suggestion, I replaced

res <- optim(init,LSS,aa=aa,method = "L-BFGS-B",lower=c(0,0,0.5))

by

res <- optim(init,LSS,aa=aa,method = "L-BFGS-B",lower=c(0,0,0.5),
control=list(parscale=c(1,1000,1)))

Now I have

> source("C:/Program Files/R/integral.R")
[1]     2.50      7000.00         0.84       # initial
[1]     2.052587 66734.476822    42.110597   # final
[1] 42820.43

instead of what I had earlier

>[1]    2.50      7000.00         0.84        # initial
>[1]    2.3487221 6999.9999823    0.5623628   # final
>[1] 75613.05

Now SS=42820, but it is still far from zero. I agree, I did not
implemented all what I was advised to, but it could take some time.

Many thanks for the help.
Remigijus

***************************************************
***************************************************


>Do read the help page.  It says:
>
> [...]
>
>`parscale' A vector of scaling values for the parameters.
>          Optimization is performed on `par/parscale' and these should
>          be comparable in the sense that a unit change in any element
>          produces about a unit change in the scaled value.

******************************************************
******************************************************

>>Dear all,
>>
>>I have a function MYFUN which depends on 3 positive parameters TETA[1],
>>TETA[2], and TETA[3]; x belongs to [0,1].
>>I integrate the function over [0,0.1], [0.1,0.2] and
>>[0.2,0.3] and want to choose the three parameters so that
>>these three integrals are as close to, resp., 2300, 4600 and 5800 as
>>possible. As I have three equations with three unknowns, I expect the
>>exact fit, i.e., the SS (see below) to be zero. However, the optim
>>function never gives me what I expect, the minimal SS value(=res$value)
>>never comes close to zero, the estimates of the parameters, res$par,
>>wildly depends on init etc.
>>I would be grateful for any comments on this miserable situation.
>>
>>aa <- c(2300,4600,5800)
>>init <- c(2.5,8000,0.84) # initial values of parameters
>>print(init)
>>###################
>>myfun <- function(x,TETA) TETA[2]*(((1-x)^(-1/TETA[3]))-
>>1)^(1/TETA[1])
>>###################
>>x <- seq(0,0.3,by=0.01)
>>plot(x,myfun(x,init),type="l")
>>###################
>>LSS <- function(teta,aa)
>>{
>>integr <- numeric(3)
>>   for(i in 1:3)
>>   {integr[i] <- 10*integrate(myfun,
>>   lower=(i-1)/10,upper=i/10,TETA=teta)$value
>>   }
>>SS <-  # SS=Sum of Squares
>>SS
>>}
>>####################
>>res <- optim(init,LSS,aa=aa,
>>method = "L-BFGS-B",lower=c(0,0,0.5))
>>print(res$par)
>>print(res$value)
>>
>>
>>
>>>source("C:/Program Files/R/integral.R")
>>
>>[1]    2.50      7000.00         0.84        # initial
>>[1]    2.3487221 6999.9999823    0.5623628   # final
>>[1] 75613.05                                 # minSS
>>
>>>source("C:/Program Files/R/integral.R")
>>
>>[1]     2.5      15000            0.84       # initial
>>[1]     2.125804 14999.999747     2.241179   # final
>>[1] 50066.35                                 # minSS
>>



From djw1005 at cam.ac.uk  Sun Mar  2 19:34:03 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Sun Mar  2 19:34:03 2003
Subject: [R] ESS+R not closing gracefully
Message-ID: <Pine.SOL.3.96.1030302165352.27074A-100000@draco.cus.cam.ac.uk>

I am having trouble with ESS+R. I don't know if it is an ESS
problem or an R problem, so I'm posting to this mailing list in
the first instance.

I am using R 1.6.2, Windows XP (latest updates installed), XEmacs 21.4,
and ESS 5.1.21. I have experienced the same problem under Windows 2000 and
recent versions of Emacs and ESS (though my current Windows XP
installation is from scratch, and I've lost details of my old
configuration).

I start up XEmacs. I press M-R to start an R session. I straightaway do

> quit()

and it quits cleanly.

Now I try something else. I start up XEmacs. I press M-R to start an R
session. I do

> hist(rnorm(10))
> dev.off()
null device
          1
> quit()
Save workspace image? [y/n/c]: n

and then it fails to quit. The Windows task manager tells me that the
process Rterm.exe is taking up 95% or so of CPU time. If I forcibly quit
it, using the Windows task manager, I see in the XEmacs window:

Process R exited abnormally with code 1 at <time>.

(I can't see any reason why, even if there is a problem, Rterm should
seemingly loop endlessly; that is why I am posting to this mailing list in
the first instance.) 

If, from the Windows command prompt, I run rterm, and do 

> hist(rnorm(10))
> dev.off()
> quit()

it quits cleanly.

In case it is relevant, I have made one change to the ESS file
ess-site.el: I added

(setq-default inferior-R-program-name 
  "c:\\program files\\R\\bin\\Rterm.exe")

(since otherwise it couldn't find Rterm.exe, even though it is on my
path); also, my emacs init file init.el reads thus:

(load "c:/program files/xemacs/xemacs-packages/lisp/ess/ess-site")
(setq comint-scroll-to-bottom-on-output t)
(setq ess-ask-for-ess-directory nil)
(setq ess-pre-run-hook '((lambda () (setq S-directory
default-directory))))
(setq ess-source-directory (expand-file-name "~/temp/"))
(global-set-key [(shift return)] 'ess-eval-paragraph)

Damon.



From rossini at blindglobe.net  Sun Mar  2 19:53:03 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Sun Mar  2 19:53:03 2003
Subject: [R] ESS+R not closing gracefully
In-Reply-To: <Pine.SOL.3.96.1030302165352.27074A-100000@draco.cus.cam.ac.uk> (Damon
 Wischik's message of "Sun, 2 Mar 2003 18:33:50 +0000 (GMT)")
References: <Pine.SOL.3.96.1030302165352.27074A-100000@draco.cus.cam.ac.uk>
Message-ID: <87isv1wqm5.fsf@jeeves.blindglobe.net>

Damon Wischik <djw1005 at cam.ac.uk> writes:


> I am having trouble with ESS+R. I don't know if it is an ESS
> problem or an R problem, so I'm posting to this mailing list in
> the first instance.

Actually, it might be an Emacs problem -- or an R problem.  The fact
that R/ESS works under windows is simply amazing.  

Unfortunately, while I've seen it, I'm not sure how to solve it; it
isn't your configuration.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------------
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(CHANGE: monday/wednesday/friday locations are completely unpredictable.)



From baiyan at ece.ogi.edu  Sun Mar  2 20:46:02 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Sun Mar  2 20:46:02 2003
Subject: [R] question on - build R as a shared library
In-Reply-To: <87fzqc8srt.fsf@jeeves.blindglobe.net>
Message-ID: <Pine.GSO.4.44.0303021115410.9949-100000@ece.ogi.edu>

The thing is that even I didn't specify 'enable-shlib', I still get
libR.so but not libR.a, I must missed something here.
Please have a look at the logs below:

--------------------------------------------
%cd /disk/hopper/projects/class/cse514/R-1.6.2/
%make distclean
...
%./configure --prefix=/disk/hopper/projects/class/cse514/R-1.6.2/
...
%cd lib/R/bin
%ls
BATCH    LINK   REMOVE  Rd2txt  Rdindex  Sd2Rd  config   libtool
COMPILE  R      Rcmd    Rdconv  Rprof    build  f77      pager
INSTALL  R.bin  Rd2dvi  Rdiff   SHLIB    check  libR.so  texi2dvi
                                                ^^^^^^^

%cd /disk/hopper/projects/class/cse514/R-1.6.2
%make
...
--------------------------------------------

Yan


On Tue, 25 Feb 2003, A.J. Rossini wrote:

> Bai Yan <baiyan at ece.ogi.edu> writes:
>
>
> > Hi Dirk, thank you for the prompt reply.
> > I found libR.so. But how can I know whether it is build as shared or not.
>
> Traditionally, for linking purposes, libR.so would be a shared
> library, where as libR.a would be a static library.
>
> best,
> -tony
>
> --
> A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
> U. of Washington Biostatistics		rossini at u.washington.edu
> FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
> -------------- http://software.biostat.washington.edu/ ----------------
> FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
> UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
> (my tuesday/wednesday/friday locations are completely unpredictable.)
>



From baiyan at ece.ogi.edu  Sun Mar  2 20:57:04 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Sun Mar  2 20:57:04 2003
Subject: [R] how to uninstall R
In-Reply-To: <87fzqc8srt.fsf@jeeves.blindglobe.net>
Message-ID: <Pine.GSO.4.44.0303021155100.9949-100000@ece.ogi.edu>

After I used 'make distclean', I still can access R input 'R' command. How
could R be completely removed? must I delete all the directory?

Thanks,
Yan



From ligges at statistik.uni-dortmund.de  Sun Mar  2 21:06:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Mar  2 21:06:03 2003
Subject: [R] how to uninstall R
References: <Pine.GSO.4.44.0303021155100.9949-100000@ece.ogi.edu>
Message-ID: <3E626431.BB3B4015@statistik.uni-dortmund.de>


Bai Yan wrote:
> 
> After I used 'make distclean', I still can access R input 'R' command. How
> could R be completely removed? must I delete all the directory?
> 
> Thanks,
> Yan

 make distclean 
cleans the sources from previous configures and makes, instead try:
 make uninstall

Uwe Ligges



From baiyan at ece.ogi.edu  Sun Mar  2 21:12:25 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Sun Mar  2 21:12:25 2003
Subject: [R] how to uninstall R
In-Reply-To: <3E626431.BB3B4015@statistik.uni-dortmund.de>
Message-ID: <Pine.GSO.4.44.0303021207490.9949-100000@ece.ogi.edu>

It cannot work.

%make uninstall
make: *** No rule to make target `uninstall'.  Stop.

Yan

On Sun, 2 Mar 2003, Uwe Ligges wrote:

>
>
> Bai Yan wrote:
> >
> > After I used 'make distclean', I still can access R input 'R' command. How
> > could R be completely removed? must I delete all the directory?
> >
> > Thanks,
> > Yan
>
>  make distclean
> cleans the sources from previous configures and makes, instead try:
>  make uninstall
>
> Uwe Ligges
>



From ligges at statistik.uni-dortmund.de  Sun Mar  2 21:20:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Mar  2 21:20:03 2003
Subject: [R] how to uninstall R
References: <Pine.GSO.4.44.0303021207490.9949-100000@ece.ogi.edu>
Message-ID: <3E626797.6DDFFECA@statistik.uni-dortmund.de>


Bai Yan wrote:
> 
> It cannot work.
> 
> %make uninstall
> make: *** No rule to make target `uninstall'.  Stop.

Well, you did a make distclean before, hence you Makefile has been
deleted.
It's generally a bad idea to have identical source path and installation
path, whcih appoears to be the case looking at your other mail on
R-Help. 

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Sun Mar  2 21:26:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Mar  2 21:26:03 2003
Subject: [R] question on - build R as a shared library
References: <Pine.GSO.4.44.0303021115410.9949-100000@ece.ogi.edu>
Message-ID: <3E62681E.47DB7D49@statistik.uni-dortmund.de>

Bai Yan wrote:
> 
> The thing is that even I didn't specify 'enable-shlib', I still get
> libR.so but not libR.a, I must missed something here.
> Please have a look at the logs below:
> 
> --------------------------------------------
> %cd /disk/hopper/projects/class/cse514/R-1.6.2/
> %make distclean
> ...
> %./configure --prefix=/disk/hopper/projects/class/cse514/R-1.6.2/
> ...
> %cd lib/R/bin
> %ls
> BATCH    LINK   REMOVE  Rd2txt  Rdindex  Sd2Rd  config   libtool
> COMPILE  R      Rcmd    Rdconv  Rprof    build  f77      pager
> INSTALL  R.bin  Rd2dvi  Rdiff   SHLIB    check  libR.so  texi2dvi
>                                                 ^^^^^^^

You builded that one on a previous run (look at the dates), I guess.
Making a clean build from sources results in neither libR.so nor libR.a.
The relevant thing is R.bin in that case.
I guess libR.so is left over from installing into the source tree, as
your --prefix statement implies ... (that's not a good idea).

Uwe Ligges



> %cd /disk/hopper/projects/class/cse514/R-1.6.2
> %make
> ...
> --------------------------------------------
> 
> Yan
> 
> On Tue, 25 Feb 2003, A.J. Rossini wrote:
> 
> > Bai Yan <baiyan at ece.ogi.edu> writes:
> >
> >
> > > Hi Dirk, thank you for the prompt reply.
> > > I found libR.so. But how can I know whether it is build as shared or not.
> >
> > Traditionally, for linking purposes, libR.so would be a shared
> > library, where as libR.a would be a static library.
> >
> > best,
> > -tony
> >
> > --
> > A.J. Rossini                          Rsrch. Asst. Prof. of Biostatistics
> > U. of Washington Biostatistics                rossini at u.washington.edu
> > FHCRC/SCHARP/HIV Vaccine Trials Net   rossini at scharp.org
> > -------------- http://software.biostat.washington.edu/ ----------------
> > FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
> > UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
> > (my tuesday/wednesday/friday locations are completely unpredictable.)
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From baiyan at ece.ogi.edu  Sun Mar  2 22:23:03 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Sun Mar  2 22:23:03 2003
Subject: [R] how to uninstall R
In-Reply-To: <3E626797.6DDFFECA@statistik.uni-dortmund.de>
Message-ID: <Pine.GSO.4.44.0303021319170.9949-100000@ece.ogi.edu>


On Sun, 2 Mar 2003, Uwe Ligges wrote:

>
>
> Bai Yan wrote:
> >
> > It cannot work.
> >
> > %make uninstall
> > make: *** No rule to make target `uninstall'.  Stop.
>
> Well, you did a make distclean before, hence you Makefile has been
> deleted.
> It's generally a bad idea to have identical source path and installation
> path, whcih appoears to be the case looking at your other mail on
> R-Help.
>


I was worrying about the disk place, since I don't have much left. I
thought using the same path might save some - because some source files
are actually copied to installation directory, maybe this is wrong. please
correct me!

Thanks,

Yan Bai



From ripley at stats.ox.ac.uk  Sun Mar  2 22:48:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Mar  2 22:48:03 2003
Subject: [R] how to uninstall R
In-Reply-To: <Pine.GSO.4.44.0303021319170.9949-100000@ece.ogi.edu>
Message-ID: <Pine.LNX.4.44.0303022138590.16084-100000@gannet.stats>

It is not actually necessary to install R: see the R-admin manual.

It is a very bad idea to install to use the source tree.  Just build in a 
directory != srcdir, as the R-admin manual explains.

You have read _all_ the R-admin manual, haven't you?  Just in case you 
haven't, please do as you are asked in INSTALL ...

  The main source of information on installation is the `R Installation
  and Administration Manual', an HTML copy of which is available as file
  `doc/html/R-admin.html'.  Please read that before installing R.  But
  if you are impatient, read on but please refer to the manual to
  resolve any problems.

!

On Sun, 2 Mar 2003, Bai Yan wrote:

> On Sun, 2 Mar 2003, Uwe Ligges wrote:
> 
> >
> >
> > Bai Yan wrote:
> > >
> > > It cannot work.
> > >
> > > %make uninstall
> > > make: *** No rule to make target `uninstall'.  Stop.
> >
> > Well, you did a make distclean before, hence you Makefile has been
> > deleted.
> > It's generally a bad idea to have identical source path and installation
> > path, whcih appoears to be the case looking at your other mail on
> > R-Help.
> >
> 
> 
> I was worrying about the disk place, since I don't have much left. I
> thought using the same path might save some - because some source files
> are actually copied to installation directory, maybe this is wrong. please
> correct me!
> 
> Thanks,
> 
> Yan Bai
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Sun Mar  2 23:26:02 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sun Mar  2 23:26:02 2003
Subject: [R] ESS+R not closing gracefully
In-Reply-To: <87isv1wqm5.fsf@jeeves.blindglobe.net>
References: <Pine.SOL.3.96.1030302165352.27074A-100000@draco.cus.cam.ac.uk>
 <Pine.SOL.3.96.1030302165352.27074A-100000@draco.cus.cam.ac.uk>
Message-ID: <5.1.0.14.2.20030302171935.01e060d8@mcmail.cis.mcmaster.ca>

Dear Tony and Damon,

I, too, have seen this problem (and other similar problems) occasionally. I 
don't really understand the source of the problem, but I think that it 
involves synchronization issues, and I find that inserting delays between 
operations seems to help. Take a look, for example, at the configuration 
files I've posted at 
<http://www.socsci.mcmaster.ca/jfox/Books/Companion/ESS/>, in particular 
the menu items for exiting. Finally, I find that problems are less common 
with Windows 2000 than with Windows 9x, but I gather this isn't your 
experience.

I hope that this helps,
  John

At 10:49 AM 3/2/2003 -0800, A.J. Rossini wrote:
>Damon Wischik <djw1005 at cam.ac.uk> writes:
>
>
> > I am having trouble with ESS+R. I don't know if it is an ESS
> > problem or an R problem, so I'm posting to this mailing list in
> > the first instance.
>
>Actually, it might be an Emacs problem -- or an R problem.  The fact
>that R/ESS works under windows is simply amazing.
>
>Unfortunately, while I've seen it, I'm not sure how to solve it; it
>isn't your configuration.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From l12345p2000 at yahoo.com  Sun Mar  2 23:35:04 2003
From: l12345p2000 at yahoo.com (P L)
Date: Sun Mar  2 23:35:04 2003
Subject: [R] error message from gls(), unstructured in lower triangle, identical diagonal, help.
In-Reply-To: <3E624562.9060603@sentoo.sn>
Message-ID: <20030302223034.74326.qmail@web21006.mail.yahoo.com>

> It's just by chance that this happened: the
> correlation you generated 
> was not strong enough, or was far from an
> unstructured correlation and 
> the algorithm did not converge (and you obtained
> this error message).
> Generate another sample might solve the problem.
> 

I think that you help me on the right point. Since
nlme() uses EM and Newton-Raphson in sequence, other
than that PROC MIXED uses Newton-Raphson only, as I
know, I am wondering whether PROC MIXED can circumvent
this situation. But the problem is as what I mentioned
in the first mail, which is I do not know how to
structure the var-cor with unstructured lower triangle
and identical diagonal in PROC MIXED.

> You might try "for fun" but it does not make much
> sense to me.

I am now doing a project which needs to generate
random samples, and fit them using mixed models with
different var-cov structures. If the problem that I
met is common, then I need to revise my codes a little
bit.

Thank you for breaking my problem.

Peng
------------------------------
Peng Liu                      |
Division of Statistics        |
Northern Illinois University  |
De Kalb, IL 60115, USA        |
E-mail: pliu at math.niu.edu     |
------------------------------



From chong at stat.purdue.edu  Sun Mar  2 23:41:09 2003
From: chong at stat.purdue.edu (Chong Gu)
Date: Sun Mar  2 23:41:09 2003
Subject: [R] gss_0.8-2
Message-ID: <200303022239.h22MdUP1123098@odds.stat.purdue.edu>

A new version of gss, version 0.8-2, is on CRAN now.  Numerous new
functionalities have been added since my last r-announce post.

An ssanova1 suite has been added since version 0.7-4.  It implements
low-dimensional approximations of the smoothing spline ANOVA models
of the ssanova suite.  ssanova1 scales much better than ssanova with
large sample sizes.

A gssanova1 suite is added for non Gaussian regression.  Similar to
ssanova1, it provides better scalability than gssanova.  Direct
cross-validation is used in gssanova1 instead of the indirect CV of
gssanova.  Currently, only three families are supported: binomial,
poisson, and Gamma; other families of gssanova will be added to
gssanova1 in the (near?) future.

An sshzd suite is added to fit hazard models using right-censored
lifetime data with possible left-truncation and covariates.  It
estimates log hazard as "bivariate" smooth functions of time and
covariates through penalized full likelihood.  It only takes static
covariates but accommodates interactions between time and covariates,
going beyond the proportional hazard models.

Utilities are provided for the calculation of a certain
Kullback-Leibler projection of cross-validated fits to "reduced model"
spaces, for the "testing" of model terms.  Projection code is provide
for ssanova1, gssanova1, ssden, and sshzd fits.

Further details are to be found in the documentations and the examples
therein.  As always, feature suggestions and bug reports will be
sincerely appreciated.

Chong Gu



From baiyan at ece.ogi.edu  Mon Mar  3 00:53:03 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Mon Mar  3 00:53:03 2003
Subject: [R] How to change the default library directory?
In-Reply-To: <Pine.GSO.4.21.0302261405410.14525-100000@fcsparc8.ncifcrf.gov>
Message-ID: <Pine.GSO.4.44.0303021535110.16151-100000@ece.ogi.edu>

I installed SJava package at $R_HOME/lib/R/library/

When I conduct library(SJava), I always need to explicitly specify the
library path, how could I change the default library path?

I have included the SJava path in the LD_LIBRARY_PATH variable as:
%echo $LD_LIBRARY_PATH
R_HOME/lib/R/library:R_HOME/lib/R/library/SJava/libs:/usr/java/j2sdk1.4.0_01/jr$

The result in R is as:
----------------------------------------------------
> library(SJava)
Error in library(SJava) : There is no package called `SJava'
> library(SJava,
lib.loc="/disk/hopper/projects/class/cse514/R/lib/R/library")
Warning message:
The Java machine is no longer initialized automatically. You must
explicitly load it in: firstlib(which.lib.loc, package)
>
----------------------------------------------------

Another question is about firstlib, what should I do to initialize the
Java machine here?

Your helps are really appreciated!!!

Yan Bai



From till.baumgaertel at epost.de  Mon Mar  3 02:25:03 2003
From: till.baumgaertel at epost.de (Till Baumgaertel)
Date: Mon Mar  3 02:25:03 2003
Subject: [R] Q: Best-Practice for Swing-GUI calling R-code on Windows?
Message-ID: <3E59772200012487@ppd27106.x.de>


org.omegahat.R.Java.REvaluator e = new
	org.omegahat.R.Java.REvaluator();

	Object val = e.eval("objects()");

	if(val != null) {
		String[] objects = (String[])val;
		for(int i = 0 ; i < objects.length; i++)
			System.err.println("("+i+") " + objects[i]);
	}
hello,

thanks to Philippe Grosjean's work I finally got SJava working (on Windows
XP!!), so that I can call Java-Code from within R.

Now I wanted to write a little Swing-GUI for entering some values and executing
a R-call with them. The results should also be presented in the Java-layer.
If possible, I'd like to see the R-console because I cat() some text what
I like (but not need) to see.

Now I'm wondering what's best practice for that? 

Trying to call R from within Java I get an exception:
java.lang.UnsatisfiedLinkError: eval
        at org.omegahat.R.Java.REvaluator.eval(Native Method)
        at org.omegahat.R.Java.REvaluator.eval(REvaluator.java:86)
        at org.omegahat.R.Java.REvaluator.eval(REvaluator.java:36)
        at SJavaTest.Main.main(Main.java:18)
Exception in thread "main" 

My SJava.DLL is in the PATH as well as the SJava-BaseDir and the Jars in
SJava/org/omegahat/Jars are in the classpath. any suggestions for solving
that?

Calling my GUI from within R is possible using .JNew and invoking show()
on the new instance. I can see the interface, but again I got stuck because
I cannot run R-code.

the code I'd like to try first is the very first example from the "Calling
R from Java"-Tutorial:
#########
org.omegahat.R.Java.REvaluator e = new
	org.omegahat.R.Java.REvaluator();

	Object val = e.eval("objects()");

	if(val != null) {
		String[] objects = (String[])val;
		for(int i = 0 ; i < objects.length; i++)
			System.err.println("("+i+") " + objects[i]);
	}
##########

could anybody give me a hint why this is not working or how i could solve
my original problem the "best" way??

thanks for any hints,
till



From ypeng at math.mun.ca  Mon Mar  3 03:16:03 2003
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Mon Mar  3 03:16:03 2003
Subject: [R] Use Rterm in rxvt for Cygwin?
Message-ID: <3E62BABA.60A65622@math.mun.ca>

Dear R users,

Does anyone notice that Rterm.exe does not work well with rxvt.exe,
an xterm emulator for Cygwin? It produces an error message window
with the following message:

    This program has performed an illegal operation
    and will be shut down.
    If the problem persists, contact the program vendor

It also prints "Signal 127" in rxvt window.

Rterm --ess, however, works. But its command line editing is awful
because it is for Emacs, not for a shell window.

Rterm.exe works well in a MS-DOS window. Because of limitations
of the MS-DOS window, I would like to use Rterm.exe in an rxvt
window. I am using R-1.6.2 and rxvt-2.7.2 on Win98se. Thanks for
any comments.

Paul.



From cadolph at fas.harvard.edu  Mon Mar  3 03:40:03 2003
From: cadolph at fas.harvard.edu (Christopher Adolph)
Date: Mon Mar  3 03:40:03 2003
Subject: [R] using data() in an example
Message-ID: <Pine.OSF.4.44.0303022132150.1387-100000@is07.fas.harvard.edu>

Hi all,

I'm trying to put together examples in an R package, and am having trouble
reading data from the package's data directory.  The data are in
comma-separated variable files, so to read a file like gw.csv, I include
in the data directory both bailey.csv and a file bailey.R which contains:

bailey <- read.csv("bailey.csv",na.strings=".");

so that typing

data(bailey)

should load the data from bailey.csv.

The problem is that the data is being read in "wrong", as a single column,
rather than a data frame with four columns.  I get:

   data.p1.p2.model
1        0.57,2,1,1
2        0.54,4,1,1
3        0.54,6,1,1
4        0.52,8,1,1
5       0.54,10,1,1
6       0.53,50,1,1
7        0.93,2,1,2
8        0.61,4,1,2
9        0.53,6,1,2
10       0.49,8,1,2
11      0.43,10,1,2
12      0.11,50,1,2
13       0.89,2,1,3
14       0.72,4,1,3
15       0.62,6,1,3
16       0.58,8,1,3
17      0.49,10,1,3
18      0.12,50,1,3
19       0.51,2,1,4
20       0.43,4,1,4
21       0.41,6,1,4
22       0.37,8,1,4
23      0.37,10,1,4
24      0.31,50,1,4

Which is wrong.  But if I use the very same command as above, but from the
command line (without the data() wrapper), it comes in right:

> read.csv("c:/progra~1/R/library/seemc/data/bailey.csv",na.strings=".")
   data p1 p2 model
1  0.57  2  1     1
2  0.54  4  1     1
3  0.54  6  1     1
4  0.52  8  1     1
5  0.54 10  1     1
6  0.53 50  1     1
7  0.93  2  1     2
8  0.61  4  1     2
9  0.53  6  1     2
10 0.49  8  1     2
11 0.43 10  1     2
12 0.11 50  1     2
13 0.89  2  1     3
14 0.72  4  1     3
15 0.62  6  1     3
16 0.58  8  1     3
17 0.49 10  1     3
18 0.12 50  1     3
19 0.51  2  1     4
20 0.43  4  1     4
21 0.41  6  1     4
22 0.37  8  1     4
23 0.37 10  1     4
24 0.31 50  1     4
>

What could be causing this?  I just want to get the example working; in
practice one wouldn't need to use the data() command for this package, but
it seems to be the only reliable way to get stuff out of the data
directory for running examples.  Any ideas?

Thanks

Chris

+-----------------------------------------------------------------+
Chris Adolph				   Department of Government
work:  617-496-4099			Littauer Center, North Yard
cell:  617-642-0683				 Harvard University
email:  cadolph at fas.harvard.edu		   Cambridge, MA 02138, USA
URLs:  www.fas.harvard.edu/~cadolph	   	  chris.adolph.name
+-----------------------------------------------------------------+



From susanms at stat.washington.edu  Mon Mar  3 05:39:02 2003
From: susanms at stat.washington.edu (Susan Shortreed)
Date: Mon Mar  3 05:39:02 2003
Subject: [R] samin and vmmin
Message-ID: <Pine.OSF.4.44.0303022024460.437413-100000@lisbon1.stat.washington.edu>

I am writing code in C and would like to call R's functions samin and
vmmin (optimization routines: simulated annealing and BFGS)

I do not understand how to create and pass in the function (as well as the
extra arguments it needs) I am optimizing.
I have read the R Extensions manual but it is still unclear to me.

Could you give me some pointers and/or direct me to some example code
which calls one of the optimizer functions and includes the definition of
the function to be optimized?

Thank you
Susan



From baiyan at ece.ogi.edu  Mon Mar  3 06:38:03 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Mon Mar  3 06:38:03 2003
Subject: REmbeddedPostgres question Re: [R] How to change the default library
 directory?
In-Reply-To: <Pine.GSO.4.44.0303021535110.16151-100000@ece.ogi.edu>
Message-ID: <Pine.GSO.4.44.0303022128300.24108-100000@ece.ogi.edu>

Hi,

I just figured out this problem by setting up the R_LIBS environment.
But a new question came up when I tried to install the REmbeddedPostgres
package. It seems this package must be installed in /usr/lib/R but cannot
be install into a user-specified library directory. Anybody here had such
experiences?

The error message is:
-------------------------------------------------

%%R CMD INSTALL -c -l $R_LIBS REmbeddedPostgres_0.2.tar.gz
* Installing *source* package 'REmbeddedPostgres' ...
creating cache ./config.cache
checking for crypt in -lcrypt... yes
You need to compile the R shared library 'libR.so'
in the R distribution (/usr/lib/R)
ERROR: configuration failed for package 'REmbeddedPostgres'

-------------------------------------------------

TIA,

Yan Bai


On Sun, 2 Mar 2003, Bai Yan wrote:

>
> I installed SJava package at $R_HOME/lib/R/library/
>
> When I conduct library(SJava), I always need to explicitly specify the
> library path, how could I change the default library path?
>
> I have included the SJava path in the LD_LIBRARY_PATH variable as:
> %echo $LD_LIBRARY_PATH
> R_HOME/lib/R/library:R_HOME/lib/R/library/SJava/libs:/usr/java/j2sdk1.4.0_01/jr$
>
> The result in R is as:
> ----------------------------------------------------
> > library(SJava)
> Error in library(SJava) : There is no package called `SJava'
> > library(SJava,
> lib.loc="/disk/hopper/projects/class/cse514/R/lib/R/library")
> Warning message:
> The Java machine is no longer initialized automatically. You must
> explicitly load it in: firstlib(which.lib.loc, package)
> >
> ----------------------------------------------------
>
> Another question is about firstlib, what should I do to initialize the
> Java machine here?
>
> Your helps are really appreciated!!!
>
> Yan Bai
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From baiyan at ece.ogi.edu  Mon Mar  3 07:53:03 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Mon Mar  3 07:53:03 2003
Subject: [R] $R_HOME
In-Reply-To: <Pine.GSO.4.44.0303022128300.24108-100000@ece.ogi.edu>
Message-ID: <Pine.GSO.4.44.0303022246560.26457-100000@ece.ogi.edu>

Suppose the R source file is at: /disk/R-1.6.2/
and R is installed at: /disk/R/

Which valud is $R_HOME?
1. /disk/
2. /disk/R-1.6.2
3. /disk/R/

I thought the answer is 3 but not sure. From the manual "R
installation and Administration", it says 'Choose a place to install
the R tree, let's call this place R_HOME'. Untar the source code.
This looks like No.1 is the correct answer because /disk/ is the place to
untar the source code. Please correct me if I am wrong. Thanks very much!

Yan



From ripley at stats.ox.ac.uk  Mon Mar  3 08:55:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Mar  3 08:55:04 2003
Subject: [R] Q: Best-Practice for Swing-GUI calling R-code on Windows?
In-Reply-To: <3E59772200012487@ppd27106.x.de>
Message-ID: <Pine.LNX.4.44.0303030740240.17885-100000@gannet.stats>

On Mon, 3 Mar 2003, Till Baumgaertel wrote:

> org.omegahat.R.Java.REvaluator e = new
> 	org.omegahat.R.Java.REvaluator();
> 
> 	Object val = e.eval("objects()");
> 
> 	if(val != null) {
> 		String[] objects = (String[])val;
> 		for(int i = 0 ; i < objects.length; i++)
> 			System.err.println("("+i+") " + objects[i]);
> 	}
> hello,
> 
> thanks to Philippe Grosjean's work I finally got SJava working (on Windows
> XP!!), so that I can call Java-Code from within R.

I don't think you have `got SJava working', as the error below is one
symptom of incomplete fixing of SJava.  (I am not sure what work of
Philippe Grosjean you are referring to, but I had to rewrite parts of the
Makefile.win as well as patch the R sources.  I sent the changes to 
Duncan TL back in November.)

There are patched sources and a compiled Windows binary version of SJava
for 1.6.2 at http://www.stats.ox.ac.uk/pub/bdr/SJava.  These were tested
pretty extensively last week, and the sources even work under R-devel
(1.7.0 to be).  They are prepared for a project I am involved with,
so there are no promises that they will stay available.  (There is even a 
binary for R-devel in the bin/windows/contrib/rw1070 area of CRAN.)


> Now I wanted to write a little Swing-GUI for entering some values and executing
> a R-call with them. The results should also be presented in the Java-layer.
> If possible, I'd like to see the R-console because I cat() some text what
> I like (but not need) to see.

Take a look at the installed examples in SJava (not all of which seem
operational).

> 
> Now I'm wondering what's best practice for that? 
> 
> Trying to call R from within Java I get an exception:
> java.lang.UnsatisfiedLinkError: eval
>         at org.omegahat.R.Java.REvaluator.eval(Native Method)
>         at org.omegahat.R.Java.REvaluator.eval(REvaluator.java:86)
>         at org.omegahat.R.Java.REvaluator.eval(REvaluator.java:36)
>         at SJavaTest.Main.main(Main.java:18)
> Exception in thread "main" 

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Mar  3 09:09:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Mar  3 09:09:04 2003
Subject: [R] samin and vmmin
In-Reply-To: <Pine.OSF.4.44.0303022024460.437413-100000@lisbon1.stat.washington.edu>
Message-ID: <Pine.LNX.4.44.0303030806390.17885-100000@gannet.stats>

nnet in bundle VR.

On Sun, 2 Mar 2003, Susan Shortreed wrote:

> I am writing code in C and would like to call R's functions samin and
> vmmin (optimization routines: simulated annealing and BFGS)
> 
> I do not understand how to create and pass in the function (as well as the
> extra arguments it needs) I am optimizing.
> I have read the R Extensions manual but it is still unclear to me.
> 
> Could you give me some pointers and/or direct me to some example code
> which calls one of the optimizer functions and includes the definition of
> the function to be optimized?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Mar  3 09:14:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Mar  3 09:14:05 2003
Subject: [R] Use Rterm in rxvt for Cygwin?
In-Reply-To: <3E62BABA.60A65622@math.mun.ca>
Message-ID: <Pine.LNX.4.44.0303030755070.17885-100000@gannet.stats>

Rterm is a Windows application.  It works fine in Windows tcsh and in 
Cygwin bash on Windows XP (and last time I looked, Windows 98 too).

I find that rxvt.exe does not work at all well on Windows XP. You should
send bug reports on it to Cygwin, not R.

There is an R console  Rgui, and the principal function of Rterm is to 
provide a batch use of R.  If you insist on using a long-obselete and 
primitive version of Windows, please use RGui.

On Sun, 2 Mar 2003, Paul Y. Peng wrote:

> Dear R users,
> 
> Does anyone notice that Rterm.exe does not work well with rxvt.exe,
> an xterm emulator for Cygwin? It produces an error message window
> with the following message:
> 
>     This program has performed an illegal operation
>     and will be shut down.
>     If the problem persists, contact the program vendor

That's rxvt, not Rterm.

> It also prints "Signal 127" in rxvt window.
> 
> Rterm --ess, however, works. But its command line editing is awful
> because it is for Emacs, not for a shell window.

No, there is no command-line editing at all and it is dangerous to use 
modes like that other than for their documented purpose.

> Rterm.exe works well in a MS-DOS window. Because of limitations
> of the MS-DOS window, I would like to use Rterm.exe in an rxvt
> window. I am using R-1.6.2 and rxvt-2.7.2 on Win98se. Thanks for
> any comments.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Mar  3 09:19:12 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Mar  3 09:19:12 2003
Subject: [R] using data() in an example
In-Reply-To: <Pine.OSF.4.44.0303022132150.1387-100000@is07.fas.harvard.edu>
Message-ID: <Pine.LNX.4.44.0303030809370.17885-100000@gannet.stats>

?data says

        4.  files ending `.csv' are read using `read.table(..., header
           = TRUE, sep = ";")', and also result in a data frame.

That may well be found first, so you need to rename bailey.csv.

You don't tell us your OS, but it looks like Windows where sorts often 
have c before R in the default locale:
> sort(c(letters, LETTERS))
 [1] "a" "A" "b" "B" "c" "C" "d" "D" "e" "E" "f" "F" "g" "G" "h" "H" "i" "I" "j"
[20] "J" "k" "K" "l" "L" "m" "M" "n" "N" "o" "O" "p" "P" "q" "Q" "r" "R" "s" "S"
[39] "t" "T" "u" "U" "v" "V" "w" "W" "x" "X" "y" "Y" "z" "Z"


On Sun, 2 Mar 2003, Christopher Adolph wrote:

> 
> Hi all,
> 
> I'm trying to put together examples in an R package, and am having trouble
> reading data from the package's data directory.  The data are in
> comma-separated variable files, so to read a file like gw.csv, I include
> in the data directory both bailey.csv and a file bailey.R which contains:
> 
> bailey <- read.csv("bailey.csv",na.strings=".");
> 
> so that typing
> 
> data(bailey)
> 
> should load the data from bailey.csv.
> 
> The problem is that the data is being read in "wrong", as a single column,
> rather than a data frame with four columns.  I get:
> 
>    data.p1.p2.model
> 1        0.57,2,1,1
> 2        0.54,4,1,1
> 3        0.54,6,1,1
> 4        0.52,8,1,1
> 5       0.54,10,1,1
> 6       0.53,50,1,1
> 7        0.93,2,1,2
> 8        0.61,4,1,2
> 9        0.53,6,1,2
> 10       0.49,8,1,2
> 11      0.43,10,1,2
> 12      0.11,50,1,2
> 13       0.89,2,1,3
> 14       0.72,4,1,3
> 15       0.62,6,1,3
> 16       0.58,8,1,3
> 17      0.49,10,1,3
> 18      0.12,50,1,3
> 19       0.51,2,1,4
> 20       0.43,4,1,4
> 21       0.41,6,1,4
> 22       0.37,8,1,4
> 23      0.37,10,1,4
> 24      0.31,50,1,4
> 
> Which is wrong.  But if I use the very same command as above, but from the
> command line (without the data() wrapper), it comes in right:
> 
> > read.csv("c:/progra~1/R/library/seemc/data/bailey.csv",na.strings=".")
>    data p1 p2 model
> 1  0.57  2  1     1
> 2  0.54  4  1     1
> 3  0.54  6  1     1
> 4  0.52  8  1     1
> 5  0.54 10  1     1
> 6  0.53 50  1     1
> 7  0.93  2  1     2
> 8  0.61  4  1     2
> 9  0.53  6  1     2
> 10 0.49  8  1     2
> 11 0.43 10  1     2
> 12 0.11 50  1     2
> 13 0.89  2  1     3
> 14 0.72  4  1     3
> 15 0.62  6  1     3
> 16 0.58  8  1     3
> 17 0.49 10  1     3
> 18 0.12 50  1     3
> 19 0.51  2  1     4
> 20 0.43  4  1     4
> 21 0.41  6  1     4
> 22 0.37  8  1     4
> 23 0.37 10  1     4
> 24 0.31 50  1     4
> >
> 
> What could be causing this?  I just want to get the example working; in
> practice one wouldn't need to use the data() command for this package, but
> it seems to be the only reliable way to get stuff out of the data
> directory for running examples.  Any ideas?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Mon Mar  3 10:29:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Mar  3 10:29:02 2003
Subject: [R] using data() in an example
In-Reply-To: <Pine.LNX.4.44.0303030809370.17885-100000@gannet.stats>
References: <Pine.LNX.4.44.0303030809370.17885-100000@gannet.stats>
Message-ID: <x2isv0x0h3.fsf@biostat.ku.dk>

ripley at stats.ox.ac.uk writes:

> ?data says
> 
>         4.  files ending `.csv' are read using `read.table(..., header
>            = TRUE, sep = ";")', and also result in a data frame.
> 
> That may well be found first, so you need to rename bailey.csv.
> 
> You don't tell us your OS, but it looks like Windows where sorts often 
> have c before R in the default locale:

Yikes! Thanks for pointing this out, Brian. 

I think we should consider it a bug(-let) and change data() to ensure
that .R files are found before any other extensions, exactly because
of this sort of application.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Mon Mar  3 10:39:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Mar  3 10:39:03 2003
Subject: [R] using data() in an example
In-Reply-To: <x2isv0x0h3.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0303030931330.18320-100000@gannet.stats>

I agree, and BTW the sort order is the same in locale en_GB on Linux and
Solaris, so this is a common trap.  I could understand CcRr as a sort 
order (it's dictionary order), but cCrR is hard to accept.

I think that RedHat 7.x/8.0 sets up locale en_GB as the default in the
UK: I keep on having to remember to change it on our boxes.

I had made a note to look into data().

Meanwhile the best fix is to save the object and use bailey.rda (and 
nothing else).

On 3 Mar 2003, Peter Dalgaard BSA wrote:

> ripley at stats.ox.ac.uk writes:
> 
> > ?data says
> > 
> >         4.  files ending `.csv' are read using `read.table(..., header
> >            = TRUE, sep = ";")', and also result in a data frame.
> > 
> > That may well be found first, so you need to rename bailey.csv.
> > 
> > You don't tell us your OS, but it looks like Windows where sorts often 
> > have c before R in the default locale:
> 
> Yikes! Thanks for pointing this out, Brian. 
> 
> I think we should consider it a bug(-let) and change data() to ensure
> that .R files are found before any other extensions, exactly because
> of this sort of application.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From till.baumgaertel at epost.de  Mon Mar  3 10:46:03 2003
From: till.baumgaertel at epost.de (Till Baumgaertel)
Date: Mon Mar  3 10:46:03 2003
Subject: AW: Re: [R] Q: Best-Practice for Swing-GUI calling R-code on Windows?
In-Reply-To: <Pine.LNX.4.44.0303030740240.17885-100000@gannet.stats>
Message-ID: <3E597722000130C4@ppd27106.x.de>

Thank you for the new SJava-binary!

But I am sorry, it won't work on my environment (Win XP pro, R 1.6.2., all
Jars in the CLASSPATH, SJava.dll in the PATH, R.DLL in the PATH). This time
the error looks totally different, but I don't have a clue what's wrong.
Could you give me a hint again?

thanks,
till

The error:

An unexpected exception has been detected in native code outside the VM.
Unexpected Signal : EXCEPTION_ACCESS_VIOLATION occurred at PC=0xAED86D0
Function=R_SetMaxNSize+0xD0
Library=C:\Programme\R\rw1062\bin\R.dll

Current Java thread:
        at org.omegahat.R.Java.REvaluator.eval(Native Method)
        at org.omegahat.R.Java.REvaluator.eval(REvaluator.java:86)
        at org.omegahat.R.Java.REvaluator.eval(REvaluator.java:36)
        at SJavaTest.Main.main(Main.java:20)

Dynamic libraries:
0x00400000 - 0x00406000         C:\Programme\Java\j2re1.4.1_01\bin\java.exe
0x77F40000 - 0x77FF0000         C:\WINDOWS\System32\ntdll.dll
0x77E40000 - 0x77F37000         C:\WINDOWS\system32\kernel32.dll
0x77DA0000 - 0x77E3A000         C:\WINDOWS\system32\ADVAPI32.dll
0x77C90000 - 0x77D05000         C:\WINDOWS\system32\RPCRT4.dll
0x77BE0000 - 0x77C33000         C:\WINDOWS\system32\MSVCRT.dll
0x6D330000 - 0x6D45A000         C:\Programme\Java\j2re1.4.1_01\bin\client\jvm.dl
l
0x77D10000 - 0x77D96000         C:\WINDOWS\system32\USER32.dll
0x77C40000 - 0x77C80000         C:\WINDOWS\system32\GDI32.dll
0x76AF0000 - 0x76B1D000         C:\WINDOWS\system32\WINMM.dll
0x10000000 - 0x1000D000         C:\WINDOWS\System32\hplun.dll
0x6D1D0000 - 0x6D1D7000         C:\Programme\Java\j2re1.4.1_01\bin\hpi.dll
0x6D300000 - 0x6D30D000         C:\Programme\Java\j2re1.4.1_01\bin\verify.dll
0x6D210000 - 0x6D229000         C:\Programme\Java\j2re1.4.1_01\bin\java.dll
0x6D320000 - 0x6D32D000         C:\Programme\Java\j2re1.4.1_01\bin\zip.dll
0x0AE20000 - 0x0AE37000         C:\Programme\R\rw1062\library\SJava\libs\SJava.d
ll
0x0AE40000 - 0x0B02E000         C:\Programme\R\rw1062\bin\R.dll
0x0B030000 - 0x0B051000         C:\Programme\R\rw1062\bin\Rblas.dll
0x77310000 - 0x7739B000         C:\WINDOWS\system32\COMCTL32.DLL
0x76350000 - 0x76396000         C:\WINDOWS\system32\COMDLG32.DLL
0x772A0000 - 0x77303000         C:\WINDOWS\system32\SHLWAPI.dll
0x69800000 - 0x69FF8000         C:\WINDOWS\system32\SHELL32.dll
0x77BD0000 - 0x77BD7000         C:\WINDOWS\system32\VERSION.dll
0x71950000 - 0x71A34000         C:\WINDOWS\WinSxS\x86_Microsoft.Windows.Common-C
ontrols_6595b64144ccf1df_6.0.0.0_x-ww_1382d70a\comctl32.dll
0x76C50000 - 0x76C72000         C:\WINDOWS\system32\imagehlp.dll
0x6DA00000 - 0x6DA7C000         C:\WINDOWS\system32\DBGHELP.dll
0x76BB0000 - 0x76BBB000         C:\WINDOWS\System32\PSAPI.DLL

Local Time = Mon Mar 03 10:38:21 2003
Elapsed Time = 1
#
# The exception above was detected in native code outside the VM
#
# Java VM: Java HotSpot(TM) Client VM (1.4.1_01-b01 mixed mode)
#
# An error report file has been saved as hs_err_pid2508.log.
# Please refer to the file for further information.
#



From darryl at hpli.hpl.hp.com  Mon Mar  3 10:51:04 2003
From: darryl at hpli.hpl.hp.com (Darryl Greig)
Date: Mon Mar  3 10:51:04 2003
Subject: [R] model.frame.default problem in function definition
In-Reply-To: <Pine.LNX.4.44.0303021604020.28217-100000@gannet.stats>
Message-ID: <000001c2e16a$0278f660$9e09b00f@hpli.hpl.hp.com>

Thanks, the new stepAIC does the job.

-----Original Message-----
From: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of
ripley at stats.ox.ac.uk
Sent: Sunday, March 02, 2003 6:14 PM
To: Darryl Greig
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] model.frame.default problem in function definition


This works in R-devel, for which NEWS says

    o   step(), add1.default() and drop1.default() now work somewhat
        better if called from a function.

It's mainly a scoping problem, related to changes made way back in 1.2.x.

However, it is also an bad example, as z is really excluded in the fit.
stepAIC in the latest MASS (VR_7.0-11) will work, but warns about this.
I hope that this is just an over-simplification of the real problem.

On Sun, 2 Mar 2003, Darryl Greig wrote:

> Could someone point me in the right direction for the following issue:
> 
> A function is defined as follows:
> 
> 	tfun <- function(dat)
> 	  {
> 	    fmla <- as.formula("y~x+z")
> 	    dat2 <- dat
> 	    mdl <- lm(fmla,dat2)
> 	    mdl <- step(mdl)
> 	  }
> 
> Then the following code
> 
> 	dat <- data.frame(x=1:10,z=1:10,y=(1:10)^2+10*(1:10))
> 	tfun(dat)
> 
> generates the output
> 
> 	Start:  AIC= 43.67
> 	 y ~ x + z
> 
> 	Error in model.frame.default(formula = y ~ z, data = dat2,
> drop.unused.levels = TRUE) :
> 		Object "dat2" not found
> 
> Any help or pointers gratefully accepted.
> 
> Thanks,
> Darryl Greig (darryl at hpli.hpl.hp.com)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Mon Mar  3 11:07:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Mar  3 11:07:03 2003
Subject: AW: Re: [R] Q: Best-Practice for Swing-GUI calling R-code on
 Windows?
In-Reply-To: <3E597722000130C4@ppd27106.x.de>
Message-ID: <Pine.LNX.4.44.0303030959440.18396-100000@gannet.stats>

Looks like a bug in your Java example.  Not that R-help is the 
right list for SJava questions, let alone Java programming ones.

I would

1) check out the SJava/examples/tdist.R example.
2) recompile from sources if 1) fails.

We really cannot debug your Windows setup remotely: all I can say is that
SJava.zip has run hundreds of examples in the last week on three different 
Windows XP machines.

On Mon, 3 Mar 2003, Till Baumgaertel wrote:

> Thank you for the new SJava-binary!
> 
> But I am sorry, it won't work on my environment (Win XP pro, R 1.6.2., all
> Jars in the CLASSPATH, SJava.dll in the PATH, R.DLL in the PATH). This time
> the error looks totally different, but I don't have a clue what's wrong.
> Could you give me a hint again?

You could check the setup instructions in my ReadMe, as that is not what 
it says to do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Mar  3 11:16:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Mar  3 11:16:02 2003
Subject: [R] ESS+R not closing gracefully
In-Reply-To: <5.1.0.14.2.20030302171935.01e060d8@mcmail.cis.mcmaster.ca>
Message-ID: <Pine.LNX.4.44.0303030926530.18320-100000@gannet.stats>

I think it is a Windows/Emacs issue.  That example works perfectly with
Rterm --ess in a shell.  Some debugging shows that Rterm calls
exit(status) and then fails to shut down.  So it is hanging in the C
shutdown routines.  My guess is that as Emacs still has the file handles
open it is using to communicate with Rterm, it is fighting with Windows to
stop them being closed.

Not an R-help issue.

On Sun, 2 Mar 2003, John Fox wrote:

> Dear Tony and Damon,
> 
> I, too, have seen this problem (and other similar problems) occasionally. I 
> don't really understand the source of the problem, but I think that it 
> involves synchronization issues, and I find that inserting delays between 
> operations seems to help. Take a look, for example, at the configuration 
> files I've posted at 
> <http://www.socsci.mcmaster.ca/jfox/Books/Companion/ESS/>, in particular 
> the menu items for exiting. Finally, I find that problems are less common 
> with Windows 2000 than with Windows 9x, but I gather this isn't your 
> experience.
> 
> I hope that this helps,
>   John
> 
> At 10:49 AM 3/2/2003 -0800, A.J. Rossini wrote:
> >Damon Wischik <djw1005 at cam.ac.uk> writes:
> >
> >
> > > I am having trouble with ESS+R. I don't know if it is an ESS
> > > problem or an R problem, so I'm posting to this mailing list in
> > > the first instance.
> >
> >Actually, it might be an Emacs problem -- or an R problem.  The fact
> >that R/ESS works under windows is simply amazing.
> >
> >Unfortunately, while I've seen it, I'm not sure how to solve it; it
> >isn't your configuration.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From simon at stats.gla.ac.uk  Mon Mar  3 11:44:04 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Mon Mar  3 11:44:04 2003
Subject: [R] multidimensional function fitting
In-Reply-To: <20030227214222.0c5ff2f6.rjvbertin@despammed.com>
Message-ID: <Pine.SOL.3.96.1030303103500.11109E-100000@moon.stats.gla.ac.uk>

> On Thu, 27 Feb 2003 13:52:50 -0500, "Wiener, Matthew" <matthew_wiener at merck.com> wrote regarding
> "[despammed] RE: [R] multidimensional function fitting"
> 
> 8-) Take a look at package mgcv.  Hope this helps.  --Matt
> 8-) 
> 
> Thank you, I just did. It may indeed be what I'm looking for (I haven't 
>quite understood everything about it...), but:
> 
> 1) The best fits I obtain with a formula like z~s(x,y) ; but this I cannot 
> possibly transport into the C programme where I need it! Maybe I wasn't
> clear on this aspect?
- Yes, this won't be entirely straightforward, but note that the
underlying code in mgcv is written in C, so it would be possible...

> 
> 2) It is very memory hungry, esp. when using the s() function: I have 
> 192Mb with 256Mb swap (not a lot, but reasonable I'd say), and I've
> never had to kill R as often as when trying gam()...
> 
- do you have a very large number of data? The way mgcv works it first
finds an "optimal" basis for smoothing and this will involve formation of
a matrix of size n^2 where n is your number of data.... The last couple of
examples in the ?gam help file show how to avoid this using the "knots"
argument to gam: basically you find a "near optimal" basis for a random
subset of your data, and then use this basis to do the smoothing on the
whole data set. (Can you let me know if this solves the problem/isn't the 
issue). 

best,
Simon

_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814



From hennig at stat.math.ethz.ch  Mon Mar  3 12:31:03 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Mon Mar  3 12:31:03 2003
Subject: [R] qda plots
In-Reply-To: <49AB9D0C6521D84ABD017BF83CDF44C401BFC562@xch1.ucc.ie>
Message-ID: <Pine.LNX.4.44.0303031221040.2072-100000@florence>

Hi,

there are some dimension reduction methods (somewhat analogous to linear
discriminants) which show groups as separated not only in means, but also
in covariance matrices. This might correspond well to a qda problem.
References are

Young, Marco and Odell, Journal of Statistical Planning and Inference, 17
(1987), 307-319
Fukunaga, Introduction to Statistical Pattern Recognition (2nd ed, p. 455
ff.), Academic Press, 1990.

As I am working recently on more flexible discriminant plots, you may also
consider my technical report on
ftp://ftp.stat.math.ethz.ch/Research-Reports/108.html
where the above mentioned methods are explained as well.
My package fpc on 
http://www.math.uni-hamburg.de/home/hennig/fixreg/fixreg.html
includes an R implementation of the method of Fukunaga 
("Bhattacharyya coordinates"). I have also R code for the method of Young
et al., but it is not yet "packaged", so you would have to contact me directly
if you would be interested in a (poorly documented) version.

Best,
Christian

On Thu, 27 Feb 2003, Power, Anne Marie wrote:

> Hi,
> 
> I have been using some of the functions in r for classification purposes,
> chiefly lda, qda, knn and nnet.
> My problem is that the only one I can figure out how to represenent
> graphically is lda (using plot.lda).  I have tried 'fooling' this function
> into accepting qda input for plotting but to no avail.  I wonder if you have
> any suggestions?
> 
> Thanks alot,
> 
> Anne Marie Power
> 
> Marine lab.
> Dept. Zooogy & Animal Ecology,
> University College Cork
> Ireland
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de



From Bernhard.Pfaff at drkw.com  Mon Mar  3 12:41:03 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Mon Mar  3 12:41:03 2003
Subject: [R] density(): obtaining p-values
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9004730261@ibfftce505.is.de.dresdnerkb.com>

Dear R-List-Member,

is there a more elegant way to obtain p-values of a vector x, whose
empirical density has been estimated with density(), than summing up the
rectangles as an approximation of the area beneath the empirical
distribution function and interpolating the values of x by using approx()?

pval.emp <- function(x)
  {
   df <- density(x,from=min(x),to=max(x),kernel="gaussian")
   width <- df$x[2]-df$x[1]
   rect <- df$y*width
   cdf.emp <- cumsum(rect)
   approx(df$x,cdf.emp,x)$y
  }

Many thks in advance,
Bernhard




----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------



From fharrell at virginia.edu  Mon Mar  3 12:53:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon Mar  3 12:53:03 2003
Subject: [R] density(): obtaining p-values
In-Reply-To: <18D602BD42B7E24EB810D6454A58DB9004730261@ibfftce505.is.de.dresdnerkb.com>
References: <18D602BD42B7E24EB810D6454A58DB9004730261@ibfftce505.is.de.dresdnerkb.com>
Message-ID: <20030303065225.5c7c6b86.fharrell@virginia.edu>

On Mon, 3 Mar 2003 12:40:37 +0100
"Pfaff, Bernhard" <Bernhard.Pfaff at drkw.com> wrote:

> Dear R-List-Member,
> 
> is there a more elegant way to obtain p-values of a vector x, whose
> empirical density has been estimated with density(), than summing up the
> rectangles as an approximation of the area beneath the empirical
> distribution function and interpolating the values of x by using approx()?
> 
> pval.emp <- function(x)
>   {
>    df <- density(x,from=min(x),to=max(x),kernel="gaussian")
>    width <- df$x[2]-df$x[1]
>    rect <- df$y*width
>    cdf.emp <- cumsum(rect)
>    approx(df$x,cdf.emp,x)$y
>   }
> 
> Many thks in advance,
> Bernhard
> 
>

You may want to refer to this just as "probability" and not "p-values".  It may not be fruitful to fit a density if what you want is cumulative probabilities.   Just compute the empirical cumulative distribution function of the original x:

library(stepfun)
ecdf(x)

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From ebrington at hotmail.com  Mon Mar  3 13:13:02 2003
From: ebrington at hotmail.com (Steve Moore)
Date: Mon Mar  3 13:13:02 2003
Subject: [R] (no subject)
Message-ID: <F118XYz96VEtWdLyKpJ000153dc@hotmail.com>

Dear Everyone,

I am a novel user of the R package (less than a week).  I am using the 
package to analyse some microarray data.  I have successfully imported the 
data, and manipulated it, resulting in additional columns of data.  However, 
I now want to extract all this new information from R for use outside the 
package.  Can anyone tell me of any commands that would allow me to 
accomplish this?

Many thanks in advance

Stephen Moore.





_________________________________________________________________
Chat online in real time with MSN Messenger http://messenger.msn.co.uk



From kurt.sys at rug.ac.be  Mon Mar  3 13:18:09 2003
From: kurt.sys at rug.ac.be (Kurt Sys)
Date: Mon Mar  3 13:18:09 2003
Subject: [R] tcltk makes R crash?
In-Reply-To: <x2u1esvsjv.fsf@biostat.ku.dk>
References: <200302252120.QAA01483@blaise.dfci.harvard.edu>
	<x2u1esvsjv.fsf@biostat.ku.dk>
Message-ID: <15971.18188.951863.540539@ksys.rug.ac.be>

Hello all,

I got a problem using the tcltk-package. It makes 'R crash':
I can use R and different packages without any problem. However, when I start the tcltk-package, the terminal I'm running R in (no matter what this 'terminal' is), will not recieve any input anymore once I set at statement which cannot be evaluated. The most easy example:
> library(tcltk)
> blabla
Error: Object "blabla" not found
> 

So, when I give these two commands, the only thing I can do (with the terminal I run R in), is 'kill client' (which is the terminal).

Sometimes (I didn't find any logic yet), I cannot see the commands I'm writing, but they are evaluated anyway (so I can quit etc, using the command 'q()', but what I write is not shown on the screen and when I'm out of R, this behaviour doesn't change for the terminal I ran R in).

I'm using Debian woody, R 1.6.2.

Anyone any idea?

thanks in advance,
Kurt



From maechler at stat.math.ethz.ch  Mon Mar  3 14:07:04 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Mar  3 14:07:04 2003
Subject: [R] extract R information 
In-Reply-To: <F118XYz96VEtWdLyKpJ000153dc@hotmail.com>
References: <F118XYz96VEtWdLyKpJ000153dc@hotmail.com>
Message-ID: <15971.21340.1336.514589@gargle.gargle.HOWL>

Note: Please always set a "Subject" in e-mails, particularly to
       mailing lists!

>>>>> "SteveM" == Steve Moore <ebrington at hotmail.com>
>>>>>     on Mon, 03 Mar 2003 12:12:16 +0000 writes:

    SteveM> Dear Everyone,

    SteveM> I am a novel user of the R package (less than a
    SteveM> week).  I am using the package to analyse some
    SteveM> microarray data.  I have successfully imported the
    SteveM> data, and manipulated it, resulting in additional
    SteveM> columns of data.  However, I now want to extract all
    SteveM> this new information from R for use outside the
    SteveM> package.  Can anyone tell me of any commands that
    SteveM> would allow me to accomplish this?


From Soren.Hojsgaard at agrsci.dk  Mon Mar  3 14:33:03 2003
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Mon Mar  3 14:33:03 2003
Subject: [R] Turning a string into an expression
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0CC614@DJFPOST01.djf.agrsci.dk>

Dear all,
I have e.g. 
	aaa <- "list(1,2,3,4)" 
and would like to get a hold on the list 
	list(1,2,3,4)
from aaa. Can anyone help with that?
Best regards 
S?ren H?jsgaard



From ripley at stats.ox.ac.uk  Mon Mar  3 14:41:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Mar  3 14:41:03 2003
Subject: [R] Turning a string into an expression
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0CC614@DJFPOST01.djf.agrsci.dk>
Message-ID: <Pine.LNX.4.44.0303031339430.23105-100000@gannet.stats>

> aaa <- "list(1,2,3,4)"
> parse(text=aaa)
expression(list(1, 2, 3, 4))

On Mon, 3 Mar 2003, S?ren H?jsgaard wrote:

> Dear all,
> I have e.g. 
> 	aaa <- "list(1,2,3,4)" 
> and would like to get a hold on the list 
> 	list(1,2,3,4)
> from aaa. Can anyone help with that?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Mon Mar  3 14:47:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Mar  3 14:47:03 2003
Subject: [R] Turning a string into an expression
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0CC614@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0CC614@DJFPOST01.djf.agrsci.dk>
Message-ID: <3E635C41.3070105@statistik.uni-dortmund.de>

S?ren H?jsgaard wrote:
> Dear all,
> I have e.g. 
> 	aaa <- "list(1,2,3,4)" 
> and would like to get a hold on the list 
> 	list(1,2,3,4)
> from aaa. Can anyone help with that?
> Best regards 
> S?ren H?jsgaard

Try
  parse(text=aaa)
for the expression and
  eval(parse(text=aaa))
to evaluate it.

Uwe Ligges



From upton at mitre.org  Mon Mar  3 14:51:44 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Mon Mar  3 14:51:44 2003
Subject: [R] Turning a string into an expression
References: <C83C5E3DEEE97E498B74729A33F6EAEC0CC614@DJFPOST01.djf.agrsci.dk>
Message-ID: <3E635C36.DE240BD2@mitre.org>

Soren,

try
eval(parse(text=aaa))

HTH
steve

S?ren H?jsgaard wrote:

> Dear all,
> I have e.g.
>         aaa <- "list(1,2,3,4)"
> and would like to get a hold on the list
>         list(1,2,3,4)
> from aaa. Can anyone help with that?
> Best regards
> S?ren H?jsgaard
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From edd at debian.org  Mon Mar  3 15:09:05 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon Mar  3 15:09:05 2003
Subject: [R] tcltk makes R crash?
In-Reply-To: <15971.18188.951863.540539@ksys.rug.ac.be>
References: <200302252120.QAA01483@blaise.dfci.harvard.edu> <x2u1esvsjv.fsf@biostat.ku.dk> <15971.18188.951863.540539@ksys.rug.ac.be>
Message-ID: <20030303140833.GA20609@sonny.eddelbuettel.com>

On Mon, Mar 03, 2003 at 01:14:04PM +0100, Kurt Sys wrote:
> I got a problem using the tcltk-package. It makes 'R crash':
> I can use R and different packages without any problem. However, when I start the tcltk-package, the terminal I'm running R in (no matter what this 'terminal' is), will not recieve any input anymore once I set at statement which cannot be evaluated. The most easy example:
> > library(tcltk)
> > blabla
> Error: Object "blabla" not found
> > 
> 
> So, when I give these two commands, the only thing I can do (with the terminal I run R in), is 'kill client' (which is the terminal).
[...] 
> I'm using Debian woody, R 1.6.2.

That sounds really odd.  

How did you get 1.6.2 onto Debian 3.0 ("woody")? One thing you could try is
to install the (older) Debian R package from the same Debian 3.0 release,
which should execute the sequence above cleanly.  You could then proceed 
in increments:  a) rebuild that R version locally on your woody machine
to demonstrate that it still works given your libraries, and then b) grab
the 1.6.2 source and build the Debian package locally against the same
setup as in a). That is bound to work "almost surely".

Let me know (off the list) if I can help with a) or b).

Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr



From jmc at research.bell-labs.com  Mon Mar  3 15:22:02 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Mon Mar  3 15:22:02 2003
Subject: [R] 'methods' and "[<-"
References: <20030302044040.GA47655487@genome.cbs.dtu.dk>
Message-ID: <3E6364E8.3FA013F7@research.bell-labs.com>

Laurent Gautier wrote:
> 
> Dear List,
> 
> I am trying to override the replace method "[<-" for
> objects of class "matrix"... with little success...
> 
> Would anyone know where I am wrong ?

Not wrong at all.  The problem is that "matrix" (and "array") are
implicit classes in R--there is no explicit class attribute, just as
there is not for the basic vector types,  "character", etc.

The effect is that methods for these data types are fixed for primitive
functions.  The internal code that dispatches methods will jump out
right away for these objects.  The argument in favor of not allowing
redefinition is partly efficiency and partly (perhaps the more important
part) that users should really be able to take the definition of
subsetting, arithmetic, and other basic operations as known and fixed
for the basic data types.

The "matrix" and "array" data types are slightly less basic, but in R
they are special and sort of built in.

Anyway,this is either a feature (in which case we'll modify the
setMethod code to throw an error) or something that might be changed.

It's no consolation, but I don't believe you can define S3-style methods
for the same combination of function and data type either.

> 
> > library(methods)
> > setReplaceMethod("[", "matrix", function(x, i, j, ..., value) {cat("I'm here.\n")})
> [1] "[<-"
> > m <- new("matrix", 0, 5, 2)
> > m[1,1] <- 2
> >
> # ..did not use my new method it seems
> 
> Thanks,
> 
> L/
> 
> PS: I am using R-1.6.2
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
John M. Chambers                  jmc at bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc



From york at noaa.gov  Mon Mar  3 16:59:02 2003
From: york at noaa.gov (Anne York)
Date: Mon Mar  3 16:59:02 2003
Subject: [R] Tabulating
Message-ID: <Pine.GSO.4.05.10303030752010.8689-100000@ofis450a.akctr.noaa.gov>

It seems that you are trying to obtain a tabulations of runs on length 2 in
your vector. 

So for 

 data<-c(10,10,11,10,12,11,10,12,11,11,10,11)

#define data2 as:

data2 <- c(data[-1],NA)

# Then, on way to obain the runs is to use table on data and data2:

 table(data,data2)


    data2
data 10 11 12
  10  1  2  2
  11  3  1  0
  12  0  2  0


I believe there is also a package written especially to do analyses of runs
in data, but offhand, I don't recall the name of it.

Anne

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Anne E. York
National Marine Mammal Laboratory
Seattle WA 98115-0070  USA
e-mail: york at ofis450a.akctr.noaa.gov
Voice: +1 206-526-4039
Fax: +1 206-526-6615
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

From: "Patrik Waldmann" <Patrik.Waldmann at djingis.se>
To: <r-help at stat.math.ethz.ch>
Date: Fri, 28 Feb 2003 12:09:38 +0100
Subject: [R] Tabulating

Hello,

I wonder if someone could send me suggestions on how to solve the following
problem:

I have a vector of an arbitrary size (ex.
data<-c(10,10,11,10,12,11,10,12,11,11,10,11))
and use the table function, which gives the following result
10  11  12
5    5     2

that's fine, but what I would like to do now is: 

construct new classes based on the number of classes from table, 10 10, 11
11, 12 12, 10
11, 10 12, 11 12. After that I would like to do tabulation on the pairs in
data, and
positions in pairs should be unimportant: 10 11 should be treated as the
same class as 11
10.
So the following result should be obtained:
10 10, 11 11, 12 12, 10 11, 10 12, 11 12
1 , 1 , 0 , 2 , 1 , 2

Remeber that it should be possible to do for an arbitrary number of
classes.

Best regards,

Patrik.Waldmann at djingis.se



From kjetil at entelnet.bo  Mon Mar  3 17:56:52 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon Mar  3 17:56:52 2003
Subject: [R] Tabulating
In-Reply-To: <Pine.GSO.4.05.10303030752010.8689-100000@ofis450a.akctr.noaa.gov>
Message-ID: <3E63500C.28376.9481D2@localhost>

On 3 Mar 2003 at 7:58, Anne York wrote:

> It seems that you are trying to obtain a tabulations of runs on length 2 in
> your vector. 
> 

If that is the case, rle (run length encoding) in base will do.
Try
?rle

Kjetil Halvorsen

> So for 
> 
>  data<-c(10,10,11,10,12,11,10,12,11,11,10,11)
> 
> #define data2 as:
> 
> data2 <- c(data[-1],NA)
> 
> # Then, on way to obain the runs is to use table on data and data2:
> 
>  table(data,data2)
> 
> 
>     data2
> data 10 11 12
>   10  1  2  2
>   11  3  1  0
>   12  0  2  0
> 
> 
> I believe there is also a package written especially to do analyses of runs
> in data, but offhand, I don't recall the name of it.
> 
> Anne
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Anne E. York
> National Marine Mammal Laboratory
> Seattle WA 98115-0070  USA
> e-mail: york at ofis450a.akctr.noaa.gov
> Voice: +1 206-526-4039
> Fax: +1 206-526-6615
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> From: "Patrik Waldmann" <Patrik.Waldmann at djingis.se>
> To: <r-help at stat.math.ethz.ch>
> Date: Fri, 28 Feb 2003 12:09:38 +0100
> Subject: [R] Tabulating
> 
> Hello,
> 
> I wonder if someone could send me suggestions on how to solve the following
> problem:
> 
> I have a vector of an arbitrary size (ex.
> data<-c(10,10,11,10,12,11,10,12,11,11,10,11))
> and use the table function, which gives the following result
> 10  11  12
> 5    5     2
> 
> that's fine, but what I would like to do now is: 
> 
> construct new classes based on the number of classes from table, 10 10, 11
> 11, 12 12, 10
> 11, 10 12, 11 12. After that I would like to do tabulation on the pairs in
> data, and
> positions in pairs should be unimportant: 10 11 should be treated as the
> same class as 11
> 10.
> So the following result should be obtained:
> 10 10, 11 11, 12 12, 10 11, 10 12, 11 12
> 1 , 1 , 0 , 2 , 1 , 2
> 
> Remeber that it should be possible to do for an arbitrary number of
> classes.
> 
> Best regards,
> 
> Patrik.Waldmann at djingis.se
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rajarshi at presidency.com  Mon Mar  3 18:02:45 2003
From: rajarshi at presidency.com (Rajarshi Guha)
Date: Mon Mar  3 18:02:45 2003
Subject: [R] saving a plot to a file
Message-ID: <200303031203.22448.rajarshi@presidency.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi,
  I'm a new user of R and have managed to make a plot of a histogram. Is there 
any way I set the title and axes labels and then save the plot as an image 
(png/gif)?


Thanks
- -- 
- -------------------------------------------------------------------
Rajarshi Guha  <rajarshi at presidency.com> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04  06F7 1BB9 E634 9B87 56EE
- -------------------------------------------------------------------
"A fractal is by definition a set for which the Hausdorff Besicovitch
dimension strictly exceeds the topological dimension."
		-- Mandelbrot, "The Fractal Geometry of Nature"

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.7 (GNU/Linux)

iD8DBQE+Y4raG7nmNJuHVu4RAv3WAKCaQO9X0ZwQwzjDlwXQ4BbKdYuH6gCeN+vD
XpeosRY4Wk+u7L/X5eBMXT4=
=VeJL
-----END PGP SIGNATURE-----



From york at noaa.gov  Mon Mar  3 18:18:02 2003
From: york at noaa.gov (Anne York)
Date: Mon Mar  3 18:18:02 2003
Subject: [R] Tabulating
In-Reply-To: <3E63500C.28376.9481D2@localhost>
Message-ID: <Pine.GSO.4.05.10303030910410.9803-100000@ofis450a.akctr.noaa.gov>

Actually, I made a mistake. Mr. Waldman does  not seem to be asking for
runs in the traditional sense but  for runs of permutations of elements of
a vector. So, I don't think that rle (as is) will do this job. 

Anne 



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Anne E. York
National Marine Mammal Laboratory
Seattle WA 98115-0070  USA
e-mail: anne.york at noaa.gov
Voice: +1 206-526-4039
Fax: +1 206-526-6615
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

On Mon, 3 Mar 2003, kjetil brinchmann halvorsen wrote:

|On 3 Mar 2003 at 7:58, Anne York wrote:
|
|> It seems that you are trying to obtain a tabulations of runs on length 2 in
|> your vector. 
|> 
|
|If that is the case, rle (run length encoding) in base will do.
|Try
|?rle
|
|Kjetil Halvorsen
|
|> So for 
|> 
|>  data<-c(10,10,11,10,12,11,10,12,11,11,10,11)
|> 
|> #define data2 as:
|> 
|> data2 <- c(data[-1],NA)
|> 
|> # Then, on way to obain the runs is to use table on data and data2:
|> 
|>  table(data,data2)
|> 
|> 
|>     data2
|> data 10 11 12
|>   10  1  2  2
|>   11  3  1  0
|>   12  0  2  0
|> 
|> 
|> I believe there is also a package written especially to do analyses of runs
|> in data, but offhand, I don't recall the name of it.
|> 
|> Anne
|> 
|> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|> Anne E. York
|> National Marine Mammal Laboratory
|> Seattle WA 98115-0070  USA
|> e-mail: york at ofis450a.akctr.noaa.gov
|> Voice: +1 206-526-4039
|> Fax: +1 206-526-6615
|> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|> 
|> From: "Patrik Waldmann" <Patrik.Waldmann at djingis.se>
|> To: <r-help at stat.math.ethz.ch>
|> Date: Fri, 28 Feb 2003 12:09:38 +0100
|> Subject: [R] Tabulating
|> 
|> Hello,
|> 
|> I wonder if someone could send me suggestions on how to solve the following
|> problem:
|> 
|> I have a vector of an arbitrary size (ex.
|> data<-c(10,10,11,10,12,11,10,12,11,11,10,11))
|> and use the table function, which gives the following result
|> 10  11  12
|> 5    5     2
|> 
|> that's fine, but what I would like to do now is: 
|> 
|> construct new classes based on the number of classes from table, 10 10, 11
|> 11, 12 12, 10
|> 11, 10 12, 11 12. After that I would like to do tabulation on the pairs in
|> data, and
|> positions in pairs should be unimportant: 10 11 should be treated as the
|> same class as 11
|> 10.
|> So the following result should be obtained:
|> 10 10, 11 11, 12 12, 10 11, 10 12, 11 12
|> 1 , 1 , 0 , 2 , 1 , 2
|> 
|> Remeber that it should be possible to do for an arbitrary number of
|> classes.
|> 
|> Best regards,
|> 
|> Patrik.Waldmann at djingis.se
|> 
|> ______________________________________________
|> R-help at stat.math.ethz.ch mailing list
|> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
|
|
|
|



From fzhang at us.ibm.com  Mon Mar  3 18:24:02 2003
From: fzhang at us.ibm.com (Fan Zhang)
Date: Mon Mar  3 18:24:02 2003
Subject: [R] optimization tools
Message-ID: <OFD7EB21E2.4F9423FE-ON85256CDE.005F5D2B@us.ibm.com>




Hi there,

Does R have solvers for linear, nonlinear and integer programming? Thanks,

-Fan



From djw1005 at cam.ac.uk  Mon Mar  3 18:32:02 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Mon Mar  3 18:32:02 2003
Subject: [R] ESS+R not closing gracefully
In-Reply-To: <Pine.LNX.4.44.0303030926530.18320-100000@gannet.stats>
Message-ID: <Pine.SOL.3.96.1030303172825.19100B-100000@libra.cus.cam.ac.uk>

On Mon, 3 Mar 2003 ripley at stats.ox.ac.uk wrote:
> I think it is a Windows/Emacs issue.  That example works perfectly with
> Rterm --ess in a shell.  Some debugging shows that Rterm calls
> exit(status) and then fails to shut down.  So it is hanging in the C
> shutdown routines.  My guess is that as Emacs still has the file handles
> open it is using to communicate with Rterm, it is fighting with Windows to
> stop them being closed.
> 
> Not an R-help issue.

In case anyone (who doesn't read the ESS mailing list) is interested:  I
contacted the ESS mailing list, and was given the following disheartening
information.

Damon.

-----------------------------------------
Date: Mon, 03 Mar 2003 06:25:11 -0800
From: "A.J. Rossini" <rossini at blindglobe.net>

It's an Emacs/Windows thing, that either R can fix or Emacs can fix.

1. The R folks don't have time right now,
2. we could talk to the Emacs folks,
3. it's not an ESS problem per say, but an ESS issue, since we
   leverage both R and Emacs.

conclusion -- it probably won't get fixed anytime soon, until someone
does some gory debugging of Emacs and R under Windows to understand
why/how file refs are staying open.  Sorry.

best,
-tony



From ligges at statistik.uni-dortmund.de  Mon Mar  3 18:38:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Mar  3 18:38:03 2003
Subject: [R] saving a plot to a file
References: <200303031203.22448.rajarshi@presidency.com>
Message-ID: <3E639331.1007580C@statistik.uni-dortmund.de>


Rajarshi Guha wrote:
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Hi,
>   I'm a new user of R and have managed to make a plot of a histogram. Is there
> any way I set the title and axes labels and then save the plot as an image
> (png/gif)?

This is a joke, isn't it?

What about
a) reading the manual "An Introduction to R" (in particular its Section
12: Graphical Procedures), 
b) reading the help pages for functions you are using,
c) using the help facilities to find functions you want to use,
d) looking for previous relevant messages in the R help archives,
e) looking into any other documentation or good book related to R.

Each one of the above mentioned methods helps!
Or for short: RTFM!

An annoyed voluntary help provider,
Uwe Ligges

 
> Thanks
> - --
> - -------------------------------------------------------------------
> Rajarshi Guha  <rajarshi at presidency.com> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04  06F7 1BB9 E634 9B87 56EE
> - -------------------------------------------------------------------



From spencer.graves at pdf.com  Mon Mar  3 18:57:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon Mar  3 18:57:03 2003
Subject: [R] optimization tools
References: <OFD7EB21E2.4F9423FE-ON85256CDE.005F5D2B@us.ibm.com>
Message-ID: <3E639715.2010000@pdf.com>

Have you looked at optim?

Spencer Graves

Fan Zhang wrote:
> 
> 
> 
> Hi there,
> 
> Does R have solvers for linear, nonlinear and integer programming? Thanks,
> 
> -Fan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Ko-Kang at xtra.co.nz  Mon Mar  3 19:25:03 2003
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Mon Mar  3 19:25:03 2003
Subject: [R] saving a plot to a file
References: <200303031203.22448.rajarshi@presidency.com>
Message-ID: <006601c2e1b2$131385b0$243158db@kwan022>

Hi,

----- Original Message -----
From: "Rajarshi Guha" <rajarshi at presidency.com>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, March 04, 2003 6:03 AM
Subject: [R] saving a plot to a file


> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Hi,
>   I'm a new user of R and have managed to make a plot of a histogram. Is
there
> any way I set the title and axes labels and then save the plot as an image
> (png/gif)?


To set the title/axis labels, one of the options is to use the main, xlab,
ylab parameters in hist().

For example:
    > hist(1:10, main = "A Histogram", xlab = "FOO", ylab = "Fred")

As for save the plot, take a look at:
    > ?png

Cheers,

Kevin

------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022



From Jim_Garrett at bd.com  Mon Mar  3 19:57:02 2003
From: Jim_Garrett at bd.com (Jim_Garrett@bd.com)
Date: Mon Mar  3 19:57:02 2003
Subject: [R] multidimensional function fitting
Message-ID: <OF643255AE.6AC0A524-ON85256CDE.00572A14@bd.com>


Have you considered fitting a neural net using the nnet package?  Since
nets are determined by a functional form that is straightforward
(recursive, but straightforward....) and a set of coefficients (weights),
they're fairly easy to program from scratch.  There are no "exotic" (to
some) basis functions to deal with.  You can find descriptions sufficient
to guide coding in Venables and Ripley's _Modern Applied Statistics with
S-Plus_, Ripley's _Pattern Recognition and Neural Networks_, and also _The
Elements of Statistical Learning_ by Hastie, Tibshirani, and Friedman.
I've found each of these to be a good general reference, by the way--if
you're going to be dealing with "curve fitting" on more than this one
occasion, one or all of these would be good to have.  Ripley's pattern
recognition book naturally focuses on classification rather than general
curve-fitting, though many ideas are common to both.

Fitting a net will put more of a burden on you to optimize the model than
mgcv will.  I would suggest  the following guidelines (most of which I
learned from Ripley's pattern recognition book):
   Any net "fitting" should actually consist of multiple fits from random
   starting points--take the fit that minimizes the fitting criterion.
   Scale predictors if necessary to ensure that predictors are on similar
   scales.
   For curve fitting, use the options "linout = T" and "skip = T" (the
   latter is optional but recommended).
   You must optimize some criterion that keeps you from overfitting.  Two
   different techniques I have used successfully are
   (a)  choose the number of hidden units and weight decay parameter to
   optimize cross-validation performance, and
   (b)  choose the number of hidden units to optimize the Bayesian
   Information Criterion (BIC) (setting weight decay to zero).
   The former should give you better performance, but the latter is less
   work and usually works pretty well.  BIC penalizes the number of
   parameters, and here the "number of parameters" is taken to be the
   number of weights.  I could send you R code that automates this.
   Using weight decay > 0 generally improves predictive performance.  Once
   you have enough hidden units, you will not overfit if you use a suitable
   weight-decay parameter.  In fact, a reasonable strategy would be to use
   BIC to select the number of hidden units, then add (say) 2 hidden units
   and find weight-decay that optimizes cross-validation performance.

In short, mgcv makes model optimization convenient but has a price in
implementation, while neural nets make implementation convenient but have a
price in optimization.  I sometimes fit a model which is then implemented
by our Software Engineering group in C, and in that situation I prefer to
pay the price that falls only on me and which I can afford to pay.  Hence I
have used neural nets.  In fact early on I specified for our software group
a "neural net evaluator" C routine that takes some net architectural
parameters (number of inputs, hidden nodes, etc.) and weights in the order
that the nnet package displays them.  Now I can essentially fit a net with
package nnet, send someone the parameters, and they'll have it running in C
in short order.

Of course, GAM's also offer much in the way of model interpretation, and if
the phenomenon at hand obeys additivity, a GAM will outperform a neural
net.  I should add that I use the mgcv package frequently, and like it very
much.

Regarding computational resources, with some datasets I've fitted complex
GAM's, neural nets, and projection pursuit (ppr in package modreg), and
didn't notice much difference in a very rough, qualitative sense.  With
enough data, they all take a while.  I didn't investigate memory usage.  Of
course, gam and ppr are doing more work--gam is optimizing smoothness, and
ppr is fitting a range of models.  If you have so much data that none of
these are feasible,  you could do worse than fitting to a random subset.
How much precision do you need anyway?  And how complex a model do you
anticipate?  1000 cases or fewer is probably more than enough for most
regression problems.  Set aside the rest, and you have a large validation
set!  In fact you might fit multiple models, each to a random subset,
implement all the models, and average their responses.

Further along these lines, you could fit quite a few regression trees using
rpart because it's very fast.  You could even do thorough cross-validation
without great demands in time or memory.  A tree won't offer a smooth
response function, but if you average enough of them, the granularity of
response should be small.  Trees, like nets, are easy to code from scratch.
This just about describes bagging, except that the multiple subsets in
bagging are generated by bootstrap sampling, so are not mutually exclusive,
can contain cases more than once, and are of the same size as the original
data.

Good luck,

Jim Garrett
Becton Dickinson Diagnostic Systems
Baltimore, Maryland, USA



--__--__--

Message: 37
Date: Fri, 28 Feb 2003 17:38:52 -0500
From: "Huntsinger, Rei
d" <reid_huntsinger at merck.com>
Subject: RE: [despammed] RE: [R] multidimensional function fitting
To: "'RenE J.V. Bertin'" <rjvbertin at despammed.com>,
   "Wiener, Matthew" <matthew_wiener at merck.com>
cc: r-help at stat.math.ethz.ch

You can use R objects, such as the return from gam, and the
predict.gam function, from C. See the R extensions manual.

Reid Huntsinger

-----Original Message-----
From: RenE J.V. Bertin [mailto:rjvbertin at despammed.com]
Sent: Thursday, February 27, 2003 3:42 PM
To: Wiener, Matthew
Cc: r-help at stat.math.ethz.ch
Subject: Re: [despammed] RE: [R] multidimensional function fitting


On Thu, 27 Feb 2003 13:52:50 -0500, "Wiener, Matthew"
<matthew_wiener at merck.com> wrote regarding
"[despammed] RE: [R] multidimensional function fitting"

8-) Take a look at package mgcv.  Hope this helps.  --Matt
8-)

Thank you, I just did. It may indeed be what I'm looking for (I haven't
quite understood everything about it...), but:

1) The best fits I obtain with a formula like z~s(x,y) ; but this I cannot
possibly transport into the C programme where I need it! Maybe I wasn't
clear on this aspect?

2) It is very memory hungry, esp. when using the s() function: I have 192Mb
with 256Mb swap (not a lot, but reasonable I'd say), and I've never had to
kill R as often as when trying gam()...

R.B.

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------


**********************************************************************
This message is intended only for the designated recipient(s).  ... [[dropped]]



From simon at stats.gla.ac.uk  Mon Mar  3 20:43:02 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Mon Mar  3 20:43:02 2003
Subject: [despammed] RE: [R] multidimensional function fitting
In-Reply-To: <20030303174839.30c1e307.rjvbertin@despammed.com>
Message-ID: <Pine.SOL.3.96.1030303193644.18612D-100000@moon.stats.gla.ac.uk>

> 
> 8-) > 2) It is very memory hungry, esp. when using the s() function: I have 
> 8-) > 192Mb with 256Mb swap (not a lot, but reasonable I'd say), and I've
> 8-) > never had to kill R as often as when trying gam()...
> 8-) > 
> 8-) - do you have a very large number of data? The way mgcv works it first
> 8-) finds an "optimal" basis for smoothing and this will involve formation of
> 
> 	Some 10000 (x,y,z). For R, that doesn't strike me as particularly much.
- The point here is that the method being used by default requires storage
of a 10000 by 10000 matrix - it's not really an issue of whether 10000 is
particularly much "for R". There is a cut and paste-able example for
getting around this at the end of the help file for gam()... gam will be
*much* faster and *much* less memory intensive if you use it. 

cheers,
Simon



From Paul.Bliese at NA.AMEDD.ARMY.MIL  Mon Mar  3 22:48:03 2003
From: Paul.Bliese at NA.AMEDD.ARMY.MIL (Bliese, Paul D MAJ WRAIR-Wash DC)
Date: Mon Mar  3 22:48:03 2003
Subject: [R] lm, gee and lme
Message-ID: <58CAB2332C0DD511BC7900A0C9EA316D013D195D@dasmtyjqf009.amedd.army.mil>

Behavioral science data is often collected from nested structures (students
in schools, in districts, etc.). This can produce nonindependence among
responses from individuals in the same groups.  Consequently, researchers
are advised to model the nested nature of the data to avoid biases in SE
estimates.

Failing to account for nonindependence can lead to SE estimates that are too
large or too small depending ones model.  In the literature on linear mixed
effect models (lme) it is well documented that ignoring nonindependence
leads to SE values that are too small when the predictor varies only across
groups (is a level-2 predictor).  So, for instance, using linear regression
(lm) to regress individual performance (level-1 outcome) on group size
(level-2 predictor) using data where a lot of individuals come from the same
groups will lead to an SE value that is too small.  Using lme in this case
leads to a larger (and generally agreed upon as being less biased) SE
estimate.

What is trickier is what happens when both the predictor and outcome vary
among individuals in the same group.  An example of this type of model would
be one where individual performance is regressed upon individual age, but
where individual peformance is partially influenced by group membership.  My
understanding here is that ignoring nonindependence (i.e., using lm)
actually results in SE estimates that are too large, while modeling the
nonindependence reduces SE and increases power.

Here is an example:
# lme model
> mod.lme<-lme(GWB.ADD4~HOR,random=~1|GRP,data=TBH)
> VarCorr(mod.lme)
GRP = pdLogChol(1) 
            Variance  StdDev   
(Intercept) 0.3160445 0.5621783
Residual    0.7449425 0.8631005
> 0.3160445/(0.3160445+0.7449425)
[1] 0.2978778  #Note the large ICC (high nonindependence)

> summary(mod.lme)$tTable
                Value  Std.Error   DF  t-value       p-value
(Intercept) 1.9846214 0.06819493 7282 29.10219 3.041808e-176
HOR         0.2493643 0.01189157 7282 20.96984  7.533401e-95

#lm model
> summary(mod.lm)$coef
             Estimate Std. Error  t value     Pr(>|t|)
(Intercept) 1.9404202 0.04437889 43.72395 0.000000e+00
HOR         0.2537195 0.01391557 18.23278 1.098509e-72

Notice the SE of .012 (lme) versus .014 (lm) and the higher t-value in lme.

These results make sense to me in that lme basically "sets aside" the
level-2 variance (tau) which is substantial in my example (see the high ICC
value).  As a result, the level-1 variable (HOR) only has to "explain"
level-1 variance (sigma-squared).  This means results in an increase in
power.

Now my question....why don't I see the same power increase if I use gee?
Notice below that the gee model SE values are basically identical to the lm
model values:

#gee model

>
mod.gee<-geese(GWB.ADD4~HOR,id=GRP,family="gaussian",corstr="exch",data=TBH)
> summary(mod.gee)
 Coefficients:
             estimate     san.se     wald p
(Intercept) 1.9847217 0.06992705 805.5802 0
HOR         0.2493582 0.01379557 326.7142 0
....
 Estimated Correlation Parameters:
       estimate     san.se     wald            p
alpha 0.3176938 0.04224159 56.56357 5.440093e-14

The SE value in the gee model (0.0138) is virtually identical to the SE
value in the lm model ignoring the nonindependence (0.0139).  Note that the
alpha estimate of .32 in gee is close to the ICC estimate in the lme model
(are these basically the same?).

I would have expected lme and gee to provide more similar answers.  Any
thoughts on why gee and lme are not more similar would be appreciated as
would any clarification about when ignoring nonindepedence leads to too
small versus too large SE values....

Paul

MAJ Paul Bliese, Ph.D.
Walter Reed Army Institute of Research
Phone: (301) 319-9873
Fax: (301) 319-9484
paul.bliese at na.amedd.army.mil



From Nick.Bond at sci.monash.edu.au  Mon Mar  3 23:06:03 2003
From: Nick.Bond at sci.monash.edu.au (Nick Bond)
Date: Mon Mar  3 23:06:03 2003
Subject: [R] transition matrix problem
Message-ID: <3E63C252.7CA5207A@sci.monash.edu.au>

I'm having trouble using some fairly simple code to change the entries
in a vector (x - the numbers 0-5) according to a simple transition
matrix that I've called p.dry.  


the error message I get is 
"no finite arguments to min; returning Inf"

Any suggestions as to where I'm going wrong greatly appreciated. Sorry
the message is lengthy!

cheers
Nick


The code is 

p.trans<-matrix(c(1,0,0,0,0,0,0.7,0.3,0,0,0,0,0,0.6,0.4,0,0,0,0,0,0.5,0.5,0,0,0,0,0,0.4,0.6,0,0,0,0,0,0.3,0.7),6,6)

x<-ceiling(runif(100,0,5))

trans<-function(x) {
x.new<-vector(,length(x))
for (i in 1:length(x)) {
if (x[i]==0) x.new[i]<-0
else
cump<-(cumsum(p.trans[,(x[i]+1)])) # +1 b.c p.trans[,1] relates to
min(x)==0
names(cump)<-c("0","1","2","3","4","5")
rand<-ceiling(runif(1,0,100))
x.new[i]<-min(as.integer(names(cump[rand<(cump*100)])))
}
return(x,x.new)
}


Basically, in the transition matrix, the columns represent the current
cell entry in the vector (e.g. column 1 represents 0 (in the vector),
and the rows in the matrix are the possible transition states.  Hence,
cell entries in the transition matrix are the probabilities associated
with each transition.

The code works on the cumulative distribution of the relevant column of
the transition matrix, which is determined by the current cell value in
x.

-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Dr Nick Bond				 
Department of Biological Sciences 	 
Monash University (Clayton Campus)
Victoria, Australia, 3800
Ph: +61 3 9905 5606	Fax: +61 3 9905 5613
Email:   Nick.Bond at sci.monash.edu.au
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From baiyan at ece.ogi.edu  Mon Mar  3 23:46:02 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Mon Mar  3 23:46:02 2003
Subject: [R] R version conflict.
In-Reply-To: <F118XYz96VEtWdLyKpJ000153dc@hotmail.com>
Message-ID: <Pine.GSO.4.44.0303031439540.18640-100000@ece.ogi.edu>

Download R-1.6.2 source code package from http://cran.r-project.org and
compiled successfully.
When run library(grid), get error message as the R version is 1.5.1, and
cannot support grid package. The weird thing is that R.Version() returned
as this R is actualy 1.5.1

Did anybody get the same problem? or I made something wrong? Thanks.

----------------------------------------
> library(grid)
Error: This is R 1.5.1, package grid needs >= 1.6.0
> R.Version()
$platform
[1] "i686-pc-linux-gnu"

$arch
[1] "i686"

$os
[1] "linux-gnu"

$system
[1] "i686, linux-gnu"

$status
[1] ""

$major
[1] "1"

$minor
[1] "5.1"

$year
[1] "2002"

$month
[1] "06"

$day
[1] "17"

$language
[1] "R"



From tblackw at umich.edu  Tue Mar  4 00:01:03 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue Mar  4 00:01:03 2003
Subject: [R] transition matrix problem
In-Reply-To: <3E63C252.7CA5207A@sci.monash.edu.au>
Message-ID: <Pine.SOL.4.44.0303031755130.7755-100000@asteroids.gpcc.itd.umich.edu>

Nick  -

Ask yourself what happens in  min(as.integer(names(cump[rand<(cump*100)])))
when the random number happens to be larger than the first entry in the
relevant column of p.trans.  How many elements in the comparison are true ?

In that case, I think you are taking the minimum of zero elements, and the
error message is quite correct.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -


On Tue, 4 Mar 2003, Nick Bond wrote:

> I'm having trouble using some fairly simple code to change the entries
> in a vector (x - the numbers 0-5) according to a simple transition
> matrix that I've called p.dry.
>
> the error message I get is  "no finite arguments to min; returning Inf"
>
> The code is
>
> p.trans<-matrix(c(1,0,0,0,0,0,0.7,0.3,0,0,0,0,0,0.6,0.4,0,0,0,0,0,0.5,0.5,0,0,0,0,0,0.4,0.6,0,0,0,0,0,0.3,0.7),6,6)
>
> x<-ceiling(runif(100,0,5))
>
> trans<-function(x) {
> x.new<-vector(,length(x))
> for (i in 1:length(x)) {
> if (x[i]==0) x.new[i]<-0
> else
> cump<-(cumsum(p.trans[,(x[i]+1)])) # +1 b.c p.trans[,1] relates to
> min(x)==0
> names(cump)<-c("0","1","2","3","4","5")
> rand<-ceiling(runif(1,0,100))
> x.new[i]<-min(as.integer(names(cump[rand<(cump*100)])))
> }
> return(x,x.new)
> }
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Dr Nick Bond
> Department of Biological Sciences
> Monash University (Clayton Campus)
> Victoria, Australia, 3800
> Ph: +61 3 9905 5606	Fax: +61 3 9905 5613
> Email:   Nick.Bond at sci.monash.edu.au
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From baiyan at ece.ogi.edu  Tue Mar  4 00:23:03 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Tue Mar  4 00:23:03 2003
Subject: [R] R version conflict.
In-Reply-To: <20030303175722.H5830@jimmy.harvard.edu>
Message-ID: <Pine.GSO.4.44.0303031517030.24846-100000@ece.ogi.edu>

My mistake :(
Seems that there's another R installed by root. So when I use .libPaths()
there're two of them:

> .libPaths()
[1] "/disk/hopper/projects/class/cse514/R/library"
[2] "/usr/lib/R/library"

How could the second path be enabled then? The R_LIBS have already been
set to as the [1] only.

Thanks,

yan

On Mon, 3 Mar 2003, Robert Gentleman wrote:

> You might check your path -- you probably have an old version that
> comes before the new one that you just built.
>
> On Mon, Mar 03, 2003 at 02:44:51PM -0800, Bai Yan wrote:
> >
> > Download R-1.6.2 source code package from http://cran.r-project.org and
> > compiled successfully.
> > When run library(grid), get error message as the R version is 1.5.1, and
> > cannot support grid package. The weird thing is that R.Version() returned
> > as this R is actualy 1.5.1
> >
> > Did anybody get the same problem? or I made something wrong? Thanks.
> >
> > ----------------------------------------
> > > library(grid)
> > Error: This is R 1.5.1, package grid needs >= 1.6.0
> > > R.Version()
> > $platform
> > [1] "i686-pc-linux-gnu"
> >
> > $arch
> > [1] "i686"
> >
> > $os
> > [1] "linux-gnu"
> >
> > $system
> > [1] "i686, linux-gnu"
> >
> > $status
> > [1] ""
> >
> > $major
> > [1] "1"
> >
> > $minor
> > [1] "5.1"
> >
> > $year
> > [1] "2002"
> >
> > $month
> > [1] "06"
> >
> > $day
> > [1] "17"
> >
> > $language
> > [1] "R"
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> --
> +---------------------------------------------------------------------------+
> | Robert Gentleman                 phone : (617) 632-5250                   |
> | Associate Professor              fax:   (617)  632-2444                   |
> | Department of Biostatistics      office: M1B20                            |
> | Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
> +---------------------------------------------------------------------------+
>



From baiyan at ece.ogi.edu  Tue Mar  4 00:54:03 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Tue Mar  4 00:54:03 2003
Subject: [R] Finally get SJava work
In-Reply-To: <20030303175722.H5830@jimmy.harvard.edu>
Message-ID: <Pine.GSO.4.44.0303031546010.28642-100000@ece.ogi.edu>

Yeah!! I finally get SJava examples run on linux. The problems is that
there's an old version installed on the machine, with static library.
Unfortunately, the path of the old version is set before the new version,
thus every time when R command is conducted, the old version is invoked
(but I didn't know), and since the libR.so is not exist in that version, I
always got linkage errors :(
After reset the PATH variable, the java file ran!

I was stuck for several days, and really happy to see the problem got
solved. Many thanks for your helps:)

Yan

On Mon, 3 Mar 2003, Robert Gentleman wrote:

> You might check your path -- you probably have an old version that
> comes before the new one that you just built.
>
> On Mon, Mar 03, 2003 at 02:44:51PM -0800, Bai Yan wrote:
> >
> > Download R-1.6.2 source code package from http://cran.r-project.org and
> > compiled successfully.
> > When run library(grid), get error message as the R version is 1.5.1, and
> > cannot support grid package. The weird thing is that R.Version() returned
> > as this R is actualy 1.5.1
> >
> > Did anybody get the same problem? or I made something wrong? Thanks.
> >
> > ----------------------------------------
> > > library(grid)
> > Error: This is R 1.5.1, package grid needs >= 1.6.0
> > > R.Version()
> > $platform
> > [1] "i686-pc-linux-gnu"
> >
> > $arch
> > [1] "i686"
> >
> > $os
> > [1] "linux-gnu"
> >
> > $system
> > [1] "i686, linux-gnu"
> >
> > $status
> > [1] ""
> >
> > $major
> > [1] "1"
> >
> > $minor
> > [1] "5.1"
> >
> > $year
> > [1] "2002"
> >
> > $month
> > [1] "06"
> >
> > $day
> > [1] "17"
> >
> > $language
> > [1] "R"
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> --
> +---------------------------------------------------------------------------+
> | Robert Gentleman                 phone : (617) 632-5250                   |
> | Associate Professor              fax:   (617)  632-2444                   |
> | Department of Biostatistics      office: M1B20                            |
> | Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
> +---------------------------------------------------------------------------+
>



From hb at maths.lth.se  Tue Mar  4 02:37:03 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue Mar  4 02:37:03 2003
Subject: [R] (no subject)
In-Reply-To: <F118XYz96VEtWdLyKpJ000153dc@hotmail.com>
Message-ID: <001601c2e1ee$8e9e72d0$7341a8c0@alpha.wehi.edu.au>

It might depend what package you are using, but in general you can save
data in data frames and matrices to file by using write.table(). It is
common to save it as a tab-delimited file so if your data is stored in a
data frame called 'df' you want to do something like

 write.table(df, file="myresults.dat", sep="\t", quote=FALSE)

The file myresults.dat can then be read by Excel and friends. For more
information see help(write.table). 

Also, please use a subject when writing to r-help. 

Hope this helps!

Henrik Bengtsson

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Steve Moore
> Sent: den 3 mars 2003 23:12
> To: r-help at stat.math.ethz.ch
> Subject: [R] (no subject)
> 
> 
> Dear Everyone,
> 
> I am a novel user of the R package (less than a week).  I am 
> using the 
> package to analyse some microarray data.  I have successfully 
> imported the 
> data, and manipulated it, resulting in additional columns of 
> data.  However, 
> I now want to extract all this new information from R for use 
> outside the 
> package.  Can anyone tell me of any commands that would allow me to 
> accomplish this?
> 
> Many thanks in advance
> 
> Stephen Moore.
> 
> 
> 
> 
> 
> _________________________________________________________________
> Chat online in real time with MSN Messenger http://messenger.msn.co.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From vsensae at hotmail.com  Tue Mar  4 03:37:03 2003
From: vsensae at hotmail.com (Vincent Stoliaroff)
Date: Tue Mar  4 03:37:03 2003
Subject: [R] writing several command line in R console
Message-ID: <F97BhI8VqzjjKXMHnXO000053d3@hotmail.com>

Hi R lovers

I would like to know how to step to the next line in the R console editor 
without breaking the continuity of my code
more clearly : if for example I write a function, so far i have to write the 
all code inside on the same line wich may become obscure as the function is 
more and more complex.
I would like to do like in the example of the manuels:

>twosam <- function(y1, y2) {
    n1  <- length(y1); n2  <- length(y2)
    yb1 <- mean(y1);   yb2 <- mean(y2)    s1  <- var(y1);    s2  <- var(y2)
    s <- ((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2)
    tst <- (yb1 - yb2)/sqrt(s2*(1/n1 + 1/n2))    tst  }


all I can do is something like that:

>twosam <- function(y1, y2) {    n1  <- length(y1); n2  <- length(y2)

+    yb1 <- mean(y1);   yb2 <- mean(y2)    s1  <- var(y1);    s2  <- var(y2)
+    s <- ((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2)
+   tst <- (yb1 - yb2)/sqrt(s2*(1/n1 + 1/n2))    tst  }

with the sign "+" in front of each line
What does this sign mean? and how could I solve my problems
Thanks



From p.murrell at auckland.ac.nz  Tue Mar  4 03:52:03 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue Mar  4 03:52:03 2003
Subject: [R] Dynamically changing point's symbol in grid.points...
References: <3E61E6DF.3060101@hppi.troitsk.ru>
Message-ID: <3E6414E2.8050406@stat.auckland.ac.nz>

Hi


M.Kondrin wrote:
> ...does not work. Do 
> k<-grid.points(c(0.1,0.2,0.3),c(0.1,0.2,0.3),pch=3,vp=viewport()) 
> (symbol - +). Try to change it grid.edit(k, pch=1) (symbol - open 
> circle). Get filled squares. pch from 0 to 25 produces the same output. 
> pch="x" - works OK. Device - x11(), gtk() (from GtkDevice). R -1.6.1


The problem is that the pch gets interpreted as an integer.

I think the right fix for this is for grid to do the coercion in C code; 
  I'll try to put this in the next grid release.

In the meantime, a workaround is to do something like ...

     grid.edit(k, pch=as.integer(1))

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz



From spencer.graves at pdf.com  Tue Mar  4 04:00:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue Mar  4 04:00:03 2003
Subject: [R] writing several command line in R console
References: <F97BhI8VqzjjKXMHnXO000053d3@hotmail.com>
Message-ID: <3E641679.2010609@pdf.com>

You can start the first line with "(".  Then everything you write will 
NOT be syntactically complelte until you issue the closing ")".  I 
learned this from Venables and Ripley, Modern Applied Statistics with S.

The "+" sign in front of each line is NOT something you should enter:  R 
changes its prompt to tell you that the previous line was not 
syntactically complete.

I prefer to keep my code someplace else and then transfer a complete 
function into R at one time.  See 
"http://socserv.socsci.mcmaster.ca/jfox/Books/Companion/ESS/index.html"

Does this answer your questions?
Best Wishes,
Spencer Graves

Vincent Stoliaroff wrote:
> 
> Hi R lovers
> 
> I would like to know how to step to the next line in the R console 
> editor without breaking the continuity of my code
> more clearly : if for example I write a function, so far i have to write 
> the all code inside on the same line wich may become obscure as the 
> function is more and more complex.
> I would like to do like in the example of the manuels:
> 
>> twosam <- function(y1, y2) {
> 
>    n1  <- length(y1); n2  <- length(y2)
>    yb1 <- mean(y1);   yb2 <- mean(y2)    s1  <- var(y1);    s2  <- var(y2)
>    s <- ((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2)
>    tst <- (yb1 - yb2)/sqrt(s2*(1/n1 + 1/n2))    tst  }
> 
> 
> all I can do is something like that:
> 
>> twosam <- function(y1, y2) {    n1  <- length(y1); n2  <- length(y2)
> 
> 
> +    yb1 <- mean(y1);   yb2 <- mean(y2)    s1  <- var(y1);    s2  <- 
> var(y2)
> +    s <- ((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2)
> +   tst <- (yb1 - yb2)/sqrt(s2*(1/n1 + 1/n2))    tst  }
> 
> with the sign "+" in front of each line
> What does this sign mean? and how could I solve my problems
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From hb at maths.lth.se  Tue Mar  4 04:07:04 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue Mar  4 04:07:04 2003
Subject: [R] writing several command line in R console
In-Reply-To: <F97BhI8VqzjjKXMHnXO000053d3@hotmail.com>
Message-ID: <000201c2e1fa$bdb27ce0$7341a8c0@alpha.wehi.edu.au>

The R prompt should be though of as a one line editor or rather one
expression editor. You can not "step" between lines etc while editing an
expression. The "+" in front of each row placed there by R indicating
that even if you have typed ENTER the expression is not finished and
that R expect you to close it (normally by closing brackets, parentesis
etc). The "+" is just an indicator and will not be included in your
expression.

What you really want to do when you create functions etc is to write the
up in an external text editor, save them with the extension *.R, e.g.
"twosam.R", and the use source to read the function in to R, i.e. 

  > source("twosam.R")

Make sure to save your twosam.R file as *text*. If you're using Windows
you can use Notepad to do this. Also, you have to save the file in the
working directory of R. You can find the current working directory of R
by

  > getwd()

Alternatively, you'll have to specify the full path to the file when
using source

  > source("C:/My Documents/hb/twosam.R")

Hope this helps! 

Henrik Bengtsson

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Vincent 
> Stoliaroff
> Sent: den 4 mars 2003 13:36
> To: r-help at stat.math.ethz.ch
> Subject: [R] writing several command line in R console
> 
> 
> 
> Hi R lovers
> 
> I would like to know how to step to the next line in the R 
> console editor 
> without breaking the continuity of my code
> more clearly : if for example I write a function, so far i 
> have to write the 
> all code inside on the same line wich may become obscure as 
> the function is 
> more and more complex.
> I would like to do like in the example of the manuels:
> 
> >twosam <- function(y1, y2) {
>     n1  <- length(y1); n2  <- length(y2)
>     yb1 <- mean(y1);   yb2 <- mean(y2)    s1  <- var(y1);    
> s2  <- var(y2)
>     s <- ((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2)
>     tst <- (yb1 - yb2)/sqrt(s2*(1/n1 + 1/n2))    tst  }
> 
> 
> all I can do is something like that:
> 
> >twosam <- function(y1, y2) {    n1  <- length(y1); n2  <- length(y2)
> 
> +    yb1 <- mean(y1);   yb2 <- mean(y2)    s1  <- var(y1);    
> s2  <- var(y2)
> +    s <- ((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2)
> +   tst <- (yb1 - yb2)/sqrt(s2*(1/n1 + 1/n2))    tst  }
> 
> with the sign "+" in front of each line
> What does this sign mean? and how could I solve my problems Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From jerrytheshrub at hotmail.com  Tue Mar  4 04:15:21 2003
From: jerrytheshrub at hotmail.com (Jeremy Z Butler)
Date: Tue Mar  4 04:15:21 2003
Subject: [R] for loop problem
Message-ID: <F155JorKDNsHU8ZAJGK0002d728@hotmail.com>

Hi,
I'm just coming to grips with "for" looping etc. and have a bit of a 
problem:

I want to generate a sequence which goes
1 2 3 4 5 6 7 8 14 15 16 17 18 19 20 21 26 27 ...
i.e. 8 consecutive numbers then 5 missed then the next 8 numbers etc.
I was going to do this using the seq() function but couldn't figure out how 
so I thought I'd try a loop:

for (x in seq(1,650,13))
{ num.set.1 <- x:x+8
}
but now what I need to do is write code such that each time it goes through 
the loop it assigns the output to a different object e.g. num.set.1 on the 
first loop then num.set.2 on the next etc. so that they can be concatenated. 
Is there any way to do this??

I may be doing this an extremely complicated way but with my zero 
programming experience its the best I can think of. Can anyone help?

J



From hb at maths.lth.se  Tue Mar  4 04:29:17 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue Mar  4 04:29:17 2003
Subject: [R] for loop problem
In-Reply-To: <F155JorKDNsHU8ZAJGK0002d728@hotmail.com>
Message-ID: <001001c2e1fe$2df0be10$7341a8c0@alpha.wehi.edu.au>

Your sequence is 1:a + k*(a+b) where a=8, b=5 and k=0,1,...,K. You can
make use of the fact that R loops of vectors if two vectors are not the
same;

  a <- 8
  b <- 5
  K <- 49
  x <- rep((0:K)*(a+b), each=a) + 1:a

Cheers

Henrik Bengtsson

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jeremy Z Butler
> Sent: den 4 mars 2003 14:14
> To: r-help at stat.math.ethz.ch
> Subject: [R] for loop problem
> 
> 
> Hi,
> I'm just coming to grips with "for" looping etc. and have a bit of a 
> problem:
> 
> I want to generate a sequence which goes
> 1 2 3 4 5 6 7 8 14 15 16 17 18 19 20 21 26 27 ...
> i.e. 8 consecutive numbers then 5 missed then the next 8 
> numbers etc. I was going to do this using the seq() function 
> but couldn't figure out how 
> so I thought I'd try a loop:
> 
> for (x in seq(1,650,13))
> { num.set.1 <- x:x+8
> }
> but now what I need to do is write code such that each time 
> it goes through 
> the loop it assigns the output to a different object e.g. 
> num.set.1 on the 
> first loop then num.set.2 on the next etc. so that they can 
> be concatenated. 
> Is there any way to do this??
> 
> I may be doing this an extremely complicated way but with my zero 
> programming experience its the best I can think of. Can anyone help?
> 
> J
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From vsensae at hotmail.com  Tue Mar  4 04:36:50 2003
From: vsensae at hotmail.com (Vincent Stoliaroff)
Date: Tue Mar  4 04:36:50 2003
Subject: [R] writing several command line in R console
Message-ID: <F964eE2FGwQ21ju2iDL000054c1@hotmail.com>


Thanks to all

1) OK for the "+" sign and the problem of syntactelly unbreaking when you 
open a { or a (
2) Thanks for the advise to use another editor for the functions. And then 
the source() function. I tried it succesfully

Long life to R!


>From: "Henrik Bengtsson" <hb at maths.lth.se>
>To: "'Vincent Stoliaroff'" <vsensae at hotmail.com>, 
><r-help at stat.math.ethz.ch>
>Subject: RE: [R] writing several command line in R console
>Date: Tue, 4 Mar 2003 14:04:13 +1100
>
>The R prompt should be though of as a one line editor or rather one
>expression editor. You can not "step" between lines etc while editing an
>expression. The "+" in front of each row placed there by R indicating
>that even if you have typed ENTER the expression is not finished and
>that R expect you to close it (normally by closing brackets, parentesis
>etc). The "+" is just an indicator and will not be included in your
>expression.
>
>What you really want to do when you create functions etc is to write the
>up in an external text editor, save them with the extension *.R, e.g.
>"twosam.R", and the use source to read the function in to R, i.e.
>
>   > source("twosam.R")
>
>Make sure to save your twosam.R file as *text*. If you're using Windows
>you can use Notepad to do this. Also, you have to save the file in the
>working directory of R. You can find the current working directory of R
>by
>
>   > getwd()
>
>Alternatively, you'll have to specify the full path to the file when
>using source
>
>   > source("C:/My Documents/hb/twosam.R")
>
>Hope this helps!
>
>Henrik Bengtsson
>
> > -----Original Message-----
> > From: r-help-admin at stat.math.ethz.ch
> > [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Vincent
> > Stoliaroff
> > Sent: den 4 mars 2003 13:36
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] writing several command line in R console
> >
> >
> >
> > Hi R lovers
> >
> > I would like to know how to step to the next line in the R
> > console editor
> > without breaking the continuity of my code
> > more clearly : if for example I write a function, so far i
> > have to write the
> > all code inside on the same line wich may become obscure as
> > the function is
> > more and more complex.
> > I would like to do like in the example of the manuels:
> >
> > >twosam <- function(y1, y2) {
> >     n1  <- length(y1); n2  <- length(y2)
> >     yb1 <- mean(y1);   yb2 <- mean(y2)    s1  <- var(y1);
> > s2  <- var(y2)
> >     s <- ((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2)
> >     tst <- (yb1 - yb2)/sqrt(s2*(1/n1 + 1/n2))    tst  }
> >
> >
> > all I can do is something like that:
> >
> > >twosam <- function(y1, y2) {    n1  <- length(y1); n2  <- length(y2)
> >
> > +    yb1 <- mean(y1);   yb2 <- mean(y2)    s1  <- var(y1);
> > s2  <- var(y2)
> > +    s <- ((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2)
> > +   tst <- (yb1 - yb2)/sqrt(s2*(1/n1 + 1/n2))    tst  }
> >
> > with the sign "+" in front of each line
> > What does this sign mean? and how could I solve my problems Thanks
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> >
> >



From bates at stat.wisc.edu  Tue Mar  4 04:45:04 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue Mar  4 04:45:04 2003
Subject: [R] for loop problem
In-Reply-To: <F155JorKDNsHU8ZAJGK0002d728@hotmail.com>
References: <F155JorKDNsHU8ZAJGK0002d728@hotmail.com>
Message-ID: <6rn0kbg61f.fsf@bates4.stat.wisc.edu>

"Jeremy Z Butler" <jerrytheshrub at hotmail.com> writes:

> Hi,
> I'm just coming to grips with "for" looping etc. and have a bit of a
> problem:
> 
> 
> I want to generate a sequence which goes
> 1 2 3 4 5 6 7 8 14 15 16 17 18 19 20 21 26 27 ...
> i.e. 8 consecutive numbers then 5 missed then the next 8 numbers etc.
> I was going to do this using the seq() function but couldn't figure
> out how so I thought I'd try a loop:
> 
> 
> for (x in seq(1,650,13))
> { num.set.1 <- x:x+8
> }
> but now what I need to do is write code such that each time it goes
> through the loop it assigns the output to a different object
> e.g. num.set.1 on the first loop then num.set.2 on the next etc. so
> that they can be concatenated. Is there any way to do this??
> 
> 
> I may be doing this an extremely complicated way but with my zero
> programming experience its the best I can think of. Can anyone help?

I suggest using a matrix.

> mseq = as.vector(matrix(1:650, nrow = 13)[1:8,])
> length(mseq)
[1] 400
> mseq[1:20]
 [1]  1  2  3  4  5  6  7  8 14 15 16 17 18 19 20 21 27 28 29 30



From FMGCFMGC at terra.es  Tue Mar  4 05:01:06 2003
From: FMGCFMGC at terra.es (FMGCFMGC)
Date: Tue Mar  4 05:01:06 2003
Subject: [R] samin and vmmin
Message-ID: <123f391268c8.1268c8123f39@teleline.es>

Hello!

Take a look at:

http://lib.stat.cmu.edu/S/minfun

The relevant file is: minfun.in (line 110 approx.)

It also points to page 210 of New S book

Hope it helps!
Fran

--- Original message: ---
I am writing code in C and would like to call R's functions samin and
vmmin (optimization routines: simulated annealing and BFGS)

I do not understand how to create and pass in the function (as well as 
the extra arguments it needs) I am optimizing.

I have read the R Extensions manual but it is still unclear to me.

Could you give me some pointers and/or direct me to some example code
which calls one of the optimizer functions and includes the definition 
of
the function to be optimized?

Thank you
Susan



From f0z6305 at labs.tamu.edu  Tue Mar  4 05:10:04 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue Mar  4 05:10:04 2003
Subject: [R] How to estimate or approximate a 3-D surface
Message-ID: <001101c2e203$11aa7c00$8bd75ba5@IE.TAMU.EDU>

Hey, R-listers

Now I am going to estimate or approximate a surface in
3-D space given a large enough number of (x,y,z) data sets.

So for these 3-D data points, is it possible to get a surface
function, like z=f(x,y) to represent this underlying surface?

Thanks for your time and point.

Fred



From jerrytheshrub at hotmail.com  Tue Mar  4 05:58:02 2003
From: jerrytheshrub at hotmail.com (Jeremy Z Butler)
Date: Tue Mar  4 05:58:02 2003
Subject: [R] log axis assignment
Message-ID: <F14901s7hpJm8OtprR00000063f@hotmail.com>

Hi again,
another problem:

This (below) isn't working and as far as I can see it damn well should. What 
I'm trying to acomplish is to run several data sets through the same 
graphing procedure, but for the pH data use a log y axis. using this code 
all graphs are drawn with a linear axis. Surely I should be able to set the 
ylog option to T using another object (logaxis).

for (n in colnames(raw))
{
if(n=="pH"){logaxis<-"T"} else {logaxis<-"F"}
plot(full.age,raw[,n],type="n",ylog=logaxis)
...
}

Any ideas what I'm doing wrong? I assume its something to do with the ylog 
(and xlog) options being read-only but I'm not sure what that means.
J



From baiyan at ece.ogi.edu  Tue Mar  4 06:07:04 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Tue Mar  4 06:07:04 2003
Subject: [R] Embed R in other applications
In-Reply-To: <001601c2e1ee$8e9e72d0$7341a8c0@alpha.wehi.edu.au>
Message-ID: <Pine.GSO.4.44.0303032047190.3389-100000@ece.ogi.edu>

Hello all,

I want to create webpages which can display the R results. The first step
is essentially getting input from client, generating graphics and
returning a page containing those images.

What should I do for this? Are there some sources on the web? Any hints
will be very helpful.

Thanks very much :)

Yan



From mschwartz at medanalytics.com  Tue Mar  4 06:27:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue Mar  4 06:27:03 2003
Subject: [R] log axis assignment
In-Reply-To: <F14901s7hpJm8OtprR00000063f@hotmail.com>
Message-ID: <001c01c2e20e$a09b5870$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jeremy Z Butler
>Sent: Monday, March 03, 2003 10:57 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] log axis assignment
>
>
>Hi again,
>another problem:
>
>This (below) isn't working and as far as I can see it damn 
>well should. What 
>I'm trying to acomplish is to run several data sets through the same 
>graphing procedure, but for the pH data use a log y axis. 
>using this code 
>all graphs are drawn with a linear axis. Surely I should be 
>able to set the 
>ylog option to T using another object (logaxis).
>
>for (n in colnames(raw))
>{
>if(n=="pH"){logaxis<-"T"} else {logaxis<-"F"}
>plot(full.age,raw[,n],type="n",ylog=logaxis)
>...
>}
>
>Any ideas what I'm doing wrong? I assume its something to do 
>with the ylog 
>(and xlog) options being read-only but I'm not sure what that means.
J


You cannot set the log scaling in the fashion in which you are trying
by setting par(ylog) as an argument to plot().  Presumably you are
getting the following error message:

"parameter "ylog" couldn't be set in high-level plot() function"


Try this instead using the proper 'log' argument to plot:

for (n in colnames(raw))
{
  if(n == "pH")
    plot(full.age, raw[,n], type = "n",  log = "y")
  else
    plot(full.age, raw[,n], type = "n")
...
}

See ?plot.default for more information.

Also, "T" and "F" as quoted characters are not the same as TRUE and
FALSE as logical boolean values.

HTH,

Marc Schwartz



From deepayan at stat.wisc.edu  Tue Mar  4 06:35:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue Mar  4 06:35:03 2003
Subject: [R] Embed R in other applications
In-Reply-To: <Pine.GSO.4.44.0303032047190.3389-100000@ece.ogi.edu>
References: <Pine.GSO.4.44.0303032047190.3389-100000@ece.ogi.edu>
Message-ID: <200303032327.54689.deepayan@stat.wisc.edu>

See http://www.math.montana.edu/Rweb/

On Monday 03 March 2003 11:00 pm, Bai Yan wrote:
> Hello all,
>
> I want to create webpages which can display the R results. The first step
> is essentially getting input from client, generating graphics and
> returning a page containing those images.
>
> What should I do for this? Are there some sources on the web? Any hints
> will be very helpful.
>
> Thanks very much :)
>
> Yan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Tue Mar  4 09:15:05 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Mar  4 09:15:05 2003
Subject: [R] R version conflict.
In-Reply-To: <Pine.GSO.4.44.0303031517030.24846-100000@ece.ogi.edu>
References: <Pine.GSO.4.44.0303031517030.24846-100000@ece.ogi.edu>
Message-ID: <x23cm3mtu1.fsf@biostat.ku.dk>

Bai Yan <baiyan at ece.ogi.edu> writes:

> My mistake :(
> Seems that there's another R installed by root. So when I use .libPaths()
> there're two of them:
> 
> > .libPaths()
> [1] "/disk/hopper/projects/class/cse514/R/library"
> [2] "/usr/lib/R/library"
> 
> How could the second path be enabled then? The R_LIBS have already been
> set to as the [1] only.

If that happens, you're running the installed R, not the one you
compiled. You need to run it as /where/you/put/it/bin/R (or bin/R if
you're in the toplevel build dir).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From petr.pikal at precheza.cz  Tue Mar  4 09:38:03 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue Mar  4 09:38:03 2003
Subject: [R] writing several command line in R console
In-Reply-To: <F97BhI8VqzjjKXMHnXO000053d3@hotmail.com>
Message-ID: <3E6473E7.11242.3FF563@localhost>

Hallo

On 4 Mar 2003 at 2:36, Vincent Stoliaroff wrote:

> 
> Hi R lovers
> 
> I would like to know how to step to the next line in the R console
> editor without breaking the continuity of my code more clearly : if
> for example I write a function, so far i have to write the all code
> inside on the same line wich may become obscure as the function is
> more and more complex. I would like to do like in the example of the
> manuels:
> 
> >twosam <- function(y1, y2) {
>     n1  <- length(y1); n2  <- length(y2)
>     yb1 <- mean(y1);   yb2 <- mean(y2)    s1  <- var(y1);    s2  <-
>     var(y2) s <- ((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2) tst <- (yb1 -
>     yb2)/sqrt(s2*(1/n1 + 1/n2))    tst  }
> 
> 
> all I can do is something like that:
> 
> >twosam <- function(y1, y2) {    n1  <- length(y1); n2  <- length(y2)
> 
> +    yb1 <- mean(y1);   yb2 <- mean(y2)    s1  <- var(y1);    s2  <-
> +    var(y2) s <- ((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2)
> +   tst <- (yb1 - yb2)/sqrt(s2*(1/n1 + 1/n2))    tst  }
> 
> with the sign "+" in front of each line
> What does this sign mean? and how could I solve my problems
> Thanks

Maybe looking to the manuals will be more precise than my 
answer.

+ is a continuity sign and means you did not finished your imput 
and you shall continue typing your command.

But why you do not use any text ditor for writing functions and 
than copy/paste to R command window?




> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

CheersPetr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From Bernhard.Pfaff at drkw.com  Tue Mar  4 09:43:07 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Tue Mar  4 09:43:07 2003
Subject: [R] Embed R in other applications
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9004730266@ibfftce505.is.de.dresdnerkb.com>

see the contributed pacakge "R2HTML"; in case you have access to a databank:
"RODBC" package and the like might also be an option in combination with
*.php and/or *.asp-files for web-publishing.
I have implemented both and it runs succesfully without any "hickups".
Updating the data, running R-program as batch via scheduler and outputting
directly or writing it first into a databank for further processing.

HTH,
Bernhard

-----Original Message-----
From: Bai Yan [mailto:baiyan at ece.ogi.edu]
Sent: 04 March 2003 06:01
To: r-help at stat.math.ethz.ch
Subject: [R] Embed R in other applications


Hello all,

I want to create webpages which can display the R results. The first step
is essentially getting input from client, generating graphics and
returning a page containing those images.

What should I do for this? Are there some sources on the web? Any hints
will be very helpful.

Thanks very much :)

Yan

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------



From petr.pikal at precheza.cz  Tue Mar  4 09:49:04 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue Mar  4 09:49:04 2003
Subject: [R] How to estimate or approximate a 3-D surface
In-Reply-To: <001101c2e203$11aa7c00$8bd75ba5@IE.TAMU.EDU>
Message-ID: <3E647608.30700.48455E@localhost>

Hi

On 3 Mar 2003 at 22:03, Feng Zhang wrote:

> Hey, R-listers
> 
> Now I am going to estimate or approximate a surface in
> 3-D space given a large enough number of (x,y,z) data sets.
> 
> So for these 3-D data points, is it possible to get a surface
> function, like z=f(x,y) to represent this underlying surface?

I am not sure but interp from akima package shall give you an 
interpolation of your data.
> 
> Thanks for your time and point.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

Cheers

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From Bernhard.Pfaff at drkw.com  Tue Mar  4 09:54:45 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Tue Mar  4 09:54:45 2003
Subject: Recall: [R] Embed R in other applications
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9004730267@ibfftce505.is.de.dresdnerkb.com>

Pfaff, Bernhard would like to recall the message, "[R] Embed R in other
applications".


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------



From stuart.leask at nottingham.ac.uk  Tue Mar  4 10:20:04 2003
From: stuart.leask at nottingham.ac.uk (Stuart Leask)
Date: Tue Mar  4 10:20:04 2003
Subject: [R] R in your pocket on a Sharp Zaurus
References: <3E647608.30700.48455E@localhost>
Message-ID: <004f01c2e22f$1ab7ab20$f2e1f380@mczsjl>

R v.1.6.2 is now available for the Sharp SL-5500 Zaurus linux pda. Thanks to
the effort of Simon Pickering at Bath University, NA handling is now correct
and graphics function fine. It can run on the unexpanded 'out of the box'
machine. The FPU emulation can slow some operations a lot, but it can do
lowess smoothing on over 10,000 data points in just a few minutes, as good
as the 486SX25 I was happy with not that many years ago. And R (+Zaurus) in
the hand/jacket pocket is worth any number of laptops in the bush.

You'll need R (see http://students.bath.ac.uk/enpsgp/Zaurus/#R), plus a few
libraries (from http://ipkgfind.handhelds.org/). To add graphics, you can
either run native X-windows - faster - or run X within qtopia (see
http://students.bath.ac.uk/enpsgp/Zaurus/#X) for convenience.

Stuart

PS.
At present the help system doesn't function. We're working on this - we're
not sure why, but note that in the current compilation, the CONTENTS folders
end up empty. All suggestions gratefully received...

Dr Stuart Leask MA MRCPsych, Clinical Lecturer in Psychiatry
University of Nottingham Dept of Psychiatry, Duncan Macmillan House
Porchester Road, Nottingham. NG3 6AA. UK
http://www.nottingham.ac.uk/psychiatry/staff/sjl.html



From kurt.sys at rug.ac.be  Tue Mar  4 10:30:03 2003
From: kurt.sys at rug.ac.be (Kurt Sys)
Date: Tue Mar  4 10:30:03 2003
Subject: [R] tex/pdf?
Message-ID: <15972.29253.501709.620758@ksys.rug.ac.be>

Hello,

I'm having some problems, now with building libraries/packages. Actually, with making pdf- or latex-files. So, everyting is ok, I can generate latex-files ('.tex') using 'R CMD Rdconv -t tex', but apparently, it are not valid latex-files (no 'documentclass', no 'body' etc). How come? Do I have to add these things manually?


Kurt.



From Morten.Sickel at nrpa.no  Tue Mar  4 10:38:02 2003
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Tue Mar  4 10:38:02 2003
Subject: [R] log axis assignment
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5E67@postix.nrpa.no>

From: Jeremy Z Butler [mailto:jerrytheshrub at hotmail.com]
> Surely I should be able to set the 
> ylog option to T using another object (logaxis).
>
>for (n in colnames(raw))
>{
>if(n=="pH"){logaxis<-"T"} else {logaxis<-"F"}
>plot(full.age,raw[,n],type="n",ylog=logaxis)
>...
>}

What (probably) will work is:

if(n=="pH"){logaxis<-"Y"} else {logaxis<-""}
plot(full.age,raw[,n],type="n",log=logaxis)

The plot-argument log takes which axis that shuld be logaritmic. 


Morten



From ripley at stats.ox.ac.uk  Tue Mar  4 10:43:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Mar  4 10:43:04 2003
Subject: [R] tex/pdf?
In-Reply-To: <15972.29253.501709.620758@ksys.rug.ac.be>
Message-ID: <Pine.LNX.4.44.0303040939090.31554-100000@gannet.stats>

On Tue, 4 Mar 2003, Kurt Sys wrote:

> I'm having some problems, now with building libraries/packages. 
Actually, with making pdf- or latex-files. So, everyting is ok, 
I can generate latex-files ('.tex') using 'R CMD Rdconv -t tex', 
but apparently, it are not valid latex-files (no 'documentclass', 
no 'body' etc). How come? Do I have to add these things manually?

No, you use help(offline=TRUE) or R CMD Rd2dvi (which is documented in 
R-exts).


Please wrap your lines in emails ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From simon at stats.gla.ac.uk  Tue Mar  4 10:56:06 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Tue Mar  4 10:56:06 2003
Subject: [R] How to estimate or approximate a 3-D surface
In-Reply-To: <001101c2e203$11aa7c00$8bd75ba5@IE.TAMU.EDU>
Message-ID: <Pine.SOL.3.96.1030304095446.25919C-100000@moon.stats.gla.ac.uk>

Have you tried looking at packages mgcv or gss? 

> Now I am going to estimate or approximate a surface in
> 3-D space given a large enough number of (x,y,z) data sets.
> 
> So for these 3-D data points, is it possible to get a surface
> function, like z=f(x,y) to represent this underlying surface?

Simon
_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814



From stuart.leask at nottingham.ac.uk  Tue Mar  4 11:23:03 2003
From: stuart.leask at nottingham.ac.uk (Stuart Leask)
Date: Tue Mar  4 11:23:03 2003
Subject: [R] How to estimate or approximate a 3-D surface
References: <Pine.SOL.3.96.1030304095446.25919C-100000@moon.stats.gla.ac.uk>
Message-ID: <007301c2e237$e1173b70$f2e1f380@mczsjl>

Locfit has worked well for me.
http://cm.bell-labs.com/cm/ms/departments/sia/project/locfit/

Stuart

Dr Stuart Leask MA MRCPsych, Clinical Lecturer in Psychiatry
University of Nottingham Dept of Psychiatry, Duncan Macmillan House
Porchester Road, Nottingham. NG3 6AA. UK
http://www.nottingham.ac.uk/psychiatry/staff/sjl.html

----- Original Message ----- 
From: "Simon Wood" <simon at stats.gla.ac.uk>
To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
Cc: "R-Help" <r-help at stat.math.ethz.ch>
Sent: Tuesday, March 04, 2003 9:55 AM
Subject: Re: [R] How to estimate or approximate a 3-D surface


> Have you tried looking at packages mgcv or gss? 
> 
> > Now I am going to estimate or approximate a surface in
> > 3-D space given a large enough number of (x,y,z) data sets.
> > 
> > So for these 3-D data points, is it possible to get a surface
> > function, like z=f(x,y) to represent this underlying surface?
> 
> Simon
> _____________________________________________________________________
> > Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
> >>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
> >>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Tue Mar  4 11:33:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Mar  4 11:33:03 2003
Subject: [R] writing several command line in R console
In-Reply-To: <3E6473E7.11242.3FF563@localhost>
References: <3E6473E7.11242.3FF563@localhost>
Message-ID: <x2of4ro20k.fsf@biostat.ku.dk>

"Petr Pikal" <petr.pikal at precheza.cz> writes:


> > I would like to know how to step to the next line in the R console
> > editor without breaking the continuity of my code more clearly : if
> > for example I write a function, so far i have to write the all code
> > inside on the same line wich may become obscure as the function is
> > more and more complex. I would like to do like in the example of the
> > manuels:
> > 
> > >twosam <- function(y1, y2) {
> >     n1  <- length(y1); n2  <- length(y2)
> >     yb1 <- mean(y1);   yb2 <- mean(y2)    s1  <- var(y1);    s2  <-
> >     var(y2) s <- ((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2) tst <- (yb1 -
> >     yb2)/sqrt(s2*(1/n1 + 1/n2))    tst  }

...
> 
> + is a continuity sign and means you did not finished your imput 
> and you shall continue typing your command.
> 
> But why you do not use any text ditor for writing functions and 
> than copy/paste to R command window?

I'm not sure if and how it works on Windows, but on Unix one of the
better kept secrets of the readline library is that you can embed
newlines by typing ctr-V ctr-J, e.g.

> x <- matrix(c(1,2,3,
                4,5,6,
                7,8,9), 3)

The nice thing is that it allows you to recall the entire command and
edit it (I don't think it survives being saved to the history file
though). If you have ever had to correct a typo in an expression that
has been split over 8 lines, you'll know what I mean:

up,up,up,up,up,up,up,up,RET,
up,up,up,up,up,up,up,up,RET,
up,up,up,up,up,up,up,up,RET,
up,up,up,up,up,up,up,up,fix typo,RET,
up,up,up,up,up,up,up,up,RET,
up,up,up,up,up,up,up,up,RET,
up,up,up,up,up,up,up,up,RET,
up,up,up,up,up,up,up,up,RET

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Tue Mar  4 11:42:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Mar  4 11:42:03 2003
Subject: [R] How to estimate or approximate a 3-D surface
In-Reply-To: <007301c2e237$e1173b70$f2e1f380@mczsjl>
Message-ID: <Pine.LNX.4.44.0303041031300.31886-100000@gannet.stats>

On Tue, 4 Mar 2003, Stuart Leask wrote:

> Locfit has worked well for me.
> http://cm.bell-labs.com/cm/ms/departments/sia/project/locfit/

Unfortunately it has not been updated for current versions of R: it also 
writes diagnostic output to stderr which is not shown on GUI versions of R
(especially on Windows).  There is a version in the Devel area on CRAN.

Package akima is the most obvious choice for interpolation.  For
smoothing, there are all the various spatial packages (and package fields)
as well as mgcv and gss already mentioned.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lun_li at hotmail.com  Tue Mar  4 11:59:02 2003
From: lun_li at hotmail.com (lun li)
Date: Tue Mar  4 11:59:02 2003
Subject: [R] Parallel programming using R
Message-ID: <BAY2-F59Tafb3n7A0t30001886b@hotmail.com>

Dear All,

For my regression problem(thousand dependents by thousand predictors by 
hundred months observations), I prefer to  parallel computation in R.  Is it 
possible to parallel programming using R as using C and Fortran?


Cheers,


Lun



From kurt.sys at rug.ac.be  Tue Mar  4 12:14:04 2003
From: kurt.sys at rug.ac.be (Kurt Sys)
Date: Tue Mar  4 12:14:04 2003
Subject: [R] tex/pdf?
In-Reply-To: <Pine.LNX.4.44.0303040939090.31554-100000@gannet.stats>
References: <15972.29253.501709.620758@ksys.rug.ac.be>
	<Pine.LNX.4.44.0303040939090.31554-100000@gannet.stats>
Message-ID: <15972.35493.494994.406906@ksys.rug.ac.be>

Mail from ripley at stats.ox.ac.uk, sent on Tuesday March 4
2003 at 09:42 (GMT+0000):

  > On Tue, 4 Mar 2003, Kurt Sys wrote:
  > 
  > > I'm having some problems, now with building
  > libraries/packages.  Actually, with making pdf- or
  > latex-files. So, everyting is ok, I can generate
  > latex-files ('.tex') using 'R CMD Rdconv -t tex', but
  > apparently, it are not valid latex-files (no
  > 'documentclass', no 'body' etc). How come? Do I have to
  > add these things manually?
  > 
  > No, you use help(offline=TRUE) or R CMD Rd2dvi (which is
  > documented in R-exts).
  > 

Ok... tnx. Was a stupid question. Should have found that myself...

Kurt.



From s.su at qut.edu.au  Tue Mar  4 12:29:03 2003
From: s.su at qut.edu.au (Steve Su)
Date: Tue Mar  4 12:29:03 2003
Subject: [R] Instability in package gld in R?
Message-ID: <001601c2e241$23b60c00$2032b583@busaccb337f>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030304/62e10691/attachment.pl

From mkondrin at hppi.troitsk.ru  Tue Mar  4 12:38:04 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Tue Mar  4 12:38:04 2003
Subject: [R] Parallel programming using R
References: <BAY2-F59Tafb3n7A0t30001886b@hotmail.com>
Message-ID: <3E6527BE.2030408@hppi.troitsk.ru>

lun li wrote:
> Dear All,
> 
> For my regression problem(thousand dependents by thousand predictors by 
> hundred months observations), I prefer to  parallel computation in R.  
> Is it possible to parallel programming using R as using C and Fortran?
> 
> 
> Cheers,
> 
> 
> Lun
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

Look up  RPvm and RMPI packages

Good luck ...



From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Mar  4 12:48:03 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue Mar  4 12:48:03 2003
Subject: [R] Parallel programming using R
In-Reply-To: <3E6527BE.2030408@hppi.troitsk.ru>
References: <BAY2-F59Tafb3n7A0t30001886b@hotmail.com> <3E6527BE.2030408@hppi.troitsk.ru>
Message-ID: <Pine.LNX.4.51.0303041246220.25225@artemis.imbe.med.uni-erlangen.de>

> lun li wrote:
> > Dear All,
> >
> > For my regression problem(thousand dependents by thousand predictors by
> > hundred months observations), I prefer to  parallel computation in R.
> > Is it possible to parallel programming using R as using C and Fortran?
> >
> >
> > Cheers,
> >
> >
> > Lun
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> Look up  RPvm and RMPI packages
>

looking at www.openmosix.org is maybe interesting, too.

Torsten

> Good luck ...
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From ugulumbe at yahoo.co.uk  Tue Mar  4 14:17:04 2003
From: ugulumbe at yahoo.co.uk (=?iso-8859-1?q?Usman=20Shehu?=)
Date: Tue Mar  4 14:17:04 2003
Subject: [R] (no subject)
Message-ID: <20030304131557.95350.qmail@web10906.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030304/fc574b6a/attachment.pl

From vito.muggeo at giustizia.it  Tue Mar  4 14:27:05 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Tue Mar  4 14:27:05 2003
Subject: [R] error using try() and coxph()
References: <BAY2-F59Tafb3n7A0t30001886b@hotmail.com> <3E6527BE.2030408@hppi.troitsk.ru> <Pine.LNX.4.51.0303041246220.25225@artemis.imbe.med.uni-erlangen.de>
Message-ID: <011601c2e251$030235a0$5c13070a@it.giustizia.it>

Dear all,
I'm experiencing some problems in using the following code to perform
simulations with Cox models (using coxph() in survival package):

for(i in 1:1000){
    dd<-....#simulate the dataframe
    o0<-try(coxph(Surv(start,stop,status)~x,data=dd))
    o1<-try(coxph(Surv(start,stop,status)~x+x:stop,data=dd))
    o2<-try(coxph(Surv(start,stop,status)~x+x:poly(stop,2),data=dd))
    ....
    }

The error (both in Rgui and in batch mode) causes R to crash immediately
with a DOS message like "Error in survival.dll"
Using coxph() without try() simulation stops because sometimes the model may
be not fitted, I get the explicit error message. Therefore I suspect that
the problem depends on using try(coxph(....)). Also note that using
try(arima(....)) for a similar problem works well.
versions: survival 2.9-4 and R 1.5.1 on WinMe
I know I should update R, but I wonder whether the problem depends on the
old version

Could anyone suggest me anything?

cheers,
vito



From duncan at research.bell-labs.com  Tue Mar  4 14:58:03 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Tue Mar  4 14:58:03 2003
Subject: [R] question about XML (package)
In-Reply-To: <3E561A7C.D14C7ACC@mitre.org>; from upton@mitre.org on Fri, Feb 21, 2003 at 07:24:28AM -0500
References: <200302210923.h1L9NFj13501@punik.econ.au.dk> <3E561A7C.D14C7ACC@mitre.org>
Message-ID: <20030304085740.B5955@jessie.research.bell-labs.com>

Apologies for the late reply; I was travelling and didn't see the message 
until Ott brought it to my attention today.

Indeed, Stephen's diagnosis and workaround is correct: excessive
trimming.  I have just put a new version of the package (XML_0.93-2)
on the Omegahat web site

  http://www.omegahat.org/RSXML


So with inputs

<?xml version="1.0"?>
<fields> 
<v1>a1  </v1>
<v1>1 </v1>
<v1>a b</v1>
<v1>a b c</v1>
<v1> a b c  </v1>
<v2> 2 </v2> 
<v3> 3</v3>
<v3> 3 </v3>
</fields>

we get

> v = xmlRoot(xmlTreeParse("oot.xml"))
> xmlSApply(v, xmlValue)
     v1      v1      v1      v1      v1      v2      v3      v3 
   "a1"     "1"   "a b" "a b c" "a b c"     "2"     "3"     "3" 


Thanks for bringing it to my attention.

 D.


Stephen C. Upton wrote:
> Ott,
> 
> I get the same thing on windows version. If you set "trim=FALSE" in the
> xmlTreeParse function call, it works. I suspect xmlTreeParse is trimming
> a little too much! But xmlTreeParse(with trim=TRUE) also works when the
> first character is a non-digit - see below. We'll probably need to look
> at the source code, unless someone else has better insight.
> 
> > a <- xmlTreeParse("test.xml",trim=FALSE)
> > a$doc
> $file
> [1] "test.xml"
> 
> $version
> [1] "1.0"
> 
> $children
> $children$fields
>  <fields>
> 
> 
>   <v1>
>   1
>   </v1>
> 
> 
>   <v2>
>    2
>   </v2>
> 
> 
>   <v3>
>    3
>   </v3>
> 
> 
>  </fields>
> 
> However, it also works when the first character is a non-digit - so far.
> Here's a revised test.xml file:
> <?xml version="1.0"?>
> <fields>
> <v1>a1 </v1>
> <v2>2 </v2>
> <v3> 3</v3>
> </fields>
> 
> > a <- xmlTreeParse("test.xml")
> > a
> $doc
> $file
> [1] "test.xml"
> 
> $version
> [1] "1.0"
> 
> $children
> $children$fields
>  <fields>
>   <v1>
>   a1
>   </v1>
>   <v2>
>   </v2>
>   <v3>
>   3
>   </v3>
>  </fields>
> 
> HTH
> steve
> 
> 
> -------------------------------
> > version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R  -
> 
> Ott Toomet wrote:
> 
> > Hi,
> >
> > I have a problem with spacing in XML files when reading them with
> > xmlTreeParse.  I don't know the exact specification of xml but
> > according what I have red before it should work.
> >
> > consider a tiny test.xml file:
> >
> > <?xml version="1.0"?>
> > <fields>
> > <v1>1 </v1>
> > <v2> 2 </v2>
> > <v3> 3</v3>
> > </fields>
> >
> > i.e. I have three fields v1, v2 and v3 which differ only by spacing.
> > Now when reading it as
> >
> > > a <- xmlTreeParse("/home/otoomet/tyyq/Taani-piir/andmed/test.xml")
> > > a$doc$children$fields
> >  <fields>
> >   <v1>
> >   </v1>
> >   <v2>
> >   2
> >   </v2>
> >   <v3>
> >   3
> >   </v3>
> >  </fields>
> >
> > you can see that field v1 is empty.  Is it my misinterpretation, or a
> > problem with the library?
> >
> > Thanks in advance,
> >
> > Ott
> >
> > -----------------
> > > version
> >          _
> > platform i686-pc-linux-gnu
> > arch     i686
> > os       linux-gnu
> > system   i686, linux-gnu
> > status
> > major    1
> > minor    5.1
> > year     2002
> > month    06
> > day      17
> > language R
> > ------------
> > Package: XML
> > Version: 0.93-1
> > Date: 2002/11/06
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From cenktan at bilgi.edu.tr  Tue Mar  4 15:04:08 2003
From: cenktan at bilgi.edu.tr (Cenktan Ozyildirim)
Date: Tue Mar  4 15:04:08 2003
Subject: [R] Unit root test for panel data
Message-ID: <AD6F561CF23D95468FDB78DE39D6944702C8FC0C@EXCHANGE>

Dear Sir/Madam,
I need to apply IPS, Fischer or any other more contemporary panel data unit
root test. I would be glad if you could inform me whether there are
r-modules which can perform these tests. I thank you very much in advance
for your precious time and interest.
Yours Sincerely,
Cenktan ?zy?ld?r?m



From rbonk at host.sk  Tue Mar  4 15:14:03 2003
From: rbonk at host.sk (Rado Bonk)
Date: Tue Mar  4 15:14:03 2003
Subject: [R] Williams' corrected G-test
Message-ID: <1046809122.1915.3.camel@templar.fns.uniba.sk>

Hi R-users,

Does anybody know under which command is Williams' corrected G-test
implemented in R? The test should determine whether the frequency of
over- versus under-estimated values differs. Is there any other test in
R which was designed to do the same?

Best regards,

Rado Bonk 

-- 
Radoslav Bonk M.S.
Dept. of Physical Geography and Geoecology
Faculty of Sciences, Comenius University
Mlynska Dolina 842 15, Bratislava, SLOVAKIA
tel: +421 905 968 127 e-mail: rbonk at host.sk



From duncan at research.bell-labs.com  Tue Mar  4 15:22:02 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Tue Mar  4 15:22:02 2003
Subject: [R] How to modify XML documents and save changes
In-Reply-To: <3E5B9BC8.BC0DA745@mitre.org>; from upton@mitre.org on Tue, Feb 25, 2003 at 11:37:29AM -0500
References: <1046169844.1042.24.camel@sista-08.esat.kuleuven.ac.be> <3E5B9BC8.BC0DA745@mitre.org>
Message-ID: <20030304092107.C5955@jessie.research.bell-labs.com>

Again, Stephen is right on the mark with his explanation of modifying
the XML objects and needing to put the modified values back into the
containing structure. Trees & graphs are slightly cumbersome in the S
language since it is not a reference-based language.  There are some
tricks one can use that are in the XML package for indexing them with
a "cursor", but these are (currently) only for use when constructing a
tree from scratch within S.

> A little cumbersome, but doable. One other option is to use xmlEventParse
> and write a handler that would add the element after the one you're
> interested in.  I hope there is a better way, but haven't seen it yet. :-(

Here there is some good news. xmlEventParse is extremely low-level
relative to xmlTreeParse and typically used for efficiency in
minimizing the amount of storage used when parsing the contents of an
XML document. The idea is that an S function gets invoked when an XML
tag is opened, and another when it is closed.

xmlTreeParse() can also be used in this event-driven style
programming.  When the XML parser encounters the close of a tag, it
looks for a suitable S function to invoke specified in the handlers
argument of xmlTreeParse.  If there is an element in that list of
functions whose name matches the tag name, it is invoked.  Thus if you
programmatically want to augment/modify the contents of an XML node,
you can supply a function that operates on that node.  The function
can return the resulting updated node and it will be inserted into the
overall tree as one would expect.

So, suppose one wants to _always_ add a node 
  <Norm></Norm>
to each <tagname></tagname> node, you can use the following

myFun <- function(node,...) {
  node <- append.XMLNode(node, xmlNode("Norm"))
  node
}

and then use this in the command

xmlTreeParse("file.xml", handlers = list(tagname = myFun), asTree = TRUE)

One can also use XSL to do this, either directly from the command
line or from S via the Sxslt package.

If one only wants to modify particular <tagname> elements, it is
probably easiest to read the entire tree and modify it directly.

For people familiar with other XML parsers, the default xmlTreeParse
behaves like DOM and xmlEventParse behaves likes SAX.  With handlers,
xmlTreeParse() provides a hybrid parser for XML somewhere between DOM
and SAX.

 D.


Stephen C. Upton wrote:
> Steffen,
> 
> As with most R objects, you're basically putting a copy of the R object into
> the new object. Any operation or function you apply to that object does not
> affect the original. Same goes for append.xmlNode - you're appending to the
> original and getting back another structure that is the original plus the
> new node. Finally, saveXML works on an object of XMLInternalDocument and doc
> (the object returned by xmlTreeParse) is a XMLDocument object.
> 
> Here's one suggestion:
> 1. Read in the doc object as you've done, but manipulate the structure as
> you would any other R object, e.g.,
> QTListNode [[1]] <-
> append.xmlNode(QTListNode[[1]],xmlNode(name="Norm",attrs=NULL))
> 2. you then need to modify that node within the root with this new, modified
> node, e.g. (assume I've assigned root <- xmlRoot(doc)),
> root[[whateverindextagnameis]] <- QTListNode[[1]]
> (I use the index here rather than the name, since it's unique - if you use a
> name,e.g., root[["tagname"]], that just adds a list element to root with
> name "tagname")
> 3. to write out, use write with toString.XMLNode,
> write(toString.XMLNode(root, file="out.xml")
> 
> Since this is probably a little cumbersome, suggest writing a function to do
> the finding, appending, and replacement.
> 
> A little cumbersome, but doable. One other option is to use xmlEventParse
> and write a handler that would add the element after the one you're
> interested in.  I hope there is a better way, but haven't seen it yet. :-(
> 
> HTH
> steve
> 
> 
> Steffen Durinck wrote:
> 
> > Dear,
> >
> > I want to read XML documents, add child nodes to some elements and store
> > everything back as an XML document.
> >
> > I've tryed the following:
> >
> > doc <- xmlTreeParse("file.xml")
> > QTListNode<-xmlElementsByTagName(xmlRoot(doc)[[1]],"tagname")
> > append.xmlNode(QTListNode[[1]],newXMLNode(name ="Norm", attrs = NULL))
> > saveXML(doc, file = "out.xml", compression = 0, indent=T)
> >
> > This doesn't seem to work.
> > Can anyone help?
> >
> > Thanks,
> > Steffen
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From gregory.benmenzer at gazdefrance.com  Tue Mar  4 15:37:30 2003
From: gregory.benmenzer at gazdefrance.com (Gregory BENMENZER)
Date: Tue, 4 Mar 2003 15:37:30 +0100
Subject: [R] linear model with arma errors
Message-ID: <OF68600A60.EB358AD9-ON41256CDF.00500A02@notes.edfgdf.fr>

Dear all,

I'm looking for how can I estimate a linear model with ar(ma) errors :

y(t)=a*X(t)+e(t) with
P(B)e(t)=Q(B)u(t)

where u is a white noise and P, Q are some polynomes.

Could you help me ?

Gr?gory Benmenzer


From gregory.benmenzer at gazdefrance.com  Tue Mar  4 15:37:30 2003
From: gregory.benmenzer at gazdefrance.com (Gregory BENMENZER)
Date: Tue, 4 Mar 2003 15:37:30 +0100
Subject: [R] linear model with arma errors
Message-ID: <OF68600A60.EB358AD9-ON41256CDF.00500A02@notes.edfgdf.fr>

Dear all,

I'm looking for how can I estimate a linear model with ar(ma) errors :

y(t)=a*X(t)+e(t) with
P(B)e(t)=Q(B)u(t)

where u is a white noise and P, Q are some polynomes.

Could you help me ?

Gr?gory Benmenzer




From eglen at pcg.wustl.edu  Tue Mar  4 16:40:52 2003
From: eglen at pcg.wustl.edu (Stephen Eglen)
Date: Tue, 4 Mar 2003 09:40:52 -0600
Subject: [R] suggestion for addition to R-lang.texi
Message-ID: <15972.51460.712059.767900@mosaics.wustl.edu>

Small suggestion for the documentation:

Should the = operator for assignments, described on
http://developer.r-project.org/equalAssign.html, now be included in
the operator table in doc/manual/R-lang.texi?  If so, one possibility
could be after lines 1096/7:

@item @code{<-}
@tab Left assignment, binary
@item @code{=}
@tab Left assignment, binary

Also, where is the best place to send suggestions of this nature? I
didn't want to send it to r-bugs, since it is not a bug.

Stephen


From bates at stat.wisc.edu  Tue Mar  4 16:44:40 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 04 Mar 2003 09:44:40 -0600
Subject: [R] linear model with arma errors
In-Reply-To: <OF68600A60.EB358AD9-ON41256CDF.00500A02@notes.edfgdf.fr>
References: <OF68600A60.EB358AD9-ON41256CDF.00500A02@notes.edfgdf.fr>
Message-ID: <6rznobnnkn.fsf@bates4.stat.wisc.edu>

"Gregory BENMENZER" <gregory.benmenzer at gazdefrance.com> writes:

> Dear all,
> 
> I'm looking for how can I estimate a linear model with ar(ma) errors :
> 
> y(t)=a*X(t)+e(t) with
> P(B)e(t)=Q(B)u(t)
> 
> where u is a white noise and P, Q are some polynomes.
> 
> Could you help me ?
> 
> Gr?gory Benmenzer

Perhaps function gls in the nlme package.  See

help('gls', package = 'nlme')


From bjw34032 at mh.uk.sbphrd.com  Tue Mar  4 16:38:53 2003
From: bjw34032 at mh.uk.sbphrd.com (Brandon Whitcher)
Date: Tue, 4 Mar 2003 15:38:53 +0000
Subject: [R] Wavelets correlation test
Message-ID: <Pine.SGI.4.44.0303041520320.132415-100000@hcu091.ha.uk.sbphrd.com>


> Hello, I use wavethresh packages to perform wavelet analysis. In
> particular, I would like to compare 2 signals (vectors) after a wavelet
> decomposition. I would like to use cor.test function, but this function
> acts on the entire vector values. I plan to perform a cor.test on each
> level of the wavelet decomposition, say N. So I will have at the end of
> a first step N results of cor.test.
>
> How can I deal with this N results to have an answer globaly ?

A lot of this code is already implemented in an alternative wavelet
analysis package for R (waveslim).  There, I have placed code to compute
multiscale covariance/correlation estimates that may also be a function of
lag.  This would provide a correlation coefficient (or autocorrelation
sequence) per scale.  Approximate confidence intervals for these estimates
are also available, there might be a reference in wave.covariance or
wave.correlation -- I can't remember.  The papers of interest are:

- Whitcher, Guttorp, Percival (2000).  Wavelet analysis of covariance with
application to atmospheric time series, JGR 105 (D11), 14,941-14,962.

- Serroukh and Walden (2000).  Wavelet scale analysis of bivariate time
series I: Motivation and estimation, Journal of Nonparametric Statistics,
13 (1), 1-36.

- Gencay, Selcuk, Whitcher (2001).  An Introduction to Wavelets and Other
Filtering Methods in Finance and Economics, Academic Press.

I think it would be difficult to make a statement for the whole series.
Some scales may agree and some scales may not.  What is the scientific
question you are trying to answer?

cheers...

Brandon

--------------------------------------------------------------------------
 Senior Researcher in Imaging                             GlaxoSmithKline
 Research Statistics Unit              New Frontiers Science Park (South)
                                          Third Avenue, Harlow   CM19 5AW
 phone:  +44 (0)127 963 1285                               United Kingdom
 fax:    +44 (0)127 964 4004

                        brandon.j.whitcher at gsk.com
--------------------------------------------------------------------------


From spencer.graves at pdf.com  Tue Mar  4 16:58:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 04 Mar 2003 07:58:03 -0800
Subject: [R] linear model with arma errors
References: <OF68600A60.EB358AD9-ON41256CDF.00500A02@notes.edfgdf.fr>
Message-ID: <3E64CD0B.6030500@pdf.com>

That's discussed in Pinhiero and Bates, Mixed Effects Models in S and 
S-Plus.  I don't have the book in my hand now, so I can't tell you 
exactly where to find it.  However, I'm pretty confident that it can be 
done in "lme".

Spencer Graves

Gregory BENMENZER wrote:
> Dear all,
> 
> I'm looking for how can I estimate a linear model with ar(ma) errors :
> 
> y(t)=a*X(t)+e(t) with
> P(B)e(t)=Q(B)u(t)
> 
> where u is a white noise and P, Q are some polynomes.
> 
> Could you help me ?
> 
> Gr?gory Benmenzer
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help


From p.dalgaard at biostat.ku.dk  Tue Mar  4 17:04:07 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 04 Mar 2003 17:04:07 +0100
Subject: [R] suggestion for addition to R-lang.texi
In-Reply-To: <15972.51460.712059.767900@mosaics.wustl.edu>
References: <15972.51460.712059.767900@mosaics.wustl.edu>
Message-ID: <x2bs0rnmo8.fsf@biostat.ku.dk>

Stephen Eglen <eglen at pcg.wustl.edu> writes:

> Small suggestion for the documentation:
> 
> Should the = operator for assignments, described on
> http://developer.r-project.org/equalAssign.html, now be included in
> the operator table in doc/manual/R-lang.texi?  If so, one possibility
> could be after lines 1096/7:
> 
> @item @code{<-}
> @tab Left assignment, binary
> @item @code{=}
> @tab Left assignment, binary
> 
> Also, where is the best place to send suggestions of this nature? I
> didn't want to send it to r-bugs, since it is not a bug.

It could easily be considered one... There is a Documentation category
in the bug repository, so why not?

BTW, I wonder: why did your mail come with sender "r-help-bounces"
instead of the usual r-help-admin and confuse my mail filter?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From adrian.trapletti at lmttrading.com  Tue Mar  4 17:37:20 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Tue, 04 Mar 2003 17:37:20 +0100
Subject: [R] tseries contains a class for irregularly spaced time series
Message-ID: <3E64D640.8185C15A@lmttrading.com>

A new version of tseries (0.9-10) has been uploaded to CRAN. The new
version contains the class "irts" for irregularly spaced time series.
Irregular time series are basically time series where each observation
(uni- or multivariate) has a time-stamp represented by an object of
class "POSIXct". It provides some basic functionality such as reading
and writing irregular time series from files, or plotting, printing,
subscripting, and interpolating irregular time series. This is a first
version of the class "irts" and I very much welcome feedback.

best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com


From mschwartz at medanalytics.com  Tue Mar  4 17:40:47 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 4 Mar 2003 10:40:47 -0600
Subject: [R] r-help-bounces and r-devel-bounces e-mail?
Message-ID: <000d01c2e26c$cf2ccbc0$0201a8c0@MARC>

Hi all,

Just curious on the sudden change in the e-mail address coming from
r-help and r-devel today. They are indicated as being
r-help-bounces at stat.math.ethz.ch and
r-devel-bounces at stat.math.ethz.ch.

Any clues?  I just noticed that my e-mail filter rule suddenly stopped
putting these messages in their respective folders this morning (my
time).

Regards,

Marc


From jgentry at jimmy.harvard.edu  Tue Mar  4 17:53:13 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Tue, 4 Mar 2003 11:53:13 -0500 (EST)
Subject: [R] r-help-bounces and r-devel-bounces e-mail?
In-Reply-To: <000d01c2e26c$cf2ccbc0$0201a8c0@MARC>
Message-ID: <Pine.SOL.4.20.0303041152580.8108-100000@santiam.dfci.harvard.edu>

> Any clues?  I just noticed that my e-mail filter rule suddenly stopped
> putting these messages in their respective folders this morning (my
> time).

I believe they're upgrading the Mailman software that runs the list.


From Charles.Annis at statisticalengineering.com  Tue Mar  4 18:05:52 2003
From: Charles.Annis at statisticalengineering.com (Charles Annis, P.E.)
Date: Tue, 4 Mar 2003 12:05:52 -0500
Subject: [R] r-help-bounces and r-devel-bounces e-mail?
In-Reply-To: <Pine.SOL.4.20.0303041152580.8108-100000@santiam.dfci.harvard.edu>
Message-ID: <000a01c2e270$5358d3a0$0202a8c0@DHT0TL11>

You need to add r-help-bounces at stat.math.ethz.ch to your filtering rules
to augment your current rule, r-help-admin at stat.math.ethz.ch




Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFAX: 503-217-5849
http://www.StatisticalEngineering.com


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jeff Gentry
Sent: Tuesday, March 04, 2003 11:53 AM
To: Marc Schwartz
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] r-help-bounces and r-devel-bounces e-mail?

> Any clues?  I just noticed that my e-mail filter rule suddenly stopped
> putting these messages in their respective folders this morning (my
> time).

I believe they're upgrading the Mailman software that runs the list.

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


From renaud.lancelot at cirad.fr  Tue Mar  4 18:11:52 2003
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Tue, 04 Mar 2003 17:11:52 +0000
Subject: [R] linear model with arma errors
In-Reply-To: <3E64CD0B.6030500@pdf.com>
References: <OF68600A60.EB358AD9-ON41256CDF.00500A02@notes.edfgdf.fr>
	<3E64CD0B.6030500@pdf.com>
Message-ID: <3E64DE58.6070306@cirad.fr>

Spencer Graves wrote:
> That's discussed in Pinhiero and Bates, Mixed Effects Models in S and 
> S-Plus.  I don't have the book in my hand now, so I can't tell you 
> exactly where to find it.  However, I'm pretty confident that it can be 
> done in "lme".

Only if the model includes random effects. Otherwise, the gls function 
might be useful. Both lme and gls are in the nlme library.

Best,

Renaud

> Spencer Graves
> 
> Gregory BENMENZER wrote:
> 
>> Dear all,
>>
>> I'm looking for how can I estimate a linear model with ar(ma) errors :
>>
>> y(t)=a*X(t)+e(t) with
>> P(B)e(t)=Q(B)u(t)
>>
>> where u is a white noise and P, Q are some polynomes.
>>
>> Could you help me ?
>>
>> Gr?gory Benmenzer
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


-- 
Dr Renaud Lancelot, v?t?rinaire
CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
Programme Productions Animales
http://www.cirad.fr/presentation/programmes/prod-ani.shtml (Fran?ais)
http://www.cirad.fr/presentation/en/program-eng/prod-ani.shtml (English)

ISRA-LNERV                      tel    +221 832 49 02
BP 2057 Dakar-Hann              fax    +221 821 18 79 (CIRAD)
Senegal                         e-mail renaud.lancelot at cirad.fr


From rossini at blindglobe.net  Tue Mar  4 18:13:07 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue, 04 Mar 2003 09:13:07 -0800
Subject: [R] suggestion for addition to R-lang.texi
In-Reply-To: <x2bs0rnmo8.fsf@biostat.ku.dk> (Peter Dalgaard BSA's message of
 "04 Mar 2003 17:04:07 +0100")
References: <15972.51460.712059.767900@mosaics.wustl.edu>
	<x2bs0rnmo8.fsf@biostat.ku.dk>
Message-ID: <87el5nrr6k.fsf@jeeves.blindglobe.net>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> BTW, I wonder: why did your mail come with sender "r-help-bounces"
> instead of the usual r-help-admin and confuse my mail filter?

Mailman upgrade?

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------------
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(CHANGE: monday/wednesday/friday locations are completely unpredictable.)


From mschwartz at medanalytics.com  Tue Mar  4 18:30:31 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 4 Mar 2003 11:30:31 -0600
Subject: [R] r-help-bounces and r-devel-bounces e-mail?
In-Reply-To: <000a01c2e270$5358d3a0$0202a8c0@DHT0TL11>
Message-ID: <000f01c2e273$c29d2470$0201a8c0@MARC>

>-----Original Message-----
>From: Charles Annis, P.E. 
>[mailto:Charles.Annis at StatisticalEngineering.com] 
>Sent: Tuesday, March 04, 2003 11:06 AM
>To: 'Jeff Gentry'; 'Marc Schwartz'
>Cc: r-help at stat.math.ethz.ch
>Subject: RE: [R] r-help-bounces and r-devel-bounces e-mail?
>
>
>You need to add r-help-bounces at stat.math.ethz.ch to your 
>filtering rules to augment your current rule, 
>r-help-admin at stat.math.ethz.ch
>
>Charles Annis, P.E.


Easy enough to do of course. Just curious if this was a temporary (as
Jeff note suggests) or a permanent change.  The 'bounces' suggests a
problem, which raised my suspicions.

>From Peter Dalgaard's reply earlier, it would seem to be unexpected.
I wasn't sure if I had perhaps missed an announcement somewhere.

Thanks,

Marc


From maechler at stat.math.ethz.ch  Tue Mar  4 18:42:15 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 4 Mar 2003 18:42:15 +0100
Subject: [R] r-help-bounces and r-devel-bounces e-mail?
In-Reply-To: <Pine.SOL.4.20.0303041152580.8108-100000@santiam.dfci.harvard.edu>
References: <000d01c2e26c$cf2ccbc0$0201a8c0@MARC>
	<Pine.SOL.4.20.0303041152580.8108-100000@santiam.dfci.harvard.edu>
Message-ID: <15972.58743.602233.554008@gargle.gargle.HOWL>

>>>>> "JeffG" == Jeff Gentry <jgentry at jimmy.harvard.edu>
>>>>>     on Tue, 4 Mar 2003 11:53:13 -0500 (EST) writes:

    >> Any clues?  I just noticed that my e-mail filter rule suddenly stopped
    >> putting these messages in their respective folders this morning (my
    >> time).

    JeffG> I believe they're upgrading the Mailman software that runs the list.

Exactly.  "They" := { (our head sys.admin.), me }

The new mailman (2.1.1 instead of 2.0.13) has quite a few new
features; particularly it says it allows unsubscribing without a
password --- something which will hopefully save quite a bit of
my time {from answering e-mails of people who are not patient
enough to read a page on the web to its end}.


I'm sorry we overlooked the change from 
    "Sender: <list>-admin at stat.math.ethz.ch"
to
    "Sender: <list>-bounces at stat.math.ethz.ch"

BTW: I think there are still some new problems that we hadn't
     seen on the testing machine on which we tried everything.
But now is past the end of the working day around here...  
Please send more feedback directly to me, aka  r-help-admin at stat....

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From petzoldt at rcs.urz.tu-dresden.de  Tue Mar  4 18:45:28 2003
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Tue, 04 Mar 2003 18:45:28 +0100
Subject: [R] implementing ecological models in R
Message-ID: <3E64E638.50506@rcs.urz.tu-dresden.de>

Hi all,

we found, that R is not only *the* superior data analysis, graphics and 
statistics package, but it is also a general tool for implementing, 
running and teaching ecological models. Last week we held our second 
course "Modelling in Limnology" using R. Some material (code and docs) 
was produced for this purpose and may be interesting to someone else, so 
I put the tutorial "Konstruktion ?kologischer Modelle mit der Open 
Source Software R" on my homepage.

The tutorial covers
* a short introduction,
* some simple regression models,
* the modelling of populations with ODEs (thanks to Woodrow Sezter!),
* some basic lake modelling stuff and
* some basic individual-based techniques (population dynamics, movement, 
Conway's game of life, an individual-based predator-prey model).

All examples are given in full source code. The tutorial is in German 
language, but possibly someone may be interested to work together with 
me on an English version in the future. It is work in progress, so 
please excuse typos and mistakes (some PDF errors are already known).
On the other hand, I would be very glad about remarks and constructive 
criticism.

The tutorial can be found on

http://www.tu-dresden.de/fghhihb/petzoldt/zeugs.html

together with an absolutely preliminary version of an accompanying 
library (the name simecol may be changed soon).

Thank you for your feedback!

Many thanks to all the people who are making the R-project possible!

Thomas

-- 
Thomas Petzoldt                    Tel. +49-351-463 3 4954
Dresden University of Technology   Fax  +49-351-463 3 7108
Institute for Hydrobiology         petzoldt at rcs.urz.tu-dresden.de
01062 Dresden

http://www.tu-dresden.de/fghhihb/petzoldt/


From mschwartz at medanalytics.com  Tue Mar  4 18:57:28 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 4 Mar 2003 11:57:28 -0600
Subject: [R] r-help-bounces and r-devel-bounces e-mail?
In-Reply-To: <15972.58743.602233.554008@gargle.gargle.HOWL>
Message-ID: <001201c2e277$86fda2b0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Martin
Maechler
>Sent: Tuesday, March 04, 2003 11:42 AM
>To: r-help at stat.math.ethz.ch
>Subject: Re: [R] r-help-bounces and r-devel-bounces e-mail?
>
>
>>>>>> "JeffG" == Jeff Gentry <jgentry at jimmy.harvard.edu>
>>>>>>     on Tue, 4 Mar 2003 11:53:13 -0500 (EST) writes:
>
>    >> Any clues?  I just noticed that my e-mail filter rule 
>suddenly stopped
>    >> putting these messages in their respective folders this 
>morning (my
>    >> time).
>
>    JeffG> I believe they're upgrading the Mailman software 
>that runs the list.
>
>Exactly.  "They" := { (our head sys.admin.), me }
>
>The new mailman (2.1.1 instead of 2.0.13) has quite a few new 
>features; particularly it says it allows unsubscribing without 
>a password --- something which will hopefully save quite a bit 
>of my time {from answering e-mails of people who are not 
>patient enough to read a page on the web to its end}.
>
>
>I'm sorry we overlooked the change from 
>    "Sender: <list>-admin at stat.math.ethz.ch"
>to
>    "Sender: <list>-bounces at stat.math.ethz.ch"
>
>BTW: I think there are still some new problems that we hadn't
>     seen on the testing machine on which we tried everything. 
>But now is past the end of the working day around here...  
>Please send more feedback directly to me, aka  r-help-admin at stat....
>
>Regards,
>Martin Maechler <maechler at stat.math.ethz.ch>	


Martin,

Thanks for the clarifications. Most importantly thanks for your energy
in maintaining and continuously improving the lists!

Best regards,

Marc


From HStevens at muohio.edu  Tue Mar  4 19:03:40 2003
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Tue, 04 Mar 2003 13:03:40 -0500
Subject: [R] Sample size and stepAIC,  step, or AIC
Message-ID: <5.1.0.14.2.20030304130131.0186ce50@po.muohio.edu>

Do any R functions incorporate a sample sample size correction (e.g., 
Burnham and Anderson 1998).
Thanks,
Hank Stevens

Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology


From alobo at ija.csic.es  Tue Mar  4 19:17:13 2003
From: alobo at ija.csic.es (Agustin Lobo)
Date: Tue, 4 Mar 2003 19:17:13 +0100 (MET)
Subject: [R] problem at installing Rade
Message-ID: <Pine.OSF.3.91.1030304190650.1314X-100000@paleo>


Hi!

I try to install the R version of ade4 on a linux (suse7.3) box
with R 1.6.2 (from rpm)
and get 
/usr/local/bin/R INSTALL ade4_1.00.tar.gz
tar: /usr/local/lib/libpthread.so.0: version `GLIBC_2.2' not found 
(required by /lib/librt.so.1)
ERROR: cannot extract package from 'ade4_1.00.tar.gz'

But I actually have glibc 2.2.4 
(at least this is what my suse's Yast conf. tool 
tells me, perhaps there is a more direct way of checking 
it?)

Having used the rpm for R, should I use the
rpm for ade4? 

Thanks 

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es


From lun_li at hotmail.com  Tue Mar  4 19:25:02 2003
From: lun_li at hotmail.com (lun li)
Date: Tue, 04 Mar 2003 18:25:02 +0000
Subject: [R] Parallel programming using R
Message-ID: <BAY2-F158NDN4CxpAOA0004e6dc@hotmail.com>

Thank you very much for  the information of  RPvm and RMPI packages. I got 
them.

Best regards,


Lun






>From: "M.Kondrin" <mkondrin at hppi.troitsk.ru>
>To: lun li <lun_li at hotmail.com>
>CC: R-Help <R-help at stat.math.ethz.ch>
>Subject: Re: [R] Parallel programming using R
>Date: Tue, 04 Mar 2003 14:25:02 -0800
>
>lun li wrote:
>>Dear All,
>>
>>For my regression problem(thousand dependents by thousand predictors by 
>>hundred months observations), I prefer to  parallel computation in R.  Is 
>>it possible to parallel programming using R as using C and Fortran?
>>
>>
>>Cheers,
>>
>>
>>Lun
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>
>Look up  RPvm and RMPI packages
>
>Good luck ...
>


From alobo at ija.csic.es  Tue Mar  4 19:37:22 2003
From: alobo at ija.csic.es (Agustin Lobo)
Date: Tue, 4 Mar 2003 19:37:22 +0100 (MET)
Subject: [R] Disregard:"problem at installing Rade"
Message-ID: <Pine.OSF.3.91.1030304193512.1314Z-100000@paleo>


Excuses to the list,

this problem is a "peculiarity" of my system that
I (thought) had solved, but after installing 
a (non-R) package seems to be here again.

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es


From ripley at stats.ox.ac.uk  Tue Mar  4 19:29:48 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 4 Mar 2003 18:29:48 +0000 (GMT)
Subject: [R] Sample size and stepAIC,  step, or AIC
In-Reply-To: <5.1.0.14.2.20030304130131.0186ce50@po.muohio.edu>
Message-ID: <Pine.LNX.4.44.0303041820370.6200-100000@gannet.stats>

They use AIC as defined by its author, Akaike.  With good reason: `sample
size' is not a well-defined concept in general, and the R functions are
general.

Most people call the adjusted (I hesitate to call it `corrected') version 
`AICC'.  I believe the `clarified' 2002 edition of Burnham & Anderson uses 
AIC_c.


(It's easy to set up problems, e.g, a binomial glm, in which the number of 
observations relevant to each parameter differs radically.  They occur in 
real life too.)

On Tue, 4 Mar 2003, Martin Henry H. Stevens wrote:

> Do any R functions incorporate a sample sample size correction (e.g., 
> Burnham and Anderson 1998).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Mar  4 19:37:24 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 4 Mar 2003 18:37:24 +0000 (GMT)
Subject: [R] problem at installing [R]ade
In-Reply-To: <Pine.OSF.3.91.1030304190650.1314X-100000@paleo>
Message-ID: <Pine.LNX.4.44.0303041832470.6200-100000@gannet.stats>

That appears to be a message from your tar.  Perhaps try

tar zxvf ade4_1.00.tar.gz
R INSTALL ade4

I suspect the first step will fail, and it would be because your pthreads
library is not the right version.  Note that it is using /usr/local/lib,
and perhaps something has installed an older version there?

On Tue, 4 Mar 2003, Agustin Lobo wrote:

> 
> Hi!
> 
> I try to install the R version of ade4 on a linux (suse7.3) box
> with R 1.6.2 (from rpm)
> and get 
> /usr/local/bin/R INSTALL ade4_1.00.tar.gz
> tar: /usr/local/lib/libpthread.so.0: version `GLIBC_2.2' not found 
> (required by /lib/librt.so.1)
> ERROR: cannot extract package from 'ade4_1.00.tar.gz'
> 
> But I actually have glibc 2.2.4 
> (at least this is what my suse's Yast conf. tool 
> tells me, perhaps there is a more direct way of checking 
> it?)
> 
> Having used the rpm for R, should I use the
> rpm for ade4? 

R packages do not come in rpms.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Mar  4 20:17:38 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 4 Mar 2003 19:17:38 +0000 (GMT)
Subject: [R] (no subject)
In-Reply-To: <20030304131557.95350.qmail@web10906.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0303041325360.9390-100000@gannet.stats>

On Tue, 4 Mar 2003, Usman Shehu wrote:

> It is possible I run R on MINGW32 MSYS? If so how do I configure the MSYS to do that. 

MSYS is an environment for building Unix packages under Windows.  R runs
under Windows:  you don't need Unix-emulation tools to run it.

We have a much more reliable set of Unix-emulation tools to build 
it, selected from Cygwin (of which MSYS is a derivative, anyway).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From l12345p2000 at yahoo.com  Tue Mar  4 21:38:16 2003
From: l12345p2000 at yahoo.com (Peng)
Date: Tue, 4 Mar 2003 12:38:16 -0800 (PST)
Subject: [R] How to extract R{i} from lme object?
Message-ID: <20030304203816.43583.qmail@web21007.mail.yahoo.com>

Hi, lme() users,

Can some one tell me how to do this.
I model Orthodont with the same G for random
variables, but different R{i}'s for boys and girls, so
that I can get sigma1_square_hat for boys and
sigma2_square_hat for girls.

The model is Y{i}=X{i}beta + Z{i}b + e{i}
b ~ iid N(0,G) and e{i} ~ iid N(0,R{i}) i=1,2
orth.lme <- lme(distance ~ Sex * age, data=Orthodont,
random=~age|Subject, weights=varIdent(form=~1|Sex),
method="ML")

I can see the numbers I need from summary(), but how
can I extract them? I tried several functions in nlme,
but I cannot find a correct one.

Peng

Peng Liu
------------------------------
Peng Liu                      |
Division of Statistics        |
Northern Illinois University  |
De Kalb, IL 60115, USA        |
E-mail: pliu at math.niu.edu     |
------------------------------


From sundar.dorai-raj at pdf.com  Tue Mar  4 22:15:35 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 04 Mar 2003 13:15:35 -0800
Subject: [R] How to extract R{i} from lme object?
References: <20030304203816.43583.qmail@web21007.mail.yahoo.com>
Message-ID: <3E651777.7020602@pdf.com>



Peng wrote:
> Hi, lme() users,
> 
> Can some one tell me how to do this.
> I model Orthodont with the same G for random
> variables, but different R{i}'s for boys and girls, so
> that I can get sigma1_square_hat for boys and
> sigma2_square_hat for girls.
> 
> The model is Y{i}=X{i}beta + Z{i}b + e{i}
> b ~ iid N(0,G) and e{i} ~ iid N(0,R{i}) i=1,2
> orth.lme <- lme(distance ~ Sex * age, data=Orthodont,
> random=~age|Subject, weights=varIdent(form=~1|Sex),
> method="ML")
> 
> I can see the numbers I need from summary(), but how
> can I extract them? I tried several functions in nlme,
> but I cannot find a correct one.
> 
> Peng
> 

Peng,

Is this what you need?

R> data(Orthodont)
R> orth.lme <- lme(distance ~ Sex * age,
+                  data=Orthodont,
+                  random=~age|Subject,
+                  weights=varIdent(form=~1|Sex),
+                  method="ML")
R> orth.lme$modelStruct$varStruct
Variance function structure of class varIdent representing
      Male    Female
1.0000000 0.4112708
R> rcov.unscaled <- as.matrix(orth.lme$modelStruct$reStruct[[1]])
R> rcov.scaled <- rcov.unscaled * orth.lme$sigma^2
R> Stdev <- sqrt(diag(rcov.scaled))
R> Stdev
(Intercept)         age
   1.7914848   0.1408001
R>

If there's nesting, look for more elements in $reStruct.

Regards,
Sundar


From l12345p2000 at yahoo.com  Tue Mar  4 23:11:54 2003
From: l12345p2000 at yahoo.com (Peng)
Date: Tue, 4 Mar 2003 14:11:54 -0800 (PST)
Subject: [R] How to extract R{i} from lme object?
In-Reply-To: <3E651777.7020602@pdf.com>
Message-ID: <20030304221154.84831.qmail@web21008.mail.yahoo.com>


--- Sundar Dorai-Raj <sundar.dorai-raj at pdf.com> wrote:
> 
> 
> Peng wrote:
> > Hi, lme() users,
> > 
> > Can some one tell me how to do this.
> > I model Orthodont with the same G for random
> > variables, but different R{i}'s for boys and
> girls, so
> > that I can get sigma1_square_hat for boys and
> > sigma2_square_hat for girls.
> > 
> > The model is Y{i}=X{i}beta + Z{i}b + e{i}
> > b ~ iid N(0,G) and e{i} ~ iid N(0,R{i}) i=1,2
> > orth.lme <- lme(distance ~ Sex * age,
> data=Orthodont,
> > random=~age|Subject,
> weights=varIdent(form=~1|Sex),
> > method="ML")
> > 
> > I can see the numbers I need from summary(), but
> how
> > can I extract them? I tried several functions in
> nlme,
> > but I cannot find a correct one.
> > 
> > Peng
> > 
> 
> Peng,
> 
> Is this what you need?
> 
> R> data(Orthodont)
> R> orth.lme <- lme(distance ~ Sex * age,
> +                  data=Orthodont,
> +                  random=~age|Subject,
> +                  weights=varIdent(form=~1|Sex),
> +                  method="ML")
> R> orth.lme$modelStruct$varStruct
> Variance function structure of class varIdent
> representing
>       Male    Female
> 1.0000000 0.4112708

Sundar, 

Thanks a lot!
In the above model, I assume the error term for boy
has iid N(0, sigma1), and that for girl has iid
N(0,sigma2). I hope that I wrote the correct lme(). If
so, what I want is:
(1/unique(attributes(orth.lme$modelStruct$varStruct)$weights)*orth.lme$sigma)^2
[1] 2.6292575 0.4447223
, where 2.629 for boys, and 0.445 for girls.

I am still wondering whether there is a function like
getVarCov(), so that I can get R var-cov matrix
directly. I looked through the function list of nlme,
but I cannot find.

Peng

> R> rcov.unscaled <-
> as.matrix(orth.lme$modelStruct$reStruct[[1]])
> R> rcov.scaled <- rcov.unscaled * orth.lme$sigma^2
> R> Stdev <- sqrt(diag(rcov.scaled))
> R> Stdev
> (Intercept)         age
>    1.7914848   0.1408001
> R>
> 
> If there's nesting, look for more elements in
> $reStruct.
> 
> Regards,
> Sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help


From lina at u.washington.edu  Tue Mar  4 23:52:47 2003
From: lina at u.washington.edu (Michael Na Li)
Date: Tue, 04 Mar 2003 14:52:47 -0800
Subject: [R] Parallel programming using R
References: <BAY2-F158NDN4CxpAOA0004e6dc@hotmail.com>
Message-ID: <a64r6id9s0.fsf@qiuranke.phony.washington.edu>

On Tue, 04 Mar 2003, lun li told this:
>  Thank you very much for  the information of  RPvm and RMPI packages. I got
>  them.
>  

You might want to wait for a few days for snow (Simple Network of
Workstations) package to reach CPAN. Or download it from here,

http://www.stat.uiowa.edu/~luke/R/cluster/cluster.html

Cheers,

Michael


From h_m_ at po.harenet.ne.jp  Wed Mar  5 03:14:37 2003
From: h_m_ at po.harenet.ne.jp (Hiroto Miyoshi)
Date: Wed, 5 Mar 2003 11:14:37 +0900
Subject: [R] logistic regression for repeated measurement
Message-ID: <002d01c2e2bc$f9733040$0500a8c0@miyoshi>

Dear R-users

I need your help.
I have a data set which was collected from 
an experiment of one between- and one 
within-subject design. And the response 
data is coded by success(1)/failure(0).

The experiment had two groups of subjects:
The one was experimental, and the 
other, control.  The experimental group
got a task training, and both groups of subjects
were tested twice, once before the training
and once after the training. at the same time.
I like to examine the effect of training by
detecting an interaction effect of the group and 
tests. 
Now, it seems glm is not appropriate to this 
situation since it does not deal with stratified
errors.

Could you lead me to appropriate functions?
Sincerely
-----------------------
Hiroto Miyoshi
????
h_m_ at po.harenet.ne.jp


From fharrell at virginia.edu  Wed Mar  5 03:33:57 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Tue, 4 Mar 2003 21:33:57 -0500
Subject: [R] logistic regression for repeated measurement
In-Reply-To: <002d01c2e2bc$f9733040$0500a8c0@miyoshi>
References: <002d01c2e2bc$f9733040$0500a8c0@miyoshi>
Message-ID: <20030304213357.57626023.fharrell@virginia.edu>

On Wed, 5 Mar 2003 11:14:37 +0900
Hiroto Miyoshi <h_m_ at po.harenet.ne.jp> wrote:

> Dear R-users
> 
> I need your help.
> I have a data set which was collected from 
> an experiment of one between- and one 
> within-subject design. And the response 
> data is coded by success(1)/failure(0).
> 
> The experiment had two groups of subjects:
> The one was experimental, and the 
> other, control.  The experimental group
> got a task training, and both groups of subjects
> were tested twice, once before the training
> and once after the training. at the same time.
> I like to examine the effect of training by
> detecting an interaction effect of the group and 
> tests. 
> Now, it seems glm is not appropriate to this 
> situation since it does not deal with stratified
> errors.
> 
> Could you lead me to appropriate functions?
> Sincerely
> -----------------------
> Hiroto Miyoshi
> h_m_ at po.harenet.ne.jp
> 

There are several ways to go.  GEE is one, random effects models another.  One other approach is to install the Hmisc and Design packages (http://hesweb1.med.virginia.edu/biostat/s) and do (assume id is the unique subject identifier):

f <- lrm(y ~ x1 + x2*x3 + ..., x=T, y=T) # working independence model
g <- robcov(f, id)         # cluster sandwich variance adjustment
h <- bootcov(f, id, B=100) # cluster bootstrap adjustment
summary(g)  # etc.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From abunn at montana.edu  Wed Mar  5 04:21:20 2003
From: abunn at montana.edu (Andy Bunn)
Date: Tue, 4 Mar 2003 20:21:20 -0700
Subject: [R] Autologistic regression
Message-ID: <000001c2e2c6$4b41ca40$15a00ecf@simATE>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030304/d12439db/attachment.pl

From f0z6305 at labs.tamu.edu  Wed Mar  5 07:05:20 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Wed, 5 Mar 2003 00:05:20 -0600
Subject: [R] How to draw several plots in one figure?
Message-ID: <000701c2e2dd$344593a0$8bd75ba5@IE.TAMU.EDU>

Hey,

I want to draw several plots sequently, but have to make them dispaly in one
figure.
So how to achieve this?

Thanks.

Fred


From hb at maths.lth.se  Wed Mar  5 07:30:34 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 5 Mar 2003 17:30:34 +1100
Subject: [R] How to draw several plots in one figure?
In-Reply-To: <000701c2e2dd$344593a0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <000d01c2e2e0$bbcd2290$7341a8c0@alpha.wehi.edu.au>

See help(layout).

Henrik Bengtsson

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Feng Zhang
> Sent: den 5 mars 2003 17:05
> To: R-Help
> Subject: [R] How to draw several plots in one figure?
> 
> 
> Hey,
> 
> I want to draw several plots sequently, but have to make them 
> dispaly in one figure. So how to achieve this?
> 
> Thanks.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>


From f0z6305 at labs.tamu.edu  Wed Mar  5 07:35:00 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Wed, 5 Mar 2003 00:35:00 -0600
Subject: [R] How to draw several plots in one figure?
References: <000701c2e2dd$344593a0$8bd75ba5@IE.TAMU.EDU>
	<001001c2e2e0$a2751910$2032b583@busaccb337f>
Message-ID: <001a01c2e2e1$590e17d0$8bd75ba5@IE.TAMU.EDU>

Thanks, Su.

But I want to plot the several plots in the same
x-y axis setting, not in multiple subplots.
----- Original Message -----
From: "Steve Su" <s.su at qut.edu.au>
To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
Sent: Wednesday, March 05, 2003 12:29 AM
Subject: Re: [R] How to draw several plots in one figure?


> Dear Fred,
>
> try par(mfrow=c(2,2)) for example, gives four plots per page. Also try
> trellis plots.
>
> Steve.
>
>
> ----- Original Message -----
> From: "Feng Zhang" <f0z6305 at labs.tamu.edu>
> To: "R-Help" <r-help at stat.math.ethz.ch>
> Sent: Wednesday, March 05, 2003 4:05 PM
> Subject: [R] How to draw several plots in one figure?
>
>
> > Hey,
> >
> > I want to draw several plots sequently, but have to make them dispaly in
> one
> > figure.
> > So how to achieve this?
> >
> > Thanks.
> >
> > Fred
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From jerrytheshrub at hotmail.com  Wed Mar  5 08:13:59 2003
From: jerrytheshrub at hotmail.com (Jeremy Z Butler)
Date: Wed, 05 Mar 2003 20:13:59 +1300
Subject: [R] How to draw several plots in one figure?
Message-ID: <F100BO4EbPjPqusNvve00024676@hotmail.com>

One way is to make inital plot:
>plot()
Then build other data into the plot using:

lines()
points()
etc.
see help files for those

Alternatively:

set par(new=T)
then plot again and the device wont be cleared
J.




>From: "Feng Zhang" <f0z6305 at labs.tamu.edu>
>To: "Steve Su" <s.su at qut.edu.au>
>CC: R-Help <r-help at stat.math.ethz.ch>
>Subject: Re: [R] How to draw several plots in one figure?
>Date: Wed, 5 Mar 2003 00:35:00 -0600
>
>Thanks, Su.
>
>But I want to plot the several plots in the same
>x-y axis setting, not in multiple subplots.
>----- Original Message -----
>From: "Steve Su" <s.su at qut.edu.au>
>To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
>Sent: Wednesday, March 05, 2003 12:29 AM
>Subject: Re: [R] How to draw several plots in one figure?
>
>
> > Dear Fred,
> >
> > try par(mfrow=c(2,2)) for example, gives four plots per page. Also try
> > trellis plots.
> >
> > Steve.
> >
> >
> > ----- Original Message -----
> > From: "Feng Zhang" <f0z6305 at labs.tamu.edu>
> > To: "R-Help" <r-help at stat.math.ethz.ch>
> > Sent: Wednesday, March 05, 2003 4:05 PM
> > Subject: [R] How to draw several plots in one figure?
> >
> >
> > > Hey,
> > >
> > > I want to draw several plots sequently, but have to make them dispaly 
>in
> > one
> > > figure.
> > > So how to achieve this?
> > >
> > > Thanks.
> > >
> > > Fred
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help


From darryl at hpli.hpl.hp.com  Wed Mar  5 08:51:22 2003
From: darryl at hpli.hpl.hp.com (Darryl Greig)
Date: Wed, 5 Mar 2003 09:51:22 +0200
Subject: BSOD with ESS[R] under win2000
Message-ID: <000401c2e2ec$04c56600$9e09b00f@hpli.hpl.hp.com>

I have had a visit from our windows buddy the BSOD twice in one day when
running
R1.6.2 under ESS5.1.24 on a win2000 platform. I wasn't doing anything
special, just
moving or resizing the emacs window, although I did have 4 or 5 emacs
windows
open at the time. Has anyone else observed this problem?

Thanks, Darryl.


From ripley at stats.ox.ac.uk  Wed Mar  5 09:07:40 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 5 Mar 2003 08:07:40 +0000 (GMT)
Subject: BSOD with ESS[R] under win2000
In-Reply-To: <000401c2e2ec$04c56600$9e09b00f@hpli.hpl.hp.com>
Message-ID: <Pine.LNX.4.44.0303050756590.15305-100000@gannet.stats>

Was there anything to indicate that this was a problem in R (and not emacs 
nor Windows, especially a Windows driver)?

Those of us who never experience it will not be familiar with `BSOD': it
is I presume the blue screen shown by a fatal error in Windows internals.
I think I have seen just once under XP (in 2 year's usage).  If so it 
contains information about the cause.

BTW, as the rw-FAQ Q2.11 indicates, this is not the right list for ESS
users' questions, but my guess would be that this is not a problem in 
either R or ESS.

On Wed, 5 Mar 2003, Darryl Greig wrote:

> I have had a visit from our windows buddy the BSOD twice in one day when
> running
> R1.6.2 under ESS5.1.24 on a win2000 platform. I wasn't doing anything
> special, just
> moving or resizing the emacs window, although I did have 4 or 5 emacs
> windows
> open at the time. Has anyone else observed this problem?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From darryl at hpli.hpl.hp.com  Wed Mar  5 09:31:31 2003
From: darryl at hpli.hpl.hp.com (Darryl Greig)
Date: Wed, 5 Mar 2003 10:31:31 +0200
Subject: BSOD with ESS[R] under win2000
In-Reply-To: <Pine.LNX.4.44.0303050756590.15305-100000@gannet.stats>
Message-ID: <000501c2e2f1$a0145d00$9e09b00f@hpli.hpl.hp.com>

It's certainly a difficult problem to isolate - as you say it may well
be connected to some other combination of application / drivers. I shall
investigate emacs help as a next step. 

-----Original Message-----
From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
Sent: Wednesday, March 05, 2003 10:08 AM
To: Darryl Greig
Cc: R-Help (E-mail)
Subject: Re: BSOD with ESS[R] under win2000


Was there anything to indicate that this was a problem in R (and not emacs 
nor Windows, especially a Windows driver)?

Those of us who never experience it will not be familiar with `BSOD': it
is I presume the blue screen shown by a fatal error in Windows internals.
I think I have seen just once under XP (in 2 year's usage).  If so it 
contains information about the cause.

BTW, as the rw-FAQ Q2.11 indicates, this is not the right list for ESS
users' questions, but my guess would be that this is not a problem in 
either R or ESS.

On Wed, 5 Mar 2003, Darryl Greig wrote:

> I have had a visit from our windows buddy the BSOD twice in one day when
> running
> R1.6.2 under ESS5.1.24 on a win2000 platform. I wasn't doing anything
> special, just
> moving or resizing the emacs window, although I did have 4 or 5 emacs
> windows
> open at the time. Has anyone else observed this problem?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From l12345p2000 at yahoo.com  Wed Mar  5 18:21:07 2003
From: l12345p2000 at yahoo.com (Peng)
Date: Wed, 5 Mar 2003 09:21:07 -0800 (PST)
Subject: [R] How to extract R{i} from lme object?
In-Reply-To: <3E65AEC8.3010508@cirad.fr>
Message-ID: <20030305172107.85888.qmail@web21007.mail.yahoo.com>


--- Renaud Lancelot <renaud.lancelot at cirad.fr> wrote:
> Hi Peng,
> 
> Peng wrote:
> [snip]
> > I am still wondering whether there is a function
> like
> > getVarCov(), so that I can get R var-cov matrix
> > directly. I looked through the function list of
> nlme,
> > but I cannot find.
> > 
> > Peng
> 
> R>library(nlme)
> R>data(Orthodont)
> R>fm1 <- lme(distance ~ age, data = Orthodont) #
> random is ~ age
> R>
> R>lapply(pdMatrix(fm1$modelStruct$reStruct), "*",
> fm1$sigma^2)
> $Subject
>              (Intercept)         age
> (Intercept)    5.414722 -0.32102403
> age           -0.321024  0.05126664
> 
> Comment: pdMatrix returns the list of var-cov
> matrices of the random 
> effects (one matrix for each level of the possibly
> multilevel 
> structure). For some computational reason, these
> matrices are scaled by 
> the residuals variance: you have to multiply them by
> the residuals variance.
> 
> If you really want a matrix (the above is a list
> with one component), 
> you can do:
> 
> R>lapply(pdMatrix(fm1$modelStruct$reStruct), "*",
> fm1$sigma^2)$Subject
>              (Intercept)         age
> (Intercept)    5.414722 -0.32102403
> age           -0.321024  0.05126664

Hi, Renaud,

I think reStruct gives the structure of random
effects, not the within group errors. And I happened
to want the structure for the later one, especially
when the within group errors are differently
structured between groups.

Regards,

Peng

------------------------------
Peng Liu                      |
Division of Statistics        |
Northern Illinois University  |
De Kalb, IL 60115, USA        |
E-mail: pliu at math.niu.edu     |
------------------------------



> 
> 
> Best,
> 
> Renaud
> 
> -- 
> Dr Renaud Lancelot, vtrinaire
> CIRAD, Dpartement Elevage et Mdecine Vtrinaire
> (CIRAD-Emvt)
> Programme Productions Animales
> http://www.cirad.fr/fr/pg_recherche/page.php?id=14
> 
> ISRA-LNERV                      tel    +221 832 49
> 02
> BP 2057 Dakar-Hann              fax    +221 821 18
> 79 (CIRAD)
> Senegal                         e-mail
> renaud.lancelot at cirad.fr
>


From pauljohn at ku.edu  Wed Mar  5 14:25:01 2003
From: pauljohn at ku.edu (Paul Johnson)
Date: Wed, 05 Mar 2003 07:25:01 -0600
Subject: Rtips still up (was Re: [R] How to draw several plots in one figure?
References: <000701c2e2dd$344593a0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <3E65FAAD.9070700@ku.edu>

Dear Feng and everybody

I still have my list of "how to" things for R and sometimes I even try
to add more.  Here's the address

http://lark.cc.ku.edu/~pauljohn/R/statsRus.html

I can't tell if you want to have several plots on the same page, in 
which case you should use this item:

http://lark.cc.ku.edu/~pauljohn/R/statsRus.html#5.1

Of if you want a full overlay onto the exact same piece of paper, in 
which you should look at:

http://lark.cc.ku.edu/~pauljohn/R/statsRus.html#5.11

When I first put up the R tips page, several of the R regulars checked 
it over for errors, but it has probably been a year or two since I got 
any advice, constructive or otherwise.  I know new users still sometimes 
find it because I get follow up questions, but I'm always glad for more 
help.  So, in case anybody has corrections or updates, please let me know.


Feng Zhang wrote:
> Hey,
> 
> I want to draw several plots sequently, but have to make them dispaly in one
> figure.
> So how to achieve this?
> 
> Thanks.
> 
> Fred


-- 
Paul E. Johnson                       email: pauljohn at ukans.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66045                FAX: (785) 864-5700


From chrysopa at insecta.ufv.br  Wed Mar  5 15:06:29 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Wed, 5 Mar 2003 11:06:29 -0300
Subject: [R] Dataframe in loop
Message-ID: <200303051106.29574.chrysopa@insecta.ufv.br>

Hi,

I try to make a dataframe in a loop function, but I dont have succeed.

The function is something like this:

for(i in c(10,12)) {
   expr
      for(j in c(1:2) {
         total <- c(1,2,3,4,5,6,7)
         nspf <- length(levels(as.factor(total)))
         fin <- data.frame(L=i,N=nspf)
         print(fin)
  }
}

This print something like this:

   L N
1 10 7
   L N
1 10 7
   L N
1 12 7
   L N
1 12 7

But I need this print like:
   L N
1 10 7
2 10 7
3 12 7
4 12 7

I try some function modification to this but dont work.

This is just an example, the real function is a little big.

Thanks
ROnaldo

-- 
Why, every one as they like; as the good woman said when she kissed her cow.
		-- Rabelais
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From rab at nauticom.net  Wed Mar  5 17:09:09 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Wed, 05 Mar 2003 11:09:09 -0500
Subject: [R] Transfer Function Modeling
In-Reply-To: <20030304221154.84831.qmail@web21008.mail.yahoo.com>
References: <20030304221154.84831.qmail@web21008.mail.yahoo.com>
Message-ID: <3E662125.5090903@nauticom.net>

I want to forecast a time series Y using a model that includes previous 
values of Y and an exogenous time series X using a transfer function. 
The standard procedure as described in Box and Jenkins and numerous 
other references is to first fit an ARIMA model to X. Use the ARIMA 
model to computer residuals for X and then apply the same ARIMA function 
to Y to compute residuals for Y. The cross correlation between these two 
sets of residuals then should allow discovery of the structure of the 
transfer function that relates X to Y. How can I do this in R? I know 
how to use the ts package to fit ARIMA models. Is it possible to use the 
"filter" function from the ts package to help compute the proper 
residuals for Y? I've read (and reread) the help file on "filter" and 
tried to apply it but I must be missing something. How can I use 
"filter" to handle both the AR and MA components? Or am I on the wrong 
track?

Rick B.


From rab at nauticom.net  Wed Mar  5 18:01:01 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Wed, 05 Mar 2003 12:01:01 -0500
Subject: [R] Transfer Function Modeling
In-Reply-To: <3E651777.7020602@pdf.com>
References: <20030304203816.43583.qmail@web21007.mail.yahoo.com>
	<3E651777.7020602@pdf.com>
Message-ID: <3E662D4D.2050509@nauticom.net>

I think I've figured out the use of "filter" in the ts package, at least 
for a simple AR model. I simulated a simple AR time series, modeled it 
using "arima",  and then used "filter" to compute the 1-step ahead 
forecasts:

 > y.arma <- arima.sim(list(ar=0.8),n=200)
 > y.arma.arima <- arima(y.arma,order=c(1,0,0),include.mean=FALSE)
 > y.arma.arima

Call:
arima(x = y.arma, order = c(1, 0, 0), include.mean = FALSE)

Coefficients:
         ar1
      0.7594
s.e.  0.0455

sigma^2 estimated as 1.059:  log likelihood = -290,  aic = 583.99

 > plot(y.arma[-1],lines="l")
 > lines(filter(y.arma,y.arma.arima$coef,method="con")[-200],lty=2)

So using the "convolution" method appears to produce the correct 
forecast for the y.arma series.

But suppose I had generated and fitted an ARMA(1,1) or ARIMA(1,1,1) 
model? How would I use "filter" in this case?

Rick B.


From cathey.tommy at epa.gov  Wed Mar  5 19:40:22 2003
From: cathey.tommy at epa.gov (Tommy E. Cathey)
Date: Wed, 05 Mar 2003 13:40:22 -0500
Subject: [R] Does barplot handle log scales?
Message-ID: <3E664495.CAF9B1C7@epa.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030305/3488c6cb/attachment.pl

From mschwartz at medanalytics.com  Wed Mar  5 19:48:35 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 5 Mar 2003 12:48:35 -0600
Subject: [R] Does barplot handle log scales?
In-Reply-To: <3E664495.CAF9B1C7@epa.gov>
Message-ID: <002001c2e347$d455a140$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tommy E.
Cathey
>Sent: Wednesday, March 05, 2003 12:40 PM
>To: R-help at stat.math.ethz.ch
>Subject: [R] Does barplot handle log scales?
>
>
>Does barplot handle log scales? Every time I try to pass 
>log="y" to barplot I get the following error message.
>
>>barplot(height=t(array(c(d1,d2,d3,d4),dim=c(NROW(d1),4))),ann=
>FALSE,axe
>>s=FALSE,col=c("#0000ff","#ff0000","#00ff00","#ffff00"),horiz=F
>ALSE,widt
>>h=c(0.5),space=c(1.2,2.0),beside=FALSE,log="y")
>
>Error in plot.window(xlim, ylim, log = "", ...) :
>        formal argument "log" matched by multiple actual arguments
>
>Thanks,
>Tommy
>
>--
>
>Tommy E. Cathey
>Senior Scientific Application Consultant
>SAIC (Contractor to EPA)
>mailto:cathey.tommy at epa.gov
>(919)541-1500
>My e-mail does not reflect the opinion of SAIC or the EPA.


Tommy,

The standard barplot() function does not handle log scales.

Please see barplot2() in the gregmisc package on CRAN.  If you have
any questions on its use, please let me know.

Best regards,

Marc Schwartz


From white.denis at epamail.epa.gov  Wed Mar  5 19:51:59 2003
From: white.denis at epamail.epa.gov (white.denis@epamail.epa.gov)
Date: Wed, 05 Mar 2003 10:51:59 -0800
Subject: [R] reserved words documentation
Message-ID: <OF01227DFC.30E3F15F-ON88256CE0.00663E30@rtp.epa.gov>

I wanted a data frame component to be named "next", for example:

> m <- data.frame (matrix (0, nrow=2, ncol=2))
> names (m) <- c("prev", "next")
> m
  prev next
1    0    0
2    0    0

But "next" being reserved prevents $ indexing without quotes:

> m$next
Error: syntax error
> m$"next"
[1] 0 0

Although they are mostly obvious, I can't find in the documentation
(using Jon Baron's searcher, at least) a list of these words.  Am I
missing the documentation, or could such a list be added to a future
release?

thanks,
Denis


From lina at u.washington.edu  Wed Mar  5 20:04:32 2003
From: lina at u.washington.edu (Michael Na Li)
Date: Wed, 05 Mar 2003 11:04:32 -0800
Subject: [R] Dataframe in loop
In-Reply-To: <200303051106.29574.chrysopa@insecta.ufv.br> ("Ronaldo Reis
 Jr."'s message of "Wed, 5 Mar 2003 11:06:29 -0300")
References: <200303051106.29574.chrysopa@insecta.ufv.br>
Message-ID: <njfzq1ab3z.fsf@qiuranke.phony.washington.edu>

On Wed, 5 Mar 2003, Ronaldo Reis, Jr. verbalised:

>  Hi,
>  
>  I try to make a dataframe in a loop function, but I dont have succeed.
>  
>  The function is something like this:
>  
>  for(i in c(10,12)) {
>     expr
      ^^^^  what's this?

>        for(j in c(1:2) {
>           total <- c(1,2,3,4,5,6,7)
>           nspf <- length(levels(as.factor(total)))
>           fin <- data.frame(L=i,N=nspf)
>           print(fin)
>    }
>  }
>  

You are creating a new data frame with in each loop.

You want something like this,
,----
| > fin <- NULL
| > for(i in c(10,12)) {
| +     for(j in c(1:2)) {
| +         total <- c(1,2,3,4,5,6,7)
| +         nspf <- length(levels(as.factor(total)))
| +         fin <- rbind (fin, c(L=i, N=nspf))
| +    }
| + }
| > print(fin)
|       L N
| [1,] 10 7
| [2,] 10 7
| [3,] 12 7
| [4,] 12 7
`----


Cheers,

Michael


From ripley at stats.ox.ac.uk  Wed Mar  5 20:09:09 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 5 Mar 2003 19:09:09 +0000 (GMT)
Subject: [R] reserved words documentation
In-Reply-To: <OF01227DFC.30E3F15F-ON88256CE0.00663E30@rtp.epa.gov>
Message-ID: <Pine.LNX.4.44.0303051903400.24342-100000@gannet.stats>

I had to read the R sources for `S Programming', which says

There are some reserved words you will not be allowed to use, for example
\begin{source}
FALSE Inf NA NaN NULL TRUE
break else for function if in next repeat while
\end{source}
and in the \s. engines (but not \R.) \sfn{return}, \sfn{F} and \sfn{T}.

[That was the list in 1999, and you would need to check.]

Yes, this should be in R-lang, the `Language Definition', but that is 
still a draft.


On Wed, 5 Mar 2003 white.denis at epamail.epa.gov wrote:

> I wanted a data frame component to be named "next", for example:
> 
> > m <- data.frame (matrix (0, nrow=2, ncol=2))
> > names (m) <- c("prev", "next")
> > m
>   prev next
> 1    0    0
> 2    0    0
> 
> But "next" being reserved prevents $ indexing without quotes:
> 
> > m$next
> Error: syntax error
> > m$"next"
> [1] 0 0
> 
> Although they are mostly obvious, I can't find in the documentation
> (using Jon Baron's searcher, at least) a list of these words.  Am I
> missing the documentation, or could such a list be added to a future
> release?
> 
> thanks,
> Denis
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ioleinik at profitlogic.com  Wed Mar  5 20:17:34 2003
From: ioleinik at profitlogic.com (Igor Oleinik)
Date: Wed, 5 Mar 2003 14:17:34 -0500 
Subject: [R] problem with ccluster package 
Message-ID: <B5EEC42D4BD0D411BE5B00B0D06865DBE3471D@sat-mail.grossprofit.com>

Hello,

I am calling cclust function in cclust package 
repeatedly until some ceratain conditions 
for a cluster are met. Unfortunately,
the system crashes on the second call (after debugging).

# kmeans res1 is a well defined matrix
cl <- cclust(res1, as.numeric(ncntrs), iter.max  = 20, verbose = FALSE,
dist="manhattan", method="kmeans")


RGui has generated errors and will be closed by Windows. ...

What might be the problem?

Thank you,

Igor.


From andy_liaw at merck.com  Wed Mar  5 20:18:39 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 05 Mar 2003 14:18:39 -0500
Subject: [R] reserved words documentation
Message-ID: <3A822319EB35174CA3714066D590DCD534BD8E@usrymx25.merck.com>

Section 10.3.3 in the R Language Manual, as distributed with R.

Andy

> -----Original Message-----
> From: white.denis at epamail.epa.gov [mailto:white.denis at epamail.epa.gov]
> Sent: Wednesday, March 05, 2003 1:52 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] reserved words documentation
> 
> 
> I wanted a data frame component to be named "next", for example:
> 
> > m <- data.frame (matrix (0, nrow=2, ncol=2))
> > names (m) <- c("prev", "next")
> > m
>   prev next
> 1    0    0
> 2    0    0
> 
> But "next" being reserved prevents $ indexing without quotes:
> 
> > m$next
> Error: syntax error
> > m$"next"
> [1] 0 0
> 
> Although they are mostly obvious, I can't find in the documentation
> (using Jon Baron's searcher, at least) a list of these words.  Am I
> missing the documentation, or could such a list be added to a future
> release?
> 
> thanks,
> Denis
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From Edmond.Ng at lshtm.ac.uk  Wed Mar  5 20:26:13 2003
From: Edmond.Ng at lshtm.ac.uk (Edmond Ng)
Date: Wed, 05 Mar 2003 19:26:13 +0000
Subject: [R] reading in tab delimited data in a loop
Message-ID: <se664f61.061@s-webmail.lshtm.ac.uk>

Dear all, 

I need to read in 4 sets of tab delimited data in a  loop. The 4 data sets are called "simu1.dat", "simu2.dat" and so on. I know what I need on the righthand side of the read.table expression but I can't the left hand side of it to work (see the line in bold below). Can you kindly help? Many thanks. 

simu1 <- matrix(0,30,3)
simu2 <- matrix(0,30,3)
simu3 <- matrix(0,30,3)
simu4 <- matrix(0,30,3)

for (i in 1:4) {
simu[i] <- read.table( paste("simu",i,".dat",sep="") )
}


Edmond


From ripley at stats.ox.ac.uk  Wed Mar  5 20:44:06 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 5 Mar 2003 19:44:06 +0000 (GMT)
Subject: [R] problem with cclust[er] package 
In-Reply-To: <B5EEC42D4BD0D411BE5B00B0D06865DBE3471D@sat-mail.grossprofit.com>
Message-ID: <Pine.LNX.4.44.0303051938060.24391-100000@gannet.stats>

On Wed, 5 Mar 2003, Igor Oleinik wrote:

> I am calling cclust function in cclust package 
> repeatedly until some ceratain conditions 
> for a cluster are met. Unfortunately,
> the system crashes on the second call (after debugging).
> 
> # kmeans res1 is a well defined matrix
> cl <- cclust(res1, as.numeric(ncntrs), iter.max  = 20, verbose = FALSE,
> dist="manhattan", method="kmeans")
> 
> 
> RGui has generated errors and will be closed by Windows. ...
> 
> What might be the problem?

There is a section in the rw-FAQ on how to find out.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bates at stat.wisc.edu  Wed Mar  5 20:48:57 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 05 Mar 2003 13:48:57 -0600
Subject: [R] PL/R is being noticed in the PostgreSQL community
Message-ID: <6rsmu1lhli.fsf@bates4.stat.wisc.edu>

An embedded message was scrubbed...
From: Paul Ramsey <pramsey at refractions.net>
Subject: Re: [GENERAL] Why PostgreSQL?
Date: Tue, 04 Mar 2003 14:51:25 -0800
Size: 4771
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030305/bcbac610/attachment.mht

From ioleinik at profitlogic.com  Wed Mar  5 20:54:19 2003
From: ioleinik at profitlogic.com (Igor Oleinik)
Date: Wed, 5 Mar 2003 14:54:19 -0500 
Subject: [R] problem with cclust[er] package 
Message-ID: <B5EEC42D4BD0D411BE5B00B0D06865DBE3471E@sat-mail.grossprofit.com>

I have checked that section already.
Sorry, I should have mentioned that.

Memory limit increase does not work.
Installtion of msvcrt.dll does not work 
either.

Thank you.

-----Original Message-----
From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
Sent: Wednesday, March 05, 2003 2:44 PM
To: Igor Oleinik
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] problem with cclust[er] package 


On Wed, 5 Mar 2003, Igor Oleinik wrote:

> I am calling cclust function in cclust package 
> repeatedly until some ceratain conditions 
> for a cluster are met. Unfortunately,
> the system crashes on the second call (after debugging).
> 
> # kmeans res1 is a well defined matrix
> cl <- cclust(res1, as.numeric(ncntrs), iter.max  = 20, verbose = FALSE,
> dist="manhattan", method="kmeans")
> 
> 
> RGui has generated errors and will be closed by Windows. ...
> 
> What might be the problem?

There is a section in the rw-FAQ on how to find out.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From clifford at galton.uchicago.edu  Wed Mar  5 21:00:58 2003
From: clifford at galton.uchicago.edu (David Clifford)
Date: Wed, 5 Mar 2003 14:00:58 -0600 (CST)
Subject: [R] reading in tab delimited data in a loop
In-Reply-To: <se664f61.061@s-webmail.lshtm.ac.uk>
Message-ID: <Pine.LNX.4.44.0303051400450.7063-100000@mj.uchicago.edu>

simu1 <- matrix(0,3,3)
simu2 <- matrix(0,3,3)
simu3 <- matrix(0,3,3)
simu4 <- matrix(0,3,3)

## save to files
write.table(simu1,"simu1.dat")
write.table(simu2,"simu2.dat")
write.table(simu3,"simu3.dat")
write.table(simu4,"simu4.dat")

## read from files into a list called simu
simu <- list(NULL)
for (i in 1:4) {
simu[[i]] <- read.table( paste("simu",i,".dat",sep="") )
}
simu[[1]]

On Wed, 5 Mar 
2003, Edmond Ng 
wrote:

> Dear all, 
> 
> I need to read in 4 sets of tab delimited data in a  loop. The 4 data sets are called "simu1.dat", "simu2.dat" and so on. I know what I need on the righthand side of the read.table expression but I can't the left hand side of it to work (see the line in bold below). Can you kindly help? Many thanks. 
> 
> simu1 <- matrix(0,30,3)
> simu2 <- matrix(0,30,3)
> simu3 <- matrix(0,30,3)
> simu4 <- matrix(0,30,3)
> 
> for (i in 1:4) {
> simu[i] <- read.table( paste("simu",i,".dat",sep="") )
> }
> 
> 
> Edmond
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From andy_liaw at merck.com  Wed Mar  5 21:01:38 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 05 Mar 2003 15:01:38 -0500
Subject: [R] reading in tab delimited data in a loop
Message-ID: <3A822319EB35174CA3714066D590DCD534BD8F@usrymx25.merck.com>

There's no bold face in plain text.  I assume it's the line inside the loop
that's giving you trouble.

Two approaches:

1. for(i in 1:4) assign(paste("simu", i, sep=""), read.table(...))

2. simu <- vector(4, mode="list")
   for(i in 1:4) simu[[i]] <- read.table(...)

Andy

> -----Original Message-----
> From: Edmond Ng [mailto:Edmond.Ng at lshtm.ac.uk]
> Sent: Wednesday, March 05, 2003 2:26 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] reading in tab delimited data in a loop
> 
> 
> Dear all, 
> 
> I need to read in 4 sets of tab delimited data in a  loop. 
> The 4 data sets are called "simu1.dat", "simu2.dat" and so 
> on. I know what I need on the righthand side of the 
> read.table expression but I can't the left hand side of it to 
> work (see the line in bold below). Can you kindly help? Many thanks. 
> 
> simu1 <- matrix(0,30,3)
> simu2 <- matrix(0,30,3)
> simu3 <- matrix(0,30,3)
> simu4 <- matrix(0,30,3)
> 
> for (i in 1:4) {
> simu[i] <- read.table( paste("simu",i,".dat",sep="") )
> }
> 
> 
> Edmond
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------


From bates at stat.wisc.edu  Wed Mar  5 21:07:46 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 05 Mar 2003 14:07:46 -0600
Subject: [R] reading in tab delimited data in a loop
In-Reply-To: <se664f61.061@s-webmail.lshtm.ac.uk>
References: <se664f61.061@s-webmail.lshtm.ac.uk>
Message-ID: <6rbs0plgq5.fsf@bates4.stat.wisc.edu>

"Edmond Ng" <Edmond.Ng at lshtm.ac.uk> writes:

> Dear all, 
> 
> I need to read in 4 sets of tab delimited data in a  loop. The 4 data sets are called "simu1.dat", "simu2.dat" and so on. I know what I need on the righthand side of the read.table expression but I can't the left hand side of it to work (see the line in bold below). Can you kindly help? Many thanks. 
> 
> simu1 <- matrix(0,30,3)
> simu2 <- matrix(0,30,3)
> simu3 <- matrix(0,30,3)
> simu4 <- matrix(0,30,3)
> 
> for (i in 1:4) {
> simu[i] <- read.table( paste("simu",i,".dat",sep="") )
> }

Use paste to generate the name and assign to do the assignment

for (i in 1:4) {
  assign(paste('simu', i), read.table( paste("simu",i,".dat",sep="")))
}


From ioleinik at profitlogic.com  Wed Mar  5 21:42:44 2003
From: ioleinik at profitlogic.com (Igor Oleinik)
Date: Wed, 5 Mar 2003 15:42:44 -0500 
Subject: [R] problem with cclust[er] package 
Message-ID: <B5EEC42D4BD0D411BE5B00B0D06865DBE34720@sat-mail.grossprofit.com>

Here is a bit of outer loop too:

			library(cclust)
			# clustering algorithm using k-means
			bDone <- 0
			ncntrs <- 2
			browser()
			while (bDone == 0) {
			
				# k-means with ncntrs (changes from 1 to
number of points) centers
				# problem starts here on the second call in
debugging mode
				# res1 is 16X52 matrix

				cl <- cclust(res1, ncntrs, iter.max  = 20,
verbose = TRUE, dist="manhattan", method="kmeans")

				# max distance from center to to any point
in cluster
				meandist <- sqrt(max(cl$withinss/cl$size)) *
20/52

				if (meandist < 0.1) bDone = 1
				
				ncntrs <- ncntrs + 1
				if (ncntrs > seascnt) bDone = 1

			} # while (bDone = 0)


I am running Win2000, R 1.6.2. I installed R
over the Internet.

Igor.



-----Original Message-----
From: Thomas W Blackwell [mailto:tblackw at umich.edu]
Sent: Wednesday, March 05, 2003 3:31 PM
To: Igor Oleinik
Subject: RE: [R] problem with cclust[er] package 



I think you will need to give us some of the outer loop,
the one which calls cclust() repeatedly and tests for the
"certain conditions".  I would look for the problem there,
not inside cclust itself ... but I could be wrong.  Also
what system, version, method of installation  ?

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

('Fraid I'm offline until tomorrow.)




On Wed, 5 Mar 2003, Igor Oleinik wrote:

> I have checked that section already.
> Sorry, I should have mentioned that.
>
> Memory limit increase does not work.
> Installtion of msvcrt.dll does not work
> either.
>
> Thank you.
>
> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Wednesday, March 05, 2003 2:44 PM
> To: Igor Oleinik
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] problem with cclust[er] package
>
>
> On Wed, 5 Mar 2003, Igor Oleinik wrote:
>
> > I am calling cclust function in cclust package
> > repeatedly until some ceratain conditions
> > for a cluster are met. Unfortunately,
> > the system crashes on the second call (after debugging).
> >
> > # kmeans res1 is a well defined matrix
> > cl <- cclust(res1, as.numeric(ncntrs), iter.max  = 20, verbose = FALSE,
> > dist="manhattan", method="kmeans")
> >
> >
> > RGui has generated errors and will be closed by Windows. ...
> >
> > What might be the problem?
>
> There is a section in the rw-FAQ on how to find out.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From bates at stat.wisc.edu  Wed Mar  5 21:52:13 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 05 Mar 2003 14:52:13 -0600
Subject: [R] reading in tab delimited data in a loop
In-Reply-To: <6rbs0plgq5.fsf@bates4.stat.wisc.edu>
References: <se664f61.061@s-webmail.lshtm.ac.uk>
	<6rbs0plgq5.fsf@bates4.stat.wisc.edu>
Message-ID: <6rk7fdk03m.fsf@bates4.stat.wisc.edu>

Douglas Bates <bates at cs.wisc.edu> writes:

> "Edmond Ng" <Edmond.Ng at lshtm.ac.uk> writes:
> 
> > Dear all, 
> > 
> > I need to read in 4 sets of tab delimited data in a  loop. The 4 data sets are called "simu1.dat", "simu2.dat" and so on. I know what I need on the righthand side of the read.table expression but I can't the left hand side of it to work (see the line in bold below). Can you kindly help? Many thanks. 
> > 
> > simu1 <- matrix(0,30,3)
> > simu2 <- matrix(0,30,3)
> > simu3 <- matrix(0,30,3)
> > simu4 <- matrix(0,30,3)
> > 
> > for (i in 1:4) {
> > simu[i] <- read.table( paste("simu",i,".dat",sep="") )
> > }
> 
> Use paste to generate the name and assign to do the assignment
> 
> for (i in 1:4) {
>   assign(paste('simu', i), read.table( paste("simu",i,".dat",sep="")))
> }

Andy Liaw's answer got back to me before mine did and I see that he
remembered to use paste('simu', i, sep='').  Andy's version is
correct - mine would generate names like 'simu 1'.


From a296180 at arbres1a.fmr.com  Wed Mar  5 22:21:01 2003
From: a296180 at arbres1a.fmr.com (David Kane  <David Kane)
Date: Wed, 5 Mar 2003 16:21:01 -0500
Subject: [R] printing POSIXct values in table labels
Message-ID: <15974.27197.927296.184929@gargle.gargle.HOWL>

Hi,

I think that there is something that I am misunderstanding in creating tables
using dates that are of class POSIXct. Consider:

> x <- data.frame(date = as.POSIXct(strptime(c(rep("2002-10-17", 4), rep("1999-12-08", 2)), format = "%Y-%m-%d")))
> x
        date
1 2002-10-17
2 2002-10-17
3 2002-10-17
4 2002-10-17
5 1999-12-08
6 1999-12-08
> table(x$date)

 944629200 1034827200 
         2          4 

I understand that the headings here are the number of seconds since some
epoch. But shouldn't the values print out here as they print out in the
dataframe?

I can get the effect that I want using:

> table(format(x$date))

1999-12-08 2002-10-17 
         2          4 

The problem is that this can add a lot of time to the calculation in big
dataframes.

> x <- data.frame(date = as.POSIXct(strptime(c(rep("2002-10-17", 40000), rep("1999-12-08", 20000)), format = "%Y-%m-%d")))
> dim(x)
[1] 60000     1
> system.time(table(x$date))
> [1] 0.19 0.00 0.19 0.00 0.00
> system.time(table(format(x$date)))
[1] 18  0 19  0  0

Am I missing something?

> R.version
         _                   
platform sparc-sun-solaris2.6
arch     sparc               
os       solaris2.6          
system   sparc, solaris2.6   
status                       
major    1                   
minor    6.2                 
year     2003                
month    01                  
day      10                  
language R                   
> 

Thanks,

Dave Kane


From r.hankin at auckland.ac.nz  Wed Mar  5 22:23:39 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Thu, 6 Mar 2003 10:23:39 +1300
Subject: [R] reserved words documentation
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BD8E@usrymx25.merck.com>
	(andy_liaw@merck.com)
References: <3A822319EB35174CA3714066D590DCD534BD8E@usrymx25.merck.com>
Message-ID: <200303052123.h25LNdQf032362@r.hankin.sges.auckland.ac.nz>

Hello everybody.

Andy Liaw points to:

> 
> Section 10.2.3 in the R Language Manual, as distributed with R.
> 

which lists reserved words.

<quote>
if else repeat while function for in next break
TRUE FALSE NULL NA Inf NaN
.. ..1 ..2
<\quote>


QUESTION: where is  "..1"  documented?

R> help.search("..1")
R> help("...")

don't help, and neither does egrep '\.\.1' R-lang.texi.

Come to think of it, the only place I could find
documentation for "..."  was in Notes on R.  

Where is the best place to look for docs on "..1"  ?




-- 

Robin Hankin, Lecturer, School of Geography and Environmental Science
Tamaki Campus Private Bag 92019 Auckland New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042


From jg_liao at yahoo.com  Wed Mar  5 22:36:11 2003
From: jg_liao at yahoo.com (Jason Liao)
Date: Wed, 5 Mar 2003 13:36:11 -0800 (PST)
Subject: [R] how to find the location of the first TRUE of a logical vector
Message-ID: <20030305213611.44127.qmail@web10507.mail.yahoo.com>

without having to check the vector element by element? Thanks a lot!

Jason

=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-8611, fax (732) 235-9777
http://www.geocities.com/jg_liao


From juli at ceam.es  Wed Mar  5 22:34:16 2003
From: juli at ceam.es (juli g. pausas)
Date: Wed, 05 Mar 2003 22:34:16 +0100
Subject: [R] cor.test in matrices
Message-ID: <3E666D58.1040805@ceam.es>

Hi,
For computing correlation among variables in a matrix, I use cor( ), but 
for computing the p-values I'm using cor.test in the following way:

cor.p <- function(X)
{
res <- matrix(0, ncol(X), ncol(X))
for (i in 1:ncol(X))
for (j in 1:ncol(X)) res[i, j]<- cor.test(X[, i], X[, j])$p.value
rownames(res) <- colnames(res) <- colnames(X)
res
}

I'm just wondering if there is a better (nicer) way to do the same.
For example, would it be possible to use apply() with cor.test instead 
of using the for loops?
I'm trying to improve my low R skills.
Thanks

Juli


From p.dalgaard at biostat.ku.dk  Wed Mar  5 22:52:17 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 05 Mar 2003 22:52:17 +0100
Subject: [R] rmutil??
In-Reply-To: <20030305214653.6a0ade65.rjvbertin@despammed.com>
References: <20030304163736.354dc5a3.rjvbertin@despammed.com>
	<Pine.SOL.3.96.1030304162204.25919F-100000@moon.stats.gla.ac.uk>
	<20030305214653.6a0ade65.rjvbertin@despammed.com>
Message-ID: <x2of4pqy5q.fsf@biostat.ku.dk>

"RenE J.V. Bertin" <rjvbertin at despammed.com> writes:

> The search function on www.r-project.org returns a certain number of
> references to packages that can no longer be found on CRAN, or so it
> would seem. I got interested in finterp(), from the package rmutil.
> What happened to that package, or the function?

On Jim Lindsey's site, I believe. I don't think his stuff was ever on
CRAN. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From mschwartz at medanalytics.com  Wed Mar  5 23:03:49 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 5 Mar 2003 16:03:49 -0600
Subject: [R] how to find the location of the first TRUE of a logical
	vector
In-Reply-To: <20030305213611.44127.qmail@web10507.mail.yahoo.com>
Message-ID: <004f01c2e363$1bd904b0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jason Liao
>Sent: Wednesday, March 05, 2003 3:36 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] how to find the location of the first TRUE of a 
>logical vector
>
>
>without having to check the vector element by element? Thanks a lot!
>
>Jason
>
>=====
>Jason G. Liao, Ph.D.
>Division of Biometrics
>University of Medicine and Dentistry of New Jersey
>335 George Street, Suite 2200
>New Brunswick, NJ 08903-2688
>phone (732) 235-8611, fax (732) 235-9777 
>http://www.geocities.com/jg_liao


If 'lv' if your logical vector, you could use something like:

min(which(lv == TRUE))

which() would return a vector of the indices within 'lv' that match
TRUE and of course min() will give you the lowest index value.

An example:

> lv <- c(FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE)
> lv
[1] FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE
> min(which(lv == TRUE))
[1] 4


HTH,

Marc Schwartz


From rob.hyndman at buseco.monash.edu.au  Wed Mar  5 23:04:06 2003
From: rob.hyndman at buseco.monash.edu.au (Rob Hyndman)
Date: Thu, 06 Mar 2003 09:04:06 +1100
Subject: [R] Re: linear model with arma errors
Message-ID: <3E667456.8E5E7A68@buseco.monash.edu.au>

> Dear all,
> 
> I'm looking for how can I estimate a linear model with ar(ma) errors :
> 
> y(t)=a*X(t)+e(t) with
> P(B)e(t)=Q(B)u(t)
> 
> where u is a white noise and P, Q are some polynomes.
> 
> Could you help me ?


Isn't this what arima in library ts does? Put X(t) into xreg and specify
the order of the arma error via the order argument.

The documentation for arima doesn't actually explain how xreg enters the
model, but if it is like the S-Plus arima.mle() function then it does
what you want. The BIG advantage of the R implementation is that it
gives inference for the regression coefficients.

[Aside to Brian Ripley: Can you please add a few lines to the arima help
file to define the model with a non-null xreg?]

Cheers,
Rob


___________________________________________________
Rob J Hyndman
Associate Professor & Director of Consulting
Department of Econometrics & Business Statistics
Monash University, VIC 3800, Australia.
http://www-personal.buseco.monash.edu.au/~hyndman/


From bates at stat.wisc.edu  Wed Mar  5 23:09:48 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 05 Mar 2003 16:09:48 -0600
Subject: [R] how to find the location of the first TRUE of a logical
	vector
In-Reply-To: <20030305213611.44127.qmail@web10507.mail.yahoo.com>
References: <20030305213611.44127.qmail@web10507.mail.yahoo.com>
Message-ID: <6rd6l5ihxv.fsf@bates4.stat.wisc.edu>

Jason Liao <jg_liao at yahoo.com> writes:

> without having to check the vector element by element? Thanks a lot!

If vec is your vector of logical values then

match(TRUE, vec)

should work.  It will return NA if there are no TRUE values.


From fharrell at virginia.edu  Wed Mar  5 23:14:17 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed, 5 Mar 2003 17:14:17 -0500
Subject: [R] cor.test in matrices
In-Reply-To: <3E666D58.1040805@ceam.es>
References: <3E666D58.1040805@ceam.es>
Message-ID: <20030305171417.3acd25fd.fharrell@virginia.edu>

On Wed, 05 Mar 2003 22:34:16 +0100
"juli g. pausas" <juli at ceam.es> wrote:

> Hi,
> For computing correlation among variables in a matrix, I use cor( ), but 
> for computing the p-values I'm using cor.test in the following way:
> 
> cor.p <- function(X)
> {
> res <- matrix(0, ncol(X), ncol(X))
> for (i in 1:ncol(X))
> for (j in 1:ncol(X)) res[i, j]<- cor.test(X[, i], X[, j])$p.value
> rownames(res) <- colnames(res) <- colnames(X)
> res
> }
> 
> I'm just wondering if there is a better (nicer) way to do the same.
> For example, would it be possible to use apply() with cor.test instead 
> of using the for loops?
> I'm trying to improve my low R skills.
> Thanks
> 
> Juli
>

One approach is to install the Hmisc package and run rcorr(X) which will give you a matrix of P values for Pearson or Spearman correlations.  See http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From pavlicov at stat.ohio-state.edu  Wed Mar  5 23:14:10 2003
From: pavlicov at stat.ohio-state.edu (Martina Pavlicova)
Date: Wed, 5 Mar 2003 17:14:10 -0500 (EST)
Subject: [R] how to find the location of the first TRUE of a logical
 vector
In-Reply-To: <20030305213611.44127.qmail@web10507.mail.yahoo.com>
Message-ID: <Pine.SOL.4.33.0303051711330.4626-100000@spatial.stat.ohio-state.edu>


It might not be the most elegant, but it works:

> foo <- c(F, F, T, F, T, T, F ,T)
> c(1:length(foo))[foo][1]
[1] 3
>

And if there is no 'T', it returns 'NA'

> foo <- c(F, F)
> c(1:length(foo))[foo][1]
[1] NA

Martina

--------------------------------------------------------------------------
Department of Statistics             Office Phone: (614) 292-1567
1958 Neil Avenue, 304E Cockins Hall  FAX: (614) 292-2096
The Ohio State University            E-mail: pavlicov at stat.ohio-state.edu
Columbus, OH 43210-1247              www.stat.ohio-state.edu/~pavlicov


On Wed, 5 Mar 2003, Jason Liao wrote:

> without having to check the vector element by element? Thanks a lot!
>
> Jason
>
> =====
> Jason G. Liao, Ph.D.
> Division of Biometrics
> University of Medicine and Dentistry of New Jersey
> 335 George Street, Suite 2200
> New Brunswick, NJ 08903-2688
> phone (732) 235-8611, fax (732) 235-9777
> http://www.geocities.com/jg_liao
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From rpeng at stat.ucla.edu  Wed Mar  5 23:19:54 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 5 Mar 2003 14:19:54 -0800 (PST)
Subject: [R] how to find the location of the first TRUE of a logical
 vector
In-Reply-To: <20030305213611.44127.qmail@web10507.mail.yahoo.com>
Message-ID: <Pine.GSO.4.10.10303051415001.5485-100000@quetelet.stat.ucla.edu>

Try,

x <- c(F,F,F,T,F,T,F,T)
min(which(x))

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 5 Mar 2003, Jason Liao wrote:

> without having to check the vector element by element? Thanks a lot!
> 
> Jason
> 
> =====
> Jason G. Liao, Ph.D.
> Division of Biometrics
> University of Medicine and Dentistry of New Jersey
> 335 George Street, Suite 2200
> New Brunswick, NJ 08903-2688
> phone (732) 235-8611, fax (732) 235-9777
> http://www.geocities.com/jg_liao
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From p.dalgaard at biostat.ku.dk  Wed Mar  5 23:32:55 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 05 Mar 2003 23:32:55 +0100
Subject: [R] reserved words documentation
In-Reply-To: <200303052123.h25LNdQf032362@r.hankin.sges.auckland.ac.nz>
References: <3A822319EB35174CA3714066D590DCD534BD8E@usrymx25.merck.com>
	<200303052123.h25LNdQf032362@r.hankin.sges.auckland.ac.nz>
Message-ID: <x2k7fdqwa0.fsf@biostat.ku.dk>

Robin Hankin <r.hankin at auckland.ac.nz> writes:

> Come to think of it, the only place I could find
> documentation for "..."  was in Notes on R.  
> 
> Where is the best place to look for docs on "..1"  ?

In the source code, I suppose. It's extremely obscure and all you
really need to know is that the ..n names are to be avoided.

If you insist, consider this

> g <- function(...) cat(..1,"/",..10,"\n")
> g(4)
Error in cat(..1, "/", ..10, "\n") : The ... list does not contain 10
> elements
> g(1,2,3,4,5,6,7,8,9,0)
1 / 0

I've only seen uses for this while debugging some really weird
constructions which I have long since forgotten. 

One strange aspect is that these really are reserved words, not just
identifiers; you can't do stuff like this:

> g <- function(...) for (i in seq(length=nargs())) 
    cat(get(paste("..",i,sep="")),"/")
> g(1,2,3,4,5,6,7,8,9,x)
Error in get(x, envir, mode, inherits) : variable "..1" was not found

But you can do that anyway, and neater, with

g <- function(...) for (i in seq(length=nargs())) cat(list(...)[[i]],"/"),x)

(The obscure bug seems to have been #813 which I recall trying to fix
an evening during DSC 2001... That particular behaviour has been
stamped out, but I suppose a sufficiently weird combination of
match.call(), substitute(), multiple levels of "..." matching, and
eval() could still cause "..1" to appear in an expression)
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From lockwood at rand.org  Wed Mar  5 23:41:44 2003
From: lockwood at rand.org (J.R. Lockwood)
Date: Wed, 5 Mar 2003 17:41:44 -0500 (EST)
Subject: [R] how to find the location of the first TRUE of a logical
 vector
In-Reply-To: <004f01c2e363$1bd904b0$0201a8c0@MARC>
Message-ID: <Pine.LNX.4.33.0303051740430.6760-100000@penguin.rand.org>

> >
> >without having to check the vector element by element? Thanks a lot!

which.max() will coerce the logical to numeric and give the location of
the first max, which is the first TRUE.

J.R. Lockwood
412-683-2300 x4941
lockwood at rand.org
http://www.rand.org/methodology/stat/members/lockwood/


From spencer.graves at pdf.com  Wed Mar  5 23:44:39 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 05 Mar 2003 14:44:39 -0800
Subject: [R] how to find the location of the first TRUE of a logical
	vector
References: <004f01c2e363$1bd904b0$0201a8c0@MARC>
Message-ID: <3E667DD7.3070108@pdf.com>

Also:

   which(lv == TRUE)[1]

Spencer Graves

Marc Schwartz wrote:
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jason Liao
>>Sent: Wednesday, March 05, 2003 3:36 PM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] how to find the location of the first TRUE of a 
>>logical vector
>>
>>
>>without having to check the vector element by element? Thanks a lot!
>>
>>Jason
>>
>>=====
>>Jason G. Liao, Ph.D.
>>Division of Biometrics
>>University of Medicine and Dentistry of New Jersey
>>335 George Street, Suite 2200
>>New Brunswick, NJ 08903-2688
>>phone (732) 235-8611, fax (732) 235-9777 
>>http://www.geocities.com/jg_liao
> 
> 
> 
> If 'lv' if your logical vector, you could use something like:
> 
> min(which(lv == TRUE))
> 
> which() would return a vector of the indices within 'lv' that match
> TRUE and of course min() will give you the lowest index value.
> 
> An example:
> 
> 
>>lv <- c(FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE)
>>lv
> 
> [1] FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE
> 
>>min(which(lv == TRUE))
> 
> [1] 4
> 
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Simon.Gatehouse at csiro.au  Thu Mar  6 01:43:18 2003
From: Simon.Gatehouse at csiro.au (Simon.Gatehouse@csiro.au)
Date: Thu, 6 Mar 2003 11:43:18 +1100 
Subject: BSOD with ESS[R] under win2000
Message-ID: <FFE02AF26875734B82A728403821CB2E04F391@asp-ri.riverside.csiro.au>

Perhaps unrelated but for what it may be worth. 

Like many, I fiddle while thinking.  Part of my fiddling has been to rapidly
resize the R consule window back and forth by dragging with the mouse on the
bottom right hand corner. I resize the window by a small amount rapidly and
continually . After about 5 seconds of such movement R crashes with the pop
up "Rgui.exe has generated errors..."  This has happened ever since 1.3, I
think. It is unrelated to any other programs I may be running at the time.  

I currently run W2000 and latest R1.6.2. The 1.7.0 development version has
same behaviour.

I have no problem with this. The value of R is immeasurable and the small
lesson in self discipline has been good for me.
 
Simon Gatehouse


-----Original Message-----
From: Darryl Greig [mailto:darryl at hpli.hpl.hp.com]
Sent: Wednesday, March 05, 2003 7:32 PM
To: ripley at stats.ox.ac.uk
Cc: 'R-Help (E-mail)'
Subject: RE: BSOD with ESS[R] under win2000


It's certainly a difficult problem to isolate - as you say it may well
be connected to some other combination of application / drivers. I shall
investigate emacs help as a next step. 

-----Original Message-----
From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
Sent: Wednesday, March 05, 2003 10:08 AM
To: Darryl Greig
Cc: R-Help (E-mail)
Subject: Re: BSOD with ESS[R] under win2000


Was there anything to indicate that this was a problem in R (and not emacs 
nor Windows, especially a Windows driver)?

Those of us who never experience it will not be familiar with `BSOD': it
is I presume the blue screen shown by a fatal error in Windows internals.
I think I have seen just once under XP (in 2 year's usage).  If so it 
contains information about the cause.

BTW, as the rw-FAQ Q2.11 indicates, this is not the right list for ESS
users' questions, but my guess would be that this is not a problem in 
either R or ESS.

On Wed, 5 Mar 2003, Darryl Greig wrote:

> I have had a visit from our windows buddy the BSOD twice in one day when
> running
> R1.6.2 under ESS5.1.24 on a win2000 platform. I wasn't doing anything
> special, just
> moving or resizing the emacs window, although I did have 4 or 5 emacs
> windows
> open at the time. Has anyone else observed this problem?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


From olivier at loudcloud.com  Thu Mar  6 02:02:37 2003
From: olivier at loudcloud.com (Olivier Collignon)
Date: Wed, 5 Mar 2003 17:02:37 -0800
Subject: [R] loop avoiding on time interval intersects
Message-ID: <PCEDKAGMCBBPILIPDNMHEEKOCBAA.olivier@loudcloud.com>

I am trying to optimize some code to take advantage of R loop-avoiding
capabilities when working on vectors/arrays that contain time intervals.

The calculation involves adding (for each time interval) the time portion
(of events defined by their start and end times) that elapsed during time
intervals.

Any advice on how to improve this code. I searched the email archive and
looked at the MASS book but did not find anything specific that relate to
that.

Not sure how t/sapply could be used here?

Thanks

Olivier Collignon
Principal, Service Level and Risk Management
EDS / Loudcloud Automated Operations



Here is the non-optimized code:
library(chron)

# create an object populated with 3 events and their start and end
timestamps
dts <- dates(c("01/01/2003", "01/02/2003", "01/03/2003", "01/04/2003",
"01/03/2003","01/06/2003"))
tms <- times(c("23:00:00", "22:00:00", "01:00:00", "18:00:00", "16:00:00",
"01:00:00"))
events <- array(chron(dates = dts, times = tms),c(3,2))

# create an object with 2 consecutive intervals (regular or not)
dts2 <- dates(c("01/01/2003", "01/03/2003", "01/03/2003", "01/06/2003"))
tms2 <- times(c("0:0:0", "0:0:0", "0:0:0", "0:0:0"))
interv <- array(chron(dates = dts2, times = tms2),c(2,2))

fnIntersect <- function(events,interv)
{
overlp <- numeric()

n <- dim(events)[1]
m <- dim(interv)[1]

# perform the query to get the overlapping elapsed time between the events
and the intervals
# returns a vector with the time intervals and the sum of the intersecting
times from the 'event' input

# intervals: +--------+--------+--------+
# events:        +1234567890+
#                    +1234+
#                    +12345678901+
#                        +1234+
#                          +1234567890+
#
#
# summing the overlaps for each interval (e.g number of minutes)
# intervals: +--------+--------+--------+
#            5+1+1    6+4+9+5+4 2+7
#            =        =         =
#            6        28        9
# loop over each interval
for (j in 1:m)
	{
	overlp[j] <- 0
# loop over each event
	for (i in 1:n)
		{
# for events ending after the start of the interval
		if (events[i,2] >= interv[j,1])
			{
# for events starting before the end of the interval
			if (events[i,1] <= interv[j,2])
				{
# add the time that elapsed during the interval across all events
				overlp[j] <- overlp[j] + abs( min(interv[j,2],events[i,2]) -
max(interv[j,1],events[i,1]) )
				}
			}
		}
	}
# output has 3 colums: start of interval, end of interval, sum of
overlapping time from events
overlp <- cbind(interv, overlp)


From jg_liao at yahoo.com  Thu Mar  6 03:42:31 2003
From: jg_liao at yahoo.com (Jason Liao)
Date: Wed, 5 Mar 2003 18:42:31 -0800 (PST)
Subject: [R] how to find the location of the first TRUE of a logical
	vector
In-Reply-To: <Pine.SOL.4.33.0303051711330.4626-100000@spatial.stat.ohio-state.edu>
Message-ID: <20030306024231.97255.qmail@web10502.mail.yahoo.com>

Many thanks to all who replied: Marc Schwartz, Douglas Grove, Spencer
Graves, J.R. Lockwood, Roger Peng, Martina Pavlicova, Steve
Su,james.holtman, Wiener, Matthew, Domijan, Katarina and Douglas Bates.
 

Let x be the logical vector. The best solution seems to be: 
which(x)[1].

Now my code is much simpler.

Jason 


=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-8611, fax (732) 235-9777
http://www.geocities.com/jg_liao


From jg_liao at yahoo.com  Thu Mar  6 03:42:49 2003
From: jg_liao at yahoo.com (Jason Liao)
Date: Wed, 5 Mar 2003 18:42:49 -0800 (PST)
Subject: [R] how to find the location of the first TRUE of a logical
	vector
In-Reply-To: <Pine.SOL.4.33.0303051711330.4626-100000@spatial.stat.ohio-state.edu>
Message-ID: <20030306024250.63901.qmail@web10501.mail.yahoo.com>

Many thanks to all who replied: Marc Schwartz, Douglas Grove, Spencer
Graves, J.R. Lockwood, Roger Peng, Martina Pavlicova, Steve
Su,james.holtman, Wiener, Matthew, Domijan, Katarina and Douglas Bates.
 

Let x be the logical vector. The best solution seems to be: 
which(x)[1].

Now my code is much simpler.

Jason 


=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-8611, fax (732) 235-9777
http://www.geocities.com/jg_liao


From jg_liao at yahoo.com  Thu Mar  6 03:43:59 2003
From: jg_liao at yahoo.com (Jason Liao)
Date: Wed, 5 Mar 2003 18:43:59 -0800 (PST)
Subject: [R] how to find the location of the first TRUE of a logical
	vector
Message-ID: <20030306024359.51692.qmail@web10508.mail.yahoo.com>

Many thanks to all who replied: Marc Schwartz, Douglas Grove, Spencer
Graves, J.R. Lockwood, Roger Peng, Martina Pavlicova, Steve
Su,james.holtman, Wiener, Matthew, Domijan, Katarina and Douglas Bates.
 

Let x be the logical vector. The best solution seems to be: 
which(x)[1].

Now my code is much simpler.

Jason 


=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-8611, fax (732) 235-9777
http://www.geocities.com/jg_liao


From lina at u.washington.edu  Thu Mar  6 08:01:41 2003
From: lina at u.washington.edu (Michael Na Li)
Date: Wed, 05 Mar 2003 23:01:41 -0800
Subject: [R] for loop problem
In-Reply-To: <F155JorKDNsHU8ZAJGK0002d728@hotmail.com> ("Jeremy Z Butler"'s
 message of "Tue, 04 Mar 2003 16:13:55 +1300")
References: <F155JorKDNsHU8ZAJGK0002d728@hotmail.com>
Message-ID: <8xu1ehf06i.fsf@qiuranke.phony.washington.edu>

On Tue, 04 Mar 2003, Jeremy Z. Butler told this:

>  I want to generate a sequence which goes 1 2 3 4 5 6 7 8 14 15 16 17 18 19
>  20 21 26 27 ...  i.e. 8 consecutive numbers then 5 missed then the next 8
>  numbers etc.  I was going to do this using the seq() function but couldn't
>  figure out how so I thought I'd try a loop:
>  
>  for (x in seq(1,650,13))
>  { num.set.1 <- x:x+8

                  ^^^^^   should be x:(x+8) 

>  }

and by all means, avoid for loop, think in vector.

Michael


From ripley at stats.ox.ac.uk  Thu Mar  6 08:22:33 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 6 Mar 2003 07:22:33 +0000 (GMT)
Subject: [R] problem with cclust[er] package 
In-Reply-To: <B5EEC42D4BD0D411BE5B00B0D06865DBE3471E@sat-mail.grossprofit.com>
Message-ID: <Pine.LNX.4.44.0303060720530.25061-100000@gannet.stats>

I was referring to section 

7.4 How do I debug code that I have compiled and dyn.load-ed?

On Wed, 5 Mar 2003, Igor Oleinik wrote:

> I have checked that section already.
> Sorry, I should have mentioned that.
> 
> Memory limit increase does not work.
> Installtion of msvcrt.dll does not work 
> either.
> 
> Thank you.
> 
> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Wednesday, March 05, 2003 2:44 PM
> To: Igor Oleinik
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] problem with cclust[er] package 
> 
> 
> On Wed, 5 Mar 2003, Igor Oleinik wrote:
> 
> > I am calling cclust function in cclust package 
> > repeatedly until some ceratain conditions 
> > for a cluster are met. Unfortunately,
> > the system crashes on the second call (after debugging).
> > 
> > # kmeans res1 is a well defined matrix
> > cl <- cclust(res1, as.numeric(ncntrs), iter.max  = 20, verbose = FALSE,
> > dist="manhattan", method="kmeans")
> > 
> > 
> > RGui has generated errors and will be closed by Windows. ...
> > 
> > What might be the problem?
> 
> There is a section in the rw-FAQ on how to find out.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From adrian.trapletti at lmttrading.com  Thu Mar  6 08:23:21 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Thu, 06 Mar 2003 08:23:21 +0100
Subject: [R] Timezones
Message-ID: <3E66F769.EE917065@lmttrading.com>

Can anybody give me a hint why as.POSIXlt doesn't recognize the same
timezones that zdump knows about (Linux Suse 8.1 and Suse 7.3)? Is there
a workaround?

R : Copyright 2002, The R Development Core Team
Version 1.6.1  (2002-11-01)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

[Previously saved workspace restored]

> Sys.time()
[1] "2003-03-06 08:20:09 CET"
> system("zdump CET")
CET  Thu Mar  6 08:20:14 2003 CET
> as.POSIXlt(Sys.time(), "HST")
[1] "2003-03-06 08:20:18 CET"
> system("zdump HST")
HST  Wed Mar  5 21:20:20 2003 HST

best
Adrian


From ripley at stats.ox.ac.uk  Thu Mar  6 08:24:36 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 6 Mar 2003 07:24:36 +0000 (GMT)
Subject: BSOD with ESS[R] under win2000
In-Reply-To: <FFE02AF26875734B82A728403821CB2E04F391@asp-ri.riverside.csiro.au>
Message-ID: <Pine.LNX.4.44.0303060723260.25061-100000@gannet.stats>

That's bug PR#1711 in the R-bugs database.

On Thu, 6 Mar 2003 Simon.Gatehouse at csiro.au wrote:

> Perhaps unrelated but for what it may be worth. 
> 
> Like many, I fiddle while thinking.  Part of my fiddling has been to rapidly
> resize the R consule window back and forth by dragging with the mouse on the
> bottom right hand corner. I resize the window by a small amount rapidly and
> continually . After about 5 seconds of such movement R crashes with the pop
> up "Rgui.exe has generated errors..."  This has happened ever since 1.3, I
> think. It is unrelated to any other programs I may be running at the time.  
> 
> I currently run W2000 and latest R1.6.2. The 1.7.0 development version has
> same behaviour.
> 
> I have no problem with this. The value of R is immeasurable and the small
> lesson in self discipline has been good for me.
>  
> Simon Gatehouse
> 
> 
> -----Original Message-----
> From: Darryl Greig [mailto:darryl at hpli.hpl.hp.com]
> Sent: Wednesday, March 05, 2003 7:32 PM
> To: ripley at stats.ox.ac.uk
> Cc: 'R-Help (E-mail)'
> Subject: RE: BSOD with ESS[R] under win2000
> 
> 
> It's certainly a difficult problem to isolate - as you say it may well
> be connected to some other combination of application / drivers. I shall
> investigate emacs help as a next step. 
> 
> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Wednesday, March 05, 2003 10:08 AM
> To: Darryl Greig
> Cc: R-Help (E-mail)
> Subject: Re: BSOD with ESS[R] under win2000
> 
> 
> Was there anything to indicate that this was a problem in R (and not emacs 
> nor Windows, especially a Windows driver)?
> 
> Those of us who never experience it will not be familiar with `BSOD': it
> is I presume the blue screen shown by a fatal error in Windows internals.
> I think I have seen just once under XP (in 2 year's usage).  If so it 
> contains information about the cause.
> 
> BTW, as the rw-FAQ Q2.11 indicates, this is not the right list for ESS
> users' questions, but my guess would be that this is not a problem in 
> either R or ESS.
> 
> On Wed, 5 Mar 2003, Darryl Greig wrote:
> 
> > I have had a visit from our windows buddy the BSOD twice in one day when
> > running
> > R1.6.2 under ESS5.1.24 on a win2000 platform. I wasn't doing anything
> > special, just
> > moving or resizing the emacs window, although I did have 4 or 5 emacs
> > windows
> > open at the time. Has anyone else observed this problem?
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar  6 09:25:56 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 6 Mar 2003 08:25:56 +0000 (GMT)
Subject: [R] printing POSIXct values in table labels
In-Reply-To: <15974.27197.927296.184929@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0303060810440.25105-100000@gannet.stats>

table() turns its argument into a factor, as it is documented to work on 
factors, only, and

> factor(x$date)
[1] 1034809200 1034809200 1034809200 1034809200 944611200  944611200 
Levels: 944611200 1034809200

That's because unique.default does not know about POSIXct objects (nor 
indeed many other classes).  It had to be unique.default to avoid the 
matrix and data frame methods.

I suggest you coerce to a suitable factor yourself for now.


On Wed, 5 Mar 2003, David Kane  <David Kane wrote:

> Hi,
> 
> I think that there is something that I am misunderstanding in creating tables
> using dates that are of class POSIXct. Consider:
> 
> > x <- data.frame(date = as.POSIXct(strptime(c(rep("2002-10-17", 4), rep("1999-12-08", 2)), format = "%Y-%m-%d")))
> > x
>         date
> 1 2002-10-17
> 2 2002-10-17
> 3 2002-10-17
> 4 2002-10-17
> 5 1999-12-08
> 6 1999-12-08
> > table(x$date)
> 
>  944629200 1034827200 
>          2          4 
> 
> I understand that the headings here are the number of seconds since some
> epoch. But shouldn't the values print out here as they print out in the
> dataframe?
> 
> I can get the effect that I want using:
> 
> > table(format(x$date))
> 
> 1999-12-08 2002-10-17 
>          2          4 
> 
> The problem is that this can add a lot of time to the calculation in big
> dataframes.
> 
> > x <- data.frame(date = as.POSIXct(strptime(c(rep("2002-10-17", 40000), rep("1999-12-08", 20000)), format = "%Y-%m-%d")))
> > dim(x)
> [1] 60000     1
> > system.time(table(x$date))
> > [1] 0.19 0.00 0.19 0.00 0.00
> > system.time(table(format(x$date)))
> [1] 18  0 19  0  0
> 
> Am I missing something?
> 
> > R.version
>          _                   
> platform sparc-sun-solaris2.6
> arch     sparc               
> os       solaris2.6          
> system   sparc, solaris2.6   
> status                       
> major    1                   
> minor    6.2                 
> year     2003                
> month    01                  
> day      10                  
> language R                   
> > 
> 
> Thanks,
> 
> Dave Kane
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar  6 09:36:33 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 6 Mar 2003 08:36:33 +0000 (GMT)
Subject: [R] Timezones
In-Reply-To: <3E66F769.EE917065@lmttrading.com>
Message-ID: <Pine.LNX.4.44.0303060827460.25105-100000@gannet.stats>

It's a Linux issue.  Solaris gives:

> Sys.time()
[1] "2003-03-06 08:27:23 GMT"
> as.POSIXlt(Sys.time(), "HST")
[1] "2003-03-05 22:27:40 HST"

which looks right to me.  Past experience suggests that Solaris's POSIX
conformance is much better than glibc's.  Since my RH7.2 box does it too,
I will look for a workaround.  (The problem seems to be in the use of
tzset, and the code of zdump may indicate how to get around this.)

Brian

On Thu, 6 Mar 2003, Adrian Trapletti wrote:

> Can anybody give me a hint why as.POSIXlt doesn't recognize the same
> timezones that zdump knows about (Linux Suse 8.1 and Suse 7.3)? Is there
> a workaround?
> 
> R : Copyright 2002, The R Development Core Team
> Version 1.6.1  (2002-11-01)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type `license()' or `licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type `contributors()' for more information.
> 
> Type `demo()' for some demos, `help()' for on-line help, or
> `help.start()' for a HTML browser interface to help.
> Type `q()' to quit R.
> 
> [Previously saved workspace restored]
> 
> > Sys.time()
> [1] "2003-03-06 08:20:09 CET"
> > system("zdump CET")
> CET  Thu Mar  6 08:20:14 2003 CET
> > as.POSIXlt(Sys.time(), "HST")
> [1] "2003-03-06 08:20:18 CET"
> > system("zdump HST")
> HST  Wed Mar  5 21:20:20 2003 HST
> 
> best
> Adrian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Thu Mar  6 09:49:36 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 6 Mar 2003 09:49:36 +0100
Subject: [R] Transfer Function Modeling
In-Reply-To: <3E662D4D.2050509@nauticom.net>
References: <3E662D4D.2050509@nauticom.net>
Message-ID: <15975.2976.842245.648801@gargle.gargle.HOWL>

>>>>> "Richard" == Richard A Bilonick <rab at nauticom.net>
>>>>>     on Wed, 05 Mar 2003 12:01:01 -0500 writes:

    Richard> I think I've figured out the use of "filter" in the ts package, at least 
    Richard> for a simple AR model. I simulated a simple AR time series, modeled it 
    Richard> using "arima",  and then used "filter" to compute the 1-step ahead 
    Richard> forecasts:

    >> y.arma <- arima.sim(list(ar=0.8),n=200)
    >> y.arma.arima <- arima(y.arma,order=c(1,0,0),include.mean=FALSE)
    >> y.arma.arima

    Richard> Call:
    Richard> arima(x = y.arma, order = c(1, 0, 0), include.mean = FALSE)

    Richard> Coefficients:
    Richard> ar1
    Richard> 0.7594
    Richard> s.e.  0.0455

    Richard> sigma^2 estimated as 1.059:  log likelihood = -290,  aic = 583.99

    >> plot(y.arma[-1],lines="l")
    >> lines(filter(y.arma,y.arma.arima$coef,method="con")[-200],lty=2)

    Richard> So using the "convolution" method appears to produce the correct 
    Richard> forecast for the y.arma series.

    Richard> But suppose I had generated and fitted an ARMA(1,1) or ARIMA(1,1,1) 
    Richard> model? How would I use "filter" in this case?

help(predict.Arima)

describes the predict() method for objects of class "Arima"
which is what you get from  res <- arima(.....)

I'd use that in any case instead of filter().


PS: Please guys, stop doing the following:
    1. You want to post something to R-help.  
    2. You are too lazy to type r-help at r-project.org [the
        shortest of several possible addresses] 
    3. you reply to another __unrelated__ posting to R-help instead.

==> all threads are mixed up !
    -- both on the mailing list archives, and on anyone's e-mail
    list who uses threaded e-mail presentation  (e.g. me.)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From gti1x at vet.gla.ac.uk  Thu Mar  6 10:46:57 2003
From: gti1x at vet.gla.ac.uk (Giles Innocent)
Date: Thu, 6 Mar 2003 09:46:57 +0000
Subject: [R] how to find the location of the first TRUE of a logical
	vector
In-Reply-To: <3E667DD7.3070108@pdf.com>;
	from spencer.graves@pdf.com on Wed, Mar 05, 2003 at 22:44:39 +0000
References: <004f01c2e363$1bd904b0$0201a8c0@MARC> <3E667DD7.3070108@pdf.com>
Message-ID: <20030306094657.A8079@leslie.vet.gla.ac.uk>

Or even:

which(lv)[1]

as lv is already a logical vector

Giles

On 2003.03.05 22:44 Spencer Graves wrote:
> Also:
> 
>   which(lv == TRUE)[1]
> 
> Spencer Graves
> 
> Marc Schwartz wrote:
>>> -----Original Message-----
>>> From: r-help-bounces at stat.math.ethz.ch 
>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jason Liao
>>> Sent: Wednesday, March 05, 2003 3:36 PM
>>> To: r-help at stat.math.ethz.ch
>>> Subject: [R] how to find the location of the first TRUE of a 
>>> logical vector
>>> 
>>> 
>>> without having to check the vector element by element? Thanks a lot!
>>> 
>>> Jason
>>> 
>>> =====
>>> Jason G. Liao, Ph.D.
>>> Division of Biometrics
>>> University of Medicine and Dentistry of New Jersey
>>> 335 George Street, Suite 2200
>>> New Brunswick, NJ 08903-2688
>>> phone (732) 235-8611, fax (732) 235-9777 
>>> http://www.geocities.com/jg_liao
>> 
>> 
>> 
>> If 'lv' if your logical vector, you could use something like:
>> 
>> min(which(lv == TRUE))
>> 
>> which() would return a vector of the indices within 'lv' that match
>> TRUE and of course min() will give you the lowest index value.
>> 
>> An example:
>> 
>> 
>>> lv <- c(FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE)
>>> lv
>> 
>> [1] FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE
>> 
>>> min(which(lv == TRUE))
>> 
>> [1] 4
>> 
>> 
>> HTH,
>> 
>> Marc Schwartz
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From poizot at cnam.fr  Thu Mar  6 11:43:31 2003
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Thu, 6 Mar 2003 10:43:31 +0000
Subject: [R] Correlation test
Message-ID: <200303061043.31109.poizot@cnam.fr>

Hi,
I need to test multiple correlation coefficient in a same time,
what's the best test for that and are should I do under R ?
Thanks
-- 
Cordialement
----------------------------------------
Emmanuel POIZOT
Cnam/Intechmer
Digue de Collignon
50110 Tourlaville
T?l : (33)(0)2 33 88 73 42
Fax : (33)(0)2 33 88 73 39
-----------------------------------------


From david.whiting at ncl.ac.uk  Thu Mar  6 13:48:00 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Thu, 6 Mar 2003 12:48:00 +0000
Subject: [stuart.leask@nottingham.ac.uk: [R] R in your pocket on a Sharp
	Zaurus]
In-Reply-To: <OE49KmXpMyhztqVDwnF000068df@hotmail.com>
References: <20030305091531.GB3729@192.168.57.2>
	<OE49KmXpMyhztqVDwnF000068df@hotmail.com>
Message-ID: <20030306124800.GE2794@192.168.57.2>

Ah, but the interesting thing is that they are coming out with a 'clam'
version like the 5MX.  Details are limited at the moment, but that could
mean the combination of 5MX usability with a supported linux distro.  I
am drooling in anticipation.  Sounds like a "I've finally finished my
PhD and deserve a treat" situation to me :)

Dave


On Thu, Mar 06, 2003 at 09:17:20AM -0000, Nigel Unwin wrote:
> Hi Dave
> 
> Interesting indeed. I had a look at the Zaurus website. Nice looking
> machine, and the graphics appear to be very good. The main draw back based
> on the web pictures/video is that the key pad is small and cramped and
> really wouldn't allow the ease/efficiency of use the series 5 does.... but
> its getting closer to something that could be a replacement or advance on
> the series 5.
> 
> Cheers for now
> 
> Nigel
> ========================================
> To find out more about our work visit our web site:
> www.ncl.ac.uk/hopit
> ========================================
> ----- Original Message -----
> From: <david.whiting at ncl.ac.uk>
> To: <setel.ammp at twiga.com>; "Nigel Unwin" <nigelunwin at hotmail.com>
> Sent: Wednesday, March 05, 2003 9:15 AM
> Subject: [stuart.leask at nottingham.ac.uk: [R] R in your pocket on a Sharp
> Zaurus]
> 
> 
> > Interesting... and Sharp are coming out with a clam-verison of this PDA
> > (i.e. like this Psion 5MX).
> >
> > Dave
> > --
> > David Whiting
> > Adult Morbidity and Mortality Project (AMMP)
> > PO Box 65243, Aga Khan Foundation Building - Ground Floor
> > Plot No 344 Urambo Street, Upanga, Dar es Salaam, Tanzania.
> >
> > Tel: +255 22 2153388, Fax: +255 22 2153385
> > AMMP website: www.ncl.ac.uk/ammp
> >
> > Against MS attachments. Why? See for example:
> > http://www.goldmark.org/netrants/no-word/attach.html
> > http://linuxtoday.com/news_story.php3?ltsn=2002-01-11-002-20-OP
> >

-- 
Dave Whiting
Dar es Salaam, Tanzania


From p.dalgaard at biostat.ku.dk  Thu Mar  6 11:35:35 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 06 Mar 2003 11:35:35 +0100
Subject: [stuart.leask@nottingham.ac.uk: [R] R in your pocket on a Sharp
	Zaurus]
In-Reply-To: <20030306124800.GE2794@192.168.57.2>
References: <20030305091531.GB3729@192.168.57.2>
	<OE49KmXpMyhztqVDwnF000068df@hotmail.com>
	<20030306124800.GE2794@192.168.57.2>
Message-ID: <x2of4ook94.fsf@biostat.ku.dk>

david.whiting at ncl.ac.uk writes:

> Ah, but the interesting thing is that they are coming out with a 'clam'
> version like the 5MX.  Details are limited at the moment, but that could
> mean the combination of 5MX usability with a supported linux distro.  I
> am drooling in anticipation.  Sounds like a "I've finally finished my
> PhD and deserve a treat" situation to me :)

SL-C700, yes. I've been looking at that one too. Terminally cute...
But I do wonder if you two are not actually talking about the same
machine. Packing a full QWERTY keyboard in between F7-F12 of a normal
keyboard has got to get a little cramped.

For the uninitiated: http://www.the-gadgeteer.com/sharp-c700-review.html

> On Thu, Mar 06, 2003 at 09:17:20AM -0000, Nigel Unwin wrote:
> > Hi Dave
> > 
> > Interesting indeed. I had a look at the Zaurus website. Nice looking
> > machine, and the graphics appear to be very good. The main draw back based
> > on the web pictures/video is that the key pad is small and cramped and
> > really wouldn't allow the ease/efficiency of use the series 5 does.... but
> > its getting closer to something that could be a replacement or advance on
> > the series 5.

> > > Interesting... and Sharp are coming out with a clam-verison of this PDA
> > > (i.e. like this Psion 5MX).


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From rob.foxall at BBSRC.AC.UK  Thu Mar  6 11:38:10 2003
From: rob.foxall at BBSRC.AC.UK (rob foxall (IFR))
Date: Thu, 6 Mar 2003 10:38:10 -0000 
Subject: [R] anova subhypotheses
Message-ID: <AF4854EAE0A4D411A7AC00508BDCD6E802969297@fr-exsrv1.ifrn.bbsrc.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030306/6366109f/attachment.pl

From ichii at ms.u-tokyo.ac.jp  Thu Mar  6 11:52:37 2003
From: ichii at ms.u-tokyo.ac.jp (Shingo Ichii)
Date: Thu, 6 Mar 2003 19:52:37 +0900
Subject: [R] installation on FreeBSD
In-Reply-To: <Pine.GSO.4.53.0302082329350.18164@hsph.harvard.edu>
References: <Pine.GSO.4.53.0302082329350.18164@hsph.harvard.edu>
Message-ID: <200303061952.HIE85476.DJJJI@ms.u-tokyo.ac.jp>

Hi,

> I just changed to FreeBSD platform, and want to install R on it. I use
> FreeBSD 5.0 and install nearly all packages on the machine. When I use
> ports to install R, (cd /usr/ports/math/R-letter, and then type make) I
> got the following error information.
> ../../../../library/methods/libs/methods.so is unchanged
> dumping R code in package 'methods'
> Fatal error: The X11 shared library could not be loaded.
>   The error was /usr/ports/math/R-letter/work/R-1.6.0/modules/R_X11.so:
> Undefined symbol "R_GlobalEnv"

I encountered the same problem.
My quick solution is:

	$ ./configure
	$ make (fails)
	$ cd src/main
	$ rm R.bin
	$ edit Makefile
	(uncomment the line 81: "R_bin_LDFLAGS = -export-dynamic")
	$ make
	$ cd ../..
	$ make

Hope this helps.

Shingo Ichii
Graduate School of Mathematical Sciences, University of Tokyo


From p.dalgaard at biostat.ku.dk  Thu Mar  6 12:30:01 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 06 Mar 2003 12:30:01 +0100
Subject: [R] anova subhypotheses
In-Reply-To: <AF4854EAE0A4D411A7AC00508BDCD6E802969297@fr-exsrv1.ifrn.bbsrc.ac.uk>
References: <AF4854EAE0A4D411A7AC00508BDCD6E802969297@fr-exsrv1.ifrn.bbsrc.ac.uk>
Message-ID: <x2k7fcohqe.fsf@biostat.ku.dk>

"rob foxall (IFR)" <rob.foxall at BBSRC.AC.UK> writes:

> Hello all,
> 
>             A really noddy question for you all: I'm trying without success to do some subhypothesis testing. Using simple anova model, with a toy dataset from a book. I have four factors A,B,C,D, and wish to test mu_C = mu_D. This is what I have tried:
> 
>  
> 
> > contrasts(infants$group,how.many=1) <- c(0,0,1,-1)
> 
> > contrasts(infants$group)
> 
>   [,1]
> 
> A    0
> 
> B    0
> 
> C    1
> 
> D   -1
> 
> > fit <- aov(age~group,data=infants)
> 
> > summary(fit)
> 
>             Df Sum Sq Mean Sq F value Pr(>F)
> 
> group        1  0.740   0.740  0.2693 0.6092
> 
> Residuals   21 57.727   2.749               
> 
>  
> 
> Now I know from the book, hand calculations and SPSS that for "group", Sum Sq = Mean Sq = 1.12, not 0.740. Also from the standard anova:
> 
>  
> 
> > contrasts(infants$group) <- "contr.treatment"
> 
> > fit <- aov(age~group,data=infants)
> 
> > summary(fit)
> 
>             Df Sum Sq Mean Sq F value Pr(>F)
> 
> group        3 14.778   4.926  2.1422 0.1285
> 
> Residuals   19 43.690   2.299         
> 
>  
> 
> So I'd like to have the (correct) Mean Sq value divided by 2.299 and
> not 2.749, with 19 and not 21 df. Any advice on how to correctly use
> contrasts for subhypothesis testing, including where to find it in
> the manuals, would be much appreciated.

(The pervasive Zelazo dataset, eh? That's not a toy, it's a Science
paper. With methodological errors, even.) 

You're not comparing the same models. With a contrast specification
like that you're describing a model where group A and B are equal to
the intercept and C is as much above the intercept as D is below.

What you need to do is to compare two models, one in which C and D are
equal (and A and B are arbitrary) and one in which they are not. E.g.,
I have

> gr
 [1] active  active  active  active  active  active  passive passive passive
[10] passive passive passive none    none    none    none    none    none
[19] ctr.8w  ctr.8w  ctr.8w  ctr.8w  ctr.8w
Levels: active passive none ctr.8w

> gr2 <- gr ; levels(gr2) <- c("active","passive","ctr/non","ctr/non")

# (note that you need to be very careful that levels are specified in
#  correct order there...)

> model1 <- lm(age~gr)
> model2 <- lm(age~gr2)
> anova(model2,model1)
Analysis of Variance Table

Model 1: age ~ gr2
Model 2: age ~ gr
  Res.Df    RSS Df Sum of Sq      F Pr(>F)
1     20 44.812
2     19 43.690  1     1.123 0.4883 0.4931

Or, a little more sneaky, use the fact that the anova table for a
model is cumulative (Type I, if you want to speak SAS-ish):

> anova(lm(age~gr2+gr))
Analysis of Variance Table

Response: age
          Df Sum Sq Mean Sq F value Pr(>F)
gr2        2 13.655   6.827  2.9692 0.0755 .
gr         1  1.123   1.123  0.4883 0.4931
Residuals 19 43.690   2.299
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From david.whiting at ncl.ac.uk  Thu Mar  6 15:26:25 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Thu, 6 Mar 2003 14:26:25 +0000
Subject: [stuart.leask@nottingham.ac.uk: [R] R in your pocket on a Sharp
	Zaurus]
In-Reply-To: <x2of4ook94.fsf@biostat.ku.dk>
References: <20030305091531.GB3729@192.168.57.2>
	<OE49KmXpMyhztqVDwnF000068df@hotmail.com> <20030306124800.GE2794@192.168.57.2>
	<x2of4ook94.fsf@biostat.ku.dk>
Message-ID: <20030306142625.GJ2794@192.168.57.2>

Oops, sorry folks, I didn't mean to send any of these emails to the R
list, I thought I was having a private  discussion...I'm going to have
to see what I did wrong.  

Dave


iOn Thu, Mar 06, 2003 at 11:35:35AM +0100, Peter Dalgaard BSA wrote:
> david.whiting at ncl.ac.uk writes:
> 
> > Ah, but the interesting thing is that they are coming out with a 'clam'
> > version like the 5MX.  Details are limited at the moment, but that could
> > mean the combination of 5MX usability with a supported linux distro.  I
> > am drooling in anticipation.  Sounds like a "I've finally finished my
> > PhD and deserve a treat" situation to me :)
> 
> SL-C700, yes. I've been looking at that one too. Terminally cute...
> But I do wonder if you two are not actually talking about the same
> machine. Packing a full QWERTY keyboard in between F7-F12 of a normal
> keyboard has got to get a little cramped.
> 
> For the uninitiated: http://www.the-gadgeteer.com/sharp-c700-review.html
> 
> > On Thu, Mar 06, 2003 at 09:17:20AM -0000, Nigel Unwin wrote:
> > > Hi Dave
> > > 
> > > Interesting indeed. I had a look at the Zaurus website. Nice looking
> > > machine, and the graphics appear to be very good. The main draw back based
> > > on the web pictures/video is that the key pad is small and cramped and
> > > really wouldn't allow the ease/efficiency of use the series 5 does.... but
> > > its getting closer to something that could be a replacement or advance on
> > > the series 5.
> 
> > > > Interesting... and Sharp are coming out with a clam-verison of this PDA
> > > > (i.e. like this Psion 5MX).
> 
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Dave Whiting
Dar es Salaam, Tanzania


From p.dalgaard at biostat.ku.dk  Thu Mar  6 12:38:47 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 06 Mar 2003 12:38:47 +0100
Subject: [R] installation on FreeBSD
In-Reply-To: <200303061952.HIE85476.DJJJI@ms.u-tokyo.ac.jp>
References: <Pine.GSO.4.53.0302082329350.18164@hsph.harvard.edu>
	<200303061952.HIE85476.DJJJI@ms.u-tokyo.ac.jp>
Message-ID: <x2fzq0ohbs.fsf@biostat.ku.dk>

Shingo Ichii <ichii at ms.u-tokyo.ac.jp> writes:

> Hi,
> 
> > I just changed to FreeBSD platform, and want to install R on it. I use
> > FreeBSD 5.0 and install nearly all packages on the machine. When I use
> > ports to install R, (cd /usr/ports/math/R-letter, and then type make) I
> > got the following error information.
> > ../../../../library/methods/libs/methods.so is unchanged
> > dumping R code in package 'methods'
> > Fatal error: The X11 shared library could not be loaded.
> >   The error was /usr/ports/math/R-letter/work/R-1.6.0/modules/R_X11.so:
> > Undefined symbol "R_GlobalEnv"
> 
> I encountered the same problem.
> My quick solution is:
> 
> 	$ ./configure
> 	$ make (fails)
> 	$ cd src/main
> 	$ rm R.bin
> 	$ edit Makefile
> 	(uncomment the line 81: "R_bin_LDFLAGS = -export-dynamic")
> 	$ make
> 	$ cd ../..
> 	$ make
> 
> Hope this helps.

A cleaner solution is to modify the line in configure that says

 freebsd[3-4].*)

to have [3-5] instead. Or change it in configure.ac and run autoconf.
The basic problem is that we didn't support FreeBSD v.5 before it
existed...
 
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From kjetil at entelnet.bo  Thu Mar  6 12:44:13 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Thu, 06 Mar 2003 07:44:13 -0400
Subject: [R] anova subhypotheses
In-Reply-To: <AF4854EAE0A4D411A7AC00508BDCD6E802969297@fr-exsrv1.ifrn.bbsrc.ac.uk>
Message-ID: <3E66FC4D.11671.1AA912@localhost>

On 6 Mar 2003 at 10:38, rob foxall (IFR) wrote:

You can use linear.hypothesis() from the
package car (on CRAN).

Kjetil Halvorsen

> Hello all,
> 
>             A really noddy question for you all: I'm trying without success to do some subhypothesis testing. Using simple anova model, with a toy dataset from a book. I have four factors A,B,C,D, and wish to test mu_C = mu_D. This is what I have tried:
> 
>  
> 
> > contrasts(infants$group,how.many=1) <- c(0,0,1,-1)
> 
> > contrasts(infants$group)
> 
>   [,1]
> 
> A    0
> 
> B    0
> 
> C    1
> 
> D   -1
> 
> > fit <- aov(age~group,data=infants)
> 
> > summary(fit)
> 
>             Df Sum Sq Mean Sq F value Pr(>F)
> 
> group        1  0.740   0.740  0.2693 0.6092
> 
> Residuals   21 57.727   2.749               
> 
>  
> 
> Now I know from the book, hand calculations and SPSS that for "group", Sum Sq = Mean Sq = 1.12, not 0.740. Also from the standard anova:
> 
>  
> 
> > contrasts(infants$group) <- "contr.treatment"
> 
> > fit <- aov(age~group,data=infants)
> 
> > summary(fit)
> 
>             Df Sum Sq Mean Sq F value Pr(>F)
> 
> group        3 14.778   4.926  2.1422 0.1285
> 
> Residuals   19 43.690   2.299         
> 
>  
> 
> So I'd like to have the (correct) Mean Sq value divided by 2.299 and not 2.749, with 19 and not 21 df. Any advice on how to correctly use contrasts for subhypothesis testing, including where to find it in the manuals, would be much appreciated.
> 
>  
> 
> Cheers,
> 
>             Rob.
> 
>  
> 
> (Other info)
> 
>  
> 
> Using R 1.6.2, windows xp, 
> 
>  
> 
> data:
> 
> > infants
> 
>    group   age
> 
> 1      A  9.00
> 
> 2      A  9.50
> 
> 3      A  9.75
> 
> 4      A 10.00
> 
> 5      A 13.00
> 
> 6      A  9.50
> 
> 7      B 11.00
> 
> 8      B 10.00
> 
> 9      B 10.00
> 
> 10     B 11.75
> 
> 11     B 10.50
> 
> 12     B 15.00
> 
> 13     C 11.50
> 
> 14     C 12.00
> 
> 15     C  9.00
> 
> 16     C 11.50
> 
> 17     C 13.25
> 
> 18     C 13.00
> 
> 19     D 13.25
> 
> 20     D 11.50
> 
> 21     D 12.00
> 
> 22     D 13.50
> 
> 23     D 11.50
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Thu Mar  6 13:13:23 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 6 Mar 2003 12:13:23 +0000 (GMT)
Subject: [R] Timezones
In-Reply-To: <Pine.LNX.4.44.0303060827460.25105-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0303061209130.26094-100000@gannet.stats>

zdump manipulates its environment directly but is otherwise the same code.
Solaris and glibc define putenv slightly differently.  There are
two lines like

        char buff[20];

in src/main/datetime.c, and if you change those to 

	static char buff[200];

it should work (increasing the length as Linux timezones can be long).
(Does for me on RH7.2.)


On Thu, 6 Mar 2003 ripley at stats.ox.ac.uk wrote:

> It's a Linux issue.  Solaris gives:
> 
> > Sys.time()
> [1] "2003-03-06 08:27:23 GMT"
> > as.POSIXlt(Sys.time(), "HST")
> [1] "2003-03-05 22:27:40 HST"
> 
> which looks right to me.  Past experience suggests that Solaris's POSIX
> conformance is much better than glibc's.  Since my RH7.2 box does it too,
> I will look for a workaround.  (The problem seems to be in the use of
> tzset, and the code of zdump may indicate how to get around this.)
> 
> Brian
> 
> On Thu, 6 Mar 2003, Adrian Trapletti wrote:
> 
> > Can anybody give me a hint why as.POSIXlt doesn't recognize the same
> > timezones that zdump knows about (Linux Suse 8.1 and Suse 7.3)? Is there
> > a workaround?
> > 
> > R : Copyright 2002, The R Development Core Team
> > Version 1.6.1  (2002-11-01)
> > 
> > R is free software and comes with ABSOLUTELY NO WARRANTY.
> > You are welcome to redistribute it under certain conditions.
> > Type `license()' or `licence()' for distribution details.
> > 
> > R is a collaborative project with many contributors.
> > Type `contributors()' for more information.
> > 
> > Type `demo()' for some demos, `help()' for on-line help, or
> > `help.start()' for a HTML browser interface to help.
> > Type `q()' to quit R.
> > 
> > [Previously saved workspace restored]
> > 
> > > Sys.time()
> > [1] "2003-03-06 08:20:09 CET"
> > > system("zdump CET")
> > CET  Thu Mar  6 08:20:14 2003 CET
> > > as.POSIXlt(Sys.time(), "HST")
> > [1] "2003-03-06 08:20:18 CET"
> > > system("zdump HST")
> > HST  Wed Mar  5 21:20:20 2003 HST
> > 
> > best
> > Adrian
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From adrian.trapletti at lmttrading.com  Thu Mar  6 13:58:34 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Thu, 06 Mar 2003 13:58:34 +0100
Subject: [R] Timezones
References: <Pine.LNX.4.44.0303061209130.26094-100000@gannet.stats>
Message-ID: <3E6745FA.A4E52248@lmttrading.com>

ripley at stats.ox.ac.uk wrote:

> zdump manipulates its environment directly but is otherwise the same code.
> Solaris and glibc define putenv slightly differently.  There are
> two lines like
>
>         char buff[20];
>
> in src/main/datetime.c, and if you change those to
>
>         static char buff[200];
>
> it should work (increasing the length as Linux timezones can be long).
> (Does for me on RH7.2.)
>

Does for me too (Suse 7.3, Suse 8.1). Thanks very much!

best
Adrian


From solares at unsl.edu.ar  Thu Mar  6 15:33:05 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Thu, 6 Mar 2003 11:33:05 -0300 (ART)
Subject: [R] tkexit
Message-ID: <33118.170.210.173.216.1046961185.squirrel@inter14.unsl.edu.ar>

Sorry, my question is if exists a command tkexit in R, i need a command how 
exit of tcl for close an aplication. How to use him. Thank


From jzhang at jimmy.harvard.edu  Thu Mar  6 16:11:22 2003
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Thu, 6 Mar 2003 10:11:22 -0500 (EST)
Subject: [R] tkexit
Message-ID: <200303061511.KAA11507@blaise.dfci.harvard.edu>

Would tkdestroy() work for you?

>Date: Thu, 6 Mar 2003 11:33:05 -0300 (ART)
>From: <solares at unsl.edu.ar>
>To: r-announce at stat.math.ethz.ch
>MIME-Version: 1.0
>Content-Transfer-Encoding: 8bit
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Spam-Status: No, hits=2.1 required=5.0 tests=NO_REAL_NAME,SPAM_PHRASE_00_01 
version=2.43
>X-Spam-Level: **
>Subject: [R] tkexit
>X-BeenThere: r-help at stat.math.ethz.ch
>X-Mailman-Version: 2.1.1
>List-Id: Main R Mailing List: Primary help <r-help.stat.math.ethz.ch>
>List-Help: <mailto:r-help-request at stat.math.ethz.ch?subject=help>
>List-Post: <mailto:r-help at stat.math.ethz.ch>
>List-Subscribe: <https://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>
>List-Archive: <https://www.stat.math.ethz.ch/pipermail/r-help>
>List-Unsubscribe: <https://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
>
>Sorry, my question is if exists a command tkexit in R, i need a command how 
>exit of tcl for close an aplication. How to use him. Thank
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Jianhua Zhang
Department of Biostatistics
Dana-Farber Cancer Institute
44 Binney Street
Boston, MA 02115-6084


From chrysopa at insecta.ufv.br  Thu Mar  6 15:46:28 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Thu, 6 Mar 2003 11:46:28 -0300
Subject: [R] Problems with variable types.
Message-ID: <200303061146.28816.chrysopa@insecta.ufv.br>

Hi all,

I have problems in a dataframe variables types.

Look:

from a loop function:
for(...){
...
dados.fin <- rbind(dados.fin, c(L=j, A=j^2,
                                Nsp=nsps,
                                N=length(amosfin$SP),
                                AmT="am",NAm=nam,
                                AMST=amst))
dados.fin <- rbind(dados.fin, c(L=j, A=j^2,
                                Nsp=nsp, 
                                N=nbicho, AmT="tot",
                                NAm=nam,
                                AMST=amst))
...
}

    dados.fin <- as.data.frame(dados.fin)

> summary(dados.fin)
  L        A           Nsp           N       AmT     NAm      AMST   
 10:10   100:10   11     : 7   12     : 5   am :30   5:60   unif:60  
 12:10   144:10   7      : 7   122    : 5   tot:30                   
 14:10   196:10   16     : 5   181    : 5                            
 16:10   256:10   25     : 5   270    : 5                            
 18:10   324:10   37     : 5   403    : 5                            
 20:10   400:10   55     : 5   55     : 5                            
                  (Other):26   (Other):30                            

All variables appear like factors, but only AmT and AMST are really factors.

I try to use 

dados.fin <- rbind(dados.fin, c(L=as.numeric(j), A=j^2,
                                Nsp=nsp, 
                                N=nbicho, AmT="tot",
                                NAm=nam,
                                AMST=amst))

and some combinations like as.numeric(as.character(j)) etc.

How I make to force the types?

Thanks for all,

Ronaldo
-- 
Pessoas que s?o boas para arranjar desculpas raramente s?o boas em
qualquer outra coisa.
                -- Benjamim Franklin
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From lehmann at puk.unibe.ch  Thu Mar  6 16:52:26 2003
From: lehmann at puk.unibe.ch (Christoph Lehmann)
Date: 06 Mar 2003 16:52:26 +0100
Subject: [R] least absolute deviation regression
Message-ID: <1046965947.9230.0.camel@christophl>

is there any package or method which enables to compute a linear
regression with the leas absolute value fit-criterion?

thanks 

christoph
-- 
Christoph Lehmann                            Phone:  ++41 31 930 93 83 
Department of Psychiatric Neurophysiology    Mobile: ++41 76 570 28 00
University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61 
Waldau                                            lehmann at puk.unibe.ch 
CH-3000 Bern 60            http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html


From p.dalgaard at biostat.ku.dk  Thu Mar  6 17:12:38 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 06 Mar 2003 17:12:38 +0100
Subject: [R] least absolute deviation regression
In-Reply-To: <1046965947.9230.0.camel@christophl>
References: <1046965947.9230.0.camel@christophl>
Message-ID: <x2heagmq2x.fsf@biostat.ku.dk>

Christoph Lehmann <lehmann at puk.unibe.ch> writes:

> is there any package or method which enables to compute a linear
> regression with the leas absolute value fit-criterion?

Try rq() from the quantreg package.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From jerosenb at hcs.harvard.edu  Thu Mar  6 18:21:05 2003
From: jerosenb at hcs.harvard.edu (janet rosenbaum)
Date: Thu, 6 Mar 2003 12:21:05 -0500 (EST)
Subject: [R] tkoptionmenu
In-Reply-To: <200303061511.KAA11507@blaise.dfci.harvard.edu> from "John Zhang"
	at Mar 06, 2003 10:11:22 AM
Message-ID: <200303061721.h26HL5fN027150@hcs.harvard.edu>


I have two questions:  one so easy that I apologise for it in advance 
and one maybe more obscure:

1.  Interactively, typing the variable name will cause its value to print.
How do I print out a variable's value inside of a script?
I've tried cat("Field separator" fsep) and variations thereon, and
haven't found anything that works.

2.  I also have a tcltk in R question.  

How do you use the command tkoptionmenu in R?  

The following are both valid syntax and both create the desired menu, 
but neither changes the variable fsep.

septype.menu <- tkoptionmenu(septype,fsep, ",",";", ".", "\t", " ", "")
septype.menu <- tkoptionmenu(septype,variable=fsep, ",",";", ".", "\t", " ", "")

septype is the frame that optionmenu is placed in, and fsep is
the variable whose value I want to change.  

I consulted with the tcltk documentation and none of their syntax or
variations thereon works.  

Thanks,

Janet Rosenbaum
Center for Basic Research in the Social Sciences, Harvard University


From spencer.graves at pdf.com  Thu Mar  6 18:42:04 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 06 Mar 2003 09:42:04 -0800
Subject: [R] tkoptionmenu
References: <200303061721.h26HL5fN027150@hcs.harvard.edu>
Message-ID: <3E67886C.6020009@pdf.com>

Regarding "1", both "cat(x)" and "print(x)" have worked for me, 
depending on the class of "x".  To get extra labeling, sometimes I have 
used

	 print(list(x=x))

and variants on that.
Hope this helps.
Spencer Graves

janet rosenbaum wrote:
> I have two questions:  one so easy that I apologise for it in advance 
> and one maybe more obscure:
> 
> 1.  Interactively, typing the variable name will cause its value to print.
> How do I print out a variable's value inside of a script?
> I've tried cat("Field separator" fsep) and variations thereon, and
> haven't found anything that works.
> 
> 2.  I also have a tcltk in R question.  
> 
> How do you use the command tkoptionmenu in R?  
> 
> The following are both valid syntax and both create the desired menu, 
> but neither changes the variable fsep.
> 
> septype.menu <- tkoptionmenu(septype,fsep, ",",";", ".", "\t", " ", "")
> septype.menu <- tkoptionmenu(septype,variable=fsep, ",",";", ".", "\t", " ", "")
> 
> septype is the frame that optionmenu is placed in, and fsep is
> the variable whose value I want to change.  
> 
> I consulted with the tcltk documentation and none of their syntax or
> variations thereon works.  
> 
> Thanks,
> 
> Janet Rosenbaum
> Center for Basic Research in the Social Sciences, Harvard University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From fruits at portland.econw.com  Thu Mar  6 19:08:34 2003
From: fruits at portland.econw.com (Eric Fruits)
Date: Thu, 6 Mar 2003 10:08:34 -0800
Subject: [R] Followup: copy-paste graphics from R to Word on Mac OS X
Message-ID: <A566ED6C-4FFE-11D7-B8F6-0003938E023E@portland.econw.com>

After trying numerous options, I'm just about at my wits end.

The most frequent suggestion was to export to a postscript or PDF file 
and import that into Word.

However, no matter what I did or how I did it, the results were 
extraordinarily ugly and somewhat time-consuming.

What I've tried so far:

1.  Copy and paste from the R graphics output window into Word (in Mac 
OS X), this is the worst result.

2.  Use pdf() to create a pdf file, then import (Insert | Picture | 
 From File ...) into Word.  This generated the second-worst results.  
Note, that if I print the .pdf file without importing, the results are 
OK.

3.  Use pdf() to create a pdf file, use MacGSView to convert to .tiff, 
then import into Word.  This provided the third-worst results.  Note 
that the .tiff file is jaggy too.

4.  Use pdf() to create a pdf file, use the full-blown version of 
Acrobat to convert to .tiff, then import into Word.  This provided the 
best, but still ugly results.  Note that the .tiff file is jaggy too.

It is conceivable that this is a Mac OS X problem, but I'm not 
convinced considering how well it handles other graphics.

Any suggestions are appreciated.

Begin forwarded message:

> From: Eric Fruits <fruits at portland.econw.com>
> Date: Fri Feb 21, 2003  10:32:52  AM US/Pacific
> To: r-help at lists.R-project.org
> Subject: Copy-paste graphics from R to Word on Mac OS X
>
> Greetings:
>
> 	I'm (very) new  to R.
>
> 	One of the features of R that I really like is R's ability to quickly 
> generate very good looking graphics.  However, I've noticed that when 
> I attempt to copy and paste the graphs from the R graphics output 
> window into Word (in Mac OS X), the resulting picture is very jaggy.
>
> 	I'm aware of the various options such as dev2bitmap, but I'd really 
> like to be able to do a quick copy and paste without switching among 
> various applications or creating extraneous files.
>
> 	Thanks.
>
> -- 
> Eric Fruits, Ph.D.
> Senior Economist & Project Manager
> ECONorthwest - Portland
>


From mmiller3 at iupui.edu  Thu Mar  6 19:32:40 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: 06 Mar 2003 13:32:40 -0500
Subject: [R] question about model formula
Message-ID: <874r6gpcqf.fsf@lumen.indyrad.iupui.edu>

Dear R Gang,

I'm interested in using R and the nls package for fitting kinetic
models.  I'm having some difficulty getting a model specified for
nls though.  The math for the model that I want to fit is

   dg(t)/dt = K1 f(t) - k2 g(t)

where g(t) and f(t) are measured data at a sequence of times t.
K1 and k2 are the parameters of the model.  If I solve this, the
solution is

  g(t) = K1 \int_0^t f(t') \exp(-k2(t-t')) dt'

and I'm not sure how to write a formula in R that I can pass to
nls that will handle both the implicit loop over the data values
of t and the interpolation and numeric integration over t'.

Can anyone help me to get this properly coded for R?

Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine


From p.dalgaard at biostat.ku.dk  Thu Mar  6 19:37:59 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 06 Mar 2003 19:37:59 +0100
Subject: [R] tkoptionmenu
In-Reply-To: <200303061721.h26HL5fN027150@hcs.harvard.edu>
References: <200303061721.h26HL5fN027150@hcs.harvard.edu>
Message-ID: <x2smu02veg.fsf@biostat.ku.dk>

"janet rosenbaum" <jerosenb at hcs.harvard.edu> writes:

> 2.  I also have a tcltk in R question.  
> 
> How do you use the command tkoptionmenu in R?  
> 
> The following are both valid syntax and both create the desired menu, 
> but neither changes the variable fsep.
> 
> septype.menu <- tkoptionmenu(septype,fsep, ",",";", ".", "\t", " ", "")
> septype.menu <- tkoptionmenu(septype,variable=fsep, ",",";", ".", "\t", " ", "")
> 
> septype is the frame that optionmenu is placed in, and fsep is
> the variable whose value I want to change.  
> 
> I consulted with the tcltk documentation and none of their syntax or
> variations thereon works.  

What tkoptionmenu command?? I don't see one

> ls("package:tcltk", pattern="enu")
[1] "tkmenu"       "tkmenubutton"

Did you write one yourself, interfacing to tk_optionMenu? That's not
completely easy to get right. Or is there one in a contributed package?

In general "variable"-type arguments need to be objects of class
tclVar.

Something like this should work, but there are a few demons lurking
inside

tkoptionmenu <- function(...) tkcmd("tk_optionMenu", ...)
tt <- tktoplevel()
w <- .Tk.subwin(tt) # this is nasty! Is everything protected from GC??
fsep <- tclVar()
m <- tkoptionmenu(w, fsep, ",",";", ".", "\t", " ", "")
tkpack(w)
# select something
tclvalue(fsep)
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From jasont at indigoindustrial.co.nz  Thu Mar  6 19:46:15 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 7 Mar 2003 07:46:15 +1300
Subject: [R] Followup: copy-paste graphics from R to Word on Mac OS X
In-Reply-To: <A566ED6C-4FFE-11D7-B8F6-0003938E023E@portland.econw.com>;
	from fruits@portland.econw.com on Thu, Mar 06, 2003 at 10:08:34AM -0800
References: <A566ED6C-4FFE-11D7-B8F6-0003938E023E@portland.econw.com>
Message-ID: <20030307074615.A4276@camille.indigoindustrial.co.nz>

On Thu, Mar 06, 2003 at 10:08:34AM -0800, Eric Fruits wrote:
[four permutations on pdf() snipped]

Have you tried other graphics drivers?  help(png) and help(jpeg) might
be other options.  I'd suggest playing with the "height" and "width"
options. 

It sounds like Word for OS-X makes whatever you're importing into a
bitmap, and does a bad job of it.  Starting with a non-vector format
at large resolution might make for some huge Word documents, but might
make the pictures prettier.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz


From matthew_wiener at merck.com  Thu Mar  6 19:50:03 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Thu, 06 Mar 2003 13:50:03 -0500
Subject: [R] Followup: copy-paste graphics from R to Word on Mac OS
 X
Message-ID: <AEBD81486231A343B1813FE62D33522501317731@usrymx15.merck.com>

I've found Word imports png pretty well.  David Brahm recently suggested
playing with the resolution and so on -- you could look it up in the mail
list archives -- but I've gotten acceptable results (on simple graphs) with
the defaults.

Hope this helps,

Matt Wiener
-----Original Message-----
From: Eric Fruits [mailto:fruits at portland.econw.com]
Sent: Thursday, March 06, 2003 1:09 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Followup: copy-paste graphics from R to Word on Mac OS X


After trying numerous options, I'm just about at my wits end.

The most frequent suggestion was to export to a postscript or PDF file 
and import that into Word.

However, no matter what I did or how I did it, the results were 
extraordinarily ugly and somewhat time-consuming.

What I've tried so far:

1.  Copy and paste from the R graphics output window into Word (in Mac 
OS X), this is the worst result.

2.  Use pdf() to create a pdf file, then import (Insert | Picture | 
 From File ...) into Word.  This generated the second-worst results.  
Note, that if I print the .pdf file without importing, the results are 
OK.

3.  Use pdf() to create a pdf file, use MacGSView to convert to .tiff, 
then import into Word.  This provided the third-worst results.  Note 
that the .tiff file is jaggy too.

4.  Use pdf() to create a pdf file, use the full-blown version of 
Acrobat to convert to .tiff, then import into Word.  This provided the 
best, but still ugly results.  Note that the .tiff file is jaggy too.

It is conceivable that this is a Mac OS X problem, but I'm not 
convinced considering how well it handles other graphics.

Any suggestions are appreciated.

Begin forwarded message:

> From: Eric Fruits <fruits at portland.econw.com>
> Date: Fri Feb 21, 2003  10:32:52  AM US/Pacific
> To: r-help at lists.R-project.org
> Subject: Copy-paste graphics from R to Word on Mac OS X
>
> Greetings:
>
> 	I'm (very) new  to R.
>
> 	One of the features of R that I really like is R's ability to
quickly 
> generate very good looking graphics.  However, I've noticed that when 
> I attempt to copy and paste the graphs from the R graphics output 
> window into Word (in Mac OS X), the resulting picture is very jaggy.
>
> 	I'm aware of the various options such as dev2bitmap, but I'd really 
> like to be able to do a quick copy and paste without switching among 
> various applications or creating extraneous files.
>
> 	Thanks.
>
> -- 
> Eric Fruits, Ph.D.
> Senior Economist & Project Manager
> ECONorthwest - Portland
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------


From p.dalgaard at biostat.ku.dk  Thu Mar  6 20:01:52 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 06 Mar 2003 20:01:52 +0100
Subject: [R] question about model formula
In-Reply-To: <874r6gpcqf.fsf@lumen.indyrad.iupui.edu>
References: <874r6gpcqf.fsf@lumen.indyrad.iupui.edu>
Message-ID: <x2of4o2uan.fsf@biostat.ku.dk>

mmiller3 at iupui.edu (Michael A. Miller) writes:

> Dear R Gang,
> 
> I'm interested in using R and the nls package for fitting kinetic
> models.  I'm having some difficulty getting a model specified for
> nls though.  The math for the model that I want to fit is
> 
>    dg(t)/dt = K1 f(t) - k2 g(t)
> 
> where g(t) and f(t) are measured data at a sequence of times t.
> K1 and k2 are the parameters of the model.  If I solve this, the
> solution is
> 
>   g(t) = K1 \int_0^t f(t') \exp(-k2(t-t')) dt'
> 
> and I'm not sure how to write a formula in R that I can pass to
> nls that will handle both the implicit loop over the data values
> of t and the interpolation and numeric integration over t'.
> 
> Can anyone help me to get this properly coded for R?

This stuff gets tricky. The way that you *want* to solve it is to feed
the differential equation into an automatic solver like lsoda or rk4
from the odesolve package, and then the result into nls. However, even
in dead simple cases, the adaptive stepsize of the integrators makes
the likelihood discontinuous enough to confuse the optimizer in nls.
The Nelder-Mead algorithm in optim() did actually converge on our
examples, but you'll need to get that wired into nls. I have a PhD
student planning to dig into just that shortly.

One trick that is known to work is to fix the integration scheme, this
may cost you in precision, but stability is much better because you use
the same time steps and the same interpolations throughout the fit.

However, you'll probably have to decide whether you can assume f to be
known, or whether the true f(t) should be considered a parameter of a
model with a bivariate response. Then it gets *really* tricky.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From dpowers at mail.la.utexas.edu  Thu Mar  6 20:14:17 2003
From: dpowers at mail.la.utexas.edu (Daniel A. Powers)
Date: Thu, 6 Mar 2003 13:14:17 -0600 (CST)
Subject: [R] Error in terms.default()  
Message-ID: <Pine.GSO.4.33.0303061310530.28109-100000@daphne.la.utexas.edu>


R-list --

I am working with some SPlus code and get the following error

Error in terms.default(formula, data = data) :
        no terms component

Can someone point me to a fix? The pasted formula looks ok
when printed during the procedure.

Thanks,
Dan

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Daniel A. Powers, Ph.D.
Associate Professor of Sociology
University of Texas at Austin
370 Burdine
Austin, TX  78712
phone: 512-232-6335
fax:   512-471-1748
dpowers at mail.la.utexas.edu


From martin.renner at stonebow.otago.ac.nz  Thu Mar  6 20:21:08 2003
From: martin.renner at stonebow.otago.ac.nz (Martin Renner)
Date: Thu, 6 Mar 2003 15:51:08 -0330
Subject: [R] Followup: copy-paste graphics from R to Word on Mac OS X
In-Reply-To: <A566ED6C-4FFE-11D7-B8F6-0003938E023E@portland.econw.com>
References: <A566ED6C-4FFE-11D7-B8F6-0003938E023E@portland.econw.com>
Message-ID: <p05200f02ba8d4c6bf0a1@[134.153.153.21]>

I had the same problem and came to this solution:

- use pdf() to create a pdf file
- open PDF in Freehand,
        during open replace fonts: ZapfDingsbat for Zapf Dingsbat
- save as PDF or EPS and import this into word - bingo

The pdf files created by pdf() seem less than perfect - on my system 
(Mac OS X) Illustrator refuses open these files and in Preview or 
Word any axis label disappear. Maybe someone here knows enough about 
the PDF format to suggest how to fix this rather complicated path.

Martin


From ripley at stats.ox.ac.uk  Thu Mar  6 20:37:51 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 6 Mar 2003 19:37:51 +0000 (GMT)
Subject: [R] Error in terms.default()  
In-Reply-To: <Pine.GSO.4.33.0303061310530.28109-100000@daphne.la.utexas.edu>
Message-ID: <Pine.LNX.4.44.0303061934340.3185-100000@gannet.stats>

R and S-PLUS handle terms very differently.

If this were a formula, terms would dispatch to term.formula, so
presumably it is not.  Do you need an as.formula() call?

On Thu, 6 Mar 2003, Daniel A. Powers wrote:

> I am working with some SPlus code and get the following error
> 
> Error in terms.default(formula, data = data) :
>         no terms component
> 
> Can someone point me to a fix? The pasted formula looks ok
> when printed during the procedure.

You need to read carefully how terms() works in R, from the help page and 
from examples in the sources.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ihaka at stat.auckland.ac.nz  Thu Mar  6 20:39:27 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Fri, 07 Mar 2003 08:39:27 +1300
Subject: [R] Error in terms.default()
References: <Pine.GSO.4.33.0303061310530.28109-100000@daphne.la.utexas.edu>
Message-ID: <3E67A3EF.3020204@stat.auckland.ac.nz>

Daniel A. Powers wrote:
> R-list --
> 
> I am working with some SPlus code and get the following error
> 
> Error in terms.default(formula, data = data) :
>         no terms component
> 
> Can someone point me to a fix? The pasted formula looks ok
> when printed during the procedure.

Without a more detailed description it's hard to say what's wrong.  It 
looks a little like the terms.default method has been called directly 
rather than via the generic terms function.  This is generally a bad idea.

-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand


From rolf at math.unb.ca  Thu Mar  6 20:42:51 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 6 Mar 2003 15:42:51 -0400 (AST)
Subject: [R] Suppressing row labels.
Message-ID: <200303061942.h26JgpC19908@gelfand.math.unb.ca>

Very often when I print a data frame (particularly when sink()-ing to
a file I do NOT want the row labels (which are in such cases usually
1, 2, ... nrow(x), where x is the data frame in question).  I can of
course edit these out ``by hand'', but that's a bit of a pain in the
pohutukawa.

I recently discovered (reading the help on print.data.frame
meticulously, and following it through to print.matrix) that
I CAN suppress these row names by executing, e.g.

	> print(x,rowlab=rep("",nrow(x)))

However it would be ever-so-slightly nicer (require somewhat fewer
key strokes) if there were an option to print.data.frame that would
allow suppression of row names.  E.g. an argument ``srn=FALSE''.
(Where ``srn'' stands for ``suppress row names''.)

I have written my own simple minded implementation of this option,
given below in case anyone else out there may have shared my
frustration at being unable to figure out how to suppress row names.

I would ask that the R developers consider including an argument like
unto this in a future release.

On a related note:  I would also like, generally speaking, NOT to
have row names included in LaTeX tables that I create from data
frames or matrices.  As far as I can discern, none of the currently
available LaTeX-ing functions provide the option of suppressing the
row names.  The functions I've looked at are:

	o xtable{xtable}
	o latex.table{quantreg}
	o latex{Hmisc}

It would be nice (said he wistfully) if the developers of at
least one of these packages would consider adding such an option.


					cheers,

						Rolf Turner

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
Code for my mild revision of print.data.frame:
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
print.data.frame <- function (x, ..., digits = NULL, quote = FALSE,
                              right = TRUE, srn=FALSE)
{
    if (length(x) == 0) {
        cat("NULL data frame with", length(row.names(x)), "rows\n")
    }
    else if (length(row.names(x)) == 0) {
        print.default(names(x), quote = FALSE)
        cat("<0 rows> (or 0-length row.names)\n")
    }
    else {
        if (!is.null(digits)) {
            op <- options(digits = digits)
            on.exit(options(op))
        }
        rowlab <- if(srn) rep("",nrow(x)) else row.names(x)
        print.matrix(format(x), rowlab=rowlab, ..., quote = quote,
                     right = right)
    }
    invisible(x)
}
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===


From Setzer.Woodrow at epamail.epa.gov  Thu Mar  6 20:45:14 2003
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Thu, 06 Mar 2003 14:45:14 -0500
Subject: [R] question about model formula
Message-ID: <OF9CC4DBF7.28968987-ON85256CE1.006B72B8@rtp.epa.gov>


I did not know about stepsize being an issue.  I had thought that
problems with convergence in this case were due to bad approximations of
the finite difference gradient.  I guessed that around the optimum,
numerical errors would come to dominate the gradient calculations,
causing convergence to fail.

I've found that the issue about confusing optimizers that use gradients
can sometimes be fixed by augmenting the original system of odes with
what I believe engineers call the sensitivity equations.  If your
original equation is
dg/dt = f(t, b), where b is a parameter to be estimated,
then include

d^2g/dtdb (be sure to remember the chain rule when doing this!)

with the original equation.  With some regularity assumptions, this
integrates to dg/db, which can be used to give nls a gradient to work
with.

R. Woodrow Setzer, Jr.                        Phone: (919) 541-0128
Experimental Toxicology Division             Fax:  (919) 541-4284
Pharmacokinetics Branch
NHEERL B143-05; US EPA; RTP, NC 27711


From lina at u.washington.edu  Thu Mar  6 20:53:54 2003
From: lina at u.washington.edu (Michael Na Li)
Date: Thu, 06 Mar 2003 11:53:54 -0800
Subject: [R] Use Rterm in rxvt for Cygwin?
In-Reply-To: <Pine.LNX.4.44.0303030755070.17885-100000@gannet.stats>
	(ripley@stats.ox.ac.uk's
	message of "Mon, 3 Mar 2003 08:05:40 +0000 (GMT)")
References: <Pine.LNX.4.44.0303030755070.17885-100000@gannet.stats>
Message-ID: <wmvfywfezx.fsf@qiuranke.phony.washington.edu>

On Mon, 3 Mar 2003, ripley at stats.ox.ac.uk outgrape:

>  Rterm is a Windows application.  It works fine in Windows tcsh and in 
>  Cygwin bash on Windows XP (and last time I looked, Windows 98 too).

Rterm doesn't work (interactively) in Cygwin bash on our machine (Windows 2000
SP 3, R 1.6.1).  (Not that I need that functionality). It gives error like,

,----
| The instruction at "0x7800270e" referenced memory at "0x0000000". The memory
| could not be read.
`----

Use Rterm for batch processing does work, however.

Michael


From ripley at stats.ox.ac.uk  Thu Mar  6 21:05:07 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 6 Mar 2003 20:05:07 +0000 (GMT)
Subject: [R] Followup: copy-paste graphics from R to Word on Mac OS X
In-Reply-To: <p05200f02ba8d4c6bf0a1@[134.153.153.21]>
Message-ID: <Pine.LNX.4.44.0303061955040.3242-100000@gannet.stats>

This is misinformation: the font name in the PDF specifications is
ZapfDingbats, and that is what the R driver uses, as in

<<
/Type /Font
/Subtype /Type1
/Name /F6
/BaseFont /ZapfDingbats
>>

I hope you have sent a suitable bug report to the supplier of your tools.x

On Thu, 6 Mar 2003, Martin Renner wrote:

> I had the same problem and came to this solution:
> 
> - use pdf() to create a pdf file
> - open PDF in Freehand,
>         during open replace fonts: ZapfDingsbat for Zapf Dingsbat
> - save as PDF or EPS and import this into word - bingo
> 
> The pdf files created by pdf() seem less than perfect - on my system 
> (Mac OS X) Illustrator refuses open these files and in Preview or 
> Word any axis label disappear. Maybe someone here knows enough about 
> the PDF format to suggest how to fix this rather complicated path.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Thu Mar  6 21:56:13 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 6 Mar 2003 14:56:13 -0600
Subject: [R] Use Rterm in rxvt for Cygwin?
In-Reply-To: <wmvfywfezx.fsf@qiuranke.phony.washington.edu>
References: <Pine.LNX.4.44.0303030755070.17885-100000@gannet.stats>
	<wmvfywfezx.fsf@qiuranke.phony.washington.edu>
Message-ID: <20030306205613.GA7382@sonny.eddelbuettel.com>

On Thu, Mar 06, 2003 at 11:53:54AM -0800, Michael Na Li wrote:
> On Mon, 3 Mar 2003, ripley at stats.ox.ac.uk outgrape:
> 
> >  Rterm is a Windows application.  It works fine in Windows tcsh and in 
> >  Cygwin bash on Windows XP (and last time I looked, Windows 98 too).
> 
> Rterm doesn't work (interactively) in Cygwin bash on our machine (Windows 2000
> SP 3, R 1.6.1).  (Not that I need that functionality). It gives error like,
> 
> ,----
> | The instruction at "0x7800270e" referenced memory at "0x0000000". The memory
> | could not be read.
> `----

But under NT4SP6 it also prints

	~> Rterm
	Fatal error: you must specify --save', --no-save' or --vanilla'

and following that hint works, i.e. 'Rterm --no-save'.

> Use Rterm for batch processing does work, however.

And most importantly 'Rterm --slave' works for ESS :)

Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr


From fharrell at virginia.edu  Thu Mar  6 22:11:20 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 6 Mar 2003 16:11:20 -0500
Subject: [R] Proper way to document print( ) functions
Message-ID: <20030306161120.303b153d.fharrell@virginia.edu>

Frequently we have a print method, say print.myclass, that has a variety of arguments.  If in the .Rd file I say

\usage{
\method{print}{myclass}(x, myarg)
}

I get a warning when running R CMD chk:

* checking generic/method consistency ... WARNING
print:
  function(x, ...)
print.myclass:
  function(x, myarg)

What is the proper way to handle this?

Thanks
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From cliff at ms.washington.edu  Thu Mar  6 22:26:06 2003
From: cliff at ms.washington.edu (Cliff Lunneborg)
Date: Thu, 6 Mar 2003 13:26:06 -0800
Subject: [R] Resizing R console window (was BSOD with ESS[R]...)
Message-ID: <001601c2e426$ffe086b0$95abd00c@C56909A>

Simon Gatehouse writes:


" Like many, I fiddle while thinking.  Part of my fiddling has been to
rapidly
resize the R console window back and forth by dragging with the mouse on
the
bottom right hand corner. I resize the window by a small amount rapidly
and
continually . After about 5 seconds of such movement R crashes with the
pop
up "Rgui.exe has generated errors..."  This has happened ever since 1.3,
I
think. It is unrelated to any other programs I may be running at the
time.

I currently run W2000 and latest R1.6.2. The 1.7.0 development version
has
same behaviour."


Here I am running R 1.6.2 (binary distribution) under W2000 and have
noticed the same behavior. After resizing the window I commonly cannot
return control to the R console and have to shut down R.

**********************************************************
Cliff Lunneborg, Professor Emeritus, Statistics &
Psychology, University of Washington, Seattle
cliff at ms.washington.edu


From ripley at stats.ox.ac.uk  Thu Mar  6 22:32:24 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 6 Mar 2003 21:32:24 +0000 (GMT)
Subject: [R] Use Rterm in rxvt for Cygwin?
In-Reply-To: <20030306205613.GA7382@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.44.0303062107310.3358-100000@gannet.stats>

On Thu, 6 Mar 2003, Dirk Eddelbuettel wrote:

> On Thu, Mar 06, 2003 at 11:53:54AM -0800, Michael Na Li wrote:
> > On Mon, 3 Mar 2003, ripley at stats.ox.ac.uk outgrape:
> > 
> > >  Rterm is a Windows application.  It works fine in Windows tcsh and in 
> > >  Cygwin bash on Windows XP (and last time I looked, Windows 98 too).
> > 
> > Rterm doesn't work (interactively) in Cygwin bash on our machine (Windows 2000
> > SP 3, R 1.6.1).  (Not that I need that functionality). It gives error like,
> > 
> > ,----
> > | The instruction at "0x7800270e" referenced memory at "0x0000000". The memory
> > | could not be read.
> > `----

I think you will find that is in msvcrt.dll, in which case it is not Rterm 
but a low-level OS interface.

> But under NT4SP6 it also prints
> 
> 	~> Rterm
> 	Fatal error: you must specify --save', --no-save' or --vanilla'
> 
> and following that hint works, i.e. 'Rterm --no-save'.

Looks like your versions of bash are not providing proper ttys to
msvcrt.dll since isatty(0) must be false to get that message.

Given that Rterm works (interactively with full command-line editing)

  in a Windows terminal on those OSes
  in bash on XP
  in tcsh on NT4, 2000 and XP

it points to Cygwin bash as the culprit.

> > Use Rterm for batch processing does work, however.
> 
> And most importantly 'Rterm --slave' works for ESS :)

It is intended that Rterm --ess be used with ESS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar  6 22:41:29 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 6 Mar 2003 21:41:29 +0000 (GMT)
Subject: [R] Proper way to document print( ) functions
In-Reply-To: <20030306161120.303b153d.fharrell@virginia.edu>
Message-ID: <Pine.LNX.4.44.0303062135060.3358-100000@gannet.stats>

The simplest way is to define the method correctly, as print.myclass(x,
myarg, ...).  That message is about the code, not the documentation, but
you will get a different one if the code and documentation disagree.

All print methods must include `...', and there is a section in `Writing R
Extensions' on why.  In brief, I should be able to define class
`richerclass' inheriting from `myclass' and have a print method for
`richerclass' with different arguments that calls NextMethod("print").

BTW this applies equally to S-PLUS.

On Thu, 6 Mar 2003, Frank E Harrell Jr wrote:

> Frequently we have a print method, say print.myclass, that has a variety of arguments.  If in the .Rd file I say
> 
> \usage{
> \method{print}{myclass}(x, myarg)
> }
> 
> I get a warning when running R CMD chk:
> 
> * checking generic/method consistency ... WARNING
> print:
>   function(x, ...)
> print.myclass:
>   function(x, myarg)
> 
> What is the proper way to handle this?
> 
> Thanks
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Thu Mar  6 23:16:25 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 06 Mar 2003 23:16:25 +0100
Subject: [R] question about model formula
In-Reply-To: <OF9CC4DBF7.28968987-ON85256CE1.006B72B8@rtp.epa.gov>
References: <OF9CC4DBF7.28968987-ON85256CE1.006B72B8@rtp.epa.gov>
Message-ID: <x2isuw2lae.fsf@biostat.ku.dk>

Setzer.Woodrow at epamail.epa.gov writes:

> I did not know about stepsize being an issue.  I had thought that
> problems with convergence in this case were due to bad approximations of
> the finite difference gradient.  I guessed that around the optimum,
> numerical errors would come to dominate the gradient calculations,
> causing convergence to fail.

In the case we looked at, it was quite obvious. nls simply ground
to a halt quite far from the optimum and plotting the SSD as a
function of the parameters showed a nice overall parabola, but with
points of discontinuity. It was without supplying gradients though,
and as you point out, that probably improves the behaviour, at least
until the "endgame" where you might find that the gradient is not zero
at the optimum and vice versa.

> I've found that the issue about confusing optimizers that use gradients
> can sometimes be fixed by augmenting the original system of odes with
> what I believe engineers call the sensitivity equations.  If your
> original equation is
> dg/dt = f(t, b), where b is a parameter to be estimated,
> then include
> 
> d^2g/dtdb (be sure to remember the chain rule when doing this!)
> 
> with the original equation.  With some regularity assumptions, this
> integrates to dg/db, which can be used to give nls a gradient to work
> with.

Yep, I know the implicit differentiation trick - even got an old paper in
Biometrics using essentially that in a PDE setting. We should probably
try it with our odesolve example (and in general there were a lot of
potential tuning knobs that we didn't touch).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From gregory_r_warnes at groton.pfizer.com  Thu Mar  6 23:21:37 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Thu, 6 Mar 2003 17:21:37 -0500 
Subject: [R] Initial release of RSessionDA
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C696@groexmb02.pfizer.com>


> Announcing the initial release of RSessionDA.
> 
> RSessionDA provides objects for interacting with R from Zope
> <www.zope.org>, a full-featured web application development system.  These
> objects permit evaluation of functions in the R language using information
> in Zope.  R data objects, graphics files, printed output, script
> transcripts, and data files can be returned to Zope for display. These
> tools make it easy to create web applications that include advanced
> statistical functionality.
> 
> RSessionDA is built on RSOAP package, which provides access to R via the
> SOAP <http://www.w3.org/TR/SOAP/"> communications protocol.  This allows
> Zope to access multiple independent R sessions running (if desired) on a
> separate compute server.
> 
> For more information on or to download RSessionDA see:
> 
> <http://software.biostat.washington.edu/statsoft/snake/RSessionDA> or
> <http://www.zope.org/Members/warnes/RSessionDA/> 
> 
> For more information on or to download RSOAP see:
> 
> <http://software.biostat.washington.edu/statsoft/snake/RSOAP> or 
> 
> For more information on Zope see:
> 
> <http://www.zope.org>
> 
> -Greg


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... [[dropped]]


From miken at bigpond.net.au  Thu Mar  6 23:23:58 2003
From: miken at bigpond.net.au (Mike Nielsen)
Date: 07 Mar 2003 09:23:58 +1100
Subject: [R] Mixed up threads
Message-ID: <1046989438.22731.60.camel@mudshark.poodle.dog>

>From Martin Maechler:
<quote>
PS: Please guys, stop doing the following:
    1. You want to post something to R-help.  
    2. You are too lazy to type r-help at r-project.org [the
        shortest of several possible addresses] 
    3. you reply to another __unrelated__ posting to R-help instead.

==> all threads are mixed up !
    -- both on the mailing list archives, and on anyone's e-mail
    list who uses threaded e-mail presentation  (e.g. me.)
</quote>

The enormous value of the mailing list archives is eroded by missing,
poorly worded or downright wrong subject fields.  A proper caption is an
important part of articulating your problem. A poorly articulated query
sends a signal to those generous souls who may reply -- it says, amongst
other things, "I'm unlikely to have looked at the documentation."  Not a
good start, especially on this list.

Regards,

Mike
-- 
Mike Nielsen <miken at bigpond.net.au>


From r.hankin at auckland.ac.nz  Thu Mar  6 23:26:25 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Fri, 7 Mar 2003 11:26:25 +1300
Subject: [R] multiple plots and postscript()
Message-ID: <200303062226.h26MQPof015927@r.hankin.sges.auckland.ac.nz>

Kia Ora everybody.

There must be an obvious answer to this, but I can't see it....

I want four square plots in one postscript file.  The canonical answer
would be:

postscript(file="~/f.ps",width=5,height=5)
par(pty="s",mfrow=c(2,2))
plot(1:19,xlab="")
plot(1:19,xlab="")
plot(1:19,xlab="")
plot(1:19,xlab="")
dev.off()

But this isn't quite what I want because there is too much space
between the individual plots.  The problem does not occur in quite the
same way on the X11() device (why is there a difference?)

What is the best way to control this aspect of the plot if I want
postscript output?







-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042


From ripley at stats.ox.ac.uk  Thu Mar  6 23:45:11 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 6 Mar 2003 22:45:11 +0000 (GMT)
Subject: [R] multiple plots and postscript()
In-Reply-To: <200303062226.h26MQPof015927@r.hankin.sges.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0303062240550.9331-100000@gannet.stats>

On Fri, 7 Mar 2003, Robin Hankin wrote:

> Kia Ora everybody.
> 
> There must be an obvious answer to this, but I can't see it....
> 
> I want four square plots in one postscript file.  The canonical answer
> would be:
> 
> postscript(file="~/f.ps",width=5,height=5)
> par(pty="s",mfrow=c(2,2))
> plot(1:19,xlab="")
> plot(1:19,xlab="")
> plot(1:19,xlab="")
> plot(1:19,xlab="")
> dev.off()
> 
> But this isn't quite what I want because there is too much space
> between the individual plots.  The problem does not occur in quite the
> same way on the X11() device (why is there a difference?)

Font size.  For 4 plots on 5" x 5" (or even for 1) you want to reduce the 
pointsize, which is designed for A4 paper.

> What is the best way to control this aspect of the plot if I want
> postscript output?

More generally, par(mar)/par(mai).  Note that this defaults to rows, and 
hence gives marginal space proportional to the pointsize.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From chong at stat.purdue.edu  Thu Mar  6 23:56:29 2003
From: chong at stat.purdue.edu (Chong Gu)
Date: Thu, 06 Mar 2003 17:56:29 -0500
Subject: [R] multiple plots and postscript() 
In-Reply-To: Your message of "Fri, 07 Mar 2003 11:26:25 +1300."
             <200303062226.h26MQPof015927@r.hankin.sges.auckland.ac.nz> 
Message-ID: <200303062256.h26MuUFE052492@odds.stat.purdue.edu>


You may try something like this:

postscript(file="fig.ps",height=4,width=4)
layout(matrix(c(0,1,2,0,3,4),2,3,byrow=TRUE),c(0,1,1),c(1,1))
par(mar=c(5,5,2,2)+.1,mex=.6)

The default spacings are different for 2x3 and 2x2.  The layout
facility allows one to cheat it out.

Good luck.

Chong Gu


> Kia Ora everybody.
> 
> There must be an obvious answer to this, but I can't see it....
> 
> I want four square plots in one postscript file.  The canonical answer
> would be:
> 
> postscript(file="~/f.ps",width=5,height=5)
> par(pty="s",mfrow=c(2,2))
> plot(1:19,xlab="")
> plot(1:19,xlab="")
> plot(1:19,xlab="")
> plot(1:19,xlab="")
> dev.off()
> 
> But this isn't quite what I want because there is too much space
> between the individual plots.  The problem does not occur in quite the
> same way on the X11() device (why is there a difference?)
> 
> What is the best way to control this aspect of the plot if I want
> postscript output?
> 
> 
> 
> 
> 
> 
> 
> -- 
> 
> Robin Hankin, Lecturer,
> School of Geography and Environmental Science
> Tamaki Campus
> Private Bag 92019 Auckland
> New Zealand
> 
> r.hankin at auckland.ac.nz
> tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From sfalcon at fhcrc.org  Fri Mar  7 00:18:41 2003
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 6 Mar 2003 15:18:41 -0800
Subject: [R] Followup: copy-paste graphics from R to Word on Mac OS X
In-Reply-To: <A566ED6C-4FFE-11D7-B8F6-0003938E023E@portland.econw.com>
References: <A566ED6C-4FFE-11D7-B8F6-0003938E023E@portland.econw.com>
Message-ID: <20030306231841.GF12438@queenbee.fhcrc.org>

I've encountered some of the same issues with jaggy graphics.  Here
is what I have found to work pretty well:

Short and sweet:

Use the bitmap() function with res=200 to create png files.

Some explaination:

As far as I can tell, png(), jpg(), and friends do not allow you to
set the resolution.  However, you can set the resolution using
bitmap().  I've had good results with res=200.

The tricky part about using bitmap() is that it relies on having
GhostScript installed and may require you to set an environment
variable (Will this have any chance of working on a Mac?)

On my Windows 2000 system, I have

        R_GSCMD = c:\gs\gs8.00\bin\gswin32c.exe

I can then create a png image that looks decent like this:

fname <- "sineWave.png"
x <- seq(0,6.5, .1)
y <- sin(x)

bitmap(file=fname, type="png256", width=4, height=4, res=200)
dev.off()

Final note:
If you want to automate plot creation, you may need to utilize the
Sys.sleep() function.  If you call a script like this:

        rterm --slave --no-save --no-restore < autoPNGplot.r

then R may complete before GhostScript gets a chance to start and
GhostScript will crash because it can't find the files it was told
to process.  Sleeping for a few seconds seems to take care of this.
You can test this yourself by trying to run the above sine wave
script redirected into rterm.  For me it crashes unless I add
Sys.sleep(2) at the end.

Hope these notes are somewhat helpful.

+ seth


From josef.frank at gmx.ch  Fri Mar  7 00:14:22 2003
From: josef.frank at gmx.ch (Josef Frank)
Date: Fri, 7 Mar 2003 00:14:22 +0100
Subject: [R] type III Sum Sq in ANOVA table - Howto?
Message-ID: <20030307001422.A192@lao-tzu.tao.de>

Hello,

as far as I see, R reports type I sums of squares. I'd like to get R to
print out type III sums of squares. 

e.g. I have the following model:
vardep~factor1*factor2

to get the type III sum of squares for factor1 I've tried
anova(lm(vardep~factor2+factor1:factor2),lm(vardep~factor1*factor2))
but that didn't yield the desired result.

Could anyone give me a hint how to proceed?

thanks in advance
Josef


From richard.kerr at mmigenomics.com  Fri Mar  7 00:47:58 2003
From: richard.kerr at mmigenomics.com (Kerr, Richard)
Date: Thu, 6 Mar 2003 15:47:58 -0800
Subject: [R] compiling R on sparc-solaris
Message-ID: <B26C735994B48F4DBF5466E72120E490390C55@dav-gen-exch.genomics.mmi.ad>

Hello,

I am trying to compile the R package on a sun.
I get the error message

rbitmap.c: In function 'my_png_error':
rbitmap.c:73: structure has no member named 'jmpbuf'
rbitmap.c: In function 'R_SaveAsPng':
rbitmap.c:122: structure has no member named 'jmpbuf'
make[4]:*** [rbitmap.lo] Error 1

Has anyone encountered this problem? Any solutions? Is there are compiled binary somewhere that I could use?

Grateful for any help.

Richard


Richard Kerr, Quantitative Geneticist
MMI Genomics
Davis, CA 95616
richard.kerr at mmigenomics.com
(desk) 530-297-2938


From andy_liaw at merck.com  Fri Mar  7 00:49:41 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 06 Mar 2003 18:49:41 -0500
Subject: [R] type III Sum Sq in ANOVA table - Howto?
Message-ID: <3A822319EB35174CA3714066D590DCD534BDB4@usrymx25.merck.com>

The short answer: use drop1().

The long(er) answer: think harder about what question(s) you want answered
(i.e., what hypotheses you really want to test, and test only those).  The
model hierarchy says that a model should not have an interaction term
involving a factor whose main effect is not present in the model.  Seen in
this light, the hypothesis you're trying to test involves a non-sensical
model.

Andy

> -----Original Message-----
> From: Josef Frank [mailto:josef.frank at gmx.ch]
> Sent: Thursday, March 06, 2003 6:14 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] type III Sum Sq in ANOVA table - Howto?
> 
> 
> Hello,
> 
> as far as I see, R reports type I sums of squares. I'd like 
> to get R to
> print out type III sums of squares. 
> 
> e.g. I have the following model:
> vardep~factor1*factor2
> 
> to get the type III sum of squares for factor1 I've tried
> anova(lm(vardep~factor2+factor1:factor2),lm(vardep~factor1*factor2))
> but that didn't yield the desired result.
> 
> Could anyone give me a hint how to proceed?
> 
> thanks in advance
> Josef
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From rolf at math.unb.ca  Fri Mar  7 01:31:37 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 6 Mar 2003 20:31:37 -0400 (AST)
Subject: [R] type III Sum Sq in ANOVA table - Howto?
Message-ID: <200303070031.h270Vb224953@gelfand.math.unb.ca>


Andy Liaw wrote:

>  The long(er) answer: think harder about what question(s) you want answered
>  (i.e., what hypotheses you really want to test, and test only those).  The
>  model hierarchy says that a model should not have an interaction term
>  involving a factor whose main effect is not present in the model.  Seen in
>  this light, the hypothesis you're trying to test involves a non-sensical
>  model.

Not really.  The hypothesis being tested by Type III sums of square
may be suspected of not being of ``central interest'', but it is NOT
(as is commonly believed) ``non-sensical''.

Let us think about the 2-way ANOVA case, where one can actually
understand what is going on.  Let the population ***cell means*** be
mu_ij (i = 1, ..., m, j = 1, ..., n) and forget about the confusing
and misleading over-parameterized model.

Testing for the significance of the ``row factor'' by Type III
sums of squares (with interaction in the model of course) tests

	H_0: mu_{1.}-bar = mu_{2.}-bar = ... = mu_{m.}-bar

I.e. that the means of the population cell means, over columns, are
all equal.  I.e. that ``when rows are averaged over columns'' there
is no row effect.

This could, at least conceiveably, be of interest.  Note that the
average is not a weighted average, saying that all columns are
equally important.  If all columns are NOT equally important (e.g.
if an item randomly drawn from the population is more likely to
``come from'' column 1 than from column 2 etc.) then this hypothesis
is less likely to be of interest.

But it isn't nonsensical.

It is true, however, that most of the time when people test things
using Type III sums of squares they don't understand what they are
really testing.  But then (said he cynically) people don't understand
what the hell they are really testing in most situations, not just
in the context of Type III sums of squares.

				cheers,

					Rolf Turner


From jerrytheshrub at hotmail.com  Fri Mar  7 01:36:22 2003
From: jerrytheshrub at hotmail.com (Jeremy Z Butler)
Date: Fri, 07 Mar 2003 13:36:22 +1300
Subject: [R] column name changes based on substrings
Message-ID: <F65yFhGVzxb8AH96IAa00006268@hotmail.com>

Hi peoples,

I'm trying to work out a function which will allow me to relace column names 
on the basis of substrings within the existing names. e.g.

I'd like:

   blah.Na  blah2.Na  blah3.Mg  blah4.Mg  blah5.K  blah6.K
R1       x         x         x         x        x        x
R2       x         x         x         x        x        x
...

to become:

    Na (%)    Na (%)    Mg (%)    Mg (%)  K (ppm)  K (ppm)
R1       x         x         x         x        x        x
R2       x         x         x         x        x        x
...

So based on whether the existing column name has a .Na or a .K etc. in it 
somewhere, I'd like it to be replaced with a name which I can provide i.e. 
Na (%) or K (%).

So far I can't even figure out how to replace a column name:

>aa[colnames(aa)=="blah3.Mg"]_colnames("Mg (%)")
Error in matrix(value, n, p) : No data to replace in matrix(...)

help please
Cheers Jeremy


From andy_liaw at merck.com  Fri Mar  7 02:08:23 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 06 Mar 2003 20:08:23 -0500
Subject: [R] type III Sum Sq in ANOVA table - Howto?
Message-ID: <3A822319EB35174CA3714066D590DCD534BDB5@usrymx25.merck.com>

> From: Rolf Turner [mailto:rolf at math.unb.ca]
> 
> Andy Liaw wrote:
> 
> >  The long(er) answer: think harder about what question(s) 
> you want answered
> >  (i.e., what hypotheses you really want to test, and test 
> only those).  The
> >  model hierarchy says that a model should not have an 
> interaction term
> >  involving a factor whose main effect is not present in the 
> model.  Seen in
> >  this light, the hypothesis you're trying to test involves 
> a non-sensical
> >  model.
> 
> Not really.  The hypothesis being tested by Type III sums of square
> may be suspected of not being of ``central interest'', but it is NOT
> (as is commonly believed) ``non-sensical''.
> 
> Let us think about the 2-way ANOVA case, where one can actually
> understand what is going on.  Let the population ***cell means*** be
> mu_ij (i = 1, ..., m, j = 1, ..., n) and forget about the confusing
> and misleading over-parameterized model.
> 
> Testing for the significance of the ``row factor'' by Type III
> sums of squares (with interaction in the model of course) tests
> 
> 	H_0: mu_{1.}-bar = mu_{2.}-bar = ... = mu_{m.}-bar
> 
> I.e. that the means of the population cell means, over columns, are
> all equal.  I.e. that ``when rows are averaged over columns'' there
> is no row effect.
> 
> This could, at least conceiveably, be of interest.  Note that the
> average is not a weighted average, saying that all columns are
> equally important.  If all columns are NOT equally important (e.g.
> if an item randomly drawn from the population is more likely to
> ``come from'' column 1 than from column 2 etc.) then this hypothesis
> is less likely to be of interest.
> 
> But it isn't nonsensical.
> 
> It is true, however, that most of the time when people test things
> using Type III sums of squares they don't understand what they are
> really testing.  But then (said he cynically) people don't understand
> what the hell they are really testing in most situations, not just
> in the context of Type III sums of squares.
> 
> 				cheers,
> 
> 					Rolf Turner

I'm sorry, but I still don't see sense of this argument.  By including the
interaction term in the model, isn't it implied that the cells have
different means, and the structure isn't a simple row + column?  Assuming
that being the case, what's the sense of "averaging" over columns (or rows)?
I can perhaps understand the utility of such "test" in an exploratory
setting, but fail to see how this can be valid test in a more rigorous
sense.  Maybe I'm stuck too deep in the rut...

Cheers,
Andy


------------------------------------------------------------------------------


From tlumley at u.washington.edu  Fri Mar  7 02:33:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 6 Mar 2003 17:33:03 -0800 (PST)
Subject: [R] type III Sum Sq in ANOVA table - Howto?
In-Reply-To: <20030307001422.A192@lao-tzu.tao.de>
Message-ID: <Pine.A41.4.44.0303061729220.52700-100000@homer32.u.washington.edu>

On Fri, 7 Mar 2003, Josef Frank wrote:

> Hello,
>
> as far as I see, R reports type I sums of squares. I'd like to get R to
> print out type III sums of squares.
>
> e.g. I have the following model:
> vardep~factor1*factor2
>
> to get the type III sum of squares for factor1 I've tried
> anova(lm(vardep~factor2+factor1:factor2),lm(vardep~factor1*factor2))
> but that didn't yield the desired result.
>
> Could anyone give me a hint how to proceed?
>

Unfortunately the arguments about whether Type III sums of squares are
part of the axis of evil have drowned out a real issue.

I would have expected the command to work, and in fact wrote a FAQ answer
saying this was the way to do it.  However, if factor1 is indeed a factor
its main effect is helpfully stuck back in the model by terms.formula.

I think this is a bug, since it doesn't happen if factor1 isn't a factor,
and leaving aside any question about Type III SS it seems to make it
impossible to fit the model
   lm(vardep~factor2+factor1:factor2)
While this model isn't terribly often useful, it is sometimes.


	-thomas


From jfox at mcmaster.ca  Fri Mar  7 03:38:58 2003
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 06 Mar 2003 21:38:58 -0500
Subject: [R] type III Sum Sq in ANOVA table - Howto?
In-Reply-To: <Pine.A41.4.44.0303061729220.52700-100000@homer32.u.washing
 ton.edu>
References: <20030307001422.A192@lao-tzu.tao.de>
Message-ID: <5.1.0.14.2.20030306213551.01e187f8@mcmail.cis.mcmaster.ca>

Dear Thomas et al.,

At 05:33 PM 3/6/2003 -0800, Thomas Lumley wrote:
>On Fri, 7 Mar 2003, Josef Frank wrote:
>
> > Hello,
> >
> > as far as I see, R reports type I sums of squares. I'd like to get R to
> > print out type III sums of squares.
> >
> > e.g. I have the following model:
> > vardep~factor1*factor2
> >
> > to get the type III sum of squares for factor1 I've tried
> > anova(lm(vardep~factor2+factor1:factor2),lm(vardep~factor1*factor2))
> > but that didn't yield the desired result.
> >
> > Could anyone give me a hint how to proceed?
> >
>
>Unfortunately the arguments about whether Type III sums of squares are
>part of the axis of evil have drowned out a real issue.
>
>I would have expected the command to work, and in fact wrote a FAQ answer
>saying this was the way to do it.  However, if factor1 is indeed a factor
>its main effect is helpfully stuck back in the model by terms.formula.
>
>I think this is a bug, since it doesn't happen if factor1 isn't a factor,
>and leaving aside any question about Type III SS it seems to make it
>impossible to fit the model
>    lm(vardep~factor2+factor1:factor2)
>While this model isn't terribly often useful, it is sometimes.

The description of model formulas in Ch. 2 of Statistical Models in S 
explains why ~factor2+factor1:factor2 is treated as it is.

Assuming that one really wants to test a "Type-III" hypothesis, the Anova 
function in the car package will do it (and "Type-II" tests as well).

Regards,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From ncroglio at iname.com  Fri Mar  7 00:41:11 2003
From: ncroglio at iname.com (Nicholas Croglio)
Date: Thu, 06 Mar 2003 18:41:11 -0500
Subject: [R] Preferred C++ compiler under Windows 2000
Message-ID: <20030306234111.89386.qmail@iname.com>

Greetings,

I know that most people on here are strong advocates of Unix or a similar OS, but I am interested in calling C++ or using C++ to call R.  What is the preferred or the compiler that works the best.  In the documentation it appears that VC++ is recommended, but in some posts I have seen statements that claim VC++ is not recommended.  I have a DEV C++ IDE, but I would like to borrow from the experience of others if possible.

Thanks,
Nicholas Croglio
--


From ncroglio at iname.com  Fri Mar  7 00:44:34 2003
From: ncroglio at iname.com (Nicholas Croglio)
Date: Thu, 06 Mar 2003 18:44:34 -0500
Subject: [R] Calling R program from an IDE
Message-ID: <20030306234434.92971.qmail@iname.com>

Greetings,

There are several editors that can call command prompts or have conficuration tools.  While learning these, I have noticed that I do not know how to execute an R program from the command line external to the R interactive environment.  It is very clearly stated for Unix type systems, but I do not see the equivalent documentation for Windows.  Please send me the link to this information.

Thanks,
Nicholas Croglio
--


From arc at arcriswell.com  Fri Mar  7 05:24:22 2003
From: arc at arcriswell.com (Andrew Criswell)
Date: Fri, 7 Mar 2003 11:24:22 +0700
Subject: [R] Exact logistic regression
Message-ID: <001f01c2e461$7168f620$758092cb@andrewhdh0e5oe>

Hello:

Is there a function that will do exact logistic regressions along the
line of LogXact?

Thanks,
ANDREW


From s2112930 at student.rmit.edu.au  Fri Mar  7 06:00:37 2003
From: s2112930 at student.rmit.edu.au (Skanda Kallur; MEngg)
Date: Fri, 07 Mar 2003 16:00:37 +1100
Subject: [R] 
Message-ID: <1047013237.d75d18a0s2112930@student.rmit.edu.au>

Hello,

I am trying to use 'R' for K-means simulatio, could you please advise me how I can read my data into a two dimesional array? Or is there any method which directly reads the excell file? Please let me know asap.

Regards

Skanda Kallur





Cogito, Ergo Sum! Rene Descartes


From s195404 at student.uq.edu.au  Fri Mar  7 07:11:19 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri,  7 Mar 2003 06:11:19 +0000
Subject: [R]
In-Reply-To: <1047013237.d75d18a0s2112930@student.rmit.edu.au>
References: <1047013237.d75d18a0s2112930@student.rmit.edu.au>
Message-ID: <1047017479.3e6838078c4db@my.uq.edu.au>

A common approach for getting data into R from Excel is to
save the spreadsheet as a CSV file and then read it into R
using read.csv. CRAN contains references to other means of
directly linking Excel and R. You may find the CSV approach
good enough. 


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting "Skanda Kallur; MEngg" <s2112930 at student.rmit.edu.au>:

> Hello,
> 
> I am trying to use 'R' for K-means simulatio, could you please advise me how
> I can read my data into a two dimesional array? Or is there any method which
> directly reads the excell file? Please let me know asap.
> 
> Regards
> 
> Skanda Kallur
> 
> 
> 
> 
> 
> Cogito, Ergo Sum! Rene Descartes
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From jlvw at rau.ac.za  Fri Mar  7 08:21:56 2003
From: jlvw at rau.ac.za (Jacob van Wyk)
Date: Fri, 07 Mar 2003 09:21:56 +0200
Subject: [R] Boot
Message-ID: <se6864b9.088@rauzen.rau.ac.za>

Hallo
Could anybody please help.
I have a simple linear regression model with 5 predictors. I want to
use "bootstrap residuals" to make inferences regarding beta(2)hat. After
fitting the model y=b0+b1+b2+b3+b4+b5 I tried the following:

mod <- lm(y ~ x1+x2+x3+x4+x5)
res <- resid(mod)
pred <- predict(mod)

Now, I have tried

boot(res, lm(res+pred ~ x1+x2+x3+x4+x5)$coef[3], R=1999)

The problem is with the "statistic". How should I "define" this?

Thanks for your time.
Jacob



Jacob L van Wyk
Department of Mathematics and Statistics
Rand Afrikaans University
P O Box 524
Auckland Park 2006
South Africa
Tel: +27-11-489-3080
Fax: +27-11-489-2832


______________________________________

VRYWARING\ \ Die inhoud en enige aanhegsels van hierdie elektron... [[dropped]]


From vito.muggeo at giustizia.it  Fri Mar  7 08:28:15 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Fri, 7 Mar 2003 08:28:15 +0100
Subject: [R] Exact logistic regression
References: <001f01c2e461$7168f620$758092cb@andrewhdh0e5oe>
Message-ID: <002901c2e47b$22ffe060$5c13070a@it.giustizia.it>

> Hello:
>
> Is there a function that will do exact logistic regressions along the
> line of LogXact?
>

No, as far as I know, there is no package to perform exact logistic
regression (namely calculate the complete permutational distribution of the
statistics of interest conditional on the ancillary statistics of the
nuisance parameters).
An alternative approach could be to perform "high order asymptotics", i.e.
saddlepoint approximation. There is a S-Plus library by Alessandra Brazzale
that does the work. Unfortunately I don't remember her URL. However note
that if the ML estimates do not exist, even the saddlepoint approximation
doesn't work.

best,
vito

> Thanks,
> ANDREW
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From p.dalgaard at biostat.ku.dk  Fri Mar  7 08:39:01 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 07 Mar 2003 08:39:01 +0100
Subject: [R] type III Sum Sq in ANOVA table - Howto?
In-Reply-To: <Pine.A41.4.44.0303061729220.52700-100000@homer32.u.washington.edu>
References: <Pine.A41.4.44.0303061729220.52700-100000@homer32.u.washington.edu>
Message-ID: <x21y1j39t6.fsf@biostat.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

> I think this is a bug, since it doesn't happen if factor1 isn't a factor,
> and leaving aside any question about Type III SS it seems to make it
> impossible to fit the model
>    lm(vardep~factor2+factor1:factor2)
> While this model isn't terribly often useful, it is sometimes.

Hmm... no ... and yes. There are some useful models, but you cannot
specify them unambiguously with model formulas. At least to my way of
thinking, the only useful way of thinking of interaction terms is that
f1:f2 describes an arbitrary pattern of means in the f1 x f2
crosstable, and the rest is just R/S being helpful in removing known
aliased effects. So f1 + f2 + f1:f2 is the same model as f2 + f1:f2 is
the same as f1:f2.

If you try to make any other sense of f2 + f1:f2  you get into
parametrization dependent models. The absense of f1 in the model could
mean no average effect of f1 or no effect of f1 at the first level of
f2 corresponding to "sum" or "treatment" contrasts. The former model
is basically what a usual Type III test would do and as several have
pointed out, the interpretation is tenuous at best. The latter model,
I agree is useful sometimes ("no difference at baseline" is a viable
hypothesis in randomised trials, e.g.) but you need to work harder to
specify it. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From ligges at statistik.uni-dortmund.de  Fri Mar  7 08:45:19 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 07 Mar 2003 08:45:19 +0100
Subject: [R] compiling R on sparc-solaris
In-Reply-To: <B26C735994B48F4DBF5466E72120E490390C55@dav-gen-exch.genomics.mmi.ad>
References: <B26C735994B48F4DBF5466E72120E490390C55@dav-gen-exch.genomics.mmi.ad>
Message-ID: <3E684E0F.2050004@statistik.uni-dortmund.de>

Kerr, Richard wrote:
> Hello,
> 
> I am trying to compile the R package on a sun.
> I get the error message
> 
> rbitmap.c: In function 'my_png_error':
> rbitmap.c:73: structure has no member named 'jmpbuf'
> rbitmap.c: In function 'R_SaveAsPng':
> rbitmap.c:122: structure has no member named 'jmpbuf'
> make[4]:*** [rbitmap.lo] Error 1
> 
> Has anyone encountered this problem? Any solutions? Is there are compiled binary somewhere that I could use?
> 
> Grateful for any help.
> 
> Richard
> 
> 
> Richard Kerr, Quantitative Geneticist
> MMI Genomics
> Davis, CA 95616
> richard.kerr at mmigenomics.com
> (desk) 530-297-2938
> 

Please tell us which versions of R, Solaris (incl. architecture), and 
libpng you are using?

Uwe Ligges


From Bill.Venables at CMIS.CSIRO.AU  Fri Mar  7 08:46:11 2003
From: Bill.Venables at CMIS.CSIRO.AU (Bill.Venables@CMIS.CSIRO.AU)
Date: Fri, 7 Mar 2003 17:46:11 +1000 
Subject: [R] type III Sum Sq in ANOVA table - Howto?
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A9165932@roper-cv.qld.cmis.CSIRO.AU>

Having sounded off on this issue so frequently (and furiously) in the past
it is perhaps de rigeur for me to say something here...  I'm older and
calmer now, though.

Suppose we have:

	fm <- aov(y ~ x + A*B, data)

Then

	dropterm(fm, test = "F")

Will get you the appropriate information when excluding the *Marginal*
terms, one at a time, from the model, i.e. for X and A:B.  It's not a bug
that nothing else happens automatically.

If you want sums of squares for the non-marginal terms, in this case for the
main effects A and B, as well, you have strayed into tricky territory.  The
first sign that not all is as it seems is that the test now depends on what
treatment contrasts you have specified: contr.treatment or one of the
others.  If you DO NOT use contr.treatment but one where the column sums of
the contrast matrix are all zero, then you can get the "SAS Type III" sums
of squares by an inexplicable (to me) trick:

	dropterm(fm, . ~ ., test = "F")

but you can check that changing the contrasts back to "contr.treatment"
gives you different (and even more dud) results.

Rolf is right: there are conceivably cases where this is testing an
hypothesis of interest, just as occasionally it is interesting to test if a
regression line goes through the origin or if a quadratic regression has
zero slope at some point, but these are not the usual cases.  But it is
rare, and in 35 years of consulting I have never really encountered such an
occasion.  The often-quoted reason to use 'Type III' tests is "to test the
main effects when interactions ARE present", which if not further amplified
or explained, really is a nonsense.  My quarrel with SAS is that what they
routinely provide *encourages* misunderstandings like this and hence bad
inference.  Making users go to some length to get such results is, in my
view, no bad thing, (although the sequential AOV table that R and S-PLUS
routinely provides is in some respects not much better from this point of
view).

Moral: Decide what null hypothesis you would like to test, within what outer
hypothesis.  Fit both models and explicitly test one within the other.
There is then no need at all for any of this Type x palarver.  Attempts to
short-circuit the process with anova tables have to be viewed with some
caution, even scepticism, as the capacity for nonsense factor is very
operative.

Note that if you go no further than what drop1 or dropterm provides under
the default case, i.e. marginal terms only, then we have no quarrel.  These
are precisely the terms invariant with respect to contrast matrix.  However
beware of hidden non-marginal terms, such as the linear term in a quadratic
regression.

Bill Venables.
>  -----Original Message-----
> From: 	John Fox [mailto:jfox at mcmaster.ca] 
> Sent:	Friday, March 07, 2003 12:39 PM
> To:	Thomas Lumley; Josef Frank
> Cc:	r-help at stat.math.ethz.ch
> Subject:	Re: [R] type III Sum Sq in ANOVA table - Howto?
> 
> Dear Thomas et al.,
> 
> At 05:33 PM 3/6/2003 -0800, Thomas Lumley wrote:
> >On Fri, 7 Mar 2003, Josef Frank wrote:
> >
> > > Hello,
> > >
> > > as far as I see, R reports type I sums of squares. I'd like to get R
> to
> > > print out type III sums of squares.
> > >
> > > e.g. I have the following model:
> > > vardep~factor1*factor2
> > >
> > > to get the type III sum of squares for factor1 I've tried
> > > anova(lm(vardep~factor2+factor1:factor2),lm(vardep~factor1*factor2))
> > > but that didn't yield the desired result.
> > >
> > > Could anyone give me a hint how to proceed?
> > >
> >
> >Unfortunately the arguments about whether Type III sums of squares are
> >part of the axis of evil have drowned out a real issue.
> >
> >I would have expected the command to work, and in fact wrote a FAQ answer
> >saying this was the way to do it.  However, if factor1 is indeed a factor
> >its main effect is helpfully stuck back in the model by terms.formula.
> >
> >I think this is a bug, since it doesn't happen if factor1 isn't a factor,
> >and leaving aside any question about Type III SS it seems to make it
> >impossible to fit the model
> >    lm(vardep~factor2+factor1:factor2)
> >While this model isn't terribly often useful, it is sometimes.
> 
> The description of model formulas in Ch. 2 of Statistical Models in S 
> explains why ~factor2+factor1:factor2 is treated as it is.
> 
> Assuming that one really wants to test a "Type-III" hypothesis, the Anova 
> function in the car package will do it (and "Type-II" tests as well).
> 
> Regards,
>   John
> 
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ligges at statistik.uni-dortmund.de  Fri Mar  7 08:48:11 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 07 Mar 2003 08:48:11 +0100
Subject: [R] Preferred C++ compiler under Windows 2000
In-Reply-To: <20030306234111.89386.qmail@iname.com>
References: <20030306234111.89386.qmail@iname.com>
Message-ID: <3E684EBB.6000908@statistik.uni-dortmund.de>

Nicholas Croglio wrote:
> Greetings,
> 
> I know that most people on here are strong advocates of Unix or a similar OS, but I am interested in calling C++ or using C++ to call R.  What is the preferred or the compiler that works the best.  In the documentation it appears that VC++ is recommended, but in some posts I have seen statements that claim VC++ is not recommended.  I have a DEV C++ IDE, but I would like to borrow from the experience of others if possible.
> 
> Thanks,
> Nicholas Croglio

The MinGW port of gcc (including g++) works perfectly.
For more details see the readme files, the manual "Writing R 
Extensions", or the book
Venables & Ripley (2000): S Programming, Springer.

Uwe Ligges


From ripley at stats.ox.ac.uk  Fri Mar  7 08:57:33 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 7 Mar 2003 07:57:33 +0000 (GMT)
Subject: [R] Followup: copy-paste graphics from R to Word on Mac OS X
In-Reply-To: <20030306231841.GF12438@queenbee.fhcrc.org>
Message-ID: <Pine.LNX.4.44.0303070751250.9913-100000@gannet.stats>

On Thu, 6 Mar 2003, Seth Falcon wrote:

> I've encountered some of the same issues with jaggy graphics.  Here
> is what I have found to work pretty well:
> 
> Short and sweet:
> 
> Use the bitmap() function with res=200 to create png files.
> 
> Some explaination:
> 
> As far as I can tell, png(), jpg(), and friends do not allow you to
> set the resolution.  However, you can set the resolution using
> bitmap().  I've had good results with res=200.

Wrong. Png and jpeg don't have a resolution, only a size in pixels.
On both Unix and Windows the png devices set the size directly.
With bitmap you set the size in inches and the resolution, and they 
get multiplied together.

Better advice: use png() directly.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Mar  7 09:02:45 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 7 Mar 2003 08:02:45 +0000 (GMT)
Subject: [R] Preferred C++ compiler under Windows 2000
In-Reply-To: <20030306234111.89386.qmail@iname.com>
Message-ID: <Pine.LNX.4.44.0303070759370.9913-100000@gannet.stats>

If you mean the preferred compiler *for use with R*, it is g++ from the
preferred suite described in README.packages.  In case you didn't
understand, gcc is the Gnu Compiler Collection, C, C++, Fortran (and in 
some bundles Java).

We also prefer standard email formatting, with line breaks.

On Thu, 6 Mar 2003, Nicholas Croglio wrote:

> I know that most people on here are strong advocates of Unix or a similar OS, but I am interested in calling C++ or using C++ to call R.  What is the preferred or the compiler that works the best.  In the documentation it appears that VC++ is recommended, but in some posts I have seen statements that claim VC++ is not recommended.  I have a DEV C++ IDE, but I would like to borrow from the experience of others if possible.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Mar  7 09:04:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 7 Mar 2003 08:04:03 +0000 (GMT)
Subject: [R] Calling R program from an IDE
In-Reply-To: <20030306234434.92971.qmail@iname.com>
Message-ID: <Pine.LNX.4.44.0303070803010.9913-100000@gannet.stats>

Do read the README.rw1062 which comes with R for Windows.

You would find the rw-FAQ helpful too.

On Thu, 6 Mar 2003, Nicholas Croglio wrote:

> There are several editors that can call command prompts or have conficuration tools.  While learning these, I have noticed that I do not know how to execute an R program from the command line external to the R interactive environment.  It is very clearly stated for Unix type systems, but I do not see the equivalent documentation for Windows.  Please send me the link to this information.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From otoomet at econ.dk  Fri Mar  7 10:01:00 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Fri, 7 Mar 2003 10:01:00 +0100
Subject: [R] Problems with variable types.
In-Reply-To: <200303061146.28816.chrysopa@insecta.ufv.br>
References: <200303061146.28816.chrysopa@insecta.ufv.br>
Message-ID: <200303070901.h27910j01692@punik.econ.au.dk>

Dear Ronaldo,

Is your problem to create a data frame where character vectors remain
characters, not factors?

In documentation of as.data.frame you can read:

Character variables passed to data.frame are converted to factor
columns unless protected by I. It also applies to adding columns to
a data frame.

So you should create your data frame like

dados.fim <- data.frame(L, A, Nsp, N, I(AmT), I(NAm), I(AMST))

I don't know what is the mode of dados.fin, but probably something
happens there too.  

Best wishes,

Ott  

 | From: "Ronaldo Reis Jr." <chrysopa at insecta.ufv.br>
 | Date: Thu, 6 Mar 2003 11:46:28 -0300
 | 
 | Hi all,
 | 
 | I have problems in a dataframe variables types.
 | 
 | Look:
 | 
 | from a loop function:
 | for(...){
 | ...
 | dados.fin <- rbind(dados.fin, c(L=j, A=j^2,
 |                                 Nsp=nsps,
 |                                 N=length(amosfin$SP),
 |                                 AmT="am",NAm=nam,
 |                                 AMST=amst))
 | dados.fin <- rbind(dados.fin, c(L=j, A=j^2,
 |                                 Nsp=nsp, 
 |                                 N=nbicho, AmT="tot",
 |                                 NAm=nam,
 |                                 AMST=amst))
 | ...
 | }
 | 
 |     dados.fin <- as.data.frame(dados.fin)
 | 
 | > summary(dados.fin)
 |   L        A           Nsp           N       AmT     NAm      AMST   
 |  10:10   100:10   11     : 7   12     : 5   am :30   5:60   unif:60  
 |  12:10   144:10   7      : 7   122    : 5   tot:30                   
 |  14:10   196:10   16     : 5   181    : 5                            
 |  16:10   256:10   25     : 5   270    : 5                            
 |  18:10   324:10   37     : 5   403    : 5                            
 |  20:10   400:10   55     : 5   55     : 5                            
 |                   (Other):26   (Other):30                            
 | 
 | All variables appear like factors, but only AmT and AMST are really factors.
 | 
 | I try to use 
 | 
 | dados.fin <- rbind(dados.fin, c(L=as.numeric(j), A=j^2,
 |                                 Nsp=nsp, 
 |                                 N=nbicho, AmT="tot",
 |                                 NAm=nam,
 |                                 AMST=amst))
 | 
 | and some combinations like as.numeric(as.character(j)) etc.
 | 
 | How I make to force the types?


From po_chasset at yahoo.fr  Fri Mar  7 10:22:30 2003
From: po_chasset at yahoo.fr (=?iso-8859-1?q?Pierre-Olivier=20Chasset?=)
Date: Fri, 7 Mar 2003 10:22:30 +0100 (CET)
Subject: [R] Cluster analysis
Message-ID: <20030307092230.5244.qmail@web40413.mail.yahoo.com>

Hello,

I would like to calculate a cluster analysis and I use the function 'hclust'.
I have seen the GRAPHICAL results of this function with 'plot'.
I would like to analyse this cluster but I don't know how to see the NUMERICAL results of each
step of this cluster like:
- R Squared
- Pseudo F
- Pseudo t**2
Thank you for any help,

Pierre-Olivier Chasset

=====
Pierre-Olivier Chasset 
41, rue de la course 
F-67000 Strasbourg 
Phone: +33 3 88 32 06 42


From hennig at stat.math.ethz.ch  Fri Mar  7 11:28:26 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Fri, 7 Mar 2003 11:28:26 +0100 (CET)
Subject: [R] Cluster analysis
In-Reply-To: <20030307092230.5244.qmail@web40413.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0303071120390.2045-100000@florence>

Hi,

it seems that you mix something up. hclust is for dissimilarity based
hierarchical cluster analysis, which has nothing to do with R squared,
Pseudo F....
Informative output about the clustering is given as value of the hclust
object, function cutree may help to extract a concrete clustering at some
level of the hierarchy.
Maybe you do not start with dissimilarity data and you might consider pam
(in library cluster), kmeans or the library mclust for Normal mixtures.
However, the statistics values you are looking for are not the primary
quantities of interest in clustering, regardless of the method.

Christian Hennig

On Fri, 7 Mar 2003, Pierre-Olivier Chasset wrote:

> Hello,
> 
> I would like to calculate a cluster analysis and I use the function 'hclust'.
> I have seen the GRAPHICAL results of this function with 'plot'.
> I would like to analyse this cluster but I don't know how to see the NUMERICAL results of each
> step of this cluster like:
> - R Squared
> - Pseudo F
> - Pseudo t**2
> Thank you for any help,
> 
> Pierre-Olivier Chasset
> 
> =====
> Pierre-Olivier Chasset 
> 41, rue de la course 
> F-67000 Strasbourg 
> Phone: +33 3 88 32 06 42
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


From dbcfmp at unileon.es  Fri Mar  7 11:29:35 2003
From: dbcfmp at unileon.es (Felipe)
Date: Fri, 7 Mar 2003 11:29:35 +0100
Subject: [R] type III Sum Sq in ANOVA table - Howto?
In-Reply-To: <200303070031.h270Vb224953@gelfand.math.unb.ca>
Message-ID: <B17BDB74-5087-11D7-93A1-0003936778C4@unileon.es>

Hi! I have found your comments very interesting, but I feel I am one of 
these people that do not understand what the hell they are really 
testing :D
Could you (or anybody) suggest me a good web site to gather this kind 
of information? Sometimes I cannot fully understand the messages of the 
list because I lack some knowledge background.
Thank you.

Felipe

El Viernes, 7 marzo, 2003, a las 01:31 AM, Rolf Turner escribi?:

>
> Andy Liaw wrote:
>
>>  The long(er) answer: think harder about what question(s) you want 
>> answered
>>  (i.e., what hypotheses you really want to test, and test only 
>> those).  The
>>  model hierarchy says that a model should not have an interaction term
>>  involving a factor whose main effect is not present in the model.  
>> Seen in
>>  this light, the hypothesis you're trying to test involves a 
>> non-sensical
>>  model.
>
> Not really.  The hypothesis being tested by Type III sums of square
> may be suspected of not being of ``central interest'', but it is NOT
> (as is commonly believed) ``non-sensical''.
>
> Let us think about the 2-way ANOVA case, where one can actually
> understand what is going on.  Let the population ***cell means*** be
> mu_ij (i = 1, ..., m, j = 1, ..., n) and forget about the confusing
> and misleading over-parameterized model.
>
> Testing for the significance of the ``row factor'' by Type III
> sums of squares (with interaction in the model of course) tests
>
> 	H_0: mu_{1.}-bar = mu_{2.}-bar = ... = mu_{m.}-bar
>
> I.e. that the means of the population cell means, over columns, are
> all equal.  I.e. that ``when rows are averaged over columns'' there
> is no row effect.
>
> This could, at least conceiveably, be of interest.  Note that the
> average is not a weighted average, saying that all columns are
> equally important.  If all columns are NOT equally important (e.g.
> if an item randomly drawn from the population is more likely to
> ``come from'' column 1 than from column 2 etc.) then this hypothesis
> is less likely to be of interest.
>
> But it isn't nonsensical.
>
> It is true, however, that most of the time when people test things
> using Type III sums of squares they don't understand what they are
> really testing.  But then (said he cynically) people don't understand
> what the hell they are really testing in most situations, not just
> in the context of Type III sums of squares.
>
> 				cheers,
>
> 					Rolf Turner
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From peter.adorjan at epigenomics.com  Fri Mar  7 11:30:44 2003
From: peter.adorjan at epigenomics.com (Peter Adorjan)
Date: Fri, 07 Mar 2003 11:30:44 +0100
Subject: [R] Job opening: Biostatistics expert
Message-ID: <3E6874D4.8070607@epigenomics.com>

I hope this may be of interest for some of you. Thanks,
Peter Adorjan

------

Biostatistics expert (Berlin, Germany)

You will lead our efforts to develop and apply statistical and 
visualization techniques for the analysis and quality control of 
high-dimensional methylation data. You will support study design in 
diagnostics and pharmaceutical research. You will analyze data from 
scientific studies and clinical trials in close cooperation with life 
scientists and external partners. You will document and present results 
internally and externally.

You hold a university degree (MS, PhD) in statistics or related field. 
Working experience in applying statistical methods in medical, 
pharmaceutical research is a strong plus. Solid analytical skills are 
essential and experience with machine learning methods is an advantage. 
You master R/S-Plus or other statistical languages like SAS; experience 
with software development is a plus (C++, Java,  CORBA, relational 
databases, XML). You can efficiently turn ideas into practical 
solutions. You are an independent, creative scientist with excellent 
communication skills. You are able to plan and supervise research and 
also able to provide effective solutions within a constrained time. You 
know how to work at an interdisciplinary nodal position between the life 
sciences and statistics. Ideally, you have experience in project- and/or 
team-management.


Epigenomics` offices are attractively located in downtown Berlin and we 
offer positions with a high degree of responsibility in an exciting and 
dynamic work atmosphere. We offer a competitive compensation package.
Human Resources Dept.
Kleine Pr?sidentenstr. 1
D-10178 Berlin, Germany
http://www.epigenomics.com
Email: careers at epigenomics.com


From fharrell at virginia.edu  Fri Mar  7 12:53:55 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 7 Mar 2003 06:53:55 -0500
Subject: [R] type III Sum Sq in ANOVA table - Howto?
In-Reply-To: <E09E527B56BE2D438A3D6A246DDD27A9165932@roper-cv.qld.cmis.CSIRO.AU>
References: <E09E527B56BE2D438A3D6A246DDD27A9165932@roper-cv.qld.cmis.CSIRO.AU>
Message-ID: <20030307065355.09e45efc.fharrell@virginia.edu>

On Fri, 7 Mar 2003 17:46:11 +1000 
Bill.Venables at cmis.csiro.au wrote:

> Having sounded off on this issue so frequently (and furiously) in the past
> it is perhaps de rigeur for me to say something here...  I'm older and
> calmer now, though.
> 
.... [much wisdom truncated] ...

After Bill Venables' welcome post I'll add :) 

There is one scientific basis for choosing type III contrasts.  If one desires a low-precision contrast (or a low power test) in the presence of major imbalances, type III is for you.
--- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From jfox at mcmaster.ca  Fri Mar  7 13:27:46 2003
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 07 Mar 2003 07:27:46 -0500
Subject: [R] Boot
In-Reply-To: <se6864b9.088@rauzen.rau.ac.za>
Message-ID: <5.1.0.14.2.20030307072422.01e166a8@mcmail.cis.mcmaster.ca>

Dear Jacob,

The appendix on bootstrapping to my R and S-PLUS Companion, available on 
the web at 
<http://www.socsci.mcmaster.ca/jfox/Books/Companion/appendix-bootstrapping.pdf>, 
discusses fixed-X resampling (which is what you're getting at here, I 
think) and includes an example.

I hope that this helps,
  John

At 09:21 AM 3/7/2003 +0200, Jacob van Wyk wrote:
>Hallo
>Could anybody please help.
>I have a simple linear regression model with 5 predictors. I want to
>use "bootstrap residuals" to make inferences regarding beta(2)hat. After
>fitting the model y=b0+b1+b2+b3+b4+b5 I tried the following:
>
>mod <- lm(y ~ x1+x2+x3+x4+x5)
>res <- resid(mod)
>pred <- predict(mod)
>
>Now, I have tried
>
>boot(res, lm(res+pred ~ x1+x2+x3+x4+x5)$coef[3], R=1999)
>
>The problem is with the "statistic". How should I "define" this?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From jfox at mcmaster.ca  Fri Mar  7 13:41:06 2003
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 07 Mar 2003 07:41:06 -0500
Subject: [R] type III Sum Sq in ANOVA table - Howto?
In-Reply-To: <B17BDB74-5087-11D7-93A1-0003936778C4@unileon.es>
References: <200303070031.h270Vb224953@gelfand.math.unb.ca>
Message-ID: <5.1.0.14.2.20030307073209.01e61120@mcmail.cis.mcmaster.ca>

Dear Felipe,

At the risk of rekindling this debate, I've placed a brief (3-page) 
document at <http://www.socsci.mcmaster.ca/jfox/.Pickup/ANOVA-notes.pdf> 
which explains the hypotheses tested by "Type-II" and "Type-III" tests, 
their relationship to the parametrization of the model, issues of power, 
etc., in the context of unbalanced two-way ANOVA. My own view is that the 
disagreement is more a question of emphasis than anything else, and that 
the points that I make in this document are widely understood.

I hope that this is of some use.
  John

At 11:29 AM 3/7/2003 +0100, Felipe wrote:
>Hi! I have found your comments very interesting, but I feel I am one of 
>these people that do not understand what the hell they are really testing :D
>Could you (or anybody) suggest me a good web site to gather this kind of 
>information? Sometimes I cannot fully understand the messages of the list 
>because I lack some knowledge background.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From bates at stat.wisc.edu  Fri Mar  7 13:44:49 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 07 Mar 2003 06:44:49 -0600
Subject: [R] column name changes based on substrings
In-Reply-To: <F65yFhGVzxb8AH96IAa00006268@hotmail.com>
References: <F65yFhGVzxb8AH96IAa00006268@hotmail.com>
Message-ID: <6rwujb8hxa.fsf@bates4.stat.wisc.edu>

"Jeremy Z Butler" <jerrytheshrub at hotmail.com> writes:

> So far I can't even figure out how to replace a column name:
> 
> >aa[colnames(aa)=="blah3.Mg"]_colnames("Mg (%)")
> Error in matrix(value, n, p) : No data to replace in matrix(...)

You replace the column names by replacing elements of the second
component of the dimnames.  The easiest way to do this is to extract
the column names as a vector of character strings then replace
components of this vector then install it as the second component of the
dimnames.

cnams = dimnames(aa)[[2]]

cnams[which(cnams == 'blah3.Mg')] = 'Mg (%)'
...
dimnames(aa)[[2]] = cnams

BTW, the use of '_' as the assignment operator is deprecated.  It
will be disabled in future versions of R.  We prefer '=' or '<-' as
the use of '_' results in code that is difficult to read.

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/


From Ted.Harding at nessie.mcc.ac.uk  Fri Mar  7 15:11:26 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 07 Mar 2003 14:11:26 -0000 (GMT)
Subject: [R] "Local trend surfaces" Ex from V&R MASS
Message-ID: <XFMail.030307141126.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

I'm probably overlooking some small point, but can't see it.

Trying the "Local trend surfaces" example from p.437 of MASS
(3rd edn) by V&R, all goes well until the line

contour(topo.mar$x, topo.mar$y, topo.lo$fit,
        levels=seq(700,1000,25), xlab="fi t", ylab="")

which produces the response:

  Error in contour.default(topo.mar$x, topo.mar$y, topo.lo$fit,
  levels = seq(700,  : 
          no proper `z' matrix specified

I've checked the sizes of topo.mar$x, topo.mar$y and topo.lo$fit, and
they should all line up, so I can't see why "no proper `z' matrix
specified". I notice that topo.lo$fit has NAs (but "NA's are allowed"
according to "?contour") and wonder if this may be causing a problem
(options("na.action")->[1] "na.omit").

Using R 1.6.2 here ... 

Thanks for any info,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 07-Mar-03                                       Time: 14:11:26
------------------------------ XFMail ------------------------------


From JonesW at kssg.com  Fri Mar  7 15:36:37 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Fri, 7 Mar 2003 14:36:37 -0000 
Subject: [R] Moving average
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE206A@GIMLI>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030307/3074e439/attachment.pl

From ripley at stats.ox.ac.uk  Fri Mar  7 15:43:36 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 7 Mar 2003 14:43:36 +0000 (GMT)
Subject: [R] "Local trend surfaces" Ex from V&R MASS
In-Reply-To: <XFMail.030307141126.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0303071438310.15774-100000@gannet.stats>

On Fri, 7 Mar 2003 Ted.Harding at nessie.mcc.ac.uk wrote:

> Hi Folks,
> 
> I'm probably overlooking some small point, but can't see it.
> 
> Trying the "Local trend surfaces" example from p.437 of MASS
> (3rd edn) by V&R, all goes well until the line
> 
> contour(topo.mar$x, topo.mar$y, topo.lo$fit,
>         levels=seq(700,1000,25), xlab="fi t", ylab="")
> 
> which produces the response:
> 
>   Error in contour.default(topo.mar$x, topo.mar$y, topo.lo$fit,
>   levels = seq(700,  : 
>           no proper `z' matrix specified
> 
> I've checked the sizes of topo.mar$x, topo.mar$y and topo.lo$fit, and
> they should all line up, so I can't see why "no proper `z' matrix
> specified". I notice that topo.lo$fit has NAs (but "NA's are allowed"
> according to "?contour") and wonder if this may be causing a problem
> (options("na.action")->[1] "na.omit").

Nope, it's an R/S difference in contour/loess (I forget which).  You need
to check the R scripts (library/MASS/scripts3 in your R installation)
which give

topo.loess <- loess(z ~ x * y, topo, degree=2, span = 0.25, normalize=F)
topo.mar <- list(x = seq(0, 6.5, dif), y=seq(0, 6.5, dif))
topo.lo <- predict(topo.loess, expand.grid(topo.mar), se=T)
topo.lo$fit <- matrix(topo.lo$fit, length(topo.mar$x), length(topo.mar$y))
contour(topo.mar$x,topo.mar$y,topo.lo$fit, levels = seq(700,1000,25),
        xlab="fit", ylab="")

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Morten.Sickel at nrpa.no  Fri Mar  7 15:49:25 2003
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Fri, 7 Mar 2003 15:49:25 +0100 
Subject: [R] Moving average
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5E93@postix.nrpa.no>

Wayne Jones wrote:
>Does anyone know if R has the functionality to calculate a simple moving
>average. I cant seem to find it in the help menu. 

does filter() do what you need?

Morten


From Morten.Sickel at nrpa.no  Fri Mar  7 15:51:13 2003
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Fri, 7 Mar 2003 15:51:13 +0100 
Subject: [R] Moving average
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5E94@postix.nrpa.no>

Sorry, a neccesary addition: filter in library ts.

Morten


From supratik at stat.ucc.ie  Fri Mar  7 16:10:36 2003
From: supratik at stat.ucc.ie (Roy, Supratik)
Date: Fri, 7 Mar 2003 15:10:36 -0000 
Subject: [R] multi-user installation
Message-ID: <F64493091FAC4D4DAC46261FEC1967995FDB6B@xch4.ucc.ie>


Hi, maybe I overlooked something. But I wanted to check
if it is possible to install R as server for multiuser environment
over a network. (i.e., installation on a Linux server on RedHat 8.0).
This was not clear to me from the installation notes.

Supratik Roy
Statistics Dept., UCC.
Cork, Ireland.


From reid_huntsinger at merck.com  Fri Mar  7 16:12:38 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri, 07 Mar 2003 10:12:38 -0500
Subject: [R] Moving average
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC377@uswpmx11.merck.com>

Try "filter" in package ts.

Reid Huntsinger

-----Original Message-----
From: Wayne Jones [mailto:JonesW at kssg.com] 
Sent: Friday, March 07, 2003 9:37 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Moving average


Hi, 

Does anyone know if R has the functionality to calculate a simple moving
average. I cant seem 
to find it in the help menu. 

thanks, 

Wayne


Dr Wayne R. Jones
Statistician / Research Analyst
KSS Group plc
St James's Buildings
79 Oxford Street
Manchester M1 6SS
Tel: +44(0)161 609 4084
Mob: +44(0)7810 523 713



KSS Ltd
A division of Knowledge Support Systems Group plc
Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS
England
Company Registration Number 2800886 (Limited) 3449594 (plc)
Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
mailto:kssg at kssg.com		http://www.kssg.com


The information in this Internet email is confidential and may b... [[dropped]]


From dth2 at u.washington.edu  Fri Mar  7 16:27:24 2003
From: dth2 at u.washington.edu (dth2@u.washington.edu)
Date: Fri, 7 Mar 2003 07:27:24 -0800 (PST)
Subject: [R] Type IV sum of squares
Message-ID: <Pine.LNX.4.43.0303070727240.18043@hymn07.u.washington.edu>

To anyone who can help:

I am trying to do an analysis of variance with a very unbalanced design and a few empty cells.  How do I get R to use type III and more importantly type IV sums of squares?

Thanks

Deven Hamilton
Department of Sociology
University of Washington


From tlumley at u.washington.edu  Fri Mar  7 16:35:46 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 7 Mar 2003 07:35:46 -0800 (PST)
Subject: [R] type III Sum Sq in ANOVA table - Howto?
In-Reply-To: <x21y1j39t6.fsf@biostat.ku.dk>
Message-ID: <Pine.A41.4.44.0303070731420.41498-100000@homer14.u.washington.edu>

On 7 Mar 2003, Peter Dalgaard BSA wrote:
> Hmm... no ... and yes. There are some useful models, but you cannot
> specify them unambiguously with model formulas. At least to my way of
> thinking, the only useful way of thinking of interaction terms is that
> f1:f2 describes an arbitrary pattern of means in the f1 x f2
> crosstable, and the rest is just R/S being helpful in removing known
> aliased effects. So f1 + f2 + f1:f2 is the same model as f2 + f1:f2 is
> the same as f1:f2.

The reason I didn't expect this that it makes : and * synonyms (for
factors).  I realise that the effects are parametrisation-dependent, but
most of the useful output of the model is parametrisation-dependent
anyway.

OTOH if it's in the White Book, as John Fox indicated, then it's by
definition not a bug.


	-thomas


From Ted.Harding at nessie.mcc.ac.uk  Fri Mar  7 16:37:38 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 07 Mar 2003 15:37:38 -0000 (GMT)
Subject: [R] "Local trend surfaces" Ex from V&R MASS
In-Reply-To: <Pine.LNX.4.44.0303071438310.15774-100000@gannet.stats>
Message-ID: <XFMail.030307153738.Ted.Harding@nessie.mcc.ac.uk>

On 07-Mar-03 ripley at stats.ox.ac.uk wrote:
> On Fri, 7 Mar 2003 Ted.Harding at nessie.mcc.ac.uk wrote:
>> Trying the "Local trend surfaces" example from p.437 of MASS
>> (3rd edn) by V&R, all goes well until the line
>> 
>> contour(topo.mar$x, topo.mar$y, topo.lo$fit,
>>         levels=seq(700,1000,25), xlab="fi t", ylab="")
>> 
>> which produces the response:
>> 
>>   Error in contour.default(topo.mar$x, topo.mar$y, topo.lo$fit,
>>   levels = seq(700,  : 
>>           no proper `z' matrix specified

Thanks, Brian! The extra command (at [***] below) solved it.

> ... it's an R/S difference in contour/loess (I forget which).

It looks as though the difference is in the behaviour of
"predict=predict.loess"): in S topo.lo$fit is a matrix-like object with
rows labelled as "x=x1", "x=x2" etc., cols labelled as "y=y1" etc., and
entries the fitted values (so it already has the requisite layout), which
from R the value of topo.lo$fit is simply a vector with as many elements
as there are prediction grid-points. Hence it needs to be reshaped into a
matrix (as in your extra command).

> You need to check the R scripts (library/MASS/scripts3 in your R
> installation) which give
> 
> topo.loess <- loess(z ~ x * y, topo, degree=2, span = 0.25,
> normalize=F)
> topo.mar <- list(x = seq(0, 6.5, dif), y=seq(0, 6.5, dif))
> topo.lo <- predict(topo.loess, expand.grid(topo.mar), se=T)
> [***] topo.lo$fit <- matrix(topo.lo$fit, length(topo.mar$x),
>                             length(topo.mar$y))
> contour(topo.mar$x,topo.mar$y,topo.lo$fit, levels = seq(700,1000,25),
>         xlab="fit", ylab="")

Many thanks!
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 07-Mar-03                                       Time: 15:37:38
------------------------------ XFMail ------------------------------


From murdoch at stats.uwo.ca  Fri Mar  7 17:29:35 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 07 Mar 2003 11:29:35 -0500
Subject: [R] Use Rterm in rxvt for Cygwin?
In-Reply-To: <wmvfywfezx.fsf@qiuranke.phony.washington.edu>
References: <Pine.LNX.4.44.0303030755070.17885-100000@gannet.stats>
	<wmvfywfezx.fsf@qiuranke.phony.washington.edu>
Message-ID: <a4ih6vc796ibmcumk6rkgc8ub6dpi897g4@4ax.com>

On Thu, 06 Mar 2003 11:53:54 -0800, you wrote in message
<wmvfywfezx.fsf at qiuranke.phony.washington.edu>:

>On Mon, 3 Mar 2003, ripley at stats.ox.ac.uk outgrape:
>
>>  Rterm is a Windows application.  It works fine in Windows tcsh and in 
>>  Cygwin bash on Windows XP (and last time I looked, Windows 98 too).
>
>Rterm doesn't work (interactively) in Cygwin bash on our machine (Windows 2000
>SP 3, R 1.6.1).  (Not that I need that functionality). It gives error like,
>
>,----
>| The instruction at "0x7800270e" referenced memory at "0x0000000". The memory
>| could not be read.
>`----

That version (and r-devel) both work fine for me in XP and Win98 under
bash.  As Brian Ripley said, it looks like a problem with the
msvcrt.dll/cygwin versions you've got on your machine.

Duncan Murdoch


From gregory_r_warnes at groton.pfizer.com  Fri Mar  7 18:08:14 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri, 7 Mar 2003 12:08:14 -0500 
Subject: [R] Moving average
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C69C@groexmb02.pfizer.com>

Or look at the 'running' function in the gregmisc package.

-Greg

> -----Original Message-----
> From: Huntsinger, Reid [mailto:reid_huntsinger at merck.com]
> Sent: Friday, March 07, 2003 10:13 AM
> To: 'Wayne Jones'; r-help at stat.math.ethz.ch
> Subject: RE: [R] Moving average
> 
> 
> Try "filter" in package ts.
> 
> Reid Huntsinger
> 
> -----Original Message-----
> From: Wayne Jones [mailto:JonesW at kssg.com] 
> Sent: Friday, March 07, 2003 9:37 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Moving average
> 
> 
> Hi, 
> 
> Does anyone know if R has the functionality to calculate a 
> simple moving
> average. I cant seem 
> to find it in the help menu. 
> 
> thanks, 
> 
> Wayne
> 
> 
> Dr Wayne R. Jones
> Statistician / Research Analyst
> KSS Group plc
> St James's Buildings
> 79 Oxford Street
> Manchester M1 6SS
> Tel: +44(0)161 609 4084
> Mob: +44(0)7810 523 713
> 
> 
> 
> KSS Ltd
> A division of Knowledge Support Systems Group plc
> Seventh Floor  St James's Buildings  79 Oxford Street  
> Manchester  M1 6SS
> England
> Company Registration Number 2800886 (Limited) 3449594 (plc)
> Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com		http://www.kssg.com
> 
> 
> The information in this Internet email is confidential and 
> may b... [[dropped]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... [[dropped]]


From ihaka at stat.auckland.ac.nz  Fri Mar  7 20:06:18 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Sat, 08 Mar 2003 08:06:18 +1300
Subject: [R] multi-user installation
References: <F64493091FAC4D4DAC46261FEC1967995FDB6B@xch4.ucc.ie>
Message-ID: <3E68EDAA.6030505@stat.auckland.ac.nz>

Roy, Supratik wrote:
> Hi, maybe I overlooked something. But I wanted to check
> if it is possible to install R as server for multiuser environment
> over a network. (i.e., installation on a Linux server on RedHat 8.0).
> This was not clear to me from the installation notes.

Installation on a Linux server is no different from installation on a 
Linux workstation.


-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand


From d.r.j.pleydell at pgr.salford.ac.uk  Fri Mar  7 20:10:19 2003
From: d.r.j.pleydell at pgr.salford.ac.uk (David)
Date: Fri, 07 Mar 2003 19:10:19 +0000
Subject: [R] REML option in gstat
Message-ID: <5.2.0.9.0.20030307183139.00b3fb00@mail.salford.ac.uk>

Hi, please help!!

I've been trying to fit variogram models using the REML method in the gstat 
package.  Every time the Windows GUI crashes.  For example

library(gstat)
data(meuse)
x <- variogram(zinc ~ 1, ~x + y, meuse)
v <- vgm(140000, "Sph", 800, nug = 10000)
plot(x, model = fit.variogram(x, model = v, fit.method=5))

Other fit methods are non problematic (eg. fit.method=7 for WLS or 
fit.method=1 for OLS)

I've tried the code on Windows XP, 98 and NT and all fail, how about 
non-Windows platforms?
Any suggestions?

Many thanks
Dave


From xsyu at u.washington.edu  Fri Mar  7 20:26:54 2003
From: xsyu at u.washington.edu (X. Yu)
Date: Fri, 7 Mar 2003 11:26:54 -0800 (PST)
Subject: [R] help on haplo.score
Message-ID: <Pine.A41.4.44.0303071115500.82890-100000@dante35.u.washington.edu>

Hi all,

Recently i am running a new package call "haplo.score" in R which compute
score statistics to evaluate the association of a trait with
haplotypes, when linkage phase is unknown.  unfortunately,
I kept getting an error message like "No variation in y values". where y
is my trait vector with 1 for disease and 0 for non-disease. if someone
happen to know why i am getting this error,  please let me know. your help
is highly appreciated.

see the following for a part of my data and code.
i have 5 loci and total 150 subjects, but here i only includes 8 of them

xuesong

## matrix for haplotype data (8x10)
geno<-matrix(c(0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0 ,1, 0, 1, 0, 1,
0, 0 ,0, 1, 0, 0, 0, 1, 0, 0,1, 1 ,0, 0, 1, 1, 0, 0, 1,
1,),byrow=TRUE,ncol=10)
geno2<-matrix(c(0, 1, 0, 1, 0, 1, 0, 1, 0, 1,0, 1, 0, 1, 0, 1, 0, 1, 0,
1,1, 1, 0, 0, 1, 1, 0, 0, 0, 1,1, 1, 0, 0, 1, 1, 0, 0, 1,
1),byrow=TRUE,ncol=10)
geno<-rbind(geno,geno2)

## trait data (binary)
y<-c(rep(0,4),rep(1,4))

## compute score statistic
library(haplo.score)
hscore<-haplo.score(y,geno,trait.type="binomial")


From ripley at stats.ox.ac.uk  Fri Mar  7 20:37:28 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 7 Mar 2003 19:37:28 +0000 (GMT)
Subject: [R] REML option in gstat
In-Reply-To: <5.2.0.9.0.20030307183139.00b3fb00@mail.salford.ac.uk>
Message-ID: <Pine.LNX.4.44.0303071934120.14479-100000@gannet.stats>

That example segfaults on Linux.

On Fri, 7 Mar 2003, David wrote:

> I've been trying to fit variogram models using the REML method in the gstat 
> package.  Every time the Windows GUI crashes.  For example
> 
> library(gstat)
> data(meuse)
> x <- variogram(zinc ~ 1, ~x + y, meuse)
> v <- vgm(140000, "Sph", 800, nug = 10000)
> plot(x, model = fit.variogram(x, model = v, fit.method=5))
> 
> Other fit methods are non problematic (eg. fit.method=7 for WLS or 
> fit.method=1 for OLS)
> 
> I've tried the code on Windows XP, 98 and NT and all fail, how about 
> non-Windows platforms?
> Any suggestions?

See Q7.3 in the rw-FAQ on how to debug compiled code.  Since you have
already re-built from the sources, this should be easy for you to do.

Alternatively, talk to the author about this.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From richard.kerr at mmigenomics.com  Fri Mar  7 20:48:07 2003
From: richard.kerr at mmigenomics.com (Kerr, Richard)
Date: Fri, 7 Mar 2003 11:48:07 -0800
Subject: [R] compiling R on sparc-solaris
Message-ID: <B26C735994B48F4DBF5466E72120E4903A0D15@dav-gen-exch.genomics.mmi.ad>



-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
Sent: Thursday, March 06, 2003 11:45 PM
To: Kerr, Richard
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] compiling R on sparc-solaris

Yes that information would be useful. It is solaris 7 for sparc architecture (Ultra 80 or Ultra 3500). I am trying to compile R 1.6.2. The libpng is version 1.1.0e

Richard

Kerr, Richard wrote:
> Hello,
> 
> I am trying to compile the R package on a sun.
> I get the error message
> 
> rbitmap.c: In function 'my_png_error':
> rbitmap.c:73: structure has no member named 'jmpbuf'
> rbitmap.c: In function 'R_SaveAsPng':
> rbitmap.c:122: structure has no member named 'jmpbuf'
> make[4]:*** [rbitmap.lo] Error 1
> 
> Has anyone encountered this problem? Any solutions? Is there are compiled binary somewhere that I could use? 

Please tell us which versions of R, Solaris (incl. architecture), and 
libpng you are using?

Uwe Ligges


From ripley at stats.ox.ac.uk  Fri Mar  7 21:01:52 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 7 Mar 2003 20:01:52 +0000 (GMT)
Subject: [R] compiling R on sparc-solaris
In-Reply-To: <B26C735994B48F4DBF5466E72120E4903A0D15@dav-gen-exch.genomics.mmi.ad>
Message-ID: <Pine.LNX.4.44.0303071958550.24243-100000@gannet.stats>

I understood libpng 1.1.x to be unreleased versions, and there is no
sign of them on www.libpng.org.

The solution is use a released version, any since 1.0.5 except 1.2.2.

On Fri, 7 Mar 2003, Kerr, Richard wrote:

> 
> 
> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Sent: Thursday, March 06, 2003 11:45 PM
> To: Kerr, Richard
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] compiling R on sparc-solaris
> 
> Yes that information would be useful. It is solaris 7 for sparc architecture (Ultra 80 or Ultra 3500). I am trying to compile R 1.6.2. The libpng is version 1.1.0e
> 
> Richard
> 
> Kerr, Richard wrote:
> > Hello,
> > 
> > I am trying to compile the R package on a sun.
> > I get the error message
> > 
> > rbitmap.c: In function 'my_png_error':
> > rbitmap.c:73: structure has no member named 'jmpbuf'
> > rbitmap.c: In function 'R_SaveAsPng':
> > rbitmap.c:122: structure has no member named 'jmpbuf'
> > make[4]:*** [rbitmap.lo] Error 1
> > 
> > Has anyone encountered this problem? Any solutions? Is there are compiled binary somewhere that I could use? 
> 
> Please tell us which versions of R, Solaris (incl. architecture), and 
> libpng you are using?
> 
> Uwe Ligges
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From verzani at math.csi.cuny.edu  Fri Mar  7 21:44:17 2003
From: verzani at math.csi.cuny.edu (verzani@math.csi.cuny.edu)
Date: Fri, 07 Mar 2003 15:44:17 -0500
Subject: [R] [Ann] New version of pmg -- Poor Man's GUI
Message-ID: <15977.1185.814679.207143@levy.math.csi.cuny.edu>

For those who are interested,

I've finished release of 0.4 of pmg and have placed it on my website
at http://www.math.csi.cuny.edu/Statistics/R/pmg.


The pmg package provides some GUI elements using the RGtk package and
friends: RGtk, OOP, RGtkExtra, RGtkHTML, RGdkPixbuf, RGtkViewers and
REventLoop from www.omegahat.org and gtkDevice from CRAN. (These
require a form of UNIX such as linux, OS X etc.) In particular the key
elements are a menubar with some basic dialogs for doing statistical
analysis and a spreadsheet interface. The goal is to make it a bit
easier for beginners to use R. It doesn't offer too much (yet?) for
advanced users.

This is still alpha quality software but seems usable enough. I'd
appreciate any bug reports and comments.


-- 
o---------------------------------------------------------------------o
|  John Verzani                            verzani at math.csi.cuny.edu  |
|  CUNY/CSI			       www.math.csi.cuny.edu/verzani  |
|  Dept. of Mathematics, 1S-215	                        718 982 3623  |
|  Staten Island, NY 10314	       	          (fax) 718 982 3631  |
o---------------------------------------------------------------------o


From lina at u.washington.edu  Fri Mar  7 23:04:09 2003
From: lina at u.washington.edu (Michael Na Li)
Date: Fri, 07 Mar 2003 14:04:09 -0800
Subject: [R] general matrix inner product?
Message-ID: <xmr89ihm06.fsf@spc147.stat.washington.edu>


Is there a "inner" function that takes a function argument.  Similar to outer
() vs. %o% such that

inner (x, y, FUN = function (z1, z2) sum (z1 * z2))

returns the same result as x %*% y?

Michael


From gregory_r_warnes at groton.pfizer.com  Sat Mar  8 01:01:31 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri, 7 Mar 2003 19:01:31 -0500 
Subject: [R] help on haplo.score
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C69E@groexmb02.pfizer.com>


The haplo.score function has the parameter "miss.val", which is used to
indicate what numeric values are used to indicate missingness.  By default,
miss.val=0.  [I suspect this is a relic of a standalone form of the
haplo.score program.] Under this coding, no row is completely observed, and
they all get deleted, resulting in an empty data set.  No variation indeed.

To resolve your problem, specify miss.val=NA.  IE,

> hscore<-haplo.score(y,geno,trait.type="binomial",miss=NA)

-Greg

> -----Original Message-----
> From: X. Yu [mailto:xsyu at u.washington.edu]
> Sent: Friday, March 07, 2003 2:27 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] help on haplo.score
> 
> 
> Hi all,
> 
> Recently i am running a new package call "haplo.score" in R 
> which compute
> score statistics to evaluate the association of a trait with
> haplotypes, when linkage phase is unknown.  unfortunately,
> I kept getting an error message like "No variation in y 
> values". where y
> is my trait vector with 1 for disease and 0 for non-disease. 
> if someone
> happen to know why i am getting this error,  please let me 
> know. your help
> is highly appreciated.
> 
> see the following for a part of my data and code.
> i have 5 loci and total 150 subjects, but here i only 
> includes 8 of them
> 
> xuesong
> 
> ## matrix for haplotype data (8x10)
> geno<-matrix(c(0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0 
> ,1, 0, 1, 0, 1,
> 0, 0 ,0, 1, 0, 0, 0, 1, 0, 0,1, 1 ,0, 0, 1, 1, 0, 0, 1,
> 1,),byrow=TRUE,ncol=10)
> geno2<-matrix(c(0, 1, 0, 1, 0, 1, 0, 1, 0, 1,0, 1, 0, 1, 0, 
> 1, 0, 1, 0,
> 1,1, 1, 0, 0, 1, 1, 0, 0, 0, 1,1, 1, 0, 0, 1, 1, 0, 0, 1,
> 1),byrow=TRUE,ncol=10)
> geno<-rbind(geno,geno2)
> 
> ## trait data (binary)
> y<-c(rep(0,4),rep(1,4))
> 
> ## compute score statistic
> library(haplo.score)
> hscore<-haplo.score(y,geno,trait.type="binomial")
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... [[dropped]]


From andrewr at uidaho.edu  Sat Mar  8 01:43:23 2003
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Fri, 07 Mar 2003 16:43:23 -0800 (PST)
Subject: [R] Looking for non-central F quantile
Message-ID: <Pine.GHP.4.51.0303071640110.9749@raptor.csrv.uidaho.edu>

Greetings all,

I'm trying to figure out how to calculate the inverse CDF (i.e. a
quantile) for a non-central F distribution.  I could put together a quick
numerical solver routine using the CDF, but I wonder if there's a function
that I've missed that would be more efficient?

Thank-you,

Andrew

Andrew Robinson			     Ph: 208 885 7115
Department of Forest Resources	     Fa: 208 885 6226
University of Idaho		     E : andrewr at uidaho.edu
PO Box 441133			     W : http://www.uidaho.edu/~andrewr
Moscow ID 83843			     Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.


From umalvarez at fata.unam.mx  Sat Mar  8 02:08:45 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Fri, 7 Mar 2003 19:08:45 -0600 (CST)
Subject: [R] Followup: copy-paste graphics from R to Word on Mac OS X
In-Reply-To: <A566ED6C-4FFE-11D7-B8F6-0003938E023E@portland.econw.com>
Message-ID: <Pine.LNX.4.44.0303071858510.1390-100000@fata.unam.mx>

Eric:

I'm working with R in an IBook with Jaguar 10.2.4. When it comes to 
ghapics manipulation the best thing for me (and I mean a real good result)  
was to save my graphics either as bitmaps or as png's files with the 
"bitmap" or the "png" devices, respectively.

Example:

x <- 1:10
y <- 11:20
plot(x,y)
dev.print(bitmap, file = "dummy.bmp", res = 600)

I should tell you that I've compiled R using fink. I've to download a 
bunch of additional software (X11, ghoscript, etc., always using fink). 
But the results are just great.

Have a look at the list files, and at the "Devices" help in the R 
software. If you need additional help with graphics or fink please let me 
know. 

Regards.



On Thu, 6 Mar 2003, Eric Fruits wrote:

> After trying numerous options, I'm just about at my wits end.
> 
> The most frequent suggestion was to export to a postscript or PDF file 
> and import that into Word.
> 
> However, no matter what I did or how I did it, the results were 
> extraordinarily ugly and somewhat time-consuming.
> 
> What I've tried so far:
> 
> 1.  Copy and paste from the R graphics output window into Word (in Mac 
> OS X), this is the worst result.
> 
> 2.  Use pdf() to create a pdf file, then import (Insert | Picture | 
>  From File ...) into Word.  This generated the second-worst results.  
> Note, that if I print the .pdf file without importing, the results are 
> OK.
> 
> 3.  Use pdf() to create a pdf file, use MacGSView to convert to .tiff, 
> then import into Word.  This provided the third-worst results.  Note 
> that the .tiff file is jaggy too.
> 
> 4.  Use pdf() to create a pdf file, use the full-blown version of 
> Acrobat to convert to .tiff, then import into Word.  This provided the 
> best, but still ugly results.  Note that the .tiff file is jaggy too.
> 
> It is conceivable that this is a Mac OS X problem, but I'm not 
> convinced considering how well it handles other graphics.
> 
> Any suggestions are appreciated.
> 
> Begin forwarded message:
> 
> > From: Eric Fruits <fruits at portland.econw.com>
> > Date: Fri Feb 21, 2003  10:32:52  AM US/Pacific
> > To: r-help at lists.R-project.org
> > Subject: Copy-paste graphics from R to Word on Mac OS X
> >
> > Greetings:
> >
> > 	I'm (very) new  to R.
> >
> > 	One of the features of R that I really like is R's ability to quickly 
> > generate very good looking graphics.  However, I've noticed that when 
> > I attempt to copy and paste the graphs from the R graphics output 
> > window into Word (in Mac OS X), the resulting picture is very jaggy.
> >
> > 	I'm aware of the various options such as dev2bitmap, but I'd really 
> > like to be able to do a quick copy and paste without switching among 
> > various applications or creating extraneous files.
> >
> > 	Thanks.
> >
> > -- 
> > Eric Fruits, Ph.D.
> > Senior Economist & Project Manager
> > ECONorthwest - Portland
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx


From spencer.graves at pdf.com  Sat Mar  8 02:48:31 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 07 Mar 2003 17:48:31 -0800
Subject: [R] Looking for non-central F quantile
References: <Pine.GHP.4.51.0303071640110.9749@raptor.csrv.uidaho.edu>
Message-ID: <3E694BEF.5060405@pdf.com>

At least you could get reasonable starting values from qchisq.  (If you 
also needed it to work in S-Plus, then you would need to port R's 
"qchisq" to S-Plus.)

Spencer Graves

Andrew Robinson wrote:
> Greetings all,
> 
> I'm trying to figure out how to calculate the inverse CDF (i.e. a
> quantile) for a non-central F distribution.  I could put together a quick
> numerical solver routine using the CDF, but I wonder if there's a function
> that I've missed that would be more efficient?
> 
> Thank-you,
> 
> Andrew
> 
> Andrew Robinson			     Ph: 208 885 7115
> Department of Forest Resources	     Fa: 208 885 6226
> University of Idaho		     E : andrewr at uidaho.edu
> PO Box 441133			     W : http://www.uidaho.edu/~andrewr
> Moscow ID 83843			     Or: http://www.biometrics.uidaho.edu
> No statement above necessarily represents my employer's opinion.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ggrothendieck at yifan.net  Sat Mar  8 02:50:52 2003
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Fri, 07 Mar 2003 20:50:52 -0500
Subject: [R] Re: General Matrix Inner Product?
Message-ID: <3E69062C.7047.22261A@localhost>

This is inefficient and its is not precisely the set of arguments you requested but its 
concise and perhaps its close enough.

> inner = function(a,b,f,g) apply(apply(outer(a,b,FUN=g),c(1,4),diag),2:3,f)
> a=matrix(1:8,2,4)
> b=t(a)
> inner(a,b,sum,"*")
     [,1] [,2]
[1,]   84  100
[2,]  100  120
> a%*%b
     [,1] [,2]
[1,]   84  100
[2,]  100  120
> inner(a,b,all,"==")
      [,1]  [,2]
[1,]  TRUE FALSE
[2,] FALSE  TRUE


From Bill.Venables at CMIS.CSIRO.AU  Sat Mar  8 06:41:29 2003
From: Bill.Venables at CMIS.CSIRO.AU (Bill.Venables@CMIS.CSIRO.AU)
Date: Sat, 8 Mar 2003 15:41:29 +1000 
Subject: [R] Type IV sum of squares
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A916593D@roper-cv.qld.cmis.CSIRO.AU>

I'm really puzzled to know what has caused the sudden rush on these kinds of
questions.

>  -----Original Message-----
> From: 	dth2 at u.washington.edu [mailto:dth2 at u.washington.edu] 
> Sent:	Saturday, March 08, 2003 1:27 AM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] Type IV sum of squares
> 
> To anyone who can help:
> 
> I am trying to do an analysis of variance with a very unbalanced design
> and a few empty cells.  How do I get R to use type III and more
> importantly type IV sums of squares?
> 
	[WNV]  My friendly advice is forget all that malarkey, and even
forget about putting it all in one big analysis of variance table.  Calmly
decide which null hypotheses you want to test within which outer hypotheses,
fit each null and each outer model, separately if necessary, test them using
anova( ) and report your results.

	Unbalanced designs and empty cells do not alter the general
procedure you should adopt one bit.  All they do is change the power of the
test, a fact of which you should be well aware, of course.  (In fact if the
design is really deficient you may find that you have a reduncancy and
cannot perform some of your tests, but that is a side issue and no 'Types'
of sums of squares can ever fix it - you need a better design to make any
progress.  )

	Hard as it may be to accept, that whole business of Type ? sums of
squares is a gigantic red herring and a distinction without a difference.
It would truly have been better if the concepts were never invented and
certainly not inflicted on a naive and unsuspecting whole statistical
generation.  This is one situation where curiously the reality is much
simpler than it might seem from some of the propaganda.

	Trust me: I'm a statistician...


> Thanks
> 
> Deven Hamilton
> Department of Sociology
> University of Washington
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Ted.Harding at nessie.mcc.ac.uk  Sat Mar  8 10:23:20 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 08 Mar 2003 09:23:20 -0000 (GMT)
Subject: [R] Type IV sum of squares
In-Reply-To: <E09E527B56BE2D438A3D6A246DDD27A916593D@roper-cv.qld.cmis.CSIRO.AU>
Message-ID: <XFMail.030308092320.Ted.Harding@nessie.mcc.ac.uk>

On 08-Mar-03 Bill.Venables at cmis.csiro.au wrote:
> I'm really puzzled to know what has caused the sudden rush on these
> kinds of questions.
> 
>       [WNV]  My friendly advice is forget all that malarkey, and even
> forget about putting it all in one big analysis of variance table. 
> Calmly decide which null hypotheses you want to test within which outer
> hypotheses, fit each null and each outer model, separately if necessary,
> test them using anova( ) and report your results.

Well, those are welcome commonsense words, to one who never understood
the "malarkey" and indeed found "Type I", "Type II", "Type III" to be
totally enigmatic terms for what seemed to be pointless distinctions.

>       Hard as it may be to accept, that whole business of Type ? sums of
> squares is a gigantic red herring and a distinction without a
> difference. It would truly have been better if the concepts were never
> invented and certainly not inflicted on a naive and unsuspecting whole
> statistical generation.  This is one situation where curiously the
> reality is much simpler than it might seem from some of the propaganda.

I'm curious as to how it came about -- that current of history (which
seems to be SAS-related) seems to have passed me by, alive and conscious
though I believe I was at the time ...

What really bothers me about it (and other things) these days is that
a Procedure With A Name becomes a fetish[*] to be worshipped by rituals
performed with a computer. The result of "propaganda"? I'm thankful that,
with R, it's quite hard to be irrational.

[*] Chambers' definition is to the point: "fetish: An object believed
    to procure for its owner the services of a spirit lodged within it:
    something regarded with irrational reverence."

>       Trust me: I'm a statistician...

But of which Type ... ?

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 08-Mar-03                                       Time: 09:23:20
------------------------------ XFMail ------------------------------


From p.dalgaard at biostat.ku.dk  Sat Mar  8 11:15:29 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Mar 2003 11:15:29 +0100
Subject: [R] Looking for non-central F quantile
In-Reply-To: <Pine.GHP.4.51.0303071640110.9749@raptor.csrv.uidaho.edu>
References: <Pine.GHP.4.51.0303071640110.9749@raptor.csrv.uidaho.edu>
Message-ID: <x2y93qyxj2.fsf@biostat.ku.dk>

Andrew Robinson <andrewr at uidaho.edu> writes:

> Greetings all,
> 
> I'm trying to figure out how to calculate the inverse CDF (i.e. a
> quantile) for a non-central F distribution.  I could put together a quick
> numerical solver routine using the CDF, but I wonder if there's a function
> that I've missed that would be more efficient?

If we had one, then there would have been an 'ncp' argument to qf()....
In my experience, uniroot() gets you there fast enough in most cases:

> uniroot(function(x)pf(x,ncp=3,4,20)-.995,c(0,1000))$root
[1] 8.301055

(BTW: That chased up a few buglets:

> pf(Inf,ncp=3,4,20)
[1] NaN
Warning message:
NaNs produced in: pnf(q, df1, df2, ncp, lower.tail, log.p)

Whereas

> pf(Inf,4,20)
[1] 1
 
which would also be a sensible result in the noncentral case. Also
-- and what I was trying -- it would be great if uniroot accepted
infinite limits, but it doesn't. Shouldn't be too hard...) 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From allende at cnb.uam.es  Sat Mar  8 12:40:43 2003
From: allende at cnb.uam.es (Ramon Alonso-Allende)
Date: Sat, 08 Mar 2003 12:40:43 +0100
Subject: Take care with codes()! (was [R] type of representation)
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C202F2C414@groexmb02.pfizer.com>
References: <D7A3CFD7825BD6119B880002A58F06C202F2C414@groexmb02.pfizer.com>
Message-ID: <3E69D6BB.90909@cnb.uam.es>

Hi

I have been ussing this code displayed while a go to do balloons plots.

My problem is that the labels of the data i'm working on now are to big 
and they overlap in the X axis.

Is there any way i can plot the text vertically or with some inclination?


Thanks

Ramon

Warnes, Gregory R wrote:
> Ahh yes, sorry about that.
> 
> Here's the corrected snippet:
> 
> # Create an Example Data Frame Containing Car x Color data
> carnames <- c("bmw","renault","mercedes","seat")
> carcolors <- c("red","white","silver","green")
> datavals <- round(rnorm(16, mean=10, sd=4),1)
> data <- data.frame(Car=rep(carnames,4),
>                    Color=rep(carcolors, c(4,4,4,4) ),
>                    Value=datavals )
> # show the data
> data
> 
> # plot the Car x Color combinations, using 'cex' to specify the dot size
> plot(x=as.numeric(data$Car),     # as.numeric give numeric values
>      y=as.numeric(data$Color), 
>      cex=data$Value/max(data$Value)*12,  # standardize size to (0,12)
>      pch=19,  # filled circle
>      col="skyblue", # dot color
>      xlab="Car", # x axis label
>      ylab="Color", # y axis label
>      xaxt="n", # no x axis lables
>      yaxt="n", # no y axis lables
>      bty="n",  # no box around the plot
>      xlim=c(0,nlevels(data$Car  )+0.5), # extra space on either end of plot
>      ylim=c(0.5,nlevels(data$Color)+1.5)  # so dots don't cross into margins
>      )
> 
> # add text labels
> text(x=1:nlevels(data$Car), y=nlevels(data$Car)+1, labels=levels(data$Car))
> text(x=0, y=1:nlevels(data$Color), labels=levels(data$Color) )
> 
> # add borders between cells
> abline(v=(0:nlevels(data$Car)+0.5))
> abline(h=(0:nlevels(data$Color)+0.5))
> 
> # annotate with actual values
> text(x=as.numeric(data$Car),     # as.numeric give numeric values
>      y=as.numeric(data$Color), 
>      labels=format(data$Value),       # label value
>      col="black", # textt color
>      )
> 
> # put a nice title
> title(main="Car by Color Popularity\n(Dot size proportional to popularity)")
> 
> 
> -Greg
> 
> 
>>-----Original Message-----
>>From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
>>Sent: Friday, January 03, 2003 1:53 PM
>>To: Warnes, Gregory R
>>Cc: 'allende at gredos.cnb.uam.es'; 'r-help at stat.math.ethz.ch'
>>Subject: RE: Take care with codes()! (was [R] type of representation)
>>
>>
>>From the help page of codes():
>>
>>     Normally `codes' is not the appropriate function to use with an
>>     unordered factor.  Use `unclass' or `as.numeric' to extract the
>>     codes used in the internal representation of the factor, as these
>>     do not assume that the codes are sorted.
>>
>>and this is one of the `normally' cases.  Your code will only work
>>correctly if the levels are in alphabetical order (in the 
>>locale in use).
>>
>>On Fri, 3 Jan 2003, Warnes, Gregory R wrote:
>>
>>
>>>How about this snippet:
>>>
>>># Create an Example Data Frame Containing Car x Color data
>>>carnames <- c("bmw","renault","mercedes","seat")
>>>carcolors <- c("red","white","silver","green")
>>>datavals <- round(rnorm(16, mean=10, sd=4),1)
>>>data <- data.frame(Car=rep(carnames,4),
>>>                   Color=rep(carcolors, c(4,4,4,4) ),
>>>                   Value=datavals )
>>># show the data
>>>data
>>>
>>># plot the Car x Color combinations, using 'cex' to specify 
>>
>>the dot size
>>
>>>plot(x=codes(data$Car),     # codes give numeric values
>>>     y=codes(data$Color),
>>>     cex=data$Value/max(data$Value)*12,  # standardize size 
>>
>>to (0,12)
>>
>>>     pch=19,  # filled circle
>>>     col="skyblue", # dot color
>>>     xlab="Car", # x axis label
>>>     ylab="Color", # y axis label
>>>     xaxt="n", # no x axis lables
>>>     yaxt="n", # no y axis lables
>>>     bty="n",  # no box around the plot
>>>     xlim=c(0,nlevels(data$Car  )+0.5), # extra space on 
>>
>>either end of plot
>>
>>>     ylim=c(0.5,nlevels(data$Color)+1.5)  # so dots don't 
>>
>>cross into margins
>>
>>>     )
>>>
>>># add text labels
>>>text(x=1:nlevels(data$Car), y=nlevels(data$Car)+1, 
>>
>>labels=levels(data$Car))
>>
>>>text(x=0, y=1:nlevels(data$Color), labels=levels(data$Color) )
>>>
>>># add borders between cells
>>>abline(v=(0:nlevels(data$Car)+0.5))
>>>abline(h=(0:nlevels(data$Color)+0.5))
>>>
>>># annotate with actual values
>>>text(x=codes(data$Car),     # codes give numeric values
>>>     y=codes(data$Color),
>>>     labels=format(data$Value),       # label value
>>>     col="black", # textt color
>>>     )
>>>
>>># put a nice title
>>>title(main="Car by Color Popularity\n(Dot size proportional 
>>
>>to popularity)")
>>
>>>
>>>-Greg
>>>
>>>
>>>>-----Original Message-----
>>>>From: allende at gredos.cnb.uam.es [mailto:allende at gredos.cnb.uam.es]
>>>>Sent: Friday, January 03, 2003 4:46 AM
>>>>To: r-help at stat.math.ethz.ch
>>>>Cc: allende at gredos.cnb.uam.es
>>>>Subject: [R] type of representation
>>>>
>>>>
>>>>Hi
>>>>
>>>>I have some data that i want to plot but i don't find how to
>>>>do it. I have car
>>>>types (bmw,renault,mercedes,seat ...), colors and a number
>>>>for each car
>>>>type-color relation.I want to come up with a matrix
>>>>representation of cars vs
>>>>colors where in each intersection i could set a dot
>>>>proportional in size to my
>>>>third variable.
>>>>
>>>>
>>>>Can anybody give me a clue of hoe to come up with such 
>>
>>representation.
>>
>>>>Thanks
>>>>
>>>>Ramon
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>>
>>>
>>>
>>>LEGAL NOTICE\ Unless expressly stated otherwise, this 
>>
>>message is ... [[dropped]]
>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>
>>
>>-- 
>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>1 South Parks Road,                     +44 1865 272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
> 
> 
> 
> LEGAL NOTICE
> Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
> 
> 

-- 
Ramon Alonso-Allende Erhardt			Tel: 91 585 46 76
Protein Design Group		   		fax: 91 585 45 06
CNB/CSIC Campus U. Autonoma. Cantoblanco  Madrid 28049
http://www.pdg.cnb.uam.es/allende/index.html


From JensScheidtmann at web.de  Sat Mar  8 15:31:48 2003
From: JensScheidtmann at web.de (Jens Scheidtmann)
Date: Sat, 8 Mar 2003 15:31:48 +0100
Subject: [R] FIX: pscales=list(...) and splom
Message-ID: <NGBBIMNFDMIPAKBNONMIAECLCAAA.JensScheidtmann@web.de>

Dear R Users,

When plotting with "splom" I tried to use the pscales=list(...) feature
Unfortunately it didn't work at all. Instead the scales always were
suppressed.

So I looked at the source of panel.pairs and found:

"draw <- is.numeric(pscales) && pscales != 0"

which rather has to be:

"draw <- is.list(pscales) || (is.numeric(pscales) && pscales != 0)"

With this change, the axis labels could be generated from the
supplied ...$at and ...$lab components of the pscales entries.
(BTW: the documentation says the components should be $at and $labels. This
is wrong!)

But....

* The limits of the axes are still generated from the data.

To make panel.pairs honor the ranges supplied in the pscales list, one has
to change

--snip--
  if (n.var > 0) {
    lim <- list(1:n.var)
    for (i in 1:n.var) {
      lim[[i]] <- extend.limits(range(as.numeric(z[, i]),
                                      na.rm = TRUE))
    }
  }
--snap--

to

--snippi--
  if (n.var > 0) {
    lim <- list(1:n.var)
    for (i in 1:n.var) {
      lim[[i]] <- extend.limits(range(as.numeric(z[, i]),
                                      na.rm = TRUE))
      if (is.list(pscales)) {
        lim[[i]] <- extend.limits(range(pscales[[i]]$at))
      }
    }
  }
--snappi--

* The labels are still not as expected.

To fix these, occurences of "as.character(axls ..." have to be replaced by
"labels ..."
(see enclosed diff).

Now a call like the following works and displays
the correct ranges and labels:

--snippa--
# Let axes start by 0 and use other decimal separator
pscal <- list(1:4)
pscal[[1]] <- list(at=seq(0,10,2), lab=paste(seq(0,10,2)))
pscal[[2]] <- list(at=seq(0,5,1), lab=paste(seq(0,5,1)))
pscal[[3]] <- list(at=seq(0,8,2), lab=paste(seq(0,8,2)))
pscal[[4]] <- list(at=seq(0,3,0.5),
lab=format(seq(0,3,0.5),decimal.mark=","))
str(pscal)
splom(~iris[1:4], groups = Species, data = iris,
      panel = panel.superpose,
      key = list(title = "Three Varieties of Iris",
        columns = 3,
        points = list(pch = super.sym$pch[1:3],
          col = super.sym$col[1:3]),
        text = list(c("Setosa", "Versicolor", "Virginica"))),
      pscale=pscal)
--snappa--

Please CC me on your replies, because I am not subscribed to this list.
Thanks.

HTH,

Jens

--
Jens Scheidtmann
Germany
-------------- next part --------------
A non-text attachment was scrubbed...
Name: panel.pairs.diff
Type: application/octet-stream
Size: 6777 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030308/5bbf0a63/panel.pairs.obj

From gregory_r_warnes at groton.pfizer.com  Sat Mar  8 16:12:11 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Sat, 8 Mar 2003 10:12:11 -0500 
Subject: [R] RE: Text Rotation (was: Take care with codes()!)
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C6A5@groexmb02.pfizer.com>


You can use the graphics parameter "srt" to rotate displayed text by a
specified number of degrees, e.g. srt=45 to put it on an angle, srt=90 to
put it vertical.  

If you do this, may need to modify the call to text to increase ylim and
change the plot location to give you more room.

I'm working to update the 'balloonplot' function in the gregmisc package now
to handle this case gracefully.

-Greg


> -----Original Message-----
> From: Ramon Alonso-Allende [mailto:allende at cnb.uam.es]
> Sent: Saturday, March 08, 2003 6:41 AM
> To: Warnes, Gregory R
> Cc: 'ripley at stats.ox.ac.uk'; 'r-help at stat.math.ethz.ch'
> Subject: Re: Take care with codes()! (was [R] type of representation)
> 
> 
> Hi
> 
> I have been ussing this code displayed while a go to do 
> balloons plots.
> 
> My problem is that the labels of the data i'm working on now 
> are to big 
> and they overlap in the X axis.
> 
> Is there any way i can plot the text vertically or with some 
> inclination?
> 
> 
> Thanks
> 
> Ramon
> 
> Warnes, Gregory R wrote:
> > Ahh yes, sorry about that.
> > 
> > Here's the corrected snippet:
> > 
> > # Create an Example Data Frame Containing Car x Color data
> > carnames <- c("bmw","renault","mercedes","seat")
> > carcolors <- c("red","white","silver","green")
> > datavals <- round(rnorm(16, mean=10, sd=4),1)
> > data <- data.frame(Car=rep(carnames,4),
> >                    Color=rep(carcolors, c(4,4,4,4) ),
> >                    Value=datavals )
> > # show the data
> > data
> > 
> > # plot the Car x Color combinations, using 'cex' to specify 
> the dot size
> > plot(x=as.numeric(data$Car),     # as.numeric give numeric values
> >      y=as.numeric(data$Color), 
> >      cex=data$Value/max(data$Value)*12,  # standardize size 
> to (0,12)
> >      pch=19,  # filled circle
> >      col="skyblue", # dot color
> >      xlab="Car", # x axis label
> >      ylab="Color", # y axis label
> >      xaxt="n", # no x axis lables
> >      yaxt="n", # no y axis lables
> >      bty="n",  # no box around the plot
> >      xlim=c(0,nlevels(data$Car  )+0.5), # extra space on 
> either end of plot
> >      ylim=c(0.5,nlevels(data$Color)+1.5)  # so dots don't 
> cross into margins
> >      )
> > 
> > # add text labels
> > text(x=1:nlevels(data$Car), y=nlevels(data$Car)+1, 
> labels=levels(data$Car))
> > text(x=0, y=1:nlevels(data$Color), labels=levels(data$Color) )
> > 
> > # add borders between cells
> > abline(v=(0:nlevels(data$Car)+0.5))
> > abline(h=(0:nlevels(data$Color)+0.5))
> > 
> > # annotate with actual values
> > text(x=as.numeric(data$Car),     # as.numeric give numeric values
> >      y=as.numeric(data$Color), 
> >      labels=format(data$Value),       # label value
> >      col="black", # textt color
> >      )
> > 
> > # put a nice title
> > title(main="Car by Color Popularity\n(Dot size proportional 
> to popularity)")
> > 
> > 
> > -Greg
> > 
> > 
> >>-----Original Message-----
> >>From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> >>Sent: Friday, January 03, 2003 1:53 PM
> >>To: Warnes, Gregory R
> >>Cc: 'allende at gredos.cnb.uam.es'; 'r-help at stat.math.ethz.ch'
> >>Subject: RE: Take care with codes()! (was [R] type of 
> representation)
> >>
> >>
> >>From the help page of codes():
> >>
> >>     Normally `codes' is not the appropriate function to use with an
> >>     unordered factor.  Use `unclass' or `as.numeric' to extract the
> >>     codes used in the internal representation of the 
> factor, as these
> >>     do not assume that the codes are sorted.
> >>
> >>and this is one of the `normally' cases.  Your code will only work
> >>correctly if the levels are in alphabetical order (in the 
> >>locale in use).
> >>
> >>On Fri, 3 Jan 2003, Warnes, Gregory R wrote:
> >>
> >>
> >>>How about this snippet:
> >>>
> >>># Create an Example Data Frame Containing Car x Color data
> >>>carnames <- c("bmw","renault","mercedes","seat")
> >>>carcolors <- c("red","white","silver","green")
> >>>datavals <- round(rnorm(16, mean=10, sd=4),1)
> >>>data <- data.frame(Car=rep(carnames,4),
> >>>                   Color=rep(carcolors, c(4,4,4,4) ),
> >>>                   Value=datavals )
> >>># show the data
> >>>data
> >>>
> >>># plot the Car x Color combinations, using 'cex' to specify 
> >>
> >>the dot size
> >>
> >>>plot(x=codes(data$Car),     # codes give numeric values
> >>>     y=codes(data$Color),
> >>>     cex=data$Value/max(data$Value)*12,  # standardize size 
> >>
> >>to (0,12)
> >>
> >>>     pch=19,  # filled circle
> >>>     col="skyblue", # dot color
> >>>     xlab="Car", # x axis label
> >>>     ylab="Color", # y axis label
> >>>     xaxt="n", # no x axis lables
> >>>     yaxt="n", # no y axis lables
> >>>     bty="n",  # no box around the plot
> >>>     xlim=c(0,nlevels(data$Car  )+0.5), # extra space on 
> >>
> >>either end of plot
> >>
> >>>     ylim=c(0.5,nlevels(data$Color)+1.5)  # so dots don't 
> >>
> >>cross into margins
> >>
> >>>     )
> >>>
> >>># add text labels
> >>>text(x=1:nlevels(data$Car), y=nlevels(data$Car)+1, 
> >>
> >>labels=levels(data$Car))
> >>
> >>>text(x=0, y=1:nlevels(data$Color), labels=levels(data$Color) )
> >>>
> >>># add borders between cells
> >>>abline(v=(0:nlevels(data$Car)+0.5))
> >>>abline(h=(0:nlevels(data$Color)+0.5))
> >>>
> >>># annotate with actual values
> >>>text(x=codes(data$Car),     # codes give numeric values
> >>>     y=codes(data$Color),
> >>>     labels=format(data$Value),       # label value
> >>>     col="black", # textt color
> >>>     )
> >>>
> >>># put a nice title
> >>>title(main="Car by Color Popularity\n(Dot size proportional 
> >>
> >>to popularity)")
> >>
> >>>
> >>>-Greg
> >>>
> >>>
> >>>>-----Original Message-----
> >>>>From: allende at gredos.cnb.uam.es [mailto:allende at gredos.cnb.uam.es]
> >>>>Sent: Friday, January 03, 2003 4:46 AM
> >>>>To: r-help at stat.math.ethz.ch
> >>>>Cc: allende at gredos.cnb.uam.es
> >>>>Subject: [R] type of representation
> >>>>
> >>>>
> >>>>Hi
> >>>>
> >>>>I have some data that i want to plot but i don't find how to
> >>>>do it. I have car
> >>>>types (bmw,renault,mercedes,seat ...), colors and a number
> >>>>for each car
> >>>>type-color relation.I want to come up with a matrix
> >>>>representation of cars vs
> >>>>colors where in each intersection i could set a dot
> >>>>proportional in size to my
> >>>>third variable.
> >>>>
> >>>>
> >>>>Can anybody give me a clue of hoe to come up with such 
> >>
> >>representation.
> >>
> >>>>Thanks
> >>>>
> >>>>Ramon
> >>>>
> >>>>______________________________________________
> >>>>R-help at stat.math.ethz.ch mailing list
> >>>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>>>
> >>>
> >>>
> >>>LEGAL NOTICE\ Unless expressly stated otherwise, this 
> >>
> >>message is ... [[dropped]]
> >>
> >>>______________________________________________
> >>>R-help at stat.math.ethz.ch mailing list
> >>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>>
> >>
> >>-- 
> >>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>University of Oxford,             Tel:  +44 1865 272861 (self)
> >>1 South Parks Road,                     +44 1865 272866 (PA)
> >>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>
> > 
> > 
> > 
> > LEGAL NOTICE
> > Unless expressly stated otherwise, this message is 
> confidential and may be privileged. It is intended for the 
> addressee(s) only. Access to this E-mail by anyone else is 
> unauthorized. If you are not an addressee, any disclosure or 
> copying of the contents of this E-mail or any action taken 
> (or not taken) in reliance on it is unauthorized and may be 
> unlawful. If you are not an addressee, please inform the 
> sender immediately.
> > 
> > 
> 
> -- 
> Ramon Alonso-Allende Erhardt			Tel: 91 585 46 76
> Protein Design Group		   		fax: 91 585 45 06
> CNB/CSIC Campus U. Autonoma. Cantoblanco  Madrid 28049
> http://www.pdg.cnb.uam.es/allende/index.html
> 
>


From gregory_r_warnes at groton.pfizer.com  Sat Mar  8 17:56:55 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Sat, 8 Mar 2003 11:56:55 -0500 
Subject: [R] RE: Text Rotation (was: Take care with codes()!)
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C6A8@groexmb02.pfizer.com>


I've just uploaded gregmisc_0.8.2.tar.gz to CRAN. It should show up in the
package repository in a day or two.  

This version of the gregmisc package provides an enhanced 'balloonplot'
function with 'rowsrt', 'colsrt' arguments to control rotation of the
labels, and 'rowmar', 'colmar' to control the amount of space reserved for
the labels.  

Here's an example:


# Create an Example Data Frame Containing Car x Color data, with long car
names
carnames <- c("BMW: High End, German",
              "Renault: Medium End, French",
              "Mercedes: High End, German", 
              "Seat: Imaginary, Unknown Producer")
carcolors <- c("red","white","silver","green")
datavals <- round(rnorm(16, mean=100, sd=60),1)
data <- data.frame(Car=rep(carnames,4),
                   Color=rep(carcolors, c(4,4,4,4) ),
                   Value=datavals )

# generate balloon plot with default scaling, the column labels will overlap
balloonplot( data$Color, data$Car, data$Value)


# try again, with column labels rodated 90 degrees, and given more space
balloonplot( data$Car, data$Color, data$Value, colmar=3, colsrt=90)

-Greg

> -----Original Message-----
> From: Warnes, Gregory R 
> Sent: Saturday, March 08, 2003 10:12 AM
> To: 'Ramon Alonso-Allende'; Warnes, Gregory R
> Cc: 'ripley at stats.ox.ac.uk'; 'r-help at stat.math.ethz.ch'
> Subject: RE: Text Rotation (was: Take care with codes()!)
> 
> 
> 
> You can use the graphics parameter "srt" to rotate displayed 
> text by a specified number of degrees, e.g. srt=45 to put it 
> on an angle, srt=90 to put it vertical.  
> 
> If you do this, may need to modify the call to text to 
> increase ylim and change the plot location to give you more room.
> 
> I'm working to update the 'balloonplot' function in the 
> gregmisc package now to handle this case gracefully.
> 
> -Greg
> 
> 
> > -----Original Message-----
> > From: Ramon Alonso-Allende [mailto:allende at cnb.uam.es]
> > Sent: Saturday, March 08, 2003 6:41 AM
> > To: Warnes, Gregory R
> > Cc: 'ripley at stats.ox.ac.uk'; 'r-help at stat.math.ethz.ch'
> > Subject: Re: Take care with codes()! (was [R] type of 
> representation)
> > 
> > 
> > Hi
> > 
> > I have been ussing this code displayed while a go to do 
> > balloons plots.
> > 
> > My problem is that the labels of the data i'm working on now 
> > are to big 
> > and they overlap in the X axis.
> > 
> > Is there any way i can plot the text vertically or with some 
> > inclination?
> > 
> > 
> > Thanks
> > 
> > Ramon
> > 
> > Warnes, Gregory R wrote:
> > > Ahh yes, sorry about that.
> > > 
> > > Here's the corrected snippet:
> > > 
> > > # Create an Example Data Frame Containing Car x Color data
> > > carnames <- c("bmw","renault","mercedes","seat")
> > > carcolors <- c("red","white","silver","green")
> > > datavals <- round(rnorm(16, mean=10, sd=4),1)
> > > data <- data.frame(Car=rep(carnames,4),
> > >                    Color=rep(carcolors, c(4,4,4,4) ),
> > >                    Value=datavals )
> > > # show the data
> > > data
> > > 
> > > # plot the Car x Color combinations, using 'cex' to specify 
> > the dot size
> > > plot(x=as.numeric(data$Car),     # as.numeric give numeric values
> > >      y=as.numeric(data$Color), 
> > >      cex=data$Value/max(data$Value)*12,  # standardize size 
> > to (0,12)
> > >      pch=19,  # filled circle
> > >      col="skyblue", # dot color
> > >      xlab="Car", # x axis label
> > >      ylab="Color", # y axis label
> > >      xaxt="n", # no x axis lables
> > >      yaxt="n", # no y axis lables
> > >      bty="n",  # no box around the plot
> > >      xlim=c(0,nlevels(data$Car  )+0.5), # extra space on 
> > either end of plot
> > >      ylim=c(0.5,nlevels(data$Color)+1.5)  # so dots don't 
> > cross into margins
> > >      )
> > > 
> > > # add text labels
> > > text(x=1:nlevels(data$Car), y=nlevels(data$Car)+1, 
> > labels=levels(data$Car))
> > > text(x=0, y=1:nlevels(data$Color), labels=levels(data$Color) )
> > > 
> > > # add borders between cells
> > > abline(v=(0:nlevels(data$Car)+0.5))
> > > abline(h=(0:nlevels(data$Color)+0.5))
> > > 
> > > # annotate with actual values
> > > text(x=as.numeric(data$Car),     # as.numeric give numeric values
> > >      y=as.numeric(data$Color), 
> > >      labels=format(data$Value),       # label value
> > >      col="black", # textt color
> > >      )
> > > 
> > > # put a nice title
> > > title(main="Car by Color Popularity\n(Dot size proportional 
> > to popularity)")
> > > 
> > > 
> > > -Greg
> > > 
> > > 
> > >>-----Original Message-----
> > >>From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> > >>Sent: Friday, January 03, 2003 1:53 PM
> > >>To: Warnes, Gregory R
> > >>Cc: 'allende at gredos.cnb.uam.es'; 'r-help at stat.math.ethz.ch'
> > >>Subject: RE: Take care with codes()! (was [R] type of 
> > representation)
> > >>
> > >>
> > >>From the help page of codes():
> > >>
> > >>     Normally `codes' is not the appropriate function to 
> use with an
> > >>     unordered factor.  Use `unclass' or `as.numeric' to 
> extract the
> > >>     codes used in the internal representation of the 
> > factor, as these
> > >>     do not assume that the codes are sorted.
> > >>
> > >>and this is one of the `normally' cases.  Your code will only work
> > >>correctly if the levels are in alphabetical order (in the 
> > >>locale in use).
> > >>
> > >>On Fri, 3 Jan 2003, Warnes, Gregory R wrote:
> > >>
> > >>
> > >>>How about this snippet:
> > >>>
> > >>># Create an Example Data Frame Containing Car x Color data
> > >>>carnames <- c("bmw","renault","mercedes","seat")
> > >>>carcolors <- c("red","white","silver","green")
> > >>>datavals <- round(rnorm(16, mean=10, sd=4),1)
> > >>>data <- data.frame(Car=rep(carnames,4),
> > >>>                   Color=rep(carcolors, c(4,4,4,4) ),
> > >>>                   Value=datavals )
> > >>># show the data
> > >>>data
> > >>>
> > >>># plot the Car x Color combinations, using 'cex' to specify 
> > >>
> > >>the dot size
> > >>
> > >>>plot(x=codes(data$Car),     # codes give numeric values
> > >>>     y=codes(data$Color),
> > >>>     cex=data$Value/max(data$Value)*12,  # standardize size 
> > >>
> > >>to (0,12)
> > >>
> > >>>     pch=19,  # filled circle
> > >>>     col="skyblue", # dot color
> > >>>     xlab="Car", # x axis label
> > >>>     ylab="Color", # y axis label
> > >>>     xaxt="n", # no x axis lables
> > >>>     yaxt="n", # no y axis lables
> > >>>     bty="n",  # no box around the plot
> > >>>     xlim=c(0,nlevels(data$Car  )+0.5), # extra space on 
> > >>
> > >>either end of plot
> > >>
> > >>>     ylim=c(0.5,nlevels(data$Color)+1.5)  # so dots don't 
> > >>
> > >>cross into margins
> > >>
> > >>>     )
> > >>>
> > >>># add text labels
> > >>>text(x=1:nlevels(data$Car), y=nlevels(data$Car)+1, 
> > >>
> > >>labels=levels(data$Car))
> > >>
> > >>>text(x=0, y=1:nlevels(data$Color), labels=levels(data$Color) )
> > >>>
> > >>># add borders between cells
> > >>>abline(v=(0:nlevels(data$Car)+0.5))
> > >>>abline(h=(0:nlevels(data$Color)+0.5))
> > >>>
> > >>># annotate with actual values
> > >>>text(x=codes(data$Car),     # codes give numeric values
> > >>>     y=codes(data$Color),
> > >>>     labels=format(data$Value),       # label value
> > >>>     col="black", # textt color
> > >>>     )
> > >>>
> > >>># put a nice title
> > >>>title(main="Car by Color Popularity\n(Dot size proportional 
> > >>
> > >>to popularity)")
> > >>
> > >>>
> > >>>-Greg
> > >>>
> > >>>
> > >>>>-----Original Message-----
> > >>>>From: allende at gredos.cnb.uam.es 
> [mailto:allende at gredos.cnb.uam.es]
> > >>>>Sent: Friday, January 03, 2003 4:46 AM
> > >>>>To: r-help at stat.math.ethz.ch
> > >>>>Cc: allende at gredos.cnb.uam.es
> > >>>>Subject: [R] type of representation
> > >>>>
> > >>>>
> > >>>>Hi
> > >>>>
> > >>>>I have some data that i want to plot but i don't find how to
> > >>>>do it. I have car
> > >>>>types (bmw,renault,mercedes,seat ...), colors and a number
> > >>>>for each car
> > >>>>type-color relation.I want to come up with a matrix
> > >>>>representation of cars vs
> > >>>>colors where in each intersection i could set a dot
> > >>>>proportional in size to my
> > >>>>third variable.
> > >>>>
> > >>>>
> > >>>>Can anybody give me a clue of hoe to come up with such 
> > >>
> > >>representation.
> > >>
> > >>>>Thanks
> > >>>>
> > >>>>Ramon
> > >>>>
> > >>>>______________________________________________
> > >>>>R-help at stat.math.ethz.ch mailing list
> > >>>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >>>>
> > >>>
> > >>>
> > >>>LEGAL NOTICE\ Unless expressly stated otherwise, this 
> > >>
> > >>message is ... [[dropped]]
> > >>
> > >>>______________________________________________
> > >>>R-help at stat.math.ethz.ch mailing list
> > >>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >>>
> > >>
> > >>-- 
> > >>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > >>Professor of Applied Statistics,  
> http://www.stats.ox.ac.uk/~ripley/
> > >>University of Oxford,             Tel:  +44 1865 272861 (self)
> > >>1 South Parks Road,                     +44 1865 272866 (PA)
> > >>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > >>
> > > 
> > > 
> > > 
> > > LEGAL NOTICE
> > > Unless expressly stated otherwise, this message is 
> > confidential and may be privileged. It is intended for the 
> > addressee(s) only. Access to this E-mail by anyone else is 
> > unauthorized. If you are not an addressee, any disclosure or 
> > copying of the contents of this E-mail or any action taken 
> > (or not taken) in reliance on it is unauthorized and may be 
> > unlawful. If you are not an addressee, please inform the 
> > sender immediately.
> > > 
> > > 
> > 
> > -- 
> > Ramon Alonso-Allende Erhardt			Tel: 91 
> 585 46 76
> > Protein Design Group		   		fax: 91 
> 585 45 06
> > CNB/CSIC Campus U. Autonoma. Cantoblanco  Madrid 28049
> > http://www.pdg.cnb.uam.es/allende/index.html
> > 
> > 
>


From hongqin at uchicago.edu  Sat Mar  8 18:01:20 2003
From: hongqin at uchicago.edu (hongqin)
Date: Sat, 8 Mar 2003 11:01:20 -0600
Subject: [R] How to store histogram plots
Message-ID: <001101c2e594$581225a0$0a688780@uchicago.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030308/3dbe0448/attachment.pl

From juli at ceam.es  Sat Mar  8 19:07:13 2003
From: juli at ceam.es (juli g. pausas)
Date: Sat, 08 Mar 2003 19:07:13 +0100
Subject: [R] hist() basic question
Message-ID: <3E6A3151.6080506@ceam.es>

Hi,
This is a very basic question, but I would like to undestand hist(). I 
thought that the hist( , freq=FALSE) should provide the relative 
frequencies (probabilities), and so they should sum 1, however:

set.seed(2)
ah <- hist(rnorm(100), freq=F)
sum(ah$intensities)
[1] 2

set.seed(2)
bh <- hist(rlnorm(100), freq=F)
sum(bh$intensities)
[1] 0.4999996

I'm getting similar figures with truehist() in MASS.
So I suppose I'm misunderstanding hist(). Any help?

Thanks

Juli


From ripley at stats.ox.ac.uk  Sat Mar  8 19:22:42 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 8 Mar 2003 18:22:42 +0000 (GMT)
Subject: [R] hist() basic question
In-Reply-To: <3E6A3151.6080506@ceam.es>
Message-ID: <Pine.LNX.4.44.0303081821040.27071-100000@gannet.stats>

A histogram has area one, not sum one.  From ?truehist

Details:

     This plots a true histogram, a density estimate of total area 1. 


On Sat, 8 Mar 2003, juli g. pausas wrote:

> Hi,
> This is a very basic question, but I would like to undestand hist(). I 
> thought that the hist( , freq=FALSE) should provide the relative 
> frequencies (probabilities), and so they should sum 1, however:
> 
> set.seed(2)
> ah <- hist(rnorm(100), freq=F)
> sum(ah$intensities)
> [1] 2
> 
> set.seed(2)
> bh <- hist(rlnorm(100), freq=F)
> sum(bh$intensities)
> [1] 0.4999996
> 
> I'm getting similar figures with truehist() in MASS.
> So I suppose I'm misunderstanding hist(). Any help?
> 
> Thanks
> 
> Juli
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Sat Mar  8 19:31:45 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 8 Mar 2003 10:31:45 -0800 (PST)
Subject: [R] hist() basic question
In-Reply-To: <3E6A3151.6080506@ceam.es>
Message-ID: <Pine.A41.4.44.0303081028320.212344-100000@homer06.u.washington.edu>

On Sat, 8 Mar 2003, juli g. pausas wrote:

> Hi,
> This is a very basic question, but I would like to undestand hist(). I
> thought that the hist( , freq=FALSE) should provide the relative
> frequencies (probabilities), and so they should sum 1, however:

No, it provides probability *densities*, which *integrate* to 1.

That is, the height of the bar is the relative frequency divided by the
width of the interval.  This is important because
  - it means histograms with different cutpoints are comparable
  - it means histograms are comparable with mathematical densities such as
a Normal, and with kernel density estimates
  - it means that the bars don't have to have the same width.

If histograms plotted relative frequencies there would be no need to
distinguish them from barplots.

	-thomas


From rg117 at yahoo.co.uk  Sat Mar  8 19:37:25 2003
From: rg117 at yahoo.co.uk (=?iso-8859-1?q?Rishabh=20Gupta?=)
Date: Sat, 8 Mar 2003 18:37:25 +0000 (GMT)
Subject: [R] hist() basic question
In-Reply-To: <Pine.A41.4.44.0303081028320.212344-100000@homer06.u.washington.edu>
Message-ID: <20030308183725.68019.qmail@web41106.mail.yahoo.com>

 --- Thomas Lumley <tlumley at u.washington.edu> wrote: > On Sat, 8 Mar 2003, juli g. pausas wrote:
> 
> > Hi,
> > This is a very basic question, but I would like to undestand hist(). I
> > thought that the hist( , freq=FALSE) should provide the relative
> > frequencies (probabilities), and so they should sum 1, however:
> 
> No, it provides probability *densities*, which *integrate* to 1.
> 
> That is, the height of the bar is the relative frequency divided by the
> width of the interval.  This is important because
>   - it means histograms with different cutpoints are comparable
>   - it means histograms are comparable with mathematical densities such as
> a Normal, and with kernel density estimates
>   - it means that the bars don't have to have the same width.
> 
> If histograms plotted relative frequencies there would be no need to
> distinguish them from barplots.
> 
> 	-thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help 

__________________________________________________

Everything you'll ever need on one web page
from News and Sport to Email and Music Charts


From spencer.graves at pdf.com  Sat Mar  8 20:54:18 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 08 Mar 2003 11:54:18 -0800
Subject: [R] How to transfer lists to other computers or to S-Plus
Message-ID: <3E6A4A6A.4080303@pdf.com>

Hi, All:

How can I transfer complicated objects like lists or a set of several 
objects from one computer to another or from R to S-Plus?

With S-Plus, I've used "data.dump" and "data.restore".  Package 
"foreign" in R has "data.restore" but not "data.dump", and the 
documentation for "data.restore" says that certain objects like formulas 
and functions may get mangled.

Thanks,
Spencer Graves


From ripley at stats.ox.ac.uk  Sat Mar  8 21:07:55 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 8 Mar 2003 20:07:55 +0000 (GMT)
Subject: [R] How to transfer lists to other computers or to S-Plus
In-Reply-To: <3E6A4A6A.4080303@pdf.com>
Message-ID: <Pine.LNX.4.44.0303082006000.29841-100000@gannet.stats>

dump()/source() is your best bet.  In some versions of S-PLUS, you may 
need to increase options(digits=) before dumping.

On Sat, 8 Mar 2003, Spencer Graves wrote:

> How can I transfer complicated objects like lists or a set of several 
> objects from one computer to another or from R to S-Plus?
> 
> With S-Plus, I've used "data.dump" and "data.restore".  Package 
> "foreign" in R has "data.restore" but not "data.dump", and the 
> documentation for "data.restore" says that certain objects like formulas 
> and functions may get mangled.

(They are intended for people with S-PLUS data.dump's and no S-PLUS.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From shutnik_xx at yahoo.co.uk  Sat Mar  8 22:14:44 2003
From: shutnik_xx at yahoo.co.uk (=?iso-8859-1?q?Shutnik?=)
Date: Sat, 8 Mar 2003 21:14:44 +0000 (GMT)
Subject: [R] where is kurtosis??
Message-ID: <20030308211444.76825.qmail@web10907.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030308/675f4500/attachment.pl

From meyer at ci.tuwien.ac.at  Sat Mar  8 22:27:22 2003
From: meyer at ci.tuwien.ac.at (David Meyer)
Date: Sat, 8 Mar 2003 22:27:22 +0100 (CET)
Subject: [R] where is kurtosis??
In-Reply-To: <20030308211444.76825.qmail@web10907.mail.yahoo.com>
Message-ID: <Pine.LNX.4.21.0303082226540.14660-100000@boromir.ci.tuwien.ac.at>


E.g., in package e1071.

best,
-d

        Mag. David Meyer            Wiedner Hauptstrasse 8-10
Vienna University of Technology     A-1040 Vienna/AUSTRIA
         Department of              Tel.: (+431) 58801/10772
Statistics and Probability Theory   Fax.: (+431) 58801/10798






On Sat, 8 Mar 2003, Shutnik wrote:

>  Dear friends,
>  I try to get started with R and can?t estimate kurtosis of a random sample by using one command. I have installed R 1.6.2. Please help.
> 
>  Max
> 
> 
> 
> 
> ---------------------------------
> 
> ur needs
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From caumann at wam.umd.edu  Sat Mar  8 23:40:20 2003
From: caumann at wam.umd.edu (Craig Aumann)
Date: Sat, 8 Mar 2003 17:40:20 -0500 (EST)
Subject: [R] Getting rid of "outer box" in cloud()
Message-ID: <Pine.SOL.4.44.0303081735070.20950-100000@rac3.wam.umd.edu>


I'm using the "cloud()" function to plot some data, but
cloud (and also wireframe) put an external box around the entire plot.
I can't figure out how to get rid of this external box.  How do I turn it
off?

There are cases when you want each plot to be sitting
inside a box (the last example on the cloud() help page, for example), but
I don't want this for what I am doing.

Please cc me with any suggestions.

Thanks!

Craig Aumann
Department of Biology
University of Maryland,
College Park, MD 20742
301-587-4924


From martin.renner at stonebow.otago.ac.nz  Sun Mar  9 00:37:28 2003
From: martin.renner at stonebow.otago.ac.nz (Martin Renner)
Date: Sat, 8 Mar 2003 20:07:28 -0330
Subject: [R] Re: Followup: copy-paste graphics from R to Word on Mac OS X
In-Reply-To: <Pine.LNX.4.44.0303061955040.3242-100000@gannet.stats>
References: <Pine.LNX.4.44.0303061955040.3242-100000@gannet.stats>
Message-ID: <p05200f02ba8ec35e1cdf@[134.153.153.21]>

I am just reproducing the text in the dialog boxes while not really 
knowing how OS X handles font names internally. I have a font called 
ZapfDingsbat on my system but in the dialog boxes it's called Zapf 
Dingsbat (with a space). This does not seem to be the main problem, 
however, since the dots in a scatterplot are displayed fine when 
importing a PDF generated by R into Word. All the axis labels, 
however, are missing. I don't know what goes wrong (or whether the 
bug is with R or OS X) but opening the PDF in Freehand and then 
saving it again seems to fix the problem. My gut feeling is that 
Illustrator (which uses PDF natively) should be able to handle a 
correct PDF. Just my 2 cents.


>This is misinformation: the font name in the PDF specifications is
>ZapfDingbats, and that is what the R driver uses, as in
>
><<
>/Type /Font
>/Subtype /Type1
>/Name /F6
>/BaseFont /ZapfDingbats
>>>
>
>I hope you have sent a suitable bug report to the supplier of your tools.x
>
>On Thu, 6 Mar 2003, Martin Renner wrote:
>
>>  I had the same problem and came to this solution:
>>
>>  - use pdf() to create a pdf file
>>  - open PDF in Freehand,
>>          during open replace fonts: ZapfDingsbat for Zapf Dingsbat
>>  - save as PDF or EPS and import this into word - bingo
>>
>>  The pdf files created by pdf() seem less than perfect - on my system
>>  (Mac OS X) Illustrator refuses open these files and in Preview or
>>  Word any axis label disappear. Maybe someone here knows enough about
>  > the PDF format to suggest how to fix this rather complicated path.
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ihaka at stat.auckland.ac.nz  Sun Mar  9 00:39:07 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Sun, 09 Mar 2003 12:39:07 +1300
Subject: [R] where is kurtosis??
References: <20030308211444.76825.qmail@web10907.mail.yahoo.com>
Message-ID: <3E6A7F1B.1030602@stat.auckland.ac.nz>

Shutnik wrote:
>  Dear friends,
>  I try to get started with R and can?t estimate kurtosis of a random sample by using one command.

Its probably worth saying that the point of a computing environment like 
R is that you can easily extend the environment by defining your own 
functions.  In the case of kurtosis you could use something like:

kurtosis <- function(x) {
	x <- x[!is.na(x)]
	sum( (x-mean(x))^4 )/ ((length(x) - 1) * var(x)^2)
}

or

kurtosis <- function(x) {
	x <- x[!is.na(x)]
	sum( (x-mean(x))^4 )/ ((length(x) - 1) * var(x)^2) - 3
}


-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand


From deepayan at stat.wisc.edu  Sun Mar  9 01:03:14 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 8 Mar 2003 18:03:14 -0600
Subject: [R] Getting rid of "outer box" in cloud()
In-Reply-To: <Pine.SOL.4.44.0303081735070.20950-100000@rac3.wam.umd.edu>
References: <Pine.SOL.4.44.0303081735070.20950-100000@rac3.wam.umd.edu>
Message-ID: <200303081803.15004.deepayan@stat.wisc.edu>

On Saturday 08 March 2003 04:40 pm, Craig Aumann wrote:
> I'm using the "cloud()" function to plot some data, but
> cloud (and also wireframe) put an external box around the entire plot.
> I can't figure out how to get rid of this external box.  How do I turn it
> off?

You can't currently. 

There should be an option in the next release. Until then, you would have to 
redefine print.trellis() 

(See https://www.stat.math.ethz.ch/pipermail/r-help/2003-February/054290.html)

Deepayan


From afristachi at earthlink.net  Sun Mar  9 01:30:58 2003
From: afristachi at earthlink.net (Anthony Fristachi)
Date: Sat, 08 Mar 2003 19:30:58 -0500
Subject: [R] Mac OS X help
Message-ID: <BA8FF572.264A%afristachi@earthlink.net>

Hello,

I installed R-1.5.1 on my Mac running OS X 10.2.4 I cannot seem to find the
program anywhere. How do I open it. This is very frustrating

Thanks.

Tony


From deleeuw at stat.ucla.edu  Sun Mar  9 01:49:34 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sat, 8 Mar 2003 16:49:34 -0800
Subject: [R] Mac OS X help
In-Reply-To: <BA8FF572.264A%afristachi@earthlink.net>
Message-ID: <FF0E7482-51C8-11D7-863C-000393BB6D36@stat.ucla.edu>

1. Upgrade to 1.6.2
2. If you want to "see" a program, use the Carbon version.
3. If you want the Darwin version, say "/usr/local/bin/R" in the
terminal window, make sure you have X11 installed, and add
/usr/local/bin to your path.

--- Jan

On Saturday, Mar 8, 2003, at 16:30 US/Pacific, Anthony Fristachi wrote:

> Hello,
>
> I installed R-1.5.1 on my Mac running OS X 10.2.4 I cannot seem to  
> find the
> program anywhere. How do I open it. This is very frustrating
>
> Thanks.
>
> Tony
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------


From deepayan at stat.wisc.edu  Sun Mar  9 02:15:24 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 8 Mar 2003 19:15:24 -0600
Subject: [R] FIX: pscales=list(...) and splom
In-Reply-To: <NGBBIMNFDMIPAKBNONMIAECLCAAA.JensScheidtmann@web.de>
References: <NGBBIMNFDMIPAKBNONMIAECLCAAA.JensScheidtmann@web.de>
Message-ID: <200303081915.24527.deepayan@stat.wisc.edu>

On Saturday 08 March 2003 08:31 am, Jens Scheidtmann wrote:
> Dear R Users,
>
> When plotting with "splom" I tried to use the pscales=list(...) feature

Well, looks like you are the first person ever to actually use this feature 
:-)

> Unfortunately it didn't work at all. Instead the scales always were
> suppressed.
>
> So I looked at the source of panel.pairs and found:
>
> "draw <- is.numeric(pscales) && pscales != 0"
>
> which rather has to be:
>
> "draw <- is.list(pscales) || (is.numeric(pscales) && pscales != 0)"

Thanks, fixed for future releases.

> With this change, the axis labels could be generated from the
> supplied ...$at and ...$lab components of the pscales entries.
> (BTW: the documentation says the components should be $at and $labels. This
> is wrong!)

Not really. If a list x has a component called labels (and no other starting 
with lab), then x$lab will return the value of x$labels.

> But....
>
> * The limits of the axes are still generated from the data.

I don't think I'm going to change this behaviour, since the value of at does 
not affect the range in other contexts. (You are of course free to define 
your own superpanel function.)

> * The labels are still not as expected.
>
> To fix these, occurences of "as.character(axls ..." have to be replaced by
> "labels ..."

Also fixed.

Deepayan


From tpapp at axelero.hu  Sun Mar  9 10:33:25 2003
From: tpapp at axelero.hu (Tamas Papp)
Date: Sun, 9 Mar 2003 10:33:25 +0100
Subject: [R] lists of lists
Message-ID: <20030309093325.GB2021@localhost>

I have a function that returns multiple elements in a list (for the
sake of the example here, this will simply be a list of two elements,
a and b, but it is actually five named elements).

This functions computes these values in an iterative manner, and I
would like to start with an empty list and append the list of return
values to this list (so that they would remain lists). The Scheme code
for the resulting list would look something like

(list (list 1 2) (list 3 4) (list 4 5))

I tried to do the same thing in R:

> l <- list()
> l <- list(unlist(l, recursive=FALSE), list(a=1, b=2)) # OK
> l <- list(unlist(l, recursive=FALSE), list(a=3, b=4)) # OK
> l <- list(unlist(l, recursive=FALSE), list(a=5, b=6)) # fails here

I would like to access the elements with eg l[[2]]$a.

Strangely enough (at least to me), I find that the following works:

l <- NULL
l <- c(l, list(list(a=1, b=2))) # for any values of 1 and 2, of course ;)

Could somebody please explain why the first way doesn't work, and why
the second does? There seems to be an implicit assumption I am making
about lists in R which is clearly wrong. Comparisons with Scheme would
be welcome (does c() "unquote" the lists it is given?)

Is there a better way to solve this problem (using another data
structure)?

Regards,

Tamas Papp

-- 
Tam?s K. Papp
E-mail: tpapp at axelero.hu (preferred, especially for large messages)
        tpapp at westel900.net
Please try to send only (latin-2) plain text, not HTML or other garbage.


From tpapp at axelero.hu  Sun Mar  9 10:16:51 2003
From: tpapp at axelero.hu (Tamas Papp)
Date: Sun, 9 Mar 2003 10:16:51 +0100
Subject: [R] strings spanning multiple lines
Message-ID: <20030309091651.GA2021@localhost>

I'd like to specify strings spanning multiple lines (ie too long to
fit in a single line without spoiling pretty-printed R code). I tried
the following way:

> a <- "multiple \
+ lines"

but 

> print(a)
[1] "multiple \nlines"

How could I avoid the extra linebreak ("\n")?

Regards,

Tamas Papp

-- 
Tam?s K. Papp
E-mail: tpapp at axelero.hu (preferred, especially for large messages)
        tpapp at westel900.net
Please try to send only (latin-2) plain text, not HTML or other garbage.


From ripley at stats.ox.ac.uk  Sun Mar  9 10:53:31 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 9 Mar 2003 09:53:31 +0000 (GMT)
Subject: [R] strings spanning multiple lines
In-Reply-To: <20030309091651.GA2021@localhost>
Message-ID: <Pine.LNX.4.44.0303090952120.14850-100000@gannet.stats>

?paste will tell you how to assemble long strings from shorter ones.

On Sun, 9 Mar 2003, Tamas Papp wrote:

> I'd like to specify strings spanning multiple lines (ie too long to
> fit in a single line without spoiling pretty-printed R code). I tried
> the following way:
> 
> > a <- "multiple \
> + lines"
> 
> but 
> 
> > print(a)
> [1] "multiple \nlines"
> 
> How could I avoid the extra linebreak ("\n")?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From laurent at cbs.dtu.dk  Sun Mar  9 14:25:59 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Sun, 9 Mar 2003 14:25:59 +0100
Subject: [R] getMethod in a setMethod context
Message-ID: <20030309132559.GA53440632@genome.cbs.dtu.dk>

Dear List,

I am currently trying to use methods from other classes to avoid
code duplication (my settings are bit complicated, inheritance
is not completely giving what I want). What I would like
to do is to be able to "get the function in the method" to
use it elsewhere...

I tried the following, but apparently it does not work, any pointer ?

  setMethod("f", signature("B"),
            getMethod("f", signature="A"),
            where=where)



Thanks,


Laurent


From m.mader at gsf.de  Sun Mar  9 14:46:57 2003
From: m.mader at gsf.de (Michael Mader)
Date: Sun, 09 Mar 2003 14:46:57 +0100
Subject: [R] getMethod in a setMethod context
References: <20030309132559.GA53440632@genome.cbs.dtu.dk>
Message-ID: <3E6B45D1.E12AF1B9@gsf.de>

Hi Laurent,

what about something like

   setMethod("f", signature("B"),
             definition=function(obj){
	        f(as(obj, "A")
              },
             where=where)
 


Cheers 

Michael


-- 
Michael T. Mader
Institute for Bioinformatics/MIPS, GSF
Ingolstaedter Landstrasse 1
D-80937 Neuherberg
0049-89-3187-3576
 
In statistics, some people worry about not seeing the forest for the
trees.
I like to look at the bark. (C. R. Blyth, 1967)


From luke at stat.uiowa.edu  Sun Mar  9 18:17:31 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Sun, 9 Mar 2003 11:17:31 -0600 (CST)
Subject: [R] getMethod in a setMethod context
In-Reply-To: <3E6B45D1.E12AF1B9@gsf.de>
Message-ID: <Pine.LNX.4.44.0303091113280.20738-100000@nokomis2.stat.umn.edu>

On Sun, 9 Mar 2003, Michael Mader wrote:

> Hi Laurent,
> 
> what about something like
> 
>    setMethod("f", signature("B"),
>              definition=function(obj){
> 	        f(as(obj, "A")
>               },
>              where=where)
>  
> 
> 
> Cheers 
> 
> Michael
> 

May not be what you want if the method for "A" calls generics for
which the class of the original obj would be more relevant.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From tlumley at u.washington.edu  Sun Mar  9 18:23:59 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 9 Mar 2003 09:23:59 -0800 (PST)
Subject: [R] lists of lists
In-Reply-To: <20030309093325.GB2021@localhost>
Message-ID: <Pine.A41.4.44.0303090916400.167622-100000@homer04.u.washington.edu>

On Sun, 9 Mar 2003, Tamas Papp wrote:

> I have a function that returns multiple elements in a list (for the
> sake of the example here, this will simply be a list of two elements,
> a and b, but it is actually five named elements).
>
> This functions computes these values in an iterative manner, and I
> would like to start with an empty list and append the list of return
> values to this list (so that they would remain lists). The Scheme code
> for the resulting list would look something like
>
> (list (list 1 2) (list 3 4) (list 4 5))
>
> I tried to do the same thing in R:
>
> > l <- list()
> > l <- list(unlist(l, recursive=FALSE), list(a=1, b=2)) # OK
> > l <- list(unlist(l, recursive=FALSE), list(a=3, b=4)) # OK
> > l <- list(unlist(l, recursive=FALSE), list(a=5, b=6)) # fails here
>
> I would like to access the elements with eg l[[2]]$a.
>
> Strangely enough (at least to me), I find that the following works:
>
> l <- NULL
> l <- c(l, list(list(a=1, b=2))) # for any values of 1 and 2, of course ;)
>
> Could somebody please explain why the first way doesn't work, and why
> the second does? There seems to be an implicit assumption I am making
> about lists in R which is clearly wrong. Comparisons with Scheme would
> be welcome (does c() "unquote" the lists it is given?)

I think you can usefully regard c() as the vector analogue of (cons).
That is, if you were adding to the head of a list you would expect
  (cons (list 3 4) l)
to do what you want, and
  c(list(3,4), l)
is the S equivalent.  Because S lists are generic vectors rather than
pairlists the natural pasting operating is more symmetric, and
  c(l, list(3,4))
adds one element, a list, to the end of l (where (cons) would do something
different).

The unlist() solution doesn't work because recursive=FALSE does one more
level of unlisting than you expect.


> Is there a better way to solve this problem (using another data
> structure)?

Not unless you know in advance how many lists you have.

	-thomas


From Simon.Gatehouse at csiro.au  Sun Mar  9 23:11:39 2003
From: Simon.Gatehouse at csiro.au (Simon.Gatehouse@csiro.au)
Date: Mon, 10 Mar 2003 09:11:39 +1100
Subject: [R] Setting a toggle parameter in winMenu
Message-ID: <FFE02AF26875734B82A728403821CB2E04F397@asp-ri.riverside.csiro.au>

Dear MS windows users of R
In MS windows R1.6.2 the console window has a menu item  "Misc>Buffered
Output" which is toggled on off with an appropriate tick check when on.
I would like to use such a toggle to set parameters in winMenu etc.  My
search of CRAN did not idicate how this could be achieved so I fear it
cannot be done. 
If this conclusion is incorrect could anybody steer me in the appropriate
direction.

Many Thanks
SimonG



***********************************
Simon Gatehouse                                  
CSIRO Exploration and Mining,
Newbigin Close off Julius Ave
North Ryde, NSW
 
Mail:      PO Box 136, North Ryde
           NSW 1670, Australia
Phone:     61 (2) 9490 8677
Fax:       61 (2) 9490 8921
Mobile:    61  0407 130 635 
E-mail:    simon.gatehouse at csiro.au
Web Page:  http://www.csiro.au/


From mentus at gmx.de  Mon Mar 10 02:51:51 2003
From: mentus at gmx.de (Fernando Henrique Ferraz Pereira da Rosa)
Date: Mon, 10 Mar 2003 02:51:51 +0100 (MET)
Subject: [R] VIM Syntax Highlighting
Message-ID: <10839.1047261111@www19.gmx.net>

     Has anyone got vim to have syntax highlighting with R function codes? I
know there's something similar that works with emacs (ESS or something like
that), but I was wondering if anyone knew an equivalent that worked with vim.


Thank you,

-- 
[]'s
mentus at gmx.de


Bitte l?cheln! Fotogalerie online mit GMX ohne eigene Homepage!


From zynnel at yahoo.com  Mon Mar 10 04:23:12 2003
From: zynnel at yahoo.com (Elena Zheleva)
Date: Sun, 9 Mar 2003 19:23:12 -0800 (PST)
Subject: [R] libR.so - not recognized
In-Reply-To: <3E61514A.70109@joeconway.com>
Message-ID: <20030310032312.7270.qmail@web11804.mail.yahoo.com>

i have a problem executing my code. it compiles just
fine but during execution it gives me the following
error:

"./r_main: error while loading shared libraries:
libR.so: canot open shared object file: No such file
or directory"

in my makefile, i have specified: 

"LIBR=-L$(top_builddir)/bin -lR 'gtk-config --libs' 
#(the path to the executable libR.so is correct) 
r_main:r_main.o
         gcc -o r_main r_main.o $(LIBR)"

any ideas why it is not working? thanks in advance for
yor help!!!

elena zheleva


From icasas at maths.uwa.edu.au  Mon Mar 10 05:20:46 2003
From: icasas at maths.uwa.edu.au (Maria Isabel Casas Villalba)
Date: Mon, 10 Mar 2003 12:20:46 +0800
Subject: [R] R command line
Message-ID: <3E6C129E.A8F90085@maths.uwa.edu.au>

Hello,

I am writting a program in C++ and I need to use the function polygamma.
I wonder if I can call this function that is included in the R library
from my program in C++.

Thanks a million,
Isabel


From IMCEAEX-_O=CSIRO_OU=CMIS_CN=RECIPIENTS_CN=VEN037 at csiro.au  Mon Mar 10 05:44:10 2003
From: IMCEAEX-_O=CSIRO_OU=CMIS_CN=RECIPIENTS_CN=VEN037 at csiro.au (IMCEAEX-_O=CSIRO_OU=CMIS_CN=RECIPIENTS_CN=VEN037@csiro.au)
Date: Mon, 10 Mar 2003 14:44:10 +1000
Subject: [R] where is kurtosis??
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A9165949@roper-cv.qld.cmis.CSIRO.AU>

This is the definition also used by the function kurtosis() in e1071, which
is the old Pearsonian definition.

The Fisherian definition uses sample cumulants (or 'k statistics') and
always seemed preferable to me as it does something about the known biases.
Programming the sample cumulant version, though, is just a bit more tricky,
but not exactly difficult.

Has anyone ever bothered to look at providing sample cumulants and their
multivariate generalizations such as Tukey's polykays?  The case is not all
that strong as the sampling behaviour of these things is pretty dodgy (and
who has ever had the luxury of a homogeneous, iid sample of any size,
anyway?), but there is a nice historical reason to look at them again, now
and then.

Bill Venables.

-----Original Message-----
From: Ross Ihaka [mailto:ihaka at stat.auckland.ac.nz]
Sent: Sunday, March 09, 2003 9:39 AM
To: Shutnik
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] where is kurtosis??


Shutnik wrote:
>  Dear friends,
>  I try to get started with R and can?t estimate kurtosis of a random
sample by using one command.

Its probably worth saying that the point of a computing environment like 
R is that you can easily extend the environment by defining your own 
functions.  In the case of kurtosis you could use something like:

kurtosis <- function(x) {
	x <- x[!is.na(x)]
	sum( (x-mean(x))^4 )/ ((length(x) - 1) * var(x)^2)
}

or

kurtosis <- function(x) {
	x <- x[!is.na(x)]
	sum( (x-mean(x))^4 )/ ((length(x) - 1) * var(x)^2) - 3
}


-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rtmoore at fas.harvard.edu  Mon Mar 10 07:08:43 2003
From: rtmoore at fas.harvard.edu (Ryan T. Moore)
Date: Mon, 10 Mar 2003 01:08:43 -0500
Subject: [R] Creating a sequence of variables in a data frame
Message-ID: <000801c2e6cb$87c17f70$c8ba6780@dhcp187109>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030310/f10be1a0/attachment.pl

From scheidtm at mx.uni-sb.de  Mon Mar 10 07:36:29 2003
From: scheidtm at mx.uni-sb.de (Jens Scheidtmann)
Date: Mon, 10 Mar 2003 07:36:29 +0100
Subject: [R] FIX: pscales=list(...) and splom
References: <NGBBIMNFDMIPAKBNONMIAECLCAAA.JensScheidtmann@web.de>
	<200303081915.24527.deepayan@stat.wisc.edu>
Message-ID: <001701c2e6cf$62207bf0$7a136086@tcmaier.chemie.unisaarland.de>

Dear Deepayan, Dear R list readers,

> On Saturday 08 March 2003 08:31 am, Jens Scheidtmann wrote:
> > Dear R Users,
> >
> > When plotting with "splom" I tried to use the pscales=list(...) feature
>
> Well, looks like you are the first person ever to actually use this
feature
> :-)

Really? %-)

[...]
> > (BTW: the documentation says the components should be $at and $labels.
This
> > is wrong!)
>
> Not really. If a list x has a component called labels (and no other
starting
> with lab), then x$lab will return the value of x$labels.

Oh, didn't remember that. I was completely fixed on fixing... :-)


> > But....
> >
> > * The limits of the axes are still generated from the data.
>
> I don't think I'm going to change this behaviour, since the value of at
does
> not affect the range in other contexts. (You are of course free to define
> your own superpanel function.)

But there isn't another way to set the range of the scales for the splom
function, is there (sorry, at the moment I am not able to look at the source
of panel.pairs)?

I have 4 variables which intrinsically have range(-1,1) and it is
significant when one of these doesn't use it's full scale. If I don't have
to look for the scales, but know that they have range(-1,1), the splom plot
becomes more comprehendable.

Thanks for you fast and kind reply,

Jens
--
Jens Scheidtmann
Germany


From jbvigo at utep.edu  Sat Mar  8 08:29:45 2003
From: jbvigo at utep.edu (Vigo Rivera, Jaime)
Date: Sat, 8 Mar 2003 00:29:45 -0700 
Subject: [R] Help
Message-ID: <F06614C8B970C24AB25242BB59F45AA1FF1B20@itdsrvmail10.utep.edu>

Mac version for 8.6 cannot run R. Click on icon shows message that "cannot
be opened because carbon lib cannot be found"; what do I do?
J.


From ripley at stats.ox.ac.uk  Mon Mar 10 08:38:46 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 10 Mar 2003 07:38:46 +0000 (GMT)
Subject: [R] R command line
In-Reply-To: <3E6C129E.A8F90085@maths.uwa.edu.au>
Message-ID: <Pine.LNX.4.44.0303100736470.9385-100000@gannet.stats>

You can make a standalone library containing polygamma.  See file
src/nmath/standalone/README in the R sources.

On Mon, 10 Mar 2003, Maria Isabel Casas Villalba wrote:

> Hello,
> 
> I am writting a program in C++ and I need to use the function polygamma.
> I wonder if I can call this function that is included in the R library
> from my program in C++.
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jasont at indigoindustrial.co.nz  Mon Mar 10 08:47:39 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 10 Mar 2003 20:47:39 +1300
Subject: [R] Creating a sequence of variables in a data frame
In-Reply-To: <000801c2e6cb$87c17f70$c8ba6780@dhcp187109>;
	from rtmoore@fas.harvard.edu on Mon, Mar 10, 2003 at 01:08:43AM -0500
References: <000801c2e6cb$87c17f70$c8ba6780@dhcp187109>
Message-ID: <20030310204739.A6416@camille.indigoindustrial.co.nz>

On Mon, Mar 10, 2003 at 01:08:43AM -0500, Ryan T. Moore wrote:
> Two questions:
> 
> 1.  I have a data frame named "data1" that includes the variable
> "old".  I want to create a sequence of new variables in the data frame
> called "old.1", "old.2", ... .  I've tried a few "paste" commands, and
> creating a new data frame of the new variables, all to no avail.  Any
> advice? 

I'd just make a dummy column in the loop, then re-write the column
name mid-loop.  e.g.

foo <- data.frame(old = sample(5,100,replace=TRUE)) #generate some data
for(ii in 1:5) {
  foo$zz <- vector(mode="logical",length=length(foo$old))
  names(foo)[ii + 1] <- paste(sep="","old.",ii) #nb - offset 1; yours
                                                #will probably vary
}
foo

> 2.  If I have a variable in a data frame, is there quick bit of code
> that creates a dummy variable for each level of that variable? 

Depends what you mean by "quick" ... ;).  I'm sure Thomas Lumley could
blast out a one-liner with reshape() that does exactly what you need,
but I'm pretty clunky with those.  I'd use the above, and roll it
through another loop.

for(jj in 1:5) { 
  foo[[jj + 1]] [which(foo$old == jj)] <- TRUE #note - same offset
                                               #from above
}

Again, I'm sure the gurus have a slick way of doing it.  I'm also sure
some of them wouldn't like to think of the above examples while eating
dinner ;)

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz


From kwan022 at stat.auckland.ac.nz  Mon Mar 10 08:48:03 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Mon, 10 Mar 2003 20:48:03 +1300 (NZDT)
Subject: [R] rpart returning only 1 node
Message-ID: <Pine.LNX.4.33.0303102045120.23435-100000@stat56.stat.auckland.ac.nz>

Hi,

This may actually be a theoretical question.

When I tried to do the following:

##########################################################
> colnames(rating.adclms)
 [1] "usage"    "mileage"  "sex"      "excess"   "ncd"     
 [6] "primage"  "minage"   "drivers"  "district" "cargroup"
[11] "car.age"  "adclms"   "days"    
> rating.r1 <- rpart(adclms ~ ., data = rating.adclms, 
+                                method = "class")
> rating.r1
n= 140602 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

1) root 140602 3792 0 (9.730303e-01 2.506365e-02 1.834967e-03 
7.112274e-05) *
##########################################################

Should I set the costs in rpart()?  I'm kind of surprised to see it only 
return 1 node for the tree.

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From ripley at stats.ox.ac.uk  Mon Mar 10 09:04:29 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 10 Mar 2003 08:04:29 +0000 (GMT)
Subject: [R] rpart returning only 1 node
In-Reply-To: <Pine.LNX.4.33.0303102045120.23435-100000@stat56.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0303100759410.11060-100000@gannet.stats>

On Mon, 10 Mar 2003, Ko-Kang Kevin Wang wrote:

> Hi,
> 
> This may actually be a theoretical question.
> 
> When I tried to do the following:
> 
> ##########################################################
> > colnames(rating.adclms)
>  [1] "usage"    "mileage"  "sex"      "excess"   "ncd"     
>  [6] "primage"  "minage"   "drivers"  "district" "cargroup"
> [11] "car.age"  "adclms"   "days"    
> > rating.r1 <- rpart(adclms ~ ., data = rating.adclms, 
> +                                method = "class")
> > rating.r1
> n= 140602 
> 
> node), split, n, loss, yval, (yprob)
>       * denotes terminal node
> 
> 1) root 140602 3792 0 (9.730303e-01 2.506365e-02 1.834967e-03 
> 7.112274e-05) *
> ##########################################################
> 
> Should I set the costs in rpart()?  I'm kind of surprised to see it only 
> return 1 node for the tree.

Why are you surprised?  One class has 97% of the examples, and it may be
impossible to get a single split that makes a worthwhile improvement (1%)
in classification.  You probably want to set cp (an argument to
rpart.control).

You could use losses, but I would use weighted sub-sampling of the
training set. See my 1996 book on Pattern Recognition and Neural Networks
for the theory and the practical details.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Mar 10 09:14:54 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 10 Mar 2003 08:14:54 +0000 (GMT)
Subject: [R] Creating a sequence of variables in a data frame
In-Reply-To: <20030310204739.A6416@camille.indigoindustrial.co.nz>
Message-ID: <Pine.LNX.4.44.0303100808380.11060-100000@gannet.stats>

On Mon, 10 Mar 2003, Jason Turner wrote:
> On Mon, Mar 10, 2003 at 01:08:43AM -0500, Ryan T. Moore wrote:

[...]
> > 2.  If I have a variable in a data frame, is there quick bit of code
> > that creates a dummy variable for each level of that variable? 
> 
> Depends what you mean by "quick" ... ;).  I'm sure Thomas Lumley could
> blast out a one-liner with reshape() that does exactly what you need,
> but I'm pretty clunky with those.  I'd use the above, and roll it
> through another loop.
> 
> for(jj in 1:5) { 
>   foo[[jj + 1]] [which(foo$old == jj)] <- TRUE #note - same offset
>                                                #from above
> }

You don't need the which(), as logical indices are just as good.

library(nnet)
?class.ind

(That returns a numeric matrix with 0/1, which is how I understand dummy 
variables are usually coded.  You could also use model.matrix(~ foo - 1).)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From otoomet at econ.dk  Mon Mar 10 09:46:35 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Mon, 10 Mar 2003 09:46:35 +0100
Subject: [R] How to store histogram plots
In-Reply-To: <001101c2e594$581225a0$0a688780@uchicago.edu>
	(hongqin@uchicago.edu)
References: <001101c2e594$581225a0$0a688780@uchicago.edu>
Message-ID: <200303100846.h2A8kZc07978@punik.econ.au.dk>

Dear Hong,

Why do you want to save the histogram on the disk?  Is it not enough
just to draw them one-by-one and read in only the data necessary for
the current one?

However, you may consider:

1) look what the hist() returns.  In particular, it has $counts
   component which you may use in order to draw a pre-calculated
   histogram later (using barplot()).  Now save the returned list
   either in a list or to the disk (using save()).  Later plot all the
   histograms.  In fact, here you are not limited with different
   histograms on different panels, you may e.g. put color-coded bars
   from different histograms on the same plot, fit a surface
   etc.  This is the flexible way.

2) Divide the graphic screen (e.g. using par(mfrow)), read the
   datasets one-by-one and plot corresponding histograms.  This is a
   simpler way.

Regards,

Ott

 | From: "hongqin" <hongqin at uchicago.edu>
 | Date: Sat, 8 Mar 2003 11:01:20 -0600
 | 
 | Hello all,
 |  
 | Is there any way to save histogram results to a file and then read it
 | back later? I am dealing with several sets of data that are too large to
 | be loaded in the same R process, but I want to plot their histogram side
 | by side for comparison. I am also considering how to use the 'wireframe'
 | function to plot these histograms in the same figure. Any suggestions
 | will be greatly appreciated. 
 |  
 | Thanks,
 |  
 | Hong


From jasont at indigoindustrial.co.nz  Mon Mar 10 10:04:25 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 10 Mar 2003 22:04:25 +1300
Subject: [R] Creating a sequence of variables in a data frame
In-Reply-To: <Pine.LNX.4.44.0303100808380.11060-100000@gannet.stats>;
	from ripley@stats.ox.ac.uk on Mon, Mar 10, 2003 at 08:14:54AM +0000
References: <20030310204739.A6416@camille.indigoindustrial.co.nz>
	<Pine.LNX.4.44.0303100808380.11060-100000@gannet.stats>
Message-ID: <20030310220425.A6798@camille.indigoindustrial.co.nz>

On Mon, Mar 10, 2003 at 08:14:54AM +0000, ripley at stats.ox.ac.uk wrote:
> On Mon, 10 Mar 2003, Jason Turner wrote:
> > for(jj in 1:5) { 
> >   foo[[jj + 1]] [which(foo$old == jj)] <- TRUE #note - same offset
> >                                                #from above
> > }
> 
> You don't need the which(), as logical indices are just as good.

(sound of forehead slapping).  Somebody spiked my coffee with decaf.

> library(nnet)
> ?class.ind

Nice.

Many thanks, for the pointer above, and for nnet.  Both are very much
appreciated.

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz


From cdeclercq at nordnet.fr  Mon Mar 10 11:21:33 2003
From: cdeclercq at nordnet.fr (Christophe Declercq)
Date: Mon, 10 Mar 2003 10:21:33 -0000
Subject: [R] VIM Syntax Highlighting
In-Reply-To: <10839.1047261111@www19.gmx.net>
Message-ID: <NGBBKLJCOLPAFMJIEMHCEEIECFAA.cdeclercq@nordnet.fr>

Hi, Fernando

> -----Message d'origine-----
> De : r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]De la part de Fernando Henrique
> Ferraz Pereira da Rosa
> Envoy? : lundi 10 mars 2003 01:52
> ? : r-help at stat.math.ethz.ch
> Objet : [R] VIM Syntax Highlighting
>
>
>      Has anyone got vim to have syntax highlighting with R
> function codes? I
> know there's something similar that works with emacs (ESS or
> something like
> that), but I was wondering if anyone knew an equivalent that
> worked with vim.

I use the MS-WINDOWS port of vim version 6, which has a syntax file for R by
Tom Payne (see http://linux.clare.cam.ac.uk/~twp20/vim/syntax/r.vim).

You can also use both TeX and R syntax in Sweave files. Below is what I use
in my 'noweb.vim' file:


syntax clear
runtime! syntax/tex.vim
syntax include @nowebR syntax/r.vim
syntax region nowebChunk start="^<<.*>>=" end="^@ " contains=@nowebR
syntax region Sexpr  start="\\Sexpr{"  end="}" keepend
hi Sexpr gui=bold guifg=chocolate2

Hope it helps.

Christophe
--
Christophe DECLERCQ, MD
Observatoire R?gional de la Sant? Nord-Pas-de-Calais
13, rue Faidherbe 59046 LILLE Cedex FRANCE
Phone +33 3 20 15 49 24
Fax   +33 3 20 55 92 30
E-mail c.declercq at orsnpdc.org


From cortega at unitec.edu  Mon Mar 10 12:17:28 2003
From: cortega at unitec.edu (Cesar Ortega)
Date: Mon, 10 Mar 2003 12:17:28 +0100
Subject: [R] sampling and gini index
Message-ID: <51238898aec7134.aec713451238898@unitec.edu>

Hi there,


I am new in R, and I was wondering if I could do the following in R, 
since I have tried in SPSS and I have only done part of it.  I 
would appreciate any help to build this routine in R, if possible:



I have a column of 284 elements Y, [...]
> 
> Iam reading these as 284 cases with a single 
> variable, which I will call Y
> 
>> 
> >  where first I need to calculate:
> >
> >GINP=[SUMi SUMj {|Yi - Yj|}]/[2(N**2)*MEAN(Y)], where Yi and Yj 
> are 
> >the 284 elements, 0<Y1<=Y2...<=Y284.  j: is the next position of i.
> 
> Here, I am doing a calculation to yield a single number. 
> Calculating 
 (I assume that N=284) 

> 
> 
> >Next, I need to take the 284 numbers and resampling them in 
> [groups 
> >of] n data (like 3, 4, 5,  etc) for M number of samples ( like 
> 1000, 
> >2000, etc, one at a time) in 3 sampling methods:
> >
> >1. Simple sampling without replacing.
> >2. Fixed systematic sampling.
> >3. Proportional sampling Madow.
> 

SIMPLE SAMPLING WITHOUT REPLACING THE POSITION VALUE, FOR INTANCE 3, IF 
WE HAVE THE POSITION 3,7,9 WITH ITS VALUES, WE COULD HAVE 3,7,10, BUT 
WE COULD NOT HAVE THE POSITIONS 9,3,7 AGAIN.  SO THIS IS A COMBINATION, 
AND IF WE TAKE 3 COMBINATIONS OUT 284 WE HAVE 284!/(3!*281!). AND WE 
NEED TO START FROM 1000 GROUPS OF COMBINATIONS. IT IS LIKE 
IF WE HAVE 1,2,3,4,5 AND WE WANT COMBINATIONS OF 2, WE COULD HAVE IN 
1,2 AND 1,3 AND 1,4 AND 1,5 AND 2,3 AND 2,4, ETC, BUT IN RANDOM ORDER.


 
> 



> >After I have the M(1000, 2000) samples of n ( 3,4, 5)elements in 
> a column,
> 
>
> 
> >I need to take one by one each of the 1000 samples of each n 
> elements 
> >and calculate:
> >
> >PI(i)=n/N in simple and fixed sampling and i belogns to the 
> sample. In 
> >MADOW  PI(i) is proprortional to an auxiliary variable Xi:PI(i)= 
> RXi, 
> >where r= MOD(TN,R), and TN=SUMi(Xi), i to N.
> 

WE KNOW r, AND TN, BUT WE NEED TO FIND R FROM THE MODAL AND r.


AND CALCULATE:
> >ESTIMATED N= SUM {1/PI(i)};
> >ESTIMATED T(Y)= SUM {Yi/PI(i)};  i belongs to the sample.
 

GINMi=[SUMi{(Yi/PI(i))*[1/PI(i)+SUMj(2/PI(j)]}]/[(2*ESTIMATED 
N*ESTIMATED T)].     i belongs to  M (1000) times, WHERE j=i+1

WE HAVE ONLY ONE VARIABLE Y, BUT WITH THE FIRST POSITION i AND THE NEXT 
j, IN THE ASCENDING ORDER.

> >And last to get the errors as:
> >
> >E1=  [SUMi {|GINP-GINMi |}]/[M] ; i belongs M
> >
> >E2= SQRT[SUMi {|GINP-GINMi |}]/[M]; i belongs TO M


From cortega at unitec.edu  Mon Mar 10 12:17:28 2003
From: cortega at unitec.edu (Cesar Ortega)
Date: Mon, 10 Mar 2003 12:17:28 +0100
Subject: [R] sampling and gini index
Message-ID: <51238898aec7134.aec713451238898@unitec.edu>

Hi there,


I am new in R, and I was wondering if I could do the following in R, 
since I have tried in SPSS and I have only done part of it.  I 
would appreciate any help to build this routine in R, if possible:



I have a column of 284 elements Y, [...]
> 
> Iam reading these as 284 cases with a single 
> variable, which I will call Y
> 
>> 
> >  where first I need to calculate:
> >
> >GINP=[SUMi SUMj {|Yi - Yj|}]/[2(N**2)*MEAN(Y)], where Yi and Yj 
> are 
> >the 284 elements, 0<Y1<=Y2...<=Y284.  j: is the next position of i.
> 
> Here, I am doing a calculation to yield a single number. 
> Calculating 
 (I assume that N=284) 

> 
> 
> >Next, I need to take the 284 numbers and resampling them in 
> [groups 
> >of] n data (like 3, 4, 5,  etc) for M number of samples ( like 
> 1000, 
> >2000, etc, one at a time) in 3 sampling methods:
> >
> >1. Simple sampling without replacing.
> >2. Fixed systematic sampling.
> >3. Proportional sampling Madow.
> 

SIMPLE SAMPLING WITHOUT REPLACING THE POSITION VALUE, FOR INTANCE 3, IF 
WE HAVE THE POSITION 3,7,9 WITH ITS VALUES, WE COULD HAVE 3,7,10, BUT 
WE COULD NOT HAVE THE POSITIONS 9,3,7 AGAIN.  SO THIS IS A COMBINATION, 
AND IF WE TAKE 3 COMBINATIONS OUT 284 WE HAVE 284!/(3!*281!). AND WE 
NEED TO START FROM 1000 GROUPS OF COMBINATIONS. IT IS LIKE 
IF WE HAVE 1,2,3,4,5 AND WE WANT COMBINATIONS OF 2, WE COULD HAVE IN 
1,2 AND 1,3 AND 1,4 AND 1,5 AND 2,3 AND 2,4, ETC, BUT IN RANDOM ORDER.


 
> 



> >After I have the M(1000, 2000) samples of n ( 3,4, 5)elements in 
> a column,
> 
>
> 
> >I need to take one by one each of the 1000 samples of each n 
> elements 
> >and calculate:
> >
> >PI(i)=n/N in simple and fixed sampling and i belogns to the 
> sample. In 
> >MADOW  PI(i) is proprortional to an auxiliary variable Xi:PI(i)= 
> RXi, 
> >where r= MOD(TN,R), and TN=SUMi(Xi), i to N.
> 

WE KNOW r, AND TN, BUT WE NEED TO FIND R FROM THE MODAL AND r.


AND CALCULATE:
> >ESTIMATED N= SUM {1/PI(i)};
> >ESTIMATED T(Y)= SUM {Yi/PI(i)};  i belongs to the sample.
 

GINMi=[SUMi{(Yi/PI(i))*[1/PI(i)+SUMj(2/PI(j)]}]/[(2*ESTIMATED 
N*ESTIMATED T)].     i belongs to  M (1000) times, WHERE j=i+1

WE HAVE ONLY ONE VARIABLE Y, BUT WITH THE FIRST POSITION i AND THE NEXT 
j, IN THE ASCENDING ORDER.

> >And last to get the errors as:
> >
> >E1=  [SUMi {|GINP-GINMi |}]/[M] ; i belongs M
> >
> >E2= SQRT[SUMi {|GINP-GINMi |}]/[M]; i belongs TO M


From alobo at ija.csic.es  Mon Mar 10 12:50:52 2003
From: alobo at ija.csic.es (Agustin Lobo)
Date: Mon, 10 Mar 2003 12:50:52 +0100 (MET)
Subject: [R] ylim in plot(corresp(,df=2))
Message-ID: <Pine.OSF.3.91.1030310124610.26931I-100000@paleo.ija.csic.es>


Hi!

If I do:

plot(corresp(a, nf = 2),xlim=c(-1,2),ylim=c(-1,1))

while the xlim takes effect, the ylim does not,
no matter the values given for ylim.

Is this intentional? is this an error?
(I think this might be related with
line 41 in biplot.default in mva)

(using R 1.6.2 on a linux (suse 7.3) box.)

Thanks

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es


From ripley at stats.ox.ac.uk  Mon Mar 10 13:15:26 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 10 Mar 2003 12:15:26 +0000 (GMT)
Subject: [R] ylim in plot(corresp(,df=2))
In-Reply-To: <Pine.OSF.3.91.1030310124610.26931I-100000@paleo.ija.csic.es>
Message-ID: <Pine.LNX.4.44.0303101212130.25994-100000@gannet.stats>

On Mon, 10 Mar 2003, Agustin Lobo wrote:

> If I do:
> 
> plot(corresp(a, nf = 2),xlim=c(-1,2),ylim=c(-1,1))
> 
> while the xlim takes effect, the ylim does not,
> no matter the values given for ylim.
> 
> Is this intentional? is this an error?

It's intentional.  In biplots the x and y axis scalings are not to be
controlled separately.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From roger at ysidro.econ.uiuc.edu  Mon Mar 10 13:21:38 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Mon, 10 Mar 2003 06:21:38 -0600 (CST)
Subject: [R] terms.formula
Message-ID: <Pine.SOL.4.30.0303100553390.7474-100000@ysidro.econ.uiuc.edu>

I'm in the very initial stage of expanding the formula processing
in my quantile regression function rq() to handle additive
nonparametric components, say qss(x), or qss(x,z).  I need some
advice about strategy for formula processing.  My initial foray
was to use:

	terms(formula,specials="qss")

and then modify the components of the resulting
terms.object.  But in changing formula at factors to drop the qss
columns and rows, I ran afoul of methodsPackageMetaName
which claimed that it was "being abused" by this.

	if(!is.null(attr(formula,"specials"))){
		qss.col <- pmatch("qss",attr(formula,"term.labels"))
        	qss.row <- formula at specials$qss
        	formula at factors <- formula at factors[-qss.row,-qss.col,drop=FALSE]
        	}

My eventual objective is to be able to  make the model.matrix
corresponding to the linear, parametric part of the formula specified,
and then to cbind additional columns corresponding to the
nonparametric components and pass the whole thing to rq.fit.xxx,
where estimation will be handled.  So the essential question at
this point is:  how should I go about stripping off the qss
components for subsequent use.


url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
email	rkoenker at uiuc.edu	Department of Economics Drayton House,
vox: 	217-333-4558		University of Illinois	30 Gorden St,
fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK
							vox:	020-7679-5838


From ripley at stats.ox.ac.uk  Mon Mar 10 13:43:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 10 Mar 2003 12:43:05 +0000 (GMT)
Subject: [R] terms.formula
In-Reply-To: <Pine.SOL.4.30.0303100553390.7474-100000@ysidro.econ.uiuc.edu>
Message-ID: <Pine.LNX.4.44.0303101234250.26456-100000@gannet.stats>

On Mon, 10 Mar 2003, Roger Koenker wrote:

> I'm in the very initial stage of expanding the formula processing
> in my quantile regression function rq() to handle additive
> nonparametric components, say qss(x), or qss(x,z).  I need some
> advice about strategy for formula processing.  My initial foray
> was to use:
> 
> 	terms(formula,specials="qss")
> 
> and then modify the components of the resulting
> terms.object.  But in changing formula at factors to drop the qss
> columns and rows, I ran afoul of methodsPackageMetaName
> which claimed that it was "being abused" by this.

That means it is being called with incorrect arguments (and you are using
without saying so R-devel aka `1.7.0 Under development (unstable)', for
which the R-devel is a more appropriate list).

I am really puzzled though: formula and terms are not S4 classes, so
why are you using formula at specials and formula at factors?  A terms
object is documented in ?terms.object, and it does not have slots.
@ is *not* the operator to access attributes, and I think this is 
quite correctly termed "being abused".

> 
> 	if(!is.null(attr(formula,"specials"))){
> 		qss.col <- pmatch("qss",attr(formula,"term.labels"))
>         	qss.row <- formula at specials$qss
>         	formula at factors <- formula at factors[-qss.row,-qss.col,drop=FALSE]
>         	}
> 
> My eventual objective is to be able to  make the model.matrix
> corresponding to the linear, parametric part of the formula specified,
> and then to cbind additional columns corresponding to the
> nonparametric components and pass the whole thing to rq.fit.xxx,
> where estimation will be handled.  So the essential question at
> this point is:  how should I go about stripping off the qss
> components for subsequent use.

Access the attributes with the correct accessor functions and this should 
be possible.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From duncan at research.bell-labs.com  Mon Mar 10 14:24:42 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Mon, 10 Mar 2003 08:24:42 -0500
Subject: [R] libR.so - not recognized
In-Reply-To: <20030310032312.7270.qmail@web11804.mail.yahoo.com>;
	from zynnel@yahoo.com on Sun, Mar 09, 2003 at 07:23:12PM -0800
References: <3E61514A.70109@joeconway.com>
	<20030310032312.7270.qmail@web11804.mail.yahoo.com>
Message-ID: <20030310082442.B3037@jessie.research.bell-labs.com>

Elena Zheleva wrote:
> i have a problem executing my code. it compiles just
> fine but during execution it gives me the following
> error:
> 
> "./r_main: error while loading shared libraries:
> libR.so: canot open shared object file: No such file
> or directory"
> 
> in my makefile, i have specified: 
> 
> "LIBR=-L$(top_builddir)/bin -lR 'gtk-config --libs' 
> #(the path to the executable libR.so is correct) 
> r_main:r_main.o
>          gcc -o r_main r_main.o $(LIBR)"
> 
> any ideas why it is not working? thanks in advance for
> yor help!!!

I assume you are working on Linux/Unix.  The problem is likely to be
that the dynamic loader (not linker) can't find libR.so.  You need to
have $R_HOME/bin (i.e. $top_builddir/bin) in your LD_LIBRARY_PATH so
that the loader can find the library.  You can use the program 'ldd'
to find out what shared libraries is linked against and will try to
load when it starts and that will also tell you where it found them
and which it did not find.


In some cases, rather than creating a stand-alone application that
embeds R, you can run your code from within R and have the same effect
but avoiding issues such as libR.so, LD_LIBRARY_PATH, etc.  And since
you are using Gtk, it might be possible to program the GUI entirely
within R via RGtk and related packages.

Good luck.


> 
> elena zheleva
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan


From bmagill at earthlink.net  Mon Mar 10 13:53:37 2003
From: bmagill at earthlink.net (Brett Magill)
Date: Mon, 10 Mar 2003 06:53:37 -0600 (CST)
Subject: [R] DLL error after update.packages
Message-ID: <7054230.1047308327030.JavaMail.nobody@ernie.psp.pas.earthlink.net>

When updataing packages from CRAN, I got the following error message:

updating HTML package descriptions
Warning message: 
DLL attempted to change FPU control word from 8001f to 9001f 

Everything seems fine, the packages updated, just wondering what this was.  R 1.6.2 on Windows 98.  Details on the packages dowloaded are below.
________________________________________________

update.packages()
trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 9312 bytes
opened URL
downloaded 9312 bytes

VR :
 Version 7.0-10 in C:/PROGRA~1/R/RW1062/library 
 Version 7.0-11 on CRAN
Update (y/N)?  y
foreign :
 Version 0.5-8 in C:/PROGRA~1/R/RW1062/library 
 Version 0.5-9 on CRAN
Update (y/N)?  y
gregmisc :
 Version 0.7.3 in C:/PROGRA~1/R/RW1062/library 
 Version 0.8.2 on CRAN
Update (y/N)?  y
nlme :
 Version 3.1-36 in C:/PROGRA~1/R/RW1062/library 
 Version 3.1-38 on CRAN
Update (y/N)?  y
trying URL `http://cran.r-project.org/bin/windows/contrib/VR.zip'
Content type `application/zip' length 1189784 bytes
opened URL
downloaded 1161Kb

trying URL `http://cran.r-project.org/bin/windows/contrib/foreign.zip'
Content type `application/zip' length 108141 bytes
opened URL
downloaded 105Kb

trying URL `http://cran.r-project.org/bin/windows/contrib/gregmisc.zip'
Content type `application/zip' length 379701 bytes
opened URL
downloaded 370Kb

trying URL `http://cran.r-project.org/bin/windows/contrib/nlme.zip'
Content type `application/zip' length 1960275 bytes
opened URL
downloaded 1914Kb


Delete downloaded files (y/N)? y

updating HTML package descriptions
Warning message: 
DLL attempted to change FPU control word from 8001f to 9001f


From carlos.ortega at minorplanet.com  Mon Mar 10 16:06:56 2003
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Mon, 10 Mar 2003 16:06:56 +0100
Subject: [R] VIM Syntax Highlighting
In-Reply-To: <10839.1047261111@www19.gmx.net>
Message-ID: <LMEKLMMLPDKOJNOOEELEMEIPEAAA.carlos.ortega@minorplanet.com>

In the Windows (GVIM - version 6.1) as well as the Linux version (GVIM -
6.1)  that syntax highlighting capability is already built in VIM.
Go to Syntax and then click on the first line of the menu (Show individual
choices). That menu will change, now instead of "Show individual choices"
you will ge a list of words sorted in alphabetical order, go to "R-Sg" and
the first choice will be "R". That is what you need.

Regards,
Carlos.


-----Mensaje original-----
De: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Fernando Henrique
Ferraz Pereira da Rosa
Enviado el: lunes, 10 de marzo de 2003 2:52
Para: r-help at stat.math.ethz.ch
Asunto: [R] VIM Syntax Highlighting


     Has anyone got vim to have syntax highlighting with R function codes? I
know there's something similar that works with emacs (ESS or something like
that), but I was wondering if anyone knew an equivalent that worked with
vim.


Thank you,

--
[]'s
mentus at gmx.de


Bitte l?cheln! Fotogalerie online mit GMX ohne eigene Homepage!

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

###  This email has been checked for all known viruses by the
###  Firstnet anti-virus system - http://www.firstnet.net.uk
###  Please email fav at firstnet.net.uk for details.


_____
The information in this email is confidential and it may not be\... [[dropped]]


From tlumley at u.washington.edu  Mon Mar 10 16:11:02 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 10 Mar 2003 07:11:02 -0800 (PST)
Subject: [R] Help
In-Reply-To: <F06614C8B970C24AB25242BB59F45AA1FF1B20@itdsrvmail10.utep.edu>
Message-ID: <Pine.A41.4.44.0303100709080.13256-100000@homer27.u.washington.edu>

On Sat, 8 Mar 2003, Vigo Rivera, Jaime wrote:

> Mac version for 8.6 cannot run R. Click on icon shows message that "cannot
> be opened because carbon lib cannot be found"; what do I do?

You need to download CarbonLib from apple.com.  This is mentioned in the
Mac FAQ, but the link there is stale. You can find CarbonLib 1.6 at
http://docs.info.apple.com/article.html?artnum=120047


	-thomas


From tlumley at u.washington.edu  Mon Mar 10 16:17:17 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 10 Mar 2003 07:17:17 -0800 (PST)
Subject: [R] terms.formula
In-Reply-To: <Pine.SOL.4.30.0303100553390.7474-100000@ysidro.econ.uiuc.edu>
Message-ID: <Pine.A41.4.44.0303100715410.13256-100000@homer27.u.washington.edu>

On Mon, 10 Mar 2003, Roger Koenker wrote:

> I'm in the very initial stage of expanding the formula processing
> in my quantile regression function rq() to handle additive
> nonparametric components, say qss(x), or qss(x,z).  I need some
> advice about strategy for formula processing.  My initial foray
> was to use:
>
> 	terms(formula,specials="qss")
>
> and then modify the components of the resulting
> terms.object.

Another approach, which you can see in coxph() in the survival package, is
to create a new formula without the qss terms.  It's not very pretty but
it seems to work portably.

	-thomas


From laurans at roazhon.inra.fr  Mon Mar 10 16:13:06 2003
From: laurans at roazhon.inra.fr (laurans)
Date: Mon, 10 Mar 2003 16:13:06 +0100
Subject: [R] GLM
Message-ID: <3E6CAB82.7070401@roazhon.inra.fr>

Hello,
I would to know the equivalent of the function step.glm for R.
Thank you

Sincerely

Martial Laurans


From spencer.graves at pdf.com  Mon Mar 10 16:31:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 10 Mar 2003 07:31:34 -0800
Subject: [R] Creating a sequence of variables in a data frame
References: <000801c2e6cb$87c17f70$c8ba6780@dhcp187109>
Message-ID: <3E6CAFD6.4070905@pdf.com>

 > data1 <- data.frame(old=1:2)
 > data1$old2 <- 3:4
 > data1
   old old2
1   1    3
2   2    4

Acceptable?
Spencer Graves

Ryan T. Moore wrote:
> Two questions:
> 
> 1.  I have a data frame named "data1" that includes the variable "old".  I want to create a sequence of new variables in the data frame called "old.1", "old.2", ... .  I've tried a few "paste" commands, and creating a new data frame of the new variables, all to no avail.  Any advice?
> 
> 2.  If I have a variable in a data frame, is there quick bit of code that creates a dummy variable for each level of that variable?
> 
> Thank you,
> Ryan Moore 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From carlos.ortega at minorplanet.com  Mon Mar 10 16:34:33 2003
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Mon, 10 Mar 2003 16:34:33 +0100
Subject: [R] sampling and gini index
In-Reply-To: <51238898aec7134.aec713451238898@unitec.edu>
Message-ID: <LMEKLMMLPDKOJNOOEELEGEJAEAAA.carlos.ortega@minorplanet.com>

Cesar,

For the first part, please check the function included. For the sampling,
please check "?sample".

Regards,
Carlos.

g.index<-function(y) {
	sum.res<-0
	y.lg<-length(y)
	y.mean<-mean(y)

	for (i in 1:y.lg) {
  		for (j in 1:y.lg) {
    			ratio.res<-abs(y[i]-y[j]) / (2 * y.lg^2 * y.mean)
    			sum.res<-sum.res+ratio.res
  		}
	}
  	return(sum.res)
 }

 y<-rnorm(284)
 g.index(y)





-----Mensaje original-----
De: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Cesar Ortega
Enviado el: lunes, 10 de marzo de 2003 12:17
Para: r-help at stat.math.ethz.ch
CC: r-help at stat.math.ethz.ch
Asunto: [R] sampling and gini index


Hi there,


I am new in R, and I was wondering if I could do the following in R,
since I have tried in SPSS and I have only done part of it.  I
would appreciate any help to build this routine in R, if possible:



I have a column of 284 elements Y, [...]
>
> Iam reading these as 284 cases with a single
> variable, which I will call Y
>
>>
> >  where first I need to calculate:
> >
> >GINP=[SUMi SUMj {|Yi - Yj|}]/[2(N**2)*MEAN(Y)], where Yi and Yj
> are
> >the 284 elements, 0<Y1<=Y2...<=Y284.  j: is the next position of i.
>
> Here, I am doing a calculation to yield a single number.
> Calculating
 (I assume that N=284)

>
>
> >Next, I need to take the 284 numbers and resampling them in
> [groups
> >of] n data (like 3, 4, 5,  etc) for M number of samples ( like
> 1000,
> >2000, etc, one at a time) in 3 sampling methods:
> >
> >1. Simple sampling without replacing.
> >2. Fixed systematic sampling.
> >3. Proportional sampling Madow.
>

SIMPLE SAMPLING WITHOUT REPLACING THE POSITION VALUE, FOR INTANCE 3, IF
WE HAVE THE POSITION 3,7,9 WITH ITS VALUES, WE COULD HAVE 3,7,10, BUT
WE COULD NOT HAVE THE POSITIONS 9,3,7 AGAIN.  SO THIS IS A COMBINATION,
AND IF WE TAKE 3 COMBINATIONS OUT 284 WE HAVE 284!/(3!*281!). AND WE
NEED TO START FROM 1000 GROUPS OF COMBINATIONS. IT IS LIKE
IF WE HAVE 1,2,3,4,5 AND WE WANT COMBINATIONS OF 2, WE COULD HAVE IN
1,2 AND 1,3 AND 1,4 AND 1,5 AND 2,3 AND 2,4, ETC, BUT IN RANDOM ORDER.



>



> >After I have the M(1000, 2000) samples of n ( 3,4, 5)elements in
> a column,
>
>
>
> >I need to take one by one each of the 1000 samples of each n
> elements
> >and calculate:
> >
> >PI(i)=n/N in simple and fixed sampling and i belogns to the
> sample. In
> >MADOW  PI(i) is proprortional to an auxiliary variable Xi:PI(i)=
> RXi,
> >where r= MOD(TN,R), and TN=SUMi(Xi), i to N.
>

WE KNOW r, AND TN, BUT WE NEED TO FIND R FROM THE MODAL AND r.


AND CALCULATE:
> >ESTIMATED N= SUM {1/PI(i)};
> >ESTIMATED T(Y)= SUM {Yi/PI(i)};  i belongs to the sample.


GINMi=[SUMi{(Yi/PI(i))*[1/PI(i)+SUMj(2/PI(j)]}]/[(2*ESTIMATED
N*ESTIMATED T)].     i belongs to  M (1000) times, WHERE j=i+1

WE HAVE ONLY ONE VARIABLE Y, BUT WITH THE FIRST POSITION i AND THE NEXT
j, IN THE ASCENDING ORDER.

> >And last to get the errors as:
> >
> >E1=  [SUMi {|GINP-GINMi |}]/[M] ; i belongs M
> >
> >E2= SQRT[SUMi {|GINP-GINMi |}]/[M]; i belongs TO M

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

###  This email has been checked for all known viruses by the
###  Firstnet anti-virus system - http://www.firstnet.net.uk
###  Please email fav at firstnet.net.uk for details.


_____
The information in this email is confidential and it may not be\... [[dropped]]


From philippe.hupe at wanadoo.fr  Mon Mar 10 16:39:59 2003
From: philippe.hupe at wanadoo.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Mon, 10 Mar 2003 16:39:59 +0100
Subject: [R] Least-squares means
Message-ID: <3E6CB1CF.20401@wanadoo.fr>

Is there any function to compute Least-squares means from a linear model 
as lsmeans does in SAS.

Thanks.


Philippe.


From ripley at stats.ox.ac.uk  Mon Mar 10 16:50:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 10 Mar 2003 15:50:02 +0000 (GMT)
Subject: [R] DLL error after update.packages
In-Reply-To: <7054230.1047308327030.JavaMail.nobody@ernie.psp.pas.earthlink.net>
Message-ID: <Pine.LNX.4.44.0303101549050.1283-100000@gannet.stats>

On Mon, 10 Mar 2003, Brett Magill wrote:

> When updataing packages from CRAN, I got the following error message:
> 
> updating HTML package descriptions
> Warning message: 
> DLL attempted to change FPU control word from 8001f to 9001f 
> 
> Everything seems fine, the packages updated, just wondering what this was. 
R 1.6.2 on Windows 98.  Details on the packages dowloaded are below.

Are you using --internet2?  In that case your Internet Explorer is buggy: 
it's a known problem.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Mar 10 17:07:16 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 10 Mar 2003 16:07:16 +0000 (GMT)
Subject: [R] GLM
In-Reply-To: <3E6CAB82.7070401@roazhon.inra.fr>
Message-ID: <Pine.LNX.4.44.0303101601510.1307-100000@gannet.stats>

R does not contain anything equivalent to step.glm: we do not copy 
incorrect functions!

There is step() in base R and stepAIC() in package MASS, both of which do 
what step.glm in S claims to do (but does not).

[step.glm has an incorrect definition of AIC, and uses Wald tests to 
approximate likelihood ratio tests, despite the Hauck-Donner effect. It 
can give seriously misleading results: this was discovered in a real 
application about 8 years ago, when I wrote stepAIC.]

On Mon, 10 Mar 2003, laurans wrote:

> I would to know the equivalent of the function step.glm for R.
> Thank you

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lm.silva at sapo.pt  Mon Mar 10 17:29:38 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Mon, 10 Mar 2003 16:29:38 +0000 (WET)
Subject: [R] predicted values
Message-ID: <1047313778.3e6cbd72942b7@webmail.sapo.pt>

Hello helpers

I fitted an SARIMA model to a time series and would like to 
predict 10 steps ahead. I made

>dataset1.arima<-arima(dataset1.ts,order=c(2,1,0),seasonal=list
(order=c(1,1,0)))

>predict(dataset1.arima,n.ahead=10)

The problem is that the predicted values came in a different 
scale. The original series has values like  26992411 and the 
predicted values are like -0.2341768144. Why is this?

thanks
luis
--
SAPO ADSL.PT, apanhe j? o comboio da Banda Larga. Kit SAPO ADSL.PT ?50

hTTP://www.sapo.pt/kitadsl


From partha_bagchi at hgsi.com  Mon Mar 10 17:28:55 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Mon, 10 Mar 2003 11:28:55 -0500
Subject: [R] sampling and gini index
Message-ID: <OF87C2419D.7E852D87-ON85256CE5.005A5769-85256CE5.005A8A4C@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030310/5ba6dece/attachment.pl

From renaud.lancelot at cirad.fr  Mon Mar 10 17:32:18 2003
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Mon, 10 Mar 2003 16:32:18 +0000
Subject: [R] DLL error after update.packages
In-Reply-To: <Pine.LNX.4.44.0303101549050.1283-100000@gannet.stats>
References: <Pine.LNX.4.44.0303101549050.1283-100000@gannet.stats>
Message-ID: <3E6CBE12.6040207@cirad.fr>

ripley at stats.ox.ac.uk wrote:
> On Mon, 10 Mar 2003, Brett Magill wrote:
> 
> 
>>When updataing packages from CRAN, I got the following error message:
>>
>>updating HTML package descriptions
>>Warning message: 
>>DLL attempted to change FPU control word from 8001f to 9001f 
>>
>>Everything seems fine, the packages updated, just wondering what this was. 
> 
> R 1.6.2 on Windows 98.  Details on the packages dowloaded are below.
> 
> Are you using --internet2?  In that case your Internet Explorer is buggy: 
> it's a known problem.
> 

I just met the same problem with Win98 / R 1.6.2 / Mozilla 1.2.1., while 
updating package from the menu. It did not happen before, with exactly 
the same config.

Best,

Renaud

-- 
Dr Renaud Lancelot, v?t?rinaire
CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
Programme Productions Animales
http://www.cirad.fr/fr/pg_recherche/page.php?id=14

ISRA-LNERV                      tel    +221 832 49 02
BP 2057 Dakar-Hann              fax    +221 821 18 79 (CIRAD)
Senegal                         e-mail renaud.lancelot at cirad.fr


From ripley at stats.ox.ac.uk  Mon Mar 10 17:39:39 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 10 Mar 2003 16:39:39 +0000 (GMT)
Subject: [R] DLL error after update.packages
In-Reply-To: <3E6CBE12.6040207@cirad.fr>
Message-ID: <Pine.LNX.4.44.0303101636310.2764-100000@gannet.stats>

On Mon, 10 Mar 2003, Renaud Lancelot wrote:

> ripley at stats.ox.ac.uk wrote:
> > On Mon, 10 Mar 2003, Brett Magill wrote:
> > 
> > 
> >>When updataing packages from CRAN, I got the following error message:
> >>
> >>updating HTML package descriptions
> >>Warning message: 
> >>DLL attempted to change FPU control word from 8001f to 9001f 
> >>
> >>Everything seems fine, the packages updated, just wondering what this was. 
> > 
> > R 1.6.2 on Windows 98.  Details on the packages dowloaded are below.
> > 
> > Are you using --internet2?  In that case your Internet Explorer is buggy: 
> > it's a known problem.
> > 
> 
> I just met the same problem with Win98 / R 1.6.2 / Mozilla 1.2.1., while 
> updating package from the menu. It did not happen before, with exactly 
> the same config.

Let's be clear: this is a warning, and R corrects the effect.  You can
rest assured that a problem was averted by R's actions.  We've only had 
reports when --internet2 is in effect (the browser is irrelevant) but it 
is entirely possible that this is caused by the winsock dlls.

There are details of this in the CHANGES file for 1.6.2: both the message 
and the corrective action were new in 1.6.2.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Mar 10 17:52:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 10 Mar 2003 16:52:05 +0000 (GMT)
Subject: [R] predicted values
In-Reply-To: <1047313778.3e6cbd72942b7@webmail.sapo.pt>
Message-ID: <Pine.LNX.4.44.0303101648440.4125-100000@gannet.stats>

On Mon, 10 Mar 2003, Luis Silva wrote:

> Hello helpers
> 
> I fitted an SARIMA model to a time series and would like to 
> predict 10 steps ahead. I made
> 
> >dataset1.arima<-arima(dataset1.ts,order=c(2,1,0),seasonal=list
> (order=c(1,1,0)))
> 
> >predict(dataset1.arima,n.ahead=10)
> 
> The problem is that the predicted values came in a different 
> scale. The original series has values like  26992411 and the 
> predicted values are like -0.2341768144. Why is this?

User error?  If we take the example in ?predict.Arima and use teh same 
orders as yours

data(USAccDeaths, package="ts")
USAccDeaths
fit <- arima(USAccDeaths, order = c(2,1,1), seasonal = list(order=c(1,1,0)))
predict(fit, n.ahead = 10)

it gives results of the expected size.  So how can we possibly debug your 
private example?

BTW, arima0 can also be used.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From luke at stat.uiowa.edu  Mon Mar 10 17:49:39 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 10 Mar 2003 10:49:39 -0600 (CST)
Subject: [R] SNOW: Simple Parallel Computing in R
Message-ID: <Pine.LNX.4.44.0303101047530.14620-100000@itasca.stat.uiowa.edu>

The package `snow' (Simple Network of Workstations), originally
announced in early form about a year ago on this list, is now
available from CRAN.  Snow implements a simple mechanism for using a
workstation cluster for ``embarrassingly parallel'' computations in R.
The interface, which is based in part on the Python CoW (Cluster of
Workstations; http://www.scipy.org/) package, is intended to be quite
simple, and is designed so that it can be implemented on top of
several different lower level communication mechanisms.  Three low
level interfaces have been implemented, one based on sockets, one
using PVM via the rpvm package, and one using MPI, via the Rmpi
package.  The page
http://www.stat.uiowa.edu/~luke/R/cluster/cluster.html provides a
brief introduction and a simple example of using the cluster for
parallel bootstrapping.  A paper on parallel computing in R using snow
is available as a technical report at
http://www.bepress.com/uwbiostat/paper193.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From den.duurs at lycos.com  Mon Mar 10 18:03:11 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Mon, 10 Mar 2003 09:03:11 -0800
Subject: [R] Moving average
Message-ID: <BJIMKGPEIPMDNDAA@mailcity.com>

Or try this: 
(x is a vector, k is window-width for moving average)


moving.average <- 
function(x, k) { 
 n <- length(x) 
 y <- rep(0, n) 
 for (i in (1+k):n) 
   y[i] <- mean(x[(i-k):i]) 
 return(y)
 } 


Remko Duursma 
--

On Fri, 7 Mar 2003 12:08:14   
 Warnes, Gregory R wrote:
>Or look at the 'running' function in the gregmisc package.
>
>-Greg
>
>> -----Original Message-----
>> From: Huntsinger, Reid [mailto:reid_huntsinger at merck.com]
>> Sent: Friday, March 07, 2003 10:13 AM
>> To: 'Wayne Jones'; r-help at stat.math.ethz.ch
>> Subject: RE: [R] Moving average
>> 
>> 
>> Try "filter" in package ts.
>> 
>> Reid Huntsinger
>> 
>> -----Original Message-----
>> From: Wayne Jones [mailto:JonesW at kssg.com] 
>> Sent: Friday, March 07, 2003 9:37 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Moving average
>> 
>> 
>> Hi, 
>> 
>> Does anyone know if R has the functionality to calculate a 
>> simple moving
>> average. I cant seem 
>> to find it in the help menu. 
>> 
>> thanks, 
>> 
>> Wayne
>> 
>> 
>> Dr Wayne R. Jones
>> Statistician / Research Analyst
>> KSS Group plc
>> St James's Buildings
>> 79 Oxford Street
>> Manchester M1 6SS
>> Tel: +44(0)161 609 4084
>> Mob: +44(0)7810 523 713
>> 
>> 
>> 
>> KSS Ltd
>> A division of Knowledge Support Systems Group plc
>> Seventh Floor  St James's Buildings  79 Oxford Street  
>> Manchester  M1 6SS
>> England
>> Company Registration Number 2800886 (Limited) 3449594 (plc)
>> Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
>> mailto:kssg at kssg.com		http://www.kssg.com
>> 
>> 
>> The information in this Internet email is confidential and 
>> may b... [[dropped]]
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> 
>
>
>LEGAL NOTICE\ Unless expressly stated otherwise, this message is... [[dropped]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From zeileis at ci.tuwien.ac.at  Mon Mar 10 18:03:50 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Mon, 10 Mar 2003 18:03:50 +0100
Subject: [R] sampling and gini index
In-Reply-To: <LMEKLMMLPDKOJNOOEELEGEJAEAAA.carlos.ortega@minorplanet.com>
References: <LMEKLMMLPDKOJNOOEELEGEJAEAAA.carlos.ortega@minorplanet.com>
Message-ID: <200303101703.h2AH3on3001479@thorin.ci.tuwien.ac.at>

On Monday 10 March 2003 16:34, Carlos Ortega wrote:

> Cesar,
>
> For the first part, please check the function included. For the
> sampling, please check "?sample".
>
> Regards,
> Carlos.
>
> g.index<-function(y) {
> 	sum.res<-0
> 	y.lg<-length(y)
> 	y.mean<-mean(y)
>
> 	for (i in 1:y.lg) {
>   		for (j in 1:y.lg) {
>     			ratio.res<-abs(y[i]-y[j]) / (2 * y.lg^2 * y.mean)
>     			sum.res<-sum.res+ratio.res
>   		}
> 	}
>   	return(sum.res)
>  }
>
>  y<-rnorm(284)
>  g.index(y)
>

A more efficient implementation of the Gini index can be found in the 
ineq package. See
  help(Gini)
  help(ineq)
Z

>
>
>
> -----Mensaje original-----
> De: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Cesar Ortega
> Enviado el: lunes, 10 de marzo de 2003 12:17
> Para: r-help at stat.math.ethz.ch
> CC: r-help at stat.math.ethz.ch
> Asunto: [R] sampling and gini index
>
>
> Hi there,
>
>
> I am new in R, and I was wondering if I could do the following in R,
> since I have tried in SPSS and I have only done part of it.  I
> would appreciate any help to build this routine in R, if possible:
>
>
>
> I have a column of 284 elements Y, [...]
>
> > Iam reading these as 284 cases with a single
> > variable, which I will call Y
> >
> > >  where first I need to calculate:
> > >
> > >GINP=[SUMi SUMj {|Yi - Yj|}]/[2(N**2)*MEAN(Y)], where Yi and Yj
> >
> > are
> >
> > >the 284 elements, 0<Y1<=Y2...<=Y284.  j: is the next position of
> > > i.
> >
> > Here, I am doing a calculation to yield a single number.
> > Calculating
>
>  (I assume that N=284)
>
> > >Next, I need to take the 284 numbers and resampling them in
> >
> > [groups
> >
> > >of] n data (like 3, 4, 5,  etc) for M number of samples ( like
> >
> > 1000,
> >
> > >2000, etc, one at a time) in 3 sampling methods:
> > >
> > >1. Simple sampling without replacing.
> > >2. Fixed systematic sampling.
> > >3. Proportional sampling Madow.
>
> SIMPLE SAMPLING WITHOUT REPLACING THE POSITION VALUE, FOR INTANCE 3,
> IF WE HAVE THE POSITION 3,7,9 WITH ITS VALUES, WE COULD HAVE 3,7,10,
> BUT WE COULD NOT HAVE THE POSITIONS 9,3,7 AGAIN.  SO THIS IS A
> COMBINATION, AND IF WE TAKE 3 COMBINATIONS OUT 284 WE HAVE
> 284!/(3!*281!). AND WE NEED TO START FROM 1000 GROUPS OF
> COMBINATIONS. IT IS LIKE
> IF WE HAVE 1,2,3,4,5 AND WE WANT COMBINATIONS OF 2, WE COULD HAVE IN
> 1,2 AND 1,3 AND 1,4 AND 1,5 AND 2,3 AND 2,4, ETC, BUT IN RANDOM
> ORDER.
>
> > >After I have the M(1000, 2000) samples of n ( 3,4, 5)elements in
> >
> > a column,
> >
> > >I need to take one by one each of the 1000 samples of each n
> >
> > elements
> >
> > >and calculate:
> > >
> > >PI(i)=n/N in simple and fixed sampling and i belogns to the
> >
> > sample. In
> >
> > >MADOW  PI(i) is proprortional to an auxiliary variable Xi:PI(i)=
> >
> > RXi,
> >
> > >where r= MOD(TN,R), and TN=SUMi(Xi), i to N.
>
> WE KNOW r, AND TN, BUT WE NEED TO FIND R FROM THE MODAL AND r.
>
> AND CALCULATE:
> > >ESTIMATED N= SUM {1/PI(i)};
> > >ESTIMATED T(Y)= SUM {Yi/PI(i)};  i belongs to the sample.
>
> GINMi=[SUMi{(Yi/PI(i))*[1/PI(i)+SUMj(2/PI(j)]}]/[(2*ESTIMATED
> N*ESTIMATED T)].     i belongs to  M (1000) times, WHERE j=i+1
>
> WE HAVE ONLY ONE VARIABLE Y, BUT WITH THE FIRST POSITION i AND THE
> NEXT j, IN THE ASCENDING ORDER.
>
> > >And last to get the errors as:
> > >
> > >E1=  [SUMi {|GINP-GINMi |}]/[M] ; i belongs M
> > >
> > >E2= SQRT[SUMi {|GINP-GINMi |}]/[M]; i belongs TO M
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ###  This email has been checked for all known viruses by the
> ###  Firstnet anti-virus system - http://www.firstnet.net.uk
> ###  Please email fav at firstnet.net.uk for details.
>
>
> _____
> The information in this email is confidential and it may not be\...
> [[dropped]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From smcnary at charm.net  Mon Mar 10 18:48:11 2003
From: smcnary at charm.net (Scot W McNary)
Date: Mon, 10 Mar 2003 12:48:11 -0500 (EST)
Subject: [R] graphics backgrounds from gray to white in png()
Message-ID: <20030310124506.J51240-100000@fellspt.charm.net>



Hi,

I'm trying to make a png file of a histogram.  I would like a white
background in the final product but end up producing a gray one, despite
setting what I think are the correct parameters.  Suggestions for how to
properly set a white background would be welcome.

Thanks in advance,

Scot


# for non-lattice
> par("bg"="white")
> par("bg")
[1] "white"

# for lattice
background<-trellis.par.get("background")
background$col<-"white"
trellis.par.set("background",background)

> trellis.par.get("background")
$col
[1] "white"

# produces gray background in png, but white when plotted in active device
> png(filename = "c:/windows/temp/test.png", width=480, height=640,
+ pointsize = 10, bg="white")
> histogram(rnorm(500))
> dev.off()
windows
      2

Vitals:

> R.version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.2
year     2003
month    01
day      10
language R


--
  Scot W. McNary  email:smcnary at charm.net


From cortega at unitec.edu  Mon Mar 10 18:41:57 2003
From: cortega at unitec.edu (Cesar Ortega)
Date: Mon, 10 Mar 2003 18:41:57 +0100
Subject: [R] sampling and gini index
Message-ID: <40d86e2176dddd74.76dddd7440d86e21@unitec.edu>

Thanks for you input,

However, I still need to do the following:

1. How can I work on the other 2 methods:Fixed systematic sampling and.
Proportional sampling Madow.

2. After I have done the 3 samplings methods, obtaining M(1000,or 2000, 
or more, etc. for each sampling method) samples of n ( 3,4, 5, etc)
elements in a column,I need to take one by one each of the 1000, 2000, 
etc. samples of each n elements and calculate in the 3 sampling methods:

a. PI(i)=n/N in simple and fixed sampling and i belogns to the sample. 
PI(i) In MADOW is proprortional to an auxiliary variable Xi:PI(i)=RXi,
where r= MOD(TN,R), and TN=SUMi(Xi), i to N.
WE KNOW r, AND TN, BUT WE NEED TO FIND R FROM THE MODAL AND r.

ALSO CALCULATE:
ESTIMATED N= SUM {1/PI(i)};
ESTIMATED T(Y)= SUM {Yi/PI(i)};  i belongs to the sample.

GINMi=[SUMi{(Yi/PI(i))*[1/PI(i)+SUMj(2/PI(j)]}]/[(2*ESTIMATED 
N*ESTIMATED T)].     i belongs to  M (1000,etc.) times, WHERE j=i+1

WE HAVE ONLY ONE VARIABLE Y, BUT WITH THE FIRST POSITION i AND THE
NEXT j, IN THE ASCENDING ORDER.

And last to get the errors as:

E1=  [SUMi {|GINP-GINMi |}]/[M] ; i belongs M

E2= SQRT[SUMi {|GINP-GINMi |}]/[M]; i belongs TO M

Thanks for your kind response,

Cesar
----- Original Message -----
From: Achim Zeileis <zeileis at ci.tuwien.ac.at>
Date: Monday, March 10, 2003 6:03 pm
Subject: Re: [R] sampling and gini index

> On Monday 10 March 2003 16:34, Carlos Ortega wrote:
> 
> > Cesar,
> >
> > For the first part, please check the function included. For the
> > sampling, please check "?sample".
> >
> > Regards,
> > Carlos.
> >
> > g.index<-function(y) {
> > 	sum.res<-0
> > 	y.lg<-length(y)
> > 	y.mean<-mean(y)
> >
> > 	for (i in 1:y.lg) {
> >   	        for (j in 1:y.lg) {
> >     	                ratio.res<-abs(y[i]-y[j]) / (2 * y.lg^2 
* 
> y.mean)>     	                sum.res<-sum.res+ratio.res
> >   	        }
> > 	}
> >   	return(sum.res)
> >  }
> >
> >  y<-rnorm(284)
> >  g.index(y)
> >
> 
> A more efficient implementation of the Gini index can be found in 
> the 
> ineq package. See
>  help(Gini)
>  help(ineq)
> Z
> 
> >
> >
> >
> > -----Mensaje original-----
> > De: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Cesar Ortega
> > Enviado el: lunes, 10 de marzo de 2003 12:17
> > Para: r-help at stat.math.ethz.ch
> > CC: r-help at stat.math.ethz.ch
> > Asunto: [R] sampling and gini index
> >
> >
> > Hi there,
> >
> >
> > I am new in R, and I was wondering if I could do the following 
> in R,
> > since I have tried in SPSS and I have only done part of it.  I
> > would appreciate any help to build this routine in R, if possible:
> >
> >
> >
> > I have a column of 284 elements Y, [...]
> >
> > > Iam reading these as 284 cases with a single
> > > variable, which I will call Y
> > >
> > > >  where first I need to calculate:
> > > >
> > > >GINP=[SUMi SUMj {|Yi - Yj|}]/[2(N**2)*MEAN(Y)], where Yi and Yj
> > >
> > > are
> > >
> > > >the 284 elements, 0<Y1<=Y2...<=Y284.  j: is the next position of
> > > > i.
> > >
> > > Here, I am doing a calculation to yield a single number.
> > > Calculating
> >
> >  (I assume that N=284)
> >
> > > >Next, I need to take the 284 numbers and resampling them in
> > >
> > > [groups
> > >
> > > >of] n data (like 3, 4, 5,  etc) for M number of samples ( like
> > >
> > > 1000,
> > >
> > > >2000, etc, one at a time) in 3 sampling methods:
> > > >
> > > >1. Simple sampling without replacing.
> > > >2. Fixed systematic sampling.
> > > >3. Proportional sampling Madow.
> >
> > SIMPLE SAMPLING WITHOUT REPLACING THE POSITION VALUE, FOR 
> INTANCE 3,
> > IF WE HAVE THE POSITION 3,7,9 WITH ITS VALUES, WE COULD HAVE 3,7,10,
> > BUT WE COULD NOT HAVE THE POSITIONS 9,3,7 AGAIN.  SO THIS IS A
> > COMBINATION, AND IF WE TAKE 3 COMBINATIONS OUT 284 WE HAVE
> > 284!/(3!*281!). AND WE NEED TO START FROM 1000 GROUPS OF
> > COMBINATIONS. IT IS LIKE
> > IF WE HAVE 1,2,3,4,5 AND WE WANT COMBINATIONS OF 2, WE COULD 
> HAVE IN
> > 1,2 AND 1,3 AND 1,4 AND 1,5 AND 2,3 AND 2,4, ETC, BUT IN RANDOM
> > ORDER.
> >
> > > >After I have the M(1000, 2000) samples of n ( 3,4, 5)elements in
> > >
> > > a column,
> > >
> > > >I need to take one by one each of the 1000 samples of each n
> > >
> > > elements
> > >
> > > >and calculate:
> > > >
> > > >PI(i)=n/N in simple and fixed sampling and i belogns to the
> > >
> > > sample. In
> > >
> > > >MADOW  PI(i) is proprortional to an auxiliary variable Xi:PI(i)=
> > >
> > > RXi,
> > >
> > > >where r= MOD(TN,R), and TN=SUMi(Xi), i to N.
> >
> > WE KNOW r, AND TN, BUT WE NEED TO FIND R FROM THE MODAL AND r.
> >
> > AND CALCULATE:
> > > >ESTIMATED N= SUM {1/PI(i)};
> > > >ESTIMATED T(Y)= SUM {Yi/PI(i)};  i belongs to the sample.
> >
> > GINMi=[SUMi{(Yi/PI(i))*[1/PI(i)+SUMj(2/PI(j)]}]/[(2*ESTIMATED
> > N*ESTIMATED T)].     i belongs to  M (1000) times, WHERE j=i+1
> >
> > WE HAVE ONLY ONE VARIABLE Y, BUT WITH THE FIRST POSITION i AND THE
> > NEXT j, IN THE ASCENDING ORDER.
> >
> > > >And last to get the errors as:
> > > >
> > > >E1=  [SUMi {|GINP-GINMi |}]/[M] ; i belongs M
> > > >
> > > >E2= SQRT[SUMi {|GINP-GINMi |}]/[M]; i belongs TO M
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> > ###  This email has been checked for all known viruses by the
> > ###  Firstnet anti-virus system - http://www.firstnet.net.uk
> > ###  Please email fav at firstnet.net.uk for details.
> >
> >
> > _____
> > The information in this email is confidential and it may not be\...
> > [[dropped]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>


From paradis at isem.univ-montp2.fr  Mon Mar 10 19:02:56 2003
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Mon, 10 Mar 2003 19:02:56 +0100
Subject: [R] ape 1.0 is on CRAN
Message-ID: <4.2.0.58.20030310180205.00b4c980@162.38.183.200>

Dear all,

The version 1.0 of ape (analysis of phylogenetics and evolution) is now on 
CRAN. The jump from version 0.2-1 to 1.0 is explained by the fact that the 
initial objectives of the project have been completed. The relevant part of 
the Changes file is shown below. All comments, suggestions, or bug reports 
are welcome.

Emmanuel Paradis



		CHANGES IN APE VERSION 1.0


NEW FEATURES

     o Two new functions, read.dna() and write.dna(), read/write in a file
       DNA sequences in interleaved or in sequential format.

     o Two new functions, read.nexus() and write.nexus(), read/write trees
       in a NEXUS file.

     o The new function bind.tree() allows to bind two trees together,
       possibly handling root edges to give internal branches.

     o The new function drop.tip() removes the tips in a phylogenetic tree,
       and trims (or not) the corresponding internal branches.

     o The new function is.ultrametric() tests if a tree is ultrametric.

     o The function plot.phylo() has more functionalities such as drawing the
       branches with different colours and/or different widths, showing the
       node labels, controling the position and font of the labels, rotating
       the labels, and controling the space around the plot.

     o The function read.tree() can now read trees with no branch length,
       such as "(a,b),c);". Consequently, the element `edge.length' in
       objects of class "phylo" is now optional.

     o The function write.tree() has a new default behaviour: if the default
       for the option `file' is used (i.e. file = ""), then a variable of
       mode character containing the tree in Newick format is returned which
       can thus be assigned (e.g., tree <- write.tree(phy)).

     o The function read.tree() has a new argument `text' which allows
       to read the tree in a variable of mode character.

     o A new data set is included: the phylogenetic relationships among
       the orders of birds from Sibley and Ahlquist (1990).


From ripley at stats.ox.ac.uk  Mon Mar 10 19:23:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 10 Mar 2003 18:23:03 +0000 (GMT)
Subject: [R] graphics backgrounds from gray to white in png()
In-Reply-To: <20030310124506.J51240-100000@fellspt.charm.net>
Message-ID: <Pine.LNX.4.44.0303101820570.5327-100000@gannet.stats>

Why are you using lattice for a single plot?

If you use lattice, you should be using trellis.device(), or at least
setting the lattice parameters *after* you open the device.  You set the 
parameters for a screen device (or whatever you had open before).

On Mon, 10 Mar 2003, Scot W McNary wrote:

> 
> 
> Hi,
> 
> I'm trying to make a png file of a histogram.  I would like a white
> background in the final product but end up producing a gray one, despite
> setting what I think are the correct parameters.  Suggestions for how to
> properly set a white background would be welcome.
> 
> Thanks in advance,
> 
> Scot
> 
> 
> # for non-lattice
> > par("bg"="white")
> > par("bg")
> [1] "white"
> 
> # for lattice
> background<-trellis.par.get("background")
> background$col<-"white"
> trellis.par.set("background",background)
> 
> > trellis.par.get("background")
> $col
> [1] "white"
> 
> # produces gray background in png, but white when plotted in active device
> > png(filename = "c:/windows/temp/test.png", width=480, height=640,
> + pointsize = 10, bg="white")
> > histogram(rnorm(500))
> > dev.off()
> windows
>       2

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jfox at mcmaster.ca  Mon Mar 10 18:46:19 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 10 Mar 2003 12:46:19 -0500
Subject: [R] Least-squares means
In-Reply-To: <3E6CB1CF.20401@wanadoo.fr>
Message-ID: <5.0.2.1.0.20030310124351.0297a628@mcmail.cis.mcmaster.ca>

Dear Philippe,

Take a look at effect, all.effects, and related functions (such as plot 
methods) in the car package. It will probably do what you want, and works 
for linear and generalized linear models. A slightly more general version 
is planned for the next release of car.

John

At 04:39 PM 3/10/2003 +0100, Philippe Hup? wrote:
>Is there any function to compute Least-squares means from a linear model 
>as lsmeans does in SAS.

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox


From deepayan at stat.wisc.edu  Mon Mar 10 19:47:10 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 10 Mar 2003 12:47:10 -0600
Subject: [R] graphics backgrounds from gray to white in png()
In-Reply-To: <20030310124506.J51240-100000@fellspt.charm.net>
References: <20030310124506.J51240-100000@fellspt.charm.net>
Message-ID: <200303101247.10907.deepayan@stat.wisc.edu>


You need to change the (lattice) background setting AFTER starting the png() 
device (lattice maintains separate settings for different devices). 

If you use png() to start subsequent devices, the same settings will be 
re-used. (The alternative is to use trellis.device(), which is the more 
traditional but not-really-necessary-in-lattice way, in which case by default 
the settings will revert back to the grey background every time a new device 
is started.)

On Monday 10 March 2003 11:48 am, Scot W McNary wrote:
> Hi,
>
> I'm trying to make a png file of a histogram.  I would like a white
> background in the final product but end up producing a gray one, despite
> setting what I think are the correct parameters.  Suggestions for how to
> properly set a white background would be welcome.
>
> Thanks in advance,
>
> Scot
>
>
> # for non-lattice
>
> > par("bg"="white")
> > par("bg")
>
> [1] "white"
>
> # for lattice
> background<-trellis.par.get("background")
> background$col<-"white"
> trellis.par.set("background",background)
>
> > trellis.par.get("background")
>
> $col
> [1] "white"
>
> # produces gray background in png, but white when plotted in active device
>
> > png(filename = "c:/windows/temp/test.png", width=480, height=640,
>
> + pointsize = 10, bg="white")
>
> > histogram(rnorm(500))
> > dev.off()
>
> windows
>       2
>
> Vitals:
> > R.version
>
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R
>
>
> --
>   Scot W. McNary  email:smcnary at charm.net
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Guangchun.Song at stjude.org  Mon Mar 10 17:43:18 2003
From: Guangchun.Song at stjude.org (Song, Guangchun)
Date: Mon, 10 Mar 2003 10:43:18 -0600
Subject: [R] help--Cox ph model
Message-ID: <A1DAD6685C12D511B20F0003472515138E6900@sjmemexc3.stjude.org>

Dear r-users,

I want to use the Cox's ph model to analyze survival data set.  How can I
extract the model coefs. and Wald test p-value or Score?

For example: I use the data set melanom in iSwR package.

> library(survival)
> data(melanom)
> attach(melanom)
> cox.model <- coxph(Surv(days,status==1)~sex)
> summary(cox.model)
Call:
coxph(formula = Surv(days, status == 1) ~ sex)

  n= 205 

     coef exp(coef) se(coef)    z     p
sex 0.662      1.94    0.265 2.50 0.013

    exp(coef) exp(-coef) lower .95 upper .95
sex      1.94      0.516      1.15      3.26

Rsquare= 0.03   (max possible= 0.937 )
Likelihood ratio test= 6.15  on 1 df,   p=0.0131
Wald test            = 6.24  on 1 df,   p=0.0125
Score (logrank) test = 6.47  on 1 df,   p=0.0110


Thanks.

Guangchun


From fjmolina at lbl.gov  Mon Mar 10 20:55:46 2003
From: fjmolina at lbl.gov (Francisco J Molina)
Date: Mon, 10 Mar 2003 11:55:46 -0800
Subject: [R] 
Message-ID: <15980.60866.871103.832440@0-e0-98-8a-c5-4a.dhcp.lbl.gov>

Subject: separator = TAB in write.table
X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
Reply-To: fjmolina at lbl.gov
FCC: /home/f/.xemacs/mail/sent


How can I choose my separator to be TAB in functions like write.table ()?


From sundar.dorai-raj at pdf.com  Mon Mar 10 21:13:42 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 10 Mar 2003 14:13:42 -0600
Subject: [R]
References: <15980.60866.871103.832440@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
Message-ID: <3E6CF1F6.8090400@pdf.com>

sep = "\t"

Francisco J Molina wrote:
> Subject: separator = TAB in write.table
> X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
> Reply-To: fjmolina at lbl.gov
> FCC: /home/f/.xemacs/mail/sent
> 
> 
> How can I choose my separator to be TAB in functions like write.table ()?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From cmoffet at nwrc.ars.usda.gov  Mon Mar 10 21:20:01 2003
From: cmoffet at nwrc.ars.usda.gov (Corey Moffet)
Date: Mon, 10 Mar 2003 13:20:01 -0700
Subject: [R] 
In-Reply-To: <15980.60866.871103.832440@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
Message-ID: <3.0.6.32.20030310132001.00f59e20@nwrc.ars.usda.gov>


write.table(df, file = "filename", sep = "\t")

At 11:55 AM 3/10/2003 -0800, Francisco J Molina wrote:
>Subject: separator = TAB in write.table
>X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
>Reply-To: fjmolina at lbl.gov
>FCC: /home/f/.xemacs/mail/sent
>
>
>How can I choose my separator to be TAB in functions like write.table ()?
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Support Scientist

University of Idaho
Northwest Watershed Research Center
800 Park Blvd, Plaza IV, Suite 105
Boise, ID 83712-7716
(208) 422-0718


From krcabrer at perseus.unalmed.edu.co  Mon Mar 10 21:32:48 2003
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Mon, 10 Mar 2003 15:32:48 -0500
Subject: [R] 
In-Reply-To: <15980.60866.871103.832440@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
References: <15980.60866.871103.832440@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
Message-ID: <oprlt50yntfaouaq@200.24.8.4>

use the option sep="\t" on write.table.
see ?write.table


On Mon, 10 Mar 2003 11:55:46 -0800, Francisco J Molina <fjmolina at lbl.gov> 
wrote:

> Subject: separator = TAB in write.table
> X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
> Reply-To: fjmolina at lbl.gov
> FCC: /home/f/.xemacs/mail/sent
>
>
> How can I choose my separator to be TAB in functions like write.table ()?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



-- 
Using M2, Opera's revolutionary e-mail client: http://www.opera.com/m2/


From p.dalgaard at biostat.ku.dk  Mon Mar 10 22:18:57 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Mar 2003 22:18:57 +0100
Subject: [R] help--Cox ph model
In-Reply-To: <A1DAD6685C12D511B20F0003472515138E6900@sjmemexc3.stjude.org>
References: <A1DAD6685C12D511B20F0003472515138E6900@sjmemexc3.stjude.org>
Message-ID: <x2adg2yl6m.fsf@biostat.ku.dk>

"Song, Guangchun" <Guangchun.Song at stjude.org> writes:

> Dear r-users,
> 
> I want to use the Cox's ph model to analyze survival data set.  How can I
> extract the model coefs. and Wald test p-value or Score?

Unlike most other modelling code, summary.coxph() just prints its
results rather than store them in an object that can be queried. So
basically, you need to copy code from summary.coxph. It's not all that
hard. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From djw1005 at cam.ac.uk  Mon Mar 10 23:16:21 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Mon, 10 Mar 2003 22:16:21 +0000 (GMT)
Subject: [R] Biplots
Message-ID: <Pine.SOL.3.96.1030310220933.6346A-100000@draco.cus.cam.ac.uk>


I want to plot biplots. I have seen the function biplot, but there are
some extra features I would like, that I do not know how to achieve.

1. My observations, and my variables, fall into groups. Is there a way to,
say, plot the observations in several different colours, according to
which group the observation falls into? Similarly with the variables? I am
used to the lattice idiom, in which one specifies groups= and
panel.groups=, but biplot is not (if I understand correctly) a lattice
function, and I don't know how to express what I want with the biplot
command. 

2. I would like to not plot arrows but instead plot axes for the
variables, as suggested by Gower & Hand (1996). Or, ideally, plot axis
lines which extend on either side of the origin, as far as the maximum and
minimum observed value for that variable.

Damon Wischik.


From zynnel at yahoo.com  Mon Mar 10 23:46:07 2003
From: zynnel at yahoo.com (Elena Zheleva)
Date: Mon, 10 Mar 2003 14:46:07 -0800 (PST)
Subject: [R] libR.so - not recognized
In-Reply-To: <20030310082442.B3037@jessie.research.bell-labs.com>
Message-ID: <20030310224607.31547.qmail@web11806.mail.yahoo.com>

Thank you for your help! That brings the question of
whether it is possible to pass a list to an R function
from a C application without creating a STRSXP list
with allocVector in the C application first (and using
eval). My main application is in C.

> In some cases, rather than creating a stand-alone
> application that
> embeds R, you can run your code from within R and
> have the same effect
> but avoiding issues such as libR.so,
> LD_LIBRARY_PATH, etc.  And since
> you are using Gtk, it might be possible to program
> the GUI entirely
> within R via RGtk and related packages.
> 
> Good luck.
> 
> 
> > 
> > elena zheleva
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> >
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> -- 
>
_______________________________________________________________
> 
> Duncan Temple Lang               
> duncan at research.bell-labs.com
> Bell Labs, Lucent Technologies    office:
> (908)582-3217
> 700 Mountain Avenue, Room 2C-259  fax:   
> (908)582-3340
> Murray Hill, NJ  07974-2070       
>          http://cm.bell-labs.com/stat/duncan


From tblackw at umich.edu  Mon Mar 10 23:54:55 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 10 Mar 2003 17:54:55 -0500 (EST)
Subject: [R] Biplots
In-Reply-To: <Pine.SOL.3.96.1030310220933.6346A-100000@draco.cus.cam.ac.uk>
Message-ID: <Pine.SOL.4.44.0303101731080.21563-100000@robotron.gpcc.itd.umich.edu>



On Mon, 10 Mar 2003, Damon Wischik wrote:

> I want to plot biplots. I have seen the function biplot, but there are
> some extra features I would like, that I do not know how to achieve.
>
> 1. My observations, and my variables, fall into groups. Is there a way to,
> say, plot the observations in several different colours, according to
> which group the observation falls into? Similarly with the variables? I am
> used to the lattice idiom, in which one specifies groups= and
> panel.groups=, but biplot is not (if I understand correctly) a lattice
> function, and I don't know how to express what I want with the biplot
> command.
>
> 2. I would like to not plot arrows but instead plot axes for the
> variables, as suggested by Gower & Hand (1996). Or, ideally, plot axis
> lines which extend on either side of the origin, as far as the maximum and
> minimum observed value for that variable.
>
> Damon Wischik.

One of the glories of R is that you're NOT limited to showing what's
already canned in custom plots.  However, it usually takes much more
work than a one-line command.  Build a matrix or data frame with the
x-y values for the points you want to show and use plot(), then many
calls to points(), lines(), text(), symbols(), axis(), title(), etc.
to build up the graphic display you want, piece by piece.  Tedious,
but it's totally flexible, and you get exactly the display you want.
And, with postscript(), the result looks absolutely great !  See the
help for each of the functions listed above, also for par() to change
the size or aspect ratio of the plot on the page.

I find it helpful to build up a script of plotting commands in a text
editor window, then run 'source("filename")' on each new version I've
saved.  My scripts the first time through use literal names for the
data objects in the workspace.  There's always time later to package
it up inside a function definition, and think then about what I would
want to be able to pass in as function arguments and what I'm willing
to leave wired into the code.  In practice, I almost never do this
polishing.  Instead, the  next time I'm doing such a problem, I grab
a few ideas from an old script and essentially start again.  That's
how I do it.  Maybe others have a much more elegant way.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -


From jerrytheshrub at hotmail.com  Tue Mar 11 00:54:47 2003
From: jerrytheshrub at hotmail.com (Jeremy Z Butler)
Date: Tue, 11 Mar 2003 12:54:47 +1300
Subject: [R] including point char. in plotted text string
Message-ID: <F9PlrwAnekVgKMy5KIN00026c67@hotmail.com>

Hi,
Is there a way to paste() a point character symbol (e.g. pch=4) into a 
text() or mtext() string? Maybe theres another function that would work ... 
expression()??
Cheers, J


From krcabrer at epm.net.co  Tue Mar 11 05:41:22 2003
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Mon, 10 Mar 2003 23:41:22 -0500
Subject: [R] fft help
Message-ID: <3E6D68F2.6080808@epm.net.co>

Hi R-users:
I want to know if there is an easy way to obtain a Fourier Transform form
a vector or an array (just like fft does),  but with a more density base.
I mean, if I have a vector of 512 of length, I want the Fourier 
Transform to
be 1024, or 2048, etc, in length (de u domain). Or should I modify the
fft C code to do that?


If I want to modify the precision of the fft function, which parameter
of the .Machine option do I modify, and how?

Thank you for your help.

Kenneth Cabrera


From tore.wentzel-larsen at helse-bergen.no  Tue Mar 11 08:43:12 2003
From: tore.wentzel-larsen at helse-bergen.no (Tore Wentzel-Larsen)
Date: Tue, 11 Mar 2003 08:43:12 +0100
Subject: [R] Interrater and intrarater reliability
Message-ID: <2BCE4822277DDF4A93570D7D01B0AAA82D34DE@ted.ihelse.net>

Dear R users

The following function is R code for the main compuations in the article:
M. Eliasziw, S Lorraine Young, M Gail Woodbury and Karen Fryday-Field (1994):
Statistical Methodology for the Concurrent Assessment of Intrarater and 
Intrarater Reliability: Using Goniometric Measurements as an Example.
Physical Therapy 74 (8); 777-788

The function gives the estimated inter- and intrarater reliabilities
(rhohat) for fixed and random rater effects, partial intrarater
reliabilities for each rater, F test statistics with corresponding 
p-values, lower bounds for one-sided confiodence intervals and
standard errors of measurement.

The defaults are set up for use in a current project.
Script for testing in the example in the article is included below the function.

Tore Wentzel-Larsen
statistician
Centre for Clinical Research
Haukeland University Hospital
N-5021 Bergen, Norway
email: tore.wentzel-larsen at helse-bergen.no

the function:
---------------------------------------------------------------------------------
relInterIntra<-function(Results,nsubj=40,nrater=3,nmeas=2,raterLabels=c('a','b','c'),rho0inter=0.6,rho0intra=.8,conf.level=.95)
{
# gives the reliability coefficients in the article by Eliasziw et. al. 1994; Phys. Therapy 74.8; 777-788.
# all references in this function are to this article.
# input: Results, data frame representating a data structure as in Table 1 (p. 779), 
#	with consecutive measurements for each rater in adjacent columns.
# rho0inter: null hypothesis value of the interrater reliability coefficient
# rho0intra: null hypothesis value of the intrarater reliability coefficient
# conf.level: confidence level of the one-sided confidence intervals reported for the reliability coefficients
Frame1<-data.frame(cbind(
	rep(1:nsubj,nrater*nmeas),rep(1:nrater,rep(nsubj*nmeas,nrater)),
	rep(rep(1:nmeas,rep(nsubj,nmeas)),nrater),
	matrix(as.matrix(Results),ncol=1)))
names(Frame1)<-c('Subject','Rater','Repetation','Result')
Frame1$Subject<-factor(Frame1$Subject)
Frame1$Rater<-factor(Frame1$Rater,labels=raterLabels)
Frame1$Repetation<-factor(Frame1$Repetation)
nn<-nsubj # this and following two commands: aliases for compatibility with Eliasziw et. al. notation
tt<-nrater
mm<-nmeas
aovFull<-aov(Result~Subject*Rater,data=Frame1)
meanSquares<-summary(aovFull)[[1]][,3]
for (raterAct in 1:tt)
{
raterActCat<-raterLabels[raterAct]
aovAct<-aov(Result~Subject,data=Frame1[Frame1$Rater==raterActCat,])
meanSquares<-c(meanSquares,summary(aovAct)[[1]][2,3])
}
names(meanSquares)<-c('MSS','MSR','MSSR','MSE',paste('MSE',levels(Frame1$Rater),sep=''))

MSS<-meanSquares[1]
MSR<-meanSquares[2]
MSSR<-meanSquares[3]
MSE<-meanSquares[4]
MSEpart<-meanSquares[-(1:4)] # the same for random and fixed, see table 2 (p. 780) and 3 (p. 281)
sighat2Srandom<-(MSS-MSSR)/(mm*tt)
sighat2Rrandom<-(MSR-MSSR)/(mm*nn)
sighat2SRrandom<-(MSSR-MSE)/mm
sighat2e<-MSE # the same for random and fixed, see table 2 (p. 780) and 3 (p. 281)
sighat2Sfixed<-(MSS-MSE)/(mm*tt)
sighat2Rfixed<-(MSR-MSSR)/(mm*nn)
sighat2SRfixed<-(MSSR-MSE)/mm
sighat2e.part<-MSEpart # the same for random and fixed, see table 2 (p. 780) and 3 (p. 281)
rhohat.inter.random<-sighat2Srandom/
	(sighat2Srandom+sighat2Rrandom+sighat2SRrandom+sighat2e)
rhohat.inter.fixed<-(sighat2Sfixed-sighat2SRfixed/tt)/
	(sighat2Sfixed+(tt-1)*sighat2SRfixed/tt+sighat2e)
rhohat.intra.random<-(sighat2Srandom+sighat2Rrandom+sighat2SRrandom)/
	(sighat2Srandom+sighat2Rrandom+sighat2SRrandom+sighat2e)
rhohat.intra.fixed<-(sighat2Sfixed+(tt-1)*sighat2SRfixed/tt)/
	(sighat2Sfixed+(tt-1)*sighat2SRfixed/tt+sighat2e)
rhohat.intra.random.part<-(sighat2Srandom+sighat2Rrandom+sighat2SRrandom)/
	(sighat2Srandom+sighat2Rrandom+sighat2SRrandom+sighat2e.part)
rhohat.intra.fixed.part<-(sighat2Sfixed+(tt-1)*sighat2SRfixed/tt)/
	(sighat2Sfixed+(tt-1)*sighat2SRfixed/tt+sighat2e.part)
Finter<-(1-rho0inter)*MSS/((1+(tt-1)*rho0inter)*MSSR)
Finter.p<-1-pf(Finter,df1=nn-1,df2=(nn-1)*(tt-1))
alpha<-1-conf.level
nu1<-
(nn-1)*(tt-1)*
(
tt*rhohat.inter.random*(MSR-MSSR)+
nn*(1+(tt-1)*rhohat.inter.random)*MSSR+
nn*tt*(mm-1)*rhohat.inter.random*MSE
)^2/
(
(nn-1)*(tt*rhohat.inter.random)^2*MSR^2+
(nn*(1+(tt-1)*rhohat.inter.random)-tt*rhohat.inter.random)^2*MSSR^2+
(nn-1)*(tt-1)*(nn*tt*(mm-1))*rhohat.inter.random^2*MSE^2
)
nu2<-
(nn-1)*(tt-1)*
(
nn*(1+(tt-1)*rhohat.inter.fixed)*MSSR+
nn*tt*(mm-1)*rhohat.inter.fixed*MSE
)^2/
(
(nn*(1+(tt-1)*rhohat.inter.fixed))^2*MSSR^2+
(nn-1)*(tt-1)*(nn*tt*(mm-1))*rhohat.inter.fixed^2*MSE^2
)
F1<-qf(1-alpha,df1=nn-1,df2=nu1)
F2<-qf(1-alpha,df1=nn-1,df2=nu2)
lowinter.random<-nn*(MSS-F1*MSSR)/
(
nn*MSS+F1*(tt*(MSR-MSSR)+
nn*(tt-1)*MSSR+nn*tt*(mm-1)*MSE)
)
lowinter.random<-min(c(lowinter.random,1))
lowinter.fixed<-nn*(MSS-F2*MSSR)/
(
nn*MSS+F2*
(nn*(tt-1)*MSSR+nn*tt*(mm-1)*MSE)
)
lowinter.fixed<-min(c(lowinter.fixed,1))
Fintra<-(1-rho0intra)*MSS/((1+(mm-1)*rho0intra)*MSE*tt)
Fintra.p<-1-pf(Fintra,df1=nn-1,df2=nn*(mm-1))
Fintra.part<-(1-rho0intra)*MSS/((1+(mm-1)*rho0intra)*MSEpart*tt)
Fintra.part.p<-1-pf(Fintra.part,df1=nn-1,df2=nn*(mm-1))
F3<-qf(1-alpha,df1=nn-1,df2=nn*(mm-1))
lowintra<-(MSS/tt-F3*MSE)/(MSS/tt+F3*(mm-1)*MSE)
lowintra<-min(c(lowintra,1))
F4<-qf(1-alpha,df1=nn-1,df2=nn*(mm-1))
lowintra.part<-(MSS/tt-F4*MSEpart)/(MSS/tt+F4*(mm-1)*MSEpart)
for (raterAct in 1:tt) lowintra.part[raterAct]<-min(lowintra.part[raterAct],1)
SEMintra<-sqrt(MSE)
SEMintra.part<-sqrt(MSEpart)
SEMinter.random<-sqrt(sighat2Rrandom+sighat2SRrandom+sighat2e)
SEMinter.fixed<-sqrt(sighat2SRfixed+sighat2e)
rels<-c(rhohat.inter.random,rhohat.intra.random,rhohat.inter.fixed,rhohat.intra.fixed,
rhohat.intra.random.part,rhohat.intra.fixed.part,
Finter,Finter.p,Fintra,Fintra.p,Fintra.part,Fintra.part.p,
lowinter.random,lowinter.fixed,lowintra,lowintra.part,
SEMintra,SEMintra.part,SEMinter.random,SEMinter.fixed)
names(rels)<-c('rhohat.inter.random','rhohat.intra.random','rhohat.inter.fixed','rhohat.intra.fixed',
paste('rhohat.intra.random.part',raterLabels,sep='.'),paste('rhohat.intra.fixed.part',raterLabels,sep='.'),
'Finter','pvalue.Finter','Fintra','pvalue.Fintra',paste('Fintra',raterLabels,sep='.'),paste('pvalue.Fintra',raterLabels,sep='.'),
'lowinter.random','lowinter.fixed','lowintra',paste('lowintra',raterLabels,sep='.'),
'SEMintra',paste('SEMintra.part',raterLabels,sep='.'),'SEMinter.random','SEMinter.fixed')
rels
} # end of function relInterIntra
--------------------------------------------------------------------------------------------------------


testing code for the Goniometer data from the article:
--------------------------------------------------------------------------------------------------------
table4<-matrix(c(
-2,16,5,11,7,-7,18,4,0,0,-3,3,7,-6,1,-13,2,4,-10,8,7,-3,-5,5,0,7,-8,1,-3,
0,16,6,10,8,-8,19,5,-3,0,-2,-1,9,-7,1,-14,1,4,-9,9,6,-2,-5,5,-1,6,-8,1,-3,
1,15,6,10,6,-8,19,5,-2,-2,-2,1,9,-6,0,-14,0,3,-10,8,7,-4,-7,5,-1,6,-8,2,-3,
2,12,4,9,5,-9,17,5,-7,1,-4,-1,4,-8,-2,-12,-1,7,-10,2,8,-5,-6,3,-4,4,-10,1,-5,
1,14,4,7,6,-10,17,5,-6,2,-3,-2,4,-10,-2,-12,0,6,-11,8,7,-5,-8,4,-3,4,-11,-1,-4,
1,13,4,8,6,-9,17,5,-5,1,-3,1,2,-9,-3,-12,0,4,-10,8,7,-5,-7,4,-4,4,-10,0,-5
),ncol=6)
relIIgon<-relInterIntra(Results=table4,nsubj=29,nrater=2,nmeas=3,raterLabels=c('universal','Lamoreux'))
relIIgon
--------------------------------------------------------------------------------------------------------


From Colin.Bleay at bristol.ac.uk  Tue Mar 11 11:58:24 2003
From: Colin.Bleay at bristol.ac.uk (CR Bleay)
Date: Tue, 11 Mar 2003 10:58:24 +0000 (GMT)
Subject: [R] RE: mvtnorm
Message-ID: <Pine.SOL.3.95q.1030311105607.28363E-100000@eis.bris.ac.uk>

I have been having problems getting the package "mvtnorm". I have been
able to get R to recognise "mvtnorm" but it cannot find the imbedded
functions.

has anybody had any similar problems, or any ideas as to what i need to
do which i haven't been doing.

cheers,

colin


From gb at stat.umu.se  Tue Mar 11 12:23:46 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=C3=B6ran_Brostr=C3=B6m?=)
Date: Tue, 11 Mar 2003 12:23:46 +0100 (CET)
Subject: [R] help--Cox ph model
In-Reply-To: <x2adg2yl6m.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0303111216140.4896-100000@tal.stat.umu.se>

On 10 Mar 2003, Peter Dalgaard BSA wrote:

> "Song, Guangchun" <Guangchun.Song at stjude.org> writes:
> 
> > Dear r-users,
> > 
> > I want to use the Cox's ph model to analyze survival data set.  How can I
> > extract the model coefs. and Wald test p-value or Score?
> 
> Unlike most other modelling code, summary.coxph() just prints its
> results rather than store them in an object that can be queried. So
> basically, you need to copy code from summary.coxph. It's not all that
> hard. 
> 
> 

On the other hand, you can do

> fit <- coxph(Surv(enter, exit, event) ~ season, data = rrv)
> coef(fit)
seasonspring seasonsummer   seasonfall 
   0.1900660   -0.4514284   -0.4560273 

and  'fit$score'  and  'fit$wald.test' to get score and Wald _statistics_. 

G?ran 
---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


From baron at cattell.psych.upenn.edu  Tue Mar 11 13:06:08 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue, 11 Mar 2003 07:06:08 -0500
Subject: [R] Goodman / Kruskal gamma
Message-ID: <20030311070608.A9292@cattell.psych.upenn.edu>

The Goodman/Kruskal gamma is a nice descriptive rank-order
correlation statistic, often used in psychology.  It is nice
because it is easy to understand.  It takes all pairs of values
of each variable and asks whether they are congruent (S+ is the
number in the same order for both variables) or discordant (S-,
opposite ranking).  The statistic is (S+ - S-)/(S+ + S-).  It is
like tau except for the denominator.  (And the significance test
is the same as the test for tau, in cor.test.)

In trying to find the gamma statistic in R, I found one version
as part of lrm in the Design library and another as part of
rcorr.cens in the Hmisc library.  The former won't compute if the
model does not converge.  The latter is not really gamma, because
it discards ties in only one of the two variables.

So here is a little function to compute gamma.  I tried other
ways of doing it, but this one seems as fast as any.  I post it
here to make sure I haven't made a major error.  x and y are
vectors of the same length.

goodman <- function(x,y){
  Rx <- outer(x,x,function(u,v) sign(u-v))
  Ry <- outer(y,y,function(u,v) sign(u-v))
  S1 <- Rx*Ry
  return(sum(S1)/sum(abs(S1)))}

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
R page:               http://finzi.psych.upenn.edu/


From luke at inpharmatica.co.uk  Tue Mar 11 13:08:24 2003
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Tue, 11 Mar 2003 12:08:24 +0000 (GMT)
Subject: [R] VIM Syntax Highlighting
In-Reply-To: <10839.1047261111@www19.gmx.net>
Message-ID: <Pine.LNX.4.21.0303111202470.32066-100000@dollis-hill.inpharmatica.co.uk>

On Mon, 10 Mar 2003, Fernando Henrique Ferraz Pereira da Rosa wrote:

>      Has anyone got vim to have syntax highlighting with R function codes? I
> know there's something similar that works with emacs (ESS or something like
> that), but I was wondering if anyone knew an equivalent that worked with vim.
> 

Version 5.6.70 of vim comes with a syntax file for "S-lang" as standard.
Either pick "S-lang" from the "Syntax" menu or do ":cal SetSyn("slang")"
on the vim command line. Not surprisingly, this works perfectly well 
with either S or R.

Luke Whitaker


From fharrell at virginia.edu  Tue Mar 11 13:59:16 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Tue, 11 Mar 2003 07:59:16 -0500
Subject: [R] Goodman / Kruskal gamma
In-Reply-To: <20030311070608.A9292@cattell.psych.upenn.edu>
References: <20030311070608.A9292@cattell.psych.upenn.edu>
Message-ID: <20030311075916.01ae5346.fharrell@virginia.edu>

On Tue, 11 Mar 2003 07:06:08 -0500
Jonathan Baron <baron at cattell.psych.upenn.edu> wrote:

> The Goodman/Kruskal gamma is a nice descriptive rank-order
> correlation statistic, often used in psychology.  It is nice
> because it is easy to understand.  It takes all pairs of values
> of each variable and asks whether they are congruent (S+ is the
> number in the same order for both variables) or discordant (S-,
> opposite ranking).  The statistic is (S+ - S-)/(S+ + S-).  It is
> like tau except for the denominator.  (And the significance test
> is the same as the test for tau, in cor.test.)
> 
> In trying to find the gamma statistic in R, I found one version
> as part of lrm in the Design library and another as part of
> rcorr.cens in the Hmisc library.  The former won't compute if the
> model does not converge.  The latter is not really gamma, because
> it discards ties in only one of the two variables.
> 
> So here is a little function to compute gamma.  I tried other
> ways of doing it, but this one seems as fast as any.  I post it
> here to make sure I haven't made a major error.  x and y are
> vectors of the same length.
> 
> goodman <- function(x,y){
>   Rx <- outer(x,x,function(u,v) sign(u-v))
>   Ry <- outer(y,y,function(u,v) sign(u-v))
>   S1 <- Rx*Ry
>   return(sum(S1)/sum(abs(S1)))}
> 
> -- 
> Jonathan Baron, Professor of Psychology, University of Pennsylvania
> R page:               http://finzi.psych.upenn.edu/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Hi Jonathan,

The "outer" method is elegant but uses too much memory for large datasets.  Use the outx=TRUE argument to rcorr.cens, which will give you gamma, with standard error.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From Colin.Bleay at bristol.ac.uk  Tue Mar 11 14:22:19 2003
From: Colin.Bleay at bristol.ac.uk (CR Bleay)
Date: Tue, 11 Mar 2003 13:22:19 +0000 (GMT)
Subject: [R]-mvtnorm 
In-Reply-To: <15980.60866.871103.832440@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
Message-ID: <Pine.SOL.3.95q.1030311131929.1616B-100000@eis.bris.ac.uk>

greetings,

I am having problems with getting R to recognise the Package "mvtnorm".
specifically it will pick up the existence of the packabe but will not
acknowledge the exostence of its functions.

does anybody have any ideas, or has encouneterd the same problem?

thank you,

colin


From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Mar 11 14:43:00 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 11 Mar 2003 14:43:00 +0100 (CET)
Subject: [R]-mvtnorm 
In-Reply-To: <Pine.SOL.3.95q.1030311131929.1616B-100000@eis.bris.ac.uk>
References: <Pine.SOL.3.95q.1030311131929.1616B-100000@eis.bris.ac.uk>
Message-ID: <Pine.LNX.4.51.0303111440030.9332@artemis.imbe.med.uni-erlangen.de>


> greetings,
>
> I am having problems with getting R to recognise the Package "mvtnorm".
> specifically it will pick up the existence of the packabe but will not
> acknowledge the exostence of its functions.
>

what exactly is the problem? You should be able to say

R> install.packages("mvtnorm")
R> library(mvtnorm)

and run some examples with

R> example(pmvt)

best,

Torsten

> does anybody have any ideas, or has encouneterd the same problem?
>
> thank you,
>
> colin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>


From cdeclercq at nordnet.fr  Tue Mar 11 15:58:28 2003
From: cdeclercq at nordnet.fr (Christophe Declercq)
Date: Tue, 11 Mar 2003 14:58:28 -0000
Subject: [R] VIM Syntax Highlighting
In-Reply-To: <Pine.LNX.4.21.0303111202470.32066-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <NGBBKLJCOLPAFMJIEMHCGEJACFAA.cdeclercq@nordnet.fr>



> De : r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]De la part de Luke Whitaker
> Envoy? : mardi 11 mars 2003 12:08
> ? : r-help at stat.math.ethz.ch
> Cc : mentus at gmx.de
> Objet : Re: [R] VIM Syntax Highlighting

[...]
> Version 5.6.70 of vim comes with a syntax file for "S-lang" as standard.
> Either pick "S-lang" from the "Syntax" menu or do ":cal SetSyn("slang")"
> on the vim command line. Not surprisingly, this works perfectly well
> with either S or R.
>

S-lang (see http://www.s-lang.org/) is not R/S...

As already said, you should use the 'r.vim' syntax file in recent versions
of vim.

Christophe
--
Christophe DECLERCQ, MD
Observatoire R?gional de la Sant? Nord-Pas-de-Calais
13, rue Faidherbe 59046 LILLE Cedex FRANCE
Phone +33 3 20 15 49 24
Fax   +33 3 20 55 92 30
E-mail c.declercq at orsnpdc.org


From rolf at math.unb.ca  Tue Mar 11 14:53:06 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 11 Mar 2003 09:53:06 -0400 (AST)
Subject: [R] fft help
Message-ID: <200303111353.h2BDr6o06639@gelfand.math.unb.ca>

Kenneth Cabrera wrote:

> I want to know if there is an easy way to obtain a Fourier Transform
> form a vector or an array (just like fft does),  but with a more
> density base.  I mean, if I have a vector of 512 of length, I want
> the Fourier Transform to be 1024, or 2048, etc, in length (de u
> domain). Or should I modify the fft C code to do that?

There is rarely if ever any point in calculating the discrete Fourier
transform at any more than n Frequencies (where n is the length of
the signal), because the transform at the n frequencies encodes
***all*** of the information in the original signal.

I.e. if you know the DFT at the Fourier frequencies omega_j, j = 0,
..., n-1 (omega_j = 2*pi*j/n, in radians per unit time) then you can
recover the original signal exactly from these values (via the
inverse DFT).

If you ***INSIST*** on calculating the DFT at a finer grid and want
to do this via the FFT, it is simple:  Just pad your signal with 0s.
E.g. if your signal has length 512 and you pad with 512 0s you will
get the DFT at Fourier frequencies with denominator 1024.

Do not kid yourself that you have gained any insight into the
behaviour of your signal by so-doing however.

> If I want to modify the precision of the fft function, which
> parameter of the .Machine option do I modify, and how?

I do not believe that ``modifying the precision of the fft function''
makes any sense.  In particular the question `` which parameter of
the .Machine option do I modify, and how?'' makes no sense at all as
far as I can discern.  ``.Machine'' is not an ``option'' it is an
object which provides information about the capability of the system
being used to store numerical values.  You cannot modify it --- those
capabilities are what you have, and that is that.


				cheers,

					Rolf Turner
					rolf at math.unb.ca


From mkondrin at hppi.troitsk.ru  Wed Mar 12 01:55:54 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Tue, 11 Mar 2003 16:55:54 -0800
Subject: [R] fft help
In-Reply-To: <3E6D68F2.6080808@epm.net.co>
References: <3E6D68F2.6080808@epm.net.co>
Message-ID: <3E6E859A.6000909@hppi.troitsk.ru>

Kenneth Cabrera wrote:

> Hi R-users:
> I want to know if there is an easy way to obtain a Fourier Transform form
> a vector or an array (just like fft does),  but with a more density base.
> I mean, if I have a vector of 512 of length, I want the Fourier 
> Transform to
> be 1024, or 2048, etc, in length (de u domain). Or should I modify the
> fft C code to do that?
>
There is no point in it. Procedure you are proposed to do is just sort 
of smoothing - it adds no new information. You see - fourier transform 
is just definition of new coordinates in functional space. If you have 
512 points - this is dimension of this space and coordinate basis can 
have only 512 vectors. Any other vectors (additional points in fourier 
transform) are linear combinations of them.


From freeman at u444.jussieu.fr  Tue Mar 11 15:12:25 2003
From: freeman at u444.jussieu.fr (Rebecca Freeman Grais)
Date: Tue, 11 Mar 2003 15:12:25 +0100
Subject: [R] beginner plotting with dates
Message-ID: <3E6DEEC9.4020109@u444.jussieu.fr>

Dear R-Help,

I am a beginner and have a question about plotting dates.  I am creating 
a very simple boxwhisker plot , boxplot(Total Case~Month).  When the 
boxplot appears, the months are re-ordered alphabetically.  I would like 
to be able to preserve the order, i.e. Jan, Feb, March, etc.  Is there a 
way to set the x-axis so that it is not automatically re-ordered? Thanks 
in advance for your help.


From lm.silva at sapo.pt  Tue Mar 11 15:22:31 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Tue, 11 Mar 2003 14:22:31 +0000 (WET)
Subject: [R] about  yesterday predicted values
Message-ID: <1047392551.3e6df127bea3c@webmail.sapo.pt>

I don't understand where is my problem. I tried the problem 
suggested by Prof. Brian Ripley

data(USAccDeaths, package="ts")

and it worked. So this is not a machine or configuration 
problem. This is my series (dataset1.ts)

          Jan      Feb      Mar      Apr      May      Jun  
Jul      Aug
1998 20957656 22280838 28048581 32286754 36456729 35575315 
34127179 34363108

1999 20597673 22495503 32313913 34403642 39324570 38507480 
36640790 36217094

2000 24841914 28977013 34243366 38180015 49119602 43809914 
41778152 45625301

2001 30366925 28705775 33911934 38647902 48854117 41389555 
43607174 41367514

2002 29111032 28055234 32778200 43894044 48513923 42018619 
38626430 38595853

2003 25680114 
27112446                                                      

          Sep      Oct      Nov      Dec
1998 34255786 33152873 29587196 25815553
1999 38141741 36711756 36950693 26657417
2000 46213806 45460357 39832263 31634397
2001 38920451 41416886 36272139 26559226
2002 42068682 41827283 33738721 31053206

I made 


dataset1.arima<-arima(x = dataset1.ts, order = c(2, 1, 0), 
seasonal = list(order = c(1, 1, 0)))

> predict(dataset1.arima,n.ahead=10)
$pred
               Mar           Apr           May           
Jun           Jul
2003  0.0007636733 -0.1296421510 -0.2341768144 -0.1240727672 -
0.1625043897
               Aug           Sep           Oct           
Nov           Dec
2003 -0.1726880234 -0.1537146941 -0.1628472385 -0.3301221034 -
0.2691800319

Where is my problem?
--
SAPO ADSL.PT, apanhe j? o comboio da Banda Larga. Kit SAPO ADSL.PT ?50

hTTP://www.sapo.pt/kitadsl


From vito.muggeo at giustizia.it  Tue Mar 11 15:20:30 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Tue, 11 Mar 2003 15:20:30 +0100
Subject: [R] about the "mini-distribution" (R for Win )
Message-ID: <004301c2e7d9$624f9f60$5c13070a@it.giustizia.it>

Dear all,
I've just downloaded the miniR.exe, miniR-1.bin,....,miniR-8.bin in order to
update R to 1.6.2 (I cannot download the file of 19Mb !). The installation
seems to have worked fine, but I can't find in the /bin dir several files
that were, for instance, in the /bin directory in the version 1.5.1

In particular the file Rcmd.exe is missing, therefore I cannot run R in
BATCH mode (I have the Perl installed on my PC).

Am I missing anything or did the installation fail?

best,
vito


From ripley at stats.ox.ac.uk  Tue Mar 11 15:37:51 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 11 Mar 2003 14:37:51 +0000 (GMT)
Subject: [R] beginner plotting with dates
In-Reply-To: <3E6DEEC9.4020109@u444.jussieu.fr>
Message-ID: <Pine.LNX.4.44.0303111436390.26682-100000@gannet.stats>

On Tue, 11 Mar 2003, Rebecca Freeman Grais wrote:

> I am a beginner and have a question about plotting dates.  I am creating 
> a very simple boxwhisker plot , boxplot(Total Case~Month).  When the 
> boxplot appears, the months are re-ordered alphabetically.  I would like 
> to be able to preserve the order, i.e. Jan, Feb, March, etc.  Is there a 
> way to set the x-axis so that it is not automatically re-ordered? Thanks 
> in advance for your help.

No, but you can set up Month (a factor?) with the levels in the order you 
want, and then boxplot will follow.  See ?factor.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Mar 11 15:43:31 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 11 Mar 2003 14:43:31 +0000 (GMT)
Subject: [R] about  yesterday predicted values
In-Reply-To: <1047392551.3e6df127bea3c@webmail.sapo.pt>
Message-ID: <Pine.LNX.4.44.0303111441290.26701-100000@gannet.stats>

On Tue, 11 Mar 2003, Luis Silva wrote:

> I don't understand where is my problem. I tried the problem 
> suggested by Prof. Brian Ripley
> 
> data(USAccDeaths, package="ts")
> 
> and it worked. So this is not a machine or configuration 
> problem. This is my series (dataset1.ts)

And I get

> predict(dataset1.arima,n.ahead=10)
$pred
          Mar      Apr      May      Jun      Jul      Aug
2003 32986447 39173626 47310648 40640324 39324741 38512562
          Sep      Oct      Nov      Dec
2003 39260897 40137559 33531143 27533809

$se
         Mar     Apr     May     Jun     Jul     Aug     Sep
2003 2595395 2727065 2852947 3292592 3470692 3640270 3881904
         Oct     Nov     Dec
2003 4056851 4224638 4407507

so I have no idea, except it *is* `a machine or configuration problem'.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lm.silva at sapo.pt  Tue Mar 11 15:43:57 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Tue, 11 Mar 2003 14:43:57 +0000 (WET)
Subject: [R] correction
Message-ID: <1047393837.3e6df62d61536@webmail.sapo.pt>

I have to make a correction

> dataset1.arima<-arima(x = dataset1.ts, order = c(2, 1, 0), 
seasonal = list(order = c(1, 1, 0)))

Error in optim(init[mask], armafn, method = "BFGS", hessian = 
TRUE, control = optim.control,  : 
        initial value in vmmin is not finite

This is the result when I use arima. The other results came 
when I tried several times the above call. How can I overcome 
this problem?

thanks 
luis
--
SAPO ADSL.PT, apanhe j? o comboio da Banda Larga. Kit SAPO ADSL.PT ?50

hTTP://www.sapo.pt/kitadsl


From ripley at stats.ox.ac.uk  Tue Mar 11 15:47:43 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 11 Mar 2003 14:47:43 +0000 (GMT)
Subject: [R] about the "mini-distribution" (R for Win )
In-Reply-To: <004301c2e7d9$624f9f60$5c13070a@it.giustizia.it>
Message-ID: <Pine.LNX.4.44.0303111445090.26701-100000@gannet.stats>

On Tue, 11 Mar 2003, vito muggeo wrote:

> I've just downloaded the miniR.exe, miniR-1.bin,....,miniR-8.bin in order to
> update R to 1.6.2 (I cannot download the file of 19Mb !). The installation
> seems to have worked fine, but I can't find in the /bin dir several files
> that were, for instance, in the /bin directory in the version 1.5.1
> 
> In particular the file Rcmd.exe is missing, therefore I cannot run R in
> BATCH mode (I have the Perl installed on my PC).

See the rw-FAQ for how to do so.

> Am I missing anything or did the installation fail?

No, it is a mini distribution. The files for compiling source packages are
not included (amongst others), and they were not included by default in 
1.5.1 either.

For rw1070, Rcmd.exe will be included in the mini distribution I expect.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Tue Mar 11 16:01:56 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 11 Mar 2003 16:01:56 +0100
Subject: [R] about the "mini-distribution" (R for Win )
In-Reply-To: <004301c2e7d9$624f9f60$5c13070a@it.giustizia.it>
References: <004301c2e7d9$624f9f60$5c13070a@it.giustizia.it>
Message-ID: <3E6DFA64.3010408@statistik.uni-dortmund.de>

vito muggeo wrote:
> Dear all,
> I've just downloaded the miniR.exe, miniR-1.bin,....,miniR-8.bin in order to
> update R to 1.6.2 (I cannot download the file of 19Mb !). The installation
> seems to have worked fine, but I can't find in the /bin dir several files
> that were, for instance, in the /bin directory in the version 1.5.1
> 
> In particular the file Rcmd.exe is missing, therefore I cannot run R in
> BATCH mode (I have the Perl installed on my PC).
> 
> Am I missing anything or did the installation fail?

For R-1.6.2 the mini distribution doesn't contain Rcmd.exe.

You have to download either the complete installation file rw1062.exe 
(19MB) or compile R yourself from sources (8.5 MB). The latter case make 
only sense if you have already got the compiler and tools (really huge 
for downloads).

Uwe Ligges


From mmiller3 at iupui.edu  Tue Mar 11 16:44:24 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: 11 Mar 2003 10:44:24 -0500
Subject: [R] beginner plotting with dates
References: <Pine.LNX.4.44.0303111436390.26682-100000@gannet.stats>
Message-ID: <87n0k1di1z.fsf@lumen.indyrad.iupui.edu>

>>>>> "ripley" == ripley  <ripley at stats.ox.ac.uk> writes:

    > On Tue, 11 Mar 2003, Rebecca Freeman Grais wrote:
    >> I am a beginner and have a question about plotting dates.
    >> I am creating a very simple boxwhisker plot ,
    >> boxplot(Total Case~Month).  When the boxplot appears, the
    >> months are re-ordered alphabetically.  I would like to be
    >> able to preserve the order, i.e. Jan, Feb, March, etc.  Is
    >> there a way to set the x-axis so that it is not
    >> automatically re-ordered? Thanks in advance for your help.

    > No, but you can set up Month (a factor?) with the levels in
    > the order you want, and then boxplot will follow.  See
    > ?factor.

I to create ordered factors from dates (and times) using chron.
For example:

> require(chron)
[1] TRUE
> dates(seq(1,100,by=10))
 [1] 01/02/70 01/12/70 01/22/70 02/01/70 02/11/70 02/21/70 03/03/70 03/13/70
 [9] 03/23/70 04/02/70
> x <- dates(seq(1,100))
> y <- seq(1,100)

> x
  [1] 01/02/70 01/03/70 01/04/70 01/05/70 01/06/70 01/07/70 01/08/70 01/09/70
  [9] 01/10/70 01/11/70 01/12/70 01/13/70 01/14/70 01/15/70 01/16/70 01/17/70
...

> plot(x,y)
> levels(months(x))
 [1] "Jan" "Feb" "Mar" "Apr" "May" "Jun" "Jul" "Aug" "Sep" "Oct" "Nov" "Dec"
> plot(months(x),y)

For time ranges spanning more than a single year, you can use
cut:

> x <- dates(seq(1,1000))
> y <- seq(1,1000)
> plot( cut(x,breaks='months'), y)

Mike


From ingo.roeder at imise.uni-leipzig.de  Tue Mar 11 17:07:28 2003
From: ingo.roeder at imise.uni-leipzig.de (Ingo Roeder)
Date: Tue, 11 Mar 2003 17:07:28 +0100
Subject: [R] objectname completion
Message-ID: <3E6E09C0.6050807@imise.uni-leipzig.de>

Dear R users,

is there any possibility to get an object-name completion within the R
command line (UNIX-version of R). As I got to know from the FAQ that 
this is possible from within Emacs (ESS), but without using Emacs?

Thank's
Ingo

-- 
-----------------------------------------------------------------
  Ingo Roeder

  Institute for Medical Informatics, Statistics and Epidemiology
  University of Leipzig
  phone: +49(0)341-97 16111,  fax: +49(0)341-97 16109
  email: ingo.roeder at imise.uni-leipzig.de

  Center for High Performance Computing
  University of Technology Dresden
  phone: +49(0)351-463 31945
-----------------------------------------------------------------


From glasgow at netplayers.biz  Mon Mar 10 15:29:00 2003
From: glasgow at netplayers.biz (Glasgow Players)
Date: Mon, 10 Mar 2003 14:29:00 +0000
Subject: [R] FAO: Staff & Students (Glasgow University & Glasgow Players)
Message-ID: <COMTECHSBSS8MyBuN6Q00001a8c@comtechsbs.comtechsupport.co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030310/c32dd585/attachment.pl

From p.dalgaard at biostat.ku.dk  Tue Mar 11 17:58:58 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 11 Mar 2003 17:58:58 +0100
Subject: [R] objectname completion
In-Reply-To: <3E6E09C0.6050807@imise.uni-leipzig.de>
References: <3E6E09C0.6050807@imise.uni-leipzig.de>
Message-ID: <x2hea96drh.fsf@biostat.ku.dk>

Ingo Roeder <ingo.roeder at imise.uni-leipzig.de> writes:

> Dear R users,
> 
> is there any possibility to get an object-name completion within the R
> command line (UNIX-version of R). As I got to know from the FAQ that
> this is possible from within Emacs (ESS), but without using Emacs?

A long-standing volunteers-welcome issue. The hooks in the readline
library are there (at least if you don't mind killing filename
completion), and getting the list of objects is essentially a matter
of cloning what ESS does.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From lm.silva at sapo.pt  Tue Mar 11 18:21:17 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Tue, 11 Mar 2003 17:21:17 +0000 (WET)
Subject: [R] MAPE
Message-ID: <1047403277.3e6e1b0d9e5ca@webmail.sapo.pt>

Hi again

With arima0 the problem was solved but what are the diferences 
between arima and arima0?

I have another question. I fit the model to the data and I make 
some predictions. But I also want to calculate MAPE based in 
the last 3 observations available. Is it possible? Can I obtain 
the fitted values from the model?

thanks~
luis
--
SAPO ADSL.PT, apanhe j? o comboio da Banda Larga. Kit SAPO ADSL.PT ?50

hTTP://www.sapo.pt/kitadsl


From abunn at montana.edu  Tue Mar 11 18:51:11 2003
From: abunn at montana.edu (Andy Bunn)
Date: Tue, 11 Mar 2003 10:51:11 -0700
Subject: [R] Time series application question
Message-ID: <000001c2e7f6$e0129340$1fa00ecf@simATE>

I am comparing the efficacy of two filtering techniques on a simulated
time series that has random and systematic errors. As the data is
simulated, I know the frequencies and amplitudes that generate the
systematic noise. I'm looking for a way to compare the techniques in a
simulation framework - i.e., I will generate many instances of the time
series varying the parameters, perform the filtering, and test the
filters against the input. I have started doing this by combining the
filtered series and the systematic noise as a single time series using
ts.union() and then running spectrum() and comparing the coherencies of
the filters against the systematic noise at the right frequencies. This
seems to work but it is simplistic. Can anybody think of a tidy method
in R of comparing two time series against a known spectrum to test which
one preserves that spectrum better?

Best regards, Andy


From rossini at blindglobe.net  Tue Mar 11 18:34:43 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue, 11 Mar 2003 09:34:43 -0800
Subject: [R] objectname completion
In-Reply-To: <x2hea96drh.fsf@biostat.ku.dk> (Peter Dalgaard BSA's message of
 "11 Mar 2003 17:58:58 +0100")
References: <3E6E09C0.6050807@imise.uni-leipzig.de>
	<x2hea96drh.fsf@biostat.ku.dk>
Message-ID: <87zno1olho.fsf@jeeves.blindglobe.net>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

>> is there any possibility to get an object-name completion within the R
>> command line (UNIX-version of R). As I got to know from the FAQ that
>> this is possible from within Emacs (ESS), but without using Emacs?
>
> A long-standing volunteers-welcome issue. The hooks in the readline
> library are there (at least if you don't mind killing filename
> completion), and getting the list of objects is essentially a matter
> of cloning what ESS does.

If you clone what ESS does, you have both object and filename
completion. 

Of course, you can also volunteer to fix what you don't like about
Emacs, as well, so that you can use ESS...

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------------
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(CHANGE: monday/wednesday/friday locations are completely unpredictable.)


From FMGCFMGC at terra.es  Tue Mar 11 20:19:41 2003
From: FMGCFMGC at terra.es (FMGCFMGC)
Date: Tue, 11 Mar 2003 19:19:41 GMT
Subject: [R] fft help
Message-ID: <1d79831d0336.1d03361d7983@teleline.es>

Hello!

I suppose you want to obtain a fft of length, for example, 1024, from a 
vector of size 100.

Fill the original vector with zeros to reach the desired length. This 
is called 'zero padding'

fftn <- function(x, n) {
  # fftn() - FFT of length n of a vector x
  # Note: It does not check if n<length(x)
  nx <- length(x)
  xx <- c(x, rep(0, n-nx))
  fft(xx)
}

See also ?nextn

Hope it helps!
Fran


From don at donarmstrong.com  Tue Mar 11 21:08:09 2003
From: don at donarmstrong.com (Don Armstrong)
Date: Tue, 11 Mar 2003 15:08:09 -0500
Subject: [R] changing pen mode [or adjusting for overlapping points?]
Message-ID: <20030311200809.GI3755@epsilon.donarmstrong.com>

I'm ploting a rather large number of points [~24,000] in two series
with slightly different distributions.

I would like to be able to effectively see where the two distributions
overlap by setting the pen mode (or it's equivalent) to allow the
overlapping portion to show up as a different color (or different
shade).

Unfortunatly, I couldn't find an option in par or postscript that
looks like it would be of use.

Ideas or suggestions?


Don Armstrong

-- 
She was alot like starbucks.
IE, generic and expensive.
 -- hugh macleod http://www.gapingvoid.com/batch3.htm

http://www.donarmstrong.com
http://www.anylevel.com
http://rzlab.ucr.edu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030311/ee13aa1d/attachment.bin

From f0z6305 at labs.tamu.edu  Tue Mar 11 21:22:29 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue, 11 Mar 2003 14:22:29 -0600
Subject: [R] About statistical independece or cumulant books or papers
Message-ID: <004d01c2e80b$f052fcd0$8bd75ba5@IE.TAMU.EDU>

Hey

I am now studying the statistical indepdence between
arbitray two random variables.
And want to use Cumulant or related method as
the starting point.

So anybody has some hints on providing me some
good textbooks or papers on cumulant or statistical
indepdence criteria?

Thanks a lot.

Fred


From spencer.graves at pdf.com  Tue Mar 11 21:24:26 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 11 Mar 2003 12:24:26 -0800
Subject: [R] changing pen mode [or adjusting for overlapping points?]
References: <20030311200809.GI3755@epsilon.donarmstrong.com>
Message-ID: <3E6E45FA.4020403@pdf.com>

  plot(1:2, col=1:2)

Is this what you want?
Spencer Graves

Don Armstrong wrote:
> I'm ploting a rather large number of points [~24,000] in two series
> with slightly different distributions.
> 
> I would like to be able to effectively see where the two distributions
> overlap by setting the pen mode (or it's equivalent) to allow the
> overlapping portion to show up as a different color (or different
> shade).
> 
> Unfortunatly, I couldn't find an option in par or postscript that
> looks like it would be of use.
> 
> Ideas or suggestions?
> 
> 
> Don Armstrong
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From jerosenb at hcs.harvard.edu  Tue Mar 11 21:39:36 2003
From: jerosenb at hcs.harvard.edu (janet rosenbaum)
Date: Tue, 11 Mar 2003 15:39:36 -0500 (EST)
Subject: [R] different file types
In-Reply-To: <Pine.SOL.4.30.0303100553390.7474-100000@ysidro.econ.uiuc.edu>
	from "Roger Koenker" at Mar 10, 2003 06:21:38 AM
Message-ID: <200303112039.h2BKda9e017881@hcs.harvard.edu>


Hi.  I am writing a program to read in different types of files from a
GUI.  While it's easy to read different types of text files, I am
stymied how to make R execute the input.  

Ideally I could get the command from input and dereference it like
	`command`(filename)
where command would be read.dta or read.table or read.xport or any of 
the similar commands.

Also, is there a way to make associative arrays?  
It would be nice to be able to get the format from input and then have
	command<-array[format]

Otherwise, I guess I'll just do cascading if's.

Thanks,

Janet Rosenbaum					  jerosenb at fas.harvard.edu
Center for Basic Research in the Social Sciences, Harvard University


From don at donarmstrong.com  Tue Mar 11 21:42:30 2003
From: don at donarmstrong.com (Don Armstrong)
Date: Tue, 11 Mar 2003 15:42:30 -0500
Subject: [R] changing pen mode [or adjusting for overlapping points?]
In-Reply-To: <3E6E45FA.4020403@pdf.com>
References: <20030311200809.GI3755@epsilon.donarmstrong.com>
	<3E6E45FA.4020403@pdf.com>
Message-ID: <20030311204229.GJ3755@epsilon.donarmstrong.com>

On Tue, 11 Mar 2003, Spencer Graves wrote:
>  plot(1:2, col=1:2)
> 
> Is this what you want?

Unless I'm mistaken, that just alternates which color is set for each
point.

What I'm looking for is a way to plot two (very large) separate
datasets on the same plot so that you can distinguish between the two.

EG: In this plot, http://rzlab.ucr.edu/images/test.png, the upper left
region should be some unique color, so you can see where the red
(currently hidden under the green) stops.


Don Armstrong

-- 
Build a fire for a man, an he'll be warm for a day.  Set a man on   
fire, and he'll be warm for the rest of his life. -- Jules Bean

http://www.donarmstrong.com
http://www.anylevel.com
http://rzlab.ucr.edu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030311/df712b71/attachment.bin

From gb at stat.umu.se  Tue Mar 11 21:59:02 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=C3=B6ran_Brostr=C3=B6m?=)
Date: Tue, 11 Mar 2003 21:59:02 +0100 (CET)
Subject: [R] Stair steps plotting
Message-ID: <Pine.LNX.4.44.0303112137560.6286-100000@tal.stat.umu.se>

Consider the following two ways of stair steps plotting:

plo <- function(ty = 2, steps = 200){
  old.par <- par(mfrow = c(2, 1))
  x <- seq(1, 100, length = steps)
  y <- seq(1, 10, length = steps)
  plot(x, y, type = "s", lty = ty, main = "Stair steps")

  x <- rep(x, each = 2)[-1]
  y <- rep(y, each = 2)[-2*steps]
  plot(x, y, type = "l", lty = ty, main = "Line steps")
  par(old.par)
}

This shows a problem with 'type = "s"' combined with "lty = "; the lines 
look solid no matter what lty is set to, if the steps are small enough. 
Is this intentional, and if so, why? This bit me when I tried to plot 
empirical cdfs with the 'type = "s"' method; some curves were impossible 
to distinguish.

Btw, I checked 'plot.survfit', and it uses the second method, probably of 
this reason.

G?ran
---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


From mschwartz at medanalytics.com  Tue Mar 11 21:58:21 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 11 Mar 2003 14:58:21 -0600
Subject: [R] changing pen mode [or adjusting for overlapping points?]
In-Reply-To: <20030311200809.GI3755@epsilon.donarmstrong.com>
Message-ID: <006e01c2e810$f3ef4420$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Don Armstrong
>Sent: Tuesday, March 11, 2003 2:08 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] changing pen mode [or adjusting for overlapping points?]
>
>
>I'm ploting a rather large number of points [~24,000] in two 
>series with slightly different distributions.
>
>I would like to be able to effectively see where the two 
>distributions overlap by setting the pen mode (or it's 
>equivalent) to allow the overlapping portion to show up as a 
>different color (or different shade).
>
>Unfortunatly, I couldn't find an option in par or postscript 
>that looks like it would be of use.
>
>Ideas or suggestions?
>
>
>Don Armstrong

I may be mis-understanding what you are trying to do, but if you are
using plot() to generate a scatter plot (as opposed to a density plot)
and there are actual overlapping points between the two sets, you
could use jitter() to introduce some random noise into the plotted
points.

Something like this might work, presuming that (x1, y1) and (x2, y2)
are your two sets of points:

> plot(x1, y1, pch = 16, col = "red")
> points(jitter(x2), jitter(y2), pch = 16, col = "blue")

The first plot() draws the initial set of data and points() adds the
second set of data to the same plot, but in a different color with
some random noise added to the points.

If that is not what you need, let us know.

Marc Schwartz


From spencer.graves at pdf.com  Tue Mar 11 22:02:56 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 11 Mar 2003 13:02:56 -0800
Subject: [R] different file types
References: <200303112039.h2BKda9e017881@hcs.harvard.edu>
Message-ID: <3E6E4F00.9000109@pdf.com>

The command "'source' causes R to accept its input from the named file".

I don't know what you mean by "associative arrays", but "`switch' 
evaluates `EXPR' and accordingly chooses one of the further arguments".

Hope this helps.
Spencer Graves

janet rosenbaum wrote:
> Hi.  I am writing a program to read in different types of files from a
> GUI.  While it's easy to read different types of text files, I am
> stymied how to make R execute the input.  
> 
> Ideally I could get the command from input and dereference it like
> 	`command`(filename)
> where command would be read.dta or read.table or read.xport or any of 
> the similar commands.
> 
> Also, is there a way to make associative arrays?  
> It would be nice to be able to get the format from input and then have
> 	command<-array[format]
> 
> Otherwise, I guess I'll just do cascading if's.
> 
> Thanks,
> 
> Janet Rosenbaum					  jerosenb at fas.harvard.edu
> Center for Basic Research in the Social Sciences, Harvard University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From don at donarmstrong.com  Tue Mar 11 22:11:40 2003
From: don at donarmstrong.com (Don Armstrong)
Date: Tue, 11 Mar 2003 16:11:40 -0500
Subject: [R] changing pen mode [or adjusting for overlapping points?]
In-Reply-To: <006e01c2e810$f3ef4420$0201a8c0@MARC>
References: <20030311200809.GI3755@epsilon.donarmstrong.com>
	<006e01c2e810$f3ef4420$0201a8c0@MARC>
Message-ID: <20030311211140.GK3755@epsilon.donarmstrong.com>

On Tue, 11 Mar 2003, Marc Schwartz wrote:
> I may be mis-understanding what you are trying to do, but if you are
> using plot() to generate a scatter plot (as opposed to a density
> plot) and there are actual overlapping points between the two sets,
> you could use jitter() to introduce some random noise into the
> plotted points.

jitter is a good idea, but in this case, the problem is the density of
the ploted points themselves. Just adding noise do much in this case.

[So that it's more clear what the problem is, I've stuck a graph up at
http://rzlab.ucr.edu/images/test.png. Ideally you should be able to
decern where the red region stops underneath the green [while at the
same time seeing that the green has outliers below it.]

There is a mode in photoshop called multiply that does something
similar, but I'm not sure if there is a postscript mode that does the
same thing. [Editing the postscript file itself is not a problem if
that's the only solution...]


Don Armstrong

-- 
My spelling ability, or rather the lack thereof, is one of the wonders
of the modern world.


http://www.donarmstrong.com
http://www.anylevel.com
http://rzlab.ucr.edu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030311/d76e3538/attachment.bin

From mschwartz at medanalytics.com  Tue Mar 11 22:18:39 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 11 Mar 2003 15:18:39 -0600
Subject: [R] changing pen mode [or adjusting for overlapping points?]
In-Reply-To: <20030311204229.GJ3755@epsilon.donarmstrong.com>
Message-ID: <007b01c2e813$ca058fe0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Don Armstrong
>Sent: Tuesday, March 11, 2003 2:43 PM
>To: r-help at stat.math.ethz.ch
>Subject: Re: [R] changing pen mode [or adjusting for 
>overlapping points?]
>
>
>On Tue, 11 Mar 2003, Spencer Graves wrote:
>>  plot(1:2, col=1:2)
>> 
>> Is this what you want?
>
>Unless I'm mistaken, that just alternates which color is set 
>for each point.
>
>What I'm looking for is a way to plot two (very large) 
>separate datasets on the same plot so that you can distinguish 
>between the two.
>
>EG: In this plot, http://rzlab.ucr.edu/images/test.png, the 
>upper left region should be some unique color, so you can see 
>where the red (currently hidden under the green) stops.
>
>
>Don Armstrong


Don,

Based upon that example, the code that I sent in my prior e-mail
should work and you may not even need to use jitter() in the points()
function call given the density of the scatterplot. You might try it
with and without using jitter() to see what makes sense for you.

You might also need to decide which set of points to draw first versus
second depending upon how they overlap.

Finally, you might also consider using the 'cex' argument in both
plot() and points(), which can reduce the size of the plotting
symbols. The default for par(cex) is 1.0, so you might try smaller
values.

Hope that helps.

Marc Schwartz


From don at donarmstrong.com  Tue Mar 11 22:28:43 2003
From: don at donarmstrong.com (Don Armstrong)
Date: Tue, 11 Mar 2003 16:28:43 -0500
Subject: [R] changing pen mode [or adjusting for overlapping points?]
In-Reply-To: <007b01c2e813$ca058fe0$0201a8c0@MARC>
References: <20030311204229.GJ3755@epsilon.donarmstrong.com>
	<007b01c2e813$ca058fe0$0201a8c0@MARC>
Message-ID: <20030311212843.GM3755@epsilon.donarmstrong.com>

On Tue, 11 Mar 2003, Marc Schwartz wrote:
> Finally, you might also consider using the 'cex' argument in both
> plot() and points(), which can reduce the size of the plotting
> symbols. The default for par(cex) is 1.0, so you might try smaller
> values.

Changing the pointsize helps a bit, however, it makes the points that
aren't overlapped almost impossible to see. [Single pixels in a
1900x1600 plot are quite hard for my eyes to dicern, and it basically
gets back to a mere density plot.]

What I'm really looking for is a method to adjust the mode in which
the points are drawn, so that those that overlap a point of a
different color produce yet a third color in the region of overlap.


Don Armstrong

-- 
"I was thinking seven figures," he said, "but I would have taken a
hundred grand. I'm not a greedy person." [All for a moldy bottle of
tropicana.]
 -- Sammi Hadzovic [in Andy Newman's 2003/02/14 NYT article.]
 http://www.nytimes.com/2003/02/14/nyregion/14EYEB.html

http://www.donarmstrong.com
http://www.anylevel.com
http://rzlab.ucr.edu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030311/13f2f1c4/attachment.bin

From spencer.graves at pdf.com  Tue Mar 11 22:37:48 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 11 Mar 2003 13:37:48 -0800
Subject: [R] changing pen mode [or adjusting for overlapping points?]
References: <006e01c2e810$f3ef4420$0201a8c0@MARC>
Message-ID: <3E6E572C.7030703@pdf.com>

Have you considered plotting the points in a random order?  With 
superimposed points, the color of the last point plotted is what appears.

Spencer Graves

Marc Schwartz wrote:
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Don Armstrong
>>Sent: Tuesday, March 11, 2003 2:08 PM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] changing pen mode [or adjusting for overlapping points?]
>>
>>
>>I'm ploting a rather large number of points [~24,000] in two 
>>series with slightly different distributions.
>>
>>I would like to be able to effectively see where the two 
>>distributions overlap by setting the pen mode (or it's 
>>equivalent) to allow the overlapping portion to show up as a 
>>different color (or different shade).
>>
>>Unfortunatly, I couldn't find an option in par or postscript 
>>that looks like it would be of use.
>>
>>Ideas or suggestions?
>>
>>
>>Don Armstrong
> 
> 
> I may be mis-understanding what you are trying to do, but if you are
> using plot() to generate a scatter plot (as opposed to a density plot)
> and there are actual overlapping points between the two sets, you
> could use jitter() to introduce some random noise into the plotted
> points.
> 
> Something like this might work, presuming that (x1, y1) and (x2, y2)
> are your two sets of points:
> 
> 
>>plot(x1, y1, pch = 16, col = "red")
>>points(jitter(x2), jitter(y2), pch = 16, col = "blue")
> 
> 
> The first plot() draws the initial set of data and points() adds the
> second set of data to the same plot, but in a different color with
> some random noise added to the points.
> 
> If that is not what you need, let us know.
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From sfalcon at fhcrc.org  Tue Mar 11 22:55:14 2003
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 11 Mar 2003 13:55:14 -0800
Subject: [R] different file types
In-Reply-To: <200303112039.h2BKda9e017881@hcs.harvard.edu>
References: <Pine.SOL.4.30.0303100553390.7474-100000@ysidro.econ.uiuc.edu>
	<200303112039.h2BKda9e017881@hcs.harvard.edu>
Message-ID: <20030311215513.GL1528@queenbee.fhcrc.org>

> Also, is there a way to make associative arrays?  
> It would be nice to be able to get the format from input and then have
> 	command<-array[format]

Named lists might do what you want.  For example,

fruitcolor <- list(apple="red", grape="green", orange="orange")

Then you could say,

fruitcolor$apple

or

fruitcolor[["apple"]]

to get "red".



+ seth


From reid_huntsinger at merck.com  Tue Mar 11 23:04:44 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Tue, 11 Mar 2003 17:04:44 -0500
Subject: [R] different file types
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC38D@uswpmx11.merck.com>

You might look at "eval" and "parse".

Reid Huntsinger

-----Original Message-----
From: Spencer Graves [mailto:spencer.graves at pdf.com] 
Sent: Tuesday, March 11, 2003 4:03 PM
To: janet rosenbaum
Cc: r-help
Subject: Re: [R] different file types


The command "'source' causes R to accept its input from the named file".

I don't know what you mean by "associative arrays", but "`switch' 
evaluates `EXPR' and accordingly chooses one of the further arguments".

Hope this helps.
Spencer Graves

janet rosenbaum wrote:
> Hi.  I am writing a program to read in different types of files from a
> GUI.  While it's easy to read different types of text files, I am
> stymied how to make R execute the input.  
> 
> Ideally I could get the command from input and dereference it like
> 	`command`(filename)
> where command would be read.dta or read.table or read.xport or any of 
> the similar commands.
> 
> Also, is there a way to make associative arrays?  
> It would be nice to be able to get the format from input and then have
> 	command<-array[format]
> 
> Otherwise, I guess I'll just do cascading if's.
> 
> Thanks,
> 
> Janet Rosenbaum
jerosenb at fas.harvard.edu
> Center for Basic Research in the Social Sciences, Harvard University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------


From jasont at indigoindustrial.co.nz  Tue Mar 11 23:07:28 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 12 Mar 2003 11:07:28 +1300
Subject: [R] different file types
In-Reply-To: <200303112039.h2BKda9e017881@hcs.harvard.edu>;
	from jerosenb@hcs.harvard.edu on Tue, Mar 11, 2003 at 03:39:36PM -0500
References: <Pine.SOL.4.30.0303100553390.7474-100000@ysidro.econ.uiuc.edu>
	<200303112039.h2BKda9e017881@hcs.harvard.edu>
Message-ID: <20030312110728.B8853@camille.indigoindustrial.co.nz>

On Tue, Mar 11, 2003 at 03:39:36PM -0500, janet rosenbaum wrote:
> 
> Hi.  I am writing a program to read in different types of files from a
> GUI.  While it's easy to read different types of text files, I am
> stymied how to make R execute the input.  
> 
> Ideally I could get the command from input and dereference it like
> 	`command`(filename)
> where command would be read.dta or read.table or read.xport or any of 
> the similar commands.

> Also, is there a way to make associative arrays?  
> It would be nice to be able to get the format from input and then have
> 	command<-array[format]

Not that I'm aware of.  Since R is a rather nice functional
programming language,  there are often other ways to do the same
thing.  I'd have the front end supply a format (table, csv, xport,
etc), then use paste() and match.fun(), e.g. 

file.format <- "csv" #this would be supplied by the gui

readCmd <- paste(sep=".","read",file.format)
readFunc <- match.fun(readCmd)
readFunc(file)

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz


From till.baumgaertel at epost.de  Wed Mar 12 00:00:57 2003
From: till.baumgaertel at epost.de (Till Baumgaertel)
Date: Wed, 12 Mar 2003 00:00:57 +0100
Subject: [R] R-Graphics: Scaling axis
Message-ID: <3E6E629C00000052@PPD27104.x.de>

Hi,

how can I scale the x- and y-axis of a "plot" to the same scale?

My problem: The following command sequence produces the plot in a square.
What I want is the x-axis to be 5 times as wide (measured e.g. in pixels)
as the y-axis is long (because y ranges from -1 to 1 and x ranges from 0
to 10).

x <- seq( from=0, to=10, by=.1)
sinx <- sin(x)
plot( x, sinx, type="l")

In noth help(plot) and help( par) I couldn't find a solution. What am I
missing?

Thanks for any hint,
till




________________________________________
Mehr Power f?r Ihre eMail - mit den neuen Leistungspaketen bei http://www.epost.de


From r.hankin at auckland.ac.nz  Wed Mar 12 01:24:39 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Wed, 12 Mar 2003 13:24:39 +1300
Subject: [R] multiple plots and postscript()
Message-ID: <200303120024.h2C0Odav010361@r.hankin.sges.auckland.ac.nz>

Many thanks to everyone who helped me with resizing my subplots.

The problem was that setting par(mfrow=c(2,2)) does not rescale the
fonts, which are set to be the right size for A4 paper.  What I didn't
realize was that resizing the fonts also resizes the positions of axis
labels and titles, making the plots look much better.  par(mar) can
also be changed from its default (A4) values.


To my eye, the optimum plots resulted from:

postscript(file="fig.ps",height=4,width=4)
layout(matrix(c(0,1,2,0,3,4),2,3,byrow=TRUE),c(0,1,1),c(1,1))
par(mar=c(5,5,2,2)+.1,mex=0.5)
plot(1:10);plot(1:10);plot(1:10);plot(1:10)
dev.off()

Could this example (or one like it) be added to the docs for par() ?
[there is something similar---but more complicated---in ?layout].


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042


From umalvarez at fata.unam.mx  Wed Mar 12 01:34:58 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Tue, 11 Mar 2003 18:34:58 -0600 (CST)
Subject: [R] manuals source (i.e. *.tex) files
Message-ID: <Pine.LNX.4.44.0303111829410.4598-100000@fata.unam.mx>

Hi:

I've installed R 1.6.1 using fink to compile it. I like to have a look at 
the manuals source files for latex (i.e. the *.tex files for r-intro, 
etc.). I have made a  search in my computer, I find the *.tex file for the 
help files but not for the manuals. Where can I find them?

Regards.

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx


From meles at free.fr  Wed Mar 12 03:37:05 2003
From: meles at free.fr (Blaise TRAMIER)
Date: Wed, 12 Mar 2003 02:37:05 +0000
Subject: [R] [OT] Appropriate test?
Message-ID: <200303120237.05306.meles@free.fr>

Hi,
	I'm having some problem with a dataset and I don't really know how to 
analyse it.

I have 20 subjects in two groups of treatment (8 an 12 subjects).
Biological measure have been recorded at different time, from t0 (before 
the treatment) to t7 (3 days after). The time elapsed between each 
measure is not constant.

What is the most appropriate test to show a difference between the 2 
treatements?

I thought that an anova for repeated measure could do the trick, but I 
didn't really find how to do it with R.

I sorry for being OT but I didn't really know where to ask this 
question. If you could redirect me on a appropriate forum or mailing 
list to have that sort of help, I would appreciate a lot.

Thanks in advance.

-- 
Blaise TRAMIER


From tlumley at u.washington.edu  Wed Mar 12 02:54:36 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 11 Mar 2003 17:54:36 -0800 (PST)
Subject: [R] manuals source (i.e. *.tex) files
In-Reply-To: <Pine.LNX.4.44.0303111829410.4598-100000@fata.unam.mx>
Message-ID: <Pine.A41.4.44.0303111754120.18874-100000@homer18.u.washington.edu>

On Tue, 11 Mar 2003, Ulises Mora Alvarez wrote:

> Hi:
>
> I've installed R 1.6.1 using fink to compile it. I like to have a look at
> the manuals source files for latex (i.e. the *.tex files for r-intro,
> etc.). I have made a  search in my computer, I find the *.tex file for the
> help files but not for the manuals. Where can I find them?
>

They are TexInfo files:  doc/manual/*.texi

	-thomas


From tblackw at umich.edu  Wed Mar 12 04:39:53 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 11 Mar 2003 22:39:53 -0500 (EST)
Subject: [R] R-Graphics: Scaling axis
In-Reply-To: <3E6E629C00000052@PPD27104.x.de>
Message-ID: <Pine.SOL.4.44.0303112229080.12628-100000@timepilot.gpcc.itd.umich.edu>

On Wed, 12 Mar 2003, Till Baumgaertel wrote:

> how can I scale the x- and y-axis of a "plot" to the same scale?
>
> My problem: The following command sequence produces the plot in a square.
> What I want is the x-axis to be 5 times as wide (measured e.g. in pixels)
> as the y-axis is long (because y ranges from -1 to 1 and x ranges from 0
> to 10).

It depends what graphics device you are using.  If the plot is in
a window on the computer screen, then resizing the window reshapes
the plot to whatever aspect ratio you want, interactively, so the
aspect ratio is not an issue.  For a hardcopy device, such as
postscript(), the traditional way to control the aspect ratio is
to fill up the rest of the page with margins.  For a nice, long
narrow plot ...

postscript("some.file.name", pointsize=11, horizontal=T)
par(mar=c(9.5,3.5,3,2), las=1)
plot(x, y, type="p")

	... but after printing one test page, I always take a ruler
and measure the spacing of the tick marks and calculate how to
adjust the margin widths better.  Seriously.  I use a ruler.
It's clunky, but if you care about the graphical scales, that's
how you do it, and no complaints.  Even the difference between "A4"
and "letter" paper sizes would throw off any automated calculation.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -


From ihaka at stat.auckland.ac.nz  Wed Mar 12 04:53:56 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Wed, 12 Mar 2003 16:53:56 +1300
Subject: [R] changing pen mode [or adjusting for overlapping points?]
References: <20030311200809.GI3755@epsilon.donarmstrong.com>
	<3E6E45FA.4020403@pdf.com> <20030311204229.GJ3755@epsilon.donarmstrong.com>
Message-ID: <3E6EAF54.7080205@stat.auckland.ac.nz>

Don Armstrong wrote:

> What I'm looking for is a way to plot two (very large) separate
> datasets on the same plot so that you can distinguish between the two.
> 
> EG: In this plot, http://rzlab.ucr.edu/images/test.png, the upper left
> region should be some unique color, so you can see where the red
> (currently hidden under the green) stops.

Interesting.  Some suggestions:

1) Change the plotting scales because all your points are clustering 
close to the top or left margins.  At a guess, try log(x) and log(1-y). 
  This should spread things out a bit.

2) You might get a better picture if you cut down the number of points 
you are plotting.

3) If you really want to use colour you will need to do some binning 
(which is implicit in your painting program analogy).  You could use a 
rectangular layout, or do hexagonal binning. Once you've binned you 
could colour a particular location according to the absolute and 
relative numbers of red and green points at that location.  For example, 
you could encode the total number of points at a location using HSV 
"value" and encode the proportion of reds as a location along a line 
joining maximal saturated red and green with the given "value". (i.e. 
values are encoded as a position in vertical slice through the HSV hexcone.)

Would it be possible to get the data to try some experiments?


-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand


From jerrytheshrub at hotmail.com  Wed Mar 12 05:14:03 2003
From: jerrytheshrub at hotmail.com (Jeremy Z Butler)
Date: Wed, 12 Mar 2003 17:14:03 +1300
Subject: [R] point characters in text
Message-ID: <F1044wkZkUv5PEt72F4000408cc@hotmail.com>

Does anyone know how to include point characters in plotted text strings 
i.e. text() or mtext()?
Jeremy


From john.maindonald at anu.edu.au  Wed Mar 12 06:04:45 2003
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 12 Mar 2003 16:04:45 +1100
Subject: [R] help-- Cox ph models
Message-ID: <244D1B86-5448-11D7-BF21-000393073F7A@anu.edu.au>

The following code should do the job.  You can if you want rename 
sum.coxph to
summary.coxph.  print.summary.coxph is needed so that printing of the 
objects
that are thus created has the same effect as calling the existing 
summary.coxph
It needs a modified help file to go with it.  I have been meaning to 
try to get this,
or something like it, incorporated into the survival package.

"sum.coxph" <-
function (object, table = TRUE, coef = TRUE, conf.int = 0.95,
     scale = 1,  ...)
{
     cox <- object
coxsum <- list(call=cox$call, fail=cox$fail, na.action=cox$na.action,
   n=cox$n, icc=cox$icc, naive.var=cox$naive.var)
     if (!is.null(cox$fail)) {
         return()
     }
     omit <- cox$na.action
     if (is.null(cox$coef)) {
         return()
     }
     beta <- cox$coef
     nabeta <- !(is.na(beta))
     beta2 <- beta[nabeta]
     if (is.null(beta) | is.null(cox$var)){
         coxsum$invalid <- TRUE
         return()
         }
         else coxsum$invalid<-FALSE
     se <- sqrt(diag(cox$var))
     if (!is.null(cox$naive.var))
         nse <- sqrt(diag(cox$naive.var))
     if (coef) {
         if (is.null(cox$naive.var)) {
             tmp <- cbind(beta, exp(beta), se, beta/se, 1 -
                 pchisq((beta/se)^2, 1))
             dimnames(tmp) <- list(names(beta), c("coef", "exp(coef)",
                 "se(coef)", "z", "p"))
         }
         else {
             tmp <- cbind(beta, exp(beta), nse, se, beta/se, 1 -
                 pchisq((beta/se)^2, 1))
             dimnames(tmp) <- list(names(beta), c("coef", "exp(coef)",
                 "se(coef)", "robust se", "z", "p"))
         }
     } else tmp <- NULL
     if (conf.int) {
         z <- qnorm((1 + conf.int)/2, 0, 1)
         beta <- beta * scale
         se <- se * scale
         tmpc <- cbind(exp(beta), exp(-beta), exp(beta - z * se),
             exp(beta + z * se))
         dimnames(tmpc) <- list(names(beta), c("exp(coef)", "exp(-coef)",
             paste("lower .", round(100 * conf.int, 2), sep = ""),
             paste("upper .", round(100 * conf.int, 2), sep = "")))
     } else tmpc <- NULL
     logtest <- -2 * (cox$loglik[1] - cox$loglik[2])
     sctest <- cox$score
     df <- length(beta2)
     Rsquare <- 1 - exp(-logtest/cox$n)
     maxRsquare <- 1 - exp(2 * cox$loglik[1]/cox$n)
     plogtest <- 1 - pchisq(logtest, df)
     pwald.test <- 1 - pchisq(cox$wald.test, df)
     pscore <- 1 - pchisq(sctest, df)
     if(!is.null(cox$rscore)){
       rscore <- cox$rscore
       prscore <- 1 - pchisq(cox$rscore, df)
       robust <- list(val=rscore, pval=prscore)
       }
     else robust <- NULL
     wald.test <- cox$wald.test
     coxsum <- c(list(call=cox$call, coefficients=tmp, intervals=tmpc, 
df=df,
       rsquare=c(Rsquare, maxRsquare),
       tests=c(logtest=logtest, wald.test=wald.test, score=sctest),
       p.tests = c(logtest=plogtest, wald.test=pwald.test,
         score=pscore), robust=robust), coxsum)
     class(coxsum) <- "summary.coxph"
     coxsum
}
"print.summary.coxph" <-
function (object, table = TRUE, coef = TRUE, conf.int = 0.95,
     scale = 1, digits = max(options()$digits - 4, 3), ...)
{
     coxsum <- object
     if (!is.null(cl <- coxsum$call)) {
         cat("Call:\n")
         dput(cl)
         cat("\n")
     }
     if (!is.null(coxsum$fail)) {
         cat(" Coxreg failed.", coxsum$fail, "\n")
         return()
     }
     savedig <- options(digits = digits)
     on.exit(options(savedig))
     omit <- coxsum$na.action
     if (length(omit))
         cat("  n=", coxsum$n, " (", naprint(omit), ")\n", sep = "")
     else cat("  n=", coxsum$n, "\n")
     if (length(coxsum$icc))
         cat("  robust variance based on", coxsum$icc[1], "groups, 
intra-class correlation =",
             format(coxsum$icc[2:3]), "\n")
     if (is.null(coxsum$coef)) {
         cat("   Null model\n")
         return()
     }
     if (coxsum$invalid)stop("input is invalid")
       if (!is.null(coxsum$coef)) {
         cat("\n")
         coxsum$coef[,"p"] <- signif(coxsum$coef[,"p"],digits-1)
         prmatrix(coxsum$coef)
     }
     if (!is.null(coxsum$intervals)) {
         cat("\n")
         prmatrix(coxsum$intervals)
     }
     logtest <- coxsum$tests["logtest"]
     sctest <- coxsum$tests["score"]
     df <- coxsum$df
     cat("\n")
     cat("Rsquare=", format(round(coxsum$rsquare[1], 3)),
         "  (max possible=", format(round(coxsum$rsquare[2],3)), ")\n")
     cat("Likelihood ratio test= ", 
format(round(coxsum$tests["logtest"], 2)),
         "  on ", df, " df,", "   p=", format(coxsum$p.tests["logtest"]),
         "\n", sep = "")
     cat("Wald test            = ", format(coxsum$tests["wald.test.x"]),
         "  on ", df, " df,", "   p=", format(
         coxsum$p.tests["wald.test.x"]), "\n", sep = "")
     cat("Score (logrank) test = ", format(round(coxsum$tests["score"], 
2)),
         "  on ", df, " df,", "   p=", format(coxsum$p.tests["score"]),
         sep = "")
     if (is.null(coxsum$robust))
         cat("\n\n")
     else cat(",   Robust = ", format(round(coxsum$robust$val, 2)), "  
p=",
         format(coxsum$robust$pval), "\n\n", sep = "")
     if (!is.null(coxsum$tests))
         cat("  (Note: the likelihood ratio and score tests",
             "assume independence of\n     observations within a 
cluster,",
             "the Wald and robust score tests do not).\n")
    invisible()
}

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From ripley at stats.ox.ac.uk  Wed Mar 12 08:15:30 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 12 Mar 2003 07:15:30 +0000 (GMT)
Subject: [R] R-Graphics: Scaling axis
In-Reply-To: <Pine.SOL.4.44.0303112229080.12628-100000@timepilot.gpcc.itd.umich.edu>
Message-ID: <Pine.LNX.4.44.0303120659300.4022-100000@gannet.stats>

Excuse me, but that is not `how you do it'. R has two automated ways. One
is the parameter `asp': see ?plot.window, and the other is the function 
eqscplot() in package MASS.  Neither need manual intervention (unless your 
output device cannot plot square pixels as square).

We need to be a bit careful about the length of axes: if x ranges from 1
to 10, the x axis does not (unless you set xaxs="i").  That's why setting
the plot region (e.g. using par(pty="s") or via the margins) often does
not do what one wants: the plot region may be square but the scales 
unequal.

On Tue, 11 Mar 2003, Thomas W Blackwell wrote:

> On Wed, 12 Mar 2003, Till Baumgaertel wrote:
> 
> > how can I scale the x- and y-axis of a "plot" to the same scale?
> >
> > My problem: The following command sequence produces the plot in a square.
> > What I want is the x-axis to be 5 times as wide (measured e.g. in pixels)
> > as the y-axis is long (because y ranges from -1 to 1 and x ranges from 0
> > to 10).
> 
> It depends what graphics device you are using.  If the plot is in
> a window on the computer screen, then resizing the window reshapes
> the plot to whatever aspect ratio you want, interactively, so the
> aspect ratio is not an issue.  

It *is* an issue for many statistical plots which rely on interpretation
via Euclidean distance, e.g. MDS plots.  One wants to resize and keep the 
aspect ratio: hence the parameter `asp', and the different resizing 
options on the Windows graphics device.

> For a hardcopy device, such as
> postscript(), the traditional way to control the aspect ratio is
> to fill up the rest of the page with margins.  For a nice, long
> narrow plot ...
> 
> postscript("some.file.name", pointsize=11, horizontal=T)
> par(mar=c(9.5,3.5,3,2), las=1)
> plot(x, y, type="p")
> 
> 	... but after printing one test page, I always take a ruler
> and measure the spacing of the tick marks and calculate how to
> adjust the margin widths better.  Seriously.  I use a ruler.
> It's clunky, but if you care about the graphical scales, that's
> how you do it, and no complaints.  Even the difference between "A4"
> and "letter" paper sizes would throw off any automated calculation.

Not so.  The size of the plot region in inches is available from the 
graphics parameters, specifically par("pin").

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Roger.Bivand at nhh.no  Wed Mar 12 08:17:16 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 12 Mar 2003 08:17:16 +0100 (CET)
Subject: [R] R-Graphics: Scaling axis
In-Reply-To: <3E6E629C00000052@PPD27104.x.de>
Message-ID: <Pine.LNX.4.44.0303120812470.1813-100000@reclus.nhh.no>

On Wed, 12 Mar 2003, Till Baumgaertel wrote:

> Hi,
> 
> how can I scale the x- and y-axis of a "plot" to the same scale?
> 
> My problem: The following command sequence produces the plot in a square.
> What I want is the x-axis to be 5 times as wide (measured e.g. in pixels)
> as the y-axis is long (because y ranges from -1 to 1 and x ranges from 0
> to 10).
> 
> x <- seq( from=0, to=10, by=.1)
> sinx <- sin(x)
> plot( x, sinx, type="l")
> 
> In noth help(plot) and help( par) I couldn't find a solution. What am I
> missing?

That's right - but the "see also" in ?plot gets you to ?plot.default,
which in turn gets you to ?plot.window:

     asp: numeric, giving the aspect ratio y/x.

where asp=1 will force plot to impose equal scales on the axes, and is 
passed through by plot().

Roger Bivand

> 
> Thanks for any hint,
> till
> 
> 
> 
> 
> ________________________________________
> Mehr Power f?r Ihre eMail - mit den neuen Leistungspaketen bei http://www.epost.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no


From deepayan at stat.wisc.edu  Wed Mar 12 08:45:50 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 12 Mar 2003 01:45:50 -0600
Subject: [R] R-Graphics: Scaling axis
In-Reply-To: <3E6E629C00000052@PPD27104.x.de>
References: <3E6E629C00000052@PPD27104.x.de>
Message-ID: <200303120145.50736.deepayan@stat.wisc.edu>

On Tuesday 11 March 2003 05:00 pm, Till Baumgaertel wrote:
> Hi,
>
> how can I scale the x- and y-axis of a "plot" to the same scale?
>
> My problem: The following command sequence produces the plot in a square.
> What I want is the x-axis to be 5 times as wide (measured e.g. in pixels)
> as the y-axis is long (because y ranges from -1 to 1 and x ranges from 0
> to 10).
>
> x <- seq( from=0, to=10, by=.1)
> sinx <- sin(x)
> plot( x, sinx, type="l")
>
> In noth help(plot) and help( par) I couldn't find a solution. What am I
> missing?

See asp in help(plot.default), though this doesn't seem to change the aspect 
ratio of the box (which you can probably do with par).

An alternative is to use xyplot in the lattice library:

xyplot(y ~ x, type = "l", aspect = 1/5)

(This will make the aspect ratio of the bounding box 1/5 and not the actual 
scales, but you can control that by further specifying xlim and ylim.)

Hope that helps,

Deepayan


From eric.esposito at gazdefrance.com  Wed Mar 12 08:46:03 2003
From: eric.esposito at gazdefrance.com (Eric ESPOSITO)
Date: Wed, 12 Mar 2003 08:46:03 +0100
Subject: [R] How to collect the Rtools to build packages
Message-ID: <OF10B98923.F506BE2D-ON41256CE7.002A0435@notes.edfgdf.fr>

After reading the readme.packages file, I would like to install the R tools
in order to build my own packages, but the internet portal
http://www.stats.ox.ac.uk/pub/Rtools/ hasn't been working since a few days.
Where can I get the file tools.zip?
Thank you!
Eric Esposito


From ripley at stats.ox.ac.uk  Wed Mar 12 09:37:53 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 12 Mar 2003 08:37:53 +0000 (GMT)
Subject: [R] How to collect the Rtools to build packages
In-Reply-To: <OF10B98923.F506BE2D-ON41256CE7.002A0435@notes.edfgdf.fr>
Message-ID: <Pine.LNX.4.44.0303120825340.8057-100000@gannet.stats>

It _is_ working: I have just checked from outside Oxford.  It was
unavailable for a few hours on Saturday (the server was being upgraded)  
but has otherwise been up (and that file downloaded successfully several
times a day) for all of the last ten days.

ftp://ftp.stats.ox.ac.uk/pub/Rtools/tools.zip will also work, in case your
problem is with your http client.

On Wed, 12 Mar 2003, Eric ESPOSITO wrote:

> After reading the readme.packages file, I would like to install the R tools
> in order to build my own packages, but the internet portal
> http://www.stats.ox.ac.uk/pub/Rtools/ hasn't been working since a few days.
> Where can I get the file tools.zip?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From otoomet at econ.dk  Wed Mar 12 09:43:37 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Wed, 12 Mar 2003 09:43:37 +0100
Subject: [R] problems with numerical optimisation
Message-ID: <200303120843.h2C8hbN09838@punik.econ.au.dk>

Dear list,

this is not a particular R question but perhaps someone can help.

I am running a maximum likelihood estimation (competing risk duration
model with unobserved heterogeneity) on 30 different datasets.  The
problem is that on 2 datasets the model does not converge.  I am
interested if there are any methods, based on the gradients or (an
approximation of) the hessian which helps to determine what is the
problem.  Can anybody recommend a good textbook about numerical
optimisation?

Currently I am using 100 BFGS iterations + 100 BHHH iterations and I
have programmed analytic gradients.  The fool-proof method of
excluding the variables one-by-one and simplifying the structure is
quite a slow and not particularily insightsful.

Thanks in advance

Ott


From Ko-Kang at xtra.co.nz  Wed Mar 12 09:40:32 2003
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Wed, 12 Mar 2003 21:40:32 +1300
Subject: [R] How to collect the Rtools to build packages
References: <OF10B98923.F506BE2D-ON41256CE7.002A0435@notes.edfgdf.fr>
Message-ID: <006301c2e873$0c22b740$8f2658db@kwan022>

----- Original Message -----
From: "Eric ESPOSITO" <eric.esposito at gazdefrance.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, March 12, 2003 8:46 PM
Subject: [R] How to collect the Rtools to build packages


> After reading the readme.packages file, I would like to install the R
tools
> in order to build my own packages, but the internet portal
> http://www.stats.ox.ac.uk/pub/Rtools/ hasn't been working since a few
days.
> Where can I get the file tools.zip?


It has been working for me!  I went there two days ago, and a few hours ago,
and just went again.  All the time I can view the page fine.

Cheers,

Kevin

------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022


From till.baumgaertel at epost.de  Wed Mar 12 10:38:45 2003
From: till.baumgaertel at epost.de (Till Baumgaertel)
Date: Wed, 12 Mar 2003 10:38:45 +0100
Subject: AW: Re: [R] R-Graphics: Scaling axis
In-Reply-To: <Pine.LNX.4.44.0303120659300.4022-100000@gannet.stats>
Message-ID: <3E66A61C00009A29@ppd27106.x.de>

Thank you!
Adding asp=1 to the plot-command does exactly what I want!

bye,
till

>-- Original Nachricht --
>From: ripley at stats.ox.ac.uk
>Date: Wed, 12 Mar 2003 07:15:30 +0000 (GMT)
>To: Thomas W Blackwell <tblackw at umich.edu>
>cc: Till Baumgaertel <till.baumgaertel at epost.de>,
>        r-help <r-help at stat.math.ethz.ch>
>Subject: Re: [R] R-Graphics: Scaling axis
>
>
>Excuse me, but that is not `how you do it'. R has two automated ways. One
>is the parameter `asp': see ?plot.window, and the other is the function

>eqscplot() in package MASS.  Neither need manual intervention (unless your
>
>output device cannot plot square pixels as square).
>
>We need to be a bit careful about the length of axes: if x ranges from
1
>to 10, the x axis does not (unless you set xaxs="i").  That's why setting
>the plot region (e.g. using par(pty="s") or via the margins) often does
>not do what one wants: the plot region may be square but the scales 
>unequal.
>
>On Tue, 11 Mar 2003, Thomas W Blackwell wrote:
>
>> On Wed, 12 Mar 2003, Till Baumgaertel wrote:
>> 
>> > how can I scale the x- and y-axis of a "plot" to the same scale?
>> >
>> > My problem: The following command sequence produces the plot in a square.
>> > What I want is the x-axis to be 5 times as wide (measured e.g. in pixels)
>> > as the y-axis is long (because y ranges from -1 to 1 and x ranges from
>0
>> > to 10).
>> 
>> It depends what graphics device you are using.  If the plot is in
>> a window on the computer screen, then resizing the window reshapes
>> the plot to whatever aspect ratio you want, interactively, so the
>> aspect ratio is not an issue.  
>
>It *is* an issue for many statistical plots which rely on interpretation
>via Euclidean distance, e.g. MDS plots.  One wants to resize and keep the
>
>aspect ratio: hence the parameter `asp', and the different resizing 
>options on the Windows graphics device.
>
>> For a hardcopy device, such as
>> postscript(), the traditional way to control the aspect ratio is
>> to fill up the rest of the page with margins.  For a nice, long
>> narrow plot ...
>> 
>> postscript("some.file.name", pointsize=11, horizontal=T)
>> par(mar=c(9.5,3.5,3,2), las=1)
>> plot(x, y, type="p")
>> 
>> 	... but after printing one test page, I always take a ruler
>> and measure the spacing of the tick marks and calculate how to
>> adjust the margin widths better.  Seriously.  I use a ruler.
>> It's clunky, but if you care about the graphical scales, that's
>> how you do it, and no complaints.  Even the difference between "A4"
>> and "letter" paper sizes would throw off any automated calculation.
>
>Not so.  The size of the plot region in inches is available from the 
>graphics parameters, specifically par("pin").
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>






________________________________________
Mehr Power f?r Ihre eMail - mit den neuen Leistungspaketen bei http://www.epost.de


From lm.silva at sapo.pt  Wed Mar 12 11:00:28 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Wed, 12 Mar 2003 10:00:28 +0000 (WET)
Subject: [R] MAPE
Message-ID: <1047463228.3e6f053c1c573@webmail.sapo.pt>

Hi again

With arima0 the problem was solved but what are the diferences
between arima and arima0?

I have another question. I fit the model to the data and I make
some predictions. But I also want to calculate MAPE based in
the last 3 observations available. Is it possible? Can I obtain
the fitted values from the model?

thanks~
luis

--


From e.pebesma at geog.uu.nl  Wed Mar 12 11:46:12 2003
From: e.pebesma at geog.uu.nl (Edzer J. Pebesma)
Date: Wed, 12 Mar 2003 11:46:12 +0100
Subject: [R] Gstat: multivariable geostatistics for S (R and S-Plus)
Message-ID: <3E6F0FF4.CCD7EDC9@geog.uu.nl>

The majority of the functionality present in the gstat stand-alone
program (http://www.gstat.org/) is now available as a package/library for
the S language (R, S-Plus), again called gstat. The package provides
multivariable geostatistical modelling, prediction and simulation, as
well as several visualisation functions.  Gstat was started 10 years
ago and was released under the GPL in 1996; the original stand-alone
program is closely linked to several GIS systems. Gstat was not initially
written for teaching purposes, but for research purposes, emphasizing
flexibility, scalability and portability. It can deal with a large number
of practical issues in geostatistics, including change of support (block
kriging), simple/ordinary/universal (co)kriging, fast local neighbourhood
selection, flexible trend modelling, variables with different sampling
configurations, and efficient simulation of large spatially correlated
random fields, indicator kriging and simulation, and (directional)
variogram and cross variogram modelling. The S formula/models interface
is used to define multivariable geostatistical models.

The source and windows package for R are available from CRAN. The page on
http://www.gstat.org/s.html has links to R and S-Plus (6.x) source code,
as well as examples, graphs, and a longer list of features. (A binary
Win32 S-Plus library is planned later this year.)

On http://www.ci.tuwien.ac.at/Conferences/DSC-2003/ you can find a
draft paper further describing the package.

Any feedback is appreciated.
--
Edzer


From p.b.pynsent at bham.ac.uk  Wed Mar 12 11:54:13 2003
From: p.b.pynsent at bham.ac.uk (p.b.pynsent)
Date: Wed, 12 Mar 2003 10:54:13 +0000
Subject: [R] Filling graphic objects
Message-ID: <F61BC66D-5478-11D7-89A6-003065F42152@bham.ac.uk>

I have used polygon() to mark the confidence limits of a survival curve.
In another project, I have used the col parameter to fill my boxplots.

The poly() description refers to  filling but actually produces 
hatching (i.e. lines ).
boxplot() does truly fill the boxes with a colour or shades of grey 
(e.g. col="red").

My novices perception of R graphics is:
If you can hatch it, you cannot fill it.
If you can fill it you cannot hatch it.

Is this correct or is there  a way of hatching my boxplots and filling 
my polygons?

Paul


From vito.muggeo at giustizia.it  Wed Mar 12 13:01:12 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Wed, 12 Mar 2003 13:01:12 +0100
Subject: [R] simulating 'non-standard' survival data 
Message-ID: <004001c2e88f$28f7efe0$5c13070a@it.giustizia.it>

Dear all,
I'm looking for someone that help me to write an R function to simulate
survival data under complex situations, namely time-varying hazard ratio,
marginal distribution of survival times and covariates. The algorithm is
described in the reference below and it should be not very difficult to
implement it. However I tried but without success....;-(
Below there the code that I used; it works but the relevant results (i.e.
the estimates) are rather far from the true value; I cannot understand where
the error is.

People interested in, could send me an e-mail privately.

best,
vito

@article{mackenzie02,
    author={T. Mackenzie and M. Abrahamowicz},
    title={Marginal and hazard ratio specific random data: Applications to
semi-parametric bootstrapping},
    journal={Statistics and Computing},
    volume={12},
    year={2002},
    pages={245-252}
}

######################?
Code to simulate survival data under complex situations (MacKenzie and
Abrahamowicz, Statistics and Computing 2002)
#######################

#sample size
n<-100
R<-1:n
#explanatory variable
x<-runif(n,3,9)
#survival time and censoring variable:
obsTime<-rexp(n,1)
status<-ifelse(runif(n)>.2,1,0)
obsTime<-obsTime[order(obsTime)]
status<-status[order(obsTime)]
dati<-matrix(-99,n,(1+2))

#hazard ratio as function of the explanatory variable xx, and survival time.
HR<-function(ttime,xx){exp(.5)} #.5 is the log hazard ratio

P<-outer(obsTime,x,HR)
PP<-t(apply(P,1,function(x){sort(cumsum(sort(x,decreasing=T)),decreasing=T)}
))
Pok<-P/PP
for(i in 1:(n-1)){
        j<- if(status[i]==1) sample(R,size=1,prob=Pok[i,]) else
sample(R,size=1)
        ind<-which(R==j)
        dati[i,]<-c(obsTime[j],status[j],x[j])
        filtro<-R!=j
        R<-R[filtro]
        Pok<-Pok[,filtro]
            }
dati[nrow(dati),]<-c(obsTime[nrow(dati)],status[nrow(dati)],x[nrow(dati)])

dati<-data.frame(dati)
names(dati)<-c("SurvTime","cens","x")
library(survival)
coxph(Surv(SurvTime,cens)~x,dati)


From ripley at stats.ox.ac.uk  Wed Mar 12 13:13:00 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 12 Mar 2003 12:13:00 +0000 (GMT)
Subject: [R] Filling graphic objects
In-Reply-To: <F61BC66D-5478-11D7-89A6-003065F42152@bham.ac.uk>
Message-ID: <Pine.LNX.4.44.0303121207160.8695-100000@gannet.stats>

On Wed, 12 Mar 2003, p.b.pynsent wrote:

> I have used polygon() to mark the confidence limits of a survival curve.
> In another project, I have used the col parameter to fill my boxplots.
> 
> The poly() description refers to  filling but actually produces 

Did you mean polygon()?

> hatching (i.e. lines ).
> boxplot() does truly fill the boxes with a colour or shades of grey 
> (e.g. col="red").
> 
> My novices perception of R graphics is:
> If you can hatch it, you cannot fill it.
> If you can fill it you cannot hatch it.
> 
> Is this correct or is there  a way of hatching my boxplots and filling 
> my polygons?

You can fill polygons or rectangles (rect()) by giving `col' and not
giving `density'.

You cannot AFAICS hatch boxplots using the existing code: they are
conventionally not filled or filled in light grey.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From michael_miettinen at yahoo.com  Wed Mar 12 14:13:04 2003
From: michael_miettinen at yahoo.com (Michael Miettinen)
Date: Wed, 12 Mar 2003 05:13:04 -0800 (PST)
Subject: [R] Simple question about export
Message-ID: <20030312131304.96747.qmail@web21109.mail.yahoo.com>

Hi, 

Sorry about making this stupid question, but I did not
find the answer from documentation. 

I managed to read my spss .sav file into the R, no
problem.  Next I would like to write this data to a
file in ascii-format. I tried to use write.table and I
got no error messages, but no file either. What is the
right way to make it?  

At least write.table("c:\foo\data.dat") does not
work..

Thanks in advance! 

Michael

=====
michael_miettinen at yahoo.com
+358 40 849 1140

__________________________________________________

Yahoo! Web Hosting - establish your business online


From mounier at lmd.polytechnique.fr  Wed Mar 12 14:28:52 2003
From: mounier at lmd.polytechnique.fr (Flore MOUNIER)
Date: Wed, 12 Mar 2003 14:28:52 +0100
Subject: [R] temporal evolution and variance after rotation of eof
Message-ID: <200303121428.52321.mounier@lmd.polytechnique.fr>

Dear R users,
I have been doing some eof analysis using princomp function, then the eof 
results were rotated with varimax and promax functions. Those functions are 
working fine. However, after their uses, I cannot find how to obtain the 
temporal evolution and the variance of the obtain components, as varimax and 
promax does not have the arguments $scores and  $sdev.

If any body, know how to obtain the temporal evolution and the variance 
without $scores and  $sdev, do not hesitate; your help will be welcome.

Thank you in advance,
Flore Mounier

-- 
Flore MOUNIER
Laboratoire de M?t?orologie Dynamique
Ecole Polytechnique
F 91128 Palaiseau Cedex
T?l:  01-69-33-36-19
Fax:  01-69-33-30-49
e-mail : mounier at lmd.polytechnique.fr


From ripley at stats.ox.ac.uk  Wed Mar 12 14:33:18 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 12 Mar 2003 13:33:18 +0000 (GMT)
Subject: [R] Simple question about export
In-Reply-To: <20030312131304.96747.qmail@web21109.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0303121330150.28716-100000@gannet.stats>

On Wed, 12 Mar 2003, Michael Miettinen wrote:

> Sorry about making this stupid question, but I did not
> find the answer from documentation. 

See the FAQ question 7.10 How do file names work in Windows?


> I managed to read my spss .sav file into the R, no
> problem.  Next I would like to write this data to a
> file in ascii-format. I tried to use write.table and I
> got no error messages, but no file either. What is the
> right way to make it?  
> 
> At least write.table("c:\foo\data.dat") does not
> work..

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gisar at nus.edu.sg  Wed Mar 12 14:47:33 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Wed, 12 Mar 2003 21:47:33 +0800
Subject: [R] Simple question about export
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F225@MBXSRV03.stf.nus.edu.sg>

Well, you did not specify the object to save in write.table(). Suppose
you want to save the following:

x <- matrix( c(1:25), nrow=5)
write.table(x, file="c:/my.output.file.txt")

If all goes well, you should see the prompt without any message. 

Also use "/" rather than "\" as it is reserved for escape sequences.

You might also consider setting the option sep="\t" and quote=FALSE to
make it truly tab-delimited file. There is also row.names, col.name
option. Try reading the R Data Import/Export or write.table() again.


-----Original Message-----
From: Michael Miettinen [mailto:michael_miettinen at yahoo.com] 
Sent: Wednesday, March 12, 2003 9:13 PM
To: R-help at stat.math.ethz.ch
Subject: [R] Simple question about export


Hi, 

Sorry about making this stupid question, but I did not
find the answer from documentation. 

I managed to read my spss .sav file into the R, no
problem.  Next I would like to write this data to a
file in ascii-format. I tried to use write.table and I
got no error messages, but no file either. What is the
right way to make it?  

At least write.table("c:\foo\data.dat") does not
work..

Thanks in advance! 

Michael

=====
michael_miettinen at yahoo.com
+358 40 849 1140

__________________________________________________

Yahoo! Web Hosting - establish your business online

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From darryl.greig at hp.com  Wed Mar 12 14:57:19 2003
From: darryl.greig at hp.com (Darryl)
Date: Wed, 12 Mar 2003 15:57:19 +0200
Subject: [R] Simple question about export
In-Reply-To: <20030312131304.96747.qmail@web21109.mail.yahoo.com>
Message-ID: <005a01c2e89f$4cf05c60$bf09b00f@hpli.hpl.hp.com>

If that is what you tried, then you didn't supply the object to the
write.table function.
e.g. if your data.frame is called mydata in R you need

write.table(mydata,"c:/foo/data.dat")

The file is ascii. Note also that you either have to use forward slashes (as
above) or double backslashes

write.table(mydata,"c:\\foo\\data.dat")

R doesn't do the expected thing with single backslashes as you wrote it.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Michael Miettinen
Sent: 12 March 2003 15:13
To: R-help at stat.math.ethz.ch
Subject: [R] Simple question about export


Hi,

Sorry about making this stupid question, but I did not
find the answer from documentation.

I managed to read my spss .sav file into the R, no
problem.  Next I would like to write this data to a
file in ascii-format. I tried to use write.table and I
got no error messages, but no file either. What is the
right way to make it?

At least write.table("c:\foo\data.dat") does not
work..

Thanks in advance!

Michael

=====
michael_miettinen at yahoo.com
+358 40 849 1140

__________________________________________________

Yahoo! Web Hosting - establish your business online

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From petr.pikal at precheza.cz  Wed Mar 12 14:58:59 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 12 Mar 2003 14:58:59 +0100
Subject: [R] changing pen mode [or adjusting for overlapping points?]
In-Reply-To: <20030311212843.GM3755@epsilon.donarmstrong.com>
References: <007b01c2e813$ca058fe0$0201a8c0@MARC>
Message-ID: <3E6F4B33.28095.195C7A4@localhost>

Hi

On 11 Mar 2003 at 16:28, Don Armstrong wrote:

> On Tue, 11 Mar 2003, Marc Schwartz wrote:
> > Finally, you might also consider using the 'cex' argument in both
> > plot() and points(), which can reduce the size of the plotting
> > symbols. The default for par(cex) is 1.0, so you might try smaller
> > values.
> 
> Changing the pointsize helps a bit, however, it makes the points that
> aren't overlapped almost impossible to see. [Single pixels in a
> 1900x1600 plot are quite hard for my eyes to dicern, and it basically
> gets back to a mere density plot.]
> 
> What I'm really looking for is a method to adjust the mode in which
> the points are drawn, so that those that overlap a point of a
> different color produce yet a third color in the region of overlap.
>

something like that?

x<-rlnorm(10000)
y<-rnorm(10000,mean=0.5)
overlap<-which(abs(x-y)<.1)
plot(1:10000,x)
points(1:10000,y,col=2)
points((1:10000)[overlap],y[overlap],col=3)

 
> 
> Don Armstrong
> 
> -- 
> "I was thinking seven figures," he said, "but I would have taken a
> hundred grand. I'm not a greedy person." [All for a moldy bottle of
> tropicana.]
>  -- Sammi Hadzovic [in Andy Newman's 2003/02/14 NYT article.]
>  http://www.nytimes.com/2003/02/14/nyregion/14EYEB.html
> 
> http://www.donarmstrong.com
> http://www.anylevel.com
> http://rzlab.ucr.edu
> 

CheersPetr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


From Carlisle.Thacker at noaa.gov  Wed Mar 12 15:04:00 2003
From: Carlisle.Thacker at noaa.gov (W. C. Thacker)
Date: Wed, 12 Mar 2003 09:04:00 -0500
Subject: [R] job opportunity
Message-ID: <3E6F3E50.14667D12@noaa.gov>

The University of Miami's Rosenstiel School of Marine and Atmospheric
Sciences (RSMAS) is seeking a research associate to work with
hydrographic data.  The objective of the project is to develop
statistical models for estimating salinity and density from
observations of temperature together with knowledge of location and
time.  Because the relationship between salinity and temperature can
be highly variable due to meandering fronts, it is important to be
able to recognize from which side of a front the data come.
Consequently, developing a water-type classifier is part of the
project.  Once the models have been developed, they are to be
implemented as a component of computational codes for assimilating
data into an ocean-circulation model.

The relationship between temperature and salinity is to be derived
from a database of temperature-salinity-pressure profiles irregularly
distributed over the world oceans and over the past thirty years.  A
much larger data-base of temperature-depth profiles is available for
use in predicting salinity.  Satellite-based observations are
available to help in determining where the more recent data are
situated relative to fronts.  The equation of state for sea water can
be used to transform the estimated salinity, together with observed
temperature, into estimates for density.  The salinity estimates
should be constrained so that the resulting density increases
monotonically with depth.

The successful candidate should have substantial computational skills.
Ability to work with large data sets is imperative, as is the ability
to examine the data graphically.  Some knowledge of statistics is
essential, especially regression, classification, and spatial
statistics.  Experience with splus and matlab is highly desirable, as
is facility with fortran and/or C.  He/she should be comfortable
working in a unix environment.  Experience working with hydrographic
data, while not essential, is certainly desirable.

The work is to be done in collaboration with scientists at UM and at
the Atlantic Oceanographic and Meteorological Laboratory (AOML), so
there will be substantial guidance in how to approach the project.
However, the successful candidate should be able to function with a
minimal of supervision once the project is underway and he/she should
assume responsibility for the project's success.  Salary will reflect
the candidate's experience and qualifications.

RSMAS and AOML are located on Virginia Key, a short drive across
Biscayne Bay from downtown Miami, Florida.  Contact Arthur Marino
(305-361-4193/marino at rsmas.miami.edu) or Carlisle Thacker
(305-361-4323/thacker at aoml.noaa.gov) for further information.  To
apply, send resume to Jean Overton, RSMAS, 4301 Rickenbacker Causeway,
Miami FL 33149.  Please include names, addresses, and phone numbers of
at least three references.


From mathieu.roelants at vub.ac.be  Wed Mar 12 15:08:50 2003
From: mathieu.roelants at vub.ac.be (Mathieu Roelants)
Date: Wed, 12 Mar 2003 15:08:50 +0100
Subject: [R] Simple question about export
References: <20030312131304.96747.qmail@web21109.mail.yahoo.com>
Message-ID: <004f01c2e8a0$e822c780$a418b886@vub.we.dier>

----- Original Message -----
From: "Michael Miettinen" <michael_miettinen at yahoo.com>
To: <R-help at stat.math.ethz.ch>
Sent: Wednesday, 12 March, 2003 2:13 PM
Subject: [R] Simple question about export


> Hi,
>
> Sorry about making this stupid question, but I did not
> find the answer from documentation.
>
> I managed to read my spss .sav file into the R, no
> problem.  Next I would like to write this data to a
> file in ascii-format. I tried to use write.table and I
> got no error messages, but no file either. What is the
> right way to make it?
>
> At least write.table("c:\foo\data.dat") does not

>From the rw-FAQ: Backslashes have to be doubled in R character strings:

write.table(x, "c:\\foo\\data.dat")

or use a forward slash:

write.table(x, "c:/foo/data.dat")

where x is your data object


Mathieu Roelants, Project Vlaamse Groeicurven    mathieu.roelants at vub.ac.be
Laboratorium Antropogenetica Vrije Universiteit Brussel, Pleinlaan 2, B-1050
Brussel   Tel.+Fax 02/629.34.07
Laboratory of Anthropogenetics - University of Brussels, Pleinlaan 2, B-1050
Brussels (Belgium) Tel.+Fax + 32 2 629 34 07


From michael_miettinen at yahoo.com  Wed Mar 12 15:08:20 2003
From: michael_miettinen at yahoo.com (Michael Miettinen)
Date: Wed, 12 Mar 2003 06:08:20 -0800 (PST)
Subject: [R] Thank you all!
Message-ID: <20030312140820.79557.qmail@web21105.mail.yahoo.com>

Wow, this is really active list. I got several
friendly answers - many on them asking me to read
documentation better. 

I found this software just today, and I may was more
eager to try it out than I should have been. :-)  

I promise to use more time with documents before my
next question. 

Thanks, 

Michael 

P.S. Yes, I got problem solved. 

__________________________________________________

Yahoo! Web Hosting - establish your business online


From MSchwartz at medanalytics.com  Wed Mar 12 15:12:33 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 12 Mar 2003 08:12:33 -0600
Subject: [R] Simple question about export
In-Reply-To: <20030312131304.96747.qmail@web21109.mail.yahoo.com>
References: <20030312131304.96747.qmail@web21109.mail.yahoo.com>
Message-ID: <3E6F4051.5080509@MedAnalytics.com>

Michael Miettinen wrote:
> Hi, 
> 
> Sorry about making this stupid question, but I did not
> find the answer from documentation. 
> 
> I managed to read my spss .sav file into the R, no
> problem.  Next I would like to write this data to a
> file in ascii-format. I tried to use write.table and I
> got no error messages, but no file either. What is the
> right way to make it?  
> 
> At least write.table("c:\foo\data.dat") does not
> work..
> 
> Thanks in advance! 
> 
> Michael


Under Windows, you need to specify files paths using either "\\" or "/" 
as the separator.  This is referred to in R Windows FAQs 2.13 and 4.1.

Also, at least in the example you give above, you did not specify the 
name of the data frame that you want to export, which is the first 
argument to write.table().

Presuming that your dataframe is called 'spss" use:

write.table(spss, "c:\\foo\\data.dat")

or

write.table(spss, "c:/foo/data.dat")

See ?write.table, the R Windows FAQ and the R Data Import/Export 
documentation.

Regards,

Marc Schwartz


From p.b.pynsent at bham.ac.uk  Wed Mar 12 16:25:40 2003
From: p.b.pynsent at bham.ac.uk (p.b.pynsent)
Date: Wed, 12 Mar 2003 15:25:40 +0000
Subject: [R] Filling graphic objects
In-Reply-To: <Pine.LNX.4.44.0303121207160.8695-100000@gannet.stats>
Message-ID: <E2149674-549E-11D7-89A6-003065F42152@bham.ac.uk>


On Wednesday, March 12, 2003, at 12:13  pm, ripley at stats.ox.ac.uk wrote:

> On Wed, 12 Mar 2003, p.b.pynsent wrote:
>
>> I have used polygon() to mark the confidence limits of a survival 
>> curve.
>> In another project, I have used the col parameter to fill my boxplots.
>>
>> The poly() description refers to  filling but actually produces
>
> Did you mean polygon()?

Yes, I  apologise

>> hatching (i.e. lines ).
>> boxplot() does truly fill the boxes with a colour or shades of grey
>> (e.g. col="red").
>>
>> My novices perception of R graphics is:
>> If you can hatch it, you cannot fill it.
>> If you can fill it you cannot hatch it.
>>
>> Is this correct or is there  a way of hatching my boxplots and filling
>> my polygons?
>
> You can fill polygons or rectangles (rect()) by giving `col' and not
> giving `density'.
>

Thank you, this is not evident from the documentation. My confidence 
limits now look much better.

> You cannot AFAICS hatch boxplots using the existing code: they are
> conventionally not filled or filled in light grey.

The problem is distinguishing more than one group  on a single boxplot, 
shades of grey are not suitable for standard figures in publications.
Anyway thank you again.

Paul


Dr. P. B. Pynsent,
Research and Teaching Centre,
Royal Orthopaedic Hospital,
Birmingham, B31 2AP, U.K.


From shutnik_xx at yahoo.co.uk  Wed Mar 12 16:45:17 2003
From: shutnik_xx at yahoo.co.uk (=?iso-8859-1?q?Shutnik?=)
Date: Wed, 12 Mar 2003 15:45:17 +0000 (GMT)
Subject: [R] R help
Message-ID: <20030312154517.34097.qmail@web10904.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030312/8be2229a/attachment.pl

From spencer.graves at pdf.com  Wed Mar 12 16:45:56 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 12 Mar 2003 07:45:56 -0800
Subject: [R] problems with numerical optimisation
References: <200303120843.h2C8hbN09838@punik.econ.au.dk>
Message-ID: <3E6F5634.7060802@pdf.com>

Do you compute the singular value decomponsition of your gradients?

Unless you compute a marginal likelihood using Monte Carlo integration, 
I would expect convergence problems to be evident in the range of the 
absolute values of the singular values of the gradients:  If the 
smallest is less than, say, 1e-15 times the largest, you are chasing 
round-off, as discussed years ago by Box, Hunter, MacGregor, and Erjavec 
(1973) "Some problems associated with the analysis of multiresponse 
data", Technometrics, 15:  33-51.

(If you are using Monte Carlo integration, then I would ask if you've 
considered Markov Chain Monte Carlo?)

Hope this helps,
Spencer Graves

Ott Toomet wrote:
> Dear list,
> 
> this is not a particular R question but perhaps someone can help.
> 
> I am running a maximum likelihood estimation (competing risk duration
> model with unobserved heterogeneity) on 30 different datasets.  The
> problem is that on 2 datasets the model does not converge.  I am
> interested if there are any methods, based on the gradients or (an
> approximation of) the hessian which helps to determine what is the
> problem.  Can anybody recommend a good textbook about numerical
> optimisation?
> 
> Currently I am using 100 BFGS iterations + 100 BHHH iterations and I
> have programmed analytic gradients.  The fool-proof method of
> excluding the variables one-by-one and simplifying the structure is
> quite a slow and not particularily insightsful.
> 
> Thanks in advance
> 
> Ott
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From otoomet at econ.dk  Wed Mar 12 16:53:11 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Wed, 12 Mar 2003 16:53:11 +0100
Subject: [R] Simple question about export
In-Reply-To: <20030312131304.96747.qmail@web21109.mail.yahoo.com> (message
	from Michael Miettinen on Wed, 12 Mar 2003 05:13:04 -0800 (PST))
References: <20030312131304.96747.qmail@web21109.mail.yahoo.com>
Message-ID: <200303121553.h2CFrBM10038@punik.econ.au.dk>

Dear Michael,

If your dataset is large, you may consider my package savetable at

www.obs.ee/~siim/savetable_0.2.1.tar.gz

This is more memory-efficient than write.table.  Unfortunately, I have
not a window binary.

Best wishes,

Ott

 | Date: Wed, 12 Mar 2003 05:13:04 -0800 (PST)
 | From: Michael Miettinen <michael_miettinen at yahoo.com>
 | Hi, 
 | 
 | Sorry about making this stupid question, but I did not
 | find the answer from documentation. 
 | 
 | I managed to read my spss .sav file into the R, no
 | problem.  Next I would like to write this data to a
 | file in ascii-format. I tried to use write.table and I
 | got no error messages, but no file either. What is the
 | right way to make it?  
 | 
 | At least write.table("c:\foo\data.dat") does not
 | work..
 | 
 | Thanks in advance! 
 | 
 | Michael


From juli at ceam.es  Wed Mar 12 17:22:06 2003
From: juli at ceam.es (juli g. pausas)
Date: Wed, 12 Mar 2003 17:22:06 +0100
Subject: [R] variables in a correlation matrix
Message-ID: <3E6F5EAE.1040606@ceam.es>

Hi,
Given a correlation matrix, how can I know which variables have certain 
correlation values?

aa <- matrix( rnorm(25, 1,1), 5,5)
colnames(aa) <- c("v1", "v2", "v3", "v4", "v5")
aacor <- cor(aa)

For instance, which variables are negatively correlated?    
aacor[aacor<0]  # provide the r values, but how I get the variables?

Any suggestion?
Thanks in advance

Juli


From spencer.graves at pdf.com  Wed Mar 12 17:30:04 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 12 Mar 2003 08:30:04 -0800
Subject: [R] R help
References: <20030312154517.34097.qmail@web10904.mail.yahoo.com>
Message-ID: <3E6F608C.7060507@pdf.com>

Regarding 1 and 2:

myfunction <-
function(m=2, n=3)	
array(rnorm(m*n), dim=c(m, n))

myfunction()

I'll let someone else answer 3.
Spencer Graves

Shutnik wrote:
>  Dear friends,
>  I work with Matlab and now a bit in trouble with getting used to R. Could you give me some help with the following questions:
> 
>  1. how to generate the random matrix mxn with constant mean and variance, say N(0,1)?
> 
>  2. how to create a code (function), say ?myfunction?, and make it available for use every time I run R?
> 
>  3. how to make a package, say ?e1071?, available for use without loading it every time when I start R?
> 
>  Thank you.
> 
>  Regards,
> 
>  Max
> 
> 
> 
> 
> ---------------------------------
> 
> ur needs
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Wed Mar 12 17:39:58 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 12 Mar 2003 16:39:58 +0000 (GMT)
Subject: [R] variables in a correlation matrix
In-Reply-To: <3E6F5EAE.1040606@ceam.es>
Message-ID: <Pine.LNX.4.44.0303121637190.8380-100000@gannet.stats>

On Wed, 12 Mar 2003, juli g. pausas wrote:

> Hi,
> Given a correlation matrix, how can I know which variables have certain 
> correlation values?
> 
> aa <- matrix( rnorm(25, 1,1), 5,5)
> colnames(aa) <- c("v1", "v2", "v3", "v4", "v5")
> aacor <- cor(aa)
> 
> For instance, which variables are negatively correlated?    
> aacor[aacor<0]  # provide the r values, but how I get the variables?

nm <- dimnames(aacor)[[1]]
cbind(nm[row(aacor)[aacor<0]], nm[col(aacor)[aacor<0]])

is one way

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mkondrin at hppi.troitsk.ru  Thu Mar 13 04:50:04 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Wed, 12 Mar 2003 19:50:04 -0800
Subject: [R] R help
References: <20030312154517.34097.qmail@web10904.mail.yahoo.com>
	<3E6F608C.7060507@pdf.com>
Message-ID: <3E6FFFEC.9030502@hppi.troitsk.ru>

Spencer Graves wrote:
> Regarding 1 and 2:
> 
> myfunction <-
> function(m=2, n=3)   
> array(rnorm(m*n), dim=c(m, n))
> 
> myfunction()
> 
> I'll let someone else answer 3.
> Spencer Graves
> 
> Shutnik wrote:
> 
>>  Dear friends,
>>  I work with Matlab and now a bit in trouble with getting used to R. 
>> Could you give me some help with the following questions:
>>
>>  1. how to generate the random matrix mxn with constant mean and 
>> variance, say N(0,1)?
>>
>>  2. how to create a code (function), say ?myfunction?, and make it 
>> available for use every time I run R?
>>
>>  3. how to make a package, say ?e1071?, available for use without 
>> loading it every time when I start R?
>>
>>  Thank you.
>>
>>  Regards,
>>
>>  Max
>>

Edit ~/.Rprofile - add line
library(e1070)


From sundar.dorai-raj at pdf.com  Wed Mar 12 17:55:41 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 12 Mar 2003 10:55:41 -0600
Subject: [R] variables in a correlation matrix
References: <3E6F5EAE.1040606@ceam.es>
Message-ID: <3E6F668D.9040800@pdf.com>



juli g. pausas wrote:
> Hi,
> Given a correlation matrix, how can I know which variables have certain 
> correlation values?
> 
> aa <- matrix( rnorm(25, 1,1), 5,5)
> colnames(aa) <- c("v1", "v2", "v3", "v4", "v5")
> aacor <- cor(aa)
> 
> For instance, which variables are negatively correlated?    
> aacor[aacor<0]  # provide the r values, but how I get the variables?
> 
> Any suggestion?
> Thanks in advance
> 
> Juli
> 


Juli,
   How about?

R> aa <- matrix( rnorm(25, 1,1), 5,5)
R> colnames(aa) <- c("v1", "v2", "v3", "v4", "v5")
R> aacor <- cor(aa)
R> negcor <- which(aacor < 0 & row(aacor) < col(aacor), TRUE)
R> apply(negcor, 2, function(x, n)
  $   n[x],
  $   n = colnames(aacor))
      row  col
[1,] "v1" "v2"
[2,] "v1" "v3"
[3,] "v2" "v3"
[4,] "v2" "v4"
[5,] "v2" "v5"
[6,] "v3" "v5"
[7,] "v4" "v5"
R>


From Bernhard.Pfaff at drkw.com  Wed Mar 12 18:00:43 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Wed, 12 Mar 2003 18:00:43 +0100
Subject: [R] R help
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB900473029A@ibfftce505.is.de.dresdnerkb.com>


 Dear friends,
 I work with Matlab and now a bit in trouble with getting used to R. Could
you give me some help with the following questions:

 1. how to generate the random matrix mxn with constant mean and variance,
say N(0,1)?

 2. how to create a code (function), say "myfunction", and make it available
for use every time I run R?

 3. how to make a package, say "e1071", available for use without loading it
every time when I start R?

 Thank you.

 Regards,

 Max



ad 3)
?Startup


Cheers,
Bernhard


---------------------------------

ur needs

	[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------


From Barker at medtap.com  Wed Mar 12 19:05:17 2003
From: Barker at medtap.com (Barker, Chris)
Date: Wed, 12 Mar 2003 13:05:17 -0500
Subject: [R] Independent Components Analysis
Message-ID: <079383C285621946A40346523D618A9F780E30@exchange2000.medtap.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030312/3d36078b/attachment.pl

From vpiorno at uvigo.es  Wed Mar 12 19:18:28 2003
From: vpiorno at uvigo.es (Vicente Piorno)
Date: Wed, 12 Mar 2003 19:18:28 +0100
Subject: [R] quasipoisson, glm.nb and AIC values
Message-ID: <5.2.0.9.2.20030312191110.00ce7628@correo.uvigo.es>

Dear R users,
I am having problems trying to fit quasipoisson and negative binomials glm. 
My data set
contains abundance (counts) of a species under different management regimens.
First, I tried to fit a poisson glm:

 > summary(model.p<-glm(abund~mgmtcat,poisson))

       Call:
       glm(formula = abund ~ mgmtcat, family = poisson)
       .
       .
       .
       (Dispersion parameter for poisson family taken to be 1)

             Null deviance: 1904.7  on 19  degrees of freedom
       Residual deviance: 1154.3  on 16  degrees of freedom
       AIC: 1275.4
      Number of Fisher Scoring iterations: 4

Wich suggests the existence of STRONG overdispersion, so I tried:

 > summary(model.qp<-glm(abund~mgmtcat,quasipoisson))

       Call:
       glm(formula = abund ~ mgmtcat, family = quasipoisson)
       .
       .
       .
       (Dispersion parameter for quasipoisson family taken to be 73.51596)

              Null deviance: 1904.7  on 19  degrees of freedom
       Residual deviance: 1154.3  on 16  degrees of freedom
       AIC: NA
      Number of Fisher Scoring iterations: 4

Here I found the first problem: AIC is not available.

I know that count data for the studied species usually show aggregation. 
So, I fitted
a negative binomial glm with the glm.nb in MASS:

 > summary.negbin(model.nb<-glm.nb(abund~mgmtcat))

       Call: glm.nb(formula = abund ~ mgmtcat, init.theta = 
1.23560100958978,  link = log)
       .
       .
       .
       (Dispersion parameter for Negative Binomial(1.2356) family taken to 
be 1)

           Null deviance: 33.173  on 19  degrees of freedom
       Residual deviance: 22.316  on 16  degrees of freedom
       AIC: -15948
       Number of Fisher Scoring iterations: 1

       Correlation of Coefficients:
                (Intercept) mgmtcat1 mgmtcat2
       mgmtcat1     -0.7052
       mgmtcat2     -0.7053   0.4974
       mgmtcat3     -0.7005   0.4940    0.494

                         Theta:  1.236
                   Std. Err.:  0.362
        2 x log-likelihood:  -211.079

And now, I am getting a negative AIC value! I have seen that this problem 
have been discused in the S-news list.
Much of the discussion there is far beyond my statistical and R knowledge. 
One of the solutions proposed there
was adding - lgamma(y +1) to the internal function loglik in glm.nb, but I 
have seen that the current version of
MASS contains that term.

My problem is that I want to compare the quasipoisson and negative binomial 
models, and I have a NA value and a negative one.
Can I obtain an AIC for the quasipoisson model? What about the negative 
AIC? Can I use it or do you think that anything is wrong?

Thanks in advance,


--
Vicente Piorno
Departamento de Ecologia y Biologia Animal - Universidad de Vigo
EUIT Forestal - Campus Universitario
36005 Pontevedra SPAIN


From ripley at stats.ox.ac.uk  Wed Mar 12 19:22:48 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 12 Mar 2003 18:22:48 +0000 (GMT)
Subject: [R] Independent Components Analysis
In-Reply-To: <079383C285621946A40346523D618A9F780E30@exchange2000.medtap.com>
Message-ID: <Pine.LNX.4.44.0303121821080.19757-100000@gannet.stats>

On CRAN there is package fastICA and an ica function in package e1071

On Wed, 12 Mar 2003, Barker, Chris wrote:

> A colleague suggested that some R software was available for estimating
> "Independent Components Analysis" (ICA) (... signal separation).
>  
> If so, I'd appreciate any pointers . 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Wed Mar 12 19:42:52 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 12 Mar 2003 19:42:52 +0100
Subject: [R] Independent Components Analysis
References: <079383C285621946A40346523D618A9F780E30@exchange2000.medtap.com>
Message-ID: <3E6F7FAC.FE679FCA@statistik.uni-dortmund.de>



"Barker, Chris" wrote:
> 
> A colleague suggested that some R software was available for estimating
> "Independent Components Analysis" (ICA) (... signal separation).
> 
> If so, I'd appreciate any pointers .
> 
>             Chris Barker
>    Director of Statistical Research
>     MEDTAP International, Inc.
>            Redwood City, Ca
> 
>         www.medtap.com <http://www.medtap.com/>
> 
>           650 632 4218


There is ica() in package "e1071" and fastICA() in "fastICA". Both
packages are available at CRAN.

Uwe Ligges


From ligges at statistik.uni-dortmund.de  Wed Mar 12 19:50:17 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 12 Mar 2003 19:50:17 +0100
Subject: [R] quasipoisson, glm.nb and AIC values
References: <5.2.0.9.2.20030312191110.00ce7628@correo.uvigo.es>
Message-ID: <3E6F8169.8176FC9E@statistik.uni-dortmund.de>



Vicente Piorno wrote:
> 
> Dear R users,
> I am having problems trying to fit quasipoisson and negative binomials glm.
> My data set
> contains abundance (counts) of a species under different management regimens.
> First, I tried to fit a poisson glm:
> 
>  > summary(model.p<-glm(abund~mgmtcat,poisson))
> 
>        Call:
>        glm(formula = abund ~ mgmtcat, family = poisson)
>        .
>        .
>        .
>        (Dispersion parameter for poisson family taken to be 1)
> 
>              Null deviance: 1904.7  on 19  degrees of freedom
>        Residual deviance: 1154.3  on 16  degrees of freedom
>        AIC: 1275.4
>       Number of Fisher Scoring iterations: 4
> 
> Wich suggests the existence of STRONG overdispersion, so I tried:
> 
>  > summary(model.qp<-glm(abund~mgmtcat,quasipoisson))
> 
>        Call:
>        glm(formula = abund ~ mgmtcat, family = quasipoisson)
>        .
>        .
>        .
>        (Dispersion parameter for quasipoisson family taken to be 73.51596)
> 
>               Null deviance: 1904.7  on 19  degrees of freedom
>        Residual deviance: 1154.3  on 16  degrees of freedom
>        AIC: NA
>       Number of Fisher Scoring iterations: 4
> 
> Here I found the first problem: AIC is not available.
> 
> I know that count data for the studied species usually show aggregation.
> So, I fitted
> a negative binomial glm with the glm.nb in MASS:
> 
>  > summary.negbin(model.nb<-glm.nb(abund~mgmtcat))
> 
>        Call: glm.nb(formula = abund ~ mgmtcat, init.theta =
> 1.23560100958978,  link = log)
>        .
>        .
>        .
>        (Dispersion parameter for Negative Binomial(1.2356) family taken to
> be 1)
> 
>            Null deviance: 33.173  on 19  degrees of freedom
>        Residual deviance: 22.316  on 16  degrees of freedom
>        AIC: -15948
>        Number of Fisher Scoring iterations: 1
> 
>        Correlation of Coefficients:
>                 (Intercept) mgmtcat1 mgmtcat2
>        mgmtcat1     -0.7052
>        mgmtcat2     -0.7053   0.4974
>        mgmtcat3     -0.7005   0.4940    0.494
> 
>                          Theta:  1.236
>                    Std. Err.:  0.362
>         2 x log-likelihood:  -211.079
> 
> And now, I am getting a negative AIC value! I have seen that this problem
> have been discused in the S-news list.
> Much of the discussion there is far beyond my statistical and R knowledge.
> One of the solutions proposed there
> was adding - lgamma(y +1) to the internal function loglik in glm.nb, but I
> have seen that the current version of
> MASS contains that term.
> 
> My problem is that I want to compare the quasipoisson and negative binomial
> models, and I have a NA value and a negative one.
> Can I obtain an AIC for the quasipoisson model? What about the negative
> AIC? Can I use it or do you think that anything is wrong?
> 
> Thanks in advance,
> 
> --
> Vicente Piorno
> Departamento de Ecologia y Biologia Animal - Universidad de Vigo
> EUIT Forestal - Campus Universitario
> 36005 Pontevedra SPAIN
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


What's wrong with a negative AIC?
I would vote against comparing different model classes using AIC.
Instead, it's a better idea to think about which model class makes sense
in a given context.

Uwe Ligges


From ripley at stats.ox.ac.uk  Wed Mar 12 20:07:45 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 12 Mar 2003 19:07:45 +0000 (GMT)
Subject: [R] quasipoisson, glm.nb and AIC values
In-Reply-To: <5.2.0.9.2.20030312191110.00ce7628@correo.uvigo.es>
Message-ID: <Pine.LNX.4.44.0303121852270.20430-100000@gannet.stats>

1) A quasi- mode does not have a likelihood and so does not have an AIC, 
by definition.

2) There is nothing wrong with a negative AIC, but you don't have one.
The value of AIC in your problem is 211.079 + 2*16 + 2.  It is summary.glm 
that is giving you misleading results.  Try the following

logLik.negbin <- function(object, ...)
{
    if (length(list(...)))
        warning("extra arguments discarded")
    p <- object$rank + 1 # for theta
    val <- object$twologlik/2
    attr(val, "df") <- p
    class(val) <- "logLik"
    val

}

then AIC(fit) will work.

3) Don't call methods like summary.negbin directly: they will not be 
user-visible.


On Wed, 12 Mar 2003, Vicente Piorno wrote:

> Dear R users,
> I am having problems trying to fit quasipoisson and negative binomials glm. 
> My data set
> contains abundance (counts) of a species under different management regimens.
> First, I tried to fit a poisson glm:
> 
>  > summary(model.p<-glm(abund~mgmtcat,poisson))
> 
>        Call:
>        glm(formula = abund ~ mgmtcat, family = poisson)
>        .
>        .
>        .
>        (Dispersion parameter for poisson family taken to be 1)
> 
>              Null deviance: 1904.7  on 19  degrees of freedom
>        Residual deviance: 1154.3  on 16  degrees of freedom
>        AIC: 1275.4
>       Number of Fisher Scoring iterations: 4
> 
> Wich suggests the existence of STRONG overdispersion, so I tried:
> 
>  > summary(model.qp<-glm(abund~mgmtcat,quasipoisson))
> 
>        Call:
>        glm(formula = abund ~ mgmtcat, family = quasipoisson)
>        .
>        .
>        .
>        (Dispersion parameter for quasipoisson family taken to be 73.51596)
> 
>               Null deviance: 1904.7  on 19  degrees of freedom
>        Residual deviance: 1154.3  on 16  degrees of freedom
>        AIC: NA
>       Number of Fisher Scoring iterations: 4
> 
> Here I found the first problem: AIC is not available.
> 
> I know that count data for the studied species usually show aggregation. 
> So, I fitted
> a negative binomial glm with the glm.nb in MASS:
> 
>  > summary.negbin(model.nb<-glm.nb(abund~mgmtcat))
> 
>        Call: glm.nb(formula = abund ~ mgmtcat, init.theta = 
> 1.23560100958978,  link = log)
>        .
>        .
>        .
>        (Dispersion parameter for Negative Binomial(1.2356) family taken to 
> be 1)
> 
>            Null deviance: 33.173  on 19  degrees of freedom
>        Residual deviance: 22.316  on 16  degrees of freedom
>        AIC: -15948
>        Number of Fisher Scoring iterations: 1
> 
>        Correlation of Coefficients:
>                 (Intercept) mgmtcat1 mgmtcat2
>        mgmtcat1     -0.7052
>        mgmtcat2     -0.7053   0.4974
>        mgmtcat3     -0.7005   0.4940    0.494
> 
>                          Theta:  1.236
>                    Std. Err.:  0.362
>         2 x log-likelihood:  -211.079
> 
> And now, I am getting a negative AIC value! I have seen that this problem 
> have been discused in the S-news list.
> Much of the discussion there is far beyond my statistical and R knowledge. 
> One of the solutions proposed there
> was adding - lgamma(y +1) to the internal function loglik in glm.nb, but I 
> have seen that the current version of
> MASS contains that term.
> 
> My problem is that I want to compare the quasipoisson and negative binomial 
> models, and I have a NA value and a negative one.
> Can I obtain an AIC for the quasipoisson model? What about the negative 
> AIC? Can I use it or do you think that anything is wrong?
> 
> Thanks in advance,
> 
> 
> --
> Vicente Piorno
> Departamento de Ecologia y Biologia Animal - Universidad de Vigo
> EUIT Forestal - Campus Universitario
> 36005 Pontevedra SPAIN
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tencpa at yahoo.it  Wed Mar 12 20:25:28 2003
From: tencpa at yahoo.it (Paolo Tenconi)
Date: Wed, 12 Mar 2003 20:25:28 +0100
Subject: [R] Rcmd BATCH
Message-ID: <000801c2e8cd$273c05e0$532d6850@paoloz8qu3qy37>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030312/b02a4f93/attachment.pl

From ripley at stats.ox.ac.uk  Wed Mar 12 20:54:57 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 12 Mar 2003 19:54:57 +0000 (GMT)
Subject: [R] Rcmd BATCH
In-Reply-To: <000801c2e8cd$273c05e0$532d6850@paoloz8qu3qy37>
Message-ID: <Pine.LNX.4.44.0303121950420.20575-100000@gannet.stats>

On Wed, 12 Mar 2003, Paolo Tenconi wrote:

> Hello,
> I've a question: I invoke R from a text editor in a Win2000 operating system using 
> 
> Rcmd.exe BATCH inFile outFile
> 
> I've two problems:
> a) If I use windows() as graphics device, all windows close immediately after script execution,
>    how can I let them not to die?

This has been discussed frequently, so you may wish to search the 
archives.

Require some user intervention, e.g. by calling a dialog box by a call to

winDialog("ok", "click to finish the script")

> 
> b) Is it possible to redirect the content of outFile to the console output?

No.  Rcmd BATCH does not have a console! But see the rw-FAQ for ways to
send output to a command prompt window:  Rcmd BATCH is just a wrapper.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From cottrell at wfu.edu  Wed Mar 12 21:17:24 2003
From: cottrell at wfu.edu (Allin Cottrell)
Date: Wed, 12 Mar 2003 15:17:24 -0500 (EST)
Subject: [R] png plots
Message-ID: <Pine.LNX.4.52.0303121510400.1783@ricardo.ecn.wfu.edu>

I saw in the archive a post from Mark Wilkinson (Feb 1, 2003), saying
that some of his R-generated png plots came out overlapping.

I am seeing the same thing (with R 1.6.2 on Linux i686).  My input
file generated 4 plot files.  The first two were fine, but the last 2
featured a weird overlay of the remaining graphs.  The problem is not
seen with postscript of pdf output.

-- 
Allin Cottrell
Department of Economics
Wake Forest University, NC


From ripley at stats.ox.ac.uk  Wed Mar 12 21:35:25 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 12 Mar 2003 20:35:25 +0000 (GMT)
Subject: [R] png plots
In-Reply-To: <Pine.LNX.4.52.0303121510400.1783@ricardo.ecn.wfu.edu>
Message-ID: <Pine.LNX.4.44.0303122033040.20629-100000@gannet.stats>

And your platform is?  There are two different png devices in R.

On Wed, 12 Mar 2003, Allin Cottrell wrote:

> I saw in the archive a post from Mark Wilkinson (Feb 1, 2003), saying
> that some of his R-generated png plots came out overlapping.
> 
> I am seeing the same thing (with R 1.6.2 on Linux i686).  My input
> file generated 4 plot files.  The first two were fine, but the last 2
> featured a weird overlay of the remaining graphs.  The problem is not
> seen with postscript of pdf output.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Wed Mar 12 21:39:00 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 12 Mar 2003 21:39:00 +0100
Subject: [R] png plots
In-Reply-To: <Pine.LNX.4.52.0303121510400.1783@ricardo.ecn.wfu.edu>
References: <Pine.LNX.4.52.0303121510400.1783@ricardo.ecn.wfu.edu>
Message-ID: <x21y1ccobf.fsf@biostat.ku.dk>

Allin Cottrell <cottrell at wfu.edu> writes:

> I am seeing the same thing (with R 1.6.2 on Linux i686).  My input
> file generated 4 plot files.  The first two were fine, but the last 2
> featured a weird overlay of the remaining graphs.  The problem is not
> seen with postscript of pdf output.

Please, provide us with a reproducible example, or this will remain
little more than hearsay... I mean, we'll take your word that the
effect exists, but what can we do about it?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From cottrell at wfu.edu  Wed Mar 12 22:00:46 2003
From: cottrell at wfu.edu (Allin Cottrell)
Date: Wed, 12 Mar 2003 16:00:46 -0500 (EST)
Subject: [R] png plots
In-Reply-To: <Pine.LNX.4.44.0303122033040.20629-100000@gannet.stats>
References: <Pine.LNX.4.44.0303122033040.20629-100000@gannet.stats>
Message-ID: <Pine.LNX.4.52.0303121554240.1783@ricardo.ecn.wfu.edu>

On Wed, 12 Mar 2003 ripley at stats.ox.ac.uk wrote:

> And your platform is?  There are two different png devices in R.
>
> On Wed, 12 Mar 2003, Allin Cottrell wrote:
>
> > I saw in the archive a post from Mark Wilkinson (Feb 1, 2003), saying
> > that some of his R-generated png plots came out overlapping.
> >
> > I am seeing the same thing (with R 1.6.2 on Linux i686).  My input
> > file generated 4 plot files.  The first two were fine, but the last 2
> > featured a weird overlay of the remaining graphs.  The problem is not
> > seen with postscript of pdf output.

How do you tell which png device is used?  help(png) and help(Devices)
don't mention anything about multiple png drivers.  R_X11.so is linked
against libpng.so.3 if that's any help.

Allin Cottrell


From cottrell at wfu.edu  Wed Mar 12 22:04:47 2003
From: cottrell at wfu.edu (Allin Cottrell)
Date: Wed, 12 Mar 2003 16:04:47 -0500 (EST)
Subject: [R] png plots
In-Reply-To: <x21y1ccobf.fsf@biostat.ku.dk>
References: <Pine.LNX.4.52.0303121510400.1783@ricardo.ecn.wfu.edu>
 <x21y1ccobf.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.52.0303121603241.1783@ricardo.ecn.wfu.edu>

On Wed, 12 Mar 2003, Peter Dalgaard BSA wrote:

> Allin Cottrell <cottrell at wfu.edu> writes:
>
> > I am seeing the same thing (with R 1.6.2 on Linux i686).  My input
> > file generated 4 plot files.  The first two were fine, but the last 2
> > featured a weird overlay of the remaining graphs.  The problem is not
> > seen with postscript of pdf output.
>
> Please, provide us with a reproducible example...

Sorry, here's one:

library(tseries)
data(EuStockMarkets)
dax <- diff(log(EuStockMarkets))[,"DAX"]
dax.garch <- garch(dax)
png()
plot(dax.garch)
dev.off()

Allin Cottrell


From ripley at stats.ox.ac.uk  Wed Mar 12 22:16:23 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 12 Mar 2003 21:16:23 +0000 (GMT)
Subject: [R] png plots
In-Reply-To: <Pine.LNX.4.52.0303121554240.1783@ricardo.ecn.wfu.edu>
Message-ID: <Pine.LNX.4.44.0303122115500.21541-100000@gannet.stats>

png() and bitmap(), the latter using ghostscript.

On Wed, 12 Mar 2003, Allin Cottrell wrote:

> On Wed, 12 Mar 2003 ripley at stats.ox.ac.uk wrote:
> 
> > And your platform is?  There are two different png devices in R.
> >
> > On Wed, 12 Mar 2003, Allin Cottrell wrote:
> >
> > > I saw in the archive a post from Mark Wilkinson (Feb 1, 2003), saying
> > > that some of his R-generated png plots came out overlapping.
> > >
> > > I am seeing the same thing (with R 1.6.2 on Linux i686).  My input
> > > file generated 4 plot files.  The first two were fine, but the last 2
> > > featured a weird overlay of the remaining graphs.  The problem is not
> > > seen with postscript of pdf output.
> 
> How do you tell which png device is used?  help(png) and help(Devices)
> don't mention anything about multiple png drivers.  R_X11.so is linked
> against libpng.so.3 if that's any help.
> 
> Allin Cottrell
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Mark.Wilkinson at stjude.org  Wed Mar 12 22:28:30 2003
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Wed, 12 Mar 2003 15:28:30 -0600
Subject: [R] png plots
Message-ID: <A1DAD6685C12D511B20F00034725151380CECE@sjmemexc3.stjude.org>

 <<Rplot001.png>>  <<Rplot002.png>>  <<Rplot003.png>>  <<Rplot004.png>> 

Indeed, the problem persists.   My code was using a for() loop:

##
png()
for (i in seq(1, 16, 4)) {
  par(mfrow=c(2, 2))
  
  for (gt in i:(i+3)) {
    mysep <- paste(rep('  ', i), collapse='')
    plot(density(rnorm(1000)), main=paste(i, gt, sep=mysep))

    for (j in 1:5) { 
      lines(density(rnorm(1000)), lty=4, col="gray")
    }
  }
}
dev.off()
## 

The code works fine on Windows. 

> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.2
year     2003
month    01
day      10
language R

Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences

The opinions expressed here are my own and do not necessarily represent
those of St. Jude Children's Research Hospital.


 -----Original Message-----
From: 	Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk] 
Sent:	Wednesday, March 12, 2003 2:39 PM
To:	Allin Cottrell
Cc:	r-help at stat.math.ethz.ch
Subject:	Re: [R] png plots

Allin Cottrell <cottrell at wfu.edu> writes:

> I am seeing the same thing (with R 1.6.2 on Linux i686).  My input
> file generated 4 plot files.  The first two were fine, but the last 2
> featured a weird overlay of the remaining graphs.  The problem is not
> seen with postscript of pdf output.

Please, provide us with a reproducible example, or this will remain
little more than hearsay... I mean, we'll take your word that the
effect exists, but what can we do about it?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot001.png
Type: application/octet-stream
Size: 6572 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030312/1962fdcc/Rplot001.obj
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot002.png
Type: application/octet-stream
Size: 8100 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030312/1962fdcc/Rplot002.obj
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot003.png
Type: application/octet-stream
Size: 9409 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030312/1962fdcc/Rplot003.obj
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot004.png
Type: application/octet-stream
Size: 10060 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030312/1962fdcc/Rplot004.obj

From csillery at selway.umt.edu  Wed Mar 12 22:34:54 2003
From: csillery at selway.umt.edu (Katalin Csillery)
Date: Wed, 12 Mar 2003 14:34:54 -0700 (MST)
Subject: [R] apply with two matrixes
Message-ID: <Pine.OSF.4.21.0303121357330.5670-100000@selway.umt.edu>


Hi,

I have a function which does a certain task with two vectors, 
f1 <- function(a,b){body}

I also have a list of matrixes (all with the same dim's), and for each
column of each matrix in the list I want to use "f1", in such way that
it gives the vector "a" in the first argument of "f1". The second argument
of the function "b" also comes form a column of matrix (same dim's as any
matrix in the list), but that matrix is the same for all matrixes in the
list.
I use a separate function with an apply command to accomplish "f1" on each
column, and than lapply that function over all matrixes in the list.
The problem is I do not know how tell to apply to use the respective
columns of the single matrix over all matrixes in the list. 

Example (this does not work this way),
m #original matrix
l <- list(m1, m2, m3, ...) #list of matrixes
f1 <- function(a, b){body}
f2 <- function (mx) apply(mx, 2, f1, b = m)
lapply(l, f2)

What I want to end up with is a list of list (say lend), where
length(lend) = length(l)
length(lend[[any]]) = varies with some properties of the matrixes

My guess is that I sould use tapply, but I could not get it right.
The problem would be pretty easy with a loop, but efficiency is very
important, because the objects are huge and functions a computationally
intense.

Thanks for any help in advance!

Katalin
___
Katalin Csillery
Division of Biological Sciences
University of Montana, Missoula MT 59801
Phone: 406 243 6106, E-mail: csillery at selway.umt.edu
----------------------------------------------------


From ihaka at stat.auckland.ac.nz  Wed Mar 12 22:53:33 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Thu, 13 Mar 2003 10:53:33 +1300
Subject: [R] png plots
References: <Pine.LNX.4.52.0303121510400.1783@ricardo.ecn.wfu.edu>
	<x21y1ccobf.fsf@biostat.ku.dk>
	<Pine.LNX.4.52.0303121603241.1783@ricardo.ecn.wfu.edu>
Message-ID: <3E6FAC5D.7000704@stat.auckland.ac.nz>

Allin Cottrell wrote:

> Sorry, here's one:
> 
> library(tseries)
> data(EuStockMarkets)
> dax <- diff(log(EuStockMarkets))[,"DAX"]
> dax.garch <- garch(dax)
> png()
> plot(dax.garch)
> dev.off()

I can confirm that the problem exists in the latest development sources 
under RedHat 7.3.  I'm teaching in bit, but I'll have a look later and 
see if there is anything obvious.

-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand


From munoz at stat.wisc.edu  Wed Mar 12 23:05:18 2003
From: munoz at stat.wisc.edu (Alejandro Munoz del Rio)
Date: Wed, 12 Mar 2003 16:05:18 -0600
Subject: [R] avoiding excel's odbc limit on number of columns
Message-ID: <000c01c2e8e4$009be740$a0566880@surgery.wisc.edu>

Dear R-Helpers,

I would like to read an Excel .xls file via RODBC. I have successfully run
the example in p. 18 of "R Data Import/Export". The problem I am facing is
that Excel's ODBC driver seems to have a limit on the number of
fields/columns (output below). I haven't found any documentation on what
this limit L might be, but I know that 128 <= L < 256.

Does anyone know of a way to avoid "L" via
- the arguments to sqlQuery() or sqlGetResults()?
- an SQL select statement that can subset the columns/fields and index a
range of columns?
- otherwise?

[system info: win98 with 128Mb RAM, R v1.6.1, RODBC v. 1.0-1, excel 2000,
odbc driver v. 03.51; my knowledge of sql = $\epsilon$.]

Gratefully,

alejandro

> #Sheet1 has 92 rows and 256 columns; its structure is roughly as follows:
> # [blank]  0  1  2 ...  254
> #         0 70 70 71 ...  63
> # [89 rows deleted]
> #       90 57 56 52 ...  37
> frame1 <- sqlQuery(channel, "select * from [Sheet1$]")
> frame1
[1] "[RODBC] ERROR: Could not SQLExecute"
[2] "S1001 -1040 [Microsoft][ODBC Excel Driver] Too many fields defined."
> odbcGetInfo(channel)
[1] "EXCEL version 08.00.0000. Driver ODBC version 03.51"
> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.1
year     2002
month    11
day      01
language R


From jimmcloughlin at earthlink.net  Thu Mar 13 00:02:15 2003
From: jimmcloughlin at earthlink.net (Jim McLoughlin)
Date: Wed, 12 Mar 2003 15:02:15 -0800
Subject: [R] problem applying .C function in outer product
In-Reply-To: <Pine.LNX.4.44.0303122115500.21541-100000@gannet.stats>
Message-ID: <AB0A065C-54DE-11D7-AD2A-000393B2DF14@earthlink.net>

Hi folks

I'm relatively new to R, and am having some problems using a c function 
I'm calling.

The function is loaded, and it works for when given specific (scalar) 
arguments, but does not work when passed Vector arguments, and 
therefore fails in the outer product I need.

Here are the details:

the C function, where the last argument is used to return the value I 
need (price):

/*
  * Wrapper for use in R - requires that return value by passed via 
argument
  */
void blackScholesR( double *S, double *K, double *r, double *T, double 
*volatility, double *price)
{
     *price = blackScholes(*S, *K, *r, *T, *volatility);
}

The function definition in R:

blackS <- function(S,K,r,T,vol){
	tempx <- .C("blackScholesR",
	as.double(S),
	as.double(K),
	as.double(r),
	as.double(T),
	as.double(vol),
	as.double(0.0))
	as.double(tempx[6])
}

This function returns the appropriate value for constant vals, example:

 > blackS(52,50,0,0.5,0.43)
[1] 7.213387

but fails if I use vector arguments for S or T.  I ultimately want to 
create an outer product varying both S and T and graph the surface.

For example, given

 > T
  [1] 0.00000000 0.03571429 0.07142857 0.10714286 0.14285714 0.17857143
  [7] 0.21428571 0.25000000 0.28571429 0.32142857 0.35714286 0.39285714
[13] 0.42857143 0.46428571 0.50000000

I get

 > blackS(52,50,0,T,0.43)
[1] 2

2 is the right answer for the first value of T, but it should produce 
an entire vector of values for all possible T.  I assume here is a 
problem with my return value in the R function blackS.  I tried return 
tempx[6] without casting casting to double.  This gives similar 
results, except it seems to be a vector embedded in a list:

blackS(52,50,0,0.5,0.43)
[[1]]
[1] 7.213387

I'm probably making an obvious mistake, but am at an impasse.  Any help 
greatly appreciated

regards

Jim M


From cottrell at wfu.edu  Thu Mar 13 00:30:42 2003
From: cottrell at wfu.edu (Allin Cottrell)
Date: Wed, 12 Mar 2003 18:30:42 -0500 (EST)
Subject: [R] problem applying .C function in outer product
In-Reply-To: <AB0A065C-54DE-11D7-AD2A-000393B2DF14@earthlink.net>
References: <AB0A065C-54DE-11D7-AD2A-000393B2DF14@earthlink.net>
Message-ID: <Pine.LNX.4.52.0303121826520.14500@ricardo.ecn.wfu.edu>

On Wed, 12 Mar 2003, Jim McLoughlin wrote:

> /*
>   * Wrapper for use in R - requires that return value by passed via
> argument
>   */
> void blackScholesR( double *S, double *K, double *r, double *T, double
> *volatility, double *price)
> {
>      *price = blackScholes(*S, *K, *r, *T, *volatility);
> }

You are passing all scalars and no vectors to the function
blackScholes().  E.g. if S is of type (double *), then *S is of type
double (a single double-precision value, S[0]), and so on for *K, *r,
*T etc.

Allin Cottrell.


From kjetil at entelnet.bo  Thu Mar 13 03:42:34 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed, 12 Mar 2003 22:42:34 -0400
Subject: [R] quasipoisson, glm.nb and AIC values
In-Reply-To: <3E6F8169.8176FC9E@statistik.uni-dortmund.de>
Message-ID: <3E6FB7DA.24376.10E9E03@localhost>

On 12 Mar 2003 at 19:50, Uwe Ligges wrote:

.
.
.
.

> I would vote against comparing different model classes using AIC.

Why? I thought one of the advantages with AIC is that it can be used 
to compare different model classes, although in practice it might be 
difficult because programs delete constants which shouldn't be 
deleted.

Kjetil Halvorsen

> Instead, it's a better idea to think about which model class makes sense
> in a given context.
> 
> Uwe Ligges
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From kjetil at entelnet.bo  Thu Mar 13 03:42:34 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed, 12 Mar 2003 22:42:34 -0400
Subject: [R] [OT] Appropriate test?
In-Reply-To: <200303120237.05306.meles@free.fr>
Message-ID: <3E6FB7DA.30144.10E9D86@localhost>

On 12 Mar 2003 at 2:37, Blaise TRAMIER wrote:

You should have a look at the package nlme, installed with your 
distribution of R. Look at the help for the function 
lme (linear mixed models). You have not described your data
sufficiently to say much more, but you have biological measurements 
changing through time, if that is in some non-linear fashion
you could have use of the function nlme (non linear mixed models). 

If this is'nt enough to get you going, come back with more
details of your data AND questions to answer.

Kjetil Halvorsen

> Hi,
> 	I'm having some problem with a dataset and I don't really know how to 
> analyse it.
> 
> I have 20 subjects in two groups of treatment (8 an 12 subjects).
> Biological measure have been recorded at different time, from t0 (before 
> the treatment) to t7 (3 days after). The time elapsed between each 
> measure is not constant.
> 
> What is the most appropriate test to show a difference between the 2 
> treatements?
> 
> I thought that an anova for repeated measure could do the trick, but I 
> didn't really find how to do it with R.
> 
> I sorry for being OT but I didn't really know where to ask this 
> question. If you could redirect me on a appropriate forum or mailing 
> list to have that sort of help, I would appreciate a lot.
> 
> Thanks in advance.
> 
> -- 
> Blaise TRAMIER
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From kjetil at entelnet.bo  Thu Mar 13 03:42:34 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed, 12 Mar 2003 22:42:34 -0400
Subject: [R] Offtopic --- book references
Message-ID: <3E6FB7DA.25523.10E9F0D@localhost>

Hola!

I am about to do this years buying for our library, and could need
help with some references. 

Some people here will start to work with IRT and Rasch models. 
>From the book descriptions on Amazon it is difficult to decide
what books to buy. 

I want one introductory book on IRT/Rasch, and one more
profound, with sufficient detail to actually start coding. 

Anybody knows some good books satisfying this criteria?

Kjetil Halvorsen


From r.hankin at auckland.ac.nz  Thu Mar 13 04:29:07 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Thu, 13 Mar 2003 16:29:07 +1300
Subject: [R] apply() and unary operators
Message-ID: <200303130329.h2D3T7o6004407@r.hankin.sges.auckland.ac.nz>

Hi everyone.

What's going on here?


> a <- matrix(1:4,2,2)
> a
     [,1] [,2]
[1,]    1    3
[2,]    2    4
> apply(a,2,sum)
[1] 3 7
> apply(a,2,"+")
     [,1] [,2]
[1,]    1    3
[2,]    2    4
> apply(a,1,"+")
     [,1] [,2]
[1,]    1    2
[2,]    3    4
> 

help(apply) says that "+" should be quoted but is otherwise silent on
unary operators.  I don't understand apply() here at all.

anyone?

-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042


From tlumley at u.washington.edu  Thu Mar 13 05:16:48 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 12 Mar 2003 20:16:48 -0800 (PST)
Subject: [R] apply() and unary operators
In-Reply-To: <200303130329.h2D3T7o6004407@r.hankin.sges.auckland.ac.nz>
Message-ID: <Pine.A41.4.44.0303122013490.70926-100000@homer33.u.washington.edu>

On Thu, 13 Mar 2003, Robin Hankin wrote:

> Hi everyone.
>
> What's going on here?
>
>
> > a <- matrix(1:4,2,2)
> > a
>      [,1] [,2]
> [1,]    1    3
> [2,]    2    4
> > apply(a,2,sum)
> [1] 3 7
> > apply(a,2,"+")
>      [,1] [,2]
> [1,]    1    3
> [2,]    2    4
> > apply(a,1,"+")
>      [,1] [,2]
> [1,]    1    2
> [2,]    3    4
> >
>
> help(apply) says that "+" should be quoted but is otherwise silent on
> unary operators.  I don't understand apply() here at all.
>

The problem is that "+" takes two arguments, but apply() gives it a single
vector argument.  I think you are actually getting the unary "+" function,
so  apply(a,1,"+") applies unary "+" to each row (which has no effect) and
then sticks the results together into a matrix.

	-thomas


From fharrell at virginia.edu  Thu Mar 13 01:58:59 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed, 12 Mar 2003 19:58:59 -0500
Subject: [R] simulating 'non-standard' survival data
In-Reply-To: <004001c2e88f$28f7efe0$5c13070a@it.giustizia.it>
References: <004001c2e88f$28f7efe0$5c13070a@it.giustizia.it>
Message-ID: <20030312195859.3e9076ca.fharrell@virginia.edu>

On Wed, 12 Mar 2003 13:01:12 +0100
vito muggeo <vito.muggeo at giustizia.it> wrote:

> Dear all,
> I'm looking for someone that help me to write an R function to simulate
> survival data under complex situations, namely time-varying hazard ratio,
> marginal distribution of survival times and covariates. The algorithm is
> described in the reference below and it should be not very difficult to
> implement it. However I tried but without success....;-(
> Below there the code that I used; it works but the relevant results (i.e.
> the estimates) are rather far from the true value; I cannot understand where
> the error is.
> 
> People interested in, could send me an e-mail privately.
> 
> best,
> vito
> 
> @article{mackenzie02,
>     author={T. Mackenzie and M. Abrahamowicz},
>     title={Marginal and hazard ratio specific random data: Applications to
> semi-parametric bootstrapping},
>     journal={Statistics and Computing},
>     volume={12},
>     year={2002},
>     pages={245-252}
> }
> 
. . .

You might look at the spower function in the Hmisc package.  It allows for complex situations such as a non-constant treatment effect on the hazard, a dropout function, a dropin function, staggered entry.  It only covers the two-sample case right now (no covariates) but it would not be too hard to add covariates (volunteers welcomed).  spower uses a trick where the time axis is discretized into for example a 2000-point grid.  That allows simple numerical integration to be used to factor in the complications, to get the cumulative hazard function and then do simulations off that.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From ripley at stats.ox.ac.uk  Thu Mar 13 06:22:17 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 13 Mar 2003 05:22:17 +0000 (GMT)
Subject: [R] quasipoisson, glm.nb and AIC values
In-Reply-To: <3E6FB7DA.24376.10E9E03@localhost>
Message-ID: <Pine.LNX.4.44.0303130513070.22357-100000@gannet.stats>

On Wed, 12 Mar 2003, kjetil brinchmann halvorsen wrote:

> On 12 Mar 2003 at 19:50, Uwe Ligges wrote:

> > I would vote against comparing different model classes using AIC.
> 
> Why? I thought one of the advantages with AIC is that it can be used 
> to compare different model classes, although in practice it might be 
> difficult because programs delete constants which shouldn't be 
> deleted.

On the last point, as log-likelihood is only defined up to a constant
(depending on the dominating measure and hence the data), it is more a
question of legitimate use of different definitions by different
programmers.  In this case it is a question of using method inherited from
glm that an inappropriate in R (but not in S) and I will fix it for R 
1.7.0.

On the first point: Akaike only defined AIC for a nested series of models.
AIC can be used to compare non-nested models, but

1) The theory needs to make assumptions which may well not hold, for 
example when comparing lme models with lm or gee models when under one 
model the MLEs fitting the other are on the boundary of the space.

2) The sampling variability of the difference in AIC is large in the
non-nested case.

See e.g.
http://www.stats.gla.ac.uk/~goeran/euroworkshop/webpages/2002/slides/brian.pdf

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From spencer.graves at pdf.com  Thu Mar 13 06:46:40 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 12 Mar 2003 21:46:40 -0800
Subject: [R] [OT] Appropriate test?
References: <3E6FB7DA.30144.10E9D86@localhost>
Message-ID: <3E701B40.4020300@pdf.com>

If you want to use nlme, am I correct is asserting that the best 
reference is

Pinhiero and Bates (2000) Mixed Effects Models in S and S-Plus (NY: 
Springer) ?

Spencer Graves

kjetil brinchmann halvorsen wrote:
> On 12 Mar 2003 at 2:37, Blaise TRAMIER wrote:
> 
> You should have a look at the package nlme, installed with your 
> distribution of R. Look at the help for the function 
> lme (linear mixed models). You have not described your data
> sufficiently to say much more, but you have biological measurements 
> changing through time, if that is in some non-linear fashion
> you could have use of the function nlme (non linear mixed models). 
> 
> If this is'nt enough to get you going, come back with more
> details of your data AND questions to answer.
> 
> Kjetil Halvorsen
> 
> 
>>Hi,
>>	I'm having some problem with a dataset and I don't really know how to 
>>analyse it.
>>
>>I have 20 subjects in two groups of treatment (8 an 12 subjects).
>>Biological measure have been recorded at different time, from t0 (before 
>>the treatment) to t7 (3 days after). The time elapsed between each 
>>measure is not constant.
>>
>>What is the most appropriate test to show a difference between the 2 
>>treatements?
>>
>>I thought that an anova for repeated measure could do the trick, but I 
>>didn't really find how to do it with R.
>>
>>I sorry for being OT but I didn't really know where to ask this 
>>question. If you could redirect me on a appropriate forum or mailing 
>>list to have that sort of help, I would appreciate a lot.
>>
>>Thanks in advance.
>>
>>-- 
>>Blaise TRAMIER
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Thu Mar 13 07:14:49 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 13 Mar 2003 06:14:49 +0000 (GMT)
Subject: [R] [OT] Appropriate test?
In-Reply-To: <3E701B40.4020300@pdf.com>
Message-ID: <Pine.LNX.4.44.0303130600560.23207-100000@gannet.stats>

On Wed, 12 Mar 2003, Spencer Graves wrote:

> If you want to use nlme, am I correct is asserting that the best 
> reference is
> 
> Pinhiero and Bates (2000) Mixed Effects Models in S and S-Plus (NY: 
> Springer) ?

Yes.

There are several other ways to do this though, and I don't think I would 
start with nlme.  The book by Diggle, Liang and Zeger is better at
showing the range of possibilities.  Note that you are rather short on 
subjects: with 8 measures on only 8 subjects (in the smaller group)
it is going to be hard to generalize to a population.  So your best hope 
is if the pattern of responses is simple (e.g. linear).

The `classical' approach is that you have an 8-way response for each 
subject, in which case you can use MANOVA (see ?summary.manova in R) to 
test the difference between groups.

Probably the most fruitful appoach is to plot all 20 responses against
time (by a lattice plot?) and then see if a simple model will summarize
all the curves.  You could then use (n)lme, but for the purposes of
testing the difference between the groups I would start by fitting the
model to each subject, and use the parameter(s) of each model as input to
MANOVA (or a multivariate T test).  The real advantage of (n)lme would
come if you have different measurement times for each subject: there are
examples of repeated measures studies of that form in MASS4 (Venables &
Ripley, 2002, see the R FAQ).

You could use aov() with an Error term.

You could use GEE.

Jim Lindsey's packages had various functions for repeated measures last 
time I looked.

> 
> Spencer Graves
> 
> kjetil brinchmann halvorsen wrote:
> > On 12 Mar 2003 at 2:37, Blaise TRAMIER wrote:
> > 
> > You should have a look at the package nlme, installed with your 
> > distribution of R. Look at the help for the function 
> > lme (linear mixed models). You have not described your data
> > sufficiently to say much more, but you have biological measurements 
> > changing through time, if that is in some non-linear fashion
> > you could have use of the function nlme (non linear mixed models). 
> > 
> > If this is'nt enough to get you going, come back with more
> > details of your data AND questions to answer.
> > 
> > Kjetil Halvorsen
> > 
> > 
> >>Hi,
> >>	I'm having some problem with a dataset and I don't really know how to 
> >>analyse it.
> >>
> >>I have 20 subjects in two groups of treatment (8 an 12 subjects).
> >>Biological measure have been recorded at different time, from t0 (before 
> >>the treatment) to t7 (3 days after). The time elapsed between each 
> >>measure is not constant.
> >>
> >>What is the most appropriate test to show a difference between the 2 
> >>treatements?
> >>
> >>I thought that an anova for repeated measure could do the trick, but I 
> >>didn't really find how to do it with R.
> >>
> >>I sorry for being OT but I didn't really know where to ask this 
> >>question. If you could redirect me on a appropriate forum or mailing 
> >>list to have that sort of help, I would appreciate a lot.
> >>
> >>Thanks in advance.
> >>
> >>-- 
> >>Blaise TRAMIER
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From petr.pikal at precheza.cz  Thu Mar 13 08:45:24 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 13 Mar 2003 08:45:24 +0100
Subject: [R] R help
In-Reply-To: <20030312154517.34097.qmail@web10904.mail.yahoo.com>
Message-ID: <3E704524.26596.42D7D5@localhost>

Hi

On 12 Mar 2003 at 15:45, Shutnik wrote:

>  Dear friends,
>  I work with Matlab and now a bit in trouble with getting used to R.
>  Could you give me some help with the following questions:
> 
>  1. how to generate the random matrix mxn with constant mean and
>  variance, say N(0,1)?
> 
>  2. how to create a code (function), say ?myfunction?, and make it
>  available for use every time I run R?
> 
>  3. how to make a package, say ?e1071?, available for use without
>  loading it every time when I start R?
> 
On Windows I use this .Rprofile file in working directory to load 
three libraries, one data set and change graphic background to 
white. Its just a plain text file.


library(fun)
library(modreg)
library(ts)
data(stand)
par(bg="white")



>  Thank you.
> 
>  Regards,
> 
>  Max
> 

Cheers

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


From Jussi.Makinen at valtiokonttori.fi  Thu Mar 13 09:04:40 2003
From: Jussi.Makinen at valtiokonttori.fi (=?iso-8859-2?Q?M=E4kinen_Jussi?=)
Date: Thu, 13 Mar 2003 10:04:40 +0200
Subject: [R] R help
Message-ID: <7EFB6224454CD511B9D700306E00F4070203617B@VKYHA01>

Try (run..):

rnorm(1, 0, 1) # (or in this case rnorm(1) - check ?rnorm)

aaa <- function(x) x + 1

aaa(1)

?.First


Regards, Jussi

-----Original Message-----
From: Petr Pikal [mailto:petr.pikal at precheza.cz]
Sent: Thursday, March 13, 2003 9:45 AM
To: Shutnik
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] R help


Hi

On 12 Mar 2003 at 15:45, Shutnik wrote:

>  Dear friends,
>  I work with Matlab and now a bit in trouble with getting used to R.
>  Could you give me some help with the following questions:
> 
>  1. how to generate the random matrix mxn with constant mean and
>  variance, say N(0,1)?
> 
>  2. how to create a code (function), say ?myfunction?, and make it
>  available for use every time I run R?
> 
>  3. how to make a package, say ?e1071?, available for use without
>  loading it every time when I start R?
> 
On Windows I use this .Rprofile file in working directory to load 
three libraries, one data set and change graphic background to 
white. Its just a plain text file.


library(fun)
library(modreg)
library(ts)
data(stand)
par(bg="white")



>  Thank you.
> 
>  Regards,
> 
>  Max
> 

Cheers

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From p.dalgaard at biostat.ku.dk  Thu Mar 13 09:20:43 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 13 Mar 2003 09:20:43 +0100
Subject: [R] [OT] Appropriate test?
In-Reply-To: <3E701B40.4020300@pdf.com>
References: <3E6FB7DA.30144.10E9D86@localhost> <3E701B40.4020300@pdf.com>
Message-ID: <x2of4fbrtw.fsf@biostat.ku.dk>

Spencer Graves <spencer.graves at pdf.com> writes:

> If you want to use nlme, am I correct is asserting that the best
> reference is
> 
> Pinhiero and Bates (2000) Mixed Effects Models in S and S-Plus (NY:
> Springer) ?

Yes. You might find it more easily if you spell Jose's name correctly
though: It's Pinheiro.

        -p
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From Ted.Harding at nessie.mcc.ac.uk  Thu Mar 13 10:12:18 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 13 Mar 2003 09:12:18 -0000 (GMT)
Subject: [R] quasipoisson, glm.nb and AIC values
In-Reply-To: <Pine.LNX.4.44.0303130513070.22357-100000@gannet.stats>
Message-ID: <XFMail.030313091218.Ted.Harding@nessie.mcc.ac.uk>

On 13-Mar-03 ripley at stats.ox.ac.uk wrote:
> 
> See e.g.
> http://www.stats.gla.ac.uk/~goeran/euroworkshop/webpages/2002/slides/bri
> an.pdf

A very useful summary. Thanks!
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 13-Mar-03                                       Time: 09:12:18
------------------------------ XFMail ------------------------------


From meles at free.fr  Thu Mar 13 11:49:11 2003
From: meles at free.fr (Blaise TRAMIER)
Date: Thu, 13 Mar 2003 10:49:11 +0000
Subject: [R] [OT] Appropriate test?
In-Reply-To: <200303120237.05306.meles@free.fr>
References: <200303120237.05306.meles@free.fr>
Message-ID: <200303131049.11740.meles@free.fr>

Le Mercredi 12 Mars 2003 02:37, Blaise TRAMIER a ?crit :
> Hi,
> 	I'm having some problem with a dataset and I don't really know how
> to analyse it.

Hi,
	thanks a lot for all your answers. I think I have plenty of leads to 
explore.

As suggested in a private mail, I tried to submit my problem to 
sci.stat.consult, without any answers yet.

Best regards.

Blaise TRAMIER
-- 
Deux choses sont infinies : l'univers et la betise humaine. En ce qui
concerne l'univers je n'en ai pas acquis la certitude absolue.
Albert Enstein.


From dieter.menne at menne-biomed.de  Thu Mar 13 11:04:53 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Thu, 13 Mar 2003 11:04:53 +0100
Subject: [R] geepack(geese) vs. glmmPQL
Message-ID: <JLEPLGAANFCEAEDCAGJNOEIBCEAA.dieter.menne@menne-biomed.de>

Dear R-List,

I have a data set (available on request) of observations from
a 2x2 conditions psychological experiment, with count of
correct/wrong decisions, and vp as the subject id.

 $ vp      : Factor w/ 10 levels "1","10","2","3",..: 1 1 1 1 1 1 1 1 2 2
...
 $ bed     : Factor w/ 2 levels "Hz15","Hz1": 1 1 1 1 2 2 2 2 1 1 ...
 $ task    : Factor w/ 2 levels "n","p": 1 1 2 2 1 1 2 2 1 1 ...
 $ decision: Factor w/ 2 levels "corr","wrong": 1 2 1 2 1 2 1 2 1 2 ...
 $ count   : int  20 14 25 26 5 29 27 7 7 10 ...

Analyzed by glmmPQL, the result is meaningful and "as expected"

--------------------------------------------
gep<-glmmPQL(decision~bed+task+bed*task,data=mag3,random=~1|vp,
             weights=count, family=binomial )

Fixed effects: decision ~ bed + task + bed * task
              Value Std.Error DF t-value p-value
(Intercept)  -0.666     0.504 65   -1.32  0.1910
bedHz1        1.187     0.746 65    1.59  0.1163
taskp         1.359     0.663 65    2.05  0.0443
bedHz1:taskp -2.328     0.986 65   -2.36  0.0213

I first had tried with geese (from geepack), but
the results were totally off.
Is this a convergence or my error in specifying
the model?

------------------------
geese(decision~bed+task+bed*task,data=mag3,id=vp,
             weights=count, family=binomial)

 Coefficients:
              estimate   san.se wald p
(Intercept)   3.36e+16 6.48e+14 2696 0
bedHz1        3.14e+16 9.54e+14 1081 0
taskp         3.54e+16 5.50e+14 4155 0
bedHz1:taskp -6.18e+16 1.14e+15 2934 0

Scale Model:
 Scale Link:                identity

 Estimated Scale Parameters:
            estimate   san.se     wald p
(Intercept) 2.31e+15 1.36e+38 2.91e-46 1

Correlation Model:
 Correlation Structure:     independence

Returned Error Value:    1
Number of clusters:   10   Maximum cluster size: 8


------------

Dieter Menne


From lm.silva at sapo.pt  Thu Mar 13 12:02:32 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Thu, 13 Mar 2003 11:02:32 +0000 (WET)
Subject: [R] standardized residuals
Message-ID: <1047553352.3e7065489648a@webmail.sapo.pt>

Dear helpers

I have a question about the arima0 function of package ts. When 
a model is fitted it is possible to get the residuals, but they 
are standardized. By their mean and std? The results I get 
don't make sense with that.
Where can I obtain more information about this function?
--


From edd at debian.org  Thu Mar 13 13:59:24 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 13 Mar 2003 06:59:24 -0600
Subject: [R] problem applying .C function in outer product
In-Reply-To: <AB0A065C-54DE-11D7-AD2A-000393B2DF14@earthlink.net>
References: <Pine.LNX.4.44.0303122115500.21541-100000@gannet.stats>
	<AB0A065C-54DE-11D7-AD2A-000393B2DF14@earthlink.net>
Message-ID: <20030313125924.GA27054@sonny.eddelbuettel.com>

On Wed, Mar 12, 2003 at 03:02:15PM -0800, Jim McLoughlin wrote:
> The function is loaded, and it works for when given specific (scalar) 
> arguments, but does not work when passed Vector arguments, and 
> therefore fails in the outer product I need.
[...] 
> blackS <- function(S,K,r,T,vol){
> 	tempx <- .C("blackScholesR",
> 	as.double(S),
> 	as.double(K),
> 	as.double(r),
> 	as.double(T),
> 	as.double(vol),
> 	as.double(0.0))
> 	as.double(tempx[6])
> }
> 
> This function returns the appropriate value for constant vals, example:
> 
> > blackS(52,50,0,0.5,0.43)
> [1] 7.213387
> 
> but fails if I use vector arguments for S or T.  I ultimately want to 
> create an outer product varying both S and T and graph the surface.

Allin already pointed out that your function is scalar-valued -- yet you
want a vector context.  No real problem there -- you simply need to provide
it.  

It so happens that I have an example in my small RQuantLib package (which is
essentially a wrapper around some functions of the larger QuantLib library)
that does just that. 

>From example(EuropeanOptionArrays):

   # define two vectors for the underlying and the volatility
   und.seq <- seq(10,180,by=2)
   vol.seq <- seq(0.1,0.9,by=0.1)
   # evaluate them along with three scalar parameters
   EOarr <- EuropeanOptionArrays("call", underlying=und.seq,
                                 strike=100, dividendYield=0.01,
                                 riskFreeRate=0.03, 
                                 maturity=1, volatility=vol.seq)
   [... more code to plot this ...]	   

and you can look how EuropeanOptionArrays is essentially looping over all
possible vector-form arguments to pass them to the scalar function that
calls the corresponding (closed-form) QuantLib pricer.  

Hope this helps, Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr


From cottrell at wfu.edu  Thu Mar 13 14:27:32 2003
From: cottrell at wfu.edu (Allin Cottrell)
Date: Thu, 13 Mar 2003 08:27:32 -0500 (EST)
Subject: [R] GARCH estimation
Message-ID: <Pine.LNX.4.52.0303130824400.1018@ricardo.ecn.wfu.edu>

Anyone know if there's an R package somewhere that supports estimation
of a linear regression model with GARCH error process?

There's a garch command in the tseries package, but unless I'm missing
something it is restricted to the univariate case, i.e. you can fit a
GARCH model to a single time-series but not estimate a model with
GARCH errors.

-- 
Allin Cottrell
Department of Economics
Wake Forest University, NC


From NIANQING.XIAO at saic.com  Thu Mar 13 15:08:38 2003
From: NIANQING.XIAO at saic.com (Xiao, Nick)
Date: Thu, 13 Mar 2003 09:08:38 -0500
Subject: [R] Independent Components Analysis
Message-ID: <E7A58A017A8B7B4BA9DC772ED12E423B01A55F05@GMTN-ESG-EXS01>

http://cran.us.r-project.org/src/contrib/PACKAGES.html#e1071
http://cran.us.r-project.org/src/contrib/PACKAGES.html#fastICA


-----Original Message-----
From: Barker, Chris [mailto:Barker at medtap.com]
Sent: Wednesday, March 12, 2003 1:05 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Independent Components Analysis


A colleague suggested that some R software was available for estimating
"Independent Components Analysis" (ICA) (... signal separation).
 
If so, I'd appreciate any pointers . 
 
            Chris Barker
   Director of Statistical Research
    MEDTAP International, Inc.
           Redwood City, Ca
 
        www.medtap.com <http://www.medtap.com/> 
 
          650 632 4218

 

This e-mail message and any attachments are confidential and may... [[dropped]]


From ZHONGW2 at wyeth.com  Thu Mar 13 15:07:34 2003
From: ZHONGW2 at wyeth.com (Wenyan Zhong)
Date: Thu, 13 Mar 2003 09:07:34 -0500
Subject: [R] error installing R on linux 8.0
Message-ID: <se704a66.039@gv01a67m>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030313/b4e0d54d/attachment.pl

From tlumley at u.washington.edu  Thu Mar 13 16:18:24 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 13 Mar 2003 07:18:24 -0800 (PST)
Subject: [R] geepack(geese) vs. glmmPQL
In-Reply-To: <JLEPLGAANFCEAEDCAGJNOEIBCEAA.dieter.menne@menne-biomed.de>
Message-ID: <Pine.A41.4.44.0303130715550.73096-100000@homer04.u.washington.edu>

On Thu, 13 Mar 2003, Dieter Menne wrote:

> Dear R-List,
>
> I have a data set (available on request) of observations from
> a 2x2 conditions psychological experiment, with count of
> correct/wrong decisions, and vp as the subject id.
<snip>
>  $ decision: Factor w/ 2 levels "corr","wrong": 1 2 1 2 1 2 1 2 1 2 ...

This is your problem.  geese() requires binary data to be 0,1, not
"corr","wrong"


	-thomas


From meinhardploner at gmx.net  Thu Mar 13 17:00:17 2003
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Thu, 13 Mar 2003 17:00:17 +0100
Subject: [R] solve lagrange
Message-ID: <E25B075C-556C-11D7-8BCF-0003930EA956@gmx.net>

Hi!
Anyone can help me solving a Lagrangian function in R?
Should I use <deriv> and then <optim> by including the
further conditions or is there an other way?
Thanks
Meinhard


From philippe.hupe at wanadoo.fr  Thu Mar 13 17:36:39 2003
From: philippe.hupe at wanadoo.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Thu, 13 Mar 2003 17:36:39 +0100
Subject: [R] Median Regression Model
Message-ID: <3E70B397.8030105@wanadoo.fr>

Hello,


Is there any function to perform median regression model ?

Thanks in advance.


From William.Alpert at barrons.com  Thu Mar 13 17:36:44 2003
From: William.Alpert at barrons.com (Alpert, William)
Date: Thu, 13 Mar 2003 11:36:44 -0500
Subject: [R] Repeated measures 2-way anova -- robustness question
Message-ID: <6CF9C2F2C5B4D51195490002A5644A9608A0AEEA@wfcmxsmb02>

I'm a journalist, wondering what questions to ask about a study that
contrasted the impact on serum cholesterol of two drugs.  This was a
40 dog study: 5 treatment blocks of 4 dogs each, randomized to: a
control block, two blocks at different doses of drug1 and two at
corresponding doses of drug2.  Analysis was 2-factor repeated measures
ANOVA on treatment group and sampling time.  Linear contrast tests
looked at differences between the drugs, and between doses, and found
p<.001 for cholesterol differences between one dosage block of drug1,
the control block and the similarly-dosed block of drug2.

Data on one of the drug blocks was actually just 3 dogs, because one
dropped out.  One critic has also claimed that the population variance
of cholesterol levels in these dogs is so wide as to cast suspicion on
estimates based on the sample variance in these small blocks.

Are there any repeated-measure ANOVA mavins who could suggest whether
the approach is sufficiently robust to violations of assumptions to
preserve the validity of those impressivly low p-values ?

Bill Alpert
william.alpert at barrons.com


From thou_69 at yahoo.com  Thu Mar 13 17:56:48 2003
From: thou_69 at yahoo.com (Tao Hou)
Date: Thu, 13 Mar 2003 08:56:48 -0800 (PST)
Subject: [R] how to install BLAS on Solaris
Message-ID: <20030313165648.60074.qmail@web21413.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030313/c10063ea/attachment.pl

From ripley at stats.ox.ac.uk  Thu Mar 13 18:07:54 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 13 Mar 2003 17:07:54 +0000 (GMT)
Subject: [R] how to install BLAS on Solaris
In-Reply-To: <20030313165648.60074.qmail@web21413.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0303131705120.1240-100000@gannet.stats>

On Thu, 13 Mar 2003, Tao Hou wrote:

> I try to install Matrix package on Solaris 7. but it require BLAS library.
I download BLAS from www.netlib.org. but there is no makefile. Could 
somebody give me some information?

f77 -O2 -c *.f
ar rc libblas.a *.o

will do.  *However* Matrix requires an lapack library, and lapack comes 
with a copy of blas and a Makefile (at least in the version I have)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rossini at blindglobe.net  Thu Mar 13 18:11:01 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu, 13 Mar 2003 09:11:01 -0800
Subject: [R] error installing R on linux 8.0
In-Reply-To: <se704a66.039@gv01a67m> ("Wenyan Zhong"'s message of "Thu, 13
 Mar 2003 09:07:34 -0500")
References: <se704a66.039@gv01a67m>
Message-ID: <874r67nqe2.fsf@jeeves.blindglobe.net>

"Wenyan Zhong" <ZHONGW2 at wyeth.com> writes:

> When installing R on linux 8.0, I got the following error message:


There is no Linux 8.0. 

There is Linux 2.4.20, etc.

Do you mean RedHat?  Suse?  Slackware?  Mandrake (any other
distributions with a version number 8 or higher?).

I know this means you aren't running Debian...

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------------
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(CHANGE: monday/wednesday/friday locations are completely unpredictable.)


From maechler at stat.math.ethz.ch  Thu Mar 13 18:20:19 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 13 Mar 2003 18:20:19 +0100
Subject: [R] Median Regression Model
In-Reply-To: <3E70B397.8030105@wanadoo.fr>
References: <3E70B397.8030105@wanadoo.fr>
Message-ID: <15984.48595.68793.446137@gargle.gargle.HOWL>

>>>>> "Philippe" == Philippe Hup? <philippe.hupe at wanadoo.fr>
>>>>>     on Thu, 13 Mar 2003 17:36:39 +0100 writes:

    Philippe> Hello,
    Philippe> Is there any function to perform median regression model ?

The "quantreg" package has even general quantile regression, not
just the 50% one.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From TyagiAnupam at aol.com  Thu Mar 13 18:28:31 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Thu, 13 Mar 2003 12:28:31 EST
Subject: [R] Median Regression Model
Message-ID: <5f.36771093.2ba219bf@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030313/85dafe89/attachment.pl

From heberto.ghezzo at mcgill.ca  Thu Mar 13 19:21:49 2003
From: heberto.ghezzo at mcgill.ca (R. Heberto Ghezzo)
Date: Thu, 13 Mar 2003 13:21:49 -0500
Subject: [R] RODBC and Excel in Widows
Message-ID: <3E70CC37.2B633888@mcgill.ca>

Hello, I have some problems with RODBC and Excel in Win98
I am using R 1.6.2 and just upgraded RODBC to the last version on CRAN.
I have an Excel file with columns Number, Name, Sex, Age, FEV1 on Sheet
1 and Number, Age, FEV1, Name, Sex on Sheet 2.
Now I open the channel to the file
> chan1 <- odbcConnectExcel("c:/testOdbc.xls")
> tables(chan1)
and the list appears with the 2 tables
> aa -> sqlFetch(chan1,"Sheet1")
and aa has the Number, Name and Sex columns correct but Age and FEV1 are
all NAs
> bb -> sqlfetch(chan1,"Sheet2")
and bb is correct!
So all numeric columns after a column of characters become NAs
Is this an Excel problem or an sql problem.? I did not find anything in
the r-help archives relative to this problem.
Thanks for any help


From MSchwartz at medanalytics.com  Thu Mar 13 19:34:09 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 13 Mar 2003 12:34:09 -0600
Subject: [R] error installing R on linux 8.0
In-Reply-To: <se704a66.039@gv01a67m>
References: <se704a66.039@gv01a67m>
Message-ID: <3E70CF21.8060709@MedAnalytics.com>

Wenyan Zhong wrote:
> Hi there,
> 
> When installing R on linux 8.0, I got the following error message:
> 
> rpm -i /mnt/cdrom/linux/8.x/R-1.6.2-1.i386.rpm
> error: /mnt/cdrom/linux/8.x/R-1.6.2-1.i386.rpm: V3 DSA signature: BAD,
> key ID 97d3544e
> error: /mnt/cdrom/linux/8.x/R-1.6.2-1.i386.rpm cannot be installed
> 
> Any suggestions as what I did wrong?
> 
> Thanks in advance.
> 
> Wenyan


I am going to presume that you mean Red Hat 8.0.

In the readme file that Martyn has on CRAN in the same directory from 
which you would have downloaded the RPM, he indicates that in order to 
check the RPM signature you have to import his public key into the RPM 
database.

The readme URL on CRAN is:

http://cran.r-project.org/bin/linux/redhat/8.x/i386/ReadMe

To quote from the file:

gpg
---
The RPMS are signed with GPG, and you are advised to check the signature
before installing them, for your own security.  You can obtain my public
key which has ID 97D3544E from any key server on pgp.net. Ask me for
my public key fingerprint if you want to be sure.

Note that, in Red Hat 8.0, you must import my public key into the RPM
database (as root) in order to check the GPG signature.  This is a
change from previous releases of Red Hat Linux.  See the man page for rpm.

Here is one way to do it:

gpg --keyserver wwwkeys.eu.pgp.net --recv-key 97d3544e
gpg --output plummer.gpg --armor --export 97d3544e
su
rpm --import plummer.gpg



Copy and paste each one of the above four commands into a console window 
and that should resolve the problem.

Hope that helps.

Regards,

Marc Schwartz


From bates at stat.wisc.edu  Thu Mar 13 21:32:23 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 13 Mar 2003 14:32:23 -0600
Subject: [R] [OT] Dirk, check your email configuration
Message-ID: <6r4r67ovmw.fsf@bates4.stat.wisc.edu>

My apologies for an off-topic post.  I send this message here because
I know that Dirk Eddelbuettel reads this list, hopefully at an address
other than <edd at sonny.eddelbuettel.com>

Dirk: Joey Hess sent a message to debian-devel saying he was getting
bounces from that address and asking for you to check your e-mail
configuration.  I can forward the message to you if you send me an
address that works.


From edd at debian.org  Thu Mar 13 21:52:25 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 13 Mar 2003 14:52:25 -0600
Subject: [R] [OT] Dirk, check your email configuration
In-Reply-To: <6r4r67ovmw.fsf@bates4.stat.wisc.edu>
References: <6r4r67ovmw.fsf@bates4.stat.wisc.edu>
Message-ID: <20030313205225.GB5758@sonny.eddelbuettel.com>

On Thu, Mar 13, 2003 at 02:32:23PM -0600, Douglas Bates wrote:
> My apologies for an off-topic post.  I send this message here because
> I know that Dirk Eddelbuettel reads this list, hopefully at an address
> other than <edd at sonny.eddelbuettel.com>

Sure do. 

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr


From khanspers at gladstone.ucsf.edu  Thu Mar 13 23:11:59 2003
From: khanspers at gladstone.ucsf.edu (Kristina Hanspers)
Date: Thu, 13 Mar 2003 14:11:59 -0800
Subject: [R] memory limit
Message-ID: <003701c2e9ad$91248960$7102280a@khlaptop1>

Hi,

I get an error saying " Cannot allocate vector of size 71289kb". So I tried
to increase memory by memory.limit(size=3000000000), I also tried other
numbers. Each time I get the message NULL and then I still get the same
error as above. I'm using Windows 2000. The system has 1G RAM, and 1.6GHz
processor. I was only running R, and was trying to do use a BioConductor
package. I apparociate your answer. Thanks,

Kristina


From ulrich.pedri at tiscali.it  Thu Mar 13 23:44:26 2003
From: ulrich.pedri at tiscali.it (Ulrich Pedri)
Date: Thu, 13 Mar 2003 23:44:26 +0100
Subject: [R] Looking for GUI
Message-ID: <3E66386D0046C4C1@mail-1.tiscalinet.it> (added by
	postmaster@mail.tiscali.it)

Hi List,

i am locking for a GUI for R. I have a Debian Woody 3.0 and running R 1.5.1. 
In office i am using SPSS 9.0 for several years now after Systat for short 
time and now i would use a statistic software under Linux at home. It seems 
that R could be that what i am looking for, but i have problems to understand 
how it works or better explained i would prefer using a good grafic interface.

Wich one could i try ??

thank you
ULI


From apjaworski at mmm.com  Fri Mar 14 00:00:00 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Thu, 13 Mar 2003 17:00:00 -0600
Subject: [R] small error in regression tests
Message-ID: <OF0DE2B9EB.0B251048-ON86256CE8.007D35FA@mmm.com>

I just r-sync'ed the r-devel version of R-1.7.0 (2003-03-11), compiled it
under RH-8.0 and ran make check.  The reg-tests-2 fails at the very end
with the message stating that "object cement was not found".  It looks like
this piece of the regression test is new to version 1.7.  The the piece of
code generating the error is:

if(require(MASS)) {
    teststep <- function(formula, data)
    {
        d2 <- data
        fit <- lm(formula, data=d2)
        step(fit)
    }
    teststep(formula(y ~ .), cement)
    detach("package:MASS")
}

It seems that it requires
        data(cement)
statement before the call to teststep.


Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


From laurent at cbs.dtu.dk  Fri Mar 14 03:01:04 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Fri, 14 Mar 2003 03:01:04 +0100
Subject: [R] memory limit
In-Reply-To: <003701c2e9ad$91248960$7102280a@khlaptop1>
References: <003701c2e9ad$91248960$7102280a@khlaptop1>
Message-ID: <20030314020104.GB2498266@genome.cbs.dtu.dk>

On Thu, Mar 13, 2003 at 02:11:59PM -0800, Kristina Hanspers wrote:
> Hi,
> 
> I get an error saying " Cannot allocate vector of size 71289kb". So I tried
> to increase memory by memory.limit(size=3000000000), I also tried other
> numbers. Each time I get the message NULL and then I still get the same
> error as above. I'm using Windows 2000. The system has 1G RAM, and 1.6GHz
> processor. I was only running R, and was trying to do use a BioConductor
> package. I apparociate your answer. Thanks,
> 
> Kristina
> 

It could truly mean that the memory is exhausted. I cannot think
of doing any diagnosis before knowing more about what you are
trying to do (which package in BioC are you using, what kind of
dataset are you working on, what is it's size, etc...)


Hopin' it helps,



Laurent


-- 
--------------------------------------------------------------
currently at the National Yang-Ming University in Taipei, Taiwan
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent


From wvedder at houston.rr.com  Fri Mar 14 03:26:52 2003
From: wvedder at houston.rr.com (William Vedder)
Date: Thu, 13 Mar 2003 20:26:52 -0600
Subject: [R] R "FinMetrics" Package Available?
Message-ID: <000901c2e9d1$2d1235c0$b600a8c0@houston.rr.com>

Hello List,

I've done some cursory searching but (so far) have struck out. Does
anyone know if the R version of the S+ FinMetrics package is available?

Best,
Bill Vedder


From rossini at blindglobe.net  Fri Mar 14 04:39:38 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu, 13 Mar 2003 19:39:38 -0800
Subject: [R] R "FinMetrics" Package Available?
In-Reply-To: <000901c2e9d1$2d1235c0$b600a8c0@houston.rr.com> ("William
 Vedder"'s message of "Thu, 13 Mar 2003 20:26:52 -0600")
References: <000901c2e9d1$2d1235c0$b600a8c0@houston.rr.com>
Message-ID: <87vfymaa6d.fsf@jeeves.blindglobe.net>

"William Vedder" <wvedder at houston.rr.com> writes:

> I've done some cursory searching but (so far) have struck out. Does
> anyone know if the R version of the S+ FinMetrics package is available?

"the R version"? 

If you can make the case to Insightful that there is a market, perhaps
they'll sell a version.

best
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------------
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(CHANGE: monday/wednesday/friday locations are completely unpredictable.)


From kjetil at entelnet.bo  Fri Mar 14 05:09:14 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri, 14 Mar 2003 00:09:14 -0400
Subject: [R] R "FinMetrics" Package Available?
In-Reply-To: <000901c2e9d1$2d1235c0$b600a8c0@houston.rr.com>
Message-ID: <3E711DAA.17711.1222306@localhost>

On 13 Mar 2003 at 20:26, William Vedder wrote:

There is no R version of the S+FinMetrics  package, and there would
be quite difficult to make one, as the c code underlying it 
is closed source. The DLL's for the ox version od ssfPack
(which underlies S+FinMetrics) is available, but uses lots of
calls to internal ox functions.

Kjetil Halvorsen

> Hello List,
> 
> I've done some cursory searching but (so far) have struck out. Does
> anyone know if the R version of the S+ FinMetrics package is available?
> 
> Best,
> Bill Vedder
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From umalvarez at fata.unam.mx  Fri Mar 14 05:17:02 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Thu, 13 Mar 2003 22:17:02 -0600 (CST)
Subject: [R] error installing R on linux 8.0
In-Reply-To: <se704a66.039@gv01a67m>
Message-ID: <Pine.LNX.4.44.0303132212130.16705-100000@fata.unam.mx>

Hi:

You are not given enough info to help you. It looks like your rmp file is 
somehow corrupted.

I haven't try in RH 8.0, but anyway try 

rmp -ivh route/to/your/R-1.6.2-1.i386.rpm

Or if you have an older version of R already running:

rpm -uvh route/to/your/R-1.6.2-1.i386.rpm

Note that you need administrator rights.


On Thu, 13 Mar 2003, Wenyan Zhong wrote:

> Hi there,
> 
> When installing R on linux 8.0, I got the following error message:
> 
> rpm -i /mnt/cdrom/linux/8.x/R-1.6.2-1.i386.rpm
> error: /mnt/cdrom/linux/8.x/R-1.6.2-1.i386.rpm: V3 DSA signature: BAD,
> key ID 97d3544e
> error: /mnt/cdrom/linux/8.x/R-1.6.2-1.i386.rpm cannot be installed
> 
> Any suggestions as what I did wrong?
> 
> Thanks in advance.
> 
> Wenyan
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx


From umalvarez at fata.unam.mx  Fri Mar 14 05:44:43 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Thu, 13 Mar 2003 22:44:43 -0600 (CST)
Subject: [R] Looking for GUI
In-Reply-To: <3E66386D0046C4C1@mail-1.tiscalinet.it> (added by
	postmaster@mail.tiscali.it)
Message-ID: <Pine.LNX.4.44.0303132237380.16807-100000@fata.unam.mx>

Hi:

I?m afraid that R doesn't have a 'good graphic interface', instead has a 
powerful command console. But if you have Gnome installed and you like to 
see a more frienly environment type at a terminal:

'R --gui=gnome' or 'R -g gnome'

Take a look at the R-intro and the R-FAQ.

Regards.

On Thu, 13 Mar 2003, Ulrich Pedri wrote:

> Hi List,
> 
> i am locking for a GUI for R. I have a Debian Woody 3.0 and running R 1.5.1. 
> In office i am using SPSS 9.0 for several years now after Systat for short 
> time and now i would use a statistic software under Linux at home. It seems 
> that R could be that what i am looking for, but i have problems to understand 
> how it works or better explained i would prefer using a good grafic interface.
> 
> Wich one could i try ??
> 
> thank you
> ULI
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx


From edd at debian.org  Fri Mar 14 06:15:55 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 13 Mar 2003 23:15:55 -0600
Subject: [R] R "FinMetrics" Package Available?
In-Reply-To: <3E711DAA.17711.1222306@localhost>
References: <000901c2e9d1$2d1235c0$b600a8c0@houston.rr.com>
	<3E711DAA.17711.1222306@localhost>
Message-ID: <20030314051555.GA17230@sonny.eddelbuettel.com>

On Fri, Mar 14, 2003 at 12:09:14AM -0400, kjetil brinchmann halvorsen wrote:
> On 13 Mar 2003 at 20:26, William Vedder wrote:
> 
> There is no R version of the S+FinMetrics  package, and there would
> be quite difficult to make one, as the c code underlying it 
> is closed source. The DLL's for the ox version od ssfPack
> (which underlies S+FinMetrics) is available, but uses lots of
> calls to internal ox functions.

AFAIK parts of that code have been used by BDR in the rewrite of the ts
package that went into R 1.5.0 -- that hence R has essentially the same code
by Koopman in StructTS, KalmanLike, tsSmooth, ...

Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr


From gisar at nus.edu.sg  Fri Mar 14 08:22:37 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Fri, 14 Mar 2003 15:22:37 +0800
Subject: [R] Looking for GUI
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053F69@MBXSRV03.stf.nus.edu.sg>

If you have cash to spare, try the commercial version S-Plus.

-----Original Message-----
From: Ulrich Pedri [mailto:ulrich.pedri at tiscali.it] 
Sent: Friday, March 14, 2003 6:44 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Looking for GUI


Hi List,

i am locking for a GUI for R. I have a Debian Woody 3.0 and running R
1.5.1. 
In office i am using SPSS 9.0 for several years now after Systat for
short 
time and now i would use a statistic software under Linux at home. It
seems 
that R could be that what i am looking for, but i have problems to
understand 
how it works or better explained i would prefer using a good grafic
interface.

Wich one could i try ??

thank you
ULI

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Fri Mar 14 09:05:32 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 14 Mar 2003 08:05:32 +0000 (GMT)
Subject: [R] R "FinMetrics" Package Available?
In-Reply-To: <20030314051555.GA17230@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.44.0303140755510.2783-100000@gannet.stats>

On Thu, 13 Mar 2003, Dirk Eddelbuettel wrote:

> On Fri, Mar 14, 2003 at 12:09:14AM -0400, kjetil brinchmann halvorsen wrote:
> > On 13 Mar 2003 at 20:26, William Vedder wrote:
> > 
> > There is no R version of the S+FinMetrics  package, and there would
> > be quite difficult to make one, as the c code underlying it 
> > is closed source. The DLL's for the ox version od ssfPack
> > (which underlies S+FinMetrics) is available, but uses lots of
> > calls to internal ox functions.
> 
> AFAIK parts of that code have been used by BDR in the rewrite of the ts
> package that went into R 1.5.0 -- that hence R has essentially the same code
> by Koopman in StructTS, KalmanLike, tsSmooth, ...

No.  SSFPack is closed source, and all the code Dirk is talking about was 
written from scratch by me, to avoid any licencing problems.

There is a lot more to S+FinMetrics than the code based on SSFPack in any 
case.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From otoomet at econ.dk  Fri Mar 14 09:21:55 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Fri, 14 Mar 2003 09:21:55 +0100
Subject: [R] memory limit
In-Reply-To: <003701c2e9ad$91248960$7102280a@khlaptop1>
	(khanspers@gladstone.ucsf.edu)
References: <003701c2e9ad$91248960$7102280a@khlaptop1>
Message-ID: <200303140821.h2E8LtP11257@punik.econ.au.dk>

Dear Kristina,

There are some general suggestions one should always try when having
problems with memory.  Have you tried to:

1) check how much memory R really takes.  Look at gc() and
   object.size(), and on system tools which tell how much memory a
   process is taking (like top on Unix).  Try mem.limits() which tells
   if there are any limits currently in effect.

2) run your analysis on a subset of your data.  Perhaps what you
   really want to do is something less complex?  You get an idea how
   much the memory comnsumption depends on the size of your data.

3) It may well be the case that the memory on your computer is getting
   fragmented.  Try another OS (unix/linux should be better), or
   reboot your computer and try again.

Perhaps it helps.

Ott

 | From: "Kristina Hanspers" <khanspers at gladstone.ucsf.edu>
 | Date: Thu, 13 Mar 2003 14:11:59 -0800
 | 
 | Hi,
 | 
 | I get an error saying " Cannot allocate vector of size 71289kb". So I tried
 | to increase memory by memory.limit(size=3000000000), I also tried other
 | numbers. Each time I get the message NULL and then I still get the same
 | error as above. I'm using Windows 2000. The system has 1G RAM, and 1.6GHz
 | processor. I was only running R, and was trying to do use a BioConductor
 | package. I apparociate your answer. Thanks,
 | 
 | Kristina


From philippe.hupe at wanadoo.fr  Fri Mar 14 09:32:05 2003
From: philippe.hupe at wanadoo.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Fri, 14 Mar 2003 09:32:05 +0100
Subject: [R] iterative reweighting in LOESS function
Message-ID: <3E719385.70602@wanadoo.fr>

Hello,

Is there an iterative reweighting option in LOESS function from modreg 
package to perform robust fitting in the presence of outliers in the data ?

Thanks in advance.

Philippe.


From ripley at stats.ox.ac.uk  Fri Mar 14 09:42:31 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 14 Mar 2003 08:42:31 +0000 (GMT)
Subject: [R] iterative reweighting in LOESS function
In-Reply-To: <3E719385.70602@wanadoo.fr>
Message-ID: <Pine.LNX.4.44.0303140839180.2783-100000@gannet.stats>

On Fri, 14 Mar 2003, Philippe Hup? wrote:

> Is there an iterative reweighting option in LOESS function from modreg 
> package to perform robust fitting in the presence of outliers in the data ?

See the help page, the reference on the help page and the source code.

I guess the answer is `not quite as you describe', but there are
precise statements in the resources of my previous paragraph.  Did you 
check the help page?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gisar at nus.edu.sg  Fri Mar 14 09:53:52 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Fri, 14 Mar 2003 16:53:52 +0800
Subject: [R] Execution halts after some time. 
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F227@MBXSRV03.stf.nus.edu.sg>

Dear all,

I fit independent GLMs for a 2x2 factorial problem on the data matrix of
size 9500 x 12 (genes x arrays) and get 9500 observed t-values using the
apply() function. Now, I wish to get the permutated p-values. Therefore
I random sample the class labels and perform the glm fitting to get the
t-values from which I can get the p-values. This is done using a for()
loop. Is there a more efficient way to do this. Each loop currently
takes 5 minutes approximately. 

More importantly I need to repeat this at least 1000 times which
requires 3-4 days but the process halts after some time. 

To isolate the problem, I rewrote the script with 10 chunks of 100
loops. The first 2 chunk runs fine and the results are ok but on the
third (sometimes fourth, fifth or sixth) chunk, I get the following
error message:

Error in FUN(newX[, i], ...) : subscript out of bounds
Execution halted

Does R have a "time out" when I use 'R --no-save < script.file' on the
UNIX platform ? 

I have checked with my system administrator and according to him there
is no upper limit to process time. I have explicitly removed every
unneccassary object at the end of each loop to keep the reserve memory.
I have tried the same on Windows and different chunks sizes and
different machines. Sometime it runs fine to completion and when it dies
it does not appear systematic.

Now I am reduced to writing scripts with chunks of 100 loops and then
collecting the chunks that were successful. I have to repeat the 1000
loops for many many different experiments and it is getting very
tedious. 

If you have any idea or had similar experience, please let me know.
Thank you.


Regards, Adai.


From philippe.hupe at wanadoo.fr  Fri Mar 14 09:59:14 2003
From: philippe.hupe at wanadoo.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Fri, 14 Mar 2003 09:59:14 +0100
Subject: [R] iterative reweighting in LOESS function
Message-ID: <3E7199E2.80405@wanadoo.fr>

I have just found the answer : iterative reweighting can be set through 
loess.control function via iterations option.


From ripley at stats.ox.ac.uk  Fri Mar 14 10:10:06 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 14 Mar 2003 09:10:06 +0000 (GMT)
Subject: [R] iterative reweighting in LOESS function
In-Reply-To: <3E7199E2.80405@wanadoo.fr>
Message-ID: <Pine.LNX.4.44.0303140907520.2783-100000@gannet.stats>

On Fri, 14 Mar 2003, Philippe Hup? wrote:

> I have just found the answer : iterative reweighting can be set through 
> loess.control function via iterations option.

No so: it's through the family argument to loess: `iterations' sets how
many iterations *when* robust fitting is selected.

This is both on the help page and in the reference there.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wolski at molgen.mpg.de  Fri Mar 14 11:15:26 2003
From: wolski at molgen.mpg.de (wolski)
Date: Fri, 14 Mar 2003 11:15:26 +0100
Subject: [R] Two graphs of different sizes on one devise. How to?
Message-ID: <200303141115260271.0AE7D56A@harry.molgen.mpg.de>

I am trying to plot two graphics with different sizes to one devise.

par(mfrow=c(1,2))
# is set the size for the first graphic
par(fig=c(0,7,0,10)/10)
#and plot it
plot(1,1)
#then i set the size 
par(fig=c(7,10,0,10)/10)

#and plot the second one
plot(2,2)


Unfortunately when i plot figure two figure 1 disapear.
How to avoid these?

/Eryk.


From plummer at iarc.fr  Fri Mar 14 11:32:58 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: 14 Mar 2003 11:32:58 +0100
Subject: [R] error installing R on linux 8.0
In-Reply-To: <3E70CF21.8060709@MedAnalytics.com>
References: <se704a66.039@gv01a67m>  <3E70CF21.8060709@MedAnalytics.com>
Message-ID: <1047637979.1027.12.camel@xena>

The problem in this case is that the RPM file is corrupted.  Try
downloading a fresh copy from CRAN.

To check if the package has been corrupted type:
rpm -K --nosignature /mnt/cdrom/linux/8.x/R-1.6.2-1.i386.rpm

It is possible to install a gpg-signed RPM package without importing the
corresponding public key into the RPM database.

Martyn

On Thu, 2003-03-13 at 19:34, Marc Schwartz wrote:
> Wenyan Zhong wrote:
> > Hi there,
> > 
> > When installing R on linux 8.0, I got the following error message:
> > 
> > rpm -i /mnt/cdrom/linux/8.x/R-1.6.2-1.i386.rpm
> > error: /mnt/cdrom/linux/8.x/R-1.6.2-1.i386.rpm: V3 DSA signature: BAD,
> > key ID 97d3544e
> > error: /mnt/cdrom/linux/8.x/R-1.6.2-1.i386.rpm cannot be installed
> > 
> > Any suggestions as what I did wrong?
> > 
> > Thanks in advance.
> > 
> > Wenyan
> 
> 
> I am going to presume that you mean Red Hat 8.0.
> 
> In the readme file that Martyn has on CRAN in the same directory from 
> which you would have downloaded the RPM, he indicates that in order to 
> check the RPM signature you have to import his public key into the RPM 
> database.
> 
> The readme URL on CRAN is:
> 
> http://cran.r-project.org/bin/linux/redhat/8.x/i386/ReadMe
> 
> To quote from the file:
> 
> gpg
> ---
> The RPMS are signed with GPG, and you are advised to check the signature
> before installing them, for your own security.  You can obtain my public
> key which has ID 97D3544E from any key server on pgp.net. Ask me for
> my public key fingerprint if you want to be sure.
> 
> Note that, in Red Hat 8.0, you must import my public key into the RPM
> database (as root) in order to check the GPG signature.  This is a
> change from previous releases of Red Hat Linux.  See the man page for rpm.
> 
> Here is one way to do it:
> 
> gpg --keyserver wwwkeys.eu.pgp.net --recv-key 97d3544e
> gpg --output plummer.gpg --armor --export 97d3544e
> su
> rpm --import plummer.gpg
> 
> 
> 
> Copy and paste each one of the above four commands into a console window 
> and that should resolve the problem.
> 
> Hope that helps.
> 
> Regards,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From ripley at stats.ox.ac.uk  Fri Mar 14 11:23:32 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 14 Mar 2003 10:23:32 +0000 (GMT)
Subject: [R] Two graphs of different sizes on one devise. How to?
In-Reply-To: <200303141115260271.0AE7D56A@harry.molgen.mpg.de>
Message-ID: <Pine.LNX.4.44.0303141020410.2951-100000@gannet.stats>

On Fri, 14 Mar 2003, wolski wrote:

> I am trying to plot two graphics with different sizes to one devise.
> 
> par(mfrow=c(1,2))
> # is set the size for the first graphic
> par(fig=c(0,7,0,10)/10)
> #and plot it
> plot(1,1)
> #then i set the size 
> par(fig=c(7,10,0,10)/10)
> 
> #and plot the second one
> plot(2,2)
> 
> 
> Unfortunately when i plot figure two figure 1 disapear.
> How to avoid these?

?par, look at `new'.

Setting fig unsets the mfrow call.

As far as I recall this is covered in some detail in `An Introduction to 
R'.  Alternatives are to use the layout facilities (?layout) or 
split.screen.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rdiaz at cnio.es  Fri Mar 14 11:05:41 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Fri, 14 Mar 2003 11:05:41 +0100
Subject: [R] gls with "crossed heteroscedasticity"
Message-ID: <200303141105.41722.rdiaz@cnio.es>

Dear All,

I am using the function gls (in the nlme package) and I would like to fit a 
heteroscedastic model, with different variances for each of the levels of two 
stratification variables.

In p. 210 of Pinheiro & Bates ("Mixed effects models in S and S-Plus", 2000, 
Springer), the authors show the use of the "*" operator. However, that is not 
what I want, because it fits a different variance parameter to each 
combination of the two levels. What I would like is more along the ways of p. 
163 and ff., where they fit models with crossed random effects.

I think this can be achieved using varComb. If we have two strata, say ID1 and 
ID2, we can do:

gls(my.formula, 
    weights = varComb( varIdent(form = ~ 1 | ID), varIdent(form = ~ 1 | ID2)))

This seems to work (and to produce reasonable results) but I am not sure if it 
is right, or I am doing something dumb. 

Best,


-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
http://bioinfo.cnio.es/~rdiaz


From vito.muggeo at giustizia.it  Fri Mar 14 11:44:10 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Fri, 14 Mar 2003 11:44:10 +0100
Subject: [R] Execution halts after some time. 
References: <024D6AEFCB92CB47BA1085751D184BB80105F227@MBXSRV03.stf.nus.edu.sg>
Message-ID: <00a401c2ea16$b151bfa0$5c13070a@it.giustizia.it>

> Dear all,
>
> I fit independent GLMs for a 2x2 factorial problem on the data matrix of
> size 9500 x 12 (genes x arrays) and get 9500 observed t-values using the
> apply() function. Now, I wish to get the permutated p-values. Therefore
> I random sample the class labels and perform the glm fitting to get the
> t-values from which I can get the p-values. This is done using a for()
> loop. Is there a more efficient way to do this. Each loop currently
> takes 5 minutes approximately.
>
Do you use glm.fit()? by calling directly glm.fit() is faster than calling
glm(); glm() itself uses glm.fit(); see ?glm.fit and you can extract the
t-values from the returned object.


I'm not able to tell something about your next questions, sorry.

best,
vito

> More importantly I need to repeat this at least 1000 times which
> requires 3-4 days but the process halts after some time.
>
> To isolate the problem, I rewrote the script with 10 chunks of 100
> loops. The first 2 chunk runs fine and the results are ok but on the
> third (sometimes fourth, fifth or sixth) chunk, I get the following
> error message:
>
> Error in FUN(newX[, i], ...) : subscript out of bounds
> Execution halted
>
> Does R have a "time out" when I use 'R --no-save < script.file' on the
> UNIX platform ?
>
> I have checked with my system administrator and according to him there
> is no upper limit to process time. I have explicitly removed every
> unneccassary object at the end of each loop to keep the reserve memory.
> I have tried the same on Windows and different chunks sizes and
> different machines. Sometime it runs fine to completion and when it dies
> it does not appear systematic.
>
> Now I am reduced to writing scripts with chunks of 100 loops and then
> collecting the chunks that were successful. I have to repeat the 1000
> loops for many many different experiments and it is getting very
> tedious.
>
> If you have any idea or had similar experience, please let me know.
> Thank you.
>
>
> Regards, Adai.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From adrian.trapletti at lmttrading.com  Fri Mar 14 12:27:47 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Fri, 14 Mar 2003 12:27:47 +0100
Subject: [R] GARCH estimation
References: <200303141104.h2EB4QfV023509@hypatia.math.ethz.ch>
Message-ID: <3E71BCB3.DD0AE1FF@lmttrading.com>

> Subject: [R] GARCH estimation
> Date: Thu, 13 Mar 2003 08:27:32 -0500 (EST)
> From: Allin Cottrell <cottrell at wfu.edu>
> To: r-help at stat.math.ethz.ch
>
> Anyone know if there's an R package somewhere that supports estimation
> of a linear regression model with GARCH error process?

Up to my knowledge: no.

> There's a garch command in the tseries package, but unless I'm missing
> something it is restricted to the univariate case, i.e. you can fit a
> GARCH model to a single time-series but not estimate a model with
> GARCH errors.

Right.

> --
> Allin Cottrell
> Department of Economics
> Wake Forest University, NC
>

best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com


From juli at ceam.es  Fri Mar 14 13:43:56 2003
From: juli at ceam.es (juli g. pausas)
Date: Fri, 14 Mar 2003 13:43:56 +0100
Subject: [R] any european maps
Message-ID: <3E71CE8C.2040107@ceam.es>

Dear all,
I've seen that there are some maps, or at least costlines in R. The oz 
package is the map of Autralia and in the fields package there is a US 
map and a world map. This world map allows to select smaller sections 
such Europe:

library(fields)
world(xlim=c(-10,18),ylim=c(36,60))

However, at this scale the map is quite crude (and several important big 
islands are messing).
My question is: is there any more accurate map of Europe available out 
there?
(I'm specially interested in the Iberian Peninsula)

Thanks in advance

Juli


From mathieu.roelants at vub.ac.be  Fri Mar 14 14:10:38 2003
From: mathieu.roelants at vub.ac.be (Mathieu Roelants)
Date: Fri, 14 Mar 2003 14:10:38 +0100
Subject: [R] any european maps
References: <3E71CE8C.2040107@ceam.es>
Message-ID: <005301c2ea2b$1bff3a80$6710210a@kuleuven.ac.be>

You can try RarcInfo, which has it's homepage at
http://matheron.estadi.uv.es/~virgil/Rpackages/RArcInfo/index.shtml.
there is a link to free data in the section "related resources".

regards

Mathieu Roelants

Mathieu Roelants  -  Project Vlaamse Groeicurven
Laboratory of Anthropogentics  University of Brussels Pleinlaan 2, B-1050
Brussels, Belgium
Tel./Fax +32 (0)2 629.34.07  mathieu.roelants at vub.ac.be
----- Original Message -----
From: "juli g. pausas" <juli at ceam.es>
To: "r-help" <r-help at stat.math.ethz.ch>
Sent: Friday, March 14, 2003 1:43 PM
Subject: [R] any european maps


> Dear all,
> I've seen that there are some maps, or at least costlines in R. The oz
> package is the map of Autralia and in the fields package there is a US
> map and a world map. This world map allows to select smaller sections
> such Europe:
>
> library(fields)
> world(xlim=c(-10,18),ylim=c(36,60))
>
> However, at this scale the map is quite crude (and several important big
> islands are messing).
> My question is: is there any more accurate map of Europe available out
> there?
> (I'm specially interested in the Iberian Peninsula)
>
> Thanks in advance
>
> Juli
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From mschwartz at medanalytics.com  Fri Mar 14 14:59:38 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 14 Mar 2003 07:59:38 -0600
Subject: [R] error installing R on linux 8.0
In-Reply-To: <1047637979.1027.12.camel@xena>
Message-ID: <009a01c2ea31$f4be6250$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Martyn Plummer
>Sent: Friday, March 14, 2003 4:33 AM
>To: MSchwartz at medanalytics.com
>Cc: r-help at stat.math.ethz.ch; Wenyan Zhong
>Subject: Re: [R] error installing R on linux 8.0
>
>
>The problem in this case is that the RPM file is corrupted.  
>Try downloading a fresh copy from CRAN.
>
>To check if the package has been corrupted type:
>rpm -K --nosignature /mnt/cdrom/linux/8.x/R-1.6.2-1.i386.rpm
>
>It is possible to install a gpg-signed RPM package without 
>importing the corresponding public key into the RPM database.
>
>Martyn


Martyn is correct of course. I had not considered a corrupted RPM in
my reply, but clearly should have.

One other thought to add, which is that it may not be the downloaded
RPM file that is corrupted, but the copy that was burned to the CD.  I
have seen a fair number of posts on RH usenet groups where folks have
downloaded the RH ISO files without problems (including the MD5
checksums being correct). However, the media check during installation
indicated a problem with the image on the CD, which could be the
result of a poor burn or a problem with the media itself.

Thus, you might want to also try a different CD as part of the
process.

Martyn, I am wondering if it would be reasonable to include a
md5summ.txt file along with the RPMs to enable a check to be made of
the downloaded (and possibly burned) RPM file against a known value
that you generate?

Best regards,

Marc Schwartz


From ZHONGW2 at wyeth.com  Fri Mar 14 15:14:59 2003
From: ZHONGW2 at wyeth.com (Wenyan Zhong)
Date: Fri, 14 Mar 2003 09:14:59 -0500
Subject: [R] error installing R on linux 8.0
Message-ID: <se719da2.002@gvn002m>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030314/3178315b/attachment.pl

From wegmann at biozentrum.uni-wuerzburg.de  Fri Mar 14 15:19:04 2003
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Fri, 14 Mar 2003 15:19:04 +0100
Subject: [R] grasper installation
Message-ID: <3E71E4D8.60B3FE6@biozentrum.uni-wuerzburg.de>

Hello R user,

I downloaded grasper_0.3-2.tar.gz and installed it as described.
$ su
$ R CMD INSTALL grasper_0.3-2.tar.gz
$ R
that seems to work, but

> grasp.GUI()
doesn't work. I read the note, that graspeR need mgcv (downloaded),
MASS, modreg and tcktk . I haven't found the last 3 packetages in the
Suse 8.1 contrib list. Where can I find them? Or what could be the
problem?

thanks in advance, cheers Martin

--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de

-------------- next part --------------
A non-text attachment was scrubbed...
Name: wegmann.vcf
Type: text/x-vcard
Size: 329 bytes
Desc: Card for Martin Wegmann
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030314/4983ac8e/wegmann.vcf

From ligges at statistik.uni-dortmund.de  Fri Mar 14 15:38:19 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 14 Mar 2003 15:38:19 +0100
Subject: [R] grasper installation
In-Reply-To: <3E71E4D8.60B3FE6@biozentrum.uni-wuerzburg.de>
References: <3E71E4D8.60B3FE6@biozentrum.uni-wuerzburg.de>
Message-ID: <3E71E95B.8050201@statistik.uni-dortmund.de>

Martin Wegmann wrote:
> Hello R user,
> 
> I downloaded grasper_0.3-2.tar.gz and installed it as described.
> $ su
> $ R CMD INSTALL grasper_0.3-2.tar.gz
> $ R
> that seems to work, but
> 
> 
>>grasp.GUI()
> 
> doesn't work. I read the note, that graspeR need mgcv (downloaded),
> MASS, modreg and tcktk . I haven't found the last 3 packetages in the
> Suse 8.1 contrib list. Where can I find them? Or what could be the
> problem?
> 
> thanks in advance, cheers Martin

MASS is in the VR package bundle, which comes with the recommended 
packages. modreg and *tcltk* are included in R's standard installation.
Do you have (the appropriate version of) tcltk installed on your machine?

Uwe Ligges


From ripley at stats.ox.ac.uk  Fri Mar 14 15:41:56 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 14 Mar 2003 14:41:56 +0000 (GMT)
Subject: [R] grasper installation
In-Reply-To: <3E71E4D8.60B3FE6@biozentrum.uni-wuerzburg.de>
Message-ID: <Pine.LNX.4.44.0303141433450.28433-100000@gannet.stats>

MASS is part of VR, and all of VR, mgcv, modreg and tcltk (sic) are 
part of all of every R installation (or should be).

However, tcltk will not work unless you have Tcl/Tk installed.

On Fri, 14 Mar 2003, Martin Wegmann wrote:

> Hello R user,
> 
> I downloaded grasper_0.3-2.tar.gz and installed it as described.
> $ su
> $ R CMD INSTALL grasper_0.3-2.tar.gz
> $ R
> that seems to work, but

You did actually have

library(grasper)

here, didn't you?

> > grasp.GUI()
> doesn't work. I read the note, that graspeR need mgcv (downloaded),
> MASS, modreg and tcktk . I haven't found the last 3 packetages in the
> Suse 8.1 contrib list. Where can I find them? Or what could be the
> problem?

So should we guess that you are using SuSe Linux?  What version of R?
And does `doen't work' actually mean? 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From temiz at deprem.gov.tr  Fri Mar 14 15:48:37 2003
From: temiz at deprem.gov.tr (orkun)
Date: Fri, 14 Mar 2003 16:48:37 +0200
Subject: [R] logistic regression 
Message-ID: <3E71EBC5.3000400@deprem.gov.tr>

Hello
1*
I need to use logistic regression. But
my data file is very huge( appx. 4 million line).
R doesn't handle such a file.
What can I do ?
------------------------
2*
So, I thought whether I could perform sta. analyses on summarised
data (count of yes/no values) of the huge file. Normally, summarised
data file short and R could handle it.
Then I used this command.
 > lo <-glm(hey.count~as.factor(jeo)+as.factor(eg)+as.factor(kon)+
as.factor(yol)+ as.factor(aks)+as.factor(fay),family=poisson,data=dt2)

as you see I used count value of yes/no data as independent data.

Is it good idea to use this method instead of binomial logistic regression ?

what do you suggest more ?

thanks in advance

-- 
Ahmet Temiz
Geological Engineer
General Directorate
of Disaster Affairs
TURKEY



______________________________________
Scanned and protected by Inflex
http://pldaniels.com/inflex

______________________________________
The views and opinions expressed in this e-mail message are the sender's own
and do not necessarily represent the views and the opinions of Earthquake Research Dept.
of General Directorate of Disaster Affairs.

Bu e-postadaki fikir ve gorusler gonderenin sahsina ait olup, yasal olarak T.C.
B.I.B. Afet Isleri Gn.Mud. Deprem Arastirma Dairesi'ni baglayici nitelikte degildir.


From wegmann at biozentrum.uni-wuerzburg.de  Fri Mar 14 16:08:48 2003
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Fri, 14 Mar 2003 16:08:48 +0100
Subject: [R] grasper installation
References: <Pine.LNX.4.44.0303141433450.28433-100000@gannet.stats>
Message-ID: <3E71F080.89FC9047@biozentrum.uni-wuerzburg.de>

Hello,

I have Tcl/tk installed but it is version 8.4. I already have a problem
with NVIZ in GRASS which requires 8.3 and doesn't work now. Same problem
with grasp?

doesn't work means that R responds after I typed in
> grasp.GUI()
command not recognized (or similar prompt)

thanks martin

ripley at stats.ox.ac.uk wrote:

> MASS is part of VR, and all of VR, mgcv, modreg and tcltk (sic) are
> part of all of every R installation (or should be).
>
> However, tcltk will not work unless you have Tcl/Tk installed.
>
> On Fri, 14 Mar 2003, Martin Wegmann wrote:
>
> > Hello R user,
> >
> > I downloaded grasper_0.3-2.tar.gz and installed it as described.
> > $ su
> > $ R CMD INSTALL grasper_0.3-2.tar.gz
> > $ R
> > that seems to work, but
>
> You did actually have
>
> library(grasper)
>
> here, didn't you?
>
> > > grasp.GUI()
> > doesn't work. I read the note, that graspeR need mgcv (downloaded),
> > MASS, modreg and tcktk . I haven't found the last 3 packetages in the
> > Suse 8.1 contrib list. Where can I find them? Or what could be the
> > problem?
>
> So should we guess that you are using SuSe Linux?  What version of R?
> And does `doen't work' actually mean?
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de

-------------- next part --------------
A non-text attachment was scrubbed...
Name: wegmann.vcf
Type: text/x-vcard
Size: 329 bytes
Desc: Card for Martin Wegmann
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030314/9e7b9333/wegmann.vcf

From jerosenb at hcs.harvard.edu  Fri Mar 14 16:09:00 2003
From: jerosenb at hcs.harvard.edu (janet rosenbaum)
Date: Fri, 14 Mar 2003 10:09:00 -0500 (EST)
Subject: [R] speedier rendering
In-Reply-To: <3E71E95B.8050201@statistik.uni-dortmund.de> from "Uwe Ligges" at
	Mar 14, 2003 03:38:19 PM
Message-ID: <200303141509.h2EF903r015915@hcs.harvard.edu>


Hi.  

We've written a GUI for R.  Under linux and Macintosh, it looks good, but 
under Windows, the rendering is unbearably slow.  
Can we do anything to speed it up?  
Is it possible to compile our program, for instance?

If not, I have a second question:
The buttons on our GUI move over whenever an operation is done, and 
that is what makes the rendering visible.  The buttons only move under
Windows, though.  On Mac and Linux, they don't move at all.
Has anyone else experienced this?
Is it possible to make the buttons stay put?  

Thanks so much,

Janet


From ripley at stats.ox.ac.uk  Fri Mar 14 16:11:13 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 14 Mar 2003 15:11:13 +0000 (GMT)
Subject: [R] logistic regression 
In-Reply-To: <3E71EBC5.3000400@deprem.gov.tr>
Message-ID: <Pine.LNX.4.44.0303141506490.9859-100000@gannet.stats>

On Fri, 14 Mar 2003, orkun wrote:

> 1*
> I need to use logistic regression. But
> my data file is very huge( appx. 4 million line).
> R doesn't handle such a file.
> What can I do ?

R does handle such files (which are tiny by data-mining standards): you
just need to put 1GB or 2GB of memory in your computer.

> ------------------------
> 2*
> So, I thought whether I could perform sta. analyses on summarised
> data (count of yes/no values) of the huge file. Normally, summarised
> data file short and R could handle it.
> Then I used this command.
>  > lo <-glm(hey.count~as.factor(jeo)+as.factor(eg)+as.factor(kon)+
> as.factor(yol)+ as.factor(aks)+as.factor(fay),family=poisson,data=dt2)
> 
> as you see I used count value of yes/no data as independent data.
> 
> Is it good idea to use this method instead of binomial logistic regression ?

No, but it would be a good idea to use binomial logistic regression (and 
not Bernoulli logistic regression).  That is, to collapse the data to 
success/failure counts over the cross-classification of the factors,
and use family=binomial.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jerosenb at hcs.harvard.edu  Fri Mar 14 16:12:46 2003
From: jerosenb at hcs.harvard.edu (janet rosenbaum)
Date: Fri, 14 Mar 2003 10:12:46 -0500 (EST)
Subject: [R] numbers and decimal points
Message-ID: <200303141512.h2EFCkZE005577@hcs.harvard.edu>


I have a question for our European readers:  how common is it to use
commas as decimal points in spread-sheet and statistics applications?

Is it an inconvenience to require that all data use a period as decimal point?
(i.e., 3.14159 rather than 3,14159).

We're trying to make our program as foolproof as possible, and would
prefer not to give users a chance to have commas as both decimal points
and field delimiters.

Thanks,

Janet Rosenbaum					  jerosenb at fas.harvard.edu
Center for Basic Research in the Social Sciences, Harvard University


From parkhurs at indiana.edu  Fri Mar 14 16:35:19 2003
From: parkhurs at indiana.edu (David Parkhurst)
Date: Fri, 14 Mar 2003 10:35:19 -0500
Subject: [R] length() misbehaving?
Message-ID: <000b01c2ea3f$573add70$b9f21644@spea.indiana.edu>

I'm having a weird problem with length(), in R1.6.1 under windows2000.  I have a
dataframe called byyr, with ten columns, the first of which is named cnd95.
summary(byyr) shows that byyr$cnd95 contains the factor level "tr" 66 times.  Also,
when I enter byyr$cnd95 at the command line, I can count 66 "tr" elements in the
resulting vector.  However, when I enter

n95trt <- length(byyr$cnd95[byyr$cnd95=="tr"])
n95trt

the result is 68!  Any ideas why this is happening, and how I can fix the miscount?
(That column also contains 69 entries of "c", and (relevantly?) two NA's.)

Thanks for any help.

Dave Parkhurst


From parkhurs at indiana.edu  Fri Mar 14 16:44:14 2003
From: parkhurs at indiana.edu (David Parkhurst)
Date: Fri, 14 Mar 2003 10:44:14 -0500
Subject: [R] Fw: length() misbehaving?:  More
Message-ID: <001d01c2ea40$936a9f00$b9f21644@spea.indiana.edu>

With the problem below, I've discoved that
n95trt<-length(byyr$cnd95[byyr$cnd95=="tr"&!is.na(byyr$cnd95)])
does give me the correct count for the number of "tr" entries.  (The same behavior
occurs for the "c" level of the cnd95 factor.)  It appears that
byyr$cnd95=="tr"
is finding both "tr" AND NA entries.  Is this a bug, or is it to be expected?

Dave

Subject: length() misbehaving?


> I'm having a weird problem with length(), in R1.6.1 under windows2000.  I have a
> dataframe called byyr, with ten columns, the first of which is named cnd95.
> summary(byyr) shows that byyr$cnd95 contains the factor level "tr" 66 times.  Also,
> when I enter byyr$cnd95 at the command line, I can count 66 "tr" elements in the
> resulting vector.  However, when I enter
>
> n95trt <- length(byyr$cnd95[byyr$cnd95=="tr"])
> n95trt
>
> the result is 68!  Any ideas why this is happening, and how I can fix the miscount?
> (That column also contains 69 entries of "c", and (relevantly?) two NA's.)
>
> Thanks for any help.
>
> Dave Parkhurst
>
>


From djw1005 at cam.ac.uk  Fri Mar 14 16:46:02 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Fri, 14 Mar 2003 15:46:02 +0000 (GMT)
Subject: [R] Biplots
Message-ID: <Pine.SOL.3.96.1030314152333.11653A-100000@draco.cus.cam.ac.uk>


A little while ago, I asked for help on producing biplots with more
options than are provided by the function biplot in library mva. No help
was forthcoming, so I wrote my own function, essentially a lattice version
of biplot with some extra features for plotting axes. In case anyone is
interested, here is a pointer to my code:
  http://www.statslab.cam.ac.uk/~djw1005/Stats/Interests/biplot.html
It's just source code; when I have time, and when I've debugged, I shall
wrap it up into a library.

The extra features are: groups parameters, so that different points and
biplot axes can be coloured differently; plotting the ranges of the biplot
axes, together with tickmarks; the usual lattice conditioning.

If anyone has any comments, I would be delighted to hear them. My routines
are barely documented, so you would probably need to look at the source
code. Undoubtedly I have written some parts poorly: there are many parts
of R programming in general and lattice in particular that I don't
understand.

The basic use is like this:

m <-
data.frame(row.names=c("Me","Law","Pitt","Li","Deneuve",
                       "Clooney","Zwilliger"),
                looks=c(8,9,4,6,10,5,4),
                charm=c(6,7,1,5,9,7,8),
                acting=c(0,8,3,9,9,6,7),
                success=c(2,6,9,5,8,9,6),
sex=c("male","male","male","female","female","male","female"))
res <- princompfull(m[,c("looks","charm","acting","success")])
res$observations$sex <- m$sex
res$variables$type <- c("personal","personal","worldly","worldly")

xyaplot (y~x, groups=sex, data=res$observations,
         axes=y~x|type, data.axes=res$variables,
         axes.spec=list(origin="o",min="min",max="max",ticks=TRUE),
         label="label", label.axes="label")

I first call (my own routine) princompfull, which is an extended version
of princomp, also returning information about the range of values in each
column. Then I call xyaplot. This takes two formulae, one a standard
formula as used by xyplot, for the observations; the other specifying a
unit vector in the direction of each axis, referring to the data frame
data.axes, which is a data frame with a row for each axis. You can specify
groups= for the observations and groups.axes= for the axes.  You can also
use axes.spec, label and label.axes to give extra specifications (see the
web page referred to above). 

I came across two issues in lattice, which may be bugs, or just my
misunderstanding. The adj parameter in ltext doesn't work properly for
specifying vertical alignment, and as.factorOrShingle does not convert a
logical vector into factors.

I depart from standard lattice usage in some ways. My panel functions take
a subset of rows of the entire data frame, not a preprocessed set of
points together with subscripts. I always find that in other plots, e.g.
xyplot, I need access to the original data frame to plot my points
properly, and this makes it easier.

I also depart from standard lattice usage in that the values in axes.spec,
and of label and label.axes, should be character strings, referring to
columns of the relevant data frames. I found this more flexible than the
standard lattice usage of giving expressions which must be evaluated in
the appropriate context: it means my main xyaplot routine doesn't need to
know about those arguments (and in particular it doesn't need to worry
about subsetting the data frame according to those arguments): they can
just be passed straight to the panel function.  (For this, I loose two
things: the ability to put in arbitrary expressions, and the freedom to
work without data frames.) 

Damon Wischik.


From ripley at stats.ox.ac.uk  Fri Mar 14 16:51:57 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 14 Mar 2003 15:51:57 +0000 (GMT)
Subject: [R] numbers and decimal points
In-Reply-To: <200303141512.h2EFCkZE005577@hcs.harvard.edu>
Message-ID: <Pine.LNX.4.44.0303141546390.10130-100000@gannet.stats>

On Fri, 14 Mar 2003, janet rosenbaum wrote:

> I have a question for our European readers:  how common is it to use
> commas as decimal points in spread-sheet and statistics applications?
> 
> Is it an inconvenience to require that all data use a period as decimal point?
> (i.e., 3.14159 rather than 3,14159).

Depends where you are in Europe ... it is extremely uncommon to the far
west of Europe.  Note that R itself does not allow this, so presumably
people using R do not find it an inconvenience and you will have seriously
skewed your sampling frame by asking on R-help if your program is not R
itself.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Mar 14 16:58:50 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 14 Mar 2003 15:58:50 +0000 (GMT)
Subject: musues of == (was [R] length() misbehaving?)
In-Reply-To: <000b01c2ea3f$573add70$b9f21644@spea.indiana.edu>
Message-ID: <Pine.LNX.4.44.0303141552230.10130-100000@gannet.stats>

It's the users who are misbehaving -- it usually is!

I think you mean [byyr$cnd95 %in% "tr"], not the same thing as R has
NA character strings.

> x <- c("a", "a", NA, "b2")
> x == "a"
[1]  TRUE  TRUE    NA FALSE
> x[x == "a"]
[1] "a" "a" NA 
> x[x %in% "a"]
[1] "a" "a"

MASS4 page 30 discusses this and similar traps.

On Fri, 14 Mar 2003, David Parkhurst wrote:

> I'm having a weird problem with length(), in R1.6.1 under windows2000.  I have a
> dataframe called byyr, with ten columns, the first of which is named cnd95.
> summary(byyr) shows that byyr$cnd95 contains the factor level "tr" 66 times.  Also,
> when I enter byyr$cnd95 at the command line, I can count 66 "tr" elements in the
> resulting vector.  However, when I enter
> 
> n95trt <- length(byyr$cnd95[byyr$cnd95=="tr"])
> n95trt
> 
> the result is 68!  Any ideas why this is happening, and how I can fix the miscount?
> (That column also contains 69 entries of "c", and (relevantly?) two NA's.)
> 
> Thanks for any help.
> 
> Dave Parkhurst
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From e.pebesma at geog.uu.nl  Wed Mar 12 11:46:12 2003
From: e.pebesma at geog.uu.nl (Edzer J. Pebesma)
Date: Wed, 12 Mar 2003 11:46:12 +0100
Subject: [R] [S] Gstat: multivariable geostatistics for S (R and S-Plus)
Message-ID: <3E6F0FF4.CCD7EDC9@geog.uu.nl>

The majority of the functionality present in the gstat stand-alone
program (http://www.gstat.org/) is now available as a package/library for
the S language (R, S-Plus), again called gstat. The package provides
multivariable geostatistical modelling, prediction and simulation, as
well as several visualisation functions.  Gstat was started 10 years
ago and was released under the GPL in 1996; the original stand-alone
program is closely linked to several GIS systems. Gstat was not initially
written for teaching purposes, but for research purposes, emphasizing
flexibility, scalability and portability. It can deal with a large number
of practical issues in geostatistics, including change of support (block
kriging), simple/ordinary/universal (co)kriging, fast local neighbourhood
selection, flexible trend modelling, variables with different sampling
configurations, and efficient simulation of large spatially correlated
random fields, indicator kriging and simulation, and (directional)
variogram and cross variogram modelling. The S formula/models interface
is used to define multivariable geostatistical models.

The source and windows package for R are available from CRAN. The page on
http://www.gstat.org/s.html has links to R and S-Plus (6.x) source code,
as well as examples, graphs, and a longer list of features. (A binary
Win32 S-Plus library is planned later this year.)

On http://www.ci.tuwien.ac.at/Conferences/DSC-2003/ you can find a
draft paper further describing the package.

Any feedback is appreciated.
--
Edzer
--------------------------------------------------------------------
This message was distributed by s-news at lists.biostat.wustl.edu.  To
...(s-news.. clipped)...

.


From ligges at statistik.uni-dortmund.de  Fri Mar 14 16:59:08 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 14 Mar 2003 16:59:08 +0100
Subject: [R] length() misbehaving?
In-Reply-To: <000b01c2ea3f$573add70$b9f21644@spea.indiana.edu>
References: <000b01c2ea3f$573add70$b9f21644@spea.indiana.edu>
Message-ID: <3E71FC4C.5030700@statistik.uni-dortmund.de>

David Parkhurst wrote:
> I'm having a weird problem with length(), in R1.6.1 under windows2000.  I have a
> dataframe called byyr, with ten columns, the first of which is named cnd95.
> summary(byyr) shows that byyr$cnd95 contains the factor level "tr" 66 times.  Also,
> when I enter byyr$cnd95 at the command line, I can count 66 "tr" elements in the
> resulting vector.  However, when I enter
> 
> n95trt <- length(byyr$cnd95[byyr$cnd95=="tr"])
> n95trt
> 
> the result is 68!  Any ideas why this is happening, and how I can fix the miscount?
> (That column also contains 69 entries of "c", and (relevantly?) two NA's.)
> 
> Thanks for any help.
> 
> Dave Parkhurst

The result you are looking for can be calculated with

  sum(byyr$cnd95 == "tr", na.rm=TRUE)


Look at

   byyr$cnd95 == "tr"

you'll get TRUE, FALSE, and NAs
Indexing with NAs yields NAs and hence these are included in the length 
of the resulting vector.

Uwe Ligges


From ligges at statistik.uni-dortmund.de  Fri Mar 14 17:01:29 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 14 Mar 2003 17:01:29 +0100
Subject: [R] Fw: length() misbehaving?:  More
In-Reply-To: <001d01c2ea40$936a9f00$b9f21644@spea.indiana.edu>
References: <001d01c2ea40$936a9f00$b9f21644@spea.indiana.edu>
Message-ID: <3E71FCD9.2060309@statistik.uni-dortmund.de>

David Parkhurst wrote:
> With the problem below, I've discoved that
> n95trt<-length(byyr$cnd95[byyr$cnd95=="tr"&!is.na(byyr$cnd95)])
> does give me the correct count for the number of "tr" entries.  (The same behavior
> occurs for the "c" level of the cnd95 factor.)  It appears that
> byyr$cnd95=="tr"
> is finding both "tr" AND NA entries.  Is this a bug, or is it to be expected?

This is expected - it's an inappropriate use of length(), see my earlier 
mail.
Calculations, comparisons and indexing with NA returns NA. That's 
documented and therefore expected.

Uwe Ligges


> Dave
> 
> Subject: length() misbehaving?
> 
> 
> 
>>I'm having a weird problem with length(), in R1.6.1 under windows2000.  I have a
>>dataframe called byyr, with ten columns, the first of which is named cnd95.
>>summary(byyr) shows that byyr$cnd95 contains the factor level "tr" 66 times.  Also,
>>when I enter byyr$cnd95 at the command line, I can count 66 "tr" elements in the
>>resulting vector.  However, when I enter
>>
>>n95trt <- length(byyr$cnd95[byyr$cnd95=="tr"])
>>n95trt
>>
>>the result is 68!  Any ideas why this is happening, and how I can fix the miscount?
>>(That column also contains 69 entries of "c", and (relevantly?) two NA's.)
>>
>>Thanks for any help.
>>
>>Dave Parkhurst
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From otoomet at econ.dk  Fri Mar 14 17:20:32 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Fri, 14 Mar 2003 17:20:32 +0100
Subject: [R] length() misbehaving?
In-Reply-To: <000b01c2ea3f$573add70$b9f21644@spea.indiana.edu>
	(parkhurs@indiana.edu)
References: <000b01c2ea3f$573add70$b9f21644@spea.indiana.edu>
Message-ID: <200303141620.h2EGKWI11442@punik.econ.au.dk>

HI Dave,

 | From: "David Parkhurst" <parkhurs at indiana.edu>
 | Date: Fri, 14 Mar 2003 10:35:19 -0500
 | 
 | I'm having a weird problem with length(), in R1.6.1 under windows2000.  I have a
 | dataframe called byyr, with ten columns, the first of which is named cnd95.
 | summary(byyr) shows that byyr$cnd95 contains the factor level "tr" 66 times.  Also,
 | when I enter byyr$cnd95 at the command line, I can count 66 "tr" elements in the
 | resulting vector.  However, when I enter
 | 
 | n95trt <- length(byyr$cnd95[byyr$cnd95=="tr"])
 | n95trt
 | 
 | the result is 68!  Any ideas why this is happening, and how I can fix the miscount?
 | (That column also contains 69 entries of "c", and (relevantly?) two NA's.)

Yes, NA-s are relevant.  Try:

> a <- factor(c("a", "a", NA))
> a
[1] a    a    <NA>
Levels:  a 
> summary(a)
   a NA's 
   2    1 
> a=="a"
[1] TRUE TRUE   NA
# there are 3 elements in the vector, hence there is 3 in a[a=="a"]?too.

> sum(a=="a", na.rm=T)
[1] 2

will give you the correct length.

perhaps it helps.

Ott

 | 
 | Thanks for any help.
 | 
 | Dave Parkhurst


From mschwartz at medanalytics.com  Fri Mar 14 17:22:48 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 14 Mar 2003 10:22:48 -0600
Subject: [R] length() misbehaving?
In-Reply-To: <000b01c2ea3f$573add70$b9f21644@spea.indiana.edu>
Message-ID: <000c01c2ea45$f48fc120$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of David
Parkhurst
>Sent: Friday, March 14, 2003 9:35 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] length() misbehaving?
>
>
>I'm having a weird problem with length(), in R1.6.1 under 
>windows2000.  I have a dataframe called byyr, with ten 
>columns, the first of which is named cnd95.
>summary(byyr) shows that byyr$cnd95 contains the factor level 
>"tr" 66 times.  Also, when I enter byyr$cnd95 at the command 
>line, I can count 66 "tr" elements in the resulting vector.  
>However, when I enter
>
>n95trt <- length(byyr$cnd95[byyr$cnd95=="tr"])
>n95trt
>
>the result is 68!  Any ideas why this is happening, and how I 
>can fix the miscount? (That column also contains 69 entries of 
>"c", and (relevantly?) two NA's.)
>
>Thanks for any help.
>
>Dave Parkhurst


It is expected.

Since NA represents a true unknown, the two NA's in your vector 'may
be' a "tr".  Thus, you get TRUE for the NA's when making the
comparison.

Instead of length(), you might want to use:

sum(byyr$cnd95[byyr$cnd95 == "tr"], na.rm = TRUE)

which will remove the two NA's.

See ?sum

HTH,

Marc Schwartz


From rdiaz at cnio.es  Fri Mar 14 17:31:59 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Fri, 14 Mar 2003 17:31:59 +0100
Subject: [R] numbers and decimal points
In-Reply-To: <200303141512.h2EFCkZE005577@hcs.harvard.edu>
References: <200303141512.h2EFCkZE005577@hcs.harvard.edu>
Message-ID: <200303141731.59864.rdiaz@cnio.es>

Dear Janet,

In Spain, it is common for spreadsheets to use commas for the decimal point. 
As well, (the spanish version of) some statistical software allows either 
comma or period. 

However, most people I know of have no problem at all using the period (and 
many of them do change the defaults in their OS and/or spreadhseet, to use 
the period instead of the comma, precisely to avoid the confussion you 
mention).

Best,

Ram?n





On Friday 14 March 2003 16:12, janet rosenbaum wrote:
> I have a question for our European readers:  how common is it to use
> commas as decimal points in spread-sheet and statistics applications?
>
> Is it an inconvenience to require that all data use a period as decimal
> point? (i.e., 3.14159 rather than 3,14159).
>
> We're trying to make our program as foolproof as possible, and would
> prefer not to give users a chance to have commas as both decimal points
> and field delimiters.
>
> Thanks,
>
> Janet Rosenbaum					  jerosenb at fas.harvard.edu
> Center for Basic Research in the Social Sciences, Harvard University
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
http://bioinfo.cnio.es/~rdiaz


From mschwartz at medanalytics.com  Fri Mar 14 17:33:40 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 14 Mar 2003 10:33:40 -0600
Subject: [R] length() misbehaving?
Message-ID: <000d01c2ea47$793a59c0$0201a8c0@MARC>

>-----Original Message-----
>From: Marc Schwartz [mailto:mschwartz at medanalytics.com] 
>Sent: Friday, March 14, 2003 10:23 AM
>To: 'David Parkhurst'; 'r-help at stat.math.ethz.ch'
>Subject: RE: [R] length() misbehaving?
>
>
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of David
Parkhurst
>>Sent: Friday, March 14, 2003 9:35 AM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] length() misbehaving?
>>
>>
>>I'm having a weird problem with length(), in R1.6.1 under
>>windows2000.  I have a dataframe called byyr, with ten 
>>columns, the first of which is named cnd95.
>>summary(byyr) shows that byyr$cnd95 contains the factor level 
>>"tr" 66 times.  Also, when I enter byyr$cnd95 at the command 
>>line, I can count 66 "tr" elements in the resulting vector.  
>>However, when I enter
>>
>>n95trt <- length(byyr$cnd95[byyr$cnd95=="tr"])
>>n95trt
>>
>>the result is 68!  Any ideas why this is happening, and how I
>>can fix the miscount? (That column also contains 69 entries of 
>>"c", and (relevantly?) two NA's.)
>>
>>Thanks for any help.
>>
>>Dave Parkhurst
>
>
>It is expected.
>
>Since NA represents a true unknown, the two NA's in your 
>vector 'may be' a "tr".  Thus, you get TRUE for the NA's when 
>making the comparison.
>
>Instead of length(), you might want to use:
>
>sum(byyr$cnd95[byyr$cnd95 == "tr"], na.rm = TRUE)
>
>which will remove the two NA's.
>
>See ?sum
>
>HTH,
>
>Marc Schwartz


Correction.  I mis-copied the code.  It should be:

sum(byyr$cnd95 == "tr", na.rm = TRUE)

Apologies,

Marc


From fharrell at virginia.edu  Fri Mar 14 17:42:02 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 14 Mar 2003 11:42:02 -0500
Subject: [R] logistic regression
In-Reply-To: <3E71EBC5.3000400@deprem.gov.tr>
References: <3E71EBC5.3000400@deprem.gov.tr>
Message-ID: <20030314114202.033b5141.fharrell@virginia.edu>

On Fri, 14 Mar 2003 16:48:37 +0200
orkun <temiz at deprem.gov.tr> wrote:

> Hello
> 1*
> I need to use logistic regression. But
> my data file is very huge( appx. 4 million line).
> R doesn't handle such a file.
> What can I do ?
> ------------------------
> 2*
> So, I thought whether I could perform sta. analyses on summarised
> data (count of yes/no values) of the huge file. Normally, summarised
> data file short and R could handle it.
> Then I used this command.
>  > lo <-glm(hey.count~as.factor(jeo)+as.factor(eg)+as.factor(kon)+
> as.factor(yol)+ as.factor(aks)+as.factor(fay),family=poisson,data=dt2)
> 
> as you see I used count value of yes/no data as independent data.
> 
> Is it good idea to use this method instead of binomial logistic regression ?
> 
> what do you suggest more ?
> 
> thanks in advance
> 
> -- 
> Ahmet Temiz
> Geological Engineer
> General Directorate
> of Disaster Affairs
> TURKEY

If you have no more than one continuous variable you can pre-process (outside of R) to collapse the data into frequency counts.  I did not check to see if glm handles frequency case weights.  The lrm function in the Design package (http://hesweb1.med.virginia.edu/biostat/s/Design.html) does.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From p.dalgaard at biostat.ku.dk  Fri Mar 14 17:56:44 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Mar 2003 17:56:44 +0100
Subject: [R] numbers and decimal points
In-Reply-To: <Pine.LNX.4.44.0303141546390.10130-100000@gannet.stats>
References: <Pine.LNX.4.44.0303141546390.10130-100000@gannet.stats>
Message-ID: <x2hea5khtf.fsf@biostat.ku.dk>

ripley at stats.ox.ac.uk writes:

> On Fri, 14 Mar 2003, janet rosenbaum wrote:
> 
> > I have a question for our European readers:  how common is it to use
> > commas as decimal points in spread-sheet and statistics applications?
> > 
> > Is it an inconvenience to require that all data use a period as decimal point?
> > (i.e., 3.14159 rather than 3,14159).
> 
> Depends where you are in Europe ... it is extremely uncommon to the far
> west of Europe.  Note that R itself does not allow this, so presumably
> people using R do not find it an inconvenience and you will have seriously
> skewed your sampling frame by asking on R-help if your program is not R
> itself.

OTOH, various Microsoft abominations (and I'm afraid also some non-MS
ones) switch the decimal symbol in many locales, so that a
tab-delimited file in Denmark and Germany will have commas instead of
periods (and CSV files use semicolon instead of comma). This is the
reason for having read.delim2 and read.csv2 in R. 

Windows users in DK practically speaking cannot save spreadsheets and
databases in the period-format without changing the locale settings of
the computer. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From spencer.graves at pdf.com  Fri Mar 14 17:18:40 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 14 Mar 2003 08:18:40 -0800
Subject: [R] Looking for GUI
References: <024D6AEFCB92CB47BA1085751D184BB801053F69@MBXSRV03.stf.nus.edu.sg>
Message-ID: <3E7200E0.9060801@pdf.com>

I'm new to R, but I've used S-Plus for years.  The S-Plus GUI is better 
that what I've been able to figure out so far for R.  In S-Plus, one can 
extract GUI commands from History and use them in a script or a 
function.  However, the GUI commands I've seen in History are NOT 
standard S commands and are therefore largely worthless for my purposes.

Hope this helps.
Spencer Graves

Adaikalavan Ramasamy wrote:
> If you have cash to spare, try the commercial version S-Plus.
> 
> -----Original Message-----
> From: Ulrich Pedri [mailto:ulrich.pedri at tiscali.it] 
> Sent: Friday, March 14, 2003 6:44 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Looking for GUI
> 
> 
> Hi List,
> 
> i am locking for a GUI for R. I have a Debian Woody 3.0 and running R
> 1.5.1. 
> In office i am using SPSS 9.0 for several years now after Systat for
> short 
> time and now i would use a statistic software under Linux at home. It
> seems 
> that R could be that what i am looking for, but i have problems to
> understand 
> how it works or better explained i would prefer using a good grafic
> interface.
> 
> Wich one could i try ??
> 
> thank you
> ULI
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tlumley at u.washington.edu  Fri Mar 14 18:35:35 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 14 Mar 2003 09:35:35 -0800 (PST)
Subject: [R] length() misbehaving?
In-Reply-To: <000b01c2ea3f$573add70$b9f21644@spea.indiana.edu>
Message-ID: <Pine.A41.4.44.0303140934210.15508-100000@homer26.u.washington.edu>

On Fri, 14 Mar 2003, David Parkhurst wrote:

> I'm having a weird problem with length(), in R1.6.1 under windows2000.  I have a
> dataframe called byyr, with ten columns, the first of which is named cnd95.
> summary(byyr) shows that byyr$cnd95 contains the factor level "tr" 66 times.  Also,
> when I enter byyr$cnd95 at the command line, I can count 66 "tr" elements in the
> resulting vector.  However, when I enter
>
> n95trt <- length(byyr$cnd95[byyr$cnd95=="tr"])
> n95trt
>

In addition to the sum() approach suggested by other people there's an
approach using %in%

  n95trt <- length(byyr$cnd95[byyr$cnd95 %in% "tr"])

You can check that NA=="tr" returns NA, but NA %in% "tr" returns FALSE.

	-thomas


From Edmond.Ng at lshtm.ac.uk  Fri Mar 14 18:40:00 2003
From: Edmond.Ng at lshtm.ac.uk (Edmond Ng)
Date: Fri, 14 Mar 2003 17:40:00 +0000
Subject: [R] odd behaviour of 'while'?
Message-ID: <se7213f9.087@s-webmail.lshtm.ac.uk>

Hi all, 

I have written a program which performs some data simulation, model fitting (to the simulated data) and then  it will save the parameter estimates from each loop into a matrix for later use.  Because convergence will not be met in some sets of the simulated data, I have used a 'while' instead of a 'for' loop for the job. With a 'for' loop I was not able to turn the counter back and repeat the same loop when non-convergence occurred. 

While my programme seems to be working alright, something rather odd is happening. A sample of my programme is as follows:- (the eaxct codes in 'single quotes' have been omitted for simplicity sake)

ilim <- 10 
while (i <= ilim) { 
y <- 'simulated some data' 
modelsummary <- try('fitted a model to the simulated data') 
on.exit( c( cat("non-convergence met at loop ", i) , next) ) 
i <- i+1
} 

When this stopped, it stopped with the warning message that I provided and the number of i was 11. I can't figure out why it is equal to 11 because the condition for the while loop should have failed when i became 11. The loop should have stopped and it should not have got to the 'on.exit' bit  in the loop  automatically. 

While it does not seem to affect the results of my programme, I would like to know why this quirk is  happening. Any help or suggestion is more than welcome. Thanks in advance. 

Edmond  






function to enable R to go to the next round once a non-convergence takes place.


From p.dalgaard at biostat.ku.dk  Fri Mar 14 18:43:22 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Mar 2003 18:43:22 +0100
Subject: [R] logistic regression
In-Reply-To: <20030314114202.033b5141.fharrell@virginia.edu>
References: <3E71EBC5.3000400@deprem.gov.tr>
	<20030314114202.033b5141.fharrell@virginia.edu>
Message-ID: <x2wuj13kud.fsf@biostat.ku.dk>

Frank E Harrell Jr <fharrell at virginia.edu> writes:


> If you have no more than one continuous variable you can pre-process
> (outside of R) to collapse the data into frequency counts. I did not
> check to see if glm handles frequency case weights. The lrm function
> in the Design package
> (http://hesweb1.med.virginia.edu/biostat/s/Design.html) does.

glm can have a matrix (cbind(success,failure)) as response.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From TyagiAnupam at aol.com  Fri Mar 14 19:03:47 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Fri, 14 Mar 2003 13:03:47 EST
Subject: [R] logistic regression 
Message-ID: <144.ce714a9.2ba37383@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030314/13bf27e2/attachment.pl

From mschwartz at medanalytics.com  Fri Mar 14 19:16:18 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 14 Mar 2003 12:16:18 -0600
Subject: [R] Looking for GUI
In-Reply-To: <3E7200E0.9060801@pdf.com>
Message-ID: <001101c2ea55$cfebebe0$0201a8c0@MARC>

>> -----Original Message-----
>> From: Ulrich Pedri [mailto:ulrich.pedri at tiscali.it]
>> Sent: Friday, March 14, 2003 6:44 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Looking for GUI
>> 
>> 
>> Hi List,
>> 
>> i am locking for a GUI for R. I have a Debian Woody 3.0 and 
>running R 
>> 1.5.1. In office i am using SPSS 9.0 for several years now after 
>> Systat for short
>> time and now i would use a statistic software under Linux at home.
It
>> seems 
>> that R could be that what i am looking for, but i have problems to
>> understand 
>> how it works or better explained i would prefer using a good grafic
>> interface.
>> 
>> Wich one could i try ??
>> 
>> thank you
>> ULI


There are a variety of R-GUI projects underway. More information is
available at http://www.sciviews.org/_rgui/.  There is also a
R-SIG-GUI e-mail list for folks interested and you may wish to
consider reviewing them and contributing to the efforts. Some
background is also available there on the pros and cons of using a
GUI.

I do not use any of the GUI's, so I cannot comment in detail. However,
it does appear that a notable amount of time and energy is being
commited to the endeavors listed.

I should note that not all of the projects listed there are actual
GUI's but are functional enhancements to editors and IDE's for use
with R.

There are many "official" and contributed documents for R, including
an increasing number of published books that cover R coding and you
may wish to review these. Most contain introductory materials for new
users. R-FAQ 2.7 reviews many of these and there is a link on the main
R page under "Documentation" for the contributed documents.

HTH,

Marc Schwartz


From jerosenb at hcs.harvard.edu  Fri Mar 14 19:17:19 2003
From: jerosenb at hcs.harvard.edu (janet rosenbaum)
Date: Fri, 14 Mar 2003 13:17:19 -0500 (EST)
Subject: [R] numbers and decimal points
In-Reply-To: <x2hea5khtf.fsf@biostat.ku.dk> from "Peter Dalgaard BSA" at Mar
	14, 2003 05:56:44 PM
Message-ID: <200303141817.h2EIHJAH009379@hcs.harvard.edu>


Thanks for all the helpful decimal point information.  I implemented it,
so our friends at WHO should be happy.

It wasn't pure laziness --- I wanted to avoid cluttering the GUI.
To paraphrase from Ethics of the Fathers, "the more features; the more worry."

Thanks,

Janet


From tlumley at u.washington.edu  Fri Mar 14 19:30:34 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 14 Mar 2003 10:30:34 -0800 (PST)
Subject: [R] logistic regression
In-Reply-To: <x2wuj13kud.fsf@biostat.ku.dk>
Message-ID: <Pine.A41.4.44.0303141030210.15508-100000@homer26.u.washington.edu>

On 14 Mar 2003, Peter Dalgaard BSA wrote:

> Frank E Harrell Jr <fharrell at virginia.edu> writes:
>
>
> > If you have no more than one continuous variable you can pre-process
> > (outside of R) to collapse the data into frequency counts. I did not
> > check to see if glm handles frequency case weights. The lrm function
> > in the Design package
> > (http://hesweb1.med.virginia.edu/biostat/s/Design.html) does.
>
> glm can have a matrix (cbind(success,failure)) as response.

Or case weights.

	-thomas


From tlumley at u.washington.edu  Fri Mar 14 19:44:34 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 14 Mar 2003 10:44:34 -0800 (PST)
Subject: [R] odd behaviour of 'while'?
In-Reply-To: <se7213f9.087@s-webmail.lshtm.ac.uk>
Message-ID: <Pine.A41.4.44.0303141031130.15508-100000@homer26.u.washington.edu>

On Fri, 14 Mar 2003, Edmond Ng wrote:

> Hi all,
>
> I have written a program which performs some data simulation, model fitting (to the simulated data) and then  it will save the parameter estimates from each loop into a matrix for later use.  Because convergence will not be met in some sets of the simulated data, I have used a 'while' instead of a 'for' loop for the job. With a 'for' loop I was not able to turn the counter back and repeat the same loop when non-convergence occurred.
>
> While my programme seems to be working alright, something rather odd is happening. A sample of my programme is as follows:- (the eaxct codes in 'single quotes' have been omitted for simplicity sake)
>
> ilim <- 10
> while (i <= ilim) {
> y <- 'simulated some data'
> modelsummary <- try('fitted a model to the simulated data')
> on.exit( c( cat("non-convergence met at loop ", i) , next) )
> i <- i+1
> }
>
> When this stopped, it stopped with the warning message that I provided
> and the number of i was 11. I can't figure out why it is equal to 11
> because the condition for the while loop should have failed when i
> became 11. The loop should have stopped and it should not have got to
> the 'on.exit' bit in the loop automatically.
>

It did stop. It then exited the loop. As it was exiting, it ran the
on.exit you provided.  I don't know why you didn't get the error
  Error: No loop to break from, jumping to top level
but then I don't know what your code really looked like

For an example of the phenomenon that actually runs, consider

f<-function ()
{
    i <- 1
    while (i < 10) {
        on.exit(cat("exited in iteration", i, "\n"))
        cat(i, "\n")
        i <- i + 1
    }
}


Also, the on.exit() could never do what you want, since you have prevented
any non-convergence errors by using try().  You probably want something
like
  if (inherits(modelsummary,"try-error")) {cat("convergence error",i)}
but it's hard to tell.


	-thomas


From spencer.graves at pdf.com  Fri Mar 14 19:59:22 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 14 Mar 2003 10:59:22 -0800
Subject: [R] odd behaviour of 'while'?
References: <se7213f9.087@s-webmail.lshtm.ac.uk>
Message-ID: <3E72268A.9020606@pdf.com>

 From ?on.exit:

  `on.exit' records the expression given as its argument as needing
      to be executed when the current function exits (either naturally
      or as the result of an error).

Thus, when "i <- i+1", it then goes to "while", which then exits, 
invoking the "on.exit" command as it does so.

Hope this helps.
Spencer Graves

Edmond Ng wrote:
> Hi all, 
> 
> I have written a program which performs some data simulation, model fitting (to the simulated data) and then  it will save the parameter estimates from each loop into a matrix for later use.  Because convergence will not be met in some sets of the simulated data, I have used a 'while' instead of a 'for' loop for the job. With a 'for' loop I was not able to turn the counter back and repeat the same loop when non-convergence occurred. 
> 
> While my programme seems to be working alright, something rather odd is happening. A sample of my programme is as follows:- (the eaxct codes in 'single quotes' have been omitted for simplicity sake)
> 
> ilim <- 10 
> while (i <= ilim) { 
> y <- 'simulated some data' 
> modelsummary <- try('fitted a model to the simulated data') 
> on.exit( c( cat("non-convergence met at loop ", i) , next) ) 
> i <- i+1
> } 
> 
> When this stopped, it stopped with the warning message that I provided and the number of i was 11. I can't figure out why it is equal to 11 because the condition for the while loop should have failed when i became 11. The loop should have stopped and it should not have got to the 'on.exit' bit  in the loop  automatically. 
> 
> While it does not seem to affect the results of my programme, I would like to know why this quirk is  happening. Any help or suggestion is more than welcome. Thanks in advance. 
> 
> Edmond  
> 
> 
> 
> 
> 
> 
> function to enable R to go to the next round once a non-convergence takes place.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From p.dalgaard at biostat.ku.dk  Fri Mar 14 20:09:40 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Mar 2003 20:09:40 +0100
Subject: [R] logistic regression
In-Reply-To: <Pine.A41.4.44.0303141030210.15508-100000@homer26.u.washington.edu>
References: <Pine.A41.4.44.0303141030210.15508-100000@homer26.u.washington.edu>
Message-ID: <x2el5922a3.fsf@biostat.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:


> On 14 Mar 2003, Peter Dalgaard BSA wrote:
> 
> > Frank E Harrell Jr <fharrell at virginia.edu> writes:
> >
> >
> > > If you have no more than one continuous variable you can pre-process
> > > (outside of R) to collapse the data into frequency counts. I did not
> > > check to see if glm handles frequency case weights. The lrm function
> > > in the Design package
> > > (http://hesweb1.med.virginia.edu/biostat/s/Design.html) does.
> >
> > glm can have a matrix (cbind(success,failure)) as response.
> 
> Or case weights.

Right. (And actually explained on p.194 in my own book too! I just got
myself confused over whether it would check for non 0-1 responses.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From gvasudevan at medarex.com  Fri Mar 14 20:26:04 2003
From: gvasudevan at medarex.com (Vasudevan, Geetha)
Date: Fri, 14 Mar 2003 11:26:04 -0800
Subject: [R] multiple plots...
Message-ID: <8249C3256E593D4FB066BB9998D9F7E41CF14F@ca2-fs03.ca2.2k.medarex.com>

Is it possible to display multiple plots in different windows rather than using the split.screen ? 
thanks.
-Geetha.


From ripley at stats.ox.ac.uk  Fri Mar 14 20:35:26 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 14 Mar 2003 19:35:26 +0000 (GMT)
Subject: [R] multiple plots...
In-Reply-To: <8249C3256E593D4FB066BB9998D9F7E41CF14F@ca2-fs03.ca2.2k.medarex.com>
Message-ID: <Pine.LNX.4.44.0303141934040.10574-100000@gannet.stats>

On Fri, 14 Mar 2003, Vasudevan, Geetha wrote:

> Is it possible to display multiple plots in different windows rather than using the split.screen ? 
> thanks.

Yes. Just open a new device with windows() (since your message was in a 
proprietary MS character set) before each plot.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From noliveir2003 at zipmail.com.br  Fri Mar 14 21:54:19 2003
From: noliveir2003 at zipmail.com.br (noliveir2003@zipmail.com.br)
Date: Fri, 14 Mar 2003 17:54:19 -0300
Subject: [R] plot
Message-ID: <3E723503000003DB@www.zipmail.com.br>

Can anyone tell me how to plot on the same graph two different functions
(of x) using two differnt y scales (axes 2 and 4)?
Thanks
Nelson


From spencer.graves at pdf.com  Fri Mar 14 22:24:29 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 14 Mar 2003 13:24:29 -0800
Subject: [R] plot
References: <3E723503000003DB@www.zipmail.com.br>
Message-ID: <3E72488D.6020501@pdf.com>

Does the following produce what you want?

plot(0:1, 0:1, type="l")
axis(4, 0:1, c(0, 2))
lines(0:1, 0.5*c(2,1))

Spencer Graves

noliveir2003 at zipmail.com.br wrote:
> Can anyone tell me how to plot on the same graph two different functions
> (of x) using two differnt y scales (axes 2 and 4)?
> Thanks
> Nelson
> 
> 
> 
> ------------------------------------------
> Use o melhor sistema de busca da Internet
> Radar UOL - http://www.radaruol.com.br
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From eglen at pcg.wustl.edu  Fri Mar 14 22:44:02 2003
From: eglen at pcg.wustl.edu (Stephen Eglen)
Date: Fri, 14 Mar 2003 15:44:02 -0600
Subject: [R] Using Arial font in linux
Message-ID: <15986.19746.234466.119758@mosaics.wustl.edu>

Hi, 

Late last year there was a thread on r-help about installing Arial
fonts on linux machines:

  http://finzi.psych.upenn.edu/R/Rhelp02/archive/8548.html

I too would like to use Arial fonts in some R plots created on my
redhat machine.  I've installed the TrueType fonts from
http://corefonts.sourceforge.net/ -- there is now a directory 
/usr/share/fonts/msttcorefonts/ and xlsfonts reports many fonts:

% xlsfonts | grep arial 
...
-monotype-arial black-medium-r-normal--0-0-0-0-p-0-ascii-0
-monotype-arial black-medium-r-normal--0-0-0-0-p-0-fcd8859-15
-monotype-arial black-medium-r-normal--0-0-0-0-p-0-iso8859-1
...

How do I specify to use the Arial family within a call to
postscript()?  The following code didn't work ...   The thread
after the suggestion to vist corefonts.sourceforge.net stopped,
without saying how to then use the fonts within R.  Do I first need to
create .afm files so that I can use the second form of argument for family?


postscript(file="try.ps", horizontal=F,
           onefile=F,
           width=4, height=4,
           family="Arial",
           pointsize=12)
hist(rnorm(100))
dev.off()

Thanks for any pointers,
Stephen


From rg117 at yahoo.co.uk  Fri Mar 14 23:09:58 2003
From: rg117 at yahoo.co.uk (=?iso-8859-1?q?Rishabh=20Gupta?=)
Date: Fri, 14 Mar 2003 22:09:58 +0000 (GMT)
Subject: [R] boxplots with multiple numerical variables
Message-ID: <20030314220958.10614.qmail@web41111.mail.yahoo.com>

Hi all,
   I have a question regarding the boxplot function. The data I am working on has 1 grouping
variable (G) and it has many numerical variables (V1, V2, V3, V4, Vx, etc). What I would like to
do is create a boxplot where the Y-axis represents the numerical values of variable V1...Vx (all
the variables have the same range). The X-axis needs to represent the G-V combination. So suppose
the possible values for G are a, b and c, Then along the x-axis there would be a boxplot for each
of the combinations:

  V1Ga, V1Gb, V1Gc, V2Ga, V2Gb, V2Gc, V3Ga, V3Gb, V3Gc,.....VxGa, VxGb, VxGc, etc
ie
  all values of V1 where the G values are a, all values of V1 where the G values are b, etc
In addition, if possible, it would be nice if each G value would have a a different colour on the
plot so that they could be seen more clearly.

I'm not sure whether such a function already exists within R or whether it would have to be
written. Either way, I would appreciate it very much if somebody could help and give me some
advice as to how I can achieve this.

Many Thanks

Rishabh

__________________________________________________

Everything you'll ever need on one web page
from News and Sport to Email and Music Charts


From macq at llnl.gov  Fri Mar 14 23:17:12 2003
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 14 Mar 2003 14:17:12 -0800
Subject: [R] Formatting significant digits with trailing zeros
Message-ID: <p05200f01ba9801ebf237@[128.115.153.6]>

I need a function like signif(), but returns the rounded values as 
character strings, formatted with trailing zeros where appropriate. 
If anyone has one, I would sure appreciate a copy.

Thanks
-Don



Details:

signif() rounds a number to a specified number of significant digits, 
for example:

>  x <- c(2.503,2.477,0.1204)

>  signif(x[1],3)
[1] 2.5

>  signif(x[2],3)
[1] 2.48

>  signif(x[3],3)
[1] 0.12

All of these are correct, numerically. But, the trailing zeros do not 
display, naturally, because the R functions that format numbers for 
printing have no way of knowing that trailing zeros are desired. 
Pretending I have the function I need, named "fmt.signif", it would 
do this:

>  fmt.signif(x[1],3)
[1] "2.50"

>  fmt.signif(x[2],3)
[1] "2.48"

>  fmt.signif(x[3],3)
[1] "0.120"

>
>  signif(x,3)
[1] "2.50" "2.48" "0.120"

For now, at least, I'm willing to assume that I never want the 
numbers formatted with exponential notation.
-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------


From tlumley at u.washington.edu  Fri Mar 14 23:36:18 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 14 Mar 2003 14:36:18 -0800 (PST)
Subject: [R] boxplots with multiple numerical variables
In-Reply-To: <20030314220958.10614.qmail@web41111.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0303141426170.15508-100000@homer26.u.washington.edu>

On Fri, 14 Mar 2003, [iso-8859-1] Rishabh Gupta wrote:

> Hi all,
>    I have a question regarding the boxplot function. The data I am working on has 1 grouping
> variable (G) and it has many numerical variables (V1, V2, V3, V4, Vx, etc). What I would like to
> do is create a boxplot where the Y-axis represents the numerical values of variable V1...Vx (all
> the variables have the same range). The X-axis needs to represent the G-V combination. So suppose
> the possible values for G are a, b and c, Then along the x-axis there would be a boxplot for each
> of the combinations:
>
>   V1Ga, V1Gb, V1Gc, V2Ga, V2Gb, V2Gc, V3Ga, V3Gb, V3Gc,.....VxGa, VxGb, VxGc, etc
> ie
>   all values of V1 where the G values are a, all values of V1 where the G values are b, etc
> In addition, if possible, it would be nice if each G value would have a a different colour on the
> plot so that they could be seen more clearly.
>
> I'm not sure whether such a function already exists within R or whether it would have to be
> written. Either way, I would appreciate it very much if somebody could help and give me some
> advice as to how I can achieve this.
>

I'm going to work with a data frame that has two variables and a binary
grouping factor

df<-data.frame(x1=rnorm(100),x2=rnorm(100),g=rep(0:1,50))


There's at least two ways to do this.  boxplot() will take a list of
vectors and do boxplots of them, so we can split() each of the vectors
   lapply(df[,1:2], function(v) split(v, df$g))
and then combine them into a single list with do.call("c",)
and then boxplot() them. That is:
   boxplot(do.call("c",lapply(df[,1:2],function(v) split(v,df$g))))
This labels the x-axis "x1.0" "x1.1", "x2.0", "x2.1"


We can also do the opposite: combine the vectors into a single variable,
add a new factor indicating which vector each observation came from, and
use boxplot() with a formula.
   ddf<-reshape(df,varying=list(x=c("x1","x2")),direction="long")
   boxplot(x1~interaction(time,g),data=ddf)
This labels the x-axis "1.0" "2.0" "1.1" "2.1"


	-thomas


From mschwartz at medanalytics.com  Fri Mar 14 23:39:31 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 14 Mar 2003 16:39:31 -0600
Subject: [R] boxplots with multiple numerical variables
In-Reply-To: <20030314220958.10614.qmail@web41111.mail.yahoo.com>
Message-ID: <002201c2ea7a$9520a710$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rishabh Gupta
>Sent: Friday, March 14, 2003 4:10 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] boxplots with multiple numerical variables
>
>
>Hi all,
>   I have a question regarding the boxplot function. The data 
>I am working on has 1 grouping variable (G) and it has many 
>numerical variables (V1, V2, V3, V4, Vx, etc). What I would 
>like to do is create a boxplot where the Y-axis represents the 
>numerical values of variable V1...Vx (all the variables have 
>the same range). The X-axis needs to represent the G-V 
>combination. So suppose the possible values for G are a, b and 
>c, Then along the x-axis there would be a boxplot for each of 
>the combinations:
>
>  V1Ga, V1Gb, V1Gc, V2Ga, V2Gb, V2Gc, V3Ga, V3Gb, 
>V3Gc,.....VxGa, VxGb, VxGc, etc ie
>  all values of V1 where the G values are a, all values of V1 
>where the G values are b, etc In addition, if possible, it 
>would be nice if each G value would have a a different colour 
>on the plot so that they could be seen more clearly.
>
>I'm not sure whether such a function already exists within R 
>or whether it would have to be written. Either way, I would 
>appreciate it very much if somebody could help and give me 
>some advice as to how I can achieve this.
>
>Many Thanks
>
>Rishabh

If I understand correctly, you basically want to generate a grouped
boxplot, where each of the numeric variables are in groups of three
(a, b and c) across the x-axis.

The final example in ?boxplot does this, though for groups of 2 and it
uses a formula method. You would just need to modify the code in the
example adding a third call to boxplot() with the 'add = TRUE'
argument set as in the second call.

Note the use of the 'at' argument, which enables you to pick
mid-points for the groups and then draw the boxplots at offsets from
the mid-points.  In the case of groups of three, you would use the
mid-points and then the mid-points minus and plus an offset.

You then also use the 'boxwex' argument, to adjust the width of the
boxplots to fit the groupings.

Finally, for the colors, you can use a different 'col' argument in
each call to boxplot, which would yield three colors, one for each of
the three boxplots in each grouping.

HTH,

Marc Schwartz


From gregory_r_warnes at groton.pfizer.com  Fri Mar 14 23:41:59 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri, 14 Mar 2003 17:41:59 -0500
Subject: [R] RSessionDA 1.0-rc1 released.
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C702@groexmb02.pfizer.com>


Release 1.0-rc1 of RSessionDA is now available.  This version provides
significantly improved security and should now be usable on public internet
sites.

Description:

RSessionDA provides an interface to R from the open-source web application
development system Zope <http://www.zope.org>.  This interface permits
evaluation of functions in the R language using information in Zope.  R data
objects, graphics files, printed output, script transcripts, and data files
can be returned to Zope for display making it easy to create web
applications that include advanced statistical functionality.
 
See  <http://software.biostat.washington.edu/statsoft/snake/RSessionDA> for
details.

-Greg


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... [[dropped]]


From tplate at blackmesacapital.com  Fri Mar 14 23:57:55 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Fri, 14 Mar 2003 15:57:55 -0700
Subject: [R] Formatting significant digits with trailing zeros
In-Reply-To: <p05200f01ba9801ebf237@[128.115.153.6]>
Message-ID: <5.1.0.14.2.20030314155626.00b1fb58@mailhost.blackmesacapital.com>

Does this do what you want?

> x <- c(2.503,2.477,0.1204)
> sapply(signif(x,3), sprintf, fmt="%#.3g")
[1] "2.50"  "2.48"  "0.120"
>

This will give you scientific notation for very large or small numbers.


At Friday 02:17 PM 3/14/2003 -0800, Don MacQueen wrote:
>I need a function like signif(), but returns the rounded values as character strings, formatted with trailing zeros where appropriate. If anyone has one, I would sure appreciate a copy.
>
>Thanks
>-Don
>
>
>
>Details:
>
>signif() rounds a number to a specified number of significant digits, for example:
>
>> x <- c(2.503,2.477,0.1204)
>
>> signif(x[1],3)
>[1] 2.5
>
>> signif(x[2],3)
>[1] 2.48
>
>> signif(x[3],3)
>[1] 0.12
>
>All of these are correct, numerically. But, the trailing zeros do not display, naturally, because the R functions that format numbers for printing have no way of knowing that trailing zeros are desired. Pretending I have the function I need, named "fmt.signif", it would do this:
>
>> fmt.signif(x[1],3)
>[1] "2.50"
>
>> fmt.signif(x[2],3)
>[1] "2.48"
>
>> fmt.signif(x[3],3)
>[1] "0.120"
>
>>
>> signif(x,3)
>[1] "2.50" "2.48" "0.120"
>
>For now, at least, I'm willing to assume that I never want the numbers formatted with exponential notation.
>-- 
>--------------------------------------
>Don MacQueen
>Environmental Protection Department
>Lawrence Livermore National Laboratory
>Livermore, CA, USA
>--------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From parkhurs at indiana.edu  Sat Mar 15 00:49:04 2003
From: parkhurs at indiana.edu (David Parkhurst)
Date: Fri, 14 Mar 2003 18:49:04 -0500
Subject: [R] Summary:  length() "ain't misbehavin'" after all
Message-ID: <005401c2ea84$83fddbb0$4b264842@spea.indiana.edu>

I asked why length(byyr$cnd95[byyr$cnd95=="tr"]) was counting NA's as well as "tr"s.
Thanks to Brian Ripley, Uwe Ligges, Ott Toomet, Marc Schwartz, and Thomas Lumley for
their help.

Two solutions were to replace my call with

length[byyr$cnd95 %in% "tr"] or with sum(byyr$cnd95 == "tr", na.rm=TRUE)

and there were variations on those themes.

Thanks again.
Dave


From nirv402 at yahoo.com  Sat Mar 15 01:14:14 2003
From: nirv402 at yahoo.com (Nirvan Sunderam)
Date: Fri, 14 Mar 2003 16:14:14 -0800 (PST)
Subject: [R] Help with reading data
Message-ID: <20030315001414.17061.qmail@web14005.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030314/88f0f7e1/attachment.pl

From jerrytheshrub at hotmail.com  Sat Mar 15 01:25:08 2003
From: jerrytheshrub at hotmail.com (Jeremy Z Butler)
Date: Sat, 15 Mar 2003 13:25:08 +1300
Subject: [R] quote supression
Message-ID: <F64cYAiG6HSpfoTiQKY0000c038@hotmail.com>

To creat a series of plots I've constructed the following, however this 
doesn't work because the colnames being feed into n are embraced by quotes 
which is stuffing up the plotting function. Is there a way to suppress to 
quotes? coercion in to a different format??

for (n in colnames(tt[7:36]))
{
par(ask=T)
attach(tt)
plot(july~n)
...
}


From p.dalgaard at biostat.ku.dk  Sat Mar 15 01:44:45 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Mar 2003 01:44:45 +0100
Subject: [R] quote supression
In-Reply-To: <F64cYAiG6HSpfoTiQKY0000c038@hotmail.com>
References: <F64cYAiG6HSpfoTiQKY0000c038@hotmail.com>
Message-ID: <x28yvh1mrm.fsf@biostat.ku.dk>

"Jeremy Z Butler" <jerrytheshrub at hotmail.com> writes:

> To creat a series of plots I've constructed the following, however
> this doesn't work because the colnames being feed into n are embraced
> by quotes which is stuffing up the plotting function. Is there a way
> to suppress to quotes? coercion in to a different format??
> 
> for (n in colnames(tt[7:36]))
> {
> par(ask=T)
> attach(tt)
> plot(july~n)
> ...
> }

[You're adding tt to the search list 30 times that way. I don't think
you want that... Also, what is tt? If a matrix then you'd probably
need tt[,7:36] ]

This is difficult to do cleanly. One reasonable way might be

for (i in 7:36)
        plot(july~tt[,i],xlab=colnames(tt)[i])

If you insist on following your original strategy you end up with
something like

        eval(substitute(plot(july~n),list(n=as.name(n))))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From eglen at pcg.wustl.edu  Sat Mar 15 02:22:48 2003
From: eglen at pcg.wustl.edu (Stephen Eglen)
Date: Fri, 14 Mar 2003 19:22:48 -0600
Subject: [R] Using Arial font in linux
In-Reply-To: <15986.19746.234466.119758@mosaics.wustl.edu>
References: <15986.19746.234466.119758@mosaics.wustl.edu>
Message-ID: <15986.32872.264000.302161@mosaics.wustl.edu>

 > How do I specify to use the Arial family within a call to
 > postscript()?  

To follow up on my previous message, in case others are interested,
this is what I did, which seems to work for me.
First, the .ttf files need converting to afm:

ttf2afm /usr/share/fonts/msttcorefonts/arial.ttf > ~/arial.afm
ttf2afm /usr/share/fonts/msttcorefonts/ariali.ttf > ~/ariali.afm
ttf2afm /usr/share/fonts/msttcorefonts/arialbd.ttf > ~/arialbd.afm
ttf2afm /usr/share/fonts/msttcorefonts/arialbi.ttf > ~/arialbi.afm

and then I did the following in R:

postscript(file="try.ps", horizontal=F,
           onefile=F,
           width=4, height=4,
           family=c("/home/stephen/arial.afm",
             "/home/stephen/arialbd.afm",
             "/home/stephen/ariali.afm",
             "/home/stephen/arialbi.afm"),
           pointsize=12)
hist(rnorm(100))
dev.off()

Stephen


From mschwartz at medanalytics.com  Sat Mar 15 02:29:02 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 14 Mar 2003 19:29:02 -0600
Subject: [R] boxplots with multiple numerical variables
In-Reply-To: <Pine.A41.4.44.0303141426170.15508-100000@homer26.u.washington.edu>
Message-ID: <002e01c2ea92$43de6b90$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Thomas Lumley
>Sent: Friday, March 14, 2003 4:36 PM
>To: Rishabh Gupta
>Cc: r-help at stat.math.ethz.ch
>Subject: Re: [R] boxplots with multiple numerical variables
>
>
>On Fri, 14 Mar 2003, [iso-8859-1] Rishabh Gupta wrote:
>
>> Hi all,
>>    I have a question regarding the boxplot function. The data I am 
>> working on has 1 grouping variable (G) and it has many numerical 
>> variables (V1, V2, V3, V4, Vx, etc). What I would like to do 
>is create 
>> a boxplot where the Y-axis represents the numerical values 
>of variable 
>> V1...Vx (all the variables have the same range). The X-axis needs
to 
>> represent the G-V combination. So suppose the possible values for G

>> are a, b and c, Then along the x-axis there would be a boxplot for 
>> each of the combinations:
>>
>>   V1Ga, V1Gb, V1Gc, V2Ga, V2Gb, V2Gc, V3Ga, V3Gb, V3Gc,.....VxGa, 
>> VxGb, VxGc, etc ie
>>   all values of V1 where the G values are a, all values of V1 where

>> the G values are b, etc In addition, if possible, it would 
>be nice if 
>> each G value would have a a different colour on the plot so 
>that they 
>> could be seen more clearly.
>>
>> I'm not sure whether such a function already exists within R or 
>> whether it would have to be written. Either way, I would 
>appreciate it 
>> very much if somebody could help and give me some advice as to how
I 
>> can achieve this.
>>
>
>I'm going to work with a data frame that has two variables and 
>a binary grouping factor
>
>df<-data.frame(x1=rnorm(100),x2=rnorm(100),g=rep(0:1,50))
>
>
>There's at least two ways to do this.  boxplot() will take a 
>list of vectors and do boxplots of them, so we can split() 
>each of the vectors
>   lapply(df[,1:2], function(v) split(v, df$g))
>and then combine them into a single list with do.call("c",)
>and then boxplot() them. That is:
>   boxplot(do.call("c",lapply(df[,1:2],function(v) 
>split(v,df$g)))) This labels the x-axis "x1.0" "x1.1", "x2.0", "x2.1"
>
>
>We can also do the opposite: combine the vectors into a single 
>variable, add a new factor indicating which vector each 
>observation came from, and use boxplot() with a formula.
>   ddf<-reshape(df,varying=list(x=c("x1","x2")),direction="long")
>   boxplot(x1~interaction(time,g),data=ddf)
>This labels the x-axis "1.0" "2.0" "1.1" "2.1"
>
>
>	-thomas


After seeing Thomas' reply, I realized that my prior approach is not
correct.

Building on Thomas' reply and to address color and box groupings if
you desire, the following will cycle through three colors, one for
each letter group. It will also group each variable based upon the a,
b and c groups. This incorporates my prior thought on boxplot
groupings and x axis labeling.

I adjusted Thomas' df to contain a grp column with three grps: a
(red), b (yellow), and c (green).  

So:

df <- data.frame(v1 = rnorm(100), v2 = rnorm(100), 
                 v3 = rnorm(100), grp = rep(letters[1:3],100))

# Define 'at' argument positions. There will be 9 boxes generated
# by the boxplot() call normally centered on x axis1:9. 
# Using 'at', you can reconfigure these.
# Note that the center boxes for each variable
# are at x axis 2, 5 and 8. The other two bars are offset by 0.5
# before and after the center box.

at = c(1.5, 2.0, 2.5, 4.5, 5.0, 5.5, 7.5, 8.0, 8.5)

# Generate plots as per Thomas' example, cycling colors and box
# positions. Set boxwex for thin boxes. Do not draw axes.

boxplot(do.call("c",lapply(df[,1:3],function(v) split(v,df$g))), 
        col = c("red", "yellow", "green"), boxwex = 0.2, at = at, 
        axes = FALSE)

# Draw y axis
axis(2)

# Draw x axis, creating letter labels below each box
axis(1, labels = rep(letters[1:3], 3), at = at)

# Now label each group of 3 boxes with the varname in the middle
# of each grouping.

mtext(side = 1, line = 3, c("V1", "V2", "V3"), at = c(2, 5, 8))

# Draw box around the whole plot

box()

The values for 'at', 'col' and 'boxwex' would of course need to be
adjusted for your actual number of variables, as would the range of
columns in the lapply() call that Thomas had first incorporated.

Sorry for my confusion earlier and hope that this helps.

Regards,

Marc Schwartz


From fharrell at virginia.edu  Sat Mar 15 02:55:55 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 14 Mar 2003 20:55:55 -0500
Subject: [R] Keywords
Message-ID: <20030314205555.02ecb273.fharrell@virginia.edu>

In trying to get R CMD check to run for Hmisc and Design, I get a lot of warnings about key words that are not defined to R.  Is there now a way to add new key words to the master list, or to have a local list that is concatenated to the master?  If there is no way to do this, I assume that the use of non-standard keywords will not disqualify a package from CRAN.

Here are some of the keywords used in my packages:

bootstrap, power (power and sample size calculations), dstudy (study design), trellis, grouping, sampling, accuracy (model predictive accuracy), overview, validate (model validation), lrm (logistic regression model)

Thanks,
Frank
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From rg117 at yahoo.co.uk  Sat Mar 15 02:56:29 2003
From: rg117 at yahoo.co.uk (=?iso-8859-1?q?Rishabh=20Gupta?=)
Date: Sat, 15 Mar 2003 01:56:29 +0000 (GMT)
Subject: [R] boxplots with multiple numerical variables
In-Reply-To: <002e01c2ea92$43de6b90$0201a8c0@MARC>
Message-ID: <20030315015629.47398.qmail@web41111.mail.yahoo.com>

Hi,
 I just tried both of the solutions that you provided. They are perfect, exacrly what I was
looking. Many Thanks four your help, I appreciate it.

Rishabh
 --- Marc Schwartz <mschwartz at medanalytics.com> wrote: > >-----Original Message-----
> >From: r-help-bounces at stat.math.ethz.ch 
> >[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Thomas Lumley
> >Sent: Friday, March 14, 2003 4:36 PM
> >To: Rishabh Gupta
> >Cc: r-help at stat.math.ethz.ch
> >Subject: Re: [R] boxplots with multiple numerical variables
> >
> >
> >On Fri, 14 Mar 2003, [iso-8859-1] Rishabh Gupta wrote:
> >
> >> Hi all,
> >>    I have a question regarding the boxplot function. The data I am 
> >> working on has 1 grouping variable (G) and it has many numerical 
> >> variables (V1, V2, V3, V4, Vx, etc). What I would like to do 
> >is create 
> >> a boxplot where the Y-axis represents the numerical values 
> >of variable 
> >> V1...Vx (all the variables have the same range). The X-axis needs
> to 
> >> represent the G-V combination. So suppose the possible values for G
> 
> >> are a, b and c, Then along the x-axis there would be a boxplot for 
> >> each of the combinations:
> >>
> >>   V1Ga, V1Gb, V1Gc, V2Ga, V2Gb, V2Gc, V3Ga, V3Gb, V3Gc,.....VxGa, 
> >> VxGb, VxGc, etc ie
> >>   all values of V1 where the G values are a, all values of V1 where
> 
> >> the G values are b, etc In addition, if possible, it would 
> >be nice if 
> >> each G value would have a a different colour on the plot so 
> >that they 
> >> could be seen more clearly.
> >>
> >> I'm not sure whether such a function already exists within R or 
> >> whether it would have to be written. Either way, I would 
> >appreciate it 
> >> very much if somebody could help and give me some advice as to how
> I 
> >> can achieve this.
> >>
> >
> >I'm going to work with a data frame that has two variables and 
> >a binary grouping factor
> >
> >df<-data.frame(x1=rnorm(100),x2=rnorm(100),g=rep(0:1,50))
> >
> >
> >There's at least two ways to do this.  boxplot() will take a 
> >list of vectors and do boxplots of them, so we can split() 
> >each of the vectors
> >   lapply(df[,1:2], function(v) split(v, df$g))
> >and then combine them into a single list with do.call("c",)
> >and then boxplot() them. That is:
> >   boxplot(do.call("c",lapply(df[,1:2],function(v) 
> >split(v,df$g)))) This labels the x-axis "x1.0" "x1.1", "x2.0", "x2.1"
> >
> >
> >We can also do the opposite: combine the vectors into a single 
> >variable, add a new factor indicating which vector each 
> >observation came from, and use boxplot() with a formula.
> >   ddf<-reshape(df,varying=list(x=c("x1","x2")),direction="long")
> >   boxplot(x1~interaction(time,g),data=ddf)
> >This labels the x-axis "1.0" "2.0" "1.1" "2.1"
> >
> >
> >	-thomas
> 
> 
> After seeing Thomas' reply, I realized that my prior approach is not
> correct.
> 
> Building on Thomas' reply and to address color and box groupings if
> you desire, the following will cycle through three colors, one for
> each letter group. It will also group each variable based upon the a,
> b and c groups. This incorporates my prior thought on boxplot
> groupings and x axis labeling.
> 
> I adjusted Thomas' df to contain a grp column with three grps: a
> (red), b (yellow), and c (green).  
> 
> So:
> 
> df <- data.frame(v1 = rnorm(100), v2 = rnorm(100), 
>                  v3 = rnorm(100), grp = rep(letters[1:3],100))
> 
> # Define 'at' argument positions. There will be 9 boxes generated
> # by the boxplot() call normally centered on x axis1:9. 
> # Using 'at', you can reconfigure these.
> # Note that the center boxes for each variable
> # are at x axis 2, 5 and 8. The other two bars are offset by 0.5
> # before and after the center box.
> 
> at = c(1.5, 2.0, 2.5, 4.5, 5.0, 5.5, 7.5, 8.0, 8.5)
> 
> # Generate plots as per Thomas' example, cycling colors and box
> # positions. Set boxwex for thin boxes. Do not draw axes.
> 
> boxplot(do.call("c",lapply(df[,1:3],function(v) split(v,df$g))), 
>         col = c("red", "yellow", "green"), boxwex = 0.2, at = at, 
>         axes = FALSE)
> 
> # Draw y axis
> axis(2)
> 
> # Draw x axis, creating letter labels below each box
> axis(1, labels = rep(letters[1:3], 3), at = at)
> 
> # Now label each group of 3 boxes with the varname in the middle
> # of each grouping.
> 
> mtext(side = 1, line = 3, c("V1", "V2", "V3"), at = c(2, 5, 8))
> 
> # Draw box around the whole plot
> 
> box()
> 
> The values for 'at', 'col' and 'boxwex' would of course need to be
> adjusted for your actual number of variables, as would the range of
> columns in the lapply() call that Thomas had first incorporated.
> 
> Sorry for my confusion earlier and hope that this helps.
> 
> Regards,
> 
> Marc Schwartz
> 
>  

__________________________________________________

Everything you'll ever need on one web page
from News and Sport to Email and Music Charts


From ripley at stats.ox.ac.uk  Sat Mar 15 04:32:38 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 15 Mar 2003 03:32:38 +0000 (GMT)
Subject: [R] Help with reading data
In-Reply-To: <20030315001414.17061.qmail@web14005.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0303150327530.10857-100000@gannet.stats>

On Fri, 14 Mar 2003, Nirvan Sunderam wrote:

> 
> everytime i try to read in data i get the following error:
> 
> Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  : 
>         line 3 did not have 5 elements
> 
> 
> it was my understanding it wasn't necessary to specifiy all defaults. The bizarre thing is this error comes from using read.table.

> When I use scan I get the following error:
> 
> Error in scan("tree.dat") : "scan" expected a real, got "<!DOCTYPE"

You appear to be trying to read an HTML (or perhaps XML or SGML) file.  
That's unlikely to be in any of the formats R can read.  Have you
downloaded this from the web and saved in the wrong format?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Mar 15 04:52:54 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 15 Mar 2003 03:52:54 +0000 (GMT)
Subject: [R] Keywords
In-Reply-To: <20030314205555.02ecb273.fharrell@virginia.edu>
Message-ID: <Pine.LNX.4.44.0303150335050.10857-100000@gannet.stats>

[This sort of question might be better on R-devel.]

On Fri, 14 Mar 2003, Frank E Harrell Jr wrote:

> In trying to get R CMD check to run for Hmisc and Design, I get a 
lot of warnings about key words that are not defined to R.  
Is there now a way to add new key words to the master list, or to 
have a local list that is concatenated to the master?

There is no way. The primary use for the list of keywords is the Java
search engine in HTML, and that uses a static list generated from the
KEYWORDS file at R build time.  That makes it a good idea to use at least 
one of the standard keywords, and makes using others of little value.
(But not zero value: keywords are used in the refman.pdf although I think 
that is not much used.)

> If there is no way to do this, I assume that the use of non-standard
keywords will not disqualify a package from CRAN.

Ask the CRAN maintainers?

> Here are some of the keywords used in my packages:
> 
> bootstrap, power (power and sample size calculations), dstudy (study design), trellis, grouping, sampling, accuracy (model predictive accuracy), overview, validate (model validation), lrm (logistic regression model)
> 
> Thanks,
> Frank
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From laurent at cbs.dtu.dk  Sat Mar 15 11:09:48 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Sat, 15 Mar 2003 11:09:48 +0100
Subject: [R] 
	configure, IBM AIX and checking whether leap seconds are treated
	according to POSIX...
Message-ID: <20030315100948.GA2656994@genome.cbs.dtu.dk>

Hi,

I am trying to compile R for 64 bits on a mainframe running
IBM AIX. Setting the environment variable OBJECT_MODE=64
leads to hanging while checking whether leap seconds are treated according to POSIX...
Interestingly, it works fine when OBJECT_MODE=32...

Any pointer would help me much...


Thanks,



L.


-- 
--------------------------------------------------------------
currently at the National Yang-Ming University in Taipei, Taiwan
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent


From l12345p2000 at yahoo.com  Sat Mar 15 15:22:16 2003
From: l12345p2000 at yahoo.com (Peng)
Date: Sat, 15 Mar 2003 06:22:16 -0800 (PST)
Subject: [R] 
	formula, how to express for transforming the whole model.matrix,
	data=Orthodont
Message-ID: <20030315142216.18836.qmail@web21006.mail.yahoo.com>

Hi, R or S+ users,

I want to make a simple transformation for the model,
but for the whole design matrix.
The model is distance ~ age * Sex, where Sex is a
factor. So the design matrix may look like the
following:
    (Intercept) age SexFemale age:SexFemale
1             1   8         0             0
2             1  10         0             0
3             1  12         0             0
4             1  14         0             0
5             1   8         0             0
6             1  10         0             0
7             1  12         0             0
8             1  14         0             0
... 
101           1   8         1             8
102           1  10         1            10
103           1  12         1            12
104           1  14         1            14
105           1   8         1             8
106           1  10         1            10
107           1  12         1            12
108           1  14         1            14

I want to have the whole design matrix transformed by
a vector of multiplicator, say c(m1, m2, m3, ... ,
m26, m27 ), for each Subject. Then the design matrix
will look like this.
    (Intercept)    age SexFemale age:SexFemale
1            m1    8m1         0             0
2            m1   10m1         0             0
3            m1   12m1         0             0
4            m1   14m1         0             0
5            m2    8m2         0             0
6            m2   10m2         0             0
7            m2   12m2         0             0
8            m2   14m2         0             0
... 
101         m26   8m26       m26          8m26
102         m26  10m26       m26         10m26
103         m26  12m26       m26         12m26
104         m26  14m26       m26         14m26
105         m27   8m27       m27          8m27
106         m27  10m27       m27         10m27
107         m27  12m27       m27         12m27
108         m27  14m27       m27         14m27

I tried to add a new column in the data, say "m". But
the following formula expression does not work. Since
Sex is a factor.
y ~ m + I(m*age) + I(m*Sex) + I(m*age*Sex)
Moreover, in order to implement the EM from "Robust
Estimation in Linear Mixed-Effects Models
Using the Multivariate t-Distribution" by Dr.
Pinheiro, I also need to transform the response, y, in
the same way. 
I did it by writing SAS liked codes (making a new
table, coding factors, finishing transformation,
making groupedData, call lme), but that is not
readable, and it will be complicated to realized that
for any other datasets.

I am wondering whether the formula has some sorts of
expression to realize transformation for the whole
design matrix, especially when having factors in the
formula.

Thanks a lot!

Peng

Peng Liu
------------------------------
Peng Liu                      |
Division of Statistics        |
Northern Illinois University  |
De Kalb, IL 60115, USA        |
E-mail: pliu at math.niu.edu     |
------------------------------


From juli at ceam.es  Sat Mar 15 17:53:43 2003
From: juli at ceam.es (juli g. pausas)
Date: Sat, 15 Mar 2003 17:53:43 +0100
Subject: [R] plots to metafile and x/y ratio
Message-ID: <3E735A97.9020700@ceam.es>

Dear all,
I have a problem which I'm not sure if it is due to my machine or if I'm 
doing something wrong.

I'm ploting a little map using  plot(val, type="l", asp=1)  where val is 
the object with the latitude/longitude data.
In the screen the figure is perfect, and I can copy to the clipboard and 
paste it to other places. I can also saved using png() or jpeg(), 
althoug the quality is much lower. However when I try to save it as 
metafile (from the plot window or by using win.matafile), the file I 
obtain do not keep the x/y ratio. I'm interested in this metafile 
because the quality in much higher then the png, jpeg.  Any suggestion?

I'm working with R.1.6.1. on Windows.
If somebody is interested, I could send them the files, they are very 
small (45 KB).
Thanks in advance.

Juli


From ripley at stats.ox.ac.uk  Sat Mar 15 19:05:47 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 15 Mar 2003 18:05:47 +0000 (GMT)
Subject: [R] plots to metafile and x/y ratio
In-Reply-To: <3E735A97.9020700@ceam.es>
Message-ID: <Pine.LNX.4.44.0303151709240.16621-100000@gannet.stats>

On Sat, 15 Mar 2003, juli g. pausas wrote:

> I have a problem which I'm not sure if it is due to my machine or if I'm 
> doing something wrong.
> 
> I'm ploting a little map using  plot(val, type="l", asp=1)  where val is 
> the object with the latitude/longitude data.
> In the screen the figure is perfect, and I can copy to the clipboard and 
> paste it to other places. I can also saved using png() or jpeg(), 
> althoug the quality is much lower. However when I try to save it as 
> metafile (from the plot window or by using win.matafile), the file I 
> obtain do not keep the x/y ratio. I'm interested in this metafile 
> because the quality in much higher then the png, jpeg.  Any suggestion?

The quality is even higher in postscript or PDF.

> I'm working with R.1.6.1. on Windows.
> If somebody is interested, I could send them the files, they are very 
> small (45 KB).

You cannot look at a win.metafile (it is a binary file in a proprietary
format); you need an application to display it and there is no reason why
that application should preserve the aspect ratio.  I just tried pasting
into Word, inserting in Word and a clipboard viewer and all preserved the
aspect ratio, but in each case it could be lost by resizing.

What exactly did you do with the metafile?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From juli at ceam.es  Sat Mar 15 19:22:04 2003
From: juli at ceam.es (juli g. pausas)
Date: Sat, 15 Mar 2003 19:22:04 +0100
Subject: [R] plots to metafile and x/y ratio
References: <Pine.LNX.4.44.0303151709240.16621-100000@gannet.stats>
Message-ID: <3E736F4C.9090603@ceam.es>

ripley at stats.ox.ac.uk wrote:

>On Sat, 15 Mar 2003, juli g. pausas wrote:
>
>>I have a problem which I'm not sure if it is due to my machine or if I'm 
>>doing something wrong.
>>
>>I'm ploting a little map using  plot(val, type="l", asp=1)  where val is 
>>the object with the latitude/longitude data.
>>In the screen the figure is perfect, and I can copy to the clipboard and 
>>paste it to other places. I can also saved using png() or jpeg(), 
>>althoug the quality is much lower. However when I try to save it as 
>>metafile (from the plot window or by using win.matafile), the file I 
>>obtain do not keep the x/y ratio. I'm interested in this metafile 
>>because the quality in much higher then the png, jpeg.  Any suggestion?
>>    
>>
>
>The quality is even higher in postscript or PDF.
>
>  
>
>>I'm working with R.1.6.1. on Windows.
>>If somebody is interested, I could send them the files, they are very 
>>small (45 KB).
>>    
>>
>
>You cannot look at a win.metafile (it is a binary file in a proprietary
>format); you need an application to display it and there is no reason why
>that application should preserve the aspect ratio.  I just tried pasting
>into Word, inserting in Word and a clipboard viewer and all preserved the
>aspect ratio, but in each case it could be lost by resizing.
>
>What exactly did you do with the metafile?
>  
>

I visualised the win.metafile files with ACDSee ver 3.0 (with resizing 
options off). Using this application, I see correctly the figure when 
saved as jpg or png file, but I do not see the metafile correctly. It 
may be a feature of the ACDSee.
Thnaks

Juli


From fredrik.lundgren at norrkoping.mail.telia.com  Sat Mar 15 19:47:46 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Sat, 15 Mar 2003 19:47:46 +0100
Subject: [R] Help.start, .Renviron , and .Rprofile
Message-ID: <000d01c2eb23$612e4440$2d0ffea9@oemcomputer>

Hello experienced R-ers,

I'm converting from S-Plus Win 98SE to
SuSE 8.1, R 1.62 and have run into som problems.

1) When I use help.start() netscape comes up OK and all links are accessible except "Search Engine & Keywords" : search doesn't work and the keywords from base doesn't respond either. ?command within R gets netscape running and works OK. 
2) I haven't been able to get Renviron.site, Rprofile.site, .Renviron, and .Rprofile to work and affect my sessions. To the best of my knowledge I have handled these files according to "Invoking R under Unix" in Rintro. .First within R works OK and this is the way I customize R at the present time.

Hopefully someone out there realizes what I'm doing wrong.

Thanks in advance

Sincerely Fredrik Lundgren


From ripley at stats.ox.ac.uk  Sat Mar 15 20:30:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 15 Mar 2003 19:30:05 +0000 (GMT)
Subject: [R] Help.start, .Renviron , and .Rprofile
In-Reply-To: <000d01c2eb23$612e4440$2d0ffea9@oemcomputer>
Message-ID: <Pine.LNX.4.44.0303151927320.31166-100000@gannet.stats>

On Sat, 15 Mar 2003, Fredrik Lundgren wrote:

> Hello experienced R-ers,
> 
> I'm converting from S-Plus Win 98SE to
> SuSE 8.1, R 1.62 and have run into som problems.
> 
> 1) When I use help.start() netscape comes up OK and all links are accessible except "Search Engine & Keywords" : search doesn't work and the keywords from base doesn't respond either. ?command within R gets netscape running and works OK. 

Which netscape is this, what Java do you have installed and is it enabled?
?help.start does contain some details of what you need.

> 2) I haven't been able to get Renviron.site, Rprofile.site, 
.Renviron, and .Rprofile to work and affect my sessions. 
To the best of my knowledge I have handled these files according 
to "Invoking R under Unix" in Rintro. .First within R works OK and 
this is the way I customize R at the present time.

No idea: do the examples in ?Startup work for you?

Please learn to wrap the lines in email messages.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From goedman at pacbell.net  Sat Mar 15 20:49:18 2003
From: goedman at pacbell.net (rob)
Date: Sat, 15 Mar 2003 11:49:18 -0800
Subject: [R] Help.start -
In-Reply-To: <000d01c2eb23$612e4440$2d0ffea9@oemcomputer>
Message-ID: <35CD6FA4-571F-11D7-A246-000393DC5238@pacbell.net>

Hi,

Further on Fredrik's question, I have encountered the same difficulty on
MAC OS X. Neither will clicking on any link work. None of the browsers
seem to work (Safari, Camino, Mozilla, Netscape, IE).

I've tried to set enableSearch tp true, but that does not help either.
 From within R, after help.start() search does not work, but e.g.
help(eigen) does work.

Thanks,
Rob

On Saturday, March 15, 2003, at 10:47 AM, Fredrik Lundgren wrote:

> Hello experienced R-ers,
>
> I'm converting from S-Plus Win 98SE to
> SuSE 8.1, R 1.62 and have run into som problems.
>
> 1) When I use help.start() netscape comes up OK and all links are 
> accessible except "Search Engine & Keywords" : search doesn't work and 
> the keywords from base doesn't respond either. ?command within R gets 
> netscape running and works OK.
> 2) I haven't been able to get Renviron.site, Rprofile.site, .Renviron, 
> and .Rprofile to work and affect my sessions. To the best of my 
> knowledge I have handled these files according to "Invoking R under 
> Unix" in Rintro. .First within R works OK and this is the way I 
> customize R at the present time.
>
> Hopefully someone out there realizes what I'm doing wrong.
>
> Thanks in advance
>
> Sincerely Fredrik Lundgren
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From ripley at stats.ox.ac.uk  Sat Mar 15 21:04:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 15 Mar 2003 20:04:04 +0000 (GMT)
Subject: [R] Help.start, .Renviron , and .Rprofile
In-Reply-To: <Pine.LNX.4.44.0303151927320.31166-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0303151959340.31257-100000@gannet.stats>

On Sat, 15 Mar 2003 ripley at stats.ox.ac.uk wrote:

> On Sat, 15 Mar 2003, Fredrik Lundgren wrote:
> 
> > I'm converting from S-Plus Win 98SE to
> > SuSE 8.1, R 1.62 and have run into som problems.
> > 
> > 1) When I use help.start() netscape comes up OK and all links are accessible except "Search Engine & Keywords" : search doesn't work and the keywords from base doesn't respond either. ?command within R gets netscape running and works OK. 
> 
> Which netscape is this, what Java do you have installed and is it enabled?
> ?help.start does contain some details of what you need.

Sorry, ?browseURL in current R: it has been moved.

Also, you could consult the R-help archives there has been much discussion
of this.  I've never seen a problem recently in RH Linux with a properly
installed Java plugin, but Mozilla in particular had a broken plugin
installation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From fredrik.lundgren at norrkoping.mail.telia.com  Sat Mar 15 21:26:42 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Sat, 15 Mar 2003 21:26:42 +0100
Subject: [R] Help.start, .Renviron , and .Rprofile
In-Reply-To: <Pine.LNX.4.44.0303151959340.31257-100000@gannet.stats>
References: <Pine.LNX.4.44.0303151959340.31257-100000@gannet.stats>
Message-ID: <200303152126.42703.fredrik.lundgren@norrkoping.mail.telia.com>

Thanks to Brain Ripley!

Enabling Java and Java Script under edit/preferences/advanced
fixed the problem with netscape (4.8)  "Search Engine & Keywords".

Fredrik


l?rdagen den 15 mars 2003 21.04 skrev du:
> On Sat, 15 Mar 2003 ripley at stats.ox.ac.uk wrote:
> > On Sat, 15 Mar 2003, Fredrik Lundgren wrote:
> > > I'm converting from S-Plus Win 98SE to
> > > SuSE 8.1, R 1.62 and have run into som problems.
> > >
> > > 1) When I use help.start() netscape comes up OK and all links are
> > > accessible except "Search Engine & Keywords" : search doesn't work and
> > > the keywords from base doesn't respond either. ?command within R gets
> > > netscape running and works OK.
> >
> > Which netscape is this, what Java do you have installed and is it
> > enabled? ?help.start does contain some details of what you need.
>
> Sorry, ?browseURL in current R: it has been moved.
>
> Also, you could consult the R-help archives there has been much discussion
> of this.  I've never seen a problem recently in RH Linux with a properly
> installed Java plugin, but Mozilla in particular had a broken plugin
> installation.


From rnassar at duke.edu  Sat Mar 15 22:53:48 2003
From: rnassar at duke.edu (Rashid Nassar)
Date: Sat, 15 Mar 2003 16:53:48 -0500 (EST)
Subject: [R] round() seems inconsistent when  rounding 5s
Message-ID: <Pine.GSO.4.53.0303151652170.1572@godzilla2.acpub.duke.edu>

It may be my lack of unerstanding, but round() seems to me to give
inconsistent results when rounding 5s as in the following examples?

> round(1.45, 1)
[1] 1.4               # OK

> round(2.45, 1)
[1] 2.5               # shouldn't this be 2.4?

> round(1.05, 1)
[1] 1.1               #  1.0 ?

and signif():

> signif(2.445, 3)
[1] 2.44             # OK

> signif(3.445, 3)
[1] 3.45             # 3.44 ?


> version
         _
platform i586-pc-linux-gnu
arch     i586
os       linux-gnu
system   i586, linux-gnu
status
major    1
minor    6.2
year     2003
month    01
day      10
language R

Many thanks!

Rashid Nassar


From spencer.graves at pdf.com  Sat Mar 15 23:35:40 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 15 Mar 2003 14:35:40 -0800
Subject: [R] round() seems inconsistent when  rounding 5s
References: <Pine.GSO.4.53.0303151652170.1572@godzilla2.acpub.duke.edu>
Message-ID: <3E73AABC.90801@pdf.com>

Consider the following:
 > tst <- .5-1e-9
 > tst
[1] 0.5
 > round(tst)
[1] 0
 > tst1 <- .5+1e-9
 > tst1
[1] 0.5
 > round(tst1)
[1] 1

Does this answer the question?
Spencer Graves
####################################################
Rashid Nassar wrote:
> It may be my lack of unerstanding, but round() seems to me to give
> inconsistent results when rounding 5s as in the following examples?
> 
> 
>>round(1.45, 1)
> 
> [1] 1.4               # OK
> 
> 
>>round(2.45, 1)
> 
> [1] 2.5               # shouldn't this be 2.4?
> 
> 
>>round(1.05, 1)
> 
> [1] 1.1               #  1.0 ?
> 
> and signif():
> 
> 
>>signif(2.445, 3)
> 
> [1] 2.44             # OK
> 
> 
>>signif(3.445, 3)
> 
> [1] 3.45             # 3.44 ?
> 
> 
> 
>>version
> 
>          _
> platform i586-pc-linux-gnu
> arch     i586
> os       linux-gnu
> system   i586, linux-gnu
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R
> 
> Many thanks!
> 
> Rashid Nassar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From feldesmanm at pdx.edu  Sat Mar 15 23:49:05 2003
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Sat, 15 Mar 2003 14:49:05 -0800
Subject: [R] round() seems inconsistent when  rounding 5s
In-Reply-To: <Pine.GSO.4.53.0303151652170.1572@godzilla2.acpub.duke.edu>
Message-ID: <5.2.0.9.2.20030315144532.015d09d0@pop4.attglobal.net>

At 01:53 PM 3/15/2003, Rashid Nassar wrote:
 >It may be my lack of unerstanding, but round() seems to me to give
 >inconsistent results when rounding 5s as in the following examples?

Not really.  Floating point numbers can't be precisely represented in 
binary and so the internal representation of 1.5 might be very different 
from what you think it is.  If you've done any programming at all, this is 
one of the first lessons you learn about "real" numbers and computers.


Dr. Marc R. Feldesman
Professor and Chairman Emeritus
Anthropology Department - Portland State University
email:  feldesmanm at pdx.edu
email:  feldesman at attglobal.net
fax:    503-725-3905


"Sometimes the lights are all shining on me, other times I can barely see,
lately it's occurred to me, what a long strange trip it's been..."  Jerry &
the boys


From gregory_r_warnes at groton.pfizer.com  Sun Mar 16 00:14:54 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Sat, 15 Mar 2003 18:14:54 -0500
Subject: [R] round() seems inconsistent when  rounding 5s
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C704@groexmb02.pfizer.com>

Actually, under the default IEEE rounding mode, decimal values ending in 5
are always rounded to the nearest even value.   This intended to ensure that
rounding does not systematically bias computations in one direction, as
would happen if 5's were always rounded either up or down.

A very useful review of the issues in floating point computations on
computer and under IEEE standard arithmetic is the paper "What Every
Computer Scientist Should Know About Floating-Point Arithmetic", by David
Goldberg, published in the March, 1991 issue of Computing Surveys.  This
paper is reprinted on the Sun website at
http://docs.sun.com/source/806-3568/ncg_goldberg.html.

-Greg

> -----Original Message-----
> From: Marc R. Feldesman [mailto:feldesmanm at pdx.edu]
> Sent: Saturday, March 15, 2003 5:49 PM
> To: Rashid Nassar; r-help
> Subject: Re: [R] round() seems inconsistent when rounding 5s
> 
> 
> At 01:53 PM 3/15/2003, Rashid Nassar wrote:
>  >It may be my lack of unerstanding, but round() seems to me to give
>  >inconsistent results when rounding 5s as in the following examples?
> 
> Not really.  Floating point numbers can't be precisely represented in 
> binary and so the internal representation of 1.5 might be 
> very different 
> from what you think it is.  If you've done any programming at 
> all, this is 
> one of the first lessons you learn about "real" numbers and computers.
> 
> 
> Dr. Marc R. Feldesman
> Professor and Chairman Emeritus
> Anthropology Department - Portland State University
> email:  feldesmanm at pdx.edu
> email:  feldesman at attglobal.net
> fax:    503-725-3905
> 
> 
> "Sometimes the lights are all shining on me, other times I 
> can barely see,
> lately it's occurred to me, what a long strange trip it's 
> been..."  Jerry &
> the boys
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... [[dropped]]


From rnassar at duke.edu  Sun Mar 16 01:34:43 2003
From: rnassar at duke.edu (Rashid Nassar)
Date: Sat, 15 Mar 2003 19:34:43 -0500 (EST)
Subject: [R] round() seems inconsistent when  rounding 5s
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C202F2C704@groexmb02.pfizer.com>
References: <D7A3CFD7825BD6119B880002A58F06C202F2C704@groexmb02.pfizer.com>
Message-ID: <Pine.GSO.4.53.0303151920420.27924@godzilla4.acpub.duke.edu>

Many thanks to all for the very quick replies.  I should have stated the
apparent problem more clearly: round() does not seem to always round 5 to
the nearest even value as I expected, as my examples (repeated below)
showed:

> round(2.45, 1)
[1] 2.5               # shouldn't this be 2.4?

> round(1.05, 1)
[1] 1.1               #  1.0 ?

> signif(3.445, 3)
[1] 3.45             # 3.44 ?

Apologies for not stating this more clearly in my first message, and again
thanks for the replies.

Rashid Nassar



On Sat, 15 Mar 2003, Warnes, Gregory R wrote:

> Actually, under the default IEEE rounding mode, decimal values ending in 5
> are always rounded to the nearest even value.   This intended to ensure that
> rounding does not systematically bias computations in one direction, as
> would happen if 5's were always rounded either up or down.
>
> A very useful review of the issues in floating point computations on
> computer and under IEEE standard arithmetic is the paper "What Every
> Computer Scientist Should Know About Floating-Point Arithmetic", by David
> Goldberg, published in the March, 1991 issue of Computing Surveys.  This
> paper is reprinted on the Sun website at
> http://docs.sun.com/source/806-3568/ncg_goldberg.html.
>
> -Greg
>
> > -----Original Message-----
> > From: Marc R. Feldesman [mailto:feldesmanm at pdx.edu]
> > Sent: Saturday, March 15, 2003 5:49 PM
> > To: Rashid Nassar; r-help
> > Subject: Re: [R] round() seems inconsistent when rounding 5s
> >
> >
> > At 01:53 PM 3/15/2003, Rashid Nassar wrote:
> >  >It may be my lack of unerstanding, but round() seems to me to give
> >  >inconsistent results when rounding 5s as in the following examples?
> >
> > Not really.  Floating point numbers can't be precisely represented in
> > binary and so the internal representation of 1.5 might be
> > very different
> > from what you think it is.  If you've done any programming at
> > all, this is
> > one of the first lessons you learn about "real" numbers and computers.
> >
> >
> > Dr. Marc R. Feldesman
> > Professor and Chairman Emeritus
> > Anthropology Department - Portland State University
> > email:  feldesmanm at pdx.edu
> > email:  feldesman at attglobal.net
> > fax:    503-725-3905
> >
> >
> > "Sometimes the lights are all shining on me, other times I
> > can barely see,
> > lately it's occurred to me, what a long strange trip it's
> > been..."  Jerry &
> > the boys
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>
> LEGAL NOTICE
> Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
>


From p.dalgaard at biostat.ku.dk  Sun Mar 16 02:28:34 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 16 Mar 2003 02:28:34 +0100
Subject: [R] round() seems inconsistent when  rounding 5s
In-Reply-To: <Pine.GSO.4.53.0303151920420.27924@godzilla4.acpub.duke.edu>
References: <D7A3CFD7825BD6119B880002A58F06C202F2C704@groexmb02.pfizer.com>
	<Pine.GSO.4.53.0303151920420.27924@godzilla4.acpub.duke.edu>
Message-ID: <x2k7f0ksl9.fsf@biostat.ku.dk>

Rashid Nassar <rnassar at duke.edu> writes:

> Many thanks to all for the very quick replies.  I should have stated the
> apparent problem more clearly: round() does not seem to always round 5 to
> the nearest even value as I expected, as my examples (repeated below)
> showed:
> 
> > round(2.45, 1)
> [1] 2.5               # shouldn't this be 2.4?
> 
> > round(1.05, 1)
> [1] 1.1               #  1.0 ?
> 
> > signif(3.445, 3)
> [1] 3.45             # 3.44 ?
> 
> Apologies for not stating this more clearly in my first message, and again
> thanks for the replies.

Yes. From my reading of the code, I would expect 2.4 in the first case
as well. It appears that the intention is to subtract off the integer
part, scale according to the number of digits and round nnn.5 +- eps
towards even values of nnn, but that's not what is happening. 

Anyone want to trace through the code and see what is going on?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Sun Mar 16 08:54:09 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 16 Mar 2003 07:54:09 +0000 (GMT)
Subject: [R] round() seems inconsistent when  rounding 5s
In-Reply-To: <x2k7f0ksl9.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0303160733270.5471-100000@gannet.stats>

On 16 Mar 2003, Peter Dalgaard BSA wrote:

> Rashid Nassar <rnassar at duke.edu> writes:
> 
> > Many thanks to all for the very quick replies.  I should have stated the
> > apparent problem more clearly: round() does not seem to always round 5 to
> > the nearest even value as I expected, as my examples (repeated below)
> > showed:
> > 
> > > round(2.45, 1)
> > [1] 2.5               # shouldn't this be 2.4?
> > 
> > > round(1.05, 1)
> > [1] 1.1               #  1.0 ?
> > 
> > > signif(3.445, 3)
> > [1] 3.45             # 3.44 ?
> > 
> > Apologies for not stating this more clearly in my first message, and again
> > thanks for the replies.
> 
> Yes. From my reading of the code, I would expect 2.4 in the first case
> as well. It appears that the intention is to subtract off the integer
> part, scale according to the number of digits and round nnn.5 +- eps
> towards even values of nnn, but that's not what is happening. 
> 
> Anyone want to trace through the code and see what is going on?

As people have already suggested, inexact representation.

2.45 is being represented as 2.4500000000000002 on my system when printed
out from the C code in fround.  It is not a binary fraction and so cannot
be represented exactly (in standard hardware).  The calculation does (2.45
- 2)*10 and rounds it, and that is just greater than 4.5 (which could be
represented exactly).

Try this:

> x <- 2.45
> (100*x - 245)
[1] 2.842171e-14

which is fairly firm evidence that the representation error is positive, 
as multiplication by 100 should be exact.  Note though that the print 
routine will multiply by powers of 10 so the only sure way is to read the 
bit pattern and compute exactly from that.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Sun Mar 16 11:36:43 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 16 Mar 2003 11:36:43 +0100
Subject: [R] round() seems inconsistent when  rounding 5s
In-Reply-To: <Pine.LNX.4.44.0303160733270.5471-100000@gannet.stats>
References: <Pine.LNX.4.44.0303160733270.5471-100000@gannet.stats>
Message-ID: <x27kazlhs4.fsf@biostat.ku.dk>

ripley at stats.ox.ac.uk writes:

> As people have already suggested, inexact representation.
> 
> 2.45 is being represented as 2.4500000000000002 on my system when printed
> out from the C code in fround.  It is not a binary fraction and so cannot
> be represented exactly (in standard hardware).  The calculation does (2.45
> - 2)*10 and rounds it, and that is just greater than 4.5 (which could be
> represented exactly).
> 
> Try this:
> 
> > x <- 2.45
> > (100*x - 245)
> [1] 2.842171e-14
> 
> which is fairly firm evidence that the representation error is positive, 
> as multiplication by 100 should be exact.  Note though that the print 
> routine will multiply by powers of 10 so the only sure way is to read the 
> bit pattern and compute exactly from that.

Ah, I see now. What I saw before was 

        ltmp = x + 0.5;
        /* implement round to even */
        if(fabs(x + 0.5 - ltmp) < 10*DBL_EPSILON
           && (ltmp % 2 == 1)) ltmp--;
        tmp = ltmp;

but that code sits inside

#ifdef USE_BUILTIN_RINT

and if that's not on we get the system rint() which very likely
will not care about using fuzz.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From mihastaut at hotmail.com  Sun Mar 16 12:49:25 2003
From: mihastaut at hotmail.com (Miha STAUT)
Date: Sun, 16 Mar 2003 11:49:25 +0000
Subject: [R] xgobi?
Message-ID: <BAY2-F120MZqasBVqbO0006059f@hotmail.com>

Hi all,

As far as I understood from the documentation of xgobi. The package is 
intended to plot data in 3D (and more). Why if I enter example(xgobi) 
nothing displays even though the example calls also the xgobi command (yes I 
did load the library)? Do I need to install anything else for xgobi to work? 
I use R 1.6.1. on Windows 2000 platform or R 1.5.1 with RedHat 7.3 (none 
works).

Miha


From ligges at statistik.uni-dortmund.de  Sun Mar 16 13:05:17 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 16 Mar 2003 13:05:17 +0100
Subject: [R] xgobi?
In-Reply-To: <BAY2-F120MZqasBVqbO0006059f@hotmail.com>
References: <BAY2-F120MZqasBVqbO0006059f@hotmail.com>
Message-ID: <3E74687D.6010507@statistik.uni-dortmund.de>

Miha STAUT wrote:
> Hi all,
> 
> As far as I understood from the documentation of xgobi. The package is 
> intended to plot data in 3D (and more). Why if I enter example(xgobi) 
> nothing displays even though the example calls also the xgobi command 
> (yes I did load the library)? Do I need to install anything else for 
> xgobi to work? I use R 1.6.1. on Windows 2000 platform or R 1.5.1 with 
> RedHat 7.3 (none works).
> 
> Miha

 From library(help=xgobi):
"Suggests: xgobi must be installed additionally, see file INSTALL."
For the Windows version: Do you have adapted the *.bat file?
For Linux: Is xgobi in your search path?

Uwe Ligges


From baron at cattell.psych.upenn.edu  Sun Mar 16 13:08:35 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sun, 16 Mar 2003 07:08:35 -0500
Subject: [R] xgobi?
In-Reply-To: <BAY2-F120MZqasBVqbO0006059f@hotmail.com>;
	from mihastaut@hotmail.com on Sun, Mar 16, 2003 at 11:49:25AM +0000
References: <BAY2-F120MZqasBVqbO0006059f@hotmail.com>
Message-ID: <20030316070835.A13528@cattell.psych.upenn.edu>

On 03/16/03 11:49, Miha STAUT wrote:
>Hi all,
>
>As far as I understood from the documentation of xgobi. The package is 
>intended to plot data in 3D (and more). Why if I enter example(xgobi) 
>nothing displays even though the example calls also the xgobi command (yes I 
>did load the library)? Do I need to install anything else for xgobi to work? 
>I use R 1.6.1. on Windows 2000 platform or R 1.5.1 with RedHat 7.3 (none 
>works).

Perhaps the documentation of the xgobi library could be clearer,
but it does say (in the xgobi function):

"The R function xgobi executes a call to the C program of the same
name, an interactive statistical graphics program which runs
under the X Window System, and returns control of the R command
line to the user."

And then, under "References" it gives links to where you can get
the xgobi program itself.  You don't mention having installed the
program, so that is probably your problem.  It does work with R
1.6.1 on RH Linux 7.3.

(BTW, it is easy to update R.  The RPM for 1.6.1 is available on
CRAN, although it was never formally announced, as I recall.)

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
Psychology webmaster: http://www.psych.upenn.edu/
R page:               http://finzi.psych.upenn.edu/
Questionnaires:       http://www.psych.upenn.edu/~baron/qs.html


From kjetil at entelnet.bo  Sun Mar 16 13:39:35 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sun, 16 Mar 2003 08:39:35 -0400
Subject: [R] 	formula, how to express for transforming the whole
	model.matrix,	data=Orthodont
In-Reply-To: <20030315142216.18836.qmail@web21006.mail.yahoo.com>
Message-ID: <3E743847.32608.4AF4C8@localhost>

On 15 Mar 2003 at 6:22, Peng wrote:

I don't know of a way to do this with formulas. 
But what you want to do is simply multiply each row
of a numeric matrix (doesn't matter that the matrix was formed by 
a call to model.matrix) with a number, which for row i
can be taken as element i of a vector. 

This is the same as premultiply the matrix with a diagonal matrix 
with the constants on the diagonal, but that is not a good way to 
implement it!

I cannot see anything simpler/faster than a simple for loop:

> age <- round(runif(20,3,15))
> age
 [1]  8 14  8  4  5 10  4 13 13 11 13 15  6 15 10  4 14  5  9 13
> sex <- factor(rep(c("F","M"),10))
> sex
 [1] F M F M F M F M F M F M F M F M F M F M
Levels: F M
> mm <- model.matrix(~age*sex)
> mm
   (Intercept) age sexM age:sexM
1            1   8    0        0
2            1  14    1       14
3            1   8    0        0
4            1   4    1        4
5            1   5    0        0
6            1  10    1       10
7            1   4    0        0
8            1  13    1       13
9            1  13    0        0
10           1  11    1       11
11           1  13    0        0
12           1  15    1       15
13           1   6    0        0
14           1  15    1       15
15           1  10    0        0
16           1   4    1        4
17           1  14    0        0
18           1   5    1        5
19           1   9    0        0
20           1  13    1       13
attr(,"assign")
[1] 0 1 2 3
attr(,"contrasts")
attr(,"contrasts")$sex
[1] "contr.treatment"

> c <- 1:20
> for (i in 1:20) {
+      mm[i,] <- mm[i,]*c[i]}
> mm
   (Intercept) age sexM age:sexM
1            1   8    0        0
2            2  28    2       28
3            3  24    0        0
4            4  16    4       16
5            5  25    0        0
6            6  60    6       60
7            7  28    0        0
8            8 104    8      104
9            9 117    0        0
10          10 110   10      110
11          11 143    0        0
12          12 180   12      180
13          13  78    0        0
14          14 210   14      210
15          15 150    0        0
16          16  64   16       64
17          17 238    0        0
18          18  90   18       90
19          19 171    0        0
20          20 260   20      260
attr(,"assign")
[1] 0 1 2 3
attr(,"contrasts")
attr(,"contrasts")$sex
[1] "contr.treatment"


Kjetil Halvorsen

> Hi, R or S+ users,
> 
> I want to make a simple transformation for the model,
> but for the whole design matrix.
> The model is distance ~ age * Sex, where Sex is a
> factor. So the design matrix may look like the
> following:
>     (Intercept) age SexFemale age:SexFemale
> 1             1   8         0             0
> 2             1  10         0             0
> 3             1  12         0             0
> 4             1  14         0             0
> 5             1   8         0             0
> 6             1  10         0             0
> 7             1  12         0             0
> 8             1  14         0             0
> ... 
> 101           1   8         1             8
> 102           1  10         1            10
> 103           1  12         1            12
> 104           1  14         1            14
> 105           1   8         1             8
> 106           1  10         1            10
> 107           1  12         1            12
> 108           1  14         1            14
> 
> I want to have the whole design matrix transformed by
> a vector of multiplicator, say c(m1, m2, m3, ... ,
> m26, m27 ), for each Subject. Then the design matrix
> will look like this.
>     (Intercept)    age SexFemale age:SexFemale
> 1            m1    8m1         0             0
> 2            m1   10m1         0             0
> 3            m1   12m1         0             0
> 4            m1   14m1         0             0
> 5            m2    8m2         0             0
> 6            m2   10m2         0             0
> 7            m2   12m2         0             0
> 8            m2   14m2         0             0
> ... 
> 101         m26   8m26       m26          8m26
> 102         m26  10m26       m26         10m26
> 103         m26  12m26       m26         12m26
> 104         m26  14m26       m26         14m26
> 105         m27   8m27       m27          8m27
> 106         m27  10m27       m27         10m27
> 107         m27  12m27       m27         12m27
> 108         m27  14m27       m27         14m27
> 
> I tried to add a new column in the data, say "m". But
> the following formula expression does not work. Since
> Sex is a factor.
> y ~ m + I(m*age) + I(m*Sex) + I(m*age*Sex)
> Moreover, in order to implement the EM from "Robust
> Estimation in Linear Mixed-Effects Models
> Using the Multivariate t-Distribution" by Dr.
> Pinheiro, I also need to transform the response, y, in
> the same way. 
> I did it by writing SAS liked codes (making a new
> table, coding factors, finishing transformation,
> making groupedData, call lme), but that is not
> readable, and it will be complicated to realized that
> for any other datasets.
> 
> I am wondering whether the formula has some sorts of
> expression to realize transformation for the whole
> design matrix, especially when having factors in the
> formula.
> 
> Thanks a lot!
> 
> Peng
> 
> Peng Liu
> ------------------------------
> Peng Liu                      |
> Division of Statistics        |
> Northern Illinois University  |
> De Kalb, IL 60115, USA        |
> E-mail: pliu at math.niu.edu     |
> ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rjporter at mindspring.com  Sun Mar 16 14:38:19 2003
From: rjporter at mindspring.com (Bob Porter)
Date: Sun, 16 Mar 2003 08:38:19 -0500
Subject: [R] scientific notation
Message-ID: <0a5801c2ebc1$4e737480$6601a8c0@HydePark>

If I knew this, I have forgotten it:

Is there a way to force R to forgo use of scientific notation,
e.g. to use  .000029 instead of 2.9e-05?
(Aside from using formatC for example)
I run across this every now and then and work around it (multiple values by 100,
for example) but cannot find any way to deal with it otherwise.  A particularly
problematic place it pops up is in axis tick labels.  There appears to be no way
to force xx.xx notation...presumably because the width is so great.  Any
suggestions?

-Bob Porter
Tampa


From Ko-Kang at xtra.co.nz  Sun Mar 16 20:00:19 2003
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Mon, 17 Mar 2003 07:00:19 +1200
Subject: [R] xgobi?
References: <BAY2-F120MZqasBVqbO0006059f@hotmail.com>
Message-ID: <001c01c2ebee$4adcbfc0$b92658db@kwan022>

----- Original Message -----
From: "Miha STAUT" <mihastaut at hotmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Sunday, March 16, 2003 11:49 PM
Subject: [R] xgobi?


> Hi all,
>
> As far as I understood from the documentation of xgobi. The package is
> intended to plot data in 3D (and more). Why if I enter example(xgobi)
> nothing displays even though the example calls also the xgobi command (yes
I
> did load the library)? Do I need to install anything else for xgobi to
work?
> I use R 1.6.1. on Windows 2000 platform or R 1.5.1 with RedHat 7.3 (none


Have you installed xgobi itself?  For Linux you can download the source file
at http://www.research.att.com/areas/stat/xgobi/index.html and compile it
yourself.  For Windows you can use (an old version) pre-compiled by Prof.
Brian Ripley at http://www.stats.ox.ac.uk/pub/MASS4/Software.html#XGobi ,
you will also need to have an X-server installed (e.g. XWin 32) on your
machine in order to use it.

Cheers,

K Wang

------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022


From mohamed at engr.uconn.edu  Sun Mar 16 22:12:07 2003
From: mohamed at engr.uconn.edu (Mohamed A. Kerasha)
Date: Sun, 16 Mar 2003 16:12:07 -0500
Subject: [R] KalmanForecast
References: <200302101336.h1ADaVPX025209@thorin.ci.tuwien.ac.at>
Message-ID: <013f01c2ec00$b40189b0$38016389@ipl>

Dear R users,

Is there any exmple (or sample code) on how to use KalmanForecast?

I really appreciate your help,

Thanks,

-Kerasha


From rolf at math.unb.ca  Mon Mar 17 01:39:35 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Sun, 16 Mar 2003 20:39:35 -0400 (AST)
Subject: [R] Error in making R-1.6.2.
Message-ID: <200303170039.h2H0dZ918294@gelfand.math.unb.ca>


I have just tried to update the version of R on our system, and when
I did ``make'', I got the following error message:

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
gcc  -I. -I../../src/include -I../../src/include  -DHAVE_CONFIG_H   -g -O2 -c platform.c -o platform.o
In file included from /usr/include/netinet/in.h:41,
                 from /usr/include/netdb.h:96,
                 from platform.c:1079:
/usr/include/sys/stream.h:307: parse error before "projid_t"
*** Error code 1
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

I looked at the file /usr/include/sys/stream.h and found the
offending line.  It is right at the end of a ``typedef''
construction.  (Whatever that is; I don't speak C.)  I've included
the beginning of this construction in what I've displayed below, so
that you can see ``where things are coming from''.  (???)

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
typedef struct datab {                         <--- Line 277 (my annotation)
        frtn_t          *db_frtnp;
        unsigned char   *db_base;
        unsigned char   *db_lim;
        unsigned char   db_ref;
                  .
                  .
                  .
        fthdr_t         *db_fthdr;
        ftflw_t         ***db_ftflw;
        uid_t           db_uid;         /* Effective user id */
        /* project ID - EXPERIMENTAL - may change in future release */
        projid_t        db_projid;             <--- Line 307 (my annotation)
} dblk_t;
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

I have no idea why there should be a ``parse error'' at or before
line 307.  Can anyone enlighten me and suggest what I can do about it?

The information about the current version is:

platform sparc-sun-solaris2.9
arch     sparc               
os       solaris2.9          
system   sparc, solaris2.9   
status                       
major    1                   
minor    5.1                 
year     2002                
month    06                  
day      17                  
language R

(As you can see I haven't upgraded for a while.  Sigh.  I've been
afraid of running into the sort of trouble that I've just run into.)

I'll be grateful for any advice, but I would humbly request that
you express it in terms as simple and explicit as you can.  As I said,
I don't speak C, and I'm very much fumbling about in the dark here.

					cheers,

						Rolf Turner
						rolf at math.unb.ca

P. S.  There are a bunch of WARNING messages in config.log, which may
be relevant as some of them refer to ``netinet'' and ``netdb:

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
configure:8871: WARNING: you cannot build info versions of the R manuals
configure:12127: WARNING: arpa/inet.h: present but cannot be compiled
configure:12129: WARNING: arpa/inet.h: check for missing prerequisite headers?
configure:12131: WARNING: arpa/inet.h: proceeding with the preprocessor's result

configure:12127: WARNING: netdb.h: present but cannot be compiled
configure:12129: WARNING: netdb.h: check for missing prerequisite headers?
configure:12131: WARNING: netdb.h: proceeding with the preprocessor's result
configure:12127: WARNING: netinet/in.h: present but cannot be compiled
configure:12129: WARNING: netinet/in.h: check for missing prerequisite headers?
configure:12131: WARNING: netinet/in.h: proceeding with the preprocessor's resul
t
configure:12127: WARNING: sys/socket.h: present but cannot be compiled
configure:12129: WARNING: sys/socket.h: check for missing prerequisite headers?
configure:12131: WARNING: sys/socket.h: proceeding with the preprocessor's resul
t
configure:12709: WARNING: could not determine type of socket length
configure:26299: WARNING: could not determine type of socket length
configure:26327: WARNING: you cannot build info versions of the R manuals
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===


From till.baumgaertel at epost.de  Mon Mar 17 02:48:49 2003
From: till.baumgaertel at epost.de (Till Baumgaertel)
Date: Mon, 17 Mar 2003 02:48:49 +0100
Subject: [R] Built-In Wilks Lambda for lda?
Message-ID: <3E66A61C00011807@ppd27106.x.de>


Hello,

using the lda-method from MASS-package I was wondering whether there is
 a built-in method for figuring out Wilks' Lambda?

Searching the Web I found in the r-help archive a thread form june 2002,
but it didn't help me. 
I understand I can use manova and its summary-method to get Wilks' Lambda
on the screen, but I don't see the connection to lda from MASS.

Or does 
  summary( manova( df[ train] ~ classes[ train]),test="Wilks")
produce Wilks Lambda as used in lda/MASS? 

In this case I would not know if an access like this
  lambda <- summary( manova( as.matrix(dataframe) ~ classes),test="Wilks")$stats[
1,2]
would give me Wilk's Lambda under all circumstances.

I played a little with some data and found out this is not working every
time. manova errors sometimes "residuals have rank x < y" where "y" equals
ncol(df). But this shouln't impact Wilk's Lambda?

Thanks for your help,
till





________________________________________
Mehr Power f?r Ihre eMail - mit den neuen Leistungspaketen bei http://www.epost.de


From fjmolina at lbl.gov  Mon Mar 17 03:28:15 2003
From: fjmolina at lbl.gov (Francisco J Molina)
Date: Sun, 16 Mar 2003 18:28:15 -0800
Subject: [R] "Debugging R from within Emacs"
Message-ID: <15989.12991.435625.415696@0-e0-98-8a-c5-4a.dhcp.lbl.gov>


In  
"Frequently Asked Questions on R"
there is a section 
"Debugging R from within Emacs"
I suppose this is for developpers ( not useful to debug R source code ).
Am I right?


From rossini at blindglobe.net  Mon Mar 17 03:56:41 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Sun, 16 Mar 2003 18:56:41 -0800
Subject: [R] "Debugging R from within Emacs"
In-Reply-To: <15989.12991.435625.415696@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
	(Francisco J Molina's message of "Sun, 16 Mar 2003 18:28:15 -0800")
References: <15989.12991.435625.415696@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
Message-ID: <87wuiyzonq.fsf@jeeves.blindglobe.net>

Francisco J Molina <fjmolina at lbl.gov> writes:


> In  
> "Frequently Asked Questions on R"
> there is a section 
> "Debugging R from within Emacs"
> I suppose this is for developpers ( not useful to debug R source code ).
> Am I right?

Only partially. 

You'll have to ask a better question to get a better answer.  What do
you mean, and what do you want to accomplish?

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------------
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(CHANGE: monday/wednesday/friday locations are completely unpredictable.)


From r.hankin at auckland.ac.nz  Mon Mar 17 04:16:53 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Mon, 17 Mar 2003 15:16:53 +1200
Subject: [R] scoping rules 
Message-ID: <200303170316.h2H3Gro0012321@r.hankin.sges.auckland.ac.nz>

Hi

I recently found a bug that was isomorphic to the following:

ll1 <- 2
increment <- function(x)
{
  l11 <- 1
  return(x+ll1)   #bug here
}

Of course, R is obeying the scoping rules just fine, but I'm evidently
not setting the do.what.I.mean.not.what.I.say variable correctly.

Now, how do I avoid making this type of error? ... and what is the
best tool for tracking it down?


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042


From fredgers at wrath.forked.net  Mon Mar 17 04:52:27 2003
From: fredgers at wrath.forked.net (Fred Gerson)
Date: Sun, 16 Mar 2003 19:52:27 -0800 (PST)
Subject: [R] RMySQL Install Problem
Message-ID: <Pine.LNX.4.43.0303161937380.29228-100000@wrath.forked.net>

Hey all,

I asked my server administrator to install the RMySQL package for me
however he was unable to and received the below errors. I searched the
archives for some of the words in the error mesage but found no answers.
Does anyone have any ideas what might be going wrong? This is R 1.6.2 on a
linux box.

Thanks,
Fred




> install.packages("RMySQL")
trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 100850 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ........
downloaded 98Kb

trying URL `http://cran.r-project.org/src/contrib/RMySQL_0.5-0.tar.gz'
Content type `application/x-tar' length 390241 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .
downloaded 381Kb

* Installing *source* package 'RMySQL' ...
creating cache ./config.cache
checking how to run the C preprocessor... cc -E
checking for mysql_init in -lmysqlclient... yes
checking for mysql.h... no
checking for /usr/local/include/mysql/mysql.h... no
checking for /usr/include/mysql/mysql.h... yes
updating cache ./config.cache
creating ./config.status
creating src/Makevars
** libs
gcc -I/usr/local/lib/R/include -I/usr/include/mysql -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c RS-DBI.c -o RS-DBI.o
gcc -I/usr/local/lib/R/include -I/usr/include/mysql -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c RS-MySQL.c -o RS-MySQL.o
RS-MySQL.c: In function `RS_MySQL_newConnection':
RS-MySQL.c:203: `MYSQL_OPT_LOCAL_INFILE' undeclared (first use in this
function)
RS-MySQL.c:203: (Each undeclared identifier is reported only once
RS-MySQL.c:203: for each function it appears in.)
make: *** [RS-MySQL.o] Error 1
ERROR: compilation failed for package 'RMySQL'

Delete downloaded files (y/N)? y

Warning message:
Installation of package RMySQL had non-zero exit status in:
install.packages("RMySQL")
> q()


From deepayan at stat.wisc.edu  Mon Mar 17 06:23:29 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 16 Mar 2003 23:23:29 -0600
Subject: [R] scoping rules
In-Reply-To: <200303170316.h2H3Gro0012321@r.hankin.sges.auckland.ac.nz>
References: <200303170316.h2H3Gro0012321@r.hankin.sges.auckland.ac.nz>
Message-ID: <200303162323.29505.deepayan@stat.wisc.edu>

On Sunday 16 March 2003 09:16 pm, Robin Hankin wrote:
> Hi
>
> I recently found a bug that was isomorphic to the following:
>
> ll1 <- 2
> increment <- function(x)
> {
>   l11 <- 1

You are not really using this variable (l11, not ll1) anywhere. Is that a 
typo? What exactly do you want to happen ?


>   return(x+ll1)   #bug here
> }
>
> Of course, R is obeying the scoping rules just fine, but I'm evidently
> not setting the do.what.I.mean.not.what.I.say variable correctly.
>
> Now, how do I avoid making this type of error? ... and what is the
> best tool for tracking it down?


From pingzhao at waffle.cs.dal.ca  Mon Mar 17 06:50:03 2003
From: pingzhao at waffle.cs.dal.ca (pingzhao)
Date: Mon, 17 Mar 2003 01:50:03 -0400
Subject: [R] search function
Message-ID: <3E76587D@webmail.ucis.dal.ca>

Could any one tell me there is a search
function for R-help Archives?

Thanks


From laurent at cbs.dtu.dk  Mon Mar 17 07:20:10 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Mon, 17 Mar 2003 07:20:10 +0100
Subject: [R] search function
In-Reply-To: <3E76587D@webmail.ucis.dal.ca>
References: <3E76587D@webmail.ucis.dal.ca>
Message-ID: <20030317062010.GA3569373@genome.cbs.dtu.dk>

On Mon, Mar 17, 2003 at 01:50:03AM -0400, pingzhao wrote:
> Could any one tell me there is a search
> function for R-help Archives?
> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


http://www.r-project.org/search.html

(accessible through the link 'search' at
http://www.r-project.org/)


Hopin' it helps,


L.


-- 
--------------------------------------------------------------
currently at the National Yang-Ming University in Taipei, Taiwan
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent


From masuno at masunosoftware.com  Mon Mar 17 08:01:39 2003
From: masuno at masunosoftware.com (Hiroshi Masuno)
Date: Mon, 17 Mar 2003 16:01:39 +0900
Subject: [R] how to use R in delphi or vb ?
Message-ID: <20030317155801.E23D.MASUNO@masunosoftware.com>

Dear Sirs,
I am a beginner of R .
Please teach me.
Do someone teach me how to use R within 'delphi ' or Visual Basic?
Sorry for my poor English,
I am a Japanese, and not good for english.

Sincerelly Yours,
Hiroshi Masuno
<masuno at masunosoftware.com>


From j+rhelp at howard.fm  Mon Mar 17 08:07:30 2003
From: j+rhelp at howard.fm (j+rhelp@howard.fm)
Date: Mon, 17 Mar 2003 18:07:30 +1100
Subject: [R] how to use R in delphi or vb ?
In-Reply-To: <20030317155801.E23D.MASUNO@masunosoftware.com>
References: <20030317155801.E23D.MASUNO@masunosoftware.com>
Message-ID: <20030317070730.2A0005068F@server2.fastmail.fm>

On Mon, 17 Mar 2003 16:01:39 +0900, "Hiroshi Masuno"
<masuno at masunosoftware.com> said:
> Do someone teach me how to use R within 'delphi ' or Visual Basic?

You need to use the COM interface:

http://cran.r-project.org/contrib/extra/dcom/

Details are in the readme.txt file on that site.

> Sorry for my poor English,

Your English is just fine!


From Jean-Pierre.Mueller at dssp.unil.ch  Mon Mar 17 08:45:01 2003
From: Jean-Pierre.Mueller at dssp.unil.ch (Jean-Pierre Muller)
Date: Mon, 17 Mar 2003 08:45:01 +0100
Subject: [R] file encoding
Message-ID: <a05200f00ba9a6b121ac9@[130.223.101.43]>

Hello,

Is file("out.txt", open="wt", encoding=ISOLatin1)
(resp: MacRoman, WinAnsi) broken/unimplemented ?

I am trying:
zz <- file("out.txt", open="wt", encoding=ISOLatin1)
cat(ASCII,file = zz, sep="\n")
close(zz)

on R162 for MacOs (carbon).

Thanks.
-- 
------------------------------------------------------------------------------
Jean-Pierre Muller
SSP / UNIL /  BFSH2 / CH-1015 Lausanne


From Morten.Sickel at nrpa.no  Mon Mar 17 09:06:30 2003
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Mon, 17 Mar 2003 09:06:30 +0100
Subject: [R] plot
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5ED8@postix.nrpa.no>

noliveir2003 at zipmail.com.br [mailto:noliveir2003 at zipmail.com.br] wrote:

>Can anyone tell me how to plot on the same graph two different functions
>(of x) using two differnt y scales (axes 2 and 4)?

The only way I've found is to use the grid library and push.viewport(). 
((...) means substitute with whatever appropriate, use help())

library(grid)
grid.newpage()
push.viewport(viewport(yscale=c(0,500),w=.75,h=.75,xscale=c(0:100)))
grid.poins(...) # Plots data point with an y-scale of 0-500
grid.xaxis(...)
grid.yaxis(...) # Draws the left y-axis
push.viewport(viewport(yscale=c(0,10),xscale=c(0:100)))
grid.poins(...) # Plots data point with an y-scale of 0-10
grid,yaxis(main=FALSE,...) # Draws the right y-axis

Morten

-- 
Morten Sickel
Norwegian Radiation Protection Authority
http://www.nrpa.no


From baron at cattell.psych.upenn.edu  Mon Mar 17 09:10:38 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Mon, 17 Mar 2003 03:10:38 -0500
Subject: [R] search function
In-Reply-To: <20030317062010.GA3569373@genome.cbs.dtu.dk>;
	from laurent@cbs.dtu.dk on Mon, Mar 17, 2003 at 07:20:10AM +0100
References: <3E76587D@webmail.ucis.dal.ca>
	<20030317062010.GA3569373@genome.cbs.dtu.dk>
Message-ID: <20030317031038.B15352@cattell.psych.upenn.edu>

On 03/17/03 07:20, Laurent Gautier wrote:
>On Mon, Mar 17, 2003 at 01:50:03AM -0400, pingzhao wrote:
>> Could any one tell me there is a search
>> function for R-help Archives?
>
>http://www.r-project.org/search.html

Also in my page below.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
R page:               http://finzi.psych.upenn.edu/


From petr.pikal at precheza.cz  Mon Mar 17 12:12:20 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 17 Mar 2003 12:12:20 +0100
Subject: [R] plot
In-Reply-To: <54DE9A561AD20C4D9FF88B116965420E4E5ED8@postix.nrpa.no>
Message-ID: <3E75BBA4.26559.13549B7@localhost>

Hi

On 17 Mar 2003 at 9:06, Morten Sickel wrote:

> noliveir2003 at zipmail.com.br [mailto:noliveir2003 at zipmail.com.br]
> wrote:
> 
> >Can anyone tell me how to plot on the same graph two different
> >functions (of x) using two differnt y scales (axes 2 and 4)?
> 
> The only way I've found is to use the grid library and
> push.viewport(). ((...) means substitute with whatever appropriate,
> use help())
> 
> library(grid)
> grid.newpage()
> push.viewport(viewport(yscale=c(0,500),w=.75,h=.75,xscale=c(0:100)))
> grid.poins(...) # Plots data point with an y-scale of 0-500
> grid.xaxis(...) grid.yaxis(...) # Draws the left y-axis
> push.viewport(viewport(yscale=c(0,10),xscale=c(0:100)))
> grid.poins(...) # Plots data point with an y-scale of 0-10
> grid,yaxis(main=FALSE,...) # Draws the right y-axis

Or maybe this small function which I use for 2 (different scale) y axes can make it 
on ordinary graphic device.

You has to provide 3 vectors x, yright and yleft and you can put lines through 
linky=T or/and smoothed lines through setting smooth > 0.

plot.yy<-function(x,yright,yleft, xlab = NULL 
,yylab=c("",""),pch=c(1,2),col=c(1,2), linky=F, smooth=0, lwds=1, ...)

{

par(mar=c(5,4,4,2),oma=c(0,0,0,3))
plot(x,yright,axes=F,ylab="", xlab=xlab, pch=pch[1],col=col[1], ...)
axis(4,pretty(range(yright,na.rm=T),10),col=col[1])

if (linky) lines(x,yright,col=col[1], ...)

if (smooth!=0) lines(supsmu(x,yright,span=smooth),col=col[1], lwd=lwds, ...)

if(yylab[1]=="") 
mtext(deparse(substitute(yright)),side=4,outer=T,line=1, col=col[1], ...)
else 
mtext(yylab[1],side=4,outer=T,line=1, col=col[1], ...)

par(new=T)
plot(x,yleft,ylab="", axes=F ,xlab=xlab, pch=pch[2],col=col[2], ...)
box()
axis(2,pretty(range(yleft,na.rm=T),10),col=col[2])
axis(1,pretty(range(x,na.rm=T),10))

if(yylab[2]=="")
mtext(deparse(substitute(yleft)),side=2,line=2, col=col[2], ...)
else
mtext(yylab[2],side=2,line=2, col=col[2], ...)


if (linky) lines(x,yleft,col=col[2], lty=2, ...)
if (smooth!=0) lines(supsmu(x,yleft,span=smooth),col=col[2], lty=2, lwd=lwds, 
...)

}



> 
> Morten
> 
> -- 
> Morten Sickel
> Norwegian Radiation Protection Authority
> http://www.nrpa.no
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Cheers

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


From phgrosjean at sciviews.org  Mon Mar 17 12:21:02 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Mon, 17 Mar 2003 12:21:02 +0100
Subject: [R] Looking for GUI
In-Reply-To: <3E66386D0046C4C1@mail-1.tiscalinet.it> (added
	bypostmaster@mail.tiscali.it)
Message-ID: <MABBLJDICACNFOLGIHJOGENLDEAA.phgrosjean@sciviews.org>

Hello,

There are no GUIs for R available yet, but a few are in preparation: PMG,
ObveRsive, TexMacs, (and SciViews, but only under Windows). Keep an eye on
http://www.r-project.org/GUI for new items, but I am afraid you wil not find
what you are looking for very soon.
Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Ulrich Pedri
Sent: jeudi 13 mars 2003 11:44
To: r-help at stat.math.ethz.ch
Subject: [R] Looking for GUI


Hi List,

i am locking for a GUI for R. I have a Debian Woody 3.0 and running R 1.5.1.
In office i am using SPSS 9.0 for several years now after Systat for short
time and now i would use a statistic software under Linux at home. It seems
that R could be that what i am looking for, but i have problems to
understand
how it works or better explained i would prefer using a good grafic
interface.

Wich one could i try ??

thank you
ULI

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From AlessandroSemeria at cramont.it  Mon Mar 17 12:47:22 2003
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Mon, 17 Mar 2003 12:47:22 +0100
Subject: [R] Help with reading data
Message-ID: <OF6AEDCD2C.EE2EC89F-ONC1256CEC.003CE748-C1256CEC.00401821@tomware.it>

Hi!
'The bizarre thing is this error comes from using read.table'
Not bizarre, read.table is a R-function  built with the R-function scan 
(you can look  the code simply  by command read.table at the R-prompt).
 'Error in scan("tree.dat") : "scan" expected a real, got "<!DOCTYPE"'
Obviously read.table is not able to read every data file (please look  at 
the help for read.table and at doc/Manual/R-data.pdf).
"DOCTYPE" is something by MS-Word file, instead to make use of scan (more 
fast) or read.table you need 
a flat ASCII file (i.e., trivial, you make a data sheet with some 
spreadsheet, Excell, and save it as separeted by tab .txt)

A.S.

----------------------------

Alessandro Semeria 
Models and Simulations Laboratory
The Environment Research Center - Montecatini (Edison Group), 
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: asemeria at cramont.it


From d.orme at imperial.ac.uk  Mon Mar 17 13:33:32 2003
From: d.orme at imperial.ac.uk (David Orme)
Date: Mon, 17 Mar 2003 12:33:32 +0000
Subject: [R] Problem with pdf device.
Message-ID: <AA41C0C8-5874-11D7-B54E-000393DC1748@ic.ac.uk>

Hi,

I seem to have broken the pdf device on my installation. I'm running R 
1.6.1 under Apple's X11 on darwin 6.3. Running the following commands 
straight after starting R (and without touching 'par') gives different 
results - the png file looks fine but I'm missing axes and labels on 
the pdf. If I try and print the pdf, axes and labels appear but with 
text characters as boxes and the plotted points vanish. I've attached 
the resulting graphics files. Inspecting the two sets of par() outputs 
doesn't show any huge differences that I can see 
("bg","cin","cra","csi","cxy","din","fin","mai","pin","plt" differ 
between the two but the differences are small). Has anyone got any idea 
what I've done to my setup and how to fix it?

Thanks,
David

> > png(file="SimplePlot.png")
> > pngpar <- par()
> > plot(1:10)
> > dev.off()
> null device
>           1
> > pdf(file="SimplePlot.png")
> > pdfpar <- par()
> > plot(1:10)
> > dev.off()
> null device
>           1
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SimplePlot.pdf
Type: application/pdf
Size: 3511 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030317/4282965b/SimplePlot.pdf
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SimplePlot.png
Type: image/png
Size: 1840 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030317/4282965b/SimplePlot.png

From rbonk at host.sk  Mon Mar 17 20:19:20 2003
From: rbonk at host.sk (Rado Bonk)
Date: 17 Mar 2003 14:19:20 -0500
Subject: [R] automated legend for points.geodata
Message-ID: <1047928760.1381.30.camel@templar.fns.uniba.sk>

Hi R-users,

I have to produce numerous plots using points.geodata function from geoR
package. The function however, doesn't have an option to include the
legend to the plot (to see the actual values of the data) Is there an
automative way to include legend to the plot using points.geodata?

I think there might be a way using "pch", "cex.max", and "cex.min"
primitives and produce the legend independently.  But due to the amount
of plots I need to produce it is not what I am looking for.

Thanks in advance,

Rado Bonk

-- 
Radoslav Bonk M.S.
Dept. of Physical Geography and Geoecology
Faculty of Sciences, Comenius University
Mlynska Dolina 842 15, Bratislava, SLOVAKIA
tel: +421 905 968 127 e-mail: rbonk at host.sk


From dfs at research.att.com  Mon Mar 17 14:28:52 2003
From: dfs at research.att.com (Deborah Swayne)
Date: Mon, 17 Mar 2003 08:28:52 -0500
Subject: [R] xgobi?
In-Reply-To: <BAY2-F120MZqasBVqbO0006059f@hotmail.com>
References: <BAY2-F120MZqasBVqbO0006059f@hotmail.com>
Message-ID: <20030317132852.GC7826063@fry.research.att.com>

> As far as I understood from the documentation of xgobi. The package is 
> intended to plot data in 3D (and more). 

While xgobi is still available, it is no longer receiving much of its
authors' attention.  Its successor ggobi (www.ggobi.org), on the other
hand, is growing all the time.  While xgobi can be launched from R,
that is the extent of its relationship to S or R; no live connection
between the two processes is maintained.  ggobi, on the other hand, is
embedded in R and has an API which is expressed in the Rggobi package.
The curious are welcome to direct further questions about ggobi and
Rggobi to ggobi-help at ggobi.org.

Debby


From gisar at nus.edu.sg  Mon Mar 17 14:42:40 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Mon, 17 Mar 2003 21:42:40 +0800
Subject: [R] X11 connection error in web cgi mode only
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F22D@MBXSRV03.stf.nus.edu.sg>

Dear all,

I am trying to create a web interface using Perl-CGI to call R plots and
to display them.
The following codes works perfectly fine when I copy and paste into the
console directly or if I save it into script.file and then R --no-save <
script.file producing the graphs. 

jpeg("graph.jpeg", width=400, height=400)
plot(rnorm(100))
dev.off()

Now, I put the line system("R --no-save < script.file > log_file") from
inside my cgi and then process it from client side, I get the following
error message:


Error in X11(paste("jpeg::", quality, ":", filename, sep = ""), width,
: 
        unable to start device JPEG
In addition: Warning message: 
unable to open connection to X11 display`' 
Execution halted


Why do I get this error and how can I fix it? Many thanks in advance.

Regards, Adai.


From Hagen.Schmoeller at iaew.rwth-aachen.de  Mon Mar 17 15:06:38 2003
From: Hagen.Schmoeller at iaew.rwth-aachen.de (=?iso-8859-1?Q?Hagen_Schm=F6ller?=)
Date: Mon, 17 Mar 2003 15:06:38 +0100
Subject: [R] Season Determination
Message-ID: <001501c2ec8e$6db7d2f0$5c6a8286@iaew.rwthaachen.de>

Hi R-Community,

I have an historical time series of power prices and would like to determine
the daily and yearly seasonal component for forecast purposes. Unfortunately
the functions "decompose" and "stl" do not provide an always identical
repeating seasonal pattern which could be continued in the future. Why and
is there a possibility to adjust a periodical function like

s(t) = a1 sin(f1 t) + b1 cos(f1 t) + a2 sin(f2 t) + b2 cos(f2 t) + ...

to a time series, if necessary with given frequencies fi.

Much thanks in advance,

Hagen Schmoeller
--
Dipl.-Ing. Hagen K. Schm?ller
Institut f?r Elektrische Anlagen und Energiewirtschaft, RWTH Aachen
Schinkelstra?e 6, D-52056 Aachen, Germany
Tel.: +49 (0)241 80-96734
Fax : +49 (0)241 80-92197
Hagen.Schmoeller at iaew.rwth-aachen.de


From dmurdoch at pair.com  Mon Mar 17 15:17:57 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 17 Mar 2003 09:17:57 -0500
Subject: [R] how to use R in delphi or vb ?
In-Reply-To: <20030317155801.E23D.MASUNO@masunosoftware.com>
References: <20030317155801.E23D.MASUNO@masunosoftware.com>
Message-ID: <culb7vksnac4m0mdmuocvfqd8q690hbad1@4ax.com>

On Mon, 17 Mar 2003 16:01:39 +0900, you wrote:

>Dear Sirs,
>I am a beginner of R .
>Please teach me.
>Do someone teach me how to use R within 'delphi ' or Visual Basic?

Someone else gave the link to the COM interface for calling R from
those languages.  If you want to write numerical code in Delphi and
call it from R, you should create a DLL, exporting the function(s)er
using the "cdecl" calling convention.  If your routine doesn't need to
allocate memory which will be returned to R, that's it.  If you want
to create strings or vectors or more complicated structures and return
them, you need to call internal R functions.

Mark Bravington has put together some sample code for Delphi, which
I've promised to put up on a web page somewhere; I haven't done that
yet though.

Duncan Murdoch


From john.janmaat at acadiau.ca  Mon Mar 17 15:20:52 2003
From: john.janmaat at acadiau.ca (John Janmaat)
Date: Mon, 17 Mar 2003 10:20:52 -0400
Subject: [R] Filled box on graph
Message-ID: <3E75D9C4.8070607@acadiau.ca>

Hello All,

I need to indicate a range on a plot.  It would be best as a filled 
rectangular region.  Do functions exist to draw filled boxes on a plot?

Thanks,

John.
-- 
--------------------------------------------------------------------------
Dr. John Janmaat
Department of Economics, Acadia University, Wolfville, NS, B4P 2R6
E-mail: jjanmaat at acadiau.ca        Web: http://ace.acadiau.ca/~jjanmaat
Tel: 902-585-1461		   Fax: 902-585-1070


From dj at research.bell-labs.com  Mon Mar 17 15:21:11 2003
From: dj at research.bell-labs.com (David James)
Date: Mon, 17 Mar 2003 09:21:11 -0500
Subject: [R] RMySQL Install Problem
In-Reply-To: <Pine.LNX.4.43.0303161937380.29228-100000@wrath.forked.net>;
	from fredgers@wrath.forked.net on Sun, Mar 16, 2003 at 07:52:27PM -0800
References: <Pine.LNX.4.43.0303161937380.29228-100000@wrath.forked.net>
Message-ID: <20030317092111.B23587@jessie.research.bell-labs.com>

Hi,

Could you tell us what version of MySQL you're running?

--
David

Fred Gerson wrote:
> Hey all,
> 
> I asked my server administrator to install the RMySQL package for me
> however he was unable to and received the below errors. I searched the
> archives for some of the words in the error mesage but found no answers.
> Does anyone have any ideas what might be going wrong? This is R 1.6.2 on a
> linux box.
> 
> Thanks,
> Fred
> 
> 
> 
> 
> > install.packages("RMySQL")
> trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 100850 bytes
> opened URL
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ........
> downloaded 98Kb
> 
> trying URL `http://cran.r-project.org/src/contrib/RMySQL_0.5-0.tar.gz'
> Content type `application/x-tar' length 390241 bytes
> opened URL
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .
> downloaded 381Kb
> 
> * Installing *source* package 'RMySQL' ...
> creating cache ./config.cache
> checking how to run the C preprocessor... cc -E
> checking for mysql_init in -lmysqlclient... yes
> checking for mysql.h... no
> checking for /usr/local/include/mysql/mysql.h... no
> checking for /usr/include/mysql/mysql.h... yes
> updating cache ./config.cache
> creating ./config.status
> creating src/Makevars
> ** libs
> gcc -I/usr/local/lib/R/include -I/usr/include/mysql -I/usr/local/include
> -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c RS-DBI.c -o RS-DBI.o
> gcc -I/usr/local/lib/R/include -I/usr/include/mysql -I/usr/local/include
> -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c RS-MySQL.c -o RS-MySQL.o
> RS-MySQL.c: In function `RS_MySQL_newConnection':
> RS-MySQL.c:203: `MYSQL_OPT_LOCAL_INFILE' undeclared (first use in this
> function)
> RS-MySQL.c:203: (Each undeclared identifier is reported only once
> RS-MySQL.c:203: for each function it appears in.)
> make: *** [RS-MySQL.o] Error 1
> ERROR: compilation failed for package 'RMySQL'
> 
> Delete downloaded files (y/N)? y
> 
> Warning message:
> Installation of package RMySQL had non-zero exit status in:
> install.packages("RMySQL")
> > q()
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
David A. James
Statistics Research, Room 2C-253
Bell Labs, Lucent Technologies 
Murray Hill, NJ 09794-0636


From fredgers at wrath.forked.net  Mon Mar 17 15:47:23 2003
From: fredgers at wrath.forked.net (Fred Gerson)
Date: Mon, 17 Mar 2003 06:47:23 -0800 (PST)
Subject: [R] RMySQL Install Problem
In-Reply-To: <20030317092111.B23587@jessie.research.bell-labs.com>
Message-ID: <Pine.LNX.4.43.0303170645530.8015-100000@wrath.forked.net>

Hey David,

Sorry about that, the server runs MySQL 3.2.39.

Thanks a lot,
Fred

On Mon, 17 Mar 2003, David James wrote:

> Hi,
>
> Could you tell us what version of MySQL you're running?
>
> --
> David
>
> Fred Gerson wrote:
> > Hey all,
> >
> > I asked my server administrator to install the RMySQL package for me
> > however he was unable to and received the below errors. I searched the
> > archives for some of the words in the error mesage but found no answers.
> > Does anyone have any ideas what might be going wrong? This is R 1.6.2 on a
> > linux box.
> >
> > Thanks,
> > Fred
> >
> >
> >
> >
> > > install.packages("RMySQL")
> > trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
> > Content type `text/plain; charset=iso-8859-1' length 100850 bytes
> > opened URL
> > .......... .......... .......... .......... ..........
> > .......... .......... .......... .......... ........
> > downloaded 98Kb
> >
> > trying URL `http://cran.r-project.org/src/contrib/RMySQL_0.5-0.tar.gz'
> > Content type `application/x-tar' length 390241 bytes
> > opened URL
> > .......... .......... .......... .......... ..........
> > .......... .......... .......... .......... ..........
> > .......... .......... .......... .......... ..........
> > .......... .......... .......... .......... ..........
> > .......... .......... .......... .......... ..........
> > .......... .......... .......... .......... ..........
> > .......... .......... .......... .......... ..........
> > .......... .......... .......... .
> > downloaded 381Kb
> >
> > * Installing *source* package 'RMySQL' ...
> > creating cache ./config.cache
> > checking how to run the C preprocessor... cc -E
> > checking for mysql_init in -lmysqlclient... yes
> > checking for mysql.h... no
> > checking for /usr/local/include/mysql/mysql.h... no
> > checking for /usr/include/mysql/mysql.h... yes
> > updating cache ./config.cache
> > creating ./config.status
> > creating src/Makevars
> > ** libs
> > gcc -I/usr/local/lib/R/include -I/usr/include/mysql -I/usr/local/include
> > -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c RS-DBI.c -o RS-DBI.o
> > gcc -I/usr/local/lib/R/include -I/usr/include/mysql -I/usr/local/include
> > -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c RS-MySQL.c -o RS-MySQL.o
> > RS-MySQL.c: In function `RS_MySQL_newConnection':
> > RS-MySQL.c:203: `MYSQL_OPT_LOCAL_INFILE' undeclared (first use in this
> > function)
> > RS-MySQL.c:203: (Each undeclared identifier is reported only once
> > RS-MySQL.c:203: for each function it appears in.)
> > make: *** [RS-MySQL.o] Error 1
> > ERROR: compilation failed for package 'RMySQL'
> >
> > Delete downloaded files (y/N)? y
> >
> > Warning message:
> > Installation of package RMySQL had non-zero exit status in:
> > install.packages("RMySQL")
> > > q()
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> --
> David A. James
> Statistics Research, Room 2C-253
> Bell Labs, Lucent Technologies
> Murray Hill, NJ 09794-0636
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From jfox at mcmaster.ca  Mon Mar 17 16:08:14 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 17 Mar 2003 10:08:14 -0500
Subject: [R] Filled box on graph
In-Reply-To: <3E75D9C4.8070607@acadiau.ca>
Message-ID: <5.1.0.14.2.20030317100727.01e71968@mcmail.cis.mcmaster.ca>

Dear John

See ?polygon.

I hope that this helps,
  John

At 10:20 AM 3/17/2003 -0400, you wrote:
>Hello All,
>
>I need to indicate a range on a plot.  It would be best as a filled 
>rectangular region.  Do functions exist to draw filled boxes on a plot?
>
>Thanks,
>
>John.
>--
>--------------------------------------------------------------------------
>Dr. John Janmaat
>Department of Economics, Acadia University, Wolfville, NS, B4P 2R6
>E-mail: jjanmaat at acadiau.ca        Web: http://ace.acadiau.ca/~jjanmaat
>Tel: 902-585-1461                  Fax: 902-585-1070
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From john.janmaat at acadiau.ca  Mon Mar 17 16:12:27 2003
From: john.janmaat at acadiau.ca (John Janmaat)
Date: Mon, 17 Mar 2003 11:12:27 -0400
Subject: [R] Filled box on graph
References: <5.1.0.14.2.20030317100727.01e71968@mcmail.cis.mcmaster.ca>
Message-ID: <3E75E5DB.4010109@acadiau.ca>

All responders,

Polygon works great, thanks.

John.

John Fox wrote:
> Dear John
> 
> See ?polygon.
> 
> I hope that this helps,
>  John
> 
> At 10:20 AM 3/17/2003 -0400, you wrote:
> 
>> Hello All,
>>
>> I need to indicate a range on a plot.  It would be best as a filled 
>> rectangular region.  Do functions exist to draw filled boxes on a plot?
>>
>> Thanks,
>>
>> John.
>> -- 
>> -------------------------------------------------------------------------- 
>>
>> Dr. John Janmaat
>> Department of Economics, Acadia University, Wolfville, NS, B4P 2R6
>> E-mail: jjanmaat at acadiau.ca        Web: http://ace.acadiau.ca/~jjanmaat
>> Tel: 902-585-1461                  Fax: 902-585-1070
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
> 
> 


-- 
--------------------------------------------------------------------------
Dr. John Janmaat
Department of Economics, Acadia University, Wolfville, NS, B4P 2R6
E-mail: jjanmaat at acadiau.ca        Web: http://ace.acadiau.ca/~jjanmaat
Tel: 902-585-1461		   Fax: 902-585-1070


From dj at research.bell-labs.com  Mon Mar 17 16:33:04 2003
From: dj at research.bell-labs.com (David James)
Date: Mon, 17 Mar 2003 10:33:04 -0500
Subject: [R] RMySQL Install Problem
In-Reply-To: <Pine.LNX.4.43.0303170645530.8015-100000@wrath.forked.net>;
	from fredgers@wrath.forked.net on Mon, Mar 17, 2003 at 06:47:23AM -0800
References: <20030317092111.B23587@jessie.research.bell-labs.com>
	<Pine.LNX.4.43.0303170645530.8015-100000@wrath.forked.net>
Message-ID: <20030317103304.C23587@jessie.research.bell-labs.com>

Fred Gerson wrote:
> Hey David,
> 
> Sorry about that, the server runs MySQL 3.2.39.

Probably you mean 3.23.39?

You need to change line 197 in the file RMySQL/src/RS-MySQL.c from

#if defined(MYSQL_VERSION_ID) && MYSQL_VERSION_ID > 32339

to

#if defined(MYSQL_VERSION_ID) && MYSQL_VERSION_ID > 32348

--
David

> 
> Thanks a lot,
> Fred
> 
> On Mon, 17 Mar 2003, David James wrote:
> 
> > Hi,
> >
> > Could you tell us what version of MySQL you're running?
> >
> > --
> > David
> >
> > Fred Gerson wrote:
> > > Hey all,
> > >
> > > I asked my server administrator to install the RMySQL package for me
> > > however he was unable to and received the below errors. I searched the
> > > archives for some of the words in the error mesage but found no answers.
> > > Does anyone have any ideas what might be going wrong? This is R 1.6.2 on a
> > > linux box.
> > >
> > > Thanks,
> > > Fred
> > >
> > >
> > >
> > >
> > > > install.packages("RMySQL")
> > > trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
> > > Content type `text/plain; charset=iso-8859-1' length 100850 bytes
> > > opened URL
> > > .......... .......... .......... .......... ..........
> > > .......... .......... .......... .......... ........
> > > downloaded 98Kb
> > >
> > > trying URL `http://cran.r-project.org/src/contrib/RMySQL_0.5-0.tar.gz'
> > > Content type `application/x-tar' length 390241 bytes
> > > opened URL
> > > .......... .......... .......... .......... ..........
> > > .......... .......... .......... .......... ..........
> > > .......... .......... .......... .......... ..........
> > > .......... .......... .......... .......... ..........
> > > .......... .......... .......... .......... ..........
> > > .......... .......... .......... .......... ..........
> > > .......... .......... .......... .......... ..........
> > > .......... .......... .......... .
> > > downloaded 381Kb
> > >
> > > * Installing *source* package 'RMySQL' ...
> > > creating cache ./config.cache
> > > checking how to run the C preprocessor... cc -E
> > > checking for mysql_init in -lmysqlclient... yes
> > > checking for mysql.h... no
> > > checking for /usr/local/include/mysql/mysql.h... no
> > > checking for /usr/include/mysql/mysql.h... yes
> > > updating cache ./config.cache
> > > creating ./config.status
> > > creating src/Makevars
> > > ** libs
> > > gcc -I/usr/local/lib/R/include -I/usr/include/mysql -I/usr/local/include
> > > -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c RS-DBI.c -o RS-DBI.o
> > > gcc -I/usr/local/lib/R/include -I/usr/include/mysql -I/usr/local/include
> > > -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c RS-MySQL.c -o RS-MySQL.o
> > > RS-MySQL.c: In function `RS_MySQL_newConnection':
> > > RS-MySQL.c:203: `MYSQL_OPT_LOCAL_INFILE' undeclared (first use in this
> > > function)
> > > RS-MySQL.c:203: (Each undeclared identifier is reported only once
> > > RS-MySQL.c:203: for each function it appears in.)
> > > make: *** [RS-MySQL.o] Error 1
> > > ERROR: compilation failed for package 'RMySQL'
> > >
> > > Delete downloaded files (y/N)? y
> > >
> > > Warning message:
> > > Installation of package RMySQL had non-zero exit status in:
> > > install.packages("RMySQL")
> > > > q()
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> > --
> > David A. James
> > Statistics Research, Room 2C-253
> > Bell Labs, Lucent Technologies
> > Murray Hill, NJ 09794-0636
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >

-- 
David A. James
Statistics Research, Room 2C-253            Phone:  (908) 582-3082       
Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
Murray Hill, NJ 09794-0636


From v_bill_pikounis at merck.com  Mon Mar 17 16:33:43 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Mon, 17 Mar 2003 10:33:43 -0500
Subject: [R] X11 connection error in web cgi mode only
Message-ID: <E827328028C66044B4998F2EC353CD30031852F5@usrymx12.merck.com>

Adai,
I think this issue or something very related to it has come up before in
this list, so you may wish to search the R-help mail archives.   From what
you say, my guess on the reason for the error is permissions related, as the
web server (Apache?) executing your CGI does not implictly have access to an
X resource, which jpeg needs to work.

I have had some luck using "Xvfb" under Linux for CGI scripts with R to
generate PNG format data graphs. But this is a work-in-progress, as I have
not solved the permissions problem with a secure method yet.  Plus there is
the complication of cleanly accessing an X display in a multi-user system.  

You can learn much about Xvfb via google.

Hope that helps,
Bill
----------------------------------------
Bill Pikounis, Ph.D.

Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

v_bill_pikounis at merck.com

Phone: 732 594 3913
Fax: 732 594 1565


> -----Original Message-----
> From: Adaikalavan Ramasamy [mailto:gisar at nus.edu.sg]
> Sent: Monday, March 17, 2003 8:43 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] X11 connection error in web cgi mode only
> 
> 
> Dear all,
> 
> I am trying to create a web interface using Perl-CGI to call 
> R plots and
> to display them.
> The following codes works perfectly fine when I copy and 
> paste into the
> console directly or if I save it into script.file and then R 
> --no-save <
> script.file producing the graphs. 
> 
> jpeg("graph.jpeg", width=400, height=400)
> plot(rnorm(100))
> dev.off()
> 
> Now, I put the line system("R --no-save < script.file > 
> log_file") from
> inside my cgi and then process it from client side, I get the 
> following
> error message:
> 
> 
> Error in X11(paste("jpeg::", quality, ":", filename, sep = ""), width,
> : 
>         unable to start device JPEG
> In addition: Warning message: 
> unable to open connection to X11 display`' 
> Execution halted
> 
> 
> Why do I get this error and how can I fix it? Many thanks in advance.
> 
> Regards, Adai.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From peter.schlattmann at medizin.fu-berlin.de  Mon Mar 17 17:11:35 2003
From: peter.schlattmann at medizin.fu-berlin.de (Dr. Peter Schlattmann)
Date: Mon, 17 Mar 2003 17:11:35 +0100 (CET)
Subject: [R] glm -gamma errors
Message-ID: <33383.160.45.172.237.1047917495.squirrel@www.medizin.fu-berlin.de>


Dear list,

I am looking for a way to fix the scale parameter when fitting a
generalized linear model with gamma errors and log link.

Is there something like "SCALE" such as in GLIM?

As always thanks a lot.

Peter


From d.bloch at unibas.ch  Mon Mar 17 17:16:58 2003
From: d.bloch at unibas.ch (Daniel Bloch)
Date: Mon, 17 Mar 2003 17:16:58 +0100
Subject: [R] "r-square in LME?
Message-ID: <3E75F4D8.E662055D@unibas.ch>

Dear Members of the R-Help-List

I analysed data with LME in R. Is there a measure for LME (likelihood
estimated) statistics
which has an analogous meaning to the coefficient of determination
(r-square) estimated by
least-square procedure?

Best wishes

Daniel Bloch


From rolf at math.unb.ca  Mon Mar 17 17:30:35 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 17 Mar 2003 12:30:35 -0400 (AST)
Subject: [R] Trying to build R-1.6.2 under sparc-sun-solaris2.9.
Message-ID: <200303171630.h2HGUZRA029389@erdos.math.unb.ca>


This is a follow-up to a message I posted yesterday concerning
building R-1.6.2.

After a deafening silence regarding that first message I decided
to be fool-hardy and just comment out the line that seemed to
be giving trouble in the file /usr/include/sys/stream.h.

This worked for a while, but soon another error resulted:

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
gcc -I. -I../../../src/include -I../../../src/include  -DHAVE_CONFIG_H  -fPIC  -g -O2 -c Rsock.c -o Rsock.lo
Rsock.c: In function `R_SockConnect':
Rsock.c:378: `len' undeclared (first use in this function)
Rsock.c:378: (Each undeclared identifier is reported only once
Rsock.c:378: for each function it appears in.)
*** Error code 1
make: Fatal error: Command failed for target `Rsock.lo'
Current working directory /tmp/Rtmp/R-1.6.2/src/modules/internet
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /tmp/Rtmp/R-1.6.2/src/modules/internet
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /tmp/Rtmp/R-1.6.2/src/modules
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /tmp/Rtmp/R-1.6.2/src
*** Error code 1
make: Fatal error: Command failed for target `R'
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

Now this (Rsock.c) is actually dinky-di R code, but of course the
error has probably been induced by the previous error involving
``stream.h'' and possibly aggravated by my commenting out the
offending line in stream.h.

Has anyone out there a clue as to what is going on, and what
I might do to fix it?

Everlastingly grateful for any suggestions.

				cheers,

					Rolf Turner
					rolf at math.unb.ca


From barbara.chisolm at glenayre.com  Mon Mar 17 17:52:17 2003
From: barbara.chisolm at glenayre.com (Chisolm, Barbara)
Date: Mon, 17 Mar 2003 11:52:17 -0500
Subject: [R] Error in file(file, "r")
Message-ID: <EA37C22921B7D611AF5200508B949B5A013F5BF6@atlanta_nt2.atlanta.glenayre.com>

Hello,

I am a new user of R, and I am not able to read/scan external files.  I am
working in a Linux environment.  I have read through the R FAQ and documents
and have not been successful using the recommendations.  Below are several
scripts I've used and the error messages. .  

I've cc'd Brandon Whitcher because it was recommended in another FAQ.   I
read that this is a bug that occurs on Windows.   Is there is a patch/fix
that I can use?  I'd appreciate any help with this problem.

Thnx,
Barbara Chisolm

Test2 <- scan("C:\\bac\\TestData2")
Error in file(file, "r") : cannot open file `C:\bac\TestData2

                                                                         '
> test1<-read.table('J:/bac/R/TestDataWord.txt')
Error in file(file, "r") : cannot open file `J:/bac/R/TestDataWord.txt'

> setwd("J:/bac/R/")
Error in setwd(dir) : cannot change working directory


From p.dalgaard at biostat.ku.dk  Mon Mar 17 18:05:49 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Mar 2003 18:05:49 +0100
Subject: [R] Trying to build R-1.6.2 under sparc-sun-solaris2.9.
In-Reply-To: <200303171630.h2HGUZRA029389@erdos.math.unb.ca>
References: <200303171630.h2HGUZRA029389@erdos.math.unb.ca>
Message-ID: <x2d6kpexea.fsf@biostat.ku.dk>

Rolf Turner <rolf at math.unb.ca> writes:

> This is a follow-up to a message I posted yesterday concerning
> building R-1.6.2.
> 
> After a deafening silence regarding that first message I decided
> to be fool-hardy and just comment out the line that seemed to
> be giving trouble in the file /usr/include/sys/stream.h.
> 
> This worked for a while, but soon another error resulted:
...
> Has anyone out there a clue as to what is going on, and what
> I might do to fix it?

[The R-core team is in meetings in Vienna, so the response rate is not
going to be great this week]

It's certainly doable:

> version
         _
platform sparc-sun-solaris2.9
arch     sparc
os       solaris2.9
system   sparc, solaris2.9
status
major    1
minor    6.2
year     2003
month    01
day      10
language R

It's been a while since I built that, but that's pretty much a vanilla
system with the Solaris 9 freeware installed. 

Your configure output suggests that you hav a system installation
problem and some include files has gone AWOL. Check the config.log for
hints about what might be missing.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From rpeng at stat.ucla.edu  Mon Mar 17 18:12:07 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 17 Mar 2003 09:12:07 -0800 (PST)
Subject: [R] X11 connection error in web cgi mode only
In-Reply-To: <024D6AEFCB92CB47BA1085751D184BB80105F22D@MBXSRV03.stf.nus.edu.sg>
Message-ID: <Pine.GSO.4.10.10303170909010.25151-100000@quetelet.stat.ucla.edu>

I believe you get this error because the jpeg and png libraries require
the X11 device to be open in order to generate the plot.  I'll guess that
if you're doing CGI then the X11 device is not available.  You can try
using the `bitmap' device if you want jpeg or png.  This converts to
jpeg/png from postscript.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Mon, 17 Mar 2003, Adaikalavan Ramasamy wrote:

> Dear all,
> 
> I am trying to create a web interface using Perl-CGI to call R plots and
> to display them.
> The following codes works perfectly fine when I copy and paste into the
> console directly or if I save it into script.file and then R --no-save <
> script.file producing the graphs. 
> 
> jpeg("graph.jpeg", width=400, height=400)
> plot(rnorm(100))
> dev.off()
> 
> Now, I put the line system("R --no-save < script.file > log_file") from
> inside my cgi and then process it from client side, I get the following
> error message:
> 
> 
> Error in X11(paste("jpeg::", quality, ":", filename, sep = ""), width,
> : 
>         unable to start device JPEG
> In addition: Warning message: 
> unable to open connection to X11 display`' 
> Execution halted
> 
> 
> Why do I get this error and how can I fix it? Many thanks in advance.
> 
> Regards, Adai.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From rpeng at stat.ucla.edu  Mon Mar 17 18:19:49 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 17 Mar 2003 09:19:49 -0800 (PST)
Subject: [R] Error in making R-1.6.2.
In-Reply-To: <200303170039.h2H0dZ918294@gelfand.math.unb.ca>
Message-ID: <Pine.GSO.4.10.10303170916160.25151-100000@quetelet.stat.ucla.edu>

My experience (which isn't worth much) is that the problem isn't with the
header file itself but that it depends on some *other* header file that
isn't getting included.  This other file may have macro definitions, etc.
which, if not included, could cause a parse error. 

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Sun, 16 Mar 2003, Rolf Turner wrote:

> 
> I have just tried to update the version of R on our system, and when
> I did ``make'', I got the following error message:
> 
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
> gcc  -I. -I../../src/include -I../../src/include  -DHAVE_CONFIG_H   -g -O2 -c platform.c -o platform.o
> In file included from /usr/include/netinet/in.h:41,
>                  from /usr/include/netdb.h:96,
>                  from platform.c:1079:
> /usr/include/sys/stream.h:307: parse error before "projid_t"
> *** Error code 1
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
> 
> I looked at the file /usr/include/sys/stream.h and found the
> offending line.  It is right at the end of a ``typedef''
> construction.  (Whatever that is; I don't speak C.)  I've included
> the beginning of this construction in what I've displayed below, so
> that you can see ``where things are coming from''.  (???)
> 
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
> typedef struct datab {                         <--- Line 277 (my annotation)
>         frtn_t          *db_frtnp;
>         unsigned char   *db_base;
>         unsigned char   *db_lim;
>         unsigned char   db_ref;
>                   .
>                   .
>                   .
>         fthdr_t         *db_fthdr;
>         ftflw_t         ***db_ftflw;
>         uid_t           db_uid;         /* Effective user id */
>         /* project ID - EXPERIMENTAL - may change in future release */
>         projid_t        db_projid;             <--- Line 307 (my annotation)
> } dblk_t;
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
> 
> I have no idea why there should be a ``parse error'' at or before
> line 307.  Can anyone enlighten me and suggest what I can do about it?
> 
> The information about the current version is:
> 
> platform sparc-sun-solaris2.9
> arch     sparc               
> os       solaris2.9          
> system   sparc, solaris2.9   
> status                       
> major    1                   
> minor    5.1                 
> year     2002                
> month    06                  
> day      17                  
> language R
> 
> (As you can see I haven't upgraded for a while.  Sigh.  I've been
> afraid of running into the sort of trouble that I've just run into.)
> 
> I'll be grateful for any advice, but I would humbly request that
> you express it in terms as simple and explicit as you can.  As I said,
> I don't speak C, and I'm very much fumbling about in the dark here.
> 
> 					cheers,
> 
> 						Rolf Turner
> 						rolf at math.unb.ca
> 
> P. S.  There are a bunch of WARNING messages in config.log, which may
> be relevant as some of them refer to ``netinet'' and ``netdb:
> 
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
> configure:8871: WARNING: you cannot build info versions of the R manuals
> configure:12127: WARNING: arpa/inet.h: present but cannot be compiled
> configure:12129: WARNING: arpa/inet.h: check for missing prerequisite headers?
> configure:12131: WARNING: arpa/inet.h: proceeding with the preprocessor's result
> 
> configure:12127: WARNING: netdb.h: present but cannot be compiled
> configure:12129: WARNING: netdb.h: check for missing prerequisite headers?
> configure:12131: WARNING: netdb.h: proceeding with the preprocessor's result
> configure:12127: WARNING: netinet/in.h: present but cannot be compiled
> configure:12129: WARNING: netinet/in.h: check for missing prerequisite headers?
> configure:12131: WARNING: netinet/in.h: proceeding with the preprocessor's resul
> t
> configure:12127: WARNING: sys/socket.h: present but cannot be compiled
> configure:12129: WARNING: sys/socket.h: check for missing prerequisite headers?
> configure:12131: WARNING: sys/socket.h: proceeding with the preprocessor's resul
> t
> configure:12709: WARNING: could not determine type of socket length
> configure:26299: WARNING: could not determine type of socket length
> configure:26327: WARNING: you cannot build info versions of the R manuals
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From N.H.Spencer at herts.ac.uk  Mon Mar 17 15:06:11 2003
From: N.H.Spencer at herts.ac.uk (Neil Spencer)
Date: Mon, 17 Mar 2003 14:06:11 -0000
Subject: [R] Short Course in R: University of Hertfordshire
Message-ID: <030e01c2ec8e$5d572aa0$de68c593@herts.ac.uk>

           One-day Course in R

       University of Hertfordshire

         Thursday 24th April 2003


http://www.herts.ac.uk/business/centres/sscu/


R is a freely-available computer package for statistics used by
professional statisticians. The command language used by R is very
similar to that used by S-PLUS, and this course also acts as an
introduction to the command language used by this package.

R can carry out standard statistical analyses, and also has powerful
facilities for users to create their own commands for non-standard
analyses or for new statistical methods. Users of R frequently publish
the code for their commands on the internet for others to use.

The main topics covered by the course are:

Obtaining the R package from the internet
Data entry and simple summary statistics
Basic statistical procedures
Obtaining and using commands designed by other researchers
Developing your own commands for non-standard analyses


Course fee: ?295 including zero V.A.T.


For an application form, please go to
http://www.herts.ac.uk/business/centres/sscu/
or contact Denise Pope on 01707 285028,
e-mail D.A.M.Pope at herts.ac.uk.

******************************************************************
Dr Neil H. Spencer
Senior Lecturer in Statistics
Head of Statistical Services and Consultancy Unit

Statistical Services and Consultancy Unit Address:
Lindop Building, University of Hertfordshire, Hatfield Campus,
College Lane, Hatfield, AL10 9AB, U.K.
Telephone: +44 (0) 1707 284366
Fax: +44 (0) 1707 284799
E-mail: statistics at herts.ac.uk
WWW: http://www.herts.ac.uk/business/centres/sscu

Departmental Address:
Dept. of Statistics, Economics, Accounting and Management Systems,
Business School, University of Hertfordshire, Hertford Campus,
Mangrove Road, Hertford, SG13 8QF, U.K.
Telephone: +44 (0) 1707 285529
Fax: +44 (0) 1707 285489
E-mail: N.H.Spencer at herts.ac.uk
WWW: http://www.herts.ac.uk/business/staff_public/nhspencer_public


From rpeng at stat.ucla.edu  Mon Mar 17 18:27:52 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 17 Mar 2003 09:27:52 -0800 (PST)
Subject: [R] Trying to build R-1.6.2 under sparc-sun-solaris2.9.
In-Reply-To: <200303171630.h2HGUZRA029389@erdos.math.unb.ca>
Message-ID: <Pine.GSO.4.10.10303170924570.25151-100000@quetelet.stat.ucla.edu>

Is it possible that something has changed in your system setup since the
last install?  The problem below seems to be that SOCKLEN_T is not
defined, which is why (I think) you get the error

> Rsock.c:378: `len' undeclared (first use in this function)

If I remember correctly, your configure gave warnings about not being able
to determine the length of a socket, which is defined in some header
files on your system somewhere (sorry, I don't use Solaris).  I'd check to
make sure these are being included or that their in the place R thinks
they are.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Mon, 17 Mar 2003, Rolf Turner wrote:

> 
> This is a follow-up to a message I posted yesterday concerning
> building R-1.6.2.
> 
> After a deafening silence regarding that first message I decided
> to be fool-hardy and just comment out the line that seemed to
> be giving trouble in the file /usr/include/sys/stream.h.
> 
> This worked for a while, but soon another error resulted:
> 
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
> gcc -I. -I../../../src/include -I../../../src/include  -DHAVE_CONFIG_H  -fPIC  -g -O2 -c Rsock.c -o Rsock.lo
> Rsock.c: In function `R_SockConnect':
> Rsock.c:378: `len' undeclared (first use in this function)
> Rsock.c:378: (Each undeclared identifier is reported only once
> Rsock.c:378: for each function it appears in.)
> *** Error code 1
> make: Fatal error: Command failed for target `Rsock.lo'
> Current working directory /tmp/Rtmp/R-1.6.2/src/modules/internet
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> Current working directory /tmp/Rtmp/R-1.6.2/src/modules/internet
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> Current working directory /tmp/Rtmp/R-1.6.2/src/modules
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> Current working directory /tmp/Rtmp/R-1.6.2/src
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
> 
> Now this (Rsock.c) is actually dinky-di R code, but of course the
> error has probably been induced by the previous error involving
> ``stream.h'' and possibly aggravated by my commenting out the
> offending line in stream.h.
> 
> Has anyone out there a clue as to what is going on, and what
> I might do to fix it?
> 
> Everlastingly grateful for any suggestions.
> 
> 				cheers,
> 
> 					Rolf Turner
> 					rolf at math.unb.ca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From ligges at statistik.uni-dortmund.de  Mon Mar 17 18:41:22 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 17 Mar 2003 18:41:22 +0100
Subject: [R] Error in file(file, "r")
In-Reply-To: <EA37C22921B7D611AF5200508B949B5A013F5BF6@atlanta_nt2.atlanta.glenayre.com>
References: <EA37C22921B7D611AF5200508B949B5A013F5BF6@atlanta_nt2.atlanta.glenayre.com>
Message-ID: <3E7608C2.3010301@statistik.uni-dortmund.de>

Chisolm, Barbara wrote:
> Hello,
> 
> I am a new user of R, and I am not able to read/scan external files.  I am
> working in a Linux environment.  I have read through the R FAQ and documents
> and have not been successful using the recommendations.  Below are several
> scripts I've used and the error messages. .  
> 
> I've cc'd Brandon Whitcher because it was recommended in another FAQ.   I
> read that this is a bug that occurs on Windows.   Is there is a patch/fix
> that I can use?  I'd appreciate any help with this problem.
> 
> Thnx,
> Barbara Chisolm
> 
> Test2 <- scan("C:\\bac\\TestData2")
> Error in file(file, "r") : cannot open file `C:\bac\TestData2

You told us you are on Linux, but C:\bac\TestData2 does look like a 
Windows environment!

>>test1<-read.table('J:/bac/R/TestDataWord.txt')
> 
> Error in file(file, "r") : cannot open file `J:/bac/R/TestDataWord.txt'
 >
> 
>>setwd("J:/bac/R/")
> 
> Error in setwd(dir) : cannot change working directory

If all these files / paths do exist: Which version of R / Windows are 
you using?

Uwe Ligges


From partha_bagchi at hgsi.com  Mon Mar 17 19:20:08 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Mon, 17 Mar 2003 13:20:08 -0500
Subject: [R] Error in file(file, "r")
Message-ID: <OF304A2FB8.F1D89A7E-ON85256CEC.006475CD-85256CEC.0064B88D@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030317/e49fc193/attachment.pl

From kwan022 at stat.auckland.ac.nz  Mon Mar 17 19:52:37 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 18 Mar 2003 06:52:37 +1200 (NZST)
Subject: [R] xgobi?
In-Reply-To: <20030317132852.GC7826063@fry.research.att.com>
Message-ID: <Pine.LNX.4.33.0303180651490.28042-100000@stat56.stat.auckland.ac.nz>

Are there any plans to implement XGvis features in GGobi?  I find the 
multidimensional scaling in XGvis quite interesting. ;-)

On Mon, 17 Mar 2003, Deborah Swayne wrote:

> Date: Mon, 17 Mar 2003 08:28:52 -0500
> From: Deborah Swayne <dfs at research.att.com>
> To: Miha STAUT <mihastaut at hotmail.com>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] xgobi?
> 
> > As far as I understood from the documentation of xgobi. The package is 
> > intended to plot data in 3D (and more). 
> 
> While xgobi is still available, it is no longer receiving much of its
> authors' attention.  Its successor ggobi (www.ggobi.org), on the other
> hand, is growing all the time.  While xgobi can be launched from R,
> that is the extent of its relationship to S or R; no live connection
> between the two processes is maintained.  ggobi, on the other hand, is
> embedded in R and has an API which is expressed in the Rggobi package.
> The curious are welcome to direct further questions about ggobi and
> Rggobi to ggobi-help at ggobi.org.
> 
> Debby
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From deli-wang at uiowa.edu  Mon Mar 17 20:42:50 2003
From: deli-wang at uiowa.edu (Deli Wang)
Date: Mon, 17 Mar 2003 13:42:50 -0600
Subject: [R] Using .Call function to do matrix calculation
Message-ID: <200303171342.50552.deli-wang@uiowa.edu>

Hello, 

Because of high dimensionality of matrix, I can not use R matrix calculation 
operator to do matrix multiplication.  My interest is the diagonal elements 
of J*J matrix( which can be got by multiplying matrix a(J*K) and b(K*J)),  
where J is too big to allocate enough memory for it.  In order to get those 
diagonals, I tried .Call function to do that. Here is c program for .Call.

#include <R.h>
#include <Rinternals.h>

SEXP var(SEXP a,SEXP b){
 int i,J=nrows(a),j,K=nrows(b),k;

 SEXP varbeta;
 PROTECT(varbeta=allocVector(REALSXP,J));

 for(j=0;j<J;j++){
  for(k=0;k<J;k++){
  if(j==k){
        for(i=0;i<K;i++) REAL(varbeta)[j]+=REAL(a)[j+i*J]*REAL(b)[i+k*K];}
    }
   }

 UNPROTECT(1);

 return (varbeta);
 }

This function did not work at all. The warning messages is the segmentation 
fault.

Could some expert help me out?

Thanks.


From r.hankin at auckland.ac.nz  Mon Mar 17 22:01:28 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Tue, 18 Mar 2003 09:01:28 +1200
Subject: [R] scoping rules; summary
Message-ID: <200303172101.h2HL1Sb4024187@r.hankin.sges.auckland.ac.nz>

Hi everyone

thanks for the replies.

The issue was NOT a font problem; I deliberately chose ll1 and l11 as
examples of easily confused variable names (evidently these were too
easily confused ;-).  The code snippet was written as intended, and
increment() contained a deliberate, highlighted, bug.  I was asking
for guidance on avoiding/finding this sort of coding error.

That was why I wrote "#bug here" in the original code, and why the
function was called increment()---because the function should have
incremented x by adding a variable whose value was 1 (of course, the
function as written, contrary to the desired functionality of
increment(), added a variable whose value was 2).  I guess I wasn't
explicit enough here.  Sorry.

The fundamental problem was, how to tell that a variable being used in
a function is not local?

One answer (thanks Patrick!): conflicts() shows masked objects on the
search path, which is not quite what I need: I want some way to list
all non-local variables that increment() uses in its body.



[The original variable names referred to genetic bandsharing data for
possums, eg

coates.female.pouchyoung.allbands.method5
and
huapai.young.male.sibling.relatedness.method3
and
huapai.old.female.nonsibling.relatedness.justdarkbands.method1

ad nauseum...hence the need for shorter example variable names!]




ll1 <- 2          #sic
increment <- function(x)
{
  l11 <- 1        #sic
  return(x+ll1)   #sic; deliberate bug here (sic)
}






-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042


From jfox at mcmaster.ca  Mon Mar 17 21:59:05 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 17 Mar 2003 15:59:05 -0500
Subject: [R] Using .Call function to do matrix calculation
In-Reply-To: <200303171342.50552.deli-wang@uiowa.edu>
Message-ID: <5.0.2.1.0.20030317155218.028bc4d8@mcmail.cis.mcmaster.ca>

Dear Deli Wang,

Perhaps this isn't what you're looking for, but it occurs to me that you 
probably can do this problem without compiled code as sapply(1:nrow(a), 
function(i) sum(a[i,] * b[,i])). This doesn't use much memory, and though 
it may execute slowly, you may also get the answer before you debug your C 
code.

I hope that this helps,
  John

At 01:42 PM 3/17/2003 -0600, Deli Wang wrote:
>Hello,
>
>Because of high dimensionality of matrix, I can not use R matrix calculation
>operator to do matrix multiplication.  My interest is the diagonal elements
>of J*J matrix( which can be got by multiplying matrix a(J*K) and b(K*J)),
>where J is too big to allocate enough memory for it.  In order to get those
>diagonals, I tried .Call function to do that. Here is c program for .Call.
>
>#include <R.h>
>#include <Rinternals.h>
>
>SEXP var(SEXP a,SEXP b){
>  int i,J=nrows(a),j,K=nrows(b),k;
>
>  SEXP varbeta;
>  PROTECT(varbeta=allocVector(REALSXP,J));
>
>  for(j=0;j<J;j++){
>   for(k=0;k<J;k++){
>   if(j==k){
>         for(i=0;i<K;i++) REAL(varbeta)[j]+=REAL(a)[j+i*J]*REAL(b)[i+k*K];}
>     }
>    }
>
>  UNPROTECT(1);
>
>  return (varbeta);
>  }
>
>This function did not work at all. The warning messages is the segmentation
>fault.
>
>Could some expert help me out?
>
>Thanks.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox


From Mcleod at cc.admin.unt.edu  Mon Mar 17 22:39:56 2003
From: Mcleod at cc.admin.unt.edu (Patrick Mcleod)
Date: Mon, 17 Mar 2003 15:39:56 -0600
Subject: [R] postscript and ps.option metrics
Message-ID: <se75ec5e.005@gwia.unt.edu>

Good Afternoon All,

I am working on a project to generate a particular celeration graph that requires a very specific height and width in the format of the postscript output.

I have attempted to specify my height and width parameters in inches as I found in the R help documentation, but this produces a graph much smaller than what it should if the standard metric is indeed inches.

Since inches do not work, I've tried to "eyeball" the metric by printing out different iterations of the height and width parameters and overlaying a copy of the graph I need on it. This is very time consuming (which I don't mind), inefficient (which I do mind), and tedious (which I do mind) as the width axis (X axis in landscape format) doesn't seem to be moving as the parameter decreases in iterations.

If someone has a few minutes, could you review the code snippet below and provide any suggestions about possible revisions/additions to this? I've looked at it so long I can't tell what might be glaringly wrong or missing.

Many Thanks,

Patrick McLeod
University of North Texas
Denton, TX.

P.S.

The specific axis measurements (in inches) should be: height=5.4, width=8.1 in a landscape format.

# TODO:

#win.graph(width=8.6,height=11.5)

postscript("C:/Data/xxxx.ps", width = 11.6, height = 7.5,
horizontal = TRUE, onefile = TRUE, paper = "letter",
family = "ComputerModern")

# Import Sample Data: Movies IMDB)
 movies <- read.table('xxxxx', header=T, row.names=NULL)
 attach(movies)

# cases <- read.table('xxxxx', header=T, row.names=NULL)
# attach(cases)

# Set up the chart

yticks <- c(1,2,3,4,5,6,7,8,9,
            10,20,30,40,50,60,70,80,90,
            100,200,300,400,500,600,700,800,900,
            1000,2000,3000,4000,5000,6000,7000,8000,9000,
            10000,20000,30000,40000,50000,60000,70000,80000,90000,
            100000,200000,300000,400000,500000,600000,700000,800000,900000,1000000)

myticks <- c(1,10,100,1000,10000,100000,1000000)
mylabs <- c("1","10","100","1,000","10,000","100,000", "1,000,000")

mnyticks <- c(5,50,500,5000,50000,500000)
mnylabs <- c("5","50","500","5,000","50,000","500,000")

xticks <- c(1:100)
#mxticks <- c(0,10,20,30,40,50,60,70,80,90,100)
periods <- c(1900,1905,1910,1915,1920,1925,1930,1935,1940,1945,1950,1955,1960,1965,1970,1975,1980,1985,1990,1995,2000)
mxticks <- c(1900,1910,1920,1930,1940,1950,1960,1970,1980,1990,2000)
mnxticks <- c(1905,1915,1925,1935,1945,1955,1965,1975,1985,1995)

mxlabs <- c("0","10","20","30","40","50","60","70","80","90","100")

plot(Year,Movies,ylim=c(1,1000000),xlim=c(1902,2002),log='y',type='o',axes=F)

axis(side=2, at=myticks, las=2, labels=mylabs, pos=1900, tck=-0.02)
axis(side=2, at=myticks, pos=1900, tck=.95, labels=F)

axis(side=2, at=yticks, labels=F, pos=1900, tck=0.01)
axis(side=2, at=yticks, labels=F, pos=1900, tck=0.93)

axis(side=2, at=mnyticks, las=2, labels=mnylabs, pos=1900, tck=-0.015, cex=.5)
axis(side=2, at=mnyticks, las=2, labels=F, pos=1900, tck=0.93, cex=.5)

axis(side=1, at=mxticks, pos=1, labels=mxlabs, tck=-0.02)
axis(side=1, at=c(1900:2000), pos=1, labels=F,tck=-0.01)
axis(side=1, at=mnxticks,pos=1, tck=.01, labels=F)
axis(side=1, at=periods, pos=1, tck=.93, labels=F)
axis(side=3, at=mxticks, pos=1000000)

axis(side=4,pos=2000,labels=F,tck=0)

dev.off()


From yfan at diversa.com  Mon Mar 17 23:06:54 2003
From: yfan at diversa.com (Yiping Fan)
Date: Mon, 17 Mar 2003 14:06:54 -0800
Subject: [R] search engine dose not work for Morzilla
Message-ID: <6AC569D81BF88545B395BD2D4984F106019E69@CHAMAELEON.diversa.com>

Hello,
   I am running R1.6.2 on Redhat8.0. I use Morzilla to display the html
file.  However,the search engine does not work.  eg. I type plot and
press search, it does not return the result but show the same page.  Any
idea?  Thanks!

Y.Fan


From maj at stats.waikato.ac.nz  Mon Mar 17 23:09:14 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue, 18 Mar 2003 10:09:14 +1200
Subject: [R] help with likelihood contour plot
Message-ID: <3E76478A.2020408@stats.waikato.ac.nz>

Can some kind person point out my error here? I'm trying to set up a 
grid for a countour plot of a likelihood function.

 > u <- rnorm(20,9.5,2.5)
 > # sample of size 20 from N(9.5,2.5^2)
 > loglik <- function(th1,th2) {
+ n <- length(u)
+ -(n/2)*log(2*pi*th2^2)-0.5*sum((u-th1)^2/th2^2)
+ }
 > x <- seq(4.5,14.5,len=50)
 > y <- seq(0.5,6,len=50)
 > f <- outer(x, y, loglik(x,y))
Error in match.fun(FUN) : not function, character, or symbol: "loglik(x, y)"
In addition: Warning message:
longer object length
         is not a multiple of shorter object length in: u - th1
 > loglik(9,2)
[1] -44.56294
 > is.function(loglik)
[1] TRUE

Thanks,

Murray
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862


From mschwartz at medanalytics.com  Mon Mar 17 23:20:23 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 17 Mar 2003 16:20:23 -0600
Subject: [R] search engine dose not work for Morzilla
In-Reply-To: <6AC569D81BF88545B395BD2D4984F106019E69@CHAMAELEON.diversa.com>
Message-ID: <020601c2ecd3$69649810$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yiping Fan
>Sent: Monday, March 17, 2003 4:07 PM
>To: R_Help (E-mail)
>Subject: [R] search engine dose not work for Morzilla
>
>
>Hello,
>   I am running R1.6.2 on Redhat8.0. I use Morzilla to display 
>the html file.  However,the search engine does not work.  eg. 
>I type plot and press search, it does not return the result 
>but show the same page.  Any idea?  Thanks!
>
>Y.Fan


See my prior post on this here:

http://maths.newcastle.edu.au/~rking/R/help/02b/4228.html

Also be sure that under Prefences (Advanced and Scripts/Plugins) that
BOTH Java and JavaScript are enabled.

Regards,

Marc Schwartz


From sundar.dorai-raj at pdf.com  Mon Mar 17 23:29:34 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 17 Mar 2003 16:29:34 -0600
Subject: [R] help with likelihood contour plot
References: <3E76478A.2020408@stats.waikato.ac.nz>
Message-ID: <3E764C4E.4070900@pdf.com>



Murray Jorgensen wrote:
> Can some kind person point out my error here? I'm trying to set up a 
> grid for a countour plot of a likelihood function.
> 
>  > u <- rnorm(20,9.5,2.5)
>  > # sample of size 20 from N(9.5,2.5^2)
>  > loglik <- function(th1,th2) {
> + n <- length(u)
> + -(n/2)*log(2*pi*th2^2)-0.5*sum((u-th1)^2/th2^2)
> + }
>  > x <- seq(4.5,14.5,len=50)
>  > y <- seq(0.5,6,len=50)
>  > f <- outer(x, y, loglik(x,y))
> Error in match.fun(FUN) : not function, character, or symbol: "loglik(x, 
> y)"
> In addition: Warning message:
> longer object length
>         is not a multiple of shorter object length in: u - th1
>  > loglik(9,2)
> [1] -44.56294
>  > is.function(loglik)
> [1] TRUE
> 
> Thanks,
> 
> Murray


Murray,
   From ?outer:

Details:

      `FUN' must be a function (or the name of it) which expects at
      least two arguments and which operates elementwise on arrays.


Thus, use "loglik" and not "loglik(x,y)", as in:

outer(x,y,loglik)

Regards,
Sundar


From rpeng at stat.ucla.edu  Tue Mar 18 02:31:45 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 17 Mar 2003 17:31:45 -0800 (PST)
Subject: [R] help with likelihood contour plot
In-Reply-To: <3E764C4E.4070900@pdf.com>
Message-ID: <Pine.GSO.4.10.10303171725010.27364-100000@quetelet.stat.ucla.edu>

Be careful, I don't think your loglik function is vectorized correctly. In
particular, it only works for single values of th1 and th2. If th1 or th2
are vectors, you will get a warning and the wrong answer. The problem is
the subtraction u - th1, because u is already vector.

outer() expects that the function you pass in is vectorized and will work
elementwise on arrays, not just single values.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Mon, 17 Mar 2003, Sundar Dorai-Raj wrote:

> 
> 
> Murray Jorgensen wrote:
> > Can some kind person point out my error here? I'm trying to set up a 
> > grid for a countour plot of a likelihood function.
> > 
> >  > u <- rnorm(20,9.5,2.5)
> >  > # sample of size 20 from N(9.5,2.5^2)
> >  > loglik <- function(th1,th2) {
> > + n <- length(u)
> > + -(n/2)*log(2*pi*th2^2)-0.5*sum((u-th1)^2/th2^2)
> > + }
> >  > x <- seq(4.5,14.5,len=50)
> >  > y <- seq(0.5,6,len=50)
> >  > f <- outer(x, y, loglik(x,y))
> > Error in match.fun(FUN) : not function, character, or symbol: "loglik(x, 
> > y)"
> > In addition: Warning message:
> > longer object length
> >         is not a multiple of shorter object length in: u - th1
> >  > loglik(9,2)
> > [1] -44.56294
> >  > is.function(loglik)
> > [1] TRUE
> > 
> > Thanks,
> > 
> > Murray
> 
> 
> Murray,
>    From ?outer:
> 
> Details:
> 
>       `FUN' must be a function (or the name of it) which expects at
>       least two arguments and which operates elementwise on arrays.
> 
> 
> Thus, use "loglik" and not "loglik(x,y)", as in:
> 
> outer(x,y,loglik)
> 
> Regards,
> Sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From ggrothendieck at volcanomail.com  Tue Mar 18 03:48:48 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Mon, 17 Mar 2003 18:48:48 -0800 (PST)
Subject: [R] Building hdf5 for ms-windows
Message-ID: <20030318024848.7B1E54239@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030317/ae2f9608/attachment.pl

From laurent at cbs.dtu.dk  Tue Mar 18 04:03:14 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Tue, 18 Mar 2003 04:03:14 +0100
Subject: [R] Building hdf5 for ms-windows
In-Reply-To: <20030318024848.7B1E54239@sitemail.everyone.net>
References: <20030318024848.7B1E54239@sitemail.everyone.net>
Message-ID: <20030318030314.GC4195376@genome.cbs.dtu.dk>

On Mon, Mar 17, 2003 at 06:48:48PM -0800, Gabor Grothendieck wrote:
> I am trying to build hdf5 for ms-windows.  I downloaded the hdf5_1.4.7.tar.gz, gunzipped it and got a tar file.  I extracted everything into a directory tree called hdf5.  I also found a Makevars.win and libhdf5.def in the R help archives from March 2002.  I put those two in hdf5 as well.
> 
> I issued the command     Rcmd build --binary hdf5
> but got this message complaining it can't find hdf5.h along with subsequent errors.
> 
> making DLL ...
> making hdf5.d from hdf5.c
> hdf5.c:24:18: hdf5.h: No such file or directory
> make[2]: *** [hdf5.d] Error 1
> make[1]: *** [src/hdf5.dll] Error 2
> make: *** [pkg-hdf5] Error 2
> make: Leaving directory `/cygdrive/c/PROGRA~1/R/rw1062/src/gnuwin32'
> *** Installation of hdf5 failed ***
> 
> What should I do?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


If your aim is only to get a working version of a package to have hdf5 functionalities,
you can try the package rhdf5 at www.bioconductor.org (there should be
a MSWindows build).


Hopin' it helps,


L.


-- 
--------------------------------------------------------------
currently at the National Yang-Ming University in Taipei, Taiwan
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent


From masuno at masunosoftware.com  Tue Mar 18 06:32:20 2003
From: masuno at masunosoftware.com (Hiroshi Masuno)
Date: Tue, 18 Mar 2003 14:32:20 +0900
Subject: [R] How to use R from Delphi
Message-ID: <20030318142914.049C.MASUNO@masunosoftware.com>

Dear Sirs,

I am a beginner about R.
Please teach me how to use R from delphi.
I know how to use R from Visual Basic, but I could not find how to use R
from delphi.

Sincerely Yours,
Hiroshi Masuno
<masuno at masunosoftware.com>


From jlvw at rau.ac.za  Tue Mar 18 06:37:49 2003
From: jlvw at rau.ac.za (Jacob van Wyk)
Date: Tue, 18 Mar 2003 07:37:49 +0200
Subject: [R] Simulation
Message-ID: <se76ccd6.018@rauzen.rau.ac.za>

Hallo all users of R.
I wish to simulate a simple linear regression, y=a+bx+e, (n=40, say),
where x is
N(0,1) and where
e is N(0,1), with probability 0.9, and
e is 3*(chisq(40,1)-1), say, with probability 0.1.
For e: would the following work, or is there a better way?

p <- rbinom(40,1,0.9)
e <- rnorm(40,0,1)*p + 3*(rchisq(40,1)-1)*(1-p)

Thanks for your time.
Regards
Jacob



Jacob L van Wyk
Department of Mathematics and Statistics
Rand Afrikaans University
P O Box 524
Auckland Park 2006
South Africa
Tel: +27-11-489-3080
Fax: +27-11-489-2832


______________________________________

VRYWARING\ \ Die inhoud en enige aanhegsels van hierdie elektron... [[dropped]]


From robert.king at newcastle.edu.au  Tue Mar 18 07:40:32 2003
From: robert.king at newcastle.edu.au (Robert King)
Date: Tue, 18 Mar 2003 17:40:32 +1100 (EST)
Subject: [R] Package installation when $RHOME is not writable (win)
Message-ID: <Pine.LNX.4.21.0303181737510.30629-100000@tolstoy.newcastle.edu.au>

I'm using R in a student lab with machines running win XP.  $RHOME is not
writable by the students.  How do I set this up so that they can install
packages?
               
Thanks,
Robert.
----
Robert King, Statistics, School of Mathematical & Physical Sciences,
University of Newcastle, Australia
Room V133  ph +61 2 4921 5548
Robert.King at newcastle.edu.au   http://maths.newcastle.edu.au/~rking/


From laurent at cbs.dtu.dk  Tue Mar 18 08:11:29 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Tue, 18 Mar 2003 08:11:29 +0100
Subject: [R] Package installation when $RHOME is not writable (win)
In-Reply-To: <Pine.LNX.4.21.0303181737510.30629-100000@tolstoy.newcastle.edu.au>
References: <Pine.LNX.4.21.0303181737510.30629-100000@tolstoy.newcastle.edu.au>
Message-ID: <20030318071129.GE4195376@genome.cbs.dtu.dk>

On Tue, Mar 18, 2003 at 05:40:32PM +1100, Robert King wrote:
> I'm using R in a student lab with machines running win XP.  $RHOME is not
> writable by the students.  How do I set this up so that they can install
> packages?
>                
> Thanks,
> Robert.
> ----
> Robert King, Statistics, School of Mathematical & Physical Sciences,
> University of Newcastle, Australia
> Room V133  ph +61 2 4921 5548
> Robert.King at newcastle.edu.au   http://maths.newcastle.edu.au/~rking/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

I am not very familiar with the windows version, but on unices this can be done without any problem.
Try '?install.packages' and check the parameter 'lib' (or 'instlib')


Hopin' it helps,


Laurent



-- 
--------------------------------------------------------------
currently at the National Yang-Ming University in Taipei, Taiwan
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent


From hb at maths.lth.se  Mon Mar 17 22:23:20 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 18 Mar 2003 08:23:20 +1100
Subject: [R] Package installation when $RHOME is not writable (win)
In-Reply-To: <Pine.LNX.4.21.0303181737510.30629-100000@tolstoy.newcastle.edu.au>
Message-ID: <001201c2eccb$6f77e5c0$e502eb82@alpha.wehi.edu.au>

Your are looking for the environment variable R_LIBS, which allows local
installation of packages. See "R Installation and Administration" and
"An Introduction to R", which you find by help.start(). Note that R_LIBS
can be set by the shell script or ~/Renviron as said in the former
document.

Cheers

Henrik Bengtsson
Mathematical Statistics, Lund University
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Robert King
> Sent: den 18 mars 2003 17:41
> To: r-help at stat.math.ethz.ch
> Subject: [R] Package installation when $RHOME is not writable (win)
> 
> 
> I'm using R in a student lab with machines running win XP.  
> $RHOME is not writable by the students.  How do I set this up 
> so that they can install packages?
>                
> Thanks,
> Robert.
> ----
> Robert King, Statistics, School of Mathematical & Physical 
> Sciences, University of Newcastle, Australia Room V133  ph 
> +61 2 4921 5548
> Robert.King at newcastle.edu.au   http://maths.newcastle.edu.au/~rking/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>


From kwan022 at stat.auckland.ac.nz  Tue Mar 18 07:28:10 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 18 Mar 2003 18:28:10 +1200 (NZST)
Subject: [R] Package installation when $RHOME is not writable (win)
In-Reply-To: <Pine.LNX.4.21.0303181737510.30629-100000@tolstoy.newcastle.edu.au>
Message-ID: <Pine.LNX.4.33.0303181827500.25092-100000@stat61.stat.auckland.ac.nz>

Hi,

I think this is covered in R for Windows FAQ in Section 2.11 and 2.12 
(http://cran.r-project.org/bin/windows/contrib/rw-FAQ.html)

On Tue, 18 Mar 2003, Robert King wrote:

> Date: Tue, 18 Mar 2003 17:40:32 +1100 (EST)
> From: Robert King <robert.king at newcastle.edu.au>
> To: r-help at stat.math.ethz.ch
> Subject: [R] Package installation when $RHOME is not writable (win)
> 
> I'm using R in a student lab with machines running win XP.  $RHOME is not
> writable by the students.  How do I set this up so that they can install
> packages?
>                
> Thanks,
> Robert.
> ----
> Robert King, Statistics, School of Mathematical & Physical Sciences,
> University of Newcastle, Australia
> Room V133  ph +61 2 4921 5548
> Robert.King at newcastle.edu.au   http://maths.newcastle.edu.au/~rking/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From tlumley at u.washington.edu  Tue Mar 18 09:02:12 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 18 Mar 2003 00:02:12 -0800 (PST)
Subject: [R] glm -gamma errors
In-Reply-To: <33383.160.45.172.237.1047917495.squirrel@www.medizin.fu-berlin.de>
Message-ID: <Pine.A41.4.44.0303180000060.37648-100000@homer09.u.washington.edu>

On Mon, 17 Mar 2003, Dr. Peter Schlattmann wrote:

>
> Dear list,
>
> I am looking for a way to fix the scale parameter when fitting a
> generalized linear model with gamma errors and log link.
>
> Is there something like "SCALE" such as in GLIM?
>

No. Because it doesn't affect the answers we don't provide a way to
specify it.

It does affect standard errors and the other output of summary.glm, so
this function does have a dispersion= argument.

	-thomas


From ripley at stats.ox.ac.uk  Tue Mar 18 09:11:56 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 18 Mar 2003 08:11:56 +0000 (GMT)
Subject: [R] postscript and ps.option metrics
In-Reply-To: <se75ec5e.005@gwia.unt.edu>
Message-ID: <Pine.LNX.4.44.0303180807090.12986-100000@gannet.stats>

Inches do work as documented, but you need to read an `An Introduction to
R' to see what it measures: it is the device region, not the figure region
nor the plot region.  That reference will tell you how to compute the size
of one from another.

On Mon, 17 Mar 2003, Patrick Mcleod wrote:

> I am working on a project to generate a particular celeration graph 
that requires a very specific height and width in the format of the 
postscript output.
> 
> I have attempted to specify my height and width parameters in inches 
as I found in the R help documentation, but this produces a graph 
much smaller than what it should if the standard metric is indeed inches.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Tue Mar 18 09:37:49 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 18 Mar 2003 09:37:49 +0100
Subject: [R] scoping rules; summary
References: <200303172101.h2HL1Sb4024187@r.hankin.sges.auckland.ac.nz>
Message-ID: <3E76DADD.99F1677E@statistik.uni-dortmund.de>



Robin Hankin wrote:
> 
> Hi everyone
> 
> thanks for the replies.
> 
> The issue was NOT a font problem; I deliberately chose ll1 and l11 as
> examples of easily confused variable names (evidently these were too
> easily confused ;-).  The code snippet was written as intended, and
> increment() contained a deliberate, highlighted, bug.  I was asking
> for guidance on avoiding/finding this sort of coding error.
> 
> That was why I wrote "#bug here" in the original code, and why the
> function was called increment()---because the function should have
> incremented x by adding a variable whose value was 1 (of course, the
> function as written, contrary to the desired functionality of
> increment(), added a variable whose value was 2).  I guess I wasn't
> explicit enough here.  Sorry.
> 
> The fundamental problem was, how to tell that a variable being used in
> a function is not local?
> 
> One answer (thanks Patrick!): conflicts() shows masked objects on the
> search path, which is not quite what I need: I want some way to list
> all non-local variables that increment() uses in its body.
> 
> [The original variable names referred to genetic bandsharing data for
> possums, eg
> 
> coates.female.pouchyoung.allbands.method5
> and
> huapai.young.male.sibling.relatedness.method3
> and
> huapai.old.female.nonsibling.relatedness.justdarkbands.method1
> 
> ad nauseum...hence the need for shorter example variable names!]
> 
> ll1 <- 2          #sic
> increment <- function(x)
> {
>   l11 <- 1        #sic
>   return(x+ll1)   #sic; deliberate bug here (sic)
> }


I think you are looking for ls() together with the debugging tool
browser():

increment <- function(x){
  l11 <- 1
  browser()    # just for debugging
  return(x+ll1)
}
increment(1)
# Now the browser opens and you can look for objects in the current
enviroment with ls().


Uwe Ligges



> --
> 
> Robin Hankin, Lecturer,
> School of Geography and Environmental Science
> Tamaki Campus
> Private Bag 92019 Auckland
> New Zealand
> 
> r.hankin at auckland.ac.nz
> tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From vfasciani at micron.com  Tue Mar 18 10:31:51 2003
From: vfasciani at micron.com (vfasciani)
Date: Tue, 18 Mar 2003 10:31:51 +0100
Subject: [R] X11 connection error in web cgi mode only
Message-ID: <713A0E408CB0D21183CF0008C7B98AC714EA4F3F@ntxamos02.azit.micron.com>

I had the some problem with some CGI and some perl program running on
SUN-SOLARIS.
At the first I left open an Xsession on my PC (NT4) adding on all programs
the followed lines:

$ENV{DISPLAY} = 'vfasciani:0.0';

In this way all programs ran well bacause they found my X11 service.

After, my system admin installed on my machine a Xvnc service
(www.realvnc.com) that allows to create graph.
Sorry but I'm not a deep UNIX user and for me is difficult explain all steps
to install it.
If you are interested I can send to you his email.

- Vittorio

_____________________
Vittorio Paolo Fasciani
Operation Software Technician
Micron Technology Italia
vfasciani at micron.com
_________________________


-----Original Message-----
From: Roger Peng [mailto:rpeng at stat.ucla.edu]
Sent: Monday, March 17, 2003 6:12 PM
To: Adaikalavan Ramasamy
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] X11 connection error in web cgi mode only


I believe you get this error because the jpeg and png libraries require
the X11 device to be open in order to generate the plot.  I'll guess that
if you're doing CGI then the X11 device is not available.  You can try
using the `bitmap' device if you want jpeg or png.  This converts to
jpeg/png from postscript.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Mon, 17 Mar 2003, Adaikalavan Ramasamy wrote:

> Dear all,
> 
> I am trying to create a web interface using Perl-CGI to call R plots and
> to display them.
> The following codes works perfectly fine when I copy and paste into the
> console directly or if I save it into script.file and then R --no-save <
> script.file producing the graphs. 
> 
> jpeg("graph.jpeg", width=400, height=400)
> plot(rnorm(100))
> dev.off()
> 
> Now, I put the line system("R --no-save < script.file > log_file") from
> inside my cgi and then process it from client side, I get the following
> error message:
> 
> 
> Error in X11(paste("jpeg::", quality, ":", filename, sep = ""), width,
> : 
>         unable to start device JPEG
> In addition: Warning message: 
> unable to open connection to X11 display`' 
> Execution halted
> 
> 
> Why do I get this error and how can I fix it? Many thanks in advance.
> 
> Regards, Adai.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Jan_Svatos at eurotel.cz  Tue Mar 18 11:48:29 2003
From: Jan_Svatos at eurotel.cz (Jan_Svatos@eurotel.cz)
Date: Tue, 18 Mar 2003 11:48:29 +0100
Subject: [R] References of R in use
Message-ID: <OF936CDCEC.7815647A-ONC1256CED.00393A45@eurotel.cz>

Dear R-users and expeRts,

can anyone provide me (and others as well, of course) with reference of
companies, scientific labs and/or schools where R is being used?
Or does some (even unofficial) list of comanies etc. where R is being used
exist?
I tried to find such an information on R's homepage and on a FAQ page, but
unsuccesfully.
(Of course, searching through this r-help conference one quickly finds lot
of universities, where R is being used, but I wonder whether there
exists some list)

Why I do I want this?

In general, managerial decisions (in large companies) about software are
most often based on references like
"Does this sotware use IBM, Sun, Oracle, MS,  big banks, big Telco
companies, NASA, Academy of Sciences, and so on?"
rather than "this soft is scalable, offers this and this and that, uses
proven and sound statistical methods..."

An information like "R is being (of course succesfully) used in ...." would
be of great help in any discussion about
Statistical and Data Mining software in our company (Eurotel is the largest
mobile operator in Czechia).
(although it seems that I am the only one or at most one of few people
knowing about R and using it in our company).

BTW,
wouldn't it be nice to have such a list somewhere at
http://www.r-project.org/ ?

Thanks in advance,
Jan


-------------------------------------------------
designed for _monospaced_ font
-------------------------------------------------
/- Jan Svatos, MSc, PhD     Sokolovska 215     -/
/- Data Analyst             Prague 9           -/
/- Eurotel Praha            190 00             -/
/- jan_svatos at eurotel.cz    Czechia            -/
-------------------------------------------------


From gengasla at cs.tu-berlin.de  Tue Mar 18 12:38:08 2003
From: gengasla at cs.tu-berlin.de (Oezlem Gengaslan)
Date: Tue, 18 Mar 2003 12:38:08 +0100 (MET)
Subject: [R] 
Message-ID: <Pine.SOL.4.53.0303181236550.28759@siesta>


Hi,

 can someone tell me, if there is a function in R for the modulo operator?

bye


From gregory.benmenzer at gazdefrance.com  Tue Mar 18 13:02:04 2003
From: gregory.benmenzer at gazdefrance.com (Gregory BENMENZER)
Date: Tue, 18 Mar 2003 13:02:04 +0100
Subject: =?iso-8859-1?Q?R=E9f=2E_=3A_[R]?=
Message-ID: <OF1118EE38.617A6042-ON41256CED.00420619@notes.edfgdf.fr>


look at the help with help(Arithmetic)

Gr?gory





gengasla at cs.tu-berlin.de@stat.math.ethz.ch on 18/03/2003 12:38:08

Envoy? par :      r-help-bounces at stat.math.ethz.ch


Pour : r-help at stat.math.ethz.ch
cc :    (ccc : Gregory BENMENZER/DEG/DR/EDFGDF/FR)
Objet :     [R]



Hi,

 can someone tell me, if there is a function in R for the modulo operator?

bye

______________________________________________
R-help at stat.math.ethz.ch mailing list
 https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From erich.neuwirth at univie.ac.at  Tue Mar 18 12:58:00 2003
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Tue, 18 Mar 2003 12:58:00 +0100
Subject: [R]
In-Reply-To: <Pine.SOL.4.53.0303181236550.28759@siesta>
References: <Pine.SOL.4.53.0303181236550.28759@siesta>
Message-ID: <3E7709C8.5000403@univie.ac.at>

Searching for
Arithmetic
shows
%%
as an infix operator




Oezlem Gengaslan wrote:

>Hi,
>
> can someone tell me, if there is a function in R for the modulo operator?
>
>bye
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>  
>


From katrin.braesel at imise.uni-leipzig.de  Tue Mar 18 14:07:10 2003
From: katrin.braesel at imise.uni-leipzig.de (Katrin Braesel)
Date: Tue, 18 Mar 2003 14:07:10 +0100
Subject: [R] To load Add-ons 
Message-ID: <FIEBLCNACFBLFGGEILDJIEBACAAA.katrin.braesel@imise.uni-leipzig.de>

Dear R Help-Team,

If I start R and type in
search()

the result is:
[1] ".GlobalEnv"    "package:ctest" "Autoloads"     "package:base"

I often need an Add-on-package. I can load it with "> library(package)" or
include a require-command in the .First-function. The .First-function is
fine, if I always use the same working directory. But I don't. And I'm not
the only one, who needs some Add-ons almost every time.
Is it possible to change the .First-function global? Or is there a
possibility to load a package by default for all users and independent from
the working directory, like "package:ctest" and "package:base"?

With kind regards
Katrin Braesel


From luke at stat.uiowa.edu  Tue Mar 18 14:11:27 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 18 Mar 2003 07:11:27 -0600 (CST)
Subject: [R] scoping rules; summary
In-Reply-To: <200303172101.h2HL1Sb4024187@r.hankin.sges.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0303180704540.31239-100000@itasca.stat.uiowa.edu>

On Tue, 18 Mar 2003, Robin Hankin wrote:

> Hi everyone
> 
> thanks for the replies.
> 
> The issue was NOT a font problem; I deliberately chose ll1 and l11 as
> examples of easily confused variable names (evidently these were too
> easily confused ;-).  The code snippet was written as intended, and
> increment() contained a deliberate, highlighted, bug.  I was asking
> for guidance on avoiding/finding this sort of coding error.
> 
> That was why I wrote "#bug here" in the original code, and why the
> function was called increment()---because the function should have
> incremented x by adding a variable whose value was 1 (of course, the
> function as written, contrary to the desired functionality of
> increment(), added a variable whose value was 2).  I guess I wasn't
> explicit enough here.  Sorry.
> 
> The fundamental problem was, how to tell that a variable being used in
> a function is not local?
> 
> One answer (thanks Patrick!): conflicts() shows masked objects on the
> search path, which is not quite what I need: I want some way to list
> all non-local variables that increment() uses in its body.
> 
> 
> 
> [The original variable names referred to genetic bandsharing data for
> possums, eg
> 
> coates.female.pouchyoung.allbands.method5
> and
> huapai.young.male.sibling.relatedness.method3
> and
> huapai.old.female.nonsibling.relatedness.justdarkbands.method1
> 
> ad nauseum...hence the need for shorter example variable names!]
> 
> 
> 
> 
> ll1 <- 2          #sic
> increment <- function(x)
> {
>   l11 <- 1        #sic
>   return(x+ll1)   #sic; deliberate bug here (sic)
> }
> 

I realise this won't help now, but I am currently working on some code
analysis tools for R that will hopefully be available by the end of
summer. These will include facilities for determining what global
variables are references in a piece of code; the current verion of would
does the following on this example:

> findGlobals(increment)
[1] "{"      "<-"     "return" "+"      "ll1"   

This set of tools will be integrated with name space mechanism that
will be available in 1.7.0. and will allow packages to be checked for
undefined functions and variables.  I suspect these tools will become
part of the tools package.

luke


-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From olefc at daimi.au.dk  Tue Mar 18 14:27:06 2003
From: olefc at daimi.au.dk (Ole Fredslund Christensen)
Date: Tue, 18 Mar 2003 14:27:06 +0100
Subject: [R] To load Add-ons 
Message-ID: <3E771EAA.A38E1110@daimi.au.dk>

Use the .Rprofile file for such things.

for example my file .Rprofile contains :


library(geoR)
library(geoRglm)
if(!exists(".Random.seed")) set.seed(1367)



-- 
Ole F. Christensen
BiRC
Datalogisk Institut
Aarhus Universitet
Ny Munkegade, Bygning 540 
8000 Aarhus C 
Denmark


From steve.roberts at man.ac.uk  Tue Mar 18 15:01:30 2003
From: steve.roberts at man.ac.uk (Steve Roberts)
Date: Tue, 18 Mar 2003 14:01:30 +0000
Subject: [R] Strange and disturbing bug
Message-ID: <3E7726BA.26128.3BD8D1@localhost>

How about this one? If I set a variable in a data.frame with a two-
part name including a dot (say y.pair), and if the variable with the 
name of the first part (y) doesn't but I ask for it's value I get the 
value of the two-part name. Ie set fred$x.pair and print the value of 
fred$x it gives me the value I set to fred$x.pair. Weird and 
somewhat disturbing!
Maybe an example makes it clearer:


  Dr Steve Roberts 
  steve.roberts at man.ac.uk

Senior Lecturer in Medical Statistics,
CMMCH NHS Trust and University of Manchester Biostatistics Group,
0161 275 5192 / 0161 276 5785


From duncan at research.bell-labs.com  Tue Mar 18 15:28:37 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Tue, 18 Mar 2003 09:28:37 -0500
Subject: [R] Strange and disturbing bug
In-Reply-To: <3E7726BA.26128.3BD8D1@localhost>;
	from steve.roberts@man.ac.uk on Tue, Mar 18, 2003 at 02:01:30PM +0000
References: <3E7726BA.26128.3BD8D1@localhost>
Message-ID: <20030318092837.D21397@jessie.research.bell-labs.com>


Hi Steve.

This is very much a feature, not a bug, and unless I am mistaken does
not relate to the use of a "two part name" (i.e. x.pair). 

The $ operator does partial matching on the names.  So fred$x yields
a partial match for fred$x.pair and gives you what you most likely
wanted.  Of course, using fred$x.pair makes this more readable in a
function/software, but partial matching is very convenient for
interactive use.

 D.


Steve Roberts wrote:
> How about this one? If I set a variable in a data.frame with a two-
> part name including a dot (say y.pair), and if the variable with the 
> name of the first part (y) doesn't but I ask for it's value I get the 
> value of the two-part name. Ie set fred$x.pair and print the value of 
> fred$x it gives me the value I set to fred$x.pair. Weird and 
> somewhat disturbing!
> Maybe an example makes it clearer:
> 
> 
>   Dr Steve Roberts 
>   steve.roberts at man.ac.uk
> 
> Senior Lecturer in Medical Statistics,
> CMMCH NHS Trust and University of Manchester Biostatistics Group,
> 0161 275 5192 / 0161 276 5785
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan


From phgrosjean at sciviews.org  Tue Mar 18 15:45:49 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 18 Mar 2003 15:45:49 +0100
Subject: [R] SciViews R GUI preview version available
Message-ID: <MABBLJDICACNFOLGIHJOCEOJDEAA.phgrosjean@sciviews.org>

Hi all,
After being a long time off the R and R-SIG-GUI lists, because I was working
hard on SciViews, I am happy to deliver the first public version of this
program. It is still v. 0.1, that is, an incomplete alpha version. It
currently installs only on Windows 2000 or XP (NOT on Windows
9X/ME/Millenium, nor any other platform!). You can download it at
http://www.sciviews.org. Please, note that the program still does not
support path names with spaces, like the default one, "C:\Program
Files\SciViews\". You _have to change_ the default value of installation
folder in the setup program to something like "c:\Pgm\SciViews\"! Of course,
you need also R installed on the same computer (at least version 1.5.0).

This package proposes:
- Insighter, a GUI specifically designed for data analysis. It offers:
  + a MDI (multiple document interface),
  + a complete IDE (code editing with syntax highlighting, bookmarks, run,
step-by-step execution,...),
  + a command bar which handle several simultaneous calculation kernels, an
advanced history of commands, syntax highlighting, and quick tips for
functions. It operates hand in hand with the integrated, advanced console
document,
  + an integrated reporting system (rich text format with graphs, figures
and embedded objects),
  + an integrated help system in HTML format (although not active yet for
R),
  + an explorer (no object explorer yet, but this is planned for the next
version),
  + a 'library docking window' (for quick reference electronic cards, code
templates, and more...),
  + a fully customizable menus/toolbars/docking panels system, very similar
to the Microsoft Office 2000 one,
  + even more customization in the SciViews sessions (icon, program title,
splash screen, default working directory,...).
- SciViews main module, to manage and open SciViews sessions,
- Xchanger, a centralized system to connect different calculation kernels
through SciViews plugs,
- currently, only one plug is provided: for R. Plugs for Octave, Matlab,
S-PLUS, Scilab, Ox, Mathematica,... are in development.

At http://www.sciviews.org/software/Insighter.gif, you will find a
screenshot example of SciViews Insighter with a R console, a R graph device
and a reporting document openend in the same session. License is GPL 2 or
above. Code source is provided but you need Visual Basic 6.0 pro to edit it.

Our next work will be dedicated to custom dialog boxes and to the object
explorer... and of course, bugs elimination and better compatibility with
Windows 9X/ME/Millenium.

Your comments are welcome.
Best regards,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................


From wei.ding at spcorp.com  Tue Mar 18 15:49:51 2003
From: wei.ding at spcorp.com (Ding, Wei)
Date: Tue, 18 Mar 2003 09:49:51 -0500
Subject: [R] network connection
Message-ID: <DF5498CC27A1D411856D00508BF9B098068E74D1@kenmsg31.schp.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030318/4c0a4033/attachment.pl

From edd at debian.org  Tue Mar 18 16:10:17 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 18 Mar 2003 09:10:17 -0600
Subject: [R] network connection
In-Reply-To: <DF5498CC27A1D411856D00508BF9B098068E74D1@kenmsg31.schp.com>
References: <DF5498CC27A1D411856D00508BF9B098068E74D1@kenmsg31.schp.com>
Message-ID: <20030318151017.GA9859@sonny.eddelbuettel.com>

On Tue, Mar 18, 2003 at 09:49:51AM -0500, Ding, Wei wrote:
> How can I configure R to allow http connection (through company firewall)?
> Your help are greatly appreciated!

a) Depends on the operating system, and you didn't tell us which one you use.

b) This is in the FAQ and R/Windows FAQ

c) One solution is to employ GNU wget -- get it, configure it for firewall
usage, test it (outside of R) and then tell R about it. Another solution on
Windows uses Internet Explorers's settings, see the rw-FAQ.

d) This has been discussed multiple times on the list, see the archive(s)
and/or suitable web searches.

Hope this helps,  Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr


From steve.roberts at man.ac.uk  Tue Mar 18 16:10:02 2003
From: steve.roberts at man.ac.uk (Steve Roberts)
Date: Tue, 18 Mar 2003 15:10:02 +0000
Subject: [R] What a wonderful list (was Strange and disturbing bug)
In-Reply-To: <3E7726BA.26128.3BD8D1@localhost>
Message-ID: <3E7736CA.6602.7A98BC@localhost>

What a wonderful set of people you are! - I 
solved by own problem, deleted the message and 
got 3 replies before I realised I'd hit "send" 
rather then "delete". 

Steve.
 
  Dr Steve Roberts 
  steve.roberts at man.ac.uk

Senior Lecturer in Medical Statistics,
CMMCH NHS Trust and University of Manchester Biostatistics Group,
0161 275 5192 / 0161 276 5785


From mschwartz at medanalytics.com  Tue Mar 18 16:10:50 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 18 Mar 2003 09:10:50 -0600
Subject: [R] network connection
In-Reply-To: <DF5498CC27A1D411856D00508BF9B098068E74D1@kenmsg31.schp.com>
Message-ID: <023c01c2ed60$9176cac0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ding, Wei
>Sent: Tuesday, March 18, 2003 8:50 AM
>To: 'R-help at lists.R-project.org'
>Subject: [R] network connection
>
>
>Hi,
>
>How can I configure R to allow http connection (through 
>company firewall)? Your help are greatly appreciated!
>
>Wei Ding, Ph.D.
>Schering-Plough Research Institute
>2015 Galloping Hill Road
>Kenilworth, NJ 07033
>Tel:  (908) 740-2592
>Fax: (908) 740-7664


See ?download.file and be sure to read the instructions carefully,
especially as they relate to the '--internet2' flag.

If you have trouble, you may wish to search the R-Help archive as this
has been discussed at length very recently.

HTH,

Marc Schwartz


From rpeng at stat.ucla.edu  Tue Mar 18 16:52:35 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 18 Mar 2003 07:52:35 -0800 (PST)
Subject: [R] To load Add-ons 
In-Reply-To: <FIEBLCNACFBLFGGEILDJIEBACAAA.katrin.braesel@imise.uni-leipzig.de>
Message-ID: <Pine.GSO.4.10.10303180751140.20101-100000@quetelet.stat.ucla.edu>

Look at ?Startup.  You might want to edit $R_HOME/etc/Rprofile.site, where
$R_HOME is the sitewide installation directory.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Tue, 18 Mar 2003, Katrin Braesel wrote:

> Dear R Help-Team,
> 
> If I start R and type in
> search()
> 
> the result is:
> [1] ".GlobalEnv"    "package:ctest" "Autoloads"     "package:base"
> 
> I often need an Add-on-package. I can load it with "> library(package)" or
> include a require-command in the .First-function. The .First-function is
> fine, if I always use the same working directory. But I don't. And I'm not
> the only one, who needs some Add-ons almost every time.
> Is it possible to change the .First-function global? Or is there a
> possibility to load a package by default for all users and independent from
> the working directory, like "package:ctest" and "package:base"?
> 
> With kind regards
> Katrin Braesel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From armin at xss.de  Tue Mar 18 17:06:21 2003
From: armin at xss.de (Armin Roehrl)
Date: Tue, 18 Mar 2003 17:06:21 +0100
Subject: [R] References of R in use
In-Reply-To: <OF936CDCEC.7815647A-ONC1256CED.00393A45@eurotel.cz>
References: <OF936CDCEC.7815647A-ONC1256CED.00393A45@eurotel.cz>
Message-ID: <200303181706.21893.armin@xss.de>

> In general, managerial decisions (in large companies) about software are
> most often based on references like
> "Does this sotware use IBM, Sun, Oracle, MS,  big banks, big Telco
> companies, NASA, Academy of Sciences, and so on?"
> rather than "this soft is scalable, offers this and this and that, uses
> proven and sound statistical methods..."

The typical dilemma .. the managers that know nothing about the technology
want to know what their competitors use and why is R not mentionned
in the in-flight magazine like Java,  .Net, etc. They can't impress their 
buddies playing golf quoting they signed a $200k service contract with R.

My advice: don't ask. Simply use R/whatever fits best and gets the job done.
Results count, not big names. Perl, Linux and Ruby made it like that into
tons of big organizations.

I know of people at the following big and small corporations using R:
- ABB
- Siemens
- HHLA 
- NASA
- Bank of Canada
- Approximity  :-)

also look at the email addresses of the people here:
http://stat.ethz.ch/CRAN/

Have fun with R,
	-A.

----------------------------------------
Armin Roehrl, http://www.approximity.com
We manage risk

Winston Wolf: That's thirty minutes away. I'll be there in ten.

First European Ruby conference, 21-22/6, Karlsruhe
http://www.approximity.com/ruby/euruko


From spencer.graves at pdf.com  Tue Mar 18 17:09:56 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 18 Mar 2003 08:09:56 -0800
Subject: [R] Simulation
References: <se76ccd6.018@rauzen.rau.ac.za>
Message-ID: <3E7744D4.4050000@pdf.com>

Consider the following:

	p <- rbinom(40, 1, 0.9)
	e <- rnorm(40, 0, 1)
	if(any(p==0))e[p==0] <- 3*(rchisq(sum(p==0), 1)-1)

To find out whether this is faster than what you wrote, surround it with 
calls to proc.time, as follows:

  	start.time <- proc.time()
	p <- rbinom(40, 1, 0.9)
	e <- rnorm(40, 0, 1)
	if(any(p==0))e[p==0] <- 3*(rchisq(sum(p==0), 1)-1)
	(elapsed.time <- proc.time()-start.time)

I got 0.21 seconds for this.  Similarly,

  	start.time <- proc.time()
	p <- rbinom(40, 1, 0.9)
	e <- rnorm(40,0,1)*p + 3*(rchisq(40,1)-1)*(1-p)
	(elapsed.time <- proc.time()-start.time)

For this, I got 0.17 seconds.  Therefore, it looks like your is faster. 
  However, the technique I displayed above might be faster in crudely 
similar contexts.

Hope this helps.
Spencer Graves

Jacob van Wyk wrote:
> Hallo all users of R.
> I wish to simulate a simple linear regression, y=a+bx+e, (n=40, say),
> where x is
> N(0,1) and where
> e is N(0,1), with probability 0.9, and
> e is 3*(chisq(40,1)-1), say, with probability 0.1.
> For e: would the following work, or is there a better way?
> 
> p <- rbinom(40,1,0.9)
> e <- rnorm(40,0,1)*p + 3*(rchisq(40,1)-1)*(1-p)
> 
> Thanks for your time.
> Regards
> Jacob
> 
> 
> 
> Jacob L van Wyk
> Department of Mathematics and Statistics
> Rand Afrikaans University
> P O Box 524
> Auckland Park 2006
> South Africa
> Tel: +27-11-489-3080
> Fax: +27-11-489-2832
> 
> 
> ______________________________________
> 
> VRYWARING\ \ Die inhoud en enige aanhegsels van hierdie elektron... [[dropped]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Tue Mar 18 17:23:22 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 18 Mar 2003 08:23:22 -0800
Subject: [R] References of R in use
References: <OF936CDCEC.7815647A-ONC1256CED.00393A45@eurotel.cz>
Message-ID: <3E7747FA.6070708@pdf.com>

	  This is not a direct answer to your question, but the book 
"Information Rules: A Strategic Guide to the Network Economy" by Carl 
Shapiro and Hal R. Varian (1998) describe how to wage and win a 
standards war.  Along with this, you may wish to review that S-News says 
about R and vice versa, the strength and depth of Insightful and the R 
Developers network (including Insightful's quarterly reports), and then 
make up your own mind.

	  If you do this, please let me know.  I work for a small company with 
many S-Plus users.  However, I have a collaborator in another company 
who is using R.  I now test virtually all software I develop in both 
S-Plus and R.

	  I hope this helps.

Best Wishes,
Spencer Graves

Jan_Svatos at eurotel.cz wrote:
> Dear R-users and expeRts,
> 
> can anyone provide me (and others as well, of course) with reference of
> companies, scientific labs and/or schools where R is being used?
> Or does some (even unofficial) list of comanies etc. where R is being used
> exist?
> I tried to find such an information on R's homepage and on a FAQ page, but
> unsuccesfully.
> (Of course, searching through this r-help conference one quickly finds lot
> of universities, where R is being used, but I wonder whether there
> exists some list)
> 
> Why I do I want this?
> 
> In general, managerial decisions (in large companies) about software are
> most often based on references like
> "Does this sotware use IBM, Sun, Oracle, MS,  big banks, big Telco
> companies, NASA, Academy of Sciences, and so on?"
> rather than "this soft is scalable, offers this and this and that, uses
> proven and sound statistical methods..."
> 
> An information like "R is being (of course succesfully) used in ...." would
> be of great help in any discussion about
> Statistical and Data Mining software in our company (Eurotel is the largest
> mobile operator in Czechia).
> (although it seems that I am the only one or at most one of few people
> knowing about R and using it in our company).
> 
> BTW,
> wouldn't it be nice to have such a list somewhere at
> http://www.r-project.org/ ?
> 
> Thanks in advance,
> Jan
> 
> 
> -------------------------------------------------
> designed for _monospaced_ font
> -------------------------------------------------
> /- Jan Svatos, MSc, PhD     Sokolovska 215     -/
> /- Data Analyst             Prague 9           -/
> /- Eurotel Praha            190 00             -/
> /- jan_svatos at eurotel.cz    Czechia            -/
> -------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From apjaworski at mmm.com  Tue Mar 18 17:25:00 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Tue, 18 Mar 2003 10:25:00 -0600
Subject: [R] network connection
Message-ID: <OF41A67D15.D92879A1-ON86256CED.0059F3C6@mmm.com>


If you are on a Windows machine try to invoke R with the --internet2
switch.

Cheers,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+-------------------------------->
|         |           "Ding, Wei"          |
|         |           <wei.ding at spcorp.com>|
|         |           Sent by:             |
|         |           r-help-bounces at stat.m|
|         |           ath.ethz.ch          |
|         |                                |
|         |                                |
|         |           03/18/2003 08:49     |
|         |                                |
|---------+-------------------------------->
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       "'R-help at lists.R-project.org'" <R-help at stat.math.ethz.ch>                                                    |
  |      cc:                                                                                                                    |
  |      Subject:  [R] network connection                                                                                       |
  >-----------------------------------------------------------------------------------------------------------------------------|




Hi,

How can I configure R to allow http connection (through company firewall)?
Your help are greatly appreciated!

Wei Ding, Ph.D.
Schering-Plough Research Institute
2015 Galloping Hill Road
Kenilworth, NJ 07033
Tel:  (908) 740-2592
Fax: (908) 740-7664



*********************************************************************
This message and any attachments are solely for the intended rec...
[[dropped]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From maechler at stat.math.ethz.ch  Tue Mar 18 17:26:32 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 18 Mar 2003 17:26:32 +0100
Subject: [R] References of R in use
In-Reply-To: <OF936CDCEC.7815647A-ONC1256CED.00393A45@eurotel.cz>
References: <OF936CDCEC.7815647A-ONC1256CED.00393A45@eurotel.cz>
Message-ID: <15991.18616.846732.542006@gargle.gargle.HOWL>

Some minimal statistics:

There are 1516 different "e-mail domain names" (the thing after
"@" in the e-mail addresses) of subscribers of r-help and r-announce.

Using bash: 
(for l in r-help r-announce;do sed 's/.*@//' $l;done)  | \
 sort | uniq | tee /tmp/r-domains | wc
   1516    1516   21218

This list with 1516 lines starts with
     2020speech.com
     aaa-plus.com
and ends with
    zwallet.com

If someone is volunteering composing such a list, I can e-mail
that list to her/him.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


>>>>> "Jan" == Jan Svatos <Jan_Svatos at eurotel.cz>
>>>>>     on Tue, 18 Mar 2003 11:48:29 +0100 writes:

    Jan> Dear R-users and expeRts, can anyone provide me (and
    Jan> others as well, of course) with reference of companies,
    Jan> scientific labs and/or schools where R is being used?
    Jan> Or does some (even unofficial) list of comanies
    Jan> etc. where R is being used exist?  I tried to find such
    Jan> an information on R's homepage and on a FAQ page, but
    Jan> unsuccesfully.  (Of course, searching through this
    Jan> r-help conference one quickly finds lot of
    Jan> universities, where R is being used, but I wonder
    Jan> whether there exists some list)

    Jan> Why I do I want this?

    Jan> In general, managerial decisions (in large companies)
    Jan> about software are most often based on references like
    Jan> "Does this sotware use IBM, Sun, Oracle, MS, big banks,
    Jan> big Telco companies, NASA, Academy of Sciences, and so
    Jan> on?"  rather than "this soft is scalable, offers this
    Jan> and this and that, uses proven and sound statistical
    Jan> methods..."

    Jan> An information like "R is being (of course succesfully)
    Jan> used in ...." would be of great help in any discussion
    Jan> about Statistical and Data Mining software in our
    Jan> company (Eurotel is the largest mobile operator in
    Jan> Czechia).  (although it seems that I am the only one or
    Jan> at most one of few people knowing about R and using it
    Jan> in our company).

    Jan> BTW, wouldn't it be nice to have such a list somewhere
    Jan> at http://www.r-project.org/ ?

    Jan> Thanks in advance, Jan


    Jan> -------------------------------------------------
    Jan> designed for _monospaced_ font
    Jan> ------------------------------------------------- /-
    Jan> Jan Svatos, MSc, PhD Sokolovska 215 -/ /- Data Analyst
    Jan> Prague 9 -/ /- Eurotel Praha 190 00 -/ /-
    Jan> jan_svatos at eurotel.cz Czechia -/
    Jan> -------------------------------------------------

    Jan> ______________________________________________
    Jan> R-help at stat.math.ethz.ch mailing list
    Jan> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ernesto at ipimar.pt  Tue Mar 18 18:03:46 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 18 Mar 2003 17:03:46 +0000
Subject: [R] weighted.mean and na.rm=T in R-1.6.2
Message-ID: <1048007026.27207.1.camel@gandalf.ipimar.pt>

Hi

It looks like the na.rm flag is not working in function weighted.mean.

> weighted.mean(mat95$U,mat95$fpanual)
[1] NA
> weighted.mean(mat95$U,mat95$fpanual,na.rm=TRUE)
[1] NA
> mat95 <- mat95[!is.na(mat95$fpanual),]
> weighted.mean(mat95$U,mat95$fpanual)
[1] 14.93259


Regards

EJ


From cottrell at wfu.edu  Tue Mar 18 18:03:19 2003
From: cottrell at wfu.edu (Allin Cottrell)
Date: Tue, 18 Mar 2003 12:03:19 -0500 (EST)
Subject: [R] "r-square in LME?
In-Reply-To: <3E75F4D8.E662055D@unibas.ch>
References: <3E75F4D8.E662055D@unibas.ch>
Message-ID: <Pine.LNX.4.52.0303181202350.14637@ricardo.ecn.wfu.edu>

On Mon, 17 Mar 2003, Daniel Bloch wrote:

> I analysed data with LME in R. Is there a measure for LME
> (likelihood estimated) statistics which has an analogous meaning to
> the coefficient of determination (r-square) estimated by
> least-square procedure?

There is not an exact analog, but the log-likelihood is commonly used
as a figure of merit.

Allin Cottrell.


From rpeng at stat.ucla.edu  Tue Mar 18 18:36:57 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 18 Mar 2003 09:36:57 -0800 (PST)
Subject: [R] weighted.mean and na.rm=T in R-1.6.2
In-Reply-To: <1048007026.27207.1.camel@gandalf.ipimar.pt>
Message-ID: <Pine.GSO.4.10.10303180936100.26514-100000@quetelet.stat.ucla.edu>

It seems you have NA's in the weights.  But from ?weighted.mean:

Details:

     If `w' is missing then all elements of `x' are given the same
     weight.

     Missing values in `w' are not handled.

Here, `w' is the vector of weights.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On 18 Mar 2003, Ernesto Jardim wrote:

> Hi
> 
> It looks like the na.rm flag is not working in function weighted.mean.
> 
> > weighted.mean(mat95$U,mat95$fpanual)
> [1] NA
> > weighted.mean(mat95$U,mat95$fpanual,na.rm=TRUE)
> [1] NA
> > mat95 <- mat95[!is.na(mat95$fpanual),]
> > weighted.mean(mat95$U,mat95$fpanual)
> [1] 14.93259
> 
> 
> Regards
> 
> EJ
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From spencer.graves at pdf.com  Tue Mar 18 18:38:12 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 18 Mar 2003 09:38:12 -0800
Subject: [R] "r-square in LME?
References: <3E75F4D8.E662055D@unibas.ch>
	<Pine.LNX.4.52.0303181202350.14637@ricardo.ecn.wfu.edu>
Message-ID: <3E775984.9030903@pdf.com>

In an unpublished note, Sundar Dorai-Raj recently cited the following as 
addressing this question:

Cox, D. R. and Snell, E. J. (1989) The Analysis of Binary Data, Second 
Edition, London: Chapman and Hall.

Nagelkerke, N. J. D. (1991) ?A Note on a General Definition of the 
Coefficient of Determination,? Biometrika, 78, 691 -692.

Apparently, Cox and Snell (1989) suggest the following

	  R1.2 = 1-(L(0)/L(b.hat))^(2/n),

where L(b) = log(likelihood(b)).  With a normal likelihood using the 
standard maximum likelihood estimate for the variance, this produces the 
standard formula for the coefficient of determination.

Nagelkerke (1991) suggested the following modification:

	  R2.2 = R1.2/(1-(L(0))^(2/n))

I don't understand this second formula, so I can't comment on it. 
Yesterday, I found a few more recent papers that looked potentially 
relevant in a search of "query.statlib.org" for "coefficient of 
determination".  However, I won't know if they are relevant until I 
actually see them.

Hope this helps.
Best Wishes,
Spencer Graves

Allin Cottrell wrote:
> On Mon, 17 Mar 2003, Daniel Bloch wrote:
> 
> 
>>I analysed data with LME in R. Is there a measure for LME
>>(likelihood estimated) statistics which has an analogous meaning to
>>the coefficient of determination (r-square) estimated by
>>least-square procedure?
> 
> 
> There is not an exact analog, but the log-likelihood is commonly used
> as a figure of merit.
> 
> Allin Cottrell.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ernesto at ipimar.pt  Tue Mar 18 18:48:48 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 18 Mar 2003 17:48:48 +0000
Subject: [R] weighted.mean and na.rm=T in R-1.6.2
In-Reply-To: <Pine.GSO.4.10.10303180936100.26514-100000@quetelet.stat.ucla.edu>
References: 
	 <Pine.GSO.4.10.10303180936100.26514-100000@quetelet.stat.ucla.edu>
Message-ID: <1048009728.27212.4.camel@gandalf.ipimar.pt>

On Tue, 2003-03-18 at 17:36, Roger Peng wrote:
> It seems you have NA's in the weights.  But from ?weighted.mean:
> 
> Details:
> 
>      If `w' is missing then all elements of `x' are given the same
>      weight.
> 
>      Missing values in `w' are not handled.
> 
> Here, `w' is the vector of weights.
> 
> -roger
> _______________________________
> UCLA Department of Statistics
> rpeng at stat.ucla.edu
> http://www.stat.ucla.edu/~rpeng
> 
> On 18 Mar 2003, Ernesto Jardim wrote:
> 
> > Hi
> > 
> > It looks like the na.rm flag is not working in function weighted.mean.
> > 
> > > weighted.mean(mat95$U,mat95$fpanual)
> > [1] NA
> > > weighted.mean(mat95$U,mat95$fpanual,na.rm=TRUE)
> > [1] NA
> > > mat95 <- mat95[!is.na(mat95$fpanual),]
> > > weighted.mean(mat95$U,mat95$fpanual)
> > [1] 14.93259
> > 
> > 
> > Regards
> > 
> > EJ
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Yes, you're correct. I missunderstood the sentence.

Regards

EJ


From trafton at itd.nrl.navy.mil  Tue Mar 18 19:26:40 2003
From: trafton at itd.nrl.navy.mil (Greg Trafton)
Date: Tue, 18 Mar 2003 13:26:40 -0500
Subject: [R] temperature profiles on maps
Message-ID: <m2isug350f.fsf@resume.itd.nrl.navy.mil>

Hi, all.  I'm looking for a way to generate temperature profiles and
display them in different colors on different maps.  I'm basically
looking for a way to display simple meteorological graphs using
different color sets within R.

Is there a way to do that kind of thing in R?

failing that, is there any way to create temperature profiles in R?

thanks!
greg


From dieter.menne at menne-biomed.de  Tue Mar 18 20:08:25 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Tue, 18 Mar 2003 20:08:25 +0100
Subject: [R] How to use R from Delphi 
Message-ID: <JLEPLGAANFCEAEDCAGJNEEJBCEAA.dieter.menne@menne-biomed.de>

Hiroshi,

Download Thomas Baier' RDCOM from //cran.r-project.org/, Software, Other.

Try to get to work the Visual basic examples coming with it, so you are sure
the package registration has worked.

I will send you by direct e-mail my RCom.pas package with an example
program, which should give you a starter.

I really works perfectly!

Dieter Menne

---------------------------------------
Dr. Dieter Menne
Biomed Software
72074 T?bingen
Tel (49) (7071) 52176
FAX (49) (7071) 55 10 46
dieter.menne at menne-biomed.de
www.menne-biomed.de


From mhp at dadlnet.dk  Tue Mar 18 20:37:30 2003
From: mhp at dadlnet.dk (Morten H Pedersen)
Date: Tue, 18 Mar 2003 20:37:30 +0100
Subject: [R] Change directory in script
Message-ID: <KAENIAILDIGDGGKMAOIPIEGPCNAA.mhp@dadlnet.dk>

Is there an R command to change directory? (it would be nice to include in
scripts to go to the right directory)

Sincerely,


Morten H Pedersen, M.D.


From JACQUELINE.LAW at ROCHE.COM  Tue Mar 18 20:40:35 2003
From: JACQUELINE.LAW at ROCHE.COM (Law, Jacqueline {Regu~Pleasanton})
Date: Tue, 18 Mar 2003 14:40:35 -0500
Subject: [R] Passing Bablok regression
Message-ID: <0F58D4CA9429D311B70A0090272A644611D9D0A7@rpbmsem1.ple.roche.com>

Hello all,

Does anyone know anything of the implementation of Passing Bablok regression
in R? Thanks!

- Jacqueline


From mschwartz at medanalytics.com  Tue Mar 18 20:53:07 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 18 Mar 2003 13:53:07 -0600
Subject: [R] Change directory in script
In-Reply-To: <KAENIAILDIGDGGKMAOIPIEGPCNAA.mhp@dadlnet.dk>
Message-ID: <002601c2ed88$015666d0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Morten 
>H Pedersen
>Sent: Tuesday, March 18, 2003 1:38 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Change directory in script
>
>
>Is there an R command to change directory? (it would be nice 
>to include in scripts to go to the right directory)
>
>Sincerely,
>
>
>Morten H Pedersen, M.D.


Yes. See ?setwd which sets the current working directory along with
getwd(), which gets the current working directory.

HTH,

Marc Schwartz


From mandevip at uaslp.mx  Tue Mar 18 21:24:49 2003
From: mandevip at uaslp.mx (Peter B. Mandeville)
Date: Tue, 18 Mar 2003 14:24:49 -0600
Subject: [R] Tukey's HSD
Message-ID: <5.1.0.14.0.20030318141937.020cfc40@localhost>

Greetings,

I am trying the get the standard errors of multiple comparisons using 
Tukey's HSD. These are not reported by the function TukeyHSD. When I apply 
the following code to the data, which I store as PROLE4.TXT, several 
unexpected things happen. First, the function TukeyHSD works for all the 
comparisons but the function simint doesn't. Second, after the application 
of na.omit def2$EL and def4$EL report factor values which have been 
omitted. Please inform me what I am doing wrong. Thank you very much.

Peter B.

dat0 <- read.table("prole4.txt",header=T)
nrow(dat0)
attach(dat0)
dat <- 
data.frame(PRO,GRA,SOL,CEN,LAC,factor(NP),factor(TP),factor(SC),factor(PD),factor(EL))
names(dat) <- c("PRO","GRA","SOL","CEN","LAC","NP","TP","SC","PD","EL")
names(dat)
nrow(dat)
detach(dat0)
attach(dat)
library(multcomp)
# SEXO (nacimientos sencillos)
def1 <- data.frame(PRO,GRA,SOL,CEN,LAC,NP,SC,PD,EL)
def2 <- na.omit(def1)
nrow(def2)
res5 <- aov(LAC~NP+SC+PD+EL+NP:SC+NP:PD+NP:EL+SC:PD+SC:EL+PD:EL,data=def2)
anova(res5)
res5 <- aov(LAC~NP+SC+PD+EL,data=def2)
summary(ci <- simint(LAC~NP,data=def2,alternative="two.sided",type="Tukey"))
summary(ci <- simint(LAC~SC,data=def2,alternative="two.sided",type="Tukey"))
summary(ci <- simint(LAC~PD,data=def2,alternative="two.sided",type="Tukey"))
summary(ci <- simint(LAC~EL,data=def2,alternative="two.sided",type="Tukey"))
TukeyHSD(res5)
summary(def2)
# TIPO (sin tomar en cuenta sexo)
def3 <- data.frame(PRO,GRA,SOL,CEN,LAC,NP,TP,PD,EL)
def4 <- na.omit(def3)
nrow(def4)
res6 <- aov(PRO~NP+TP+PD+EL,data=def4)
summary(ci <- simint(PRO~NP,data=def4,alternative="two.sided",type="Tukey"))
summary(ci <- simint(PRO~TP,data=def4,alternative="two.sided",type="Tukey"))
summary(ci <- simint(PRO~PD,data=def4,alternative="two.sided",type="Tukey"))
summary(ci <- simint(PRO~EL,data=def4,alternative="two.sided",type="Tukey"))
TukeyHSD(res6)
def4$EL
summary(def4)


EL	ove	NP	PD	pld	pls	pes	GRA	SOL	CEN	PRO	LAC	TP	NUL0	

SC	NUL1	NUL2	NUL3	NUL4	NUL5	NJUL6	NUL7	NUL8	NUL9	NUL10	NUL11	NUL12	NUL13	

NUL14	NUL15	NUL16
0	429	3	1	NA	NA	60	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	5.8	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	901	3	0	NA	NA	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	5	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	939	1	0	NA	NA	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	4.5	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	911	3	0	NA	NA	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	5.7	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	932	1	1	NA	NA	49	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	4.8	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	431	3	0	NA	NA	66	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	5.6	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	928	1	0	NA	NA	60	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	5.2	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	984	3	1	NA	NA	71	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	5.6	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	971	1	1	NA	NA	75	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	5.7	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	967	1	1	NA	NA	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	5.5	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	930	1	0	NA	NA	61	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	5.5	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	821	3	1	NA	NA	64	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	3.9	NA	4.5	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	973	1	0	NA	NA	53	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	4.5	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	940	1	1	NA	NA	59	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	4.7	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	902	3	0	NA	NA	69	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	5.3	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	424	3	1	NA	NA	72	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	4.9	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	910	3	0	NA	NA	66	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	4.4	NA	4.4	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	943	2	1	NA	NA	68	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	4.2	NA	3.5	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	983	3	1	NA	NA	72	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	4.9	5.2	NA	NA	NA	NA	NA	

NA	NA	NA
0	845	3	0	NA	NA	63	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	4.2	NA	4.5	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	942	2	0	NA	NA	76	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	5	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	432	2	0	NA	NA	58	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	3.5	3.1	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	427	1	1	NA	NA	72	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	5.5	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	927	1	0	NA	NA	68	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	4.6	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	969	1	0	NA	NA	58	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	3.8	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	430	1	1	NA	NA	52	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	4.7	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	944	2	1	NA	NA	69	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	4.1	NA	3.6	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	842	3	0	NA	NA	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	5.4	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	824	3	1	NA	NA	72	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	4	4.2	NA	NA	NA	NA	NA	

NA	NA	NA
0	972	1	1	NA	NA	59	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	4.9	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	907	3	1	NA	NA	72	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	4	4.8	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	933	1	0	NA	NA	77	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	4.7	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	948	2	1	NA	NA	79	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	4.3	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	828	3	0	NA	NA	72	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	5.35	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	950	2	1	NA	NA	72	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	4.95	3.65	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	908	3	1	NA	NA	76	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	4.8	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	935	1	0	NA	NA	62	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	5.85	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	946	2	1	NA	NA	60	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	6.1	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	955	2	0	NA	NA	58	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	4.2	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	881	2	0	NA	NA	66	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	5	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	880	2	1	NA	NA	61	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	5.1	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	993	1	1	NA	NA	55	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	4.9	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	937	1	1	NA	NA	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	5.2	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	951	2	1	NA	NA	59	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	5.8	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
0	929	1	0	NA	NA	66	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	4.65	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
1	429	3	1	830	5810	63	7.9	19.0772	0.9633	6.336	4.1440	1	NA	

M	NA	NA	1	NA	NA	NA	7.5	NA	NA	NA	1.7	NA	NA	

NA	242.8571429	NA
1	901	3	0	1050	7350	65	5.2	15.6811	0.8985	4.993	4.6280	1	NA	

M	NA	NA	1	NA	NA	NA	6.75	NA	NA	NA	1.75	NA	NA	

NA	250	NA
1	939	1	0	910	6370	65	6.5	17.2569	0.9255	5.311	4.7140	1	NA	

M	NA	NA	1	NA	NA	NA	6	NA	NA	NA	1.5	NA	NA	

NA	214.2857143	NA
1	911	3	0	730	5110	62	4.45	16.2733	1.0191	5.6376	4.7886	1	NA	

M	NA	NA	1	NA	NA	NA	6.8	NA	NA	NA	1.1	NA	NA	

NA	157.1428571	NA
1	932	1	1	620	4340	47	6.05	17.5768	0.9496	5.21	4.5974	1	NA	

H	1	NA	NA	NA	5.6	NA	NA	NA	0.8	NA	NA	NA	

114.2857143	NA	NA	NA
1	431	3	0	1010	7070	68	5.7	16.668	0.9925	4.2638	4.2605	1	NA	

M	NA	NA	1	NA	NA	NA	6.75	NA	NA	NA	1.15	NA	NA	

NA	164.2857143	NA
1	928	1	0	620	4340	61	5.3	17.1691	1.0524	5.819	4.4288	1	NA	

H	1	NA	NA	NA	6.2	NA	NA	NA	1	NA	NA	NA	

142.8571429	NA	NA	NA
1	984	3	1	1230	8610	70	5.85	16.5224	0.9581	4.8196	4.1933	1	NA	

M	NA	NA	1	NA	NA	NA	6.95	NA	NA	NA	1.35	NA	NA	

NA	192.8571429	NA
1	971	1	1	980	6860	75	3.6	14.859	0.9133	4.8452	4.8687	1	NA	

H	1	NA	NA	NA	6.8	NA	NA	NA	1.1	NA	NA	NA	

157.1428571	NA	NA	NA
1	967	1	1	590	4130	64	4.35	15.3313	1.0314	5.4273	4.4245	1	NA	

M	NA	NA	1	NA	NA	NA	7.25	NA	NA	NA	1.75	NA	NA	

NA	250	NA
1	930	1	0	1030	7210	60	6.5	17.6682	0.9209	4.7378	4.5775	1	NA	

H	1	NA	NA	NA	6.85	NA	NA	NA	1.35	NA	NA	NA	

192.8571429	NA	NA	NA
1	821	3	1	840	5880	63	4.7	15.6316	0.9317	4.6632	4.6000	2	2	

NA	1	NA	1	NA	4.6	NA	5.3	NA	0.7	NA	0.8	NA	100	

NA	114.2857143	NA
1	973	1	0	810	5670	54	4.35	15.5708	0.9512	4.3925	4.4537	1	NA	

H	1	NA	NA	NA	6.05	NA	NA	NA	1.55	NA	NA	NA	

221.4285714	NA	NA	NA
1	940	1	1	1090	7630	60	5.8	16.2437	0.8345	4.4947	4.6009	1	NA	

M	NA	NA	1	NA	NA	NA	6.45	NA	NA	NA	1.75	NA	NA	

NA	250	NA
1	902	3	0	760	5320	69	4	16.1382	0.9373	5.2997	4.5986	1	NA	

M	NA	NA	1	NA	NA	NA	6.85	NA	NA	NA	1.55	NA	NA	

NA	221.4285714	NA
1	424	3	1	1090	7630	76	5.85	17.1757	0.9085	5.6672	4.3849	1	NA	

M	NA	NA	1	NA	NA	NA	6.45	NA	NA	NA	1.55	NA	NA	

NA	221.4285714	NA
1	910	3	0	1210	8470	65	3.1	14.4557	0.8932	4.7002	4.8132	2	2	

NA	1	NA	1	NA	5	NA	5.75	NA	0.6	NA	1.35	NA	

85.71428571	NA	192.8571429	NA
1	943	2	1	1100	7700	70	3.08	14.6979	0.9272	4.8118	4.5723	2	2	

NA	1	NA	1	NA	5.25	NA	4.55	NA	1.05	NA	1.05	NA	150	

NA	150	NA
1	983	3	1	1080	7560	75	4.55	15.4898	0.9379	4.9698	4.4378	2	2	

NA	NA	NA	1	2	NA	NA	5.65	5.9	NA	NA	0.75	0.7	NA	

NA	107.1428571	100
1	845	3	0	1160	8120	68	3.2	14.3972	0.9306	5.2766	4.8183	2	2	

NA	1	NA	1	NA	5.3	NA	5.45	NA	1.1	NA	0.95	NA	

157.1428571	NA	135.7142857	NA
1	942	2	0	1140	7980	78	5.4	15.9254	0.8813	5.0543	4.5529	1	NA	

H	1	NA	NA	NA	6.45	NA	NA	NA	1.45	NA	NA	NA	

207.1428571	NA	NA	NA
1	432	2	0	900	6300	64	3.6	14.5923	0.9294	4.8429	4.7923	2	2	

NA	1	2	NA	NA	4.35	3.85	NA	NA	0.85	0.75	NA	NA	

121.4285714	107.1428571	NA	NA
1	427	1	1	1160	8120	71	5.9	17.3822	0.8706	5.1249	4.8432	1	NA	

H	1	NA	NA	NA	6.45	NA	NA	NA	0.95	NA	NA	NA	

135.7142857	NA	NA	NA
1	927	1	0	1040	7280	70	4.4	15.2082	0.9057	5.5637	4.4724	1	NA	

M	NA	NA	1	NA	NA	NA	6.85	NA	NA	NA	2.25	NA	NA	

NA	321.4285714	NA
1	969	1	0	1240	8680	58	5.5	16.9229	0.9047	6.0078	4.4780	1	NA	

M	NA	NA	1	NA	NA	NA	5.5	NA	NA	NA	1.7	NA	NA	

NA	242.8571429	NA
1	430	1	1	1060	7420	53	4.95	16.4996	0.9162	6.091	4.5810	1	NA	

H	1	NA	NA	NA	5.75	NA	NA	NA	1.05	NA	NA	NA	150	

NA	NA	NA
1	944	2	1	1000	7000	64	4.78	15.5751	0.9495	4.939	4.5379	2	2	

NA	1	NA	1	NA	5.15	NA	4.5	NA	1.05	NA	0.9	NA	150	

NA	128.5714286	NA
1	842	3	0	840	5880	63	4.35	15.9875	0.9588	6.5985	4.7820	1	NA	

M	NA	NA	1	NA	NA	NA	7.25	NA	NA	NA	1.85	NA	NA	

NA	264.2857143	NA
1	824	3	1	670	4690	67	9.3	19.635	0.9135	5.7158	4.2071	2	2	

NA	NA	NA	1	2	NA	NA	4.8	4.8	NA	NA	0.8	0.6	NA	

NA	114.2857143	85.71428571
1	972	1	1	610	4270	57	4.9	16.092	0.9606	5.9049	4.0272	1	NA	

M	NA	NA	1	NA	NA	NA	5.9	NA	NA	NA	1	NA	NA	

NA	142.8571429	NA
1	907	3	1	660	4620	70	2.175	14.5555	0.9921	5.978	5.0494	2	2	

NA	1	2	NA	NA	4.8	5.6	NA	NA	0.8	0.8	NA	NA	

114.2857143	114.2857143	NA	NA
1	933	1	0	1560	10920	75	5.95	16.5261	0.8619	5.1828	4.1857	1	NA	

H	1	NA	NA	NA	6	NA	NA	NA	1.3	NA	NA	NA	

185.7142857	NA	NA	NA
1	948	2	1	940	6580	75	3.2	13.6218	0.8953	5.3101	4.0436	1	NA	

M	NA	NA	1	NA	NA	NA	6.1	NA	NA	NA	1.8	NA	NA	

NA	257.1428571	NA
1	828	3	0	830	5810	69	3.5	14.8816	1.1364	6.0835	4.4151	1	NA	

H	1	NA	NA	NA	6.5	NA	NA	NA	1.15	NA	NA	NA	

164.2857143	NA	NA	NA
1	950	2	1	1230	8610	69	3.35	14.6723	0.9105	4.9111	4.4324	2	2	

NA	1	2	NA	NA	5.6	4.35	NA	NA	0.65	0.7	NA	NA	

92.85714286	100	NA	NA
1	908	3	1	590	4130	75	3.65	15.7291	1.0126	5.7469	4.7311	1	NA	

H	1	NA	NA	NA	6	NA	NA	NA	1.2	NA	NA	NA	

171.4285714	NA	NA	NA
1	935	1	0	1010	7070	63	3.05	13.5582	0.9083	4.978	4.6294	1	NA	

M	NA	NA	1	NA	NA	NA	6.8	NA	NA	NA	0.95	NA	NA	

NA	135.7142857	NA
1	946	2	1	1040	7280	62	2.7	14.1274	0.9088	5.4058	4.8800	1	NA	

M	NA	NA	1	NA	NA	NA	7.3	NA	NA	NA	1.2	NA	NA	

NA	171.4285714	NA
1	955	2	0	1030	7210	56	4.65	15.9676	0.9686	5.4131	4.5413	1	NA	

H	1	NA	NA	NA	5.5	NA	NA	NA	1.3	NA	NA	NA	

185.7142857	NA	NA	NA
1	881	2	0	1150	8050	63	4.4	15.5641	0.9257	5.1027	4.9923	1	NA	

H	1	NA	NA	NA	6.85	NA	NA	NA	1.85	NA	NA	NA	

264.2857143	NA	NA	NA
1	880	2	1	600	4200	61	5.95	16.667	0.9071	5.286	4.5717	1	NA	

H	1	NA	NA	NA	6.7	NA	NA	NA	1.6	NA	NA	NA	

228.5714286	NA	NA	NA
1	993	1	1	1040	7280	56	4.45	15.8671	0.9917	5.3033	4.4320	1	NA	

H	1	NA	NA	NA	6.4	NA	NA	NA	1.5	NA	NA	NA	

214.2857143	NA	NA	NA
1	937	1	1	620	4340	65	3.65	15.4919	0.9529	5.5597	4.9008	1	NA	

M	NA	NA	1	NA	NA	NA	6	NA	NA	NA	0.8	NA	NA	

NA	114.2857143	NA
1	951	2	1	840	5880	60	2.2	13.9062	0.9501	5.7269	4.9766	1	NA	

H	1	NA	NA	NA	6.9	NA	NA	NA	1.1	NA	NA	NA	

157.1428571	NA	NA	NA
1	929	1	0	880	6160	65	5.7	16.6332	0.9504	5.362	4.9691	1	NA	

H	1	NA	NA	NA	6.1	NA	NA	NA	1.45	NA	NA	NA	

207.1428571	NA	NA	NA
2	429	3	1	900	6300	61	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	10	NA	NA	NA	2.5	NA	NA	

NA	357.1428571	NA
2	901	3	0	1120	7840	64	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	9	NA	NA	NA	2.25	NA	NA	

NA	321.4285714	NA
2	939	1	0	1170	8190	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	7.85	NA	NA	NA	1.85	NA	NA	

NA	264.2857143	NA
2	911	3	0	990	6930	62	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	9	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
2	932	1	1	730	5110	48	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	7.4	NA	NA	NA	1.8	NA	NA	NA	

257.1428571	NA	NA	NA
2	431	3	0	1000	7000	66	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	8.75	NA	NA	NA	2	NA	NA	

NA	285.7142857	NA
2	928	1	0	810	5670	60	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	8.3	NA	NA	NA	2.1	NA	NA	NA	300	

NA	NA	NA
2	984	3	1	1020	7140	68	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	9.35	NA	NA	NA	2.4	NA	NA	

NA	342.8571429	NA
2	971	1	1	1170	8190	77	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	8.95	NA	NA	NA	2.15	NA	NA	NA	

307.1428571	NA	NA	NA
2	967	1	1	370	2590	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	7.9	NA	NA	NA	0.65	NA	NA	

NA	92.85714286	NA
2	930	1	0	1270	8890	63	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	9.5	NA	NA	NA	2.65	NA	NA	NA	

378.5714286	NA	NA	NA
2	821	3	1	570	3990	63	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	5.9	NA	6.7	NA	1.3	NA	1.4	NA	

185.7142857	NA	200	NA
2	973	1	0	1170	8190	53	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	8.35	NA	NA	NA	2.3	NA	NA	NA	

328.5714286	NA	NA	NA
2	940	1	1	620	4340	58	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	6.5	NA	NA	NA	0.05	NA	NA	

NA	7.142857143	NA
2	902	3	0	590	4130	69	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	6.75	NA	NA	NA	-0.1	NA	NA	

NA	-14.28571429	NA
2	424	3	1	1050	7350	70	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	8.7	NA	NA	NA	2.25	NA	NA	

NA	321.4285714	NA
2	910	3	0	1410	9870	62	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	7.1	NA	7.55	NA	2.1	NA	1.8	NA	300	

NA	257.1428571	NA
2	943	2	1	1110	7770	69	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	7.15	NA	6.5	NA	1.9	NA	1.95	NA	

271.4285714	NA	278.5714286	NA
2	983	3	1	930	6510	70	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	7	7.5	NA	NA	1.35	1.6	NA	

NA	192.8571429	228.5714286
2	845	3	0	750	5250	64	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	6.9	NA	7.2	NA	1.6	NA	1.75	NA	

228.5714286	NA	250	NA
2	942	2	0	980	6860	75	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	8.8	NA	NA	NA	2.35	NA	NA	NA	

335.7142857	NA	NA	NA
2	432	2	0	960	6720	63	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	5.8	6.1	NA	NA	1.45	2.25	NA	NA	

207.1428571	321.4285714	NA	NA
2	427	1	1	1430	10010	72	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	9	NA	NA	NA	2.55	NA	NA	NA	

364.2857143	NA	NA	NA
2	927	1	0	940	6580	69	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	7.75	NA	NA	NA	0.9	NA	NA	

NA	128.5714286	NA
2	969	1	0	570	3990	61	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	6.2	NA	NA	NA	0.7	NA	NA	

NA	100	NA
2	430	1	1	810	5670	52	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	7.5	NA	NA	NA	1.75	NA	NA	NA	250	

NA	NA	NA
2	944	2	1	1040	7280	65	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	6.7	NA	6	NA	1.55	NA	1.5	NA	

221.4285714	NA	214.2857143	NA
2	842	3	0	680	4760	62	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	8.15	NA	NA	NA	0.9	NA	NA	

NA	128.5714286	NA
2	824	3	1	860	6020	65	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	5.675	5.15	NA	NA	0.875	0.35	NA	

NA	125	50
2	972	1	1	440	3080	55	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	6.15	NA	NA	NA	0.25	NA	NA	

NA	35.71428571	NA
2	907	3	1	610	4270	70	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	6	7.1	NA	NA	1.2	1.5	NA	NA	

171.4285714	214.2857143	NA	NA
2	933	1	0	780	5460	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	6.7	NA	NA	NA	0.7	NA	NA	NA	100	

NA	NA	NA
2	948	2	1	950	6650	77	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	8.3	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
2	828	3	0	1110	7770	78	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	8.5	NA	NA	NA	2	NA	NA	NA	

285.7142857	NA	NA	NA
2	950	2	1	1340	9380	71	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	6.5	5.25	NA	NA	0.9	0.9	NA	NA	

128.5714286	128.5714286	NA	NA
2	908	3	1	780	5460	78	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	7.9	NA	NA	NA	1.9	NA	NA	NA	

271.4285714	NA	NA	NA
2	935	1	0	990	6930	64	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	8.75	NA	NA	NA	1.95	NA	NA	

NA	278.5714286	NA
2	946	2	1	680	4760	58	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	7.6	NA	NA	NA	0.3	NA	NA	

NA	42.85714286	NA
2	955	2	0	1340	9380	56	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	7.25	NA	NA	NA	1.75	NA	NA	NA	250	

NA	NA	NA
2	881	2	0	1150	8050	63	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	9	NA	NA	NA	2.15	NA	NA	NA	

307.1428571	NA	NA	NA
2	880	2	1	950	6650	61	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	9.1	NA	NA	NA	2.4	NA	NA	NA	

342.8571429	NA	NA	NA
2	993	1	1	1040	7280	54	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	7.9	NA	NA	NA	1.5	NA	NA	NA	

214.2857143	NA	NA	NA
2	937	1	1	530	3710	64	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	7.85	NA	NA	NA	1.85	NA	NA	

NA	264.2857143	NA
2	951	2	1	870	6090	57	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	9	NA	NA	NA	2.1	NA	NA	NA	300	

NA	NA	NA
2	929	1	0	880	6160	63	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	7.8	NA	NA	NA	1.7	NA	NA	NA	

242.8571429	NA	NA	NA
3	429	3	1	860	6020	62	7	17.7976	0.956	5.3892	4.4035	1	NA	

M	NA	NA	1	NA	NA	NA	12.6	NA	NA	NA	2.6	NA	NA	

NA	371.4285714	NA
3	901	3	0	1190	8330	65	5.6	15.591	0.9374	4.7194	4.3281	1	NA	

M	NA	NA	1	NA	NA	NA	11.2	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
3	939	1	0	1140	7980	65	9.2	19.1892	0.9486	4.5073	4.3879	1	NA	

M	NA	NA	1	NA	NA	NA	9.75	NA	NA	NA	1.9	NA	NA	

NA	271.4285714	NA
3	911	3	0	950	6650	61	4.85	16.0773	0.9968	5.2862	4.5513	1	NA	

M	NA	NA	1	NA	NA	NA	11	NA	NA	NA	2	NA	NA	

NA	285.7142857	NA
3	932	1	1	520	3640	47	4.4	15.458	0.937	4.8687	4.8308	1	NA	

H	1	NA	NA	NA	8.9	NA	NA	NA	1.5	NA	NA	NA	

214.2857143	NA	NA	NA
3	431	3	0	970	6790	67	6.55	17.9977	0.982	5.4131	4.5395	1	NA	

M	NA	NA	1	NA	NA	NA	10.4	NA	NA	NA	1.65	NA	NA	

NA	235.7142857	NA
3	928	1	0	1060	7420	60	2.95	14.7257	0.9423	4.8435	5.0909	1	NA	

H	1	NA	NA	NA	10.35	NA	NA	NA	2.05	NA	NA	NA	

292.8571429	NA	NA	NA
3	984	3	1	1250	8750	71	4.95	16.2411	0.9724	4.7976	4.2909	1	NA	

M	NA	NA	1	NA	NA	NA	11.3	NA	NA	NA	1.95	NA	NA	

NA	278.5714286	NA
3	971	1	1	1240	8680	75	2.85	13.626	0.8832	4.7437	4.9090	1	NA	

H	1	NA	NA	NA	11	NA	NA	NA	2.05	NA	NA	NA	

292.8571429	NA	NA	NA
3	967	1	1	610	4270	66	4.95	16.3346	1.2042	6.7383	3.4654	1	NA	

M	NA	NA	1	NA	NA	NA	10.2	NA	NA	NA	2.3	NA	NA	

NA	328.5714286	NA
3	930	1	0	1170	8190	61	4.35	15.5872	0.8856	4.9457	5.4037	1	NA	

H	1	NA	NA	NA	11.8	NA	NA	NA	2.3	NA	NA	NA	

328.5714286	NA	NA	NA
3	821	3	1	660	4620	60	5	16.8527	0.8861	5.3297	5.0295	2	2	

NA	1	NA	1	NA	7	NA	7.9	NA	1.1	NA	1.2	NA	

157.1428571	NA	171.4285714	NA
3	973	1	0	1110	7770	55	3.35	13.7739	0.9647	4.7053	4.7780	1	NA	

H	1	NA	NA	NA	10.7	NA	NA	NA	2.35	NA	NA	NA	

335.7142857	NA	NA	NA
3	940	1	1	620	4340	62	5.2	16.1314	0.86	5.3345	4.7606	1	NA	

M	NA	NA	1	NA	NA	NA	7.85	NA	NA	NA	1.35	NA	NA	

NA	192.8571429	NA
3	902	3	0	340	2380	69	5.4	16.6801	0.9767	5.7431	4.6088	1	NA	

M	NA	NA	1	NA	NA	NA	7.5	NA	NA	NA	0.75	NA	NA	

NA	107.1428571	NA
3	424	3	1	1350	9450	72	5.2	15.9619	0.9222	5.6713	4.4370	1	NA	

M	NA	NA	1	NA	NA	NA	10.8	NA	NA	NA	2.1	NA	NA	

NA	300	NA
3	910	3	0	1550	10850	60	3.4	13.6954	0.8531	4.6495	4.7654	2	2	

NA	1	NA	1	NA	9.6	NA	9.4	NA	2.5	NA	1.85	NA	

357.1428571	NA	264.2857143	NA
3	943	2	1	1070	7490	69	2.2	12.8268	0.8907	4.703	4.6222	2	2	

NA	1	NA	1	NA	8.2	NA	8.9	NA	1.05	NA	2.4	NA	150	

NA	342.8571429	NA
3	983	3	1	1250	8750	68	4.6	15.6929	0.8693	5.2363	4.7671	2	2	

NA	NA	NA	1	2	NA	NA	9	9.8	NA	NA	2	2.3	NA	

NA	285.7142857	328.5714286
3	845	3	0	1300	9100	67	3.5	14.3058	0.8882	4.9715	5.1609	2	2	

NA	1	NA	1	NA	8.5	NA	9	NA	1.6	NA	1.8	NA	

228.5714286	NA	257.1428571	NA
3	942	2	0	1330	9310	79	4.2	14.8591	0.8411	4.7502	4.7516	1	NA	

H	1	NA	NA	NA	11.8	NA	NA	NA	3	NA	NA	NA	

428.5714286	NA	NA	NA
3	432	2	0	840	5880	62	3.35	12.9283	0.9263	4.3896	4.4326	2	2	

NA	1	2	NA	NA	7	6.1	NA	NA	1.2	0	NA	NA	

171.4285714	0	NA	NA
3	427	1	1	1600	11200	72	3.5	13.9122	0.8883	4.7642	4.8212	1	NA	

H	1	NA	NA	NA	11.4	NA	NA	NA	2.4	NA	NA	NA	

342.8571429	NA	NA	NA
3	927	1	0	1090	7630	71	6.05	16.7539	0.8757	5.0501	4.9403	1	NA	

M	NA	NA	1	NA	NA	NA	9.5	NA	NA	NA	1.75	NA	NA	

NA	250	NA
3	969	1	0	1140	7980	60	7.05	17.7921	0.89396	5.4955	4.6257	1	NA	

M	NA	NA	1	NA	NA	NA	8.2	NA	NA	NA	2	NA	NA	

NA	285.7142857	NA
3	430	1	1	1050	7350	53	4.8	15.8801	0.9037	5.3402	4.9923	1	NA	

H	1	NA	NA	NA	9.35	NA	NA	NA	1.85	NA	NA	NA	

264.2857143	NA	NA	NA
3	944	2	1	1130	7910	63	3.75	14.4299	0.8831	4.7073	4.8568	2	2	

NA	1	NA	1	NA	8.1	NA	7.2	NA	1.4	NA	1.2	NA	200	

NA	171.4285714	NA
3	842	3	0	1060	7420	65	5.8	16.8265	0.8622	5.1499	5.0847	1	NA	

M	NA	NA	1	NA	NA	NA	10.4	NA	NA	NA	2.25	NA	NA	

NA	321.4285714	NA
3	824	3	1	850	5950	66	7.5	17.6537	0.8641	5.1453	4.1440	2	2	

NA	NA	NA	1	2	NA	NA	6.85	6.3	NA	NA	1.175	1.15	NA	

NA	167.8571429	164.2857143
3	972	1	1	600	4200	59	5.95	16.3922	0.9777	5.5579	4.0210	1	NA	

M	NA	NA	1	NA	NA	NA	7.1	NA	NA	NA	0.95	NA	NA	

NA	135.7142857	NA
3	907	3	1	370	2590	68	3.9	15.419	0.9485	5.5041	4.8418	2	2	

NA	1	2	NA	NA	7.05	8.25	NA	NA	1.05	1.15	NA	NA	150	

164.2857143	NA	NA
3	933	1	0	830	5810	74	6.45	16.9218	0.8681	5.2265	5.3864	1	NA	

H	1	NA	NA	NA	7.85	NA	NA	NA	1.15	NA	NA	NA	

164.2857143	NA	NA	NA
3	948	2	1	980	6860	74	2.58	13.0917	0.9296	4.7829	4.8722	1	NA	

M	NA	NA	1	NA	NA	NA	10.5	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
3	828	3	0	1050	7350	75	2.75	13.9027	0.9414	5.6133	4.4709	1	NA	

H	1	NA	NA	NA	10.7	NA	NA	NA	2.2	NA	NA	NA	

314.2857143	NA	NA	NA
3	950	2	1	1170	8190	68	3.35	13.9495	0.8313	4.69	4.7855	2	2	

NA	1	2	NA	NA	7.85	6.2	NA	NA	1.35	0.95	NA	NA	

192.8571429	135.7142857	NA	NA
3	908	3	1	750	5250	75	2.65	14.4253	0.9624	5.173	4.7469	1	NA	

H	1	NA	NA	NA	10.15	NA	NA	NA	2.25	NA	NA	NA	

321.4285714	NA	NA	NA
3	935	1	0	1150	8050	67	2.4	13.0541	0.8498	5.0126	4.0403	1	NA	

M	NA	NA	1	NA	NA	NA	11.1	NA	NA	NA	2.35	NA	NA	

NA	335.7142857	NA
3	946	2	1	1070	7490	61	3.35	14.3247	1.2582	5.309	4.6039	1	NA	

M	NA	NA	1	NA	NA	NA	10	NA	NA	NA	2.4	NA	NA	

NA	342.8571429	NA
3	955	2	0	1080	7560	55	4.83	15.9277	0.9109	5.271	4.7770	1	NA	

H	1	NA	NA	NA	8.85	NA	NA	NA	1.6	NA	NA	NA	

228.5714286	NA	NA	NA
3	881	2	0	1300	9100	62	4.55	15.6193	0.9223	5.1887	4.5059	1	NA	

H	1	NA	NA	NA	11	NA	NA	NA	2	NA	NA	NA	

285.7142857	NA	NA	NA
3	880	2	1	960	6720	58	5	16.7463	0.9113	5.3744	4.8342	1	NA	

H	1	NA	NA	NA	11.4	NA	NA	NA	2.3	NA	NA	NA	

328.5714286	NA	NA	NA
3	993	1	1	1170	8190	53	4.75	15.4019	0.8642	4.8863	4.6721	1	NA	

H	1	NA	NA	NA	10	NA	NA	NA	2.1	NA	NA	NA	300	

NA	NA	NA
3	937	1	1	610	4270	61	3.45	14.3967	0.8454	5.0849	4.7918	1	NA	

M	NA	NA	1	NA	NA	NA	10.2	NA	NA	NA	2.35	NA	NA	

NA	335.7142857	NA
3	951	2	1	870	6090	57	3.8	15.1248	0.8971	5.2255	4.4212	1	NA	

H	1	NA	NA	NA	11.2	NA	NA	NA	2.2	NA	NA	NA	

314.2857143	NA	NA	NA
3	929	1	0	800	5600	61	5	16.1549	0.8877	4.777	4.8643	1	NA	

H	1	NA	NA	NA	11.6	NA	NA	NA	3.8	NA	NA	NA	

542.8571429	NA	NA	NA
4	429	3	1	860	6020	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15.2	NA	NA	NA	2.6	NA	NA	

NA	371.4285714	NA
4	901	3	0	1240	8680	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	13.7	NA	NA	NA	2.5	NA	NA	

NA	357.1428571	NA
4	939	1	0	1240	8680	66	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	12.2	NA	NA	NA	2.45	NA	NA	

NA	350	NA
4	911	3	0	870	6090	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	14.8	NA	NA	NA	3.8	NA	NA	

NA	542.8571429	NA
4	932	1	1	460	3220	46	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	12.2	NA	NA	NA	3.3	NA	NA	NA	

471.4285714	NA	NA	NA
4	431	3	0	890	6230	72	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	13.6	NA	NA	NA	3.2	NA	NA	

NA	457.1428571	NA
4	928	1	0	850	5950	64	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	13.2	NA	NA	NA	2.85	NA	NA	NA	

407.1428571	NA	NA	NA
4	984	3	1	1240	8680	74	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	14.6	NA	NA	NA	3.3	NA	NA	

NA	471.4285714	NA
4	971	1	1	1130	7910	82	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	13.8	NA	NA	NA	2.8	NA	NA	NA	400	

NA	NA	NA
4	967	1	1	730	5110	68	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	13.4	NA	NA	NA	3.2	NA	NA	

NA	457.1428571	NA
4	930	1	0	1290	9030	64	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	14.8	NA	NA	NA	3	NA	NA	NA	

428.5714286	NA	NA	NA
4	821	3	1	560	3920	57	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	8.1	NA	8.9	NA	1.1	NA	1	NA	

157.1428571	NA	142.8571429	NA
4	973	1	0	1360	9520	57	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	12.6	NA	NA	NA	1.9	NA	NA	NA	

271.4285714	NA	NA	NA
4	940	1	1	760	5320	59	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	9.15	NA	NA	NA	1.3	NA	NA	

NA	185.7142857	NA
4	902	3	0	770	5390	71	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	8.7	NA	NA	NA	1.2	NA	NA	

NA	171.4285714	NA
4	424	3	1	1010	7070	69	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	13.1	NA	NA	NA	2.3	NA	NA	

NA	328.5714286	NA
4	910	3	0	1470	10290	59	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	11.3	NA	10.5	NA	1.7	NA	1.1	NA	

242.8571429	NA	157.1428571	NA
4	943	2	1	1100	7700	67	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	10.6	NA	10.2	NA	2.4	NA	1.3	NA	

342.8571429	NA	185.7142857	NA
4	983	3	1	1560	10920	70	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	10.8	11.2	NA	NA	1.8	1.4	NA	

NA	257.1428571	200
4	845	3	0	1280	8960	65	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	11	NA	11.2	NA	2.5	NA	2.2	NA	

357.1428571	NA	314.2857143	NA
4	942	2	0	1220	8540	78	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	14	NA	NA	NA	2.2	NA	NA	NA	

314.2857143	NA	NA	NA
4	432	2	0	860	6020	60	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	8.4	7.6	NA	NA	1.4	1.5	NA	NA	200	

214.2857143	NA	NA
4	427	1	1	1480	10360	70	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	14.4	NA	NA	NA	3	NA	NA	NA	

428.5714286	NA	NA	NA
4	927	1	0	1050	7350	69	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	11.8	NA	NA	NA	2.3	NA	NA	

NA	328.5714286	NA
4	969	1	0	1310	9170	60	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	10.8	NA	NA	NA	2.6	NA	NA	

NA	371.4285714	NA
4	430	1	1	1040	7280	52	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	11.7	NA	NA	NA	2.35	NA	NA	NA	

335.7142857	NA	NA	NA
4	944	2	1	980	6860	61	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	9.7	NA	9	NA	1.6	NA	1.8	NA	

228.5714286	NA	257.1428571	NA
4	842	3	0	970	6790	61	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	12.6	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
4	824	3	1	870	6090	62	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	8.7	8.1	NA	NA	1.85	1.8	NA	

NA	264.2857143	257.1428571
4	972	1	1	670	4690	56	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	9.2	NA	NA	NA	2.1	NA	NA	

NA	300	NA
4	907	3	1	510	3570	64	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	8.3	8.9	NA	NA	1.25	0.65	NA	NA	

178.5714286	92.85714286	NA	NA
4	933	1	0	700	4900	72	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	10.2	NA	NA	NA	2.35	NA	NA	NA	

335.7142857	NA	NA	NA
4	948	2	1	950	6650	74	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	12.6	NA	NA	NA	2.1	NA	NA	

NA	300	NA
4	828	3	0	1200	8400	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	13.3	NA	NA	NA	2.6	NA	NA	NA	

371.4285714	NA	NA	NA
4	950	2	1	1130	7910	69	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	9.8	7.8	NA	NA	1.95	1.6	NA	NA	

278.5714286	228.5714286	NA	NA
4	908	3	1	920	6440	76	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	12.2	NA	NA	NA	2.05	NA	NA	NA	

292.8571429	NA	NA	NA
4	935	1	0	1000	7000	66	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	12.9	NA	NA	NA	1.8	NA	NA	

NA	257.1428571	NA
4	946	2	1	1220	8540	62	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	12.7	NA	NA	NA	2.7	NA	NA	

NA	385.7142857	NA
4	955	2	0	900	6300	54	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	10.7	NA	NA	NA	1.85	NA	NA	NA	

264.2857143	NA	NA	NA
4	881	2	0	1160	8120	61	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	13	NA	NA	NA	2	NA	NA	NA	

285.7142857	NA	NA	NA
4	880	2	1	1040	7280	59	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	13.5	NA	NA	NA	2.1	NA	NA	NA	300	

NA	NA	NA
4	993	1	1	1110	7770	53	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	12.4	NA	NA	NA	2.4	NA	NA	NA	

342.8571429	NA	NA	NA
4	937	1	1	930	6510	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	12.7	NA	NA	NA	2.5	NA	NA	

NA	357.1428571	NA
4	951	2	1	1030	7210	57	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	13.5	NA	NA	NA	2.3	NA	NA	NA	

328.5714286	NA	NA	NA
4	929	1	0	670	4690	59	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	11.6	NA	NA	NA	0	NA	NA	NA	0	

NA	NA	NA
5	429	3	1	860	6020	60	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	16.8	NA	NA	NA	1.6	NA	NA	

NA	228.5714286	NA
5	901	3	0	1530	10710	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15	NA	NA	NA	1.3	NA	NA	

NA	185.7142857	NA
5	939	1	0	1030	7210	66	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	13.8	NA	NA	NA	1.6	NA	NA	

NA	228.5714286	NA
5	911	3	0	1020	7140	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	16	NA	NA	NA	1.2	NA	NA	

NA	171.4285714	NA
5	932	1	1	690	4830	47	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	13	NA	NA	NA	0.8	NA	NA	NA	

114.2857143	NA	NA	NA
5	431	3	0	880	6160	71	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15.3	NA	NA	NA	1.7	NA	NA	

NA	242.8571429	NA
5	928	1	0	1000	7000	66	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	14.6	NA	NA	NA	1.4	NA	NA	NA	200	

NA	NA	NA
5	984	3	1	1300	9100	75	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15.7	NA	NA	NA	1.1	NA	NA	

NA	157.1428571	NA
5	971	1	1	1100	7700	81	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	15.4	NA	NA	NA	1.6	NA	NA	NA	

228.5714286	NA	NA	NA
5	967	1	1	650	4550	68	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	14.2	NA	NA	NA	0.8	NA	NA	

NA	114.2857143	NA
5	930	1	0	1260	8820	66	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	17.2	NA	NA	NA	2.4	NA	NA	NA	

342.8571429	NA	NA	NA
5	821	3	1	720	5040	58	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	9.5	NA	11.1	NA	1.4	NA	2.2	NA	200	

NA	314.2857143	NA
5	973	1	0	940	6580	55	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	14.7	NA	NA	NA	2.1	NA	NA	NA	300	

NA	NA	NA
5	940	1	1	910	6370	58	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	10.7	NA	NA	NA	1.55	NA	NA	

NA	221.4285714	NA
5	902	3	0	580	4060	70	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	10.6	NA	NA	NA	1.9	NA	NA	

NA	271.4285714	NA
5	424	3	1	920	6440	69	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15.4	NA	NA	NA	2.3	NA	NA	

NA	328.5714286	NA
5	910	3	0	1180	8260	59	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	12.4	NA	12	NA	1.1	NA	1.5	NA	

157.1428571	NA	214.2857143	NA
5	943	2	1	1050	7350	68	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	12.5	NA	12.8	NA	1.9	NA	2.6	NA	

271.4285714	NA	371.4285714	NA
5	983	3	1	1490	10430	72	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	12.7	13.1	NA	NA	1.9	1.9	NA	

NA	271.4285714	271.4285714
5	845	3	0	1290	9030	66	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	12.7	NA	12.1	NA	1.7	NA	0.9	NA	

242.8571429	NA	128.5714286	NA
5	942	2	0	1470	10290	77	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	16.6	NA	NA	NA	2.6	NA	NA	NA	

371.4285714	NA	NA	NA
5	432	2	0	1150	8050	59	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	10.4	9.5	NA	NA	2	1.9	NA	NA	

285.7142857	271.4285714	NA	NA
5	427	1	1	1370	9590	71	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	16.9	NA	NA	NA	2.5	NA	NA	NA	

357.1428571	NA	NA	NA
5	927	1	0	1110	7770	72	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	14	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
5	969	1	0	1170	8190	60	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	13.1	NA	NA	NA	2.3	NA	NA	

NA	328.5714286	NA
5	430	1	1	1100	7700	53	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	13.4	NA	NA	NA	1.7	NA	NA	NA	

242.8571429	NA	NA	NA
5	944	2	1	1000	7000	62	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	10.9	NA	10.5	NA	1.2	NA	1.5	NA	

171.4285714	NA	214.2857143	NA
5	842	3	0	1190	8330	64	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15.9	NA	NA	NA	3.3	NA	NA	

NA	471.4285714	NA
5	824	3	1	910	6370	63	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	10.2	9.9	NA	NA	1.5	1.8	NA	

NA	214.2857143	257.1428571
5	972	1	1	860	6020	58	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	10.8	NA	NA	NA	1.6	NA	NA	

NA	228.5714286	NA
5	907	3	1	540	3780	64	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	8.9	12.4	NA	NA	0.6	3.5	NA	NA	

85.71428571	500	NA	NA
5	933	1	0	970	6790	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	10.8	NA	NA	NA	0.6	NA	NA	NA	

85.71428571	NA	NA	NA
5	948	2	1	920	6440	71	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15.2	NA	NA	NA	2.6	NA	NA	

NA	371.4285714	NA
5	828	3	0	1300	9100	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	16.1	NA	NA	NA	2.8	NA	NA	NA	400	

NA	NA	NA
5	950	2	1	1280	8960	67	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	11.8	9.4	NA	NA	2	1.6	NA	NA	

285.7142857	228.5714286	NA	NA
5	908	3	1	780	5460	74	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	14.7	NA	NA	NA	2.5	NA	NA	NA	

357.1428571	NA	NA	NA
5	935	1	0	840	5880	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	16.1	NA	NA	NA	3.2	NA	NA	

NA	457.1428571	NA
5	946	2	1	1190	8330	61	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15.4	NA	NA	NA	2.7	NA	NA	

NA	385.7142857	NA
5	955	2	0	780	5460	53	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	12.7	NA	NA	NA	2	NA	NA	NA	

285.7142857	NA	NA	NA
5	881	2	0	940	6580	60	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	15.6	NA	NA	NA	2.6	NA	NA	NA	

371.4285714	NA	NA	NA
5	880	2	1	970	6790	59	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	16	NA	NA	NA	2.5	NA	NA	NA	

357.1428571	NA	NA	NA
5	993	1	1	910	6370	51	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	13.4	NA	NA	NA	1	NA	NA	NA	

142.8571429	NA	NA	NA
5	937	1	1	520	3640	61	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	14.8	NA	NA	NA	2.1	NA	NA	

NA	300	NA
5	951	2	1	980	6860	59	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	15	NA	NA	NA	1.5	NA	NA	NA	

214.2857143	NA	NA	NA
5	929	1	0	570	3990	59	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	12.6	NA	NA	NA	1	NA	NA	NA	

142.8571429	NA	NA	NA
6	429	3	1	660	4620	62	5.05	16.9774	0.9746	5.5998	4.5458	1	NA	

M	NA	NA	1	NA	NA	NA	19.4	NA	NA	NA	2.6	NA	NA	

NA	371.4285714	NA
6	901	3	0	1000	7000	66	4.55	15.4437	0.9935	5.1693	4.8502	1	NA	

M	NA	NA	1	NA	NA	NA	18	NA	NA	NA	3	NA	NA	

NA	428.5714286	NA
6	939	1	0	1060	7420	64	6.1	16.7385	0.9602	4.7581	4.3109	1	NA	

M	NA	NA	1	NA	NA	NA	16.5	NA	NA	NA	2.7	NA	NA	

NA	385.7142857	NA
6	911	3	0	710	4970	63	5.2	17.2575	0.9877	5.3961	4.8169	1	NA	

M	NA	NA	1	NA	NA	NA	18.5	NA	NA	NA	2.5	NA	NA	

NA	357.1428571	NA
6	932	1	1	650	4550	46	5.5	16.7657	0.9098	5.1846	4.5115	1	NA	

H	1	NA	NA	NA	15.3	NA	NA	NA	2.3	NA	NA	NA	

328.5714286	NA	NA	NA
6	431	3	0	950	6650	70	6.88	18.5071	0.985	5.4229	4.4153	1	NA	

M	NA	NA	1	NA	NA	NA	17.6	NA	NA	NA	2.3	NA	NA	

NA	328.5714286	NA
6	928	1	0	710	4970	64	1.9	13.9556	0.9558	5.1012	5.0358	1	NA	

H	1	NA	NA	NA	16.2	NA	NA	NA	1.6	NA	NA	NA	

228.5714286	NA	NA	NA
6	984	3	1	970	6790	73	4.85	15.9945	0.9295	4.986	4.7362	1	NA	

M	NA	NA	1	NA	NA	NA	19.3	NA	NA	NA	3.6	NA	NA	

NA	514.2857143	NA
6	971	1	1	940	6580	80	2.2	13.0615	0.8875	4.6825	4.7745	1	NA	

H	1	NA	NA	NA	16.9	NA	NA	NA	1.5	NA	NA	NA	

214.2857143	NA	NA	NA
6	967	1	1	530	3710	65	2.4	14.3946	0.9388	5.4192	4.9133	1	NA	

M	NA	NA	1	NA	NA	NA	15.8	NA	NA	NA	1.6	NA	NA	

NA	228.5714286	NA
6	930	1	0	1130	7910	66	4.4	15.964	0.9347	4.934	5.0291	1	NA	

H	1	NA	NA	NA	18.9	NA	NA	NA	1.7	NA	NA	NA	

242.8571429	NA	NA	NA
6	821	3	1	510	3570	58	6.6	17.8747	0.881	4.9772	4.3771	2	2	

NA	1	NA	1	NA	11.3	NA	13.2	NA	1.8	NA	2.1	NA	

257.1428571	NA	300	NA
6	973	1	0	1300	9100	54	5.1	15.3135	0.9908	4.617	4.6014	1	NA	

H	1	NA	NA	NA	17	NA	NA	NA	2.3	NA	NA	NA	

328.5714286	NA	NA	NA
6	940	1	1	810	5670	59	7.15	18.0143	0.8136	4.7798	4.4476	1	NA	

M	NA	NA	1	NA	NA	NA	13	NA	NA	NA	2.3	NA	NA	

NA	328.5714286	NA
6	902	3	0	670	4690	73	4.85	15.7197	0.92	4.8689	4.6200	1	NA	

M	NA	NA	1	NA	NA	NA	13	NA	NA	NA	2.4	NA	NA	

NA	342.8571429	NA
6	424	3	1	1030	7210	67	7.5	18.0128	0.8064	5.6256	4.5920	1	NA	

M	NA	NA	1	NA	NA	NA	18.6	NA	NA	NA	3.2	NA	NA	

NA	457.1428571	NA
6	910	3	0	1400	9800	57	4.4	13.8194	0.8946	4.6384	4.1078	2	2	

NA	1	NA	1	NA	14.3	NA	13.8	NA	1.9	NA	1.8	NA	

271.4285714	NA	257.1428571	NA
6	943	2	1	1110	7770	67	2.9	13.8548	0.8571	5.0391	4.7372	2	2	

NA	1	NA	1	NA	14.6	NA	14.6	NA	2.1	NA	1.8	NA	300	

NA	257.1428571	NA
6	983	3	1	1440	10080	73	4.55	15.8253	0.8652	5.1691	4.4592	2	2	

NA	NA	NA	1	2	NA	NA	14.9	15.2	NA	NA	2.2	2.1	NA	

NA	314.2857143	300
6	845	3	0	1450	10150	62	4.3	15.5403	0.8624	4.9112	4.9429	2	2	

NA	1	NA	1	NA	14.6	NA	14.5	NA	1.9	NA	2.4	NA	

271.4285714	NA	342.8571429	NA
6	942	2	0	1290	9030	76	5	15.7011	0.8825	4.2987	4.6454	1	NA	

H	1	NA	NA	NA	18.8	NA	NA	NA	2.2	NA	NA	NA	

314.2857143	NA	NA	NA
6	432	2	0	850	5950	61	4	14.3549	0.8557	4.1283	4.6591	2	2	

NA	1	2	NA	NA	12	10.6	NA	NA	1.6	1.1	NA	NA	

228.5714286	157.1428571	NA	NA
6	427	1	1	1250	8750	72	3.95	14.4881	0.8486	4.5507	4.8020	1	NA	

H	1	NA	NA	NA	18.8	NA	NA	NA	1.9	NA	NA	NA	

271.4285714	NA	NA	NA
6	927	1	0	830	5810	68	3.1	13.8521	0.8392	4.668	5.0914	1	NA	

M	NA	NA	1	NA	NA	NA	16.5	NA	NA	NA	2.5	NA	NA	

NA	357.1428571	NA
6	969	1	0	1030	7210	59	4.4	15.2993	0.8705	4.8931	4.5359	1	NA	

M	NA	NA	1	NA	NA	NA	15	NA	NA	NA	1.9	NA	NA	

NA	271.4285714	NA
6	430	1	1	850	5950	51	4	15.5964	0.9378	5.3157	4.6998	1	NA	

H	1	NA	NA	NA	15.7	NA	NA	NA	2.3	NA	NA	NA	

328.5714286	NA	NA	NA
6	944	2	1	880	6160	62	5.2	16.6809	0.9457	5.4364	4.8765	2	2	

NA	1	NA	1	NA	12.2	NA	13	NA	1.3	NA	2.5	NA	

185.7142857	NA	357.1428571	NA
6	842	3	0	1100	7700	65	6.75	17.9719	0.8244	5.0104	4.5160	1	NA	

M	NA	NA	1	NA	NA	NA	18.8	NA	NA	NA	2.9	NA	NA	

NA	414.2857143	NA
6	824	3	1	900	6300	64	8.3	18.8525	0.9206	5.2981	3.9821	2	2	

NA	NA	NA	1	2	NA	NA	11.8	11.2	NA	NA	1.6	1.3	NA	

NA	228.5714286	185.7142857
6	972	1	1	860	6020	60	5.18	16.0795	0.8499	4.8398	4.2259	1	NA	

M	NA	NA	1	NA	NA	NA	13	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
6	907	3	1	470	3290	62	3	15.3783	0.9116	5.3246	5.3549	2	2	

NA	1	2	NA	NA	10	13.8	NA	NA	1.1	1.4	NA	NA	

157.1428571	200	NA	NA
6	933	1	0	1270	8890	73	7.9	19.2105	1.0045	5.4256	3.8112	1	NA	

H	1	NA	NA	NA	12.2	NA	NA	NA	1.4	NA	NA	NA	200	

NA	NA	NA
6	948	2	1	880	6160	74	3.65	14.0899	0.8594	4.9583	4.1550	1	NA	

M	NA	NA	1	NA	NA	NA	17.5	NA	NA	NA	2.3	NA	NA	

NA	328.5714286	NA
6	828	3	0	1120	7840	75	4	14.9827	0.8794	5.1715	4.1542	1	NA	

H	1	NA	NA	NA	18	NA	NA	NA	1.9	NA	NA	NA	

271.4285714	NA	NA	NA
6	950	2	1	1100	7700	71	5.4	15.9338	0.817	5.1472	4.3952	2	2	

NA	1	2	NA	NA	13.3	11.1	NA	NA	1.5	1.7	NA	NA	

214.2857143	242.8571429	NA	NA
6	908	3	1	840	5880	76	2.95	14.7587	0.9408	5.4155	4.4787	1	NA	

H	1	NA	NA	NA	16.4	NA	NA	NA	1.7	NA	NA	NA	

242.8571429	NA	NA	NA
6	935	1	0	1030	7210	66	6.5	17.1533	0.7878	4.8197	5.1471	1	NA	

M	NA	NA	1	NA	NA	NA	18.2	NA	NA	NA	2.1	NA	NA	

NA	300	NA
6	946	2	1	1270	8890	63	3.5	14.6398	0.8345	5.5628	4.1129	1	NA	

M	NA	NA	1	NA	NA	NA	18	NA	NA	NA	2.6	NA	NA	

NA	371.4285714	NA
6	955	2	0	660	4620	53	5.1	16.924	1.1593	5.7368	4.5981	1	NA	

H	1	NA	NA	NA	14.6	NA	NA	NA	1.9	NA	NA	NA	

271.4285714	NA	NA	NA
6	881	2	0	970	6790	63	4	13.4816	0.8876	4.9474	4.6631	1	NA	

H	1	NA	NA	NA	17.4	NA	NA	NA	1.8	NA	NA	NA	

257.1428571	NA	NA	NA
6	880	2	1	1150	8050	59	4.15	15.9467	0.8998	5.2735	4.5117	1	NA	

H	1	NA	NA	NA	17.5	NA	NA	NA	1.5	NA	NA	NA	

214.2857143	NA	NA	NA
6	993	1	1	640	4480	51	5.7	16.3382	0.8542	4.8081	4.9576	1	NA	

H	1	NA	NA	NA	15	NA	NA	NA	1.6	NA	NA	NA	

228.5714286	NA	NA	NA
6	937	1	1	900	6300	61	2.58	13.4489	0.8486	4.6395	5.2953	1	NA	

M	NA	NA	1	NA	NA	NA	16.8	NA	NA	NA	2	NA	NA	

NA	285.7142857	NA
6	951	2	1	930	6510	58	2.93	14.4347	0.9221	5.2961	5.1234	1	NA	

H	1	NA	NA	NA	15.4	NA	NA	NA	0.4	NA	NA	NA	

57.14285714	NA	NA	NA
6	929	1	0	760	5320	57	6.7	17.3978	0.9096	5.4418	4.6569	1	NA	

H	1	NA	NA	NA	14	NA	NA	NA	1.4	NA	NA	NA	200	

NA	NA	NA
7	429	3	1	1020	7140	66	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	22	NA	NA	NA	2.6	NA	NA	

NA	371.4285714	NA
7	901	3	0	1160	8120	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	18	NA	NA	NA	0	NA	NA	

NA	0	NA
7	939	1	0	1080	7560	64	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	16.5	NA	NA	NA	0	NA	NA	

NA	0	NA
7	911	3	0	540	3780	61	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	20.7	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
7	932	1	1	670	4690	46	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	17.2	NA	NA	NA	1.9	NA	NA	NA	

271.4285714	NA	NA	NA
7	431	3	0	700	4900	69	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	20.4	NA	NA	NA	2.8	NA	NA	

NA	400	NA
7	928	1	0	850	5950	63	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	18.6	NA	NA	NA	2.4	NA	NA	NA	

342.8571429	NA	NA	NA
7	984	3	1	1040	7280	74	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	20.5	NA	NA	NA	1.2	NA	NA	

NA	171.4285714	NA
7	971	1	1	1000	7000	80	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	19.6	NA	NA	NA	2.7	NA	NA	NA	

385.7142857	NA	NA	NA
7	967	1	1	630	4410	68	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	18.3	NA	NA	NA	2.5	NA	NA	

NA	357.1428571	NA
7	930	1	0	800	5600	63	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	18.9	NA	NA	NA	0	NA	NA	NA	0	

NA	NA	NA
7	821	3	1	790	5530	57	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	12.7	NA	15.4	NA	1.4	NA	2.2	NA	200	

NA	314.2857143	NA
7	973	1	0	620	4340	52	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	17.8	NA	NA	NA	0.8	NA	NA	NA	

114.2857143	NA	NA	NA
7	940	1	1	730	5110	58	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15	NA	NA	NA	2	NA	NA	

NA	285.7142857	NA
7	902	3	0	490	3430	70	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	13.8	NA	NA	NA	0.8	NA	NA	

NA	114.2857143	NA
7	424	3	1	1000	7000	66	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	21.1	NA	NA	NA	2.5	NA	NA	

NA	357.1428571	NA
7	910	3	0	940	6580	59	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	14.3	NA	13.8	NA	0	NA	0	NA	0	

NA	0	NA
7	943	2	1	1080	7560	69	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	17	NA	17	NA	2.4	NA	2.4	NA	

342.8571429	NA	342.8571429	NA
7	983	3	1	1270	8890	75	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	15.7	16.8	NA	NA	0.8	1.6	NA	

NA	114.2857143	228.5714286
7	845	3	0	920	6440	61	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	14.6	NA	14.5	NA	0	NA	0	NA	0	

NA	0	NA
7	942	2	0	1120	7840	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	19.6	NA	NA	NA	0.8	NA	NA	NA	

114.2857143	NA	NA	NA
7	432	2	0	810	5670	59	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	10.6	10.6	NA	NA	-1.4	0	NA	NA	-200	

0	NA	NA
7	427	1	1	950	6650	69	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	21.6	NA	NA	NA	2.8	NA	NA	NA	400	

NA	NA	NA
7	927	1	0	600	4200	67	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	14.8	NA	NA	NA	-1.7	NA	NA	

NA	-242.8571429	NA
7	969	1	0	910	6370	57	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	14.4	NA	NA	NA	-0.6	NA	NA	

NA	-85.71428571	NA
7	430	1	1	940	6580	50	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	17.4	NA	NA	NA	1.7	NA	NA	NA	

242.8571429	NA	NA	NA
7	944	2	1	800	5600	61	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	13.2	NA	13	NA	1	NA	0	NA	

142.8571429	NA	0	NA
7	842	3	0	1110	7770	66	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	17.6	NA	NA	NA	-1.2	NA	NA	

NA	-171.4285714	NA
7	824	3	1	930	6510	65	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	13.1	12.9	NA	NA	1.3	1.7	NA	

NA	185.7142857	242.8571429
7	972	1	1	870	6090	58	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	14.7	NA	NA	NA	1.7	NA	NA	

NA	242.8571429	NA
7	907	3	1	620	4340	63	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	11.5	15.1	NA	NA	1.5	1.3	NA	NA	

214.2857143	185.7142857	NA	NA
7	933	1	0	900	6300	74	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	11.6	NA	NA	NA	-0.6	NA	NA	NA	

-85.71428571	NA	NA	NA
7	948	2	1	760	5320	70	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	18.4	NA	NA	NA	0.9	NA	NA	

NA	128.5714286	NA
7	828	3	0	970	6790	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	17.6	NA	NA	NA	-0.4	NA	NA	NA	

-57.14285714	NA	NA	NA
7	950	2	1	780	5460	66	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	12.4	12.7	NA	NA	-0.9	1.6	NA	NA	

-128.5714286	228.5714286	NA	NA
7	908	3	1	540	3780	72	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	19.2	NA	NA	NA	2.8	NA	NA	NA	400	

NA	NA	NA
7	935	1	0	510	3570	64	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	20.2	NA	NA	NA	2	NA	NA	

NA	285.7142857	NA
7	946	2	1	920	6440	60	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	18	NA	NA	NA	0	NA	NA	

NA	0	NA
7	955	2	0	510	3570	52	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	15.4	NA	NA	NA	0.8	NA	NA	NA	

114.2857143	NA	NA	NA
7	881	2	0	670	4690	62	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	18.7	NA	NA	NA	1.3	NA	NA	NA	

185.7142857	NA	NA	NA
7	880	2	1	1000	7000	56	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	19.3	NA	NA	NA	1.8	NA	NA	NA	

257.1428571	NA	NA	NA
7	993	1	1	780	5460	50	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	16.6	NA	NA	NA	1.6	NA	NA	NA	

228.5714286	NA	NA	NA
7	937	1	1	640	4480	61	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	18.7	NA	NA	NA	1.9	NA	NA	

NA	271.4285714	NA
7	951	2	1	690	4830	58	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	17.2	NA	NA	NA	1.8	NA	NA	NA	

257.1428571	NA	NA	NA
7	929	1	0	530	3710	59	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	15.4	NA	NA	NA	1.4	NA	NA	NA	200	

NA	NA	NA
8	429	3	1	900	6300	65	5.68	16.1635	0.9621	5.3671	4.2113	1	NA	

M	NA	NA	1	NA	NA	NA	25.1	NA	NA	NA	3.1	NA	NA	

NA	442.8571429	NA
8	901	3	0	800	5600	63	6.98	17.0048	0.9543	4.8211	4.0640	1	NA	

M	NA	NA	1	NA	NA	NA	18.2	NA	NA	NA	0.2	NA	NA	

NA	28.57142857	NA
8	939	1	0	830	5810	63	8.95	19.3697	0.9632	5.0307	4.3357	1	NA	

M	NA	NA	1	NA	NA	NA	18.5	NA	NA	NA	2	NA	NA	

NA	285.7142857	NA
8	911	3	0	670	4690	62	8.25	19.8412	0.9834	5.7728	3.9698	1	NA	

M	NA	NA	1	NA	NA	NA	20.7	NA	NA	NA	0	NA	NA	

NA	0	NA
8	932	1	1	700	4900	47	5.18	16.3061	0.9209	4.7981	4.4756	1	NA	

H	1	NA	NA	NA	19.6	NA	NA	NA	2.4	NA	NA	NA	

342.8571429	NA	NA	NA
8	431	3	0	630	4410	69	9.9	20.8608	0.9791	5.7811	4.2551	1	NA	

M	NA	NA	1	NA	NA	NA	24	NA	NA	NA	3.6	NA	NA	

NA	514.2857143	NA
8	928	1	0	830	5810	64	8.08	19.7357	0.8818	5.2446	4.4946	1	NA	

H	1	NA	NA	NA	20.3	NA	NA	NA	1.7	NA	NA	NA	

242.8571429	NA	NA	NA
8	984	3	1	930	6510	75	5.18	17.0582	0.95	5.3715	4.8009	1	NA	

M	NA	NA	1	NA	NA	NA	22.5	NA	NA	NA	2	NA	NA	

NA	285.7142857	NA
8	971	1	1	1100	7700	82	3.4	14.7585	0.8408	5.1013	4.5636	1	NA	

H	1	NA	NA	NA	22.1	NA	NA	NA	2.5	NA	NA	NA	

357.1428571	NA	NA	NA
8	967	1	1	640	4480	69	2.35	14.0045	1.0535	5.6424	4.7497	1	NA	

M	NA	NA	1	NA	NA	NA	21	NA	NA	NA	2.7	NA	NA	

NA	385.7142857	NA
8	930	1	0	820	5740	64	7.41	18.3067	0.8855	5.364	4.5603	1	NA	

H	1	NA	NA	NA	19.8	NA	NA	NA	0.9	NA	NA	NA	

128.5714286	NA	NA	NA
8	821	3	1	900	6300	57	5.13	16.3417	0.8331	5.14	4.6987	2	2	

NA	1	NA	1	NA	14.8	NA	18	NA	2.1	NA	2.6	NA	300	

NA	371.4285714	NA
8	973	1	0	580	4060	55	6.9	17.2547	0.9636	4.8645	4.3322	1	NA	

H	1	NA	NA	NA	17.8	NA	NA	NA	0	NA	NA	NA	0	

NA	NA	NA
8	940	1	1	650	4550	59	5.78	16.8999	0.85	5.0757	4.5029	1	NA	

M	NA	NA	1	NA	NA	NA	16.4	NA	NA	NA	1.4	NA	NA	

NA	200	NA
8	902	3	0	430	3010	72	8.15	18.8143	0.9067	5.3197	4.5349	1	NA	

M	NA	NA	1	NA	NA	NA	13.5	NA	NA	NA	-0.3	NA	NA	

NA	-42.85714286	NA
8	424	3	1	920	6440	64	9.1	21.9653	0.8046	5.7028	4.6460	1	NA	

M	NA	NA	1	NA	NA	NA	18.5	NA	NA	NA	-2.6	NA	NA	

NA	-371.4285714	NA
8	910	3	0	730	5110	58	7.05	17.617	0.8379	4.7632	4.4574	2	2	

NA	1	NA	1	NA	16	NA	15.9	NA	1.7	NA	2.1	NA	

242.8571429	NA	300	NA
8	943	2	1	1050	7350	68	1.9	13.7342	0.8377	4.8279	5.2575	2	2	

NA	1	NA	1	NA	19.2	NA	18.8	NA	2.2	NA	1.8	NA	

314.2857143	NA	257.1428571	NA
8	983	3	1	1000	7000	72	4.38	16.4772	0.8883	5.3279	4.7988	2	2	

NA	NA	NA	1	2	NA	NA	16.9	18	NA	NA	1.2	1.2	NA	

NA	171.4285714	171.4285714
8	845	3	0	570	3990	61	6	16.7211	0.8967	5.0728	4.2495	2	2	

NA	1	NA	1	NA	15.2	NA	15.8	NA	0.6	NA	1.3	NA	

85.71428571	NA	185.7142857	NA
8	942	2	0	1100	7700	74	8.25	18.9948	0.8265	4.796	4.7719	1	NA	

H	1	NA	NA	NA	21.4	NA	NA	NA	1.8	NA	NA	NA	

257.1428571	NA	NA	NA
8	432	2	0	670	4690	59	4.35	15.5865	0.9609	5.425	4.4614	2	2	

NA	1	2	NA	NA	10.6	12.1	NA	NA	0	1.5	NA	NA	0	

214.2857143	NA	NA
8	427	1	1	1210	8470	70	5.15	16.08	0.8726	4.5459	5.0295	1	NA	

H	1	NA	NA	NA	23.4	NA	NA	NA	1.8	NA	NA	NA	

257.1428571	NA	NA	NA
8	927	1	0	590	4130	67	7.75	18.5432	0.8469	5.2674	4.6225	1	NA	

M	NA	NA	1	NA	NA	NA	16.6	NA	NA	NA	1.8	NA	NA	

NA	257.1428571	NA
8	969	1	0	900	6300	57	7.4	18.0368	0.8876	4.9387	4.4640	1	NA	

M	NA	NA	1	NA	NA	NA	16	NA	NA	NA	1.6	NA	NA	

NA	228.5714286	NA
8	430	1	1	720	5040	48	4.48	16.0622	0.9883	5.4078	5.1728	1	NA	

H	1	NA	NA	NA	19.6	NA	NA	NA	2.2	NA	NA	NA	

314.2857143	NA	NA	NA
8	944	2	1	710	4970	60	4	15.603	0.9262	5.353	4.8140	2	2	

NA	1	NA	1	NA	14.5	NA	14.2	NA	1.3	NA	1.2	NA	

185.7142857	NA	171.4285714	NA
8	842	3	0	860	6020	63	8.4	19.9905	0.8514	5.2522	4.7739	1	NA	

M	NA	NA	1	NA	NA	NA	20	NA	NA	NA	2.4	NA	NA	

NA	342.8571429	NA
8	824	3	1	750	5250	66	8	18.7251	0.9256	5.1191	4.3815	2	2	

NA	NA	NA	1	2	NA	NA	14.7	14.6	NA	NA	1.6	1.7	NA	

NA	228.5714286	242.8571429
8	972	1	1	800	5600	60	5.15	15.7894	0.9079	4.9373	4.6048	1	NA	

M	NA	NA	1	NA	NA	NA	16.4	NA	NA	NA	1.7	NA	NA	

NA	242.8571429	NA
8	907	3	1	520	3640	65	3.3	15.1618	0.8838	5.2133	4.8590	2	2	

NA	1	2	NA	NA	12.5	16.6	NA	NA	1	1.5	NA	NA	

142.8571429	214.2857143	NA	NA
8	933	1	0	910	6370	74	6.8	17.1098	0.8434	4.5169	4.3801	1	NA	

H	1	NA	NA	NA	14.2	NA	NA	NA	2.6	NA	NA	NA	

371.4285714	NA	NA	NA
8	948	2	1	780	5460	73	2.05	12.5017	0.8991	4.5379	4.6481	1	NA	

M	NA	NA	1	NA	NA	NA	20.3	NA	NA	NA	1.9	NA	NA	

NA	271.4285714	NA
8	828	3	0	950	6650	74	7.3	18.0557	0.8806	5.2207	4.6066	1	NA	

H	1	NA	NA	NA	19.2	NA	NA	NA	1.6	NA	NA	NA	

228.5714286	NA	NA	NA
8	950	2	1	1030	7210	69	3.7	14.3019	0.8218	4.8616	4.6980	2	2	

NA	1	2	NA	NA	13.8	14.4	NA	NA	1.4	1.7	NA	NA	200	

242.8571429	NA	NA
8	908	3	1	570	3990	74	3.4	15.1663	1.0018	5.6201	5.1884	1	NA	

H	1	NA	NA	NA	20.6	NA	NA	NA	1.4	NA	NA	NA	200	

NA	NA	NA
8	935	1	0	900	6300	67	4.64	18.2419	0.8023	4.3612	4.6433	1	NA	

M	NA	NA	1	NA	NA	NA	22.6	NA	NA	NA	2.4	NA	NA	

NA	342.8571429	NA
8	946	2	1	1000	7000	60	4	14.5934	0.855	4.8543	4.7834	1	NA	

M	NA	NA	1	NA	NA	NA	19.8	NA	NA	NA	1.8	NA	NA	

NA	257.1428571	NA
8	955	2	0	640	4480	51	8.45	21.6158	0.9222	5.5085	4.1200	1	NA	

H	1	NA	NA	NA	16.9	NA	NA	NA	1.5	NA	NA	NA	

214.2857143	NA	NA	NA
8	881	2	0	1000	7000	61	9	21.1995	0.9425	4.9712	5.8918	1	NA	

H	1	NA	NA	NA	19.2	NA	NA	NA	0.5	NA	NA	NA	

71.42857143	NA	NA	NA
8	880	2	1	950	6650	58	5.4	17.0459	0.9603	5.7872	4.8226	1	NA	

H	1	NA	NA	NA	21.6	NA	NA	NA	2.3	NA	NA	NA	

328.5714286	NA	NA	NA
8	993	1	1	850	5950	52	3.95	14.8537	0.8564	5.0336	4.8679	1	NA	

H	1	NA	NA	NA	17.7	NA	NA	NA	1.1	NA	NA	NA	

157.1428571	NA	NA	NA
8	937	1	1	800	5600	63	2.7	14.0521	0.8847	5.1837	5.2022	1	NA	

M	NA	NA	1	NA	NA	NA	21.7	NA	NA	NA	3	NA	NA	

NA	428.5714286	NA
8	951	2	1	830	5810	61	3.65	15.3151	0.899	5.9267	5.0292	1	NA	

H	1	NA	NA	NA	18.5	NA	NA	NA	1.3	NA	NA	NA	

185.7142857	NA	NA	NA
8	929	1	0	460	3220	61	8.5	19.1467	0.9035	5.1083	4.4243	1	NA	

H	1	NA	NA	NA	16.9	NA	NA	NA	1.5	NA	NA	NA	

214.2857143	NA	NA	NA
9	429	3	1	380	2660	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	24.2	NA	NA	NA	-0.9	NA	NA	

NA	-128.5714286	NA
9	901	3	0	670	4690	64	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	18.2	NA	NA	NA	0	NA	NA	

NA	0	NA
9	939	1	0	700	4900	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	19.2	NA	NA	NA	0.7	NA	NA	

NA	100	NA
9	911	3	0	650	4550	62	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	21.1	NA	NA	NA	0.4	NA	NA	

NA	57.14285714	NA
9	932	1	1	450	3150	49	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	20.1	NA	NA	NA	0.5	NA	NA	NA	

71.42857143	NA	NA	NA
9	431	3	0	510	3570	69	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	24.7	NA	NA	NA	0.7	NA	NA	

NA	100	NA
9	928	1	0	730	5110	64	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	19.5	NA	NA	NA	-0.8	NA	NA	NA	

-114.2857143	NA	NA	NA
9	984	3	1	740	5180	75	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	24.7	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
9	971	1	1	940	6580	83	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22.8	NA	NA	NA	0.7	NA	NA	NA	100	

NA	NA	NA
9	967	1	1	600	4200	68	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	22.8	NA	NA	NA	1.8	NA	NA	

NA	257.1428571	NA
9	930	1	0	610	4270	64	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	21.2	NA	NA	NA	1.4	NA	NA	NA	200	

NA	NA	NA
9	821	3	1	560	3920	58	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	14.8	NA	17	NA	0	NA	-1	NA	0	

NA	-142.8571429	NA
9	973	1	0	520	3640	54	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	20	NA	NA	NA	2.2	NA	NA	NA	

314.2857143	NA	NA	NA
9	940	1	1	530	3710	62	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	17.8	NA	NA	NA	1.4	NA	NA	

NA	200	NA
9	902	3	0	400	2800	73	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15.2	NA	NA	NA	1.7	NA	NA	

NA	242.8571429	NA
9	424	3	1	860	6020	67	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
9	910	3	0	780	5460	62	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	17.8	NA	17	NA	1.8	NA	1.1	NA	

257.1428571	NA	157.1428571	NA
9	943	2	1	770	5390	68	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	21.3	NA	21.8	NA	2.1	NA	3	NA	300	

NA	428.5714286	NA
9	983	3	1	670	4690	73	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	20.2	18.2	NA	NA	3.3	0.2	NA	

NA	471.4285714	28.57142857
9	845	3	0	420	2940	65	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	15.7	NA	16.7	NA	0.5	NA	0.9	NA	

71.42857143	NA	128.5714286	NA
9	942	2	0	780	5460	76	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	23.1	NA	NA	NA	1.7	NA	NA	NA	

242.8571429	NA	NA	NA
9	432	2	0	540	3780	61	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	11.6	14	NA	NA	1	1.9	NA	NA	

142.8571429	271.4285714	NA	NA
9	427	1	1	850	5950	71	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22.2	NA	NA	NA	-1.2	NA	NA	NA	

-171.4285714	NA	NA	NA
9	927	1	0	540	3780	68	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	17.4	NA	NA	NA	0.8	NA	NA	

NA	114.2857143	NA
9	969	1	0	770	5390	60	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	16.4	NA	NA	NA	0.4	NA	NA	

NA	57.14285714	NA
9	430	1	1	520	3640	51	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	18.5	NA	NA	NA	-1.1	NA	NA	NA	

-157.1428571	NA	NA	NA
9	944	2	1	650	4550	64	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	14.9	NA	14.2	NA	0.4	NA	0	NA	

57.14285714	NA	0	NA
9	842	3	0	850	5950	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	21.4	NA	NA	NA	1.4	NA	NA	

NA	200	NA
9	824	3	1	530	3710	66	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	16.7	16	NA	NA	2	1.4	NA	

NA	285.7142857	200
9	972	1	1	550	3850	59	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	17.3	NA	NA	NA	0.9	NA	NA	

NA	128.5714286	NA
9	907	3	1	570	3990	64	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	13.6	17	NA	NA	1.1	0.4	NA	NA	

157.1428571	57.14285714	NA	NA
9	933	1	0	1070	7490	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	15.2	NA	NA	NA	1	NA	NA	NA	

142.8571429	NA	NA	NA
9	948	2	1	650	4550	74	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	21.2	NA	NA	NA	0.9	NA	NA	

NA	128.5714286	NA
9	828	3	0	840	5880	75	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	19.2	NA	NA	NA	0	NA	NA	NA	0	

NA	NA	NA
9	950	2	1	1060	7420	71	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	14.6	14.4	NA	NA	0.8	0	NA	NA	

114.2857143	0	NA	NA
9	908	3	1	590	4130	74	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22.7	NA	NA	NA	2.1	NA	NA	NA	300	

NA	NA	NA
9	935	1	0	480	3360	67	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	24	NA	NA	NA	1.4	NA	NA	

NA	200	NA
9	946	2	1	640	4480	62	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	21	NA	NA	NA	1.2	NA	NA	

NA	171.4285714	NA
9	955	2	0	480	3360	55	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	18.2	NA	NA	NA	1.3	NA	NA	NA	

185.7142857	NA	NA	NA
9	881	2	0	700	4900	63	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	20.2	NA	NA	NA	1	NA	NA	NA	

142.8571429	NA	NA	NA
9	880	2	1	770	5390	59	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	20.9	NA	NA	NA	-0.7	NA	NA	NA	-100	

NA	NA	NA
9	993	1	1	670	4690	54	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	18	NA	NA	NA	0.3	NA	NA	NA	

42.85714286	NA	NA	NA
9	937	1	1	770	5390	60	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	21	NA	NA	NA	-0.7	NA	NA	

NA	-100	NA
9	951	2	1	600	4200	58	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	19.6	NA	NA	NA	1.1	NA	NA	NA	

157.1428571	NA	NA	NA
9	929	1	0	420	2940	64	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	17.2	NA	NA	NA	0.3	NA	NA	NA	

42.85714286	NA	NA	NA
10	429	3	1	380	2660	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	24.2	NA	NA	NA	0	NA	NA	

NA	0	NA
10	901	3	0	700	4900	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	20.8	NA	NA	NA	2.6	NA	NA	

NA	371.4285714	NA
10	939	1	0	740	5180	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	21.3	NA	NA	NA	2.1	NA	NA	

NA	300	NA
10	911	3	0	610	4270	62	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	22.7	NA	NA	NA	1.6	NA	NA	

NA	228.5714286	NA
10	932	1	1	690	4830	47	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	21.3	NA	NA	NA	1.2	NA	NA	NA	

171.4285714	NA	NA	NA
10	431	3	0	480	3360	69	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	26.6	NA	NA	NA	1.9	NA	NA	

NA	271.4285714	NA
10	928	1	0	740	5180	65	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	21.2	NA	NA	NA	1.7	NA	NA	NA	

242.8571429	NA	NA	NA
10	984	3	1	740	5180	75	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	26	NA	NA	NA	1.3	NA	NA	

NA	185.7142857	NA
10	971	1	1	700	4900	83	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	25.4	NA	NA	NA	2.6	NA	NA	NA	

371.4285714	NA	NA	NA
10	967	1	1	420	2940	67	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	23	NA	NA	NA	0.2	NA	NA	

NA	28.57142857	NA
10	930	1	0	440	3080	66	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	21.6	NA	NA	NA	0.4	NA	NA	NA	

57.14285714	NA	NA	NA
10	821	3	1	660	4620	59	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	15.7	NA	18.8	NA	0.9	NA	1.8	NA	

128.5714286	NA	257.1428571	NA
10	973	1	0	560	3920	57	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22	NA	NA	NA	2	NA	NA	NA	

285.7142857	NA	NA	NA
10	940	1	1	700	4900	63	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	20	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
10	902	3	0	460	3220	73	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15.7	NA	NA	NA	NA	NA	NA	

NA	NA	NA
10	424	3	1	860	6020	70	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
10	910	3	0	720	5040	63	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	18.8	NA	18.4	NA	1	NA	1.4	NA	

142.8571429	NA	200	NA
10	943	2	1	750	5250	69	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	23.2	NA	23.6	NA	1.9	NA	1.8	NA	

271.4285714	NA	257.1428571	NA
10	983	3	1	580	4060	75	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	19.7	20	NA	NA	-0.5	1.8	NA	

NA	-71.42857143	257.1428571
10	845	3	0	440	3080	66	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	15	NA	18	NA	-0.7	NA	1.3	NA	-100	

NA	185.7142857	NA
10	942	2	0	980	6860	76	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	23.5	NA	NA	NA	0.4	NA	NA	NA	

57.14285714	NA	NA	NA
10	432	2	0	540	3780	62	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	11.6	15	NA	NA	0	1	NA	NA	0	

142.8571429	NA	NA
10	427	1	1	1110	7770	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	21	NA	NA	NA	-1.2	NA	NA	NA	

-171.4285714	NA	NA	NA
10	927	1	0	540	3780	70	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	18	NA	NA	NA	0.6	NA	NA	

NA	85.71428571	NA
10	969	1	0	650	4550	61	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	17.7	NA	NA	NA	1.3	NA	NA	

NA	185.7142857	NA
10	430	1	1	510	3570	51	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	20.3	NA	NA	NA	1.8	NA	NA	NA	

257.1428571	NA	NA	NA
10	944	2	1	540	3780	65	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	14	NA	14.6	NA	-0.9	NA	0.4	NA	

-128.5714286	NA	57.14285714	NA
10	842	3	0	740	5180	64	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	22	NA	NA	NA	0.6	NA	NA	

NA	85.71428571	NA
10	824	3	1	500	3500	67	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	15.6	16.2	NA	NA	-1.1	0.2	NA	

NA	-157.1428571	28.57142857
10	972	1	1	500	3500	59	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	20	NA	NA	NA	2.7	NA	NA	

NA	385.7142857	NA
10	907	3	1	600	4200	65	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	14.2	15.7	NA	NA	0.6	-1.3	NA	NA	

85.71428571	-185.7142857	NA	NA
10	933	1	0	880	6160	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	16	NA	NA	NA	0.8	NA	NA	NA	

114.2857143	NA	NA	NA
10	948	2	1	550	3850	75	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	22	NA	NA	NA	0.8	NA	NA	

NA	114.2857143	NA
10	828	3	0	790	5530	74	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	17.4	NA	NA	NA	-1.8	NA	NA	NA	

-257.1428571	NA	NA	NA
10	950	2	1	1010	7070	70	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	16.9	15.3	NA	NA	2.3	0.9	NA	NA	

328.5714286	128.5714286	NA	NA
10	908	3	1	500	3500	74	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	23.3	NA	NA	NA	0.6	NA	NA	NA	

85.71428571	NA	NA	NA
10	935	1	0	610	4270	69	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	24.4	NA	NA	NA	0.4	NA	NA	

NA	57.14285714	NA
10	946	2	1	600	4200	61	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	22.6	NA	NA	NA	1.6	NA	NA	

NA	228.5714286	NA
10	955	2	0	420	2940	54	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	19.6	NA	NA	NA	1.4	NA	NA	NA	200	

NA	NA	NA
10	881	2	0	550	3850	62	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	20	NA	NA	NA	-0.2	NA	NA	NA	

-28.57142857	NA	NA	NA
10	880	2	1	470	3290	58	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22.4	NA	NA	NA	1.5	NA	NA	NA	

214.2857143	NA	NA	NA
10	993	1	1	760	5320	54	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	20.4	NA	NA	NA	2.4	NA	NA	NA	

342.8571429	NA	NA	NA
10	937	1	1	780	5460	62	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	23.4	NA	NA	NA	2.4	NA	NA	

NA	342.8571429	NA
10	951	2	1	610	4270	60	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	20.4	NA	NA	NA	0.8	NA	NA	NA	

114.2857143	NA	NA	NA
10	929	1	0	520	3640	64	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	19.2	NA	NA	NA	2	NA	NA	NA	

285.7142857	NA	NA	NA
11	429	3	1	310	2170	65	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	26.5	NA	NA	NA	2.3	NA	NA	

NA	328.5714286	NA
11	901	3	0	600	4200	67	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	21	NA	NA	NA	0.2	NA	NA	

NA	28.57142857	NA
11	939	1	0	700	4900	66	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	22.6	NA	NA	NA	1.3	NA	NA	

NA	185.7142857	NA
11	911	3	0	550	3850	67	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	23	NA	NA	NA	0.3	NA	NA	

NA	42.85714286	NA
11	932	1	1	650	4550	47	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22.2	NA	NA	NA	0.9	NA	NA	NA	

128.5714286	NA	NA	NA
11	431	3	0	500	3500	71	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	27.9	NA	NA	NA	1.3	NA	NA	

NA	185.7142857	NA
11	928	1	0	750	5250	64	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22.7	NA	NA	NA	1.5	NA	NA	NA	

214.2857143	NA	NA	NA
11	984	3	1	560	3920	75	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	29	NA	NA	NA	3	NA	NA	

NA	428.5714286	NA
11	971	1	1	550	3850	83	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	29.4	NA	NA	NA	4	NA	NA	NA	

571.4285714	NA	NA	NA
11	967	1	1	320	2240	67	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	26.2	NA	NA	NA	3.2	NA	NA	

NA	457.1428571	NA
11	930	1	0	540	3780	68	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22.8	NA	NA	NA	1.2	NA	NA	NA	

171.4285714	NA	NA	NA
11	821	3	1	880	6160	61	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	16	NA	19	NA	0.3	NA	0.2	NA	

42.85714286	NA	28.57142857	NA
11	973	1	0	500	3500	59	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22.2	NA	NA	NA	0.2	NA	NA	NA	

28.57142857	NA	NA	NA
11	940	1	1	480	3360	64	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	20.6	NA	NA	NA	0.6	NA	NA	

NA	85.71428571	NA
11	902	3	0	370	2590	75	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	15.2	NA	NA	NA	-0.5	NA	NA	

NA	-71.42857143	NA
11	424	3	1	820	5740	70	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
11	910	3	0	490	3430	65	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	21	NA	20.5	NA	2.2	NA	2.1	NA	

314.2857143	NA	300	NA
11	943	2	1	490	3430	69	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	23.8	NA	24.6	NA	0.6	NA	1	NA	

85.71428571	NA	142.8571429	NA
11	983	3	1	450	3150	75	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	22	22.4	NA	NA	2.3	2.4	NA	

NA	328.5714286	342.8571429
11	845	3	0	320	2240	65	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	16	NA	19.6	NA	1	NA	1.6	NA	

142.8571429	NA	228.5714286	NA
11	942	2	0	800	5600	77	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	24	NA	NA	NA	0.5	NA	NA	NA	

71.42857143	NA	NA	NA
11	432	2	0	580	4060	63	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	12.4	16.2	NA	NA	0.8	1.2	NA	NA	

114.2857143	171.4285714	NA	NA
11	427	1	1	1160	8120	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	25.2	NA	NA	NA	4.2	NA	NA	NA	600	

NA	NA	NA
11	927	1	0	400	2800	71	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	20.6	NA	NA	NA	2.6	NA	NA	

NA	371.4285714	NA
11	969	1	0	700	4900	62	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	21	NA	NA	NA	3.3	NA	NA	

NA	471.4285714	NA
11	430	1	1	430	3010	52	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	23	NA	NA	NA	2.7	NA	NA	NA	

385.7142857	NA	NA	NA
11	944	2	1	320	2240	67	NA	NA	NA	NA	NA	2	2	

NA	1	NA	1	NA	13.6	NA	16.8	NA	-0.4	NA	2.2	NA	

-57.14285714	NA	314.2857143	NA
11	842	3	0	760	5320	64	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	24.8	NA	NA	NA	2.8	NA	NA	

NA	400	NA
11	824	3	1	310	2170	68	NA	NA	NA	NA	NA	2	2	

NA	NA	NA	1	2	NA	NA	16.4	16.4	NA	NA	0.8	0.2	NA	

NA	114.2857143	28.57142857
11	972	1	1	460	3220	60	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	21.8	NA	NA	NA	1.8	NA	NA	

NA	257.1428571	NA
11	907	3	1	610	4270	64	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	14.2	15.3	NA	NA	0	-0.4	NA	NA	0	

-57.14285714	NA	NA
11	933	1	0	1000	7000	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	17.6	NA	NA	NA	1.6	NA	NA	NA	

228.5714286	NA	NA	NA
11	948	2	1	370	2590	74	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	23.3	NA	NA	NA	1.3	NA	NA	

NA	185.7142857	NA
11	828	3	0	820	5740	74	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	17.9	NA	NA	NA	0.5	NA	NA	NA	

71.42857143	NA	NA	NA
11	950	2	1	910	6370	70	NA	NA	NA	NA	NA	2	2	

NA	1	2	NA	NA	17.4	16	NA	NA	0.5	0.7	NA	NA	

71.42857143	100	NA	NA
11	908	3	1	440	3080	73	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	26	NA	NA	NA	2.7	NA	NA	NA	

385.7142857	NA	NA	NA
11	935	1	0	590	4130	68	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	25.4	NA	NA	NA	1	NA	NA	

NA	142.8571429	NA
11	946	2	1	570	3990	60	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	23.8	NA	NA	NA	1.2	NA	NA	

NA	171.4285714	NA
11	955	2	0	470	3290	55	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22	NA	NA	NA	2.4	NA	NA	NA	

342.8571429	NA	NA	NA
11	881	2	0	540	3780	62	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22.4	NA	NA	NA	2.4	NA	NA	NA	

342.8571429	NA	NA	NA
11	880	2	1	560	3920	58	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	24	NA	NA	NA	1.6	NA	NA	NA	

228.5714286	NA	NA	NA
11	993	1	1	700	4900	55	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	21.6	NA	NA	NA	1.2	NA	NA	NA	

171.4285714	NA	NA	NA
11	937	1	1	620	4340	64	NA	NA	NA	NA	NA	1	NA	

M	NA	NA	1	NA	NA	NA	23.4	NA	NA	NA	0	NA	NA	

NA	0	NA
11	951	2	1	400	2800	59	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	22.6	NA	NA	NA	2.2	NA	NA	NA	

314.2857143	NA	NA	NA
11	929	1	0	320	2240	64	NA	NA	NA	NA	NA	1	NA	

H	1	NA	NA	NA	20	NA	NA	NA	0.8	NA	NA	NA	

114.2857143	NA	NA	NA
12	429	3	1	300	2100	67	8.05	19.0819	0.9039	5.8475	3.8131	1	NA	

M	NA	NA	1	NA	NA	NA	28.3	NA	NA	NA	1.8	NA	NA	

NA	257.1428571	NA
12	901	3	0	480	3360	69	6.8	17.1301	0.884	4.7708	4.3048	1	NA	

M	NA	NA	1	NA	NA	NA	23.2	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
12	939	1	0	610	4270	68	7.6	18.3774	0.9529	5.1315	4.1302	1	NA	

M	NA	NA	1	NA	NA	NA	24.1	NA	NA	NA	1.5	NA	NA	

NA	214.2857143	NA
12	911	3	0	550	3850	67	8.4	19.542	0.9099	5.3574	4.2909	1	NA	

M	NA	NA	1	NA	NA	NA	23	NA	NA	NA	0	NA	NA	

NA	0	NA
12	932	1	1	540	3780	50	7.8	18.7603	0.9831	5.5026	4.0155	1	NA	

H	1	NA	NA	NA	22.2	NA	NA	NA	0	NA	NA	NA	0	

NA	NA	NA
12	431	3	0	360	2520	73	8.05	20.414	1.0373	7.0453	4.0891	1	NA	

M	NA	NA	1	NA	NA	NA	28	NA	NA	NA	0.1	NA	NA	

NA	14.28571429	NA
12	928	1	0	610	4270	67	9.6	20.8487	0.842	5.4314	4.5009	1	NA	

H	1	NA	NA	NA	23.2	NA	NA	NA	0.5	NA	NA	NA	

71.42857143	NA	NA	NA
12	984	3	1	450	3150	76	8.4	18.8994	0.8285	5.4391	4.3645	1	NA	

M	NA	NA	1	NA	NA	NA	29	NA	NA	NA	0	NA	NA	

NA	0	NA
12	971	1	1	370	2590	84	8.2	18.7883	0.9271	5.6094	4.1184	1	NA	

H	1	NA	NA	NA	29.4	NA	NA	NA	0	NA	NA	NA	0	

NA	NA	NA
12	967	1	1	260	1820	69	8.2	19.7012	0.9617	6.154	4.2830	1	NA	

M	NA	NA	1	NA	NA	NA	24	NA	NA	NA	-2.2	NA	NA	

NA	-314.2857143	NA
12	930	1	0	450	3150	68	10.3	21.9012	0.9985	5.794	4.0915	1	NA	

H	1	NA	NA	NA	23.6	NA	NA	NA	0.8	NA	NA	NA	

114.2857143	NA	NA	NA
12	821	3	1	700	4900	62	7.3	18.2748	0.928	5.5328	4.2001	2	2	

NA	1	NA	1	NA	18.5	NA	20.4	NA	2.5	NA	1.4	NA	

357.1428571	NA	200	NA
12	973	1	0	480	3360	60	8.17	19.8487	0.9432	5.2258	4.2900	1	NA	

H	1	NA	NA	NA	24.8	NA	NA	NA	2.6	NA	NA	NA	

371.4285714	NA	NA	NA
12	940	1	1	450	3150	64	8	18.9898	0.9948	5.82	4.0742	1	NA	

M	NA	NA	1	NA	NA	NA	22.2	NA	NA	NA	1.6	NA	NA	

NA	228.5714286	NA
12	902	3	0	400	2800	77	7.5	18.3286	0.9251	4.7682	4.3104	1	NA	

M	NA	NA	1	NA	NA	NA	18.6	NA	NA	NA	3.4	NA	NA	

NA	485.7142857	NA
12	424	3	1	830	5810	71	9.15	21.1182	0.9008	6.2436	4.1781	1	NA	

M	NA	NA	1	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	

NA	NA	NA
12	910	3	0	640	4480	65	6.7	16.602	0.9024	5.1347	4.0429	2	2	

NA	1	NA	1	NA	22	NA	22	NA	1	NA	1.5	NA	

142.8571429	NA	214.2857143	NA
12	943	2	1	340	2380	70	8	18.9112	0.9374	5.3698	3.9104	2	2	

NA	1	NA	1	NA	26.1	NA	26	NA	2.3	NA	1.4	NA	

328.5714286	NA	200	NA
12	983	3	1	420	2940	75	8	17.9703	0.8794	5.03995	3.8725	2	2	

NA	NA	NA	1	2	NA	NA	23.1	24.1	NA	NA	1.1	1.7	NA	

NA	157.1428571	242.8571429
12	845	3	0	390	2730	63	6.95	17.8857	0.8816	4.8955	4.0415	2	2	

NA	1	NA	1	NA	18.3	NA	20	NA	2.3	NA	0.4	NA	

328.5714286	NA	57.14285714	NA
12	942	2	0	850	5950	77	7.9	18.8338	0.8297	4.3915	4.4030	1	NA	

H	1	NA	NA	NA	25.4	NA	NA	NA	1.4	NA	NA	NA	200	

NA	NA	NA
12	432	2	0	450	3150	63	7.1	17.8344	0.945	5.4013	3.9837	2	2	

NA	1	2	NA	NA	14	18.8	NA	NA	1.6	2.6	NA	NA	

228.5714286	371.4285714	NA	NA
12	427	1	1	1030	7210	73	8.45	19.2424	0.8298	5.2241	4.4896	1	NA	

H	1	NA	NA	NA	25.8	NA	NA	NA	0.6	NA	NA	NA	

85.71428571	NA	NA	NA
12	927	1	0	580	4060	72	9.6	20.1228	0.789	4.844	4.4104	1	NA	

M	NA	NA	1	NA	NA	NA	22.6	NA	NA	NA	2	NA	NA	

NA	285.7142857	NA
12	969	1	0	610	4270	62	8.5	19.4813	0.857	5.5157	4.1294	1	NA	

M	NA	NA	1	NA	NA	NA	22	NA	NA	NA	1	NA	NA	

NA	142.8571429	NA
12	430	1	1	610	4270	54	8.65	19.919	0.897	5.0038	4.2938	1	NA	

H	1	NA	NA	NA	24.8	NA	NA	NA	1.8	NA	NA	NA	

257.1428571	NA	NA	NA
12	944	2	1	250	1750	67	9	20.4849	0.9319	5.4332	4.0641	2	2	

NA	1	NA	1	NA	17	NA	18	NA	3.4	NA	1.2	NA	

485.7142857	NA	171.4285714	NA
12	842	3	0	800	5600	64	8.45	19.4899	0.8272	4.8111	4.5430	1	NA	

M	NA	NA	1	NA	NA	NA	27	NA	NA	NA	2.2	NA	NA	

NA	314.2857143	NA
12	824	3	1	210	1470	68	8.1	18.71	0.9	5.31	4.1700	2	2	

NA	NA	NA	1	2	NA	NA	19	19	NA	NA	2.6	2.6	NA	

NA	371.4285714	371.4285714
12	972	1	1	350	2450	60	7.45	18.0437	0.8862	4.9058	4.1457	1	NA	

M	NA	NA	1	NA	NA	NA	21.8	NA	NA	NA	0	NA	NA	

NA	0	NA
12	907	3	1	660	4620	63	7.75	19.3411	0.8738	6.0474	4.4596	2	2	

NA	1	2	NA	NA	17	17	NA	NA	2.8	1.7	NA	NA	400	

242.8571429	NA	NA
12	933	1	0	1090	7630	73	8.05	18.4025	0.8614	4.4922	4.5331	1	NA	

H	1	NA	NA	NA	19	NA	NA	NA	1.4	NA	NA	NA	200	

NA	NA	NA
12	948	2	1	240	1680	74	7.85	18.6638	0.8286	5.0908	3.8407	1	NA	

M	NA	NA	1	NA	NA	NA	27.2	NA	NA	NA	3.9	NA	NA	

NA	557.1428571	NA
12	828	3	0	840	5880	74	10.2	21.6667	0.8751	6.1423	3.9300	1	NA	

H	1	NA	NA	NA	23.1	NA	NA	NA	5.2	NA	NA	NA	

742.8571429	NA	NA	NA
12	950	2	1	880	6160	70	9.6	20.618	0.8295	5.6526	4.0939	2	2	

NA	1	2	NA	NA	18.3	16.5	NA	NA	0.9	0.5	NA	NA	

128.5714286	71.42857143	NA	NA
12	908	3	1	370	2590	73	9.8	21.5713	0.9861	5.8596	4.1217	1	NA	

H	1	NA	NA	NA	27.7	NA	NA	NA	1.7	NA	NA	NA	

242.8571429	NA	NA	NA
12	935	1	0	610	4270	70	7.9	18.7722	0.8049	4.9627	4.2804	1	NA	

M	NA	NA	1	NA	NA	NA	26.8	NA	NA	NA	1.4	NA	NA	

NA	200	NA
12	946	2	1	600	4200	62	6.95	17.7376	0.8232	5.2329	4.2653	1	NA	

M	NA	NA	1	NA	NA	NA	23.8	NA	NA	NA	0	NA	NA	

NA	0	NA
12	955	2	0	440	3080	56	9.15	20.3768	0.9268	5.9223	4.1215	1	NA	

H	1	NA	NA	NA	22	NA	NA	NA	0	NA	NA	NA	0	

NA	NA	NA
12	881	2	0	450	3150	63	8	19.2697	0.979	5.8033	4.1106	1	NA	

H	1	NA	NA	NA	23.4	NA	NA	NA	1	NA	NA	NA	

142.8571429	NA	NA	NA
12	880	2	1	520	3640	59	8.15	19.4556	0.9267	5.6218	4.0434	1	NA	

H	1	NA	NA	NA	24	NA	NA	NA	0	NA	NA	NA	0	

NA	NA	NA
12	993	1	1	750	5250	54	7.55	18.2651	0.8267	4.5025	4.3729	1	NA	

H	1	NA	NA	NA	22.5	NA	NA	NA	0.9	NA	NA	NA	

128.5714286	NA	NA	NA
12	937	1	1	650	4550	62	7.33	17.7424	0.8506	5.4672	4.1036	1	NA	

M	NA	NA	1	NA	NA	NA	25	NA	NA	NA	1.6	NA	NA	

NA	228.5714286	NA
12	951	2	1	560	3920	59	10.3	22.1086	0.9119	7.1849	3.8335	1	NA	

H	1	NA	NA	NA	23	NA	NA	NA	0.4	NA	NA	NA	

57.14285714	NA	NA	NA
12	929	1	0	460	3220	66	8.14	19.4538	0.9234	4.829	4.0279	1	NA	

H	1	NA	NA	NA	22	NA	NA	NA	2	NA	NA	NA	

285.7142857	NA	NA	NA


From elvis at xlsolutions-corp.com  Tue Mar 18 21:02:16 2003
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 18 Mar 2003 12:02:16 -0800
Subject: [R] 
	COURSE***R/S-plus Fundamentals and Programming Techniques***April
	2003 - Boston and San Francisco
Message-ID: <APEHLKCMHHAKBGLAPKPCIEMECCAA.elvis@xlsolutions-corp.com>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud
to announce a 2-day course: "R/S-plus Fundamentals and Programming
Techniques".

**** Boston, MA-----------------> April 10-11
**** San Francisco -------------> April 28-29

Course Description:

This two-day R/S-plus course focuses on a broad spectrum of topics,
from reading raw data to a comparison of R and S. We will learn
the essentials of data manipulation, graphical visualization
and R/S-plus programming. We will explore statistical data analysis tools,
including graphics with data sets. How to enhance your plots.
We will perform basic statistics and fit linear regression models.
Participants are encouraged to bring data for interactive sessions


Course Outline:

- An Overview of R: Installation and Demonstration
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling
- Generalized Linear Models
- Linear Regression
- Parametric Models, etc
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)



Payments are due AFTER the course and early-bird ends February 28.

Registration:

Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578 x221
Visit us: www.xlsolutions-corp.com/training.htm


Course Format:

This course consists of a series of short lectures with
demonstrations and interactive sessions for the participants.
Each student is provided with bound copies of the notes and
a CD-ROM containing all examples, exercises and software used
on the course.



Share Your Thoughts:

Are there any additional topics you would like for this course to address?
Would you like for this course to be offered in another city?

Please let us know by contributing to our recommendation list:
training at xlsolutions-corp.com.

========================================================================

R/S-Plus Fundamentals and Programming Techniques / Boston March 2003
Pre-registration Form (Please email or print and fax: 206-686-1578)
XLsolutions Corporation: For your Solutions needs, Consulting and Training.
www.xlsolutions-corp.com



Title...... First Name ................. Last Name....................

Organization..........................................................

Mailing Address.......................................................

.....................................................................

.....................................................................

Zip Code...................... Country.............................

Telephone........................... Fax ...............................

E-mail................................................................



Elvis Miller, PhD
Manager Training and Technical Support
North American Division
XLSolutions Corporation
Email: elvis at xlsolutions-corp.com
Phone: 206-686-1578
Web: www.xlsolutions-corp.com


From mt at michaelltaylor.com  Tue Mar 18 22:23:21 2003
From: mt at michaelltaylor.com (michaell taylor)
Date: 18 Mar 2003 16:23:21 -0500
Subject: [R] Change directory in script
In-Reply-To: <KAENIAILDIGDGGKMAOIPIEGPCNAA.mhp@dadlnet.dk>
References: <KAENIAILDIGDGGKMAOIPIEGPCNAA.mhp@dadlnet.dk>
Message-ID: <1048022602.4761.11.camel@xeon>

Look at:
?setwd

On Tue, 2003-03-18 at 14:37, Morten H Pedersen wrote:
> Is there an R command to change directory? (it would be nice to include in
> scripts to go to the right directory)
> 
> Sincerely,
> 
> 
> Morten H Pedersen, M.D.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Hui_Wang at affymetrix.com  Tue Mar 18 22:20:13 2003
From: Hui_Wang at affymetrix.com (Wang, Hui)
Date: Tue, 18 Mar 2003 13:20:13 -0800
Subject: [R] How to free memory
Message-ID: <48F1F432BF75D6118FAC0002B325BE3610CF48@ntex04.affymetrix.com>

Hi List,

Could anybody give me some tips on how to free up memory in R(after reaching
the limit of allocated memory size)? By removing the object using "rm"
doesnot seem help much.

Thanks

-h


From jerome at hivnet.ubc.ca  Tue Mar 18 22:26:53 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Tue, 18 Mar 2003 13:26:53 -0800
Subject: [R] frailty variance parameter in survreg()
Message-ID: <200303182132.NAA12091@hivnet.ubc.ca>


Is there a simple way to extract the frailty variance parameter (theta)?
Below is an example of the method that I have.

  library(survival)
  data(rats)
  rfit2b <- survreg(Surv(time, status) ~ rx +
                       frailty.gaussian(litter, df=13, sparse=TRUE), rats )

 {
  #According to rfit2b$printfun, this is the way to extract "theta"
  if (!is.null(rfit2b$history[[1]]$history))
   theta <- rfit2b$history[[1]]$history[nrow(rfit2b$history[[1]]$history), 1]
  else theta <- rfit2b$history[[1]]$theta
 }
  theta   # This is 0.01926811

#It would be a nice feature if the final variance estimate
#was directly accessible by:
  rfit2b$history[[1]]$theta   # This is 0.01926953   != theta 

Could we make it that way?

Sincerely,
Jerome Asselin

P.S.: I am using the survival package 2.9-6 on R 1.6.2 on RedHat Linux 7.2.

-- 

Jerome Asselin (J?r?me), Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital, 608 - 1081 Burrard Street
Vancouver, British Columbia, CANADA V6Z 1Y6
Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044


From gvasudevan at medarex.com  Tue Mar 18 23:03:10 2003
From: gvasudevan at medarex.com (Vasudevan, Geetha)
Date: Tue, 18 Mar 2003 14:03:10 -0800
Subject: [R] How to free memory
Message-ID: <8249C3256E593D4FB066BB9998D9F7E41CF15D@ca2-fs03.ca2.2k.medarex.com>


R> help(Memory) or help(gc) 
tells something about this.

-g

-----Original Message-----
From:	Wang, Hui [mailto:Hui_Wang at affymetrix.com]
Sent:	Tue 3/18/2003 1:20 PM
To:	r-help at stat.math.ethz.ch
Cc:	
Subject:	[R] How to free memory
Hi List,

Could anybody give me some tips on how to free up memory in R(after reaching
the limit of allocated memory size)? By removing the object using "rm"
doesnot seem help much.

Thanks

-h

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From bjwhitcher at yahoo.co.uk  Tue Mar 18 23:52:08 2003
From: bjwhitcher at yahoo.co.uk (=?iso-8859-1?q?Brandon=20Whitcher?=)
Date: Tue, 18 Mar 2003 22:52:08 +0000 (GMT)
Subject: [R] Re: Error in file(file, "r")
In-Reply-To: <EA37C22921B7D611AF5200508B949B5A013F5BF6@atlanta_nt2.atlanta.glenayre.com>
Message-ID: <20030318225208.56800.qmail@web21508.mail.yahoo.com>

 --- "Chisolm, Barbara" <barbara.chisolm at glenayre.com> wrote: 

> Hello,
> 
> I am a new user of R, and I am not able to read/scan external files.  I am
> working in a Linux environment.  I have read through the R FAQ and documents
> and have not been successful using the recommendations.  Below are several
> scripts I've used and the error messages. .  
> 
> I've cc'd Brandon Whitcher because it was recommended in another FAQ.   I
> read that this is a bug that occurs on Windows.   Is there is a patch/fix
> that I can use?  I'd appreciate any help with this problem.
> 
> Thnx,
> Barbara Chisolm
> 
> Test2 <- scan("C:\\bac\\TestData2")
> Error in file(file, "r") : cannot open file `C:\bac\TestData2
> 
>                                                                          '
> > test1<-read.table('J:/bac/R/TestDataWord.txt')
> Error in file(file, "r") : cannot open file `J:/bac/R/TestDataWord.txt'
> 
> > setwd("J:/bac/R/")
> Error in setwd(dir) : cannot change working directory
>  

Um, I'm confused as to why I was cc'ed for this problem.  I operate a couple of
packages but am not involved in core R questions.

Which FAQ was I referenced on?

Brandon


From cherylh at montana.edu  Wed Mar 19 05:25:38 2003
From: cherylh at montana.edu (Cheryl H.)
Date: Tue, 18 Mar 2003 21:25:38 -0700
Subject: [R] r-help using random generating
Message-ID: <5.1.1.6.0.20030318212124.00b18148@TREX2.MSU.MONTANA.EDU>

To whom it may concern:
Given that my sample size is n, my mean is 100, and my sd is 10, I need to 
use a random number generator (which I believe is the function 
rnorm(5,100,10)), but I need to repeat it a large number of times, and then 
plot the sampling distributions of the sample means, sd's, and variances of 
those generated sets. I'm having a real hard time trying to figure out how 
to do this easily. Please help if possible! Thanks,
Cheryl


From maj at stats.waikato.ac.nz  Wed Mar 19 05:39:08 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Wed, 19 Mar 2003 16:39:08 +1200
Subject: [R] r-help using random generating
References: <5.1.1.6.0.20030318212124.00b18148@TREX2.MSU.MONTANA.EDU>
Message-ID: <3E77F46C.1060306@stats.waikato.ac.nz>

Student Exercise?!

Cheryl H. wrote:
> To whom it may concern:
> Given that my sample size is n, my mean is 100, and my sd is 10, I need 
> to use a random number generator (which I believe is the function 
> rnorm(5,100,10)), but I need to repeat it a large number of times, and 
> then plot the sampling distributions of the sample means, sd's, and 
> variances of those generated sets. I'm having a real hard time trying to 
> figure out how to do this easily. Please help if possible! Thanks,
> Cheryl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862


From gisar at nus.edu.sg  Wed Mar 19 06:14:34 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Wed, 19 Mar 2003 13:14:34 +0800
Subject: [R] r-help using random generating
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F22F@MBXSRV03.stf.nus.edu.sg>

Yes it looks like a really good student exercise into the sampling
properties of a distribution.

What you need to do is initialize vectors beforehand that will contain
the mean and variance values. Then simply use a for() loop that
generates 5 random numbers. Use the mean(), var() and store the values
into the vector. Then a simple plot() should suffice. 

Since it is a simple problem, I will leave you to it.

-----Original Message-----
From: Murray Jorgensen [mailto:maj at stats.waikato.ac.nz] 
Sent: Wednesday, March 19, 2003 12:39 PM
Cc: R-help at stat.math.ethz.ch
Subject: Re: [R] r-help using random generating


Student Exercise?!

Cheryl H. wrote:
> To whom it may concern:
> Given that my sample size is n, my mean is 100, and my sd is 10, I 
> need
> to use a random number generator (which I believe is the function 
> rnorm(5,100,10)), but I need to repeat it a large number of times, and

> then plot the sampling distributions of the sample means, sd's, and 
> variances of those generated sets. I'm having a real hard time trying
to 
> figure out how to do this easily. Please help if possible! Thanks,
> Cheryl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From otoomet at econ.dk  Wed Mar 19 07:51:33 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Wed, 19 Mar 2003 07:51:33 +0100
Subject: [R] How to free memory
In-Reply-To: <48F1F432BF75D6118FAC0002B325BE3610CF48@ntex04.affymetrix.com>
	(Hui_Wang@affymetrix.com)
References: <48F1F432BF75D6118FAC0002B325BE3610CF48@ntex04.affymetrix.com>
Message-ID: <200303190651.h2J6pXV01517@punik.econ.au.dk>

 | From: "Wang, Hui" <Hui_Wang at affymetrix.com>
 | Date: Tue, 18 Mar 2003 13:20:13 -0800
 | 
 | Hi List,
 | 
 | Could anybody give me some tips on how to free up memory in R(after reaching
 | the limit of allocated memory size)? By removing the object using "rm"
 | doesnot seem help much.

Attaching datasets may take quite a lot memory too.  Look at attach()
and detach().

Ott


From arv at ono.com  Wed Mar 19 08:35:14 2003
From: arv at ono.com (arv@ono.com)
Date: Wed, 19 Mar 2003 08:35:14 +0100
Subject: [R] temperature profiles on maps
Message-ID: <1dc6c71dc2a4.1dc2a41dc6c7@ono.com>

Hi Greg,

Probably you need to look at filled.contour(). I've managed to plot 
similar graphics from netCDF files. If you need some more explanation 
let me know.

Cheers

Antonio Rodr?guez

----- Mensaje Original -----
Remitente: Greg Trafton <trafton at itd.nrl.navy.mil>
Fecha: Martes, Marzo 18, 2003 7:26 pm
Asunto: [R] temperature profiles on maps

> Hi, all.  I'm looking for a way to generate temperature profiles and
> display them in different colors on different maps.  I'm basically
> looking for a way to display simple meteorological graphs using
> different color sets within R.
> 
> Is there a way to do that kind of thing in R?
> 
> failing that, is there any way to create temperature profiles in R?
> 
> thanks!
> greg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From azzalini at stat.unipd.it  Wed Mar 19 10:09:20 2003
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Wed, 19 Mar 2003 10:09:20 +0100
Subject: [R] RMySQL
Message-ID: <20030319090920.3E3F77CA804@tango.stat.unipd.it>


Hi. Could anyone help with the following?

>  library(RMySQL)
Loading required package: methods 
>  handle<-dbDriver("MySQL")
> con<-dbConnect(handle, dbname="echp",  host="tango", user="aa")
Segmentation fault

Some  variants of the above cheme invariably end up with the same conclusion.
The "DBI"  and "RMySQL" packages have compiled correclty, apparently,
when installed.  Here below are system data.

Best wishes,

Adelchi Azzalini


> R.version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.1              
year     2002             
month    11               
day      01               
language R                

-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit? di Padova, Italia
http://azzalini.stat.unipd.it/


From charles at maths.leeds.ac.uk  Wed Mar 19 10:26:37 2003
From: charles at maths.leeds.ac.uk (Charles Taylor)
Date: Wed, 19 Mar 2003 09:26:37 GMT
Subject: [R] postscript problems
Message-ID: <200303190926.JAA19443@lebesgue.leeds.ac.uk>

I am using R-1.6.1 and when I save a figure using

dev.print(file="figure.eps")

and then insert this figure into a LaTeX file (using
\includegraphics and the package graphicx) , the figure 
obscures some nearby text (it gets blanked out by "white").

Comparing the postscript file to that produced by an earlier
version of R I can see the extra lines marked with a star below:



%%Page: 1 1
bp
/bg { 1.0000 1.0000 1.0000 } def  *
0.00 0.00 841.89 595.28 r p2      *
204.83 90.14 318.71 513.85 cl     *
204.83 90.14 318.71 513.85 cl


If I remove these 3 lines by hand the problem disappears, but
surely there is an easier way!?


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Mar 19 10:53:19 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 19 Mar 2003 10:53:19 +0100 (MET)
Subject: [R] Tukey's HSD
In-Reply-To: <5.1.0.14.0.20030318141937.020cfc40@localhost>
Message-ID: <Pine.SOL.3.96.1030319105101.2815A-100000@cssun.rrze.uni-erlangen.de>



On Tue, 18 Mar 2003, Peter B. Mandeville wrote:

> Greetings,
> 
> I am trying the get the standard errors of multiple comparisons using 
> Tukey's HSD. These are not reported by the function TukeyHSD. When I apply 
> the following code to the data, which I store as PROLE4.TXT, several 

sorry, I'm not able to parse the data you copied to the end of your mail.
Could you please send me the text file as attachment and I'll have a look.

best, 

Torsten

> unexpected things happen. First, the function TukeyHSD works for all the 
> comparisons but the function simint doesn't. Second, after the application 
> of na.omit def2$EL and def4$EL report factor values which have been 
> omitted. Please inform me what I am doing wrong. Thank you very much.
> 
> Peter B.
> 
> dat0 <- read.table("prole4.txt",header=T)
> nrow(dat0)
> attach(dat0)
> dat <- 
> data.frame(PRO,GRA,SOL,CEN,LAC,factor(NP),factor(TP),factor(SC),factor(PD),factor(EL))
> names(dat) <- c("PRO","GRA","SOL","CEN","LAC","NP","TP","SC","PD","EL")
> names(dat)
> nrow(dat)
> detach(dat0)
> attach(dat)
> library(multcomp)
> # SEXO (nacimientos sencillos)
> def1 <- data.frame(PRO,GRA,SOL,CEN,LAC,NP,SC,PD,EL)
> def2 <- na.omit(def1)
> nrow(def2)
> res5 <- aov(LAC~NP+SC+PD+EL+NP:SC+NP:PD+NP:EL+SC:PD+SC:EL+PD:EL,data=def2)
> anova(res5)
> res5 <- aov(LAC~NP+SC+PD+EL,data=def2)
> summary(ci <- simint(LAC~NP,data=def2,alternative="two.sided",type="Tukey"))
> summary(ci <- simint(LAC~SC,data=def2,alternative="two.sided",type="Tukey"))
> summary(ci <- simint(LAC~PD,data=def2,alternative="two.sided",type="Tukey"))
> summary(ci <- simint(LAC~EL,data=def2,alternative="two.sided",type="Tukey"))
> TukeyHSD(res5)
> summary(def2)
> # TIPO (sin tomar en cuenta sexo)
> def3 <- data.frame(PRO,GRA,SOL,CEN,LAC,NP,TP,PD,EL)
> def4 <- na.omit(def3)
> nrow(def4)
> res6 <- aov(PRO~NP+TP+PD+EL,data=def4)
> summary(ci <- simint(PRO~NP,data=def4,alternative="two.sided",type="Tukey"))
> summary(ci <- simint(PRO~TP,data=def4,alternative="two.sided",type="Tukey"))
> summary(ci <- simint(PRO~PD,data=def4,alternative="two.sided",type="Tukey"))
> summary(ci <- simint(PRO~EL,data=def4,alternative="two.sided",type="Tukey"))
> TukeyHSD(res6)
> def4$EL
> summary(def4)
> 
> 
> EL	ove	NP	PD	pld	pls	pes	GRA	SOL	CEN	PRO	LAC	TP	NUL0	
> 
> SC	NUL1	NUL2	NUL3	NUL4	NUL5	NJUL6	NUL7	NUL8	NUL9	NUL10	NUL11	NUL12	NUL13	
> 
> NUL14	NUL15	NUL16
> 0	429	3	1	NA	NA	60	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5.8	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	901	3	0	NA	NA	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	939	1	0	NA	NA	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	4.5	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	911	3	0	NA	NA	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5.7	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	932	1	1	NA	NA	49	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	4.8	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	431	3	0	NA	NA	66	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5.6	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	928	1	0	NA	NA	60	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	5.2	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	984	3	1	NA	NA	71	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5.6	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	971	1	1	NA	NA	75	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	5.7	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	967	1	1	NA	NA	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5.5	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	930	1	0	NA	NA	61	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	5.5	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	821	3	1	NA	NA	64	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	3.9	NA	4.5	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	973	1	0	NA	NA	53	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	4.5	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	940	1	1	NA	NA	59	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	4.7	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	902	3	0	NA	NA	69	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5.3	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	424	3	1	NA	NA	72	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	4.9	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	910	3	0	NA	NA	66	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	4.4	NA	4.4	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	943	2	1	NA	NA	68	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	4.2	NA	3.5	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	983	3	1	NA	NA	72	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	4.9	5.2	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	845	3	0	NA	NA	63	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	4.2	NA	4.5	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	942	2	0	NA	NA	76	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	5	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	432	2	0	NA	NA	58	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	3.5	3.1	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	427	1	1	NA	NA	72	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	5.5	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	927	1	0	NA	NA	68	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	4.6	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	969	1	0	NA	NA	58	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	3.8	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	430	1	1	NA	NA	52	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	4.7	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	944	2	1	NA	NA	69	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	4.1	NA	3.6	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	842	3	0	NA	NA	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5.4	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	824	3	1	NA	NA	72	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	4	4.2	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	972	1	1	NA	NA	59	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	4.9	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	907	3	1	NA	NA	72	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	4	4.8	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	933	1	0	NA	NA	77	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	4.7	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	948	2	1	NA	NA	79	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	4.3	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	828	3	0	NA	NA	72	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	5.35	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	950	2	1	NA	NA	72	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	4.95	3.65	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	908	3	1	NA	NA	76	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	4.8	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	935	1	0	NA	NA	62	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5.85	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	946	2	1	NA	NA	60	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.1	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	955	2	0	NA	NA	58	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	4.2	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	881	2	0	NA	NA	66	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	5	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	880	2	1	NA	NA	61	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	5.1	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	993	1	1	NA	NA	55	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	4.9	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	937	1	1	NA	NA	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5.2	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	951	2	1	NA	NA	59	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	5.8	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 0	929	1	0	NA	NA	66	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	4.65	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 1	429	3	1	830	5810	63	7.9	19.0772	0.9633	6.336	4.1440	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.5	NA	NA	NA	1.7	NA	NA	
> 
> NA	242.8571429	NA
> 1	901	3	0	1050	7350	65	5.2	15.6811	0.8985	4.993	4.6280	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.75	NA	NA	NA	1.75	NA	NA	
> 
> NA	250	NA
> 1	939	1	0	910	6370	65	6.5	17.2569	0.9255	5.311	4.7140	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6	NA	NA	NA	1.5	NA	NA	
> 
> NA	214.2857143	NA
> 1	911	3	0	730	5110	62	4.45	16.2733	1.0191	5.6376	4.7886	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.8	NA	NA	NA	1.1	NA	NA	
> 
> NA	157.1428571	NA
> 1	932	1	1	620	4340	47	6.05	17.5768	0.9496	5.21	4.5974	1	NA	
> 
> H	1	NA	NA	NA	5.6	NA	NA	NA	0.8	NA	NA	NA	
> 
> 114.2857143	NA	NA	NA
> 1	431	3	0	1010	7070	68	5.7	16.668	0.9925	4.2638	4.2605	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.75	NA	NA	NA	1.15	NA	NA	
> 
> NA	164.2857143	NA
> 1	928	1	0	620	4340	61	5.3	17.1691	1.0524	5.819	4.4288	1	NA	
> 
> H	1	NA	NA	NA	6.2	NA	NA	NA	1	NA	NA	NA	
> 
> 142.8571429	NA	NA	NA
> 1	984	3	1	1230	8610	70	5.85	16.5224	0.9581	4.8196	4.1933	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.95	NA	NA	NA	1.35	NA	NA	
> 
> NA	192.8571429	NA
> 1	971	1	1	980	6860	75	3.6	14.859	0.9133	4.8452	4.8687	1	NA	
> 
> H	1	NA	NA	NA	6.8	NA	NA	NA	1.1	NA	NA	NA	
> 
> 157.1428571	NA	NA	NA
> 1	967	1	1	590	4130	64	4.35	15.3313	1.0314	5.4273	4.4245	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.25	NA	NA	NA	1.75	NA	NA	
> 
> NA	250	NA
> 1	930	1	0	1030	7210	60	6.5	17.6682	0.9209	4.7378	4.5775	1	NA	
> 
> H	1	NA	NA	NA	6.85	NA	NA	NA	1.35	NA	NA	NA	
> 
> 192.8571429	NA	NA	NA
> 1	821	3	1	840	5880	63	4.7	15.6316	0.9317	4.6632	4.6000	2	2	
> 
> NA	1	NA	1	NA	4.6	NA	5.3	NA	0.7	NA	0.8	NA	100	
> 
> NA	114.2857143	NA
> 1	973	1	0	810	5670	54	4.35	15.5708	0.9512	4.3925	4.4537	1	NA	
> 
> H	1	NA	NA	NA	6.05	NA	NA	NA	1.55	NA	NA	NA	
> 
> 221.4285714	NA	NA	NA
> 1	940	1	1	1090	7630	60	5.8	16.2437	0.8345	4.4947	4.6009	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.45	NA	NA	NA	1.75	NA	NA	
> 
> NA	250	NA
> 1	902	3	0	760	5320	69	4	16.1382	0.9373	5.2997	4.5986	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.85	NA	NA	NA	1.55	NA	NA	
> 
> NA	221.4285714	NA
> 1	424	3	1	1090	7630	76	5.85	17.1757	0.9085	5.6672	4.3849	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.45	NA	NA	NA	1.55	NA	NA	
> 
> NA	221.4285714	NA
> 1	910	3	0	1210	8470	65	3.1	14.4557	0.8932	4.7002	4.8132	2	2	
> 
> NA	1	NA	1	NA	5	NA	5.75	NA	0.6	NA	1.35	NA	
> 
> 85.71428571	NA	192.8571429	NA
> 1	943	2	1	1100	7700	70	3.08	14.6979	0.9272	4.8118	4.5723	2	2	
> 
> NA	1	NA	1	NA	5.25	NA	4.55	NA	1.05	NA	1.05	NA	150	
> 
> NA	150	NA
> 1	983	3	1	1080	7560	75	4.55	15.4898	0.9379	4.9698	4.4378	2	2	
> 
> NA	NA	NA	1	2	NA	NA	5.65	5.9	NA	NA	0.75	0.7	NA	
> 
> NA	107.1428571	100
> 1	845	3	0	1160	8120	68	3.2	14.3972	0.9306	5.2766	4.8183	2	2	
> 
> NA	1	NA	1	NA	5.3	NA	5.45	NA	1.1	NA	0.95	NA	
> 
> 157.1428571	NA	135.7142857	NA
> 1	942	2	0	1140	7980	78	5.4	15.9254	0.8813	5.0543	4.5529	1	NA	
> 
> H	1	NA	NA	NA	6.45	NA	NA	NA	1.45	NA	NA	NA	
> 
> 207.1428571	NA	NA	NA
> 1	432	2	0	900	6300	64	3.6	14.5923	0.9294	4.8429	4.7923	2	2	
> 
> NA	1	2	NA	NA	4.35	3.85	NA	NA	0.85	0.75	NA	NA	
> 
> 121.4285714	107.1428571	NA	NA
> 1	427	1	1	1160	8120	71	5.9	17.3822	0.8706	5.1249	4.8432	1	NA	
> 
> H	1	NA	NA	NA	6.45	NA	NA	NA	0.95	NA	NA	NA	
> 
> 135.7142857	NA	NA	NA
> 1	927	1	0	1040	7280	70	4.4	15.2082	0.9057	5.5637	4.4724	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.85	NA	NA	NA	2.25	NA	NA	
> 
> NA	321.4285714	NA
> 1	969	1	0	1240	8680	58	5.5	16.9229	0.9047	6.0078	4.4780	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5.5	NA	NA	NA	1.7	NA	NA	
> 
> NA	242.8571429	NA
> 1	430	1	1	1060	7420	53	4.95	16.4996	0.9162	6.091	4.5810	1	NA	
> 
> H	1	NA	NA	NA	5.75	NA	NA	NA	1.05	NA	NA	NA	150	
> 
> NA	NA	NA
> 1	944	2	1	1000	7000	64	4.78	15.5751	0.9495	4.939	4.5379	2	2	
> 
> NA	1	NA	1	NA	5.15	NA	4.5	NA	1.05	NA	0.9	NA	150	
> 
> NA	128.5714286	NA
> 1	842	3	0	840	5880	63	4.35	15.9875	0.9588	6.5985	4.7820	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.25	NA	NA	NA	1.85	NA	NA	
> 
> NA	264.2857143	NA
> 1	824	3	1	670	4690	67	9.3	19.635	0.9135	5.7158	4.2071	2	2	
> 
> NA	NA	NA	1	2	NA	NA	4.8	4.8	NA	NA	0.8	0.6	NA	
> 
> NA	114.2857143	85.71428571
> 1	972	1	1	610	4270	57	4.9	16.092	0.9606	5.9049	4.0272	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	5.9	NA	NA	NA	1	NA	NA	
> 
> NA	142.8571429	NA
> 1	907	3	1	660	4620	70	2.175	14.5555	0.9921	5.978	5.0494	2	2	
> 
> NA	1	2	NA	NA	4.8	5.6	NA	NA	0.8	0.8	NA	NA	
> 
> 114.2857143	114.2857143	NA	NA
> 1	933	1	0	1560	10920	75	5.95	16.5261	0.8619	5.1828	4.1857	1	NA	
> 
> H	1	NA	NA	NA	6	NA	NA	NA	1.3	NA	NA	NA	
> 
> 185.7142857	NA	NA	NA
> 1	948	2	1	940	6580	75	3.2	13.6218	0.8953	5.3101	4.0436	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.1	NA	NA	NA	1.8	NA	NA	
> 
> NA	257.1428571	NA
> 1	828	3	0	830	5810	69	3.5	14.8816	1.1364	6.0835	4.4151	1	NA	
> 
> H	1	NA	NA	NA	6.5	NA	NA	NA	1.15	NA	NA	NA	
> 
> 164.2857143	NA	NA	NA
> 1	950	2	1	1230	8610	69	3.35	14.6723	0.9105	4.9111	4.4324	2	2	
> 
> NA	1	2	NA	NA	5.6	4.35	NA	NA	0.65	0.7	NA	NA	
> 
> 92.85714286	100	NA	NA
> 1	908	3	1	590	4130	75	3.65	15.7291	1.0126	5.7469	4.7311	1	NA	
> 
> H	1	NA	NA	NA	6	NA	NA	NA	1.2	NA	NA	NA	
> 
> 171.4285714	NA	NA	NA
> 1	935	1	0	1010	7070	63	3.05	13.5582	0.9083	4.978	4.6294	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.8	NA	NA	NA	0.95	NA	NA	
> 
> NA	135.7142857	NA
> 1	946	2	1	1040	7280	62	2.7	14.1274	0.9088	5.4058	4.8800	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.3	NA	NA	NA	1.2	NA	NA	
> 
> NA	171.4285714	NA
> 1	955	2	0	1030	7210	56	4.65	15.9676	0.9686	5.4131	4.5413	1	NA	
> 
> H	1	NA	NA	NA	5.5	NA	NA	NA	1.3	NA	NA	NA	
> 
> 185.7142857	NA	NA	NA
> 1	881	2	0	1150	8050	63	4.4	15.5641	0.9257	5.1027	4.9923	1	NA	
> 
> H	1	NA	NA	NA	6.85	NA	NA	NA	1.85	NA	NA	NA	
> 
> 264.2857143	NA	NA	NA
> 1	880	2	1	600	4200	61	5.95	16.667	0.9071	5.286	4.5717	1	NA	
> 
> H	1	NA	NA	NA	6.7	NA	NA	NA	1.6	NA	NA	NA	
> 
> 228.5714286	NA	NA	NA
> 1	993	1	1	1040	7280	56	4.45	15.8671	0.9917	5.3033	4.4320	1	NA	
> 
> H	1	NA	NA	NA	6.4	NA	NA	NA	1.5	NA	NA	NA	
> 
> 214.2857143	NA	NA	NA
> 1	937	1	1	620	4340	65	3.65	15.4919	0.9529	5.5597	4.9008	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6	NA	NA	NA	0.8	NA	NA	
> 
> NA	114.2857143	NA
> 1	951	2	1	840	5880	60	2.2	13.9062	0.9501	5.7269	4.9766	1	NA	
> 
> H	1	NA	NA	NA	6.9	NA	NA	NA	1.1	NA	NA	NA	
> 
> 157.1428571	NA	NA	NA
> 1	929	1	0	880	6160	65	5.7	16.6332	0.9504	5.362	4.9691	1	NA	
> 
> H	1	NA	NA	NA	6.1	NA	NA	NA	1.45	NA	NA	NA	
> 
> 207.1428571	NA	NA	NA
> 2	429	3	1	900	6300	61	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10	NA	NA	NA	2.5	NA	NA	
> 
> NA	357.1428571	NA
> 2	901	3	0	1120	7840	64	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	9	NA	NA	NA	2.25	NA	NA	
> 
> NA	321.4285714	NA
> 2	939	1	0	1170	8190	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.85	NA	NA	NA	1.85	NA	NA	
> 
> NA	264.2857143	NA
> 2	911	3	0	990	6930	62	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	9	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 2	932	1	1	730	5110	48	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	7.4	NA	NA	NA	1.8	NA	NA	NA	
> 
> 257.1428571	NA	NA	NA
> 2	431	3	0	1000	7000	66	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	8.75	NA	NA	NA	2	NA	NA	
> 
> NA	285.7142857	NA
> 2	928	1	0	810	5670	60	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	8.3	NA	NA	NA	2.1	NA	NA	NA	300	
> 
> NA	NA	NA
> 2	984	3	1	1020	7140	68	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	9.35	NA	NA	NA	2.4	NA	NA	
> 
> NA	342.8571429	NA
> 2	971	1	1	1170	8190	77	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	8.95	NA	NA	NA	2.15	NA	NA	NA	
> 
> 307.1428571	NA	NA	NA
> 2	967	1	1	370	2590	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.9	NA	NA	NA	0.65	NA	NA	
> 
> NA	92.85714286	NA
> 2	930	1	0	1270	8890	63	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	9.5	NA	NA	NA	2.65	NA	NA	NA	
> 
> 378.5714286	NA	NA	NA
> 2	821	3	1	570	3990	63	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	5.9	NA	6.7	NA	1.3	NA	1.4	NA	
> 
> 185.7142857	NA	200	NA
> 2	973	1	0	1170	8190	53	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	8.35	NA	NA	NA	2.3	NA	NA	NA	
> 
> 328.5714286	NA	NA	NA
> 2	940	1	1	620	4340	58	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.5	NA	NA	NA	0.05	NA	NA	
> 
> NA	7.142857143	NA
> 2	902	3	0	590	4130	69	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.75	NA	NA	NA	-0.1	NA	NA	
> 
> NA	-14.28571429	NA
> 2	424	3	1	1050	7350	70	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	8.7	NA	NA	NA	2.25	NA	NA	
> 
> NA	321.4285714	NA
> 2	910	3	0	1410	9870	62	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	7.1	NA	7.55	NA	2.1	NA	1.8	NA	300	
> 
> NA	257.1428571	NA
> 2	943	2	1	1110	7770	69	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	7.15	NA	6.5	NA	1.9	NA	1.95	NA	
> 
> 271.4285714	NA	278.5714286	NA
> 2	983	3	1	930	6510	70	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	7	7.5	NA	NA	1.35	1.6	NA	
> 
> NA	192.8571429	228.5714286
> 2	845	3	0	750	5250	64	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	6.9	NA	7.2	NA	1.6	NA	1.75	NA	
> 
> 228.5714286	NA	250	NA
> 2	942	2	0	980	6860	75	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	8.8	NA	NA	NA	2.35	NA	NA	NA	
> 
> 335.7142857	NA	NA	NA
> 2	432	2	0	960	6720	63	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	5.8	6.1	NA	NA	1.45	2.25	NA	NA	
> 
> 207.1428571	321.4285714	NA	NA
> 2	427	1	1	1430	10010	72	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	9	NA	NA	NA	2.55	NA	NA	NA	
> 
> 364.2857143	NA	NA	NA
> 2	927	1	0	940	6580	69	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.75	NA	NA	NA	0.9	NA	NA	
> 
> NA	128.5714286	NA
> 2	969	1	0	570	3990	61	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.2	NA	NA	NA	0.7	NA	NA	
> 
> NA	100	NA
> 2	430	1	1	810	5670	52	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	7.5	NA	NA	NA	1.75	NA	NA	NA	250	
> 
> NA	NA	NA
> 2	944	2	1	1040	7280	65	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	6.7	NA	6	NA	1.55	NA	1.5	NA	
> 
> 221.4285714	NA	214.2857143	NA
> 2	842	3	0	680	4760	62	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	8.15	NA	NA	NA	0.9	NA	NA	
> 
> NA	128.5714286	NA
> 2	824	3	1	860	6020	65	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	5.675	5.15	NA	NA	0.875	0.35	NA	
> 
> NA	125	50
> 2	972	1	1	440	3080	55	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	6.15	NA	NA	NA	0.25	NA	NA	
> 
> NA	35.71428571	NA
> 2	907	3	1	610	4270	70	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	6	7.1	NA	NA	1.2	1.5	NA	NA	
> 
> 171.4285714	214.2857143	NA	NA
> 2	933	1	0	780	5460	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	6.7	NA	NA	NA	0.7	NA	NA	NA	100	
> 
> NA	NA	NA
> 2	948	2	1	950	6650	77	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	8.3	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 2	828	3	0	1110	7770	78	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	8.5	NA	NA	NA	2	NA	NA	NA	
> 
> 285.7142857	NA	NA	NA
> 2	950	2	1	1340	9380	71	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	6.5	5.25	NA	NA	0.9	0.9	NA	NA	
> 
> 128.5714286	128.5714286	NA	NA
> 2	908	3	1	780	5460	78	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	7.9	NA	NA	NA	1.9	NA	NA	NA	
> 
> 271.4285714	NA	NA	NA
> 2	935	1	0	990	6930	64	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	8.75	NA	NA	NA	1.95	NA	NA	
> 
> NA	278.5714286	NA
> 2	946	2	1	680	4760	58	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.6	NA	NA	NA	0.3	NA	NA	
> 
> NA	42.85714286	NA
> 2	955	2	0	1340	9380	56	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	7.25	NA	NA	NA	1.75	NA	NA	NA	250	
> 
> NA	NA	NA
> 2	881	2	0	1150	8050	63	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	9	NA	NA	NA	2.15	NA	NA	NA	
> 
> 307.1428571	NA	NA	NA
> 2	880	2	1	950	6650	61	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	9.1	NA	NA	NA	2.4	NA	NA	NA	
> 
> 342.8571429	NA	NA	NA
> 2	993	1	1	1040	7280	54	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	7.9	NA	NA	NA	1.5	NA	NA	NA	
> 
> 214.2857143	NA	NA	NA
> 2	937	1	1	530	3710	64	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.85	NA	NA	NA	1.85	NA	NA	
> 
> NA	264.2857143	NA
> 2	951	2	1	870	6090	57	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	9	NA	NA	NA	2.1	NA	NA	NA	300	
> 
> NA	NA	NA
> 2	929	1	0	880	6160	63	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	7.8	NA	NA	NA	1.7	NA	NA	NA	
> 
> 242.8571429	NA	NA	NA
> 3	429	3	1	860	6020	62	7	17.7976	0.956	5.3892	4.4035	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	12.6	NA	NA	NA	2.6	NA	NA	
> 
> NA	371.4285714	NA
> 3	901	3	0	1190	8330	65	5.6	15.591	0.9374	4.7194	4.3281	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	11.2	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 3	939	1	0	1140	7980	65	9.2	19.1892	0.9486	4.5073	4.3879	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	9.75	NA	NA	NA	1.9	NA	NA	
> 
> NA	271.4285714	NA
> 3	911	3	0	950	6650	61	4.85	16.0773	0.9968	5.2862	4.5513	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	11	NA	NA	NA	2	NA	NA	
> 
> NA	285.7142857	NA
> 3	932	1	1	520	3640	47	4.4	15.458	0.937	4.8687	4.8308	1	NA	
> 
> H	1	NA	NA	NA	8.9	NA	NA	NA	1.5	NA	NA	NA	
> 
> 214.2857143	NA	NA	NA
> 3	431	3	0	970	6790	67	6.55	17.9977	0.982	5.4131	4.5395	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10.4	NA	NA	NA	1.65	NA	NA	
> 
> NA	235.7142857	NA
> 3	928	1	0	1060	7420	60	2.95	14.7257	0.9423	4.8435	5.0909	1	NA	
> 
> H	1	NA	NA	NA	10.35	NA	NA	NA	2.05	NA	NA	NA	
> 
> 292.8571429	NA	NA	NA
> 3	984	3	1	1250	8750	71	4.95	16.2411	0.9724	4.7976	4.2909	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	11.3	NA	NA	NA	1.95	NA	NA	
> 
> NA	278.5714286	NA
> 3	971	1	1	1240	8680	75	2.85	13.626	0.8832	4.7437	4.9090	1	NA	
> 
> H	1	NA	NA	NA	11	NA	NA	NA	2.05	NA	NA	NA	
> 
> 292.8571429	NA	NA	NA
> 3	967	1	1	610	4270	66	4.95	16.3346	1.2042	6.7383	3.4654	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10.2	NA	NA	NA	2.3	NA	NA	
> 
> NA	328.5714286	NA
> 3	930	1	0	1170	8190	61	4.35	15.5872	0.8856	4.9457	5.4037	1	NA	
> 
> H	1	NA	NA	NA	11.8	NA	NA	NA	2.3	NA	NA	NA	
> 
> 328.5714286	NA	NA	NA
> 3	821	3	1	660	4620	60	5	16.8527	0.8861	5.3297	5.0295	2	2	
> 
> NA	1	NA	1	NA	7	NA	7.9	NA	1.1	NA	1.2	NA	
> 
> 157.1428571	NA	171.4285714	NA
> 3	973	1	0	1110	7770	55	3.35	13.7739	0.9647	4.7053	4.7780	1	NA	
> 
> H	1	NA	NA	NA	10.7	NA	NA	NA	2.35	NA	NA	NA	
> 
> 335.7142857	NA	NA	NA
> 3	940	1	1	620	4340	62	5.2	16.1314	0.86	5.3345	4.7606	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.85	NA	NA	NA	1.35	NA	NA	
> 
> NA	192.8571429	NA
> 3	902	3	0	340	2380	69	5.4	16.6801	0.9767	5.7431	4.6088	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.5	NA	NA	NA	0.75	NA	NA	
> 
> NA	107.1428571	NA
> 3	424	3	1	1350	9450	72	5.2	15.9619	0.9222	5.6713	4.4370	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10.8	NA	NA	NA	2.1	NA	NA	
> 
> NA	300	NA
> 3	910	3	0	1550	10850	60	3.4	13.6954	0.8531	4.6495	4.7654	2	2	
> 
> NA	1	NA	1	NA	9.6	NA	9.4	NA	2.5	NA	1.85	NA	
> 
> 357.1428571	NA	264.2857143	NA
> 3	943	2	1	1070	7490	69	2.2	12.8268	0.8907	4.703	4.6222	2	2	
> 
> NA	1	NA	1	NA	8.2	NA	8.9	NA	1.05	NA	2.4	NA	150	
> 
> NA	342.8571429	NA
> 3	983	3	1	1250	8750	68	4.6	15.6929	0.8693	5.2363	4.7671	2	2	
> 
> NA	NA	NA	1	2	NA	NA	9	9.8	NA	NA	2	2.3	NA	
> 
> NA	285.7142857	328.5714286
> 3	845	3	0	1300	9100	67	3.5	14.3058	0.8882	4.9715	5.1609	2	2	
> 
> NA	1	NA	1	NA	8.5	NA	9	NA	1.6	NA	1.8	NA	
> 
> 228.5714286	NA	257.1428571	NA
> 3	942	2	0	1330	9310	79	4.2	14.8591	0.8411	4.7502	4.7516	1	NA	
> 
> H	1	NA	NA	NA	11.8	NA	NA	NA	3	NA	NA	NA	
> 
> 428.5714286	NA	NA	NA
> 3	432	2	0	840	5880	62	3.35	12.9283	0.9263	4.3896	4.4326	2	2	
> 
> NA	1	2	NA	NA	7	6.1	NA	NA	1.2	0	NA	NA	
> 
> 171.4285714	0	NA	NA
> 3	427	1	1	1600	11200	72	3.5	13.9122	0.8883	4.7642	4.8212	1	NA	
> 
> H	1	NA	NA	NA	11.4	NA	NA	NA	2.4	NA	NA	NA	
> 
> 342.8571429	NA	NA	NA
> 3	927	1	0	1090	7630	71	6.05	16.7539	0.8757	5.0501	4.9403	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	9.5	NA	NA	NA	1.75	NA	NA	
> 
> NA	250	NA
> 3	969	1	0	1140	7980	60	7.05	17.7921	0.89396	5.4955	4.6257	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	8.2	NA	NA	NA	2	NA	NA	
> 
> NA	285.7142857	NA
> 3	430	1	1	1050	7350	53	4.8	15.8801	0.9037	5.3402	4.9923	1	NA	
> 
> H	1	NA	NA	NA	9.35	NA	NA	NA	1.85	NA	NA	NA	
> 
> 264.2857143	NA	NA	NA
> 3	944	2	1	1130	7910	63	3.75	14.4299	0.8831	4.7073	4.8568	2	2	
> 
> NA	1	NA	1	NA	8.1	NA	7.2	NA	1.4	NA	1.2	NA	200	
> 
> NA	171.4285714	NA
> 3	842	3	0	1060	7420	65	5.8	16.8265	0.8622	5.1499	5.0847	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10.4	NA	NA	NA	2.25	NA	NA	
> 
> NA	321.4285714	NA
> 3	824	3	1	850	5950	66	7.5	17.6537	0.8641	5.1453	4.1440	2	2	
> 
> NA	NA	NA	1	2	NA	NA	6.85	6.3	NA	NA	1.175	1.15	NA	
> 
> NA	167.8571429	164.2857143
> 3	972	1	1	600	4200	59	5.95	16.3922	0.9777	5.5579	4.0210	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	7.1	NA	NA	NA	0.95	NA	NA	
> 
> NA	135.7142857	NA
> 3	907	3	1	370	2590	68	3.9	15.419	0.9485	5.5041	4.8418	2	2	
> 
> NA	1	2	NA	NA	7.05	8.25	NA	NA	1.05	1.15	NA	NA	150	
> 
> 164.2857143	NA	NA
> 3	933	1	0	830	5810	74	6.45	16.9218	0.8681	5.2265	5.3864	1	NA	
> 
> H	1	NA	NA	NA	7.85	NA	NA	NA	1.15	NA	NA	NA	
> 
> 164.2857143	NA	NA	NA
> 3	948	2	1	980	6860	74	2.58	13.0917	0.9296	4.7829	4.8722	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10.5	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 3	828	3	0	1050	7350	75	2.75	13.9027	0.9414	5.6133	4.4709	1	NA	
> 
> H	1	NA	NA	NA	10.7	NA	NA	NA	2.2	NA	NA	NA	
> 
> 314.2857143	NA	NA	NA
> 3	950	2	1	1170	8190	68	3.35	13.9495	0.8313	4.69	4.7855	2	2	
> 
> NA	1	2	NA	NA	7.85	6.2	NA	NA	1.35	0.95	NA	NA	
> 
> 192.8571429	135.7142857	NA	NA
> 3	908	3	1	750	5250	75	2.65	14.4253	0.9624	5.173	4.7469	1	NA	
> 
> H	1	NA	NA	NA	10.15	NA	NA	NA	2.25	NA	NA	NA	
> 
> 321.4285714	NA	NA	NA
> 3	935	1	0	1150	8050	67	2.4	13.0541	0.8498	5.0126	4.0403	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	11.1	NA	NA	NA	2.35	NA	NA	
> 
> NA	335.7142857	NA
> 3	946	2	1	1070	7490	61	3.35	14.3247	1.2582	5.309	4.6039	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10	NA	NA	NA	2.4	NA	NA	
> 
> NA	342.8571429	NA
> 3	955	2	0	1080	7560	55	4.83	15.9277	0.9109	5.271	4.7770	1	NA	
> 
> H	1	NA	NA	NA	8.85	NA	NA	NA	1.6	NA	NA	NA	
> 
> 228.5714286	NA	NA	NA
> 3	881	2	0	1300	9100	62	4.55	15.6193	0.9223	5.1887	4.5059	1	NA	
> 
> H	1	NA	NA	NA	11	NA	NA	NA	2	NA	NA	NA	
> 
> 285.7142857	NA	NA	NA
> 3	880	2	1	960	6720	58	5	16.7463	0.9113	5.3744	4.8342	1	NA	
> 
> H	1	NA	NA	NA	11.4	NA	NA	NA	2.3	NA	NA	NA	
> 
> 328.5714286	NA	NA	NA
> 3	993	1	1	1170	8190	53	4.75	15.4019	0.8642	4.8863	4.6721	1	NA	
> 
> H	1	NA	NA	NA	10	NA	NA	NA	2.1	NA	NA	NA	300	
> 
> NA	NA	NA
> 3	937	1	1	610	4270	61	3.45	14.3967	0.8454	5.0849	4.7918	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10.2	NA	NA	NA	2.35	NA	NA	
> 
> NA	335.7142857	NA
> 3	951	2	1	870	6090	57	3.8	15.1248	0.8971	5.2255	4.4212	1	NA	
> 
> H	1	NA	NA	NA	11.2	NA	NA	NA	2.2	NA	NA	NA	
> 
> 314.2857143	NA	NA	NA
> 3	929	1	0	800	5600	61	5	16.1549	0.8877	4.777	4.8643	1	NA	
> 
> H	1	NA	NA	NA	11.6	NA	NA	NA	3.8	NA	NA	NA	
> 
> 542.8571429	NA	NA	NA
> 4	429	3	1	860	6020	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15.2	NA	NA	NA	2.6	NA	NA	
> 
> NA	371.4285714	NA
> 4	901	3	0	1240	8680	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	13.7	NA	NA	NA	2.5	NA	NA	
> 
> NA	357.1428571	NA
> 4	939	1	0	1240	8680	66	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	12.2	NA	NA	NA	2.45	NA	NA	
> 
> NA	350	NA
> 4	911	3	0	870	6090	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	14.8	NA	NA	NA	3.8	NA	NA	
> 
> NA	542.8571429	NA
> 4	932	1	1	460	3220	46	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	12.2	NA	NA	NA	3.3	NA	NA	NA	
> 
> 471.4285714	NA	NA	NA
> 4	431	3	0	890	6230	72	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	13.6	NA	NA	NA	3.2	NA	NA	
> 
> NA	457.1428571	NA
> 4	928	1	0	850	5950	64	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	13.2	NA	NA	NA	2.85	NA	NA	NA	
> 
> 407.1428571	NA	NA	NA
> 4	984	3	1	1240	8680	74	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	14.6	NA	NA	NA	3.3	NA	NA	
> 
> NA	471.4285714	NA
> 4	971	1	1	1130	7910	82	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	13.8	NA	NA	NA	2.8	NA	NA	NA	400	
> 
> NA	NA	NA
> 4	967	1	1	730	5110	68	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	13.4	NA	NA	NA	3.2	NA	NA	
> 
> NA	457.1428571	NA
> 4	930	1	0	1290	9030	64	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	14.8	NA	NA	NA	3	NA	NA	NA	
> 
> 428.5714286	NA	NA	NA
> 4	821	3	1	560	3920	57	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	8.1	NA	8.9	NA	1.1	NA	1	NA	
> 
> 157.1428571	NA	142.8571429	NA
> 4	973	1	0	1360	9520	57	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	12.6	NA	NA	NA	1.9	NA	NA	NA	
> 
> 271.4285714	NA	NA	NA
> 4	940	1	1	760	5320	59	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	9.15	NA	NA	NA	1.3	NA	NA	
> 
> NA	185.7142857	NA
> 4	902	3	0	770	5390	71	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	8.7	NA	NA	NA	1.2	NA	NA	
> 
> NA	171.4285714	NA
> 4	424	3	1	1010	7070	69	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	13.1	NA	NA	NA	2.3	NA	NA	
> 
> NA	328.5714286	NA
> 4	910	3	0	1470	10290	59	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	11.3	NA	10.5	NA	1.7	NA	1.1	NA	
> 
> 242.8571429	NA	157.1428571	NA
> 4	943	2	1	1100	7700	67	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	10.6	NA	10.2	NA	2.4	NA	1.3	NA	
> 
> 342.8571429	NA	185.7142857	NA
> 4	983	3	1	1560	10920	70	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	10.8	11.2	NA	NA	1.8	1.4	NA	
> 
> NA	257.1428571	200
> 4	845	3	0	1280	8960	65	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	11	NA	11.2	NA	2.5	NA	2.2	NA	
> 
> 357.1428571	NA	314.2857143	NA
> 4	942	2	0	1220	8540	78	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	14	NA	NA	NA	2.2	NA	NA	NA	
> 
> 314.2857143	NA	NA	NA
> 4	432	2	0	860	6020	60	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	8.4	7.6	NA	NA	1.4	1.5	NA	NA	200	
> 
> 214.2857143	NA	NA
> 4	427	1	1	1480	10360	70	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	14.4	NA	NA	NA	3	NA	NA	NA	
> 
> 428.5714286	NA	NA	NA
> 4	927	1	0	1050	7350	69	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	11.8	NA	NA	NA	2.3	NA	NA	
> 
> NA	328.5714286	NA
> 4	969	1	0	1310	9170	60	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10.8	NA	NA	NA	2.6	NA	NA	
> 
> NA	371.4285714	NA
> 4	430	1	1	1040	7280	52	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	11.7	NA	NA	NA	2.35	NA	NA	NA	
> 
> 335.7142857	NA	NA	NA
> 4	944	2	1	980	6860	61	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	9.7	NA	9	NA	1.6	NA	1.8	NA	
> 
> 228.5714286	NA	257.1428571	NA
> 4	842	3	0	970	6790	61	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	12.6	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 4	824	3	1	870	6090	62	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	8.7	8.1	NA	NA	1.85	1.8	NA	
> 
> NA	264.2857143	257.1428571
> 4	972	1	1	670	4690	56	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	9.2	NA	NA	NA	2.1	NA	NA	
> 
> NA	300	NA
> 4	907	3	1	510	3570	64	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	8.3	8.9	NA	NA	1.25	0.65	NA	NA	
> 
> 178.5714286	92.85714286	NA	NA
> 4	933	1	0	700	4900	72	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	10.2	NA	NA	NA	2.35	NA	NA	NA	
> 
> 335.7142857	NA	NA	NA
> 4	948	2	1	950	6650	74	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	12.6	NA	NA	NA	2.1	NA	NA	
> 
> NA	300	NA
> 4	828	3	0	1200	8400	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	13.3	NA	NA	NA	2.6	NA	NA	NA	
> 
> 371.4285714	NA	NA	NA
> 4	950	2	1	1130	7910	69	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	9.8	7.8	NA	NA	1.95	1.6	NA	NA	
> 
> 278.5714286	228.5714286	NA	NA
> 4	908	3	1	920	6440	76	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	12.2	NA	NA	NA	2.05	NA	NA	NA	
> 
> 292.8571429	NA	NA	NA
> 4	935	1	0	1000	7000	66	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	12.9	NA	NA	NA	1.8	NA	NA	
> 
> NA	257.1428571	NA
> 4	946	2	1	1220	8540	62	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	12.7	NA	NA	NA	2.7	NA	NA	
> 
> NA	385.7142857	NA
> 4	955	2	0	900	6300	54	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	10.7	NA	NA	NA	1.85	NA	NA	NA	
> 
> 264.2857143	NA	NA	NA
> 4	881	2	0	1160	8120	61	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	13	NA	NA	NA	2	NA	NA	NA	
> 
> 285.7142857	NA	NA	NA
> 4	880	2	1	1040	7280	59	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	13.5	NA	NA	NA	2.1	NA	NA	NA	300	
> 
> NA	NA	NA
> 4	993	1	1	1110	7770	53	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	12.4	NA	NA	NA	2.4	NA	NA	NA	
> 
> 342.8571429	NA	NA	NA
> 4	937	1	1	930	6510	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	12.7	NA	NA	NA	2.5	NA	NA	
> 
> NA	357.1428571	NA
> 4	951	2	1	1030	7210	57	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	13.5	NA	NA	NA	2.3	NA	NA	NA	
> 
> 328.5714286	NA	NA	NA
> 4	929	1	0	670	4690	59	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	11.6	NA	NA	NA	0	NA	NA	NA	0	
> 
> NA	NA	NA
> 5	429	3	1	860	6020	60	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16.8	NA	NA	NA	1.6	NA	NA	
> 
> NA	228.5714286	NA
> 5	901	3	0	1530	10710	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15	NA	NA	NA	1.3	NA	NA	
> 
> NA	185.7142857	NA
> 5	939	1	0	1030	7210	66	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	13.8	NA	NA	NA	1.6	NA	NA	
> 
> NA	228.5714286	NA
> 5	911	3	0	1020	7140	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16	NA	NA	NA	1.2	NA	NA	
> 
> NA	171.4285714	NA
> 5	932	1	1	690	4830	47	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	13	NA	NA	NA	0.8	NA	NA	NA	
> 
> 114.2857143	NA	NA	NA
> 5	431	3	0	880	6160	71	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15.3	NA	NA	NA	1.7	NA	NA	
> 
> NA	242.8571429	NA
> 5	928	1	0	1000	7000	66	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	14.6	NA	NA	NA	1.4	NA	NA	NA	200	
> 
> NA	NA	NA
> 5	984	3	1	1300	9100	75	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15.7	NA	NA	NA	1.1	NA	NA	
> 
> NA	157.1428571	NA
> 5	971	1	1	1100	7700	81	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	15.4	NA	NA	NA	1.6	NA	NA	NA	
> 
> 228.5714286	NA	NA	NA
> 5	967	1	1	650	4550	68	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	14.2	NA	NA	NA	0.8	NA	NA	
> 
> NA	114.2857143	NA
> 5	930	1	0	1260	8820	66	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	17.2	NA	NA	NA	2.4	NA	NA	NA	
> 
> 342.8571429	NA	NA	NA
> 5	821	3	1	720	5040	58	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	9.5	NA	11.1	NA	1.4	NA	2.2	NA	200	
> 
> NA	314.2857143	NA
> 5	973	1	0	940	6580	55	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	14.7	NA	NA	NA	2.1	NA	NA	NA	300	
> 
> NA	NA	NA
> 5	940	1	1	910	6370	58	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10.7	NA	NA	NA	1.55	NA	NA	
> 
> NA	221.4285714	NA
> 5	902	3	0	580	4060	70	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10.6	NA	NA	NA	1.9	NA	NA	
> 
> NA	271.4285714	NA
> 5	424	3	1	920	6440	69	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15.4	NA	NA	NA	2.3	NA	NA	
> 
> NA	328.5714286	NA
> 5	910	3	0	1180	8260	59	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	12.4	NA	12	NA	1.1	NA	1.5	NA	
> 
> 157.1428571	NA	214.2857143	NA
> 5	943	2	1	1050	7350	68	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	12.5	NA	12.8	NA	1.9	NA	2.6	NA	
> 
> 271.4285714	NA	371.4285714	NA
> 5	983	3	1	1490	10430	72	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	12.7	13.1	NA	NA	1.9	1.9	NA	
> 
> NA	271.4285714	271.4285714
> 5	845	3	0	1290	9030	66	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	12.7	NA	12.1	NA	1.7	NA	0.9	NA	
> 
> 242.8571429	NA	128.5714286	NA
> 5	942	2	0	1470	10290	77	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	16.6	NA	NA	NA	2.6	NA	NA	NA	
> 
> 371.4285714	NA	NA	NA
> 5	432	2	0	1150	8050	59	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	10.4	9.5	NA	NA	2	1.9	NA	NA	
> 
> 285.7142857	271.4285714	NA	NA
> 5	427	1	1	1370	9590	71	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	16.9	NA	NA	NA	2.5	NA	NA	NA	
> 
> 357.1428571	NA	NA	NA
> 5	927	1	0	1110	7770	72	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	14	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 5	969	1	0	1170	8190	60	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	13.1	NA	NA	NA	2.3	NA	NA	
> 
> NA	328.5714286	NA
> 5	430	1	1	1100	7700	53	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	13.4	NA	NA	NA	1.7	NA	NA	NA	
> 
> 242.8571429	NA	NA	NA
> 5	944	2	1	1000	7000	62	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	10.9	NA	10.5	NA	1.2	NA	1.5	NA	
> 
> 171.4285714	NA	214.2857143	NA
> 5	842	3	0	1190	8330	64	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15.9	NA	NA	NA	3.3	NA	NA	
> 
> NA	471.4285714	NA
> 5	824	3	1	910	6370	63	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	10.2	9.9	NA	NA	1.5	1.8	NA	
> 
> NA	214.2857143	257.1428571
> 5	972	1	1	860	6020	58	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	10.8	NA	NA	NA	1.6	NA	NA	
> 
> NA	228.5714286	NA
> 5	907	3	1	540	3780	64	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	8.9	12.4	NA	NA	0.6	3.5	NA	NA	
> 
> 85.71428571	500	NA	NA
> 5	933	1	0	970	6790	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	10.8	NA	NA	NA	0.6	NA	NA	NA	
> 
> 85.71428571	NA	NA	NA
> 5	948	2	1	920	6440	71	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15.2	NA	NA	NA	2.6	NA	NA	
> 
> NA	371.4285714	NA
> 5	828	3	0	1300	9100	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	16.1	NA	NA	NA	2.8	NA	NA	NA	400	
> 
> NA	NA	NA
> 5	950	2	1	1280	8960	67	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	11.8	9.4	NA	NA	2	1.6	NA	NA	
> 
> 285.7142857	228.5714286	NA	NA
> 5	908	3	1	780	5460	74	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	14.7	NA	NA	NA	2.5	NA	NA	NA	
> 
> 357.1428571	NA	NA	NA
> 5	935	1	0	840	5880	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16.1	NA	NA	NA	3.2	NA	NA	
> 
> NA	457.1428571	NA
> 5	946	2	1	1190	8330	61	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15.4	NA	NA	NA	2.7	NA	NA	
> 
> NA	385.7142857	NA
> 5	955	2	0	780	5460	53	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	12.7	NA	NA	NA	2	NA	NA	NA	
> 
> 285.7142857	NA	NA	NA
> 5	881	2	0	940	6580	60	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	15.6	NA	NA	NA	2.6	NA	NA	NA	
> 
> 371.4285714	NA	NA	NA
> 5	880	2	1	970	6790	59	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	16	NA	NA	NA	2.5	NA	NA	NA	
> 
> 357.1428571	NA	NA	NA
> 5	993	1	1	910	6370	51	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	13.4	NA	NA	NA	1	NA	NA	NA	
> 
> 142.8571429	NA	NA	NA
> 5	937	1	1	520	3640	61	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	14.8	NA	NA	NA	2.1	NA	NA	
> 
> NA	300	NA
> 5	951	2	1	980	6860	59	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	15	NA	NA	NA	1.5	NA	NA	NA	
> 
> 214.2857143	NA	NA	NA
> 5	929	1	0	570	3990	59	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	12.6	NA	NA	NA	1	NA	NA	NA	
> 
> 142.8571429	NA	NA	NA
> 6	429	3	1	660	4620	62	5.05	16.9774	0.9746	5.5998	4.5458	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	19.4	NA	NA	NA	2.6	NA	NA	
> 
> NA	371.4285714	NA
> 6	901	3	0	1000	7000	66	4.55	15.4437	0.9935	5.1693	4.8502	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18	NA	NA	NA	3	NA	NA	
> 
> NA	428.5714286	NA
> 6	939	1	0	1060	7420	64	6.1	16.7385	0.9602	4.7581	4.3109	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16.5	NA	NA	NA	2.7	NA	NA	
> 
> NA	385.7142857	NA
> 6	911	3	0	710	4970	63	5.2	17.2575	0.9877	5.3961	4.8169	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.5	NA	NA	NA	2.5	NA	NA	
> 
> NA	357.1428571	NA
> 6	932	1	1	650	4550	46	5.5	16.7657	0.9098	5.1846	4.5115	1	NA	
> 
> H	1	NA	NA	NA	15.3	NA	NA	NA	2.3	NA	NA	NA	
> 
> 328.5714286	NA	NA	NA
> 6	431	3	0	950	6650	70	6.88	18.5071	0.985	5.4229	4.4153	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	17.6	NA	NA	NA	2.3	NA	NA	
> 
> NA	328.5714286	NA
> 6	928	1	0	710	4970	64	1.9	13.9556	0.9558	5.1012	5.0358	1	NA	
> 
> H	1	NA	NA	NA	16.2	NA	NA	NA	1.6	NA	NA	NA	
> 
> 228.5714286	NA	NA	NA
> 6	984	3	1	970	6790	73	4.85	15.9945	0.9295	4.986	4.7362	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	19.3	NA	NA	NA	3.6	NA	NA	
> 
> NA	514.2857143	NA
> 6	971	1	1	940	6580	80	2.2	13.0615	0.8875	4.6825	4.7745	1	NA	
> 
> H	1	NA	NA	NA	16.9	NA	NA	NA	1.5	NA	NA	NA	
> 
> 214.2857143	NA	NA	NA
> 6	967	1	1	530	3710	65	2.4	14.3946	0.9388	5.4192	4.9133	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15.8	NA	NA	NA	1.6	NA	NA	
> 
> NA	228.5714286	NA
> 6	930	1	0	1130	7910	66	4.4	15.964	0.9347	4.934	5.0291	1	NA	
> 
> H	1	NA	NA	NA	18.9	NA	NA	NA	1.7	NA	NA	NA	
> 
> 242.8571429	NA	NA	NA
> 6	821	3	1	510	3570	58	6.6	17.8747	0.881	4.9772	4.3771	2	2	
> 
> NA	1	NA	1	NA	11.3	NA	13.2	NA	1.8	NA	2.1	NA	
> 
> 257.1428571	NA	300	NA
> 6	973	1	0	1300	9100	54	5.1	15.3135	0.9908	4.617	4.6014	1	NA	
> 
> H	1	NA	NA	NA	17	NA	NA	NA	2.3	NA	NA	NA	
> 
> 328.5714286	NA	NA	NA
> 6	940	1	1	810	5670	59	7.15	18.0143	0.8136	4.7798	4.4476	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	13	NA	NA	NA	2.3	NA	NA	
> 
> NA	328.5714286	NA
> 6	902	3	0	670	4690	73	4.85	15.7197	0.92	4.8689	4.6200	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	13	NA	NA	NA	2.4	NA	NA	
> 
> NA	342.8571429	NA
> 6	424	3	1	1030	7210	67	7.5	18.0128	0.8064	5.6256	4.5920	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.6	NA	NA	NA	3.2	NA	NA	
> 
> NA	457.1428571	NA
> 6	910	3	0	1400	9800	57	4.4	13.8194	0.8946	4.6384	4.1078	2	2	
> 
> NA	1	NA	1	NA	14.3	NA	13.8	NA	1.9	NA	1.8	NA	
> 
> 271.4285714	NA	257.1428571	NA
> 6	943	2	1	1110	7770	67	2.9	13.8548	0.8571	5.0391	4.7372	2	2	
> 
> NA	1	NA	1	NA	14.6	NA	14.6	NA	2.1	NA	1.8	NA	300	
> 
> NA	257.1428571	NA
> 6	983	3	1	1440	10080	73	4.55	15.8253	0.8652	5.1691	4.4592	2	2	
> 
> NA	NA	NA	1	2	NA	NA	14.9	15.2	NA	NA	2.2	2.1	NA	
> 
> NA	314.2857143	300
> 6	845	3	0	1450	10150	62	4.3	15.5403	0.8624	4.9112	4.9429	2	2	
> 
> NA	1	NA	1	NA	14.6	NA	14.5	NA	1.9	NA	2.4	NA	
> 
> 271.4285714	NA	342.8571429	NA
> 6	942	2	0	1290	9030	76	5	15.7011	0.8825	4.2987	4.6454	1	NA	
> 
> H	1	NA	NA	NA	18.8	NA	NA	NA	2.2	NA	NA	NA	
> 
> 314.2857143	NA	NA	NA
> 6	432	2	0	850	5950	61	4	14.3549	0.8557	4.1283	4.6591	2	2	
> 
> NA	1	2	NA	NA	12	10.6	NA	NA	1.6	1.1	NA	NA	
> 
> 228.5714286	157.1428571	NA	NA
> 6	427	1	1	1250	8750	72	3.95	14.4881	0.8486	4.5507	4.8020	1	NA	
> 
> H	1	NA	NA	NA	18.8	NA	NA	NA	1.9	NA	NA	NA	
> 
> 271.4285714	NA	NA	NA
> 6	927	1	0	830	5810	68	3.1	13.8521	0.8392	4.668	5.0914	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16.5	NA	NA	NA	2.5	NA	NA	
> 
> NA	357.1428571	NA
> 6	969	1	0	1030	7210	59	4.4	15.2993	0.8705	4.8931	4.5359	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15	NA	NA	NA	1.9	NA	NA	
> 
> NA	271.4285714	NA
> 6	430	1	1	850	5950	51	4	15.5964	0.9378	5.3157	4.6998	1	NA	
> 
> H	1	NA	NA	NA	15.7	NA	NA	NA	2.3	NA	NA	NA	
> 
> 328.5714286	NA	NA	NA
> 6	944	2	1	880	6160	62	5.2	16.6809	0.9457	5.4364	4.8765	2	2	
> 
> NA	1	NA	1	NA	12.2	NA	13	NA	1.3	NA	2.5	NA	
> 
> 185.7142857	NA	357.1428571	NA
> 6	842	3	0	1100	7700	65	6.75	17.9719	0.8244	5.0104	4.5160	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.8	NA	NA	NA	2.9	NA	NA	
> 
> NA	414.2857143	NA
> 6	824	3	1	900	6300	64	8.3	18.8525	0.9206	5.2981	3.9821	2	2	
> 
> NA	NA	NA	1	2	NA	NA	11.8	11.2	NA	NA	1.6	1.3	NA	
> 
> NA	228.5714286	185.7142857
> 6	972	1	1	860	6020	60	5.18	16.0795	0.8499	4.8398	4.2259	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	13	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 6	907	3	1	470	3290	62	3	15.3783	0.9116	5.3246	5.3549	2	2	
> 
> NA	1	2	NA	NA	10	13.8	NA	NA	1.1	1.4	NA	NA	
> 
> 157.1428571	200	NA	NA
> 6	933	1	0	1270	8890	73	7.9	19.2105	1.0045	5.4256	3.8112	1	NA	
> 
> H	1	NA	NA	NA	12.2	NA	NA	NA	1.4	NA	NA	NA	200	
> 
> NA	NA	NA
> 6	948	2	1	880	6160	74	3.65	14.0899	0.8594	4.9583	4.1550	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	17.5	NA	NA	NA	2.3	NA	NA	
> 
> NA	328.5714286	NA
> 6	828	3	0	1120	7840	75	4	14.9827	0.8794	5.1715	4.1542	1	NA	
> 
> H	1	NA	NA	NA	18	NA	NA	NA	1.9	NA	NA	NA	
> 
> 271.4285714	NA	NA	NA
> 6	950	2	1	1100	7700	71	5.4	15.9338	0.817	5.1472	4.3952	2	2	
> 
> NA	1	2	NA	NA	13.3	11.1	NA	NA	1.5	1.7	NA	NA	
> 
> 214.2857143	242.8571429	NA	NA
> 6	908	3	1	840	5880	76	2.95	14.7587	0.9408	5.4155	4.4787	1	NA	
> 
> H	1	NA	NA	NA	16.4	NA	NA	NA	1.7	NA	NA	NA	
> 
> 242.8571429	NA	NA	NA
> 6	935	1	0	1030	7210	66	6.5	17.1533	0.7878	4.8197	5.1471	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.2	NA	NA	NA	2.1	NA	NA	
> 
> NA	300	NA
> 6	946	2	1	1270	8890	63	3.5	14.6398	0.8345	5.5628	4.1129	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18	NA	NA	NA	2.6	NA	NA	
> 
> NA	371.4285714	NA
> 6	955	2	0	660	4620	53	5.1	16.924	1.1593	5.7368	4.5981	1	NA	
> 
> H	1	NA	NA	NA	14.6	NA	NA	NA	1.9	NA	NA	NA	
> 
> 271.4285714	NA	NA	NA
> 6	881	2	0	970	6790	63	4	13.4816	0.8876	4.9474	4.6631	1	NA	
> 
> H	1	NA	NA	NA	17.4	NA	NA	NA	1.8	NA	NA	NA	
> 
> 257.1428571	NA	NA	NA
> 6	880	2	1	1150	8050	59	4.15	15.9467	0.8998	5.2735	4.5117	1	NA	
> 
> H	1	NA	NA	NA	17.5	NA	NA	NA	1.5	NA	NA	NA	
> 
> 214.2857143	NA	NA	NA
> 6	993	1	1	640	4480	51	5.7	16.3382	0.8542	4.8081	4.9576	1	NA	
> 
> H	1	NA	NA	NA	15	NA	NA	NA	1.6	NA	NA	NA	
> 
> 228.5714286	NA	NA	NA
> 6	937	1	1	900	6300	61	2.58	13.4489	0.8486	4.6395	5.2953	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16.8	NA	NA	NA	2	NA	NA	
> 
> NA	285.7142857	NA
> 6	951	2	1	930	6510	58	2.93	14.4347	0.9221	5.2961	5.1234	1	NA	
> 
> H	1	NA	NA	NA	15.4	NA	NA	NA	0.4	NA	NA	NA	
> 
> 57.14285714	NA	NA	NA
> 6	929	1	0	760	5320	57	6.7	17.3978	0.9096	5.4418	4.6569	1	NA	
> 
> H	1	NA	NA	NA	14	NA	NA	NA	1.4	NA	NA	NA	200	
> 
> NA	NA	NA
> 7	429	3	1	1020	7140	66	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22	NA	NA	NA	2.6	NA	NA	
> 
> NA	371.4285714	NA
> 7	901	3	0	1160	8120	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18	NA	NA	NA	0	NA	NA	
> 
> NA	0	NA
> 7	939	1	0	1080	7560	64	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16.5	NA	NA	NA	0	NA	NA	
> 
> NA	0	NA
> 7	911	3	0	540	3780	61	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20.7	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 7	932	1	1	670	4690	46	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	17.2	NA	NA	NA	1.9	NA	NA	NA	
> 
> 271.4285714	NA	NA	NA
> 7	431	3	0	700	4900	69	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20.4	NA	NA	NA	2.8	NA	NA	
> 
> NA	400	NA
> 7	928	1	0	850	5950	63	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	18.6	NA	NA	NA	2.4	NA	NA	NA	
> 
> 342.8571429	NA	NA	NA
> 7	984	3	1	1040	7280	74	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20.5	NA	NA	NA	1.2	NA	NA	
> 
> NA	171.4285714	NA
> 7	971	1	1	1000	7000	80	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	19.6	NA	NA	NA	2.7	NA	NA	NA	
> 
> 385.7142857	NA	NA	NA
> 7	967	1	1	630	4410	68	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.3	NA	NA	NA	2.5	NA	NA	
> 
> NA	357.1428571	NA
> 7	930	1	0	800	5600	63	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	18.9	NA	NA	NA	0	NA	NA	NA	0	
> 
> NA	NA	NA
> 7	821	3	1	790	5530	57	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	12.7	NA	15.4	NA	1.4	NA	2.2	NA	200	
> 
> NA	314.2857143	NA
> 7	973	1	0	620	4340	52	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	17.8	NA	NA	NA	0.8	NA	NA	NA	
> 
> 114.2857143	NA	NA	NA
> 7	940	1	1	730	5110	58	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15	NA	NA	NA	2	NA	NA	
> 
> NA	285.7142857	NA
> 7	902	3	0	490	3430	70	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	13.8	NA	NA	NA	0.8	NA	NA	
> 
> NA	114.2857143	NA
> 7	424	3	1	1000	7000	66	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21.1	NA	NA	NA	2.5	NA	NA	
> 
> NA	357.1428571	NA
> 7	910	3	0	940	6580	59	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	14.3	NA	13.8	NA	0	NA	0	NA	0	
> 
> NA	0	NA
> 7	943	2	1	1080	7560	69	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	17	NA	17	NA	2.4	NA	2.4	NA	
> 
> 342.8571429	NA	342.8571429	NA
> 7	983	3	1	1270	8890	75	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	15.7	16.8	NA	NA	0.8	1.6	NA	
> 
> NA	114.2857143	228.5714286
> 7	845	3	0	920	6440	61	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	14.6	NA	14.5	NA	0	NA	0	NA	0	
> 
> NA	0	NA
> 7	942	2	0	1120	7840	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	19.6	NA	NA	NA	0.8	NA	NA	NA	
> 
> 114.2857143	NA	NA	NA
> 7	432	2	0	810	5670	59	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	10.6	10.6	NA	NA	-1.4	0	NA	NA	-200	
> 
> 0	NA	NA
> 7	427	1	1	950	6650	69	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	21.6	NA	NA	NA	2.8	NA	NA	NA	400	
> 
> NA	NA	NA
> 7	927	1	0	600	4200	67	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	14.8	NA	NA	NA	-1.7	NA	NA	
> 
> NA	-242.8571429	NA
> 7	969	1	0	910	6370	57	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	14.4	NA	NA	NA	-0.6	NA	NA	
> 
> NA	-85.71428571	NA
> 7	430	1	1	940	6580	50	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	17.4	NA	NA	NA	1.7	NA	NA	NA	
> 
> 242.8571429	NA	NA	NA
> 7	944	2	1	800	5600	61	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	13.2	NA	13	NA	1	NA	0	NA	
> 
> 142.8571429	NA	0	NA
> 7	842	3	0	1110	7770	66	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	17.6	NA	NA	NA	-1.2	NA	NA	
> 
> NA	-171.4285714	NA
> 7	824	3	1	930	6510	65	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	13.1	12.9	NA	NA	1.3	1.7	NA	
> 
> NA	185.7142857	242.8571429
> 7	972	1	1	870	6090	58	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	14.7	NA	NA	NA	1.7	NA	NA	
> 
> NA	242.8571429	NA
> 7	907	3	1	620	4340	63	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	11.5	15.1	NA	NA	1.5	1.3	NA	NA	
> 
> 214.2857143	185.7142857	NA	NA
> 7	933	1	0	900	6300	74	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	11.6	NA	NA	NA	-0.6	NA	NA	NA	
> 
> -85.71428571	NA	NA	NA
> 7	948	2	1	760	5320	70	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.4	NA	NA	NA	0.9	NA	NA	
> 
> NA	128.5714286	NA
> 7	828	3	0	970	6790	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	17.6	NA	NA	NA	-0.4	NA	NA	NA	
> 
> -57.14285714	NA	NA	NA
> 7	950	2	1	780	5460	66	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	12.4	12.7	NA	NA	-0.9	1.6	NA	NA	
> 
> -128.5714286	228.5714286	NA	NA
> 7	908	3	1	540	3780	72	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	19.2	NA	NA	NA	2.8	NA	NA	NA	400	
> 
> NA	NA	NA
> 7	935	1	0	510	3570	64	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20.2	NA	NA	NA	2	NA	NA	
> 
> NA	285.7142857	NA
> 7	946	2	1	920	6440	60	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18	NA	NA	NA	0	NA	NA	
> 
> NA	0	NA
> 7	955	2	0	510	3570	52	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	15.4	NA	NA	NA	0.8	NA	NA	NA	
> 
> 114.2857143	NA	NA	NA
> 7	881	2	0	670	4690	62	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	18.7	NA	NA	NA	1.3	NA	NA	NA	
> 
> 185.7142857	NA	NA	NA
> 7	880	2	1	1000	7000	56	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	19.3	NA	NA	NA	1.8	NA	NA	NA	
> 
> 257.1428571	NA	NA	NA
> 7	993	1	1	780	5460	50	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	16.6	NA	NA	NA	1.6	NA	NA	NA	
> 
> 228.5714286	NA	NA	NA
> 7	937	1	1	640	4480	61	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.7	NA	NA	NA	1.9	NA	NA	
> 
> NA	271.4285714	NA
> 7	951	2	1	690	4830	58	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	17.2	NA	NA	NA	1.8	NA	NA	NA	
> 
> 257.1428571	NA	NA	NA
> 7	929	1	0	530	3710	59	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	15.4	NA	NA	NA	1.4	NA	NA	NA	200	
> 
> NA	NA	NA
> 8	429	3	1	900	6300	65	5.68	16.1635	0.9621	5.3671	4.2113	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	25.1	NA	NA	NA	3.1	NA	NA	
> 
> NA	442.8571429	NA
> 8	901	3	0	800	5600	63	6.98	17.0048	0.9543	4.8211	4.0640	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.2	NA	NA	NA	0.2	NA	NA	
> 
> NA	28.57142857	NA
> 8	939	1	0	830	5810	63	8.95	19.3697	0.9632	5.0307	4.3357	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.5	NA	NA	NA	2	NA	NA	
> 
> NA	285.7142857	NA
> 8	911	3	0	670	4690	62	8.25	19.8412	0.9834	5.7728	3.9698	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20.7	NA	NA	NA	0	NA	NA	
> 
> NA	0	NA
> 8	932	1	1	700	4900	47	5.18	16.3061	0.9209	4.7981	4.4756	1	NA	
> 
> H	1	NA	NA	NA	19.6	NA	NA	NA	2.4	NA	NA	NA	
> 
> 342.8571429	NA	NA	NA
> 8	431	3	0	630	4410	69	9.9	20.8608	0.9791	5.7811	4.2551	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	24	NA	NA	NA	3.6	NA	NA	
> 
> NA	514.2857143	NA
> 8	928	1	0	830	5810	64	8.08	19.7357	0.8818	5.2446	4.4946	1	NA	
> 
> H	1	NA	NA	NA	20.3	NA	NA	NA	1.7	NA	NA	NA	
> 
> 242.8571429	NA	NA	NA
> 8	984	3	1	930	6510	75	5.18	17.0582	0.95	5.3715	4.8009	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22.5	NA	NA	NA	2	NA	NA	
> 
> NA	285.7142857	NA
> 8	971	1	1	1100	7700	82	3.4	14.7585	0.8408	5.1013	4.5636	1	NA	
> 
> H	1	NA	NA	NA	22.1	NA	NA	NA	2.5	NA	NA	NA	
> 
> 357.1428571	NA	NA	NA
> 8	967	1	1	640	4480	69	2.35	14.0045	1.0535	5.6424	4.7497	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21	NA	NA	NA	2.7	NA	NA	
> 
> NA	385.7142857	NA
> 8	930	1	0	820	5740	64	7.41	18.3067	0.8855	5.364	4.5603	1	NA	
> 
> H	1	NA	NA	NA	19.8	NA	NA	NA	0.9	NA	NA	NA	
> 
> 128.5714286	NA	NA	NA
> 8	821	3	1	900	6300	57	5.13	16.3417	0.8331	5.14	4.6987	2	2	
> 
> NA	1	NA	1	NA	14.8	NA	18	NA	2.1	NA	2.6	NA	300	
> 
> NA	371.4285714	NA
> 8	973	1	0	580	4060	55	6.9	17.2547	0.9636	4.8645	4.3322	1	NA	
> 
> H	1	NA	NA	NA	17.8	NA	NA	NA	0	NA	NA	NA	0	
> 
> NA	NA	NA
> 8	940	1	1	650	4550	59	5.78	16.8999	0.85	5.0757	4.5029	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16.4	NA	NA	NA	1.4	NA	NA	
> 
> NA	200	NA
> 8	902	3	0	430	3010	72	8.15	18.8143	0.9067	5.3197	4.5349	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	13.5	NA	NA	NA	-0.3	NA	NA	
> 
> NA	-42.85714286	NA
> 8	424	3	1	920	6440	64	9.1	21.9653	0.8046	5.7028	4.6460	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.5	NA	NA	NA	-2.6	NA	NA	
> 
> NA	-371.4285714	NA
> 8	910	3	0	730	5110	58	7.05	17.617	0.8379	4.7632	4.4574	2	2	
> 
> NA	1	NA	1	NA	16	NA	15.9	NA	1.7	NA	2.1	NA	
> 
> 242.8571429	NA	300	NA
> 8	943	2	1	1050	7350	68	1.9	13.7342	0.8377	4.8279	5.2575	2	2	
> 
> NA	1	NA	1	NA	19.2	NA	18.8	NA	2.2	NA	1.8	NA	
> 
> 314.2857143	NA	257.1428571	NA
> 8	983	3	1	1000	7000	72	4.38	16.4772	0.8883	5.3279	4.7988	2	2	
> 
> NA	NA	NA	1	2	NA	NA	16.9	18	NA	NA	1.2	1.2	NA	
> 
> NA	171.4285714	171.4285714
> 8	845	3	0	570	3990	61	6	16.7211	0.8967	5.0728	4.2495	2	2	
> 
> NA	1	NA	1	NA	15.2	NA	15.8	NA	0.6	NA	1.3	NA	
> 
> 85.71428571	NA	185.7142857	NA
> 8	942	2	0	1100	7700	74	8.25	18.9948	0.8265	4.796	4.7719	1	NA	
> 
> H	1	NA	NA	NA	21.4	NA	NA	NA	1.8	NA	NA	NA	
> 
> 257.1428571	NA	NA	NA
> 8	432	2	0	670	4690	59	4.35	15.5865	0.9609	5.425	4.4614	2	2	
> 
> NA	1	2	NA	NA	10.6	12.1	NA	NA	0	1.5	NA	NA	0	
> 
> 214.2857143	NA	NA
> 8	427	1	1	1210	8470	70	5.15	16.08	0.8726	4.5459	5.0295	1	NA	
> 
> H	1	NA	NA	NA	23.4	NA	NA	NA	1.8	NA	NA	NA	
> 
> 257.1428571	NA	NA	NA
> 8	927	1	0	590	4130	67	7.75	18.5432	0.8469	5.2674	4.6225	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16.6	NA	NA	NA	1.8	NA	NA	
> 
> NA	257.1428571	NA
> 8	969	1	0	900	6300	57	7.4	18.0368	0.8876	4.9387	4.4640	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16	NA	NA	NA	1.6	NA	NA	
> 
> NA	228.5714286	NA
> 8	430	1	1	720	5040	48	4.48	16.0622	0.9883	5.4078	5.1728	1	NA	
> 
> H	1	NA	NA	NA	19.6	NA	NA	NA	2.2	NA	NA	NA	
> 
> 314.2857143	NA	NA	NA
> 8	944	2	1	710	4970	60	4	15.603	0.9262	5.353	4.8140	2	2	
> 
> NA	1	NA	1	NA	14.5	NA	14.2	NA	1.3	NA	1.2	NA	
> 
> 185.7142857	NA	171.4285714	NA
> 8	842	3	0	860	6020	63	8.4	19.9905	0.8514	5.2522	4.7739	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20	NA	NA	NA	2.4	NA	NA	
> 
> NA	342.8571429	NA
> 8	824	3	1	750	5250	66	8	18.7251	0.9256	5.1191	4.3815	2	2	
> 
> NA	NA	NA	1	2	NA	NA	14.7	14.6	NA	NA	1.6	1.7	NA	
> 
> NA	228.5714286	242.8571429
> 8	972	1	1	800	5600	60	5.15	15.7894	0.9079	4.9373	4.6048	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16.4	NA	NA	NA	1.7	NA	NA	
> 
> NA	242.8571429	NA
> 8	907	3	1	520	3640	65	3.3	15.1618	0.8838	5.2133	4.8590	2	2	
> 
> NA	1	2	NA	NA	12.5	16.6	NA	NA	1	1.5	NA	NA	
> 
> 142.8571429	214.2857143	NA	NA
> 8	933	1	0	910	6370	74	6.8	17.1098	0.8434	4.5169	4.3801	1	NA	
> 
> H	1	NA	NA	NA	14.2	NA	NA	NA	2.6	NA	NA	NA	
> 
> 371.4285714	NA	NA	NA
> 8	948	2	1	780	5460	73	2.05	12.5017	0.8991	4.5379	4.6481	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20.3	NA	NA	NA	1.9	NA	NA	
> 
> NA	271.4285714	NA
> 8	828	3	0	950	6650	74	7.3	18.0557	0.8806	5.2207	4.6066	1	NA	
> 
> H	1	NA	NA	NA	19.2	NA	NA	NA	1.6	NA	NA	NA	
> 
> 228.5714286	NA	NA	NA
> 8	950	2	1	1030	7210	69	3.7	14.3019	0.8218	4.8616	4.6980	2	2	
> 
> NA	1	2	NA	NA	13.8	14.4	NA	NA	1.4	1.7	NA	NA	200	
> 
> 242.8571429	NA	NA
> 8	908	3	1	570	3990	74	3.4	15.1663	1.0018	5.6201	5.1884	1	NA	
> 
> H	1	NA	NA	NA	20.6	NA	NA	NA	1.4	NA	NA	NA	200	
> 
> NA	NA	NA
> 8	935	1	0	900	6300	67	4.64	18.2419	0.8023	4.3612	4.6433	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22.6	NA	NA	NA	2.4	NA	NA	
> 
> NA	342.8571429	NA
> 8	946	2	1	1000	7000	60	4	14.5934	0.855	4.8543	4.7834	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	19.8	NA	NA	NA	1.8	NA	NA	
> 
> NA	257.1428571	NA
> 8	955	2	0	640	4480	51	8.45	21.6158	0.9222	5.5085	4.1200	1	NA	
> 
> H	1	NA	NA	NA	16.9	NA	NA	NA	1.5	NA	NA	NA	
> 
> 214.2857143	NA	NA	NA
> 8	881	2	0	1000	7000	61	9	21.1995	0.9425	4.9712	5.8918	1	NA	
> 
> H	1	NA	NA	NA	19.2	NA	NA	NA	0.5	NA	NA	NA	
> 
> 71.42857143	NA	NA	NA
> 8	880	2	1	950	6650	58	5.4	17.0459	0.9603	5.7872	4.8226	1	NA	
> 
> H	1	NA	NA	NA	21.6	NA	NA	NA	2.3	NA	NA	NA	
> 
> 328.5714286	NA	NA	NA
> 8	993	1	1	850	5950	52	3.95	14.8537	0.8564	5.0336	4.8679	1	NA	
> 
> H	1	NA	NA	NA	17.7	NA	NA	NA	1.1	NA	NA	NA	
> 
> 157.1428571	NA	NA	NA
> 8	937	1	1	800	5600	63	2.7	14.0521	0.8847	5.1837	5.2022	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21.7	NA	NA	NA	3	NA	NA	
> 
> NA	428.5714286	NA
> 8	951	2	1	830	5810	61	3.65	15.3151	0.899	5.9267	5.0292	1	NA	
> 
> H	1	NA	NA	NA	18.5	NA	NA	NA	1.3	NA	NA	NA	
> 
> 185.7142857	NA	NA	NA
> 8	929	1	0	460	3220	61	8.5	19.1467	0.9035	5.1083	4.4243	1	NA	
> 
> H	1	NA	NA	NA	16.9	NA	NA	NA	1.5	NA	NA	NA	
> 
> 214.2857143	NA	NA	NA
> 9	429	3	1	380	2660	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	24.2	NA	NA	NA	-0.9	NA	NA	
> 
> NA	-128.5714286	NA
> 9	901	3	0	670	4690	64	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.2	NA	NA	NA	0	NA	NA	
> 
> NA	0	NA
> 9	939	1	0	700	4900	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	19.2	NA	NA	NA	0.7	NA	NA	
> 
> NA	100	NA
> 9	911	3	0	650	4550	62	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21.1	NA	NA	NA	0.4	NA	NA	
> 
> NA	57.14285714	NA
> 9	932	1	1	450	3150	49	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	20.1	NA	NA	NA	0.5	NA	NA	NA	
> 
> 71.42857143	NA	NA	NA
> 9	431	3	0	510	3570	69	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	24.7	NA	NA	NA	0.7	NA	NA	
> 
> NA	100	NA
> 9	928	1	0	730	5110	64	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	19.5	NA	NA	NA	-0.8	NA	NA	NA	
> 
> -114.2857143	NA	NA	NA
> 9	984	3	1	740	5180	75	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	24.7	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 9	971	1	1	940	6580	83	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22.8	NA	NA	NA	0.7	NA	NA	NA	100	
> 
> NA	NA	NA
> 9	967	1	1	600	4200	68	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22.8	NA	NA	NA	1.8	NA	NA	
> 
> NA	257.1428571	NA
> 9	930	1	0	610	4270	64	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	21.2	NA	NA	NA	1.4	NA	NA	NA	200	
> 
> NA	NA	NA
> 9	821	3	1	560	3920	58	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	14.8	NA	17	NA	0	NA	-1	NA	0	
> 
> NA	-142.8571429	NA
> 9	973	1	0	520	3640	54	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	20	NA	NA	NA	2.2	NA	NA	NA	
> 
> 314.2857143	NA	NA	NA
> 9	940	1	1	530	3710	62	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	17.8	NA	NA	NA	1.4	NA	NA	
> 
> NA	200	NA
> 9	902	3	0	400	2800	73	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15.2	NA	NA	NA	1.7	NA	NA	
> 
> NA	242.8571429	NA
> 9	424	3	1	860	6020	67	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 9	910	3	0	780	5460	62	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	17.8	NA	17	NA	1.8	NA	1.1	NA	
> 
> 257.1428571	NA	157.1428571	NA
> 9	943	2	1	770	5390	68	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	21.3	NA	21.8	NA	2.1	NA	3	NA	300	
> 
> NA	428.5714286	NA
> 9	983	3	1	670	4690	73	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	20.2	18.2	NA	NA	3.3	0.2	NA	
> 
> NA	471.4285714	28.57142857
> 9	845	3	0	420	2940	65	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	15.7	NA	16.7	NA	0.5	NA	0.9	NA	
> 
> 71.42857143	NA	128.5714286	NA
> 9	942	2	0	780	5460	76	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	23.1	NA	NA	NA	1.7	NA	NA	NA	
> 
> 242.8571429	NA	NA	NA
> 9	432	2	0	540	3780	61	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	11.6	14	NA	NA	1	1.9	NA	NA	
> 
> 142.8571429	271.4285714	NA	NA
> 9	427	1	1	850	5950	71	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22.2	NA	NA	NA	-1.2	NA	NA	NA	
> 
> -171.4285714	NA	NA	NA
> 9	927	1	0	540	3780	68	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	17.4	NA	NA	NA	0.8	NA	NA	
> 
> NA	114.2857143	NA
> 9	969	1	0	770	5390	60	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	16.4	NA	NA	NA	0.4	NA	NA	
> 
> NA	57.14285714	NA
> 9	430	1	1	520	3640	51	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	18.5	NA	NA	NA	-1.1	NA	NA	NA	
> 
> -157.1428571	NA	NA	NA
> 9	944	2	1	650	4550	64	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	14.9	NA	14.2	NA	0.4	NA	0	NA	
> 
> 57.14285714	NA	0	NA
> 9	842	3	0	850	5950	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21.4	NA	NA	NA	1.4	NA	NA	
> 
> NA	200	NA
> 9	824	3	1	530	3710	66	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	16.7	16	NA	NA	2	1.4	NA	
> 
> NA	285.7142857	200
> 9	972	1	1	550	3850	59	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	17.3	NA	NA	NA	0.9	NA	NA	
> 
> NA	128.5714286	NA
> 9	907	3	1	570	3990	64	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	13.6	17	NA	NA	1.1	0.4	NA	NA	
> 
> 157.1428571	57.14285714	NA	NA
> 9	933	1	0	1070	7490	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	15.2	NA	NA	NA	1	NA	NA	NA	
> 
> 142.8571429	NA	NA	NA
> 9	948	2	1	650	4550	74	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21.2	NA	NA	NA	0.9	NA	NA	
> 
> NA	128.5714286	NA
> 9	828	3	0	840	5880	75	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	19.2	NA	NA	NA	0	NA	NA	NA	0	
> 
> NA	NA	NA
> 9	950	2	1	1060	7420	71	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	14.6	14.4	NA	NA	0.8	0	NA	NA	
> 
> 114.2857143	0	NA	NA
> 9	908	3	1	590	4130	74	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22.7	NA	NA	NA	2.1	NA	NA	NA	300	
> 
> NA	NA	NA
> 9	935	1	0	480	3360	67	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	24	NA	NA	NA	1.4	NA	NA	
> 
> NA	200	NA
> 9	946	2	1	640	4480	62	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21	NA	NA	NA	1.2	NA	NA	
> 
> NA	171.4285714	NA
> 9	955	2	0	480	3360	55	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	18.2	NA	NA	NA	1.3	NA	NA	NA	
> 
> 185.7142857	NA	NA	NA
> 9	881	2	0	700	4900	63	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	20.2	NA	NA	NA	1	NA	NA	NA	
> 
> 142.8571429	NA	NA	NA
> 9	880	2	1	770	5390	59	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	20.9	NA	NA	NA	-0.7	NA	NA	NA	-100	
> 
> NA	NA	NA
> 9	993	1	1	670	4690	54	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	18	NA	NA	NA	0.3	NA	NA	NA	
> 
> 42.85714286	NA	NA	NA
> 9	937	1	1	770	5390	60	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21	NA	NA	NA	-0.7	NA	NA	
> 
> NA	-100	NA
> 9	951	2	1	600	4200	58	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	19.6	NA	NA	NA	1.1	NA	NA	NA	
> 
> 157.1428571	NA	NA	NA
> 9	929	1	0	420	2940	64	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	17.2	NA	NA	NA	0.3	NA	NA	NA	
> 
> 42.85714286	NA	NA	NA
> 10	429	3	1	380	2660	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	24.2	NA	NA	NA	0	NA	NA	
> 
> NA	0	NA
> 10	901	3	0	700	4900	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20.8	NA	NA	NA	2.6	NA	NA	
> 
> NA	371.4285714	NA
> 10	939	1	0	740	5180	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21.3	NA	NA	NA	2.1	NA	NA	
> 
> NA	300	NA
> 10	911	3	0	610	4270	62	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22.7	NA	NA	NA	1.6	NA	NA	
> 
> NA	228.5714286	NA
> 10	932	1	1	690	4830	47	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	21.3	NA	NA	NA	1.2	NA	NA	NA	
> 
> 171.4285714	NA	NA	NA
> 10	431	3	0	480	3360	69	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	26.6	NA	NA	NA	1.9	NA	NA	
> 
> NA	271.4285714	NA
> 10	928	1	0	740	5180	65	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	21.2	NA	NA	NA	1.7	NA	NA	NA	
> 
> 242.8571429	NA	NA	NA
> 10	984	3	1	740	5180	75	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	26	NA	NA	NA	1.3	NA	NA	
> 
> NA	185.7142857	NA
> 10	971	1	1	700	4900	83	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	25.4	NA	NA	NA	2.6	NA	NA	NA	
> 
> 371.4285714	NA	NA	NA
> 10	967	1	1	420	2940	67	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	23	NA	NA	NA	0.2	NA	NA	
> 
> NA	28.57142857	NA
> 10	930	1	0	440	3080	66	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	21.6	NA	NA	NA	0.4	NA	NA	NA	
> 
> 57.14285714	NA	NA	NA
> 10	821	3	1	660	4620	59	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	15.7	NA	18.8	NA	0.9	NA	1.8	NA	
> 
> 128.5714286	NA	257.1428571	NA
> 10	973	1	0	560	3920	57	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22	NA	NA	NA	2	NA	NA	NA	
> 
> 285.7142857	NA	NA	NA
> 10	940	1	1	700	4900	63	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 10	902	3	0	460	3220	73	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15.7	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 10	424	3	1	860	6020	70	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 10	910	3	0	720	5040	63	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	18.8	NA	18.4	NA	1	NA	1.4	NA	
> 
> 142.8571429	NA	200	NA
> 10	943	2	1	750	5250	69	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	23.2	NA	23.6	NA	1.9	NA	1.8	NA	
> 
> 271.4285714	NA	257.1428571	NA
> 10	983	3	1	580	4060	75	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	19.7	20	NA	NA	-0.5	1.8	NA	
> 
> NA	-71.42857143	257.1428571
> 10	845	3	0	440	3080	66	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	15	NA	18	NA	-0.7	NA	1.3	NA	-100	
> 
> NA	185.7142857	NA
> 10	942	2	0	980	6860	76	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	23.5	NA	NA	NA	0.4	NA	NA	NA	
> 
> 57.14285714	NA	NA	NA
> 10	432	2	0	540	3780	62	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	11.6	15	NA	NA	0	1	NA	NA	0	
> 
> 142.8571429	NA	NA
> 10	427	1	1	1110	7770	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	21	NA	NA	NA	-1.2	NA	NA	NA	
> 
> -171.4285714	NA	NA	NA
> 10	927	1	0	540	3780	70	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18	NA	NA	NA	0.6	NA	NA	
> 
> NA	85.71428571	NA
> 10	969	1	0	650	4550	61	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	17.7	NA	NA	NA	1.3	NA	NA	
> 
> NA	185.7142857	NA
> 10	430	1	1	510	3570	51	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	20.3	NA	NA	NA	1.8	NA	NA	NA	
> 
> 257.1428571	NA	NA	NA
> 10	944	2	1	540	3780	65	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	14	NA	14.6	NA	-0.9	NA	0.4	NA	
> 
> -128.5714286	NA	57.14285714	NA
> 10	842	3	0	740	5180	64	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22	NA	NA	NA	0.6	NA	NA	
> 
> NA	85.71428571	NA
> 10	824	3	1	500	3500	67	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	15.6	16.2	NA	NA	-1.1	0.2	NA	
> 
> NA	-157.1428571	28.57142857
> 10	972	1	1	500	3500	59	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20	NA	NA	NA	2.7	NA	NA	
> 
> NA	385.7142857	NA
> 10	907	3	1	600	4200	65	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	14.2	15.7	NA	NA	0.6	-1.3	NA	NA	
> 
> 85.71428571	-185.7142857	NA	NA
> 10	933	1	0	880	6160	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	16	NA	NA	NA	0.8	NA	NA	NA	
> 
> 114.2857143	NA	NA	NA
> 10	948	2	1	550	3850	75	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22	NA	NA	NA	0.8	NA	NA	
> 
> NA	114.2857143	NA
> 10	828	3	0	790	5530	74	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	17.4	NA	NA	NA	-1.8	NA	NA	NA	
> 
> -257.1428571	NA	NA	NA
> 10	950	2	1	1010	7070	70	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	16.9	15.3	NA	NA	2.3	0.9	NA	NA	
> 
> 328.5714286	128.5714286	NA	NA
> 10	908	3	1	500	3500	74	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	23.3	NA	NA	NA	0.6	NA	NA	NA	
> 
> 85.71428571	NA	NA	NA
> 10	935	1	0	610	4270	69	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	24.4	NA	NA	NA	0.4	NA	NA	
> 
> NA	57.14285714	NA
> 10	946	2	1	600	4200	61	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22.6	NA	NA	NA	1.6	NA	NA	
> 
> NA	228.5714286	NA
> 10	955	2	0	420	2940	54	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	19.6	NA	NA	NA	1.4	NA	NA	NA	200	
> 
> NA	NA	NA
> 10	881	2	0	550	3850	62	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	20	NA	NA	NA	-0.2	NA	NA	NA	
> 
> -28.57142857	NA	NA	NA
> 10	880	2	1	470	3290	58	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22.4	NA	NA	NA	1.5	NA	NA	NA	
> 
> 214.2857143	NA	NA	NA
> 10	993	1	1	760	5320	54	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	20.4	NA	NA	NA	2.4	NA	NA	NA	
> 
> 342.8571429	NA	NA	NA
> 10	937	1	1	780	5460	62	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	23.4	NA	NA	NA	2.4	NA	NA	
> 
> NA	342.8571429	NA
> 10	951	2	1	610	4270	60	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	20.4	NA	NA	NA	0.8	NA	NA	NA	
> 
> 114.2857143	NA	NA	NA
> 10	929	1	0	520	3640	64	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	19.2	NA	NA	NA	2	NA	NA	NA	
> 
> 285.7142857	NA	NA	NA
> 11	429	3	1	310	2170	65	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	26.5	NA	NA	NA	2.3	NA	NA	
> 
> NA	328.5714286	NA
> 11	901	3	0	600	4200	67	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21	NA	NA	NA	0.2	NA	NA	
> 
> NA	28.57142857	NA
> 11	939	1	0	700	4900	66	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22.6	NA	NA	NA	1.3	NA	NA	
> 
> NA	185.7142857	NA
> 11	911	3	0	550	3850	67	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	23	NA	NA	NA	0.3	NA	NA	
> 
> NA	42.85714286	NA
> 11	932	1	1	650	4550	47	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22.2	NA	NA	NA	0.9	NA	NA	NA	
> 
> 128.5714286	NA	NA	NA
> 11	431	3	0	500	3500	71	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	27.9	NA	NA	NA	1.3	NA	NA	
> 
> NA	185.7142857	NA
> 11	928	1	0	750	5250	64	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22.7	NA	NA	NA	1.5	NA	NA	NA	
> 
> 214.2857143	NA	NA	NA
> 11	984	3	1	560	3920	75	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	29	NA	NA	NA	3	NA	NA	
> 
> NA	428.5714286	NA
> 11	971	1	1	550	3850	83	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	29.4	NA	NA	NA	4	NA	NA	NA	
> 
> 571.4285714	NA	NA	NA
> 11	967	1	1	320	2240	67	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	26.2	NA	NA	NA	3.2	NA	NA	
> 
> NA	457.1428571	NA
> 11	930	1	0	540	3780	68	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22.8	NA	NA	NA	1.2	NA	NA	NA	
> 
> 171.4285714	NA	NA	NA
> 11	821	3	1	880	6160	61	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	16	NA	19	NA	0.3	NA	0.2	NA	
> 
> 42.85714286	NA	28.57142857	NA
> 11	973	1	0	500	3500	59	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22.2	NA	NA	NA	0.2	NA	NA	NA	
> 
> 28.57142857	NA	NA	NA
> 11	940	1	1	480	3360	64	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20.6	NA	NA	NA	0.6	NA	NA	
> 
> NA	85.71428571	NA
> 11	902	3	0	370	2590	75	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	15.2	NA	NA	NA	-0.5	NA	NA	
> 
> NA	-71.42857143	NA
> 11	424	3	1	820	5740	70	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 11	910	3	0	490	3430	65	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	21	NA	20.5	NA	2.2	NA	2.1	NA	
> 
> 314.2857143	NA	300	NA
> 11	943	2	1	490	3430	69	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	23.8	NA	24.6	NA	0.6	NA	1	NA	
> 
> 85.71428571	NA	142.8571429	NA
> 11	983	3	1	450	3150	75	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	22	22.4	NA	NA	2.3	2.4	NA	
> 
> NA	328.5714286	342.8571429
> 11	845	3	0	320	2240	65	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	16	NA	19.6	NA	1	NA	1.6	NA	
> 
> 142.8571429	NA	228.5714286	NA
> 11	942	2	0	800	5600	77	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	24	NA	NA	NA	0.5	NA	NA	NA	
> 
> 71.42857143	NA	NA	NA
> 11	432	2	0	580	4060	63	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	12.4	16.2	NA	NA	0.8	1.2	NA	NA	
> 
> 114.2857143	171.4285714	NA	NA
> 11	427	1	1	1160	8120	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	25.2	NA	NA	NA	4.2	NA	NA	NA	600	
> 
> NA	NA	NA
> 11	927	1	0	400	2800	71	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	20.6	NA	NA	NA	2.6	NA	NA	
> 
> NA	371.4285714	NA
> 11	969	1	0	700	4900	62	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21	NA	NA	NA	3.3	NA	NA	
> 
> NA	471.4285714	NA
> 11	430	1	1	430	3010	52	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	23	NA	NA	NA	2.7	NA	NA	NA	
> 
> 385.7142857	NA	NA	NA
> 11	944	2	1	320	2240	67	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	NA	1	NA	13.6	NA	16.8	NA	-0.4	NA	2.2	NA	
> 
> -57.14285714	NA	314.2857143	NA
> 11	842	3	0	760	5320	64	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	24.8	NA	NA	NA	2.8	NA	NA	
> 
> NA	400	NA
> 11	824	3	1	310	2170	68	NA	NA	NA	NA	NA	2	2	
> 
> NA	NA	NA	1	2	NA	NA	16.4	16.4	NA	NA	0.8	0.2	NA	
> 
> NA	114.2857143	28.57142857
> 11	972	1	1	460	3220	60	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21.8	NA	NA	NA	1.8	NA	NA	
> 
> NA	257.1428571	NA
> 11	907	3	1	610	4270	64	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	14.2	15.3	NA	NA	0	-0.4	NA	NA	0	
> 
> -57.14285714	NA	NA
> 11	933	1	0	1000	7000	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	17.6	NA	NA	NA	1.6	NA	NA	NA	
> 
> 228.5714286	NA	NA	NA
> 11	948	2	1	370	2590	74	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	23.3	NA	NA	NA	1.3	NA	NA	
> 
> NA	185.7142857	NA
> 11	828	3	0	820	5740	74	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	17.9	NA	NA	NA	0.5	NA	NA	NA	
> 
> 71.42857143	NA	NA	NA
> 11	950	2	1	910	6370	70	NA	NA	NA	NA	NA	2	2	
> 
> NA	1	2	NA	NA	17.4	16	NA	NA	0.5	0.7	NA	NA	
> 
> 71.42857143	100	NA	NA
> 11	908	3	1	440	3080	73	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	26	NA	NA	NA	2.7	NA	NA	NA	
> 
> 385.7142857	NA	NA	NA
> 11	935	1	0	590	4130	68	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	25.4	NA	NA	NA	1	NA	NA	
> 
> NA	142.8571429	NA
> 11	946	2	1	570	3990	60	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	23.8	NA	NA	NA	1.2	NA	NA	
> 
> NA	171.4285714	NA
> 11	955	2	0	470	3290	55	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22	NA	NA	NA	2.4	NA	NA	NA	
> 
> 342.8571429	NA	NA	NA
> 11	881	2	0	540	3780	62	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22.4	NA	NA	NA	2.4	NA	NA	NA	
> 
> 342.8571429	NA	NA	NA
> 11	880	2	1	560	3920	58	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	24	NA	NA	NA	1.6	NA	NA	NA	
> 
> 228.5714286	NA	NA	NA
> 11	993	1	1	700	4900	55	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	21.6	NA	NA	NA	1.2	NA	NA	NA	
> 
> 171.4285714	NA	NA	NA
> 11	937	1	1	620	4340	64	NA	NA	NA	NA	NA	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	23.4	NA	NA	NA	0	NA	NA	
> 
> NA	0	NA
> 11	951	2	1	400	2800	59	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	22.6	NA	NA	NA	2.2	NA	NA	NA	
> 
> 314.2857143	NA	NA	NA
> 11	929	1	0	320	2240	64	NA	NA	NA	NA	NA	1	NA	
> 
> H	1	NA	NA	NA	20	NA	NA	NA	0.8	NA	NA	NA	
> 
> 114.2857143	NA	NA	NA
> 12	429	3	1	300	2100	67	8.05	19.0819	0.9039	5.8475	3.8131	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	28.3	NA	NA	NA	1.8	NA	NA	
> 
> NA	257.1428571	NA
> 12	901	3	0	480	3360	69	6.8	17.1301	0.884	4.7708	4.3048	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	23.2	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 12	939	1	0	610	4270	68	7.6	18.3774	0.9529	5.1315	4.1302	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	24.1	NA	NA	NA	1.5	NA	NA	
> 
> NA	214.2857143	NA
> 12	911	3	0	550	3850	67	8.4	19.542	0.9099	5.3574	4.2909	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	23	NA	NA	NA	0	NA	NA	
> 
> NA	0	NA
> 12	932	1	1	540	3780	50	7.8	18.7603	0.9831	5.5026	4.0155	1	NA	
> 
> H	1	NA	NA	NA	22.2	NA	NA	NA	0	NA	NA	NA	0	
> 
> NA	NA	NA
> 12	431	3	0	360	2520	73	8.05	20.414	1.0373	7.0453	4.0891	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	28	NA	NA	NA	0.1	NA	NA	
> 
> NA	14.28571429	NA
> 12	928	1	0	610	4270	67	9.6	20.8487	0.842	5.4314	4.5009	1	NA	
> 
> H	1	NA	NA	NA	23.2	NA	NA	NA	0.5	NA	NA	NA	
> 
> 71.42857143	NA	NA	NA
> 12	984	3	1	450	3150	76	8.4	18.8994	0.8285	5.4391	4.3645	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	29	NA	NA	NA	0	NA	NA	
> 
> NA	0	NA
> 12	971	1	1	370	2590	84	8.2	18.7883	0.9271	5.6094	4.1184	1	NA	
> 
> H	1	NA	NA	NA	29.4	NA	NA	NA	0	NA	NA	NA	0	
> 
> NA	NA	NA
> 12	967	1	1	260	1820	69	8.2	19.7012	0.9617	6.154	4.2830	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	24	NA	NA	NA	-2.2	NA	NA	
> 
> NA	-314.2857143	NA
> 12	930	1	0	450	3150	68	10.3	21.9012	0.9985	5.794	4.0915	1	NA	
> 
> H	1	NA	NA	NA	23.6	NA	NA	NA	0.8	NA	NA	NA	
> 
> 114.2857143	NA	NA	NA
> 12	821	3	1	700	4900	62	7.3	18.2748	0.928	5.5328	4.2001	2	2	
> 
> NA	1	NA	1	NA	18.5	NA	20.4	NA	2.5	NA	1.4	NA	
> 
> 357.1428571	NA	200	NA
> 12	973	1	0	480	3360	60	8.17	19.8487	0.9432	5.2258	4.2900	1	NA	
> 
> H	1	NA	NA	NA	24.8	NA	NA	NA	2.6	NA	NA	NA	
> 
> 371.4285714	NA	NA	NA
> 12	940	1	1	450	3150	64	8	18.9898	0.9948	5.82	4.0742	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22.2	NA	NA	NA	1.6	NA	NA	
> 
> NA	228.5714286	NA
> 12	902	3	0	400	2800	77	7.5	18.3286	0.9251	4.7682	4.3104	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	18.6	NA	NA	NA	3.4	NA	NA	
> 
> NA	485.7142857	NA
> 12	424	3	1	830	5810	71	9.15	21.1182	0.9008	6.2436	4.1781	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	
> 
> NA	NA	NA
> 12	910	3	0	640	4480	65	6.7	16.602	0.9024	5.1347	4.0429	2	2	
> 
> NA	1	NA	1	NA	22	NA	22	NA	1	NA	1.5	NA	
> 
> 142.8571429	NA	214.2857143	NA
> 12	943	2	1	340	2380	70	8	18.9112	0.9374	5.3698	3.9104	2	2	
> 
> NA	1	NA	1	NA	26.1	NA	26	NA	2.3	NA	1.4	NA	
> 
> 328.5714286	NA	200	NA
> 12	983	3	1	420	2940	75	8	17.9703	0.8794	5.03995	3.8725	2	2	
> 
> NA	NA	NA	1	2	NA	NA	23.1	24.1	NA	NA	1.1	1.7	NA	
> 
> NA	157.1428571	242.8571429
> 12	845	3	0	390	2730	63	6.95	17.8857	0.8816	4.8955	4.0415	2	2	
> 
> NA	1	NA	1	NA	18.3	NA	20	NA	2.3	NA	0.4	NA	
> 
> 328.5714286	NA	57.14285714	NA
> 12	942	2	0	850	5950	77	7.9	18.8338	0.8297	4.3915	4.4030	1	NA	
> 
> H	1	NA	NA	NA	25.4	NA	NA	NA	1.4	NA	NA	NA	200	
> 
> NA	NA	NA
> 12	432	2	0	450	3150	63	7.1	17.8344	0.945	5.4013	3.9837	2	2	
> 
> NA	1	2	NA	NA	14	18.8	NA	NA	1.6	2.6	NA	NA	
> 
> 228.5714286	371.4285714	NA	NA
> 12	427	1	1	1030	7210	73	8.45	19.2424	0.8298	5.2241	4.4896	1	NA	
> 
> H	1	NA	NA	NA	25.8	NA	NA	NA	0.6	NA	NA	NA	
> 
> 85.71428571	NA	NA	NA
> 12	927	1	0	580	4060	72	9.6	20.1228	0.789	4.844	4.4104	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22.6	NA	NA	NA	2	NA	NA	
> 
> NA	285.7142857	NA
> 12	969	1	0	610	4270	62	8.5	19.4813	0.857	5.5157	4.1294	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	22	NA	NA	NA	1	NA	NA	
> 
> NA	142.8571429	NA
> 12	430	1	1	610	4270	54	8.65	19.919	0.897	5.0038	4.2938	1	NA	
> 
> H	1	NA	NA	NA	24.8	NA	NA	NA	1.8	NA	NA	NA	
> 
> 257.1428571	NA	NA	NA
> 12	944	2	1	250	1750	67	9	20.4849	0.9319	5.4332	4.0641	2	2	
> 
> NA	1	NA	1	NA	17	NA	18	NA	3.4	NA	1.2	NA	
> 
> 485.7142857	NA	171.4285714	NA
> 12	842	3	0	800	5600	64	8.45	19.4899	0.8272	4.8111	4.5430	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	27	NA	NA	NA	2.2	NA	NA	
> 
> NA	314.2857143	NA
> 12	824	3	1	210	1470	68	8.1	18.71	0.9	5.31	4.1700	2	2	
> 
> NA	NA	NA	1	2	NA	NA	19	19	NA	NA	2.6	2.6	NA	
> 
> NA	371.4285714	371.4285714
> 12	972	1	1	350	2450	60	7.45	18.0437	0.8862	4.9058	4.1457	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	21.8	NA	NA	NA	0	NA	NA	
> 
> NA	0	NA
> 12	907	3	1	660	4620	63	7.75	19.3411	0.8738	6.0474	4.4596	2	2	
> 
> NA	1	2	NA	NA	17	17	NA	NA	2.8	1.7	NA	NA	400	
> 
> 242.8571429	NA	NA
> 12	933	1	0	1090	7630	73	8.05	18.4025	0.8614	4.4922	4.5331	1	NA	
> 
> H	1	NA	NA	NA	19	NA	NA	NA	1.4	NA	NA	NA	200	
> 
> NA	NA	NA
> 12	948	2	1	240	1680	74	7.85	18.6638	0.8286	5.0908	3.8407	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	27.2	NA	NA	NA	3.9	NA	NA	
> 
> NA	557.1428571	NA
> 12	828	3	0	840	5880	74	10.2	21.6667	0.8751	6.1423	3.9300	1	NA	
> 
> H	1	NA	NA	NA	23.1	NA	NA	NA	5.2	NA	NA	NA	
> 
> 742.8571429	NA	NA	NA
> 12	950	2	1	880	6160	70	9.6	20.618	0.8295	5.6526	4.0939	2	2	
> 
> NA	1	2	NA	NA	18.3	16.5	NA	NA	0.9	0.5	NA	NA	
> 
> 128.5714286	71.42857143	NA	NA
> 12	908	3	1	370	2590	73	9.8	21.5713	0.9861	5.8596	4.1217	1	NA	
> 
> H	1	NA	NA	NA	27.7	NA	NA	NA	1.7	NA	NA	NA	
> 
> 242.8571429	NA	NA	NA
> 12	935	1	0	610	4270	70	7.9	18.7722	0.8049	4.9627	4.2804	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	26.8	NA	NA	NA	1.4	NA	NA	
> 
> NA	200	NA
> 12	946	2	1	600	4200	62	6.95	17.7376	0.8232	5.2329	4.2653	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	23.8	NA	NA	NA	0	NA	NA	
> 
> NA	0	NA
> 12	955	2	0	440	3080	56	9.15	20.3768	0.9268	5.9223	4.1215	1	NA	
> 
> H	1	NA	NA	NA	22	NA	NA	NA	0	NA	NA	NA	0	
> 
> NA	NA	NA
> 12	881	2	0	450	3150	63	8	19.2697	0.979	5.8033	4.1106	1	NA	
> 
> H	1	NA	NA	NA	23.4	NA	NA	NA	1	NA	NA	NA	
> 
> 142.8571429	NA	NA	NA
> 12	880	2	1	520	3640	59	8.15	19.4556	0.9267	5.6218	4.0434	1	NA	
> 
> H	1	NA	NA	NA	24	NA	NA	NA	0	NA	NA	NA	0	
> 
> NA	NA	NA
> 12	993	1	1	750	5250	54	7.55	18.2651	0.8267	4.5025	4.3729	1	NA	
> 
> H	1	NA	NA	NA	22.5	NA	NA	NA	0.9	NA	NA	NA	
> 
> 128.5714286	NA	NA	NA
> 12	937	1	1	650	4550	62	7.33	17.7424	0.8506	5.4672	4.1036	1	NA	
> 
> M	NA	NA	1	NA	NA	NA	25	NA	NA	NA	1.6	NA	NA	
> 
> NA	228.5714286	NA
> 12	951	2	1	560	3920	59	10.3	22.1086	0.9119	7.1849	3.8335	1	NA	
> 
> H	1	NA	NA	NA	23	NA	NA	NA	0.4	NA	NA	NA	
> 
> 57.14285714	NA	NA	NA
> 12	929	1	0	460	3220	66	8.14	19.4538	0.9234	4.829	4.0279	1	NA	
> 
> H	1	NA	NA	NA	22	NA	NA	NA	2	NA	NA	NA	
> 
> 285.7142857	NA	NA	NA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From vfasciani at micron.com  Wed Mar 19 11:35:31 2003
From: vfasciani at micron.com (vfasciani)
Date: Wed, 19 Mar 2003 11:35:31 +0100
Subject: [R] X11 connection error in web cgi mode only
Message-ID: <713A0E408CB0D21183CF0008C7B98AC714EA4F49@ntxamos02.azit.micron.com>

According to my sysadmin I post his answer for all useRs.

-Vittorio

____________________
Vittorio Paolo Fasciani
Operation Software Technician
Micron Technology Italia
vfasciani at micron.com
_________________________


-----Original Message-----
From: eboriani 
Sent: Wednesday, March 19, 2003 11:03 AM
To: 'v_bill_pikounis at merck.com'
Cc: vfasciani
Subject: RE: [R] X11 connection error in web cgi mode only


Bill,

in order to use vnc as an X11 server you need of:

- the vnc binary (or vnc source to compile n the server), generally you can
find the binary for the following path: /usr/local, you can find the binary
on the vnc web site  (www.realvnc.com).

- appropriate settings to start the vncserver, a my script for vncserver
start/stop follow:

#!/bin/ksh

case "$1" in
 
'start')
        # Start the X server deamon
        PATH=$PATH:/usr/local/vnc:/usr/openwin/bin/
        export PATH
        HOME=/
        export HOME
        OPENWINHOME=/usr/openwin
        export OPENWINHOME
        /usr/local/vnc/vncserver
        DISPLAY=unix:1.0
        export DISPLAY
        /usr/openwin/bin/xhost +host1 host2 ......
        ;;
 
'stop')
        # Stop the X server deamon
        PATH=$PATH:/usr/local/vnc:/usr/openwin/bin/
        export PATH
        /usr/local/vnc/vncserver -kill :1
        ;;
*)
        echo "Usage: $0 { start | stop }"
        exit 1
        ;;
esac

If all work fine you should see running a process like this: 

root 29315     1  0   Jan 15 ?       164:32 Xvnc :1 -desktop X -auth
//.Xauthority -geometry 1024x768 -depth 16 -rfbwait 12

Let me know any issues.

Regards
--Ettore


-----Original Message-----
From: Adaikalavan Ramasamy [mailto:gisar at nus.edu.sg]
Sent: Monday, March 17, 2003 2:43 PM
To: r-help at stat.math.ethz.ch
Subject: [R] X11 connection error in web cgi mode only


Dear all,

I am trying to create a web interface using Perl-CGI to call R plots and
to display them.
The following codes works perfectly fine when I copy and paste into the
console directly or if I save it into script.file and then R --no-save <
script.file producing the graphs. 

jpeg("graph.jpeg", width=400, height=400)
plot(rnorm(100))
dev.off()

Now, I put the line system("R --no-save < script.file > log_file") from
inside my cgi and then process it from client side, I get the following
error message:


Error in X11(paste("jpeg::", quality, ":", filename, sep = ""), width,
: 
        unable to start device JPEG
In addition: Warning message: 
unable to open connection to X11 display`' 
Execution halted


Why do I get this error and how can I fix it? Many thanks in advance.

Regards, Adai.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Hagen.Schmoeller at iaew.rwth-aachen.de  Wed Mar 19 11:35:37 2003
From: Hagen.Schmoeller at iaew.rwth-aachen.de (=?iso-8859-1?Q?Hagen_Schm=F6ller?=)
Date: Wed, 19 Mar 2003 11:35:37 +0100
Subject: [R] adjusting a periodical function to a time series
Message-ID: <000201c2ee03$486c60d0$5c6a8286@iaew.rwthaachen.de>

Hi R-Community,

is there a possibility to adjust a periodical function like

s(t) = a1 sin(f1 t) + b1 cos(f1 t) + a2 sin(f2 t) + b2 cos(f2 t) + ...

to a time series with R, if necessary with given frequencies fi.

Much thanks in advance,

Hagen Schmoeller
--
Dipl.-Ing. Hagen K. Schm?ller
Institut f?r Elektrische Anlagen und Energiewirtschaft, RWTH Aachen
Schinkelstra?e 6, D-52056 Aachen, Germany
Tel.: +49 (0)241 80-96734
Fax : +49 (0)241 80-92197
Hagen.Schmoeller at iaew.rwth-aachen.de


From jasont at indigoindustrial.co.nz  Thu Mar 13 21:25:07 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 14 Mar 2003 09:25:07 +1300
Subject: [R] apply with two matrixes
In-Reply-To: <Pine.OSF.4.21.0303121357330.5670-100000@selway.umt.edu>;
	from csillery@selway.umt.edu on Wed, Mar 12, 2003 at 02:34:54PM -0700
References: <Pine.OSF.4.21.0303121357330.5670-100000@selway.umt.edu>
Message-ID: <20030314092507.C21248@camille.indigoindustrial.co.nz>

On Wed, Mar 12, 2003 at 02:34:54PM -0700, Katalin Csillery wrote:
> I have a function which does a certain task with two vectors, 
> f1 <- function(a,b){body}
> 
> I also have a list of matrixes (all with the same dim's), and for each
> column of each matrix in the list I want to use "f1", in such way that
> it gives the vector "a" in the first argument of "f1". The second argument
> of the function "b" also comes form a column of matrix (same dim's as any
> matrix in the list), but that matrix is the same for all matrixes in the
> list.
> I use a separate function with an apply command to accomplish "f1" on each
> column, and than lapply that function over all matrixes in the list.
> The problem is I do not know how tell to apply to use the respective
> columns of the single matrix over all matrixes in the list. 
> 
> Example (this does not work this way),
> m #original matrix
> l <- list(m1, m2, m3, ...) #list of matrixes
> f1 <- function(a, b){body}
> f2 <- function (mx) apply(mx, 2, f1, b = m)
> lapply(l, f2)
> 
> What I want to end up with is a list of list (say lend), where
> length(lend) = length(l)
> length(lend[[any]]) = varies with some properties of the matrixes
> 
> My guess is that I sould use tapply, but I could not get it right.
> The problem would be pretty easy with a loop, but efficiency is very
> important, because the objects are huge and functions a computationally
> intense.

<sidenote about loops>
A loop probably wouldn't be as bad as you might think.  I'm led to believe
that much of the loop avoidance philosophy in R/S is to help readability, 
these days.  Once there was an efficiency argument, but those days
are gone, for R at least.
</sidenote about loops>

I think the above doesn't work because by the time apply goes to call
f1 with b=m as an argument, it might not be in an environment where 
f1 or m are defined.  Do you get an error message to that effect?  It's 
hard to diagnose from here, using only the above information.

Using *apply, something like this might work.  

lend <- lapply(l, function(mx,mb,...) {
			f1 <- function(a,b,...) {body}
			apply(mx,2,f1,mb,...) 
			}, m)

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz


From adrian.trapletti at lmttrading.com  Wed Mar 19 12:35:06 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Wed, 19 Mar 2003 12:35:06 +0100
Subject: [R] adjusting a periodical function to a time series
References: <200303191104.h2JB4TfV014047@hypatia.math.ethz.ch>
Message-ID: <3E7855EA.7A04695A@lmttrading.com>

> Subject: [R] adjusting a periodical function to a time series
> Date: Wed, 19 Mar 2003 11:35:37 +0100
> From: Hagen Schm?ller<Hagen.Schmoeller at iaew.rwth-aachen.de>
> To: <r-help at stat.math.ethz.ch>
>
> Hi R-Community,
>
> is there a possibility to adjust a periodical function like
>
> s(t) = a1 sin(f1 t) + b1 cos(f1 t) + a2 sin(f2 t) + b2 cos(f2 t) + ...
>
> to a time series with R, if necessary with given frequencies fi.
>
> Much thanks in advance,
>
> Hagen Schmoeller
> --
> Dipl.-Ing. Hagen K. Schm?ller
> Institut f?r Elektrische Anlagen und Energiewirtschaft, RWTH Aachen
> Schinkelstra?e 6, D-52056 Aachen, Germany
> Tel.: +49 (0)241 80-96734
> Fax : +49 (0)241 80-92197
> Hagen.Schmoeller at iaew.rwth-aachen.de

Maybe something like this:

data(lh)
y <- lh
t <- 1:length(y)

err <- function(par)
{
    x <- par[1]+par[2]*sin(t)+par[3]*cos(t)
    sum((y-x)^2)
}

op <- optim(c(0,0,0), err)

op$par

plot(lh)

lines(op$par[1]+op$par[2]*sin(t)+op$par[3]*cos(t), col="red")


best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com


From matthew_wiener at merck.com  Wed Mar 19 14:35:53 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Wed, 19 Mar 2003 08:35:53 -0500
Subject: [R] r-help using random generating
Message-ID: <AEBD81486231A343B1813FE62D335225013177B3@usrymx15.merck.com>

You can save some time by generating all your samples at one time:

t1 <- matrix(rnorm(5 * n, 100, 10), nc = n)
apply(t1, 2, mean)
(Or use colVars and colMeans to save even more time)

Hope this helps,

Matt Wiener

-----Original Message-----
From: Cheryl H. [mailto:cherylh at montana.edu] 
Sent: Tuesday, March 18, 2003 11:26 PM
To: R-help at stat.math.ethz.ch
Subject: [R] r-help using random generating


To whom it may concern:
Given that my sample size is n, my mean is 100, and my sd is 10, I need to 
use a random number generator (which I believe is the function 
rnorm(5,100,10)), but I need to repeat it a large number of times, and then 
plot the sampling distributions of the sample means, sd's, and variances of 
those generated sets. I'm having a real hard time trying to figure out how 
to do this easily. Please help if possible! Thanks,
Cheryl

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------


From brahm at alum.mit.edu  Wed Mar 19 16:11:02 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Wed, 19 Mar 2003 10:11:02 -0500
Subject: [R] network connection
References: <DF5498CC27A1D411856D00508BF9B098068E74D1@kenmsg31.schp.com>
Message-ID: <15992.34950.836194.681228@gargle.gargle.HOWL>

Wei Ding <wei.ding at spcorp.com> wrote:
> How can I configure R to allow http connection (through company firewall)?

Repeating my R-help message of 2/18/03, for R-1.6.2 under Solaris 2.6:

1) In my .Rprofile:  options(download.file.method="wget")
   (The default method "internal" does not seem to work for me.)

2) In my .cshrc:     setenv http_proxy <some.proxy.server>:8000

3) <some.proxy.server> is NOT the name I find in my web browser!  The web
   browser knows the machine that serves "Proxy Auto-Configuration" files, but
   I needed to get the name of an actual proxy server from our local guru.
-- 
                              -- David Brahm (brahm at alum.mit.edu)


From laurent.duperval at microcell.ca  Wed Mar 19 17:45:01 2003
From: laurent.duperval at microcell.ca (laurent.duperval@microcell.ca)
Date: Wed, 19 Mar 2003 11:45:01 -0500 (EST)
Subject: [R] How would I analyse data like this?
Message-ID: <20030319164501.4972416BCA@mailserv.microcell.ca>

Hello,

I'm a new R user and I'm having a little trouble getting started. I'm hoping
someone can help me out.

I have data that looks like this:

phone|state|code|amount|left|channel|time|mtd
15555551234|3|983|1000|266|IN|2003-03-16 23:57:21-05|C
15555552345|3|983|3000|0|IN|2003-03-16 23:58:16-05|C
15555552346|3|983|1000|40|IN|2003-03-16 23:58:24-05|C

Which I've read using scan(). 

data <- scan(file = "data.dat", what = list("",0,0,0,0,"","",""), sep = "|", skip = 1)

Now, I want to do things like this:

- A histogram for the 5th column for every 50 units. I can generate the
  histogram but most of my values are between 0-500. A few are above that.
  I'd like to bundle them all in a generic 500+ category. I can't figure out
  how. This is what I'm doing

hist(data[[5]], br=c(0,50,100,150,200,250,300,350,400,450,500,1000))
Error in hist.default(data[[5]], br = c(0, 50, 100, 150, 200, 250, 300,  : 
	some `x' not counted; maybe `breaks' do not span range of `x'


- How do I count the number of times channel "IN" occurs with code = 983? How about if
  I want to combine IN and code=983 or 982 or 981?

- Finally (for today at least) how do I count the number of times code=983 and
  date=2003-03-16 (without the time) occur. I'm hoping this will also help
  me build histograms for days of the week and for hours of the day.

  Thanks,

  L
  
-- 
Laurent Duperval <laurent.duperval at microcell.ca>

ZYMURGY'S FIRST LAW OF EVOLVING SYSTEM DYNAMICS
    Once you open a can of worms, the only way to recan them is to use
    a larger can.


From mdw at u.washington.edu  Wed Mar 19 17:57:38 2003
From: mdw at u.washington.edu (Michael D. Ward)
Date: Wed, 19 Mar 2003 08:57:38 -0800 (PST)
Subject: [R] 
Message-ID: <Pine.LNX.4.43.0303190857380.8524@hymn05.u.washington.edu>

Has anyone allocated more than one Gig of memory for R under Windows? When I try the diagnostic tells me I am decreasing memory and the memory size value is a very large negative number.

I suspect the problem may be a signed integer that overflows. Is 1 G a hard
limit for memory allocation in R under Windows?



Michael D. Ward
University of Washington
Seattle, WA, 98195-3530


From cfleming at pressroom.com  Wed Mar 19 18:00:30 2003
From: cfleming at pressroom.com (Charles M. Fleming)
Date: Wed, 19 Mar 2003 12:00:30 -0500
Subject: [R] Center of Closed Contour
Message-ID: <20030319170029.GA8925@pressroom.com>

I am searching for a utility in R which will determine the mean location of
a closed contour and eventually record the location in an ASCII file. By 
means of the contour utility in R, I am able to produce an image of a contour,
but I am seeking a procedure which will produce the coordinates of the
center of mass of the contour. From my actual set of data, the contour
utility will produce several hundered closed non-intersecting and
non-concentric contours like a lattice of disks. I want the location of
those disks via a program. Is there any package in R which will lend
itself to this problem?

Thank you,

Charles Fleming


From dambra at unina.it  Tue Mar 18 20:47:31 2003
From: dambra at unina.it (Prof. Luigi D'Ambra)
Date: Tue, 18 Mar 2003 20:47:31 +0100
Subject: [R] 
	Course on "Data Mining and Explorative Multivariate Data Analysis"
Message-ID: <00f101c2ed87$36e943e0$75fde18f@BIAGIO>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030318/b9f39e0c/attachment.pl

From tblackw at umich.edu  Wed Mar 19 18:22:19 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 19 Mar 2003 12:22:19 -0500 (EST)
Subject: [R] How would I analyse data like this?
In-Reply-To: <20030319164501.4972416BCA@mailserv.microcell.ca>
Message-ID: <Pine.SOL.4.44.0303191214540.16678-100000@millipede.gpcc.itd.umich.edu>

Laurent  -

Good for you for figuring out scan().  For hist(), append one more
number to "breaks" that's guaranteed to be above all the data values.
(In the return value from hist(), "breaks" has n+1 entries when the
histogram has n bars, and it's a good guess that input=output.)

For example:
hist(data[[5]], br=c(50*(seq(11)-1), 1000, 1+max(data[[5]])))

For counting, try the function table().  eg:

table(data[[3]], data[[6]])
table(data[[3]], data[[7]], data[[6]])

-  tom blackwell  -  u michigan medical school  -   ann arbor  -


On Wed, 19 Mar 2003 laurent.duperval at microcell.ca wrote:

> Hello,
>
> I'm a new R user and I'm having a little trouble getting started. I'm hoping
> someone can help me out.
>
> I have data that looks like this:
>
> phone|state|code|amount|left|channel|time|mtd
> 15555551234|3|983|1000|266|IN|2003-03-16 23:57:21-05|C
> 15555552345|3|983|3000|0|IN|2003-03-16 23:58:16-05|C
> 15555552346|3|983|1000|40|IN|2003-03-16 23:58:24-05|C
>
> Which I've read using scan().
>
> data <- scan(file = "data.dat", what = list("",0,0,0,0,"","",""), sep = "|", skip = 1)
>
> Now, I want to do things like this:
>
> - A histogram for the 5th column for every 50 units. I can generate the
>   histogram but most of my values are between 0-500. A few are above that.
>   I'd like to bundle them all in a generic 500+ category. I can't figure out
>   how. This is what I'm doing
>
> hist(data[[5]], br=c(0,50,100,150,200,250,300,350,400,450,500,1000))
> Error in hist.default(data[[5]], br = c(0, 50, 100, 150, 200, 250, 300,  :
> 	some `x' not counted; maybe `breaks' do not span range of `x'
>
>
> - How do I count the number of times channel "IN" occurs with code = 983? How about if
>   I want to combine IN and code=983 or 982 or 981?
>
> - Finally (for today at least) how do I count the number of times code=983 and
>   date=2003-03-16 (without the time) occur. I'm hoping this will also help
>   me build histograms for days of the week and for hours of the day.
>
>   Thanks,
>
>   L
>
> --
> Laurent Duperval <laurent.duperval at microcell.ca>
>
> ZYMURGY'S FIRST LAW OF EVOLVING SYSTEM DYNAMICS
>     Once you open a can of worms, the only way to recan them is to use
>     a larger can.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From laurent.duperval at microcell.ca  Wed Mar 19 18:40:20 2003
From: laurent.duperval at microcell.ca (laurent.duperval@microcell.ca)
Date: Wed, 19 Mar 2003 12:40:20 -0500 (EST)
Subject: [R] How would I analyse data like this?
Message-ID: <20030319174022.B698216BCB@mailserv.microcell.ca>

On 19 Mar, james.holtman at convergys.com wrote:
> Have you tried:
>       data <- read.table("data.dat", header=TRUE, sep="|", as.is=TRUE)
> 

Yes I did. However, it takes a LOT more time because of the date/time
string. The result looks like this:


str(data)
`data.frame':	317437 obs. of  8 variables:
 $ phone   : num  1.52e+10 1.42e+10 1.82e+10 1.65e+10 1.65e+10 ...
 $ state   : int  3 3 3 3 3 3 3 3 3 3 ...
 $ code    : int  983 983 983 983 3000 983 983 983 983 5203 ...
 $ amount  : int  1000 1000 2500 2500 2500 1000 1000 2500 2500 2500 ...
 $ left    : int  260 0 0 25 0 1260 273 0 0 0 ...
 $ channel : Factor w/ 5 levels "CSR","IN","IVR",..: 2 5 4 2 3 2 2 3 4 3 ...
 $ time    : Factor w/ 312198 levels "2002-10-16 ..",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ mtd     : Factor w/ 2 levels "C","D": 1 1 1 1 1 1 1 1 1 1 ...

I think the 312198 factor level is wrong. Also, the phone column is  a string,
not a number. I didn't see how to specify that with read.table(). (In my
original post, I think I forgot to mention that I had over 300,000 entries in
my file).

> change your 'br' range to:
>       br=c(0,50,100,150,200,250,300,350,400,450,500,1e10)
> to make sure that you include everything in the last range.

I tried that, but the result is a graph that is too wide. It treats the range
as numerical values instead of bins. Well, to me, anyway. If it's acceptable
policy, I can post a screenshot of the result here (about 25K). Everything is
bunched up on the left, but the right portion is much larger and contains
nothing.

>> - How do I count the number of times channel "IN" occurs with code = 983?
> How about if
>>   I want to combine IN and code=983 or 982 or 981?
> sum(data$channel == "IN" && (data$code %in% c(983,982,981))

Thank, I'll try that.

>>
>> - Finally (for today at least) how do I count the number of times
> code=983 and
>>   date=2003-03-16 (without the time) occur. I'm hoping this will also
> help
>>   me build histograms for days of the week and for hours of the day.
> You need to split off the date from that column with:
> 
> data$date <- unlist(lapply(strsplit(data$time, " "), function(x) x[1]))  #
> get just date
> counts <- table(list(data$date, data$code))  # computes all the counts at
> once into matrix
> 

Ok, I'll try all this.

While I was writing this message, a few more answers came in. Let me try
all those before I reply to them.


Thanks to all,

L

-- 
Laurent Duperval <laurent.duperval at microcell.ca>

"I'm not going to so my maths homework. Look at these unsolved problems. Here's a number in mortal combat with another. One of them is going to get subtracted. But why? What will be left of him? If I answered these, it would kill the suspense. It would resolve the conflict and turn intriguing possibilities into boring old facts."
"I never really thought about the literary possibilities of maths."
"I prefer to savour the mystery."
                                           -Calvin & Hobbes


From rossini at blindglobe.net  Wed Mar 19 18:41:33 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 19 Mar 2003 09:41:33 -0800
Subject: [R]
In-Reply-To: <Pine.LNX.4.43.0303190857380.8524@hymn05.u.washington.edu>
	("Michael
	D. Ward"'s message of "Wed, 19 Mar 2003 08:57:38 -0800 (PST)")
References: <Pine.LNX.4.43.0303190857380.8524@hymn05.u.washington.edu>
Message-ID: <87fzpjjlte.fsf@jeeves.blindglobe.net>

"Michael D. Ward" <mdw at u.washington.edu> writes:


> Has anyone allocated more than one Gig of memory for R under
> Windows? When I try the diagnostic tells me I am decreasing memory
> and the memory size value is a very large negative number.
>
> I suspect the problem may be a signed integer that overflows. Is 1 G a hard
> limit for memory allocation in R under Windows?

Mike, you shouldn't need to allocate -- as of a few years back, R
allocs as needed.  You can set max size, but not sure why you would
sensibly want to do that, unless you are protecting other
executables. 

Also see R for Windows FAQ 2.6.

best,
-tony


-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------------
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(CHANGE: monday/wednesday/friday locations are completely unpredictable.)


From tblackw at umich.edu  Wed Mar 19 18:59:32 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 19 Mar 2003 12:59:32 -0500 (EST)
Subject: [R] Center of Closed Contour
In-Reply-To: <20030319170029.GA8925@pressroom.com>
Message-ID: <Pine.SOL.4.44.0303191250420.16678-100000@millipede.gpcc.itd.umich.edu>


I think you have to roll your own.  Best idea I can come up with is a
classic application of Monte Carlo integration.  Throw down a million
(say) random points, uniformly distributed throughout the 2D region
where the contours will be plotted.  For each point, evaluate whether
it is inside or outside the contours (equivalently, whether the surface
being contoured is above or below the contour level at this point).
Then calculate the sample mean of x coordinates, similarly y coordinates,
for all points which map inside the contour.  And ignore all random
points which fall outside the contour.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -


On Wed, 19 Mar 2003, Charles M. Fleming wrote:

> I am searching for a utility in R which will determine the mean location of
> a closed contour and eventually record the location in an ASCII file. By
> means of the contour utility in R, I am able to produce an image of a contour,
> but I am seeking a procedure which will produce the coordinates of the
> center of mass of the contour. From my actual set of data, the contour
> utility will produce several hundered closed non-intersecting and
> non-concentric contours like a lattice of disks. I want the location of
> those disks via a program. Is there any package in R which will lend
> itself to this problem?
>
> Thank you,
>
> Charles Fleming
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From tblackw at umich.edu  Wed Mar 19 19:14:19 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 19 Mar 2003 13:14:19 -0500 (EST)
Subject: [R] How would I analyse data like this?
In-Reply-To: <20030319164501.4972416BCA@mailserv.microcell.ca>
Message-ID: <Pine.SOL.4.44.0303191302440.16678-100000@millipede.gpcc.itd.umich.edu>

> ... the graph is too wide ... (from hist()).

Ah, yes.

Try setting parameter  xlim=c(0,1200)  in the call to hist().

If that doesn't work, then catch the return value from hist(),
and re-plot using barplot().  For example:

temp <- hist(data[[5]], breaks=c(50*(seq(11)-1), 1000, max(data[[5]])))
barplot(temp$counts, xlim=c(0,600))

-  tom blackwell  -  u michigan medical school  -  ann arbor  -


From abunn at montana.edu  Wed Mar 19 19:15:14 2003
From: abunn at montana.edu (Andy Bunn)
Date: Wed, 19 Mar 2003 11:15:14 -0700
Subject: [R] Time Series-like barplot?
Message-ID: <NEBBIPHDAMMOKDKPOFFIGEIICHAA.abunn@montana.edu>

I have data structured like the following:

> foo.mat <- matrix(NA, ncol = 5, nrow = 10)
> foo.mat[2:6,1] <- 1
> foo.mat[1:3,2] <- 1
> foo.mat[3:10,3] <- 1
> foo.mat[1:10,4] <- 1
> foo.mat[8:10,5] <- 1
> foo.mat
      [,1] [,2] [,3] [,4] [,5]
 [1,]   NA    1   NA    1   NA
 [2,]    1    1   NA    1   NA
 [3,]    1    1    1    1   NA
 [4,]    1   NA    1    1   NA
 [5,]    1   NA    1    1   NA
 [6,]    1   NA    1    1   NA
 [7,]   NA   NA    1    1   NA
 [8,]   NA   NA    1    1    1
 [9,]   NA   NA    1    1    1
[10,]   NA   NA    1    1    1

I am trying to create a plot with horizontal bars that has 1:10 on the
x-axis and plots the length of the data (i.e., 1) in the correct context.
E.g.,:

  5               ------
  4 --------------------
  3     ----------------
  2 -----
  1   ---------
   1-2-3-4-5-6-7-8-9-10


Does any body have a suggestion?

Thanks, Andy


From tblackw at umich.edu  Wed Mar 19 19:20:50 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 19 Mar 2003 13:20:50 -0500 (EST)
Subject: [R] Tukey's HSD
In-Reply-To: <5.1.0.14.0.20030318141937.020cfc40@localhost>
Message-ID: <Pine.SOL.4.44.0303191315530.16678-100000@millipede.gpcc.itd.umich.edu>

What function "simint()" ?

At least using R 1.6.1 (Redhat linux), help.search("simint")
returns "No help files found ...".

Also, it's no surprise that  na.omit()  might omit rows with NA's
but then NOT purge the levels attribute of each column that is a
factor for factor levels that are no longer used.  For a simple
example of this, try

table(def4$TP, def4$EL)

(or some such object names - I no longer have the body of the
original email).

-  tom blackwell  -  u michigan medical school  -  ann arbor  -


From apjaworski at mmm.com  Wed Mar 19 19:40:00 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Wed, 19 Mar 2003 12:40:00 -0600
Subject: [R] Tukey's HSD
Message-ID: <OFE435744B.5D75B2CB-ON86256CEE.00666D66@mmm.com>


Simint is in the multcomp package.

Cheers,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+-------------------------------->
|         |           Thomas W Blackwell   |
|         |           <tblackw at umich.edu>  |
|         |           Sent by:             |
|         |           r-help-bounces at stat.m|
|         |           ath.ethz.ch          |
|         |                                |
|         |                                |
|         |           03/19/2003 12:20     |
|         |                                |
|---------+-------------------------------->
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       "Peter B. Mandeville" <mandevip at uaslp.mx>                                                                    |
  |      cc:       r-help at stat.math.ethz.ch                                                                                     |
  |      Subject:  Re: [R] Tukey's HSD                                                                                          |
  >-----------------------------------------------------------------------------------------------------------------------------|




What function "simint()" ?

At least using R 1.6.1 (Redhat linux), help.search("simint")
returns "No help files found ...".

Also, it's no surprise that  na.omit()  might omit rows with NA's
but then NOT purge the levels attribute of each column that is a
factor for factor levels that are no longer used.  For a simple
example of this, try

table(def4$TP, def4$EL)

(or some such object names - I no longer have the body of the
original email).

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From volkswirt at gmx.net  Wed Mar 19 20:11:02 2003
From: volkswirt at gmx.net (volkswirt@gmx.net)
Date: Wed, 19 Mar 2003 20:11:02 +0100 (MET)
Subject: [R] 
Message-ID: <27255.1048101062@www55.gmx.net>

Dear Colleagues!   
Could you please tell me a command to remove a row or collumn from a 
matrix, to gain from e.g.: 
1 2 3 4 5 
6 7 8 9 0 
 
e.g.: 
1 3 4 5 
6 8 9 0 
 
Thank you in advance.


From jasont at indigoindustrial.co.nz  Wed Mar 19 20:13:18 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 20 Mar 2003 07:13:18 +1200
Subject: [R] How would I analyse data like this?
In-Reply-To: <20030319174022.B698216BCB@mailserv.microcell.ca>;
	from laurent.duperval@microcell.ca on Wed, Mar 19, 2003 at 12:40:20PM -0500
References: <20030319174022.B698216BCB@mailserv.microcell.ca>
Message-ID: <20030320071318.A24027@camille.indigoindustrial.co.nz>

On Wed, Mar 19, 2003 at 12:40:20PM -0500, laurent.duperval at microcell.ca wrote:
> On 19 Mar, james.holtman at convergys.com wrote:
> > Have you tried:
> >       data <- read.table("data.dat", header=TRUE, sep="|", as.is=TRUE)
> > 
> 
> Yes I did. However, it takes a LOT more time because of the date/time
> string. The result looks like this:
> 
> 
> str(data)
> `data.frame':	317437 obs. of  8 variables:
>  $ phone   : num  1.52e+10 1.42e+10 1.82e+10 1.65e+10 1.65e+10 ...
>  $ state   : int  3 3 3 3 3 3 3 3 3 3 ...
>  $ code    : int  983 983 983 983 3000 983 983 983 983 5203 ...
>  $ amount  : int  1000 1000 2500 2500 2500 1000 1000 2500 2500 2500 ...
>  $ left    : int  260 0 0 25 0 1260 273 0 0 0 ...
>  $ channel : Factor w/ 5 levels "CSR","IN","IVR",..: 2 5 4 2 3 2 2 3 4 3 ...
>  $ time    : Factor w/ 312198 levels "2002-10-16 ..",..: 1 2 3 4 5 6 7 8 9 10 ...
>  $ mtd     : Factor w/ 2 levels "C","D": 1 1 1 1 1 1 1 1 1 1 ...
> 
> I think the 312198 factor level is wrong. Also, the phone column is  a string,
> not a number. I didn't see how to specify that with read.table(). (In my
> original post, I think I forgot to mention that I had over 300,000 entries in
> my file).

Check out the colClasses argument to read.table.  Something like...

library(methods) #necessary for colClasses

data <- read.table("data.dat", header=TRUE, sep="|", 
		colClasses=c("character","integer","integer",
				"integer","integer","character","character",
				"character"))

You can convert the items you need to be factors after they're loaded,
like this...

data$mtd <- factor(data$mtd)

Hope it helps

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz


From macq at llnl.gov  Wed Mar 19 20:14:27 2003
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 19 Mar 2003 11:14:27 -0800
Subject: [R] Numerical precision and signif()
Message-ID: <p05200f0bba9e5c6827c0@[128.115.153.6]>

I have encountered something about signif() that I don't understand. 
It presents a problem for the situation in which I'm using it.

>  foo <- 3.7e7
>  formatC(foo,digits=22)
[1] "               37000000"
>  formatC(signif(foo,2),digits=22)
[1] "36999999.99999997764826"
>  formatC(signif(foo,3),digits=22)
[1] "36999999.99999997764826"
>  formatC(signif(foo,4),digits=22)
[1] "36999999.99999998509884"
>  formatC(signif(foo,5),digits=22)
[1] "36999999.99999999254942"
>  formatC(signif(foo,6),digits=22)
[1] "36999999.99999999254942"
>  formatC(signif(foo,7),digits=22)
[1] "               37000000"

The difference between foo and signif(foo,5) is large enough to make 
a practical difference:

>  signif(5.5e-7*foo,3)
[1] 20.4
>  signif(5.5e-7*signif(foo,5),3)
[1] 20.3

>  round(5.5e-7*foo,1)
[1] 20.4
>  round(5.5e-7*signif(foo,5),1)
[1] 20.3


(foo is a unit conversion factor; I shouldn't need to use signif() on 
it, but I was trying it as a workaround for another problem, and this 
came up. 5.5e-7 is a measurement whose units need to be converted)


While I'm at it, why is this?
>  format(0.037,dig=22)
[1] "0.037"
>  formatC(0.037,dig=22)
[1] "0.03699999999999999816813"



>  version
          _
platform sparc-sun-solaris2.7
arch     sparc
os       solaris2.7
system   sparc, solaris2.7
status
major    1
minor    6.2
year     2003
month    01
day      10
language R

Thanks
-Don
-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------


From dnogues at ipe.csic.es  Wed Mar 19 20:14:25 2003
From: dnogues at ipe.csic.es (=?ISO-8859-1?Q?David_Nogu=E9s?=)
Date: Wed, 19 Mar 2003 20:14:25 +0100
Subject: [R] graspeR problem
Message-ID: <3E78C191.2070701@ipe.csic.es>

Hi everybody

Im triying to develop a GAM using GraspeR, but i have found some problem 
in grasp.model

I always obtain same error:


RESPONSE NAME:  Aves
Error in "[.data.frame"(XXX, , c(1, sX)) :
        invalid subscript type

The data are a vector for response and a vector for predictors. They 
must be data.frame?

-- 
David Nogu?s Bravo

Functional Ecology and Biodiversity Department
Pyrenean Institute of Ecology
Spanish Research Council


From white.denis at epamail.epa.gov  Wed Mar 19 20:19:23 2003
From: white.denis at epamail.epa.gov (white.denis@epamail.epa.gov)
Date: Wed, 19 Mar 2003 11:19:23 -0800
Subject: [R] Center of Closed Contour
Message-ID: <OFB8F3780D.9A1F0D4C-ON88256CEE.00692E1F@rtp.epa.gov>

Although I had versions of the 2-D polygon centroid algorithm written in
C and Fortran years ago, I can't find them today.  The formula can be
found at http://astronomy.swin.edu.au/~pbourke/geometry/polyarea/.
Functions for calculating polygon area in R package "splancs" (function
areapl) or in R package "tripack" (function voronoi.area), might be
adaptable.

> I am searching for a utility in R which will determine the mean
location of
> a closed contour and eventually record the location in an ASCII file.
By
> means of the contour utility in R, I am able to produce an image of a
contour,
> but I am seeking a procedure which will produce the coordinates of the
> center of mass of the contour. From my actual set of data, the contour
> utility will produce several hundered closed non-intersecting and
> non-concentric contours like a lattice of disks. I want the location
of
> those disks via a program. Is there any package in R which will lend
> itself to this problem?


From krcabrer at perseus.unalmed.edu.co  Wed Mar 19 20:29:16 2003
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Wed, 19 Mar 2003 14:29:16 -0500
Subject: [R] Sorry for the mistake!
Message-ID: <oprmaq22kmfaouaq@200.24.8.4>

DDear R Users!
SSorry for the mistake!!!
II send you a .zip file of some database.
SI ask you for pardon!

KKenneth
-- 
Using M2, Opera's revolutionary e-mail client: http://www.opera.com/m2/


From laurent.duperval at microcell.ca  Wed Mar 19 20:28:07 2003
From: laurent.duperval at microcell.ca (laurent.duperval@microcell.ca)
Date: Wed, 19 Mar 2003 14:28:07 -0500 (EST)
Subject: [R] Some more general questions
Message-ID: <20030319192809.F3F0416BCB@mailserv.microcell.ca>

Hi,

Some general questions. I want to build a web page with numerical analysis
generated by R. I have a few questions:

- Can I control the output of a function? For example, if I do:

> summary(data[[5]])
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
    0.0     0.0   120.0   193.3   310.0 10290.0 

can I control the output to be something like

min=0
q1=0.0
q2=120.0
q3=193.3
max=10290.0

in order to parse with an external program?

- Yet another question on histograms: can I produce them with character
  strings? I'm guessing I need to map each character value to a numerical
  one and use that instead.

Thanks,

L

-- 
Laurent Duperval <laurent.duperval at microcell.ca>

"My doctor told me to stop having intimate dinners for four.  Unless there are
three other people." 
        - Orson Welles


From jasont at indigoindustrial.co.nz  Wed Mar 19 20:32:43 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 20 Mar 2003 07:32:43 +1200
Subject: [R]
In-Reply-To: <27255.1048101062@www55.gmx.net>;
	from volkswirt@gmx.net on Wed, Mar 19, 2003 at 08:11:02PM +0100
References: <27255.1048101062@www55.gmx.net>
Message-ID: <20030320073243.B24027@camille.indigoindustrial.co.nz>

On Wed, Mar 19, 2003 at 08:11:02PM +0100, volkswirt at gmx.net wrote:
> Dear Colleagues!   
> Could you please tell me a command to remove a row or collumn from a 
> matrix, to gain from e.g.: 
> 1 2 3 4 5 
> 6 7 8 9 0 
>  
> e.g.: 
> 1 3 4 5 
> 6 8 9 0 
>  

If mm is your matrix, mm[,-2] will do the above.  This is detailed
further in "An Introduction to R", section 2.7 (R-intro.pdf).

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz


From spencer.graves at pdf.com  Wed Mar 19 20:49:13 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 19 Mar 2003 11:49:13 -0800
Subject: [R]
References: <27255.1048101062@www55.gmx.net>
Message-ID: <3E78C9B9.1050005@pdf.com>

 > A <- array(1:6, dim=c(2,3))
 > A[,-2]
      [,1] [,2]
[1,]    1    5
[2,]    2    6

Is this what you want?
Spencer Graves

volkswirt at gmx.net wrote:
> Dear Colleagues!   
> Could you please tell me a command to remove a row or collumn from a 
> matrix, to gain from e.g.: 
> 1 2 3 4 5 
> 6 7 8 9 0 
>  
> e.g.: 
> 1 3 4 5 
> 6 8 9 0 
>  
> Thank you in advance.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Wed Mar 19 20:56:59 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 19 Mar 2003 11:56:59 -0800
Subject: [R] Time Series-like barplot?
References: <NEBBIPHDAMMOKDKPOFFIGEIICHAA.abunn@montana.edu>
Message-ID: <3E78CB8B.4090904@pdf.com>

The following produces thick lines like you requested:

	plot(c(1, 10), c(1, 5), type="n")
	for(j in 1:5)
	  lines(range(which(!is.na(foo.mat[,j]))), rep(j, 2), lwd=10)

If you want open bars, then draw boxes inside the loop.

Is this satisfactory?
Spencer Graves

Andy Bunn wrote:
> I have data structured like the following:
> 
> 
>>foo.mat <- matrix(NA, ncol = 5, nrow = 10)
>>foo.mat[2:6,1] <- 1
>>foo.mat[1:3,2] <- 1
>>foo.mat[3:10,3] <- 1
>>foo.mat[1:10,4] <- 1
>>foo.mat[8:10,5] <- 1
>>foo.mat
> 
>       [,1] [,2] [,3] [,4] [,5]
>  [1,]   NA    1   NA    1   NA
>  [2,]    1    1   NA    1   NA
>  [3,]    1    1    1    1   NA
>  [4,]    1   NA    1    1   NA
>  [5,]    1   NA    1    1   NA
>  [6,]    1   NA    1    1   NA
>  [7,]   NA   NA    1    1   NA
>  [8,]   NA   NA    1    1    1
>  [9,]   NA   NA    1    1    1
> [10,]   NA   NA    1    1    1
> 
> I am trying to create a plot with horizontal bars that has 1:10 on the
> x-axis and plots the length of the data (i.e., 1) in the correct context.
> E.g.,:
> 
>   5               ------
>   4 --------------------
>   3     ----------------
>   2 -----
>   1   ---------
>    1-2-3-4-5-6-7-8-9-10
> 
> 
> Does any body have a suggestion?
> 
> Thanks, Andy
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From vograno at arbitrade.com  Wed Mar 19 21:11:29 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Wed, 19 Mar 2003 14:11:29 -0600
Subject: [R] Some more general questions
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DD43@jupiter.arbitrade.com>

The answer to your first question is yes, you can. Under the hood a call
"summary(data[[5]])" invovles an implicit call to print() of the value
returned by summary(). This print produces the output you see. So you need
to suppress the default print and call one of your own, e.g.

> x <- summary(data[[5]])   # no print since the returned value is assigned
> my.custom.print(x)

A caviat, R will try to print the value returned by my.custom.print. To
suppress it the return value should be made invisible, e.g. put
invisible(NULL) in the end of my.custom.print

> -----Original Message-----
> From: laurent.duperval at microcell.ca
> [mailto:laurent.duperval at microcell.ca]
> Sent: Wednesday, March 19, 2003 11:28 AM
> To: R Help List
> Subject: [R] Some more general questions
> 
> 
> Hi,
> 
> Some general questions. I want to build a web page with 
> numerical analysis
> generated by R. I have a few questions:
> 
> - Can I control the output of a function? For example, if I do:
> 
> > summary(data[[5]])
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
>     0.0     0.0   120.0   193.3   310.0 10290.0 
> 
> can I control the output to be something like
> 
> min=0
> q1=0.0
> q2=120.0
> q3=193.3
> max=10290.0
> 
> in order to parse with an external program?
> 
> - Yet another question on histograms: can I produce them with 
> character
>   strings? I'm guessing I need to map each character value to 
> a numerical
>   one and use that instead.
> 
> Thanks,
> 
> L
> 
> -- 
> Laurent Duperval <laurent.duperval at microcell.ca>
> 
> "My doctor told me to stop having intimate dinners for four.  
> Unless there are
> three other people." 
>         - Orson Welles
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-------------------------------------------------- 
DISCLAIMER\ This e-mail, and any attachments thereto, is intende... [[dropped]]


From mschwartz at medanalytics.com  Wed Mar 19 21:11:36 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 19 Mar 2003 14:11:36 -0600
Subject: [R] Time Series-like barplot?
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIGEIICHAA.abunn@montana.edu>
Message-ID: <001601c2ee53$bf5bdcc0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Andy Bunn
>Sent: Wednesday, March 19, 2003 12:15 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Time Series-like barplot?
>
>
>I have data structured like the following:
>
>> foo.mat <- matrix(NA, ncol = 5, nrow = 10)
>> foo.mat[2:6,1] <- 1
>> foo.mat[1:3,2] <- 1
>> foo.mat[3:10,3] <- 1
>> foo.mat[1:10,4] <- 1
>> foo.mat[8:10,5] <- 1
>> foo.mat
>      [,1] [,2] [,3] [,4] [,5]
> [1,]   NA    1   NA    1   NA
> [2,]    1    1   NA    1   NA
> [3,]    1    1    1    1   NA
> [4,]    1   NA    1    1   NA
> [5,]    1   NA    1    1   NA
> [6,]    1   NA    1    1   NA
> [7,]   NA   NA    1    1   NA
> [8,]   NA   NA    1    1    1
> [9,]   NA   NA    1    1    1
>[10,]   NA   NA    1    1    1
>
>I am trying to create a plot with horizontal bars that has 
>1:10 on the x-axis and plots the length of the data (i.e., 1) 
>in the correct context.
>E.g.,:
>
>  5               ------
>  4 --------------------
>  3     ----------------
>  2 -----
>  1   ---------
>   1-2-3-4-5-6-7-8-9-10
>
>
>Does any body have a suggestion?
>
>Thanks, Andy


How about something like the following with your matrix 'foo.mat' in
place.  Somebody else may have (hopefully has) a more efficient
approach or knows of a function.

# Put together a matrix containing the positions
# in foo.mat that have a 1
v1 <- which(foo.mat == 1, arr.ind = TRUE)

# Now get range() for each group (bar)
v2 <- tapply(v1[ , 1], v1[, 2], range)

# Convert to matrix, in this case 5 x 2
v3 <- matrix(unlist(v2), ncol = 2, byrow = TRUE)

# Set up plot window w/ appropriate size
# Add one to y axis to have space below 
# and above bars
plot(c(1, max(v3)), c(0, dim(v3)[1] + 1), type = "n", axes = FALSE,
ann = FALSE)

# now draw bars using rect()
rect(v3[, 1], 1:dim(v3)[1] - 0.25, v3[, 2], 1:dim(v3)[1] + 0.25, col =
"grey")

# now draw axes
axis(1, at = 1:max(v3))
axis(2, at = 1:dim(v3)[1], las = 2)

# draw box around it
box()



Hope that helps,

Marc Schwartz


From JACQUELINE.LAW at ROCHE.COM  Wed Mar 19 21:12:55 2003
From: JACQUELINE.LAW at ROCHE.COM (Law, Jacqueline {Regu~Pleasanton})
Date: Wed, 19 Mar 2003 15:12:55 -0500
Subject: [R] Mixed effects model
Message-ID: <0F58D4CA9429D311B70A0090272A644611D9D0B4@rpbmsem1.ple.roche.com>

Dear all,

I am having troubles specifying the formula in the function aov. The model that I want to estimate is
   Y(i,j) = a + b*X1(i) + c*X2(j) + d*X1(i)*X2(j) + e(i,j)
where X1 is a factor variable, fixed
X2 is a factor variable, fixed
the interaction term X1*X2 is random

I would like to get the estimates for the fixed effects X1 and X2. 

Thanks very much for your help!

- Jacqueline


From tblackw at umich.edu  Wed Mar 19 21:23:27 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 19 Mar 2003 15:23:27 -0500 (EST)
Subject: [R] Some more general questions
In-Reply-To: <20030319192809.F3F0416BCB@mailserv.microcell.ca>
Message-ID: <Pine.SOL.4.44.0303191508020.5191-100000@robotron.gpcc.itd.umich.edu>

For summary(), yes, you can alter the way things are displayed.
It's easiest to think of capturing the output from summary() in
a temporary variable, then displaying that variable's value, but
this could also all be done as inline code.  For example,

temp <- summary(data[[5]])
print(cbind(names(temp), format(as.numeric(temp))), quote=F)

Second question:  calling  hist()  with a vector of character
strings doesn't work, and arguably, it shouldn't.  There's no
intrinsic notion of "interval" for character strings, no sense
in which you want to discretize continuous data into a set of
contiguous, discrete "bins".  Character strings are discrete
already.  So use  barplot(table(data[[ ? ]])).  (Can't remember
which columns in your exampel would have string values.)  Or
temp <- table(data) and print the result however you want.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -


On Wed, 19 Mar 2003 laurent.duperval at microcell.ca wrote:

> Some general questions.
>
> - Can I control the output of a function? For example, if I do:
> > summary(data[[5]])
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>     0.0     0.0   120.0   193.3   310.0 10290.0
>
> can I control the output to be something like
>
> min=0
> q1=0.0
> q2=120.0
> q3=193.3
> max=10290.0
>
> in order to parse with an external program?
>
> - Yet another question on histograms: can I produce them with character
>   strings? I'm guessing I need to map each character value to a numerical
>   one and use that instead.
>


From dunn at usq.edu.au  Thu Mar 20 00:56:48 2003
From: dunn at usq.edu.au (Peter Dunn)
Date: 20 Mar 2003 09:56:48 +1000
Subject: [R] The best way to end up with WMF files
Message-ID: <1048118208.10762.123.camel@grover.sci.usq.edu.au>

Hi all

I am doing some stats work for a group of biologists
who require windows metafiles (*.wmf) for their publications.
To create these, I appear to have two choices:

1.  Restart my machine in Windows and use  savePlot
2.  Keep my machine in linux, save as another format,
    then convert.

I'd rather stay in linux; but how do I get wmf files?  I looked
at using ImageMagick's  convert, but it appears only to *read*
wmf files and not write them according to the help (not that
I could get it to read them when I tried... but that's another
story).  

And if I do create another format first and eventually end up with
a wmf, what is the best way to get there without loosing quality
on the way through the conversion(s)?  

So my question is this:  How can I end up with a wmf files using
linux, without sacrificing too much (any?) quality on the way?

I looked in the Mail archives and couldn't find anything useful.

Thanks as always,

P.

-- 
Dr Peter Dunn          (USQ CRICOS No. 00244B)
  Web:    http://www.sci.usq.edu.au/staff/dunn
  Email:  dunn @ usq.edu.au
Opinions expressed are mine, not those of USQ.  Obviously...


From rossini at blindglobe.net  Thu Mar 20 01:29:15 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 19 Mar 2003 16:29:15 -0800
Subject: [R] The best way to end up with WMF files
In-Reply-To: <1048118208.10762.123.camel@grover.sci.usq.edu.au> (Peter
 Dunn's message of "20 Mar 2003 09:56:48 +1000")
References: <1048118208.10762.123.camel@grover.sci.usq.edu.au>
Message-ID: <87bs06yj6s.fsf@jeeves.blindglobe.net>

Peter Dunn <dunn at usq.edu.au> writes:

> I am doing some stats work for a group of biologists
> who require windows metafiles (*.wmf) for their publications.
> To create these, I appear to have two choices:
>
> 1.  Restart my machine in Windows and use  savePlot
> 2.  Keep my machine in linux, save as another format,
>     then convert.
>
> I'd rather stay in linux; but how do I get wmf files?  I looked
> at using ImageMagick's  convert, but it appears only to *read*
> wmf files and not write them according to the help (not that
> I could get it to read them when I tried... but that's another
> story).  
>
> And if I do create another format first and eventually end up with
> a wmf, what is the best way to get there without loosing quality
> on the way through the conversion(s)?  
>
> So my question is this:  How can I end up with a wmf files using
> linux, without sacrificing too much (any?) quality on the way?
>
> I looked in the Mail archives and couldn't find anything useful.

It is not clear that you can.  At least as of 9 months ago, there were
no decent *2wmf converters (decent = vector results, rather than crude
bitmaps).  

Best of luck, and if you find a good (non-bitmapped graphics)
solution, let us know!

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------------
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(CHANGE: monday/wednesday/friday locations are completely unpredictable.)


From sfalcon at fhcrc.org  Thu Mar 20 03:36:13 2003
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 19 Mar 2003 18:36:13 -0800
Subject: [R] The best way to end up with WMF files
In-Reply-To: <1048118208.10762.123.camel@grover.sci.usq.edu.au>
References: <1048118208.10762.123.camel@grover.sci.usq.edu.au>
Message-ID: <20030320023612.GA1857@queenbee.fhcrc.org>

> And if I do create another format first and eventually end up with
> a wmf, what is the best way to get there without loosing quality
> on the way through the conversion(s)?  

I've had success creating good looking png's using a hack with
bitmap().  Set res=200, and you'll end up with a png file with a very
large canvas.  If you open in Mozilla, for example, the plot will be
giant.  The image can then be resized when you import to ....

Everyone keeps telling me that you can use png() and get good
results, but I haven't been able to make that work yet.

For example, I've been able to import the png into Windows apps and
resize and have it look nice.  The same png's can be used (and
resized) for creating PDF with pdflatex.

+ seth


From kjetil at entelnet.bo  Thu Mar 20 03:29:24 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed, 19 Mar 2003 22:29:24 -0400
Subject: [R] 
In-Reply-To: <Pine.LNX.4.43.0303190857380.8524@hymn05.u.washington.edu>
Message-ID: <3E78EF44.12044.ADCA0D@localhost>

On 19 Mar 2003 at 8:57, Michael D. Ward wrote:

Please use a subject line!

I have a machine with 1.5Gb of physical memory, and have for a long 
time used --max-mem-size 2G, 
without any problems. Just yesterday that wasn't enough, so I tried 
to increase to --max-mem-size 4G, which was rejected by R. 
I lowered to 3G, and the program seemt to be running fine, but 
eventually I had to kill the process (hanging). 

This is windows XP professional. So, at least on XP, there is 
certainly not a hard coded limit of 1G. But why the limit somewhere 
between 3 and 4G?

Have others had problems with R processes eventually hanging on XP, 
if using more than 2G og memory?

Kjetil Halvorsen

> Has anyone allocated more than one Gig of memory for R under Windows? When I try the diagnostic tells me I am decreasing memory and the memory size value is a very large negative number.
> 
> I suspect the problem may be a signed integer that overflows. Is 1 G a hard
> limit for memory allocation in R under Windows?
> 
> 
> 
> Michael D. Ward
> University of Washington
> Seattle, WA, 98195-3530
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From bpeng at stat.rice.edu  Thu Mar 20 05:44:21 2003
From: bpeng at stat.rice.edu (Bo Peng)
Date: Wed, 19 Mar 2003 22:44:21 -0600
Subject: [R] R-1.6.2: installation problem on Solaris 2.8
Message-ID: <20030320044421.GA9792@stat.rice.edu>

Hello,

I tried to compile R-1.6.2 from source on Solaris 2.8. There is no 
problem with configure and make. However, `make test' fails with error 
message:

helpdesk at stat007:~/trial/R-1.6.2 % make check
make[1]: Entering directory `/home/helpdesk/trial/R-1.6.2/tests'
make[2]: Entering directory `/home/helpdesk/trial/R-1.6.2/tests'
make[3]: Entering directory `/home/helpdesk/trial/R-1.6.2/tests/Examples'
make[4]: Entering directory `/home/helpdesk/trial/R-1.6.2/tests/Examples'
make[4]: Leaving directory `/home/helpdesk/trial/R-1.6.2/tests/Examples'
make[4]: Entering directory `/home/helpdesk/trial/R-1.6.2/tests/Examples'
collecting examples for package 'base' ...
make[5]: Entering directory `/home/helpdesk/trial/R-1.6.2/src/library'
 >>> Building/Updating help pages for package 'base'
     Formats: text example 
make[5]: Leaving directory `/home/helpdesk/trial/R-1.6.2/src/library'
running code in 'base-Ex.R' ...make[4]: *** [base-Ex.Rout] Error 1
make[4]: Leaving directory `/home/helpdesk/trial/R-1.6.2/tests/Examples'
make[3]: *** [test-Examples-Base] Error 2
make[3]: Leaving directory `/home/helpdesk/trial/R-1.6.2/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/home/helpdesk/trial/R-1.6.2/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/home/helpdesk/trial/R-1.6.2/tests'
make: *** [check] Error 2

If I ignore this and run `make install' etc, R seems to be running fine 
untile I plot anything like `plot(1,1)'. One graphics window will appear 
and disappear, R will die saying 'bus error'.

I am using gcc 3.2.1, I can supply further info if necessary.

Thanks.

-- 
Bo Peng


From ripley at stats.ox.ac.uk  Thu Mar 20 08:29:00 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 20 Mar 2003 07:29:00 +0000 (GMT)
Subject: [R] R-1.6.2: installation problem on Solaris 2.8
In-Reply-To: <20030320044421.GA9792@stat.rice.edu>
Message-ID: <Pine.LNX.4.44.0303200727280.16595-100000@gannet.stats>

There is a bug in gcc-3.2.1 (and 3.2.2) on Solaris.  Don't use them.
It has been reported and acknowledged by the gcc maintainers.

On Wed, 19 Mar 2003, Bo Peng wrote:

> I tried to compile R-1.6.2 from source on Solaris 2.8. There is no 
> problem with configure and make. However, `make test' fails with error 
> message:

[...]

> I am using gcc 3.2.1, I can supply further info if necessary.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From v_bill_pikounis at merck.com  Thu Mar 20 12:17:12 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Thu, 20 Mar 2003 06:17:12 -0500
Subject: [R] The best way to end up with WMF files
Message-ID: <E827328028C66044B4998F2EC353CD300318531C@usrymx12.merck.com>

Hi Peter,

> And if I do create another format first and eventually end up with
> a wmf, what is the best way to get there without loosing quality
> on the way through the conversion(s)?  
> 
> So my question is this:  How can I end up with a wmf files using
> linux, without sacrificing too much (any?) quality on the way?

If I understand your questions correctly, one other potential option comes
from the libEMF ( http://libemf.sourceforge.net/ and
http://sourceforge.net/projects/libemf ) library and a tool called pstoedit
( http://www.pstoedit.net/pstoedit/ ). With these I have had some success
converting PostScript formatted (single) data graphs into Enhanced Windows
Metafile format (EMF) under Linux. My tests have not been extensive,
however, just some simple scatterplots with lowess curves and a couple of
the lattice/grid examples.  The quality of the graphs was acceptable to me
in these simple tests, and the desirable resolution characteristics of
vector-based graphs remained.  

Some fiddling was needed to get pstoedit to recognize libEMF at build time -
I use Mandrake 9.0.  The libEMF library in particular required some patches
to handle gcc 3.x. These patches have been submitted but the libEMF author
has not updated the original tarball yet.  The patches were fairly simple to
apply, although I did not document my path in doing so.  

Also, pstoedit runs under Windows, and the conversion to WMF/EMF is implicit
in its already built installer, so perhaps the biologists would not object
to doing the conversion from PostScript -> WMF directly on their machines?
(No GUI, of course, and ghostscript installation may be required if I
remember correctly, so I understand this may not be feasible for your target
audience. I also recall that the a flag to rotate the graphs was needed.)

Hope that helps,
Bill

----------------------------------------
Bill Pikounis, Ph.D.
Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

v_bill_pikounis at merck.com

Phone: 732 594 3913
Fax: 732 594 1565


> -----Original Message-----
> From: Peter Dunn [mailto:dunn at usq.edu.au]
> Sent: Wednesday, March 19, 2003 6:57 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] The best way to end up with WMF files
> 
> 
> Hi all
> 
> I am doing some stats work for a group of biologists
> who require windows metafiles (*.wmf) for their publications.
> To create these, I appear to have two choices:
> 
> 1.  Restart my machine in Windows and use  savePlot
> 2.  Keep my machine in linux, save as another format,
>     then convert.
> 
> I'd rather stay in linux; but how do I get wmf files?  I looked
> at using ImageMagick's  convert, but it appears only to *read*
> wmf files and not write them according to the help (not that
> I could get it to read them when I tried... but that's another
> story).  
> 
> And if I do create another format first and eventually end up with
> a wmf, what is the best way to get there without loosing quality
> on the way through the conversion(s)?  
> 
> So my question is this:  How can I end up with a wmf files using
> linux, without sacrificing too much (any?) quality on the way?
> 
> I looked in the Mail archives and couldn't find anything useful.
> 
> Thanks as always,
> 
> P.
> 
> -- 
> Dr Peter Dunn          (USQ CRICOS No. 00244B)
>   Web:    http://www.sci.usq.edu.au/staff/dunn
>   Email:  dunn @ usq.edu.au
> Opinions expressed are mine, not those of USQ.  Obviously...
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From mmarques at inescporto.pt  Thu Mar 20 12:48:35 2003
From: mmarques at inescporto.pt (Mmarques INESC)
Date: Thu, 20 Mar 2003 11:48:35 +0000
Subject: [R] Matrix problems
Message-ID: <17493393984.20030320114835@inescn.pt>

Hi all.
I do not know if it is a bug in the windows version but i have this
problem.
Reading a file with 200000 rows, 2 columns and transforming into a
200000 x 2 matrix.
If I try to find an element by using the which command which gives
some correct indexes plus some others passing the 200000 row
boundaries.
If I try to reach those "outbound" indexs I get an "Error: subscript out
of bounds" .
Is this a limitation of matrix function ? or am i doing something
wrong ?
Example :

 > str(mat1)
 num [1:200000, 1:2] 185 212 222 269 342 349 361 367 397 423 ...
 > which(mat1 == 185)
  [1]      1 201920 203792 205211 206604 220417 223767 225169 239420 243768 249351 249395 252077
 What could be happening ?

 Thanks in advance
 Mark Marques


From gb at stat.umu.se  Thu Mar 20 13:04:21 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 20 Mar 2003 13:04:21 +0100 (CET)
Subject: [R] Matrix problems
In-Reply-To: <17493393984.20030320114835@inescn.pt>
Message-ID: <Pine.LNX.4.44.0303201302160.1121-100000@tal.stat.umu.se>

On Thu, 20 Mar 2003, Mmarques INESC wrote:

> Hi all.
> I do not know if it is a bug in the windows version but i have this
> problem.
> Reading a file with 200000 rows, 2 columns and transforming into a
> 200000 x 2 matrix.
> If I try to find an element by using the which command which gives
> some correct indexes plus some others passing the 200000 row
> boundaries.
> If I try to reach those "outbound" indexs I get an "Error: subscript out
> of bounds" .
> Is this a limitation of matrix function ? or am i doing something
> wrong ?
> Example :
> 
>  > str(mat1)
>  num [1:200000, 1:2] 185 212 222 269 342 349 361 367 397 423 ...

>   [1]      1 201920 203792 205211 206604 220417 223767 225169 239420 243768 249351 249395 252077
>  What could be happening ?
>  > which(mat1 == 185)
mat1 is a matrix 200000x2 but also a vector of length 400000. Try

> ?which

and

> which(mat1 == 185, arr.ind = TRUE)

G?ran
---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


From gisar at nus.edu.sg  Thu Mar 20 13:30:58 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Thu, 20 Mar 2003 20:30:58 +0800
Subject: [R] Matrix problems
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F230@MBXSRV03.stf.nus.edu.sg>

  It 'unwraps' the 200,000 x 2 matrix into a vector with 400,000
elements and giving you the location/subscripts of this vector that
matches the criterion. Instead you should use  

apply(mat1, 2, function(y) which( y == 2 ))  

  which gives you the rows in each column that corresponds to 185.

Try length(mat1) and dim(mat1) and you will see that for length(), it
coerces the object into a vector first. 


-----Original Message-----
From: Mmarques INESC [mailto:mmarques at inescporto.pt] 
Sent: Thursday, March 20, 2003 7:49 PM
To: R-help Mailing list.
Subject: [R] Matrix problems


Hi all.
I do not know if it is a bug in the windows version but i have this
problem. Reading a file with 200000 rows, 2 columns and transforming
into a 200000 x 2 matrix. If I try to find an element by using the which
command which gives some correct indexes plus some others passing the
200000 row boundaries. If I try to reach those "outbound" indexs I get
an "Error: subscript out of bounds" . Is this a limitation of matrix
function ? or am i doing something wrong ? Example :

 > str(mat1)
 num [1:200000, 1:2] 185 212 222 269 342 349 361 367 397 423 ...  >
which(mat1 == 185)
  [1]      1 201920 203792 205211 206604 220417 223767 225169 239420
243768 249351 249395 252077
 What could be happening ?

 Thanks in advance
 Mark Marques

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From upton at mitre.org  Thu Mar 20 15:11:09 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Thu, 20 Mar 2003 09:11:09 -0500
Subject: [R] The best way to end up with WMF files
References: <E827328028C66044B4998F2EC353CD300318531C@usrymx12.merck.com>
Message-ID: <3E79CBFC.83FF99E1@mitre.org>

Hi Peter,

Have you looked at openoffice? http://www.openoffice.org/
It can import and export to a variety of formats, including WMF. It works on my
Windows version, not sure about the Linux version.

HTH
steve


> > -----Original Message-----
> > From: Peter Dunn [mailto:dunn at usq.edu.au]
> > Sent: Wednesday, March 19, 2003 6:57 PM
> > To: R-help at stat.math.ethz.ch
> > Subject: [R] The best way to end up with WMF files
> >
> >
> > Hi all
> >
> > I am doing some stats work for a group of biologists
> > who require windows metafiles (*.wmf) for their publications.
> > To create these, I appear to have two choices:
> >
> > 1.  Restart my machine in Windows and use  savePlot
> > 2.  Keep my machine in linux, save as another format,
> >     then convert.
> >
> > I'd rather stay in linux; but how do I get wmf files?  I looked
> > at using ImageMagick's  convert, but it appears only to *read*
> > wmf files and not write them according to the help (not that
> > I could get it to read them when I tried... but that's another
> > story).
> >
> > And if I do create another format first and eventually end up with
> > a wmf, what is the best way to get there without loosing quality
> > on the way through the conversion(s)?
> >
> > So my question is this:  How can I end up with a wmf files using
> > linux, without sacrificing too much (any?) quality on the way?
> >
> > I looked in the Mail archives and couldn't find anything useful.
> >
> > Thanks as always,
> >
> > P.
> >
> > --
> > Dr Peter Dunn          (USQ CRICOS No. 00244B)
> >   Web:    http://www.sci.usq.edu.au/staff/dunn
> >   Email:  dunn @ usq.edu.au
> > Opinions expressed are mine, not those of USQ.  Obviously...
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> ------------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ernesto at ipimar.pt  Thu Mar 20 16:02:15 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 20 Mar 2003 15:02:15 +0000
Subject: [R] [Fwd: Your message to R-help awaits moderator approval]
Message-ID: <1048172534.1305.17.camel@gandalf.ipimar.pt>

I've received this message from the R list. What is this ? Why is my
header "suspicious" ?

EJ

-----Forwarded Message-----

> From: r-help-bounces at stat.math.ethz.ch
> To: ernesto at ipimar.pt
> Subject: Your message to R-help awaits moderator approval
> Date: 20 Mar 2003 15:36:40 +0100
> 
> Your mail to 'R-help' with the subject
> 
>     combining dataframes
> 
> Is being held until the list moderator can review it for approval.
> 
> The reason it is being held:
> 
>     Message has a suspicious header
> 
> Either the message will get posted to the list, or you will receive
> notification of the moderator's decision.  If you would like to cancel
> this posting, please visit the following URL:
> 
>     https://www.stat.math.ethz.ch/mailman/confirm/r-help/c5faf8e878507308cb9ec9afd25782cbb1e96239


From ernesto at ipimar.pt  Thu Mar 20 16:09:17 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 20 Mar 2003 15:09:17 +0000
Subject: [R] dataframes (The message that once had a suspicious header)
Message-ID: <1048172957.1308.19.camel@gandalf.ipimar.pt>

Hi

I want to combine 2 dataframes (t1 and t2) in order to get a third one
(t3). The dataframes are below.

In SQL I would do something like:

SELECT t1.f1,t1.f2,t1.f3,t2.f4 FROM t1, t2
WHERE t1.f1=t2.f1 AND t1.f2=t2.f2

How can I do it with R ?

Thanks

EJ

> t1
  f1 f2 f3
1  A  C E1
2  A  D E2
3  B  C E3
4  B  D E4
> t2
  f1 f2 f4
1  A  C F1
2  A  C F2
3  B  C F3
4  B  C F4
5  A  D F5
6  A  D F6
> t3
  f1 f2 f3 f4
1  A  C E1 F1
2  A  C E1 F2
3  B  C E3 F3
4  B  C E3 F4
5  A  D E2 F5
6  A  D E2 F6


From bpeng at stat.rice.edu  Thu Mar 20 16:23:40 2003
From: bpeng at stat.rice.edu (Bo Peng)
Date: Thu, 20 Mar 2003 09:23:40 -0600
Subject: [R] R-1.6.2: installation problem on Solaris 2.8
In-Reply-To: <Pine.LNX.4.44.0303200727280.16595-100000@gannet.stats>
References: <20030320044421.GA9792@stat.rice.edu>
	<Pine.LNX.4.44.0303200727280.16595-100000@gannet.stats>
Message-ID: <20030320152340.GA12795@stat.rice.edu>

On Thu, Mar 20, 2003 at 07:29:00AM +0000, ripley at stats.ox.ac.uk wrote:

> > I tried to compile R-1.6.2 from source on Solaris 2.8. There is no 
> > problem with configure and make. However, `make test' fails with error 
> > message:

> [...]

> > I am using gcc 3.2.1, I can supply further info if necessary.

> There is a bug in gcc-3.2.1 (and 3.2.2) on Solaris.  Don't use them.
> It has been reported and acknowledged by the gcc maintainers.

That is unfortunate. Is there any work-around? I tried to set 
environment variable cpp as /usr/site/gcc-2.95.3/bin/gcc or gcc-3.0.4 
but ./configure says

...
checking command to parse /usr/ccs/bin/nm -p output... ok
checking how to run the C preprocessor... /usr/site/gcc-2.95.3/bin/gcc
configure: error: C preprocessor "/usr/site/gcc-2.95.3/bin/gcc" fails sanity check
See `config.log' for more details.

-- 
Bo Peng


From s-plus at wiwi.uni-bielefeld.de  Thu Mar 20 17:23:55 2003
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Thu, 20 Mar 2003 17:23:55 +0100
Subject: [R] dataframes (The message that once had a suspicious header)
References: <1048172957.1308.19.camel@gandalf.ipimar.pt>
Message-ID: <3E79EB1B.6D4C4AE6@wiwi.uni-bielefeld.de>


Ernesto Jardim wrote:

> Hi
>
> I want to combine 2 dataframes (t1 and t2) in order to get a third one
> (t3). The dataframes are below.
>
> In SQL I would do something like:
>
> SELECT t1.f1,t1.f2,t1.f3,t2.f4 FROM t1, t2
> WHERE t1.f1=t2.f1 AND t1.f2=t2.f2
>
> How can I do it with R ?
>
> Thanks
>
> EJ
>
> > t1
>   f1 f2 f3
> 1  A  C E1
> 2  A  D E2
> 3  B  C E3
> 4  B  D E4
> > t2
>   f1 f2 f4
> 1  A  C F1
> 2  A  C F2
> 3  B  C F3
> 4  B  C F4
> 5  A  D F5
> 6  A  D F6
> > t3
>   f1 f2 f3 f4
> 1  A  C E1 F1
> 2  A  C E1 F2
> 3  B  C E3 F3
> 4  B  C E3 F4
> 5  A  D E2 F5
> 6  A  D E2 F6
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Try function "merge". For details see: help(merge)

> t1
     [,1] [,2] [,3]
[1,] "A"  "C"  "E1"
[2,] "A"  "D"  "E2"
[3,] "B"  "C"  "E3"
[4,] "B"  "D"  "E4"
> t2
     [,1] [,2] [,3]
[1,] "A"  "C"  "F1"
[2,] "A"  "C"  "F2"
[3,] "B"  "C"  "F3"
[4,] "B"  "C"  "F4"
[5,] "A"  "D"  "F5"
[6,] "A"  "D"  "F6"
> merge(t1,t2,1:2)
  V1 V2 V3.x V3.y
1  A  C   E1   F1
2  A  C   E1   F2
3  A  D   E2   F5
4  A  D   E2   F6
5  B  C   E3   F3
6  B  C   E3   F4

--- Peter Wolf


From ligges at statistik.uni-dortmund.de  Thu Mar 20 18:27:45 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 Mar 2003 18:27:45 +0100 (MET)
Subject: [R] postscript problems
In-Reply-To: <200303190926.JAA19443@lebesgue.leeds.ac.uk>
Message-ID: <Pine.GSO.4.21.0303201822190.10069-100000@amadeus.statistik.uni-dortmund.de>



On Wed, 19 Mar 2003, Charles Taylor wrote:

> I am using R-1.6.1 and when I save a figure using
>
> dev.print(file="figure.eps")
> 
> and then insert this figure into a LaTeX file (using
> \includegraphics and the package graphicx) , the figure 
> obscures some nearby text (it gets blanked out by "white").
> 
> Comparing the postscript file to that produced by an earlier
> version of R I can see the extra lines marked with a star below:
> 
> 
> 
> %%Page: 1 1
> bp
> /bg { 1.0000 1.0000 1.0000 } def  *
> 0.00 0.00 841.89 595.28 r p2      *
> 204.83 90.14 318.71 513.85 cl     *
> 204.83 90.14 318.71 513.85 cl
> 
> 
> If I remove these 3 lines by hand the problem disappears, but
> surely there is an easier way!?

It works for a particular example on WinNT, R-1.6.2.
Please tell us your OS.
Please provide an example that reproduces your problem.

Uwe Ligges


From rg117 at yahoo.co.uk  Thu Mar 20 18:46:04 2003
From: rg117 at yahoo.co.uk (=?iso-8859-1?q?Rishabh=20Gupta?=)
Date: Thu, 20 Mar 2003 17:46:04 +0000 (GMT)
Subject: [R] Measure of Redundancy In Variables
Message-ID: <20030320174604.16040.qmail@web41105.mail.yahoo.com>

Hi all,
  I have a question which I guess is more of a general stats question than a specific R quetions.
I have a data set that contains a large number of numerical variables (in the hundreds). What I
would like to do is quantify the redundancy in those variables. Let me explain what I mean by
that.
If I use Principle Component Analysis (PCA) to reduce the amount of variables, the process
measures the relationship between the different variables and reorganises it so that each variable
provides unique information and removes any redundancy between different variables. What I would
like to do is a kind of measure between the data before PCA and after PCA. For example, if there
is no redundancy, i.e. all of the pre-PCA variables provide unique information, the redundancy
rate would be 100%. On the other hand if all the pre-PCA variables provide the same information
than the redundancy rate would be 1%.
Could anyone tell me if there is a method of measuring this redundancy rate or something similar
in R.
If somebody could help me with this issue it would be greatly appreciated. Many Thanks

Rishabh


From spencer.graves at pdf.com  Thu Mar 20 19:30:01 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 20 Mar 2003 10:30:01 -0800
Subject: [R] Measure of Redundancy In Variables
References: <20030320174604.16040.qmail@web41105.mail.yahoo.com>
Message-ID: <3E7A08A9.8020603@pdf.com>

Have you considered "factanal" in library "mva"?  How do the 
"uniquenesses" in the "factanal" object relate to what you want?  From 
what I read of your question, it sounds like they estimate exactly what 
you want.

Hope this helps.
Spencer Graves

Rishabh Gupta wrote:
> Hi all,
>   I have a question which I guess is more of a general stats question than a specific R quetions.
> I have a data set that contains a large number of numerical variables (in the hundreds). What I
> would like to do is quantify the redundancy in those variables. Let me explain what I mean by
> that.
> If I use Principle Component Analysis (PCA) to reduce the amount of variables, the process
> measures the relationship between the different variables and reorganises it so that each variable
> provides unique information and removes any redundancy between different variables. What I would
> like to do is a kind of measure between the data before PCA and after PCA. For example, if there
> is no redundancy, i.e. all of the pre-PCA variables provide unique information, the redundancy
> rate would be 100%. On the other hand if all the pre-PCA variables provide the same information
> than the redundancy rate would be 1%.
> Could anyone tell me if there is a method of measuring this redundancy rate or something similar
> in R.
> If somebody could help me with this issue it would be greatly appreciated. Many Thanks
> 
> Rishabh
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rg117 at yahoo.co.uk  Thu Mar 20 19:30:57 2003
From: rg117 at yahoo.co.uk (=?iso-8859-1?q?Rishabh=20Gupta?=)
Date: Thu, 20 Mar 2003 18:30:57 +0000 (GMT)
Subject: [R] ANOVA: F value >1 or < 1
Message-ID: <20030320183057.9402.qmail@web41103.mail.yahoo.com>

Hello,
  I have a question regarding anova. I am a bit comfused about the F value. My understanding is
that the F value indicates the ability of numerical variable V to discriminate between different
values of grouping variable G. If the F value is equal or close to 1.0, it means that all the
variances of the groups are similar and that V is unable to discriminate for G. On the other hand
if the F value is far from 1.0, it suggests that the variances of the groups are different.
The issues that I am comfused about is F values of <1 vs >1. My understanding is that the values
are equal to their reciprocal as far as the discriminance is concerned. So 0.5 is equivalent to
1/0.5. Could somebody please tell me whether this is correct or not, or whether I have got it
completely wrong.
 Your help is greatly apprecited. Many Thanks

Rishabh


From janetlim at econs.umass.edu  Thu Mar 20 19:56:41 2003
From: janetlim at econs.umass.edu (Jeannette Wicks-Lim)
Date: Thu, 20 Mar 2003 13:56:41 -0500
Subject: [R] Question about Error due to memory allocation issue
Message-ID: <1048186601.3e7a0ee9e700b@mail-4.oit.umass.edu>

Hi, 

I'm new to using R and I'm having problems in trying to do some quantile 
regressions with the package quantreg. When I try to use rq [specifically, I 
type in: rq(lnwagehr~lnmin1 +  lncpi +  ue03 + ue35 + ue57 + ue79, tau=.05, 
data=mydata, weights=pworwgt, method="fn", na.omit) ] , the computer churns for 
about 15 minutes and then spits out the following error message:

Error: cannot allocate vector of size 109035 Kb

I'm not sure what it going on but here is some (possibly) relevant info:

-My computer has 512Mb of memory
-My data set was originally in Stata and I read it into R using the package 
foreign
-My data set is VERY LARGE: about 1.4 million obs. The data set was 90Mb in 
Stata. The model I've tried to evaluate only has 5 variables, but I'd like to 
expand this to about 43 (I have lots of state and year dummies). 

I have tried using the command: memory.size(max=TRUE):
> memory.size(max=TRUE)
[1] 2076487680

but I then get (after submitting another rq command):

Error: cannot allocate vector of size 76324 Kb

Thanks very much for any help you can provide!

Jeannette Wicks-Lim
Department of Economics
University of Massachusetts, Amherst
Amherst, MA 01003


From m.moldovan at inbox.lv  Thu Mar 20 20:28:31 2003
From: m.moldovan at inbox.lv (Max Moldovan)
Date: Thu, 20 Mar 2003 21:28:31 +0200
Subject: [R] R help
Message-ID: <1048188511.3e7a165f8ba27@www2.inbox.lv>

Dear colleagues,

Where I can find datasets for exploring the ?detection of change-point in 
regression relationship? problem? I would appreciate any information about 
sources of such datasets inside or outside R. 

Thank you, 

Max




---
This message contains no viruses. 
Guaranteed by Kaspersky Anti-Virus.
www.antivirus.lv


From spencer.graves at pdf.com  Thu Mar 20 20:46:12 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 20 Mar 2003 11:46:12 -0800
Subject: [R] ANOVA: F value >1 or < 1
References: <20030320183057.9402.qmail@web41103.mail.yahoo.com>
Message-ID: <3E7A1A84.9040502@pdf.com>

	  The F ratio compares the variability between groups to a supposedly 
independent estimate of what that variability would be if there were no 
group effect.

	  If F is large (much greater than 1), it suggests that there probably 
is a group effect.

	  If F is small (quite close to 0), it suggests some other violation of 
assumptions.  This can occur in a balanced 2-way layout where factor A 
is unimportant while B is large but excluded from the model.

tst.df2 <- data.frame(A=rep(letters[1:2], each=2), B=rep(letters[1:2], 
2), y = rep(1:2, 2)+0.01*rnorm(4))

anova(lm(y~A, tst.df2))
Analysis of Variance Table

Response: y
           Df  Sum Sq Mean Sq F value Pr(>F)
A          1 0.00010 0.00010   2e-04 0.9896
Residuals  2 0.96970 0.48485

Hope this helps
Spencer Graves

Rishabh Gupta wrote:
> Hello,
>   I have a question regarding anova. I am a bit comfused about the F value. My understanding is
> that the F value indicates the ability of numerical variable V to discriminate between different
> values of grouping variable G. If the F value is equal or close to 1.0, it means that all the
> variances of the groups are similar and that V is unable to discriminate for G. On the other hand
> if the F value is far from 1.0, it suggests that the variances of the groups are different.
> The issues that I am comfused about is F values of <1 vs >1. My understanding is that the values
> are equal to their reciprocal as far as the discriminance is concerned. So 0.5 is equivalent to
> 1/0.5. Could somebody please tell me whether this is correct or not, or whether I have got it
> completely wrong.
>  Your help is greatly apprecited. Many Thanks
> 
> Rishabh
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From MSchwartz at medanalytics.com  Thu Mar 20 21:01:23 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 20 Mar 2003 14:01:23 -0600
Subject: [R] RH 8.0, Mozilla and help.start() - Deja Vu All Over Again....
Message-ID: <3E7A1E13.9060305@MedAnalytics.com>

Hi all,

In the continuing process of dealing with the upgrades to Mozilla under 
RH 8.0 Linux (present stable release is 1.3) and as a result, the 
"breakage" of R's help.start() function, which is a java applet based 
search engine, I wanted to point out to folks some key points of 
information.

If you are upgrading to Mozilla version 1.3 under RH 8.0 from an older 
version, even one of the devel versions such as 1.3a or 1.3b, you need 
to carefully read the Installation Notes at:

http://www.mozilla.org/releases/mozilla1.3/

Most significantly in this case, is that the RPMS for RH 8.0 of this 
version of Mozilla are compiled with gcc version 3.2.

The present official release of Java from Sun is not and therefore the 
Sun Java plugins for Mozilla will not work with 1.3, breaking 
help.start(). As of this writing Sun does not have a gcc 3.2 compiled 
Java download available, though is expected to in the near future.

In order to get help.start() working in this scenario, you need to 
download the gcc 3.2 compiled versions of Java from one of the 
Blackdown.org mirrors at:

http://www.blackdown.org/java-linux/mirrors.html

Once at the mirror of your choice, go into the JDK-1.4.1/i386/01 folder.

Download:

j2re-1.4.1-01-linux-i586-gcc3.2.bin
INSTALL-j2re
README

Be sure to read the README and INSTALL-j2re files carefully and fully.

The .bin file is the install executable and you of course, need to 
change the file attributes to make it executable after download. Note 
that by default this file will extract and install in its download 
directory and it does not prompt you for a target. Again, read the 
installation instructions carefully.

The key will be to remove the existing Java shortcut in your Mozilla 
plugins folder, which for me using Moz 1.3 is:

/usr/lib/mozilla-1.3/plugins

Depending upon what version of Java you presently have installed, the 
existing shortcut may be to .../javaplugin_oji.so or to 
.../libjavaplugin_oji.so.

Once you have installed the Blackdown.org version of Java as per the 
installation instructions, you will need to recreate the shortcut to the 
new Java plugin, which for me is:

/usr/java/j2re1.4.1/plugin/i386/mozilla/javaplugin_oji.so

Hence, in the /usr/lib/mozilla-1.3/plugins folder using a terminal as 
root, enter:

ln -s /usr/java/j2re1.4.1/plugin/i386/mozilla/javaplugin_oji.so

Of course, in each case, replace my path(s) with yours, if different.

Finally, be sure that in the Mozilla Preferences settings, you have BOTH 
Java and JavaScript enabled on the Advanced and Advanced/Scripts&Plugins 
tabs respectively.

Basically, once you have completed these steps, help.start() should work 
with Moz 1.3. If it is working properly, you should see a Mozilla status 
line message indicating that the Java applet has started ("Applet 
SearchEngine Started") when you go to the Search Engine & Keywords 
search page (not the initial page).

I hope that this information helps folks. This seems to be an ongoing 
(but hopefully not never ending) saga.

Best regards,

Marc Schwartz


From pingzhao at waffle.cs.dal.ca  Thu Mar 20 22:59:39 2003
From: pingzhao at waffle.cs.dal.ca (pingzhao)
Date: Thu, 20 Mar 2003 17:59:39 -0400
Subject: [R] Install R on unix
Message-ID: <3E86FC30@webmail.ucis.dal.ca>

Hello,

I just tried to install R (unix version), but I have 
not successed.

I download the file and uncompresssed it in a R folder.
then I used the following commands:

./configure
make

The attached are error message:
Could any one tell me how to fix it??

Thanks


R is now configured for sparc-sun-solaris2.6

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc  -g -O2
  C++ compiler:              g++  -g -O2
  Fortran compiler:          f77  -g

  X11 support:               yes
  Gnome support:             no
  Tcl/Tk support:            yes
  Readline support:          no

  R profiling support:       yes
  R as a shared library:     no

  Recommended packages:      yes

configure: WARNING: you cannot build DVI versions of the R manuals
configure: WARNING: you cannot build info versions of the R manuals
configure: WARNING: you cannot build PDF versions of the R manuals
slri05:/home/pingzhao/R/R-1.6.2> make
creating src/scripts/R.fe
mkdir -p -- ../../bin


Stata 6 installation
--------------------

The installation files are missing

(no action taken)
*** Error code 1
make: Fatal error: Command failed for target `install-cmds'
Current working directory /home/pingzhao/R/R-1.6.2/src/scripts
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /home/pingzhao/R/R-1.6.2/src/scripts
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /home/pingzhao/R/R-1.6.2/src
*** Error code 1
make: Fatal error: Command failed for target `R'


From mhoward at micron.com  Thu Mar 20 23:12:55 2003
From: mhoward at micron.com (mhoward)
Date: Thu, 20 Mar 2003 15:12:55 -0700
Subject: [R] Plot multi series on one plot
Message-ID: <D7E178FC91F3D21186A90008C7B9A5B81148492F@ntexchange09.micron.com>

R help,

How can I plot the below data table by Data ~ Site  and group by Grinder and Equip Id
so I get a chart like this Excel version? I have tried coplot with little success and lattice
makes a pretty good chart like I want, but I am using the DCOM so it does not display
correctly. I would like to make this using the base library if possible.

 <<...OLE_Obj...>> 



DATA TABLE

      BATCH EQUIPID     MEAN  RANGE    GRINDER   SITE    DATA
1   1010001    8 2250.073 461.01 GRD001 LOC001 2429.86
2   1010001    8 2250.073 461.01 GRD001 LOC002 2300.81
3   1010001    8 2250.073 461.01 GRD001 LOC003 2327.50
4   1010001    8 2250.073 461.01 GRD001 LOC004 2318.72
5   1010001    8 2250.073 461.01 GRD001 LOC005 2363.11
6   1010001    8 2250.073 461.01 GRD001 LOC006 2413.53
7   1010001    8 2250.073 461.01 GRD001 LOC007 2586.55
8   1010001    8 2250.073 461.01 GRD002 LOC001 2252.66
9   1010001    8 2250.073 461.01 GRD002 LOC002 2136.54
10  1010001    8 2250.073 461.01 GRD002 LOC003 2139.90
11  1010001    8 2250.073 461.01 GRD002 LOC004 2160.41
12  1010001    8 2250.073 461.01 GRD002 LOC005 2160.30
13  1010001    8 2250.073 461.01 GRD002 LOC006 2202.80
14  1010001    8 2250.073 461.01 GRD002 LOC007 2301.19
15  1010001    8 2250.073 461.01 GRD003 LOC001 2224.50
16  1010001    8 2250.073 461.01 GRD003 LOC002 2132.33
17  1010001    8 2250.073 461.01 GRD003 LOC003 2125.54
18  1010001    8 2250.073 461.01 GRD003 LOC004 2145.55
19  1010001    8 2250.073 461.01 GRD003 LOC005 2140.55
20  1010001    8 2250.073 461.01 GRD003 LOC006 2159.47
21  1010001    8 2250.073 461.01 GRD003 LOC007 2229.72
22  1010001    9 2229.146 460.00 GRD001 LOC001 2278.88
23  1010001    9 2229.146 460.00 GRD001 LOC002 2303.24
24  1010001    9 2229.146 460.00 GRD001 LOC003 2342.55
25  1010001    9 2229.146 460.00 GRD001 LOC004 2226.61
26  1010001    9 2229.146 460.00 GRD001 LOC005 2577.06
27  1010001    9 2229.146 460.00 GRD001 LOC006 2301.44
28  1010001    9 2229.146 460.00 GRD001 LOC007 2211.39
29  1010001    9 2229.146 460.00 GRD002 LOC001 2152.65
30  1010001    9 2229.146 460.00 GRD002 LOC002 2272.51
31  1010001    9 2229.146 460.00 GRD002 LOC003 2219.08
32  1010001    9 2229.146 460.00 GRD002 LOC004 2152.11
33  1010001    9 2229.146 460.00 GRD002 LOC005 2321.38
34  1010001    9 2229.146 460.00 GRD002 LOC006 2178.04
35  1010001    9 2229.146 460.00 GRD002 LOC007 2175.39
36  1010001    9 2229.146 460.00 GRD003 LOC001 2120.77
37  1010001    9 2229.146 460.00 GRD003 LOC002 2220.48
38  1010001    9 2229.146 460.00 GRD003 LOC003 2151.57
39  1010001    9 2229.146 460.00 GRD003 LOC004 2117.06
40  1010001    9 2229.146 460.00 GRD003 LOC005 2219.41
41  1010001    9 2229.146 460.00 GRD003 LOC006 2131.36
42  1010001    9 2229.146 460.00 GRD003 LOC007 2139.09

Mike


From mbell at jhsph.edu  Fri Mar 21 00:08:17 2003
From: mbell at jhsph.edu (Michelle L. Bell)
Date: Thu, 20 Mar 2003 18:08:17 -0500
Subject: [R] param() in R
Message-ID: <98fa43991dfa.991dfa98fa43@jhsph.edu>

Are there equivalent functions in R to the param() and parameters() in 
Splus?
Thank you.


From dederderian at micron.com  Fri Mar 21 00:39:53 2003
From: dederderian at micron.com (dederderian)
Date: Thu, 20 Mar 2003 16:39:53 -0700
Subject: [R] command line limit?
Message-ID: <CFEFA50C9BCAD21197470001FA7EBA6B0C0BFC37@ntexchange05.micron.com>

Is there a limit on the length of a command line in R?
Thanks,
Dan


From bpeng at stat.rice.edu  Fri Mar 21 03:48:31 2003
From: bpeng at stat.rice.edu (Bo Peng)
Date: Thu, 20 Mar 2003 20:48:31 -0600
Subject: [R] R-1.6.2: installation problem on Solaris 2.8
In-Reply-To: <20030320152340.GA12795@stat.rice.edu>
References: <20030320044421.GA9792@stat.rice.edu>
	<Pine.LNX.4.44.0303200727280.16595-100000@gannet.stats>
	<20030320152340.GA12795@stat.rice.edu>
Message-ID: <20030321024831.GA29264@stat.rice.edu>

> > There is a bug in gcc-3.2.1 (and 3.2.2) on Solaris.  Don't use them.
> > It has been reported and acknowledged by the gcc maintainers.

I changed to gcc-2.95.3 (by setting CC and CXX environment variables) 
and everything is fine now. 

Thanks.

-- 
Bo Peng


From dunn at usq.edu.au  Fri Mar 21 07:45:41 2003
From: dunn at usq.edu.au (Peter Dunn)
Date: 21 Mar 2003 16:45:41 +1000
Subject: [R] The best way to end up with TIFF {Was:  end up with WMF)
Message-ID: <1048229141.1541.44.camel@grover.sci.usq.edu.au>

Hi all

I posted a couple of days ago about how to end up with wmf files
eventually in R for linux.

The short answer was:  you (probably) can't...and don't!

The journal in question also accepts TIFF files, I am told (it's
a physiology journal).

So I adjust my question:  What is the best way to get TIFF files
out of R?  It can't create them directly as far as I can tell.
ImageMagick's convert can create TIFF; what is the best way to
get there from R?  Thru postscript first?

P. 
-- 
Dr Peter Dunn          (USQ CRICOS No. 00244B)
  Web:    http://www.sci.usq.edu.au/staff/dunn
  Email:  dunn @ usq.edu.au
Opinions expressed are mine, not those of USQ.  Obviously...


From ripley at stats.ox.ac.uk  Fri Mar 21 08:16:37 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 21 Mar 2003 07:16:37 +0000 (GMT)
Subject: [R] The best way to end up with TIFF {Was:  end up with WMF)
In-Reply-To: <1048229141.1541.44.camel@grover.sci.usq.edu.au>
Message-ID: <Pine.LNX.4.44.0303210713340.1729-100000@gannet.stats>

On 21 Mar 2003, Peter Dunn wrote:

> I posted a couple of days ago about how to end up with wmf files
> eventually in R for linux.
> 
> The short answer was:  you (probably) can't...and don't!
> 
> The journal in question also accepts TIFF files, I am told (it's
> a physiology journal).
> 
> So I adjust my question:  What is the best way to get TIFF files
> out of R?  It can't create them directly as far as I can tell.
> ImageMagick's convert can create TIFF; what is the best way to
> get there from R?  Thru postscript first?

Via PNG, probably, although bitmap() will automate going via postscript.
Note that TIFF is a multitude of formats, and not all tools accept all the 
sub-formats, in particular compression schemes, so I would use 
uncompressed TIFF.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Fri Mar 21 08:37:10 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 20 Mar 2003 23:37:10 -0800 (PST)
Subject: [R] Question about Error due to memory allocation issue
In-Reply-To: <1048186601.3e7a0ee9e700b@mail-4.oit.umass.edu>
Message-ID: <Pine.A41.4.44.0303202333410.59574-100000@homer20.u.washington.edu>

On Thu, 20 Mar 2003, Jeannette Wicks-Lim wrote:

> Hi,
>
> I'm new to using R and I'm having problems in trying to do some quantile
> regressions with the package quantreg. When I try to use rq [specifically, I
> type in: rq(lnwagehr~lnmin1 +  lncpi +  ue03 + ue35 + ue57 + ue79, tau=.05,
> data=mydata, weights=pworwgt, method="fn", na.omit) ] , the computer churns for
> about 15 minutes and then spits out the following error message:
>
> Error: cannot allocate vector of size 109035 Kb
>

This means that it tried to allocate 109035k on top of what was already
allocated, and couldn't.

You probably can't fit this model in the memory.  Fortunately you probably
don't want to.

You can almost certainly either aggregate to a smaller number of
observations or analyse subgroups of the data and get a more useful result
as well as one that R can compute.

	-thomas


From tlumley at u.washington.edu  Fri Mar 21 08:39:33 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 20 Mar 2003 23:39:33 -0800 (PST)
Subject: [R] 
In-Reply-To: <3E78EF44.12044.ADCA0D@localhost>
Message-ID: <Pine.A41.4.44.0303202337251.59574-100000@homer20.u.washington.edu>

On Wed, 19 Mar 2003, kjetil brinchmann halvorsen wrote:

> On 19 Mar 2003 at 8:57, Michael D. Ward wrote:
>
> Please use a subject line!
>
> I have a machine with 1.5Gb of physical memory, and have for a long
> time used --max-mem-size 2G,
> without any problems. Just yesterday that wasn't enough, so I tried
> to increase to --max-mem-size 4G, which was rejected by R.
> I lowered to 3G, and the program seemt to be running fine, but
> eventually I had to kill the process (hanging).
>
> This is windows XP professional. So, at least on XP, there is
> certainly not a hard coded limit of 1G. But why the limit somewhere
> between 3 and 4G?
>

Well, 4Gb is the maximum addressable with 32bit pointers and you would
need to fit the operating system and the R program in there as well as the
R heap.

	-thomas


From sue at xlsolutions-corp.com  Thu Mar 20 19:29:29 2003
From: sue at xlsolutions-corp.com (sue@xlsolutions-corp.com)
Date: Thu, 20 Mar 2003 13:29:29 -0500
Subject: [R] 
	COURSE***R/S-plus Fundamentals and Programming Techniques***April
	2003 - Boston and San Francisco
Message-ID: <1048184969.3e7a0889dc736@email.featureprice.com>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud
to announce a 2-day course: "R/S-plus Fundamentals and Programming Techniques".

**** Boston, MA-----------------> April 10-11
**** San Francisco -------------> April 28-29

Course Description:

This two-day R/S-plus course focuses on a broad spectrum of topics, 
from reading raw data to a comparison of R and S. We will learn 
the essentials of data manipulation, graphical visualization 
and R/S-plus programming. We will explore statistical data analysis tools,
including graphics with data sets. How to enhance your plots.
We will perform basic statistics and fit linear regression models. 
Participants are encouraged to bring data for interactive sessions


Course Outline:

- An Overview of R: Installation and Demonstration
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling 
- Generalized Linear Models
- Linear Regression
- Parametric Models, etc
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)



Payments are due AFTER the course and early-bird ends February 28.

Registration:

Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578 x221
Visit us: www.xlsolutions-corp.com/training.htm


Course Format:

This course consists of a series of short lectures with
demonstrations and interactive sessions for the participants.
Each student is provided with bound copies of the notes and
a CD-ROM containing all examples, exercises and software used
on the course.



Share Your Thoughts:

Are there any additional topics you would like for this course to address?
Would you like for this course to be offered in another city?

Please let us know by contributing to our recommendation list:
training at xlsolutions-corp.com.

========================================================================

R/S-Plus Fundamentals and Programming Techniques / Boston March 2003
Pre-registration Form (Please email or print and fax: 206-686-1578)
XLsolutions Corporation: For your Solutions needs, Consulting and Training.
www.xlsolutions-corp.com



Title...... First Name ................. Last Name....................

Organization..........................................................

Mailing Address.......................................................

.....................................................................

.....................................................................

Zip Code...................... Country.............................

Telephone........................... Fax ...............................

E-mail................................................................



Elvis Miller, PhD
Manager Training and Technical Support
North American Division
XLSolutions Corporation
Email: elvis at xlsolutions-corp.com
Phone: 206-686-1578
Web: www.xlsolutions-corp.com


From alessandro.semeria at cramont.it  Fri Mar 21 09:43:52 2003
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Fri, 21 Mar 2003 09:43:52 +0100
Subject: [R] Re: [BioC] mva functions
Message-ID: <OF6E91581F.4DB4FE57-ONC1256CF0.002F35A6-C1256CF0.002F445C@tomware.it>

Probably you have to set a new max value for the max 
amount of the "heap" memory, look at the R-help on 'memory.limit' 
function.

Good luck 
A.S.

----------------------------

Alessandro Semeria 
Models and Simulations Laboratory
The Environment Research Center - Montecatini (Edison Group), 
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: asemeria at cramont.it


From socher at stat.uni-muenchen.de  Fri Mar 21 09:45:08 2003
From: socher at stat.uni-muenchen.de (Anne-Laure Boulesteix)
Date: Fri, 21 Mar 2003 09:45:08 +0100
Subject: [R] CCA (Curvilinear Component Analysis)
Message-ID: <3E7AD114.7090706@stat.uni-muenchen.de>


Hi,
Does anyone know if  Curvilinear Component Analysis (CCA) or Curvilinear 
Distance Analysis (CDA) has already been implemented in R ? I couldn't 
find it.

Many thanks
Anne-Laure


From poizot at cnam.fr  Fri Mar 21 11:54:44 2003
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Fri, 21 Mar 2003 10:54:44 +0000
Subject: [R] Postscript PBs
Message-ID: <200303211054.44505.poizot@cnam.fr>

Hi,
I use R 1.6.2 under Mandrake9.0.
I've got a problem with the postscript files I try to creat.
When I look to the file with ghostview it's ok.
When I want to print it, I've got a blank page or a black page (fill of black 
encre)
I changed the printer (guessing it was my driver printer), it was the same.
Does anyone had the same problem and resolved it ?

-- 
Cordialy
----------------------------------------
Emmanuel POIZOT
Cnam/Intechmer
Digue de Collignon
50110 Tourlaville
T?l : (33)(0)2 33 88 73 42
Fax : (33)(0)2 33 88 73 39
-----------------------------------------


From poizot at cnam.fr  Fri Mar 21 12:35:51 2003
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Fri, 21 Mar 2003 11:35:51 +0000
Subject: [R] Postscript PB
Message-ID: <200303211135.51176.poizot@cnam.fr>

Hi,
I use R 1.6.2 under Mandrake9.0.
I've got a problem with the postscript files I try to creat.
When I look to the file with ghostview it's ok.
When I want to print it, I've got a blank page or a black page (fill of black 
encre)
I changed the printer (guessing it was my driver printer), it was the same.
Does anyone had the same problem and resolved it ?

-- 
Cordialement
----------------------------------------
Emmanuel POIZOT
Cnam/Intechmer
Digue de Collignon
50110 Tourlaville
T?l : (33)(0)2 33 88 73 42
Fax : (33)(0)2 33 88 73 39
-----------------------------------------


From Deschodt at waika9.com  Fri Mar 21 11:56:51 2003
From: Deschodt at waika9.com (vincent deschodt)
Date: Fri, 21 Mar 2003 11:56:51 +0100
Subject: [R] question
Message-ID: <000a01c2ef98$94cd5fb0$318f3e3e@revolution>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030321/ab748ea5/attachment.pl

From JonesW at kssg.com  Fri Mar 21 14:00:55 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Fri, 21 Mar 2003 13:00:55 -0000
Subject: [R] Integer manipulation
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE20D0@GIMLI>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030321/a183b846/attachment.pl

From tlumley at u.washington.edu  Fri Mar 21 14:58:28 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 21 Mar 2003 05:58:28 -0800 (PST)
Subject: [R] Integer manipulation
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB01EE20D0@GIMLI>
Message-ID: <Pine.A41.4.44.0303210551130.224474-100000@homer07.u.washington.edu>

On Fri, 21 Mar 2003, Wayne Jones wrote:

> Hi there,
>
> When I enter a particularly long number into R it rounds it down into
> scientific notation.
> For example,
>
> > 2510000002679
>
> [1] 2.51e+12
>
> How can I preserve the precision of the original number?

It has been preserved:
> a<-2510000002679
> 2510000000000-a
[1] -2679

For numbers above 2^31 (or whatever .Machine$integer.max is), you have to
use floating point, which gives you about 15 digits accuracy.

If you want to print a number to more digits than the default, use the
digits= option to print(), or change options(digits)

	-thomas


From ahmlatif at hotmail.com  Fri Mar 21 15:00:31 2003
From: ahmlatif at hotmail.com (Mahbub Latif)
Date: Fri, 21 Mar 2003 14:00:31 +0000
Subject: [R] trellis plot
Message-ID: <F197nvgK3AezAJVbufY0003750d@hotmail.com>

An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20030321/ebb2b888/attachment.html

From Barker at medtap.com  Fri Mar 21 15:19:45 2003
From: Barker at medtap.com (Barker, Chris)
Date: Fri, 21 Mar 2003 09:19:45 -0500
Subject: [R] Redundancy in Variables (and canonical correlation)
Message-ID: <079383C285621946A40346523D618A9F780FDB@exchange2000.medtap.com>


 Base on the earlier question: there is a "redundancy" measure for
Canonical Correlation "Canonical Correlation Redundancy Analysis". You
may be able to adapt it to your situation. 
 
See the 
paper by 
Stewart David W., Love W. (1968), A General Canonical Correlation Index,
Psychological Bulletin, 70, 160-163.

There are dozens of references to it and "canonical correlation
redundancy "
on a Google Search (many are pointers to the online SAS help). 





            Chris Barker
   Director of Statistical Research
    MEDTAP International, Inc.
           Redwood City, Ca
 
        www.medtap.com
 
          650 632 4218

>


From mmiller3 at iupui.edu  Fri Mar 21 15:34:09 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: 21 Mar 2003 09:34:09 -0500
Subject: [R] Plot multi series on one plot
In-Reply-To: <D7E178FC91F3D21186A90008C7B9A5B81148492F@ntexchange09.micron.com>
References: <D7E178FC91F3D21186A90008C7B9A5B81148492F@ntexchange09.micron.com>
Message-ID: <87wuis23ha.fsf@lumen.indyrad.iupui.edu>

>>>>> "mhoward" == mhoward  <mhoward at micron.com> writes:

    > R help, How can I plot the below data table by Data ~ Site
    > and group by Grinder and Equip Id so I get a chart like
    > this Excel version? I have tried coplot with little success
    > and lattice makes a pretty good chart like I want, but I am
    > using the DCOM so it does not display correctly. I would
    > like to make this using the base library if possible.

    >  <<...OLE_Obj...>>

Your excel plot did not come along with your message, so I'm not
quite sure what you're looking for.  I won't let that stop me
from suggesting something though!

I know you've said lattice is not working for you, but I still
recommend it - something like

 df <- read.table('tmp.dat',header=T)
 dotplot(SITE~DATA|GRINDER*EQUIPID, data=df)

Other wise you can use dotchart, which is in the base library.
Try something like this:

 dotchart(tapply(df$DATA, list(df$SITE,paste(df$GRINDER,df$EQUIPID)), mean))

Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine


From otoomet at econ.dk  Fri Mar 21 15:43:52 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Fri, 21 Mar 2003 15:43:52 +0100
Subject: [R] barplot legend size
Message-ID: <200303211443.h2LEhqe03202@punik.econ.au.dk>

Dear R-people,

are there any way to change the size of legend in barplot?  I have
tried various versions of cex, both as par(cex.*= ) and barplot(...,
cex.*= ).  So long without success.

Sincerely,

Ott

> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    5.1              
year     2002             
month    06               
day      17               
language R                
-- 
Ott Toomet
PhD Student

Dept. of Economics
?rhus University
Building 322
Universitetsparken
8000 ?rhus C
Denmark

otoomet at econ.au.dk
ph: (+45) 89 42 20 27
-------------------------------------------

 (o_         (*_         (O_         (o< -!  
//\         //\         //\         //\      
V_/_        V_/_        V_/_        V_/_     
					     
standard    drunken     shocked     noisy    
penguin     penguin     penguin     penguin


From mschwartz at medanalytics.com  Fri Mar 21 15:59:35 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 21 Mar 2003 08:59:35 -0600
Subject: [R] barplot legend size
In-Reply-To: <200303211443.h2LEhqe03202@punik.econ.au.dk>
Message-ID: <002d01c2efba$7d5e9020$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ott Toomet
>Sent: Friday, March 21, 2003 8:44 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] barplot legend size
>
>
>Dear R-people,
>
>are there any way to change the size of legend in barplot?  I 
>have tried various versions of cex, both as par(cex.*= ) and 
>barplot(..., cex.*= ).  So long without success.
>
>Sincerely,
>
>Ott

Ott,

When you say the size of the legend I presume that you mean the text
within the legend given that you are trying to use par("cex").

Instead of creating the legend within the barplot() call (ie.
barplot(...., legend = ....) ), remove the 'legend' argument and call
legend() after the barplot call with your legend specifications.

See ?legend, which provides additional formatting flexibility,
including position, text size and spacing options among others.

HTH,

Marc Schwartz


From rgentlem at jimmy.harvard.edu  Fri Mar 21 16:01:47 2003
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Fri, 21 Mar 2003 10:01:47 -0500
Subject: [R] ArrayAnalyzer and Bioconductor
Message-ID: <20030321100147.B14924@jimmy.harvard.edu>

Today, Insightful Corporation (www.insightful.com) is announcing the
availability of S+ArrayAnalyzer, a new, integrated module for S-PLUS
based on collaboration with the BioConductor Project
(www.bioconductor.org) - an open source and open development software
project for the analysis and comprehension of genomic data.

The collaboration between Insightful and BioConductor delivers
benefits to both commercial and academic researchers analyzing
microarray experiments:

- BioConductor's advanced analytics for genomic data will be available
  to a wider audience via a commercially supported product from
  Insightful, a long-established vendor with fully staffed tech
  support, training, and consulting.

- S+ArrayAnalyzer adds numerous features that can improve productivity
  for many users, such as installation, more data access and import
  options, a guided-workflow interface, interactive graphs with
  hyperlinked annotation, Web deployment of applications.

- Insightful will sponsor a graduate student position in the
  BioConductor project to help drive continued advancements and
  innovation in both the open source and commercial offerings.

- A new differential expression library (lpetest), written by
  Insightful and the University of Virginia, will be ported to R and
  made available on the Comprehensive R Archive Network (CRAN) and
  BioConductor in Summer 2003.

Spokespeople for BioConductor see the collaboration as helping ensure
the distribution and high-level end-user support of key research tools
to the broadest possible population of researchers. These people
include: S.Dudoit, Division of Biostatistics, University of
California, Berkeley; R.A. Irizarry, Department of Biostatistics,
Johns Hopkins University; V.J. Carey, Harvard Medical School;
R. Gentleman, Harvard School of Public Health.

Shawn Javid, Insightful's CEO had this to add, "The collaboration with
BioConductor is a blueprint for how Insightful can work with the open
source community to bring highly innovative data analysis applications
to the widest possible user base.  This cooperation improves the
analytic solutions available to our common base of S programmers and
the non-statisticians who benefit from using applications developed
with S-PLUS and R."

S+ArrayAnalyzer is available now with pricing for commercial and
academic organizations available by calling (800)569-0123 x479, or via
email at pharmasales at insightful.com


From chrysopa at insecta.ufv.br  Fri Mar 21 18:11:41 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Fri, 21 Mar 2003 14:11:41 -0300
Subject: [R] Trying to make a nested lme analysis
Message-ID: <20030321171017.M33537@insecta.ufv.br>

Hi,

I'm trying to understand the lme output and procedure.
I'm using the Crawley's book.

I'm try to analyse the rats example take from Sokal and Rohlf (1995).
I make a nested analysis using aov following the book.

> summary(rats)
    Glycogen       Treatment      Rat          Liver  
 Min.   :125.0   Min.   :1   Min.   :1.0   Min.   :1  
 1st Qu.:135.8   1st Qu.:1   1st Qu.:1.0   1st Qu.:1  
 Median :141.0   Median :2   Median :1.5   Median :2  
 Mean   :142.2   Mean   :2   Mean   :1.5   Mean   :2  
 3rd Qu.:150.0   3rd Qu.:3   3rd Qu.:2.0   3rd Qu.:3  
 Max.   :162.0   Max.   :3   Max.   :2.0   Max.   :3  

> attach(rats)
> Treatment <- factor(Treatment)
> Rat <- factor(Rat)
> Liver <- factor(Liver)

> model <- aov(Glycogen~Treatment/Rat/Liver+Error(Treatment/Rat/Liver))
> summary(model)

Error: Treatment
          Df  Sum Sq Mean Sq
Treatment  2 1557.56  778.78

Error: Treatment:Rat
              Df Sum Sq Mean Sq
Treatment:Rat  3 797.67  265.89

Error: Treatment:Rat:Liver
                    Df Sum Sq Mean Sq
Treatment:Rat:Liver 12  594.0    49.5

Error: Within
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 18 381.00   21.17               
> 

OK,

Then I try to make this analysis using lme.

> model <- lme(Glycogen~Treatment, random=~1|Treatment/Rat/Liver)
> summary(model)
Linear mixed-effects model fit by REML
 Data: NULL 
       AIC      BIC    logLik
  233.6213 244.0968 -109.8106

Random effects:
 Formula: ~1 | Treatment
        (Intercept)
StdDev:    3.541272

 Formula: ~1 | Rat %in% Treatment
        (Intercept)
StdDev:     6.00658

 Formula: ~1 | Liver %in% Rat %in% Treatment
        (Intercept) Residual
StdDev:    3.764883 4.600247

Fixed effects: Glycogen ~ Treatment 
Error in if (any(wchLv <- (as.double(levels(xtTab[, wchPval])) == 0))) { 
: 
	missing value where logical needed
In addition: Warning message: 
NaNs produced in: pt(q, df, lower.tail, log.p) 
> 

The random effects are correct, the variance component is OK:

In nested aov | In nested lme
Residual
21.1666       | 21.16227
Liver in Rats
14.16667      | 14.17434
Rats in Treatment
36.0648       | 36.079

But I not understand why the Fixed effects error?

What is the problem in my formula to make this analysis using lme?

Thanks for all
Inte
Ronaldo


--
|   //|\\   [*****************************]
|| ( ? ? )  [Ronaldo Reis J?nior          ]
|     V     [ESALQ/USP-Entomologia, CP-09 ]
||  / l \   [13418-900 Piracicaba - SP    ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ]
||/(linux)\ [chrysopa at insecta.ufv.br      ]
|/ (linux) \[ICQ#: 5692561                ]
||  ( x )   [*****************************]
||| _/ \_ Powered by Gnu/Debian Woody
-----------------------------------
Insecta - Entomologia
Departamento de Biologia Animal
Universidade Federal de Vi?osa
-----------------------------------


From kjetil at entelnet.bo  Fri Mar 21 18:35:20 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri, 21 Mar 2003 13:35:20 -0400
Subject: [R] rsync
Message-ID: <3E7B1518.5560.762452@localhost>

Hola!

I am now downloading r-devel to compile it on windows XP. The CRAN
source code page says "you will prefere to use rsync". I am googling 
around, and cannot find anything about rsync on windows. 

Anybody has any experience with rsync on windows?

Kjetil


From wolf at micro-biolytics.com  Fri Mar 21 19:42:57 2003
From: wolf at micro-biolytics.com (wolf@micro-biolytics.com)
Date: Fri, 21 Mar 2003 19:42:57 +0100
Subject: [R] Savitzky-Golay Derivative and Smoothing
Message-ID: <OF04E93EE0.E206DE81-ONC1256CF0.0066CF27@imtek.uni-freiburg.de>

Hello,

Is there any libary with the algorithms of the Savitzky-Golay Derivative
and Smoothing. I found the calculation on the web site
"www.galactic.com/algorithms/" but I'm to new in R so I cant programm it in
R.
Can someone help me?

Thanx
Andreas

micro-biolytics GmbH
Andreas Wolf

Georges-K?hler-Allee 102
D - 79110 Freiburg
Fon: +49-761-2037524
Fax: +49-761-2037522

eMail: wolf at micro-biolytics.com
Web:   http://www.micro-biolytics.com

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
CONFIDENTIALITY NOTICE

This e-mail is intended only for the addressee named above and may contain
confidential information. If you are not the intended recipient, please let
us know immediately by return e-mail and then delete this e-mail, without
disclosing or copying the contents.


From andy_liaw at merck.com  Fri Mar 21 18:59:33 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 21 Mar 2003 12:59:33 -0500
Subject: [R] Savitzky-Golay Derivative and Smoothing
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F89A@usrymx25.merck.com>

If I'm not mistaken, that's sort of local polynomial with even degree and
fixed bandwidth (based on my own interpretation of description in Numerical
Recipes).  You can do that with functions in the KernSmooth package.

HTH,
Andy

> -----Original Message-----
> From: wolf at micro-biolytics.com [mailto:wolf at micro-biolytics.com]
> Sent: Friday, March 21, 2003 1:43 PM
> To: R-help at lists.R-project.org
> Subject: [R] Savitzky-Golay Derivative and Smoothing
> 
> 
> Hello,
> 
> Is there any libary with the algorithms of the Savitzky-Golay 
> Derivative
> and Smoothing. I found the calculation on the web site
> "www.galactic.com/algorithms/" but I'm to new in R so I cant 
> programm it in
> R.
> Can someone help me?
> 
> Thanx
> Andreas
> 
> micro-biolytics GmbH
> Andreas Wolf
> 
> Georges-K?hler-Allee 102
> D - 79110 Freiburg
> Fon: +49-761-2037524
> Fax: +49-761-2037522
> 
> eMail: wolf at micro-biolytics.com
> Web:   http://www.micro-biolytics.com
> 
> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
> CONFIDENTIALITY NOTICE
> 
> This e-mail is intended only for the addressee named above 
> and may contain
> confidential information. If you are not the intended 
> recipient, please let
> us know immediately by return e-mail and then delete this 
> e-mail, without
> disclosing or copying the contents.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From kwan022 at stat.auckland.ac.nz  Fri Mar 21 20:05:52 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 22 Mar 2003 07:05:52 +1200 (NZST)
Subject: [R] rsync
In-Reply-To: <3E7B1518.5560.762452@localhost>
Message-ID: <Pine.LNX.4.33.0303220704150.5767-100000@stat56.stat.auckland.ac.nz>

Hi,

Perhaps have a look at 
http://optics.ph.unimelb.edu.au/help/rsync/rsync_pc1.html "Installing 
rsync on a Windows machine"?

FYI, I did a google search on "Using rsync on Windows" and found it.

On Fri, 21 Mar 2003, kjetil brinchmann halvorsen wrote:

> Date: Fri, 21 Mar 2003 13:35:20 -0400
> From: kjetil brinchmann halvorsen <kjetil at entelnet.bo>
> To: R-help at stat.math.ethz.ch
> Subject: [R] rsync
> 
> Hola!
> 
> I am now downloading r-devel to compile it on windows XP. The CRAN
> source code page says "you will prefere to use rsync". I am googling 
> around, and cannot find anything about rsync on windows. 
> 
> Anybody has any experience with rsync on windows?
> 
> Kjetil
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From sfalcon at fhcrc.org  Fri Mar 21 19:10:22 2003
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 21 Mar 2003 10:10:22 -0800
Subject: [R] rsync
In-Reply-To: <3E7B1518.5560.762452@localhost>
References: <3E7B1518.5560.762452@localhost>
Message-ID: <20030321181022.GD4420@queenbee.fhcrc.org>

> I am now downloading r-devel to compile it on windows XP. The CRAN
> source code page says "you will prefere to use rsync". I am googling 
> around, and cannot find anything about rsync on windows. 

You can use rsync on Windows via the Cygwin toolset (see
www.cygwin.com).  

I've also seen an rsync for windows written in Python, but haven't
tried it.  

+ seth


From rpeng at stat.ucla.edu  Fri Mar 21 19:39:13 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri, 21 Mar 2003 10:39:13 -0800 (PST)
Subject: [R] question
In-Reply-To: <000a01c2ef98$94cd5fb0$318f3e3e@revolution>
Message-ID: <Pine.GSO.4.10.10303211038530.26616-100000@quetelet.stat.ucla.edu>

Try using the `pixmap' package from CRAN.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Fri, 21 Mar 2003, vincent deschodt wrote:

> How can i open a  bmp image and transform it in a matrix of pixels?
> how can i save it after transform on matrix?
> (Sorry for my english i don't speak it very well)
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From jerome at hivnet.ubc.ca  Fri Mar 21 20:07:10 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Fri, 21 Mar 2003 11:07:10 -0800
Subject: [R] trellis plot
In-Reply-To: <F197nvgK3AezAJVbufY0003750d@hotmail.com>
References: <F197nvgK3AezAJVbufY0003750d@hotmail.com>
Message-ID: <200303211912.LAA10050@hivnet.ubc.ca>


Hi Latif,

You need to build your own panel function that will fit your purpose.
This will do what you want, but it's not very elegant. A better solution 
would have the panel function depend on the value of z. Any other suggestions 
on own to do this?

Jerome

library(lattice)

x <- c(rep(LETTERS[1:4],13), rep(LETTERS[4:1],12))

y <- rnorm(100)
z <- rep(1:2,50)
x <- c("A","B",x)
y <- c(-1.5,-2.5,y)
z <- c(1:2,z)
bwplot(y~factor(x)|z,layout=c(2,1), panel=function(x,y) 
 {
   panel.bwplot(x[-1],y[-1],horizontal=F)
   panel.xyplot(x[1],y[1],pch=20,cex=2,col="red")
 })


On March 21, 2003 06:00 am, you wrote:
> 
> Hi there,
> 
> I need some help about trellis plot. I have the following plot.
> 
> x <- c(rep(LETTERS[1:4],13), rep(LETTERS[4:1],12))
> 
> y <- rnorm(100)
> z <- rep(1:2,50)
> bwplot(y~factor(x)|z,layout=c(2,1),  panel=function(x,y) 
panel.bwplot(x,y,horizontal=F))
> 
> 
> Now I want to place "*" on the positions (1,-1.5) in the first panel and 
(2,-2.5) in the second panel. I need help on this.
> 
>  
> 
> Thanks.
> 
> 
> 
> Mahbub.


From reid_huntsinger at merck.com  Fri Mar 21 20:15:53 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri, 21 Mar 2003 14:15:53 -0500
Subject: [R] Install R on unix
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC3C2@uswpmx11.merck.com>

It looks like the Makefiles "make" is looking at aren't the ones configure
created. I did the install on solaris 2.6 with no problem just now. The line
about "Stata 6 installation" is certainly suspicious... maybe some makefiles
got overwritten somehow?

Can you start clean and try again?

Reid Huntsinger


-----Original Message-----
From: pingzhao [mailto:pingzhao at waffle.cs.dal.ca] 
Sent: Thursday, March 20, 2003 5:00 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Install R on unix


Hello,

I just tried to install R (unix version), but I have 
not successed.

I download the file and uncompresssed it in a R folder.
then I used the following commands:

./configure
make

The attached are error message:
Could any one tell me how to fix it??

Thanks


R is now configured for sparc-sun-solaris2.6

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc  -g -O2
  C++ compiler:              g++  -g -O2
  Fortran compiler:          f77  -g

  X11 support:               yes
  Gnome support:             no
  Tcl/Tk support:            yes
  Readline support:          no

  R profiling support:       yes
  R as a shared library:     no

  Recommended packages:      yes

configure: WARNING: you cannot build DVI versions of the R manuals
configure: WARNING: you cannot build info versions of the R manuals
configure: WARNING: you cannot build PDF versions of the R manuals
slri05:/home/pingzhao/R/R-1.6.2> make
creating src/scripts/R.fe
mkdir -p -- ../../bin


Stata 6 installation
--------------------

The installation files are missing

(no action taken)
*** Error code 1
make: Fatal error: Command failed for target `install-cmds'
Current working directory /home/pingzhao/R/R-1.6.2/src/scripts
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /home/pingzhao/R/R-1.6.2/src/scripts
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /home/pingzhao/R/R-1.6.2/src
*** Error code 1
make: Fatal error: Command failed for target `R'

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------


From sabrina.servanty at caramail.com  Fri Mar 21 20:21:36 2003
From: sabrina.servanty at caramail.com (sabrina servanty)
Date: Fri, 21 Mar 2003 20:21:36 +0100
Subject: [R] Problem with read.table
Message-ID: <1048274496002354@lycos-europe.com>

An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20030321/7d274a31/attachment.html

From erich.neuwirth at univie.ac.at  Fri Mar 21 20:35:07 2003
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Fri, 21 Mar 2003 20:35:07 +0100
Subject: [R] rsync
In-Reply-To: <20030321181022.GD4420@queenbee.fhcrc.org>
References: <3E7B1518.5560.762452@localhost>
	<20030321181022.GD4420@queenbee.fhcrc.org>
Message-ID: <3E7B696B.9090708@univie.ac.at>




Seth Falcon wrote:

>>I am now downloading r-devel to compile it on windows XP. The CRAN
>>source code page says "you will prefere to use rsync". I am googling 
>>around, and cannot find anything about rsync on windows. 
>>    
>>
>
>You can use rsync on Windows via the Cygwin toolset (see
>www.cygwin.com).  
>  
>

If you do that and also want to use Brian Ripley's toolkit for compiling,
you might get into trouble because of incompatible versions of
cygwin1.dll

I managed to get a working solution by using rsync from

http://optics.ph.unimelb.edu.au/help/rsync/rsync_pc1.html

and putting rsync.exe into the directory with brian's binaries (sed, 
grep, diff ...)
this rsync vversion can work with brian's version of cygwin1.dll.


From wagner at comp.ufla.br  Fri Mar 21 20:37:33 2003
From: wagner at comp.ufla.br (Wagner Silva)
Date: Fri, 21 Mar 2003 16:37:33 -0300 (BRT)
Subject: [R] 
Message-ID: <Pine.LNX.4.44.0303211636570.6898-100000@assembly.comp.ufla.br>



-- 
=====================================
      Wagner Silva
    wagner at comp.ufla.br
  Bacharel em Ci?ncia da Computa??o
Universidade Federal de Lavras


From ben at zoo.ufl.edu  Fri Mar 21 20:58:47 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Fri, 21 Mar 2003 14:58:47 -0500 (EST)
Subject: [R] Problem with read.table
In-Reply-To: <1048274496002354@lycos-europe.com>
Message-ID: <Pine.LNX.4.44.0303211458380.20775-100000@bolker.zoo.ufl.edu>


  Should that be sep="\t" ?

On Fri, 21 Mar 2003, sabrina servanty wrote:

> Dear all,
> 
> I was used to work on R1.6 and I have now passed on R1.6.2 but I can't read my
> file (and that is a big problem!!).
> I made a data sheet with some
> spreadsheet in Excell, and save it as separeted by tab .txt.
> I write in R
> read.table ("file.txt",h=T,sep="/t",dec=",")
> But R consider that I have only one column (eG one variable)!!!
> 
> I have tried a lot of thing (I don't wrote the spreadsheet,I have verified in word
> that my column was really separated by tabulation...) but I really don't find.
> It may be really simple but I'm not really good to speak with R!
> 
> Regards
> 
> Sabrina Servanty.
> 
> ______________________________________________________
> Bo?te aux lettres - Caramail - http://www.caramail.com
> 
> 
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From mschwartz at medanalytics.com  Fri Mar 21 20:55:55 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 21 Mar 2003 13:55:55 -0600
Subject: [R] Problem with read.table
In-Reply-To: <1048274496002354@lycos-europe.com>
Message-ID: <005901c2efe3$e344b260$0201a8c0@MARC>

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of sabrina
servanty
Sent: Friday, March 21, 2003 1:22 PM
To: R-help at stat.math.ethz.ch
Subject: [R] Problem with read.table


Dear all, 

I was used to work on R1.6 and I have now passed on R1.6.2 but I can't
read my 
file (and that is a big problem!!).
I made a data sheet with some 
spreadsheet in Excell, and save it as separeted by tab .txt.
I write in R
read.table ("file.txt",h=T,sep="/t",dec=",")
But R consider that I have only one column (eG one variable)!!!

I have tried a lot of thing (I don't wrote the spreadsheet,I have
verified in word 
that my column was really separated by tabulation....) but I really
don't find.
It may be really simple but I'm not really good to speak with R!

Regards

Sabrina Servanty.
---------------------------------

Sabrina,

Try reversing the "/" in your 'sep = "/t"' argument.  You have it
reveresed at the moment, assuming that is is copied here as you are
using it.

The tab character is:  "\t"

So the command should be:

read.table ("file.txt",h=T,sep="\t",dec=",")

HTH,

Marc Schwartz


From jerome at hivnet.ubc.ca  Fri Mar 21 20:57:30 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Fri, 21 Mar 2003 11:57:30 -0800
Subject: [R] Problem with read.table
In-Reply-To: <1048274496002354@lycos-europe.com>
References: <1048274496002354@lycos-europe.com>
Message-ID: <200303212002.MAA12218@hivnet.ubc.ca>


How about replacing "/t" by "\t" ?

Jerome


From spencer.graves at pdf.com  Fri Mar 21 21:02:39 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 21 Mar 2003 12:02:39 -0800
Subject: [R] Problem with read.table
References: <1048274496002354@lycos-europe.com>
Message-ID: <3E7B6FDF.4060103@pdf.com>

Have you tried "count.fields" to confirm that R thinks all records have 
the same number of fields?

Spencer Graves

sabrina servanty wrote:
> Dear all,
> 
> I was used to work on R1.6 and I have now passed on R1.6.2 but I can't 
> read my
> file (and that is a big problem!!).
> I made a data sheet with some
> spreadsheet in Excell, and save it as separeted by tab .txt.
> I write in R
> read.table ("file.txt",h=T,sep="/t",dec=",")
> But R consider that I have only one column (eG one variable)!!!
> 
> I have tried a lot of thing (I don't wrote the spreadsheet,I have 
> verified in word
> that my column was really separated by tabulation...) but I really don't 
> find.
> It may be really simple but I'm not really good to speak with R!
> 
> Regards
> 
> Sabrina Servanty.
> 
> ______________________________________________________
> Bo?te aux lettres - Caramail - http://www.caramail.com
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From sabrina.servanty at caramail.com  Fri Mar 21 21:29:27 2003
From: sabrina.servanty at caramail.com (sabrina servanty)
Date: Fri, 21 Mar 2003 21:29:27 +0100
Subject: [R] Re:problem with read.table
Message-ID: <1048278567000443@lycos-europe.com>

An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20030321/83441bde/attachment.html

From andy_liaw at merck.com  Fri Mar 21 21:36:52 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 21 Mar 2003 15:36:52 -0500
Subject: [R] manipulating "..." inside a function
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F89E@usrymx25.merck.com>

Dear R-help,

Can some one tell me how to do the following (if it's possible)?

Suppose I have a function like this:

f <- function(x, y, ...) {
    ## some code
    g(x, y, ...)
   ## some more code
}

The problem is that g() may not understand everything that comes through in
"...".  Is there a way to delete some component of "..." and then pass it to
g()?

Here's the description of the real problem:  f() is a panel.something
function, and g() is a model fitting function.  Lattice passes
"panel.number" as part of "..." to f(), and g() complains about unused
argument "panel.number".

I'd be very grateful for any help!

Cheers,
Andy


------------------------------------------------------------------------------


From matthew_wiener at merck.com  Fri Mar 21 21:48:01 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Fri, 21 Mar 2003 15:48:01 -0500
Subject: [R] manipulating "..." inside a function
Message-ID: <AEBD81486231A343B1813FE62D335225013177BD@usrymx15.merck.com>

As Brian Ripley pointed out in a recent post, you can just give g() its own
"..." argument.

Regards, 

Matt Wiener

-----Original Message-----
From: Liaw, Andy [mailto:andy_liaw at merck.com] 
Sent: Friday, March 21, 2003 3:37 PM
To: 'r-help at stat.math.ethz.ch'
Subject: [R] manipulating "..." inside a function


Dear R-help,

Can some one tell me how to do the following (if it's possible)?

Suppose I have a function like this:

f <- function(x, y, ...) {
    ## some code
    g(x, y, ...)
   ## some more code
}

The problem is that g() may not understand everything that comes through in
"...".  Is there a way to delete some component of "..." and then pass it to
g()?

Here's the description of the real problem:  f() is a panel.something
function, and g() is a model fitting function.  Lattice passes
"panel.number" as part of "..." to f(), and g() complains about unused
argument "panel.number".

I'd be very grateful for any help!

Cheers,
Andy


----------------------------------------------------------------------------
--

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

----------------------------------------------------------------------------
--
Notice: This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
may be confidential, proprietary copyrighted and/or legally privileged, and
is intended solely for the use of the individual or entity named on this
message.  If you are not the intended recipient, and have received this
message in error, please immediately return this by e-mail and then delete
it.

============================================================================
==


------------------------------------------------------------------------------


From ben at zoo.ufl.edu  Fri Mar 21 21:59:23 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Fri, 21 Mar 2003 15:59:23 -0500 (EST)
Subject: [R] manipulating "..." inside a function
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4F89E@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0303211557220.23483-100000@bolker.zoo.ufl.edu>


  I have a couple of slightly ugly functions to do this in my bbmisc 
package:

clean.args <- function(argstr,fn,extrabad=NULL,dots.ok=TRUE) {
  fnargs <- names(formals(fn))
  if (length(argstr)>0 && !("..." %in% fnargs && dots.ok))  {
    badargs <- !sapply(names(argstr),"%in%",c(fnargs,""))
    argstr <- argstr[!badargs]
  }
  for (i in extrabad)
    argstr[[i]] <- NULL
  argstr
}

remove.args <- function(argstr,fn) {
  fnargs <- names(formals(fn))
  argstr[!(names(argstr) %in% fnargs)]
}


On Fri, 21 Mar 2003, Liaw, Andy wrote:

> Dear R-help,
> 
> Can some one tell me how to do the following (if it's possible)?
> 
> Suppose I have a function like this:
> 
> f <- function(x, y, ...) {
>     ## some code
>     g(x, y, ...)
>    ## some more code
> }
> 
> The problem is that g() may not understand everything that comes through in
> "...".  Is there a way to delete some component of "..." and then pass it to
> g()?
> 
> Here's the description of the real problem:  f() is a panel.something
> function, and g() is a model fitting function.  Lattice passes
> "panel.number" as part of "..." to f(), and g() complains about unused
> argument "panel.number".
> 
> I'd be very grateful for any help!
> 
> Cheers,
> Andy
> 
> 
> ------------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From andy_liaw at merck.com  Fri Mar 21 22:40:57 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 21 Mar 2003 16:40:57 -0500
Subject: [R] manipulating "..." inside a function
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F89F@usrymx25.merck.com>

Thanks to those who responded.  I finally got by with some pretty ugly hack
(ceorcing ... to list, delete the unwanted part, add other arguments, and
use do.call).

Cheers,
Andy

> -----Original Message-----
> From: Ben Bolker [mailto:ben at zoo.ufl.edu]
> Sent: Friday, March 21, 2003 3:59 PM
> To: Liaw, Andy
> Cc: 'r-help at stat.math.ethz.ch'
> Subject: Re: [R] manipulating "..." inside a function
> 
> 
> 
>   I have a couple of slightly ugly functions to do this in my bbmisc 
> package:
> 
> clean.args <- function(argstr,fn,extrabad=NULL,dots.ok=TRUE) {
>   fnargs <- names(formals(fn))
>   if (length(argstr)>0 && !("..." %in% fnargs && dots.ok))  {
>     badargs <- !sapply(names(argstr),"%in%",c(fnargs,""))
>     argstr <- argstr[!badargs]
>   }
>   for (i in extrabad)
>     argstr[[i]] <- NULL
>   argstr
> }
> 
> remove.args <- function(argstr,fn) {
>   fnargs <- names(formals(fn))
>   argstr[!(names(argstr) %in% fnargs)]
> }
> 
> 
> On Fri, 21 Mar 2003, Liaw, Andy wrote:
> 
> > Dear R-help,
> > 
> > Can some one tell me how to do the following (if it's possible)?
> > 
> > Suppose I have a function like this:
> > 
> > f <- function(x, y, ...) {
> >     ## some code
> >     g(x, y, ...)
> >    ## some more code
> > }
> > 
> > The problem is that g() may not understand everything that 
> comes through in
> > "...".  Is there a way to delete some component of "..." 
> and then pass it to
> > g()?
> > 
> > Here's the description of the real problem:  f() is a 
> panel.something
> > function, and g() is a model fitting function.  Lattice passes
> > "panel.number" as part of "..." to f(), and g() complains 
> about unused
> > argument "panel.number".
> > 
> > I'd be very grateful for any help!
> > 
> > Cheers,
> > Andy
> > 
> > 
> > 
> --------------------------------------------------------------
> ----------------
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> -- 
> 318 Carr Hall                                bolker at zoo.ufl.edu
> Zoology Department, University of Florida    
> http://www.zoo.ufl.edu/bolker
> Box 118525                                   (ph)  352-392-5697
> Gainesville, FL 32611-8525                   (fax) 352-392-3704
> 
> 

------------------------------------------------------------------------------


From fharrell at virginia.edu  Sat Mar 22 13:32:47 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sat, 22 Mar 2003 07:32:47 -0500
Subject: [R] Two courses in Philadelphia
Message-ID: <20030322073247.3fbfa501.fharrell@virginia.edu>

I am presenting two courses in Philadelphia in May-June organized by Insightful Corporation.  These courses have hands-on workshops and have received excellent reviews from past participants (let me know if you want to see the reviews from previous years' courses).  Both courses are applicable to S-Plus and R users.  The second course covers regression modeling methods that are of interest to those who don't use either statistical computing package.
---------------------------------------------------------------------
S-Plus for Statistical Data Analysis and Graphics: May 28-30

This course covers data manipulation and overviews the use of S for bootstrapping, simulation, and sample size/power calculations.  General elements of constructing good graphics (with much reference to the work of Bill Cleveland) are covered after presenting a series of graphical horrors, and exploratory data analysis and Trellis/Lattice graphics are emphasized.  LaTeX, advanced statistical table making, statistical reporting, and reproducible research are covered briefly.  Many functions from the Hmisc library are covered.  For a full course description see http://www.insightful.com/services/course.asp?CID=26
---------------------------------------------------------------------
Regression Modeling Strategies: June 2-4

This course emphasizes statistical modeling methodology from my book Regression Modeling Strategies (Springer, 2001) and has workshops using the Design library.
Some of the key topics covered are how and where to "spend" degrees of freedom, data reduction, multiple imputation of missing predictor variables, relaxing nonlinearity assumptions, hazards of stepwise variable selection, handling interactions, model validation, and graphically displaying complex regression models.  A full course description may be found at http://www.insightful.com/services/course.asp?CID=27


To Register:	- Web: http://www.insightful.com/services/register.asp
		- Email: kkelly at insightful.com
		- Call Kim Kelly at: 800-569-0123 x278
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From ernesto at ipimar.pt  Thu Mar 20 15:41:02 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 20 Mar 2003 14:41:02 +0000
Subject: [R] combining dataframes
Message-ID: <1048171262.1308.14.camel@gandalf.ipimar.pt>

Hi

I want to combine 2 dataframes (t1 and t2) in order to get a third one
(t3). The dataframes are below.

In SQL I would do something like:

SELECT t1.f1,t1.f2,t1.f3,t2.f4 FROM t1, t2
WHERE t1.f1=t2.f1 AND t1.f2=t2.f2

How can I do it with R ?

Thanks

EJ

> t1
  f1 f2 f3
1  A  C E1
2  A  D E2
3  B  C E3
4  B  D E4
> t2
  f1 f2 f4
1  A  C F1
2  A  C F2
3  B  C F3
4  B  C F4
5  A  D F5
6  A  D F6
> t3
  f1 f2 f3 f4
1  A  C E1 F1
2  A  C E1 F2
3  B  C E3 F3
4  B  C E3 F4
5  A  D E2 F5
6  A  D E2 F6


From Richard.Reed at med.va.gov  Sat Mar 22 20:07:35 2003
From: Richard.Reed at med.va.gov (Reed, Richard W)
Date: Sat, 22 Mar 2003 11:07:35 -0800
Subject: [R] Sample weights
Message-ID: <469283227067D51191580000F8058ADF39A978@VHAPUGEXC2>

R Users
	I am a new user of R. I have sample weights that I would like to
apply to some of the variables in my data set. Where can I go for
information on how to do that?
Richard


From f0z6305 at labs.tamu.edu  Sat Mar 22 20:17:41 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Sat, 22 Mar 2003 13:17:41 -0600
Subject: [R] How to check a matrix is positive definite?
Message-ID: <000c01c2f0a7$b5789b20$8bd75ba5@IE.TAMU.EDU>

Hey, all

Given a square matrix, how can I check if this matrix
is positive definite or not?

Thanks.

Fred


From jfox at mcmaster.ca  Sat Mar 22 21:13:49 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 22 Mar 2003 15:13:49 -0500
Subject: [R] How to check a matrix is positive definite?
In-Reply-To: <000c01c2f0a7$b5789b20$8bd75ba5@IE.TAMU.EDU>
Message-ID: <5.1.0.14.2.20030322151206.01e27190@mcmail.cis.mcmaster.ca>

Dear Feng Zhang,

If the matrix is *symmetric* and positive-definite, then all of its 
eigenvalues are positive.

I hope that this helps,
  John

At 01:17 PM 3/22/2003 -0600, Feng Zhang wrote:

>Given a square matrix, how can I check if this matrix
>is positive definite or not?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From jfox at mcmaster.ca  Sat Mar 22 21:15:27 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 22 Mar 2003 15:15:27 -0500
Subject: [R] Sample weights
In-Reply-To: <469283227067D51191580000F8058ADF39A978@VHAPUGEXC2>
Message-ID: <5.1.0.14.2.20030322151446.01e6cad0@mcmail.cis.mcmaster.ca>

Dear Richard,

See the survey package.

John

At 11:07 AM 3/22/2003 -0800, Reed, Richard W wrote:
>         I am a new user of R. I have sample weights that I would like to
>apply to some of the variables in my data set. Where can I go for
>information on how to do that?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From spencer.graves at pdf.com  Sat Mar 22 21:15:00 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 22 Mar 2003 12:15:00 -0800
Subject: [R] How to check a matrix is positive definite?
References: <000c01c2f0a7$b5789b20$8bd75ba5@IE.TAMU.EDU>
Message-ID: <3E7CC444.10401@pdf.com>

 > tst <- array(c(1,2,2,1), dim=c(2,2))
 > eigen(tst)
$values
[1]  3 -1

$vectors
           [,1]       [,2]
[1,] 0.7071068  0.7071068
[2,] 0.7071068 -0.7071068

Does this answer your question?
Spencer Graves

Feng Zhang wrote:
> Hey, all
> 
> Given a square matrix, how can I check if this matrix
> is positive definite or not?
> 
> Thanks.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Richard.Reed at med.va.gov  Sat Mar 22 22:35:29 2003
From: Richard.Reed at med.va.gov (Reed, Richard W)
Date: Sat, 22 Mar 2003 13:35:29 -0800
Subject: [R] Sample weights
Message-ID: <469283227067D51191580000F8058ADF39A97E@VHAPUGEXC2>

Hi John--
	I haven't seen anything on the website that has a name like that. Do
you mean "The R Environment for Statistical Computing and Graphics:
Reference Manual"?
Richard

-----Original Message-----
From: John Fox [mailto:jfox at mcmaster.ca]
Sent: Saturday, March 22, 2003 12:15 PM
To: Reed, Richard W
Cc: 'r-help at lists.R-project.org'
Subject: Re: [R] Sample weights


Dear Richard,

See the survey package.

John

At 11:07 AM 3/22/2003 -0800, Reed, Richard W wrote:
>         I am a new user of R. I have sample weights that I would like to
>apply to some of the variables in my data set. Where can I go for
>information on how to do that?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From rossini at blindglobe.net  Sat Mar 22 22:52:04 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Sat, 22 Mar 2003 13:52:04 -0800
Subject: [R] Sample weights
In-Reply-To: <469283227067D51191580000F8058ADF39A97E@VHAPUGEXC2> ("Reed,
 Richard W"'s message of "Sat, 22 Mar 2003 13:35:29 -0800")
References: <469283227067D51191580000F8058ADF39A97E@VHAPUGEXC2>
Message-ID: <877karrrwb.fsf@jeeves.blindglobe.net>


No, John means that you need to install the survey package from CRAN,
which contains analytics for handling sample weights within the
context of various inferential tools.

There is some documentation that comes with it.

best,
-tony

"Reed, Richard W" <Richard.Reed at med.va.gov> writes:

> Hi John--
> 	I haven't seen anything on the website that has a name like that. Do
> you mean "The R Environment for Statistical Computing and Graphics:
> Reference Manual"?

> Richard
>
> -----Original Message-----
> From: John Fox [mailto:jfox at mcmaster.ca]
> Sent: Saturday, March 22, 2003 12:15 PM
> To: Reed, Richard W
> Cc: 'r-help at lists.R-project.org'
> Subject: Re: [R] Sample weights
>
>
> Dear Richard,
>
> See the survey package.
>
> John
>
> At 11:07 AM 3/22/2003 -0800, Reed, Richard W wrote:
>>         I am a new user of R. I have sample weights that I would like to
>>apply to some of the variables in my data set. Where can I go for
>>information on how to do that?
>
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------------
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(CHANGE: monday/wednesday/friday locations are completely unpredictable.)


From Richard.Reed at med.va.gov  Sat Mar 22 23:09:31 2003
From: Richard.Reed at med.va.gov (Reed, Richard W)
Date: Sat, 22 Mar 2003 14:09:31 -0800
Subject: [R] Sample weights
Message-ID: <469283227067D51191580000F8058ADF39A97F@VHAPUGEXC2>

Okay.Thanks, Tony.

-----Original Message-----
From: rossini at blindglobe.net [mailto:rossini at blindglobe.net]
Sent: Saturday, March 22, 2003 1:52 PM
To: Reed, Richard W
Cc: 'r-help at lists.R-project.org'
Subject: Re: [R] Sample weights



No, John means that you need to install the survey package from CRAN,
which contains analytics for handling sample weights within the
context of various inferential tools.

There is some documentation that comes with it.

best,
-tony

"Reed, Richard W" <Richard.Reed at med.va.gov> writes:

> Hi John--
> 	I haven't seen anything on the website that has a name like that. Do
> you mean "The R Environment for Statistical Computing and Graphics:
> Reference Manual"?

> Richard
>
> -----Original Message-----
> From: John Fox [mailto:jfox at mcmaster.ca]
> Sent: Saturday, March 22, 2003 12:15 PM
> To: Reed, Richard W
> Cc: 'r-help at lists.R-project.org'
> Subject: Re: [R] Sample weights
>
>
> Dear Richard,
>
> See the survey package.
>
> John
>
> At 11:07 AM 3/22/2003 -0800, Reed, Richard W wrote:
>>         I am a new user of R. I have sample weights that I would like to
>>apply to some of the variables in my data set. Where can I go for
>>information on how to do that?
>
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ --------------------
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(CHANGE: monday/wednesday/friday locations are completely unpredictable.)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From jmiyamot at u.washington.edu  Sun Mar 23 00:27:17 2003
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Sat, 22 Mar 2003 15:27:17 -0800 (PST)
Subject: [R] 
	extracting the names of the dataframe and variables in aov or lm
Message-ID: <Pine.A41.4.44.0303221525130.30968-100000@mead2.u.washington.edu>

Dear R Users,
   I want to write a function that applies to the dataframe and variables
that were used in a previous call to lm or aov.  In order to do this, I
need to write a function that applies to the output of lm or aov, and
yields the names of the dataframe and variables that were used in the lm
or aov analysis.
   For example, suppose that I give the command:

aov.out <- aov( Rt ~ Vis*Cmplx*Isi, data = Rt.data)

I want to write a function E that applies to aov.out such that

E(aov.out) = c("Rd.data", "Rt", "Vis", "Cmplx", "Isi").

In other words, I want to write an extractor function that yields the
dataframe and variables that were used in a previous call to lm or aov.  I
realize that aov.out$call shows this information, but I don't know how to
automatically extract the names of the dataframe and variables from
aov.out$call.  The reason I am trying to extract these names is that I
want to write a general purpose function that displays descriptive
statistics and plots that are relevant to an aov or lm analysis.  If I
could extract these names from previous aov or lm output, I wouldn't have
to mention them individually as inputs to my function.

John Miyamoto

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------


From highstat at highstat.com  Sun Mar 23 02:09:42 2003
From: highstat at highstat.com (Alain Zuur)
Date: Sun, 23 Mar 2003 01:09:42 +0000
Subject: [R] export lm object to ascii from batch mode
Message-ID: <5.2.0.9.2.20030323010005.00ba0cf0@mail.highstat.com>

An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20030323/cca98ac0/attachment.html

From spencer.graves at pdf.com  Sun Mar 23 02:45:56 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 22 Mar 2003 17:45:56 -0800
Subject: [R] export lm object to ascii from batch mode
References: <5.2.0.9.2.20030323010005.00ba0cf0@mail.highstat.com>
Message-ID: <3E7D11D4.9080808@pdf.com>

Did you try "sink"?

Spencer Graves

Alain Zuur wrote:
> Hi,
> 
> I'm running R in batch mode from Tcl. I'm using R code of the form:   
> tmp<-lm(Y ~ X)  
> 
> I would like to have the:   print(summary(tmp))
> output in an ascii file. In the same way/format as it would normally 
> appear in R.
> 
> Any suggestions would be very helpful (tried all the functions dump, 
> save, write, etc, their help files and archives..but I'm stuck).
> 
> Kind regards,
> 
> Alain
> 
> In a later stage, I want to do the same for the summary stuff of  
> step(), gam() and glm().
> 
> 
> 
> 
> 
> Dr Alain F. Zuur
> 
> NEW: Statistics course "Analysing Biological and Environmental Field Data"
> http://www.highstat.com <http://www.highstat.com/>
> 
> 
> Highland Statistics Ltd.
> Statistical courses, consultancy and data analysis
> 6 Laverock road
> Newburgh AB41 6FN
> Aberdeenshire
> United Kingdom
> Tel: +44 (0)1358 789293
> email: highstat at highstat.com
> 
> 
> Brodgar: Software for Multivariate Analysis and Multivariate Time Series 
> Analysis
> http://www.brodgar.com <http://www.brodgar.com/>
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From wolf at micro-biolytics.com  Sun Mar 23 05:03:07 2003
From: wolf at micro-biolytics.com (wolf@micro-biolytics.com)
Date: Sun, 23 Mar 2003 05:03:07 +0100
Subject: [R] Is there any good tool for Hanling Data on the Net
Message-ID: <OF7CC8F0E0.85A5C98C-ONC1256CF2.0016420A@imtek.uni-freiburg.de>

Hello,

Is there any good windows-tool in the internet(shareware or Freeware) for
hanling and manipulating data. Currently I'm using excel, but there are
plenty of limetations on this program e.g. im working with svm's and I need
a lot more colums for my data. Because of this the handling of my data is
very time intensive and I'm now looking for a simple program witch can
handle my data (read data, ad data, transpond data etc.)

Thanx Andreas


From ripley at stats.ox.ac.uk  Sun Mar 23 07:00:22 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 23 Mar 2003 06:00:22 +0000 (GMT)
Subject: [R] memory usage on Windows (was no subject)
In-Reply-To: <3E78EF44.12044.ADCA0D@localhost>
Message-ID: <Pine.LNX.4.44.0303230554420.17623-100000@gannet.stats>

On Wed, 19 Mar 2003, kjetil brinchmann halvorsen wrote:

> On 19 Mar 2003 at 8:57, Michael D. Ward wrote:
> 
> Please use a subject line!

Yes, please do follow your own advice!

> I have a machine with 1.5Gb of physical memory, and have for a long 
> time used --max-mem-size 2G, 
> without any problems. Just yesterday that wasn't enough, so I tried 
> to increase to --max-mem-size 4G, which was rejected by R. 
> I lowered to 3G, and the program seemt to be running fine, but 
> eventually I had to kill the process (hanging). 
> 
> This is windows XP professional. So, at least on XP, there is 
> certainly not a hard coded limit of 1G. But why the limit somewhere 
> between 3 and 4G?
> 
> Have others had problems with R processes eventually hanging on XP, 
> if using more than 2G og memory?

XP is said to have a 2Gb limit for the user memory address space.  So does
Windows 2000 Professional, but Server is said to have 3Gb.  That's for all
processes, not per process.  So I would expect a 2Gb or 3Gb limit, from 
the OS, not R.

As the documentation says (in the CHANGES file), up to 1700Mb has been
used successfully on 2000/XP.

> 
> Kjetil Halvorsen
> 
> > Has anyone allocated more than one Gig of memory for R under Windows? When I try the diagnostic tells me I am decreasing memory and the memory size value is a very large negative number.
> > 
> > I suspect the problem may be a signed integer that overflows. Is 1 G a hard
> > limit for memory allocation in R under Windows?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pooh at hus.osaka-u.ac.jp  Sun Mar 23 08:07:22 2003
From: pooh at hus.osaka-u.ac.jp (MIYAMOTO Yusuke)
Date: Sun, 23 Mar 2003 16:07:22 +0900
Subject: [R]  extracting the names of the dataframe and variables in aov
 or lm
In-Reply-To: <Pine.A41.4.44.0303221525130.30968-100000@mead2.u.washington.edu>
References: <Pine.A41.4.44.0303221525130.30968-100000@mead2.u.washington.edu>
Message-ID: <20030323160722.72183e76.pooh@hus.osaka-u.ac.jp>

Hello, John:

How about this?
 >  df.name  <- aov.out$call$data
 > var.names <- names(aov.out$model)

I think it works to achieve your goals, but it may be 
that there are more elegant ways.

# By the way, I guess you're an experimental/cognitive psychologist
# from variable names in your example.  It's my joy, because there are 
# few R-users in my circle.

--
  MIYAMOTO Yusuke
  Graduate School of Human Sciences, Osaka University
  <pooh at hus.osaka-u.ac.jp>
  http://koko15.hus.osaka-u.ac.jp/~yusuke/


On Sat, 22 Mar 2003 15:27:17 -0800 (PST)
John Miyamoto <jmiyamot at u.washington.edu> wrote:

> Dear R Users,
>    I want to write a function that applies to the dataframe and variables
> that were used in a previous call to lm or aov.  In order to do this, I
> need to write a function that applies to the output of lm or aov, and
> yields the names of the dataframe and variables that were used in the lm
> or aov analysis.
>    For example, suppose that I give the command:
> 
> aov.out <- aov( Rt ~ Vis*Cmplx*Isi, data = Rt.data)
> 
> I want to write a function E that applies to aov.out such that
> 
> E(aov.out) = c("Rd.data", "Rt", "Vis", "Cmplx", "Isi").
> 
> In other words, I want to write an extractor function that yields the
> dataframe and variables that were used in a previous call to lm or aov.  I
> realize that aov.out$call shows this information, but I don't know how to
> automatically extract the names of the dataframe and variables from
> aov.out$call.  The reason I am trying to extract these names is that I
> want to write a general purpose function that displays descriptive
> statistics and plots that are relevant to an aov or lm analysis.  If I
> could extract these names from previous aov or lm output, I wouldn't have
> to mention them individually as inputs to my function.
> 
> John Miyamoto
> 
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
> Homepage http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From TyagiAnupam at aol.com  Sun Mar 23 18:47:58 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Sun, 23 Mar 2003 12:47:58 EST
Subject: [R] combining dataframes
Message-ID: <11a.203da053.2baf4d4e@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030323/2780ec05/attachment.pl

From gulisija at calshp.cals.wisc.edu  Sun Mar 23 20:41:34 2003
From: gulisija at calshp.cals.wisc.edu (Davorka Gulisija)
Date: Sun, 23 Mar 2003 13:41:34 -0600 (CST)
Subject: [R] Loess
Message-ID: <Pine.GHP.4.44.0303231324370.16592-100000@calshp.cals.wisc.edu>


Hi,


I am using Loess.smooth (Modreg) in order to infer certain relationship
for the data set of ~130,000 observations with ~300 distinct values of
single predictor. I understand that fitted values (y-hat) are just 300
Weighted LS fits in certain neighborhood of predictors. I am bit confused about
how exactly is this neighborhood assigned . Say I choose spanning
parameter = .5, for each LS analysis 75000 observations should be used.
However, intuitively it doesn't seem right since points are not equally
distributed among predictors and there are many observations for a single
value of predictor.

I would appreciate if someone could clear this for me.

Thank you,


Davorka


From ripley at stats.ox.ac.uk  Sun Mar 23 20:54:52 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 23 Mar 2003 19:54:52 +0000 (GMT)
Subject: [R] Loess
In-Reply-To: <Pine.GHP.4.44.0303231324370.16592-100000@calshp.cals.wisc.edu>
Message-ID: <Pine.LNX.4.44.0303231947450.18095-100000@gannet.stats>

On Sun, 23 Mar 2003, Davorka Gulisija wrote:

> I am using Loess.smooth (Modreg) in order to infer certain relationship

I presume you mean loess.smooth in package modreg?  (People do sometimes 
modify functions and (un-)capitalize the names.)

> for the data set of ~130,000 observations with ~300 distinct values of
> single predictor. I understand that fitted values (y-hat) are just 300
> Weighted LS fits in certain neighborhood of predictors. 

That is not what ?loess.smooth says it does, and it does what its help 
says not what you claim -- you seem to be confusing loess.smooth with 
loess.

> I am bit confused about
> how exactly is this neighborhood assigned . Say I choose spanning
> parameter = .5, for each LS analysis 75000 observations should be used.
> However, intuitively it doesn't seem right since points are not equally
> distributed among predictors and there are many observations for a single
> value of predictor.
> 
> I would appreciate if someone could clear this for me.

The help pages and their references will help you clear up your confusion:  
the source code is the ultimate authority.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Sun Mar 23 22:34:09 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 23 Mar 2003 22:34:09 +0100
Subject: [R] param() in R
References: <98fa43991dfa.991dfa98fa43@jhsph.edu>
Message-ID: <3E7E2851.E9268B01@statistik.uni-dortmund.de>

"Michelle L. Bell" wrote:
> 
> Are there equivalent functions in R to the param() and parameters() in
> Splus?

These functions are designed to work on pframe objects in S-PLUS. A
"pframe" class is not defined in R, AFAIK.

Consider to work object-oriented (e.g. create a S4 class with package
methods) and build a class for which the required(?) "parameters" are
well defined.

Uwe Ligges
[Apologies if the question already has been answered, but my e-mail-I/O
is not well sorted these days...]


From hack at pedos.hr  Sun Mar 23 23:18:59 2003
From: hack at pedos.hr (Branimir K. Hackenberger)
Date: Sun, 23 Mar 2003 23:18:59 +0100
Subject: [R] fontsize
Message-ID: <000001c2f18a$36f39870$cfcc35a1@BranimirHackenberger>


Hi all !

How to change fontsize of contour labels (function: contour(), package:
base)

Thanks!


Branimir


From Sue_Paul at moh.govt.nz  Mon Mar 24 02:14:22 2003
From: Sue_Paul at moh.govt.nz (Sue_Paul@moh.govt.nz)
Date: Mon, 24 Mar 2003 13:14:22 +1200
Subject: [R] APC Modelling and the GLM function
Message-ID: <OF40121CCD.72CF5B69-ONCC256CF3.000480C7@moh.govt.nz>

Hi all
Apologies for any cross posting.
I have encountered a rather bizarre "problem" in Splus and R.  I am using Age-Period-Cohort models to model cervical cancer and have run the same data
on both R (v.1.4.1 & v1.6.2) and Splus (version 6.0).  I used the same command line in both Splus and R:  glm(cases~-1+as.factor(age)
+as.factor(period)+as.factor(cohort)+offset(log(person.years)),family="poisson",data=mydata)
While Splus and R fit APC models using different constraints, the fitted values should be identical.  However, I have found the following:
   Both Splus and R models give you the same value for the residual deviance;
   If I use the function fitted.values on the glm object then both Splus AND R models returns the same number of cases (and hence the same incidence
   rate once you have divided by person years at risk);
   However, if I try to derive the fitted values "manually":  i.e. fitted incidence rate = exp{ age.effect+period.effect+cohort.effect} then I get a
   completely different set of fitted incidence rates.
To do a quick check I also looked at second differences to see if these were identifiable, and found that the second differences for the age effects
are consistent in both R and Splus.  The period and cohort effects however, yield completely different second differences (in R & Splus).  I guess
this kind of narrows down the problem to the age and period effects, although I still cannot understand why glm would return the same deviance and
fitted number of cases, if all the second differences and fitted rates were not identifiable.
I am quite puzzled by this and can't seem to figure out what is going wrong.
I would really appreciate any help that anyone can give me.
Thanking you in advance

Kind Regards
Sue Paul
Advisor (Statistics)
Public Health Intelligence
Ministry of Health
DDI: 04 460 4926
Mobile: 021 100 3340
Fax: 04 495 4401

http://www.moh.govt.nz/PHI
mailto:sue_paul at moh.govt.nz


From jmiyamot at u.washington.edu  Mon Mar 24 02:19:04 2003
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Sun, 23 Mar 2003 17:19:04 -0800 (PST)
Subject: [R] Summary: extracting the names of the dataframe and variables
Message-ID: <Pine.A41.4.44.0303231715370.26244-100000@mead2.u.washington.edu>

Dear R Help,
   Thanks to Spencer Graves and Yusuke Miyamoto for suggestions.  The
original question was how to extract the name of the data set and variable
names from an lm or aov output object.  The following function based on
their suggestions does the trick.

v.names <- function(lm.out, data.name=NA) {
	X <- names(lm.out$model)
	Y <- c(as.character(lm.out$call$data), X)
	names(Y) <- c("data", "dep.var",
		paste("var", 1:(length(X) - 1), sep=""))
	Y
	}  #end of v.names function definition

tst.dat <- data.frame(Vis=rep(c(-1, 1), 8),
        Cmplx=rep(rep(c(-1,1), each=2), 4),
	Isi=rep(rep(c(-1,1), each=4), 2),
        Rt=rnorm(16))

tst.fit <- lm(Rt ~ Vis*Cmplx*Isi, data=tst.dat)

v.names(tst.fit)
     data   dep.var      var1      var2      var3
"tst.dat"      "Rt"     "Vis"   "Cmplx"     "Isi"

Thank you,

John Miyamoto

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------


From jim.lemon at uts.edu.au  Mon Mar 24 05:05:11 2003
From: jim.lemon at uts.edu.au (Jim Lemon)
Date: Mon, 24 Mar 2003 15:05:11 +1100
Subject: [R] Scripting with an external editor
Message-ID: <0HC800AV1JAPCR@mail.uts.edu.au>

I've had time to return to the "external editor" project. The following 
function does almost what I want, which is to allow an external editor to 
feed command lines to R.

ext.editor<-function(editor) {
 ext.input<-pipe(editor,"r")
 eval(parse(ext.input))
 close(ext.input)
}

While the description of parse() indicates that it should parse input line by 
line, the output of the editor is not read until it exits. The external 
editor is sending the output as requested, so I must be using the wrong 
connection setup. Any hints?

Jim

Feel free to ignore any garbage below this line.



UTS CRICOS Provider Code:  00099F

DISCLAIMER\ ====================================================... [[dropped]]


From Simon.Wotherspoon at utas.edu.au  Mon Mar 24 05:17:41 2003
From: Simon.Wotherspoon at utas.edu.au (Simon Wotherspoon)
Date: Mon, 24 Mar 2003 15:17:41 +1100
Subject: [R] 
Message-ID: <JPEJIEHCLCCMMBFGMPDGGEJJCCAA.Simon.Wotherspoon@utas.edu.au>

Hi,
	In 1.6.2 at least, when constructing a sequence of dates with seq and the
by argument inherits from difftime, the "units" attribute seems to be
ignored.  E.g.
try



str <- strptime("23/3/2003 06:00:00","%d/%m/%Y %H:%M:%S")
end <- strptime("23/3/2003 06:02:00","%d/%m/%Y %H:%M:%S")
step <- strptime("23/3/2003 06:01:00","%d/%m/%Y %H:%M:%S") -
  strptime("23/3/2003 06:00:00","%d/%m/%Y %H:%M:%S")
seq(str,end,step)


A possible fix is to replace the lines

  if (inherits(by, "difftime")) {
     by <- unclass(by)
  }

in seq.POSIXt with

  if (inherits(by, "difftime")) {
    by <- switch(attr(by, "units"), secs = by, mins = 60 * by, hours = 60 *
                 60 * by, days = 60 * 60 * 24 * by, weeks = 60 * 60 *
                 24 * 7 * by)
  }

as in "-.POSIXt", but this may not be the best solution.

I can't really see the point of representing difftime objects in terms of
different units, given POSIXct is always stored as seconds.  Would it be
better to move the whole "unit" business into a print method, more or less
as it is for POSIXct?

Simon.

---


From ravishan at fas.harvard.edu  Mon Mar 24 05:36:45 2003
From: ravishan at fas.harvard.edu (Nirmala Ravishankar)
Date: Sun, 23 Mar 2003 23:36:45 -0500 (EST)
Subject: [R] Robust standard errors
Message-ID: <Pine.LNX.4.44.0303232330240.10868-100000@ice4.fas.harvard.edu>

I am trying to calculate robust standard errors for a logit model.  I 
installed the package "car" and tried using hccm.default, but that 
required an lm object.  Is there some way to do a similar operation for a 
glm object?


x <- hccm.default(glm(winner ~ racebl + racehi + raceas + inchi + incmed + 
edhs + edcol + edba + agec1 + agec4 + sex + margin + regla + regbay + 
regsc + libcon+ pdem + poth, data = zol, family = binomial, weights = 
NULL))

Error in hccm.default(glm(winner ~ racebl + racehi + raceas + inchi +  : 
	requires an lm object
> 


Thanks,
Nirmala Ravishankar


 
**********************************************************************
Nirmala Ravishankar
First Year Graduate Student,
Government Department,
Harvard University


From darryl.greig at hp.com  Mon Mar 24 07:37:27 2003
From: darryl.greig at hp.com (Darryl)
Date: Mon, 24 Mar 2003 08:37:27 +0200
Subject: [R] fontsize
In-Reply-To: <000001c2f18a$36f39870$cfcc35a1@BranimirHackenberger>
Message-ID: <000701c2f1cf$d6f945a0$bf09b00f@hpli.hpl.hp.com>

?contour suggests labcex is the right parameter.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Branimir K.
Hackenberger
Sent: 24 March 2003 00:19
To: r-help at stat.math.ethz.ch
Subject: [R] fontsize



Hi all !

How to change fontsize of contour labels (function: contour(), package:
base)

Thanks!


Branimir

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From yanyu at cs.ucla.edu  Mon Mar 24 08:29:12 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Sun, 23 Mar 2003 23:29:12 -0800 (PST)
Subject: [R] arima
Message-ID: <Pine.SOL.4.33.0303232308360.6574-100000@panther.cs.ucla.edu>

Hello,
  I have a couple of Qs about arima() in ts package.
1. I know the basic concept of arima model, but not very sure about the
value returned by arima(), such as sigma2. from the help in R, sigma2 is
the MLE of the innovations variance..   but i am still not sure what this
"innovations variance" refer to.
My Q is which book or paper I should look at to figure out the
terms used by arima() function?

The help in R on arima listed quite a few reference. I am wondering which
one I should look at to get a quick hold of the meanings of the input and
output parameters of arima()?

2. How to determine the input parameters of arima(), like *order*? Is it a
trial-and-error process? I try a few of them, then pick a best fit one
based on the model
fitting results, i.e., the returned value.

3. My objective is prediction(fine grain interpolation), e.g., if I
interpolate a new point for every two original points in the original
series, after model fitting, I have the coefficient of different
components in the model. Is there a function that can output the
interpolated values based on returned value of arima()?

THANKS a lot in advance!
yan


From yanyu at cs.ucla.edu  Mon Mar 24 08:31:57 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Sun, 23 Mar 2003 23:31:57 -0800 (PST)
Subject: [R] wavelet model on time series in R?
Message-ID: <Pine.SOL.4.33.0303232329180.6574-100000@panther.cs.ucla.edu>

Hello,
Is there package built for R that can do model/prediction on time
series data using wavelet?
If not, does anyone know what popular software can do that?

Thanks much,
yan


From p.dalgaard at biostat.ku.dk  Mon Mar 24 08:56:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Mar 2003 08:56:04 +0100
Subject: [R] APC Modelling and the GLM function
In-Reply-To: <OF40121CCD.72CF5B69-ONCC256CF3.000480C7@moh.govt.nz>
References: <OF40121CCD.72CF5B69-ONCC256CF3.000480C7@moh.govt.nz>
Message-ID: <x24r5tryej.fsf@biostat.ku.dk>

Sue_Paul at moh.govt.nz writes:

> Hi all
> Apologies for any cross posting.

[I've redirected my reply to r-help (not r-announce) and deleted
allstat since they have a different followup policy than we do.]

> I have encountered a rather bizarre "problem" in Splus and R. I am
> using Age-Period-Cohort models to model cervical cancer and have run
> the same data on both R (v.1.4.1 & v1.6.2) and Splus (version 6.0).
> I used the same command line in both Splus and R:
> glm(cases~-1+as.factor(age)
> +as.factor(period)+as.factor(cohort)+offset(log(person.years)),
> +family="poisson",data=mydata)
> While Splus and R fit APC models using different constraints, the
> fitted values should be identical. However, I have found the
> following: Both Splus and R models give you the same value for the
> residual deviance; If I use the function fitted.values on the glm
> object then both Splus AND R models returns the same number of cases
> (and hence the same incidence rate once you have divided by person
> years at risk); However, if I try to derive the fitted values
> "manually": i.e. fitted incidence rate = exp{
> age.effect+period.effect+cohort.effect} then I get a completely
> different set of fitted incidence rates. To do a quick check I also
> looked at second differences to see if these were identifiable, and
> found that the second differences for the age effects are consistent
> in both R and Splus. The period and cohort effects however, yield
> completely different second differences (in R & Splus). I guess this
> kind of narrows down the problem to the age and period effects,
> although I still cannot understand why glm would return the same
> deviance and fitted number of cases, if all the second differences
> and fitted rates were not identifiable. I am quite puzzled by this
> and can't seem to figure out what is going wrong. I would really
> appreciate any help that anyone can give me. Thanking you in advance

My guess is that you're being done in by contrast settings (removing
the intercept only affects the coding of the first term, AFAIR). Try
redoing the S-PLUS analysis using treatment contrasts, or the R
analysis using Helmert contrasts (are you sure you know how to
interpret the estimated coefficients when Helmert contrasts are being
used?).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Mon Mar 24 11:26:38 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 24 Mar 2003 10:26:38 +0000 (GMT)
Subject: [R] Scripting with an external editor
In-Reply-To: <0HC800AV1JAPCR@mail.uts.edu.au>
Message-ID: <Pine.LNX.4.44.0303241012490.18578-100000@gannet.stats>

On Mon, 24 Mar 2003, Jim Lemon wrote:

> I've had time to return to the "external editor" project. The following 
> function does almost what I want, which is to allow an external editor to 
> feed command lines to R.
> 
> ext.editor<-function(editor) {
>  ext.input<-pipe(editor,"r")
>  eval(parse(ext.input))
>  close(ext.input)
> }
> 
> While the description of parse() indicates that it should parse input line by 
> line, the output of the editor is not read until it exits. The external 
> editor is sending the output as requested, so I must be using the wrong 
> connection setup. Any hints?

?parse says

     `parse' returns the parsed but unevaluated expressions in a list. 
     Each element of the list is of mode `expression'.

that is, it takes all the input and returns a list once all the input has 
been parsed.  There is no multi-tasking in the R evaluator, and you have 
no loop in your code, so eval can only be called once when parse exits.

I am not clear what you actually want.  If it is to repeatedly send a
block of code to R and get that block evaluated then you need to indicate
the end of the block somehow, split the pipe stream up into blocks and run
a loop to parse and evaluate each block.  If you want to simulate the
command-line, the easiest way to do this is to submit to the command line,
and to help with that you would have to at least tell us your platform!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bitwrit at ozemail.com.au  Mon Mar 24 12:12:14 2003
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Mon, 24 Mar 2003 22:12:14 +1100
Subject: [R] Scripting with an external editor
Message-ID: <20030324111238.LSEO3162.mta10.mail.mel.aone.net.au@there>

ripley at stats.ox.ac.uk wrote:
> ?parse says
>
>      `parse' returns the parsed but unevaluated expressions in a list.
>      Each element of the list is of mode `expression'.
>
> that is, it takes all the input and returns a list once all the input
> has been parsed.  There is no multi-tasking in the R evaluator, and you
> have no loop in your code, so eval can only be called once when parse
> exits.
>
> I am not clear what you actually want.  If it is to repeatedly send a
> block of code to R and get that block evaluated then you need to
> indicate the end of the block somehow, split the pipe stream up into
> blocks and run a loop to parse and evaluate each block.  If you want to
> simulate the command-line, the easiest way to do this is to submit to
> the command line, and to help with that you would have to at least tell
> us your platform!

My apologies.

OS - Linux (RedHat 7.2)

I had read the section in the R Language Manual about parsing:

"The read-eval-print loop forms the basic command line interface to R. 
Textual input is read until a complete R expression is available."

The initial aim is to send selected text from the editor to the R command 
line. If I manually invoke the editor from a terminal, I can do exactly 
this, with each section of text appearing as if entered when sent from the 
external editor. However, your suggestion about blocking is probably the 
answer, as I noticed the blocking option but decided that the explanation 
on the help page for "connections" implied that a non-blocking mode would 
be the correct one:

"In non-blocking mode, operations return as soon as possible, so on input 
they will return with whatever input is available..."

Any suggestions would be greatly appreciated.

Jim


From p.campbell at econ.bbk.ac.uk  Mon Mar 24 12:37:46 2003
From: p.campbell at econ.bbk.ac.uk (Campbell)
Date: Mon, 24 Mar 2003 11:37:46 +0000
Subject: [R] Install on Solaris 5.9
Message-ID: <se7eee17.086@markets.econ.bbk.ac.uk>

I'm trying to install R-1.6.2 on a Sparc machine running Solaris 5.9.  I download and unpack R, run ./Configure from the R directory.  Configure fails.The last line on the Configure script prints is 'Checking for Fortran 77 name-mangling scheme',  This output and the config.log files are available at:
	http://www.phineas.pwp.blueyonder.co.uk/config.log
and
	http://www.phineas.pwp.blueyonder.co.uk/configout

If you prefer I could post these 2 files directly to the mailing list.

I currently have autoconf 2.57, automake 1.7.2, gcc 3.2.2, make 3.80 and readline 4.3 installed. 

Phineas Campbell


From ripley at stats.ox.ac.uk  Mon Mar 24 12:59:15 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 24 Mar 2003 11:59:15 +0000 (GMT)
Subject: [R] Install on Solaris 5.9
In-Reply-To: <se7eee17.086@markets.econ.bbk.ac.uk>
Message-ID: <Pine.LNX.4.44.0303241151250.18683-100000@gannet.stats>

On Mon, 24 Mar 2003, Campbell wrote:

> I'm trying to install R-1.6.2 on a Sparc machine running Solaris 5.9.  I download and unpack R, run ./Configure from the R directory.  Configure fails.The last line on the Configure script prints is 'Checking for Fortran 77 name-mangling scheme',  This output and the config.log files are available at:
> 	http://www.phineas.pwp.blueyonder.co.uk/config.log
> and
> 	http://www.phineas.pwp.blueyonder.co.uk/configout
> 
> If you prefer I could post these 2 files directly to the mailing list.
> 
> I currently have autoconf 2.57, automake 1.7.2, gcc 3.2.2, make 3.80 
and readline 4.3 installed. 

gcc 3.2.2 has a fatal bug for compiling R on Solaris, so the first thing 
you need is a less buggy C compiler.  Preferably the Sun C/F9x compilers, 
but failing that gcc 3.2 will do.


You don't appear to have a working Fortran compiler installed, as 
config.log says at the end (before the symbols)

configure:15266: error: cannot compile a simple Fortran program
See `config.log' for more details.

It's found something called fc, which does not work.  If you have really 
installed gcc 3.2.2, the build went wrong and g77 did not get installed.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jfox at mcmaster.ca  Mon Mar 24 13:36:47 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 24 Mar 2003 07:36:47 -0500
Subject: [R] Robust standard errors
In-Reply-To: <Pine.LNX.4.44.0303232330240.10868-100000@ice4.fas.harvard.
 edu>
Message-ID: <5.1.0.14.2.20030324072040.01e14f28@mcmail.cis.mcmaster.ca>

Dear Nirmala,

The object of the various HCCM estimators is to compute standard errors 
that are approximately correct when the error variance in a linear model 
isn't constant. I don't see the relevance to a logit model. Perhaps you can 
explain further what you have in mind (or perhaps someone else is aware of 
a generalization to GLMs).

A small point: hccm.default isn't meant to be called directly, but rather 
through the generic function hccm. If you look at hccm.default you'll see 
that it's only purpose is to report an error when hccm is called with a 
non-lm object. Since glm objects inherit from lm, hccm.lm would normally be 
called, but would fail for a different reason, reporting that an unweighted 
lm object is required. Perhaps this is why you set weights=NULL in the call 
to glm. Weights in glm, incidentally, refer to so-called prior weights -- 
glm still returns weights from its last iteration. The functions hccm.lm 
and hccm.default are pretty simple, and you could discover all this by 
looking at them.

John

At 11:36 PM 3/23/2003 -0500, Nirmala Ravishankar wrote:
>I am trying to calculate robust standard errors for a logit model.  I
>installed the package "car" and tried using hccm.default, but that
>required an lm object.  Is there some way to do a similar operation for a
>glm object?
>
>
>x <- hccm.default(glm(winner ~ racebl + racehi + raceas + inchi + incmed +
>edhs + edcol + edba + agec1 + agec4 + sex + margin + regla + regbay +
>regsc + libcon+ pdem + poth, data = zol, family = binomial, weights =
>NULL))
>
>Error in hccm.default(glm(winner ~ racebl + racehi + raceas + inchi +  :
>         requires an lm object
> >

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From wegmann at biozentrum.uni-wuerzburg.de  Mon Mar 24 14:09:24 2003
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Mon, 24 Mar 2003 14:09:24 +0100
Subject: [R] cross correlation
Message-ID: <3E7F0384.2FEEA89B@biozentrum.uni-wuerzburg.de>

Hello,

does anybody has experience in doing cross correlation of image data
sets from GRASS - GIS? looking for dependencies inbetween image
composites.
what would be the command for computing a cross correlation?

thanks in advance, Martin

--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de

-------------- next part --------------
A non-text attachment was scrubbed...
Name: wegmann.vcf
Type: text/x-vcard
Size: 329 bytes
Desc: Card for Martin Wegmann
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030324/6ebce064/wegmann.vcf

From venkat.prasad at siritech.com  Mon Mar 24 14:23:49 2003
From: venkat.prasad at siritech.com (venkat.prasad@siritech.com)
Date: Mon, 24 Mar 2003 18:53:49 +0530
Subject: [R] Help regarding C/C++ usage ..
Message-ID: <OF8E2DF366.E4478AD3-ON65256CF3.0048E206@siri.co.in>

Hi,

We have started to use R for our statistical based application especially
for Clustering.    Clustering is one of features of the software that we
are developing.  We are developing the entire product using Microsoft
Technologies VC++, VB with ODBC.  I wanted to use R for performing the
Clustering and generate results.  I want to call R functions in my C++
program.  How can I do that ?  I would appreciate if you could give me the
entire syntax for building too.   It would be great help and boost for my
software development if you could send me a sample project.

Thanks in advance awaiting a early and positive response.

Regards,
Venkat Prasad M S


From ocbruno at netscape.net  Mon Mar 24 14:25:39 2003
From: ocbruno at netscape.net (ocbruno@netscape.net)
Date: Mon, 24 Mar 2003 08:25:39 -0500
Subject: [R] About Scheffe test
Message-ID: <51750999.39BE6946.00206454@netscape.net>

Dear coleagues,

I wrote a script for a multiple comparisions
like Scheffe test, according Zar, JH. Biostatiscal Analysis
pg.196..
my data is fish larvae abundance with 4 tratments
month (with 12 levels), year (with 9 levels), station
of year (with 4 levels) and area (with 3 levels)
after an anova procedure i apply this:

Scheffe<-function(mxa,mxb,ms,na,nb,k,F){
 # Scheffe test for multiple comparision
 # where mxa is mean of A(month, year,station or area
 # mxb is some but other treatment
 # ms is mean square of anova results
 # na is number of A sample nb is number
 # of sample B, k is degree of freedon of
 # of treatments and F is critical value to
 # to compare
 #if S > Scrit -reject H0 else S < Scrit -accept H0
 SE<-sqrt(ms*(1/na+1/nb))
 S<-abs(mxb-mxa)/SE
 Scrit<-sqrt((k-1)*F)
 if (S > Scrit) result<-c("rej H0") else result<-c("ac H0")
 return(cbind(S,Scrit,result))
 }
Is there some errors??
Is possible find the F values in R??
Thanks for some help

Marcelo



From ripley at stats.ox.ac.uk  Mon Mar 24 14:39:40 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 24 Mar 2003 13:39:40 +0000 (GMT)
Subject: [R] Help regarding C/C++ usage ..
In-Reply-To: <OF8E2DF366.E4478AD3-ON65256CF3.0048E206@siri.co.in>
Message-ID: <Pine.LNX.4.44.0303241328120.18843-100000@gannet.stats>

Are you working for a commercial organization?  This reads like a request
for technical consultancy.  If the `product' is for sale you need to
ensure that you can meet the requirements of the GPL which applies to R.

This is possible, in several different ways.  Although R itself is free, I 
am unaware of providers of free technical consultancy for it.

On Mon, 24 Mar 2003 venkat.prasad at siritech.com wrote:

> We have started to use R for our statistical based application especially
> for Clustering.    Clustering is one of features of the software that we
> are developing.  We are developing the entire product using Microsoft
> Technologies VC++, VB with ODBC.  I wanted to use R for performing the
> Clustering and generate results.  I want to call R functions in my C++
> program.  How can I do that ?  I would appreciate if you could give me the
> entire syntax for building too.   It would be great help and boost for my
> software development if you could send me a sample project.
> 
> Thanks in advance awaiting a early and positive response.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Roger.Bivand at nhh.no  Mon Mar 24 15:32:36 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 24 Mar 2003 15:32:36 +0100 (CET)
Subject: [R] Help regarding C/C++ usage ..
In-Reply-To: <OF8E2DF366.E4478AD3-ON65256CF3.0048E206@siri.co.in>
Message-ID: <Pine.LNX.4.44.0303241525540.1812-100000@reclus.nhh.no>

On Mon, 24 Mar 2003 venkat.prasad at siritech.com wrote:

> Hi,
> 
> We have started to use R for our statistical based application especially
> for Clustering.    Clustering is one of features of the software that we
> are developing.  We are developing the entire product using Microsoft
> Technologies VC++, VB with ODBC.  I wanted to use R for performing the
> Clustering and generate results.  I want to call R functions in my C++
> program.  How can I do that ?  I would appreciate if you could give me the
> entire syntax for building too.   It would be great help and boost for my
> software development if you could send me a sample project.

Two points: most of the information you may find useful is documenmted on 
the R project website, and secondly, because R is open source, doubts 
about documented functionality can be resolved by reading the entire code, 
which is entirely at your disposal. I'm sure lots of people would be 
interested in your generous contribution of your conclusions back to the 
community. Specifically, use of the search facility on the website will 
give you an initial guide to where to look - treat this as an exercise in 
datamining on R.

> 
> Thanks in advance awaiting a early and positive response.
> 
> Regards,
> Venkat Prasad M S

Roger Bivand

Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no


From tlumley at u.washington.edu  Mon Mar 24 16:19:37 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 24 Mar 2003 07:19:37 -0800 (PST)
Subject: [R] Robust standard errors
In-Reply-To: <5.1.0.14.2.20030324072040.01e14f28@mcmail.cis.mcmaster.ca>
Message-ID: <Pine.A41.4.44.0303240714310.158356-100000@homer03.u.washington.edu>

On Mon, 24 Mar 2003, John Fox wrote:

> Dear Nirmala,
>
> The object of the various HCCM estimators is to compute standard errors
> that are approximately correct when the error variance in a linear model
> isn't constant. I don't see the relevance to a logit model. Perhaps you can
> explain further what you have in mind (or perhaps someone else is aware of
> a generalization to GLMs).

Exactly the same reasoning as for linear models leads to `sandwich'
standard error estimators for GLMs.  GLMs ordinarily require mean and
variance correctly specified to give valid standard errors; the sandwich
estimators require only that the mean is correctly specified.

For a binary logit model on independent observations this doesn't get you
much further, as the entire likelihood is going to be correct if the mean
is correct, but for other GLMs it is a useful technique.

Some options are to use the gee or geepack packages to do an analysis with
only one observation per group, or the survey package to do an analysis
without sampling weights.


	-thomas


From till.baumgaertel at epost.de  Mon Mar 24 16:31:29 2003
From: till.baumgaertel at epost.de (Till Baumgaertel)
Date: Mon, 24 Mar 2003 16:31:29 +0100
Subject: AW: [R] wavelet model on time series in R?
In-Reply-To: <Pine.SOL.4.33.0303232329180.6574-100000@panther.cs.ucla.edu>
Message-ID: <3E7E2C6100000BF0@PPD27104.x.de>

Yan,

There's the wavethresh- and the waveslim-package.
I work with wavethresh and use lda from MASS-package to make prediction
which works quite good.

My original data is not a time-series, but a physical curve. But for your
use it shouldn't make *any* difference.

cu
till

>-- Original Nachricht --
>Date: Sun, 23 Mar 2003 23:31:57 -0800 (PST)
>From: Yan Yu <yanyu at cs.ucla.edu>
>To: <r-help at stat.math.ethz.ch>
>Subject: [R] wavelet model on time series in R?
>
>
>Hello,
>Is there package built for R that can do model/prediction on time
>series data using wavelet?
>If not, does anyone know what popular software can do that?
>
>Thanks much,
>yan
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help






________________________________________
Mehr Power f?r Ihre eMail - mit den neuen Leistungspaketen bei http://www.epost.de


From wolski at molgen.mpg.de  Mon Mar 24 16:48:28 2003
From: wolski at molgen.mpg.de (wolski)
Date: Mon, 24 Mar 2003 16:48:28 +0100
Subject: [R] Is it a bug in list() behavior?
Message-ID: <200303241648280372.0FBC4902@harry.molgen.mpg.de>

Hello!

let:

test<-1:3
list(test)
names(test)<-c("X11","X12","Y23")
>test[["Y2"]]
3

I had assumed that the names in a list are like a keys in a hash.
Therefore i thought that no value should be returned.

The behavior of:

>test["Y2"]
<NA> 
  NA 

is as i expected.


Should it be as it is? How is the definition of [[]] and []?

/Eryk


From ligges at statistik.uni-dortmund.de  Mon Mar 24 16:54:43 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 24 Mar 2003 16:54:43 +0100
Subject: [R] Is it a bug in list() behavior?
In-Reply-To: <200303241648280372.0FBC4902@harry.molgen.mpg.de>
References: <200303241648280372.0FBC4902@harry.molgen.mpg.de>
Message-ID: <3E7F2A43.4070804@statistik.uni-dortmund.de>

wolski wrote:
> Hello!
> 
> let:
> 
> test<-1:3
> list(test)
> names(test)<-c("X11","X12","Y23")
> 
>>test[["Y2"]]
> 
> 3
> 
> I had assumed that the names in a list are like a keys in a hash.
> Therefore i thought that no value should be returned.
> 
> The behavior of:
> 
> 
>>test["Y2"]
> 
> <NA> 
>   NA 
> 
> is as i expected.
> 
> 
> Should it be as it is? How is the definition of [[]] and []?

No! See "An Introduction to R", Section 6.1:
"The names of components may be abbreviated down to the minimum number 
of letters needed to identify them uniquely. Thus Lst$coefficients may 
be minimally specified as Lst$coe and Lst$covariance as Lst$cov."

Uwe Ligges


From ltorgo at liacc.up.pt  Mon Mar 24 18:01:11 2003
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Mon, 24 Mar 2003 17:01:11 +0000
Subject: [R] Problem with the step() function
Message-ID: <200303241701.11383.ltorgo@liacc.up.pt>

Dear all,
I'm having some problems with using the step() function inside another 
function. I think it is an environment problem but I do not know how to 
overcome it. Any suggestions are appreciated. 

I've prepared a simple example to illustrate my problem:

> library(MASS)
> data(Boston)
> my.fun <- function(dataset) {
+   l <- lm(medv ~ .,data=dataset)
+   final.l <- step(l)
+ }
> model <- my.fun(Boston)
Start:  AIC= 1589.64 
 medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad +  
    tax + ptratio + black + lstat 

          Df Sum of Sq     RSS     AIC
- age      1       0.1 11078.8  1587.6
- indus    1       2.5 11081.3  1587.8
<none>                 11078.8  1589.6
- chas     1     219.0 11297.8  1597.5
- tax      1     242.3 11321.0  1598.6
- crim     1     243.2 11322.0  1598.6
- zn       1     257.5 11336.3  1599.3
- black    1     270.6 11349.4  1599.9
- rad      1     479.2 11557.9  1609.1
- nox      1     487.2 11565.9  1609.4
- ptratio  1    1194.2 12273.0  1639.4
- dis      1    1232.4 12311.2  1641.0
- rm       1    1871.3 12950.1  1666.6
- lstat    1    2410.8 13489.6  1687.3
Error in model.frame.default(formula = medv ~ crim + zn + indus + chas +  : 
	Object "dataset" not found

Apparently the step() function is not able to find the "dataset" object which 
is created inside the my.fun() function.

My system information:
> R.version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.1              
year     2002             
month    11               
day      01               
language R

Thank you for any hints.

-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
    Machine Learning Group           Fax   : (+351) 22 600 36 54
    R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
    4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo


From ripley at stats.ox.ac.uk  Mon Mar 24 18:46:37 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 24 Mar 2003 17:46:37 +0000 (GMT)
Subject: [R] Problem with the step() function
In-Reply-To: <200303241701.11383.ltorgo@liacc.up.pt>
Message-ID: <Pine.LNX.4.44.0303241740470.1274-100000@gannet.stats>

Use R-devel, where this has been changed and your example works.

On Mon, 24 Mar 2003, Luis Torgo wrote:

> Dear all,
> I'm having some problems with using the step() function inside another 
> function. I think it is an environment problem but I do not know how to 
> overcome it. Any suggestions are appreciated. 
> 
> I've prepared a simple example to illustrate my problem:
> 
> > library(MASS)
> > data(Boston)
> > my.fun <- function(dataset) {
> +   l <- lm(medv ~ .,data=dataset)
> +   final.l <- step(l)
> + }
> > model <- my.fun(Boston)
> Start:  AIC= 1589.64 
>  medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad +  
>     tax + ptratio + black + lstat 
> 
>           Df Sum of Sq     RSS     AIC
> - age      1       0.1 11078.8  1587.6
> - indus    1       2.5 11081.3  1587.8
> <none>                 11078.8  1589.6
> - chas     1     219.0 11297.8  1597.5
> - tax      1     242.3 11321.0  1598.6
> - crim     1     243.2 11322.0  1598.6
> - zn       1     257.5 11336.3  1599.3
> - black    1     270.6 11349.4  1599.9
> - rad      1     479.2 11557.9  1609.1
> - nox      1     487.2 11565.9  1609.4
> - ptratio  1    1194.2 12273.0  1639.4
> - dis      1    1232.4 12311.2  1641.0
> - rm       1    1871.3 12950.1  1666.6
> - lstat    1    2410.8 13489.6  1687.3
> Error in model.frame.default(formula = medv ~ crim + zn + indus + chas +  : 
> 	Object "dataset" not found
> 
> Apparently the step() function is not able to find the "dataset" object which 
> is created inside the my.fun() function.
> 
> My system information:
> > R.version
>          _                
> platform i686-pc-linux-gnu
> arch     i686             
> os       linux-gnu        
> system   i686, linux-gnu  
> status                    
> major    1                
> minor    6.1              
> year     2002             
> month    11               
> day      01               
> language R
> 
> Thank you for any hints.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tplate at blackmesacapital.com  Mon Mar 24 18:47:06 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Mon, 24 Mar 2003 10:47:06 -0700
Subject: [R] Is it a bug in list() behavior?
In-Reply-To: <3E7F2A43.4070804@statistik.uni-dortmund.de>
References: <200303241648280372.0FBC4902@harry.molgen.mpg.de>
 <200303241648280372.0FBC4902@harry.molgen.mpg.de>
Message-ID: <5.1.0.14.2.20030324095705.06d81a30@mailhost.blackmesacapital.com>

As wolski/Eryk's example shows, it seems that "[[" for lists accepts abbreviations, whereas "[" does not.  Is this intended?  (This is a difference from S-plus - both "[" and "[[" for lists accept abbreviations in S-plus (V6.1 for Windows at least.)

I couldn't find any mention of this difference in regards to accepting abbreviations in either ?"[" or section 6.1 of the Introduction to R, or in the R Language Manual, or in the R Reference Manual.  [As an aside, I'd rather that the subset operators didn't accept abbreviations at all,but ...]

The name returned by "[" for a non-existent element of a list also seems of dubious correctness.

> list(abc=123)[["a"]]
[1] 123
> list(abc=123)["a"]
$"NA"
NULL

> list(abc=123)$a
[1] 123
> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.2            
year     2003           
month    01             
day      10             
language R              
>


At Monday 04:54 PM 3/24/2003 +0100, you wrote:
>wolski wrote:
>>Hello!
>>let:
>>test<-1:3
>>list(test)
>>names(test)<-c("X11","X12","Y23")
>>
>>>test[["Y2"]]
>>3
>>I had assumed that the names in a list are like a keys in a hash.
>>Therefore i thought that no value should be returned.
>>The behavior of:
>>
>>>test["Y2"]
>><NA>   NA 
>>is as i expected.
>>
>>Should it be as it is? How is the definition of [[]] and []?
>
>No! See "An Introduction to R", Section 6.1:
>"The names of components may be abbreviated down to the minimum number of letters needed to identify them uniquely. Thus Lst$coefficients may be minimally specified as Lst$coe and Lst$covariance as Lst$cov."
>
>Uwe Ligges
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From wegmann at biozentrum.uni-wuerzburg.de  Mon Mar 24 18:47:56 2003
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Mon, 24 Mar 2003 18:47:56 +0100
Subject: [R] cross correaltion
Message-ID: <3E7F44CC.6CC02DC2@biozentrum.uni-wuerzburg.de>

Hello,

does anybody has experience in doing cross correlation of image data
sets from GRASS - GIS? looking for dependencies inbetween image
composites.
what would be the command for computing a cross correlation?

thanks in advance, Martin

--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de

-------------- next part --------------
A non-text attachment was scrubbed...
Name: wegmann.vcf
Type: text/x-vcard
Size: 329 bytes
Desc: Card for Martin Wegmann
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030324/0b4d4fab/wegmann.vcf

From tlumley at u.washington.edu  Mon Mar 24 18:52:19 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 24 Mar 2003 09:52:19 -0800 (PST)
Subject: [R] Problem with the step() function
In-Reply-To: <200303241701.11383.ltorgo@liacc.up.pt>
Message-ID: <Pine.A41.4.44.0303240951450.38442-100000@homer10.u.washington.edu>

On Mon, 24 Mar 2003, Luis Torgo wrote:

> Dear all,
> I'm having some problems with using the step() function inside another
> function. I think it is an environment problem but I do not know how to
> overcome it. Any suggestions are appreciated.

It's a bug. It's been reported and fixed for some time in the development
version.

	-thomas


From JBorders at qac.org  Mon Mar 24 18:56:21 2003
From: JBorders at qac.org (John Borders)
Date: Mon, 24 Mar 2003 12:56:21 -0500
Subject: [R] Box Plot Question
Message-ID: <F3B3CBB30317D71188B10090279AA47916D9E0@LIBXCHNG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030324/0e13fbb1/attachment.pl

From white.denis at epamail.epa.gov  Mon Mar 24 19:15:23 2003
From: white.denis at epamail.epa.gov (white.denis@epamail.epa.gov)
Date: Mon, 24 Mar 2003 10:15:23 -0800
Subject: [R] cross correaltion
Message-ID: <OFEE38310F.5CD2B477-ON88256CF3.00636A67@rtp.epa.gov>


Have you tried the GRASS mailing lists?

http://grass.itc.it/support.html

> Hello,
>
> does anybody has experience in doing cross correlation of image data
> sets from GRASS - GIS? looking for dependencies inbetween image
> composites.
> what would be the command for computing a cross correlation?
>
> thanks in advance, Martin
>


From ligges at statistik.uni-dortmund.de  Mon Mar 24 19:31:37 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 24 Mar 2003 19:31:37 +0100
Subject: [R] Is it a bug in list() behavior?
In-Reply-To: <5.1.0.14.2.20030324095705.06d81a30@mailhost.blackmesacapital.com>
References: <200303241648280372.0FBC4902@harry.molgen.mpg.de>
	<200303241648280372.0FBC4902@harry.molgen.mpg.de>
	<5.1.0.14.2.20030324095705.06d81a30@mailhost.blackmesacapital.com>
Message-ID: <3E7F4F09.5050006@statistik.uni-dortmund.de>

Tony Plate wrote:
> As wolski/Eryk's example shows, it seems that "[[" for lists accepts abbreviations, whereas "[" does not.  Is this intended?  (This is a difference from S-plus - both "[" and "[[" for lists accept abbreviations in S-plus (V6.1 for Windows at least.)

The general subscripting operator [] doesn't support abbreviations at 
all. I don't know of any reference that states [] supports partial 
matching of character strings.


> I couldn't find any mention of this difference in regards to accepting abbreviations in either ?"[" or section 6.1 of the Introduction to R, or in the R Language Manual, or in the R Reference Manual.  [As an aside, I'd rather that the subset operators didn't accept abbreviations at all,but ...]

[[]] is the component extractor for lists, and the reference I gave 
tells us that partial matching works for component indexing.
I agree that it's a good idea to mention this behaviour in the R 
Language *Definition* manual.



> The name returned by "[" for a non-existent element of a list also seems of dubious correctness.
> 
> 
>>list(abc=123)[["a"]]
> 
> [1] 123
> 
>>list(abc=123)["a"]
> 
> $"NA"
> NULL

Everything as expected from my point of view. Do you mean the "NA" is 
"dubious"?

See the R Language Definition, Section 3.4.1:
"Notice however, that there are different modes of NA?the literal 
constant is of mode "logical", but it is frequently automatically 
coerced to other types."
Remember, it's a name!

Uwe Ligges


> 
>>list(abc=123)$a
> 
> [1] 123
> 
>>version
> 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    6.2            
> year     2003           
> month    01             
> day      10             
> language R              
> 
> 
> 
> At Monday 04:54 PM 3/24/2003 +0100, you wrote:
> 
>>wolski wrote:
>>
>>>Hello!
>>>let:
>>>test<-1:3
>>>list(test)
>>>names(test)<-c("X11","X12","Y23")
>>>
>>>
>>>>test[["Y2"]]
>>>
>>>3
>>>I had assumed that the names in a list are like a keys in a hash.
>>>Therefore i thought that no value should be returned.
>>>The behavior of:
>>>
>>>
>>>>test["Y2"]
>>>
>>><NA>   NA 
>>>is as i expected.
>>>
>>>Should it be as it is? How is the definition of [[]] and []?
>>
>>No! See "An Introduction to R", Section 6.1:
>>"The names of components may be abbreviated down to the minimum number of letters needed to identify them uniquely. Thus Lst$coefficients may be minimally specified as Lst$coe and Lst$covariance as Lst$cov."
>>
>>Uwe Ligges
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ligges at statistik.uni-dortmund.de  Mon Mar 24 19:42:37 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 24 Mar 2003 19:42:37 +0100
Subject: [R] Box Plot Question
In-Reply-To: <F3B3CBB30317D71188B10090279AA47916D9E0@LIBXCHNG>
References: <F3B3CBB30317D71188B10090279AA47916D9E0@LIBXCHNG>
Message-ID: <3E7F519D.6000105@statistik.uni-dortmund.de>

John Borders wrote:
> I would like to create 15 box plots from two sets of data.
> 
> Set1 - containts PayGrade, Min_Salary, Max_Salary  data for 15 pay grades
> Set2 - contains PayGrade, Actual_Min, Actual_Max, and Actual_Mean for the 15
> pay grades
> 
> I would like 15 box plots  (one for each paygrade) whose whiskers were the
> Min_Salary and Max_Salary data
> and whose 'box' was Actual_Min, Actual_Mean, Actual_Max

a) Use merge() to merge the data frames.

> in order to show -- for each of teh 15 grades -- the width of the
> 'theoretical' pay grade, and the distribution of actual salaries within each
> of the 15 grades.
> 
> Any suggestions?

b) Look how boxplot.default() calls bxp() for plotting.
You might want to call bxp() directly with an appropriate structured 
object (a list like that one boxplot.default() returns) as its argument.

Uwe Ligges

> Thank you for any help.
> 
> J Borders (novice user)
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Mon Mar 24 20:12:55 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 24 Mar 2003 11:12:55 -0800
Subject: [R] Is it a bug in list() behavior?
References: <200303241648280372.0FBC4902@harry.molgen.mpg.de>
	<200303241648280372.0FBC4902@harry.molgen.mpg.de>
	<5.1.0.14.2.20030324095705.06d81a30@mailhost.blackmesacapital.com>
	<3E7F4F09.5050006@statistik.uni-dortmund.de>
Message-ID: <3E7F58B7.4080003@pdf.com>

This is a difference between S-Plus and R.

S-Plus 6.1 for Windows Professional Ed. Rel. 1:
 > tst <- c(a1 = 1, b2 = 3)
 > tst["a"]
  a1
   1

R 1.6.2:
 > tst <- c(a1=1, b2=3)
 > tst["a"]
<NA>
   NA

This is important for me, because some of my collaborators use S-Plus 
but not R and others use R but not S-Plus.  It's best for me if I can 
adopt a style of use that is maximally transportable.

Best Wishes,
Spencer Graves

Uwe Ligges wrote:
> Tony Plate wrote:
> 
>> As wolski/Eryk's example shows, it seems that "[[" for lists accepts 
>> abbreviations, whereas "[" does not.  Is this intended?  (This is a 
>> difference from S-plus - both "[" and "[[" for lists accept 
>> abbreviations in S-plus (V6.1 for Windows at least.)
> 
> 
> The general subscripting operator [] doesn't support abbreviations at 
> all. I don't know of any reference that states [] supports partial 
> matching of character strings.
> 
> 
>> I couldn't find any mention of this difference in regards to accepting 
>> abbreviations in either ?"[" or section 6.1 of the Introduction to R, 
>> or in the R Language Manual, or in the R Reference Manual.  [As an 
>> aside, I'd rather that the subset operators didn't accept 
>> abbreviations at all,but ...]
> 
> 
> [[]] is the component extractor for lists, and the reference I gave 
> tells us that partial matching works for component indexing.
> I agree that it's a good idea to mention this behaviour in the R 
> Language *Definition* manual.
> 
> 
> 
>> The name returned by "[" for a non-existent element of a list also 
>> seems of dubious correctness.
>>
>>
>>> list(abc=123)[["a"]]
>>
>>
>> [1] 123
>>
>>> list(abc=123)["a"]
>>
>>
>> $"NA"
>> NULL
> 
> 
> Everything as expected from my point of view. Do you mean the "NA" is 
> "dubious"?
> 
> See the R Language Definition, Section 3.4.1:
> "Notice however, that there are different modes of NA?the literal 
> constant is of mode "logical", but it is frequently automatically 
> coerced to other types."
> Remember, it's a name!
> 
> Uwe Ligges
> 
> 
>>
>>> list(abc=123)$a
>>
>>
>> [1] 123
>>
>>> version
>>
>>
>>          _              platform i386-pc-mingw32
>> arch     i386           os       mingw32        system   i386, 
>> mingw32  status                  major    1              minor    
>> 6.2            year     2003           month    01             
>> day      10             language R             
>>
>>
>> At Monday 04:54 PM 3/24/2003 +0100, you wrote:
>>
>>> wolski wrote:
>>>
>>>> Hello!
>>>> let:
>>>> test<-1:3
>>>> list(test)
>>>> names(test)<-c("X11","X12","Y23")
>>>>
>>>>
>>>>> test[["Y2"]]
>>>>
>>>>
>>>> 3
>>>> I had assumed that the names in a list are like a keys in a hash.
>>>> Therefore i thought that no value should be returned.
>>>> The behavior of:
>>>>
>>>>
>>>>> test["Y2"]
>>>>
>>>>
>>>> <NA>   NA is as i expected.
>>>>
>>>> Should it be as it is? How is the definition of [[]] and []?
>>>
>>>
>>> No! See "An Introduction to R", Section 6.1:
>>> "The names of components may be abbreviated down to the minimum 
>>> number of letters needed to identify them uniquely. Thus 
>>> Lst$coefficients may be minimally specified as Lst$coe and 
>>> Lst$covariance as Lst$cov."
>>>
>>> Uwe Ligges
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Edmond.Ng at lshtm.ac.uk  Mon Mar 24 20:40:06 2003
From: Edmond.Ng at lshtm.ac.uk (Edmond Ng)
Date: Mon, 24 Mar 2003 19:40:06 +0000
Subject: [R] how to show a section of a matrix neatly (or row by row) that
	satisfies some condition
Message-ID: <se7f5f1e.077@s-webmail.lshtm.ac.uk>

Hi all, 

I want to show the rows of a matrix (100x3) of which some of its elements satisfy a certain condition. In particular, how can I display the 2 rows of my matrix one after the 
other and not all all elements of column 1 first, then column 2 and so on. See the following. 

> finest[finest[,1] > 10^3] 
[1] 4.960632e+13 3.612619e+04 7.668204e+12 1.001911e+04 8.886153e-01
[6] 6.130777e-01

> dim(finest) 
[1] 100   3


Many thanks in advance. 

Edmond


From tplate at blackmesacapital.com  Mon Mar 24 20:45:18 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Mon, 24 Mar 2003 12:45:18 -0700
Subject: [R] Is it a bug in list() behavior?
In-Reply-To: <3E7F4F09.5050006@statistik.uni-dortmund.de>
References: <5.1.0.14.2.20030324095705.06d81a30@mailhost.blackmesacapital.com>
 <200303241648280372.0FBC4902@harry.molgen.mpg.de>
 <200303241648280372.0FBC4902@harry.molgen.mpg.de>
 <5.1.0.14.2.20030324095705.06d81a30@mailhost.blackmesacapital.com>
Message-ID: <5.1.0.14.2.20030324115926.06d3a550@mailhost.blackmesacapital.com>

At Monday 07:31 PM 3/24/2003 +0100, Uwe Ligges wrote:
>Tony Plate wrote:
>>As wolski/Eryk's example shows, it seems that "[[" for lists accepts abbreviations, whereas "[" does not.  Is this intended?  (This is a difference from S-plus - both "[" and "[[" for lists accept abbreviations in S-plus (V6.1 for Windows at least.)
>
>The general subscripting operator [] doesn't support abbreviations at all. I don't know of any reference that states [] supports partial matching of character strings.

My copy of the Blue Book, Section 11.4.1 (p357 of 1996 printing) seems to pretty strongly imply that "[" supports partial matching of character strings (it gives S-code for handling of indices, and uses pmatch for handling character indices in extraction contexts).  However, I certainly wouldn't advocate adding this to R if all existing software works without this capability.  It does seem worth documenting in place where beginning users can find it though.

>>The name returned by "[" for a non-existent element of a list also seems of dubious correctness.
>>
>>>list(abc=123)[["a"]]
>>[1] 123
>>
>>>list(abc=123)["a"]
>>$"NA"
>>NULL
>
>Everything as expected from my point of view. Do you mean the "NA" is "dubious"?

Yes, the string "NA" as a name is of dubious correctness.  The behavior of "[" with vectors is more what I would have expected:
> c(abc=123)["ab"]
<NA> 
  NA 
>

-- Tony Plate


From matthew_wiener at merck.com  Mon Mar 24 20:49:41 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Mon, 24 Mar 2003 14:49:41 -0500
Subject: [R] how to show a section of a matrix neatly (or row by row
 ) that satisfies some condition
Message-ID: <AEBD81486231A343B1813FE62D335225013177C7@usrymx15.merck.com>

You're missing a comma in the subscript.  The comma tells it that your test
is for the appropriate rows.

You want: finest[finest[,1] > 10^3,]

Hope this helps,

Matt Wiener

-----Original Message-----
From: Edmond Ng [mailto:Edmond.Ng at lshtm.ac.uk] 
Sent: Monday, March 24, 2003 2:40 PM
To: r-help at stat.math.ethz.ch
Subject: [R] how to show a section of a matrix neatly (or row by row) that
satisfies some condition


Hi all, 

I want to show the rows of a matrix (100x3) of which some of its elements
satisfy a certain condition. In particular, how can I display the 2 rows of
my matrix one after the 
other and not all all elements of column 1 first, then column 2 and so on.
See the following. 

> finest[finest[,1] > 10^3] 
[1] 4.960632e+13 3.612619e+04 7.668204e+12 1.001911e+04 8.886153e-01
[6] 6.130777e-01

> dim(finest) 
[1] 100   3


Many thanks in advance. 

Edmond

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------


From spencer.graves at pdf.com  Mon Mar 24 21:02:05 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 24 Mar 2003 12:02:05 -0800
Subject: [R] how to show a section of a matrix neatly (or row by row)
 that	satisfies some condition
References: <se7f5f1e.077@s-webmail.lshtm.ac.uk>
Message-ID: <3E7F643D.1000302@pdf.com>

I think you need a comma after "10^3", e.g.,:

tst <- array(1:9, dim=c(3,3))
tst[tst[,1]>1,]

Spencer Graves

Edmond Ng wrote:
> Hi all, 
> 
> I want to show the rows of a matrix (100x3) of which some of its elements satisfy a certain condition. In particular, how can I display the 2 rows of my matrix one after the 
> other and not all all elements of column 1 first, then column 2 and so on. See the following. 
> 
> 
>>finest[finest[,1] > 10^3] 
> 
> [1] 4.960632e+13 3.612619e+04 7.668204e+12 1.001911e+04 8.886153e-01
> [6] 6.130777e-01
> 
> 
>>dim(finest) 
> 
> [1] 100   3
> 
> 
> Many thanks in advance. 
> 
> Edmond
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From dyang at nrcan.gc.ca  Mon Mar 24 21:33:13 2003
From: dyang at nrcan.gc.ca (Yang, Richard)
Date: Mon, 24 Mar 2003 15:33:13 -0500
Subject: [R] Winedt and R on Windows XP
Message-ID: <F0E0B899CB43D5118D220002A55113CF21BBFE@s2-edm-r1.nofc.cfs.nrcan.gc.ca>

Dear All;

	I have used Winedt editor in conjunction with R on the Win2K
platform for more than a year without any problem. Recently I purchased a P4
machine with Windows XP. Following the installation of  R1.62 and WinEdt 5.3
to separate directories, I copied R-WinEdt to the Plugins subdirectory under
the Winedt directory, clicked on the "install" file and edited the Rprofile
with two options as follows:
          	options(editor="\"c:/apps/WinEdt Team/Winedt\
-c="R-Winedt-edit\" -e = r.ini -V")
	options(pager="\"c:/apps/WinEdt Team/Winedt\ -C="R-Winedt\" -e =
r.ini -V")

	After I started up R and opened Winedt, there were no R script, run,
history icons shown on the WinEdt window. What did I miss ? Any suggestions?


Richard


From ligges at statistik.uni-dortmund.de  Mon Mar 24 22:26:08 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 24 Mar 2003 22:26:08 +0100
Subject: [R] Winedt and R on Windows XP
References: <F0E0B899CB43D5118D220002A55113CF21BBFE@s2-edm-r1.nofc.cfs.nrcan.gc.ca>
Message-ID: <3E7F77F0.67D183D4@statistik.uni-dortmund.de>

"Yang, Richard" wrote:
> 
> Dear All;
> 
>         I have used Winedt editor in conjunction with R on the Win2K
> platform for more than a year without any problem. Recently I purchased a P4
> machine with Windows XP. Following the installation of  R1.62 

I guess you mean R-1.6.2, but which version of R-WinEdt (it's mentioned
in ReadMe.txt; please use the latest one: 1.4-1)?


> and WinEdt 5.3
> to separate directories, I copied R-WinEdt to the Plugins subdirectory under
> the Winedt directory, clicked on the "install" file and edited the Rprofile
> with two options as follows:
>                 options(editor="\"c:/apps/WinEdt Team/Winedt\
> -c="R-Winedt-edit\" -e = r.ini -V")
>         options(pager="\"c:/apps/WinEdt Team/Winedt\ -C="R-Winedt\" -e =
> r.ini -V")

These are just the lines to turn (R-)WinEdt into the editor and pager
used by R.
If you really need these lines, you have to 
a) set all required quotes,
b) escape the right quotes, and
c) specify the executable instead of the path (I guess you did the
latter assuming a default installation):

 options(editor="\"c:/apps/WinEdt Team/Winedt/WinEdt\" 
   -c=\"R-Winedt-edit\" -e=r.ini -V")
 options(pager="\"c:/apps/WinEdt Team/Winedt/WinEdt\" 
   -C=\"R-Winedt\" -e=r.ini -V")

Please follow the examples in ReadMe.txt.


>         After I started up R and opened Winedt, there were no R script, run,
> history icons shown on the WinEdt window. What did I miss ? Any suggestions?

Have you installed R-WinEdt properly (the answer is YES, if there is a
file c:/apps/WinEdt Team/Winedt/R.ini, as mentioned in the ReadMe.txt)?
Have you created the shortcuts to start WinEdt with the R-WinEdt plugin
properly (it's mentioned in ReadMe.txt).

For further communication related to R-WinEdt, please contact its author
directly.

Uwe Ligges

[BTW: Looks like my comments at DSC2003 on the desirability of a new and
convenient installation procedure for R-WinEdt were correct.]


From andy_liaw at merck.com  Mon Mar 24 22:17:36 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 24 Mar 2003 16:17:36 -0500
Subject: [R] compiling R on Linux w/ Intel compilers
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F8AE@usrymx25.merck.com>

Dear R-help,

Has anyone been able to compile R on Linux using Intel's C(++) and Fortran
compilers?  When I tried it (using R-devel from March 19), I get the
following error when it gets to compiling the "methods" package.  Can some
one tells me where to start looking?  What is "error 139"?  Any help greatly
appreciated!

Cheers,
Andy

PS:  This is on Mandrake 9.0, running on P3 Xeon.

make[3]: Entering directory `/home/andy/R-devel/src/library/methods'
config.status: creating src/library/methods/Makefile
make[3]: Leaving directory `/home/andy/R-devel/src/library/methods'
make[3]: Entering directory `/home/andy/R-devel/src/library/methods'
config.status: creating src/library/methods/DESCRIPTION
building package 'methods'
mkdir -p -- ../../../library/methods/R
mkdir -p -- ../../../library/methods/man
make[4]: Entering directory `/home/andy/R-devel/src/library/methods/src'
config.status: creating src/library/methods/src/Makefile
make[4]: Leaving directory `/home/andy/R-devel/src/library/methods/src'
make[4]: Entering directory `/home/andy/R-devel/src/library/methods/src'
making do_substitute_direct.d from do_substitute_direct.c
making methods_list_dispatch.d from methods_list_dispatch.c
making method_meta_data.d from method_meta_data.c
making slot.d from slot.c
making class_support.d from class_support.c
making tests.d from tests.c
make[5]: Entering directory `/home/andy/R-devel/src/library/methods/src'
make[5]: `Makedeps' is up to date.
make[5]: Leaving directory `/home/andy/R-devel/src/library/methods/src'
make[5]: Entering directory `/home/andy/R-devel/src/library/methods/src'
icc -I../../../../include  -I/usr/local/include -D__NO_MATH_INLINES -mp
-fpic  -g -c do_substitute_direct.c -o do_substitute_direct.o
icc -I../../../../include  -I/usr/local/include -D__NO_MATH_INLINES -mp
-fpic  -g -c methods_list_dispatch.c -o methods_list_dispatch.o
icc -I../../../../include  -I/usr/local/include -D__NO_MATH_INLINES -mp
-fpic  -g -c method_meta_data.c -o method_meta_data.o
icc -I../../../../include  -I/usr/local/include -D__NO_MATH_INLINES -mp
-fpic  -g -c slot.c -o slot.o
icc -I../../../../include  -I/usr/local/include -D__NO_MATH_INLINES -mp
-fpic  -g -c class_support.c -o class_support.o
icc -I../../../../include  -I/usr/local/include -D__NO_MATH_INLINES -mp
-fpic  -g -c tests.c -o tests.o
icc -shared  -L/usr/local/lib -o methods.so do_substitute_direct.o
methods_list_dispatch.o method_meta_data.o slot.o class_support.o tests.o
-L../../../../bin -lR
mkdir -p -- ../../../../library/methods/libs
make[5]: Leaving directory `/home/andy/R-devel/src/library/methods/src'
make[4]: Leaving directory `/home/andy/R-devel/src/library/methods/src'
make[4]: Entering directory `/home/andy/R-devel/src/library/methods'
dumping R code in package 'methods'
make[4]: *** [../../../library/methods/R/all.rda] Error 139
make[4]: Leaving directory `/home/andy/R-devel/src/library/methods'
make[3]: *** [all] Error 2
make[3]: Leaving directory `/home/andy/R-devel/src/library/methods'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/andy/R-devel/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/andy/R-devel/src'
make: *** [R] Error 1


Andy I. Liaw, PhD
Biometrics Research          Phone: (732) 594-0820
Merck & Co., Inc.              Fax: (732) 594-1565
P.O. Box 2000, RY84-16            Rahway, NJ 07065
mailto:andy_liaw at merck.com




------------------------------------------------------------------------------


From ligges at statistik.uni-dortmund.de  Mon Mar 24 23:04:35 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 24 Mar 2003 23:04:35 +0100
Subject: [R] Is it a bug in list() behavior?
References: <5.1.0.14.2.20030324095705.06d81a30@mailhost.blackmesacapital.com>
	<200303241648280372.0FBC4902@harry.molgen.mpg.de>
	<200303241648280372.0FBC4902@harry.molgen.mpg.de>
	<5.1.0.14.2.20030324115926.06d3a550@mailhost.blackmesacapital.com>
Message-ID: <3E7F80F3.2388B9CB@statistik.uni-dortmund.de>

Tony Plate wrote:
> 
> At Monday 07:31 PM 3/24/2003 +0100, Uwe Ligges wrote:
> >Tony Plate wrote:
> >>As wolski/Eryk's example shows, it seems that "[[" for lists accepts abbreviations, whereas "[" does not.  Is this intended?  (This is a difference from S-plus - both "[" and "[[" for lists accept abbreviations in S-plus (V6.1 for Windows at least.)
> >
> >The general subscripting operator [] doesn't support abbreviations at all. I don't know of any reference that states [] supports partial matching of character strings.
> 
> My copy of the Blue Book, Section 11.4.1 (p357 of 1996 printing) seems to pretty strongly imply that "[" supports partial matching of character strings (it gives S-code for handling of indices, and uses pmatch for handling character indices in extraction contexts).  However, I certainly wouldn't advocate adding this to R if all existing software works without this capability.  It does seem worth documenting in place where beginning users can find it though.
> 
> >>The name returned by "[" for a non-existent element of a list also seems of dubious correctness.
> >>
> >>>list(abc=123)[["a"]]
> >>[1] 123
> >>
> >>>list(abc=123)["a"]
> >>$"NA"
> >>NULL
> >
> >Everything as expected from my point of view. Do you mean the "NA" is "dubious"?
> 
> Yes, the string "NA" as a name is of dubious correctness.  The behavior of "[" with vectors is more what I would have expected:
> > c(abc=123)["ab"]
> <NA>
>   NA
> >
> 
> -- Tony Plate

Two last points:
- related to Tony Plate's mail: I don't have any S books at home (where
I am right now).
- related to Spencer Graves' mail: Transportability is not really an
issue. Or do you want to write code relying on partial matching? I
won't-or try to avoid it, at least. Example:
 LL <- list(a1=1, a2=2)
 LL$a # Hmmm ... partial matching can be quite dangerous!

I leave this topic open now.

Uwe


From mail at fwr.on.ca  Mon Mar 24 23:00:36 2003
From: mail at fwr.on.ca (Nurnberg-LaZerte)
Date: Mon, 24 Mar 2003 17:00:36 -0500
Subject: [R] using tapply with a matrix?
Message-ID: <E18xZzh-0004Bp-00@server.family>

I've successfully created my own function (topbot) that takes a vector as input and used it with tapply()  and an input vector (data$depth) and classification factor (data$profile):
vols <- tapply(data$depth, data$profile, topbot)
works great.

But now I want to do something similar, except my function will take a 3 column matrix with nrows() equal to the factor's length. tapply doesn't like this; I suspect it converts the 3 column matrox into a vector by ignoring the DIM atribute. 

I can't apply the funtion to each column separately as I need the info in all three simultaneously for the function's results.

I could always revert to "for" loops but was looking for a more concise solution in the spirit of "R".

Thanks in advance for any suggestions,
Bruce L.


From tlumley at u.washington.edu  Mon Mar 24 23:30:44 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 24 Mar 2003 14:30:44 -0800 (PST)
Subject: [R] using tapply with a matrix?
In-Reply-To: <E18xZzh-0004Bp-00@server.family>
Message-ID: <Pine.A41.4.44.0303241430170.104082-100000@homer25.u.washington.edu>

On Mon, 24 Mar 2003, Nurnberg-LaZerte wrote:

> I've successfully created my own function (topbot) that takes a vector as input and used it with tapply()  and an input vector (data$depth) and classification factor (data$profile):
> vols <- tapply(data$depth, data$profile, topbot)
> works great.
>
> But now I want to do something similar, except my function will take a 3
> column matrix with nrows() equal to the factor's length. tapply doesn't
> like this; I suspect it converts the 3 column matrox into a vector by
> ignoring the DIM atribute.
>

Use by()


	-thomas


From mail at fwr.on.ca  Tue Mar 25 02:38:55 2003
From: mail at fwr.on.ca (Nurnberg-LaZerte)
Date: Mon, 24 Mar 2003 20:38:55 -0500
Subject: [R] using tapply with a matrix?
In-Reply-To: <Pine.A41.4.44.0303241430170.104082-100000@homer25.u.washington.edu>
References: <E18xZzh-0004Bp-00@server.family>
	<Pine.A41.4.44.0303241430170.104082-100000@homer25.u.washington.edu>
Message-ID: <E18xdOy-0004EM-00@server.family>

** Reply to message from Thomas Lumley <tlumley at u.washington.edu> on Mon, 24 Mar 2003 14:30:44 -0800 (PST)

>Use by()

That's what I need. 

Somebody should put a link to by() in the tapply() section of the html docs.

Thanks.


From gisar at nus.edu.sg  Tue Mar 25 04:26:08 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Tue, 25 Mar 2003 11:26:08 +0800
Subject: [R] Box Plot Question
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053F8C@MBXSRV03.stf.nus.edu.sg>

If I understand you correctly, you have the five number summary (min,
q1, median/mean, q3, max). 
Have a look at the function bxp() where you can supply the summary
values as a list. 

-----Original Message-----
From: John Borders [mailto:JBorders at qac.org] 
Sent: Tuesday, March 25, 2003 1:56 AM
To: 'r-help at stat.math.ethz.ch'
Subject: [R] Box Plot Question


I would like to create 15 box plots from two sets of data.

Set1 - containts PayGrade, Min_Salary, Max_Salary  data for 15 pay
grades Set2 - contains PayGrade, Actual_Min, Actual_Max, and Actual_Mean
for the 15 pay grades

I would like 15 box plots  (one for each paygrade) whose whiskers were
the Min_Salary and Max_Salary data and whose 'box' was Actual_Min,
Actual_Mean, Actual_Max

in order to show -- for each of teh 15 grades -- the width of the
'theoretical' pay grade, and the distribution of actual salaries within
each of the 15 grades.

Any suggestions?

Thank you for any help.

J Borders (novice user)

	[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rnelson at cariboo.bc.ca  Mon Mar 24 20:40:45 2003
From: rnelson at cariboo.bc.ca (Ross Nelson)
Date: Mon, 24 Mar 2003 11:40:45 -0800
Subject: [R] negative binomial regression
Message-ID: <81CA6C96-5E30-11D7-B1A3-000393BA1D66@cariboo.bc.ca>

I would like to know if it is possible to perform negative binomial 
regression with rate data (incidence density) using the glm.nb (in 
MASS) function.

I used the poisson regression glm call to assess the count of injuries 
across census tracts.  The glm request was adjusted to handle the data 
as rates using the offset parameter since the population of census 
tracts can vary by a factor of three.

eg.  Call:
glm(formula = inj ~ lp + rdm, family = poisson(), data = ww,
     offset = log(pop))

Deviance Residuals:
      Min        1Q    Median        3Q       Max
-17.2779   -2.6034   -0.4519    2.0837   16.9275

Coefficients:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -1.11593    0.01482 -75.290  < 2e-16 ***
lp2          0.11569    0.01477   7.835 4.70e-15 ***
lp3          0.02374    0.01763   1.346    0.178
lp4          0.17777    0.01922   9.248  < 2e-16 ***
rdm2        -0.08810    0.01747  -5.044 4.57e-07 ***
rdm3         0.08750    0.01533   5.706 1.15e-08 ***
rdm4         0.10513    0.01518   6.925 4.35e-12 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1


inj and pop are interval, while lp and rdm are categorical.


A test of the dispersion indicates that the data is over dispersed, and 
thus that an alternative distribution should be used.

I am not sure, however, if or how to modify the glm.nb to handle this 
situation.

glm.nb(formula, ...,  init.theta, link = log)

  
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: text/enriched
Size: 1584 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030324/8e5a3516/attachment.bin

From ripley at stats.ox.ac.uk  Tue Mar 25 09:09:19 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 25 Mar 2003 08:09:19 +0000 (GMT)
Subject: [R] negative binomial regression
In-Reply-To: <81CA6C96-5E30-11D7-B1A3-000393BA1D66@cariboo.bc.ca>
Message-ID: <Pine.LNX.4.44.0303250804220.4981-100000@gannet.stats>

No modification is required.  The standard way in S to handle offsets is
via the offset() function, and that works in glm.nb.  The offset argument
to R's glm is unnecessary.

See ?Insurance and try
glm.nb(Claims ~ District + Group + Age + offset(log(Holders)),data = 
       Insurance)

(which is not over-dispersed and so gives some warnings).


On Mon, 24 Mar 2003, Ross Nelson wrote:

> I would like to know if it is possible to perform negative binomial 
> regression with rate data (incidence density) using the glm.nb (in 
> MASS) function.
> 
> I used the poisson regression glm call to assess the count of injuries 
> across census tracts.  The glm request was adjusted to handle the data 
> as rates using the offset parameter since the population of census 
> tracts can vary by a factor of three.
> 
> eg.  Call:
> glm(formula = inj ~ lp + rdm, family = poisson(), data = ww,
>      offset = log(pop))
> 
> Deviance Residuals:
>       Min        1Q    Median        3Q       Max
> -17.2779   -2.6034   -0.4519    2.0837   16.9275
> 
> Coefficients:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept) -1.11593    0.01482 -75.290  < 2e-16 ***
> lp2          0.11569    0.01477   7.835 4.70e-15 ***
> lp3          0.02374    0.01763   1.346    0.178
> lp4          0.17777    0.01922   9.248  < 2e-16 ***
> rdm2        -0.08810    0.01747  -5.044 4.57e-07 ***
> rdm3         0.08750    0.01533   5.706 1.15e-08 ***
> rdm4         0.10513    0.01518   6.925 4.35e-12 ***
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> 
> 
> inj and pop are interval, while lp and rdm are categorical.
> 
> 
> A test of the dispersion indicates that the data is over dispersed, and 
> thus that an alternative distribution should be used.
> 
> I am not sure, however, if or how to modify the glm.nb to handle this 
> situation.
> 
> glm.nb(formula, ...,  init.theta, link = log)
> 
>   

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hennig at stat.math.ethz.ch  Tue Mar 25 09:54:35 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Tue, 25 Mar 2003 09:54:35 +0100 (CET)
Subject: [R] isoMDS results
Message-ID: <Pine.LNX.4.44.0303250949080.2045-100000@florence>

Hi,

this is a second try to post this to the R-help mailing list. The first one
has been rejected because of a too large attachment.
Now I ask this without attaching the data. If you want to reproduce the
results, please contact me directly to get the data.

(First mail, rejected:)
> Attached there is a 149*149 dissimilarity matrix; it is a file obtained by 
> save(dm,file="dissim.Rsav").

OK, here is my question:

I worry about the reproducability of the results of isoMDS. 

I try
> set.seed(5678)
> mdslinux <- isoMDS(dm,k=4)
initial  value 31.071976 
final  value 31.071976 
converged

> R.version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.2              
year     2003             
month    01               
day      10               
language R                


My co-worker works also with the same dissimilarity matrix and did the same
on a Windows machine (unfortunately I do not have the version data, but
it should not be too old) and got
> set.seed(5678)
> mdswin <- isoMDS(dm,k=4)
initial  value 31.071976 
final  value 24.16980
converged

As to be expected, also the resulting MDS-configurations differ. 
Initially, the cmdcsale version seems to be used, and this is
identical. BTW, I often observed that the isoMDS iteration does not change
anything (but not always) 
from the cmdscale initial configuration on my machine, and I have
been somewhat sceptical more than once if this is correct. 

Can all this be explained with Windows/Linux differences or what else may
happen here?

Best,
Christian



-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


From potharst at few.eur.nl  Tue Mar 25 12:07:27 2003
From: potharst at few.eur.nl (R. Potharst)
Date: Tue, 25 Mar 2003 12:07:27 +0100
Subject: [R] R software for Hastie book
Message-ID: <3E80386F.4BEE2D5E@few.eur.nl>

Does anyone know whether there is an R version of the S-Plus 
software that can be downloaded from the website of the book 
Elements of Statistical Learning by Hastie, Tibshirani and 
Friedman?

Rob Potharst

-- 
**********************************************************
Dr. Rob Potharst
Lecturer in Computer Science    
Erasmus University              email: potharst at few.eur.nl
P.O. Box 1738                   phone: +31.10.408.1343
3000 DR Rotterdam               fax:   +31.10.408.9167
the Netherlands                 home:  +31.20.463.6694
homepage: http://www.few.eur.nl/few/people/potharst/


From potharst at few.eur.nl  Tue Mar 25 12:15:43 2003
From: potharst at few.eur.nl (R. Potharst)
Date: Tue, 25 Mar 2003 12:15:43 +0100
Subject: [R] R software for Hastie book
Message-ID: <3E803A5F.1167821C@few.eur.nl>

Does anyone know whether there is an R version of the S-Plus 
software that can be downloaded from the website of the book 
Elements of Statistical Learning by Hastie, Tibshirani and 
Friedman?

Rob Potharst

-- 
**********************************************************
Dr. Rob Potharst
Lecturer in Computer Science    
Erasmus University              email: potharst at few.eur.nl
P.O. Box 1738                   phone: +31.10.408.1343
3000 DR Rotterdam               fax:   +31.10.408.9167
the Netherlands                 home:  +31.20.463.6694
homepage: http://www.few.eur.nl/few/people/potharst/


From stanimura-ngs at umin.ac.jp  Tue Mar 25 12:47:18 2003
From: stanimura-ngs at umin.ac.jp (Susumu =?ISO-2022-JP?B?VEFOSU1VUkEvGyRCQytCPBsoQiAbJEI/OBsoQg==?=)
Date: Tue, 25 Mar 2003 20:47:18 +0900
Subject: [R] Cannot rebuild src.rpm
Message-ID: <20030325204718.351a1233.stanimura-ngs@umin.ac.jp>

I use R-1.5.1-1 on VineLinux2.6, which is modified and developed from
RedHat7.2.  Today I tried version-up R system, but I could not
rebuild.

Rebuilding R-1.6.2-1.src.rpm failed with the following message.

make[5]: Leaving directory `/home/umusus/rpm/BUILD/R-1.6.2/src/library'
running code in 'tcltk-Ex.R' ...X11 connection rejected because of wrong authentication.
X connection to localhost:11.0 broken (explicit kill or server shutdown).
make[4]: *** [tcltk-Ex.Rout] Error 1
make[4]: Leaving directory `/home/umusus/rpm/BUILD/R-1.6.2/tests/Examples'
make[3]: *** [test-Examples-Base] Error 2
make[3]: Leaving directory `/home/umusus/rpm/BUILD/R-1.6.2/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/home/umusus/rpm/BUILD/R-1.6.2/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/home/umusus/rpm/BUILD/R-1.6.2/tests'
make: *** [check] Error 2
Bad exit status from /var/tmp/rpm-tmp.17191 (%build)

However, a old package, R-base-1.5.1-1, could have rebuilt without any
problem.  I am very happy if someone give me some hits or comments.


From cortega at unitec.edu  Tue Mar 25 12:50:11 2003
From: cortega at unitec.edu (Cesar Ortega)
Date: Tue, 25 Mar 2003 12:50:11 +0100
Subject: [R] 
Message-ID: <7d615ef6200b626b.200b626b7d615ef6@unitec.edu>

Hi there,

Thank you in advance for your help.

I need to do the following:

1. Take one file from excell and one from SPSS and with the data 
calculate:

ESTIMATED N= SUM {1/PI(i)};  PI is the proportion
ESTIMATED T(Y)= SUM {Yi/PI(i)};  i belongs to the sample.

GINMi=[SUMi{(Yi/PI(i))*[1/PI(i)+SUMj(2/PI(j)]}]/[(2*ESTIMATED 
N*ESTIMATED T)].     i belongs to  M (1000,etc.) times, WHERE j=i+1

WE HAVE ONLY ONE VARIABLE Y, BUT WITH THE FIRST POSITION i AND THE
NEXT j, IN THE ASCENDING ORDER.

And last to get the errors as:

E1=  [SUMi {|GINP-GINMi |}]/[M] ; i belongs M

E2= SQRT[SUMi {|GINP-GINMi |}]/[M]; i belongs TO M

Thanks,

Cesar Ortega


From cortega at unitec.edu  Tue Mar 25 12:50:11 2003
From: cortega at unitec.edu (Cesar Ortega)
Date: Tue, 25 Mar 2003 12:50:11 +0100
Subject: [R] 
Message-ID: <7d615ef6200b626b.200b626b7d615ef6@unitec.edu>

Hi there,

Thank you in advance for your help.

I need to do the following:

1. Take one file from excell and one from SPSS and with the data 
calculate:

ESTIMATED N= SUM {1/PI(i)};  PI is the proportion
ESTIMATED T(Y)= SUM {Yi/PI(i)};  i belongs to the sample.

GINMi=[SUMi{(Yi/PI(i))*[1/PI(i)+SUMj(2/PI(j)]}]/[(2*ESTIMATED 
N*ESTIMATED T)].     i belongs to  M (1000,etc.) times, WHERE j=i+1

WE HAVE ONLY ONE VARIABLE Y, BUT WITH THE FIRST POSITION i AND THE
NEXT j, IN THE ASCENDING ORDER.

And last to get the errors as:

E1=  [SUMi {|GINP-GINMi |}]/[M] ; i belongs M

E2= SQRT[SUMi {|GINP-GINMi |}]/[M]; i belongs TO M

Thanks,

Cesar Ortega


From pfm401 at lineone.net  Tue Mar 25 13:33:08 2003
From: pfm401 at lineone.net (pfm401@lineone.net)
Date: Tue, 25 Mar 2003 12:33:08 +0000
Subject: [R] Help : stablereg parameter interpretation
Message-ID: <3E7B8AA200005220@mk-cpfrontend-4.mail.uk.tiscali.com>

Dear all,

I am having difficulty interpreting the parameter estimates from the stablereg
function. Specifically I am trying to keep things simple to start with by
using stablereg to fit a normal distribution to a simulated data set from
that distribution (in order to understand the way that stablereg reports
parameter estimates). I cannot work out the scale on which the dispersion
parameter (some function of the standard deviation if the data are normal)
is reported. The location parameter i.e. the mean is obvious.

For example:

set.seed(1234)
# Simulate normal data with mean 5 and sd 2 using rstable> normal5.2<-rstable(10000,loc=5,disp=2/sqrt(2),skew=0,tail=2)
mean(normal5.2)
[1] 5.010073
sd(normal5.2)
[1] 2.005362

# summary(lm(normal5.2~1)) yields similar results



fittest<-stablereg(y=normal5.2,loc=~1,disp=~1,iloc=5,idisp=2/sqrt(2),iskew=0,itail=2,oskew=F,otail=F)
# Normal model, as skew=0 and tail=2

yields :

Call:
stablereg(y = normal5.2, loc = ~1, disp = ~1, iloc = 5, idisp = 2/sqrt(2),

    iskew = 0, itail = 2, oskew = F, otail = F)

-Log likelihood              21498.69
No. of obs                   10000
No. of estimated parameters  2
No. of parameters            4
Degrees of freedom           9998
AIC                          21500.69
Iterations                   6

Location parameters
~1
             estimate       se
(Intercept)     5.015  0.02011

Dispersion parameters
   estimate        se
1    0.2888  0.008753

Correlations:
          1         2
1  1.000000 -0.001761
2 -0.001761  1.000000


so that 5.015 is indeed the (approx.) mean. As dispersion uses a log link
function and disp=sd/sqrt(2) for the normal (I think!) I tried
sqrt(2)*exp(0.2888)
which gives 1.887727
and 95% confidence limits at sqrt(2)*exp(0.2888+-1.96*0.008753)
i.e. (1.854968,1.921065)

Without going into more detail I have tried this for different parameter
values and simulations and cannot resolve the dispersion parameter to the
standard deviation. Clearly I am missing something!!

Any help is much appreciated.

Thanks in advance,
Paul.


From ripley at stats.ox.ac.uk  Tue Mar 25 13:46:30 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 25 Mar 2003 12:46:30 +0000 (GMT)
Subject: [R] Help : stablereg parameter interpretation
In-Reply-To: <3E7B8AA200005220@mk-cpfrontend-4.mail.uk.tiscali.com>
Message-ID: <Pine.LNX.4.44.0303251242500.3595-100000@gannet.stats>

In which package is the stablereg function?

I could not find it in any of the CRAN packages, and vaguely recall it
may be in one of Jim Lindsey's.  In any case, the best thing to do is to 
ask the author.

On Tue, 25 Mar 2003 pfm401 at lineone.net wrote:

> Dear all,
> 
> I am having difficulty interpreting the parameter estimates from the stablereg
> function. Specifically I am trying to keep things simple to start with by
> using stablereg to fit a normal distribution to a simulated data set from
> that distribution (in order to understand the way that stablereg reports
> parameter estimates). I cannot work out the scale on which the dispersion
> parameter (some function of the standard deviation if the data are normal)
> is reported. The location parameter i.e. the mean is obvious.
> 
> For example:
> 
> set.seed(1234)
> # Simulate normal data with mean 5 and sd 2 using rstable> normal5.2<-rstable(10000,loc=5,disp=2/sqrt(2),skew=0,tail=2)
> mean(normal5.2)
> [1] 5.010073
> sd(normal5.2)
> [1] 2.005362
> 
> # summary(lm(normal5.2~1)) yields similar results
> 
> 
> 
> fittest<-stablereg(y=normal5.2,loc=~1,disp=~1,iloc=5,idisp=2/sqrt(2),iskew=0,itail=2,oskew=F,otail=F)
> # Normal model, as skew=0 and tail=2
> 
> yields :
> 
> Call:
> stablereg(y = normal5.2, loc = ~1, disp = ~1, iloc = 5, idisp = 2/sqrt(2),
> 
>     iskew = 0, itail = 2, oskew = F, otail = F)
> 
> -Log likelihood              21498.69
> No. of obs                   10000
> No. of estimated parameters  2
> No. of parameters            4
> Degrees of freedom           9998
> AIC                          21500.69
> Iterations                   6
> 
> Location parameters
> ~1
>              estimate       se
> (Intercept)     5.015  0.02011
> 
> Dispersion parameters
>    estimate        se
> 1    0.2888  0.008753
> 
> Correlations:
>           1         2
> 1  1.000000 -0.001761
> 2 -0.001761  1.000000
> 
> 
> so that 5.015 is indeed the (approx.) mean. As dispersion uses a log link
> function and disp=sd/sqrt(2) for the normal (I think!) I tried
> sqrt(2)*exp(0.2888)
> which gives 1.887727
> and 95% confidence limits at sqrt(2)*exp(0.2888+-1.96*0.008753)
> i.e. (1.854968,1.921065)
> 
> Without going into more detail I have tried this for different parameter
> values and simulations and cannot resolve the dispersion parameter to the
> standard deviation. Clearly I am missing something!!
> 
> Any help is much appreciated.
> 
> Thanks in advance,
> Paul.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From stanimura-ngs at umin.ac.jp  Tue Mar 25 13:48:34 2003
From: stanimura-ngs at umin.ac.jp (Susumu =?ISO-2022-JP?B?VEFOSU1VUkEvGyRCQytCPBsoQiAbJEI/OBsoQg==?=)
Date: Tue, 25 Mar 2003 21:48:34 +0900
Subject: [R] self-solution (was Cannot rebuild src.rpm)
In-Reply-To: <20030325204718.351a1233.stanimura-ngs@umin.ac.jp>
References: <20030325204718.351a1233.stanimura-ngs@umin.ac.jp>
Message-ID: <20030325214834.552bdd4f.stanimura-ngs@umin.ac.jp>

Hi there,

When tried on not remote but local PC, it succeeded.

On Tue, 25 Mar 2003 20:47:18 +0900
Susumu TANIMURA <stanimura-ngs at umin.ac.jp> wrote:

> I use R-1.5.1-1 on VineLinux2.6, which is modified and developed
> from RedHat7.2.  Today I tried version-up R system, but I could not
> rebuild.
> 
> Rebuilding R-1.6.2-1.src.rpm failed with the following message.

[snip]


From david.whiting at ncl.ac.uk  Tue Mar 25 16:47:15 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Tue, 25 Mar 2003 15:47:15 +0000
Subject: [R]
In-Reply-To: <7d615ef6200b626b.200b626b7d615ef6@unitec.edu>
References: <7d615ef6200b626b.200b626b7d615ef6@unitec.edu>
Message-ID: <20030325154715.GP2735@192.168.57.2>

Try the following function:

student.exercise <- function (i.think.so = TRUE) {
 if (i.think.so) {
 	cat("Hmmm...how many marks do I get for answering this?\n")
	}
	else
	{
	cat("Sorry, my mistake\n")
	}
}


On Tue, Mar 25, 2003 at 12:50:11PM +0100, Cesar Ortega wrote:
> Hi there,
> 
> Thank you in advance for your help.
> 
> I need to do the following:
> 
> 1. Take one file from excell and one from SPSS and with the data 
> calculate:
> 
> ESTIMATED N= SUM {1/PI(i)};  PI is the proportion
> ESTIMATED T(Y)= SUM {Yi/PI(i)};  i belongs to the sample.
> 
> GINMi=[SUMi{(Yi/PI(i))*[1/PI(i)+SUMj(2/PI(j)]}]/[(2*ESTIMATED 
> N*ESTIMATED T)].     i belongs to  M (1000,etc.) times, WHERE j=i+1
> 
> WE HAVE ONLY ONE VARIABLE Y, BUT WITH THE FIRST POSITION i AND THE
> NEXT j, IN THE ASCENDING ORDER.
> 
> And last to get the errors as:
> 
> E1=  [SUMi {|GINP-GINMi |}]/[M] ; i belongs M
> 
> E2= SQRT[SUMi {|GINP-GINMi |}]/[M]; i belongs TO M
> 
> Thanks,
> 
> Cesar Ortega
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Dave Whiting
Dar es Salaam, Tanzania


From potharst at few.eur.nl  Tue Mar 25 14:15:53 2003
From: potharst at few.eur.nl (R. Potharst)
Date: Tue, 25 Mar 2003 14:15:53 +0100
Subject: [R] R software for Hastie book
Message-ID: <3E805689.2A0E36D8@few.eur.nl>

Hello R users,

Does anyone know whether there is an R version of the S-Plus 
software that can be downloaded from the website of the book 
Elements of Statistical Learning by Hastie, Tibshirani and 
Friedman?

Thanks beforehand,

Rob Potharst
-- 
**********************************************************
Dr. Rob Potharst
Lecturer in Computer Science    
Erasmus University              email: potharst at few.eur.nl
P.O. Box 1738                   phone: +31.10.408.1343
3000 DR Rotterdam               fax:   +31.10.408.9167
the Netherlands                 home:  +31.20.463.6694
homepage: http://www.few.eur.nl/few/people/potharst/


From potharst at few.eur.nl  Tue Mar 25 14:34:21 2003
From: potharst at few.eur.nl (R. Potharst)
Date: Tue, 25 Mar 2003 14:34:21 +0100
Subject: [R] R software for Hastie book
Message-ID: <3E805ADD.55C98E2B@few.eur.nl>

Hello R users,

Does anyone know whether there is an R version of the S-Plus 
software that can be downloaded from the website of the book 
Elements of Statistical Learning by Hastie, Tibshirani and 
Friedman?

Thanks beforehand,

Rob Potharst
-- 
**********************************************************
Dr. Rob Potharst
Lecturer in Computer Science    
Erasmus University              email: potharst at few.eur.nl
P.O. Box 1738                   phone: +31.10.408.1343
3000 DR Rotterdam               fax:   +31.10.408.9167
the Netherlands                 home:  +31.20.463.6694
homepage: http://www.few.eur.nl/few/people/potharst/


From maechler at stat.math.ethz.ch  Tue Mar 25 14:53:16 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 25 Mar 2003 14:53:16 +0100
Subject: [R] command line limit?
In-Reply-To: <CFEFA50C9BCAD21197470001FA7EBA6B0C0BFC37@ntexchange05.micron.com>
References: <CFEFA50C9BCAD21197470001FA7EBA6B0C0BFC37@ntexchange05.micron.com>
Message-ID: <16000.24396.376617.601420@gargle.gargle.HOWL>


>>>>> "dederderian" == dederderian  <dederderian at micron.com>
>>>>>     on Thu, 20 Mar 2003 16:39:53 -0700 writes:

    dederderian> Is there a limit on the length of a command
    dederderian> line in R?  Thanks, Dan

yes, necessarily so, since computers are finite...  :-)


From Kris.Nackaerts at agr.kuleuven.ac.be  Tue Mar 25 15:06:22 2003
From: Kris.Nackaerts at agr.kuleuven.ac.be (Kris Nackaerts)
Date: Tue, 25 Mar 2003 15:06:22 +0100
Subject: [R] geoR vector length error
Message-ID: <1048601182.3e80625e62f11@webmail.kuleuven.ac.be>

Dear,

we have a problem with geoR. We try to read an ASCII table (x,y,z) with 40000 
lines. With read.geodata we get the error: 

Error in vector("double", length) : cannot allocate vector of length 799980000

We can read the file without any problem with read.table, but trying to 
convert it to the geodata class gets the same error.

Any help/tips would be appreciated.


Kris, Dave

-- 
------------------------------------------------------------------------
 
 http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=krisn
 
------------------------------------------------------------------------
 Minds are like parachutes, they only work when open


From andy_liaw at merck.com  Tue Mar 25 15:02:14 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 25 Mar 2003 09:02:14 -0500
Subject: [R] R software for Hastie book
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F8B4@usrymx25.merck.com>

There's no point in posting the same message 3 times, especially within a
day.  The short answer to your question is "yes and no".  The book does have
a web site with a "software" section.

Andy

> -----Original Message-----
> From: R. Potharst [mailto:potharst at few.eur.nl]
> Sent: Tuesday, March 25, 2003 8:16 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] R software for Hastie book
> 
> 
> Hello R users,
> 
> Does anyone know whether there is an R version of the S-Plus 
> software that can be downloaded from the website of the book 
> Elements of Statistical Learning by Hastie, Tibshirani and 
> Friedman?
> 
> Thanks beforehand,
> 
> Rob Potharst
> -- 
> **********************************************************
> Dr. Rob Potharst
> Lecturer in Computer Science    
> Erasmus University              email: potharst at few.eur.nl
> P.O. Box 1738                   phone: +31.10.408.1343
> 3000 DR Rotterdam               fax:   +31.10.408.9167
> the Netherlands                 home:  +31.20.463.6694
> homepage: http://www.few.eur.nl/few/people/potharst/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------


From m.moldovan at inbox.lv  Tue Mar 25 15:50:55 2003
From: m.moldovan at inbox.lv (Max Moldovan)
Date: Tue, 25 Mar 2003 16:50:55 +0200
Subject: [R] R help: correlograms
Message-ID: <1048603855.3e806ccf10861@www2.inbox.lv>

Dear colleagues,

Where I can find tools for drawing correlograms (graphical representations of 
autocorrelation and partial autocorrelation functions)?

Thank you,

Max




---
This message contains no viruses. 
Guaranteed by Kaspersky Anti-Virus.
www.antivirus.lv


From tlumley at u.washington.edu  Tue Mar 25 16:06:51 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 25 Mar 2003 07:06:51 -0800 (PST)
Subject: [R] geoR vector length error
In-Reply-To: <1048601182.3e80625e62f11@webmail.kuleuven.ac.be>
Message-ID: <Pine.A41.4.44.0303250703480.94596-100000@homer36.u.washington.edu>

On Tue, 25 Mar 2003, Kris Nackaerts wrote:

> Dear,
>
> we have a problem with geoR. We try to read an ASCII table (x,y,z) with 40000
> lines. With read.geodata we get the error:
>
> Error in vector("double", length) : cannot allocate vector of length 799980000
>
> We can read the file without any problem with read.table, but trying to
> convert it to the geodata class gets the same error.

Looking at the source of as.geodata() it seems that it uses dist() to
check for coincident points, and this will involve creating a vector of
length approximately 8x10^8. You can't do that in R.

	-thomas


From tlumley at u.washington.edu  Tue Mar 25 16:08:07 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 25 Mar 2003 07:08:07 -0800 (PST)
Subject: [R] using tapply with a matrix?
In-Reply-To: <E18xdOy-0004EM-00@server.family>
Message-ID: <Pine.A41.4.44.0303250707270.94596-100000@homer36.u.washington.edu>

On Mon, 24 Mar 2003, Nurnberg-LaZerte wrote:

> ** Reply to message from Thomas Lumley <tlumley at u.washington.edu> on Mon, 24 Mar 2003 14:30:44 -0800 (PST)
>
> >Use by()
>
> That's what I need.
>
> Somebody should put a link to by() in the tapply() section of the html docs.
>

Somebody just did.

	-thomas


From jfox at mcmaster.ca  Tue Mar 25 16:17:40 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 25 Mar 2003 10:17:40 -0500
Subject: [R] R help: correlograms
In-Reply-To: <1048603855.3e806ccf10861@www2.inbox.lv>
Message-ID: <5.1.0.14.2.20030325101618.01e22930@mcmail.cis.mcmaster.ca>

Dear Max,

See the acf and pacf functions in the ts package.

John

At 04:50 PM 3/25/2003 +0200, Max Moldovan wrote:

>Where I can find tools for drawing correlograms (graphical representations of
>autocorrelation and partial autocorrelation functions)?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From dederderian at micron.com  Tue Mar 25 17:17:19 2003
From: dederderian at micron.com (dederderian)
Date: Tue, 25 Mar 2003 09:17:19 -0700
Subject: [R] command line limit?
Message-ID: <CFEFA50C9BCAD21197470001FA7EBA6B18F9DE2E@ntexchange05.micron.com>

Very insightful.  Thanks Martin.

Maybe, I need to explain my problem a little better.
I am creating an R comfile within a perl script.  

When I run this R comfile using:
    source("Rcomfile.txt")
It works fine.

When I run it from within my perl script using:
    R --no-save < Rcomfile.txt
It does not work.
I receive this error message in the middle of a long command line:
    Error: syntax error
    Execution halted

I only see this problem when I have really "long" command lines within the comfile.
I don't really have a work around for getting rid of my long command lines so I would like to find a way to make this work.


-----Original Message-----
From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
Sent: Tuesday, March 25, 2003 6:53 AM
To: dederderian
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R] command line limit?



>>>>> "dederderian" == dederderian  <dederderian at micron.com>
>>>>>     on Thu, 20 Mar 2003 16:39:53 -0700 writes:

    dederderian> Is there a limit on the length of a command
    dederderian> line in R?  Thanks, Dan

yes, necessarily so, since computers are finite...  :-)


From ripley at stats.ox.ac.uk  Tue Mar 25 17:56:45 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 25 Mar 2003 16:56:45 +0000 (GMT Standard Time)
Subject: [R] command line limit?
In-Reply-To: <CFEFA50C9BCAD21197470001FA7EBA6B18F9DE2E@ntexchange05.micron.com>
Message-ID: <Pine.WNT.4.44.0303251647470.3964-100000@gannet.stats.ox.ac.uk>

On Tue, 25 Mar 2003, dederderian wrote:

> Very insightful.  Thanks Martin.
>
> Maybe, I need to explain my problem a little better.

Yes, please do: you seem to be talking about console input lines, not the
command line at all.

> I am creating an R comfile within a perl script.
>
> When I run this R comfile using:
>     source("Rcomfile.txt")
> It works fine.
>
> When I run it from within my perl script using:
>     R --no-save < Rcomfile.txt
> It does not work.
> I receive this error message in the middle of a long command line:
>     Error: syntax error
>     Execution halted
>
> I only see this problem when I have really "long" command lines within the comfile.
> I don't really have a work around for getting rid of my long command lines so I would like to find a way to make this work.

Why can't you call source() in Rcomfile.txt?

AFAIK there is a 1022 char limit on input lines at the console, including
redirected.  From src/unix/system.txt

 *  2. CONSOLE I/O
 *
 *  The first group of functions is concerned with reading and
 *  writing to the system console.
 *
 *    int   R_ReadConsole(char *prompt, char *buf, int buflen, int hist)
 *
 *  This function prints the given prompt at the console and then
 *  does a gets(3)-like operation, transferring up to "buflen" characters
 *  into the buffer "buf".  The last two characters are set to "\n\0"
 *  to preserve sanity.

and buflen is 1024 in src/main/main.c


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From paallen at attglobal.net  Tue Mar 25 17:56:27 2003
From: paallen at attglobal.net (Phillip J. Allen)
Date: Tue, 25 Mar 2003 11:56:27 -0500
Subject: [R] Bar plot with variable width (down a drill hole)?
Message-ID: <3E808A3B.3060607@attglobal.net>

Hi all,

I am trying to make a bar plot of  observations along a line or 
specifically a drill hole with the bars widths representing the interval 
of the observation and the length of the bar the actual data.  My data 
is in the following format:

from(m)        to(m)        Intensity of silicification
0                    1.2            0
1.2                  4.0            1
4.0                   4.2            3
4.2                    5.0           2
5.0                    25            1
25.0                    30.1        0
30.1                    36.2         2
......


Is the barplot() function what I really want to use?

Thanks for any help.

Phillip J. Allen
Consulting Geochemist/Geologist
Lima Peru
e-mail: paallen at attglobal.net


From dederderian at micron.com  Tue Mar 25 18:08:00 2003
From: dederderian at micron.com (dederderian)
Date: Tue, 25 Mar 2003 10:08:00 -0700
Subject: [R] command line limit?
Message-ID: <CFEFA50C9BCAD21197470001FA7EBA6B18F9DE2F@ntexchange05.micron.com>

Sorry, I thought I was replying to R-help.  
Anyways, you were correct.  I had already tried inserting a couple "\n"'s into the comfile with no luck.  I was still receiving the same error.  After your suggestion I inserted even more and it worked.

Regarding the suggestion of calling source(comfile), I didn't want to have to create a second comfile just to call another comfile.  Your suggestion would have worked though.  Knowing the actual limit is ~1022 is good info.  Now I can build that limit into my perl script.

Thanks for your help.
Dan

-----Original Message-----
From: Prof Brian D Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Tuesday, March 25, 2003 9:57 AM
To: dederderian
Cc: 'Martin Maechler'; 'r-help at stat.math.ethz.ch'
Subject: RE: [R] command line limit?


On Tue, 25 Mar 2003, dederderian wrote:

> Very insightful.  Thanks Martin.
>
> Maybe, I need to explain my problem a little better.

Yes, please do: you seem to be talking about console input lines, not the
command line at all.

> I am creating an R comfile within a perl script.
>
> When I run this R comfile using:
>     source("Rcomfile.txt")
> It works fine.
>
> When I run it from within my perl script using:
>     R --no-save < Rcomfile.txt
> It does not work.
> I receive this error message in the middle of a long command line:
>     Error: syntax error
>     Execution halted
>
> I only see this problem when I have really "long" command lines within the comfile.
> I don't really have a work around for getting rid of my long command lines so I would like to find a way to make this work.

Why can't you call source() in Rcomfile.txt?

AFAIK there is a 1022 char limit on input lines at the console, including
redirected.  From src/unix/system.txt

 *  2. CONSOLE I/O
 *
 *  The first group of functions is concerned with reading and
 *  writing to the system console.
 *
 *    int   R_ReadConsole(char *prompt, char *buf, int buflen, int hist)
 *
 *  This function prints the given prompt at the console and then
 *  does a gets(3)-like operation, transferring up to "buflen" characters
 *  into the buffer "buf".  The last two characters are set to "\n\0"
 *  to preserve sanity.

and buflen is 1024 in src/main/main.c


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Ted.Harding at nessie.mcc.ac.uk  Tue Mar 25 19:01:05 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 25 Mar 2003 18:01:05 -0000 (GMT)
Subject: [R] Bar plot with variable width (down a drill hole)?
In-Reply-To: <3E808A3B.3060607@attglobal.net>
Message-ID: <XFMail.030325180105.Ted.Harding@nessie.mcc.ac.uk>

On 25-Mar-03 Phillip J. Allen wrote:
> I am trying to make a bar plot of  observations along a line or 
> specifically a drill hole with the bars widths representing the
> interval of the observation and the length of the bar the actual
> data.  My data is in the following format:
> 
> from(m)        to(m)        Intensity of silicification
> 0              1.2            0
> 1.2            4.0            1
> 4.0            4.2            3
> 4.2            5.0            2
> 5.0            25             1
> 25.0           30.1           0
> 30.1           36.2           2
> ......
> 
> 
> Is the barplot() function what I really want to use?

It looks as though it should do: see in particular the
arguments height, width, and space, to the function
as described in help(barplot).

For example:
x0<-c(0, 1.2, 4.0, 4.2, 5.0, 25.0, 30.1)
x1<-c(1.2, 4.0, 4.2, 5.0, 25.0, 30.1, 36.2)
y<-c(0, 1, 3, 2, 1, 0, 2)
w<-x1-x0
y[y==0]<-0.001
barplot(height=y,width=w,space=0)

(the extra 0.001 gives a thickened baseline where y=0, to
avoid the impression that there is no bar at such points)

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 25-Mar-03                                       Time: 18:01:05
------------------------------ XFMail ------------------------------


From deepayan at stat.wisc.edu  Tue Mar 25 19:42:27 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 25 Mar 2003 12:42:27 -0600
Subject: [R] manipulating "..." inside a function
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4F89E@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD5C4F89E@usrymx25.merck.com>
Message-ID: <200303251242.27939.deepayan@stat.wisc.edu>

On Friday 21 March 2003 02:36 pm, Liaw, Andy wrote:
> Dear R-help,
>
> Can some one tell me how to do the following (if it's possible)?
>
> Suppose I have a function like this:
>
> f <- function(x, y, ...) {
>     ## some code
>     g(x, y, ...)
>    ## some more code
> }

Why not (in the context you describe below)

f <- function(x, y, panel.number, ...) {
    ## some code
    g(x, y, ...)
   ## some more code
}

? (This is the trick usually used for the strip function in particular.) 

> The problem is that g() may not understand everything that comes through in
> "...".  Is there a way to delete some component of "..." and then pass it
> to g()?
>
> Here's the description of the real problem:  f() is a panel.something
> function, and g() is a model fitting function.  Lattice passes
> "panel.number" as part of "..." to f(), and g() complains about unused
> argument "panel.number".
>
> I'd be very grateful for any help!
>
> Cheers,
> Andy
>
>
> ---------------------------------------------------------------------------
>---
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From andy_liaw at merck.com  Tue Mar 25 19:51:39 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 25 Mar 2003 13:51:39 -0500
Subject: [R] manipulating "..." inside a function
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F8BA@usrymx25.merck.com>

> From: Deepayan Sarkar [mailto:deepayan at stat.wisc.edu]
> On Friday 21 March 2003 02:36 pm, Liaw, Andy wrote:
> > Dear R-help,
> >
> > Can some one tell me how to do the following (if it's possible)?
> >
> > Suppose I have a function like this:
> >
> > f <- function(x, y, ...) {
> >     ## some code
> >     g(x, y, ...)
> >    ## some more code
> > }
> 
> Why not (in the context you describe below)
> 
> f <- function(x, y, panel.number, ...) {
>     ## some code
>     g(x, y, ...)
>    ## some more code
> }
> 
> ? (This is the trick usually used for the strip function in 
> particular.) 

Ah... Yes.  It didn't come me to put unwanted argument as part of the formal
parameters of the function to catch it.  Very nifty!  Thanks!

Andy


------------------------------------------------------------------------------


From MSchwartz at medanalytics.com  Tue Mar 25 19:54:47 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 25 Mar 2003 12:54:47 -0600
Subject: [R] Bar plot with variable width (down a drill hole)?
In-Reply-To: <3E808A3B.3060607@attglobal.net>
References: <3E808A3B.3060607@attglobal.net>
Message-ID: <3E80A5F7.1030204@MedAnalytics.com>

Phillip J. Allen wrote:
> Hi all,
> 
> I am trying to make a bar plot of  observations along a line or 
> specifically a drill hole with the bars widths representing the interval 
> of the observation and the length of the bar the actual data.  My data 
> is in the following format:
> 
> from(m)        to(m)        Intensity of silicification
> 0                    1.2            0
> 1.2                  4.0            1
> 4.0                   4.2            3
> 4.2                    5.0           2
> 5.0                    25            1
> 25.0                    30.1        0
> 30.1                    36.2         2
> ......
> 
> 
> Is the barplot() function what I really want to use?
> 
> Thanks for any help.
> 
> Phillip J. Allen
> Consulting Geochemist/Geologist
> Lima Peru
> e-mail: paallen at attglobal.net


Phillip,

How about this, which will generate a vertical barplot, a y axis from 0 
down to 40 meters and bar widths and colors for each segment varied:

from <- c(0, 1.2, 4.0, 4.2, 5.0, 25.0, 30.1)
to <- c(1.2, 4.0, 4.2, 5.0, 25, 30.1, 36.2)
intensity <- c(0, 1, 3, 2, 1, 0, 2)
barplot(intensity, width = -(to - from),
         space = 0, horiz = TRUE, ylim = c(-40, 0))
axis(2, las = 2, labels = c(40, 30, 20, 10, 0))
mtext(side = 2, text = "Hole Depth (m)", line = 3)


Hope that helps,

Marc Schwartz


From kwan022 at stat.auckland.ac.nz  Tue Mar 25 21:07:34 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 26 Mar 2003 08:07:34 +1200 (NZST)
Subject: [R] R software for Hastie book
In-Reply-To: <3E805ADD.55C98E2B@few.eur.nl>
Message-ID: <Pine.LNX.4.33.0303260759500.19397-100000@stat56.stat.auckland.ac.nz>

Hi,

Firstly please don't post the same message to the list 4 times.  It does 
take a few minutes for a message to pass through the entire list, so if 
you don't get your message from the list within seconds, wait a while and 
it will come through.

Second, there is no "R version of the S-plus software".  R and S-plus are 
two different software: R is open-sourced and free; S-plus is a commercial 
software supported by Insightful.  Both are "dialects" of John Chambers's 
S language.

Thirdly, there is a web site for the book: 
http://www-stat.stanford.edu/~tibs/ElemStatLearn/ where you can download 
all datasets; as well as some "S-plus functions".  Most of the 
functions under "S-plus function" should work under R, for the functions 
that aren't working you can probably modifiy them slightly to get them to 
work.

On Tue, 25 Mar 2003, R. Potharst wrote:

> Date: Tue, 25 Mar 2003 14:34:21 +0100
> From: R. Potharst <potharst at few.eur.nl>
> To: r-help at stat.math.ethz.ch
> Subject: [R] R software for Hastie book
> 
> Hello R users,
> 
> Does anyone know whether there is an R version of the S-Plus 
> software that can be downloaded from the website of the book 
> Elements of Statistical Learning by Hastie, Tibshirani and 
> Friedman?
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From chrysopa at insecta.ufv.br  Tue Mar 25 20:19:11 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Tue, 25 Mar 2003 16:19:11 -0300
Subject: [R] Howto calculate MS from a unbalanced data
Message-ID: <200303251619.12008.chrysopa@insecta.ufv.br>

Hi,

I make a nested lme analysis, it is ok.
The estructure is:

lme(y~x,random=~1|x/animal)

It is no the exactly formula, but the teoretical formula. The real formula 
have a new variable with x/animal group.

Now I try to construct a nested lme table like the traditional anova table to 
presentation of the data.

---------------------------------------------
| Source | SS | d.f. |    MS    | F  | P    |
---------------------------------------------
    a           2                 1.9 0.1682
    b           21 
  resid         657   var(resid)
---------------------------------------------
  Total   2222
---------------------------------------------
For balanced data it is easy to complete. I use:

MSb = var(b)*n + var(resid)
MSa = var(a)*bn + MSb

where:

var(a), var(b) and var(resid) are the variance component get by the 
VarCorr(m1).

MSb and MSa are my questions (Mean Square).

n is the number of samples in group x/animal (unbalanced)

b is the number of animal in x (balanced)

Howto calculate the n if it is different for each group?

Exist any other easy form to present the results?

Thanks
Ronaldo
-- 
Justice always prevails ... three times out of seven!
		-- Michael J. Wagner
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From wmorgan at mitre.org  Tue Mar 25 21:42:45 2003
From: wmorgan at mitre.org (William T Morgan)
Date: 25 Mar 2003 15:42:45 -0500
Subject: [R] locfit troubles
Message-ID: <1048624965.10457.58.camel@paradise.mitre.org>

Dear R experts,

We've been playing with the locfit package and are experiencing a
problem I am hoping for some help on.

We have a dataset of 13k points, one dimension of which is "judgment",
either 0 or 1, and the other "score", an arbitrary scalar (in this case
it's between .65 and .85). We use

  locfit(judgement~score,kern="rect",deg=0,family="normal",alpha=c(alpha0,alpha1))

which is the simplest scenario we can think of (though not the one we
would like to use ultimately). The problem: under very small alpha1s
(e.g. 0.001), we see the warning "newsplit: out of vertex space" and
locfit produces a non-sensical output.

Does anyone know the source of this warning? More importantly, are we
mistaken in our usage of such a small alpha1? (The scores are very
tightly packed; there are no windows of size .001 without at least
a few datapoints).

Thank you for your help.

-- 
William T Morgan <wmorgan at mitre.org>
The Mitre Corporation


From dthibault at esperion.com  Tue Mar 25 22:01:24 2003
From: dthibault at esperion.com (David Thibault)
Date: Tue, 25 Mar 2003 16:01:24 -0500
Subject: [R] Help with data.frame subsets
Message-ID: <45B255AB58EB904C840B6D0AF4E3A1CC0D28EF@independence.esperion.com>

Hello all,

I'm trying to get a subset of a data frame by taking all rows where the 2nd
column is >= Min and <= Max.  I can do that by a 2 step process similar to
the following:

subData <- dataFrame[dataFrame[,2] >= Min,]
subData2 <- subData[subData[,2] <= Max,]

Then I try to graph the results where col 2 is the X var and col 3 is the Y
var.  Therefore I do the following:
X <- subData2[,2]
Y <- subData2[,3]

HOWEVER, sometimes subData2 is only left with 1 row remaining after the
subsetting operation.  If it gets down to that point R seems to return the
results as a LIST and not as a data frame.  Then when I do the X and Y
assignments above it gives the following error:

Error in subData2[, 2] : incorrect number of dimensions

I can't always assume that subData2 will be a list because most of the time
multiple rows are left in the subset and therefore it's still a data frame.
Does anyone have a solution for handling this kind of operation that won't
crash on me half the time?

Thanks in advance,
Dave


From upton at mitre.org  Tue Mar 25 22:18:57 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Tue, 25 Mar 2003 16:18:57 -0500
Subject: [R] Help with data.frame subsets
References: <45B255AB58EB904C840B6D0AF4E3A1CC0D28EF@independence.esperion.com>
Message-ID: <3E80C7C1.7348E0DF@mitre.org>

Dave,

Look at subset. This function retains the data as a data frame.  You can do
both your operations at once also.

HTH
steve

David Thibault wrote:

> Hello all,
>
> I'm trying to get a subset of a data frame by taking all rows where the 2nd
> column is >= Min and <= Max.  I can do that by a 2 step process similar to
> the following:
>
> subData <- dataFrame[dataFrame[,2] >= Min,]
> subData2 <- subData[subData[,2] <= Max,]
>
> Then I try to graph the results where col 2 is the X var and col 3 is the Y
> var.  Therefore I do the following:
> X <- subData2[,2]
> Y <- subData2[,3]
>
> HOWEVER, sometimes subData2 is only left with 1 row remaining after the
> subsetting operation.  If it gets down to that point R seems to return the
> results as a LIST and not as a data frame.  Then when I do the X and Y
> assignments above it gives the following error:
>
> Error in subData2[, 2] : incorrect number of dimensions
>
> I can't always assume that subData2 will be a list because most of the time
> multiple rows are left in the subset and therefore it's still a data frame.
> Does anyone have a solution for handling this kind of operation that won't
> crash on me half the time?
>
> Thanks in advance,
> Dave
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From paallen at attglobal.net  Tue Mar 25 22:48:55 2003
From: paallen at attglobal.net (Phillip J. Allen)
Date: Tue, 25 Mar 2003 16:48:55 -0500
Subject: [R] Re: Bar plot with variable width (down a drill hole) - now
	missing intervals?
Message-ID: <3E80CEC7.6090901@attglobal.net>

Hi again,

Thanks Ted and Marc its works.  But of course after pulling in in some 
real life data I discoverd one hitch.  Often there are missing 
intervals.  For example:
from <- c(0, 1.2, 4.0, 4.2, 5.0, 25.0, 30.1, 45)
to <- c(1.2, 4.0, 4.2, 5.0, 25, 30.1, 36.2, 50)
intensity <- c(0, 1, 3, 2, 1, 0, 2, 5)
barplot(intensity, width = -(to - from),
        space = 0, horiz = TRUE, ylim = c(-40, 0))

And it appears a barplot() is just stacking bars one on top the other 
and the help page doesn't indicate anyway to position the bar along the 
y-axis.  So does anyone have a nifty trick to to fill in blank gaps?  At 
least my database can check for "overlaping" intervals before I get the 
data into R.

Thanks,

Phillip J. Allen
Consulting Geochemist/Geologist
Lima Peru
e-mail: paallen at attglobal.net



Phillip,

How about this, which will generate a vertical barplot, a y axis from 0 
down to 40 meters and bar widths and colors for each segment varied:

from <- c(0, 1.2, 4.0, 4.2, 5.0, 25.0, 30.1)
to <- c(1.2, 4.0, 4.2, 5.0, 25, 30.1, 36.2)
intensity <- c(0, 1, 3, 2, 1, 0, 2)
barplot(intensity, width = -(to - from),
        space = 0, horiz = TRUE, ylim = c(-40, 0))
axis(2, las = 2, labels = c(40, 30, 20, 10, 0))
mtext(side = 2, text = "Hole Depth (m)", line = 3)


Hope that helps,

Marc Schwartz
**********************************************

It looks as though it should do: see in particular the
arguments height, width, and space, to the function
as described in help(barplot).

For example:
x0<-c(0, 1.2, 4.0, 4.2, 5.0, 25.0, 30.1)
x1<-c(1.2, 4.0, 4.2, 5.0, 25.0, 30.1, 36.2)
y<-c(0, 1, 3, 2, 1, 0, 2)
w<-x1-x0
y[y==0]<-0.001
barplot(height=y,width=w,space=0)

(the extra 0.001 gives a thickened baseline where y=0, to
avoid the impression that there is no bar at such points)

Ted.
******************************
original message

Hi all,



I am trying to make a bar plot of  observations along a line or 
specifically a drill hole with the bars widths representing the interval 
of the observation and the length of the bar the actual data.  My data 
is in the following format:



from(m)        to(m)        Intensity of silicification

0                    1.2            0

1.2                  4.0            1

4.0                   4.2            3

4.2                    5.0           2

5.0                    25            1

25.0                    30.1        0

30.1                    36.2         2

......





Is the barplot() function what I really want to use?



Thanks for any help.



Phillip J. Allen

Consulting Geochemist/Geologist

Lima Peru

e-mail: paallen at attglobal.net


From rpeng at stat.ucla.edu  Tue Mar 25 23:15:49 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 25 Mar 2003 14:15:49 -0800 (PST)
Subject: [R] locfit troubles
In-Reply-To: <1048624965.10457.58.camel@paradise.mitre.org>
Message-ID: <Pine.GSO.4.10.10303251409380.1485-100000@quetelet.stat.ucla.edu>

You should look at

Loader, C. (1999) Local Regression and Likelihood, Springer.

on which the package is based.  In particular, check out page 218.

locfit() evaluates the regression surface over a grid that's chosen
adaptively.  In small bandwidth situations, it can run out of memory for
storing the grid.  Try increasing the `maxk' argument.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On 25 Mar 2003, William T Morgan wrote:

> Dear R experts,
> 
> We've been playing with the locfit package and are experiencing a
> problem I am hoping for some help on.
> 
> We have a dataset of 13k points, one dimension of which is "judgment",
> either 0 or 1, and the other "score", an arbitrary scalar (in this case
> it's between .65 and .85). We use
> 
>   locfit(judgement~score,kern="rect",deg=0,family="normal",alpha=c(alpha0,alpha1))
> 
> which is the simplest scenario we can think of (though not the one we
> would like to use ultimately). The problem: under very small alpha1s
> (e.g. 0.001), we see the warning "newsplit: out of vertex space" and
> locfit produces a non-sensical output.
> 
> Does anyone know the source of this warning? More importantly, are we
> mistaken in our usage of such a small alpha1? (The scores are very
> tightly packed; there are no windows of size .001 without at least
> a few datapoints).
> 
> Thank you for your help.
> 
> -- 
> William T Morgan <wmorgan at mitre.org>
> The Mitre Corporation
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From tplate at blackmesacapital.com  Tue Mar 25 23:54:47 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue, 25 Mar 2003 15:54:47 -0700
Subject: [R] Help with data.frame subsets
In-Reply-To: <45B255AB58EB904C840B6D0AF4E3A1CC0D28EF@independence.esperi
 on.com>
Message-ID: <5.2.0.9.2.20030325154205.00a93558@mailhost.blackmesacapital.com>

The "[" operator also takes a drop= argument (type ?"[" to see the help page and find details.)

So you can do what you want in a single step, as follows:

subData <- dataFrame[dataFrame[,2]>=Min & dataFrame[,2]<=Max, , drop=F]

[If your "dataFrame" object really is a data.frame, the drop=F shouldn't be necessary -- maybe you have actually have a matrix and not a data frame, because the default behavior for dataframes is to keep the result as a dataframe when the result contains only one row, in contrast to the default behavior for matrices, which is to drop any dimension that has only one element.

> x <- data.frame(a=1:3,b=2:4)
> x
  a b
1 1 2
2 2 3
3 3 4
> x[1,] # default behavior of [ on data.frame is to not drop when have a single row
  a b
1 1 2
> class(x[1,])
[1] "data.frame"
> x[1,,drop=T] # returns a list
$a
[1] 1

$b
[1] 2

> xx <- as.matrix(x)
> xx[1,] # returns a vector
a b 
1 2 
> dim(xx[1,,drop=F]) # returns a matrix
[1] 1 2
> dim(xx[1,])
NULL
>


]


At Tuesday 04:01 PM 3/25/2003 -0500, David Thibault wrote:
>Hello all,
>
>I'm trying to get a subset of a data frame by taking all rows where the 2nd
>column is >= Min and <= Max.  I can do that by a 2 step process similar to
>the following:
>
>subData <- dataFrame[dataFrame[,2] >= Min,]
>subData2 <- subData[subData[,2] <= Max,]
>
>Then I try to graph the results where col 2 is the X var and col 3 is the Y
>var.  Therefore I do the following:
>X <- subData2[,2]
>Y <- subData2[,3]
>
>HOWEVER, sometimes subData2 is only left with 1 row remaining after the
>subsetting operation.  If it gets down to that point R seems to return the
>results as a LIST and not as a data frame.  Then when I do the X and Y
>assignments above it gives the following error:
>
>Error in subData2[, 2] : incorrect number of dimensions
>
>I can't always assume that subData2 will be a list because most of the time
>multiple rows are left in the subset and therefore it's still a data frame.
>Does anyone have a solution for handling this kind of operation that won't
>crash on me half the time?
>
>Thanks in advance,
>Dave
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ys3 at cec.wustl.edu  Wed Mar 26 00:58:33 2003
From: ys3 at cec.wustl.edu (yanni@cec)
Date: Tue, 25 Mar 2003 17:58:33 -0600
Subject: [R] How to write the output of a function into a file?
Message-ID: <018301c2f32a$714553a0$60a5fc80@mulan>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030325/eadba30d/attachment.pl

From kwan022 at stat.auckland.ac.nz  Wed Mar 26 02:12:10 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 26 Mar 2003 13:12:10 +1200 (NZST)
Subject: [R] How to write the output of a function into a file?
In-Reply-To: <018301c2f32a$714553a0$60a5fc80@mulan>
Message-ID: <Pine.LNX.4.33.0303261311090.25072-100000@stat56.stat.auckland.ac.nz>

Hi,

On Tue, 25 Mar 2003, yanni at cec wrote:

> Date: Tue, 25 Mar 2003 17:58:33 -0600
> From: "yanni at cec" <ys3 at cec.wustl.edu>
> To: r-help at stat.math.ethz.ch
> Subject: [R] How to write the output of a function into a file?
> 
> I cannot find the solutions in the mannual about "import and export of data".
> For example, I run 
> >chisq.test(x,p=probs)
>     chi-squared.....
> 
> .........
> 
> How can I write the output into a file? Is there some file operations in R?

Take a look at 
 ?write
 ?save

> Actually, I only want to save the P-value. But I don't know how I can extract the P-value field only from the output
> of chisq.test. So, I think I would better save all the output. I tried cat/write....They cannot do this.

It is very clearly documented in ?chisq.test (to get only the p-value).

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From laurent at cbs.dtu.dk  Wed Mar 26 03:59:07 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Wed, 26 Mar 2003 03:59:07 +0100
Subject: [R] RSPerl, R-1.6.2 and Perl-5.8.0
Message-ID: <20030326025907.GB13169478@genome.cbs.dtu.dk>

Hi,

I tried to run the test (after installing the pacakge),
but ran into an error:
[laurent at ym151011 tests]$ perl -I../share/blib/arch -I../share/blib/lib test.pl 
1..1
Can't load '../share/blib/arch/auto/R/R.so' for module R: /usr/lib/perl5/vendor_perl/5.8.0/i386-linux-thread-multi/auto/ModPerl/Global/Global.so: undefined symbol: modperl_perl_global_avcv_call at /usr/lib/perl5/5.8.0/i386-linux-thread-multi/DynaLoader.pm line 229.
 at test.pl line 11
Compilation failed in require at test.pl line 11.
BEGIN failed--compilation aborted at test.pl line 11.
not ok 1

Any suggestion ?


Thanks,



Laurent


From ripley at stats.ox.ac.uk  Wed Mar 26 08:10:20 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 26 Mar 2003 07:10:20 +0000 (GMT)
Subject: [R] RSPerl, R-1.6.2 and Perl-5.8.0
In-Reply-To: <20030326025907.GB13169478@genome.cbs.dtu.dk>
Message-ID: <Pine.LNX.4.44.0303260709150.6251-100000@gannet.stats>

On Wed, 26 Mar 2003, Laurent Gautier wrote:

> I tried to run the test (after installing the pacakge),
> but ran into an error:
> [laurent at ym151011 tests]$ perl -I../share/blib/arch -I../share/blib/lib test.pl 
> 1..1
> Can't load '../share/blib/arch/auto/R/R.so' for module R: /usr/lib/perl5/vendor_perl/5.8.0/i386-linux-thread-multi/auto/ModPerl/Global/Global.so: undefined symbol: modperl_perl_global_avcv_call at /usr/lib/perl5/5.8.0/i386-linux-thread-multi/DynaLoader.pm line 229.
>  at test.pl line 11
> Compilation failed in require at test.pl line 11.
> BEGIN failed--compilation aborted at test.pl line 11.
> not ok 1
> 
> Any suggestion ?

RSPerl is an Omegahat package, so send a bug report there?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gavin.simpson at ucl.ac.uk  Wed Mar 26 10:19:21 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 26 Mar 2003 09:19:21 -0000
Subject: [R] How to write the output of a function into a file?
In-Reply-To: <018301c2f32a$714553a0$60a5fc80@mulan>
Message-ID: <000801c2f378$c985cf10$4c202880@gsimpson>

does sink()

do what you want?

see ?sink for more

> #divert printed results to file
> sink(file = output.txt)
> #commands here
> chisq.test(x,p=probs)
> #turn off sink
> sink(file = NULL)

If you are not typing the commands at the prompt but are using an external
editor or text file for your commands via source() then you need to wrap
chisq.test(x,p=probs) in print() eg:

print(chisq.test(x,p=probs))

Hope this helps

Gavin

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of yanni at cec
Sent: 25 March 2003 23:59
To: r-help
Subject: [R] How to write the output of a function into a file?


I cannot find the solutions in the mannual about "import and export of
data".
For example, I run 
>chisq.test(x,p=probs)
    chi-squared.....

.........

How can I write the output into a file? Is there some file operations in R?
Actually, I only want to save the P-value. But I don't know how I can
extract the P-value field only from the output
of chisq.test. So, I think I would better save all the output. I tried
cat/write....They cannot do this.

Thanks in advance.

	[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Ted.Harding at nessie.mcc.ac.uk  Wed Mar 26 10:59:23 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 26 Mar 2003 09:59:23 -0000 (GMT)
Subject: [R] Re: Bar plot with variable width (down a drill hole) - n
In-Reply-To: <3E80CEC7.6090901@attglobal.net>
Message-ID: <XFMail.030326095923.Ted.Harding@nessie.mcc.ac.uk>

On 25-Mar-03 Phillip J. Allen wrote:
> Thanks Ted and Marc its works.  But of course after pulling in in some 
> real life data I discoverd one hitch.  Often there are missing 
> intervals.  For example:
> from <- c(0, 1.2, 4.0, 4.2, 5.0, 25.0, 30.1, 45)
> to <- c(1.2, 4.0, 4.2, 5.0, 25, 30.1, 36.2, 50)
> intensity <- c(0, 1, 3, 2, 1, 0, 2, 5)
> barplot(intensity, width = -(to - from),
>         space = 0, horiz = TRUE, ylim = c(-40, 0))
> 
> And it appears a barplot() is just stacking bars one on top the other 
> and the help page doesn't indicate anyway to position the bar along the
> y-axis.  So does anyone have a nifty trick to to fill in blank gaps? 
> At least my database can check for "overlaping" intervals before I
> get the data into R.

Well, I have constructed "by hand" for the above example a way of
doing it. First, I have used the "add a small bit to true zeros"
trick to make these stand out from the line of the axis; secondly,
I have filled in the gap where there are no data by inserting
the width of the gap into "width" (which I call "w"), and inserting
a true zero into "intensity" (which I call "y"). This one-off code
is as follows (starting with your 3 lines which define the data):

from <- c(0, 1.2, 4.0, 4.2, 5.0, 25.0, 30.1, 45)
to <- c(1.2, 4.0, 4.2, 5.0, 25, 30.1, 36.2, 50)
intensity <- c(0, 1, 3, 2, 1, 0, 2, 5)

y<-intensity;
y[y==0]<-0.005;
y<-c(y[1:7],0,y[8])

w<-(-(to - from))
w<-c(w[1:7],-(45-36.2),w[8])

barplot(y, w, space = 0, horiz = TRUE, ylim = c(-50, 0))

This does produce a plot which represents the full situation:
positive intensities get a proper "bar"; gaps with missing
data are represented by the line of the vertical axis;
intervals with intensity=0 are represented by a thickened
segment of the vertical axis.

However, this kind of situation needs thought about alternative
ways of representing it.

One possibility might be to have the vertical axis invisible,
so that gaps in the data are represented by gaps in the axis
(and then there would be no need for "adding a bit to true zeros").
Possibly this can be arranged by some setting of "par", though
I can't seem to achieve it with barplot. Ideas, anyone?
(It looks as though "axis" in barplot means the scale which is
plotted below or on the side, and not the lines which bound the
barplot itself).

Other thoughts are based on how I might approach this plotting
problem outside R. In particular, I might draw this kind of
graph using the 'pic' program in troff (groff for GNU people).
With this, it would be straightforward to draw the vertical
axis dotted, or dashed, or blank, wherever there is an interval
with missing data; otherwise, as an unbroken line.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 26-Mar-03                                       Time: 09:59:23
------------------------------ XFMail ------------------------------


From kwan022 at stat.auckland.ac.nz  Wed Mar 26 12:20:04 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 26 Mar 2003 23:20:04 +1200 (NZST)
Subject: [R] ifelse()
Message-ID: <Pine.LNX.4.33.0303262315460.32110-100000@stat56.stat.auckland.ac.nz>

Hi,

I'm not sure if this can be done but..

I know that with ifelse() I can do something like:
  ifelse(x <= 3, 1, 2)
to go through each element in my vector x, and if x_i <= 3 substitute the 
number with 1 else with 2.  Essentially I'll get a vector with 2 levels.

Can I tweak it so I can get 3-levels?  For example:
  if(x <= 3) then 1
  elseif(3 < x <= 4) then 2
  elseif(x > 4) then 3

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From jasont at indigoindustrial.co.nz  Wed Mar 26 11:49:27 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 26 Mar 2003 22:49:27 +1200
Subject: [R] ifelse()
In-Reply-To: 
	<Pine.LNX.4.33.0303262315460.32110-100000@stat56.stat.auckland.ac.nz>; from
	kwan022@stat.auckland.ac.nz on Wed, Mar 26, 2003 at 11:20:04PM +1200
References: <Pine.LNX.4.33.0303262315460.32110-100000@stat56.stat.auckland.ac.nz>
Message-ID: <20030326224927.A28632@camille.indigoindustrial.co.nz>

On Wed, Mar 26, 2003 at 11:20:04PM +1200, Ko-Kang Kevin Wang wrote:
> Hi,
> 
> I'm not sure if this can be done but..
> 
> I know that with ifelse() I can do something like:
>   ifelse(x <= 3, 1, 2)
> to go through each element in my vector x, and if x_i <= 3 substitute the 
> number with 1 else with 2.  Essentially I'll get a vector with 2 levels.
> 
> Can I tweak it so I can get 3-levels?  For example:
>   if(x <= 3) then 1
>   elseif(3 < x <= 4) then 2
>   elseif(x > 4) then 3

You can, like this (1 if zz < 5, 2 if  5 <= zz < 10, 3 if zz >= 10) 
> zz <- 1:20
> ifelse(zz < 5, 1, ifelse(zz < 10, 2,3))
 [1] 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz


From kwan022 at stat.auckland.ac.nz  Wed Mar 26 12:47:57 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 26 Mar 2003 23:47:57 +1200 (NZST)
Subject: [R] Re: ifelse()
In-Reply-To: <Pine.LNX.4.33.0303262315460.32110-100000@stat56.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.33.0303262347000.32256-100000@stat56.stat.auckland.ac.nz>

Hi,

I've found a much better solution than using ifelse().  I found about 
cut() from MASS4 Page 383, which actually does a better job .

On Wed, 26 Mar 2003, Ko-Kang Kevin Wang wrote:

> Date: Wed, 26 Mar 2003 23:20:04 +1200 (NZST)
> From: Ko-Kang Kevin Wang <kwan022 at stat.auckland.ac.nz>
> To: R Help <r-help at stat.math.ethz.ch>
> Subject: ifelse()
> 
> Hi,
> 
> I'm not sure if this can be done but..
> 
> I know that with ifelse() I can do something like:
>   ifelse(x <= 3, 1, 2)
> to go through each element in my vector x, and if x_i <= 3 substitute the 
> number with 1 else with 2.  Essentially I'll get a vector with 2 levels.
> 
> Can I tweak it so I can get 3-levels?  For example:
>   if(x <= 3) then 1
>   elseif(3 < x <= 4) then 2
>   elseif(x > 4) then 3
> 
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From Ted.Harding at nessie.mcc.ac.uk  Wed Mar 26 11:41:45 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 26 Mar 2003 10:41:45 -0000 (GMT)
Subject: [R] Re: Bar plot with variable width (down a drill hole) - n
In-Reply-To: <XFMail.030326095923.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.030326104145.Ted.Harding@nessie.mcc.ac.uk>

On 26-Mar-03 Ted Harding wrote:
> On 25-Mar-03 Phillip J. Allen wrote:
> However, this kind of situation needs thought about alternative
> ways of representing it.
> 
> One possibility might be to have the vertical axis invisible,
> so that gaps in the data are represented by gaps in the axis
> (and then there would be no need for "adding a bit to true zeros").
> Possibly this can be arranged by some setting of "par", though
> I can't seem to achieve it with barplot. Ideas, anyone?
> (It looks as though "axis" in barplot means the scale which is
> plotted below or on the side, and not the lines which bound the
> barplot itself).

Just had a thought on this front, and it works!

Where there are missing data, give intensity the value "NA", but
fill in the gaps in width as before (and you don't need to "thicken"
true zeros any more -- unless you want to):

from <- c(0, 1.2, 4.0, 4.2, 5.0, 25.0, 30.1, 45)
to <- c(1.2, 4.0, 4.2, 5.0, 25, 30.1, 36.2, 50)
intensity <- c(0, 1, 3, 2, 1, 0, 2, 5)

y<-intensity;
y<-c(y[1:7],NA,y[8])

w<-(-(to - from))
w<-c(w[1:7],-(45-36.2),w[8])

barplot(y, w, space = 0, horiz = TRUE, ylim = c(-50, 0))

Cheers,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 26-Mar-03                                       Time: 10:41:45
------------------------------ XFMail ------------------------------


From maechler at stat.math.ethz.ch  Wed Mar 26 12:00:28 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 26 Mar 2003 12:00:28 +0100
Subject: [R] ifelse()
In-Reply-To: <20030326224927.A28632@camille.indigoindustrial.co.nz>
References: <Pine.LNX.4.33.0303262315460.32110-100000@stat56.stat.auckland.ac.nz>
	<20030326224927.A28632@camille.indigoindustrial.co.nz>
Message-ID: <16001.34892.154355.441422@gargle.gargle.HOWL>

>>>>> "Jason" == Jason Turner <jasont at indigoindustrial.co.nz>
>>>>>     on Wed, 26 Mar 2003 22:49:27 +1200 writes:

    Jason> On Wed, Mar 26, 2003 at 11:20:04PM +1200, Ko-Kang
    Jason> Kevin Wang wrote:
    >> Hi,
    >> 
    >> I'm not sure if this can be done but..
    >> 
    >> I know that with ifelse() I can do something like:
    >> ifelse(x <= 3, 1, 2) to go through each element in my
    >> vector x, and if x_i <= 3 substitute the number with 1
    >> else with 2.  Essentially I'll get a vector with 2
    >> levels.
    >> 
    >> Can I tweak it so I can get 3-levels?  For example: if(x
    >> <= 3) then 1 elseif(3 < x <= 4) then 2 elseif(x > 4) then
    >> 3

    Jason> You can, like this (1 if zz < 5, 2 if 5 <= zz < 10, 3
    Jason> if zz >= 10)
    >> zz <- 1:20 ifelse(zz < 5, 1, ifelse(zz < 10, 2,3))
    Jason>  [1] 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3

Yes, but for cases like this (interval cutting),
the function
		cut()
will be much more efficient (and its call easier to read).
Martin


From schlegel at cs.uni-duesseldorf.de  Wed Mar 26 12:10:11 2003
From: schlegel at cs.uni-duesseldorf.de (schlegel@cs.uni-duesseldorf.de)
Date: Wed, 26 Mar 2003 12:10:11 +0100
Subject: [R] Solving equations
Message-ID: <3E818A93.FC981C57@cs.uni-duesseldorf.de>

Hello,

Does somebody knows if there exists a function which solves a set of
equation, say f(vars),
for the variables vars (similar to Solve in mathematica).
The functions I am considering are of the form f(t) ~ A*exp(B*t), where
A and B are matrices.

Thanks Thomas


From kwan022 at stat.auckland.ac.nz  Wed Mar 26 13:13:57 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu, 27 Mar 2003 00:13:57 +1200 (NZST)
Subject: [R] Plotting K-M Curve when have several strata
Message-ID: <Pine.LNX.4.33.0303270007580.32256-100000@stat56.stat.auckland.ac.nz>

Hi,

If I have:
  foo <- survfit(y ~ x)
where y is a survival object and x is a n-level factor.  The documentation 
says when I plot(foo), the confidence intervals will not be plotted (which 
I guess is understandable as otherwise the plot will get really messy).  

I tried to plot with confidence intervals by using:
  plot(foo, conf.int = TRUE)
and indeed the resulting plot is messy.  However I'm just wondering if I 
can (suppose x is a 2-level factor) use different colours and line types 
for the confidence lines?  If I do:  
  plot(foo, conf.int = TRUE, col = 1:2)
then I'll get two different colours.  What I would like is to then plot 
the confidence lines using lty = 2 (while keeping the colour).

Can I do this?

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From david.barron at jesus.ox.ac.uk  Wed Mar 26 13:25:30 2003
From: david.barron at jesus.ox.ac.uk (David Barron)
Date: Wed, 26 Mar 2003 12:25:30 -0000
Subject: [R] Plotting K-M Curve when have several strata
References: <Pine.LNX.4.33.0303270007580.32256-100000@stat56.stat.auckland.ac.nz>
Message-ID: <00db01c2f392$caf19540$ed8901a3@sbs.ox.ac.uk>

You could try something like:

plot(foo[1],conf.int=TRUE)
par(new=TRUE)
plot(foo[2],conf.int=TRUE,col=2)

Seems to work!

David

----- Original Message -----
From: "Ko-Kang Kevin Wang" <kwan022 at stat.auckland.ac.nz>
To: "R Help" <r-help at stat.math.ethz.ch>
Sent: Wednesday, March 26, 2003 12:13 PM
Subject: [R] Plotting K-M Curve when have several strata


> Hi,
>
> If I have:
>   foo <- survfit(y ~ x)
> where y is a survival object and x is a n-level factor.  The documentation
> says when I plot(foo), the confidence intervals will not be plotted (which
> I guess is understandable as otherwise the plot will get really messy).
>
> I tried to plot with confidence intervals by using:
>   plot(foo, conf.int = TRUE)
> and indeed the resulting plot is messy.  However I'm just wondering if I
> can (suppose x is a 2-level factor) use different colours and line types
> for the confidence lines?  If I do:
>   plot(foo, conf.int = TRUE, col = 1:2)
> then I'll get two different colours.  What I would like is to then plot
> the confidence lines using lty = 2 (while keeping the colour).
>
> Can I do this?
>
> --
> Cheers,
>
> Kevin
>
> --------------------------------------------------------------------------
----
> /* Time is the greatest teacher, unfortunately it kills its students */
>
> --
> Ko-Kang Kevin Wang
> Master of Science (MSc) Student
> SLC Tutor and Lab Demonstrator
> Department of Statistics
> University of Auckland
> New Zealand
> Homepage: http://www.stat.auckland.ac.nz/~kwan022
> Ph: 373-7599
>     x88475 (City)
>     x88480 (Tamaki)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>


From r.ghezzo at staff.mcgill.ca  Wed Mar 26 15:05:59 2003
From: r.ghezzo at staff.mcgill.ca (r.ghezzo)
Date: Wed, 26 Mar 2003 09:05:59 -0500
Subject: [R] RODBC and Excel in Widows
Message-ID: <3E9A84A2@webmail.mcgill.ca>

HI,
 no sorry, so far nobody answer. So it probably does not have a solution.
 Excell is from you.know.who

>===== Original Message From Meinhard Ploner <meinhard.ploner at univie.ac.at> 
=====
>Hello!
>Did you resolve the problem?
>I'm interested in the solution, too.
>Meinhard
>
>On Thursday, March 13, 2003, at 07:21  PM, R. Heberto Ghezzo wrote:
>
>> Hello, I have some problems with RODBC and Excel in Win98
>> I am using R 1.6.2 and just upgraded RODBC to the last version on CRAN.
>> I have an Excel file with columns Number, Name, Sex, Age, FEV1 on Sheet
>> 1 and Number, Age, FEV1, Name, Sex on Sheet 2.
>> Now I open the channel to the file
>>> chan1 <- odbcConnectExcel("c:/testOdbc.xls")
>>> tables(chan1)
>> and the list appears with the 2 tables
>>> aa -> sqlFetch(chan1,"Sheet1")
>> and aa has the Number, Name and Sex columns correct but Age and FEV1
>> are
>> all NAs
>>> bb -> sqlfetch(chan1,"Sheet2")
>> and bb is correct!
>> So all numeric columns after a column of characters become NAs
>> Is this an Excel problem or an sql problem.? I did not find anything in
>> the r-help archives relative to this problem.
>> Thanks for any help
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>

R. Heberto Ghezzo Ph.D.
Meakins-Christie Labs
McGill University
Montreal - Que - Canada


From heeringa at let.rug.nl  Wed Mar 26 16:23:05 2003
From: heeringa at let.rug.nl (Heeringa W.J.)
Date: Wed, 26 Mar 2003 16:23:05 +0100
Subject: [R] CMDS
Message-ID: <03032616230500.20714@geri>

Dear statisticians,

I have a small question about the Classifical Multidimensional scaling 
routine in R. Is this procedure always metric?

Best regards,

Wilbert Heeringa


From david.meyer at ci.tuwien.ac.at  Wed Mar 26 15:23:51 2003
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Wed, 26 Mar 2003 15:23:51 +0100
Subject: [R] RODBC and Excel in Widows
References: <3E9A84A2@webmail.mcgill.ca>
Message-ID: <3E81B7F7.F389A3AD@ci.tuwien.ac.at>

You might look at Thomas Baier's DCOM interface as an alternative to the
odbc-method for accessing EXCEL-files.

-d

"r.ghezzo" wrote:
> 
> HI,
>  no sorry, so far nobody answer. So it probably does not have a solution.
>  Excell is from you.know.who
> 
> >===== Original Message From Meinhard Ploner <meinhard.ploner at univie.ac.at>
> =====
> >Hello!
> >Did you resolve the problem?
> >I'm interested in the solution, too.
> >Meinhard
> >
> >On Thursday, March 13, 2003, at 07:21  PM, R. Heberto Ghezzo wrote:
> >
> >> Hello, I have some problems with RODBC and Excel in Win98
> >> I am using R 1.6.2 and just upgraded RODBC to the last version on CRAN.
> >> I have an Excel file with columns Number, Name, Sex, Age, FEV1 on Sheet
> >> 1 and Number, Age, FEV1, Name, Sex on Sheet 2.
> >> Now I open the channel to the file
> >>> chan1 <- odbcConnectExcel("c:/testOdbc.xls")
> >>> tables(chan1)
> >> and the list appears with the 2 tables
> >>> aa -> sqlFetch(chan1,"Sheet1")
> >> and aa has the Number, Name and Sex columns correct but Age and FEV1
> >> are
> >> all NAs
> >>> bb -> sqlfetch(chan1,"Sheet2")
> >> and bb is correct!
> >> So all numeric columns after a column of characters become NAs
> >> Is this an Excel problem or an sql problem.? I did not find anything in
> >> the r-help archives relative to this problem.
> >> Thanks for any help
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>
> 
> R. Heberto Ghezzo Ph.D.
> Meakins-Christie Labs
> McGill University
> Montreal - Que - Canada
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
        Mag. David Meyer            Wiedner Hauptstrasse 8-10
Vienna University of Technology     A-1040 Vienna/AUSTRIA
         Department of              Tel.: (+431) 58801/10772
Statistics and Probability Theory   Fax.: (+431) 58801/10798


From ripley at stats.ox.ac.uk  Wed Mar 26 15:24:35 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 26 Mar 2003 14:24:35 +0000 (GMT)
Subject: [R] RODBC and Excel in Widows
In-Reply-To: <3E9A84A2@webmail.mcgill.ca>
Message-ID: <Pine.LNX.4.44.0303261418480.4439-100000@gannet.stats>

Why don't you debug the code and send the patch needed to the maintainer?
R is supposed to be a collaborative project, and we need more 
contributors, especially on Windows.

Looking forwards to your positive contribution ....

On Wed, 26 Mar 2003, r.ghezzo wrote:

> HI,
>  no sorry, so far nobody answer. So it probably does not have a solution.
>  Excell is from you.know.who
> 
> >===== Original Message From Meinhard Ploner <meinhard.ploner at univie.ac.at> 
> =====
> >Hello!
> >Did you resolve the problem?
> >I'm interested in the solution, too.
> >Meinhard
> >
> >On Thursday, March 13, 2003, at 07:21  PM, R. Heberto Ghezzo wrote:
> >
> >> Hello, I have some problems with RODBC and Excel in Win98
> >> I am using R 1.6.2 and just upgraded RODBC to the last version on CRAN.
> >> I have an Excel file with columns Number, Name, Sex, Age, FEV1 on Sheet
> >> 1 and Number, Age, FEV1, Name, Sex on Sheet 2.
> >> Now I open the channel to the file
> >>> chan1 <- odbcConnectExcel("c:/testOdbc.xls")
> >>> tables(chan1)
> >> and the list appears with the 2 tables
> >>> aa -> sqlFetch(chan1,"Sheet1")
> >> and aa has the Number, Name and Sex columns correct but Age and FEV1
> >> are
> >> all NAs
> >>> bb -> sqlfetch(chan1,"Sheet2")
> >> and bb is correct!
> >> So all numeric columns after a column of characters become NAs
> >> Is this an Excel problem or an sql problem.? I did not find anything in
> >> the r-help archives relative to this problem.
> >> Thanks for any help
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>
> 
> R. Heberto Ghezzo Ph.D.
> Meakins-Christie Labs
> McGill University
> Montreal - Que - Canada
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From philippe.hupe at wanadoo.fr  Wed Mar 26 15:35:50 2003
From: philippe.hupe at wanadoo.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Wed, 26 Mar 2003 15:35:50 +0100
Subject: [R] Spatial Clustering
Message-ID: <3E81BAC6.5000803@wanadoo.fr>

Hello,

Does anyone know any package which can perform spatial clustering ?

Thanks.


From tmulholl at bigpond.net.au  Wed Mar 26 15:56:19 2003
From: tmulholl at bigpond.net.au (Tom Mulholland)
Date: Wed, 26 Mar 2003 22:56:19 +0800
Subject: [R] RODBC and Excel in Widows
In-Reply-To: <3E70CC37.2B633888@mcgill.ca>
Message-ID: <000401c2f3a7$dd3f5b00$0202a8c0@WorkGroup>

I routinely use Excel to store my data. I am using 1.6.2 and probably have
the latestet RODBC. I recall when I first started using it having similar
problems. If I recall correctly the solution (which I didn't identify
precisely) was to make sure that my spreadsheet didn't have any abnormal
cells. By that I mean I made sure all labels were textual on the first line,
no extra spaces anywhere (especially at the end of a cell) If I were using
numbers as codes I spelt them out.

So my advice is to try to start really small and make your way upwards. If
something doesn't work try putting quotes around it etc. When I get to work
tomorrow I'll see if I have any notes that I may have written when I was
plodding through this phase. I can recall a problem that I had with a
product from you.know.who that wouldn't work because a space was formatted
as bold. So it is quite possible for an excel sheet to have hidden "stuff"
that you can't see.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of R. Heberto Ghezzo
Sent: Friday, 14 March 2003 2:22 AM
To: r-help at stat.math.ethz.ch
Subject: [R] RODBC and Excel in Widows


Hello, I have some problems with RODBC and Excel in Win98
I am using R 1.6.2 and just upgraded RODBC to the last version on CRAN.
I have an Excel file with columns Number, Name, Sex, Age, FEV1 on Sheet
1 and Number, Age, FEV1, Name, Sex on Sheet 2.
Now I open the channel to the file
> chan1 <- odbcConnectExcel("c:/testOdbc.xls")
> tables(chan1)
and the list appears with the 2 tables
> aa -> sqlFetch(chan1,"Sheet1")
and aa has the Number, Name and Sex columns correct but Age and FEV1 are
all NAs
> bb -> sqlfetch(chan1,"Sheet2")
and bb is correct!
So all numeric columns after a column of characters become NAs
Is this an Excel problem or an sql problem.? I did not find anything in
the r-help archives relative to this problem.
Thanks for any help

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Wed Mar 26 16:24:25 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 26 Mar 2003 07:24:25 -0800
Subject: [R] Solving equations
References: <3E818A93.FC981C57@cs.uni-duesseldorf.de>
Message-ID: <3E81C629.5070103@pdf.com>

	  What do you mean "solve"?  Do you want to solve for "t" in f(t) = 
A*exp(B*t), where A and B are given square matrices?  Is "t" a scalar or 
also a square matrix or something else, and does "*" refer to 
element-wise multiplication (as in R) or matrix multiplication (written 
"%*%" in R)?

	  Suppose we want to solve

	  F = A %*% exp(B%*%t)

where A, B, and F are given square matrices.  I might approach it as 
follows:

	  Ainv.F <- solve(A, F) # compute inverse(A)%*%F

	  AiF.eig <- eigen(Ainv.F)

#  Then check to make sure there are no repeated eigenvalues,
#  or if there are that a Jordon canonical form is still diagonal.
#  This will give Ainv.F in a form
#        Evec %*% diag(Lam) %*% inverse(Evec)
#  The natural log of this is just
#        Evec %*% diag(log(Lam)) %*% inverse(Evec)

 From this point, you can solve for "t"

Does this help?
Sorry this is a bit cryptic, but I don't have time to write and debug 
code for this myself right now.

Hope this helps,
Spencer Graves

schlegel at cs.uni-duesseldorf.de wrote:
> Hello,
> 
> Does somebody knows if there exists a function which solves a set of
> equation, say f(vars),
> for the variables vars (similar to Solve in mathematica).
> The functions I am considering are of the form f(t) ~ A*exp(B*t), where
> A and B are matrices.
> 
> Thanks Thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Roger.Bivand at nhh.no  Wed Mar 26 16:25:50 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 26 Mar 2003 16:25:50 +0100 (CET)
Subject: [R] Spatial Clustering
In-Reply-To: <3E81BAC6.5000803@wanadoo.fr>
Message-ID: <Pine.LNX.4.44.0303261610450.3759-100000@reclus.nhh.no>

On Wed, 26 Mar 2003, Philippe Hup? wrote:

> Hello,
> 
> Does anyone know any package which can perform spatial clustering ?
> 
That depends on what you mean by spatial clustering? Of points on a plane, 
maybe - if so, spatial, spatstat, and splancs offer functions. In the 
environmental data domain, maybe ade4, but you would need to be a little 
more specific about your research question.

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no


From spencer.graves at pdf.com  Wed Mar 26 16:25:30 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 26 Mar 2003 07:25:30 -0800
Subject: [R] Spatial Clustering
References: <3E81BAC6.5000803@wanadoo.fr>
Message-ID: <3E81C66A.7010804@pdf.com>

Did you look at library(cluster) in R?

Spencer Graves

Philippe Hup? wrote:
> Hello,
> 
> Does anyone know any package which can perform spatial clustering ?
> 
> Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From dvumani at hotmail.com  Wed Mar 26 18:35:27 2003
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Wed, 26 Mar 2003 17:35:27 +0000
Subject: [R] Simple NLME problem (I hope)  
Message-ID: <F147zBdDA6VzpJxV0Hv00002661@hotmail.com>


Dear R-Users:

I would like to fit a multilevel model using LME such that the parameters 
after fitting the multilevel in two separate groups and when I use the 
complete data (with interactions between the grouping variable and the other 
variables) set are comparable (or the same).

The problem I am having currently is that I am not sure whether it is 
possible to let the random error term to vary by group such that the models 
are comparable. At present only one random error term is estimate and this 
"sort of" distorts the parameter estimates for the fixed and other random 
effects.

Looking forward to your help.



Vumani Dlamini


From gvasudevan at medarex.com  Wed Mar 26 19:35:25 2003
From: gvasudevan at medarex.com (Vasudevan, Geetha)
Date: Wed, 26 Mar 2003 10:35:25 -0800
Subject: [R] 2 scatter plots in the same graphic window....
Message-ID: <8249C3256E593D4FB066BB9998D9F7E41CF191@ca2-fs03.ca2.2k.medarex.com>

Hello,

I am trying to do a scatter plot of x1,y1 and x2,y2 in the same graphics window with diff col/pch values. i cannot get it to do them in the same window. 

what is the cmd to do this? thanks.


From hb at maths.lth.se  Wed Mar 26 19:54:22 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 26 Mar 2003 19:54:22 +0100
Subject: [R] 2 scatter plots in the same graphic window....
In-Reply-To: <8249C3256E593D4FB066BB9998D9F7E41CF191@ca2-fs03.ca2.2k.medarex.com>
Message-ID: <000501c2f3c9$1d5f5c00$e502eb82@alpha.wehi.edu.au>

plot() and points(), e.g.

x <- matrix(rnorm(300), ncol=3)
plot(x[,1],x[,2], pch=1, col="red")
points(x[,1],x[,3], pch=2, col="blue")

Cheers

Henrik Bengtsson
Lund University

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Vasudevan, Geetha
> Sent: den 26 mars 2003 19:35
> To: r-help at stat.math.ethz.ch
> Subject: [R] 2 scatter plots in the same graphic window....
> 
> 
> Hello,
> 
> I am trying to do a scatter plot of x1,y1 and x2,y2 in the 
> same graphics window with diff col/pch values. i cannot get 
> it to do them in the same window. 
> 
> what is the cmd to do this? thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>


From ben at zoo.ufl.edu  Wed Mar 26 20:08:32 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Wed, 26 Mar 2003 14:08:32 -0500 (EST)
Subject: [R] 2 scatter plots in the same graphic window....
In-Reply-To: <8249C3256E593D4FB066BB9998D9F7E41CF191@ca2-fs03.ca2.2k.medarex.com>
Message-ID: <Pine.LNX.4.44.0303261406270.16699-100000@bolker.zoo.ufl.edu>


  Either

n1 <- length(x1)
n2 <- length(x2)
plot(c(x1,x2),c(y1,y2),col=rep(c(1,2),c(n1,n2)), pch=rep(c(1,2),c(n1,n2))

OR

plot(x1,y1,xlim=range(c(x1,x2)),ylim=range(c(y1,y2)),col=1,pch=1)
points(x2,y2,col=2,pch=2)

will work.

  Ben Bolker

On Wed, 26 Mar 2003, Vasudevan, Geetha wrote:

> Hello,
> 
> I am trying to do a scatter plot of x1,y1 and x2,y2 in the same graphics
> window with diff col/pch values. i cannot get it to do them in the same
> window.
> 
> what is the cmd to do this? thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From spencer.graves at pdf.com  Wed Mar 26 20:07:27 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 26 Mar 2003 11:07:27 -0800
Subject: [R] 2 scatter plots in the same graphic window....
References: <8249C3256E593D4FB066BB9998D9F7E41CF191@ca2-fs03.ca2.2k.medarex.com>
Message-ID: <3E81FA6F.3000205@pdf.com>

x1 <- 1:9
y1 <- x1
x2 <- x1
y2 <- 9-x1
plot(c(0, 9), c(0, 9), type="n")
points(x1, y1, col=1, pch=1)
points(x2, y2, col=2, pch=2)

Is this what you want?
Spencer Graves

Vasudevan, Geetha wrote:
> Hello,
> 
> I am trying to do a scatter plot of x1,y1 and x2,y2 in the same graphics window with diff col/pch values. i cannot get it to do them in the same window. 
> 
> what is the cmd to do this? thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From gvasudevan at medarex.com  Wed Mar 26 20:35:24 2003
From: gvasudevan at medarex.com (Vasudevan, Geetha)
Date: Wed, 26 Mar 2003 11:35:24 -0800
Subject: [R] hist overlay...
Message-ID: <8249C3256E593D4FB066BB9998D9F7E41CF192@ca2-fs03.ca2.2k.medarex.com>

thanks to all for the 2d scatter plot.

i have one more. 

how do i plot 'hist(y1, col="red") and hist(y2,col="blue") in the same window? 

thanks again.


From ys3 at cec.wustl.edu  Wed Mar 26 20:35:25 2003
From: ys3 at cec.wustl.edu (aprilsun)
Date: Wed, 26 Mar 2003 13:35:25 -0600
Subject: [R] a statistic question about chisq.test()
Message-ID: <002201c2f3ce$d9acaca0$60a5fc80@mulan>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030326/e6e50517/attachment.pl

From jerome at hivnet.ubc.ca  Wed Mar 26 20:52:43 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed, 26 Mar 2003 11:52:43 -0800
Subject: [R] hist overlay...
In-Reply-To: <8249C3256E593D4FB066BB9998D9F7E41CF192@ca2-fs03.ca2.2k.medarex.com>
References: <8249C3256E593D4FB066BB9998D9F7E41CF192@ca2-fs03.ca2.2k.medarex.com>
Message-ID: <200303261958.LAA09510@hivnet.ubc.ca>


Do you mean two separate plots in the same window? If so, read the 
documentation on "multiple figure environment" in the chapter on "Graphical 
Procedures" in the manual "An Introduction to R".

Alternately, reading plot help file will lead you to the par help file, which 
will enable you to do "multiple figure environment" and lots more...

Jerome Asselin

On March 26, 2003 11:35 am, Vasudevan, Geetha wrote:
> thanks to all for the 2d scatter plot.
>
> i have one more.
>
> how do i plot 'hist(y1, col="red") and hist(y2,col="blue") in the same
> window?
>
> thanks again.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ihaka at stat.auckland.ac.nz  Wed Mar 26 21:26:46 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Thu, 27 Mar 2003 08:26:46 +1200
Subject: [R] hist overlay...
References: <8249C3256E593D4FB066BB9998D9F7E41CF192@ca2-fs03.ca2.2k.medarex.com>
Message-ID: <3E820D06.30007@stat.auckland.ac.nz>

Vasudevan, Geetha wrote:
> thanks to all for the 2d scatter plot.
> 
> i have one more. 
> 
> how do i plot 'hist(y1, col="red") and hist(y2,col="blue") in the same window? 

Here are a couple of ways to do what you have asked for
(as oppposed to want you want :-).

I'm assuming that you precompute the histograms as follows:

x <- rnorm(100)
y <- rnorm(100)
xh = hist(x, plot=FALSE)
yh = hist(y, plot=FALSE)

You can customize these two "hist" calls anyway you like.

Here is a function which will plot the result as superimposed bars.

hist2v <-
function(xh, yh) {
   plot.new()
   plot.window(xlim=range(xh$breaks, yh$breaks),
               ylim=range(0, xh$density, yh$density))
   rect(xh$breaks[-length(xh$breaks)], 0,
        xh$breaks[-1], xh$density, border="blue")
   rect(yh$breaks[-length(yh$breaks)], 0,
        yh$breaks[-1], yh$density, border="red")
   axis(1)
   axis(2)
}

and one which will plot only the tops of the bars:

hist2v <-
function(xh, yh) {
   plot.new()
   plot.window(xlim=range(xh$breaks, yh$breaks),
               ylim=range(0, xh$density, yh$density))
   nx = length(xh$density)
   ny = length(yh$density)
   lines(rep(xh$breaks, c(1, rep(2, nx - 1), 1)),
         rep(xh$density, each = 2), col = "red")
   lines(rep(yh$breaks, c(1, rep(2, ny - 1), 1)),
         rep(yh$density, each = 2), col = "blue")
   axis(1)
   axis(2)
}

Either of these functions could be called as

hist2v(xh, yh)

It would be easy to add colour and line texture arguments.

-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand


From gvasudevan at medarex.com  Wed Mar 26 21:31:29 2003
From: gvasudevan at medarex.com (Vasudevan, Geetha)
Date: Wed, 26 Mar 2003 12:31:29 -0800
Subject: [R] hist overlay...
Message-ID: <8249C3256E593D4FB066BB9998D9F7E41CF194@ca2-fs03.ca2.2k.medarex.com>

Cool, thanks!


-----Original Message-----
From:	Ross Ihaka [mailto:ihaka at stat.auckland.ac.nz]
Sent:	Wed 3/26/2003 12:26 PM
To:	Vasudevan, Geetha
Cc:	r-help at stat.math.ethz.ch
Subject:	Re: [R] hist overlay...
Vasudevan, Geetha wrote:
> thanks to all for the 2d scatter plot.
> 
> i have one more. 
> 
> how do i plot 'hist(y1, col="red") and hist(y2,col="blue") in the same window? 

Here are a couple of ways to do what you have asked for
(as oppposed to want you want :-).

I'm assuming that you precompute the histograms as follows:

x <- rnorm(100)
y <- rnorm(100)
xh = hist(x, plot=FALSE)
yh = hist(y, plot=FALSE)

You can customize these two "hist" calls anyway you like.

Here is a function which will plot the result as superimposed bars.

hist2v <-
function(xh, yh) {
   plot.new()
   plot.window(xlim=range(xh$breaks, yh$breaks),
               ylim=range(0, xh$density, yh$density))
   rect(xh$breaks[-length(xh$breaks)], 0,
        xh$breaks[-1], xh$density, border="blue")
   rect(yh$breaks[-length(yh$breaks)], 0,
        yh$breaks[-1], yh$density, border="red")
   axis(1)
   axis(2)
}

and one which will plot only the tops of the bars:

hist2v <-
function(xh, yh) {
   plot.new()
   plot.window(xlim=range(xh$breaks, yh$breaks),
               ylim=range(0, xh$density, yh$density))
   nx = length(xh$density)
   ny = length(yh$density)
   lines(rep(xh$breaks, c(1, rep(2, nx - 1), 1)),
         rep(xh$density, each = 2), col = "red")
   lines(rep(yh$breaks, c(1, rep(2, ny - 1), 1)),
         rep(yh$density, each = 2), col = "blue")
   axis(1)
   axis(2)
}

Either of these functions could be called as

hist2v(xh, yh)

It would be easy to add colour and line texture arguments.

-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand


From ligges at statistik.uni-dortmund.de  Wed Mar 26 22:24:01 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 26 Mar 2003 22:24:01 +0100
Subject: [R] a statistic question about chisq.test()
References: <002201c2f3ce$d9acaca0$60a5fc80@mulan>
Message-ID: <3E821A71.2A1FA766@statistik.uni-dortmund.de>

aprilsun wrote:
> 
> Hi,
> In the chisq.test(), if the expected frequency for some categories is <5, there will be a warning message which says
> Warning message:
> Chi-squared approximation may be incorrect in: chisq.test(x, p = probs)

It's a warning message, not an error. It point's you to the problem that
a number < 5 is not "large", whereas in theory "large" numbers are
assumed when running this test.

 
> I am wondering whether there are some methods to get rid of this mistake... Seems the ?chisq.test() doesn't provide more
> options to solve this problem. Or, the only choice is to preprocess the data to avoid this situation?

It depends on the problem. Fisher's exact test (or it's extended
version) might be an alternative, see ?fisher.test and an appropriate
statistics textbook.

Uwe Ligges


> Thanks a lot!
> 
> aprilsun


From jmagalhaes at oninetspeed.pt  Wed Mar 26 23:25:25 2003
From: jmagalhaes at oninetspeed.pt (Jorge =?iso-8859-15?q?Magalh=E3es?=)
Date: Wed, 26 Mar 2003 22:25:25 +0000
Subject: [R] Categorical data (Monte Carlo exact p-value)
Message-ID: <200303262225.26038.jmagalhaes@oninetspeed.pt>

In R program, I can perform categorical data test analysis like  Odds ratio 
test  in stratified 2x2 contingency tables? I do that in statistical package 
StatXact, but i would like perform the same test in R environment.

Thanks very much

Jorge Magalh?es


From wettenhall at wehi.edu.au  Wed Mar 26 23:30:15 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Thu, 27 Mar 2003 09:30:15 +1100 (EST)
Subject: [R] R TclTk iwidgets::comboboc
Message-ID: <Pine.LNX.4.44.0303270919550.16075-100000@unix24.alpha.wehi.edu.au>

Hi,

I am trying to create a drop-down combobox in R TclTk.  

The following works fine for a ListBox but fails for a combobox:

################# THIS WORKS FINE - CREATES AN EMPTY LISTBOX ##
tt<-tktoplevel()
win <- .Tk.subwin(tt)
.Tcl(paste("listbox",.Tk.ID(win),.Tcl.args()))
tkpack(win)

################## THIS FAILS - ATTEMPTS TO CREATE A COMBOBOX ##
tt<-tktoplevel()
win <- .Tk.subwin(tt)
.Tcl(paste("iwidgets::combobox",.Tk.ID(win),.Tcl.args()))
Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), 
class = "tclObj") : 
        [tcl] .

I am using R 1.6.2 (with tcltk package 1.6.2) and ActiveTcl 
8.3.5.0 in Windows 2000.  Below I've included some of the 
relevant ActiveTcl help.  I'm not sure why it has "funny characters".


#
# Non?.editable Dropdown Combobox
#
iwidgets::combobox .cb1 ?.labeltext Month: \ ?.selectioncommand 
{puts ?selected: [.cb1 getcurselection]"} \ ?.editable false 
?.listheight 185 ?.popupcursor hand1 .cb1 insert list end Jan 
Feb Mar Apr May June Jul Aug Sept Oct Nov Dec

BTW, Thanks very much to all organizers and presenters at the 
DSC 2003 - a huge sucess!

Regards,
James

--------------------------------------------------------------------------
James Wettenhall                                  Tel: (+61 3) 9345 2629
Division of Genetics and Bioinformatics           Fax: (+61 3) 9347 0852
The Walter & Eliza Hall Institute         E-mail: wettenhall at wehi.edu.au
 of Medical Research,                     Mobile: (+61 / 0 ) 438 527 921    
1G Royal Parade,
Parkville, Vic 3050, Australia
http://www.wehi.edu.au
--------------------------------------------------------------------------


From sck2348 at cacs.louisiana.edu  Thu Mar 27 00:41:46 2003
From: sck2348 at cacs.louisiana.edu (Komanduru Sai C)
Date: Wed, 26 Mar 2003 17:41:46 -0600 (CST)
Subject: [R] nls
Message-ID: <200303262341.h2QNflq13394@mailer.cacs.louisiana.edu>

Hi,

 df <- read.table("data.txt", header=T);						
 library(nls);
 fm <- nls(y ~ a*(x+d)^(-b), df, start=list(a=max(df->y,na.rm=T)/2,b=1,d=0));

 I was using the following routine which was giving Singular Gradient, Error in 
numericDeriv(form[[3]], names(ind), env) : 
        Missing value or an Infinity produced when evaluating the model errors.
        

I also tried the below method given by Dr. Dougla Bates. But still am getting 
the error.
 Error in numericDeriv(form[[3]], names(ind), env) : 
        Missing value or an Infinity produced when evaluating the model


 df <- read.table("data.txt", header=T);						
 df1 = na.omit(df[, 1:2])
 library(nls);
 fm = nls(y ~ (x+d)^(-exp(lb)), data = df1, start=c(lb = 0, d = 0),alg = 
'plinear', trace = TRUE);




  I would be glad if someone can help me.

Thanks & Regards,
Sai Charan Komanduru

>To: Komanduru Sai C <sck2348 at cacs.louisiana.edu>
>Cc: r-help at stat.math.ethz.ch
>Subject: Re: [R] nls
>From: Douglas Bates <bates at stat.wisc.edu>
>Date: 19 Feb 2003 08:33:52 -0600
>User-Agent: Gnus/5.0808 (Gnus v5.8.8) XEmacs/21.4 (Common Lisp)
>MIME-Version: 1.0
>X-Keywords: 
>
>Komanduru Sai C <sck2348 at cacs.louisiana.edu> writes:
>
>> Hi,
>> 
>> I am using nls library
>> 
>> df <- read.table("data.txt", header=T);						
>> library(nls);
>> fm <- nls(y ~ a*(x+d)^(-b), df, start=list(a=max(df->y,na.rm=T)/2,b=1,d=0));
>> coef(fm); 
>> q();
>
>1) Are you sure you meant max(df->y, na.rm=TRUE) and not 
>   max(df$y, na.rm=TRUE)? 
>
>2) To begin you may want to use a data frame without the missing data
>   df1 = na.omit(df[, 1:2])
>
>3) Use the plinear algorithm and change from b to exp(lb)
>
>   fm = nls(y ~ (x+d)^(-exp(lb)), data = df1, start=c(lb = 0, d = 0),
>            alg = 'plinear', trace = TRUE)
>
>-- 
>Douglas Bates                            bates at stat.wisc.edu
>Statistics Department                    608/262-2598
>University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/


From spencer.graves at pdf.com  Thu Mar 27 01:11:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 26 Mar 2003 16:11:34 -0800
Subject: [R] nls
References: <200303262341.h2QNflq13394@mailer.cacs.louisiana.edu>
Message-ID: <3E8241B6.3060408@pdf.com>

Have you tried using "optim"?

An article in the Americal Statistician said that in S-Plus, "nls" often 
had convergence problems that could be solved by first using "nlminb" 
and then using the output of "nlminb" as starting values for "nls".

R is not S-Plus, but it's possible that "nls" may have some of the same 
problems in R as it does in S-Plus.  R does not have "nlminb" [Ripley 
said in a separate context, "We do not copy defective software"], but it 
has "optim", which seems to be better.  In particular, "optim" will 
estimate the Hessian, and you can compute eigenvalues of the Hessian to 
make sure it is positive definite before passing the output of "optim" 
to "nls".  Or maybe you won't even need "nls".

I'm not sure, but I believe the suggestion to use "nlminb" first came 
from the following article:

16.  McCullough, B. D.   (1999), ``Assessing the reliability of 
statistical software: Part II'', The American Statistician,  53  , 149-159

I hope this helps.
Spencer Graves

Komanduru Sai C wrote:
> Hi,
> 
>  df <- read.table("data.txt", header=T);						
>  library(nls);
>  fm <- nls(y ~ a*(x+d)^(-b), df, start=list(a=max(df->y,na.rm=T)/2,b=1,d=0));
> 
>  I was using the following routine which was giving Singular Gradient, Error in 
> numericDeriv(form[[3]], names(ind), env) : 
>         Missing value or an Infinity produced when evaluating the model errors.
>         
> 
> I also tried the below method given by Dr. Dougla Bates. But still am getting 
> the error.
>  Error in numericDeriv(form[[3]], names(ind), env) : 
>         Missing value or an Infinity produced when evaluating the model
> 
> 
>  df <- read.table("data.txt", header=T);						
>  df1 = na.omit(df[, 1:2])
>  library(nls);
>  fm = nls(y ~ (x+d)^(-exp(lb)), data = df1, start=c(lb = 0, d = 0),alg = 
> 'plinear', trace = TRUE);
> 
> 
> 
> 
>   I would be glad if someone can help me.
> 
> Thanks & Regards,
> Sai Charan Komanduru
> 
> 
>>To: Komanduru Sai C <sck2348 at cacs.louisiana.edu>
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] nls
>>From: Douglas Bates <bates at stat.wisc.edu>
>>Date: 19 Feb 2003 08:33:52 -0600
>>User-Agent: Gnus/5.0808 (Gnus v5.8.8) XEmacs/21.4 (Common Lisp)
>>MIME-Version: 1.0
>>X-Keywords: 
>>
>>Komanduru Sai C <sck2348 at cacs.louisiana.edu> writes:
>>
>>
>>>Hi,
>>>
>>>I am using nls library
>>>
>>>df <- read.table("data.txt", header=T);						
>>>library(nls);
>>>fm <- nls(y ~ a*(x+d)^(-b), df, start=list(a=max(df->y,na.rm=T)/2,b=1,d=0));
>>>coef(fm); 
>>>q();
>>
>>1) Are you sure you meant max(df->y, na.rm=TRUE) and not 
>>  max(df$y, na.rm=TRUE)? 
>>
>>2) To begin you may want to use a data frame without the missing data
>>  df1 = na.omit(df[, 1:2])
>>
>>3) Use the plinear algorithm and change from b to exp(lb)
>>
>>  fm = nls(y ~ (x+d)^(-exp(lb)), data = df1, start=c(lb = 0, d = 0),
>>           alg = 'plinear', trace = TRUE)
>>
>>-- 
>>Douglas Bates                            bates at stat.wisc.edu
>>Statistics Department                    608/262-2598
>>University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Thu Mar 27 01:15:46 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 26 Mar 2003 16:15:46 -0800
Subject: [R] Categorical data (Monte Carlo exact p-value)
References: <200303262225.26038.jmagalhaes@oninetspeed.pt>
Message-ID: <3E8242B2.7070503@pdf.com>

A search in the standard R documentation for "Fisher's exact test" 
reveals a command "fisher.test", and a search for "Chi-square" reveals a 
"chisq.test".

Spencer Graves

Jorge Magalh?es wrote:
> In R program, I can perform categorical data test analysis like  Odds ratio 
> test  in stratified 2x2 contingency tables? I do that in statistical package 
> StatXact, but i would like perform the same test in R environment.
> 
> Thanks very much
> 
> Jorge Magalh?es
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From wettenhall at wehi.edu.au  Thu Mar 27 01:25:08 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Thu, 27 Mar 2003 11:25:08 +1100 (EST)
Subject: [R] R TclTk iwidgets::combobox
In-Reply-To: <x2ptody9vb.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0303271114060.16531-100000@unix24.alpha.wehi.edu.au>

Thanks Peter,

I've started a new R session (in Windows) and managed to get 
both ways working now : 

### THIS WORKS !!! ###
library(tcltk)
tclRequire("IWidgets")
tt<-tktoplevel()
combo <- tkwidget(tt,"iwidgets::combobox")
tkpack(combo)

### AND THIS WORKS TOO !!! ###
tt<-tktoplevel()
win <- .Tk.subwin(tt)
.Tcl(paste("iwidgets::combobox",.Tk.ID(win),.Tcl.args()))
tkpack(win)

But they both fail in my old R session - maybe I've tclRequired 
another package or loaded another package which is interfering 
or maybe a Tcl object hasn't been cleaned from memory properly.

Thanks very much for your help!
Regards,
James



On 27 Mar 2003, Peter Dalgaard BSA wrote:

> James Wettenhall <wettenhall at wehi.edu.au> writes:
> 
> > Hi,
> > 
> > I am trying to create a drop-down combobox in R TclTk.  
> > 
> > The following works fine for a ListBox but fails for a combobox:
> > 
> > ################# THIS WORKS FINE - CREATES AN EMPTY LISTBOX ##
> > tt<-tktoplevel()
> > win <- .Tk.subwin(tt)
> > .Tcl(paste("listbox",.Tk.ID(win),.Tcl.args()))
> > tkpack(win)
> > 
> > ################## THIS FAILS - ATTEMPTS TO CREATE A COMBOBOX ##
> > tt<-tktoplevel()
> > win <- .Tk.subwin(tt)
> > .Tcl(paste("iwidgets::combobox",.Tk.ID(win),.Tcl.args()))
> > Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), 
> > class = "tclObj") : 
> >         [tcl] .
> 
> Hmm, can't see why that shouldn't work. On Linux, this seems to work fine:
> 
> tt<-tktoplevel()
> combo <- tkwidget(tt,"iwidgets::combobox")
> tkpack(combo)
> 
> and your code seems to work as well...
> 
> You remembered to tclRequire("Iwidgets"), I assume?
> 
> 

-- 
--------------------------------------------------------------------------
James Wettenhall                                  Tel: (+61 3) 9345 2629
Division of Genetics and Bioinformatics           Fax: (+61 3) 9347 0852
The Walter & Eliza Hall Institute         E-mail: wettenhall at wehi.edu.au
 of Medical Research,                     Mobile: (+61 / 0 ) 438 527 921    
1G Royal Parade,
Parkville, Vic 3050, Australia
http://www.wehi.edu.au
--------------------------------------------------------------------------


From matthew_wiener at merck.com  Thu Mar 27 02:07:38 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Wed, 26 Mar 2003 20:07:38 -0500
Subject: [R] a statistic question about chisq.test()
Message-ID: <AEBD81486231A343B1813FE62D335225013177D9@usrymx15.merck.com>

One other option.

I usually find that when I do the chisq.test with exact p-value calculation,
I find the p-values are nearly identical to the results when I use the
approximation and get the warnings (I'm usually dealing with just a few bins
with less than 5, and many bins with more than 5).

So frequently, when I'm using chisq.test in a program, and expect to do it
many times, I'll sometimes eliminate the warnings this way:

old.warn <- options()$warn
options(warn = -1)
< do the chisq.test here >
options(warn = old.warn)

This will suppress the warning messages.  

Hope this helps.

Matt Wiener

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: Wednesday, March 26, 2003 4:24 PM
To: aprilsun
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] a statistic question about chisq.test()


aprilsun wrote:
> 
> Hi,
> In the chisq.test(), if the expected frequency for some categories is <5,
there will be a warning message which says
> Warning message:
> Chi-squared approximation may be incorrect in: chisq.test(x, p = probs)

It's a warning message, not an error. It point's you to the problem that
a number < 5 is not "large", whereas in theory "large" numbers are
assumed when running this test.

 
> I am wondering whether there are some methods to get rid of this
mistake... Seems the ?chisq.test() doesn't provide more
> options to solve this problem. Or, the only choice is to preprocess the
data to avoid this situation?

It depends on the problem. Fisher's exact test (or it's extended
version) might be an alternative, see ?fisher.test and an appropriate
statistics textbook.

Uwe Ligges


> Thanks a lot!
> 
> aprilsun

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------


From kjetil at entelnet.bo  Thu Mar 27 03:47:29 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed, 26 Mar 2003 22:47:29 -0400
Subject: [R] Categorical data (Monte Carlo exact p-value)
In-Reply-To: <200303262225.26038.jmagalhaes@oninetspeed.pt>
Message-ID: <3E822E01.17945.819CD8@localhost>

On 26 Mar 2003 at 22:25, Jorge Magalh?es wrote:

Does
?mantelhaen.test

do what you want? (it is in package ctest).

Kjetil Halvorsen

> In R program, I can perform categorical data test analysis like  Odds ratio 
> test  in stratified 2x2 contingency tables? I do that in statistical package 
> StatXact, but i would like perform the same test in R environment.
> 
> Thanks very much
> 
> Jorge Magalh?es
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From kjetil at entelnet.bo  Thu Mar 27 03:47:30 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed, 26 Mar 2003 22:47:30 -0400
Subject: [R] a statistic question about chisq.test()
In-Reply-To: <002201c2f3ce$d9acaca0$60a5fc80@mulan>
Message-ID: <3E822E02.24509.819F2A@localhost>

On 26 Mar 2003 at 13:35, aprilsun wrote:

First, look at the expected values under the null. If only a few are 
below 5 and all are above 1 there are probably no problem.

Second, you can use chisq.test with the argument
simulate.p.value=TRUE

Kjetil Halvorsen


> Hi, 
> In the chisq.test(), if the expected frequency for some categories is <5, there will be a warning message which says
> Warning message: 
> Chi-squared approximation may be incorrect in: chisq.test(x, p = probs)
> 
> I am wondering whether there are some methods to get rid of this mistake... Seems the ?chisq.test() doesn't provide more
> options to solve this problem. Or, the only choice is to preprocess the data to avoid this situation?
> 
> Thanks a lot!
> 
> aprilsun
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From MSchwartz at medanalytics.com  Thu Mar 27 03:56:01 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 26 Mar 2003 20:56:01 -0600
Subject: [R] Re: Bar plot with variable width (down a drill hole) - now
 missing intervals?
In-Reply-To: <3E80CEC7.6090901@attglobal.net>
References: <3E80CEC7.6090901@attglobal.net>
Message-ID: <3E826841.9050902@MedAnalytics.com>

Phillip J. Allen wrote:
> Hi again,
> 
> Thanks Ted and Marc its works.  But of course after pulling in in some 
> real life data I discoverd one hitch.  Often there are missing 
> intervals.  For example:
> from <- c(0, 1.2, 4.0, 4.2, 5.0, 25.0, 30.1, 45)
> to <- c(1.2, 4.0, 4.2, 5.0, 25, 30.1, 36.2, 50)
> intensity <- c(0, 1, 3, 2, 1, 0, 2, 5)
> barplot(intensity, width = -(to - from),
>        space = 0, horiz = TRUE, ylim = c(-40, 0))
> 
> And it appears a barplot() is just stacking bars one on top the other 
> and the help page doesn't indicate anyway to position the bar along the 
> y-axis.  So does anyone have a nifty trick to to fill in blank gaps?  At 
> least my database can check for "overlaping" intervals before I get the 
> data into R.
> 
> Thanks,
> 
> Phillip J. Allen
> Consulting Geochemist/Geologist
> Lima Peru
> e-mail: paallen at attglobal.net


Phillip,

Sorry for the delay in replying to this e-mail. I was busy much of the 
day catching up on a project for a client and finally had a chance for a 
breather this evening.

I took note of Ted's reply using NA in the intensity vector which is the 
right approach. I thought you might want an automated approach to 
dealing with missing intervals from dataset to dataset. The code below 
should work, with the assumption that at least the first interval is OK 
and should handle multiple missing intervals in one set. I added a 
second missing interval in your example above to the code below. You 
should test this a bit more to be sure.

What this does is to scan the vectors for a break in the sequence and 
inserts (using insert() )the missing interval(s) with an NA value.

Note that a "0" interval value will have a line in the interval, whereas 
a missing interval with an NA will show nothing.

Hope that this helps.

Marc Schwartz

------------------------

from <- c(0, 1.2, 4.0, 4.2,  5.0, 25.0, 30.1, 45, 55)
to <-   c(1.2, 4.0, 4.2, 5.0, 25, 30.1, 36.2, 50, 63)
intensity <- c(0, 1, 3, 2, 1, 0, 2, 5, 7)

insert <- function(old.vec, pos, val)
{
   left <- old.vec[1:pos]
   right <- old.vec[-(1:pos)]

   new.vec <- c(left, val, right)

   invisible(new.vec)
}

i <- 1

repeat
{
   if (to[i] != from[i + 1])
   {
     from <- insert(from, i, to[i])
     to <- insert(to, i, from[i + 2])
     intensity <- insert(intensity, i, NA)

     i <- i + 1
   }

   i <- i + 1

   if (i >= length(from)) break
}

barplot(intensity, width = -(to - from),
         space = 0, horiz = TRUE,
         ylab = "Depth (m)", ylim = c(-63, 0))

barplot(intensity, width = -(to - from),
         space = 0, horiz = TRUE,
         ylab = "Depth (m)", ylim = c(-63, 0))

axis(2, labels = seq(60, 0, -10), las = 2)
box()

 > from
  [1]  0.0  1.2  4.0  4.2  5.0 25.0 30.1 36.2 45.0 50.0 55.0
 > to
  [1]  1.2  4.0  4.2  5.0 25.0 30.1 36.2 45.0 50.0 55.0 63.0
 > intensity
  [1]  0  1  3  2  1  0  2 NA  5 NA  7
 >


From ozric at web.de  Thu Mar 27 09:30:11 2003
From: ozric at web.de (Christian Schulz)
Date: Thu, 27 Mar 2003 09:30:11 +0100
Subject: [R] missing value analysis for survey data
Message-ID: <001701c2f43b$15b90510$4301ebd9@pc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030327/5b8cd7ea/attachment.pl

From tw.chan at sociology.oxford.ac.uk  Thu Mar 27 11:32:28 2003
From: tw.chan at sociology.oxford.ac.uk (Tak Wing Chan)
Date: Thu, 27 Mar 2003 10:32:28 +0000
Subject: [R] Multinomial logistic regression under R and Stata
Message-ID: <3E82D33C.7050700@sociology.oxford.ac.uk>

Dear Colleagues

I have been fitting some multinomial logistic regression models using R 
(version 1.6.1 on a linux box) and Stata 7. Although the vast majority 
of the parameter estimates and standard errors I get from R are the same 
as those from Stata (given rounding errors and so on), there are a few 
estimates for the same model which are quite different. I would be most 
grateful if colleagues could advise me as to what might be causing this, 
and should I worry ...

Anyway, with R, I have been using the function multinom under the 
package nnet. Below are two examples where the estimates for standard 
error differ substantially between R and Stata:

          beta              s.e.
R:        5.939880 2.920165
Stata:  5.939747 5.455495

R:      11.228705 2.191625
Stata: 11.22761  4.630293

The parameters concerned are the quadratic term of a quantitative 
variable (measuring social status). I notice that the s.e. for this 
quadratic term are large anyway compared to other s.e. in the model.

There are other differences between R and Stata, and these concerned the 
intercept terms. Here is an example:

           beta            s.e.
R:        0.2870793 0.4512347
Stata: -0.2109653 0.5053566

Since both estimates are not significantly different from zero, I trust 
I can ignore the difference between the estimates. Or could I?

Many thanks in advance for any help. Please let me know if I should 
provide further info.

With best wishes.  

Wing
  

-- 
Department of Sociology, University of Oxford,
Littlegate House, St Ebbes, Oxford OX1 1PT, UK
tel: +44 (1865) 286176, fax: +44 (1865) 286171
http://users.ox.ac.uk/~sfos0006


From JonesW at kssg.com  Thu Mar 27 11:38:18 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Thu, 27 Mar 2003 10:38:18 -0000
Subject: [R] Na action with Lowess smoothing
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE20EB@GIMLI>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030327/d3ef2488/attachment.pl

From luchini at ehess.cnrs-mrs.fr  Thu Mar 27 12:24:53 2003
From: luchini at ehess.cnrs-mrs.fr (=?iso-8859-15?q?St=E9phane=20Luchini?=)
Date: Thu, 27 Mar 2003 12:24:53 +0100
Subject: [R] How to obtain final gradient estimation from optim
Message-ID: <200303271224.53553.luchini@ehess.cnrs-mrs.fr>

I use optim to compute maximum likelihood estimations without giving an 
analytical gradient to optim. However, I would like to 
get an output of the final numerical gradient vector and the final matrix of 
contributions to the gradient. But I did not 
find any mention of this kind of output in help pages. Does anyone know how to 
do that ?

Stephane Luchini
GREQAM
Marseille, France


From ripley at stats.ox.ac.uk  Thu Mar 27 11:58:40 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 27 Mar 2003 10:58:40 +0000 (GMT)
Subject: [R] Multinomial logistic regression under R and Stata
In-Reply-To: <3E82D33C.7050700@sociology.oxford.ac.uk>
Message-ID: <Pine.LNX.4.44.0303271048240.1470-100000@gannet.stats>

Perhaps you should ask Stata how it finds its estimates, and why it 
disagrees with R?

R uses the observed information matrix for the standard errors.  It is
also possible to use the expected (Fisher) information matrix.  Where they
differ, the observed one is generally regarded as a better choice,
especially when as here the curvature is measured over a reasonably-sized
neighbourhood.

Intercepts often depend on coding, and you should cross-check the coding.
More generally, such differences can be caused by the Hauck-Donner effect 
and lack of convergence, so it is almost always worth playing with the 
convergence criteria.

On Thu, 27 Mar 2003, Tak Wing Chan wrote:

> Dear Colleagues
> 
> I have been fitting some multinomial logistic regression models using R 
> (version 1.6.1 on a linux box) and Stata 7. Although the vast majority 
> of the parameter estimates and standard errors I get from R are the same 
> as those from Stata (given rounding errors and so on), there are a few 
> estimates for the same model which are quite different. I would be most 
> grateful if colleagues could advise me as to what might be causing this, 
> and should I worry ...
> 
> Anyway, with R, I have been using the function multinom under the 
> package nnet. Below are two examples where the estimates for standard 
> error differ substantially between R and Stata:
> 
>           beta              s.e.
> R:        5.939880 2.920165
> Stata:  5.939747 5.455495
> 
> R:      11.228705 2.191625
> Stata: 11.22761  4.630293
> 
> The parameters concerned are the quadratic term of a quantitative 
> variable (measuring social status). I notice that the s.e. for this 
> quadratic term are large anyway compared to other s.e. in the model.
> 
> There are other differences between R and Stata, and these concerned the 
> intercept terms. Here is an example:
> 
>            beta            s.e.
> R:        0.2870793 0.4512347
> Stata: -0.2109653 0.5053566
> 
> Since both estimates are not significantly different from zero, I trust 
> I can ignore the difference between the estimates. Or could I?
> 
> Many thanks in advance for any help. Please let me know if I should 
> provide further info.
> 
> With best wishes.  
> 
> Wing
>   
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar 27 12:52:19 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 27 Mar 2003 11:52:19 +0000 (GMT)
Subject: [R] How to obtain final gradient estimation from optim
In-Reply-To: <200303271224.53553.luchini@ehess.cnrs-mrs.fr>
Message-ID: <Pine.LNX.4.44.0303271142320.1577-100000@gannet.stats>

On Thu, 27 Mar 2003, [iso-8859-15] St?phane Luchini wrote:

> I use optim to compute maximum likelihood estimations without giving an 
> analytical gradient to optim. However, I would like to 
> get an output of the final numerical gradient vector and the final matrix of 
> contributions to the gradient. But I did not 
> find any mention of this kind of output in help pages. Does anyone know how to 
> do that ?

No, and optim does not even necessarily calculate a gradient.
But if it does, it is supposed to be zero at a maximum....

I don't lnow what you mean by `contributions to the gradient': optim works 
with the (I presume) log-likelihood.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rjporter at mindspring.com  Thu Mar 27 13:27:28 2003
From: rjporter at mindspring.com (Bob Porter)
Date: Thu, 27 Mar 2003 07:27:28 -0500
Subject: [R] a statistic question about chisq.test() (aprilsun)
Message-ID: <035901c2f45c$3b63f3d0$6501a8c0@HydePark>

The Chisquare test is based upon a normal approx of the (essentially) binomial
distribution for the data in question.  Small EXPECTED (not observed) values
(<5) suggest a asymetric distribution and potential errors in inferential
conclusions.  The alternative is the exact test, which calculates the exact
probabilities of the observed distribution, or a more extreme one, given the
constraining expectations.

It is usually much more useful to make the statistics fit the data question than
to assume or force the vice versa.

--Bob Porter, Tampa


> Hi,
> In the chisq.test(), if the expected frequency for some categories is <5,
there will be a warning message which says
> Warning message:
> Chi-squared approximation may be incorrect in: chisq.test(x, p = probs)
>
> I am wondering whether there are some methods to get rid of this mistake...
Seems the ?chisq.test() doesn't provide more
> options to solve this problem. Or, the only choice is to preprocess the data
to avoid this situation?
>
> Thanks a lot!
>
> aprilsun


From mcmt84 at yahoo.com  Thu Mar 27 13:59:31 2003
From: mcmt84 at yahoo.com (Tom Smith)
Date: Thu, 27 Mar 2003 04:59:31 -0800 (PST)
Subject: [R] Using ? for object summaries
Message-ID: <20030327125931.22860.qmail@web41204.mail.yahoo.com>

This short script makes ?name give help on "name" and
provides a summary of the variable "name"
[specifically, str("name") and summary ("name")]. I
add this to my .Rprofile to save my fingers some
typing.

"?" <- function(name) {
  try(str(name))
  options(show.error.messages = FALSE)
  try(print(summary(name)))
  try(do.call("help",list(deparse(substitute(name)))))
  options(show.error.messages = TRUE)
}


From ghosh at science.unitn.it  Thu Mar 27 14:22:43 2003
From: ghosh at science.unitn.it (Ghosh Mini)
Date: Thu, 27 Mar 2003 14:22:43 +0100 (MET)
Subject: [R] Request
In-Reply-To: <20030325163421.N4227@itc.it>
Message-ID: <Pine.OSF.4.44.0303271413420.26253-100000@omega.science.unitn.it>



Dear all,

I am trying to learn R.
Is it possible to find the mean of some rows (of some table) and to put it
in new table.

For example we have following table

         date      x      y      z
1  05-23-2001      7      1      3
2  05-24-2001      8      4      5
3  05-24-2001      6      0      0
4  05-24-2001     26      2      6
5  06-19-2001      0      7      0
6  06-19-2001      5      0      2


and I want to make the table

         date      x      y      z
1  05-23-2001
2  05-24-2001      (mean values for each day's)
6  06-19-2001

Is it possible to do this using R???

If possible pl. help me. Thanking you.

Regards,
mini


From sundar.dorai-raj at pdf.com  Thu Mar 27 14:49:51 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 27 Mar 2003 05:49:51 -0800
Subject: [R] Request
References: <Pine.OSF.4.44.0303271413420.26253-100000@omega.science.unitn.it>
Message-ID: <3E83017F.7050807@pdf.com>



Ghosh Mini wrote:
> 
> Dear all,
> 
> I am trying to learn R.
> Is it possible to find the mean of some rows (of some table) and to put it
> in new table.
> 
> For example we have following table
> 
>          date      x      y      z
> 1  05-23-2001      7      1      3
> 2  05-24-2001      8      4      5
> 3  05-24-2001      6      0      0
> 4  05-24-2001     26      2      6
> 5  06-19-2001      0      7      0
> 6  06-19-2001      5      0      2
> 
> 
> and I want to make the table
> 
>          date      x      y      z
> 1  05-23-2001
> 2  05-24-2001      (mean values for each day's)
> 6  06-19-2001
> 
> Is it possible to do this using R???
> 
> If possible pl. help me. Thanking you.
> 


Let `dframe' contain your first table. Then use aggregate:


aggregate(dframe[, c("x", "y", "z")],
           list(date = dframe$date),
           mean)

HTH,

Sundar


From ccleland at optonline.net  Thu Mar 27 14:50:34 2003
From: ccleland at optonline.net (ccleland@optonline.net)
Date: Thu, 27 Mar 2003 08:50:34 -0500
Subject: [R] Request
Message-ID: <a9f1aafedd.afedda9f1a@optonline.net>

An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20030327/0726248e/attachment.html

From dvumani at hotmail.com  Thu Mar 27 15:12:58 2003
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Thu, 27 Mar 2003 14:12:58 +0000
Subject: [R] random error and grouping variable correlated
Message-ID: <F100B53WU1VOmmuoqfy0000ea56@hotmail.com>

Dear R-users:

Is it possible to fit linear mixed models using LME when the random error is 
correlated with one of the covariates in the model?

Thanks.

Vumani Dlamini


From luchini at ehess.cnrs-mrs.fr  Thu Mar 27 15:22:56 2003
From: luchini at ehess.cnrs-mrs.fr (=?iso-8859-1?q?St=E9phane=20Luchini?=)
Date: Thu, 27 Mar 2003 15:22:56 +0100
Subject: [R] How to obtain final gradient estimation from optim
In-Reply-To: <Pine.LNX.4.44.0303271142320.1577-100000@gannet.stats>
References: <Pine.LNX.4.44.0303271142320.1577-100000@gannet.stats>
Message-ID: <200303271522.56052.luchini@ehess.cnrs-mrs.fr>



Le Jeudi 27 Mars 2003 12:52, ripley at stats.ox.ac.uk a ?crit :
> On Thu, 27 Mar 2003, [iso-8859-15] St?phane Luchini wrote:
> > I use optim to compute maximum likelihood estimations without giving an
> > analytical gradient to optim. However, I would like to
> > get an output of the final numerical gradient vector and the final matrix
> > of contributions to the gradient. But I did not
> > find any mention of this kind of output in help pages. Does anyone know
> > how to do that ?
>
> No, and optim does not even necessarily calculate a gradient.
> But if it does, it is supposed to be zero at a maximum....

It is zero at the theoretical level, it is not zero at a numerical level and 
it can be used to compute the Outer Product of the Gradient as an estimator 
of the information matrix instead of the inverse hessian. For long 
computation, it enables one to get an estimation of standard deviations 
without computing the hessian matrix which can take a long time. 

>
> I don't lnow what you mean by `contributions to the gradient': optim works
> with the (I presume) log-likelihood.

The matrix of the contribution to the gradient with a typical element $G_{ti}$ 
defined as follows:

$$G_{ti}(y,\theta) = \partial \ell_t(u,\theta) / \partial \theta_i$$

where $\ell$ is the contribution i to the log-lokelihood. Using such a matrix, 
one can verify convergence using a Gauss-Newton regression such that

$$Intercept = G b + residuals$$

and the parameters b as to be close to zero if the parameters estimates are 
close to the true parameters. This is why it is usefull to get as an output 
(when it is avalaible) of the gradient and the G matrix. Moreover, when 
analytical gradients are not straightforward to define, it will allow one to 
compare the numerical results of two procedures (one with giving to R the 
analytical gradient and one without it).


From hi_ono2001 at ybb.ne.jp  Thu Mar 27 15:49:04 2003
From: hi_ono2001 at ybb.ne.jp (Hisaji Ono)
Date: Thu, 27 Mar 2003 23:49:04 +0900
Subject: [R] About ability of  "allShortestPaths" function in e1071 package 
Message-ID: <004401c2f470$034c9420$048001db@webgis>

Hello.

 R's e1071 package has "allShortestPaths" function using Floyd's algorithm.

 It is very useful for road network analysis. I'll try to analyze facility
allocation programs using this.

 I'd like to know how much nodes this function can deal with?

 And for larger nodes(for example million nodes), allShortestPaths employs
graph partition algorithm?


 Regards.


From f.mercier at fournier.fr  Thu Mar 27 15:54:51 2003
From: f.mercier at fournier.fr (f.mercier@fournier.fr)
Date: Thu, 27 Mar 2003 15:54:51 +0100
Subject: [R] Plot of Canonical Correlation Analysis
Message-ID: <OFBF40D911.F616DE7C-ONC1256CF6.0051548B@fournier.fr>

Dear all,

I didn't find any graphical solution in the package "mva" to plot the
canonical scores from a CCA (canonical correlation analysis).
Does anybody knows how to plot or has anybody already programmed :
      - the map of the canonical scores,
      - the graph of the canonical weights,
      - the correlation circle i.e. the canonical loadings ?
Thank you for help ...

Francois M.


From spencer.graves at pdf.com  Thu Mar 27 16:08:38 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 27 Mar 2003 07:08:38 -0800
Subject: [R] Request
References: <a9f1aafedd.afedda9f1a@optonline.net>
Message-ID: <3E8313F6.7030903@pdf.com>

"rowMeans" also works.  Alternatives can be timed using "proc.time".

Spencer Graves

ccleland at optonline.net wrote:
> Ghosh Mini <ghosh at science.unitn.it <mailto:ghosh at science.unitn.it>>
> 
>  > Is it possible to find the mean of some rows (of some table) and
>  > to put it in new table.
> 
> Maybe you want something like this:
> 
> apply(mydata[, c("x", "y", "z")], 2, function(x){tapply(x, 
> list(mydata$date), mean, na.rm=TRUE)})
> 
> hope this helps,
> 
> Chuck Cleland
> 
> 
>  
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From otoomet at econ.dk  Thu Mar 27 16:28:51 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Thu, 27 Mar 2003 16:28:51 +0100
Subject: [R] How to obtain final gradient estimation from optim
In-Reply-To: <200303271522.56052.luchini@ehess.cnrs-mrs.fr> (message from
	Stphane Luchini on Thu, 27 Mar 2003 15:22:56 +0100)
References: <Pine.LNX.4.44.0303271142320.1577-100000@gannet.stats>
	<200303271522.56052.luchini@ehess.cnrs-mrs.fr>
Message-ID: <200303271528.h2RFSp901957@punik.econ.au.dk>

Hi,

 | From: St?phane Luchini <luchini at ehess.cnrs-mrs.fr>
 | 
 | > No, and optim does not even necessarily calculate a gradient.
 | > But if it does, it is supposed to be zero at a maximum....
 | 
 | It is zero at the theoretical level, it is not zero at a numerical level and 
 | it can be used to compute the Outer Product of the Gradient as an estimator 
 | of the information matrix instead of the inverse hessian. For long 
 | computation, it enables one to get an estimation of standard deviations 
 | without computing the hessian matrix which can take a long time. 

you can calculate information matrix _only_ if your gradient is in a
matrix form (as I understand this is what you call for the matrix of
the contributions).  I.e. your gradient should have one (vector)
component for each observation (or each individual).  I am not sure if
optim() can handle such (documentation says the function should return
a scalar result...).  In that case you may use BHHH method as

  hess <- function(theta, ...) {
    g <- gradient(theta, ...)
    -t(g) %*% g
  }

You may take a look at my package econ at
www.obs.ee/~siim/econ_0.0-4.tar.gz which includes BHHH method and can
return the gradient too (however, not in matrix form).  I should warn
you that it is not well documented nor tested.  If you are interested
in Newton-Raphson method, you may look at nlm() too.

 | The matrix of the contribution to the gradient with a typical element $G_{ti}$ 
 | defined as follows:
 | 
 | $$G_{ti}(y,\theta) = \partial \ell_t(u,\theta) / \partial \theta_i$$


you mean

$$G_{ti}(y,\theta) = \partial \ell_i(u,\theta) / \partial \theta_t$$

where i means observations (individuals) and t parameters?  Or am I
misunderstanding something?

Perhaps it helps

Ott


From wmorgan at mitre.org  Thu Mar 27 16:30:03 2003
From: wmorgan at mitre.org (William T Morgan)
Date: 27 Mar 2003 10:30:03 -0500
Subject: [R] locfit troubles
In-Reply-To: <Pine.GSO.4.10.10303251409380.1485-100000@quetelet.stat.ucla.edu>
References: 
	 <Pine.GSO.4.10.10303251409380.1485-100000@quetelet.stat.ucla.edu>
Message-ID: <1048779003.11571.109.camel@paradise.mitre.org>

On Tue, 2003-03-25 at 17:15, Roger Peng wrote: 
> locfit() evaluates the regression surface over a grid that's chosen
> adaptively.  In small bandwidth situations, it can run out of memory for
> storing the grid.  Try increasing the `maxk' argument.

That was it! We had gone over the book but never quite made it to page
218. Thank you for a timely and accurate reply.

-- 
William T Morgan <wmorgan at mitre.org>
The Mitre Corporation


From tlumley at u.washington.edu  Thu Mar 27 16:54:15 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 27 Mar 2003 07:54:15 -0800 (PST)
Subject: [R] How to obtain final gradient estimation from optim
In-Reply-To: <200303271522.56052.luchini@ehess.cnrs-mrs.fr>
Message-ID: <Pine.A41.4.44.0303270749170.211842-100000@homer04.u.washington.edu>

On Thu, 27 Mar 2003, [iso-8859-1] Stphane Luchini wrote:

> Le Jeudi 27 Mars 2003 12:52, ripley at stats.ox.ac.uk a crit :
> >
> > I don't lnow what you mean by `contributions to the gradient': optim works
> > with the (I presume) log-likelihood.
>
> The matrix of the contribution to the gradient with a typical element $G_{ti}$
> defined as follows:
>
> $$G_{ti}(y,\theta) = \partial \ell_t(u,\theta) / \partial \theta_i$$
>
> where $\ell$ is the contribution i to the log-lokelihood. Using such a matrix,
> one can verify convergence using a Gauss-Newton regression such that
>
> $$Intercept = G b + residuals$$
>

As Brian pointed out, optim() works with the objective function (eg
loglikelihood).  In your notation, optim never sees anything with a t
subscript so it can't possibly do this.

What's more, it is not necessary that the loglikelihood is computed as sum
of independent terms.  There are several examples in the R distribution
where R is used to maximised a likelihood that isn't of this form.

	-thomas


From plummer at iarc.fr  Thu Mar 27 18:17:28 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: 27 Mar 2003 18:17:28 +0100
Subject: [R] Re: [Rd] R-1.7.0 beta available
In-Reply-To: <3E830A1B.20200@MedAnalytics.com>
References: <Pine.WNT.4.44.0303271352300.1760-100000@gannet.stats.ox.ac.uk>
	 <3E830A1B.20200@MedAnalytics.com>
Message-ID: <1048785528.2862.113.camel@xena>

On Thu, 2003-03-27 at 15:26, Marc Schwartz wrote:
> Prof Brian D Ripley wrote:
> > On Thu, 27 Mar 2003, Marc Schwartz wrote:
> > 
> > 
> >>ripley at stats.ox.ac.uk wrote:
> >>
> >>>On Wed, 26 Mar 2003, Marc Schwartz wrote:
> >>>
> >>>[...]
> >>>
> >>>
> >>>>As an aside, RH 9 to be called 'Shrike', (curiously skipping 8.1 due to
> >>>>binary incompatibility issues) will be available on March 31 to paid RHN
> >>>>subscribers. It will be available a week later to all folks.
> >>>
> >>>
> >>>Martyn Plummer has already mentioned this and that he will be testing it
> >>>before release.
> >>
> >>OK...I must have missed that post. Apologies.
> > 
> > 
> > It was to R-core, so there was no way for you to know.
> > 
> > 
> >>I will be downloading the RH 9 ISO's early as a paid RHN subscriber, so
> >>if there is anything that I can do to help Martyn in validating or
> >>confirming any issues, let me know. I have cc'd Martyn on this post.
> > 
> > 
> > Thanks for the offer: I am sure Martyn will appreciate it.  Meanwhile I am
> > replacing a RH7.2 machine with an RH8.0 one.
> > 
> > Brian
> > 
> 
> Prof. Ripley,
> 
> Thanks for the clarification.
> 
> FWIW, RH 8.0 has been very stable on my Dell i8200 laptop, upon which I 
> run RH 8.0 dual-booted using GRUB with WinXP Pro.
> 
> It will be interesting to see the improvements in RH 9, especially any 
> performance enhancements and X related updates including, as I 
> understand, better AA font support, which will be helpful on the UXGA 
> LCD panel.
> 
> Martyn, let me know if I can be of help.

Many thanks for your help Marc. You just have to run "make check" on the
latest beta on RH 9.0 and let us know what happens. A clean install,
rather than an upgrade is the best testing environment since an upgrade
may leave RPMS from previous installations lying around, but you are not
obliged to do this.  I don't expect any problems this time since the
major change relates to threading and, as Brian has already pointed out,
R doesn't use threads.

By the way, I shall continue to provide R RPMS for RH 7.x for those
people who follow the rule of never upgrading to an x.0 release.

Martyn


From Friedrich.Leisch at ci.tuwien.ac.at  Thu Mar 27 19:12:43 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu, 27 Mar 2003 19:12:43 +0100
Subject: [R] 
	Re: About ability of  "allShortestPaths" function in e1071 package 
In-Reply-To: <004401c2f470$034c9420$048001db@webgis>
References: <004401c2f470$034c9420$048001db@webgis>
Message-ID: <16003.16155.236695.187268@galadriel.ci.tuwien.ac.at>

>>>>> On Thu, 27 Mar 2003 23:49:04 +0900,
>>>>> Hisaji Ono (HO) wrote:

  > Hello.
  >  R's e1071 package has "allShortestPaths" function using Floyd's algorithm.

  >  It is very useful for road network analysis. I'll try to analyze facility
  > allocation programs using this.

  >  I'd like to know how much nodes this function can deal with?

  >  And for larger nodes(for example million nodes), allShortestPaths employs
  > graph partition algorithm?

no, the current implementation uses matrices to represent the graph,
hence it can only handle several thousand nodes depending on thje
amount of memory your computer has. millions of nodes is currently
impossible.

best,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------


From jyuzh at yahoo.com  Thu Mar 27 20:09:23 2003
From: jyuzh at yahoo.com (Jane Yu)
Date: Thu, 27 Mar 2003 11:09:23 -0800 (PST)
Subject: [R] get the values of unique ID
Message-ID: <20030327190923.27537.qmail@web13304.mail.yahoo.com>

Hi, All,
I wonder anyone can help me find a faster algorithm to
get the values of unique ID (most ID has 2-3 values,
varies).
My data looks like:
ID Values
1 250
2 300
1 251
3 5000
4 600
10 521
3  5500
I would like output to look like:
ID, avg(values), stdev(values), value 1,val 2,val3,...

I used 2 for loops trying to get the values
for (i in 1:n){
  value <- NULL
  for(j in 1:m){
    if(data[j,1] == uniqueid[i]){
         value <- c(value, data[j,2])
          ....
    }
  }
}
Since both n and m are about 10000, the algorithm is
really slow.  I believe there is some function out
there that can do better than this in R. 

Thanks

-Jindan


From mschwartz at medanalytics.com  Thu Mar 27 20:35:19 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 27 Mar 2003 13:35:19 -0600
Subject: [R] Re: [Rd] R-1.7.0 beta available
In-Reply-To: <1048785528.2862.113.camel@xena>
Message-ID: <000a01c2f498$0110cdc0$0201a8c0@MARC>

>-----Original Message-----
>
> SNIP
>
>Many thanks for your help Marc. You just have to run "make 
>check" on the latest beta on RH 9.0 and let us know what 
>happens. A clean install, rather than an upgrade is the best 
>testing environment since an upgrade may leave RPMS from 
>previous installations lying around, but you are not obliged 
>to do this.  I don't expect any problems this time since the 
>major change relates to threading and, as Brian has already 
>pointed out, R doesn't use threads.
>
>By the way, I shall continue to provide R RPMS for RH 7.x for 
>those people who follow the rule of never upgrading to an x.0
release.
>
>Martyn

Martyn,

You are very welcome.  

It was my plan to do a clean install with RH 9. I am hoping to
download the ISO's via RHN during the week of the 31st along with the
other paying bleeding edge adopters, so hopefully I will have an
answer that week.

This is predicated of course on it being reasonable to have an
optimistic outlook relative to there being no substantive problems
during the install and subsequent tweaking...  :-)

BTW, on the x.0 release issue, a perhaps not so subtle point.  All of
the recent official RH informational documents and e-mails have it as
" RH 9", not "RH 9.0".  Perhaps an indication that RH is moving to a
whole version numbering scheme to enable faster adoption of new
versions...marketing...  ;-)

Best regards,

Marc


From spencer.graves at pdf.com  Thu Mar 27 20:40:18 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 27 Mar 2003 11:40:18 -0800
Subject: [R] get the values of unique ID
References: <20030327190923.27537.qmail@web13304.mail.yahoo.com>
Message-ID: <3E8353A2.1010405@pdf.com>

tst.df <- data.frame(ID=rep(1:2, 2), Values=1:4)
tapply(tst.df$Values, tst.df$ID, mean)
tapply(tst.df$Values, tst.df$ID, sd)

Is this what you want?
(Time it using "start.time <- proc.time()" before and "elapsed.time <- 
proc.time()-start.time" after.)
Spencer Graves

Jane Yu wrote:
> Hi, All,
> I wonder anyone can help me find a faster algorithm to
> get the values of unique ID (most ID has 2-3 values,
> varies).
> My data looks like:
> ID Values
> 1 250
> 2 300
> 1 251
> 3 5000
> 4 600
> 10 521
> 3  5500
> I would like output to look like:
> ID, avg(values), stdev(values), value 1,val 2,val3,...
> 
> I used 2 for loops trying to get the values
> for (i in 1:n){
>   value <- NULL
>   for(j in 1:m){
>     if(data[j,1] == uniqueid[i]){
>          value <- c(value, data[j,2])
>           ....
>     }
>   }
> }
> Since both n and m are about 10000, the algorithm is
> really slow.  I believe there is some function out
> there that can do better than this in R. 
> 
> Thanks
> 
> -Jindan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From hi_ono2001 at ybb.ne.jp  Thu Mar 27 20:40:49 2003
From: hi_ono2001 at ybb.ne.jp (Hisaji Ono)
Date: Fri, 28 Mar 2003 04:40:49 +0900
Subject: [R] 
	Re: About ability of  "allShortestPaths" function in e1071 package 
References: <004401c2f470$034c9420$048001db@webgis>
	<16003.16155.236695.187268@galadriel.ci.tuwien.ac.at>
Message-ID: <00e001c2f498$c4f3bef0$048001db@webgis>

Vielen Dank, Dr. Leisch.

>no, the current implementation uses matrices to represent the graph,
>hence it can only handle several thousand nodes depending on thje
>amount of memory your computer has. millions of nodes is currently
>impossible.


From cmorab at bellsouth.net  Thu Mar 27 20:47:12 2003
From: cmorab at bellsouth.net (cmorab@bellsouth.net)
Date: Thu, 27 Mar 2003 14:47:12 -0500
Subject: [R] Question about R^2 in nonlinear models
Message-ID: <000701c2f499$a9878600$6101a8c0@launchmodem.com>

Dear all

I'm not sure is this question has much sense, but I'm working with nonlinear
models using the nlme library (gnls fit for different groups) and I'm
wondering if I can get the values of R-squared for each fit. I'll appreciate
any comment.

Thanks in advance

C. Mora


From spencer.graves at pdf.com  Thu Mar 27 21:18:41 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 27 Mar 2003 12:18:41 -0800
Subject: [R] Question about R^2 in nonlinear models
References: <000701c2f499$a9878600$6101a8c0@launchmodem.com>
Message-ID: <3E835CA1.6060204@pdf.com>

R^2 = 1 - var(residuals)/var(y)

Note, however, that one can get R^2 < 0, e.g., with a straight line 
through the origin.  If "nlme" does not automatically report R^2, this 
may be why.

Hope this helps.
Spencer Graves

cmorab at bellsouth.net wrote:
> Dear all
> 
> I'm not sure is this question has much sense, but I'm working with nonlinear
> models using the nlme library (gnls fit for different groups) and I'm
> wondering if I can get the values of R-squared for each fit. I'll appreciate
> any comment.
> 
> Thanks in advance
> 
> C. Mora
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rpeng at stat.ucla.edu  Thu Mar 27 21:35:43 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu, 27 Mar 2003 12:35:43 -0800 (PST)
Subject: [R] get the values of unique ID
In-Reply-To: <20030327190923.27537.qmail@web13304.mail.yahoo.com>
Message-ID: <Pine.GSO.4.10.10303271231560.24477-100000@quetelet.stat.ucla.edu>

You might want to try working with split().  For example:

df <- data.frame(ID = c(1,1,1,2,2,2), Values = c(40,50,40,60,70,80))

sdf <- split(df, df$ID)
lapply(sdf, function(x) with(x, c(ID[1],mean(Values),sd(Values),Values)))

Since each ID could take different numbers of values (I assume), you'll
still end up with a "ragged array".

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Thu, 27 Mar 2003, Jane Yu wrote:

> Hi, All,
> I wonder anyone can help me find a faster algorithm to
> get the values of unique ID (most ID has 2-3 values,
> varies).
> My data looks like:
> ID Values
> 1 250
> 2 300
> 1 251
> 3 5000
> 4 600
> 10 521
> 3  5500
> I would like output to look like:
> ID, avg(values), stdev(values), value 1,val 2,val3,...
> 
> I used 2 for loops trying to get the values
> for (i in 1:n){
>   value <- NULL
>   for(j in 1:m){
>     if(data[j,1] == uniqueid[i]){
>          value <- c(value, data[j,2])
>           ....
>     }
>   }
> }
> Since both n and m are about 10000, the algorithm is
> really slow.  I believe there is some function out
> there that can do better than this in R. 
> 
> Thanks
> 
> -Jindan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From bates at stat.wisc.edu  Thu Mar 27 21:42:57 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 27 Mar 2003 14:42:57 -0600
Subject: [R] Question about R^2 in nonlinear models
In-Reply-To: <3E835CA1.6060204@pdf.com>
References: <000701c2f499$a9878600$6101a8c0@launchmodem.com>
	<3E835CA1.6060204@pdf.com>
Message-ID: <6rllz0sfqm.fsf@bates4.stat.wisc.edu>

Spencer Graves <spencer.graves at pdf.com> writes:

> R^2 = 1 - var(residuals)/var(y)
> 
> Note, however, that one can get R^2 < 0, e.g., with a straight line
> through the origin.  If "nlme" does not automatically report R^2, this
> may be why.

Neither nls nor the nonlinear model fitting functions from the nlme
package report an R^2 value because this statistic doesn't always make
sense for a nonlinear model.  R^2 for a linear model is a way of
comparing the fitted model to a trivial model that predicts all the
responses by a constant.  If there is a constant term in the linear
model formula (and this can be detected) then the constant model will
be nested within the fitted model.  For a nonlinear model it would be
difficult to determine if the constant model is nested within the
fitted model.  In many cases it is not and an R^2 value would be very
difficult to interpret - some might even say meaningless.

If you really want an R^2 value you could use SAS PROC NLIN which
*always* produces an ANOVA table and the R^2 value, even when it is
meaningless :-).


From jfkincaid at salisbury.edu  Thu Mar 27 22:17:35 2003
From: jfkincaid at salisbury.edu (Joel Kincaid)
Date: Thu, 27 Mar 2003 16:17:35 -0500
Subject: [R] Logical  Indexing of vectors -- Odd Behavior or....
Message-ID: <se832422.009@mail2.salisbury.edu>

R-Community,

I'm puzzled by the following behavior in R 1.6.2 and have found no
reference to this in the archives: 

>P <- seq(.1,.9,by=.1)

>P[P > .4] 
[1] 0.5 0.6 0.7 0.8 0.9
as expected. However, 
>P[P > .3]
[1] 0.3 0.4 0.5 0.6 0.7 0.8 0.9
    ??? 
Which is unexpected. Furthermore on the logical side
> P>.1
[1] FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> P>.2
[1] FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> P>.3
[1] FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> P>.4
[1] FALSE FALSE FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE
> P>.5
[1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE  TRUE  TRUE
> P>.6
[1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE
> P>.7
[1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE  TRUE


What's with .3 and .7? Any pointers to where I might find out the info
would be greatly appreciated,

I'm running 1.6.2 on windows XP, 
Sincerely,


Joel F. Kincaid, Ph. D.
Assistant Professor
Department of Economics and Finance
Franklin P. Perdue School of Business
Salisbury University
Salisbury Maryland, 21801
Phone: (410) 548-4416
Email:   jfkincaid at salisbury.edu


From white.denis at epamail.epa.gov  Thu Mar 27 22:32:49 2003
From: white.denis at epamail.epa.gov (white.denis@epamail.epa.gov)
Date: Thu, 27 Mar 2003 13:32:49 -0800
Subject: [R] Logical  Indexing of vectors -- Odd Behavior or....
Message-ID: <OF64F09BF8.5B3539CC-ON88256CF6.00760CE7@rtp.epa.gov>


Notice that

> seq (.1, .9, by=.1)[3] - 0.3
[1] 5.551115e-17

See the thread "[R] round() seems inconsistent when rounding 5s" about
March 16 on the same issue, inexact representation.

> R-Community,
>
> I'm puzzled by the following behavior in R 1.6.2 and have found no
> reference to this in the archives:
>
> >P <- seq(.1,.9,by=.1)
>
> >P[P > .4]
> [1] 0.5 0.6 0.7 0.8 0.9
> as expected. However,
> >P[P > .3]
> [1] 0.3 0.4 0.5 0.6 0.7 0.8 0.9
>     ???
> Which is unexpected. Furthermore on the logical side
> > P>.1
> [1] FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> > P>.2
> [1] FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> > P>.3
> [1] FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> > P>.4
> [1] FALSE FALSE FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE
> > P>.5
> [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE  TRUE  TRUE
> > P>.6
> [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE
> > P>.7
> [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE  TRUE
>
>
> What's with .3 and .7? Any pointers to where I might find out the info
> would be greatly appreciated,
>
> I'm running 1.6.2 on windows XP,
> Sincerely,
>


From ligges at statistik.uni-dortmund.de  Thu Mar 27 22:39:06 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 27 Mar 2003 22:39:06 +0100
Subject: [R] Logical  Indexing of vectors -- Odd Behavior or....
References: <se832422.009@mail2.salisbury.edu>
Message-ID: <3E836F7A.3BA89276@statistik.uni-dortmund.de>

Joel Kincaid wrote:
> 
> R-Community,
> 
> I'm puzzled by the following behavior in R 1.6.2 and have found no
> reference to this in the archives:
> 
> >P <- seq(.1,.9,by=.1)
> 
> >P[P > .4]
> [1] 0.5 0.6 0.7 0.8 0.9
> as expected. However,
> >P[P > .3]
> [1] 0.3 0.4 0.5 0.6 0.7 0.8 0.9
>     ???
> Which is unexpected. Furthermore on the logical side
> > P>.1
> [1] FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> > P>.2
> [1] FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> > P>.3
> [1] FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> > P>.4
> [1] FALSE FALSE FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE
> > P>.5
> [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE  TRUE  TRUE
> > P>.6
> [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE
> > P>.7
> [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE  TRUE
> 
> What's with .3 and .7? Any pointers to where I might find out the info
> would be greatly appreciated,
> 
> I'm running 1.6.2 on windows XP,
> Sincerely,
> 
> Joel F. Kincaid, Ph. D.
> Assistant Professor
> Department of Economics and Finance
> Franklin P. Perdue School of Business
> Salisbury University
> Salisbury Maryland, 21801
> Phone: (410) 548-4416
> Email:   jfkincaid at salisbury.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

a) It has nothing to do with indexing.
b) It not completely unexpected.

In seq() some computations are involved, hence it's just a very small
inaccuracy which is expected when working with limited machines such as
computers:

 options(digits=22) # some more details ...
 seq(.1, .9, .1)    # Ah, that's it! ;-)

Uwe Ligges


From spencer.graves at pdf.com  Thu Mar 27 22:51:04 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 27 Mar 2003 13:51:04 -0800
Subject: [R] Logical  Indexing of vectors -- Odd Behavior or....
References: <OF64F09BF8.5B3539CC-ON88256CF6.00760CE7@rtp.epa.gov>
Message-ID: <3E837248.8090107@pdf.com>

I get the same answer from S-Plus 6.1 as R 1.6.2 (under Windows 2000)

tst.seq <- seq(.1, .9, by=.1)
(outer(tst.seq, round(tst.seq, 1), ">") %*% rep(1,9))[,1]
[1] 0 1 3 3 4 5 7 7 8

Enjoy,
Spencer Graves

white.denis at epamail.epa.gov wrote:
> Notice that
> 
> 
>>seq (.1, .9, by=.1)[3] - 0.3
> 
> [1] 5.551115e-17
> 
> See the thread "[R] round() seems inconsistent when rounding 5s" about
> March 16 on the same issue, inexact representation.
> 
> 
>>R-Community,
>>
>>I'm puzzled by the following behavior in R 1.6.2 and have found no
>>reference to this in the archives:
>>
>>
>>>P <- seq(.1,.9,by=.1)
>>
>>>P[P > .4]
>>
>>[1] 0.5 0.6 0.7 0.8 0.9
>>as expected. However,
>>
>>>P[P > .3]
>>
>>[1] 0.3 0.4 0.5 0.6 0.7 0.8 0.9
>>    ???
>>Which is unexpected. Furthermore on the logical side
>>
>>>P>.1
>>
>>[1] FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
>>
>>>P>.2
>>
>>[1] FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
>>
>>>P>.3
>>
>>[1] FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
>>
>>>P>.4
>>
>>[1] FALSE FALSE FALSE FALSE TRUE TRUE  TRUE  TRUE  TRUE
>>
>>>P>.5
>>
>>[1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE  TRUE  TRUE
>>
>>>P>.6
>>
>>[1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE
>>
>>>P>.7
>>
>>[1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE  TRUE
>>
>>
>>What's with .3 and .7? Any pointers to where I might find out the info
>>would be greatly appreciated,
>>
>>I'm running 1.6.2 on windows XP,
>>Sincerely,
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From york at noaa.gov  Thu Mar 27 22:52:17 2003
From: york at noaa.gov (Anne York)
Date: Thu, 27 Mar 2003 13:52:17 -0800 (PST)
Subject: [R] mozilla and R -- again 
Message-ID: <Pine.GSO.4.05.10303271340300.6662-100000@ofis450a.akctr.noaa.gov>

I noticed last week that when using mozilla (both 1.2 and 1.3) as  the
help browser in R, it exhibits the following behavior: 

1. assuming the browser is running go to the help -> "search engine and key
words"

2. enter a string, say "plot"

3. when the "search results" are displayed, click on something, say
"abline"

4. go back to the search results using the browser "Back" button

5. click on something else, eg, "arrows"

Nothing happens.  I get the same results with mozilla 1.2 and 1.3
running R 1.6.2 in both RH 8.0 and Windows 2000.  

Seems like the links just die. I'm wondering if this is this simply a
mozilla issue as browsers work fine with R.  Or perhaps some of the R gurus
might have some idea if mozilla can be configured differently to work
better with R? 


Thanks,
Anne

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Anne E. York
National Marine Mammal Laboratory
Seattle WA 98115-0070  USA
e-mail: anne.york at noaa.gov
Voice: +1 206-526-4039
Fax: +1 206-526-6615
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


From r.darnell at uq.edu.au  Thu Mar 27 23:03:46 2003
From: r.darnell at uq.edu.au (Ross Darnell)
Date: 28 Mar 2003 08:03:46 +1000
Subject: [R] RE: Simple NLME problem (I hope)
Message-ID: <of3w8o1p.fsf@uq.edu.au>


Date: Wed, 26 Mar 2003 17:35:27 +0000
From: "Vumani Dlamini" <dvumani at hotmail.com>
Subject: [R] Simple NLME problem (I hope)  
To: r-help at stat.math.ethz.ch
Message-ID: <F147zBdDA6VzpJxV0Hv00002661 at hotmail.com>
Content-Type: text/plain; format=flowed


"Vumani Dlamini" wrote:
>Dear R-Users:

>I would like to fit a multilevel model using LME such that the parameters 
>after fitting the multilevel in two separate groups and when I use the 
>complete data (with interactions between the grouping variable and the other 
>variables) set are comparable (or the same).

>The problem I am having currently is that I am not sure whether it is 
>possible to let the random error term to vary by group such that the models 
>are comparable. At present only one random error term is estimate and this 
>"sort of" distorts the parameter estimates for the fixed and other random 
>effects.

>Looking forward to your help.

It may be that you want to use the "weights=varIdent(form=~1|groups)"
argument which will fit a variance for each level of the groups
factor.


-- 
Ross Darnell
School of Health and Rehabilitation Sciences
University of Queensland, Brisbane QLD 4067 AUSTRALIA
Email: <r.darnell at uq.edu.au>
Phone +61 7 3365 6087
http://www.uq.edu.au/~uqrdarne/


From mschwartz at medanalytics.com  Thu Mar 27 23:20:32 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 27 Mar 2003 16:20:32 -0600
Subject: [R] mozilla and R -- again 
In-Reply-To: <Pine.GSO.4.05.10303271340300.6662-100000@ofis450a.akctr.noaa.gov>
Message-ID: <002401c2f4af$1550dbb0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Anne York
>Sent: Thursday, March 27, 2003 3:52 PM
>To: Help R
>Subject: [R] mozilla and R -- again 
>
>
>I noticed last week that when using mozilla (both 1.2 and 1.3) 
>as  the help browser in R, it exhibits the following behavior: 
>
>1. assuming the browser is running go to the help -> "search 
>engine and key words"
>
>2. enter a string, say "plot"
>
>3. when the "search results" are displayed, click on 
>something, say "abline"
>
>4. go back to the search results using the browser "Back" button
>
>5. click on something else, eg, "arrows"
>
>Nothing happens.  I get the same results with mozilla 1.2 and 
>1.3 running R 1.6.2 in both RH 8.0 and Windows 2000.  
>
>Seems like the links just die. I'm wondering if this is this 
>simply a mozilla issue as browsers work fine with R.  Or 
>perhaps some of the R gurus might have some idea if mozilla 
>can be configured differently to work better with R? 
>
>
>Thanks,
>Anne


Anne kindly e-mailed me and we had an offline exchange on this prior
to her post here.  I can also confirm this behavior with R 1.6.2 under
WinXP using Mozilla 1.3.  

However, if I use IE 6 SP1, this does not occur. So this would seem to
be yet another example of a Mozilla related Java engine/applet issue.

When going back to the search results page using Mozilla, a quick
visual scan of the HTML code does not show any changes from the
initial version that worked.  If you move the mouse over the links,
the mouse changes, however the link URL does not show on the Mozilla
status line, suggesting that something is at least partially blocking
the link activation in the browser.

Regards,

Marc Schwartz


From kjetil at entelnet.bo  Fri Mar 28 01:39:50 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Thu, 27 Mar 2003 20:39:50 -0400
Subject: [R] Na action with Lowess smoothing
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB01EE20EB@GIMLI>
Message-ID: <3E836196.10416.84407@localhost>

On 27 Mar 2003 at 10:38, Wayne Jones wrote:

Check out the version og lowess in the gregmisc package, it has a
formula interface and na.action argument.
(Why cannot this be included in base R, to avoid having two othervise 
identical functions?)

Kjetil Halvorsen


> Hi there, 
> 
> I cant seem to find a way for the lowess smoothing function to handle "NA"
> values. 
> 
> Can anyone help??
> 
> Regards, 
> 
> Wayne
> 
> 
> Dr Wayne R. Jones
> Statistician / Research Analyst
> KSS Group plc
> St James's Buildings
> 79 Oxford Street
> Manchester M1 6SS
> Tel: +44(0)161 609 4084
> Mob: +44(0)7810 523 713
> 
> 
> 
> KSS Ltd
> A division of Knowledge Support Systems Group plc
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS  England
> Company Registration Number 2800886 (Limited) 3449594 (plc)
> Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com		http://www.kssg.com
> 
> 
> The information in this Internet email is confidential and may b... {{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From fharrell at virginia.edu  Fri Mar 28 01:46:42 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 27 Mar 2003 19:46:42 -0500
Subject: [R] mozilla and R -- again
In-Reply-To: <002401c2f4af$1550dbb0$0201a8c0@MARC>
References: <Pine.GSO.4.05.10303271340300.6662-100000@ofis450a.akctr.noaa.gov>
	<002401c2f4af$1550dbb0$0201a8c0@MARC>
Message-ID: <20030327194642.64e103cd.fharrell@virginia.edu>

On Thu, 27 Mar 2003 16:20:32 -0600
Marc Schwartz <mschwartz at medanalytics.com> wrote:

> >-----Original Message-----
> >From: r-help-bounces at stat.math.ethz.ch 
> >[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Anne York
> >Sent: Thursday, March 27, 2003 3:52 PM
> >To: Help R
> >Subject: [R] mozilla and R -- again 
> >
> >
> >I noticed last week that when using mozilla (both 1.2 and 1.3) 
> >as  the help browser in R, it exhibits the following behavior: 
> >
> >1. assuming the browser is running go to the help -> "search 
> >engine and key words"
> >
> >2. enter a string, say "plot"
> >
> >3. when the "search results" are displayed, click on 
> >something, say "abline"
> >
> >4. go back to the search results using the browser "Back" button
> >
> >5. click on something else, eg, "arrows"
> >
> >Nothing happens.  I get the same results with mozilla 1.2 and 
> >1.3 running R 1.6.2 in both RH 8.0 and Windows 2000.  
> >
> >Seems like the links just die. I'm wondering if this is this 
> >simply a mozilla issue as browsers work fine with R.  Or 
> >perhaps some of the R gurus might have some idea if mozilla 
> >can be configured differently to work better with R? 
> >
> >
> >Thanks,
> >Anne
> 
> 
> Anne kindly e-mailed me and we had an offline exchange on this prior
> to her post here.  I can also confirm this behavior with R 1.6.2 under
> WinXP using Mozilla 1.3.  
> 
> However, if I use IE 6 SP1, this does not occur. So this would seem to
> be yet another example of a Mozilla related Java engine/applet issue.
> 
> When going back to the search results page using Mozilla, a quick
> visual scan of the HTML code does not show any changes from the
> initial version that worked.  If you move the mouse over the links,
> the mouse changes, however the link URL does not show on the Mozilla
> status line, suggesting that something is at least partially blocking
> the link activation in the browser.
> 
> Regards,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

With all the problems using java-based search on Linux I was wondering why java was needed.  Could this have been done more simply?  I am not very knowledgeable about java so please forgive me if the answer is obvious.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From tblackw at umich.edu  Fri Mar 28 02:06:08 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 27 Mar 2003 20:06:08 -0500 (EST)
Subject: [R] Multinomial logistic regression under R and Stata
In-Reply-To: <3E82D33C.7050700@sociology.oxford.ac.uk>
Message-ID: <Pine.SOL.4.44.0303271930370.13853-100000@tetris.gpcc.itd.umich.edu>

Wing  -

Apologies if I'm overdoing the answer to a fundamentally simple question.

There's another experiment you might do:  Try doing the orthogonalization
between quadratic and linear terms yourself, explicitly.  (See below.)
Find out whether and how much the reported standard errors change in each
package, when you do the orthogonalization explicitly, ahead of time,
versus when you let the multinom() fitting routine use its own default
procedure.  The package whose standard error estimate doesn't change is
doing it right.

I think it's not possible to do the orthogonalization exactly, because
one doesn't have access ahead of time to the weights that will be used
in the multinomial fit.  But maybe approximate is good enough to show
whether there is a difference in the standard errors.

Suppose your "social status" covariate is a column in a data frame
 d1  named "soc.st".  The non-orthogonalized quadratic term would be
"soc.st^2".  Define a new data frame, d2, by

 d2 <- cbind(d1, soc.quad = residuals(lm(soc.st^2 ~ soc.st, data=d1)))

The column named "soc.quad" in d2 is the quadratic term, crudely
orthogonalized to the constant and linear terms in soc.st.  Use it
in your multinomial regression in place of "soc.st^2", (if that's
what you were doing before) and see whether both packages give the
same estimates and standard errors that they did before.  I'll be
most surprised if the estimates are different, but I expect that
one package or the other will change its reported standard errors.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



On Thu, 27 Mar 2003, Tak Wing Chan wrote:

> Dear Colleagues
>
> I have been fitting some multinomial logistic regression models using R
> (version 1.6.1 on a linux box) and Stata 7. Although the vast majority
> of the parameter estimates and standard errors I get from R are the same
> as those from Stata (given rounding errors and so on), there are a few
> estimates for the same model which are quite different. I would be most
> grateful if colleagues could advise me as to what might be causing this,
> and should I worry ...
>
> Anyway, with R, I have been using the function multinom under the
> package nnet. Below are two examples where the estimates for standard
> error differ substantially between R and Stata:
>
>           beta              s.e.
> R:        5.939880 2.920165
> Stata:  5.939747 5.455495
>
> R:      11.228705 2.191625
> Stata: 11.22761  4.630293
>
> The parameters concerned are the quadratic term of a quantitative
> variable (measuring social status). I notice that the s.e. for this
> quadratic term are large anyway compared to other s.e. in the model.
>
> There are other differences between R and Stata, and these concerned the
> intercept terms. Here is an example:
>
>            beta            s.e.
> R:        0.2870793 0.4512347
> Stata: -0.2109653 0.5053566
>
> Since both estimates are not significantly different from zero, I trust
> I can ignore the difference between the estimates. Or could I?
>
> Many thanks in advance for any help. Please let me know if I should
> provide further info.
>
> With best wishes.
>
> Wing
> --
> Department of Sociology, University of Oxford,
> Littlegate House, St Ebbes, Oxford OX1 1PT, UK
> tel: +44 (1865) 286176, fax: +44 (1865) 286171
> http://users.ox.ac.uk/~sfos0006


From tlumley at u.washington.edu  Fri Mar 28 02:19:25 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 27 Mar 2003 17:19:25 -0800 (PST)
Subject: [R] mozilla and R -- again
In-Reply-To: <20030327194642.64e103cd.fharrell@virginia.edu>
Message-ID: <Pine.A41.4.44.0303271715260.30460-100000@homer34.u.washington.edu>

On Thu, 27 Mar 2003, Frank E Harrell Jr wrote:

>
> With all the problems using java-based search on Linux I was wondering
> why java was needed.  Could this have been done more simply?  I am not
> very knowledgeable about java so please forgive me if the answer is
> obvious.

Well, the searching needs a search program to be run, triggered by
something you do in the browser.

This requires either a program that can run in the browser (Java, as
JavaScript I don't think can handle this sort of thing) or requires some
way of calling R from the browser (even worse).

Better solutions would seem to require either R doing the HTML rendering
or R running an HTTP server.  Neither is out of the question, but it isn't
straightforward.  Stata uses the former solution and I believe SAS uses
the latter.

	-thomas


From yfan at diversa.com  Fri Mar 28 02:34:05 2003
From: yfan at diversa.com (Yiping Fan)
Date: Thu, 27 Mar 2003 17:34:05 -0800
Subject: [R] overlapping pattern match
Message-ID: <6AC569D81BF88545B395BD2D4984F10601E4E6@CHAMAELEON.diversa.com>

Hi, all,
     I have a string like  "aaacdf",  I want to find how many "aa" in the
string. Obviously, It is 2 in this case.  it is easy to do in Perl, but how
to do such  overlapping match in R or Splus.  Thanks!

Y.Fan


From f0z6305 at labs.tamu.edu  Fri Mar 28 04:48:51 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu, 27 Mar 2003 19:48:51 -0800
Subject: [R] A dead problem on deriving the derivative equation.
References: <F100BO4EbPjPqusNvve00024676@hotmail.com>
Message-ID: <002b01c2f4dd$9dcb6ea0$46475ba5@zhangfeng>

Hey, R-listers

I was totally confused by a seemling simple first derivative
function.
Given the Kullback-Leibler divergence function between
a true pdf function P(x,theta) and an approximation pdf
function Q(theta)=q1(theta1)*q2(theta2)*...*qn(thetan),
where theta=[theta1,theta2, ..., thetan]'.
KL(Q||P) 
= \integration Q(theta)*log(P(x,theta)/Q(theta)) dtheta

So how to derive the first derivative of KL with respect 
to theta1?

Thanks for your helpful advices.

Fred


From spencer.graves at pdf.com  Fri Mar 28 03:08:56 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 27 Mar 2003 18:08:56 -0800
Subject: [R] A dead problem on deriving the derivative equation.
References: <F100BO4EbPjPqusNvve00024676@hotmail.com>
	<002b01c2f4dd$9dcb6ea0$46475ba5@zhangfeng>
Message-ID: <3E83AEB8.5060800@pdf.com>

Do you want numbers?  If yes, did you try programming KL(theta) as a 
function, then computing

D.KL <- (KL(theta+delta)-KL(delta))/delta

for some suitably small delta?

Spencer Graves

Feng Zhang wrote:
> Hey, R-listers
> 
> I was totally confused by a seemling simple first derivative
> function.
> Given the Kullback-Leibler divergence function between
> a true pdf function P(x,theta) and an approximation pdf
> function Q(theta)=q1(theta1)*q2(theta2)*...*qn(thetan),
> where theta=[theta1,theta2, ..., thetan]'.
> KL(Q||P) 
> = \integration Q(theta)*log(P(x,theta)/Q(theta)) dtheta
> 
> So how to derive the first derivative of KL with respect 
> to theta1?
> 
> Thanks for your helpful advices.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From f0z6305 at labs.tamu.edu  Fri Mar 28 05:18:41 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu, 27 Mar 2003 20:18:41 -0800
Subject: [R] A dead problem on deriving the derivative equation.
References: <F100BO4EbPjPqusNvve00024676@hotmail.com>
	<002b01c2f4dd$9dcb6ea0$46475ba5@zhangfeng> <3E83AEB8.5060800@pdf.com>
Message-ID: <003c01c2f4e1$1e4ac230$46475ba5@zhangfeng>

Not for calculation on numbers, 
just to derive the symbolic formulation with
theta, x..


----- Original Message ----- 
From: "Spencer Graves" <spencer.graves at PDF.COM>
To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Thursday, March 27, 2003 6:08 PM
Subject: Re: [R] A dead problem on deriving the derivative equation.


> Do you want numbers?  If yes, did you try programming KL(theta) as a 
> function, then computing
> 
> D.KL <- (KL(theta+delta)-KL(delta))/delta
> 
> for some suitably small delta?
> 
> Spencer Graves
> 
> Feng Zhang wrote:
> > Hey, R-listers
> > 
> > I was totally confused by a seemling simple first derivative
> > function.
> > Given the Kullback-Leibler divergence function between
> > a true pdf function P(x,theta) and an approximation pdf
> > function Q(theta)=q1(theta1)*q2(theta2)*...*qn(thetan),
> > where theta=[theta1,theta2, ..., thetan]'.
> > KL(Q||P) 
> > = \integration Q(theta)*log(P(x,theta)/Q(theta)) dtheta
> > 
> > So how to derive the first derivative of KL with respect 
> > to theta1?
> > 
> > Thanks for your helpful advices.
> > 
> > Fred
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>


From spencer.graves at pdf.com  Fri Mar 28 04:01:45 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 27 Mar 2003 19:01:45 -0800
Subject: [R] A dead problem on deriving the derivative equation.
References: <F100BO4EbPjPqusNvve00024676@hotmail.com>
	<002b01c2f4dd$9dcb6ea0$46475ba5@zhangfeng> <3E83AEB8.5060800@pdf.com>
	<003c01c2f4e1$1e4ac230$46475ba5@zhangfeng>
Message-ID: <3E83BB19.9030303@pdf.com>

If the limits of integration do not include theta, then you can 
interchange the order of integration and differentiation.  To go beyond 
this, I think I would need more specifics.

Spencer Graves
p.s.  You've got the negative of the standard KL divergence;  see, e.g.,
"http://www.cis.hut.fi/aapo/papers/NCS99web/node26.html".

Feng Zhang wrote:
> Not for calculation on numbers, 
> just to derive the symbolic formulation with
> theta, x..
> 
> 
> ----- Original Message ----- 
> From: "Spencer Graves" <spencer.graves at PDF.COM>
> To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
> Cc: <r-help at stat.math.ethz.ch>
> Sent: Thursday, March 27, 2003 6:08 PM
> Subject: Re: [R] A dead problem on deriving the derivative equation.
> 
> 
> 
>>Do you want numbers?  If yes, did you try programming KL(theta) as a 
>>function, then computing
>>
>>D.KL <- (KL(theta+delta)-KL(delta))/delta
>>
>>for some suitably small delta?
>>
>>Spencer Graves
>>
>>Feng Zhang wrote:
>>
>>>Hey, R-listers
>>>
>>>I was totally confused by a seemling simple first derivative
>>>function.
>>>Given the Kullback-Leibler divergence function between
>>>a true pdf function P(x,theta) and an approximation pdf
>>>function Q(theta)=q1(theta1)*q2(theta2)*...*qn(thetan),
>>>where theta=[theta1,theta2, ..., thetan]'.
>>>KL(Q||P) 
>>>= \integration Q(theta)*log(P(x,theta)/Q(theta)) dtheta
>>>
>>>So how to derive the first derivative of KL with respect 
>>>to theta1?
>>>
>>>Thanks for your helpful advices.
>>>
>>>Fred
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From jameson at coost.com  Fri Mar 28 06:55:20 2003
From: jameson at coost.com (Jameson C. Burt)
Date: Fri, 28 Mar 2003 00:55:20 -0500
Subject: [R] file.show("morley.tab") responds "NO FILE"
Message-ID: <20030328055520.GA28769@coost.com>

"An Introduction to R", Venables and Smith, Version 1.6.2 (2003-01-10) 
    http://cran.r-project.org/doc/manuals/R-intro.pdf
has in its "Appendix A: A sample session", page 81, 
   file.show("morley.tab")
I get the response
   NO FILE morley.tab

The following  "Introduction to the R Project for Statistical Computing"
   www.itc.nl/~rossiter/teach/sstat14/ RIntro_ITC_2003022.pdf
comments on the same problem at the bottom of his page 5 and on page 6.
His solution is to enter the full path
   file.show("/usr/lib/R/library/base/data/morley.tab")
which works but depends on your system's R.home(),
/usr/lib/R for me [my searchpaths() includes /usr/lib/R/library/base].
He then suggests the solution
   data(morley)
This works, but would force a few line changes 
in Appendix A of the document "An Introduction to R".

Venables and Smith's succeeding example for beginners to try has
   read.table("morley.tab")
which also fails with
   cannot open file `morley.tab'

I use Debian Linux version 3.0 (woody) 
with installed R version 1.5.1,
  r-base          statistical computing language and environment
  r-base-core     core of statistical computing language and env
  r-base-dev      installation of auxiliary GNU R packages
  r-base-html     html docs for statistical computing system fun
  r-base-latex    LaTeX docs for statistical computing system fu
  r-doc-html      html manuals for statistical computing system
  r-doc-info      info manuals statistical computing system
  r-doc-pdf       pdf manuals for statistical computing system
  r-gnome         Gnome gui for statistical computing system
  r-mathlib       standalone mathematics library
  r-recommended   collection of recommended packages

Perhaps others don't have this same  file.show("morley.tab") 
problem, but if others do have this problem, 
then this beginners' documentation should alter a couple lines 
on page 81.



-- 
Jameson C. Burt, NJ9L   Fairfax, Virginia, USA
jameson at coost.com       http://www.coost.com
(202) 690-0380 (work)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 240 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030328/f65bc83f/attachment.bin

From dray at biomserv.univ-lyon1.fr  Fri Mar 28 07:50:03 2003
From: dray at biomserv.univ-lyon1.fr (Stephane Dray)
Date: Fri, 28 Mar 2003 07:50:03 +0100
Subject: [R] Plot of Canonical Correlation Analysis
In-Reply-To: <OFBF40D911.F616DE7C-ONC1256CF6.0051548B@fournier.fr>
References: <OFBF40D911.F616DE7C-ONC1256CF6.0051548B@fournier.fr>
Message-ID: <a05010400baa99f913df9@[134.214.32.69]>

Hello Fran?ois,
A lot of multivariate analyses are available in the ade4 package... 
but not canonical correlation analysis. However, you can use the 
graphical functions of this library to plot the results from mva's 
cancor:
- s.arrow for plotting variables by arrows
- s.label to plot individuals
- s.corcircle for correlation circle.

Hope this helps,
Cheers


>Dear all,
>
>I didn't find any graphical solution in the package "mva" to plot the
>canonical scores from a CCA (canonical correlation analysis).
>Does anybody knows how to plot or has anybody already programmed :
>       - the map of the canonical scores,
>       - the graph of the canonical weights,
>       - the correlation circle i.e. the canonical loadings ?
>Thank you for help ...
>
>Francois M.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
St?phane DRAY
---------------------------------------------------------------
Biom?trie et Biologie ?volutive - Equipe "?cologie Statistique"
Universite Lyon 1 - Bat 711 - 69622 Villeurbanne CEDEX - France

Tel : 04 72 43 27 56			   Fax : 04 78 89 27 19
       04 72 43 27 57 	   E-mail : dray at biomserv.univ-lyon1.fr 
---------------------------------------------------------------
Web                            http://www.steph280.freesurf.fr/
---------------------------------------------------------------


From mitsu5 at ruby.famille.ne.jp  Fri Mar 28 08:04:53 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Fri, 28 Mar 2003 16:04:53 +0900
Subject: [R] the chi-square test for trend
Message-ID: <200303280704.h2S74rMv002732@mp2.vectant.ne.jp>

Dear all:

This is a newbie's question.

Will anyone who knows the package to do the program:
" Mantel-Haenszel extension of the chi-square test for trend 
(Schlesselman 1982, pp. 203-206) "

please tell the location?

I appreciate in advance.


--------========----------
Mitsuo Igarashi
mitsu5 at ruby.famille.ne.jp


From david.whiting at ncl.ac.uk  Fri Mar 28 09:02:55 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Fri, 28 Mar 2003 08:02:55 +0000
Subject: [R] mozilla and R -- again
In-Reply-To: <Pine.A41.4.44.0303271715260.30460-100000@homer34.u.washington.edu>
References: <20030327194642.64e103cd.fharrell@virginia.edu>
	<Pine.A41.4.44.0303271715260.30460-100000@homer34.u.washington.edu>
Message-ID: <20030328080255.GB11782@192.168.57.2>

On Thu, Mar 27, 2003 at 05:19:25PM -0800, Thomas Lumley wrote:
> On Thu, 27 Mar 2003, Frank E Harrell Jr wrote:
> 
> >
> > With all the problems using java-based search on Linux I was wondering
> > why java was needed.  Could this have been done more simply?  I am not
> > very knowledgeable about java so please forgive me if the answer is
> > obvious.
> 
> Well, the searching needs a search program to be run, triggered by
> something you do in the browser.
> 
> This requires either a program that can run in the browser (Java, as
> JavaScript I don't think can handle this sort of thing) or requires some
> way of calling R from the browser (even worse).
> 
> Better solutions would seem to require either R doing the HTML rendering
> or R running an HTTP server.  Neither is out of the question, but it isn't
> straightforward.  Stata uses the former solution and I believe SAS uses
> the latter.
> 
> 	-thomas

I have just set up emacs to work with a text browser called w3m (using
emacs-w3m).  This is light and fast and displays webpages in an emacs
buffer.  It is surprisingly useful.  I also have a little function
that takes the output of help.search() and creates a webpage with
hyperlinks and can therefore do a search that creates a webpage and
then display the webpage in an emacs buffer.

I have just start trying to cobble something together that combines
these more formally and hope that I should be able to do something
like M-x help-search, enter a search phrase and display the results as
a webpage with links all in emacs/ESS/w3m.  I don't have a clue about
lisp (except that it seems to involve lots of brackets and has a
considerable history) so this will is unlikely to move forward very
fast.  This does not provide all of the functionality of help.start()
but might be a way of getting free of these java issues (for those
happy to use emacs and ESS that is).

I am doing this on linux, but w3m is also available for MS Windows.

BTW just to push it I also used sweave(), xtable and latex2html
together - it was quite interesting, although latex2html does not
recognise the code environment - something else to tiniker with,
perhaps.  I haven't yet tried the html package that was announced here
a short while ago, but the possibility of combining these as an
alternative way of displaying output from R (esp. large tables?) could
be fun to explore.

Dave

> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Dave Whiting
Dar es Salaam, Tanzania


From ripley at stats.ox.ac.uk  Fri Mar 28 08:11:11 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 28 Mar 2003 07:11:11 +0000 (GMT)
Subject: [R] mozilla and R -- again 
In-Reply-To: <002401c2f4af$1550dbb0$0201a8c0@MARC>
Message-ID: <Pine.LNX.4.44.0303280705570.1173-100000@gannet.stats>

On Thu, 27 Mar 2003, Marc Schwartz wrote:

> >-----Original Message-----
> >From: r-help-bounces at stat.math.ethz.ch 
> >[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Anne York
> >Sent: Thursday, March 27, 2003 3:52 PM
> >To: Help R
> >Subject: [R] mozilla and R -- again 
> >
> >
> >I noticed last week that when using mozilla (both 1.2 and 1.3) 
> >as  the help browser in R, it exhibits the following behavior: 
> >
> >1. assuming the browser is running go to the help -> "search 
> >engine and key words"
> >
> >2. enter a string, say "plot"
> >
> >3. when the "search results" are displayed, click on 
> >something, say "abline"
> >
> >4. go back to the search results using the browser "Back" button
> >
> >5. click on something else, eg, "arrows"
> >
> >Nothing happens.  I get the same results with mozilla 1.2 and 
> >1.3 running R 1.6.2 in both RH 8.0 and Windows 2000.  
> >
> >Seems like the links just die. I'm wondering if this is this 
> >simply a mozilla issue as browsers work fine with R.  Or 
> >perhaps some of the R gurus might have some idea if mozilla 
> >can be configured differently to work better with R? 
> >
> >
> >Thanks,
> >Anne
> 
> 
> Anne kindly e-mailed me and we had an offline exchange on this prior
> to her post here.  I can also confirm this behavior with R 1.6.2 under
> WinXP using Mozilla 1.3.  
> 
> However, if I use IE 6 SP1, this does not occur. So this would seem to
> be yet another example of a Mozilla related Java engine/applet issue.
> 
> When going back to the search results page using Mozilla, a quick
> visual scan of the HTML code does not show any changes from the
> initial version that worked.  If you move the mouse over the links,
> the mouse changes, however the link URL does not show on the Mozilla
> status line, suggesting that something is at least partially blocking
> the link activation in the browser.

I get similar behaviour in Netscape 7.02. There the link does show.  
However, after going back it is a relative URL not an absolute URL, so the
browser has lost the base URL.  Given this is an auto-generated page, that 
is not too suprising: going back to auto-generated pages often does not 
work (and the URL in the address box was wrong, still that of the previous 
page).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Mar 28 08:37:54 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 28 Mar 2003 07:37:54 +0000 (GMT)
Subject: [R] file.show("morley.tab") responds "NO FILE"
In-Reply-To: <20030328055520.GA28769@coost.com>
Message-ID: <Pine.LNX.4.44.0303280728440.1211-100000@gannet.stats>

At the top of a `A sample session' it says

  Login, start your windowing system. You should also have the file 
  morley.tab in your working directory. If not, seek the local expert (or 
  get it yourself from the base/data subdirectory of the default R library 
  tree). If you have, proceed. 

I submit that the `problem' is that you did not follow those instructions.

It is deliberate that you should use a local file, as this gives a pattern
for you to use with your own data.


On Fri, 28 Mar 2003, Jameson C. Burt wrote:

> "An Introduction to R", Venables and Smith, Version 1.6.2 (2003-01-10) 
>     http://cran.r-project.org/doc/manuals/R-intro.pdf
> has in its "Appendix A: A sample session", page 81, 
>    file.show("morley.tab")
> I get the response
>    NO FILE morley.tab

The response is platform-specific, BTW.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Fri Mar 28 08:43:52 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 Mar 2003 08:43:52 +0100
Subject: [R] file.show("morley.tab") responds "NO FILE"
In-Reply-To: <20030328055520.GA28769@coost.com>
References: <20030328055520.GA28769@coost.com>
Message-ID: <3E83FD38.4060008@statistik.uni-dortmund.de>

Jameson C. Burt wrote:
> "An Introduction to R", Venables and Smith, Version 1.6.2 (2003-01-10) 
>     http://cran.r-project.org/doc/manuals/R-intro.pdf
> has in its "Appendix A: A sample session", page 81, 
>    file.show("morley.tab")
> I get the response
>    NO FILE morley.tab

The solution: Please read the first 8 lines (on page 80) of that 
Appendix as well.
"You should also have the file ?morley.tab? in your working directory. 
If not, seek the local expert (or get it yourself from the ?base/data? 
subdirectory of the default R library tree). If you have, proceed."

Uwe Ligges


> The following  "Introduction to the R Project for Statistical Computing"
>    www.itc.nl/~rossiter/teach/sstat14/ RIntro_ITC_2003022.pdf
> comments on the same problem at the bottom of his page 5 and on page 6.
> His solution is to enter the full path
>    file.show("/usr/lib/R/library/base/data/morley.tab")
> which works but depends on your system's R.home(),
> /usr/lib/R for me [my searchpaths() includes /usr/lib/R/library/base].
> He then suggests the solution
>    data(morley)
> This works, but would force a few line changes 
> in Appendix A of the document "An Introduction to R".
> 
> Venables and Smith's succeeding example for beginners to try has
>    read.table("morley.tab")
> which also fails with
>    cannot open file `morley.tab'
> 
> I use Debian Linux version 3.0 (woody) 
> with installed R version 1.5.1,
>   r-base          statistical computing language and environment
>   r-base-core     core of statistical computing language and env
>   r-base-dev      installation of auxiliary GNU R packages
>   r-base-html     html docs for statistical computing system fun
>   r-base-latex    LaTeX docs for statistical computing system fu
>   r-doc-html      html manuals for statistical computing system
>   r-doc-info      info manuals statistical computing system
>   r-doc-pdf       pdf manuals for statistical computing system
>   r-gnome         Gnome gui for statistical computing system
>   r-mathlib       standalone mathematics library
>   r-recommended   collection of recommended packages
> 
> Perhaps others don't have this same  file.show("morley.tab") 
> problem, but if others do have this problem, 
> then this beginners' documentation should alter a couple lines 
> on page 81.


From ripley at stats.ox.ac.uk  Fri Mar 28 08:50:30 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 28 Mar 2003 07:50:30 +0000 (GMT)
Subject: [R] Na action with Lowess smoothing
In-Reply-To: <3E836196.10416.84407@localhost>
Message-ID: <Pine.LNX.4.44.0303280738220.1211-100000@gannet.stats>

On Thu, 27 Mar 2003, kjetil brinchmann halvorsen wrote:

> On 27 Mar 2003 at 10:38, Wayne Jones wrote:
> 
> Check out the version og lowess in the gregmisc package, it has a
> formula interface and na.action argument.
> (Why cannot this be included in base R, to avoid having two othervise 
> identical functions?)

The one in R is a long-standing S-compatible one, and in S lowess was
superseded by loess over a decade ago.  So a better answer is `use loess
instead'.

> > I cant seem to find a way for the lowess smoothing function to handle "NA"
> > values. 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From syed at saudionline.com.sa  Fri Mar 28 09:52:55 2003
From: syed at saudionline.com.sa (Syed Gillani)
Date: Fri, 28 Mar 2003 11:52:55 +0300
Subject: [R] the chi-square test for trend
References: <200303280704.h2S74rMv002732@mp2.vectant.ne.jp>
Message-ID: <002001c2f507$6d3dfb70$991eeed5@kfnghfad2khpgj>

Can't help you there but please see Mark Myatt's Home page
http://www.myatt.demon.co.uk/ for a lot of useful information and utilities
for epidemiological work.

----- Original Message -----
From: "Mitsuo Igarashi" <mitsu5 at ruby.famille.ne.jp>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, March 28, 2003 10:04 AM
Subject: [R] the chi-square test for trend


> Dear all:
>
> This is a newbie's question.
>
> Will anyone who knows the package to do the program:
> " Mantel-Haenszel extension of the chi-square test for trend
> (Schlesselman 1982, pp. 203-206) "
>
> please tell the location?
>
> I appreciate in advance.
>
>
> --------========----------
> Mitsuo Igarashi
> mitsu5 at ruby.famille.ne.jp
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From lecoutre at stat.ucl.ac.be  Fri Mar 28 10:10:11 2003
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Fri, 28 Mar 2003 10:10:11 +0100
Subject: [R] the chi-square test for trend
Message-ID: <5.1.1.5.2.20030328100351.01e99b10@stat4ux.stat.ucl.ac.be>



Hi,

Please find here a function to compute Mantel-Haenszel Chi squared as well
as Cochran-Armitage test for trend (suitable when one of the dimensions is 2).
Both functions take as argument a contingency table.
By the way, the MH Chi? is very easy to compute as it is defined as n*rho.

Eric Lecoutre

------------------------------------------------------------------
tablepearson=function(x,scores.type="table")
{

# Statistic
	sR=scores(x,1,scores.type)
	sC=scores(x,2,scores.type)
	n=sum(data)
	Rbar=sum(apply(x,1,sum)*sR)/n
	Cbar=sum(apply(x,2,sum)*sC)/n
	ssr=sum(x*(sR-Rbar)^2)
	ssc=sum(t(x)* (sC-Cbar)^2)
	tmpij=outer(sR,sC,FUN=function(a,b) return((a-Rbar)*(b-Cbar)))
	ssrc= sum(x*tmpij)
	v=ssrc
	w=sqrt(ssr*ssc)
	r=v/w
# ASE
	bij=outer(sR,sC, FUN=function(a,b)return((a-Rbar)^2*ssc + (b-Cbar)^2*ssr))	
	tmp1=1/w^2
	tmp2=x*(w*tmpij - (bij*v)/(2*w))^2
	tmp3=sum(tmp2)
	ASE=tmp1*sqrt(tmp3)
# Test
	var0= (sum(x*tmpij) - (ssrc^2/n))/ (ssr*ssc)
	tb=r/sqrt(var0)
	p.value=2*(1-pnorm(tb))
# Output
	out=list(estimate=r,ASE=ASE,statistic=tb,p.value=p.value,name="Pearson 
Correlation",bornes=c(-1,1))
	class(out)="ordtest"
	return(out)
}

tableChisqMH=function(x)
{
	n=sum(x)
	G2=n*(tablepearson(x)^2)
	dll=1
	p.value=1-pchisq(G2,dll)
	out=list(estimate=G2,dll=dll,p.value=p.value,dim=dim(x),name="Mantel-Haenszel 
Chi-square")
	return(out)

}



tabletrend=function(x,transpose=FALSE)
{
	if (any(dim(x)==2))
	{
	if (transpose==TRUE) {
	x=t(x)
	}
	
	if (dim(x)[2]!=2){stop("Cochran-Armitage test for trend must be used with 
a (R,2) table. Use transpose argument",call.=FALSE) }
	
	nidot=apply(x,1,sum)
	n=sum(nidot)

	Ri=scores(x,1,"table")
	Rbar=sum(nidot*Ri)/n
	
	s2=sum(nidot*(Ri-Rbar)^2)
	pdot1=sum(x[,1])/n
	T=sum(x[,1]*(Ri-Rbar))/sqrt(pdot1*(1-pdot1)*s2)
	p.value.uni=1-pnorm(abs(T))
	p.value.bi=2*p.value.uni
	out=list(estimate=T,dim=dim(x),p.value.uni=p.value.uni,p.value.bi=p.value.bi,name="Cochran-Armitage 
test for trend")
	return(out)
	
	}
	else {stop("Cochran-Armitage test for trend must be used with a (2,C) or a 
(R,2) table",call.=FALSE) }
}

-----------------------------------------------------------------------

__________________________________________________

Eric Lecoutre           Informaticien/Statisticien
Institut de Statistique                        UCL

                               (+32) (0)10 47 30 50
                            lecoutre at stat.ucl.ac.be
     http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
__________________________________________________
Le vrai danger, ce n?est pas quand les ordinateurs
penseront comme des hommes, c?est quand les hommes
penseront comme des ordinateurs.     Sydney Harris


From lecoutre at stat.ucl.ac.be  Fri Mar 28 11:14:50 2003
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Fri, 28 Mar 2003 11:14:50 +0100
Subject: [R] the chi-square test for trend / Correction
Message-ID: <5.1.1.5.2.20030328111407.01ed5e40@stat4ux.stat.ucl.ac.be>



Hi (again),

Please find here a correction of the function I send previously



---------------------------------------------------------
tableChisqMH=function(x)
{
	n=sum(x)
	G2=(n-1)*(tablepearson(x)$estimate^2)
	dll=1
	p.value=1-pchisq(G2,dll)
	out=list(estimate=G2,dll=dll,p.value=p.value,dim=dim(x),name="Mantel-Haenszel 
Chi-square")
	return(out)

}
---------------------------------------------------------


Eric

__________________________________________________

Eric Lecoutre           Informaticien/Statisticien
Institut de Statistique                        UCL

                               (+32) (0)10 47 30 50
                            lecoutre at stat.ucl.ac.be
     http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
__________________________________________________
Le vrai danger, ce n'est pas quand les ordinateurs
penseront comme des hommes, c'est quand les hommes
penseront comme des ordinateurs.     Sydney Harris


From meles at free.fr  Fri Mar 28 12:49:21 2003
From: meles at free.fr (Meles MELES)
Date: Fri, 28 Mar 2003 11:49:21 +0000
Subject: [R] Poisson Regression
Message-ID: <200303281149.21788.meles@free.fr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi,
        somebody asked me to do a Poisson regression on cancer incidence over
years to see wether if there is a descending or an ascending tendancy.
I tried with R, but it complains that the data are not integer but
floating poing data. So, as I never did that sort of thing before, I'm a 
bit lost.

the data serie looks like this
SEX  PERIOD     INCIDENCE
1    [1978;1982]  57,3
1    [1983;1987]  58,3
1    [1988;1992]  65
1    [1993;1997]  56,8
2    [1978;1982]  4,6
2    [1983;1987]  5
2    [1988;1992]  5,1
2    [1993;1997]  6,2

Any suggestions?

Thanks a lot
- -- 
La publicit?, c'est la science qui consiste ? interrompre
les processus du cerveau le temps de lui piquer du fric.
Stephen Leacoch
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.2.1 (GNU/Linux)

iD8DBQE+hDbBs13e5HkHBycRAneHAKC0V5Ac8Mx4aszWljskHGRAKKUfFgCff73L
T1ThlptzCnjJxMTMaPizHi4=
=8ttc
-----END PGP SIGNATURE-----


From bob.ohara at helsinki.fi  Fri Mar 28 12:29:16 2003
From: bob.ohara at helsinki.fi (Anon.)
Date: Fri, 28 Mar 2003 13:29:16 +0200
Subject: [R] Plot of Canonical Correlation Analysis
References: <OFBF40D911.F616DE7C-ONC1256CF6.0051548B@fournier.fr>
Message-ID: <3E84320C.2020302@helsinki.fi>

f.mercier at fournier.fr wrote:
> Dear all,
> 
> I didn't find any graphical solution in the package "mva" to plot the
> canonical scores from a CCA (canonical correlation analysis).
> Does anybody knows how to plot or has anybody already programmed :
>       - the map of the canonical scores,
>       - the graph of the canonical weights,
>       - the correlation circle i.e. the canonical loadings ?
> Thank you for help ...
> 
Have a look at Jari Oksanen's vegan package.  It's on CRAN, but it also 
has its own page: <http://cc.oulu.fi/~jarioksa/softhelp/vegan.html>

Bob

-- 
Bob O'Hara

Rolf Nevanlinna Institute
P.O. Box 4 (Yliopistonkatu 5)
FIN-00014 University of Helsinki
Finland
Telephone: +358-9-191 23743
Mobile: +358 50 599 0540
Fax:  +358-9-191 22 779
WWW:  http://www.RNI.Helsinki.FI/~boh/


From plummer at iarc.fr  Fri Mar 28 12:57:05 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: 28 Mar 2003 12:57:05 +0100
Subject: [R] Poisson Regression
In-Reply-To: <200303281149.21788.meles@free.fr>
References: <200303281149.21788.meles@free.fr>
Message-ID: <1048852625.997.30.camel@xena>

On Fri, 2003-03-28 at 12:49, Meles MELES wrote:
> Hi,
>         somebody asked me to do a Poisson regression on cancer incidence over
> years to see wether if there is a descending or an ascending tendancy.
> I tried with R, but it complains that the data are not integer but
> floating poing data. So, as I never did that sort of thing before, I'm a 
> bit lost.
> 
> the data serie looks like this
> SEX  PERIOD     INCIDENCE
> 1    [1978;1982]  57,3
> 1    [1983;1987]  58,3
> 1    [1988;1992]  65
> 1    [1993;1997]  56,8
> 2    [1978;1982]  4,6
> 2    [1983;1987]  5
> 2    [1988;1992]  5,1
> 2    [1993;1997]  6,2
> 
> Any suggestions?

You don't have enough information. You need the number of events (y) and
the number of person-years at risk (pyar) separately. What you have is
the incidence rate (y/pyar) * (some scale factor).

With the correct data, your model will look something like this

glm(y ~ sex + period + offset(log(pyar)), family=poisson)

Judging by the PERIOD variable, I guess that you are looking at cancer
incidence data from volumes V to VIII of "Cancer Incidence in Five
Continents". In this case it is possible to reconstruce the original
age-specific incidence data from the published incidence rate and the
population pyramid data.

Martyn


From gavin.simpson at ucl.ac.uk  Fri Mar 28 12:52:02 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 28 Mar 2003 11:52:02 -0000
Subject: [R] Plot of Canonical Correlation Analysis
In-Reply-To: <3E84320C.2020302@helsinki.fi>
Message-ID: <001101c2f520$72542170$4c202880@gsimpson>

If the original poster actually meant output from cancor() in library(mva)
then I don't think Jari's vegan package will necessarily work "out of the
box" for objects created using cancor().

Quoting the help file on scores() :
<quote>
Currently the function seems to work at least for `isoMDS', `prcomp',
`princomp', `ca', `pca'.  It may work for other cases, or fail mysteriously.
</quote>

I've just looked at the code for scores() in vegan (which is used to plot
non-vegan-created ordination results) and it does not know about the values
returned in a cancor object (cor, xcoef, ycoef, xcenter, ycenter etc.).

There has been confusion over the use of three letter acronyms for methods
in community ecology with some people using CCA for canonical correlation
analysis, and others, like Jari and in the limnology/ecology field, using
CCA to mean Canonical Correspondence Analysis.  The two methods are very
different.  (I prefer CCA = Canonical Correspondence Analysis myself - but
that how I learned the method!)

Hope this helps.

Gav

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Anon.
Sent: 28 March 2003 11:29
To: f.mercier at fournier.fr
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Plot of Canonical Correlation Analysis


f.mercier at fournier.fr wrote:
> Dear all,
> 
> I didn't find any graphical solution in the package "mva" to plot the
> canonical scores from a CCA (canonical correlation analysis).
> Does anybody knows how to plot or has anybody already programmed :
>       - the map of the canonical scores,
>       - the graph of the canonical weights,
>       - the correlation circle i.e. the canonical loadings ?
> Thank you for help ...
> 
Have a look at Jari Oksanen's vegan package.  It's on CRAN, but it also 
has its own page: <http://cc.oulu.fi/~jarioksa/softhelp/vegan.html>

Bob

-- 
Bob O'Hara

Rolf Nevanlinna Institute
P.O. Box 4 (Yliopistonkatu 5)
FIN-00014 University of Helsinki
Finland
Telephone: +358-9-191 23743
Mobile: +358 50 599 0540
Fax:  +358-9-191 22 779
WWW:  http://www.RNI.Helsinki.FI/~boh/

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From jarioksa at sun3.oulu.fi  Fri Mar 28 12:59:41 2003
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 28 Mar 2003 13:59:41 +0200
Subject: [R] Plot of Canonical Correlation Analysis
In-Reply-To: <3E84320C.2020302@helsinki.fi>
References: <OFBF40D911.F616DE7C-ONC1256CF6.0051548B@fournier.fr>
	 <3E84320C.2020302@helsinki.fi>
Message-ID: <1048852781.27118.26.camel@pc112145.oulu.fi>

On Fri, 2003-03-28 at 13:29, Anon. wrote:
> f.mercier at fournier.fr wrote:
> > Dear all,
> > 
> > I didn't find any graphical solution in the package "mva" to plot the
> > canonical scores from a CCA (canonical correlation analysis).
> > Does anybody knows how to plot or has anybody already programmed :
> >       - the map of the canonical scores,
> >       - the graph of the canonical weights,
> >       - the correlation circle i.e. the canonical loadings ?
> > Thank you for help ...
> > 
> Have a look at Jari Oksanen's vegan package.  It's on CRAN, but it also 
> has its own page: <http://cc.oulu.fi/~jarioksa/softhelp/vegan.html>

No, don't do that.

The package has a function called cca, but that's different CCA than
your CCA. The package wouldn't help you with your problem. We are just
running short of TLAs. 

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>


From noelia.llorens at uib.es  Fri Mar 28 13:25:44 2003
From: noelia.llorens at uib.es (Noelia LLorens)
Date: Fri, 28 Mar 2003 13:25:44 +0100
Subject: [R] Robust standard errors
Message-ID: <018e01c2f525$282b0be0$5e4cce82@uib>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030328/e09649c1/attachment.pl

From christmann at statistik.uni-dortmund.de  Fri Mar 28 14:43:09 2003
From: christmann at statistik.uni-dortmund.de (Andreas Christmann)
Date: Fri, 28 Mar 2003 14:43:09 +0100
Subject: [R] Tweedie, dglm in R ?
Message-ID: <3E84516D.9030008@statistik.uni-dortmund.de>

Has anyone converted the S-PLUS software
tweedie, dglm, polygamma, digamma
written by Gordon Smyth to R?

The S-Plus sources are:
http://www.statsci.org/s/dglm.html
http://www.statsci.org/s/digammaf.html
http://www.statsci.org/s/polygamm.html
http://www.statsci.org/s/tweedief.html

Some modifications seem to be necessary for e.g. in
glm.weights, lm.wfit, ...

Andreas Christmann

-----------------------------------------------------------------------------
Andreas Christmann
University of Dortmund
Department of Statistics
44221 Dortmund
Germany
-----
Phone: +231 / 755 3180
Email: christmann at statistik.uni-dortmund.de
WWW: 
http://www.statistik.uni-dortmund.de/de/content/einrichtungen/lehrstuehle/datenanalyse.html
-----------------------------------------------------------------------------


From Tobias.Mueller at biozentrum.uni-wuerzburg.de  Fri Mar 28 15:00:07 2003
From: Tobias.Mueller at biozentrum.uni-wuerzburg.de (Tobias Mueller)
Date: Fri, 28 Mar 2003 15:00:07 +0100
Subject: [R] Problems with make.cdf.package
Message-ID: <3E845567.5000900@biozentrum.uni-wuerzburg.de>

Hi all,

I have some problems with the function 'make.cdf.package'.
I installed the affy package as well as the makecdfenv package.
Then I tried to make an environment by using

R> make.cdf.env(filename)

or resp.

R> make.cdf.package(filename)

Both commands yield the error message:
==============================================
Reading CDF file.
Creating CDF environment
Wait for about 228 
dots...................................................................................................................................................................................................................
Error in make.cdf.package(filename) :
         couldn't find function "createPackage"
==============================================

Does somebody have an idea why this error message occur resp. where I 
can find the function 'createPackage'?

Thanx a lot,
Tobias


From pfm401 at lineone.net  Fri Mar 28 10:09:34 2003
From: pfm401 at lineone.net (pfm401@lineone.net)
Date: Fri, 28 Mar 2003 09:09:34 +0000
Subject: [R] Testing for randomness
Message-ID: <3E8221B5000021F4@mk-cpfrontend-3.mail.uk.tiscali.com>

Dear all,

Is there a test in R for the randomness of a sequence of observations (e.g.
to test the random number generator)? Specifically I am looking for autocorrelations
which are not necessarily linear in nature, which the acf function does
not seem to be flexible enough to detect as it tests for linear autocorrelation.

Thanks in advance,
Paul.


From p.dalgaard at biostat.ku.dk  Fri Mar 28 15:28:13 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 28 Mar 2003 15:28:13 +0100
Subject: [R] Tweedie, dglm in R ?
In-Reply-To: <3E84516D.9030008@statistik.uni-dortmund.de>
References: <3E84516D.9030008@statistik.uni-dortmund.de>
Message-ID: <x2brzvmupu.fsf@biostat.ku.dk>

Andreas Christmann <christmann at statistik.uni-dortmund.de> writes:

> Has anyone converted the S-PLUS software
> tweedie, dglm, polygamma, digamma
> written by Gordon Smyth to R?
> 
> The S-Plus sources are:
> http://www.statsci.org/s/dglm.html
> http://www.statsci.org/s/digammaf.html
> http://www.statsci.org/s/polygamm.html
> http://www.statsci.org/s/tweedief.html
> 
> Some modifications seem to be necessary for e.g. in
> glm.weights, lm.wfit, ...

Did you look in

http://www.statsci.org/r/index.html

???
Some of the stuff (but not all) would seem to be in the StatMod library.

Anyway, Gordon is a nice guy, and I'm sure he'd be grateful
for help with the porting, so why not just contact him?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From mros at autan.toulouse.inra.fr  Fri Mar 28 15:25:18 2003
From: mros at autan.toulouse.inra.fr (Mathieu Ros)
Date: Fri, 28 Mar 2003 15:25:18 +0100 (MET)
Subject: [R] Tweedie, dglm in R ?
In-Reply-To: <3E84516D.9030008@statistik.uni-dortmund.de>
References: <3E84516D.9030008@statistik.uni-dortmund.de>
Message-ID: <16004.21331.490560.189304@autan.toulouse.inra.fr>

>>>>> "AC" == Andreas Christmann <christmann at statistik.uni-dortmund.de> disait:

    AC> Has anyone converted the S-PLUS software tweedie, dglm,
    AC> polygamma, digamma written by Gordon Smyth to R?

    AC> The S-Plus sources are: http://www.statsci.org/s/dglm.html
    AC> http://www.statsci.org/s/digammaf.html
    AC> http://www.statsci.org/s/polygamm.html
    AC> http://www.statsci.org/s/tweedief.html

    AC> Some modifications seem to be necessary for e.g. in
    AC> glm.weights, lm.wfit, ...

I use dglm on S+2000 and then dump the results in R for further
processing.
I'd also like this code to be converted to R, but I had
always thought that it wasn't open source. Maybe it would be worth
asking to G. Smyth. 

-- 
Mathieu Ros
PhD student, INRA.


From david.whiting at ncl.ac.uk  Fri Mar 28 19:35:39 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Fri, 28 Mar 2003 18:35:39 +0000
Subject: R, w3m, ESS, ... [was Re: [R] mozilla and R -- again]
In-Reply-To: <87smt7tv35.fsf@jeeves.blindglobe.net>
References: <20030327194642.64e103cd.fharrell@virginia.edu>
	<Pine.A41.4.44.0303271715260.30460-100000@homer34.u.washington.edu>
	<20030328080255.GB11782@192.168.57.2> <87smt7tv35.fsf@jeeves.blindglobe.net>
Message-ID: <20030328183539.GB365@192.168.57.2>

On Fri, Mar 28, 2003 at 06:38:22AM -0800, A.J. Rossini wrote:

[...]
> > fast.  This does not provide all of the functionality of help.start()
> > but might be a way of getting free of these java issues (for those
> > happy to use emacs and ESS that is).
> 
> Very, very interesting.  Let me know if I can help.

Without doubt.  How about this problem: I can get input from the
minibuffer and store it in a variable.  I haven't yet found out how to
call R from a lisp function (or more correctly do thing like
eval-region/eval-my-search-function) and when I do I want to be able
to pass the entered value to the function.  I plan to try to work on
this over the weekend so if you can give me some pointers in that
direction it would be helpful.  Please remember though that I am very,
very new to lisp.

> Let us know if you make progress that you'd like to share!

Okay, will do.  BTW, what's the best way to handle
discussion/collaboration on this?  Off-list, at least until something
more solid appears?  It is probably a little tangential to R-help for
now and I have not subscribed to the ESS list. 

Bye for now.

Dave

-- 
Dave Whiting
Dar es Salaam, Tanzania


From paulda at BATTELLE.ORG  Fri Mar 28 16:52:04 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Fri, 28 Mar 2003 10:52:04 -0500
Subject: [R] weighted least squares
Message-ID: 
 <940250A9EB37A24CBE28D858EF077749136C34@ws-bco-mse3.milky-way.battelle.org>


I apologize, in advance, for cross-posting this to 
the R listserv.  I have submitted this query twice 
to the S listserv (yesterday and this morning)and 
neither post has "made it", not sure why.

When I run the code

gls.1 <- 
gls(y ~ x, data = foo.frame, 
weights = varPower(form = ~ fitted(.)|group),
control = list(maxIter = 500, msMaxIter = 500), 
verbose = TRUE)

I get the message

"Warning messages:
a database with name "controlvals" already in search 
list: access by where="controlvals" may not work in: 
attach(controlvals)"

and Splus tells me that "Maximum number of iterations
reached without convergence".

What's going on?  I don't remember ever attaching a
database named "controlvals".


Respectfully & Much Thanks in Advance,

 David Paul


From lcfrancoa at hotmail.com  Fri Mar 28 17:00:28 2003
From: lcfrancoa at hotmail.com (=?iso-8859-1?B?bHVpcyBjZWZlcmlubyBmcmFuY28gYXJiZWzhZXo=?=)
Date: Fri, 28 Mar 2003 16:00:28 +0000
Subject: [R] header intact
Message-ID: <F166wjwydLmm1ivskPo0001accf@hotmail.com>







_________________________________________________________________

http://messenger.yupimsn.com/


From tmurph6 at po-box.mcgill.ca  Fri Mar 28 17:14:50 2003
From: tmurph6 at po-box.mcgill.ca (Tanya Murphy)
Date: Fri, 28 Mar 2003 11:14:50 -0500
Subject: [R] HTML help pages unreadable
Message-ID: <3EB08DA3@webmail.mcgill.ca>

Hello all,

The help pages for R (and Perl, too) are often unreadable. Has anyone had this 
problem? I am using MS IE on Windows 95 as my web browser. Do I need to 
download a font or something?

Thanks for your time!

Tanya Murphy


From p.b.pynsent at bham.ac.uk  Fri Mar 28 17:17:55 2003
From: p.b.pynsent at bham.ac.uk (p.b.pynsent)
Date: Fri, 28 Mar 2003 16:17:55 +0000
Subject: [R] Plotting K-M Curve when have several strata
In-Reply-To: <Pine.LNX.4.33.0303270007580.32256-100000@stat56.stat.auckland.ac.nz>
Message-ID: <D571B35D-6138-11D7-94A2-003065F42152@bham.ac.uk>

Kevin,
If you really want to get control of the colours then pick up the  
relevant returned values and pass them individually to lines().
foo[[2]] will hold time axis, foo[[8]] and [[9]]the upper and lower ci.
I actually feed the ci values into polygon() and am then able to  
produce shaded confidence intervals.
eg
fit.r <- survfit(Surv(fuperiod, censor), data=s.data, type=  
"kaplan-meier", conf.type="plain", conf.lower="peto")
x <- c(0,fit.r[[2]]) #add at time 0
y <- c(1,fit.r[[5]])
plot(x,y, col="blue",type="n",xlab="Time (years)",ylab="Proportion  
surviving")
xp <- c(x,rev(x))
yp <- c(1,fit.r[[8]],rev(fit.r[[9]]),1)
polygon(xp,yp,density=NULL,col="pink", border= "pink", lwd=0.5)
lines(x,y, col="blue",type="l",lwd=3)

Paul

On Wednesday, March 26, 2003, at 12:13  pm, Ko-Kang Kevin Wang wrote:

> Hi,
>
> If I have:
>   foo <- survfit(y ~ x)
> where y is a survival object and x is a n-level factor.  The  
> documentation
> says when I plot(foo), the confidence intervals will not be plotted  
> (which
> I guess is understandable as otherwise the plot will get really messy).
>
> I tried to plot with confidence intervals by using:
>   plot(foo, conf.int = TRUE)
> and indeed the resulting plot is messy.  However I'm just wondering if  
> I
> can (suppose x is a 2-level factor) use different colours and line  
> types
> for the confidence lines?  If I do:
>   plot(foo, conf.int = TRUE, col = 1:2)
> then I'll get two different colours.  What I would like is to then plot
> the confidence lines using lty = 2 (while keeping the colour).
>
> Can I do this?
>
> --  
> Cheers,
>
> Kevin
>
> ----------------------------------------------------------------------- 
> -------
> /* Time is the greatest teacher, unfortunately it kills its students */
>
> --
> Ko-Kang Kevin Wang
> Master of Science (MSc) Student
> SLC Tutor and Lab Demonstrator
> Department of Statistics
> University of Auckland
> New Zealand
> Homepage: http://www.stat.auckland.ac.nz/~kwan022
> Ph: 373-7599
>     x88475 (City)
>     x88480 (Tamaki)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
Prof. P. B. Pynsent,
Research and Teaching Centre,
Royal Orthopaedic Hospital,
Birmingham, B31 2AP, U.K.


From ripley at stats.ox.ac.uk  Fri Mar 28 17:39:04 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Fri, 28 Mar 2003 16:39:04 +0000 (GMT)
Subject: [R] Testing for randomness
In-Reply-To: <3E8221B5000021F4@mk-cpfrontend-3.mail.uk.tiscali.com>
Message-ID: <Pine.LNX.4.44.0303281637120.20269-100000@test.stats>

Autocorrelations are by definition linear.  Do you mean non-linear 
dependencies in a bivariate scatterplot?

There are many such tests, but R is not the plase to find them.  Pierre 
l'Ecuyer has a test suite, and George Marsaglia's DIEHARD can still be 
found.


On Fri, 28 Mar 2003 pfm401 at lineone.net wrote:

> Dear all,
> 
> Is there a test in R for the randomness of a sequence of observations (e.g.
> to test the random number generator)? Specifically I am looking for autocorrelations
> which are not necessarily linear in nature, which the acf function does
> not seem to be flexible enough to detect as it tests for linear autocorrelation.
> 
> Thanks in advance,
> Paul.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tmurph6 at po-box.mcgill.ca  Fri Mar 28 17:42:18 2003
From: tmurph6 at po-box.mcgill.ca (Tanya Murphy)
Date: Fri, 28 Mar 2003 11:42:18 -0500
Subject: [R] Statistical computing
Message-ID: <3EB0F3C7@webmail.mcgill.ca>

Hello,

I've been trying to familiarize myself with the computing tools of the trade 
(e.g. SAS, R, Perl, LaTex) and I've been getting somewhere with the individual 
programs, but I'm trying to get a better sense of how to integrate these 
tools. I'd like to use scripts and create reports in a more organized way. Can 
anyone recommend books or, better yet free online articles, on this topic? 
Maybe I should be a little more specific about what I do: I'm a research 
assistant in clinical epidemiology doing mainly data management and analysis. 
I do a number of repetitive tasks like updating a research database from the 
original clinic database and other sources, create reports, create graphical 
output for individual patients, as well as work on individual research 
projects. Unfortunately I am not working closely with 'real' statisticians who 
have probably developped good work habits using these tools. Any advice on 
'the big picture' would be greatly appreciated.

Thanks!

Tanya Murphy


From laura at bayesian-bay.freeserve.co.uk  Fri Mar 28 17:44:21 2003
From: laura at bayesian-bay.freeserve.co.uk (Laura Gross)
Date: Fri, 28 Mar 2003 16:44:21 +0000
Subject: [R] Problems with data.matrix
Message-ID: <Z9EyyLDlvHh+EwYu@toastyhamster.karoo.co.uk>

Dear List

I have what is probably a simple problem that I just can't seem to
solve.

I have a data list which is in the form: lev2.list

[[1]]
        1      2
      number number
[[2]]
        3      4
      number number

etc down to [[1100]]

I'm wanting to convert this to a data.matrix so I can plot the values,
however, when I use new<-data.matrix(lev2.list), I get a data matrix
that reads:

[1, ] Numeric, 2
[2, ] Numeric, 2

with every line down to [1100, ] reading 'Numeric,2'

Why am I getting this output? Why will R not display the numbers in a
data.matrix?

Many thanks for any help
Laura


From tw.chan at sociology.oxford.ac.uk  Fri Mar 28 18:16:57 2003
From: tw.chan at sociology.oxford.ac.uk (Tak Wing Chan)
Date: Fri, 28 Mar 2003 17:16:57 +0000
Subject: [R] 
	[Fwd: Re: st: Multinomial logistic regression under R and Stata]
Message-ID: <3E848389.5070104@sociology.oxford.ac.uk>

  Hello

Following Professor Ripley's suggestion, I've posted my query to the 
Stata list as well. So far, I have one reply from that list, which I am 
forwarding for your reference.

Many thanks to colleagues for your replies. I will follow up and check 
out your suggestions, and report back in due course.

Cheers.  Wing

-------- Original Message --------
Subject: Re: st: Multinomial logistic regression under R and Stata
Date: Sat, 29 Mar 2003 01:35:01 +0900
From: Joseph Coveney <jcoveney at bigplanet.com>
Reply-To: statalist at hsphsun2.harvard.edu
To: Statalist <statalist at hsphsun2.harvard.edu>



Tak Wing Chan found some differences in the standard errors of ceratin parameter 
estimates for a particular multinomial logistic model fitted by -mlogit- and by the 
corresponding command in R.  

As Scott Merryman pointed out in, Brian Ripley, posting on the R Help list in response 
to Tak Wing's posting about the discrepancies, mentioned that the Hauck-Donner 
Phenomenon, which I had never heard of, is among the possibilities for an explanation 
of the discrepancies between Stata and R:  "R uses the observed information matrix for 
the standard errors.  It is also possible to use the expected (Fisher) information matrix.  
Where they differ, the observed one is generally regarded as a better choice, especially 
when as here the curvature is measured over a reasonably-sized neighbourhood.  . . . 
such differences can [also] be caused by the Hauck-Donner effect and lack of 
convergence, so it is almost always worth playing with the convergence criteria."

I'm not certain that it matters, if I'm not mistaken, since the canonical link is used, but I 
believe that Stata uses the observed information matrix by default with -mlogit-, 
anyway.  So that doesn't appear to be the root of the problem.  If the likelihood-
maximization methods and convergence criteria are similar (and these can be 
checked), then that leaves the "Hauck-Donner effect" as a suspect.

>From some preliminary probing that is illustrated in the do-file below, it seems that any 
culpability of the Hauck-Donner Phenomenon can be ascertained by invoking the 
-robust- option in Stata.  Although it won't be necessary to cross-check it in R in order to 
rule out the possibility, it is very likely for it to be possible for Tak Wing to do so, since I 
would wager that R has an analogous option for the Huber-White-sandwich variance 
estimator with its multinomial logistic regression command.

Joseph Coveney

--------------------------------------------------------------------------------

/* Examples of the Hauck-Donner Phenomenon
   and the ability of the Huber-White-sandwich
   variance estimator to help Wald tests to overcome it.

   First example, from
   http://www.math.yorku.ca/Who/Faculty/Monette/pub/s-98/0028.html
*/
clear
set more off
set obs 200
generate byte y = _n>_N/2
generate byte x = -15
replace x = -1 in 99
replace x = -1 in 101
replace x = 1 in 100
replace x = 1 in 102
replace x = 15 in 103/l
glm y x, family(binomial) link(logit)
/*  The recommended approach to overcome the 
    sensitivity of the Wald test to this phenomenon
    is to use a likelihood-ratio test or a Fisher-Rao
    efficient score test (but see Douglas McManus's posting at
    http://www.math.yorku.ca/Who/Faculty/Monette/S-news/0049.html)
    . . . */
estimates store A
glm y, family(binomial) link(logit) nolog
lrtest A ., stats
*  Well enough; however, with -robust- . . .
glm y x, family(binomial) link(logit) robust nolog
/*  Second example, from
    http://maths.newcastle.edu.au/~rking/R/help/02b/3791.html
*/
clear
input byte pid byte x byte y byte z 
 1 8 7 1 
 2 8 3 1 
 3 0 5 0 
 4 0 9 0 
 5 8 1 1
end
glm z y x, family(binomial) link(logit)
estimates store A
glm z y, family(binomial) link(logit) nolog
lrtest A ., stats
* Again, . . .
glm z y x, family(binomial) link(logit) robust nolog
exit

--------------------------------------------------------------------------------

*
*   For searches and help try:
*   http://www.stata.com/support/faqs/res/findit.html
*   http://www.stata.com/support/statalist/faq
*   http://www.ats.ucla.edu/stat/stata/




-- 
Department of Sociology, University of Oxford,
Littlegate House, St Ebbes, Oxford OX1 1PT, UK
tel: +44 (1865) 286176, fax: +44 (1865) 286171
http://users.ox.ac.uk/~sfos0006


From jfox at mcmaster.ca  Fri Mar 28 18:18:37 2003
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 28 Mar 2003 12:18:37 -0500
Subject: [R] Problems with data.matrix
In-Reply-To: <Z9EyyLDlvHh+EwYu@toastyhamster.karoo.co.uk>
Message-ID: <5.1.0.14.2.20030328121342.01e70c50@mcmail.cis.mcmaster.ca>

Dear Laura,

I believe that matrix(unlist(lev2.list), ncol=2, byrow=TRUE) will do what 
you want, assuming that each of the elements of the list composes one row 
of the matrix. If the list elements are columns, then 
data.matrix(as.data.frame(lev2.list)) or matrix(unlist(lev2.list), nrow=2) 
should do the trick.

John

At 04:44 PM 3/28/2003 +0000, Laura Gross wrote:
>I have what is probably a simple problem that I just can't seem to
>solve.
>
>I have a data list which is in the form: lev2.list
>
>[[1]]
>         1      2
>       number number
>[[2]]
>         3      4
>       number number
>
>etc down to [[1100]]
>
>I'm wanting to convert this to a data.matrix so I can plot the values,
>however, when I use new<-data.matrix(lev2.list), I get a data matrix
>that reads:
>
>[1, ] Numeric, 2
>[2, ] Numeric, 2
>
>with every line down to [1100, ] reading 'Numeric,2'
>
>Why am I getting this output? Why will R not display the numbers in a
>data.matrix?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From JFKINCAID at salisbury.edu  Fri Mar 28 18:17:22 2003
From: JFKINCAID at salisbury.edu (Joel Kincaid)
Date: Fri, 28 Mar 2003 12:17:22 -0500
Subject: [R] Re: Logical  Indexing of vectors -- Odd Behavior or....
Message-ID: <se843d55.053@mail2.salisbury.edu>




Joel F. Kincaid, Ph. D.
Assistant Professor
Department of Economics and Finance
Franklin P. Perdue School of Business
Salisbury University
Salisbury Maryland, 21801
Phone: (410) 548-4416
Email:   jfkincaid at salisbury.edu





>>> Joel Kincaid 03/27/03 16:17 PM >>>
R-Community,
I'm puzzled by the following behavior in R 1.6.2 and have found no
reference to this in the archives: 
>P <- seq(.1,.9,by=.1)

<snip snip >naive presumptions deleted.

And so P <- round(seq(.1,.9,.1),2) produces the naively expected
results. Thanks for your help.
cheers,


From JFKINCAID at salisbury.edu  Fri Mar 28 18:19:00 2003
From: JFKINCAID at salisbury.edu (Joel Kincaid)
Date: Fri, 28 Mar 2003 12:19:00 -0500
Subject: [R] mozilla and R -- again
Message-ID: <se843db8.055@mail2.salisbury.edu>

R-Community,

Having experinced similar broken links, I came upon the following work
around:
1) When the intial page is brought up from a search, 
instead of directly clicking on a link of interest, right click on the
link and open in a new tab.
2) In the new tab one seems to be able to follow links back and
forth....
3) in the orginal page returned by the search, one can follow  other
links to new tabs, etc.

Bit of a pain but it works most of the time: Even so, on occasion the
links seem to break....

This works on mozillia 1.3 and NS 7.02

cheers

Joel F. Kincaid, Ph. D.
Assistant Professor
Department of Economics and Finance
Franklin P. Perdue School of Business
Salisbury University
Salisbury Maryland, 21801
Phone: (410) 548-4416
Email:   jfkincaid at salisbury.edu 



Joel F. Kincaid, Ph. D.
Assistant Professor
Department of Economics and Finance
Franklin P. Perdue School of Business
Salisbury University
Salisbury Maryland, 21801
Phone: (410) 548-4416
Email:   jfkincaid at salisbury.edu


From fharrell at virginia.edu  Fri Mar 28 18:43:25 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 28 Mar 2003 12:43:25 -0500
Subject: [R] Statistical computing
In-Reply-To: <3EB0F3C7@webmail.mcgill.ca>
References: <3EB0F3C7@webmail.mcgill.ca>
Message-ID: <20030328124325.7ee0880b.fharrell@virginia.edu>

On Fri, 28 Mar 2003 11:42:18 -0500
Tanya Murphy <tmurph6 at po-box.mcgill.ca> wrote:

> Hello,
> 
> I've been trying to familiarize myself with the computing tools of the trade 
> (e.g. SAS, R, Perl, LaTex) and I've been getting somewhere with the individual 
> programs, but I'm trying to get a better sense of how to integrate these 
> tools. I'd like to use scripts and create reports in a more organized way. Can 
> anyone recommend books or, better yet free online articles, on this topic? 
> Maybe I should be a little more specific about what I do: I'm a research 
> assistant in clinical epidemiology doing mainly data management and analysis. 
> I do a number of repetitive tasks like updating a research database from the 
> original clinic database and other sources, create reports, create graphical 
> output for individual patients, as well as work on individual research 
> projects. Unfortunately I am not working closely with 'real' statisticians who 
> have probably developped good work habits using these tools. Any advice on 
> 'the big picture' would be greatly appreciated.
> 
> Thanks!
> 
> Tanya Murphy
>

Take a look at the following:

http://hesweb1.med.virginia.edu/biostat/teaching/statcomp/notes.pdf
http://hesweb1.med.virginia.edu/biostat/s/doc/splus.pdf
http://hesweb1.med.virginia.edu/biostat/teaching/statcomp
http://hesweb1.med.virginia.edu/biostat/presentations/feh/clinreport/dmcreport.pdf

For statistical reports you have chosen well, in considering intergrating R and LaTeX.  The Alzola-Harrell text also covers a bit about using make and Perl to run scripts (to get data from SAS to R, run R, etc.).
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From spencer.graves at pdf.com  Fri Mar 28 18:37:45 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 28 Mar 2003 09:37:45 -0800
Subject: [R] Problems with data.matrix
References: <Z9EyyLDlvHh+EwYu@toastyhamster.karoo.co.uk>
Message-ID: <3E848869.1090306@pdf.com>

 > tst.list <- list(a=1:2, b=3:4)
 > data.matrix(as.data.frame(tst.list))
   a b
1 1 3
2 2 4

Is this what you want?
Spencer Graves

Laura Gross wrote:
> Dear List
> 
> I have what is probably a simple problem that I just can't seem to
> solve.
> 
> I have a data list which is in the form: lev2.list
> 
> [[1]]
>         1      2
>       number number
> [[2]]
>         3      4
>       number number
> 
> etc down to [[1100]]
> 
> I'm wanting to convert this to a data.matrix so I can plot the values,
> however, when I use new<-data.matrix(lev2.list), I get a data matrix
> that reads:
> 
> [1, ] Numeric, 2
> [2, ] Numeric, 2
> 
> with every line down to [1100, ] reading 'Numeric,2'
> 
> Why am I getting this output? Why will R not display the numbers in a
> data.matrix?
> 
> Many thanks for any help
> Laura
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From chrysopa at insecta.ufv.br  Fri Mar 28 19:00:51 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Fri, 28 Mar 2003 15:00:51 -0300
Subject: [R] Ajusts in nls
Message-ID: <200303281500.51918.chrysopa@insecta.ufv.br>

Hi,

I make an ajust using NLS.

The ajust is:

> library(nls)
> modelo <- nls(y~a-b*exp(-c*x),start=list(a=100,b=90,c=0.1609))
> summary(modelo)

Formula: y ~ a - b * exp(-c * x)

Parameters:
  Estimate Std. Error t value Pr(>|t|)    
a 115.2527     2.9139   39.55  < 2e-16 ***
b 118.6876     7.8925   15.04  < 2e-16 ***
c   0.1235     0.0171    7.22 2.44e-09 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Residual standard error: 13.21 on 51 degrees of freedom

Correlation of Parameter Estimates:
        a      b
b  0.0784       
c -0.6587 0.4612


My doubt is about the model significance, I read in list some questions about 
the nonsense of this, but I need of the model significance and the R^2.

I make this:

modelonulo <- lm(y~1)

> anova(modelo,modelonulo,test="F")
Analysis of Variance Table

Model 1: y ~ a - b * exp(-c * x)
Model 2: y ~ 1
  Res.Df Res.Sum Sq Df Sum Sq F value    Pr(>F)    
1     51       8897                                
2     53      59008 -2 -50111  143.62 < 2.2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

And the R^2 is:

> 50111/59008
[1] 0.8492238

It is """correct"""?

Thanks
Ronaldo
-- 
Sutil como gato que vai pegar passarinho.
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From jerome at hivnet.ubc.ca  Fri Mar 28 19:33:31 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Fri, 28 Mar 2003 10:33:31 -0800
Subject: [R] overlapping pattern match
In-Reply-To: <6AC569D81BF88545B395BD2D4984F10601E4E6@CHAMAELEON.diversa.com>
References: <6AC569D81BF88545B395BD2D4984F10601E4E6@CHAMAELEON.diversa.com>
Message-ID: <200303281838.KAA15770@hivnet.ubc.ca>


Here's a way.

string <- "aaacdf"
pattern <- "aa"
nstring <- nchar(string)
npattern <- nchar(pattern)
stringlist <- substring(string, 1:(nstring-npattern+1), npattern:nstring)
sum(stringlist==pattern)

Also, have a look at: pmatch, charmatch, grep, sub, gsub, regexpr, chartr. I 
couldn't find a simple function to do what you want.

Hope this helps.

Jerome

On March 27, 2003 05:34 pm, Yiping Fan wrote:
> Content-Length: 360
> Status: R
> X-Status: N
>
> Hi, all,
>      I have a string like  "aaacdf",  I want to find how many "aa" in the
> string. Obviously, It is 2 in this case.  it is easy to do in Perl, but how
> to do such  overlapping match in R or Splus.  Thanks!
>
> Y.Fan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From mschwartz at medanalytics.com  Fri Mar 28 20:20:51 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 28 Mar 2003 13:20:51 -0600
Subject: [R] mozilla and R -- again 
In-Reply-To: <Pine.LNX.4.44.0303280705570.1173-100000@gannet.stats>
Message-ID: <000001c2f55f$26661e00$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
>ripley at stats.ox.ac.uk
>Sent: Friday, March 28, 2003 1:11 AM
>To: Marc Schwartz
>Cc: 'Help R'; 'Anne York'
>Subject: RE: [R] mozilla and R -- again 
>

> SNIP

>I get similar behaviour in Netscape 7.02. There the link does show.
>However, after going back it is a relative URL not an absolute 
>URL, so the browser has lost the base URL.  Given this is an 
>auto-generated page, that 
>is not too suprising: going back to auto-generated pages often 
>does not 
>work (and the URL in the address box was wrong, still that of 
>the previous 
>page).
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)`
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595



I spent some time searching both Mozilla's Bugzilla and some
Mozilla/Netscape Usenet groups this morning. While I have not found a
parallel of this particular situation, I do find some posts suggesting
problems with the Gecko DOM implementation with respect to the
handling of relative URL's in Java and JavaScript.

These posts are as recent as this month, while others go back two or
three years. Some of them also suggest that these relative URL related
problems seen in Gecko based browsers (which of course includes NS)
are not seen in MS IE, which is consistent with what I have observed
in this situation. 

To Prof. Ripley's point, the address bar URL does not change upon
returning to the search results or main search page. The address bar
sequence that I see with Mozilla 1.3 under WinXP is as follows:

Main Search Page:
file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.html

Search Results Page (Using "plot"):
file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.html

Click on "abline":
file:///C:/PROGRA~1/R/rw1062/library/base/html/abline.html

Back Button to Search Results Page:
file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.html

Back Button to Main Search Page:
file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.html

Note that the address bar URL did not change either forward or
backward at the Search Results page.



In IE 6 SP1, I get the following sequence in the address bar:

Main Search Page: C:\Program
Files\R\rw1062\doc\html\search\SearchEngine.html

Search Results Page (Using "plot"): C:\Program
Files\R\rw1062\doc\html\search\SearchEngine.html

Click on "abline": C:\Program
Files\R\rw1062\library\base\html\abline.html

Back Button to Search Results Page: C:\Program
Files\R\rw1062\doc\html\search\SearchEngine.html

Back Button to Main Search Page: C:\Program
Files\R\rw1062\doc\html\search\SearchEngine.html



Finally, in RH 8.0 using Mozilla 1.3 I get:

Main Search Page:
file:///tmp/Rtmp1560/.R/doc/html/search/SearchEngine.html

Search Results Page:
file:///tmp/Rtmp1560/.R/doc/html/search/SearchEngine.html

Click on abline: file:///tmp/Rtmp1560/.R/library/base/html/abline.html

Back Button to Search Results Page:
file:///tmp/Rtmp1560/.R/doc/html/search/SearchEngine.html

Back Button to Main Search Page:
file:///tmp/Rtmp1560/.R/doc/html/search/SearchEngine.html



Prompted by Prof. Ripley's reply regarding the use of relative URL's,
I did some further "digging", keeping in mind that the actual HTML
code in the various help.start() related pages are relative URLs. To
wit, the results page URL for 'abline' under WinXP:

href="../../../library/base/html/abline.html"



When using the Mozilla DOM inspector to look at the 'BaseURl' for the
results page I get:

Before:
"file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.html"

After:
"wyciwyg://0/file:///tmp/Rtmp1560/.R/doc/html/search/SearchEngine.html
"

So this would suggest that the URL after hitting the Back Button is
being corrupted, as Prof. Ripley suggested.



When I go into the Mozilla JavaScript Console after using the Back
Button, I get:

Error: [Exception... "Component returned failure code: 0x80004005
(NS_ERROR_FAILURE) [nsIURI.hostPort]"  nsresult: "0x80004005
(NS_ERROR_FAILURE)"  location: "JS frame ::
chrome://navigator/content/nsBrowserStatusHandler.js :: anonymous ::
line 350"  data: no]
Source File: chrome://navigator/content/nsBrowserStatusHandler.js
Line: 350

Security Error: Content at
wyciwyg://0/file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.
html may not load or link to
file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.html.


Curiously, the Security Error seems to be picking up the mis-match
between the correct URL and the corrupted version.


It was mentioned in a post this morning by Prof. Kincaid that tabbed
browsing in Mozilla works (ie. open the search results target page in
a new tab instead of in the same tab) and I concur. That seems to work
well.

Is there any sense in using absolute URL's in just the search results
page HTML as opposed to relative URL's? It is not relative URL's in
and of themselves that are problems, but apparently when used in
conjunction with Java/JavaScript.

Perhaps I am overlooking other implications of such a change and given
that there are work arounds near term, I would imagine that this would
be a lesser priority issue.

I hope the above information might provide some insights.

Best regards,

Marc Schwartz


From mschwartz at medanalytics.com  Fri Mar 28 20:31:30 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 28 Mar 2003 13:31:30 -0600
Subject: [R] mozilla and R -- again 
Message-ID: <000101c2f560$a41c9f80$0201a8c0@MARC>

Correction:  In my prior post, I mixed the RH URL with the WinXP URL
in the following lines and should be corrected as:


When using the Mozilla DOM inspector to look at the 'BaseURl' for the
results page I get:

Before:
"file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.html"

After:
"wyciwyg://0/file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine
.html"


Of course the same relative phenomenon occurs in RH.


Marc Schwartz


From tblackw at umich.edu  Fri Mar 28 20:38:00 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 28 Mar 2003 14:38:00 -0500 (EST)
Subject: [R] Problems with data.matrix
In-Reply-To: <Z9EyyLDlvHh+EwYu@toastyhamster.karoo.co.uk>
Message-ID: <Pine.SOL.4.44.0303281430500.26627-100000@asteroids.gpcc.itd.umich.edu>

Laura  -

If I'm not mistaken, the two replies already on the R-help mailing
list do not answer the question you are asking.  If you've already
solved it, fine.  If not, do   str(lev2.list)  and send me the output.

Sounds to me as though  lev2.list  is not currently a data frame
or any of the other elementary data structures in R.  It might be
one of the crazy "lists of length zero" that Bioconductor and other
attempts to do "object oriented" programming in R are so fond of.

Maybe you can tell us more about what package or source is producing
the structure and the data in  lev2.list.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



On Fri, 28 Mar 2003, Laura Gross wrote:

> I have a data list which is in the form: lev2.list
>
> [[1]]
>         1      2
>       number number
> [[2]]
>         3      4
>       number number
>
> etc down to [[1100]]
>
> I'm wanting to convert this to a data.matrix so I can plot the values,
> however, when I use new<-data.matrix(lev2.list), I get a data matrix
> that reads:
>
> [1, ] Numeric, 2
> [2, ] Numeric, 2
>
> with every line down to [1100, ] reading 'Numeric,2'
>
> Why am I getting this output? Why will R not display the numbers in a
> data.matrix?
>
> Many thanks for any help
> Laura


From FMGCFMGC at terra.es  Fri Mar 28 23:26:44 2003
From: FMGCFMGC at terra.es (FMGCFMGC)
Date: Fri, 28 Mar 2003 22:26:44 GMT
Subject: [R] overlapping pattern match
Message-ID: <1f27b25461.254611f27b@teleline.es>

try with this:

your.string <- "aaacdf"
nc1 <- nchar(your.string)-1
x <- unlist(strsplit(cadena, NULL)) 
x2 <- c()
for (i in 1:nc1)
  x2 <- c(x2, paste(x2[i], x2[i+1], sep=""))
cat("ocurrences of <aa> in <your.string>:", length(grep("aa", x2)),
  sep="", fill=TRUE)

Hope it helps!
Fran

--- original message ---
Hi, all,
     I have a string like  "aaacdf",  I want to find how many "aa" in 
the string. Obviously, It is 2 in this case.  it is easy to do in Perl, 
but how to do such  overlapping match in R or Splus.  Thanks!

Y.Fan


From FMGCFMGC at terra.es  Fri Mar 28 23:31:49 2003
From: FMGCFMGC at terra.es (FMGCFMGC)
Date: Fri, 28 Mar 2003 22:31:49 GMT
Subject: [R] overlapping pattern match (errata)
Message-ID: <1ffed221c6.221c61ffed@teleline.es>

hello again!

there is an error in my previous post:

your.string <- "aaacdf"
nc1 <- nchar(your.string)-1
x <- unlist(strsplit(your.string, NULL)) ######## CORRECT
x2 <- c()
for (i in 1:nc1)
 x2 <- c(x2, paste(x2[i], x2[i+1], sep=""))
cat("ocurrences of <aa> in <your.string>:", length(grep("aa", x2)),
 sep="", fill=TRUE)

Hope it helps!
Fran


From FMGCFMGC at terra.es  Fri Mar 28 23:36:31 2003
From: FMGCFMGC at terra.es (FMGCFMGC)
Date: Fri, 28 Mar 2003 22:36:31 GMT
Subject: [R] overlapping pattern match (errata 2.0)
Message-ID: <1fd001ffc0.1ffc01fd00@teleline.es>

well! excuse me again but...

your.string <- "aaacdf"
nc1 <- nchar(your.string)-1
x <- unlist(strsplit(your.string, NULL)) ######## CORRECT
x2 <- c()
for (i in 1:nc1)
x2 <- c(x2, paste(x[i], x[i+1], sep="")) ######## ERRATA 2
cat("ocurrences of <aa> in <your.string>: ", length(grep("aa", x2)),
sep="", fill=TRUE)

Fran

PD: sorry again


From h95mr at mun.ca  Sat Mar 29 00:02:47 2003
From: h95mr at mun.ca (Martin Renner)
Date: Fri, 28 Mar 2003 19:32:47 -0330
Subject: [R] trouble with predict.smooth.Pspline
In-Reply-To: <20030328124325.7ee0880b.fharrell@virginia.edu>
References: <3EB0F3C7@webmail.mcgill.ca>
 <20030328124325.7ee0880b.fharrell@virginia.edu>
Message-ID: <p05200f28baaa6f6d574f@[134.153.153.21]>

I have problems getting predict.smooth.Pspline (part of the pspline 
package) to work. Here's an example on artificial data:

########start#########
library (Pspline)
tt <- seq (0,1,length=20)
xt <- tt^3

fit <- smooth.Pspline (tt, xt, norder=3,df=4, method=2)

fit <- smooth.Pspline (tt, xt, norder=3,spar=0.0001, method=1)
plot (tt,xt)
lines(fit)       # so far everything works fine - looks fine at least

predict.smooth.Pspline (fit, tt, nderiv=0)[,1]

####### end ##########

This produces only 20x NaN instead of something similar to xt


At the end I'm trying to get 2nd derivatives of quintic spline fits. 
Does anybody know how to get predict.smooth.Pspline or is there 
another way to do this? Any help would be greatly appreciated. Cheers,

	Martin


From Rob.Balshaw at syreon.com  Sat Mar 29 00:58:17 2003
From: Rob.Balshaw at syreon.com (Rob Balshaw)
Date: Fri, 28 Mar 2003 15:58:17 -0800
Subject: [R] Observational data questions <not S-language question>
Message-ID: <NFBBIINHNJMJKENFNIIDGEHADIAA.Rob.Balshaw@syreon.com>

< This is not an S-language question, but I hoped it would be of at least
passing interest to some members of the group. >

I've encountered a situation which I'm sure is familiar to many.

We're looking at an observational dataset with data from many thousands of
patients.  (So many patients, I won't bother to discuss the observed
significance levels of our results.  Everything is significant.)

One of our predictive factors of interest is Treatment (Trt A vs Trt B).
There are several covariates measured on the patients at the time of entry
in the study (say, X1 and X2).  The outcome of interest is time to death.
Some patients will develop a disease prior to death, and it is thought that
Disease is an important risk factor for death.

The develpment of Disease has been linked to the use of Treatment B.
Covariate X1 is also thought to predict Disease.  Covariates X1 and X2 are
thought to influence the risk of death but may also influence the choice of
treatments.

All in all, a pretty standard observational study scenario.

Now we conduct a proportional hazards regression analysis for time to death,
with Trt, X1 and X2 as covariates.  Using this model, we find that Trt A has
a hazard ratio considerably less than 1.  Treatment A appears to reduce the
risk of death after adjusting for differences in the observed covariates X1
and X2.

Next we include Disease as a time dependent covariate.  Under this model,
Trt A has a hazard ratio considerably greater than 1, as does Disease.
Thus, Trt A now appears to *increase* the risk of death (after adjusting for
the observed covariates X1 and X2 *and* the development of Disease).

My difficulty arises when I try to explain to clinicians that I do not find
these results contradictory.

The hazard ratio for drug A relative to drug B could easily be 1.2 when we
attempt to 'adjust for' the develpment of Disease.  This addresses a
completely different question than the analysis where Disease is ignored, so
it is quite possible for the answer to appear to be so different.

My questions:

(1) Does my interpretation sound reasonable?  I've had so many clinicians
question me, I'm starting to lose confidence...

(2) Has this phenomenon been explained nicely anywhere?  I'd love to be able
to argue by appeal to authority...

Thanks for any comments or suggestions.  (I'm tempted to build a simulation
of this effect, but I'm not certain the clinicians would be too impressed.)

Cheers,

Rob

-- Robert Balshaw, Ph.D.
-- Senior Biostatistician, Syreon Corp.
-- Phone: 604.676.5900x220; Fax: 604.676.5911


From reevejd at earthlink.net  Sat Mar 29 01:24:02 2003
From: reevejd at earthlink.net (John Reeve)
Date: Fri, 28 Mar 2003 18:24:02 -0600
Subject: [R] Repeated measures help
Message-ID: <003901c2f589$918607c0$952bf8d1@Gateway355F>

Hello R Folks,

Would someone mind posting a simple example of a repeated measures analysis
using lme?  I'm trying to duplicate the analyses in Chapter 3 of the "SAS
System for Mixed Models" manual, in particular those on p. 88-102 and
involving different correlation structures.  The data have the usual
split-plot layout for repeated measures.  I have downloaded the "SASMixed"
examples from CRAN and run them, but except for the first example these
don't seem to match the SAS output.  Thanks for any help.

Best wishes,
John
reevejd at earthlink.net


From reevejd at earthlink.net  Sat Mar 29 01:03:09 2003
From: reevejd at earthlink.net (John Reeve)
Date: Fri, 28 Mar 2003 18:03:09 -0600
Subject: [R] Repeated measures help
Message-ID: <000a01c2f586$aa52c890$952bf8d1@Gateway355F>

Hello R Folks,

Would someone mind posting a simple example of a repeated measures analysis
using lme?  I'm trying to duplicate the analyses in Chapter 3 of the "SAS
System for Mixed Models" manual, in particular those on p. 88-102 and
involving different correlation structures.  The data have the usual
split-plot layout for repeated measures.  I have downloaded the "SASMixed"
examples from CRAN and run them, but except for the first example these
don't seem to match the SAS output.  Thanks for any help.

Best wishes,
John Reeve


From mitsu5 at ruby.famille.ne.jp  Sat Mar 29 01:42:19 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Sat, 29 Mar 2003 09:42:19 +0900
Subject: [R] the chi-square test for trend
Message-ID: <200303290042.h2T0gIMv009779@mp2.vectant.ne.jp>

Hello Eric. Thank you so much.

I have just started to learn R. I am a bit bewildered to look 
at these programs. 
For example,I can not find "scores() and scores.type" in 
help("scores") and so on. Then I can not run these functions.

Will you or anybody please to teach me how to run the functions?
--------========----------
Mitsuo Igarashi
mitsu5 at ruby.famille.ne.jp


Eric Lecoutre <lecoutre at stat.ucl.ac.be> wrote:

> 
> 
> Hi,
> 
> Please find here a function to compute Mantel-Haenszel Chi squared as well
> as Cochran-Armitage test for trend (suitable when one of the dimensions is 2).
> Both functions take as argument a contingency table.
> By the way, the MH Chi? is very easy to compute as it is defined as n*rho.
> 
> Eric Lecoutre
> 
> ------------------------------------------------------------------
> tablepearson=function(x,scores.type="table")
> {
> 
> # Statistic
> 	sR=scores(x,1,scores.type)
> 	sC=scores(x,2,scores.type)
> 	n=sum(data)
> 	Rbar=sum(apply(x,1,sum)*sR)/n
> 	Cbar=sum(apply(x,2,sum)*sC)/n
> 	ssr=sum(x*(sR-Rbar)^2)
> 	ssc=sum(t(x)* (sC-Cbar)^2)
> 	tmpij=outer(sR,sC,FUN=function(a,b) return((a-Rbar)*(b-Cbar)))
> 	ssrc= sum(x*tmpij)
> 	v=ssrc
> 	w=sqrt(ssr*ssc)
> 	r=v/w
> # ASE
> 	bij=outer(sR,sC, FUN=function(a,b)return((a-Rbar)^2*ssc + (b-Cbar)^2*ssr))	
> 	tmp1=1/w^2
> 	tmp2=x*(w*tmpij - (bij*v)/(2*w))^2
> 	tmp3=sum(tmp2)
> 	ASE=tmp1*sqrt(tmp3)
> # Test
> 	var0= (sum(x*tmpij) - (ssrc^2/n))/ (ssr*ssc)
> 	tb=r/sqrt(var0)
> 	p.value=2*(1-pnorm(tb))
> # Output
> 	out=list(estimate=r,ASE=ASE,statistic=tb,p.value=p.value,name="Pearson 
> Correlation",bornes=c(-1,1))
> 	class(out)="ordtest"
> 	return(out)
> }
> 
> tableChisqMH=function(x)
> {
> 	n=sum(x)
> 	G2=n*(tablepearson(x)^2)
> 	dll=1
> 	p.value=1-pchisq(G2,dll)
> 	out=list(estimate=G2,dll=dll,p.value=p.value,dim=dim(x),name="Mantel-Haenszel 
> Chi-square")
> 	return(out)
> 
> }
> 
> 
> 
> tabletrend=function(x,transpose=FALSE)
> {
> 	if (any(dim(x)==2))
> 	{
> 	if (transpose==TRUE) {
> 	x=t(x)
> 	}
> 	
> 	if (dim(x)[2]!=2){stop("Cochran-Armitage test for trend must be used with 
> a (R,2) table. Use transpose argument",call.=FALSE) }
> 	
> 	nidot=apply(x,1,sum)
> 	n=sum(nidot)
> 
> 	Ri=scores(x,1,"table")
> 	Rbar=sum(nidot*Ri)/n
> 	
> 	s2=sum(nidot*(Ri-Rbar)^2)
> 	pdot1=sum(x[,1])/n
> 	T=sum(x[,1]*(Ri-Rbar))/sqrt(pdot1*(1-pdot1)*s2)
> 	p.value.uni=1-pnorm(abs(T))
> 	p.value.bi=2*p.value.uni
> 	out=list(estimate=T,dim=dim(x),p.value.uni=p.value.uni,p.value.bi=p.value.bi,name="Cochran-Armitage 
> test for trend")
> 	return(out)
> 	
> 	}
> 	else {stop("Cochran-Armitage test for trend must be used with a (2,C) or a 
> (R,2) table",call.=FALSE) }
> }
> 
> -----------------------------------------------------------------------
> 
> __________________________________________________
> 
> Eric Lecoutre           Informaticien/Statisticien
> Institut de Statistique                        UCL
> 
>                                (+32) (0)10 47 30 50
>                             lecoutre at stat.ucl.ac.be
>      http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
> __________________________________________________
> Le vrai danger, ce n?st pas quand les ordinateurs
> penseront comme des hommes, c?st quand les hommes
> penseront comme des ordinateurs.     Sydney Harris


From nirmalg at psu.edu  Sat Mar 29 02:13:44 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Fri, 28 Mar 2003 20:13:44 -0500 (EST)
Subject: [R] obtaining coefficients from a pspline fit
Message-ID: <200303290113.UAA24219@webmail7.cac.psu.edu>


Hi.. I'm relatively new to both nonparametric modeling and R.. I'm trying to fit
a regression spline or a piecewise polynomial using R and have teh following
qns.:

1. How do I fit a regression spline/piecewise polynomial to the data for some
specified degree of the polynomial?

2. How do I obtain the coefficients of the model?

I tried the following (based on an example in the help):

> data(cars)
>  attach(cars)
>  plot(speed, dist, main = "data(cars)  &  smoothing splines")
>  cars.spl <- sm.spline(speed, dist)
> cars.spl
Call:
smooth.Pspline(x = ux, y = tmp[, 1], w = tmp[, 2], method = method)

Smoothing Parameter (Spar): 366.8429 
Equivalent Degrees of Freedom (Df): 2.428851 
GCV Criterion: 29.54554 
CV  Criterion: 39.18787 

> coef(cars.spl)
NULL

As seen above, it doesn't give me the coefficients though it seems to have
fitted a piecewise linear model.. I just get "NULL".. is there some other
function that will do this?

Please cc me on the reply as I'm not subscribed to the list yet..

Thanks,
nirmal


From spencer.graves at pdf.com  Sat Mar 29 05:45:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 28 Mar 2003 20:45:06 -0800
Subject: [R] Repeated measures help
References: <003901c2f589$918607c0$952bf8d1@Gateway355F>
Message-ID: <3E8524D2.9090701@pdf.com>

Did you look at Pinhiero and Bates (2000) Mixed Effects Models in S and 
S-Plus (Springer)?

I've been able to do several things with lme using this book that I 
could not figure out without it;  "lme" is state of the art but not easy 
to use.  It is a space shuttle, not a bottle rocket.

Spencer Graves

John Reeve wrote:
> Hello R Folks,
> 
> Would someone mind posting a simple example of a repeated measures analysis
> using lme?  I'm trying to duplicate the analyses in Chapter 3 of the "SAS
> System for Mixed Models" manual, in particular those on p. 88-102 and
> involving different correlation structures.  The data have the usual
> split-plot layout for repeated measures.  I have downloaded the "SASMixed"
> examples from CRAN and run them, but except for the first example these
> don't seem to match the SAS output.  Thanks for any help.
> 
> Best wishes,
> John
> reevejd at earthlink.net
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From mschwartz at medanalytics.com  Sat Mar 29 06:11:04 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 28 Mar 2003 23:11:04 -0600
Subject: [R] mozilla and R -- again 
Message-ID: <004901c2f5b1$9a505e50$0201a8c0@MARC>

Good evening all,

This will be my last post on this subject...I promise...  :-)

I have spent more time searching this evening on this, only because I
had some gut feelings that my first impression earlier today was not
entirely accurate. Indeed, that seems to be the case here. While I
have not located "conclusive" facts to explain this phenomenon, I have
located sufficient piecemeal information to at least suggest some
possibilities.

In addition, I am also rapidly coming to the conclusion that I am
learning much more about the internal workings of Mozilla than I
really need to know.  :-)

First, the URL showing in the Mozilla DOM/JavaScript Object browser in
WinXP that I referenced earlier
("wyciwyg://0/file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngin
e.html") reflects the use of the "wyciwyg" protocol, which is
apparently used by the Gecko engine to interact with the "Cache"
functions in the browser for **dynamically generated pages**. Thus the
active page URL is not actually "corrupted" as I suggested and this
also applies to the Linux variant of the same URL.

This may not be the sole "rasion d'etre" for wyciwyg, but it certainly
seems to be a significant foundation.

In other words, as I understand it, when you use the Back and/or
Forward buttons and the page you are recalling was dynamically
generated, it is the wyciwyg protocol that Gecko uses to retrieve the
URL's and the page from the Cache. Hence the prefix of "wyciwyg://0/"
in the URL above.

There are several sites that came up in searches suggesting that the
combination of the wyciwyg protocol and Java/JavaScript, along with
both the memory and disk caches can result in the compromise of
"dynamically" generated pages (at least as they are rendered in the
browser after being recalled from the cache). In addition there are
references to possible security risks with the wyciwyg protocol due to
URL spoofing. 

There is an indication in Bugzilla that the latter issue has been very
recently resolved via patches to docshell and imposed restrictions on
what type of pages can be loaded via the wyciwyg protocol and it may
be this change that was reflected in the Security Warning in the
JavaScript Console that I included earlier today.

Some information on these sites would imply that the type of behavior
that we see with relative URL links from the R Java search engine
applet might be expected as a consequence of the combination of the
various above factors.

It is also suggested that the "broken URL" behavior does not occur in
MS IE since MS does not utilize the wyciwyg protocol approach to
recalling dynamically generated pages from IE's cache. 

This would seem to reinforce the possibility that there is something
unique to the use of the wyciwyg protocol by the Gecko engine in this
scenario and the possibility of some "environmental" compromise of the
integrity of the page content in the browser.

In either case, since specific details are somewhat sparse, I am
unclear as to whether or not this behavior is to be fixed. What is
clear is that these symptoms appear to be known and at least similar
issues have been around for a period of time over which multiple
versions of Mozilla have been released without a change.

At this point, I'll leave you with the above and presume that we'll
need to live with this behavior for at least the near term,
notwithstanding the workarounds discussed earlier.

Best regards to all,

Marc Schwartz


From gisar at nus.edu.sg  Sat Mar 29 07:53:39 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Sat, 29 Mar 2003 14:53:39 +0800
Subject: [R] Problems with data.matrix
Message-ID: <024D6AEFCB92CB47BA1085751D184BB8015FDC9D@MBXSRV03.stf.nus.edu.sg>


unlist() ... 

x <- list(NULL)
x <- list( c(1,2), c(3,4), c(5,6), c(7,8) )
y <- unlist(x)
z <- matrix( y, nrow=2 ) 



-----Original Message-----
From: Laura Gross [mailto:laura at bayesian-bay.freeserve.co.uk] 
Sent: Saturday, March 29, 2003 12:44 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Problems with data.matrix

Dear List

I have what is probably a simple problem that I just can't seem to
solve.

I have a data list which is in the form: lev2.list

[[1]]
        1      2
      number number
[[2]]
        3      4
      number number

etc down to [[1100]]

I'm wanting to convert this to a data.matrix so I can plot the values,
however, when I use new<-data.matrix(lev2.list), I get a data matrix
that reads:

[1, ] Numeric, 2
[2, ] Numeric, 2

with every line down to [1100, ] reading 'Numeric,2'

Why am I getting this output? Why will R not display the numbers in a
data.matrix?

Many thanks for any help
Laura

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From fredrik.lundgren at norrkoping.mail.telia.com  Sat Mar 29 07:55:25 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Sat, 29 Mar 2003 07:55:25 +0100
Subject: [R] "ordered dotplot"
Message-ID: <000a01c2f5c0$2e01efc0$2d0ffea9@oemcomputer>

Hello,
I'm using linux R 1.6.2 and have a named vector (double) which I want too plot with lattice and dotplot. I want both names and values ordered by the vector. In S-Plus this was easy in R I fail.

Sincerely Fredrik Lundgren


From ripley at stats.ox.ac.uk  Sat Mar 29 08:30:28 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 29 Mar 2003 07:30:28 +0000 (GMT)
Subject: [R] obtaining coefficients from a pspline fit
In-Reply-To: <200303290113.UAA24219@webmail7.cac.psu.edu>
Message-ID: <Pine.LNX.4.44.0303290722090.5067-100000@gannet.stats>

1) sm.spline is in package Pspline.  It does not fit a regression spline: 
use ns/bs in packages splines with lm() to do that.  For what you did do, 
smooth.spline in package modreg would be preferred.

2) I don't see why you think the coefficients would be useful.  You need 
to know the knots and the respresentation of the spline too.  What do you 
want to do with them?  For almost all purposes you want to call predict()
on a regression-spline fit.

Coefficients are less useful in linear regression than many people think,
too, but they can often be sent up to have a direct interpretation.  That 
is never true of spline coefficients.

My advice is that you seek local statistical advice.  If you find
something hard to do in R it is usually because no one has wanted to do
it, and that is usually because it is not seen as helpful.

On Fri, 28 Mar 2003, Nirmal Govind wrote:

> 
> Hi.. I'm relatively new to both nonparametric modeling and R.. I'm trying to fit
> a regression spline or a piecewise polynomial using R and have teh following
> qns.:
> 
> 1. How do I fit a regression spline/piecewise polynomial to the data for some
> specified degree of the polynomial?
> 
> 2. How do I obtain the coefficients of the model?
> 
[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From david.whiting at ncl.ac.uk  Sat Mar 29 11:08:58 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Sat, 29 Mar 2003 10:08:58 +0000
Subject: [R] Statistical computing
In-Reply-To: <20030328124325.7ee0880b.fharrell@virginia.edu>
References: <3EB0F3C7@webmail.mcgill.ca>
	<20030328124325.7ee0880b.fharrell@virginia.edu>
Message-ID: <20030329100858.GA6908@192.168.57.2>

On Fri, Mar 28, 2003 at 12:43:25PM -0500, Frank E Harrell Jr wrote:
> On Fri, 28 Mar 2003 11:42:18 -0500
> Tanya Murphy <tmurph6 at po-box.mcgill.ca> wrote:
> 
> > Hello,
> > 
> > I've been trying to familiarize myself with the computing tools of the trade 
> > (e.g. SAS, R, Perl, LaTex) and I've been getting somewhere with the individual 
> > programs, but I'm trying to get a better sense of how to integrate these 
> > tools. I'd like to use scripts and create reports in a more organized way. Can 
> > anyone recommend books or, better yet free online articles, on this topic? 
> > Maybe I should be a little more specific about what I do: I'm a research 
> > assistant in clinical epidemiology doing mainly data management and analysis. 
> > I do a number of repetitive tasks like updating a research database from the 
> > original clinic database and other sources, create reports, create graphical 
> > output for individual patients, as well as work on individual research 
> > projects. Unfortunately I am not working closely with 'real' statisticians who 
> > have probably developped good work habits using these tools. Any advice on 
> > 'the big picture' would be greatly appreciated.
> > 
> > Thanks!
> > 
> > Tanya Murphy
> >
> 
> Take a look at the following:
> 
> http://hesweb1.med.virginia.edu/biostat/teaching/statcomp/notes.pdf
> http://hesweb1.med.virginia.edu/biostat/s/doc/splus.pdf
> http://hesweb1.med.virginia.edu/biostat/teaching/statcomp
> http://hesweb1.med.virginia.edu/biostat/presentations/feh/clinreport/dmcreport.pdf
> 
> For statistical reports you have chosen well, in considering intergrating R and LaTeX.  The Alzola-Harrell text also covers a bit about using make and Perl to run scripts (to get data from SAS to R, run R, etc.).

I have been extremely impressed by the way sweave (combines LaTeX and
R), and RODBC (in my case with MySQL) work together for data
management, reporting, writing stuff and even creating presentations.
I use a LaTeX document class called 'Prosper" that creates PDF
presentations with many of the features and appearance of MS
Powerpoint presentations.

For Sweave, take look at:
http://www.ci.tuwien.ac.at/~leisch/Sweave/Sweave-manual-20021007.pdf
http://cran.r-project.org/doc/Rnews/Rnews_2002-3.pdf (pages 28-31)

For Prosper take a look at:
http://sourceforge.net/projects/prosper/
and then google for: latex prosper 
and you will find many links to tutorials etc. 


Dave


-- 
Dave Whiting
Dar es Salaam, Tanzania


From david.whiting at ncl.ac.uk  Sat Mar 29 14:37:41 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Sat, 29 Mar 2003 13:37:41 +0000
Subject: R, w3m incl. images, ESS, ... [was Re: [R] mozilla and R --
	again]
In-Reply-To: <20030328183539.GB365@192.168.57.2>
References: <20030327194642.64e103cd.fharrell@virginia.edu>
	<Pine.A41.4.44.0303271715260.30460-100000@homer34.u.washington.edu>
	<20030328080255.GB11782@192.168.57.2> <87smt7tv35.fsf@jeeves.blindglobe.net>
	<20030328183539.GB365@192.168.57.2>
Message-ID: <20030329133741.GA8421@192.168.57.2>

One other thing to mention.  w3m can be compiled with image support
(which seemed strange to me at first considering w3m is a text
browser).  Any, this means that graphics can also be displayed inline.
I have used Zed Shaw's html.r and run his example code.  It works very
nicely.  I have a screen shot of the output if people want to see what
it looks like but don't have a website on which to post it.  If anyone
wants to see it, let me know and I email it.  It is a 14k png file, so
is not too heavy.

I have also downloaded Eric Lecoutre's R2HTML and will have a play
with that.  

So, all (?) I need to do now is learn enough lisp to stick it all
together.

Dave.




On Fri, Mar 28, 2003 at 06:35:39PM +0000, david.whiting at ncl.ac.uk wrote:
> On Fri, Mar 28, 2003 at 06:38:22AM -0800, A.J. Rossini wrote:
> 
> [...]
> > > fast.  This does not provide all of the functionality of help.start()
> > > but might be a way of getting free of these java issues (for those
> > > happy to use emacs and ESS that is).
> > 
> > Very, very interesting.  Let me know if I can help.
> 
> Without doubt.  How about this problem: I can get input from the
> minibuffer and store it in a variable.  I haven't yet found out how to
> call R from a lisp function (or more correctly do thing like
> eval-region/eval-my-search-function) and when I do I want to be able
> to pass the entered value to the function.  I plan to try to work on
> this over the weekend so if you can give me some pointers in that
> direction it would be helpful.  Please remember though that I am very,
> very new to lisp.
> 
> > Let us know if you make progress that you'd like to share!
> 
> Okay, will do.  BTW, what's the best way to handle
> discussion/collaboration on this?  Off-list, at least until something
> more solid appears?  It is probably a little tangential to R-help for
> now and I have not subscribed to the ESS list. 
> 
> Bye for now.
> 
> Dave
> 

-- 
Dave Whiting
Dar es Salaam, Tanzania


From ghosh at science.unitn.it  Sat Mar 29 13:53:38 2003
From: ghosh at science.unitn.it (Ghosh Mini)
Date: Sat, 29 Mar 2003 13:53:38 +0100 (MET)
Subject: [R] Request
In-Reply-To: <Pine.OSF.4.44.0303271413420.26253-100000@omega.science.unitn.it>
Message-ID: <Pine.OSF.4.44.0303271638570.12799-100000@omega.science.unitn.it>


Dear all,

I am calling a table (data of several years) by psql command (order by
date)

aggregate(mydata[, c("nymphs", "adults")],list(date = mydata$date)

is giving table order by month (of each year) like


1 09-29-1999 0.00000000 0.00000000
2 09-30-1999 0.16666667 0.00000000
3 10-05-2000 0.55555556 0.05555556
4 11-04-2000 0.07142857 0.00000000
5 11-05-2000 0.55000000 0.05000000
6 12-08-1999 0.00000000 0.00000000
7 12-09-2000 0.56410256 0.00000000

I want it arranged by date (increasing order).

If possible pl. help me, thanking you.

regards,
mini


From ripley at stats.ox.ac.uk  Sat Mar 29 14:33:27 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 29 Mar 2003 13:33:27 +0000 (GMT)
Subject: [R] Request
In-Reply-To: <Pine.OSF.4.44.0303271638570.12799-100000@omega.science.unitn.it>
Message-ID: <Pine.LNX.4.44.0303291322140.8963-100000@gannet.stats>

As far as I can see those are just character strings, and what has psql to 
do with it?  Some more details would have been helpful.

Your strings do not appear to be valid dates: the ISO standard is
1999-09-29 etc.  So the simplest solution is to use a Standard data
format, which will sort the way you want them.  If you cannot do that, try
?strptime and ?as.POSIXct to see how to convert your strings to POSIXct
dates, and if you want, back to a useful format.

Alternatively, you could re-arrange the strings via strsplit.

The bottom line is simple: use a proper format.  That someone with an 
Italian email address is using an American-only format is puzzling.

On Sat, 29 Mar 2003, Ghosh Mini wrote:

> 
> Dear all,
> 
> I am calling a table (data of several years) by psql command (order by
> date)
> 
> aggregate(mydata[, c("nymphs", "adults")],list(date = mydata$date)
> 
> is giving table order by month (of each year) like
> 
> 
> 1 09-29-1999 0.00000000 0.00000000
> 2 09-30-1999 0.16666667 0.00000000
> 3 10-05-2000 0.55555556 0.05555556
> 4 11-04-2000 0.07142857 0.00000000
> 5 11-05-2000 0.55000000 0.05000000
> 6 12-08-1999 0.00000000 0.00000000
> 7 12-09-2000 0.56410256 0.00000000
> 
> I want it arranged by date (increasing order).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From deepayan at stat.wisc.edu  Sat Mar 29 14:55:18 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 29 Mar 2003 07:55:18 -0600
Subject: [R] "ordered dotplot"
In-Reply-To: <000a01c2f5c0$2e01efc0$2d0ffea9@oemcomputer>
References: <000a01c2f5c0$2e01efc0$2d0ffea9@oemcomputer>
Message-ID: <200303290755.18766.deepayan@stat.wisc.edu>


For example ? 

On Saturday 29 March 2003 12:55 am, Fredrik Lundgren wrote:
> Hello,
> I'm using linux R 1.6.2 and have a named vector (double) which I want too
> plot with lattice and dotplot. I want both names and values ordered by the
> vector. In S-Plus this was easy in R I fail.
>
> Sincerely Fredrik Lundgren
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From jean.vidal at freesurf.fr  Sat Mar 29 15:03:24 2003
From: jean.vidal at freesurf.fr (Jean Vidal)
Date: Sat, 29 Mar 2003 15:03:24 +0100
Subject: [R] Plot of Canonical Correlation Analysis
Message-ID: <5.1.0.14.0.20030329145525.01c29ce0@pop.freesurf.fr>


f.mercier at fournier.fr wrote:
 > Dear all,
 >
 > I didn't find any graphical solution in the package "mva" to plot the
 > canonical scores from a CCA (canonical correlation analysis).
 > Does anybody knows how to plot or has anybody already programmed :
 > - the map of the canonical scores,
 > - the graph of the canonical weights,
 > - the correlation circle i.e. the canonical loadings ?
 > Thank you for help ...
 >

You may find an answer in the package ADE4, on CRAN.
It has lot of graphical representations and documents with examples can be 
found on the Lyon university site.
For canonical correlation analysis, you will find them at :
http://pbil.univ-lyon1.fr/R/cours/bsb.pdf
It's written in french, but that won't be a problem for you ;-)


From djw1005 at cam.ac.uk  Sat Mar 29 15:18:28 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Sat, 29 Mar 2003 14:18:28 +0000 (GMT)
Subject: [R] Temporarily turn off certain warnings
Message-ID: <Pine.SOL.3.96.1030329140106.1646A-100000@libra.cus.cam.ac.uk>


When I call, for example
> min()
> min(Inf,Inf)
I get the warning: "no finite arguments to min; returning Inf".

When I make such a call, it is usually intentionally. I would like to turn
off those warnings, so they don't hide other (usually more serious)
warnings. (I like to debug my programs with options(warn=2).)

How can I write a function which does the same as min but doesn't generate
these warnings? I wrote my own version of min, but I'm not confident it
deals properly with all the structures that min deals with. So what I'd
like to know is how I can turn off a specific warning in a specific block
of code. I looked at try, but it seems to deal with errors rather than
warnings.

Damon Wischik.


From ripley at stats.ox.ac.uk  Sat Mar 29 15:31:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 29 Mar 2003 14:31:03 +0000 (GMT)
Subject: [R] Temporarily turn off certain warnings
In-Reply-To: <Pine.SOL.3.96.1030329140106.1646A-100000@libra.cus.cam.ac.uk>
Message-ID: <Pine.LNX.4.44.0303291426450.9056-100000@gannet.stats>

>From fixInNamespace, a new function in 1.7.0-to-be

    if (bindingIsLocked(subx, ns)) {
        unlockBinding(subx, ns)
        assign(subx, x, env = ns)
        w <- options("warn")
        on.exit(options(w))
        options(warn = -1)
        lockBinding(subx, ns)
    }

and if the function continues and you want warnings back on, you could do

        w <- options("warn")
        on.exit(options(w))
        options(warn = -1)
        lockBinding(subx, ns)
        options(w)
	on.exit()

On Sat, 29 Mar 2003, Damon Wischik wrote:

> 
> When I call, for example
> > min()
> > min(Inf,Inf)
> I get the warning: "no finite arguments to min; returning Inf".
> 
> When I make such a call, it is usually intentionally. I would like to turn
> off those warnings, so they don't hide other (usually more serious)
> warnings. (I like to debug my programs with options(warn=2).)
> 
> How can I write a function which does the same as min but doesn't generate
> these warnings? I wrote my own version of min, but I'm not confident it
> deals properly with all the structures that min deals with. So what I'd
> like to know is how I can turn off a specific warning in a specific block
> of code. I looked at try, but it seems to deal with errors rather than
> warnings.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From james.holtman at convergys.com  Sat Mar 29 18:02:54 2003
From: james.holtman at convergys.com (james.holtman@convergys.com)
Date: Sat, 29 Mar 2003 12:02:54 -0500
Subject: [R] overlapping pattern match (errata 2.0)
Message-ID: <OFB47EA292.C5F8161A-ON85256CF8.005D77AB@convergys.com>


Another way to find all the multiple occurances of a character in a string
is to use 'rle':

> x.s <- 'aaabbcdeeeffffggiijjysbbddeffghjjjsdkkkkk'
> x <- unlist(strsplit(x.s, NULL))
> x
 [1] "a" "a" "a" "b" "b" "c" "d" "e" "e" "e" "f" "f" "f" "f" "g" "g" "i"
"i" "j"
[20] "j" "y" "s" "b" "b" "d" "d" "e" "f" "f" "g" "h" "j" "j" "j" "s" "d"
"k" "k"
[39] "k" "k" "k"
> rle(x)
Run Length Encoding
  lengths: int [1:21] 3 2 1 1 3 4 2 2 2 1 ...
  values : chr [1:21] "a" "b" "c" "d" "e" "f" "g" "i" "j" "y" "s" "b" "d"
"e" "f" "g" ...
>

When the lengths are >1, the corresponding 'values' are the repeated
characters.




                                                                                                                                           
                      FMGCFMGC                                                                                                             
                      <FMGCFMGC at terra.es>          To:       yfan at diversa.com                                                              
                      Sent by:                     cc:       r-help at stat.math.ethz.ch                                                      
                      r-help-bounces at stat.m        Subject:  Re: [R] overlapping pattern match (errata 2.0)                                
                      ath.ethz.ch                                                                                                          
                                                                                                                                           
                                                                                                                                           
                      03/28/03 17:36                                                                                                       
                                                                                                                                           
                                                                                                                                           




well! excuse me again but...

your.string <- "aaacdf"
nc1 <- nchar(your.string)-1
x <- unlist(strsplit(your.string, NULL)) ######## CORRECT
x2 <- c()
for (i in 1:nc1)
x2 <- c(x2, paste(x[i], x[i+1], sep="")) ######## ERRATA 2
cat("ocurrences of <aa> in <your.string>: ", length(grep("aa", x2)),
sep="", fill=TRUE)

Fran

PD: sorry again

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help




--
"NOTICE:  The information contained in this electronic mail transmission is
intended by Convergys Corporation for the use of the named individual or
entity to which it is directed and may contain information that is
privileged or otherwise confidential.  If you have received this electronic
mail transmission in error, please delete it from your system without
copying or forwarding it, and notify the sender of the error by reply email
or by telephone (collect), so that the sender's address records can be
corrected."


From mentus at gmx.de  Sat Mar 29 19:37:52 2003
From: mentus at gmx.de (Fernando Henrique Ferraz)
Date: Sat, 29 Mar 2003 15:37:52 -0300
Subject: [R] Goodness of fit tests
Message-ID: <20030329183752.GA25607@mentecapto.ogm>

  
   I have a dataset which I want to model using a Poisson distribution, with a given parameter. I would like to know what is the proper way to do a 'goodness of fit' test using R.
   I know the steps I'd take if I were to do it 'manually': grouping the numbers into classes, calculating the expected frequencies using 'ppois', then calculating Chi_2_obs = Sum (e_i - o_i)^2/e_i) (where e_i represents the expected frequencies and o_i the observeds ones) and then finally calculating the p-value (using pchisq).
   I've read a lot of documentation, also tried googling for 'goodness of fit R' but it was helpless, most of it is only about 'regression analysis'. Does anyone know if there is a simpler way to do this?


Thank you, 

 
<Fernando Henrique Ferraz Pereira da Rosa - mentus at gmx.de>


From meyer at ci.tuwien.ac.at  Sat Mar 29 21:33:10 2003
From: meyer at ci.tuwien.ac.at (David Meyer)
Date: Sat, 29 Mar 2003 21:33:10 +0100 (CET)
Subject: [R] Goodness of fit tests
In-Reply-To: <20030329183752.GA25607@mentecapto.ogm>
Message-ID: <Pine.LNX.4.21.0303292132400.5852-100000@boromir.ci.tuwien.ac.at>

Try `goodfit' in package `vcd'.

g.,
-d

        Mag. David Meyer            Wiedner Hauptstrasse 8-10
Vienna University of Technology     A-1040 Vienna/AUSTRIA
         Department of              Tel.: (+431) 58801/10772
Statistics and Probability Theory   Fax.: (+431) 58801/10798






On Sat, 29 Mar 2003, Fernando Henrique Ferraz wrote:

>   
>    I have a dataset which I want to model using a Poisson distribution, with a given parameter. I would like to know what is the proper way to do a 'goodness of fit' test using R.
>    I know the steps I'd take if I were to do it 'manually': grouping the numbers into classes, calculating the expected frequencies using 'ppois', then calculating Chi_2_obs = Sum (e_i - o_i)^2/e_i) (where e_i represents the expected frequencies and o_i the observeds ones) and then finally calculating the p-value (using pchisq).
>    I've read a lot of documentation, also tried googling for 'goodness of fit R' but it was helpless, most of it is only about 'regression analysis'. Does anyone know if there is a simpler way to do this?
> 
> 
> Thank you, 
> 
>  
> <Fernando Henrique Ferraz Pereira da Rosa - mentus at gmx.de>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From flying2001us at yahoo.com  Sat Mar 29 22:49:21 2003
From: flying2001us at yahoo.com (Chris Xin)
Date: Sat, 29 Mar 2003 13:49:21 -0800 (PST)
Subject: [R] pdf function assignment (beginner's question)
Message-ID: <20030329214921.37732.qmail@web11805.mail.yahoo.com>

hi,

how can I assign a pdf function (not the standard
stats distribution, and quite complex, exponential
calculations  involved) and plot its cdf curve in R? 

thanks!


From nirmalg at psu.edu  Sat Mar 29 23:14:03 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Sat, 29 Mar 2003 17:14:03 -0500 (EST)
Subject: [R] obtaining coefficients from a pspline fit
Message-ID: <200303292214.RAA21559@webmail5.cac.psu.edu>


Thanks for your reply...

> 2) I don't see why you think the coefficients would be useful.  You need 
> to know the knots and the respresentation of the spline too.  What do you 
> want to do with them?  For almost all purposes you want to call predict

The reason I wanted the coefficients is so that I can do the prediction outside
of R, say for example in Excel, once the spline has been created. 

I just googled and found that there's something called RExcel which can call R
from within Excel.. I think this might be what I need then... will give it a
try..

Thanks,
nirmal


From hammett at princeton.edu  Sun Mar 30 03:19:33 2003
From: hammett at princeton.edu (Greg Hammett)
Date: Sat, 29 Mar 2003 20:19:33 -0500
Subject: [R] simple test of lme, questions on DF corrections
Message-ID: <200303300119.h2U1JXg21977@hammett-xt.pppl.gov>

I'm a physicist working on fusion energy and dabble in statistics
only occasionally, so please excuse gaps in my statistical
knowledge.  I'd appreciate any help that a real statistics expert
could provide.  Most people in my field do only very simple
statistics, and I am trying to extend some work on multivariate
linear regression to account for significant between-group
correlated errors.  It looks to me like the lme routine in the
nlme package does most of what I want. (My congrats to the
developers of R and nlme, they are extremely useful!).

To summarize my questions: I've tested lme on a very simple test
case (with just 1 parameter, the mean, and 1 random effect), but
the results are somewhat different than I get from some simple
maximum-likelhood formulas.  It appears that some quantities
calculated by lme are corrected for the reduction in the degrees
of freedom due to the number of fit parameters.  But these
corrections are slightly different (0.3%-3%) than what I would
have expected, and I'd like to understand these differences
better.  The transcript of an R session documenting these issues
is at the end of this message.

--------------------------------------------

Details:

I've read relevant parts of Pinheiro and Bates's book and various
articles.  To test my understanding of various definitions, I
considered the simplest limit of fitting a 1-parameter model
(i.e., just the mean or intercept) with 1 level of grouping:

y_ij = beta + b_i + e_ij

where beta is the population mean, b_i is the random effect for
the i'th group, and e_ij is the random error of the j'th
observation from the i'th group.  I'm using the simple "Rail"
dataset of N=18 observations, consisting of 3 measurements of
ultrasound wave travel time for each of N_groups=6 rails, as used
in the examples on p. 5-11 of Pinheiro & Bates.  I am using the
method="ML" option in lme to use the Maximum Likelihood method.

In this simple limit, the expressions for the maximum likelihood
formulas (such as Eq. 2.6 of P&B) greatly simplify, as the
relevant variance-covariance matrices simplify to scalar
numbers.  One can then analytically calculate the
maximum-likelihood results for various quantities, getting the
standard-looking results that the ML estimate of the within-group
random error is

sigma^2 = sum(e_ij^2)/N       Eq. g.1

and the ML estimate of the between-group random error is:

sigma_b^2 = sum(b.hat_i^2)/N_groups       Eq. g.2

(where b.hat_i are the fitted estimates of b_i, and e_ij are the
residuals after fitting).

Note that these formulas are slightly different than the standard
unbiased least-squares results, which divide by the number of
degrees of freedom corrected for the number of fit parameters.
As usual, maximum likelihood ML estimates are slightly downward
biased because of this.  [As I understand it, REML is designed to
correct for this, and does so very well in balanced designs.  But
for the eventual fusion problem I'm interested in, the dataset is
very unbalanced and lme with method="REML" appears to give
excessively pessimistic error estimates, so I'm using ML instead,
which gives results consistent with a couple of other methods
I've used: cross-validation and a weighted jackknife.]

However, from the test I do with the Rail dataset below, it
appears that lme actually doesn't use the above formula for sigma
but instead includes some kind of correction for the reduced
degrees of freedom.  lme's result is very close to:

sigma^2 = sum(e_ij^2)/(N-N_groups)

lme's sigma is only 0.3% low compared to this, so I don't worry
about this much, but I'd still like to understand how lme is
calculating sigma and why it differs slightly even from this
result.

lme's calculation of sigma_b is very close to Eq. g.2 above (and
so doesn't appear to include a DF correction?), but is 0.5% high,
just enough different to be a little puzzling.

Does anyone know of a simple explanation of these small
differences?  I could "just read the source code" (I have glanced
at it), but I assume it is all cast in terms of the general
matrix formulation and the degrees-of-freedom (DF) correction is
buried somewhere hard to understand.  I haven't noticed a mention
in any of the documentation that some of the results from
lme(method="ML") attempt to correct for the O(p/n) bias of
standard maximum-likelihood estimates.  Does anyone know of any
documentation or references regarding this?

Finally, if the within-group rms error sigma and the
between-group rms error sigma_b have been estimated, then a
standard calculation seems to show that the uncertainty
sigma_beta in the estimated population mean beta is:

sigma_beta^2 = sigma^2/N + sigma_b^2/N_groups

The value of sigma_beta reported by lme is 3% higher than this
formula.  I could imagine that a DF correction to a ML estimate
gives small differences from this formula for some reason, but
I'd like to understand it better.   In the Rail data, the
uncertainty sigma_beta is dominated by the between-group error
sigma_b, so in the 95% confidence interval I might have thought
one would use a t-statistic with ~N_groups degrees of freedom,
but it appears that the 95% confidence interval caclulated by
interval() is using DF~=N-2.  Any comments?

Below is a transcript of an R session documenting the various
issues mentioned about.  Perhaps I'm just ignorant of some
standard corrections that experts assume every one knows, and I'd
appreciate any feedback.

Thanks,

Greg


Greg Hammett
Lecturer with rank of Professor, 
   Program in Plasma Physics, Princeton University
Principal Research Physicist, 
   Princeton Plasma Physics Laboratory


###################################################################

R : Copyright 2003, The R Development Core Team
Version 1.6.2  (2003-01-10)
> #
> # Test lme using Rail dataset from p.9-10 of Pinheiro and Bates Book.
> #
> 
> library(nlme)
Loading required package: nls 
Loading required package: lattice 
> data(Rail)
> # simple set of 18 data points:
> Rail
Grouped Data: travel ~ 1 | Rail
   Rail travel
1     1     55
2     1     53
3     1     54
4     2     26
5     2     37
6     2     32
7     3     78
8     3     91
9     3     85
10    4     92
11    4    100
12    4     96
13    5     49
14    5     51
15    5     50
16    6     80
17    6     85
18    6     83
> 
> fm1 <- lme(travel~1, data=Rail, random=~1|Rail, method="ML")
> summary(fm1)
Linear mixed-effects model fit by maximum likelihood
 Data: Rail 
       AIC      BIC    logLik
  134.5600 137.2312 -64.28002

Random effects:
 Formula: ~1 | Rail
        (Intercept) Residual
StdDev:    22.62435 4.020779

Fixed effects: travel ~ 1 
            Value Std.Error DF  t-value p-value
(Intercept)  66.5  9.554026 12 6.960416  <.0001

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-1.61098123 -0.28887045  0.03454167  0.21372781  1.62222280 

Number of Observations: 18
Number of Groups: 6 
> 
> # Agrees with book.  
> # lme's est of "within-group" sigma is labelled "Residual" 4.0208
> # lme's est of "between-group" sigma_b is StdDev of Intercept 22.624
> 
> 
> # This should be the Maximum Likelihood Estimate (which ignores the
> # reduction of the DF by the # of fit parameters) of the std. dev. of the
> # within-group residual: 
> (sum(fm1$residuals[,2]**2)/length(fm1$residuals[,2]) )**0.5
[1] 3.291492
> # but this gives only 3.29, compared to lme's sigma=4.0208.
> 
> # Apparently lme is including a correction for the number of Degrees of
> # Freedom, reduced from the # of observations by 6 (the # of groups):
> 
> (sum(fm1$residuals[,2]**2)/(length(fm1$residuals[,2])-6) )**0.5
[1] 4.031238
> # (although this is still 0.3% low...)
> 
> # This should be the ML est. of the std. dev. of the random effect b_i
> # coefficients:
> 
> (sum(ranef(fm1)**2)/length(ranef(fm1)[,]) )**0.5
[1] 22.50619
> # but it is 0.5% low from lme's sigma_b=22.62435.
> 
> # Random-effects Variance matrix is a single number in this case:
> VarCorr(fm1)
Rail = pdLogChol(1) 
            Variance  StdDev   
(Intercept) 511.86112 22.624348
Residual     16.16667  4.020779
> 
> # Taking lme's estimate of the within-group sigma and between-group
> # sigma_b, the uncertainty in the mean of the data should be:
> 
> (fm1$sigma^2/18+as.real(VarCorr(fm1)[1,1])/6)^0.5
[1] 9.284844
> # though this is 3% lower than lme's reported Std.Error of the intercept
> # of 9.554026:
> (fm1$sigma^2/18+as.real(VarCorr(fm1)[1,1])/6)^0.5/9.554026
[1] 0.9718253
> 
> intervals(fm1)
Approximate 95% confidence intervals

 Fixed effects:
               lower est.    upper
(Intercept) 46.27006 66.5 86.72994

 Random Effects:
  Level: Rail 
                   lower     est.    upper
sd((Intercept)) 12.77211 22.62435 40.07648

 Within-group standard error:
   lower     est.    upper 
2.695008 4.020779 5.998746 
> 
> # The 95% confidence interval for beta (the intercept), is very close to
> # what one expects with sigma_beta=9.554026, with a t value of 2.110 for
> # DF=N-1=17, though it is actually closer to the t value of 2.120 for
> # DF=16:
> (66.5-46.27006)/9.554026
[1] 2.117426
> qt(0.975,df=16)  # t-value for 95% confidence interval and df=16
[1] 2.119905
> qt(0.975,df=6)   # t-value for 95% confidence interval and df=6
[1] 2.446912
> 
> # However, since the uncertainty in beta is dominated by the
> # between-group errors, shouldn't the DF used for the t value
> # be close to the number of groups, 6, not the number of 
> # observations, 18?
>


From marquito_ufrj at hotmail.com  Sun Mar 30 05:25:57 2003
From: marquito_ufrj at hotmail.com (Marcus V. Stecklow)
Date: Sun, 30 Mar 2003 03:25:57 +0000
Subject: [R] Using the R commands
Message-ID: <F63TM8PjgtJTYaiLSLw0000fe70@hotmail.com>

Hi,

My name is MArcus Vinicius and i`m learning to use the R and have a problem.

I`m doing a program and it`s have a loop using the for command. inside the 
loop i have a variable and in each step of loop she have a new value.

The question is: How can i store the values and make a table?

I tried to use the matrix command but it`s only stored the last value of the 
variable

Can i help me?







_________________________________________________________________
MSN Messenger: converse com os seus amigos online.  
http://messenger.msn.com.br


From baron at cattell.psych.upenn.edu  Sun Mar 30 05:48:36 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sat, 29 Mar 2003 22:48:36 -0500
Subject: [R] Using the R commands
In-Reply-To: <F63TM8PjgtJTYaiLSLw0000fe70@hotmail.com>;
	from marquito_ufrj@hotmail.com on Sun, Mar 30, 2003 at 03:25:57AM +0000
References: <F63TM8PjgtJTYaiLSLw0000fe70@hotmail.com>
Message-ID: <20030329224836.A13398@cattell.psych.upenn.edu>

On 03/30/03 03:25, Marcus V. Stecklow wrote:

>I`m doing a program and it`s have a loop using the for command. inside the 
>loop i have a variable and in each step of loop she have a new value.
>
>The question is: How can i store the values and make a table?

For example:
Squares <- rep(NA,10) # make an empty vector with 10 places
for (i in 1:10) Squares[i] <- i^2 # fill it with squares
Squares # print it

Lots of other ways to do this.  For example, you can use
Squares <- {}
for the first step.
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
R page:               http://finzi.psych.upenn.edu/


From confirm-326122-78148-r-help=lists.r-project.org at citius.getresponse.com  Sun Mar 30 08:18:05 2003
From: confirm-326122-78148-r-help=lists.r-project.org at citius.getresponse.com (Matt Reams)
Date: 30 Mar 2003 06:18:05 -0000
Subject: [R] Request for confirmation.
Message-ID: <20030330061805.12236.qmail@citius.getresponse.com>

You have just requested to subscribe to a quality
business opportunity opt-in list maintained by
GetResponse.com opt-in/autoresponder service.
The list owner has requested your confirmation 
to verify your e-mail address.


To activate your subscription and instantly receive 
information on an extremely HOT business opportunity,
simply click the link below!
http://www.getresponse.com/confirm.pl?a=326122&b=r-help%40lists.r-project.org&c=78148


You can also simply reply to this message, but do 
not change the subject line if you do.

You can unsubscribe or change your details at any time.


Thanks!



--
Email address: r-help at lists.r-project.org
Type of request: import
Timestamp: 1049005085
IP address: not specified


From ripley at stats.ox.ac.uk  Sun Mar 30 09:25:34 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 30 Mar 2003 08:25:34 +0100 (BST)
Subject: [R] Using the R commands
In-Reply-To: <20030329224836.A13398@cattell.psych.upenn.edu>
Message-ID: <Pine.LNX.4.44.0303300819590.16109-100000@gannet.stats>

On Sat, 29 Mar 2003, Jonathan Baron wrote:

> On 03/30/03 03:25, Marcus V. Stecklow wrote:
> 
> >I`m doing a program and it`s have a loop using the for command. inside the 
> >loop i have a variable and in each step of loop she have a new value.
> >
> >The question is: How can i store the values and make a table?
> 
> For example:
> Squares <- rep(NA,10) # make an empty vector with 10 places
> for (i in 1:10) Squares[i] <- i^2 # fill it with squares
> Squares # print it
> 
> Lots of other ways to do this.  For example, you can use
> Squares <- {}
> for the first step.

The best idea is start out with a vector of the correct length and the 
correct type (rep(NA, 10) is logical), e.g.

Squares <- numeric(10)

This helps for long vectors by reducing the number of copies made.
Squares <- {} is equivalent to setting the result to NULL, just more
obscure.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jgursky at eng.utoledo.edu  Sun Mar 30 10:13:06 2003
From: jgursky at eng.utoledo.edu (Jeremy)
Date: Sun, 30 Mar 2003 03:13:06 -0500
Subject: [R] Question on Plotting
Message-ID: <001a01c2f694$32317550$6802a8c0@Highroller>

I am looking to plot confidence and prediction interval bands for a
specfic set of data.  What R commands would i use to plot this data?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20030330/3993ba06/attachment.html
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 145 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030330/3993ba06/attachment.gif

From darryl.greig at hp.com  Sun Mar 30 10:35:10 2003
From: darryl.greig at hp.com (Darryl)
Date: Sun, 30 Mar 2003 10:35:10 +0200
Subject: [R] Question on Plotting
In-Reply-To: <001a01c2f694$32317550$6802a8c0@Highroller>
Message-ID: <000501c2f697$46f71e10$bf09b00f@hpli.hpl.hp.com>

MessageI believe there are several packages that can do this. I have found
the errorbars function in Frank Harrell's Hmisc
package (http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html) to be quite
good.
  -----Original Message-----
  From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Jeremy
  Sent: 30 March 2003 10:13
  To: R-help at stat.math.ethz.ch
  Subject: [R] Question on Plotting


  I am looking to plot confidence and prediction interval bands for a
specfic set of data.  What R commands would i use to plot this data?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20030330/972fb598/attachment.html
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 145 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030330/972fb598/attachment.gif

From p.dalgaard at biostat.ku.dk  Sun Mar 30 11:56:45 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 30 Mar 2003 11:56:45 +0200
Subject: [R] Using the R commands
In-Reply-To: <Pine.LNX.4.44.0303300819590.16109-100000@gannet.stats>
References: <Pine.LNX.4.44.0303300819590.16109-100000@gannet.stats>
Message-ID: <x27kahfa8y.fsf@biostat.ku.dk>

ripley at stats.ox.ac.uk writes:

> On Sat, 29 Mar 2003, Jonathan Baron wrote:
> 
> > On 03/30/03 03:25, Marcus V. Stecklow wrote:
> > 
> > >I`m doing a program and it`s have a loop using the for command. inside the 
> > >loop i have a variable and in each step of loop she have a new value.
> > >
> > >The question is: How can i store the values and make a table?
> > 
> > For example:
> > Squares <- rep(NA,10) # make an empty vector with 10 places
> > for (i in 1:10) Squares[i] <- i^2 # fill it with squares
> > Squares # print it
> > 
> > Lots of other ways to do this.  For example, you can use
> > Squares <- {}
> > for the first step.
> 
> The best idea is start out with a vector of the correct length and the 
> correct type (rep(NA, 10) is logical), e.g.
> 
> Squares <- numeric(10)
> 
> This helps for long vectors by reducing the number of copies made.
> Squares <- {} is equivalent to setting the result to NULL, just more
> obscure.

And also note that many of these cases are more succinctly expressed
using implicit loops, like

Squares <- sapply(1:10,function(x)x^2)

or even

Squares <- sapply(1:10,"^",y=2)


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From bitwrit at ozemail.com.au  Sun Mar 30 14:45:13 2003
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Sun, 30 Mar 2003 22:45:13 +1000
Subject: [R] Scripting with an external editor
In-Reply-To: <Pine.LNX.4.44.0303241012490.18578-100000@gannet.stats>
References: <Pine.LNX.4.44.0303241012490.18578-100000@gannet.stats>
Message-ID: <20030330113939.UWBN27552.mta09.mail.mel.aone.net.au@there>

Hi again,

If my trawling through the "connections" code is correct, a pipe 
connection is designed to read to EOF before returning its input to the 
parsing function. Blocking is not an option with this type of connection. 
As I do not know how to spoof an EOF on an open pipe, it looks like I 
would have to rewrite 3 or 4 fairly low level functions to return input on 
EOL.

My impression is that this is the wrong way to go about this. After all, I 
am sure that something similar is already being done using the present 
connection functions. Any suggestions as to where else I might look would 
be greatly appreciated.

OS - Linux
R v1.5.1

To reiterate, what I am attempting to do is to send selected text from an 
external editor to the R command line, where it will be processed as if 
entered from the keyboard. I have accomplished everything except getting 
the selections of text which are sent from the external editor to be 
processed individually rather than all in a bunch when the external editor 
exits. For example:

Select the following text in the editor and send it:

cat("Mean of x\n")
x<-1:10
mean(x)

R shows:

Mean of x
[1] 5.5

Select more text and send it:

cat("Sum of x\n")
sum(x)

R shows:

Sum of x
[1] 55

What happens now - selections are sent, but nothing happens until the 
external editor is closed, at which point, R shows:

Mean of x
[1] 5.5
Sum of x
[1] 55


Thanks,

Jim


From agusalon at macris.com  Sun Mar 30 14:11:15 2003
From: agusalon at macris.com (Agustin Alonso)
Date: Sun, 30 Mar 2003 14:11:15 +0200
Subject: [R] Two bugs in TS package?
Message-ID: <001101c2f6b5$7763ae10$34466093@macris.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030330/6eac7399/attachment.pl

From mschwartz at medanalytics.com  Sun Mar 30 17:12:23 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 30 Mar 2003 09:12:23 -0600
Subject: [R] Question on Plotting
In-Reply-To: <001a01c2f694$32317550$6802a8c0@Highroller>
Message-ID: <003001c2f6ce$c501ca80$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] 
>On Behalf Of Jeremy
>Sent: Sunday, March 30, 2003 2:13 AM
>To: R-help at stat.math.ethz.ch
>Subject: [R] Question on Plotting
>
>
>I am looking to plot confidence and prediction interval bands for a
specfic set of data.  
>What R commands would i use to plot this data?

There is an example in ?predict.lm (which you should read), but it
does not include the scatterplot. So if you want the data points
themselves included in your graph, you can use something like the
following:

# Generate x and y
x <- rnorm(50)
y <- x + rnorm(50)

# Create model
mod <- lm(y ~ x)

# Generate new dataframe containing prediction data
# of 50 points over the range of x values
# This does two things:
# 1. It limits the prediction based values of x to 
# the range of known data
# 2. It keeps the values of x in numeric sequence for
# matlines()
# Be sure that the new data frame colnames are the same
# as your model terms
new <- data.frame(x = seq(min(x), max(x),
                      by = (max(x) - min(x)) / 49))

# Now create matrix of fitted values and upper and lower limits
# for prediction bands and confidence bands
pred.lim <- predict(mod, newdata = new, interval = "prediction")
conf.lim <- predict(mod, newdata = new, interval = "confidence")

# Generate plot, setting y axis to include range of 
# prediction values
plot(x, y, xlab = "x", ylab = "y", col = "black", bg = "red", 
     pch = 21, las = 1, cex = 0.9, ylim = range(y, pred.lim, na.rm =
TRUE))

# Use matlines() to draw fitted line and pred/conf bands
matlines(new$x, pred.lim, lty = c(1, 4, 4), 
         lwd = c(2, 1, 1), col = c("black", "red", "red"))

matlines(new$x, conf.lim, lty = c(1, 3, 3), 
         lwd = c(2, 1, 1), col = c("black", "darkgreen", "darkgreen"))



Hope that helps,

Marc Schwartz


From eglen at pcg.wustl.edu  Sun Mar 30 20:11:41 2003
From: eglen at pcg.wustl.edu (Stephen Eglen)
Date: Sun, 30 Mar 2003 12:11:41 -0600
Subject: [R] Suggestion: add log argument to stripchart
Message-ID: <16007.13149.387846.821040@mosaics.wustl.edu>

Hello,

I frequently use stripchart to summarise data.  Recently I wished to
plot a stripchart on a log scale, so modified stripchart locally.  The
change is small, just adding log="" to the function call and
then changing line 42 of src/library/base/R/stripchart.R from:

    plot(xlim, ylim, type="n", ann=FALSE, axes=FALSE)

to: 

    plot(xlim, ylim, type="n", ann=FALSE, axes=FALSE, log=log)

Could I request this be added?  If so, I'd be happy to send a patch
for the .R and .Rd files.  boxplot() already offers the log argument,
so I hope this is a reasonable and useful request.

Stephen


From philippe.hupe at wanadoo.fr  Sun Mar 30 21:17:14 2003
From: philippe.hupe at wanadoo.fr (Philippe =?iso-8859-1?q?Hup=E9?=)
Date: Sun, 30 Mar 2003 20:17:14 +0100
Subject: [R] Fortran compilation problem
Message-ID: <200303302017.14635.philippe.hupe@wanadoo.fr>

Hello,

I have problem when i am trying to install a package containing fortran source 
code. I give below the result of installation for one package (I have always 
the same message : /usr/bin/ld: can not find  -lreadline):

g77 -mieee-fp  -fPIC  -g -O2 -c akima.new.f -o akima.new.o
g77 -mieee-fp  -fPIC  -g -O2 -c idbvip.f -o idbvip.o
g77 -mieee-fp  -fPIC  -g -O2 -c idcldp.f -o idcldp.o
g77 -mieee-fp  -fPIC  -g -O2 -c idgrid.f -o idgrid.o
g77 -mieee-fp  -fPIC  -g -O2 -c idlctn.f -o idlctn.o
g77 -mieee-fp  -fPIC  -g -O2 -c idpdrv.f -o idpdrv.o
g77 -mieee-fp  -fPIC  -g -O2 -c idptip.f -o idptip.o
g77 -mieee-fp  -fPIC  -g -O2 -c idptli.f -o idptli.o
g77 -mieee-fp  -fPIC  -g -O2 -c idsfft.f -o idsfft.o
g77 -mieee-fp  -fPIC  -g -O2 -c idtang.f -o idtang.o
g77 -mieee-fp  -fPIC  -g -O2 -c idxchg.f -o idxchg.o
g77 -mieee-fp  -fPIC  -g -O2 -c tripack.f -o tripack.o
g77 -mieee-fp  -fPIC  -g -O2 -c ttidbs.f -o ttidbs.o
gcc -shared  -o akima.so akima.new.o idbvip.o idcldp.o idgrid.o idlctn.o 
idpdrv.o idptip.o idptli.o idsfft.o idtang.o idxchg.o tripack.o ttidbs.o  
-L/usr/lib/gcc-lib/i386-linux/2.95.4 -lreadline -ldl -lncurses -lg2c-pic -lm 
-L/usr/lib/R/bin -lR
/usr/bin/ld: can not find  -lreadline
collect2: ld returned 1 exit status
make: *** [akima.so] Erreur 1
ERROR: compilation failed for package 'akima'

Thanks in advance.


From dvumani at hotmail.com  Sun Mar 30 20:29:58 2003
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Sun, 30 Mar 2003 18:29:58 +0000
Subject: [R] memory problems in NLME
Message-ID: <F1336HHGNZ4mF1IT18o000002bf@hotmail.com>

Dear R-Users


I am trying to fit a random coeficient model with about 30 covariates with a 
random intercept and one random slope. The data set has 65000 observations, 
and whenever I use LME I get the message that all memory has been used.

I was wondering whether there is a more efficient way fo fitting the model.

OS:          Windows 2000
R version:   R 1.6.2
Memory:      128Mb
Free HD:     <>11Gb

Looking forward to you help as always.


Vumani Dlamini


From TyagiAnupam at aol.com  Sun Mar 30 20:42:31 2003
From: TyagiAnupam at aol.com (AT)
Date: Sun, 30 Mar 2003 13:42:31 -0500
Subject: [R] Scripting with an external editor
In-Reply-To: <20030330113939.UWBN27552.mta09.mail.mel.aone.net.au@there>
References: <20030330113939.UWBN27552.mta09.mail.mel.aone.net.au@there>
Message-ID: <3E873A96.9090905@aol.com>

An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20030330/f608b3e0/attachment.html

From ripley at stats.ox.ac.uk  Sun Mar 30 20:47:32 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 30 Mar 2003 19:47:32 +0100 (BST)
Subject: [R] Two bugs in TS package?
In-Reply-To: <001101c2f6b5$7763ae10$34466093@macris.com>
Message-ID: <Pine.LNX.4.44.0303301936140.16430-100000@gannet.stats>

On Sun, 30 Mar 2003, Agustin Alonso wrote:

> I am working with the Time Series package, and I have found that the 
results returned by the following two funtions are not what it 
should be expected.
> 
> 1.- The function tsp(name of a series) does not report the start, deltat and frequency of the series. For example, for the series: deaths, from library MASS, 
>     tsp(deaths) returns: 1974.000 1979.917 12.000, but the expected return should be: 1974 0.083333 12.

tsp is *not* in the TS package, and it is documented in help(tsp) to give
`the start time in time units, the end time and the frequency.'

Who `expected' the values you gave, and why `should' they be expected to
differ from the documentation?

> 2.- The function Box.test does not report the correct degrees of 
freedom. The reported df are the same as the number of lags given by the user.

What in your opinion is the correct number of df, and what is your
reference?  Have you checked the references given on the help page?

> Would you, please, verify if I am right?

Why not read the documentation rather than asking R-help to do it for you?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sun Mar 30 20:56:20 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 30 Mar 2003 19:56:20 +0100 (BST)
Subject: [R] Scripting with an external editor
In-Reply-To: <20030330113939.UWBN27552.mta09.mail.mel.aone.net.au@there>
Message-ID: <Pine.LNX.4.44.0303301948120.16430-100000@gannet.stats>

On Sun, 30 Mar 2003, Jim Lemon wrote:

> If my trawling through the "connections" code is correct, a pipe 
> connection is designed to read to EOF before returning its input to the 
> parsing function. Blocking is not an option with this type of connection. 

Not so: it is parse(file=) that is designed to read to EOF.  pipe() does 
nothing, but reading from a pipe reads connections however much is asked 
for.  If you want non-blocking, use a socket or fifo.

> As I do not know how to spoof an EOF on an open pipe, it looks like I 
> would have to rewrite 3 or 4 fairly low level functions to return input on 
> EOL.
>
> My impression is that this is the wrong way to go about this. After all, I 
> am sure that something similar is already being done using the present 
> connection functions. Any suggestions as to where else I might look would 
> be greatly appreciated.

I have already sent you such a reply, on Monday 24th.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sun Mar 30 20:59:15 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 30 Mar 2003 19:59:15 +0100 (BST)
Subject: [R] Suggestion: add log argument to stripchart
In-Reply-To: <16007.13149.387846.821040@mosaics.wustl.edu>
Message-ID: <Pine.LNX.4.44.0303301957290.16430-100000@gannet.stats>

FYI, feature-freeze on R 1.7.0 was last Wednesday, so your timing is
singularly unfortunate.

Please send this as a wishlist item to R-bugs, as otherwise it is likely 
to get lost.

On Sun, 30 Mar 2003, Stephen Eglen wrote:

> Hello,
> 
> I frequently use stripchart to summarise data.  Recently I wished to
> plot a stripchart on a log scale, so modified stripchart locally.  The
> change is small, just adding log="" to the function call and
> then changing line 42 of src/library/base/R/stripchart.R from:
> 
>     plot(xlim, ylim, type="n", ann=FALSE, axes=FALSE)
> 
> to: 
> 
>     plot(xlim, ylim, type="n", ann=FALSE, axes=FALSE, log=log)
> 
> Could I request this be added?  If so, I'd be happy to send a patch
> for the .R and .Rd files.  boxplot() already offers the log argument,
> so I hope this is a reasonable and useful request.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sun Mar 30 21:04:20 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 30 Mar 2003 20:04:20 +0100 (BST)
Subject: [R] Fortran compilation problem
In-Reply-To: <200303302017.14635.philippe.hupe@wanadoo.fr>
Message-ID: <Pine.LNX.4.44.0303302000160.16430-100000@gannet.stats>

You have not given us even minimal information (R version, platform, etc).

My guess is that you installed R from an RPM, and you do not have
(something like) readline-devel installed.  However, this is easily fixed
by editing R_HOME/etc/Makeconf and removing '-lreadline -ldl -lncurses'
from the FLIBS macro.

This has come up many times, so a search of the archives should be
revealing.

On Sun, 30 Mar 2003, Philippe Hup? wrote:

> Hello,
> 
> I have problem when i am trying to install a package containing fortran source 
> code. I give below the result of installation for one package (I have always 
> the same message : /usr/bin/ld: can not find  -lreadline):
> 
> g77 -mieee-fp  -fPIC  -g -O2 -c akima.new.f -o akima.new.o
> g77 -mieee-fp  -fPIC  -g -O2 -c idbvip.f -o idbvip.o
> g77 -mieee-fp  -fPIC  -g -O2 -c idcldp.f -o idcldp.o
> g77 -mieee-fp  -fPIC  -g -O2 -c idgrid.f -o idgrid.o
> g77 -mieee-fp  -fPIC  -g -O2 -c idlctn.f -o idlctn.o
> g77 -mieee-fp  -fPIC  -g -O2 -c idpdrv.f -o idpdrv.o
> g77 -mieee-fp  -fPIC  -g -O2 -c idptip.f -o idptip.o
> g77 -mieee-fp  -fPIC  -g -O2 -c idptli.f -o idptli.o
> g77 -mieee-fp  -fPIC  -g -O2 -c idsfft.f -o idsfft.o
> g77 -mieee-fp  -fPIC  -g -O2 -c idtang.f -o idtang.o
> g77 -mieee-fp  -fPIC  -g -O2 -c idxchg.f -o idxchg.o
> g77 -mieee-fp  -fPIC  -g -O2 -c tripack.f -o tripack.o
> g77 -mieee-fp  -fPIC  -g -O2 -c ttidbs.f -o ttidbs.o
> gcc -shared  -o akima.so akima.new.o idbvip.o idcldp.o idgrid.o idlctn.o 
> idpdrv.o idptip.o idptli.o idsfft.o idtang.o idxchg.o tripack.o ttidbs.o  
> -L/usr/lib/gcc-lib/i386-linux/2.95.4 -lreadline -ldl -lncurses -lg2c-pic -lm 
> -L/usr/lib/R/bin -lR
> /usr/bin/ld: can not find  -lreadline
> collect2: ld returned 1 exit status
> make: *** [akima.so] Erreur 1
> ERROR: compilation failed for package 'akima'


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From philippe.hupe at wanadoo.fr  Sun Mar 30 22:16:56 2003
From: philippe.hupe at wanadoo.fr (Philippe =?iso-8859-1?q?Hup=E9?=)
Date: Sun, 30 Mar 2003 21:16:56 +0100
Subject: [R] Fortran compilation problem
In-Reply-To: <Pine.LNX.4.44.0303302000160.16430-100000@gannet.stats>
References: <Pine.LNX.4.44.0303302000160.16430-100000@gannet.stats>
Message-ID: <200303302116.56066.philippe.hupe@wanadoo.fr>

I have the 1.6.2 version installed on Debian Linux woody (deb packages have 
been downloading from CRAN)

Le Dimanche 30 Mars 2003 20:04, ripley at stats.ox.ac.uk a ?crit :
> You have not given us even minimal information (R version, platform, etc).
>
> My guess is that you installed R from an RPM, and you do not have
> (something like) readline-devel installed.  However, this is easily fixed
> by editing R_HOME/etc/Makeconf and removing '-lreadline -ldl -lncurses'
> from the FLIBS macro.
>
> This has come up many times, so a search of the archives should be
> revealing.
>
> On Sun, 30 Mar 2003, Philippe Hup? wrote:
> > Hello,
> >
> > I have problem when i am trying to install a package containing fortran
> > source code. I give below the result of installation for one package (I
> > have always the same message : /usr/bin/ld: can not find  -lreadline):
> >
> > g77 -mieee-fp  -fPIC  -g -O2 -c akima.new.f -o akima.new.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c idbvip.f -o idbvip.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c idcldp.f -o idcldp.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c idgrid.f -o idgrid.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c idlctn.f -o idlctn.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c idpdrv.f -o idpdrv.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c idptip.f -o idptip.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c idptli.f -o idptli.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c idsfft.f -o idsfft.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c idtang.f -o idtang.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c idxchg.f -o idxchg.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c tripack.f -o tripack.o
> > g77 -mieee-fp  -fPIC  -g -O2 -c ttidbs.f -o ttidbs.o
> > gcc -shared  -o akima.so akima.new.o idbvip.o idcldp.o idgrid.o idlctn.o
> > idpdrv.o idptip.o idptli.o idsfft.o idtang.o idxchg.o tripack.o ttidbs.o
> > -L/usr/lib/gcc-lib/i386-linux/2.95.4 -lreadline -ldl -lncurses -lg2c-pic
> > -lm -L/usr/lib/R/bin -lR
> > /usr/bin/ld: can not find  -lreadline
> > collect2: ld returned 1 exit status
> > make: *** [akima.so] Erreur 1
> > ERROR: compilation failed for package 'akima'


From Philippe.Hupe at curie.fr  Sun Mar 30 22:57:32 2003
From: Philippe.Hupe at curie.fr (Philippe =?iso-8859-1?q?Hup=E9?=)
Date: Sun, 30 Mar 2003 21:57:32 +0100
Subject: [R] Fortran compilation problem
In-Reply-To: <200303302116.56066.philippe.hupe@wanadoo.fr>
References: <Pine.LNX.4.44.0303302000160.16430-100000@gannet.stats>
	<200303302116.56066.philippe.hupe@wanadoo.fr>
Message-ID: <200303302157.32026.Philippe.Hupe@curie.fr>

I have installed libreadline4-dev and now it works !!

Le Dimanche 30 Mars 2003 21:16, Philippe Hup? a ?crit :
> I have the 1.6.2 version installed on Debian Linux woody (deb packages have
> been downloading from CRAN)
>
> Le Dimanche 30 Mars 2003 20:04, ripley at stats.ox.ac.uk a ?crit :
> > You have not given us even minimal information (R version, platform,
> > etc).
> >
> > My guess is that you installed R from an RPM, and you do not have
> > (something like) readline-devel installed.  However, this is easily fixed
> > by editing R_HOME/etc/Makeconf and removing '-lreadline -ldl -lncurses'
> > from the FLIBS macro.
> >
> > This has come up many times, so a search of the archives should be
> > revealing.
> >
> > On Sun, 30 Mar 2003, Philippe Hup? wrote:
> > > Hello,
> > >
> > > I have problem when i am trying to install a package containing fortran
> > > source code. I give below the result of installation for one package (I
> > > have always the same message : /usr/bin/ld: can not find  -lreadline):
> > >
> > > g77 -mieee-fp  -fPIC  -g -O2 -c akima.new.f -o akima.new.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idbvip.f -o idbvip.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idcldp.f -o idcldp.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idgrid.f -o idgrid.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idlctn.f -o idlctn.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idpdrv.f -o idpdrv.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idptip.f -o idptip.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idptli.f -o idptli.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idsfft.f -o idsfft.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idtang.f -o idtang.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idxchg.f -o idxchg.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c tripack.f -o tripack.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c ttidbs.f -o ttidbs.o
> > > gcc -shared  -o akima.so akima.new.o idbvip.o idcldp.o idgrid.o
> > > idlctn.o idpdrv.o idptip.o idptli.o idsfft.o idtang.o idxchg.o
> > > tripack.o ttidbs.o -L/usr/lib/gcc-lib/i386-linux/2.95.4 -lreadline -ldl
> > > -lncurses -lg2c-pic -lm -L/usr/lib/R/bin -lR
> > > /usr/bin/ld: can not find  -lreadline
> > > collect2: ld returned 1 exit status
> > > make: *** [akima.so] Erreur 1
> > > ERROR: compilation failed for package 'akima'
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From bates at stat.wisc.edu  Sun Mar 30 22:13:46 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 30 Mar 2003 14:13:46 -0600
Subject: [R] memory problems in NLME
In-Reply-To: <F1336HHGNZ4mF1IT18o000002bf@hotmail.com>
References: <F1336HHGNZ4mF1IT18o000002bf@hotmail.com>
Message-ID: <6rd6k8txxh.fsf@bates4.stat.wisc.edu>

"Vumani Dlamini" <dvumani at hotmail.com> writes:

> I am trying to fit a random coeficient model with about 30 covariates
> with a random intercept and one random slope. The data set has 65000
> observations, and whenever I use LME I get the message that all memory
> has been used.

Do you know what the number of columns in the model matrix for the
fixed-effects will be?  You say you have 30 covariates but if some of
those are factors or if you take powers of continuous covariates or
interactions between terms then the number of columns in the model
matrix can be much larger than 30.  Given the dimensions you mention
it seems that the model matrix for the fixed effects is nearly 16 MB
in size or larger.  Evaluation of the log-likelihood requires 3 or 4
copies of matrices like this plus the original data frame and the
memory being used by other R objects.

> I was wondering whether there is a more efficient way fo fitting the model.

Saikat DebRoy and I are working on a new package for lme and related
functions using S4 classes.  That package, which we plan to release in
a 'snapshot' form shortly after R-1.7.0 is released (scheduled for April 16,
2003), controls the number of copies of the model matrices being
created.

I can run this example on the new package and the old package and
provide comparisons if you wish.  I use a machine with 1 GB of memory
which should be enough. Please contact me off-list.


From edd at debian.org  Sun Mar 30 22:19:00 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 30 Mar 2003 14:19:00 -0600
Subject: [R] Fortran compilation problem
In-Reply-To: <200303302116.56066.philippe.hupe@wanadoo.fr>
References: <Pine.LNX.4.44.0303302000160.16430-100000@gannet.stats>
	<200303302116.56066.philippe.hupe@wanadoo.fr>
Message-ID: <20030330201859.GA29942@sonny.eddelbuettel.com>

On Sun, Mar 30, 2003 at 09:16:56PM +0100, Philippe Hup? wrote:
> I have the 1.6.2 version installed on Debian Linux woody (deb packages have 
> been downloading from CRAN)

Please install r-base-dev, which via its Depends ensures that you get what
is required for the most common situations:

   Package: r-base-dev
   [...]
   Depends: r-base-core, blas-dev (>= 1.0-9), build-essential, g77 | \
   g77-3.0 | f2c | fortran77-compiler , gcc | gcc-3.0 | c-compiler, \
   g++ | g++-3.0, libncurses5-dev, libreadline4-dev

In particular, this ensure presence of compilers for C, C++, and Fortan as
well as header file packages for curses and readline.

Dirk

> Le Dimanche 30 Mars 2003 20:04, ripley at stats.ox.ac.uk a ?crit :
> > You have not given us even minimal information (R version, platform, etc).
> >
> > My guess is that you installed R from an RPM, and you do not have
> > (something like) readline-devel installed.  However, this is easily fixed
> > by editing R_HOME/etc/Makeconf and removing '-lreadline -ldl -lncurses'
> > from the FLIBS macro.
> >
> > This has come up many times, so a search of the archives should be
> > revealing.
> >
> > On Sun, 30 Mar 2003, Philippe Hup? wrote:
> > > Hello,
> > >
> > > I have problem when i am trying to install a package containing fortran
> > > source code. I give below the result of installation for one package (I
> > > have always the same message : /usr/bin/ld: can not find  -lreadline):
> > >
> > > g77 -mieee-fp  -fPIC  -g -O2 -c akima.new.f -o akima.new.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idbvip.f -o idbvip.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idcldp.f -o idcldp.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idgrid.f -o idgrid.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idlctn.f -o idlctn.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idpdrv.f -o idpdrv.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idptip.f -o idptip.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idptli.f -o idptli.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idsfft.f -o idsfft.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idtang.f -o idtang.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c idxchg.f -o idxchg.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c tripack.f -o tripack.o
> > > g77 -mieee-fp  -fPIC  -g -O2 -c ttidbs.f -o ttidbs.o
> > > gcc -shared  -o akima.so akima.new.o idbvip.o idcldp.o idgrid.o idlctn.o
> > > idpdrv.o idptip.o idptli.o idsfft.o idtang.o idxchg.o tripack.o ttidbs.o
> > > -L/usr/lib/gcc-lib/i386-linux/2.95.4 -lreadline -ldl -lncurses -lg2c-pic
> > > -lm -L/usr/lib/R/bin -lR
> > > /usr/bin/ld: can not find  -lreadline
> > > collect2: ld returned 1 exit status
> > > make: *** [akima.so] Erreur 1
> > > ERROR: compilation failed for package 'akima'
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Wishful thinking can dominate much of the work of a profession for a decade,
but not indefinitely.   -- Robert Shiller, on Efficient Markets models, 2002


From bates at stat.wisc.edu  Sun Mar 30 22:32:59 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 30 Mar 2003 14:32:59 -0600
Subject: [R] Fortran compilation problem
In-Reply-To: <200303302116.56066.philippe.hupe@wanadoo.fr>
References: <Pine.LNX.4.44.0303302000160.16430-100000@gannet.stats>
	<200303302116.56066.philippe.hupe@wanadoo.fr>
Message-ID: <6rvfy0sih0.fsf@bates4.stat.wisc.edu>

Philippe Hup? <philippe.hupe at wanadoo.fr> writes:

> I have the 1.6.2 version installed on Debian Linux woody (deb packages have 
> been downloading from CRAN)

Under Debian you should install the r-base-dev package (also available
on CRAN) if you wish to compile and install R packages with Fortran or
C source code.

The r-base-dev package will require several other packages
 $ dpkg-deb --info r-base-dev_1.6.2-1_all.deb 
 new debian package, version 2.0.
 size 1628 bytes: control archive= 1256 bytes.
    1195 bytes,    25 lines      control              
     269 bytes,     9 lines   *  postinst             #!/bin/sh
     425 bytes,    26 lines   *  preinst              #!/bin/sh
     202 bytes,     7 lines   *  prerm                #!/bin/sh
 Package: r-base-dev
 Version: 1.6.2-1
 Section: devel
 Priority: optional
 Architecture: all
 Depends: r-base-core, blas-dev (>= 1.0-9), build-essential, g77 | g77-3.0 | f2c | fortran77-compiler , gcc | gcc-3.0 | c-compiler, g++ | g++-3.0, libncurses5-dev, libreadline4-dev
 Installed-Size: 32
 Maintainer: Dirk Eddelbuettel <edd at debian.org>
 Source: r-base
 Description: GNU R installation of auxiliary GNU R packages
  R is `GNU S' - A language and environment for statistical computing
  and graphics. R is similar to the award-winning S system, which was
  developed at Bell Laboratories by John Chambers et al. It provides a
  wide variety of statistical and graphical techniques (linear and
  nonlinear modelling, statistical tests, time series analysis,
  classification, clustering, ...).
  .
  R is designed as a true computer language with control-flow
  constructions for iteration and alternation, and it allows users to
  add additional functionality by defining new functions. For
  computationally intensive tasks, C, C++ and Fortran code can be
  linked and called at run time.
  .
  This packages ensures that other Debian packages needed for installation of
  some auxiliary R packages are installed.


From ndesta at vt.edu  Sun Mar 30 22:49:51 2003
From: ndesta at vt.edu (ndesta)
Date: Sun, 30 Mar 2003 15:49:51 -0500
Subject: [R] problems with read.table in windows
Message-ID: <3E891D2E@zathras>

I was wondering if anyone can help me with  read.table.  I have been trying to 
use it to read a txt file that I put in my current working directory.  It just 
wont get it.  I keep getting the error that that the new name I assigned to 
the file imorted is not found.

Thanks,
Nardos Desta


From chrysopa at insecta.ufv.br  Sun Mar 30 23:08:57 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Sun, 30 Mar 2003 18:08:57 -0300
Subject: [R] Problem to install RMySQL
Message-ID: <200303301808.58494.chrysopa@insecta.ufv.br>

Hi,

I try to update my RMySQL but it dont work.

Creating a new generic function for "print" in package 
RMySQL 
[1] "print"
Error in getProperties(ClassDef) : "slots" is not a valid slot for this object 
(or was mistakenly deleted)
Execution halted
ERROR: execution of package source for 'RMySQL' failed

MySQL 3.23.52

Thanks
Ronaldo
-- 
FORTUNE'S RULES TO LIVE BY: #2
	Never goose a wolverine.
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From ripley at stats.ox.ac.uk  Sun Mar 30 23:21:20 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 30 Mar 2003 22:21:20 +0100 (BST)
Subject: [R] problems with read.table in windows
In-Reply-To: <3E891D2E@zathras>
Message-ID: <Pine.LNX.4.44.0303302220350.16749-100000@gannet.stats>

Please show us exactly what you did: or see the R Data Import/Export 
manual.

On Sun, 30 Mar 2003, ndesta wrote:

> I was wondering if anyone can help me with  read.table.  I have been trying to 
> use it to read a txt file that I put in my current working directory.  It just 
> wont get it.  I keep getting the error that that the new name I assigned to 
> the file imorted is not found.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From upton at mitre.org  Sun Mar 30 23:23:11 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Sun, 30 Mar 2003 16:23:11 -0500
Subject: [R] problems with read.table in windows
References: <3E891D2E@zathras>
Message-ID: <3E87603E.DC1DB54F@mitre.org>

Nardos,

First, have you looked at the documentation for read.table, i.e., ?read.table

Second, have you looked at the R import /export manual listed under the help menu?

If so, then what parts of those instructions are not clear to you? Have you done a
dir() command from the prompt to ensure you are in the same directory as the file
you are trying to read? If all that is true, what is the command you are using,
and what is the exact error message you are getting?

This info will help us help you.

steve

ndesta wrote:

> I was wondering if anyone can help me with  read.table.  I have been trying to
> use it to read a txt file that I put in my current working directory.  It just
> wont get it.  I keep getting the error that that the new name I assigned to
> the file imorted is not found.
>
> Thanks,
> Nardos Desta
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Sun Mar 30 23:23:42 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 30 Mar 2003 22:23:42 +0100 (BST)
Subject: [R] Problem to install RMySQL
In-Reply-To: <200303301808.58494.chrysopa@insecta.ufv.br>
Message-ID: <Pine.LNX.4.44.0303302221500.16749-100000@gannet.stats>

We need to know

- your platform
- your version of R
- your version of DBI
- your version of RMySQL

but *not* the version of MySQL!

My guess is that the version of R is the problem.

On Sun, 30 Mar 2003, Ronaldo Reis Jr. wrote:

> I try to update my RMySQL but it dont work.
> 
> Creating a new generic function for "print" in package 
> RMySQL 
> [1] "print"
> Error in getProperties(ClassDef) : "slots" is not a valid slot for this object 
> (or was mistakenly deleted)
> Execution halted
> ERROR: execution of package source for 'RMySQL' failed
> 
> MySQL 3.23.52

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From peter at esb.ucp.pt  Sun Mar 30 23:30:27 2003
From: peter at esb.ucp.pt (Peter Ho)
Date: Sun, 30 Mar 2003 22:30:27 +0100
Subject: [R] Lattice: Saving multiple plots
Message-ID: <3E8761F3.2030206@esb.ucp.pt>

Hi  lattice users,

Is there a way to automatically save trellis plots , when "layout" is 
used to produce graphs on more than one page (graph window). In the 
example below, I have 4 graphs on each  of 4 pages. I want to save each 
 page separately.

######
splom(~final.princomp.pc.scores.five[1:3]|Syrup.time*Massequite.temp, 
groups=Batch.number,data= final.princomp.pc.scores.five,
panel = panel.superpose,
key = list(title = "Batches",
                  points = list(pch = super.sym$pch[1:14],
                 col = super.sym$col[1:14]),
                 text = 
list(c("1","2","3","4","5","6","7","8","9","10","11","12","13","14")),
            columns=7),aspect=1,layout = c(2,2,4))
#####

With only one page of graphs I would normally use the following script 
in the beginning.For example:

#####
jpeg(file="graph1.jpeg", width=960, height=960, quality=100)
#####

Is there a similar way to save these graphs?

Thanks in advance.

Peter


From bates at stat.wisc.edu  Sun Mar 30 23:37:11 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 30 Mar 2003 15:37:11 -0600
Subject: [R] problems with read.table in windows
In-Reply-To: <3E891D2E@zathras>
References: <3E891D2E@zathras>
Message-ID: <6ry92wr0xk.fsf@bates4.stat.wisc.edu>

ndesta <ndesta at vt.edu> writes:

> I was wondering if anyone can help me with read.table.  I have been
> trying to use it to read a txt file that I put in my current working
> directory.  It just wont get it.  I keep getting the error that that
> the new name I assigned to the file imorted is not found.
> 
> Thanks,
> Nardos Desta

If you are running Rgui try

mydata = read.table(file.choose())

which will bring up a chooser panel for you to click on the name of
the file that you want.


From s.mcclatchie at niwa.co.nz  Sun Mar 30 23:56:16 2003
From: s.mcclatchie at niwa.co.nz (Sam McClatchie)
Date: Mon, 31 Mar 2003 09:56:16 +1200
Subject: [R] r-help: mozilla and R -- again 
Message-ID: <3E876800.3000907@niwa.cri.nz>

System info:
Mandrake 9.0
R Version 1.6.1
ESS 5.1.21
Emacs 21.2.1
-------------------
-----Original Message-----
 > >From: r-help-bounces at stat.math.ethz.ch
 > >[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Anne York
 > >Sent: Thursday, March 27, 2003 3:52 PM
 > >To: Help R
 > >Subject: [R] mozilla and R -- again
 > >
 > >
 > >I noticed last week that when using mozilla (both 1.2 and 1.3)
 > >as  the help browser in R, it exhibits the following behavior:
 > >
 > >1. assuming the browser is running go to the help -> "search
 > >engine and key words"
 > >
 > >2. enter a string, say "plot"
 > >
 > >3. when the "search results" are displayed, click on
 > >something, say "abline"
 > >
 > >4. go back to the search results using the browser "Back" button
 > >
 > >5. click on something else, eg, "arrows"
 > >
 > >Nothing happens.  I get the same results with mozilla 1.2 and
 > >1.3 running R 1.6.2 in both RH 8.0 and Windows 2000.
 > >
 > >Seems like the links just die. I'm wondering if this is this
 > >simply a mozilla issue as browsers work fine with R.  Or
 > >perhaps some of the R gurus might have some idea if mozilla
 > >can be configured differently to work better with R?
 > >

Hi

Yes, I got the same result with Mozilla 1.1
Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.1) Gecko/20020826
but how serious is the inconvenience? After clicking on 'arrows' and 
going nowhere, it is a matter of a second or two to back out to the 
search panel, type in arrows and you are there.

OK, it's not perfect, but who is?

Sam
-- 
Sam McClatchie, Research scientist (fisheries acoustics))))))))))
NIWA (National Institute of Water & Atmospheric Research Ltd)
PO Box 14 901, Kilbirnie, Wellington, New Zealand
s.mcclatchie at niwa.cri.nz
Research home page <http://www.smcc.150m.com/>
                       /\
            >><xX(&>
                    /// \\\
                   //// \\\\
                  ///  <%)Xx><<
                 /////  \\\\\\
           ><(((@>
     ><(((%>     ..>><xX(?>O<?)Xx><<


From bojaniss at poczta.onet.pl  Mon Mar 31 02:08:11 2003
From: bojaniss at poczta.onet.pl (Michal Bojanowski)
Date: Mon, 31 Mar 2003 02:08:11 +0200
Subject: [R] fitted() and loglm()
Message-ID: <15815194135.20030331020811@poczta.onet.pl>

Hello,

I encountered some difficulities using loglm() from MASS package. I
had to fit several (about 20) models to the same dataset and than
compare the fitted values. Each time a call to loglm() looks like

loglm(freq ~ x + y + y*z , data=d)

where d is a data.frame containing a bunch of factors x, y, z ...
as well as a vector of frequencies (freq).

For each created model object somewhere later I used fitted() to
obtain fitted values. The result returned was always an array.
Unfortunately for different models its structure (i.e. dim attribute)
is different (probably because of different ordering of the factors in
the model formulas). That makes any calculations on those arrays very
tedious.

Actually I would expect fitted(loglm(freq ~ x)) to return a vector and
fitted(loglm(~ x)) to return an array. Just to preserve the structure
of entered observed frequencies. Correct me if I'm wrong.

Is there a good remedy for the problem above apart from comparing array
structures ,,by hand'' and than using aperm() to make all of them
comformable?

I would be very gratefull for some hints. Thank you in advance for
your time.



Micha?




~,~`~,~`~,~`~,~`~,~`~,~
Micha? Bojanowski
bojaniss at poczta.onet.pl


From ceciliashiraiwa at ig.com.br  Mon Mar 31 02:10:52 2003
From: ceciliashiraiwa at ig.com.br (ceciliashiraiwa@ig.com.br)
Date: Sun, 30 Mar 2003 21:10:52 -0300
Subject: [R] Windows and Linux version
Message-ID: <200303310011.h2V0B2GM006489@hypatia.math.ethz.ch>

Hi, 

I would like to know if my files saved on R windows version will run 
normally on Linux version? 

Thanks 
Ceclia 

_________________________________________________________
Voce quer um iGMail protegido contra vrus e spams? 
Clique aqui: http://www.igmailseguro.ig.com.br


From krcabrer at epm.net.co  Mon Mar 31 02:47:34 2003
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Sun, 30 Mar 2003 19:47:34 -0500
Subject: [R] Windows and Linux version
References: <200303310011.h2V0B2GM006489@hypatia.math.ethz.ch>
Message-ID: <3E879026.6010503@epm.net.co>

If you are asking about .Rdata files, the answer is yes...
I do that several times and it works without any problem.
The .Rhistory file is an ASCII file, so, no problem...

Best Regards
Saludos desde Colombia

Kenneth

ceciliashiraiwa at ig.com.br wrote:

>Hi, 
>
>I would like to know if my files saved on R windows version will run 
>normally on Linux version? 
>
>Thanks 
>Cec?lia 
>
>_________________________________________________________
>Voce quer um iGMail protegido contra v?rus e spams? 
>Clique aqui: http://www.igmailseguro.ig.com.br
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>  
>

-- 
Kenneth Roy Cabrera Torres
Celular +57 (315) 405 9339


From r.hankin at auckland.ac.nz  Mon Mar 31 06:00:23 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Mon, 31 Mar 2003 16:00:23 +1200
Subject: [R] integer overflow error problem 
Message-ID: <200303310400.h2V40NGA001064@r.hankin.sges.auckland.ac.nz>

Hi List

Try the following simple set of functions (R-1.6.1):

 square <- function(x){x*x}
 cube <- function(x) {x*x*x}
 f1 <- function(x){square(x)*(x+1)}
 f2 <- function(x){square(x)+cube(x)}
 error <- function(x){f1(x)-f2(x)}

[see how f1() and f2() are algebraically identical].  Then:

R>  error(cube(20))
[1] 0
> 

no problem.   Then:

R>  error(cube(1:20))
 [1]  0  0  0  0  0  0  0  0  0  0 NA NA NA NA NA NA NA NA NA NA
Warning message: 
NAs produced by integer overflow in: x * x * x 


See how error() fails for the vector but not for the single number
argument.  Is R being reasonable here?








-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042


From deepayan at stat.wisc.edu  Mon Mar 31 06:46:09 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 30 Mar 2003 22:46:09 -0600
Subject: [R] Lattice: Saving multiple plots
In-Reply-To: <3E8761F3.2030206@esb.ucp.pt>
References: <3E8761F3.2030206@esb.ucp.pt>
Message-ID: <200303302246.09145.deepayan@stat.wisc.edu>

On Sunday 30 March 2003 03:30 pm, Peter Ho wrote:
> Hi  lattice users,
>
> Is there a way to automatically save trellis plots , when "layout" is
> used to produce graphs on more than one page (graph window). In the
> example below, I have 4 graphs on each  of 4 pages. I want to save each
>  page separately.
>
> ######
> splom(~final.princomp.pc.scores.five[1:3]|Syrup.time*Massequite.temp,
> groups=Batch.number,data= final.princomp.pc.scores.five,
> panel = panel.superpose,
> key = list(title = "Batches",
>                   points = list(pch = super.sym$pch[1:14],
>                  col = super.sym$col[1:14]),
>                  text =
> list(c("1","2","3","4","5","6","7","8","9","10","11","12","13","14")),
>             columns=7),aspect=1,layout = c(2,2,4))
> #####
>
> With only one page of graphs I would normally use the following script
> in the beginning.For example:
>
> #####
> jpeg(file="graph1.jpeg", width=960, height=960, quality=100)
> #####
>
> Is there a similar way to save these graphs?

Following documentation in ?jpeg, 

jpeg(file="graph%03d.jpeg", width=960, height=960, quality=100)

would seem to work (creating files graph001.jpeg, graph002.jpeg, etc).

-Deepayan


From akira.onozuka.ao at bayer.co.jp  Mon Mar 31 06:47:01 2003
From: akira.onozuka.ao at bayer.co.jp (akira.onozuka.ao@bayer.co.jp)
Date: Mon, 31 Mar 2003 13:47:01 +0900
Subject: [R] read.table command in Rweb
Message-ID: <OF55F1DFFD.701EEDBB-ON49256CFA.0019301C@jp.bayer.cnb>

Dear Readers,

I amd not so sure if this is the best site to ask this question, but does
anybody know why Rweb can't recognize read.table command?
I installed Rweb on local host machine.

I made this input file as '/tmp/data.txt'.

     a    b    c    d
a    0    1    3    2
b    1    0    1    1
c    3    1    0    2

R can recognaize the following command 1

###command 1###
library(mva)
d<-read.table(file ="/tmp/data.txt")
c<-hclust(as.dist(d),method='average')
plot(c,hang=-1)
################

but, Rweb doesn't responde to this script.
Rweb can recognize command 2

###command 2###
read.csv(file ="/tmp/data.txt", header = T , sep = "\t")
###############

but,
###command 3###
library(mva)
d<-read.csv(file ="/tmp/data.txt", header = T , sep = "\t")
c<-hclust(as.dist(d),method='average')
plot(c,hang=-1)
###############

doesn't seem to be a correct script. So, my question is

(1)Why Rweb can't understand read.table command
(2)Please correct command 3 in right form.


******************************************
Akira Onozuka
Researcher, Bioinformatics
Screening Technology, Research Center Kyoto
Bayer Yakuhin Ltd.
Tel. (0774)75-2458
Fax. (0774)75-2506
E-mail: Akira.Onozuka.AO at bayer.co.jp


From ripley at stats.ox.ac.uk  Mon Mar 31 07:46:45 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 31 Mar 2003 06:46:45 +0100 (BST)
Subject: [R] Lattice: Saving multiple plots
In-Reply-To: <3E8761F3.2030206@esb.ucp.pt>
Message-ID: <Pine.LNX.4.44.0303310643250.1173-100000@gannet.stats>

You can generate plots on multiple jpeg files. See ?jpeg for the format of 
the `file' argument; this happens by default.

However, this is not `saving multiple plots' and that is more difficult.
Remember a lattice plot object is plotted by printing, so you can save the 
object and then open a new device and print it again.

On Sun, 30 Mar 2003, Peter Ho wrote:

> Is there a way to automatically save trellis plots , when "layout" is 
> used to produce graphs on more than one page (graph window). In the 
> example below, I have 4 graphs on each  of 4 pages. I want to save each 
>  page separately.
> 
> ######
> splom(~final.princomp.pc.scores.five[1:3]|Syrup.time*Massequite.temp, 
> groups=Batch.number,data= final.princomp.pc.scores.five,
> panel = panel.superpose,
> key = list(title = "Batches",
>                   points = list(pch = super.sym$pch[1:14],
>                  col = super.sym$col[1:14]),
>                  text = 
> list(c("1","2","3","4","5","6","7","8","9","10","11","12","13","14")),
>             columns=7),aspect=1,layout = c(2,2,4))
> #####
> 
> With only one page of graphs I would normally use the following script 
> in the beginning.For example:
> 
> #####
> jpeg(file="graph1.jpeg", width=960, height=960, quality=100)
> #####
> 
> Is there a similar way to save these graphs?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Mar 31 08:06:36 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 31 Mar 2003 07:06:36 +0100 (BST)
Subject: [R] integer overflow error problem 
In-Reply-To: <200303310400.h2V40NGA001064@r.hankin.sges.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0303310700030.1236-100000@gannet.stats>

On Mon, 31 Mar 2003, Robin Hankin wrote:

> Try the following simple set of functions (R-1.6.1):
> 
>  square <- function(x){x*x}
>  cube <- function(x) {x*x*x}
>  f1 <- function(x){square(x)*(x+1)}
>  f2 <- function(x){square(x)+cube(x)}
>  error <- function(x){f1(x)-f2(x)}
> 
> [see how f1() and f2() are algebraically identical].  Then:
> 
> R>  error(cube(20))
> [1] 0
> > 
> 
> no problem.   Then:
> 
> R>  error(cube(1:20))
>  [1]  0  0  0  0  0  0  0  0  0  0 NA NA NA NA NA NA NA NA NA NA
> Warning message: 
> NAs produced by integer overflow in: x * x * x 
> 
> 
> See how error() fails for the vector but not for the single number
> argument.  Is R being reasonable here?

Yes, but is the user being reasonable here?

20 is double
1:20 is integer.

and if you give an integer argument you get integer arithmetic.
Note that R did not `fail': it returned a sensible answer and gave a 
warning.

Programmers do need to know about representation issues, and this is a 
programming task.  Don't expect computers to be able to hold arbitrarily 
large numbers exactly.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Mon Mar 31 09:12:00 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 31 Mar 2003 09:12:00 +0200
Subject: [R] integer overflow error problem 
In-Reply-To: <200303310400.h2V40NGA001064@r.hankin.sges.auckland.ac.nz>
References: <200303310400.h2V40NGA001064@r.hankin.sges.auckland.ac.nz>
Message-ID: <16007.59968.675563.366830@gargle.gargle.HOWL>

>>>>> "Robin" == Robin Hankin <r.hankin at auckland.ac.nz>
>>>>>     on Mon, 31 Mar 2003 16:00:23 +1200 writes:

    Robin> Hi List Try the following simple set of functions
    Robin> (R-1.6.1):

    Robin>  square <- function(x){x*x} cube <- function(x)
    Robin> {x*x*x} f1 <- function(x){square(x)*(x+1)} f2 <-
    Robin> function(x){square(x)+cube(x)} error <-
    Robin> function(x){f1(x)-f2(x)}

    Robin> [see how f1() and f2() are algebraically identical].
    Robin> Then:

    R> error(cube(20))
    Robin> [1] 0
    >>

    Robin> no problem.  Then:

    R> error(cube(1:20))
    Robin>  [1] 0 0 0 0 0 0 0 0 0 0 NA NA NA NA NA NA NA NA NA
    Robin> NA Warning message: NAs produced by integer overflow
    Robin> in: x * x * x


    Robin> See how error() fails for the vector but not for the
    Robin> single number argument.  Is R being reasonable here?

yes,  `as always' :-)

The clue is:  20 is not integer, but 20:20 or as.integer(20) is

Martin






    Robin> --

    Robin> Robin Hankin, Lecturer, School of Geography and
    Robin> Environmental Science Tamaki Campus Private Bag 92019
    Robin> Auckland New Zealand

    Robin> r.hankin at auckland.ac.nz tel 0064-9-373-7599 x6820;
    Robin> FAX 0064-9-373-7042

    Robin> ______________________________________________
    Robin> R-help at stat.math.ethz.ch mailing list
    Robin> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From gisar at nus.edu.sg  Mon Mar 31 09:30:09 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Mon, 31 Mar 2003 15:30:09 +0800
Subject: [R] SAM: Significance of Microarray Analysis availability in R
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F236@MBXSRV03.stf.nus.edu.sg>

Dear all, 

I have been asked to compare the SAM method on some datasets I have.
Searching the archives and help files for SAM was not fruitful. As I
understand it is available as Excel add-in and not in R. 

I am wondering if anyone has written this (in R or S-PLUS) and would be
willing to share it or at least point me right direction. Thank you. 

Regards, Adai.


From fredrik.lundgren at norrkoping.mail.telia.com  Mon Mar 31 09:46:26 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Mon, 31 Mar 2003 09:46:26 +0200
Subject: [R] "font problems in X11 with linux R"
Message-ID: <200303310946.26447.fredrik.lundgren@norrkoping.mail.telia.com>

Hello,

I'm inexperienced with linux, X11 and R. A font problem have surfaced. When I 
use pairs in John Fox's car library e.g.:

> pairs(cbind(prestige, income, education, women))
Error in text.default(x, y, txt, cex = cex, font = font) : 
        X11 font at size 16 could not be loaded
In addition: Warning message: 
freeing previous text buffer in GText 
> 

Evidently there is some problem with my fonts or their loading in X11.
 
However, I can add text to a plot up to size 24 but not larger - 

"Warning message:
X11 used font size 24 when 30 was requested"

In addition - when i use help.start() within R and choses 
 "Search Engine & Keywords" a window pops up with the following text
in the windowbar: "Netscape:subprocess diagnostics(stdout/stderr)" and the 
following message: "Warning: Cannot convert string 
"-*-helvetica-*-*-*-*-*-*-12-*-*-*-iso8859-1"to type FontsStruct" but 
otherwise help.start with Netscape works OK.

No other problems with fonts have surfaced - for example I can use font size 
16 in StarOffice 6.0 and Xemacs 21.4 without problems. I realize that this is 
more a Linux or X11 than a R question but actually I don't know where to 
turn.
I use SuSE linux 8.1, R 1.62, and Netscape 4.8.
How do I fix this problem?

Sincerely Fredrik Lundgren


From pata at atrey.karlin.mff.cuni.cz  Mon Mar 31 10:05:56 2003
From: pata at atrey.karlin.mff.cuni.cz (Patricia Rexova)
Date: Mon, 31 Mar 2003 10:05:56 +0200 (CEST)
Subject: [R] memory.size problem
Message-ID: <Pine.LNX.4.44.0303310957200.1862-100000@atrey.karlin.mff.cuni.cz>

Hello,
I have this problem:
I want make 2-way anova lm(x~y+z).
x,y,z are vectors of 4268 numbers (numbers 1-15).

R writes me back:
> lm(x~y+z)
Error: cannot allocate vector of size 35677 Kb
In addition: Warning message:
Reached total allocation of 127Mb: see help(memory.size)

I tried to change memory size and object size

> options(memory=1E15)
> options(object.size=5E12)
But this does not help.

Could you help me with the easiest way to deal my problem?
Thanks a lot

Patricia


From ripley at stats.ox.ac.uk  Mon Mar 31 09:45:06 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 31 Mar 2003 08:45:06 +0100 (BST)
Subject: [R] memory.size problem
In-Reply-To: <Pine.LNX.4.44.0303310957200.1862-100000@atrey.karlin.mff.cuni.cz>
Message-ID: <Pine.LNX.4.44.0303310842380.1376-100000@gannet.stats>

On Mon, 31 Mar 2003, Patricia Rexova wrote:

> Hello,
> I have this problem:
> I want make 2-way anova lm(x~y+z).
> x,y,z are vectors of 4268 numbers (numbers 1-15).
> 
> R writes me back:
> > lm(x~y+z)
> Error: cannot allocate vector of size 35677 Kb
> In addition: Warning message:
> Reached total allocation of 127Mb: see help(memory.size)
> 
> I tried to change memory size and object size
> 
> > options(memory=1E15)
> > options(object.size=5E12)
> But this does not help.
> 
> Could you help me with the easiest way to deal my problem?

Yes, follow the instructions: you are using R and not S-PLUS.
Do try help(memory.size) as suggested!  The information is also in the 
rw-FAQ.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From weiss at wiso-r610.wiso.uni-koeln.de  Mon Mar 31 11:22:54 2003
From: weiss at wiso-r610.wiso.uni-koeln.de (Bernd Weiss)
Date: Mon, 31 Mar 2003 11:22:54 +0200
Subject: [R] point-biserial correlation
Message-ID: <3E88250D.12939.8D7ACA@localhost>

Dear list,

has anyone written a package/function in R for computing a point-
biserial resp. biserial correlation?

Thanks in advance

Bernd


From wegmann at biozentrum.uni-wuerzburg.de  Mon Mar 31 11:33:56 2003
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Mon, 31 Mar 2003 11:33:56 +0200
Subject: [R] ccf
Message-ID: <3E880B84.E28E4874@biozentrum.uni-wuerzburg.de>

Hello,

I am looking for a command for cross correlation like ccf but which
computes the cross-correlation of more than two (in my case 1800)
series.

any ideas? thanks a lot in advance, Cheers Martin

--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de


From ripley at stats.ox.ac.uk  Mon Mar 31 11:46:38 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Mon, 31 Mar 2003 10:46:38 +0100 (BST)
Subject: [R] ccf
In-Reply-To: <3E880B84.E28E4874@biozentrum.uni-wuerzburg.de>
Message-ID: <Pine.LNX.4.44.0303311044170.1953-100000@test.stats>

On Mon, 31 Mar 2003, Martin Wegmann wrote:

> Hello,
> 
> I am looking for a command for cross correlation like ccf but which
> computes the cross-correlation of more than two (in my case 1800)
> series.

acf on multiple time series does this.

Note that you can always do it pairwise via ccf.

I very much doubt that the cross-correlations on 1800 series make 
statistical sense, though.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From krcabrer at epm.net.co  Mon Mar 31 13:00:23 2003
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Mon, 31 Mar 2003 06:00:23 -0500
Subject: [R] Three graphs
Message-ID: <3E881FC7.5050103@epm.net.co>

Hi R-users:
How can I obtain 3 graphics in a page but, one on the top and centered, and
the other two in the bottom ?

Thank you for your help

-- 
Kenneth Roy Cabrera Torres
Celular +57 (315) 405 9339


From m.mader at gsf.de  Mon Mar 31 13:25:39 2003
From: m.mader at gsf.de (Michael Mader)
Date: Mon, 31 Mar 2003 13:25:39 +0200
Subject: [R] Three graphs
References: <3E881FC7.5050103@epm.net.co>
Message-ID: <3E8825B3.81FE0F09@gsf.de>

Kenneth Cabrera wrote:

> How can I obtain 3 graphics in a page but, one on the top and centered, and
> the other two in the bottom ?
?par
but probably R-intro is what you need

Cheers

Michael

-- 
Michael T. Mader
Institute for Bioinformatics/MIPS, GSF
Ingolstaedter Landstrasse 1
D-80937 Neuherberg
0049-89-3187-3576
 
In statistics, some people worry about not seeing the forest for the
trees.
I like to look at the bark. (C. R. Blyth, 1967)


From ghosh at science.unitn.it  Mon Mar 31 13:40:23 2003
From: ghosh at science.unitn.it (Ghosh Mini)
Date: Mon, 31 Mar 2003 13:40:23 +0200 (MET DST)
Subject: [R] request
In-Reply-To: <20030325163421.N4227@itc.it>
Message-ID: <Pine.OSF.4.44.0303311328200.24507-100000@omega.science.unitn.it>


Dear all,

Hope you are fine there. I want to know

" Is it possible to treat Day,month and year seperately in a data frame in
R"

Means, suppose I want to take mean of data first by day wise and then by
month. Is it possible using R??

Thanking you,
regards,
mini


From plummer at iarc.fr  Mon Mar 31 14:39:15 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: 31 Mar 2003 14:39:15 +0200
Subject: [R] Three graphs
In-Reply-To: <3E8825B3.81FE0F09@gsf.de>
References: <3E881FC7.5050103@epm.net.co>  <3E8825B3.81FE0F09@gsf.de>
Message-ID: <1049114356.1884.3.camel@xena>

On Mon, 2003-03-31 at 13:25, Michael Mader wrote:
> Kenneth Cabrera wrote:
> 
> > How can I obtain 3 graphics in a page but, one on the top and centered, and
> > the other two in the bottom ?
> ?par
> but probably R-intro is what you need

In this case, I think layout() is required:

layout(mat = matrix(c(1,1,2,3), 2, 2, byrow=TRUE))
layout.show(3)

Or, if you want all three graphics to have the same width:

layout(mat = matrix(c(0,1,1,0,2,2,3,3), nrow=2, ncol=4, byrow=TRUE))
layout.show(3)

Martyn


From david.whiting at ncl.ac.uk  Mon Mar 31 17:20:37 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Mon, 31 Mar 2003 15:20:37 +0000
Subject: [R] Statistical computing
In-Reply-To: <20030329074447.129d3215.fharrell@virginia.edu>
References: <3EB0F3C7@webmail.mcgill.ca>
	<20030328124325.7ee0880b.fharrell@virginia.edu>
	<20030329100858.GA6908@192.168.57.2>
	<20030329074447.129d3215.fharrell@virginia.edu>
Message-ID: <20030331152037.GG28925@192.168.57.2>

On Sat, Mar 29, 2003 at 07:44:47AM -0500, Frank E Harrell Jr wrote:

> David - I am a big fan of Sweave also.  There is some writeup about it
> in one of the documents I referenced.  Next I need to get into MySQL.
> If you stumble across any tutorials for that that are not on
> r-project.org please let me know.  -Frank

Frank, do you mean for SQL in general or specifically related to R
working with SQL/MySQL?  

I think there are many tutorials on SQL and MySQL on the web and the
MySQL manual contains everything you ever wanted to know about MySQL
(and more that you'll probably hope you never want to know about :).
There are tutorials within the manual that I think are well-written
and clear.

For me the only thing I had to think about in putting it together was
when installing unixODBC (on linux) and even that was not too hard.  I
just had to create the .ini files because I had problems with
ODBCConfig.  

If you know a little SQL then the R Data Import/Export manual and the
RODBC help page are probably all you really need.

Dave

-- 
Dave Whiting
Dar es Salaam, Tanzania


From jfox at mcmaster.ca  Mon Mar 31 15:02:23 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 31 Mar 2003 08:02:23 -0500
Subject: [R] "font problems in X11 with linux R"
In-Reply-To: <200303310946.26447.fredrik.lundgren@norrkoping.mail.telia.
 com>
Message-ID: <5.1.0.14.2.20030331075939.01e32df0@mcmail.cis.mcmaster.ca>

Dear Fredrik,

At 09:46 AM 3/31/2003 +0200, Fredrik Lundgren wrote:
>Hello,
>
>I'm inexperienced with linux, X11 and R. A font problem have surfaced. When I
>use pairs in John Fox's car library e.g.:

Please note that the pairs function (as opposed to scatterplot.matrix) is 
not in car, but in the base package. I hope that someone else will be able 
to help with the font problem.

John


-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From mschwartz at medanalytics.com  Mon Mar 31 15:05:17 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 31 Mar 2003 07:05:17 -0600
Subject: [R] "font problems in X11 with linux R"
In-Reply-To: <200303310946.26447.fredrik.lundgren@norrkoping.mail.telia.com>
Message-ID: <009101c2f786$2e0b5c50$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Fredrik
Lundgren
>Sent: Monday, March 31, 2003 1:46 AM
>To: R-help at stat.math.ethz.ch
>Subject: [R] "font problems in X11 with linux R"
>
>
>Hello,
>
>I'm inexperienced with linux, X11 and R. A font problem have 
>surfaced. When I 
>use pairs in John Fox's car library e.g.:
>
>> pairs(cbind(prestige, income, education, women))
>Error in text.default(x, y, txt, cex = cex, font = font) : 
>        X11 font at size 16 could not be loaded
>In addition: Warning message: 
>freeing previous text buffer in GText 
>> 
>
>Evidently there is some problem with my fonts or their loading in
X11.
> 
>However, I can add text to a plot up to size 24 but not larger - 
>
>"Warning message:
>X11 used font size 24 when 30 was requested"
>
>In addition - when i use help.start() within R and choses 
> "Search Engine & Keywords" a window pops up with the 
>following text in the windowbar: "Netscape:subprocess 
>diagnostics(stdout/stderr)" and the 
>following message: "Warning: Cannot convert string 
>"-*-helvetica-*-*-*-*-*-*-12-*-*-*-iso8859-1"to type FontsStruct" but

>otherwise help.start with Netscape works OK.
>
>No other problems with fonts have surfaced - for example I can 
>use font size 
>16 in StarOffice 6.0 and Xemacs 21.4 without problems. I 
>realize that this is 
>more a Linux or X11 than a R question but actually I don't 
>know where to 
>turn.
>I use SuSE linux 8.1, R 1.62, and Netscape 4.8.
>How do I fix this problem?
>
>Sincerely Fredrik Lundgren


It sounds like you might not have scaled versions of your fonts loaded
in /etc/X11/fs/config

Take a look in there for the following lines, depending upon whether
you have 75 or 100 dpi fonts loaded:

/usr/X11R6/lib/X11/fonts/75dpi:unscaled
/usr/X11R6/lib/X11/fonts/100dpi:unscaled

See if there are also the following lines:

/usr/X11R6/lib/X11/fonts/75dpi 
/usr/X11R6/lib/X11/fonts/100dpi 

If one of the second set of lines are not present to correspond with
one of the first two lines, it is likely that scaled versions of your
fonts are not being loaded by the font server.

You will need to add the appropriate line to /etc/X11/fs/config as
root when not running X and then restart X.

In RH (which I use), the console commands would be:

/usr/sbin/chkfontpath -q -r /usr/X11R6/lib/X11/fonts/75dpi
/usr/sbin/chkfontpath -q -a /usr/X11R6/lib/X11/fonts/75dpi 

or

/usr/sbin/chkfontpath -q -r /usr/X11R6/lib/X11/fonts/100dpi
/usr/sbin/chkfontpath -q -a /usr/X11R6/lib/X11/fonts/100dpi 

I don't want to assume that SUSE has the same commands and/or paths,
but perhaps.  If not, you may just be able to edit /etc/X11/fs/config
directly, making sure that you verify the paths on your installation
as well.

Then restart X.

Perhaps another SUSE user here can verify the proper resolution.

Hope that helps.

Marc Schwartz


From noel at univ-lille3.fr  Mon Mar 31 17:07:00 2003
From: noel at univ-lille3.fr (Noel Yvonnick)
Date: Mon, 31 Mar 2003 15:07:00 +0000
Subject: [R] Re: point-biserial correlation
Message-ID: <200303311507.00203.noel@univ-lille3.fr>

> has anyone written a package/function in R for computing a point-
> biserial resp. biserial correlation?

Note that the point-biserial correlation is nothing but the standard 
correlation coefficient when one of the variables is dichotomous, so that 
cor(.) is OK.

The biserial is different and includes a correction for the so-called "point 
of dichotomy". The following should work (translating a formula found in a 
psychometric manual) :

cor.biserial = function(x,y)
{
  stopifnot(is.factor(x))
  stopifnot(length(levels(x))==2)
  stopifnot(length(x)==length(y))

  N = length(y)

  # Success / Failure frequencies
  f = table(x)/length(x)

  # Means of success/failure groups on the global score
  m = tapply(y,x,mean)

  # Variance of the global score
  Sy = sqrt(var(y)*(N-1)/N)

  # Biserial correlation
  # Be cautious in interpreting the sign : 
  # depends upon the ordering of levels(x)
  ((m[1]-m[2])/Sy)*(f[1]*f[2]/dnorm(f[1]-.5))

}

Yvonnick Noel, PhD.
Department of Psychology
U. of Lille 3


From p.dalgaard at biostat.ku.dk  Mon Mar 31 16:06:47 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 31 Mar 2003 16:06:47 +0200
Subject: [R] "font problems in X11 with linux R"
In-Reply-To: <009101c2f786$2e0b5c50$0201a8c0@MARC>
References: <009101c2f786$2e0b5c50$0201a8c0@MARC>
Message-ID: <x2el4nfx54.fsf@biostat.ku.dk>

"Marc Schwartz" <mschwartz at medanalytics.com> writes:

> >surfaced. When I 
> >use pairs in John Fox's car library e.g.:
> >
> >> pairs(cbind(prestige, income, education, women))
> >Error in text.default(x, y, txt, cex = cex, font = font) : 
> >        X11 font at size 16 could not be loaded
> >In addition: Warning message: 
> >freeing previous text buffer in GText 
> >> 
> >
> >Evidently there is some problem with my fonts or their loading in
> X11.
> > 
> >However, I can add text to a plot up to size 24 but not larger - 
> >
> >"Warning message:
> >X11 used font size 24 when 30 was requested"
> >
> >In addition - when i use help.start() within R and choses 
> > "Search Engine & Keywords" a window pops up with the 
> >following text in the windowbar: "Netscape:subprocess 
> >diagnostics(stdout/stderr)" and the 
> >following message: "Warning: Cannot convert string 
> >"-*-helvetica-*-*-*-*-*-*-12-*-*-*-iso8859-1"to type FontsStruct" but
> 
> >otherwise help.start with Netscape works OK.
> >
> >No other problems with fonts have surfaced - for example I can 
> >use font size 
> >16 in StarOffice 6.0 and Xemacs 21.4 without problems. I 
> >realize that this is 
> >more a Linux or X11 than a R question but actually I don't 
> >know where to 
> >turn.
> >I use SuSE linux 8.1, R 1.62, and Netscape 4.8.
> >How do I fix this problem?
> >
> >Sincerely Fredrik Lundgren
> 
> 
> It sounds like you might not have scaled versions of your fonts loaded
> in /etc/X11/fs/config
> 
> Take a look in there for the following lines, depending upon whether
> you have 75 or 100 dpi fonts loaded:
> 
> /usr/X11R6/lib/X11/fonts/75dpi:unscaled
> /usr/X11R6/lib/X11/fonts/100dpi:unscaled
> 
> See if there are also the following lines:
> 
> /usr/X11R6/lib/X11/fonts/75dpi 
> /usr/X11R6/lib/X11/fonts/100dpi 
> 
> If one of the second set of lines are not present to correspond with
> one of the first two lines, it is likely that scaled versions of your
> fonts are not being loaded by the font server.

I think that on SuSE you want *both* the 75dpi and 100dpi fontsets
installed. The internal code assumes that either you have the full set
of unscaled fonts or have scalable fonts (this is arguably a bug, but
I'm not sure I dare touch that particular piece of code at this
point), and SuSE gives you only one of the unscaled ones bye default.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From tmurph6 at po-box.mcgill.ca  Mon Mar 31 16:04:25 2003
From: tmurph6 at po-box.mcgill.ca (Tanya Murphy)
Date: Mon, 31 Mar 2003 09:04:25 -0500
Subject: [R] Statistical computing
Message-ID: <3EC51A1E@webmail.mcgill.ca>

Thanks to all who have replied to this. I find the advice very encouraging. 
I've been reading the recommended links on Sweave and I think it will answer a 
major part of my goals.

As for Perl vs. Python, I don't know which would be best. I've started out in 
Perl because someone got me started with a little Perl program, but I've 
looked at Python, too. I'm working in Windows (and that's not likely to change 
anytime soon--at the office, anyway) and I think WinEdt serves as a good 
enhanced editor for the main applications--LaTex, R and Perl--as well as a way 
to organize the files for a project. The GUI for Pyton seems nice, too, 
though.

Saghir, why do you prefer Python?

Is there a fairly easy way to become SAS-free for data management and 
cleaning? I'm told R is really not ideal for data cleaning. Is this what RODBC 
is about?

Tanya


>===== Original Message From "Bashir Saghir (Aztek Global)" 
<Saghir.Bashir at UCB-Group.com> =====
>Dear Tanya,
>
>Have you considered using Python (www.python.org) instead of Perl? I use
>Python, LaTeX, and R for doing what you describe. My process is evolving and
>cannot recommend it as being the best. Essentially I am moving towards a
>database approach currently using dictionaries in Python. In the longer term
>I plan to switch to MySQL.
>
>In summary I split the problem into bits that link into a relational
>database and use meta data to run my reports. So once the data base is set
>up I only need to give the key information and my programs find all relevant
>information in the database meaning that I never need to modify any programs
>to run a report with new data - just the database.
>
>I don't know of any references for this bnut if you get any to your original
>query I would be interested.
>
>Best regards,
>Saghir
>
>> -----Original Message-----
>> From:	Tanya Murphy [SMTP:tmurph6 at po-box.mcgill.ca]
>> Sent:	Friday, 28 March, 2003 5:42 PM
>> To:	r-help
>> Subject:	[R] Statistical computing
>>
>> Hello,
>>
>> I've been trying to familiarize myself with the computing tools of the
>> trade
>> (e.g. SAS, R, Perl, LaTex) and I've been getting somewhere with the
>> individual
>> programs, but I'm trying to get a better sense of how to integrate these
>> tools. I'd like to use scripts and create reports in a more organized way.
>> Can
>> anyone recommend books or, better yet free online articles, on this topic?
>>
>> Maybe I should be a little more specific about what I do: I'm a research
>> assistant in clinical epidemiology doing mainly data management and
>> analysis.
>> I do a number of repetitive tasks like updating a research database from
>> the
>> original clinic database and other sources, create reports, create
>> graphical
>> output for individual patients, as well as work on individual research
>> projects. Unfortunately I am not working closely with 'real' statisticians
>> who
>> have probably developped good work habits using these tools. Any advice on
>>
>> 'the big picture' would be greatly appreciated.
>>
>> Thanks!
>>
>> Tanya Murphy
>>


From Saghir.Bashir at UCB-Group.com  Mon Mar 31 16:23:37 2003
From: Saghir.Bashir at UCB-Group.com (Bashir Saghir (Aztek Global))
Date: Mon, 31 Mar 2003 16:23:37 +0200
Subject: [R] Statistical computing
Message-ID: <3EBA5559F490D61189430002A5F0AE89030184F3@ntexcrd.braine.ucb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030331/08a86665/attachment.pl

From spencer.graves at pdf.com  Mon Mar 31 16:31:40 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 31 Mar 2003 06:31:40 -0800
Subject: [R] integer overflow error problem
References: <Pine.LNX.4.44.0303310700030.1236-100000@gannet.stats>
Message-ID: <3E88514C.20704@pdf.com>

As usual, Prof. Ripley helped enlighten the rest of us.  Consider the 
following:

 > error(cube(as.integer(20)))
[1] NA
Warning message:
NAs produced by integer overflow in: x * x * x
 > error(cube(as.numeric(1:20)))
  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

Best Regards,
Spencer Graves

ripley at stats.ox.ac.uk wrote:
> On Mon, 31 Mar 2003, Robin Hankin wrote:
> 
> 
>>Try the following simple set of functions (R-1.6.1):
>>
>> square <- function(x){x*x}
>> cube <- function(x) {x*x*x}
>> f1 <- function(x){square(x)*(x+1)}
>> f2 <- function(x){square(x)+cube(x)}
>> error <- function(x){f1(x)-f2(x)}
>>
>>[see how f1() and f2() are algebraically identical].  Then:
>>
>>R>  error(cube(20))
>>[1] 0
>>
>>no problem.   Then:
>>
>>R>  error(cube(1:20))
>> [1]  0  0  0  0  0  0  0  0  0  0 NA NA NA NA NA NA NA NA NA NA
>>Warning message: 
>>NAs produced by integer overflow in: x * x * x 
>>
>>
>>See how error() fails for the vector but not for the single number
>>argument.  Is R being reasonable here?
> 
> 
> Yes, but is the user being reasonable here?
> 
> 20 is double
> 1:20 is integer.
> 
> and if you give an integer argument you get integer arithmetic.
> Note that R did not `fail': it returned a sensible answer and gave a 
> warning.
> 
> Programmers do need to know about representation issues, and this is a 
> programming task.  Don't expect computers to be able to hold arbitrarily 
> large numbers exactly.
>


From volkswirt at gmx.net  Mon Mar 31 16:41:48 2003
From: volkswirt at gmx.net (volkswirt@gmx.net)
Date: Mon, 31 Mar 2003 16:41:48 +0200 (MEST)
Subject: [R] 
Message-ID: <7451.1049121708@www25.gmx.net>

How can I remove all rows/collumns from a matrix that fulfill a certain  
condition? For instance: remove all negative elements from a [n,1]-matrix.  
I intended to write a function for this aim, but it does not work. Despite  
that it may help to get my point, when I ad it:  
  
kratek<-function(eine)  
{  
halt<-0  
for(index in 1:dim(eine)[1])  
{  
if(eine[(index-halt),1]<=0)  
{  
eine<-eine[-(index-halt),]  
halt<-halt+1  
}  
}  
eine  
}  
 
Thank You in advance!


From p.dalgaard at biostat.ku.dk  Mon Mar 31 16:56:54 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 31 Mar 2003 16:56:54 +0200
Subject: [R]
In-Reply-To: <7451.1049121708@www25.gmx.net>
References: <7451.1049121708@www25.gmx.net>
Message-ID: <x2adfbfutl.fsf@biostat.ku.dk>

volkswirt at gmx.net writes:

> How can I remove all rows/collumns from a matrix that fulfill a certain  
> condition? For instance: remove all negative elements from a [n,1]-matrix.  
> I intended to write a function for this aim, but it does not work. Despite  
> that it may help to get my point, when I ad it:  
>   
> kratek<-function(eine)  
> {  
> halt<-0  
> for(index in 1:dim(eine)[1])  
> {  
> if(eine[(index-halt),1]<=0)  
> {  
> eine<-eine[-(index-halt),]  
> halt<-halt+1  
> }  
> }  
> eine  
> }  

Like this?

m <- matrix(rnorm(20),ncol=2)
m[6,1]<-NA
m[-which(m[,1]<=0),]

(Notice that this is not the same as m[m[,1]>0,] as soon as NA's are
involved).


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From v_bill_pikounis at merck.com  Mon Mar 31 16:53:22 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Mon, 31 Mar 2003 09:53:22 -0500
Subject: [R] Statistical computing
Message-ID: <E827328028C66044B4998F2EC353CD3003185379@usrymx12.merck.com>

Hi Tanya,
You really cannot lose with either Perl or Python.  Either of them, along
with other tools mentioned, will suffice for making your work SAS-free. But
I would also not underestimate R for "data-cleaning"...

> Is there a fairly easy way to become SAS-free for data management and 
> cleaning? I'm told R is really not ideal for data cleaning. 

I must admit that I am always eager to debunk the myth that SAS is (so much)
better than the S language for data management, because to me the myth
mostly points out that many statisticians have never used anything else but
SAS.

Best Regards,
Bill

----------------------------------------
Bill Pikounis, Ph.D.
Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

v_bill_pikounis at merck.com

Phone: 732 594 3913
Fax: 732 594 1565


> -----Original Message-----
> From: Tanya Murphy [mailto:tmurph6 at po-box.mcgill.ca]
> Sent: Monday, March 31, 2003 9:04 AM
> To: Bashir Saghir (Aztek Global); r-help at stat.math.ethz.ch
> Subject: RE: [R] Statistical computing
> 
> 
> Thanks to all who have replied to this. I find the advice 
> very encouraging. 
> I've been reading the recommended links on Sweave and I think 
> it will answer a 
> major part of my goals.
> 
> As for Perl vs. Python, I don't know which would be best. 
> I've started out in 
> Perl because someone got me started with a little Perl 
> program, but I've 
> looked at Python, too. I'm working in Windows (and that's not 
> likely to change 
> anytime soon--at the office, anyway) and I think WinEdt 
> serves as a good 
> enhanced editor for the main applications--LaTex, R and 
> Perl--as well as a way 
> to organize the files for a project. The GUI for Pyton seems 
> nice, too, 
> though.
> 
> Saghir, why do you prefer Python?
> 
> Is there a fairly easy way to become SAS-free for data management and 
> cleaning? I'm told R is really not ideal for data cleaning. 
> Is this what RODBC 
> is about?
> 
> Tanya
> 
> 
> >===== Original Message From "Bashir Saghir (Aztek Global)" 
> <Saghir.Bashir at UCB-Group.com> =====
> >Dear Tanya,
> >
> >Have you considered using Python (www.python.org) instead of 
> Perl? I use
> >Python, LaTeX, and R for doing what you describe. My process 
> is evolving and
> >cannot recommend it as being the best. Essentially I am 
> moving towards a
> >database approach currently using dictionaries in Python. In 
> the longer term
> >I plan to switch to MySQL.
> >
> >In summary I split the problem into bits that link into a relational
> >database and use meta data to run my reports. So once the 
> data base is set
> >up I only need to give the key information and my programs 
> find all relevant
> >information in the database meaning that I never need to 
> modify any programs
> >to run a report with new data - just the database.
> >
> >I don't know of any references for this bnut if you get any 
> to your original
> >query I would be interested.
> >
> >Best regards,
> >Saghir
> >
> >> -----Original Message-----
> >> From:	Tanya Murphy [SMTP:tmurph6 at po-box.mcgill.ca]
> >> Sent:	Friday, 28 March, 2003 5:42 PM
> >> To:	r-help
> >> Subject:	[R] Statistical computing
> >>
> >> Hello,
> >>
> >> I've been trying to familiarize myself with the computing 
> tools of the
> >> trade
> >> (e.g. SAS, R, Perl, LaTex) and I've been getting somewhere with the
> >> individual
> >> programs, but I'm trying to get a better sense of how to 
> integrate these
> >> tools. I'd like to use scripts and create reports in a 
> more organized way.
> >> Can
> >> anyone recommend books or, better yet free online 
> articles, on this topic?
> >>
> >> Maybe I should be a little more specific about what I do: 
> I'm a research
> >> assistant in clinical epidemiology doing mainly data management and
> >> analysis.
> >> I do a number of repetitive tasks like updating a research 
> database from
> >> the
> >> original clinic database and other sources, create reports, create
> >> graphical
> >> output for individual patients, as well as work on 
> individual research
> >> projects. Unfortunately I am not working closely with 
> 'real' statisticians
> >> who
> >> have probably developped good work habits using these 
> tools. Any advice on
> >>
> >> 'the big picture' would be greatly appreciated.
> >>
> >> Thanks!
> >>
> >> Tanya Murphy
> >>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------


From Richard.Reed at med.va.gov  Sun Mar 30 21:21:15 2003
From: Richard.Reed at med.va.gov (Reed, Richard W)
Date: Sun, 30 Mar 2003 11:21:15 -0800
Subject: [R] Sample Weights
Message-ID: <469283227067D51191580000F8058ADF39A996@VHAPUGEXC2>

Dear R Users--

	I am trying to apply a sample weight variable to my calculations.
The dataset is from the Department of Labor. I believe that NORC constructed
the sample and did the sampling. They sampled nearly 17,000 young adults.
The sample weight variable converts the sample into the 34,000,000 in the US
population that they represent. I imported AFQT from SPSS. When I query,
"is.data.frame(AFQT)" the answer is TRUE.

	I am trying to apply svydesign from the Survey Package:

svydesign(ids, probs=NULL, strata = NULL, variables = NULL, fpc=NULL, data =
NULL, nest = FALSE, check.strata = !nest, weights=NULL) 

Below represents my effort to apply the function and the error message
(which I don't understand).
> AFQTs<-svydesign(id=~0,weights=AFQT$ASVABSW,data=AFQT)
Error in apply(probs, 1, prod) : dim(X) must have a positive length
Thanks for your help--
Richard


From jfox at mcmaster.ca  Mon Mar 31 17:19:35 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 31 Mar 2003 10:19:35 -0500
Subject: [R] 
In-Reply-To: <7451.1049121708@www25.gmx.net>
Message-ID: <5.1.0.14.2.20030331101555.01e77420@mcmail.cis.mcmaster.ca>

At 04:41 PM 3/31/2003 +0200, volkswirt at gmx.net wrote:
>How can I remove all rows/collumns from a matrix that fulfill a certain
>condition? For instance: remove all negative elements from a [n,1]-matrix.
>I intended to write a function for this aim, but it does not work. Despite
>that it may help to get my point, when I ad it:
>
>kratek<-function(eine)
>{
>halt<-0
>for(index in 1:dim(eine)[1])
>{
>if(eine[(index-halt),1]<=0)
>{
>eine<-eine[-(index-halt),]
>halt<-halt+1
>}
>}
>eine
>}
>

I'm not entirely sure that I understand what you want, but perhaps the 
following will help: Given a matrix A,  the command A[,apply(A, 2, 
function(x) all(x>=0))] will remove columns with negative elements, and 
A[apply(A, 1, function(x) all(x>=0)),] will remove rows with negative elements.

Does that help?
  John



-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From andy_liaw at merck.com  Mon Mar 31 17:21:43 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 31 Mar 2003 10:21:43 -0500
Subject: [R] Statistical computing
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F901@usrymx25.merck.com>

I can't even be called a novice in either Perl or Python, but...

I believe one of the big virtue of Python is code readability.  IIRC that
was one of the original design goals of Python.  (There is a quote: "Python
is beautiful, but Perl is more fun.")

Cheers,
Andy

> -----Original Message-----
> From: Bashir Saghir (Aztek Global) 
> [mailto:Saghir.Bashir at ucb-group.com]
> Sent: Monday, March 31, 2003 9:24 AM
> To: 'Tanya Murphy'; Bashir Saghir (Aztek Global);
> r-help at stat.math.ethz.ch
> Subject: RE: [R] Statistical computing
> 
> 
> <snip>
> >Saghir, why do you prefer Python?
> <snip>
> 
> I was thinking about learning Perl many years ago and I asked 
> my system
> admin for advice. His enthusiasm for Python steered me away 
> from Perl and
> I've been hooked since. Basically it is easy to learn and program
> development is quick. 
> Saghir
> 
> > >===== Original Message From "Bashir Saghir (Aztek Global)" 
> > <Saghir.Bashir at UCB-Group.com> =====
> > >Dear Tanya,
> > >
> > >Have you considered using Python (www.python.org) instead 
> of Perl? I use
> > >Python, LaTeX, and R for doing what you describe. My 
> process is evolving
> > and
> > >cannot recommend it as being the best. Essentially I am 
> moving towards a
> > >database approach currently using dictionaries in Python. 
> In the longer
> > term
> > >I plan to switch to MySQL.
> > >
> > >In summary I split the problem into bits that link into a 
> relational
> > >database and use meta data to run my reports. So once the 
> data base is
> > set
> > >up I only need to give the key information and my programs find all
> > relevant
> > >information in the database meaning that I never need to modify any
> > programs
> > >to run a report with new data - just the database.
> > >
> > >I don't know of any references for this bnut if you get any to your
> > original
> > >query I would be interested.
> > >
> > >Best regards,
> > >Saghir
> > >
> > >> -----Original Message-----
> > >> From:	Tanya Murphy [SMTP:tmurph6 at po-box.mcgill.ca]
> > >> Sent:	Friday, 28 March, 2003 5:42 PM
> > >> To:	r-help
> > >> Subject:	[R] Statistical computing
> > >>
> > >> Hello,
> > >>
> > >> I've been trying to familiarize myself with the 
> computing tools of the
> > >> trade
> > >> (e.g. SAS, R, Perl, LaTex) and I've been getting 
> somewhere with the
> > >> individual
> > >> programs, but I'm trying to get a better sense of how to 
> integrate
> > these
> > >> tools. I'd like to use scripts and create reports in a 
> more organized
> > way.
> > >> Can
> > >> anyone recommend books or, better yet free online 
> articles, on this
> > topic?
> > >>
> > >> Maybe I should be a little more specific about what I do: I'm a
> > research
> > >> assistant in clinical epidemiology doing mainly data 
> management and
> > >> analysis.
> > >> I do a number of repetitive tasks like updating a 
> research database
> > from
> > >> the
> > >> original clinic database and other sources, create 
> reports, create
> > >> graphical
> > >> output for individual patients, as well as work on 
> individual research
> > >> projects. Unfortunately I am not working closely with 'real'
> > statisticians
> > >> who
> > >> have probably developped good work habits using these 
> tools. Any advice
> > on
> > >>
> > >> 'the big picture' would be greatly appreciated.
> > >>
> > >> Thanks!
> > >>
> > >> Tanya Murphy
> > >>
> > 
> > 
> --------------------------------------------------------- 
> Legal Notice: This electronic mail and its attachments are 
> intended solely
> for the person(s) to whom they are addressed and contain 
> information which
> is confidential or otherwise protected from disclosure, except for the
> purpose they are intended to. Dissemination, distribution, or 
> reproduction
> by anyone other than their intended recipients is prohibited 
> and may be
> illegal. If you are not an intended recipient, please 
> immediately inform the
> sender and send him/her back the present e-mail and its 
> attachments and
> destroy any copies which may be in your possession. 
> ---------------------------------------------------------
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From fredrik.lundgren at norrkoping.mail.telia.com  Mon Mar 31 17:27:44 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Mon, 31 Mar 2003 17:27:44 +0200
Subject: [R] summary("font problems in X11 with linux R")
In-Reply-To: <x2el4nfx54.fsf@biostat.ku.dk>
References: <009101c2f786$2e0b5c50$0201a8c0@MARC>
	<x2el4nfx54.fsf@biostat.ku.dk>
Message-ID: <200303311727.44781.fredrik.lundgren@norrkoping.mail.telia.com>

Marvellous!

Thanks to Marc Swartz and Peter Dalgaard the "font problems in X11 with linux 
R" was solved. 
I added 
 /usr/X11R6/lib/X11/fonts/75dpi
/usr/X11R6/lib/X11/fonts/100dpi
to 
/etc/X11/fs/config
but nothing happened until I in addition installed 
100dpi
fonts from the SUSE dvd
and then alas - no more font problems
with 'pairs', 'scatterplot.matrix' etc but still the window with message: 
"Warning: Cannot convert string
"-*-helvetica-*-*-*-*-*-*-12-*-*-*-iso8859-1"to type FontsStruct" comes up 
with help.start() on Netscape.

However, I think this is a little unfair of SuSE.....

Well, thanks again a lot

Fredrik
m?ndagen den 31 mars 2003 16.06 skrev Peter Dalgaard BSA:
> "Marc Schwartz" <mschwartz at medanalytics.com> writes:
> > >surfaced. When I
> > >
> > >use pairs in John Fox's car library e.g.:
> > >> pairs(cbind(prestige, income, education, women))
> > >
> > >Error in text.default(x, y, txt, cex = cex, font = font) :
> > >        X11 font at size 16 could not be loaded
> > >In addition: Warning message:
> > >freeing previous text buffer in GText
> > >
> > >
> > >Evidently there is some problem with my fonts or their loading in
> >
> > X11.
> >
> > >However, I can add text to a plot up to size 24 but not larger -
> > >
> > >"Warning message:
> > >X11 used font size 24 when 30 was requested"
> > >
> > >In addition - when i use help.start() within R and choses
> > > "Search Engine & Keywords" a window pops up with the
> > >following text in the windowbar: "Netscape:subprocess
> > >diagnostics(stdout/stderr)" and the
> > >following message: "Warning: Cannot convert string
> > >"-*-helvetica-*-*-*-*-*-*-12-*-*-*-iso8859-1"to type FontsStruct" but
> > >
> > >otherwise help.start with Netscape works OK.
> > >
> > >No other problems with fonts have surfaced - for example I can
> > >use font size
> > >16 in StarOffice 6.0 and Xemacs 21.4 without problems. I
> > >realize that this is
> > >more a Linux or X11 than a R question but actually I don't
> > >know where to
> > >turn.
> > >I use SuSE linux 8.1, R 1.62, and Netscape 4.8.
> > >How do I fix this problem?
> > >
> > >Sincerely Fredrik Lundgren
> >
> > It sounds like you might not have scaled versions of your fonts loaded
> > in /etc/X11/fs/config
> >
> > Take a look in there for the following lines, depending upon whether
> > you have 75 or 100 dpi fonts loaded:
> >
> > /usr/X11R6/lib/X11/fonts/75dpi:unscaled
> > /usr/X11R6/lib/X11/fonts/100dpi:unscaled
> >
> > See if there are also the following lines:
> >
> > /usr/X11R6/lib/X11/fonts/75dpi
> > /usr/X11R6/lib/X11/fonts/100dpi
> >
> > If one of the second set of lines are not present to correspond with
> > one of the first two lines, it is likely that scaled versions of your
> > fonts are not being loaded by the font server.
>
> I think that on SuSE you want *both* the 75dpi and 100dpi fontsets
> installed. The internal code assumes that either you have the full set
> of unscaled fonts or have scalable fonts (this is arguably a bug, but
> I'm not sure I dare touch that particular piece of code at this
> point), and SuSE gives you only one of the unscaled ones bye default.


From fharrell at virginia.edu  Mon Mar 31 17:39:04 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon, 31 Mar 2003 10:39:04 -0500
Subject: [R] Statistical computing
In-Reply-To: <3EC51A1E@webmail.mcgill.ca>
References: <3EC51A1E@webmail.mcgill.ca>
Message-ID: <20030331103904.5d37f935.fharrell@virginia.edu>

On Mon, 31 Mar 2003 09:04:25 -0500
Tanya Murphy <tmurph6 at po-box.mcgill.ca> wrote:

> Thanks to all who have replied to this. I find the advice very encouraging. 
> I've been reading the recommended links on Sweave and I think it will answer a 
> major part of my goals.
> 
> As for Perl vs. Python, I don't know which would be best. I've started out in 
> Perl because someone got me started with a little Perl program, but I've 
> looked at Python, too. I'm working in Windows (and that's not likely to change 
> anytime soon--at the office, anyway) and I think WinEdt serves as a good 
> enhanced editor for the main applications--LaTex, R and Perl--as well as a way 
> to organize the files for a project. The GUI for Pyton seems nice, too, 
> though.
> 
> Saghir, why do you prefer Python?
> 
> Is there a fairly easy way to become SAS-free for data management and 
> cleaning? I'm told R is really not ideal for data cleaning. Is this what RODBC 
> is about?
> 
> Tanya

The S language is actually better than SAS for data manipulation unless you have a massive database.  The trouble is that you don't learn data manipulation by looking at documention of individual functions.  Chapter 4 of Alzola and Harrell has attempted to provide several data manipulation/variable recoding examples.

The main reason I'm confident in saying that S is better in what many people say SAS is best at is that many manipulation and recoding tasks benefit greatly from vector operations across multiple codes within a variable.  Contrast this with multiple IF statements required in many SAS applications.  

One feature of SAS that is frequently used for data manipulation is BY with FIRST.variable and LAST.variable.  As seen in the examples I mentioned above, you handle this in a completely different way in S (using lags, aggregation functions, or for loops).
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From ozdogan at crsa.bu.edu  Mon Mar 31 17:40:28 2003
From: ozdogan at crsa.bu.edu (Mutlu Ozdogan)
Date: Mon, 31 Mar 2003 10:40:28 -0500 (EST)
Subject: [R] raw image data in R and ipred
Message-ID: <200303311540.KAA05442@crsa.bu.edu>

Dear R-help list,

I am very new to R software.  I am trying to use the IPRED (bagging with 
regression trees) package to classify multi-layer raw binary images in R.

I first begin with extracting training data from my binary images.  I do this by 
selecting 5000 random pixels from a 25 layer image (each layer is 1200x1200 
pixels and there are 25 layers all short integer binary) and reading out the 
ASCII file.  The training and pruning in IPRED is done with this data set and 
there are no problems here.

My goal is to apply the trained and pruned trees to the full raw binary image.  
This is where my question is:  

Is it possible to bring a 25 layer binary image data into R, keep it in 
binary format, and apply bagging tree rules (generated with training sample) to 
generate a single layer binary image data containing predicted outcomes?

Thank you very much for your help.

Best,

Mutlu Ozdogan



-------------------------------
Mr. Mutlu Ozdogan
Center for Remote Sensing
Boston University
725 Commonwealth Avenue
Boston, MA 02215 USA
phone (617)353-5981
fax (617)353-3200
ozdogan at bu.edu
-------------------------------


From upton at mitre.org  Mon Mar 31 17:54:17 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Mon, 31 Mar 2003 10:54:17 -0500
Subject: [R] Statistical computing
References: <E827328028C66044B4998F2EC353CD3003185379@usrymx12.merck.com>
Message-ID: <3E8864A9.8418C5BC@mitre.org>

Hi Tanya,

I would also like to second Bill's comment on not underestimating R for "data
cleaning". I have had great success with simple R scripts and functions for
parsing data that I've abandoned my use of Python - not that there is anything
wrong with Python! It's just that I can do all that I need to do in selecting
subsets, etc. with R that I found no need for another, supplemental language - not
to mention the extra learning curve. FWIW, if you have some rather large files
(GB's), get lots of memory!

HTH
steve

"Pikounis, Bill" wrote:

> Hi Tanya,
> You really cannot lose with either Perl or Python.  Either of them, along
> with other tools mentioned, will suffice for making your work SAS-free. But
> I would also not underestimate R for "data-cleaning"...
>
> > Is there a fairly easy way to become SAS-free for data management and
> > cleaning? I'm told R is really not ideal for data cleaning.
>
> I must admit that I am always eager to debunk the myth that SAS is (so much)
> better than the S language for data management, because to me the myth
> mostly points out that many statisticians have never used anything else but
> SAS.
>
> Best Regards,
> Bill
>
> ----------------------------------------
> Bill Pikounis, Ph.D.
> Biometrics Research Department
> Merck Research Laboratories
> PO Box 2000, MailDrop RY84-16
> 126 E. Lincoln Avenue
> Rahway, New Jersey 07065-0900
> USA
>
> v_bill_pikounis at merck.com
>
> Phone: 732 594 3913
> Fax: 732 594 1565
>
> > -----Original Message-----
> > From: Tanya Murphy [mailto:tmurph6 at po-box.mcgill.ca]
> > Sent: Monday, March 31, 2003 9:04 AM
> > To: Bashir Saghir (Aztek Global); r-help at stat.math.ethz.ch
> > Subject: RE: [R] Statistical computing
> >
> >
> > Thanks to all who have replied to this. I find the advice
> > very encouraging.
> > I've been reading the recommended links on Sweave and I think
> > it will answer a
> > major part of my goals.
> >
> > As for Perl vs. Python, I don't know which would be best.
> > I've started out in
> > Perl because someone got me started with a little Perl
> > program, but I've
> > looked at Python, too. I'm working in Windows (and that's not
> > likely to change
> > anytime soon--at the office, anyway) and I think WinEdt
> > serves as a good
> > enhanced editor for the main applications--LaTex, R and
> > Perl--as well as a way
> > to organize the files for a project. The GUI for Pyton seems
> > nice, too,
> > though.
> >
> > Saghir, why do you prefer Python?
> >
> > Is there a fairly easy way to become SAS-free for data management and
> > cleaning? I'm told R is really not ideal for data cleaning.
> > Is this what RODBC
> > is about?
> >
> > Tanya
> >
> >
> > >===== Original Message From "Bashir Saghir (Aztek Global)"
> > <Saghir.Bashir at UCB-Group.com> =====
> > >Dear Tanya,
> > >
> > >Have you considered using Python (www.python.org) instead of
> > Perl? I use
> > >Python, LaTeX, and R for doing what you describe. My process
> > is evolving and
> > >cannot recommend it as being the best. Essentially I am
> > moving towards a
> > >database approach currently using dictionaries in Python. In
> > the longer term
> > >I plan to switch to MySQL.
> > >
> > >In summary I split the problem into bits that link into a relational
> > >database and use meta data to run my reports. So once the
> > data base is set
> > >up I only need to give the key information and my programs
> > find all relevant
> > >information in the database meaning that I never need to
> > modify any programs
> > >to run a report with new data - just the database.
> > >
> > >I don't know of any references for this bnut if you get any
> > to your original
> > >query I would be interested.
> > >
> > >Best regards,
> > >Saghir
> > >
> > >> -----Original Message-----
> > >> From:      Tanya Murphy [SMTP:tmurph6 at po-box.mcgill.ca]
> > >> Sent:      Friday, 28 March, 2003 5:42 PM
> > >> To:        r-help
> > >> Subject:   [R] Statistical computing
> > >>
> > >> Hello,
> > >>
> > >> I've been trying to familiarize myself with the computing
> > tools of the
> > >> trade
> > >> (e.g. SAS, R, Perl, LaTex) and I've been getting somewhere with the
> > >> individual
> > >> programs, but I'm trying to get a better sense of how to
> > integrate these
> > >> tools. I'd like to use scripts and create reports in a
> > more organized way.
> > >> Can
> > >> anyone recommend books or, better yet free online
> > articles, on this topic?
> > >>
> > >> Maybe I should be a little more specific about what I do:
> > I'm a research
> > >> assistant in clinical epidemiology doing mainly data management and
> > >> analysis.
> > >> I do a number of repetitive tasks like updating a research
> > database from
> > >> the
> > >> original clinic database and other sources, create reports, create
> > >> graphical
> > >> output for individual patients, as well as work on
> > individual research
> > >> projects. Unfortunately I am not working closely with
> > 'real' statisticians
> > >> who
> > >> have probably developped good work habits using these
> > tools. Any advice on
> > >>
> > >> 'the big picture' would be greatly appreciated.
> > >>
> > >> Thanks!
> > >>
> > >> Tanya Murphy
> > >>
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> ------------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From gemireni at qubisoft.it  Mon Mar 31 17:48:52 2003
From: gemireni at qubisoft.it (Gianluca Emireni)
Date: Mon, 31 Mar 2003 17:48:52 +0200
Subject: [R] Using R2HTML
Message-ID: <HBEKIOBADKJHAGANMFFHEEAICAAA.gemireni@qubisoft.it>

Hello,
I'm using R2HTML library to make a HTML page output (both data frames and
graphics):

HTMLStart(outdir=paste(getwd(),"/prove html", sep = ""),filename="index",
echo = F, HTMLframe = T, withprompt = "HTML> ", CSSFile = "R2HTML.CSS",
Title = "Indici di attivit?")
...

barplot(tab41[,2],main="...",ylab="%",names.arg=rownames(tab41),cex.names=0.
7)
grid(nx=0,ny=NULL,lty=2)
barplot(tab41[,3],main="...",ylab="",names.arg=rownames(tab41),cex.names=0.7
)
grid(nx=0,ny=NULL,lty=2)
barplot(tab41[,4],main="...",ylab="giorni",names.arg=rownames(tab41),cex.nam
es=0.7)
grid(nx=0,ny=NULL,lty=2)

HTMLplot(Caption=paste("Indici di attivit? - centro
n.",cod.centro),GraphDirectory = get(".HTML.outdir", env = get("HTMLenv",
envir = .GlobalEnv)), GraphFileName = "ind-pos",Align = "center")

	But I get this error:

Error in dev.print(png, file = AbsGraphFileName, width = 400) :
	can only print from screen device
Execution halted

Can anyone help me?
Thanks


From tlumley at u.washington.edu  Mon Mar 31 18:02:52 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 31 Mar 2003 08:02:52 -0800 (PST)
Subject: [R] Sample Weights
In-Reply-To: <469283227067D51191580000F8058ADF39A996@VHAPUGEXC2>
Message-ID: <Pine.A41.4.44.0303310758230.109778-100000@homer25.u.washington.edu>

On Sun, 30 Mar 2003, Reed, Richard W wrote:

> Dear R Users--
>
> 	I am trying to apply a sample weight variable to my calculations.
> The dataset is from the Department of Labor. I believe that NORC constructed
> the sample and did the sampling. They sampled nearly 17,000 young adults.
> The sample weight variable converts the sample into the 34,000,000 in the US
> population that they represent. I imported AFQT from SPSS. When I query,
> "is.data.frame(AFQT)" the answer is TRUE.
>
> 	I am trying to apply svydesign from the Survey Package:
>
> svydesign(ids, probs=NULL, strata = NULL, variables = NULL, fpc=NULL, data =
> NULL, nest = FALSE, check.strata = !nest, weights=NULL)
>
> Below represents my effort to apply the function and the error message
> (which I don't understand).
> > AFQTs<-svydesign(id=~0,weights=AFQT$ASVABSW,data=AFQT)
> Error in apply(probs, 1, prod) : dim(X) must have a positive length

It's a bug.  It seems that weights must be a formula or dataframe, vectors
aren't allowed.

That is, you want
    AFQTs<-svydesign(id=~0, weights=~ASVABSW, data=AFQT)

This formulation works on the `fpc' example in the package
data(fpc)
svydesign(id=~0, weights=~weight, data=fpc)

You can also do
      svydesign(id=~0,weights=data.frame(AFQT$ASVABSW), data=AFQT)
In this case you wouldn't want to, but if the weight vector wasn't a
componet of the data frame it might be necessary

Thanks for pointing this out.

	-thomas


From spencer.graves at pdf.com  Mon Mar 31 18:11:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 31 Mar 2003 08:11:34 -0800
Subject: [R] rbind data.frames with character vectors? 
Message-ID: <3E8868B6.9070008@pdf.com>

"rbind(A, B)" converts character columns of A and B to factors.  This 
means that "A <- rbind(A, B)" generates NAs unless the character strings 
in B are already levels of the corresponding columns of A.

I've got a work-around, but I'm not happy with it.  What do you suggest?

Example:

 > A <- data.frame(a=1)
 > A$b <- "A"
 > B <- data.frame(a=2)
 > B$b <- "B"
 > sapply(A, data.class)
           a           b
   "numeric" "character"
 > AB <- rbind(A,B)
 > sapply(AB, data.class)
         a         b
"numeric"  "factor"
 > C. <- data.frame(a=3)
 > C.$b <- "C"
 > rbind(AB, C.)
     a    b
1   1    A
11  2    B
111 3 <NA>
Warning message:
invalid factor level, NAs generated in: "[<-.factor"(*tmp*, ri, value = 
"C")
 > sapply(rbind(AB, C.), data.class)
         a         b
"numeric"  "factor"
Warning message:
invalid factor level, NAs generated in: "[<-.factor"(*tmp*, ri, value = 
"C")

Thanks,
Spencer Graves
p.s.  This example produces the desired result in S-Plus 2000 and 6.1 
Professional for Windows 2000.


From bates at stat.wisc.edu  Mon Mar 31 18:12:57 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 31 Mar 2003 10:12:57 -0600
Subject: [R] Statistical computing
In-Reply-To: <3EBA5559F490D61189430002A5F0AE89030184F3@ntexcrd.braine.ucb>
References: <3EBA5559F490D61189430002A5F0AE89030184F3@ntexcrd.braine.ucb>
Message-ID: <6ry92vv7jq.fsf@bates4.stat.wisc.edu>

"Bashir Saghir (Aztek Global)" <Saghir.Bashir at ucb-group.com> writes:

> <snip>
> >Saghir, why do you prefer Python?
> <snip>
> 
> I was thinking about learning Perl many years ago and I asked my system
> admin for advice. His enthusiasm for Python steered me away from Perl and
> I've been hooked since. Basically it is easy to learn and program
> development is quick. 

Python 'feels' very much like R to me (and a bit like Java too).  Perl
is great for the two-minute hack to accomplish an awkward
transformation but the saying in the Python community is that "Hell is
reading someone else's perl code".  It could also be said that
"Purgatory is reading your own perl code from more than a few weeks
ago".

I like the IDE for Python.  For me working in Python is similar to
working in R in that I have a window open where I am writing the code
and another interactive window where I can send snippets of the code
for execution, say to test out exactly what the result of some
expression is.  Once you get beyond the initial shock of discovering
that the indentation of code in python determines the lexical grouping
you find that python is a clean, well-structured language.  I don't
think the same can be said for perl.

Tanya mentioned data management and data cleaning.  I think the
combination of a relational database management system, such as MySQL
or PostgreSQL, and Python and R is very powerful for data cleaning.
Python can be used for sequential processing and for loading the
database.  SQL can be used for examining the structure of the data and
for detecting unusual cases.  R can be used for model fitting and
graphics on the entire data set, if it is not huge, or on a subset, if
it is huge.

Together I find this combination more powerful than SAS or SPSS and
definitely faster.  However, using this combination requires learning
three different languages.


From ripley at stats.ox.ac.uk  Mon Mar 31 19:07:06 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Mon, 31 Mar 2003 18:07:06 +0100 (BST)
Subject: [R] Using R2HTML
In-Reply-To: <HBEKIOBADKJHAGANMFFHEEAICAAA.gemireni@qubisoft.it>
Message-ID: <Pine.LNX.4.44.0303311800310.3175-100000@gannet.stats>

HTMLplot is documented to

     Exports the active graphic to a JPEG or GIF file and add it to a
     target HTML output, by writing the <IMG> tag.

but the code uses dev.print which is intended to *printing* from a screen
device.  Please send report to the author of R2HTML: he probably should be
using dev.copy.

I presume you are doing this in a script and so your current device is
a postscript device.


On Mon, 31 Mar 2003, Gianluca Emireni wrote:

> Hello,
> I'm using R2HTML library to make a HTML page output (both data frames and
> graphics):
> 
> HTMLStart(outdir=paste(getwd(),"/prove html", sep = ""),filename="index",
> echo = F, HTMLframe = T, withprompt = "HTML> ", CSSFile = "R2HTML.CSS",
> Title = "Indici di attivit?")
> ...
> 
> barplot(tab41[,2],main="...",ylab="%",names.arg=rownames(tab41),cex.names=0.
> 7)
> grid(nx=0,ny=NULL,lty=2)
> barplot(tab41[,3],main="...",ylab="",names.arg=rownames(tab41),cex.names=0.7
> )
> grid(nx=0,ny=NULL,lty=2)
> barplot(tab41[,4],main="...",ylab="giorni",names.arg=rownames(tab41),cex.nam
> es=0.7)
> grid(nx=0,ny=NULL,lty=2)
> 
> HTMLplot(Caption=paste("Indici di attivit? - centro
> n.",cod.centro),GraphDirectory = get(".HTML.outdir", env = get("HTMLenv",
> envir = .GlobalEnv)), GraphFileName = "ind-pos",Align = "center")
> 
> 	But I get this error:
> 
> Error in dev.print(png, file = AbsGraphFileName, width = 400) :
> 	can only print from screen device
> Execution halted
> 
> Can anyone help me?
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Mar 31 19:23:58 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Mon, 31 Mar 2003 18:23:58 +0100 (BST)
Subject: [R] rbind data.frames with character vectors? 
In-Reply-To: <3E8868B6.9070008@pdf.com>
Message-ID: <Pine.LNX.4.44.0303311816240.3175-100000@gannet.stats>

That is not how you are intended to put character strings in data frames 
in S.  Rather, there is

A <- data.frame(a=1, b=I("A"))
B <- data.frame(a=2, b=I("B"))
AB <- rbind(A,B)

etc works (at least in R-devel)

Using $ on data frame is underhand, and avoids some of the consistency 
checks.

We are planning to use I("foo") to put the column in as a character 
column and use it consistently, but for 1.8.0 not 1.7.x


On Mon, 31 Mar 2003, Spencer Graves wrote:

> "rbind(A, B)" converts character columns of A and B to factors.  This 
> means that "A <- rbind(A, B)" generates NAs unless the character strings 
> in B are already levels of the corresponding columns of A.
> 
> I've got a work-around, but I'm not happy with it.  What do you suggest?
> 
> Example:
> 
>  > A <- data.frame(a=1)
>  > A$b <- "A"
>  > B <- data.frame(a=2)
>  > B$b <- "B"
>  > sapply(A, data.class)
>            a           b
>    "numeric" "character"
>  > AB <- rbind(A,B)
>  > sapply(AB, data.class)
>          a         b
> "numeric"  "factor"
>  > C. <- data.frame(a=3)
>  > C.$b <- "C"
>  > rbind(AB, C.)
>      a    b
> 1   1    A
> 11  2    B
> 111 3 <NA>
> Warning message:
> invalid factor level, NAs generated in: "[<-.factor"(*tmp*, ri, value = 
> "C")
>  > sapply(rbind(AB, C.), data.class)
>          a         b
> "numeric"  "factor"
> Warning message:
> invalid factor level, NAs generated in: "[<-.factor"(*tmp*, ri, value = 
> "C")
> 
> Thanks,
> Spencer Graves
> p.s.  This example produces the desired result in S-Plus 2000 and 6.1 
> Professional for Windows 2000.

I am not at clear sure that is intentional, though.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From weiss at wiso-r610.wiso.uni-koeln.de  Mon Mar 31 19:23:20 2003
From: weiss at wiso-r610.wiso.uni-koeln.de (Bernd Weiss)
Date: Mon, 31 Mar 2003 19:23:20 +0200
Subject: [R] Re: point-biserial correlation
In-Reply-To: <200303311507.00203.noel@univ-lille3.fr>
Message-ID: <3E889595.14318.2451ED6@localhost>

On 31 Mar 2003 at 15:07, Noel Yvonnick wrote:

[...]

> Note that the point-biserial correlation is nothing but the standard
> correlation coefficient when one of the variables is dichotomous, so
> that cor(.) is OK.

Yes, this is a misleading subject.

> The biserial is different and includes a correction for the so-called
> "point of dichotomy". The following should work (translating a formula
> found in a psychometric manual) :
> 

[...]

>   # Biserial correlation
>   # Be cautious in interpreting the sign : 
>   # depends upon the ordering of levels(x)
>   ((m[1]-m[2])/Sy)*(f[1]*f[2]/dnorm(f[1]-.5))
> 

Thanks a lot for your help. Your code inspired me to do some modifications.

(1) Following a German statistic book (Bortz, J?rgen, 1993: Statistik. Heidelberg: 
Springer) I use the following term "dnorm(qnorm(f[1]))" instead of "dnorm(f[1]-.5)".

(2) I added some code for handling NA's.

(3) Finaly, it is now possible to do some significance test for rbis.


Bernd


# Modification of Noel Yvonnick function for computing biserial correlations
# x.na: 0/1 variable
# y.na: continuous variable  
cor.biserial = function(x.na,y.na)
{	
  x <- x[!is.na(y.na) & !is.na(x.na)]
  y <- y[!is.na(y.na) & !is.na(x.na)]
  
  stopifnot(is.factor(x))
  stopifnot(length(levels(x))==2)
  stopifnot(length(x)==length(y))

  N = length(y)

  # Success / Failure frequencies
  n <- table(x)
  f = table(x)/length(x)

  # Means of success/failure groups on the global score
  m = tapply(y,x,mean)

  # Variance of the global score
  Sy = sqrt(var(y)*(N-1)/N)

  # Biserial correlation
  # Be cautious in interpreting the sign : 
  # depends upon the ordering of levels(x)
  rbis <- ((m[1]-m[2])/Sy)*(f[1]*f[2]/dnorm(qnorm(f[1])))

  # significance test for rbis
  rhobis <- sqrt(n[1]*n[2])/(dnorm(qnorm(f[1]))*N*sqrt(N))
  z <- rbis/rhobis
  alpha <- ifelse(z<0,pnorm(z),1-pnorm(z))

  return(rbis,rhobis,z,alpha,N)
}


From TyagiAnupam at aol.com  Mon Mar 31 19:36:46 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Mon, 31 Mar 2003 12:36:46 EST
Subject: [R] Scripting with an external editor
Message-ID: <169.1c8337bf.2bb9d6ae@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030331/52fd9898/attachment.pl

From chrysopa at insecta.ufv.br  Mon Mar 31 14:18:52 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Mon, 31 Mar 2003 09:18:52 -0300
Subject: [R] Problem to install RMySQL
In-Reply-To: <Pine.LNX.4.44.0303302221500.16749-100000@gannet.stats>
References: <Pine.LNX.4.44.0303302221500.16749-100000@gannet.stats>
Message-ID: <200303310918.53060.chrysopa@insecta.ufv.br>

OK

Em Dom 30 Mar 2003 18:23, ripley at stats.ox.ac.uk escreveu:
> We need to know
>
> - your platform

GNU/Linux Debian woody/testing

> - your version of R

R 1.6.2

> - your version of DBI

0.1-4

> - your version of RMySQL

The lasted version to update (0.5)

Thanks

> but *not* the version of MySQL!
>
> My guess is that the version of R is the problem.
>
> On Sun, 30 Mar 2003, Ronaldo Reis Jr. wrote:
> > I try to update my RMySQL but it dont work.
> >
> > Creating a new generic function for "print" in package
> > RMySQL
> > [1] "print"
> > Error in getProperties(ClassDef) : "slots" is not a valid slot for this
> > object (or was mistakenly deleted)
> > Execution halted
> > ERROR: execution of package source for 'RMySQL' failed
> >
> > MySQL 3.23.52

-- 

Fazer dinheiro ? arte, trabalhar ? arte e bons neg?cios s?o a melhor arte de 
todas

--Andy Warhol
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From TyagiAnupam at aol.com  Mon Mar 31 19:45:22 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Mon, 31 Mar 2003 12:45:22 EST
Subject: [R] Statistical computing
Message-ID: <150.1d9b4eb6.2bb9d8b2@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030331/7c36ad09/attachment.pl

From chunlou at yahoo.com  Mon Mar 31 19:51:12 2003
From: chunlou at yahoo.com (Chunlou Yung)
Date: Mon, 31 Mar 2003 12:51:12 -0500
Subject: [R] Statistical computing... Perl, Python, Octave, GAP
In-Reply-To: <3EBA5559F490D61189430002A5F0AE89030184F3@ntexcrd.braine.ucb>
Message-ID: <NCBBKDNFIKJKKCFELNNMGECADFAA.chunlou@yahoo.com>

My two cents on Perl and Python (and stuff) :)....

Perl was designed to be "easy" to use but not necessarily the easiest thing
to learn (it's not hard to get started, nonetheless; just perhaps a bit hard
to master), while Python was designed to be "obvious" to learn and write and
read. Perl to scripting language is like C/C++ to compiled language, whereas
Python akin to Java (my feeling anyway). Let me elaborate...

Library Size: As far as I know, Perl has twice as large a library of modules
(about 4000) as Python, though both are certainly continuing to grow. (Like,
you're probably not going to write your own XML parser.) Don't expect
anything in advanced math in either one (why would you? You have R). As for
DB support, both are strong in that regard.

Bioinformatics: There're also vast volume of codes written in Perl and
Python in bioinformatics (freely) available on this planet, just so you
know--save yourself some time.

Capability: If you must write some code on your own, as opposed to stealing
it from someone else, Perl and Python both can do a good job, as far as
"data cleaning" (be prepared to learn regular expression, though), or task
automation goes. But...

Flexibility/Readability: Perl is a ridiculously flexible language.
Generally, it's a good thing for an individual programmer, since he can do
things however he wants but an issue for a team of programmers and a
headache for a project manager, as it's rather hard to impose consistency in
the way people code because there're so many ways to do it in Perl.

So a side effect of Perl's flexibility is its readability. Python (like
Java) tends to be more readable--maybe except for Python's "print" statement
:)

Speed: Benchmarks generally place Perl faster than Python. But for small
jobs, their speed difference doesn't matter much. Besides, speed probably
depends more on how you write your code than what you write it in.

OOP: If you're going to program extensively, sooner or later, you'll
probably run into OOP. Python's implementation of OOP is pretty natural
(especially if you come from Java or something) and it's easy to understand.
Perl has its own unique implementation of OOP--if you're a Perl guy/gal, its
implementation is brilliant; if not, it's absolutely, utterly queer--like,
for one thing, you could have both procedural codes and OOP codes in same
Perl's module (this flexibility doesn't mean you should do it--probably few
people do, as it will inadvertantly lead to confusion). (But then, S also
has its own implementation of OOP.)

Basically, Perl is a procedural language that can do OOP in its own weird
way; Python is a OOP language that can pretend to be a procedural language.

GUI: If you need to write a GUI, you could do it in Perl or Python (or TCL
as well, yet another scripting language), not that you should--it's slow and
clumsy. VB or Java would be a better choice--they're still slow but not as
clumsy. If you need speed, perhaps C++ is your only choice. Web-based GUI
would be an option, as long as you don't inadvertantly expose your company's
secret to your competitors via the Web.

Survival: If you're concerned about whether Perl or Python would ever go out
of business, my prediction is, they won't. Python is a continuous rising
star, continuously luring users away from Perl and capturing many newcomers,
who prefers a cleaner language. But Perl is not going to extinct, just as C
is not going to die any time soon. Geeks tend to like Perl; most other
normal human beings found Python just fine.

Support Group: Both Perl and Python have excellent support groups. If you're
not too antisocial, you should have no problem to find help from total
strangers over the Web for most of your daily problems (programming or
otherwise).

-------------

By the way, if by any chance you need something that can do matrix/numerical
computation very, very fast, Octave is a good product too. It's free. It's
as fast as Matlab, faster than R, but slower than C.

And if on some rare (or weird) occasions, you need to do some computatonal
group theory stuff, GAP (Groups, Algorithms and Programming) is for you.
It's free too. (You can find it at http://www.gap-system.org)

Hope it helps.


--cy


From ripley at stats.ox.ac.uk  Mon Mar 31 19:52:11 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Mon, 31 Mar 2003 18:52:11 +0100 (BST)
Subject: [R] Scripting with an external editor
In-Reply-To: <169.1c8337bf.2bb9d6ae@aol.com>
Message-ID: <Pine.LNX.4.44.0303311847080.3175-100000@gannet.stats>

On Mon, 31 Mar 2003 TyagiAnupam at aol.com wrote:

> In a message dated 3/31/03 6:32:45 AM Eastern Standard Time, 
> bitwrit at ozemail.com.au writes:
> 
> > AT wrote:
> > >If you are not trying to write R editing functionality for an editor
> > >other than (X)Emacs or WinEdt, what you describe below is already
> > >available in these editors using ESS with (X)Emacs and R macros for
> > >WinEdt. 
> > 
> > Well, in fact, I am trying to use the functionality already present in 
> > NEdit, which is in my opinion a pretty good editor. Thanks for the tip 
> > about WinEdit - I will follow it up
> 
> It is WinEdt NOT WinEdit (that is another editor).
> 
> Another tip---R macro installation for WinEdt asks you to use its 
> initialization file that makes R components possible. I had trouble 
> configuring it with earlier my configuration of WinEdt, so I created another 
> instance (desktop Icon) of WinEdt that uses R initialization file, while 
> keeping the old configuration for other work.
> 
> > >John Fox's enhancements for using ESS with Xemacs at page below. You
> > >can also use ESS alone, without these enhanced menus, etc.
> > 
> > Couldn't find much about how ESS actually does the trick. Either this is a 
> > very difficult thing to do or it is quite easy but very difficult to find 
> > out about. I lean toward the latter at the moment

I think the `trick' is how text for parsing is sent to R, and the answer 
is via the command line, using C redirection (and ptys under Unix).
I've already suggested that approach a week ago.

This thread is getting very bitty, and I am still waiting for a clear 
statement of what it is that Jim is trying to achieve.  It sounds as if 
using redirection (and the -ess flag under Windows) is what is required.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From neoroxana at yahoo.com.br  Mon Mar 31 19:55:58 2003
From: neoroxana at yahoo.com.br (=?iso-8859-1?q?Roxana=20Bravo?=)
Date: Mon, 31 Mar 2003 14:55:58 -0300 (ART)
Subject: [R] circle
Message-ID: <20030331175558.79644.qmail@web21006.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030331/fd24901d/attachment.pl

From peter at esb.ucp.pt  Mon Mar 31 19:57:11 2003
From: peter at esb.ucp.pt (Peter Ho)
Date: Mon, 31 Mar 2003 18:57:11 +0100
Subject: [R] Lattice: Saving multiple plots
References: <3E8761F3.2030206@esb.ucp.pt>
	<200303302246.09145.deepayan@stat.wisc.edu>
Message-ID: <3E888177.1030109@esb.ucp.pt>

Deepayan,

Thanks alot. The script you suggested  worked, as was documented in  ?jpeg.

Peter

Deepayan Sarkar wrote:

>On Sunday 30 March 2003 03:30 pm, Peter Ho wrote:
>  
>
>>Hi  lattice users,
>>
>>Is there a way to automatically save trellis plots , when "layout" is
>>used to produce graphs on more than one page (graph window). In the
>>example below, I have 4 graphs on each  of 4 pages. I want to save each
>> page separately.
>>
>>######
>>splom(~final.princomp.pc.scores.five[1:3]|Syrup.time*Massequite.temp,
>>groups=Batch.number,data= final.princomp.pc.scores.five,
>>panel = panel.superpose,
>>key = list(title = "Batches",
>>                  points = list(pch = super.sym$pch[1:14],
>>                 col = super.sym$col[1:14]),
>>                 text =
>>list(c("1","2","3","4","5","6","7","8","9","10","11","12","13","14")),
>>            columns=7),aspect=1,layout = c(2,2,4))
>>#####
>>
>>With only one page of graphs I would normally use the following script
>>in the beginning.For example:
>>
>>#####
>>jpeg(file="graph1.jpeg", width=960, height=960, quality=100)
>>#####
>>
>>Is there a similar way to save these graphs?
>>    
>>
>
>Following documentation in ?jpeg, 
>
>jpeg(file="graph%03d.jpeg", width=960, height=960, quality=100)
>
>would seem to work (creating files graph001.jpeg, graph002.jpeg, etc).
>
>-Deepayan
>
>  
>


From ripley at stats.ox.ac.uk  Mon Mar 31 20:13:50 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Mon, 31 Mar 2003 19:13:50 +0100 (BST)
Subject: [R] Statistical computing
In-Reply-To: <150.1d9b4eb6.2bb9d8b2@aol.com>
Message-ID: <Pine.LNX.4.44.0303311911070.3449-100000@gannet.stats>

On Mon, 31 Mar 2003 TyagiAnupam at aol.com wrote:

> In a message dated 3/31/03 10:21:20 AM Eastern Standard Time, 
> v_bill_pikounis at merck.com writes:
> 
> > I must admit that I am always eager to debunk the myth that SAS is (so much)
> > better than the S language for data management, because to me the myth
> > mostly points out that many statisticians have never used anything else but
> > SAS.
> > 
> 
> Depends on the size of the data and what one is trying to do. I tried to 
> subset a data.frame when memory.size() showed about 20M, nothing else was 
> running other than R, and it reached the memory limit 127M without doing the 
> job. The object is about 10M. Any hints?

Get more memory!  128Mb is very little for a Windows PC these days, and
you can buy many Gb for the price of a SAS licence.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From spencer.graves at pdf.com  Mon Mar 31 20:33:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 31 Mar 2003 10:33:06 -0800
Subject: [R] Statistical computing
References: <150.1d9b4eb6.2bb9d8b2@aol.com>
Message-ID: <3E8889E2.4030805@pdf.com>

What did you use for subsetting?

Spencer Graves

TyagiAnupam at aol.com wrote:
> In a message dated 3/31/03 10:21:20 AM Eastern Standard Time, 
> v_bill_pikounis at merck.com writes:
> 
> 
>>I must admit that I am always eager to debunk the myth that SAS is (so much)
>>better than the S language for data management, because to me the myth
>>mostly points out that many statisticians have never used anything else but
>>SAS.
>>
> 
> 
> Depends on the size of the data and what one is trying to do. I tried to 
> subset a data.frame when memory.size() showed about 20M, nothing else was 
> running other than R, and it reached the memory limit 127M without doing the 
> job. The object is about 10M. Any hints?
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From white.denis at epamail.epa.gov  Mon Mar 31 20:45:46 2003
From: white.denis at epamail.epa.gov (white.denis@epamail.epa.gov)
Date: Mon, 31 Mar 2003 10:45:46 -0800
Subject: [R] circle
Message-ID: <OFFA809AF2.94827C6F-ON88256CFA.0065A12F@rtp.epa.gov>


plot.new ()
plot.window (c(0,1), c(0,1))

# method 1
symbols (0.5, 0.5, circles=0.01, inches=FALSE, add=TRUE)

# method 2
points (0.5, 0.5, pch=21, cex=3, col="green")

# method 3
library (maptree)
ngon (c(0.5, 0.5, 10, 2), n=10, type=2)


> I hope this isnt a stupid question .I wonder if someone could
> help me out..I want to plot a circle and dont know exactly if
> there is a special function in R or something that could help me out


From neoroxana at yahoo.com.br  Mon Mar 31 21:46:04 2003
From: neoroxana at yahoo.com.br (=?iso-8859-1?q?Roxana=20Bravo?=)
Date: Mon, 31 Mar 2003 16:46:04 -0300 (ART)
Subject: [R] monte carlo method for circle area
Message-ID: <20030331194604.94066.qmail@web21004.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030331/ca112f62/attachment.pl

From KKarty at affinnova.com  Mon Mar 31 22:02:20 2003
From: KKarty at affinnova.com (Kevin Karty)
Date: Mon, 31 Mar 2003 15:02:20 -0500
Subject: [R] Does R have an inverse wishart distribution?
Message-ID: <90821ABF429A074DA88E56D1DF7A716159E99D@afifs1.affinnova.com>



If so, I've had trouble finding it.  Can anyone help?


From white.denis at epamail.epa.gov  Mon Mar 31 22:04:48 2003
From: white.denis at epamail.epa.gov (white.denis@epamail.epa.gov)
Date: Mon, 31 Mar 2003 12:04:48 -0800
Subject: [R] monte carlo method for circle area
Message-ID: <OF836E9508.CA3815BC-ON88256CFA.006DEBEC@rtp.epa.gov>


You can look at the function ngon in package maptree to see how to
generate a polygon definition of a circle (to whatever resolution you
want).  Then you can use the polygon clipping functions in gpclib to
clip your points to a circle.

> I ve got an assignment which consists in calculating the area of
> a circle given  a certain radius and center using the monte carlo
> method, which means that I have to plot a circle given its parameters.
> Limit the area inside it...with as many sample points as possible...
> and all of this inside a nxn size window, which could be 1x1, or any
> size actually. I wonder how I could just limit the area inside the
> circle..that would be great help for me. Some of you have given me
> several suggestions about plotting a circle using some built-in
> functions but I wonder if its suits my problem since I have to
> somehow limit the circles inner area.


From ben at zoo.ufl.edu  Mon Mar 31 22:25:09 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Mon, 31 Mar 2003 15:25:09 -0500 (EST)
Subject: [R] Does R have an inverse wishart distribution?
In-Reply-To: <90821ABF429A074DA88E56D1DF7A716159E99D@afifs1.affinnova.com>
Message-ID: <Pine.LNX.4.44.0303311518400.27862-100000@bolker.zoo.ufl.edu>


  Do you want to simulate from it?
  If so, I could send you various bits of code (some sent by Bill Venables 
to the S-PLUS help list long ago), which I would eventually mean to 
package and put up.
 
  I don't have any code for calculating probability densities (or 
cumulative distribution functions, or quantiles).

  Ben Bolker

On Mon, 31 Mar 2003, Kevin Karty wrote:

> 
> 
> If so, I've had trouble finding it.  Can anyone help?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From bates at stat.wisc.edu  Mon Mar 31 22:21:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 31 Mar 2003 14:21:03 -0600
Subject: [R] monte carlo method for circle area
In-Reply-To: <20030331194604.94066.qmail@web21004.mail.yahoo.com>
References: <20030331194604.94066.qmail@web21004.mail.yahoo.com>
Message-ID: <6r1y0nthhs.fsf@bates4.stat.wisc.edu>

Roxana Bravo <neoroxana at yahoo.com.br> writes:

> I ve got an assignment which consists in calculating the area of a
> circle given a certain radius and center using the monte carlo
> method, which means that I have to plot a circle given its
> parameters. Limit the area inside it...with as many sample points as
> possible...and all of this inside a nxn size window, which could be
> 1x1, or any size actually. I wonder how I could just limit the area
> inside the circle..that would be great help for me. Some of you have
> given me several suggestions about plotting a circle using some
> built-in functions but I wonder if its suits my problem since I have
> to somehow limit the circles inner area.

At least you state that this is an assignment :-)  It is close enough
to something that I have been describing to a class that I will answer
here and sent a copy to my class.

One way to do this is to simulate a large number of points uniformly
distributed in the rectangle [-1,1]x[-1,1] and check the distance of
the point from the origin.  The ratio of the number of points of
distance less that 1 from the origin to the total number of points
simulated is an estimate of the ratio of the area of the unit circle
to the area of the rectangle (4, in this case).  We expect the ratio
to be close to pi/4.

Interestingly, in my first simulation I got a ratio that is exactly
pi/4 to 4 significant digits.

> rdat = matrix(runif(10000 * 2, min = -1 , max = 1), nrow = 2)
> sum(colSums(rdat * rdat) < 1) 
[1] 7854
> pi/4 
[1] 0.7853982


From HStevens at muohio.edu  Mon Mar 31 22:42:49 2003
From: HStevens at muohio.edu (Hank Stevens)
Date: Mon, 31 Mar 2003 15:42:49 -0500
Subject: [R] power.t.test
Message-ID: <5.1.0.14.2.20030331151728.017ff468@po.muohio.edu>

power.t.test() requires a standard deviation as input, but for a two sample 
test, I do not understand what is required. Is it the standard deviation of 
the means (standard error), or of the combined sample?

thanks,
Hank Stevens


Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology


From r.hankin at auckland.ac.nz  Mon Mar 31 22:47:41 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Tue, 1 Apr 2003 08:47:41 +1200
Subject: [R] integer overflow error problem
In-Reply-To: <3E88514C.20704@pdf.com> (message from Spencer Graves on Mon, 31
	Mar 2003 06:31:40 -0800)
References: <Pine.LNX.4.44.0303310700030.1236-100000@gannet.stats>
	<3E88514C.20704@pdf.com>
Message-ID: <200303312047.h2VKlfOb028972@r.hankin.sges.auckland.ac.nz>

Hi everyone

As many people pointed out, R is behaving as documented.  The issue
was that a:b has storage mode integer if a is (numerically) equal to
an integer.  Thus:


R> storage.mode(as.double(1.0):3)
[1] "integer"

But

R> storage.mode(as.double(1.1):3)
[1] "double"
R> storage.mode(1)
[1] "double"
R> 


as documented under help(":").

Now _why_ does colon have this behaviour, when it seems that very few
other functions return integers; help(":") gives no clue to the
motivation.  Splus does the same thing (apparently), so there must be
some rationale.  What is it?

Also, it would appear, both "if(2+2==4)" and "(1:10)==4" are
inadvisable, because in both cases, at least one side of the "==" is a
double.  How do I get round this?


cheers


rksh


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042


From p.connolly at hortresearch.co.nz  Mon Mar 31 22:53:36 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 1 Apr 2003 08:53:36 +1200
Subject: [R] model.tables limitations
Message-ID: <20030331205336.GI6236@hortresearch.co.nz>

There is a warning in the help file for model.tables

Warning:

     The implementation is incomplete, and only the simpler cases have
     been tested thoroughly.

     Weighted `aov' fits are not supported.

Could it be that 'simpler cases' excludes those with any NAs?  I get
an error message:

Error in replications(paste("~", paste(names(tables), collapse = "+")),  : 
	na.action must be a function

Could it simply be that na.action = na.omit doesn't make it through,
or should I be looking somewhere else?


best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


From p.dalgaard at biostat.ku.dk  Mon Mar 31 22:57:56 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 31 Mar 2003 22:57:56 +0200
Subject: [R] Scripting with an external editor
In-Reply-To: <Pine.LNX.4.44.0303311847080.3175-100000@gannet.stats>
References: <Pine.LNX.4.44.0303311847080.3175-100000@gannet.stats>
Message-ID: <x2r88np82z.fsf@biostat.ku.dk>

"Prof. Brian Ripley" <ripley at stats.ox.ac.uk> writes:

> I think the `trick' is how text for parsing is sent to R, and the answer 
> is via the command line, using C redirection (and ptys under Unix).
> I've already suggested that approach a week ago.

Yes. As far as I know, ESS sits on top of the "comint" layer, which is
a body of code that is designed to run any stdio program from within
emacs. So you don't just have to clone ESS, but also whatever comint
does on Windows (which is likely nontrivial).

> This thread is getting very bitty, and I am still waiting for a clear 
> statement of what it is that Jim is trying to achieve.  It sounds as if 
> using redirection (and the -ess flag under Windows) is what is required.

-- or setReader(), except that that doesn't exist in R (yet?). You
*might* be able to fake something like that using fileevents in Tcl,
but don't come to me if you can't get it to work...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Mon Mar 31 22:57:12 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Mon, 31 Mar 2003 21:57:12 +0100 (BST)
Subject: [R] integer overflow error problem
In-Reply-To: <200303312047.h2VKlfOb028972@r.hankin.sges.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0303312152540.8649-100000@gannet.stats>

On Tue, 1 Apr 2003, Robin Hankin wrote:

[...]

> Now _why_ does colon have this behaviour, when it seems that very few
> other functions return integers; help(":") gives no clue to the
> motivation.  Splus does the same thing (apparently), so there must be
> some rationale.  What is it?

If you mean integers, it helps to have them to avoid rounding errors.
S-PLUS (sic) currently thinks 20 is integer and 20. is double.

> Also, it would appear, both "if(2+2==4)" and "(1:10)==4" are
> inadvisable, because in both cases, at least one side of the "==" is a
> double.  How do I get round this?

?identical
?as.equal

BTW, == does coerce as needed, so 2+2==as.integer(4) is fine.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mschwartz at medanalytics.com  Mon Mar 31 22:58:51 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 31 Mar 2003 14:58:51 -0600
Subject: [R] power.t.test
In-Reply-To: <5.1.0.14.2.20030331151728.017ff468@po.muohio.edu>
Message-ID: <00b901c2f7c8$569a2e20$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Hank Stevens
>Sent: Monday, March 31, 2003 2:43 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] power.t.test
>
>
>power.t.test() requires a standard deviation as input, but for 
>a two sample 
>test, I do not understand what is required. Is it the standard 
>deviation of 
>the means (standard error), or of the combined sample?
>
>thanks,
>Hank Stevens


The 'sd' argument is the standard deviation of the mean for *each*
sample, keeping in mind that the underlying assumption is that both
samples have equal variances.  Thus you need only specify one value.

HTH,

Marc Schwartz


From ripley at stats.ox.ac.uk  Mon Mar 31 23:02:39 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Mon, 31 Mar 2003 22:02:39 +0100 (BST)
Subject: [R] model.tables limitations
In-Reply-To: <20030331205336.GI6236@hortresearch.co.nz>
Message-ID: <Pine.LNX.4.44.0303312200220.8649-100000@gannet.stats>

On Tue, 1 Apr 2003, Patrick Connolly wrote:

> There is a warning in the help file for model.tables
> 
> Warning:
> 
>      The implementation is incomplete, and only the simpler cases have
>      been tested thoroughly.
> 
>      Weighted `aov' fits are not supported.
> 
> Could it be that 'simpler cases' excludes those with any NAs?  I get
> an error message:
> 
> Error in replications(paste("~", paste(names(tables), collapse = "+")),  : 
> 	na.action must be a function
> 
> Could it simply be that na.action = na.omit doesn't make it through,
> or should I be looking somewhere else?

This is fixed in R-devel, but for now run na.omit explicitly in advance of 
your fit.  The issue is that na.omit leaves information on the model frame 
that replications() does not understand.

That said, model.tables basically assumes balance, and although it works 
correctly for unbalanced fits, I doubt if people actually want the results 
it gives.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Mon Mar 31 23:07:39 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 31 Mar 2003 23:07:39 +0200
Subject: [R] power.t.test
In-Reply-To: <5.1.0.14.2.20030331151728.017ff468@po.muohio.edu>
References: <5.1.0.14.2.20030331151728.017ff468@po.muohio.edu>
Message-ID: <x2n0jbp7ms.fsf@biostat.ku.dk>

Hank Stevens <HStevens at muohio.edu> writes:

> power.t.test() requires a standard deviation as input, but for a two
> sample test, I do not understand what is required. Is it the standard
> deviation of the means (standard error), or of the combined sample?

The two (theoretical) distributions from which samples are drawn are
assumed to have the same SD. This is the value to plug in.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From jasont at indigoindustrial.co.nz  Mon Mar 31 23:28:09 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 1 Apr 2003 09:28:09 +1200
Subject: [R] request
In-Reply-To: 
	<Pine.OSF.4.44.0303311328200.24507-100000@omega.science.unitn.it>; from
	ghosh@science.unitn.it on Mon, Mar 31, 2003 at 01:40:23PM +0200
References: <20030325163421.N4227@itc.it>
	<Pine.OSF.4.44.0303311328200.24507-100000@omega.science.unitn.it>
Message-ID: <20030401092809.B6211@camille.indigoindustrial.co.nz>

On Mon, Mar 31, 2003 at 01:40:23PM +0200, Ghosh Mini wrote:
> 
> Dear all,
> 
> Hope you are fine there. I want to know
> 
> " Is it possible to treat Day,month and year seperately in a data frame in
> R"

It's easy, if your date column is a POSIX*t date/time class.
help(DateTimeClasses) should shed some light.

> Means, suppose I want to take mean of data first by day wise and then by
> month. Is it possible using R??

Use by() or tapply() with format(your.POSIX*t.object) for indicies,
and it's pretty easy.

Something like this, as a toy example...

myData <- data.frame(numbers=1:20)
myData$date <- as.POSIXct(paste(sep="-","2003",1:4,1:20))
myData

#by day
by(myData$numbers,as.character(format(myData$date,"%d")),sum) 

#by month
by(myData$numbers,as.character(format(myData$date,"%m")),sum)

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz


From kjetil at entelnet.bo  Mon Mar 31 23:31:06 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon, 31 Mar 2003 17:31:06 -0400
Subject: [R] Three graphs
In-Reply-To: <3E881FC7.5050103@epm.net.co>
Message-ID: <3E887B5A.915.3BBA77@localhost>

On 31 Mar 2003 at 6:00, Kenneth Cabrera wrote:

There are multiple ways to do this, see

?layout
?split.screen

split.screen seems to be the best for what you ask. But, split.screen
seems to be broken in rw1062, so the following example is from R-
devel (1.7 to be), on windows:

> par(bg="white")
> split.screen( matrix( c(0, 0.3, 0.5, 1, 0.3, 0.7, 0.5, 1, 
+                         0.7, 1, 0.5, 1, 0, 0.5, 0, 0.5, 
+                         0.5, 1, 0, 0.5), 5, 4, byrow=TRUE))
[1] 1 2 3 4 5
> screen(2)
> plot(1:10, 1:10)
> screen(4)
> plot(1:10, 1:10)
> screen(5)
> plot(1:10, 1:10)
> close.screen(all=TRUE)

I defines two plots not to be used, to qchieve the centering of the 
upper plot. (That might not be necessary, try). 

By the way, the help page for split.screen is a bit cryptic, it says

figs A two-element vector describing the number of rows and the 
number of columns in a screen matrix or a matrix with 4 columns. If a 
matrix, then each row describes a screen with values for the left, 
right, bottom, and top of the screen (in that order) in NDC units. 

without explaining what is NCD units. help.search("NCD") doesn't 
help, and NDC is not in the index of either MASS4 or 'S Programming'. 

But MASS4 (page 78) has a better explanation, can that be 
incorporated into the help page?

Kjetil Halvorsen




> Hi R-users:
> How can I obtain 3 graphics in a page but, one on the top and centered, and
> the other two in the bottom ?
> 
> Thank you for your help
> 
> -- 
> Kenneth Roy Cabrera Torres
> Celular +57 (315) 405 9339
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From chrysopa at insecta.ufv.br  Fri Mar 21 15:19:21 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Fri, 21 Mar 2003 11:19:21 -0300
Subject: [R] Trying to make a nested lme analysis
Message-ID: <200303211119.21611.chrysopa@insecta.ufv.br>

Hi,

I'm trying to understand the lme output and procedure.
I'm using the Crawley's book.

I'm try to analyse the rats example take from Sokal and Rohlf (1995).
I make a nested analysis using aov following the book.

> summary(rats)
    Glycogen       Treatment      Rat          Liver  
 Min.   :125.0   Min.   :1   Min.   :1.0   Min.   :1  
 1st Qu.:135.8   1st Qu.:1   1st Qu.:1.0   1st Qu.:1  
 Median :141.0   Median :2   Median :1.5   Median :2  
 Mean   :142.2   Mean   :2   Mean   :1.5   Mean   :2  
 3rd Qu.:150.0   3rd Qu.:3   3rd Qu.:2.0   3rd Qu.:3  
 Max.   :162.0   Max.   :3   Max.   :2.0   Max.   :3  

> attach(rats)
> Treatment <- factor(Treatment)
> Rat <- factor(Rat)
> Liver <- factor(Liver)

> model <- aov(Glycogen~Treatment/Rat/Liver+Error(Treatment/Rat/Liver))
> summary(model)

Error: Treatment
          Df  Sum Sq Mean Sq
Treatment  2 1557.56  778.78

Error: Treatment:Rat
              Df Sum Sq Mean Sq
Treatment:Rat  3 797.67  265.89

Error: Treatment:Rat:Liver
                    Df Sum Sq Mean Sq
Treatment:Rat:Liver 12  594.0    49.5

Error: Within
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 18 381.00   21.17               
> 

OK,

Then I try to make this analysis using lme.

> model <- lme(Glycogen~Treatment, random=~1|Treatment/Rat/Liver)
> summary(model)
Linear mixed-effects model fit by REML
 Data: NULL 
       AIC      BIC    logLik
  233.6213 244.0968 -109.8106

Random effects:
 Formula: ~1 | Treatment
        (Intercept)
StdDev:    3.541272

 Formula: ~1 | Rat %in% Treatment
        (Intercept)
StdDev:     6.00658

 Formula: ~1 | Liver %in% Rat %in% Treatment
        (Intercept) Residual
StdDev:    3.764883 4.600247

Fixed effects: Glycogen ~ Treatment 
Error in if (any(wchLv <- (as.double(levels(xtTab[, wchPval])) == 0))) { : 
	missing value where logical needed
In addition: Warning message: 
NaNs produced in: pt(q, df, lower.tail, log.p) 
> 

The random effects are correct, the variance component is OK:

In nested aov | In nested lme
Residual
21.1666       | 21.16227
Liver in Rats
14.16667      | 14.17434
Rats in Treatment
36.0648       | 36.079

But I not understand why the Fixed effects error?

What is the problem in my formula to make this analysis using lme?

Thanks for all
Inte
Ronaldo
-- 
Anger kills as surely as the other vices.
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From solares at unsl.edu.ar  Thu Mar  6 15:22:17 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Thu, 06 Mar 2003 14:22:17 -0000
Subject: [R] post mail
Message-ID: <59479.170.210.173.216.1046960512.squirrel@inter14.unsl.edu.ar>

Hello, I want post my mail solares at unsl.edu.ar


From solares at unsl.edu.ar  Thu Mar  6 15:23:47 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Thu, 06 Mar 2003 14:23:47 -0000
Subject: [R] post mail
Message-ID: <59656.170.210.173.216.1046960590.squirrel@inter14.unsl.edu.ar>

Hello, i want post my mail in r-announce. solares at unsl.edu.ar. thanks


