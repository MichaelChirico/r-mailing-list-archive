From dibella at avignon.inra.fr  Tue Oct  1 09:30:13 2002
From: dibella at avignon.inra.fr (Carlos Di Bella)
Date: Tue, 01 Oct 2002 09:30:13 +0200
Subject: [R] Image treatement
Message-ID: <4.3.1.0.20021001092738.00ac5630@avignon.inra.fr>

Hello, I'm begining with R and I'm very interested to treat satellite 
images with it. I want to ask you:
a) Is it possible to read binary files with R?
b) How could I view images (in a matrix array format) with R?

thank you very much
Carlos

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Oct  1 09:35:03 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Oct 2002 09:35:03 +0200
Subject: [R] Image treatement
In-Reply-To: <4.3.1.0.20021001092738.00ac5630@avignon.inra.fr>
References: <4.3.1.0.20021001092738.00ac5630@avignon.inra.fr>
Message-ID: <15769.20519.589114.221336@gargle.gargle.HOWL>

>>>>> "Carlos" == Carlos Di Bella <dibella at avignon.inra.fr>
>>>>>     on Tue, 01 Oct 2002 09:30:13 +0200 writes:

    Carlos> Hello, I'm begining with R and I'm very interested
    Carlos> to treat satellite images with it. I want to ask you: 

    Carlos> a) Is it possible to read binary files with R?
yes, typically using readBin() 

    Carlos> b) How could I view images (in a matrix array
    Carlos>    format) with R?

using image().

help(readBin)  and  help(image)  should get you further.

    Carlos> thank you very much Carlos
you're welcome!
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maj at waikato.ac.nz  Tue Oct  1 05:59:29 2002
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Tue, 01 Oct 2002 15:59:29 +1200
Subject: [R] Longer synonym for R?
Message-ID: <E17wEIA-0008Rf-00@euler.math.waikato.ac.nz>

Not good. Your are being pointed to CRAN resources. But the whole point of
doing a Google is to access non-CRAN resources.

Murray Jorgensen

At 10:41 30/09/02 +0200, you wrote:
>
>The first hit of Googling for
>
>  Using CRAN to fit nonlinear random coefficients models
>
>gave me 
>
>  http://cran.r-project.org/src/contrib/Descriptions/nlme.INDEX
>
>which isn't too bad, is it?
>
>
>Furthermore 
>
>  Using R to fit nonlinear random coefficients models
>
>gave me
>
>  R: Linear and nonlinear mixed effects models
>at
> 
>http://www.maths.lth.se/bioinformatics/software/R/library/nlme/html/00Inde
x.html
>
>not bad too.
>
>
>Jens Oehlschl?gel
>
>-- 
>Werden Sie mit uns zum "OnlineStar 2002"! Jetzt GMX w?hlen -
>und tolle Preise absahnen! http://www.onlinestar.de
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
._._
>  
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html 
Department of Statistics, University of Waikato, Hamilton, New Zealand 
Email: maj at waikato.ac.nz                            Fax +64-7 838 4155
Phone  +64-7 838 4773 wk    +64 7 849 6486 home     Mobile 021 395 862


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bhx2 at mevik.net  Tue Oct  1 10:18:41 2002
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge?= Mevik)
Date: 01 Oct 2002 10:18:41 +0200
Subject: [R] Polymars
In-Reply-To: <95AC7052DE4A78488DCFB615F7A49EA4059D0CD5@jewels.msu.montana.edu>
References: <95AC7052DE4A78488DCFB615F7A49EA4059D0CD5@jewels.msu.montana.edu>
Message-ID: <7oadly607y.fsf@foo.nemo-project.org>

Mars is implemented in mda.

-- 
Bj?rn-Helge Mevik

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tura at centroin.com.br  Tue Oct  1 11:19:37 2002
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Tue, 01 Oct 2002 06:19:37 -0300
Subject: [R] Update packages
In-Reply-To: <Pine.LNX.4.33.0209301635220.3488-100000@imbe78.imbe.med.un
 i-erlangen.de>
Message-ID: <5.1.0.14.2.20021001060248.009ee420@centroin.com.br>

Good Morning!

I have been having problems with the update of my R. 
Some packages (ipred, randomForest, gregmisc, Hmisc and Design)that it has new versions are not available in CRAN through the command: update.packages ().  
Will it be that my product has a defect?
I use R in win98SE with 128 Mb de RAM and AMD 1.2Ghz

Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Tue Oct  1 12:05:07 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 01 Oct 2002 11:05:07 +0100
Subject: [R] Inverting polygon
In-Reply-To: <OF54CE057A.343E257A-ON88256C44.0054DB53@rtp.epa.gov>
References: <OF54CE057A.343E257A-ON88256C44.0054DB53@rtp.epa.gov>
Message-ID: <1033466708.4501.20.camel@gandalf>

Hi

Thanks for your help.

EJ

On Mon, 2002-09-30 at 16:28, white.denis at epamail.epa.gov wrote:
> An even better solution, obviating the extra call to lines is:
> 
> n <- 50 * 3
> x <- runif (n)
> y <- runif (n)
> x[(seq(n) %% 3) == 0] <- NA
> y[(seq(n) %% 3) == 0] <- NA
> 
> plot.new ()
> range.x <- range (x, na.rm=TRUE)
> range.y <- range (y, na.rm=TRUE)
> plot.window (range.x, range.y, asp=1)
> lines (x, y)
> 
> wind.x <- c(range.x, rev (range.x), range.x[1])
> wind.y <- c(range.y[1], range.y, rev (range.y))
> 
> # example polygon
> poly.x <- wind.x / 2 + 0.25
> poly.y <- wind.y / 2 + 0.25
> 
> mask.x <- c(wind.x, poly.x)
> mask.y <- c(wind.y, poly.y)
> polygon (mask.x, mask.y, col="white", border="white")


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Oct  1 11:49:22 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Oct 2002 11:49:22 +0200
Subject: [R] Update packages
In-Reply-To: <5.1.0.14.2.20021001060248.009ee420@centroin.com.br>
References: <Pine.LNX.4.33.0209301635220.3488-100000@imbe78.imbe.med.un
 i-erlangen.de>
	<5.1.0.14.2.20021001060248.009ee420@centroin.com.br>
Message-ID: <15769.28578.529535.272817@gargle.gargle.HOWL>

>>>>> "Bernardo" == Bernardo Rangel Tura <tura at centroin.com.br>
>>>>>     on Tue, 01 Oct 2002 06:19:37 -0300 writes:

    Bernardo> I have been having problems with
    Bernardo> the update of my R.  Some packages (ipred,
    Bernardo> randomForest, gregmisc, Hmisc and Design) that it
    Bernardo> has new versions are not available in CRAN through
    Bernardo> the command: update.packages ().  Will it be that
    Bernardo> my product has a defect?  I use R in win98SE with
    Bernardo> 128 Mb de RAM and AMD 1.2Ghz

Hmisc and Design have been announced by Frank Harrell as not yet
to be available on CRAN because they don't pass "R CMD check" (without
many warnings).
The other 3 packages are on CRAN.  Note however, that for Windows,
new *binary* versions must be made available (by Prof. Brian Ripley or
Duncan Murdoch mainly I think) and there, the newest packages
are dated Sept.1 (look manually for the needed zip files in
 http://cran.R-project.org/bin/windows/contrib/ ).
I'm not entirely sure how the CRAN maintainers populate that
directory, though.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kwan022 at stat.auckland.ac.nz  Tue Oct  1 11:55:11 2002
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 1 Oct 2002 21:55:11 +1200 (NZST)
Subject: [R] Cleveland's Cut-and-Stack Plot
Message-ID: <Pine.SOL.4.21.0210012154080.21593-100000@stat1.stat.auckland.ac.nz>

Hi,

Is there a function in R that does Cleveland's Cut-and-Stack plot (Page
190 -- 191, The Elements of Graphing Data, William S. Cleveland)?

Or do I need to do it the hard way, i.e. set par(mfrow = c(m, n)) then do
it one-by-one?  

(I have a time series data set that is almost identical to the description
in Cleveland's book, hence I'm interested in trying the Cut-and-Stack
plot)

Cheers,

Kevin

------------------------------------------------------------------------------
Ko-Kang Kevin Wang
Postgraduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From allan.tucker at brunel.ac.uk  Tue Oct  1 12:01:54 2002
From: allan.tucker at brunel.ac.uk (Allan Tucker)
Date: Tue, 1 Oct 2002 11:01:54 +0100
Subject: [R] PAM and CLARA
Message-ID: <005301c26931$92922340$8e185386@CSSRAJT>

Hi,

 I am using the PAM and CLARA packages in R and have found that the =
 resulting clusters do not vary between runs. As I understand, these =
 algorithms should both have random starting points and, therefore, their =
 solutions should vary from run to run (unless the clustering is =
 trivial). This is the case with K-means on the dataset that I am using. =
 Could anyone explain why this might be occurring.

 Thanks,

 Allan.

-------------------------------------------------------------------------
Dr Allan Tucker
Research Fellow
Department of Information Systems and Computing
Brunel University
Uxbridge
Middlesex,
UB8 3PH, 
United Kingdom

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Oct  1 12:33:41 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Oct 2002 12:33:41 +0200
Subject: [R] Cleveland's Cut-and-Stack Plot
In-Reply-To: <Pine.SOL.4.21.0210012154080.21593-100000@stat1.stat.auckland.ac.nz>
References: <Pine.SOL.4.21.0210012154080.21593-100000@stat1.stat.auckland.ac.nz>
Message-ID: <15769.31237.571791.71506@gargle.gargle.HOWL>

>>>>> "KKWa" == Ko-Kang Kevin Wang <kwan022 at stat.auckland.ac.nz>
>>>>>     on Tue, 1 Oct 2002 21:55:11 +1200 (NZST) writes:

    KKWa> Hi, Is there a function in R that does Cleveland's
    KKWa> Cut-and-Stack plot (Page 190 -- 191, The Elements of
    KKWa> Graphing Data, William S. Cleveland)?

or p.162-3, "Visualizing Data"  by W.S.Cleveland (1993)

Yes. I have something, see below.
Differences:
1) I don't like the stacking from bottom to top, since I read
   graphics (and time) top to bottom

2) By default, I use about 5% overlap on each side

3) no visual reference grid yet. The function was born in 1994,
   long before I even thought of using lattice/trellis.

The function (+ help page) I have is part of a local package which would
probably be called "sfsmisc" (miscellaneous nice utilities of
the S.f.S. (Seminar for Statistics) of ETH Zurich.

I'm about to make this available as beta version within the
several hours, 
	ftp://stat.ethz.ch/U/maechler/R/sfsmisc_0.8-0.tar.gz
and later on CRAN.
Note that the package does not contain any source code and hence
should easily port to Windows.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ko-Kang at xtra.co.nz  Tue Oct  1 12:54:41 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Tue, 1 Oct 2002 22:54:41 +1200
Subject: [R] Problems installing Package with r 1.5.1
References: <200209302146580020.1226BD31@harry.molgen.mpg.de>
Message-ID: <002901c26938$f33706f0$a72758db@kwan022>

Hi,

I am assuming that your platform is Windows, and I'm also assuming that you
are trying to install your own package.

How did you build the package?  Did you use
   Rcmd build --binary mscalib
(or something like that) in command line prompt?

Did you have any spaces in your directories (sometimes it may not working)?

Did you have all the right tools in places and set up your PATH variable
right?

Cheers,

Ko-Kang Wang
------------------------------------------------
Ko-Kang Kevin Wang
Post Graduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckand.ac.nz/~kwan022

----- Original Message -----
From: "wolski" <wolski at molgen.mpg.de>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, October 01, 2002 7:46 AM
Subject: [R] Problems installing Package with r 1.5.1


> R : Copyright 2002, The R Development Core Team
> Version 1.5.1  (2002-06-17)
>
> > install.packages("O:/Rpack/mscalib.zip", .libPaths()[1], CRAN = NULL)
> updating HTML package descriptions
> Warning message:
> error -1 in extracting from zip file
> > install.packages("O:/Rpack/zzz.zip", .libPaths()[1], CRAN = NULL)
> updating HTML package descriptions
> Warning message:
> error -1 in extracting from zip file
>
> On the same machine the same file
>
>
> R : Copyright 2002, The R Development Core Team
> Version 1.4.1  (2002-01-30)
> > install.packages("O:/Rpack/zzz.zip", .libPaths()[1], CRAN = NULL)
> >





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From petr.pikal at precheza.cz  Tue Oct  1 13:42:48 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 1 Oct 2002 13:42:48 +0200
Subject: [R] 2 plots sharing axis / combining factors
In-Reply-To: <3D986C37.9477428E@ceam.es>
Message-ID: <3D99A658.14651.1937835@localhost>

Hi

On 30 Sep 2002 at 17:22, juli g. pausas wrote:

> Dear R users,
> 
> - Is it possible to produce a figure with 2 plots that they share one
> of the axis, e.g., the y-axis? I did not succeed by setting mai[4] <-
> 0. Is there a simple way?
> 
> - How could I convert 2 factor variables in a single factor variable
> which is the combination of the other 2. Example:
>     lith: a factor 2 levels "ca", "ma"
>     sp: a factor with 2 levels, "ph", "qi"

interaction(f1,f2)

works if f1 and f2 are factors with the same length

if one factor is shorter than the other the shorter one is recycled

> and I'd like to obtain:
>     splith: a factor with 4 levels: phma, phca, qima, qica
> 
> on way is by using ifelse:
> 
> splith <- as.factor(ifelse(sp=="ph", ifelse(lith=="ma", "phma",
> "phca"), ifelse(lith=="ma", "qima", "qica")))
> 
> which works fine, but I've got the feeling that it can be done in a
> more efficient way, especially for other cases where factors have more
> than 2 levels.
> 
> 
> Thanks in advance for any suggestion
> 
> Juli
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.- r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help",
> or "[un]subscribe" (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Tue Oct  1 14:31:40 2002
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 01 Oct 2002 08:31:40 -0400
Subject: [R] 2 plots sharing axis / combining factors
In-Reply-To: <3D986C37.9477428E@ceam.es>
Message-ID: <5.1.0.14.2.20021001082847.02de8e20@mcmail.cis.mcmaster.ca>

Dear Juli,

At 05:22 PM 9/30/2002 +0200, juli g. pausas wrote:

>- How could I convert 2 factor variables in a single factor variable
>which is the combination of the other 2.
>Example:
>     lith: a factor 2 levels "ca", "ma"
>     sp: a factor with 2 levels, "ph", "qi"
>and I'd like to obtain:
>     splith: a factor with 4 levels: phma, phca, qima, qica
>
>on way is by using ifelse:
>
>splith <- as.factor(ifelse(sp=="ph", ifelse(lith=="ma", "phma", "phca"),
>ifelse(lith=="ma", "qima", "qica")))
>
>which works fine, but I've got the feeling that it can be done in a more
>efficient way, especially for other cases where factors have more than 2
>levels.

How about this?

         splith <- factor(paste(as.character(lith),as.character(sp), sep="."))

If you prefer that the levels be pasted without the periods, then you could 
use sep="".

John




-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Hicham.Zmarrou at student.uva.nl  Tue Oct  1 15:09:20 2002
From: Hicham.Zmarrou at student.uva.nl (H. Zmarrou)
Date: Tue, 01 Oct 2002 15:09:20 +0200
Subject: [R] R GUI
Message-ID: <568524564e72.564e72568524@student.uva.nl>

Dear Sir ,madame:H> Dear sir: I discover last week the R software 
statistics
    programm, I have a small question, if there package to
    plot in 3 dimension the density of some bivarite
    distribution

    If yes i would ask you gratefully a help.  Thank you very
    much




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Oct  1 15:24:00 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Oct 2002 15:24:00 +0200
Subject: [R] Delayed (and doubled) R-help mails
Message-ID: <15769.41456.414217.85593@gargle.gargle.HOWL>

During the last 24 hours or so,
quite a few e-mails have been delayed for the R-help (and in one
case the R-announce) mailing lists.

The double posting of  "New version of ipred package" to
R-announce is my fault, not the posters.

I apologize for all inconveniences.
The reason is a mail server upgrade and reconfiguration.
This should all be past now and the delayed mail hopefully soon
arrive everywhere.

The good news is that the mail server should now be considerably
more powerful, i.e. delays in general should have become
smaller. (please do *NOT* reply to R-help and discuss the delays
.. we've been there more than once)

Yours,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Hicham.Zmarrou at student.uva.nl  Tue Oct  1 15:24:37 2002
From: Hicham.Zmarrou at student.uva.nl (H. Zmarrou)
Date: Tue, 01 Oct 2002 15:24:37 +0200
Subject: [R] R-gui
Message-ID: <5687fd56dc2b.56dc2b5687fd@student.uva.nl>

I discover last week the R software statistics programm, I have a small 
 questions, When we generate a bivariate normal distribution is it 
 possible to plot the generate distribution.
 The second one if there is a code to generate a bivariate student 
 distribution. 
 If yes i would ask you gratefully a help.

 Thank you very much



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Oct  1 15:54:51 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 1 Oct 2002 06:54:51 -0700 (PDT)
Subject: [R] 2 plots sharing axis / combining factors
In-Reply-To: <3D986C37.9477428E@ceam.es>
Message-ID: <Pine.A41.4.44.0210010654140.29574-100000@homer21.u.washington.edu>

On Mon, 30 Sep 2002, juli g. pausas wrote:
> - How could I convert 2 factor variables in a single factor variable
> which is the combination of the other 2.
> Example:
>     lith: a factor 2 levels "ca", "ma"
>     sp: a factor with 2 levels, "ph", "qi"
> and I'd like to obtain:
>     splith: a factor with 4 levels: phma, phca, qima, qica
>

strata(lith,sp) or interaction(lith,sp)

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From carlos.ortega at minorplanet.com  Tue Oct  1 17:09:20 2002
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Tue, 1 Oct 2002 17:09:20 +0200
Subject: [R] R-gui
In-Reply-To: <5687fd56dc2b.56dc2b5687fd@student.uva.nl>
Message-ID: <LMEKLMMLPDKOJNOOEELEEEAKDLAA.carlos.ortega@minorplanet.com>

Yes,

For the bivariate normal distribution and the T distribution, use the
package: mvtnorm.
And for a 3D graphical representation use the command "barplot2" within the
package: gregmisc.

Both packages are available for Windows and Linux (you do not detail which
OS you use)...

Hope it helps.

Carlos Ortega.

-----Mensaje original-----
De: owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch]En nombre de H. Zmarrou
Enviado el: martes, 01 de octubre de 2002 15:25
Para: r-help at stat.math.ethz.ch
Asunto: [R] R-gui


I discover last week the R software statistics programm, I have a small
 questions, When we generate a bivariate normal distribution is it
 possible to plot the generate distribution.
 The second one if there is a code to generate a bivariate student
 distribution.
 If yes i would ask you gratefully a help.

 Thank you very much



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


_____
The information in this email is confidential and it may not be
disclosed or used by anyone other than the addressee. If you are not the
intended recipient, any disclosure, copying, distribution or any action taken or
omitted is prohibited and may be unlawful.
Minorplanet cannot accept responsibility for the accuracy or completeness of
this email as it has been transmitted over a public network. If you suspect
that the email may have been amended, please call the sender.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richards at upci.pitt.edu  Tue Oct  1 18:14:40 2002
From: richards at upci.pitt.edu (Richards, Tom)
Date: Tue, 1 Oct 2002 12:14:40 -0400
Subject: [R] R installation on Linux
Message-ID: <73D624FECBBAF6459BB60437FF7C02FB06D2F6@nsabpmail>

Here is a related question on the same topic:

I have recently installed R 1.5.1, with rpm, under Redhat 7.3.  Things were going great, until I tried to install the package subselect, which said it needs BLAS.  Now, does this mean that I need to build R from scratch, including BLAS in the process, or is there a way to just install BLAS and then have subselect work?  Thanks in advance...

Tom

> -----Original Message-----
> From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> Sent: Monday, September 30, 2002 8:54 AM
> To: Steffen Durinck
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] R installation on Linux
> 
> 
> [Sorry, this got bounced because the original had "To:
> r-help at hypatia.math.ethz.ch" (??)]
> 
> Steffen Durinck <Steffen.Durinck at esat.kuleuven.ac.be> writes:
> 
> > Dear,
> > 
> > I'm new to both Linux and R. I've to build R from source code
> > and typed in the R-1.5.1 directory
> > 
> > ./configure
> > 
> > the configuration starts but after a few lines the 
> following error occurs:
> > 
> > checking for C compiler default output... configure: error: 
> C compiler
> > cannot create executables
> > 
> > what should i do?
> 
> Install the C compiler? or possibly development libraries.
> 
> If you look in the file config.log, there should be some hints about
> exactly what went wrong.
> 
> It might also be useful if you told us which Linux distribution we are
> talking about.
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: 
> (+45) 35327907
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ramasamy at stats.ox.ac.uk  Tue Oct  1 19:04:15 2002
From: ramasamy at stats.ox.ac.uk (Adaikalavan Ramasamy)
Date: Tue, 1 Oct 2002 18:04:15 +0100 (BST)
Subject: [R] Memory problem
In-Reply-To: <14c.14f19665.2ac953ce@aol.com>
Message-ID: <Pine.GSO.4.31.0210011753180.23944-100000@nightingale.stats>

Try memory.limit(512) which makes the computer think you got more than you
have. However I found this to slow the whole compluter down instead, so
the must be a problem with this fudge.

I would suggest for you to have a look the .RData file. If it is too
large, then you probably have unwanted objects. Best to remove these using
rm(). You can of course use a processor with more RAM or making your codes
memory efficient (using C etc).

Does anyone have a better solution ? I think it would be good to have a
webpage regarding this problem as this seems to be a main problem with
newbies such as myself wh have successfully used inefficient codes or
extremely long codes coupled with alarge datamatrix to play with. Just a
suggestion. Thanks.

On Mon, 30 Sep 2002 Bayesianbay at aol.com wrote:

> Dear list
>
> I am running a data simulation, which is needed to simulate up to a million
> pieces of data.
>
> I am getting the following memory error :
>
> Error: cannot allocate vector of size 11 Kb
> In addition: Warning message:
> Reached total allocation of 255Mb: see help(memory.size)
>
> I am running a PC with 256Mb RAM and R seems to be taking up the entire
> allocation and is still not able to do the simulation.
> Could anybody tell me how much RAM is needed for this sort of process and if
> there is any way of allocating more memory to R.
>
> Many thanks
> Laura
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Tue Oct  1 19:50:25 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue, 1 Oct 2002 13:50:25 -0400 (EDT)
Subject: [R] R-gui
In-Reply-To: <LMEKLMMLPDKOJNOOEELEEEAKDLAA.carlos.ortega@minorplanet.com>
Message-ID: <Pine.LNX.4.44.0210011349330.19583-100000@bolker.zoo.ufl.edu>



  Yes, although I'd recommend persp() or contour() (in base R) instead of 
barplot2() if you're going to plot bivariate *continuous* densities.

On Tue, 1 Oct 2002, Carlos Ortega wrote:

> Yes,
> 
> For the bivariate normal distribution and the T distribution, use the
> package: mvtnorm.
> And for a 3D graphical representation use the command "barplot2" within the
> package: gregmisc.
> 
> Both packages are available for Windows and Linux (you do not detail which
> OS you use)...
> 
> Hope it helps.
> 
> Carlos Ortega.
> 
> -----Mensaje original-----
> De: owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch]En nombre de H. Zmarrou
> Enviado el: martes, 01 de octubre de 2002 15:25
> Para: r-help at stat.math.ethz.ch
> Asunto: [R] R-gui
> 
> 
> I discover last week the R software statistics programm, I have a small
>  questions, When we generate a bivariate normal distribution is it
>  possible to plot the generate distribution.
>  The second one if there is a code to generate a bivariate student
>  distribution.
>  If yes i would ask you gratefully a help.
> 
>  Thank you very much
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
> 
> 
> _____
> The information in this email is confidential and it may not be
> disclosed or used by anyone other than the addressee. If you are not the
> intended recipient, any disclosure, copying, distribution or any action taken or
> omitted is prohibited and may be unlawful.
> Minorplanet cannot accept responsibility for the accuracy or completeness of
> this email as it has been transmitted over a public network. If you suspect
> that the email may have been amended, please call the sender.
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Tue Oct  1 20:05:24 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Tue, 1 Oct 2002 14:05:24 -0400 
Subject: [R] R-gui
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20149D01D@groexmb02.pfizer.com>


Hi, 

'barplot2' doesn't do 3d plots, perhaps you were thinking of the 'hist2d'
function from the 'gregmisc' package instead?

The functions 'persp', 'countour', and 'contour.filled' in the 'base'
package provide alternative visualizations of 2+1 dimensional data.  See
?hist2d for an example of using 'hist2d' and 'persp' together.

-Greg ('gregmisc' package maintainer)

> -----Original Message-----
> From: Carlos Ortega [mailto:carlos.ortega at minorplanet.com]
> Sent: Tuesday, October 01, 2002 11:09 AM
> To: H. Zmarrou; r-help at stat.math.ethz.ch
> Subject: RE: [R] R-gui
> Importance: High
> 
> 
> Yes,
> 
> For the bivariate normal distribution and the T distribution, use the
> package: mvtnorm.
> And for a 3D graphical representation use the command 
> "barplot2" within the
> package: gregmisc.
> 
> Both packages are available for Windows and Linux (you do not 
> detail which
> OS you use)...
> 
> Hope it helps.
> 
> Carlos Ortega.
> 
> -----Mensaje original-----
> De: owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch]En nombre de H. Zmarrou
> Enviado el: martes, 01 de octubre de 2002 15:25
> Para: r-help at stat.math.ethz.ch
> Asunto: [R] R-gui
> 
> 
> I discover last week the R software statistics programm, I 
> have a small
>  questions, When we generate a bivariate normal distribution is it
>  possible to plot the generate distribution.
>  The second one if there is a code to generate a bivariate student
>  distribution.
>  If yes i would ask you gratefully a help.
> 
>  Thank you very much
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.
> -.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._.
> _._
> 
> 
> _____
> The information in this email is confidential and it may not be
> disclosed or used by anyone other than the addressee. If you 
> are not the
> intended recipient, any disclosure, copying, distribution or 
> any action taken or
> omitted is prohibited and may be unlawful.
> Minorplanet cannot accept responsibility for the accuracy or 
> completeness of
> this email as it has been transmitted over a public network. 
> If you suspect
> that the email may have been amended, please call the sender.
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richards at upci.pitt.edu  Tue Oct  1 20:44:24 2002
From: richards at upci.pitt.edu (Richards, Tom)
Date: Tue, 1 Oct 2002 14:44:24 -0400
Subject: [R] R installation on Linux
Message-ID: <73D624FECBBAF6459BB60437FF7C02FB06D2FC@nsabpmail>

You only need to get the blas and lapack rpm's and install them.
Then all works perfectly well with installing subselect.


> -----Original Message-----
> From: Richards, Tom [mailto:richards at biounix3.upci.pitt.edu]
> Sent: Tuesday, October 01, 2002 12:15 PM
> To: r-help at stat.math.ethz.ch
> Subject: RE: [R] R installation on Linux
> 
> 
> Here is a related question on the same topic:
> 
> I have recently installed R 1.5.1, with rpm, under Redhat 
> 7.3.  Things were going great, until I tried to install the 
> package subselect, which said it needs BLAS.  Now, does this 
> mean that I need to build R from scratch, including BLAS in 
> the process, or is there a way to just install BLAS and then 
> have subselect work?  Thanks in advance...
> 
> Tom
> 
> > -----Original Message-----
> > From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> > Sent: Monday, September 30, 2002 8:54 AM
> > To: Steffen Durinck
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] R installation on Linux
> > 
> > 
> > [Sorry, this got bounced because the original had "To:
> > r-help at hypatia.math.ethz.ch" (??)]
> > 
> > Steffen Durinck <Steffen.Durinck at esat.kuleuven.ac.be> writes:
> > 
> > > Dear,
> > > 
> > > I'm new to both Linux and R. I've to build R from source code
> > > and typed in the R-1.5.1 directory
> > > 
> > > ./configure
> > > 
> > > the configuration starts but after a few lines the 
> > following error occurs:
> > > 
> > > checking for C compiler default output... configure: error: 
> > C compiler
> > > cannot create executables
> > > 
> > > what should i do?
> > 
> > Install the C compiler? or possibly development libraries.
> > 
> > If you look in the file config.log, there should be some hints about
> > exactly what went wrong.
> > 
> > It might also be useful if you told us which Linux 
> distribution we are
> > talking about.
> > 
> > -- 
> >    O__  ---- Peter Dalgaard             Blegdamsvej 3  
> >   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
> >  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> > (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: 
> > (+45) 35327907
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> > -.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read 
> > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: 
> > r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> > _._._._._._._._._
> > 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hodgess at uhddx01.dt.uh.edu  Tue Oct  1 22:05:51 2002
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Tue, 1 Oct 2002 15:05:51 -0500 (CDT)
Subject: [R] High Frequency Time Series
Message-ID: <200210012005.PAA27759@uhddx01.dt.uh.edu>

Dear R People:

I have a weekly time series.  How do I put this into the
ts command, please?

That is, what do I use for frequency, please?

R version 1.5.1 for Windows.

Thanks in advance.

Sincerely,
Erin
mailto: hodgess at uhddx01.dt.uh.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Tue Oct  1 11:11:05 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 1 Oct 2002 21:11:05 +1200
Subject: [R] Bits of scientific notation in write.table() output
In-Reply-To: <7BB4C1D7A9B8D311A6D100C04F1FF97F042E18AE@mnmail.arbitrade.com>; from swisdom@deephavenfunds.com on Fri, Sep 27, 2002 at 01:36:31PM -0500
References: <7BB4C1D7A9B8D311A6D100C04F1FF97F042E18AE@mnmail.arbitrade.com>
Message-ID: <20021001211105.A16525@camille.indigoindustrial.co.nz>

On Fri, Sep 27, 2002 at 01:36:31PM -0500, Steve Wisdom wrote:
> 
> What's the preferred method for avoiding `unexpected' bits of scientific
> notation in write.table() output? I've found several inelegant workarounds,
> but I'm sure I'm overlooking an obvious answer

You have to format first, then write.  Otherwise, write.table will
format for you, and computers are rarely commended for their taste.

Something like...

write.table(format(df,format=f),file="foo.txt")
read.table("foo.txt")
    df
1   95000
2   96000
3   97000
4   98000
5   99000
6  100000
7  101000
8  102000
9  103000
10 104000
11 105000


Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nolan at mail.nih.gov  Tue Oct  1 23:18:57 2002
From: nolan at mail.nih.gov (Nolan, John (NIH/CIT))
Date: Tue, 1 Oct 2002 17:18:57 -0400 
Subject: [R] Does R have graphlets?
Message-ID: <64BC9A2B18FC5843BA0DE93548F745F30B4F87BF@NIHEXCHANGE3.nih.gov>

I've been experimenting some with the graphlets which S-Plus 6.1 has.  Is
there
something similar in R?  I've looked through documentations, and at SJava,
but haven't found it.

(If you don't know what a graphlet is, here's what it appears to be:
a graphlet is a binary file that encodes information about
a graph.  Java uses spgraph.jar to display the graph and allow certain
actions - 
clicking on individual points can bring up a text string or a href, there
can be
active regions, etc.  Basically, it seems like a simple way for us non-Java
folks to get a graph with links up, using S-Plus.)

Any leads would be appreciated.

Thanks,  John

............................................................................
.....

John Nolan
Visiting Fellow, National Institutes of Health
NIH/CIT, Building 12A, Room 2001
phone: 301.402.9712       fax: 301.402.4544




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sperber at mail.ufv.br  Wed Oct  2 00:13:36 2002
From: sperber at mail.ufv.br (Carlos Sperber)
Date: Tue, 01 Oct 2002 19:13:36 -0300
Subject: [R] R kills procedure during model fitting
Message-ID: <5.1.0.14.0.20021001191015.024ecdd0@pop.ufv.br>

I am trying to fit a model with nested blocks and 12650 lines (units), and 
when I try to fit the complete model, R kills the procedure.
Within Windows it does not work - ok, I expected that - but this does also 
occur within Linux environment.
I think there is a memory problem. Is there a way to solve this problem?

Carlos Frankl Sperber
Ecology & Evolution
General Biology Department
Federal University of Vi?osa
Departamento de Biologia Geral
Universidade Federal de Vi?osa
36571-000 Vi?osa - MG
Brazil

tel: +55 (0xx) 31 3899 2556
fax: +55 (0xx) 31 3899 2549
E-mail: sperber at ufv.br


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bill.Venables at cmis.csiro.au  Wed Oct  2 02:44:48 2002
From: Bill.Venables at cmis.csiro.au (Bill.Venables@cmis.csiro.au)
Date: Wed, 2 Oct 2002 10:44:48 +1000 
Subject: [R] 2 plots sharing axis / combining factors
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A91654D4@Roper-CV.qld.cmis.csiro.au>

Two short replies to Thomas's answer:

"strata" is from the survival package.

"interaction" and "strata" do slightly different things.  
The order in which the levels are cycled is different and 

In both cases the new level set is the cartesian product of all the
component level sets, but with strata any vacant levels are pruned, with
interaction they are not.

Bill Venables.

-----Original Message-----
From: Thomas Lumley [mailto:tlumley at u.washington.edu]
Sent: Tuesday, October 01, 2002 11:55 PM
To: juli g. pausas
Cc: r-help
Subject: Re: [R] 2 plots sharing axis / combining factors


On Mon, 30 Sep 2002, juli g. pausas wrote:
> - How could I convert 2 factor variables in a single factor variable
> which is the combination of the other 2.
> Example:
>     lith: a factor 2 levels "ca", "ma"
>     sp: a factor with 2 levels, "ph", "qi"
> and I'd like to obtain:
>     splith: a factor with 4 levels: phma, phca, qima, qica
>

strata(lith,sp) or interaction(lith,sp)

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Wed Oct  2 05:46:06 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 01 Oct 2002 20:46:06 -0700
Subject: [R] Does R have graphlets?
In-Reply-To: <64BC9A2B18FC5843BA0DE93548F745F30B4F87BF@NIHEXCHANGE3.nih.gov>
References: <64BC9A2B18FC5843BA0DE93548F745F30B4F87BF@NIHEXCHANGE3.nih.gov>
Message-ID: <87d6qtlczl.fsf@jeeves.blindglobe.net>

>>>>> "john" == John Nolan <Nolan> writes:

    john> I've been experimenting some with the graphlets which S-Plus
    john> 6.1 has.  Is there something similar in R?  I've looked
    john> through documentations, and at SJava, but haven't found it.

    john> (If you don't know what a graphlet is, here's what it
    john> appears to be: a graphlet is a binary file that encodes
    john> information about a graph.  Java uses spgraph.jar to display
    john> the graph and allow certain actions - clicking on individual
    john> points can bring up a text string or a href, there can be
    john> active regions, etc.  Basically, it seems like a simple way
    john> for us non-Java folks to get a graph with links up, using
    john> S-Plus.)

An extremely crude version is the ROrca package, which provides linked
plots, dynamic graphics, brushing, and extraction of brushed points.

See http://software.biostat.washington.edu/statsoft/orca for links to
a preliminary version.

You need SJava to make it work.

I'm not going to be doing much with it in the next 2 months, but have
a large set of additions for 2003 (assuming a number of things which
may/may not happen).

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Wed Oct  2 06:51:53 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 1 Oct 2002 21:51:53 -0700 (PDT)
Subject: [R] R kills procedure during model fitting
In-Reply-To: <5.1.0.14.0.20021001191015.024ecdd0@pop.ufv.br>
Message-ID: <Pine.GSO.4.10.10210012150100.28769-100000@quetelet.stat.ucla.edu>

When you say "R kills the procedure" do you mean that R itself gets
killed, or that the function you are running gets killed *within* R?
Sometimes, when I run memory intensive procedures (on a GNU/Linux
platform) the OS will kill the R process if things get out of control.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Tue, 1 Oct 2002, Carlos Sperber wrote:

> I am trying to fit a model with nested blocks and 12650 lines (units), and 
> when I try to fit the complete model, R kills the procedure.
> Within Windows it does not work - ok, I expected that - but this does also 
> occur within Linux environment.
> I think there is a memory problem. Is there a way to solve this problem?
> 
> Carlos Frankl Sperber
> Ecology & Evolution
> General Biology Department
> Federal University of Viosa
> Departamento de Biologia Geral
> Universidade Federal de Viosa
> 36571-000 Viosa - MG
> Brazil
> 
> tel: +55 (0xx) 31 3899 2556
> fax: +55 (0xx) 31 3899 2549
> E-mail: sperber at ufv.br
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Oct  2 08:46:22 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 2 Oct 2002 08:46:22 +0200
Subject: [R] Polymars
In-Reply-To: <95AC7052DE4A78488DCFB615F7A49EA4059D0CD5@jewels.msu.montana.edu>
References: <95AC7052DE4A78488DCFB615F7A49EA4059D0CD5@jewels.msu.montana.edu>
Message-ID: <15770.38462.697432.416697@gargle.gargle.HOWL>

>>>>> "DavidB" == Brown, David <djbrown at montana.edu>
>>>>>     on Fri, 27 Sep 2002 10:33:33 -0600 writes:

    DavidB> I've seen references to "polymars", an R
    DavidB> implementation of Friedman's MARS algorithm.  Can
    DavidB> anyone tell me where I might be able to find this
    DavidB> (doesn't seem to be in the contributed packages.

not visibly anymore, but in "Archive" of old packages, i.e., in
the States,
  http://cran.US.r-project.org/src/contrib/Archive/  -> polymars_1.0-5.tar.gz

Its DESCRIPTION says

 >> Package: polymars
 >> Version: 1.0-5
 >> Title: Polychotomous Regression based on MARS
 >> Author: Charles Kooperberg and Martin O'Connor 
 >>         R port by Guido Masarotto <guido at sirio.stat.unipd.it>
 >> Maintainer: Guido Masarotto <guido at sirio.stat.unipd.it>
 >> Description: (polychotomous) regression based on 
 >>              Multivariate Adaptive Regression Splines
 >> License: Free for non-commercial purposes. See the original README.

As far as I remember (from heresay of the CRAN maintainers),
there have been at least two problems which made it disappear from
"official" CRAN:

  - The "Maintainer" did not continue to maintain it when it
    became evident the package needed some fixes to pass "R CMD check"
  - The "License" made it no so much useful anyway such as to
    try to find another maintainer.

The good news is that Charles Kooperberg recently told me about
his plans of providing improved code and maintaining it himself
in the future. 

If Charles (the owner of the code) changes the licence to GPL,
I'd volunteer to spend a few hours on the package to have it
pass "R .. check" to be back on CRAN till Charles' new code will
appear.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Wed Oct  2 09:06:04 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 2 Oct 2002 09:06:04 +0200 (CEST)
Subject: [R] Atlas shared
In-Reply-To: <x2n0pygygv.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0210020854520.7587-100000@tal.stat.umu.se>


In a FAQ on an ATLAS home page I see that shared libraries are not
supported, and indeed, when I build from source I only get static
libraries. R  needs shared libraries (right?!), so how do I get that?
With Debian (and Windows?) there are no problems, since there are
prebuilt shared libraries, but how about RedHat? (These are my three
systems.)

How do I get shared atlas libraries that work with  R  on RedHat?

Thanks,

G?ran
---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From adrian.trapletti at lmttrading.com  Wed Oct  2 09:28:26 2002
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Wed, 02 Oct 2002 09:28:26 +0200
Subject: [R] High Frequency Time Series
Message-ID: <3D9AA01A.88D27DC6@lmttrading.com>

> Date: Tue, 1 Oct 2002 15:05:51 -0500 (CDT)
> From: Erin Hodgess <hodgess at uhddx01.dt.uh.edu>
> Subject: [R] High Frequency Time Series
>
> Dear R People:
>
> I have a weekly time series.  How do I put this into the
> ts command, please?
>
> That is, what do I use for frequency, please?
>
> R version 1.5.1 for Windows.
>
> Thanks in advance.
>
> Sincerely,
> Erin
> mailto: hodgess at uhddx01.dt.uh.edu

Dear Erin

>From the documentation of ts:

     The value of argument `frequency' is used when the series is
     sampled an integral number of times in each unit time interval.
     For example, one could use a value of `7' for `frequency' when the
     data are sampled daily, and the natural time period is a week, or
     `12' when the data are sampled monthly and the natural time period
     is a year.  Values of `4' and `12' are assumed in (e.g.) `print'
     methods to imply a quarterly and monthly series respectively.

Hence, the frequency is chosen according to the "natural time period". For a natural time period of one year, frequency = 52:

ts(data,start=c(start.year,start.week),frequency=52)

best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5633
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Detlef.Steuer at unibw-hamburg.de  Wed Oct  2 09:37:28 2002
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Wed, 02 Oct 2002 09:37:28 +0200 (CEST)
Subject: [R] SuSE rpms for R-1.6.0  available
In-Reply-To: <x2n0pygygv.fsf@biostat.ku.dk>
Message-ID: <XFMail.20021002093728.steuer@unibw-hamburg.de>

RPMs for R-1.6.0 for SuSE Linux Versions 7.3/8.0
have been built and uploaded to CRAN. 

They should be found on the website within the next 24 hours.

The contrib RPMs will need a day or two to be rebuild for R-1.6.0.

SuSE 8.1 RPMS will be uploaded as soon as I have updated one of my machines.
(Or got user mode linux running, whatever happens first.)

Thank you, R Core Team!

Detlef Steuer





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From takezawa at affrc.go.jp  Wed Oct  2 10:19:39 2002
From: takezawa at affrc.go.jp (Takezawa Kunio)
Date: Wed, 02 Oct 2002 17:19:39 +0900
Subject: [R] Re: Rcmd SHLIB" does not work
Message-ID: <200210020819.AA00064@takezawa175.affrc.go.jp>

R users
E-mail: r-help at stat.math.ethz.ch

    I really appreciate information from Dr. Ligges and Dr. Wang.
I managed to create DLL files by MinGW and use them as subroutines
on R.
    Thank you very much again.

    ********     E-mail: takezawa at affrc.go.jp     ********
***** http://cse.naro.affrc.go.jp/takezawa/patent-e.html *****
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Hicham.Zmarrou at student.uva.nl  Wed Oct  2 11:28:03 2002
From: Hicham.Zmarrou at student.uva.nl (H. Zmarrou)
Date: Wed, 02 Oct 2002 11:28:03 +0200
Subject: [R] T-Distribution
Message-ID: <5c18d75c8b9d.5c8b9d5c18d7@student.uva.nl>


Dear sir,
I would ask if there are in R some code to generate a random sample 
from a mvariate student distribution like that one wich generate the 
multivariate normal one i mean( rmvnorm(n, mu, sigma)
Second question : if R can plot density 3Dcurve I don't mean de 
histogram but de hole density function(normal for example).
I use a windows version of The R software

Thank you in advance
wiyh kind regard

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From patrik.waldmann at djingis.se  Wed Oct  2 12:01:50 2002
From: patrik.waldmann at djingis.se (Patrik Waldmann)
Date: Wed, 2 Oct 2002 12:01:50 +0200
Subject: [R] Introduction of NA:s
Message-ID: <000501c269fa$bb8e4980$a110a8c0@djingis.se>

Hello,

I wonder if someone could help me with the following: I have generated 10 000 values from rnorm and now I want to randomly replace 500 of those with NA. The problem is that values indexed between 6-10,16-20,26-30.... only should be considered for replacement. Any suggestions?

Patrik Waldmann


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From susana at novalis.fc.up.pt  Wed Oct  2 12:06:48 2002
From: susana at novalis.fc.up.pt (susana)
Date: Wed, 2 Oct 2002 11:06:48 +0100
Subject: [R] Problem reading netCDF files
In-Reply-To: <20020927104900.A5660@rzsrv2.rz.tu-bs.de>
References: <E17ukos-0002qn-00@euler.math.waikato.ac.nz> <20020927104900.A5660@rzsrv2.rz.tu-bs.de>
Message-ID: <200210021003.g92A3Uw04895@cafirewall.fc.up.pt>


Hi,

I've been using package netCDF to open and read netcdf files and it works 
fine. However with some files I obtain  unexpected negative and erroneous 
results.

It seems to be related to the following warning:

Warning message: format.char: coercing 'x' to 'character' in: 
format.char(nam.ob, width = max.ncnam, flag = "-")

Any suggestions?


Thank you!


Susana


(R1.5.1 with Linux Mandrake 8.2)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nwagner at mecha.uni-stuttgart.de  Wed Oct  2 12:53:53 2002
From: nwagner at mecha.uni-stuttgart.de (Nils Wagner)
Date: Wed, 02 Oct 2002 12:53:53 +0200
Subject: [R] Re: SuSE rpms for R-1.6.0  available
References: <XFMail.20021002093728.steuer@unibw-hamburg.de>
Message-ID: <3D9AD041.9B8D15AD@mecha.uni-stuttgart.de>

Detlef Steuer schrieb:
> 
>          ["CC: R-announce" made this message bounce;
>                            I'm not sure if it should be "R-announced", MM]
> 
> RPMs for R-1.6.0 for SuSE Linux Versions 7.3/8.0
> have been built and uploaded to CRAN.

gibt es die demn?chst auch f?r 8.1 - die neue SuSE gibt es seit Montag
im Handel...

Nils Wagner


> 
> They should be found on the website within the next 24 hours.
> 
> The contrib RPMs will need a day or two to be rebuild for R-1.6.0.
> 
> SuSE 8.1 RPMS will be uploaded as soon as I have updated one of my machines.
> (Or got user mode linux running, whatever happens first.)
> 
> Thank you, R Core Team!
> 
> Detlef Steuer
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-announce mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kwan022 at stat.auckland.ac.nz  Wed Oct  2 13:01:19 2002
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 2 Oct 2002 23:01:19 +1200 (NZST)
Subject: [R] R Guide for Windows Users -- Updated
Message-ID: <Pine.SOL.4.21.0210022258520.27872-100000@stat1.stat.auckland.ac.nz>

Hi,

I have just released an updated version (2.0) of my R Guide for Windows
Users.

Table of Contents:
  1 Introduction 
  2 Installation 
      2.1 Installing R Base 
      2.2 Installing packages 
  3 Running R 
      3.1 Rgui 
          3.1.1 Setting Working Directory 
          3.1.2 Writing, Editing Commands 
      3.2 Rcmd 
      3.3 Rterm 
  4 Compile R Source 
      4.1 Preparation  
      4.2 Set PATH Variable 
          4.2.1 Windows 9x 
          4.2.2 Windows ME 
          4.2.3 Windows NT, 2000, and XP
      4.3 Comiling R from Source     
          4.3.1 Building Bitmap Device Support
          4.3.2 Building Tcl/Tk Support 
          4.3.3 Building the Manuals
          4.3.4 Building the Installers
          4.3.5 Recommended packages 
  5 Build R Package 
      5.1 Preparation  
      5.2 Documenting R Functions
      5.3 Documenting Data Sets 
      5.4 Compile the package 
  6 Emacs Speaks Statistics (ESS) 
      6.1 Getting (X)Emacs and ESS   
      6.2 Installing ESS 
      6.3 ESS Quick Reference 
  7 Using GGobi with R (Rggobi) 
      7.1 Introduction   
      7.2 Getting GGobi 
      7.3 Installing GGobi 
      7.4 Running GGobi 

It is available from CRAN (under Documentation -> Contributed), as well as
http://www.stat.auckland.ac.nz/~kwan022/rinfo.php .  The guide is updated
for R 1.6.0.

I would also like to take this opportunity to thank Paul Murrell, Vito
Muggeo, and Steve Wisdom for their valuable contributions.

Cheers,

Kevin

------------------------------------------------------------------------------
Ko-Kang Kevin Wang
Postgraduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Oct  2 13:08:16 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 Oct 2002 13:08:16 +0200
Subject: [R] Introduction of NA:s
In-Reply-To: <000501c269fa$bb8e4980$a110a8c0@djingis.se>
References: <000501c269fa$bb8e4980$a110a8c0@djingis.se>
Message-ID: <x2wup1p07z.fsf@biostat.ku.dk>

"Patrik Waldmann" <patrik.waldmann at djingis.se> writes:

> Hello,
> 
> I wonder if someone could help me with the following: I have
> generated 10 000 values from rnorm and now I want to randomly
> replace 500 of those with NA. The problem is that values indexed
> between 6-10,16-20,26-30.... only should be considered for
> replacement. Any suggestions?

x <- rnorm(10000)
x[sample(c(outer(-4:0,seq(10,10000,10),"+")),500)] <- NA

print(matrix(x,ncol=10,byrow=T),digits=1)


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bayesianbay at aol.com  Wed Oct  2 13:48:56 2002
From: Bayesianbay at aol.com (Bayesianbay@aol.com)
Date: Wed, 2 Oct 2002 07:48:56 EDT
Subject: [R] Alternative to slow double for() loop
Message-ID: <122.181feee6.2acc3728@aol.com>

Dear List

Many thanks to those who helped me yesterday regarding possible ways to 
increase memory size in R.

I have found the inefficient part of my program to be a double for() loop, 
and was wondering if anybody could suggest an alternative to using this 
double loop which would speed things up.

The program looks like this:

for (j in 1:m) {
for (i in 1:n) {
times<-comp.list[[j]][which(comp.list[[j]]$V1==i),]
T<-ncol(times)
Y<-times$V2
Y<-data.matrix(Y)
cova<-subset(times, select=V3:V16)
cova<-data.matrix(cova)
pr<-exp(cova%*%beta)/(1+exp(cova%*%beta))
dipr<-diag(c(pr[1,1], pr[2,1]))
dipr1<-dipr-(pr%*%t(pr))
A<-diag(c(dipr1[1,1],dipr1[2,2]))
D<-t(cova)%*%A
V<-A
u1<-D%*%solve(V)%*%(Y-pr)
u<-u+u1
usq<-usq+(u1%*%t(u1))
dvd<-dvd+D%*%solve(V)%*%t(D)
u.list[[j]]<-u
usq.list[[j]]<-usq
dvd.list[[j]]<-dvd
}}

where j are a number of different data sets and i are the numbers of people 
within the data set

Many thanks for any help, I'm still trying to learn the best ways of writing 
R code!

Laura
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolfgang.grond at web.de  Wed Oct  2 14:01:25 2002
From: wolfgang.grond at web.de (Wolfgang Grond)
Date: Wed, 2 Oct 2002 14:01:25 +0200
Subject: [R] output from script
Message-ID: <200210021201.g92C1OX19213@mailgate5.cinetic.de>

Hi,

perhaps the answer to my question is obvious and I didn?t find it because I?m new to R ...

The problem is as follows:
I read some data from file, do some commands which are well processed and finally make some graphics. OK
Then I put these commands together in a *.R file which I can process ...

Among these i. e. is

sum_input = summary(mydatatable)
sum_input
.....
plot(mydatatable)

What happens:
If in the script the command above comes before a plot command the plot is shown in a graphics window but not the output of the command in the console window. I therefore thought that I should define an active window and changes the order ...

sum_input = summary(mydatatable)
plot(mydatatable)
bringToTop(-1)
sum_input

I see the plot, but not the output of sum_input

Of course, if I input the command from the keyboard, I get an output.

What happens?

Many thanks in advance for any help.

Wolfgang


-------------------------------------------------------------------
 Dr. Wolfgang Grond

 Kompetenzzentrum f=FCr den               Email: grond at kegom.de
 Elektronischen Gesch=E4ftsverkehr        http://www.kegom.de
 in Ober- und Mittelfranken - KEGOM

 Industrie- und Handelskammer           Phone: +49 921 886-519
 f=FCr Oberfranken Bayreuth               Fax:   +49 921 886-122
 Bereich Innovation.Umwelt              Email: grond at bayreuth.ihk.de
 Bahnhofstrasse 23-27                   http://www.bayreuth.ihk.de
 D-95444 Bayreuth, Germany
 --------------------------------------------------------------------
______________________________________________________________________________
Wie ware das: mehrere E-Mail Adressen - aber nur ein Postfach ?



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Wed Oct  2 14:02:06 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 02 Oct 2002 08:02:06 -0400
Subject: [R] Introduction of NA:s
In-Reply-To: <000501c269fa$bb8e4980$a110a8c0@djingis.se>
Message-ID: <5.1.0.14.2.20021002075510.02cd5da8@mcmail.cis.mcmaster.ca>

Dear Patrik,

At 12:01 PM 10/2/2002 +0200, Patrik Waldmann wrote:
>Hello,
>
>I wonder if someone could help me with the following: I have generated 10 
>000 values from rnorm and now I want to randomly replace 500 of those with 
>NA. The problem is that values indexed between 6-10,16-20,26-30.... only 
>should be considered for replacement. Any suggestions?

There's probably a cleverer way of doing it, but the following should work:

         nums <- 1:10000
         data <- rnorm(10000)
         data[sample(nums[is.element(nums - 10*floor(nums/10), c(0,6:9))], 
500)] <- NA

I hope that this helps,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bojaniss at poczta.onet.pl  Wed Oct  2 14:02:32 2002
From: bojaniss at poczta.onet.pl (bojaniss)
Date: Wed, 2 Oct 2002 14:02:32 +0200
Subject: [R] T-Distribution
In-Reply-To: <5c18d75c8b9d.5c8b9d5c18d7@student.uva.nl>
References: <5c18d75c8b9d.5c8b9d5c18d7@student.uva.nl>
Message-ID: <795446890.20021002140232@poczta.onet.pl>

Hello Hicham,

Wednesday, October 2, 2002, 11:28:03 AM, you wrote:


HZ> Dear sir,
HZ> I would ask if there are in R some code to generate a random sample 
HZ> from a mvariate student distribution like that one wich generate the 
HZ> multivariate normal one i mean( rmvnorm(n, mu, sigma)

Try rt() function, type ?rt for help.

HZ> Second question : if R can plot density 3Dcurve I don't mean de 
HZ> histogram but de hole density function(normal for example).

I think sm.density function in sm package (available on CRAN) will
do what you want.

hope this helps


Michal


~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~

Michal Bojanowski - mbojanowski at samba.iss.uw.edu.pl
Polish General Social Survey
Institute for Social Studies
University of Warsaw
http://www.iss.uw.edu.pl/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lecoutre at stat.ucl.ac.be  Wed Oct  2 14:50:18 2002
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Wed, 02 Oct 2002 14:50:18 +0200
Subject: [R] Introduction of NA:s
In-Reply-To: <000501c269fa$bb8e4980$a110a8c0@djingis.se>
Message-ID: <5.1.1.5.2.20021002144827.00b66708@stat4ux.stat.ucl.ac.be>


You could use the following:

x <- rnorm(10000)
ind <- unlist(matrix(1:10000,byrow=T, ncol=10)[,6:10])
selection <- sample(ind, 500)
x[selection] <- NA


I am pretty sure there is a quicker way to create selection vector...

Eric


At 12:01 2/10/2002 +0200, you wrote:
>Hello,
>
>I wonder if someone could help me with the following: I have generated 10 
>000 values from rnorm and now I want to randomly replace 500 of those with 
>NA. The problem is that values indexed between 6-10,16-20,26-30.... only 
>should be considered for replacement. Any suggestions?
>
>Patrik Waldmann


__________________________________________________

Eric Lecoutre           Informaticien/Statisticien
Institut de Statistique                        UCL

                               (+32) (0)10 47 30 50
                            lecoutre at stat.ucl.ac.be
     http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

__________________________________________________
Le vrai danger, ce n'est pas quand les ordinateurs
penseront comme des hommes, c'est quand les hommes
penseront comme des ordinateurs.     Sydney Harris


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Wed Oct  2 14:52:33 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 02 Oct 2002 14:52:33 +0200
Subject: [R] Introduction of NA:s
References: <000501c269fa$bb8e4980$a110a8c0@djingis.se>
Message-ID: <3D9AEC11.83D37358@statistik.uni-dortmund.de>

Patrik Waldmann wrote:
> 
> Hello,
> 
> I wonder if someone could help me with the following: I have generated 10 000 values from rnorm and now I want to randomly replace 500 of those with NA. The problem is that values indexed between 6-10,16-20,26-30.... only should be considered for replacement. Any suggestions?


is.na(MyData[sample(outer(10 * 0:999, 6:10, "+"), 500)]) <- TRUE

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.C.Rougier at durham.ac.uk  Wed Oct  2 15:19:54 2002
From: J.C.Rougier at durham.ac.uk (Jonathan Rougier)
Date: Wed, 02 Oct 2002 14:19:54 +0100
Subject: [R] Introduction of NA:s
References: <000501c269fa$bb8e4980$a110a8c0@djingis.se> <x2wup1p07z.fsf@biostat.ku.dk>
Message-ID: <3D9AF27A.26220817@durham.ac.uk>

Peter Dalgaard BSA wrote:
> 
> "Patrik Waldmann" <patrik.waldmann at djingis.se> writes:
> 
> > Hello,
> >
> > I wonder if someone could help me with the following: I have
> > generated 10 000 values from rnorm and now I want to randomly
> > replace 500 of those with NA. The problem is that values indexed
> > between 6-10,16-20,26-30.... only should be considered for
> > replacement. Any suggestions?
> 
> x <- rnorm(10000)
> x[sample(c(outer(-4:0,seq(10,10000,10),"+")),500)] <- NA
> 
> print(matrix(x,ncol=10,byrow=T),digits=1)

Peter's solution is very lean, but the following might be more
transparent:

> x <- matrix(rnorm(10000), 10)
> x[6:10, ][sample(1:5000, 500)] <- NA
> x <- as.vector(x)

Cheers, Jonathan.

-- 
Jonathan Rougier                       Science Laboratories
Department of Mathematical Sciences    South Road
University of Durham                   Durham DH1 3LE
tel: +44 (0)191 374 2361, fax: +44 (0)191 374 7388
http://www.maths.dur.ac.uk/stats/people/jcr/jcr.html
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Wed Oct  2 15:39:39 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 02 Oct 2002 08:39:39 -0500
Subject: [R] Atlas shared
In-Reply-To: <Pine.LNX.4.44.0210020854520.7587-100000@tal.stat.umu.se>
References: <Pine.LNX.4.44.0210020854520.7587-100000@tal.stat.umu.se>
Message-ID: <6ry99ht0x0.fsf@bates3.stat.wisc.edu>

G?ran Brostr?m <gb at stat.umu.se> writes:

> In a FAQ on an ATLAS home page I see that shared libraries are not
> supported, and indeed, when I build from source I only get static
> libraries. R  needs shared libraries (right?!), so how do I get that?
> With Debian (and Windows?) there are no problems, since there are
> prebuilt shared libraries, but how about RedHat? (These are my three
> systems.)
> 
> How do I get shared atlas libraries that work with  R  on RedHat?

I believe that Camm Maguire, the Debian maintainer of the atlas2
packages, tweaked the makefile for atlas to produce shared libraries.

The atlas developers don't like shared libraries because position
independent code takes a performance hit.  Their objective is to get
the absolute best performance so they only produce static libraries.

You may want to get the sources for the Debian atlas packages and look
at what Camm does in the makefile.  I am Cc:'ing Camm on this reply in
case he wants to add anything.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Wed Oct  2 15:52:50 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 2 Oct 2002 15:52:50 +0200 (CEST)
Subject: [R] Dataframes and assign
In-Reply-To: <Pine.LNX.4.44.0210020854520.7587-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.44.0210021346530.7970-100000@tal.stat.umu.se>


I have the following function:

putsoc <- function(age, dat){
  ## age is an integer
  ## dat is a data.frame

  new.name <- paste("soc", as.character(age), sep = ".")
  if (new.name %in% names(dat)) stop(paste(new.name, "already in place"))

  dat$new.var <- rep(1, nrow(dat)) ## Just nonsense.

  n.var <- ncol(dat)
  names(dat)[ncol(dat)] <- new.name
  return(dat)
}

i.e., the function adds a new variable to a data frame. The problem is
that I only have the new variable name in a text string, and so would
like to use 'assign'. I have two questions:

1. Is my solution 'safe': Can I trust that the new variable always will be
   the last one in the augmented data frame?

2. If I instead used 'assign(new.name, new.var)' how do I put the result
   into the data frame?

---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From edd at debian.org  Wed Oct  2 16:04:15 2002
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 02 Oct 2002 09:04:15 -0500
Subject: [R] Atlas shared
Message-ID: <E17wk6p-0006sV-00@sonny.eddelbuettel.com>


> In a FAQ on an ATLAS home page I see that shared libraries are not
> supported, and indeed, when I build from source I only get static
> libraries. R  needs shared libraries (right?!), so how do I get that?
> With Debian (and Windows?) there are no problems, since there are
> prebuilt shared libraries, but how about RedHat? (These are my three
> systems.)
> 
> How do I get shared atlas libraries that work with  R  on RedHat?

You could try to fudge it and simply place the Debian libraries onto 
a RH system, preferably by converting the .deb into a .rpm via the alien 
program.

Or you could study the build process of Debian's atlas package and apply
it to a .rpm.  My recollection from talking to our Atlas maintainer is that
this is not a straightforward process -- so your cost/benefit analysis might
lead you to the first solution.

Dirk

-- 
According to the latest figures, 43% of all signatures are totally worthless.   
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From L.Whitaker at inpharmatica.co.uk  Wed Oct  2 16:06:23 2002
From: L.Whitaker at inpharmatica.co.uk (Luke Whitaker)
Date: Wed, 02 Oct 2002 15:06:23 +0100
Subject: [R] Parameterisation of interaction terms in lm
Message-ID: <3D9AFD5F.2060007@inpharmatica.co.uk>

Hello,

I have a 2 factor linear model, in which the only terms I am interested 
in estimating and
testing are the interaction terms. I want to control for the main 
effects but have no interest
in estimating or testing them. However, I would like an estimate of the 
interaction effects
for every level of the interactions, whereas what I get is one fewer 
estimate than this, with the
first level apparently used as a baseline.

For example, suppose factor A has 2 levels, and factor B has 4 levels, I 
would like 4 estimates,
one for each level of B, showing how much different the actual A*B 
effect is from what it would
be if there were no interaction. I suspect it is necessary to assume the 
mean interaction is zero in
order to be estimable.

Although the experiment was designed to be balanced, there are some 
missing data, but no empty
cells. The experiment is actually a gene expression micro array, where A 
is tissue type and B represents
a number of genes of interest.

I have searched the archives, and read the docs relating to contrasts, 
but only succeeded in getting
confused. I would be very grateful if someone could point me to the 
solution.

Sincerely,

Luke Whitaker

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From reid_huntsinger at merck.com  Wed Oct  2 15:31:59 2002
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Wed, 02 Oct 2002 09:31:59 -0400
Subject: [R] Atlas shared
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC176@uswpmx11.merck.com>

I don't see why the Debian shared libraries shouldn't work, but it's not too
hard to make shared ATLAS: first you need to get the flags for
position-independent code (-fPIC on gcc) into the compilations, which can be
done in the "config" program (add it to the defaults for the C and Fortran
compiler flags), then you extract the object files from the .a archive built
by "make install" and put them into a shared library with ld -shared. See
the "Program Library Howto" at
http://www.ibiblio.org/pub/Linux/docs/HOWTO/other-formats/pdf/Program-Librar
y-HOWTO.pdf.

PS I couldn't make it work without saying "yes" to pthreads in the config
program, though, and trying to give the libraries different names (in the
config program) also didn't work. 

Reid Huntsinger

-----Original Message-----
From: G?ran Brostr?m [mailto:gb at stat.umu.se]
Sent: Wednesday, October 02, 2002 3:06 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Atlas shared



In a FAQ on an ATLAS home page I see that shared libraries are not
supported, and indeed, when I build from source I only get static
libraries. R  needs shared libraries (right?!), so how do I get that?
With Debian (and Windows?) there are no problems, since there are
prebuilt shared libraries, but how about RedHat? (These are my three
systems.)

How do I get shared atlas libraries that work with  R  on RedHat?

Thanks,

G?ran
---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From camm at enhanced.com  Wed Oct  2 16:26:53 2002
From: camm at enhanced.com (Camm Maguire)
Date: 02 Oct 2002 10:26:53 -0400
Subject: [R] Atlas shared
In-Reply-To: Douglas Bates's message of "02 Oct 2002 08:39:39 -0500"
References: <Pine.LNX.4.44.0210020854520.7587-100000@tal.stat.umu.se> <6ry99ht0x0.fsf@bates3.stat.wisc.edu>
Message-ID: <54smzosyqa.fsf@intech19.enhanced.com>

Greetings!  What Doug said is right -- you can just unpack the debian
sources and run debian/rules build to see what happens.  In most
cases, this will actually run several prebuilt 'build-records', and
won't time anything on your box at all.  We need this to play nicely
with the autobuilders.  If you want to do the timing, execute
'fakeroot debian/rules custom'.  Most of this is explained in the
README.Debian file.

P.S. -- is there a reason not to just use Debian?

Take care,

Douglas Bates <bates at stat.wisc.edu> writes:

> G=F6ran Brostr=F6m <gb at stat.umu.se> writes:
> 
> > In a FAQ on an ATLAS home page I see that shared libraries are not
> > supported, and indeed, when I build from source I only get static
> > libraries. R  needs shared libraries (right?!), so how do I get that?
> > With Debian (and Windows?) there are no problems, since there are
> > prebuilt shared libraries, but how about RedHat? (These are my three
> > systems.)
> >=20
> > How do I get shared atlas libraries that work with  R  on RedHat?
> 
> I believe that Camm Maguire, the Debian maintainer of the atlas2
> packages, tweaked the makefile for atlas to produce shared libraries.
> 
> The atlas developers don't like shared libraries because position
> independent code takes a performance hit.  Their objective is to get
> the absolute best performance so they only produce static libraries.
> 
> You may want to get the sources for the Debian atlas packages and look
> at what Camm does in the makefile.  I am Cc:'ing Camm on this reply in
> case he wants to add anything.
> 
> 

-- 
Camm Maguire			     			camm at enhanced.com
==========================================================================
"The earth is but one country, and mankind its citizens."  --  Baha'u'llah
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Wed Oct  2 17:11:26 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 2 Oct 2002 08:11:26 -0700 (PDT)
Subject: [R] Atlas shared
In-Reply-To: <Pine.LNX.4.44.0210020854520.7587-100000@tal.stat.umu.se>
Message-ID: <Pine.GSO.4.10.10210020804270.5538-100000@quetelet.stat.ucla.edu>

I thought that if you build R from source, you can specify the path to the
ATLAS static libraries in the LD_FLAGS part of the config.site file.  Or,
if you put the ATLAS libraries in a place like /usr/local/lib it should
get picked up automatically during configure.  Either way, it should get
linked in at build time, no?

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 2 Oct 2002, Gran Brostrm wrote:

> 
> In a FAQ on an ATLAS home page I see that shared libraries are not
> supported, and indeed, when I build from source I only get static
> libraries. R  needs shared libraries (right?!), so how do I get that?
> With Debian (and Windows?) there are no problems, since there are
> prebuilt shared libraries, but how about RedHat? (These are my three
> systems.)
> 
> How do I get shared atlas libraries that work with  R  on RedHat?
> 
> Thanks,
> 
> Gran
> ---
>  Gran Brostrm                    tel: +46 90 786 5223
>  Department of Statistics          fax: +46 90 786 6614
>  Ume University                   http://www.stat.umu.se/egna/gb/
>  SE-90187 Ume, Sweden             e-mail: gb at stat.umu.se
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From clk at fhcrc.org  Wed Oct  2 17:14:16 2002
From: clk at fhcrc.org (Charles Kooperberg)
Date: Wed, 02 Oct 2002 08:14:16 -0700
Subject: [R] Polymars
References: <95AC7052DE4A78488DCFB615F7A49EA4059D0CD5@jewels.msu.montana.edu> <15770.38462.697432.416697@gargle.gargle.HOWL>
Message-ID: <3D9B0D48.64876B1@fhcrc.org>

Actually,

If David is on a unix/linux based system, I can email him
a package right now.

Charles

Martin Maechler wrote:
> 
> >>>>> "DavidB" == Brown, David <djbrown at montana.edu>
> >>>>>     on Fri, 27 Sep 2002 10:33:33 -0600 writes:
> 
>     DavidB> I've seen references to "polymars", an R
>     DavidB> implementation of Friedman's MARS algorithm.  Can
>     DavidB> anyone tell me where I might be able to find this
>     DavidB> (doesn't seem to be in the contributed packages.
> 
> not visibly anymore, but in "Archive" of old packages, i.e., in
> the States,
>   http://cran.US.r-project.org/src/contrib/Archive/  -> polymars_1.0-5.tar.gz
> 
> Its DESCRIPTION says
> 
>  >> Package: polymars
>  >> Version: 1.0-5
>  >> Title: Polychotomous Regression based on MARS
>  >> Author: Charles Kooperberg and Martin O'Connor
>  >>         R port by Guido Masarotto <guido at sirio.stat.unipd.it>
>  >> Maintainer: Guido Masarotto <guido at sirio.stat.unipd.it>
>  >> Description: (polychotomous) regression based on
>  >>              Multivariate Adaptive Regression Splines
>  >> License: Free for non-commercial purposes. See the original README.
> 
> As far as I remember (from heresay of the CRAN maintainers),
> there have been at least two problems which made it disappear from
> "official" CRAN:
> 
>   - The "Maintainer" did not continue to maintain it when it
>     became evident the package needed some fixes to pass "R CMD check"
>   - The "License" made it no so much useful anyway such as to
>     try to find another maintainer.
> 
> The good news is that Charles Kooperberg recently told me about
> his plans of providing improved code and maintaining it himself
> in the future.
> 
> If Charles (the owner of the code) changes the licence to GPL,
> I'd volunteer to spend a few hours on the package to have it
> pass "R .. check" to be back on CRAN till Charles' new code will
> appear.
> 
> Martin Maechler <maechler at stat.math.ethz.ch>    http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16    Leonhardstr. 27
> ETH (Federal Inst. Technology)  8092 Zurich     SWITZERLAND
> phone: x-41-1-632-3408          fax: ...-1228                   <><

-- 
------------------------------------------------------------------------
Charles Kooperberg        
Fred Hutchinson Cancer Research Center  (206) 667-7808
Division of Public Health Sciences      (206) 667-4142 (fax)
1100 Fairview Avenue / MP 1002          clk at fhcrc.org
Seattle, WA 98109-1024                  http://bear.fhcrc.org/~clk
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Oct  2 17:25:53 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 Oct 2002 17:25:53 +0200
Subject: [R] output from script
In-Reply-To: <200210021201.g92C1OX19213@mailgate5.cinetic.de>
References: <200210021201.g92C1OX19213@mailgate5.cinetic.de>
Message-ID: <x2bs6cq2v2.fsf@biostat.ku.dk>

Wolfgang Grond <wolfgang.grond at web.de> writes:

> sum_input = summary(mydatatable)
     *
Check the syntax! "_" is an alias for the assignment operator "<-".
(That's because an adm3a terminal back in the stone age used to print
that character as a left-arrow.) It's being deprecated in 1.6.0, but
it will take a while before you can use it in variable names.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Oct  2 17:53:52 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 2 Oct 2002 08:53:52 -0700 (PDT)
Subject: [R] 2 plots sharing axis / combining factors
In-Reply-To: <E09E527B56BE2D438A3D6A246DDD27A91654D4@Roper-CV.qld.cmis.csiro.au>
Message-ID: <Pine.A41.4.44.0210020853030.138456-100000@homer34.u.washington.edu>

On Wed, 2 Oct 2002 Bill.Venables at CMIS.CSIRO.AU wrote:

> Two short replies to Thomas's answer:
>
> "strata" is from the survival package.
>

Yes. There was discussion about migrating it into base, and I thought that
had happened, but it didn't.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From f.calboli at ucl.ac.uk  Wed Oct  2 18:24:49 2002
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: Wed, 02 Oct 2002 17:24:49 +0100
Subject: [R] drop1
Message-ID: <3.0.6.32.20021002172449.00a1b490@pop-server.ucl.ac.uk>

Dear All,

I was trying to reproduce prof. Venables analysis on Sheffe data for rats:

http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

I have no problems concerning the aov side of the analysis, but I noticed
that drop1 in R gives me a completely different result than those on the
Exegeses. In particular my Sum of Squares and RSS are wildly different.

I used :

> drop1(aov.model1,.~.,test="F")

Single term deletions

Model:
WT ~ Litter + Mother + Litter:Mother
              Df Sum of Sq    RSS    AIC F value   Pr(F)  
<none>                     2440.8  257.0                  
Litter         3     591.7 3032.5  264.3  3.6362 0.01968 *
Mother         3     582.3 3023.1  264.1  3.5782 0.02099 *
Litter:Mother  9     824.1 3264.9  256.8  1.6881 0.12005  

which is pretty different form prof. Venables results:

Model:
Wt ? Litter * Mother
	Df 	Sum of Sq RSS 	F Value 	Pr(F)
<none> 	2440.816
Litter	 3 	27.6559 2468.472 0.169959 0.9161176
Mother 	3 	671.7376 3112.554 4.128153 0.0114165
Litter:Mother 9 824.0725 3264.889 1.688108 0.1200530

Any suggestion why?

Regards,
Federico Calboli

=========================

Federico C.F. Calboli

Department of Biology
University College London
Room 327
Darwin Building
Gower Street
London
WClE 6BT

Tel: (+44) 020 7679 4395 
Fax (+44) 020 7679 7096
f.calboli at ucl.ac.uk

=========================



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mail at fwr.on.ca  Wed Oct  2 18:44:45 2002
From: mail at fwr.on.ca (FWR)
Date: Wed, 2 Oct 2002 12:44:45 -0400
Subject: [R] Convert daily to weekly ts ?
Message-ID: <E17wmc9-0006Xq-00@server.family>

Have 3.5 years daily data that I want to convert to weekly. Looking for something like SAS's "expand" function, where you can specify the conversion function (sum, average, etc.) and get a new vector out with different sampling frequencies. 

Anything like that in R ?? Have been looking all over...

Thanks,
B.D.L.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andyj at splash.princeton.edu  Wed Oct  2 19:06:37 2002
From: andyj at splash.princeton.edu (Andy Jacobson)
Date: 02 Oct 2002 13:06:37 -0400
Subject: [R] .C() and C++ name mangling
Message-ID: <f2kadlwvkgy.fsf@tazman.Princeton.EDU>

Howdy,

        I'm working with some external code written in C++, which I
        would like to call via dyn.load() and .C() from R.  The
        function prototype looks like:

        gaRemin(int *, float *, float *, int *, float *, float *, 
                float *, float *, float *)

        but to call this function from R using .C() I have had to use
        the mangled version of this function name,

        gaRemin__FPiPfT1T0T1N41

        Is using the mangled name my best option, or is there some way
        that R knows to interpret unmangled function names from C++
        shared library objects?

        I'm concerned about portability of the resultant code in the
        case that name-mangling is handled differently from platform
        to platform.

        This is Linux, Redhat 7.2 with g++-2.96.

        Thanks for any help you can offer,

                Andy

-- 
Andy Jacobson

arj at gfdl.gov

Program in Atmospheric and Oceanic Sciences
Sayre Hall, Forrestal Campus
Princeton University
PO Box CN710 Princeton, NJ 08544-0710 USA

Tel: 609/258-5260  Fax: 609/258-2850
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Wed Oct  2 19:19:45 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 02 Oct 2002 12:19:45 -0500
Subject: [R] Dataframes and assign
In-Reply-To: <Pine.LNX.4.44.0210021346530.7970-100000@tal.stat.umu.se>
References: <Pine.LNX.4.44.0210021346530.7970-100000@tal.stat.umu.se>
Message-ID: <6rwup0sqq6.fsf@bates3.stat.wisc.edu>

G?ran Brostr?m <gb at stat.umu.se> writes:

> I have the following function:
> 
> putsoc <- function(age, dat){
>   ## age is an integer
>   ## dat is a data.frame
> 
>   new.name <- paste("soc", as.character(age), sep = ".")
>   if (new.name %in% names(dat)) stop(paste(new.name, "already in place"))
> 
>   dat$new.var <- rep(1, nrow(dat)) ## Just nonsense.
> 
>   n.var <- ncol(dat)
>   names(dat)[ncol(dat)] <- new.name
>   return(dat)
> }

The $ operator is 'syntactic sugar' that allows you to write
frm$colname instead of frm[['colname']].  In your case you are
generating the name as a character string so you should use the second
form.  That is, write your function as

putsoc <- function(age, dat) {
   new.name <- paste("soc", as.character(age), sep = ".")
   if (new.name %in% names(dat)) stop(paste(new.name, "already in place"))
 
   dat[[new.var]] <- rep(1, nrow(dat))
   return(dat)
}

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rvaradha at jhsph.edu  Wed Oct  2 19:44:23 2002
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Wed, 02 Oct 2002 13:44:23 -0400
Subject: [R] xtable for Cox model output
Message-ID: <7c62327c6df7.7c6df77c6232@jhsph.edu>

Hi:

I am using R 1.5.0 on Windows.  I was not able to get the xtable 
function in the "xtable" library to recognize a Cox model object 
from "survival" library. I was wondering whether there is another way 
to do this.

thanks,
Ravi.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Wed Oct  2 19:50:46 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 02 Oct 2002 13:50:46 -0400
Subject: [R] T-Distribution
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC738@usrymx10.merck.com>

> From: bojaniss [mailto:bojaniss at poczta.onet.pl]
> 
> Hello Hicham,
> 
> Wednesday, October 2, 2002, 11:28:03 AM, you wrote:
> 
> HZ> Dear sir,
> HZ> I would ask if there are in R some code to generate a 
> random sample 
> HZ> from a mvariate student distribution like that one wich 
> generate the 
> HZ> multivariate normal one i mean( rmvnorm(n, mu, sigma)
> 
> Try rt() function, type ?rt for help.

That's _univariate_ t.  Use the mvtnorm package for multivariate t
distribution.
 
> HZ> Second question : if R can plot density 3Dcurve I don't mean de 
> HZ> histogram but de hole density function(normal for example).
> 
> I think sm.density function in sm package (available on CRAN) will
> do what you want.

That gives the kernel density estimate, given data.  It's not clear what
Hicham wants.  If he wants the _true_ density of a multivariate t, he needs
to contruct a grid (e.g., with expand.grid) and evaluate the multivariate t
density on that grid, then use persp to draw the surface.

Andy
 
> hope this helps
> 
> 
> Michal
> 
> 
> ~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~
> 
> Michal Bojanowski - mbojanowski at samba.iss.uw.edu.pl
> Polish General Social Survey
> Institute for Social Studies
> University of Warsaw
> http://www.iss.uw.edu.pl/
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jyan at stat.wisc.edu  Wed Oct  2 19:59:51 2002
From: jyan at stat.wisc.edu (Jun Yan)
Date: Wed, 2 Oct 2002 12:59:51 -0500 (CDT)
Subject: [R] output from script
In-Reply-To: <200210021201.g92C1OX19213@mailgate5.cinetic.de>
Message-ID: <Pine.LNX.4.21.0210021254230.15810-100000@gstat304.stat.wisc.edu>

If you are using source, you may set echo = TRUE and print.eval =
TRUE. see

?source

Jun

On Wed, 2 Oct 2002, Wolfgang Grond wrote:

> Hi,
> 
> perhaps the answer to my question is obvious and I didnt find it because Im new to R ...
> 
> The problem is as follows:
> I read some data from file, do some commands which are well processed and finally make some graphics. OK
> Then I put these commands together in a *.R file which I can process ...
> 
> Among these i. e. is
> 
> sum_input = summary(mydatatable)
> sum_input
> .....
> plot(mydatatable)
> 
> What happens:
> If in the script the command above comes before a plot command the plot is shown in a graphics window but not the output of the command in the console window. I therefore thought that I should define an active window and changes the order ...
> 
> sum_input = summary(mydatatable)
> plot(mydatatable)
> bringToTop(-1)
> sum_input
> 
> I see the plot, but not the output of sum_input
> 
> Of course, if I input the command from the keyboard, I get an output.
> 
> What happens?
> 
> Many thanks in advance for any help.
> 
> Wolfgang



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dimitrov at gnf.org  Wed Oct  2 21:11:35 2002
From: dimitrov at gnf.org (Peter Dimitrov)
Date: 02 Oct 2002 12:11:35 -0700
Subject: [R] .C() and C++ name mangling
In-Reply-To: <f2kadlwvkgy.fsf@tazman.Princeton.EDU>
References: <f2kadlwvkgy.fsf@tazman.Princeton.EDU>
Message-ID: <1033585895.32214.26.camel@cb3.gnf.org>

Enclose the interface function, in your case gaRemin with extern "C"
statement like this:

extern "C"
{

	gaRemin(int *, float *, float *, int *, float *, float *, 
		float *, float *, float *) {
		...
	}

}

Also, look at the "Writing R Extensions" manual in R help, specifically
the chapter "System and foreign language interfaces", section
"Interfacing C++ code", for more information.

peter

On Wed, 2002-10-02 at 10:06, Andy Jacobson wrote:
> Howdy,
> 
>         I'm working with some external code written in C++, which I
>         would like to call via dyn.load() and .C() from R.  The
>         function prototype looks like:
> 
>         gaRemin(int *, float *, float *, int *, float *, float *, 
>                 float *, float *, float *)
> 
>         but to call this function from R using .C() I have had to use
>         the mangled version of this function name,
> 
>         gaRemin__FPiPfT1T0T1N41
> 
>         Is using the mangled name my best option, or is there some way
>         that R knows to interpret unmangled function names from C++
>         shared library objects?
> 
>         I'm concerned about portability of the resultant code in the
>         case that name-mangling is handled differently from platform
>         to platform.
> 
>         This is Linux, Redhat 7.2 with g++-2.96.
> 
>         Thanks for any help you can offer,
> 
>                 Andy
> 
> -- 
> Andy Jacobson
> 
> arj at gfdl.gov
> 
> Program in Atmospheric and Oceanic Sciences
> Sayre Hall, Forrestal Campus
> Princeton University
> PO Box CN710 Princeton, NJ 08544-0710 USA
> 
> Tel: 609/258-5260  Fax: 609/258-2850
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chrysopa at insecta.ufv.br  Wed Oct  2 21:26:50 2002
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Wed, 2 Oct 2002 16:26:50 -0300
Subject: [R] help to make a map on R
Message-ID: <200210021626.50618.chrysopa@insecta.ufv.br>

Hi all,
I need a little help for construct an state's map on R.

The first problem is to get the data.

I have a datafile of longitude and latitude in the follow format:

trajectory	latitude	longtude
T		-22.045618	-51.287056
T		-22.067078	-51.265888
T		-22.067039	-51.207249

T		-22.059690	-48.089695
T		-22.075529	-48.074608
T		-22.072460	-48.044472

T		-22.062767	-48.298473
T		-22.077349	-48.322140
T		-22.047001	-48.347443
T		-22.054266	-48.369331
T		-22.042810	-48.392612
T		-22.064812	-48.422195
T		-22.062544	-48.443497

To read a file is simple, but I need that R change the value of
trajectory after a blank line, reading something like this:

trajectory	latitude	longitude
T1		-22.045618	-51.287056
T1		-22.067078	-51.265888
T1		-22.067039	-51.207249
T2		-22.059690	-48.089695
T2		-22.075529	-48.074608
T2		-22.072460	-48.044472
T3		-22.062767	-48.298473
T3		-22.077349	-48.322140
T3		-22.047001	-48.347443
T3		-22.054266	-48.369331
T3		-22.042810	-48.392612
T3		-22.064812	-48.422195
T3		-22.062544	-48.443497

Each trajectory is a line that is a little piece of my map.

After this, to make a map I execute:

tapply() for separate the coordinates for each trajectory, something like 
this:

> longitude <- tapply(longitude,trajectory,c)
> longitude
$T1
[1] -51.2871 -51.2659 -51.2072

$T2
[1] -48.0897 -48.0746 -48.0445

$T3
[1] -48.2985 -48.3221 -48.3474 -48.3693 -48.3926 -48.4222 -48.4435

> latitude <- tapply(latitude,trajectory,c)
> latitude
$T1
[1] -22.0456 -22.0671 -22.0670

$T2
[1] -22.0597 -22.0755 -22.0725

$T3
[1] -22.0628 -22.0773 -22.0470 -22.0543 -22.0428 -22.0648 -22.0625

The nest step is to make a plot with the coordinates.

> plot(longitude,latitude, asp = 1, type = "n")

And finally plot the lines for each trajectory, and all lines together, 
make a Sao Paulo's map and your cities limits.

> lines(longitude$T1,latitude$T1)
> lines(longitude$T2,latitude$T2)
> lines(longitude$T3,latitude$T3)

How can I make to automatized this process? Because I can about 3000 
trajectory.

Any other idea for make this is welcome.


Thanks for all

Inte mais
Ronaldo
-- 
And Bruce is effectively building BruceIX
	-- Alan Cox
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][SO: CL 7.0 (2.2.19)]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Conectiva Linux 7.0 D+:) | Lxuser#: 205366

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rajeet_nair at yahoo.com  Wed Oct  2 21:37:20 2002
From: rajeet_nair at yahoo.com (Rajeet Nair)
Date: Wed, 2 Oct 2002 12:37:20 -0700 (PDT)
Subject: [R] Calling R functions from C++ code
Message-ID: <20021002193720.43576.qmail@web21505.mail.yahoo.com>

Hi
Just wanted to know if it is possible to call R
functions through a C++ application. Like a C++
program which takes data input from the user and the
choice of operation that has to be performed on that
data then passes this data to the particular R
function .
If yes where could I get some examples of such
programs.
Rajeet N

__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Wed Oct  2 21:45:46 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 2 Oct 2002 21:45:46 +0200 (CEST)
Subject: [R] Atlas shared
In-Reply-To: <E17wk6p-0006sV-00@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.44.0210022130410.10002-100000@tal.stat.umu.se>

I got several answers to my question about shared atlas libraries,
see below, where you also find Dirk Eddelbuettel's answer. I tried his
'lazy' alternative by using 'alien' on my Debian system to get  .rpm
versions of the  .deb  libraries. This worked fine. I had to rebuild
R, though.

Dirk's 'hard work' alternative was also (in essence) suggested by
Douglas Bates, Reid Huntsinger, and Camm Maguire. I haven't tried
it yet, but I may when time permits.

Roger Peng suggested that it should be possible to link with
the _static_ libraries. Haven't checked, and haven't noticed any
reaction to his suggestion either. Would be nice if it worked.

Many thanks to all who answered!

G?ran

On Wed, 2 Oct 2002, Dirk Eddelbuettel wrote:

>
> > In a FAQ on an ATLAS home page I see that shared libraries are not
> > supported, and indeed, when I build from source I only get static
> > libraries. R  needs shared libraries (right?!), so how do I get that?
> > With Debian (and Windows?) there are no problems, since there are
> > prebuilt shared libraries, but how about RedHat? (These are my three
> > systems.)
> >
> > How do I get shared atlas libraries that work with  R  on RedHat?
>
> You could try to fudge it and simply place the Debian libraries onto
> a RH system, preferably by converting the .deb into a .rpm via the alien
> program.
>
> Or you could study the build process of Debian's atlas package and apply
> it to a .rpm.  My recollection from talking to our Atlas maintainer is that
> this is not a straightforward process -- so your cost/benefit analysis might
> lead you to the first solution.
>
> Dirk
>
> --
> According to the latest figures, 43% of all signatures are totally worthless.
>

---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ivo.Bloechliger at epfl.ch  Wed Oct  2 21:51:08 2002
From: Ivo.Bloechliger at epfl.ch (Ivo Bloechliger)
Date: Wed, 2 Oct 2002 21:51:08 +0200
Subject: [R] Your application is on GNUWin II
Message-ID: <15771.20012.939016.56588@gargle.gargle.HOWL>

	       [was caught as "spam" for R-announce;
	        manually sent to R-help instead:  MM ]

We are very pleased to inform you, that we have included your 
application (for which you are listed as author or contact person) into 
GNUWin II (http://gnuwin.epfl.ch). We would like to thank you for your 
contribution to the world of free software.

  {Moderator: This is a cheap CD-ROM full of GNU Software for Windows incl. R }

GNUWin shall help to introduce users to free software, to show that it 
exists (and works!) and to ease a future migration to an entirely free 
system, like GNU/Linux for instance.

GNUWin itself is meant to be 'libre' (free in the sens of the GPL). You 
can find iso images of GNUWin on the Swiss Sunsite Mirror at
ftp://sunsite.cnlab-switch.ch/mirror/gnuwin/
http://sunsite.cnlab-switch.ch/ftp/mirror/gnuwin/

or from our (for the moment somewhat loaded) site at 
http://gnuwin.epfl.ch/iso/

Note: Some few applications have been added very recently only, and may 
not be on the ISO image yet. Sorry about that.

    Best regards
    GNU Generation (http://gnugeneration.epfl.ch)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Wed Oct  2 22:04:32 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 2 Oct 2002 22:04:32 +0200 (CEST)
Subject: [R] Dataframes and assign
In-Reply-To: <6rwup0sqq6.fsf@bates3.stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0210022151540.10029-100000@tal.stat.umu.se>

Douglas,

this was exactly what I needed! And new to me.

Thanks,

G?ran

On 2 Oct 2002, Douglas Bates wrote:

> G?ran Brostr?m <gb at stat.umu.se> writes:
>
> > I have the following function:
> >
> > putsoc <- function(age, dat){
> >   ## age is an integer
> >   ## dat is a data.frame
> >
> >   new.name <- paste("soc", as.character(age), sep = ".")
> >   if (new.name %in% names(dat)) stop(paste(new.name, "already in place"))
> >
> >   dat$new.var <- rep(1, nrow(dat)) ## Just nonsense.
> >
> >   n.var <- ncol(dat)
> >   names(dat)[ncol(dat)] <- new.name
> >   return(dat)
> > }
>
> The $ operator is 'syntactic sugar' that allows you to write
> frm$colname instead of frm[['colname']].  In your case you are
> generating the name as a character string so you should use the second
> form.  That is, write your function as
>
> putsoc <- function(age, dat) {
>    new.name <- paste("soc", as.character(age), sep = ".")
>    if (new.name %in% names(dat)) stop(paste(new.name, "already in place"))
>
>    dat[[new.var]] <- rep(1, nrow(dat))
>    return(dat)
> }
>

---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mail at fwr.on.ca  Wed Oct  2 22:56:17 2002
From: mail at fwr.on.ca (FWR)
Date: Wed, 2 Oct 2002 16:56:17 -0400
Subject: [R] Re: Convert daily to weekly ts ?
Message-ID: <E17wqXa-0006aQ-00@server.family>

>Have 3.5 years daily data that I want to convert to weekly. Looking for something 
> like SAS's "expand" function, where you can specify the conversion function (sum, 
> average, etc.) and get a new vector out with different sampling frequencies.

OK, think I see what to do. The ts class has no calendar/date functions, it assumes a constant delta-t. So I could use "aggregate.ts" on my daily data with a ts having a defined frequency of 364 and knock it down to 52. That would work ok.

However, for calendar/date based aggregation to monthly/quarterly/yearly summaries I need to first create the appropriate factor based on a POSIX date vector and then use that in the "by" variable of "aggregate.data.frame"

I think  ...
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jim.Sfiridis at business.uconn.edu  Wed Oct  2 23:07:14 2002
From: Jim.Sfiridis at business.uconn.edu (Jim Sfiridis)
Date: Wed, 2 Oct 2002 17:07:14 -0400 
Subject: [R] Downloading the basic package
Message-ID: <D7A2FF1C042CD4119BD5009027E400AA039E9061@enterprise3.business.uconn.edu>

Hi, everyone! I downloaded the zip file for installing the basic package of
R, but when I went to unzip the files using the install option, I could not
do it. I was only able to extract the files, but couldn't open R without a
file with the 'EXE' suffix. Has anyone had a similar problem? Any solutions,
please? Thanks. Jim Sfiridis, University of Connecticut, USA. 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From magnus at hetland.org  Wed Oct  2 23:30:51 2002
From: magnus at hetland.org (Magnus Lie Hetland)
Date: Wed, 2 Oct 2002 23:30:51 +0200
Subject: [R] help to make a map on R
In-Reply-To: <200210021626.50618.chrysopa@insecta.ufv.br>; from chrysopa@insecta.ufv.br on Wed, Oct 02, 2002 at 04:26:50PM -0300
References: <200210021626.50618.chrysopa@insecta.ufv.br>
Message-ID: <20021002233051.A21885@idi.ntnu.no>

Ronaldo Reis Jr. <chrysopa at insecta.ufv.br>:
>
> Hi all,
> I need a little help for construct an state's map on R.
> 
> The first problem is to get the data.
> 
> I have a datafile of longitude and latitude in the follow format:
[snip]
> To read a file is simple, but I need that R change the value of
> trajectory after a blank line, reading something like this:
> Each trajectory is a line that is a little piece of my map.
[snip]

Not sure if this is heresy ;) but this sort of thing would be very
easy to do with a programming language such as Python, Ruby, or Perl
(or even awk) as a preprocessing step.

For example (in Python):

----------------------------------------------------------------------
num = 1
lines = iter(open('map.data'))
print lines.next(),
for line in lines:
    if line.isspace():
        num += 1
    else:
        fields = line.split()
        fields[0] += str(num)
	print '\t'.join(fields)
----------------------------------------------------------------------

Just a thought :)

-- 
Magnus Lie Hetland        Practical Python          The Anygui Project
http://hetland.org        http://ppython.com        http://anygui.org
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From s-luppescu at uchicago.edu  Wed Oct  2 23:14:04 2002
From: s-luppescu at uchicago.edu (Stuart Luppescu)
Date: 02 Oct 2002 16:14:04 -0500
Subject: [R] Atlas shared
In-Reply-To: <6ry99ht0x0.fsf@bates3.stat.wisc.edu>
References: <Pine.LNX.4.44.0210020854520.7587-100000@tal.stat.umu.se> 
	<6ry99ht0x0.fsf@bates3.stat.wisc.edu>
Message-ID: <1033593244.7116.9.camel@musuko.uchicago.edu>

On Wed, 2002-10-02 at 08:39, Douglas Bates wrote:
> The atlas developers don't like shared libraries because position
> independent code takes a performance hit.  Their objective is to get
> the absolute best performance so they only produce static libraries.

I thought the idea with atlas was that the libraries should be
specifically optimized for and built on the machine it will be run on.
At least I'm *hoping* that the 5 hours it took to build atlas on my
Athlon XP 2100 Gentoo linux box were worth it.
-- 
Stuart Luppescu -=- s-luppescu at uchicago.edu        
University of Chicago -=- CCSR 
$B:MJ8$HCRF`H~$NIc(B -=-    Kernel 2.4.19-xfs-r1                
There's only one everything. 
 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: This is a digitally signed message part
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021002/2a3ef422/attachment.bin

From bates at stat.wisc.edu  Wed Oct  2 23:41:52 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 02 Oct 2002 16:41:52 -0500
Subject: [R] .C() and C++ name mangling
In-Reply-To: <f2kadlwvkgy.fsf@tazman.Princeton.EDU>
References: <f2kadlwvkgy.fsf@tazman.Princeton.EDU>
Message-ID: <6r4rc4plgf.fsf@bates3.stat.wisc.edu>

Andy Jacobson <andyj at splash.princeton.edu> writes:

> Howdy,
> 
>         I'm working with some external code written in C++, which I
>         would like to call via dyn.load() and .C() from R.  The
>         function prototype looks like:
> 
>         gaRemin(int *, float *, float *, int *, float *, float *, 
>                 float *, float *, float *)
> 
>         but to call this function from R using .C() I have had to use
>         the mangled version of this function name,
> 
>         gaRemin__FPiPfT1T0T1N41
> 
>         Is using the mangled name my best option, or is there some way
>         that R knows to interpret unmangled function names from C++
>         shared library objects?
> 
>         I'm concerned about portability of the resultant code in the
>         case that name-mangling is handled differently from platform
>         to platform.
> 
>         This is Linux, Redhat 7.2 with g++-2.96.
> 
>         Thanks for any help you can offer,
> 
>                 Andy
> 
> -- 
> Andy Jacobson
> 
> arj at gfdl.gov
> 
> Program in Atmospheric and Oceanic Sciences
> Sayre Hall, Forrestal Campus
> Princeton University
> PO Box CN710 Princeton, NJ 08544-0710 USA
> 
> Tel: 609/258-5260  Fax: 609/258-2850
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r.hankin at auckland.ac.nz  Wed Oct  2 23:38:22 2002
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Thu, 3 Oct 2002 09:38:22 +1200
Subject: [R] R vs Fortran
Message-ID: <200210022138.g92LcMx10901@r.hankin.sges.auckland.ac.nz>


Dear R experts

I work in computational fluid dynamics in 2D: I have a 200-by-200
array of fluid properties such as density and velocity and these
evolve in time (the precise equations depend on the problem).

Up to now, I've been using Fortran and the code is very very messy.
It works, but a professional programmer friend of mine saw the source
code once, and had to be strapped down for his own (and my!) safety.
It's time to rewrite it in a more object-oriented manner.

I have a couple of options: port the thing to c++, or deal directly in
R.  The R route has a number of advantages.  For example, I deal with
fluxes between adjacent chessboard-square-style elements.  The Fortran
idiom is:


    do 10 i=1,200
      do 20 j=1,200
        flux(i,j) = ( r(i,j)*u(i+1,j) + r(i+1,j)*u(i,j) ) /2
20    continue
10  continue

where r is the density and u the x-component of velocity.  I might
need to do this or similar-looking things such as u(i+1,j)*v(i,j+1)
perhaps a hundred times in my Fortran code.  But in R we could have

flux =  ( r*right(u) + right(r)*u ) /2

[where right <- function(x){cbind(x[,-1],NA)} ]

To my mind, the functional form is much better: it's vectorized and
clear and terse.  My question is, is it fast? (or more precisely, how
much slower would this nice approach be than my clunky old Fortran).
I guess I could tolerate a factor of two or three, and wait for a
shiny next-generation PC.


any comments anyone?




-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

as of: Thu Oct  3 09:30:01 NZST 2002
This (linux) system up continuously for:  399 days, 16 hours, 12 minutes
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Richard.Rowe at jcu.edu.au  Wed Oct  2 23:42:51 2002
From: Richard.Rowe at jcu.edu.au (Richard Rowe)
Date: Thu, 03 Oct 2002 07:42:51 +1000
Subject: [R] Re: Workshop: DSC 2003
In-Reply-To: <15770.63670.972703.294768@galadriel.ci.tuwien.ac.at>
Message-ID: <5.0.0.25.1.20021003074053.03c838a0@pop.jcu.edu.au>

At 15:46 02/10/02 +0200, you wrote:
>We invite papers on topics related to statistical computing.  Deadline
>for submission of papers is 2002-11-30.  Notification about acceptance
>or rejection will be sent before 2002-01-31.

It's not that I'm coming, but there seems to be a timing problem (now how 
do you do one of those tongue in cheek things?)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct  3 00:32:37 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Oct 2002 00:32:37 +0200
Subject: [R] Atlas shared
In-Reply-To: <Pine.LNX.4.44.0210022130410.10002-100000@tal.stat.umu.se>
References: <Pine.LNX.4.44.0210022130410.10002-100000@tal.stat.umu.se>
Message-ID: <x2y99gmpyy.fsf@biostat.ku.dk>

G?ran Brostr?m <gb at stat.umu.se> writes:


> Roger Peng suggested that it should be possible to link with
> the _static_ libraries. Haven't checked, and haven't noticed any
> reaction to his suggestion either. Would be nice if it worked.

That works fine. As far as I remember you just need to set LDFLAGS
with the relevant -L option, e.g.

LDFLAGS=-L/usr/src/pd/ATLAS/lib/Linux_PIIISSE1_2/ ./configure
make

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct  3 00:45:29 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Oct 2002 00:45:29 +0200
Subject: [R] R vs Fortran
In-Reply-To: <200210022138.g92LcMx10901@r.hankin.sges.auckland.ac.nz>
References: <200210022138.g92LcMx10901@r.hankin.sges.auckland.ac.nz>
Message-ID: <x2u1k4mpdi.fsf@biostat.ku.dk>

Robin Hankin <r.hankin at auckland.ac.nz> writes:

> 
>     do 10 i=1,200
>       do 20 j=1,200
>         flux(i,j) = ( r(i,j)*u(i+1,j) + r(i+1,j)*u(i,j) ) /2
> 20    continue
> 10  continue
> 
> where r is the density and u the x-component of velocity.  I might
> need to do this or similar-looking things such as u(i+1,j)*v(i,j+1)
> perhaps a hundred times in my Fortran code.  But in R we could have
> 
> flux =  ( r*right(u) + right(r)*u ) /2
> 
> [where right <- function(x){cbind(x[,-1],NA)} ]
> 
> To my mind, the functional form is much better: it's vectorized and
> clear and terse.  My question is, is it fast? (or more precisely, how
> much slower would this nice approach be than my clunky old Fortran).
> I guess I could tolerate a factor of two or three, and wait for a
> shiny next-generation PC.
> 
> 
> any comments anyone?

I would be highly surprised if it turned out to be even remotely fast
in R...

This kind of thing generally needs a compiled language like C(++) or
Fortran. Preferably with good optimisers.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jyan at stat.wisc.edu  Thu Oct  3 00:47:56 2002
From: jyan at stat.wisc.edu (Jun Yan)
Date: Wed, 2 Oct 2002 17:47:56 -0500 (CDT)
Subject: [R] xtable for Cox model output
In-Reply-To: <7c62327c6df7.7c6df77c6232@jhsph.edu>
Message-ID: <Pine.LNX.4.21.0210021715180.30865-100000@ludwig.stat.wisc.edu>

This is because there is no method of xtable for class "coxph". However,
you may always apply xtable on data.frame or matrix. The following
function creates a matrix tmp (as in summary.coxph) and apply xtable on
it.

xtable.coxph <- 
function (x, caption = NULL, label = NULL, align = NULL, vsep = NULL, 
    digits = NULL, display = NULL) 
{
    cox <- x
    beta <- cox$coef
    se <- sqrt(diag(cox$var))
    if (is.null(cox$naive.var)) {
      tmp <- cbind(beta, exp(beta), se, beta/se, 1 - pchisq((beta/se)^2,
1))
      dimnames(tmp) <- list(names(beta), c("coef", "exp(coef)", 
                                           "se(coef)", "z", "p"))
    }
    else {
      tmp <- cbind(beta, exp(beta), nse, se, beta/se, signif(1 -
pchisq((beta/se)^2, 1), digits - 1))
      dimnames(tmp) <- list(names(beta), c("coef", "exp(coef)", 
                                           "se(coef)", "robust se", "z",
"p"))
    }
    xtable(tmp, caption = NULL, label = NULL, align = NULL, vsep = NULL, 
           digits = NULL, display = NULL)
}



On Wed, 2 Oct 2002, Ravi Varadhan wrote:

> Hi:
> 
> I am using R 1.5.0 on Windows.  I was not able to get the xtable 
> function in the "xtable" library to recognize a Cox model object 
> from "survival" library. I was wondering whether there is another way 
> to do this.
> 
> thanks,
> Ravi.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Thu Oct  3 02:19:37 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 02 Oct 2002 20:19:37 -0400
Subject: [R] drop1
In-Reply-To: <3.0.6.32.20021002172449.00a1b490@pop-server.ucl.ac.uk>
Message-ID: <5.1.0.14.2.20021002201554.01dae630@mcmail.cis.mcmaster.ca>

Dear Federico,

At 05:24 PM 10/2/2002 +0100, Federico Calboli wrote:
>Dear All,
>
>I was trying to reproduce prof. Venables analysis on Sheffe data for rats:
>
>http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf
>
>I have no problems concerning the aov side of the analysis, but I noticed
>that drop1 in R gives me a completely different result than those on the
>Exegeses. In particular my Sum of Squares and RSS are wildly different.
>
>I used :
>
> > drop1(aov.model1,.~.,test="F")
>
>Single term deletions
>
>Model:
>WT ~ Litter + Mother + Litter:Mother
>               Df Sum of Sq    RSS    AIC F value   Pr(F)
><none>                     2440.8  257.0
>Litter         3     591.7 3032.5  264.3  3.6362 0.01968 *
>Mother         3     582.3 3023.1  264.1  3.5782 0.02099 *
>Litter:Mother  9     824.1 3264.9  256.8  1.6881 0.12005
>
>which is pretty different form prof. Venables results:
>
>Model:
>Wt ? Litter * Mother
>         Df      Sum of Sq RSS   F Value         Pr(F)
><none>  2440.816
>Litter  3       27.6559 2468.472 0.169959 0.9161176
>Mother  3       671.7376 3112.554 4.128153 0.0114165
>Litter:Mother 9 824.0725 3264.889 1.688108 0.1200530
>
>Any suggestion why?

The default contrast type for unordered factors is different in S-Plus and 
R: In S-Plus it is contr.helmert; in R, contr.treatment. You can obtain the 
published results by, e.g., setting the contrast type explicitly:

     > mod.1 <- aov(Wt ~ Litter*Mother, data=genotype)
     > drop1(mod.1, .~., test="F")
     Single term deletions

     Model:
     Wt ~ Litter + Mother + Litter:Mother
                 Df Sum of Sq    RSS    AIC F value   Pr(F)
     <none>                     2440.8  257.0
     Litter         3     591.7 3032.5  264.3  3.6362 0.01968
     Mother         3     582.3 3023.1  264.1  3.5782 0.02099
     Litter:Mother  9     824.1 3264.9  256.8  1.6881 0.12005

     > mod.2 <- update(mod.1,
     +     contrasts=list(Litter=contr.helmert, Mother=contr.helmert))
     > drop1(mod.2, .~., test="F")
     Single term deletions

     Model:
     Wt ~ Litter + Mother + Litter:Mother
                 Df Sum of Sq    RSS    AIC F value   Pr(F)
     <none>                     2440.8  257.0
     Litter         3      27.7 2468.5  251.7  0.1700 0.91612
     Mother         3     671.7 3112.6  265.9  4.1282 0.01142
     Litter:Mother  9     824.1 3264.9  256.8  1.6881 0.12005

Regards,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bill.Venables at cmis.csiro.au  Thu Oct  3 02:20:44 2002
From: Bill.Venables at cmis.csiro.au (Bill.Venables@cmis.csiro.au)
Date: Thu, 3 Oct 2002 10:20:44 +1000 
Subject: [R] drop1
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A91654E5@Roper-CV.qld.cmis.csiro.au>

The explanation is simple.  The default R contrasts are

options(contrasts=c("contr.treatments", "contr.poly"))

whereas for S-PLUS (on which I worked) they are

options(contrasts=c("contr.helmert", "contr.poly"))

If you declare these as the contrasts (or indeed any of the standard
contrast matrix generators EXCEPT contr.treatment) you should get the same
answers as published in the Exegeses paper.

Someday I really need to update and publish that old thing... Hmm.

Bill Venables.

-----Original Message-----
From: Federico Calboli [mailto:f.calboli at ucl.ac.uk]
Sent: Thursday, October 03, 2002 2:25 AM
To: r-help at stat.math.ethz.ch
Subject: [R] drop1


Dear All,

I was trying to reproduce prof. Venables analysis on Sheffe data for rats:

http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

I have no problems concerning the aov side of the analysis, but I noticed
that drop1 in R gives me a completely different result than those on the
Exegeses. In particular my Sum of Squares and RSS are wildly different.

I used :

> drop1(aov.model1,.~.,test="F")

Single term deletions

Model:
WT ~ Litter + Mother + Litter:Mother
              Df Sum of Sq    RSS    AIC F value   Pr(F)  
<none>                     2440.8  257.0                  
Litter         3     591.7 3032.5  264.3  3.6362 0.01968 *
Mother         3     582.3 3023.1  264.1  3.5782 0.02099 *
Litter:Mother  9     824.1 3264.9  256.8  1.6881 0.12005  

which is pretty different form prof. Venables results:

Model:
Wt ~ Litter * Mother
	Df 	Sum of Sq RSS 	F Value 	Pr(F)
<none> 	2440.816
Litter	 3 	27.6559 2468.472 0.169959 0.9161176
Mother 	3 	671.7376 3112.554 4.128153 0.0114165
Litter:Mother 9 824.0725 3264.889 1.688108 0.1200530

Any suggestion why?

Regards,
Federico Calboli

=========================

Federico C.F. Calboli

Department of Biology
University College London
Room 327
Darwin Building
Gower Street
London
WClE 6BT

Tel: (+44) 020 7679 4395 
Fax (+44) 020 7679 7096
f.calboli at ucl.ac.uk

=========================



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Thu Oct  3 02:30:36 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 02 Oct 2002 20:30:36 -0400
Subject: [R] Parameterisation of interaction terms in lm
In-Reply-To: <3D9AFD5F.2060007@inpharmatica.co.uk>
Message-ID: <5.1.0.14.2.20021002202053.02dd1350@mcmail.cis.mcmaster.ca>

Dear Luke,

At 03:06 PM 10/2/2002 +0100, Luke Whitaker wrote:

>I have a 2 factor linear model, in which the only terms I am interested in 
>estimating and
>testing are the interaction terms. I want to control for the main effects 
>but have no interest
>in estimating or testing them. However, I would like an estimate of the 
>interaction effects
>for every level of the interactions, whereas what I get is one fewer 
>estimate than this, with the
>first level apparently used as a baseline.
>
>For example, suppose factor A has 2 levels, and factor B has 4 levels, I 
>would like 4 estimates,
>one for each level of B, showing how much different the actual A*B effect 
>is from what it would
>be if there were no interaction. I suspect it is necessary to assume the 
>mean interaction is zero in
>order to be estimable.
>
>Although the experiment was designed to be balanced, there are some 
>missing data, but no empty
>cells. The experiment is actually a gene expression micro array, where A 
>is tissue type and B represents
>a number of genes of interest.
>
>I have searched the archives, and read the docs relating to contrasts, but 
>only succeeded in getting
>confused. I would be very grateful if someone could point me to the solution.

Estimating interactions depends upon how the factors are resolved into 
contrasts. For example, for the default "treatment" contrasts 
(contr.treatment), the coefficients for the omitted levels are implicitly 
set to 0.

 From your description, it sounds as if you want "sum-to-zero" contrasts 
(contr.sum), obtained in R in several ways -- for example, by resetting the 
contrasts option for unordered factors, or by specifying the contrasts 
argument to lm.

Using contr.sum, you'll still get one fewer coefficient than level for each 
factor, but you can fill in the missing coefficients for the interactions 
by taking the negatives of the sums of the estimates in each row and column 
(since the estimates are constrained to sum to 0 over each coordinate).

Whether this is really of more interest than simply examining the cell 
means is another question.

I hope that this helps,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kwan022 at stat.auckland.ac.nz  Thu Oct  3 02:48:13 2002
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu, 3 Oct 2002 12:48:13 +1200 (NZST)
Subject: [R] ts() object
Message-ID: <Pine.SOL.4.21.0210031246520.22847-100000@stat1.stat.auckland.ac.nz>

Hi,

Suppose I got a ts() object that looks like:
      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec
1983  587  498  617  502  566  495  500  522  592  574  629  400
1984  620  545  550  500  604  533  547  596  530  616  672  412
1985  625  497  624  540  645  493  604  610  505  650  633  403

and I'd like to extract out 1984 data.  How can I do it?  I tried to
subset it as I'd have done with data frames or matrices, but it didn't
work (as the object is not a data frame nor a matrix).

Cheers,

Kevin

------------------------------------------------------------------------------
Ko-Kang Kevin Wang
Postgraduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Thu Oct  3 02:48:39 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed, 2 Oct 2002 20:48:39 -0400
Subject: [R] xtable for Cox model output
In-Reply-To: <7c62327c6df7.7c6df77c6232@jhsph.edu>
References: <7c62327c6df7.7c6df77c6232@jhsph.edu>
Message-ID: <20021002204839.0c4eb206.fharrell@virginia.edu>

On Wed, 02 Oct 2002 13:44:23 -0400
Ravi Varadhan <rvaradha at jhsph.edu> wrote:

> Hi:
> 
> I am using R 1.5.0 on Windows.  I was not able to get the xtable 
> function in the "xtable" library to recognize a Cox model object 
> from "survival" library. I was wondering whether there is another way 
> to do this.
> 
> thanks,
> Ravi.
> 
>

library(Design)   # uses library(survival) and library(Hmisc)
f <- cph(Surv(dtime,event) ~ ...., surv=TRUE) # modification of coxph
w <- latex(f)   # creates f.tex for LaTeX representation of model fit

latex.cph will represent regression splines (from rcs(x,knots)) and interactions in good algebraic form.

Frank Harrell
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From yuelin at pandora.outcomes.chop.edu  Thu Oct  3 04:47:08 2002
From: yuelin at pandora.outcomes.chop.edu (Yuelin Li)
Date: Wed, 2 Oct 2002 22:47:08 -0400 (EDT)
Subject: [R] install.packages("grid") failed
Message-ID: <200210030247.g932l8i06726@pandora.outcomes.chop.edu>

I just successfully compiled R-1.6.0 on a Red Hat 7.2 machine.  When I 
tried to install "grid" from source, I got this error.  Any 
suggestions?  I don't think it is a dependency problem.  I also attach 
the output from library().

Yuelin Li.

-------------
> install.packages("grid")
trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 84585 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... ..
downloaded 82Kb

trying URL `http://cran.r-project.org/src/contrib/grid_0.6-1.tar.gz'
Content type `application/x-tar' length 139516 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... ......
downloaded 136Kb

* Installing *source* package 'grid' ...
** libs
gcc -I/usr/local/lib/R/include  -I/usr/local/include 
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c gpar.c -o gpar.o
gcc -I/usr/local/lib/R/include  -I/usr/local/include 
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c grid.c -o grid.o
grid.c: In function `L_text':
grid.c:1091: warning: passing arg 9 of `GEText' makes pointer from 
integer without a cast
grid.c:1091: incompatible type for argument 12 of `GEText'
grid.c:1091: too few arguments to function `GEText'
make: *** [grid.o] Error 1
ERROR: compilation failed for package 'grid'

Delete downloaded files (y/N)? y


-----  output from library() ----------

Packages in library `/usr/local/lib/R/library':

base                    The R base package
boot                    Bootstrap R (S-Plus) Functions (Canty)
class                   Functions for classification
cluster                 Functions for clustering (by Rousseeuw et al.)
ctest                   Classical Tests
eda                     Exploratory Data Analysis
foreign                 Read data stored by Minitab, S, SAS, SPSS,
                        Stata, ...
gregmisc                Greg's Miscellaneous Functions
grid                    The Grid Graphics Package
KernSmooth              Functions for kernel smoothing for Wand &
                        Jones (1995)
lattice                 Lattice Graphics
lqs                     Resistant Regression and Covariance Estimation
MASS                    Main Library of Venables and Ripley's MASS
methods                 Formal Methods and Classes
mgcv                    Multiple smoothing parameter estimation and
                        GAMs by GCV
modreg                  Modern Regression: Smoothing and Local Methods
mva                     Classical Multivariate Analysis
nlme                    Linear and nonlinear mixed effects models
nnet                    Feed-forward neural networks and multinomial
                        log-linear models
rpart                   Recursive partitioning
SASmixed                Data sets from "SAS System for Mixed Models"
spatial                 functions for kriging and point pattern
                        analysis
splines                 Regression Spline Functions and Classes
stepfun                 Step Functions, including Empirical
                        Distributions
survival                Survival analysis, including penalised
                        likelihood.
tcltk                   Interface to Tcl/Tk
tools                   Tools for Package Development and
                        Administration
ts                      Time series functions
xgobi                   Interface to the XGobi and XGvis programs for
                        graphical data analysis


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From edd at debian.org  Thu Oct  3 05:15:35 2002
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 2 Oct 2002 22:15:35 -0500
Subject: [R] ts() object
In-Reply-To: <Pine.SOL.4.21.0210031246520.22847-100000@stat1.stat.auckland.ac.nz>
References: <Pine.SOL.4.21.0210031246520.22847-100000@stat1.stat.auckland.ac.nz>
Message-ID: <20021003031535.GA438@sonny.eddelbuettel.com>

On Thu, Oct 03, 2002 at 12:48:13PM +1200, Ko-Kang Kevin Wang wrote:
> Hi,
> 
> Suppose I got a ts() object that looks like:
>       Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec
> 1983  587  498  617  502  566  495  500  522  592  574  629  400
> 1984  620  545  550  500  604  533  547  596  530  616  672  412
> 1985  625  497  624  540  645  493  604  610  505  650  633  403
> 
> and I'd like to extract out 1984 data.  How can I do it?  I tried to

window(my.ts, start=c(1984,1), end=c(1984,12))

Dirk

-- 
Good judgement comes from experience; experience comes from bad judgement. 
							    -- Fred Brooks
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tchur at optusnet.com.au  Thu Oct  3 05:57:08 2002
From: tchur at optusnet.com.au (tchur@optusnet.com.au)
Date: Thu, 03 Oct 2002 13:57:08 +1000
Subject: [R] help to make a map on R
Message-ID: <200210030357.g933v8Q17465@mail020.syd.optusnet.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021003/b619408b/attachment.pl

From p.murrell at auckland.ac.nz  Thu Oct  3 06:16:16 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 03 Oct 2002 16:16:16 +1200
Subject: [R] install.packages("grid") failed
References: <200210030247.g932l8i06726@pandora.outcomes.chop.edu>
Message-ID: <3D9BC490.3BD5F09E@stat.auckland.ac.nz>

Hi


Yuelin Li wrote:
> 
> I just successfully compiled R-1.6.0 on a Red Hat 7.2 machine.  When I
> tried to install "grid" from source, I got this error.  Any
> suggestions?  I don't think it is a dependency problem.  I also attach
> the output from library().


R-1.6.0 comes bundled with a new version of grid.  This should be
installed automatically during the build of R.  i.e., you do not need to
download and install grid separately, it should already be there if R
has built correctly.

The (old) version of grid on CRAN is not compatible with R-1.6.0.  We
will rectify this as soon as possible.  Apologies for the problems.

The good news is that you hopefully have grid installed.  The failed
install from CRAN should not have affected the grid that was
automatically installed when R built (at least, when I just tried doing
what you did I still have an installed, working grid).

Hope that helps.

Paul
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From michel.arnaud at cirad.fr  Thu Oct  3 08:23:53 2002
From: michel.arnaud at cirad.fr (Michel ARNAUD)
Date: Thu, 03 Oct 2002 08:23:53 +0200
Subject: [R] Matlab to R ?
References: <2C23DE2983BE034CB1CB90DB6B813FD6028AC176@uswpmx11.merck.com>
Message-ID: <3D9BE279.FE019296@cirad.fr>

Hello

I have a matlab program. I would like to transfer code in R. Is there any translator ?
Thanks for your help


--
Michel ARNAUD
CIRAD TA60/15
73, av. Jean Fran?ois Breton
34938 MONTPELLIER CEDEX 5
tel : 04 67 59 38 34
Fax : 04 67 59 38 38

-------------- next part --------------
A non-text attachment was scrubbed...
Name: michel.arnaud.vcf
Type: text/x-vcard
Size: 204 bytes
Desc: Carte pour Michel ARNAUD
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021003/1454bf97/michel.arnaud.vcf

From gb at stat.umu.se  Thu Oct  3 09:37:39 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 3 Oct 2002 09:37:39 +0200 (CEST)
Subject: [R] summary and logical
In-Reply-To: <x2y99gmpyy.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0210030932260.11453-100000@tal.stat.umu.se>


In R-1.6.0 (Linux) I notice that 'summary' on a data.frame doesn't treat
logicals nicely. I only get

    event
 Length:148939
 Mode  :logical

Is this a bug? (I expected frequencies for TRUE and FALSE, of course.)

G?ran
---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Thu Oct  3 09:43:46 2002
From: siim at obs.ee (Ott Toomet)
Date: Thu, 3 Oct 2002 09:43:46 +0200 (CEST)
Subject: [R] help to make a map on R
In-Reply-To: <200210021626.50618.chrysopa@insecta.ufv.br>
Message-ID: <Pine.LNX.4.44.0210030905060.1566-100000@localhost.localdomain>

On Wed, 2 Oct 2002, Ronaldo Reis Jr. wrote:

  |Hi all,
  |I need a little help for construct an state's map on R.

I strongly recommend to take a look at package maps
(ftp://ftp.mcs.vuw.ac.nz/pub/statistics/map/), as suggested before.  It
includes maps of US (states and counties), UK (counties), New-Zealand and
China.  A pretty good descritption can be found at ,,Constructing a
geographical database'' by Richard Becker nad Allan Wilks, it is available
at web.

The problem in your case seem to be that you have not defined polylines and
polygons as are needed for the map() function.  Basically, the database
needs the definitions of line segments (borders, coastlines etc.), one
definition for one line.  Therafter you need definitions of polugons
(administrative units, lakes, cities...) desrcribed by the line segments
above.  And last, you need names for each of the polygon (you may be happy
with dummy names only).  From your description it seems to me that you don't
have descriptions of polygons.  If you have copirighted data, it is perhaps
not worth of so much work, but it depends on how much polyugons do you have.

----

If you don't want to use the package, I would suggest something following:

  |I have a datafile of longitude and latitude in the follow format:
  |
  |trajectory	latitude	longtude
  |T		-22.045618	-51.287056
  |T		-22.067078	-51.265888
  |T		-22.067039	-51.207249
  |
  |T		-22.059690	-48.089695
  |T		-22.075529	-48.074608
  |T		-22.072460	-48.044472
  |
  |T		-22.062767	-48.298473

I would perhaps use perl to transform the original file to a new one where I
give unique name for every trajectory (you may let me know if you are not
familiar with perl).

  |To read a file is simple, but I need that R change the value of
  |trajectory after a blank line, reading something like this:
  |
  |trajectory	latitude	longitude
  |T1		-22.045618	-51.287056
  |T1		-22.067078	-51.265888
  |T1		-22.067039	-51.207249
  |T2		-22.059690	-48.089695
  |T2		-22.075529	-48.074608

...

  |tapply() for separate the coordinates for each trajectory, something like 
  |this:
  |
  |> longitude <- tapply(longitude,trajectory,c)
  |> latitude <- tapply(latitude,trajectory,c)
  |The nest step is to make a plot with the coordinates.
  |
  |> plot(longitude,latitude, asp = 1, type = "n")

What about (not tested)

plot(1:2, xlim=range(unlist(longitude)), ylim=range(unlist(latitude)),
type="n")
lapply(1:length(unique(trajectory)), FUN=function(i) {
	lines(longitude[[1]], latitude[[i]])
	NULL
	}


Ott

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From aaltimim at hotmail.com  Thu Oct  3 09:44:49 2002
From: aaltimim at hotmail.com (Ali Al-Timimi)
Date: Thu, 03 Oct 2002 03:44:49 -0400
Subject: [R] Newbie Q: Help with loading libraries in Mac OS X
Message-ID: <B9C16DB1.150E%aaltimim@hotmail.com>

I am trying to load two libraries (mclust and tcltk) in Mac OS X (10.1.5).
My R version is 1.5.1

I have tried both the Carbon version and the Darwin command line version =,
but I get the following errors:

IN DARWIN:

> library(mclust)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"/usr/local/lib/R/library/mclust/libs/mclust.so":
  dlcompat: dyld: /usr/local/lib/R/bin/R.bin Undefined symbols:
/usr/local/lib/R/library/mclust/libs/mclust.so undefined reference to
_dgemv_ expected to be defined in the executable
/usr/local/lib/R/library/mclust/libs/mclust.so undefined reference to _dge
Error in library(mclust) : .First.lib failed


> library(tcltk)
Error in firstlib(which.lib.loc, package) :
        no display name and no $DISPLAY environment variable
Error in library(tcltk) : .First.lib failed


Now when I try using the install.packages(), I get the following:

> install.packages(mclust)
trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 84585 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... ..
downloaded 82Kb

Error in unique(pkgs) : Object "mclust" not found
In addition: Warning message:
argument `lib' is missing: using /usr/local/lib/R/library in:
install.packages(mclust)

> install.packages(tcltk)
trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 84585 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... ..
downloaded 82Kb

Error in unique(pkgs) : Object "tcltk" not found
In addition: Warning message:
argument `lib' is missing: using /usr/local/lib/R/library in:
install.packages(tcltk)

IN THE CARBON VERSION:

> library(tcltk)
Error in library.dynam("tcltk", pkg, lib) :
    dynamic library `tcltk' not found
Error in library(tcltk) : .First.lib failed

> library(mclust)
Error in library.dynam("mclust", pkg, lib) :
    dynamic library `mclust' not found
Error in library(mclust) : .First.lib failed


Any help would be appreciated!

Thanks,

Ali


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lancelot at sentoo.sn  Thu Oct  3 10:55:11 2002
From: lancelot at sentoo.sn (Renaud Lancelot)
Date: Thu, 03 Oct 2002 08:55:11 +0000
Subject: [R] help to make a map on R
References: <200210021626.50618.chrysopa@insecta.ufv.br>
Message-ID: <3D9C05EF.3F667C60@sentoo.sn>

"Ronaldo Reis Jr." wrote:
> 
> Hi all,
> I need a little help for construct an state's map on R.
> 
> The first problem is to get the data.
> 
> I have a datafile of longitude and latitude in the follow format:
> 
> trajectory      latitude        longtude
> T               -22.045618      -51.287056
> T               -22.067078      -51.265888
> T               -22.067039      -51.207249
> 
> T               -22.059690      -48.089695
> T               -22.075529      -48.074608
> T               -22.072460      -48.044472
> 
> T               -22.062767      -48.298473
> T               -22.077349      -48.322140
> T               -22.047001      -48.347443
> T               -22.054266      -48.369331
> T               -22.042810      -48.392612
> T               -22.064812      -48.422195
> T               -22.062544      -48.443497
> 
> To read a file is simple, but I need that R change the value of
> trajectory after a blank line, reading something like this:
> 
> trajectory      latitude        longitude
> T1              -22.045618      -51.287056
> T1              -22.067078      -51.265888
> T1              -22.067039      -51.207249
> T2              -22.059690      -48.089695
> T2              -22.075529      -48.074608
> T2              -22.072460      -48.044472
> T3              -22.062767      -48.298473
> T3              -22.077349      -48.322140
> T3              -22.047001      -48.347443
> T3              -22.054266      -48.369331
> T3              -22.042810      -48.392612
> T3              -22.064812      -48.422195
> T3              -22.062544      -48.443497
> 
> Each trajectory is a line that is a little piece of my map.
> 
> After this, to make a map I execute:
> 
> tapply() for separate the coordinates for each trajectory, something like
> this:
> 
> > longitude <- tapply(longitude,trajectory,c)
> > longitude
> $T1
> [1] -51.2871 -51.2659 -51.2072
> 
> $T2
> [1] -48.0897 -48.0746 -48.0445
> 
> $T3
> [1] -48.2985 -48.3221 -48.3474 -48.3693 -48.3926 -48.4222 -48.4435
> 
> > latitude <- tapply(latitude,trajectory,c)
> > latitude
> $T1
> [1] -22.0456 -22.0671 -22.0670
> 
> $T2
> [1] -22.0597 -22.0755 -22.0725
> 
> $T3
> [1] -22.0628 -22.0773 -22.0470 -22.0543 -22.0428 -22.0648 -22.0625
> 
> The nest step is to make a plot with the coordinates.
> 
> > plot(longitude,latitude, asp = 1, type = "n")
> 
> And finally plot the lines for each trajectory, and all lines together,
> make a Sao Paulo's map and your cities limits.
> 
> > lines(longitude$T1,latitude$T1)
> > lines(longitude$T2,latitude$T2)
> > lines(longitude$T3,latitude$T3)
> 
> How can I make to automatized this process? Because I can about 3000
> trajectory.
> 
> Any other idea for make this is welcome.
> 

Hi Ronaldo,

ReadCoord <- function(file){
  ext <- readLines(con = file, n = -1)
  nam <- unlist(strsplit(ext[1], split = " "))
  nam <- nam[nam != ""]
  ext <- ext[-1]
  List <- list()
  j <- 1
  for (i in seq(along = ext)) {
    ok <- T
    coord <- character(0)
    while(ok){
      val <- unlist(strsplit(ext[i], split = " "))
      val <- val[val != ""]
      if(length(val) != 3) ok <- F
      else{
        coord <- c(coord, paste(val[1], j, sep = ""), val[2:3])
        i <- i + 1
        }
      }
    mat <- matrix(coord, ncol = 3, byrow = T)
    List[[j]] <- mat
    j <- j +1
  }
  df <- as.data.frame(do.call("rbind", List))
  names(df) <- nam
  df[,2] <- as.numeric(as.character(df[,2]))
  df[,3] <- as.numeric(as.character(df[,3]))
  dimnames(df)[[1]] <- as.character(seq(nrow(df)))
  df
}

Data <- ReadCoord("d:/analyses/travail/data/coord.txt")
attach(Data)
plot(longitude, latitude, asp = 1, type = "n")
tapply(seq(nrow(Data)),
       Data[,1],
       function(x, data) lines(data[x, "longitude"], data[x,
"latitude"]),
       data = Data)
detach()


Hope this helps,

Renaud


-- 
Dr Renaud Lancelot, v?t?rinaire
CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
Programme Productions Animales
http://www.cirad.fr/presentation/programmes/prod-ani.shtml (Fran?ais)
http://www.cirad.fr/presentation/en/program-eng/prod-ani.shtml (English)

ISRA-LNERV                      tel    +221 832 49 02
BP 2057 Dakar-Hann              fax    +221 821 18 79 (CIRAD)
Senegal                         e-mail renaud.lancelot at cirad.fr
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct  3 11:08:00 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Oct 2002 11:08:00 +0200
Subject: [R] Newbie Q: Help with loading libraries in Mac OS X
In-Reply-To: <B9C16DB1.150E%aaltimim@hotmail.com>
References: <B9C16DB1.150E%aaltimim@hotmail.com>
Message-ID: <x2zntv3n67.fsf@biostat.ku.dk>

Ali Al-Timimi <aaltimim at hotmail.com> writes:

> I am trying to load two libraries (mclust and tcltk) in Mac OS X (10.1.5).
> My R version is 1.5.1
> 
> I have tried both the Carbon version and the Darwin command line version =,
> but I get the following errors:
....
> > library(tcltk)
> Error in firstlib(which.lib.loc, package) :
>         no display name and no $DISPLAY environment variable
> Error in library(tcltk) : .First.lib failed

You need to have an X11 server running for tcltk to work. (Currently,
at least. There are native Mac Tcl/Tk versions but to my knowledge
that's not what the tcltk package links against.) Jan de Leeuw will
know the details, and I believe he also wrote them down somewhere.


> Now when I try using the install.packages(), I get the following:
...
> Error in unique(pkgs) : Object "tcltk" not found
> In addition: Warning message:
> argument `lib' is missing: using /usr/local/lib/R/library in:
> install.packages(tcltk)

Yes. These are base packages and not available separately

> IN THE CARBON VERSION:
> 
> > library(tcltk)
> Error in library.dynam("tcltk", pkg, lib) :
>     dynamic library `tcltk' not found
> Error in library(tcltk) : .First.lib failed

Tcl/Tk is not supported under Carbon.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct  3 11:20:21 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Oct 2002 11:20:21 +0200
Subject: [R] summary and logical
In-Reply-To: <Pine.LNX.4.44.0210030932260.11453-100000@tal.stat.umu.se>
References: <Pine.LNX.4.44.0210030932260.11453-100000@tal.stat.umu.se>
Message-ID: <x2vg4j3mlm.fsf@biostat.ku.dk>

G?ran Brostr?m <gb at stat.umu.se> writes:

> In R-1.6.0 (Linux) I notice that 'summary' on a data.frame doesn't treat
> logicals nicely. I only get
> 
>     event
>  Length:148939
>  Mode  :logical
> 
> Is this a bug? (I expected frequencies for TRUE and FALSE, of course.)

Not a bug, but a fairly obviously missing feature... Logicals used to
be automatically converted to factors so it wasn't noticed earlier. 

Looks like a one-line change to summary.default, so we might just be
convinced to put it in for 1.6.1, even if it's not strictly a bug.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Oct  3 11:48:41 2002
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 3 Oct 2002 11:48:41 +0200 (MEST)
Subject: [R] T-Distribution
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC738@usrymx10.merck.com>
Message-ID: <Pine.LNX.4.21.0210031146460.15739-100000@artemis>


> > 
> > Try rt() function, type ?rt for help.
> 
> That's _univariate_ t.  Use the mvtnorm package for multivariate t
> distribution.
>  

hm, unless I as the maintainer miss something important: random number
generation of the multivariate t is not in mvtnorm (yet?) :-)

Torsten


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct  3 12:34:44 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Oct 2002 12:34:44 +0200
Subject: [R] T-Distribution
In-Reply-To: <Pine.LNX.4.21.0210031146460.15739-100000@artemis>
References: <Pine.LNX.4.21.0210031146460.15739-100000@artemis>
Message-ID: <x2r8f73j5n.fsf@biostat.ku.dk>

Torsten Hothorn <Torsten.Hothorn at rzmail.uni-erlangen.de> writes:

> > > 
> > > Try rt() function, type ?rt for help.
> > 
> > That's _univariate_ t.  Use the mvtnorm package for multivariate t
> > distribution.
> >  
> 
> hm, unless I as the maintainer miss something important: random number
> generation of the multivariate t is not in mvtnorm (yet?) :-)

Hm, am I missing something or can't you just 

  rmvt <- function(corr,df) rmvnorm(n,sigma=corr)/(rchisq(n,df)/df)

??

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Thu Oct  3 13:11:11 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 03 Oct 2002 12:11:11 +0100
Subject: [R] Strange behaviour of "image"
Message-ID: <1033643471.6222.26.camel@gandalf>

Hi

I'm using "image" and got some strange results. When I define the color
sequence as "col=gray(seq(0.95,0,-0.01))" or
"col=gray(seq(0.94,0,-0.01))" I got an error

Error in gray(level) : invalid gray level, must be in [0,1].

If I use 0.96 or 0.93 it works ...

EJ

ps: R 1.6.0 on SuSE Linux 8.0

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at cbs.dtu.dk  Thu Oct  3 14:20:10 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Thu, 3 Oct 2002 14:20:10 +0200
Subject: [R] cacheMetaData in R-1.6.0
Message-ID: <20021003122010.GG12655@giraffa.cbs.dtu.dk>

Hi,

I upgraded to R-1.6.0 and I am facing the following error
when loading a package I am working on.


Error in mlistMetaName(f) : No way to associate a generic function with
an object of class "NULL"
Error in library(affy) : .First.lib failed

This happen when I do
cacheMetaData(as.environment(where))
in the .First.lib function

Any hint ?


L.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Thu Oct  3 13:24:43 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 3 Oct 2002 13:24:43 +0200
Subject: [R] seq(*,by=) rounding problem {was 'Strange behaviour of "image"'}
In-Reply-To: <1033643471.6222.26.camel@gandalf>
References: <1033643471.6222.26.camel@gandalf>
Message-ID: <15772.10491.775414.242361@gargle.gargle.HOWL>

>>>>> "Ernesto" == Ernesto Jardim <ernesto at ipimar.pt>
>>>>>     on 03 Oct 2002 12:11:11 +0100 writes:

    Ernesto> Hi I'm using "image" and got some strange
    Ernesto> results. When I define the color sequence as
    Ernesto> "col=gray(seq(0.95,0,-0.01))" or
    Ernesto> "col=gray(seq(0.94,0,-0.01))" I got an error

    Ernesto> Error in gray(level) : invalid gray level, must be
    Ernesto> in [0,1].

    Ernesto> If I use 0.96 or 0.93 it works ...

yes, this is just floating point arithmetic, or "rounding" :
The following reveals the problem :

 > range(seq(0.94,0, by = -0.01))
 [1] -1.110223e-16  9.400000e-01
 > range(seq(0.93,0, by = -0.01))
 [1] 0.00 0.93
 > range(seq(0.96,0, by = -0.01))
 [1] 0.00 0.96

BTW, I usually never use "by=" in seq() exactly for this reason
(and rather use "length=" instead).

Martin
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Thu Oct  3 13:29:51 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 3 Oct 2002 13:29:51 +0200
Subject: [R] cacheMetaData in R-1.6.0
In-Reply-To: <20021003122010.GG12655@giraffa.cbs.dtu.dk>
References: <20021003122010.GG12655@giraffa.cbs.dtu.dk>
Message-ID: <15772.10799.792208.496277@gargle.gargle.HOWL>

>>>>> "Laurent" == Laurent Gautier <laurent at cbs.dtu.dk>
>>>>>     on Thu, 3 Oct 2002 14:20:10 +0200 writes:

    Laurent> Hi, I upgraded to R-1.6.0 and I am facing the
    Laurent> following error when loading a package I am working
    Laurent> on.


    Laurent> Error in mlistMetaName(f) : No way to associate a
    Laurent> generic function with an object of class "NULL"
    Laurent> Error in library(affy) : .First.lib failed

    Laurent> This happen when I do
    Laurent> cacheMetaData(as.environment(where)) in the
    Laurent> .First.lib function

    Laurent> Any hint ?

Try to reinstall "affy".

{I'm answering because the expert here is probably not yet at
 work ..}

All packages using S4 methods/classes are installed as
``binary'', and the problem could be that the internal metadata
representation of these things was extended changed from 1.5.x to 1.6.

This would mean you should probably re-install most bioconductor
packages since most of these rely on the modern methods.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at cbs.dtu.dk  Thu Oct  3 14:36:35 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Thu, 3 Oct 2002 14:36:35 +0200
Subject: [R] cacheMetaData in R-1.6.0
In-Reply-To: <15772.10799.792208.496277@gargle.gargle.HOWL>
References: <20021003122010.GG12655@giraffa.cbs.dtu.dk> <15772.10799.792208.496277@gargle.gargle.HOWL>
Message-ID: <20021003123635.GH12655@giraffa.cbs.dtu.dk>

On Thu, Oct 03, 2002 at 01:29:51PM +0200, Martin Maechler wrote:
> >>>>> "Laurent" == Laurent Gautier <laurent at cbs.dtu.dk>
> >>>>>     on Thu, 3 Oct 2002 14:20:10 +0200 writes:
> 
>     Laurent> Hi, I upgraded to R-1.6.0 and I am facing the
>     Laurent> following error when loading a package I am working
>     Laurent> on.
> 
> 
>     Laurent> Error in mlistMetaName(f) : No way to associate a
>     Laurent> generic function with an object of class "NULL"
>     Laurent> Error in library(affy) : .First.lib failed
> 
>     Laurent> This happen when I do
>     Laurent> cacheMetaData(as.environment(where)) in the
>     Laurent> .First.lib function
> 
>     Laurent> Any hint ?
> 
> Try to reinstall "affy".


...I did... (it would have too easy ;) )...

> 
> {I'm answering because the expert here is probably not yet at
>  work ..}
> 

Thanks.

> All packages using S4 methods/classes are installed as
> ``binary'', and the problem could be that the internal metadata
> representation of these things was extended changed from 1.5.x to 1.6.
> 
> This would mean you should probably re-install most bioconductor
> packages since most of these rely on the modern methods.
> 

The funny thing is that 'Biobase' behaves nicely... 


> Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
> ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
> phone: x-41-1-632-3408		fax: ...-1228			<><

-- 
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Thu Oct  3 14:30:09 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 3 Oct 2002 14:30:09 +0200
Subject: [R] summary and logical
In-Reply-To: <x2vg4j3mlm.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0210030932260.11453-100000@tal.stat.umu.se>
	<x2vg4j3mlm.fsf@biostat.ku.dk>
Message-ID: <15772.14417.542848.504232@gargle.gargle.HOWL>

>>>>> "PD" == Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
>>>>>     on 03 Oct 2002 11:20:21 +0200 writes:

    PD> G?ran Brostr?m <gb at stat.umu.se> writes:
    >> In R-1.6.0 (Linux) I notice that 'summary' on a
    >> data.frame doesn't treat logicals nicely. I only get
    >> 
    >> event Length:148939 Mode :logical
    >> 
    >> Is this a bug? (I expected frequencies for TRUE and
    >> FALSE, of course.)

    PD> Not a bug, but a fairly obviously missing
    PD> feature... Logicals used to be automatically converted
    PD> to factors so it wasn't noticed earlier.

    PD> Looks like a one-line change to summary.default, so we
    PD> might just be convinced to put it in for 1.6.1, even if
    PD> it's not strictly a bug.

"yes" I said instinctivly -- but then realized that S-plus 6.1
doesn't summary()ze differently either.  

So we might be more careful...

Anyway, I'd want that after the change,

  lvar <- (1:20 %% 3 == 1)
  summary(lvar) ## and
  summary(as.factor(lvar))

*be* distinguishable.
If we do the change, (I'm "make checking" it), we should make it
distinguishibly, maybe even adding the word (line) "logical", e.g., like

> summary(lvar)
   Mode   FALSE    TRUE 
logical      13       7 

and {used in summary.data.frame()} :
 
> sd <- summary(data.frame(x=1:10, y=round(rnorm(10),2), F=gl(2,5),L=(1:10)>7))
> sd
       x               y          F         L          
 Min.   : 1.00   Min.   :-1.120   1:5   Mode :logical  
 1st Qu.: 3.25   1st Qu.:-0.790   2:5   FALSE:7        
 Median : 5.50   Median :-0.695         TRUE :3        
 Mean   : 5.50   Mean   :-0.223                        
 3rd Qu.: 7.75   3rd Qu.: 0.390                        
 Max.   :10.00   Max.   : 1.530                        
> str(sd)
 chr [1:6, 1:4] "Min.   : 1.00  " "1st Qu.: 3.25  " "Median : 5.50  " ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:6] "" "" "" "" ...
  ..$ : chr [1:4] "      x" "      y" "F" "    L"
 - attr(*, "class")= chr "table"
> 

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Thu Oct  3 14:09:55 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 03 Oct 2002 08:09:55 -0400
Subject: [R] Atlas shared
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC73F@usrymx10.merck.com>

> From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> 
> G?ran Brostr?m <gb at stat.umu.se> writes:
> 
> 
> > Roger Peng suggested that it should be possible to link with
> > the _static_ libraries. Haven't checked, and haven't noticed any
> > reaction to his suggestion either. Would be nice if it worked.
> 
> That works fine. As far as I remember you just need to set LDFLAGS
> with the relevant -L option, e.g.
> 
> LDFLAGS=-L/usr/src/pd/ATLAS/lib/Linux_PIIISSE1_2/ ./configure
> make

I thought passing it to configure in the --with-blas= argument also works,
no?

Andy


> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: 
> (+45) 35327907
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From awitney at sghms.ac.uk  Thu Oct  3 14:42:13 2002
From: awitney at sghms.ac.uk (Adam Witney)
Date: Thu, 03 Oct 2002 13:42:13 +0100
Subject: [R] Newbie Q: Help with loading libraries in Mac OS X
In-Reply-To: <x2zntv3n67.fsf@biostat.ku.dk>
Message-ID: <B9C1F9B5.8CAC%a.witney@sghms.ac.uk>

On 3/10/02 10:08 am, "Peter Dalgaard BSA" <p.dalgaard at biostat.ku.dk> wrote:

> Ali Al-Timimi <aaltimim at hotmail.com> writes:
> 
>> I am trying to load two libraries (mclust and tcltk) in Mac OS X (10.1.5).
>> My R version is 1.5.1
>> 
>> I have tried both the Carbon version and the Darwin command line version =,
>> but I get the following errors:
> ....
>>> library(tcltk)
>> Error in firstlib(which.lib.loc, package) :
>>         no display name and no $DISPLAY environment variable
>> Error in library(tcltk) : .First.lib failed
> 
> You need to have an X11 server running for tcltk to work. (Currently,
> at least. There are native Mac Tcl/Tk versions but to my knowledge
> that's not what the tcltk package links against.) Jan de Leeuw will
> know the details, and I believe he also wrote them down somewhere.

If you are on OSX then you can install x11 and tcl/tk using fink
(fink.sourceforge.net). I have not tried the libraries you are looking at
here, but I have several other tcl applications running nicely

adam


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Thu Oct  3 15:30:41 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 03 Oct 2002 14:30:41 +0100
Subject: [R] seq(*,by=) rounding problem {was 'Strange behaviour of
	"image"'}
In-Reply-To: <15772.10491.775414.242361@gargle.gargle.HOWL>
References: <1033643471.6222.26.camel@gandalf> 
	<15772.10491.775414.242361@gargle.gargle.HOWL>
Message-ID: <1033651841.6222.31.camel@gandalf>

Cool !

Thanks

EJ

On Thu, 2002-10-03 at 12:24, Martin Maechler wrote:
> >>>>> "Ernesto" == Ernesto Jardim <ernesto at ipimar.pt>
> >>>>>     on 03 Oct 2002 12:11:11 +0100 writes:
> 
>     Ernesto> Hi I'm using "image" and got some strange
>     Ernesto> results. When I define the color sequence as
>     Ernesto> "col=gray(seq(0.95,0,-0.01))" or
>     Ernesto> "col=gray(seq(0.94,0,-0.01))" I got an error
> 
>     Ernesto> Error in gray(level) : invalid gray level, must be
>     Ernesto> in [0,1].
> 
>     Ernesto> If I use 0.96 or 0.93 it works ...
> 
> yes, this is just floating point arithmetic, or "rounding" :
> The following reveals the problem :
> 
>  > range(seq(0.94,0, by = -0.01))
>  [1] -1.110223e-16  9.400000e-01
>  > range(seq(0.93,0, by = -0.01))
>  [1] 0.00 0.93
>  > range(seq(0.96,0, by = -0.01))
>  [1] 0.00 0.96
> 
> BTW, I usually never use "by=" in seq() exactly for this reason
> (and rather use "length=" instead).
> 
> Martin
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Oct  3 15:41:43 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 3 Oct 2002 06:41:43 -0700 (PDT)
Subject: [R] Convert daily to weekly ts ?
In-Reply-To: <E17wmc9-0006Xq-00@server.family>
Message-ID: <Pine.A41.4.44.0210030641200.112860-100000@homer41.u.washington.edu>

On Wed, 2 Oct 2002, FWR wrote:

> Have 3.5 years daily data that I want to convert to weekly. Looking for
> something like SAS's "expand" function, where you can specify the
> conversion function (sum, average, etc.) and get a new vector out with
> different sampling frequencies.
>

aggregate().

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From erich.neuwirth at univie.ac.at  Thu Oct  3 15:56:36 2002
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 03 Oct 2002 15:56:36 +0200
Subject: [R] R-1.6.0 windows binary
References: <x2n0pygygv.fsf@biostat.ku.dk>
Message-ID: <3D9C4C94.4050505@univie.ac.at>

For people needing a windows binary, but not compiling themselves,
I put a windows binary on

http://mailbox.univie.ac.at/erich.neuwirth/RWin/rw1060.exe

This is meant as intermediate offer until the official
binary appears on CRAN.


-- 
--
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Thu Oct  3 15:57:28 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Thu, 03 Oct 2002 09:57:28 -0400
Subject: [R] Parameterisation of interaction terms in lm
References: <5.1.0.14.2.20021002202053.02dd1350@mcmail.cis.mcmaster.ca>
Message-ID: <3D9C4CC8.49633A43@umsanet.edu.bo>


> Using contr.sum, you'll still get one fewer coefficient than level for each
> factor, but you can fill in the missing coefficients for the interactions
> by taking the negatives of the sums of the estimates in each row and column

or even simpler by dummy.coef

Kjetil Halvorsen
> (since the estimates are constrained to sum to 0 over each coordinate).
> 
> Whether this is really of more interest than simply examining the cell
> means is another question.
> 
> I hope that this helps,
>   John
> 
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgilbert at bank-banque-canada.ca  Thu Oct  3 16:07:27 2002
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 03 Oct 2002 10:07:27 -0400
Subject: [R] Matlab to R ?
References: <2C23DE2983BE034CB1CB90DB6B813FD6028AC176@uswpmx11.merck.com> <3D9BE279.FE019296@cirad.fr>
Message-ID: <3D9C4F1F.3906E7E7@bank-banque-canada.ca>

Michel ARNAUD wrote:
> 
> Hello
> 
> I have a matlab program. I would like to transfer code in R. Is there any translator ?

Below is an old Unix script which does about 80% of the simple part of
translation. You will need to work out the harder things (like many of
the function calls). You do need to know pretty well what your matlab
code does, and know enough R to translate the hard parts. It would also
be a good idea to have some examples to test with.

Paul Gilbert
______
#!/bin/csh
cp $1 $2
ex -s $2 <<eof
   g/%/s//#/g
   g/function\(..*\)=\(..*\)(\(..*\)/s//\2 <-function( \3 { \1/
   g/end/s//   } #/
   g/for\(..*\)=\(..*\):\(..*\)/s//for ( \1 in \2 : \3 ) {/
   g/_/s//./g
   g/;/s///g
   g/==/s//@@/g
   g/=/s//<-/g
   g/@@/s//==/g
   g/zeros(/s//matrix(0,/g
   g/ones(/s//matrix(1,/g
   g/eye(/s//diag(1,/g
   g/\/s//solve(,)/g
   g/fsolve('\(..*\)'/s//ms(~\1 /g
   g/param(\(..*\))/s//param[ \1 ] /g
   g/var(\(..*\))/s//var[ \1 ] /g
   g/mod1(\(..*\)/s//mod1[ \1 /g
   wq
eof
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgilbert at bank-banque-canada.ca  Thu Oct  3 16:30:17 2002
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 03 Oct 2002 10:30:17 -0400
Subject: [R] R vs Fortran
References: <200210022138.g92LcMx10901@r.hankin.sges.auckland.ac.nz> <x2u1k4mpdi.fsf@biostat.ku.dk>
Message-ID: <3D9C5479.2C8F3177@bank-banque-canada.ca>

Peter Dalgaard BSA wrote:
> 
> Robin Hankin <r.hankin at auckland.ac.nz> writes:
> 
> >
> >     do 10 i=1,200
> >       do 20 j=1,200
> >         flux(i,j) = ( r(i,j)*u(i+1,j) + r(i+1,j)*u(i,j) ) /2
> > 20    continue
> > 10  continue
> >
> > where r is the density and u the x-component of velocity.  I might
> > need to do this or similar-looking things such as u(i+1,j)*v(i,j+1)
> > perhaps a hundred times in my Fortran code.  But in R we could have
> >
> > flux =  ( r*right(u) + right(r)*u ) /2
> >
> > [where right <- function(x){cbind(x[,-1],NA)} ]
> >
> > To my mind, the functional form is much better: it's vectorized and
> > clear and terse.  My question is, is it fast? (or more precisely, how
> > much slower would this nice approach be than my clunky old Fortran).
> > I guess I could tolerate a factor of two or three, and wait for a
> > shiny next-generation PC.
> >
> >
> > any comments anyone?
> 
> I would be highly surprised if it turned out to be even remotely fast
> in R...
> 
> This kind of thing generally needs a compiled language like C(++) or
> Fortran. Preferably with good optimisers.

I guess speed is relative. I've had pretty good luck with similar
calculations in R. If you are repeating the calculation millions of
times then you will be in trouble, but if you are only repeating it
hundreds of times then I find the other overheads are more important
(such as user error checking).

However, you've forgotten what might be your most attractive option:
leave the computationally intensive blocks in clunky old Fortran
(separated in nice clean little function blocks) and glue it together
with R. But I would not even bother with this until you find it is too
slow.

Paul
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Thu Oct  3 16:55:35 2002
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 3 Oct 2002 07:55:35 -0700
Subject: [R] help to make a map on R
In-Reply-To: <200210021626.50618.chrysopa@insecta.ufv.br>
References: <200210021626.50618.chrysopa@insecta.ufv.br>
Message-ID: <p05111a02b9c208b4cbf0@[128.115.153.6]>

If I understand the question correctly, the solution is simpler than 
some of the other suggestions. Here is what I would do.

First, here is an example data file:

traj	lat	long
T	2.1	3.4
T	4.2	5.1
T	3.6	6.2
T	4.2	5.1

T	11.4	12.3
T	13.2	14.8
T	9.3	11.2

T	19.4	20.3
T	21.3	16.8
T	22.3	15.6
T	23.1	14.4

T	34.2	32.3
T	39.2	34.8
T	39.3	31.2

Next, here is a script to make the plot:

## read the data (the delimiter is tab character in this example)
dat <- read.delim('junk.dat',colClasses=c('character','numeric','numeric'),
                   blank.lines.skip=FALSE)

## change "T" to "T1", "T2" etc.
rl <- rle(dat$traj)
dat <- dat[dat$traj != '',]
lens <- rl$lengths[rl$lengths != 1]
dat$traj <- paste(dat$traj,
                   rep(1:lens),lens),
                   sep='')

## function for plotting lines
lfun <- function(df) lines(df$long,df$lat)

## prepare an empty plot with the correct range
ylm <- range(dat$lat)
xlm <- range(dat$long)
plot(xlm,ylm,type='n')

## add the lines to the plot, one line for each trajectory
lapply(split(dat,dat$traj),lfun)

Since you have about 3000 trajectories, the lapply() step may take a long time.

The essential steps are the use of the rle() and rep() functions. 
That, and including the blank lines while reading the data file.

Very important warning: this method assumes that whenever there is a 
blank line there is only one blank line. Never two or more blank 
lines next to each other.

I hope this helps
-Don

At 4:26 PM -0300 10/2/02, Ronaldo Reis Jr. wrote:
>Hi all,
>I need a little help for construct an state's map on R.
>
>The first problem is to get the data.
>
>I have a datafile of longitude and latitude in the follow format:
>
>trajectory	latitude	longtude
>T		-22.045618	-51.287056
>T		-22.067078	-51.265888
>T		-22.067039	-51.207249
>
>T		-22.059690	-48.089695
>T		-22.075529	-48.074608
>T		-22.072460	-48.044472
>
>T		-22.062767	-48.298473
>T		-22.077349	-48.322140
>T		-22.047001	-48.347443
>T		-22.054266	-48.369331
>T		-22.042810	-48.392612
>T		-22.064812	-48.422195
>T		-22.062544	-48.443497
>
>To read a file is simple, but I need that R change the value of
>trajectory after a blank line, reading something like this:
>
>trajectory	latitude	longitude
>T1		-22.045618	-51.287056
>T1		-22.067078	-51.265888
>T1		-22.067039	-51.207249
>T2		-22.059690	-48.089695
>T2		-22.075529	-48.074608
>T2		-22.072460	-48.044472
>T3		-22.062767	-48.298473
>T3		-22.077349	-48.322140
>T3		-22.047001	-48.347443
>T3		-22.054266	-48.369331
>T3		-22.042810	-48.392612
>T3		-22.064812	-48.422195
>T3		-22.062544	-48.443497
>
>Each trajectory is a line that is a little piece of my map.
>
>After this, to make a map I execute:
>
>tapply() for separate the coordinates for each trajectory, something like
>this:
>
>>  longitude <- tapply(longitude,trajectory,c)
>>  longitude
>$T1
>[1] -51.2871 -51.2659 -51.2072
>
>$T2
>[1] -48.0897 -48.0746 -48.0445
>
>$T3
>[1] -48.2985 -48.3221 -48.3474 -48.3693 -48.3926 -48.4222 -48.4435
>
>>  latitude <- tapply(latitude,trajectory,c)
>>  latitude
>$T1
>[1] -22.0456 -22.0671 -22.0670
>
>$T2
>[1] -22.0597 -22.0755 -22.0725
>
>$T3
>[1] -22.0628 -22.0773 -22.0470 -22.0543 -22.0428 -22.0648 -22.0625
>
>The nest step is to make a plot with the coordinates.
>
>>  plot(longitude,latitude, asp = 1, type = "n")
>
>And finally plot the lines for each trajectory, and all lines together,
>make a Sao Paulo's map and your cities limits.
>
>>  lines(longitude$T1,latitude$T1)
>>  lines(longitude$T2,latitude$T2)
>>  lines(longitude$T3,latitude$T3)
>
>How can I make to automatized this process? Because I can about 3000
>trajectory.
>
>Any other idea for make this is welcome.
>
>
>Thanks for all
>
>Inte mais
>Ronaldo

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mail at fwr.on.ca  Thu Oct  3 18:05:16 2002
From: mail at fwr.on.ca (FWR)
Date: Thu, 3 Oct 2002 12:05:16 -0400
Subject: [R] Re: Convert daily to weekly ts ?
In-Reply-To: <20021003073557.B17918@camille.indigoindustrial.co.nz>
References: <E17wqXa-0006aQ-00@server.family> <20021003073557.B17918@camille.indigoindustrial.co.nz>
Message-ID: <E17x8TU-0006rX-00@server.family>

Thanks to Jason Turner and others for their comments. 

I still have to decide whether the calendar (POSIXt) based week-of-year aggregates, or the constant 7-day aggregates (using aggregate.ts), are more appropriate for what I want to do with these several years of daily data. 

In my case, the POSIXt based week-of-year calculations end up with a less than 7 day aggregate at the beginning and end of each year, sometimes only one day is used in the aggregation. The week-of-year starts not on 1-Jan but on the first Sunday of January. There are a varying number of weeks in any given year.

What I want is to break up each year separately into exactly 52 equal-length intervals and obtain an average property over each interval. 

Unfortunately, aggregate.ts requires that 52 be evenly divisible into #days/year . It doesn't do interpolations. I might be able to fudge it with the eps parameter ... or just randomly throw out 1 or 2 days per year.

Wishlist: that aggregate.ts that could use interpolation methods to change frequencies.

Thanks,
Bruce L.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From roger at ysidro.econ.uiuc.edu  Thu Oct  3 18:52:00 2002
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Thu, 3 Oct 2002 11:52:00 -0500 (CDT)
Subject: [R] T-Distribution
In-Reply-To: <x2r8f73j5n.fsf@biostat.ku.dk>
Message-ID: <Pine.GSO.4.33.0210031149470.25405-100000@ysidro.econ.uiuc.edu>

On 3 Oct 2002, Peter Dalgaard BSA wrote:

> > hm, unless I as the maintainer miss something important: random number
> > generation of the multivariate t is not in mvtnorm (yet?) :-)
>
> Hm, am I missing something or can't you just
>
>   rmvt <- function(corr,df) rmvnorm(n,sigma=corr)/(rchisq(n,df)/df)

I think Peter intended to write:

   rmvt <- function(corr,df) rmvnorm(n,sigma=corr)/sqrt(rchisq(n,df)/df)


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Mike.Prager at noaa.gov  Thu Oct  3 19:24:28 2002
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Thu, 03 Oct 2002 13:24:28 -0400
Subject: [R] R vs Fortran
Message-ID: <5.1.0.14.2.20021003132204.00abfc70@hermes.nos.noaa.gov>

[This was sent to Robin earlier and is posted here in case any others are 
interested in modern Fortran.]


At 09:38 AM 10/03/2002 +1200, Robin Hankin wrote:

>I work in computational fluid dynamics in 2D: I have a 200-by-200
>array of fluid properties such as density and velocity and these
>evolve in time (the precise equations depend on the problem).
>Up to now, I've been using Fortran and the code is very very messy.

>[...]

>flux =  ( r*right(u) + right(r)*u ) /2
>
>[where right <- function(x){cbind(x[,-1],NA)} ]

Just to remind you, you can do this kind of thing in modern 
Fortran.  Intrinsic vector and matrix operations have been available in the 
Fortran language for about ten years (since Fortran 90).  In my experience, 
Fortran is usually much faster than R.  It will probably be easier to port 
your code to modern Fortran than to C and its derivatives, and also less 
error prone.

If the code is messy, why not clean it up?  It is possible to write good 
code, and messy code, in any language.

Some comparisons of Fortran and C++, and information on modern Fortran as a 
scientific programming language, can be found at

http://www.cts.com.au/compare.html

http://citeseer.nj.nec.com/cache/papers/cs/7409/http:zSzzSzwww.cs.colorado.eduzSz~zornzSzcs5535zSzFall-1995zSzprojectszSzwharton.pdf/wharton95should.pdf

http://www.kcl.ac.uk/kis/support/cit/fortran/f90home.html

http://www.ibiblio.org/pub/languages/fortran/ch1-2.html


Whatever path you choose, good luck!



-- 
Michael Prager      <Mike.Prager at noaa.gov>
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516  USA
http://shrimp.ccfhrb.noaa.gov/~mprager/

Standard Disclaimers:
* Opinions expressed here are personal and are not otherwise represented.
* Any use of tradenames does not constitute a NOAA or NMFS endorsement.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bhoel at web.de  Thu Oct  3 20:39:35 2002
From: bhoel at web.de (Berthold =?iso-8859-15?q?H=F6llmann?=)
Date: 03 Oct 2002 20:39:35 +0200
Subject: [R] Re: SuSE rpms for R-1.6.0  available
In-Reply-To: <XFMail.20021002093728.steuer@unibw-hamburg.de>
References: <XFMail.20021002093728.steuer@unibw-hamburg.de>
Message-ID: <m27kgzwemw.fsf@pchoel.privat.uni-hamburg.de>

Detlef Steuer <Detlef.Steuer at unibw-hamburg.de> writes:

> 	 ["CC: R-announce" made this message bounce;
> 			   I'm not sure if it should be "R-announced", MM]
> 
> RPMs for R-1.6.0 for SuSE Linux Versions 7.3/8.0
> have been built and uploaded to CRAN.
> 
> They should be found on the website within the next 24 hours.
> 
> The contrib RPMs will need a day or two to be rebuild for R-1.6.0.
> 
> SuSE 8.1 RPMS will be uploaded as soon as I have updated one of my machines.
> (Or got user mode linux running, whatever happens first.)
> 
> Thank you, R Core Team!
> 
> Detlef Steuer

I tried to install R-base-1.6.0-1.i386.rpm:

> md5sum R-base-1.6.0-1.i386.rpm 
a3e4585c37206aabddd580c3a30a7f37  R-base-1.6.0-1.i386.rpm

and got

(lots of)
user steuer does not exist - using root
user steuer does not exist - using root
var/tmp/rpm-tmp.18919: fg: no job control
execution of R-base-1.6.0-1 script failed, exit status 1

on SuSE 8.0

Greetings

Berthold
-- 
bhoel at web.de / http://starship.python.net/crew/bhoel/
        It is unlawful to use this email address for unsolicited ads
        (USC Title 47 Sec.227). I will assess a US$500 charge for
        reviewing and deleting each unsolicited ad.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From murad at godel.bioc.columbia.edu  Thu Oct  3 20:57:27 2002
From: murad at godel.bioc.columbia.edu (Murad Nayal)
Date: Thu, 03 Oct 2002 14:57:27 -0400
Subject: [R] curiousity with hist
Message-ID: <3D9C9317.C2D1407B@godel.bioc.columbia.edu>



Hello, 

I am rather new to R. in trying to use the hist() command I get behavior
that is somewhat puzzling me, in short, for a vector 'data' of about
2000 elements ranging from -1,1 I do:

hist(data,probability=TRUE) 

I get a histogram with the y axis ranging from 0.0 -> 6.0 at the highest
bin. This bin's relative frequency should be 0.6. this bin's raw count
is 1200 (out of about 2000 observations in the vector 'data'). so this 6
is not the raw count, probability=relative frequency or percentage. What
is it? I get the raw counts plotted correctly if I do a

hist(data)

any help/ideas would be greatly appreciated
thanks
Murad
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rlee at fpcc.net  Thu Oct  3 21:14:45 2002
From: rlee at fpcc.net (Rob Lee)
Date: Thu, 3 Oct 2002 13:14:45 -0600 (MDT)
Subject: [R] lm fitting with a specified slope 
Message-ID: <Pine.LNX.4.33.0210031308320.14221-100000@aberdeen.fpcc.net>


Is there an easy way to do a linear model with an a priori known slope?

In essence, I want to minimize the residuals around a line of known slope.

-R

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From murad at godel.bioc.columbia.edu  Thu Oct  3 21:15:27 2002
From: murad at godel.bioc.columbia.edu (Murad Nayal)
Date: Thu, 03 Oct 2002 15:15:27 -0400
Subject: [R] [Fwd: curiousity with hist]
Message-ID: <3D9C974F.8E548CF1@godel.bioc.columbia.edu>


just realized that the bin value is actually the relative frequency
divided by the bin width. sorry for consuming band width.

Alas, is there anyway to make hist() calculate relative frequencies
irrespective of bin width?

thanks


Murad Nayal wrote:
> 
> Hello,
> 
> I am rather new to R. in trying to use the hist() command I get behavior
> that is somewhat puzzling me, in short, for a vector 'data' of about
> 2000 elements ranging from -1,1 I do:
> 
> hist(data,probability=TRUE)
> 
> I get a histogram with the y axis ranging from 0.0 -> 6.0 at the highest
> bin. This bin's relative frequency should be 0.6. this bin's raw count
> is 1200 (out of about 2000 observations in the vector 'data'). so this 6
> is not the raw count, probability=relative frequency or percentage. What
> is it? I get the raw counts plotted correctly if I do a
> 
> hist(data)
> 
> any help/ideas would be greatly appreciated
> thanks
> Murad
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From peter.vikstrom at ekhist.umu.se  Thu Oct  3 22:19:48 2002
From: peter.vikstrom at ekhist.umu.se (=?iso-8859-1?Q?Peter_Vikstr=F6m?=)
Date: Thu, 3 Oct 2002 22:19:48 +0200
Subject: [R] Error in princomp?
Message-ID: <JAEIJJHNGFAGGDGPAGIKEENOCBAA.peter.vikstrom@ekhist.umu.se>

Hello!

When using princomp() for principal components analysis, the resulting
loadings matrix differs between R and the output from other programs (S-plus
and SAS)
The difference is that the sign of some columns in the loadings matrix. The
absolute values, however, are the same.
This sign difference also exists when comparing the princomp() results with
the manually calculated eigen vectors using eigen().
Is this a bug in R?
I am using R ver 1.5.1

Thanks in advance,
Peter

===========================================
Peter Vikstr?m
Dept. of Economic History
Ume? University
SE-901 87  UME?

E-mail: peter.vikstrom at ekhist.umu.se
===========================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Thu Oct  3 22:33:05 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Thu, 3 Oct 2002 16:33:05 -0400 
Subject: [R] lm fitting with a specified slope 
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20149D037@groexmb02.pfizer.com>


Assume the model:

  X1 <- rnorm(1000)
  X2 <- rnorm(1000)

  B1 = 1.75 # known a-priorori
  B2 = 0.5  # unknown a-priorori

  Y  <- 1.75 * X1 + 0.5 * X2  + rnorm(1000,sd=0.25)

Then wouldn't this do the trick? :

  reg <- lm( (Y - 1.75 * X1) ~ X2 ) 


-Greg

> -----Original Message-----
> From: Rob Lee [mailto:rlee at fpcc.net]
> Sent: Thursday, October 03, 2002 3:15 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] lm fitting with a specified slope 
> 
> 
> 
> Is there an easy way to do a linear model with an a priori 
> known slope?
> 
> In essence, I want to minimize the residuals around a line of 
> known slope.
> 
> -R
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lsjensen at micron.com  Thu Oct  3 22:44:56 2002
From: lsjensen at micron.com (lsjensen)
Date: Thu, 3 Oct 2002 14:44:56 -0600 
Subject: [R] Does R have graphlets?
Message-ID: <D7E178FC91F3D21186A90008C7B9A5B81008155F@ntexchange09.micron.com>

This sample code creates a image map html file (similar to SPlus graphlets?)
that references a PNG file. Its not pretty but should give you some ideas to
make some simple R plots more web-interactive. You might need to change the
paths, etc to get it to work on your environment. Should be easy to wrap
this up in a more generic function. 

Landon Jensen
Fab3 Parametrics/Integration
Micron Technology, Inc.

################
# data
x<-1:10
y<-rnorm(10)

#range of data
xmin<-min(x)
xmax<-max(x)
ymin<-min(y)
ymax<-max(y)
xdelta<-xmax-xmin
ydelta<-ymax-ymin

# pixel size of png plot
xsize<-600
ysize<-400

# define click zones (+/- pixels)
clickzones=5

# create png plot
png(file="/home/www/html/temp/imagemap.png",height=ysize,width=xsize)
par(mar=c(4,4,4,4))
plot(x,y)
usr<-par("usr")
plt<-par("plt")
dev.off()

# create mapping, active area coordinates
x1pixels<-clickzones
x2pixels<-clickzones
y1pixels<-clickzones
y2pixels<-clickzones

dataxmin<-usr[1]
dataxmax<-usr[2]
dataymin<-usr[3]
dataymax<-usr[4]

plotxmin<-plt[1]
plotxmax<-plt[2]
plotymin<-plt[3]
plotymax<-plt[4]

datawidth<-dataxmax-dataxmin
dataheight<-dataymax-dataymin

ratioxmin<-dataxmin/plotxmin
ratioxmax<-dataxmax/plotxmax
ratioymin<-dataymin/plotymin
ratioymax<-dataymax/plotymax

pixelxmin<-dataxmin*xsize/ratioxmin
pixelxmax<-dataxmax*xsize/ratioxmax
pixelymin<-dataymin*ysize/ratioymin
pixelymax<-dataymax*ysize/ratioymax

pixelwidth<-pixelxmax-pixelxmin
pixelheight<-pixelymax-pixelymin

AAC<-c()
for(i in 1:length(x)) {
  x1<-(x[i]-dataxmin)/datawidth
  x1<-x1*pixelwidth
  x1<-floor(x1+pixelxmin + .5)

  y1<-(1-(y[i]-dataymin)/dataheight)
  y1<-y1*pixelheight
  y1<-floor(y1+pixelymin + .5)

 
AAC<-c(AAC,paste((x1-x1pixels),",",(y1-y1pixels),",",(x1+x2pixels),",",(y1+y
2pixels),sep=""))
}

# create html file
write("<html><head><title>Image Map
Test</title></head><body>",file="/home/www/html/temp/imagemap.html")
write("<img src='imagemap.png' border=1 usemap='#imagemap.png'
ISMAP>",file="/home/www/html/temp/imagemap.html",append=TRUE)
write("<map
name='imagemap.png'>",file="/home/www/html/temp/imagemap.html",append=TRUE)
for(i in 1:length(x)) {
  write(paste("<area coords='",AAC[i],"' alt='x=",x[i],",y=",y[i],"'
href='http://yelinux3.micron.com/temp/test.html'>",sep=""),file="/home/www/h
tml/temp/imagemap.html",append=TRUE)
}
write("</map></body>",file="/home/www/html/temp/imagemap.html",append=TRUE)
write("</html>",file="/home/www/html/temp/imagemap.html",append=TRUE)
################



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct  3 22:53:57 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Oct 2002 22:53:57 +0200
Subject: [R] lm fitting with a specified slope
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C20149D037@groexmb02.pfizer.com>
References: <D7A3CFD7825BD6119B880002A58F06C20149D037@groexmb02.pfizer.com>
Message-ID: <x2zntvnt0a.fsf@biostat.ku.dk>

"Warnes, Gregory R" <gregory_r_warnes at groton.pfizer.com> writes:

> Assume the model:
> 
>   X1 <- rnorm(1000)
>   X2 <- rnorm(1000)
> 
>   B1 = 1.75 # known a-priorori
>   B2 = 0.5  # unknown a-priorori
> 
>   Y  <- 1.75 * X1 + 0.5 * X2  + rnorm(1000,sd=0.25)
> 
> Then wouldn't this do the trick? :
> 
>   reg <- lm( (Y - 1.75 * X1) ~ X2 ) 

I'd prefer

lm(Y ~ X2 + offset(1.75*X1))

This allows you to do things like

>  predict(lm( Y ~ X2 + offset(1.75*X1) ), data.frame(X1=10,X2=10))
[1] 22.41585

whereas

>  predict(lm( (Y - 1.75*X1) ~ X2 ), data.frame(X1=10,X2=10))
[1] 4.915847


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r.hankin at auckland.ac.nz  Thu Oct  3 22:51:23 2002
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Fri, 4 Oct 2002 08:51:23 +1200
Subject: [R] Matlab to R ?
In-Reply-To: <3D9BE279.FE019296@cirad.fr> (message from Michel ARNAUD on Thu,
	03 Oct 2002 08:23:53 +0200)
References: <2C23DE2983BE034CB1CB90DB6B813FD6028AC176@uswpmx11.merck.com> <3D9BE279.FE019296@cirad.fr>
Message-ID: <200210032051.g93KpNL18379@r.hankin.sges.auckland.ac.nz>

Hello Michel

a good place to start would be R-and-octave.txt, on the contributed
section of CRAN (Octave is the free version of Matlab).

This shows how common Matlab idioms translate to R.

There seem to be more and more people interested in porting from
Matlab/octave to R.   How about a specialist mailing list?


rksh


> 
> Hello
> 
> I have a matlab program. I would like to transfer code in R. Is there any translator ?
> Thanks for your help
> 
> 
> --


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

as of: Fri Oct  4 08:49:00 NZST 2002
This (linux) system up continuously for:  400 days, 15 hours, 31 minutes
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ml at henge-ernst.de  Thu Oct  3 23:20:01 2002
From: ml at henge-ernst.de (=?iso-8859-15?q?J=FCrgen=20Henge-Ernst?=)
Date: Thu, 3 Oct 2002 23:20:01 +0200
Subject: [R] Re: SuSE rpms for R-1.6.0  available
In-Reply-To: <m27kgzwemw.fsf@pchoel.privat.uni-hamburg.de>
References: <XFMail.20021002093728.steuer@unibw-hamburg.de> <m27kgzwemw.fsf@pchoel.privat.uni-hamburg.de>
Message-ID: <200210032320.17276.ml@henge-ernst.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On Thursday 03 October 2002 20:39, Berthold H?llmann wrote:
> user steuer does not exist - using root
> user steuer does not exist - using root
> var/tmp/rpm-tmp.18919: fg: no job control
> execution of R-base-1.6.0-1 script failed, exit status 1
that's a packing error/warning. With a line like
%defattr(-, root, root)
in the %files -section of the SPEC-file such warnings can be avoided

Greetings J?rgen

- -- 
 Juergen Henge-Ernst // Hauptstrasse 37 // 67591 M?lsheim // Germany
           email: juergen at henge-ernst.de        ICQ 56324358
Key fingerprint = 5FFD 89AC 6C7B 76DD 5FAC  9A3F D1A9 0C9B 3B49 67B1
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.6 (GNU/Linux)
Comment: For info see http://www.gnupg.org

iD8DBQE9nLSB0akMmztJZ7ERAsbYAKCBtYVGd4ECGbW7anpz6s1MtS4eXQCggEGU
aatKMN3OxOYilhIN+207njU=
=VC+H
-----END PGP SIGNATURE-----

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Oct  4 02:01:49 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 3 Oct 2002 17:01:49 -0700 (PDT)
Subject: [R] Error in princomp?
In-Reply-To: <JAEIJJHNGFAGGDGPAGIKEENOCBAA.peter.vikstrom@ekhist.umu.se>
Message-ID: <Pine.A41.4.44.0210031700450.73942-100000@homer10.u.washington.edu>

On Thu, 3 Oct 2002, [iso-8859-1] Peter Vikstrm wrote:

> Hello!
>
> When using princomp() for principal components analysis, the resulting
> loadings matrix differs between R and the output from other programs (S-plus
> and SAS)
> The difference is that the sign of some columns in the loadings matrix. The
> absolute values, however, are the same.
> This sign difference also exists when comparing the princomp() results with
> the manually calculated eigen vectors using eigen().
> Is this a bug in R?

No. The results are only defined up to a sign change.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From feldesmanm at pdx.edu  Fri Oct  4 02:21:42 2002
From: feldesmanm at pdx.edu (Marc Feldesman)
Date: Thu, 3 Oct 2002 17:21:42 -0700
Subject: [R] Error in princomp?
In-Reply-To: <JAEIJJHNGFAGGDGPAGIKEENOCBAA.peter.vikstrom@ekhist.umu.se>
References: <JAEIJJHNGFAGGDGPAGIKEENOCBAA.peter.vikstrom@ekhist.umu.se>
Message-ID: <20021003172142.30c90db9.feldesmanm@pdx.edu>

On Thu, 3 Oct 2002 22:19:48 +0200, an incredible array of electrons randomly cascading around the Universe collided and turned into words spewed forth by Peter Vikstr?m:


Peter> Hello!
Peter> 
Peter> When using princomp() for principal components analysis, the resulting
Peter> loadings matrix differs between R and the output from other programs (S-plus
Peter> and SAS)
Peter> The difference is that the sign of some columns in the loadings matrix. The
Peter> absolute values, however, are the same.
Peter> This sign difference also exists when comparing the princomp() results with
Peter> the manually calculated eigen vectors using eigen().
Peter> Is this a bug in R?
Peter> I am using R ver 1.5.1

Signs of principal components are arbitrary.  It isn't uncommon at all to have two programs give the same absolute value pc's but differ in sign.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mail at fwr.on.ca  Fri Oct  4 03:24:42 2002
From: mail at fwr.on.ca (FWR)
Date: Thu, 3 Oct 2002 21:24:42 -0400
Subject: [R] spline bug ?
Message-ID: <E17xHCt-0006v9-00@server.family>

# Is this a bug or something I don't understand?
spline(date, stor, n=52, xmin=mind, xmax=maxd)
# gives length(x) of 53 ????, but y has the expected length of 52 
# Shouldn't they be the same length? From help (spline):
# spline returns a list containing components x and y which give the 
# ordinates where interpolation took place and the interpolated values

# xmin and xmax are inside min(date) and max(date) if that's important 

# If I construct the x vector separately with length 52, approx works fine 
approx(date,stor,xout=x)
# Actually, I constructed the x vector used above with:
x<-spline(date, stor, n=51, xmin=mind, xmax=maxd)$x
# note the use of 51, not 52

#Thanks, Bruce L.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.connolly at hortresearch.co.nz  Fri Oct  4 04:25:48 2002
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Fri, 4 Oct 2002 14:25:48 +1200
Subject: [R] Does the perl language have an equivalent to browser?
Message-ID: <20021004022548.GA5376@hortresearch.co.nz>

I'm asking on this list because the question will be more easily
understood than on a Perl list.  Lots of talented people using R also
know how to use Perl, so it's easier to ask them.

Running a Perl script with the -d switch can do some pretty neat
things, but as far as I can tell, every line has to be done
individually.  Is there a way to specify where to stop in the way
browser() does in the S language?

best


-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plorch at zoo.utoronto.ca  Fri Oct  4 05:35:46 2002
From: plorch at zoo.utoronto.ca (plorch@zoo.utoronto.ca)
Date: Thu, 3 Oct 2002 23:35:46 -0400
Subject: [R] Model II regression on segmented data
Message-ID: <5ED58AC2-D74A-11D6-BE85-0050E4F94F2A@zoo.utoronto.ca>

I am interested in doing Reduced Major Axis regression in R.  Has anyone 
implemented this?

I am aware of how to calculate the slope using RMA (and previous threads 
on this list about RMA), but I would like to estimate break points in 
data where there are two (or more) distinct trends.  This is 
straightforward with Ordinary Least Squares (iteratively try x values, 
set up dummy variables, find x that maximizes R^2).  But it seems like 
it would be more difficult with RMA.  The critical thing, it seems to 
me, would be how to estimate R^2 for the more complex model.   Once the 
break point is identified, it would also be nice to also estimate the 
two (or more trends).

Thanks for any help you can give.
	 -pat


	Dr. Patrick D. Lorch
	Zoology Dept.				W: 416-978-0172
	University of Toronto		F: 416-978-8532
	Ramsay Wright Labs		plorch at zoo.utoronto.ca
	25 Harbord St.			http://www.zoo.utoronto.ca/lrowe/plorch
	Toronto, Ontario  M5S 3G5
	CANADA

Public encryption key available upon request.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maj at waikato.ac.nz  Fri Oct  4 07:05:16 2002
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Fri, 04 Oct 2002 17:05:16 +1200
Subject: [R] pairs() of pair
Message-ID: <E17xKka-0002Gh-00@euler.math.waikato.ac.nz>

Suppose one has two matrices A and B, both with dimensions n by p.

How may one produce a combined plot of two scatterplot matrices, with that
for A above the diagonal and that for B below?


Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html 
Department of Statistics, University of Waikato, Hamilton, New Zealand 
Email: maj at waikato.ac.nz                            Fax +64-7 838 4155
Phone  +64-7 838 4773 wk    +64 7 849 6486 home     Mobile 021 395 862

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ddmagee at lbl.gov  Fri Oct  4 07:25:10 2002
From: ddmagee at lbl.gov (David Magee)
Date: Thu, 03 Oct 2002 22:25:10 -0700
Subject: [R] Rterm Rcmd failure
Message-ID: <3D9D2636.12105E3@lbl.gov>

I tried running these  under Windows XP from the dos prompt
at C:/R/rw1050/bin


Rterm --restore --save < test.R
it returned
>  (block char)cError: syntax error.

test.R has two lines:
c<-1
c

Do I need a file header for the test.R file?


Then I tried:
>Rcmd BATCH test.R
it returned
perl' is not recognized as an internal or external command, operable
program or batch file.

I have perl loaded already.



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Friedrich.Leisch at ci.tuwien.ac.at  Thu Oct  3 10:47:03 2002
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu, 3 Oct 2002 10:47:03 +0200
Subject: [R] Re: Workshop: DSC 2003
In-Reply-To: <5.0.0.25.1.20021003074053.03c838a0@pop.jcu.edu.au>
References: <15770.63670.972703.294768@galadriel.ci.tuwien.ac.at>
	<5.0.0.25.1.20021003074053.03c838a0@pop.jcu.edu.au>
Message-ID: <15772.1031.745279.705566@celeborn.leisch.at>

>>>>> On Thu, 03 Oct 2002 07:42:51 +1000,
>>>>> Richard Rowe (RR) wrote:

  > At 15:46 02/10/02 +0200, you wrote:
  >> We invite papers on topics related to statistical computing.  Deadline
  >> for submission of papers is 2002-11-30.  Notification about acceptance
  >> or rejection will be sent before 2002-01-31.

  > It's not that I'm coming, but there seems to be a timing problem (now how 
  > do you do one of those tongue in cheek things?)


Ooops, even 3 people proofreading are no guarantee ... notification
will of course be on  2003-01-31.

thanks for catching the typo.

best,
fritz

-- 
-------------------------------------------------------------------
                        Friedrich  Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jarioksa at sun3.oulu.fi  Fri Oct  4 08:43:56 2002
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Fri, 04 Oct 2002 09:43:56 +0300
Subject: [R] Error in princomp? 
In-Reply-To: Message from Thomas Lumley <tlumley@u.washington.edu> 
   of "Thu, 03 Oct 2002 17:01:49 PDT." <Pine.A41.4.44.0210031700450.73942-100000@homer10.u.washington.edu> 
Message-ID: <200210040643.g946hua02043@pc112145.oulu.fi>


tlumley at u.washington.edu said:
> On Thu, 3 Oct 2002, [iso-8859-1] Peter Vikstr?m wrote:
> Hello! >
> When using princomp() for principal components analysis, the resulting
> loadings matrix differs between R and the output from other programs
> (S-plus
> and SAS)
> The difference is that the sign of some columns in the loadings
> matrix. The
> absolute values, however, are the same.
> This sign difference also exists when comparing the princomp() results
> with
> the manually calculated eigen vectors using eigen().
> Is this a bug in R?

> No. The results are only defined up to a sign change. 

A more intriguing feature in R is that its two alternative PCAs in mva differ 
slightly and report slightly different square roots of eigenvalues:

(here I use my own data set, but the result are similar with any you have:)

> princomp(varespec)$sdev[1:5]
   Comp.1    Comp.2    Comp.3    Comp.4    Comp.5 
30.692367 21.094028 11.257890  8.417428  6.811818 
> prcomp(varespec)$sdev[1:5]
[1] 31.352493 21.547715 11.500023  8.598469  6.958325

The reason is, of course, that `prcomp' opts for unbiased variance whereas 
`princomp' works hard to get biased variances, but of course we can turn that 
off:

>  princomp(varespec)$sdev[1:5]/sqrt(1 - 1/nrow(varespec))
   Comp.1    Comp.2    Comp.3    Comp.4    Comp.5 
31.352493 21.547715 11.500023  8.598469  6.958325 

The practise in prcomp seems to be similar to the normal one, so that its 
eigenvalues add up to variance:

> sum(apply(varespec, 2, var))
[1] 1825.659
> sum(princomp(varespec)$sdev^2)
[1] 1749.590
> sum(prcomp(varespec)$sdev^2)
[1] 1825.659

However, princomp seems to work hard to get biased estimates of covariance:

 cv <- covmat$cov * (1 - 1/n.obs) # in princomp.default
(here covmat$cov is the matrix of unbiased covariances)

whereas it doesn't do the same if analysis is based on correlations:

    if (cor) { # in princomp.default
        sds <- sqrt(diag(cv))
        cv <- cv/(sds %o% sds)
    }

Whereas prcomp is just as explicit in opting for unbiased variances, although it
has to do this after extracting the singular values (s$d) which otherwise would
be related to sums of squares instead of variances:

    s$d <- s$d/sqrt(max(1, nrow(x) - 1))

Personally, I'd opt for the prcomp alternative (which is the official 
recommendation anyhow).

Except for sign, the PC solutions are indeterminate for scale (scores at least,
the loadings are habitually orthonormal == rotation matrix). It seems that R
opts for slight inconsistency, though. Square root of eigenvalues are geared for
variances, but the scores for sums of squares. 

> sum(prcomp(varespec)$sdev^2)
[1] 1825.659
> sum(prcomp(varespec)$x^2) 
[1] 41990.17
> sum(prcomp(varespec)$x^2)/(nrow(varespec)-1)
[1] 1825.659

The current scaling is just as correct as the alternatives, of course, but not 
concordant with the square root of eigenvalues: eigenvalues are divided by df 
after extraction, but scores are not. This can be turned of by dividing the 
scores by sqrt(nrow(x)-1) -- which of course is a constant for any matrix x.

Peter Vikstr?m's message alone didn't make me to study PCA output in R this
closely, but I just confronted a really weird scaling in another software and
trying to understand that one I looked at R as well. I am just implementing Cajo
ter Braak's "Redundancy Analysis" for ecological community data in R (a spin-off
from his "Canonical Correspondence Analysis"), but I couldn't get similar
species scores as in his software Canoco, although my results were similar to
PCAs in R. Canoco works like it would use covariance matrix or svd of centred
data -- it does neither, but something more obscure, but it looks like this from
the surface. However, the species scores (which are relative to eigenvalues:
site scores are orthonormal) are divided by the standard deviation of each
species. So they are the square roots of ``variance explained by axis'' for each
species, or look like coming from correlation matrix although the analysis is
based on covariance matrix. I won't implement that behaviour, but that's 
an interesting alternative.

This message really was a digression...

cheers, jari oksanen 
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matthias.burger at epigenomics.com  Fri Oct  4 08:58:24 2002
From: matthias.burger at epigenomics.com (Matthias Burger)
Date: Fri, 04 Oct 2002 08:58:24 +0200
Subject: [R] RMySQL_0.5-0 installation problem
Message-ID: <3D9D3C10.7020802@epigenomics.com>


Hi,

in the process of upgrading to R 1.6.0 I tried to install the latest RMySQL 
(0.5-0) package (Omegahat).

The following error was reported
[...]
   gcc -I/mnt/local/R/R-1.6.0/lib/R/include -I/usr/include/mysql 
-I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c RS-MySQL.c 
-o RS-MySQL.o
RS-MySQL.c: In function `RS_MySQL_newConnection':
RS-MySQL.c:203: `MYSQL_OPT_LOCAL_INFILE' undeclared (first use in this 
function)RS-MySQL.c:203: (Each undeclared identifier is reported only once
RS-MySQL.c:203: for each function it appears in.)
make: *** [RS-MySQL.o] Error 1
ERROR: compilation failed for package 'RMySQL'

Any hint on what to try next would be highly appreciated.

Regards,

   Matthias


sys info:

This is on a Athlon 900 host with debian 3.0 (testing), kernel 2.4.19
MySQL packages libmysqlclient10 + libmysqlclient10-dev installed
$ mysql -V
mysql  Ver 11.15 Distrib 3.23.47, for pc-linux-gnu (i686)

R version, built from source, make & check OK
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.0
year     2002
month    10
day      01
language R

-- 
Matthias Burger

Bioinformatics R&D
Epigenomics AG                      www.epigenomics.com
Kleine Pr?sidentenstra?e 1          fax:   +49-30-24345-555
10178 Berlin Germany                phone: +49-30-24345-0


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Fri Oct  4 09:39:22 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 Oct 2002 09:39:22 +0200
Subject: [R] Re: Matlab to R ?
In-Reply-To: <200210032051.g93KpNL18379@r.hankin.sges.auckland.ac.nz>
References: <2C23DE2983BE034CB1CB90DB6B813FD6028AC176@uswpmx11.merck.com>
	<3D9BE279.FE019296@cirad.fr>
	<200210032051.g93KpNL18379@r.hankin.sges.auckland.ac.nz>
Message-ID: <15773.17834.519855.498186@gargle.gargle.HOWL>


>>>>> "Robin" == Robin Hankin <r.hankin at auckland.ac.nz>
>>>>>     on Fri, 4 Oct 2002 08:51:23 +1200 writes:

    Robin> Hello Michel a good place to start would be
    Robin> R-and-octave.txt, on the contributed section of CRAN
    Robin> (Octave is the free version of Matlab).

    Robin> This shows how common Matlab idioms translate to R.

and I assume you have seen Paul Gilbert's reply, giving "ex"
translations of a few idioms.

    Robin> There seem to be more and more people interested in
    Robin> porting from Matlab/octave to R.  How about a
    Robin> specialist mailing list?

I think a few interested people should "sit together" (in cyberspace)
and try to improve on the current state.
I've included John Eaton, the author of GNU octave (the free
matlab `substitute'), because he certainly knows more about the
matlab "syntax" than any of us (and Kurt who once new a lot
about octave).

Probably everyone agrees that a Matlab -> R translation cannot
(and probably should not) be automated to full extent.  On the
other hand, Paul Gilbert's "ex" script should be made into a
perl or python {or "octave" !?} script and could be enhanced
considerably, probably.

It could help matlab/octave users switch to R.
Another reason I'm interested to some extent is the
Statistics+Matlab community & software ("Wavelets", "Smoothers" etc)
where I would like us to get better connected to.

    Robin> How about a specialist mailing list?

Not sure if this is needed and makes sense;  I have already set up a dozen
R-SIG-* (R Special Interest Group in ****) mailing lists and
only a few are somewhat active.
But then it may make sense for a short time?

    MichelA> I have a matlab program. I would like to transfer code in
    MichelA> R. Is there any translator ?  Thanks for your help

--
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From valdentro at hotmail.com  Fri Oct  4 10:21:12 2002
From: valdentro at hotmail.com (juan pablo perez)
Date: Fri, 04 Oct 2002 08:21:12 +0000
Subject: [R] pipes in R
Message-ID: <F179nrYclEKDX8zGDms0001388e@hotmail.com>

Hello!
it?s possible to build pipes in R?

e.g. something like this

boxplot(aaa$bbb)|dev.print(postscript)

Thanks in advance

Juan Pablo

_________________________________________________________________
MSN Fotos: la forma m?s f?cil de compartir e imprimir fotos. 
http://photos.msn.es/support/worldwide.aspx

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Fri Oct  4 10:28:01 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 04 Oct 2002 10:28:01 +0200
Subject: [R] Rterm Rcmd failure
References: <3D9D2636.12105E3@lbl.gov>
Message-ID: <3D9D5111.E5D6F1EB@statistik.uni-dortmund.de>

David Magee wrote:
> 
> I tried running these  under Windows XP from the dos prompt
> at C:/R/rw1050/bin
> 
> Rterm --restore --save < test.R
> it returned
> >  (block char)cError: syntax error.
> 
> test.R has two lines:
> c<-1
> c
> 
> Do I need a file header for the test.R file?

No. It works for me (R-1.6.0, WinNT4.0). Are there any special
characters in your file?


> Then I tried:
> >Rcmd BATCH test.R
> it returned
> perl' is not recognized as an internal or external command, operable
> program or batch file.

Is the path to perl set properly?
 
> I have perl loaded already.


Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Fri Oct  4 12:35:03 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 4 Oct 2002 12:35:03 +0200 (CEST)
Subject: [R] dropterm in a function
Message-ID: <Pine.LNX.4.44.0210041227430.14680-100000@tal.stat.umu.se>


I'm trying to use 'dropterm' (from MASS) in a function along the lines

run <- function(dat){
  fit <- (something)(Y ~ (something), data = dat)
  lr <- dropterm(fit, test = "Chisq")
  return(fit, lr)
}

but running 'run' I get (those scoping rules again...?)

Error in terms.formula(formula, special, data = data) :
        Object "dat" not found

This works fine at the command line. Can I send 'dat' to 'dropterm'
somehow, or what should I do?

Thankful for any suggestion, including reading certain books!

G?ran


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From david.meyer at ci.tuwien.ac.at  Fri Oct  4 12:41:12 2002
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Fri, 04 Oct 2002 12:41:12 +0200
Subject: [R] Re: Matlab to R ?
References: <2C23DE2983BE034CB1CB90DB6B813FD6028AC176@uswpmx11.merck.com>
		<3D9BE279.FE019296@cirad.fr>
		<200210032051.g93KpNL18379@r.hankin.sges.auckland.ac.nz> <15773.17834.519855.498186@gargle.gargle.HOWL>
Message-ID: <3D9D7048.235DFA1@ci.tuwien.ac.at>

Another (complementary) issue might be data exchange, at least for more
complex data not fitting in a simple .csv format.

I think this can be done using `StatDataML' (the R part is on CRAN):
in addition to the R package, there are read and write functions
available both for MATLAB and octave producing/reading StatDataML which
will probably appear somewhere on omegahat in the near future (I can
provide a snapshot if anybody would like to play with it).

David.

Martin Maechler wrote:
> 
> >>>>> "Robin" == Robin Hankin <r.hankin at auckland.ac.nz>
> >>>>>     on Fri, 4 Oct 2002 08:51:23 +1200 writes:
> 
>     Robin> Hello Michel a good place to start would be
>     Robin> R-and-octave.txt, on the contributed section of CRAN
>     Robin> (Octave is the free version of Matlab).
> 
>     Robin> This shows how common Matlab idioms translate to R.
> 
> and I assume you have seen Paul Gilbert's reply, giving "ex"
> translations of a few idioms.
> 
>     Robin> There seem to be more and more people interested in
>     Robin> porting from Matlab/octave to R.  How about a
>     Robin> specialist mailing list?
> 
> I think a few interested people should "sit together" (in cyberspace)
> and try to improve on the current state.
> I've included John Eaton, the author of GNU octave (the free
> matlab `substitute'), because he certainly knows more about the
> matlab "syntax" than any of us (and Kurt who once new a lot
> about octave).
> 
> Probably everyone agrees that a Matlab -> R translation cannot
> (and probably should not) be automated to full extent.  On the
> other hand, Paul Gilbert's "ex" script should be made into a
> perl or python {or "octave" !?} script and could be enhanced
> considerably, probably.
> 
> It could help matlab/octave users switch to R.
> Another reason I'm interested to some extent is the
> Statistics+Matlab community & software ("Wavelets", "Smoothers" etc)
> where I would like us to get better connected to.
> 
>     Robin> How about a specialist mailing list?
> 
> Not sure if this is needed and makes sense;  I have already set up a dozen
> R-SIG-* (R Special Interest Group in ****) mailing lists and
> only a few are somewhat active.
> But then it may make sense for a short time?
> 
>     MichelA> I have a matlab program. I would like to transfer code in
>     MichelA> R. Is there any translator ?  Thanks for your help
> 
> --
> Martin Maechler <maechler at stat.math.ethz.ch>    http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16    Leonhardstr. 27
> ETH (Federal Inst. Technology)  8092 Zurich     SWITZERLAND
> phone: x-41-1-632-3408          fax: ...-1228                   <><
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
	Mag. David Meyer		Wiedner Hauptstrasse 8-10
Vienna University of Technology		A-1040 Vienna/AUSTRIA
         Department of			Tel.: (+431) 58801/10772
Statistics and Probability Theory	mail: david.meyer at ci.tuwien.ac.at
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ted.Harding at nessie.mcc.ac.uk  Fri Oct  4 14:31:56 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 04 Oct 2002 13:31:56 +0100 (BST)
Subject: [R] Re: Matlab to R ?
In-Reply-To: <15773.17834.519855.498186@gargle.gargle.HOWL>
Message-ID: <XFMail.021004133156.Ted.Harding@nessie.mcc.ac.uk>

On 04-Oct-02 Martin Maechler wrote:
>     Robin> This shows how common Matlab idioms translate to R.
> and I assume you have seen Paul Gilbert's reply, giving "ex"
> translations of a few idioms.
>     Robin> There seem to be more and more people interested in
>     Robin> porting from Matlab/octave to R.  How about a
>     Robin> specialist mailing list?
> Probably everyone agrees that a Matlab -> R translation cannot
> (and probably should not) be automated to full extent.  On the
> other hand, Paul Gilbert's "ex" script should be made into a
> perl or python {or "octave" !?} script and could be enhanced
> considerably, probably.

While matlab/octave are a powerful packages for numerical and
logical computation on vectors and matrices, and therefore lend
themselves well to Statistics (I was using octave and, earlier,
MatLab long before R was properly on the scene), they not only
differ from R in their primary purposes but also in their languages
and constructs. For this reason I doubt that Paul Gilbert's
'ex' script will encourage many to migrate from matlab/octave
to R: simple line-editing substitutions do no go far enough;
the script is not "intelligent".

To take a simple example: I have an ocyave file "sap.m" which
simply reads in some data and constructs some derived data:

  SAP = [ 112 108 110 85 92 NaN 89 NaN 112 NaN NaN
  107 NaN 115 NaN 104 NaN NaN NaN NaN NaN NaN
  ....
  67 81 107 109 110 100 NaN NaN NaN NaN NaN ];
  SAP20  = SAP(:,1);
  SAP30  = SAP(:,2);
  ....
  SAP120 = SAP(:,11);

Paul's script produces:
  SAP <- [ 112 108 110 85 92 NaN 89 NaN 112 NaN NaN
  107 NaN 115 NaN 104 NaN NaN NaN NaN NaN NaN
  ....
  67 81 107 109 110 100 NaN NaN NaN NaN NaN ]
  SAP20  = SAP(:,1)
  SAP30  = SAP(:,2)
  ....
  SAP120 = SAP(:,11)

and all it has done is to replace "=" by "<-" and remove the
semicolons. It has not recognised the data structure (a matrix)
being assigned to SAP. 'R' will not accept this output, even at
its firs tline, let alone get as far as doing the wrong thing
with it! Nor will the subsidiary assignments at the end work.

In fact, it is not obvious (except perhaps to a fluent "sight
reader" of 'ex' commands) what the script does, what it does not
do, and  -- above all -- what it does that it should have done
differently.

I would agree that a more flexible language such as 'perl' or
'python' or (my favourite) 'awk' should be used instead: these
languages are capable of sophisticated parsing of input lines,
recognising their intent, and generating appropriate output.
I.e. the programmer can build "intelligence" into the script.

But in fact I think I would prefer to see a general interface
whereby R and octave/matlab could cooperate with each other,
each calling the other as required and contributing their
respective strengths, rather than join in a movement to induce
users to migrate from octave/matlab to R. To some extent this
can be done without effort, since R can import and export
octave/matlab files in the "save -ascii" format (though I have
observed that for import to work it is necessary to edit out
the first line of the octave file). Matlab/octave can be readily
programmed to generate command files for another language (I have
often programmed 'pic' commands from within octave, for instance,
to generate complex data plots from internal data), and I dare
say one could do the same from within R (though I have never
tried this myself).

> It could help matlab/octave users switch to R.
> Another reason I'm interested to some extent is the
> Statistics+Matlab community & software ("Wavelets", "Smoothers" etc)
> where I would like us to get better connected to.

See above.

> Robin> How about a specialist mailing list?
> 
> Not sure if this is needed and makes sense;

I'm inclined to agree with this: experience shows that the
subscriber mass is usually sub-critical! The best place to
catch the eye of people who might be interested is the main list.

Best wishes to all,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 04-Oct-02                                       Time: 13:31:56
------------------------------ XFMail ------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jrogers at cantatapharm.com  Fri Oct  4 15:02:46 2002
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Fri, 4 Oct 2002 09:02:46 -0400
Subject: [R] T-Distribution
Message-ID: <99A12772DCDEEB458B996332957B0D530116B7@mercury.cantatapharm.com>

Roger Koeneker wrote: 

> 
>   rmvt <- function(corr,df)
rmvnorm(n,sigma=corr)/sqrt(rchisq(n,df)/df) 
>

That would do the trick. 

One interesting note relating to Hicham's original question (Hicham was
the originator of this thread): 

The multivariate T distribution does not have elliptical contours. For
example, the contours of an independent bivariate T are not circles. One
of the many fascinating facts about the independent bivariate Normal
distribution is that it is the ONLY independent bivariate distribution
with circular contours. Many people may know this, but I know it was a
surprise to me when I learned it.

--Jim 

James A. Rogers <rogers at cantatapharm.com>
Statistical Scientist
Cantata Pharmaceuticals 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From phgrosje at ulb.ac.be  Fri Oct  4 15:32:12 2002
From: phgrosje at ulb.ac.be (Philippe Grosjean)
Date: Fri, 4 Oct 2002 15:32:12 +0200
Subject: [R] Re: Matlab to R ?
In-Reply-To: <15773.17834.519855.498186@gargle.gargle.HOWL>
Message-ID: <MABBLJDICACNFOLGIHJOAEMFCPAA.phgrosje@ulb.ac.be>

I have the same problem: many Matlab scripts to be converted in R. Half of
functions in the PASTECS R library are translations from Matlab 4.X - 5.X
scripts. The biggest difficulty here is that the Matlab scripts/functions
were written in the context of ... Matlab, of course. And Matlab does not
uses data frames, factors, ts, etc... Also, most Matlab scripts are not
written in a way that  directly translate into the objetc/methods paradigm
(print, summary, plot, predict, etc.) that makes the force of R. Finally,
the S language is much more powerful on subsetting matrices, and sometimes,
3 to 6 code lines in Matlab can be elegantly rewritten in one line of code
in S language. However, some Matlab 6.X (release 12 or more) scripts
translated in S language run much slower in R!

So, according to all these remarks, shouldn't it be more interesting to
develop an interface for calling a Matlab/Octave script from within R? If it
is an Octave script, we stay in the GNU licence world, so, there is no
problem.

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
( ( ( ( (
 ) ) ) ) )      Philippe Grosjean
( ( ( ( (
 ) ) ) ) )      IFREMER Nantes - DEL/AO
( ( ( ( (       rue de l'Ile d'Yeu, BP 21105, 44311 Nantes Cedex 3
 ) ) ) ) )      tel: (33) 02.40.37.42.29, fax: (33) 02.40.37.42.41
( ( ( ( ( 
 ) ) ) ) )      SciViews project coordinator (http://www.sciviews.org)
( ( ( ( (       e-mail: phgrosjean at sciviews.org
 ) ) ) ) ) 
( ( ( ( (       "I'm 100% confident that p is between 0 and 1"
 ) ) ) ) )                                L. Gonick & W. Smith (1993)
.......................................................................
 

>>>>> "Robin" == Robin Hankin <r.hankin at auckland.ac.nz>
>>>>>     on Fri, 4 Oct 2002 08:51:23 +1200 writes:

    Robin> Hello Michel a good place to start would be
    Robin> R-and-octave.txt, on the contributed section of CRAN
    Robin> (Octave is the free version of Matlab).

    Robin> This shows how common Matlab idioms translate to R.

and I assume you have seen Paul Gilbert's reply, giving "ex"
translations of a few idioms.

    Robin> There seem to be more and more people interested in
    Robin> porting from Matlab/octave to R.  How about a
    Robin> specialist mailing list?

I think a few interested people should "sit together" (in cyberspace)
and try to improve on the current state.
I've included John Eaton, the author of GNU octave (the free
matlab `substitute'), because he certainly knows more about the
matlab "syntax" than any of us (and Kurt who once new a lot
about octave).

Probably everyone agrees that a Matlab -> R translation cannot
(and probably should not) be automated to full extent.  On the
other hand, Paul Gilbert's "ex" script should be made into a
perl or python {or "octave" !?} script and could be enhanced
considerably, probably.

It could help matlab/octave users switch to R.
Another reason I'm interested to some extent is the
Statistics+Matlab community & software ("Wavelets", "Smoothers" etc)
where I would like us to get better connected to.

    Robin> How about a specialist mailing list?

Not sure if this is needed and makes sense;  I have already set up a dozen
R-SIG-* (R Special Interest Group in ****) mailing lists and
only a few are somewhat active.
But then it may make sense for a short time?

    MichelA> I have a matlab program. I would like to transfer code in
    MichelA> R. Is there any translator ?  Thanks for your help

--
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._
._._._._._._._._._._._._._._._._._._._._._._._._._._._._



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From duncan at research.bell-labs.com  Fri Oct  4 15:35:23 2002
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Fri, 4 Oct 2002 09:35:23 -0400
Subject: [R] Re: Matlab to R ?
In-Reply-To: <15773.17834.519855.498186@gargle.gargle.HOWL>; from maechler@stat.math.ethz.ch on Fri, Oct 04, 2002 at 09:39:22AM +0200
References: <2C23DE2983BE034CB1CB90DB6B813FD6028AC176@uswpmx11.merck.com> <3D9BE279.FE019296@cirad.fr> <200210032051.g93KpNL18379@r.hankin.sges.auckland.ac.nz> <15773.17834.519855.498186@gargle.gargle.HOWL>
Message-ID: <20021004093523.B22667@jessie.research.bell-labs.com>


As Martin mentions, a fool-proof, automated translator from
Octave/Matlab to S is unlikely to be complete.  A very different
approach is to leave the existing code in Octave/Matlab and call it
from S.  That is "guaranteed" to have the "same" semantics.  As luck
would have it, I have implemented the basic interface between R and
Octave which allows Octave users to call R code, and that R code to
call back to Octave. The package is available from
    http://www.omegahat.org/ROctave 

There will be configuration issues and annoying bugs to work out, but
the basic model follows that of all the inter-system interfaces we
have developed and is well established.  What is needed is some users
to try it and report the problems.

I believe that a similar R-Matlab interface is feasible and I hope to
do that over the next month or two.

 D.


Martin Maechler wrote:
> 
> >>>>> "Robin" == Robin Hankin <r.hankin at auckland.ac.nz>
> >>>>>     on Fri, 4 Oct 2002 08:51:23 +1200 writes:
> 
>     Robin> Hello Michel a good place to start would be
>     Robin> R-and-octave.txt, on the contributed section of CRAN
>     Robin> (Octave is the free version of Matlab).
> 
>     Robin> This shows how common Matlab idioms translate to R.
> 
> and I assume you have seen Paul Gilbert's reply, giving "ex"
> translations of a few idioms.
> 
>     Robin> There seem to be more and more people interested in
>     Robin> porting from Matlab/octave to R.  How about a
>     Robin> specialist mailing list?
> 
> I think a few interested people should "sit together" (in cyberspace)
> and try to improve on the current state.
> I've included John Eaton, the author of GNU octave (the free
> matlab `substitute'), because he certainly knows more about the
> matlab "syntax" than any of us (and Kurt who once new a lot
> about octave).
> 
> Probably everyone agrees that a Matlab -> R translation cannot
> (and probably should not) be automated to full extent.  On the
> other hand, Paul Gilbert's "ex" script should be made into a
> perl or python {or "octave" !?} script and could be enhanced
> considerably, probably.
> 
> It could help matlab/octave users switch to R.
> Another reason I'm interested to some extent is the
> Statistics+Matlab community & software ("Wavelets", "Smoothers" etc)
> where I would like us to get better connected to.
> 
>     Robin> How about a specialist mailing list?
> 
> Not sure if this is needed and makes sense;  I have already set up a dozen
> R-SIG-* (R Special Interest Group in ****) mailing lists and
> only a few are somewhat active.
> But then it may make sense for a short time?
> 
>     MichelA> I have a matlab program. I would like to transfer code in
>     MichelA> R. Is there any translator ?  Thanks for your help
> 
> --
> Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
> ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
> phone: x-41-1-632-3408		fax: ...-1228			<><
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From peter.schlattmann at medizin.fu-berlin.de  Fri Oct  4 16:06:24 2002
From: peter.schlattmann at medizin.fu-berlin.de (Peter Schlattmann)
Date: Fri, 04 Oct 2002 16:06:24 +0200
Subject: [R] gnls from library nlme
Message-ID: <3D9DA060.8C16144C@medizin.fu-berlin.de>

Dear all,

I am trying to gain some experience with the function gnls from the nlme
package.
I tried to model the Theophyline data by trying to model the presumed
dependency of
the clearance on the body weight.

This is my  function call of gnls:

gnls(conc~SSfol(Dose,Time,lKe,lKa,lCl),data=Theoph,
params=list(lKe~1,lKa~1,lCl~Wt),start=c(-2.4,0.46,-3.22,0.01))

That's been the result:

Error in as.vector(x, mode) : cannot coerce to vector

I tried various other calls with no success. Does anyone have a hint for
me?

Thanks a lot
Peter

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Oct  4 16:22:55 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 4 Oct 2002 07:22:55 -0700 (PDT)
Subject: [R] dropterm in a function
In-Reply-To: <Pine.LNX.4.44.0210041227430.14680-100000@tal.stat.umu.se>
Message-ID: <Pine.A41.4.44.0210040717460.112986-100000@homer10.u.washington.edu>

On Fri, 4 Oct 2002, [iso-8859-1] Gran Brostrm wrote:

>
> I'm trying to use 'dropterm' (from MASS) in a function along the lines
>
> run <- function(dat){
>   fit <- (something)(Y ~ (something), data = dat)
>   lr <- dropterm(fit, test = "Chisq")
>   return(fit, lr)
> }
>
> but running 'run' I get (those scoping rules again...?)
>
> Error in terms.formula(formula, special, data = data) :
>         Object "dat" not found
>
> This works fine at the command line. Can I send 'dat' to 'dropterm'
> somehow, or what should I do?
>

What is "something"? If "something" is lm or glm this works for me. I
would expect it not to work for lme().

This isn't precisely a scoping rules issue, but a nonstandard evaluation
rules one.  Functions using model formulas have to do strange things to
evaluate variables, and they don't always work consistently.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgilbert at bank-banque-canada.ca  Fri Oct  4 16:57:31 2002
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 04 Oct 2002 10:57:31 -0400
Subject: [R] Re: Matlab to R ?
References: <2C23DE2983BE034CB1CB90DB6B813FD6028AC176@uswpmx11.merck.com> 	<3D9BE279.FE019296@cirad.fr> 	<200210032051.g93KpNL18379@r.hankin.sges.auckland.ac.nz> <15773.17834.519855.498186@gargle.gargle.HOWL>
Message-ID: <3D9DAC5B.8CC11891@bank-banque-canada.ca>

Martin Maechler wrote:

> Probably everyone agrees that a Matlab -> R translation cannot
> (and probably should not) be automated to full extent.  On the
> other hand, Paul Gilbert's "ex" script should be made into a
> perl or python {or "octave" !?} script and could be enhanced
> considerably, probably.
...

Perhaps I should have qualified the extent of the translation done by my
script somewhat more, but I'm not sure how much pay back there is from
doing a lot better job of the translation. (BTW, the script probably
pre-dates python and almost pre-dates perl.) I think you need to
distinguish at least three groups of interest in R/Matlab:

1/ Running Matlab code from R (Duncan Temple Lang's approach).

2/ Keeping a common code base to run in both R and Matlab. As far as I
know, no one is working on tools to do this, But Jim Ramsay's functional
data analysis library is based on this approach.

3/ One time conversion from Matlab to R.

My script was for the last purpose, but in addition I should add that it
is really meant for the case were one intends to keep  developing the R
version of the code once it is translated. If you just want a
translation that runs, then it is not very good (perhaps very bad). If
you want good R code with clean idioms, then even a running translation
is going to be pretty bad. So, you need to do a fair amount of work even
if you get a running translation. My script does a certain amount of the
boring part, but there is still a lot of work necessary to get good R
code.

Paul Gilbert
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From clists at perrin.socsci.unc.edu  Fri Oct  4 17:59:01 2002
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Fri, 4 Oct 2002 11:59:01 -0400 (EDT)
Subject: [R] Does the perl language have an equivalent to browser?
In-Reply-To: <20021004022548.GA5376@hortresearch.co.nz>
Message-ID: <Pine.LNX.4.21.0210041157200.26630-100000@perrin.socsci.unc.edu>

I don't know exactly what browser() does, but when you run perl -d use the
c command to follow through the script:

c <linenumber> # continue until reaching line <linenumber>

Or, set one or more breakpoints:
b <linenumber>
b <sub name>

and then use:

c

to continue to the next breakpoint.

Use d to delete a breakpoint.

Answers to this and much more can be found using perldoc perldebug.

ap

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu


On Fri, 4 Oct 2002, Patrick Connolly wrote:

> I'm asking on this list because the question will be more easily
> understood than on a Perl list.  Lots of talented people using R also
> know how to use Perl, so it's easier to ask them.
> 
> Running a Perl script with the -d switch can do some pretty neat
> things, but as far as I can tell, every line has to be done
> individually.  Is there a way to specify where to stop in the way
> browser() does in the S language?
> 
> best
> 
> 
> -- 
> Patrick Connolly
> HortResearch
> Mt Albert
> Auckland
> New Zealand 
> Ph: +64-9 815 4200 x 7188
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
> I have the world`s largest collection of seashells. I keep it on all
> the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
> 
> 
> ______________________________________________________
> The contents of this e-mail are privileged and/or confidential to the
> named recipient and are not to be used by any other person and/or
> organisation. If you have received this e-mail in error, please notify 
> the sender and delete all material pertaining to this e-mail.
> ______________________________________________________
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rlee at fpcc.net  Fri Oct  4 18:07:15 2002
From: rlee at fpcc.net (Rob Lee)
Date: Fri, 4 Oct 2002 10:07:15 -0600 (MDT)
Subject: [R] Fortran and R: F90
Message-ID: <Pine.LNX.4.33.0210040956120.16328-100000@aberdeen.fpcc.net>


I too have some messy F77 code that I'm considering porting to F90.

BUT:
Has anyone had luck creating shared-objects from F90 to load in R?

What about submitting packages to CRAN with F90 code? 

BTW: I'm using the Intel compilers for Linux - free for Not-for-profit 
orgs. 

-R

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Brian.J.GREGOR at odot.state.or.us  Fri Oct  4 18:17:41 2002
From: Brian.J.GREGOR at odot.state.or.us (Brian.J.GREGOR@odot.state.or.us)
Date: Fri, 4 Oct 2002 09:17:41 -0700 
Subject: [R] help to make a map on R
Message-ID: <372EFF9FE4E42E419C978E7A305DC5FE014E5144@EXSALEM5.highway.odot.state.or.us>

I've put together a few functions to help us make maps in our office.  The
first, import.poly, takes a ascii file export of a polygon coverage from
GeoMedia and imports it into a list that I've structured to use with the
polygon() function.  The second, plot.poly, makes maps using the polygon()
function. I also am working on functions to plot transportation networks
that I would be willing to share if anyone is interested.

import.poly <- function(x){
#  Open the text file and read into an object
   in.file <- file(x, "r")
   temp.file <- readLines(in.file)
   close(in.file)
#  Initialize a list to hold the results and vectors to hold all the
coordinates (for determining ranges)
#  poly <- lapply(1:length(temp.file), function(x) 0)
   poly <- list()
   all.x <- NULL
   all.y <- NULL
#  Each polygon is a character string in a vector.  Process each in turn.
   for(i in 1:length(temp.file)){
    temp.poly <- unlist(strsplit(temp.file[i], ",")) # create charater
vector from character string
    zone <- temp.poly[1] # extract the polygon identifier
    x <- as.numeric(temp.poly[seq(3, length(temp.poly), by=2)]) # extract a
vector of x coordinates
    y <- as.numeric(temp.poly[seq(2, length(temp.poly)-1, by=2)])  # extract
a vector of y coordinates
    poly[[i]] <- list("zone"=zone, "x"=x, "y"=y)  # make a list element of
the identifier and the xs and ys
    all.x <- c(all.x, x)  # concatenate the xs to a master list
    all.y <- c(all.y, y)  # concatenate the ys to a master list
   }
   x.range <- range(all.x)  # determine the range of all xs
   y.range <- range(all.y)  # determine the range of all ys
   result <- list("x.range"=x.range, "y.range"=y.range, "poly"=poly)  # put
the ranges and polygon info in a list
}

plot.poly <- function(geo, data, n, type="e", br=0, col="heat", leg.loc=0,
bnd=0, size=5, title=""){
#  The arguments are: geo = the geographic coverage
#  data = the data to be plotted by color.  Must be a vector with a names
attribute equal to the polygon names
#  n = the number of classes to depict
#  type = the types of class breaks: "e" = equal interval, "q" = quantile,
"c" = custom
#  br = a vector of custom breaks, only necessary if type="c"
#  col = name of an R color palette.  Supported types are "heat", "topo",
"terrain" and "rainbow"
#  leg.loc = a list (constructed using locator(1)) with the legend location.
This is optional.
#  bnd = a list (constructed using locator(2)) with the boundaries of the
area to be plotted.  This is optional.
#  size = the size of the maximum plot dimension in inches (default is 5
inches)
#  title = the title to be printed on the plot
#  Establish the plotting range if established with "bnd" argument or entire
coverage
   if(is.list(bnd)){xrange <- c(min(bnd$x), max(bnd$x)); yrange <-
c(min(bnd$y), max(bnd$y))}   
   else {xrange <- geo$x.range; yrange <- geo$y.range}
#  Scale the x and y dimenstions to be geographically correct   
   xlen <- abs(diff(xrange))*49  # 49 miles for each degree of longitude
   ylen <- abs(diff(yrange))*69  # 69 miles for each degree of latitude
   maxlen <- max(xlen, ylen)
   par(pin=size*c(xlen/maxlen, ylen/maxlen)) # set the plot size parameters
#  Plot a blank frame with title and axis labels
   plot(0, 0, xlim=xrange, ylim=yrange, type="n", xlab="longitude",
ylab="latitude", main=title)
#  Set up the color palette for plotting
   if(col=="heat") colors <- heat.colors(n)
   if(col=="rainbow") colors <- rainbow(n)
   if(col=="terrain") colors <- terrain.colors(n)
   if(col=="topo") colors <- topo.colors(n)
#  Set up the class breaks depending on the type parameter (custom, equal
interval, or quantile)
   if(type=="c") br <- br
   if(type=="e") br <- seq(min(data), max(data), length=n+1)
   if(type=="q") br <- quantile(data, probs=seq(0,1,1/n))
   cuts <- cut(data, br, labels=F, include.lowest=T)
   names(cuts) <- names(data) # name the vector of factors the same as the
data, used later in coloring
#  Go through a loop to plot each polygon
   for(i in 1:length(geo$poly)){
      color <- colors[cuts[geo$poly[[i]]$zone]] # choose the plot color
based on the class it is in
      polygon(geo$poly[[i]]$x, geo$poly[[i]]$y, col=color) # plot the
polygon with that color
   }
#  Plot the legend
   cuts <- cut(data, br, include.lowest=T) # do cuts() again to get
intervals for the cuts rather than integers 
   leg.txt <- as.character(levels(cuts)) # convert the intervals into text
to use in the legend
   if(leg.loc==0) leg.loc <- locator(1) # if the legend location has not
been specified wait for user to locate it
   legend(leg.loc$x, leg.loc$y, leg.txt, fill=colors, bg="white") # plot the
legend
}

Brian Gregor, P.E.
Transportation Planning Analysis Unit
Oregon Department of Transportation
Brian.J.GREGOR at odot.state.or.us
(503) 986-4120
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Benjamin.STABLER at odot.state.or.us  Fri Oct  4 18:59:57 2002
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Fri, 4 Oct 2002 09:59:57 -0700 
Subject: [R] R 1.6 Gui for Windows
Message-ID: <76A000A82289D411952F001083F9DD06039AC79E@EXSALEM4-BU.highway.odot.state.or.us>

I upgraded to R Gui 1.6 this morning and I can't seem to get it to accept my
new startup directory.  R 1.51 will accept
"F:\_ben\bls\gen1\results\bls\analysis" as the start in directory for the R
Gui shortcut, but R 1.6 will not.  R 1.6 will accept
"F:\_ben\bls\gen1\results\bls".  It seems to have trouble when I add
"\analysis."  R still loads fine but I get the following error:

Error in testRversion(descfile) : This package has not been installed
properly
See the Note in ?library

Also, R 1.6 will let me set the working directory to include "analysis."  I
can ignore the error and R still loads in the correct directory.  But I am
curious as to why this is.  Any ideas?  Thanks.

Ben Stabler
Oregon, USA.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plorch at zoo.utoronto.ca  Fri Oct  4 19:37:25 2002
From: plorch at zoo.utoronto.ca (plorch@zoo.utoronto.ca)
Date: Fri, 4 Oct 2002 13:37:25 -0400
Subject: [R] Using an external editor to write functions
Message-ID: <F20C102A-D7BF-11D6-88F3-0050E4F94F2A@zoo.utoronto.ca>

I am having trouble getting a new version of Alphatk to send commands to 
R.  I have filed a bug report with the Alpha guys about that.

In the meantime, and for those not using Alpha and not wanting to us 
fix() or edit(), what is the best way to import the text of the function 
after modifying it so that it can be run in R (carbon GUI version 1.5.1 
on OS X 10.1.5)?  I have been typing
	name<-
and then pasting the function from the clipboard.  I seem to remember a 
more elegant way to do this, but ...
	Thanks,
	 -Pat

	Dr. Patrick D. Lorch
	Zoology Dept.				W: 416-978-0172
	University of Toronto		F: 416-978-8532
	Ramsay Wright Labs		plorch at zoo.utoronto.ca
	25 Harbord St.			http://www.zoo.utoronto.ca/lrowe/plorch
	Toronto, Ontario  M5S 3G5
	CANADA

Public encryption key available upon request.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Fri Oct  4 21:00:18 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 4 Oct 2002 21:00:18 +0200 (CEST)
Subject: [R] dropterm in a function
In-Reply-To: <Pine.A41.4.44.0210040717460.112986-100000@homer10.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0210042054390.15775-100000@tal.stat.umu.se>

On Fri, 4 Oct 2002, Thomas Lumley wrote:

> On Fri, 4 Oct 2002, [iso-8859-1] G?ran Brostr?m wrote:
>
> >
> > I'm trying to use 'dropterm' (from MASS) in a function along the lines
> >
> > run <- function(dat){
> >   fit <- (something)(Y ~ (something), data = dat)
> >   lr <- dropterm(fit, test = "Chisq")
> >   return(fit, lr)
> > }
> >
> > but running 'run' I get (those scoping rules again...?)
> >
> > Error in terms.formula(formula, special, data = data) :
> >         Object "dat" not found
> >
> > This works fine at the command line. Can I send 'dat' to 'dropterm'
> > somehow, or what should I do?
> >
>
> What is "something"? If "something" is lm or glm this works for me. I
> would expect it not to work for lme().

It is 'coxph'. So I shouldn't expect it to work? A pity, because it is a
nice feature. Thanks,

G?ran


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Fri Oct  4 21:05:48 2002
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 4 Oct 2002 12:05:48 -0700
Subject: [R] Getting rid of extra connections?
Message-ID: <p05111a01b9c394b99cf6@[128.115.153.6]>

I'm trying to figure out how to get out of this situation:

>  source('monit.r')
Error in file(file, "r") : All connections are in use

>  showConnections()
      description class mode text isopen can read can write

>  help.search('connection')
Error in file(file, "r") : All connections are in use

>  q()
Save workspace image? [y/n/c]: y
Error in file(file, "wb") : All connections are in use

As best as I can tell, I got a bunch of extra connections by 
experimenting with the split.scree() and layout() functions. But I 
can't, so far, find a way to remove or close them. When I use ls() to 
see a list of objects, they all look like things I explicitly 
created, i.e., vectors, lists, functions, etc., and not like 
connection objects. I can't find any connection object to close with 
the close() function. I have closed all graphics devices with 
dev.off().

I suppose I can quit without saving, and then restart R to get out of 
this mess, but I'd like to find a clean way out. Suggestions?

Thanks
-Don

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Oct  4 21:15:38 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 4 Oct 2002 12:15:38 -0700 (PDT)
Subject: [R] dropterm in a function
In-Reply-To: <Pine.LNX.4.44.0210042054390.15775-100000@tal.stat.umu.se>
Message-ID: <Pine.A41.4.44.0210041215130.66818-100000@homer04.u.washington.edu>

On Fri, 4 Oct 2002, [iso-8859-1] Gran Brostrm wrote:

> On Fri, 4 Oct 2002, Thomas Lumley wrote:
>
> > On Fri, 4 Oct 2002, [iso-8859-1] Gran Brostrm wrote:
> >
> > >
> > > I'm trying to use 'dropterm' (from MASS) in a function along the lines
> > >
> > > run <- function(dat){
> > >   fit <- (something)(Y ~ (something), data = dat)
> > >   lr <- dropterm(fit, test = "Chisq")
> > >   return(fit, lr)
> > > }
> > >
> > > but running 'run' I get (those scoping rules again...?)
> > >
> > > Error in terms.formula(formula, special, data = data) :
> > >         Object "dat" not found
> > >
> > > This works fine at the command line. Can I send 'dat' to 'dropterm'
> > > somehow, or what should I do?
> > >
> >
> > What is "something"? If "something" is lm or glm this works for me. I
> > would expect it not to work for lme().
>
> It is 'coxph'. So I shouldn't expect it to work? A pity, because it is a
> nice feature. Thanks,
>

No, you should expect it to work, I just know that it doesn't. It needs
fixing.


	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mail at fwr.on.ca  Fri Oct  4 21:17:51 2002
From: mail at fwr.on.ca (FWR)
Date: Fri, 4 Oct 2002 15:17:51 -0400
Subject: [R] spline bug ?
Message-ID: <E17xXxQ-0004Em-00@server.family>

The bug reported above for "spline" is probably related to a similar problem with sequencing in POSIX dates.
For example this works ok:
> seq(from=1,to=4,out.length=4)
 [1]  1  2  3  4 

But the following gives an output length of five, not four:
> seq(from=ISOdate(2000,1,1),to=ISOdate(2000,1,4),length.out=4)
[1] "2000-01-01 07:00:00 EST" "2000-01-02 01:00:00 EST"
[3] "2000-01-02 19:00:00 EST" "2000-01-03 13:00:00 EST"
[5] "2000-01-04 07:00:00 EST"

Surely this is a bug?

Bruce L.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Fri Oct  4 22:04:44 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 04 Oct 2002 15:04:44 -0500
Subject: [R] Binaries of R-1.6.0 for Debian
Message-ID: <6rlm5eotr7.fsf@bates3.stat.wisc.edu>

Dirk Eddelbuettel prepared and uploaded the Debian source and
i386-binary packages for R-1.6.0 to the Debian mirrors on Oct. 1.  By
now these sources have been compiled on several other architectures
including alpha, hppa, ia64, mips, and powerpc.  Those running the
testing versions of Debian 3.1 (codename "sarge") or the unstable
versions of Debian 3.1 (codename "sid") can update their packages
using standard Debian package tools, such as apt, and the Debian
archives.

As a convenience we provide copies of the i386 packages on CRAN under
bin/linux/debian.  In addition, we have prepared binary (i386) versions 
of these packages for Debian 3.0 (codename "woody"), the stable
release.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Fri Oct  4 22:13:35 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 Oct 2002 22:13:35 +0200
Subject: [R] spline bug ?
In-Reply-To: <E17xXxQ-0004Em-00@server.family>
References: <E17xXxQ-0004Em-00@server.family>
Message-ID: <15773.63087.171899.462397@gargle.gargle.HOWL>

>>>>> "Bruce" == Bruce L <mail at fwr.on.ca>
>>>>>     on Fri, 4 Oct 2002 15:17:51 -0400 writes:

    Bruce> The bug reported above for "spline" is probably related to a similar problem with sequencing in POSIX dates.
    Bruce> For example this works ok:
    >> seq(from=1,to=4,out.length=4)
    Bruce> [1]  1  2  3  4 

    Bruce> But the following gives an output length of five, not four:
    >> seq(from=ISOdate(2000,1,1),to=ISOdate(2000,1,4),length.out=4)
    Bruce> [1] "2000-01-01 07:00:00 EST" "2000-01-02 01:00:00 EST"
    Bruce> [3] "2000-01-02 19:00:00 EST" "2000-01-03 13:00:00 EST"
    Bruce> [5] "2000-01-04 07:00:00 EST"

    Bruce> Surely this is a bug?

indeed.  Thanks a lot for reducing the problem so far!

The bug is in  seq.POSIXct()
and here is the fix -- soon to appear in "R-patched"  snapshots.

Index: src/library/base/R/datetime.R
===================================================================
RCS file: /home/rdevel/CVS-ARCHIVE/R/src/library/base/R/datetime.R,v
retrieving revision 1.35.2.1
retrieving revision 1.35.2.2
diff -w -r1.35.2.1 -r1.35.2.2
461,462c461,464
<         incr <- (to - from)/length.out
<         res <- seq.default(from, to, incr)
---
>         ## Till (and incl.) 1.6.0 :
>         ##- incr <- (to - from)/length.out
>         ##- res <- seq.default(from, to, incr)
>         res <- seq.default(from, to, length.out = length.out)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Fri Oct  4 23:36:53 2002
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 4 Oct 2002 14:36:53 -0700
Subject: [R] Getting rid of extra connections?
In-Reply-To: <x2fzvlncmi.fsf@biostat.ku.dk>
References: <p05111a01b9c394b99cf6@[128.115.153.6]>
 <x2fzvlncmi.fsf@biostat.ku.dk>
Message-ID: <p05111a06b9c3b834edc1@[128.115.153.6]>

Thank you Peter,

For anyone who is interested, these two examples illustrate nicely:

## example 1
for (i in 1:50) {foo <- pipe('date') ; rm(foo) ; cat(i,' ')}
showConnections(all=T)
closeAllConnections()

## example 2
for (i in 1:50) {foo <- pipe('date') ; close(foo) ; cat(i,' ')}


I would have sworn I had tried putting that close() in there, but 
evidently I didn't. Also, I was looking at ?connections, but missed 
?showConnections. Oops.

I did figure out that I was wrong about split.screen being the cause. 
I'm actually monitoring several data files that have new data 
appended once per minute, and my current code uses pipe() like yours. 
Down the road I'm hoping to use a socket connection.


>  version
          _                  
platform sparc-sun-solaris2.7
arch     sparc              
os       solaris2.7         
system   sparc, solaris2.7  
status                      
major    1                  
minor    5.1                
year     2002               
month    06                 
day      17
language R                  

-Don

At 11:00 PM +0200 10/4/02, Peter Dalgaard BSA wrote:
>Don MacQueen <macq at llnl.gov> writes:
>
>>  I'm trying to figure out how to get out of this situation:
>>
>>  >  source('monit.r')
>>  Error in file(file, "r") : All connections are in use
>>
>>  >  showConnections()
>>        description class mode text isopen can read can write
>>
>>  >  help.search('connection')
>>  Error in file(file, "r") : All connections are in use
>>
>>  >  q()
>>  Save workspace image? [y/n/c]: y
>>  Error in file(file, "wb") : All connections are in use
>>
>>  As best as I can tell, I got a bunch of extra connections by
>>  experimenting with the split.scree() and layout() functions. But I
>>  can't, so far, find a way to remove or close them. When I use ls() to
>>  see a list of objects, they all look like things I explicitly created,
>>  i.e., vectors, lists, functions, etc., and not like connection
>>  objects. I can't find any connection object to close with the close()
>>  function. I have closed all graphics devices with dev.off().
>>
>>  I suppose I can quit without saving, and then restart R to get out of
>>  this mess, but I'd like to find a clean way out. Suggestions?
>
>Happened to me recently. (With a function designed to monitor my sales
>rank at Amazon if you must know...) showConnections(all=T) indicates
>what is up, and closeAllConnections() is the immediate way out. To
>avoid getting into the pickle in the first place, you need to use code
>like
>
>    z <- scan(c<-pipe("grep -v CEST ~/sales.log"))
>    close(c)
>
>The last bit looks like a clear bug. Surely, we could
>closeAllConnections() before trying to save the workspace?
>
>--
>    O__  ---- Peter Dalgaard             Blegdamsvej 3 
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N  
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Sat Oct  5 02:16:25 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 04 Oct 2002 19:16:25 -0500
Subject: [R] gnls from library nlme
In-Reply-To: <3D9DA060.8C16144C@medizin.fu-berlin.de>
References: <3D9DA060.8C16144C@medizin.fu-berlin.de>
Message-ID: <6rvg4hoi3q.fsf@bates3.stat.wisc.edu>

Peter Schlattmann <peter.schlattmann at medizin.fu-berlin.de> writes:

> Dear all,
> 
> I am trying to gain some experience with the function gnls from the nlme
> package.
> I tried to model the Theophyline data by trying to model the presumed
> dependency of
> the clearance on the body weight.
> 
> This is my  function call of gnls:
> 
> gnls(conc~SSfol(Dose,Time,lKe,lKa,lCl),data=Theoph,
> params=list(lKe~1,lKa~1,lCl~Wt),start=c(-2.4,0.46,-3.22,0.01))
> 
> That's been the result:
> 
> Error in as.vector(x, mode) : cannot coerce to vector
> 
> I tried various other calls with no success. Does anyone have a hint for
> me?
> 
> Thanks a lot
> Peter

There is a bug in the R version of gnls.  A certain construction is
needed when deparsing in S-PLUS but not needed in R.

I will upload a new version of the nlme package for R.  If you want to
test out the fix, the diff is given below.

Index: gnls.R
===================================================================
RCS file: /home/CVS/src/Rlibs/nlme/R/gnls.R,v
retrieving revision 1.7.2.2
diff -c -r1.7.2.2 gnls.R
*** gnls.R	9 Aug 2002 19:45:28 -0000	1.7.2.2
--- gnls.R	5 Oct 2002 00:04:48 -0000
***************
*** 233,239 ****
    names(plist) <- pnames
    for (nm in pnames) {
      plist[[nm]] <- TRUE
!     if (deparse(as.vector(params[[nm]][[3]])) != "1") {
        plist[[nm]] <-
          model.matrix(asOneSidedFormula(params[[nm]][[3]]),
                   model.frame(asOneSidedFormula(params[[nm]][[3]]), dataModShrunk))
--- 233,239 ----
    names(plist) <- pnames
    for (nm in pnames) {
      plist[[nm]] <- TRUE
!     if (deparse(params[[nm]][[3]]) != "1") {
        plist[[nm]] <-
          model.matrix(asOneSidedFormula(params[[nm]][[3]]),
                   model.frame(asOneSidedFormula(params[[nm]][[3]]), dataModShrunk))

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at cbs.dtu.dk  Sat Oct  5 14:49:22 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Sat, 5 Oct 2002 14:49:22 +0200
Subject: [R] R.1.6.0 and R CMD check (one more thing)
Message-ID: <20021005124922.GB2063@giraffa.cbs.dtu.dk>

 forget to say that if I install the pacakge, and copy paste
 the example in a R session after loading the package, the example
 works....



 L.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at cbs.dtu.dk  Sat Oct  5 14:47:33 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Sat, 5 Oct 2002 14:47:33 +0200
Subject: [R] R-1.6.0 and R CMD check
Message-ID: <20021005124733.GA2063@giraffa.cbs.dtu.dk>

Hi,

I upgraded to R-1.6.0 and R CMD check is behaving a bit weird.
The package I am check cannot make it throught because of
errors like 

> ##___ Examples ___:
> 
>      data(Dilution)
>      hist(Dilution[,1])
Error in if (log == T) { : missing value where logical needed
Execution halted


while the function called in the example defined in the .Rd fiel
as a signature in which 'log=T' is stated...
If I comment out this example I end up with an another similar error
in an another example. 


Am I the only one ?


Laurent

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sat Oct  5 14:42:18 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 05 Oct 2002 14:42:18 +0200
Subject: [R] R-1.6.0 and R CMD check
In-Reply-To: <20021005124733.GA2063@giraffa.cbs.dtu.dk>
References: <20021005124733.GA2063@giraffa.cbs.dtu.dk>
Message-ID: <x2bs69m505.fsf@biostat.ku.dk>

Laurent Gautier <laurent at cbs.dtu.dk> writes:

> Hi,
> 
> I upgraded to R-1.6.0 and R CMD check is behaving a bit weird.
> The package I am check cannot make it throught because of
> errors like 
> 
> > ##___ Examples ___:
> > 
> >      data(Dilution)
> >      hist(Dilution[,1])
> Error in if (log == T) { : missing value where logical needed
> Execution halted
> 
> 
> while the function called in the example defined in the .Rd fiel
> as a signature in which 'log=T' is stated...
> If I comment out this example I end up with an another similar error
> in an another example. 
> 
> 
> Am I the only one ?

The new QA tools are more insistent that you use the canonical
TRUE/FALSE rather than T/F in examples. T and F are ordinary variables
which might be redefined by the user and R CMD check now simulates
that situation by running the checks with T <- F <- NULL.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From stamps.d.a at att.net  Sat Oct  5 16:43:49 2002
From: stamps.d.a at att.net (David Stamps)
Date: Sat, 05 Oct 2002 10:43:49 -0400
Subject: [R] Implementation of  S-Plus "nlmib" routine in R
Message-ID: <3D9EFAA5.9050209@att.net>

Where can I find a package with an R  implementation of the S-Plus
"nlmib" general
minimzation routine described in
Venables & Ripley's  "Modern Applie Statistics with S-Plus", 3rd Ed., pp
267 - 270?

Thanks,

David Stamps
stamps.d.a at att.net






-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Sat Oct  5 17:36:10 2002
From: siim at obs.ee (Ott Toomet)
Date: Sat, 5 Oct 2002 17:36:10 +0200 (CEST)
Subject: [R] pipes in R
In-Reply-To: <F179nrYclEKDX8zGDms0001388e@hotmail.com>
Message-ID: <Pine.LNX.4.44.0210051732510.1390-100000@localhost.localdomain>

Hola,

On Fri, 4 Oct 2002, juan pablo perez wrote:

  |Hello!
  |it?s possible to build pipes in R?
  |
  |e.g. something like this
  |
  |boxplot(aaa$bbb)|dev.print(postscript)

Unfortunately, I do not know about pipes as you mentioned.  But you may use
pipes in filenames as

plot(...)
dev.copy2eps(file="|lpr -Pfoo")

or something like that.  Be aware that using a wrong (nonexistent) command with pipe
kills R 1.5.1 (I suppose not 1.6.0).

Ott


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Sat Oct  5 19:46:58 2002
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 05 Oct 2002 13:46:58 -0400
Subject: [R] Implementation of  S-Plus "nlmib" routine in R
In-Reply-To: <3D9EFAA5.9050209@att.net>
Message-ID: <5.1.0.14.2.20021005134542.02c9a3d0@mcmail.cis.mcmaster.ca>

Dear David,

At 10:43 AM 10/5/2002 -0400, David Stamps wrote:
>Where can I find a package with an R  implementation of the S-Plus
>"nlmib" general
>minimzation routine described in
>Venables & Ripley's  "Modern Applie Statistics with S-Plus", 3rd Ed., pp
>267 - 270?

The optimization functions in R and S-PLUS are a different. Take a look at 
nlm and optim in R.

I hope that this helps,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jyan at stat.wisc.edu  Sat Oct  5 21:55:33 2002
From: jyan at stat.wisc.edu (Jun Yan)
Date: Sat, 5 Oct 2002 14:55:33 -0500 (CDT)
Subject: [R] Implementation of  S-Plus "nlmib" routine in R
In-Reply-To: <3D9EFAA5.9050209@att.net>
Message-ID: <Pine.LNX.4.21.0210051454040.12441-100000@ludwig.stat.wisc.edu>

On Sat, 5 Oct 2002, David Stamps wrote:

> Where can I find a package with an R  implementation of the S-Plus
> "nlmib" general
> minimzation routine described in
> Venables & Ripley's  "Modern Applie Statistics with S-Plus", 3rd Ed., pp
> 267 - 270?

David,

R base has functions to do that. See

?nlm
?D

and the reference therein.

Jun Yan

Department of Statistics          Office: CSSC 4252
university of Wisconsin-Madison   Tel: (608)262-7478 
1210 W. Dayton St.                Email: jyan at stat.wisc.edu
Madison, WI 53706                 URL: http://www.stat.wisc.edu/~jyan





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From v.samak at verizon.net  Sat Oct  5 23:21:00 2002
From: v.samak at verizon.net (Vele Samak)
Date: Sat, 5 Oct 2002 17:21:00 -0400
Subject: [R] Implementation of  S-Plus "nlmib" routine in R
In-Reply-To: <3D9EFAA5.9050209@att.net>
Message-ID: <000001c26cb5$1a5edc60$6501a8c0@prilep>

Try nlm and optim in the base package. Both of these are substitutes for
the nlminb in splus, although optim is a more generic one with box
constraints. 

Perhaps others can elaborate on this. 

--
Vele Samak
http://www.velesamak.com 

-----Original Message-----
From: owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch] On Behalf Of David Stamps
Sent: Saturday, October 05, 2002 10:44 AM
To: R-help at stat.math.ethz.ch
Subject: [R] Implementation of S-Plus "nlmib" routine in R


Where can I find a package with an R  implementation of the S-Plus
"nlmib" general minimzation routine described in Venables & Ripley's
"Modern Applie Statistics with S-Plus", 3rd Ed., pp 267 - 270?

Thanks,

David Stamps
stamps.d.a at att.net






-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-.-
r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Sun Oct  6 00:04:13 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Sat, 5 Oct 2002 15:04:13 -0700 (PDT)
Subject: [R] R-1.6.0 and R CMD check
In-Reply-To: <20021005124733.GA2063@giraffa.cbs.dtu.dk>
Message-ID: <20021005220413.46352.qmail@web13903.mail.yahoo.com>


Hi,

this is probably due to changes in R CMD check that now complain if T and F are
used instead of TRUE and FALSE (which is risky because T and F can be
overridden by the user). From the R 1.6.0 announcement:


         CHANGES IN R VERSION 1.6.0

[...]


UTILITIES

    o	R CMD check now tests for mis-use on an installed or binary
	package, and sets 'T' and 'F' to 'NULL' when running the
	examples.


Deepayan

--- Laurent Gautier <laurent at cbs.dtu.dk> wrote:
> Hi,
> 
> I upgraded to R-1.6.0 and R CMD check is behaving a bit weird.
> The package I am check cannot make it throught because of
> errors like 
> 
> > ##___ Examples ___:
> > 
> >      data(Dilution)
> >      hist(Dilution[,1])
> Error in if (log == T) { : missing value where logical needed
> Execution halted
> 
> 
> while the function called in the example defined in the .Rd fiel
> as a signature in which 'log=T' is stated...
> If I comment out this example I end up with an another similar error
> in an another example. 
> 
> 
> Am I the only one ?
> 
> 
> Laurent
> 
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


__________________________________________________

Faith Hill - Exclusive Performances, Videos & More

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jrogers at cantatapharm.com  Sun Oct  6 02:33:48 2002
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Sat, 5 Oct 2002 20:33:48 -0400
Subject: [R] T-Distribution
Message-ID: <99A12772DCDEEB458B996332957B0D530116B8@mercury.cantatapharm.com>

Timo (see below) was kind enough to reply in private that part of my comment was incorrect. 
 
As he points out, the joint distribution of two independent T distributions is NOT a multivariate T distribution in the usual sense. That distinction had not occured to me. 
 
I hope I do more good than harm by trying to learn in public...
 
Jim
 
-----Original Message----- 
From: Timo M?kel?inen [mailto:Timo.Makelainen at Helsinki.fi] 
Sent: Sat 10/5/2002 1:52 AM 
To: Jim Rogers 
Cc: 
Subject: Re: [R] T-Distribution



	On 4 Oct 2002, at 9:02, Jim Rogers wrote:
	
	> Roger Koeneker wrote:
	>
	> >
	> >   rmvt <- function(corr,df)
	> rmvnorm(n,sigma=corr)/sqrt(rchisq(n,df)/df)
	> >
	>
	> That would do the trick.
	>
	> One interesting note relating to Hicham's original question (Hicham
	> was the originator of this thread):
	>
	> The multivariate T distribution does not have elliptical contours. For
	> example, the contours of an independent bivariate T are not circles.
	
	But this differs from common usage (and your formulae above):  the
	multivariate T has dependent components and also ellipsoidal level
	surfaces (Raiffa & Schlaifer 1961, 1968, Section 8.3; there may be
	a problem with subsection 8.3.1, though).
	
	> One of the many fascinating facts about the independent bivariate
	> Normal distribution is that it is the ONLY independent bivariate
	> distribution with circular contours. Many people may know this, but I
	> know it was a surprise to me when I learned it.
	>
	> --Jim
	>
	> James A. Rogers <rogers at cantatapharm.com>
	> Statistical Scientist
	> Cantata Pharmaceuticals
	>
	> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
	> -.-.-.-.- r-help mailing list -- Read
	> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help",
	> or "[un]subscribe" (in the "body", not the subject !)  To:
	> r-help-request at stat.math.ethz.ch
	> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
	> _._._._._
	
	Best wishes,
	
	Timo
	
	
	Timo Makelainen, Department of Mathematics
	University of Helsinki, P.O. Box 4
	FIN-00014 Helsinki
	Tel.: +358-9-19122863
	Fax:  +358-9-19123213
	E-mail: Timo.Makelainen at Helsinki.Fi
	


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mabramso at gmu.edu  Sun Oct  6 06:09:28 2002
From: mabramso at gmu.edu (Myriam Abramson)
Date: 06 Oct 2002 00:09:28 -0400
Subject: [R] error bars in line plots
Message-ID: <m3adlsryx3.fsf@home.sweet.home>

Hi!

Could you tell me how I can draw a graph with error bars? 
Sorry, I don't use R that often and I couldn't find it easily in the
documentation. 

TIA


-- 
                                   myriam

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ko-Kang at xtra.co.nz  Sun Oct  6 12:12:34 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Sun, 6 Oct 2002 23:12:34 +1300
Subject: [R] error bars in line plots
References: <m3adlsryx3.fsf@home.sweet.home>
Message-ID: <001601c26d20$e4ee78d0$7f2758db@kwan022>

Hi,

Take a look at http://finzi.psych.upenn.edu/R/Rhelp02/archive/4124.html and
its thread.

You may want to bookmark Jonathan Baron's page,
http://finzi.psych.upenn.edu/search.html , which lets you search the r-help
archive and R documentations.  You can find more information about error
bars there.

Hope this helps,

Kevin

------------------------------------------------
Ko-Kang Kevin Wang
Post Graduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckand.ac.nz/~kwan022

----- Original Message -----
From: "Myriam Abramson" <mabramso at gmu.edu>
To: <r-help at stat.math.ethz.ch>
Sent: Sunday, October 06, 2002 5:09 PM
Subject: [R] error bars in line plots


> Hi!
>
> Could you tell me how I can draw a graph with error bars?
> Sorry, I don't use R that often and I couldn't find it easily in the
> documentation.
>
> TIA
>
>
> --
>                                    myriam
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Marcus_Jellinghaus at gmx.de  Sun Oct  6 15:49:51 2002
From: Marcus_Jellinghaus at gmx.de (Marcus Jellinghaus)
Date: Sun, 6 Oct 2002 09:49:51 -0400
Subject: [R] Why are big data.frames slow? What can I do to get it faster?
Message-ID: <ANEPLCDCPMDLBOLGOBCBIEJBDPAA.Marcus_Jellinghaus@GMX.DE>

Hello,

I?m quite new to this list.
I have a high frequency-dataset with more than 500.000 records.
I want to edit a data.frame "Test". My small programm runs fine with a small
part of the dataset (just 100 records), but it is very slow with a huge
dataset. Of course it get?s slower with more records, but when I change just
the size of the frame and keep the number of edited records fixed, I see
that it is also getting slower.

Here is my program:

print(dim(test)[1])
Sys.time()
for(i in 1:100) {
  test[i,6] = paste(test[i,2],"-",test[i,3], sep = "")
}
Sys.time()

I connect 2 currency symbols to a currency pair.
I always calculate only for the first 100 lines.
WHen I load just 100 lines in the data.frame "test", it takes 1 second.
When I load 1000 lines, editing 100 lines takes 2 seconds,
10,000 lines loaded and 100 lines editing takes 5 seconds,
100,000 lines loaded and editing 100 lines takes 31 seconds,
500,000 lines loaded and editing 100 lines takes 11 minutes(!!!).

My computer has 1 GB Ram, so that shouldn?t be the reason.

Of course, I could work with many small data.frames instead of one big, but
the program above is just the very first step and so I don?t want to split.

Is there a way to edit big data.frames without waiting for a long time?


Thank?s a lot for help,


Marcus

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sun Oct  6 16:55:54 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 06 Oct 2002 16:55:54 +0200
Subject: [R] R 1.6 Gui for Windows
References: <76A000A82289D411952F001083F9DD06039AC79E@EXSALEM4-BU.highway.odot.state.or.us>
Message-ID: <3DA04EFA.40820905@statistik.uni-dortmund.de>

Benjamin.STABLER at odot.state.or.us wrote:
> 
> I upgraded to R Gui 1.6 this morning and I can't seem to get it to accept my
> new startup directory.  R 1.51 will accept
> "F:\_ben\bls\gen1\results\bls\analysis" as the start in directory for the R
> Gui shortcut, but R 1.6 will not.  R 1.6 will accept
> "F:\_ben\bls\gen1\results\bls".  It seems to have trouble when I add
> "\analysis."  R still loads fine but I get the following error:
>
> Error in testRversion(descfile) : This package has not been installed
> properly
> See the Note in ?library
> 
> Also, R 1.6 will let me set the working directory to include "analysis."  

[Looks like there wasn't any answer to this mail before]
Including the dot?


> I can ignore the error and R still loads in the correct directory.  
> But I am curious as to why this is.  Any ideas?  Thanks.

 
Maybe there is an .Renviron or .Rprofile file or something like that in
your directory that causes the error message? Or a .First() function in
your .Rdata workspace in that directory?

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Sun Oct  6 18:11:43 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 6 Oct 2002 09:11:43 -0700 (PDT)
Subject: [R] Implementation of  S-Plus "nlmib" routine in R
In-Reply-To: <3D9EFAA5.9050209@att.net>
Message-ID: <Pine.A41.4.44.0210060910010.12090-100000@homer25.u.washington.edu>

On Sat, 5 Oct 2002, David Stamps wrote:

> Where can I find a package with an R  implementation of the S-Plus
> "nlmib" general
> minimzation routine described in
> Venables & Ripley's  "Modern Applie Statistics with S-Plus", 3rd Ed., pp
> 267 - 270?


The method="L-BFGS-B" option in optim() is a box-constrained quasi-Newton
optimiser.   I don't know if it's the same one as nlminb, but it works
pretty well.  There's also method="BFGS" for an unconstrained version that
may be more efficient.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sun Oct  6 19:57:39 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 06 Oct 2002 19:57:39 +0200
Subject: [R] Why are big data.frames slow? What can I do to get it faster?
References: <ANEPLCDCPMDLBOLGOBCBIEJBDPAA.Marcus_Jellinghaus@GMX.DE>
Message-ID: <3DA07993.90E08E4B@statistik.uni-dortmund.de>

Marcus Jellinghaus wrote:
> 
> Hello,
> 
> I?m quite new to this list.
> I have a high frequency-dataset with more than 500.000 records.
> I want to edit a data.frame "Test". My small programm runs fine with a small
> part of the dataset (just 100 records), but it is very slow with a huge
> dataset. Of course it get?s slower with more records, but when I change just
> the size of the frame and keep the number of edited records fixed, I see
> that it is also getting slower.
> 
> Here is my program:
> 
> print(dim(test)[1])
> Sys.time()
> for(i in 1:100) {
>   test[i,6] = paste(test[i,2],"-",test[i,3], sep = "")
> }
> Sys.time()
> 
> I connect 2 currency symbols to a currency pair.
> I always calculate only for the first 100 lines.
> WHen I load just 100 lines in the data.frame "test", it takes 1 second.
> When I load 1000 lines, editing 100 lines takes 2 seconds,
> 10,000 lines loaded and 100 lines editing takes 5 seconds,
> 100,000 lines loaded and editing 100 lines takes 31 seconds,
> 500,000 lines loaded and editing 100 lines takes 11 minutes(!!!).
> 
> My computer has 1 GB Ram, so that shouldn?t be the reason.
> 
> Of course, I could work with many small data.frames instead of one big, but
> the program above is just the very first step and so I don?t want to split.
> 
> Is there a way to edit big data.frames without waiting for a long time?

Well, the point is, I guess, to address elements in a large data.frame,
which reasonably takes much more time than in a small one.

Maybe it's an idea to use vectorized operations instead of the loop,
which is preferable, if your computation is easy vectorizable without a
big penalty of memory consumption:

 test[1:100, 6] <- paste(test[1:100, 2], "-", test[1:100, 3], sep = "")
or 
 test[ , 6] <- paste(test[ , 2], "-", test[ , 3], sep = "")
for the whole data.frame.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Sun Oct  6 23:21:41 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 6 Oct 2002 14:21:41 -0700 (PDT)
Subject: [R] Why are big data.frames slow? What can I do to get it faster?
In-Reply-To: <ANEPLCDCPMDLBOLGOBCBIEJBDPAA.Marcus_Jellinghaus@GMX.DE>
Message-ID: <Pine.A41.4.44.0210061420050.97302-100000@homer19.u.washington.edu>

On Sun, 6 Oct 2002, Marcus Jellinghaus wrote:

> Hello,
>
> Im quite new to this list.
> I have a high frequency-dataset with more than 500.000 records.
> I want to edit a data.frame "Test". My small programm runs fine with a small
> part of the dataset (just 100 records), but it is very slow with a huge
> dataset. Of course it gets slower with more records, but when I change just
> the size of the frame and keep the number of edited records fixed, I see
> that it is also getting slower.
>
> Here is my program:
>
> print(dim(test)[1])
> Sys.time()
> for(i in 1:100) {
>   test[i,6] = paste(test[i,2],"-",test[i,3], sep = "")
> }
> Sys.time()

1.6.0 has faster dataframe indexing.  Also, there's no need to do this one
line at a time
  i<-1:100
  test[i,6]<-paste(test[i,2],test[i,3],sep="-")
should be quite a bit faster.

	-thomas


> I connect 2 currency symbols to a currency pair.
> I always calculate only for the first 100 lines.
> WHen I load just 100 lines in the data.frame "test", it takes 1 second.
> When I load 1000 lines, editing 100 lines takes 2 seconds,
> 10,000 lines loaded and 100 lines editing takes 5 seconds,
> 100,000 lines loaded and editing 100 lines takes 31 seconds,
> 500,000 lines loaded and editing 100 lines takes 11 minutes(!!!).
>
> My computer has 1 GB Ram, so that shouldnt be the reason.
>
> Of course, I could work with many small data.frames instead of one big, but
> the program above is just the very first step and so I dont want to split.
>
> Is there a way to edit big data.frames without waiting for a long time?
>
>
> Thanks a lot for help,
>
>
> Marcus
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle
^^^^^^^^^^^^^^^^^^^^^^^^
- NOTE NEW EMAIL ADDRESS


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Torsten.Hothorn at rzmail.uni-erlangen.de  Mon Oct  7 08:32:49 2002
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon, 7 Oct 2002 08:32:49 +0200 (MEST)
Subject: [R] T-Distribution
In-Reply-To: <x2r8f73j5n.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.21.0210070831050.15763-100000@artemis>


> Torsten Hothorn <Torsten.Hothorn at rzmail.uni-erlangen.de> writes:
> 
> > > > 
> > > > Try rt() function, type ?rt for help.
> > > 
> > > That's _univariate_ t.  Use the mvtnorm package for multivariate t
> > > distribution.
> > >  
> > 
> > hm, unless I as the maintainer miss something important: random number
> > generation of the multivariate t is not in mvtnorm (yet?) :-)
> 
> Hm, am I missing something or can't you just 
> 
>   rmvt <- function(corr,df) rmvnorm(n,sigma=corr)/(rchisq(n,df)/df)
> 
> ??

yep.

The version with `sqrt' involved is now part of the mvtnorm package,

Torsten

> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Mon Oct  7 09:23:08 2002
From: siim at obs.ee (Ott Toomet)
Date: Mon, 7 Oct 2002 09:23:08 +0200 (CEST)
Subject: [R] error bars in line plots
In-Reply-To: <m3adlsryx3.fsf@home.sweet.home>
Message-ID: <Pine.LNX.4.44.0210070918260.1327-100000@localhost.localdomain>

On 6 Oct 2002, Myriam Abramson wrote:

  |Hi!
  |
  |Could you tell me how I can draw a graph with error bars? 
  |Sorry, I don't use R that often and I couldn't find it easily in the
  |documentation. 

There is no errorbars function in the package.  But you may easily construct
your own using segments().  I add my own versions below (actually, why not
put something similar into the base package?).

You may use it as:
plot(x,y)
errorbars(x,y, dy=dy)

The second function is for using with matplot().

Ott

-----------------------

errorbars <- function(x, y, dy=NULL, dx=NULL, ...) {
  if(dy) {
    segments(x, y-dy, x, y+dy, ...)
  }
  if(dx) {
    segments(x-dx, y, x+dx, y, ...)
  }
}


materrorbars <- function(x, y, dy=NULL, dx=NULL,
                         col=par("col"), lty=par("lty")) {
  M <- ncol(y)
  if(is.matrix(x))
    N <- nrow(x)
  else {
    N <- length(x)
    x <- matrix(x, N, M)
  }
  karv <- rep(col, length.out=M)
  joon <- rep(lty, length.out=M)
  if(!is.null(dy)) {
    for(i in seq(M)) {
      segments(x[,i], y[,i]-dy[,i], x[,i], y[,i]+dy[,i],
               col=karv[i], lty=joon[i])
    }
  }
  if(!is.null(dx)) {
    for(i in seq(M)) {
      segments(x[,i]-dx[,i], y[,i], x[,i]+dx[,i], y[,i],
               col=karv[i], lty=joon[i])
    }
  }
}

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Detlef.Steuer at unibw-hamburg.de  Mon Oct  7 09:35:20 2002
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Mon, 07 Oct 2002 09:35:20 +0200 (CEST)
Subject: [R] Re: SuSE rpms for R-1.6.0  available
In-Reply-To: <200210032320.17276.ml@henge-ernst.de>
Message-ID: <XFMail.20021007093520.steuer@unibw-hamburg.de>

Thanks for the hints!
The base rpms have been updated, contrib rpms can be found on CRAN now.

At least now I know the rpms get used really!

detlef


On 03-Oct-2002 J?rgen Henge-Ernst wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> On Thursday 03 October 2002 20:39, Berthold H?llmann wrote:
>> user steuer does not exist - using root
>> user steuer does not exist - using root
>> var/tmp/rpm-tmp.18919: fg: no job control
>> execution of R-base-1.6.0-1 script failed, exit status 1
> that's a packing error/warning. With a line like
> %defattr(-, root, root)
> in the %files -section of the SPEC-file such warnings can be avoided
> 
> Greetings J?rgen
> 
> - -- 
>  Juergen Henge-Ernst // Hauptstrasse 37 // 67591 M?lsheim // Germany
>            email: juergen at henge-ernst.de        ICQ 56324358
> Key fingerprint = 5FFD 89AC 6C7B 76DD 5FAC  9A3F D1A9 0C9B 3B49 67B1
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.0.6 (GNU/Linux)
> Comment: For info see http://www.gnupg.org
> 
> iD8DBQE9nLSB0akMmztJZ7ERAsbYAKCBtYVGd4ECGbW7anpz6s1MtS4eXQCggEGU
> aatKMN3OxOYilhIN+207njU=
> =VC+H
> -----END PGP SIGNATURE-----
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _

"There is no way to peace, peace is the way." -- Ghandi

Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From juli at ceam.es  Mon Oct  7 10:03:07 2002
From: juli at ceam.es (juli g. pausas)
Date: Mon, 07 Oct 2002 10:03:07 +0200
Subject: [R] error bars in line plots
Message-ID: <3DA13FBB.46C7B343@ceam.es>

barsd <- function(barmatrix, sdmatrix, ...)
{
 r <- barplot(barmatrix, beside= T, ...)
 if(!missing(sdmatrix)) arrows(r, barmatrix, r, barmatrix+sdmatrix,
length= 0.05, angle=90)
}



> Date: 06 Oct 2002 00:09:28 -0400
> From: Myriam Abramson
> Subject: [R] error bars in line plots
>
> Hi!
>
> Could you tell me how I can draw a graph with error bars?
> Sorry, I don't use R that often and I couldn't find it easily in the
> documentation.
>
> TIA
>




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jsendak at omniwhittington.co.uk  Mon Oct  7 11:30:28 2002
From: jsendak at omniwhittington.co.uk (Sendak, John)
Date: Mon, 7 Oct 2002 10:30:28 +0100 
Subject: [R] RE: new packages: geepack and KMsurv
Message-ID: <C31235FCFBCCD411BD630008C7F33A598039C9@ACH_MAIL1>

I downloaded geepack from your site and installed it from the zip file.
However, although it appears under my library directory, I could not load
into R.


Regards

John Sendak


platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.0            
year     2002           
month    10             
day      01             
language R              


 -----Original Message-----
From: 	Jun Yan [mailto:jyan at stat.wisc.edu] 
Sent:	07 October 2002 04:59
To:	r-announce at r-project.org
Subject:	new packages: geepack and KMsurv


I uploaded two packages to cran two weeks ago, and have just compiled them
for windows using the cross-building tools on linux. Now I would like to
anounce their existence.

The first package, geepack, is generalized estimating equations modeling 
for both mean and association structure for multivariate responses. The
DESCRIPTION file is

Package: geepack
Version: 0.1-4
Date: 2002/9/28
Title: Generalized Estimating Equation Package
Author: Jun Yan <jyan at stat.wisc.edu>
Maintainer: Jun Yan <jyan at stat.wisc.edu>
Description: Generalized estimating equations solver for parameters in
mean, scale, and correlation structures, through mean link, scale link, and
correlation link. Can also handle clustered categorical responses.
License: GPL version 2 or later.

The second package KMsurv is a data package for the textbook Klein and
Moeschberger (1997), Survival Analysis. It may be useful in teaching
or studying such a course. The DESCRIPTION file is 

Package: KMsurv
Version: 0.1-1
Date: 2002/05/18
Title: Data sets from Klein and Moeschberger (1997), Survival Analysis
Author: Original by Klein and Moeschberger 
  modifications by Jun Yan <jyan at stat.wisc.edu>
Maintainer: Jun Yan <jyan at stat.wisc.edu>
Description: Data sets and functions for Klein and Moeschberger (1997), 
  "Survival Analysis, Techniques for Censored and Truncated Data",
Springer. 
Depends: survival
License: GPL version 2.0 or later

The windows version of these packages are available at
    http://franz.stat.wisc.edu/~jyan/mysoft/

I am grateful to Professor Douglas Bates and Professor Jason Fine for
encouragement, discussions and comments. 

Please kindly let me know if there are any questions, comments,
and bugs of course.

Jun Yan

Department of Statistics          Office: CSSC 4252
university of Wisconsin-Madison   Tel: (608)262-7478 
1210 W. Dayton St.                Email: jyan at stat.wisc.edu
Madison, WI 53706                 URL: http://www.stat.wisc.edu/~jyan





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-announce mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

_______
Confidentiality Notice

This email (and any attachment) is intended only for the attention of the
addressee.  Its unauthorised use, disclosure, storage or copying is not
permitted.  If you are not the intended recipient, please destroy all copies
and inform the sender by return email.  Thank you
_________________________________________________________________
This email has been scanned for all viruses by the MessageLabs SkyScan
service. For more information on a proactive anti-virus service working
around the clock, around the globe, visit http://www.messagelabs.com
________________________________________________________________________

____
Confidentiality Notice

This email (and any attachment) is intended only for the attention of the addressee.  Its unauthorised use, disclosure, storage or copying is not permitted.  If you are not the intended recipient, please destroy all copies and inform the sender by return email.  Thank you
____________________________________________________________________
This email has been scanned for all viruses by the MessageLabs SkyScan
service. For more information on a proactive anti-virus service working
around the clock, around the globe, visit http://www.messagelabs.com
________________________________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chr.schulz at email.de  Mon Oct  7 12:06:40 2002
From: chr.schulz at email.de (chr.schulz@email.de)
Date: Mon, 7 Oct 2002 12:06:40 +0200
Subject: [R] R 1.6 Gui for Windows
Message-ID: <200210071006.g97A6eX02294@mailgate5.cinetic.de>

...i have  the same problem and didn't now why ?

Error in testRversion(descfile) : This package has not been installed properly
 See the Note in ?library

The problem is the .First() Function, but the same works in R1.5.1 without problems ?

thanks for advance,christian

options(editor="\"c:/DevelopeWinedt/winedt\"-c=\"R-WinEdt-edit\" -e=r.ini -V")
options(pager="\"c:/DevelopeWinedt/winedt\" -C=\"R-WinEdt\" -e=r.ini -V")

file.show(".Rhistory")
.First <-function() { options(prompt="$ ",continue="+\t")
options(digits=3,length=999)
library(ipred)
library(relimp)
library(hmisc)
library(design)
library(e1071)
library(lattice)
library(grid)
library(XML)
library(ctest)
library(cluster)
library(foreign)
#library(mva)
library(RODBC)
library(foreign)
#library(xtable)
library(rpart)
#library(tools)}
Sys.putenv("TCL_LIBRARY"="c:/develope/Tcl/lib/tcl8.3")
library(tcltk) #help()

Freq <- function(x){
  xmat<-as.matrix(x)

  ifelse (ncol(xmat)==1,{

  Count<-table(x)
  Total<-sum(Count)
  Prcnt<-100*(Count/Total)
  x1<-cbind(Count,Prcnt)
  x2<-cbind(Total,sum(Prcnt))
  Frequency.Table<-as.data.frame(rbind(x1,x2))
  c<-nrow(Frequency.Table)
  rownames(Frequency.Table)[c]<-"Total"
  return(Frequency.Table)}
  ,
  return("To use this function across multiple columns use apply"))
    }

eda.shape <- function(x) {
    par(mfrow=c(2,2))
    hist(x)
    boxplot(x)
    iqd  <- summary(x)[5] - summary(x)[2]
    plot(density(x,bw=2*iqd),xlab="x",ylab="",type="l")
    qqnorm(x)
    qqline(x)
    }
eda.ts <- function(x) {
    par(mfrow=c(2,1))
    plot.ts(x)
    acf(x)
    invisible()
    }
replace.na.m <-
  function (x){
    X<-mean(x,na.rm=TRUE)
    ifelse ( is.na(x)=="TRUE",X,x)
}
replace.na.x<-
  function(x, value){
    ifelse (is.na(x)=="TRUE", value , x)
}

.Last <- function() {
graphics.off()
cat(paste(date(),"\nAdiosAmigos\n"))
}


Uwe Ligges schrieb:

Benjamin.STABLER at odot.state.or.us wrote:

I upgraded to R Gui 1.6 this morning and I can't seem to get it to accept my
new startup directory.  R 1.51 will accept
"F:\_ben\bls\gen1\results\bls\analysis" as the start in directory for the R
Gui shortcut, but R 1.6 will not.  R 1.6 will accept
"F:\_ben\bls\gen1\results\bls".  It seems to have trouble when I add
"\analysis."  R still loads fine but I get the following error:

Error in testRversion(descfile) : This package has not been installed
properly
See the Note in ?library

Also, R 1.6 will let me set the working directory to include "analysis."  


[Looks like there wasn't any answer to this mail before]
Including the dot?


I can ignore the error and R still loads in the correct directory.  
But I am curious as to why this is.  Any ideas?  Thanks.


 
Maybe there is an .Renviron or .Rprofile file or something like that in
your directory that causes the error message? Or a .First() function in
your .Rdata workspace in that directory?

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From volker.franz at tuebingen.mpg.de  Mon Oct  7 12:55:10 2002
From: volker.franz at tuebingen.mpg.de (Volker Franz)
Date: Mon, 7 Oct 2002 12:55:10 +0200
Subject: [R] error bars in line plots
In-Reply-To: <001601c26d20$e4ee78d0$7f2758db@kwan022>
References: <m3adlsryx3.fsf@home.sweet.home>
	<001601c26d20$e4ee78d0$7f2758db@kwan022>
Message-ID: <15777.26638.74620.803964@pimento.kyb.local>

Hi, 

    >> Could you tell me how I can draw a graph with error bars?
>>>>> "KKW" == Ko-Kang Kevin Wang <Ko-Kang at xtra.co.nz> writes:
    KKW> Hi, Take a look at
    KKW> http://finzi.psych.upenn.edu/R/Rhelp02/archive/4124.html and
    KKW> its thread.

I just had a look at this page and expanded the examples a bit:

##Sample data:
mydat <- data.frame(x=1:10, y=1:10, dy=rnorm(10))
attach(mydat)

##Style of errorbars:
myangle=90  #Angle from shaft to edge of arrow head.
mylength=0.2#Length of arrow head in inches (!!!)

##One--sided errorbars:
plot(x,y,ylim=range(y,y+dy))
arrows(x,y,x,y+dy,angle=myangle,length=mylength)

##Two--sided errorbars:
plot(x,y,ylim=range(y-dy,y+dy))
arrows(x,y-dy,x,y+dy,code = 3,angle=myangle,length=mylength)

HTH
Volker
-- 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Marcus_Jellinghaus at gmx.de  Mon Oct  7 13:08:54 2002
From: Marcus_Jellinghaus at gmx.de (Marcus Jellinghaus)
Date: Mon, 7 Oct 2002 07:08:54 -0400
Subject: [R] Why are big data.frames slow? What can I do to get it faster?
In-Reply-To: <3DA07993.90E08E4B@statistik.uni-dortmund.de>
Message-ID: <ANEPLCDCPMDLBOLGOBCBMEJPDPAA.Marcus_Jellinghaus@GMX.DE>

First I want to say "thank you" to everybody who replied.
I understand that vectorized operations instead of the loop are faster.
I also made sure not to use factors.

Since the loop runs 100times in my example, the loop should only take the
time of the vectorized operation mutliplied by 100.
But the loop takes about 10 minutes, the  vectorized operation takes about 3
seconds. (See below)
Why that? Shouldn?t the loop take max 100*3seconds = 5 minutes?

I?m interested in that because I think that I will have computations that
are easily vectorizable(like this example) and that I will have computations
that are not/very difficult vectorizable.

Marcus Jellinghaus


> print(dim(test)[1])
[1] 500000
> Sys.time()
[1] "2002-10-07 06:17:33 Eastern Sommerzeit"
> test[1:100,6] = paste(test[1:100,2],"-",test[1:100,3], sep = "")
> Sys.time()
[1] "2002-10-07 06:17:35 Eastern Sommerzeit"

[..]

> print(dim(test)[1])
[1] 500000
> Sys.time()
[1] "2002-10-07 06:05:29 Eastern Sommerzeit"
> for(i in 1:100) {
+   test[i,6] = paste(test[i,2],"-",test[i,3], sep = "")
+ }
> Sys.time()
[1] "2002-10-07 06:15:17 Eastern Sommerzeit"


-----Urspr?ngliche Nachricht-----
Von: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
Gesendet: Sunday, October 06, 2002 1:58 PM
An: Marcus Jellinghaus
Cc: r-help at stat.math.ethz.ch
Betreff: Re: [R] Why are big data.frames slow? What can I do to get it
faster?


Marcus Jellinghaus wrote:
>
> Hello,
>
> I?m quite new to this list.
> I have a high frequency-dataset with more than 500.000 records.
> I want to edit a data.frame "Test". My small programm runs fine with a
small
> part of the dataset (just 100 records), but it is very slow with a huge
> dataset. Of course it get?s slower with more records, but when I change
just
> the size of the frame and keep the number of edited records fixed, I see
> that it is also getting slower.
>
> Here is my program:
>
> print(dim(test)[1])
> Sys.time()
> for(i in 1:100) {
>   test[i,6] = paste(test[i,2],"-",test[i,3], sep = "")
> }
> Sys.time()
>
> I connect 2 currency symbols to a currency pair.
> I always calculate only for the first 100 lines.
> WHen I load just 100 lines in the data.frame "test", it takes 1 second.
> When I load 1000 lines, editing 100 lines takes 2 seconds,
> 10,000 lines loaded and 100 lines editing takes 5 seconds,
> 100,000 lines loaded and editing 100 lines takes 31 seconds,
> 500,000 lines loaded and editing 100 lines takes 11 minutes(!!!).
>
> My computer has 1 GB Ram, so that shouldn?t be the reason.
>
> Of course, I could work with many small data.frames instead of one big,
but
> the program above is just the very first step and so I don?t want to
split.
>
> Is there a way to edit big data.frames without waiting for a long time?

Well, the point is, I guess, to address elements in a large data.frame,
which reasonably takes much more time than in a small one.

Maybe it's an idea to use vectorized operations instead of the loop,
which is preferable, if your computation is easy vectorizable without a
big penalty of memory consumption:

 test[1:100, 6] <- paste(test[1:100, 2], "-", test[1:100, 3], sep = "")
or
 test[ , 6] <- paste(test[ , 2], "-", test[ , 3], sep = "")
for the whole data.frame.

Uwe Ligges

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Mon Oct  7 15:23:54 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Mon, 7 Oct 2002 13:23:54 +0000
Subject: [R] Error in writeBin(object, con, size = 2)
Message-ID: <15777.35562.225819.101362@hugo.paed.uni-muenchen.de>

Hi all,

I wrote a function (in R batch mode) which reads binary data,
interpolates sometimes and wrote a new binary file of the same size as
the input file. Her is a bit of code:

while (length( head <- readBin(si, integer(), 64, size=2))) {
      data <- readBin(si, integer(), head[5], size=2)
      ## now write head to new file
      writeBin(head, so, size=2)
      ## if head[4] is 9 or 10, interpolate 
      if(head[4] == 9 | head[4] == 10) 
        ## interpolate data
        data <-int(data)
      writeBin(data, so, size=2)
}

si and so are the binary in- and output connections, "int()"
interpolates between some data segments and returns a numeric vector
of the same length as the input vector. 

However, if the data were interpolated, the execution stops with the
follwing error:

Error in writeBin(data, so, size = 2) : That size is unknown on this machine
Execution halted

This error only occured, if "int()" was called before
writeBin(). int() returns a numeric vector with integers.

With writeBin(data, so) everything works, but this gives the wrong
bytes per element in the byte stream.

Any suggestions?
Thanks, Sven

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Mon Oct  7 13:58:58 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon, 7 Oct 2002 07:58:58 -0400
Subject: [R] error bars in line plots
In-Reply-To: <Pine.LNX.4.44.0210070918260.1327-100000@localhost.localdomain>
References: <m3adlsryx3.fsf@home.sweet.home>
	<Pine.LNX.4.44.0210070918260.1327-100000@localhost.localdomain>
Message-ID: <20021007075858.60b3aa62.fharrell@virginia.edu>

On Mon, 7 Oct 2002 09:23:08 +0200 (CEST)
Ott Toomet <siim at obs.ee> wrote:

> On 6 Oct 2002, Myriam Abramson wrote:
> 
>   |Hi!
>   |
>   |Could you tell me how I can draw a graph with error bars? 
>   |Sorry, I don't use R that often and I couldn't find it easily in the
>   |documentation. 
> 
> There is no errorbars function in the package.  But you may easily construct
> your own using segments().  I add my own versions below (actually, why not
> put something similar into the base package?).
> 
> You may use it as:
> plot(x,y)
> errorbars(x,y, dy=dy)
> 
> The second function is for using with matplot().
> 
> Ott
> 
> -----------------------
> 
> errorbars <- function(x, y, dy=NULL, dx=NULL, ...) {

. . .

Also look at errbar and xYplot in the Hmisc library.  -Frank Harrell
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Oct  7 14:02:01 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 07 Oct 2002 14:02:01 +0200
Subject: [R] Why are big data.frames slow? What can I do to get it faster?
In-Reply-To: <ANEPLCDCPMDLBOLGOBCBMEJPDPAA.Marcus_Jellinghaus@GMX.DE>
References: <ANEPLCDCPMDLBOLGOBCBMEJPDPAA.Marcus_Jellinghaus@GMX.DE>
Message-ID: <x2ofa6qwxy.fsf@biostat.ku.dk>

"Marcus Jellinghaus" <Marcus_Jellinghaus at gmx.de> writes:

> First I want to say "thank you" to everybody who replied.
> I understand that vectorized operations instead of the loop are faster.
> I also made sure not to use factors.
> 
> Since the loop runs 100times in my example, the loop should only take the
> time of the vectorized operation mutliplied by 100.
> But the loop takes about 10 minutes, the  vectorized operation takes about 3
> seconds. (See below)
> Why that? Shouldn?t the loop take max 100*3seconds = 5 minutes?

You'll likely have to invoke the garbage collector a couple of times,
and there might also be issues of memory growth kicking in. Once you
get beyond some threshold, the machine starts swapping bits and pieces
of the workspace in and out of physical memory,

It's somewhat difficult to reproduce the behaviour, since you only give
part of the code necessary (e.g. how many *columns* do you have in
your data frame?) 

Something like this?

N <- 100000
test <- as.data.frame(lapply(1:6,function(i)rnorm(N)))
unix.time(test[1:100,6] <- paste(test[1:100,2],"-",test[1:100,3], sep = ""))
unix.time(for (i in 1:100) test[i,6] <- paste(test[i,2],"-",test[i,3], sep = ""))

(Using N==500000 made my little desktop swap like crazy, but the above
gave something like 2s CPU time for the 1st case and 92s CPU + 23s
system for the other one with R 1.6.0)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Oct  7 15:04:56 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 7 Oct 2002 15:04:56 +0200 (MET DST)
Subject: [R] R 1.6 Gui for Windows
In-Reply-To: <200210071006.g97A6eX02294@mailgate5.cinetic.de>
Message-ID: <Pine.GSO.4.21.0210071502290.4198-100000@amadeus.statistik.uni-dortmund.de>



On Mon, 7 Oct 2002 chr.schulz at email.de wrote:

> ...i have  the same problem and didn't now why ?
> 
> Error in testRversion(descfile) : This package has not been installed properly
>  See the Note in ?library
> 
> The problem is the .First() Function, but the same works in R1.5.1 without problems ?
> 
> thanks for advance,christian
> 
> options(editor="\"c:/DevelopeWinedt/winedt\"-c=\"R-WinEdt-edit\" -e=r.ini -V")
> options(pager="\"c:/DevelopeWinedt/winedt\" -C=\"R-WinEdt\" -e=r.ini -V")
> 
> file.show(".Rhistory")
> .First <-function() { options(prompt="$ ",continue="+\t")
> options(digits=3,length=999)
> library(ipred)
> library(relimp)
> library(hmisc)
> library(design)
> library(e1071)
> library(lattice)
> library(grid)
> library(XML)
> library(ctest)
> library(cluster)
> library(foreign)
> #library(mva)
> library(RODBC)
> library(foreign)
> #library(xtable)
> library(rpart)
> #library(tools)}
> Sys.putenv("TCL_LIBRARY"="c:/develope/Tcl/lib/tcl8.3")
> library(tcltk) #help()



Obviously, you are loading a number of packages.
The package structure is tested more intensively with R-1.6.0 than before,
so you might consider to update the package which produces that error
message ...

Just start R without that .First function and load the packages step by
step to see, which one produces the error message ...

Uwe Ligges




> Freq <- function(x){
>   xmat<-as.matrix(x)
> 
>   ifelse (ncol(xmat)==1,{
> 
>   Count<-table(x)
>   Total<-sum(Count)
>   Prcnt<-100*(Count/Total)
>   x1<-cbind(Count,Prcnt)
>   x2<-cbind(Total,sum(Prcnt))
>   Frequency.Table<-as.data.frame(rbind(x1,x2))
>   c<-nrow(Frequency.Table)
>   rownames(Frequency.Table)[c]<-"Total"
>   return(Frequency.Table)}
>   ,
>   return("To use this function across multiple columns use apply"))
>     }
> 
> eda.shape <- function(x) {
>     par(mfrow=c(2,2))
>     hist(x)
>     boxplot(x)
>     iqd  <- summary(x)[5] - summary(x)[2]
>     plot(density(x,bw=2*iqd),xlab="x",ylab="",type="l")
>     qqnorm(x)
>     qqline(x)
>     }
> eda.ts <- function(x) {
>     par(mfrow=c(2,1))
>     plot.ts(x)
>     acf(x)
>     invisible()
>     }
> replace.na.m <-
>   function (x){
>     X<-mean(x,na.rm=TRUE)
>     ifelse ( is.na(x)=="TRUE",X,x)
> }
> replace.na.x<-
>   function(x, value){
>     ifelse (is.na(x)=="TRUE", value , x)
> }
> 
> .Last <- function() {
> graphics.off()
> cat(paste(date(),"\nAdiosAmigos\n"))
> }
> 
> 
> Uwe Ligges schrieb:
> 
> Benjamin.STABLER at odot.state.or.us wrote:
> 
> I upgraded to R Gui 1.6 this morning and I can't seem to get it to accept my
> new startup directory.  R 1.51 will accept
> "F:\_ben\bls\gen1\results\bls\analysis" as the start in directory for the R
> Gui shortcut, but R 1.6 will not.  R 1.6 will accept
> "F:\_ben\bls\gen1\results\bls".  It seems to have trouble when I add
> "\analysis."  R still loads fine but I get the following error:
> 
> Error in testRversion(descfile) : This package has not been installed
> properly
> See the Note in ?library
> 
> Also, R 1.6 will let me set the working directory to include "analysis."  
> 
> 
> [Looks like there wasn't any answer to this mail before]
> Including the dot?
> 
> 
> I can ignore the error and R still loads in the correct directory.  
> But I am curious as to why this is.  Any ideas?  Thanks.
> 
> 
>  
> Maybe there is an .Renviron or .Rprofile file or something like that in
> your directory that causes the error message? Or a .First() function in
> your .Rdata workspace in that directory?
> 
> Uwe Ligges
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jarioksa at sun3.oulu.fi  Mon Oct  7 15:28:16 2002
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Mon, 07 Oct 2002 16:28:16 +0300
Subject: [R] RE: new packages: geepack and KMsurv 
In-Reply-To: Message from "Sendak, John" <jsendak@omniwhittington.co.uk> 
   of "Mon, 07 Oct 2002 10:30:28 BST." <C31235FCFBCCD411BD630008C7F33A598039C9@ACH_MAIL1> 
Message-ID: <200210071328.g97DSGW18586@pc112145.oulu.fi>


jsendak at omniwhittington.co.uk said:
> I downloaded geepack from your site and installed it from the zip
> file. However, although it appears under my library directory, I could
> not load into R.

I found out that all old packages with compiled code in shared libraries fail to
load in R-1.6.0. My platform is RH7.3 with the notorious C/G77 compiler, but the
reason seem not to be changes in compiler, but changes in R. Packages that I had
compiled and installed day before upgrading to R-1.6.0 failed after upgrading.
The problem vanishes when the package is re-installed from the source. This is a
mild nuisance and for several packages I wait that they are ugpraded in CRAN so
that re-building happens automatically. I am not sure if this is the reason with
your trouble with binary packages, since your platform is very different. This
is the output I get with one example package:

> library(acepack)
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
	unable to load shared library "/usr/lib/R/library/acepack/libs/acepack.so":
  libR.so: cannot open shared object file: No such file or directory
Error in library(acepack) : .First.lib failed
# But it is there:

> system("ls /usr/lib/R/library/acepack/libs/acepack.so -l")
-rwxr-xr-x    1 root     root        68548 May 29 11:00 /usr/lib/R/library/acepack/libs/acepack.so

> dyn.load("/usr/lib/R/library/acepack/libs/acepack.so")
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
	unable to load shared library "/usr/lib/R/library/acepack/libs/acepack.so":
  libR.so: cannot open shared object file: No such file or directory

I have tried to find if this new behaviour is documented, but I haven't yet
found anything, so this may be an "undocumented feature". Who knows?

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct  7 15:37:31 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 7 Oct 2002 14:37:31 +0100 (BST)
Subject: [R] RE: new packages: geepack and KMsurv
In-Reply-To: <C31235FCFBCCD411BD630008C7F33A598039C9@ACH_MAIL1>
Message-ID: <Pine.LNX.4.31.0210071433180.2077-100000@gannet.stats>

There will be a checked Windows version on CRAN tomorrow which you will be
able to download in the usual way for contributed package. (I've just
uploaded about 50 new/updated precompiled packages for Windows 1.6.0.)

On Mon, 7 Oct 2002, Sendak, John wrote:

> I downloaded geepack from your site and installed it from the zip file.
> However, although it appears under my library directory, I could not load
> into R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jrgonzalez at ico.scs.es  Mon Oct  7 16:01:07 2002
From: jrgonzalez at ico.scs.es (Juan Ramon Gonzalez)
Date: Mon, 7 Oct 2002 16:01:07 +0200
Subject: [R] Rcmd check examples
Message-ID: <002b01c26e09$fc215880$1100a8c0@ico.scs.es>

Hello R-listers,

I have created a library but it don't pass the Rcmd check when it is
checking the examples. Error mesage:

"Running examples failed"

I have executed the instructions written in the Rd file in a R console and
it runs ok.

Does anybody know what it is happening?

Thank you,

Juan Ramon

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Mon Oct  7 16:04:00 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Mon, 7 Oct 2002 10:04:00 -0400 
Subject: [R] error bars in line plots
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20149D03F@groexmb02.pfizer.com>

Try the  plotCI() and/or plotmeans() functions in the 'gregmisc' package.

-Greg



> -----Original Message-----
> From: Myriam Abramson [mailto:mabramso at gmu.edu]
> Sent: Sunday, October 06, 2002 12:09 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] error bars in line plots
> 
> 
> Hi!
> 
> Could you tell me how I can draw a graph with error bars? 
> Sorry, I don't use R that often and I couldn't find it easily in the
> documentation. 
> 
> TIA
> 
> 
> -- 
>                                    myriam
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jyan at stat.wisc.edu  Mon Oct  7 16:11:08 2002
From: jyan at stat.wisc.edu (Jun Yan)
Date: Mon, 7 Oct 2002 09:11:08 -0500 (CDT)
Subject: [R] new packages: geepack and KMsurv
In-Reply-To: <C31235FCFBCCD411BD630008C7F33A598039C9@ACH_MAIL1>
Message-ID: <Pine.LNX.4.21.0210070904180.26870-100000@ludwig.stat.wisc.edu>

On Mon, 7 Oct 2002, Sendak, John wrote:

> I downloaded geepack from your site and installed it from the zip file.
> However, although it appears under my library directory, I could not load
> into R.
> 
> 
> Regards
> 
> John Sendak

Several people have nicely pointed out the geepack windows binary is not
working, because the individual files in it were gzipped. I just
recompiled and now there is a new version at

   http://franz.stat.wisc.edu/~jyan/mysoft/

(click the windows binary on this page)

I will not have a chance to test it until I get home this evening. Please
let me know if it is still not working.

I appreciate people's quick feedback.

Jun Yan

Department of Statistics          Office: CSSC 4252
university of Wisconsin-Madison   Tel: (608)262-7478 
1210 W. Dayton St.                Email: jyan at stat.wisc.edu
Madison, WI 53706                 URL: http://www.stat.wisc.edu/~jyan





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Oct  7 16:30:06 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 07 Oct 2002 16:30:06 +0200
Subject: [R] RE: new packages: geepack and KMsurv
In-Reply-To: <200210071328.g97DSGW18586@pc112145.oulu.fi>
References: <200210071328.g97DSGW18586@pc112145.oulu.fi>
Message-ID: <x2vg4epbip.fsf@biostat.ku.dk>

Jari Oksanen <jarioksa at sun3.oulu.fi> writes:

> jsendak at omniwhittington.co.uk said:
> > I downloaded geepack from your site and installed it from the zip
> > file. However, although it appears under my library directory, I could
> > not load into R.
> 
> I found out that all old packages with compiled code in shared libraries fail to
> load in R-1.6.0. My platform is RH7.3 with the notorious C/G77 compiler, but the
> reason seem not to be changes in compiler, but changes in R. Packages that I had
> compiled and installed day before upgrading to R-1.6.0 failed after upgrading.
> The problem vanishes when the package is re-installed from the source. This is a
> mild nuisance and for several packages I wait that they are ugpraded in CRAN so
> that re-building happens automatically. I am not sure if this is the reason with
> your trouble with binary packages, since your platform is very different. This
> is the output I get with one example package:
> 
> > library(acepack)
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
> 	unable to load shared library "/usr/lib/R/library/acepack/libs/acepack.so":
>   libR.so: cannot open shared object file: No such file or directory
> Error in library(acepack) : .First.lib failed
> # But it is there:
> 
> > system("ls /usr/lib/R/library/acepack/libs/acepack.so -l")
> -rwxr-xr-x    1 root     root        68548 May 29 11:00 /usr/lib/R/library/acepack/libs/acepack.so
> 
> > dyn.load("/usr/lib/R/library/acepack/libs/acepack.so")
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
> 	unable to load shared library "/usr/lib/R/library/acepack/libs/acepack.so":
>   libR.so: cannot open shared object file: No such file or directory
> 
> I have tried to find if this new behaviour is documented, but I haven't yet
> found anything, so this may be an "undocumented feature". Who knows?

Odd, I just tried with a recent R-devel:


> library(odesolve,lib.loc='~/Rlib')
>

works fine, and my odesolve was built under 1.5.1 and does have an odesolve.so.

Now the error message claims that the library is absent, so does the
file actually exist? And did you install from RPM or from source?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Mon Oct  7 16:46:49 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 07 Oct 2002 10:46:49 -0400
Subject: [R] Why are big data.frames slow? What can I do to get it
 fas	ter?
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC774@usrymx10.merck.com>

Extracting from data frame one element at a time the way you did is
expensive.  I.e., test[i, 6] is slower than test$whatever[i].

As an example:

> dat <- data.frame(a = sample(LETTERS, 1e6, replace=TRUE), b=1:1e6,
+                   c=rep("A", 1e6))
> dat$a <- as.character(dat$a)
> dat$c <- as.character(dat$c)
> 
> system.time(
+ for(i in 1:10) {
+   dat[i, 3] <- paste(dat[i, 1], "-", dat[i, 2], sep="")
+ }
+ )
[1] 26.17  0.13 26.67    NA    NA
> 
> system.time(
+ for(i in 1:10) {
+   dat$c[i] <- paste(dat$a[i], "-", dat$b[i], sep="")
+ }
+ )
[1] 0.16 0.00 0.16   NA   NA

HTH,
Andy





> -----Original Message-----
> From: Marcus Jellinghaus [mailto:Marcus_Jellinghaus at gmx.de]
> Sent: Monday, October 07, 2002 7:09 AM
> To: Uwe Ligges
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Why are big data.frames slow? What can I do to get it
> faster?
> 
> 
> First I want to say "thank you" to everybody who replied.
> I understand that vectorized operations instead of the loop 
> are faster.
> I also made sure not to use factors.
> 
> Since the loop runs 100times in my example, the loop should 
> only take the
> time of the vectorized operation mutliplied by 100.
> But the loop takes about 10 minutes, the  vectorized 
> operation takes about 3
> seconds. (See below)
> Why that? Shouldn?t the loop take max 100*3seconds = 5 minutes?
> 
> I?m interested in that because I think that I will have 
> computations that
> are easily vectorizable(like this example) and that I will 
> have computations
> that are not/very difficult vectorizable.
> 
> Marcus Jellinghaus
> 
> 
> > print(dim(test)[1])
> [1] 500000
> > Sys.time()
> [1] "2002-10-07 06:17:33 Eastern Sommerzeit"
> > test[1:100,6] = paste(test[1:100,2],"-",test[1:100,3], sep = "")
> > Sys.time()
> [1] "2002-10-07 06:17:35 Eastern Sommerzeit"
> 
> [..]
> 
> > print(dim(test)[1])
> [1] 500000
> > Sys.time()
> [1] "2002-10-07 06:05:29 Eastern Sommerzeit"
> > for(i in 1:100) {
> +   test[i,6] = paste(test[i,2],"-",test[i,3], sep = "")
> + }
> > Sys.time()
> [1] "2002-10-07 06:15:17 Eastern Sommerzeit"
> 
> 
> -----Urspr?ngliche Nachricht-----
> Von: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Gesendet: Sunday, October 06, 2002 1:58 PM
> An: Marcus Jellinghaus
> Cc: r-help at stat.math.ethz.ch
> Betreff: Re: [R] Why are big data.frames slow? What can I do to get it
> faster?
> 
> 
> Marcus Jellinghaus wrote:
> >
> > Hello,
> >
> > I?m quite new to this list.
> > I have a high frequency-dataset with more than 500.000 records.
> > I want to edit a data.frame "Test". My small programm runs 
> fine with a
> small
> > part of the dataset (just 100 records), but it is very slow 
> with a huge
> > dataset. Of course it get?s slower with more records, but 
> when I change
> just
> > the size of the frame and keep the number of edited records 
> fixed, I see
> > that it is also getting slower.
> >
> > Here is my program:
> >
> > print(dim(test)[1])
> > Sys.time()
> > for(i in 1:100) {
> >   test[i,6] = paste(test[i,2],"-",test[i,3], sep = "")
> > }
> > Sys.time()
> >
> > I connect 2 currency symbols to a currency pair.
> > I always calculate only for the first 100 lines.
> > WHen I load just 100 lines in the data.frame "test", it 
> takes 1 second.
> > When I load 1000 lines, editing 100 lines takes 2 seconds,
> > 10,000 lines loaded and 100 lines editing takes 5 seconds,
> > 100,000 lines loaded and editing 100 lines takes 31 seconds,
> > 500,000 lines loaded and editing 100 lines takes 11 minutes(!!!).
> >
> > My computer has 1 GB Ram, so that shouldn?t be the reason.
> >
> > Of course, I could work with many small data.frames instead 
> of one big,
> but
> > the program above is just the very first step and so I don?t want to
> split.
> >
> > Is there a way to edit big data.frames without waiting for 
> a long time?
> 
> Well, the point is, I guess, to address elements in a large 
> data.frame,
> which reasonably takes much more time than in a small one.
> 
> Maybe it's an idea to use vectorized operations instead of the loop,
> which is preferable, if your computation is easy vectorizable 
> without a
> big penalty of memory consumption:
> 
>  test[1:100, 6] <- paste(test[1:100, 2], "-", test[1:100, 3], 
> sep = "")
> or
>  test[ , 6] <- paste(test[ , 2], "-", test[ , 3], sep = "")
> for the whole data.frame.
> 
> Uwe Ligges
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikalzet at libero.it  Mon Oct  7 17:30:19 2002
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Mon, 7 Oct 2002 17:30:19 +0200 (CEST)
Subject: [R] Problems with libpng12.so.0 in Mandrake 8.2 )
Message-ID: <Pine.LNX.4.44.0210071729020.1909-100000@localhost.localdomain>


On Mon, 7 Oct 2002, [iso-8859-1] CARLOS ORTEGA wrote:

> I have just downloaded the R-1.6.0's rpm for
> Mandrake8.2. I installed your previous rpms without
> any problem, but in this case, I cannot do that
> because there is a dependence with the
> "libpng12.so.0". 

On my system:

locate libpng12.so.0
gives me:  /usr/lib/libpng12.so.0

urpmf /usr/lib/libpng12.so.0
gives me:  libpng3 /usr/lib/libpng12.so.0

You must install libpng3.

However, if I do:

rpm -q libpng3

I get libpng3-1.2.4-3.1mdk.i586.rpm

This is not the version on the original mandrake 8.2 installation CD, it 
is an update mandrake has furnished since.

So, if installing libpng3 from your original installion CD won't work, 
download the update from mandrake mirrors (its about 160 Kb)

/pub/Mandrake_Mirror/Mandrake/updates/8.2/RPMS> libpng3-1.2.4-3.1mdk.i586.rpm

Please let me know how it worked.

-- 
Michele Alzetta


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Mon Oct  7 20:43:34 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Mon, 7 Oct 2002 18:43:34 +0000
Subject: [R] Error in writeBin(object, con, size = 2)
In-Reply-To: <Pine.LNX.4.31.0210071723070.2879-100000@gannet.stats>
References: <15777.35562.225819.101362@hugo.paed.uni-muenchen.de>
	<Pine.LNX.4.31.0210071723070.2879-100000@gannet.stats>
Message-ID: <15777.54742.914565.971038@hugo.paed.uni-muenchen.de>

ripley at stats.ox.ac.uk writes:
 > I suspect your interpolation produces numeric not integer vectors.  size=2
 > does not exist for numeric (aka double) vectors.

Yes, that was it.

 > 
 > I really don't understand why this was not obvious!  How did you expect
 > numeric data to be output in two bytes?

The unexpected thing was that the data was sometimes numeric and
sometimes integer. I need the output in two bytes because of some old
DOS programms some of us still use.

Bye, Sven

 > 
 > On Mon, 7 Oct 2002, Sven Garbade wrote:
 > 
 > > Hi all,
 > >
 > > I wrote a function (in R batch mode) which reads binary data,
 > > interpolates sometimes and wrote a new binary file of the same size as
 > > the input file. Her is a bit of code:
 > >
 > > while (length( head <- readBin(si, integer(), 64, size=2))) {
 > >       data <- readBin(si, integer(), head[5], size=2)
 > >       ## now write head to new file
 > >       writeBin(head, so, size=2)
 > >       ## if head[4] is 9 or 10, interpolate
 > >       if(head[4] == 9 | head[4] == 10)
 > >         ## interpolate data
 > >         data <-int(data)
 > >       writeBin(data, so, size=2)
 > > }
 > >
 > > si and so are the binary in- and output connections, "int()"
 > > interpolates between some data segments and returns a numeric vector
 > > of the same length as the input vector.
 > >
 > > However, if the data were interpolated, the execution stops with the
 > > follwing error:
 > >
 > > Error in writeBin(data, so, size = 2) : That size is unknown on this machine
 > > Execution halted
 > >
 > > This error only occured, if "int()" was called before
 > > writeBin(). int() returns a numeric vector with integers.
 > >
 > > With writeBin(data, so) everything works, but this gives the wrong
 > > bytes per element in the byte stream.
 > >
 > > Any suggestions?
 > > Thanks, Sven
 > >
 > > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
 > > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
 > > Send "info", "help", or "[un]subscribe"
 > > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
 > > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
 > >
 > 
 > -- 
 > Brian D. Ripley,                  ripley at stats.ox.ac.uk
 > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
 > University of Oxford,             Tel:  +44 1865 272861 (self)
 > 1 South Parks Road,                     +44 1865 272860 (secr)
 > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
 > 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct  7 18:25:51 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 7 Oct 2002 17:25:51 +0100 (BST)
Subject: [R] Error in writeBin(object, con, size = 2)
In-Reply-To: <15777.35562.225819.101362@hugo.paed.uni-muenchen.de>
Message-ID: <Pine.LNX.4.31.0210071723070.2879-100000@gannet.stats>

I suspect your interpolation produces numeric not integer vectors.  size=2
does not exist for numeric (aka double) vectors.

I really don't understand why this was not obvious!  How did you expect
numeric data to be output in two bytes?

On Mon, 7 Oct 2002, Sven Garbade wrote:

> Hi all,
>
> I wrote a function (in R batch mode) which reads binary data,
> interpolates sometimes and wrote a new binary file of the same size as
> the input file. Her is a bit of code:
>
> while (length( head <- readBin(si, integer(), 64, size=2))) {
>       data <- readBin(si, integer(), head[5], size=2)
>       ## now write head to new file
>       writeBin(head, so, size=2)
>       ## if head[4] is 9 or 10, interpolate
>       if(head[4] == 9 | head[4] == 10)
>         ## interpolate data
>         data <-int(data)
>       writeBin(data, so, size=2)
> }
>
> si and so are the binary in- and output connections, "int()"
> interpolates between some data segments and returns a numeric vector
> of the same length as the input vector.
>
> However, if the data were interpolated, the execution stops with the
> follwing error:
>
> Error in writeBin(data, so, size = 2) : That size is unknown on this machine
> Execution halted
>
> This error only occured, if "int()" was called before
> writeBin(). int() returns a numeric vector with integers.
>
> With writeBin(data, so) everything works, but this gives the wrong
> bytes per element in the byte stream.
>
> Any suggestions?
> Thanks, Sven
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Benjamin.STABLER at odot.state.or.us  Mon Oct  7 19:22:10 2002
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Mon, 7 Oct 2002 10:22:10 -0700 
Subject: [R] R 1.6 Gui for Windows
Message-ID: <76A000A82289D411952F001083F9DD06039AC7AD@EXSALEM4-BU.highway.odot.state.or.us>

R 1.6 loaded fine when I disabled one of our packages that was called with
the first function in Rprofile.  Thanks for the help.  

Regards,
Ben Stabler
Oregon, USA

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
Sent: Monday, October 07, 2002 6:05 AM
To: chr.schulz at email.de
Cc: STABLER Benjamin; R-help at stat.math.ethz.ch
Subject: Re: [R] R 1.6 Gui for Windows




On Mon, 7 Oct 2002 chr.schulz at email.de wrote:

> ...i have  the same problem and didn't now why ?
> 
> Error in testRversion(descfile) : This package has not been installed
properly
>  See the Note in ?library
> 
> The problem is the .First() Function, but the same works in R1.5.1 without
problems ?
> 
> thanks for advance,christian
> 
> options(editor="\"c:/DevelopeWinedt/winedt\"-c=\"R-WinEdt-edit\" -e=r.ini
-V")
> options(pager="\"c:/DevelopeWinedt/winedt\" -C=\"R-WinEdt\" -e=r.ini -V")
> 
> file.show(".Rhistory")
> .First <-function() { options(prompt="$ ",continue="+\t")
> options(digits=3,length=999)
> library(ipred)
> library(relimp)
> library(hmisc)
> library(design)
> library(e1071)
> library(lattice)
> library(grid)
> library(XML)
> library(ctest)
> library(cluster)
> library(foreign)
> #library(mva)
> library(RODBC)
> library(foreign)
> #library(xtable)
> library(rpart)
> #library(tools)}
> Sys.putenv("TCL_LIBRARY"="c:/develope/Tcl/lib/tcl8.3")
> library(tcltk) #help()



Obviously, you are loading a number of packages.
The package structure is tested more intensively with R-1.6.0 than before,
so you might consider to update the package which produces that error
message ...

Just start R without that .First function and load the packages step by
step to see, which one produces the error message ...

Uwe Ligges




> Freq <- function(x){
>   xmat<-as.matrix(x)
> 
>   ifelse (ncol(xmat)==1,{
> 
>   Count<-table(x)
>   Total<-sum(Count)
>   Prcnt<-100*(Count/Total)
>   x1<-cbind(Count,Prcnt)
>   x2<-cbind(Total,sum(Prcnt))
>   Frequency.Table<-as.data.frame(rbind(x1,x2))
>   c<-nrow(Frequency.Table)
>   rownames(Frequency.Table)[c]<-"Total"
>   return(Frequency.Table)}
>   ,
>   return("To use this function across multiple columns use apply"))
>     }
> 
> eda.shape <- function(x) {
>     par(mfrow=c(2,2))
>     hist(x)
>     boxplot(x)
>     iqd  <- summary(x)[5] - summary(x)[2]
>     plot(density(x,bw=2*iqd),xlab="x",ylab="",type="l")
>     qqnorm(x)
>     qqline(x)
>     }
> eda.ts <- function(x) {
>     par(mfrow=c(2,1))
>     plot.ts(x)
>     acf(x)
>     invisible()
>     }
> replace.na.m <-
>   function (x){
>     X<-mean(x,na.rm=TRUE)
>     ifelse ( is.na(x)=="TRUE",X,x)
> }
> replace.na.x<-
>   function(x, value){
>     ifelse (is.na(x)=="TRUE", value , x)
> }
> 
> .Last <- function() {
> graphics.off()
> cat(paste(date(),"\nAdiosAmigos\n"))
> }
> 
> 
> Uwe Ligges schrieb:
> 
> Benjamin.STABLER at odot.state.or.us wrote:
> 
> I upgraded to R Gui 1.6 this morning and I can't seem to get it to accept
my
> new startup directory.  R 1.51 will accept
> "F:\_ben\bls\gen1\results\bls\analysis" as the start in directory for the
R
> Gui shortcut, but R 1.6 will not.  R 1.6 will accept
> "F:\_ben\bls\gen1\results\bls".  It seems to have trouble when I add
> "\analysis."  R still loads fine but I get the following error:
> 
> Error in testRversion(descfile) : This package has not been installed
> properly
> See the Note in ?library
> 
> Also, R 1.6 will let me set the working directory to include "analysis."  
> 
> 
> [Looks like there wasn't any answer to this mail before]
> Including the dot?
> 
> 
> I can ignore the error and R still loads in the correct directory.  
> But I am curious as to why this is.  Any ideas?  Thanks.
> 
> 
>  
> Maybe there is an .Renviron or .Rprofile file or something like that in
> your directory that causes the error message? Or a .First() function in
> your .Rdata workspace in that directory?
> 
> Uwe Ligges
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
> 
> 
> 
> 
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From duncan at research.bell-labs.com  Mon Oct  7 20:02:58 2002
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Mon, 7 Oct 2002 14:02:58 -0400
Subject: [R] RE: new packages: geepack and KMsurv
In-Reply-To: <200210071328.g97DSGW18586@pc112145.oulu.fi>; from jarioksa@sun3.oulu.fi on Mon, Oct 07, 2002 at 04:28:16PM +0300
References: <jsendak@omniwhittington.co.uk> <200210071328.g97DSGW18586@pc112145.oulu.fi>
Message-ID: <20021007140258.A24939@jessie.research.bell-labs.com>


The key to the error message 

> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
> 	unable to load shared library "/usr/lib/R/library/acepack/libs/acepack.so":
>   libR.so: cannot open shared object file: No such file or directory
> Error in library(acepack) : .First.lib failed

is the libR.so.  That means that at some stage you compiled R with the
--enable-R-shlib flag and built libR.so.  Then, when you installed a
new version of R, you did not use the --enable-R-shlib flag. So
libR.so was not built. But when a package is installed and libR.so
exists, that package is linked against the libR.so. So when that
previously compiled package is loaded into the new R that has no
libR.so, you get the error message you are seeing.

To get around this problem, either re-install the packages from source
as you mention or rebuild R with the --enable-R-shlib flag passed to
configure. I agree this is annoying. It is a natural issue when we
have component based software; both a blessing and a curse.

 D.

Jari Oksanen wrote:
> 
> jsendak at omniwhittington.co.uk said:
> > I downloaded geepack from your site and installed it from the zip
> > file. However, although it appears under my library directory, I could
> > not load into R.
> 
> I found out that all old packages with compiled code in shared libraries fail to
> load in R-1.6.0. My platform is RH7.3 with the notorious C/G77 compiler, but the
> reason seem not to be changes in compiler, but changes in R. Packages that I had
> compiled and installed day before upgrading to R-1.6.0 failed after upgrading.
> The problem vanishes when the package is re-installed from the source. This is a
> mild nuisance and for several packages I wait that they are ugpraded in CRAN so
> that re-building happens automatically. I am not sure if this is the reason with
> your trouble with binary packages, since your platform is very different. This
> is the output I get with one example package:
> 
> > library(acepack)
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
> 	unable to load shared library "/usr/lib/R/library/acepack/libs/acepack.so":
>   libR.so: cannot open shared object file: No such file or directory
> Error in library(acepack) : .First.lib failed
> # But it is there:
> 
> > system("ls /usr/lib/R/library/acepack/libs/acepack.so -l")
> -rwxr-xr-x    1 root     root        68548 May 29 11:00 /usr/lib/R/library/acepack/libs/acepack.so
> 
> > dyn.load("/usr/lib/R/library/acepack/libs/acepack.so")
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
> 	unable to load shared library "/usr/lib/R/library/acepack/libs/acepack.so":
>   libR.so: cannot open shared object file: No such file or directory
> 
> I have tried to find if this new behaviour is documented, but I haven't yet
> found anything, so this may be an "undocumented feature". Who knows?
> 
> cheers, jari oksanen
> -- 
> Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
> Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
> email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Fri Oct  4 17:18:09 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Fri, 04 Oct 2002 11:18:09 -0400
Subject: [R] lm fitting with a specified slope
References: <Pine.LNX.4.33.0210031308320.14221-100000@aberdeen.fpcc.net>
Message-ID: <3D9DB131.27CA08CA@umsanet.edu.bo>

You want offset.

Kjetil Halvorsen

Rob Lee wrote:
> 
> Is there an easy way to do a linear model with an a priori known slope?
> 
> In essence, I want to minimize the residuals around a line of known slope.
> 
> -R
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Richard.Rowe at jcu.edu.au  Tue Oct  8 00:02:49 2002
From: Richard.Rowe at jcu.edu.au (Richard Rowe)
Date: Tue, 08 Oct 2002 08:02:49 +1000
Subject: [R] error bars in line plots
In-Reply-To: <Pine.LNX.4.44.0210070918260.1327-100000@localhost.localdom
 ain>
References: <m3adlsryx3.fsf@home.sweet.home>
Message-ID: <5.0.0.25.1.20021008075453.03001070@pop.jcu.edu.au>

At 09:23 07/10/02 +0200, you wrote:
>On 6 Oct 2002, Myriam Abramson wrote:
>
>   |Hi!
>   |
>   |Could you tell me how I can draw a graph with error bars?
>   |Sorry, I don't use R that often and I couldn't find it easily in the
>   |documentation.
>and Ott Toomet responded
>There is no errorbars function in the package.  But you may easily construct
>your own using segments().  I add my own versions below (actually, why not
>put something similar into the base package?).

When I first met the problem I felt error bars should be added ... however 
different disciplines have different ideas on what confidence intervals 
should be and a 'packaged' version of 'error bars' may be less than 
helpful.  Maybe a short script should be put somewhere accessable?  I built 
my own script in a couple of minutes based on previous solutions given by 
readers of r-help ... . It is actually a nice beginner exercise in R 
programming, taking a few moments with every prospect of swift success,


Richard Rowe
Senior Lecturer
Department of Zoology and Tropical Ecology, James Cook University
Townsville, Queensland 4811, Australia
fax (61)7 47 25 1570
phone (61)7 47 81 4851
e-mail: Richard.Rowe at jcu.edu.au
http://www.jcu.edu.au/school/tbiol/zoology/homepage.html

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mail at fwr.on.ca  Tue Oct  8 01:25:40 2002
From: mail at fwr.on.ca (FWR)
Date: Mon, 7 Oct 2002 19:25:40 -0400
Subject: [R] PostgreSQL & DBI or ???
Message-ID: <E17yhFu-0001tS-00@server.family>

The only database access package I see on CRAN is DBI. 
But is there a PostgreSQL driver for it yet? (where?)
There is no sign of an RPgSQL package on CRAN either. 
What to do?

Thanks,
Bruce L.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r.hankin at auckland.ac.nz  Tue Oct  8 05:18:33 2002
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Tue, 8 Oct 2002 16:18:33 +1300
Subject: [R] status of CRAN
Message-ID: <200210080318.g983IXO24774@r.hankin.sges.auckland.ac.nz>

Dear List

the other day, I had my yearly staff interview with my Head of
Department.

Under my list of publications, I included a document which I wrote
(R-and-octave.txt) that ended up in the "contributed docs" section of
CRAN.

Unfortunately, neither my HoD nor the personnel person were terribly
impressed with it, even though its preparation time was commensurate
with many of my (co authored) dead-tree publications.

They cited lack of peer-review, and fact that it was disseminated
solely over the 'net as reasons.  They were very nice about it, but
the bottom line was that it just didn't count for very much.  I tried
to point out that CRAN was highly regarded, but was unable to come up
with much in the way of objective evidence.

How would members of the List respond to this criticism?  Does anyone
have anything I could use to bolster my position?  Although specific
feedback about R-and-octave.txt would be very welcome, I'd also like
the List to suggest objective (and convincing!) facts which I could
use next week at the follow-up meeting.


Thanks in advance




-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

as of: Tue Oct  8 16:12:00 NZDT 2002
This (linux) system up continuously for:  404 days, 21 hours, 54 minutes
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jeff_hamann at hamanndonald.com  Tue Oct  8 08:11:45 2002
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Mon, 7 Oct 2002 23:11:45 -0700
Subject: [R] dyn.load and c-function
Message-ID: <000b01c26e91$9486ca10$0300a8c0@godzilla>

I've got a c function in a dll and have been able to call it from R. The
function is :

void __stdcall testfunc2(
  unsigned long *a,
  double        *b,
  unsigned long *c,
  double        *result )
{
    *result = 0;

    *result = (*a) * (*b) * (*c);
}

and the R code to call the function is as follows:

dyn.load("c:/openfvs/biometrics/debug/biometrics.dll" )
tf2 <- function( a, b, c, d )
  .C("testfunc2",
     as.integer(a),
     as.double(b),
     as.integer(c),
     as.double(d) )

I'm having a little trouble getting the value out of the R function. I would
like to be able to call the R funcion as :

val <- tf2( a, b, c )

when I'e tried to call the function as:

tf2 <- function( a, b, c )
  .C("testfunc2",
     as.integer(a),
     as.double(b),
     as.integer(c),
     as.double(d) )[[4]]

I get an "Object d not found" error...

how would I write the R part so that I can call my function the way I want
to?

Thanks,
jeff.





Jeff D. Hamann
Hamann, Donald & Associates, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
Bus. 541-753-7333
Cell. 541-740-5988
jeff_hamann at hamanndonald.com
www.hamanndonald.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jdn at cs.sfu.ca  Tue Oct  8 09:00:09 2002
From: jdn at cs.sfu.ca (Jason Nielsen)
Date: Tue, 8 Oct 2002 00:00:09 -0700 (PDT)
Subject: [R] Fortran and R: F90
Message-ID: <Pine.GSO.4.10.10210072342080.8328-100000@stawlmihq>

As far as I know R does not support modern Fortran (i.e. f90/95).  I have
tried with several different f95 compilers to load f90 code to no avail.
Intel's Fortran compiler (ifc) is particularly bad as it doesn't play nice
with gcc.  It is a shame as f90 is quite pleasant.  I highly doubt this
situation will change until g95 becomes part of gcc, a very long time in
coming!  If I'm wrong I would be more than happy to be enlightened :-).  

Jason

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Oct  8 09:03:22 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Oct 2002 09:03:22 +0200
Subject: [R] dyn.load and c-function
In-Reply-To: <000b01c26e91$9486ca10$0300a8c0@godzilla>
References: <000b01c26e91$9486ca10$0300a8c0@godzilla>
Message-ID: <x2bs65l8ed.fsf@biostat.ku.dk>

"Jeff D. Hamann" <jeff_hamann at hamanndonald.com> writes:

> tf2 <- function( a, b, c )
>   .C("testfunc2",
>      as.integer(a),
>      as.double(b),
>      as.integer(c),
>      as.double(d) )[[4]]
> 
> I get an "Object d not found" error...
> 
> how would I write the R part so that I can call my function the way I want
> to?

Your C function assumes that d (or "result" as you call it on the
other side) exists with the relevant length. So you need to create it:

tf2 <- function( a, b, c ){
    d <- double(length(a))
   .C("testfunc2",
      as.integer(a),
      as.double(b),
      as.integer(c),
      d)[[4]]
}

or just 

tf2 <- function( a, b, c )
   .C("testfunc2",
      as.integer(a),
      as.double(b),
      as.integer(c),
      double(length(a)))[[4]]


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jarioksa at sun3.oulu.fi  Tue Oct  8 09:27:45 2002
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Tue, 08 Oct 2002 10:27:45 +0300
Subject: [R] RE: new packages: geepack and KMsurv 
In-Reply-To: Message from Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk> 
   of "07 Oct 2002 16:30:06 +0200." <x2vg4epbip.fsf@biostat.ku.dk> 
Message-ID: <200210080727.g987Rjq03233@pc112145.oulu.fi>


p.dalgaard at biostat.ku.dk said:
> Now the error message claims that the library is absent, so does the
> file actually exist? And did you install from RPM or from source

Both: After finding this problem with Martyn Plummer's RPM, I installed from 
the source (usual magic: ./configure && make). The problem pertains is the same.

duncan at research.bell-labs.com said:
> is the libR.so.  That means that at some stage you compiled R with the
> --enable-R-shlib flag and built libR.so.  Then, when you installed a
> new version of R, you did not use the --enable-R-shlib flag. So
> libR.so was not built. But when a package is installed and libR.so
> exists, that package is linked against the libR.so. So when that
> previously compiled package is loaded into the new R that has no
> libR.so, you get the error message you are seeing.

Now it looks that this is deeper in the configure scripts or in the way they 
work in RH7.3 (gcc 2.96, b***y b*****ds). The ./configure claims that R is not 
built as a shared library, but still dyn.load looks for libR.so. This is the output 
when I build from the source:

./configure info screen:

R is now configured for i686-pc-linux-gnu

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc  -D__NO_MATH_INLINES -mieee-fp -g -O2
  C++ compiler:              g++  -mieee-fp -g -O2
  Fortran compiler:          g77  -mieee-fp -g -O2

  X11 support:               yes
  Gnome support:             no
  Tcl/Tk support:            yes
  Readline support:          yes

  R profiling support:       yes
  R as a shared library:     no

  Recommended packages:      yes

And this happens when I run the code I "make'd" (I guess gnu `make' is a weak verb
and has regular declension):

[jarioksa at pc112145 R-1.6.0]$ /tmp/R-1.6.0/bin/R

R : Copyright 2002, The R Development Core Team
Version 1.6.0  (2002-10-01)

[...snip...]

> library(akima) # Like it should be: not installed with this version
Error in library(akima) : There is no package called `akima'
> dyn.load("/usr/lib/R/library/akima/libs/akima.so")
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
	unable to load shared library "/usr/lib/R/library/akima/libs/akima.so":
  libR.so: cannot open shared object file: No such file or directory

I am bushed.

Exactly the same thing happens with Martyn Plummer's rpm package.

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Marcus_Jellinghaus at gmx.de  Tue Oct  8 10:11:16 2002
From: Marcus_Jellinghaus at gmx.de (Marcus Jellinghaus)
Date: Tue, 8 Oct 2002 04:11:16 -0400
Subject: [R] Why are big data.frames slow? What can I do to get it faster?
In-Reply-To: <x2ofa6qwxy.fsf@biostat.ku.dk>
Message-ID: <ANEPLCDCPMDLBOLGOBCBGELDDPAA.Marcus_Jellinghaus@GMX.DE>

I wanted to know why not-vectorized operations are slow.
Thank you for your suggestions.
I did three things:
-Beside looking at the total computation time, I analyzed the
GarbageCollection-time (gc()).
-I told R to use more memory. I use version 1.6.0 and used the command
"Rgui --min-vsize=600M --min-nsize=10M"
-I used test$Fieldname[i] instead of test[i, 6].

My results show that it saves a lot of time when I use enough memory and the
fieldnames. So thank?s a lot!

Here are the details:
Without fieldnames and without use of more memory:
GC-Time: 494Seconds, other calculations 124Seconds, Total 619Seconds.

Without fieldnames, with "Rgui --min-vsize=600M --min-nsize=10M"
GC-Time: 34Seconds, other calculations 114Seconds, Total 148Seconds.

With fieldnames, without use of more memory:
GC-Time: 0,5 Seconds, other calculations 2 Seconds, Total 2,5 Seconds.
(but long time for loading the matrix)

with fieldnames, with "Rgui --min-vsize=600M --min-nsize=10M"
GC-Time: < 1 Second, other calculations < 1 Second, Total < 1 second

Marcus Jellinghaus



Peter Dalgaard writes:

>You'll likely have to invoke the garbage collector a couple of times,
>and there might also be issues of memory growth kicking in. Once you
>get beyond some threshold, the machine starts swapping bits and pieces
>of the workspace in and out of physical memory,


Andy Liaw writes:

>If you are on Windows and using R version prior to 1.6.0, make sure R can
>use all 1GB of the ram, as the default is to use up to 256MB or physical
>RAM, which ever is smaller.  In R-1.6.0, that limit is raised to the
smaller
>of 1GB and physical RAM.
[..]
>Extracting from data frame one element at a time the way you did is
>expensive.  I.e., test[i, 6] is slower than test$whatever[i].


Peter Dalgaard writes:

> It's somewhat difficult to reproduce the behaviour, since you only give
> part of the code necessary (e.g. how many *columns* do you have in
> your data frame?)

> summary(test)
    datetime                       CCY1               CCY2
Bid               Ask             CCYPair
 Min.   :2002-05-28 00:00:02   Length:500000      Length:500000      Min.
:  0.557   Min.   :  0.5574   Length:500000
 1st Qu.:2002-05-28 17:30:47   Mode  :character   Mode  :character   1st
Qu.:  1.532   1st Qu.:  1.5319   Mode  :character
 Median :2002-05-29 14:43:02                                         Median
:  4.047   Median :  4.0476
 Mean   :2002-05-29 14:42:36                                         Mean
: 38.664   Mean   : 38.6858
 3rd Qu.:2002-05-30 10:22:30                                         3rd
Qu.: 32.888   3rd Qu.: 32.8891
 Max.   :2002-05-31 02:58:54                                         Max.
:182.150   Max.   :182.3000

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Tue Oct  8 10:12:49 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 8 Oct 2002 10:12:49 +0200 (CEST)
Subject: [R] Frailty and coxph
Message-ID: <Pine.LNX.4.44.0210080948290.23441-100000@tal.stat.umu.se>


Does someone know the rules by which 'coxph' returns 'frail', the
predicted frailty terms? In my test function:

-----------------------------------------------
fr <- function(){
  #testing(frailty terms in 'survival'
  require(survival)
  dat <- data.frame(exit = 1:6,
                    event = rep(1, 6),
                    x = rep(c(0, 1), 3),
                    id = rep(1:2, rep(3, 2))
                    )
   fit1 <- coxph(Surv(exit, event) ~ x +
                frailty(id, dist = "gaussian"), data = dat)
  return(fit$frail)
}
-----------------------------------------------

the result is 'NULL', but with 'real data', I usually get the predicted
frailties. The help pages doesn't even mention the component 'frail', but
in the code I can see that 'frail' is reurned if  'nfrail > 0'. And
(from 'coxpenal.fit.s'):

---------------------------
  if (any(sparse)) {
    ...
  }else{
     nfrail <- 0
    ...
  }
---------------------------
and
---------------------------
  sparse <- sapply(pattr, function(x) !is.null(x$sparse) &&  x$sparse)
---------------------------

but here I lose track (lost patience:() of what is happening. I would like
to have the predicted frailty terms _always_ when I have a frailty term in
the model. What can I do? Or can someone explain in simple words what the
rules are that decide whether I get the predicted vaues or not?

G?ran


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Oct  8 10:27:10 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Oct 2002 10:27:10 +0200
Subject: [R] RE: new packages: geepack and KMsurv
In-Reply-To: <200210080727.g987Rjq03233@pc112145.oulu.fi>
References: <200210080727.g987Rjq03233@pc112145.oulu.fi>
Message-ID: <x28z19nxnl.fsf@biostat.ku.dk>

Jari Oksanen <jarioksa at sun3.oulu.fi> writes:

> duncan at research.bell-labs.com said:
> > is the libR.so.  That means that at some stage you compiled R with the
> > --enable-R-shlib flag and built libR.so.  Then, when you installed a
> > new version of R, you did not use the --enable-R-shlib flag. So
> > libR.so was not built. But when a package is installed and libR.so
> > exists, that package is linked against the libR.so. So when that
> > previously compiled package is loaded into the new R that has no
> > libR.so, you get the error message you are seeing.
...
> > library(akima) # Like it should be: not installed with this version
> Error in library(akima) : There is no package called `akima'
> > dyn.load("/usr/lib/R/library/akima/libs/akima.so")
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
> 	unable to load shared library "/usr/lib/R/library/akima/libs/akima.so":
>   libR.so: cannot open shared object file: No such file or directory
> 
> I am bushed.

Nono. You just need to read what Duncan was saying: It's the shared
libraries *in the packages* that are referring to libR.so. Rebuild R
with

path/to/configure --enable-R-shlib && make 

Then your old libraries should work (although I suspect that the ones
that you rebuilt now do not work....).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Mon Oct  7 23:00:23 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 8 Oct 2002 10:00:23 +1300
Subject: [R] PostgreSQL & DBI or ???
In-Reply-To: <E17yhFu-0001tS-00@server.family>; from mail@fwr.on.ca on Mon, Oct 07, 2002 at 07:25:40PM -0400
References: <E17yhFu-0001tS-00@server.family>
Message-ID: <20021008100023.B19957@camille.indigoindustrial.co.nz>

On Mon, Oct 07, 2002 at 07:25:40PM -0400, FWR wrote:
> The only database access package I see on CRAN is DBI. 
> But is there a PostgreSQL driver for it yet? 

No.

> There is no sign of an RPgSQL package on CRAN either. 

There is one here:

http://rpgsql.sourceforge.net/

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jarioksa at sun3.oulu.fi  Tue Oct  8 11:57:50 2002
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Tue, 08 Oct 2002 12:57:50 +0300
Subject: [R] RE: new packages: geepack and KMsurv 
In-Reply-To: Message from Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk> 
   of "08 Oct 2002 10:27:10 +0200." <x28z19nxnl.fsf@biostat.ku.dk> 
Message-ID: <200210080957.g989voa18816@pc112145.oulu.fi>

Dear Peter, Duncan &al,

Yes, with  --enable-R-shlib && make things seem to work: R is able to load 
both olden and newly installed libraries. Some baffling details remain:

- I am sure that I never earlier enabled this when building R, but now it seems 
to be necessary for loading old libraries. I don't know why. 

- Binary upgrading of rpm's (1.5.1 -> 1.6.0) in my RH7.3 is incompatible with
old libraries, and these must be re-installed (or R must be built from the
source with --enable-R-shlib). 

It seems that ./configure with default switches gives different configuration 
(although it doesn't say so). "Undocumented behaviour" may be good phrase here.

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krcabrer at epm.net.co  Tue Oct  8 12:37:49 2002
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Tue, 08 Oct 2002 05:37:49 -0500
Subject: [R] status of CRAN
References: <200210080318.g983IXO24774@r.hankin.sges.auckland.ac.nz>
Message-ID: <3DA2B57D.7050308@epm.net.co>

Dear Dr. Hankin:

I think your case can be other professors cases when they write
gnu documentation.

I suggest to put a download counter.... but I don't know if CRAN would
like to do that.

The feedbacks could be a very good evidence to show how many users read
your document.

I hope tha HoD and the personnel person will understand that the net  is 
sometimes even
more disseminated than many publications.

Robin Hankin wrote:

>Dear List
>
>the other day, I had my yearly staff interview with my Head of
>Department.
>
>Under my list of publications, I included a document which I wrote
>(R-and-octave.txt) that ended up in the "contributed docs" section of
>CRAN.
>
>Unfortunately, neither my HoD nor the personnel person were terribly
>impressed with it, even though its preparation time was commensurate
>with many of my (co authored) dead-tree publications.
>
>They cited lack of peer-review, and fact that it was disseminated
>solely over the 'net as reasons.  They were very nice about it, but
>the bottom line was that it just didn't count for very much.  I tried
>to point out that CRAN was highly regarded, but was unable to come up
>with much in the way of objective evidence.
>
>How would members of the List respond to this criticism?  Does anyone
>have anything I could use to bolster my position?  Although specific
>feedback about R-and-octave.txt would be very welcome, I'd also like
>the List to suggest objective (and convincing!) facts which I could
>use next week at the follow-up meeting.
>
>
>Thanks in advance
>
>
>
>
>  
>

-- 
Kenneth Roy Cabrera Torres
Celular +57 (315) 405 9339



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krcabrer at epm.net.co  Tue Oct  8 12:50:20 2002
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Tue, 08 Oct 2002 05:50:20 -0500
Subject: [R] Ordinal categorical data with GLM
References: <3E96F037.60105@arcriswell.com>
Message-ID: <3DA2B86C.3090807@epm.net.co>

Hello Dear R List:

Is there an easy way (one line command, or at least without "for") to 
make a
categorization of a continuos variable that I have in a vector, say "x", 
and the
limits of the categories in other vector, say "y". The vector "x" is 
10000 length
and the "y" vector is 101 length for 100 categories, where rank of "x" 
is narrow
or at least the same than the rank of "y".

Thank you for your ideas.

Kenneth

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.C.Rougier at durham.ac.uk  Tue Oct  8 12:58:24 2002
From: J.C.Rougier at durham.ac.uk (Jonathan Rougier)
Date: Tue, 08 Oct 2002 11:58:24 +0100
Subject: [R] hash argument of new.env()
Message-ID: <3DA2BA50.31DE140E@durham.ac.uk>

Hi everyone,

There is no mention in ?new.env (R-1.6.0) of what the effect of setting
the hash argument of new.env() actually does.  What does it mean in
performance terms to say that "the environment will be hashed"?

Thanks, Jonathan.
-- 
Jonathan Rougier                       Science Laboratories
Department of Mathematical Sciences    South Road
University of Durham                   Durham DH1 3LE
tel: +44 (0)191 374 2361, fax: +44 (0)191 374 7388
http://www.maths.dur.ac.uk/stats/people/jcr/jcr.html
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hande at tcd.ie  Tue Oct  8 13:04:19 2002
From: hande at tcd.ie (Elaine Hand)
Date: Tue, 8 Oct 2002 12:04:19 +0100
Subject: [R] temporal simulation
Message-ID: <f04320406b9c86ab5dee1@[134.226.180.106]>

Hello,

I am new to R and was wondering if anybody would be able to advice me 
on the following query. Is there any package available to generate a 
mixed Poisson process, temporal data, using R? If anybody has 
accomplished this before or has any advice I would appreciate it.

Regards,

Elaine Hand
-- 


Elaine Hand
Department of Community Health & General Practice
Trinity College Dublin
Trinity Centre for Health Sciences
AMNCH
Dublin 24
Ireland

email: hande at tcd.ie
telephone: +353 1 608 3460
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Oct  8 13:55:40 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Oct 2002 13:55:40 +0200
Subject: [R] hash argument of new.env()
In-Reply-To: <3DA2BA50.31DE140E@durham.ac.uk>
References: <3DA2BA50.31DE140E@durham.ac.uk>
Message-ID: <x2ptulm9fn.fsf@biostat.ku.dk>

Jonathan Rougier <J.C.Rougier at durham.ac.uk> writes:

> Hi everyone,
> 
> There is no mention in ?new.env (R-1.6.0) of what the effect of setting
> the hash argument of new.env() actually does.  What does it mean in
> performance terms to say that "the environment will be hashed"?

It's difficult to say since there are various tradeoffs (especially
between speed and space). Empirically, I seem to recall that we did
some benchmarking and the effect of hashing was essentially nil for
typical environments created by R function calls. However, that's not
the only potential usage of environments in R; they can also be used
for what other languages call associative arrays or hashes. For large
environments, the potential speedup is from the O(N) complexity of a
linear search to a constant-time lookup using a hash-key on a near
empty table, but there's also an administrative overhead of re-hashing
an environment if it outgrows its hashtable, etc., etc.

There are several webpages that discuss hashing (although not all of
them relate to this particular meaning of the word...) e.g.
http://www-theory.dcs.st-and.ac.uk/~mda/cs2001/hashing/general.html

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Tue Oct  8 13:53:33 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue, 8 Oct 2002 07:53:33 -0400
Subject: [R] status of CRAN
In-Reply-To: <200210080318.g983IXO24774@r.hankin.sges.auckland.ac.nz>; from r.hankin@auckland.ac.nz on Tue, Oct 08, 2002 at 04:18:33PM +1300
References: <200210080318.g983IXO24774@r.hankin.sges.auckland.ac.nz>
Message-ID: <20021008075333.A1957@cattell.psych.upenn.edu>

On 10/08/02 16:18, Robin Hankin wrote:
Dear List

>Under my list of publications, I included a document which I wrote
(R-and-octave.txt) that ended up in the "contributed docs" section of
CRAN.

>Unfortunately, neither my HoD nor the personnel person were terribly
impressed with it ...

>They cited lack of peer-review, and fact that it was disseminated
solely over the 'net as reasons.

>How would members of the List respond to this criticism?

It seems to me that the 'net is a non-issue and could be refuted by
pointing to the existence of refereed journal published solely or
mainly on the internet.  (I started to search for them, and I found
many, but no complete list.)

The point about peer-review is more serious.  Papers given at
meetings, and even those posted on papers.ssrn.com, are often of low
quality; their selection is based on the topic more than the content.
But some scholarship _is_ important even though it is not refereed.

I think a good way to handle this is with letters of recommendation
written by people known to your evaluators.  This is an imposition, of
course, but such letters need not be long.

I don't think hit counts are very useful.  They are based more on the
topic, or the author's reputation, than the content.  (SSRN, however,
makes a big deal out of download counts, even though these are based
on reading the abstract only.)

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jzhang at jimmy.harvard.edu  Tue Oct  8 14:21:55 2002
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Tue, 8 Oct 2002 08:21:55 -0400 (EDT)
Subject: [R] PostgreSQL & DBI or ???
Message-ID: <200210081221.IAA28402@blaise.dfci.harvard.edu>


>Date: Mon, 7 Oct 2002 19:25:40 -0400
>To: "R's help mailing list" <r-help at stat.math.ethz.ch>
>From: "FWR" <mail at fwr.on.ca>
>Subject: [R] PostgreSQL & DBI or ???
>MIME-Version: 1.0
>
>The only database access package I see on CRAN is DBI. 
>But is there a PostgreSQL driver for it yet? (where?)
>There is no sign of an RPgSQL package on CRAN either. 
>What to do?

Have a look at http://rdbi.sourceforge.net. 

>
>Thanks,
>Bruce L.
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Tue Oct  8 14:42:50 2002
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 08 Oct 2002 08:42:50 -0400
Subject: [R] Ordinal categorical data with GLM
In-Reply-To: <3DA2B86C.3090807@epm.net.co>
References: <3E96F037.60105@arcriswell.com>
Message-ID: <5.1.0.14.2.20021008083909.02ab4bf0@mcmail.cis.mcmaster.ca>

Dear Kenneth,

At 05:50 AM 10/8/2002 -0500, Kenneth Cabrera wrote:

>Is there an easy way (one line command, or at least without "for") to make a
>categorization of a continuos variable that I have in a vector, say "x", 
>and the
>limits of the categories in other vector, say "y". The vector "x" is 10000 
>length
>and the "y" vector is 101 length for 100 categories, where rank of "x" is 
>narrow
>or at least the same than the rank of "y".

         cut(x, breaks=y)

or, if you want an ordered factor,

         ordered(cut(x, breaks=y))

Be careful to set the first entry of breaks below min(x). See ?cuts for 
details.

I hope that this helps,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Tue Oct  8 15:05:07 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 08 Oct 2002 06:05:07 -0700
Subject: JSS (was: Re: [R] status of CRAN)
In-Reply-To: <200210080318.g983IXO24774@r.hankin.sges.auckland.ac.nz>
References: <200210080318.g983IXO24774@r.hankin.sges.auckland.ac.nz>
Message-ID: <871y71axoc.fsf@jeeves.blindglobe.net>


>>>>> "robin" == Robin Hankin <r.hankin at auckland.ac.nz> writes:

    robin> How would members of the List respond to this criticism?
    robin> Does anyone have anything I could use to bolster my
    robin> position?  Although specific feedback about
    robin> R-and-octave.txt would be very welcome, I'd also like the
    robin> List to suggest objective (and convincing!) facts which I
    robin> could use next week at the follow-up meeting.

I hate to say this, but it's pretty standard.  I've had to put up with
this yearly (ESS is a major time suck, and it's just one of many
software/www/documentation projects that I'm involved with).

Can you spin it into an R-news article, or better yet, is it written
in a way that might be publishable in the Journal of Statistical
Software?  (R-news is listed, but not necessarily peer-reviewed, JSS
_IS_ peer reviewed).  I suspect that you would have to change things
slightly (and it is peer reviewed, so could be rejected), but
still, it might be worth a shot.

http://www.jstatsoft.org/

Note that JSS is affiliated with a decent print journal, Journal of
Computational and Graphical Statistics, which is put out by the
American Statistical Association.  It would be harder to get it
published there (JCGS), but there should be no issue with your HoD/etc
for getting credit for publication in JSS.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krcabrer at perseus.unalmed.edu.co  Tue Oct  8 15:13:19 2002
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Tue, 08 Oct 2002 08:13:19 -0500
Subject: [R] how to make categorization
References: <3E96F037.60105@arcriswell.com> <3DA2B86C.3090807@epm.net.co>
Message-ID: <3DA2D9EF.1080705@perseus.unalmed.edu.co>

Hello Dear R List:

>
> Is there an easy way (one line command, or at least without "for") to 
> make a
> categorization of a continuos variable that I have in a vector, say 
> "x", and the
> limits of the categories in other vector, say "y". The vector "x" is 
> 10000 length
> and the "y" vector is 101 length for 100 categories, where rank of "x" 
> is narrow
> or at least the same than the rank of "y".
>
> Thank you for your ideas.


-- 
Kenneth Roy Cabrera Torres
Unviersidad Nacional de Colombia, Sede Medell?n
Instituto de Ciencias Naturales y Ecolog?a
Escuela de Geociencias
e-mail krcabrer at unalmed.edu.co
Tel +57 (4) 430-9351



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From roger at ysidro.econ.uiuc.edu  Tue Oct  8 15:31:32 2002
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Tue, 8 Oct 2002 08:31:32 -0500 (CDT)
Subject: [R] image axes
Message-ID: <Pine.GSO.4.33.0210080818450.2271-100000@ysidro.econ.uiuc.edu>

I'm plotting matrices with image() and would like the axes to reflect
the conventional view that the upper left corner of the plot is (1,1).
But image seems to think that the lower left corner is (1,1).  Can
someone suggest a way of persuading it to think otherwise.  In effect,
I just want the y axis to run from from 1 to n downwards, not upwards.

I thought that something like axes=FALSE in image and

	axis(2,rev(pretty(1:n)))

would do this, but the rev() effect gets lost for reasons I'm not too
clear about.  Thanks for any suggestions...


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rgentlem at jimmy.harvard.edu  Tue Oct  8 16:17:27 2002
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Tue, 8 Oct 2002 10:17:27 -0400
Subject: [R] hash argument of new.env()
In-Reply-To: <3DA2BA50.31DE140E@durham.ac.uk>; from J.C.Rougier@durham.ac.uk on Tue, Oct 08, 2002 at 11:58:24AM +0100
References: <3DA2BA50.31DE140E@durham.ac.uk>
Message-ID: <20021008101727.H10602@jimmy.harvard.edu>

As Peter said,
  hashing tends to be effective if
   1) you have lots of things (most R environments in practice have
  very few objects so hashing is not so important, but for base it
  is).
   2) you access them individually. If for example you will always
  apply some operation to all the objects (or even most, I think) then
  a hash table doesn't really help and can hurt.

  But for some operations (especially in comp. bio.) they are very
  helpful and substantially reduce the time used to do lookups.



On Tue, Oct 08, 2002 at 11:58:24AM +0100, Jonathan Rougier wrote:
> Hi everyone,
> 
> There is no mention in ?new.env (R-1.6.0) of what the effect of setting
> the hash argument of new.env() actually does.  What does it mean in
> performance terms to say that "the environment will be hashed"?
> 
> Thanks, Jonathan.
> -- 
> Jonathan Rougier                       Science Laboratories
> Department of Mathematical Sciences    South Road
> University of Durham                   Durham DH1 3LE
> tel: +44 (0)191 374 2361, fax: +44 (0)191 374 7388
> http://www.maths.dur.ac.uk/stats/people/jcr/jcr.html
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20
| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
+---------------------------------------------------------------------------+
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Tue Oct  8 16:34:25 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 08 Oct 2002 09:34:25 -0500
Subject: [R] Windows binaries on cran.us.r-project.org
Message-ID: <6r7kgt9ez2.fsf@bates3.stat.wisc.edu>

We mentioned in previous messages that the machine that serves as
cran.us.r-project.org suffered a hardware failure recently and all the
file systems had to be regenerated from the backups.  When I
reinstalled the crontab entry that does the daily mirroring of
cran.r-project.org I made a mistake which resulted in the
bin/windows/base/ directory not being updated.  As a result, the
binaries of R-1.6.0 for Windows never appeared on the U.S. mirror.

This has been corrected.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chr.schulz at email.de  Tue Oct  8 17:06:18 2002
From: chr.schulz at email.de (chr.schulz@email.de)
Date: Tue, 8 Oct 2002 17:06:18 +0200
Subject: [R] sem (lisrel) - starting problems
Message-ID: <200210081506.g98F6DX07426@mailgate5.cinetic.de>

Hi,

(1.) 
How is it possible to get  automatic a "lower triangle of correlation matrix" ?

h.cor <- cor(dat,use="pairwise.complete.obs")
zz <- lower.tri(h.cor,diag=T)
### that's not what i wish and "wrong" ?
results <- matrix(unlist(h.cor[upper.tri(h.cor,diag=T)]))
results <- matrix(unlist(h.cor[upper.tri(h.cor,diag=T)]),5)

Must i take the lowest Frequency for the n value in SEM,because n is different if
i have NA's in data and use "pairwise.complete.obs" ?

(2.)
I'm little confused about the notation for the parameters

compcar and personcar are the independent latent variable mesurementModel 
satisfaction is the unobserved dependend var. what is measure with loyalty
and i assume here is no error and fix it by 1 .


thanks for advance 
christian


h.semModel <- matrix(c(
+                                    'nemploy -> compcar','lamx11', NA,
+                                    'sales -> compcar','lamx21', NA,
+                                    'sex -> personcar','lamx12', NA,
+                                    'age -> personcar','lamx22',NA,  
+                                    'loyalty -> satisfaction','lamy1',1,
+                                    'compcar <-> personcar','beta',NA,
+                                    'compcar -> loyalty','gam1',NA,
+                                    'personcar -> loyalty','gam2',NA),
+                                   ncol=3, byrow=TRUE)
$ 
$ 
$ 
$      sem.h <- sem(h.semModel,h.sem, 2802,debug=T)

 observed variables:
[1] "1:nemploy" "2:sales"   "3:sex"     "4:age"     "5:loyalty"


 latent variables:
[1] "6:compcar"      "7:personcar"    "8:satisfaction"


 parameters:
[1] "1:lamx11" "2:lamx21" "3:lamx12" "4:lamx22" "5:lamy1"  "6:beta"  
[7] "7:gam1"   "8:gam2"  


 RAM:
     heads to from parameter start
[1,]     1  6    1         1    NA
[2,]     1  6    2         2    NA
[3,]     1  7    3         3    NA
[4,]     1  7    4         4    NA
[5,]     1  8    5         5     1
[6,]     2  7    6         6    NA
[7,]     1  5    6         7    NA
[8,]     1  5    7         8    NA
Error in solve.default(C[ind, ind]) : singular matrix `a' in solve


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Tue Oct  8 17:52:49 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 8 Oct 2002 17:52:49 +0200 (CEST)
Subject: [R] Re: Frailty and coxph
In-Reply-To: <Pine.LNX.4.44.0210080948290.23441-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.44.0210081748000.24407-100000@tal.stat.umu.se>

On Tue, 8 Oct 2002, G?ran Brostr?m wrote:

>
> Does someone know the rules by which 'coxph' returns 'frail', the
> predicted frailty terms? In my test function:

[...]

Expanding my example function:

-------------------------------------------------------------
fr <- function(lup){
  #testing(frailty terms in 'survival'
  require(survival)

  lupp <- 2 * lup

  dat <- data.frame(exit = 1:lupp,
                    event = rep(1, lupp),
                    x = rep(c(0, 1), lup),
                    family = sample(rep(1:lup, 2))
                    )
    fit1 <- coxph(Surv(exit, event) ~ x +
                frailty(family, dist = "gaussian"), data = dat)

  return(fit1$frail)
-------------------------------------------------------------

> fr(5)
NULL
> fr(6)
[1]  0.04036113  0.17815670  0.02927139 -0.12160991  0.13439779
-0.26057710

'lup' larger than 5 (only) returns predicted frailty terms.

G?ran


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Oct  8 18:07:15 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 8 Oct 2002 09:07:15 -0700 (PDT)
Subject: [R] Fortran and R: F90
In-Reply-To: <Pine.GSO.4.10.10210072342080.8328-100000@stawlmihq>
Message-ID: <Pine.A41.4.44.0210080906050.73908-100000@homer36.u.washington.edu>

On Tue, 8 Oct 2002, Jason Nielsen wrote:

> As far as I know R does not support modern Fortran (i.e. f90/95).  I have
> tried with several different f95 compilers to load f90 code to no avail.
> Intel's Fortran compiler (ifc) is particularly bad as it doesn't play nice
> with gcc.  It is a shame as f90 is quite pleasant.  I highly doubt this
> situation will change until g95 becomes part of gcc, a very long time in
> coming!  If I'm wrong I would be more than happy to be enlightened :-).
>

Even if g95 never exists the situation should improve in a few years.  The
new Fortran 2000 standard defines how to communicate between C and
Fortran.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Oct  8 18:16:51 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 8 Oct 2002 09:16:51 -0700 (PDT)
Subject: [R] hash argument of new.env()
In-Reply-To: <3DA2BA50.31DE140E@durham.ac.uk>
Message-ID: <Pine.A41.4.44.0210080914150.73908-100000@homer36.u.washington.edu>

On Tue, 8 Oct 2002, Jonathan Rougier wrote:

> Hi everyone,
>
> There is no mention in ?new.env (R-1.6.0) of what the effect of setting
> the hash argument of new.env() actually does.  What does it mean in
> performance terms to say that "the environment will be hashed"?
>

If the environment has a lot of things in it then lookup should be faster
with hashing -- it should be roughly independent of the number of things
in the environment.   I believe that in the bioconductor project this is
actually noticeable when you have data on 5000 genes in an environment.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Tue Oct  8 18:14:59 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Tue, 08 Oct 2002 12:14:59 -0400
Subject: [R] Ordinal categorical data with GLM
References: <3E96F037.60105@arcriswell.com> <3DA2B86C.3090807@epm.net.co>
Message-ID: <3DA30483.77A9D54F@umsanet.edu.bo>

something like cut(x, br=y) ?

Kjetil Halvorsen

Kenneth Cabrera wrote:
> 
> Hello Dear R List:
> 
> Is there an easy way (one line command, or at least without "for") to
> make a
> categorization of a continuos variable that I have in a vector, say "x",
> and the
> limits of the categories in other vector, say "y". The vector "x" is
> 10000 length
> and the "y" vector is 101 length for 100 categories, where rank of "x"
> is narrow
> or at least the same than the rank of "y".
> 
> Thank you for your ideas.
> 
> Kenneth
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Tue Oct  8 18:30:48 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Tue, 8 Oct 2002 09:30:48 -0700
Subject: JSS (was: Re: [R] status of CRAN)
In-Reply-To: <871y71axoc.fsf@jeeves.blindglobe.net>
Message-ID: <4D991334-DADB-11D6-A6CA-000393860F3C@stat.ucla.edu>

I might add that this is one of the main reasons JSS was
started. Observe that JSS will also start a section
"Code Snippets", which will have code submissions
similar perhaps to JRSS-C (Applied Statistics) and
preferably in Sweave form (details are being worked
out).

On Tuesday, October 8, 2002, at 06:05 AM, A.J. Rossini wrote:

>
>>>>>> "robin" == Robin Hankin <r.hankin at auckland.ac.nz> writes:
>
>     robin> How would members of the List respond to this criticism?
>     robin> Does anyone have anything I could use to bolster my
>     robin> position?  Although specific feedback about
>     robin> R-and-octave.txt would be very welcome, I'd also like the
>     robin> List to suggest objective (and convincing!) facts which I
>     robin> could use next week at the follow-up meeting.
>
> I hate to say this, but it's pretty standard.  I've had to put up with
> this yearly (ESS is a major time suck, and it's just one of many
> software/www/documentation projects that I'm involved with).
>
> Can you spin it into an R-news article, or better yet, is it written
> in a way that might be publishable in the Journal of Statistical
> Software?  (R-news is listed, but not necessarily peer-reviewed, JSS
> _IS_ peer reviewed).  I suspect that you would have to change things
> slightly (and it is peer reviewed, so could be rejected), but
> still, it might be worth a shot.
>
> http://www.jstatsoft.org/
>
> Note that JSS is affiliated with a decent print journal, Journal of
> Computational and Graphical Statistics, which is put out by the
> American Statistical Association.  It would be harder to get it
> published there (JCGS), but there should be no issue with your HoD/etc
> for getting credit for publication in JSS.
>
> best,
> -tony
>
> --  
> A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
> U. of Washington Biostatistics		rossini at u.washington.edu	
> FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
> -------------- http://software.biostat.washington.edu/ ----------------
> FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
> UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
> (my tuesday/wednesday/friday locations are completely unpredictable.)
>
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Oct  8 18:36:30 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 8 Oct 2002 09:36:30 -0700 (PDT)
Subject: [R] Frailty and coxph
In-Reply-To: <Pine.LNX.4.44.0210080948290.23441-100000@tal.stat.umu.se>
Message-ID: <Pine.A41.4.44.0210080920220.73908-100000@homer36.u.washington.edu>

On Tue, 8 Oct 2002, [iso-8859-1] Gran Brostrm wrote:

>
> Does someone know the rules by which 'coxph' returns 'frail', the
> predicted frailty terms? In my test function:
>
> -----------------------------------------------
> fr <- function(){
>   #testing(frailty terms in 'survival'
>   require(survival)
>   dat <- data.frame(exit = 1:6,
>                     event = rep(1, 6),
>                     x = rep(c(0, 1), 3),
>                     id = rep(1:2, rep(3, 2))
>                     )
>    fit1 <- coxph(Surv(exit, event) ~ x +
>                 frailty(id, dist = "gaussian"), data = dat)
>   return(fit$frail)
> }
> -----------------------------------------------
>
> the result is 'NULL', but with 'real data', I usually get the predicted
> frailties. The help pages doesn't even mention the component 'frail', but
> in the code I can see that 'frail' is reurned if  'nfrail > 0'. And
> (from 'coxpenal.fit.s'):


The frailties are always returned. However, they aren't always returned
in the same place.  They are returned in $frail if they are computed by
the sparse algorithm described in help(frailty), and in $coef if the full
Newton-Raphson algorithm is used.

By default, then, frailties on more than 5 individuals will be in $frail,
fewer than five in $coef. In your example we have
> coef(fit1)
         x    gauss:1    gauss:2
-0.1143062  1.4837374 -1.4837374

which are the missing frailties.

You can use frailty(id, dist="gaussian", sparse=TRUE) to force the
frailties to be returned in $frail or sparse=FALSE to force them to be in
$coef.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Oct  8 19:46:29 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 08 Oct 2002 19:46:29 +0200
Subject: [R] image axes
References: <Pine.GSO.4.33.0210080818450.2271-100000@ysidro.econ.uiuc.edu>
Message-ID: <3DA319F5.4EB5BE90@statistik.uni-dortmund.de>



Roger Koenker wrote:
> 
> I'm plotting matrices with image() and would like the axes to reflect
> the conventional view that the upper left corner of the plot is (1,1).
> But image seems to think that the lower left corner is (1,1).  Can
> someone suggest a way of persuading it to think otherwise.  In effect,
> I just want the y axis to run from from 1 to n downwards, not upwards.
> 
> I thought that something like axes=FALSE in image and
> 
>         axis(2,rev(pretty(1:n)))
> 
> would do this, but the rev() effect gets lost for reasons I'm not too
> clear about.  Thanks for any suggestions...

Reason: you specify 'at', i.e. where the tick marks are plotted, and
that's the same positions as before.
You have to specify the labels addtionally. So the following should do
the trick:

 axis(2, at = pretty(1:n), labels = rev(pretty(1:n)))

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From roger at ysidro.econ.uiuc.edu  Tue Oct  8 20:05:00 2002
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Tue, 8 Oct 2002 13:05:00 -0500 (CDT)
Subject: [R] image axes
In-Reply-To: <3DA319F5.4EB5BE90@statistik.uni-dortmund.de>
Message-ID: <Pine.GSO.4.33.0210081300260.2271-100000@ysidro.econ.uiuc.edu>

Thanks Uwe, that's not quite what I wanted, but it was an excellent hint.
For the record, the suggestion works fine if pretty is symmetrically
spaced on the axis, but otherwise it isn't quite the right thing.  But
this is easily fixed by playing with the image x,y arguments as follows:

image(x=1:p,y=-(n:1),t(z),axes=FALSE,
        col=c("white","gray"),xlab="column",ylab="row")
axis(1,pretty(1:p))
axis(2,pretty(-(n:1)),labels=rev(pretty(1:n)))


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Tue, 8 Oct 2002, Uwe Ligges wrote:

>
>
> Roger Koenker wrote:
> >
> > I'm plotting matrices with image() and would like the axes to reflect
> > the conventional view that the upper left corner of the plot is (1,1).
> > But image seems to think that the lower left corner is (1,1).  Can
> > someone suggest a way of persuading it to think otherwise.  In effect,
> > I just want the y axis to run from from 1 to n downwards, not upwards.
> >
> > I thought that something like axes=FALSE in image and
> >
> >         axis(2,rev(pretty(1:n)))
> >
> > would do this, but the rev() effect gets lost for reasons I'm not too
> > clear about.  Thanks for any suggestions...
>
> Reason: you specify 'at', i.e. where the tick marks are plotted, and
> that's the same positions as before.
> You have to specify the labels addtionally. So the following should do
> the trick:
>
>  axis(2, at = pretty(1:n), labels = rev(pretty(1:n)))
>
> Uwe Ligges
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pem at theriver.com  Tue Oct  8 20:17:35 2002
From: pem at theriver.com (Patrick E. McKnight)
Date: Tue, 8 Oct 2002 11:17:35 -0700 (MST)
Subject: [R] data.frame merge matching several columns
Message-ID: <62068.128.196.98.70.1034101055.squirrel@192.168.0.2>

Greetings,

Is it possible to match several columns in a merge statement?  Here is my
problem:

data1 looks like this...

SUBID  TARGID  ITEM  RATING
1         1      1      4
1         1      2      5
1         1      3      3
1         1      4      2
1         1      5      5
......

SUBID is the ID for the raters, TARGID is the ID for the targets being
rated, ITEM ranges from 1 to 64 crossed by TARGID (i.e., all targets were
rated on 64 items), and RATING is the rating given by SUBID for each
TARGID and ITEM.

My second dataset looks like this data2:

TARGID  ITEM  TARGET
1        1      5
1        2      4
1        3      6
1        4      2
1        5      3
.......

TARGID again is the target's ID, ITEM ranges from 1 to 64, and TARGET is
the rating provided by the target.

I would like to merge these two data.frames by TARGID and ITEM to yield
the following structure:

SUBID  TARGID  ITEM  RATING  TARGET
1         1      1      4      5
1         1      2      5      4
1         1      3      3      6
1         1      4      2      2
1         1      5      5      3
........

I realize that merge appears to be the proper tool but there is no
documentation for how to merge by multiple columns.  Is this possible?

Thanks in advance for any assistance with the problem.


--
Cheers,

Patrick


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Tue Oct  8 20:35:44 2002
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 08 Oct 2002 14:35:44 -0400
Subject: [R] sem (lisrel) - starting problems
In-Reply-To: <200210081506.g98F6DX07426@mailgate5.cinetic.de>
Message-ID: <5.1.0.14.2.20021008142438.02bf5d60@mcmail.cis.mcmaster.ca>

Dear Christian,

At 05:06 PM 10/8/2002 +0200, chr.schulz at email.de wrote:
>Hi,
>
>(1.)
>How is it possible to get  automatic a "lower triangle of correlation 
>matrix" ?
>
>h.cor <- cor(dat,use="pairwise.complete.obs")
>zz <- lower.tri(h.cor,diag=T)
>### that's not what i wish and "wrong" ?
>results <- matrix(unlist(h.cor[upper.tri(h.cor,diag=T)]))
>results <- matrix(unlist(h.cor[upper.tri(h.cor,diag=T)]),5)

You can use the full correlation matrix for sem -- you don't need to make 
the matrix lower triangular; sem accepts a triangular correlation matrix to 
make it easier to input correlation matrices directly.

>Must i take the lowest Frequency for the n value in SEM,because n is 
>different if
>i have NA's in data and use "pairwise.complete.obs" ?

There's no correct answer to this question. A pairwise-present correlation 
matrix may not even be positive definite.

>(2.)
>I'm little confused about the notation for the parameters
>
>compcar and personcar are the independent latent variable mesurementModel
>satisfaction is the unobserved dependend var. what is measure with loyalty
>and i assume here is no error and fix it by 1 .
>
>
>
>h.semModel <- matrix(c(
>+                                    'nemploy -> compcar','lamx11', NA,
>+                                    'sales -> compcar','lamx21', NA,
>+                                    'sex -> personcar','lamx12', NA,
>+                                    'age -> personcar','lamx22',NA,
>+                                    'loyalty -> satisfaction','lamy1',1,
>+                                    'compcar <-> personcar','beta',NA,
>+                                    'compcar -> loyalty','gam1',NA,
>+                                    'personcar -> loyalty','gam2',NA),
>+                                   ncol=3, byrow=TRUE)
>$
>$
>$
>$      sem.h <- sem(h.semModel,h.sem, 2802,debug=T)

Yes, I can see that this is confused. It's hard to know what the correct 
input should be without knowing some more about the model you want to fit, 
but maybe the following will help:

(1) Do you intend nemploy and sales to be indicators of compcar? If so, the 
arrows are going in the wrong direction.

(2) A similar comment applies to sex and age as indicators of personcar, 
but it's hard to imagine that such a specification would make sense.

(3) Note that you require an identifying constraint for the latent 
variables, such as setting one of the lambdas for each to 1. Alternatively, 
you could set the variance of each of these latent variables to 1.

(4) As things stand, you've specified no variance parameters for the 
exogenous latent variables and no error-variance parameter for the 
endogenous variable loyalty.

Regards,
  John



-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Paul.Bliese at NA.AMEDD.ARMY.MIL  Tue Oct  8 20:55:43 2002
From: Paul.Bliese at NA.AMEDD.ARMY.MIL (Bliese, Paul D MAJ WRAIR-Wash DC)
Date: Tue, 8 Oct 2002 14:55:43 -0400 
Subject: [R] Orthogonal Polynomials
Message-ID: <58CAB2332C0DD511BC7900A0C9EA316D013D1719@dasmtyjqf009.amedd.army.mil>

Looking to the wonderful statistical advice that this group can offer.

In behavioral science applications of stats, we are often introduced to
coefficients for orthogonal polynomials that are nice integers.  For
instance, Kirk's experimental design book presents the following
coefficients for p=4:

Linear     -3 -1  1  3
Quadratic   1 -1 -1  1
Cubic      -1  3 -3  1

In R orthogonal polynomials are not integers. For instance, in R where p =4:

> poly(c(1:4),3)
              1    2          3
[1,] -0.6708204  0.5 -0.2236068
[2,] -0.2236068 -0.5  0.6708204
[3,]  0.2236068 -0.5 -0.6708204
[4,]  0.6708204  0.5  0.2236068

Where, of course, column 1 is linear, column 2 Quadratic and 3 cubic.

My experience is that the coding scheme used in R works "better" than the
integer scheme discussed in Kirk for many regression type analyses.

Can anyone enlighten me as to why?

Thanks,

Paul Bliese
Walter Reed Army Institute of Research
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jeff_hamann at hamanndonald.com  Tue Oct  8 20:59:32 2002
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Tue, 8 Oct 2002 11:59:32 -0700
Subject: [R] dyn.load and c-function
References: <000b01c26e91$9486ca10$0300a8c0@godzilla> <x2bs65l8ed.fsf@biostat.ku.dk>
Message-ID: <000e01c26efc$d6560210$0300a8c0@godzilla>

perfect. thanks.

jeff.

----- Original Message -----
From: "Peter Dalgaard BSA" <p.dalgaard at biostat.ku.dk>
To: "Jeff D. Hamann" <jeff_hamann at hamanndonald.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Tuesday, October 08, 2002 12:03 AM
Subject: Re: [R] dyn.load and c-function


> "Jeff D. Hamann" <jeff_hamann at hamanndonald.com> writes:
>
> > tf2 <- function( a, b, c )
> >   .C("testfunc2",
> >      as.integer(a),
> >      as.double(b),
> >      as.integer(c),
> >      as.double(d) )[[4]]
> >
> > I get an "Object d not found" error...
> >
> > how would I write the R part so that I can call my function the way I
want
> > to?
>
> Your C function assumes that d (or "result" as you call it on the
> other side) exists with the relevant length. So you need to create it:
>
> tf2 <- function( a, b, c ){
>     d <- double(length(a))
>    .C("testfunc2",
>       as.integer(a),
>       as.double(b),
>       as.integer(c),
>       d)[[4]]
> }
>
> or just
>
> tf2 <- function( a, b, c )
>    .C("testfunc2",
>       as.integer(a),
>       as.double(b),
>       as.integer(c),
>       double(length(a)))[[4]]
>
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Tue Oct  8 21:41:30 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 8 Oct 2002 21:41:30 +0200 (CEST)
Subject: [R] Numeric to factor
Message-ID: <Pine.LNX.4.44.0210082128370.24747-100000@tal.stat.umu.se>

I find 'How do I convert factors to numeric?' in the FAQ (7.12), but not
the other way around. Trivial maybe, but

> codes(factor(c(2, 10))
[1] 2 1
> codes(factor(c(2, 9)))
[1] 1 2

How do I get the levels attached to the codes in numeric order?

G?ran
---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From trafton at itd.nrl.navy.mil  Tue Oct  8 21:50:55 2002
From: trafton at itd.nrl.navy.mil (Greg Trafton)
Date: Tue, 08 Oct 2002 15:50:55 -0400
Subject: [R] repeated measures help; disagreement with SPSS
Message-ID: <m38z18hfq8.fsf@viz.itd.nrl.navy.mil>

Hi, all.

I have a simple design I'm comparing to output from SPSS.

the design is 1 repeated measure (session) and 1 between measure
(cond).  my dependent measure is rl.  here is the data I'm using (in a
data.frame):

mig <- data.frame(subj=factor(rep(subj,3)),
                  cond=factor(rep(cond,3)),
                  session=factor(c(rep(1,nsubj),rep(2,nsubj),rep(3,nsubj))),
                  rl)
> mig
    subj cond session      rl
1  401.1   NW       1  6.4081
2  402.1   NW       1  5.8861
3  500.1  NWC       1  5.3492
4  502.1  NWC       1  8.5302
5  601.1  NWR       1  2.7519
6  602.1  NWR       1  4.5404
7  603.1  NWR       1  4.3442
8  604.1  NWR       1  3.6722
9  401.1   NW       2  6.1492
10 402.1   NW       2  5.0506
11 500.1  NWC       2  6.5625
12 502.1  NWC       2 11.4430
13 601.1  NWR       2  2.8450
14 602.1  NWR       2  5.6558
15 603.1  NWR       2  3.3340
16 604.1  NWR       2  5.0548
17 401.1   NW       3  5.2717
18 402.1   NW       3  3.7337
19 500.1  NWC       3  3.6659
20 502.1  NWC       3  5.9463
21 601.1  NWR       3  2.3356
22 602.1  NWR       3  7.5458
23 603.1  NWR       3  5.0322
24 604.1  NWR       3  4.1381

I'm interested in the main effect of cond, session, and the
interaction between the two.

and here is what I get:

> tapply(mig$rl,IND=list(mig$cond, mig$session),FUN=mean)
           1       2        3
NW  6.147100 5.59990 4.502700
NWC 6.939700 9.00275 4.806100
NWR 3.827175 4.22240 4.762925

(the means are correct, duh ;-)

> summary(aov(rl ~ cond * session + Error(subj), data=mig))

Error: subj
          Df Sum Sq Mean Sq F value Pr(>F)
cond       2 28.305  14.153  1.9916 0.2311
Residuals  5 35.531   7.106               

Error: Within
             Df  Sum Sq Mean Sq F value  Pr(>F)  
session       2  4.4502  2.2251  2.9868 0.09616 .
cond:session  4 17.7335  4.4334  5.9509 0.01024 *
Residuals    10  7.4499  0.7450                  
---
Signif. codes:  0  `***'  0.001  `**'  0.01  `*'  0.05  `.'  0.1  ` '  1 

(the cond effect is consistent with SPSS)

> summary(aov(rl ~ cond * session + Error(subj/(session)), data=mig))

Error: subj
          Df Sum Sq Mean Sq F value Pr(>F)
cond       2 28.305  14.153  1.9916 0.2311
Residuals  5 35.531   7.106               

Error: subj:session
             Df  Sum Sq Mean Sq F value  Pr(>F)  
session       2  4.4502  2.2251  2.9868 0.09616 .
cond:session  4 17.7335  4.4334  5.9509 0.01024 *
Residuals    10  7.4499  0.7450                  
---
Signif. codes:  0  `***'  0.001  `**'  0.01  `*'  0.05  `.'  0.1  ` '  1 

(I ran this one this way b/c of a similar example from Baron's "Notes
for psychology experiments.  Unfortunately, neither the session nor
the interaction cond:session are the same as SPSS's output, though the
degrees of freedom are correct in both, of course).

I'm certainly able to believe that SPSS is wrong and R is right, but
thought I'd check with this list to make sure I'm not doing something
completely stupid...

(this is only a partial dataset; I'm using it just to test for now)

thanks!
greg

(I'm drawing heavily on "Notes on the use of R for psychology
experiments and questionnaires" by Jonathan Baron.)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pem at theriver.com  Tue Oct  8 21:57:49 2002
From: pem at theriver.com (Patrick E. McKnight)
Date: Tue, 8 Oct 2002 12:57:49 -0700 (MST)
Subject: [R] data.frame merge matching several columns
In-Reply-To: <5.1.0.14.2.20021008125748.0472b640@mailhost.blackmesacapital.com>
References: <62068.128.196.98.70.1034101055.squirrel@192.168.0.2>
        <5.1.0.14.2.20021008125748.0472b640@mailhost.blackmesacapital.com>
Message-ID: <62329.128.196.98.70.1034107069.squirrel@192.168.0.2>

Tony,

Right you are!  Apologies for overlooking such an obvious feature.  Thanks
for your help.

Cheers,

Patrick


> It looks like it works right out of the box.  (The documentation for
> merge() in R1.5.1 pretty clearly mentions the possibility of merging on
> multiple columns .)
>
>  > m1 <- read.table("tmp1.txt", header=T, row.names=NULL)
>  > m2 <- read.table("tmp2.txt", header=T, row.names=NULL)
>  > m1
>    SUBID TARGID ITEM RATING
> 1     1      1    1      4
> 2     1      1    2      5
> 3     1      1    3      3
> 4     1      1    4      2
> 5     1      1    5      5
>  > m2
>    TARGID ITEM TARGET
> 1      1    1      5
> 2      1    2      4
> 3      1    3      6
> 4      1    4      2
> 5      1    5      3
>  > merge(m1, m2)
>    TARGID ITEM SUBID RATING TARGET
> 1      1    1     1      4      5
> 2      1    2     1      5      4
> 3      1    3     1      3      6
> 4      1    4     1      2      2
> 5      1    5     1      5      3
>  >
>
> At 11:17 AM 10/8/2002 -0700, you wrote:
>>Greetings,
>>
>>Is it possible to match several columns in a merge statement?  Here is
>> my problem:
>>
>>data1 looks like this...
>>
>>SUBID  TARGID  ITEM  RATING
>>1         1      1      4
>>1         1      2      5
>>1         1      3      3
>>1         1      4      2
>>1         1      5      5
>>......
>>
>>SUBID is the ID for the raters, TARGID is the ID for the targets being
>> rated, ITEM ranges from 1 to 64 crossed by TARGID (i.e., all targets
>> were rated on 64 items), and RATING is the rating given by SUBID for
>> each TARGID and ITEM.
>>
>>My second dataset looks like this data2:
>>
>>TARGID  ITEM  TARGET
>>1        1      5
>>1        2      4
>>1        3      6
>>1        4      2
>>1        5      3
>>.......
>>
>>TARGID again is the target's ID, ITEM ranges from 1 to 64, and TARGET
>> is the rating provided by the target.
>>
>>I would like to merge these two data.frames by TARGID and ITEM to yield
>> the following structure:
>>
>>SUBID  TARGID  ITEM  RATING  TARGET
>>1         1      1      4      5
>>1         1      2      5      4
>>1         1      3      3      6
>>1         1      4      2      2
>>1         1      5      5      3
>>........
>>
>>I realize that merge appears to be the proper tool but there is no
>> documentation for how to merge by multiple columns.  Is this possible?
>>
>>Thanks in advance for any assistance with the problem.
>>
>>
>>--
>>Cheers,
>>
>>Patrick
>>
>>
>>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>> r-help mailing list -- Read
>> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help", or
>> "[un]subscribe"
>>(in the "body", not the subject !)  To:
>> r-help-request at stat.math.ethz.ch
>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>>


--
Cheers,

Patrick


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Oct  8 23:15:32 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Oct 2002 23:15:32 +0200
Subject: [R] repeated measures help; disagreement with SPSS
In-Reply-To: <m38z18hfq8.fsf@viz.itd.nrl.navy.mil>
References: <m38z18hfq8.fsf@viz.itd.nrl.navy.mil>
Message-ID: <x23crgljij.fsf@biostat.ku.dk>

Greg Trafton <trafton at itd.nrl.navy.mil> writes:

> > summary(aov(rl ~ cond * session + Error(subj/(session)), data=mig))
> 
> Error: subj
>           Df Sum Sq Mean Sq F value Pr(>F)
> cond       2 28.305  14.153  1.9916 0.2311
> Residuals  5 35.531   7.106               
> 
> Error: subj:session
>              Df  Sum Sq Mean Sq F value  Pr(>F)  
> session       2  4.4502  2.2251  2.9868 0.09616 .
> cond:session  4 17.7335  4.4334  5.9509 0.01024 *
> Residuals    10  7.4499  0.7450                  
> ---
> Signif. codes:  0  `***'  0.001  `**'  0.01  `*'  0.05  `.'  0.1  ` '  1 
> 
> (I ran this one this way b/c of a similar example from Baron's "Notes
> for psychology experiments.  Unfortunately, neither the session nor
> the interaction cond:session are the same as SPSS's output, though the
> degrees of freedom are correct in both, of course).
> 
> I'm certainly able to believe that SPSS is wrong and R is right, but
> thought I'd check with this list to make sure I'm not doing something
> completely stupid...

This is consistent with both lm() (using subj as a systematic effect)
and lme(), so I'd strongly suspect that SPSS is getting it wrong. What
does SPSS give?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Oct  8 23:37:40 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 8 Oct 2002 14:37:40 -0700 (PDT)
Subject: [R] data.frame merge matching several columns
In-Reply-To: <62068.128.196.98.70.1034101055.squirrel@192.168.0.2>
Message-ID: <Pine.A41.4.44.0210081435510.73908-100000@homer36.u.washington.edu>

On Tue, 8 Oct 2002, Patrick E. McKnight wrote:

> Greetings,
>
> Is it possible to match several columns in a merge statement?  Here is my
> problem:
>
> data1 looks like this...
>
> SUBID  TARGID  ITEM  RATING
> 1         1      1      4
> 1         1      2      5
> 1         1      3      3
> 1         1      4      2
> 1         1      5      5
> ......
>
> SUBID is the ID for the raters, TARGID is the ID for the targets being
> rated, ITEM ranges from 1 to 64 crossed by TARGID (i.e., all targets were
> rated on 64 items), and RATING is the rating given by SUBID for each
> TARGID and ITEM.
>
> My second dataset looks like this data2:
>
> TARGID  ITEM  TARGET
> 1        1      5
> 1        2      4
> 1        3      6
> 1        4      2
> 1        5      3
> .......
>
> TARGID again is the target's ID, ITEM ranges from 1 to 64, and TARGET is
> the rating provided by the target.
>
> I would like to merge these two data.frames by TARGID and ITEM to yield
> the following structure:
>
> SUBID  TARGID  ITEM  RATING  TARGET
> 1         1      1      4      5
> 1         1      2      5      4
> 1         1      3      3      6
> 1         1      4      2      2
> 1         1      5      5      3
> ........
>
> I realize that merge appears to be the proper tool but there is no
> documentation for how to merge by multiple columns.  Is this possible?
>

Yes. help(merge) says "By default the data frames are merged on the
columns with names they both have," which handles your example.

You could also do
  merge(x,y,by=c("TARGID","ITEM")
to specify the columns explicitly.

	-thomas







-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Tue Oct  8 23:41:50 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 08 Oct 2002 16:41:50 -0500
Subject: [R] Orthogonal Polynomials
In-Reply-To: <58CAB2332C0DD511BC7900A0C9EA316D013D1719@dasmtyjqf009.amedd.army.mil>
References: <58CAB2332C0DD511BC7900A0C9EA316D013D1719@dasmtyjqf009.amedd.army.mil>
Message-ID: <6ry99838wx.fsf@bates3.stat.wisc.edu>

"Bliese, Paul D MAJ WRAIR-Wash DC" <Paul.Bliese at NA.AMEDD.ARMY.MIL> writes:

> Looking to the wonderful statistical advice that this group can offer.
> 
> In behavioral science applications of stats, we are often introduced to
> coefficients for orthogonal polynomials that are nice integers.  For
> instance, Kirk's experimental design book presents the following
> coefficients for p=4:
> 
> Linear     -3 -1  1  3
> Quadratic   1 -1 -1  1
> Cubic      -1  3 -3  1
> 
> In R orthogonal polynomials are not integers. For instance, in R where p =4:
> 
> > poly(c(1:4),3)
>               1    2          3
> [1,] -0.6708204  0.5 -0.2236068
> [2,] -0.2236068 -0.5  0.6708204
> [3,]  0.2236068 -0.5 -0.6708204
> [4,]  0.6708204  0.5  0.2236068
> 
> Where, of course, column 1 is linear, column 2 Quadratic and 3 cubic.
> 
> My experience is that the coding scheme used in R works "better" than the
> integer scheme discussed in Kirk for many regression type analyses.
> 
> Can anyone enlighten me as to why?

I think the only difference is that the columns in the orthogonal
polynomial representation in R are scaled to have unit length.  The
rows in the table you give from Kirk's book have lengths sqrt(20), 2,
and sqrt(20) respectively so

> poly(1:4,3)*sqrt(20)
      1         2  3
[1,] -3  2.236068 -1
[2,] -1 -2.236068  3
[3,]  1 -2.236068 -3
[4,]  3  2.236068  1

gives you the first and third rows from Kirk in the first and third
columns.

Although there is some slight numerical advantage in having the
columns of a model matrix of comparable length I don't think it would
be noticeable here.





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Oct  9 00:27:00 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Oct 2002 00:27:00 +0200
Subject: [R] repeated measures help; disagreement with SPSS
In-Reply-To: <m34rbwhae8.fsf@viz.itd.nrl.navy.mil>
References: <m38z18hfq8.fsf@viz.itd.nrl.navy.mil>
	<x23crgljij.fsf@biostat.ku.dk> <m34rbwhae8.fsf@viz.itd.nrl.navy.mil>
Message-ID: <x2y998k1mz.fsf@biostat.ku.dk>

Greg Trafton <trafton at itd.nrl.navy.mil> writes:

> Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:
> 
> > Greg Trafton <trafton at itd.nrl.navy.mil> writes:
> >
> >> > summary(aov(rl ~ cond * session + Error(subj/(session)), data=mig))
> >> 
> >> Error: subj
> >>           Df Sum Sq Mean Sq F value Pr(>F)
> >> cond       2 28.305  14.153  1.9916 0.2311
> >> Residuals  5 35.531   7.106               
> >> 
> >> Error: subj:session
> >>              Df  Sum Sq Mean Sq F value  Pr(>F)  
> >> session       2  4.4502  2.2251  2.9868 0.09616 .
> >> cond:session  4 17.7335  4.4334  5.9509 0.01024 *
> >> Residuals    10  7.4499  0.7450                  
> >> ---
> >> Signif. codes:  0  `***'  0.001  `**'  0.01  `*'  0.05  `.'  0.1  ` '  1 
> >> 
> >> (I ran this one this way b/c of a similar example from Baron's "Notes
> >> for psychology experiments.  Unfortunately, neither the session nor
> >> the interaction cond:session are the same as SPSS's output, though the
> >> degrees of freedom are correct in both, of course).
> >> 
> >> I'm certainly able to believe that SPSS is wrong and R is right, but
> >> thought I'd check with this list to make sure I'm not doing something
> >> completely stupid...
> >
> > This is consistent with both lm() (using subj as a systematic effect)
> > and lme(), so I'd strongly suspect that SPSS is getting it wrong. What
> > does SPSS give?
> 
> OK, now I get to show off my ignorance of SPSS ;-) Perhaps I'm using
> it wrong, arg.
> 
> I'm including the spool file and a word copy of it (which looks pretty
> ugly):

Argh. You have no idea how difficult it is to read that stuff when
you're not on a Windows machine... But I suppose that converting it to
plain text is a pain even *on* Windows.

Anyways, as far as I can see, you are in fact getting the same
interaction test (RL*COND, Sphericity Assumed, Type III SS=17.734), so
I'd suspect that the test for the main effect is one of those weird
things where  you take the average over the three levels of cond,
ignoring the fact that one level occurs twice as often as the others.

What happens if you run the SPSS analysis without the interaction term? 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hjm at tacgi.com  Wed Oct  9 00:56:13 2002
From: hjm at tacgi.com (Harry Mangalam)
Date: Tue, 08 Oct 2002 15:56:13 -0700
Subject: [R] Removal of temp files in R 1.60 with xgobi - reversable?
References: <f04320406b9c86ab5dee1@[134.226.180.106]>
Message-ID: <3DA3628D.6090500@tacgi.com>

 From the NEWS file for R 1.60:

Each R session uses a per-session temporary directory which
	is removed at normal termination.  The directory name is given
	by the tempdir() function, and filenames returned by
	tempfile() will be within that directory.

Is there any way to maintain these temporary files?  I use R to generate output 
files that  are viewable with the xgobi package which has a 'keep' option to 
maintain temporary files, but this seems to be overridden in R itself.

It worked OK with R up to 1.51, I think.

I'd actually like to be able to specify the entire temp directory as well since 
I have to generate this directory anyway.


-- 
Cheers, Harry
Harry J Mangalam - 949 856 2847 (v&f) - hjm at tacgi.com (primary)
                 <<plain text much appreciated>>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andys at neptuneinc.org  Wed Oct  9 01:15:48 2002
From: andys at neptuneinc.org (Andrew Schuh)
Date: Tue, 8 Oct 2002 17:15:48 -0600
Subject: [R] plotting questions
Message-ID: <200210081715.48975.andys@neptuneinc.org>

I'm having some issues with using chron() objects for the x-axis in plots.

#########
plot(chron(c("07/01/01","08/01/02")),c(100,200),cex.axis=5)
#########

It doesn't seem to scale up the cex of the x-axis.  Is there any way to scale 
these x-axis labels up?

Also, I'm not sure but I don't believe I have even seen this behavior. 

#############
plot(chron(c("07/01/01","08/01/02")),c(100,200),cex.axis=5)
points(chron(c("07/01/01","08/01/02","12/01/01")),c(100,200,150),type="b")
#############

It could be me but I think points() had always sorted the values before 
connecting the points with lines?
 
I'm working with R1.6 on Redhat 7.3(i386). 
-- 
Sincerely,

+++++++++++*******+++++***++*
Andrew Schuh
Environmental Mathematician
Neptune and Co.
(505) 884-8455
andys at neptuneinc.org
+++++++++++*******+++++***++*
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Oct  9 01:55:20 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 8 Oct 2002 16:55:20 -0700 (PDT)
Subject: [R] Numeric to factor
In-Reply-To: <Pine.LNX.4.44.0210082128370.24747-100000@tal.stat.umu.se>
Message-ID: <Pine.A41.4.44.0210081649030.73908-100000@homer36.u.washington.edu>

On Tue, 8 Oct 2002, [iso-8859-1] Gran Brostrm wrote:

> I find 'How do I convert factors to numeric?' in the FAQ (7.12), but not
> the other way around. Trivial maybe, but
>
> > codes(factor(c(2, 10))
> [1] 2 1
> > codes(factor(c(2, 9)))
> [1] 1 2
>
> How do I get the levels attached to the codes in numeric order?
>

The short answer is that you don't. If you care about the order of the
codes then you have an ordered factor
>  codes(ordered(c(2, 10)))
[1] 1 2
>  codes(ordered(c(2, 9)))
[1] 1 2

As the code for codes.factor is
function (x, ...)
{
    rank(levels(x))[x]
}
you can't change the order from the default, lexicographic order.

Perhaps your problem is that you think codes() means something (eg the
numbers used internally to code the factor).

This may be illuminating:
> unclass(factor(c(2,9)))
[1] 1 2
attr(,"levels")
[1] "2" "9"
> unclass(factor(c(2,10)))
[1] 1 2
attr(,"levels")
[1] "2"  "10"
> as.integer(factor(c(2,9)))
[1] 1 2
> as.integer(factor(c(2,10)))
[1] 1 2
>

	-thomas



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Paul.Bliese at NA.AMEDD.ARMY.MIL  Wed Oct  9 02:56:47 2002
From: Paul.Bliese at NA.AMEDD.ARMY.MIL (Bliese, Paul D MAJ WRAIR-Wash DC)
Date: Tue, 8 Oct 2002 20:56:47 -0400 
Subject: [R] Summary Orthogonal Polynomials
Message-ID: <58CAB2332C0DD511BC7900A0C9EA316D013D171A@dasmtyjqf009.amedd.army.mil>

As usual, the R newsgroup set me straight (thanks to Douglas Bates, Robert
Balshaw and Albyn Jones).

There is really no difference between using orthogonal polynomials of the
form:

Linear     -3 -1  1  3 
Quadratic   1 -1 -1  1 
Cubic      -1  3 -3  1 

Versus

> poly(c(1:4),3) 
              1    2          3 
[1,] -0.6708204  0.5 -0.2236068 
[2,] -0.2236068 -0.5  0.6708204 
[3,]  0.2236068 -0.5 -0.6708204 
[4,]  0.6708204  0.5  0.2236068 


My observation that different coding schemes yielded different results was
based upon a colleague's analysis of some data (though the jumping to the
wrong conclusion was my own doing).  The newsgroup's responses motivated me
to run my own comparisons in R, and of course the coding scheme doesn't make
a bit of difference.

The reason why the contrasts look different is that R is rescaling the
variables to have unit length.  The unit length of the first row, for
instance is 20, so R divides -3, -1, 1, 3 by sqrt(20) and returns:

> c(-3,-1,1,3)/sqrt(20)
[1] -0.6708204 -0.2236068  0.2236068  0.6708204

Paul Bliese
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From trafton at itd.nrl.navy.mil  Wed Oct  9 03:18:33 2002
From: trafton at itd.nrl.navy.mil (Greg Trafton)
Date: Tue, 08 Oct 2002 21:18:33 -0400
Subject: [R] repeated measures help; disagreement with SPSS
In-Reply-To: <x2y998k1mz.fsf@biostat.ku.dk> (Peter Dalgaard BSA's message of
 "09 Oct 2002 00:27:00 +0200")
References: <m38z18hfq8.fsf@viz.itd.nrl.navy.mil>
	<x23crgljij.fsf@biostat.ku.dk> <m34rbwhae8.fsf@viz.itd.nrl.navy.mil>
	<x2y998k1mz.fsf@biostat.ku.dk>
Message-ID: <m3y9985s0m.fsf@viz.itd.nrl.navy.mil>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> Argh. You have no idea how difficult it is to read that stuff when
> you're not on a Windows machine... But I suppose that converting it to
> plain text is a pain even *on* Windows.

My apologies.  I hate the program and environment too, which is one of
the reasons I'm trying to change ;-)

> Anyways, as far as I can see, you are in fact getting the same
> interaction test (RL*COND, Sphericity Assumed, Type III SS=17.734), so
> I'd suspect that the test for the main effect is one of those weird
> things where  you take the average over the three levels of cond,
> ignoring the fact that one level occurs twice as often as the others.
>
> What happens if you run the SPSS analysis without the interaction term? 

YES!  You were exactly right.  I tried to change the model in SPSS,
but it wouldn't let me in that case (it always includes the
interaction, grumble).  so I made every condition have the same
number of data points.  and that showed up as the exact same set of
numbers in SPSS and R (whew!):  same p values, same SS, MS, etc.

OK, so the next question is, I understand your reasoning about the
weird thing, but which one *should* I use, the weighted version (like
R) or the unweighted (like SPSS)?  (realistically, this probably
doesn't happen too much, and certainly not to this degree, so it
probably doesn't have much of a profound effect in any case).  This is
probably not the right place for this question, but ...

thanks a ton for your help!

greg
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bill.Venables at cmis.csiro.au  Wed Oct  9 06:38:31 2002
From: Bill.Venables at cmis.csiro.au (Bill.Venables@cmis.csiro.au)
Date: Wed, 9 Oct 2002 14:38:31 +1000 
Subject: [R] Summary Orthogonal Polynomials
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A9165528@Roper-CV.qld.cmis.csiro.au>

I agree that it doesn't matter a damn what coding you use, but sometimes it
is useful to look at an integer version of the contrast matrix just to see
what's going on.  This is useful for teaching.  Here is the way I have done
it in the past using a function from the MASS library.  Not automatic, but
this is not the kind of thing you need to do every day...  I have trimmed
the output a bit to make it more readable, too.

> library(MASS)
> X <- poly(1:8, 5)
> dim(X)
[1] 8 5

> fractions(X/rep(X[1, ], each=nrow(X)))  # gets rid of surds.
         1     2     3     4     5    
[1,]     1     1     1     1     1
[2,]   5/7   1/7  -5/7 -13/7 -23/7
[3,]   3/7  -3/7    -1  -3/7  17/7
[4,]   1/7  -5/7  -3/7   9/7  15/7
[5,]  -1/7  -5/7   3/7   9/7 -15/7
[6,]  -3/7  -3/7     1  -3/7 -17/7
[7,]  -5/7   1/7   5/7 -13/7  23/7
[8,]    -1     1    -1     1    -1

> fractions(X/rep(X[1, ], each = nrow(X)))*7
       1   2   3   4   5  
[1,]   7   7   7   7   7
[2,]   5   1  -5 -13 -23
[3,]   3  -3  -7  -3  17
[4,]   1  -5  -3   9  15
[5,]  -1  -5   3   9 -15
[6,]  -3  -3   7  -3 -17
[7,]  -5   1   5 -13  23
[8,]  -7   7  -7   7  -7

In fact I find fractions() useful for a lot of things, somewhat to my
surprise.

Bill Venables.


-----Original Message-----
From: Bliese, Paul D MAJ WRAIR-Wash DC
[mailto:Paul.Bliese at NA.AMEDD.ARMY.MIL]
Sent: Wednesday, October 09, 2002 10:57 AM
To: 'r-help at stat.math.ethz.ch'
Subject: [R] Summary Orthogonal Polynomials


As usual, the R newsgroup set me straight (thanks to Douglas Bates, Robert
Balshaw and Albyn Jones).

There is really no difference between using orthogonal polynomials of the
form:

Linear     -3 -1  1  3 
Quadratic   1 -1 -1  1 
Cubic      -1  3 -3  1 

Versus

> poly(c(1:4),3) 
              1    2          3 
[1,] -0.6708204  0.5 -0.2236068 
[2,] -0.2236068 -0.5  0.6708204 
[3,]  0.2236068 -0.5 -0.6708204 
[4,]  0.6708204  0.5  0.2236068 


My observation that different coding schemes yielded different results was
based upon a colleague's analysis of some data (though the jumping to the
wrong conclusion was my own doing).  The newsgroup's responses motivated me
to run my own comparisons in R, and of course the coding scheme doesn't make
a bit of difference.

The reason why the contrasts look different is that R is rescaling the
variables to have unit length.  The unit length of the first row, for
instance is 20, so R divides -3, -1, 1, 3 by sqrt(20) and returns:

> c(-3,-1,1,3)/sqrt(20)
[1] -0.6708204 -0.2236068  0.2236068  0.6708204

Paul Bliese
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chr.schulz at email.de  Wed Oct  9 07:57:45 2002
From: chr.schulz at email.de (chr.schulz@email.de)
Date: Wed, 9 Oct 2002 07:57:45 +0200
Subject: [R] sem (lisrel) - starting problems
Message-ID: <200210090557.g995vjX02422@mailgate5.cinetic.de>

hello john,

(1) Do you intend nemploy and sales to be indicators of compcar? If so, the arrows are going in the wrong direction.

..yes, is lamx1 etc. correct for this part  and lamy1 etc. for the latent y-variable ?

(2) A similar comment applies to sex and age as indicators of personcar, but it's hard to imagine that such a specification would make sense.

.....this is first  an easy example with my data , but why you think it is nonsense that age and sexual status are indicators for a latent variable personalCharacteristics  
(...of course the scale's should be approriate ?)


Many thanks for your comments !

christian


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Wed Oct  9 08:22:12 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 9 Oct 2002 08:22:12 +0200 (CEST)
Subject: [R] Numeric to factor
In-Reply-To: <Pine.A41.4.44.0210081649030.73908-100000@homer36.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0210090800580.26050-100000@tal.stat.umu.se>

On Tue, 8 Oct 2002, Thomas Lumley wrote:

> On Tue, 8 Oct 2002, [iso-8859-1] G?ran Brostr?m wrote:
>
> > I find 'How do I convert factors to numeric?' in the FAQ (7.12), but not
> > the other way around. Trivial maybe, but
> >
> > > codes(factor(c(2, 10))
> > [1] 2 1
> > > codes(factor(c(2, 9)))
> > [1] 1 2
> >
> > How do I get the levels attached to the codes in numeric order?
> >
>
> The short answer is that you don't. If you care about the order of the
> codes then you have an ordered factor
> >  codes(ordered(c(2, 10)))
> [1] 1 2
> >  codes(ordered(c(2, 9)))
> [1] 1 2
>
> As the code for codes.factor is
> function (x, ...)
> {
>     rank(levels(x))[x]
> }
> you can't change the order from the default, lexicographic order.
>
> Perhaps your problem is that you think codes() means something (eg the
> numbers used internally to code the factor).

Yes. I thought I would get the internal codes, as for an ordered factor.
In fact, I wasn't interested in factors per se; my problem is that I have
a data frame with one column of IDs (each nine digits long), and I want
new IDs numbered 1, 2, 3, ...., preserving the original order. The reason
for that is that I then can index other variables with the IDs and write
some smart functions. I tried

> new.id <- codes(factor(old.id))

but  discovered that order (the one I wanted)was not preserved. As some
respondents have explained,

> new.id <- as.integer(factor(old.id))

does the trick (BTW, is this the best way to do what I want?).
Thanks to all who responded.

G?ran

>
> This may be illuminating:
> > unclass(factor(c(2,9)))
> [1] 1 2
> attr(,"levels")
> [1] "2" "9"
> > unclass(factor(c(2,10)))
> [1] 1 2
> attr(,"levels")
> [1] "2"  "10"
> > as.integer(factor(c(2,9)))
> [1] 1 2
> > as.integer(factor(c(2,10)))
> [1] 1 2
> >
>
> 	-thomas
>
>
>

---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Wed Oct  9 08:29:17 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 09 Oct 2002 08:29:17 +0200
Subject: [R] plotting questions
References: <200210081715.48975.andys@neptuneinc.org>
Message-ID: <3DA3CCBD.FA60E456@statistik.uni-dortmund.de>

Andrew Schuh wrote:
> 
> I'm having some issues with using chron() objects for the x-axis in plots.
> 
> #########
> plot(chron(c("07/01/01","08/01/02")),c(100,200),cex.axis=5)
> #########
> 
> It doesn't seem to scale up the cex of the x-axis.  Is there any way to scale
> these x-axis labels up?

I'd call it a bug in the method plot.times().
You can get around it with

 par(cex.axis = 5)
 plot(chron(c("07/01/01", "08/01/02")), c(100,200))


> Also, I'm not sure but I don't believe I have even seen this behavior.
> 
> #############
> plot(chron(c("07/01/01","08/01/02")),c(100,200),cex.axis=5)
> points(chron(c("07/01/01","08/01/02","12/01/01")),c(100,200,150),type="b")
> #############
> 
> It could be me but I think points() had always sorted the values before
> connecting the points with lines?

Really? I think not since I am using R (version 0.63.0 ?) ;-)

> I'm working with R1.6 on Redhat 7.3(i386).

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct  9 08:28:57 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 9 Oct 2002 07:28:57 +0100 (BST)
Subject: [R] Orthogonal Polynomials
In-Reply-To: <58CAB2332C0DD511BC7900A0C9EA316D013D1719@dasmtyjqf009.amedd.army.mil>
Message-ID: <Pine.LNX.4.31.0210090723470.18522-100000@gannet.stats>

The difference is just normalization (and that the tables are transposed
in your example).  That is, R uses orthonormal polynomials, and tables of
orthogonal polynomials also have normalizing coefficients.

Normalization should not affect the least-squares fitting, but it does
make interpretation of the coefficients easier.

On Tue, 8 Oct 2002, Bliese, Paul D MAJ WRAIR-Wash DC wrote:

> Looking to the wonderful statistical advice that this group can offer.
>
> In behavioral science applications of stats, we are often introduced to
> coefficients for orthogonal polynomials that are nice integers.  For
> instance, Kirk's experimental design book presents the following
> coefficients for p=4:
>
> Linear     -3 -1  1  3
> Quadratic   1 -1 -1  1
> Cubic      -1  3 -3  1
>
> In R orthogonal polynomials are not integers. For instance, in R where p =4:
>
> > poly(c(1:4),3)
>               1    2          3
> [1,] -0.6708204  0.5 -0.2236068
> [2,] -0.2236068 -0.5  0.6708204
> [3,]  0.2236068 -0.5 -0.6708204
> [4,]  0.6708204  0.5  0.2236068
>
> Where, of course, column 1 is linear, column 2 Quadratic and 3 cubic.
>
> My experience is that the coding scheme used in R works "better" than the
> integer scheme discussed in Kirk for many regression type analyses.
>
> Can anyone enlighten me as to why?
>
> Thanks,
>
> Paul Bliese
> Walter Reed Army Institute of Research
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct  9 08:40:35 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 9 Oct 2002 07:40:35 +0100 (BST)
Subject: [R] Removal of temp files in R 1.60 with xgobi - reversable?
In-Reply-To: <3DA3628D.6090500@tacgi.com>
Message-ID: <Pine.LNX.4.31.0210090734580.18522-100000@gannet.stats>

The issue seems to me that you are using the temporary directory for
files which you don't want to be temporary. Answer: don't use the
temporary directory!

xgobi(keep=TRUE) keeps files after the xgobi() function terminates, but
only for the duration of the R session.  So you can easily copy them
somewhere permanent. If that isn't sufficient for you, alter the
following line in the xgobi function:

    dfile <- tempfile(paste(fprefix, abbreviate(gsub("[^A-Za-z0-9]",
        "", title), 5), sep = ""))

not to use tempfile.

On Tue, 8 Oct 2002, Harry Mangalam wrote:

>  From the NEWS file for R 1.60:
>
> Each R session uses a per-session temporary directory which
> 	is removed at normal termination.  The directory name is given
> 	by the tempdir() function, and filenames returned by
> 	tempfile() will be within that directory.
>
> Is there any way to maintain these temporary files?  I use R to generate output
> files that  are viewable with the xgobi package which has a 'keep' option to
> maintain temporary files, but this seems to be overridden in R itself.
>
> It worked OK with R up to 1.51, I think.
>
> I'd actually like to be able to specify the entire temp directory as well since
> I have to generate this directory anyway.
>
>
> --
> Cheers, Harry
> Harry J Mangalam - 949 856 2847 (v&f) - hjm at tacgi.com (primary)
>                  <<plain text much appreciated>>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kwan022 at stat.auckland.ac.nz  Wed Oct  9 09:23:27 2002
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 9 Oct 2002 20:23:27 +1300 (NZDT)
Subject: [R] Multiplication of Matrices
Message-ID: <Pine.SOL.4.21.0210092021390.12082-100000@stat1.stat.auckland.ac.nz>

Hi,

Suppose I have a matrix, A.  Is there an easy way to find A^{n}?

I mean, I can do something like:
  A %*% A %*% A %*% A
for A^4, but if I want A^{10} it would be kind of annoying...

Cheers,

Kevin

------------------------------------------------------------------------------
Ko-Kang Kevin Wang
Postgraduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dominik.grathwohl at rdls.nestle.com  Wed Oct  9 10:28:44 2002
From: dominik.grathwohl at rdls.nestle.com (Grathwohl,Dominik,LAUSANNE,NRC/NT)
Date: Wed, 9 Oct 2002 10:28:44 +0200 
Subject: [R] proc mixed vs. lme
Message-ID: <89466355CEFE7244AC3A013E45641C18949557@lsmail2.crn.nestrd.ch>

Dear All,

Comparing linear mixed effect models in SAS and R, I found the following
discrepancy:

                            SAS                           R
random statement            random subj(program);         random = ~ 1 |
Subj
-2*loglik                   1420.8                        1439.363
random effects
variance(Intercept)         9.6033                        9.604662
variance(residual)          1.1969                        1.187553
the first 3 fixed effects
intercept                   83.0952                       81.10544
ProgramCont                -3.4952                       -1.11526
ProgramRI                  -1.9702                       -1.04517
...                        ...                            ...

Can somebody explain me this different results?

thanks in advance,

Dominik



The two examples can be found in the internet:
http://ftp.sas.com/samples and http://cran.r-project.org

#My work around:

> R.version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.0            
year     2002           
month    10             
day      01             
language R

#The SAS code from "http://ftp.sas.com/samples/A55235":

data weights;
   input subj program$ s1 s2 s3 s4 s5 s6 s7;
   datalines;
 1      CONT      85    85    86    85    87    86    87
 2      CONT      80    79    79    78    78    79    78
 3      CONT      78    77    77    77    76    76    77
 4      CONT      84    84    85    84    83    84    85
 5      CONT      80    81    80    80    79    79    80
 6      CONT      76    78    77    78    78    77    74
 7      CONT      79    79    80    79    80    79    81
 8      CONT      76    76    76    75    75    74    74
 9      CONT      77    78    78    80    80    81    80
10      CONT      79    79    79    79    77    78    79
11      CONT      81    81    80    80    80    81    82
12      CONT      77    76    77    78    77    77    77
13      CONT      82    83    83    83    84    83    83
14      CONT      84    84    83    82    81    79    78
15      CONT      79    81    81    82    82    82    80
16      CONT      79    79    78    77    77    78    78
17      CONT      83    82    83    85    84    83    82
18      CONT      78    78    79    79    78    77    77
19      CONT      80    80    79    79    80    80    80
20      CONT      78    79    80    81    80    79    80
 1      RI        79    79    79    80    80    78    80
 2      RI        83    83    85    85    86    87    87
 3      RI        81    83    82    82    83    83    82
 4      RI        81    81    81    82    82    83    81
 5      RI        80    81    82    82    82    84    86
 6      RI        76    76    76    76    76    76    75
 7      RI        81    84    83    83    85    85    85
 8      RI        77    78    79    79    81    82    81
 9      RI        84    85    87    89    88    85    86
10      RI        74    75    78    78    79    78    78
11      RI        76    77    77    77    77    76    76
12      RI        84    84    86    85    86    86    86
13      RI        79    80    79    80    80    82    82
14      RI        78    78    77    76    75    75    76
15      RI        78    80    77    77    75    75    75
16      RI        84    85    85    85    85    83    82
 1      WI        84    85    84    83    83    83    84
 2      WI        74    75    75    76    75    76    76
 3      WI        83    84    82    81    83    83    82
 4      WI        86    87    87    87    87    87    86
 5      WI        82    83    84    85    84    85    86
 6      WI        79    80    79    79    80    79    80
 7      WI        79    79    79    81    81    83    83
 8      WI        87    89    91    90    91    92    92
 9      WI        81    81    81    82    82    83    83
10      WI        82    82    82    84    86    85    87
11      WI        79    79    80    81    81    81    81
12      WI        79    80    81    82    83    82    82
13      WI        83    84    84    84    84    83    83
14      WI        81    81    82    84    83    82    85
15      WI        78    78    79    79    78    79    79
16      WI        83    82    82    84    84    83    84
17      WI        80    79    79    81    80    80    80
18      WI        80    82    82    82    81    81    81
19      WI        85    86    87    86    86    86    86
20      WI        77    78    80    81    82    82    82
21      WI        80    81    80    81    81    82    83
;
               
/*---Data Set 3.2(b)---*/

data weight2; 
   set weights;
   time=1; strength=s1; output;
   time=2; strength=s2; output;
   time=3; strength=s3; output;
   time=4; strength=s4; output;
   time=5; strength=s5; output;
   time=6; strength=s6; output;
   time=7; strength=s7; output;
   keep subj program time strength;
run;
    
proc sort data=weight2; 
   by program time;
run;


/*---Data Set 3.2(c)---*/

proc means data=weight2 noprint; 
   by program time; 
   var strength;
   output out=avg mean=strength;
run;
               
               
/*---produces Output 3.1 on pages 91-92---*/

proc mixed data=weight2;
   class program subj time;
   model strength = program time program*time /s;
   random subj(program);
run;



#The SAS results:

                                      Covariance Parameter
                                            Estimates

                                    Cov Parm          Estimate

                                    subj(program)       9.6033
                                    Residual            1.1969

                                      The Mixed Procedure

                                         Fit Statistics

                              -2 Res Log Likelihood          1420.8
                              AIC (smaller is better)        1424.8
                              AICC (smaller is better)       1424.9
                              BIC (smaller is better)        1428.9


                                    Solution for Fixed Effects

                                                     Standard
      Effect          program    time    Estimate       Error      DF    t
Value    Pr > |t|

      Intercept                           83.0952      0.7171      54
115.87      <.0001
      program         CONT                -3.4952      1.0268      54
-3.40      0.0013
      program         RI                  -1.9702      1.0906      54
-1.81      0.0764
      program         WI                        0           .       .
.         .
      time                       1        -2.0476      0.3376     324
-6.06      <.0001
      time                       2        -1.4286      0.3376     324
-4.23      <.0001
      time                       3        -1.1905      0.3376     324
-3.53      0.0005
      time                       4        -0.5714      0.3376     324
-1.69      0.0915
      time                       5        -0.4762      0.3376     324
-1.41      0.1594
      time                       6        -0.3810      0.3376     324
-1.13      0.2600
      time                       7              0           .       .
.         .
      program*time    CONT       1         2.1976      0.4834     324
4.55      <.0001
      program*time    CONT       2         1.7786      0.4834     324
3.68      0.0003
      program*time    CONT       3         1.5905      0.4834     324
3.29      0.0011
      program*time    CONT       4         1.0214      0.4834     324
2.11      0.0354
      program*time    CONT       5         0.6762      0.4834     324
1.40      0.1628
      program*time    CONT       6         0.3810      0.4834     324
0.79      0.4312
      program*time    CONT       7              0           .       .
.         .
      program*time    RI         1         0.6101      0.5134     324
1.19      0.2356
      program*time    RI         2         0.8661      0.5134     324
1.69      0.0926
      program*time    RI         3         0.8780      0.5134     324
1.71      0.0882
      program*time    RI         4         0.4464      0.5134     324
0.87      0.3852
      program*time    RI         5         0.6012      0.5134     324
1.17      0.2425
      program*time    RI         6         0.3810      0.5134     324
0.74      0.4586
      program*time    RI         7              0           .       .
.         .
      program*time    WI         1              0           .       .
.         .
      program*time    WI         2              0           .       .
.         .
      program*time    WI         3              0           .       .
.         .
      program*time    WI         4              0           .       .
.         .
      program*time    WI         5              0           .       .
.         .
      program*time    WI         6              0           .       .
.         .
      program*time    WI         7              0           .       .
.         .



#The R code:

library(nlme)
library(SASmixed)
options( contrasts = c(unordered = "contr.SAS", ordered = contr.poly")) 
data(Weights) 
fm1Weight <- lme( strength ~ Program * Time, data = Weights, random = ~ 1 |
Subj) 
summary( fm1Weight )
VarCorr( fm1Weight ) 



#The R results:

> summary( fm1Weight )               
Linear mixed-effects model fit by REML
 Data: Weights 
       AIC      BIC    logLik
  1455.363 1487.153 -719.6815

Random effects:
 Formula: ~1 | Subj
        (Intercept) Residual
StdDev:    3.099139 1.089749

Fixed effects: strength ~ Program * Time 
                    Value Std.Error  DF   t-value p-value
(Intercept)      81.10544 0.7001315 339 115.84315  <.0001
ProgramCONT      -1.11526 1.0024358  54  -1.11255  0.2708
ProgramRI        -1.04517 1.0646834  54  -0.98168  0.3306
Time              0.15986 0.0224702 339   7.11447  <.0001
ProgramCONT:Time -0.18397 0.0321725 339  -5.71827  <.0001
ProgramRI:Time   -0.05495 0.0341703 339  -1.60822  0.1087
 Correlation: 
                 (Intr) PrCONT PrgrRI Time   PCONT:
ProgramCONT      -0.698                            
ProgramRI        -0.658  0.459                     
Time             -0.225  0.157  0.148              
ProgramCONT:Time  0.157 -0.225 -0.103 -0.698       
ProgramRI:Time    0.148 -0.103 -0.225 -0.658  0.459

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-3.11669139 -0.60963281  0.03963523  0.63074983  3.33520406 

Number of Observations: 399
Number of Groups: 57 

> VarCorr( fm1Weight )
Subj = pdLogChol(1) 
            Variance StdDev  
(Intercept) 9.604662 3.099139
Residual    1.187553 1.089749



Dominik Grathwohl 
Biostatistician 
Nestl? Research Center 
PO Box 44, CH-1000 Lausanne 26 
Phone: + 41 21 785 8034 
Fax: + 41 21 785 8556 
e-mail: dominik.grathwohl at rdls.nestle.com 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From philippe.grosjean at ifremer.fr  Wed Oct  9 10:35:45 2002
From: philippe.grosjean at ifremer.fr (Philippe Grosjean)
Date: Wed, 9 Oct 2002 10:35:45 +0200
Subject: [R] R 1.6.0 benchmark with and without optimized ATLAS
Message-ID: <MABBLJDICACNFOLGIHJOMEPACPAA.philippe.grosjean@ifremer.fr>

Hello,

I am updating my benchmark (http://www.sciviews.org/other/benchmark.htm) to
recent versions of data analysis software (including R 1.6.0 and Splus 6.1),
and I now run it on a Pentium IV instead of the old Celeron 500 Mhz that
candidates for retirement. I test R under Windows Xp pro with and without
optimized BLAS. I use the optimized Rblas.dll for P4 found on CRAN. Here are
the results. Beside the discussion of limited role of the benchmark and
cautions on its interpretation (see the benchmark web page where this is
developed), does anyone want to comment it. I would more particularly
appreciate comments on the differences between results with and without the
optimized BLAS library (cross-product is 3 times faster, but linear
regression and inverse are slower with the optimized BLAS).

Best,

Philippe

...........]<(({?<...............<?}))><...............................
( ( ( ( (
 ) ) ) ) )      Philippe Grosjean
( ( ( ( (
 ) ) ) ) )      IFREMER Nantes - DEL/AO
( ( ( ( (       rue de l'Ile d'Yeu, BP 21105, 44311 Nantes Cedex 3
 ) ) ) ) )      tel: (33) 02.40.37.42.29, fax: (33) 02.40.37.42.41
( ( ( ( (	e-mail: philippe.grosjean at ifremer.fr
 ) ) ) ) )
( ( ( ( (      "I'm 100% confident that p is between 0 and 1"
 ) ) ) ) )                                L. Gonick & W. Smith (1993)
.......................................................................


Benchmark on PIV 1.6 Ghz, 512 Mb Ram, Win Xp pro :
==================================================
note the code for the test is available on the web page
(see http://www.sciviews.org/other/benchmark.htm).

- R 1.6.0 with standard Rblas.dll

   R Benchmark
   ===========
Number of times each test is run__________________________:  3

   I. Matrix calculation
   ---------------------
Creation, transp., deformation of a 1200x1200 matrix (sec):
0.973333333333333
1250x1250 normal distributed random matrix ^1000____ (sec):
2.25333333333333
Sorting of 1,100,000 random values__________________ (sec):
0.463333333333335
550x550 cross-product matrix (b = a' * a)___________ (sec):
0.463333333333331
Linear regression over a 700x700 matrix (c = a \ b') (sec):  1.75
                      --------------------------------------------
                 Trimmed geom. mean (2 extremes eliminated):
0.924125732935107

   II. Matrix functions
   --------------------
FFT over 900,000 random values______________________ (sec):
1.53666666666667
Eigenvalues of a 220x220 random matrix______________ (sec):
0.466666666666669
Determinant of a 750x750 random matrix______________ (sec):  1.65
Cholesky decomposition of a 1000x1000 matrix________ (sec):
1.30333333333334
Inverse of a 500x500 random matrix__________________ (sec):
1.76000000000000
                      --------------------------------------------
                Trimmed geom. mean (2 extremes eliminated):
1.48949725041955

   III. Programmation
   ------------------
225,000 Fibonacci numbers calculation (vector calc)_ (sec):  0.25
Creation of a 1500x1500 Hilbert matrix (matrix calc) (sec):
0.49333333333333
Grand common divisors of 35,000 pairs (recursion)___ (sec):
0.539999999999997
Creation of a 220x220 Toeplitz matrix (loops)_______ (sec):
0.896666666666666
Escoufier's method on a 22x22 matrix (mixed)________ (sec):
0.159999999999997
                      --------------------------------------------
                Trimmed geom. mean (2 extremes eliminated):
0.405344927915484


Total time for all 15 tests_________________________ (sec):  14.96
Overall mean (sum of I, II and III trimmed means/3)_ (sec):
0.823250186027012
                      --- End of test ---


- R 1.6.0 with optimized Rblas.dll (P4 version)

   R Benchmark
   ===========
Number of times each test is run__________________________:  3

   I. Matrix calculation
   ---------------------
Creation, transp., deformation of a 1200x1200 matrix (sec):  0.98
1250x1250 normal distributed random matrix ^1000____ (sec):
2.25666666666667
Sorting of 1,100,000 random values__________________ (sec):
0.466666666666664
550x550 cross-product matrix (b = a' * a)___________ (sec):
0.156666666666669
Linear regression over a 700x700 matrix (c = a \ b') (sec):  2.03
                      --------------------------------------------
                 Trimmed geom. mean (2 extremes eliminated):
0.975535245596796

   II. Matrix functions
   --------------------
FFT over 900,000 random values______________________ (sec):  1.49
Eigenvalues of a 220x220 random matrix______________ (sec):
0.463333333333334
Determinant of a 750x750 random matrix______________ (sec):
1.32333333333333
Cholesky decomposition of a 1000x1000 matrix________ (sec):
1.15333333333333
Inverse of a 500x500 random matrix__________________ (sec):  1.98
                      --------------------------------------------
                Trimmed geom. mean (2 extremes eliminated):
1.31503341435566

   III. Programmation
   ------------------
225,000 Fibonacci numbers calculation (vector calc)_ (sec):  0.25
Creation of a 1500x1500 Hilbert matrix (matrix calc) (sec):
0.470000000000004
Grand common divisors of 35,000 pairs (recursion)___ (sec):
0.533333333333336
Creation of a 220x220 Toeplitz matrix (loops)_______ (sec):
0.906666666666666
Escoufier's method on a 22x22 matrix (mixed)________ (sec):
0.170000000000002
                      --------------------------------------------
                Trimmed geom. mean (2 extremes eliminated):
0.397202705684386


Total time for all 15 tests_________________________ (sec):  14.63
Overall mean (sum of I, II and III trimmed means/3)_ (sec):
0.798725071833925
                      --- End of test ---


- Splus 6.1 on the same computer

   Splus Benchmark
   ===============
Number of times each test is run__________________________:  3

   I. Matrix calculation
   ---------------------
Creation, transp., deformation of a 1200x1200 matrix (sec):
2.02266666666666
1250x1250 normal distributed random matrix ^1000____ (sec):
3.31466666666667
Sorting of 1,100,000 random values__________________ (sec):
1.22866666666666
550x550 cross-product matrix (b = a' * a)___________ (sec):
0.427666666666667
Linear regression over a 700x700 matrix (c = a \ b') (sec):
2.18966666666667
                      --------------------------------------------
                      Trimmed mean (2 extremes eliminated):
1.81366666666667

   II. Matrix functions
   --------------------
FFT over 900,000 random values______________________ (sec):  1.963
Eigenvalues of a 220x220 random matrix______________ (sec):
0.330333333333333
Determinant of a 750x750 random matrix______________ (sec):
0.670999999999997
Cholesky decomposition of a 1000x1000 matrix________ (sec):
2.76366666666667
Inverse of a 500x500 random matrix__________________ (sec):  2.644
                      --------------------------------------------
                      Trimmed mean (2 extremes eliminated):
1.75933333333333

   III. Programmation
   ------------------
225,000 Fibonacci numbers calculation (vector calc)_ (sec):
0.501000000000005
Creation of a 1500x1500 Hilbert matrix (matrix calc) (sec):
0.514000000000001
Grand common divisors of 35,000 pairs (recursion)___ (sec):
0.333666666666659
Creation of a 220x220 Toeplitz matrix (loops)_______ (sec):
6.71633333333334
Escoufier's method on a 22x22 matrix (mixed)________ (sec):  5.108
                      --------------------------------------------
                      Trimmed mean (2 extremes eliminated):  2.041


Total time for all 15 tests_________________________ (sec):
30.7283333333333
Overall mean (sum of I, II and III trimmed means/3)_ (sec):
1.87133333333333
                      --- End of test ---


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Tue Oct  8 21:51:29 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 9 Oct 2002 08:51:29 +1300
Subject: [R] Multiplication of Matrices
In-Reply-To: <Pine.SOL.4.21.0210092021390.12082-100000@stat1.stat.auckland.ac.nz>; from kwan022@stat.auckland.ac.nz on Wed, Oct 09, 2002 at 08:23:27PM +1300
References: <Pine.SOL.4.21.0210092021390.12082-100000@stat1.stat.auckland.ac.nz>
Message-ID: <20021009085129.A25932@camille.indigoindustrial.co.nz>

On Wed, Oct 09, 2002 at 08:23:27PM +1300, Ko-Kang Kevin Wang wrote:
> Suppose I have a matrix, A.  Is there an easy way to find A^{n}?

Jim Lindsey's package rmutil (Repeated Measures Utilities) has
the matrix exponential function mexp - very nice.

http://alpha.luc.ac.be/~jlindsey/rcode.html

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kwan022 at stat.auckland.ac.nz  Wed Oct  9 10:53:59 2002
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 9 Oct 2002 21:53:59 +1300 (NZDT)
Subject: [R] s.window in stl()
Message-ID: <Pine.SOL.4.21.0210092150290.21211-100000@stat1.stat.auckland.ac.nz>

Hi,

This is actually a theory question.

I'm a bit confused by the s.window parameter in the stl() function (which
is in the ts package).  For example, in the stl documentation it uses the
nottem data, and then:
  plot(stl(nottem, s.win = 4, t.win = 50, t.jump = 1))

What does it mean by s.win = 4?  Is it because a year has 4 seasons
(namely Spring, Summer, Autumn and Winter)?  If so will it make sense if I
use 12 for the 12 months (as I've got a similar data set, and wondering
about this s.window when I fit the data with stl()).

Cheers,

Kevin

------------------------------------------------------------------------------
Ko-Kang Kevin Wang
Postgraduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Wed Oct  9 13:18:09 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Wed, 9 Oct 2002 11:18:09 +0000
Subject: [R] Large F-value and small P-value
Message-ID: <15780.4209.609651.321735@hugo.paed.uni-muenchen.de>

Hi all,
I computed a Wilks Lambda Test with manova:

> df.man <- manova(df.mul ~ 1, na.rm=TRUE)

> summary(df.man, intercep=T, test="Wilks")
            Df     Wilks approx F num Df den Df  Pr(>F)  
(Intercept)  1 0.0002824    393.3      9      1 0.03911 *
Residuals    9                                           
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

I'm wondering about the very high F value and the comparative low p
value. 
 
Sven

The dataframe:

> df.mul
   Above_3 Above_45 Before_3 Before_45 Behind_3 Behind_45 Below_3 Below_45
am    0.19     0.40     0.09      0.07    -0.95     -0.35   -0.10     0.18
ik   -0.03     0.20     0.25      0.31    -0.12      0.16    0.40     0.35
jb   -0.21     0.29    -0.25     -0.10    -0.48      0.11    0.05     0.20
js    0.45     0.59    -0.07     -0.51    -0.15      0.55    0.14     0.22
ko    0.14     0.66     0.09      0.50     0.29      0.40   -0.03     0.27
mw    0.11     0.15    -0.10      0.00    -0.62      0.07   -0.52    -0.01
og   -0.92    -0.40    -2.43     -1.78    -1.94     -0.60   -1.25    -0.96
sb   -0.05     0.07    -0.12     -0.11    -0.26     -0.20    0.01    -0.16
sm   -1.12    -0.67    -1.30     -0.98    -1.36     -1.00   -0.60    -0.34
sw    0.11     0.31    -1.00      0.31    -0.96     -0.78   -0.61     0.12
   Blank
am  0.28
ik  0.29
jb  0.27
js  0.52
ko  0.63
mw  0.26
og -0.01
sb  0.33
sm  0.04
sw  1.05

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Oct  9 13:22:31 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Oct 2002 13:22:31 +0200
Subject: [R] Large F-value and small P-value
In-Reply-To: <15780.4209.609651.321735@hugo.paed.uni-muenchen.de>
References: <15780.4209.609651.321735@hugo.paed.uni-muenchen.de>
Message-ID: <x2smzfyhzc.fsf@biostat.ku.dk>

Sven Garbade <garbade at psy.uni-muenchen.de> writes:

> Hi all,
> I computed a Wilks Lambda Test with manova:
> 
> > df.man <- manova(df.mul ~ 1, na.rm=TRUE)
> 
> > summary(df.man, intercep=T, test="Wilks")
>             Df     Wilks approx F num Df den Df  Pr(>F)  
> (Intercept)  1 0.0002824    393.3      9      1 0.03911 *
> Residuals    9                                           
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> 
> I'm wondering about the very high F value and the comparative low p
> value. 

You mean large p, I suppose. 

You don't see F tests with 1 DF in the denominator every day.
Fisher+v.Belle lists the 95% quantile for F(9,1) as 240.5, so I
wouldn't worry...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct  9 13:27:27 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 9 Oct 2002 12:27:27 +0100 (GMT Daylight Time)
Subject: [R] Multiplication of Matrices
In-Reply-To: <Pine.SOL.4.21.0210092021390.12082-100000@stat1.stat.auckland.ac.nz>
Message-ID: <Pine.WNT.4.44.0210091223170.1076-100000@gannet.stats.ox.ac.uk>

On Wed, 9 Oct 2002, Ko-Kang Kevin Wang wrote:

> Suppose I have a matrix, A.  Is there an easy way to find A^{n}?
>
> I mean, I can do something like:
>   A %*% A %*% A %*% A
> for A^4, but if I want A^{10} it would be kind of annoying...

Use the eigendecomposition.  If A = V %*% diag(lam) %*% t(V), then
A^n = V %*% diag(lam^n) %*% t(V).  More care (including complex conjugates)
is needed if the eigendecomposition is complex, but the method still works.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dominik.grathwohl at rdls.nestle.com  Wed Oct  9 13:31:42 2002
From: dominik.grathwohl at rdls.nestle.com (Grathwohl,Dominik,LAUSANNE,NRC/NT)
Date: Wed, 9 Oct 2002 13:31:42 +0200 
Subject: [R] proc mixed vs. lme
Message-ID: <89466355CEFE7244AC3A013E45641C1894955A@lsmail2.crn.nestrd.ch>

Hallo Peter,

Thank you for the advice, now I have to update my table:

                            SAS                           R
random statement            random subj(program);         random = ~ 1 |
Subj
-2*loglik                   1420.8                        1420.820
random effects
variance(Intercept)         9.6033                        9.603331
variance(residual)          1.1969                        1.196873
the first 3 fixed effects
intercept                   83.0952                        83.09524
ProgramCont                -3.4952                       -3.49524
ProgramRI                  -1.9702                       -1.97024
...                        ...                            ...

Everything looks nice. Perhaps Douglas could update the help file in
SASmixed, 
where I copied the misleading code!

Kind regards,

Dominik

> -----Original Message-----
> From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> Sent: mercredi, 9. octobre 2002 12:37
> To: Grathwohl,Dominik,LAUSANNE,NRC/NT
> Subject: Re: [R] proc mixed vs. lme
> 
> 
> "Grathwohl,Dominik,LAUSANNE,NRC/NT" 
> <dominik.grathwohl at rdls.nestle.com> writes:
> 
> > Comparing linear mixed effect models in SAS and R, I found 
> the following
> > discrepancy:
> > 
> >                             SAS                           R
> > random statement            random subj(program);         
> random = ~ 1 |
> > Subj
> > -2*loglik                   1420.8                        1439.363
> > random effects
> > variance(Intercept)         9.6033                        9.604662
> > variance(residual)          1.1969                        1.187553
>  
> ...
> 
> 
> > #The R code:
> > 
> > library(nlme)
> > library(SASmixed)
> > options( contrasts = c(unordered = "contr.SAS", ordered = 
> contr.poly")) 
> > data(Weights) 
> > fm1Weight <- lme( strength ~ Program * Time, data = 
> Weights, random = ~ 1 |
> > Subj) 
> > summary( fm1Weight )
> > VarCorr( fm1Weight ) 
> 
> It helps considerably if you fit the same model! Try:
> 
> fm1Weight <- lme( strength ~ factor(Program) * factor(Time), 
>       data = Weights, random = ~ 1 | Subj) 
> 
> (or change the variables from numeric to factor inside Weights).
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: 
> (+45) 35327907
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Wed Oct  9 13:39:08 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 09 Oct 2002 07:39:08 -0400
Subject: [R] Multiplication of Matrices
In-Reply-To: <20021009085129.A25932@camille.indigoindustrial.co.nz>
References: <Pine.SOL.4.21.0210092021390.12082-100000@stat1.stat.auckland.ac.nz>
 <Pine.SOL.4.21.0210092021390.12082-100000@stat1.stat.auckland.ac.nz>
Message-ID: <5.1.0.14.2.20021009073811.01dafcd8@mcmail.cis.mcmaster.ca>

Dear Jason and Kevin,

At 08:51 AM 10/9/2002 +1300, Jason Turner wrote:
>On Wed, Oct 09, 2002 at 08:23:27PM +1300, Ko-Kang Kevin Wang wrote:
> > Suppose I have a matrix, A.  Is there an easy way to find A^{n}?
>
>Jim Lindsey's package rmutil (Repeated Measures Utilities) has
>the matrix exponential function mexp - very nice.
>
>http://alpha.luc.ac.be/~jlindsey/rcode.html

I haven't seen Jim Lindsey's function, but how about the following?

         mp <- function (X, p) if (p == 1) return(X) else X %*% Recall(X, p-1)

Regards,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Wed Oct  9 15:39:47 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Wed, 9 Oct 2002 13:39:47 +0000
Subject: [R] Large F-value and small P-value
In-Reply-To: <x2smzfyhzc.fsf@biostat.ku.dk>
References: <15780.4209.609651.321735@hugo.paed.uni-muenchen.de>
	<x2smzfyhzc.fsf@biostat.ku.dk>
Message-ID: <15780.12707.144995.859104@hugo.paed.uni-muenchen.de>

Peter Dalgaard BSA writes:
 > Sven Garbade <garbade at psy.uni-muenchen.de> writes:
 > 
 > > Hi all,
 > > I computed a Wilks Lambda Test with manova:
 > > 
 > > > df.man <- manova(df.mul ~ 1, na.rm=TRUE)
 > > 
 > > > summary(df.man, intercep=T, test="Wilks")
 > >             Df     Wilks approx F num Df den Df  Pr(>F)  
 > > (Intercept)  1 0.0002824    393.3      9      1 0.03911 *
 > > Residuals    9                                           
 > > ---
 > > Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
 > > 
 > > I'm wondering about the very high F value and the comparative low p
 > > value. 
 > 
 > You mean large p, I suppose. 

sorry... 

 > You don't see F tests with 1 DF in the denominator every day.
 > Fisher+v.Belle lists the 95% quantile for F(9,1) as 240.5, so I
 > wouldn't worry...

Yes, in the meantime I've found a F-table in a textbook.

Thanks!
Sven

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From arc at arcriswell.com  Thu Oct 10 01:42:56 2002
From: arc at arcriswell.com (Andrew Criswell)
Date: Thu, 10 Oct 2002 06:42:56 +0700
Subject: [R] Help with 
Message-ID: <002701c26fed$993a6af0$23d994cb@andrewvhowclyz>

Hello All:

I hope I can get someone interested in this problem:

Agresti in "Analysis of Categorical Data," p. 289, applies a "row and column
effects model" to analyze a two-dimensional cross-classification of ordinal
data.

He got his results in either SAS or GLIM. Is there a way to replicate his
results with R?

He claims the RC model fits well with G^2(RC) = 3.57 with df = 8.  The ML
estimates for the row scores are (-1.11, -1.12, -0.37, 0.03, 1.01, 1.82) and
the column estimates are (-1.68, -0.14, 0.14, 1.41) and beta = 0.17

Below, is the data:

tbl.0 <- expand.grid(SOCIO = letters[1:6],
                               MENTAL = c('well', 'mild', 'moderate',
'impaired))

COUNTS <- c( 64, 57, 57, 72, 36, 21,
                          94, 94, 105, 141, 97, 71,
                          58, 54, 65, 77, 54, 54,
                          46, 40, 60, 94, 78, 71)

data.0 <- data.frame(tbl.0, COUNTS)

Thanks,
ANDREW




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Wed Oct  9 13:43:03 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 09 Oct 2002 07:43:03 -0400
Subject: [R] sem (lisrel) - starting problems
In-Reply-To: <200210090557.g995vjX02422@mailgate5.cinetic.de>
Message-ID: <5.1.0.14.2.20021009073925.01dafab8@mcmail.cis.mcmaster.ca>

Dear Christian,

At 07:57 AM 10/9/2002 +0200, chr.schulz at email.de wrote:
>hello john,
>
>(1) Do you intend nemploy and sales to be indicators of compcar? If so, 
>the arrows are going in the wrong direction.
>
>..yes, is lamx1 etc. correct for this part  and lamy1 etc. for the latent 
>y-variable ?

I'm not sure that I follow. You can make up whatever parameter names you 
want, so certainly you can use lamx1 and lamy1. Note that  if two 
parameters have the same name then that implies an equality constraint; 
different names -- as here -- imply different parameters.

>(2) A similar comment applies to sex and age as indicators of personcar, 
>but it's hard to imagine that such a specification would make sense.
>
>.....this is first  an easy example with my data , but why you think it is 
>nonsense that age and sexual status are indicators for a latent variable 
>personalCharacteristics
>(...of course the scale's should be approriate ?)

I can't really tell without knowing what the variables are, but I usually 
think of something named "age" or "sex" as exogenous.

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From juli at ceam.es  Wed Oct  9 13:39:29 2002
From: juli at ceam.es (juli g. pausas)
Date: Wed, 09 Oct 2002 13:39:29 +0200
Subject: [R] log in barplot
Message-ID: <3DA41571.9F6280AC@ceam.es>

Hi,

In plot, axis can be in log format,  e.g.  plot(*, log="y")
Does a similar option exist for barplot ?

Thanks

Juli

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From susanabarbosa at novalis.fc.up.pt  Wed Oct  9 14:55:00 2002
From: susanabarbosa at novalis.fc.up.pt (Susana Barbosa)
Date: Wed, 9 Oct 2002 13:55:00 +0100
Subject: [R] s.window in stl()
In-Reply-To: <Pine.SOL.4.21.0210092150290.21211-100000@stat1.stat.auckland.ac.nz>
References: <Pine.SOL.4.21.0210092150290.21211-100000@stat1.stat.auckland.ac.nz>
Message-ID: <200210091251.g99CpPo00972@cafirewall.fc.up.pt>


Hi,

I think s.window is the span is lags of loess window. 
Loess centers a window for each time and fits a line by weighted 
least-squares (more weight is given to observations close to the middle of 
the window); the residual (vertical) distance from the line to each point in 
the window is determined. The outliers (points with large residuals) are then 
downweighted and the line is re-estimated; this process is iterated a few 
times. 

So with monthly data you don't have to use s.window=12 (and notice it must be 
odd!)

Hope it helps


Susana
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Wed Oct  9 15:31:47 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 09 Oct 2002 08:31:47 -0500
Subject: [R] Summary Orthogonal Polynomials
In-Reply-To: <E09E527B56BE2D438A3D6A246DDD27A9165528@Roper-CV.qld.cmis.csiro.au>
References: <E09E527B56BE2D438A3D6A246DDD27A9165528@Roper-CV.qld.cmis.csiro.au>
Message-ID: <6rwuorspq4.fsf@bates3.stat.wisc.edu>

Bill.Venables at CMIS.CSIRO.AU writes:

> I agree that it doesn't matter a damn what coding you use, but sometimes it
> is useful to look at an integer version of the contrast matrix just to see
> what's going on.  This is useful for teaching.  Here is the way I have done
> it in the past using a function from the MASS library.  Not automatic, but
> this is not the kind of thing you need to do every day...  I have trimmed
> the output a bit to make it more readable, too.
> 
> > library(MASS)
> > X <- poly(1:8, 5)
> > dim(X)
> [1] 8 5
> 
> > fractions(X/rep(X[1, ], each=nrow(X)))  # gets rid of surds.
>          1     2     3     4     5    
> [1,]     1     1     1     1     1
> [2,]   5/7   1/7  -5/7 -13/7 -23/7
> [3,]   3/7  -3/7    -1  -3/7  17/7
> [4,]   1/7  -5/7  -3/7   9/7  15/7
> [5,]  -1/7  -5/7   3/7   9/7 -15/7
> [6,]  -3/7  -3/7     1  -3/7 -17/7
> [7,]  -5/7   1/7   5/7 -13/7  23/7
> [8,]    -1     1    -1     1    -1
> 
> > fractions(X/rep(X[1, ], each = nrow(X)))*7
>        1   2   3   4   5  
> [1,]   7   7   7   7   7
> [2,]   5   1  -5 -13 -23
> [3,]   3  -3  -7  -3  17
> [4,]   1  -5  -3   9  15
> [5,]  -1  -5   3   9 -15
> [6,]  -3  -3   7  -3 -17
> [7,]  -5   1   5 -13  23
> [8,]  -7   7  -7   7  -7
> 
> In fact I find fractions() useful for a lot of things, somewhat to my
> surprise.

I did try fractions() on the example that Paul gave, poly(1:4, 3), and
the result is hard to interpret.

> fractions(poly(1:4, 3))
     1                2                3               
[1,] -5494877/8191279              1/2    -98209/439204
[2,]    -98209/439204             -1/2    208010/310083
[3,]    208010/930249             -1/2 -5494877/8191279
[4,]    208010/310083              1/2    208010/930249
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Wed Oct  9 15:35:01 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 09 Oct 2002 08:35:01 -0500
Subject: [R] proc mixed vs. lme
In-Reply-To: <89466355CEFE7244AC3A013E45641C18949557@lsmail2.crn.nestrd.ch>
References: <89466355CEFE7244AC3A013E45641C18949557@lsmail2.crn.nestrd.ch>
Message-ID: <6rr8ezspkq.fsf@bates3.stat.wisc.edu>

"Grathwohl,Dominik,LAUSANNE,NRC/NT" <dominik.grathwohl at rdls.nestle.com> writes:

> Dear All,
> 
> Comparing linear mixed effect models in SAS and R, I found the following
> discrepancy:
> 
>                             SAS                           R
> random statement            random subj(program);         random = ~ 1 |
> Subj
> -2*loglik                   1420.8                        1439.363
> random effects
> variance(Intercept)         9.6033                        9.604662
> variance(residual)          1.1969                        1.187553
> the first 3 fixed effects
> intercept                   83.0952                       81.10544
> ProgramCont                -3.4952                       -1.11526
> ProgramRI                  -1.9702                       -1.04517
> ...                        ...                            ...
> 
> Can somebody explain me this different results?

Different contrasts.  Try setting

options(contrasts = c(contr.SAS, contr.poly))

and doing the analysis in R again.

Note that all of these examples are available in the SASmixed package
for R.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Oct  9 16:03:28 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 9 Oct 2002 07:03:28 -0700 (PDT)
Subject: [R] plotting questions
In-Reply-To: <200210081715.48975.andys@neptuneinc.org>
Message-ID: <Pine.A41.4.44.0210090702380.176580-100000@homer03.u.washington.edu>

On Tue, 8 Oct 2002, Andrew Schuh wrote:

> Also, I'm not sure but I don't believe I have even seen this behavior.
>
> #############
> plot(chron(c("07/01/01","08/01/02")),c(100,200),cex.axis=5)
> points(chron(c("07/01/01","08/01/02","12/01/01")),c(100,200,150),type="b")
> #############
>
> It could be me but I think points() had always sorted the values before
> connecting the points with lines?

It's you.  There are a number of examples, especially for time series,
that wouldn't work if points() sorted the lines.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Wed Oct  9 16:19:16 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 9 Oct 2002 09:19:16 -0500
Subject: [R] log in barplot
In-Reply-To: <3DA41571.9F6280AC@ceam.es>
Message-ID: <001201c26f9e$dbf30d10$0201a8c0@MARC>

> -----Original Message-----
> From: owner-r-help at stat.math.ethz.ch [mailto:owner-r-
> help at stat.math.ethz.ch] On Behalf Of juli g. pausas
> Sent: Wednesday, October 09, 2002 6:39 AM
> To: r-help
> Subject: [R] log in barplot
> 
> Hi,
> 
> In plot, axis can be in log format,  e.g.  plot(*, log="y")
> Does a similar option exist for barplot ?
> 
> Thanks
> 
> Juli

Juli,

Look at barplot2() in the gregmisc package.  It will allow for log
scaling on both x and y axes.

If you have any questions regarding its use, let me know as I am the
author of the barplot2() enhancements to the base barplot() function.

Regards,

Marc Schwartz


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Oct  9 16:56:39 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Oct 2002 16:56:39 +0200
Subject: [R] Summary Orthogonal Polynomials
In-Reply-To: <6rwuorspq4.fsf@bates3.stat.wisc.edu>
References: <E09E527B56BE2D438A3D6A246DDD27A9165528@Roper-CV.qld.cmis.csiro.au>
	<6rwuorspq4.fsf@bates3.stat.wisc.edu>
Message-ID: <x2bs63y82g.fsf@biostat.ku.dk>

Douglas Bates <bates at stat.wisc.edu> writes:

> Bill.Venables at CMIS.CSIRO.AU writes:
> 
> > In fact I find fractions() useful for a lot of things, somewhat to my
> > surprise.
> 
> I did try fractions() on the example that Paul gave, poly(1:4, 3), and
> the result is hard to interpret.
> 
> > fractions(poly(1:4, 3))
>      1                2                3               
> [1,] -5494877/8191279              1/2    -98209/439204
> [2,]    -98209/439204             -1/2    208010/310083
> [3,]    208010/930249             -1/2 -5494877/8191279
> [4,]    208010/310083              1/2    208010/930249

It gets nicer if you square them to get rid of the sqrt(5) factor:

> fractions(poly(1:4, 3)^2)
     1    2    3   
[1,] 9/20  1/4 1/20
[2,] 1/20  1/4 9/20
[3,] 1/20  1/4 9/20
[4,] 9/20  1/4 1/20

(Anyone want to extend fractions() to deal with square roots as well?)


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andys at neptuneinc.org  Wed Oct  9 17:09:31 2002
From: andys at neptuneinc.org (Andrew Schuh)
Date: Wed, 9 Oct 2002 09:09:31 -0600
Subject: [R] plotting questions
In-Reply-To: <3DA3CCBD.FA60E456@statistik.uni-dortmund.de>
References: <200210081715.48975.andys@neptuneinc.org> <3DA3CCBD.FA60E456@statistik.uni-dortmund.de>
Message-ID: <200210090909.31632.andys@neptuneinc.org>

Thanks for the solution on the labels.  It worked fine.  I've used points() in 
this fashion hundreds of times and I guess I just had lucky data sets and 
never noticed how points() worked.

On Wednesday 09 October 2002 12:29 am, you wrote:
> Andrew Schuh wrote:
> > I'm having some issues with using chron() objects for the x-axis in
> > plots.
> >
> > #########
> > plot(chron(c("07/01/01","08/01/02")),c(100,200),cex.axis=5)
> > #########
> >
> > It doesn't seem to scale up the cex of the x-axis.  Is there any way to
> > scale these x-axis labels up?
>
> I'd call it a bug in the method plot.times().
> You can get around it with
>
>  par(cex.axis = 5)
>  plot(chron(c("07/01/01", "08/01/02")), c(100,200))
>
> > Also, I'm not sure but I don't believe I have even seen this behavior.
> >
> > #############
> > plot(chron(c("07/01/01","08/01/02")),c(100,200),cex.axis=5)
> > points(chron(c("07/01/01","08/01/02","12/01/01")),c(100,200,150),type="b"
> >) #############
> >
> > It could be me but I think points() had always sorted the values before
> > connecting the points with lines?
>
> Really? I think not since I am using R (version 0.63.0 ?) ;-)
>
> > I'm working with R1.6 on Redhat 7.3(i386).
>
> Uwe Ligges

-- 
Sincerely,

+++++++++++*******+++++***++*
Andrew Schuh
Environmental Mathematician
Neptune and Co.
(505) 884-8455
andys at neptuneinc.org
+++++++++++*******+++++***++*
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Wed Oct  9 17:21:55 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 09 Oct 2002 10:21:55 -0500
Subject: [R] proc mixed vs. lme
In-Reply-To: <89466355CEFE7244AC3A013E45641C1894955A@lsmail2.crn.nestrd.ch>
References: <89466355CEFE7244AC3A013E45641C1894955A@lsmail2.crn.nestrd.ch>
Message-ID: <6rd6qjskmk.fsf@bates3.stat.wisc.edu>

"Grathwohl,Dominik,LAUSANNE,NRC/NT" <dominik.grathwohl at rdls.nestle.com> writes:

> Hallo Peter,
> 
> Thank you for the advice, now I have to update my table:
> 
>                             SAS                           R
> random statement            random subj(program);         random = ~ 1 |
> Subj
> -2*loglik                   1420.8                        1420.820
> random effects
> variance(Intercept)         9.6033                        9.603331
> variance(residual)          1.1969                        1.196873
> the first 3 fixed effects
> intercept                   83.0952                        83.09524
> ProgramCont                -3.4952                       -3.49524
> ProgramRI                  -1.9702                       -1.97024
> ...                        ...                            ...
> 
> Everything looks nice. Perhaps Douglas could update the help file in
> SASmixed, 
> where I copied the misleading code!

Umm, my version of that help file has

\examples{
options(
  contrasts = c(unordered = "contr.SAS", ordered = "contr.poly"))
data(Weights)
fm1Weight <- lme( strength ~ Program * Time,
                  data = Weights, random = ~ 1 | Subj)
summary( fm1Weight )               # compare with output 3.1, p. 91
VarCorr( fm1Weight )
anova( fm1Weight )
fm2Weight <- update( fm1Weight, random = ~ Time | Subj )
anova( fm1Weight, fm2Weight )
summary( fm2Weight )
VarCorr( fm2Weight )
intervals( fm2Weight )
}

Notice the first line.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Oct  9 17:40:14 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Oct 2002 17:40:14 +0200
Subject: [R] proc mixed vs. lme
In-Reply-To: <6rd6qjskmk.fsf@bates3.stat.wisc.edu>
References: <89466355CEFE7244AC3A013E45641C1894955A@lsmail2.crn.nestrd.ch>
	<6rd6qjskmk.fsf@bates3.stat.wisc.edu>
Message-ID: <x27kgry61t.fsf@biostat.ku.dk>

Douglas Bates <bates at stat.wisc.edu> writes:

> "Grathwohl,Dominik,LAUSANNE,NRC/NT" <dominik.grathwohl at rdls.nestle.com> writes:
> 
> > Hallo Peter,
> > 
> > Thank you for the advice, now I have to update my table:
> > 
> >                             SAS                           R
> > random statement            random subj(program);         random = ~ 1 |
> > Subj
> > -2*loglik                   1420.8                        1420.820
> > random effects
> > variance(Intercept)         9.6033                        9.603331
> > variance(residual)          1.1969                        1.196873
> > the first 3 fixed effects
> > intercept                   83.0952                        83.09524
> > ProgramCont                -3.4952                       -3.49524
> > ProgramRI                  -1.9702                       -1.97024
> > ...                        ...                            ...
> > 
> > Everything looks nice. Perhaps Douglas could update the help file in
> > SASmixed, 
> > where I copied the misleading code!
> 
> Umm, my version of that help file has
> 
> \examples{
> options(
>   contrasts = c(unordered = "contr.SAS", ordered = "contr.poly"))
> data(Weights)
> fm1Weight <- lme( strength ~ Program * Time,
>                   data = Weights, random = ~ 1 | Subj)
> summary( fm1Weight )               # compare with output 3.1, p. 91
> VarCorr( fm1Weight )
> anova( fm1Weight )
> fm2Weight <- update( fm1Weight, random = ~ Time | Subj )
> anova( fm1Weight, fm2Weight )
> summary( fm2Weight )
> VarCorr( fm2Weight )
> intervals( fm2Weight )
> }
> 
> Notice the first line.

That's not the issue (and I believe it was in Dominik's code too).
Dominik's PROC MIXED code was using Time as a categorical variable,
whereas it is numeric in the Weights data frame. (whereas Program is
already a factor - I missed that). Of course the model ~Program*Time
is perfectly sensible even with Time as numeric, it's just not the
same model that Dominik was comparing with....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dominik.grathwohl at rdls.nestle.com  Wed Oct  9 20:19:37 2002
From: dominik.grathwohl at rdls.nestle.com (Grathwohl,Dominik,LAUSANNE,NRC/NT)
Date: Wed, 9 Oct 2002 20:19:37 +0200 
Subject: [R] Summary: proc mixed vs. lme
Message-ID: <89466355CEFE7244AC3A013E45641C1894955D@lsmail2.crn.nestrd.ch>

Summary: proc mixed vs. lme

The objective of this summary is to help people 
to get more familiar with the specification of 
random effects with proc mixed or lme. 
Very useful are the examples of Ramon Littell's book:
"SAS System for Mixed Models (1996)" 
(http://ftp.sas.com/samples/A55235)
The same data set's are kindly made available 
by Douglas Bates in the library(SASmixed).
In the help file are examples of the lme statements 
equivalent to the proc mixed ones.

To explain the different estimates,
Hein and Brian suppose to check whether both 
analyses with SAS and R uses ML estimates 
or REML estimates. However, this was not the problem, 
the default in proc mixed and lme is already REML.
Douglas advise me to use his option:
options( contrasts = c(unordered = "contr.SAS", 
ordered = contr.poly"))
However, I already used this option, 
because I copied the code from the SASmixed help file. 
Peter gave me the first hint 
and this solves the problem:
To change the model formula in lme,
from: strength ~ Program * Time 
to: strength ~ factor(Program) * factor(Time)
Now the option statement grasp! 
For people like me who try to get familiar 
with the specification of random effects 
would it helpful if the help file of SASmixed 
would be updated or the variables time and program 
would be already introduced as factors 
in the Weights data set.

Thank you all for the useful advises,

Dominik
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Wed Oct  9 21:05:35 2002
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 9 Oct 2002 12:05:35 -0700
Subject: [R] Dealing with xmalloc: out of virtual memory
Message-ID: <p05111a01b9ca202801e7@[128.115.153.6]>

I have a file of R code which I source().
The code has this structure:

repeat {
   ## check size of each of sixteen files
   ## if any of the file sizes has increased, then
   ##     read the last 65 lines of all the files
   ##     do a few computations, make a plot
}

With the intention of using Ctrl-C to manually break the loop when desired.

I set this thing running yesterday afternoon, and came in this 
morning to find it had crashed with this message
    xmalloc: out of virtual memory
and returned to the OS.

None of my objects are large, but they are repeatedly being 
overwritten so maybe  the following note from the online FAQ (section 
7.1) is relevant?

    "The new garbage collector does not move objects in memory, 
meaning that it is possible for the free memory to become fragmented 
so that large objects cannot be allocated even when there is 
apparently enough memory for them."

I've done some searching in the R-help archives, the various 
reference documents, the FAQ, but haven't yet found anything that I 
recognize as a solution.

I've some ideas, i.e., execute memory.profile() or gc() periodically 
to watch what's happening. In the meantime, I would appreciate 
suggestions.

Thanks
-Don



Version information:

>  version
          _
platform sparc-sun-solaris2.7
arch     sparc
os       solaris2.7
system   sparc, solaris2.7
status
major    1
minor    6.0
year     2002
month    10
day      01
language R

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Wed Oct  9 21:30:34 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Wed, 9 Oct 2002 15:30:34 -0400 (EDT)
Subject: [R] polynomial
Message-ID: <Pine.LNX.4.44.0210091529230.11575-100000@bolker.zoo.ufl.edu>


  Any better (more efficient, built-in) ideas for computing 

 coef[1]+coef[2]*x+coef[3]*x^2+ ...

 than

polynom <- function(coef,x) {
  n <- length(coef)
  
sum(coef*apply(matrix(c(rep(x,n),seq(0,n-1)),ncol=2),1,function(z)z[1]^z[2]))
}

?

  Ben
-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Oct  9 22:14:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Oct 2002 22:14:03 +0200
Subject: [R] polynomial
In-Reply-To: <Pine.LNX.4.44.0210091529230.11575-100000@bolker.zoo.ufl.edu>
References: <Pine.LNX.4.44.0210091529230.11575-100000@bolker.zoo.ufl.edu>
Message-ID: <x2d6qjv08k.fsf@biostat.ku.dk>

Ben Bolker <ben at zoo.ufl.edu> writes:

>   Any better (more efficient, built-in) ideas for computing 
> 
>  coef[1]+coef[2]*x+coef[3]*x^2+ ...
> 
>  than
> 
> polynom <- function(coef,x) {
>   n <- length(coef)
>   
> sum(coef*apply(matrix(c(rep(x,n),seq(0,n-1)),ncol=2),1,function(z)z[1]^z[2]))
> }

Back when debugging polyroot() I used this one

polyeval<-function(coef,x){v<-0;for (i in rev(coef)) v<-v*x+i; v}

Can't vouch for the efficiency, but  it vectorizes nicely in x.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From f0z6305 at labs.tamu.edu  Wed Oct  9 22:25:46 2002
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Wed, 9 Oct 2002 15:25:46 -0500
Subject: [R] Summary: proc mixed vs. lme
References: <89466355CEFE7244AC3A013E45641C1894955D@lsmail2.crn.nestrd.ch>
Message-ID: <031f01c26fd2$0c63af30$8bd75ba5@IE.TAMU.EDU>

Sorry to bother you.
I want to know if there are some Logistical Regression
functions in R?

Thanks.



----- Original Message -----
From: "Grathwohl,Dominik,LAUSANNE,NRC/NT"
<dominik.grathwohl at rdls.nestle.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, October 09, 2002 1:19 PM
Subject: [R] Summary: proc mixed vs. lme


> Summary: proc mixed vs. lme
>
> The objective of this summary is to help people
> to get more familiar with the specification of
> random effects with proc mixed or lme.
> Very useful are the examples of Ramon Littell's book:
> "SAS System for Mixed Models (1996)"
> (http://ftp.sas.com/samples/A55235)
> The same data set's are kindly made available
> by Douglas Bates in the library(SASmixed).
> In the help file are examples of the lme statements
> equivalent to the proc mixed ones.
>
> To explain the different estimates,
> Hein and Brian suppose to check whether both
> analyses with SAS and R uses ML estimates
> or REML estimates. However, this was not the problem,
> the default in proc mixed and lme is already REML.
> Douglas advise me to use his option:
> options( contrasts = c(unordered = "contr.SAS",
> ordered = contr.poly"))
> However, I already used this option,
> because I copied the code from the SASmixed help file.
> Peter gave me the first hint
> and this solves the problem:
> To change the model formula in lme,
> from: strength ~ Program * Time
> to: strength ~ factor(Program) * factor(Time)
> Now the option statement grasp!
> For people like me who try to get familiar
> with the specification of random effects
> would it helpful if the help file of SASmixed
> would be updated or the variables time and program
> would be already introduced as factors
> in the Weights data set.
>
> Thank you all for the useful advises,
>
> Dominik
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zeileis at ci.tuwien.ac.at  Wed Oct  9 22:28:49 2002
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Wed, 09 Oct 2002 22:28:49 +0200
Subject: [R] polynomial
References: <Pine.LNX.4.44.0210091529230.11575-100000@bolker.zoo.ufl.edu>
Message-ID: <3DA49181.C98BB5C4@ci.tuwien.ac.at>

Ben Bolker wrote:
> 
>   Any better (more efficient, built-in) ideas for computing
> 
>  coef[1]+coef[2]*x+coef[3]*x^2+ ...
> 
>  than
> 
> polynom <- function(coef,x) {
>   n <- length(coef)
> 
> sum(coef*apply(matrix(c(rep(x,n),seq(0,n-1)),ncol=2),1,function(z)z[1]^z[2]))
> }
> 
> ?

I think the function 
  polynom2 <- function(x, coef) sum(coef * x^seq(0,length(coef)-1))
is a little bit simpler and quicker for high order polynoms. But if you
want to be able to compute the function for vector-valued x, then you
might need something like
  polynom3 <- function(x, coef)
    apply(coef * sapply(as.matrix(x),
    function(x) x^seq(0,length(coef)-1)), 2, sum)

Then you can do:
R> mycoef <- rnorm(10000) 
R> polynom(mycoef, 0.5)
[1] -0.1422343
R> polynom2(0.5, mycoef)
[1] -0.1422343
R> polynom2(0.75, mycoef)
[1] -1.395595
R> polynom3(c(0.5, 0.75), mycoef)
[1] -0.1422343 -1.3955947

Best,
Z


>   Ben
> --
> 318 Carr Hall                                bolker at zoo.ufl.edu
> Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
> Box 118525                                   (ph)  352-392-5697
> Gainesville, FL 32611-8525                   (fax) 352-392-3704
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Wed Oct  9 23:25:09 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Wed, 9 Oct 2002 17:25:09 -0400 (Eastern Daylight Time)
Subject: [R] Multiple plots
Message-ID: <Pine.WNT.4.44.0210091719470.241-100000@P00B0D082649C.neu.edu.>

Hi,

I would love to make multiple histograms transposed one on another
in order to show relation between the sets. I tried to write
a function like this, but R tells me, that I cannot use add=FALSE in
high-level commands. That's nice but I am supposed to do?

	rm(list=ls())
	# what's wrong with underscore?
        #getwd("/home/matej/docs/skola/stat\_anal-cj3534/assign01/")
	load("assign01.RData")

	postscript("assign01.eps",onefile=FALSE)
	plot(itg$WFemale,xlab="Number of victims",\
	ylab="Frequencies",col="blue",main="Intimate Homicide\
	Victims",type="l")
	plot(itg$WMale,add=FALSE,axes=FALSE,col="red",type="l")
	quit(save="no")

Please, be patient with me, I am really newbie, and although it is
probably pretty stupid question, I was not able to find an answer in
all documentation (moreover, R for Beginners says, that add is OK
for every graph).

Thanks for any hint,

Matej Cepl

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Oct 10 00:42:55 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 9 Oct 2002 15:42:55 -0700 (PDT)
Subject: [R] polynomial
In-Reply-To: <Pine.LNX.4.44.0210091529230.11575-100000@bolker.zoo.ufl.edu>
Message-ID: <Pine.A41.4.44.0210091534120.64022-100000@homer13.u.washington.edu>

On Wed, 9 Oct 2002, Ben Bolker wrote:

>
>   Any better (more efficient, built-in) ideas for computing
>
>  coef[1]+coef[2]*x+coef[3]*x^2+ ...
>
>  than
>
> polynom <- function(coef,x) {
>   n <- length(coef)
>
> sum(coef*apply(matrix(c(rep(x,n),seq(0,n-1)),ncol=2),1,function(z)z[1]^z[2]))
> }
>

Well if x is a scalar as in your example
  n<-length(coef)-1
  sum(coef*x^(0:n))
seems simpler, or if x is a vector then
  n<-length(coef)-1
  rowSums(coef*outer(0:n,x,"^"))
or if it's a long enough vector that you don't want n copies of it
  rval<-coef[1]
  xn<-x
  n<-length(coef)
  for(i in 2:n){
	rval<-rval+coef[i]*xn
	xn<-xn*x
	}


Unlike lapply, which is actually faster than a for() loop, apply() is
basically a clarity optimisation rather than a speed optimisation, and in
this case I don't think it's clearer.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.connolly at hortresearch.co.nz  Thu Oct 10 01:23:33 2002
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 10 Oct 2002 12:23:33 +1300
Subject: [R] grid graphics and par settings
Message-ID: <20021009232333.GA28111@hortresearch.co.nz>

I see that adj is not a graphical parameter that can be used in a key
list to use with lattice functions.

Is that because it's not yet implemented in gpar?  If so, it could
also explain why it's not available in grid.text.

Is there a work around?  Centering looks silly on my plot.


best


-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Thu Oct 10 01:28:03 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 09 Oct 2002 19:28:03 -0400
Subject: [R] Help with 
In-Reply-To: <002701c26fed$993a6af0$23d994cb@andrewvhowclyz>
Message-ID: <5.1.0.14.2.20021009192025.02785b58@mcmail.cis.mcmaster.ca>

Dear Andrew,

I recall that some time ago you posted a question to the list about fitting 
the linear-by-linear association model, and that Duncan Mackay pointed you 
towards <http://math.cl.uh.edu/~thompsonla/5537/Splusdiscrete.PDF>, which 
contains examples from Agresti worked in S. I assume that the RC model 
isn't included there.

The RC model isn't a loglinear model, so fitting it directly by glm 
software isn't possible, as far as I know. I believe that fitting the model 
in SAS requires a macro; I'm not sure how it's done in GLIM, but probably 
in a similar manner. Agresti describes a method, due to Goodman, that 
shouldn't be hard to implement, but I know of no ready-made solutions.

Regards,
  John

At 06:42 AM 10/10/2002 +0700, Andrew Criswell wrote:
>Hello All:
>
>I hope I can get someone interested in this problem:
>
>Agresti in "Analysis of Categorical Data," p. 289, applies a "row and column
>effects model" to analyze a two-dimensional cross-classification of ordinal
>data.
>
>He got his results in either SAS or GLIM. Is there a way to replicate his
>results with R?
>
>He claims the RC model fits well with G^2(RC) = 3.57 with df = 8.  The ML
>estimates for the row scores are (-1.11, -1.12, -0.37, 0.03, 1.01, 1.82) and
>the column estimates are (-1.68, -0.14, 0.14, 1.41) and beta = 0.17
>
>Below, is the data:
>
>tbl.0 <- expand.grid(SOCIO = letters[1:6],
>                                MENTAL = c('well', 'mild', 'moderate',
>'impaired))
>
>COUNTS <- c( 64, 57, 57, 72, 36, 21,
>                           94, 94, 105, 141, 97, 71,
>                           58, 54, 65, 77, 54, 54,
>                           46, 40, 60, 94, 78, 71)
>
>data.0 <- data.frame(tbl.0, COUNTS)

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mabramso at gmu.edu  Thu Oct 10 04:31:54 2002
From: mabramso at gmu.edu (Myriam Abramson)
Date: 09 Oct 2002 22:31:54 -0400
Subject: [R] read.table conversion question
Message-ID: <m3ofa3owh1.fsf@home.sweet.home>


Hi!

I would like to read data read with read.table row by row into a
c() vector. 

data<-read.table("test",header=FALSE)
for (i in 1:length(data[[1]])) {
      temp <- ??
      do something with temp
        }

data[1,] gives me 
  V1 V2 V3 V4   V5
1  1 -1 -1 -1 0.33

c[temp[1],temp[2]) gives me
$V1
[1] 1

$V2
[1] -1


Sorry if that's well known but I can't still figure it out. 
-- 
                                   myriam

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jbalinc at insight.rr.com  Thu Oct 10 06:20:52 2002
From: jbalinc at insight.rr.com (Jess Balint)
Date: Wed, 9 Oct 2002 23:20:52 -0500
Subject: [R] Exporting Charts or Graphs
Message-ID: <20021009232052.570e8044.jbalinc@insight.rr.com>

Hello all, I am fairly new to R and hope not to be a bother. I have used the R-GUI a small amount under Microsoft Windows0S. I recall the ability to export created charts and graphs to JPEG or other various image formats. How can I do this in the UNIX CLI version? Thank you.

Also, I have receiveder the following error after installing a package via CRAN. How would I fix this? Thank you.

Jess

Warning message: 
argument `lib' is missing: using /usr/local/R/lib/R/library in: install.packages("RMySQL")

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From abunn59715 at earthlink.net  Thu Oct 10 08:16:19 2002
From: abunn59715 at earthlink.net (Andy Bunn)
Date: Thu, 10 Oct 2002 00:16:19 -0600
Subject: [R] Generating AR1 data
Message-ID: <NEBBIPHDAMMOKDKPOFFIAEOBCGAA.abunn59715@earthlink.net>

Hi, Is there an easy way to generate data with temporal autocorrelation? I
want to generate data with something like rnorm where I can specify the
mean, variance and time lag. Does such a thing exist?

Yours, AB

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Oct 10 08:39:59 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 10 Oct 2002 07:39:59 +0100 (BST)
Subject: [R] Exporting Charts or Graphs
In-Reply-To: <20021009232052.570e8044.jbalinc@insight.rr.com>
Message-ID: <Pine.LNX.4.31.0210100733450.18651-100000@gannet.stats>

On Wed, 9 Oct 2002, Jess Balint wrote:

> Hello all, I am fairly new to R and hope not to be a bother. I have used the R-GUI a small amount under Microsoft Windows0S. I recall the ability to export created charts and graphs to JPEG or other various image formats. How can I do this in the UNIX CLI version? Thank you.

There are jpeg(), png() and bitmap() devices and the dev2bitmap() function
under Unix versions of R, although they all require additional software at
the time R is built or is run.  The simplest way usually is to re-plot the
graph after opening a jpeg (etc) device, then call dev.off().

> Also, I have receiveder the following error after installing a package via CRAN. How would I fix this? Thank you.

Call install.packages correctly with two arguments: see its help page.
install.packages("RMySQL", .Library) is probably what you wanted.

>
> Jess
>
> Warning message:
> argument `lib' is missing: using /usr/local/R/lib/R/library in: install.packages("RMySQL")

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From miken at bigpond.net.au  Thu Oct 10 08:48:31 2002
From: miken at bigpond.net.au (Mike Nielsen)
Date: 10 Oct 2002 16:48:31 +1000
Subject: [R] Aggregating data -- table almost does it
Message-ID: <1034232517.2821.39.camel@CPE-144-132-182-167>

Dear r-helpers,

I have a data frame that looks like this:

> str(fred)
`data.frame':	3243 obs. of  14 variables:
 $ date       : chr  "02-09-19" "02-09-19" "02-09-19" "02-09-19" ...
 $ time       : chr  "10:31:34" "10:31:34" "10:31:39" "11:36:12" ...
 $ cpusys     : num  0 0.11 0.37 0 0.13 0.46 0 0.01 0.01 0 ...
 $ cpuelapsed : num  0.00328 0.44335 5.08891 0.01576 0.53153 ...
 $ cpuuser    : num  0 0.3 4.19 0 0.28 4.07 0 0 0 0 ...
 $ dread      : int  0 0 0 0 0 0 0 0 0 0 ...
 $ dwrit      : int  0 0 0 0 0 0 0 0 0 0 ...
 $ sread      : int  10 1273 1271 10 1271 1270 0 10 17 27 ...
 $ swrit      : int  0 13 30 0 9 29 0 0 3 0 ...
 $ lread      : int  0 27 0 0 27 0 0 0 0 0 ...
 $ lwrit      : int  0 27 0 0 27 0 0 0 0 0 ...
 $ sbhr       : num  89.25 29.24  5.01 89.25 29.31 ...
 $ lbhr       : num   0.0 99.1  0.0  0.0 99.1 ...
 $ dates.chron:Classes 'chron', 'dates', 'times'  atomic [1:3243] 11949
11949 11949 11949 11949 ...
  .. ..- attr(*, "format")= chr [1:2] "y-m-d" "h:m:s"
  .. ..- attr(*, "origin")= Named num [1:3] 1 1 1970
  .. .. ..- attr(*, "names")= chr [1:3] "month" "day" "year"

Each observation represents an "event".  

Now, I would like to (for example) count the number of events (or maybe
find the mean of a certain variable) in each hour of each day.  To
count, I could use:

> table(as.character(dates(fred$dates.chron)),hours(fred$dates.chron))
          
           10 11  12   13 14
  09/19/02  3 63 112 3042 23

(there is, so far, only one day's worth of events in the data frame).

To do fancier stuff, I know I could use aggregate.

However, I only get a column for each hour in which there was an event. 
What I would dearly love to have is 24 columns, with 0 (zero) indicating
that there were no events in that hour of that day.

Of course, I could use a loop, or even re-write the SQL that I use to
get the data frame, but, after hours of fiddling with it and flipping
through R manuals, I'm starting to boggle and also to fall behind on
what was to be a quick project.  Still, I'd really like to know the
elegant R solution that has got to exist, and would be extremely
grateful to any kind soul who could point me in the right direction.


Thanks so much.

Regards,

Mike

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Thu Oct 10 09:13:35 2002
From: siim at obs.ee (Ott Toomet)
Date: Thu, 10 Oct 2002 09:13:35 +0200 (CEST)
Subject: [R] Multiple plots
In-Reply-To: <Pine.WNT.4.44.0210091719470.241-100000@P00B0D082649C.neu.edu.>
Message-ID: <Pine.LNX.4.44.0210100909410.3008-100000@localhost.localdomain>

On Wed, 9 Oct 2002, Matej Cepl wrote:

  |Hi,
  |
  |I would love to make multiple histograms transposed one on another
  |in order to show relation between the sets. I tried to write
  |a function like this, but R tells me, that I cannot use add=FALSE in
  |high-level commands. That's nice but I am supposed to do?
  |
  |	rm(list=ls())
  |	# what's wrong with underscore?
  |        #getwd("/home/matej/docs/skola/stat\_anal-cj3534/assign01/")

On my system (linux, R 1.5.1), underscore seems to work in file names both
quoted and unquoted.

  |	load("assign01.RData")
  |
  |	postscript("assign01.eps",onefile=FALSE)
  |	plot(itg$WFemale,xlab="Number of victims",\
  |	ylab="Frequencies",col="blue",main="Intimate Homicide\
  |	Victims",type="l")
  |	plot(itg$WMale,add=FALSE,axes=FALSE,col="red",type="l")
  |	quit(save="no")


I think you are trying to plot to line-plots on the same graph.  If so, you
should use

plot(female...) # no add= here
lines(male....) # no add= here

lines is basically the same as plot(), but it does not erase the previous
picture.  

If your idea was indeed to make to separate plots, drop add= in both cases.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ddmagee at lbl.gov  Thu Oct 10 09:16:29 2002
From: ddmagee at lbl.gov (David Magee)
Date: Thu, 10 Oct 2002 00:16:29 -0700
Subject: [R] normalizing heteroscedastic variance
Message-ID: <3DA5294C.9D2119DA@lbl.gov>

I have many sets of heteroscedastic data y.  I want to normalize each
set independently so I can compare across replicates.
Within a set, the mean of y = 0 and the slope = 0 as a function of x,
and the variance of y varies by x.
The range of y is (-1, +1) more or less and The range of x is (.6,10.5)
Imagine a looking at a cone sideways.

I split the data into range factors using
f <- round(x)
then calculated the sd for each range using
yfsd<-tapply(ma[[10]][,1], A, sd)
Now I would like to divide each element of y by yfsd
dim(y)=5000
yfsd has 10 values for the 10 factors
If I use tapply I get a vector with 10 values. This is not what I want.
Any cleaver ideas? Do I need to loop or use a while statement.
Thanks,
D




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dominik.grathwohl at rdls.nestle.com  Thu Oct 10 09:40:20 2002
From: dominik.grathwohl at rdls.nestle.com (Grathwohl,Dominik,LAUSANNE,NRC/NT)
Date: Thu, 10 Oct 2002 09:40:20 +0200
Subject: [R] Summary: proc mixed vs. lme
Message-ID: <89466355CEFE7244AC3A013E45641C1894955E@lsmail2.crn.nestrd.ch>

Hi Freq

if you like to get familiar with logistic regression in R, I would
recommend the text book of Venables and Ripley (Modern Applied 
Statistics with S-PLUS). All data sets and functions 
are available for R in the MASS-library. The MASS-library could be down
loaded 
from http://cran.r-project.org/bin/windows/contrib/VR.zip (e.g.. Windows
users).
The glm function plays the key role. With the help of this function you
could fit
logistic regression models. First step in the material could be:

library(MASS)
?glm

Regards,

Dominik

> -----Original Message-----
> From: Feng Zhang [mailto:f0z6305 at labs.tamu.edu]
> Sent: mercredi, 9. octobre 2002 22:26
> To: Grathwohl,Dominik,LAUSANNE,NRC/NT; r-help at stat.math.ethz.ch
> Subject: Re: [R] Summary: proc mixed vs. lme
> 
> 
> Sorry to bother you.
> I want to know if there are some Logistical Regression
> functions in R?
> 
> Thanks.
> 
> 
> 
> ----- Original Message -----
> From: "Grathwohl,Dominik,LAUSANNE,NRC/NT"
> <dominik.grathwohl at rdls.nestle.com>
> To: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, October 09, 2002 1:19 PM
> Subject: [R] Summary: proc mixed vs. lme
> 
> 
> > Summary: proc mixed vs. lme
> >
> > The objective of this summary is to help people
> > to get more familiar with the specification of
> > random effects with proc mixed or lme.
> > Very useful are the examples of Ramon Littell's book:
> > "SAS System for Mixed Models (1996)"
> > (http://ftp.sas.com/samples/A55235)
> > The same data set's are kindly made available
> > by Douglas Bates in the library(SASmixed).
> > In the help file are examples of the lme statements
> > equivalent to the proc mixed ones.
> >
> > To explain the different estimates,
> > Hein and Brian suppose to check whether both
> > analyses with SAS and R uses ML estimates
> > or REML estimates. However, this was not the problem,
> > the default in proc mixed and lme is already REML.
> > Douglas advise me to use his option:
> > options( contrasts = c(unordered = "contr.SAS",
> > ordered = contr.poly"))
> > However, I already used this option,
> > because I copied the code from the SASmixed help file.
> > Peter gave me the first hint
> > and this solves the problem:
> > To change the model formula in lme,
> > from: strength ~ Program * Time
> > to: strength ~ factor(Program) * factor(Time)
> > Now the option statement grasp!
> > For people like me who try to get familiar
> > with the specification of random effects
> > would it helpful if the help file of SASmixed
> > would be updated or the variables time and program
> > would be already introduced as factors
> > in the Weights data set.
> >
> > Thank you all for the useful advises,
> >
> > Dominik
> > 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.
> -.-.-
> > r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> >
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._.
> _._
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", 
> "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jmiyamot at u.washington.edu  Thu Oct 10 09:42:22 2002
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Thu, 10 Oct 2002 00:42:22 -0700 (PDT)
Subject: [R] Environment variables under Windows
Message-ID: <Pine.A41.4.44.0210100026360.49902-100000@mead1.u.washington.edu>

Greetings,

I have a question pertaining to the concept of "environment variables"
that is mentioned in the R documentation for "Startup" and also in the
discussion of the Windows configuration of R in the recent book "An
Introduction to R" authored by Venables, Smith, and the R Development Core
Team (referred to as VS in this message).

The Startup documentation and VS make reference to environment variables,
e.g., R\_ENVIRON, R_USER, or R\_PROFILE.  Apparently the R startup
procedure operates differently depending on whether these variables are
"set" or "unset".  What is unclear to me is how to set these variables.

For example, is something to be done with the AUTOEXEC.BAT file or the
CONFIG.SYS file, or perhaps one must alter the Properties of the shortcut
icon for R?  Another possibility is that one must insert some lines in the
RProfile file.  On my installation I have two files names RProfile.  The
first is in the directory \rw1041\etc, and the second is in the directory,
\rw1041\library\base\R.  Does one "set" an environment variable by placing
an appropriate line in a RProfile file?

John

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Hicham.Zmarrou at student.uva.nl  Thu Oct 10 09:44:20 2002
From: Hicham.Zmarrou at student.uva.nl (H. Zmarrou)
Date: Thu, 10 Oct 2002 09:44:20 +0200
Subject: [R] Help?
Message-ID: <277c4d274f6c.274f6c277c4d@student.uva.nl>


Dear Sir :

I would ask if R contains some propreties to write the greeks(lambda, 
theta,xsi,......) en also if R can also the mathematics signs like 
integrals, indices.......

Your sincerly:

H.Zmarrou
University of Amsterdam:

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct 10 09:48:55 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Oct 2002 09:48:55 +0200
Subject: [R] read.table conversion question
In-Reply-To: <m3ofa3owh1.fsf@home.sweet.home>
References: <m3ofa3owh1.fsf@home.sweet.home>
Message-ID: <x2ptuiwx7c.fsf@biostat.ku.dk>

Myriam Abramson <mabramso at gmu.edu> writes:

> Hi!
> 
> I would like to read data read with read.table row by row into a
> c() vector. 
> 
> data<-read.table("test",header=FALSE)
> for (i in 1:length(data[[1]])) {
>       temp <- ??
>       do something with temp
>         }
> 
> data[1,] gives me 
>   V1 V2 V3 V4   V5
> 1  1 -1 -1 -1 0.33
> 
> c[temp[1],temp[2]) gives me
> $V1
> [1] 1
> 
> $V2
> [1] -1
> 
> 
> Sorry if that's well known but I can't still figure it out. 

Data frames are essentially lists of variables, and a row of a data
frame is a list as well (it must be able to hold values of different
modes). To turn it into a vector, you can use unlist():

 data(airquality)
 c(airquality[1,])
 unlist(airquality[1,])

or, same effect:

 c(airquality[1,], recursive=TRUE)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From theis at statistik.uni-dortmund.de  Thu Oct 10 10:07:41 2002
From: theis at statistik.uni-dortmund.de (Winfried Theis)
Date: Thu, 10 Oct 2002 10:07:41 +0200 (MEST)
Subject: [R] Help?
In-Reply-To: <277c4d274f6c.274f6c277c4d@student.uva.nl>
Message-ID: <XFMail.021010100741.theis@statistik.uni-dortmund.de>

Hi!

See help(plotmath)
On 10-Oct-02 H. Zmarrou wrote:
> 
> Dear Sir :
> 
> I would ask if R contains some propreties to write the greeks(lambda, 
> theta,xsi,......) en also if R can also the mathematics signs like 
> integrals, indices.......
> 
See help(plotmath) there you'll find all you need.

Winfried

> Your sincerly:
> 
> H.Zmarrou
> University of Amsterdam:
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _

---------------------------------------------------------------------
E-Mail: Winfried Theis <theis at statistik.uni-dortmund.de>
Date: 10-Oct-02

Dipl.-Math. Winfried Theis
SFB 475, Fachbereich Statistik, Universit"at Dortmund, 44221 Dortmund
Tel.: +49-231-755-5903 FAX: +49-231-755-4387
----------------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bernhard.Pfaff at drkw.com  Thu Oct 10 09:51:32 2002
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Thu, 10 Oct 2002 09:51:32 +0200
Subject: [R] polynomial
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9001CADEB6@ibfftce505.is.de.dresdnerkb.com>

Hello Ben,

would the supplementary package 'polynom' of help to you?

library(polynom)
p <- polynomial(c(1,-1.11,0,0,0.18))
predict(p, 'your values for x')

Rgds,
Bernhard


-----Original Message-----
From: Thomas Lumley [mailto:tlumley at u.washington.edu]
Sent: 10 October 2002 00:43
To: bolker at zoo.ufl.edu
Cc: R help list
Subject: Re: [R] polynomial


On Wed, 9 Oct 2002, Ben Bolker wrote:

>
>   Any better (more efficient, built-in) ideas for computing
>
>  coef[1]+coef[2]*x+coef[3]*x^2+ ...
>
>  than
>
> polynom <- function(coef,x) {
>   n <- length(coef)
>
>
sum(coef*apply(matrix(c(rep(x,n),seq(0,n-1)),ncol=2),1,function(z)z[1]^z[2])
)
> }
>

Well if x is a scalar as in your example
  n<-length(coef)-1
  sum(coef*x^(0:n))
seems simpler, or if x is a vector then
  n<-length(coef)-1
  rowSums(coef*outer(0:n,x,"^"))
or if it's a long enough vector that you don't want n copies of it
  rval<-coef[1]
  xn<-x
  n<-length(coef)
  for(i in 2:n){
	rval<-rval+coef[i]*xn
	xn<-xn*x
	}


Unlike lapply, which is actually faster than a for() loop, apply() is
basically a clarity optimisation rather than a speed optimisation, and in
this case I don't think it's clearer.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From John.Gavin at ubsw.com  Thu Oct 10 11:44:04 2002
From: John.Gavin at ubsw.com (John.Gavin@ubsw.com)
Date: Thu, 10 Oct 2002 10:44:04 +0100
Subject: [R] problem with Sweave on 1.6 on NT4
Message-ID: <8C2B4A87FC7E0147A65DC17BF4BDDC3120DF10@NLDNC006PEX1.ubsgs.ubsgroup.net>

Hi,

I recently compiled 1.6 on NT4 but
I am having a problem with Sweave.

Using the inbuilt 'Sweave-test-1.Rnw' file as an example:

-------
> library(tools)
> testfile <- file.path(.path.package("tools"),
                      "Sweave", "Sweave-test-1.Rnw")

## create a LaTeX file
Sweave(testfile)
testfile <- file.path(.path.package("tools"),
+                       "Sweave", "Sweave-test-1.Rnw")
> 
> ## create a LaTeX file
> Sweave(testfile)
Writing to file Sweave-test-1.tex
Processing code chunks ...
 1 : print term verbatim
 2 : term hide
 3 : echo print term verbatim
 4 : term verbatim
 5 : echo term verbatim
 6 : echo term verbatim eps pdf
 7 : echo term verbatim eps pdf

You can now run LaTeX on Sweave-test-1.tex 
---------

But the opening lines of Sweave-test-1.tex are: 

---------
% -*- mode: noweb; noweb-default-code-mode: R-mode; -*-
\documentclass[a4paper]{article}

\title{A Test File}
\author{Friedrich Leisch}


\usepackage{a4wide}

\usepackage{c:etcRrw1060/share/texmf/Sweave}
\begin{document}
...
------------

The line '\usepackage{c:etcRrw1060/share/texmf/Sweave}' is wrong.
In V1.5.1 it used to read 
\usepackage{c:/etc/R/rw1051/library/tools/Sweave/Sweave}
i.e. 'c:etcRrw1060' should be 'c:/etc/R/rw1060' 
and I think the reference should be 
c:/etc/R/rw1060/library/tools/Sweave/Sweave,
(not the 'share/texmf' folder) as that is where Sweave.sty is.
(The only *.sty file in the folder 'share/texmf/' is Rd.sty.)

Is there is something that I try to set to get Sweave
insert the correct line in latex to load the Sweave.sty file?

platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.0            
year     2002           
month    10             
day      01             
language R       

Regards,

John.

John Gavin <john.gavin at ubsw.com>,
Quantitative Risk Models and Statistics,
UBS Warburg, 100 Liverpool Street (6th floor),
London EC2M 2RH, UK.
Phone +44 (0) 207 567 4289
Fax   +44 (0) 207 568 5352

Visit our website at http://www.ubswarburg.com

This message contains confidential information and is intended only 
for the individual named.  If you are not the named addressee you 
should not disseminate, distribute or copy this e-mail.  Please 
notify the sender immediately by e-mail if you have received this 
e-mail by mistake and delete this e-mail from your system.

E-mail transmission cannot be guaranteed to be secure or error-free 
as information could be intercepted, corrupted, lost, destroyed, 
arrive late or incomplete, or contain viruses.  The sender therefore 
does not accept liability for any errors or omissions in the contents 
of this message which arise as a result of e-mail transmission.  If 
verification is required please request a hard-copy version.  This 
message is provided for informational purposes and should not be 
construed as a solicitation or offer to buy or sell any securities or 
related financial instruments.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dominik.grathwohl at rdls.nestle.com  Thu Oct 10 11:45:24 2002
From: dominik.grathwohl at rdls.nestle.com (Grathwohl,Dominik,LAUSANNE,NRC/NT)
Date: Thu, 10 Oct 2002 11:45:24 +0200
Subject: [R] Summary: proc mixed vs. lme
Message-ID: <89466355CEFE7244AC3A013E45641C18949563@lsmail2.crn.nestrd.ch>

I forgot, glm is of course part of the base package.
You need not to load MASS, simply try:

?glm

Dominik

> -----Original Message-----
> From: Feng Zhang [mailto:f0z6305 at labs.tamu.edu]
> Sent: mercredi, 9. octobre 2002 22:26
> To: Grathwohl,Dominik,LAUSANNE,NRC/NT; r-help at stat.math.ethz.ch
> Subject: Re: [R] Summary: proc mixed vs. lme
> 
> 
> Sorry to bother you.
> I want to know if there are some Logistical Regression
> functions in R?
> 
> Thanks.
> 
> 
> 
> ----- Original Message -----
> From: "Grathwohl,Dominik,LAUSANNE,NRC/NT"
> <dominik.grathwohl at rdls.nestle.com>
> To: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, October 09, 2002 1:19 PM
> Subject: [R] Summary: proc mixed vs. lme
> 
> 
> > Summary: proc mixed vs. lme
> >
> > The objective of this summary is to help people
> > to get more familiar with the specification of
> > random effects with proc mixed or lme.
> > Very useful are the examples of Ramon Littell's book:
> > "SAS System for Mixed Models (1996)"
> > (http://ftp.sas.com/samples/A55235)
> > The same data set's are kindly made available
> > by Douglas Bates in the library(SASmixed).
> > In the help file are examples of the lme statements
> > equivalent to the proc mixed ones.
> >
> > To explain the different estimates,
> > Hein and Brian suppose to check whether both
> > analyses with SAS and R uses ML estimates
> > or REML estimates. However, this was not the problem,
> > the default in proc mixed and lme is already REML.
> > Douglas advise me to use his option:
> > options( contrasts = c(unordered = "contr.SAS",
> > ordered = contr.poly"))
> > However, I already used this option,
> > because I copied the code from the SASmixed help file.
> > Peter gave me the first hint
> > and this solves the problem:
> > To change the model formula in lme,
> > from: strength ~ Program * Time
> > to: strength ~ factor(Program) * factor(Time)
> > Now the option statement grasp!
> > For people like me who try to get familiar
> > with the specification of random effects
> > would it helpful if the help file of SASmixed
> > would be updated or the variables time and program
> > would be already introduced as factors
> > in the Weights data set.
> >
> > Thank you all for the useful advises,
> >
> > Dominik
> > 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.
> -.-.-
> > r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> >
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._.
> _._
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Oct 10 12:26:58 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 10 Oct 2002 11:26:58 +0100 (GMT Daylight Time)
Subject: [R] Generating AR1 data
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIAEOBCGAA.abunn59715@earthlink.net>
Message-ID: <Pine.WNT.4.44.0210101126070.940-100000@gannet.stats.ox.ac.uk>

On Thu, 10 Oct 2002, Andy Bunn wrote:

> Hi, Is there an easy way to generate data with temporal autocorrelation? I
> want to generate data with something like rnorm where I can specify the
> mean, variance and time lag. Does such a thing exist?

arima.sim in package ts.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vdooren at rulsfb.leidenuniv.nl  Thu Oct 10 14:03:18 2002
From: vdooren at rulsfb.leidenuniv.nl (Tom Van Dooren)
Date: Thu, 10 Oct 2002 13:03:18 +0100
Subject: [R] "multivariate" mixed models with crossed random effects
Message-ID: <3DA56C86.70C1B157@rulsfb.leidenuniv.nl>

Hello,

I am currently analysis a dataset of chaffinch song durations.
Per observed song, the durations of two parts (segments) of the song are

recorded.
One can assume that a random effect of bird and of song type contribute
to duration variation.
With songtype nested within bird, lme does well in estimating random
effects of bird and songtype on durations of both parts of a song, and
of the correlation between bird random effects. I coded this model as
follows:

modelnested<-lme(duration~part,random=list(bird=~part,songtype=~part),
weights=varIdent(form=~1|part),data=data)

So the mean durations are estimated per song part, I get random effects
of bird and songtype, plus the correlation between random effects on
both parts, and error variances are estimated separately per song part.

Now it is possible to classify songs according to sonogram properties,
such that songtype according to that classification is not nested
anymore within bird (so different birds can sing the same song).
When the songtype and bird random effects are crossed, I modelled
duration of each separate  part of a song as:

modelcrossed<-lme(durationfirstpart~1,
random=pdBlocked(list(pdIdent(~bird-1),pdIdent(~songtype-1))),data=dataseparateparts)

In the case of crossed random effects,does anyone know whether it is
possible to have
durations of both song parts in a single model, so that I can estimate
the correlation between random effects of bird or songtype on both
durations, just as the nested model does?

Best regards, much thanks for your help,

Tom Van Dooren
Section Theoretical Evolutionary Biology
Leiden University
The Netherlands

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Thu Oct 10 13:19:10 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 10 Oct 2002 12:19:10 +0100
Subject: [R] NEdit Highligth patterns for R
Message-ID: <1034248750.5057.77.camel@gandalf>

Hi

I've just submitted to the NEdit development team a R highligth patterns
for NEdit (www.nedit.org).

NEdit is a text editor for LINUX which I use to write small R functions.
In my opinion is a very good tool for small scripts, maybe for huge
projects is not the best.

I'm attaching the R-5.1.pats file so you can try it. 

As usual contributions and comments are welcome.

Regards

EJ 


-------------- next part --------------
!=============================================================================
!
! Syntax Highlighting Patterns for R
! by Ernesto Jardim, ernesto at ipimar.pt
! version: 1.0
!
! Configuring NEdit to use a new pattern set: 
! 
! * Close your NEdit sessions 
! * Start an NEdit session using the import command line option with the pattern you downloaded: 
! 
!   # nedit -import R-5.1.pats
! 
! * Go into the recognition patterns dialog (Preferences>Default Settings>Syntax Highlighting>Recognition Patterns...) and verify that the patterns are imported 
! * Use Preferences>Save Defaults... to store the modifications. 
! 
! * This version has been verified with the following versions on NEdit
!  - 5.1
!
!=============================================================================

nedit.highlightPatterns: \n\
R:1:0{\n\
Note:"#!":"$"::Note::\n\
Comment:"#":"$"::TextComment::\n\
Keyword:",|<(return|if|then|else|in|switch|while|for|function|do|done)>":::Keyword::D\n\
Loop and Equation:"\\[|\\]|\\(|\\)|\\{|\\}|\\<-|,":::Loop and Equation::\n\
Operators:"!|~|:|\\^|\\*|%|\\<|\\>|==|\\>=|\\<=|&|\\$|-|=|\\+|""|/":::Operators::\n\
}
nedit.languageModes: 	R:.q .r .R::::::
nedit.styles: Note:darkRed:Italic\n\
TextComment:darkBlue:Italic\n\
Loop and Equation:darkRed:Bold\n\
Operators:darkGreen:Bold\n\

From ligges at statistik.uni-dortmund.de  Thu Oct 10 13:09:27 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 10 Oct 2002 13:09:27 +0200
Subject: [R] Help?
References: <277c4d274f6c.274f6c277c4d@student.uva.nl>
Message-ID: <3DA55FE7.A28E0FA3@statistik.uni-dortmund.de>



"H. Zmarrou" wrote:
> 
> Dear Sir :
> 
> I would ask if R contains some propreties to write the greeks(lambda,
> theta,xsi,......) en also if R can also the mathematics signs like
> integrals, indices.......

Yes. See ?plotmath for details.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Thu Oct 10 13:15:55 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 10 Oct 2002 13:15:55 +0200
Subject: [R] Environment variables under Windows
References: <Pine.A41.4.44.0210100026360.49902-100000@mead1.u.washington.edu>
Message-ID: <3DA5616B.290A2112@statistik.uni-dortmund.de>

John Miyamoto wrote:
> 
> Greetings,
> 
> I have a question pertaining to the concept of "environment variables"
> that is mentioned in the R documentation for "Startup" and also in the
> discussion of the Windows configuration of R in the recent book "An
> Introduction to R" authored by Venables, Smith, and the R Development Core
> Team (referred to as VS in this message).
> 
> The Startup documentation and VS make reference to environment variables,
> e.g., R\_ENVIRON, R_USER, or R\_PROFILE.  Apparently the R startup
> procedure operates differently depending on whether these variables are
> "set" or "unset".  What is unclear to me is how to set these variables.
> 
> For example, is something to be done with the AUTOEXEC.BAT file or the
> CONFIG.SYS file, or perhaps one must alter the Properties of the shortcut
> icon for R?  Another possibility is that one must insert some lines in the
> RProfile file.  On my installation I have two files names RProfile.  The
> first is in the directory \rw1041\etc, and the second is in the directory,
> \rw1041\library\base\R.  Does one "set" an environment variable by placing
> an appropriate line in a RProfile file?

1) See the R for Windows FAQs
2) See ?.Renviron for details on how to set those variables in a file
like .Renviron
3) There are different versions of Windows with different approaches to
set global environment variables. In Win9x and friends it is done in
autoexec.bat, but on WinNT,2k,XP you should set it at another place.
Details hopefully in the manuals of your OS.
4) You can set it temporarily in R by using Sys.putenv() (that's
possible in Rprofile as well, but I think not recommended, just to
answer your last question).


Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Oct 10 13:32:26 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 10 Oct 2002 12:32:26 +0100 (GMT Daylight Time)
Subject: [R] Environment variables under Windows
In-Reply-To: <Pine.A41.4.44.0210100026360.49902-100000@mead1.u.washington.edu>
Message-ID: <Pine.WNT.4.44.0210101229520.1816-100000@gannet.stats.ox.ac.uk>

On Thu, 10 Oct 2002, John Miyamoto wrote:

> Greetings,
>
> I have a question pertaining to the concept of "environment variables"
> that is mentioned in the R documentation for "Startup" and also in the
> discussion of the Windows configuration of R in the recent book "An
> Introduction to R" authored by Venables, Smith, and the R Development Core
> Team (referred to as VS in this message).
>
> The Startup documentation and VS make reference to environment variables,
> e.g., R\_ENVIRON, R_USER, or R\_PROFILE.  Apparently the R startup
> procedure operates differently depending on whether these variables are
> "set" or "unset".  What is unclear to me is how to set these variables.
>
> For example, is something to be done with the AUTOEXEC.BAT file or the
> CONFIG.SYS file, or perhaps one must alter the Properties of the shortcut
> icon for R?  Another possibility is that one must insert some lines in the
> RProfile file.  On my installation I have two files names RProfile.  The
> first is in the directory \rw1041\etc, and the second is in the directory,
> \rw1041\library\base\R.  Does one "set" an environment variable by placing
> an appropriate line in a RProfile file?

No. See the rw-FAQ questions 2.2 and 3.2.

You either use the command line or the .Renviron file (just as is
documented for Unix).

Please upgrade from rw1041 to rw1060 first.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From saerens at isys.ucl.ac.be  Thu Oct 10 14:36:44 2002
From: saerens at isys.ucl.ac.be (Marco Saerens)
Date: Thu, 10 Oct 2002 13:36:44 +0100
Subject: [R] Correspondence analysis/optimal scaling with ordinal variable
Message-ID: <p05111a00b9cb1b9e53a1@[130.104.153.118]>

Dear R specialists,

I have a multivariate statistics question that I want to submit to 
the R community (which conveys a very good statistical knowledge).

I need to perform an optimal scaling based on a discrete variable and 
an ordinal variable. The discrete variable, Area, defines a 
geographical area. The ordinal variable, EducationLevel, describes 
the education level of individuals (the ordinal factors are 
"VeryLow", "Low, "Medium", "Large", "VeryLarge").

I have a data set specifying, for each area (rows), the number of 
individuals in this area having a given education level (columns). It 
looks like:

Area    VeryLow    Low    Medium    Large    VeryLarge
A1         6        21      15        11         0
A2         2         4       8        17         9
etc

Meaning that in area A1 there are 6 individuals with very low 
education level, 21 with low education level, etc.

I need to compute a score for each area that reflects the education 
level in this area. This can be done by using correspondence 
analysis: The scores on the first factor represent an optimal scaling 
in a certain sense (see the book of Greenacre (1984) "Theory and 
applications of correspondence analysis" for instance). In other 
words, I have to transform my ordinal variable "EducationLevel" into 
a continuous variable "EducationScore".

However, this procedure does not account for the fact that one of my 
variables (EducationLevel) is ordinal. For instance, the weights 
obtained after performing the correspondence analysis could be 
non-monotically increasing (weights used in order to compute the 
projection on the first factor).

In summary, the question is:

(1) Are there statistical procedures that account for the ordinal 
nature of the Level variable (so that the weights are monotically 
increasing: order constraints on the weights) ?

(2) Are these procedures implemented in R or S-Plus ?

Please, feel free to answer to "saerens at ulb.ac.be".

Many Thanks !!

Marco Saerens
-- 

      """
      ? ?
_oOO-(_)-OOo______________________________________________________________
Prof. Marco Saerens
Information Systems Research Unit (ISYS)
IAG
Universit? Catholique de Louvain            Tel:   +32(0)10.47.92.46.
Place des Doyens 1                          Fax:   +32(0)10.47.83.24.
B-1348 Louvain-la-Neuve                     Email: saerens at isys.ucl.ac.be
BELGIUM
__________________________________________________________________________

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct 10 13:40:37 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Oct 2002 13:40:37 +0200
Subject: [R] Re: [R-gui] NEdit Highligth patterns for R
In-Reply-To: <1034248750.5057.77.camel@gandalf>
References: <1034248750.5057.77.camel@gandalf>
Message-ID: <x2bs62wmh6.fsf@biostat.ku.dk>

Ernesto Jardim <ernesto at ipimar.pt> writes:
> 
> I've just submitted to the NEdit development team a R highligth patterns
> for NEdit (www.nedit.org).
> 
> NEdit is a text editor for LINUX which I use to write small R functions.

Actually, it would appear to be available for Win32 and MacOSX as
well. (Personally I'm still hooked on Emacs though, and would likely
be driven nuts by an editor that has a different interpretation of
things like Ctrl-A...)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Roger.Lee at hannover-re.com  Thu Oct 10 15:01:16 2002
From: Roger.Lee at hannover-re.com (Roger.Lee@hannover-re.com)
Date: Thu, 10 Oct 2002 14:01:16 +0100
Subject: [R] MIME-Version: 1.0
Message-ID: <B52265FE5857D7438959650383C622A3111C24@ie0x0001.hannover-re.grp>




Roger Lee
Hannover Life Reassurance (Ireland) Ltd
4 Custom House Plaza, IFSC, Dublin 1, Ireland
Tel: +353 1 612-5872 Fax: +353 1 673-6917
roger.lee at hannover-re.com
http://www.hannoverlifere.com



======   Legal Disclaimer   ======

As you may know, emails sent via Internet can easily be altered or manipulated by third persons. For this reason, we do not assume any responsibility for changes made to this message after it was sent.
Furthermore please note that the information (including any attachments) in this email is strictly confidential and solely intended for the addressee named above. If you are neither the intended recipient nor an employee or agent responsible for delivering this message to the intended recipient, we hereby notify you that any form of unauthorized use, publication, reproduction, copying or disclosure of this emails contents is not permitted.
If you have received this communication in error, please notify the sender and delete the email from your computer system.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Thu Oct 10 15:24:06 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 10 Oct 2002 14:24:06 +0100
Subject: [R] Re: [R-gui] NEdit Highligth patterns for R
In-Reply-To: <x2bs62wmh6.fsf@biostat.ku.dk>
References: <1034248750.5057.77.camel@gandalf> 
	<x2bs62wmh6.fsf@biostat.ku.dk>
Message-ID: <1034256247.5051.80.camel@gandalf>

Hi

It's true, you can use NEdit in windows with cygwin. I just don't like
these "emulation" environments.

Regards

EJ

On Thu, 2002-10-10 at 12:40, Peter Dalgaard BSA wrote:
> Ernesto Jardim <ernesto at ipimar.pt> writes:
> > 
> > I've just submitted to the NEdit development team a R highligth patterns
> > for NEdit (www.nedit.org).
> > 
> > NEdit is a text editor for LINUX which I use to write small R functions.
> 
> Actually, it would appear to be available for Win32 and MacOSX as
> well. (Personally I'm still hooked on Emacs though, and would likely
> be driven nuts by an editor that has a different interpretation of
> things like Ctrl-A...)
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Thu Oct 10 15:37:11 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 10 Oct 2002 14:37:11 +0100
Subject: [R] Re: [R-gui] NEdit Highligth patterns for R
Message-ID: <1034257031.6926.85.camel@gandalf>

-----Forwarded Message-----

> From: Ernesto Jardim <ernesto at ipimar.pt>
> To: Agustin Lobo <alobo at ija.csic.es>
> Subject: Re: [R-gui] NEdit Highligth patterns for R
> Date: 10 Oct 2002 14:36:24 +0100
> 
> Hi
> 
> You have to install the *.pats file.
> 
> Use 
> 
> nedit -import R-5.1.pats
> 
> then "save defaults".
> 
> If you inspect the R-5.1.pats file there's a small description of the
> instalation procedure.
> 
> Regards
> 
> EJ
> 
> On Thu, 2002-10-10 at 14:24, Agustin Lobo wrote:
> > Ernesto,
> > Where should we copy to the *.pats file and
> > how can we add R to the list of languages within
> > nedit? I do not see any  *.pats file
> > in the nedit tar file.
> > 
> > Agus
> > 
> > Dr. Agustin Lobo
> > Instituto de Ciencias de la Tierra (CSIC)
> > Lluis Sole Sabaris s/n
> > 08028 Barcelona SPAIN
> > tel 34 93409 5410
> > fax 34 93411 0012
> > alobo at ija.csic.es
> > 
> > 
> > On 10 Oct 2002, Ernesto Jardim wrote:
> > 
> > > Hi
> > > 
> > > I've just submitted to the NEdit development team a R highligth patterns
> > > for NEdit (www.nedit.org).
> > > 
> > > NEdit is a text editor for LINUX which I use to write small R functions.
> > > In my opinion is a very good tool for small scripts, maybe for huge
> > > projects is not the best.
> > > 
> > > I'm attaching the R-5.1.pats file so you can try it. 
> > > 
> > > As usual contributions and comments are welcome.
> > > 
> > > Regards
> > > 
> > > EJ 
> > > 
> > > 
> > > 
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Roger.Lee at hannover-re.com  Thu Oct 10 15:27:59 2002
From: Roger.Lee at hannover-re.com (Roger.Lee@hannover-re.com)
Date: Thu, 10 Oct 2002 14:27:59 +0100
Subject: [R] help ! calculating relative mortality using survival5
Message-ID: <B52265FE5857D7438959650383C622A3112CCB@ie0x0001.hannover-re.grp>

Hi All,

I am relatively new to R (took a class 2 yrs ago ...), and am hoping someone can point me in the right direction for a problem I'd like to solve in R :

I would like to calculate the relative mortality of a particular impairment, relative to the standard population. 

I.e. I'm trying to find S_relative(t) in the eqn below :

  S_impar(t) = S_standard(t) * S_relative(t)

where S_standard(t) is the mortality of the general population, and S_impar is the mortality of the the impaired group under consideration.

Is doing something like this possible in R ?

I have a dataset for an impaired group containing survival time (x), and an right-censoring indicator (ind), from which I can get the estimated survival function S_impar(t), using something like fit<-survfit(Surv(x,ind)~1).

And from some statistics literature, I gather I can get what I want using "ratetable", "survexp" and "offset".

But I've poured through the help files, but I still have some questions ... specifically, 

I have a table of probabilities of death on each day for each age for the general population. How do I convert that into a table that ratetable can use ? And how would I read in that table ? (i.e. How do I get S_standard(t) from the table I have ?)

And what is the survfit function to use to calculate S_relative(t) ? 

Any ideas ? If someone has done something similar to this, I'd love to hear their approach. Thanks you so much !

Roger



Roger Lee
Hannover Life Reassurance (Ireland) Ltd
4 Custom House Plaza, IFSC, Dublin 1, Ireland
Tel: +353 1 612-5872 Fax: +353 1 673-6917
roger.lee at hannover-re.com
http://www.hannoverlifere.com



======   Legal Disclaimer   ======

As you may know, emails sent via Internet can easily be altered or manipulated by third persons. For this reason, we do not assume any responsibility for changes made to this message after it was sent.
Furthermore please note that the information (including any attachments) in this email is strictly confidential and solely intended for the addressee named above. If you are neither the intended recipient nor an employee or agent responsible for delivering this message to the intended recipient, we hereby notify you that any form of unauthorized use, publication, reproduction, copying or disclosure of this emails contents is not permitted.
If you have received this communication in error, please notify the sender and delete the email from your computer system.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mastropi at uwalumni.com  Thu Oct 10 15:50:00 2002
From: mastropi at uwalumni.com (Daniel Mastropietro)
Date: Thu, 10 Oct 2002 10:50:00 -0300
Subject: [R] Generating AR1 data
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIAEOBCGAA.abunn59715@earthlink.net>
Message-ID: <4.2.2.20021010104823.00ae1660@pop3.norton.antivirus>

Try arima.sim() in the ts package.

At 12:16 AM 10/10/2002 -0600, Andy Bunn wrote:
>Hi, Is there an easy way to generate data with temporal autocorrelation? I
>want to generate data with something like rnorm where I can specify the
>mean, variance and time lag. Does such a thing exist?
>
>Yours, AB

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hennig at stat.math.ethz.ch  Thu Oct 10 16:02:00 2002
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Thu, 10 Oct 2002 16:02:00 +0200 (CEST)
Subject: [R] Correspondence analysis/optimal scaling with ordinal variable
In-Reply-To: <p05111a00b9cb1b9e53a1@[130.104.153.118]>
Message-ID: <Pine.LNX.4.44.0210101558220.26678-100000@florence>

Dear Marco, 

although I am not really an expert in this, it may be helpful to consider
the Wiley-book A. Gifi "Nonlinear multivariate analysis" (1990) or perhaps
the paper by Michailidis and de Leeuw about the "Gifi system":

http://citeseer.nj.nec.com/cache/papers/cs/14429/http:zSzzSzwww.stat.ucla.eduzSzpaperszSzpreprintszSz204zSz204.pdf/michailidis98gifi.pdf

The keyword should be "nonlinear principal components".
I do not know about implementations in R.

Best,
Christian

On Thu, 10 Oct 2002, Marco Saerens wrote:

> Dear R specialists,
> 
> I have a multivariate statistics question that I want to submit to 
> the R community (which conveys a very good statistical knowledge).
> 
> I need to perform an optimal scaling based on a discrete variable and 
> an ordinal variable. The discrete variable, Area, defines a 
> geographical area. The ordinal variable, EducationLevel, describes 
> the education level of individuals (the ordinal factors are 
> "VeryLow", "Low, "Medium", "Large", "VeryLarge").
> 
> I have a data set specifying, for each area (rows), the number of 
> individuals in this area having a given education level (columns). It 
> looks like:
> 
> Area    VeryLow    Low    Medium    Large    VeryLarge
> A1         6        21      15        11         0
> A2         2         4       8        17         9
> etc
> 
> Meaning that in area A1 there are 6 individuals with very low 
> education level, 21 with low education level, etc.
> 
> I need to compute a score for each area that reflects the education 
> level in this area. This can be done by using correspondence 
> analysis: The scores on the first factor represent an optimal scaling 
> in a certain sense (see the book of Greenacre (1984) "Theory and 
> applications of correspondence analysis" for instance). In other 
> words, I have to transform my ordinal variable "EducationLevel" into 
> a continuous variable "EducationScore".
> 
> However, this procedure does not account for the fact that one of my 
> variables (EducationLevel) is ordinal. For instance, the weights 
> obtained after performing the correspondence analysis could be 
> non-monotically increasing (weights used in order to compute the 
> projection on the first factor).
> 
> In summary, the question is:
> 
> (1) Are there statistical procedures that account for the ordinal 
> nature of the Level variable (so that the weights are monotically 
> increasing: order constraints on the weights) ?
> 
> (2) Are these procedures implemented in R or S-Plus ?
> 
> Please, feel free to answer to "saerens at ulb.ac.be".
> 
> Many Thanks !!
> 
> Marco Saerens
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (current)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Oct 10 16:24:20 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 10 Oct 2002 07:24:20 -0700 (PDT)
Subject: [R] Aggregating data -- table almost does it
In-Reply-To: <1034232517.2821.39.camel@CPE-144-132-182-167>
Message-ID: <Pine.A41.4.44.0210100723190.90812-100000@homer33.u.washington.edu>

On 10 Oct 2002, Mike Nielsen wrote:

> Now, I would like to (for example) count the number of events (or maybe
> find the mean of a certain variable) in each hour of each day.  To
> count, I could use:
>
> > table(as.character(dates(fred$dates.chron)),hours(fred$dates.chron))
>
>            10 11  12   13 14
>   09/19/02  3 63 112 3042 23
>
> (there is, so far, only one day's worth of events in the data frame).
>
> To do fancier stuff, I know I could use aggregate.
>
> However, I only get a column for each hour in which there was an event.
> What I would dearly love to have is 24 columns, with 0 (zero) indicating
> that there were no events in that hour of that day.
>

You can define a factor with 24 levels, then they will all be used in
table
> table(data)
data
 1  2  3  4  5  6  7  8  9 10
 3  7 14 22 16 12 13  5  2  6
> table(factor(data,levels=1:24))

 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 3  7 14 22 16 12 13  5  2  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0


	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgilbert at bank-banque-canada.ca  Thu Oct 10 17:36:18 2002
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 10 Oct 2002 11:36:18 -0400
Subject: [R] polynomial
References: <Pine.LNX.4.44.0210091529230.11575-100000@bolker.zoo.ufl.edu>
Message-ID: <3DA59E72.99FF768F@bank-banque-canada.ca>

Ben Bolker wrote:
> 
>   Any better (more efficient, built-in) ideas for computing
> 
>  coef[1]+coef[2]*x+coef[3]*x^2+ ...
> 
>  than
> 
> polynom <- function(coef,x) {
>   n <- length(coef)
> 
> sum(coef*apply(matrix(c(rep(x,n),seq(0,n-1)),ncol=2),1,function(z)z[1]^z[2]))
> }
> 

You should be aware that accuracy rather than efficiency is often a
problem with this representation of high order polynomials. Acton (1970)
gives an example of an order 20 polynomial where extremely small changes
in the coefficients of high order terms result in large changes in the
roots. If your intention is to evaluate the polynomial value then you
will want to consider a Horner scheme. If your intention is to find the
polynomial roots then you should try to avoid the polynomial coefficient
representation if at all possible.

This problem comes up in ARMA and VAR time series models, where
stability of the models is determined by the roots of the determinant of
the AR polynomial matrix. For multivariate models this can be a fairly
high order polynomial. There is a much better way to calculate the roots
in this case.

Paul Gilbert
-----
Acton, F. S. (1970) Numerical Methods that Work, Harper & Row, NY.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Thu Oct 10 17:43:11 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Thu, 10 Oct 2002 08:43:11 -0700
Subject: [R] Correspondence analysis/optimal scaling with ordinal variable
In-Reply-To: <p05111a00b9cb1b9e53a1@[130.104.153.118]>
Message-ID: <FB68FD28-DC66-11D6-A3DB-000393860F3C@stat.ucla.edu>

ftp://gifi.stat.ucla.edu/pub/homalsR.tar.gz does "correspondence
analysis" for an arbitrary number of variables (not just 2), each of
which can be treated as numerical, ordinal, or nominal. In fact, it
can do much more.

It has a nice tcl/tk interface, and the documentation is abysmal.

On Thursday, October 10, 2002, at 05:36 AM, Marco Saerens wrote:

> Dear R specialists,
>
> I have a multivariate statistics question that I want to submit to the  
> R community (which conveys a very good statistical knowledge).
>
> I need to perform an optimal scaling based on a discrete variable and  
> an ordinal variable. The discrete variable, Area, defines a  
> geographical area. The ordinal variable, EducationLevel, describes the  
> education level of individuals (the ordinal factors are "VeryLow",  
> "Low, "Medium", "Large", "VeryLarge").
>
> I have a data set specifying, for each area (rows), the number of  
> individuals in this area having a given education level (columns). It  
> looks like:
>
> Area    VeryLow    Low    Medium    Large    VeryLarge
> A1         6        21      15        11         0
> A2         2         4       8        17         9
> etc
>
> Meaning that in area A1 there are 6 individuals with very low  
> education level, 21 with low education level, etc.
>
> I need to compute a score for each area that reflects the education  
> level in this area. This can be done by using correspondence analysis:  
> The scores on the first factor represent an optimal scaling in a  
> certain sense (see the book of Greenacre (1984) "Theory and  
> applications of correspondence analysis" for instance). In other  
> words, I have to transform my ordinal variable "EducationLevel" into a  
> continuous variable "EducationScore".
>
> However, this procedure does not account for the fact that one of my  
> variables (EducationLevel) is ordinal. For instance, the weights  
> obtained after performing the correspondence analysis could be  
> non-monotically increasing (weights used in order to compute the  
> projection on the first factor).
>
> In summary, the question is:
>
> (1) Are there statistical procedures that account for the ordinal  
> nature of the Level variable (so that the weights are monotically  
> increasing: order constraints on the weights) ?
>
> (2) Are these procedures implemented in R or S-Plus ?
>
> Please, feel free to answer to "saerens at ulb.ac.be".
>
> Many Thanks !!
>
> Marco Saerens
> --  
>
>      """
>      ? ?
> _oOO-(_)- 
> OOo______________________________________________________________
> Prof. Marco Saerens
> Information Systems Research Unit (ISYS)
> IAG
> Universit? Catholique de Louvain            Tel:   +32(0)10.47.92.46.
> Place des Doyens 1                          Fax:   +32(0)10.47.83.24.
> B-1348 Louvain-la-Neuve                     Email:  
> saerens at isys.ucl.ac.be
> BELGIUM
> _______________________________________________________________________ 
> ___
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Thu Oct 10 18:20:19 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 10 Oct 2002 17:20:19 +0100
Subject: [R] contour in lattice
Message-ID: <1034266821.5051.107.camel@gandalf>

Hi

I'm using lattice's function levelplot but when I choose the flag
contour =TRUE I get very strange results. It looks like the contour
lines have nothing to do with the "image" plot under ...

Is there some known problem with this function ?

Regards

EJ

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From arc at arcriswell.com  Fri Oct 11 06:25:51 2002
From: arc at arcriswell.com (Andrew Criswell)
Date: Fri, 11 Oct 2002 11:25:51 +0700
Subject: [R] Correspondence analysis/optimal scaling with ordinal variable
References: <p05111a00b9cb1b9e53a1@[130.104.153.118]>
Message-ID: <00a401c270de$4933d720$82d994cb@andrewvhowclyz>

Dear Marco:

Alan Agresti in "Categorical Data Analysis," p. 291-3 describes the use of
correspondence analysis and provides an example.

Laura Thompson in "Splus Manual to Accompany Agresti's Categorical Data
Analysis" implements Agresti's example on p. 45-6. Some slight modifications
will render the example in R.  Her paper can be found on

http://math.cl.uh.edu/~thompsonla/5537/Splusdiscrete.PDF

This might be of benefit to your work.

Best wishes,
ANDREW

Andrew Criswell
Professor of Finance
Graduate School, Bangkok University


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Thu Oct 10 18:41:10 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 10 Oct 2002 17:41:10 +0100
Subject: [R] Variance in interp (akima)
Message-ID: <1034268070.5057.110.camel@gandalf>

Hi

Is there a way of getting variances in linear interpolation with akima ?
Is there other function that make linear interpolation and estimates
variances ?

Regards
 
EJ



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Thu Oct 10 20:28:34 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Thu, 10 Oct 2002 18:28:34 +0000
Subject: [R] Extracting p values from object of class `"pairwise.htest"'
Message-ID: <15781.50898.865635.202325@hugo.paed.uni-muenchen.de>

Hi,

can I extract the p-values after a pairwise comparision with
pairwise.t.test()? The object of class "pairwise.htest". 

Thanks, Sven

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From putler at commerce.ubc.ca  Thu Oct 10 18:33:01 2002
From: putler at commerce.ubc.ca (Dan Putler)
Date: Thu, 10 Oct 2002 09:33:01 -0700
Subject: [R] Re: [R-gui] NEdit Highligth patterns for R
In-Reply-To: <1034256247.5051.80.camel@gandalf>
References: <1034248750.5057.77.camel@gandalf>
 <x2bs62wmh6.fsf@biostat.ku.dk>
 <1034256247.5051.80.camel@gandalf>
Message-ID: <200210100933010600.0020E828@smtp.interchange.ubc.ca>

Hi All,

Zed Shaw has written an R/S context highlighter for JEdit (www.jedit.org), an open source text editor written in Java (no need for Cygwin, and it runs on Macs as well).  The URL to the highlighter is http://community.jedit.org/modules.php?op=modload&name=downloads&file=index&req=getit&lid=217

Dan
  

*********** REPLY SEPARATOR  ***********

On 10/10/2002 at 2:24 PM Ernesto Jardim wrote:

>Hi
>
>It's true, you can use NEdit in windows with cygwin. I just don't like
>these "emulation" environments.
>
>Regards
>
>EJ
>
>On Thu, 2002-10-10 at 12:40, Peter Dalgaard BSA wrote:
>> Ernesto Jardim <ernesto at ipimar.pt> writes:
>> > 
>> > I've just submitted to the NEdit development team a R highligth
>patterns
>> > for NEdit (www.nedit.org).
>> > 
>> > NEdit is a text editor for LINUX which I use to write small R
>functions.
>> 
>> Actually, it would appear to be available for Win32 and MacOSX as
>> well. (Personally I'm still hooked on Emacs though, and would likely
>> be driven nuts by an editor that has a different interpretation of
>> things like Ctrl-A...)
>> 
>> -- 
>>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>> r-help mailing list -- Read
>http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>>
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
>
>_______________________________________________
>R-SIG-GUI mailing list
>R-SIG-GUI at stat.math.ethz.ch
>http://www.stat.math.ethz.ch/mailman/listinfo/r-sig-gui


_________________________________________
Dan Putler
UBC Commerce
Email: putler dot commerce dot ubc dot ca
Phone: 604-822-8329



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From reid_huntsinger at merck.com  Thu Oct 10 18:44:52 2002
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Thu, 10 Oct 2002 12:44:52 -0400
Subject: [R] temporal simulation
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC1A0@uswpmx11.merck.com>

One way to do this (for the interval [0,T]) is to first generate the total
count n (from a mixture of Poissons), then generate an iid sample of n draws
from the normalized intensity (representing the event times). (Then you
probably want to sort them.) 

How to do these steps depends on the mixing distribution and normalized
intensity. If the mixing distribution is discrete, say contained in vectors
"intensity" (intensity value) and "p" (probability), you could generate a
vector of N counts from the mixture as follows:

lambda <- sample(x=intensity, size=N, replace=TRUE, prob=p)
n <- rpois(n=N,lambda=lambda)

In general you need a way like "sample" to draw a sample from your mixing
distribution (and your normalized intensity). The "r" functions (rgamma,
etc) might help if you are using common distributions.

For example if you wanted a constant intensity, you could use runif as
follows to get a list of N draws from the process:

draws <- runif(sum(n),min=0,max=T) # all strung together
f <- rep(1:N,n)                    # vector indicates group 
                                   #   membership (simulation trial #) of
event
sim <- split(draws,f)              # chop draws up into trial i with n[i]
events


Reid Huntsinger

-----Original Message-----
From: Elaine Hand [mailto:hande at tcd.ie]
Sent: Tuesday, October 08, 2002 7:04 AM
To: r-help at stat.math.ethz.ch
Subject: [R] temporal simulation


Hello,

I am new to R and was wondering if anybody would be able to advice me 
on the following query. Is there any package available to generate a 
mixed Poisson process, temporal data, using R? If anybody has 
accomplished this before or has any advice I would appreciate it.

Regards,

Elaine Hand
-- 


Elaine Hand
Department of Community Health & General Practice
Trinity College Dublin
Trinity Centre for Health Sciences
AMNCH
Dublin 24
Ireland

email: hande at tcd.ie
telephone: +353 1 608 3460
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Thu Oct 10 18:59:11 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Thu, 10 Oct 2002 09:59:11 -0700
Subject: [R] Correspondence analysis/optimal scaling with ordinal variable
In-Reply-To: <Pine.LNX.4.44.0210101558220.26678-100000@florence>
Message-ID: <995D5B00-DC71-11D6-A3DB-000393860F3C@stat.ucla.edu>

The paper is in Statistical Science, 1998, 13, 307-336

The homals program in R (ftp://gifi.stat.ucla.edu/pub/homalsR.tar.gz)
has, in the Gifi terminology, homals and princals and overals (and
a few new extensions). It will be packaged soon, I hope.


On Thursday, October 10, 2002, at 07:02 AM, Christian Hennig wrote:

> Dear Marco,
>
> although I am not really an expert in this, it may be helpful to  
> consider
> the Wiley-book A. Gifi "Nonlinear multivariate analysis" (1990) or  
> perhaps
> the paper by Michailidis and de Leeuw about the "Gifi system":
>
> http://citeseer.nj.nec.com/cache/papers/cs/14429/ 
> http:zSzzSzwww.stat.ucla.eduzSzpaperszSzpreprintszSz204zSz204.pdf/ 
> michailidis98gifi.pdf
>
> The keyword should be "nonlinear principal components".
> I do not know about implementations in R.
>
> Best,
> Christian
>
> On Thu, 10 Oct 2002, Marco Saerens wrote:
>
>> Dear R specialists,
>>
>> I have a multivariate statistics question that I want to submit to
>> the R community (which conveys a very good statistical knowledge).
>>
>> I need to perform an optimal scaling based on a discrete variable and
>> an ordinal variable. The discrete variable, Area, defines a
>> geographical area. The ordinal variable, EducationLevel, describes
>> the education level of individuals (the ordinal factors are
>> "VeryLow", "Low, "Medium", "Large", "VeryLarge").
>>
>> I have a data set specifying, for each area (rows), the number of
>> individuals in this area having a given education level (columns). It
>> looks like:
>>
>> Area    VeryLow    Low    Medium    Large    VeryLarge
>> A1         6        21      15        11         0
>> A2         2         4       8        17         9
>> etc
>>
>> Meaning that in area A1 there are 6 individuals with very low
>> education level, 21 with low education level, etc.
>>
>> I need to compute a score for each area that reflects the education
>> level in this area. This can be done by using correspondence
>> analysis: The scores on the first factor represent an optimal scaling
>> in a certain sense (see the book of Greenacre (1984) "Theory and
>> applications of correspondence analysis" for instance). In other
>> words, I have to transform my ordinal variable "EducationLevel" into
>> a continuous variable "EducationScore".
>>
>> However, this procedure does not account for the fact that one of my
>> variables (EducationLevel) is ordinal. For instance, the weights
>> obtained after performing the correspondence analysis could be
>> non-monotically increasing (weights used in order to compute the
>> projection on the first factor).
>>
>> In summary, the question is:
>>
>> (1) Are there statistical procedures that account for the ordinal
>> nature of the Level variable (so that the weights are monotically
>> increasing: order constraints on the weights) ?
>>
>> (2) Are these procedures implemented in R or S-Plus ?
>>
>> Please, feel free to answer to "saerens at ulb.ac.be".
>>
>> Many Thanks !!
>>
>> Marco Saerens
>>
>
> -- 
> ***********************************************************************
> Christian Hennig
> Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (current)
> and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
> hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
> hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
> #######################################################################
> ich empfehle www.boag.de
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andys at neptuneinc.org  Thu Oct 10 19:16:42 2002
From: andys at neptuneinc.org (Andrew Schuh)
Date: Thu, 10 Oct 2002 11:16:42 -0600
Subject: [R] cex in Windows vs. Linux
Message-ID: <200210101116.42224.andys@neptuneinc.org>

I go back and forth from Linux to Windoze often and have to run the same 
r-scripts.  I was wondering why it seems like the default plotting size of 
labels, symbols, titles, etc seem smaller in Linux than in Windows.  Is there 
a quick way to remedy this so I don't have to manually change the cex 
settings from 1 to 1.3 every time I go from Windoze to Linux?
-- 
Sincerely,

+++++++++++*******+++++***++*
Andrew Schuh
Environmental Mathematician
Neptune and Co.
(505) 884-8455
andys at neptuneinc.org
+++++++++++*******+++++***++*
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Thu Oct 10 18:30:12 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Thu, 10 Oct 2002 12:30:12 -0400
Subject: [R] Generating AR1 data
References: <NEBBIPHDAMMOKDKPOFFIAEOBCGAA.abunn59715@earthlink.net>
Message-ID: <3DA5AB14.F22CCBD0@umsanet.edu.bo>

help.search("arima.sim")
> 


gives the result:

Help files with alias or title matching `arima.sim',
type `help(FOO, package = PKG)' to inspect entry `FOO(PKG) TITLE':

arima.sim(boot)         Simulate from an ARIMA Model
arima.sim(ts)           Simulate from an ARIMA Model


Kjetil Halvorsen

Andy Bunn wrote:
> 
> Hi, Is there an easy way to generate data with temporal autocorrelation? I
> want to generate data with something like rnorm where I can specify the
> mean, variance and time lag. Does such a thing exist?
> 
> Yours, AB
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zeileis at ci.tuwien.ac.at  Thu Oct 10 19:38:43 2002
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Thu, 10 Oct 2002 19:38:43 +0200
Subject: [R] Extracting p values from object of class `"pairwise.htest"'
References: <15781.50898.865635.202325@hugo.paed.uni-muenchen.de>
Message-ID: <3DA5BB23.F28D66E1@ci.tuwien.ac.at>

Sven Garbade wrote:
> 
> Hi,
> 
> can I extract the p-values after a pairwise comparision with
> pairwise.t.test()? The object of class "pairwise.htest".

This is a list with one component being "p.value". You can extract it as
usual with
  pairwise.t.test()$p.value

> Thanks, Sven
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Thu Oct 10 19:41:18 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Thu, 10 Oct 2002 13:41:18 -0400
Subject: [R] Re: [R-gui] NEdit Highligth patterns for R
In-Reply-To: <200210100933010600.0020E828@smtp.interchange.ubc.ca>
References: <1034248750.5057.77.camel@gandalf> <x2bs62wmh6.fsf@biostat.ku.dk> <1034256247.5051.80.camel@gandalf> <200210100933010600.0020E828@smtp.interchange.ubc.ca>
Message-ID: <20021010174118.GA1372@komensky.surfbest.net>

On Thu, Oct 10, 2002 at 09:33:01AM -0700, Dan Putler wrote:
> Zed Shaw has written an R/S context highlighter for JEdit
> (www.jedit.org), an open source text editor written in Java (no
> need for Cygwin, and it runs on Macs as well).  The URL to the

I believe that NEdit is a native Windows application (but I am
not sure using gvim under Linux most of the time) so no need of
both cygwin and Java.

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
The law, in its majestic equality, forbids the rich as well as
the poor to sleep under bridges, to beg in the streets, and to
steal bread.
    -- Anatole France

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Thu Oct 10 21:54:21 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Thu, 10 Oct 2002 19:54:21 +0000
Subject: [R] Extracting t values from object of class `"pairwise.htest"'
In-Reply-To: <3DA5BB23.F28D66E1@ci.tuwien.ac.at>
References: <15781.50898.865635.202325@hugo.paed.uni-muenchen.de>
	<3DA5BB23.F28D66E1@ci.tuwien.ac.at>
Message-ID: <15781.56045.795838.483951@hugo.paed.uni-muenchen.de>

Achim Zeileis writes:
 > Sven Garbade wrote:
 > > 
 > > Hi,
 > > 
 > > can I extract the p-values after a pairwise comparision with
 > > pairwise.t.test()? The object of class "pairwise.htest".
 > 
 > This is a list with one component being "p.value". You can extract it as
 > usual with
 >   pairwise.t.test()$p.value

Sorry, I don't mean the p-values, but the t-values.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Thu Oct 10 21:56:17 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: 10 Oct 2002 19:56:17 +0000
Subject: No subject
Message-ID: <87adlm5aqm.fsf@hugo.paed.uni-muenchen.de>

Achim Zeileis writes:
 > Sven Garbade wrote:
 > > 
 > > Hi,
 > > 
 > > can I extract the p-values after a pairwise comparision with
 > > pairwise.t.test()? The object of class "pairwise.htest".
 > 
 > This is a list with one component being "p.value". You can extract it as
 > usual with
 >   pairwise.t.test()$p.value

Sorry, I don't mean the p-values, but the t-values.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Thu Oct 10 20:31:58 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 10 Oct 2002 14:31:58 -0400
Subject: [R] tapply for matrices
Message-ID: <20021010143158.0a3f75d3.fharrell@virginia.edu>

Does anyone have something like tapply that is extremely fast for matrices when there is a very large number of levels of the grouping variable?  
I'm referring to, for example, 

tapply(x, grouping.variable, function.operating.on.submatrix)

where x is a matrix and the submatrix is a subset of the rows of x.  The grouping variable's length equals the number of rows of x.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Thu Oct 10 20:57:05 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 10 Oct 2002 13:57:05 -0500
Subject: [R] Extracting t values from object of class `"pairwise.htest"'
In-Reply-To: <15781.56045.795838.483951@hugo.paed.uni-muenchen.de>
Message-ID: <007301c2708e$d3f8a570$0201a8c0@MARC>

> -----Original Message-----
> Achim Zeileis writes:
>  > Sven Garbade wrote:
>  > >
>  > > Hi,
>  > >
>  > > can I extract the p-values after a pairwise comparision with
>  > > pairwise.t.test()? The object of class "pairwise.htest".
>  >
>  > This is a list with one component being "p.value". You can extract
it as
>  > usual with
>  >   pairwise.t.test()$p.value
> 
> Sorry, I don't mean the p-values, but the t-values.

That would be:

pairwise.t.test(...)$statistic

Look at ?t.test and scroll to the "Value" section which defines the list
components returned.

HTH.

Marc



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Thu Oct 10 21:50:57 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 10 Oct 2002 15:50:57 -0400
Subject: [R] Re: [S] tapply for matrices
In-Reply-To: <5.1.0.14.2.20021010124853.04a23ea0@mailhost.blackmesacapital.com>
References: <20021010143158.0a3f75d3.fharrell@virginia.edu>
	<5.1.0.14.2.20021010124853.04a23ea0@mailhost.blackmesacapital.com>
Message-ID: <20021010155057.5d51136d.fharrell@virginia.edu>

Tony Plate provided what seems to be a very fast and elegant solution - see below.  I have modified his solution slightly:

mapply <- function(X, INDEX, FUN=NULL, ..., simplify=TRUE) {
## Matrix tapply
## X: matrix with n rows; INDEX: vector or list of vectors of length n
## FUN: function to operate on submatrices of x by INDEX
## ...: arguments to FUN; simplify: see sapply
## Modification of code by Tony Plate <tplate at blackmesacapital.com> 10Oct02
idx.list <- tapply(seq(nrow(X)), INDEX, c)
sapply(idx.list, function(idx,x,fun,...) fun(x[idx,,drop=FALSE],...),
       x=X, fun=FUN, ..., simplify=simplify)
}

Example: mapply(x, groups, quantile, probs=c(.25,.5)) will create a matrix of first and second quartiles of submatrices of x grouped by groups.

The usages I have for this right now are certain within-subject bivariate summaries when subjects have multiple rows of data.

Thanks Tony,

Frank

P.S.  Dave Krantz <dhk at paradox.psych.columbia.edu> reported that he wrote a function mtapply that uses for loops for this but that pays a lot of attention to formatting the output as an array with sensible dimnames.

On Thu, 10 Oct 2002 12:51:54 -0600
Tony Plate <tplate at blackmesacapital.com> wrote:

> I use the following idiom for this:
> 
> idx.list <- tapply(seq(numRows(x)), x[,grouping.variable], c)
> lapply(idx.list, function(idx, x) {
>     submatrix <- x[idx,,drop=F]
>     ... operate on submatrix ...
> }, x)
> 
> which seems pretty fast.  I sometimes sort x beforehand so that rows with 
> the same value of the grouping variable are adjacent.
> 
> Hope this helps,
> 
> Tony Plate
> 
> PS. Please excuse me if the above code has any typos -- it's from memory.
> 
> At 02:31 PM 10/10/2002 -0400, you wrote:
> >Does anyone have something like tapply that is extremely fast for matrices 
> >when there is a very large number of levels of the grouping variable?
> >I'm referring to, for example,
> >
> >tapply(x, grouping.variable, function.operating.on.submatrix)
> >
> >where x is a matrix and the submatrix is a subset of the rows of x.  The 
> >grouping variable's length equals the number of rows of x.
> >--

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chrysopa at insecta.ufv.br  Thu Oct 10 22:38:44 2002
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Thu, 10 Oct 2002 17:38:44 -0300
Subject: [R] CRAN mirror
Message-ID: <200210101738.44412.chrysopa@insecta.ufv.br>

Hi
how I must make to officialize my mirror in the main R website?

My CRAN's mirror is sited in Federal University of Vi?osa in Minas Gerais 
State - Brazil.

The address is:

http://www.termix.ufv.br/CRAN

It is diary updated

Bie
Ronaldo

-- 
Q:	How does a hacker fix a function which
	doesn't work for all of the elements in its domain?
A:	He changes the domain.
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][SO: CL 7.0 (2.2.19)]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Conectiva Linux 7.0 D+:) | Lxuser#: 205366

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct 10 22:31:35 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Oct 2002 22:31:35 +0200
Subject: [R] Extracting t values from object of class `"pairwise.htest"'
In-Reply-To: <007301c2708e$d3f8a570$0201a8c0@MARC>
References: <007301c2708e$d3f8a570$0201a8c0@MARC>
Message-ID: <x27kgqyr14.fsf@biostat.ku.dk>

"Marc Schwartz" <mschwartz at medanalytics.com> writes:

> > -----Original Message-----
> > Achim Zeileis writes:
> >  > Sven Garbade wrote:
> >  > >
> >  > > Hi,
> >  > >
> >  > > can I extract the p-values after a pairwise comparision with
> >  > > pairwise.t.test()? The object of class "pairwise.htest".
> >  >
> >  > This is a list with one component being "p.value". You can extract
> it as
> >  > usual with
> >  >   pairwise.t.test()$p.value
> > 
> > Sorry, I don't mean the p-values, but the t-values.
> 
> That would be:
> 
> pairwise.t.test(...)$statistic
> 
> Look at ?t.test and scroll to the "Value" section which defines the list
> components returned.

But pairwise.t.test doesn't return the individual t statistics. It
ends with

    ans <- list(method = METHOD, data.name = DNAME, p.value = PVAL, 
        p.adjust.method = p.adjust.method)
    class(ans) <- "pairwise.htest"
    ans

so you'd have to modify the function to get at the actual t statistics.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct 10 22:39:27 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Oct 2002 22:39:27 +0200
Subject: [R] Re: [S] tapply for matrices
In-Reply-To: <20021010155057.5d51136d.fharrell@virginia.edu>
References: <20021010143158.0a3f75d3.fharrell@virginia.edu>
	<5.1.0.14.2.20021010124853.04a23ea0@mailhost.blackmesacapital.com>
	<20021010155057.5d51136d.fharrell@virginia.edu>
Message-ID: <x23creyqo0.fsf@biostat.ku.dk>

Frank E Harrell Jr <fharrell at virginia.edu> writes:

> Tony Plate provided what seems to be a very fast and elegant solution - see below.  I have modified his solution slightly:
> 
> mapply <- function(X, INDEX, FUN=NULL, ..., simplify=TRUE) {
> ## Matrix tapply

Before this propagates too far: The name "mapply" has also been
suggested for a "multiple apply", which is like lapply/sapply but
takes multiple X arguments and a FUN of several arguments. So
perhaps matrix.apply() or so would be better?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Thu Oct 10 22:47:32 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 10 Oct 2002 16:47:32 -0400
Subject: [R] Re: [S] tapply for matrices
In-Reply-To: <x23creyqo0.fsf@biostat.ku.dk>
References: <20021010143158.0a3f75d3.fharrell@virginia.edu>
	<5.1.0.14.2.20021010124853.04a23ea0@mailhost.blackmesacapital.com>
	<20021010155057.5d51136d.fharrell@virginia.edu>
	<x23creyqo0.fsf@biostat.ku.dk>
Message-ID: <20021010164732.4b0fe55b.fharrell@virginia.edu>

Good idea Peter -Frank

On 10 Oct 2002 22:39:27 +0200
Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> wrote:

> Frank E Harrell Jr <fharrell at virginia.edu> writes:
> 
> > Tony Plate provided what seems to be a very fast and elegant solution - see below.  I have modified his solution slightly:
> > 
> > mapply <- function(X, INDEX, FUN=NULL, ..., simplify=TRUE) {
> > ## Matrix tapply
> 
> Before this propagates too far: The name "mapply" has also been
> suggested for a "multiple apply", which is like lapply/sapply but
> takes multiple X arguments and a FUN of several arguments. So
> perhaps matrix.apply() or so would be better?
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Thu Oct 10 22:49:01 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 10 Oct 2002 15:49:01 -0500
Subject: [R] Extracting t values from object of class `"pairwise.htest"'
In-Reply-To: <x27kgqyr14.fsf@biostat.ku.dk>
Message-ID: <008c01c2709e$77db9c60$0201a8c0@MARC>

> -----Original Message-----
> From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> 
> "Marc Schwartz" <mschwartz at medanalytics.com> writes:
> 
> > > -----Original Message-----
> > > Achim Zeileis writes:
> > >  > Sven Garbade wrote:
> > >  > >
> > >  > > Hi,
> > >  > >
> > >  > > can I extract the p-values after a pairwise comparision with
> > >  > > pairwise.t.test()? The object of class "pairwise.htest".
> > >  >
> > >  > This is a list with one component being "p.value". You can
extract
> > it as
> > >  > usual with
> > >  >   pairwise.t.test()$p.value
> > >
> > > Sorry, I don't mean the p-values, but the t-values.
> >
> > That would be:
> >
> > pairwise.t.test(...)$statistic
> >
> > Look at ?t.test and scroll to the "Value" section which defines the
list
> > components returned.
> 
> But pairwise.t.test doesn't return the individual t statistics. It
> ends with
> 
>     ans <- list(method = METHOD, data.name = DNAME, p.value = PVAL,
>         p.adjust.method = p.adjust.method)
>     class(ans) <- "pairwise.htest"
>     ans
> 
> so you'd have to modify the function to get at the actual t
statistics.

Thanks Peter.  I stand corrected.  I missed the now obvious and not so
subtle difference in the class objects of htest and pairwise.htest.

Marc



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From smichalske at apple.com  Thu Oct 10 23:47:51 2002
From: smichalske at apple.com (Steven Michalske)
Date: Thu, 10 Oct 2002 14:47:51 -0700
Subject: [R] looking for a quick solution
Message-ID: <ECBCBAD1-DC99-11D6-97BA-003065D4A1F4@apple.com>

Hello,

I have a large data set of points (120K) to large to open in most 
spreadsheet programs and i need to calculate the true RMS of the 
waveform.  The waveform is jagged,  how could i go about calculating 
the RMS value of all the data points from a table that i have read in?

Thank you for any help, i hope i posted this to the right list :-P

a quick search on mailing list archives provided no insight :-(

Steven Michalske

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brian.o'gorman at noaa.gov  Fri Oct 11 00:38:03 2002
From: brian.o'gorman at noaa.gov (Brian O'Gorman)
Date: Thu, 10 Oct 2002 14:38:03 -0800
Subject: [R] make check when installing R-1.6.0
Message-ID: <3DA6014B.8497B981@noaa.gov>

This is the result of my make check,  could anyone help me out on this
one?

     Formats: text example
running code in 'base-Ex.R' ...*** Error code 1
make: Fatal error: Command failed for target `base-Ex.Rout'
Current working directory /apps/R/R-1.6.0/tests/Examples
*** Error code 1
make: Fatal error: Command failed for target `test-Examples-Base'
Current working directory /apps/R/R-1.6.0/tests/Examples
*** Error code 1
make: Fatal error: Command failed for target `test-Examples'
Current working directory /apps/R/R-1.6.0/tests
*** Error code 1
make: Fatal error: Command failed for target `test-all-basics'
Current working directory /apps/R/R-1.6.0/tests
*** Error code 1
make: Fatal error: Command failed for target `check'

-------------- next part --------------
A non-text attachment was scrubbed...
Name: brian.o'gorman.vcf
Type: text/x-vcard
Size: 211 bytes
Desc: Card for Brian O'Gorman
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021010/9ec005ca/brian.ogorman.vcf

From latouche at linuxmail.org  Fri Oct 11 00:40:46 2002
From: latouche at linuxmail.org (aurelien latouche)
Date: Fri, 11 Oct 2002 06:40:46 +0800
Subject: [R] R 1.6.0 on alphaserver ds10
Message-ID: <20021010224046.9493.qmail@linuxmail.org>

hi,
i've succesfully built R 1.6.0
on a ds10 with a " stock" redhat 6.2
all tests are ok
i've installed the following packages
 survival and cmprsk succesfully
but when i use the crr function (cmprsk package)
i got a segmentation fault

my question is : 
any one build a R version with ev6 processor
(with or with out compaq fortran and c)

thanks

-- 
Get your free email from www.linuxmail.org 


Powered by Outblaze
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vito.muggeo at giustizia.it  Thu Oct 10 12:06:52 2002
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Thu, 10 Oct 2002 12:06:52 +0200
Subject: [R] Generating AR1 data
References: <NEBBIPHDAMMOKDKPOFFIAEOBCGAA.abunn59715@earthlink.net>
Message-ID: <009201c27044$cf3a80c0$5c13070a@it.giustizia.it>

See arima.sim() in the ts package;
also it seems there is another arima.sim() in the boot package, but I don't
know wheter it is the same.

best,
vito

----- Original Message -----
From: "Andy Bunn" <abunn59715 at earthlink.net>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, October 10, 2002 8:16 AM
Subject: [R] Generating AR1 data


> Hi, Is there an easy way to generate data with temporal autocorrelation? I
> want to generate data with something like rnorm where I can specify the
> mean, variance and time lag. Does such a thing exist?
>
> Yours, AB
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From keef9490 at uidaho.edu  Fri Oct 11 03:26:53 2002
From: keef9490 at uidaho.edu (Robert Keefe)
Date: Thu, 10 Oct 2002 18:26:53 -0700 (PDT)
Subject: [R] Re: [S] tapply for matrices
In-Reply-To: <x23creyqo0.fsf@biostat.ku.dk>
Message-ID: <Pine.GHP.4.30.0210101704380.26911-100000@falcon.csrv.uidaho.edu>


Hi All,

On a related note, I am a Newbie, and have written the
following function (below) as a much quicker alternative to
aggregate(). I wrote it because aggregate() seems to bog down
severely on the larger data frames that I work with (let's say
5000 x 50), and when the index variable has many levels, and when
multiple variables are used as indices. My version is just
combining tapply and sapply...

As far as I can tell, the only difference (aside from not
having methods for ts and/or other objects yet), is that my
function doesn't add columns containing the index variable(s)
in the output. (This can easily be added).

Perhaps people can comment on why the approach I've taken
may not be a good one (so that I can improve it, and learn more
about writing functions in general).

Thanks in advance for any suggestions or comments!

Cheers,

Rob


ag.fast <- function(x,by=NULL,FUN=NULL,...) {

 if(is.null(FUN)) stop("You need to specify a legitimate function.")
 FUN <- match.fun(FUN)
 n <- length(by)
 if(n==1)
   int <- by[1]
 else
   int <- interaction(by[1:n], drop=T)

 f <- function(x, FUN,...) {
   tapply(x,int,FUN,...)
  }

 x <- x[,1:ncol(x)]
 s <- sapply(x,f,FUN,...)
 s <- data.frame(cbind(s[,c(1:ncol(s))]))
 return(s)

}


____________

Rob Keefe
M.S. student
Department of Forest Resources
University of Idaho
PO Box 441133
Moscow, ID
83844-1133

Lab: (208) 885-5165
Home: (208) 882-9749




> Frank E Harrell Jr <fharrell at virginia.edu> writes:
>
> > Tony Plate provided what seems to be a very fast and elegant solution - see below.  I have modified his solution slightly:
> >
> > mapply <- function(X, INDEX, FUN=NULL, ..., simplify=TRUE) {
> > ## Matrix tapply
>
> Before this propagates too far: The name "mapply" has also been
> suggested for a "multiple apply", which is like lapply/sapply but
> takes multiple X arguments and a FUN of several arguments. So
> perhaps matrix.apply() or so would be better?
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>






-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thou_69 at yahoo.com  Fri Oct 11 04:05:00 2002
From: thou_69 at yahoo.com (Tao Hou)
Date: Thu, 10 Oct 2002 19:05:00 -0700 (PDT)
Subject: [R] BATCH problem
Message-ID: <20021011020500.91696.qmail@web21407.mail.yahoo.com>

Hi, 
I use R 1.5.* before,everything works great. after I
upgrade to 1.6. I find I problem. in dos command
windows, when I try:

Rcmd BATCH file1 file2

I will get a error message which say"perl is not
recognize as an internal or external command,operable
program or batch file"

please help me!

Thank you

Tao Hou


__________________________________________________

Faith Hill - Exclusive Performances, Videos & More

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From otoomet at econ.dk  Fri Oct 11 08:32:56 2002
From: otoomet at econ.dk (Ott Toomet)
Date: Fri, 11 Oct 2002 08:32:56 +0200
Subject: [R] Re: tapply for matrices
Message-ID: <200210110632.g9B6Wur04042@localhost.localdomain>

I have made a similar simple routine for my own purposes.  I have not
compared the speed.  Is there any good reason not to add something
similar to the base package, perhaps as a method for tapply?

Ott

----------------------------

tmapply <- function(X, INDEX, FUN=sum, ...) {
### tapply a function over a columns of a matrix
  tvapply <- function(X, ...) {
    ## apply the function for a (column) vector
    tapply(X, INDEX, FUN, ...)
  }
  apply(X, 2, FUN=tvapply, ...)
}
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Fri Oct 11 08:47:02 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Thu, 10 Oct 2002 23:47:02 -0700 (PDT)
Subject: [R] contour in lattice
In-Reply-To: <1034266821.5051.107.camel@gandalf>
Message-ID: <20021011064702.41658.qmail@web13907.mail.yahoo.com>


--- Ernesto Jardim <ernesto at ipimar.pt> wrote:
> Hi
> 
> I'm using lattice's function levelplot but when I choose the flag
> contour =TRUE I get very strange results. It looks like the contour
> lines have nothing to do with the "image" plot under ...

What version of lattice do you have ? Could you give an example ? e.g., 

> data(volcano)
> levelplot(volcano, contour = TRUE)

looks OK to me.

Deepayan


__________________________________________________

Faith Hill - Exclusive Performances, Videos & More

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 11 09:26:57 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 11 Oct 2002 08:26:57 +0100 (BST)
Subject: [R] Generating AR1 data
In-Reply-To: <009201c27044$cf3a80c0$5c13070a@it.giustizia.it>
Message-ID: <Pine.LNX.4.31.0210110826090.10008-100000@gannet.stats>

On Thu, 10 Oct 2002, vito muggeo wrote:

> See arima.sim() in the ts package;
> also it seems there is another arima.sim() in the boot package, but I don't
> know wheter it is the same.

There is no arima.sim() in boot: it was removed when arima.sim() was added
to ts.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Friedrich.Leisch at ci.tuwien.ac.at  Fri Oct 11 10:05:33 2002
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Fri, 11 Oct 2002 10:05:33 +0200
Subject: [R] problem with Sweave on 1.6 on NT4
In-Reply-To: <8C2B4A87FC7E0147A65DC17BF4BDDC3120DF10@NLDNC006PEX1.ubsgs.ubsgroup.net>
References: <8C2B4A87FC7E0147A65DC17BF4BDDC3120DF10@NLDNC006PEX1.ubsgs.ubsgroup.net>
Message-ID: <15782.34381.625683.873528@galadriel.ci.tuwien.ac.at>

>>>>> On Thu, 10 Oct 2002 10:44:04 +0100,
>>>>> John Gavin (JG) wrote:

  > Hi,
  > I recently compiled 1.6 on NT4 but
  > I am having a problem with Sweave.

  > Using the inbuilt 'Sweave-test-1.Rnw' file as an example:

  > -------
  >> library(tools)
  >> testfile <- file.path(.path.package("tools"),
  >                       "Sweave", "Sweave-test-1.Rnw")

  > ## create a LaTeX file
  > Sweave(testfile)
  > testfile <- file.path(.path.package("tools"),
  > +                       "Sweave", "Sweave-test-1.Rnw")
  >> 
  >> ## create a LaTeX file
  >> Sweave(testfile)
  > Writing to file Sweave-test-1.tex
  > Processing code chunks ...
  >  1 : print term verbatim
  >  2 : term hide
  >  3 : echo print term verbatim
  >  4 : term verbatim
  >  5 : echo term verbatim
  >  6 : echo term verbatim eps pdf
  >  7 : echo term verbatim eps pdf

  > You can now run LaTeX on Sweave-test-1.tex 
  > ---------

  > But the opening lines of Sweave-test-1.tex are: 

  > ---------
  > % -*- mode: noweb; noweb-default-code-mode: R-mode; -*-
  > \documentclass[a4paper]{article}

  > \title{A Test File}
  > \author{Friedrich Leisch}


  > \usepackage{a4wide}

  > \usepackage{c:etcRrw1060/share/texmf/Sweave}
  > \begin{document}
  > ...
  > ------------

  > The line '\usepackage{c:etcRrw1060/share/texmf/Sweave}' is wrong.
  > In V1.5.1 it used to read 
  > \usepackage{c:/etc/R/rw1051/library/tools/Sweave/Sweave}
  > i.e. 'c:etcRrw1060' should be 'c:/etc/R/rw1060' 
  > and I think the reference should be 
  > c:/etc/R/rw1060/library/tools/Sweave/Sweave,
  > (not the 'share/texmf' folder) as that is where Sweave.sty is.
  > (The only *.sty file in the folder 'share/texmf/' is Rd.sty.)

  > Is there is something that I try to set to get Sweave
  > insert the correct line in latex to load the Sweave.sty file?


The line is correct (I want Sweave.sty to be in $R_HOME/share/texmf),
but the install procedure had a bug which I have fixed a few minutes
ago. This caused Sweave.sty not to be copied to $R_HOME/share/texmf.

As a quick fix for 1.6.0: please copy Sweave.sty manually to
$R_HOME/share/texmf.

Another thing is the c:etcRrw1060 ... does R.home() work properly on
your system or do we have a problem there? 


Best,
Fritz

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Roger.Lee at hannover-re.com  Fri Oct 11 10:41:19 2002
From: Roger.Lee at hannover-re.com (Roger.Lee@hannover-re.com)
Date: Fri, 11 Oct 2002 09:41:19 +0100
Subject: [R] automatic chi-square grouping in R
Message-ID: <B52265FE5857D7438959650383C622A3112CCE@ie0x0001.hannover-re.grp>

I'm doing some chi-square tests, and I recall some arbitrary rule that says each band must have at least 5 events in order for the test to be meaningful. Is there some way to do the banding automagically in R ? For instance, in the following survdiff, I'm trying to see if ADL affects survival. But when ADL=3,5 and 6, the number observed is too little. Anyway for me to tell R how to group them ? Like "R, combine ADL=5 and ADL=6, and redo the test" ?

-----------

Call:
survdiff(formula = Surv(days, status) ~ adl, data = nu)

       N Observed Expected (O-E)^2/E (O-E)^2/V
adl=0 92        6     8.74   0.86134   1.17556
adl=1 38        5     3.41   0.74346   0.83435
adl=2 60        9    10.56   0.22975   0.39159
adl=3 44        4     5.22   0.28487   0.33978
adl=4 27        6     2.32   5.83153   6.30818
adl=5 31        3     3.12   0.00456   0.00506
adl=6 16        2     1.63   0.08385   0.08835

 Chisq= 8.2  on 6 degrees of freedom, p= 0.226 

-------

On a related note, is it possible to tell R to group together values, for instance, if I have age in my data ranging from 30-60, is it possible to tell R to convert all ages 30-35 into 32.5, all age from 36-40 into 37.5 ... etc ? I mean I can always do this in Excel before I feed the data into R, but it seems R must be able to do something like this. I just don't know where to begin looking in the manual for something like this ...

Thanks so much guys,

Roger


======   Legal Disclaimer   ======

As you may know, emails sent via Internet can easily be altered or manipulated by third persons. For this reason, we do not assume any responsibility for changes made to this message after it was sent.
Furthermore please note that the information (including any attachments) in this email is strictly confidential and solely intended for the addressee named above. If you are neither the intended recipient nor an employee or agent responsible for delivering this message to the intended recipient, we hereby notify you that any form of unauthorized use, publication, reproduction, copying or disclosure of this emails contents is not permitted.
If you have received this communication in error, please notify the sender and delete the email from your computer system.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Fri Oct 11 11:48:04 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 11 Oct 2002 10:48:04 +0100
Subject: [R] RE: [R-gui] NEdit Highligth patterns for R
In-Reply-To: <MABBLJDICACNFOLGIHJOKEBADAAA.philippe.grosjean@ifremer.fr>
References: <MABBLJDICACNFOLGIHJOKEBADAAA.philippe.grosjean@ifremer.fr>
Message-ID: <1034329684.15227.12.camel@gandalf>

Hi

I agree with your comments and of course you identifie the problems
regarding the implementation of your suggestions.

Of course we'd need bidireccional communication to implement it. I think
it's impossible to do it statically.

What I want with NEdit is a very ligth editor (which jedit is not) that
highlights the most important language syntax, so that It becomes easier
to write functions and scripts. I get that with NEdit.

Of course there's a lot that can be further developed and NEdit seems
very flexible and easy to use.

Regards

EJ

On Fri, 2002-10-11 at 09:00, Philippe Grosjean wrote:
> >Hi
> 
> >I've just submitted to the NEdit development team a R highligth patterns
> >for NEdit (www.nedit.org).
> 
> >NEdit is a text editor for LINUX which I use to write small R functions.
> >In my opinion is a very good tool for small scripts, maybe for huge
> >projects is not the best.
> 
> >I'm attaching the R-5.1.pats file so you can try it.
> 
> >As usual contributions and comments are welcome.
> 
> >Regards
> 
> >EJ
> 
> Nice. But regarding synthax highlighting, I stick with two problems:
> 
> 1) It would be interesting to highlight in different colors functions and
> arguments... but they can have same name. Example: plot(x, col=2) -argument
> 'col' and col(x), function 'col'. For the moment, the only easy way I found
> is to define argument followed by = in the dictionnary, like 'col=' for the
> argument. However, space is allowed between 'col' and '=', and then the
> argument is not correctly coloured. So, I add an automatic correction that
> eliminates spaces before a single '=' sign. But now that '=' is also allowed
> as asignment, it is problematic: col = 1, with 'col' being the name of a
> variable (indeed, col <- 1) is now highlighted as an argument.
> 
> 2) Of course, one could statically define the dictionnary with, let's say,
> all functions and arguments in the base and recommended packages. I would
> prefer a dynamic construction of the dictionnary: when a library is loaded,
> terms are added, when it is unloaded, they are eliminated. This is only
> possible with a bidirectionnal communication between the editor and the R
> calculation kernel. I got this in SciViews but how to do that in Nedit or
> other separate script editors?
> 
> Regards,
> 
> Philippe Grosjean
> 
> ...........]<(({?<...............<?}))><...............................
> ( ( ( ( (
>  ) ) ) ) )      Philippe Grosjean
> ( ( ( ( (
>  ) ) ) ) )      IFREMER Nantes - DEL/AO
> ( ( ( ( (       rue de l'Ile d'Yeu, BP 21105, 44311 Nantes Cedex 3
>  ) ) ) ) )      tel: (33) 02.40.37.42.29, fax: (33) 02.40.37.42.41
> ( ( ( ( (	    e-mail: philippe.grosjean at ifremer.fr
>  ) ) ) ) )
> ( ( ( ( (       "I'm 100% confident that p is between 0 and 1"
>  ) ) ) ) )                                L. Gonick & W. Smith (1993)
> .......................................................................
> 
> 
> 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Fri Oct 11 12:48:39 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 11 Oct 2002 11:48:39 +0100
Subject: [R] contour in lattice
In-Reply-To: <20021011064702.41658.qmail@web13907.mail.yahoo.com>
References: <20021011064702.41658.qmail@web13907.mail.yahoo.com>
Message-ID: <1034333320.15635.101.camel@gandalf>

Hi

I'm using lattice 0.5-6 and R 1.6.0 in a SuSE 8.0 linux box.

The volcano dataset is a matrix with x and y has margins and z has the
values.

I'm using a data.frame with 4 columns (x, y, z, year) and I'm using a
z~x*y|year formula. 

The image result is ok but the contour is not ...

Looking at documentation I understand that I the way I'm doing it is
correct.

I've uploaded two files, the dump of my dataset and a pdf with the
result I'm getting with:

levelplot(Zest~x*y, data=recs2001, contour=TRUE)

in my web page (http://ej.freezope.org/R)  

If you can please take a look.

Regards

EJ

On Fri, 2002-10-11 at 07:47, Deepayan Sarkar wrote:
> 
> --- Ernesto Jardim <ernesto at ipimar.pt> wrote:
> > Hi
> > 
> > I'm using lattice's function levelplot but when I choose the flag
> > contour =TRUE I get very strange results. It looks like the contour
> > lines have nothing to do with the "image" plot under ...
> 
> What version of lattice do you have ? Could you give an example ? e.g., 
> 
> > data(volcano)
> > levelplot(volcano, contour = TRUE)
> 
> looks OK to me.
> 
> Deepayan
> 
> 
> __________________________________________________
> Do you Yahoo!?
> Faith Hill - Exclusive Performances, Videos & More
> http://faith.yahoo.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From christof at nicht-ich.de  Fri Oct 11 14:32:24 2002
From: christof at nicht-ich.de (Christof Meigen)
Date: 11 Oct 2002 14:32:24 +0200
Subject: [R] absurd computiation times of lme
Message-ID: <87lm55gnqf.fsf@home.nicht-ich.de>


Hi,

i've been trying to apply the lme apprach to growth curves
of children, but lme keeps running for ever and ever as
soon as I use a reasonable basis.

First Example:
Data are 39 boys from the Berkeley growth study, each one 
measured 31 times at the ages of
1.00  1.25  1.50  1.75  2.00  3.00  4.00  5.00  6.00  7.00  8.00  8.50
9.00  9.50 10.00 10.50 11.00 11.50 12.00 12.50 13.00 13.50 14.00 14.50
15.00 15.50 16.00 16.50 17.00 17.50 18.00

from experience we know that a bspline basis with at least 12 to 15
knots is needed to model a complete growth curve. I take the spline
basis matrix as both fixed and random effect (not forgetting the
-1, since the intercept is included in the splines).

When I use 3 knots (5 parameters), computation time is about
5 Minutes on a 750MHz machine. The fitting makes sense but
is very bad due to the lack of flexibility. 4 knots take
27 Min to compute and 5 knots take more than 5 hours
(I interrupted after that). 

I played around with pdMat, but actually it does not make sense
to restrict the variance - co-varience matrix.

Second example:

In this case, we have about 800 children with measurements
between 0 and 2.5 years. Unfortunatly, the number of the 
measurements as well as the timing differs a lot, it is only
guranteed that each child is measured at least once in all
of the 5 first quarters. 

Chosing a model like height ~ age, like in the Oxboys example
from "Mixed Effext Models in S and S-PLUS" does not make
sense since growth velocity changes rapidly in the first 
two years. So, I sticked to the spline approach, since I thought,
that 3 knots would suffice this time. 

Unfortunatly, the computation would not stop after
more than 10 hours. Taking less children doesn't change much, and
I can't use less knots. 

Although I don't expect reasonable results from that, but even with
only three children (as below) the computation wouldn't stop soon.

Data looks like below, B1..B5 are the basis matrix for the
spline basis, and I use 

kidGroup <- groupedData(height ~ B1+B2+B3+B4+B5 -1 | Id, data=kids)
fm <- lme(kidGroup)


Using a model like
kidGroup <- groupedData(height ~ sqrt(age) | Id, data=kids)

works very fast, but the model is not appropriate and the
fitting is bad. 

What is the reason for this exponential-lookking increase in
computation time and is there any way to overcome that?

Or are there more clever approaches for this data?

Thanks in advance,
        Christof


      Id  age height   B1     B2      B3     B4     B5
1  16162 0.10   56.6 0.7786 0.2120 0.0090 0.0001 0.0000
2  16162 0.21   59.4 0.5759 0.3852 0.0375 0.0011 0.0000
3  16162 0.36   62.3 0.3609 0.5325 0.1005 0.0059 0.0000
4  16162 0.51   64.5 0.2074 0.5937 0.1817 0.0169 0.0000
5  16162 0.62   66.9 0.1280 0.5944 0.2470 0.0305 0.0000
6  16162 0.71   68.8 0.0806 0.5728 0.3006 0.0458 0.0000
7  16162 0.98   72.0 0.0100 0.4293 0.4400 0.1204 0.0000
8  16162 1.15   74.9 0.0005 0.3139 0.4909 0.1946 0.0000
9  16162 1.48   75.8 0.0000 0.1358 0.4554 0.4024 0.0062
10 16162 1.79   79.5 0.0000 0.0458 0.3006 0.5728 0.0806
11 16162 1.94   81.0 0.0000 0.0224 0.2111 0.5981 0.1681

12 16216 0.10   54.5 0.7786 0.2120 0.0090 0.0001 0.0000
13 16216 0.18   58.0 0.6272 0.3439 0.0281 0.0007 0.0000
14 16216 0.33   64.2 0.3986 0.5105 0.0861 0.0045 0.0000
15 16216 0.42   68.3 0.2927 0.5663 0.1314 0.0094 0.0000
16 16216 0.54   69.8 0.1832 0.5972 0.1993 0.0201 0.0000
17 16216 0.70   73.2 0.0851 0.5761 0.2947 0.0439 0.0000
18 16216 0.82   76.0 0.0407 0.5255 0.3632 0.0705 0.0000
19 16216 1.05   78.5 0.0040 0.3820 0.4656 0.1481 0.0000
20 16216 1.26   81.5 0.0000 0.2440 0.4999 0.2560 0.0000
21 16216 1.32   81.5 0.0000 0.2103 0.4954 0.2940 0.0001
22 16216 1.52   85.2 0.0000 0.1204 0.4400 0.4293 0.0100
23 16216 1.90   89.5 0.0000 0.0276 0.2350 0.5967 0.1406

24 16233 0.09   55.3 0.7991 0.1933 0.0074 0.0000 0.0000
25 16233 0.32   64.8 0.4118 0.5024 0.0815 0.0041 0.0000
26 16233 0.51   68.4 0.2074 0.5937 0.1817 0.0169 0.0000
27 16233 0.59   69.5 0.1471 0.5974 0.2290 0.0262 0.0000
28 16233 0.91   75.4 0.0201 0.4742 0.4091 0.0964 0.0000
29 16233 1.16   78.5 0.0003 0.3072 0.4925 0.1997 0.0000
30 16233 1.34   82.9 0.0000 0.1997 0.4925 0.3072 0.0003
31 16233 1.94   86.7 0.0000 0.0224 0.2111 0.5981 0.1681
32 16233 2.03   88.6 0.0000 0.0132 0.1589 0.5848 0.2429
33 16233 2.37   90.5 0.0000 0.0002 0.0150 0.2652 0.7193
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.C.Rougier at durham.ac.uk  Fri Oct 11 13:04:53 2002
From: J.C.Rougier at durham.ac.uk (Jonathan Rougier)
Date: Fri, 11 Oct 2002 12:04:53 +0100
Subject: [R] make check when installing R-1.6.0
References: <3DA6014B.8497B981@noaa.gov>
Message-ID: <3DA6B055.F5486C7@durham.ac.uk>

Brian O'Gorman wrote:
> 
> This is the result of my make check,  could anyone help me out on this
> one?
> 
>      Formats: text example
> running code in 'base-Ex.R' ...*** Error code 1
> make: Fatal error: Command failed for target `base-Ex.Rout'
> Current working directory /apps/R/R-1.6.0/tests/Examples
> *** Error code 1
> make: Fatal error: Command failed for target `test-Examples-Base'
> Current working directory /apps/R/R-1.6.0/tests/Examples
> *** Error code 1
> make: Fatal error: Command failed for target `test-Examples'
> Current working directory /apps/R/R-1.6.0/tests
> *** Error code 1
> make: Fatal error: Command failed for target `test-all-basics'
> Current working directory /apps/R/R-1.6.0/tests
> *** Error code 1
> make: Fatal error: Command failed for target `check'

You want to check the file "${R_HOME}/test/Examples/base-Ex.Rout"
but my guess would be that you are picking up an old version of MASS.

Cheers, Jonathan.
-- 
Jonathan Rougier                       Science Laboratories
Department of Mathematical Sciences    South Road
University of Durham                   Durham DH1 3LE
tel: +44 (0)191 374 2361, fax: +44 (0)191 374 7388
http://www.maths.dur.ac.uk/stats/people/jcr/jcr.html
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jan.wiener at tuebingen.mpg.de  Fri Oct 11 13:47:46 2002
From: jan.wiener at tuebingen.mpg.de (Jan Malte Wiener)
Date: Fri, 11 Oct 2002 13:47:46 +0200
Subject: [R] plot region ??
Message-ID: <3DA6BA62.4@tuebingen.mpg.de>


hi,
i am using the barplot function, but i have problems with the plot 
region when adjusting the bar width manually. if you only want to plot 2 
bars the default barwidth is to wide (aesthetically speaking). by 
adjusting width and xlim one can actually produce narrow bars, but then 
the plotted graph is not in the center of the plot region, which means 
that for example the title of the plot isn't centered above the barplot.

e.g.
toPlot<-c(5,6)
barplot(toPlot, width=c(0.4), xlim=c(0,3))
title(main = "Female - Male", font.main=2)

any ideas how to get rid of this problem ??

greetinx jan

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From arnottj at essc.psu.edu  Fri Oct 11 14:49:24 2002
From: arnottj at essc.psu.edu (Justin Arnott)
Date: Fri, 11 Oct 2002 08:49:24 -0400
Subject: [R] Problems with cclust
Message-ID: <3DA6C8D4.26EACCA3@essc.psu.edu>

To Whom It May Concern,

I am currently trying to use R to perform a "kmeans" clustering of a
three dimensional data set.  In the directory
R-1.5.1/library/cclust/data/  I have created a file that
has the following format (only the first few lines are shown for
brevity):

            B                  X.Vtl     X.Vtu
1   -0.529043  1.307031  1.625169
2   -0.752502  1.132813  1.480548
3   -0.769839  0.888365  1.178828
4   -0.333035  0.732639  0.802276
5   -0.172183  0.636773  1.217721


The file has the name test3.tab in that directory.  When I then use R,
I load the data as follows:

>data(test3)

For a simple test, I attempt to use the kmeans method by using the
command that follows:

> cclust(test3, 2, method="kmeans")
Error in as.double.default(x) : (list) object cannot be coerced to
vector type 14


Below the command is the error I receive.  The matrix that I entered
does have columns corresponding to variables and rows to observations as
shown in the documentation so I'm not sure why it is not of the right
format.

Any help on how to "fix" this error would be greatly appreciated!!

Thanks,
Justin Arnott

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 11 16:08:42 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 11 Oct 2002 15:08:42 +0100 (BST)
Subject: [R] make check when installing R-1.6.0
In-Reply-To: <3DA6B055.F5486C7@durham.ac.uk>
Message-ID: <Pine.LNX.4.31.0210111506170.11300-100000@gannet.stats>

On Fri, 11 Oct 2002, Jonathan Rougier wrote:

> Brian O'Gorman wrote:
> >
> > This is the result of my make check,  could anyone help me out on this
> > one?
> >
> >      Formats: text example
> > running code in 'base-Ex.R' ...*** Error code 1
> > make: Fatal error: Command failed for target `base-Ex.Rout'
> > Current working directory /apps/R/R-1.6.0/tests/Examples
> > *** Error code 1
> > make: Fatal error: Command failed for target `test-Examples-Base'
> > Current working directory /apps/R/R-1.6.0/tests/Examples
> > *** Error code 1
> > make: Fatal error: Command failed for target `test-Examples'
> > Current working directory /apps/R/R-1.6.0/tests
> > *** Error code 1
> > make: Fatal error: Command failed for target `test-all-basics'
> > Current working directory /apps/R/R-1.6.0/tests
> > *** Error code 1
> > make: Fatal error: Command failed for target `check'
>
> You want to check the file "${R_HOME}/test/Examples/base-Ex.Rout"
> but my guess would be that you are picking up an old version of MASS.

Pretty unlikely: MASS ships with 1.6.0 and the test is run with --vanilla
so no other library directory is used (unless you have R_LIBS set in the
environment, not a good idea).  So why pick on MASS?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From egonw at sci.kun.nl  Fri Oct 11 16:42:23 2002
From: egonw at sci.kun.nl (E.L. Willighagen)
Date: Fri, 11 Oct 2002 16:42:23 +0200
Subject: [R] binary to decimal number
Message-ID: <200210111642.23640.egonw@sci.kun.nl>


Hi all,

is there a method for transforming 1010 into 10, i.e. a binary number
into a decimal value?

kind regards,

Egon
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From christof at nicht-ich.de  Fri Oct 11 18:51:34 2002
From: christof at nicht-ich.de (Christof Meigen)
Date: 11 Oct 2002 18:51:34 +0200
Subject: [R] absurd computiation times of lme
In-Reply-To: <3DA6D86B.1B82044B@sentoo.sn>
References: <87lm55gnqf.fsf@home.nicht-ich.de> <3DA6D86B.1B82044B@sentoo.sn>
Message-ID: <87wuooor55.fsf@home.nicht-ich.de>


Hi Renaud,

Renaud Lancelot <lancelot at sentoo.sn> writes:
> It is because of the random effects (the estimations of the var-cov
> random-effect matrix is very computer intensive). I think you would need
> a very large data set to be able to estimate so many random-effect
> parameters (21 parameters: 6 variances and 15 covariances). 

Well, in the case of the children I do have quite large datasets,
around 1000 children with altogether much more than 5000 measurements.

> May be it
> would be easier to fit non-linear models. I am not a specialist of human
> growth, but what about models like JPPS ? 

JPPS, which models a whole growth curve, needs the adult height of the
child. Still it is very hard to fit, and optimization sometimes fails
to converge even on what looks like perfect data, see for example
"Mathematical models of growth in stature throuout childhood", by
Ledford & Cole.

JPPS has 6 Parameters, which is one more than I would use for the 
little kids. The point in using a spline basis was to make quite
little a priori assumptions on the model but let "lme" do the
job of deciding what the curve should look like. Unfortunatly, this
seems more than it can handle. 

I just thought it would be a good way to avoid that kind of
"why did you chose than model" questions, which might lead to
very annoing discussions if someone puts effort into rejecting
all of your views.

        Christof


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.C.Rougier at durham.ac.uk  Fri Oct 11 17:05:52 2002
From: J.C.Rougier at durham.ac.uk (Jonathan Rougier)
Date: Fri, 11 Oct 2002 16:05:52 +0100
Subject: [R] make check when installing R-1.6.0
References: <Pine.LNX.4.31.0210111506170.11300-100000@gannet.stats>
Message-ID: <3DA6E8D0.36B89D58@durham.ac.uk>

ripley at stats.ox.ac.uk wrote:
> 
> On Fri, 11 Oct 2002, Jonathan Rougier wrote:
> 
> > Brian O'Gorman wrote:
> > >
> > > This is the result of my make check,  could anyone help me out on this
> > > one?
> > >
> > >      Formats: text example
> > > running code in 'base-Ex.R' ...*** Error code 1
> > > make: Fatal error: Command failed for target `base-Ex.Rout'
> > > Current working directory /apps/R/R-1.6.0/tests/Examples
> > > *** Error code 1
> > > make: Fatal error: Command failed for target `test-Examples-Base'
> > > Current working directory /apps/R/R-1.6.0/tests/Examples
> > > *** Error code 1
> > > make: Fatal error: Command failed for target `test-Examples'
> > > Current working directory /apps/R/R-1.6.0/tests
> > > *** Error code 1
> > > make: Fatal error: Command failed for target `test-all-basics'
> > > Current working directory /apps/R/R-1.6.0/tests
> > > *** Error code 1
> > > make: Fatal error: Command failed for target `check'
> >
> > You want to check the file "${R_HOME}/test/Examples/base-Ex.Rout"
> > but my guess would be that you are picking up an old version of MASS.
> 
> Pretty unlikely: MASS ships with 1.6.0 and the test is run with --vanilla
> so no other library directory is used (unless you have R_LIBS set in the
> environment, not a good idea).  So why pick on MASS?

Hi Brian,

It's what happened to me!  We have a common library on our network that
contained a very old version of MASS, and it is specified in the R_LIBS
variable.  After installing R-1.6.0 I arranged in my .Rprofile to
exchange the order of common/lib/R and ${R_HOME}/library in my search
list but, as you point out, this didn't allow me to run "make check"
without getting caught up with the old version of MASS.

Cheers, Jonathan.

-- 
Jonathan Rougier                       Science Laboratories
Department of Mathematical Sciences    South Road
University of Durham                   Durham DH1 3LE
tel: +44 (0)191 374 2361, fax: +44 (0)191 374 7388
http://www.maths.dur.ac.uk/stats/people/jcr/jcr.html
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hennig at stat.math.ethz.ch  Fri Oct 11 17:19:36 2002
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Fri, 11 Oct 2002 17:19:36 +0200 (CEST)
Subject: [R] Problems with cclust
In-Reply-To: <3DA6C8D4.26EACCA3@essc.psu.edu>
Message-ID: <Pine.LNX.4.44.0210111718090.28366-100000@florence>

Function kmeans in library(mva) should do what you want. 

Christian 

On Fri, 11 Oct 2002, Justin Arnott wrote:

> To Whom It May Concern,
> 
> I am currently trying to use R to perform a "kmeans" clustering of a
> three dimensional data set.  In the directory
> R-1.5.1/library/cclust/data/  I have created a file that
> has the following format (only the first few lines are shown for
> brevity):
> 
>             B                  X.Vtl     X.Vtu
> 1   -0.529043  1.307031  1.625169
> 2   -0.752502  1.132813  1.480548
> 3   -0.769839  0.888365  1.178828
> 4   -0.333035  0.732639  0.802276
> 5   -0.172183  0.636773  1.217721
> 
> 
> The file has the name test3.tab in that directory.  When I then use R,
> I load the data as follows:
> 
> >data(test3)
> 
> For a simple test, I attempt to use the kmeans method by using the
> command that follows:
> 
> > cclust(test3, 2, method="kmeans")
> Error in as.double.default(x) : (list) object cannot be coerced to
> vector type 14
> 
> 
> Below the command is the error I receive.  The matrix that I entered
> does have columns corresponding to variables and rows to observations as
> shown in the documentation so I'm not sure why it is not of the right
> format.
> 
> Any help on how to "fix" this error would be greatly appreciated!!
> 
> Thanks,
> Justin Arnott
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (current)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 11 17:26:19 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 11 Oct 2002 16:26:19 +0100 (BST)
Subject: [R] make check when installing R-1.6.0
In-Reply-To: <3DA6E8D0.36B89D58@durham.ac.uk>
Message-ID: <Pine.LNX.4.31.0210111625040.11488-100000@gannet.stats>

On Fri, 11 Oct 2002, Jonathan Rougier wrote:

> ripley at stats.ox.ac.uk wrote:
> >
> > On Fri, 11 Oct 2002, Jonathan Rougier wrote:
> >
> > > Brian O'Gorman wrote:
> > > >
> > > > This is the result of my make check,  could anyone help me out on this
> > > > one?
> > > >
> > > >      Formats: text example
> > > > running code in 'base-Ex.R' ...*** Error code 1
> > > > make: Fatal error: Command failed for target `base-Ex.Rout'
> > > > Current working directory /apps/R/R-1.6.0/tests/Examples
> > > > *** Error code 1
> > > > make: Fatal error: Command failed for target `test-Examples-Base'
> > > > Current working directory /apps/R/R-1.6.0/tests/Examples
> > > > *** Error code 1
> > > > make: Fatal error: Command failed for target `test-Examples'
> > > > Current working directory /apps/R/R-1.6.0/tests
> > > > *** Error code 1
> > > > make: Fatal error: Command failed for target `test-all-basics'
> > > > Current working directory /apps/R/R-1.6.0/tests
> > > > *** Error code 1
> > > > make: Fatal error: Command failed for target `check'
> > >
> > > You want to check the file "${R_HOME}/test/Examples/base-Ex.Rout"
> > > but my guess would be that you are picking up an old version of MASS.
> >
> > Pretty unlikely: MASS ships with 1.6.0 and the test is run with --vanilla
> > so no other library directory is used (unless you have R_LIBS set in the
> > environment, not a good idea).  So why pick on MASS?
>
> Hi Brian,
>
> It's what happened to me!  We have a common library on our network that
> contained a very old version of MASS, and it is specified in the R_LIBS
> variable.  After installing R-1.6.0 I arranged in my .Rprofile to
> exchange the order of common/lib/R and ${R_HOME}/library in my search
> list but, as you point out, this didn't allow me to run "make check"
> without getting caught up with the old version of MASS.

~/.Rprofile is not read under --vanilla, AFAIK. Do you have R_LIBS in your
shell environment?

It's much easier to use .Renviron.

>
> Cheers, Jonathan.
>
> --
> Jonathan Rougier                       Science Laboratories
> Department of Mathematical Sciences    South Road
> University of Durham                   Durham DH1 3LE
> tel: +44 (0)191 374 2361, fax: +44 (0)191 374 7388
> http://www.maths.dur.ac.uk/stats/people/jcr/jcr.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From shajjiouafi at cdcixis-cm.com  Fri Oct 11 17:44:51 2002
From: shajjiouafi at cdcixis-cm.com (Hajji Ouafi, Saad)
Date: Fri, 11 Oct 2002 17:44:51 +0200
Subject: [R] Help about the white noise test
Message-ID: <3A6D2FEEF9C3D51197E200034779C076068424EA@msdenfert.smt.cmi.net>

Hello,
I would like to perform the test of white noise on a time serie. I couldn't
find the instruction corresponding to the white noise test.
Thank you
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From trafton at itd.nrl.navy.mil  Fri Oct 11 18:11:20 2002
From: trafton at itd.nrl.navy.mil (Greg Trafton)
Date: Fri, 11 Oct 2002 12:11:20 -0400
Subject: [R] post-hocs with multiple factors (anovas)?
In-Reply-To: <m38z18hfq8.fsf@viz.itd.nrl.navy.mil> (Greg Trafton's message
 of "Tue, 08 Oct 2002 15:50:55 -0400")
Message-ID: <m3y995ez13.fsf@viz.itd.nrl.navy.mil>

Hi, all.  I'm working on post hoc comparisons on anovas with multiple
factors.  the design is 1 repeated measure (session) and 1 between measure
(cond).  my dependent measure is rl.  here is the data I'm using (in a
data.frame):

mig <- data.frame(subj=factor(rep(subj,3)),
                  cond=factor(rep(cond,3)),
                  session=factor(c(rep(1,nsubj),rep(2,nsubj),rep(3,nsubj))),
                  rl)
> mig
    subj cond session      rl
1  401.1   NW       1  6.4081
2  402.1   NW       1  5.8861
3  500.1  NWC       1  5.3492
4  502.1  NWC       1  8.5302
5  601.1  NWR       1  2.7519
6  602.1  NWR       1  4.5404
7  603.1  NWR       1  4.3442
8  604.1  NWR       1  3.6722
9  401.1   NW       2  6.1492
10 402.1   NW       2  5.0506
11 500.1  NWC       2  6.5625
12 502.1  NWC       2 11.4430
13 601.1  NWR       2  2.8450
14 602.1  NWR       2  5.6558
15 603.1  NWR       2  3.3340
16 604.1  NWR       2  5.0548
17 401.1   NW       3  5.2717
18 402.1   NW       3  3.7337
19 500.1  NWC       3  3.6659
20 502.1  NWC       3  5.9463
21 601.1  NWR       3  2.3356
22 602.1  NWR       3  7.5458
23 603.1  NWR       3  5.0322
24 604.1  NWR       3  4.1381

summary(mgroup <- aov(rl ~ cond * session + Error(subj/(session)), data=mig))

I'm interested in posthoc comparisons between:
various levels of condition (I can get this with TukeyHSD,
pairwise.t.test, or multcomp)
various levels of session (ditto)
the full 6 comparisons (3 sessions by 2 conditions).  that is, I want
to know if NW-session1 is diff from NW-session2, etc.

> tapply(mig$rl,IND=list(mig$cond, mig$session),FUN=mean)
           1       2        3
NW  6.147100 5.59990 4.502700
NWC 6.939700 9.00275 4.806100
NWR 3.827175 4.22240 4.762925

Each of the earlier tests I've tried (TukeyHSD, pairwise.*, and
multcomp) all seem to do only one factor at a time.

Suggestions?

thanks!
greg

(I know my dataset is small, doesn't give appropriate omnibus stats to
run the post-hocs, but I'm currently in testing mode.)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ren_Yu at hgsi.com  Fri Oct 11 18:11:08 2002
From: Ren_Yu at hgsi.com (Ren_Yu@hgsi.com)
Date: Fri, 11 Oct 2002 12:11:08 -0400
Subject: [R] read.table( ... comment.char="#") truncated my data
Message-ID: <OFAF5F871A.9A57AAF0-ON85256C4F.00578166@hgsi.com>

Dear all,

I found that the new feature of the comment.char="#"  argument in the 
read.table function truncated my data while the data set actually contains 
 '#'. We analyze lot of data that contain '#'. This is really annoying and 
it is also not compatible earlier version of R. I searched the R archive 
and found the following message for the scan function. Is it possible to 
change the default to " " in read.table ?

Thanks,

Ren



On Tue, 19 Feb 2002, Steve Cassidy wrote: 
> I've just discovered the recent addition of the comment.char arg to 
scan, a 
> useful feature no doubt but the default value of # rather than "" breaks 
my 
> code which looks for # as a delimeter in a file and provides a messy 
> incompatability with earlier versions of R and with Splus. 
> 
> Is there any chance that this default could be changed to ""? 
It already has been. The NEWS for R-patched / R-devel says: 
    o The default has been changed to scan(comment.char="") for 
        consistency with earlier code (as in the previous item). 
-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20021011/03fc07da/attachment.html

From malmo at unitra.sk  Fri Oct 11 18:58:15 2002
From: malmo at unitra.sk (Peter Adamka)
Date: 11 Oct 2002 18:58:15 +0200
Subject: [R] replace
Message-ID: <1034355495.5745.9.camel@whiper>

The thing I need to do is to replace NA values with 0.
But I;m not able to determine how to do it.
I'm relative new, pls Help.
Malmo



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Oct 11 19:19:14 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 11 Oct 2002 19:19:14 +0200
Subject: [R] replace
In-Reply-To: <1034355495.5745.9.camel@whiper>
References: <1034355495.5745.9.camel@whiper>
Message-ID: <x21y6wyju5.fsf@biostat.ku.dk>

Peter Adamka <malmo at unitra.sk> writes:

> The thing I need to do is to replace NA values with 0.
> But I;m not able to determine how to do it.

x[is.na(x)] <- 0

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Fri Oct 11 19:23:07 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Fri, 11 Oct 2002 10:23:07 -0700 (PDT)
Subject: [R] contour in lattice
In-Reply-To: <1034333320.15635.101.camel@gandalf>
Message-ID: <20021011172307.14817.qmail@web13904.mail.yahoo.com>


Hi,

the problem is due to the fact that your data frame doesn't have z-values for
all possible x-y combinations (equivalent to a matrix in contour with lots of
NA's), which contourplot can't handle. This is definitely a bug in contourplot,
and I will try to look into it. 

Deepayan

--- Ernesto Jardim <ernesto at ipimar.pt> wrote:
> Hi
> 
> I'm using lattice 0.5-6 and R 1.6.0 in a SuSE 8.0 linux box.
> 
> The volcano dataset is a matrix with x and y has margins and z has the
> values.
> 
> I'm using a data.frame with 4 columns (x, y, z, year) and I'm using a
> z~x*y|year formula. 
> 
> The image result is ok but the contour is not ...
> 
> Looking at documentation I understand that I the way I'm doing it is
> correct.
> 
> I've uploaded two files, the dump of my dataset and a pdf with the
> result I'm getting with:
> 
> levelplot(Zest~x*y, data=recs2001, contour=TRUE)
> 
> in my web page (http://ej.freezope.org/R)  
> 
> If you can please take a look.
> 
> Regards
> 
> EJ
> 
> On Fri, 2002-10-11 at 07:47, Deepayan Sarkar wrote:
> > 
> > --- Ernesto Jardim <ernesto at ipimar.pt> wrote:
> > > Hi
> > > 
> > > I'm using lattice's function levelplot but when I choose the flag
> > > contour =TRUE I get very strange results. It looks like the contour
> > > lines have nothing to do with the "image" plot under ...
> > 
> > What version of lattice do you have ? Could you give an example ? e.g., 
> > 
> > > data(volcano)
> > > levelplot(volcano, contour = TRUE)
> > 
> > looks OK to me.
> > 
> > Deepayan


__________________________________________________

Faith Hill - Exclusive Performances, Videos & More

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jzhang at jimmy.harvard.edu  Fri Oct 11 19:46:28 2002
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Fri, 11 Oct 2002 13:46:28 -0400 (EDT)
Subject: [R] read.table( ... comment.char="#") truncated my data
Message-ID: <200210111746.NAA28965@blaise.dfci.harvard.edu>


>To: r-help at stat.math.ethz.ch
>Subject: [R] read.table( ... comment.char="#") truncated my data
>MIME-Version: 1.0
>From: Ren_Yu at hgsi.com
>Date: Fri, 11 Oct 2002 12:11:08 -0400
>X-MIMETrack: Serialize by Router on Mozart/Hgsi(Release 5.0.8 |June 18, 2001) 
at 10/11/2002 12:11:08 PM, Serialize complete at 10/11/2002 12:11:08 PM
>X-MailScanner: Found to be clean
>
>Dear all,
>
>I found that the new feature of the comment.char="#"  argument in the 
>read.table function truncated my data while the data set actually contains 
> '#'. We analyze lot of data that contain '#'. This is really annoying and 
>it is also not compatible earlier version of R. I searched the R archive 
>and found the following message for the scan function. Is it possible to 
>change the default to " " in read.table ?

Why do not you try to reset the value using comment.char = " " each time when 
you call read.table?


>
>Thanks,
>
>Ren
>
>
>
>On Tue, 19 Feb 2002, Steve Cassidy wrote: 
>> I've just discovered the recent addition of the comment.char arg to 
>scan, a 
>> useful feature no doubt but the default value of # rather than "" breaks 
>my 
>> code which looks for # as a delimeter in a file and provides a messy 
>> incompatability with earlier versions of R and with Splus. 
>> 
>> Is there any chance that this default could be changed to ""? 
>It already has been. The NEWS for R-patched / R-devel says: 
>    o The default has been changed to scan(comment.char="") for 
>        consistency with earlier code (as in the previous item). 
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272860 (secr)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Fri Oct 11 19:57:03 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Fri, 11 Oct 2002 10:57:03 -0700 (PDT)
Subject: [R] grid graphics and par settings
In-Reply-To: <20021009232333.GA28111@hortresearch.co.nz>
Message-ID: <20021011175703.34269.qmail@web13906.mail.yahoo.com>


--- Patrick Connolly <p.connolly at hortresearch.co.nz> wrote:
> I see that adj is not a graphical parameter that can be used in a key
> list to use with lattice functions.
> 
> Is that because it's not yet implemented in gpar?  If so, it could
> also explain why it's not available in grid.text.

adj is not exactly a graphical parameter, it's more a property of text.
grid.text has an argument called 'just' which serves the same purpose.

The fact that adj doesn't work in key is due to my laziness, I just didn't get
around to implementing it. I have fixed it in the development version now.

> Is there a work around?  Centering looks silly on my plot.

You could try out the development version at

http://www.stat.wisc.edu/~deepayan/R/lattice_0.6-4.tar.gz

The documentation needs updates, but otherwise, it should be useable. Note that
only ajd = 0, .5 and 1 will give sensible text justification in key.

Deepayan



__________________________________________________

Faith Hill - Exclusive Performances, Videos & More

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rolf at math.unb.ca  Fri Oct 11 20:00:42 2002
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 11 Oct 2002 15:00:42 -0300 (ADT)
Subject: [R] Installing local package under Windows.
Message-ID: <200210111800.PAA06576@gelfand.math.unb.ca>


I'm working on a system in which PCs (running various versions
of Windows, mainly 98 I think) are networked together using
a system called ``Novell''.

I recently got our Computing Services people to install R
on this system, and it appears to work seamlessly.

I mainly want to use R in a time series course which I am
teaching this term, and to that end I wanted to install a
supplementary package of time series utilities which I
have written, for my students' benefit.

I cannot get this locally built package to install under
this Windows system.  (The package was built under Unix, and
installs there, with no complaints.)

I have been trying to follow the instructions in the ``R Installation
and Administration'' guide, section 5.1 ``Installing packages.''

I proceeded as follows:
	
1. Uploaded the zip file ``ts.sup_0.0-0.tar.gz'' from the
   Unix box to the Windows system, via ftp (binary mode set).

2. Placed the zip file in F:\rproject

	--- the F: drive is effectively one's ``login directory''
	when one has connected to the Novell network.
	
	--- the directory ``rproject'' seems to be created by R
	as the base location in which to do its thing.

3. Executed

	> .libPaths("L:/statdata")

   to make ``L:/statdata'' the first entry in .libPaths().

   I have write permission in L:/statdata (and of course not
   elsewhere on the network drives).  This --- i.e. L:/statdata ---
   is the location where our stats group routinely places data sets
   for the students to access.

   Having done this I executed

	>.libPaths()

   to see if it had ``taken'' and got

   [1] "L:/statdata"                "O:/EXEFILES/RW1051/library"

   as hoped.  (The second entry is the default value of .libPaths().)

4. Clicked on the Packages button of the R gui, and then on

   Install package from local zip file...

5. An application box popped up as a result; I had to type in
   the name of the zip file since the point-and-click seemed to
   insist that the extension be ``.zip'' (whereas it was/is actually
   ``.gz''.

The following set of error messages resulted:


> install.packages("F:/rproject/ts.sup_0.0-0.tar.gz", .libPaths()[1], CRAN = NULL)
updating HTML package descriptions
Error in file(f.tg, open = "w") : unable to open connection
In addition: Warning messages: 
1: error 1 in extracting from zip file 
2: cannot update HTML package index in: make.packages.html(lib.loc) 
3: cannot open file `O:\EXEFILES\RW1051/doc/html/search/index.txt' 
> 


So it can't open some ``connection'', can't do a bunch of other
things it thinks it ought to do, and seems to be looking at the
O: drive rather than the L: drive to which I directed its attention.

Can anyone suggest anything I might do to remedy the situation?

Do I need to process the zip file in a different way?  I tried
changing the extension to .zip, but of course that didn't help.

Is some piece of software missing?

If nothing can be done about the ``install' problem, is there any way
--- instead of installing a package --- that I can make the contents
of ``ts.sup'' available to my students over the Novell network.  (The
contents consist of functions, data sets, and documentation thereon.)

I'm groping around pretty blindly; I have no feel for Windows at all,
and our Computing Services people who run the Novell network know
nothing about R, so I'm unlikely to get any help from them.

Any advice greatly appreciated.

			cheers,

				Rolf Turner
				rolf at math.unb.ca


P. S. Version details:

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    5.1            
year     2002           
month    06             
day      17             
language R 

(I wonder a bit about that ``mingw32'' --- Windows 3.2??? ---
but that's what it says.)

				R. T.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jgentry at jimmy.harvard.edu  Fri Oct 11 20:36:36 2002
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Fri, 11 Oct 2002 14:36:36 -0400 (EDT)
Subject: [R] replace
In-Reply-To: <1034355495.5745.9.camel@whiper>
Message-ID: <Pine.SOL.4.20.0210111434200.9540-100000@santiam.dfci.harvard.edu>

> The thing I need to do is to replace NA values with 0.
> But I;m not able to determine how to do it.

In what sort of structure?

A vector?
> a <- c(1,2,NA,3,4,NA,5,6,NA)
> a
[1]  1  2 NA  3  4 NA  5  6 NA
> a[!is.na(a)]
[1] 1 2 3 4 5 6

A list?
> a <- list(1,2,3,NA,4,5,NA,6,NA,7)
> a[!sapply(a,is.na)]
[[1]]
[1] 1

[[2]]
[1] 2

[[3]]
[1] 3

[[4]]
[1] 4

[[5]]
[1] 5

[[6]]
[1] 6

[[7]]
[1] 7

Something else?

-Jeff

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fjmolina at lbl.gov  Fri Oct 11 09:38:40 2002
From: fjmolina at lbl.gov (Francisco J Molina)
Date: Fri, 11 Oct 2002 00:38:40 -0700
Subject: No subject
Message-ID: <15782.32768.844334.240092@0-e0-98-8a-c5-4a.dhcp.lbl.gov>

Subject: 
X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
Reply-To: fjmolina at lbl.gov
FCC: ~/mail/sent


I have noticed that my R processes do not occupay more than 50% of my CPU activity. Is
there any way of changing this?
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jzhang at jimmy.harvard.edu  Fri Oct 11 20:38:37 2002
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Fri, 11 Oct 2002 14:38:37 -0400 (EDT)
Subject: [R] replace
Message-ID: <200210111838.OAA06539@blaise.dfci.harvard.edu>


>Subject: [R] replace
>From: Peter Adamka <malmo at unitra.sk>
>To: r-help at stat.math.ethz.ch
>Content-Transfer-Encoding: 7bit
>Date: 11 Oct 2002 18:58:15 +0200
>Mime-Version: 1.0
>
>The thing I need to do is to replace NA values with 0.
>But I;m not able to determine how to do it.
>I'm relative new, pls Help.
>Malmo

Is this what you wanted?

tt <- c(1, 2, NA, NA, 5, NA)
tt[is.na(tt)] <- 0

tt now is:
tt
[1] 1 2 0 0 5 0

>
>
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brandt at unt.edu  Fri Oct 11 20:43:19 2002
From: brandt at unt.edu (Patrick Brandt)
Date: 11 Oct 2002 13:43:19 -0500
Subject: [R] Help about the white noise test
In-Reply-To: 
	<3A6D2FEEF9C3D51197E200034779C076068424EA@msdenfert.smt.cmi.net>
References: <3A6D2FEEF9C3D51197E200034779C076068424EA@msdenfert.smt.cmi.net>
Message-ID: <1034361800.23340.2.camel@pc97220.psci.unt.edu>

Try Box.test() in the package ts.

On Fri, 2002-10-11 at 10:44, Hajji Ouafi, Saad wrote:
> Hello,
> I would like to perform the test of white noise on a time serie. I couldn't
> find the instruction corresponding to the white noise test.
> Thank you
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-- 
Patrick T. Brandt
Assistant Professor
Department of Political Science
University of North Texas
brandt at unt.edu
http://www.psci.unt.edu/~brandt

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jgentry at jimmy.harvard.edu  Fri Oct 11 21:00:08 2002
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Fri, 11 Oct 2002 15:00:08 -0400 (EDT)
Subject: [R] replace
In-Reply-To: <Pine.SOL.4.20.0210111434200.9540-100000@santiam.dfci.harvard.edu>
Message-ID: <Pine.SOL.4.20.0210111457210.9540-100000@santiam.dfci.harvard.edu>

Following up on my own message, sorry I was just removing NAs, sorry.

> A vector?
> > a <- c(1,2,NA,3,4,NA,5,6,NA)
> > a
> [1]  1  2 NA  3  4 NA  5  6 NA

> a[is.na(a)] <- 0
> a
[1] 1 2 0 3 4 0 5 6 0

> A list?
> > a <- list(1,2,3,NA,4,5,NA,6,NA,7)
> a <- lapply(a,function(x){if(is.na(x))return(0) else(return(x))})
> a 
[[1]]
[1] 1

[[2]]
[1] 2

[[3]]
[1] 3

[[4]]
[1] 0

[[5]]
[1] 4

[[6]]
[1] 5

[[7]]
[1] 0

[[8]]
[1] 6

[[9]]
[1] 0

[[10]]
[1] 7


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Oct 11 21:09:32 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 11 Oct 2002 21:09:32 +0200
Subject: [R] Installing local package under Windows.
In-Reply-To: <200210111800.PAA06576@gelfand.math.unb.ca>
References: <200210111800.PAA06576@gelfand.math.unb.ca>
Message-ID: <x2vg48x05v.fsf@biostat.ku.dk>

Rolf Turner <rolf at math.unb.ca> writes:

> I cannot get this locally built package to install under
> this Windows system.  (The package was built under Unix, and
> installs there, with no complaints.)
> 
> I have been trying to follow the instructions in the ``R Installation
> and Administration'' guide, section 5.1 ``Installing packages.''
> 
> I proceeded as follows:
> 	
> 1. Uploaded the zip file ``ts.sup_0.0-0.tar.gz'' from the
>    Unix box to the Windows system, via ftp (binary mode set).

Whoops. There's your first problem. A .tar.gz file is not a zip file.
The 2nd problem is that this is a *source* package, whereas most of
the Windows procedures assume prepackaged binaries (and they are not
the same, even with no C/Fortran code involved).
 
> 4. Clicked on the Packages button of the R gui, and then on
> 
>    Install package from local zip file...
 
> 5. An application box popped up as a result; I had to type in
>    the name of the zip file since the point-and-click seemed to
>    insist that the extension be ``.zip'' (whereas it was/is actually
>    ``.gz''.

...so those steps are not going to work!
 
The correct steps are outlined in the src/gnuwin32/readme.packages
file in the source distribution. I think you can get away with
following the instructions near the end;

----
If you have a Unix/Linux box, it will suffice to zip up the Unix
installation of the package.  Install the package, then

        cd `R RHOME`/library
        zip -r9l /dest/mypkg.zip mypkg

(the -l flag converts to CRLF line endings: it is not necessary but
users may want to read the information files in a Windows editor).
----

Otherwise you'll have to install the tools and abide by the
instructions under "Simple ports". (In Brians typical style, these
instructions are generally accurate, but somewhat unforgiving. You
have to make sure that you read exactly what they say and not what you
think they probably ought to say...)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rlee at fpcc.net  Fri Oct 11 21:46:06 2002
From: rlee at fpcc.net (Rob Lee)
Date: Fri, 11 Oct 2002 13:46:06 -0600 (MDT)
Subject: [R] Rebuilding $HOME/.R/help.db
Message-ID: <Pine.LNX.4.33.0210111339260.5396-100000@aberdeen.fpcc.net>


I managed to delete my $HOME/.R/help.db

Now help.search("some.topic") reports:
"cannot open file $HOME/.R/help.db"

I can't find any documentation on how to rebuild it.

-R

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From s-luppescu at uchicago.edu  Fri Oct 11 21:53:10 2002
From: s-luppescu at uchicago.edu (Stuart Luppescu)
Date: 11 Oct 2002 14:53:10 -0500
Subject: [R] Any MD5 digests for source files?
Message-ID: <1034365990.23508.10.camel@musuko.uchicago.edu>

Do MD5 digests exist somewhere for the source packages? If not, is there
some other way to verify the integrity of the files we've downloaded?

Thanks.
-- 
Stuart Luppescu -=- s-luppescu at uchicago.edu        
University of Chicago -=- CCSR 
$B:MJ8$HCRF`H~$NIc(B -=-    Kernel 2.4.19-xfs-r1                
There *is* no such thing as a civil engineer. 
 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: This is a digitally signed message part
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021011/0d465628/attachment.bin

From ripley at stats.ox.ac.uk  Fri Oct 11 22:04:31 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 11 Oct 2002 21:04:31 +0100 (BST)
Subject: [R] read.table( ... comment.char="#") truncated my data
In-Reply-To: <OFAF5F871A.9A57AAF0-ON85256C4F.00578166@hgsi.com>
Message-ID: <Pine.LNX.4.31.0210112050340.11898-100000@gannet.stats>

The default has been "#" since version 1.4.0, that is for the last *five*
releases of R.  Changing *now* would be `not compatible earlier versions
of R'.

On Fri, 11 Oct 2002 Ren_Yu at hgsi.com wrote:

> I found that the new feature of the comment.char="#"  argument in the
> read.table function truncated my data while the data set actually contains
>  '#'. We analyze lot of data that contain '#'. This is really annoying and
> it is also not compatible earlier version of R. I searched the R archive
> and found the following message for the scan function. Is it possible to
> change the default to " " in read.table ?

Yes, and it is easy for you to do: see read.csv for a hint about how to do
so.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fjmolina at lbl.gov  Fri Oct 11 11:09:01 2002
From: fjmolina at lbl.gov (Francisco J Molina)
Date: Fri, 11 Oct 2002 02:09:01 -0700
Subject: No subject
Message-ID: <15782.38189.42371.814988@0-e0-98-8a-c5-4a.dhcp.lbl.gov>

Subject: activity of CPU used by R 
X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
Reply-To: fjmolina at lbl.gov
FCC: ~/mail/sent


My R processes never use more than 50% of my CPU activity. Is there any way I can make
them use more of it?
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Fri Oct 11 22:49:23 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Fri, 11 Oct 2002 16:49:23 -0400 (EDT)
Subject: [R] read.table( ... comment.char="#") truncated my data
In-Reply-To: <OFAF5F871A.9A57AAF0-ON85256C4F.00578166@hgsi.com>
Message-ID: <Pine.LNX.4.44.0210111645540.15042-100000@bolker.zoo.ufl.edu>


 I would guess the answer is yes (although I'm not in R-Core), but in the
meanwhile you can easily override the definition with your own by putting
something like

old.read.table <- read.table
read.table <- function(...) {
   old.read.table(...,comment.char="")
}

in your .Rprofile or .First function, which will work
as long as you never use the comment.char argument explicitly
with your new version of read.table ...

(warning: I haven't tested this)

On Fri, 11 Oct 2002 Ren_Yu at hgsi.com wrote:

> Dear all,
> 
> I found that the new feature of the comment.char="#"  argument in the 
> read.table function truncated my data while the data set actually contains 
>  '#'. We analyze lot of data that contain '#'. This is really annoying and 
> it is also not compatible earlier version of R. I searched the R archive 
> and found the following message for the scan function. Is it possible to 
> change the default to " " in read.table ?
> 
> Thanks,
> 
> Ren
> 
> 
> 
> On Tue, 19 Feb 2002, Steve Cassidy wrote: 
> > I've just discovered the recent addition of the comment.char arg to 
> scan, a 
> > useful feature no doubt but the default value of # rather than "" breaks 
> my 
> > code which looks for # as a delimeter in a file and provides a messy 
> > incompatability with earlier versions of R and with Splus. 
> > 
> > Is there any chance that this default could be changed to ""? 
> It already has been. The NEWS for R-patched / R-devel says: 
>     o The default has been changed to scan(comment.char="") for 
>         consistency with earlier code (as in the previous item). 
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Fri Oct 11 22:56:25 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Fri, 11 Oct 2002 16:56:25 -0400 (EDT)
Subject: [R] replace
In-Reply-To: <1034355495.5745.9.camel@whiper>
Message-ID: <Pine.LNX.4.44.0210111656170.15056-100000@bolker.zoo.ufl.edu>


x[is.na(x)] <- 0

On 11 Oct 2002, Peter Adamka wrote:

> The thing I need to do is to replace NA values with 0.
> But I;m not able to determine how to do it.
> I'm relative new, pls Help.
> Malmo
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ren_Yu at hgsi.com  Fri Oct 11 23:18:49 2002
From: Ren_Yu at hgsi.com (Ren_Yu@hgsi.com)
Date: Fri, 11 Oct 2002 17:18:49 -0400
Subject: [R] read.table( ... comment.char="#") truncated my data
Message-ID: <OFCECA5759.BA0C468C-ON85256C4F.0074CD3F@hgsi.com>

Thanks a lot! That works. This will solve my problem. Otherwise I need to 
update lots of R functions we have developed based on R1.3.1.




Ben Bolker <ben at zoo.ufl.edu>
10/11/2002 04:49 PM
Please respond to bolker

 
        To:     Ren_Yu at hgsi.com
        cc:     r-help at stat.math.ethz.ch
        Subject:        Re: [R] read.table( ... comment.char="#") truncated my data



 I would guess the answer is yes (although I'm not in R-Core), but in the
meanwhile you can easily override the definition with your own by putting
something like

old.read.table <- read.table
read.table <- function(...) {
   old.read.table(...,comment.char="")
}

in your .Rprofile or .First function, which will work
as long as you never use the comment.char argument explicitly
with your new version of read.table ...

(warning: I haven't tested this)

On Fri, 11 Oct 2002 Ren_Yu at hgsi.com wrote:

> Dear all,
> 
> I found that the new feature of the comment.char="#"  argument in the 
> read.table function truncated my data while the data set actually 
contains 
>  '#'. We analyze lot of data that contain '#'. This is really annoying 
and 
> it is also not compatible earlier version of R. I searched the R archive 

> and found the following message for the scan function. Is it possible to 

> change the default to " " in read.table ?
> 
> Thanks,
> 
> Ren
> 
> 
> 
> On Tue, 19 Feb 2002, Steve Cassidy wrote: 
> > I've just discovered the recent addition of the comment.char arg to 
> scan, a 
> > useful feature no doubt but the default value of # rather than "" 
breaks 
> my 
> > code which looks for # as a delimeter in a file and provides a messy 
> > incompatability with earlier versions of R and with Splus. 
> > 
> > Is there any chance that this default could be changed to ""? 
> It already has been. The NEWS for R-patched / R-devel says: 
>     o The default has been changed to scan(comment.char="") for 
>         consistency with earlier code (as in the previous item). 
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20021011/b6b58ef1/attachment.html

From tkeitt at mail.utexas.edu  Fri Oct 11 23:31:36 2002
From: tkeitt at mail.utexas.edu (Timothy H. Keitt)
Date: 11 Oct 2002 17:31:36 -0400
Subject: [R] Re: no subject (cpu usage)
In-Reply-To: <15782.38189.42371.814988@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
References: <15782.38189.42371.814988@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
Message-ID: <1034371899.6877.53.camel@peregrine>

Remove that pesky second processor!

Tim

On Fri, 2002-10-11 at 05:09, Francisco J Molina wrote:
> Subject: activity of CPU used by R 
> X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
> Reply-To: fjmolina at lbl.gov
> FCC: ~/mail/sent
> 
> 
> My R processes never use more than 50% of my CPU activity. Is there any way I can make
> them use more of it?
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-- 
Timothy H. Keitt
Section of Integrative Biology
University of Texas at Austin

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From aolinto at bignet.com.br  Fri Oct 11 23:39:40 2002
From: aolinto at bignet.com.br (Antonio Olinto)
Date: Fri, 11 Oct 2002 18:39:40 -0300
Subject: [R] barplot x axis
References: <200210111800.PAA06576@gelfand.math.unb.ca> <x2vg48x05v.fsf@biostat.ku.dk>
Message-ID: <008801c2716e$c9c0eb40$39cffea9@batata>

Hi,

I'm running r160 under Windows 98SE and I noticed that barplots are
different in this version. "X" axis line is not drawn any more. How can I
make it visible again?

Thanks,

Antonio Olinto





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Fri Oct 11 23:43:25 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 Oct 2002 16:43:25 -0500
Subject: [R] absurd computiation times of lme
In-Reply-To: <87wuooor55.fsf@home.nicht-ich.de>
References: <87lm55gnqf.fsf@home.nicht-ich.de> <3DA6D86B.1B82044B@sentoo.sn>
	<87wuooor55.fsf@home.nicht-ich.de>
Message-ID: <6r1y6w648y.fsf@bates4.stat.wisc.edu>

Christof Meigen <christof at nicht-ich.de> writes:

> Renaud Lancelot <lancelot at sentoo.sn> writes:
> > It is because of the random effects (the estimations of the var-cov
> > random-effect matrix is very computer intensive). I think you would need
> > a very large data set to be able to estimate so many random-effect
> > parameters (21 parameters: 6 variances and 15 covariances). 
> 
> Well, in the case of the children I do have quite large datasets,
> around 1000 children with altogether much more than 5000 measurements.

But you are also implicitly estimating the random effects for each
child.  These are sometimes regarded as 'nuisance' parameters but they
still need to be estimated, at least implicitly.  In this case there
would be about 6000 of them (1000 children by 6 random effects per
child).

I would recommend that you start with a spline model for the fixed
effects but use either a simple additive shift for the random effects
(random = ~1|Subject) or an additive shift and a shift in the time
trend (random = ~ age | Subject).  You simply don't have enough data
to estimate 6 parameters from the data for each child.

There is a big difference when fitting random effects between adding
parameters in the fixed effects, which are estimated from all the
data, and adding parameters in the random effects, which are estimated
from the data for one subject.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Sat Oct 12 01:59:20 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 11 Oct 2002 16:59:20 -0700 (PDT)
Subject: [R] Any MD5 digests for source files?
In-Reply-To: <1034365990.23508.10.camel@musuko.uchicago.edu>
Message-ID: <Pine.A41.4.44.0210111643520.44210-100000@homer32.u.washington.edu>

On 11 Oct 2002, Stuart Luppescu wrote:

> Do MD5 digests exist somewhere for the source packages? If not, is there
> some other way to verify the integrity of the files we've downloaded?

No, there aren't any things like that.  There have been discussions from
time to time about signing packages, but it never got anywhere.

Without some way to certify public keys it would be less helpful than you
might think. If you download from the central CRAN site in Austria then a
package can only be invalid if either the maintainer's computers were
cracked or if they were misled into accepting a fake package.  In neither
case could you trust CRAN for MD5 digests.

You would need packages to be signed by their authors, using public keys
available independently from CRAN or certified by someone you trust to get
a genuine improvement in security. This would be useful (along the lines
that Debian uses), but it hasn't happened yet.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Sat Oct 12 03:22:17 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri, 11 Oct 2002 18:22:17 -0700 (PDT)
Subject: [R] CPU activity
In-Reply-To: <15782.38189.42371.814988@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
Message-ID: <Pine.GSO.4.10.10210111821240.3120-100000@fisher.stat.ucla.edu>

Are you using a dual processor machine?  Some versions of 'top' only
report 50% usage when you're using one processor.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Fri, 11 Oct 2002, Francisco J Molina wrote:

> Subject: activity of CPU used by R 
> X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
> Reply-To: fjmolina at lbl.gov
> FCC: ~/mail/sent
> 
> 
> My R processes never use more than 50% of my CPU activity. Is there any way I can make
> them use more of it?
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Sat Oct 12 04:44:25 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 11 Oct 2002 21:44:25 -0500
Subject: [R] barplot x axis
In-Reply-To: <008801c2716e$c9c0eb40$39cffea9@batata>
Message-ID: <000901c27199$47d2fda0$0201a8c0@MARC>

> -----Original Message-----
> Hi,
> 
> I'm running r160 under Windows 98SE and I noticed that barplots are
> different in this version. "X" axis line is not drawn any more. How
can I
> make it visible again?
> 
> Thanks,
> 
> Antonio Olinto

To the best of my knowledge, nothing in barplot() has changed recently.

Are you referring to having column names printed below the bars or an
actual axis line with tick marks and labels?

If the former (just bar labels) then:

If your 'height' argument does not have a 'names' attribute, then no
names will be printed below the bars (or to the left of the bars if
horiz = TRUE). 

You can check this by 

> names(height)

replacing the actual vector name that you are using for 'height'.  If it
returns NULL, that is why you are not getting bar labels.

You can either create a names attribute or explicitly define the column
names by passing a vector of names to the 'names.arg' argument to
barplot().

Try this to demonstrate:

> test <- 1:20
> barplot(test)

This will draw 20 vertical bars with no bar labels.

Now try:

> test <- 1:20
> names(test) <- 1:20
> barplot(test)

Now 'test' has a names attribute and you will get 20 bars labeled with
1:20 under the bars.

Alternatively, you can also do the following using names.arg:

> test <- 1:20
> barplot(test, names.arg = 1:20)

This will also result in 20 bars labeled with 1:20 under the bars.


If the latter (a lined axis with tick marks and labels) then:

> test <- 1:20
> mp <- barplot(test)
> axis(1, at = mp, labels = 1:20)

The second line stores the mid-points of the bars in 'mp'. The third
line creates an x axis ('1'), with tickmarks set at the bar mid-points
('at = mp') and labels below the tickmarks of 1:20.

Lastly, if you want a frame around the entire plot, call:

> box()

HTH.

Marc Schwartz



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Oct 12 07:19:53 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 12 Oct 2002 06:19:53 +0100 (BST)
Subject: [R] read.table( ... comment.char="#") truncated my data
In-Reply-To: <OFCECA5759.BA0C468C-ON85256C4F.0074CD3F@hgsi.com>
Message-ID: <Pine.LNX.4.31.0210120615010.12540-100000@gannet.stats>

On Fri, 11 Oct 2002 Ren_Yu at hgsi.com wrote:

> Thanks a lot! That works. This will solve my problem. Otherwise I need to
> update lots of R functions we have developed based on R1.3.1.
>
>
>
>
> Ben Bolker <ben at zoo.ufl.edu>
> 10/11/2002 04:49 PM
> Please respond to bolker
>
>
>         To:     Ren_Yu at hgsi.com
>         cc:     r-help at stat.math.ethz.ch
>         Subject:        Re: [R] read.table( ... comment.char="#") truncated my data
>
>
>
>  I would guess the answer is yes (although I'm not in R-Core), but in the
> meanwhile you can easily override the definition with your own by putting
> something like

Well, no, you can't in R>=1.6.0.  Sometimes the definition in base will be
used, depending if namespaces are involved.

> old.read.table <- read.table
> read.table <- function(...) {
>    old.read.table(...,comment.char="")
> }
>
> in your .Rprofile or .First function, which will work
> as long as you never use the comment.char argument explicitly
> with your new version of read.table ...
>
> (warning: I haven't tested this)

A better version (following read.csv as I hinted previously)

old.read,table <- function(..., comment.char="")
   read.table(..., comment.char=comment.char)

and use old.read.table explicitly.

>
> On Fri, 11 Oct 2002 Ren_Yu at hgsi.com wrote:
>
> > Dear all,
> >
> > I found that the new feature of the comment.char="#"  argument in the
> > read.table function truncated my data while the data set actually
> contains
> >  '#'. We analyze lot of data that contain '#'. This is really annoying
> and
> > it is also not compatible earlier version of R. I searched the R archive
>
> > and found the following message for the scan function. Is it possible to
>
> > change the default to " " in read.table ?
> >
> > Thanks,
> >
> > Ren
> >
> >
> >
> > On Tue, 19 Feb 2002, Steve Cassidy wrote:
> > > I've just discovered the recent addition of the comment.char arg to
> > scan, a
> > > useful feature no doubt but the default value of # rather than ""
> breaks
> > my
> > > code which looks for # as a delimeter in a file and provides a messy
> > > incompatability with earlier versions of R and with Splus.
> > >
> > > Is there any chance that this default could be changed to ""?
> > It already has been. The NEWS for R-patched / R-devel says:
> >     o The default has been changed to scan(comment.char="") for
> >         consistency with earlier code (as in the previous item).
> >
>
> --
> 318 Carr Hall                                bolker at zoo.ufl.edu
> Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
> Box 118525                                   (ph)  352-392-5697
> Gainesville, FL 32611-8525                   (fax) 352-392-3704
>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lina at u.washington.edu  Thu Oct 10 23:17:45 2002
From: lina at u.washington.edu (Michael Na Li)
Date: Thu, 10 Oct 2002 14:17:45 -0700
Subject: [R] Re: [R-gui] NEdit Highligth patterns for R
In-Reply-To: <20021010174118.GA1372@komensky.surfbest.net> (Matej Cepl's
 message of "Thu, 10 Oct 2002 13:41:18 -0400")
References: <1034248750.5057.77.camel@gandalf> <x2bs62wmh6.fsf@biostat.ku.dk>
	<1034256247.5051.80.camel@gandalf>
	<200210100933010600.0020E828@smtp.interchange.ubc.ca>
	<20021010174118.GA1372@komensky.surfbest.net>
Message-ID: <jeit0at2me.fsf@qiuranke.phony.washington.edu>

On Thu, 10 Oct 2002, Matej Cepl stated:

>  On Thu, Oct 10, 2002 at 09:33:01AM -0700, Dan Putler wrote:
> > Zed Shaw has written an R/S context highlighter for JEdit
> > (www.jedit.org), an open source text editor written in Java (no
> > need for Cygwin, and it runs on Macs as well).  The URL to the
>  
>  I believe that NEdit is a native Windows application (but I am
>  not sure using gvim under Linux most of the time) so no need of
>  both cygwin and Java.

But it needs an X server where cygwin-x11 is the only one that's free.

Michael  

-- 
----------------------------------------------------------------------------
Michael Na Li                               
Email: lina at u.washington.edu
Department of Biostatistics, Box 357232
University of Washington, Seattle, WA 98195  
---------------------------------------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From juli at ceam.es  Sat Oct 12 15:35:34 2002
From: juli at ceam.es (juli g. pausas)
Date: Sat, 12 Oct 2002 15:35:34 +0200
Subject: [R] barplot x axis
Message-ID: <3DA82526.5BB9C889@ceam.es>

Perhaps you could solve it using:     box()



> Date: Fri, 11 Oct 2002 18:39:40 -0300
> From: "Antonio Olinto"
> Subject: [R] barplot x axis
>
> Hi,
>
> I'm running r160 under Windows 98SE and I noticed that barplots are
> different in this version. "X" axis line is not drawn any more. How can I
> make it visible again?
>
> Thanks,
>
> Antonio Olinto
>




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From aolinto at bignet.com.br  Sat Oct 12 17:02:27 2002
From: aolinto at bignet.com.br (aolinto@bignet.com.br)
Date: Sat, 12 Oct 2002 12:02:27 -0300
Subject: [R] barplot x axis
In-Reply-To: <000901c27199$47d2fda0$0201a8c0@MARC>
References: <000901c27199$47d2fda0$0201a8c0@MARC>
Message-ID: <1034434947.3da839830f56b@webmail.bcmg.com.br>

Dear Schwartz and Pausas,

Thanks for your messages.

I was referring to the axis line and its tick marks.

If you write barplot(table(c(1,2,2,3,3,3,4,4,5))) in R150 and in R160 you will 
have different plots. The last one will not display the x axis line and tick 
marks, but only x axis labels, isn't it?

In this case "axis(1, at = mp, labels = 1:5)" solves the problem.

Best regards,

Antonio Olinto


Marc Schwartz <mschwartz at medanalytics.com>:

> To the best of my knowledge, nothing in barplot() has changed recently.
> 
> Are you referring to having column names printed below the bars or an
> actual axis line with tick marks and labels?
> 
> If the former (just bar labels) then:
> 
> If your 'height' argument does not have a 'names' attribute, then no
> names will be printed below the bars (or to the left of the bars if
> horiz = TRUE). 
> 
> You can check this by 
> 
> > names(height)
> 
> replacing the actual vector name that you are using for 'height'.  If it
> returns NULL, that is why you are not getting bar labels.
> 
> You can either create a names attribute or explicitly define the column
> names by passing a vector of names to the 'names.arg' argument to
> barplot().
> 
> Try this to demonstrate:
> 
> > test <- 1:20
> > barplot(test)
> 
> This will draw 20 vertical bars with no bar labels.
> 
> Now try:
> 
> > test <- 1:20
> > names(test) <- 1:20
> > barplot(test)
> 
> Now 'test' has a names attribute and you will get 20 bars labeled with
> 1:20 under the bars.
> 
> Alternatively, you can also do the following using names.arg:
> 
> > test <- 1:20
> > barplot(test, names.arg = 1:20)
> 
> This will also result in 20 bars labeled with 1:20 under the bars.
> 
> 
> If the latter (a lined axis with tick marks and labels) then:
> 
> > test <- 1:20
> > mp <- barplot(test)
> > axis(1, at = mp, labels = 1:20)
> 
> The second line stores the mid-points of the bars in 'mp'. The third
> line creates an x axis ('1'), with tickmarks set at the bar mid-points
> ('at = mp') and labels below the tickmarks of 1:20.
> 
> Lastly, if you want a frame around the entire plot, call:
> 
> > box()
> 
> HTH.
> 
> Marc Schwartz
> 
> 



---
Mensagem enviada via webmail.bcmg.com.br
---
Bignet CMG Navegando com voce !
SITE..: http://www.bcmg.com.br
EMAIL.: suporte at bcmg.com.br

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krupa at alpha.sggw.waw.pl  Sat Oct 12 19:44:03 2002
From: krupa at alpha.sggw.waw.pl (Jan Krupa)
Date: Sat, 12 Oct 2002 19:44:03 +0200 (CEST)
Subject: [R] Learning R: which book to choose?
Message-ID: <Pine.LNX.4.21.0210121940380.1008-100000@mel222.sggw.waw.pl>


I am new to R. I am going to by one of the following book:

1.
William N. Venables and Brian D. Ripley. Modern Applied Statistics 
with S-Plus.
Third Edition. Springer, 1999. ISBN 0-387-98825-4.

2.
 The  Fourth Edition of the book from point 1.

3.
`S Programming'
 by W. N. Venables and B. D. Ripley
 Springer. ISBN 0-387-98966-8, 2000.


I can only by one of the above books.

Q1.
I have found the following info at the site
http://www.stats.ox.ac.uk/pub/MASS4/ :

''The material on programming has been reduced since the first and 
second editions''

Is that also true that 
The material on programming has been reduced since the THIRD  edition?

Q2. Which of the books 1 or 2 do you suggest to buy?
I mean which one is more complete?
May be the third (3) book would be enough to learn R?

TIA

Jan

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sat Oct 12 20:09:22 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Oct 2002 20:09:22 +0200
Subject: [R] binary to decimal number
References: <200210111642.23640.egonw@sci.kun.nl>
Message-ID: <3DA86552.699DC596@statistik.uni-dortmund.de>



"E.L. Willighagen" wrote:
> 
> Hi all,
> 
> is there a method for transforming 1010 into 10, i.e. a binary number
> into a decimal value?

I don't have a clever idea right now, but the following should do the
trick, if your binary number is called "b":

 bindec <- function(b) 
   sum(as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0))

 bindec(b)

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sat Oct 12 20:23:02 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Oct 2002 20:23:02 +0200
Subject: [R] Rebuilding $HOME/.R/help.db
References: <Pine.LNX.4.33.0210111339260.5396-100000@aberdeen.fpcc.net>
Message-ID: <3DA86886.FCFB0ED@statistik.uni-dortmund.de>



Rob Lee wrote:
> 
> I managed to delete my $HOME/.R/help.db
> 
> Now help.search("some.topic") reports:
> "cannot open file $HOME/.R/help.db"
> 
> I can't find any documentation on how to rebuild it.

Regularly, rebuild is done by help.search() automatically if the file is
missing and you haven't changed the defaults for the function nor those
in options(). Look closer if you have changed anything or maybe there
are wrong permissions ...

Uwe Ligges

BTW: The location of the file has changed in R-1.6.0, see the NEWS file.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sat Oct 12 20:29:36 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Oct 2002 20:29:36 +0200
Subject: [R] plot region ??
References: <3DA6BA62.4@tuebingen.mpg.de>
Message-ID: <3DA86A10.31EEE1CC@statistik.uni-dortmund.de>



Jan Malte Wiener wrote:
> 
> hi,
> i am using the barplot function, but i have problems with the plot
> region when adjusting the bar width manually. if you only want to plot 2
> bars the default barwidth is to wide (aesthetically speaking). by
> adjusting width and xlim one can actually produce narrow bars, but then
> the plotted graph is not in the center of the plot region, which means
> that for example the title of the plot isn't centered above the barplot.
> 
> e.g.
> toPlot<-c(5,6)
> barplot(toPlot, width=c(0.4), xlim=c(0,3))
> title(main = "Female - Male", font.main=2)
> 
> any ideas how to get rid of this problem ??

barplot() returns the x locations, so just call it two times (the second
time more fuzzy) as follows, or look at the code how the locations are
calculated internally.

  temp <- barplot(toPlot, width = 0.4)
  barplot(toPlot, width = 0.4, xlim = mean(temp) + c(-2, 2))
 
Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From juli at ceam.es  Sat Oct 12 20:27:26 2002
From: juli at ceam.es (juli g. pausas)
Date: Sat, 12 Oct 2002 20:27:26 +0200
Subject: [R] reshape
Message-ID: <3DA8698E.691C1A99@ceam.es>

I'd like to convert a data.frame from (long format):
gen   maxh  resp
1         12.3   y
.           .       .
.           .       .
where resp is a factor with levels "y" and "n"
to the wide format:

gen  maxh.y  maxh.n
.           .       .
.           .       .

I've done it as follows:

maxh.y <- split(maxh, resp)$y
gy <- split(gen, resp)$y
yes <- data.frame(hr, gen=gy)

maxh.n <- split(maxh, resp)$n
gn <- split(gen, resp)$n
no <- data.frame(hn, gen=gn)

wide <- merge(yes, no, by= "gen") # gen maxh.y maxh.n

This worked well, but would it be possible to do it with reshape? I've
tried but I didn't succeed.
Thanks

Juli

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Mike.Prager at noaa.gov  Sat Oct 12 20:43:12 2002
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Sat, 12 Oct 2002 14:43:12 -0400
Subject: [R] Learning R: which book to choose?
In-Reply-To: <Pine.LNX.4.21.0210121940380.1008-100000@mel222.sggw.waw.pl
 >
Message-ID: <5.1.0.14.0.20021012143338.00a74918@hermes.nos.noaa.gov>

At 07:44 PM 10/12/2002 +0200, Jan Krupa wrote:
>I am new to R. I am going to by one of the following book:
>
>1. [...]Modern Applied Statistics [MASS] with S-Plus. Third Edition.[...]
>
>2. The  Fourth Edition of the book from point 1.
>
>3. `S Programming'[...]
>
>  Q1. ''The material on programming has been reduced since the first and 
> second editions''  Is that also true that
>The material on programming has been reduced since the THIRD  edition?

Not as far as I can see.

>  Q2. Which of the books 1 or 2 do you suggest to buy? I mean which one is 
> more complete?

The 4th edn is more up to date than the 3rd edn., and it has added specific 
coverage of R.

>  May be the third (3) book would be enough to learn R?

#2 (MASS 4) would probably be better.  It covers basic programming and also 
many of the available S functions, including statistical and graphics 
routines. For most users, it would be a better introduction than `S 
Programming', which is more technically oriented.


-- 
Michael Prager, Ph.D.                <Mike.Prager at noaa.gov>
NOAA Beaufort Laboratory
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/
***

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tdt2+ at pitt.edu  Sat Oct 12 21:34:24 2002
From: tdt2+ at pitt.edu (Truc Truong)
Date: Sat, 12 Oct 2002 15:34:24 -0400
Subject: [R] max, min residuals for qqnorm plot
Message-ID: <22831530.1034436864@HL145.fdl.pitt.edu>

>From Tom Truong, biostat student at Univ of Pittsburgh

I would like to get the max, min values for residuals on my qqnorm plot to 
compare the skewness between different transformations.  Can you suggest a 
command or some ways to accomplish this?   Thank you.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ko-Kang at xtra.co.nz  Sat Oct 12 21:44:19 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Sun, 13 Oct 2002 08:44:19 +1300
Subject: [R] Learning R: which book to choose?
References: <Pine.LNX.4.21.0210121940380.1008-100000@mel222.sggw.waw.pl>
Message-ID: <004901c27227$eaf040e0$b32558db@kwan022>

----- Original Message -----
From: "Jan Krupa" <krupa at alpha.sggw.waw.pl>
To: "r-help mailing list" <r-help at stat.math.ethz.ch>
Sent: Sunday, October 13, 2002 6:44 AM
Subject: [R] Learning R: which book to choose?


>
> I am new to R. I am going to by one of the following book:
>
> 1.
> William N. Venables and Brian D. Ripley. Modern Applied Statistics
> with S-Plus.
> Third Edition. Springer, 1999. ISBN 0-387-98825-4.
>
> 2.
>  The  Fourth Edition of the book from point 1.
>
> 3.
> `S Programming'
>  by W. N. Venables and B. D. Ripley
>  Springer. ISBN 0-387-98966-8, 2000.
>
>
> I can only by one of the above books.
>
> Q1.
> I have found the following info at the site
> http://www.stats.ox.ac.uk/pub/MASS4/ :
>
> ''The material on programming has been reduced since the first and
> second editions''
>
> Is that also true that
> The material on programming has been reduced since the THIRD  edition?
>
> Q2. Which of the books 1 or 2 do you suggest to buy?
> I mean which one is more complete?
> May be the third (3) book would be enough to learn R?

It depends on what you want to do.  If you are only using R to do normal
analysis, either (1) or (2) above will be sufficient.  I would recommend
(2), as it is the latest version AND it is written for R 1.5.0 in mind, i.e.
takes in the changes made since MASS3.  MASS3 was written a bit more towards
S-plus, though the materials can be used in R too.  As for the pricing, I
think both MASS3 and MASS4 have roughly the same price.

S Programing is more for developers or more experienced users (I've a copy
of it, as well as MASS4).  It also talks about the object-oriented features,
how to write classes, functions...etc.

Hope this helps,

Ko-Kang Wang


------------------------------------------------
Ko-Kang Kevin Wang
Post Graduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Sat Oct 12 22:46:20 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sat, 12 Oct 2002 15:46:20 -0500
Subject: [R] barplot x axis
In-Reply-To: <1034434947.3da839830f56b@webmail.bcmg.com.br>
Message-ID: <001301c27230$6c97f590$0201a8c0@MARC>

> -----Original Message-----
> Dear Schwartz and Pausas,
> 
> Thanks for your messages.

You are welcome.

> I was referring to the axis line and its tick marks.
> 
> If you write barplot(table(c(1,2,2,3,3,3,4,4,5))) in R150 and in R160
you will
> have different plots. The last one will not display the x axis line
and tick
> marks, but only x axis labels, isn't it?
> 
> In this case "axis(1, at = mp, labels = 1:5)" solves the problem.
> 
> Best regards,
> 
> Antonio Olinto

Antonio,

It turns out that the change in behavior, which I was able to duplicate
by re-installing V1.5.1 on my system, is the result in the change in
coding in the axis() function internal C code (do_axis) in V.1.6.0 and
not in barplot().  The code in barplot() did not change either in
content or in the default argument values.

If you review the C do_axis code in the V1.5.1 plot.c, which is the C
source code for many of the plotting functions, you will find that the
author overrides the passed "lty" argument.  The author has a comment in
the C code as follows:

  /* I can't think of a good reason to allow axes with a non-solid
line-type,
     * so I override any value the user may have specified.
     * This may need to be revisited, but this should
     * cover 99.99% of the cases. */

In barplot(), the following code is called to draw the label axis (x
axis when horiz = FALSE):

axis(if (horiz) 
                2
            else 1, at = at.l, labels = names.arg, lty = 0, cex.axis =
cex.names, 
                ...)

Note that the 'lty' argument is specified as "0", which should be
"blank" or no line.

However, the V1.5.x internal C code in plot.c overrides this value with
"solid" as per the author's comments above. Thus in V.1.5.x, you get a
solid line on the x axis.

In V.1.6.0, there was a change in axis() to allow for the user
specification of "lty", "lwd" and "col" line parameters as arguments to
axis().  

The V1.6.0 internal C code for do_axis was changed to facilitate this
and therefore the axis call in V.1.6.0 barplot() as above now results in
no line being drawn, since the "lty = 0" (blank) argument in not
overridden in the internal C code.

Hence the (perhaps unintended) change in the default behavior in
barplot() in V.1.6.0.

It took me a while to track this down and finally isolated it to the
axis() function change in 1.6.0.

I am also copying this reply to r-devel, more as an FYI, since my guess
is that other functions, either R standard functions or community based
functions, may have their default behavior altered as well.

Marc Schwartz



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Sat Oct 12 11:31:29 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sat, 12 Oct 2002 22:31:29 +1300
Subject: [R] Learning R: which book to choose?
In-Reply-To: <Pine.LNX.4.21.0210121940380.1008-100000@mel222.sggw.waw.pl>; from krupa@alpha.sggw.waw.pl on Sat, Oct 12, 2002 at 07:44:03PM +0200
References: <Pine.LNX.4.21.0210121940380.1008-100000@mel222.sggw.waw.pl>
Message-ID: <20021012223129.A27891@camille.indigoindustrial.co.nz>

On Sat, Oct 12, 2002 at 07:44:03PM +0200, Jan Krupa wrote:
> I am new to R. I am going to by one of the following book:
> 
> 1.
> William N. Venables and Brian D. Ripley. Modern Applied Statistics 
> with S-Plus.
> Third Edition. Springer, 1999. ISBN 0-387-98825-4.
> 
> 2.
>  The  Fourth Edition of the book from point 1.
> 
> 3.
> `S Programming'
>  by W. N. Venables and B. D. Ripley
>  Springer. ISBN 0-387-98966-8, 2000.

It depends.  Do you want to use R for analysis, or to write your
own extensions?  Probably the first, I'd guess; extension writing 
usually comes later.

Modern Applied Statistics with S-Plus, 4th edition (MASS4) is a good 
introduction if you're already a statistician.  If not, a a good
introductory book is

Introductory Statistics with R.  Peter Dalgaard.  Springer.
ISBN 0387954759

MASS4 is certainly more complete than ISwR, but if you're not already 
a statistician, it's a difficult starting book (challenging, but not
impossible).

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cnlawren at phy.olemiss.edu  Sun Oct 13 06:21:05 2002
From: cnlawren at phy.olemiss.edu (Chris Lawrence)
Date: Sat, 12 Oct 2002 23:21:05 -0500
Subject: [R] Learning R: which book to choose?
In-Reply-To: <Pine.LNX.4.21.0210121940380.1008-100000@mel222.sggw.waw.pl>
References: <Pine.LNX.4.21.0210121940380.1008-100000@mel222.sggw.waw.pl>
Message-ID: <20021013042105.GA26429@phy.olemiss.edu>

On Oct 12, Jan Krupa wrote:
> I am new to R. I am going to by one of the following book:
> 
> 1.
> William N. Venables and Brian D. Ripley. Modern Applied Statistics 
> with S-Plus.
> Third Edition. Springer, 1999. ISBN 0-387-98825-4.
> 
> 2.
>  The  Fourth Edition of the book from point 1.
> 
> 3.
> `S Programming'
>  by W. N. Venables and B. D. Ripley
>  Springer. ISBN 0-387-98966-8, 2000.
> 
> 
> I can only by one of the above books.

It really depends on your field and level of expertise.  If you are a
statistician (i.e. you have a degree in statistics or biostatistics),
or from a very strong mathematical backgroud, MASS is probably the
appropriate book, although you may want something more introductory.
(I haven't seen MASS4 yet.)

OTOH, if you're a social scientist, I'd *strongly* recommend John
Fox's "Companion to Applied Regression with R and S-Plus."

(It also depends somewhat on what you actually want to do with R, as
others have suggested...)


Chris
-- 
Chris Lawrence <cnlawren at phy.olemiss.edu> - http://www.lordsutch.com/chris/

Computer Systems Manager, Physics and Astronomy, Univ. of Mississippi
Ph.D. Candidate, Political Science
125B Lewis Hall - 662-915-5765
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Oct 13 09:27:01 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 13 Oct 2002 08:27:01 +0100 (BST)
Subject: [R] barplot x axis
In-Reply-To: <1034434947.3da839830f56b@webmail.bcmg.com.br>
Message-ID: <Pine.LNX.4.31.0210130821550.22048-100000@gannet.stats>

The error appears to have been in R 1.5.x, not 1.6.0.  The horizontal axis
was plotted with lty=0, and that was not being respected in 1.5.x.  As
from 1.6.0 axis() does respect lty (and other arguments: see the NEWS
file).

BTW, please do use the R version numbers, not your own private ones!

On Sat, 12 Oct 2002 aolinto at bignet.com.br wrote:

> Dear Schwartz and Pausas,
>
> Thanks for your messages.
>
> I was referring to the axis line and its tick marks.
>
> If you write barplot(table(c(1,2,2,3,3,3,4,4,5))) in R150 and in R160 you will
> have different plots. The last one will not display the x axis line and tick
> marks, but only x axis labels, isn't it?
>
> In this case "axis(1, at = mp, labels = 1:5)" solves the problem.
>
> Best regards,
>
> Antonio Olinto
>
>
> Marc Schwartz <mschwartz at medanalytics.com>:
>
> > To the best of my knowledge, nothing in barplot() has changed recently.
> >
> > Are you referring to having column names printed below the bars or an
> > actual axis line with tick marks and labels?
> >
> > If the former (just bar labels) then:
> >
> > If your 'height' argument does not have a 'names' attribute, then no
> > names will be printed below the bars (or to the left of the bars if
> > horiz = TRUE).
> >
> > You can check this by
> >
> > > names(height)
> >
> > replacing the actual vector name that you are using for 'height'.  If it
> > returns NULL, that is why you are not getting bar labels.
> >
> > You can either create a names attribute or explicitly define the column
> > names by passing a vector of names to the 'names.arg' argument to
> > barplot().
> >
> > Try this to demonstrate:
> >
> > > test <- 1:20
> > > barplot(test)
> >
> > This will draw 20 vertical bars with no bar labels.
> >
> > Now try:
> >
> > > test <- 1:20
> > > names(test) <- 1:20
> > > barplot(test)
> >
> > Now 'test' has a names attribute and you will get 20 bars labeled with
> > 1:20 under the bars.
> >
> > Alternatively, you can also do the following using names.arg:
> >
> > > test <- 1:20
> > > barplot(test, names.arg = 1:20)
> >
> > This will also result in 20 bars labeled with 1:20 under the bars.
> >
> >
> > If the latter (a lined axis with tick marks and labels) then:
> >
> > > test <- 1:20
> > > mp <- barplot(test)
> > > axis(1, at = mp, labels = 1:20)
> >
> > The second line stores the mid-points of the bars in 'mp'. The third
> > line creates an x axis ('1'), with tickmarks set at the bar mid-points
> > ('at = mp') and labels below the tickmarks of 1:20.
> >
> > Lastly, if you want a frame around the entire plot, call:
> >
> > > box()
> >
> > HTH.
> >
> > Marc Schwartz
> >
> >
>
>
>
> ---
> Mensagem enviada via webmail.bcmg.com.br
> ---
> Bignet CMG Navegando com voce !
> SITE..: http://www.bcmg.com.br
> EMAIL.: suporte at bcmg.com.br
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From valdentro at hotmail.com  Sun Oct 13 12:26:35 2002
From: valdentro at hotmail.com (juan pablo perez)
Date: Sun, 13 Oct 2002 10:26:35 +0000
Subject: [R] row and column totals in multidimensional tables
Message-ID: <F504nDVwEdkCBD2Fcke00000e74@hotmail.com>



Hello!

the function apply() allows to compute the row sum of a multidimensional 
table but, when I try to merge the new column with the original table whith 
cbind(), the grouping varibles disapear and the new table is bidimensional.
Knows anybody how to add row totals to a multidimensional table?

Thanks in advance

Juan Pablo



_________________________________________________________________
?nase al mayor servicio mundial de correo electr?nico: 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tura at centroin.com.br  Sun Oct 13 12:30:34 2002
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Sun, 13 Oct 2002 07:30:34 -0300
Subject: [R] Installing local package under Windows.
In-Reply-To: <200210111800.PAA06576@gelfand.math.unb.ca>
Message-ID: <5.1.0.14.2.20021013072848.00a0c0f0@centroin.com.br>

At 15:00 11/10/2002 -0300, Rolf Turner wrote:

>        
>1. Uploaded the zip file ``ts.sup_0.0-0.tar.gz'' from the
>   Unix box to the Windows system, via ftp (binary mode set).

I nor a R master but  *.tar.gz file is not a zip file.
You need *.zip file for windows...



Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cwills at ucsd.edu  Sun Oct 13 16:18:54 2002
From: cwills at ucsd.edu (Dr. Chris Wills)
Date: Sun, 13 Oct 2002 07:18:54 -0700
Subject: No subject
Message-ID: <p05111a28b9cf31337e96@[137.110.21.179]>

Dear R Gang:
	I have a Macintosh G4 powerbook, running OS 9.2.  Last week I 
ran a statistical analysis program that I wrote in R for two days 
continuously.  The program does repeated intensive computations on a 
large data set.
	The program completed its task successfully, but during the 
process I noted that the computer seemed to be running unusually hot. 
Shortly after the program stopped, something unrepairable happened to 
the computer.  I don't know the cause of the problem yet, and won't 
find out until Monday or Tuesday, but it seems to involve the hard 
drive - Norton Disk Doctor cannot fix it, nor can I restore the 
original software to the hard drive.
	The computer breakdown may of course be unrelated to my use 
of R, but I am concerned that running the computer so intensively may 
have caused the problem.  Has anyboody run into a similar problem 
using R on a G4 machine?  I have also been running R on a G3 I-Book, 
using the same operating system, though not the same program, and I 
have had no problems.
	Thanks!
	Chris Wills
-- 
Christopher Wills
Professor of Biology
Division of Biological Sciences
University of California, San Diego
La Jolla CA 92093

Phone 858-534-4113
Fax 858-534-7108
e-mail cwills at ucsd.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at cbs.dtu.dk  Sun Oct 13 19:33:47 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Sun, 13 Oct 2002 19:33:47 +0200
Subject: [R] R process size growing in time...
Message-ID: <20021013173347.GC3768@giraffa.cbs.dtu.dk>

Dear all,

I observed that the R process is growing in time (I was working with
the same session for two days, and the size reached 300 Mb). Explicit
calls to 'gc()' did show a trigger around 90 Mb but did not change
the RSS (while I remembered that my linux was nicely behaving before
and the process size was shrinking when R was freeing memory...). I
ended up saving the session, ending it then starting it again (and
the process size was around 90 Mb).

I do not know whether this was caused by the recent changes in the
garbage collection, or by possible leaks in the libraries/functions
I have been using (mainly 'hclust' and 'cmdscale').

Did anybody experienced something similar ?



L.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From MASandberg at aol.com  Sun Oct 13 19:49:56 2002
From: MASandberg at aol.com (MASandberg@aol.com)
Date: Sun, 13 Oct 2002 13:49:56 EDT
Subject: [R] R-1.5.1 for MacOS X
Message-ID: <aa.1368db47.2adb0c44@aol.com>

I just downloaded and installed R-1.5.1 for MacOS X on my Macintosh HD by 
"Upgrade", but cannot find the application in my directory (or by searching). 
  All that I can find are the sw:lib files and the several packages in my 
"Receipts" folder.   Can anyone tell me how to access the application?

Thanks,
Mike Sandberg

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sun Oct 13 20:25:59 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 13 Oct 2002 20:25:59 +0200
Subject: [R] Re: [bad designed hardware]
References: <p05111a28b9cf31337e96@[137.110.21.179]>
Message-ID: <3DA9BAB7.97889070@statistik.uni-dortmund.de>

"Dr. Chris Wills" wrote:
> 
> Dear R Gang:

Dear guy,


>         I have a Macintosh G4 powerbook, running OS 9.2.  Last week I
> ran a statistical analysis program that I wrote in R for two days
> continuously.  The program does repeated intensive computations on a
> large data set.
>         The program completed its task successfully, but during the
> process I noted that the computer seemed to be running unusually hot.
> Shortly after the program stopped, something unrepairable happened to
> the computer.  I don't know the cause of the problem yet, and won't
> find out until Monday or Tuesday, but it seems to involve the hard
> drive - Norton Disk Doctor cannot fix it, nor can I restore the
> original software to the hard drive.
>         The computer breakdown may of course be unrelated to my use
> of R, but I am concerned that running the computer so intensively may
> have caused the problem.  Has anyboody run into a similar problem
> using R on a G4 machine?  I have also been running R on a G3 I-Book,
> using the same operating system, though not the same program, and I
> have had no problems.

You ran calculations and so you used your CPU extraordinary, so it's
reasonable that it gets warmer than in other circumstances. If the
cooling system doesn't work sufficiently, that might cause damages. In
that case your hardware was not designed properly (e.g. to cool the 100%
used CPU).

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Kosenkov.Kirill at nac.spb.ru  Sun Oct 13 20:36:40 2002
From: Kosenkov.Kirill at nac.spb.ru (=?koi8-r?B?68/Txc7Lz9cg68nSyczMIO7Jy8/MwcXXyd4=?=)
Date: Sun, 13 Oct 2002 22:36:40 +0400
Subject: [R] HOW to resize existing graphics window??
Message-ID: <001b01c272e7$7c48c1b0$6900a8c0@nac.net>

Sorry for newbie question, but i havent find the way to
resize existing graphics window from r console. Of course,
i can do it by dragging window borders and i can 
set up size of the device (window) if i call
windows(width,height)
but is it really impossible to resize existing window??
how i can do this?
i am using R 1.6.0 on Microsoft Windows 2000 OS
Thanks for your help




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sun Oct 13 22:07:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 13 Oct 2002 22:07:03 +0200
Subject: [R] R process size growing in time...
In-Reply-To: <20021013173347.GC3768@giraffa.cbs.dtu.dk>
References: <20021013173347.GC3768@giraffa.cbs.dtu.dk>
Message-ID: <x21y6uw1aw.fsf@biostat.ku.dk>

Laurent Gautier <laurent at cbs.dtu.dk> writes:

> Dear all,
> 
> I observed that the R process is growing in time (I was working with
> the same session for two days, and the size reached 300 Mb). Explicit
> calls to 'gc()' did show a trigger around 90 Mb but did not change
> the RSS (while I remembered that my linux was nicely behaving before
> and the process size was shrinking when R was freeing memory...). I
> ended up saving the session, ending it then starting it again (and
> the process size was around 90 Mb).
> 
> I do not know whether this was caused by the recent changes in the
> garbage collection, or by possible leaks in the libraries/functions
> I have been using (mainly 'hclust' and 'cmdscale').
> 
> Did anybody experienced something similar ?

Achim found a rather nasty memory leak, traced to the deparsing code.
You might want to try the current r-patched snapshot and see if your
problem goes away.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bojaniss at poczta.onet.pl  Sun Oct 13 23:29:13 2002
From: bojaniss at poczta.onet.pl (Michal Bojanowski)
Date: Sun, 13 Oct 2002 23:29:13 +0200
Subject: [R] R process size growing in time...
In-Reply-To: <20021013173347.GC3768@giraffa.cbs.dtu.dk>
References: <20021013173347.GC3768@giraffa.cbs.dtu.dk>
Message-ID: <4136377968.20021013232913@poczta.onet.pl>

Hello Laurent,

Sunday, October 13, 2002, 7:33:47 PM, you wrote:

LG> Dear all,

LG> I observed that the R process is growing in time (I was working with
LG> the same session for two days, and the size reached 300 Mb). Explicit
LG> calls to 'gc()' did show a trigger around 90 Mb but did not change
LG> the RSS (while I remembered that my linux was nicely behaving before
LG> and the process size was shrinking when R was freeing memory...). I
LG> ended up saving the session, ending it then starting it again (and
LG> the process size was around 90 Mb).

LG> I do not know whether this was caused by the recent changes in the
LG> garbage collection, or by possible leaks in the libraries/functions
LG> I have been using (mainly 'hclust' and 'cmdscale').

LG> Did anybody experienced something similar ?



Hello ---

I think I did notice something similar, while working with R ver. 1060 on Windows
98. I remember, that I was working on some graphs. I didn't perform any `heavy'
calculations, no large datasets. I was producing the graphs many times though
while working on details. I didn't run any applications other than R and a text
editor. After an hour or so of work I wanted to go to Desktop by pressing a
button "show desktop" by the "Start" button. I received something like "There
isn't enough memory to perform this operation". Everything was OK when I
restarted R.

I didn't know about the gc() function, so I don't have any `numbers'.

I thought it occured because of `instability' of Windows, but now, if it happens
on other systems as well Windows might not be the only problem.


mb.


~,~`~,~`~,~`~,~`~,~`~,~`~,~`~,~
Michal Bojanowski
Institute for Social Studies
University of Warsaw
http://www.iss.uw.edu.pl

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From a.witney at sghms.ac.uk  Mon Oct 14 00:23:07 2002
From: a.witney at sghms.ac.uk (Adam Witney)
Date: Sun, 13 Oct 2002 23:23:07 +0100
Subject: [R] R-1.5.1 for MacOS X
In-Reply-To: <aa.1368db47.2adb0c44@aol.com>
Message-ID: <B9CFB0DB.96CD%a.witney@sghms.ac.uk>


I presume you are using fink to do this? There should be an application 'R'
in the /sw/bin directory




> I just downloaded and installed R-1.5.1 for MacOS X on my Macintosh HD by
> "Upgrade", but cannot find the application in my directory (or by searching).
> All that I can find are the sw:lib files and the several packages in my
> "Receipts" folder.   Can anyone tell me how to access the application?
> 
> Thanks,
> Mike Sandberg


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lockwood at rand.org  Mon Oct 14 00:42:13 2002
From: lockwood at rand.org (J.R. Lockwood)
Date: Sun, 13 Oct 2002 18:42:13 -0400 (EDT)
Subject: [R] R process size growing in time...
In-Reply-To: <20021013173347.GC3768@giraffa.cbs.dtu.dk>
Message-ID: <Pine.LNX.4.33.0210131835330.3702-100000@penguin.rand.org>

> 
> Did anybody experienced something similar ?
> 

I have experienced similar problems with R 1.6.0.  I have simulation
code (using nothing but functions in base and in nlme) that had run
without problem throughout the 1.5.x series and as soon as I upgraded,
the code continued to consume physical and virtual memory during
processing until it brought the system to a near deadlock.

J.R. Lockwood
412-683-2300 x4941
lockwood at rand.org
http://www.rand.org/methodology/stat/members/lockwood/


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jbalinc at insight.rr.com  Sun Oct 13 23:47:52 2002
From: jbalinc at insight.rr.com (Jess Balint)
Date: Sun, 13 Oct 2002 22:47:52 +0100
Subject: [R] barplot(): X-Axis Labels
Message-ID: <20021013224752.47a84732.jbalinc@insight.rr.com>

Hello all. I have a simple barplot with sixteen different segments. When I plot my data, only five or six of the labels are showing in the x-axis. How do go get them all to show? Can I set them at a 45.degree angle? Thank you.

Jess
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jyan at stat.wisc.edu  Mon Oct 14 06:14:28 2002
From: jyan at stat.wisc.edu (Jun Yan)
Date: Sun, 13 Oct 2002 23:14:28 -0500 (CDT)
Subject: [R] reshape
In-Reply-To: <3DA8698E.691C1A99@ceam.es>
Message-ID: <Pine.LNX.4.21.0210132311360.5636-100000@istat01.stat.wisc.edu>

juli, assuming your "gen" is the identification variable for clusters, the
following is an illustration.

Jun

> dat <- data.frame(gen=rep(1:5, rep(2,5)), maxh=rnorm(10),
resp=rep(c("y", "n"), 5))
> dat
   gen        maxh resp
1    1 -1.53878091    y
2    1 -0.71171477    n
3    2  0.93065758    y
4    2 -1.65696752    n
5    3 -0.09981616    y
6    3  0.08186816    n
7    4  0.11563345    y
8    4  0.04991344    n
9    5  0.67936629    y
10   5 -1.29308856    n
> dat.w <- reshape(dat, idvar="gen", timevar="resp", v.names="maxh",
direction="wide")
> dat.w
  gen      maxh.n      maxh.y
1   1 -0.71171477 -1.53878091
3   2 -1.65696752  0.93065758
5   3  0.08186816 -0.09981616
7   4  0.04991344  0.11563345
9   5 -1.29308856  0.67936629
>

On Sat, 12 Oct 2002, juli g. pausas wrote:

> I'd like to convert a data.frame from (long format):
> gen   maxh  resp
> 1         12.3   y
> .           .       .
> .           .       .
> where resp is a factor with levels "y" and "n"
> to the wide format:
> 
> gen  maxh.y  maxh.n
> .           .       .
> .           .       .
> 
> I've done it as follows:
> 
> maxh.y <- split(maxh, resp)$y
> gy <- split(gen, resp)$y
> yes <- data.frame(hr, gen=gy)
> 
> maxh.n <- split(maxh, resp)$n
> gn <- split(gen, resp)$n
> no <- data.frame(hn, gen=gn)
> 
> wide <- merge(yes, no, by= "gen") # gen maxh.y maxh.n
> 
> This worked well, but would it be possible to do it with reshape? I've
> tried but I didn't succeed.
> Thanks
> 
> Juli
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From f0z6305 at labs.tamu.edu  Mon Oct 14 06:29:10 2002
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Sun, 13 Oct 2002 23:29:10 -0500
Subject: [R] TEST
Message-ID: <05ab01c2733a$3e19f0a0$8bd75ba5@IE.TAMU.EDU>

Hope this time my help message would be sent out.

Sorry for bothering you.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct 14 10:17:35 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 14 Oct 2002 09:17:35 +0100 (BST)
Subject: [R] HOW to resize existing graphics window??
In-Reply-To: <001b01c272e7$7c48c1b0$6900a8c0@nac.net>
Message-ID: <Pine.LNX.4.31.0210140914490.29348-100000@gannet.stats>

There is no way to resize an existing graphics window from the command
line on any of the R graphics platforms, and no one has ever asked for
this before.  Why do you want to do it?

It would not be very difficult to implement, so if you would like to
contribute the code, please do so.


On Sun, 13 Oct 2002, [koi8-r] .......... wrote:

> Sorry for newbie question, but i havent find the way to
> resize existing graphics window from r console. Of course,
> i can do it by dragging window borders and i can
> set up size of the device (window) if i call
> windows(width,height)
> but is it really impossible to resize existing window??
> how i can do this?
> i am using R 1.6.0 on Microsoft Windows 2000 OS
> Thanks for your help
>
>
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikael.niva at ebc.uu.se  Mon Oct 14 10:34:07 2002
From: mikael.niva at ebc.uu.se (Mikael Niva)
Date: Mon, 14 Oct 2002 10:34:07 +0200
Subject: [R] Post hoc Multiple comparison
Message-ID: <001301c2735c$767ec480$3d9aee82@uu.se>

Dear R-listers

I'm a new R-user who needs some help with a test that I want to do. I
have done a field experiment: four treatments (cont, x, y and xy) at
three sites (A, B and C), the response is count data (0 - 15). I've done
a Poisson regression:


>glm(response~as.factor(treatment)*as.factor(site), family=quasipoisson,
offset(max.response), data=dat)

The "offset" is the maximum response for the sample, different for each
sample (8 - 34). To extract, I've used:


>drop1(dat.glm, .~., test="Chisq")

However, how do I do a post-hoc multiple comparison to see which
treatment(s) and interaction(s) are giving significant effects? I have
found the "multcomp package" with the "csimtest" but it requires the
"parameter estimates", how do I get these for all my "treatments" and
"sites?


Yours sincerely
Micke


************************************************************************
******
Mikael Niva
Dept. of Plant Ecology
EBC, Uppsala universitet


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From egonw at sci.kun.nl  Mon Oct 14 10:50:43 2002
From: egonw at sci.kun.nl (E.L. Willighagen)
Date: Mon, 14 Oct 2002 10:50:43 +0200
Subject: [R] log10(), floor() combo issue?
Message-ID: <200210141050.43412.egonw@sci.kun.nl>


Hi all,

in my search for a nice binary2decimal method, I received this nice
code (thanx to Uwe Ligges):

 bindec <- function(b)
   sum(as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0))

It fails, however, with:

> bindec(1000)
[1] 4
Warning message:
longer object length
        is not a multiple of shorter object length in: 
as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0)

The reason is the combination of floor() and log10():

log10(1000) = 3 

ok, but:

floor(log10(1000)) = 2

? Ok, I can live with some floating point inaccuracy, but this seems
at least a bit strange, and to me troublesome as it makes the bindec()
method fail...

I've also tried to force the output of log10(1000) into integer format
with

floor(as.integer(log10(b)))

However, with the same disappointing results...

Ideas?

kind regards,

Egon
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Kosenkov.Kirill at nac.spb.ru  Mon Oct 14 11:05:03 2002
From: Kosenkov.Kirill at nac.spb.ru (=?koi8-r?B?68/Txc7Lz9cg68nSyczMIO7Jy8/MwcXXyd4=?=)
Date: Mon, 14 Oct 2002 13:05:03 +0400
Subject: [R] HOW to resize existing graphics window??
References: <Pine.LNX.4.31.0210140914490.29348-100000@gannet.stats>
Message-ID: <000d01c27360$cb796360$6900a8c0@nac.net>

<<There is no way to resize an existing graphics window from the command
<<ine on any of the R graphics platforms, and no one has ever asked for
<<this before.
I found in mailing list archives article, that describes how to resize
X11 graphical window on *nix through *nix command-line interface from R.:)
We can not say that "no one" asked for it:)

<<Why do you want to do it?
I want to do it cause i need to preserve size of plot when i copy it to the
other program or when i save it to file. I mean, that, for some reasons, i
dont want to resize plot after i have copied it or after i've save it to
file.
I need to adjust plot size 'on the fly' and _before_ i export it.

When i copy a plot i think it copies in sizes of device size, am i right?
Or which object (or which region) i really copying when i copying the plot?
Is it 'figure region'? Or
it is 'display region' of the device? or 'plot region'? I just have not find
a way, that i can
setup overall size of region, which copies when i trying to copy a plot. And
for this
reason i have thought, that only way to resize region, that actually copies,
is to resize
device.

Now i do resizing in such manner:
i open new device with size, that i need and copying the plot to this device
and closing
'old' device. Or i do it through R recordPlot - replayPlot capabilities.

Thanks for your help and sorry for my english not very well.

P.S. - maybe you know, are there any R-related resources in russian
language?
Or are there any R-contributors in Russia? or any information about R
and  R-community in Russia? I am from Russia and i have not find any person
that using R here yet, and have not found any resources about R in
russian.....


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Oct 14 12:18:43 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 14 Oct 2002 12:18:43 +0200
Subject: [R] Re: log10(), floor() combo issue?
References: <200210141050.43412.egonw@sci.kun.nl>
Message-ID: <3DAA9A03.F4D88D68@statistik.uni-dortmund.de>

"E.L. Willighagen" wrote:
> 
> Hi all,
> 
> in my search for a nice binary2decimal method, I received this nice
> code (thanx to Uwe Ligges):
> 
>  bindec <- function(b)
>    sum(as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0))
> 
> It fails, however, with:
> 
> > bindec(1000)
> [1] 4
> Warning message:
> longer object length
>         is not a multiple of shorter object length in:
> as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0)
> 
> The reason is the combination of floor() and log10():
> 
> log10(1000) = 3
> 
> ok, but:
> 
> floor(log10(1000)) = 2
> 
> ? Ok, I can live with some floating point inaccuracy, but this seems
> at least a bit strange, and to me troublesome as it makes the bindec()
> method fail...
> 
> I've also tried to force the output of log10(1000) into integer format
> with
> 
> floor(as.integer(log10(b)))
> 
> However, with the same disappointing results...


Sorry, I haven't thought about that. Another, numerical more stable
solution is:

  bindec <- function(b){
    temp <- as.integer(unlist(strsplit(b, "")))
    sum(temp * 2^((length(temp) - 1):0))
  }

  bindec(1000)


Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Oct 14 12:31:02 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Oct 2002 12:31:02 +0200
Subject: [R] log10(), floor() combo issue?
In-Reply-To: <200210141050.43412.egonw@sci.kun.nl>
References: <200210141050.43412.egonw@sci.kun.nl>
Message-ID: <x2of9x48ih.fsf@biostat.ku.dk>

"E.L. Willighagen" <egonw at sci.kun.nl> writes:

> The reason is the combination of floor() and log10():
> 
> log10(1000) = 3 
> 
> ok, but:
> 
> floor(log10(1000)) = 2
> 
> ? Ok, I can live with some floating point inaccuracy, but this seems
> at least a bit strange, and to me troublesome as it makes the bindec()
> method fail...

Well, the reason is of course that

> print(log10(1000),18)
[1] 2.99999999999999956

Having log10 exact for integer powers of 10 is apparently too much to
ask from a binary computer, although it might in principle be possible
(but I believe log10(x) is computed as log(x)/log(10)). For negative
powers it really is impossible.
 
> I've also tried to force the output of log10(1000) into integer format
> with
> 
> floor(as.integer(log10(b)))
> 
> However, with the same disappointing results...

(as.integer() truncates, so floor() is superfluous)

The only way out is to add "fuzz" as in

floor(log10(b)+1e-10)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From newsday at email.it  Mon Oct 14 12:50:13 2002
From: newsday at email.it (News Day)
Date: Mon, 14 Oct 2002 12:50:13 0200
Subject: [R] Condividi i tuoi files con Grokster
Message-ID: <1034592613.430@inwind.it>

Vuoi scaricare da Internet ogni tipo di files: programmi, giochi, MP3, 
filmati, foto e tanto altro?

Visita il sito http://anzwers.org/free/grokster/ e scarica il software per 
condividere i tuoi files
con tutto il mondo!


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From amurta at ipimar.pt  Mon Oct 14 13:15:16 2002
From: amurta at ipimar.pt (Alberto Murta)
Date: Mon, 14 Oct 2002 11:15:16 +0000
Subject: [R] Re: [bad designed hardware]
References: <p05111a28b9cf31337e96@[137.110.21.179]> <3DA9BAB7.97889070@statistik.uni-dortmund.de>
Message-ID: <3DAAA744.33859BC2@ipimar.pt>

I've a colleague that has a Mac G4, and after a day of normal work (such
as wordprocessing) he can do fried eggs on its back side. I think this
ability to do fried eggs has nothing to do with R.

Alberto

Uwe Ligges wrote:
> 
> "Dr. Chris Wills" wrote:
> >
> > Dear R Gang:
> 
> Dear guy,
> 
> >         I have a Macintosh G4 powerbook, running OS 9.2.  Last week I
> > ran a statistical analysis program that I wrote in R for two days
> > continuously.  The program does repeated intensive computations on a
> > large data set.
> >         The program completed its task successfully, but during the
> > process I noted that the computer seemed to be running unusually hot.
> > Shortly after the program stopped, something unrepairable happened to
> > the computer.  I don't know the cause of the problem yet, and won't
> > find out until Monday or Tuesday, but it seems to involve the hard
> > drive - Norton Disk Doctor cannot fix it, nor can I restore the
> > original software to the hard drive.
> >         The computer breakdown may of course be unrelated to my use
> > of R, but I am concerned that running the computer so intensively may
> > have caused the problem.  Has anyboody run into a similar problem
> > using R on a G4 machine?  I have also been running R on a G3 I-Book,
> > using the same operating system, though not the same program, and I
> > have had no problems.
> 
> You ran calculations and so you used your CPU extraordinary, so it's
> reasonable that it gets warmer than in other circumstances. If the
> cooling system doesn't work sufficiently, that might cause damages. In
> that case your hardware was not designed properly (e.g. to cool the 100%
> used CPU).
> 
> Uwe Ligges
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
                           Alberto G. Murta                      
          IPIMAR -  Institute for Fisheries and Sea Research
            Avenida de Brasilia, 1449-006 Lisboa, Portugal       
Tel:+351 213027062; Fax:+351 213015849; http://www.ipimar.pt/pelagicos/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jan_Svatos at eurotel.cz  Mon Oct 14 13:28:08 2002
From: Jan_Svatos at eurotel.cz (Jan_Svatos@eurotel.cz)
Date: Mon, 14 Oct 2002 13:28:08 +0200
Subject: [R] automatic chi-square grouping in R
Message-ID: <OF15703C49.C1D510ED-ONC1256C52.003D7641@eurotel.cz>


Hi,
there are possibilities to group, regroup, and transform data in R easily.
For example,

adl2<-adl
adl2[adl2==5 | adl2==6]<-7 #or whatever you want
then
survdiff(formula = Surv(days, status) ~ adl2, data = nu)

To make this automagically, I would use something along these simple lines:

t1<-table(adl)
#then order it (descending)
t2<-t1[rev(order(t1))]
t3<-t2[t2>=5] #or another threshold
remainder<-sum(t2[t2<5])
names(remainder)<-"Blahblah"
mynewadlgrouping<-rbind(t3,remainder) # I think it is correct, if not, then
use cbind() or even simpler c()

and use as.factor(mynewadlgrouping) instead of adl.

But joining groups in order to build bigger groups is sometimes
statistically doubtful.
The same for age :

age[age>30 & age<=35]<-32.5
age[age>35 & age<=40]<-37.5
etc.

Or there is a possibility to build factor, for example

age2<-as.factor(floor(age/5))

JS


- - - Original message: - - -
From: owner-r-help at stat.math.ethz.ch
Send: 11.10.2002 12:03:08
To: <r-help at stat.math.ethz.ch>
Subject: [R] automatic chi-square grouping in R

I'm doing some chi-square tests, and I recall some arbitrary rule that says

each band must have at least 5 events in order for the test to be
meaningful.
Is there some way to do the banding automagically in R ? For instance, in
the
following survdiff, I'm trying to see if ADL affects survival. But when
ADL=3,5
and 6, the number observed is too little. Anyway for me to tell R how to
group
them ? Like "R, combine ADL=5 and ADL=6, and redo the test" ?

-----------

Call:
survdiff(formula = Surv(days, status) ~ adl, data = nu)

       N Observed Expected (O-E)^2/E (O-E)^2/V
adl=0 92        6     8.74   0.86134   1.17556
adl=1 38        5     3.41   0.74346   0.83435
adl=2 60        9    10.56   0.22975   0.39159
adl=3 44        4     5.22   0.28487   0.33978
adl=4 27        6     2.32   5.83153   6.30818
adl=5 31        3     3.12   0.00456   0.00506
adl=6 16        2     1.63   0.08385   0.08835

 Chisq= 8.2  on 6 degrees of freedom, p= 0.226

-------

On a related note, is it possible to tell R to group together values, for
instance, if I have age in my data ranging from 30-60, is it possible to
tell R
to convert all ages 30-35 into 32.5, all age from 36-40 into 37.5 ... etc ?
I
mean I can always do this in Excel before I feed the data into R, but it
seems
R must be able to do something like this. I just don't know where to begin
looking in the manual for something like this ...

Thanks so much guys,

Roger


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plxmh at nottingham.ac.uk  Mon Oct 14 13:45:32 2002
From: plxmh at nottingham.ac.uk (Martin Hoyle)
Date: Mon, 14 Oct 2002 12:45:32 +0100
Subject: [R] Learning R: which book to choose?
Message-ID: <sdaabc75.051@ccw0m.nottingham.ac.uk>

I have found "Statistical Computing. An Introduction to Data Analysis
using S-Plus" by Crawley vey helpful as an intermediate text. The book
is very clear, however, there's very little programming.
It's available from Amazon.com.

Regards,
Martin.

Martin Hoyle,
School of Life and Environmental Sciences,
University of Nottingham,
University Park,
Nottingham,
NG7 2RD,
UK
Webpage: http://myprofile.cos.com/martinhoyle

>>> Jan Krupa <krupa at alpha.sggw.waw.pl> 10/12/02 06:44PM >>>

I am new to R. I am going to by one of the following book:

1.
William N. Venables and Brian D. Ripley. Modern Applied Statistics 
with S-Plus.
Third Edition. Springer, 1999. ISBN 0-387-98825-4.

2.
 The  Fourth Edition of the book from point 1.

3.
`S Programming'
 by W. N. Venables and B. D. Ripley
 Springer. ISBN 0-387-98966-8, 2000.


I can only by one of the above books.

Q1.
I have found the following info at the site
http://www.stats.ox.ac.uk/pub/MASS4/ :

''The material on programming has been reduced since the first and 
second editions''

Is that also true that 
The material on programming has been reduced since the THIRD  edition?

Q2. Which of the books 1 or 2 do you suggest to buy?
I mean which one is more complete?
May be the third (3) book would be enough to learn R?

TIA

Jan

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html 
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To:
r-help-request at stat.math.ethz.ch 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plxmh at nottingham.ac.uk  Mon Oct 14 13:52:14 2002
From: plxmh at nottingham.ac.uk (Martin Hoyle)
Date: Mon, 14 Oct 2002 12:52:14 +0100
Subject: [R] barplot(): X-Axis Labels
Message-ID: <sdaabe03.045@ccw0m.nottingham.ac.uk>

Try using las=2 in the barplot command;

barplot(response variable means,names=levels(explanatory
variable),las=2)

The text is then at 90 degrees,

Martin.

Martin Hoyle,
School of Life and Environmental Sciences,
University of Nottingham,
University Park,
Nottingham,
NG7 2RD,
UK
Webpage: http://myprofile.cos.com/martinhoyle

>>> Jess Balint <jbalinc at insight.rr.com> 10/13/02 10:47PM >>>
Hello all. I have a simple barplot with sixteen different segments.
When I plot my data, only five or six of the labels are showing in the
x-axis. How do go get them all to show? Can I set them at a 45.degree
angle? Thank you.

Jess
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html 
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To:
r-help-request at stat.math.ethz.ch 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct 14 12:34:40 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 14 Oct 2002 11:34:40 +0100 (BST)
Subject: [R] HOW to resize existing graphics window??
In-Reply-To: <000d01c27360$cb796360$6900a8c0@nac.net>
Message-ID: <Pine.LNX.4.31.0210141129290.29656-100000@gannet.stats>

You can do what you want by re-drawing the plot at the size you want on a
new device.  Copying plots is approximate at best, and I would not
recommend it for precise work.  Just rerun the R commands to generate the
plot.

On Mon, 14 Oct 2002, [koi8-r] ........ wrote:

> <<There is no way to resize an existing graphics window from the command
> <<ine on any of the R graphics platforms, and no one has ever asked for
> <<this before.
> I found in mailing list archives article, that describes how to resize
> X11 graphical window on *nix through *nix command-line interface from R.:)
> We can not say that "no one" asked for it:)

> <<Why do you want to do it?
> I want to do it cause i need to preserve size of plot when i copy it to the
> other program or when i save it to file. I mean, that, for some reasons, i
> dont want to resize plot after i have copied it or after i've save it to
> file.
> I need to adjust plot size 'on the fly' and _before_ i export it.
>
> When i copy a plot i think it copies in sizes of device size, am i right?
> Or which object (or which region) i really copying when i copying the plot?
> Is it 'figure region'? Or
> it is 'display region' of the device? or 'plot region'? I just have not find
> a way, that i can
> setup overall size of region, which copies when i trying to copy a plot. And
> for this
> reason i have thought, that only way to resize region, that actually copies,
> is to resize
> device.

Copying a plot replays the display list on a new device.  So it is the
device region.

> Now i do resizing in such manner:
> i open new device with size, that i need and copying the plot to this device
> and closing
> 'old' device. Or i do it through R recordPlot - replayPlot capabilities.
>
> Thanks for your help and sorry for my english not very well.

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From juli at ceam.es  Mon Oct 14 14:20:45 2002
From: juli at ceam.es (juli g. pausas)
Date: Mon, 14 Oct 2002 14:20:45 +0200
Subject: [R] barplot + plot
Message-ID: <3DAAB69D.2BFDA7A0@ceam.es>

Dear all,
I've got another question,
By default barplot and plot seem to produce slightly different y-axis.
The problem I've got is when using a mix figure with both, barplot and
plot. For example:

barplot(1:5, ylim=c(0, 6))
par(new= T)
plot(1:5, 9:5, type="b", axes=FALSE, ylim=c(0,9))
axis(4)
box()

note that both plots (barplot and plot) should start at 0, but the exact
starting at 0 is only produced with barplot but not with plot.
Is there a way to make the two axes more coherent, that is both starting
at the exact 0 or both starting like the plot?

Thanks a lot for any suggestion

Juli

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct 14 14:32:05 2002
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Oct 2002 13:32:05 +0100 (BST)
Subject: [R] log10(), floor() combo issue?
In-Reply-To: <200210141050.43412.egonw@sci.kun.nl>
Message-ID: <Pine.GSO.4.31.0210141328280.9801-100000@toucan.stats>

You will find that a `fuzz', typically 1.0e-7, is added to quantities
before floor() or as.integer() all over R.  seq.default() is one example.

For log10(1000) we use log(1000)/log(10), and that is not a ratio of
integers.

On Mon, 14 Oct 2002, E.L. Willighagen wrote:

>
> Hi all,
>
> in my search for a nice binary2decimal method, I received this nice
> code (thanx to Uwe Ligges):
>
>  bindec <- function(b)
>    sum(as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0))
>
> It fails, however, with:
>
> > bindec(1000)
> [1] 4
> Warning message:
> longer object length
>         is not a multiple of shorter object length in:
> as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0)
>
> The reason is the combination of floor() and log10():
>
> log10(1000) = 3
>
> ok, but:
>
> floor(log10(1000)) = 2
>
> ? Ok, I can live with some floating point inaccuracy, but this seems
> at least a bit strange, and to me troublesome as it makes the bindec()
> method fail...
>
> I've also tried to force the output of log10(1000) into integer format
> with
>
> floor(as.integer(log10(b)))
>
> However, with the same disappointing results...
>
> Ideas?
>
> kind regards,
>
> Egon
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Torsten.Hothorn at rzmail.uni-erlangen.de  Mon Oct 14 14:06:10 2002
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon, 14 Oct 2002 14:06:10 +0200 (MEST)
Subject: [R] Post hoc Multiple comparison
In-Reply-To: <001301c2735c$767ec480$3d9aee82@uu.se>
Message-ID: <Pine.LNX.4.21.0210141400120.15474-100000@artemis>


> Dear R-listers
> 
> I'm a new R-user who needs some help with a test that I want to do. I
> have done a field experiment: four treatments (cont, x, y and xy) at
> three sites (A, B and C), the response is count data (0 - 15). I've done
> a Poisson regression:
> 
> 
> >glm(response~as.factor(treatment)*as.factor(site), family=quasipoisson,
> offset(max.response), data=dat)
> 
> The "offset" is the maximum response for the sample, different for each
> sample (8 - 34). To extract, I've used:
> 
> 
> >drop1(dat.glm, .~., test="Chisq")
> 
> However, how do I do a post-hoc multiple comparison to see which
> treatment(s) and interaction(s) are giving significant effects? I have
> found the "multcomp package" with the "csimtest" but it requires the
> "parameter estimates", how do I get these for all my "treatments" and
> "sites?
> 

you can extract the parameter estimates from the model using `coef' and
their covariance matrix by `vcov'. Maybe you need to pass the constrasts
of interest to glm, for example using:

R> contrasts(treatment) <- C

where C is the MP-inverse of your contrast matrix (see MASS3, 1999, page
200 for more details). That gives you all you need for calling
csim{int,test}.

Torsten

> 
> Yours sincerely
> Micke
> 
> 
> ************************************************************************
> ******
> Mikael Niva
> Dept. of Plant Ecology
> EBC, Uppsala universitet
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From malmo at unitra.sk  Mon Oct 14 14:48:52 2002
From: malmo at unitra.sk (Peter Adamka)
Date: 14 Oct 2002 14:48:52 +0200
Subject: [R] Thanks
Message-ID: <1034599732.18252.1.camel@whiper>

Thanks a lot for all Your replies. It's working now.
		Malmo



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct 14 14:49:45 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 14 Oct 2002 13:49:45 +0100 (BST)
Subject: [R] ActiveTcl Version
In-Reply-To: <3D873E94.90103@esb.ucp.pt>
Message-ID: <Pine.LNX.4.31.0210141347330.1247-100000@gannet.stats>

You mean under Windows, I presume?

For the record (I've been away but could see no reply), the binary
versions *need* Tcl 8.3.x, as all the docs say.

It is possible to build the sources against 8.4, but that crashes for me.


On Tue, 17 Sep 2002, Peter Ho wrote:

> Dear Tcl/Tk users,
>
> Will R work with the more recent version of  ActiveTcl 8.4.0.1 or should
> I use ActiveTcl 8.3.4.3?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Detlef.Steuer at unibw-hamburg.de  Mon Oct 14 14:51:39 2002
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Mon, 14 Oct 2002 14:51:39 +0200 (CEST)
Subject: [R] log10(), floor() combo issue?
In-Reply-To: <200210141050.43412.egonw@sci.kun.nl>
Message-ID: <XFMail.20021014145139.steuer@unibw-hamburg.de>


On 14-Oct-2002 E.L. Willighagen wrote:
> 
> Hi all,
> 
> in my search for a nice binary2decimal method, I received this nice
> code (thanx to Uwe Ligges):
> 
>  bindec <- function(b)
>    sum(as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0))


Nice function!

> 
> It fails, however, with:
> 
>> bindec(1000)
> [1] 4
> Warning message:
> longer object length
>         is not a multiple of shorter object length in: 
> as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0)
> 
> The reason is the combination of floor() and log10():
> 
> log10(1000) = 3 
> 
> ok, but:
> 
> floor(log10(1000)) = 2

Just throw in a round of rounding (say to 10 digits):

floor(round(log10(b),10)).

This repairs the numerical inaccuracies of taking logarithms,
if those are not too large :-).

> floor(round(log10(1000),10))
[1] 3

detlef


> 
> ? Ok, I can live with some floating point inaccuracy, but this seems
> at least a bit strange, and to me troublesome as it makes the bindec()
> method fail...
> 
> I've also tried to force the output of log10(1000) into integer format
> with
> 
> floor(as.integer(log10(b)))
> 
> However, with the same disappointing results...
> 
> Ideas?
> 
> kind regards,
> 
> Egon
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _

"There is no way to peace, peace is the way." -- Ghandi

Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From use at eio.uva.es  Mon Oct 14 15:35:07 2002
From: use at eio.uva.es (=?Windows-1252?Q?Eusebio_Arenal_Guti=E9rrez?=)
Date: Mon, 14 Oct 2002 15:35:07 +0200
Subject: [R] Functions for Descriptive Statistics and Inference
Message-ID: <002801c27386$83acff80$6958589d@juanito>

I'm using R to teach basic satistics and I want to know if there ara
fuctions in any CRAN library to perform:

1) skewness and kurtosis of one sample.

2) Kolmogorov or chi-squared lack of fit test for a distribution family,
i.e. Lilliefors test.

Thanks in advanced,

Eusebio

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From phgrosje at ulb.ac.be  Mon Oct 14 15:33:11 2002
From: phgrosje at ulb.ac.be (Philippe Grosjean)
Date: Mon, 14 Oct 2002 15:33:11 +0200
Subject: [R] HOW to resize existing graphics window??
In-Reply-To: <Pine.LNX.4.31.0210140914490.29348-100000@gannet.stats>
Message-ID: <MABBLJDICACNFOLGIHJOCENMCPAA.phgrosje@ulb.ac.be>

If you need to redimension the graph window before drawing a new graph with
different requirements of the previous one, the quick and easy answer is to
close the previous graph window and to create a new one with the desired
dimensions. For instance:

windows(width=6, height=4)
graph1 <- dev.cur()
plot(rnorm(50, rnorm(50))

# If you want to change the size of graph1 before drawing a new plot:
dev.off(graph1)
graph1 <- windows(width=5, height=5)
hist(rnorm(200))

Best,

Philippe Grosjean

>On Sun, 13 Oct 2002, [koi8-r] .......... wrote:

>> Sorry for newbie question, but i havent find the way to
>> resize existing graphics window from r console. Of course,
>> i can do it by dragging window borders and i can
>> set up size of the device (window) if i call
>> windows(width,height)
>> but is it really impossible to resize existing window??
>> how i can do this?
>> i am using R 1.6.0 on Microsoft Windows 2000 OS
>> Thanks for your help

Prof. B. Ripley replied:
>There is no way to resize an existing graphics window from the command
>line on any of the R graphics platforms, and no one has ever asked for
>this before.  Why do you want to do it?

>It would not be very difficult to implement, so if you would like to
>contribute the code, please do so.





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From knordstr at sun3.oulu.fi  Mon Oct 14 16:00:40 2002
From: knordstr at sun3.oulu.fi (Kenneth Nordstrom)
Date: Mon, 14 Oct 2002 17:00:40 +0300 (EEST)
Subject: [R] re: OSF/Tru64 binaries?
Message-ID: <200210141400.RAA14276@cc.oulu.fi>

Hello,

is someone still building binaries of R for Alpha Unix?
There is an empty link under precomplied binaries.
If not, can one still find binaries of older versions 
(< 1.6.0) somewhere?
(Having problems compiling 1.6.0 on this platform...)

Thanks,
Kenneth Nordstr?m


..................................................................

Kenneth Nordstr?m                  tel: +358-8-553 1829
Professor of Statistics                 +358-8-553 1820
Dept of Math Sciences/Statistics   
Univ of Oulu                       fax: +358-8-553 1848
P.O. Box 3000
FIN-90401 Oulu                     kenneth.nordstrom at oulu.fi
FINLAND                            http://stat.oulu.fi/nordstrom

..................................................................
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Oct 14 16:09:59 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 14 Oct 2002 07:09:59 -0700 (PDT)
Subject: [R] Re: your mail
In-Reply-To: <p05111a28b9cf31337e96@[137.110.21.179]>
Message-ID: <Pine.A41.4.44.0210140708030.71008-100000@homer07.u.washington.edu>

On Sun, 13 Oct 2002, Dr. Chris Wills wrote:

> of R, but I am concerned that running the computer so intensively may
> have caused the problem.  Has anyboody run into a similar problem
> using R on a G4 machine?  I have also been running R on a G3 I-Book,
> using the same operating system, though not the same program, and I
> have had no problems.

I have noticed that my iBook gets rather hot when used extensively, but I
don't think it should be enough to cause hardware breakdowns -- it would
seem more likely that the CPU itself would be affected by high
temperatures.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Mon Oct 14 16:11:27 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 14 Oct 2002 09:11:27 -0500
Subject: [R] barplot + plot
In-Reply-To: <3DAAB69D.2BFDA7A0@ceam.es>
Message-ID: <001001c2738b$96e84cd0$0201a8c0@MARC>

> -----Original Message-----
> Dear all,
> I've got another question,
> By default barplot and plot seem to produce slightly different y-axis.
> The problem I've got is when using a mix figure with both, barplot and
> plot. For example:
> 
> barplot(1:5, ylim=c(0, 6))
> par(new= T)
> plot(1:5, 9:5, type="b", axes=FALSE, ylim=c(0,9))
> axis(4)
> box()
> 
> note that both plots (barplot and plot) should start at 0, but the
exact
> starting at 0 is only produced with barplot but not with plot.
> Is there a way to make the two axes more coherent, that is both
starting
> at the exact 0 or both starting like the plot?
> 
> Thanks a lot for any suggestion
> 
> Juli

Juli,

The difference is in the way that barplot() and plot() draw the style of
axes by default.

In barplot(), which you call first, it sets par(yaxs = "i") explicitly
in the code.

Unless you change it, plot() uses the default parameter value of
par(yaxs = "r"), which draws a different style of axis.

If you add:

par(yaxs = "i") before your plot(...) line, you will get a consistent 0
starting point.

See ?par and scroll to par(xaxs), which describes the style of axes
available for both x and y.

Thus, your example code should look like:

barplot(1:5, ylim=c(0, 9))
par(new= T)
par(yaxs = "i")
plot(1:5, 9:5, type="b", axes=FALSE, ylim=c(0,6))
axis(4)
box()

I presume that you explicitly want the y axis ranges to be different.
If not, be sure to set ylim to the same values.

HTH.

Marc Schwartz



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Mon Oct 14 16:29:32 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 14 Oct 2002 09:29:32 -0500
Subject: [R] barplot + plot
Message-ID: <001701c2738e$1e029070$0201a8c0@MARC>

> -----Original Message-----
>
> SNIP
>
> Thus, your example code should look like:
> 
> barplot(1:5, ylim=c(0, 9))
> par(new= T)
> par(yaxs = "i")
> plot(1:5, 9:5, type="b", axes=FALSE, ylim=c(0,6))
> axis(4)
> box()
> 

A quick clarification.  I just noted that I reversed the ylim settings
from Juli's original example code.

Of course the example code should be:

barplot(1:5, ylim=c(0, 6))
par(new= T)
par(yaxs = "i")
plot(1:5, 9:5, type="b", axes=FALSE, ylim=c(0,9))
axis(4)
box()

Marc Schwartz
<In need of more coffee this morning>



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Mon Oct 14 16:33:32 2002
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 14 Oct 2002 07:33:32 -0700
Subject: [R] R 1.6.0 Solaris crash with xmalloc: out of virtual memory
Message-ID: <p05111a01b9d0848e6831@[128.115.153.6]>

	[some de-capitalization of *SXP done manually by mailing 
	 list maintainer ; the originally was caught as potential spam.  MM]

I have a little R program that crashes with the message
   xmalloc: out of virtual memory

The code has a repeat{} loop that watches the sizes of some files. 
When there's an increase it updates things by reading the last 65 
lines of each file, doing some calculations, and re-making a plot. 
After about 260 updates it crashes with the message
   xmalloc: out of virtual memory
and returns to the OS.

I inserted calls to gc() and memory.profile().

The value of CHARSXP from memory.profile() increases linearly at a 
rate of about 332.6 units per update, from 37178 just after R is 
started to 123319 shortly before it crashes. None of the others 
change much.

 From Rinternals.h,
   #define CHARSXP  9   /* "scalar" string type (internal only)*/
and it seems like this should give me a clue where to look in my code 
for something that keeps grabbing more memory, but I'm not getting it.

The values returned by gc() change (see below), but I don't know if 
the amount of change is significant.

Any suggestions would be most welcome.

Thanks
-Don

>  version
          _
platform sparc-sun-solaris2.7
arch     sparc
os       solaris2.7
system   sparc, solaris2.7
status
major    1
minor    6.0
year     2002
month    10
day      01
language R


----------------- At the beginning -------------
--- gc() returns:
          used (Mb) gc trigger (Mb)
Ncells 254150  6.8     467875 12.5
Vcells 408499  3.2     886807  6.8

--- memory.profile() returns:
NilSXP SymSXP ListSXP CloSXP EnvSXP PromSXP LangSXP SpecialSXP
      1   4919  128880   1440     13      18   63607         59

BUILTINSXP CHARSXP LGLSXP - - INTSXP REALSXP CPLXSXP STRSXP
        513   37178   1712 0 0    237    9047       8  10201

  DOTSXP ANYSXP VECSXP EXPRSXP - EXTPTRSXP WEAKREFSXP
  1           0    341       2 0         0          0

---------------- Just before the crash ------------
--- gc() returns:
          used (Mb) gc trigger (Mb)
Ncells 347539  9.3     597831 16.0
Vcells 566319  4.4    1103261  8.5

--- memory.profile() returns:
NilSXP SymSXP ListSXP CloSXP EnvSXP PromSXP LangSXP SpecialSXP
      1   4921  131330   1440     13      18   63607         59

BUILTINSXP CHARSXP LGLSXP - - INTSXP REALSXP CPLXSXP STRSXP
        513  123319   1726 0 0    275    9308       8  10613

DOTSXP ANYSXP VECSXP EXPRSXP - EXTPTRSXP WEAKREFSXP
      1      0    427       2 0         0          0

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Mon Oct 14 16:57:35 2002
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 14 Oct 2002 07:57:35 -0700
Subject: [R] Re:
In-Reply-To: <p05111a28b9cf31337e96@[137.110.21.179]>
References: <p05111a28b9cf31337e96@[137.110.21.179]>
Message-ID: <p05111a02b9d08b6d045b@[128.115.153.6]>

You could go to the Apple sci-tech mailing list and ask this question 
of people who often do intensive computations on Apple hardware. They 
might be able to give a realistic sense of how plausible this concern 
is.

-Don

At 7:18 AM -0700 10/13/02, Dr. Chris Wills wrote:
>Dear R Gang:
>	I have a Macintosh G4 powerbook, running OS 9.2.  Last week I 
>ran a statistical analysis program that I wrote in R for two days 
>continuously.  The program does repeated intensive computations on a 
>large data set.
>	The program completed its task successfully, but during the 
>process I noted that the computer seemed to be running unusually 
>hot. Shortly after the program stopped, something unrepairable 
>happened to the computer.  I don't know the cause of the problem 
>yet, and won't find out until Monday or Tuesday, but it seems to 
>involve the hard drive - Norton Disk Doctor cannot fix it, nor can I 
>restore the original software to the hard drive.
>	The computer breakdown may of course be unrelated to my use 
>of R, but I am concerned that running the computer so intensively 
>may have caused the problem.  Has anyboody run into a similar 
>problem using R on a G4 machine?  I have also been running R on a G3 
>I-Book, using the same operating system, though not the same 
>program, and I have had no problems.
>	Thanks!
>	Chris Wills
>--
>Christopher Wills
>Professor of Biology
>Division of Biological Sciences
>University of California, San Diego
>La Jolla CA 92093
>
>Phone 858-534-4113
>Fax 858-534-7108
>e-mail cwills at ucsd.edu
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From H.Putter at lumc.nl  Mon Oct 14 17:03:40 2002
From: H.Putter at lumc.nl (Putter, H. (MStat))
Date: Mon, 14 Oct 2002 17:03:40 +0200
Subject: [R] Question: concatenating lists
Message-ID: <27E647E5629ED211BF78009027289C6303863B54@mail1>

Dear R users,

I have the following problem. I have a number of lists with identical
structure. Each component is a vector, matrix or array, but components of
different lists may be of different size. How do I combine the lists to get
a new list such that each component of this list contains the components of
the individual lists?

An example may explain most clearly what I need.

Suppose I have three lists:
list1 <- list(a=1:2,b=matrix(1,2,2))
list2 <- list(a=3:5,b=matrix(-1,3,3))
list3 <- list(a=6:9,b=matrix(5,4,4))

The result should give me something like:

$a:
     [,1] [,2] [,3] 
[1,]    1    3    6
[2,]    2    4    7
[3,]   NA    5    8
[4,]   NA   NA    9


$b:
, , 1
     [,1] [,2] [,3] [,4] 
[1,]    1    1   NA   NA
[2,]    1    1   NA   NA
[3,]   NA   NA   NA   NA
[4,]   NA   NA   NA   NA

, , 2
     [,1] [,2] [,3] [,4] 
[1,]   -1   -1   -1   NA
[2,]   -1   -1   -1   NA
[3,]   -1   -1   -1   NA
[4,]   NA   NA   NA   NA

, , 3
     [,1] [,2] [,3] [,4] 
[1,]    5    5    5    5
[2,]    5    5    5    5
[3,]    5    5    5    5
[4,]    5    5    5    5

Any ideas would be much appreciated.
Best regards,
	Hein


Hein Putter
Department of Medical Statistics
Leiden University Medical Center
P.O.Box 9604,  
2300 RC Leiden, The Netherlands
phone  +31-71-5276827
fax    +31-71-5276799
e-mail h.putter at lumc.nl
http://www.medstat.medfac.leidenuniv.nl/MS/Hp



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From azboater at dakotacom.net  Mon Oct 14 17:34:14 2002
From: azboater at dakotacom.net (Scott Marley)
Date: Mon, 14 Oct 2002 08:34:14 -0700
Subject: [R] New to R and need help
Message-ID: <000d01c27397$2a1f8580$bfaf8796@marleyux8q0l48>

All,

I just took a cool R workshop and I'm chomping at the bit to play around
with it.  I'm fairly familiar with SAS and have some data that I used  with
Sas.  My question is:  How do I take a text file(I think my instructor
called it a rectangular file) and import it to R.  In sas you use an input
statement followed by Variable name and the column numbers for the location
of the data.  Does R have a similar procedure?  What would the syntax look
like?  Thank you for any help you can offer.



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Mon Oct 14 17:39:51 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 14 Oct 2002 17:39:51 +0200
Subject: [R] New to R and need help
In-Reply-To: <000d01c27397$2a1f8580$bfaf8796@marleyux8q0l48>
References: <000d01c27397$2a1f8580$bfaf8796@marleyux8q0l48>
Message-ID: <15786.58695.825623.866965@gargle.gargle.HOWL>

>>>>> "Scott" == Scott Marley <azboater at dakotacom.net>
>>>>>     on Mon, 14 Oct 2002 08:34:14 -0700 writes:

    Scott> All,

    Scott> I just took a cool R workshop and I'm chomping at the
    Scott> bit to play around with it.  I'm fairly familiar with
    Scott> SAS and have some data that I used with Sas.  My
    Scott> question is: How do I take a text file(I think my
    Scott> instructor called it a rectangular file) and import
    Scott> it to R.  In sas you use an input statement followed
    Scott> by Variable name and the column numbers for the
    Scott> location of the data.  Does R have a similar
    Scott> procedure?  What would the syntax look like?  Thank
    Scott> you for any help you can offer.

help(read.table)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Oct 14 18:18:09 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Oct 2002 18:18:09 +0200
Subject: [R] New to R and need help
In-Reply-To: <15786.58695.825623.866965@gargle.gargle.HOWL>
References: <000d01c27397$2a1f8580$bfaf8796@marleyux8q0l48>
	<15786.58695.825623.866965@gargle.gargle.HOWL>
Message-ID: <x23cr90zb2.fsf@biostat.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> >>>>> "Scott" == Scott Marley <azboater at dakotacom.net>
> >>>>>     on Mon, 14 Oct 2002 08:34:14 -0700 writes:
> 
>     Scott> All,
> 
>     Scott> I just took a cool R workshop and I'm chomping at the
>     Scott> bit to play around with it.  I'm fairly familiar with
>     Scott> SAS and have some data that I used with Sas.  My
>     Scott> question is: How do I take a text file(I think my
>     Scott> instructor called it a rectangular file) and import
>     Scott> it to R.  In sas you use an input statement followed
>     Scott> by Variable name and the column numbers for the
>     Scott> location of the data.  Does R have a similar
>     Scott> procedure?  What would the syntax look like?  Thank
>     Scott> you for any help you can offer.
> 
> help(read.table)

(Why don't we have examples in there??) 

Specifically, you do something like

x <- read.table("myfile.txt")
names(x) <- c("age", "height", "weight")

or, preferably, add a 1st row containing the variable names to the
data file and do

x <- read.table("myfile.txt", header=TRUE)

There's a number of fine points concerning missing value specification
and variable types, for which the help page should be consulted.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rg117 at ohm.york.ac.uk  Mon Oct 14 18:19:14 2002
From: rg117 at ohm.york.ac.uk (Rishabh Gupta)
Date: Mon, 14 Oct 2002 17:19:14 +0100
Subject: [R] normalizing data sets
Message-ID: <001301c2739d$702c3400$35892090@ohm.york.ac.uk>

Hi,
 Can someone tell me how to normalize a data set so that the mean of the set is 0 and the variance is 1. As I understand, when you
calculate the principle components of a data set through correlation as
< princomp( dataset,  cor=T ) >
then a similar calculation is performed. I would like to know how I can perform such a calulation directly. Any help would be
greatly appreciated.

Many Thanks

Rishabh

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Mon Oct 14 18:51:30 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 14 Oct 2002 11:51:30 -0500
Subject: [R] barplot(): X-Axis Labels
In-Reply-To: <sdaabe03.045@ccw0m.nottingham.ac.uk>
Message-ID: <001d01c273a1$f297f8d0$0201a8c0@MARC>

> -----Original Message-----
> Martin Hoyle wrote:
>
> Try using las=2 in the barplot command;
> 
> barplot(response variable means,names=levels(explanatory
> variable),las=2)
> 
> The text is then at 90 degrees,
>
> >>> Jess Balint <jbalinc at insight.rr.com> 10/13/02 10:47PM >>>
>
> Hello all. I have a simple barplot with sixteen different segments.
> When I plot my data, only five or six of the labels are showing in the
> x-axis. How do go get them all to show? Can I set them at a 45.degree
> angle? Thank you.
> 
> Jess

In addition to Martin's suggestion, you might wish to use meaningful
abbreviations to shorten the labels.

You can also use par("cex.axis") to make the font a bit smaller.  You'll
need to draw the x and y axis separately, lest both fonts be small.
Example:

mp <- barplot(1:16, axes = FALSE, axisnames = FALSE)
axis(2)
axis(1, at = mp, labels = 1:16, cex.axis = 0.5)

You can play around with the value of par("cex.axis") in the 3rd line to
see what size may look good.


If you do want 45 degree x axis labels, one approach is using a
suggestion from Uwe Ligges that I found in a prior post (though, with
slight modification):

labels <- paste("This is bar #", 1:16, sep ="")
mp <- barplot(1:16, axes = FALSE, axisnames = FALSE)
text(mp, par("usr")[3], labels = labels, srt = 45, adj = 1, xpd = TRUE)
axis(2)


You may need to play around with the mp and par("usr")[3] arguments to
text() to get the labels positioned the way you wish, but this should
work.

For example, if you want to draw the actual x axis line and tick marks,
you'll need to shift the rotated x axis labels downward:

labels <- paste("This is bar #", 1:16, sep ="")
mp <- barplot(1:16, axes = FALSE, axisnames = FALSE)
text(mp, par("usr")[3] - 0.5, labels = labels, srt = 45, adj = 1, xpd =
TRUE)
axis(1, at = mp, labels = FALSE)
axis(2)


Finally, you can also combine my other suggestion of reducing the font
size by setting "cex" in the call to text() as follows:

labels <- paste("This is bar #", 1:16, sep ="")
mp <- barplot(1:16, axes = FALSE, axisnames = FALSE)
text(mp, par("usr")[3], labels = labels, srt = 45, adj = 1, cex = 0.5,
xpd = TRUE)
axis(2)

HTH.

Marc Schwartz



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bayesianbay at aol.com  Mon Oct 14 19:10:44 2002
From: Bayesianbay at aol.com (Bayesianbay@aol.com)
Date: Mon, 14 Oct 2002 13:10:44 EDT
Subject: [R] Vector of quantiles
Message-ID: <1c7.da79.2adc5494@aol.com>

I have a quick question which is very simple but I seem to have a mental 
block!

I'm using the pchisq function to specify a Chi Squared distribution with 9 df 
which I'm then going to use in the Kolmogorov-Smirnov Test to test some 
simulated values.

 so simply: pchisq(q, df=9)

I know that q is the vector of quantiles but could anybody tell me what 
exactly this vector needs to contain?

Many Thanks
Laura
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ko-Kang at xtra.co.nz  Mon Oct 14 20:22:56 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Tue, 15 Oct 2002 07:22:56 +1300
Subject: [R] ActiveTcl Version
References: <Pine.LNX.4.31.0210141347330.1247-100000@gannet.stats>
Message-ID: <009501c273ae$b9261660$0e3158db@kwan022>

I've managed to compile R-1.6.0 (Patched) with ActiveTcl 8.4.0.1 two days
ago, on Windows.

(Though I'm not sure the changes made from 8.3.x to 8.4.x).

Cheers,

Kevin

------------------------------------------------
Ko-Kang Kevin Wang
Post Graduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022

----- Original Message -----
From: <ripley at stats.ox.ac.uk>
To: "Peter Ho" <peter at esb.ucp.pt>
Cc: "R" <R-help at stat.math.ethz.ch>
Sent: Tuesday, October 15, 2002 1:49 AM
Subject: Re: [R] ActiveTcl Version


> You mean under Windows, I presume?
>
> For the record (I've been away but could see no reply), the binary
> versions *need* Tcl 8.3.x, as all the docs say.
>
> It is possible to build the sources against 8.4, but that crashes for me.
>
>
> On Tue, 17 Sep 2002, Peter Ho wrote:
>
> > Dear Tcl/Tk users,
> >
> > Will R work with the more recent version of  ActiveTcl 8.4.0.1 or should
> > I use ActiveTcl 8.3.4.3?
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From remigijus.lapinskas at maf.vu.lt  Mon Oct 14 20:17:45 2002
From: remigijus.lapinskas at maf.vu.lt (Remigijus Lapinskas)
Date: Mon, 14 Oct 2002 20:17:45 +0200
Subject: [R] log10(), floor() combo issue?
References: <XFMail.20021014145139.steuer@unibw-hamburg.de>
Message-ID: <19845.021014@maf.vu.lt>

bindec (at least, on my computer) works only for moderate values of b:

bindec <- function(b){
as.i <- as.integer(unlist(strsplit(b,"")))
print(as.i)
fl <- 2^(floor(round(log10(b),10)):0)
print(fl)
dec <- sum(as.i * fl)
dec
}

> bindec(10000)
[1] 1 0 0 0 0
[1] 16  8  4  2  1
[1] 16
> bindec(100000)
[1]  1 NA NA  0  5
[1] 32 16  8  4  2  1
[1] NA
Warning messages:
1: NAs introduced by coercion
2: longer object length
        is not a multiple of shorter object length in: as.i * fl

The reason is that b soon jumps to scientific notation:

> b <- 100000
> b
[1] 1e+05

Here is a slightly improved version of bindec:

> bindec.n <- function(b) {
as.i <- as.integer(unlist((strsplit(b, ""))))
print(as.i)
fl <- 2^(floor(log10(as.numeric(b)+1.0e-7):0))
print(fl)
dec <- sum(as.i * fl)
dec}

> bindec.n("100000")
[1] 1 0 0 0 0 0
[1] 32 16  8  4  2  1
[1] 32
> bindec.n("1000000000000000000")
 [1] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 [1] 131072.0  65536.0  32768.0  16384.0   8192.0   4096.0   2048.0   1024.0
 [9]    512.0    256.0    128.0     64.0     32.0     16.0      8.0      4.0
[17]      2.0      1.0      0.5
[1] 131072

Best,
Remigijus


Monday, October 14, 2002, 2:51:39 PM, you wrote:


DS> On 14-Oct-2002 E.L. Willighagen wrote:
>>
>> Hi all,
>>
>> in my search for a nice binary2decimal method, I received this nice
>> code (thanx to Uwe Ligges):
>>
>>  bindec <- function(b)
>>    sum(as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0))


DS> Nice function!

>>
>> It fails, however, with:
>>
>>> bindec(1000)
>> [1] 4
>> Warning message:
>> longer object length
>>         is not a multiple of shorter object length in:
>> as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0)
>>
>> The reason is the combination of floor() and log10():
>>
>> log10(1000) = 3
>>
>> ok, but:
>>
>> floor(log10(1000)) = 2

DS> Just throw in a round of rounding (say to 10 digits):

DS> floor(round(log10(b),10)).

DS> This repairs the numerical inaccuracies of taking logarithms,
DS> if those are not too large :-).

>> floor(round(log10(1000),10))
DS> [1] 3

DS> detlef


>>
>> ? Ok, I can live with some floating point inaccuracy, but this seems
>> at least a bit strange, and to me troublesome as it makes the bindec()
>> method fail...
>>
>> I've also tried to force the output of log10(1000) into integer format
>> with
>>
>> floor(as.integer(log10(b)))
>>
>> However, with the same disappointing results...
>>
>> Ideas?
>>
>> kind regards,
>>
>> Egon
>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
>> -
>> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
>> _

DS> "There is no way to peace, peace is the way." -- Ghandi

DS> Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
DS> ***** Encrypted mail preferred *****
DS> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
DS> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
DS> Send "info", "help", or "[un]subscribe"
DS> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
DS> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._




Linkejimai,
Remigijus                            mailto:remigijus.lapinskas at maf.vu.lt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at cbs.dtu.dk  Mon Oct 14 21:54:45 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Mon, 14 Oct 2002 21:54:45 +0200
Subject: [R] Vector of quantiles
In-Reply-To: <1c7.da79.2adc5494@aol.com>
References: <1c7.da79.2adc5494@aol.com>
Message-ID: <20021014195445.GC6875@giraffa.cbs.dtu.dk>

I am not sure I saw where is your trouble, but may be a figure will help
to see...

q <- seq(0.1, 30)
p <- pchisq(q, df=9)
plot(q, p, type="l", xlab="quantiles")

points(q, rep(0, length(q)), col="red", pch="+")


Hopin' it helps,


Laurent


On Mon, Oct 14, 2002 at 01:10:44PM -0400, Bayesianbay at aol.com wrote:
> I have a quick question which is very simple but I seem to have a mental 
> block!
> 
> I'm using the pchisq function to specify a Chi Squared distribution with 9 df 
> which I'm then going to use in the Kolmogorov-Smirnov Test to test some 
> simulated values.
> 
>  so simply: pchisq(q, df=9)
> 
> I know that q is the vector of quantiles but could anybody tell me what 
> exactly this vector needs to contain?
> 
> Many Thanks
> Laura
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Mon Oct 14 21:45:36 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Mon, 14 Oct 2002 15:45:36 -0400
Subject: [R] Vector of quantiles
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20149D08D@groexmb02.pfizer.com>


You should be able to do

	ks.test( x, "pchisq", df=9)

to do a KS test on data 'x' against a chi-square with 9 df.  For example,

	> x <- rchisq(1000,df=9)
	> ks.test( x, "pchisq", df=9)
	
	?One-sample Kolmogorov-Smirnov test
	
	data:  x 
	D = 0.0192, p-value = 0.8568
	alternative hypothesis: two.sided 

See the ks.test help page for more details.

-Greg


> -----Original Message-----
> From: Bayesianbay at aol.com [mailto:Bayesianbay at aol.com]
> Sent: Monday, October 14, 2002 1:11 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Vector of quantiles
> 
> 
> I have a quick question which is very simple but I seem to 
> have a mental 
> block!
> 
> I'm using the pchisq function to specify a Chi Squared 
> distribution with 9 df 
> which I'm then going to use in the Kolmogorov-Smirnov Test to 
> test some 
> simulated values.
> 
>  so simply: pchisq(q, df=9)
> 
> I know that q is the vector of quantiles but could anybody 
> tell me what 
> exactly this vector needs to contain?
> 
> Many Thanks
> Laura
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Mon Oct 14 22:10:44 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 14 Oct 2002 13:10:44 -0700 (PDT)
Subject: [R] R 1.6.0 Solaris crash with xmalloc: out of virtual memory
In-Reply-To: <p05111a01b9d0848e6831@[128.115.153.6]>
Message-ID: <Pine.GSO.4.10.10210141309340.26566-100000@fisher.stat.ucla.edu>

This may be caused by the memory leak found in the 'deparse' function (on
1.6.0). Maybe you should see if this happens with the latest R-patched?

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Mon, 14 Oct 2002, Don MacQueen wrote:

> 	[some de-capitalization of *SXP done manually by mailing 
> 	 list maintainer ; the originally was caught as potential spam.  MM]
> 
> I have a little R program that crashes with the message
>    xmalloc: out of virtual memory
> 
> The code has a repeat{} loop that watches the sizes of some files. 
> When there's an increase it updates things by reading the last 65 
> lines of each file, doing some calculations, and re-making a plot. 
> After about 260 updates it crashes with the message
>    xmalloc: out of virtual memory
> and returns to the OS.
> 
> I inserted calls to gc() and memory.profile().
> 
> The value of CHARSXP from memory.profile() increases linearly at a 
> rate of about 332.6 units per update, from 37178 just after R is 
> started to 123319 shortly before it crashes. None of the others 
> change much.
> 
>  From Rinternals.h,
>    #define CHARSXP  9   /* "scalar" string type (internal only)*/
> and it seems like this should give me a clue where to look in my code 
> for something that keeps grabbing more memory, but I'm not getting it.
> 
> The values returned by gc() change (see below), but I don't know if 
> the amount of change is significant.
> 
> Any suggestions would be most welcome.
> 
> Thanks
> -Don
> 
> >  version
>           _
> platform sparc-sun-solaris2.7
> arch     sparc
> os       solaris2.7
> system   sparc, solaris2.7
> status
> major    1
> minor    6.0
> year     2002
> month    10
> day      01
> language R
> 
> 
> ----------------- At the beginning -------------
> --- gc() returns:
>           used (Mb) gc trigger (Mb)
> Ncells 254150  6.8     467875 12.5
> Vcells 408499  3.2     886807  6.8
> 
> --- memory.profile() returns:
> NilSXP SymSXP ListSXP CloSXP EnvSXP PromSXP LangSXP SpecialSXP
>       1   4919  128880   1440     13      18   63607         59
> 
> BUILTINSXP CHARSXP LGLSXP - - INTSXP REALSXP CPLXSXP STRSXP
>         513   37178   1712 0 0    237    9047       8  10201
> 
>   DOTSXP ANYSXP VECSXP EXPRSXP - EXTPTRSXP WEAKREFSXP
>   1           0    341       2 0         0          0
> 
> ---------------- Just before the crash ------------
> --- gc() returns:
>           used (Mb) gc trigger (Mb)
> Ncells 347539  9.3     597831 16.0
> Vcells 566319  4.4    1103261  8.5
> 
> --- memory.profile() returns:
> NilSXP SymSXP ListSXP CloSXP EnvSXP PromSXP LangSXP SpecialSXP
>       1   4921  131330   1440     13      18   63607         59
> 
> BUILTINSXP CHARSXP LGLSXP - - INTSXP REALSXP CPLXSXP STRSXP
>         513  123319   1726 0 0    275    9308       8  10613
> 
> DOTSXP ANYSXP VECSXP EXPRSXP - EXTPTRSXP WEAKREFSXP
>       1      0    427       2 0         0          0
> 
> -- 
> --------------------------------------
> Don MacQueen
> Environmental Protection Department
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> --------------------------------------
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Mon Oct 14 23:20:47 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Mon, 14 Oct 2002 17:20:47 -0400
Subject: [R] Another newbie question: curve of normal distribution
Message-ID: <20021014212046.GA6464@komensky.surfbest.net>


I would like to get a curve of normal distrubtion over the
histogram. Something like the following (which obviously doesn't
work; see attached example).

	maluj <- function() {

	vrhy=read.csv("pennies.csv",head=TRUE)

	hf=table(vrhy$HEADS)
	postscript("heads.eps",onefile=FALSE,width=4.134,height=3.445,pointsize=12)
	plot(hf,main="Frequency distribution of heads",xlab="Throws",
		ylab="Frequency")
	lines(rnorm(length(hf),mean=mean(hf),sd=sd(hf)))
	dev.off(2)

	}

Any help, please?

Thanks

	Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
understand, v.:
    To reach a point, in your investigation of some subject,
    at which you cease to examine what is really present, and
    operate on the basis of your own internal model instead.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: heads.eps
Type: application/postscript
Size: 5242 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021014/b203f123/heads.eps

From p.dalgaard at biostat.ku.dk  Mon Oct 14 23:30:49 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Oct 2002 23:30:49 +0200
Subject: [R] R 1.6.0 Solaris crash with xmalloc: out of virtual memory
In-Reply-To: <Pine.GSO.4.10.10210141309340.26566-100000@fisher.stat.ucla.edu>
References: <Pine.GSO.4.10.10210141309340.26566-100000@fisher.stat.ucla.edu>
Message-ID: <x2y990zp12.fsf@biostat.ku.dk>

Roger Peng <rpeng at stat.ucla.edu> writes:

> This may be caused by the memory leak found in the 'deparse' function (on
> 1.6.0). Maybe you should see if this happens with the latest R-patched?

Hmm, the "signature" is not quite consitent with that problem, but you
could always try.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolfram at fischer-zim.ch  Mon Oct 14 22:10:15 2002
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Mon, 14 Oct 2002 22:10:15 +0200
Subject: [R] import a bitmap image and add it to graphics display
Message-ID: <20021014221015.A1244@s1x.zimnet.ch>

Hello

Is there a possibility to import and add a bitmap image (png or 
similar) to a R graphics display. It would be helpful e.g. to
locate positions of points of a scanned map or to add a background
to a R graphic.

Wolfram
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jbalinc at insight.rr.com  Mon Oct 14 19:21:46 2002
From: jbalinc at insight.rr.com (Jess Balint)
Date: Mon, 14 Oct 2002 18:21:46 +0100
Subject: [R] barplot(): X-Axis Labels
In-Reply-To: <001d01c273a1$f297f8d0$0201a8c0@MARC>
References: <sdaabe03.045@ccw0m.nottingham.ac.uk>
	<001d01c273a1$f297f8d0$0201a8c0@MARC>
Message-ID: <20021014182146.782a95c8.jbalinc@insight.rr.com>

On Mon, 14 Oct 2002 11:51:30 -0500
"Marc Schwartz" <mschwartz at medanalytics.com> wrote:

> labels <- paste("This is bar #", 1:16, sep ="")
> mp <- barplot(1:16, axes = FALSE, axisnames = FALSE)
> text(mp, par("usr")[3], labels = labels, srt = 45, adj = 1, xpd = TRUE)
> axis(2)
> 

Thank you all very much for your assistance. One more issue I do have is creating a label for the x-axis. If I specificy xlab = "" within the barplot(), it get overwritten by the category labels. I tried to add one below that with text( locator( 1 ), "x-axis label" ), but it seems that it won't insert the text below a certain threshold. Is there a way around this?
Thanks again.

Jess
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From johns2326 at hotmail.com  Tue Oct 15 01:21:35 2002
From: johns2326 at hotmail.com (John Smith)
Date: Mon, 14 Oct 2002 19:21:35 -0400
Subject: [R] Browser icon for CRAN
Message-ID: <F132tg2c7qIA3EEmYDK000015e3@hotmail.com>

On newer versions of MS Internet Explorer and Netscape Navigator, little 
icons show up in the search window to identify a site. For example, when I 
point my browser to www.apple.com is displays a little grey apple. Likewise, 
yahoo.com presents a big red Y and an exclamation point. Are these called 
"browser icons", or "web icons"? In any case, I'm wondering why CRAN's is a 
capital S. Nice looking font, but shouldn't that be ... oh well, I'm sure 
there's a good explanation. Just curious.

John Shonder



_________________________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Tue Oct 15 04:35:49 2002
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 14 Oct 2002 22:35:49 -0400
Subject: [R] Question: concatenating lists
Message-ID: <5.1.0.14.2.20021014215153.01daa9a8@mcmail.cis.mcmaster.ca>

Dear Hein,

On Mon Oct 14 2002 - 17:03:40 CEST, you wrote:


>I have the following problem. I have a number of lists with identical
>structure. Each component is a vector, matrix or array, but components of
>different lists may be of different size. How do I combine the lists to get
>a new list such that each component of this list contains the components of
>the individual lists?
>
>An example may explain most clearly what I need.
>
>Suppose I have three lists:
>list1 <- list(a=1:2,b=matrix(1,2,2))
>list2 <- list(a=3:5,b=matrix(-1,3,3))
>list3 <- list(a=6:9,b=matrix(5,4,4))
>
>The result should give me something like:
>
>$a:
>      [,1] [,2] [,3]
>[1,] 1 3 6
>[2,] 2 4 7
>[3,] NA 5 8
>[4,] NA NA 9
>
>$b:
>, , 1
>      [,1] [,2] [,3] [,4]
>[1,] 1 1 NA NA
>[2,] 1 1 NA NA
>[3,] NA NA NA NA
>[4,] NA NA NA NA
>
>, , 2
>      [,1] [,2] [,3] [,4]
>[1,] -1 -1 -1 NA
>[2,] -1 -1 -1 NA
>[3,] -1 -1 -1 NA
>[4,] NA NA NA NA
>
>, , 3
>      [,1] [,2] [,3] [,4]
>[1,] 5 5 5 5
>[2,] 5 5 5 5
>[3,] 5 5 5 5
>[4,] 5 5 5 5
>
>Any ideas would be much appreciated.

Here's a solution to your problem. I haven't tested it extensively, and 
it's a bit awkward, but it seems to work. I expect that, as is usually the 
case, you'll have several better suggestions shortly.

     combine <- function(...){
         NApad <- function(x, dim){
             result <- array(NA, dim)
             subscript <- as.matrix(do.call("expand.grid", lapply(dim(x), 
function(x) 1:x)))
             result[subscript] <- x
             result
             }
         paste.arrays <- function(...) {
             arrays <- list(...)
             n <- length(arrays)
             d <- dim(arrays[[1]])
             array(unlist(arrays), c(d, n))
             }
         lists <- list(...)
         result <- lists[[1]]
         components <- names(result)
         for (component in components){
             list.components <- lapply(lapply(lists, function(x) 
x[[component]]), as.array)
             d <- do.call("pmax", lapply(list.components, dim))
             result[[component]] <- do.call("paste.arrays",
                 lapply(list.components, function(x) NApad(x, d)))
             }
         result
         }

This assumes that the lists passed as arguments to combine have the same 
elements, and that corresponding elements are vectors or arrays of the same 
dimension (though not necessarily of the same order). Applying the function 
to your example:

     > combine(list1, list2, list3)
     $a
         [,1] [,2] [,3]
     [1,]    1    3    6
     [2,]    2    4    7
     [3,]   NA    5    8
     [4,]   NA   NA    9

     $b
     , , 1

         [,1] [,2] [,3] [,4]
     [1,]    1    1   NA   NA
     [2,]    1    1   NA   NA
     [3,]   NA   NA   NA   NA
     [4,]   NA   NA   NA   NA

     , , 2

         [,1] [,2] [,3] [,4]
     [1,]   -1   -1   -1   NA
     [2,]   -1   -1   -1   NA
     [3,]   -1   -1   -1   NA
     [4,]   NA   NA   NA   NA

     , , 3

         [,1] [,2] [,3] [,4]
     [1,]    5    5    5    5
     [2,]    5    5    5    5
     [3,]    5    5    5    5
     [4,]    5    5    5    5


I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Tue Oct 15 04:59:35 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 14 Oct 2002 21:59:35 -0500
Subject: [R] barplot(): X-Axis Labels
In-Reply-To: <20021014182146.782a95c8.jbalinc@insight.rr.com>
Message-ID: <001601c273f6$e5bccd20$0201a8c0@MARC>

> -----Original Message-----
> Thank you all very much for your assistance. One more issue I do have
is
> creating a label for the x-axis. If I specificy xlab = "" within the
barplot(), it get
> overwritten by the category labels. I tried to add one below that with
text(
> locator( 1 ), "x-axis label" ), but it seems that it won't insert the
text below a
> certain threshold. Is there a way around this?
> Thanks again.
> 
> Jess

Jess,

Normally when drawing text outside the plot region, which is defined by
the box() around the barplot in this case, you need to use mtext() and
not text().

The generation of the 45 degree rotated axis labels in the code I posted
earlier "tricks" the text() command in drawing the labels outside the
plot region.  The x and y coordinate values that text() uses are based
upon the plot region area coordinates.

Add the following line to the end of the prior example code:

mtext("x-axis label", line = 3, side = 1)

It will get overwritten by the axis labels, so you will need to adjust
the "line = " argument to move the x axis label vertically to a position
that makes sense with your real data. 

The "line" argument starts at 0 (zero) near the x axis itself and
increases as you approach the bottom limit of the open graphics window.
If you go too high in "line = ", it will be drawn outside (below) the
visible window.  Thus, you may have to adjust the margin boundaries for
the window to provide additional room below the plot region.  You can do
this by using par("mar") before the barplot is drawn.

HTH.

Marc



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From azboater at dakotacom.net  Tue Oct 15 06:17:05 2002
From: azboater at dakotacom.net (Scott Marley)
Date: Mon, 14 Oct 2002 21:17:05 -0700
Subject: [R] New to R and need help
References: <000d01c27397$2a1f8580$bfaf8796@marleyux8q0l48><15786.58695.825623.866965@gargle.gargle.HOWL> <x23cr90zb2.fsf@biostat.ku.dk>
Message-ID: <00f101c27401$c02d51a0$bfaf8796@marleyux8q0l48>


----- Original Message -----
From: "Peter Dalgaard BSA" <p.dalgaard at biostat.ku.dk>
To: "Martin Maechler" <maechler at stat.math.ethz.ch>
Cc: "Scott Marley" <azboater at dakotacom.net>; <r-help at stat.math.ethz.ch>
Sent: Monday, October 14, 2002 9:18 AM
Subject: Re: [R] New to R and need help


> Martin Maechler <maechler at stat.math.ethz.ch> writes:
>
> > >>>>> "Scott" == Scott Marley <azboater at dakotacom.net>
> > >>>>>     on Mon, 14 Oct 2002 08:34:14 -0700 writes:
> >
> >     Scott> All,
> >
> >     Scott> I just took a cool R workshop and I'm chomping at the
> >     Scott> bit to play around with it.  I'm fairly familiar with
> >     Scott> SAS and have some data that I used with Sas.  My
> >     Scott> question is: How do I take a text file(I think my
> >     Scott> instructor called it a rectangular file) and import
> >     Scott> it to R.  In sas you use an input statement followed
> >     Scott> by Variable name and the column numbers for the
> >     Scott> location of the data.  Does R have a similar
> >     Scott> procedure?  What would the syntax look like?  Thank
> >     Scott> you for any help you can offer.
> >
> > help(read.table)
>
> (Why don't we have examples in there??)
>
> Specifically, you do something like
>
> x <- read.table("myfile.txt")
> names(x) <- c("age", "height", "weight")
>
> or, preferably, add a 1st row containing the variable names to the
> data file and do
>
> x <- read.table("myfile.txt", header=TRUE)
>
> There's a number of fine points concerning missing value specification
> and variable types, for which the help page should be consulted.
>

Peter and all others,

Thank you for your help.  I was able to get the file loaded in.  The data
set I have is unusual in regards to having spaces inbetween variables.
Usually the columns lack spaces inbetween in my other data sets.  In SAS I
would give the variable name then the column #.  Is there a similar
procedure in R?

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Oct 15 08:52:24 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 15 Oct 2002 08:52:24 +0200
Subject: [R] Another newbie question: curve of normal distribution
References: <20021014212046.GA6464@komensky.surfbest.net>
Message-ID: <3DABBB28.B966C1FF@statistik.uni-dortmund.de>



Matej Cepl wrote:
> 
> I would like to get a curve of normal distrubtion over the
> histogram. Something like the following (which obviously doesn't
> work; see attached example).
> 
>         maluj <- function() {
> 
>         vrhy=read.csv("pennies.csv",head=TRUE)
> 
>         hf=table(vrhy$HEADS)
>         postscript("heads.eps",onefile=FALSE,width=4.134,height=3.445,pointsize=12)
>         plot(hf,main="Frequency distribution of heads",xlab="Throws",
>                 ylab="Frequency")
>         lines(rnorm(length(hf),mean=mean(hf),sd=sd(hf)))

Try
	 curve(function(x) dnorm(x, mean=mean(hf), sd=sd(hf)), 
            add = TRUE, from = min(hf) to = max(hf))

Uwe Ligges

>         dev.off(2)
> 
>         }
> 
> Any help, please?
> 
> Thanks
> 
>         Matej
> 
> --
> Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
> 138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
> 
> understand, v.:
>     To reach a point, in your investigation of some subject,
>     at which you cease to examine what is really present, and
>     operate on the basis of your own internal model instead.
> 
>   ------------------------------------------------------------------------
>                 Name: heads.eps
>    heads.eps    Type: Postscript Document (application/postscript)
>             Encoding: quoted-printable
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Oct 15 09:35:11 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 15 Oct 2002 09:35:11 +0200
Subject: [R] barplot(): X-Axis Labels
In-Reply-To: <001d01c273a1$f297f8d0$0201a8c0@MARC>
References: <sdaabe03.045@ccw0m.nottingham.ac.uk>
	<001d01c273a1$f297f8d0$0201a8c0@MARC>
Message-ID: <15787.50479.742304.529046@gargle.gargle.HOWL>

>>>>> "Marc" == Marc Schwartz <mschwartz at medanalytics.com>
>>>>>     on Mon, 14 Oct 2002 11:51:30 -0500 writes:

    >> -----Original Message-----
    >> Martin Hoyle wrote:
    >> 
    >> Try using las=2 in the barplot command;
    >> 
    >> barplot(response variable means,names=levels(explanatory
    >> variable),las=2)
    >> 
    >> The text is then at 90 degrees,
    >> 
    >> >>> Jess Balint <jbalinc at insight.rr.com> 10/13/02 10:47PM >>>
    >> 
    >> Hello all. I have a simple barplot with sixteen different segments.
    >> When I plot my data, only five or six of the labels are showing in the
    >> x-axis. How do go get them all to show? Can I set them at a 45.degree
    >> angle? Thank you.
    >> 
    >> Jess

    Marc> In addition to Martin's suggestion, you might wish to use meaningful
    Marc> abbreviations to shorten the labels.

    Marc> You can also use par("cex.axis") to make the font a bit smaller.  You'll
    Marc> need to draw the x and y axis separately, lest both fonts be small.
    Marc> Example:

    Marc> mp <- barplot(1:16, axes = FALSE, axisnames = FALSE)
    Marc> axis(2)
    Marc> axis(1, at = mp, labels = 1:16, cex.axis = 0.5)

    Marc> ....
    Marc> ....   {more nice explanations and examples}
    Marc> ....

Just a remark on the example above (and the ones not cited
here), particularly since I've seen other people do the same:

If it's just one axis annotation that you want to "fiddle" with
and the other drawn regularly, it's slightly ``nicer'' to use
{with the above}

  mp <- barplot(1:16, xaxt = "n", axisnames = FALSE)
  ##                  ~~~~~~~~~~
  axis(1, at = mp, labels = 1:16, cex.axis = 0.5)

instead of `` axes = FALSE '' and the extra ``axis(2)'' command.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Oct 15 10:13:55 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 15 Oct 2002 10:13:55 +0200
Subject: [R] New to R and need help
References: <000d01c27397$2a1f8580$bfaf8796@marleyux8q0l48><15786.58695.825623.866965@gargle.gargle.HOWL> <x23cr90zb2.fsf@biostat.ku.dk> <00f101c27401$c02d51a0$bfaf8796@marleyux8q0l48>
Message-ID: <3DABCE43.62DCA226@statistik.uni-dortmund.de>



Scott Marley wrote:
> 
> ----- Original Message -----
> From: "Peter Dalgaard BSA" <p.dalgaard at biostat.ku.dk>
> To: "Martin Maechler" <maechler at stat.math.ethz.ch>
> Cc: "Scott Marley" <azboater at dakotacom.net>; <r-help at stat.math.ethz.ch>
> Sent: Monday, October 14, 2002 9:18 AM
> Subject: Re: [R] New to R and need help
> 
> > Martin Maechler <maechler at stat.math.ethz.ch> writes:
> >
> > > >>>>> "Scott" == Scott Marley <azboater at dakotacom.net>
> > > >>>>>     on Mon, 14 Oct 2002 08:34:14 -0700 writes:
> > >
> > >     Scott> All,
> > >
> > >     Scott> I just took a cool R workshop and I'm chomping at the
> > >     Scott> bit to play around with it.  I'm fairly familiar with
> > >     Scott> SAS and have some data that I used with Sas.  My
> > >     Scott> question is: How do I take a text file(I think my
> > >     Scott> instructor called it a rectangular file) and import
> > >     Scott> it to R.  In sas you use an input statement followed
> > >     Scott> by Variable name and the column numbers for the
> > >     Scott> location of the data.  Does R have a similar
> > >     Scott> procedure?  What would the syntax look like?  Thank
> > >     Scott> you for any help you can offer.
> > >
> > > help(read.table)
> >
> > (Why don't we have examples in there??)
> >
> > Specifically, you do something like
> >
> > x <- read.table("myfile.txt")
> > names(x) <- c("age", "height", "weight")
> >
> > or, preferably, add a 1st row containing the variable names to the
> > data file and do
> >
> > x <- read.table("myfile.txt", header=TRUE)
> >
> > There's a number of fine points concerning missing value specification
> > and variable types, for which the help page should be consulted.
> >
> 
> Peter and all others,
> 
> Thank you for your help.  I was able to get the file loaded in.  The data
> set I have is unusual in regards to having spaces inbetween variables.
> Usually the columns lack spaces inbetween in my other data sets.  In SAS I
> would give the variable name then the column #.  Is there a similar
> procedure in R?

See ?read.fwf

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Oct 15 10:17:00 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Oct 2002 10:17:00 +0200
Subject: [R] New to R and need help
In-Reply-To: <00f101c27401$c02d51a0$bfaf8796@marleyux8q0l48>
References: <000d01c27397$2a1f8580$bfaf8796@marleyux8q0l48>
	<15786.58695.825623.866965@gargle.gargle.HOWL>
	<x23cr90zb2.fsf@biostat.ku.dk>
	<00f101c27401$c02d51a0$bfaf8796@marleyux8q0l48>
Message-ID: <x2u1joyv43.fsf@biostat.ku.dk>

"Scott Marley" <azboater at dakotacom.net> writes:

> > x <- read.table("myfile.txt", header=TRUE)
> >
> > There's a number of fine points concerning missing value specification
> > and variable types, for which the help page should be consulted.
> >
> 
> Peter and all others,
> 
> Thank you for your help.  I was able to get the file loaded in.  The data
> set I have is unusual in regards to having spaces inbetween variables.
> Usually the columns lack spaces inbetween in my other data sets.  In SAS I
> would give the variable name then the column #.  Is there a similar
> procedure in R?

Yes, read.fwf() (fixed-width format)

Also note that the "foreign" package will allow you to read datasets
in SAS portable libraries directly. 

(These ones: libname foo xport "foo.xpt";)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bayesianbay at aol.com  Tue Oct 15 11:49:15 2002
From: Bayesianbay at aol.com (Bayesianbay@aol.com)
Date: Tue, 15 Oct 2002 05:49:15 EDT
Subject: [R] Kolmogorov-Smirnov Test
Message-ID: <31.2e973788.2add3e9b@aol.com>

Many thanks for the help I received from people yesterday regarding vector 
quantiles.

I have a question regarding the Kolmogorov-Smirnov test.

I have a vector of 1000 numbers (called 'data') which I suspect to follow a 
chi-squared distribution with 9 df so I am running the command:

ks.test(data, "pchisq", df=9)

I am continually getting a p-value of  < 2.2e-16 which is leading to a 
continual conclusion that my numbers are not equal to the distribution being 
tested.

I have tried changing the number of df and although the value of D statistic 
changes (ranging from 0.2 to 1) I always get a p-value of < 2.2e-16 

What I am doing wrong here and is there any way to forc R to give me any more 
detail about the calculation it has carried out?

Thanks in advance
Laura
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bigler at fowi.ethz.ch  Tue Oct 15 13:29:31 2002
From: bigler at fowi.ethz.ch (Christof Bigler)
Date: Tue, 15 Oct 2002 13:29:31 +0200
Subject: [R] glm and Newey-West estimator
Message-ID: <5F4F05E2-E031-11D6-9951-000A27D7D440@fowi.ethz.ch>

Dear R-users,

has anybody combined the glm function with the Newey-West estimator of 
variance, similar as in Stata 7.0? I'd like to estimate corrected 
standard errors within a logistic regression model, taking into account 
the auto-correlated binary observations within individuals.
I use R1.5.1 on Mac OS X (10.2).

Thanks,
Christof

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jan.wiener at tuebingen.mpg.de  Tue Oct 15 13:38:18 2002
From: jan.wiener at tuebingen.mpg.de (Jan Malte Wiener)
Date: Tue, 15 Oct 2002 13:38:18 +0200
Subject: [R] V-value in the wilcox.test resp. wilcox.exact 
Message-ID: <3DABFE2A.3070704@tuebingen.mpg.de>

hi,
when performing a wilcox.test or a wilcox.exact i get results that looks 
like this:

wilcox.exact(x, mu=.5)
         Exact Wilcoxon signed rank test

data:  x
V = 207, p-value = 0.0006905
alternative hypothesis: true mu is not equal to 0.5


the way i understand the wilcox.test (or wilcox.exact) the V-value 
represents the summed up ranks of either the positive or negative 
differences, whichever sum is BIGGER.

to actually look up the p-value in a table (and to quote it in a 
publication) i need the T value, which to my understanding is the summed 
up ranks of either the positive or negative differences, whichever sum 
is SMALLER.

so i guess my question is: how do i get the T-value

thanks,
jan

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plxmh at nottingham.ac.uk  Tue Oct 15 14:05:58 2002
From: plxmh at nottingham.ac.uk (Martin Hoyle)
Date: Tue, 15 Oct 2002 13:05:58 +0100
Subject: [R] normalizing data sets
Message-ID: <sdac12bc.074@ccw0m.nottingham.ac.uk>



Martin Hoyle,
School of Life and Environmental Sciences,
University of Nottingham,
University Park,
Nottingham,
NG7 2RD,
UK
Webpage: http://myprofile.cos.com/martinhoyle

>>> "Rishabh Gupta" <rg117 at ohm.york.ac.uk> 10/14/02 05:19PM >>>
Hi,
 Can someone tell me how to normalize a data set so that the mean of
the set is 0 and the variance is 1. As I understand, when you
calculate the principle components of a data set through correlation
as
< princomp( dataset,  cor=T ) >
then a similar calculation is performed. I would like to know how I can
perform such a calulation directly. Any help would be
greatly appreciated.

Many Thanks

Rishabh

Dear Rishabh,

Suppose your data was in variable x, with the following values;

 x<-c(5,4,6,8,6,9,2,7,6,8)

Then create the variable xtransformed;

xtransformed<-(x-mean(x))/sd(x)

Then xtransformed has mean of 0 and variance of 1 as required;

mean(xtransformed) = 0,
var(xtransformed) = 1,

Regards,
Martin.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Oct 15 14:13:26 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Oct 2002 14:13:26 +0200
Subject: [R] V-value in the wilcox.test resp. wilcox.exact
In-Reply-To: <3DABFE2A.3070704@tuebingen.mpg.de>
References: <3DABFE2A.3070704@tuebingen.mpg.de>
Message-ID: <x2adlf3no9.fsf@biostat.ku.dk>

Jan Malte Wiener <jan.wiener at tuebingen.mpg.de> writes:

> the way i understand the wilcox.test (or wilcox.exact) the V-value
> represents the summed up ranks of either the positive or negative
> differences, whichever sum is BIGGER.
> 
> to actually look up the p-value in a table (and to quote it in a
> publication) i need the T value, which to my understanding is the
> summed up ranks of either the positive or negative differences,
> whichever sum is SMALLER.
> 
> so i guess my question is: how do i get the T-value

At least for wilcox.test, V is the sum of the *positive* ranks. The
sum of the negative ranks can be obtained by switching the sign on x
and mu. 

In the absence of ties and exact zeros, the two rank sums add up to
sum(1:N) == N*(N+1)/2

If ties are present, standard tables are wrong anyway...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From christof at nicht-ich.de  Tue Oct 15 16:16:45 2002
From: christof at nicht-ich.de (Christof Meigen)
Date: 15 Oct 2002 16:16:45 +0200
Subject: [R] absurd computiation times of lme
In-Reply-To: <6r1y6w648y.fsf@bates4.stat.wisc.edu>
References: <87lm55gnqf.fsf@home.nicht-ich.de> <3DA6D86B.1B82044B@sentoo.sn>
	<87wuooor55.fsf@home.nicht-ich.de>
	<6r1y6w648y.fsf@bates4.stat.wisc.edu>
Message-ID: <873cr7948i.fsf@home.nicht-ich.de>



Hi,

thanks a lot for all your hints. Alas, some problems remain

Douglas Bates <bates at stat.wisc.edu> writes:
> But you are also implicitly estimating the random effects for each
> child.  These are sometimes regarded as 'nuisance' parameters but they
> still need to be estimated, at least implicitly.  In this case there
> would be about 6000 of them (1000 children by 6 random effects per
> child).

I'm aware of that, and would not dare to estimate these parameters
independently per child, since I would be overfitting the data.

But I thought one could use lme to constain this flexibility by
using information derived from the rest of the population. If this would
only mean subtracting the mean curve, I woulnd't need lme, would I:

> There is a big difference when fitting random effects between adding
> parameters in the fixed effects, which are estimated from all the
> data, and adding parameters in the random effects, which are estimated
> from the data for one subject.

Does this really mean that the estimates for the random effects are
totally independent from the rest of the data? So, if my random
effect is flexible enough to model more ore less any curve,
this "any" curve will be fitted to the data no matter how unlikely
it is (looking at the rest of the population) and how little
data is availiable on this subject?

The point is that the inclusion criterium for the children is that
they have _at least_ measurments in each quarter, but some have
measurements every month or so. I thought lme would be a good 
way to deal with this difference in the amount of information available.

> I would recommend that you start with a spline model for the fixed
> effects but use either a simple additive shift for the random effects
> (random = ~1|Subject) or an additive shift and a shift in the time
> trend (random = ~ age | Subject).  You simply don't have enough data
> to estimate 6 parameters from the data for each child.

Bad enough, this is for an PhD (luckily not mine) about growth
velocity. The medical Prof sees no problem, saying: when you
have two measurements you have a growth velocity for the timepoint
right between these measurements. 

I think this is a bad approach and suggested to smooth the curves
before. The approach of using (random = ~ age | Subject) or,
as seen from looking at the log's, better (random = ~ age^0.15 | Subject),
works as expected, but gives fits which are sometimes as far as
3 cm from the real measurements (while the measurement error
is assumed to be about 0.5cm). These unusual decelerations are
exactly what the wannabe-PhD is interested in.

Finally, the argument with the "too little data" does not apply
to the set-up with with Berkeley Boys, with each one 31 measurements,
where a 7-parameters spline basis random effect wouldn't converge
within several hours.

        Christof
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Tue Oct 15 15:29:06 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue, 15 Oct 2002 09:29:06 -0400 (EDT)
Subject: [R] normalizing data sets
In-Reply-To: <001301c2739d$702c3400$35892090@ohm.york.ac.uk>
Message-ID: <Pine.LNX.4.44.0210150927360.28436-100000@bolker.zoo.ufl.edu>


  ?scale

 (by the way, that's "principal" components analysis ...)


On Mon, 14 Oct 2002, Rishabh Gupta wrote:

> Hi,
>  Can someone tell me how to normalize a data set so that the mean of the set is 0 and the variance is 1. As I understand, when you
> calculate the principle components of a data set through correlation as
> < princomp( dataset,  cor=T ) >
> then a similar calculation is performed. I would like to know how I can perform such a calulation directly. Any help would be
> greatly appreciated.
> 
> Many Thanks
> 
> Rishabh
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Oct 15 15:24:44 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Oct 2002 15:24:44 +0200
Subject: [R] absurd computiation times of lme
In-Reply-To: <873cr7948i.fsf@home.nicht-ich.de>
References: <87lm55gnqf.fsf@home.nicht-ich.de> <3DA6D86B.1B82044B@sentoo.sn>
	<87wuooor55.fsf@home.nicht-ich.de>
	<6r1y6w648y.fsf@bates4.stat.wisc.edu>
	<873cr7948i.fsf@home.nicht-ich.de>
Message-ID: <x265w33kdf.fsf@biostat.ku.dk>

Christof Meigen <christof at nicht-ich.de> writes:

> I think this is a bad approach and suggested to smooth the curves
> before. The approach of using (random = ~ age | Subject) or,
> as seen from looking at the log's, better (random = ~ age^0.15 | Subject),
> works as expected, but gives fits which are sometimes as far as
> 3 cm from the real measurements (while the measurement error
> is assumed to be about 0.5cm). These unusual decelerations are
> exactly what the wannabe-PhD is interested in.

This stuff can be tricky. We've had some success a couple of years back
with variants of models like


lme.obj <- lme(log(Height)~ns(sqrt(Age),knots=sqrt(c(0.25,.5,1,5)),
  Boundary.knots=c(0,sqrt(10))), random=~sqrt(Age)|ID,
  correlation=corExp(value=c(-log(0.2),0.1),form=~sqrt(Age),nugget=T))

This was also on children, albeit severely growth-retarded, and with a
less regular sampling than you seem to have. Notice that we felt it
was necessary to add some sort of correlation structure. One gotcha
which gave us convergence problems turned out to be due to the
starting value of corExp() being keyed to the *minimum* distance
between two measurements on the same individual. The really crucial
thing, however, was the need to work with transformations on both the
x and y axes in order to roughly stabilize the variance and avoid
"ringing" effects of fitting sharp gradients at small ages.
 
> Finally, the argument with the "too little data" does not apply
> to the set-up with with Berkeley Boys, with each one 31 measurements,
> where a 7-parameters spline basis random effect wouldn't converge
> within several hours.

Well, I'm sure that Doug and Jose would appreciate any insights that
could help them speed up the algorithms...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chr.schulz at email.de  Tue Oct 15 15:37:12 2002
From: chr.schulz at email.de (chr.schulz@email.de)
Date: Tue, 15 Oct 2002 15:37:12 +0200
Subject: [R] Identification of heterogeneous subpopulation (MECOSA3)
Message-ID: <200210151337.g9FDbCX20430@mailgate5.cinetic.de>

Hi,

i read something about MECOSA3 (G.Arminger)
which is a software to :
"Analysis of finite mixtures of conditional Lisrel models"

I'm very interested to identify heterogeneous subpopulations and ask
me are similar functions doing something in R, too ???

I know SEM and perhaps with some additions/modifications it is possible
doing this general mean- and covariance structures with metric and
non-metric dependent variables and mixtures of conditional multivariate
normal distributed variables ?

...but until now i'm not a expert for this and must train myself to understand
the  mathematical purposes and intentions from this apporach.

Neverthless it would be nice when an expert for this have some
R  related suggestions for me i.e. working with special packages/functions
as a starting point !


Thanks for advance and regards,
Christian

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 15 15:42:57 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 15 Oct 2002 14:42:57 +0100 (BST)
Subject: [R] ActiveTcl Version
In-Reply-To: <009501c273ae$b9261660$0e3158db@kwan022>
Message-ID: <Pine.LNX.4.31.0210151441400.3016-100000@gannet.stats>

But did it work reliably?

I got

1) Compilation warnings
2) Random crashes using 8.4.0.1

and the same happened with the betas of 8.4.  PD is looking into this.

On Tue, 15 Oct 2002, Ko-Kang Kevin Wang wrote:

> I've managed to compile R-1.6.0 (Patched) with ActiveTcl 8.4.0.1 two days
> ago, on Windows.
>
> (Though I'm not sure the changes made from 8.3.x to 8.4.x).
>
> Cheers,
>
> Kevin
>
> ------------------------------------------------
> Ko-Kang Kevin Wang
> Post Graduate PGDipSci Student
> Department of Statistics
> University of Auckland
> New Zealand
> www.stat.auckland.ac.nz/~kwan022
>
> ----- Original Message -----
> From: <ripley at stats.ox.ac.uk>
> To: "Peter Ho" <peter at esb.ucp.pt>
> Cc: "R" <R-help at stat.math.ethz.ch>
> Sent: Tuesday, October 15, 2002 1:49 AM
> Subject: Re: [R] ActiveTcl Version
>
>
> > You mean under Windows, I presume?
> >
> > For the record (I've been away but could see no reply), the binary
> > versions *need* Tcl 8.3.x, as all the docs say.
> >
> > It is possible to build the sources against 8.4, but that crashes for me.
> >
> >
> > On Tue, 17 Sep 2002, Peter Ho wrote:
> >
> > > Dear Tcl/Tk users,
> > >
> > > Will R work with the more recent version of  ActiveTcl 8.4.0.1 or should
> > > I use ActiveTcl 8.3.4.3?
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272860 (secr)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-
> > r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> >
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
> >
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 15 15:45:46 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 15 Oct 2002 14:45:46 +0100 (BST)
Subject: [R] New to R and need help
In-Reply-To: <x23cr90zb2.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.31.0210151443260.3016-100000@gannet.stats>

On 14 Oct 2002, Peter Dalgaard BSA wrote:

> Martin Maechler <maechler at stat.math.ethz.ch> writes:
>
> > >>>>> "Scott" == Scott Marley <azboater at dakotacom.net>
> > >>>>>     on Mon, 14 Oct 2002 08:34:14 -0700 writes:
> >
> >     Scott> All,
> >
> >     Scott> I just took a cool R workshop and I'm chomping at the
> >     Scott> bit to play around with it.  I'm fairly familiar with
> >     Scott> SAS and have some data that I used with Sas.  My
> >     Scott> question is: How do I take a text file(I think my
> >     Scott> instructor called it a rectangular file) and import
> >     Scott> it to R.  In sas you use an input statement followed
> >     Scott> by Variable name and the column numbers for the
> >     Scott> location of the data.  Does R have a similar
> >     Scott> procedure?  What would the syntax look like?  Thank
> >     Scott> you for any help you can offer.
> >
> > help(read.table)
>
> (Why don't we have examples in there??)

Well, we do have a half a manual (R Data Import/Export) devoted to this,
and that is referenced from the help page.

There is also a chapter of `An Introduction to R' with examples.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lm.silva at sapo.pt  Tue Oct 15 16:20:28 2002
From: lm.silva at sapo.pt (Luis Miguel Almeida da Silva)
Date: Tue, 15 Oct 2002 15:20:28 +0100 (WEST)
Subject: [R] R memory 
Message-ID: <1034691628.3dac242cc411c@webmail.sapo.pt>

Hello

I was doing PCA (principal component analysis) with a DNA 
expression matrix (7000 rows/38 columns; from golubEsets) but I 
had the following problem

"Error:cannot allocate vector of size 397051 Kb
In addition: Warning message:
Reached total allocation of 119Mb: see help(memory.size)" 

I've already done some filtering (reduced to 3051 rows) but the 
problem remains, only the size of the vector to allocate is 
smaller.

Can I allocate more memory? How? Probably the problem is also 
from the machine itself, which is a Pentium III 700 Mhz 128Mb 
RAM. Could you help me?

Thanks

Luis Silva

--------------------------------------------
SAPO ADSL.PT Agora o kit apenas por 75 Eur. e tr?fego ilimitado at? ao final de 2002!
Mais informa??es em http://www.sapo.pt/kitadsl
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Oct 15 16:24:25 2002
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 15 Oct 2002 16:24:25 +0200 (MEST)
Subject: [R] V-value in the wilcox.test resp. wilcox.exact 
In-Reply-To: <3DABFE2A.3070704@tuebingen.mpg.de>
Message-ID: <Pine.LNX.4.21.0210151614520.5824-100000@artemis>


> hi,
> when performing a wilcox.test or a wilcox.exact i get results that looks 
> like this:
> 
> wilcox.exact(x, mu=.5)
>          Exact Wilcoxon signed rank test
> 
> data:  x
> V = 207, p-value = 0.0006905
> alternative hypothesis: true mu is not equal to 0.5
> 
> 
> the way i understand the wilcox.test (or wilcox.exact) the V-value 
> represents the summed up ranks of either the positive or negative 
> differences, whichever sum is BIGGER.

no. wilcox.test computes the statistic along the following lines

        x <- x - mu
        ZEROES <- any(x == 0)
        if(ZEROES)
            x <- x[x != 0]
        ...
        r <- rank(abs(x))
        STATISTIC <- sum(r[x > 0])

i.e. the sum of the ranks of the absolute values of x which belong
to positive values of x. 

> 
> to actually look up the p-value in a table (and to quote it in a 
> publication) i need the T value, which to my understanding is the summed 
> up ranks of either the positive or negative differences, whichever sum 
> is SMALLER.
> 

wilcox.test computes the p-value for you, no need to look up tables.

Torsten

> so i guess my question is: how do i get the T-value
> 
> thanks,
> jan
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From oehl_list at gmx.de  Tue Oct 15 17:13:39 2002
From: oehl_list at gmx.de (oehl_list@gmx.de)
Date: Tue, 15 Oct 2002 17:13:39 +0200 (MEST)
Subject: [R] X-Priority: 3 (Normal)
Message-ID: <12190.1034694819@www23.gmx.net>


# you need to distinguish datatypes 'character' and 'numeric'

bindec <- function(
 b # a CHARACTER representing a binary number
){
as.i <- as.integer(unlist(strsplit(b,"")))
print(as.i)
fl <- 2^(floor(round(log10(as.numeric(b)),10)):0)  # convert b to numeric
print(fl)
dec <- sum(as.i * fl)
dec
}

> bindec("100000")
[1] 1 0 0 0 0 0
[1] 32 16  8  4  2  1
[1] 32

# Best


# Jens Oehlschl?gel

-- 
+++ GMX - Mail, Messaging & more  http://www.gmx.net +++
NEU: Mit GMX ins Internet. Rund um die Uhr f?r 1 ct/ Min. surfen!

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jane.mcferren at lycos.co.uk  Tue Oct 15 17:30:17 2002
From: jane.mcferren at lycos.co.uk (Jane McFerren)
Date: Tue, 15 Oct 2002 17:30:17 +0200 (MEST)
Subject: [R] Plotting two ecdf curves on same axes
Message-ID: <1034695809005911@lycos.co.uk>

Dear R listers

Could somebody please advise me how to draw two empirical cumulative distribution 
functions on the same set of axes?

I know I should be using the ecdf command but I'm not sure what to add to it to force it 
to plot twice on the axes

Thanks
Jane
______________________________________________________
Check out all the latest outrageous email attachments on the Outrageous Email Chart! - http://viral.lycos.co.uk	


From tlumley at u.washington.edu  Tue Oct 15 17:32:05 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 15 Oct 2002 08:32:05 -0700 (PDT)
Subject: [R] glm and Newey-West estimator
In-Reply-To: <5F4F05E2-E031-11D6-9951-000A27D7D440@fowi.ethz.ch>
Message-ID: <Pine.A41.4.44.0210150830000.123024-100000@homer39.u.washington.edu>

On Tue, 15 Oct 2002, Christof Bigler wrote:

> Dear R-users,
>
> has anybody combined the glm function with the Newey-West estimator of
> variance, similar as in Stata 7.0? I'd like to estimate corrected
> standard errors within a logistic regression model, taking into account
> the auto-correlated binary observations within individuals.
> I use R1.5.1 on Mac OS X (10.2).
>
There is code at
  http://faculty.washington.edu/tlumley/weave.html

(as you will see there is also code to do this for Stata 5.0 -- I suspect
I was responsible for Stata realising that the Newey-West estimator works
with glms)

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jg_liao at yahoo.com  Tue Oct 15 18:38:25 2002
From: jg_liao at yahoo.com (Jason Liao)
Date: Tue, 15 Oct 2002 09:38:25 -0700 (PDT)
Subject: [R] case study of efficient R coding
Message-ID: <20021015163825.32174.qmail@web10507.mail.yahoo.com>

The following are four ways I coded for the variance of multinomial
distribution and their CPU time. It is a bit surprising that the 3rd
method beats the 4th one substantially.


 var.multinomial1 = function(n, pi)
+   {
+      p = length(pi);
+      var = array(0, c(p,p));
+      
+      for(i in 1:p)
+        for(j in 1:p)
+        {
+           if(i==j) var[i,j] = n*pi[i]*(1-pi[1])
+   else var[i,j] = - n*pi[i]*pi[j];
+        }
+    }
> 
>    var.multinomial2 = function(n, pi)
+    {
+      n*( -pi%*%t(pi) + diag(pi) )
+    }
>    
>            var.multinomial3 = function(n, pi)
+            {
+               var = -pi%*%t(pi);
+               var[row(var)==col(var)] = pi*(1-pi); 
+               n*var;
+            }
>    
>    var.multinomial4 = function(n, pi)
+            {
+               var = -pi%*%t(pi);
+               var[seq(1, by=(p+1), length=p)] = pi*(1-pi); 
+               n*var;
+            }
>    
>    n = 100;
>    pi = exp( rnorm(10));
>    pi = pi/sum(pi);
>    n.simu = 1000;
>    
>    system.time(for(i in 1:n.simu) var = var.multinomial1(n, pi))
[1]  4.50  0.04 99.73    NA    NA
>     system.time(for(i in 1:n.simu) var = var.multinomial2(n, pi))
[1]  0.33  0.00 10.74    NA    NA
>      system.time(for(i in 1:n.simu) var = var.multinomial3(n, pi))
[1] 0.14 0.00 4.17   NA   NA
>       system.time(for(i in 1:n.simu) var = var.multinomial4(n, pi))
[1] 0.21 0.00 6.47   NA   NA
>    
>      
>    
But first, does anyone know a vectorized way of coding (summing the
outter product of rows)

p = 10;
x = rnorm(p*p);
dim(x) = c(p.p);

var = array(0, c(p,p));
for(i in 1:p) var = var + x[i,]%*% t(x[i,]);

=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-8611, fax (732) 235-9777
http://www.geocities.com/jg_liao

__________________________________________________

Faith Hill - Exclusive Performances, Videos & More

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jyan at stat.wisc.edu  Tue Oct 15 18:41:26 2002
From: jyan at stat.wisc.edu (Jun Yan)
Date: Tue, 15 Oct 2002 11:41:26 -0500 (CDT)
Subject: [R] glm and Newey-West estimator
In-Reply-To: <5F4F05E2-E031-11D6-9951-000A27D7D440@fowi.ethz.ch>
Message-ID: <Pine.LNX.4.21.0210151116150.31111-100000@ludwig.stat.wisc.edu>

On Tue, 15 Oct 2002, Christof Bigler wrote:

> Dear R-users,
> 
> has anybody combined the glm function with the Newey-West estimator of 
> variance, similar as in Stata 7.0? I'd like to estimate corrected 
> standard errors within a logistic regression model, taking into account 
> the auto-correlated binary observations within individuals.
> I use R1.5.1 on Mac OS X (10.2).
> 
> Thanks,
> Christof

Alternatively, you may try package geepack, which can model the ar1
correlation structure within a cluster. I am not sure if this Newey-West
estimator is the same as the "sandwich" variance estimator though. Maybe
someone knows this better can explain.

Jun Yan

Department of Statistics          Office: CSSC 4252
university of Wisconsin-Madison   Tel: (608)262-7478 
1210 W. Dayton St.                Email: jyan at stat.wisc.edu
Madison, WI 53706                 URL: http://www.stat.wisc.edu/~jyan






-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mdsohn at lbl.gov  Tue Oct 15 18:44:43 2002
From: mdsohn at lbl.gov (Michael D. Sohn)
Date: Tue, 15 Oct 2002 09:44:43 -0700
Subject: [R] setting xlim in plot of POSIXlt values
Message-ID: <3DAC45FB.74EE0892@lbl.gov>

I'm plotting values against date:
theX <- paste(theval$Date, theval$Time)
theX <- strptime(theX, format="%m/%d/%Y %H:%M:%S")
plot(theX, theval$Value, type="l", ylim=c(0, 1500))

How do I set the xlimits?  I tried:

plot(theX, theval$Value, type="l", xlim=c(theX[1], theX[100]), ylim=c(0,
1500))

what am I missing?

thanks,
Mike


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rg117 at ohm.york.ac.uk  Tue Oct 15 18:49:07 2002
From: rg117 at ohm.york.ac.uk (Rishabh Gupta)
Date: Tue, 15 Oct 2002 17:49:07 +0100
Subject: [R] normalizing data sets
References: <001301c2739d$702c3400$35892090@ohm.york.ac.uk>
Message-ID: <000e01c2746a$c759c620$35892090@ohm.york.ac.uk>

Hi,
 Thanks for all your replies. You have solved my problem.

Many Thanks

Rishabh
----- Original Message -----
From: "Rishabh Gupta" <rg117 at ohm.york.ac.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, October 14, 2002 5:19 PM
Subject: [R] normalizing data sets


| Hi,
|  Can someone tell me how to normalize a data set so that the mean of the set is 0 and the variance is 1. As I understand, when you
| calculate the principle components of a data set through correlation as
| < princomp( dataset,  cor=T ) >
| then a similar calculation is performed. I would like to know how I can perform such a calulation directly. Any help would be
| greatly appreciated.
|
| Many Thanks
|
| Rishabh
|
| -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
| r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
| Send "info", "help", or "[un]subscribe"
| (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
| _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
|

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 15 18:57:08 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 15 Oct 2002 17:57:08 +0100 (BST)
Subject: [R] R memory 
In-Reply-To: <1034691628.3dac242cc411c@webmail.sapo.pt>
Message-ID: <Pine.LNX.4.31.0210151754150.4702-100000@gannet.stats>

On Tue, 15 Oct 2002, Luis Miguel Almeida da Silva wrote:

> Hello
>
> I was doing PCA (principal component analysis) with a DNA
> expression matrix (7000 rows/38 columns; from golubEsets) but I
> had the following problem
>
> "Error:cannot allocate vector of size 397051 Kb
> In addition: Warning message:
> Reached total allocation of 119Mb: see help(memory.size)"
>
> I've already done some filtering (reduced to 3051 rows) but the
> problem remains, only the size of the vector to allocate is
> smaller.
>
> Can I allocate more memory? How? Probably the problem is also
> from the machine itself, which is a Pentium III 700 Mhz 128Mb
> RAM. Could you help me?

See the rw-FAQ.

What method are you using, though?  prcomp or princomp?  princomp
works on the covariance matrix that is only 38x38, and this seems
perfectly feasible.

>
> Thanks
>
> Luis Silva
>
> --------------------------------------------
> SAPO ADSL.PT Agora o kit apenas por 75 Eur. e trfego ilimitado at ao final de 2002!
> Mais informaes em http://www.sapo.pt/kitadsl
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Tue Oct 15 19:10:20 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 15 Oct 2002 12:10:20 -0500
Subject: [R] absurd computiation times of lme
In-Reply-To: <873cr7948i.fsf@home.nicht-ich.de>
References: <87lm55gnqf.fsf@home.nicht-ich.de> <3DA6D86B.1B82044B@sentoo.sn>
	<87wuooor55.fsf@home.nicht-ich.de>
	<6r1y6w648y.fsf@bates4.stat.wisc.edu>
	<873cr7948i.fsf@home.nicht-ich.de>
Message-ID: <878z0zaarn.fsf@bates5.stat.wisc.edu>

Christof Meigen <christof at nicht-ich.de> writes:

> Hi,
> 
> thanks a lot for all your hints. Alas, some problems remain
> 
> Douglas Bates <bates at stat.wisc.edu> writes:
> > But you are also implicitly estimating the random effects for each
> > child.  These are sometimes regarded as 'nuisance' parameters but they
> > still need to be estimated, at least implicitly.  In this case there
> > would be about 6000 of them (1000 children by 6 random effects per
> > child).
> 
> I'm aware of that, and would not dare to estimate these parameters
> independently per child, since I would be overfitting the data.
> 
> But I thought one could use lme to constain this flexibility by
> using information derived from the rest of the population. If this would
> only mean subtracting the mean curve, I woulnd't need lme, would I:

I don't think I said that it was as simple as subtracting the mean
curve.  Mixed-effects models do perform a type of regularization of
the individual estimates but this is not as simple as subtracting the
mean curve.

> > There is a big difference when fitting random effects between adding
> > parameters in the fixed effects, which are estimated from all the
> > data, and adding parameters in the random effects, which are estimated
> > from the data for one subject.

> Does this really mean that the estimates for the random effects are
> totally independent from the rest of the data? 

Once again, I didn't say the estimates were totally independent from
the rest of the data.  What I was trying to say is that adding
several, possibly correlated, random effects for each subject adds
much more complexity than does adding parameters to the fixed effects.

> So, if my random effect is flexible enough to model more or less any
> curve, this "any" curve will be fitted to the data no matter how
> unlikely it is (looking at the rest of the population) and how
> little data is availiable on this subject?

Modelling with random effects causes some 'shrinkage to the mean'
relative to fitting each subject's data separately.  However, if you
are going to estimate a large number of random effects and their
variances and their covariances you need to have a large amount of
data for each subject and it will take a long time.

> The point is that the inclusion criterium for the children is that
> they have _at least_ measurments in each quarter, but some have
> measurements every month or so. I thought lme would be a good 
> way to deal with this difference in the amount of information available.
> 
> > I would recommend that you start with a spline model for the fixed
> > effects but use either a simple additive shift for the random effects
> > (random = ~1|Subject) or an additive shift and a shift in the time
> > trend (random = ~ age | Subject).  You simply don't have enough data
> > to estimate 6 parameters from the data for each child.
> 
> Bad enough, this is for an PhD (luckily not mine) about growth
> velocity. The medical Prof sees no problem, saying: when you
> have two measurements you have a growth velocity for the timepoint
> right between these measurements. 

> I think this is a bad approach and suggested to smooth the curves
> before. The approach of using (random = ~ age | Subject) or,
> as seen from looking at the log's, better (random = ~ age^0.15 | Subject),
> works as expected, but gives fits which are sometimes as far as
> 3 cm from the real measurements (while the measurement error
> is assumed to be about 0.5cm). These unusual decelerations are
> exactly what the wannabe-PhD is interested in.
> 
> Finally, the argument with the "too little data" does not apply
> to the set-up with with Berkeley Boys, with each one 31 measurements,
> where a 7-parameters spline basis random effect wouldn't converge
> within several hours.

If you have 7 parameters in the random effects and a general
variance-covariance matrix (i.e. symmetric, positive-definite but with
no further constraints on its form) there are seven variances and 21
covariances to estimate.  Optimization is with respect to another
parameterization but it still has dimension 28 in this case.  Roughly
speaking, optimization problems have exponential complexity and it
does not surprise me that this would take a very long time.  You must
ask yourself if you think that the ways in which these growth curves
differ has that great a dimensionality.  In most cases I think it is a
more effective modeling strategy to start with a few random effects
and check residuals to see if the model needs to be made more complex
instead of starting with an overly complex model.

As Peter suggested, if you feel that lme is inadequate for your
purposes we invite you to write better software.



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Tue Oct 15 19:17:27 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Tue, 15 Oct 2002 13:17:27 -0400
Subject: [R] Another newbie question: curve of normal distribution
In-Reply-To: <3DABD2E7.70DC95AF@sentoo.sn>
References: <20021014212046.GA6464@komensky.surfbest.net> <3DABD2E7.70DC95AF@sentoo.sn>
Message-ID: <20021015171727.GA2776@komensky.surfbest.net>

On Tue, Oct 15, 2002 at 08:33:43AM +0000, Renaud Lancelot wrote:
> Hi Matej,
> 
> heads  <- rbinom(n = 100, size = 40, p = .5) ### simulated data
> X <- quantile(heads, probs = seq(.001, .999, length = 1000))
> Y <- dnorm(X, mean = mean(heads), sd = sqrt(var(heads)))
> hist(heads, probability = T)
> lines(X, Y, col = "red")

Thanks, that's exactly what I need -- sorry for not explaining
better.

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
[W]hat country can preserve its liberties, if its rulers are not
warned from time to time that [the] people preserve the spirit of
resistance? Let them take arms...The tree of liberty must be
refreshed from time to time, with the blood of patriots and
tyrants.
    -- Thomas Jefferson, letter to Col. William S. Smith, 1787

-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021015/9c50a1cd/attachment.bin

From Ko-Kang at xtra.co.nz  Tue Oct 15 20:11:43 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Wed, 16 Oct 2002 07:11:43 +1300
Subject: [R] ActiveTcl Version
References: <Pine.LNX.4.31.0210151441400.3016-100000@gannet.stats>
Message-ID: <006401c27476$5254fe60$f42037d2@kwan022>


----- Original Message -----
From: <ripley at stats.ox.ac.uk>
To: "Ko-Kang Kevin Wang" <Ko-Kang at xtra.co.nz>
Cc: "Peter Ho" <peter at esb.ucp.pt>; "R" <R-help at stat.math.ethz.ch>
Sent: Wednesday, October 16, 2002 2:42 AM
Subject: Re: [R] ActiveTcl Version


> But did it work reliably?
>
> I got
>
> 1) Compilation warnings
> 2) Random crashes using 8.4.0.1
>
> and the same happened with the betas of 8.4.  PD is looking into this.

So far it works very stable.  I compiled it on Sunday night (R-patched as at
13th Oct), with 8.4.0.1 (which I think, is the official release version of
ActiveTcl, i.e. not Beta), got no compilation errors/warnings.  I've since
been using it without crashing it once..

Cheers,

Kevin


------------------------------------------------
Ko-Kang Kevin Wang
Post Graduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From reid_huntsinger at merck.com  Tue Oct 15 20:59:14 2002
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Tue, 15 Oct 2002 14:59:14 -0400
Subject: [R] case study of efficient R coding
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC1AF@uswpmx11.merck.com>

t(X)%*%X or better crossprod(X) is the sum of outer products
of the rows of X. The (i,j) entry is the sum of X[k,i]*X[k,j]
over k, i.e., the (i,j) entry of the outer product of X[k, ]
with itself.

Reid Huntsinger

-----Original Message-----
From: Jason Liao [mailto:jg_liao at yahoo.com]
Sent: Tuesday, October 15, 2002 12:38 PM
To: r-help at stat.math.ethz.ch
Subject: [R] case study of efficient R coding


[...]
But first, does anyone know a vectorized way of coding (summing the
outter product of rows)

p = 10;
x = rnorm(p*p);
dim(x) = c(p.p);

var = array(0, c(p,p));
for(i in 1:p) var = var + x[i,]%*% t(x[i,]);

=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-8611, fax (732) 235-9777
http://www.geocities.com/jg_liao

__________________________________________________

Faith Hill - Exclusive Performances, Videos & More

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Tue Oct 15 21:21:43 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Tue, 15 Oct 2002 15:21:43 -0400
Subject: [R] Plotting two ecdf curves on same axes
In-Reply-To: <1034695809005911@lycos.co.uk>
References: <1034695809005911@lycos.co.uk>
Message-ID: <20021015152143.7c4cee2c.fharrell@virginia.edu>

On Tue, 15 Oct 2002 17:30:17 +0200 (MEST)
Jane McFerren <jane.mcferren at lycos.co.uk> wrote:

> Dear R listers
> 
> Could somebody please advise me how to draw two empirical cumulative distribution 
> functions on the same set of axes?
> 
> I know I should be using the ecdf command but I'm not sure what to add to it to force it 
> to plot twice on the axes
> 
> Thanks
> Jane
> ______________________________________________________

One way is

library(Hmisc)
ecdf(~ y, groups=grouping.variable)

You can also produce multiple panels:

ecdf(~ y | state, groups=urban.vs.rural)

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jyan at stat.wisc.edu  Tue Oct 15 22:35:43 2002
From: jyan at stat.wisc.edu (Jun Yan)
Date: Tue, 15 Oct 2002 15:35:43 -0500 (CDT)
Subject: [R] case study of efficient R coding
In-Reply-To: <20021015163825.32174.qmail@web10507.mail.yahoo.com>
Message-ID: <Pine.LNX.4.21.0210151520390.32109-100000@ludwig.stat.wisc.edu>

This is an interesting case study. Method 3 and 4 only differ in how the
indexes are obtained. Method 3 uses seq, which uses the primitive function
c. Method 4 evaluates p^2 logical expression in R. When p is small, method
4 can beat method 3. But as p gets bigger, the time usage by method 3 only
slightly increases, while the time usage by method 4 increasely
dramatically.

test <- function(nsim, p) {
  z1<- system.time(for (i in 1:nsim) seq(1, by=(p+1), length=p))
  mat <- matrix(1, p, p)
  z2 <- system.time(for (i in 1:nsim) row(mat) == col(mat))
  rbind(seq=z1, rowcol=z2)
}

> test(1000, 200)
       [,1] [,2] [,3] [,4] [,5]
seq    0.21    0 0.21    0    0
rowcol 9.16    0 9.16    0    0
> test(1000, 100)
       [,1] [,2] [,3] [,4] [,5]
seq    0.17 0.01 0.19    0    0
rowcol 2.06 0.00 2.05    0    0
> test(1000, 10)
       [,1] [,2] [,3] [,4] [,5]
seq    0.16 0.00 0.16    0    0
rowcol 0.04 0.01 0.05    0    0

On Tue, 15 Oct 2002, Jason Liao wrote:

> The following are four ways I coded for the variance of multinomial
> distribution and their CPU time. It is a bit surprising that the 3rd
> method beats the 4th one substantially.
> 
> 
>  var.multinomial1 = function(n, pi)
> +   {
> +      p = length(pi);
> +      var = array(0, c(p,p));
> +      
> +      for(i in 1:p)
> +        for(j in 1:p)
> +        {
> +           if(i==j) var[i,j] = n*pi[i]*(1-pi[1])
> +   else var[i,j] = - n*pi[i]*pi[j];
> +        }
> +    }
> > 
> >    var.multinomial2 = function(n, pi)
> +    {
> +      n*( -pi%*%t(pi) + diag(pi) )
> +    }
> >    
> >            var.multinomial3 = function(n, pi)
> +            {
> +               var = -pi%*%t(pi);
> +               var[row(var)==col(var)] = pi*(1-pi); 
> +               n*var;
> +            }
> >    
> >    var.multinomial4 = function(n, pi)
> +            {
> +               var = -pi%*%t(pi);
> +               var[seq(1, by=(p+1), length=p)] = pi*(1-pi); 
> +               n*var;
> +            }
> >    
> >    n = 100;
> >    pi = exp( rnorm(10));
> >    pi = pi/sum(pi);
> >    n.simu = 1000;
> >    
> >    system.time(for(i in 1:n.simu) var = var.multinomial1(n, pi))
> [1]  4.50  0.04 99.73    NA    NA
> >     system.time(for(i in 1:n.simu) var = var.multinomial2(n, pi))
> [1]  0.33  0.00 10.74    NA    NA
> >      system.time(for(i in 1:n.simu) var = var.multinomial3(n, pi))
> [1] 0.14 0.00 4.17   NA   NA
> >       system.time(for(i in 1:n.simu) var = var.multinomial4(n, pi))
> [1] 0.21 0.00 6.47   NA   NA
> >    
> >      
> >    
> But first, does anyone know a vectorized way of coding (summing the
> outter product of rows)
> 
> p = 10;
> x = rnorm(p*p);
> dim(x) = c(p.p);
> 
> var = array(0, c(p,p));
> for(i in 1:p) var = var + x[i,]%*% t(x[i,]);
> 
> =====
> Jason G. Liao, Ph.D.
> Division of Biometrics
> University of Medicine and Dentistry of New Jersey
> 335 George Street, Suite 2200
> New Brunswick, NJ 08903-2688
> phone (732) 235-8611, fax (732) 235-9777
> http://www.geocities.com/jg_liao
> 
> __________________________________________________
> 
> Faith Hill - Exclusive Performances, Videos & More
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From csillery at selway.umt.edu  Tue Oct 15 23:00:02 2002
From: csillery at selway.umt.edu (Katalin Csillery)
Date: Tue, 15 Oct 2002 15:00:02 -0600 (MDT)
Subject: No subject
Message-ID: <Pine.OSF.4.21.0210151449160.22736-100000@selway.umt.edu>


Hi,

I have a coding problem. I have data pairs, and I want to calculate a
parameter for the data pairs as a whole data set (so not using the
information that thely are pairs) I am looking for bias in that certain
parameter so I want to bootstrap these data pairs(!), and than calculate
the parameter. I run into a coding problem. How should I define theta in
order to resample the pairs, but than use the ncol=2 matrix as a whole in 
the bootstrap function.
Does anybody have an idea for that?

Thanks, Kati 

_____________________________________________________________________________
Katalin Csillery

Division of Biological Sciences
University of Montana
Missoula MT 59801
Phone: 406 243 6106
E-mail: csillery at selway.umt.edu
_____________________________________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Oct 15 23:34:53 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 15 Oct 2002 14:34:53 -0700 (PDT)
Subject: [R] glm and Newey-West estimator
In-Reply-To: <Pine.LNX.4.21.0210151116150.31111-100000@ludwig.stat.wisc.edu>
Message-ID: <Pine.A41.4.44.0210151428530.123024-100000@homer39.u.washington.edu>

On Tue, 15 Oct 2002, Jun Yan wrote:

> On Tue, 15 Oct 2002, Christof Bigler wrote:
>
> > Dear R-users,
> >
> > has anybody combined the glm function with the Newey-West estimator of
> > variance, similar as in Stata 7.0? I'd like to estimate corrected
> > standard errors within a logistic regression model, taking into account
> > the auto-correlated binary observations within individuals.
> > I use R1.5.1 on Mac OS X (10.2).
> >
> > Thanks,
> > Christof
>
> Alternatively, you may try package geepack, which can model the ar1
> correlation structure within a cluster. I am not sure if this Newey-West
> estimator is the same as the "sandwich" variance estimator though. Maybe
> someone knows this better can explain.
>

It's not the same, though it's a similar idea.  The gee version of
sandwich estimator uses the fact that observations on different clusters
are independent to get a variance estimator.

In time series there aren't any fully independent replicates, and
using the same formula as for longitudinal data will give 0 for your
standard errors. Roughly speaking, the Newey-West estimator involves
chopping the time series into pieces long enough to be approximately
independent and then treating them as clusters.  In fact it's more elegant
than that, but that gives a fairly accurate heuristic idea.

	-thomas




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rdarnell at shrs.uq.edu.au  Wed Oct 16 02:48:11 2002
From: rdarnell at shrs.uq.edu.au (Ross Darnell)
Date: 16 Oct 2002 10:48:11 +1000
Subject: [R] lme and singularities
Message-ID: <hefn9pkk.fsf@shrs.uq.edu.au>



I am trying to use lme to fit a model with one between subjects factor
"A", in a repeated measures design.

I keep getting 

Error in MEEM(object, conLin, control$niterEM) : 
	Singularity in backsolve at level 0, block 1

There are no obserations in one level of factor A at the last
time. The table of counts are

             Time
            1  2  3  6
A  1       15 14 15 15
   2       20 17 17  0
   3       28 26 26 27
   4       29 26 28 29

and there is only one observation per subject per time.

I can fit a fixed terms model (ignoring subjects) using lm.

I thought that I should be able to estimate all bar one parameter in
this model.

Any enlightenments would be appreciated.

Ross Darnell

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bfbraum at fas.harvard.edu  Wed Oct 16 03:10:32 2002
From: bfbraum at fas.harvard.edu (Bear F. Braumoeller)
Date: Tue, 15 Oct 2002 21:10:32 -0400 (EDT)
Subject: [R] Seeking compiled OS X "contrib" packages
Message-ID: <Pine.OSF.4.44.0210152050590.2832-100000@is08.fas.harvard.edu>

Does anyone out there have a complete set of compiled packages (libraries)
in the "contributed" category (i.e. not base or recommended) for a
Macintosh running OS X?  How about a relatively complete set?

I am running the precompiled version of R 1.6.0 written by Stefano Iacus
(Stefano, if you're reading this, it's terrific).  The only problem is
that there's no facility for importing and processing new packages.  I
downloaded the "how to download and build your own additional packages"
file that Stefano wrote.  I downloaded MPW and MacPerl, as well as all of
the ancillary files, and after some trial and error got everything
running.  I then spent seven solid hours trying to get it to build even a
single package.  No dice.  I kept getting errors of one kind or another
(my R 1.6 came with no "share" directory, so I copied the one from 1.5.1;
Perl needed a handful of files copied into the working directory, so I did
so; and so forth).

Finally, I got it to produce a sample library (bootstrap) that looked like
it should work, right down to the "built" line in the doc file.  Not a
single error.  Unfortunately, R still does not recognize it as a
legitimate library/package, and I can't for the life of me figure out why.

I know I'm not a programmer (for one thing, they get paid better than I
do), and I know that I will be roundly derided as a wimp for writing this,
but I give up.  Has anyone out there accomplished this feat (or imported
the contrib packages via the XWindows version), and if so, would you be
willing to end my suffering?  I have seen some posted online, but as luck
would have it they don't overlap much with the ones I'm interested in.
I'd rather try to get them all in one fell swoop.

Thanks,
-Bear

Bear F. Braumoeller
Assistant Professor
Department of Government
Harvard University


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wss at ufla.br  Wed Oct 16 05:01:10 2002
From: wss at ufla.br (Washington Santos Silva)
Date: Wed, 16 Oct 2002 00:01:10 -0300
Subject: [R] StructTS basic question (Without html-ification, I hope!)
Message-ID: <00a101c274c0$60827360$abfa83c8@x>

Dear list
 
I would like to use the StructTS function in the ts library to fit the '
BSM ' model.
I have some, probably basics, questions about the model and about the
function(s):

1) How can I check the statistical significance of the estimated
parameters(variances)?

2) Is there some way to find what component "dominate" the series?

3) Is there a function to produce out-of-sample forecasts from this
model?

Thanks a lot for any help.

Washington S. Silva

OS: Windows 98
R: 1.5.1




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Wed Oct 16 07:09:35 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Tue, 15 Oct 2002 22:09:35 -0700
Subject: [R] Seeking compiled OS X "contrib" packages
In-Reply-To: <Pine.OSF.4.44.0210152050590.2832-100000@is08.fas.harvard.edu>
Message-ID: <76B4F1C6-E0C5-11D6-9F48-000393860F3C@stat.ucla.edu>

The version at ftp://gifi.stat.ucla.edu/pub comes with 240 compiled
packages. But it is the X11/Darwin version, not the Carbon one
with the nice interface. Although it does have gnome support
again.

On Tuesday, October 15, 2002, at 06:10 PM, Bear F. Braumoeller wrote:

> Does anyone out there have a complete set of compiled packages  
> (libraries)
> in the "contributed" category (i.e. not base or recommended) for a
> Macintosh running OS X?  How about a relatively complete set?
>
> I am running the precompiled version of R 1.6.0 written by Stefano  
> Iacus
> (Stefano, if you're reading this, it's terrific).  The only problem is
> that there's no facility for importing and processing new packages.  I
> downloaded the "how to download and build your own additional packages"
> file that Stefano wrote.  I downloaded MPW and MacPerl, as well as all  
> of
> the ancillary files, and after some trial and error got everything
> running.  I then spent seven solid hours trying to get it to build  
> even a
> single package.  No dice.  I kept getting errors of one kind or another
> (my R 1.6 came with no "share" directory, so I copied the one from  
> 1.5.1;
> Perl needed a handful of files copied into the working directory, so I  
> did
> so; and so forth).
>
> Finally, I got it to produce a sample library (bootstrap) that looked  
> like
> it should work, right down to the "built" line in the doc file.  Not a
> single error.  Unfortunately, R still does not recognize it as a
> legitimate library/package, and I can't for the life of me figure out  
> why.
>
> I know I'm not a programmer (for one thing, they get paid better than I
> do), and I know that I will be roundly derided as a wimp for writing  
> this,
> but I give up.  Has anyone out there accomplished this feat (or  
> imported
> the contrib packages via the XWindows version), and if so, would you be
> willing to end my suffering?  I have seen some posted online, but as  
> luck
> would have it they don't overlap much with the ones I'm interested in.
> I'd rather try to get them all in one fell swoop.
>
> Thanks,
> -Bear
>
> Bear F. Braumoeller
> Assistant Professor
> Department of Government
> Harvard University
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fredrik.karlsson at ling.umu.se  Wed Oct 16 07:11:09 2002
From: fredrik.karlsson at ling.umu.se (Fredrik Karlsson)
Date: Wed, 16 Oct 2002 07:11:09 +0200
Subject: [R] Database newbee problem...
Message-ID: <20021016051109.GA25176@ling.umu.se>

Hi all,


This is a potentially very stupid question about MySQL <-> R
interaction, but I have not been able to solve it.
I'm just trying to connect R to my MySQL databse, and gets this:

> library(RMySQL)
Loading required package: methods 
> m <- dbDriver("MySQL")
> con <- dbConnect(m,group="testdb")

Process R segmentation fault at Wed Oct 16 07:04:30 2002

My .my.conf contains this:

[client]
user = zak
host = localhost
password=<something>

[rs-dbi]
database = sdata

[testdb]
host = localhost
database = testDB

and connecting through the mysql client is no problem using those
settings:

$ mysql 
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 34 to server version: 3.23.49-log

Type 'help;' or '\h' for help. Type '\c' to clear the buffer.

mysql> use testDB
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql> show tables;

+------------------+
| Tables_in_testDB |
+------------------+
| pet              |
+------------------+
1 row in set (0.00 sec)

mysql>


What's wrong with my setup that's causing R to segfault (but not mysql
client)?
Any ideas?

/Fredrik
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct 16 11:42:48 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 16 Oct 2002 10:42:48 +0100 (GMT Daylight Time)
Subject: [R] Database newbee problem...
In-Reply-To: <20021016051109.GA25176@ling.umu.se>
Message-ID: <Pine.WNT.4.44.0210161036580.2256-100000@gannet.stats.ox.ac.uk>

It's very hard to debug someone else's machine, not least when you haven't
even told us the OS you are using.  In general you need to get a symbolic
debugger (e.g. gdb) into use to investigate this sort of problem.

However, a version mismatch between the RMySQL compilation and the MySQL
installation has caused this for me.  Looks like the MySQL shared libraries
are not always compatible when their version numbers suggest they should
be, and after a MySQL upgrade I needed to reinstall RMySQL.

On Wed, 16 Oct 2002, Fredrik Karlsson wrote:

> Hi all,
>
>
> This is a potentially very stupid question about MySQL <-> R
> interaction, but I have not been able to solve it.
> I'm just trying to connect R to my MySQL databse, and gets this:
>
> > library(RMySQL)
> Loading required package: methods
> > m <- dbDriver("MySQL")
> > con <- dbConnect(m,group="testdb")
>
> Process R segmentation fault at Wed Oct 16 07:04:30 2002
>
> My .my.conf contains this:
>
> [client]
> user = zak
> host = localhost
> password=<something>
>
> [rs-dbi]
> database = sdata
>
> [testdb]
> host = localhost
> database = testDB
>
> and connecting through the mysql client is no problem using those
> settings:
>
> $ mysql
> Welcome to the MySQL monitor.  Commands end with ; or \g.
> Your MySQL connection id is 34 to server version: 3.23.49-log
>
> Type 'help;' or '\h' for help. Type '\c' to clear the buffer.
>
> mysql> use testDB
> Reading table information for completion of table and column names
> You can turn off this feature to get a quicker startup with -A
>
> Database changed
> mysql> show tables;
>
> +------------------+
> | Tables_in_testDB |
> +------------------+
> | pet              |
> +------------------+
> 1 row in set (0.00 sec)
>
> mysql>
>
>
> What's wrong with my setup that's causing R to segfault (but not mysql
> client)?
> Any ideas?
>
> /Fredrik
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pwolf at wiwi.uni-bielefeld.de  Wed Oct 16 11:55:20 2002
From: pwolf at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Wed, 16 Oct 2002 11:55:20 +0200
Subject: [R] log10(), floor() combo issue / APL-encode, APL-decode, chcode
Message-ID: <3DAD3787.87C527C9@wiwi.uni-bielefeld.de>

D. Steuer wrote:

> On 14-Oct-2002 E.L. Willighagen wrote:
>>
>> Hi all,
>>
>> in my search for a nice binary2decimal method, I received this nice
>> code (thanx to Uwe Ligges):
>>
>>  bindec <- function(b)
>>    sum(as.integer(unlist(strsplit(b, ""))) * 2^(floor(log10(b)):0))
>
> Nice function!

Some years ago we used the nice APL-functions "decode" and "encode"
for such a job.There are a lot situations for using them, for example
to change the representation of a number.

For details, have a look at: http://www.acm.org/sigapl/encode.htm

Here are two simple R-Versions:

decode <- function(b, base) {
   # simple version of APL-decode / APL-base "_|_", pw10/02
   # "decode" converts "b" using the increments "base"
   b <- as.integer(b)
   if( length(base) == 1 ) base<-rep(base,length(b))
   base<-c(base,1)
   number<-as.vector( cumprod(rev(base)[ 1:length(b) ] ) %*% rev(b) )
   number
}

encode <- function(number, base) {
   # simple version of APL-encode / APL-representation "T", pw 10/02
   # "encode" converts the numbers "number" using the radix vector
"base"
   n.base <- length(base); result <- matrix(0, length(base),
length(number))
   for(i in n.base:1){
     result[i,] <- if(base[i]>0) number %% base[i] else number
     number     <- ifelse(rep(base[i]>0,length(number)),
                          floor(number/base[i]), 0)
   }
   return( if(length(number)==1) result[,1] else result )
}

For changing the number system ( bin to hex ) the function "chcode" may
help:

chcode <- function(b, base.in=2, base.out=10,
digits="0123456789ABCDEF"){
   # change of number systems, pw 10/02
   # e.g.: from 2 2 2 2 ...  ->  16 16 16 ...
   digits<-substring(digits,1:nchar(digits),1:nchar(digits))
   if(length(base.in)==1) base.in <- rep(base.in, max(nchar(b)-1))
   if(is.numeric(b)) b <- as.character(as.integer(b))
   b.num <- lapply(strsplit(b,""), function(x) match(x,digits)-1  )
   result <- lapply(b.num, function(x){
                cumprod(rev(c(base.in,1))[ 1:length(x) ] ) %*% rev(x)
             } )
   number<-unlist(result)
   cat("decimal representation:",number,"\n")
   if(length(base.out)==1){
      base.out<-rep(base.out,1+ceiling(log( max(number), base=base.out )
) )
   }
   n.base <- length(base.out); result <- NULL
   for(i in n.base:1){
     result <- rbind(number %% base.out[i], result)
     number <- floor(number/base.out[i])
   }
   result[]<-digits[result+1]
   apply(result, 2, paste, collapse="")
}

any comments for improvements?

Peter


--------------------------------------------------
Some examples:

> chcode(c("1000","1100","2000"),2,16)
decimal representation: 8 12 16
[1] "08" "0C" "10"
> chcode(c("08","0C","10"),16,2)
decimal representation: 8 12 16
[1] "01000" "01100" "10000"

> print(encode(c(15, 31, 32, 33, 75), c(16, 16, 16,16)))
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    0
[2,]    0    0    0    0    0
[3,]    0    1    2    2    4
[4,]   15   15    0    1   11
> print(encode(c(15, 31, 32, 33, 75), c(4, 4, 4, 4)))
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    1
[2,]    0    1    2    2    0
[3,]    3    3    0    0    2
[4,]    3    3    0    1    3
> print(encode(c(13), c(2, 2, 2, 2)))
[1] 1 1 0 1
> print(encode(c(62), c(16, 16, 16)))
[1]  0  3 14

> print(decode(c(1, 1, 1, 1), c(2, 2, 2, 2)))
[1] 15
# Convert 2 days, 3 hours, 5 minutes, and 27 seconds to seconds
> print(decode(c(2, 3, 5, 27), c(0, 24, 60, 60)))
[1] 183927


---------------------------------------------
Dr. Peter Wolf
Dept. of Economics
University of Bielefeld
pwolf at wiwi.uni-bielefeld.de

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From petr.pikal at precheza.cz  Wed Oct 16 12:14:05 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 16 Oct 2002 12:14:05 +0200
Subject: [R] peaks
In-Reply-To: <3.0.32.20021015180933.00b136a0@hermes.eawag.ch>
Message-ID: <3DAD580D.19903.1000EE5@localhost>



On 15 Oct 2002 at 18:09, Rieckermann Joerg wrote:

> Dear Petr,
> 
> I have been fooling around with this peaks function of yours/Ripley
> and don't seem to get the main idea.
> 
> What I intend to do is locate the peaks in a vector and later use thes
> values. So the position of the peaks would be of great interest.
> 
> My questions:
> * Why does peak retunr a smaller vector?
it gives you a shorter vector due to span value. The greater the span value the 
shorter resulting vector.

> * How can I correct for it to correctly locate the peaks?

use odd numbers for span - 3,5,7....

x<-c(1:44,103,46:75,103,77:100)
> x.t<-peaks(x,21)
> seq(along=x)[x.t]
[1] 45 76
> x[x.t]
[1] 103 103

> x.t<-peaks(x,20)
> seq(along=x)[x.t]
[1] 46 77
> x[x.t]
[1] 46 77

if you use bigger span numbers you can get rid of some peaks which are near one 
to another eg select only "important" peaks. However you can miss some peaks, 
especially near the ends of your vector.

> 
> > x<-c(1:44,103,46:75,103,77:100)
> > peaks<-function(series,span=3)
> + {
> + z <- embed(series, span)
> + s <- span%/%2
> + v<- max.col(z) == 1 + s
> + result <- c(rep(FALSE,s),v)
> + result <- result[1:(length(result)-s)]
> + result
> + }
> > t<-peaks(x,20)
> > t
>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> FALSE FALSE [14] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> FALSE FALSE FALSE FALSE [27] FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> FALSE FALSE FALSE FALSE FALSE FALSE [40] FALSE FALSE FALSE FALSE FALSE
> FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE [53] FALSE FALSE FALSE
> FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [66] FALSE
> FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE
> [79] FALSE FALSE FALSE
> 
> > length(t)
> [1] 81
> > length(x)
> [1] 100
> > which(x>100)	#peak position in x
> [1] 45 76
> > which(t==T)		#peak position i get from 'peaks'
> [1] 46 77
> 
> I would be grateful for any hint.
> 
> Best regards, 
> Joerg
> 
> 
> 
Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nolwenn.lemeur at nantes.inserm.fr  Wed Oct 16 14:40:07 2002
From: nolwenn.lemeur at nantes.inserm.fr (Nolwenn Le Meur)
Date: Wed, 16 Oct 2002 14:40:07 +0200
Subject: [R] CGI and RSPerl
Message-ID: <LMEBLNBEKKODLAONNGJMCEIACAAA.nolwenn.lemeur@nantes.inserm.fr>

Hi,

Does anybody try to write CGI script using RSPerl package ?

I am interested in RWeb but that doesn't really do what I want.
In fact I would like the user to load the file to analyze; then a R program
will treat the data ,display resulting graphs and save results in text
files.
I have test the following script by John Barnett without success.

#!/usr/lib/R/bin/R.bin --source
invisible(library(RSPerl));
foo <- .PerlExpr("use CGI;");
foo <- .PerlExpr("$q = new CGI; 1;");
a <- .PerlExpr("$q->param('a')");
cat(.PerlExpr("$q->header . $q->start_html . 'Hellooooo....';"),
    a,
    .PerlExpr("$q->end_html"));

I get the error:

premature end of script headers : /var/www/cgi-bin/test.cgi

Thanks to help,

Nolwenn

********************************************
Nolwenn Le Meur
INSERM U533
Facult? de m?decine
1, rue Gaston Veil
44035 Nantes Cedex 1
France

Tel: (+33)-2-40-41-29-86 (office)
     (+33)-2-40-41-28-44 (secretary)
Fax: (+33)-2-40-41-29-50
mail: nolwenn.lemeur at nantes.inserm.fr
********************************************

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From christof at nicht-ich.de  Wed Oct 16 16:11:54 2002
From: christof at nicht-ich.de (Christof Meigen)
Date: 16 Oct 2002 16:11:54 +0200
Subject: [R] absurd computiation times of lme
In-Reply-To: <878z0zaarn.fsf@bates5.stat.wisc.edu>
References: <87lm55gnqf.fsf@home.nicht-ich.de> <3DA6D86B.1B82044B@sentoo.sn>
	<87wuooor55.fsf@home.nicht-ich.de>
	<6r1y6w648y.fsf@bates4.stat.wisc.edu>
	<873cr7948i.fsf@home.nicht-ich.de>
	<878z0zaarn.fsf@bates5.stat.wisc.edu>
Message-ID: <87ptuascb9.fsf@home.nicht-ich.de>


Douglas Bates <bates at stat.wisc.edu> writes:
> You must
> ask yourself if you think that the ways in which these growth curves
> differ has that great a dimensionality.  In most cases I think it is a
> more effective modeling strategy to start with a few random effects
> and check residuals to see if the model needs to be made more complex
> instead of starting with an overly complex model.

I discussed that with Jim Ramsay, and he strongly discouraged me 
to "guess a reasonable, low dimensional basis", using either
known models for growth curves or something like PCA.

His argument was, that, in the first case, I put too much a priori
assumtions into the model, and in the other, that I use results
from the data to analyze the data, which would be some kind of
statistical "deadly sin".

He suggested, and that seemed plausible to me, to use indeed a
much too complex/flexible model like a quite high-dimensional
spline basis, and use lme to constrain that flexibility.

It seems to turn out that lme is not really made for this ...

> As Peter suggested, if you feel that lme is inadequate for your
> purposes we invite you to write better software.

...which does not mean I'd dare to say that I could write "better"
software, I had a look at the code when I was trying to write
a band-structured pdMat, and I'm really impressed ...

        Christof
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bfbraum at fas.harvard.edu  Wed Oct 16 16:57:09 2002
From: bfbraum at fas.harvard.edu (Bear F. Braumoeller)
Date: Wed, 16 Oct 2002 10:57:09 -0400
Subject: [R] Seeking compiled OS X "contrib" packages
In-Reply-To: <76B4F1C6-E0C5-11D6-9F48-000393860F3C@stat.ucla.edu>
Message-ID: <8B37BB45-E117-11D6-9861-003065F6CEFA@fas.harvard.edu>

I don't mind X11; XDarwin is up and running on my computer, but I  
finally gave up on installing R v1.5.1 for XWindows bc. I couldn't get  
it to run (someone wrote in about problems with the installer and  
symbolic links, or sthg., which I suspect is what was giving me grief).  
  So I went to the Carbon version.

The compiled packages are GREAT, thanks!  One more question: any idea  
why a significant percentage (say half) return e.g.

 > library(cobs)
Error in library.dynam("cobs", pkg, lib) :
	dynamic library `cobs' not found
Error in library(cobs) : .First.lib failed

while the others don't?  Is this due to an X11/Carbon difference?   
They're both 1.6.0.

Thanks,
-Bear

On Wednesday, October 16, 2002, at 01:09  AM, Jan de Leeuw wrote:

> The version at ftp://gifi.stat.ucla.edu/pub comes with 240 compiled
> packages. But it is the X11/Darwin version, not the Carbon one
> with the nice interface. Although it does have gnome support
> again.
>
> On Tuesday, October 15, 2002, at 06:10 PM, Bear F. Braumoeller wrote:
>
>> Does anyone out there have a complete set of compiled packages  
>> (libraries)
>> in the "contributed" category (i.e. not base or recommended) for a
>> Macintosh running OS X?  How about a relatively complete set?
>>
>> I am running the precompiled version of R 1.6.0 written by Stefano  
>> Iacus
>> (Stefano, if you're reading this, it's terrific).  The only problem is
>> that there's no facility for importing and processing new packages.  I
>> downloaded the "how to download and build your own additional  
>> packages"
>> file that Stefano wrote.  I downloaded MPW and MacPerl, as well as  
>> all of
>> the ancillary files, and after some trial and error got everything
>> running.  I then spent seven solid hours trying to get it to build  
>> even a
>> single package.  No dice.  I kept getting errors of one kind or  
>> another
>> (my R 1.6 came with no "share" directory, so I copied the one from  
>> 1.5.1;
>> Perl needed a handful of files copied into the working directory, so  
>> I did
>> so; and so forth).
>>
>> Finally, I got it to produce a sample library (bootstrap) that looked  
>> like
>> it should work, right down to the "built" line in the doc file.  Not a
>> single error.  Unfortunately, R still does not recognize it as a
>> legitimate library/package, and I can't for the life of me figure out  
>> why.
>>
>> I know I'm not a programmer (for one thing, they get paid better than  
>> I
>> do), and I know that I will be roundly derided as a wimp for writing  
>> this,
>> but I give up.  Has anyone out there accomplished this feat (or  
>> imported
>> the contrib packages via the XWindows version), and if so, would you  
>> be
>> willing to end my suffering?  I have seen some posted online, but as  
>> luck
>> would have it they don't overlap much with the ones I'm interested in.
>> I'd rather try to get them all in one fell swoop.
>>
>> Thanks,
>> -Bear
>>
>> Bear F. Braumoeller
>> Assistant Professor
>> Department of Government
>> Harvard University
>>
>>
>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
>> .-.-.-.-.-
>> r-help mailing list -- Read  
>> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To:  
>> r-help-request at stat.math.ethz.ch
>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._. 
>> _._._._._
>>
>>
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical  
> Software
> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email:  
> deleeuw at stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>   
> ----------------------------------------------------------------------- 
> --------------------------
>           No matter where you go, there you are. --- Buckaroo Banzai
>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
>   
> ----------------------------------------------------------------------- 
> --------------------------
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>


Bear F. Braumoeller
Assistant Professor
Department of Government
Harvard University

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Wed Oct 16 17:18:19 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Wed, 16 Oct 2002 08:18:19 -0700
Subject: [R] Seeking compiled OS X "contrib" packages
In-Reply-To: <8B37BB45-E117-11D6-9861-003065F6CEFA@fas.harvard.edu>
Message-ID: <804929FA-E11A-11D6-A9D8-000393860F3C@stat.ucla.edu>

What's "cobs", for example ? I think you cannot run the packages which  
dynamically
load C code from my Darwin/X11 version with your Carbon loader.

On Wednesday, October 16, 2002, at 07:57 AM, Bear F. Braumoeller wrote:

> I don't mind X11; XDarwin is up and running on my computer, but I  
> finally gave up on installing R v1.5.1 for XWindows bc. I couldn't get  
> it to run (someone wrote in about problems with the installer and  
> symbolic links, or sthg., which I suspect is what was giving me  
> grief).  So I went to the Carbon version.
>
> The compiled packages are GREAT, thanks!  One more question: any idea  
> why a significant percentage (say half) return e.g.
>
> > library(cobs)
> Error in library.dynam("cobs", pkg, lib) :
> 	dynamic library `cobs' not found
> Error in library(cobs) : .First.lib failed
>
> while the others don't?  Is this due to an X11/Carbon difference?   
> They're both 1.6.0.
>
> Thanks,
> -Bear
>
> On Wednesday, October 16, 2002, at 01:09  AM, Jan de Leeuw wrote:
>
>> The version at ftp://gifi.stat.ucla.edu/pub comes with 240 compiled
>> packages. But it is the X11/Darwin version, not the Carbon one
>> with the nice interface. Although it does have gnome support
>> again.
>>
>> On Tuesday, October 15, 2002, at 06:10 PM, Bear F. Braumoeller wrote:
>>
>>> Does anyone out there have a complete set of compiled packages  
>>> (libraries)
>>> in the "contributed" category (i.e. not base or recommended) for a
>>> Macintosh running OS X?  How about a relatively complete set?
>>>
>>> I am running the precompiled version of R 1.6.0 written by Stefano  
>>> Iacus
>>> (Stefano, if you're reading this, it's terrific).  The only problem  
>>> is
>>> that there's no facility for importing and processing new packages.   
>>> I
>>> downloaded the "how to download and build your own additional  
>>> packages"
>>> file that Stefano wrote.  I downloaded MPW and MacPerl, as well as  
>>> all of
>>> the ancillary files, and after some trial and error got everything
>>> running.  I then spent seven solid hours trying to get it to build  
>>> even a
>>> single package.  No dice.  I kept getting errors of one kind or  
>>> another
>>> (my R 1.6 came with no "share" directory, so I copied the one from  
>>> 1.5.1;
>>> Perl needed a handful of files copied into the working directory, so  
>>> I did
>>> so; and so forth).
>>>
>>> Finally, I got it to produce a sample library (bootstrap) that  
>>> looked like
>>> it should work, right down to the "built" line in the doc file.  Not  
>>> a
>>> single error.  Unfortunately, R still does not recognize it as a
>>> legitimate library/package, and I can't for the life of me figure  
>>> out why.
>>>
>>> I know I'm not a programmer (for one thing, they get paid better  
>>> than I
>>> do), and I know that I will be roundly derided as a wimp for writing  
>>> this,
>>> but I give up.  Has anyone out there accomplished this feat (or  
>>> imported
>>> the contrib packages via the XWindows version), and if so, would you  
>>> be
>>> willing to end my suffering?  I have seen some posted online, but as  
>>> luck
>>> would have it they don't overlap much with the ones I'm interested  
>>> in.
>>> I'd rather try to get them all in one fell swoop.
>>>
>>> Thanks,
>>> -Bear
>>>
>>> Bear F. Braumoeller
>>> Assistant Professor
>>> Department of Government
>>> Harvard University
>>>
>>>
>>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
>>> .-.-.-.-.-.-
>>> r-help mailing list -- Read  
>>> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>>> Send "info", "help", or "[un]subscribe"
>>> (in the "body", not the subject !)  To:  
>>> r-help-request at stat.math.ethz.ch
>>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
>>> ._._._._._
>>>
>>>
>> ===
>> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
>> Editor: Journal of Multivariate Analysis, Journal of Statistical  
>> Software
>> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
>> phone (310)-825-9550;  fax (310)-206-5658;  email:  
>> deleeuw at stat.ucla.edu
>> homepage: http://gifi.stat.ucla.edu
>>   
>> ---------------------------------------------------------------------- 
>> ---------------------------
>>           No matter where you go, there you are. --- Buckaroo Banzai
>>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
>>   
>> ---------------------------------------------------------------------- 
>> ---------------------------
>>
>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
>> .-.-.-.-.-
>> r-help mailing list -- Read  
>> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To:  
>> r-help-request at stat.math.ethz.ch
>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._. 
>> _._._._._
>>
>>
>
>
> Bear F. Braumoeller
> Assistant Professor
> Department of Government
> Harvard University
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From juan at ipimar.pt  Wed Oct 16 18:47:00 2002
From: juan at ipimar.pt (Juan Zwolinski)
Date: Wed, 16 Oct 2002 17:47:00 +0100
Subject: [R] Ordinary and simple kriging
Message-ID: <3DAD9804.2E3DF6E2@ipimar.pt>

I'm performing ordinary and simple kriging from a set of non-negative
values:

	 
>krige.control.sk<-krige.control(type.krige="sk",obj.model=my.variogram.model,beta=my.variogram.model$beta)

>sk<-krige.conv(cadiz.geo,data=amostragem.cadiz$dia1.std,locations=as.matrix(cadiz.polygrid[,c(1,2)]),krige=krige.control.sk)
krige.conv: model with constant mean
krige.conv: Kriging performed using global neighbourhood

and

>krige.control.ok<-krige.control(type.krige="ok",obj.model=my.variogram.model)

>ok<-krige.conv(cadiz.geo,data=amostragem.cadiz$dia1.std,locations=as.matrix(cadiz.polygrid[,c(1,2)]),krige=krige.control.ok)
krige.conv: model with constant mean
krige.conv: Kriging performed using global neighbourhood

where my.variogram.model is gaussian fitted through variofit with
"cressie" weigths.

I'm getting the same predicted values for both models, 12%  of them
being negative. Is it because simple and ordinary kriging predictions
are not including the overall mean? If this is the case what mean should
I use?
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From juan at ipimar.pt  Wed Oct 16 19:48:14 2002
From: juan at ipimar.pt (Juan Zwolinski)
Date: Wed, 16 Oct 2002 18:48:14 +0100
Subject: [R] [Fwd: Ordinary and simple kriging]
Message-ID: <3DADA65E.4B7BFC65@ipimar.pt>

Juan Zwolinski wrote:
> 
> I'm performing ordinary and simple kriging from a set of non-negative
> values:
> 
> 
> >krige.control.sk<-krige.control(type.krige="sk",obj.model=my.variogram.model,beta=my.variogram.model$beta)
> 
> >sk<-krige.conv(cadiz.geo,data=amostragem.cadiz$dia1.std,locations=as.matrix(cadiz.polygrid[,c(1,2)]),krige=krige.control.sk)
> krige.conv: model with constant mean
> krige.conv: Kriging performed using global neighbourhood
> 
> and
> 
> >krige.control.ok<-krige.control(type.krige="ok",obj.model=my.variogram.model)
> 
> >ok<-krige.conv(cadiz.geo,data=amostragem.cadiz$dia1.std,locations=as.matrix(cadiz.polygrid[,c(1,2)]),krige=krige.control.ok)
> krige.conv: model with constant mean
> krige.conv: Kriging performed using global neighbourhood
> 
> where my.variogram.model is gaussian fitted through variofit with
> "cressie" weigths.
> 
> I'm getting the same predicted values for both models, 12%  of them
> being negative. Is it because simple and ordinary kriging predictions
> are not including the overall mean? If this is the case what mean should
> I use?

Thank you for your help
Juan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rjvbertin at hotmail.com  Wed Oct 16 20:10:23 2002
From: rjvbertin at hotmail.com (RenE J.V. Bertin)
Date: Wed, 16 Oct 2002 20:10:23 +0200
Subject: [R] performance issues: gcc 2.95.3 vs. gcc 3.2.0
Message-ID: <20021016201023.2d06880e.rjvbertin@hotmail.com>

Hello,

I recently installed gcc 3.2.0 next to my old gcc 2.95.3 . I understood that this should give me some performance gain. I indeed found some, but in a few cases I actually observed a considerable loss in performance. I would be interested to learn if others have similar experiences, and what the general opinion is concerning what version (and flags) to use for R!

1) gcc 3.2.0 -O3 can be much slower than gcc 3.2.0 -O2, causing a collection of simple
tests to take over 50s instead of under 20s. This is due to -finline-functions!!

2) I have my own graphing/analysis programme that contains an expression language with a
byte compiler (i.e. the parser constructs a call graph with the callback function pointers,
memory for arguments and other relevant information). Again, I mostly find small performance
gains, but also 1 particular construct (calling a procedure via the 'call' routine) that
is almost 10x slower with gcc 3.2.0 than with gcc 2.95.3 . (I don't understand why it is so
fast with 2.95.3 but that's another issue :)). No influence of -finline-functions here.
I imagine that this could be an issue for R too!

R.B.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Wed Oct 16 20:13:48 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 16 Oct 2002 11:13:48 -0700 (PDT)
Subject: [R] Bootstrapping pairs (was Re: [none])
In-Reply-To: <Pine.OSF.4.21.0210151449160.22736-100000@selway.umt.edu>
Message-ID: <Pine.GSO.4.10.10210161109350.14856-100000@fisher.stat.ucla.edu>

I think you can use the 'boot' library for this kind of problem.  Suppose
a had a matrix called 'data' which is n x 2 and I want to bootstrap a
statistic (called 'my.statistic') which operates on the entire matrix.

boot.func <- function(x, i) { my.statistic(x[i,]) }
b <- boot(data, boot.func, R = 1000)

The object 'b' contains the bootstrapped values of your statistic
(obtained by resampling rows of the matrix, which in this case is
resampling pairs).

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Tue, 15 Oct 2002, Katalin  Csillery wrote:

> 
> Hi,
> 
> I have a coding problem. I have data pairs, and I want to calculate a
> parameter for the data pairs as a whole data set (so not using the
> information that thely are pairs) I am looking for bias in that certain
> parameter so I want to bootstrap these data pairs(!), and than calculate
> the parameter. I run into a coding problem. How should I define theta in
> order to resample the pairs, but than use the ncol=2 matrix as a whole in 
> the bootstrap function.
> Does anybody have an idea for that?
> 
> Thanks, Kati 
> 
> _____________________________________________________________________________
> Katalin Csillery
> 
> Division of Biological Sciences
> University of Montana
> Missoula MT 59801
> Phone: 406 243 6106
> E-mail: csillery at selway.umt.edu
> _____________________________________________________________________________
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tkeitt at mail.utexas.edu  Wed Oct 16 22:46:10 2002
From: tkeitt at mail.utexas.edu (Timothy H. Keitt)
Date: 16 Oct 2002 13:46:10 -0700
Subject: [R] performance issues: gcc 2.95.3 vs. gcc 3.2.0
In-Reply-To: <20021016201023.2d06880e.rjvbertin@hotmail.com>
References: <20021016201023.2d06880e.rjvbertin@hotmail.com>
Message-ID: <1034801172.1247.40.camel@peregrine>

Benchmarking is of course a tricky business. One thought -- some
optimizations will increase code size and might bump a given loop out of
the on-chip or secondary cache. You'll see a big slow down in that case.

T.

On Wed, 2002-10-16 at 11:10, RenE J.V. Bertin wrote:
> Hello,
> 
> I recently installed gcc 3.2.0 next to my old gcc 2.95.3 . I understood that this should give me some performance gain. I indeed found some, but in a few cases I actually observed a considerable loss in performance. I would be interested to learn if others have similar experiences, and what the general opinion is concerning what version (and flags) to use for R!
> 
> 1) gcc 3.2.0 -O3 can be much slower than gcc 3.2.0 -O2, causing a collection of simple
> tests to take over 50s instead of under 20s. This is due to -finline-functions!!
> 
> 2) I have my own graphing/analysis programme that contains an expression language with a
> byte compiler (i.e. the parser constructs a call graph with the callback function pointers,
> memory for arguments and other relevant information). Again, I mostly find small performance
> gains, but also 1 particular construct (calling a procedure via the 'call' routine) that
> is almost 10x slower with gcc 3.2.0 than with gcc 2.95.3 . (I don't understand why it is so
> fast with 2.95.3 but that's another issue :)). No influence of -finline-functions here.
> I imagine that this could be an issue for R too!
> 
> R.B.
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-- 
Timothy H. Keitt
Section of Integrative Biology
University of Texas at Austin

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jin_xiaodong at yahoo.com  Wed Oct 16 22:55:43 2002
From: jin_xiaodong at yahoo.com (xiaodong jin)
Date: Wed, 16 Oct 2002 13:55:43 -0700 (PDT)
Subject: [R] how to overlay the histogram with fitted gamma density plot (emergent!!)
Message-ID: <20021016205543.8652.qmail@web14203.mail.yahoo.com>


For a real data column X value ranged between (56.4521,32317.9) with missing values, I need to overlay 2 plots: histogram & fitted gamma density.

I use following to generate histogram.

xbk_seq(50,33000,by=100)

hist(x,breaks=xbk)

But I don't know how to get "fitted gamma density"?

In SAS proc capability, I got Shape=2.59, Scale=3481).

But when I do

plot(dgamma(x, shape=2.59, rate=1,scale=3481)), it gives me a flat densed line close to 0, which does not look correct.

Would anybody help me on this?

Thanks!

Shelton



---------------------------------

Faith Hill - Exclusive Performances, Videos, & more
faith.yahoo.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20021016/0757ad80/attachment.html

From p.dalgaard at biostat.ku.dk  Wed Oct 16 23:28:24 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 16 Oct 2002 23:28:24 +0200
Subject: [R] how to overlay the histogram with fitted gamma density plot (emergent!!)
In-Reply-To: <20021016205543.8652.qmail@web14203.mail.yahoo.com>
References: <20021016205543.8652.qmail@web14203.mail.yahoo.com>
Message-ID: <x2of9uul8n.fsf@biostat.ku.dk>

xiaodong jin <jin_xiaodong at yahoo.com> writes:

> For a real data column X value ranged between (56.4521,32317.9) with missing values, I need to overlay 2 plots: histogram & fitted gamma density.
> 
> I use following to generate histogram.
> 
> xbk_seq(50,33000,by=100)
> 
> hist(x,breaks=xbk)
> 
> But I don't know how to get "fitted gamma density"?
> 
> In SAS proc capability, I got Shape=2.59, Scale=3481).
> 
> But when I do
> 
> plot(dgamma(x, shape=2.59, rate=1,scale=3481)), it gives me a flat densed line close to 0, which does not look correct.
> 
> Would anybody help me on this?

First of all, you need to make sure that your histogram is on "density
scale" (i.e. not raw bin counts) by using prob=TRUE. Then comes the
issue of checking that SAS and R agree on the parametrization of the
gamma distribution. 

The MASS library has fitdistr() which might be helpful.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From king at tolstoy.newcastle.edu.au  Thu Oct 17 00:35:35 2002
From: king at tolstoy.newcastle.edu.au (king@tolstoy.newcastle.edu.au)
Date: Thu, 17 Oct 2002 08:35:35 +1000 (EST)
Subject: [R] Batch mode on windows
Message-ID: <Pine.LNX.4.21.0210170832480.8472-100000@tolstoy.newcastle.edu.au>

Posted on behalf of chenwj <stop4optimal at hotmail.com> who is having
trouble posting.

hi all,

I'm completely new in R, and here are my questions (under windows):

1.  i want to run my four R files (pl1.r -- pl4.r) in batch mode.  i'd
like to write a batch file using Rterm.exe, since i dont get perl
installed on my computer.  My experimental batch file (*.bat) didnt work,
which contains the following lines.  however it works well when i pasted
each single line to run in the command prompt (eg. cmd).  i wonder what's
wrong with my batch file.

D:\R\bin\Rterm.exe --vanilla <d:\work\pl1.r> pl1.out
D:\R\bin\Rterm.exe --vanilla <d:\work\pl2.r> pl2.out
D:\R\bin\Rterm.exe --vanilla <d:\work\pl3.r> pl3.out
D:\R\bin\Rterm.exe --vanilla <d:\work\pl4.r> pl4.out

  
2. If one of my above R files contains a function from a outside package
(eg. quantreg), how to load it in command prompt, or how to get the
package loading process involved in my batch file?

Can anyone give me some guide?

thanks a million.

regards,
chenwj



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Drew.Tyre at csiro.au  Thu Oct 17 01:08:10 2002
From: Drew.Tyre at csiro.au (Drew.Tyre@csiro.au)
Date: Thu, 17 Oct 2002 09:08:10 +1000
Subject: [R] error in make pkg-...
Message-ID: <745A64FABDC57D4E83A71D1B613687B293EF48@apogon.bne.marine.csiro.au>

Hi All,

I am trying to build a couple of packages from source, one of my own and
others. I have had this working under R1.5.0, now trying to set up on a new
machine under R1.6.0. Starting from various places, I am getting an error in
MkRules that I do not understand. 

C:\PROGRA~1\R\rw1060\src\gnuwin32>make libR.a libRblas.a
MkRules:91: *** missing separator.  Stop.

The example is from the text in readme.packages. I get the same error on
everything I've tried.

The only thing I can think of that I have done differently is to edit the
path variables in MkRules to point to all the locations they are supposed to
point to. I've checked all these and they are correct. The tools, ming-w
compiler, and perl are installed and in the path. Any pointers as to how to
identify where the problem lies gratefully received. 

Cheers,
Drew

Drew Tyre
CSIRO Marine Research, PO Box 120
Cleveland, QLD, 4163, Australia
drew.tyre at csiro.au
voice: +61 7 3826 7263 fax: + 61 7 3826 7222


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Drew.Tyre at csiro.au  Thu Oct 17 01:34:51 2002
From: Drew.Tyre at csiro.au (Drew.Tyre@csiro.au)
Date: Thu, 17 Oct 2002 09:34:51 +1000
Subject: [R] FIXED: error in make pkg-...
Message-ID: <745A64FABDC57D4E83A71D1B613687B293EF49@apogon.bne.marine.csiro.au>

Sorry, spoke too quickly!

The problem was caused by my editing the MkRules file with an editor that
replaces tabs with spaces. Make evidently requires that all lines start with
a tab (see http://www.delorie.com/djgpp/v2faq/faq22_17.html). Perhaps worth
warning windoze users like myself of such perils in readme.packages or
somewhere similar! 

Now I have a new problem, but it looks fixable. 

Thanks for your attention.

Drew 

Drew Tyre
CSIRO Marine Research, PO Box 120
Cleveland, QLD, 4163, Australia
drew.tyre at csiro.au
voice: +61 7 3826 7263 fax: + 61 7 3826 7222


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From f0z6305 at labs.tamu.edu  Thu Oct 17 03:28:12 2002
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Wed, 16 Oct 2002 20:28:12 -0500
Subject: [R] Trigamma function
Message-ID: <004401c2757c$7591d040$8bd75ba5@IE.TAMU.EDU>

Hey, all

Do you how to calculate the trigamma function, that is
d**2(log(gamma(x))) / dx**2.
The second-order derivative of log(Gamma(x))?

I cannot find it in the R package, and somebody knows who or where to get
such one?

Thanks.

Fred



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Thu Oct 17 04:45:16 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 16 Oct 2002 22:45:16 -0400
Subject: [R] Batch mode on windows
In-Reply-To: <Pine.LNX.4.21.0210170832480.8472-100000@tolstoy.newcastle.
 edu.au>
Message-ID: <5.1.0.14.2.20021016223101.020bea90@mcmail.cis.mcmaster.ca>

Dear chenwj,

At 08:35 AM 10/17/2002 +1000, king at tolstoy.newcastle.edu.au wrote:

>I'm completely new in R, and here are my questions (under windows):
>
>1.  i want to run my four R files (pl1.r -- pl4.r) in batch mode.  i'd
>like to write a batch file using Rterm.exe, since i dont get perl
>installed on my computer.  My experimental batch file (*.bat) didnt work,
>which contains the following lines.  however it works well when i pasted
>each single line to run in the command prompt (eg. cmd).  i wonder what's
>wrong with my batch file.
>
>D:\R\bin\Rterm.exe --vanilla <d:\work\pl1.r> pl1.out
>D:\R\bin\Rterm.exe --vanilla <d:\work\pl2.r> pl2.out
>D:\R\bin\Rterm.exe --vanilla <d:\work\pl3.r> pl3.out
>D:\R\bin\Rterm.exe --vanilla <d:\work\pl4.r> pl4.out

It's a little hard to tell exactly what the problem is. If each of the 
command files pl1.r, etc. works individually, this looks to me like it 
should work. It might help to know what the command files contain and what 
was the nature of the error. Your experimental DOS batch file must have had 
a specific name -- I assume something.bat. You are trying to run the DOS 
batch file at the DOS command prompt, aren't you -- not from the R console?

>
>2. If one of my above R files contains a function from a outside package
>(eg. quantreg), how to load it in command prompt, or how to get the
>package loading process involved in my batch file?

You need to attach packages in the command file just as you would if you 
were working interactively -- e.g., by including the command library(quantreg).

I hope that this helps,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bill.Venables at cmis.csiro.au  Thu Oct 17 05:26:21 2002
From: Bill.Venables at cmis.csiro.au (Bill.Venables@cmis.csiro.au)
Date: Thu, 17 Oct 2002 13:26:21 +1000
Subject: [R] Trigamma function
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A916556B@Roper-CV.qld.cmis.csiro.au>

Feng Zhang asks:

>  -----Original Message-----
> From: 	Feng Zhang [mailto:f0z6305 at labs.tamu.edu] 
> Sent:	Thursday, October 17, 2002 11:28 AM
> To:	R-Help
> Subject:	[R] Trigamma function
> 
> Hey, all
> 
> Do you how to calculate the trigamma function, that is
> d**2(log(gamma(x))) / dx**2.
> The second-order derivative of log(Gamma(x))?
> 
> I cannot find it in the R package, and somebody knows who or where to get
> such one?
	[WNV]  Eh?  Try package:base.  Hard to avoid really.
	> find(trigamma)
	[1] "package:base"
	> trigamma(1:10)
	 [1] 1.6449341 0.6449341 0.3949341 0.2838230 0.2213230 0.1813230
0.1535452
	 [8] 0.1331370 0.1175120 0.1051663
	> 
	Easy peasy.

> Thanks.
> 
> Fred
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-
> r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From daodao99 at student.umu.se  Thu Oct 17 06:00:20 2002
From: daodao99 at student.umu.se (Danardono)
Date: Thu, 17 Oct 2002 13:00:20 +0900
Subject: [R] Database newbee problem...
References: <20021016051109.GA25176@ling.umu.se>
Message-ID: <3DAE35D4.1000105@student.umu.se>

Just curious, does the function dbDriver exist in RMySQL?
I usually use dbManager.

>>m <- dbDriver("MySQL")
>>con <- dbConnect(m,group="testdb")
>>    
>>
/Danar.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From drf5n at mug.sys.virginia.edu  Thu Oct 17 06:04:17 2002
From: drf5n at mug.sys.virginia.edu (David Forrest)
Date: Thu, 17 Oct 2002 00:04:17 -0400 (EDT)
Subject: [R] Multiple colors in plots/lookup function
Message-ID: <Pine.LNX.4.33.0210162357500.28668-100000@mug.sys.virginia.edu>

Hello,
  I'd like to do something like:

 n<-100
 zz<-cbind(rnorm(n),rnorm(n),floor(runif(n)*3+1))
 colors<-c("red","green","blue")

 plot(zz,col=colors(zz[3]))

and have a matrix of scatterplots colored by class.  The above does not
work, of course, but I'm not sure exactly what function I'm looking for.

Thank you for your time,
Dave,
-- 
 Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
 drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Thu Oct 17 07:41:10 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 16 Oct 2002 22:41:10 -0700 (PDT)
Subject: [R] Trigamma function
In-Reply-To: <004401c2757c$7591d040$8bd75ba5@IE.TAMU.EDU>
Message-ID: <Pine.GSO.4.10.10210162240310.12781-100000@quetelet.stat.ucla.edu>

Yes, the function is called 'trigamma'.  Try

?trigamma

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 16 Oct 2002, Feng Zhang wrote:

> Hey, all
> 
> Do you how to calculate the trigamma function, that is
> d**2(log(gamma(x))) / dx**2.
> The second-order derivative of log(Gamma(x))?
> 
> I cannot find it in the R package, and somebody knows who or where to get
> such one?
> 
> Thanks.
> 
> Fred
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From river3600 at yahoo.com  Thu Oct 17 07:48:10 2002
From: river3600 at yahoo.com (Boaz W)
Date: Wed, 16 Oct 2002 22:48:10 -0700 (PDT)
Subject: [R] Help
Message-ID: <20021017054810.21127.qmail@web12904.mail.yahoo.com>

Hello,

I  already download rm160.sit  to a iMac9.1 computer.
But I can not run R-icon for installation of R. The
computer told me --the application "R" could not be
opend because 
"Carbonlib" could not be found. I donot know why I
could not install R to the computer.

Thank you.

Jinbo

__________________________________________________

Faith Hill - Exclusive Performances, Videos & More

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Oct 17 08:17:38 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 17 Oct 2002 07:17:38 +0100 (BST)
Subject: [R] FIXED: error in make pkg-...
In-Reply-To: <745A64FABDC57D4E83A71D1B613687B293EF49@apogon.bne.marine.csiro.au>
Message-ID: <Pine.LNX.4.31.0210170714410.2942-100000@gannet.stats>

Well, would Windows users even know they had such an editor?  It's not
something which has ever come up before, and adding warnings for ever
single problem of any one user's deficient environment would be
overwhelming.

Note that none of the lines the user is expected to edit involve tabs.

On Thu, 17 Oct 2002 Drew.Tyre at csiro.au wrote:

> Sorry, spoke too quickly!
>
> The problem was caused by my editing the MkRules file with an editor that
> replaces tabs with spaces. Make evidently requires that all lines start with
> a tab (see http://www.delorie.com/djgpp/v2faq/faq22_17.html). Perhaps worth
> warning windoze users like myself of such perils in readme.packages or
> somewhere similar!
>
> Now I have a new problem, but it looks fixable.
>
> Thanks for your attention.
>
> Drew
>
> Drew Tyre
> CSIRO Marine Research, PO Box 120
> Cleveland, QLD, 4163, Australia
> drew.tyre at csiro.au
> voice: +61 7 3826 7263 fax: + 61 7 3826 7222
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at cbs.dtu.dk  Thu Oct 17 09:18:35 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Thu, 17 Oct 2002 09:18:35 +0200
Subject: [R] Multiple colors in plots/lookup function
In-Reply-To: <Pine.LNX.4.33.0210162357500.28668-100000@mug.sys.virginia.edu>
References: <Pine.LNX.4.33.0210162357500.28668-100000@mug.sys.virginia.edu>
Message-ID: <20021017071835.GA22787@giraffa.cbs.dtu.dk>

On Thu, Oct 17, 2002 at 12:04:17AM -0400, David Forrest wrote:
> Hello,
>   I'd like to do something like:
> 
>  n<-100
>  zz<-cbind(rnorm(n),rnorm(n),floor(runif(n)*3+1))
>  colors<-c("red","green","blue")
> 
>  plot(zz,col=colors(zz[3]))

if you replace the last line by
plot(zz,col=colors[zz[, 3]])
it seems to work.

Hopin' it helps,


L.


> 
> and have a matrix of scatterplots colored by class.  The above does not
> work, of course, but I'm not sure exactly what function I'm looking for.
> 
> Thank you for your time,
> Dave,
> -- 
>  Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
>  drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Gordon.Morrison at CommerzbankIB.com  Thu Oct 17 08:32:44 2002
From: Gordon.Morrison at CommerzbankIB.com (Morrison, Gordon)
Date: Thu, 17 Oct 2002 07:32:44 +0100
Subject: [R] RE: R2HTML package for R 1.6
Message-ID: <FAD50FCCDDD5D511865200508BB2CDA50C71A2@xmx2lonib.lonib.commerzbank.com>

Does this help on our backtest reporting?


Regards,


Gordon Morrison
Global Head of Quantitative Research

> *	+ 44 20 7653 7642
> Mob:     + 44 7867 801951
> fax:	+ 44 20 7645 7442
> * 	mailto:gordon.morrison at commerzbankib.com
> web:	http://www.cbksec.com/research/quant
> *	Commerzbank Securities
> 	60 Gracechurch Street
>                 London EC3V 0HR, U.K.
> 


-----Original Message-----
From: Eric Lecoutre [mailto:lecoutre at stat.ucl.ac.be]
Sent: 15 October 2002 17:25
To: r-announce at stat.math.ethz.ch
Subject: R2HTML package for R 1.6




Hello R communauty,

I have submitted to CRAN the package R2HTML.

The purpose of this package is twice:

- provide base HTML exportation functions. Basically, you will use them 
exactly as a print function (or a cat(...file=)). Thus, making dynamic HTML 
reports is possible.

- making live HTML output with frames and command, which is very usefull 
for teaching purpose, as the student can keep a trace of his session, 
graphs beeing included as pictures.

I am afraid the doc. is not very fine, but don't hesitate to ask me any 
question about the use of this package.

Eric Lecoutre

PS: as most of R users, I am a statistician who has an empirical knowledge 
of informatic (and programmation). The code of R2HTML is certainly not the 
most efficient. In particular, I would ba happy to benefit of a real 
programmer's experience to improve the exportation of lists objects.







__________________________________________________

Eric Lecoutre           Informaticien/Statisticien
Institut de Statistique                        UCL

                               (+32) (0)10 47 30 50
                            lecoutre at stat.ucl.ac.be
     http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

__________________________________________________
Le vrai danger, ce n'est pas quand les ordinateurs
penseront comme des hommes, c'est quand les hommes
penseront comme des ordinateurs.     Sydney Harris


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-announce mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


********************************************************************** 
This communication is confidential and is intended only for 
the person to whom it is addressed.  If you are not that person you
are not permitted to make use of the information and you are requested 
to notify <mailto:LONIB.Postmaster at commerzbankib.com> immediately that 
you have received it and then destroy the copy in your possession.
Commerzbank AG is regulated by the FSA for the conduct of investment
business in the UK.
**********************************************************************

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From e.corda at oncfs.gouv.fr  Thu Oct 17 08:40:19 2002
From: e.corda at oncfs.gouv.fr (E. Corda)
Date: Thu, 17 Oct 2002 08:40:19 +0200
Subject: [R] constructing grouped data object when grouping is nested within a fixed factor
In-Reply-To: <3.0.1.32.20021016112044.006b07e8@mail.sky.fr>
References: <3.0.1.32.20021016112044.006b07e8@mail.sky.fr>
Message-ID: <15790.23379.768080.844176@gargle.gargle.HOWL>


       [this was erronously sent to "owner-R-help" {which is the
        list maintainer, a person -- manually re-posted, MM.]
Dear all,
Does anyone know how to construct a grouped data object where the grouping
variable is nested within a fixed factor? 
Indeed I have three zones which I consider as the levels of a fixed factor,
and in each zone I have 5 circuits on which several observations were made.
My grouping variable is the circuit nested within zone. So is it possible
to specify this although the zone is considered as fixed? After that I
would like to specify a mixed-effects model using nlme library.
Another question linked to the first one: in such a case, is it equivalent
to create a new CIRCUIT variable numbered from 1 to 15, and to specify it
as the grouping variable?
Thanks in advance for any help.
Eve CORDA 
Office national de la chasse et de la faune sauvage
5, rue de Saint Thibault
SAINT-BENOIST
78610 AUFFARGIS
BP 20 - 78612 LE PERRAY EN YVELINES Cedex
FRANCE
Tel : +33 (0)1.30.46.60.64
Fax : +33 (0)1.30.46.60.99
Email : e.corda at oncfs.gouv.fr
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From humbertc at univ-mlv.fr  Thu Oct 17 09:56:20 2002
From: humbertc at univ-mlv.fr (Cyril Humbert)
Date: Thu, 17 Oct 2002 09:56:20 +0200
Subject: [R] xyplot(y~x, type="l") with missing values (NA)
Message-ID: <20021017095620.A1488@borneo.univ-mlv.fr>

With the function plot(x, y, type="l") points are not connected
when x or y contain a missing value (NA). Is it possible to do
the same with the lattice function xyplot() ?

For example:

	library(lattice)
	x <- c(1, 2, NA, 4, 5)
	y <- x
	plot(x, y, type="l")
	xyplot(y~x, type="l")

In the first plot, the point 2 is not connected to the point 4
whereas there are in the second plot.

Thanks
-- 
Cyril 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Detlef.Steuer at unibw-hamburg.de  Thu Oct 17 10:24:43 2002
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Thu, 17 Oct 2002 10:24:43 +0200 (CEST)
Subject: [R] Multiple colors in plots/lookup function
In-Reply-To: <Pine.LNX.4.33.0210162357500.28668-100000@mug.sys.virginia.edu>
Message-ID: <XFMail.20021017102443.steuer@unibw-hamburg.de>


On 17-Oct-2002 David Forrest wrote:
> Hello,
>   I'd like to do something like:
> 
>  n<-100
>  zz<-cbind(rnorm(n),rnorm(n),floor(runif(n)*3+1))
>  colors<-c("red","green","blue")
> 
>  plot(zz,col=colors(zz[3]))

but this does:
 plot(zz, col=colors[zz[,3]])

detlef


> 
> and have a matrix of scatterplots colored by class.  The above does not
> work, of course, but I'm not sure exactly what function I'm looking for.
> 
> Thank you for your time,
> Dave,
> -- 
>  Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
>  drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _

"There is no way to peace, peace is the way." -- Ghandi

Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mijeom.joe at samsung.com  Thu Oct 17 11:00:26 2002
From: mijeom.joe at samsung.com (=?EUC-KR?B?wba5zMGh?=)
Date: Thu, 17 Oct 2002 18:00:26 +0900
Subject: [R] tapply result into plotting
Message-ID: <0H4400FQ5BL6Z2@ms8.samsung.com>

Dear Helper:

I did program "tapply", then get the results.
But I'm in trouble with the next step on which I want to make the plot using the results of "tapply".

Say, programming tapply(X, INDICES, Function), get the results with INDICES and values calculating Function of X.
Here, I like to plot(INDICES, values calculating Function of X).
Could you let me know how to do it?
Thank you so much.

MIJEOM JOE, Ph.D. 
Advisory Engineer, IT Infrastructure Team
Information Technology R & D Center
SAMSUNG SDS CO., LTD.

TEL: 82-31-785-4527 
FAXL: 82-31-785-4452
CELL: 82-11-9556-6808
E-mail: mijeom.joe at samsung.com
KCCH: 82-2-974-2501 (Extension 1458)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richard.nixon at mrc-bsu.cam.ac.uk  Thu Oct 17 11:06:00 2002
From: richard.nixon at mrc-bsu.cam.ac.uk (Richard Nixon)
Date: Thu, 17 Oct 2002 10:06:00 +0100 (BST)
Subject: [R] Multiple colors in plots/lookup function
Message-ID: <E1826bQ-0007JU-00@bernstein.mrc-bsu.cam.ac.uk>

 
> Hello,
>   I'd like to do something like:
> 
>  n<-100
>  zz<-cbind(rnorm(n),rnorm(n),floor(runif(n)*3+1))
>  colors<-c("red","green","blue")
> 
>  plot(zz,col=colors(zz[3]))
> 
> and have a matrix of scatterplots colored by class.  The above does not
> work, of course, but I'm not sure exactly what function I'm looking for.
> 

Dave,
Not quite sure what you are after. Are you wanting to plot n vs zz for each 
column of zz?. If so try this...

n <- 100
zz <- cbind(rnorm(n),rnorm(n),floor(runif(n)*3+1))
colors<-c("red","green","blue")
for(i in 1:3){
    plot(1:n,zz[,i],col=colors[i],ylim=range(zz))
    par(new=T)
}

or a pairs type plot. In which case something like this will do (not sure what 
you mean about the colours in this case)

par(mfrow=c(3,3))
for(i in 1:3){
    for(j in 1:3){
        plot(zz[,i],zz[,j],col=colors[i],ylim=range(zz), xlim=range(zz))
    }
}

Richard

--
Dr. Richard Nixon
MRC Biostatistics Unit, Cambridge, UK
http://www.mrc-bsu.cam.ac.uk/personal/richard
Tel: +44 (0)1223 330382, Fax: +44 (0)1223 33038

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kdb at kvl.dk  Thu Oct 17 12:18:20 2002
From: kdb at kvl.dk (Karsten D Bjerre)
Date: Thu, 17 Oct 2002 12:18:20 +0200
Subject: [R] Polar plot, circular plot (angular data)
Message-ID: <sdaeaaa0.034@gwia.kvl.dk>

Dear R-users, 

Hereby a polar plot function for plotting angular data. I hope it will be usefull for some of you. 

I had a need to plot frequencies of wind-directions. The not-that-cheap SigmaPlot software did not allow me to change the orientation of the angular axis to clockwise orientation (what is used for meteorological observations). I even tried the latest version availible at the time (late 2001), but I did not succed. Returning to my own computer with newly saved SP-files, however, I was not able to open them. This is one of many reasons why open-source software is such a good alternative! 

After making my polar plots, I spend some time making the code more flexible. 
As I am a "learning by doing" R-programmer, the code may benefit from further development - particulary for adjustment to general R-language conventions for plot-functions. 
If possible, it would be nice to have a polar plot function as a more permanent part of R! 

Thanks to Ross Ihaka at R-help (Mon May 28 2001) for some of the polar.plot code used. 

Best wishes, 
Karsten 

 
#########
"polar.plot" <-
function (r, theta, theta.zero = 0, theta.clw = FALSE, method = 1, 
    rlabel.axis = 0, dir = 8, rlimits = NULL, grid.circle.pos = NULL, 
    grid.lwd = 1, grid.col = "black", points.pch = 20, points.cex = 1, 
    lp.col = "black", lines.lwd = 1, lines.lty = 1, polygon.col = NA, 
    polygon.bottom = TRUE, overlay = NULL, pi2.lab = TRUE, text.lab = NULL, 
    num.lab = NULL, rlabel.method = 1, rlabel.pos = 3, rlabel.cex = 1, 
    rlabel.col = "black", tlabel.offset = 0.1, tlabel.cex = 1.5, 
    tlabel.col = "black", main = NULL, sub = NULL) 
{
# r:   (vector of) radial data.
# theta: (vector of) angular data (in radians).
# theta.zero: angular direction on plot of theta = 0 (in radians).
# theta.clw: clockwise orientation of theta values (default = FALSE).
#
# method: (plotting of (r,theta)-data): 
# 1: points (default)
# 2: line 
# 3: polygon
#
# rlabel.axis: angular direction on the plot of radial label axis (in radians).
# dir: number of radial grid lines (default=8).
# rlimts: Interval for radial axis as a numeric vector: c(lower,upper). Interval will be extended by the default use of pretty()-function. (default = NULL).
# grid.circle.pos: radial axis position of grid circles as numeric vector of minimum length 2. Overrides the default positioning of grid circles by pretty()-function. (default = NULL).
# grid.lwd. grid line width.  
# grid.col: grid line color.
#  
# points.pch: points plotting symbol.
# point.cex: character expansion factor for points.
# lp.col: color of points (method 1) or lines (method 2 and method 3). In method 3, set lp.col=0 for polygons without border.  
# lines.lwd: line width for plotting methods 2 and 3 (default = 1).
# lines.lty: line type (default = 1).
# polygon.col: color of polygon (defalut = NA).
# polygon.bottom: polygon to the back i.e. behind the grid (default = TRUE).
#
# overlay: NULL (default), no overlay
#          1, overlay data on existing plot
#          2, overlay data, grid and labels on existing plot.
#
# pi2.lab:  angular labels in radians (0, pi/2, pi, 3*pi/2) (default).
# text.lab: angular axis labels from a character vector c("N","E","S","W") (default = NULL).
# num.lab:  numeric angular axis labels in interval [0;num.lab[ (default = NULL). Number of labels: dir.
#
# rlabel.method (plotting of radial axis labels):
#    0: no radial labels.
#    1: labels at pretty radial distances (default). 
#    2: exclude label at radial distace 0.
#    3: exclude label at maximum radial distance.
#    4: exclude radial labels at distance 0 and at maximum radial distance.
# rlabel.pos: text position of radial axis labels (NULL,1,2,3,4).
# rlabel.cex: cex for radial axis labels.
# rlabel.col: color of the radial labels.
#
# tlabel.offset: radial offset for angular axis labels in fraction of maximum radial value (default = 0.1).
# tlabel.cex: cex for angular axis labels.
# tlabel.col: angular labels color.
# 
# main: plot main title.
# sub:  plot sub title.
  
    fit.rad <- function(x, twop = 2 * pi) {
        for (i in 1:length(x)) {
            while (x[i] < 0) x[i] <- x[i] + twop
            while (x[i] >= twop) x[i] <- x[i] - twop
        }
        return(x)
    }
    if (is.null(rlimits)) 
        rpretty <- pretty(range(abs(r), 0, na.rm = TRUE))
    if (is.numeric(rlimits) & length(rlimits) == 2) 
        rpretty <- pretty(range(abs(rlimits[1]), abs(rlimits[2])))
    if (is.numeric(grid.circle.pos) & length(grid.circle.pos) > 
        1) 
        rpretty <- grid.circle.pos
    lab.dist <- max(rpretty)
    if (!is.null(text.lab) || is.numeric(num.lab) || pi2.lab) {
        lab.dist <- lab.dist * (tlabel.offset + 1)
    }
    if (is.null(overlay)) {
        plot.new()
        ps <- max(lab.dist, max(rpretty))
        plot.window(xlim = c(-ps, ps), ylim = c(-ps, ps), asp = 1)
        title(main = main, sub = sub)
    }
    drawgrid <- function() {
        if (dir > 0) {
            rDir <- seq(0, 2 * pi, length = dir + 1)[-(dir + 
                1)]
            segments(0, 0, max(rpretty) * cos(rDir), max(rpretty) * 
                sin(rDir), col = grid.col, lwd = grid.lwd)
        }
        grid <- seq(0, 2 * pi, length = 360/4 + 1)
        for (rad in rpretty) {
            if (rad > 0) 
                lines(rad * cos(grid), rad * sin(grid), col = grid.col, 
                  lwd = grid.lwd)
        }
        if (rlabel.method != 0) {
            if (rlabel.method == 1) 
                radLabels <- 1:length(rpretty)
            if (rlabel.method == 2) 
                radLabels <- 2:length(rpretty)
            if (rlabel.method == 3) 
                radLabels <- 1:(length(rpretty) - 1)
            if (rlabel.method == 4) {
                if (length(rpretty) > 2) 
                  radLabels <- 2:(length(rpretty) - 1)
                else radLabels <- NULL
            }
            if (!is.null(radLabels)) {
                xpos <- rpretty[radLabels] * cos(rlabel.axis)
                ypos <- rpretty[radLabels] * sin(rlabel.axis)
                text(xpos, ypos, rpretty[radLabels], cex = rlabel.cex, 
                  pos = rlabel.pos, col = rlabel.col)
            }
        }
        if (!is.numeric(num.lab)) {
            if (pi2.lab & !is.character(text.lab)) 
                t.lab <- expression(0, pi/2, pi, 3 * pi/2)
            if (!pi2.lab & is.character(text.lab)) 
                t.lab <- text.lab
            labDir <- seq(0, 2 * pi, length = length(t.lab) + 
                1)[-(length(t.lab) + 1)]
            labDir <- fit.rad(theta.zero + (!theta.clw) * labDir - 
                (theta.clw) * labDir)
            text(lab.dist * cos(labDir), lab.dist * sin(labDir), 
                t.lab, cex = tlabel.cex, col = tlabel.col)
        }
        if (!pi2.lab & is.null(text.lab) & is.numeric(num.lab)) {
            labDir <- seq(0, 2 * pi, length = num.lab + 1)[-(num.lab + 
                1)]
            labDir <- fit.rad(theta.zero + (!theta.clw) * labDir - 
                (theta.clw) * labDir)
            text(lab.dist * cos(labDir), lab.dist * sin(labDir), 
                paste(num.lab * labDir/(2 * pi)), cex = tlabel.cex, 
                col = tlabel.col)
        }
        if ((is.character(text.lab) & is.numeric(num.lab)) || 
            (is.character(text.lab) & pi2.lab) || (pi2.lab & 
            is.numeric(num.lab))) 
            print("More than one type of angular labels was requested.")
    }
    theta2 <- fit.rad(theta.zero + (!theta.clw) * theta - (theta.clw) * 
        theta)
    cartesian.rt <- cbind(r * cos(theta2), r * sin(theta2))
    if (method == 1) {
        if (is.null(overlay) || overlay == 2) 
            drawgrid()
        points(cartesian.rt[, 1], cartesian.rt[, 2], col = lp.col, 
            pch = points.pch, cex = points.cex)
    }
    if (method == 2) {
        if (is.null(overlay) || overlay == 2) 
            drawgrid()
        lines(cartesian.rt[, 1], cartesian.rt[, 2], lwd = lines.lwd, 
            col = lp.col, lty = lines.lty)
    }
    if ((method == 2 || method == 3) & length(r) <= 1) 
        print("More than one data point is needed for line and polygon methods.")
    if (method == 3) {
        if (!polygon.bottom & (is.null(overlay) || overlay == 
            2)) 
            drawgrid()
        polygon(cartesian.rt, lwd = lines.lwd, col = polygon.col, 
            border = lp.col, lty = lines.lty)
        if (polygon.bottom & (is.null(overlay) || overlay == 
            2)) 
            drawgrid()
    }
}
 

###########################
# data
div<-50
theta <- seq(0, 2 * pi, length = div + 1)[-(div+1)]
r<-1:(div)
r2<-rep(12,times=div)
r3<-rep(32,times=div)
 
# use of polar.plot
polar.plot(9, pi/4, dir = 4, points.cex = 1.5)
polar.plot(r, theta)
polar.plot(r, theta, method = 2, lines.lwd = 3, lines.lty=2, lp.col = "blue")
polar.plot(r, theta, method=3, pi2.lab = FALSE, dir = 7, lines.lwd = 3, polygon.col="blue", lp.col = "red", grid.circle.pos = c(0, 50), rlabel.method=4 )
 
# overlay of polar plots
polar.plot(r3, theta, method = 3, rlimits=c(0,50), rlabel.method = 2, lp.col = 0, polygon.col = "blue")
polar.plot(r2, theta, method = 3, overlay=1, lp.col = 0, polygon.col = "white")
polar.plot(r/2+15, 2*theta, lp.col = "red", method = 1, rlimits=c(0,50), overlay =2, points.cex = 1.5)
title(main="Overlay red points on white polygon on blue polygon")
 
# theta axis labels as text
textlabels<-c('N','E','S','W')
polar.plot(r, theta, theta.clw = TRUE, theta.zero = pi/2, text.lab = textlabels , pi2.lab = FALSE, lines.lwd = 3, grid.lwd = 1, grid.col = "darkgreen", rlabel.method = 2, rlabel.axis = -pi/2, rlabel.cex = 2, rlabel.pos = NULL, rlabel.col = "brown", tlabel.col = "darkgreen",  points.cex = 3, points.pch = 21, tlabel.cex = 3, tlabel.offset = 0.3, lp.col = "red")
title(main="A Compas Rose\n  Hurray for the R core group!")
 
# Example by Ross Ihaka at R-help
group <- sample(3, 100, replace = TRUE)
theta <- 0.5 * rnorm(100) + 0.5 * group
r <- rnorm(100, 4)
polar.plot(r, theta, lp.col = c("red","green4","blue")[group], points.pch = 19)

 
---ooo--- 
Karsten Dalsgaard Bjerre (M.Sc. Agriculture, Ph.D. Student). 
Department of Plant Biology 
Royal Veterinary and Agricultural University 
40 Thorvaldsensvej 
DK-1871 Frederiksberg C 
Denmark 
Tel: (+45) 3528 3418 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Derek.Eder at neuro.gu.se  Thu Oct 17 13:07:45 2002
From: Derek.Eder at neuro.gu.se (Derek Eder)
Date: Thu, 17 Oct 2002 13:07:45 +0200
Subject: [R]  Mixture Transition Distribution (MTD) time series model
	in R or S ?
Message-ID: <sdaeb6c0.041@dss2.med.gu.se>

Has anyone see an S or R implementation of the MTD time series model*?


*  e.g.:    Le, N.D., Martin, R.D. and Raftery, A.E. (1996) Modeling outliers, bursts and flat stretches in time series using mixture transition distribution (MTD) models. Journal of the American Statistical Association, 91: 1504-1515

http://www.stat.washington.edu/raftery/Research/TS/ts.html 


- Derek Eder

Derek N. Eder
G?teborgs Universitet
Institutionen f?r klinisk neurovetenskap
Klinisk Neurofysiologi
Sahlgrenska universitetssjukhuset SS/SU
Bl? str?ket 7, v?n 3
SE 413 45  G?teborg
Sverige
Tlf. +46 (031) 34  244 14  (office)   NYTT!
Tlf. +46 (031) 34 212 83  (laboratory)
Tlf. +46 0709 / 7 212 83 (mobil)
Fax. +46 (031) 82 81 63 
derek.eder at neuro.gu.se


Gothenburg University
Institute of Clinical Neuroscience,
Department of Clinical Neurophysiology
Salhgrenska Hospital  SU/SS
SE 413 45  G?teborg
Sweden



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rjvbertin at hotmail.com  Thu Oct 17 13:25:32 2002
From: rjvbertin at hotmail.com (RenE J.V. Bertin)
Date: Thu, 17 Oct 2002 13:25:32 +0200
Subject: [R] manova with Error?
Message-ID: <20021017132532.70c70fca.rjvbertin@hotmail.com>

Let's say I have a within-subject experiment with 2 observables, obs1 and ob2 and 2 independent factors, fac1 and fac2.

I can do

summary( aov( obs1~fac1*fac2 + Error(Subject/(fac1*fac2)) ) )
summary( aov( obs2~fac1*fac2 + Error(Subject/(fac1*fac2)) ) )

to test the 2 observables separately.

> summary( fit<-manova( cbind(obs1,obs2)~fac1*fac2 + Error(Subject/(fac1*fac2)) ) )

gives results that seem sensible, but that I suppose represent the effects on obs1 and obs2 combined. The example for summary.manova shows that 
> summary.aov(fit)
would print the effects separately for each observable. However, I get the message

Error in 1:object$rank : NA/NaN argument

and
> class(fit)
[1] "aovlist" "listof"


I suppose that this means that I shouldn't want to do this sort of test, and rather look at each observable separately. The question is: why? Is there a simple explanation comprehensible for the non-statistician?

RenE Bertin.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Thu Oct 17 13:28:42 2002
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 17 Oct 2002 07:28:42 -0400
Subject: [R] Multiple colors in plots/lookup function
In-Reply-To: <Pine.LNX.4.33.0210162357500.28668-100000@mug.sys.virginia.
 edu>
Message-ID: <5.1.0.14.2.20021017071947.027e1e48@mcmail.cis.mcmaster.ca>

Dear David,

At 12:04 AM 10/17/2002 -0400, David Forrest wrote:

>   I'd like to do something like:
>
>  n<-100
>  zz<-cbind(rnorm(n),rnorm(n),floor(runif(n)*3+1))
>  colors<-c("red","green","blue")
>
>  plot(zz,col=colors(zz[3]))
>
>and have a matrix of scatterplots colored by class.  The above does not
>work, of course, but I'm not sure exactly what function I'm looking for.

A couple of people have already mentioned that specifying 
col=colors[zz[,3]] will colour the points in a scatterplot (not a 
scatterplot matrix) by the values of zz[,3]. Since there are just two other 
columns (the third column of zz is ignored in the first argument to plot), 
you get a scatterplot, not a scatterplot matrix, and it's hard to see how a 
scatterplot matrix would be relevant.

If, however, you want a scatterplot matrix of pairwise plots for three or 
more variables coloured by the levels of a factor, the scatterplot.matrix 
function in the car package should do what you want.

Regards,
John


-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krupa at alpha.sggw.waw.pl  Thu Oct 17 15:41:45 2002
From: krupa at alpha.sggw.waw.pl (Jan Krupa)
Date: Thu, 17 Oct 2002 15:41:45 +0200 (CEST)
Subject: [R] Learning R: which book to choose?
In-Reply-To: <004901c27227$eaf040e0$b32558db@kwan022>
Message-ID: <Pine.LNX.4.21.0210171537160.459-100000@mel222.sggw.waw.pl>



Thank you very much for all answers.

Greetings

Jan


On Sun, 13 Oct 2002, Ko-Kang Kevin Wang wrote:

> ----- Original Message -----
> From: "Jan Krupa" <krupa at alpha.sggw.waw.pl>
> Subject: [R] Learning R: which book to choose?
> 
> > Q2. Which of the books 1 or 2 do you suggest to buy?
> 
> It depends on what you want to do.  If you are only using R to do normal


> 
> Ko-Kang Wang
> 
> 
> ------------------------------------------------
> Ko-Kang Kevin Wang
> Post Graduate PGDipSci Student
> Department of Statistics
> University of Auckland
> New Zealand
> www.stat.auckland.ac.nz/~kwan022


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct 17 13:50:30 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Oct 2002 13:50:30 +0200
Subject: [R] manova with Error?
In-Reply-To: <20021017132532.70c70fca.rjvbertin@hotmail.com>
References: <20021017132532.70c70fca.rjvbertin@hotmail.com>
Message-ID: <x2smz5473t.fsf@biostat.ku.dk>

"RenE J.V. Bertin" <rjvbertin at hotmail.com> writes:

> Let's say I have a within-subject experiment with 2 observables, obs1 and ob2 and 2 independent factors, fac1 and fac2.
> 
> I can do
> 
> summary( aov( obs1~fac1*fac2 + Error(Subject/(fac1*fac2)) ) )
> summary( aov( obs2~fac1*fac2 + Error(Subject/(fac1*fac2)) ) )
> 
> to test the 2 observables separately.
> 
> > summary( fit<-manova( cbind(obs1,obs2)~fac1*fac2 + Error(Subject/(fac1*fac2)) ) )
> 
> gives results that seem sensible, but that I suppose represent the
> effects on obs1 and obs2 combined. The example for summary.manova
> shows that > summary.aov(fit) would print the effects separately for
> each observable. However, I get the message
> 
> Error in 1:object$rank : NA/NaN argument
> 
> and
> > class(fit)
> [1] "aovlist" "listof"
> 
> 
> I suppose that this means that I shouldn't want to do this sort of
> test, and rather look at each observable separately. The question
> is: why? Is there a simple explanation comprehensible for the
> non-statistician?

This is not my specialty, but could it be that you have an empty error
stratum? I.e. if Subject:fac1:fac2 is the entire data set, then there
is no DF for the residual error. (If so, try Error(Subject/(fac1+fac2)) )

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rjvbertin at hotmail.com  Thu Oct 17 14:46:50 2002
From: rjvbertin at hotmail.com (RenE J.V. Bertin)
Date: Thu, 17 Oct 2002 14:46:50 +0200
Subject: [R] manova with Error?
In-Reply-To: <x2smz5473t.fsf@biostat.ku.dk>
References: <20021017132532.70c70fca.rjvbertin@hotmail.com>
	<x2smz5473t.fsf@biostat.ku.dk>
Message-ID: <20021017144650.0e6a1aec.rjvbertin@hotmail.com>

On 17 Oct 2002 13:50:30 +0200, Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> wrote regarding "Re:
[R] manova with Error?"

Hi,

8-) 
8-) This is not my specialty, but could it be that you have an empty error
8-) stratum? I.e. if Subject:fac1:fac2 is the entire data set, then there
8-) is no DF for the residual error. (If so, try Error(Subject/(fac1+fac2)) )


I'm not sure what you mean with "the entire data set". I have one value for obs1 and one for obs2 for each combination of Subject, fac1 and fac2.

I tried your suggestion; got the same error message.

BTW: Would that not also cause problems in a regular anova, with aov?

RenE Bertin.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Thu Oct 17 14:51:16 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 17 Oct 2002 14:51:16 +0200 (CEST)
Subject: [R] 'text' can't find "x"
Message-ID: <Pine.LNX.4.44.0210171433560.18626-100000@tal.stat.umu.se>

I wanted to add some text to a plot and got (R-1.6.0, Linux):

>  text(x = c(1, 4), y = 5, labels = x)
Error in text.default(x = c(1766, 1895), y = 5, labels = x) :
        Object "x" not found

With the default value of 'labels':

>  text(x = c(1, 2), y = 5, labels = seq(along = x))
Error in seq(along = x) : Object "x" not found

A scoping bug? :)

But

>  text(x = c(1, 2), y = 5)

is OK. Doesn't give the labels I want, though. But why does it work, i.e.,
why is 'x' found in this case and not when I write out the default?

---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Thu Oct 17 15:21:13 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 17 Oct 2002 15:21:13 +0200
Subject: [R] Multiple colors in plots/lookup function
In-Reply-To: <5.1.0.14.2.20021017071947.027e1e48@mcmail.cis.mcmaster.ca>
References: <Pine.LNX.4.33.0210162357500.28668-100000@mug.sys.virginia.
 edu>
	<5.1.0.14.2.20021017071947.027e1e48@mcmail.cis.mcmaster.ca>
Message-ID: <15790.47433.860124.144333@gargle.gargle.HOWL>

>>>>> "John" == John Fox <jfox at mcmaster.ca>
>>>>>     on Thu, 17 Oct 2002 07:28:42 -0400 writes:

    John> Dear David, At 12:04 AM 10/17/2002 -0400, David
    John> Forrest wrote:

    >> I'd like to do something like:
    >> 
    >> n<-100 zz<-cbind(rnorm(n),rnorm(n),floor(runif(n)*3+1))
    >> colors<-c("red","green","blue")
    >> 
    >> plot(zz,col=colors(zz[3]))
    >> 
    >> and have a matrix of scatterplots colored by class.  The
    >> above does not work, of course, but I'm not sure exactly
    >> what function I'm looking for.

    John> A couple of people have already mentioned that
    John> specifying col=colors[zz[,3]] will colour the points
    John> in a scatterplot (not a scatterplot matrix) by the
    John> values of zz[,3]. 

yes, even in a scatterplot matrix.
Try a very slight variation of the above :

  n <- 100
  zz <- data.frame(Z1 = rnorm(n), Z2 = rnorm(n), Ufact = floor(runif(n)*3+1))
  colors <- c("red","green","blue")
  plot(zz, col = colors[zz[, 3]])

i.e., the only practical difference is that I used 
data.frame() instead of
cbind()

--> which changes things:  The plot() method for a data.frame calls
pairs() which *is* the same as a scatterplot matrix.

    John> 	Since there are just two other
    John> columns (the third column of zz is ignored in the
    John> first argument to plot), you get a scatterplot, not a
    John> scatterplot matrix, and it's hard to see how a
    John> scatterplot matrix would be relevant.

indeed!

    John> If, however, you want a scatterplot matrix of pairwise
    John> plots for three or more variables coloured by the
    John> levels of a factor, the scatterplot.matrix function in
    John> the car package should do what you want.

I don't see why pairs()  {or as mentioned,  plot( ) for a data.frame}
shouldn't be sufficient.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pokapika at hotmail.com  Thu Oct 17 15:20:44 2002
From: pokapika at hotmail.com (Polona Razpotnik)
Date: Thu, 17 Oct 2002 15:20:44 +0200
Subject: [R] Data import
Message-ID: <F148UkAiKbuagPwCLji000039f7@hotmail.com>

Hello!

I have a question regarding data import.
My data are in txt file in two long columns looking like this:

D1
1       a
2       b
3       c
4       d
D2
1       e
2       f
3       g
4       h
D3
1       i
2       j
3       k
4       l     etc.

I would like to have them in the table looking like this (after importing 
them to R):

      D1    D2    D3
1    a       e       i
2    b       f       j
3    c       g       k
4    d       h      l

Can this be achieved directly from the txt file or do I have to rearrange 
it?

Thank you very much for any help!
Polona (a newcomer in the world of R)

_________________________________________________________________
Get faster connections-- switch toMSN Internet Access! 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dj at research.bell-labs.com  Thu Oct 17 15:40:48 2002
From: dj at research.bell-labs.com (David James)
Date: Thu, 17 Oct 2002 09:40:48 -0400
Subject: [R] Database newbee problem...
In-Reply-To: <3DAE35D4.1000105@student.umu.se>; from daodao99@student.umu.se on Thu, Oct 17, 2002 at 01:00:20PM +0900
References: <20021016051109.GA25176@ling.umu.se> <3DAE35D4.1000105@student.umu.se>
Message-ID: <20021017094048.C10454@jessie.research.bell-labs.com>

Danardono wrote:
> Just curious, does the function dbDriver exist in RMySQL?
> I usually use dbManager.
> 
> >>m <- dbDriver("MySQL")
> >>con <- dbConnect(m,group="testdb")
> >>    
> >>
> /Danar.
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

There has been a change in function names in the new RMySQL 0.5-0
version (also in the new ROracle and RSQLite).  The reason is that
the R-SIG-DB has agreed on a common interface to all databases,
and as part of this new common interface, most functions have been
renamed.  The following simple name mapping may help you upgrade
existing code to the new DBI:

pre-DBI                  DBI 0.1-4 
----------------------   ----------------------------------
dbManager                dbDriver
dbConnect                dbConnect
dbExecStatement          dbSendQuery
dbExec                   dbSendQuery
quickSQL                 dbGetQuery
fetch                    fetch
getTables                dbListTables
getConnections           dbListConnections
getResultSets            dbListResults
getConnection            dbGetConnection
getFields                dbColumnInfo         # for a result set 
getFields                dbListFields         # for a table name in a conn
getStatement             dbGetStatement
getRowsAffected          dbGetRowsAffected
getRowCount              dbGetRowCount
hasCompleted             dbHasCompleted
getInfo                  dbGetInfo
describe                 summary
getTableFields           dbListFields
getTable                 dbReadTable
assignTable              dbWriteTable
existsTable              dbExistsTable
SQLDataType              dbDataType
make.SQL.name            make.db.name
isSQLKeyword             isSQLKeyword
removeTable              dbRemoveTable
getException             dbGetException
load                     dbDriver
unload                   dbUnloadDriver
commit                   dbCommit
rollback                 dbRollback
callProc                 dbCallProc
close                    dbDisconnect
close                    dbClearResult

getVersion               NA
getCurrentDatabase       NA
getNumRows               NA
getNullOk                NA
getNumCols               NA
getDatabases             NA
getTableIndices          NA

NA                       dbGetDBIVersion

-- 
David A. James
Statistics Research, Room 2C-253            Phone:  (908) 582-3082       
Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
Murray Hill, NJ 09794-0636
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct 17 15:54:55 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Oct 2002 15:54:55 +0200
Subject: [R] manova with Error?
In-Reply-To: <20021017144650.0e6a1aec.rjvbertin@hotmail.com>
References: <20021017132532.70c70fca.rjvbertin@hotmail.com>
	<x2smz5473t.fsf@biostat.ku.dk>
	<20021017144650.0e6a1aec.rjvbertin@hotmail.com>
Message-ID: <x2fzv541cg.fsf@biostat.ku.dk>

"RenE J.V. Bertin" <rjvbertin at hotmail.com> writes:

> On 17 Oct 2002 13:50:30 +0200, Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> wrote regarding "Re:
> [R] manova with Error?"
> 
> Hi,
> 
> 8-) 
> 8-) This is not my specialty, but could it be that you have an empty error
> 8-) stratum? I.e. if Subject:fac1:fac2 is the entire data set, then there
> 8-) is no DF for the residual error. (If so, try Error(Subject/(fac1+fac2)) )
> 
> 
> I'm not sure what you mean with "the entire data set". I have one value for obs1 and one for obs2 for each combination of Subject, fac1 and fac2.

That's what I meant.
 
> I tried your suggestion; got the same error message.

Too bad.
 
> BTW: Would that not also cause problems in a regular anova, with aov?

Not necessarily. (I knew that it works there.) 

I think what you're trying to do makes sense, it's just that
summary.manova isn't quite up to the task (or perhaps aov() or
manova() isn't).

To let others chip in, let's try on data that are available to
everyone:

example(summary.manova) # includes defn. of Y, rate, additive
fit <- manova(Y ~ rate + Error(additive))
fit
summary(fit)
summary.aov(fit)
summary(fit[[1]])
summary(fit[[2]])
summary(fit[[3]])

of which only the raw print of "fit" and the very last line give
sensible results. 

I would expect at least summary(fit[[2]]) to work, but it is stumbling
upon

        ss <- list(0)
        nmrows <- character(0)

and a little later

    names(ss) <- nmrows

Anyone have further clues?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rg117 at ohm.york.ac.uk  Thu Oct 17 16:29:41 2002
From: rg117 at ohm.york.ac.uk (Rishabh Gupta)
Date: Thu, 17 Oct 2002 15:29:41 +0100
Subject: [R] panel vs subpanel in cloud from lattice library
Message-ID: <001501c275e9$a14e7ae0$35892090@ohm.york.ac.uk>

Hi,
    Could somebody explain to be the different between the panel and the subpanel parameter in the cloud function of the lattice
library. I'm not sure when to use which.
Thanks

Rishabh

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Thu Oct 17 17:07:53 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Thu, 17 Oct 2002 11:07:53 -0400 (EDT)
Subject: [R] spatial ARMA
Message-ID: <Pine.LNX.4.44.0210171053110.1693-100000@bolker.zoo.ufl.edu>


  I am currently struggling to implement Jones and Vecchia's (1993) 
spatial ARMA models.  Anyone out there done it already (in R, or 
some other platform)?

  Ben Bolker

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rjvbertin at hotmail.com  Thu Oct 17 17:13:34 2002
From: rjvbertin at hotmail.com (RenE J.V. Bertin)
Date: Thu, 17 Oct 2002 17:13:34 +0200
Subject: [R] manova with Error?
In-Reply-To: <x2fzv541cg.fsf@biostat.ku.dk>
References: <20021017132532.70c70fca.rjvbertin@hotmail.com>
	<x2smz5473t.fsf@biostat.ku.dk>
	<20021017144650.0e6a1aec.rjvbertin@hotmail.com>
	<x2fzv541cg.fsf@biostat.ku.dk>
Message-ID: <20021017171334.25e66dbd.rjvbertin@hotmail.com>

On 17 Oct 2002 15:54:55 +0200, Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> wrote regarding "Re:
[R] manova with Error?"

8-) To let others chip in, let's try on data that are available to
8-) everyone:
8-) 
8-) example(summary.manova) # includes defn. of Y, rate, additive
8-) fit <- manova(Y ~ rate + Error(additive))
8-) fit
8-) summary(fit)
8-) summary.aov(fit)
8-) summary(fit[[1]])
8-) summary(fit[[2]])
8-) summary(fit[[3]])
8-) 
8-) of which only the raw print of "fit" and the very last line give
8-) sensible results. 

	With my own data, I do get output from summary(fit), and not the error message that arises in this case. And, indeed, summary(fit[[1]]) says "No error degrees of freedom". I can make this data available to everyone, but please indicate what the best way to export it is.

8-) Anyone have further clues?

Maybe the result class:

> example(summary.manova)
> class(fit)
[1] "manova" "maov"   "aov"    "mlm"    "lm"    

> fit<-manova(Y~rate + Error(additive))
> class(fit)
[1] "aovlist" "listof" 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Thu Oct 17 17:22:25 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu, 17 Oct 2002 08:22:25 -0700 (PDT)
Subject: [R] Help
In-Reply-To: <20021017054810.21127.qmail@web12904.mail.yahoo.com>
Message-ID: <Pine.GSO.4.10.10210170821230.17159-100000@quetelet.stat.ucla.edu>

It seems you need to download and install the CarbonLib 1.4 from the Apple
developer's website.  See the rmac-FAQ for the link.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 16 Oct 2002, Boaz W wrote:

> Hello,
> 
> I  already download rm160.sit  to a iMac9.1 computer.
> But I can not run R-icon for installation of R. The
> computer told me --the application "R" could not be
> opend because 
> "Carbonlib" could not be found. I donot know why I
> could not install R to the computer.
> 
> Thank you.
> 
> Jinbo
> 
> __________________________________________________
> 
> Faith Hill - Exclusive Performances, Videos & More
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ted.Harding at nessie.mcc.ac.uk  Thu Oct 17 17:24:31 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 17 Oct 2002 16:24:31 +0100 (BST)
Subject: [R] Non-central distributions
Message-ID: <XFMail.021017162431.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

I note that, while the "chisq" functions

     dchisq(x, df, ncp=0, log = FALSE)
     pchisq(q, df, ncp=0, lower.tail = TRUE, log.p = FALSE)
     qchisq(p, df, ncp=0, lower.tail = TRUE, log.p = FALSE)
     rchisq(n, df, ncp=0)

all have a slot for the non-centrality parameter "ncp", of
the functions for the t and F distributions:

     dt(x, df, log = FALSE)
     pt(q, df, ncp=0, lower.tail = TRUE, log.p = FALSE)
     qt(p, df,        lower.tail = TRUE, log.p = FALSE)
     rt(n, df)

     df(x, df1, df2, log = FALSE)
     pf(q, df1, df2, ncp=0, lower.tail = TRUE, log.p = FALSE)
     qf(p, df1, df2,        lower.tail = TRUE, log.p = FALSE)
     rf(n, df1, df2)

only the CDF functions 'pt' and 'pf' allow this parameter to
be set. (If you try in the others, you get the message
"unused argument(s) (ncp ...)").

Why is this? Being able to set it would be just as useful ...

Thanks, and best wishes to all,
Ted.
[and apologies if I should have been able to read the answer
for myself, somewhere ... ]




--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 17-Oct-02                                       Time: 16:24:31
------------------------------ XFMail ------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Thu Oct 17 17:34:05 2002
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 17 Oct 2002 11:34:05 -0400
Subject: [R] Multiple colors in plots/lookup function
In-Reply-To: <15790.47433.860124.144333@gargle.gargle.HOWL>
References: <5.1.0.14.2.20021017071947.027e1e48@mcmail.cis.mcmaster.ca>
 <Pine.LNX.4.33.0210162357500.28668-100000@mug.sys.virginia. edu>
 <5.1.0.14.2.20021017071947.027e1e48@mcmail.cis.mcmaster.ca>
Message-ID: <5.1.0.14.2.20021017113120.020fa690@mcmail.cis.mcmaster.ca>

Dear Martin,

At 03:21 PM 10/17/2002 +0200, Martin Maechler wrote:
> >>>>> "John" == John Fox <jfox at mcmaster.ca>
> >>>>>     on Thu, 17 Oct 2002 07:28:42 -0400 writes:
>
>     John> Dear David, At 12:04 AM 10/17/2002 -0400, David
>     John> Forrest wrote:
>
>     >> I'd like to do something like:
>     >>
>     >> n<-100 zz<-cbind(rnorm(n),rnorm(n),floor(runif(n)*3+1))
>     >> colors<-c("red","green","blue")
>     >>
>     >> plot(zz,col=colors(zz[3]))
>     >>
>     >> and have a matrix of scatterplots colored by class.  The
>     >> above does not work, of course, but I'm not sure exactly
>     >> what function I'm looking for.
>
>     John> A couple of people have already mentioned that
>     John> specifying col=colors[zz[,3]] will colour the points
>     John> in a scatterplot (not a scatterplot matrix) by the
>     John> values of zz[,3].
>
>yes, even in a scatterplot matrix.
>Try a very slight variation of the above :
>
>   n <- 100
>   zz <- data.frame(Z1 = rnorm(n), Z2 = rnorm(n), Ufact = floor(runif(n)*3+1))
>   colors <- c("red","green","blue")
>   plot(zz, col = colors[zz[, 3]])
>
>i.e., the only practical difference is that I used
>data.frame() instead of
>cbind()
>
>--> which changes things:  The plot() method for a data.frame calls
>pairs() which *is* the same as a scatterplot matrix.
>
>     John>       Since there are just two other
>     John> columns (the third column of zz is ignored in the
>     John> first argument to plot), you get a scatterplot, not a
>     John> scatterplot matrix, and it's hard to see how a
>     John> scatterplot matrix would be relevant.
>
>indeed!
>
>     John> If, however, you want a scatterplot matrix of pairwise
>     John> plots for three or more variables coloured by the
>     John> levels of a factor, the scatterplot.matrix function in
>     John> the car package should do what you want.
>
>I don't see why pairs()  {or as mentioned,  plot( ) for a data.frame}
>shouldn't be sufficient.

Actually, scatterplot.matrix calls pairs; it just makes it simpler (in my 
opinion) to get a graph with features like points plotted with different 
colours and symbols, a legend, univariate displays down the main diagonal, 
concentration ellipses, regression lines, etc.

Regards,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct 17 17:48:48 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Oct 2002 17:48:48 +0200
Subject: [R] Non-central distributions
In-Reply-To: <XFMail.021017162431.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.021017162431.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <x23cr53w2n.fsf@biostat.ku.dk>

(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:

> only the CDF functions 'pt' and 'pf' allow this parameter to
> be set. (If you try in the others, you get the message
> "unused argument(s) (ncp ...)").
> 
> Why is this? Being able to set it would be just as useful ...

We don't have any references on how to calculate them! (Except for the
brute-force approaches of numeric differentiation, root finding, and
transformation of uniform distributions.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From f0z6305 at labs.tamu.edu  Thu Oct 17 17:56:28 2002
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu, 17 Oct 2002 10:56:28 -0500
Subject: [R] matrix input
Message-ID: <003501c275f5$c106a270$8bd75ba5@IE.TAMU.EDU>

Hey, all

Will u please tell me how to input a matrix (n x m) A
in R?
I cannot find such commond in the manual.

Thanks a lot.

Fred

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From peter.schlattmann at medizin.fu-berlin.de  Thu Oct 17 18:04:55 2002
From: peter.schlattmann at medizin.fu-berlin.de (Peter Schlattmann)
Date: Thu, 17 Oct 2002 18:04:55 +0200
Subject: [R] weighted nls
Message-ID: <3DAEDFA7.E70F145F@medizin.fu-berlin.de>

Dear all,

within the help file for nonlinear regression an upcoming option 
for optional weights is mentioned. Is this already available?

Thanks a lot!

peter

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From stop4optimal at hotmail.com  Thu Oct 17 18:15:42 2002
From: stop4optimal at hotmail.com (chenwj)
Date: Fri, 18 Oct 2002 00:15:42 +0800
Subject: [R] questions about batch manipulation
Message-ID: <OE67oBDyseVwrblZz0200001b74@hotmail.com>

hi all,

I'm completely new in R, and here are my questions (under windows):

1.  i want to run my four R files (pl1.r -- pl4.r) in batch mode.  i'd like
to write a batch file using Rterm.exe, since i dont get perl installed on my
computer.  My experimental batch file (*.bat) didnt work, which contains the
following lines.  however it works well when i pasted each single line to
run in the command prompt (eg. cmd).  i wonder what's wrong with my batch
file.

D:\R\bin\Rterm.exe --vanilla <d:\work\pl1.r> pl1.out
D:\R\bin\Rterm.exe --vanilla <d:\work\pl2.r> pl2.out
D:\R\bin\Rterm.exe --vanilla <d:\work\pl3.r> pl3.out
D:\R\bin\Rterm.exe --vanilla <d:\work\pl4.r> pl4.out


2. If one of my above R files contains a function from a outside package
(eg. quantreg),  how to load it in command prompt, or how to get the package
loading process involved in my batch file?

Can anyone give me some guide?

thanks a million.

regards,
chenwj
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bjwhitcher at yahoo.co.uk  Thu Oct 17 18:13:23 2002
From: bjwhitcher at yahoo.co.uk (=?iso-8859-1?q?Brandon=20Whitcher?=)
Date: Thu, 17 Oct 2002 17:13:23 +0100 (BST)
Subject: [R] Installing R1.6.0 on SGI
Message-ID: <20021017161323.12282.qmail@web21510.mail.yahoo.com>


I am currently trying to install R 1.6.0 on an SGI Octane running:

> uname -aR

IRIX64 hcu091 6.5 6.5.9m 07201608 IP30

and I am receiving a fatal error during the make step.  Any help in this matter would be greatly appreciated.

Here is the final output from "./configure"...

----------

R is now configured for mips-sgi-irix6.5

Source directory: .

Installation directory: /usr/local

C compiler: gcc -g -O2

C++ compiler: g++ -g -O2

Fortran compiler: g77 -g -O2

X11 support: yes

Gnome support: no

Tcl/Tk support: yes

Readline support: no

R profiling support: yes

R as a shared library: no

Recommended packages: yes

----------

A minor issue is that even though I have installed readline (although in

a nonstandard directory), it is not supporting it.

Here is the fatal error from "make"...

----------

building package 'methods'

all.R is unchanged

../../../library/methods/man/methods.Rd is unchanged

UX:make: INFO: `Makedeps' is up to date.

gcc -I../../../../include -I/usr/freeware/include -g -O2 -c

do_substitute_direct.c -o do_substitute_direct.o

gcc -I../../../../include -I/usr/freeware/include -g -O2 -c

methods_list_dispatch.c -o methods_list_dispatch.o

gcc -I../../../../include -I/usr/freeware/include -g -O2 -c

method_meta_data.c -o method_meta_data.o

gcc -I../../../../include -I/usr/freeware/include -g -O2 -c

slot.c -o slot.o

gcc -I../../../../include -I/usr/freeware/include -g -O2 -c

class_support.c -o class_support.o

gcc -shared -L/usr/local/lib -o methods.so do_substitute_direct.o

methods_list_dispatch.o method_meta_data.o slot.o class_support.o

dumping R code in package 'methods'

Fatal error: The X11 shared library could not be loaded.

The error was 216482:/var/R-1.6.0/bin/R.bin: rld: Fatal Error:

unresolvable symbol in /var/R-1.6.0/modules/R_X11.so: png_set_IHDR

*** Error code 2 (bu21)

*** Error code 1 (bu21)

*** Error code 1 (bu21)

*** Error code 1 (bu21)

*** Error code 1 (bu21)

----------

Brandon Whitcher




---------------------------------
Get a bigger mailbox -- choose a size that fits your needs.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20021017/371cdd61/attachment.html

From Ted.Harding at nessie.mcc.ac.uk  Thu Oct 17 18:13:30 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 17 Oct 2002 17:13:30 +0100 (BST)
Subject: [R] Non-central distributions
In-Reply-To: <x23cr53w2n.fsf@biostat.ku.dk>
Message-ID: <XFMail.021017171330.Ted.Harding@nessie.mcc.ac.uk>

Thanks, Peter! (Must try to give this some thought ...).

Anyway, in this respect R is still ahead of S-Plus, which
doesn't seem to carry ANY non-centrality as standard!
(Except possibly obscurely tucked away in some add-on library).

Ted.

On 17-Oct-02 Peter Dalgaard BSA wrote:
> (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:
> 
>> only the CDF functions 'pt' and 'pf' allow this parameter to
>> be set. (If you try in the others, you get the message
>> "unused argument(s) (ncp ...)").
>> 
>> Why is this? Being able to set it would be just as useful ...
> 
> We don't have any references on how to calculate them! (Except for the
> brute-force approaches of numeric differentiation, root finding, and
> transformation of uniform distributions.)

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 17-Oct-02                                       Time: 17:13:30
------------------------------ XFMail ------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Oct 17 18:27:41 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 17 Oct 2002 17:27:41 +0100 (BST)
Subject: [R] manova with Error?
In-Reply-To: <20021017144650.0e6a1aec.rjvbertin@hotmail.com>
Message-ID: <Pine.LNX.4.31.0210171726070.962-100000@gannet.stats>

manova with Error is not supported: no one has written the code for it.
It took long enough for someone to come up with the code for manova and
for aov with Error!

?Error refers you to aov, not manova.

On Thu, 17 Oct 2002, RenE J.V. Bertin wrote:

> On 17 Oct 2002 13:50:30 +0200, Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> wrote regarding "Re:
> [R] manova with Error?"
>
> Hi,
>
> 8-)
> 8-) This is not my specialty, but could it be that you have an empty error
> 8-) stratum? I.e. if Subject:fac1:fac2 is the entire data set, then there
> 8-) is no DF for the residual error. (If so, try Error(Subject/(fac1+fac2)) )
>
>
> I'm not sure what you mean with "the entire data set". I have one value for obs1 and one for obs2 for each combination of Subject, fac1 and fac2.
>
> I tried your suggestion; got the same error message.
>
> BTW: Would that not also cause problems in a regular anova, with aov?
>
> RenE Bertin.
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Oct 17 18:43:09 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 17 Oct 2002 17:43:09 +0100 (BST)
Subject: [R] 'text' can't find "x"
In-Reply-To: <Pine.LNX.4.44.0210171433560.18626-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.31.0210171741270.2256-100000@gannet.stats>

On Thu, 17 Oct 2002, [iso-8859-1] Gran Brostrm wrote:

> I wanted to add some text to a plot and got (R-1.6.0, Linux):
>
> >  text(x = c(1, 4), y = 5, labels = x)
> Error in text.default(x = c(1766, 1895), y = 5, labels = x) :
>         Object "x" not found
>
> With the default value of 'labels':
>
> >  text(x = c(1, 2), y = 5, labels = seq(along = x))
> Error in seq(along = x) : Object "x" not found
>
> A scoping bug? :)

No, a scoping misunderstanding.  Default arguments are evaluated in the
frame of the function: explicit values in the frame of the caller.

See `S Programming' p.44, for example.

>
> But
>
> >  text(x = c(1, 2), y = 5)
>
> is OK. Doesn't give the labels I want, though. But why does it work, i.e.,
> why is 'x' found in this case and not when I write out the default?
>
> ---
>  Gran Brostrm                    tel: +46 90 786 5223
>  Department of Statistics          fax: +46 90 786 6614
>  Ume University                   http://www.stat.umu.se/egna/gb/
>  SE-90187 Ume, Sweden             e-mail: gb at stat.umu.se
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tebaldi at rap.ucar.edu  Thu Oct 17 18:47:32 2002
From: tebaldi at rap.ucar.edu (Claudia Tebaldi)
Date: Thu, 17 Oct 2002 10:47:32 -0600 (MDT)
Subject: [R] making R-1.6.0 on Linux Debian
Message-ID: <Pine.GSO.4.05.10210171032210.5212-100000@virga.rap.ucar.edu>

I'm running R-1.4.1 on a linux debian (version 2.2) box. 
I've tried to upgrade to R-1.6.0, and the execution of make halts with the
following error messages:

make[4]: Entering directory `/home/tebaldi/R/R-1.6.0/src/library/methods'
dumping R code in package 'methods'
Error in testRversion(descfile) : This package has not been installed
properly
 See the Note in ?library
Execution halted
make[4]: *** [../../../library/methods/R/all.rda] Error 1
make[4]: Leaving directory `/home/tebaldi/R/R-1.6.0/src/library/methods'
make[3]: *** [all] Error 2
make[3]: Leaving directory `/home/tebaldi/R/R-1.6.0/src/library/methods'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/tebaldi/R/R-1.6.0/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/tebaldi/R/R-1.6.0/src'
make: *** [R] Error 1
161.280u 8.410s 2:52.68 98.2%   0+0k 0+0io 545013pf+0w


Something similar happened a few months ago, when I tried to upgrade to
R-1.5.1. At the time the solution suggested was to use the
precompiled binary distribution, available on CRAN.
Turns out, I do not have root privileges and I cannot touch the files in
/etc. At the time I gave up, but now I'd really like to "step up" to the
newer version of R.
I've looked around but I cannot find any help for installing these
precompiled  binary, if not by the 'apt-get' program, 
to which I have no access as simple user of the machine (i.e I cannot add
lines to the files in /etc like it is explained in the
/bin/linux/debian/ReadMe file.


Can someone please either help me with the error message or point
me at instructions on how to install binaries without going through the
apt-... program? I assume they are somewhere, but don't know where!

Thanks in advance

claudia




----------------------------------------------------------------------
claudia tebaldi                                     NCAR  ESIG/RAP
project scientist                                   P.O. Box 3000
M-W       @FL (303) 497-8133                        Boulder, CO 80307
Tu-Th-F   @ML (303) 497-1621                        tebaldi at ucar.edu
--------------------------------------------------------------------------





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Matthew.Pocernich at parsons.com  Thu Oct 17 18:51:24 2002
From: Matthew.Pocernich at parsons.com (Matthew Pocernich)
Date: Thu, 17 Oct 2002 11:51:24 -0500
Subject: [R] Posix Problem, difftime 
Message-ID: <"EXCHDAL06-021017165124Z-32707*/PRMD=Parsons/ADMD= /C=US/"@MHS>

I am having a series of problems using date time data that has been converted into a POSIXt and POSIXlt classes.  I have  hourly time series data from 1900 that has been converted from text data.
 
I assume most of my problems come from a mis-underdanding of the POSIX class.  My matrix named (aa) for this year is approx 8700 by 4.   When I try to calculate the length of posit column ( which is the date and time) I get
 
> length(aa$posit)
[1] 9
 
When I try to combined POSIX columns or manipulate them like matrices, I have problems such as 
 
> cbind(aa$posit, aa$posit)
Error in cbind(...) : cannot create a matrix from these types
 
Ultimately I would like to check to make certain the hourly data is not missing.  I tried doing this using vectors such as difftime(aa$posit, lag(aa$posit)).  This didn't work.  Ultimately I used a for loop, which is very slow and it produces the following error.  The last column is the difference in times between subsequent posit values.  The fourth row shows a 2 hour gap between events.  (This did not happen in any of the other days.  ) 
 
 
     tide               posit diffh y365 diftime
7223 -1.25 1901-10-28 22:00:00  -2.7  301       1
7224 -2.75 1901-10-28 23:00:00  -1.5  301       1
7225 -2.25 1901-10-29 00:00:00   0.5  302       1
7226 -0.25 1901-10-29 01:00:00   2.0  302       2
7227  2.65 1901-10-29 02:00:00   2.9  302       1
 
Any help or suggestions are greatly appreciated.
 
Thanks,
 
Matt 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Oct 17 19:45:50 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 17 Oct 2002 10:45:50 -0700 (PDT)
Subject: [R] 'text' can't find "x"
In-Reply-To: <Pine.LNX.4.44.0210171433560.18626-100000@tal.stat.umu.se>
Message-ID: <Pine.A41.4.44.0210171041120.56050-100000@homer22.u.washington.edu>

On Thu, 17 Oct 2002, [iso-8859-1] Gran Brostrm wrote:

>
> With the default value of 'labels':
>
> >  text(x = c(1, 2), y = 5, labels = seq(along = x))
> Error in seq(along = x) : Object "x" not found
>
> A scoping bug? :)
>
> But
>
> >  text(x = c(1, 2), y = 5)
>
> is OK. Doesn't give the labels I want, though. But why does it work, i.e.,
> why is 'x' found in this case and not when I write out the default?
>

Explicit arguments are evaluated in the calling environment and the value
is passed to the function.  Default arguments are evaluated inside the
function,  so that defaults like seq(along=x) work.

Evaluating explicit arguments inside the function would be a Really Bad
Idea, as you would need to know what variables existed inside the
function.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From edd at debian.org  Thu Oct 17 19:58:07 2002
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 17 Oct 2002 12:58:07 -0500
Subject: [R] making R-1.6.0 on Linux Debian
Message-ID: <E182EuN-0003BW-00@sonny.eddelbuettel.com>



> Something similar happened a few months ago, when I tried to upgrade to
> R-1.5.1. At the time the solution suggested was to use the
> precompiled binary distribution, available on CRAN.
> Turns out, I do not have root privileges and I cannot touch the files in
> /etc. At the time I gave up, but now I'd really like to "step up" to the
> newer version of R.
> I've looked around but I cannot find any help for installing these
> precompiled  binary, if not by the 'apt-get' program, 
> to which I have no access as simple user of the machine (i.e I cannot add
> lines to the files in /etc like it is explained in the
> /bin/linux/debian/ReadMe file.

Given your situation, you might want to try a fudge or two.  

A .deb archive can be opened with the GNU ar archiver (see "man ar") via 
"ar xv foo.deb" That gives you three files, one which is a tarball with 
the actual "package".  You could simply untar this below you home directory
--- and then set R_HOME accordingly in what would be /usr/bin/R.

That said, it might just be easier if you made sure you have the usual
compilers and tools installed, and built a new R locally into a subdir
of your home directory.  

Dirk

-- 
According to the latest figures, 43% of all signatures are totally worthless.   
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tliu at u.washington.edu  Thu Oct 17 20:38:02 2002
From: tliu at u.washington.edu (Ta Liu)
Date: Thu, 17 Oct 2002 11:38:02 -0700 (PDT)
Subject: [R] LAD
Message-ID: <Pine.A41.4.44.0210171135430.92668-100000@dante11.u.washington.edu>


Dear R help list,

Does anyone know where and how to get the LAD estimator in R for the
robustness of linear models? Or it is not even available at all for R?

thanks in advance.




Best,

Ta

----------------------------------
Ta Liu
Postdoctoral Research Associate
Center for Innovation and Research
in  Graduate Education (CIRGE)
UNIVERSITY OF WASHINGTON

M319 Miller
Box 353600
Seattle, Washington, 98195-3600
Tel: (206) 616-6364
Fax (206) 616-6762

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Matthew.Pocernich at parsons.com  Thu Oct 17 20:40:20 2002
From: Matthew.Pocernich at parsons.com (Matthew Pocernich)
Date: Thu, 17 Oct 2002 13:40:20 -0500
Subject: [R] FW: Posix Problem, difftime 
Message-ID: <"EXCHDAL06-021017184020Z-33516*/PRMD=Parsons/ADMD= /C=US/"@MHS>

Okay - using the chron package, I have solved a lot of my problems.  I still get that peculiar result showing a two hour gap in the data at the position indicated below.
 
Thanks, - Matt
 
     tide               posit diffh y365 diftime
7223 -1.25 1901-10-28 22:00:00  -2.7  301       1
7224 -2.75 1901-10-28 23:00:00  -1.5  301       1
7225 -2.25 1901-10-29 00:00:00   0.5  302       1
7226 -0.25 1901-10-29 01:00:00   2.0  302       2
7227  2.65 1901-10-29 02:00:00   2.9  302       1
 
Any help or suggestions are greatly appreciated.
 
Thanks,
 
Matt 
 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Thu Oct 17 21:06:10 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Thu, 17 Oct 2002 12:06:10 -0700 (PDT)
Subject: [R] xyplot(y~x, type="l") with missing values (NA)
In-Reply-To: <20021017095620.A1488@borneo.univ-mlv.fr>
Message-ID: <20021017190610.34668.qmail@web13902.mail.yahoo.com>



This can be called a bug, I think. No easy fix right now, but I'll try to do
something for future versions.

Deepayan

--- Cyril Humbert <humbertc at univ-mlv.fr> wrote:
> With the function plot(x, y, type="l") points are not connected
> when x or y contain a missing value (NA). Is it possible to do
> the same with the lattice function xyplot() ?
> 
> For example:
> 
> 	library(lattice)
> 	x <- c(1, 2, NA, 4, 5)
> 	y <- x
> 	plot(x, y, type="l")
> 	xyplot(y~x, type="l")
> 
> In the first plot, the point 2 is not connected to the point 4
> whereas there are in the second plot.
> 
> Thanks
> -- 
> Cyril 
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Thu Oct 17 21:28:18 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Thu, 17 Oct 2002 12:28:18 -0700 (PDT)
Subject: [R] panel vs subpanel in cloud from lattice library
In-Reply-To: <001501c275e9$a14e7ae0$35892090@ohm.york.ac.uk>
Message-ID: <20021017192818.30728.qmail@web13907.mail.yahoo.com>



--- Rishabh Gupta <rg117 at ohm.york.ac.uk> wrote:
> Hi,
>     Could somebody explain to be the different between the panel and the
> subpanel parameter in the cloud function of the lattice
> library. I'm not sure when to use which.

The panel function is supposed to draw everything inside a panel. In the case
of cloud, this would mean the surrounding box, the arrows/scales, etc (i.e.,
the part of the plot that doesn't depend on the data), and also, the data. If
the panel function can do this itself, that's fine. It just so happens that
panel.cloud has an argument called subpanel (defaults to panel.xyplot) which it
uses to draw the data after determining the 2d projections of the 3d data. If
you specify subpanel in the call to cloud, it is ignored by cloud and is passed
to the panel function (as is any other argument it doesn't recognize).

Hope that explains things.

Now, panel.cloud in the current version of lattice is very messy, but has been
cleaned up considerably in the next version (which should be released soon). So
if you want to write new panel functions, you should probably wait till then.

Deepayan 



__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Robert.Schick at noaa.gov  Thu Oct 17 21:39:08 2002
From: Robert.Schick at noaa.gov (Robert Schick)
Date: Thu, 17 Oct 2002 12:39:08 -0700
Subject: [R] Newbie Time Series Questions
Message-ID: <3DAF11DC.2C6470F7@noaa.gov>

I have a data set of monthly river flows from 1960-2000, which are
similar in structure to the nottem data:

> klam.flow
      Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
1961 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
1962 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
...

I tried plotting with 

> ts.plot(klam.flow)

Which quickly led me to realize the data aren't a "ts" object, as it
plotted 40 stacked lines instead of one long series. I've tried
converting to this using ts or as.ts, e.g.

> klam.ts <- ts(data=klam.flow, start=1960,end=2000, frequency=12)

But this seems to explode the number of time series, e.g.

> klam.ts
          Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
Jan 1960 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
Feb 1960 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
Mar 1960 2511 2852 3661 2103 2189  2548 3841 2937  857  743 1058 1574
...

Any advice on how to properly create the ts object so it looks and plots
a la Figure 13.15 in VR?

I'm using R 1.60 on a Windows 2000 box.

Thanks
-- 
Rob Schick
Research Associate
NOAA Fisheries
Santa Cruz Lab
110 Shaffer Road
Santa Cruz, CA 95060
Phone: 831.420.3960
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at cbs.dtu.dk  Thu Oct 17 22:57:58 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Thu, 17 Oct 2002 22:57:58 +0200
Subject: [R] Installing R1.6.0 on SGI
In-Reply-To: <20021017161323.12282.qmail@web21510.mail.yahoo.com>
References: <20021017161323.12282.qmail@web21510.mail.yahoo.com>
Message-ID: <20021017205758.GA31386@giraffa.cbs.dtu.dk>

On Thu, Oct 17, 2002 at 05:13:23PM +0100, Brandon Whitcher wrote:
> 
> I am currently trying to install R 1.6.0 on an SGI Octane running:
> 
> > uname -aR
> 
> IRIX64 hcu091 6.5 6.5.9m 07201608 IP30
> 
> and I am receiving a fatal error during the make step.  Any help in this matter would be greatly appreciated.
> 
> Here is the final output from "./configure"...
> 
> ----------
> 
> R is now configured for mips-sgi-irix6.5
> 
> Source directory: .
> 
> Installation directory: /usr/local
> 
> C compiler: gcc -g -O2
> 
> C++ compiler: g++ -g -O2
> 
> Fortran compiler: g77 -g -O2
> 
> X11 support: yes
> 
> Gnome support: no
> 
> Tcl/Tk support: yes
> 
> Readline support: no
> 
> R profiling support: yes
> 
> R as a shared library: no
> 
> Recommended packages: yes
> 
> ----------
> 
> A minor issue is that even though I have installed readline (although in
> 
> a nonstandard directory), it is not supporting it.
> 
> Here is the fatal error from "make"...
> 

You can check what is going on with readline in configure.log I think.
You can also use the file config.site to specify odd places 
(ex:  CPPFLAGS="-I/usr/freeware/include -I/usr/local/include" )


> ----------
> 
> building package 'methods'
> 
> all.R is unchanged
> 
> ../../../library/methods/man/methods.Rd is unchanged
> 
> UX:make: INFO: `Makedeps' is up to date.
> 
> gcc -I../../../../include -I/usr/freeware/include -g -O2 -c
> 
> do_substitute_direct.c -o do_substitute_direct.o
> 
> gcc -I../../../../include -I/usr/freeware/include -g -O2 -c
> 
> methods_list_dispatch.c -o methods_list_dispatch.o
> 
> gcc -I../../../../include -I/usr/freeware/include -g -O2 -c
> 
> method_meta_data.c -o method_meta_data.o
> 
> gcc -I../../../../include -I/usr/freeware/include -g -O2 -c
> 
> slot.c -o slot.o
> 
> gcc -I../../../../include -I/usr/freeware/include -g -O2 -c
> 
> class_support.c -o class_support.o
> 
> gcc -shared -L/usr/local/lib -o methods.so do_substitute_direct.o
> 
> methods_list_dispatch.o method_meta_data.o slot.o class_support.o
> 
> dumping R code in package 'methods'
> 
> Fatal error: The X11 shared library could not be loaded.
> 
> The error was 216482:/var/R-1.6.0/bin/R.bin: rld: Fatal Error:
> 
> unresolvable symbol in /var/R-1.6.0/modules/R_X11.so: png_set_IHDR
> 
> *** Error code 2 (bu21)
> 
> *** Error code 1 (bu21)
> 
> *** Error code 1 (bu21)
> 
> *** Error code 1 (bu21)
> 
> *** Error code 1 (bu21)
> 


I do not know about this particular one (neither I tried to install
1.6.0 on a SGI), sorry...
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fredrik.karlsson at ling.umu.se  Thu Oct 17 22:16:53 2002
From: fredrik.karlsson at ling.umu.se (Fredrik Karlsson)
Date: Thu, 17 Oct 2002 22:16:53 +0200
Subject: [R] Database newbee problem...
In-Reply-To: <20021016085508.A20312@jessie.research.bell-labs.com>
References: <20021016051109.GA25176@ling.umu.se> <20021016085508.A20312@jessie.research.bell-labs.com>
Message-ID: <20021017201653.GA9443@ling.umu.se>

Hi and thank you all for your quick response,

Indeed, the version of R I am working on is 1.6.0 on a Debian Woody
 (stable) system. All the client and server MySQL packages report version 
 3.23.49-8. According to the MySQL web page, the current stable version of 
MySQL is 3.23.53. Development release is 4.0.4.

Could anyone please advice me on a version of MySQL that does work. 
For me, the important thing is to get a working MySQL <-> R connection
going.

Thanks!

/Fredrik


On Wed, Oct 16, 2002 at 08:55:08AM -0400, David James wrote:
> Hi Fredrik,
> 
> I've heard people running Debian having this problem, but
> I have only access to solaris, red-hat, and Irix systems.
> Could you tell me the exact versions of R (1.6.0, I presume),
> MySQL client and server?
> 
> thanks,
> 
> --
> David
> 
> Fredrik Karlsson wrote:
> > Hi all,
> > 
> > 
> > This is a potentially very stupid question about MySQL <-> R
> > interaction, but I have not been able to solve it.
> > I'm just trying to connect R to my MySQL databse, and gets this:
> > 
> > > library(RMySQL)
> > Loading required package: methods 
> > > m <- dbDriver("MySQL")
> > > con <- dbConnect(m,group="testdb")
> > 
> > Process R segmentation fault at Wed Oct 16 07:04:30 2002
> > 
> > My .my.conf contains this:
> > 
> > [client]
> > user = zak
> > host = localhost
> > password=<something>
> > 
> > [rs-dbi]
> > database = sdata
> > 
> > [testdb]
> > host = localhost
> > database = testDB
> > 
> > and connecting through the mysql client is no problem using those
> > settings:
> > 
> > $ mysql 
> > Welcome to the MySQL monitor.  Commands end with ; or \g.
> > Your MySQL connection id is 34 to server version: 3.23.49-log
> > 
> > Type 'help;' or '\h' for help. Type '\c' to clear the buffer.
> > 
> > mysql> use testDB
> > Reading table information for completion of table and column names
> > You can turn off this feature to get a quicker startup with -A
> > 
> > Database changed
> > mysql> show tables;
> > 
> > +------------------+
> > | Tables_in_testDB |
> > +------------------+
> > | pet              |
> > +------------------+
> > 1 row in set (0.00 sec)
> > 
> > mysql>
> > 
> > 
> > What's wrong with my setup that's causing R to segfault (but not mysql
> > client)?
> > Any ideas?
> > 
> > /Fredrik
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 
> -- 
> David A. James
> Statistics Research, Room 2C-253            Phone:  (908) 582-3082       
> Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
> Murray Hill, NJ 09794-0636
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Thu Oct 17 22:15:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 17 Oct 2002 15:15:03 -0500
Subject: [R] making R-1.6.0 on Linux Debian
In-Reply-To: <Pine.GSO.4.05.10210171032210.5212-100000@virga.rap.ucar.edu>
References: <Pine.GSO.4.05.10210171032210.5212-100000@virga.rap.ucar.edu>
Message-ID: <6ry98wyg8o.fsf@bates4.stat.wisc.edu>

Claudia Tebaldi <tebaldi at rap.ucar.edu> writes:

> I'm running R-1.4.1 on a linux debian (version 2.2) box. 
> I've tried to upgrade to R-1.6.0, and the execution of make halts with the
> following error messages:
> 
> make[4]: Entering directory `/home/tebaldi/R/R-1.6.0/src/library/methods'
> dumping R code in package 'methods'
> Error in testRversion(descfile) : This package has not been installed
> properly
>  See the Note in ?library
> Execution halted
> make[4]: *** [../../../library/methods/R/all.rda] Error 1
> make[4]: Leaving directory `/home/tebaldi/R/R-1.6.0/src/library/methods'
> make[3]: *** [all] Error 2
> make[3]: Leaving directory `/home/tebaldi/R/R-1.6.0/src/library/methods'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/home/tebaldi/R/R-1.6.0/src/library'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/tebaldi/R/R-1.6.0/src'
> make: *** [R] Error 1
> 161.280u 8.410s 2:52.68 98.2%   0+0k 0+0io 545013pf+0w
> 
> 
> Something similar happened a few months ago, when I tried to upgrade to
> R-1.5.1. At the time the solution suggested was to use the
> precompiled binary distribution, available on CRAN.
> Turns out, I do not have root privileges and I cannot touch the files in
> /etc. At the time I gave up, but now I'd really like to "step up" to the
> newer version of R.
> I've looked around but I cannot find any help for installing these
> precompiled  binary, if not by the 'apt-get' program, 
> to which I have no access as simple user of the machine (i.e I cannot add
> lines to the files in /etc like it is explained in the
> /bin/linux/debian/ReadMe file.
> 
> 
> Can someone please either help me with the error message or point
> me at instructions on how to install binaries without going through the
> apt-... program? I assume they are somewhere, but don't know where!

My suggestion would be to download the .deb files and run

 dpkg --inst=~ -i *.deb

The manual page for dpkg says

       --root=dir | --admindir=dir | --instdir=dir
              Change default directories.  admindir defaults to  /var/lib/dpkg
              and  contains  many  files that give information about status of
              installed or uninstalled packages, etc.  instdir defaults  to  /
              and  refers to the directory where packages are to be installed.
              instdir is also the directory passed to chroot(2) before running
              package's installation scripts, which means that the scripts see
              instdir as a root directory.  Changing root changes  instdir  to
              dir and admindir to dir/var/lib/dpkg.

I haven't tried this myself.  Debian experts such as Dirk Eddelbuettel
or Tony Rossini may be able to suggest an easier method.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Thu Oct 17 09:22:04 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 17 Oct 2002 20:22:04 +1300
Subject: [R] Posix Problem, difftime
In-Reply-To: <"EXCHDAL06-021017165124Z-32707*/PRMD=Parsons/ADMD= /C=US/"@MHS>; from Matthew.Pocernich@parsons.com on Thu, Oct 17, 2002 at 11:51:24AM -0500
References: <"EXCHDAL06-021017165124Z-32707*/PRMD=Parsons/ADMD= /C=US/"@MHS>
Message-ID: <20021017202204.A2394@camille.indigoindustrial.co.nz>

On Thu, Oct 17, 2002 at 11:51:24AM -0500, Matthew Pocernich wrote:
... [trouble with POSIX date/time classes] ...

> I assume most of my problems come from a mis-underdanding of the POSIX class.  My matrix named (aa) for this year is approx 8700 by 4.   When I try to calculate the length of posit column ( which is the date and time) I get

Judging by the different column types this looks more like a data frame than
a matrix - minor picky point, but computers are even pickier ;-).

> > length(aa$posit)
> [1] 9

Correct.  aa$posit is a POSIXlt structure, which is effectively a 9 element list. 
Each list element is a vector as long as the number of rows in your data.frame.

Using the aa you've provided (data frame with 5 rows):

> length(aa$posit)  #gives list length - POSIXlt objects have 9 list elements.
[1] 9
> length(as.character(aa$posit)) #convert to string dates, then get length
[1] 5
> lapply(aa$posit,length)  #get length of every list member
$sec
[1] 5

$min
[1] 5

$hour
[1] 5

$mday
[1] 5

$mon
[1] 5

$year
[1] 5

$wday
[1] 5

$yday
[1] 5

$isdst
[1] 5

> When I try to combined POSIX columns or manipulate them like matrices, I have problems such as 
>  
> > cbind(aa$posit, aa$posit)
> Error in cbind(...) : cannot create a matrix from these types

Yes.  cbind works nicly with vectors of atomic data types.  It gets a little hairy with
lists.

> Ultimately I would like to check to make certain the hourly data is not missing.  ...
> Ultimately I used a for loop, which is very slow and it produces the following error.  

As Larry Wall once said in answer to a perl question: 

Q. Why is this so clumsy?
A. The trick is to use [the language's] strengths rather than its weaknesses.
             -- Larry Wall in <8225 at jpl-devvax.JPL.NASA.GOV>

What's below works using R's wonderful indexing, with difftime.  Note that the first
element of the list is more properly NA than 0; there is no "before-the-first" 
observation, so time difference makes no sense for the first.

> aa
   tide               posit diffh y365
1 -1.25 1901-10-28 22:00:00  -2.7  301
2 -2.75 1901-10-28 23:00:00  -1.5  301
3 -2.25 1901-10-29 00:00:00   0.5  302
4 -0.25 1901-10-29 01:00:00   2.0  302
5  2.65 1901-10-29 02:00:00   2.9  302

> n.obs <- nrow(aa)  #the number of rows - just a convenience thing.
> n.obs  #check it.
[1] 5
> aa$difftime <- c(NA,difftime(aa$posit[2:n.obs],aa$posit[1:(n.obs-1)]))
> aa
   tide               posit diffh y365 difftime
1 -1.25 1901-10-28 22:00:00  -2.7  301       NA
2 -2.75 1901-10-28 23:00:00  -1.5  301        1
3 -2.25 1901-10-29 00:00:00   0.5  302        1
4 -0.25 1901-10-29 01:00:00   2.0  302        1
5  2.65 1901-10-29 02:00:00   2.9  302        1

# a quick check on which rows had difftime not equal to 1:
> aa[which(aa$difftime != 1),]
[1] tide     posit    diffh    y365     difftime
<0 rows> (or 0-length row.names)


[side issue, to answer the question that's probably in your head now:
"why are dates so hard in R?"]

Dates and times are implemented very thorougly and very solidly
in R.  

Dates and times themselves have a ludicrous, irrational, irregular 
structure, and are probably the hardest sticking point in any piece 
of programming.  Anything that handles dates solidly and in generality 
is going to be hard.  Even worse, differnt operating systems and 
programming environments all had their own, uh, "clever" solutions.  
Integrating this, and making it work the same way no matter where R 
is running is a very, very difficult thing.

Believe it or not, R makes dates and times much, much easier.
If it seems to have some bizarre corners, it's because dates and
times have some very very strange twists.

So, let me just thank Brian D. Ripley and Kurt Hornik once again 
for the wonderful job they've done on the date/time classes.
Good work, guys.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Thu Oct 17 09:36:27 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 17 Oct 2002 20:36:27 +1300
Subject: [R] matrix input
In-Reply-To: <003501c275f5$c106a270$8bd75ba5@IE.TAMU.EDU>; from f0z6305@labs.tamu.edu on Thu, Oct 17, 2002 at 10:56:28AM -0500
References: <003501c275f5$c106a270$8bd75ba5@IE.TAMU.EDU>
Message-ID: <20021017203627.C2394@camille.indigoindustrial.co.nz>

On Thu, Oct 17, 2002 at 10:56:28AM -0500, Feng Zhang wrote:
> Hey, all
> 
> Will u please tell me how to input a matrix (n x m) A
> in R?
> I cannot find such commond in the manual.

Weird.  I found it hard to miss.  Where did you look?

By "input" what do you mean?  Type it in from the R-prompt, or read
it off a disk, download from a url connection, load it from a database
server, copy it from an SAS export file, or ...

I think the two most likely questions you're trying to ask are
1) type it in.  For example:
A <- matrix(c(1,2,4,5,6,9),nrow=2)

2) read it off disk.
For that, you'll need the R Data Import/Export Manual that
came with your R distribution.  If you can't find that,
look here:

http://cran.r-project.org/doc/manuals/R-data.pdf

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zeileis at ci.tuwien.ac.at  Thu Oct 17 22:39:10 2002
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Thu, 17 Oct 2002 22:39:10 +0200
Subject: [R] Newbie Time Series Questions
References: <3DAF11DC.2C6470F7@noaa.gov>
Message-ID: <3DAF1FEE.B6A51C68@ci.tuwien.ac.at>

Robert Schick wrote:
> 
> I have a data set of monthly river flows from 1960-2000, which are
> similar in structure to the nottem data:
> 
> > klam.flow
>       Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
> 1961 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
> 1962 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
> ...
> 
> I tried plotting with
> 
> > ts.plot(klam.flow)
> 
> Which quickly led me to realize the data aren't a "ts" object, as it
> plotted 40 stacked lines instead of one long series. I've tried
> converting to this using ts or as.ts, e.g.
> 
> > klam.ts <- ts(data=klam.flow, start=1960,end=2000, frequency=12)

If I understand your data correctly they start in October 1961? Then you
should do something like

R> klam.flow2 <- ts(as.vector(t(klam.flow)), start = c(1961, 10), freq =
12)
R> plot(klam.flow2)

This turns your time series to one long vector first and then adds the
"ts" properties.
Z

> But this seems to explode the number of time series, e.g.
> 
> > klam.ts
>           Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
> Jan 1960 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
> Feb 1960 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
> Mar 1960 2511 2852 3661 2103 2189  2548 3841 2937  857  743 1058 1574
> ...
> 
> Any advice on how to properly create the ts object so it looks and plots
> a la Figure 13.15 in VR?
> 
> I'm using R 1.60 on a Windows 2000 box.
> 
> Thanks
> --
> Rob Schick
> Research Associate
> NOAA Fisheries
> Santa Cruz Lab
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: 831.420.3960
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Thu Oct 17 22:44:45 2002
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 17 Oct 2002 13:44:45 -0700
Subject: [R] Posix Problem, difftime
In-Reply-To: <"EXCHDAL06-021017165124Z-32707*/PRMD=Parsons/ADMD=
 /C=US/"@MHS>
References: <"EXCHDAL06-021017165124Z-32707*/PRMD=Parsons/ADMD=
 /C=US/"@MHS>
Message-ID: <p05111a08b9d4ceb6c982@[128.115.153.6]>

Your first step would be to use POSIXct, not POSIXlt.
POSIXlt objects are actually lists, and cbind() doesn't have meaning for lists.
POSIXct objects are actually numeric vectors, so they can be combined 
into matrices.

However, matrices are either numeric or character, so POSIXct objects 
combined into a matrix will get displayed in their numeric form:

>  cbind(ISOdatetime(2002,1:2,3,13,0, 0),ISOdatetime(2001,1:2,3,13,0,0))
            [,1]      [,2]
[1,] 1010091600 978555600
[2,] 1012770000 981234000

Checking for missing hours is pretty easy with POSIXct objects:

>  foo <- ISOdatetime(1901,1,2,c(11:14,16:18),0,0)

>  foo
[1] "1901-01-02 11:00:00 PST" "1901-01-02 12:00:00 PST" "1901-01-02 
13:00:00 PST" "1901-01-02 14:00:00 PST" "1901-01-02 16:00:00 PST"
[6] "1901-01-02 17:00:00 PST" "1901-01-02 18:00:00 PST"

>  diff(as.numeric(foo))
[1] 3600 3600 3600 7200 3600 3600

>  any(diff(as.numeric(foo)) != 3600)
[1] TRUE

Because an hour = 3600 seconds.

Regarding the 2 hour interval, have you considered that there may be 
a transition from daylight savings time to standard time? I don't 
know if that was in effect in 1901 in whatever timezone you're in, 
and if it was, whether 29 Oct was the day of transition, but it's 
worth considering. Other than that, in order to help, I'd have to see 
what your data looked like before it was in R, and what code you used 
to convert it to POSIXt.

-Don

At 11:51 AM -0500 10/17/02, Matthew Pocernich wrote:
>I am having a series of problems using date time data that has been 
>converted into a POSIXt and POSIXlt classes.  I have  hourly time 
>series data from 1900 that has been converted from text data.
>
>I assume most of my problems come from a mis-underdanding of the 
>POSIX class.  My matrix named (aa) for this year is approx 8700 by 
>4.   When I try to calculate the length of posit column ( which is 
>the date and time) I get
>
>>  length(aa$posit)
>[1] 9
>

Because it's a list with 9 elements. Try unclass(aa$posit) to see.

>When I try to combined POSIX columns or manipulate them like 
>matrices, I have problems such as
>
>>  cbind(aa$posit, aa$posit)
>Error in cbind(...) : cannot create a matrix from these types
>
>Ultimately I would like to check to make certain the hourly data is 
>not missing.  I tried doing this using vectors such as 
>difftime(aa$posit, lag(aa$posit)).  This didn't work.  Ultimately I 
>used a for loop, which is very slow and it produces the following 
>error.  The last column is the difference in times between 
>subsequent posit values.  The fourth row shows a 2 hour gap between 
>events.  (This did not happen in any of the other days.  )
>
>
>      tide               posit diffh y365 diftime
>7223 -1.25 1901-10-28 22:00:00  -2.7  301       1
>7224 -2.75 1901-10-28 23:00:00  -1.5  301       1
>7225 -2.25 1901-10-29 00:00:00   0.5  302       1
>7226 -0.25 1901-10-29 01:00:00   2.0  302       2
>7227  2.65 1901-10-29 02:00:00   2.9  302       1
>
>Any help or suggestions are greatly appreciated.
>
>Thanks,
>
>Matt
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From f0z6305 at labs.tamu.edu  Thu Oct 17 22:56:09 2002
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu, 17 Oct 2002 15:56:09 -0500
Subject: [R] Nonlinear PCA function
Message-ID: <01a101c2761f$9ea432e0$8bd75ba5@IE.TAMU.EDU>

Hey, all

Do you know if there are some Nonlinear PCA algorithm
or functions provided by R package?

Now I am working on this and want to see if somebody already did this by R
language.

Thanks a lot.

Fred

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From robert.schick at noaa.gov  Thu Oct 17 23:04:10 2002
From: robert.schick at noaa.gov (Robert Schick)
Date: Thu, 17 Oct 2002 14:04:10 -0700
Subject: [R] Newbie Time Series Questions
References: <3DAF11DC.2C6470F7@noaa.gov> <3DAF1FEE.B6A51C68@ci.tuwien.ac.at>
Message-ID: <3DAF25CA.673E45AC@noaa.gov>

Thanks - That did the trick. Curious why the following doesn't quite
work:
klam.ts <- ts(data=klam.flow, start=c(1960,10), frequency=12)

The above doesn't make the vector.

Rob

Achim Zeileis wrote:
> 
> Robert Schick wrote:
> >
> > I have a data set of monthly river flows from 1960-2000, which are
> > similar in structure to the nottem data:
> >
> > > klam.flow
> >       Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
> > 1961 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
> > 1962 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
> > ...
> >
> > I tried plotting with
> >
> > > ts.plot(klam.flow)
> >
> > Which quickly led me to realize the data aren't a "ts" object, as it
> > plotted 40 stacked lines instead of one long series. I've tried
> > converting to this using ts or as.ts, e.g.
> >
> > > klam.ts <- ts(data=klam.flow, start=1960,end=2000, frequency=12)
> 
> If I understand your data correctly they start in October 1961? Then you
> should do something like
> 
> R> klam.flow2 <- ts(as.vector(t(klam.flow)), start = c(1961, 10), freq =
> 12)
> R> plot(klam.flow2)
> 
> This turns your time series to one long vector first and then adds the
> "ts" properties.
> Z
> 
> > But this seems to explode the number of time series, e.g.
> >
> > > klam.ts
> >           Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
> > Jan 1960 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
> > Feb 1960 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
> > Mar 1960 2511 2852 3661 2103 2189  2548 3841 2937  857  743 1058 1574
> > ...
> >
> > Any advice on how to properly create the ts object so it looks and plots
> > a la Figure 13.15 in VR?
> >
> > I'm using R 1.60 on a Windows 2000 box.
> >
> > Thanks
> > --
> > Rob Schick
> > Research Associate
> > NOAA Fisheries
> > Santa Cruz Lab
> > 110 Shaffer Road
> > Santa Cruz, CA 95060
> > Phone: 831.420.3960
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Rob Schick
Research Associate
NOAA Fisheries
Santa Cruz Lab
110 Shaffer Road
Santa Cruz, CA 95060
Phone: 831.420.3960
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zeileis at ci.tuwien.ac.at  Thu Oct 17 23:08:17 2002
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Thu, 17 Oct 2002 23:08:17 +0200
Subject: [R] Newbie Time Series Questions
References: <3DAF11DC.2C6470F7@noaa.gov> <3DAF1FEE.B6A51C68@ci.tuwien.ac.at> <3DAF25CA.673E45AC@noaa.gov>
Message-ID: <3DAF26C1.E9C8C620@ci.tuwien.ac.at>

Robert Schick wrote:
> 
> Thanks - That did the trick. Curious why the following doesn't quite
> work:
> klam.ts <- ts(data=klam.flow, start=c(1960,10), frequency=12)
> 
> The above doesn't make the vector.

It assumes that klam.flow contains 12 different time series *each* with
frequency 12 and generates a multiple time series of class "mts". This
is what you need if you have for example flow measurements of several
rives or measurements at several locations.
Z

> Rob
> 
> Achim Zeileis wrote:
> >
> > Robert Schick wrote:
> > >
> > > I have a data set of monthly river flows from 1960-2000, which are
> > > similar in structure to the nottem data:
> > >
> > > > klam.flow
> > >       Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
> > > 1961 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
> > > 1962 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
> > > ...
> > >
> > > I tried plotting with
> > >
> > > > ts.plot(klam.flow)
> > >
> > > Which quickly led me to realize the data aren't a "ts" object, as it
> > > plotted 40 stacked lines instead of one long series. I've tried
> > > converting to this using ts or as.ts, e.g.
> > >
> > > > klam.ts <- ts(data=klam.flow, start=1960,end=2000, frequency=12)
> >
> > If I understand your data correctly they start in October 1961? Then you
> > should do something like
> >
> > R> klam.flow2 <- ts(as.vector(t(klam.flow)), start = c(1961, 10), freq =
> > 12)
> > R> plot(klam.flow2)
> >
> > This turns your time series to one long vector first and then adds the
> > "ts" properties.
> > Z
> >
> > > But this seems to explode the number of time series, e.g.
> > >
> > > > klam.ts
> > >           Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
> > > Jan 1960 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
> > > Feb 1960 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
> > > Mar 1960 2511 2852 3661 2103 2189  2548 3841 2937  857  743 1058 1574
> > > ...
> > >
> > > Any advice on how to properly create the ts object so it looks and plots
> > > a la Figure 13.15 in VR?
> > >
> > > I'm using R 1.60 on a Windows 2000 box.
> > >
> > > Thanks
> > > --
> > > Rob Schick
> > > Research Associate
> > > NOAA Fisheries
> > > Santa Cruz Lab
> > > 110 Shaffer Road
> > > Santa Cruz, CA 95060
> > > Phone: 831.420.3960
> > > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > > Send "info", "help", or "[un]subscribe"
> > > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 
> --
> Rob Schick
> Research Associate
> NOAA Fisheries
> Santa Cruz Lab
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: 831.420.3960
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Oct 17 23:27:36 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 17 Oct 2002 14:27:36 -0700 (PDT)
Subject: [R] Posix Problem, difftime 
In-Reply-To: <"EXCHDAL06-021017165124Z-32707*/PRMD=Parsons/ADMD= /C=US/"@MHS>
Message-ID: <Pine.A41.4.44.0210171421450.56050-100000@homer22.u.washington.edu>

On Thu, 17 Oct 2002, Matthew Pocernich wrote:

>  When I try to combined POSIX columns or manipulate them like matrices,
> I have problems such as
>
> > cbind(aa$posit, aa$posit)
> Error in cbind(...) : cannot create a matrix from these types

As it says, you can't create matrix from these types.  Matrices can only
hold numbers or characters. You can create a dataframe.

> Ultimately I would like to check to make certain the hourly data is not
> missing.  I tried doing this using vectors such as difftime(aa$posit,
> lag(aa$posit)).  This didn't work.  Ultimately I used a for loop, which

No, lag() just adjusts the time series attributes of a vector.

You could do
  n<-length(a$posit)
  difftime(a$posit[1:(n-1)],a$posit[2:n])

> is very slow and it produces the following error.  The last column is
> the difference in times between subsequent posit values.  The fourth row
> shows a 2 hour gap between events.  (This did not happen in any of the
> other days.  )
>
>
>      tide               posit diffh y365 diftime
> 7223 -1.25 1901-10-28 22:00:00  -2.7  301       1
> 7224 -2.75 1901-10-28 23:00:00  -1.5  301       1
> 7225 -2.25 1901-10-29 00:00:00   0.5  302       1
> 7226 -0.25 1901-10-29 01:00:00   2.0  302       2
> 7227  2.65 1901-10-29 02:00:00   2.9  302       1
>
> Any help or suggestions are greatly appreciated.

At least in my time zone this is correct.  There was a 2 hour interval
between 1901-10-29 00:00:00 and 1901-10-29 01:00:00.  Note that 1901-10-28
is the last Saturday in October: it was the end of summer time.

> as.POSIXlt(ISOdate(1901,10,29))$isdst
[1] 0
> as.POSIXlt(ISOdate(1901,10,28))$isdst
[1] 1


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From christopher.m.turner at jpmorgan.com  Thu Oct 17 23:29:11 2002
From: christopher.m.turner at jpmorgan.com (christopher.m.turner@jpmorgan.com)
Date: Thu, 17 Oct 2002 17:29:11 -0400
Subject: [R] Newbie Time Series Questions
Message-ID: <OF67DA81B5.A6C9BF96-ON85256C55.00758E10@ny.jpmorgan.com>


Assuming what you are starting with is a matrix or dataframe, with months
as column names and years as rownames, then

      ts(c(t(klam.flow)), start=c(1961, 10), freq=12)

should work.

Chris Turner





|---------+------------------------------>
|         |                              |
|         |           Robert.Schick at noaa.|
|         |           gov                |
|         |           Sent by:           |
|         |           owner-r-help at stat.m|
|         |           ath.ethz.ch        |
|         |                              |
|         |                              |
|         |           10/17/02 03:39 PM  |
|         |                              |
|---------+------------------------------>
  >-------------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                               |
  |        To:      r-help-digest at stat.math.ethz.ch                                                                               |
  |        cc:                                                                                                                    |
  |        Subject: [R] Newbie Time Series Questions                                                                              |
  >-------------------------------------------------------------------------------------------------------------------------------|



I have a data set of monthly river flows from 1960-2000, which are
similar in structure to the nottem data:

> klam.flow
      Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
1961 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
1962 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
...

I tried plotting with

> ts.plot(klam.flow)

Which quickly led me to realize the data aren't a "ts" object, as it
plotted 40 stacked lines instead of one long series. I've tried
converting to this using ts or as.ts, e.g.

> klam.ts <- ts(data=klam.flow, start=1960,end=2000, frequency=12)

But this seems to explode the number of time series, e.g.

> klam.ts
          Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
Jan 1960 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
Feb 1960 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
Mar 1960 2511 2852 3661 2103 2189  2548 3841 2937  857  743 1058 1574
...

Any advice on how to properly create the ts object so it looks and plots
a la Figure 13.15 in VR?

I'm using R 1.60 on a Windows 2000 box.

Thanks
--
Rob Schick
Research Associate
NOAA Fisheries
Santa Cruz Lab
110 Shaffer Road
Santa Cruz, CA 95060
Phone: 831.420.3960
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._





This communication is for informational purposes only.  It is not intended as
an offer or solicitation for the purchase or sale of any financial instrument
or as an official confirmation of any transaction. All market prices, data
and other information are not warranted as to completeness or accuracy and
are subject to change without notice. Any comments or statements made herein
do not necessarily reflect those of J.P. Morgan Chase & Co., its
subsidiaries and affiliates.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chong at stat.purdue.edu  Thu Oct 17 23:30:54 2002
From: chong at stat.purdue.edu (Chong Gu)
Date: Thu, 17 Oct 2002 16:30:54 -0500
Subject: [R] data.frame bug?
Message-ID: <200210172130.g9HLUu6d106484@odds.stat.purdue.edu>


I'd like to create a data frame with components

> jk$x1
[1] 2
> jk$x2
         [,1] [,2]
[1,]    0    0

I used to be able to do it with

> jk <- data.frame(x1=2,x2=I(matrix(0,1,2)))

But now I get a error message.  

Can I still do what I want?  Thanks for any help.

Chong Gu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Thu Oct 17 10:41:25 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 17 Oct 2002 21:41:25 +1300
Subject: [R] Newbie Time Series Questions
In-Reply-To: <3DAF11DC.2C6470F7@noaa.gov>; from Robert.Schick@noaa.gov on Thu, Oct 17, 2002 at 12:39:08PM -0700
References: <3DAF11DC.2C6470F7@noaa.gov>
Message-ID: <20021017214125.B2618@camille.indigoindustrial.co.nz>

On Thu, Oct 17, 2002 at 12:39:08PM -0700, Robert Schick wrote:
> I have a data set of monthly river flows from 1960-2000, which are
> similar in structure to the nottem data:
> 
> > klam.flow
>       Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
> 1961 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
> 1962 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
> ...
> 
> Which quickly led me to realize the data aren't a "ts" object, as it
> plotted 40 stacked lines instead of one long series. I've tried
> converting to this using ts or as.ts, e.g.

looks like a data frame, then.  You've got to R it's not a multivariate
time series; R thinks it's one series for Oct, one for Nov, etc.
So, convert to matrix, and you'll need to:

1) transpose it, so the *column* vectors are sequential in time (by default,
when R unrolls a matrix to a vector, it stacks the columns, not the rows).
2) convert the matrix to a vector, so R knows it's univariate.
3) *then* convert to time series.  whew.  ;-)

klam.ts <- ts(as.vector(t(klam.flow)),frequency=12,start=c(1961,10))

klam.ts
      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec
1961                                              1461 1716 2524
1962 1773 1906 2005 1756 1575 1387  983 1094 1382 1907 2253 1985
1963 1907 1769 1676 2634 1386  929  766  968 1309      

If that's wrong - i.e. each row in klam.flow is one year and the columns
are just in a funny order - you'll have to juggle the columns before step 
1 above.  Like so:

> klam.ts <- ts(as.vector(t(klam.flow[,c(4:12,1:3)])),frequency=12,start=c(1961,1))
> klam.ts
      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec
1961 1773 1906 2005 1756 1575 1387  983 1094 1382 1461 1716 2524
1962 1907 1769 1676 2634 1386  929  766  968 1309 1907 2253 1985

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From roger at ysidro.econ.uiuc.edu  Fri Oct 18 00:06:26 2002
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Thu, 17 Oct 2002 17:06:26 -0500 (CDT)
Subject: [R] LAD
In-Reply-To: <Pine.A41.4.44.0210171135430.92668-100000@dante11.u.washington.edu>
Message-ID: <Pine.GSO.4.33.0210171706010.17928-100000@ysidro.econ.uiuc.edu>

See the quantreg package on CRAN...


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Thu, 17 Oct 2002, Ta Liu wrote:

>
> Dear R help list,
>
> Does anyone know where and how to get the LAD estimator in R for the
> robustness of linear models? Or it is not even available at all for R?
>
> thanks in advance.
>
>
>
>
> Best,
>
> Ta
>
> ----------------------------------
> Ta Liu
> Postdoctoral Research Associate
> Center for Innovation and Research
> in  Graduate Education (CIRGE)
> UNIVERSITY OF WASHINGTON
>
> M319 Miller
> Box 353600
> Seattle, Washington, 98195-3600
> Tel: (206) 616-6364
> Fax (206) 616-6762
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.connolly at hortresearch.co.nz  Fri Oct 18 00:46:36 2002
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Fri, 18 Oct 2002 11:46:36 +1300
Subject: [R] data.frame bug?
In-Reply-To: <200210172130.g9HLUu6d106484@odds.stat.purdue.edu>
References: <200210172130.g9HLUu6d106484@odds.stat.purdue.edu>
Message-ID: <20021017224636.GB15047@hortresearch.co.nz>

On Thu, 17-Oct-2002 at 04:30PM -0500, Chong Gu wrote:

|> 
|> I'd like to create a data frame with components
|> 
|> > jk$x1
|> [1] 2
|> > jk$x2
|>          [,1] [,2]
|> [1,]    0    0
|> 
|> I used to be able to do it with
|> 
|> > jk <- data.frame(x1=2,x2=I(matrix(0,1,2)))
|> 
|> But now I get a error message.  
|> 
|> Can I still do what I want?  Thanks for any help.

Not if you want to call and use it a data frame.  A list as you've
made could still suit your purposes, but if you want a dataframe, it
has to have elements that are of equal lengths.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gu4 at llnl.gov  Fri Oct 18 01:05:40 2002
From: gu4 at llnl.gov (Pauline Gu)
Date: Thu, 17 Oct 2002 16:05:40 -0700
Subject: [R] Installing R1.6.0 on Solaris 5.6
In-Reply-To: <20021017205758.GA31386@giraffa.cbs.dtu.dk>
References: <20021017161323.12282.qmail@web21510.mail.yahoo.com>
 <20021017161323.12282.qmail@web21510.mail.yahoo.com>
Message-ID: <5.1.1.5.2.20021017155952.031aa460@poptop.llnl.gov>

Hello,

I am trying to install R1.6.0 in a 32 bit Sun Solaris 5.6 machine using the 
solaris cc and f77.  The configurations went successful.  But, when I try 
to make, the following error occurs:

config.status: creating src/library/ctest/Makefile
config.status: creating src/library/ctest/DESCRIPTION
building package 'ctest'
mkdir -p -- ../../../library/ctest/R
mkdir -p -- ../../../library/ctest/man
config.status: creating src/library/ctest/src/Makefile
make: Fatal error: Don't know how to make target `ansari.d'
Current working directory /home/pgu/R-1.6.0.32bit/src/library/ctest/src
*** Error code 1
make: Fatal error: Command failed for target `all'
Current working directory /home/pgu/R-1.6.0.32bit/src/library/ctest
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /home/pgu/R-1.6.0.32bit/src/library
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /home/pgu/R-1.6.0.32bit/src
*** Error code 1
make: Fatal error: Command failed for target `R'


Does any body have the same problem?  Can any body help here?

Thanks in advance for your help.

Pauline

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Fri Oct 18 01:20:51 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Thu, 17 Oct 2002 16:20:51 -0700
Subject: [R] Nonlinear PCA function
In-Reply-To: <01a101c2761f$9ea432e0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <13A04A33-E227-11D6-B357-003065A21C86@stat.ucla.edu>

ftp://gifi.stat.ucla.edu/pub/homalsR.tar.gz

but since nonlinear PCA can de defined in various ways,
you may have something different in mind

--- Jan

On Thursday, Oct 17, 2002, at 13:56 US/Pacific, Feng Zhang wrote:

> Hey, all
>
> Do you know if there are some Nonlinear PCA algorithm
> or functions provided by R package?
>
> Now I am working on this and want to see if somebody already did this  
> by R
> language.
>
> Thanks a lot.
>
> Fred
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics
US mail: 8142 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
                  www: http://www.stat.ucla.edu/~deleeuw
======================================================================== 
====
          Remember, wherever you go, there you are. --- Buckaroo Banzai
======================================================================== 
====

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cliff at ms.washington.edu  Fri Oct 18 01:41:59 2002
From: cliff at ms.washington.edu (Cliff Lunneborg)
Date: Thu, 17 Oct 2002 16:41:59 -0700
Subject: [R] Startup on Windows 2000
Message-ID: <006401c27636$c9117030$1f92e40c@C56909A>

I am having difficulty coming to grips with Appendix B.2 of the
otherwise very useful "An Introduction to R" and the related help file
for Startup. I am running RGui 1.6.0 on a Windows 2000 machine from the
default installation. How the concepts discussed in B.2 and the Startup
help file relate to what I see on my machine is something of a mystery.

I quote from the Startup file:

"In R, the startup mechanism is as follows.

Unless --no-environ was given, R searches for user and site files to
process for setting environment variables. The name of the site file is
the one pointed to by the environment variable R\_ENVIRON; if this is
unset, `$R_HOME/etc/Renviron.site' is used. The user files searched for
are `.Renviron' in the current or in the user's home directory (in that
order). See Details for how the files are read."

How can I tell if "--no-environ" was given? I cannot find either
Renviron.site or .Renviron on my system.

Then, Startup continues:

"Then R searches for the site-wide startup profile unless the command
line option --no-site-file was given. The name of this file is taken
from the value of the R\_PROFILE environment variable. If this variable
is unset, the default is `$R_HOME/etc/Rprofile.site'. This code is
loaded into package base."

Can I tell if "--no-site-file" was given? I don't find any object named
Rprofile.site on my machine.

Returning to Startup:

"Then, unless --no-init-file was given, R searches for a file called
`.Rprofile' in the current directory or in the user's home directory (in
that order) and sources it into the user workspace."

Was "--no.init.file" given in the default startup? I cannot find a file
.Rprofile anywhere.

Back to Startup:

"It then loads a saved image of the user workspace from `.RData' if
there
is one (unless --no-restore-data was specified, or --no-restore)."

Since R opens with a saved workspace, I'd guess "--no-restore-data" was
not specified.

"Finally, if a function .First exists, it is executed as .First()."

I located such a function in a Rprofile file. It appears to load the
ctest package.

"The functions .First and .Last can be defined in the appropriate
startup
profiles or reside in `.RData'."

What or where are these appropriate startup profiles?  I located a
second Rprofile file in the \etc folder, but when I added a .First
function there it seemed to override the other .First function. Is that
intentional?

Later in the Startup help:

"Lines in a site or user environment file should be either comment lines
starting with #, or lines of the form name=value. The latter sets the
environmental variable name to value, overriding an existing value. If
value is of the form ${foo-bar}, the value is that of the environmental
variable foo if that exists and is set to a non-empty value, otherwise
bar. This construction can be nested, so bar can be of the same form (as
in ${foo-${bar-blah}})."

Are environment files the same as profile files?

Finally, towards the bottom of the Startup help:

"Examples
## Some examples with a Unix flavour
# ~/.Renviron
R_LIBS=~/R/library
PAGER=/usr/local/bin/less

# .Rprofile
options(width=65, digits=5)
options(show.signif.stars=FALSE)
ps.options(horizontal=FALSE)
set.seed(1234)
.First <- function() cat("\n   Welcome to R!\n\n")
.Last <- function()  cat("\n   Goodbye!\n\n")

## if .Renviron contains
FOOBAR="coo\bar"doh\ex"abc\"def'"

## then we get
> cat(Sys.getenv("FOOBAR"), "\n")
coo\bardoh\exabc"def' "

What would some Windows examples look like?

I love R, and I would really like to learn something more about how it
is being customized for me and how I can (if I should) try to customize
it myself.

Clifford E. Lunneborg
Emeritus Professor, Statistics and Psychology
University of Washington, Seattle
Email: cliff at ms.washington.edu
Phone: 206 364 2013
Fax: 206 366 1078


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Oct 18 01:50:07 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 17 Oct 2002 16:50:07 -0700 (PDT)
Subject: [R] data.frame bug?
In-Reply-To: <200210172130.g9HLUu6d106484@odds.stat.purdue.edu>
Message-ID: <Pine.A41.4.44.0210171646390.56050-100000@homer22.u.washington.edu>

On Thu, 17 Oct 2002, Chong Gu wrote:

>
> I'd like to create a data frame with components
>
> > jk$x1
> [1] 2
> > jk$x2
>          [,1] [,2]
> [1,]    0    0
>
> I used to be able to do it with
>
> > jk <- data.frame(x1=2,x2=I(matrix(0,1,2)))
>
> But now I get a error message.
>

If your computer does what mine does then this isn't what gives an error
message. The error message comes when you print.

>  jk <- data.frame(x1=2,x2=I(matrix(0,1,2)))
> jk
Error in data.frame(x1 = "2", x2 = c("0", "0"), check.names = FALSE,
row.names = "1") :
        row.names should specify one of the variables
> jk$x1
[1] 2
> jk$x2
     [,1] [,2]
[1,]    0    0

and it's caused in format.data.frame by the fact that format(jk[[2]]) is a
vector, not a matrix.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From harvill at math.msstate.edu  Fri Oct 18 02:22:28 2002
From: harvill at math.msstate.edu (Jane L. Harvill)
Date: Thu, 17 Oct 2002 19:22:28 -0500 (CDT)
Subject: [R] Help with DLLs
Message-ID: <Pine.SOL.4.10.10210171914450.4169-100000@ra.msstate.edu>

I'm using R version 1.5.1, and Microsoft Developer Studio 97 (yes, I know
it's old, but it's expensive to upgrade) on Windows 98.  I created the DLL
file with the compiler.  The name of the file containing the subroutine is
leaf.f and the subroutine is named leaf.f. In my R program (which defines
a function called leaf), I have 
	x <- .Fortran("leaf",...)  
where the ... are the arguments passed.  I source("leaf.s"), and then
dyn.load("leaf.dll"), and when I run leaf(100), I get the following error

Error in .Fortran("leaf",as.integer(nn),as.double(u),as.double(A), :
         C/Fortran function name not in load table

Does anyone know what is causing this error message and how to fix the
problem?
Incidentally, the same code works FINE on the Unix version of R, but I was
hoping to transfer it to my PC so that I could use it in a presentation
without having to rely on an unreliable internet connection.

Any words of wisdom are greatly appreciated.

Sincerely,
Jane Harvill



Dr. Jane L. Harvill, Ph.D.
Department of Mathematics and Statistics
Drawer MA
Mississippi State, Mississippi 39762
Phone: (662) 325-3414
FAX:   (662) 325-0005
URL:   http://www2.msstate.edu/~harvill/


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Fri Oct 18 05:07:55 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 17 Oct 2002 23:07:55 -0400
Subject: [R] Nonlinear PCA function
In-Reply-To: <13A04A33-E227-11D6-B357-003065A21C86@stat.ucla.edu>
References: <01a101c2761f$9ea432e0$8bd75ba5@IE.TAMU.EDU>
	<13A04A33-E227-11D6-B357-003065A21C86@stat.ucla.edu>
Message-ID: <20021017230755.1e912573.fharrell@virginia.edu>

On Thu, 17 Oct 2002 16:20:51 -0700
Jan de Leeuw <deleeuw at stat.ucla.edu> wrote:

> ftp://gifi.stat.ucla.edu/pub/homalsR.tar.gz
> 
> but since nonlinear PCA can de defined in various ways,
> you may have something different in mind
> 
> --- Jan
> 
> On Thursday, Oct 17, 2002, at 13:56 US/Pacific, Feng Zhang wrote:
> 
> > Hey, all
> >
> > Do you know if there are some Nonlinear PCA algorithm
> > or functions provided by R package?
> >
> > Now I am working on this and want to see if somebody already did this  
> > by R
> > language.
> >
> > Thanks a lot.
> >
> > Fred

The transcan function in the Hmisc package does nonlinear PCs, or at least it derives the nonlinear transformations you can feed into prcomp or other functions.  See http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html and a case study in my book Regression Modeling Strategies (Springer, 2001).
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Mark.Bravington at csiro.au  Fri Oct 18 05:58:04 2002
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Fri, 18 Oct 2002 14:58:04 +1100
Subject: [R] code to turn T into TRUE
Message-ID: <A8877251964B294BAB5BA1FC58B43FED025B4316@molly.tas.csiro.au>

Does anyone have code that will methodically process R sourcecode, turning
T's into TRUE and F's into FALSE? I got bored doing this by hand, after the
first 30-odd functions-- there are hundreds left to do. I don't want to
simply deparse everything, because that would destroy my beautiful
formatting.

The reason it's not trivial, is that comment lines, quotes, and split lines
need to be kept track of. There are no syntax errors in the code (i.e. it
all parses OK into functions).

The absolute ideal would be if the code itself was in R (because I need to
run this from R), but presumably if there was a Perl script, I could launch
that from within R too.

FWIW I'm running Windows 2000, and hovering between R1.5.1 and R1.6.0.

Thanks for any help

Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington at csiro.au 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bill.Venables at cmis.csiro.au  Fri Oct 18 06:19:26 2002
From: Bill.Venables at cmis.csiro.au (Bill.Venables@cmis.csiro.au)
Date: Fri, 18 Oct 2002 14:19:26 +1000
Subject: [R] Non-central distributions
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A9165572@Roper-CV.qld.cmis.csiro.au>

Ted Harding says:

>  -----Original Message-----
> From: 	Ted.Harding at nessie.mcc.ac.uk
> [mailto:Ted.Harding at nessie.mcc.ac.uk] 
> Sent:	Friday, October 18, 2002 2:14 AM
> To:	Peter Dalgaard BSA
> Cc:	r-help at stat.math.ethz.ch
> Subject:	Re: [R] Non-central distributions
> 
> Thanks, Peter! (Must try to give this some thought ...).
	[WNV]  The density functions for the t and F distributions are in
fact quite easy and only require hypergeometric functions in addition to
standard things.  These could be useful anyway for all sorts of things.
	As far as I know, percentage points of the non-central distributions
are not much used, but what would be very useful would be to have the
percentage points (with respect to the non-centrality parameter) of the
distribution function G(delta) = 1-P(X^2, n, delta), (i.e. you take the
upper tail area as defining a distribution function in delta.  Such a
distributon has a finite probability at the origin, of course.  These are
the quantities you need, for example, for things like sample size
determination and power calculations.

	Random numbers from the non-central distributions are easy enough to
generate, of course, using the central ones.  Again, I'm not sure just how
much slick versions of them would be useful, though.


> Anyway, in this respect R is still ahead of S-Plus, which
> doesn't seem to carry ANY non-centrality as standard!
> (Except possibly obscurely tucked away in some add-on library).
	[WNV]  Tsk tsk, Ted.  They are there for pf and pchisq, at least.

	Bill Venables.

> Ted.
> 
> On 17-Oct-02 Peter Dalgaard BSA wrote:
> > (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:
> > 
> >> only the CDF functions 'pt' and 'pf' allow this parameter to
> >> be set. (If you try in the others, you get the message
> >> "unused argument(s) (ncp ...)").
> >> 
> >> Why is this? Being able to set it would be just as useful ...
> > 
> > We don't have any references on how to calculate them! (Except for the
> > brute-force approaches of numeric differentiation, root finding, and
> > transformation of uniform distributions.)
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 17-Oct-02                                       Time: 17:13:30
> ------------------------------ XFMail ------------------------------
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-
> r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Fri Oct 18 08:45:54 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 18 Oct 2002 08:45:54 +0200
Subject: [R] Non-central distributions
In-Reply-To: <E09E527B56BE2D438A3D6A246DDD27A9165572@Roper-CV.qld.cmis.csiro.au>
References: <E09E527B56BE2D438A3D6A246DDD27A9165572@Roper-CV.qld.cmis.csiro.au>
Message-ID: <15791.44578.187614.230488@gargle.gargle.HOWL>

>>>>> "Bill" == Bill Venables <Bill.Venables at cmis.csiro.au>
>>>>>     on Fri, 18 Oct 2002 14:19:26 +1000 writes:

    Bill> Ted Harding says:
    >> -----Original Message-----
    >> From: 	Ted.Harding at nessie.mcc.ac.uk
    >> Sent:	Friday, October 18, 2002 2:14 AM
    >> To:	Peter Dalgaard BSA
    >> Cc:	r-help at stat.math.ethz.ch
    >> Subject:	Re: [R] Non-central distributions
    >> 
    >> Thanks, Peter! (Must try to give this some thought ...).

    Bill> [WNV] The density functions for the t and F
    Bill> distributions are in fact quite easy and only require
    Bill> hypergeometric functions in addition to standard
    Bill> things.  These could be useful anyway for all sorts of
    Bill> things.  As far as I know, percentage points of the
    Bill> non-central distributions are not much used, but what
    Bill> would be very useful would be to have the percentage
    Bill> points (with respect to the non-centrality parameter)
    Bill> of the distribution function G(delta) = 1-P(X^2, n,
    Bill> delta), (i.e. you take the upper tail area as defining
    Bill> a distribution function in delta.  Such a distributon
    Bill> has a finite probability at the origin, of course.
    Bill> These are the quantities you need, for example, for
    Bill> things like sample size determination and power calculations.

probably an exercise of reading the sections in Johnson et al
(see "HRK" below). I remember having seen quite a few references there.
Contributions are welcome..

    Bill> Random numbers from the non-central distributions are
    Bill> easy enough to generate, of course, using the central
    Bill> ones.  Again, I'm not sure just how much slick
    Bill> versions of them would be useful, though.

In the next major version of R, 1.7.x,
I plan to have finished the code for rchisq(*, ncp = *)
{and possibly for some of  ?chisq(*, df = 0, *) }
thanks to a suggestion from Hans R. Kuensch:

  HRK> I think the help file for the Chisquare distribution should
  HRK> indicate clearly whether df has to be a natural number or can be
  HRK> any positive number. Also I don't understand why rchisq works
  HRK> only in the central case. It should be easy to do the general
  HRK> case by decomposing it as the sum of a central chisquare with df
  HRK> degrees of freedom plus a noncentral chisquare with zero degrees
  HRK> of freedom (which is a Poisson mixture of central chisquares
  HRK> with integer degrees of freedom), see Formula (29.5b-c) in
  HRK> Johnson, Kotz, Balakrishnan (1995).  The noncentral chisquare
  HRK> with arbitary degrees of freedom is of interest for simulating
  HRK> the Cox-Ingersoll-Ross model for interest rates in finance.


    >> Anyway, in this respect R is still ahead of S-Plus, which
    >> doesn't seem to carry ANY non-centrality as standard!
    >> (Except possibly obscurely tucked away in some add-on library).

    Bill> [WNV]  Tsk tsk, Ted.  They are there for pf and pchisq, at least.

     [ but of course, R is still ahead  ;-) ;-) ]

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 18 08:49:18 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 18 Oct 2002 07:49:18 +0100 (BST)
Subject: [R] Startup on Windows 2000
In-Reply-To: <006401c27636$c9117030$1f92e40c@C56909A>
Message-ID: <Pine.LNX.4.31.0210180739410.2899-100000@gannet.stats>

Unfortunately the Startup.Rd file was written for Unix, and in 1.6.0 is
not accurate for other platforms.  It has been altered in R-patched.

On Thu, 17 Oct 2002, Cliff Lunneborg wrote:

> I am having difficulty coming to grips with Appendix B.2 of the
> otherwise very useful "An Introduction to R" and the related help file
> for Startup. I am running RGui 1.6.0 on a Windows 2000 machine from the
> default installation. How the concepts discussed in B.2 and the Startup
> help file relate to what I see on my machine is something of a mystery.
>
> I quote from the Startup file:
>
> "In R, the startup mechanism is as follows.
>
> Unless --no-environ was given, R searches for user and site files to
> process for setting environment variables. The name of the site file is
> the one pointed to by the environment variable R\_ENVIRON; if this is
> unset, `$R_HOME/etc/Renviron.site' is used. The user files searched for
> are `.Renviron' in the current or in the user's home directory (in that
> order). See Details for how the files are read."
>
> How can I tell if "--no-environ" was given? I cannot find either
> Renviron.site or .Renviron on my system.

The files need not exist, and are only used if they do exist.  *You* gave
the command line so you specified --no-environ or not.

$R_HOME/etc/Renviron.site is only used on Unix: that was a documentation
error.

> Then, Startup continues:
>
> "Then R searches for the site-wide startup profile unless the command
> line option --no-site-file was given. The name of this file is taken
> from the value of the R\_PROFILE environment variable. If this variable
> is unset, the default is `$R_HOME/etc/Rprofile.site'. This code is
> loaded into package base."
>
> Can I tell if "--no-site-file" was given? I don't find any object named
> Rprofile.site on my machine.

Same answer.  Rprofile.site is intended for R code to be run initially for
all users and all usages of that R installation, e.g. to load local
package.

> Returning to Startup:
>
> "Then, unless --no-init-file was given, R searches for a file called
> `.Rprofile' in the current directory or in the user's home directory (in
> that order) and sources it into the user workspace."
>
> Was "--no.init.file" given in the default startup? I cannot find a file
> .Rprofile anywhere.

Same answer.

> Back to Startup:
>
> "It then loads a saved image of the user workspace from `.RData' if
> there
> is one (unless --no-restore-data was specified, or --no-restore)."
>
> Since R opens with a saved workspace, I'd guess "--no-restore-data" was
> not specified.

Same answer.

> "Finally, if a function .First exists, it is executed as .First()."
>
> I located such a function in a Rprofile file. It appears to load the
> ctest package.

Yes, but you can put such an object earlier in the search path and so
override that one.

> "The functions .First and .Last can be defined in the appropriate
> startup
> profiles or reside in `.RData'."
>
> What or where are these appropriate startup profiles?

Rprofile.site, .Rprofile.

> I located a
> second Rprofile file in the \etc folder, but when I added a .First
> function there it seemed to override the other .First function. Is that
> intentional?

Yes.  Most things in R are intentional!

> Later in the Startup help:
>
> "Lines in a site or user environment file should be either comment lines
> starting with #, or lines of the form name=value. The latter sets the
> environmental variable name to value, overriding an existing value. If
> value is of the form ${foo-bar}, the value is that of the environmental
> variable foo if that exists and is set to a non-empty value, otherwise
> bar. This construction can be nested, so bar can be of the same form (as
> in ${foo-${bar-blah}})."
>
> Are environment files the same as profile files?

No, that's why the names are different (and the examples given are
different).  An environment file is like .Renviron, and is described in
the Details section (as the help file says).  A profile file contains R
code.

> Finally, towards the bottom of the Startup help:
>
> "Examples
> ## Some examples with a Unix flavour
> # ~/.Renviron
> R_LIBS=~/R/library
> PAGER=/usr/local/bin/less
>
> # .Rprofile
> options(width=65, digits=5)
> options(show.signif.stars=FALSE)
> ps.options(horizontal=FALSE)
> set.seed(1234)
> .First <- function() cat("\n   Welcome to R!\n\n")
> .Last <- function()  cat("\n   Goodbye!\n\n")
>
> ## if .Renviron contains
> FOOBAR="coo\bar"doh\ex"abc\"def'"
>
> ## then we get
> > cat(Sys.getenv("FOOBAR"), "\n")
> coo\bardoh\exabc"def' "
>
> What would some Windows examples look like?

.Rprofile the same.
.Renviron

R_LIBS=c:/R/library


> I love R, and I would really like to learn something more about how it
> is being customized for me and how I can (if I should) try to customize
> it myself.

Some of this is in the rw-FAQ, including the use of .Renviron.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Fri Oct 18 08:59:10 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 18 Oct 2002 08:59:10 +0200
Subject: [R] Help with DLLs
References: <Pine.SOL.4.10.10210171914450.4169-100000@ra.msstate.edu>
Message-ID: <3DAFB13E.7FC86AE@statistik.uni-dortmund.de>



"Jane L. Harvill" wrote:
> 
> I'm using R version 1.5.1, and Microsoft Developer Studio 97 (yes, I know
> it's old, but it's expensive to upgrade) on Windows 98.  I created the DLL
> file with the compiler.  The name of the file containing the subroutine is
> leaf.f and the subroutine is named leaf.f. In my R program (which defines
> a function called leaf), I have
>         x <- .Fortran("leaf",...)

If your subroutine is called "leaf.f", it's a good idea to call this
one, but not "leaf".

Uwe Ligges


> where the ... are the arguments passed.  I source("leaf.s"), and then
> dyn.load("leaf.dll"), and when I run leaf(100), I get the following error
> 
> Error in .Fortran("leaf",as.integer(nn),as.double(u),as.double(A), :
>          C/Fortran function name not in load table
> 
> Does anyone know what is causing this error message and how to fix the
> problem?
> Incidentally, the same code works FINE on the Unix version of R, but I was
> hoping to transfer it to my PC so that I could use it in a presentation
> without having to rely on an unreliable internet connection.
> 
> Any words of wisdom are greatly appreciated.
> 
> Sincerely,
> Jane Harvill
> 
> Dr. Jane L. Harvill, Ph.D.
> Department of Mathematics and Statistics
> Drawer MA
> Mississippi State, Mississippi 39762
> Phone: (662) 325-3414
> FAX:   (662) 325-0005
> URL:   http://www2.msstate.edu/~harvill/
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Fri Oct 18 08:58:59 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 18 Oct 2002 08:58:59 +0200
Subject: [R] code to turn T into TRUE
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED025B4316@molly.tas.csiro.au>
References: <A8877251964B294BAB5BA1FC58B43FED025B4316@molly.tas.csiro.au>
Message-ID: <15791.45363.714884.53805@gargle.gargle.HOWL>

>>>>> "Mark" == Mark Bravington <Mark.Bravington at csiro.au>
>>>>>     on Fri, 18 Oct 2002 14:58:04 +1100 writes:

    Mark> Does anyone have code that will methodically process R
    Mark> sourcecode, turning T's into TRUE and F's into FALSE?
    Mark> I got bored doing this by hand, after the first 30-odd
    Mark> functions-- there are hundreds left to do. I don't
    Mark> want to simply deparse everything, because that would
    Mark> destroy my beautiful formatting.

Same boat ("beautiful formatting") here.

Yes, ESS has had code for several year to do this 
{CC to ESS-help, since people there might be interested additionally} :

  M-x R-fix-T-F            (guess who wrote it)

which does it very quickly for one file.
Note that the emacs-lisp code we put in ESS is somewhat smart;
we only replace T/F when *not* inside a string or comment.

If anybody has time & knowledge to translate the Emacs-Lisp code to perl
or python or... we could provide it (from CRAN or so) :

;;;---------------------------------------------------------------------------
(defun R-fix-T-F (&optional from quietly)
  "Fix T/F into TRUE and FALSE --- CAUTIOUSLY"
  (interactive "d\nP"); point and prefix (C-u)
  (save-excursion
    (goto-char from)
    (ess-rep-regexp "\\(\\([][=,()]\\|<-\\|_\\) *\\)T\\>" "\\1TRUE"
		    'fixcase nil (not quietly))
    (goto-char from)
    (ess-rep-regexp "\\(\\([][=,()]\\|<-\\|_\\\) *\\)F\\>" "\\1FALSE"
		    'fixcase nil (not quietly))))

(defun ess-rep-regexp (regexp to-string &optional fixedcase literal verbose)
  "Instead of (replace-regexp..) -- do NOT replace in strings or comments.
 If FIXEDCASE is non-nil, do *not* alter case of replacement text.
 If LITERAL   is non-nil, do *not* treat `\\' as special.
 If VERBOSE   is non-nil, (message ..) about replacements."
  (let ((case-fold-search (and case-fold-search
			       (not fixedcase))); t  <==> ignore case in search
	(pl) (p))
    (while (setq p (re-search-forward regexp nil t))
      (cond ((not (inside-string/comment-p (1- p)))
	     (if verbose
		 (let ((beg (match-beginning 0)))
		   (message "(beg,p)= (%d,%d) = %s"
			    beg p (buffer-substring beg p) )))
	     (replace-match to-string fixedcase literal)
	     ;;or (if verbose (setq pl (append pl (list p))))
	     )))
    ;;or (if (and verbose pl)
    ;;or  (message "s/%s/%s/ at %s" regexp to-string pl))
    ) )

(defun inside-string/comment-p (pos)
  "Return non-nil if POSition [defaults to (point) is inside string or comment
 (according to syntax). NOT OKAY for multi-line comments!!"
  ;;FIXME (defun S-calculate-indent ..) in ./essl-s.el can do that ...
  (interactive "d");point by default
  (let ((pps (save-excursion
	       (parse-partial-sexp
		(save-excursion (beginning-of-line) (point))
		pos))))
    (or (nth 3 pps) (nth 4 pps)))); 3: string,  4: comment

;;;---------------------------------------------------------------------------

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 18 09:04:08 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 18 Oct 2002 08:04:08 +0100 (BST)
Subject: [R] Newbie Time Series Questions
In-Reply-To: <3DAF11DC.2C6470F7@noaa.gov>
Message-ID: <Pine.LNX.4.31.0210180800360.2899-100000@gannet.stats>

On Thu, 17 Oct 2002, Robert Schick wrote:

> I have a data set of monthly river flows from 1960-2000, which are
> similar in structure to the nottem data:
>
> > klam.flow
>       Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
> 1961 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
> 1962 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
> ...

Is that starting in Oct 1961 or what?


> I tried plotting with
>
> > ts.plot(klam.flow)
>
> Which quickly led me to realize the data aren't a "ts" object, as it
> plotted 40 stacked lines instead of one long series. I've tried
> converting to this using ts or as.ts, e.g.
>
> > klam.ts <- ts(data=klam.flow, start=1960,end=2000, frequency=12)
>
> But this seems to explode the number of time series, e.g.
>
> > klam.ts
>           Oct  Nov  Dec  Jan  Feb   Mar  Apr  May  Jun  Jul  Aug  Sep
> Jan 1960 1461 1716 2524 1773 1906  2005 1756 1575 1387  983 1094 1382
> Feb 1960 1907 2253 1985 1907 1769  1676 2634 1386  929  766  968 1309
> Mar 1960 2511 2852 3661 2103 2189  2548 3841 2937  857  743 1058 1574

I think you have a data frame or matrix.

If a matrix, try

klam.ts <- ts(as.vectior(t(klam.flow)), start=c(1961,10), frequency=12)

If a data frame, try as.matrix and then the above.

> Any advice on how to properly create the ts object so it looks and plots
> a la Figure 13.15 in VR?

The issue is to start with a `ts' object.  The above may help, but your
descriptions are not really consistent.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 18 09:07:08 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 18 Oct 2002 08:07:08 +0100 (BST)
Subject: [R] Database newbee problem...
In-Reply-To: <20021017201653.GA9443@ling.umu.se>
Message-ID: <Pine.LNX.4.31.0210180806310.2899-100000@gannet.stats>

On Thu, 17 Oct 2002, Fredrik Karlsson wrote:

> Hi and thank you all for your quick response,
>
> Indeed, the version of R I am working on is 1.6.0 on a Debian Woody
>  (stable) system. All the client and server MySQL packages report version
>  3.23.49-8. According to the MySQL web page, the current stable version of
> MySQL is 3.23.53. Development release is 4.0.4.
>
> Could anyone please advice me on a version of MySQL that does work.
> For me, the important thing is to get a working MySQL <-> R connection
> going.

3.23.49 does work.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 18 09:22:19 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 18 Oct 2002 08:22:19 +0100 (BST)
Subject: [R] Installing R1.6.0 on Solaris 5.6
In-Reply-To: <5.1.1.5.2.20021017155952.031aa460@poptop.llnl.gov>
Message-ID: <Pine.LNX.4.31.0210180812310.2899-100000@gannet.stats>

This works for me on Solaris 2.7 (and I guess you mean Solaris 2.6 aka
SunOS 5.6).  With those compilers, the .d file is almost empty.  Check
Makeconf and etc/Makeconf contain the rule

.c.d:
        @echo > $@

If they do, the problem is likely to be your make.  The R-admin manual
does say that GNU make is needed (rather than Sun make) in some
circumstances in Solaris 2.x, x < 7.  So you could try GNU make.

Unfortunately Solaris 2.6 is now a rather old version, and we can't be
expected to check on it.  My sysadmins say it is impossible to keep secure
these days.

On Thu, 17 Oct 2002, Pauline Gu wrote:

> Hello,
>
> I am trying to install R1.6.0 in a 32 bit Sun Solaris 5.6 machine using the
> solaris cc and f77.  The configurations went successful.  But, when I try
> to make, the following error occurs:
>
> config.status: creating src/library/ctest/Makefile
> config.status: creating src/library/ctest/DESCRIPTION
> building package 'ctest'
> mkdir -p -- ../../../library/ctest/R
> mkdir -p -- ../../../library/ctest/man
> config.status: creating src/library/ctest/src/Makefile
> make: Fatal error: Don't know how to make target `ansari.d'
> Current working directory /home/pgu/R-1.6.0.32bit/src/library/ctest/src
> *** Error code 1
> make: Fatal error: Command failed for target `all'
> Current working directory /home/pgu/R-1.6.0.32bit/src/library/ctest
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> Current working directory /home/pgu/R-1.6.0.32bit/src/library
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> Current working directory /home/pgu/R-1.6.0.32bit/src
> *** Error code 1
> make: Fatal error: Command failed for target `R'
>
>
> Does any body have the same problem?  Can any body help here?
>
> Thanks in advance for your help.
>
> Pauline
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 18 09:30:45 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 18 Oct 2002 08:30:45 +0100 (BST)
Subject: [R] Help with DLLs
In-Reply-To: <Pine.SOL.4.10.10210171914450.4169-100000@ra.msstate.edu>
Message-ID: <Pine.LNX.4.31.0210180823170.2899-100000@gannet.stats>

DO read readme.packages.

1) Did you export the symbols from your DLL?  It's the most common fault.
pedump will tell you, as will dump under VC++6 (at least).

2) .Fortran is designed for use with g77, and whatever you are using
(I was unaware that  Developer Studio 97 contained a Fortran compiler)
may well be using different conventions, so readme.packages tells you to
use .C with the name-mangled symbol produced.

3) The recommended compilers for use with R for Windows are *free*.
You are likely to find it much easier to follow the recommendations.

On Thu, 17 Oct 2002, Jane L. Harvill wrote:

> I'm using R version 1.5.1, and Microsoft Developer Studio 97 (yes, I know
> it's old, but it's expensive to upgrade) on Windows 98.  I created the DLL
> file with the compiler.  The name of the file containing the subroutine is
> leaf.f and the subroutine is named leaf.f. In my R program (which defines
                                     ^^^^^^
Really?  Not leaf?

> a function called leaf), I have
> 	x <- .Fortran("leaf",...)
> where the ... are the arguments passed.  I source("leaf.s"), and then
> dyn.load("leaf.dll"), and when I run leaf(100), I get the following error
>
> Error in .Fortran("leaf",as.integer(nn),as.double(u),as.double(A), :
>          C/Fortran function name not in load table
>
> Does anyone know what is causing this error message and how to fix the
> problem?
> Incidentally, the same code works FINE on the Unix version of R, but I was
> hoping to transfer it to my PC so that I could use it in a presentation
> without having to rely on an unreliable internet connection.
>
> Any words of wisdom are greatly appreciated.
>
> Sincerely,
> Jane Harvill
>
>
>
> Dr. Jane L. Harvill, Ph.D.
> Department of Mathematics and Statistics
> Drawer MA
> Mississippi State, Mississippi 39762
> Phone: (662) 325-3414
> FAX:   (662) 325-0005
> URL:   http://www2.msstate.edu/~harvill/
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 18 09:55:00 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 18 Oct 2002 08:55:00 +0100 (BST)
Subject: [R] code to turn T into TRUE
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED025B4316@molly.tas.csiro.au>
Message-ID: <Pine.LNX.4.31.0210180844130.2899-100000@gannet.stats>

I don't think we have a complete tool.  You do really need to parse the
code, and relating the parsed code to your `beautiful formatting'
is the problem.

When I kept common S/R source code, I used a Perl script for the bulk of
this.  It is conservative, and does not process lines with quoted
expressions at all.  Basically it was

s/=(\s*)F([^A-Za-z0-9\.\"])/=$1FALSE$2/go;
s/=(\s*)T([^A-Za-z0-9\.\"])/=$1TRUE$2/go;
s/\{T\}/{TRUE}/go;
s/\{F\}/{FALSE}/go;

and that correctly converted my source code and help files.


On Fri, 18 Oct 2002 Mark.Bravington at csiro.au wrote:

> Does anyone have code that will methodically process R sourcecode, turning
> T's into TRUE and F's into FALSE? I got bored doing this by hand, after the
> first 30-odd functions-- there are hundreds left to do. I don't want to
> simply deparse everything, because that would destroy my beautiful
> formatting.
>
> The reason it's not trivial, is that comment lines, quotes, and split lines
> need to be kept track of. There are no syntax errors in the code (i.e. it
> all parses OK into functions).
>
> The absolute ideal would be if the code itself was in R (because I need to
> run this from R), but presumably if there was a Perl script, I could launch
> that from within R too.
>
> FWIW I'm running Windows 2000, and hovering between R1.5.1 and R1.6.0.
>
> Thanks for any help
>
> Mark
>
> *******************************
>
> Mark Bravington
> CSIRO (CMIS)
> PO Box 1538
> Castray Esplanade
> Hobart
> TAS 7001
>
> phone (61) 3 6232 5118
> fax (61) 3 6232 5012
> Mark.Bravington at csiro.au
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at cbs.dtu.dk  Fri Oct 18 11:40:42 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Fri, 18 Oct 2002 11:40:42 +0200
Subject: [R] code to turn T into TRUE
In-Reply-To: <15791.45363.714884.53805@gargle.gargle.HOWL>
References: <A8877251964B294BAB5BA1FC58B43FED025B4316@molly.tas.csiro.au> <15791.45363.714884.53805@gargle.gargle.HOWL>
Message-ID: <20021018094042.GE6634@giraffa.cbs.dtu.dk>

I do not know if it's me or my versions of emacs, but I never managed to
make M-x R-fix-T-F have any action on my buffers...

------------
In GNU Emacs 21.2.1 (i386-mandrake-linux-gnu, X toolkit, Xaw3d scroll
bars)
 of 2002-08-18 on ke.mandrakesoft.com, modified by Mandrake
 configured using `configure  --prefix=/usr --libexecdir=/usr/lib
 --sharedstatedir=/var --with-gcc --with-pop --mandir=/usr/share/man
 --infodir=/usr/share/info --with-x-toolkit i386-mandrake-linux
 --libdir=/usr/lib'
------------

ess version is ess-5.1.24 (note: I remembered that the making of the pdf
manuals was broken when building (so the build was interupted)).


I attached a small perl script I used to update my packages
(but it does not check whether T and F are inside ""s...)



L.

On Fri, Oct 18, 2002 at 08:58:59AM +0200, Martin Maechler wrote:
> >>>>> "Mark" == Mark Bravington <Mark.Bravington at csiro.au>
> >>>>>     on Fri, 18 Oct 2002 14:58:04 +1100 writes:
> 
>     Mark> Does anyone have code that will methodically process R
>     Mark> sourcecode, turning T's into TRUE and F's into FALSE?
>     Mark> I got bored doing this by hand, after the first 30-odd
>     Mark> functions-- there are hundreds left to do. I don't
>     Mark> want to simply deparse everything, because that would
>     Mark> destroy my beautiful formatting.
> 
> Same boat ("beautiful formatting") here.
> 
> Yes, ESS has had code for several year to do this 
> {CC to ESS-help, since people there might be interested additionally} :
> 
>   M-x R-fix-T-F            (guess who wrote it)
> 
> which does it very quickly for one file.
> Note that the emacs-lisp code we put in ESS is somewhat smart;
> we only replace T/F when *not* inside a string or comment.
> 
> If anybody has time & knowledge to translate the Emacs-Lisp code to perl
> or python or... we could provide it (from CRAN or so) :
> 
> ;;;---------------------------------------------------------------------------
> (defun R-fix-T-F (&optional from quietly)
>   "Fix T/F into TRUE and FALSE --- CAUTIOUSLY"
>   (interactive "d\nP"); point and prefix (C-u)
>   (save-excursion
>     (goto-char from)
>     (ess-rep-regexp "\\(\\([][=,()]\\|<-\\|_\\) *\\)T\\>" "\\1TRUE"
> 		    'fixcase nil (not quietly))
>     (goto-char from)
>     (ess-rep-regexp "\\(\\([][=,()]\\|<-\\|_\\\) *\\)F\\>" "\\1FALSE"
> 		    'fixcase nil (not quietly))))
> 
> (defun ess-rep-regexp (regexp to-string &optional fixedcase literal verbose)
>   "Instead of (replace-regexp..) -- do NOT replace in strings or comments.
>  If FIXEDCASE is non-nil, do *not* alter case of replacement text.
>  If LITERAL   is non-nil, do *not* treat `\\' as special.
>  If VERBOSE   is non-nil, (message ..) about replacements."
>   (let ((case-fold-search (and case-fold-search
> 			       (not fixedcase))); t  <==> ignore case in search
> 	(pl) (p))
>     (while (setq p (re-search-forward regexp nil t))
>       (cond ((not (inside-string/comment-p (1- p)))
> 	     (if verbose
> 		 (let ((beg (match-beginning 0)))
> 		   (message "(beg,p)= (%d,%d) = %s"
> 			    beg p (buffer-substring beg p) )))
> 	     (replace-match to-string fixedcase literal)
> 	     ;;or (if verbose (setq pl (append pl (list p))))
> 	     )))
>     ;;or (if (and verbose pl)
>     ;;or  (message "s/%s/%s/ at %s" regexp to-string pl))
>     ) )
> 
> (defun inside-string/comment-p (pos)
>   "Return non-nil if POSition [defaults to (point) is inside string or comment
>  (according to syntax). NOT OKAY for multi-line comments!!"
>   ;;FIXME (defun S-calculate-indent ..) in ./essl-s.el can do that ...
>   (interactive "d");point by default
>   (let ((pps (save-excursion
> 	       (parse-partial-sexp
> 		(save-excursion (beginning-of-line) (point))
> 		pos))))
>     (or (nth 3 pps) (nth 4 pps)))); 3: string,  4: comment
> 
> ;;;---------------------------------------------------------------------------
> 
> Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
> ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
> phone: x-41-1-632-3408		fax: ...-1228			<><
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-------------- next part --------------
## GPL
##
## usage:
## perl fixTnF.pl <path to package>
## example:
## perl fixTnF.pl Rstuff/affy
## 
## original files are copied to '<file>_old'
##

use POSIX;
use File::Copy cp;

$dir = shift;
chdir($dir) || die("cannot cd to dir ".$dir);

$com = 'ls R/*.R man/*.Rd';
@files = `$com`;
chomp(@files);
foreach $file (@files) {
    if (-f $file.'_old') {
	print STDERR 'found a file named ', $file.'_old', "\n";
	print STDERR "nothing was done. Please move it.\n";
	exit(0);
    }
}
foreach $file (@files) {
    cp($file, $file.'_old');
    unlink($file);
    open(IN, $file.'_old') or die("cannot open ".$file.'_old');
    open(OUT, '>'.$file);
    while(<IN>) {
	s/(\[|&|\||=|,| |\()T(&|\|| |,|=|\)|$ |\])/${1}TRUE$2/og;
	s/(\[|&|\||=|,| |\()F(&|\|| |,|=|\)|$ |\])/${1}FALSE$2/og;
	##print STDERR $_;
	print OUT $_;
    }
    close(IN);
    close(OUT);
}

From Ted.Harding at nessie.mcc.ac.uk  Fri Oct 18 10:45:52 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 18 Oct 2002 09:45:52 +0100 (BST)
Subject: [R] Non-central distributions
In-Reply-To: <E09E527B56BE2D438A3D6A246DDD27A9165572@Roper-CV.qld.cmis.csiro.au>
Message-ID: <XFMail.021018094552.Ted.Harding@nessie.mcc.ac.uk>

On 18-Oct-02 Bill.Venables at cmis.csiro.au wrote:
> As far as I know, percentage points of the non-central
> distributions are not much used, but what would be very
> useful would be to have the percentage points (with respect
> to the non-centrality parameter) of the distribution function
> G(delta) = 1-P(X^2, n, delta), (i.e. you take the upper tail
> area as defining a distribution function in delta.  Such a
> distributon has a finite probability at the origin, of course.
> These are the quantities you need, for example, for things
> like sample size determination and power calculations.

Yes, this is precisely why I was looking for non-central t.
(Your "fiducial" inversion of the distribution function would
of course give confidence limits for delta at the percentiles.)

>> Anyway, in this respect R is still ahead of S-Plus, which
>> doesn't seem to carry ANY non-centrality as standard!
>> (Except possibly obscurely tucked away in some add-on library).
>       [WNV]  Tsk tsk, Ted.  They are there for pf and pchisq, at least.
> 
>       Bill Venables.

OOPS! Yes, you are right, now that I look properly. In fact it
is there for pf, pchisq and pbeta. (Having failed with pt, and
adopted a misguided search strategy in S-Plus's on-line Language
Reference -- namely, hoping that "full-text search" for "central"
would hit it -- I concluded that it wasn't there ... ).

But, as Martin Maechler says, R is still ahead on that front!

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 18-Oct-02                                       Time: 09:45:52
------------------------------ XFMail ------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mpiktas at delfi.lt  Fri Oct 18 12:27:26 2002
From: mpiktas at delfi.lt (Vaidotas Zemlys)
Date: Fri, 18 Oct 2002 11:27:26 +0100
Subject: [R] RAM usage
Message-ID: <3DAFE20E.50505@delfi.lt>

Hi,

I'm having problems while working with large data sets with R 1.5.1 in
windows 2000. Given a integer matrix size of 30 columns and  15000 rows
my function should return a boolean matrix size of about 5000 rows and
15000 columns.

First of all I tried to run this function on computer with 256 MB of 
RAM. I increased memory limit of R with memory.limit() up to 512 MB. I 
was inspecting memory and processor usage through Windows  task manager. 
At first R was using 100% of processor and memory usage was constantly 
increasing. When there were no physical memory left, R began using 
virtual memory. Then the processor usage dropped, but there was 
instensive work with hard drive. Of course that slowed down 
calculations. Yet the memory used by R always changed, and that was I
think the  sign, that R was calculating. But after a while the task
manager showed that R uses constant size of memory. The Rgui was not
responding, so I assumed that R crashed.

So I tried to run the calculations on another win2k box with 1024 MB of 
RAM with the same R version 1.5.1.  This time virtual memory was not 
used, yet still R froze. The memory usage grew to about 450 MB and then 
R stopped. Memory usage was not changing, Rgui did not respond, yet 
processor was used 100%. Task manager showed that peak memory usage was 
about 760 MB.

On smaller data sets there were no problems, memory usage was constantly 
  increasing and processor was used 100%. My function does not use fancy 
functions. Basically it just sums, finds minimum and maximum, uses 
subseting of a matrix, and calculates correlation matrix between 10 
columns of a given matrix.

So I would like to ask can R at all perform such calculations where a 
lot of memory must be used? And if R can do such calculations, what are 
specific problems, topics or tips which should be known before letting R 
to do these calculations?

Thanks in advance, for any help and special thanks for reading such a 
long letter.

Vaidotas Zemlys

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sholl at gmx.net  Fri Oct 18 11:32:45 2002
From: sholl at gmx.net (Stephan Holl)
Date: Fri, 18 Oct 2002 11:32:45 +0200
Subject: [R] extracting elements from data.frame using TRUE/FALSE
Message-ID: <20021018113245.5ae52c53.sholl@gmx.net>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Dear List, 
I try to extract elements out of an existing data.frame.
but my following functions only returns a dataframe with nothing in it.
the including function get.hist.s() plots a beautyfied histogram...

any clue?!

get.disag2 <- function(x,y,z) {

# x: dataframe including y as variable
# z: element of variable y in dataframe x

blah <- x[x$z==y, ]

get.hist.s(blah)
}

Thank you for your help

Cheers
- -- 
Stephan Holl

GnuPG Key-ID: 11946A09
ICQ# 117277975 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.7 (GNU/Linux)

iD8DBQE9r9U9Eg9SKhGUagkRAsYsAJ4o+tpSoBIg0wjrTXSlPAndLWZdTwCdF8/Z
4oq1HQoDD027HsGe0CMa6Os=
=DJRR
-----END PGP SIGNATURE-----
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hiss999 at hiss999.co.uk  Fri Oct 18 11:24:06 2002
From: hiss999 at hiss999.co.uk (LuThEr/hiss999)
Date: Fri, 18 Oct 2002 10:24:06 +0100
Subject: [R] Test
Message-ID: <B9D59199.44CC%hiss999@hiss999.co.uk>

Please disregard.
-- 
LuThEr/hiss999

>-------computer generated sound/visuals at hiss999.co.uk-----------

>>********************<<hiss999 at hiss999.co.uk>>

>>>******************************<<http://www.hiss999.co.uk/>>



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hiss999 at hiss999.co.uk  Fri Oct 18 12:09:59 2002
From: hiss999 at hiss999.co.uk (LuThEr/hiss999)
Date: Fri, 18 Oct 2002 11:09:59 +0100
Subject: [R] Test
Message-ID: <B9D59C63.44D1%hiss999@hiss999.co.uk>

Please disregard.
-- 
LuThEr/hiss999

>-------computer generated sound/visuals at hiss999.co.uk-----------

>>********************<<hiss999 at hiss999.co.uk>>

>>>******************************<<http://www.hiss999.co.uk/>>



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mpiktas at delfi.lt  Fri Oct 18 14:21:19 2002
From: mpiktas at delfi.lt (Vaidotas Zemlys)
Date: Fri, 18 Oct 2002 13:21:19 +0100
Subject: [R] RAM usage
References: <076838A70B41D31181FB002048403C2D0C8FE662@exchuk09.eu.ssmb.com>
Message-ID: <3DAFFCBF.6030804@delfi.lt>

Hi,

  > You'll need to post the code for anyone to be able to help. There are
  >  many ways to do the same thing, some hugely more efficient than
  > others.
  >

Ok, here it is:

#main function
rptree <-
function(X,y,depth=3,count=10) {
      X <- as.matrix(X)
      y <- as.vector(y)

      m <- dim(X)[1]
      n <- dim(X)[2]

      if(!identical(m,length(y))) {
          stop("Nesutampa dimensijos")
      }

      cnames <- colnames(X)
      tree <- list()
      snames <- list()
      node <- node.div(X,y,count=count,sep="",col.names=cnames)
      l <- node$l
      paths <- node$paths
      rownames(l) <- node$snames -> rownames(paths)
      tree[[1]] <- list(subsets=l,paths=paths)
      snames[[1]] <- node$snames

      if(depth>1) {
          for(i in 2:depth) {
              nl <- dim(tree[[i-1]]$subsets)[1]
              off <-0
              l <- logical();
              paths <- numeric();
              l.snames <- character();
              for(j in 1:nl) {
                  subs <- tree[[i-1]]$subsets[j,]
                  node <- node.div(X[subs,],y[subs],count=count,name=snames[[i-1]][j],col.names=cnames)
                  if(node$bonferoni>0) {
                      nnl <- dim(node$l)[1]
                      subss <- matrix(rep(subs,nnl),nrow=nnl,byrow=TRUE)
                      subss[subss] <- node$l
                      l <- rbind(l,subss)
                      paths <- rbind(paths,cbind(matrix(rep(tree[[i-1]]$paths[j,],nnl),nrow=nnl,byrow=TRUE), node$paths))
                      l.snames[off+1:nnl] <- node$snames
                      off <- off + nnl
                  }
              }
              rownames(l) <- l.snames -> rownames(paths)
              tree[[i]] <- list(subsets=l,paths=paths)
              snames[[i]] <- l.snames
          }

      }
      names(tree) <- paste("lv",1:depth,sep="")
      tree$X <- X
      tree$y <- y

      attributes(tree)$class <- "rptree"
      tree

}

#function node.div used in main function rptree
node.div <-
function(X,y,count=10,name="subset",sep=".",col.names=NULL) {

      m <- dim(X)[1]
      n <- dim(X)[2]

      SZZ=sum(y^2)
      SZ=sum(y)

      t <- rep(0,n)
      for(i in 1:n) {
          n1_length(X[X[,i]==0,i])
          if((n1>10) && (n1<(m-10))) {
              if(min(c(n1,m-n1)==n1)) {
                  SX <- sum(y[X[,i]==0])
                  SXX <- sum(y[X[,i]==0]^2)
                  n2 <- m-n1
              }
              else {
                  SX <- sum(y[X[,i]>0])
                  SXX <- sum(y[X[,i]>0]^2)
                  n2 <- n1
                  n1 <- m-n1
              }
              SY <- SZ-SX;
              SYY <- SZZ-SXX;

              SSX <- SXX-(1/n1)*(SX)^2
              SSY <- SYY-(1/n2)*(SY)^2
              v <- (SSX+SSY)/(m-2)
              stderr <- sqrt(v*(1/n1+1/n2))
              t[i] <- abs(SX/n1-SY/n2)/stderr
          }
      }

      #t <- t[t>0]
      bonf <- length(t[t>0])
      ind <- rep(0,count)
      if(bonf>1) {
          st <- sort(t,decreasing=TRUE,index.return=TRUE)
          j <- 1
          jj <- 1
          ind[1] <- st$ix[1]
          q.value <- qt(0.975,m-2)
          while((j<count) && (st$x[jj+1]>q.value) && (j<n)) {
              max.cor <- max(abs(cor(X[,c(ind,st$ix[jj+1])])[j+1,1:j]))

              if(max.cor<0.9) {
                  j <- j + 1
                  jj <- jj + 1
                  ind[j]_st$ix[jj]
              }
              else {
                  jj <- jj + 1
              }
          }
      }
      else {
          if(bonf==1) {
              ind[1]_(1:n)[t>0]
          }
      }
      ind <- ind[ind>0]
      ni <- length(ind)
      if(ni>0) {
          l_X[,ind]>0
          l <- t(matrix(c(l,!l),nrow=m))
          paths <- cbind(rep(ind,2),rep(c(1,0),each=ni))
          if(identical(col.names,NULL)) {
              snames <- paste(name,paste(rep(ind,2),rep(c(1,0),each=ni),sep="@"),sep=sep)
          }
          else {
              snames <- paste(name,paste(rep(col.names[ind],2),rep(c(1,0),each=ni),sep="@"),sep=sep)
          }
          list(l=l,paths=paths,snames=snames,bonferoni=bonf)
      }
      else {
          list(bonferoni=bonf)
      }
}


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mpiktas at delfi.lt  Fri Oct 18 15:50:39 2002
From: mpiktas at delfi.lt (Vaidotas Zemlys)
Date: Fri, 18 Oct 2002 14:50:39 +0100
Subject: [R] RAM usage
References: <3DAFE20E.50505@delfi.lt> <3DB0001C.4030508@perseus.unalmed.edu.co>
Message-ID: <3DB011AF.7070307@delfi.lt>

Hi,

> Dr. Zemlys: Have you tried with --max-mem-size option in the R command 
> line? Here is an excerpt from the FAQ file 2.6 There seems to be a limit 
> on the memory it uses! Indeed there is. It is set by the command-line 
> flag |--max-mem-size| (see How do I install R for Windows? 
> <cid:part1.06010309.09030302 at perseus.unalmed.edu.co>) and defaults to 
> the smaller of the amount of physical RAM in the machine and 1Gb. It can 
> be set to any amount over 10M. (R will not run in less.) Be aware though 
> that Windows has (in most versions) a maximum amount of user virtual 
> memory of 2Gb, and parts of this can be reserved by processes but not 
> used. Because of the way the memory manager works, it is possible that 
> there will be free memory but R will not be able to make use of it. Use 
> |?Memory| and |?memory.size| for information about memory usage. The 
> limit can be raised by calling |memory.limit| within a running R 
> session. We have found that starting R with too large a value of 
> |--max-mem-size| may fail: the limit seemed to be about 1.7Gb on Windows 
> 2000 Professional. R can be compiled to use a different memory manager 
> which might be better at using large amounts of memory, but is 
> substantially slower (making R several times slower on some tasks). -- 

When I tried to run my function on computer with 1 GB of RAM, I set 
memory.limit(1024), yet R froze when it hasn't had reached that limit. 
Windows task manager showed that R is using about 450 MB of RAM at the time 
when it froze. When I tried to run calculations without adjusting 
memory.limit, R exited from function with error message, that I should 
adjust memory limit, because it cannot allocate vector of some size.

So I think the problem is not with the memory limits.

Vaidotas Zemlys



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 18 15:03:29 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 18 Oct 2002 14:03:29 +0100 (BST)
Subject: [R] RAM usage
In-Reply-To: <3DAFE20E.50505@delfi.lt>
Message-ID: <Pine.LNX.4.31.0210181355400.7984-100000@gannet.stats>

On Fri, 18 Oct 2002, Vaidotas Zemlys wrote:

> I'm having problems while working with large data sets with R 1.5.1 in
> windows 2000. Given a integer matrix size of 30 columns and  15000 rows
> my function should return a boolean matrix size of about 5000 rows and
> 15000 columns.

That's  75million items of 4bytes each, hence almost 300Mb for that one
object.

> First of all I tried to run this function on computer with 256 MB of
> RAM. I increased memory limit of R with memory.limit() up to 512 MB. I
> was inspecting memory and processor usage through Windows  task manager.
> At first R was using 100% of processor and memory usage was constantly
> increasing. When there were no physical memory left, R began using
> virtual memory. Then the processor usage dropped, but there was
> instensive work with hard drive. Of course that slowed down
> calculations. Yet the memory used by R always changed, and that was I
> think the  sign, that R was calculating. But after a while the task
> manager showed that R uses constant size of memory. The Rgui was not
> responding, so I assumed that R crashed.

Don't think so.  More likely that Windows is having problems managing the
memory requirements.  You are trying to access an object too big to fit
into RAM, and that going to cause severe strain.

> So I tried to run the calculations on another win2k box with 1024 MB of
> RAM with the same R version 1.5.1.  This time virtual memory was not
> used, yet still R froze. The memory usage grew to about 450 MB and then
> R stopped. Memory usage was not changing, Rgui did not respond, yet
> processor was used 100%. Task manager showed that peak memory usage was
> about 760 MB.

Again, there is likely a problem with Windows allocating a contiguous
chunk of 300Mb of memory.  Try this sort of thing only after a fresh
reboot.

> On smaller data sets there were no problems, memory usage was constantly
>   increasing and processor was used 100%. My function does not use fancy
> functions. Basically it just sums, finds minimum and maximum, uses
> subseting of a matrix, and calculates correlation matrix between 10
> columns of a given matrix.
>
> So I would like to ask can R at all perform such calculations where a
> lot of memory must be used? And if R can do such calculations, what are
> specific problems, topics or tips which should be known before letting R
> to do these calculations?

R can. The question is `can Windows'?  If possible use a Unix-based OS.

You have not told us your problem, so has not demonstrated that
`a lot of memory must be used'.   Hard to help when we don't know what you
are attempting, but few problems cannot be done in pieces.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Derek.Eder at neuro.gu.se  Fri Oct 18 15:28:12 2002
From: Derek.Eder at neuro.gu.se (Derek Eder)
Date: Fri, 18 Oct 2002 15:28:12 +0200
Subject: [R] Hmisc masks unpaste from Chron
Message-ID: <sdb02912.008@dss2.med.gu.se>

.. Just a friendly warning:  

The Hmsic library masks the "unpaste"  function from the Chron library.  This causes the crashing of simple chron operations such as:   times("12:12:12")

If you need both libraries, loading Hmisc first may work for you too.

- Derek Eder





Derek N. Eder
G?teborgs Universitet
Institutionen f?r klinisk neurovetenskap
Klinisk Neurofysiologi
Sahlgrenska universitetssjukhuset SS/SU
Bl? str?ket 7, v?n 3
SE 413 45  G?teborg
Sverige
Tlf. +46 (031) 34  244 14  (office)   NYTT!
Tlf. +46 (031) 34 212 83  (laboratory)
Tlf. +46 0709 / 7 212 83 (mobil)
Fax. +46 (031) 82 81 63 
derek.eder at neuro.gu.se


Gothenburg University
Institute of Clinical Neuroscience,
Department of Clinical Neurophysiology
Salhgrenska Hospital  SU/SS
SE 413 45  G?teborg
Sweden



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Oct 18 16:20:26 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 18 Oct 2002 07:20:26 -0700 (PDT)
Subject: [R] data.frame bug?
In-Reply-To: <20021017224636.GB15047@hortresearch.co.nz>
Message-ID: <Pine.A41.4.44.0210180709340.126482-100000@homer38.u.washington.edu>

On Fri, 18 Oct 2002, Patrick Connolly wrote:

> On Thu, 17-Oct-2002 at 04:30PM -0500, Chong Gu wrote:
>
> |>
> |> I'd like to create a data frame with components
> |>
> |> > jk$x1
> |> [1] 2
> |> > jk$x2
> |>          [,1] [,2]
> |> [1,]    0    0
> |>
> |> I used to be able to do it with
> |>
> |> > jk <- data.frame(x1=2,x2=I(matrix(0,1,2)))
> |>
> |> But now I get a error message.
> |>
> |> Can I still do what I want?  Thanks for any help.
>
> Not if you want to call and use it a data frame.  A list as you've
> made could still suit your purposes, but if you want a dataframe, it
> has to have elements that are of equal lengths.
>

This is slightly misleading.  It's quite possible to have complicated
objects in a data frame, including things that are in fact matrices
eg
   data.frame(a=1:2,b=Surv(1:2))
where the second column is a matrix with some extra attributes. This is a
Good Thing.

It has in the past been possible to have matrices in data frames, and it
still is possible to create them -- the reported bug is in printing them,
and I think it is a bug.

	-thomas



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tobi.g at bluewin.ch  Fri Oct 18 16:48:23 2002
From: tobi.g at bluewin.ch (Tobias Graessli)
Date: Fri, 18 Oct 2002 16:48:23 +0200
Subject: [R] Pulldown-Menue in tcl
Message-ID: <001101c276b5$6919eca0$46fe55a0@yesbabyyes>

Does anybody know how to make a pulldown-menue with tcl in R? Or does
anybody have an example!
Best wishes
Tobias Graessli
graestob at zhwin.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wviechtb at s.psych.uiuc.edu  Fri Oct 18 18:09:57 2002
From: wviechtb at s.psych.uiuc.edu (Wolfgang Viechtbauer)
Date: Fri, 18 Oct 2002 11:09:57 -0500 (CDT)
Subject: [R] Non-central distributions
In-Reply-To: <XFMail.021017162431.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.SOL.4.30.0210181004510.1775-100000@s.psych.uiuc.edu>

> all have a slot for the non-centrality parameter "ncp", of
> the functions for the t and F distributions:
>
>      dt(x, df, log = FALSE)
>      pt(q, df, ncp=0, lower.tail = TRUE, log.p = FALSE)
>      qt(p, df,        lower.tail = TRUE, log.p = FALSE)
>      rt(n, df)

Here is a function for calculating the density of a non-central t.

dtnc <- function(x, df, ncp=0) {
   y <- -ncp*x/sqrt(df+x^2)
   a <- (-y + sqrt(y^2 + 4*df)) / 2
   Hhmy <- 1/gamma(df+1) * a^df * exp(-0.5*(a+y)^2) * sqrt(2*pi*a^2/(df+a^2)) * (1 - 3*df/(4*(df+a^2)^2) + 5*df^2/(6*(df+a^2)^3))
gamma(df + 1) / (2^((df-1)/2) * gamma(df/2) * sqrt(pi*df)) * exp(-0.5*df*ncp^2/(df+x^2)) * (df/(df+x^2))^((df+1)/2) * Hhmy
}

This is an approximation based on Resnikoff & Lieberman (1957). But it's
quite accurate. The exact pdf can either be expressed as an infinite sum
or requires the evaluation of an integral. I tried to implement the
latter using integrate(), but the results were very erratic. I checked
the accuracy of the approximation in various ways:

Comparing dtnc to dt in case ncp = 0 results in a maximum error of .0046
at the point x = 0 and df = 1. For df = 10, that error is already down
to .000021. I also compared pt with

integrate(dtnc, lower=-Inf, upper=x, df=df, ncp=ncp)

for a wide range of df's and ncp's and found that the results closely
matched to at least three decimal places even for small df. For 12 df,
differences only showed up in the 5th decimal. Obviously, use of
integrate() might contribute a little bit to the discrepancies.

Also, I checked whether dtnc integrates to 1 with

integrate(dtnc, lower=-Inf, upper=Inf, df=df, ncp=ncp)

for a wide range of df's and ncp's. Differences from 1 only showed up in
the second decimal places for df = 1, third decimal place for df = 2,
and the fourth decimal place for df = 4, and so on ...

So, it looks like the approximation provides pretty accurate results.

--
Wolfgang Viechtbauer

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pwolf at wiwi.uni-bielefeld.de  Fri Oct 18 18:29:54 2002
From: pwolf at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Fri, 18 Oct 2002 18:29:54 +0200
Subject: [R] code to turn T into TRUE
Message-ID: <3DB03702.76BB3F73@wiwi.uni-bielefeld.de>

Mark wrote:

> Does anyone have code that will methodically process R sourcecode,
turning
> T's into TRUE and F's into FALSE? I got bored doing this by hand,
after the
> first 30-odd functions-- there are hundreds left to do. I don't want
to
> simply deparse everything, because that would destroy my beautiful
> formatting.

Here is another solution based on an R function. You can use it
to change a name of a variable:

rename <- function(name,oldname="T",newname="TRUE"){
  # pw 10/02
  abc1<-c("",".",LETTERS,letters); abc2<-c(abc1,as.character(0:9))
  dump(name); fns<-scan("dumpdata.R","",sep="\n")
  if(0==length(matches<-grep(oldname,fns))) return("no changes")
  match.lines<-fns[matches]; changes<-0
  for(i in 1:length(match.lines)){
    line<-strsplit(paste("",match.lines[i],""),oldname)[[1]]
    h1<-sapply(line,function(x)any(substring(x,1,        1)
==abc2))

h2<-sapply(line,function(x)any(substring(x,nchar(x),nchar(x))==abc1))
    h <- h1[-1] | h2[-length(h2)]; changes<-changes+sum(!h)

line<-paste(rbind(c("",c(newname,oldname)[1+h]),line)[-1],collapse="")
    match.lines[i]<-substring(line,2,nchar(line)-1)
  }
  fns[matches]<-lapply(match.lines,paste,collapse="")
  eval(parse(text=unlist(fns)),envir=sys.parent())
  return(paste(changes,"changes"))
}

Example:

> rename("rename","oldname","OLD")
Read 18 items
[1] "4 changes"
> rename
function(name,OLD="T",newname="TRUE"){
  # pw 10/02
  abc1<-c("",".",LETTERS,letters); abc2<-c(abc1,as.character(0:9))
  dump(name); fns<-scan("dumpdata.R","",sep="\n")
  if(0==length(matches<-grep(OLD,fns))) return("no changes")
  match.lines<-fns[matches]; changes<-0
  for(i in 1:length(match.lines)){
    line<-strsplit(paste("",match.lines[i],""),OLD)[[1]]
    h1<-sapply(line,function(x)any(substring(x,1,        1)
==abc2))

h2<-sapply(line,function(x)any(substring(x,nchar(x),nchar(x))==abc1))
    h <- h1[-1] | h2[-length(h2)]; changes<-changes+sum(!h)
    line<-paste(rbind(c("",c(newname,OLD)[1+h]),line)[-1],collapse="")
    match.lines[i]<-substring(line,2,nchar(line)-1)
  }
  fns[matches]<-lapply(match.lines,paste,collapse="")
  eval(parse(text=unlist(fns)),envir=sys.parent())
  return(paste(changes,"changes"))
}


Peter Wolf

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vpiorno at uvigo.es  Fri Oct 18 18:39:28 2002
From: vpiorno at uvigo.es (Vicente Piorno)
Date: Fri, 18 Oct 2002 18:39:28 +0200
Subject: [R] Gutman mu' monotonicity coefficient
Message-ID: <002101c276c4$ed3cd650$742492c1@DROSOPHILA>

Dear members,
I am wondering if it is available any function to compute Gutman mu2
monotonicity coefficient with R. If not, I would greatly appreciate
indications that helped me to obtain it by other means.
--
Vicente Piorno
Departamento de Ecolox?a e Biolox?a Animal
EUT Forestal
Campus Universitario
36005 Pontevedra SPAIN

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From daniel.hoppe at em.uni-karlsruhe.de  Fri Oct 18 19:28:37 2002
From: daniel.hoppe at em.uni-karlsruhe.de (Daniel Hoppe)
Date: Fri, 18 Oct 2002 19:28:37 +0200
Subject: [R] Question regarding nonlinear regression
Message-ID: <000401c276cb$cbfa4390$bcd515ac@chiloe>

Hi all,

I'm trying to calculate a nonlinear regression to get a simpler expression
for a complicated formula.

I expect that a function of the type


              1
   ----------------------------
           - (a + b1*x + b2*y)
    1 + e

should be a good fit. Now I'm trying to calculate a regression with R and
must admit that I'm slightly confused by the variety of possibilities to run
this calculation. My first approach was to calculate the regression with the
least-squares-method and "optim" manually. This seems to work quite well.
"An Introduction to R" points out that this can be done with "nlm" which
seems to work for me too. Now "nls" and "gnlm" seem to point into this
direction as well. Could anyone advise me,  if I'm on the right track and
what the advantages and disadvantages of the different approaches are?

Thanks a lot for your support!

Best Regards,

Daniel Hoppe

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From presnell at stat.ufl.edu  Fri Oct 18 19:55:57 2002
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Fri, 18 Oct 2002 13:55:57 -0400
Subject: [R] Non-central distributions
In-Reply-To: <15791.44578.187614.230488@gargle.gargle.HOWL>
References: <E09E527B56BE2D438A3D6A246DDD27A9165572@Roper-CV.qld.cmis.csiro.au>
	<15791.44578.187614.230488@gargle.gargle.HOWL>
Message-ID: <15792.19245.432498.731336@eelpout.stat.ufl.edu>


In message <15791.44578.187614.230488 at gargle.gargle.HOWL> you write:
> 
> probably an exercise of reading the sections in Johnson et al
> (see "HRK" below). I remember having seen quite a few references there.
> Contributions are welcome..
> ...
> In the next major version of R, 1.7.x,
> I plan to have finished the code for rchisq(*, ncp = *)
> {and possibly for some of  ?chisq(*, df = 0, *) }
> thanks to a suggestion from Hans R. Kuensch:

I haven't followed this entire thread, so I apologize if I'm
completely off the mark, especially since I strongly suspect that
Martin and others would be aware of this information already.

Still, FWIW, probably all of these routines are available, albeit in
Fortran, in Barry W. Brown, James Lovato, and Kathy Russell's cdflib,
which seems to be unencumbered by any license restrictions.  I have
used this library before without any problems, and I'm sure that I
have dynloaded it into Splus, and probably into R as well.  Maybe it
would at least be useful as a reference while you code this up in C?
Should be on statlib.

-- 
Brett Presnell
Department of Statistics
University of Florida
http://www.stat.ufl.edu/~presnell/

"We don't think that the popularity of an error makes it the truth."
   -- Richard Stallman
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mike at gene-hacker.net  Fri Oct 18 21:16:00 2002
From: mike at gene-hacker.net (Michael Maibaum)
Date: Fri, 18 Oct 2002 12:16:00 -0700
Subject: [R] Building R on Mac OS X-"dumping methods" problem
Message-ID: <09C91FEA-E2CE-11D6-A816-000A277AA008@gene-hacker.net>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


I am trying to create a darwinports package for R, but I cannot get R 
to compile on Mac OSX 10.2.

I have install g77 which seems fine. R compiles without problems until 
it reaches


dumping R code in package 'methods'
Error in .Call("R_initialize_methods_metadata", table, PACKAGE = 
"methods") :
         .Call function name not in load table
Execution halted
gnumake[4]: *** [../../../library/methods/R/all.rda] Error 1


my configure environment is
	FFLAGS="-O3 -funroll-all-loops" LDFLAGS="-L/opt/local/lib/" \
				CPPFLAGS="-I/opt/local/include/"

configure.args	--without-gnome --enable-R-shlib 
- --mandir='/opt/local/share/man' \
				--with-tcl-config=/System/Library/Tcl/8.3/tclConfig.sh \
				-C --without-blas

any suggestions? THis is essentially identical to the way fink builds R 
so...?

thanks

Michael
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.7 (Darwin)

iD8DBQE9sF32ilk3LUlIL0MRAoz1AJ9EQbLFSYAWualuWJDiyvGuA9oc1ACgwQLY
7PQtpox/Dxtw5oN7OLRcMvs=
=FzYj
-----END PGP SIGNATURE-----

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deho at fas.harvard.edu  Fri Oct 18 21:42:55 2002
From: deho at fas.harvard.edu (Daniel En-Wenn Ho)
Date: Fri, 18 Oct 2002 15:42:55 -0400 (EDT)
Subject: [R] Densities in legend
Message-ID: <Pine.OSF.4.44.0210181539310.21040-100000@is08.fas.harvard.edu>

Hello all,

Does anyone know how to add densities of a histogram to a legend?

I have tried to label five histograms with the following code, to no
avail -- each time, the legend symbol is simply blank.

postscript("graph9.eps")
title=c("Comparison of Quintiles")
hist(quant1$pre,xlim=c(260,310),ylim=c(0,12),ylab="Frequency",xlab="Cholesterol",density=10,main=title)
hist(quant2$pre,add=TRUE,density=20)
hist(quant3$pre,add=TRUE,density=30)
hist(quant4$pre,add=TRUE,density=40)
hist(quant5$pre,add=TRUE,density=50)
legend(260,12,density=c(10,20,30,40,50),legend=c("Quintile 1","Quintile 2","Quintile 3","Quintile 4","Quintile 5"))
dev.off()

Many thanks,

Dan

daniel_ho at harvard.edu



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From a296180 at agate.fmr.com  Fri Oct 18 22:23:57 2002
From: a296180 at agate.fmr.com (David Kane  <David Kane)
Date: Fri, 18 Oct 2002 16:23:57 -0400
Subject: [R] Correct placement of .tex files in an R package
Message-ID: <15792.28125.878978.237141@gargle.gargle.HOWL>

I have a package in which I would like to store a LaTeX .tex file. It is not
documentation on any particular function, but is related to the package. In
thought that I could just create a "doc" directory under the "inst"
subdirectory and place it there. I thought that things in "inst" were just
recursively copied when the package was installed.

Alas, when I check the package (named "portfolio"), I get messages like:

Error in codoc(package = "portfolio") : cannot source usages in documentation object 'attribution'

and

Error in checkDocArgs(package = "portfolio") : 
	cannot source usages in documentation object 'attribution'

The name of my file is "attribution.tex".

Why is the happening and what can I do about it?

> version
         _                   
platform sparc-sun-solaris2.6
arch     sparc               
os       solaris2.6          
system   sparc, solaris2.6   
status                       
major    1                   
minor    5.1                 
year     2002                
month    06                  
day      17                  
language R                   
> 

Thanks,

Dave Kane




-- 
David Kane
Geode Capital Management
617-563-0122
david.d.kane at fmr.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Sat Oct 19 00:28:19 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Fri, 18 Oct 2002 15:28:19 -0700
Subject: [R] Building R on Mac OS X-"dumping methods" problem
In-Reply-To: <09C91FEA-E2CE-11D6-A816-000A277AA008@gene-hacker.net>
Message-ID: <E720FEDD-E2E8-11D6-8092-000393860F3C@stat.ucla.edu>

This was an error we had about half a year ago when building R on
  OS X. Which gcc ? Which R ? Which g77 ? Are you sure you are
building from a clean install (not installed over a previous version) ?

--- Jan

On Friday, October 18, 2002, at 12:16 PM, Michael Maibaum wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>
> I am trying to create a darwinports package for R, but I cannot get R  
> to compile on Mac OSX 10.2.
>
> I have install g77 which seems fine. R compiles without problems until  
> it reaches
>
>
> dumping R code in package 'methods'
> Error in .Call("R_initialize_methods_metadata", table, PACKAGE =  
> "methods") :
>         .Call function name not in load table
> Execution halted
> gnumake[4]: *** [../../../library/methods/R/all.rda] Error 1
>
>
> my configure environment is
> 	FFLAGS="-O3 -funroll-all-loops" LDFLAGS="-L/opt/local/lib/" \
> 				CPPFLAGS="-I/opt/local/include/"
>
> configure.args	--without-gnome --enable-R-shlib -  
> --mandir='/opt/local/share/man' \
> 				--with-tcl-config=/System/Library/Tcl/8.3/tclConfig.sh \
> 				-C --without-blas
>
> any suggestions? THis is essentially identical to the way fink builds  
> R so...?
>
> thanks
>
> Michael
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.0.7 (Darwin)
>
> iD8DBQE9sF32ilk3LUlIL0MRAoz1AJ9EQbLFSYAWualuWJDiyvGuA9oc1ACgwQLY
> 7PQtpox/Dxtw5oN7OLRcMvs=
> =FzYj
> -----END PGP SIGNATURE-----
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mike at gene-hacker.net  Sat Oct 19 00:57:40 2002
From: mike at gene-hacker.net (Michael Maibaum)
Date: Fri, 18 Oct 2002 15:57:40 -0700
Subject: [R] Building R on Mac OS X-"dumping methods" problem
In-Reply-To: <E720FEDD-E2E8-11D6-8092-000393860F3C@stat.ucla.edu>
Message-ID: <00A9DC5E-E2ED-11D6-A816-000A277AA008@gene-hacker.net>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


On Friday, October 18, 2002, at 03:28 PM, Jan de Leeuw wrote:

> This was an error we had about half a year ago when building R on
>  OS X. Which gcc ? Which R ? Which g77 ? Are you sure you are
> building from a clean install (not installed over a previous version) ?


R 1.6.0, clean install.

standard gcc 3.1 from Apple with 10.2, g77 is

%g77 -v
Reading specs from  
/opt/local/lib/gcc-lib/powerpc-apple-darwin6.1/3.1/specs
Configured with: ../gcc3/configure --prefix=/opt/local  
- --enable-languages=f77 --infodir=/opt/local/share/info
Thread model: single
Apple Computer, Inc. GCC version 1151, based on gcc version 3.1  
20020420 (prerelease)
(basically the fink one, but ported to darwinports)

thanks,

Michael
>
> --- Jan
>
> On Friday, October 18, 2002, at 12:16 PM, Michael Maibaum wrote:
>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>>
>> I am trying to create a darwinports package for R, but I cannot get R  
>> to compile on Mac OSX 10.2.
>>
>> I have install g77 which seems fine. R compiles without problems  
>> until it reaches
>>
>>
>> dumping R code in package 'methods'
>> Error in .Call("R_initialize_methods_metadata", table, PACKAGE =  
>> "methods") :
>>         .Call function name not in load table
>> Execution halted
>> gnumake[4]: *** [../../../library/methods/R/all.rda] Error 1
>>
>>
>> my configure environment is
>> 	FFLAGS="-O3 -funroll-all-loops" LDFLAGS="-L/opt/local/lib/" \
>> 				CPPFLAGS="-I/opt/local/include/"
>>
>> configure.args	--without-gnome --enable-R-shlib -  
>> --mandir='/opt/local/share/man' \
>> 				--with-tcl-config=/System/Library/Tcl/8.3/tclConfig.sh \
>> 				-C --without-blas
>>
>> any suggestions? THis is essentially identical to the way fink builds  
>> R so...?
>>
>> thanks
>>
>> Michael
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v1.0.7 (Darwin)
>>
>> iD8DBQE9sF32ilk3LUlIL0MRAoz1AJ9EQbLFSYAWualuWJDiyvGuA9oc1ACgwQLY
>> 7PQtpox/Dxtw5oN7OLRcMvs=
>> =FzYj
>> -----END PGP SIGNATURE-----
>>
>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
>> .-.-.-.-.-
>> r-help mailing list -- Read  
>> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To:  
>> r-help-request at stat.math.ethz.ch
>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._. 
>> _._._._._
>>
>>
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical  
> Software
> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email:  
> deleeuw at stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>   
> ----------------------------------------------------------------------- 
> --------------------------
>           No matter where you go, there you are. --- Buckaroo Banzai
>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
>   
> ----------------------------------------------------------------------- 
> --------------------------
>
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.7 (Darwin)

iD8DBQE9sJHpilk3LUlIL0MRAsSGAKCqTJpzEzXE13EvKCRNVY1iY0M40QCZAeUf
N8mRDdN2d5jWQu5XL+mpKvU=
=JoOi
-----END PGP SIGNATURE-----

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Sat Oct 19 00:52:52 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Fri, 18 Oct 2002 15:52:52 -0700
Subject: [R] Building R on Mac OS X-"dumping methods" problem
In-Reply-To: <00A9DC5E-E2ED-11D6-A816-000A277AA008@gene-hacker.net>
Message-ID: <5547296E-E2EC-11D6-8092-000393860F3C@stat.ucla.edu>

Hm. That's basically what I use, and I don't have that problem
(any more). Are you using the --enable-shlib flag when
building R ?

On Friday, October 18, 2002, at 03:57 PM, Michael Maibaum wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>
> On Friday, October 18, 2002, at 03:28 PM, Jan de Leeuw wrote:
>
>> This was an error we had about half a year ago when building R on
>>  OS X. Which gcc ? Which R ? Which g77 ? Are you sure you are
>> building from a clean install (not installed over a previous version)  
>> ?
>
>
> R 1.6.0, clean install.
>
> standard gcc 3.1 from Apple with 10.2, g77 is
>
> %g77 -v
> Reading specs from  
> /opt/local/lib/gcc-lib/powerpc-apple-darwin6.1/3.1/specs
> Configured with: ../gcc3/configure --prefix=/opt/local -  
> --enable-languages=f77 --infodir=/opt/local/share/info
> Thread model: single
> Apple Computer, Inc. GCC version 1151, based on gcc version 3.1  
> 20020420 (prerelease)
> (basically the fink one, but ported to darwinports)
>
> thanks,
>
> Michael
>>
>> --- Jan
>>
>> On Friday, October 18, 2002, at 12:16 PM, Michael Maibaum wrote:
>>
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA1
>>>
>>>
>>> I am trying to create a darwinports package for R, but I cannot get  
>>> R to compile on Mac OSX 10.2.
>>>
>>> I have install g77 which seems fine. R compiles without problems  
>>> until it reaches
>>>
>>>
>>> dumping R code in package 'methods'
>>> Error in .Call("R_initialize_methods_metadata", table, PACKAGE =  
>>> "methods") :
>>>         .Call function name not in load table
>>> Execution halted
>>> gnumake[4]: *** [../../../library/methods/R/all.rda] Error 1
>>>
>>>
>>> my configure environment is
>>> 	FFLAGS="-O3 -funroll-all-loops" LDFLAGS="-L/opt/local/lib/" \
>>> 				CPPFLAGS="-I/opt/local/include/"
>>>
>>> configure.args	--without-gnome --enable-R-shlib -  
>>> --mandir='/opt/local/share/man' \
>>> 				--with-tcl-config=/System/Library/Tcl/8.3/tclConfig.sh \
>>> 				-C --without-blas
>>>
>>> any suggestions? THis is essentially identical to the way fink  
>>> builds R so...?
>>>
>>> thanks
>>>
>>> Michael
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG v1.0.7 (Darwin)
>>>
>>> iD8DBQE9sF32ilk3LUlIL0MRAoz1AJ9EQbLFSYAWualuWJDiyvGuA9oc1ACgwQLY
>>> 7PQtpox/Dxtw5oN7OLRcMvs=
>>> =FzYj
>>> -----END PGP SIGNATURE-----
>>>
>>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
>>> .-.-.-.-.-.-
>>> r-help mailing list -- Read  
>>> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>>> Send "info", "help", or "[un]subscribe"
>>> (in the "body", not the subject !)  To:  
>>> r-help-request at stat.math.ethz.ch
>>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
>>> ._._._._._
>>>
>>>
>> ===
>> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
>> Editor: Journal of Multivariate Analysis, Journal of Statistical  
>> Software
>> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
>> phone (310)-825-9550;  fax (310)-206-5658;  email:  
>> deleeuw at stat.ucla.edu
>> homepage: http://gifi.stat.ucla.edu
>>   
>> ---------------------------------------------------------------------- 
>> ---------------------------
>>           No matter where you go, there you are. --- Buckaroo Banzai
>>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
>>   
>> ---------------------------------------------------------------------- 
>> ---------------------------
>>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.0.7 (Darwin)
>
> iD8DBQE9sJHpilk3LUlIL0MRAsSGAKCqTJpzEzXE13EvKCRNVY1iY0M40QCZAeUf
> N8mRDdN2d5jWQu5XL+mpKvU=
> =JoOi
> -----END PGP SIGNATURE-----
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mike at gene-hacker.net  Sat Oct 19 01:28:31 2002
From: mike at gene-hacker.net (Michael Maibaum)
Date: Fri, 18 Oct 2002 16:28:31 -0700
Subject: [R] Building R on Mac OS X-"dumping methods" problem
In-Reply-To: <5547296E-E2EC-11D6-8092-000393860F3C@stat.ucla.edu>
Message-ID: <501CDFD0-E2F1-11D6-A816-000A277AA008@gene-hacker.net>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


On Friday, October 18, 2002, at 03:52 PM, Jan de Leeuw wrote:

> Hm. That's basically what I use, and I don't have that problem
> (any more). Are you using the --enable-shlib flag when
> building R ?


yes, but I've tried it without as well....

Is this likely to be a problem with the compiler itself? WOuld it be 
worth getting fink to build g77 and trying to build R with that g77 
instead?

thanks

Michael
>
> On Friday, October 18, 2002, at 03:57 PM, Michael Maibaum wrote:
>
>> On Friday, October 18, 2002, at 03:28 PM, Jan de Leeuw wrote:
>>
>>> This was an error we had about half a year ago when building R on
>>>  OS X. Which gcc ? Which R ? Which g77 ? Are you sure you are
>>> building from a clean install (not installed over a previous 
>>> version) ?
>>
>>
>> R 1.6.0, clean install.
>>
>> standard gcc 3.1 from Apple with 10.2, g77 is
>>
>> %g77 -v
>> Reading specs from 
>> /opt/local/lib/gcc-lib/powerpc-apple-darwin6.1/3.1/specs
>> Configured with: ../gcc3/configure --prefix=/opt/local - 
>> --enable-languages=f77 --infodir=/opt/local/share/info
>> Thread model: single
>> Apple Computer, Inc. GCC version 1151, based on gcc version 3.1 
>> 20020420 (prerelease)
>> (basically the fink one, but ported to darwinports)
>>>
>>> On Friday, October 18, 2002, at 12:16 PM, Michael Maibaum wrote:
>>>
>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>> Hash: SHA1
>>>>
>>>>
>>>> I am trying to create a darwinports package for R, but I cannot get 
>>>> R to compile on Mac OSX 10.2.
>>>>
>>>> I have install g77 which seems fine. R compiles without problems 
>>>> until it reaches
>>>>
>>>>
>>>> dumping R code in package 'methods'
>>>> Error in .Call("R_initialize_methods_metadata", table, PACKAGE = 
>>>> "methods") :
>>>>         .Call function name not in load table
>>>> Execution halted
>>>> gnumake[4]: *** [../../../library/methods/R/all.rda] Error 1
>>>>
>>>>
>>>> my configure environment is
>>>> 	FFLAGS="-O3 -funroll-all-loops" LDFLAGS="-L/opt/local/lib/" \
>>>> 				CPPFLAGS="-I/opt/local/include/"
>>>>
>>>> configure.args	--without-gnome --enable-R-shlib - 
>>>> --mandir='/opt/local/share/man' \
>>>> 				--with-tcl-config=/System/Library/Tcl/8.3/tclConfig.sh \
>>>> 				-C --without-blas
>>>>
>>>> any suggestions? THis is essentially identical to the way fink 
>>>> builds R so...?
>>>>
>>>> thanks
>>>>
>>>> Michael
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.7 (Darwin)

iD8DBQE9sJkkilk3LUlIL0MRAsOwAKCMXMqUQ6Jjncs6ndbw9aIeumpipACeOQQ6
cAJ5D5pSpyRylxvh25xQ9Z4=
=CTp8
-----END PGP SIGNATURE-----

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Sat Oct 19 01:34:20 2002
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 18 Oct 2002 16:34:20 -0700
Subject: [R] Building R on Mac OS X-"dumping methods" problem
In-Reply-To: <09C91FEA-E2CE-11D6-A816-000A277AA008@gene-hacker.net>
References: <09C91FEA-E2CE-11D6-A816-000A277AA008@gene-hacker.net>
Message-ID: <p05111a05b9d648985a56@[128.115.153.6]>

I don't think I can help debug your problem with specific 
suggestions, but I can say that a after a default configure R 
compiles successfully in 10.2. Albeit, with various additional 
libraries installed from fink (dlcompat  readline  g77  ncurses  pcre 
bzip2 tcltk atlas)

Presumably, then, your problem results from one of the non-default 
args you have supplied to configure, or perhaps the absence of one of 
those other packages, or maybe a difference between the darwinports 
version of one of them and fink's version.

I hope this helps at least a little!

-Don

At 12:16 PM -0700 10/18/02, Michael Maibaum wrote:
>-----BEGIN PGP SIGNED MESSAGE-----
>Hash: SHA1
>
>
>I am trying to create a darwinports package for R, but I cannot get 
>R to compile on Mac OSX 10.2.
>
>I have install g77 which seems fine. R compiles without problems 
>until it reaches
>
>
>dumping R code in package 'methods'
>Error in .Call("R_initialize_methods_metadata", table, PACKAGE = "methods") :
>         .Call function name not in load table
>Execution halted
>gnumake[4]: *** [../../../library/methods/R/all.rda] Error 1
>
>
>my configure environment is
>	FFLAGS="-O3 -funroll-all-loops" LDFLAGS="-L/opt/local/lib/" \
>				CPPFLAGS="-I/opt/local/include/"
>
>configure.args	--without-gnome --enable-R-shlib - 
>--mandir='/opt/local/share/man' \
> 
>	--with-tcl-config=/System/Library/Tcl/8.3/tclConfig.sh \
>				-C --without-blas
>
>any suggestions? THis is essentially identical to the way fink builds R so...?
>
>thanks
>
>Michael
>-----BEGIN PGP SIGNATURE-----
>Version: GnuPG v1.0.7 (Darwin)
>
>iD8DBQE9sF32ilk3LUlIL0MRAoz1AJ9EQbLFSYAWualuWJDiyvGuA9oc1ACgwQLY
>7PQtpox/Dxtw5oN7OLRcMvs=
>=FzYj
>-----END PGP SIGNATURE-----
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mike at gene-hacker.net  Sat Oct 19 01:49:25 2002
From: mike at gene-hacker.net (Michael Maibaum)
Date: Fri, 18 Oct 2002 16:49:25 -0700
Subject: [R] Building R on Mac OS X-"dumping methods" problem
In-Reply-To: <p05111a05b9d648985a56@[128.115.153.6]>
Message-ID: <3BB53D5C-E2F4-11D6-A816-000A277AA008@gene-hacker.net>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


On Friday, October 18, 2002, at 04:34 PM, Don MacQueen wrote:

> I don't think I can help debug your problem with specific suggestions, 
> but I can say that a after a default configure R compiles successfully 
> in 10.2. Albeit, with various additional libraries installed from fink 
> (dlcompat  readline  g77  ncurses  pcre bzip2 tcltk atlas)

I have dlcompat, readline, g77, ncurses and bzip2 ship with 10.2, are 
they explicitly needed to be rebuilt, I was keeping things simple and 
not trying to build the tk interface or atlas, that is for once I got 
the basics going (I thought....). I've also tried building R with no 
additional args to configure, except ENV variables needed to point it 
at g77 in /opt/local.

>
> Presumably, then, your problem results from one of the non-default 
> args you have supplied to configure, or perhaps the absence of one of 
> those other packages, or maybe a difference between the darwinports 
> version of one of them and fink's version.
>
> I hope this helps at least a little!

thanks for the help, I'l keep tweaking variables in the system and see 
if I can tie it down to something. I just need a faster machine to do 
all this recompiling on ;)

cheers

Michael

>
> -Don
>
> At 12:16 PM -0700 10/18/02, Michael Maibaum wrote:
>>
>> I am trying to create a darwinports package for R, but I cannot get R 
>> to compile on Mac OSX 10.2.
>>
>> I have install g77 which seems fine. R compiles without problems 
>> until it reaches
>>
>>
>> dumping R code in package 'methods'
>> Error in .Call("R_initialize_methods_metadata", table, PACKAGE = 
>> "methods") :
>>         .Call function name not in load table
>> Execution halted
>> gnumake[4]: *** [../../../library/methods/R/all.rda] Error 1
>>
>>
>> my configure environment is
>> 	FFLAGS="-O3 -funroll-all-loops" LDFLAGS="-L/opt/local/lib/" \
>> 				CPPFLAGS="-I/opt/local/include/"
>>
>> configure.args	--without-gnome --enable-R-shlib - 
>> --mandir='/opt/local/share/man' \
>> 	--with-tcl-config=/System/Library/Tcl/8.3/tclConfig.sh \
>> 				-C --without-blas
>>
>> any suggestions? THis is essentially identical to the way fink builds 
>> R so...?
>>
>> thanks
>>
>> Michael
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.7 (Darwin)

iD8DBQE9sJ4Kilk3LUlIL0MRAnrlAJ91oW0e3LjwrNlcNmBADFSBjm2l6wCeMrNn
1DDXtxWtY/2wBSBc5NF2NsU=
=R8C7
-----END PGP SIGNATURE-----

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tom.kennedy at bigpond.com  Sat Oct 19 02:37:10 2002
From: tom.kennedy at bigpond.com (Tom Kennedy)
Date: Sat, 19 Oct 2002 11:37:10 +1100
Subject: [R] Building R on Mac OS X-"dumping methods" problem
Message-ID: <3DB0A936.7060209@bigpond.com>

I have also had the same problem in trying to get R to build on MacOS X.

dumping R code in package 'methods'
Error in .Call("R_initialize_methods_metadata", table, PACKAGE = 
"methods") :
         .Call function name not in load table
Execution halted


OS	10.2.1
gcc	3.1 --supplied by apple
g77	GNU Fortran (GCC 3.1 20020420 (prerelease))
./configure --with-aqua --without-x --enable-R-shlib CPPFLAGS=''

which gives

R is now configured for powerpc-apple-darwin6.1

   Source directory:          .
   Installation directory:    /usr/local

   C compiler:                gcc  -g -O2
   C++ compiler:              g++  -g -O2
   Fortran compiler:          g77  -g -O2

   X11 support:               no
   Gnome support:             no
   Tcl/Tk support:            no
   Readline support:          no

   R profiling support:       yes
   R as a shared library:     yes

   Recommended packages:      no


I have used a number of differing configurations all without success.

./configure
./configure --with-x
./configure --with-aqua --without-x

I used have darwinports instead of fink to get dlcompat.
I don't think darwinports current has a g77 for instllation. I got mine 
from http://gravity.psu.edu/~khanna/g77v3-bin.tar.gz .
I build without atlas or tcltk.
Why do you need to get a curses lib and bzip2, there are already 
versions installed in 10.2?

The cvs version of fink for 10.2 always kernel panics my machine during 
the apt compile, so I have not been able to use fink.

I had the same error on a solaris box (2.6) which resolved when gcc was 
upgraded to 3.3.

-Tom






-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From stop4optimal at hotmail.com  Sat Oct 19 03:41:09 2002
From: stop4optimal at hotmail.com (chenwj)
Date: Sat, 19 Oct 2002 03:41:09 +0200 (MEST)
Subject: [R] Date: Sat, 19 Oct 2002 09:44:55 +0800
Message-ID: <OE69EUPiiB1rsrfkgU700002fb5@hotmail.com>

hi all,

i'v got a question here:

i'm writing a *.bat file using Rterm.exe to several simliar R files, which
all contain functions from some outside package (eg. quantreg).  my question
is, how to invoke the package in my *.bat file.

Anyone give a hand to me?

regards,
chenwj



Dept. of Statistics
Fudan Univerisity, China
email: chenwj at online.sh.cn
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jaitchis at hwy.com.au  Sat Oct 19 09:49:32 2002
From: jaitchis at hwy.com.au (John Aitchison)
Date: Sat, 19 Oct 2002 17:49:32 +1000
Subject: [R] RAM usage
In-Reply-To: <Pine.LNX.4.31.0210181355400.7984-100000@gannet.stats>
References: <3DAFE20E.50505@delfi.lt>
Message-ID: <3DB19B2C.8811.1FFB91@localhost>



On 18 Oct 2002, at 14:03, ripley at stats.ox.ac.uk wrote:

> On Fri, 18 Oct 2002, Vaidotas Zemlys wrote:
> 
> > I'm having problems while working with large data sets with R 1.5.1
> > in windows 2000. Given a integer matrix size of 30 columns and 
> > 15000 rows my function should return a boolean matrix size of about
> > 5000 rows and 15000 columns.

snip
> 
> 
> Don't think so.  More likely that Windows is having problems managing
> the memory requirements.  You are trying to access an object too big
> to fit into RAM, and that going to cause severe strain.

snip
> 
> Again, there is likely a problem with Windows allocating a contiguous
> chunk of 300Mb of memory.  Try this sort of thing only after a fresh
> reboot.
> 
snip

> 
> R can. The question is `can Windows'?  If possible use a Unix-based
> OS.

Windows leaves a LOT of junk lying around in RAM (recently used 
DLL's etc)  and even after a reboot there is still some reclaimable 
RAM (from processes used in startup). 

I use a program called MemTurbo http://www.memturbo.com/
which will do a ram scrub (releasing unused ram when free ram 
limits are reached) and a ram defrag (so if contiguous ram is 
needed then this might help). It has been around a while, I have 
used it since an earlier version .. I don't believe it is perfect but it 
does seem to do a good job of the arcane area of windows memory 
management. 

Maybe that will help to get you "clean ram".

The other area that might be worth attention is the number of 
processes that are currently running .. you can perhaps kill some 
of these. And, of course defragging your hard disk(s) and perhaps 
managing the swap file yourself are old favourites, not to mention 
cleaning the registry .. none of these should in theory have 
anything to do with memory management (by R), but in practice 
there seem to be some complex "interactions" in the OS, between 
the OS and the registry and RAM and concurrent threads. 

I have also found that a "lightly loaded"  Windows machine (one 
with very few programs installed) is much more likely to be stable 
than one with many programs installed, and I have a glimmering of 
an idea that there is some critical size of the registry beyond which 
something starts to thrash (? if the registry size is greater than 
available physical RAM) . Of course none of this registry business  
SHOULD affect R, but then again, Windoze is a black box, so who 
knows what goes on with program loading, thread interaction etc 
etc


To cut a long story short, it might just possibly help if you try to 
keep your ram and your disks and swapfiles and registry as clean 
as possible.


fwiw





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jaitchis at hwy.com.au  Sat Oct 19 09:49:32 2002
From: jaitchis at hwy.com.au (John Aitchison)
Date: Sat, 19 Oct 2002 17:49:32 +1000
Subject: [R] RAM usage
In-Reply-To: <Pine.LNX.4.31.0210181355400.7984-100000@gannet.stats>
References: <3DAFE20E.50505@delfi.lt>
Message-ID: <3DB19B2C.8811.1FFB91@localhost>



On 18 Oct 2002, at 14:03, ripley at stats.ox.ac.uk wrote:

> On Fri, 18 Oct 2002, Vaidotas Zemlys wrote:
> 
> > I'm having problems while working with large data sets with R 1.5.1
> > in windows 2000. Given a integer matrix size of 30 columns and 
> > 15000 rows my function should return a boolean matrix size of about
> > 5000 rows and 15000 columns.

snip
> 
> 
> Don't think so.  More likely that Windows is having problems managing
> the memory requirements.  You are trying to access an object too big
> to fit into RAM, and that going to cause severe strain.

snip
> 
> Again, there is likely a problem with Windows allocating a contiguous
> chunk of 300Mb of memory.  Try this sort of thing only after a fresh
> reboot.
> 
snip

> 
> R can. The question is `can Windows'?  If possible use a Unix-based
> OS.

Windows leaves a LOT of junk lying around in RAM (recently used 
DLL's etc)  and even after a reboot there is still some reclaimable 
RAM (from processes used in startup). 

I use a program called MemTurbo http://www.memturbo.com/
which will do a ram scrub (releasing unused ram when free ram 
limits are reached) and a ram defrag (so if contiguous ram is 
needed then this might help). It has been around a while, I have 
used it since an earlier version .. I don't believe it is perfect but it 
does seem to do a good job of the arcane area of windows memory 
management. 

Maybe that will help to get you "clean ram".

The other area that might be worth attention is the number of 
processes that are currently running .. you can perhaps kill some 
of these. And, of course defragging your hard disk(s) and perhaps 
managing the swap file yourself are old favourites, not to mention 
cleaning the registry .. none of these should in theory have 
anything to do with memory management (by R), but in practice 
there seem to be some complex "interactions" in the OS, between 
the OS and the registry and RAM and concurrent threads. 

I have also found that a "lightly loaded"  Windows machine (one 
with very few programs installed) is much more likely to be stable 
than one with many programs installed, and I have a glimmering of 
an idea that there is some critical size of the registry beyond which 
something starts to thrash (? if the registry size is greater than 
available physical RAM) . Of course none of this registry business  
SHOULD affect R, but then again, Windoze is a black box, so who 
knows what goes on with program loading, thread interaction etc 
etc


To cut a long story short, it might just possibly help if you try to 
keep your ram and your disks and swapfiles and registry as clean 
as possible.


fwiw





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Oct 19 10:28:38 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 19 Oct 2002 09:28:38 +0100 (BST)
Subject: [R] data.frame bug?
In-Reply-To: <Pine.A41.4.44.0210180709340.126482-100000@homer38.u.washington.edu>
Message-ID: <Pine.LNX.4.31.0210190927360.14639-100000@gannet.stats>

The example is a bug in format.AsIs which I have just fixed.

On Fri, 18 Oct 2002, Thomas Lumley wrote:

> On Fri, 18 Oct 2002, Patrick Connolly wrote:
>
> > On Thu, 17-Oct-2002 at 04:30PM -0500, Chong Gu wrote:
> >
> > |>
> > |> I'd like to create a data frame with components
> > |>
> > |> > jk$x1
> > |> [1] 2
> > |> > jk$x2
> > |>          [,1] [,2]
> > |> [1,]    0    0
> > |>
> > |> I used to be able to do it with
> > |>
> > |> > jk <- data.frame(x1=2,x2=I(matrix(0,1,2)))
> > |>
> > |> But now I get a error message.
> > |>
> > |> Can I still do what I want?  Thanks for any help.
> >
> > Not if you want to call and use it a data frame.  A list as you've
> > made could still suit your purposes, but if you want a dataframe, it
> > has to have elements that are of equal lengths.
> >
>
> This is slightly misleading.  It's quite possible to have complicated
> objects in a data frame, including things that are in fact matrices
> eg
>    data.frame(a=1:2,b=Surv(1:2))
> where the second column is a matrix with some extra attributes. This is a
> Good Thing.
>
> It has in the past been possible to have matrices in data frames, and it
> still is possible to create them -- the reported bug is in printing them,
> and I think it is a bug.
>
> 	-thomas
>
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sat Oct 19 11:50:16 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 19 Oct 2002 11:50:16 +0200
Subject: [R] Building R on Mac OS X-"dumping methods" problem
In-Reply-To: <3DB0A936.7060209@bigpond.com>
References: <3DB0A936.7060209@bigpond.com>
Message-ID: <x265vy69lz.fsf@biostat.ku.dk>

Tom Kennedy <tom.kennedy at bigpond.com> writes:

> I have also had the same problem in trying to get R to build on MacOS X.
> 
> dumping R code in package 'methods'
> Error in .Call("R_initialize_methods_metadata", table, PACKAGE =
> "methods") :
>          .Call function name not in load table
> Execution halted

Hmm. Now I don't know OSX, but this points quite squarely at a dynamic
library loading failure. Does this affect other .Call() instances? Is
it possible that you're picking up another version of methods.so (or
whatever the extension is)? 

Are there "ldd" and "nm" command in MOSX? If so, what do they tell you
about the dyn.lib.? Is there an R_initialize_methods_metadata in it?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sat Oct 19 12:47:55 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 19 Oct 2002 12:47:55 +0200
Subject: [R] Date: Sat, 19 Oct 2002 09:44:55 +0800
References: <OE69EUPiiB1rsrfkgU700002fb5@hotmail.com>
Message-ID: <3DB1385B.D9B3C4E7@statistik.uni-dortmund.de>

chenwj wrote:
> 
> hi all,
> 
> i'v got a question here:
> 
> i'm writing a *.bat file using Rterm.exe to several simliar R files, which
> all contain functions from some outside package (eg. quantreg).  my question
> is, how to invoke the package in my *.bat file.
> 
> Anyone give a hand to me?
> 
> regards,
> chenwj
> 

Write "library(quantreg)" in your R files, it cannot be done in the
Windows batch file.
Or, if you don't want to write it in each of your .R files, load the
package in .../etc/Rprofile, for example, so it is present everytime R
starts.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sat Oct 19 13:02:47 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 19 Oct 2002 13:02:47 +0200
Subject: [R] Densities in legend
References: <Pine.OSF.4.44.0210181539310.21040-100000@is08.fas.harvard.edu>
Message-ID: <3DB13BD7.30BD7E6A@statistik.uni-dortmund.de>

Daniel En-Wenn Ho wrote:
> 
> Hello all,
> 
> Does anyone know how to add densities of a histogram to a legend?
> 
> I have tried to label five histograms with the following code, to no
> avail -- each time, the legend symbol is simply blank.
> 
> postscript("graph9.eps")
> title=c("Comparison of Quintiles")
> hist(quant1$pre,xlim=c(260,310),ylim=c(0,12),ylab="Frequency",xlab="Cholesterol",density=10,main=title)
> hist(quant2$pre,add=TRUE,density=20)
> hist(quant3$pre,add=TRUE,density=30)
> hist(quant4$pre,add=TRUE,density=40)
> hist(quant5$pre,add=TRUE,density=50)
> legend(260,12,density=c(10,20,30,40,50),legend=c("Quintile 1","Quintile 2","Quintile 3","Quintile 4","Quintile 5"))
> dev.off()
> 

The following will do the trick:
  legend(260, 12, fill = TRUE, angle = 45, density = 1:5 * 10, legend =
paste("Quantile", 1:5))

a) You need to specify "fill = TRUE" to draw boxes beside the legend
texts.
b) You need to specify an "angle" to plot shading lines.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Sat Oct 19 18:29:46 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sat, 19 Oct 2002 09:29:46 -0700
Subject: [R] Building R on Mac OS X-"dumping methods" problem
In-Reply-To: <x265vy69lz.fsf@biostat.ku.dk>
Message-ID: <FAB42F97-E37F-11D6-9E42-000393860F3C@stat.ucla.edu>

It's something local. One thing that comes to mind is: did he unpack
the R-1.6.0 archive with Stuffit Expander ? Older versions truncate long
filenames. Always use tar or pax.

nm methods.so | grep R_initialize

should tell Tom if the symbol is there

On Saturday, October 19, 2002, at 02:50 AM, Peter Dalgaard BSA wrote:

> Tom Kennedy <tom.kennedy at bigpond.com> writes:
>
>> I have also had the same problem in trying to get R to build on MacOS  
>> X.
>>
>> dumping R code in package 'methods'
>> Error in .Call("R_initialize_methods_metadata", table, PACKAGE =
>> "methods") :
>>          .Call function name not in load table
>> Execution halted
>
> Hmm. Now I don't know OSX, but this points quite squarely at a dynamic
> library loading failure. Does this affect other .Call() instances? Is
> it possible that you're picking up another version of methods.so (or
> whatever the extension is)?
>
> Are there "ldd" and "nm" command in MOSX? If so, what do they tell you
> about the dyn.lib.? Is there an R_initialize_methods_metadata in it?
>
> --  
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nlpace at remi.med.utah.edu  Sat Oct 19 22:22:13 2002
From: nlpace at remi.med.utah.edu (Nathan Leon Pace, MD, MStat)
Date: Sat, 19 Oct 2002 14:22:13 -0600
Subject: [R] confidence intervals
Message-ID: <3DB1BEF5.9070701@bigpace.med.utah.edu>

Hi,

I have created non linear mixed effects models using the nlme package 
version 3.

I'm looking for methods (software) to calculate confidence intervals on 
population predicted values.

Thanks

-- 
Nathan Leon Pace, MD, MStat  Work:nlpace at bigpace.med.utah.ed
Department of Anesthesiology Play:nlpaces at attbi.com
University of Utah           Voice Work:801.581.6393  Play:801.467.2925
Salt Lake City, Utah         Fax   Work:801.581.4367  Play:801.467.0555


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tom.kennedy at bigpond.com  Sun Oct 20 00:38:12 2002
From: tom.kennedy at bigpond.com (Tom Kennedy)
Date: Sun, 20 Oct 2002 09:38:12 +1100
Subject: [R] Building R on Mac OS X-"dumping methods" problem
Message-ID: <3DB1DED4.3060903@bigpond.com>

I have done some more homework.
I am running macos X 10.2.1 on a G3 700MHz ibook.
Developer tool July 2002 with August update.

I get R by rsync. I have tried all three version released, pathched and 
devel and get the same problem with all of them.

If I run nm on methods.so, I get:

       $nm methods.so |grep R_initialize
       00002db8 T _R_initialize_methods_metadata

It is present but, is the leading underscore significant?

There is no 'ldd' on darwin but otool -L is the same I think. It gives 
the same output.

        $otool -L methods.so
        methods.so:
         /usr/local/lib/R/bin/libR.dylib (compatibility version 0.0.0, 
      current version 0.0.0)
        /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current 
version 60.2.0)

This is a curious result since there is not currently a library at
/usr/local/lib/R/bin/libR.dylib since I have not install yet.
I did do a partial install and it made no difference.

If I look for libraries in R.bin, I get the following result and it 
looks OK to me. Likewise it is identical for the dynamic library 
libR.dylib. It is finding the dlcompat libdl, using the system ncurses, 
libc and libz library.

$otool -L R.bin
R.bin:
         /System/Library/Frameworks/Carbon.framework/Versions/A/Carbon 
(compatibility version 2.0.0, current version 122.0.0)
         /opt/local/lib/libdl.1.dylib (compatibility version 1.0.0, 
current version 1.0.0)
         /usr/lib/libncurses.5.dylib (compatibility version 5.0.0, 
current version 5.0.0)
         /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, 
current version 60.2.0)
         /usr/lib/libz.1.1.3.dylib (compatibility version 1.0.0, current 
version 1.1.3)

In the R.bin, I looked for Call routine

$nm R.bin|grep Call
00002bd8 T _R_addCallRoutine
00071988 T _R_addTaskCallback
00071624 T _R_getTaskCallbackNames
000715c0 T _R_removeTaskCallback
00071810 T _R_taskCallbackRoutine
000860e8 T _RecordGraphicsCall
000712a4 T _Rf_addTaskCallback
00002c34 T _Rf_freeCallSymbol
000032c8 T _Rf_lookupRegisteredCallSymbol
00071480 T _Rf_removeTaskCallbackByIndex
000713a0 T _Rf_removeTaskCallbackByName
0005544c t _assignCall
00012ccc T _baseCallback
00085038 t _makeErrorCall
0005533c t _replaceCall

Does this look right?

I tested another .Call interface by running R and then loading library 
ctest. ansari uses a library call and I got this result for 
example(ansari.test).

...
Warning message:
Cannot compute exact p-value with ties in: ansari.test.default(ramsay, 
jung.parekh)
Error in .C("pansari", as.integer(length(q)), p = as.double(q), 
as.integer(m),  :
         C/Fortran function name not in load table

Looks like this is not just a problem in metheds.so.
Could the configure process be going wrong? The R.bin seems
to work OK but it cannot load external dynamic libraries.

Regards Tom




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Sun Oct 20 01:18:11 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Sat, 19 Oct 2002 19:18:11 -0400
Subject: [R] Missing values?
In-Reply-To: <20021010174118.GA1372@komensky.surfbest.net>
References: <1034248750.5057.77.camel@gandalf> <x2bs62wmh6.fsf@biostat.ku.dk> <1034256247.5051.80.camel@gandalf> <200210100933010600.0020E828@smtp.interchange.ubc.ca> <20021010174118.GA1372@komensky.surfbest.net>
Message-ID: <20021019231811.GA662@komensky.surfbest.net>


Simple question: I have imported a table from SPSS via read.spss,
but I have not figured out how to tell R that values 8,9 are
considered NA.

After reading help, I thought that something like

is.na(data$P4)<-c(8,9)

would go, but apparently it doesn't (mean gives the same value
without regards to na.rm).

Could anybody help me, please?

Thanks,

	Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
See, when the GOVERNMENT spends money, it creates jobs; whereas
when the money is left in the hands of TAXPAYERS, God only knows
what they do with it. Bake it into pies, probably. Anything to
avoid creating jobs.
    -- Dave Barry

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From stop4optimal at hotmail.com  Sun Oct 20 08:21:06 2002
From: stop4optimal at hotmail.com (chenwj)
Date: Sun, 20 Oct 2002 14:21:06 +0800
Subject: [R] Date: Sat, 19 Oct 2002 09:44:55 +0800
References: <OE69EUPiiB1rsrfkgU700002fb5@hotmail.com> <3DB1385B.D9B3C4E7@statistik.uni-dortmund.de>
Message-ID: <OE33XH0R5f94h0FiXiF00003a1b@hotmail.com>

thank you very much!

but could you please explain more details about your 2 proposals,  'coz i'm
completely new in R (especially for the second one)?

best regards,
chenwj


----- Original Message -----
From: "Uwe Ligges" <ligges at statistik.uni-dortmund.de>
To: "chenwj" <stop4optimal at hotmail.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Saturday, October 19, 2002 6:47 PM
Subject: Re: [R] Date: Sat, 19 Oct 2002 09:44:55 +0800


> chenwj wrote:
> >
> > hi all,
> >
> > i'v got a question here:
> >
> > i'm writing a *.bat file using Rterm.exe to several simliar R files,
which
> > all contain functions from some outside package (eg. quantreg).  my
question
> > is, how to invoke the package in my *.bat file.
> >
> > Anyone give a hand to me?
> >
> > regards,
> > chenwj
> >
>
> Write "library(quantreg)" in your R files, it cannot be done in the
> Windows batch file.
> Or, if you don't want to write it in each of your .R files, load the
> package in .../etc/Rprofile, for example, so it is present everytime R
> starts.
>
> Uwe Ligges
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Oct 20 09:15:57 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 20 Oct 2002 08:15:57 +0100 (BST)
Subject: [R] Missing values?
In-Reply-To: <20021019231811.GA662@komensky.surfbest.net>
Message-ID: <Pine.LNX.4.31.0210200812160.16164-100000@gannet.stats>

On Sat, 19 Oct 2002, Matej Cepl wrote:

> Simple question: I have imported a table from SPSS via read.spss,
> but I have not figured out how to tell R that values 8,9 are
> considered NA.
>
> After reading help, I thought that something like
>
> is.na(data$P4)<-c(8,9)
>
> would go, but apparently it doesn't (mean gives the same value
> without regards to na.rm).

That sets NA values alternately to 8 and 9.  Try

attach(data)
P4[P4 %in% c(8, 9)] <- NA
detach()

assuming P4 is a numeric vector.

There's a section on `Re-coding Missing Values' in MASS4 that elaborates
on this.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From phgrosje at ulb.ac.be  Sun Oct 20 10:44:06 2002
From: phgrosje at ulb.ac.be (Philippe Grosjean)
Date: Sun, 20 Oct 2002 10:44:06 +0200
Subject: [R] Interrupt calc/buffer output of R under Windows
Message-ID: <MABBLJDICACNFOLGIHJOCEAGDAAA.phgrosje@ulb.ac.be>

Hi all,

I want maximum control of R, including calculation / buffer output
interruption. With Rgui, pressing ESC interrupt both calculation and buffer
output. However, with Rterm, ctrl-c works only in calculation, but does not
interrupt buffer output:

with:

i <- 1
while (i > 0) i <- i + 1

which runs an infinite loop, pressing ctrl-c interrupt it. OK. But:

rnorm(1000000)

is not interrupted before the 1,000,000 numbers are buffered to the console.
I only can pausi it temporarily by pression break, but I do not come back to
the prompt and buffer output is continued when I "unpause" it.

Any hint on how to stop buffer output in RTerm?

By the way, is it something different in infer mode (Rterm --ess)? What are
the major differences between normal and infer mode?

Thank you.
Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
( ( ( ( (
 ) ) ) ) )      Philippe Grosjean
( ( ( ( (
 ) ) ) ) )      IFREMER Nantes - DEL/AO
( ( ( ( (       rue de l'Ile d'Yeu, BP 21105, 44311 Nantes Cedex 3
 ) ) ) ) )      tel: (33) 02.40.37.42.29, fax: (33) 02.40.37.42.41
( ( ( ( (
 ) ) ) ) )      SciViews project coordinator (http://www.sciviews.org)
( ( ( ( (       e-mail: phgrosjean at sciviews.org
 ) ) ) ) )
( ( ( ( (       "I'm 100% confident that p is between 0 and 1"
 ) ) ) ) )                                L. Gonick & W. Smith (1993)
.......................................................................


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Oct 20 11:59:08 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 20 Oct 2002 10:59:08 +0100 (BST)
Subject: [R] Date: Sat, 19 Oct 2002 09:44:55 +0800
In-Reply-To: <OE33XH0R5f94h0FiXiF00003a1b@hotmail.com>
Message-ID: <Pine.LNX.4.31.0210201048020.16393-100000@gannet.stats>

On Sun, 20 Oct 2002, chenwj wrote:

> thank you very much!
>
> but could you please explain more details about your 2 proposals,  'coz i'm
> completely new in R (especially for the second one)?

See ?Startup or the appropriate appendix to `An Introduction to R'.

Comment to Uwe: it is _not_ a good idea to tamper with .../etc/Rprofile,
as that is part of base (and base is now a namespace).  Use
.../etc/Profile.site or .Rprofile instead, each of which is sourced in the
user workspace.

Probably the best idea is to have a file .Rprofile containing the single
line

library(quantreg)

in the same directory as the R scripts you want to run. Then every time
you start Rterm _in that directory_, that .Rprofile will be run.

Note: for Classic MacOS users, there is no Rprofile.site despite what
?Startup says in R <= 1.6.0, so use the appendix to `An Introduction to
R'.


[I have proposed a simpler mechanism for this along the lines of S4's,
with a set of files like .Rpackages and Rpackages.site which contain a
list of packages to be loaded.  It's likely to get implemented for 1.7.0.]


> ----- Original Message -----
> From: "Uwe Ligges" <ligges at statistik.uni-dortmund.de>
> To: "chenwj" <stop4optimal at hotmail.com>
> Cc: <r-help at stat.math.ethz.ch>
> Sent: Saturday, October 19, 2002 6:47 PM
> Subject: Re: [R] Date: Sat, 19 Oct 2002 09:44:55 +0800
>
>
> > chenwj wrote:
> > >
> > > hi all,
> > >
> > > i'v got a question here:
> > >
> > > i'm writing a *.bat file using Rterm.exe to several simliar R files,
> which
> > > all contain functions from some outside package (eg. quantreg).  my
> question
> > > is, how to invoke the package in my *.bat file.
> > >
> > > Anyone give a hand to me?
> > >
> > > regards,
> > > chenwj
> > >
> >
> > Write "library(quantreg)" in your R files, it cannot be done in the
> > Windows batch file.
> > Or, if you don't want to write it in each of your .R files, load the
> > package in .../etc/Rprofile, for example, so it is present everytime R
> > starts.
> >
> > Uwe Ligges
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-
> > r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> >
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
> >
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lm.silva at sapo.pt  Sun Oct 20 12:22:39 2002
From: lm.silva at sapo.pt (Luis Miguel Almeida da Silva)
Date: Sun, 20 Oct 2002 11:22:39 +0100 (WEST)
Subject: [R] scatterplot3d
Message-ID: <1035109359.3db283ef2378e@webmail.sapo.pt>

Hello!

I have a 38x3 matrix and I would like to make a 3d plot. 
However the first 27 rows are from one class and the others are 
from other class. My target is to plot the two classes with 
different colors in the same 3d plot. Is it possible? I have 
already package scatterplot3d.

Thank you

--------------------------------------------
SAPO ADSL.PT Agora o kit apenas por 75 Eur. e tr?fego ilimitado at? ao final de 2002!
sapo.pt/kitadsl
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From CJSwanepoel at t-online.de  Sun Oct 20 11:44:27 2002
From: CJSwanepoel at t-online.de (CJSwanepoel@t-online.de)
Date: Sun, 20 Oct 2002 11:44:27 +0200 (CEST)
Subject: [R] Make on RedHat 8.0
Message-ID: <1035106171.3db2777bc7615@webmail.t-online.de>

Hallo R-help,

I am experiencing difficulty when making R on RedHat Linux 8.0. I'm not
able to display my plots with the R-Viewer. The default file
'Rplots.ps' is also not consistent with the last plot so that I can't
use an external PS-Viewer to view my plots. Does R support RH 8.0? Do
you have any suggestions on how I can solve this problem? Is a .RPM
planned for the near future?

Thanks in advance
Chris.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sun Oct 20 16:09:44 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 20 Oct 2002 16:09:44 +0200
Subject: [R] scatterplot3d
References: <1035109359.3db283ef2378e@webmail.sapo.pt>
Message-ID: <3DB2B928.76D9EF6B@statistik.uni-dortmund.de>



Luis Miguel Almeida da Silva wrote:
> 
> Hello!
> 
> I have a 38x3 matrix and I would like to make a 3d plot.
> However the first 27 rows are from one class and the others are
> from other class. My target is to plot the two classes with
> different colors in the same 3d plot. Is it possible? I have
> already package scatterplot3d.

Yes, just specify a vector containing the colours (either by names or
numbers). Example:

  X <- matrix(rnorm(3*38), ncol = 3)
  scatterplot3d(X, type = "h", 
    color = rep(c("black", "red"), c(27, 11)))

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Sun Oct 20 18:53:17 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: 20 Oct 2002 11:53:17 -0500
Subject: [R] Make on RedHat 8.0
In-Reply-To: <1035130665.1542.6.camel@DELL8200>
References: <1035130665.1542.6.camel@DELL8200>
Message-ID: <1035132798.1542.42.camel@DELL8200>

> Hallo R-help,
> 
> I am experiencing difficulty when making R on RedHat Linux 8.0. I'm not
> able to display my plots with the R-Viewer. The default file
> 'Rplots.ps' is also not consistent with the last plot so that I can't
> use an external PS-Viewer to view my plots. Does R support RH 8.0? Do
> you have any suggestions on how I can solve this problem? Is a .RPM
> planned for the near future?
> 
> Thanks in advance
> Chris. 

Chris,

I now have a dual-boot WinXP Pro/RH 8.0 system running on a Dell i8200
laptop and recently downloaded the 1.6.0 source RPM from CRAN
(http://cran.r-project.org/bin/linux/redhat/SRPMS/). I did an "rpmbuild
--rebuild" on it and installed the resultant RPM. I have not attempted
to build R from "pure" source, though I do have the source tarball.

So far it seems to be working well, though I will acknowledge that I
have not performed extensive testing on it.  

The one thing to note is that the resultant RPM file is about 10.8 Mb
versus the RH 7.x RPM at 11.4 Mb. I am not sure if I erred in the
building of the 8.0 RPM or if this is to be expected as a result of the
changes in RH 8.0.

Chris, if you have some sample code/data, I would be happy to test it on
my system.

I am also copying Martyn Plummer, as the RH maintainer on this, to
solicit any feedback. If the RPM that I have created is valid, I would
be more than happy to make it available for CRAN. If it is not, I would
be happy to engage in appropriate changes to make it so.

Marc


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From umalvarez at fata.unam.mx  Sun Oct 20 19:14:28 2002
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Sun, 20 Oct 2002 12:14:28 -0500 (CDT)
Subject: [R] R 1.6.0 running on Mac OS 10.2.1?
In-Reply-To: <3DB1DED4.3060903@bigpond.com>
Message-ID: <Pine.LNX.4.44.0210201211030.14086-100000@fata.unam.mx>

Hi:

Has anybody of the Mac users been able to install R 1.6.0 on a Mac with 
the OS Jaguar?

For what I've been reading, doesn't seem so.

Any help will be appreciated.

-- 
Ulises M. Alvarez
LAB. DE CHOQUES DEBILES
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From R.Goecke at t-online.de  Sun Oct 20 21:42:11 2002
From: R.Goecke at t-online.de (Roland Goecke)
Date: Sun, 20 Oct 2002 21:42:11 +0200
Subject: [R] Visualising the effects of PCAs
Message-ID: <3DB30713.5010804@t-online.de>

Hi,

this may sound like a very stupid question and perhaps it is, so I 
apologise in advance if anyone feels bored by it.

I have done some principal component analysis with prcomp and what I 
would like to do is to visualise the effect of a principal component, 
i.e. show a graph of my data and then show how that graph would change 
if I go, let's say, one standard deviation, in either direction. Kind of 
original graph plus graph with +1 s.d. plus graph with -1 s.d. I know 
how to plot several graphs together but how do I compute the points of 
the graphs with the PC effects in R?

Regards
Roland

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Sun Oct 20 22:43:01 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sun, 20 Oct 2002 13:43:01 -0700
Subject: [R] R 1.6.0 running on Mac OS 10.2.1?
In-Reply-To: <Pine.LNX.4.44.0210201211030.14086-100000@fata.unam.mx>
Message-ID: <8658DC07-E46C-11D6-8653-000393860F3C@stat.ucla.edu>

Darwin/X11 R 1.6.0 installs out of the box on Jaguar, provided
you have the appropriate fink libraries on your machine (xfree86,  
dlcompat,
readline, tcltk, libjpeg, libpng, g77 or f2c, gnome if you want it),
and provided g77, readline, and f2c are the 10.2 versions of
these fink tools. So: update the OS, then update fink, then install R.

See ftp://gifi.stat.ucla.edu/pub/R-1.6.0.tar.gz (this has more than
240 precompiled packages), but it does not have the dylibs from
fink (and, for some packages, from various other places).

What you had been reading about was an attempt to use darwinports
instead of fink (so far without success).

Also, the Carbon R runs just fine on Jaguar.

On Sunday, October 20, 2002, at 10:14 AM, Ulises Mora Alvarez wrote:

> Hi:
>
> Has anybody of the Mac users been able to install R 1.6.0 on a Mac with
> the OS Jaguar?
>
> For what I've been reading, doesn't seem so.
>
> Any help will be appreciated.
>
> --  
> Ulises M. Alvarez
> LAB. DE CHOQUES DEBILES
> FISICA APLICADA Y TECNOLOGIA AVANZADA
> UNAM
> umalvarez at fata.unam.mx
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From David.Orlovich at botany.otago.ac.nz  Sun Oct 20 23:03:45 2002
From: David.Orlovich at botany.otago.ac.nz (David Orlovich)
Date: Mon, 21 Oct 2002 10:03:45 +1300
Subject: [R] R 1.6.0 running on Mac OS 10.2.1?
In-Reply-To: <8658DC07-E46C-11D6-8653-000393860F3C@stat.ucla.edu>
Message-ID: <6BD1B6F2-E46F-11D6-92B9-000A2793FF1A@planta.otago.ac.nz>

Initially I had troubles installing the Darwin X11 R but this weekend I  
successfully compiled KDE, then I compiled R 1.6.0 on my machine  
(running Jaguar), and it all works fine.  Don't give up :)  David  
Orlovich.


On Monday, October 21, 2002, at 09:43 AM, Jan de Leeuw wrote:

> Darwin/X11 R 1.6.0 installs out of the box on Jaguar, provided
> you have the appropriate fink libraries on your machine (xfree86,  
> dlcompat,
> readline, tcltk, libjpeg, libpng, g77 or f2c, gnome if you want it),
> and provided g77, readline, and f2c are the 10.2 versions of
> these fink tools. So: update the OS, then update fink, then install R.
>
> See ftp://gifi.stat.ucla.edu/pub/R-1.6.0.tar.gz (this has more than
> 240 precompiled packages), but it does not have the dylibs from
> fink (and, for some packages, from various other places).
>
> What you had been reading about was an attempt to use darwinports
> instead of fink (so far without success).
>
> Also, the Carbon R runs just fine on Jaguar.
>
> On Sunday, October 20, 2002, at 10:14 AM, Ulises Mora Alvarez wrote:
>
>> Hi:
>>
>> Has anybody of the Mac users been able to install R 1.6.0 on a Mac  
>> with
>> the OS Jaguar?
>>
>> For what I've been reading, doesn't seem so.
>>
>> Any help will be appreciated.
>>
>> -- Ulises M. Alvarez
>> LAB. DE CHOQUES DEBILES
>> FISICA APLICADA Y TECNOLOGIA AVANZADA
>> UNAM
>> umalvarez at fata.unam.mx
>>
>>
>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
>> .-.-.-.-.-
>> r-help mailing list -- Read  
>> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To:  
>> r-help-request at stat.math.ethz.ch
>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._. 
>> _._._._._
>>
>>
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical  
> Software
> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email:  
> deleeuw at stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>   
> ----------------------------------------------------------------------- 
> --------------------------
>           No matter where you go, there you are. --- Buckaroo Banzai
>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
>   
> ----------------------------------------------------------------------- 
> --------------------------
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From umalvarez at fata.unam.mx  Mon Oct 21 03:02:44 2002
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Sun, 20 Oct 2002 20:02:44 -0500 (CDT)
Subject: [R] R 1.6.0 running on Mac OS 10.2.1?
In-Reply-To: <6BD1B6F2-E46F-11D6-92B9-000A2793FF1A@planta.otago.ac.nz>
Message-ID: <Pine.LNX.4.44.0210201955410.14773-100000@fata.unam.mx>

I've just tried. It doesn't work.

After running: ./configure
I got:
Error message:
configure: error: Neither an F77 compiler nor f2c found

I've just installed and updated fik and the X server.

I'm doing something wrong. More help would be appreciated.
By the way, how you compiled KDE?

Thanks.

OS: Jaguar 10.2.1
Processor: G3 700 Mhz


On Mon, 21 Oct 2002, David Orlovich wrote:

> Initially I had troubles installing the Darwin X11 R but this weekend I  
> successfully compiled KDE, then I compiled R 1.6.0 on my machine  
> (running Jaguar), and it all works fine.  Don't give up :)  David  
> Orlovich.
> 
> 
> On Monday, October 21, 2002, at 09:43 AM, Jan de Leeuw wrote:
> 
> > Darwin/X11 R 1.6.0 installs out of the box on Jaguar, provided
> > you have the appropriate fink libraries on your machine (xfree86,  
> > dlcompat,
> > readline, tcltk, libjpeg, libpng, g77 or f2c, gnome if you want it),
> > and provided g77, readline, and f2c are the 10.2 versions of
> > these fink tools. So: update the OS, then update fink, then install R.
> >
> > See ftp://gifi.stat.ucla.edu/pub/R-1.6.0.tar.gz (this has more than
> > 240 precompiled packages), but it does not have the dylibs from
> > fink (and, for some packages, from various other places).
> >
> > What you had been reading about was an attempt to use darwinports
> > instead of fink (so far without success).
> >
> > Also, the Carbon R runs just fine on Jaguar.
> >
> > On Sunday, October 20, 2002, at 10:14 AM, Ulises Mora Alvarez wrote:
> >
> >> Hi:
> >>
> >> Has anybody of the Mac users been able to install R 1.6.0 on a Mac  
> >> with
> >> the OS Jaguar?
> >>
> >> For what I've been reading, doesn't seem so.
> >>
> >> Any help will be appreciated.
> >>
> >> -- Ulises M. Alvarez
> >> LAB. DE CHOQUES DEBILES
> >> FISICA APLICADA Y TECNOLOGIA AVANZADA
> >> UNAM
> >> umalvarez at fata.unam.mx
> >>
> >>
> >> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> >> .-.-.-.-.-
> >> r-help mailing list -- Read  
> >> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> >> Send "info", "help", or "[un]subscribe"
> >> (in the "body", not the subject !)  To:  
> >> r-help-request at stat.math.ethz.ch
> >> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._. 
> >> _._._._._
> >>
> >>
> > ===
> > Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> > Editor: Journal of Multivariate Analysis, Journal of Statistical  
> > Software
> > US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
> > phone (310)-825-9550;  fax (310)-206-5658;  email:  
> > deleeuw at stat.ucla.edu
> > homepage: http://gifi.stat.ucla.edu
> >   
> > ----------------------------------------------------------------------- 
> > --------------------------
> >           No matter where you go, there you are. --- Buckaroo Banzai
> >                    http://gifi.stat.ucla.edu/sounds/nomatter.au
> >   
> > ----------------------------------------------------------------------- 
> > --------------------------
> >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> > .-.-.-.-.-
> > r-help mailing list -- Read  
> > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To:  
> > r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> > ._._._._
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
Ulises M. Alvarez
LAB. DE CHOQUES DEBILES
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From David.Orlovich at botany.otago.ac.nz  Mon Oct 21 03:31:48 2002
From: David.Orlovich at botany.otago.ac.nz (David Orlovich)
Date: Mon, 21 Oct 2002 14:31:48 +1300
Subject: [R] R 1.6.0 running on Mac OS 10.2.1?
In-Reply-To: <Pine.LNX.4.44.0210201955410.14773-100000@fata.unam.mx>
Message-ID: <DE3A982E-E494-11D6-9E57-000393900EB4@botany.otago.ac.nz>

have you got the developer tools installed from developer.apple.com?


On Monday, October 21, 2002, at 02:02 PM, Ulises Mora Alvarez wrote:

> I've just tried. It doesn't work.
>
> After running: ./configure
> I got:
> Error message:
> configure: error: Neither an F77 compiler nor f2c found
>
> I've just installed and updated fik and the X server.
>
> I'm doing something wrong. More help would be appreciated.
> By the way, how you compiled KDE?
>
> Thanks.
>
> OS: Jaguar 10.2.1
> Processor: G3 700 Mhz
>
>
> On Mon, 21 Oct 2002, David Orlovich wrote:
>
>> Initially I had troubles installing the Darwin X11 R but this weekend  
>> I
>> successfully compiled KDE, then I compiled R 1.6.0 on my machine
>> (running Jaguar), and it all works fine.  Don't give up :)  David
>> Orlovich.
>>
>>
>> On Monday, October 21, 2002, at 09:43 AM, Jan de Leeuw wrote:
>>
>>> Darwin/X11 R 1.6.0 installs out of the box on Jaguar, provided
>>> you have the appropriate fink libraries on your machine (xfree86,
>>> dlcompat,
>>> readline, tcltk, libjpeg, libpng, g77 or f2c, gnome if you want it),
>>> and provided g77, readline, and f2c are the 10.2 versions of
>>> these fink tools. So: update the OS, then update fink, then install  
>>> R.
>>>
>>> See ftp://gifi.stat.ucla.edu/pub/R-1.6.0.tar.gz (this has more than
>>> 240 precompiled packages), but it does not have the dylibs from
>>> fink (and, for some packages, from various other places).
>>>
>>> What you had been reading about was an attempt to use darwinports
>>> instead of fink (so far without success).
>>>
>>> Also, the Carbon R runs just fine on Jaguar.
>>>
>>> On Sunday, October 20, 2002, at 10:14 AM, Ulises Mora Alvarez wrote:
>>>
>>>> Hi:
>>>>
>>>> Has anybody of the Mac users been able to install R 1.6.0 on a Mac
>>>> with
>>>> the OS Jaguar?
>>>>
>>>> For what I've been reading, doesn't seem so.
>>>>
>>>> Any help will be appreciated.
>>>>
>>>> -- Ulises M. Alvarez
>>>> LAB. DE CHOQUES DEBILES
>>>> FISICA APLICADA Y TECNOLOGIA AVANZADA
>>>> UNAM
>>>> umalvarez at fata.unam.mx
>>>>
>>>>
>>>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
>>>> .-
>>>> .-.-.-.-.-
>>>> r-help mailing list -- Read
>>>> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>>>> Send "info", "help", or "[un]subscribe"
>>>> (in the "body", not the subject !)  To:
>>>> r-help-request at stat.math.ethz.ch
>>>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._. 
>>>> _.
>>>> _._._._._
>>>>
>>>>
>>> ===
>>> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
>>> Editor: Journal of Multivariate Analysis, Journal of Statistical
>>> Software
>>> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
>>> phone (310)-825-9550;  fax (310)-206-5658;  email:
>>> deleeuw at stat.ucla.edu
>>> homepage: http://gifi.stat.ucla.edu
>>>
>>> --------------------------------------------------------------------- 
>>> --
>>> --------------------------
>>>           No matter where you go, there you are. --- Buckaroo Banzai
>>>                    http://gifi.stat.ucla.edu/sounds/nomatter.au
>>>
>>> --------------------------------------------------------------------- 
>>> --
>>> --------------------------
>>>
>>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>>> .-.-.-.-.-
>>> r-help mailing list -- Read
>>> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>>> Send "info", "help", or "[un]subscribe"
>>> (in the "body", not the subject !)  To:
>>> r-help-request at stat.math.ethz.ch
>>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
>>> ._
>>> ._._._._
>>
>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
>> .-.-.-.-.-
>> r-help mailing list -- Read  
>> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To:  
>> r-help-request at stat.math.ethz.ch
>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._. 
>> _._._._._
>>
>
> -- 
> Ulises M. Alvarez
> LAB. DE CHOQUES DEBILES
> FISICA APLICADA Y TECNOLOGIA AVANZADA
> UNAM
> umalvarez at fata.unam.mx
>
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From liulei at l.imap.itd.umich.edu  Mon Oct 21 09:01:01 2002
From: liulei at l.imap.itd.umich.edu (Lei Liu)
Date: Mon, 21 Oct 2002 03:01:01 -0400
Subject: [R] newbie question: call C function from R in Windows XP
Message-ID: <5.1.0.14.1.20021021023458.00c1ba60@l.imap.itd.umich.edu>

Hello,

I need to call an C function MH.c in my R code in Windows XP. I downloaded 
the software form http://www.stats.ox.ac.uk/pub/Rtools/ and installed them. 
But when I run the command "..\bin\Rcmd SHLIB MH.c", I got message "perl is 
not recognized as and internal or external command, operable program or 
batch file". How should I do?

As a newbie, I just wonder if there is a setup file so I can install all 
the software I needed for compiling C code once and for all. Can someone 
provide me a comprehensive list for the installation? Thanks very much!

Lei


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From xpuig at dsss.scs.es  Mon Oct 21 11:23:28 2002
From: xpuig at dsss.scs.es (Xavi)
Date: Mon, 21 Oct 2002 11:23:28 +0200
Subject: [R] mixed effect-models
Message-ID: <001301c278e3$840effc0$3418db92@dsss.scs.es>

Hello,
?
I believe that in R, it is not possible to analyze mixed effect-models
when the distribucion is not gaussian (p.e. binomial or poisson), isn't?
?
Somebody can suggest me alternative? 
?
thanks
? 
xavi
?



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From epakpahan at hki-indonesia.org  Mon Oct 21 11:27:00 2002
From: epakpahan at hki-indonesia.org (Eduwin Pakpahan)
Date: Mon, 21 Oct 2002 16:27:00 +0700
Subject: [R] R-software manual 
Message-ID: <AF0250AF659F1A4C9A2EA2D0F0EFC6E303568C@hkjkex.hkijkt.fam>

I am a student from Indonesia. 
May I know where I can find the manual using R-software? I am trying to
investigate logistic regression and likelihood using this software...

Thank you,

Edwin



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mail-list at linaria.dst.unive.it  Mon Oct 21 11:48:02 2002
From: mail-list at linaria.dst.unive.it (Claudio Agostinelli)
Date: Mon, 21 Oct 2002 11:48:02 +0200 (CEST)
Subject: [R] possible bug in sd
In-Reply-To: <Pine.LNX.4.31.0210180844130.2899-100000@gannet.stats>
Message-ID: <Pine.LNX.4.33L2.0210211143180.24474-100000@linaria.dst.unive.it>

Dear All,
I think there is a small bug in sd when the argument is a dataframe and
there are missing values:

> x <- data.frame(matrix(rnorm(12,0,1), nrow=4, ncol=3))
> x[1,1] <- NA
> sd(x)
Error in var(x, na.rm = na.rm) : missing observations in cov/cor
> sd(x, na.rm=TRUE)
Error in var(x, na.rm = na.rm) : missing observations in cov/cor
> sapply(x, sd, na.rm=TRUE)
       X1        X2        X3
1.0308198 0.4817945 1.5692881
> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.0
year     2002
month    10
day      01
language R

The way to fix it should be to replace the lines:
        sapply(x, sd)
in the definition of the sd function with
        sapply(x, sd, na.rm=na.rm)

Best,
Claudio Agostinelli

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mpiktas at delfi.lt  Mon Oct 21 12:37:57 2002
From: mpiktas at delfi.lt (Vaidotas Zemlys)
Date: Mon, 21 Oct 2002 11:37:57 +0100
Subject: [R] RAM usage
References: <3DAFE20E.50505@delfi.lt>
Message-ID: <3DB3D905.6030409@delfi.lt>

Hi,


 >> I'm having problems while working with large data sets with R 1.5.1 in
 >> windows 2000. Given a integer matrix size of 30 columns and  15000 rows
 >> my function should return a boolean matrix size of about 5000 rows and
 >> 15000 columns.

 >That's  75million items of 4bytes each, hence almost 300Mb for that one
 >object.

Does that mean that R reserves 4 bytes for logical object with length 1? On 
the whole how much memory R allocates for different data types? I searched 
a bit, but I didn't find anything useful on this subject. I would like to 
know if it is possible how much memory R needs for storing for example real 
matrix size of 50 rows and 100 columns together with column and row names. 
Or where to find information on such subject.

I thought that R needs only 1 byte for storing logical byte, and because of 
that I underestimated the size of memory R would need to use.


 > You have not told us your problem, so has not demonstrated that
 > `a lot of memory must be used'.   Hard to help when we don't know what 
  > you are attempting, but few problems cannot be done in pieces

I did not tell my problem, because I thought that it was more or less 
irrelevant to the memory usage problems I was experiencing. My intention 
was to ask about how R manages memory and is there something special about 
that management everyone should know, but I don't know. I'm sorry if my 
letter was a bit unclear, English is not my native language.

As for my problem, I'm trying to find out how well recursive partitioning 
could separate a "pure" subset. In recursive partitioning (and all tree 
methods) the tree is grown using the splits, that separates node into two 
subsets best. Thus given set is divided into subsets minimizing broadly 
speaking some statistic, which depends on all subsets. My goal is to 
single out one "pure" subset, I don't care about other subsets, so clearly 
I do not want to minimize some statistic which depends on all subsets. So I 
try to grow trees using not only the splits that are best, but the splits 
that are nearly best as well. To be exact I use 10 best splits for every 
node. So if I split the root node twice I get 1000 trees. I have to save 
information about terminal nodes, that is what objects do belong to it. As 
these objects are elements of a given vector y, for each terminal node I 
save the logical vector length of a given vector where TRUE in position i 
means that element y[i] is present in that terminal node.

To sum up I have a initial matrix X where dim(X)[1]==m, dim(X)[2]==n, 
vector y, length(y)==m, and I do splitting of y upon the columns of X. For 
each terminal node I save a logical vector t, length(t)==length(y)==m, 
where t[i]==TRUE for some i, means that y[i] belongs to terminal node t. 
With 1000 trees I can have maximum 4000 terminal nodes, so I need to store 
4000*m logical items. As you can understand from my previous letters, I 
encountered problems, when m is about 15000.

I'm trying to grow these trees purely for exploratory reasons, it may be 
that my mathematical and statistical assumptions can be totally wrong, so 
that's why I did not give much details about my problem earlier.

Thanks for all your answers.

Vaidotas Zemlys

PS R rulezzz!!! :)








-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From saundersp at bluelizard.org.uk  Mon Oct 21 12:43:59 2002
From: saundersp at bluelizard.org.uk (Phil Saunders)
Date: Mon, 21 Oct 2002 11:43:59 +0100
Subject: [R] Combinatorial Optimisation
Message-ID: <A5B74A99C30DBB46B9A819C3BD4A65F1191632@blsvr-2.bluelizard.org.uk>

Hi

I am looking to perform a discrete mean-variance optimisation, specifically to maximise the ratio of portfolio mean over portfolio standard deviation for a portfolio of several hundred stocks through discrete position size holdings in each stock, where all position sizes must be elements of a small finite set of integer amounts which include zero.

I don't think any of the standard R optimisation functions are ideally suited to this particular task, but perhaps there is a way to tailor them to this purpose, or does anyone know of any alternative R algorithms which would address this problem well?

Phil



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct 21 13:12:25 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 21 Oct 2002 12:12:25 +0100 (BST)
Subject: [R] newbie question: call C function from R in Windows XP
In-Reply-To: <5.1.0.14.1.20021021023458.00c1ba60@l.imap.itd.umich.edu>
Message-ID: <Pine.LNX.4.31.0210211209570.8534-100000@gannet.stats>

On Mon, 21 Oct 2002, Lei Liu wrote:

> Hello,
>
> I need to call an C function MH.c in my R code in Windows XP. I downloaded
> the software form http://www.stats.ox.ac.uk/pub/Rtools/ and installed them.
> But when I run the command "..\bin\Rcmd SHLIB MH.c", I got message "perl is
> not recognized as and internal or external command, operable program or
> batch file". How should I do?

Install perl like that web page (and readme.packages) suggests.

> As a newbie, I just wonder if there is a setup file so I can install all
> the software I needed for compiling C code once and for all. Can someone
> provide me a comprehensive list for the installation? Thanks very much!

No location, as the locations etc change almost weekly.

The file readme.packages does have a comprehensive list and a checklist.

There is a portal provided, which you went to, and that too contains all
the information.  We can't do the clicking for you!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dominik.grathwohl at rdls.nestle.com  Mon Oct 21 13:30:17 2002
From: dominik.grathwohl at rdls.nestle.com (Grathwohl,Dominik,LAUSANNE,NRC/NT)
Date: Mon, 21 Oct 2002 13:30:17 +0200
Subject: [R] baseline category logits
Message-ID: <89466355CEFE7244AC3A013E45641C1894958D@lsmail2.crn.nestrd.ch>

Dear all,

I have a question about baseline category logits.
My data is about colors of infant stools. 
Stools can be brow, green or yellow.
Color of stools is collected at 4 visits. 
However, at visits only marginal information 
is available, not the sequence of color.
E.g. sequence: YYYYYBYBY is collapsed to 2B, 0G, 7Y.
Infants are randomized to two infant formula groups
(for1, for2) in a factorial design. Question of 
interest is, whether one of the two formula can 
influence the color of stools.

The data looks like:

     for1 for2 visit1    visit2    visit3    visit4
----------------------------------------------------
subj |   |   | B  G  Y | B  G  Y | B  G  Y | B  G  Y  
------------------------------------------------
   1 | 0 | 0 | 2  0  7 | 0  0  5 | 0  0  3 | 0  0  4
   2 | 0 | 0 | 0  0 13 | 0  2 15 | 0  0 13 | 0  0 10
   3 | 0 | 1 | 1  1 17 | 0  0 17 | 1  0 10 | 0  0  9
   4 | 0 | 1 | 0  0 10 | 0  0 10 | 0  5 11 | 0  6  9
...
  31 | 1 | 0 | 2  0  7 | 0  0  1 | 0  0  0 | 0  0  0
  32 | 1 | 0 | 0  0  3 | 0  0  5 | 0  0  3 | 0  0  5
  33 | 1 | 1 | 0  0 10 | 0  0 11 | 0  0  3 | 0  0  3
  34 | 1 | 1 | 0  0  9 | 0  0  9 | 0  0  8 | 0  0  3
...

I am thinking of a baseline category logits model 
like Agrestis Alligator Food Choice Example in the
(1996) book, but additional with some time dependency.
Perhaps, random effects could be useful 
to model time dependency.

Alternatively, I can handle every color as a separate 
variable, doing three separate longitudinal analysis, 
one of yellow stool counts, one for green stool counts 
and one for brown stool counts.

Every help would be appreciate, 
perhaps someone could point me to a similar example.

Kind regards, 

Dominik 


Dominik Grathwohl 
Biostatistician 
Nestl? Research Center 
PO Box 44, CH-1000 Lausanne 26 
Phone: + 41 21 785 8034 
Fax: + 41 21 785 8556 
e-mail: dominik.grathwohl at rdls.nestle.com 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From peter.cameron at enscitech.com  Mon Oct 21 14:03:57 2002
From: peter.cameron at enscitech.com (Peter Cameron)
Date: Mon, 21 Oct 2002 13:03:57 +0100
Subject: [R] Does SJava work on Windows? It does (ish) on Linux
Message-ID: <003e01c278f9$ef91e120$0a00a8c0@energyscitech>

Apologies for posting to this list but my attempts to join the omegahelp
list bounce back with address unknown errors.

I'm struggling to get SJava working on windows 98. I'm using R 1.6 and the
latest SJava 0.65 and JDK 1.3.1_04. I keep getting an Unsatisified Link
error on initR.

Our Java application gets launched with a wrapper script. I've put the
library paths and current directory in PATH, specified them on the java
command line using -Djava.library.path= (this is necessary otherwise the
DLLs cannot be located in the first instance, despite them being in PATH).
I've specified the full pathnames of the DLLs in the System.loadLibrary java
calls, but to no avail. Why isn't the initR being resolved?

Do I have to compile R ( I assume the 1.6  R.dll is OK for SJava 0.65?).

On my Linux system I compiled R 1.3 from source as a shared library, and
then successfully installed the SJava 0.65. With both Java 1.3.1 and Java
1.4.1 I get hotspot exception 11 whenever I try to invoke the Revaluator
methods call and eval. If I trace the JNI calls I get an error about scalar
data being passed to a function that is expecting an array (or perhaps it's
vice versa). What does work is voidEval which is sufficient for our
purposes, although SJava seems flaky in the stability department.

Any help on getting SJava working on Windows is appreciated.

Cheers,
Peter


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Mon Oct 21 14:23:54 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Oct 2002 08:23:54 -0400
Subject: [R] RAM usage
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC7D2@usrymx10.merck.com>

> From: Vaidotas Zemlys [mailto:mpiktas at delfi.lt]
> Hi,
> 
>  >> I'm having problems while working with large data sets 
> with R 1.5.1 in
>  >> windows 2000. Given a integer matrix size of 30 columns 
> and  15000 rows
>  >> my function should return a boolean matrix size of about 
> 5000 rows and
>  >> 15000 columns.
> 
>  >That's  75million items of 4bytes each, hence almost 300Mb 
> for that one
>  >object.
> 
> Does that mean that R reserves 4 bytes for logical object 
> with length 1? On 
> the whole how much memory R allocates for different data 
> types? I searched 
> a bit, but I didn't find anything useful on this subject. I 
> would like to 
> know if it is possible how much memory R needs for storing 
> for example real 
> matrix size of 50 rows and 100 columns together with column 
> and row names. 
> Or where to find information on such subject.
> 
> I thought that R needs only 1 byte for storing logical byte, 
> and because of 
> that I underestimated the size of memory R would need to use.

You can use object.size() to get some idea on how R allocates memory:

> object.size(logical(1000))/1000
[1] 4.028
> object.size(integer(1000))/1000
[1] 4.028
> object.size(double(1000))/1000
[1] 8.028

So it seems like R allocates logicals as if they are integers.  My guess is
that this makes it easier to coerce logicals to integers for things like
sum(is.na(x))?

Andy


------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From roger at ysidro.econ.uiuc.edu  Mon Oct 21 14:30:19 2002
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Mon, 21 Oct 2002 07:30:19 -0500 (CDT)
Subject: [R] Sparse Matrix Package
Message-ID: <Pine.GSO.4.33.0210210724030.23827-100000@ysidro.econ.uiuc.edu>


R_go_nots:

We would like to call your attention to a new R package called SparseM.
The package offers a reasonably transparent access to basic linear
algebra including linear equation solving for sparse matrices.
Functions for solving sparse linear least squares problems
are provided to illustrate the approach.  Since only the non-zero
elements of the relevant matrices are stored, significant improvements
in both memory requirements and computational speed are possible
in some problems.  The package includes an R vignette that describes
the design philosophy and discusses several examples.

We would, of course, welcome comments on any aspect of the package.

Roger Koenker  and Pin Ng


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Mon Oct 21 14:29:28 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Oct 2002 08:29:28 -0400
Subject: [R] possible bug in sd
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC7D3@usrymx10.merck.com>

> From: Claudio Agostinelli [mailto:mail-list at linaria.dst.unive.it]
> 
> Dear All,
> I think there is a small bug in sd when the argument is a 
> dataframe and
> there are missing values:
> 
> > x <- data.frame(matrix(rnorm(12,0,1), nrow=4, ncol=3))
> > x[1,1] <- NA
> > sd(x)
> Error in var(x, na.rm = na.rm) : missing observations in cov/cor
> > sd(x, na.rm=TRUE)
> Error in var(x, na.rm = na.rm) : missing observations in cov/cor
> > sapply(x, sd, na.rm=TRUE)
>        X1        X2        X3
> 1.0308198 0.4817945 1.5692881

That's because sd looks like the following:

function (x, na.rm = FALSE) 
{
    if (is.matrix(x)) 
        apply(x, 2, sd)
    else if (is.vector(x)) 
        sqrt(var(x, na.rm = na.rm))
    else if (is.data.frame(x)) 
        sapply(x, sd)
    else sqrt(var(as.vector(x), na.rm = na.rm))
}

Notice how the na.rm argument never got passed in the apply() and sapply()
calls.  I'd call that a bug alright.

Cheers,
Andy

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Oct 21 14:58:05 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 21 Oct 2002 14:58:05 +0200
Subject: [R] possible bug in sd
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC7D3@usrymx10.merck.com>
References: <51F9C42DA15CD311BD220008C707D81906FFC7D3@usrymx10.merck.com>
Message-ID: <x2elakne3m.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> function (x, na.rm = FALSE) 
> {
>     if (is.matrix(x)) 
>         apply(x, 2, sd)
>     else if (is.vector(x)) 
>         sqrt(var(x, na.rm = na.rm))
>     else if (is.data.frame(x)) 
>         sapply(x, sd)
>     else sqrt(var(as.vector(x), na.rm = na.rm))
> }
> 
> Notice how the na.rm argument never got passed in the apply() and sapply()
> calls.  I'd call that a bug alright.

Fixed for 1.6.1beta (as of tomorrow).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct 21 15:02:49 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 21 Oct 2002 14:02:49 +0100 (BST)
Subject: [R] RAM usage
In-Reply-To: <3DB3D905.6030409@delfi.lt>
Message-ID: <Pine.LNX.4.31.0210211355230.6615-100000@gannet.stats>

On Mon, 21 Oct 2002, Vaidotas Zemlys wrote:

> Hi,
>
>
>  >> I'm having problems while working with large data sets with R 1.5.1 in
>  >> windows 2000. Given a integer matrix size of 30 columns and  15000 rows
>  >> my function should return a boolean matrix size of about 5000 rows and
>  >> 15000 columns.
>
>  >That's  75million items of 4bytes each, hence almost 300Mb for that one
>  >object.
>
> Does that mean that R reserves 4 bytes for logical object with length 1? On
> the whole how much memory R allocates for different data types? I searched

R uses C integers, which are almost always 4 bytes.  Fortran does
for logicals usually, for example, and that's probably why S did.  It's
quite hard to work with smaller types in a portable way.  (char need not
be 1 byte, for example.)

A logical vector of length 1 needs a lot more than 4 bytes, but one of
length 1e5 will be close to 4e5 bytes (unless it has names).  There's
overhead and lignment issues to consider.

> a bit, but I didn't find anything useful on this subject. I would like to
> know if it is possible how much memory R needs for storing for example real
> matrix size of 50 rows and 100 columns together with column and row names.
> Or where to find information on such subject.

In the source files.  reals are stored in the system's C double type,
which is usually 4 bytes.

> I thought that R needs only 1 byte for storing logical byte, and because of
> that I underestimated the size of memory R would need to use.
>
>
>  > You have not told us your problem, so has not demonstrated that
>  > `a lot of memory must be used'.   Hard to help when we don't know what
>   > you are attempting, but few problems cannot be done in pieces
>
> I did not tell my problem, because I thought that it was more or less
> irrelevant to the memory usage problems I was experiencing. My intention
> was to ask about how R manages memory and is there something special about
> that management everyone should know, but I don't know. I'm sorry if my
> letter was a bit unclear, English is not my native language.

But you did claim `must be used'.  That really is rarely the case, and the
skill in programming R (or S) is use memory within the resources
available.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct 21 15:05:56 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 21 Oct 2002 14:05:56 +0100 (BST)
Subject: [R] mixed effect-models
In-Reply-To: <001301c278e3$840effc0$3418db92@dsss.scs.es>
Message-ID: <Pine.LNX.4.31.0210211403000.6615-100000@gannet.stats>

Sure you can!

See glmmPQL in package MASS, glmm in package glmmGibbs, glmm in one of
Jim Lindsey's packages, ....

There is even a discussion of this in MASS4 secion 10.4.


On Mon, 21 Oct 2002, Xavi wrote:

> I believe that in R, it is not possible to analyze mixed effect-models
> when the distribucion is not gaussian (p.e. binomial or poisson), isn't?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct 21 15:23:50 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 21 Oct 2002 14:23:50 +0100 (BST)
Subject: [R] RAM usage
In-Reply-To: <Pine.LNX.4.31.0210211355230.6615-100000@gannet.stats>
Message-ID: <Pine.LNX.4.31.0210211422020.6816-100000@gannet.stats>

On Mon, 21 Oct 2002 ripley at stats.ox.ac.uk wrote:

> > I would like to
> > know if it is possible how much memory R needs for storing for example real
> > matrix size of 50 rows and 100 columns together with column and row names.
> > Or where to find information on such subject.
>
> In the source files.  reals are stored in the system's C double type,
> which is usually 4 bytes.

Oops, 8 bytes, usually.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From michael.wolf at econ.upf.es  Mon Oct 21 15:31:27 2002
From: michael.wolf at econ.upf.es (Michael Wolf)
Date: Mon, 21 Oct 2002 15:31:27 +0200
Subject: [R] Boot package for R 1.3.0
Message-ID: <3DB401AF.1060607@econ.upf.es>

Dear all,

I have Linux with R 1.3.0
I want to install the `boot' add-on package. Upon downloading
the latest version and following the install directions, I got
the error message:

ERROR: This R is version 1.3.0
        package `boot' depends on R 1.5.0

Well, I am not really a computer expert, so I am a bit hesitant
to uninstall my version 1.3.0 and then intstall the new version
1.5.0 (unless somebody can assure me that this is really easy ...).

Does anybody have an older version of boot_xxx.tar.gz around that
might be compatible with R 1.3.0?

Since I do not subscribe to the mailing list, please reply to me
directly.

Thanks much,
Michael
-- 
**********************************************************************
*                                                                    *
*  Michael Wolf                  Tel:   +34 93 542 2552              *
*  Department of Economics       Fax:   +34 93 542 1746              *
*  Universitat Pompeu Fabra      email: michael.wolf at econ.upf.es     *
*  Ramon Trias Fargas 25-27      www:   http://www.econ.upf.es/~wolf *
*  E-08005 Barcelona                                                 *
*  Spain                                                             *
*                                                                    *
**********************************************************************


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From michael.wolf at econ.upf.es  Mon Oct 21 15:34:34 2002
From: michael.wolf at econ.upf.es (Michael Wolf)
Date: Mon, 21 Oct 2002 15:34:34 +0200
Subject: [R] Sorry! [Fwd: Boot package for R 1.3.0]
Message-ID: <3DB4026A.1070104@econ.upf.es>

Ooops, sorry!

I just found some precompiled binary packages for Suse 7.3
on CRAN and this should do the trick.

My apologies,
Michael
-- 
**********************************************************************
*                                                                    *
*  Michael Wolf                  Tel:   +34 93 542 2552              *
*  Department of Economics       Fax:   +34 93 542 1746              *
*  Universitat Pompeu Fabra      email: michael.wolf at econ.upf.es     *
*  Ramon Trias Fargas 25-27      www:   http://www.econ.upf.es/~wolf *
*  E-08005 Barcelona                                                 *
*  Spain                                                             *
*                                                                    *
**********************************************************************

-------------- next part --------------
An embedded message was scrubbed...
From: Michael Wolf <michael.wolf at econ.upf.es>
Subject: Boot package for R 1.3.0
Date: Mon, 21 Oct 2002 15:31:27 +0200
Size: 1848
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021021/c685d7bc/BootpackageforR1.3.mht

From tlumley at u.washington.edu  Mon Oct 21 15:50:43 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 21 Oct 2002 06:50:43 -0700 (PDT)
Subject: [R] newbie question: call C function from R in Windows XP
In-Reply-To: <5.1.0.14.1.20021021023458.00c1ba60@l.imap.itd.umich.edu>
Message-ID: <Pine.A41.4.44.0210210643300.58844-100000@homer13.u.washington.edu>

On Mon, 21 Oct 2002, Lei Liu wrote:

> Hello,
>
> I need to call an C function MH.c in my R code in Windows XP. I downloaded
> the software form http://www.stats.ox.ac.uk/pub/Rtools/ and installed them.
> But when I run the command "..\bin\Rcmd SHLIB MH.c", I got message "perl is
> not recognized as and internal or external command, operable program or
> batch file". How should I do?

You need Perl.  I think that's the only other tool you will need.

> As a newbie, I just wonder if there is a setup file so I can install all
> the software I needed for compiling C code once and for all.

We can't provide a single package of everything, largely because of the
licensing terms of the Perl distribution.  There is a comprehensive list
in readme.packages.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Oct 21 16:03:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 21 Oct 2002 07:03:03 -0700 (PDT)
Subject: [R] mixed effect-models
In-Reply-To: <001301c278e3$840effc0$3418db92@dsss.scs.es>
Message-ID: <Pine.A41.4.44.0210210651400.58844-100000@homer13.u.washington.edu>

On Mon, 21 Oct 2002, Xavi wrote:

> Hello,
> 
> I believe that in R, it is not possible to analyze mixed effect-models
> when the distribucion is not gaussian (p.e. binomial or poisson), isn't?

It depends on exactly what you mean.

 - Jim Lindsey's packages will fit (at least) random intercept models

 - For binomial or Poisson models with reasonably large means (perhaps 4
or so) the PQL approximation used by glmmPQL in the MASS package is pretty
good.

> Somebody can suggest me alternative?

Again, it depends on why you want to fit mixed-effects models. You may be
able to fit marginal models (GEE) instead.

If you really want to fit mixed models with multiple random effects to
binary data you probably need SAS PROC NLMIXED or a Bayesian solution
(or HLM or MLWiN might be able to do it by now).

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Oct 21 16:09:54 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 21 Oct 2002 07:09:54 -0700 (PDT)
Subject: [R] RAM usage
In-Reply-To: <3DB3D905.6030409@delfi.lt>
Message-ID: <Pine.A41.4.44.0210210703220.58844-100000@homer13.u.washington.edu>

On Mon, 21 Oct 2002, Vaidotas Zemlys wrote:

> Hi,
>
>
>  >> I'm having problems while working with large data sets with R 1.5.1 in
>  >> windows 2000. Given a integer matrix size of 30 columns and  15000 rows
>  >> my function should return a boolean matrix size of about 5000 rows and
>  >> 15000 columns.
>
>  >That's  75million items of 4bytes each, hence almost 300Mb for that one
>  >object.
>
> Does that mean that R reserves 4 bytes for logical object with length 1? On
> the whole how much memory R allocates for different data types? I searched
> a bit, but I didn't find anything useful on this subject.

The information is implicitly in the help for .C/.Fortran.

R stores integer, factor and logical variables in vectors of C int,
numeric variables in vectors of C double. On most platforms these are 4
and 8 bytes respectively.  Lists are vectors of pointers, using 4 bytes
per element on 32 bit platforms, 8 bytes on 64bit platforms.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Mon Oct 21 17:18:27 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Mon, 21 Oct 2002 11:18:27 -0400
Subject: [R] bug in nlme?
Message-ID: <3DB41AC3.70D790FB@umsanet.edu.bo>

The following error occurs with the latest version of nlme (
Version: 3.1-32
Date: 2002/10/06)
on R 1.6.0, precompiled binary for windows(98).

> avila.nlme2 <- update(avila.nlme1, fixed=LKe+lKa+lCl ~ Periodo+Trat, 
+   
start=c(avila.fix1[1],0,0,0,0,avila.fix1[2],0,0,0,0,avila.fix1[3],0,0,0,0))
Error: subscript out of bounds
> traceback()
7: eval(expr, envir, enclos)
6: eval(modelExpression[[2]], envir = nlEnv)
5: nlme.formula(model = Conc ~ SSfol(200, Tiempo, lKe, lKa, lCl), 
       data = avila, fixed = LKe + lKa + lCl ~ Periodo + Trat, random =
structure(list(
           Voluntario = structure(c(-72.0327852991691,
-10.9140457582845, 
           -2.40173940775114), formula = structure(list(lKe ~ 1, 
               lKa ~ 1, lCl ~ 1), class = "listForm"), Dimnames = list(
               c("lKe", "lKa", "lCl"), c("lKe", "lKa", "lCl")), class =
c("pdDiag", 
           "pdMat"))), settings = c(0, 1, 0, 1), class = "reStruct",
.Names = "Voluntario", plen = structure(3, .Names = "Voluntario")), 
       groups = ~Voluntario, start = structure(list(fixed =
structure(c(-4.48968407530164, 
       0, 0, 0, 0, -0.48160421584142, 0, 0, 0, 0, -0.746292880938506, 
       0, 0, 0, 0), .Names = c("lKe", "", "", "", "", "lKa", "", 
       "", "", "", "lCl", "", "", "", ""))), .Names = "fixed"), 
       na.action = na.omit)
4: nlme(model = Conc ~ SSfol(200, Tiempo, lKe, lKa, lCl), data = avila, 
       fixed = LKe + lKa + lCl ~ Periodo + Trat, random =
structure(list(
           Voluntario = structure(c(-72.0327852991691,
-10.9140457582845, 
           -2.40173940775114), formula = structure(list(lKe ~ 1, 
               lKa ~ 1, lCl ~ 1), class = "listForm"), Dimnames = list(
               c("lKe", "lKa", "lCl"), c("lKe", "lKa", "lCl")), class =
c("pdDiag", 
           "pdMat"))), settings = c(0, 1, 0, 1), class = "reStruct",
.Names = "Voluntario", plen = structure(3, .Names = "Voluntario")), 
       groups = ~Voluntario, start = structure(list(fixed =
structure(c(-4.48968407530164, 
       0, 0, 0, 0, -0.48160421584142, 0, 0, 0, 0, -0.746292880938506, 
       0, 0, 0, 0), .Names = c("lKe", "", "", "", "", "lKa", "", 
       "", "", "", "lCl", "", "", "", ""))), .Names = "fixed"), 
       na.action = na.omit)
3: do.call("nlme", nextCall)
2: update.nlme(avila.nlme1, fixed = LKe + lKa + lCl ~ Periodo + 
       Trat, start = c(avila.fix1[1], 0, 0, 0, 0, avila.fix1[2], 
       0, 0, 0, 0, avila.fix1[3], 0, 0, 0, 0))
1: update(avila.nlme1, fixed = LKe + lKa + lCl ~ Periodo + Trat, 
       start = c(avila.fix1[1], 0, 0, 0, 0, avila.fix1[2], 0, 0, 
           0, 0, avila.fix1[3], 0, 0, 0, 0))


Kjetil Halvorsen
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From weiss at wiso-r610.wiso.uni-koeln.de  Mon Oct 21 17:39:01 2002
From: weiss at wiso-r610.wiso.uni-koeln.de (Bernd Weiss)
Date: Mon, 21 Oct 2002 17:39:01 +0200
Subject: [R] Adjusting for heteroscedasticity 
Message-ID: <3DB43BAB.3785.1DB49F6@localhost>

Hi,

am I right that there is no option in R to adjust for heteroscedasticity  
(e.g. in logistic regressions).

TIA,

Bernd
-- 
Bernd Weiss <bernd.weiss at wiso.uni-koeln.de>
Forschungsinstitut fuer Soziologie, Universitaet zu Koeln      
<http://www.uni-koeln.de/wiso-fak/fisoz/mitarbeiter/bw/>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From f0z6305 at labs.tamu.edu  Mon Oct 21 17:45:56 2002
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Mon, 21 Oct 2002 10:45:56 -0500
Subject: [R] mixed effect-models
References: <Pine.A41.4.44.0210210651400.58844-100000@homer13.u.washington.edu>
Message-ID: <005001c27918$f1e79fe0$8bd75ba5@IE.TAMU.EDU>

So in R there is no package for mixed models with multiple random effects to
Binary data?

Thanks.

----- Original Message -----
From: "Thomas Lumley" <tlumley at u.washington.edu>
To: "Xavi" <xpuig at dsss.scs.es>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, October 21, 2002 9:03 AM
Subject: Re: [R] mixed effect-models


> On Mon, 21 Oct 2002, Xavi wrote:
>
> > Hello,
> >
> > I believe that in R, it is not possible to analyze mixed effect-models
> > when the distribucion is not gaussian (p.e. binomial or poisson), isn't?
>
> It depends on exactly what you mean.
>
>  - Jim Lindsey's packages will fit (at least) random intercept models
>
>  - For binomial or Poisson models with reasonably large means (perhaps 4
> or so) the PQL approximation used by glmmPQL in the MASS package is pretty
> good.
>
> > Somebody can suggest me alternative?
>
> Again, it depends on why you want to fit mixed-effects models. You may be
> able to fit marginal models (GEE) instead.
>
> If you really want to fit mixed models with multiple random effects to
> binary data you probably need SAS PROC NLMIXED or a Bayesian solution
> (or HLM or MLWiN might be able to do it by now).
>
> -thomas
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plummer at iarc.fr  Mon Oct 21 17:49:45 2002
From: plummer at iarc.fr (Martyn Plummer)
Date: Mon, 21 Oct 2002 17:49:45 +0200 (CEST)
Subject: [R] Make on RedHat 8.0
In-Reply-To: <1035132798.1542.42.camel@DELL8200>
Message-ID: <XFMail.20021021174945.plummer@iarc.fr>

On 20-Oct-2002 Marc Schwartz wrote:
>> Hallo R-help,
>> 
>> I am experiencing difficulty when making R on RedHat Linux 8.0. I'm not
>> able to display my plots with the R-Viewer. The default file
>> 'Rplots.ps' is also not consistent with the last plot so that I can't
>> use an external PS-Viewer to view my plots. Does R support RH 8.0? Do
>> you have any suggestions on how I can solve this problem? Is a .RPM
>> planned for the near future?
>> 
>> Thanks in advance
>> Chris. 
> 
> Chris,
> 
> I now have a dual-boot WinXP Pro/RH 8.0 system running on a Dell i8200
> laptop and recently downloaded the 1.6.0 source RPM from CRAN
> (http://cran.r-project.org/bin/linux/redhat/SRPMS/). I did an "rpmbuild
> --rebuild" on it and installed the resultant RPM. I have not attempted
> to build R from "pure" source, though I do have the source tarball.
> 
> So far it seems to be working well, though I will acknowledge that I
> have not performed extensive testing on it.  
> 
> The one thing to note is that the resultant RPM file is about 10.8 Mb
> versus the RH 7.x RPM at 11.4 Mb. I am not sure if I erred in the
> building of the 8.0 RPM or if this is to be expected as a result of the
> changes in RH 8.0.
> 
> Chris, if you have some sample code/data, I would be happy to test it on
> my system.
> 
> I am also copying Martyn Plummer, as the RH maintainer on this, to
> solicit any feedback. If the RPM that I have created is valid, I would
> be more than happy to make it available for CRAN. If it is not, I would
> be happy to engage in appropriate changes to make it so.

I wasn't able to create an RPM for Red Hat 8.0 because it was released
a mere two days before R 1.6.0.  I have ordered a copy and it is on
its way.  Several people have offered to create RPMS for Red Hat 8.0,
but I am turning down such offers because I don't want to temporarily
hand over the job of creating RPMS to someone else.  I hope that only a
few early adopters of Red Hat 8.0 have been inconvenienced by the lack
of RPMS. They should be up by the end of the week.

I'll look into these issues when I get it. One thing I can say is
that if the RPM builds, then R passes "make check".

Martyn
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ekr at rtfm.com  Mon Oct 21 15:26:46 2002
From: ekr at rtfm.com (Eric Rescorla)
Date: Mon, 21 Oct 2002 06:26:46 -0700
Subject: [R] More Logistic Regression Tools?
Message-ID: <200210211326.g9LDQkA05033@sierra.rtfm.com>

I've been using R to do logistic regresssion, and that's working
well, but there are two things I haven't figured out how to do.

(1) Is there some pre-existing function that will let you compute the
    odds ratios and confidence intervals for them for a specific fit. I know
    how to do this manually or even write a function that I can call with
    the coefficients and se, but extending the printing function was a
    little more work than I expected.

    I.e. I'm looking for something where you'd type
    odds.ratios(fit)

    and get:

    Coefficient		Odds ratio	95%	CI
    XXX			5.2		1.5	7.2
    
    etc.

(2) I'd like to compute goodness-of-fit statistics for my fit
    (Hosmer-Lemeshow, Pearson, etc.). I didn't see a package that
    did this. Have I missed one?

Thanks,
-Ekr

    
    
  

	


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Mon Oct 21 18:27:01 2002
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 21 Oct 2002 09:27:01 -0700
Subject: [R] R 1.6.0 running on Mac OS 10.2.1?
In-Reply-To: <Pine.LNX.4.44.0210201955410.14773-100000@fata.unam.mx>
References: <Pine.LNX.4.44.0210201955410.14773-100000@fata.unam.mx>
Message-ID: <p05111a02b9d9da0a7112@[128.115.153.6]>

Type

   fink list | grep ' i '

and look at the results. It should include this:

  i      g77     3.1-20020420-2  GNU FORTRAN77 compiler.

If not, then type

   fink install g77

(and sit back and wait a long time!).

You will have to take similar steps for the other packages from fink 
that Jan mentioned in his earlier response to your questions.

Then try ./configure again.

-Don

At 8:02 PM -0500 10/20/02, Ulises Mora Alvarez wrote:
>I've just tried. It doesn't work.
>
>After running: ./configure
>I got:
>Error message:
>configure: error: Neither an F77 compiler nor f2c found
>
>I've just installed and updated fik and the X server.
>
>I'm doing something wrong. More help would be appreciated.
>By the way, how you compiled KDE?
>
>Thanks.
>
>OS: Jaguar 10.2.1
>Processor: G3 700 Mhz
>

<- snip ->

>
>--
>Ulises M. Alvarez
>LAB. DE CHOQUES DEBILES
>FISICA APLICADA Y TECNOLOGIA AVANZADA
>UNAM
>umalvarez at fata.unam.mx
>


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ko-Kang at xtra.co.nz  Mon Oct 21 18:33:40 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Tue, 22 Oct 2002 05:33:40 +1300
Subject: [R] R-software manual 
References: <AF0250AF659F1A4C9A2EA2D0F0EFC6E303568C@hkjkex.hkijkt.fam>
Message-ID: <003101c2791f$9d5d26f0$c72037d2@kwan022>

----- Original Message -----
From: "Eduwin Pakpahan" <epakpahan at hki-indonesia.org>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, October 21, 2002 10:27 PM
Subject: [R] R-software manual


> I am a student from Indonesia.
> May I know where I can find the manual using R-software? I am trying to
> investigate logistic regression and likelihood using this software...


Take a look under Documentation -> Contributed in CRAN.  You might also want
to look in the documentation for glm, which can be found within R by:
   help(glm)

Cheers,

Ko-Kang Wang

------------------------------------------------
Ko-Kang Kevin Wang
Post Graduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Oct 21 19:53:30 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 21 Oct 2002 19:53:30 +0200
Subject: [R] More Logistic Regression Tools?
In-Reply-To: <200210211326.g9LDQkA05033@sierra.rtfm.com>
References: <200210211326.g9LDQkA05033@sierra.rtfm.com>
Message-ID: <x2ptu3d6g5.fsf@biostat.ku.dk>

Eric Rescorla <ekr at rtfm.com> writes:

> I've been using R to do logistic regresssion, and that's working
> well, but there are two things I haven't figured out how to do.
> 
> (1) Is there some pre-existing function that will let you compute the
>     odds ratios and confidence intervals for them for a specific fit. I know
>     how to do this manually or even write a function that I can call with
>     the coefficients and se, but extending the printing function was a
>     little more work than I expected.
> 
>     I.e. I'm looking for something where you'd type
>     odds.ratios(fit)
> 
>     and get:
> 
>     Coefficient		Odds ratio	95%	CI
>     XXX			5.2		1.5	7.2

My favourite version of this is

library(MASS)
example(glm)
exp(cbind(coef(glm.D93),confint(glm.D93)))

(OK, so that's a Poisson regression, not a logistic one, but you get
the picture.) Notice that rather than est.+-2SE it gives you
likelihood ratio profiling, which is hardly worth not doing these
days.
     
>     etc.
> 
> (2) I'd like to compute goodness-of-fit statistics for my fit
>     (Hosmer-Lemeshow, Pearson, etc.). I didn't see a package that
>     did this. Have I missed one?

As I understand it, some of these methods are rather unreliable. It
might be a good idea to hear if Frank Harrell has anything to say.
Last time someone requested a g-o-f statistic, he said that he
regretted ever implementing it in SAS....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Mon Oct 21 20:12:55 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 21 Oct 2002 13:12:55 -0500
Subject: [R] Make on RedHat 8.0
In-Reply-To: <XFMail.20021021174945.plummer@iarc.fr>
Message-ID: <000801c2792d$7cb34d90$0201a8c0@MARC>

> -----Original Message-----
> I wasn't able to create an RPM for Red Hat 8.0 because it was 
> released a mere two days before R 1.6.0.  I have ordered a 
> copy and it is on its way.  Several people have offered to 
> create RPMS for Red Hat 8.0, but I am turning down such 
> offers because I don't want to temporarily hand over the job 
> of creating RPMS to someone else.  I hope that only a few 
> early adopters of Red Hat 8.0 have been inconvenienced by the 
> lack of RPMS. They should be up by the end of the week.
> 
> I'll look into these issues when I get it. One thing I can 
> say is that if the RPM builds, then R passes "make check".
> 
> Martyn

Martyn,

Thanks for the update and I can certainly understand the issues behind
retaining control and liabilities.

Your last comment also helps as I continue to experience no problems
with the RH 8.0 version of 1.6.0 that I am presently using.

If it would be of help in the mean time, if anyone using RH 8.0 has any
questions regarding creating the R 1.6.0 RPM from the SRPM on CRAN using
their own system, I'd be happy to answer questions.

Best regards,

Marc


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From JSung at fmcg.com  Mon Oct 21 20:30:38 2002
From: JSung at fmcg.com (Jun Sung)
Date: Mon, 21 Oct 2002 14:30:38 -0400
Subject: [R] trouble with R DCOM
Message-ID: <45900AE67810B54F8BE84248840BFD4F8464B2@EXCHANGE.FMCG.com>

Dear all:

I am having trouble with automating R under win32.
Is there a way to guarantee R server instance to remain 'alive' and also
to pass complicated interactive commands?
It works well as a simple calculator, but the overhead of creating an
instance of R for each minor calculation is too heavy.

Also, when using interactive features, R server does not seem to
respond, esp for ggobi.

BTW, I surveyed a while ago how much interest there was in using vtk for
3d visualization for R.
It is not so difficult, but it seems that ggobi serves the purpose in
most cases, and with even less effort.

Thanks in advance for any help/comment.
/js

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Mon Oct 21 20:46:42 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Mon, 21 Oct 2002 11:46:42 -0700
Subject: [R] Sparse Matrix Package
In-Reply-To: <Pine.GSO.4.33.0210210724030.23827-100000@ysidro.econ.uiuc.edu>
Message-ID: <70C3E32A-E525-11D6-90ED-000393860F3C@stat.ucla.edu>

Note: both SparseM and rgenout compile out of the (CRAN) box on Jaguar.

On Monday, October 21, 2002, at 05:30 AM, Roger Koenker wrote:

>
> R_go_nots:
>
> We would like to call your attention to a new R package called SparseM.
> The package offers a reasonably transparent access to basic linear
> algebra including linear equation solving for sparse matrices.
> Functions for solving sparse linear least squares problems
> are provided to illustrate the approach.  Since only the non-zero
> elements of the relevant matrices are stored, significant improvements
> in both memory requirements and computational speed are possible
> in some problems.  The package includes an R vignette that describes
> the design philosophy and discusses several examples.
>
> We would, of course, welcome comments on any aspect of the package.
>
> Roger Koenker  and Pin Ng
>
>
> url:	http://www.econ.uiuc.edu		Roger Koenker
> email	roger at ysidro.econ.uiuc.edu		Department of Economics
> vox: 	217-333-4558				University of Illinois
> fax:   	217-244-6678				Champaign, IL 61820
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Mon Oct 21 21:11:49 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon, 21 Oct 2002 15:11:49 -0400
Subject: [R] More Logistic Regression Tools?
In-Reply-To: <200210211326.g9LDQkA05033@sierra.rtfm.com>
References: <200210211326.g9LDQkA05033@sierra.rtfm.com>
Message-ID: <20021021151149.1f97524f.fharrell@virginia.edu>

On Mon, 21 Oct 2002 06:26:46 -0700
Eric Rescorla <ekr at rtfm.com> wrote:

> I've been using R to do logistic regresssion, and that's working
> well, but there are two things I haven't figured out how to do.
> 
> (1) Is there some pre-existing function that will let you compute the
>     odds ratios and confidence intervals for them for a specific fit. I know
>     how to do this manually or even write a function that I can call with
>     the coefficients and se, but extending the printing function was a
>     little more work than I expected.
> 
>     I.e. I'm looking for something where you'd type
>     odds.ratios(fit)
> 
>     and get:
> 
>     Coefficient		Odds ratio	95%	CI
>     XXX			5.2		1.5	7.2
>     
>     etc.
> 

library(Design)  # see hesweb1.med.virginia.edu/biostat/rms
d <- datadist(mydataframe); options(datadist='d') # defines data ranges etc.
f <- lrm(y ~ ....)
summary(f, age=c(21,65))
# 65:21 year OR (even if age is nonlinear)
# other continuous variables: use quartiles

See all the contrast function in Design.

> (2) I'd like to compute goodness-of-fit statistics for my fit
>     (Hosmer-Lemeshow, Pearson, etc.). I didn't see a package that
>     did this. Have I missed one?

Hosmer-Lemeshow has low power and relies on arbitrary binning of predicted probabilities.  The Hosmer-Le Cessie omnibus test is unique and has more power usually.  To get it:

f <- update(f, x=T, y=T)
resid(f, 'gof')  # uses residuals.lrm

Frank Harrell

> 
> Thanks,
> -Ekr
> 
>     
>     
>   
> 
> 	
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Mon Oct 21 21:13:50 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon, 21 Oct 2002 15:13:50 -0400
Subject: [R] Adjusting for heteroscedasticity
In-Reply-To: <3DB43BAB.3785.1DB49F6@localhost>
References: <3DB43BAB.3785.1DB49F6@localhost>
Message-ID: <20021021151350.35c9b797.fharrell@virginia.edu>

On Mon, 21 Oct 2002 17:39:01 +0200
Bernd Weiss <weiss at wiso-r610.wiso.uni-koeln.de> wrote:

> Hi,
> 
> am I right that there is no option in R to adjust for heteroscedasticity  
> (e.g. in logistic regressions).
> 
> TIA,
> 
> Bernd
> -- 
> Bernd Weiss <bernd.weiss at wiso.uni-koeln.de>
> Forschungsinstitut fuer Soziologie, Universitaet zu Koeln      
> <http://www.uni-koeln.de/wiso-fak/fisoz/mitarbeiter/bw/>

library(Design)  # see hesweb1.med.virginia.edu/biostat/rms
f <- lrm(..., x=T, y=T)
g <- robcov(f)  # Huber-White covariance matrix
h <- bootcov(f, B=200)  # bootstrap covariance matrix

Both robcov and bootcov will do intra-cluster correlation adjustments:
robcov(f, subject.id) or bootcov(f, subject.id)
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct 21 21:50:39 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 21 Oct 2002 20:50:39 +0100 (BST)
Subject: [R] mixed effect-models
In-Reply-To: <005001c27918$f1e79fe0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <Pine.LNX.4.31.0210212047030.29130-100000@gannet.stats>

On Mon, 21 Oct 2002, Feng Zhang wrote:

> So in R there is no package for mixed models with multiple random effects to
> Binary data?

R-help has already been told about two in answer to the original question.

GLMMs for binary data are a tricky inference problem and all the software
I know of has drawbacks but real problems do get solved using it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Mon Oct 21 22:07:01 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 21 Oct 2002 15:07:01 -0500
Subject: [R] bug in nlme?
In-Reply-To: <3DB41AC3.70D790FB@umsanet.edu.bo>
References: <3DB41AC3.70D790FB@umsanet.edu.bo>
Message-ID: <6rptu3pndm.fsf@bates4.stat.wisc.edu>

Try removing the names from the vector avila.fix1 before calling
update.  You can do this with
 names(avila.fix1) <- NULL

I think the problem may be that the names LKe, lKa, and lCl
are being propagated from the starting values and overwriting the
parameters in the environment in which the model is to be evaluated.
Notice that the names of the extended starting estimates are

.Names = c("lKe", "", "", "", "", "lKa", "", "", "", "", "lCl",
  "", "", "", "")))

and those conflict with parameter names.

If this does fix your problem we will modify the nlme code to strip
names from the starting estimates and avoid this problem in the
future.

kjetil halvorsen <kjetilh at umsanet.edu.bo> writes:

> The following error occurs with the latest version of nlme (
> Version: 3.1-32
> Date: 2002/10/06)
> on R 1.6.0, precompiled binary for windows(98).
> 
> > avila.nlme2 <- update(avila.nlme1, fixed=LKe+lKa+lCl ~ Periodo+Trat, 
> +   
> start=c(avila.fix1[1],0,0,0,0,avila.fix1[2],0,0,0,0,avila.fix1[3],0,0,0,0))
> Error: subscript out of bounds
> > traceback()
> 7: eval(expr, envir, enclos)
> 6: eval(modelExpression[[2]], envir = nlEnv)
> 5: nlme.formula(model = Conc ~ SSfol(200, Tiempo, lKe, lKa, lCl), 
>        data = avila, fixed = LKe + lKa + lCl ~ Periodo + Trat, random =
> structure(list(
>            Voluntario = structure(c(-72.0327852991691,
> -10.9140457582845, 
>            -2.40173940775114), formula = structure(list(lKe ~ 1, 
>                lKa ~ 1, lCl ~ 1), class = "listForm"), Dimnames = list(
>                c("lKe", "lKa", "lCl"), c("lKe", "lKa", "lCl")), class =
> c("pdDiag", 
>            "pdMat"))), settings = c(0, 1, 0, 1), class = "reStruct",
> .Names = "Voluntario", plen = structure(3, .Names = "Voluntario")), 
>        groups = ~Voluntario, start = structure(list(fixed =
> structure(c(-4.48968407530164, 
>        0, 0, 0, 0, -0.48160421584142, 0, 0, 0, 0, -0.746292880938506, 
>        0, 0, 0, 0), .Names = c("lKe", "", "", "", "", "lKa", "", 
>        "", "", "", "lCl", "", "", "", ""))), .Names = "fixed"), 
>        na.action = na.omit)
> 4: nlme(model = Conc ~ SSfol(200, Tiempo, lKe, lKa, lCl), data = avila, 
>        fixed = LKe + lKa + lCl ~ Periodo + Trat, random =
> structure(list(
>            Voluntario = structure(c(-72.0327852991691,
> -10.9140457582845, 
>            -2.40173940775114), formula = structure(list(lKe ~ 1, 
>                lKa ~ 1, lCl ~ 1), class = "listForm"), Dimnames = list(
>                c("lKe", "lKa", "lCl"), c("lKe", "lKa", "lCl")), class =
> c("pdDiag", 
>            "pdMat"))), settings = c(0, 1, 0, 1), class = "reStruct",
> .Names = "Voluntario", plen = structure(3, .Names = "Voluntario")), 
>        groups = ~Voluntario, start = structure(list(fixed =
> structure(c(-4.48968407530164, 
>        0, 0, 0, 0, -0.48160421584142, 0, 0, 0, 0, -0.746292880938506, 
>        0, 0, 0, 0), .Names = c("lKe", "", "", "", "", "lKa", "", 
>        "", "", "", "lCl", "", "", "", ""))), .Names = "fixed"), 
>        na.action = na.omit)
> 3: do.call("nlme", nextCall)
> 2: update.nlme(avila.nlme1, fixed = LKe + lKa + lCl ~ Periodo + 
>        Trat, start = c(avila.fix1[1], 0, 0, 0, 0, avila.fix1[2], 
>        0, 0, 0, 0, avila.fix1[3], 0, 0, 0, 0))
> 1: update(avila.nlme1, fixed = LKe + lKa + lCl ~ Periodo + Trat, 
>        start = c(avila.fix1[1], 0, 0, 0, 0, avila.fix1[2], 0, 0, 
>            0, 0, avila.fix1[3], 0, 0, 0, 0))
> 
> 
> Kjetil Halvorsen
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pkraft at zoology.uq.edu.au  Mon Oct 21 23:22:08 2002
From: pkraft at zoology.uq.edu.au (Peter Kraft)
Date: Tue, 22 Oct 2002 07:22:08 +1000
Subject: [R] 3-D scatter plot laid over Surface plot
Message-ID: <3DB47000.3010206@zoology.uq.edu.au>

Hello,
 I have created a Fitness surface (persp()), with data that was created 
 by a tp spline procedure. Now I would like to superimpose a set (XYZ) of 
 existing points (from two different treatments) onto this surface.
 I didn't come across any function or command that is able to do this in R.
 Could somebody please help me in finding a solution to this problem

 Thank you

 Peter


-- 




Peter Kraft
Department of Zoology and Entomology
University of Queensland
Brisbane 4072
Queensland
Australia
Email: pkraft at zoology.uq.edu.au
Phone: +61 7 3365 1391
Fax:   +61 7 3365 1655
Web:   http://www.zen.uq.edu.au


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From VBMorozov at lbl.gov  Tue Oct 22 01:39:34 2002
From: VBMorozov at lbl.gov (Vladimir Morozov)
Date: Mon, 21 Oct 2002 16:39:34 -0700
Subject: [R] overlaying plots
Message-ID: <001301c2795b$1cd4d410$e7200380@lbl.gov>

Dear R-gurus:

How do I overlay 2 plots in the same frame in R?
Or, if I have a histogram, and I want to plot a function in the same frame -
how do I do it?

Thank you very much,
Vlad


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From djense00 at yahoo.com  Tue Oct 22 01:45:42 2002
From: djense00 at yahoo.com (DAVID JENSEN)
Date: Mon, 21 Oct 2002 16:45:42 -0700 (PDT)
Subject: [R] Script
Message-ID: <20021021234542.12456.qmail@web10405.mail.yahoo.com>

I am brand new to R and would like to know if there is
a way to be able to create, save and retrieve a
program in R like a script object in S-Plus.  I am
just not sure how to do this.  I'm sure there are many
ways to do this ranging from simple to complex, but
the simplest way would be best for me.  Thanks, in advance...

__________________________________________________

Y! Web Hosting - Let the expert host your web site

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andreww at cheque.uq.edu.au  Tue Oct 22 13:28:51 2002
From: andreww at cheque.uq.edu.au (Andrew C. Ward)
Date: Tue, 22 Oct 2002 11:28:51 -0000
Subject: [R] Script
Message-ID: <01C279BE.FBFD3DE0.andreww@cheque.uq.edu.au>

David,

Once you're in R, just use source(file="commands.r") to run all the R commands in a file.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



On Tuesday, October 22, 2002 9:46 AM, DAVID JENSEN [SMTP:djense00 at yahoo.com] wrote:
> I am brand new to R and would like to know if there is
> a way to be able to create, save and retrieve a
> program in R like a script object in S-Plus.  I am
> just not sure how to do this.  I'm sure there are many
> ways to do this ranging from simple to complex, but
> the simplest way would be best for me.  Thanks, in advance...
> 
> __________________________________________________
> 
> Y! Web Hosting - Let the expert host your web site
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andreww at cheque.uq.edu.au  Tue Oct 22 13:34:16 2002
From: andreww at cheque.uq.edu.au (Andrew C. Ward)
Date: Tue, 22 Oct 2002 11:34:16 -0000
Subject: [R] overlaying plots
Message-ID: <01C279BE.FDEC63B0.andreww@cheque.uq.edu.au>

Vlad,

This is typically achieved by drawing your 'main' plot first, then adding 
points, lines, etc to it for whatever else you want to plot. For instance
	> x <- rnorm(1000)
	> tmp <- hist(x)
	> points(tmp$mids, tmp$counts)
	> abline(v=mean(x), col="red", lwd=2, lty=3)


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



On Tuesday, October 22, 2002 9:40 AM, Vladimir Morozov 
[SMTP:VBMorozov at lbl.gov] wrote:
> Dear R-gurus:
>
> How do I overlay 2 plots in the same frame in R?
> Or, if I have a histogram, and I want to plot a function in the same 
frame -
> how do I do it?
>
> Thank you very much,
> Vlad
>
>
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.  
-.-.-.-
> r-help mailing list -- Read 
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.  
_._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From f0z6305 at labs.tamu.edu  Tue Oct 22 04:19:15 2002
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Mon, 21 Oct 2002 21:19:15 -0500
Subject: [R]Gaussian Mixture Models
Message-ID: <000f01c27971$6b5bd140$8bd75ba5@IE.TAMU.EDU>

Hey,

Dose R include some package for Gaussian Mixture Model data generation and
parameters estimation?

Now I want to assign lots of multivariate data into a GMM model.
So just wondering if given sample data, can we use
some functions to estimate the compoents' density
function.

Thanks for your support.

Fred

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From christianlederer at t-online.de  Tue Oct 22 06:58:47 2002
From: christianlederer at t-online.de (Christian Lederer)
Date: Tue, 22 Oct 2002 06:58:47 +0200
Subject: [R] Sample from a hazard function
Message-ID: <20021022065847.7e544f07.christianlederer@t-online.de>


Dear R-gurus,

is there a simple way to simulate of random deviates with a given hazard function? 
Of course, one could do it by foot by calculating the inverse distribution function, 
but perhaps someone knows a package which provides this (perhaps using a more
elegant method).

Christian :-)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bill.Venables at cmis.csiro.au  Tue Oct 22 03:54:35 2002
From: Bill.Venables at cmis.csiro.au (Bill.Venables@cmis.csiro.au)
Date: Tue, 22 Oct 2002 11:54:35 +1000
Subject: [R] RE: [S] VIF Variance Inflation Factor
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A9165584@Roper-CV.qld.cmis.csiro.au>

Kenneth Cabrera asks:

>  -----Original Message-----
> From: 	Kenneth Cabrera [mailto:krcabrer at epm.net.co] 
> Sent:	Tuesday, October 22, 2002 10:05 AM
> Cc:	s-news at lists.biostat.wustl.edu
> Subject:	[S] VIF Variance Inflation Factor
> 
> Hi Dear S+ Users:
> 
> How can I obtain the VIF of a lm object?
	[WNV]  this comes up every now and then and I suppose it has been
answered dozens of times, but here is a simple version of a generic function
that people might find useful (and may consider adding methods to)

vif <- function(object, ...)
UseMethod("vif")

vif.default <- function(object, ...)
stop("No default method for vif.  Sorry.")

vif.lm <- function(object, ...) {	
  V <- summary(object)$cov.unscaled
  Vi <- crossprod(model.matrix(object))
	nam <- names(coef(object))
  if(k <- match("(Intercept)", nam, nomatch = F)) {
		v1 <- diag(V)[-k]
		v2 <- (diag(Vi)[-k] - Vi[k, -k]^2/Vi[k,k])
		nam <- nam[-k]
	} else {
		v1 <- diag(V)
		v2 <- diag(Vi)
		warning("No intercept term detected.  Results may
surprise.")
	}
	structure(v1*v2, names = nam)
}

	[WNV]  use in the obvious way.  (Works in both S universes.)

	> fm <- lm(Gas ~ Insul/Temp, whiteside)
	> vif(fm)
	  Insul InsulBeforeTemp InsulAfterTemp 
	 4.3299        2.932245       2.397654
	> fm <- lm(Gas ~ Insul + Temp, whiteside)
	> vif(fm)
	    Insul     Temp 
	 1.027048 1.027048
	> fm <- lm(Gas ~ Temp, whiteside)
	> vif(fm)
	 Temp 
	    1
	>


> Thank you for your help!
> 
> Kenneth Cabrera
> 
> --------------------------------------------------------------------
> This message was distributed by s-news at lists.biostat.wustl.edu.  To
> unsubscribe send e-mail to s-news-request at lists.biostat.wustl.edu with
> the BODY of the message:  unsubscribe s-news

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dominik.grathwohl at rdls.nestle.com  Tue Oct 22 08:34:47 2002
From: dominik.grathwohl at rdls.nestle.com (Grathwohl,Dominik,LAUSANNE,NRC/NT)
Date: Tue, 22 Oct 2002 08:34:47 +0200
Subject: [R] mixed effect-models
Message-ID: <89466355CEFE7244AC3A013E45641C1894958E@lsmail2.crn.nestrd.ch>

Do I understand right, there is no multinom (nnet), with random effects
available in R!
Do I need to switch to SAS, PROC NLMIXED applying Agresti's example:
http://stat2.uibk.ac.at/SMIJ/hartzel_abs.html

Dominik

> On Mon, 21 Oct 2002, Xavi wrote:
> 
> > Hello,
> > =A0
> > I believe that in R, it is not possible to analyze mixed effect-models
> > when the distribucion is not gaussian (p.e. binomial or poisson), isn't=
> ?
> 
> It depends on exactly what you mean.
> 
>  - Jim Lindsey's packages will fit (at least) random intercept models
> 
>  - For binomial or Poisson models with reasonably large means (perhaps 4
> or so) the PQL approximation used by glmmPQL in the MASS package is prett=
> y
> good.
> 
> > Somebody can suggest me alternative?
> 
> Again, it depends on why you want to fit mixed-effects models. You may be
> able to fit marginal models (GEE) instead.
>
> If you really want to fit mixed models with multiple random effects to
> binary data you probably need SAS PROC NLMIXED or a Bayesian solution
> (or HLM or MLWiN might be able to do it by now).
>
>	-thomas
Dominik Grathwohl 
Biostatistician 
Nestl? Research Center 
PO Box 44, CH-1000 Lausanne 26 
Phone: + 41 21 785 8034 
Fax: + 41 21 785 8556 
e-mail: dominik.grathwohl at rdls.nestle.com 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From grimm.heinz at rcc.ch  Tue Oct 22 09:54:00 2002
From: grimm.heinz at rcc.ch (Heinz Grimm)
Date: Tue, 22 Oct 2002 09:54:00 +0200
Subject: [R] Does SJava work on Windows? It does (ish) on Linux
Message-ID: <3DB50417.A70C9A58@rcc.ch>

Hi Peter,

>Apologies for posting to this list but my attempts to join the
omegahelp
>list bounce back with address unknown errors.

It's a typo in the omega web page. The correct mail address is
omega-help at omegahat.org (not omega-help at www.omegahat.org)

>I'm struggling to get SJava working on windows 98. I'm using R 1.6 and
the
>latest SJava 0.65 and JDK 1.3.1_04. I keep getting an Unsatisified Link

>error on initR.


>Our Java application gets launched with a wrapper script. I've put the
>library paths and current directory in PATH, specified them on the java

>command line using -Djava.library.path= (this is necessary otherwise
the
>DLLs cannot be located in the first instance, despite them being in
PATH).
>I've specified the full pathnames of the DLLs in the System.loadLibrary
java
>calls, but to no avail. Why isn't the initR being resolved?

I had similar problems, see my summary:
http://www.omegahat.org/pipermail/omega-help/2002-October/000232.html

>Do I have to compile R ( I assume the 1.6 R.dll is OK for SJava 0.65?).

I have done my tests with R1.5.1. There is a problem with SJava and R,
that has to be fixed in R, see
http://r-bugs.biostat.ku.dk/cgi-bin/R/incoming?id=2003;user=guest

.
.
.
>Any help on getting SJava working on Windows is appreciated.

If you want to give it a try, I can send you the modified SJava
sources/DLL.

Heinz
-------------- next part --------------
A non-text attachment was scrubbed...
Name: grimm.heinz.vcf
Type: text/x-vcard
Size: 291 bytes
Desc: Card for Heinz Grimm
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021022/95a399fe/grimm.heinz.vcf

From ligges at statistik.uni-dortmund.de  Tue Oct 22 09:53:47 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 22 Oct 2002 09:53:47 +0200
Subject: [R] 3-D scatter plot laid over Surface plot
References: <3DB47000.3010206@zoology.uq.edu.au>
Message-ID: <3DB5040B.AD80BD46@statistik.uni-dortmund.de>

Peter Kraft wrote:
> 
> Hello,
>  I have created a Fitness surface (persp()), with data that was created
>  by a tp spline procedure. Now I would like to superimpose a set (XYZ) of
>  existing points (from two different treatments) onto this surface.
>  I didn't come across any function or command that is able to do this in R.
>  Could somebody please help me in finding a solution to this problem

A message on R-help from Ben Bolker "[R] persp(): add second plane",
dated 14 Mar 2002, answers your question. You'll find it in the mailing
list archive.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From NMBahoshy at aol.com  Tue Oct 22 10:17:40 2002
From: NMBahoshy at aol.com (NMBahoshy@aol.com)
Date: Tue, 22 Oct 2002 04:17:40 EDT
Subject: [R] dyn.load()
Message-ID: <a.273d4e51.2ae663a4@aol.com>

Dear R-help,

I am trying to use routines written in C and Embedded SQL on Sybase in R using dyn.load().

I compiled a couple of test functions into a .so file which I tried to load with R's dynl.load().  This is what happened:

> dyn.load("libRClib.so")
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library "/home/develop/bahomar/tmp/libRClib.so":
  ld.so.1: /home/develop/bahomar/R/lib/R/bin/R.bin: fatal: relocation error: file /opt/sybase/embeddedsql/lib/libct.so: symbol comn_free: referenced symbol not found

As far as I can see there are no unsatisfied symbols. In particular, the symbol comn_free is defined:

> ldd libRClib.so
        libdl.so.1 =>    /usr/lib/libdl.so.1
        libct.so =>      /opt/sybase/embeddedsql/lib/libct.so
        libcs.so =>      /opt/sybase/embeddedsql/lib/libcs.so
        libtcl.so =>     /opt/sybase/embeddedsql/lib/libtcl.so
        libcomn.so =>    /opt/sybase/embeddedsql/lib/libcomn.so
        libintl.so =>    /opt/sybase/embeddedsql/lib/libintl.so
        libnsl.so.1 =>   /usr/lib/libnsl.so.1
        libm.so.1 =>     /usr/lib/libm.so.1
        libc.so.1 =>     /usr/lib/libc.so.1
        libmp.so.2 =>    /usr/lib/libmp.so.2
        /usr/platform/SUNW,Ultra-Enterprise/lib/libc_psr.so.1

> nm /opt/sybase/embeddedsql/lib/libct.so | grep comn_free
[1719]  |         0|       0|NOTY |GLOB |0    |UNDEF  |comn_free

But:

> nm /opt/sybase/embeddedsql/lib/libintl.so | grep comn_free
[167]   |      5624|      12|FUNC |GLOB |0    |7      |comn_free

Platform:

I am running R:

> R.Version()
$platform
[1] "sparc-sun-solaris2.8"

$arch
[1] "sparc"

$os
[1] "solaris2.8"

$system
[1] "sparc, solaris2.8"

$status
[1] ""

$major
[1] "1"

$minor
[1] "5.1"

$year
[1] "2002"

$month
[1] "06"

$day
[1] "17"

$language
[1] "R"

on UNIX:

> uname -a 
SunOS amtss014 5.8 Generic_108528-01 sun4u sparc SUNW,Ultra-Enterprise


I compiled the shared library as follows:

cc -o libRClib.so -G RCtest.c  \
-I${SYBASE}/embeddedsql/include \
-I${FIRAS_INCLUDE} \
-L${SYBASE}/embeddedsql/lib -L${FIRAS_LIB} \
-ldl -lct -lcs -ltcl -lcomn -lintl -lnsl \
-lmm_infc -lmm_fc -lm


I tried different orderings for the included libraries; to no avail.

I also used the shared library from a test programme. It compile and ran correctly.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mpiktas at delfi.lt  Tue Oct 22 11:33:14 2002
From: mpiktas at delfi.lt (Vaidotas Zemlys)
Date: Tue, 22 Oct 2002 10:33:14 +0100
Subject: [R] RAM usage 
References: <3DAFE20E.50505@delfi.lt>
Message-ID: <3DB51B5A.7060601@delfi.lt>

Hi,

Brian D. Ripley wrote:

 >> I did not tell my problem, because I thought that it was more or less
 >> irrelevant to the memory usage problems I was experiencing. My intention
 >> was to ask about how R manages memory and is there something special >about
 >> that management everyone should know, but I don't know. I'm sorry if my
 >> letter was a bit unclear, English is not my native language.

 > But you did claim `must be used'.  That really is rarely the case, and
 > the skill in programming R (or S) is use memory within the resources
 > available.

Yes I did write 'must be used', yet I did not want to claim anything. 
Really, I did not want to express so strictly. I should of used 'is used', 
or something else. As I said English is not my native language:)

I tried to run the same calculations with initial matrix size of 7500 rows 
and 70 columns, on Linux machine as you suggested.  Debian Woody, R version 
1.5.1 with 256 MB RAM and 256 MB Swap, everything worked fine, not like on 
Windows 2000 Professional machine with 256 RAM. It seems that Win2k is 
really missing something with memory management, or R windows build is 
somewhat different from linux build?

Thanks for everybody's answers

Vaidotas Zemlys



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From james.lindsey at luc.ac.be  Tue Oct 22 10:29:50 2002
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Tue, 22 Oct 2002 10:29:50 +0200 (MET DST)
Subject: [R] mixed effect-models
In-Reply-To: <001301c278e3$840effc0$3418db92@dsss.scs.es> from "Xavi" at Oct 21, 2002 11:23:28 AM
Message-ID: <200210220829.KAA19030@luc.ac.be>

> 
> Hello,
> ?
> I believe that in R, it is not possible to analyze mixed effect-models
> when the distribucion is not gaussian (p.e. binomial or poisson), isn't?

Several of the functions in my repeated library handle such data,
available at www.luc.ac.be/~jlindsey/rcode.html
Brian Riply also has a function that will do some glmms.
  Jim

> ?
> Somebody can suggest me alternative? 
> ?
> thanks
> ? 
> xavi
> ?
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From james.lindsey at luc.ac.be  Tue Oct 22 10:36:38 2002
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Tue, 22 Oct 2002 10:36:38 +0200 (MET DST)
Subject: [R] mixed effect-models
In-Reply-To: <Pine.A41.4.44.0210210651400.58844-100000@homer13.u.washington.edu> from "Thomas Lumley" at Oct 21, 2002 07:03:03 AM
Message-ID: <200210220836.KAA27066@luc.ac.be>

> 
> On Mon, 21 Oct 2002, Xavi wrote:
> 
> > Hello,
> > ?
> > I believe that in R, it is not possible to analyze mixed effect-models
> > when the distribucion is not gaussian (p.e. binomial or poisson), isn't?
> 
> It depends on exactly what you mean.
> 
>  - Jim Lindsey's packages will fit (at least) random intercept models

gnlmix will fit one arbitrarily selected random parameter (usually not
the intercept) in a linear or nonlinear regression function with
arbitrary conditional and mixing distributions. Jim

> 
>  - For binomial or Poisson models with reasonably large means (perhaps 4
> or so) the PQL approximation used by glmmPQL in the MASS package is pretty
> good.
> 
> > Somebody can suggest me alternative?
> 
> Again, it depends on why you want to fit mixed-effects models. You may be
> able to fit marginal models (GEE) instead.
> 
> If you really want to fit mixed models with multiple random effects to
> binary data you probably need SAS PROC NLMIXED or a Bayesian solution
> (or HLM or MLWiN might be able to do it by now).
> 
> 	-thomas
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Friedrich.Leisch at ci.tuwien.ac.at  Tue Oct 22 11:18:01 2002
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Tue, 22 Oct 2002 11:18:01 +0200
Subject: [R] CRAN mirror
In-Reply-To: <200210101738.44412.chrysopa@insecta.ufv.br>
References: <200210101738.44412.chrysopa@insecta.ufv.br>
Message-ID: <15797.6089.829392.135732@galadriel.ci.tuwien.ac.at>

>>>>> On Thu, 10 Oct 2002 17:38:44 -0300,
>>>>> Ronaldo Reis (RR) wrote:

  > Hi
  > how I must make to officialize my mirror in the main R website?

Sending email to cran at r-project.org rather than the help mailing list
is probably the better way ... this email simply skipped my attention.


  > My CRAN's mirror is sited in Federal University of Vi?osa in Minas Gerais 
  > State - Brazil.

  > The address is:

  > http://www.termix.ufv.br/CRAN

  > It is diary updated

Thanks a lot, we have included the site to the list of mirrors on CRAN
and in the R sources.

Best,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 22 11:29:10 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 22 Oct 2002 10:29:10 +0100 (BST)
Subject: [R] RAM usage 
In-Reply-To: <3DB51B5A.7060601@delfi.lt>
Message-ID: <Pine.LNX.4.31.0210221027550.4857-100000@gannet.stats>

On Tue, 22 Oct 2002, Vaidotas Zemlys wrote:

> Hi,
>
> Brian D. Ripley wrote:
>
>  >> I did not tell my problem, because I thought that it was more or less
>  >> irrelevant to the memory usage problems I was experiencing. My intention
>  >> was to ask about how R manages memory and is there something special >about
>  >> that management everyone should know, but I don't know. I'm sorry if my
>  >> letter was a bit unclear, English is not my native language.
>
>  > But you did claim `must be used'.  That really is rarely the case, and
>  > the skill in programming R (or S) is use memory within the resources
>  > available.
>
> Yes I did write 'must be used', yet I did not want to claim anything.
> Really, I did not want to express so strictly. I should of used 'is used',
> or something else. As I said English is not my native language:)
>
> I tried to run the same calculations with initial matrix size of 7500 rows
> and 70 columns, on Linux machine as you suggested.  Debian Woody, R version
> 1.5.1 with 256 MB RAM and 256 MB Swap, everything worked fine, not like on
> Windows 2000 Professional machine with 256 RAM. It seems that Win2k is
> really missing something with memory management, or R windows build is
> somewhat different from linux build?

It's Windows.  We have on Windows to use a non-standard memory manager as
the native one is so slow.  Both don't handle large memory blocks well.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hennig at stat.math.ethz.ch  Tue Oct 22 11:37:34 2002
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Tue, 22 Oct 2002 11:37:34 +0200 (CEST)
Subject: [R]Gaussian Mixture Models
In-Reply-To: <000f01c27971$6b5bd140$8bd75ba5@IE.TAMU.EDU>
Message-ID: <Pine.LNX.4.44.0210221136580.28060-100000@florence>

Try library(mclust).

On Mon, 21 Oct 2002, Feng Zhang wrote:

> Hey,
> 
> Dose R include some package for Gaussian Mixture Model data generation and
> parameters estimation?
> 
> Now I want to assign lots of multivariate data into a GMM model.
> So just wondering if given sample data, can we use
> some functions to estimate the compoents' density
> function.
> 
> Thanks for your support.
> 
> Fred
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (current)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mspan at swets.nl  Tue Oct 22 11:54:47 2002
From: mspan at swets.nl (Mark Span)
Date: Tue, 22 Oct 2002 11:54:47 +0200
Subject: [R] constraints again
Message-ID: <4D3C22EDD692D411A99F00508BAEE3750265BF51@swets-nt9>

I would like to fit the following function on my data. 

    out.nls<-nls(z ~ p1+
 
(p2*dat)+(p3*dat^2)+(p4*dat^3)+(p5*AgeS)+(p6*AgeS^2)+(p7*AgeS^3)+
                    (p8*(dat*AgeS))+(p9*(dat^2*AgeS))+(p10*(dat^3*AgeS))+
 
(p11*(dat*AgeS^2))+(p12*(dat*AgeS^3))+(p13*(dat^2*AgeS^2))+
                    (p14*(dat^2*AgeS^3))+(p15*(dat^3*AgeS^3)),
 
start=list(p1=0,p2=0,p3=0,p4=0,p5=0,p6=0,p7=0,p8=0,p9=0,p10=0,p11=0,p12=0,p1
3=0,p14=0,p15=0),trace=trace,
        control=control)

which relates the z-score on a IQ subtest to Age (AgeS) and Raw Score (dat).
Allthough the dataset is quite large, older subjects usually do not provide
large 'raw scores', and young subjects do not provide low scores. This leads
to incorrect fits for large raw scores for older subjects and low raw scores
for young subjects. I would like to constrain the fit so, that the 'link'
between raw score and z-score for all ages is monotonical. Can anybody
direct me to an answer? 

Looking through FAQ and list, I realize that there is no 'easy way'. So
presumably I am looking for directions...

Mark M. Span

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Tue Oct 22 12:50:26 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Tue, 22 Oct 2002 06:50:26 -0400
Subject: [R] Sample from a hazard function
In-Reply-To: <20021022065847.7e544f07.christianlederer@t-online.de>
References: <20021022065847.7e544f07.christianlederer@t-online.de>
Message-ID: <20021022065026.0c70cf80.fharrell@virginia.edu>

On Tue, 22 Oct 2002 06:58:47 +0200
Christian Lederer <christianlederer at t-online.de> wrote:

> 
> Dear R-gurus,
> 
> is there a simple way to simulate of random deviates with a given hazard function? 
> Of course, one could do it by foot by calculating the inverse distribution function, 
> but perhaps someone knows a package which provides this (perhaps using a more
> elegant method).
> 
> Christian :-)

You might take a look at the spower function in the Hmisc library (http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html) which does this quite simply by approximating the hazard function over a fine grid to turn the problem into a simple discrete distribution one.  spower does power simulation for 2-sample survival tests under complex conditions such as delated treatment effect, dropout, dropin, etc.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bernhard.Pfaff at drkw.com  Tue Oct 22 12:55:21 2002
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Tue, 22 Oct 2002 12:55:21 +0200
Subject: [R] constraints again
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9001CADF0F@ibfftce505.is.de.dresdnerkb.com>

Hello Mark,

you might try a simple time trend as an regressor. BTW, is it really
neccesarry to estimate the model by nls? Wouldn't lm suffice?

Bernhard

-----Original Message-----
From: Mark Span [mailto:mspan at swets.nl]
Sent: 22 October 2002 11:55
To: 'r-help at lists.R-project.org'
Subject: [R] constraints again


I would like to fit the following function on my data. 

    out.nls<-nls(z ~ p1+
 
(p2*dat)+(p3*dat^2)+(p4*dat^3)+(p5*AgeS)+(p6*AgeS^2)+(p7*AgeS^3)+
                    (p8*(dat*AgeS))+(p9*(dat^2*AgeS))+(p10*(dat^3*AgeS))+
 
(p11*(dat*AgeS^2))+(p12*(dat*AgeS^3))+(p13*(dat^2*AgeS^2))+
                    (p14*(dat^2*AgeS^3))+(p15*(dat^3*AgeS^3)),
 
start=list(p1=0,p2=0,p3=0,p4=0,p5=0,p6=0,p7=0,p8=0,p9=0,p10=0,p11=0,p12=0,p1
3=0,p14=0,p15=0),trace=trace,
        control=control)

which relates the z-score on a IQ subtest to Age (AgeS) and Raw Score (dat).
Allthough the dataset is quite large, older subjects usually do not provide
large 'raw scores', and young subjects do not provide low scores. This leads
to incorrect fits for large raw scores for older subjects and low raw scores
for young subjects. I would like to constrain the fit so, that the 'link'
between raw score and z-score for all ages is monotonical. Can anybody
direct me to an answer? 

Looking through FAQ and list, I realize that there is no 'easy way'. So
presumably I am looking for directions...

Mark M. Span

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sharon at math.chalmers.se  Tue Oct 22 15:13:41 2002
From: sharon at math.chalmers.se (Sharon Kuhlmann-Berenzon)
Date: Tue, 22 Oct 2002 15:13:41 +0200 (MET DST)
Subject: [R] Mixture of Univariate Normals
Message-ID: <Pine.SOL.4.30.0210221438490.3201-100000@krilov.math.chalmers.se>


Dear list,

Can anyone provide a package or code for estimating the parameters of a
mixture of c (c >=2) univariate normal distributions?

I've tried the algorithm provided by Venables & Ripley (1999) p 263, for
the mixture of two normal, but I don't find the "ms" function in R. I've
used nls instead, but I'm not sure if it works the same.

The data I have is very peaked and with long tails. It should be the
mixture of two distributions (2 types of particles), possibly with the
same mean or very similar means. The QQ plot using the results of the VR
algorithm (above), however, still show a clear S shape. Could this mean
that there is yet another normal distribution in the mixture, ie c=3?

I've started the VR algorithm with different starting points, but they
always converge to the same estimates.  I have about < 12000
observations, and the VR algorithm converges after about 15 iterations.

Thank you for any help.


Sharon K?hlmann


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
SHARON K?HLMANN-BERENZON

Tel. +46-31-772 53 60			Dept. Mathematical Statistics
Fax. +46-31-772 35 08			Chalmers University of Tech.
e-mail: sharon at math.chalmers.se		Eklandagatan 86
					412 96 G?teborg, Sweden

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Marketinging at eyou.com  Tue Oct 22 15:32:44 2002
From: Marketinging at eyou.com (Tom)
Date: Tue, 22 Oct 2002 21:32:44 +0800
Subject: [R] Mime-Version: 1.0
Message-ID: <200210221332.g9MDWZC6021347@hypatia.math.ethz.ch>

An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20021022/c59b90ea/attachment.html

From petr.pikal at precheza.cz  Tue Oct 22 15:33:19 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 22 Oct 2002 15:33:19 +0200
Subject: [R] overlaying plots
In-Reply-To: <001301c2795b$1cd4d410$e7200380@lbl.gov>
Message-ID: <3DB56FBF.11546.1ACF523@localhost>



On 21 Oct 2002 at 16:39, Vladimir Morozov wrote:

> Dear R-gurus:
I would not call myself anything like that, but anyway, you should 
be more specific in your questions.

ppp <- rnorm(1000)
hist(ppp, prob=T)
lines(density(ppp))

for instance these three lines will give you a histogram with a line 
density plot.

And I definitely recommend you RTFM (especially An 
introduction to R) and help files for plot.

> 
> How do I overlay 2 plots in the same frame in R?
> Or, if I have a histogram, and I want to plot a function in the same
> frame - how do I do it?
> 
> Thank you very much,
> Vlad
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.- r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help",
> or "[un]subscribe" (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From snw at mcs.st-and.ac.uk  Tue Oct 22 16:29:59 2002
From: snw at mcs.st-and.ac.uk (Simon Wood)
Date: Tue, 22 Oct 2002 15:29:59 +0100 (BST)
Subject: [R] constraints again
In-Reply-To: <18D602BD42B7E24EB810D6454A58DB9001CADF0F@ibfftce505.is.de.dresdnerkb.com>
Message-ID: <Pine.GSO.4.21.0210221517020.24943-100000@dolphin>

Since your model seems to be linear (in the paramters) you could impose
the constraint approximately using quadratic programming. i.e. fit it as a
linear model subject to linear constraints. Writing your model as
z=f(dat,AgeS)+error
the constraint is just 
df/ddat >0 
for all dat AgeS combinations. You (probably) can't do all dat/AgeS
combinations and retain linearity off the model, but instead you could
impose this constraint at each point on a mesh covering the relevant part
of the AgeS-dat plane. The key bit to recognise is that the partial of f
w.r.t. dat is just a linear transformation of the model parameters, so
that at any dat,AgeS: 
df/ddat = \sum_i c_i p_i     
for some constants c_i that you can easily obtain. Hence your constraint
is just a set of linear constraints of the form:

\sum_i c_i p_i >0

- you can easily apply constraints like this to  the least squares fitting
problem for your model. Routine pcls() in package mgcv will do this for
example, or see package quadprog. 

Simon

  ______________________________________________________________________
> Simon Wood  snw at st-and.ac.uk  http://www.ruwpa.st-and.ac.uk/simon.html
> CREEM, The Observatory, Buchanan Gardens, St Andrews, Fife KY16 9LZ UK
> Direct telephone: (0)1334 461844          Indirect fax: (0)1334 463748 


> I would like to fit the following function on my data. 
> 
>     out.nls<-nls(z ~ p1+
>  
> (p2*dat)+(p3*dat^2)+(p4*dat^3)+(p5*AgeS)+(p6*AgeS^2)+(p7*AgeS^3)+
>                     (p8*(dat*AgeS))+(p9*(dat^2*AgeS))+(p10*(dat^3*AgeS))+
>  
> (p11*(dat*AgeS^2))+(p12*(dat*AgeS^3))+(p13*(dat^2*AgeS^2))+
>                     (p14*(dat^2*AgeS^3))+(p15*(dat^3*AgeS^3)),
>  
> start=list(p1=0,p2=0,p3=0,p4=0,p5=0,p6=0,p7=0,p8=0,p9=0,p10=0,p11=0,p12=0,p1
> 3=0,p14=0,p15=0),trace=trace,
>         control=control)
> 
> which relates the z-score on a IQ subtest to Age (AgeS) and Raw Score (dat).
> Allthough the dataset is quite large, older subjects usually do not provide
> large 'raw scores', and young subjects do not provide low scores. This leads
> to incorrect fits for large raw scores for older subjects and low raw scores
> for young subjects. I would like to constrain the fit so, that the 'link'
> between raw score and z-score for all ages is monotonical. Can anybody
> direct me to an answer? 
> 
> Looking through FAQ and list, I realize that there is no 'easy way'. So
> presumably I am looking for directions...
> 
> Mark M. Span
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
> 
> 
> ----------------------------------------------------------------------
> If you have received this e-mail in error or wish to read our e-mail 
> disclaimer statement and monitoring policy, please refer to 
> http://www.drkw.com/disc/email/ or contact the sender.
> ----------------------------------------------------------------------
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Tue Oct 22 17:00:45 2002
From: brahm at alum.mit.edu (David Brahm)
Date: Tue, 22 Oct 2002 11:00:45 -0400
Subject: [R] 3-D scatter plot laid over Surface plot
In-Reply-To: <28414240@toto.iv>
Message-ID: <15797.26653.218454.420764@gargle.gargle.HOWL>

Peter Kraft <pkraft at zoology.uq.edu.au> wrote:
> I have created a Fitness surface (persp())...  Now I would like to
> superimpose a set (XYZ) of existing points ... onto this surface.

Uwe Ligges <ligges at statistik.uni-dortmund.de> has already pointed out Ben
Bolker's <ben at zoo.ufl.edu> excellent R-help message of 3/14/02, which I merely
summarize here.  Save your persp() invisible output as "pmat":
  R> pmat <- persp(...)

Define the handy function "trans3d":
  R> trans3d <- function(x,y,z, pmat) {
  R>   tmat <- t(cbind(x,y,z,1) %*% pmat)
  R>   list(x=tmat[1,]/tmat[4,], y=tmat[2,]/tmat[4,])
  R> }

Now you can convert 3D coordinates to 2D coordinates for use with points, etc:
  R> points(trans3d(myx, myy, myz, pmat))
-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Tue Oct 22 16:27:14 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Tue, 22 Oct 2002 10:27:14 -0400
Subject: FW: [R]  Mixture Transition Distribution (MTD) time series model in R or S ?
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20149D0F5@groexmb02.pfizer.com>


Forwarded from Adrian Raftery:

-----Original Message-----
From: Adrian Raftery [mailto:raftery at stat.washington.edu]
Sent: Tuesday, October 22, 2002 10:15 AM
To: Warnes, Gregory R
Subject: Re: FW: [R] Mixture Transition Distribution (MTD) time series
model in R or S ?

Thanks, Greg. Current MTD software is reviewed in

Andr? Berchtold and Adrian E. Raftery
"The Mixture Transition Distribution (MTD) Model for High-Order Markov
Chains
and Non-Gaussian Time Series."
Technical Report no. 360, Department of Statistics, University of
Washington.
http://www.stat.washington.edu/www/research/reports/1990s/
To appear in Statistical Science, 2002.

There's nothing in R currently that I know of.

Would you send this information on to the list?

 Thanks much,

Adrian


 -------------------------------------------------------------------
 Adrian E. Raftery
 Professor of Statistics and Sociology
 Director, Center for Statistics and the Social Sciences
 University of Washington, Box 354320	 Phone: (206) 543-4505
 Seattle, WA 98195-4320.		 FAX:   (206) 221-6873
 Web: www.stat.washington.edu/raftery;   www.csss.washington.edu
 -------------------------------------------------------------------



LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hennig at stat.math.ethz.ch  Tue Oct 22 17:42:20 2002
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Tue, 22 Oct 2002 17:42:20 +0200 (CEST)
Subject: [R] Mixture of Univariate Normals
In-Reply-To: <Pine.SOL.4.30.0210221438490.3201-100000@krilov.math.chalmers.se>
Message-ID: <Pine.LNX.4.44.0210221737370.28060-100000@florence>

Dear Sharon,

the recent version of the library mclust can fit mixtures of
one-dimensional Normal distributions. It provides a decision about the
number of components by Bayesian Information criterion, too.

Did you consider a single Cauchy or t-distribution for your data? Perhaps
the tails of Normal distributions shrink too quickly for your data, so that
you would need unreasonable many Normal components?

Christian 

On Tue, 22 Oct 2002, Sharon Kuhlmann-Berenzon wrote:

> 
> Dear list,
> 
> Can anyone provide a package or code for estimating the parameters of a
> mixture of c (c >=2) univariate normal distributions?
> 
> I've tried the algorithm provided by Venables & Ripley (1999) p 263, for
> the mixture of two normal, but I don't find the "ms" function in R. I've
> used nls instead, but I'm not sure if it works the same.
> 
> The data I have is very peaked and with long tails. It should be the
> mixture of two distributions (2 types of particles), possibly with the
> same mean or very similar means. The QQ plot using the results of the VR
> algorithm (above), however, still show a clear S shape. Could this mean
> that there is yet another normal distribution in the mixture, ie c=3?
> 
> I've started the VR algorithm with different starting points, but they
> always converge to the same estimates.  I have about < 12000
> observations, and the VR algorithm converges after about 15 iterations.
> 
> Thank you for any help.
> 
> 
> Sharon K?hlmann
> 
> 
> +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
> SHARON K?HLMANN-BERENZON
> 
> Tel. +46-31-772 53 60			Dept. Mathematical Statistics
> Fax. +46-31-772 35 08			Chalmers University of Tech.
> e-mail: sharon at math.chalmers.se		Eklandagatan 86
> 					412 96 G?teborg, Sweden
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (current)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jrogers at cantatapharm.com  Tue Oct 22 17:46:19 2002
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Tue, 22 Oct 2002 11:46:19 -0400
Subject: [R] gnuclient.exe as pager ?
Message-ID: <99A12772DCDEEB458B996332957B0D530116C8@mercury.cantatapharm.com>

Hi,
 
I see there are some previous threads on gnuclient.exe, but I can't
figure this out based on those...

I recently started using ESS with Xemacs. I'm on Windows XP. On starting
iESS, my editor gets set to 'gnuclient.exe'. I don't understand how this
works, since there is no executable anywhere on my machine called
"gnuclient.exe". But I have no complaints: I like the primitive
spreadsheet that now gets invoked by edit.data.frame. Now, I would like
to be able to also use this gizmo as my pager (I would prefer to only
call edit.data.frame when I really intend to do some editing). But
setting options(pager = "gnuclient.exe") doesn't do the trick. I can't
figure out what's going on, since page calls file.show, which calls
.Internal. 

So, can I use "gnuclient.exe" as my pager? How? 

If replying to the newsgroup, please copy me, as I only get the digest. 

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    5.1            
year     2002           
month    06             
day      17             
language R    



Thanks very much, 
Jim Rogers



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rjvbertin at hotmail.com  Tue Oct 22 18:00:18 2002
From: rjvbertin at hotmail.com (RenE J.V. Bertin)
Date: Tue, 22 Oct 2002 18:00:18 +0200
Subject: [R] gcc 3.2 performance
Message-ID: <20021022180018.4a965c8f.rjvbertin@hotmail.com>

This is (slightly) off-topic, but may be of interest:

I've done some comparing of the overall performance obtained with gcc 3.2.0, compared to gcc 2.95.3 (linux/x86 platform). Has anybody done similar things, and/or does anybody have any comments on this? (Maybe be handled off-list AFAIAC.)

1) On simple benchmarks (dhrystone, "floating dhrystone", some of my own), 3.2 is faster than 2.95.3, but with -O2 only. With -O3, execution times on these can become 2x longer with 3.2 . This appears to be due to -finline-functions that is activated by -O3.

2) Comparison with my own graphing programme with its own expression language (with a byte compiler that that constructs call-graphs with functionpointers to the callbacks and other relevant info, probably not unlike the one in R). Here, 3.2 with -O3 is generally somewhat faster, but I found a single construct (calling a user-defined procedure using a user-supplied pointer to it) that takes almost 10x as long to evaluate with the 3.2 binary.

Specifically, concerning point 2): if sum is a procedure that evaluates add[$[0],$[1]] ($ being an array with the procedure's arguments) and v1,v2 are constants, sum[v1,v2] is very slightly slower with 3.2 than with 2.95.3 . call[&sum,v1,v1] with 2.95.3 takes as much time as evaluating just v1,v2 (sic!!), whereas with 3.2 it takes more than 50% more time than sum[v1,v2] (and evaluating v1,v2 is faster). In both cases, the procedure code *is* evaluated, and my "compiler" doesn't do loop optimising :)
I think that "flabbergasted" is a correct description of my state of mind in this...

R.B.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rjvbertin at hotmail.com  Tue Oct 22 18:05:14 2002
From: rjvbertin at hotmail.com (RenE J.V. Bertin)
Date: Tue, 22 Oct 2002 18:05:14 +0200
Subject: [R] tracing a warning message?
Message-ID: <20021022180514.3d831457.rjvbertin@hotmail.com>

Is there an equivalent to traceback() for tracing a warning message? Since upgrading to 1.6.0, I get a message, at startup, that "the use of _ is deprecated". I've never used this operator in any of the functions I wrote, so some library must use it.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Mike.Lane at verispan.com  Tue Oct 22 18:13:24 2002
From: Mike.Lane at verispan.com (Mike.Lane@verispan.com)
Date: Tue, 22 Oct 2002 12:13:24 -0400
Subject: [R] axis
Message-ID: <OFED969E5F.D3B7173D-ON85256C5A.00587359@synergyhc.com>

I am using R 1.6.0 on Windows 2000 Professional.  I am trying to rotate
x-axis
labels using "srt = 45, adj = 1", but nothing is happening.  It is like the
axis
command is ignoring the "srt" and "adj" arguments.

Thanks,

Mike Lane









-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Tue Oct 22 18:19:09 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Tue, 22 Oct 2002 12:19:09 -0400
Subject: [R] RE: [S] VIF Variance Inflation Factor
References: <E09E527B56BE2D438A3D6A246DDD27A9165584@Roper-CV.qld.cmis.csiro.au>
Message-ID: <3DB57A7D.53CE2A5@umsanet.edu.bo>

There is a vif() function in the car package.

Kjetil Halvorsen

Bill.Venables at CMIS.CSIRO.AU wrote:
> 
> Kenneth Cabrera asks:
> 
> >  -----Original Message-----
> > From:         Kenneth Cabrera [mailto:krcabrer at epm.net.co]
> > Sent: Tuesday, October 22, 2002 10:05 AM
> > Cc:   s-news at lists.biostat.wustl.edu
> > Subject:      [S] VIF Variance Inflation Factor
> >
> > Hi Dear S+ Users:
> >
> > How can I obtain the VIF of a lm object?
>         [WNV]  this comes up every now and then and I suppose it has been
> answered dozens of times, but here is a simple version of a generic function
> that people might find useful (and may consider adding methods to)
> 
> vif <- function(object, ...)
> UseMethod("vif")
> 
> vif.default <- function(object, ...)
> stop("No default method for vif.  Sorry.")
> 
> vif.lm <- function(object, ...) {
>   V <- summary(object)$cov.unscaled
>   Vi <- crossprod(model.matrix(object))
>         nam <- names(coef(object))
>   if(k <- match("(Intercept)", nam, nomatch = F)) {
>                 v1 <- diag(V)[-k]
>                 v2 <- (diag(Vi)[-k] - Vi[k, -k]^2/Vi[k,k])
>                 nam <- nam[-k]
>         } else {
>                 v1 <- diag(V)
>                 v2 <- diag(Vi)
>                 warning("No intercept term detected.  Results may
> surprise.")
>         }
>         structure(v1*v2, names = nam)
> }
> 
>         [WNV]  use in the obvious way.  (Works in both S universes.)
> 
>         > fm <- lm(Gas ~ Insul/Temp, whiteside)
>         > vif(fm)
>           Insul InsulBeforeTemp InsulAfterTemp
>          4.3299        2.932245       2.397654
>         > fm <- lm(Gas ~ Insul + Temp, whiteside)
>         > vif(fm)
>             Insul     Temp
>          1.027048 1.027048
>         > fm <- lm(Gas ~ Temp, whiteside)
>         > vif(fm)
>          Temp
>             1
>         >
> 
> > Thank you for your help!
> >
> > Kenneth Cabrera
> >
> > --------------------------------------------------------------------
> > This message was distributed by s-news at lists.biostat.wustl.edu.  To
> > ....

> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 22 18:52:39 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 22 Oct 2002 17:52:39 +0100 (BST)
Subject: [R] Mixture of Univariate Normals
In-Reply-To: <Pine.SOL.4.30.0210221438490.3201-100000@krilov.math.chalmers.se>
Message-ID: <Pine.LNX.4.31.0210221729570.29174-100000@gannet.stats>

On Tue, 22 Oct 2002, Sharon Kuhlmann-Berenzon wrote:

> Can anyone provide a package or code for estimating the parameters of a
> mixture of c (c >=2) univariate normal distributions?

Alternatives include packages mclust and mda.

> I've tried the algorithm provided by Venables & Ripley (1999) p 263, for
> the mixture of two normal, but I don't find the "ms" function in R. I've
> used nls instead, but I'm not sure if it works the same.

Try Venables & Ripley (2002) instead, or even look in the R scripts
in the MASS library, specifically the MASS/scripts/ch16.R file.
(The version for the 1999 book is MASS/scripts/ch08.R.)

> The data I have is very peaked and with long tails. It should be the
> mixture of two distributions (2 types of particles), possibly with the
> same mean or very similar means. The QQ plot using the results of the VR
> algorithm (above), however, still show a clear S shape. Could this mean
> that there is yet another normal distribution in the mixture, ie c=3?

Well, a mixture of two normals is not long-tailed, so I think you need
something else, e.g. a mixture of t's.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rg117 at ohm.york.ac.uk  Tue Oct 22 19:05:48 2002
From: rg117 at ohm.york.ac.uk (Rishabh Gupta)
Date: Tue, 22 Oct 2002 18:05:48 +0100
Subject: [R] extracting variables with patttern templates
Message-ID: <000501c279ed$4551e440$35892090@ohm.york.ac.uk>

Hi all,
 I was wondering, does R have a facility to extract datasets based on a string template. I know that you can do something like:
    X["a"]    # extract from 'X' the dataset named 'a'.

What I would like is something which says, from 'X' extract all the datasets that have an 'a':
    X[pat = "a"]

I know that the 'pat' option can be used when just listing all the object that exist, but is there any way to extract only certain
dataset from within an object using a smiliar technique.
Any help would be greatly appreciated.

Many Thanks!

Rishabh

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Tue Oct 22 19:37:06 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue, 22 Oct 2002 13:37:06 -0400 (EDT)
Subject: [R] Mixture of Univariate Normals
In-Reply-To: <Pine.SOL.4.30.0210221438490.3201-100000@krilov.math.chalmers.se>
Message-ID: <Pine.LNX.4.44.0210221331590.5435-100000@bolker.zoo.ufl.edu>

On Tue, 22 Oct 2002, Sharon Kuhlmann-Berenzon wrote:

> 
> Dear list,
> 
> Can anyone provide a package or code for estimating the parameters of a
> mixture of c (c >=2) univariate normal distributions?
> 
> I've tried the algorithm provided by Venables & Ripley (1999) p 263, for
> the mixture of two normal, but I don't find the "ms" function in R. I've
> used nls instead, but I'm not sure if it works the same.

  optim() is a closer analogue, but if you're assuming normal 
distributions you should be able to reduce your problem to one that can be 
handled by least-squares (nls).

See the on-line complements, 
http://www.stats.ox.ac.uk/pub/MASS3/Compl.shtml, under chapter 8 the R 
complements say:

Function nls is in standard package nls . Most of the optimization 
examples can be done using nlm or optim , but symbolic differentiation 
using deriv does not work for our examples. See the script ch08.R for 
details.

> The data I have is very peaked and with long tails. It should be the
> mixture of two distributions (2 types of particles), possibly with the
> same mean or very similar means. The QQ plot using the results of the VR
> algorithm (above), however, still show a clear S shape. Could this mean
> that there is yet another normal distribution in the mixture, ie c=3?

  Actually it sounds more like a mixture of t-distributions to me.  I'd 
take a shot at modifying the VR algorithm accordingly.  (Although I would 
note that if the means are very similar you may have some trouble 
identifying the mixture ...)

> I've started the VR algorithm with different starting points, but they
> always converge to the same estimates.  I have about < 12000
> observations, and the VR algorithm converges after about 15 iterations.
> 
> Thank you for any help.
> 
> 
> Sharon K?hlmann
> 
> 
> +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
> SHARON K?HLMANN-BERENZON
> 
> Tel. +46-31-772 53 60			Dept. Mathematical Statistics
> Fax. +46-31-772 35 08			Chalmers University of Tech.
> e-mail: sharon at math.chalmers.se		Eklandagatan 86
> 					412 96 G?teborg, Sweden
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Tue Oct 22 19:35:56 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 22 Oct 2002 10:35:56 -0700 (PDT)
Subject: [R] Mixture of Univariate Normals
In-Reply-To: <Pine.SOL.4.30.0210221438490.3201-100000@krilov.math.chalmers.se>
Message-ID: <Pine.GSO.4.10.10210221034040.8482-100000@fisher.stat.ucla.edu>

You should be able to use the 'optim' function in R.  I think this is
demonstrated in MASS 4th edition (not 100% sure).

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Tue, 22 Oct 2002, Sharon Kuhlmann-Berenzon wrote:

> 
> Dear list,
> 
> Can anyone provide a package or code for estimating the parameters of a
> mixture of c (c >=2) univariate normal distributions?
> 
> I've tried the algorithm provided by Venables & Ripley (1999) p 263, for
> the mixture of two normal, but I don't find the "ms" function in R. I've
> used nls instead, but I'm not sure if it works the same.
> 
> The data I have is very peaked and with long tails. It should be the
> mixture of two distributions (2 types of particles), possibly with the
> same mean or very similar means. The QQ plot using the results of the VR
> algorithm (above), however, still show a clear S shape. Could this mean
> that there is yet another normal distribution in the mixture, ie c=3?
> 
> I've started the VR algorithm with different starting points, but they
> always converge to the same estimates.  I have about < 12000
> observations, and the VR algorithm converges after about 15 iterations.
> 
> Thank you for any help.
> 
> 
> Sharon Khlmann
> 
> 
> +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
> SHARON KHLMANN-BERENZON
> 
> Tel. +46-31-772 53 60			Dept. Mathematical Statistics
> Fax. +46-31-772 35 08			Chalmers University of Tech.
> e-mail: sharon at math.chalmers.se		Eklandagatan 86
> 					412 96 Gteborg, Sweden
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mschwartz at medanalytics.com  Tue Oct 22 20:00:17 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 22 Oct 2002 13:00:17 -0500
Subject: [R] axis
In-Reply-To: <OFED969E5F.D3B7173D-ON85256C5A.00587359@synergyhc.com>
Message-ID: <002001c279f4$e1e1adc0$0201a8c0@MARC>

> -----Original Message-----
> From: owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch] On Behalf Of 
> Mike.Lane at verispan.com
> Sent: Tuesday, October 22, 2002 11:13 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] axis
> 
> 
> I am using R 1.6.0 on Windows 2000 Professional.  I am trying
> to rotate x-axis labels using "srt = 45, adj = 1", but 
> nothing is happening.  It is like the axis command is 
> ignoring the "srt" and "adj" arguments.
> 
> Thanks,
> 
> Mike Lane

Mike,

Take a look at this post from me a week ago on Oct 14 on this same
issue.

http://www.r-project.org/nocvs/mail/r-help/2002/8321.html

See the second code example that shows how to do 45* rotated x-axis
labels.

You need to use text() in order to do what you are trying to do.

You may also wish to see my follow to a related query in that same
thread at

http://www.r-project.org/nocvs/mail/r-help/2002/8334.html

Regards,

Marc Schwartz

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rjvbertin at hotmail.com  Tue Oct 22 20:06:14 2002
From: rjvbertin at hotmail.com (RenE J.V. Bertin)
Date: Tue, 22 Oct 2002 20:06:14 +0200
Subject: [R] tracing a warning message?
In-Reply-To: <200210221732.OAA07642@gelfand.math.unb.ca>
References: <200210221732.OAA07642@gelfand.math.unb.ca>
Message-ID: <20021022200614.3087cec8.rjvbertin@hotmail.com>

Thanks to Rolf Turner and Matthew Wiener for pointing out that options(warn=2) will allow to do this. Some expression in 'gregmisc' turned out to be the culprit.

RenE Bertin
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bill.Shipley at Usherbrooke.ca  Tue Oct 22 23:49:34 2002
From: Bill.Shipley at Usherbrooke.ca (Bill Shipley)
Date: Tue, 22 Oct 2002 14:49:34 -0700
Subject: [R] cubic spline smoothers with heterogeneous variances
Message-ID: <5.1.1.6.0.20021022144340.00b01660@courrier.usherbrooke.ca>

Hello. I have data (plant weights over time) that are non-linear and in 
which the variance increases over time.  I have to estimate the first 
derivatives of plant weight given time (i.e. growth rate) and their se, 
using a regression smoother, and I have been considering cubic spline 
smoothers.  However, I do not know if this can be done given that the error 
variance would increase over time.  Does anyone know what the effect of a 
non-constant error variance has on the estimates of the 1st derivative and 
its se?

Bill Shipley
Departement de biologie
Universite de Sherbrooke
Sherbrooke (Quebec) CANADA J1K 2R9
Bill.Shipley at USherbrooke.ca
http://callisto.si.usherb.ca:8080/bshipley/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ypeng at math.mun.ca  Tue Oct 22 21:29:52 2002
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Tue, 22 Oct 2002 16:59:52 -0230
Subject: [R] Draw ellipses in S-PLUS or R?
Message-ID: <3DB5A730.5DB472B9@math.mun.ca>

Dear S-PLUS/R users:

Do you know any default function or a user contributed function that
can draw an ellipse with given axes and origin? Thanks for any help.

Paul.
--
Romance, like alcohol, should be enjoyed, but should not be allowed to
become necessary.
                -- Edgar Friedenberg
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 22 21:36:18 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 22 Oct 2002 20:36:18 +0100 (BST)
Subject: [R] gnuclient.exe as pager ?
In-Reply-To: <99A12772DCDEEB458B996332957B0D530116C8@mercury.cantatapharm.com>
Message-ID: <Pine.LNX.4.31.0210221925070.29902-100000@gannet.stats>

You need to install gnuserv. You can get it from the windows/emacs/contrib
area on any GNU mirror, and there is more information in the NTemacs FAQ
(in windows/emacs/docs).  You will need something like

(require 'gnuserv)
(gnuserv-start)
(setq gnuserv-frame (selected-frame))

in _emacs or site-start.el.

Once that's done, you can from a command line use

gnuclientw foo

and file foo popds up to view in a emacs frame.

If you use

gnuclient foo

foo popds up to be edited, and you need to release the file (^x # as I
recall).

So you want gnuclientw and not gnuclient as your pager.


On Tue, 22 Oct 2002, Jim Rogers wrote:

> I see there are some previous threads on gnuclient.exe, but I can't
> figure this out based on those...
>
> I recently started using ESS with Xemacs. I'm on Windows XP. On starting
> iESS, my editor gets set to 'gnuclient.exe'. I don't understand how this
> works, since there is no executable anywhere on my machine called
> "gnuclient.exe". But I have no complaints: I like the primitive
> spreadsheet that now gets invoked by edit.data.frame. Now, I would like

Objection!  The R data editor is not primitive, and it is not a
spreadsheet.

> to be able to also use this gizmo as my pager (I would prefer to only

It is not a pager either.  A pager displays a text file, a page at a time.

> call edit.data.frame when I really intend to do some editing). But
> setting options(pager = "gnuclient.exe") doesn't do the trick. I can't
> figure out what's going on, since page calls file.show, which calls
> .Internal.

but R is Open Source and you can read the code ....

> So, can I use "gnuclient.exe" as my pager? How?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ypeng at math.mun.ca  Tue Oct 22 22:03:28 2002
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Tue, 22 Oct 2002 17:33:28 -0230
Subject: [R] Re: [S] Draw ellipses in S-PLUS or R?
References: <51F9C42DA15CD311BD220008C707D81906FFC7F0@usrymx10.merck.com>
Message-ID: <3DB5AF10.78444903@math.mun.ca>

Many thanks to Andy Liaw for quickly reminding me of "ellipse"
package in CRAN. It is apparently what I wanted. Not sure whether
it will work in S-PLUS or not. But I will give it a try.
Thank you.

Paul.

> 
> Have you checked CRAN?  There's an "ellipse" package on CRAN for quite a
> while.
> 
> Andy
> 
> > -----Original Message-----
> > From: Paul Y. Peng [mailto:ypeng at math.mun.ca]
> > Sent: Tuesday, October 22, 2002 3:30 PM
> > To: s-news; r-help at stat.math.ethz.ch
> > Subject: [S] Draw ellipses in S-PLUS or R?
> >
> >
> > Dear S-PLUS/R users:
> >
> > Do you know any default function or a user contributed function that
> > can draw an ellipse with given axes and origin? Thanks for any help.
> >
> > Paul.
> > --
> > Romance, like alcohol, should be enjoyed, but should not be allowed to
> > become necessary.
> >                 -- Edgar Friedenberg
> > --------------------------------------------------------------------
> > This message was distributed by s-news at lists.biostat.wustl.edu.  To
> > ....

> >
> 
> ------------------------------------------------------------------------------
> Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.
> 
> ==============================================================================
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 22 22:43:05 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 22 Oct 2002 21:43:05 +0100 (BST)
Subject: [R] extracting variables with patttern templates
In-Reply-To: <000501c279ed$4551e440$35892090@ohm.york.ac.uk>
Message-ID: <Pine.LNX.4.31.0210222134470.30035-100000@gannet.stats>

What is X?  The only things I can think of in R that could be thought to
contain datasets are lists, and they are extracted via [[ ]].
Or perhaps X is a data frame and you meant columns (`variables' but
perhaps also more general objects).

In either case you can do this by indexing.  To extract all the columns of
a data frame whose name contains `a' I can use

X[grep("a", names(X))]

and that allows regular expressions just like the `pattern' argument of
ls/objects.

It's hard to give precise answers to vague questions, but I hope that
gives
you enough of an idea.

On Tue, 22 Oct 2002, Rishabh Gupta wrote:

> Hi all,
>  I was wondering, does R have a facility to extract datasets based on a string template. I know that you can do something like:
>     X["a"]    # extract from 'X' the dataset named 'a'.
>
> What I would like is something which says, from 'X' extract all the datasets that have an 'a':
>     X[pat = "a"]
>
> I know that the 'pat' option can be used when just listing all the object that exist, but is there any way to extract only certain
> dataset from within an object using a smiliar technique.
> Any help would be greatly appreciated.
>
> Many Thanks!
>
> Rishabh
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Tue Oct 22 22:59:11 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue, 22 Oct 2002 16:59:11 -0400 (EDT)
Subject: [R] tracing a warning message?
In-Reply-To: <20021022180514.3d831457.rjvbertin@hotmail.com>
Message-ID: <Pine.LNX.4.44.0210221525450.6068-100000@bolker.zoo.ufl.edu>


  Something like

cd /usr/local/lib/R/library
find . -path "./*/R/*" | xargs grep _ | egrep -v  \
"^[^_]*#.*_.*|[\"\'].*_.*[\"\']" | more

works for me on Linux; this finds all the files in the R directories of 
your installed libraries (provided they're located where I have them), 
searches for instances of _, and weeds out lines where _ occurs after # or 
between quotes (I know there are some patterns this will miss, such as 

a _ "_" 

but this should be good for a first pass)

  Ben Bolker


On Tue, 22 Oct 2002, RenE J.V. Bertin wrote:

> Is there an equivalent to traceback() for tracing a warning message?
> Since upgrading to 1.6.0, I get a message, at startup, that "the use of
> _ is deprecated". I've never used this operator in any of the functions
> I wrote, so some library must use it.
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help", or
> "[un]subscribe" (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From david.baird at agresearch.co.nz  Tue Oct 22 23:02:49 2002
From: david.baird at agresearch.co.nz (Baird, David)
Date: Wed, 23 Oct 2002 10:02:49 +1300
Subject: [R] Documentation of R Version 2 binary file format (.rda)
Message-ID: <1BA54664A9D7834F9095E436EEED4CAA3FD578@lakefront.agresearch.co.nz>

Is there a document available that gives a clear description
of the layout of data in a version 2 .RDA file. I have a free
program (http://www.vsn-intl.com/genstat/downloads/datald.htm)
(Windows/Linux/Sun MOTIF exes available) that reads and writes 
a wide range of file formats, and have been requested by my users 
to add R to this. It already does S+.

Regards,
David
_________________________________________________________
Dr David Baird, Biometrician  EMail:  David.Baird at AgResearch.CO.NZ
Mail: AgResearch, PO Box 60, Gerald St, Lincoln, NEW ZEALAND
Phone: +64 3 983 3975   Fax: +64 3 983 3946
=======================================================================
Attention: The information contained in this message and/or attachments
from AgResearch Limited is intended only for the persons or entities
to which it is addressed and may contain confidential and/or privileged
material. Any review, retransmission, dissemination or other use of, or
taking of any action in reliance upon, this information by persons or
entities other than the intended recipients is prohibited by AgResearch
Limited. If you have received this message in error, please notify the
sender immediately.
=======================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From carders at north.sr.unh.edu  Tue Oct 22 23:40:08 2002
From: carders at north.sr.unh.edu (Hilmar M. Carders)
Date: Tue, 22 Oct 2002 17:40:08 -0400 (EDT)
Subject: [R] list of exit codes?
Message-ID: <Pine.LNX.4.44.0210161116220.19977-100000@north.sr.unh.edu>


I was just running some regressions and R died with an exit code of 137.  
I assume the problem has something to do with memory usage since I was 
using some fairly large data sets and the Linux system I am on was 
getting real slow just before the crash.   

This prompted me to go looking for a list of R exit codes, but a search
yielded nothing.  Is there such a list?





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gu4 at llnl.gov  Tue Oct 22 23:59:02 2002
From: gu4 at llnl.gov (Pauline Gu)
Date: Tue, 22 Oct 2002 14:59:02 -0700
Subject: [R] segmentation fault in ROracle
In-Reply-To: <3DB5AF10.78444903@math.mun.ca>
References: <51F9C42DA15CD311BD220008C707D81906FFC7F0@usrymx10.merck.com>
Message-ID: <5.1.1.5.2.20021022145301.031b7b08@poptop.llnl.gov>

Hello,

Thanks for Brain and Uwe for responding to my installation problem on 32bit 
machine.

I switched to 64bit Sun Machine and R installation was successful and 
ROracle package was loaded successfully too.

But, I got "segmentation fault" when trying "library(ROracle)".  The 
ORACLE_HOME is set and the LD_LIBRARY_PATH does
include $ORACLE_HOME/lib.

Thanks in advance for helping.

Pauline

 > library(DBI)
 > library(ROracle)
Segmentation Fault

 > version
          _
platform sparc-sun-solaris2.7
arch     sparc
os       solaris2.7
system   sparc, solaris2.7
status
major    1
minor    6.0
year     2002
month    10
day      01
language R
  

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From djense00 at yahoo.com  Wed Oct 23 00:03:15 2002
From: djense00 at yahoo.com (DAVID JENSEN)
Date: Tue, 22 Oct 2002 15:03:15 -0700 (PDT)
Subject: [R] Your opinions
Message-ID: <20021022220315.19304.qmail@web10407.mail.yahoo.com>

I am a long-time statistician and SAS programmer
interested in learning R or S-Plus.  I am intrigued by
being able to do statistical analysis in a more
interactive environment than I am used to in SAS, not
to mention using the much better and easier graphics
capabilities.  In other words I am tired of having to
develop a whole SAS program just to read some data in,
do an ANOVA and a scatterplot.  From what I have
learned of R/S-Plus it appears to be a whole lot
easier (and much more fun) to do things like this in
R/S-Plus than it is in SAS.  If it matters, I will be
running R or S-Plus in Windows 2000.  

For starters, I have access to both R 1.60 and S-Plus
2000 with the ability to obtain a low-cost student
license for S-Plus 6 in the near future if I decide
to.  So the availability of either system is the same.
 As an absolute beginner, I would like your opinions
on which environment would be preferable - R or
S-Plus.  Let's assume that I am willing to put in the
time and effort to make the obvious differences
between the two environments (the GUI interface in
S-Plus) a non-issue.  I am a programmer so I prefer to
learn and use the command-line interface anyway.  So
let's just say that I would very seldom use the GUI in
S-Plus anyway (that may or may not be true but I am
trying to make things equal in terms of the two
environments' capabilities rather than judging them by
how convienient they are).    

Is there a practical reason to choose R over S in
terms of functionality or efficiency?  I will have
some fairly large datasets (over 100,000 obs with 40
variables) but mostly smaller datasets with only a
couple thousand observations.  Am I better off, given
the fact that I have access to S-Plus to use it given
the built-in conveniences which include the GUI.  Or
is there a very practical reason to choose R, other
than the fact that I have great admiration for an
open-source software project and those who contribute
to it.  If I did not have the access I do to S-Plus,
it would be a no-brainer.  I would happily choose R. 
But given the fact I do have access to S-Plus, is
there a reason to instead choose R?  Is what I learn
to do in R directly applicable to S-Plus or are the
differences profound enough as to be confusing
switching back and forth?

Thanks so much in advance for your advice.

Dave  

__________________________________________________

 the expert host your web site

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maj at waikato.ac.nz  Wed Oct 23 01:00:13 2002
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Wed, 23 Oct 2002 12:00:13 +1300
Subject: [R] Mixture of Univariate Normals
In-Reply-To: <Pine.LNX.4.31.0210221729570.29174-100000@gannet.stats>
References: <Pine.SOL.4.30.0210221438490.3201-100000@krilov.math.chalmers.se>
Message-ID: <E18486I-0004qe-00@euler.math.waikato.ac.nz>

At 17:52 22/10/02 +0100, ripley at stats.ox.ac.uk wrote:
[...]
>Well, a mixture of two normals is not long-tailed, so I think you need
>something else, e.g. a mixture of t's.
>

Or a mixture of three normals, the third with a large sigma.


Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html 
Department of Statistics, University of Waikato, Hamilton, New Zealand 
Email: maj at waikato.ac.nz                            Fax +64-7 838 4155
Phone  +64-7 838 4773 wk    +64 7 849 6486 home     Mobile 021 395 862

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andreww at cheque.uq.edu.au  Wed Oct 23 12:44:56 2002
From: andreww at cheque.uq.edu.au (Andrew C. Ward)
Date: Wed, 23 Oct 2002 10:44:56 -0000
Subject: [R] Your opinions
Message-ID: <01C27A81.3CC46930.andreww@cheque.uq.edu.au>

David,

Since starting to use R (around version 1.3.?) I've only used S-PLUS for 
two reasons:
	1. if I already had a lot of data and functions there and didn't have time 
to get them into R.
	2. if I had to merge several data frames together. merge() in R didn't 
seem to work for me.

In other words, I have been able to do everything I wanted to do using R. 
If you have access to a student version of S-PLUS, however, you may as well 
try it out. For creating one-off graphs, the GUI approach in S-PLUS is 
arguably faster than preparing a script in R. Syntax in both systems is 
very much the same. I found that panel functions I created using S-PLUS had 
to be re-written in R, but otherwise most of my code needed only minor 
adjustments.

If you work or will work for a commercial organisation AND it is prepared 
to spend a lot of money, S-PLUS may be the way to go. If you're only a 
tinkerer, or you're a student/academic, or your company can't afford lots 
of software, you can't really go wrong with R.

I don't think I've answered your questions. Maybe someone else will :-)


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



On Wednesday, October 23, 2002 8:03 AM, DAVID JENSEN 
[SMTP:djense00 at yahoo.com] wrote:
> I am a long-time statistician and SAS programmer
> interested in learning R or S-Plus.  I am intrigued by
> being able to do statistical analysis in a more
> interactive environment than I am used to in SAS, not
> to mention using the much better and easier graphics
> capabilities.  In other words I am tired of having to
> develop a whole SAS program just to read some data in,
> do an ANOVA and a scatterplot.  From what I have
> learned of R/S-Plus it appears to be a whole lot
> easier (and much more fun) to do things like this in
> R/S-Plus than it is in SAS.  If it matters, I will be
> running R or S-Plus in Windows 2000.
>
> For starters, I have access to both R 1.60 and S-Plus
> 2000 with the ability to obtain a low-cost student
> license for S-Plus 6 in the near future if I decide
> to.  So the availability of either system is the same.
>  As an absolute beginner, I would like your opinions
> on which environment would be preferable - R or
> S-Plus.  Let's assume that I am willing to put in the
> time and effort to make the obvious differences
> between the two environments (the GUI interface in
> S-Plus) a non-issue.  I am a programmer so I prefer to
> learn and use the command-line interface anyway.  So
> let's just say that I would very seldom use the GUI in
> S-Plus anyway (that may or may not be true but I am
> trying to make things equal in terms of the two
> environments' capabilities rather than judging them by
> how convienient they are).
>
> Is there a practical reason to choose R over S in
> terms of functionality or efficiency?  I will have
> some fairly large datasets (over 100,000 obs with 40
> variables) but mostly smaller datasets with only a
> couple thousand observations.  Am I better off, given
> the fact that I have access to S-Plus to use it given
> the built-in conveniences which include the GUI.  Or
> is there a very practical reason to choose R, other
> than the fact that I have great admiration for an
> open-source software project and those who contribute
> to it.  If I did not have the access I do to S-Plus,
> it would be a no-brainer.  I would happily choose R.
> But given the fact I do have access to S-Plus, is
> there a reason to instead choose R?  Is what I learn
> to do in R directly applicable to S-Plus or are the
> differences profound enough as to be confusing
> switching back and forth?
>
> Thanks so much in advance for your advice.
>
> Dave
>
> __________________________________________________
>
>  the expert host your web site
>
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.  
-.-.-.-
> r-help mailing list -- Read 
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.  
_._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Wed Oct 23 02:35:34 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 22 Oct 2002 17:35:34 -0700
Subject: [R] gnuclient.exe as pager ?
In-Reply-To: <Pine.LNX.4.31.0210221925070.29902-100000@gannet.stats>
References: <Pine.LNX.4.31.0210221925070.29902-100000@gannet.stats>
Message-ID: <87r8eikn55.fsf@jeeves.blindglobe.net>

>>>>> "ripley" == ripley  <ripley at stats.ox.ac.uk> writes:

    ripley> You need to install gnuserv. You can get it from the
    ripley> windows/emacs/contrib area on any GNU mirror, and there is
    ripley> more information in the NTemacs FAQ (in
    ripley> windows/emacs/docs).  You will need something like


    ripley> (require 'gnuserv)
    ripley> (gnuserv-start)
    ripley> (setq gnuserv-frame (selected-frame))

Which should work with XEmacs -- the XEmacs installation (at least for
cygwin, I don't have non-cygwin installed, unfortunately) has gnuserv
installed by default (at least you can have it installed with all the
rest of the packages).

Once installed, that incantation should work.



    ripley> in _emacs or site-start.el.

>From the menu, pull down the Options -> Edit Init File 

to edit the init file.


    ripley> Once that's done, you can from a command line use

    ripley> gnuclientw foo

    ripley> and file foo popds up to view in a emacs frame.

    ripley> If you use

    ripley> gnuclient foo

    ripley> foo popds up to be edited, and you need to release the file (^x # as I
    ripley> recall).

    ripley> So you want gnuclientw and not gnuclient as your pager.


Actually, under XEmacs (and with the caveat, it is the Cygwin version)
you actually do want gnuclient.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r.hankin at auckland.ac.nz  Wed Oct 23 03:32:00 2002
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Wed, 23 Oct 2002 14:32:00 +1300
Subject: [R] vectorizing a function
Message-ID: <200210230132.g9N1W0d24683@r.hankin.sges.auckland.ac.nz>

Dear R-xperts

I have just written a little hypergeometric function, included below
[the hypergeometric function crops up when solving a common type of
ODE].

It works fine on single values of the primary argument z, but
vectorizing it is getting confusing.

The best I have come up with so far just tests for z being longer than
1 and if so, uses sapply() recursively.  This is fine, except that it
doesn't preserve the dimensions correctly if z is a matrix or an
array.  And the function doesn't work properly if z is a scalar but A
is a vector.

besselI() does The Right Thing (tm), but it is internal ; what is the
best way to vectorize this type of function?





hypergeo <- function(A,B,C,z,tol=1e-6){
  if(length(z) > 1) {
    return(sapply(z,hypergeo,A=A,B=B,C=C,tol=tol))
  } else { 
    term <- tmp <- 1
    
    for(n in 1:100){
      term <- term*A*B/C
      term=term*z/n
      
      partial.sum <- tmp + term
      if ((abs(partial.sum-tmp)<tol) || is.infinite(partial.sum)){return(partial.sum)}
      A <- A+1
      B <- B+1
      C <- C+1
      tmp <- partial.sum
    }
    return (NaN)
  }
}


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

as of: Wed Oct 23 14:25:00 NZDT 2002
This (linux) system up continuously for:  419 days, 20 hours, 07 minutes
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bill.Venables at cmis.csiro.au  Wed Oct 23 05:55:05 2002
From: Bill.Venables at cmis.csiro.au (Bill.Venables@cmis.csiro.au)
Date: Wed, 23 Oct 2002 13:55:05 +1000
Subject: [R] vectorizing a function
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A91655A1@Roper-CV.qld.cmis.csiro.au>

Robin Hankin asks:

>  -----Original Message-----
> From: 	Robin Hankin [mailto:r.hankin at auckland.ac.nz] 
> Sent:	Wednesday, October 23, 2002 11:32 AM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] vectorizing a function
> 
> Dear R-xperts
> 
> I have just written a little hypergeometric function, included below
> [the hypergeometric function crops up when solving a common type of
> ODE].
> 
> It works fine on single values of the primary argument z, but
> vectorizing it is getting confusing.
> 
> The best I have come up with so far just tests for z being longer than
> 1 and if so, uses sapply() recursively.  This is fine, except that it
> doesn't preserve the dimensions correctly if z is a matrix or an
> array.  And the function doesn't work properly if z is a scalar but A
> is a vector.
> 
> besselI() does The Right Thing (tm), but it is internal ; what is the
> best way to vectorize this type of function?
> 
> 
> 
> 
> 
> hypergeo <- function(A,B,C,z,tol=1e-6){
>   if(length(z) > 1) {
>     return(sapply(z,hypergeo,A=A,B=B,C=C,tol=tol))
>   } else { 
>     term <- tmp <- 1
>     
>     for(n in 1:100){
>       term <- term*A*B/C
>       term=term*z/n
>       
>       partial.sum <- tmp + term
>       if ((abs(partial.sum-tmp)<tol) ||
> is.infinite(partial.sum)){return(partial.sum)}
>       A <- A+1
>       B <- B+1
>       C <- C+1
>       tmp <- partial.sum
>     }
>     return (NaN)
>   }
> }
> 
> 
	[WNV]  Hmm.  Not sure if this is the best way to calculate this
function, particularly if z is near 1, but here is one way to vectorize it.
I've added a few purist refinements, of course.  Also, I'm really not sure
that the convergence check is all that secure.  Use with extreme caution,
particularly if |z| is near 1.

	(NOTE: this is also vectorized wrt A, B and C as a kind of bonus.)

	hyper <- function(A, B, C, z, tol = sqrt(.Machine$double.eps), maxit
= 10000) {
	    term <- z
	    term[ ] <- 1
	    partial.sum <- term
	    n <- 0
	    while(max(abs(term)) > tol && (n <- n+1) < maxit) {
	      term <- term*A*B/C * z/n
	      partial.sum <- partial.sum + term
	      A <- A+1
	      B <- B+1
	      C <- C+1
	    }
	    if(n == maxit) warning("convergence may not have been achieved")
	    partial.sum
	} 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct 23 08:38:43 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 23 Oct 2002 07:38:43 +0100 (BST)
Subject: [R] list of exit codes?
In-Reply-To: <Pine.LNX.4.44.0210161116220.19977-100000@north.sr.unh.edu>
Message-ID: <Pine.LNX.4.31.0210230727590.30633-100000@gannet.stats>

On Tue, 22 Oct 2002, Hilmar M. Carders wrote:

>
> I was just running some regressions and R died with an exit code of 137.
> I assume the problem has something to do with memory usage since I was
> using some fairly large data sets and the Linux system I am on was
> getting real slow just before the crash.
>
> This prompted me to go looking for a list of R exit codes, but a search
> yielded nothing.  Is there such a list?

Not that I am aware of.  However, the only exit codes that I am aware that
R itself produces are via R_CleanUp, and I can see that called with
0, 1 and 2.

0 is a normal exit
1 is an error exit in non-interactive mode
2 is `suicide', a catastrophic error (or termination by SIGUSR1)

I think error codes like 137 come from your C run-time system.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Wed Oct 23 08:48:20 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Wed, 23 Oct 2002 02:48:20 -0400
Subject: [R] Counting NA?
Message-ID: <20021023064820.GA1296@komensky.surfbest.net>

Hi,

how to do quickly equivalent of the following?

	counter = 0
	for(i in 1:length(data$S2)) {
		if(!is.na(data$S2[i])) {
			counter = counter + 1
		}
	}

I have imagined something like length(x,na.rm=TRUE).

How can I get values usually taken from tables like z-score, 
values of t distribution etc.? I could not find them among 
values mentioned in info file.

Thanks,

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
The difference between death and taxes is death doesn't get worse
every time Congress meets
    -- Will Rogers

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at cbs.dtu.dk  Wed Oct 23 10:53:30 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Wed, 23 Oct 2002 10:53:30 +0200
Subject: [R] Counting NA?
In-Reply-To: <20021023064820.GA1296@komensky.surfbest.net>
References: <20021023064820.GA1296@komensky.surfbest.net>
Message-ID: <20021023085329.GA27378@giraffa.cbs.dtu.dk>

On Wed, Oct 23, 2002 at 02:48:20AM -0400, Matej Cepl wrote:
> Hi,
> 
> how to do quickly equivalent of the following?
> 
> 	counter = 0
> 	for(i in 1:length(data$S2)) {
> 		if(!is.na(data$S2[i])) {
> 			counter = counter + 1
> 		}
> 	}
> 


Try:

sum(is.na(data$2))



Hopin' it helps,


L.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct 23 12:14:47 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 23 Oct 2002 11:14:47 +0100 (BST)
Subject: [R] Counting NA?
In-Reply-To: <20021023064820.GA1296@komensky.surfbest.net>
Message-ID: <Pine.LNX.4.31.0210231111040.3684-100000@gannet.stats>

On Wed, 23 Oct 2002, Matej Cepl wrote:

> Hi,
>
> how to do quickly equivalent of the following?
>
> 	counter = 0
> 	for(i in 1:length(data$S2)) {
> 		if(!is.na(data$S2[i])) {
> 			counter = counter + 1
> 		}
> 	}
>
> I have imagined something like length(x,na.rm=TRUE).

sum(is.na(data$s2)), using that the fact that TRUE/FALSE are coerced to
1/0.

> How can I get values usually taken from tables like z-score,
> values of t distribution etc.? I could not find them among
> values mentioned in info file.

Use qnorm/pnorm etc.  Here's the examples from chapter 1 of MASS4 (a good
reference!)

The \s. environment includes the equivalent of a comprehensive set of
statistical tables; one can work out $P$ values or critical values for
a wide range of distributions (see Table~\ref{tab:dist.1} on
page~\pageref{tab:dist.1}).
\begin{session}
1 - pf(4.3781, 4, 76)&$P$ value from the ANOVA table above.\cr
qf(0.95, 4, 76)&corresponding 5\% critical point.\cr
\end{session}

In R you could also use

pf(4.3781, 4, 76, lower.tail=FALSE)

although I tend to find that too much typing.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From saundersp at bluelizard.org.uk  Wed Oct 23 12:49:26 2002
From: saundersp at bluelizard.org.uk (Phil Saunders)
Date: Wed, 23 Oct 2002 11:49:26 +0100
Subject: [R] Combinatorial Optimisation
Message-ID: <A5B74A99C30DBB46B9A819C3BD4A65F1191638@blsvr-2.bluelizard.org.uk>

Cheers Jim

Your response is exactly what I was hoping for, confirming my suspicions that (for once) R does not have a ready-made function for the purpose, and that what I actually need is one of the various combinatorial optimisation algorithms dotted  around the web, such as simulated annealing, genetic algorithms, taboo search, memetic algorithms, neural networks, et al.

I did manage to cobble together some R code for a taboo search, but I'm no expert in optimisation so I'm not convinced that it is working as efficiently as it should be, and would therefore be very interested in your simulated annealing code as I'll bet it works better than mine!

The SPSA algorithm is also very interesting, especially if it really is as efficient as the website claims, so if you have any code for this then again it would be very welcome, but otherwise I'll have a go at translating the MATLAB code in the overview document into R.

Thanks very much for your response - it's already been very helpful.

Phil

-----Original Message-----
From: Jim_Garrett at bd.com [mailto:Jim_Garrett at bd.com] 
Sent: 22 October 2002 14:45
To: Phil Saunders
Subject: Re: [R] Combinatorial Optimisation



Hello Phil,

There are a number of possibilities that are not hard to implement, though
I don't know of anything out-of-the-box.  You will probably have to do some
coding.

First, if you can implement a "steepest descent" algorithm in which,
beginning from some candidate point, you move to a neighboring point if
your criterion suggests it's better, simply run this algorithm many times
beginning each run from a different randomly-selected starting point.
Simple probability theory indicates that this will converge (in the number
of runs) to the true solution.  In the "consider the neighbors" step, you
could consider all neighbors and pick the best, or just pick one at random
(which might actually do better--it will be less likely to get stuck in
poor local optima).  In many problems this works very quickly, it's just
not very sexy.

Second, you can generalize this a bit and try "simulated annealing" in
which neighboring candidate points are randomly selected.  However, whereas
in steepest descent the algorithm will never move to a point that's worse,
with simulated annealing this happens with probability that decreases as
the candidate point looks worse.  I.e., if the candidate point is just a
little worse, the algorithm moves with moderate to high probability.  But
if the point is a lot worse, the algorithm will make this move with small
probability.  Furthermore, the scaling of "badness" becomes continuously
greater, so that eventually the algorithm will not move to even slightly
worse points.  I have R code to do this, but it requires that you write
some routines that are specific to your problem, mainly defining your loss
function and the function that runs the random selection of neighbors (and
hence implicitly defines what a neighbor is).  If you'd like to try this
out, let me know.

As with steepest descent, I would try several simulated annealing runs.
But simulated annealing is more likely to get a good optimum in a small
number of runs.

One nice thing about simulated annealing is that you can handle complex
constraints by coding the point-selection routine to never selected an
impermissible point.  However, this could cause the optimization to be
trapped.  Another nice feature is (depending on the point-selection routine
again) neighbors involve single-component changes, and if you can write
your loss function so that it can be updated rather than recomputed from
scratch, simulated annealing can be relatively fast.

Third, there's an extremely efficient continuous optimizer that is not
known as well as it ought to be, called Simultaneous Perturbation
Stochastic Approximation (SPSA); there's a web site at
www.jhuapl.edu/spsa/.  I've adapted it to subset selection (in the context
of determining which regression inputs to use).  A potential downside is
that it will randomly partition the components, and will apply the loss
function to each half.  Initially, roughly half would be used.  However,
suppose the optimal solution involves 5 components and you have 95 others.
It will calculate the loss function on the 95.  In some situations this can
be computationally difficult or mathematically impossible.  I have some
code that I could probably generalize pretty well; again, you'll have to
write the loss function.  Again, let me know if you'd like to give it a
try.

Finally, as you probably already know, everybody and their brother has some
combinatorial optimization algorithm.  Some that come to mind are ant
searches, genetic algorithms, and taboo search.  They will all probably
work if used correctly.  But I can't offer much help on them!

Again, I'm happy to offer code, though it's not going to be an
out-of-the-box solution.  I can get you simulated annealing code faster
than SPSA code.  Let me know if you're interested.

Good luck,

Jim Garrett
Becton Dickinson Diagnostic Systems
Baltmore, Maryland, USA



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Wed Oct 23 13:31:00 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 23 Oct 2002 07:31:00 -0400
Subject: [R] Counting NA?
In-Reply-To: <20021023064820.GA1296@komensky.surfbest.net>
Message-ID: <5.1.0.14.2.20021023072408.020a3720@mcmail.cis.mcmaster.ca>

Dear Matej,

At 02:48 AM 10/23/2002 -0400, Matej Cepl wrote:

>How can I get values usually taken from tables like z-score,
>values of t distribution etc.? I could not find them among
>values mentioned in info file.

R has random-number generators and cumulative-probability, density, and 
quantile functions for all of the standard statistical distributions. The 
names are very regular -- for example, rt, pt, dt, and qt for the 
t-distribution, and rnorm, pnorm, dnorm, and qnorm for the normal. Try, for 
example, help(rt) for the details. Even better, look at section 8 (on 
probability distributions) of  An Introduction to R, one of the manuals 
available on CRAN.

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dwartel at ulb.ac.be  Wed Oct 23 13:54:50 2002
From: dwartel at ulb.ac.be (David Wartel)
Date: Wed, 23 Oct 2002 13:54:50 +0200
Subject: [R] Counting NA?
In-Reply-To: <20021023064820.GA1296@komensky.surfbest.net>
References: <20021023064820.GA1296@komensky.surfbest.net>
Message-ID: <200210231354.50052.dwartel@ulb.ac.be>

Surely not the best method:
length(which(is.na(data$S2)==TRUE))


On Wednesday 23 October 2002 08:48, Matej Cepl wrote:
> Hi,
>
> how to do quickly equivalent of the following?
>
> 	counter = 0
> 	for(i in 1:length(data$S2)) {
> 		if(!is.na(data$S2[i])) {
> 			counter = counter + 1
> 		}
> 	}
>
> I have imagined something like length(x,na.rm=TRUE).
>
> How can I get values usually taken from tables like z-score,
> values of t distribution etc.? I could not find them among
> values mentioned in info file.
>
> Thanks,
>
> Matej

-- 
David Wartel

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Wed Oct 23 14:12:31 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Wed, 23 Oct 2002 08:12:31 -0400 (EDT)
Subject: [R] Counting NA?
In-Reply-To: <20021023064820.GA1296@komensky.surfbest.net>
Message-ID: <Pine.LNX.4.44.0210230803100.7299-100000@bolker.zoo.ufl.edu>


   sum(is.na(data$S2))
  [is.na returns TRUE/FALSE, which can also be added up as 0/1 values]

  For your other question: see ?pt, ?pnorm (which will also give you 
information about qt, qnorm, the quantile functions)

  Or help.search("normal"), help.search("Student")

On Wed, 23 Oct 2002, Matej Cepl wrote:

> Hi,
> 
> how to do quickly equivalent of the following?
> 
> 	counter = 0
> 	for(i in 1:length(data$S2)) {
> 		if(!is.na(data$S2[i])) {
> 			counter = counter + 1
> 		}
> 	}
> 
> I have imagined something like length(x,na.rm=TRUE).
> 
> How can I get values usually taken from tables like z-score, 
> values of t distribution etc.? I could not find them among 
> values mentioned in info file.
> 
> Thanks,
> 
> Matej
> 
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Oct 23 14:10:02 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Oct 2002 14:10:02 +0200
Subject: [R] Draw ellipses in S-PLUS or R?
In-Reply-To: <3DB5A730.5DB472B9@math.mun.ca>
References: <3DB5A730.5DB472B9@math.mun.ca>
Message-ID: <15798.37274.666885.481039@gargle.gargle.HOWL>

>>>>> "Paul" == Paul Y Peng <ypeng at math.mun.ca>
>>>>>     on Tue, 22 Oct 2002 16:59:52 -0230 writes:

    Paul> Dear S-PLUS/R users:
    Paul> Do you know any default function or a user contributed function that
    Paul> can draw an ellipse with given axes and origin? Thanks for any help.

Yes, here (written for R, should work in S-plus as well;
	   for the examples, and S-plus, you need to replace
	   col = "gray" by col = <number>}


### Copyright 2002 (C) Martin Maechler <maechler at stat.math.ethz.ch>

## Martin's Solution : radially equispaced ("radial gleichm?ssig") :

ellipsePoints <- function(a,b, alpha = 0, loc = c(0,0), n = 201)
{
    ## Purpose: ellipse points,radially equispaced, given geometric par.s
    ## -------------------------------------------------------------------------
    ## Arguments: a, b : length of half axes in (x,y) direction
    ##            alpha: angle (in degrees) for rotation
    ##            loc  : center of ellipse
    ##            n    : number of points
    ## -------------------------------------------------------------------------
    ## Author: Martin Maechler, Date: 19 Mar 2002, 16:26

    B <- min(a,b)
    A <- max(a,b)
    ## B <= A
    d2 <- (A-B)*(A+B)                   #= A^2 - B^2
    phi <- 2*pi*seq(0,1, len = n)
    sp <- sin(phi)
    cp <- cos(phi)
    r <- a*b / sqrt(B^2 + d2 * sp^2)
    xy <- r * cbind(cp, sp)
    ## xy are the ellipse points for alpha = 0 and loc = (0,0)
    al <- alpha * pi/180
    ca <- cos(al)
    sa <- sin(al)
    xy %*% rbind(c(ca, sa), c(-sa, ca)) + cbind(rep(loc[1],n),
                                                rep(loc[2],n))
}

## Example:

ep <- ellipsePoints(2,5)
str(ep)
plot(ep, type="n",asp=1) ; polygon(ep, col = 2)
## rotate by 30 degrees :
plot(ellipsePoints(2,5, alpha = 30), asp=1)
abline(h=0,v=0,col="gray")
abline(a=0,b= tan( 30 *pi/180), col=2, lty = 2)
abline(a=0,b= tan(120 *pi/180), col=3, lty = 2)


## Movie : rotating ellipse  :
nTurns <- 4 # #{full 360 deg turns}
for(al in 1:(nTurns*360)) {
    ep <- ellipsePoints(3,6, alpha=al, loc = c(5,2))
    plot(ep,type="l",xlim=c(-1,11),ylim=c(-4,8),
         asp=1, axes = FALSE, xlab="", ylab="")
}

## Movie : rotating _filled_ ellipse {less nice to look at}
for(al in 1:180) {
    ep <- ellipsePoints(3,6, alpha=al, loc = c(5,2))
    plot(ep,type="n",xlim=c(-1,11),ylim=c(-4,8),
         asp=1, axes = FALSE, xlab="", ylab="")
    polygon(ep,col=2,border=3,lwd=2.5)
}

###-------------------------------------------------



For R, there's also the  "ellipse" package on CRAN
which does other ellipses (confidence ...).
i.e.
	install.package("ellipse")
	library(ellipse)
if you're online.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From peter.schlattmann at medizin.fu-berlin.de  Wed Oct 23 14:43:09 2002
From: peter.schlattmann at medizin.fu-berlin.de (Peter Schlattmann)
Date: Wed, 23 Oct 2002 14:43:09 +0200
Subject: [R] weighted nonlinear least squares wtih gnls
Message-ID: <3DB6995D.4DB20869@medizin.fu-berlin.de>

Dear all,

I try to perform weighted linear least squares wtih using glns.

The weights are something like

ww<-rep(c((0.1,0.9),n))

my dataframe is named test and I add ww to test by test$ww

Now using 

vf1<-varFixed(~ww)
vf1<-Initialize(test,vf1)

does not produce any usable weights. Does anyone have a
working exampel for this kind of problem?

Thans a lot for oyur help
Peter

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Oct 23 14:48:48 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Oct 2002 14:48:48 +0200
Subject: [R] cubic spline smoothers with heterogeneous variances
In-Reply-To: <5.1.1.6.0.20021022144340.00b01660@courrier.usherbrooke.ca>
References: <5.1.1.6.0.20021022144340.00b01660@courrier.usherbrooke.ca>
Message-ID: <15798.39600.209271.72683@gargle.gargle.HOWL>

>>>>> "Bill" == Bill Shipley <Bill.Shipley at Usherbrooke.ca>
>>>>>     on Tue, 22 Oct 2002 14:49:34 -0700 writes:

    Bill> Hello. I have data (plant weights over time) that are
    Bill> non-linear and in which the variance increases over
    Bill> time.  I have to estimate the first derivatives of
    Bill> plant weight given time (i.e. growth rate) and their
    Bill> se, using a regression smoother, and I have been
    Bill> considering cubic spline smoothers.  

fine. I do so too if I need derivatives.

    Bill> However, I do not know if this can be done given that
    Bill> the error variance would increase over time.  

I'd hope that a simple two-stage procedure (possibly iterated)
would be enough :

1. Smooth(x,y) with ``df = small'' (depend on your context),
   i.e. getting a smooth solution.
2. Get the residuals and  Smooth(x, abs(resid)) 
   to get an estimate proportional to sigma(x).
3. Smooth(x, y,  weights = 1 / sigma(x))

{now you could iterate "2." and "3." and hopefully see
 convergence (of some kind)}.

    Bill> Does anyone know what the effect of a non-constant error
    Bill> variance has on the estimates of the 1st derivative
    Bill> and its se?

"adverse" (effects), but hopefully you'd only look at the 1st
derivative after the above 2-stage solution.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lin00025 at mc.duke.edu  Wed Oct 23 15:26:51 2002
From: lin00025 at mc.duke.edu (Simon M Lin)
Date: Wed, 23 Oct 2002 09:26:51 -0400
Subject: [R] R-1.6.0 compiled on 64-bit AIX- memory problem?
Message-ID: <OF3C32BC25.78552FA4-ON85256C5B.0047E339@notes.duke.edu>

Hello,

Is it true that R-1.6.0 compiled under 64-bit is less efficient on using
memory than compiled under 32-bit?

Here are my observations:

1. I have an SGI IRIX box (2Gb RAM) running 32-bit version of R-1.5.0. It
CAN handle a large data set (an 1111000 * 18 array).
2. For the same data set, on an IBM AIX 64-bit box (64GB RAM) with the new
version of R-1.6.0, it gives an out of memory error.

I am not sure if the problem is caused by 32-/64-bit compilation, or other
AIX vs IRIX issues.

Can the AIX problem be solved by compiling R-1.6.0 under 32-bit?

Thanks!

Simon

================================================================
     Simon Lin, M.D.
     Ph: (919) 681-9646 FAX: (919) 681-8028
     Lin00025 (at) mc.duke.edu
     Box 3958, Duke University Medical Center
     Durham, NC 27710
================================================================



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From arc at arcriswell.com  Thu Oct 24 03:58:23 2002
From: arc at arcriswell.com (Andrew Criswell)
Date: Thu, 24 Oct 2002 08:58:23 +0700
Subject: [R] ordinal logit
Message-ID: <000501c27b01$4ce7ab30$d87d92cb@andrewvhowclyz>

Hello:

I hope someone can help.

I want to run a multinomial logit model where the response variable is
ordinal and the covariates are nominal.  The particular type of model I wish
to run is a "baseline logit model."

Is it possible to do so in R? I have seen that lrm() can run
"continuation-ratio" and "proportional odds" logit models, but not
"baseline" models.

Thanks,
ANDREW


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jan_Svatos at eurotel.cz  Wed Oct 23 15:11:03 2002
From: Jan_Svatos at eurotel.cz (Jan_Svatos@eurotel.cz)
Date: Wed, 23 Oct 2002 15:11:03 +0200
Subject: [R] Counting NA?
Message-ID: <OF536ABAE4.2DA0A5AD-ONC1256C5B.0048273D@eurotel.cz>


Hi,

length(data$S2[is.na(data$S2)]) #counts NA
length(data$S2[!is.na(data$S2)]) #counts NOT NA

is the easiest solution I know.
JS


- - - Original message: - - -
From: owner-r-help at stat.math.ethz.ch
Send: 23.10.2002 9:50:19
To: r-help at stat.math.ethz.ch
Subject: [R] Counting NA?

Hi,

how to do quickly equivalent of the following?

 counter = 0
 for(i in 1:length(data$S2)) {
  if(!is.na(data$S2[i])) {
   counter = counter + 1
  }
 }

I have imagined something like length(x,na.rm=TRUE).

How can I get values usually taken from tables like z-score,
values of t distribution etc.? I could not find them among
values mentioned in info file.

Thanks,

Matej

--
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488

The difference between death and taxes is death doesn't get worse
every time Congress meets
    -- Will Rogers

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Oct 23 16:18:00 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Oct 2002 16:18:00 +0200
Subject: [R] 2003 Chambers Software Competition [fwd]
Message-ID: <15798.44952.945484.144916@gargle.gargle.HOWL>

{This was posted to S-news, but not on R-help, yet.
 It belongs here too. I've set "Reply-To" L.Galway, as for the S-news one.
 Thank you very much, John Chambers! 
 Martin Maechler, R-help list moderator
}

		John M. Chambers Statistical Software Award
		Statistical Computing Section
		American Statistical Association
 
The Statistical Computing Section of the American Statistical Association
announces the competition for the John M. Chambers Statistical Software
Award. In 1998 the Association for Computing Machinery  presented its
Software System Award to John Chambers for the design and development of S.
Dr. Chambers generously donated his award to the Statistical Computing
Section to endow an annual prize for statistical software written by an
undergraduate or graduate student.  The prize carries with it a cash award
of $ 1000, plus a substantial allowance for travel to the annual Joint
Statistical Meetings where the award will be presented.
 
To be eligible, an entrant must have designed and implemented a piece of
statistical software.  The applicant must have begun the development while a
student, and must either currently be a student, or have completed all
requirements for the last degree earned after January 1, 2000.  To apply for
the award, entrants must provide the following materials:
 
	A current CV.
 
	A letter from a faculty mentor at their academic institution.  The
letter should confirm that the software is the work of the student, certify
the student status of the entrant when the software began to be developed
(and either the  current student status and the date of degree completion),
and briefly discuss the importance of the software to statistical practice.
 
	A brief, one to two page description of the software, summarizing
what it does, how it does it, and why it is an important contribution.  If
the entrant has continued developing the software after finishing their
studies, the description should indicate what was developed when the entrant
was a student and what has been added since.
 
	Access to the software by the award committee for their use on
inputs of their choosing.  Access to the software can consist of an
executable file, Web-based access, macro code, or other appropriate form.
Access should be accompanied by enough information to allow the judges to
effectively use and evaluate the software.  This information can be provided
in a variety of ways, including but not limited to a user manual (paper or
electronic), a paper, a URL, online help to the system, and source code.  In
particular, the entrant must be prepared to provide complete source code for
inspection by the committee if requested.
 
All materials must be in English.  We prefer that electronic text be
submitted in Postscript or PDF.  The entries will be judged on a variety of
dimensions, including the importance and relevance for statistical practice
of the tasks performed by the software, ease of use, clarity of description,
elegance and availability for use by the statistical community. Preference
will be given to those entries that are grounded in software design rather
than calculation.  The decision of the award committee is final.
 
All application materials must be received by 5:00pm PST, Thursday, February
28, 2003 at the address below.  The winner will be announced in the spring
of 2003 and the award will be given at the 2003 Joint Statistical Meetings.
 
Information on the competition can also be accessed on the website of the
Statistical Computing Section (www.statcomputing.org), including the names
and contributions of previous winners.  A current pointer to the section
website is also available from the ASA website at www.amstat.org. Inquiries
and application materials should be emailed or mailed to:
 
                Chambers Software Award
                c/o Lionel Galway
                The RAND Corporation
                1700 Main St.
                Santa Monica, CA 90407
                Lionel_Galway at rand.org <mailto:Lionel_Galway at rand.org>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Oct 23 16:31:42 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Oct 2002 16:31:42 +0200
Subject: [R] Draw ellipses in S-PLUS or R?
In-Reply-To: <20021023092911.G5452@jimmy.harvard.edu>
References: <3DB5A730.5DB472B9@math.mun.ca>
	<15798.37274.666885.481039@gargle.gargle.HOWL>
	<20021023092911.G5452@jimmy.harvard.edu>
Message-ID: <15798.45774.837277.801825@gargle.gargle.HOWL>

>>>>> "RobG" == Robert Gentleman <rgentlem at jimmy.harvard.edu>
>>>>>     on Wed, 23 Oct 2002 09:29:11 -0400 writes:

    RobG> Isn't there a package called ellipse ??

yes {as, I say so at the end of my posting}.
But it doesn't do what the ellipsePoints() I posted did :

Draw an ellipse from *geometrical* parameters.
It "only" draws  (confidence like) ellipses specified by mean
and covariance matrix.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Wed Oct 23 16:52:49 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Wed, 23 Oct 2002 10:52:49 -0400
Subject: [R] Counting NA?
In-Reply-To: <200210231354.50052.dwartel@ulb.ac.be>
References: <20021023064820.GA1296@komensky.surfbest.net> <200210231354.50052.dwartel@ulb.ac.be>
Message-ID: <20021023145249.GE737@komensky.surfbest.net>

On Wed, Oct 23, 2002 at 01:54:50PM +0200, David Wartel wrote:
> Surely not the best method:
> length(which(is.na(data$S2)==TRUE))

Hi,

I am sorry, of course, that I have found similar solution
("==TRUE" is unnecessary) five seconds after firing up
'sendmail -q'.  Thanks for the references to z-score,
t-distribution, etc., though.

One this I was really surprised what that in order to get data
from the same data I have to use following construct constantly:

	sumyes <- length(data$S2[data$S2 == 1 & !is.na(data$S2)])

Isn't there any way how to say R, that I want eliminate NA data 
for all my following calculations?

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
The politician attempts to remedy the evil by increasing the very
thing that caused the evil in the first place: legal plunder.
    -- Frederick Bastiat

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From daniel.hoppe at em.uni-karlsruhe.de  Wed Oct 23 17:36:09 2002
From: daniel.hoppe at em.uni-karlsruhe.de (Daniel Hoppe)
Date: Wed, 23 Oct 2002 17:36:09 +0200
Subject: [R] Question regarding RInterpreter.dll
Message-ID: <001001c27aa9$e9dd2080$c1d615ac@chiloe>

Hi all,

I'd like to plug together my Java-application with R and actually I'm too
much a Windows addict ;-) to build R from scratch with all the Unix-style
build environment. Can the RInterpreter.DLL be obtained somewhere on CRAN?
Are there strong reasons for not including RInterpreter.dll in the Windows
distribution?

Best Regards,

Daniel Hoppe

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vpiorno at uvigo.es  Wed Oct 23 18:31:24 2002
From: vpiorno at uvigo.es (Vicente Piorno)
Date: Wed, 23 Oct 2002 18:31:24 +0200
Subject: [R] loglinear models
Message-ID: <004301c27ab1$a2979b80$742492c1@DROSOPHILA>

I am using the loglin function of the base package to fit log-linear models.
I am interested in obtaining the parameter values and their standard errors.
Parameters are easily obtained, but I haven't found the way of obtaining
their standad errors. Is this possible with the loglin function? If not, is
there any other function to get them?
Many thanks,
--
Vicente Piorno
Departamento de Ecolox?a e Biolox?a Animal
EUT Forestal
Campus Universitario
36005 Pontevedra SPAIN

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jg_liao at yahoo.com  Wed Oct 23 19:02:52 2002
From: jg_liao at yahoo.com (Jason Liao)
Date: Wed, 23 Oct 2002 10:02:52 -0700 (PDT)
Subject: [R] R1.6.1 solves severe memory problem in R1.6.0
Message-ID: <20021023170252.59582.qmail@web10507.mail.yahoo.com>

I am analyzing a 10000 by 40 microarray data and need to use simulation
to assess the effect of multi-comparisons. My R program is
computationally intensive. When run under R1.6.0, however, only 5-20%
of CPU is used and my hard disk is moving constantly. I just downloaded
the R.1.6.1 beta. The R program finally uses 98% of the CPU and the
disk gets a rest.

Thought you might be interested. My machine is Win 2000.

Jason
  

=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-8611, fax (732) 235-9777
http://www.geocities.com/jg_liao

__________________________________________________

 the expert host your web site

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Oct 23 19:52:21 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 23 Oct 2002 10:52:21 -0700 (PDT)
Subject: [R] R-1.6.0 compiled on 64-bit AIX- memory problem?
In-Reply-To: <OF3C32BC25.78552FA4-ON85256C5B.0047E339@notes.duke.edu>
Message-ID: <Pine.A41.4.44.0210231051180.178484-100000@homer06.u.washington.edu>

On Wed, 23 Oct 2002, Simon M Lin wrote:

> Hello,
>
> Is it true that R-1.6.0 compiled under 64-bit is less efficient on using
> memory than compiled under 32-bit?

Yes. Pointers take up twice as much space.

> Here are my observations:
>
> 1. I have an SGI IRIX box (2Gb RAM) running 32-bit version of R-1.5.0. It
> CAN handle a large data set (an 1111000 * 18 array).
> 2. For the same data set, on an IBM AIX 64-bit box (64GB RAM) with the new
> version of R-1.6.0, it gives an out of memory error.
>
> I am not sure if the problem is caused by 32-/64-bit compilation, or other
> AIX vs IRIX issues.

The pointer size difference shouldn't affect an array that much.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct 23 21:39:00 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 23 Oct 2002 20:39:00 +0100 (BST)
Subject: [R] loglinear models
In-Reply-To: <004301c27ab1$a2979b80$742492c1@DROSOPHILA>
Message-ID: <Pine.LNX.4.31.0210232037260.1639-100000@gannet.stats>

It's a fundamental limitation of that method of fitting.

Most people fit log-linear models via surrogate Poisson models in glm or
via multinom {nnet}.  There are worked examples of all the approaches in
MASS3/4.

On Wed, 23 Oct 2002, Vicente Piorno wrote:

> I am using the loglin function of the base package to fit log-linear models.
> I am interested in obtaining the parameter values and their standard errors.
> Parameters are easily obtained, but I haven't found the way of obtaining
> their standad errors. Is this possible with the loglin function? If not, is
> there any other function to get them?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r.hankin at auckland.ac.nz  Wed Oct 23 22:00:07 2002
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Thu, 24 Oct 2002 09:00:07 +1300
Subject: [R] vectorizing a function
In-Reply-To: 
	<E09E527B56BE2D438A3D6A246DDD27A91655A1@Roper-CV.qld.cmis.csiro.au>
	(Bill.Venables@CMIS.CSIRO.AU)
References: <E09E527B56BE2D438A3D6A246DDD27A91655A1@Roper-CV.qld.cmis.csiro.au>
Message-ID: <200210232000.g9NK07217729@r.hankin.sges.auckland.ac.nz>

Hi Bill


> > besselI() does The Right Thing (tm), but it is internal ; what is the
> > best way to vectorize this type of function?
> > 

> > [my clunky hypergeometric function deleted]


> [Bill's disclaimer]

 
> 	(NOTE: this is also vectorized wrt A, B and C as a kind of bonus.)
> 
> 	hyper <- function(A, B, C, z, tol = sqrt(.Machine$double.eps), maxit
> = 10000) {
> 	    term <- z
> 	    term[ ] <- 1
> 	    partial.sum <- term
> 	    n <- 0
> 	    while(max(abs(term)) > tol && (n <- n+1) < maxit) {
> 	      term <- term*A*B/C * z/n
> 	      partial.sum <- partial.sum + term
> 	      A <- A+1
> 	      B <- B+1
> 	      C <- C+1
> 	    }
> 	    if(n == maxit) warning("convergence may not have been achieved")
> 	    partial.sum
> 	} 
> 


thank you very much for this: I guess the answer is to build
vectorization in, rather than to bolt it on afterwards!

The only advantage of my original function is that in mine, each
evaluation stops as soon as possible, whereas in Bill's improved
vectorized version, evaluation of each element continues until the
worst-case element finishes.  I imagine that this isn't much of a
problem, unless one deliberatly finds some arguments to make it so.

(incidentally, I am particularly taken with "term[] <- 1",
considerably better than ,y term <- 1+term*0 )-:

Perhaps I should have rephrased my question.  For a function which
absolutely cannot be written in a vectorized manner, eg pparz() below,
what is the best way to emulate true vectorization a la hyper() above?

[qparz() is a quantile function and pparz() inverts it to give the
CDF; try pparz(1:20,c(10,0.1, -0.1)) ]



qparz <- function(p , params) {
  C <- params[1]
  l1 <- params[2]
  l2 <- params[3]
  if(p <=  0) {return(0)  }
  if(p >=  1) {return(Inf)}
C*p^l1*(1-p)^l2
}

pparz <- function(x , params) {
     f <- function(p,a){qparz(p=p,params=a[1:3])-a[4]}
     options(warn = -1)
     if(length(x)==1) {
       return(     uniroot(f,c(0,1),tol=1e-5,a=c(params,x))$root)
     } else {
       return(sapply(x,pparz,params))
     }
}





-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

as of: Thu Oct 24 08:37:00 NZDT 2002
This (linux) system up continuously for:  420 days, 14 hours, 19 minutes
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lukeh at email.byu.edu  Wed Oct 23 22:41:06 2002
From: lukeh at email.byu.edu (Luke Hutchison)
Date: 23 Oct 2002 14:41:06 -0600
Subject: [R] Obtaining covariance matrices for kmeans output clusters
Message-ID: <1035405673.1296.1422.camel@lukeh.dnsalias.net>

I am having trouble getting a covariance matrix for each cluster which
is output by kmeans().  My input looks like:

> imagedat <- read.table("table", header=TRUE)
> imagedat
        Red Green Blue
0_0       5     7    8
1_0       5     5   18
2_0       7     8   49
3_0      22     8   76
4_0      54    10   67
5_0      50     9   28
6_0      18    10   15
7_0       9     7    6
8_0       2     5    7
...

I cluster using

> cl <- kmeans(imagedat, nclust, maxsteps)
> cl
$cluster
     [1]  1  1  9  8  2  9  1  1  1  1  1  1  1  1  1  8  8  8  8  4    
    [25]  9  9  8  8  8  2  2  9  1  1  9  9  7 10 10 10 10 10 10 10 10 
...
$centers
          Red      Green      Blue
1    9.940421   7.744428  11.11652
2   85.198120  18.363348  68.10173
3  109.247072  80.873439  87.42371
...

I then try applying "var" to each Red, Green, Blue triplet (i.e. row) in
the cluster output using 

> covar <- tapply(imagedat, factor(cl$clust), var)
        arguments must have same length

but obviously imagedat is being looked at as a stacked array, three
times the length of cl$clust, so I get the above error.

So my questions are:
(1) How can I get ten 3x3 covariance matrices from the clustering
results "cl$clust", i.e. one for each cluster, with the covariance of
Red, Blue and Green from "imagedat" for each cluster?
(2) How then can I apply operations to all of the matrices at once, i.e.
take the inverse of all of them, or multiply them all by a constant,
without having to write a for-loop?  How can I apply operations to them
each in turn, say in a for-loop?

Thanks very much for any pointers, I'm new to R and its
data-manipulation and storage mechanisms are puzzling to me.

Luke Hutchison.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Wed Oct 23 22:00:13 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 23 Oct 2002 16:00:13 -0400
Subject: [R] loglinear models
In-Reply-To: <004301c27ab1$a2979b80$742492c1@DROSOPHILA>
Message-ID: <5.0.2.1.0.20021023155647.00ad2990@mcmail.cis.mcmaster.ca>

Dear Vicente,

At 06:31 PM 10/23/2002 +0200, Vicente Piorno wrote:
>I am using the loglin function of the base package to fit log-linear models.
>I am interested in obtaining the parameter values and their standard errors.
>Parameters are easily obtained, but I haven't found the way of obtaining
>their standad errors. Is this possible with the loglin function? If not, is
>there any other function to get them?
>Many thanks,

The loglin function fits loglinear models by iterative proportional 
fitting, so standard errors for the parameter estimates are not produced. 
An alternative is to fit the model as a Poisson generalized linear model 
with the glm function, using the cell counts as the response; glm produces 
both estimated coefficients and standard errors, but be careful with the 
parametrization: it is conventional to parametrize loglinear models using 
sum-to-zero constraints (i.e., contr.sum).

I hope that this helps,
  John





____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox
____________________________

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From latouche at linuxmail.org  Wed Oct 23 23:34:37 2002
From: latouche at linuxmail.org (aurelien latouche)
Date: Thu, 24 Oct 2002 05:34:37 +0800
Subject: [R] Survival+cmprsk seg fault
Message-ID: <20021023213437.8405.qmail@linuxmail.org>

Hi,
Still got pb to make work on alpha (debian 3.0)
prev post was "R 1.6.0 on ds10 compaq"
got segfault when using crr function
gdb shows that the pb came from survival function survindex2.c
any 64 bits user ?
-- 

Powered by Outblaze
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Thu Oct 24 01:56:44 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Wed, 23 Oct 2002 19:56:44 -0400
Subject: [R] Counting NA?
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20149D119@groexmb02.pfizer.com>



> -----Original Message-----
> From: Matej Cepl [mailto:matej at ceplovi.cz]
> Sent: Wednesday, October 23, 2002 10:53 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Counting NA?
> 
> 
> On Wed, Oct 23, 2002 at 01:54:50PM +0200, David Wartel wrote:
> > Surely not the best method:
> > length(which(is.na(data$S2)==TRUE))
> 

For pure convenience, the gregmisc package includes a generic function
'nobs' which (for vectors) does sum(!is.na(x)).

	> library(gregmisc)
	> nobs( c(1,2,3,4,5,NA,NA,NA ))
	[1] 5

> One this I was really surprised what that in order to get data
> from the same data I have to use following construct constantly:
> 
> 	sumyes <- length(data$S2[data$S2 == 1 & !is.na(data$S2)])
> 
> Isn't there any way how to say R, that I want eliminate NA data 
> for all my following calculations?

Well, the simplest thing would be to create a new variable with the missing
values removed, 

	y <- na.omit(data$S2)

which is pretty much equivalent to

	y <- data$S2[!is.na(data$S2)]

in this case.

For data frames it na.omit removes rows with any missing value, which is
what we often desire:

> data <- data.frame( x=rnorm(10), y=rnorm(10))
> data$y[3] <- NA
> data
             x          y
1  -1.40045667  0.1370657
2   0.16997476  0.4742317
3   0.66760007         NA
4   1.55857918  0.7787977
5  -0.70213268 -0.3806202
6  -1.03643219  0.4481208
7  -0.72489209  0.5521957
8  -0.86034676  1.3522844
9   0.50605859  1.5335474
10 -0.05295296  1.4871456
> na.omit(data)
             x          y
1  -1.40045667  0.1370657
2   0.16997476  0.4742317
4   1.55857918  0.7787977
5  -0.70213268 -0.3806202
6  -1.03643219  0.4481208
7  -0.72489209  0.5521957
8  -0.86034676  1.3522844
9   0.50605859  1.5335474
10 -0.05295296  1.4871456
> 

-Greg


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Simon.Gatehouse at csiro.au  Thu Oct 24 04:13:05 2002
From: Simon.Gatehouse at csiro.au (Gatehouse, Simon (E&M, North Ryde))
Date: Thu, 24 Oct 2002 12:13:05 +1000
Subject: [R] Rjava failing to initialize in Windows 2000
Message-ID: <FFE02AF26875734B82A728403821CB2E04F29C@asp-ri.riverside.csiro.au>

Dear Any,
I am trying to initialise Rjava with the objective of running ORCA within R.

I am running R1.5.1 on Windows2000 and get the same problem with Sun
Java run time jre-1.2.2_013 
Java  j2re-1.4.1_01
Microsoft Java Virtual Machine Build 3805 


.JavaInit() is failing at :
    .C("s_start_VM", as.character(classPath), as.character(classPath), 
        length(as.character(properties)))
 with the error message
 "Couldn't start Java Virtual Machine: Can't create Java Virtual Machine"


With the following arguements:
classPath= 
"C:/PROGRA~1/R/rw1051/library/SJava/org/omegahat/Jars/Environment.jar;
C:/PROGRA~1/R/rw1051/library/SJava/org/..;
C:/PROGRA~1/R/rw1051/library/SJava/org/omegahat/Jars/antlr.jar;
C:/PROGRA~1/R/rw1051/library/SJava/org/omegahat/Jars/jas.jar;
C:/PROGRA~1/R/rw1051/library/SJava/org/omegahat/Jars/jhall.jar"
All files are present in the appropriate directories

properties= 
[1] "-DEmbeddedInR=true"

[2]
"-DInterfaceManagerClass=org/omegahat/Interfaces/NativeInterface/OmegaInterf
aceManager"          
[3] "-DForeignReferenceBaseClass=org/omegahat/R/Java/RForeignReference"

[4] "-Djava.compiler=NONE"

[5] "-DOMEGA_HOME=C:/PROGRA~1/R/rw1051/library/SJava/org/omegahat"

[6]
"-DOmegahatSearchPath=.,${OMEGA_HOME}/Environment/Scripts/Run,${OMEGA_HOME}/
Jars/Environment.jar"
[7] "-Djava.library.path=C:/PROGRA~1/R/rw1051/library/SJava/libs"


As far as I can tell all file references appear to be OK

Has anyone tried this under similar circumstances? Am I missing something
obvious? 
I have little idea about where to proceed next.

Any suggestions would be much appreciated.

Regards
Simon Gatehouse

***********************************
Simon Gatehouse                                  
CSIRO Exploration and Mining,
Newbigin Close off Julius Ave
North Ryde, NSW
 
Mail:      PO Box 136, North Ryde
           NSW 1670, Australia
Phone:     61 (2) 9490 8677
Fax:       61 (2) 9490 8921
Mobile:    61  0407 130 635 
E-mail:    simon.gatehouse at csiro.au
Web Page:  http://www.csiro.au/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From petr.pikal at precheza.cz  Thu Oct 24 07:55:33 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 24 Oct 2002 07:55:33 +0200
Subject: [R] Counting NA?
In-Reply-To: <20021023145249.GE737@komensky.surfbest.net>
References: <200210231354.50052.dwartel@ulb.ac.be>
Message-ID: <3DB7A775.1922.3C8A75@localhost>



On 23 Oct 2002 at 10:52, Matej Cepl wrote:

> On Wed, Oct 23, 2002 at 01:54:50PM +0200, David Wartel wrote:
> > Surely not the best method:
> > length(which(is.na(data$S2)==TRUE))
> 
> Hi,
> 
> I am sorry, of course, that I have found similar solution
> ("==TRUE" is unnecessary) five seconds after firing up
> 'sendmail -q'.  Thanks for the references to z-score,
> t-distribution, etc., though.
> 
> One this I was really surprised what that in order to get data
> from the same data I have to use following construct constantly:
> 
>  sumyes <- length(data$S2[data$S2 == 1 & !is.na(data$S2)])
> 
> Isn't there any way how to say R, that I want eliminate NA data 
> for all my following calculations?

?na.rm
?na.omit
?na.exclude

depending what you want to do with the result.



> 
> Matej
> 
> -- 
> Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
> 138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
> 
> The politician attempts to remedy the evil by increasing the very
> thing that caused the evil in the first place: legal plunder.
>     -- Frederick Bastiat
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.- r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help",
> or "[un]subscribe" (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From daniel.hoppe at em.uni-karlsruhe.de  Thu Oct 24 08:28:17 2002
From: daniel.hoppe at em.uni-karlsruhe.de (Daniel Hoppe)
Date: Thu, 24 Oct 2002 08:28:17 +0200
Subject: AW: [R] Rjava failing to initialize in Windows 2000
In-Reply-To: <FFE02AF26875734B82A728403821CB2E04F29C@asp-ri.riverside.csiro.au>
Message-ID: <000001c27b26$8a806840$c1d615ac@chiloe>

Hi,

this guy seems to have had the same problem:

http://www.r-project.org/nocvs/mail/r-help/2002/5756.html

He didn't get replies, but maybe he figured out what the problem was. The
error message is typical for a virtual machine if the bootstrap-parameters
are invalid, e.g. the virtual machine type (JIT, hotspot, server) or if the
specified heap-size cannot be allocated.

Please drop a note if you figure out the problem, I might be the next to
step into this (OK, I'm not even as far as having build R from source, so it
might take a while...)

Daniel

-----Urspr?ngliche Nachricht-----
Von: owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch]Im Auftrag von Gatehouse, Simon
(E&M, North Ryde)
Gesendet: Donnerstag, 24. Oktober 2002 04:13
An: r-help at stat.math.ethz.ch
Betreff: [R] Rjava failing to initialize in Windows 2000


Dear Any,
I am trying to initialise Rjava with the objective of running ORCA within R.

I am running R1.5.1 on Windows2000 and get the same problem with Sun
Java run time jre-1.2.2_013
Java  j2re-1.4.1_01
Microsoft Java Virtual Machine Build 3805


.JavaInit() is failing at :
    .C("s_start_VM", as.character(classPath), as.character(classPath),
        length(as.character(properties)))
 with the error message
 "Couldn't start Java Virtual Machine: Can't create Java Virtual Machine"


With the following arguements:
classPath=
"C:/PROGRA~1/R/rw1051/library/SJava/org/omegahat/Jars/Environment.jar;
C:/PROGRA~1/R/rw1051/library/SJava/org/..;
C:/PROGRA~1/R/rw1051/library/SJava/org/omegahat/Jars/antlr.jar;
C:/PROGRA~1/R/rw1051/library/SJava/org/omegahat/Jars/jas.jar;
C:/PROGRA~1/R/rw1051/library/SJava/org/omegahat/Jars/jhall.jar"
All files are present in the appropriate directories

properties=
[1] "-DEmbeddedInR=true"

[2]
"-DInterfaceManagerClass=org/omegahat/Interfaces/NativeInterface/OmegaInterf
aceManager"
[3] "-DForeignReferenceBaseClass=org/omegahat/R/Java/RForeignReference"

[4] "-Djava.compiler=NONE"

[5] "-DOMEGA_HOME=C:/PROGRA~1/R/rw1051/library/SJava/org/omegahat"

[6]
"-DOmegahatSearchPath=.,${OMEGA_HOME}/Environment/Scripts/Run,${OMEGA_HOME}/
Jars/Environment.jar"
[7] "-Djava.library.path=C:/PROGRA~1/R/rw1051/library/SJava/libs"


As far as I can tell all file references appear to be OK

Has anyone tried this under similar circumstances? Am I missing something
obvious?
I have little idea about where to proceed next.

Any suggestions would be much appreciated.

Regards
Simon Gatehouse

***********************************
Simon Gatehouse
CSIRO Exploration and Mining,
Newbigin Close off Julius Ave
North Ryde, NSW

Mail:      PO Box 136, North Ryde
           NSW 1670, Australia
Phone:     61 (2) 9490 8677
Fax:       61 (2) 9490 8921
Mobile:    61  0407 130 635
E-mail:    simon.gatehouse at csiro.au
Web Page:  http://www.csiro.au/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From petr.pikal at precheza.cz  Thu Oct 24 07:55:33 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 24 Oct 2002 07:55:33 +0200
Subject: [R] Counting NA?
In-Reply-To: <20021023145249.GE737@komensky.surfbest.net>
References: <200210231354.50052.dwartel@ulb.ac.be>
Message-ID: <3DB7A775.1922.3C8A75@localhost>



On 23 Oct 2002 at 10:52, Matej Cepl wrote:

> On Wed, Oct 23, 2002 at 01:54:50PM +0200, David Wartel wrote:
> > Surely not the best method:
> > length(which(is.na(data$S2)==TRUE))
> 
> Hi,
> 
> I am sorry, of course, that I have found similar solution
> ("==TRUE" is unnecessary) five seconds after firing up
> 'sendmail -q'.  Thanks for the references to z-score,
> t-distribution, etc., though.
> 
> One this I was really surprised what that in order to get data
> from the same data I have to use following construct constantly:
> 
>  sumyes <- length(data$S2[data$S2 == 1 & !is.na(data$S2)])
> 
> Isn't there any way how to say R, that I want eliminate NA data 
> for all my following calculations?

?na.rm
?na.omit
?na.exclude

depending what you want to do with the result.



> 
> Matej
> 
> -- 
> Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
> 138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
> 
> The politician attempts to remedy the evil by increasing the very
> thing that caused the evil in the first place: legal plunder.
>     -- Frederick Bastiat
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.- r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help",
> or "[un]subscribe" (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Detlef.Steuer at unibw-hamburg.de  Thu Oct 24 08:58:08 2002
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Thu, 24 Oct 2002 08:58:08 +0200 (CEST)
Subject: [R] Combinatorial Optimisation
In-Reply-To: <A5B74A99C30DBB46B9A819C3BD4A65F1191638@blsvr-2.bluelizard.org.uk>
Message-ID: <XFMail.20021024085808.steuer@unibw-hamburg.de>

This thread missed me somehow.

If not mentioned before:
simulated annealing is implemented in optim().

dst

On 23-Oct-2002 Phil Saunders wrote:
> Cheers Jim
> 
> Your response is exactly what I was hoping for, confirming my suspicions that
> (for once) R does not have a ready-made function for the purpose, and that
> what I actually need is one of the various combinatorial optimisation
> algorithms dotted  around the web, such as simulated annealing, genetic
> algorithms, taboo search, memetic algorithms, neural networks, et al.
> 
> I did manage to cobble together some R code for a taboo search, but I'm no
> expert in optimisation so I'm not convinced that it is working as efficiently
> as it should be, and would therefore be very interested in your simulated
> annealing code as I'll bet it works better than mine!
> 
> The SPSA algorithm is also very interesting, especially if it really is as
> efficient as the website claims, so if you have any code for this then again
> it would be very welcome, but otherwise I'll have a go at translating the
> MATLAB code in the overview document into R.
> 
> Thanks very much for your response - it's already been very helpful.
> 
> Phil
> 
> -----Original Message-----
> From: Jim_Garrett at bd.com [mailto:Jim_Garrett at bd.com] 
> Sent: 22 October 2002 14:45
> To: Phil Saunders
> Subject: Re: [R] Combinatorial Optimisation
> 
> 
> 
> Hello Phil,
> 
> There are a number of possibilities that are not hard to implement, though
> I don't know of anything out-of-the-box.  You will probably have to do some
> coding.
> 
> First, if you can implement a "steepest descent" algorithm in which,
> beginning from some candidate point, you move to a neighboring point if
> your criterion suggests it's better, simply run this algorithm many times
> beginning each run from a different randomly-selected starting point.
> Simple probability theory indicates that this will converge (in the number
> of runs) to the true solution.  In the "consider the neighbors" step, you
> could consider all neighbors and pick the best, or just pick one at random
> (which might actually do better--it will be less likely to get stuck in
> poor local optima).  In many problems this works very quickly, it's just
> not very sexy.
> 
> Second, you can generalize this a bit and try "simulated annealing" in
> which neighboring candidate points are randomly selected.  However, whereas
> in steepest descent the algorithm will never move to a point that's worse,
> with simulated annealing this happens with probability that decreases as
> the candidate point looks worse.  I.e., if the candidate point is just a
> little worse, the algorithm moves with moderate to high probability.  But
> if the point is a lot worse, the algorithm will make this move with small
> probability.  Furthermore, the scaling of "badness" becomes continuously
> greater, so that eventually the algorithm will not move to even slightly
> worse points.  I have R code to do this, but it requires that you write
> some routines that are specific to your problem, mainly defining your loss
> function and the function that runs the random selection of neighbors (and
> hence implicitly defines what a neighbor is).  If you'd like to try this
> out, let me know.
> 
> As with steepest descent, I would try several simulated annealing runs.
> But simulated annealing is more likely to get a good optimum in a small
> number of runs.
> 
> One nice thing about simulated annealing is that you can handle complex
> constraints by coding the point-selection routine to never selected an
> impermissible point.  However, this could cause the optimization to be
> trapped.  Another nice feature is (depending on the point-selection routine
> again) neighbors involve single-component changes, and if you can write
> your loss function so that it can be updated rather than recomputed from
> scratch, simulated annealing can be relatively fast.
> 
> Third, there's an extremely efficient continuous optimizer that is not
> known as well as it ought to be, called Simultaneous Perturbation
> Stochastic Approximation (SPSA); there's a web site at
> www.jhuapl.edu/spsa/.  I've adapted it to subset selection (in the context
> of determining which regression inputs to use).  A potential downside is
> that it will randomly partition the components, and will apply the loss
> function to each half.  Initially, roughly half would be used.  However,
> suppose the optimal solution involves 5 components and you have 95 others.
> It will calculate the loss function on the 95.  In some situations this can
> be computationally difficult or mathematically impossible.  I have some
> code that I could probably generalize pretty well; again, you'll have to
> write the loss function.  Again, let me know if you'd like to give it a
> try.
> 
> Finally, as you probably already know, everybody and their brother has some
> combinatorial optimization algorithm.  Some that come to mind are ant
> searches, genetic algorithms, and taboo search.  They will all probably
> work if used correctly.  But I can't offer much help on them!
> 
> Again, I'm happy to offer code, though it's not going to be an
> out-of-the-box solution.  I can get you simulated annealing code faster
> than SPSA code.  Let me know if you're interested.
> 
> Good luck,
> 
> Jim Garrett
> Becton Dickinson Diagnostic Systems
> Baltmore, Maryland, USA
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _

"There is no way to peace, peace is the way." -- Ghandi

Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From noel at univ-lille3.fr  Thu Oct 24 10:10:11 2002
From: noel at univ-lille3.fr (Noel Yvonnick)
Date: Thu, 24 Oct 2002 10:10:11 +0200
Subject: [R] Re: Gaussian Mixtures Models
Message-ID: <200210241010.11888.noel@univ-lille3.fr>

I join below a piece of code I have written for GMM in the special case of 
spherical noise. Note that the end condition is a fixed number of iterations. 
you may want to replace it by some criterion on the change in loglikelihood 
or something like that.

You may want to test it by typing:

# generate some bivariate data
t <- seq(.15,3.05,length=100)
X <- cbind(t,t+1.25*sin(2*t)) + matrix(rnorm(200,0,.1),100,2)

# GMM with 20 classes (or "points")
gm <- gmm(X,npts=20)

You may also want to free the variance parameters (var.equal=FALSE) and the 
prior probabilities (prior.probs=TRUE), though it is not recommended to free 
both of them.

Hope this helps,

-- 
Yvonnick Noel
Universite de Lille 3
UFR de psychologie


#####################################################################################
gmm <- function(X,npts,tmax=40,var.equal=TRUE,prior.prob=FALSE,plot.true=T)
{    

    # Needed packages
    require(mva)
    require(scatterplot3d)
    #require(MASS)
 
    X <- as.matrix(X)
    n <- nrow(X)
    p <- ncol(X)
    priors <- matrix(1,n,1) %*% matrix(1/npts,1,npts)
    
    # For drawing distribution width in the 2D case
    theta <- seq(0,2*pi,length=360)
    circle <- cbind(cos(theta),sin(theta))
    
    # Starting model: sample of observed data
    model <- X[sample(npts),]
    
    # Initialize inverse variance parameter
    d2 <- dist2(X,model)
    beta <- rep((n*p*npts)/sum(d2),npts)
  
    for(t in 1:tmax)
    {
        # Probabilities
        R <- exp(-.5 * (d2 %*% diag(beta))) * priors
                  
        # Responsibilities
        R <- R / apply(R,1,"sum")
        G <- apply(R,2,"sum")
        model <- (t(R)/G) %*% X
        
        # Plotting (each 5 iterations)
	if((plot.true)&&(((t%/%5)-(t/5))==0))
        {
            if(p==2)
            { 
                plot(X,pch=19,cex=.5,col="red",xlab="",ylab="",main="")
                points(model,col="blue",pch=19,cex=.7)
                for(l in 1:npts)
                {
	            icirc <- circle * 1.96 * sqrt(1/beta[l])
                    lines((matrix(1,360,1) %*% model[l,]) + 
icirc,col="darkgreen")
                }
            }
            else if(p==3)
            {
        
                gph <- 
scatterplot3d(X[,c(1,3,2)],highlight.3d=TRUE,pch=19,xlab="",ylab="",zlab="",main="")
                gph$points3d(model[,c(1,3,2)],col="blue",pch=19)

            }
            else if(p>3)
            {
                pc<-princomp(model)
                gph <- 
scatterplot3d(predict(pc,X)[,c(1,3,2)],highlight.3d=TRUE,pch=19,xlab="",ylab="",zlab="",main="")
                gph$points3d(pc$scores[,c(1,3,2)],col="blue",pch=19)

            }
        
        } 

        d2 <- dist2(X,model)

        # Constrain to equal variances
	if(var.equal)  { beta <- rep((n*p)/sum(R*d2),npts) }
        
        # In case of unequal variances
        else           { beta <- (p*G)/apply(R*d2,2,"sum") }

        # Take prior probabilities into account...
        if(prior.prob) { priors <- matrix(1,n,1) %*% (G / n) }
        
    }
    list(model=model,beta=beta,d2=d2,priors=priors)
}

############################################################################################
dist2 <- function(X,Y)
{
	if(missing(Y)) Y <- X
	
	if(!is.matrix(X)) X <- as.matrix(X)
	if(!is.matrix(Y)) Y <- as.matrix(Y)

	dimx<-dim(X)
	dimy<-dim(Y)
 
	sqrx<-diag(X%*%t(X))
	sqry<-diag(Y%*%t(Y))
 
	(sqrx %*% matrix(1,1,dimy[1])) + (matrix(1,dimx[1],1) %*% sqry) - 
(2*X%*%t(Y))
}    
###########################################################################################


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hjm at uninova.pt  Thu Oct 24 10:36:23 2002
From: hjm at uninova.pt (Hugo Morganho)
Date: Thu, 24 Oct 2002 09:36:23 +0100
Subject: [R] Tree construction in Rpart
Message-ID: <005d01c27b38$6f6bdc80$820310ac@pcbav>

  Hi,
     I have one question:
     Does the rpart tree construction have a depth limith for the tree?

     Thanks a lot
     Hugo

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Oct 24 14:19:37 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 24 Oct 2002 13:19:37 +0100 (BST)
Subject: [R] Tree construction in Rpart
In-Reply-To: <005d01c27b38$6f6bdc80$820310ac@pcbav>
Message-ID: <Pine.LNX.4.31.0210241318040.4935-100000@gannet.stats>

On Thu, 24 Oct 2002, Hugo Morganho wrote:

>      I have one question:
>      Does the rpart tree construction have a depth limith for the tree?

Yes. ?rpart.control would have told you.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Oct 24 13:47:00 2002
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 24 Oct 2002 13:47:00 +0200 (MEST)
Subject: [R] Tree construction in Rpart
In-Reply-To: <005d01c27b38$6f6bdc80$820310ac@pcbav>
Message-ID: <Pine.LNX.4.21.0210241346240.1874-100000@artemis>

>   Hi,
>      I have one question:
>      Does the rpart tree construction have a depth limith for the tree?
> 

the tree growing can be controlled by `rpart.control()', 

Torsten

>      Thanks a lot
>      Hugo
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ekr at rtfm.com  Thu Oct 24 17:52:13 2002
From: ekr at rtfm.com (Eric Rescorla)
Date: Thu, 24 Oct 2002 08:52:13 -0700
Subject: [R] glm and lrm disagree with zero table cells
Message-ID: <200210241552.g9OFqDA37742@sierra.rtfm.com>

I've noticed that glm and lrm give extremely different results if you
attempt to fit a saturated model to a dataset with zero cells. Consider,
for instance the data from, Agresti's Death Penalty example [0].

The crosstab table is:

, , PENALTY = NO

       VIC
DEF     BLACK WHITE
  BLACK    97    52
  WHITE     9   132

, , PENALTY = YES

       VIC
DEF     BLACK WHITE
  BLACK     6    11
  WHITE     0    19


Regression with an unsaturated model produces essentially
the same fit parameters with both glm and lrm. However, 
if we try to fit a saturated model....

FITTING WITH GLM:
> summary(glm(PENALTY~DEF*VIC,binomial))

Call:
glm(formula = PENALTY ~ DEF * VIC, family = binomial)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.6195  -0.5186  -0.5186  -0.3465   2.3845  

Coefficients:
                  Estimate Std. Error z value Pr(>|z|)    
(Intercept)        -2.7830     0.4207  -6.615 3.71e-11 ***
DEFWHITE           -4.7823     8.8981  -0.537   0.5910    
VICWHITE            1.2296     0.5358   2.295   0.0217 *  
DEFWHITE:VICWHITE   4.3973     8.9076   0.494   0.6216    
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 226.51  on 325  degrees of freedom
Residual deviance: 218.39  on 322  degrees of freedom
AIC: 226.39

Number of Fisher Scoring iterations: 6


FITTING WITH LRM:
> lrm(PENALTY~DEF*VIC)

Logistic Regression Model

lrm(formula = PENALTY ~ DEF * VIC)


Frequencies of Responses
 NO YES 
290  36 

       Obs  Max Deriv Model L.R.       d.f.          P          C        Dxy 
       326      0.002       8.13          3     0.0435      0.624      0.248 
     Gamma      Tau-a         R2      Brier 
     0.383      0.049      0.049      0.096 

                      Coef   S.E.    Wald Z P     
Intercept             -2.783  0.4207 -6.62  0.0000
DEF=WHITE             -5.490 20.8691 -0.26  0.7925
VIC=WHITE              1.230  0.5358  2.29  0.0217
DEF=WHITE * VIC=WHITE  5.105 20.8732  0.24  0.8068



If we fill in the remaining table cell with a dummy value, [1]
however, then glm and lrm produce essentially the same result.
Here's the glm result.

> summary(glm(PENALTY~DEF*VIC,binomial))

Call:
glm(formula = PENALTY ~ DEF * VIC, family = binomial)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.6195  -0.5186  -0.5186  -0.3465   2.3845  

Coefficients:
                  Estimate Std. Error z value Pr(>|z|)    
(Intercept)        -2.7829     0.4192  -6.639 3.15e-11 ***
DEFWHITE            0.5857     1.1343   0.516   0.6056    
VICWHITE            1.2296     0.5346   2.300   0.0215 *  
DEFWHITE:VICWHITE  -0.9707     1.2070  -0.804   0.4213    
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 230.90  on 326  degrees of freedom
Residual deviance: 224.88  on 323  degrees of freedom
AIC: 232.88

Number of Fisher Scoring iterations: 4


So, my question here is: is this normal behavior? If it
is, perhaps someone could speculate on why the results are
different.

Thanks,
-Ekr


[0] Agresti, A., "Categorical Data Analysis", Wiley 1990.
The data set can be found at http://www.rtfm.com/death.txt

[1] http://www.rtfm.com/death-filled-in.txt





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ms451a14 at vmesa12.u-3mrs.fr  Thu Oct 24 18:08:27 2002
From: ms451a14 at vmesa12.u-3mrs.fr (rachid cheddadi)
Date: Thu, 24 Oct 2002 18:08:27 +0200
Subject: [R] package installation
Message-ID: <3DB81AFB.AB255190@vmesa12.u-3mrs.fr>

Hi, 
I had R working since version 1.4. Then I bought a new HD and installed
a RH 7.3 on it and since then I can no longer install any R package. 
Here is the failure message I obtain: 

... 
g77   -fPIC  -O2 -m486 -fno-strength-reduce -g -c sortm.f -o sortm.o
gcc -shared  -o fields.so css.o csstr.o cvrcss.o cvrf.o dchold.o dcopy.o
ddot.o                                                   dlv.o dmaket.o
drdfun.o dsetup.o expbs.o expfn.o
gaspbs.o gaspfn.o gcvcss.o
gcvf                                                  c.o hsort.o
ifind.o inpoly.o lscv.o m2deb.o mkpoly.o mltdrb.o mltdtd.o msort.o
m                                                  ulteb.o multgb.o
multrb.o nkden.o nkreg.o nvden.o radbas.o radfun.o rcss.o
rcssr                                                  .o rcsswt.o
rkmat.o sortm.o   -L/usr/local/lib
-L/usr/lib/gcc-lib/i386-redhat-li                                                 
nux/2.96 -L/usr/lib/gcc-lib/i386-redhat-linux/2.96/../../.. -lreadline
-ldl
-lnc                                                  urses -lg2c -lm
-L/usr/lib/R/bin -lR
/usr/bin/ld: cannot find -lncurses
collect2: ld returned 1 exit status
make: *** [fields.so] Erreur 1
ERROR: compilation failed for package 'fields' 
  

I obtain the same message for any other package. I checked, I have
readline and ncurses installed. So I don't quite see where the problem
comes from. 
Any help please? 
Many thanks 
Rachid 

-- 
Dr. Rachid Cheddadi
Centre universitaire Arles      Tel: 00.33.(0)4.90.96.18.18
European Pollen Database        Fax: 00.33.(0)4.90.93.98.03
CNRS - UMR 6116                 rachid.cheddadi at wanadoo.fr
13200 Arles - France            rachid.cheddadi at vmesa12.u-3mrs.fr
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pri at chu.com.au  Thu Oct 24 18:03:45 2002
From: pri at chu.com.au (Philip Rhoades)
Date: Fri, 25 Oct 2002 02:03:45 +1000
Subject: [R] Need rowModes, gsummary has errors
Message-ID: <20021024160345.GA19907@phil.chu.com.au>

Hi people,

It would be good to have a fn rowModes (most common number) like 
rowMeans.

I have tried gsummary on a data frame but get:

> t<-read.table("tt.txt")
> t
   V1 V2 V3 V4 V5
1  1  2  3  4  5
2  2  3  4  5  6
3  3  4  5  6  7
> gsummary(t, Mode)
Error in getGroups.data.frame(object, form, level) : 	Invalid formula 
for groups

Help greatly appreciated . .

Thanks,

Phil.
-- 
Philip Rhoades

Pricom Pty Limited  (ACN  003 252 275)
GPO Box 3411
Sydney NSW	2001
Australia
Mobile:  +61:0411-185-652
Fax:  +61:2:8923-5363
E-mail:  pri at chu.com.au
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct 24 19:54:10 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Oct 2002 19:54:10 +0200
Subject: [R] glm and lrm disagree with zero table cells
In-Reply-To: <200210241552.g9OFqDA37742@sierra.rtfm.com>
References: <200210241552.g9OFqDA37742@sierra.rtfm.com>
Message-ID: <x2iszru3i5.fsf@biostat.ku.dk>

Eric Rescorla <ekr at rtfm.com> writes:

> I've noticed that glm and lrm give extremely different results if you
> attempt to fit a saturated model to a dataset with zero cells. Consider,
...
> Coefficients:
>                   Estimate Std. Error z value Pr(>|z|)    
> (Intercept)        -2.7830     0.4207  -6.615 3.71e-11 ***
> DEFWHITE           -4.7823     8.8981  -0.537   0.5910    
> VICWHITE            1.2296     0.5358   2.295   0.0217 *  
> DEFWHITE:VICWHITE   4.3973     8.9076   0.494   0.6216    
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> 
> (Dispersion parameter for binomial family taken to be 1)
> 
>     Null deviance: 226.51  on 325  degrees of freedom
> Residual deviance: 218.39  on 322  degrees of freedom
...
>        Obs  Max Deriv Model L.R.       d.f.          P          C        Dxy 
>        326      0.002       8.13          3     0.0435      0.624      0.248 
>      Gamma      Tau-a         R2      Brier 
>      0.383      0.049      0.049      0.096 
> 
>                       Coef   S.E.    Wald Z P     
> Intercept             -2.783  0.4207 -6.62  0.0000
> DEF=WHITE             -5.490 20.8691 -0.26  0.7925
> VIC=WHITE              1.230  0.5358  2.29  0.0217
> DEF=WHITE * VIC=WHITE  5.105 20.8732  0.24  0.8068

These are *not* extremely different! In fact, they are essentially
equivalent. The maximum likelihood estimates of the 2nd and 4th
coefficients are theoretically infinite, and it is only a matter of
when the two routines decide to stop the iterations. The 1st and 3rd
coefficients are the same, so are their SEs, and also the sum of the
2nd and 4th is -.39 in both cases. The likelihood ratio in the first
model is 226.51-218.39 = 8.12 and in the second it is given as 8.13.

[And where did lrm() come from? It's not in the standard packages, and
I'm not going to wade through 150+ CRAN packages to locate it...] 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ekr at rtfm.com  Thu Oct 24 20:59:58 2002
From: ekr at rtfm.com (Eric Rescorla)
Date: 24 Oct 2002 11:59:58 -0700
Subject: [R] glm and lrm disagree with zero table cells
In-Reply-To: <x2iszru3i5.fsf@biostat.ku.dk>
References: <200210241552.g9OFqDA37742@sierra.rtfm.com>
	<x2iszru3i5.fsf@biostat.ku.dk>
Message-ID: <kjelaf7jdd.fsf@romeo.rtfm.com>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:
> Eric Rescorla <ekr at rtfm.com> writes:
> >        Obs  Max Deriv Model L.R.       d.f.          P          C        Dxy 
> >        326      0.002       8.13          3     0.0435      0.624      0.248 
> >      Gamma      Tau-a         R2      Brier 
> >      0.383      0.049      0.049      0.096 
> > 
> >                       Coef   S.E.    Wald Z P     
> > Intercept             -2.783  0.4207 -6.62  0.0000
> > DEF=WHITE             -5.490 20.8691 -0.26  0.7925
> > VIC=WHITE              1.230  0.5358  2.29  0.0217
> > DEF=WHITE * VIC=WHITE  5.105 20.8732  0.24  0.8068
> 
> These are *not* extremely different! In fact, they are essentially
> equivalent. The maximum likelihood estimates of the 2nd and 4th
> coefficients are theoretically infinite, and it is only a matter of
> when the two routines decide to stop the iterations.
Ah. That's the part I didn't understand. Thanks.

> [And where did lrm() come from? It's not in the standard packages, and
> I'm not going to wade through 150+ CRAN packages to locate it...] 
My bad. It's from Frank Harell's Design library.

Thanks again,
-Ekr

-- 
[Eric Rescorla                                   ekr at rtfm.com]
                http://www.rtfm.com/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From qwertyu2000us at yahoo.com  Thu Oct 24 21:05:30 2002
From: qwertyu2000us at yahoo.com (dave qwertyu)
Date: Thu, 24 Oct 2002 12:05:30 -0700 (PDT)
Subject: [R] nonlinear least square fit of a known function
Message-ID: <20021024190530.72135.qmail@web12705.mail.yahoo.com>


Dear R community,

I have data of x versus y and I know exactly what kind
of function to fit the data.  I just need to fit the
parameters with weighted nonlinear least square.

I am sure R can do this easily, but where do I start?

Thanks a lot in advance!!   Dave

__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Thu Oct 24 21:52:59 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu, 24 Oct 2002 12:52:59 -0700 (PDT)
Subject: [R] packages in non-system directories
Message-ID: <Pine.GSO.4.10.10210241240360.1329-100000@fisher.stat.ucla.edu>

Quick question about installing packages on a system where you do not have
root access.  Suppose a person is using R on a shared system where he
cannot write to the installation directory (i.e. /usr/local/lib/R).  What
general advice would you give regarding where to install packages from
CRAN. Should he use the R_LIBS environment variable or maybe .libPaths()
in R or .Renviron?

Thanks,

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Oct 24 22:09:13 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 24 Oct 2002 13:09:13 -0700 (PDT)
Subject: [R] glm and lrm disagree with zero table cells
In-Reply-To: <200210241552.g9OFqDA37742@sierra.rtfm.com>
Message-ID: <Pine.A41.4.44.0210241303380.38190-100000@homer29.u.washington.edu>

On Thu, 24 Oct 2002, Eric Rescorla wrote:

> I've noticed that glm and lrm give extremely different results if you
> attempt to fit a saturated model to a dataset with zero cells. Consider,
> for instance the data from, Agresti's Death Penalty example [0].

The MLEs are infinite, so there are bound to be problems.  Both methods
will stop short of infinity, when the coefficients or likelihood stop
changing, but where they stop will depend on the exact tolerance and
stopping rule.

They aren't actually that different in terms of fitted values.  For
example, the zero cell has a fitted probability of 0.00025 and 0.0005 in
the two models.


	-thomas



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Thu Oct 24 09:23:49 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 24 Oct 2002 20:23:49 +1300
Subject: [R] package installation
In-Reply-To: <3DB81AFB.AB255190@vmesa12.u-3mrs.fr>; from ms451a14@vmesa12.u-3mrs.fr on Thu, Oct 24, 2002 at 06:08:27PM +0200
References: <3DB81AFB.AB255190@vmesa12.u-3mrs.fr>
Message-ID: <20021024202349.A9111@camille.indigoindustrial.co.nz>

On Thu, Oct 24, 2002 at 06:08:27PM +0200, rachid cheddadi wrote:
> I had R working since version 1.4. Then I bought a new HD and installed
> a RH 7.3 on it and since then I can no longer install any R package. 
> Here is the failure message I obtain: 
...
> /usr/bin/ld: cannot find -lncurses
> collect2: ld returned 1 exit status
> make: *** [fields.so] Erreur 1
> ERROR: compilation failed for package 'fields' 

Hrm, how did you re-install R under the new RH7.3?
Source, or RPM, or...?  

1) from the shell prompt, as root, (assuming bash here), try

/sbin/ldconfig

and try again.

2) if that didn't work, try

find /usr/ -name "libncurses*" -print

After a few minutes, that should find where the system put
libncurses.  It might not be on the library search path, which
(under older versions of RedHat anyway) were configured in 
/etc/ld.so.conf.  If it's in a directory not listed in /etc/ld.so.conf,
(as root) edit the file and put the directory in there, then
run /sbin/ldconfig again.

If that doesn't work... ???

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct 24 22:56:58 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Oct 2002 22:56:58 +0200
Subject: [R] packages in non-system directories
In-Reply-To: <Pine.GSO.4.10.10210241240360.1329-100000@fisher.stat.ucla.edu>
References: <Pine.GSO.4.10.10210241240360.1329-100000@fisher.stat.ucla.edu>
Message-ID: <x2elaftv1h.fsf@biostat.ku.dk>

Roger Peng <rpeng at stat.ucla.edu> writes:

> Quick question about installing packages on a system where you do not have
> root access.  Suppose a person is using R on a shared system where he
> cannot write to the installation directory (i.e. /usr/local/lib/R).  What
> general advice would you give regarding where to install packages from
> CRAN. Should he use the R_LIBS environment variable or maybe .libPaths()
> in R or .Renviron?

Quick answer:

echo 'R_LIBS=/home/pd/Rlibrary' > /home/pd/.Renviron

which of course can be varied in several ways.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Oct 24 23:06:47 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Oct 2002 23:06:47 +0200
Subject: [R] package installation
In-Reply-To: <20021024202349.A9111@camille.indigoindustrial.co.nz>
References: <3DB81AFB.AB255190@vmesa12.u-3mrs.fr>
	<20021024202349.A9111@camille.indigoindustrial.co.nz>
Message-ID: <x2adl3tul4.fsf@biostat.ku.dk>

Jason Turner <jasont at indigoindustrial.co.nz> writes:

> On Thu, Oct 24, 2002 at 06:08:27PM +0200, rachid cheddadi wrote:
> > I had R working since version 1.4. Then I bought a new HD and installed
> > a RH 7.3 on it and since then I can no longer install any R package. 
> > Here is the failure message I obtain: 
> ...
> > /usr/bin/ld: cannot find -lncurses

....
> /etc/ld.so.conf.  If it's in a directory not listed in /etc/ld.so.conf,
> (as root) edit the file and put the directory in there, then
> run /sbin/ldconfig again.
> 
> If that doesn't work... ???

...you might want to check whether you have the ncurses-devel RPM
installed.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Thu Oct 24 10:19:19 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 24 Oct 2002 21:19:19 +1300
Subject: [R] package installation
In-Reply-To: <x2adl3tul4.fsf@biostat.ku.dk>; from p.dalgaard@biostat.ku.dk on Thu, Oct 24, 2002 at 11:06:47PM +0200
References: <3DB81AFB.AB255190@vmesa12.u-3mrs.fr> <20021024202349.A9111@camille.indigoindustrial.co.nz> <x2adl3tul4.fsf@biostat.ku.dk>
Message-ID: <20021024211919.A9217@camille.indigoindustrial.co.nz>

On Thu, Oct 24, 2002 at 11:06:47PM +0200, Peter Dalgaard BSA wrote:
> Jason Turner <jasont at indigoindustrial.co.nz> writes:
> 
> > On Thu, Oct 24, 2002 at 06:08:27PM +0200, rachid cheddadi wrote:
> > > I had R working since version 1.4. Then I bought a new HD and installed
> > > a RH 7.3 on it and since then I can no longer install any R package. 
> > > Here is the failure message I obtain: 
> > ...
> > > /usr/bin/ld: cannot find -lncurses
> 
> ....
> > /etc/ld.so.conf.  If it's in a directory not listed in /etc/ld.so.conf,
> > (as root) edit the file and put the directory in there, then
> > run /sbin/ldconfig again.
> > 
> > If that doesn't work... ???
> 
> ...you might want to check whether you have the ncurses-devel RPM
> installed.

Much more likely.  Thanks Peter - forgot that.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pavlicov at stat.ohio-state.edu  Thu Oct 24 23:16:39 2002
From: pavlicov at stat.ohio-state.edu (Martina Pavlicova)
Date: Thu, 24 Oct 2002 17:16:39 -0400 (EDT)
Subject: [R] mixed effect model
In-Reply-To: <Pine.SOL.4.33.0210241652590.709-100000@spatial.stat.ohio-state.edu>
Message-ID: <Pine.SOL.4.33.0210241707410.709-100000@spatial.stat.ohio-state.edu>


Dear all,

is it possible to fit a following mixed effect model?

Y_ij = mu + X_i * beta + b_i + b_ij + epsilon_ij

	b_i  ~ Gaus [ 0, sigma^2 ]
	b_ij ~ Gaus [ 0, sigma_i^2 ]
 	where 	i = 1 ... M
 		j = 1 ... M_i

X_i is a 0/1 treatment variable (beta a scalar)

In my problem:
	i ... subject
	j ... voxel in subject


Note that the b_ij have different variance for each subject i.


Is it possible to fit this model using lme()?

Thank you very much.

Martina Pavlicova
--------------------------------------------------------------------------
Department of Statistics             Office Phone: (614) 292-1567
1958 Neil Avenue, 304E Cockins Hall  FAX: (614) 292-2096
The Ohio State University            E-mail: pavlicov at stat.ohio-state.edu
Columbus, OH 43210-1247              www.stat.ohio-state.edu/~pavlicov



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rjporter at surfbest.net  Thu Oct 24 23:19:08 2002
From: rjporter at surfbest.net (Bob Porter)
Date: Thu, 24 Oct 2002 17:19:08 -0400
Subject: [R] environmental variables list
Message-ID: <015601c27ba2$ff87bf40$d6f38141@hom>

Is there any place in which the possible or "usual " or "handy" contents
(variable settings) of .Renviron and .Rprofile are listed?  This is NOT a
question about how to use them or what they are for.  I just want to review
possible settings and cannot find a list anywhere,  I only find ref to
individual variables here and there.  Where should I look?
Thanks
Bob Porter, Tampa



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From apjaworski at mmm.com  Thu Oct 24 23:46:19 2002
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Thu, 24 Oct 2002 16:46:19 -0500
Subject: [R] nonlinear least square fit of a known function
Message-ID: <OF25CC3548.8B78D079-ON86256C5C.00779099@mmm.com>


Try

> library(nls)
> ?nls

Cheers,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+------------------------------>
|         |           dave qwertyu       |
|         |           <qwertyu2000us at yaho|
|         |           o.com>             |
|         |           Sent by:           |
|         |           owner-r-help at stat.m|
|         |           ath.ethz.ch        |
|         |                              |
|         |                              |
|         |           10/24/2002 14:05   |
|         |                              |
|---------+------------------------------>
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       r-help at stat.math.ethz.ch                                                                                     |
  |      cc:                                                                                                                    |
  |      Subject:  [R] nonlinear least square fit of a known function                                                           |
  >-----------------------------------------------------------------------------------------------------------------------------|




Dear R community,

I have data of x versus y and I know exactly what kind
of function to fit the data.  I just need to fit the
parameters with weighted nonlinear least square.

I am sure R can do this easily, but where do I start?

Thanks a lot in advance!!   Dave

__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From djense00 at yahoo.com  Fri Oct 25 01:06:09 2002
From: djense00 at yahoo.com (DAVID JENSEN)
Date: Thu, 24 Oct 2002 16:06:09 -0700 (PDT)
Subject: [R] source function help
Message-ID: <20021024230609.78202.qmail@web10407.mail.yahoo.com>

I am new to R and have probably a very simple
question...

I am using the "source" function to read an R source
file called, let's say, "first.r".  This file was
created in Notepad in Windows 2000.  This is a
simplistic example, but let's say in this file I have
the following commands:

x<-c(0,2,3,4,5,6)
y<-mean(x)
y


When I run this source function I assumed that I would
get a listing of the object "y" which is, of course,
the mean of the "x" vector.  It finds the source file
and seems to create all the objects but does not act
on the final command which simply asks it to list the
value of "y".  Why is this?  I assumed the source
function would simply run the "script" I had in this
source file, command by command and list the value of
"y".  I can later issue a separate command:

> y

and get the value for y, but I cannot figure out how
to make the script in the file give me this without
having to go in manually and ask for it.

Am I missing something?  Is there a way to do what I
want it to.  Forgive my naivete...I am a SAS
programmer taking baby steps in R!!!

Thanks,
Dave

__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From seth at reflectivity.com  Fri Oct 25 01:40:34 2002
From: seth at reflectivity.com (Seth Northrop)
Date: Thu, 24 Oct 2002 16:40:34 -0700 (PDT)
Subject: [R] plot slow?
Message-ID: <Pine.LNX.4.44.0210241636420.14491-100000@internal.reflectivity.com>


Hi,

I just installed R and am comparing it to other packages (such as Igor).  
So, you'll have to excuse me if this is a stupid question.  I run the
simple command:

plot(1:1000000)

And it seems SO slow!  Igor blasts through this.

My theory is that R is redrawing the screen for every point that's being 
graphed.  Is it possible to control how often R redraws a plot as its 
building it - or, is there some other trick here to speeding up plots with 
lots of points?

Thanks!
Seth


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Fri Oct 25 02:31:44 2002
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 24 Oct 2002 20:31:44 -0400
Subject: [R] nonlinear least square fit of a known function
In-Reply-To: <OF25CC3548.8B78D079-ON86256C5C.00779099@mmm.com>
Message-ID: <5.1.0.14.2.20021024202950.020a2ad0@mcmail.cis.mcmaster.ca>

Dear Andy and Dave,

The nls documentation indicates that weights aren't (yet) implemented.

Regards,
  John

At 04:46 PM 10/24/2002 -0500, apjaworski at mmm.com wrote:

>Try
>
> > library(nls)
> > ?nls
>
>Cheers,
>
>Andy
>
>__________________________________
>Andy Jaworski
>Engineering Systems Technology Center
>3M Center, 518-1-01
>St. Paul, MN 55144-1000
>-----
>
>
>Dear R community,
>
>I have data of x versus y and I know exactly what kind
>of function to fit the data.  I just need to fit the
>parameters with weighted nonlinear least square.
>
>I am sure R can do this easily, but where do I start?
>
>Thanks a lot in advance!!   Dave
>
>__________________________________________________
>

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From s195404 at student.uq.edu.au  Fri Oct 25 03:24:42 2002
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri, 25 Oct 2002 11:24:42 +1000 (EST)
Subject: [R] plot slow?
In-Reply-To: <Pine.LNX.4.44.0210241636420.14491-100000@internal.reflectivity.com>
References: <Pine.LNX.4.44.0210241636420.14491-100000@internal.reflectivity.com>
Message-ID: <1035509082.3db89d5af198e@my.uq.edu.au>

I tried the following commands with R1.6.0 on Win2K:

> x <- 1:1000000
> system.time(plot(x,x,pch="."))

The plot took about 28s on my PIII. This seems okay for 1000000 
points. By any chance are you an author of Igor :-)

Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting Seth Northrop <seth at reflectivity.com>:

> 
> Hi,
> 
> I just installed R and am comparing it to other packages (such
> as Igor).  
> So, you'll have to excuse me if this is a stupid question.  I
> run the
> simple command:
> 
> plot(1:1000000)
> 
> And it seems SO slow!  Igor blasts through this.
> 
> My theory is that R is redrawing the screen for every point
> that's being 
> graphed.  Is it possible to control how often R redraws a plot
> as its 
> building it - or, is there some other trick here to speeding
> up plots with 
> lots of points?
> 
> Thanks!
> Seth
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
.-.-.-.-.-.-
> r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._._._
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From drf5n at mug.sys.virginia.edu  Fri Oct 25 04:09:20 2002
From: drf5n at mug.sys.virginia.edu (David Forrest)
Date: Thu, 24 Oct 2002 22:09:20 -0400 (EDT)
Subject: [R] source function help
In-Reply-To: <20021024230609.78202.qmail@web10407.mail.yahoo.com>
Message-ID: <Pine.LNX.4.33.0210242200100.28668-100000@mug.sys.virginia.edu>

On Thu, 24 Oct 2002, DAVID JENSEN wrote:
...
>
> When I run this source function I assumed that I would
> get a listing of the object "y" which is, of course,
> the mean of the "x" vector.  It finds the source file
> and seems to create all the objects but does not act
> on the final command which simply asks it to list the
> value of "y".  Why is this?  I assumed the source
> function would simply run the "script" I had in this
> source file, command by command and list the value of
> "y".  I can later issue a separate command:

Try:     source('file', echo=TRUE)

or       print(y)    in your script.

> and get the value for y, but I cannot figure out how
> to make the script in the file give me this without
> having to go in manually and ask for it.
>
> Am I missing something?  Is there a way to do what I
> want it to.  Forgive my naivete...I am a SAS
> programmer taking baby steps in R!!!

I'm a naive SAS programmer fighting with DATA and TRANSPOSE today.

Dave
-- 
 Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
 drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jgentry at jimmy.harvard.edu  Fri Oct 25 04:18:21 2002
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu, 24 Oct 2002 22:18:21 -0400 (EDT)
Subject: [R] source function help
In-Reply-To: <20021024230609.78202.qmail@web10407.mail.yahoo.com>
Message-ID: <Pine.SOL.4.20.0210242217440.28008-100000@santiam.dfci.harvard.edu>


On Thu, 24 Oct 2002, DAVID JENSEN wrote:
> Am I missing something?  Is there a way to do what I
> want it to.  Forgive my naivete...I am a SAS

Try 'print(y)'

-J

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From edd at debian.org  Fri Oct 25 04:23:20 2002
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 24 Oct 2002 21:23:20 -0500
Subject: [R] plot slow?
In-Reply-To: <1035509082.3db89d5af198e@my.uq.edu.au>
References: <Pine.LNX.4.44.0210241636420.14491-100000@internal.reflectivity.com> <1035509082.3db89d5af198e@my.uq.edu.au>
Message-ID: <20021025022320.GA2951@sonny.eddelbuettel.com>

On Fri, Oct 25, 2002 at 11:24:42AM +1000, Andrew C. Ward wrote:
> I tried the following commands with R1.6.0 on Win2K:
> 
> > x <- 1:1000000
> > system.time(plot(x,x,pch="."))
> 
> The plot took about 28s on my PIII. This seems okay for 1000000 
> points. By any chance are you an author of Igor :-)

FWIW  2.96s on my Athlon running Linux is even better.

-- 
Good judgement comes from experience; experience comes from bad judgement. 
							    -- Fred Brooks
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From seth at reflectivity.com  Fri Oct 25 04:33:16 2002
From: seth at reflectivity.com (Seth Northrop)
Date: Thu, 24 Oct 2002 19:33:16 -0700 (PDT)
Subject: [R] plot slow?
In-Reply-To: <20021025022320.GA2951@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.44.0210241928030.21723-100000@internal.reflectivity.com>

> FWIW  2.96s on my Athlon running Linux is even better.
> 

Yes, I'm hitting about 6-7s on linux - but, Igor seems to be able to plot 
10-20x faster - largely I believe because they aren't doing nearly as many 
redraws of the window while it tries to build the graph.

So, is it not possible to toggle the refresh rate (how often R draws the 
graph as its plotting points?)  

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mj.manning at niwa.co.nz  Fri Oct 25 06:04:08 2002
From: mj.manning at niwa.co.nz (Michael J. Manning)
Date: Fri, 25 Oct 2002 17:04:08 +1300
Subject: [R] plot slow?
References: <Pine.LNX.4.44.0210241636420.14491-100000@internal.reflectivity.com> <1035509082.3db89d5af198e@my.uq.edu.au>
Message-ID: <3DB8C2B8.2020309@niwa.co.nz>

And ca. 28 seconds on my PIII box, also with R.1.6.0 and Win2K; 24 
seconds when I turned the CD player off...

MJM

Andrew C. Ward wrote:
> I tried the following commands with R1.6.0 on Win2K:
> 
> 
>>x <- 1:1000000
>>system.time(plot(x,x,pch="."))
> 
> 
> The plot took about 28s on my PIII.

Michael J. Manning
National Institute of Water and Atmospheric Research Ltd
PO Box 14901, Kilbirnie
Wellington, New Zealand
Tel 64 4 386 0581
Fax 64 4 386 0574

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rsadler at agric.uwa.edu.au  Fri Oct 25 08:10:12 2002
From: rsadler at agric.uwa.edu.au (rohan sadler)
Date: Fri, 25 Oct 2002 14:10:12 +0800
Subject: [R] re: problem installing library sm
Message-ID: <3DB8E044.5080700@agric.uwa.edu.au>

Hi All,

I am having trouble installing the sm package, and only the sm package. 
My box is RedHat 7.3 on a PIV. Readline 4.3-3 is installed (suited for 
RH 8, but same error under readline 4.2 for RH 7.3), but it seems to be 
looking for the readline library in the wrong directory. Will installing 
readline 4.1 do the trick? What else could be done?


Rohan Sadler

[root at rsadler R]# R CMD INSTALL sm_2.0-6.tar.gz
WARNING: ignoring environment value of R_HOME
* Installing *source* package 'sm' ...
** libs
g77 -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g -c routines.f -o 
routines.o
gcc -shared -L/usr/local/lib -o sm.so routines.o  -L/usr/local/lib 
-L/usr/lib/gcc-lib/i386-redhat-linux/2.96 
-L/usr/lib/gcc-lib/i386-redhat-linux/2.96/../../.. -lreadline -ldl 
-lncurses -lg2c -lm
/usr/bin/ld: cannot find -lreadline
collect2: ld returned 1 exit status
make: *** [sm.so] Error 1
ERROR: compilation failed for package 'sm'

[root at rsadler R]# locate readline
/usr/lib/python1.5/lib-dynload/readline.so
/usr/lib/python2.2/lib-dynload/readline.so
/usr/lib/python2.2/lib-dynload/xreadlinesmodule.so
/usr/lib/libreadline.so.4
/usr/lib/libreadline.so.4.2
/usr/lib/libguilereadline.so.0
/usr/lib/libguilereadline.a
/usr/lib/libguilereadline.la
/usr/lib/libguilereadline.so
/usr/lib/libguilereadline.so.0.0.0
/usr/lib/libreadline.so.3
/usr/lib/libreadline.so.3.0
/usr/lib/R/library/base/R-ex/readline.R
/usr/lib/R/library/base/help/readline
/usr/lib/R/library/base/html/readline.html
/usr/lib/libreadline.so.4.1
/usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.a
/usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.la
/usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.so
/usr/libexec/rep/0.15.1/i386-redhat-linux/readline.a
/usr/libexec/rep/0.15.1/i386-redhat-linux/readline.la
/usr/libexec/rep/0.15.1/i386-redhat-linux/readline.so
/usr/share/doc/vim-common-6.1/syntax/readline.vim
/usr/share/doc/python2-docs-2.2/lib/libreadline.tex
/usr/share/doc/python2-docs-2.2/lib/libxreadlines.tex
/usr/share/man/man3/readline.3.gz
/usr/share/info/readline.info.gz
/usr/share/vim/vim61/indent/readline.vim
/usr/share/vim/vim61/syntax/readline.vim
/usr/share/guile/1.3.4/ice-9/readline.scm
/usr/local/lib/R/library/base/help/readline
/usr/local/lib/R/library/base/html/readline.html
/usr/local/lib/R/library/base/latex/readline.tex
/usr/local/lib/R/library/base/R-ex/readline.R
/home/rsadler/downloads/R/R-1.5.1/src/library/base/man/readline.Rd
/home/rsadler/downloads/R/R-1.5.1/library/base/help/readline
/home/rsadler/downloads/R/R-1.5.1/library/base/html/readline.html
/home/rsadler/downloads/R/R-1.5.1/library/base/latex/readline.tex
/home/rsadler/downloads/R/R-1.5.1/library/base/R-ex/readline.R

-- 
Ecosystems Research Group (ERGO)
School of Plant Biology (Botany), Faculty of Natural & Agricultural Sciences,
The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009, Australia

Ph:  +61 8 9380 7914
Fax: +61 8 9380 7925
email: rsadler at agric.uwa.edu.au
ERGO's web site:<http://www.botany.uwa.edu.au/ergo>




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From adrian.trapletti at lmttrading.com  Fri Oct 25 09:46:21 2002
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Fri, 25 Oct 2002 09:46:21 +0200
Subject: [R] Combinatorial Optimisation
References: <200210250201.g9P214Ui023993@hypatia.math.ethz.ch>
Message-ID: <3DB8F6CC.8C3D4E9@lmttrading.com>

> Date: Thu, 24 Oct 2002 08:58:08 +0200 (CEST)
> From: Detlef Steuer <Detlef.Steuer at unibw-hamburg.de>
> Subject: RE: [R] Combinatorial Optimisation
>
> This thread missed me somehow.
>
> If not mentioned before:
> simulated annealing is implemented in optim().

The current implementation of simulated annealing in optim() has been designed for a continuos parameter space. The next candidate
point in the parameter space is generated from a Gaussian Markov kernel with scale proportional to the actual temperature. However,
it is quite simple to change this for a combinatorial optimization:

in the R source tree, see the file src/main/optim.c, function samin:

What you need to change are the four lines, that are responsible for generating a new candidate point:

for (i = 0; i < n; i++)
  dp[i] = scale * t * norm_rand();  /* random perturbation */
for (i = 0; i < n; i++)
  ptry[i] = p[i] + dp[i];  /* new candidate point */

You could, e.g., replace them by a call to an R function, which randomly selects a new candidate point of a finite set of points.
Hence, to quickly get SA for combinatorial optimization:

Copy and paste samin from optim.c
Change the four lines
Write an R wrapper for this new function

best
Adrian

PS: TO R-DEVEL: What about having this behaviour in optim (default as is, optional a function argument which selects a candidate
point)?

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Isabelle.ZABALZA-MEZGHANI at ifp.fr  Fri Oct 25 10:01:25 2002
From: Isabelle.ZABALZA-MEZGHANI at ifp.fr (ZABALZA Isabelle)
Date: Fri, 25 Oct 2002 10:01:25 +0200
Subject: [R] Problem when fitting a constant response
Message-ID: <3DB8FA55.BE531EBD@ifp.fr>

    Hello,

I would like to treat a very simple case : to fit a linear model with 5
parameters (including main terms, interactions and quadratic terms using
a central composite design with 27 runs) for a constant response (e.g
resp = 100.0). The fitting process works and return me a good intercept
value (the value of my constant) and some negligeable effects (around
e-15). But, I don't understand some results :
the t values (or the F stat) indicates some influent parameters
(although they are negligeable in comparison with the intercept) and the
R2 value is not equal to 1 (Multiple r2 = 0.72, and adj r2 = -0.187),
although the residuals are near zero. I know, it is a very special case
(regression is not necessary), but it is just to understand what is
happening.

Thank you in advance,

Isabelle Zabalza-Mezghani

--
Isabelle Zabalza-Mezghani          Tel : 01 47 52 61 99
Institut Franais du Ptrole       E-mail : isabelle.zabalza-mezghani at ifp.fr
1-4 Av. Bois Preau - Bat Lauriers
92852 Rueil Malmaison Cedex, France


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolfram at fischer-zim.ch  Fri Oct 25 10:02:39 2002
From: wolfram at fischer-zim.ch (Wolfram Fischer - Z/I/M)
Date: Fri, 25 Oct 2002 10:02:39 +0200
Subject: [R] merge: How to preserve the original order?
Message-ID: <20021025100239.A1548@s1x.zimnet.ch>

I tried:
    x.vals <- data.frame(
          id = c( 'A1', 'C2', 'B3' )
        , ref = c( 'Ref1', 'Ref2' ,'Ref1' )
        , val = c( 1.11, 2.22, 3.33 )
        )
    x.labels <- data.frame(
          ref = c( 'Ref1', 'Ref2' )
        , label = c( 'Label01', 'Label02' )
        )

    merge( x.vals, x.labels, by='ref', all.x = T, sort=F )

I received:
         ref  id  val   label
    1   Ref1  A1 1.11 Label01
    2   Ref1  B3 3.33 Label01
    3   Ref2  C2 2.22 Label02

Alltough 'sort=F' is set, the original order: id = A1, C2, B3 is
not preserved. - Is there a possibility to preserve the original
order (when there is no key field which can be ordered after merging).
(Perhaps 'merge' is not the right solution for this problem?)

Wolfram
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mrufino at cmima.csic.es  Fri Oct 25 12:41:37 2002
From: mrufino at cmima.csic.es (Marta Rufino)
Date: Fri, 25 Oct 2002 12:41:37 +0200
Subject: [R] functions
Message-ID: <3.0.1.32.20021025124137.00822770@cucafera.icm.csic.es>

Hello,

I am a newbie in R,
I just did my first function, which works!!! And I would like to know, if I
can create a directory in the library with my functions, in a way, which I
could call that like we call the packages ?
Can anyone help me?
Thanks in advance
Marta
    

><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>
`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.??

Marta Rufino

Centre Mediterrani d'Investigacions Marines i Ambientals
(CMIMA). CSIC
Passeig Maritim 37-49
08003  BARCELONA

Tfno:34 93 230 95 40
Tfax:34 93 230 95 55

><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>
`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.??


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From carlos.ortega at minorplanet.com  Fri Oct 25 12:56:05 2002
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Fri, 25 Oct 2002 12:56:05 +0200
Subject: [R] re: problem installing library sm
In-Reply-To: <3DB8E044.5080700@agric.uwa.edu.au>
Message-ID: <LMEKLMMLPDKOJNOOEELEGEELDMAA.carlos.ortega@minorplanet.com>

Hi All,

I had the same compilation error when installing "randomForest" on a Linux
box with Mandrake8.2 and Mandrake9.0 and with R-1.6.0.

Carlos.

-----Mensaje original-----
De: owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch]En nombre de rohan sadler
Enviado el: viernes, 25 de octubre de 2002 8:10
Para: R Help
Asunto: [R] re: problem installing library sm


Hi All,

I am having trouble installing the sm package, and only the sm package.
My box is RedHat 7.3 on a PIV. Readline 4.3-3 is installed (suited for
RH 8, but same error under readline 4.2 for RH 7.3), but it seems to be
looking for the readline library in the wrong directory. Will installing
readline 4.1 do the trick? What else could be done?


Rohan Sadler

[root at rsadler R]# R CMD INSTALL sm_2.0-6.tar.gz
WARNING: ignoring environment value of R_HOME
* Installing *source* package 'sm' ...
** libs
g77 -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g -c routines.f -o
routines.o
gcc -shared -L/usr/local/lib -o sm.so routines.o  -L/usr/local/lib
-L/usr/lib/gcc-lib/i386-redhat-linux/2.96
-L/usr/lib/gcc-lib/i386-redhat-linux/2.96/../../.. -lreadline -ldl
-lncurses -lg2c -lm
/usr/bin/ld: cannot find -lreadline
collect2: ld returned 1 exit status
make: *** [sm.so] Error 1
ERROR: compilation failed for package 'sm'

[root at rsadler R]# locate readline
/usr/lib/python1.5/lib-dynload/readline.so
/usr/lib/python2.2/lib-dynload/readline.so
/usr/lib/python2.2/lib-dynload/xreadlinesmodule.so
/usr/lib/libreadline.so.4
/usr/lib/libreadline.so.4.2
/usr/lib/libguilereadline.so.0
/usr/lib/libguilereadline.a
/usr/lib/libguilereadline.la
/usr/lib/libguilereadline.so
/usr/lib/libguilereadline.so.0.0.0
/usr/lib/libreadline.so.3
/usr/lib/libreadline.so.3.0
/usr/lib/R/library/base/R-ex/readline.R
/usr/lib/R/library/base/help/readline
/usr/lib/R/library/base/html/readline.html
/usr/lib/libreadline.so.4.1
/usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.a
/usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.la
/usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.so
/usr/libexec/rep/0.15.1/i386-redhat-linux/readline.a
/usr/libexec/rep/0.15.1/i386-redhat-linux/readline.la
/usr/libexec/rep/0.15.1/i386-redhat-linux/readline.so
/usr/share/doc/vim-common-6.1/syntax/readline.vim
/usr/share/doc/python2-docs-2.2/lib/libreadline.tex
/usr/share/doc/python2-docs-2.2/lib/libxreadlines.tex
/usr/share/man/man3/readline.3.gz
/usr/share/info/readline.info.gz
/usr/share/vim/vim61/indent/readline.vim
/usr/share/vim/vim61/syntax/readline.vim
/usr/share/guile/1.3.4/ice-9/readline.scm
/usr/local/lib/R/library/base/help/readline
/usr/local/lib/R/library/base/html/readline.html
/usr/local/lib/R/library/base/latex/readline.tex
/usr/local/lib/R/library/base/R-ex/readline.R
/home/rsadler/downloads/R/R-1.5.1/src/library/base/man/readline.Rd
/home/rsadler/downloads/R/R-1.5.1/library/base/help/readline
/home/rsadler/downloads/R/R-1.5.1/library/base/html/readline.html
/home/rsadler/downloads/R/R-1.5.1/library/base/latex/readline.tex
/home/rsadler/downloads/R/R-1.5.1/library/base/R-ex/readline.R

--
Ecosystems Research Group (ERGO)
School of Plant Biology (Botany), Faculty of Natural & Agricultural
Sciences,
The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009,
Australia

Ph:  +61 8 9380 7914
Fax: +61 8 9380 7925
email: rsadler at agric.uwa.edu.au
ERGO's web site:<http://www.botany.uwa.edu.au/ergo>




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


_____
The information in this email is confidential and it may not be
disclosed or used by anyone other than the addressee. If you are not the
intended recipient, any disclosure, copying, distribution or any action taken or
omitted is prohibited and may be unlawful.
Minorplanet cannot accept responsibility for the accuracy or completeness of
this email as it has been transmitted over a public network. If you suspect
that the email may have been amended, please call the sender.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Bayesianbay at aol.com  Fri Oct 25 13:16:55 2002
From: Bayesianbay at aol.com (Bayesianbay@aol.com)
Date: Fri, 25 Oct 2002 07:16:55 EDT
Subject: [R] Quantil-quantile plot help
Message-ID: <54.d76655.2aea8227@aol.com>

Dear list

I am using the qq.plot command to create quantile-quantile plots. The plot 
should display a 45 degree reference line upon which the points of the graph 
should fall if the two distributions being examined are roughly equal.

If I try:
x<-rchisq(100, df=6)
qq.plot(x, dist="chisq", df=6)

Then I get a quantile plot which has an intercept of roughly 1 when the line 
should be going through (0,0)?

Could someone explain why this is happening on this plot and how I can get 
what I need?

Many thanks
Laura
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ted.Harding at nessie.mcc.ac.uk  Fri Oct 25 13:55:53 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 25 Oct 2002 12:55:53 +0100 (BST)
Subject: [R] Problem when fitting a constant response
In-Reply-To: <3DB8FA55.BE531EBD@ifp.fr>
Message-ID: <XFMail.021025125553.Ted.Harding@nessie.mcc.ac.uk>

On 25-Oct-02 ZABALZA Isabelle wrote:
> I would like to treat a very simple case : to fit a linear model
> with 5 parameters (including main terms, interactions and quadratic
> terms using a central composite design with 27 runs) for a constant
> response (e.g resp = 100.0). The fitting process works and return
> me a good intercept value (the value of my constant) and some
> negligeable effects (around e-15). But, I don't understand some
> results :
> the t values (or the F stat) indicates some influent parameters
> (although they are negligeable in comparison with the intercept)
> and the R2 value is not equal to 1 (Multiple r2 = 0.72, and
> adj r2 = -0.187), although the residuals are near zero. I know,
> it is a very special case (regression is not necessary), but it is
> just to understand what is happening.

Probably what is happening is that the fitted values are computed
from the fitted constants, so the results are not _exactly_ equal
to the constant value you put in to start with (owing to rounding
or truncation errors in the machine computation). The intercept
would be slightly different from the constant as stored internally,
but this would not be visible in its displayed value (unless you
displayed it to say 20 significant figures). However, the effects,
which should be exact zeros, are showing up as very small numbers,
which is the clue to what is going on.

Consequently, the fitted values differ very slightly from the "data",
so there some very small sums of squares both for residuals and for
regression effects. Your t and F statistics are ratios of these
very small numbers, and may well come out looking like large
numbers (strictly speaking, you should be dividing zero by zero
and getting a "NaN" result).

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 25-Oct-02                                       Time: 12:55:53
------------------------------ XFMail ------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 25 14:15:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 25 Oct 2002 13:15:03 +0100 (BST)
Subject: [R] merge: How to preserve the original order?
In-Reply-To: <20021025100239.A1548@s1x.zimnet.ch>
Message-ID: <Pine.LNX.4.31.0210251305290.10820-100000@gannet.stats>

You did get the original order as described in help(merge).  You can't
have the original order for x *and* the original order for y, and it is
clearly documented that you get that for y.

Try

merge( x.labels, x.vals, by='ref', sort=FALSE )

after reading the help page.  (Why did you specify all.x=T for
this example?)


On Fri, 25 Oct 2002, Wolfram Fischer - Z/I/M wrote:

> I tried:
>     x.vals <- data.frame(
>           id = c( 'A1', 'C2', 'B3' )
>         , ref = c( 'Ref1', 'Ref2' ,'Ref1' )
>         , val = c( 1.11, 2.22, 3.33 )
>         )
>     x.labels <- data.frame(
>           ref = c( 'Ref1', 'Ref2' )
>         , label = c( 'Label01', 'Label02' )
>         )
>
>     merge( x.vals, x.labels, by='ref', all.x = T, sort=F )
>
> I received:
>          ref  id  val   label
>     1   Ref1  A1 1.11 Label01
>     2   Ref1  B3 3.33 Label01
>     3   Ref2  C2 2.22 Label02
>
> Alltough 'sort=F' is set, the original order: id = A1, C2, B3 is
> not preserved. - Is there a possibility to preserve the original
> order (when there is no key field which can be ordered after merging).
> (Perhaps 'merge' is not the right solution for this problem?)

If you have an ordered id field (who would have guessed in this example
that those were ordered?) you can always sort on it. Here's another
solution.

x.vals$order <- seq(len=nrow(x.vals))
m <- merge( x.vals, x.labels, by='ref', all.x = T, sort=F )
m[sort.list(m$order), -4]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Fri Oct 25 14:37:56 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 25 Oct 2002 08:37:56 -0400
Subject: [R] [., multiple inheritance, and R 1.6
Message-ID: <20021025083756.49287f47.fharrell@virginia.edu>

Matt Nelson <MNelson at sequenom.com> reported a problem using the Hmisc library that did not occur with versions of R before 1.6.  I am running

platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.0
year     2002
month    10
day      01
language R

> library(Hmisc)
> g <- factor(sample(c('a','b'),100,TRUE))
> label(g) <- 'label for g'
> class(g)
[1] "labelled" "factor"
> d <- data.frame(g,y)
> d[d$g=='a',]
1

Error in NextMethod("[") : ..1 used in an incorrect context, no ... to look in
> traceback()
7: NextMethod("[")
6: "[.factor"(xj, i)
5: NextMethod("[")
4: "[.labelled"(xj, i)
3: xj[i]
2: "[.data.frame"(d, d$g == "a", )   # in package:base
1: d[d$g == "a", ]

The error occurs in [.labelled before [.factor (the one in Hmisc that overrides the builtin [.factor)) is invoked.  [.labelled is defined as

function(x, ...) {
  atr <- attributes(x)
  cat(1)
  x <- NextMethod("[")
  cat(2)
  attr(x, "label") <- atr$label
  if(length(atr$units)) attr(x,'units') <- atr$units
  if(!inherits(x,'labelled'))
    attr(x,'class') <- c("labelled", attr(x,'class'))
  x
}

One confusing point is that the cat(2) is not executed although traceback() indicates that it was.  So the problem may instead be in [.factor.  Before I pursue this further, does anyone know of a change in 1.6 that would cause problems with [. and multiple inheritance?  The problem does not occur when subsetting the vector (g[g=='a']), so [.data.frame is also involved:

[.factor in Hmisc is defined as

function(x, ..., drop=TRUE) {
  atx <- attributes(x)
  nam <- atx$names
  atx$levels <- atx$names <- NULL
  y <- as.integer(x)[...]
  ln <- length(nam)
  nam <- if(ln) nam[...] else NULL
  opt <- .Options$drop.factor.levels
  if(!length(opt)) opt <- .Options$drop.unused.levels  # 18Mar01
  if(drop && (!missing(drop) || (length(opt)==0 || opt))) {
        oldClass(y) <- NULL
        j <- sort(unique(y))
        y[] <- match(y,j)
        levels(y) <- levels(x)[j]
  } else if(length(y)) levels(y) <- levels(x) ##only needed for length 0 subscripts
  attributes(y) <- c(attributes(y), atx, if(ln)list(names=nam))
  y
}

Thanks for any help,

Frank

P.S.  As always, if an option existed to carry along attributes such as 'label', 'units', 'comment', no additional [. functions such as [.labelled would need to be defined by users. 
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From SAULEAUEA at ch-mulhouse.fr  Fri Oct 25 14:46:53 2002
From: SAULEAUEA at ch-mulhouse.fr (=?iso-8859-1?Q?SAULEAU_Erik-Andr=E9?=)
Date: Fri, 25 Oct 2002 14:46:53 +0200
Subject: [R] Age-period-cohort model
Message-ID: <1B849FE29A3ED21198A40008C72853B301C4FC28@MESSAGERIE>

Dear R-list,

I think it's really a newbie question but ...

I try to model age-period-cohort models with polynoms in each effect. I have
for each level of age and period some cases -k- and persons-years -py-.
Models are A_xP_y:
log(k_age,period/py_age,period)=f(polynom(x),age)+f(polynom(y),period). For
exemple I try to adjust an A2P3 :
log(k/py)=a1.age+a2.age*age+p1.period+p2.period*period+p3.period*period*peri
od.  I define factor(effect). My command is:

glm(k~-1+a+a2+p+p2+p3+offset(log(py)), family=poisson).

But I obtain only estimation for a and p and "NA" for a2, p2, p3.
What is the problem?

Thanks for advance.

============================================
Erik-Andr? SAULEAU

SEAIM
H?pital du Hasenrain
BP 1070
87, Avenue de Altkirch
68051 MULHOUSE C?dex
Tel: 03-89-64-79-95
M?l: sauleauea at ch-mulhouse.fr
============================================




************************************************************************************
Afin d'?viter toute propagation de virus informatique, et en compl?ment des dispositifs en place, ce message (et ses pi?ces jointes s'il y en a) a ?t? automatiquement analys? par un antivirus de messagerie. 
***********************************************************************************


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jzhang at jimmy.harvard.edu  Fri Oct 25 15:11:55 2002
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Fri, 25 Oct 2002 09:11:55 -0400 (EDT)
Subject: [R] functions
Message-ID: <200210251311.JAA16513@blaise.dfci.harvard.edu>


>X-Sender: mrufino at cucafera.icm.csic.es
>Date: Fri, 25 Oct 2002 12:41:37 +0200
>To: R-help at stat.math.ethz.ch
>From: Marta Rufino <mrufino at cmima.csic.es>
>Subject: [R] functions
>Mime-Version: 1.0
>Content-Transfer-Encoding: 8bit
>X-MIME-Autoconverted: from quoted-printable to 8bit by hypatia.math.ethz.ch id 
g9PATjxA021844
>
>Hello,
>
>I am a newbie in R,
>I just did my first function, which works!!! And I would like to know, if I
>can create a directory in the library with my functions, in a way, which I
>could call that like we call the packages ?
>Can anyone help me?

The section Writing R Extensions in An Introduction to R has everything you need 
to know.


>Thanks in advance
>Marta
>    
>
>><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>
>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.??
>
>Marta Rufino
>
>Centre Mediterrani d'Investigacions Marines i Ambientals
>(CMIMA). CSIC
>Passeig Maritim 37-49
>08003  BARCELONA
>
>Tfno:34 93 230 95 40
>Tfax:34 93 230 95 55
>
>><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>
>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.??
>
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Fri Oct 25 15:42:58 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 25 Oct 2002 08:42:58 -0500
Subject: [R] nonlinear least square fit of a known function
In-Reply-To: <5.1.0.14.2.20021024202950.020a2ad0@mcmail.cis.mcmaster.ca>
References: <5.1.0.14.2.20021024202950.020a2ad0@mcmail.cis.mcmaster.ca>
Message-ID: <6rfzuuzlb1.fsf@bates4.stat.wisc.edu>

John Fox <jfox at mcmaster.ca> writes:

> Dear Andy and Dave,
> 
> The nls documentation indicates that weights aren't (yet) implemented.
> 
> Regards,
>   John

But there is an example in the documentation, contributed by Martin
Maechler, showing how to do weighted nonlinear least squares.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From KruzanEttie at alloymail.com  Fri Oct 25 16:07:14 2002
From: KruzanEttie at alloymail.com (KruzanEttie@alloymail.com)
Date: Fri, 25 Oct 2002 16:07:14 +0200 (MEST)
Subject: No subject
Message-ID: <200210251407.g9PE7ExA011678@hypatia.math.ethz.ch>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Oct 25 16:22:11 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 25 Oct 2002 16:22:11 +0200
Subject: [R] nonlinear least square fit of a known function
In-Reply-To: <6rfzuuzlb1.fsf@bates4.stat.wisc.edu>
References: <5.1.0.14.2.20021024202950.020a2ad0@mcmail.cis.mcmaster.ca>
	<6rfzuuzlb1.fsf@bates4.stat.wisc.edu>
Message-ID: <x2znt2mwdo.fsf@biostat.ku.dk>

Douglas Bates <bates at stat.wisc.edu> writes:

> John Fox <jfox at mcmaster.ca> writes:
> 
> > Dear Andy and Dave,
> > 
> > The nls documentation indicates that weights aren't (yet) implemented.
> > 
> > Regards,
> >   John
> 
> But there is an example in the documentation, contributed by Martin
> Maechler, showing how to do weighted nonlinear least squares.

And of course multiplying both sides of a model formula with the
square root of the weights is not going to make the model any more nor
less nonlinear. (But predicting and such requires a little care).
Actually Martin's example is slightly different from what weights=w
would do since his weights depend on the predictor.

Still, a weights argument would be nice. Could we have one for 1.7.0?
Any inklings about how hard it would be to implement?

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolfram at fischer-zim.ch  Fri Oct 25 16:53:15 2002
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Fri, 25 Oct 2002 16:53:15 +0200
Subject: [R] merge: How to preserve the original order?
In-Reply-To: <Pine.LNX.4.31.0210251305290.10820-100000@gannet.stats>
Message-ID: <20021025165315.A2982@s1x.zimnet.ch>

Thank you, Brian and Sundar, for your help!

Indeed, I should have found the first solution myself
by studying thoroughly the help pages.

If there is not a correspondent x.labels$ref for each x.vals$ref
then all.x=T (resp. all.y=T) is necessary. 
But in this case, changing the first and second argument of merge()
not works as expected. If I expand x.vals with 'Ref3' as:

    x.vals <- data.frame(
          id = c( 'A1', 'C2', 'B3', 'D4' )
        , ref = c( 'Ref1', 'Ref2' , 'Ref3','Ref1' )
        , val = c( 1.11, 2.22, 3.33, 4.44 )
        )

And I try:
    merge( x.labels, x.vals, by='ref', all.y = T, sort=F )

I get:
        ref   label id  val
   1   Ref1 Label01 A1 1.11
   2   Ref2 Label02 C2 2.22
   3   Ref1 Label01 D4 4.44
   4   Ref3    <NA> B3 3.33

('Ref3' is now on line 4, but it should be on line 3 as in x.vals.)

This seems to be an exception of what is described on the help page.

Your interesting alternative solution was helpful for this case.
Thanks!

Wolfram


--- In reply to: ---
>Date:    25.10.02 13:15 (+0100)
>From:    ripley at stats.ox.ac.uk
>Subject: Re: [R] merge: How to preserve the original order?
>
> You did get the original order as described in help(merge).  You can't
> have the original order for x *and* the original order for y, and it is
> clearly documented that you get that for y.
> 
> Try
> 
> merge( x.labels, x.vals, by='ref', sort=FALSE )
> 
> after reading the help page.  (Why did you specify all.x=T for
> this example?)
> 
> 
> On Fri, 25 Oct 2002, Wolfram Fischer - Z/I/M wrote:
> 
> > I tried:
> >     x.vals <- data.frame(
> >           id = c( 'A1', 'C2', 'B3' )
> >         , ref = c( 'Ref1', 'Ref2' ,'Ref1' )
> >         , val = c( 1.11, 2.22, 3.33 )
> >         )
> >     x.labels <- data.frame(
> >           ref = c( 'Ref1', 'Ref2' )
> >         , label = c( 'Label01', 'Label02' )
> >         )
> >
> >     merge( x.vals, x.labels, by='ref', all.x = T, sort=F )
> >
> > I received:
> >          ref  id  val   label
> >     1   Ref1  A1 1.11 Label01
> >     2   Ref1  B3 3.33 Label01
> >     3   Ref2  C2 2.22 Label02
> >
> > Alltough 'sort=F' is set, the original order: id = A1, C2, B3 is
> > not preserved. - Is there a possibility to preserve the original
> > order (when there is no key field which can be ordered after merging).
> > (Perhaps 'merge' is not the right solution for this problem?)
> 
> If you have an ordered id field (who would have guessed in this example
> that those were ordered?) you can always sort on it. Here's another
> solution.
> 
> x.vals$order <- seq(len=nrow(x.vals))
> m <- merge( x.vals, x.labels, by='ref', all.x = T, sort=F )
> m[sort.list(m$order), -4]
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Fri Oct 25 16:59:44 2002
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 25 Oct 2002 10:59:44 -0400
Subject: [R] Quantil-quantile plot help
In-Reply-To: <54.d76655.2aea8227@aol.com>
Message-ID: <5.1.0.14.2.20021025105357.021036f8@mcmail.cis.mcmaster.ca>

Dear Laura,

At 07:16 AM 10/25/2002 -0400, Bayesianbay at aol.com wrote:

>I am using the qq.plot command to create quantile-quantile plots. The plot
>should display a 45 degree reference line upon which the points of the graph
>should fall if the two distributions being examined are roughly equal.
>
>If I try:
>x<-rchisq(100, df=6)
>qq.plot(x, dist="chisq", df=6)
>
>Then I get a quantile plot which has an intercept of roughly 1 when the line
>should be going through (0,0)?
>
>Could someone explain why this is happening on this plot and how I can get
>what I need?

I guess that you're using qq.plot in the car package. As the help file 
explains, the line is fit by default through the quartiles of the two 
distributions, and there is an option to fit by robust regression. The 
general idea is that the data could come from the reference distribution 
but possibly with a different location and scale, and hence the line need 
not have an intercept of 0 and a slope of 1.

You could add the 45-degree line with abline(0,1), but there is no way at 
present of suppressing the line that qq.plot draws (short of rewriting 
qq.plot.default). I'll add an option to suppress the line when I next 
update the package.

Regards,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Oct 25 17:03:37 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 25 Oct 2002 16:03:37 +0100 (BST)
Subject: [R] re: problem installing library sm
In-Reply-To: <LMEKLMMLPDKOJNOOEELEGEELDMAA.carlos.ortega@minorplanet.com>
Message-ID: <Pine.LNX.4.31.0210251600480.6289-100000@gannet.stats>

This will happen on any package using Fortran if you don't have the
libraries installed properly.  I presum each of you worked from RPMs,
or R would not have been built.

I suggest you edit R_HOME/etc/Makeconf, which will be something like

FLIBS =  -L/usr/local/lib -L/usr/local/lib/gcc-lib/i686-pc-linux-gnu/3.2
-L/usr/local/lib/gcc-lib/i686-pc-linux-gnu/3.2/../../..
-lreadline -ldl -lncurses -lfrtbegin -lg2c -lm -lgcc_s

and remove -lreadline -ldl -lncurses.  I don't see how they could be
needed for a Fortran-based package.

On Fri, 25 Oct 2002, Carlos Ortega wrote:

> Hi All,
>
> I had the same compilation error when installing "randomForest" on a Linux
> box with Mandrake8.2 and Mandrake9.0 and with R-1.6.0.
>
> Carlos.
>
> -----Mensaje original-----
> De: owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch]En nombre de rohan sadler
> Enviado el: viernes, 25 de octubre de 2002 8:10
> Para: R Help
> Asunto: [R] re: problem installing library sm
>
>
> Hi All,
>
> I am having trouble installing the sm package, and only the sm package.
> My box is RedHat 7.3 on a PIV. Readline 4.3-3 is installed (suited for
> RH 8, but same error under readline 4.2 for RH 7.3), but it seems to be
> looking for the readline library in the wrong directory. Will installing
> readline 4.1 do the trick? What else could be done?
>
>
> Rohan Sadler
>
> [root at rsadler R]# R CMD INSTALL sm_2.0-6.tar.gz
> WARNING: ignoring environment value of R_HOME

Heed the warning, and unset it!

> * Installing *source* package 'sm' ...
> ** libs
> g77 -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g -c routines.f -o
> routines.o
> gcc -shared -L/usr/local/lib -o sm.so routines.o  -L/usr/local/lib
> -L/usr/lib/gcc-lib/i386-redhat-linux/2.96
> -L/usr/lib/gcc-lib/i386-redhat-linux/2.96/../../.. -lreadline -ldl
> -lncurses -lg2c -lm
> /usr/bin/ld: cannot find -lreadline
> collect2: ld returned 1 exit status
> make: *** [sm.so] Error 1
> ERROR: compilation failed for package 'sm'
>
> [root at rsadler R]# locate readline
> /usr/lib/python1.5/lib-dynload/readline.so
> /usr/lib/python2.2/lib-dynload/readline.so
> /usr/lib/python2.2/lib-dynload/xreadlinesmodule.so
> /usr/lib/libreadline.so.4
> /usr/lib/libreadline.so.4.2
> /usr/lib/libguilereadline.so.0
> /usr/lib/libguilereadline.a
> /usr/lib/libguilereadline.la
> /usr/lib/libguilereadline.so
> /usr/lib/libguilereadline.so.0.0.0
> /usr/lib/libreadline.so.3
> /usr/lib/libreadline.so.3.0
> /usr/lib/R/library/base/R-ex/readline.R
> /usr/lib/R/library/base/help/readline
> /usr/lib/R/library/base/html/readline.html
> /usr/lib/libreadline.so.4.1
> /usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.a
> /usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.la
> /usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.so
> /usr/libexec/rep/0.15.1/i386-redhat-linux/readline.a
> /usr/libexec/rep/0.15.1/i386-redhat-linux/readline.la
> /usr/libexec/rep/0.15.1/i386-redhat-linux/readline.so
> /usr/share/doc/vim-common-6.1/syntax/readline.vim
> /usr/share/doc/python2-docs-2.2/lib/libreadline.tex
> /usr/share/doc/python2-docs-2.2/lib/libxreadlines.tex
> /usr/share/man/man3/readline.3.gz
> /usr/share/info/readline.info.gz
> /usr/share/vim/vim61/indent/readline.vim
> /usr/share/vim/vim61/syntax/readline.vim
> /usr/share/guile/1.3.4/ice-9/readline.scm
> /usr/local/lib/R/library/base/help/readline
> /usr/local/lib/R/library/base/html/readline.html
> /usr/local/lib/R/library/base/latex/readline.tex
> /usr/local/lib/R/library/base/R-ex/readline.R
> /home/rsadler/downloads/R/R-1.5.1/src/library/base/man/readline.Rd
> /home/rsadler/downloads/R/R-1.5.1/library/base/help/readline
> /home/rsadler/downloads/R/R-1.5.1/library/base/html/readline.html
> /home/rsadler/downloads/R/R-1.5.1/library/base/latex/readline.tex
> /home/rsadler/downloads/R/R-1.5.1/library/base/R-ex/readline.R
>
> --
> Ecosystems Research Group (ERGO)
> School of Plant Biology (Botany), Faculty of Natural & Agricultural
> Sciences,
> The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009,
> Australia
>
> Ph:  +61 8 9380 7914
> Fax: +61 8 9380 7925
> email: rsadler at agric.uwa.edu.au
> ERGO's web site:<http://www.botany.uwa.edu.au/ergo>
>
>
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
>
>
> _____
> The information in this email is confidential and it may not be
> disclosed or used by anyone other than the addressee. If you are not the
> intended recipient, any disclosure, copying, distribution or any action taken or
> omitted is prohibited and may be unlawful.
> Minorplanet cannot accept responsibility for the accuracy or completeness of
> this email as it has been transmitted over a public network. If you suspect
> that the email may have been amended, please call the sender.
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Fri Oct 25 17:21:09 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri, 25 Oct 2002 08:21:09 -0700 (PDT)
Subject: [R] re: problem installing library sm
In-Reply-To: <3DB8E044.5080700@agric.uwa.edu.au>
Message-ID: <Pine.GSO.4.10.10210250820130.4568-100000@quetelet.stat.ucla.edu>

It seems you don't have the readline-devel package installed.  I think you
need this to compile R packages.  However, I don't see why only the 'sm'
package would fail....

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Fri, 25 Oct 2002, rohan sadler wrote:

> Hi All,
> 
> I am having trouble installing the sm package, and only the sm package. 
> My box is RedHat 7.3 on a PIV. Readline 4.3-3 is installed (suited for 
> RH 8, but same error under readline 4.2 for RH 7.3), but it seems to be 
> looking for the readline library in the wrong directory. Will installing 
> readline 4.1 do the trick? What else could be done?
> 
> 
> Rohan Sadler
> 
> [root at rsadler R]# R CMD INSTALL sm_2.0-6.tar.gz
> WARNING: ignoring environment value of R_HOME
> * Installing *source* package 'sm' ...
> ** libs
> g77 -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g -c routines.f -o 
> routines.o
> gcc -shared -L/usr/local/lib -o sm.so routines.o  -L/usr/local/lib 
> -L/usr/lib/gcc-lib/i386-redhat-linux/2.96 
> -L/usr/lib/gcc-lib/i386-redhat-linux/2.96/../../.. -lreadline -ldl 
> -lncurses -lg2c -lm
> /usr/bin/ld: cannot find -lreadline
> collect2: ld returned 1 exit status
> make: *** [sm.so] Error 1
> ERROR: compilation failed for package 'sm'
> 
> [root at rsadler R]# locate readline
> /usr/lib/python1.5/lib-dynload/readline.so
> /usr/lib/python2.2/lib-dynload/readline.so
> /usr/lib/python2.2/lib-dynload/xreadlinesmodule.so
> /usr/lib/libreadline.so.4
> /usr/lib/libreadline.so.4.2
> /usr/lib/libguilereadline.so.0
> /usr/lib/libguilereadline.a
> /usr/lib/libguilereadline.la
> /usr/lib/libguilereadline.so
> /usr/lib/libguilereadline.so.0.0.0
> /usr/lib/libreadline.so.3
> /usr/lib/libreadline.so.3.0
> /usr/lib/R/library/base/R-ex/readline.R
> /usr/lib/R/library/base/help/readline
> /usr/lib/R/library/base/html/readline.html
> /usr/lib/libreadline.so.4.1
> /usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.a
> /usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.la
> /usr/libexec/rep/0.15.1/i386-redhat-linux/rep/io/readline.so
> /usr/libexec/rep/0.15.1/i386-redhat-linux/readline.a
> /usr/libexec/rep/0.15.1/i386-redhat-linux/readline.la
> /usr/libexec/rep/0.15.1/i386-redhat-linux/readline.so
> /usr/share/doc/vim-common-6.1/syntax/readline.vim
> /usr/share/doc/python2-docs-2.2/lib/libreadline.tex
> /usr/share/doc/python2-docs-2.2/lib/libxreadlines.tex
> /usr/share/man/man3/readline.3.gz
> /usr/share/info/readline.info.gz
> /usr/share/vim/vim61/indent/readline.vim
> /usr/share/vim/vim61/syntax/readline.vim
> /usr/share/guile/1.3.4/ice-9/readline.scm
> /usr/local/lib/R/library/base/help/readline
> /usr/local/lib/R/library/base/html/readline.html
> /usr/local/lib/R/library/base/latex/readline.tex
> /usr/local/lib/R/library/base/R-ex/readline.R
> /home/rsadler/downloads/R/R-1.5.1/src/library/base/man/readline.Rd
> /home/rsadler/downloads/R/R-1.5.1/library/base/help/readline
> /home/rsadler/downloads/R/R-1.5.1/library/base/html/readline.html
> /home/rsadler/downloads/R/R-1.5.1/library/base/latex/readline.tex
> /home/rsadler/downloads/R/R-1.5.1/library/base/R-ex/readline.R
> 
> -- 
> Ecosystems Research Group (ERGO)
> School of Plant Biology (Botany), Faculty of Natural & Agricultural Sciences,
> The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009, Australia
> 
> Ph:  +61 8 9380 7914
> Fax: +61 8 9380 7925
> email: rsadler at agric.uwa.edu.au
> ERGO's web site:<http://www.botany.uwa.edu.au/ergo>
> 
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Oct 25 17:44:30 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 25 Oct 2002 08:44:30 -0700 (PDT)
Subject: [R] plot slow?
In-Reply-To: <Pine.LNX.4.44.0210241636420.14491-100000@internal.reflectivity.com>
Message-ID: <Pine.A41.4.44.0210250837280.139148-100000@homer35.u.washington.edu>

On Thu, 24 Oct 2002, Seth Northrop wrote:

>
> Hi,
>
> I just installed R and am comparing it to other packages (such as Igor).
> So, you'll have to excuse me if this is a stupid question.  I run the
> simple command:
>
> plot(1:1000000)
>
> And it seems SO slow!  Igor blasts through this.

It is fairly slow, but as my screen only has about a million pixels it's
unusual that I want to plot a million points on it.  It's even slower (of
course)  over an X-Windows link.  Part of the problem is the need for a
portable interface to the graphics driver.

When it's really painfully slow is drawing a finely detailed image plot.

> My theory is that R is redrawing the screen for every point that's being
> graphed.  Is it possible to control how often R redraws a plot as its
> building it - or, is there some other trick here to speeding up plots with
> lots of points?

Your theory is wrong.

There is probably room for optimisation in the graphics code, but it
isn't a terribly high priority.  The main place where improvement is
planned is in the redrawing of the screen when the graphics window is
uncovered.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From joshi at engr.orst.edu  Fri Oct 25 21:01:50 2002
From: joshi at engr.orst.edu (Saket Joshi)
Date: Fri, 25 Oct 2002 12:01:50 -0700 (PDT)
Subject: [R] R v/s S-plus
Message-ID: <Pine.GSO.4.44.0210251200090.19377-100000@flop.ENGR.ORST.EDU>

Hi all,

I have Splus and R both on my unix machine. I intend to keep only one of
them. R looks to be a better choice. But I want to confirm. Is there any
function or group of functions in Splus that are absent in R?
Thanks,
Saket.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From JDeke at mathematica-mpr.com  Fri Oct 25 22:08:40 2002
From: JDeke at mathematica-mpr.com (John Deke)
Date: Fri, 25 Oct 2002 16:08:40 -0400
Subject: [R] R v/s S-plus
Message-ID: <897E2332A97AD311AEBB00508B116D540765C039@mpr1>

This is probably a much more narrow answer than what you wanted, but I
noticed the other day that Splus has a function called qdunnett() that R
lacks (this has to do with multiple comparisons, I believe). Does anyone
know if there's an R equivalent to this SPlus function? 

-----Original Message-----
From: owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch]On Behalf Of Saket Joshi
Sent: Friday, October 25, 2002 3:02 PM
To: r-help at stat.math.ethz.ch
Subject: [R] R v/s S-plus


Hi all,

I have Splus and R both on my unix machine. I intend to keep only one of
them. R looks to be a better choice. But I want to confirm. Is there any
function or group of functions in Splus that are absent in R?
Thanks,
Saket.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From adrian.trapletti at lmttrading.com  Fri Oct 25 23:32:32 2002
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Fri, 25 Oct 2002 23:32:32 +0200
Subject: [R] Combinatorial Optimisation
References: <Pine.LNX.4.31.0210251259530.10820-100000@gannet.stats>
Message-ID: <3DB9B870.D7D565C1@lmttrading.com>

ripley at stats.ox.ac.uk wrote:

> Adrian,
>
> Thanks for the idea.  If you were willing to contribute a patch to do this
> we would be happy to incorporate it.

Patches for optim.c and optim.Rd against R-1.6.0 source are attached. I didn't test too extensively, but the basic things and the
traveling salesman example seem to work cleanly. I would be glad if you could review and maybe enhance, in particular the S related
code, in optim.c, because there I am really not an expert.

Furthermore, as I was scanning through optim.c I was not sure if line 99 (original)

     df[i] = REAL(s)[i] * (OS->parscale[i])/(OS->fnscale);

is correct. Shouldn't that be

    df[i] = REAL(s)[i] / ((OS->parscale[i])*(OS->fnscale));

to get back to the optim-internal scaling?

best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com


-------------- next part --------------
7c7
<   box-constrained optimization.
---
>   box-constrained optimization and simulated annealing.
21,22c21,24
<    \code{"Nelder-Mead"} and \code{"SANN"} method. If it is \code{NULL}
<    and it is needed, a finite-difference approximation will be used.}
---
>    \code{"Nelder-Mead"} method. If it is \code{NULL} and it is needed, a
>    finite-difference approximation will be used. For the \code{"SANN"}
>    method it is a function to generate a new candidate point. If it is
>    \code{NULL} a default Gaussian Markov kernel is used.}
59c61
<   Method \code{"SANN"} is a variant of simulated annealing
---
>   Method \code{"SANN"} is by default a variant of simulated annealing
64,69c66,73
<   acceptance probability. The next candidate point is generated from a
<   Gaussian Markov kernel with scale proportional to the actual temperature.
<   Temperatures are decreased according to the logarithmic cooling
<   schedule as given in Belisle (1992, p. 890). Note that the
<   \code{"SANN"} method depends critically on the settings of the
<   control parameters.  It is not a general-purpose method but can be
---
>   acceptance probability. By default the next candidate point is
>   generated from a Gaussian Markov kernel with scale proportional to the
>   actual temperature. If a function to generate a new candidate point is
>   given, method \code{"SANN"} can also be used to solve combinatorial
>   optimization problems. Temperatures are decreased according to the
>   logarithmic cooling schedule as given in Belisle (1992, p. 890). Note
>   that the \code{"SANN"} method depends critically on the settings of
>   the control parameters. It is not a general-purpose method but can be 
176c180
< 
---
>   
240a245,290
> 
> ## Combinatorial optimization: Traveling salesman problem
> library(mva)
> 
> data(eurodist)
> eurodistmat <- as.matrix(eurodist)
> 
> distance <- function(sq) {  # Target function
>     sq2 <- embed(sq, 2)
>     return(sum(eurodistmat[cbind(sq2[,2],sq2[,1])]))
> }
> 
> genseq <- function(sq) {  # Generate new candidate sequence 
>     idx <- seq(2, NROW(eurodistmat)-1, by=1)
>     changepoints <- sample(idx, size=2, replace=FALSE)
>     tmp <- sq[changepoints[1]]
>     sq[changepoints[1]] <- sq[changepoints[2]]
>     sq[changepoints[2]] <- tmp
>     return(sq)
> }
> 
> sq <- c(1,2:NROW(eurodistmat),1)  # Initial sequence
> distance(sq)
> 
> res <- optim(sq, distance, genseq, method="SANN",
>              control=list(maxit=20000, temp=2000 ,trace=T))
> res  # Near optimum distance around 12842
> 
> loc <- cmdscale(eurodist)
> rx <- range(x <- loc[,1])
> ry <- range(y <- -loc[,2])
> tspinit <- loc[sq,]
> tspres <- loc[res$par,]
> s <- seq(NROW(tspres)-1)
> 
> plot(x, y, type="n", asp=1, xlab="", ylab="",
>      main="initial solution of traveling salesman problem")
> arrows(tspinit[s,1], -tspinit[s,2], tspinit[s+1,1], -tspinit[s+1,2],
>        angle=10, col="green") 
> text(x, y, names(eurodist), cex=0.8)
> 
> plot(x, y, type="n", asp=1, xlab="", ylab="",
>      main="optim() 'solving' traveling salesman problem") 
> arrows(tspres[s,1], -tspres[s,2], tspres[s+1,1], -tspres[s+1,2],
>        angle=10, col="red")
> text(x, y, names(eurodist), cex=0.8)
-------------- next part --------------
*** ./src/main/optim.c.origin	Mon Apr  8 08:19:48 2002
--- ./src/main/optim.c	Fri Oct 25 18:27:41 2002
***************
*** 155,164 ****
--- 155,193 ----
  	}
  	UNPROTECT(1); /* x */
      }
  }
  
+ static void genptry(int n, double *p, double *ptry, double scale, void *ex)
+ {    
+     SEXP s, x;
+     int i;
+     OptStruct OS = (OptStruct) ex;
+     PROTECT_INDEX ipx;
+ 
+     if (!isNull(OS->R_gcall)) {  /* user defined generation of candidate point */
+       	PROTECT(x = allocVector(REALSXP, n));
+ 	for (i = 0; i < n; i++) {
+ 	    if (!R_FINITE(p[i])) error("non-finite value supplied by optim");
+ 	    REAL(x)[i] = p[i] * (OS->parscale[i]);
+ 	}
+ 	SETCADR(OS->R_gcall, x);
+ 	PROTECT_WITH_INDEX(s = eval(OS->R_gcall, OS->R_env), &ipx);
+ 	REPROTECT(s = coerceVector(s, REALSXP), ipx);
+ 	if(LENGTH(s) != n)
+ 	    error("candidate point in optim evaluated to length %d not %d",
+ 		  LENGTH(s), n);
+ 	for (i = 0; i < n; i++)
+ 	    ptry[i] = REAL(s)[i] / (OS->parscale[i]);
+ 	UNPROTECT(2);
+     } 
+     else {  /* default Gaussian Markov kernel */
+         for (i = 0; i < n; i++)
+             ptry[i] = p[i] + scale * norm_rand();  /* new candidate point */
+     }
+ }
+ 
  /* par fn gr method options */
  SEXP do_optim(SEXP call, SEXP op, SEXP args, SEXP rho)
  {
      SEXP par, fn, gr, method, options, tmp, slower, supper;
      SEXP res, value, counts, conv;
***************
*** 219,237 ****
  	for (i = 0; i < npar; i++)
  	    REAL(par)[i] = opar[i] * (OS->parscale[i]);
  	grcount = NA_INTEGER;
  
      }
!     else if (strcmp(tn, "SANN") == 0) {
!       tmax = asInteger(getListElement(options, "tmax"));
!       temp = asReal(getListElement(options, "temp"));
!       if (tmax == NA_INTEGER) error("tmax is not an integer");
!       samin (npar, dpar, &val, fminfn, maxit, tmax, temp, trace, (void *)OS);
!       for (i = 0; i < npar; i++)
! 	  REAL(par)[i] = dpar[i] * (OS->parscale[i]);
!       fncount = maxit;
!       grcount = NA_INTEGER;
  
      } else if (strcmp(tn, "BFGS") == 0) {
  	SEXP ndeps;
  
  	nREPORT = asInteger(getListElement(options, "REPORT"));
--- 248,273 ----
  	for (i = 0; i < npar; i++)
  	    REAL(par)[i] = opar[i] * (OS->parscale[i]);
  	grcount = NA_INTEGER;
  
      }
!     else if (strcmp(tn, "SANN") == 0) {	
!         tmax = asInteger(getListElement(options, "tmax"));
!         temp = asReal(getListElement(options, "temp"));
!         if (tmax == NA_INTEGER) error("tmax is not an integer");
!         if (!isNull(gr)) {
!             if (!isFunction(gr)) error("gr is not a function");
!                 PROTECT(OS->R_gcall = lang2(gr, R_NilValue));
!         } else {
! 	    PROTECT(OS->R_gcall = R_NilValue); /* for balance */
!         }
!         samin (npar, dpar, &val, fminfn, maxit, tmax, temp, trace, (void *)OS);
!         for (i = 0; i < npar; i++)
!             REAL(par)[i] = dpar[i] * (OS->parscale[i]);
!         fncount = maxit;
!         grcount = NA_INTEGER;
!         UNPROTECT(1);  /* OS->R_gcall */
  
      } else if (strcmp(tn, "BFGS") == 0) {
  	SEXP ndeps;
  
  	nREPORT = asInteger(getListElement(options, "REPORT"));
***************
*** 1056,1074 ****
  	Rprintf ("sann objective function values\n");
  	Rprintf ("initial       value %f\n", *yb);
      }
      scale = 1.0/ti;
      its = itdoc = 1;
!     while (its < maxit) { /* cool down system */
  	t = ti/log((double)its + E1);  /* temperature annealing schedule */
  	k = 1;
  	while ((k <= tmax) && (its < maxit))  /* iterate at constant temperature */
  	{
! 	    for (i = 0; i < n; i++)
! 		dp[i] = scale * t * norm_rand();  /* random perturbation */
! 	    for (i = 0; i < n; i++)
! 		ptry[i] = p[i] + dp[i];  /* new candidate point */
  	    ytry = fminfn (n, ptry, ex);
  	    if (!R_FINITE(ytry)) ytry = big;
  	    dy = ytry - y;
  	    if ((dy <= 0.0) || (unif_rand() < exp(-dy/t))) {  /* accept new point? */
  		for (j = 0; j < n; j++) p[j] = ptry[j];
--- 1092,1107 ----
  	Rprintf ("sann objective function values\n");
  	Rprintf ("initial       value %f\n", *yb);
      }
      scale = 1.0/ti;
      its = itdoc = 1;
!     while (its < maxit) {  /* cool down system */
  	t = ti/log((double)its + E1);  /* temperature annealing schedule */
  	k = 1;
  	while ((k <= tmax) && (its < maxit))  /* iterate at constant temperature */
  	{
!             genptry(n, p, ptry, scale * t, ex);  /* generate new candidate point */
  	    ytry = fminfn (n, ptry, ex);
  	    if (!R_FINITE(ytry)) ytry = big;
  	    dy = ytry - y;
  	    if ((dy <= 0.0) || (unif_rand() < exp(-dy/t))) {  /* accept new point? */
  		for (j = 0; j < n; j++) p[j] = ptry[j];

From Robert.Schick at noaa.gov  Fri Oct 25 23:45:12 2002
From: Robert.Schick at noaa.gov (Robert Schick)
Date: Fri, 25 Oct 2002 14:45:12 -0700
Subject: [R] reshape: duplicate rows to multiple cols
Message-ID: <3DB9BB68.6F4BE853@noaa.gov>

I have a dataframe that I'm trying to reshape, and need advice. My data:

> klam.merge[200:225,]
           stream lulc          x sumlength    pct.lgth
200 1223030419685   92 0.25000000      9.89  2.52780586
201 1223030419686   23 0.00274154      4.73  0.05796068
202 1223030419686   41 0.75009917      4.73 15.85833341
203 1223030419686   42 2.65000000      4.73 56.02536998
204 1223030419686   43 0.11715929      4.73  2.47694058
205 1223030419686   51 0.71000000      4.73 15.01057082
206 1223030419686   71 0.50000000      4.73 10.57082452

I want the reshape to have the pct.lgth value put into its corresponding
lulc col, e.g.
stream		sumlength	lulc.23		lulc.41		lulc.42		lulc.51 ...
1223030419686	4.73		0.05796068	15.85833341	56.02536998     15.01057082

I've tried:

>klam.wide <- reshape(klam.merge, varying=list(levels(klam.merge$lulc)), + timevar="stream",drop="x",direction="wide")

which yields

Error in "[<-.data.frame"(*tmp*, , varying[, i], value =
thistime[match(rval[,  : 
        subscript out of bounds
In addition: There were 20 warnings (use warnings() to see them)
>

I've also tried above syntax with times=list(levels(klam.merge$lulc))
but I get the same error.

Thoughts on what I'm missing?

-- 
Rob Schick
Research Associate
NOAA Fisheries
Santa Cruz Lab
110 Shaffer Road
Santa Cruz, CA 95060
Phone: 831.420.3960
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Robert.Schick at noaa.gov  Sat Oct 26 00:05:47 2002
From: Robert.Schick at noaa.gov (Robert Schick)
Date: Fri, 25 Oct 2002 15:05:47 -0700
Subject: [R] refined reshape question
Message-ID: <3DB9C03B.BAE00778@noaa.gov>

I tried something else, which gets me close:
> klam.wide <- reshape(klam.merge, idvar="stream",timevar="lulc",direction="wide",drop=c("x","sumlength"))

If I don't drop the "sumlength" variable, I get 
sumlength.0 pct.lgth.0 sumlength.11 pct.lgth.11 ...

Anyway to get sum length in just once while reshaping?
-- 
Rob Schick
Research Associate
NOAA Fisheries
Santa Cruz Lab
110 Shaffer Road
Santa Cruz, CA 95060
Phone: 831.420.3960
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From forporphyry at hotmail.com  Sat Oct 26 01:05:18 2002
From: forporphyry at hotmail.com (graham lawrence)
Date: Fri, 25 Oct 2002 16:05:18 -0700
Subject: [R] source output differs from console output
Message-ID: <F143ybqfAj81EYtN3Is00003eca@hotmail.com>


Dear R-help,
I would like to be able to run the following code sequence as a source 
routine.
If I paste it into R via the clipboard it works as expected, but if I source 
the code instead then the last 3 statements fail.
I've also tried writing to the file in place of the sink sequence, but that 
also hits a snag.  R 1.6, w98e2, dfr is a data frame containing the content 
of Julian Faraway's gala data frame.  I append the console log and 3 outputs 
to the file.
Thanks for your help.

qnum<-""
if(given[1]!="NA")qnum<-paste("\n",given[1],".",sep = "")
xfr<-dfr
if(given[2]!="NA")
{
x<-as.numeric(unlist(strsplit(given[2],",")))
xfr<-cbind(dfr[,x])
}
varlst<-names(xfr)
mr<-lm(eval(parse(text=paste(varlst[1],"~",paste(varlst[-1],collapse="+")))), 
data=xfr)
write(qnum,"math.txt",append = TRUE)
sink("math.txt",append = TRUE)
summary(mr)
sink()

The console log was as follows

>given
[1] "1"       "1,3,5,7"
>qnum<-""
>if(given[1]!="NA")qnum<-paste("\n",given[1],".",sep = "")
>xfr<-gala
>if(given[2]!="NA")
+  {
+  x<-as.numeric(unlist(strsplit(given[2],",")))
+  xfr<-cbind(gala[,x])
+  }
>varlst<-names(xfr)
>mr<-lm(eval(parse(text=paste(varlst[1],"~",paste(varlst[-1],collapse="+")))), 
>data=xfr)
>write(qnum,"math.txt",append = TRUE)
>sink("math.txt",append = TRUE)
>summary(mr)
>sink()
>write("now i run it as a source via mrfit.R","math.txt",append=TRUE)
>source("../sources/mrfit.R")
>write("now i run it with a write statement instead of the sink 
>sequence","math.txt",append=TRUE)
>qnum<-""
>if(given[1]!="NA")qnum<-paste("\n",given[1],".",sep = "")
>xfr<-dfr
>if(given[2]!="NA")
+  {
+  x<-as.numeric(unlist(strsplit(given[2],",")))
+  xfr<-cbind(dfr[,x])
+  }
>varlst<-names(xfr)
>mr<-lm(eval(parse(text=paste(varlst[1],"~",paste(varlst[-1],collapse="+")))), 
>data=xfr)
>write(qnum,"math.txt",append = TRUE)
>write(summary(mr),"math.txt",append = TRUE)
Error in cat(list(...), file, sep, fill, labels, append) :
        argument 1 not yet handled by cat
>l<-summary(mr)
>write(l,"math.txt",append = TRUE)
Error in cat(list(...), file, sep, fill, labels, append) :
        argument 1 not yet handled by cat
>l

Call:
lm(formula = eval(parse(text = paste(varlst[1], "~", paste(varlst[-1],
    collapse = "+")))), data = xfr)

Residuals:
    Min      1Q  Median      3Q     Max
-103.66  -53.31  -35.18   23.30  305.12

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept) 62.15560   22.98119   2.705 0.011901 *
Area         0.08465    0.02072   4.085 0.000375 ***
Nearest      0.37841    1.24235   0.305 0.763101
Adjacent    -0.01104    0.02072  -0.533 0.598893
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 94.45 on 26 degrees of freedom
Multiple R-Squared: 0.3914,     Adjusted R-squared: 0.3212
F-statistic: 5.573 on 3 and 26 DF,  p-value: 0.004334

The 3 outputs to the file math.txt follow

1.

Call:
lm(formula = eval(parse(text = paste(varlst[1], "~", paste(varlst[-1],
    collapse = "+")))), data = xfr)

Residuals:
    Min      1Q  Median      3Q     Max
-103.66  -53.31  -35.18   23.30  305.12

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept) 62.15560   22.98119   2.705 0.011901 *
Area         0.08465    0.02072   4.085 0.000375 ***
Nearest      0.37841    1.24235   0.305 0.763101
Adjacent    -0.01104    0.02072  -0.533 0.598893
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 94.45 on 26 degrees of freedom
Multiple R-Squared: 0.3914,	Adjusted R-squared: 0.3212
F-statistic: 5.573 on 3 and 26 DF,  p-value: 0.004334

now i run it as a source via mrfit.R

1.
now i run it with a write statement instead of the sink sequence

1.






_________________________________________________________________
Internet access plans that fit your lifestyle -- join MSN. 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ilievs at lovell.econ.queensu.ca  Sat Oct 26 02:24:03 2002
From: ilievs at lovell.econ.queensu.ca (Stephen Elijah)
Date: Fri, 25 Oct 2002 20:24:03 -0400 (EDT)
Subject: [R] Fortran
Message-ID: <Pine.LNX.4.44.0210252016090.18991-100000@lovell.econ.queensu.ca>

Hello everybody,
Could someone please send me a very simple example using Fortran from
R? Say pass a value to an executable and get the result in R. Actually it
seems it may be possible to call an *.f file ?? or I am wrong again?
The manual is very terse on the subject.
Thank you very much

Stephen Elijah

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Richard.Rowe at jcu.edu.au  Sat Oct 26 01:46:18 2002
From: Richard.Rowe at jcu.edu.au (Richard Rowe)
Date: Sat, 26 Oct 2002 09:46:18 +1000
Subject: [R] points on a sphere
Message-ID: <5.0.0.25.1.20021026093941.02d490d0@pop.jcu.edu.au>

Not an R question directly, but has anyone got a method for placing a 
moderately large number of (near) equi-spaced points on a sphere?  I have a 
nasty feeling platonic solids are needed for exact solutions and I'm 
thinking of samplings involving around 200 - 1000 regularly-spaced points,

Thanks,

Richard Rowe

Richard Rowe
Senior Lecturer
Department of Zoology and Tropical Ecology, James Cook University
Townsville, Queensland 4811, Australia
fax (61)7 47 25 1570
phone (61)7 47 81 4851
e-mail: Richard.Rowe at jcu.edu.au
http://www.jcu.edu.au/school/tbiol/zoology/homepage.html

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From csillery at selway.umt.edu  Sat Oct 26 02:10:28 2002
From: csillery at selway.umt.edu (Katalin Csillery)
Date: Fri, 25 Oct 2002 18:10:28 -0600 (MDT)
Subject: No subject
Message-ID: <Pine.OSF.4.21.0210251804360.9240-100000@selway.umt.edu>


Hi,

Does anybody know how to make the pop up window for graphics work on Mac
OS X (Jaguar)? Neither it works form terminal nor from emacs or xemacs.
Thanks,
Katalin


Katalin Csillery
Division of Biological Sciences
University of Montana, Missoula MT 59801
Phone: 406 243 6106, E-mail: csillery at selway.umt.edu

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From naumov at buffalo.edu  Sat Oct 26 02:22:15 2002
From: naumov at buffalo.edu (Aleksey Naumov)
Date: Fri, 25 Oct 2002 20:22:15 -0400
Subject: [R] Using the Search Engine & Keywords
Message-ID: <200210252022.15772.naumov@buffalo.edu>

Dear R experts,
 
Can anyone running R on Linux share how they use the "Search Engine & 
Keywords" page of R documentation? I cannot do any javascript on this page, 
either searching for a term or following the keyword links. I tried Konqueror 
(3.0.4, with javascript globally enabled), Mozilla (1.1), and Galeon (1.2.5), 
but none of them do anything... 
Sorry, I don't know anything about javascript. Still, it seems installation 
procedure for R should at least somehow instruct a user how to set up the 
search engine... the keyword page is in my mind one of the most useful in the 
whole documentation...

Thanks,
Aleksey
P.S. I use R 1.6.0 on Mandrake 9.0

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Sat Oct 26 04:05:48 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 25 Oct 2002 22:05:48 -0400
Subject: [R] R v/s S-plus
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC80D@usrymx10.merck.com>

Right.  Splus has its own multicomp() function, which R doesn't have.
However, there's the multcomp package which does handle many-to-one
comparisons (but not exactly the Dunnett procedure).

For Saket's original question:  Splus 6.x also comes with the `robust' and
`missing' libraries for robust modelling and missing value imputations.  I
believe there are also bootstrap functions that people at Insightful wrote.
Also, it's probably fair to say that the trellis graphics in Splus is more
`mature' (although I must say that lattice in R has come a long way!).  R
does not have brush(), but you can do that (and lots more) with the xgobi or
the Rggobi package.  gam() in the mgcv package fits one type of GAM, but
gam() in Splus is different (and allow both loess and spline terms).
twoway() in Splus is missing in R (although there's medpolish in the eda
package).

I'm sure there's more, but these are what I can think of off the top of my
head.  It depends on whether these things matters to you.  (Why can't you
keep both?  It doesn't really take up that much room.  Also, to be fair,
should you also ask on S-news to get opnions from "the other side"?)

Andy

-----Original Message-----
From: John Deke [mailto:JDeke at mathematica-mpr.com]
Sent: Friday, October 25, 2002 4:09 PM
To: 'Saket Joshi'; 'r-help at stat.math.ethz.ch'
Subject: RE: [R] R v/s S-plus


This is probably a much more narrow answer than what you wanted, but I
noticed the other day that Splus has a function called qdunnett() that R
lacks (this has to do with multiple comparisons, I believe). Does anyone
know if there's an R equivalent to this SPlus function? 

-----Original Message-----
From: owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch]On Behalf Of Saket Joshi
Sent: Friday, October 25, 2002 3:02 PM
To: r-help at stat.math.ethz.ch
Subject: [R] R v/s S-plus


Hi all,

I have Splus and R both on my unix machine. I intend to keep only one of
them. R looks to be a better choice. But I want to confirm. Is there any
function or group of functions in Splus that are absent in R?
Thanks,
Saket.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Sat Oct 26 04:13:58 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 25 Oct 2002 22:13:58 -0400
Subject: [R] Fortran
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC80E@usrymx10.merck.com>

Which manual did you read?  I thought the "Writing R Extensions" manual has
quite a few examples!

Try the following fortran (say "square.f"):

      subroutine square(n, x, x2)
      integer i,n
      double precision x(n), x2(n)
      do i = 1, n
         x2(i) = x(i) * x(i)
      end do
      end

Then compile with `R CMD SHLIB square.f' which produces squared.so on *nix.
(On Windoze, you'd do `Rcmd SHLIB sqaure.f', which produces squared.dll,
assuming you've got the right tools installed.)  You then start up R, and do

  dyn.load("square.so")  ## Or dyn.load("square.dll") on Windoze
  x <- 1:10
  .Fortran("square", as.integer(length(x)), as.double(x),
as.double(numeric(length(x)))


Andy 

-----Original Message-----
From: Stephen Elijah [mailto:ilievs at lovell.econ.queensu.ca]
Sent: Friday, October 25, 2002 8:24 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Fortran


Hello everybody,
Could someone please send me a very simple example using Fortran from
R? Say pass a value to an executable and get the result in R. Actually it
seems it may be possible to call an *.f file ?? or I am wrong again?
The manual is very terse on the subject.
Thank you very much

Stephen Elijah

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Sat Oct 26 04:27:23 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 25 Oct 2002 22:27:23 -0400
Subject: [R] cubic spline smoothers with heterogeneous variances
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC80F@usrymx10.merck.com>

Sorry for coming to this so late.  My understanding of the problem seems to
be different from Martin's.  Hopefully someone can set me straight.

In Martin's Step 1, why use a small df?  I thought if the objective is to
estimate the variance function first, then one would want estimate of the
regression function to have as small a bias as possible (so that the
residuals would consist of mostly error and very little bias).  I believe
that was the motivation behind those difference-based estimators of the
residual variance.

Also, I was under the impression that the estimation of derivatives has been
worked on quite a bit using local polynomials, so why not use those?  One
just need a variable bandwith smoother for heteroscedastic error.

Cheers,
Andy

-----Original Message-----
From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
>>>>> "Bill" == Bill Shipley <Bill.Shipley at Usherbrooke.ca>
>>>>>     on Tue, 22 Oct 2002 14:49:34 -0700 writes:

    Bill> Hello. I have data (plant weights over time) that are
    Bill> non-linear and in which the variance increases over
    Bill> time.  I have to estimate the first derivatives of
    Bill> plant weight given time (i.e. growth rate) and their
    Bill> se, using a regression smoother, and I have been
    Bill> considering cubic spline smoothers.  

fine. I do so too if I need derivatives.

    Bill> However, I do not know if this can be done given that
    Bill> the error variance would increase over time.  

I'd hope that a simple two-stage procedure (possibly iterated)
would be enough :

1. Smooth(x,y) with ``df = small'' (depend on your context),
   i.e. getting a smooth solution.
2. Get the residuals and  Smooth(x, abs(resid)) 
   to get an estimate proportional to sigma(x).
3. Smooth(x, y,  weights = 1 / sigma(x))

{now you could iterate "2." and "3." and hopefully see
 convergence (of some kind)}.

    Bill> Does anyone know what the effect of a non-constant error
    Bill> variance has on the estimates of the 1st derivative
    Bill> and its se?

"adverse" (effects), but hopefully you'd only look at the 1st
derivative after the above 2-stage solution.

Martin Maechler <maechler at stat.math.ethz.ch>
http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Sat Oct 26 05:17:49 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Fri, 25 Oct 2002 20:17:49 -0700
Subject: [R] points on a sphere
In-Reply-To: <5.0.0.25.1.20021026093941.02d490d0@pop.jcu.edu.au>
Message-ID: <81D2F3B6-E891-11D6-AE20-000393860F3C@stat.ucla.edu>

This puts n points in R^p "as equally spaced as possible". If  
sphere=TRUE
it constrains them to be on the sphere.
============================================================

equidist<-function(n, p, eps=1e-6, itmax=Inf, verbose=TRUE,  
sphere=FALSE) {
x<-matrix(rnorm(n*p),n,p); sprev<-0; itel<-1
if (sphere) x<-row.norm(x) else x<-x/sqrt(sum(x^2))
repeat{
	s<-sum(d<-eudist(x))
	if (verbose) cat(formatC(itel,width=6),
			formatC(s,digits=6,width=20,format="f"),"\n")
	if ((((s-sprev)/sprev) < eps) || (itel == itmax)) return(x)
	diag(d)<-1; e<-1/d; f<-apply(e,1,sum); e<--e; diag(e)<-f
	x<-e%*%x
	if (sphere) x<-row.norm(x) else x<-x/sqrt(sum(x^2))
	sprev<-s; itel<-itel+1
	}
}

row.norm<-function(x) x/sqrt(apply(x^2,1,sum))

eudist<-function(x){
c<-crossprod(t(x)); s<-diag(c)
sqrt(outer(s,s,"+")-2*c)
}

bmat<-function(d,delta,w){
}



On Friday, October 25, 2002, at 04:46 PM, Richard Rowe wrote:

> Not an R question directly, but has anyone got a method for placing a  
> moderately large number of (near) equi-spaced points on a sphere?  I  
> have a nasty feeling platonic solids are needed for exact solutions  
> and I'm thinking of samplings involving around 200 - 1000  
> regularly-spaced points,
>
> Thanks,
>
> Richard Rowe
>
> Richard Rowe
> Senior Lecturer
> Department of Zoology and Tropical Ecology, James Cook University
> Townsville, Queensland 4811, Australia
> fax (61)7 47 25 1570
> phone (61)7 47 81 4851
> e-mail: Richard.Rowe at jcu.edu.au
> http://www.jcu.edu.au/school/tbiol/zoology/homepage.html
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Sat Oct 26 05:20:08 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Fri, 25 Oct 2002 20:20:08 -0700
Subject: [R] Re: 
In-Reply-To: <Pine.OSF.4.21.0210251804360.9240-100000@selway.umt.edu>
Message-ID: <D47D95A3-E891-11D6-AE20-000393860F3C@stat.ucla.edu>

You mean the aqua graphics device window from the Darwin/X11
version ? Not possible yet. Use the X11 graphics or the Carbon R.

On Friday, October 25, 2002, at 05:10 PM, Katalin Csillery wrote:

>
> Hi,
>
> Does anybody know how to make the pop up window for graphics work on  
> Mac
> OS X (Jaguar)? Neither it works form terminal nor from emacs or xemacs.
> Thanks,
> Katalin
>
>
> Katalin Csillery
> Division of Biological Sciences
> University of Montana, Missoula MT 59801
> Phone: 406 243 6106, E-mail: csillery at selway.umt.edu
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lukeh at email.byu.edu  Sat Oct 26 05:40:21 2002
From: lukeh at email.byu.edu (Luke Hutchison)
Date: 25 Oct 2002 21:40:21 -0600
Subject: [R] points on a sphere
In-Reply-To: <5.0.0.25.1.20021026093941.02d490d0@pop.jcu.edu.au>
References: <5.0.0.25.1.20021026093941.02d490d0@pop.jcu.edu.au>
Message-ID: <1035603622.1637.638.camel@lukeh.dnsalias.net>

On Fri, 2002-10-25 at 17:46, Richard Rowe wrote:
> Not an R question directly, but has anyone got a method for placing a 
> moderately large number of (near) equi-spaced points on a sphere?  I have a 
> nasty feeling platonic solids are needed for exact solutions and I'm 
> thinking of samplings involving around 200 - 1000 regularly-spaced points,

There's some C source for that here:

  http://astronomy.swin.edu.au/~pbourke/geometry/spherepoints/

Regards,
Luke Hutchison.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ko-Kang at xtra.co.nz  Sat Oct 26 05:45:35 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Sat, 26 Oct 2002 16:45:35 +1300
Subject: [R] Fortran
References: <Pine.LNX.4.44.0210252016090.18991-100000@lovell.econ.queensu.ca>
Message-ID: <006701c27ca2$2742ca70$5c2758db@kwan022>

Hi,

I did this a few months ago.  Suppose I have the following Fortran
subroutine:
  c A Fortran program that calculates Fibonacci Sequence.
  c Implemented by Ko-Kang Wang

  c23456789
        SUBROUTINE Fibonacci(num, a)

  c Overriding all implicit rules, i.e. undeclare all variables.
        IMPLICIT NONE

  c Declaration of Variables
        DOUBLE PRECISION num, i, fib, prev1, prev2
        CHARACTER a
        prev1 = 1
        prev2 = 0

  c When all = TRUE, follow this loop
  c This loop prints out all values in the sequence
        IF ((a .EQ. 'T') .OR. (a .EQ. 'TRUE')) THEN
        write(*,*) 1
        DO 10 i = 2, num
          fib = prev1 + prev2
          prev2 = prev1
          prev1 = fib
          write(*,*) fib
  10    CONTINUE

  c When all = FALSE, follow this loop
  c This loop only prints the last value in the sequence
        ELSEIF ((a .EQ. 'F') .OR. (a .EQ. 'FALSE')) THEN
        DO 20 i = 2, num
          fib = prev1 + prev2
          num = fib
          prev2 = prev1
          prev1 = fib
  20    CONTINUE
        RETURN
        ENDIF
        END

Note that I have indented the subtroutine by 2 spaces, so it is easier to
read in the email.  You may wish to remove the indentation.

Now, suppose that it is saves as Fibonacci.f and that you're running on
Unix/Linux, then you will want to do:
   R CMD SHLIB Fibonacci.f
this will generates two files:
   Fibonacci.so Fibonacci.o

If you're using Windows, you will need to do:
   Rcmd SHLIB Fibonacci.f
as stated in "Writing R Extensions".

The next thing is to open R and:
  # Load the compiled shared library in.
  dyn.load("Fibonacci.so")

  # Write a function that calls the Fortran subroutine.
  Fibonacci <- function(n, all = T) {
      .Fortran("fibonacci",
         ans = as.double(n),
         as.character(all))$ans
  }

  # Try it out!
  Fibonacci(10)

  Fibonacci(10, all = F)

This is just a silly example, but you get the idea... :-)

Cheers,

Kevin

------------------------------------------------
Ko-Kang Kevin Wang
Post Graduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022


----- Original Message -----
From: "Stephen Elijah" <ilievs at lovell.econ.queensu.ca>
To: <r-help at stat.math.ethz.ch>
Sent: Saturday, October 26, 2002 1:24 PM
Subject: [R] Fortran


> Hello everybody,
> Could someone please send me a very simple example using Fortran from
> R? Say pass a value to an executable and get the result in R. Actually it
> seems it may be possible to call an *.f file ?? or I am wrong again?
> The manual is very terse on the subject.
> Thank you very much
>
> Stephen Elijah
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jyan at stat.wisc.edu  Sat Oct 26 06:10:52 2002
From: jyan at stat.wisc.edu (Jun Yan)
Date: Fri, 25 Oct 2002 23:10:52 -0500 (CDT)
Subject: [R] reshape: duplicate rows to multiple cols
In-Reply-To: <3DB9BB68.6F4BE853@noaa.gov>
Message-ID: <Pine.LNX.4.21.0210252307540.3661-100000@istat02.stat.wisc.edu>

What you need is to specifying arguments idvar, timevar, drop, and v.names
like the following:

> klam
          stream lulc          x sumlength    pct.lgth
201 1.223030e+12   23 0.00274154      4.73  0.05796068
202 1.223030e+12   41 0.75009917      4.73 15.85833341
203 1.223030e+12   42 2.65000000      4.73 56.02536998
204 1.223030e+12   43 0.11715929      4.73  2.47694058
205 1.223030e+12   51 0.71000000      4.73 15.01057082
206 1.223030e+12   71 0.50000000      4.73 10.57082452
> klam.w <- reshape(klam, idvar="stream", timevar="lulc", drop="x",
v.names="pct.lgth", direction="wide")
> klam.w
          stream sumlength pct.lgth.23 pct.lgth.41 pct.lgth.42 pct.lgth.43
pct.lgth.51 pct.lgth.71
201 1.223030e+12      4.73  0.05796068    15.85833    56.02537    2.476941
15.01057    10.57082


Jun Yan

Department of Statistics          Office: CSSC 4252
university of Wisconsin-Madison   Tel: (608)262-7478 
1210 W. Dayton St.                Email: jyan at stat.wisc.edu
Madison, WI 53706                 URL: http://www.stat.wisc.edu/~jyan

On Fri, 25 Oct 2002, Robert Schick wrote:

> I have a dataframe that I'm trying to reshape, and need advice. My data:
> 
> > klam.merge[200:225,]
>            stream lulc          x sumlength    pct.lgth
> 200 1223030419685   92 0.25000000      9.89  2.52780586
> 201 1223030419686   23 0.00274154      4.73  0.05796068
> 202 1223030419686   41 0.75009917      4.73 15.85833341
> 203 1223030419686   42 2.65000000      4.73 56.02536998
> 204 1223030419686   43 0.11715929      4.73  2.47694058
> 205 1223030419686   51 0.71000000      4.73 15.01057082
> 206 1223030419686   71 0.50000000      4.73 10.57082452
> 
> I want the reshape to have the pct.lgth value put into its corresponding
> lulc col, e.g.
> stream		sumlength	lulc.23		lulc.41		lulc.42		lulc.51 ...
> 1223030419686	4.73		0.05796068	15.85833341	56.02536998     15.01057082
> 
> I've tried:
> 
> >klam.wide <- reshape(klam.merge, varying=list(levels(klam.merge$lulc)), + timevar="stream",drop="x",direction="wide")
> 
> which yields
> 
> Error in "[<-.data.frame"(*tmp*, , varying[, i], value =
> thistime[match(rval[,  : 
>         subscript out of bounds
> In addition: There were 20 warnings (use warnings() to see them)
> >
> 
> I've also tried above syntax with times=list(levels(klam.merge$lulc))
> but I get the same error.
> 
> Thoughts on what I'm missing?
> 
> -- 
> Rob Schick
> Research Associate
> NOAA Fisheries
> Santa Cruz Lab
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: 831.420.3960
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jyan at stat.wisc.edu  Sat Oct 26 06:37:10 2002
From: jyan at stat.wisc.edu (Jun Yan)
Date: Fri, 25 Oct 2002 23:37:10 -0500 (CDT)
Subject: [R] source output differs from console output
In-Reply-To: <F143ybqfAj81EYtN3Is00003eca@hotmail.com>
Message-ID: <Pine.LNX.4.21.0210252328440.3661-100000@istat02.stat.wisc.edu>

On Fri, 25 Oct 2002, graham lawrence wrote:

> 
> Dear R-help,
> I would like to be able to run the following code sequence as a source 
> routine.
> If I paste it into R via the clipboard it works as expected, but if I source 
> the code instead then the last 3 statements fail.
> I've also tried writing to the file in place of the sink sequence, but that 
> also hits a snag.  R 1.6, w98e2, dfr is a data frame containing the content 
> of Julian Faraway's gala data frame.  I append the console log and 3 outputs 
> to the file.

`write' can write a data object (matrix or data.frame) out to a
file. `sink' can divert R output of any R object to a file. The error in
your code occurs when you try to `write' a summary object out. I think
`sink' may be enough for your need.

Jun Yan

Department of Statistics          Office: CSSC 4252
university of Wisconsin-Madison   Tel: (608)262-7478 
1210 W. Dayton St.                Email: jyan at stat.wisc.edu
Madison, WI 53706                 URL: http://www.stat.wisc.edu/~jyan




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Oct 26 06:45:23 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 26 Oct 2002 05:45:23 +0100 (BST)
Subject: [R] source output differs from console output
In-Reply-To: <F143ybqfAj81EYtN3Is00003eca@hotmail.com>
Message-ID: <Pine.LNX.4.31.0210260540020.8548-100000@gannet.stats>

1) When you use source() you need to explicitly print results, and not
rely on auto-printing.

2) write() is not the way to write to a file, except for matrices. Use
cat() directly. In any case, you don't want to write the summary to the
file, but the printed version produced by the print method for the summary
object.

So add some print() statements to your script and all should be well.

On Fri, 25 Oct 2002, graham lawrence wrote:

> I would like to be able to run the following code sequence as a source
> routine.
> If I paste it into R via the clipboard it works as expected, but if I source
> the code instead then the last 3 statements fail.
> I've also tried writing to the file in place of the sink sequence, but that
> also hits a snag.  R 1.6, w98e2, dfr is a data frame containing the content
> of Julian Faraway's gala data frame.  I append the console log and 3 outputs
> to the file.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Oct 26 07:04:29 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 26 Oct 2002 06:04:29 +0100 (BST)
Subject: [R] Using the Search Engine & Keywords
In-Reply-To: <200210252022.15772.naumov@buffalo.edu>
Message-ID: <Pine.LNX.4.31.0210260548430.8548-100000@gannet.stats>

1) It uses Java, not just javascript.  You do have Java installed and
enabled?  It does say in several places it is Java-based.

2) I have yet to see a Linux installation of R 1.6.0 where this did not
work out of the box, although ours are all Red Hat.  I understood from the
Mandrake maintainer that the patch I put in for 1.5.1 had re-enabled this
in Mozilla 1.0 on Mandrake.

On Fri, 25 Oct 2002, Aleksey Naumov wrote:

> Dear R experts,
>
> Can anyone running R on Linux share how they use the "Search Engine &
> Keywords" page of R documentation? I cannot do any javascript on this page,
> either searching for a term or following the keyword links. I tried Konqueror
> (3.0.4, with javascript globally enabled), Mozilla (1.1), and Galeon (1.2.5),
> but none of them do anything...
> Sorry, I don't know anything about javascript. Still, it seems installation
> procedure for R should at least somehow instruct a user how to set up the
> search engine... the keyword page is in my mind one of the most useful in the
> whole documentation...

Um, how can you tell if it doesn't work ...?   There is also help.search()
to do almost the same thing.

It's hard to give instructions to undo something peculiar about a
particular user's OS installation.

> Thanks,
> Aleksey
> P.S. I use R 1.6.0 on Mandrake 9.0

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andreww at cheque.uq.edu.au  Sat Oct 26 21:02:14 2002
From: andreww at cheque.uq.edu.au (Andrew C. Ward)
Date: Sat, 26 Oct 2002 19:02:14 -0000
Subject: [R] functions
Message-ID: <01C27D22.36A2BC70.andreww@cheque.uq.edu.au>

Marta,

The "Writing R Extensions" manual is probably geared towards those who 
write complex packages including source code and documentation. This may 
seem incomprehensible overkill  to those who have just a few R functions 
they want available from any and all their workspaces. Further, in R 1.6.0 
packages now need a "Built" tag in the DESCRIPTION file, which again may be 
irrelevant to those who have a just a few R functions.

What I do is have the following line in my .Rprofile file:
	> source("acw.R")
where the file "acw.R" contains R functions. This means that these 
functions are accessible from within any .RData file I'm using (assuming 
I've appropriately set R_USER).

E-mail me privately if you would like more details about this.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



On Friday, October 25, 2002 8:42 PM, Marta Rufino 
[SMTP:mrufino at cmima.csic.es] wrote:
> Hello,
>
> I am a newbie in R,
> I just did my first function, which works!!! And I would like to know, if 
I
> can create a directory in the library with my functions, in a way, which 
I
> could call that like we call the packages ?
> Can anyone help me?
> Thanks in advance
> Marta
>
>
> ><((((o>`..,,..??`..,..??`....,><((((o>`..,,..??`..,..??`....,><((((o>
> `..,,..??`..,..??`....,><((((o>`..,,..??`..,..??`....,><((((o>`..,,..?
>
> Marta Rufino
>
> Centre Mediterrani d'Investigacions Marines i Ambientals
> (CMIMA). CSIC
> Passeig Maritim 37-49
> 08003  BARCELONA
>
> Tfno:34 93 230 95 40
> Tfax:34 93 230 95 55
>
> ><((((o>`..,,..??`..,..??`....,><((((o>`..,,..??`..,..??`....,><((((o>
> `..,,..??`..,..??`....,><((((o>`..,,..??`..,..??`....,><((((o>`..,,..?
>
>
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.  
-.-.-.-
> r-help mailing list -- Read 
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.  
_._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andreww at cheque.uq.edu.au  Sat Oct 26 21:49:31 2002
From: andreww at cheque.uq.edu.au (Andrew C. Ward)
Date: Sat, 26 Oct 2002 19:49:31 -0000
Subject: [R] R v/s S-plus
Message-ID: <01C27D29.43AB8300.andreww@cheque.uq.edu.au>

No doubt there are many capabilities that S-PLUS has that R lacks. Given 
the considerable price difference (thousands of dollars versus free), the 
choice depends on how much you value the additional capabilities of S-PLUS, 
the technical support, and the scripts you've developed in S-PLUS. From my 
perspective, I had to make very few changes to my S-PLUS scripts for them 
to work in R (notably panel functions) and haven't suffered from the 
transition.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



On Saturday, October 26, 2002 5:02 AM, Saket Joshi 
[SMTP:joshi at engr.orst.edu] wrote:
> Hi all,
>
> I have Splus and R both on my unix machine. I intend to keep only one of
> them. R looks to be a better choice. But I want to confirm. Is there any
> function or group of functions in Splus that are absent in R?
> Thanks,
> Saket.
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.  
-.-.-.-.-
> r-help mailing list -- Read 
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.  
_._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dmurdoch at pair.com  Sat Oct 26 13:39:41 2002
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 26 Oct 2002 07:39:41 -0400
Subject: [R] Points on a sphere
Message-ID: <edvkrukf2bo20t34ugfbbul0ovl6o8okkn@4ax.com>

I don't have code for this in R, but a general technique I've used is
as follows:

Start with 4 points at the corners of a regular tetrahedron.  Then
recursively subdivide each triangular face into 3 triangular faces by
placing a point at the center of it. This is easy, just average the 3
vertices and normalize to length 1.   The only tricky part is keeping
track of which vertices form faces.

Duncan Murdoch
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From umalvarez at fata.unam.mx  Sat Oct 26 22:35:12 2002
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Sat, 26 Oct 2002 15:35:12 -0500 (CDT)
Subject: [R] sully question (R-1.6.0 on Jaguar)
In-Reply-To: <p05111a02b9d9da0a7112@[128.115.153.6]>
Message-ID: <Pine.LNX.4.44.0210261523560.6387-100000@fata.unam.mx>

Hi:

First, I like to thank you all for the help I've already received.

Second: After successful ./configure & make, How in the world can I 
launch the R software?

I've tried from a terminal, with and without Fink, and with and without 
the X server.

Any help is appreciated.

Version: 1.6.0
OS: Mac OS 10.2.1 Jaguar
Processor: G3 700 MHz


On Mon, 21 Oct 2002, Don MacQueen wrote:

> Type
> 
>    fink list | grep ' i '
> 
> and look at the results. It should include this:
> 
>   i      g77     3.1-20020420-2  GNU FORTRAN77 compiler.
> 
> If not, then type
> 
>    fink install g77
> 
> (and sit back and wait a long time!).
> 
> You will have to take similar steps for the other packages from fink 
> that Jan mentioned in his earlier response to your questions.
> 
> Then try ./configure again.
> 
> -Don
> 
> At 8:02 PM -0500 10/20/02, Ulises Mora Alvarez wrote:
> >I've just tried. It doesn't work.
> >
> >After running: ./configure
> >I got:
> >Error message:
> >configure: error: Neither an F77 compiler nor f2c found
> >
> >I've just installed and updated fik and the X server.
> >
> >I'm doing something wrong. More help would be appreciated.
> >By the way, how you compiled KDE?
> >
> >Thanks.
> >
> >OS: Jaguar 10.2.1
> >Processor: G3 700 Mhz
> >
> 
> <- snip ->
> 
> >
> >--
> >Ulises M. Alvarez
> >LAB. DE CHOQUES DEBILES
> >FISICA APLICADA Y TECNOLOGIA AVANZADA
> >UNAM
> >umalvarez at fata.unam.mx
> >
> 
> 
> 

-- 
Ulises M. Alvarez
LAB. DE CHOQUES DEBILES
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Sat Oct 26 23:24:26 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Sat, 26 Oct 2002 17:24:26 -0400
Subject: [R] Still missing something on missing values...
Message-ID: <20021026212426.GA652@komensky.surfbest.net>

Hi,

I have a SPSS datafile which is used for my textbook in the
statistics (and which is available on
http://abacon.com/fox/s6720p2.sav, but it is originally from
ICPSR).

When I opened it with SPSS 10 and run Frequencies on it I 
have got 979 valid data a 27 missing. However, see below 
(unfortunately, I have used R in preparation of my homework, 
which caused me an error on this):

	> data=read.spss("s6720p2.sav")
	> levels(data$CP1)
	[1] "Rf"      "Dk"      "Neither" "Oppose"  "Favor"
	> length(data$CP1[data$CP1=="Favor"])
	[1] 727
	> length(data$CP1[data$CP1=="Oppose"])
	[1] 177
	> length(data$CP1[data$CP1=="Neither"])
	[1] 79
	> length(data$CP1[data$CP1=="Dk"])
	[1] 19
	> length(data$CP1[data$CP1=="Rf"])
	[1] 3
	> data$CP1[data$CP1=="Rf" | data$CP1=="Dk"]<-NA
	> length(data$CP1[!is.na(data$CP1)])
	[1] 983
	> length(data$CP1[is.na(data$CP1)])
	[1] 22
	> 727+177+79
	[1] 983

Now, what is even more strange is, that when I have exported just 
the variable CP1 from the full file (in SPSS) and run on it the 
same frequencies as in the full size version, the results were 
same as in R (yes, I have checked that the definition of the 
missing values was the same: 8,9 -- labelled as Rf and Dk).

I have uploaded the data and all reports (in PDF) on 
http://www.volny.cz/cepls/ps-pdf/s6720p2.zip.

Could anybody help me to understand what I did wrong, please?

	Thanks
	
		Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
In those days spirits were brave, the stakes were high, men were
real men, women were real women and small furry creatures from
Alpha Centauri were real small furry creatures from Alpha
Centauri.
    -- Douglas Adams

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Sat Oct 26 23:36:40 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Sat, 26 Oct 2002 17:36:40 -0400
Subject: [R] sully question (R-1.6.0 on Jaguar)
In-Reply-To: <Pine.LNX.4.44.0210261523560.6387-100000@fata.unam.mx>
References: <p05111a02b9d9da0a7112@[128.115.153.6]> <Pine.LNX.4.44.0210261523560.6387-100000@fata.unam.mx>
Message-ID: <20021026213640.GA1071@komensky.surfbest.net>

On Sat, Oct 26, 2002 at 03:35:12PM -0500, Ulises Mora Alvarez wrote:
> Second: After successful ./configure & make, How in the world can I 
> launch the R software?

You should make probably also 'make install' (see INSTALL file) 
and the program should be put in the right place (whatever it is 
on Jaguar).

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
Q: Is vi an easy editor to learn, is it intuitive?
A: Yes, some of us think so. But most people think that we are
   crazy.
    -- vi FAQ

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Sun Oct 27 00:30:33 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Sat, 26 Oct 2002 18:30:33 -0400
Subject: [R] sully question (R-1.6.0 on Jaguar)
In-Reply-To: <20021026213640.GA1071@komensky.surfbest.net>
References: <p05111a02b9d9da0a7112@[128.115.153.6]> <Pine.LNX.4.44.0210261523560.6387-100000@fata.unam.mx> <20021026213640.GA1071@komensky.surfbest.net>
Message-ID: <20021026223033.GA2101@komensky.surfbest.net>

On Sat, Oct 26, 2002 at 05:36:40PM -0400, Matej Cepl wrote:
> On Sat, Oct 26, 2002 at 03:35:12PM -0500, Ulises Mora Alvarez wrote:
> > Second: After successful ./configure & make, How in the world can I 
> > launch the R software?
> 
> You should make probably also 'make install' (see INSTALL file) 
> and the program should be put in the right place (whatever it is 
> on Jaguar).

Sorry, there's a typo here: it should read "so that the program 
is put in the right place" instead of "and the ..." -- running 
'make install' should secure the trick.

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
Opinions founded on prejudice are always sustained with the
greatest violence.
    -- Hebrew Proverb

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sun Oct 27 01:11:45 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 27 Oct 2002 01:11:45 +0200
Subject: [R] Still missing something on missing values...
In-Reply-To: <20021026212426.GA652@komensky.surfbest.net>
References: <20021026212426.GA652@komensky.surfbest.net>
Message-ID: <x2d6pw7q32.fsf@biostat.ku.dk>

Matej Cepl <matej at ceplovi.cz> writes:

> Hi,
> 
> I have a SPSS datafile which is used for my textbook in the
> statistics (and which is available on
> http://abacon.com/fox/s6720p2.sav, but it is originally from
> ICPSR).
> 
> When I opened it with SPSS 10 and run Frequencies on it I 
> have got 979 valid data a 27 missing. However, see below 
> (unfortunately, I have used R in preparation of my homework, 
> which caused me an error on this):
> 
> 	> data=read.spss("s6720p2.sav")
> 	> levels(data$CP1)
> 	[1] "Rf"      "Dk"      "Neither" "Oppose"  "Favor"
> 	> length(data$CP1[data$CP1=="Favor"])
> 	[1] 727
> 	> length(data$CP1[data$CP1=="Oppose"])
> 	[1] 177
> 	> length(data$CP1[data$CP1=="Neither"])
> 	[1] 79
> 	> length(data$CP1[data$CP1=="Dk"])
> 	[1] 19
> 	> length(data$CP1[data$CP1=="Rf"])
> 	[1] 3
> 	> data$CP1[data$CP1=="Rf" | data$CP1=="Dk"]<-NA
> 	> length(data$CP1[!is.na(data$CP1)])
> 	[1] 983
> 	> length(data$CP1[is.na(data$CP1)])
> 	[1] 22
> 	> 727+177+79
> 	[1] 983
> 
> Now, what is even more strange is, that when I have exported just 
> the variable CP1 from the full file (in SPSS) and run on it the 
> same frequencies as in the full size version, the results were 
> same as in R (yes, I have checked that the definition of the 
> missing values was the same: 8,9 -- labelled as Rf and Dk).
> 
> I have uploaded the data and all reports (in PDF) on 
> http://www.volny.cz/cepls/ps-pdf/s6720p2.zip.
> 
> Could anybody help me to understand what I did wrong, please?

The length(data$CP1[data$CP1=="Rf"]) construction is unsound (what
happens if there are NA in the indexing variable?) and you'd be better
off with sum(data$CP1 %in% "Rf") or simply table(data$CP1), but that
seems unrelated here.

As you say, your cp1.pdf is perfectly in accordance with the R output,
whereas cp1-whole_data.pdf differs. It also includes the rather
extraordinary claim that 979+27=1005 !! Is there any chance you may
have accidentally modified it?

[If your instructor still insists that SPSS must be right, and this
really is what it gives as output, I'd point out the obvious
discrepancies with itself and with the data set with just the CP1
variable in it, leaving R out of the discussion...]

What is ICPSR, btw?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mabramso at gmu.edu  Sun Oct 27 02:45:27 2002
From: mabramso at gmu.edu (Myriam Abramson)
Date: 26 Oct 2002 20:45:27 -0400
Subject: [R] 3D plot?
In-Reply-To: <Pine.LNX.4.31.0210260548430.8548-100000@gannet.stats>
References: <Pine.LNX.4.31.0210260548430.8548-100000@gannet.stats>
Message-ID: <m365vo3e1k.fsf@home.sweet.home>


Hi!

How do I draw a 3d plot, with an x,y,z matrix of coordinates? 
I found counter plots but that's not exactly what I want. 

TIA 
-- 
                                   myriam

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Sun Oct 27 02:16:21 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Sat, 26 Oct 2002 20:16:21 -0400
Subject: [R] Still missing something on missing values...
In-Reply-To: <x2d6pw7q32.fsf@biostat.ku.dk>
References: <20021026212426.GA652@komensky.surfbest.net> <x2d6pw7q32.fsf@biostat.ku.dk>
Message-ID: <20021027001620.GA2658@komensky.surfbest.net>

On Sun, Oct 27, 2002 at 01:11:45AM +0200, Peter Dalgaard BSA wrote:
> The length(data$CP1[data$CP1=="Rf"]) construction is unsound (what
> happens if there are NA in the indexing variable?) and you'd be better
> off with sum(data$CP1 %in% "Rf") or simply table(data$CP1), but that
> seems unrelated here.

I knew, that there are non, but of course you are right, that 
your construction is more robust. Unfortunately, I have not heard 
about %in% operator before :-).

> As you say, your cp1.pdf is perfectly in accordance with the R output,
> whereas cp1-whole_data.pdf differs. It also includes the rather
> extraordinary claim that 979+27=1005 !! Is there any chance you may
> have accidentally modified it?

No, I have just print out to the file from the SPSS report
program (I can send you the report in the original .spo file, if
it is of any worth to you) to the file through Apple Laserwriter
Windows NT driver and then via GSView created PDF file. I have 
really low meaning about the Microsoft's printer drivers, but I 
do not suppose, that they would change a value in the printed 
table :-).

I totally missed the claim, that 979+27=1005, but yes it is
there. Wow! We have to have something in our family (my wife
after first using TeX found a mistake in the Windows
distribution, which caused a postponement of the release of the
TeXLive 7 for a couple of weeks :-). I could not believe that I
have found a bug in so venerable program as SPSS is. :-)

> [If your instructor still insists that SPSS must be right, and this
> really is what it gives as output, I'd point out the obvious
> discrepancies with itself and with the data set with just the CP1
> variable in it, leaving R out of the discussion...]

I will immediately do it.

> What is ICPSR, btw?

Inter-University Consortium for Political and Social Research,
which provides _a huge_ (and more or less free) bank of data for
social sciences. Check it out at http://www.icpsr.umich.edu
(unfortunately, the server seems to be down today).

Thanks a lot for help,

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
As with the Christian religion, the worst advertisement for
Socialism is its adherents.
    -- George Orwell

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From janef at stat.berkeley.edu  Sun Oct 27 02:11:02 2002
From: janef at stat.berkeley.edu (Jane Fridlyand)
Date: Sat, 26 Oct 2002 18:11:02 -0700 (PDT)
Subject: [R] denoising univariate data with wavelets
Message-ID: <Pine.SOL.4.31.0210261803220.23313-100000@toto.Berkeley.EDU>


Hi,

I am interested in a applying wavelets as a smoothing tool for my
(1-dimensional) data. I looked into wavetresh and waveslim packages but
could not quite figure out an obvious way to do this after running dwt or
wt functions. Would someone be able to point me in the right direction on
how to denoise univariate data using one of wavelet packages available in
R?

Thank you very much

Jane

ps kalman filter does a good job on my data but tends to dampen spikes too
much so i was looking to compare its performance with wavelets denoising.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From janef at stat.berkeley.edu  Sun Oct 27 02:57:24 2002
From: janef at stat.berkeley.edu (Jane Fridlyand)
Date: Sat, 26 Oct 2002 18:57:24 -0700 (PDT)
Subject: [R] denoising univariate data with wavelets 
Message-ID: <Pine.SOL.4.31.0210261852500.23832-100000@toto.Berkeley.EDU>


SORRY for the duplicate: sent to the wrong address the first time!!!
_______________

Hi,

I am interested in a applying wavelets as a smoothing tool for my
(1-dimensional) data. I looked into wavetresh and waveslim packages but
could not quite figure out an obvious way to do this after running dwt or
wt functions. Would someone be able to point me in the right direction on
how to denoise univariate data using one of wavelet packages available in
R?

Thank you very much

Jane

ps kalman filter does a good job on my data but tends to dampen spikes too
much so i was looking to compare its performance with wavelets denoising.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krcabrer at epm.net.co  Sun Oct 27 03:35:34 2002
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Sat, 26 Oct 2002 21:35:34 -0500
Subject: [R] 3D plot?
References: <Pine.LNX.4.31.0210260548430.8548-100000@gannet.stats> <m365vo3e1k.fsf@home.sweet.home>
Message-ID: <3DBB50F6.3000706@epm.net.co>

Maybe you are looking for
persp

or with the library

scatterplot3d


Myriam Abramson wrote:

>Hi!
>
>How do I draw a 3d plot, with an x,y,z matrix of coordinates? 
>I found counter plots but that's not exactly what I want. 
>
>TIA 
>  
>

-- 
Kenneth Roy Cabrera Torres
Celular +57 (315) 405 9339



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayan at stat.wisc.edu  Sun Oct 27 05:58:21 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 26 Oct 2002 23:58:21 -0500
Subject: [R] 3D plot?
In-Reply-To: <m365vo3e1k.fsf@home.sweet.home>
References: <Pine.LNX.4.31.0210260548430.8548-100000@gannet.stats> <m365vo3e1k.fsf@home.sweet.home>
Message-ID: <200210262358.21741.deepayan@stat.wisc.edu>

On Saturday 26 October 2002 07:45 pm, Myriam Abramson wrote:
> Hi!
>
> How do I draw a 3d plot, with an x,y,z matrix of coordinates?
> I found counter plots but that's not exactly what I want.

If you want 3d scatter plots, you could use either scatterplot3d (in the 
scatterplot3d package) or cloud (in the lattice package). If you want a 3d 
surface, you could use persp (in base).

Deepayan


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikalzet at libero.it  Sun Oct 27 09:43:25 2002
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Sun, 27 Oct 2002 09:43:25 +0100 (CET)
Subject: [R] Using the Search Engine & Keywords
In-Reply-To: <Pine.LNX.4.31.0210260548430.8548-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0210262311320.1871-100000@macchinetta.miadimora>

On Sat, 26 Oct 2002 ripley at stats.ox.ac.uk wrote:

> 1) It uses Java, not just javascript.  You do have Java installed and
> enabled?  It does say in several places it is Java-based.

Mandrake 9.0 does not have java enabled in mozilla by default. If I 
remember correctly, there were (are ?) problems with java in the gcc 3.2 
environment. I have yet to try installing java on Mandrake 9.0.  

> I understood from the
> Mandrake maintainer that the patch I put in for 1.5.1 had re-enabled this
> in Mozilla 1.0 on Mandrake.

On Mandrake 8.2 the R 1.6.0 browser help page works correctly on mozilla, 
(though not under konqueror, even with java enabled and apparently 
working).

> On Fri, 25 Oct 2002, Aleksey Naumov wrote:
> 
> > Can anyone running R on Linux share how they use the "Search Engine &
> > Keywords" page of R documentation? I cannot do any javascript on this page,
> > either searching for a term or following the keyword links. I tried Konqueror
> > (3.0.4, with javascript globally enabled), Mozilla (1.1), and Galeon (1.2.5),
> > but none of them do anything...

You need to install java.

-- 
Michele Alzetta


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From R.Goecke at t-online.de  Sun Oct 27 15:22:16 2002
From: R.Goecke at t-online.de (Roland Goecke)
Date: Sun, 27 Oct 2002 15:22:16 +0100
Subject: [R] Error message stack overflow
Message-ID: <3DBBF698.8050507@t-online.de>

Hi,

when I start R, I get the following error message and the program 
aborts. What does it mean? What do I have to do?

---8<--------------------------

R : Copyright 2002, The R Development Core Team
Version 1.5.1 Patched (2002-07-29)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

Error: protect(): stack overflow
Fatal error: unable to restore saved data in .RData

---8<--------------------------

Cheers
Roland

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Sun Oct 27 22:48:26 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 27 Oct 2002 13:48:26 -0800 (PST)
Subject: [R] Still missing something on missing values...
In-Reply-To: <x2d6pw7q32.fsf@biostat.ku.dk>
Message-ID: <Pine.A41.4.44.0210271338060.67500-100000@homer18.u.washington.edu>

On 27 Oct 2002, Peter Dalgaard BSA wrote:

>
> As you say, your cp1.pdf is perfectly in accordance with the R output,
> whereas cp1-whole_data.pdf differs. It also includes the rather
> extraordinary claim that 979+27=1005 !! Is there any chance you may
> have accidentally modified it?
>

I can verify the SPSS 10 results as well (cut and pasted directly)

FAVOR: DEATH PENALTY FOR MURDERERS
		Frequency	Percent	Valid Percent	Cumulative Percent
Valid	Favor	708	70.4	72.3	72.3
	Oppose	189	18.8	19.3	91.6
	Neither	82	8.2	8.4	100.0
	Total	979	97.4	100.0
Missing	Dk	24	2.4
	Rf	3	.3
	Total	27	2.6
Total		1005	100.0


Distinctly weird.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Mon Oct 28 01:51:34 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Sun, 27 Oct 2002 19:51:34 -0500
Subject: [R] Still missing something on missing values...
In-Reply-To: <Pine.A41.4.44.0210271338060.67500-100000@homer18.u.washington.edu>
References: <x2d6pw7q32.fsf@biostat.ku.dk> <Pine.A41.4.44.0210271338060.67500-100000@homer18.u.washington.edu>
Message-ID: <20021028005134.GA1555@komensky.surfbest.net>

On Sun, Oct 27, 2002 at 01:48:26PM -0800, Thomas Lumley wrote:
> Distinctly weird.

Considering the price tag of SPSS I would use much stronger
words, if I bought the thing myself. :-)

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
If it dies, it's biology.  If it blows up, it's chemistry,
and if it doesn't work, it's physics.
	-- University bathroom graffito

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From s195404 at student.uq.edu.au  Mon Oct 28 02:32:38 2002
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Mon, 28 Oct 2002 11:32:38 +1000 (EST)
Subject: [R] Still missing something on missing values...
In-Reply-To: <20021028005134.GA1555@komensky.surfbest.net>
References: <x2d6pw7q32.fsf@biostat.ku.dk> <Pine.A41.4.44.0210271338060.67500-100000@homer18.u.washington.edu> <20021028005134.GA1555@komensky.surfbest.net>
Message-ID: <1035768757.3dbc93b603b4a@my.uq.edu.au>

I recall SPSS distinguishing between so-called "system" and "user" 
missing values. Maybe this has something to do with it.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting Matej Cepl <matej at ceplovi.cz>:

> On Sun, Oct 27, 2002 at 01:48:26PM -0800, Thomas Lumley
> wrote:
> > Distinctly weird.
> 
> Considering the price tag of SPSS I would use much stronger
> words, if I bought the thing myself. :-)
> 
> Matej
> 
> -- 
> Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
> 138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
>  
> If it dies, it's biology.  If it blows up, it's chemistry,
> and if it doesn't work, it's physics.
> 	-- University bathroom graffito
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
.-.-.-.-.-.-
> r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._._._
> 



CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rsadler at agric.uwa.edu.au  Mon Oct 28 05:56:15 2002
From: rsadler at agric.uwa.edu.au (rohan sadler)
Date: Mon, 28 Oct 2002 12:56:15 +0800
Subject: [R] re: problem installing library sm
Message-ID: <3DBCC36F.8050305@agric.uwa.edu.au>

Hi all,

The suggestions were great. However, after installing readline-devel I 
had to install ncurses-devel before getting sm to work. Can this be put 
into the RH 7.3 Readme when downloading R rpms (and other distbns like 
Mandrake where there may be a similar problem)?

Thanks for your help.

Rohan Sadler

-- 
Ecosystems Research Group (ERGO)
School of Plant Biology (Botany), Faculty of Natural & Agricultural Sciences,
The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009, Australia

Ph:  +61 8 9380 7914
Fax: +61 8 9380 7925
email: rsadler at agric.uwa.edu.au
ERGO's web site:<http://www.botany.uwa.edu.au/ergo>



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Mon Oct 28 08:05:18 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Sun, 27 Oct 2002 23:05:18 -0800 (PST)
Subject: [R] denoising univariate data with wavelets 
In-Reply-To: <Pine.SOL.4.31.0210261852500.23832-100000@toto.Berkeley.EDU>
Message-ID: <Pine.GSO.4.10.10210272300110.27757-100000@quetelet.stat.ucla.edu>

I'm not a wavelet expert, but a simple way (using the `wavethresh'
package) is:

x <- sort(runif(2^10))
y <- sin(2*pi*x) + .4 * rnorm(2^10)
plot(x, y)

wy <- wd(y)
thresh <- threshold(wy, type="soft")
yr <- wr(thresh)

lines(x, yr)

Hope this helps,

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Sat, 26 Oct 2002, Jane Fridlyand wrote:

> 
> SORRY for the duplicate: sent to the wrong address the first time!!!
> _______________
> 
> Hi,
> 
> I am interested in a applying wavelets as a smoothing tool for my
> (1-dimensional) data. I looked into wavetresh and waveslim packages but
> could not quite figure out an obvious way to do this after running dwt or
> wt functions. Would someone be able to point me in the right direction on
> how to denoise univariate data using one of wavelet packages available in
> R?
> 
> Thank you very much
> 
> Jane
> 
> ps kalman filter does a good job on my data but tends to dampen spikes too
> much so i was looking to compare its performance with wavelets denoising.
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ms451a14 at vmesa12.u-3mrs.fr  Mon Oct 28 10:45:35 2002
From: ms451a14 at vmesa12.u-3mrs.fr (rachid cheddadi)
Date: Mon, 28 Oct 2002 10:45:35 +0100
Subject: [R] R Package installation
Message-ID: <3DBD073F.E3B3187A@vmesa12.u-3mrs.fr>

Just a word to say thanks for your help.
Yes, in order to install R packages I needed ncurses-devel which was not
installed.
Many thanks
Rachid
-- 
Dr. Rachid Cheddadi
Centre universitaire Arles      Tel: 00.33.(0)4.90.96.18.18
European Pollen Database        Fax: 00.33.(0)4.90.93.98.03
CNRS - UMR 6116                 rachid.cheddadi at wanadoo.fr
13200 Arles - France            rachid.cheddadi at vmesa12.u-3mrs.fr
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From AlessandroSemeria at cramont.it  Mon Oct 28 12:38:40 2002
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Mon, 28 Oct 2002 12:38:40 +0100
Subject: [R] create an object list in a loop
Message-ID: <OFC10C24CF.4880398A-ONC1256C60.00322545@tomware.it>

Hi! Probably I perform this question because I did'nt  still understand the
R-philosophy.
 I have to build  many matrix, with different dimensions, and  I would to
assign them a
same 'prefix' name, i.e. "aval", but, obviuosly different suffix, something
like:
for (i in 1:n) {
     aval%i% <- matrix(scan(data....),nrow=nr[i],ncol=nc[i]
...
          }
where "%i%" is a  symbol to indicate different label for different index i.
Ther'is some trick to "paste" a label(i)  and to build the object aval%i%
or some other way
to perform my task?
Thanks in advance for your help!
--------------------------
Sincerely yours.
Dr. Alessandro Semeria
Models and Simulation Lab of
The Environment Research Center - Montecatini (Edison Group),
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: asemeria at cramont.it




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vito.muggeo at giustizia.it  Mon Oct 28 12:50:17 2002
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Mon, 28 Oct 2002 12:50:17 +0100
Subject: [R] arima() in for loop
Message-ID: <008901c27e78$3807b640$5c13070a@it.giustizia.it>

hi all,
In a simulation context I'm running in a for loop the arima() function

for( i in 1:1000){
        y<-arima.sim(....)
        out<-arima(y,....)
        ........
         }
Everything works, but after some cycle (10, say) I get error due to the
particular y-values simulated. (E.g., a *frequent* error is "Error in
svd(na.omit(xreg)) : 0 extent dimensions") As a consequence the overall loop
does not continue!

Is it possible to skip the "errors" ? i.e I'd like that, when arima() is not
able to estimate the model, it returns 0, say (or some other object), in
order to allow the loop to go on.

I tried to look inside the code of arima(), but I'm not so expert to find
the solution

Many thanks,
best,
vito

Sorry if you receive this message two times.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From AlessandroSemeria at cramont.it  Mon Oct 28 12:54:55 2002
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Mon, 28 Oct 2002 12:54:55 +0100
Subject: [R] create an object list in a loop
Message-ID: <OF84A30E68.6848FBE1-ONC1256C60.00413192@tomware.it>

Hi! Probably I perform this question because I did'nt  still understand the
R-philosophy.
 I have to build  many matrix, with different dimensions, and  I would to
assign them a
same 'prefix' name, i.e. "aval", but, obviuosly different suffix, something
like:
for (i in 1:n) {
     aval%i% <- matrix(scan(data....),nrow=nr[i],ncol=nc[i]
...
          }
where "%i%" is a  symbol to indicate different label for different index i.
Ther'is some trick to "paste" a label(i)  and to build the object aval%i%
or some other way
to perform my task?
Thanks in advance for your help!
--------------------------
Sincerely yours.
Dr. Alessandro Semeria
Models and Simulation Lab of
The Environment Research Center - Montecatini (Edison Group),
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: asemeria at cramont.it


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zeileis at ci.tuwien.ac.at  Mon Oct 28 14:26:05 2002
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Mon, 28 Oct 2002 14:26:05 +0100
Subject: [R] create an object list in a loop
References: <OF84A30E68.6848FBE1-ONC1256C60.00413192@tomware.it>
Message-ID: <3DBD3AED.DB13CEE5@ci.tuwien.ac.at>

AlessandroSemeria at cramont.it wrote:
> 
> Hi! Probably I perform this question because I did'nt  still understand the
> R-philosophy.
>  I have to build  many matrix, with different dimensions, and  I would to
> assign them a
> same 'prefix' name, i.e. "aval", but, obviuosly different suffix, something
> like:
> for (i in 1:n) {
>      aval%i% <- matrix(scan(data....),nrow=nr[i],ncol=nc[i]
> ...
>           }

You can do something like

for (i in 1:n) {
    assign(paste("aval", i, sep = ""), matrix(..., nrow = nr[i], ncol =
nc[i]))
}

Z


> where "%i%" is a  symbol to indicate different label for different index i.
> Ther'is some trick to "paste" a label(i)  and to build the object aval%i%
> or some other way
> to perform my task?
> Thanks in advance for your help!
> --------------------------
> Sincerely yours.
> Dr. Alessandro Semeria
> Models and Simulation Lab of
> The Environment Research Center - Montecatini (Edison Group),
> Via Ciro Menotti 48,
> 48023 Marina di Ravenna (RA), Italy
> Tel. +39 544 536811
> Fax. +39 544 538663
> E-mail: asemeria at cramont.it
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rbonk at host.sk  Mon Oct 28 14:51:38 2002
From: rbonk at host.sk (Rado Bonk)
Date: Mon, 28 Oct 2002 14:51:38 +0100
Subject: [R] labels for scattered points
Message-ID: <20021028145137.A24450@creon.profinet.sk>

Hello,

I have a set of 70 geodata points. I would like to print them with its
labels (z -value). (I played with points.geodata, however it only
controls points size, pattern and color. Not labels.)

Thanks,

Rado

-- 
Radoslav Bonk M.S.
Dept. of Physical Geography and Geoecology
Faculty of Sciences, Comenius University
Mlynska Dolina 842 15, Bratislava, SLOVAKIA
tel: +421 2 602 96 250 e-mail: rbonk at host.sk
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Claudio.Verzilli at lshtm.ac.uk  Mon Oct 28 15:00:55 2002
From: Claudio.Verzilli at lshtm.ac.uk (Claudio Verzilli)
Date: Mon, 28 Oct 2002 14:00:55 +0000
Subject: [R] arima() in for loop
Message-ID: <sdbd4323.086@s-webmail.lshtm.ac.uk>

you could try with the function...try().
Hope it helps,

Claudio


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Mon Oct 28 15:06:37 2002
From: siim at obs.ee (Ott Toomet)
Date: Mon, 28 Oct 2002 15:06:37 +0100 (CET)
Subject: [R] create an object list in a loop
In-Reply-To: <OF84A30E68.6848FBE1-ONC1256C60.00413192@tomware.it>
Message-ID: <Pine.LNX.4.44.0210281502530.8553-100000@localhost.localdomain>

Hi,

On Mon, 28 Oct 2002 AlessandroSemeria at cramont.it wrote:

  |Hi! Probably I perform this question because I did'nt  still understand the
  |R-philosophy.
  | I have to build  many matrix, with different dimensions, and  I would to
  |assign them a
  |same 'prefix' name, i.e. "aval", but, obviuosly different suffix, something
  |like:
  |for (i in 1:n) {
  |     aval%i% <- matrix(scan(data....),nrow=nr[i],ncol=nc[i]
  |...
  |          }
  |where "%i%" is a  symbol to indicate different label for different index i.
  |Ther'is some trick to "paste" a label(i)  and to build the object aval%i%
  |or some other way
  |to perform my task?

There is two solutions:

a) use assign:

assign(paste("aval", i, sep="")) <- matrix(...)

b) use lists.  I would prefer this one as it is more in line with R
philosophy, and the components are more easy to handle later:

aval <- vector("list", n)
for(i in 1:n)
   aval[[i]] <- matrix(...)

you can later access the components as aval[[1]]


Cheers,

Ott

------------------
Ott Toomet
otoomet at econ.au.dk

---------------------------------------------------------

 (o_         (*_         (O_         (o< -!      (o<)<
//\         //\         //\         //\         //\
V_/_        V_/_        V_/_        V_/_        V_/_

standard    drunken     shocked     noisy      penguin
penguin     penguin     penguin     penguin    eating fish

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hodgess at uhddx01.dt.uh.edu  Mon Oct 28 15:14:32 2002
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Mon, 28 Oct 2002 08:14:32 -0600 (CST)
Subject: [R] [r] Nonlinear time series
Message-ID: <200210281414.IAA15189@uhddx01.dt.uh.edu>

Dear R People:

Is there code for nonlinear time series available, please?

I'm looking for something that could also provide a model for
forecasts.

This is for R V1.5.1 on a PC.

Thank you very much in advance!

sincerely
Erin Hodgess
mailto: hodgess at uhddx01.dt.uh.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jbowers at csm.berkeley.edu  Mon Oct 28 15:20:25 2002
From: jbowers at csm.berkeley.edu (Jake Bowers)
Date: Mon, 28 Oct 2002 06:20:25 -0800 (PST)
Subject: [R] create an object list in a loop
In-Reply-To: <OF84A30E68.6848FBE1-ONC1256C60.00413192@tomware.it>
Message-ID: <Pine.SV4.3.96.1021028061704.14156A-100000@csm.Berkeley.EDU>

Hi.

How about:

n<-10
aval<-list()
for(i in 1:n){
 aval[[i]]<-matrix(....)
}

Then you could access the first matrix as aval[[1]]

Good luck.

Jake
------
Jake Bowers
Dept of Political Science
University of Michigan


On Mon, 28 Oct 2002 AlessandroSemeria at cramont.it wrote:

> Hi! Probably I perform this question because I did'nt  still understand the
> R-philosophy.
>  I have to build  many matrix, with different dimensions, and  I would to
> assign them a
> same 'prefix' name, i.e. "aval", but, obviuosly different suffix, something
> like:
> for (i in 1:n) {
>      aval%i% <- matrix(scan(data....),nrow=nr[i],ncol=nc[i]
> ...
>           }
> where "%i%" is a  symbol to indicate different label for different index i.
> Ther'is some trick to "paste" a label(i)  and to build the object aval%i%
> or some other way
> to perform my task?
> Thanks in advance for your help!
> --------------------------
> Sincerely yours.
> Dr. Alessandro Semeria
> Models and Simulation Lab of
> The Environment Research Center - Montecatini (Edison Group),
> Via Ciro Menotti 48,
> 48023 Marina di Ravenna (RA), Italy
> Tel. +39 544 536811
> Fax. +39 544 538663
> E-mail: asemeria at cramont.it
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Mon Oct 28 15:37:44 2002
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 28 Oct 2002 09:37:44 -0500
Subject: [R] create an object list in a loop
In-Reply-To: <OFC10C24CF.4880398A-ONC1256C60.00322545@tomware.it>
Message-ID: <5.1.0.14.2.20021028093402.020f61d0@mcmail.cis.mcmaster.ca>

Dear Allesandro,

At 12:38 PM 10/28/2002 +0100, AlessandroSemeria at cramont.it wrote:
>Hi! Probably I perform this question because I did'nt  still understand the
>R-philosophy.
>  I have to build  many matrix, with different dimensions, and  I would to
>assign them a
>same 'prefix' name, i.e. "aval", but, obviuosly different suffix, something
>like:
>for (i in 1:n) {
>      aval%i% <- matrix(scan(data....),nrow=nr[i],ncol=nc[i]
>...
>           }
>where "%i%" is a  symbol to indicate different label for different index i.
>Ther'is some trick to "paste" a label(i)  and to build the object aval%i%
>or some other way
>to perform my task?
>Thanks in advance for your help!

You can use paste() within assign() to compose the variable names:

         assign(paste("aval", i, sep=""), 
matrix(scan(data....),nrow=nr[i],ncol=nc[i])

(I'm not sure what it is you're assigning to each of these variables, but I 
assume that it makes sense.)

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Mon Oct 28 15:41:08 2002
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 28 Oct 2002 09:41:08 -0500
Subject: [R] arima() in for loop
In-Reply-To: <008901c27e78$3807b640$5c13070a@it.giustizia.it>
Message-ID: <5.1.0.14.2.20021028093941.020b1ed8@mcmail.cis.mcmaster.ca>

Dear VIto,

At 12:50 PM 10/28/2002 +0100, vito muggeo wrote:
>hi all,
>In a simulation context I'm running in a for loop the arima() function
>
>for( i in 1:1000){
>         y<-arima.sim(....)
>         out<-arima(y,....)
>         ........
>          }
>Everything works, but after some cycle (10, say) I get error due to the
>particular y-values simulated. (E.g., a *frequent* error is "Error in
>svd(na.omit(xreg)) : 0 extent dimensions") As a consequence the overall loop
>does not continue!
>
>Is it possible to skip the "errors" ? i.e I'd like that, when arima() is not
>able to estimate the model, it returns 0, say (or some other object), in
>order to allow the loop to go on.
>
>I tried to look inside the code of arima(), but I'm not so expert to find
>the solution

Take a look at the try function, which is designed to trap errors.

Regards,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Mon Oct 28 15:38:27 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Mon, 28 Oct 2002 09:38:27 -0500
Subject: [R] Fw: Re: Different missing values when exporting?
Message-ID: <20021028143827.GB608@komensky.surfbest.net>

Although I still not like the Microsoftish attempt of SPSS to do
things for myself, which I do not know about (and I am not
warned), apparently it is not such mistake, and my apologies are
due to SPSS. However, I still not like the idea, that I am not
warned that two apparently integers are real numbers in fact and
that incredible result 979+27=1005 is due to rounding-up error.

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
Give your heartache to him. (1Pt 5,7; Mt 11:28-30)

----- Forwarded message from Raynald Levesque <rlevesque at videotron.ca> -----

> Date: Sun, 27 Oct 2002 18:56:28 -0500
> From: Raynald Levesque <rlevesque at videotron.ca>
> Subject: Re: Different missing values when exporting?
> To: cepl at surfbest.net
> 
> The original data file is weighted by variable wt2.
> 
> When you save variable cp1 in a separate sav file, that file is not
> weighted by  wt2.  So the FREQ results are different.

----- End forwarded message -----
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Oct 28 15:43:57 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 28 Oct 2002 15:43:57 +0100
Subject: [R] create an object list in a loop
In-Reply-To: <Pine.SV4.3.96.1021028061704.14156A-100000@csm.Berkeley.EDU>
References: <Pine.SV4.3.96.1021028061704.14156A-100000@csm.Berkeley.EDU>
Message-ID: <x2bs5e62tu.fsf@biostat.ku.dk>

Jake Bowers <jbowers at csm.berkeley.edu> writes:

> Hi.
> 
> How about:
> 
> n<-10
> aval<-list()
> for(i in 1:n){
>  aval[[i]]<-matrix(....)
> }
> 
> Then you could access the first matrix as aval[[1]]

or, 

aval <- lapply(1:n, function(i) matrix(.....))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Oct 28 15:55:59 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 28 Oct 2002 15:55:59 +0100
Subject: [R] create an object list in a loop
In-Reply-To: <x2bs5e62tu.fsf@biostat.ku.dk>
References: <Pine.SV4.3.96.1021028061704.14156A-100000@csm.Berkeley.EDU>
	<x2bs5e62tu.fsf@biostat.ku.dk>
Message-ID: <x27kg2629s.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> Jake Bowers <jbowers at csm.berkeley.edu> writes:
> 
> > Hi.
> > 
> > How about:
> > 
> > n<-10
> > aval<-list()
> > for(i in 1:n){
> >  aval[[i]]<-matrix(....)
> > }
> > 
> > Then you could access the first matrix as aval[[1]]
> 
> or, 
> 
> aval <- lapply(1:n, function(i) matrix(.....))

Sorry, forgot to say that the construct

 aval<-list()
 for(i in 1:n) aval[[i]]<-.....

is distictly bad since it requires a reallocation of the list every
time you add to it. If you have to do it that way, use 

aval <- vector("list", n)

to create aval with the correct length from the outset. (Of course
this is just another good reason to prefer lapply() ... .)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Mon Oct 28 16:38:44 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Mon, 28 Oct 2002 10:38:44 -0500
Subject: [R] Still missing something on missing values...
In-Reply-To: <1035768757.3dbc93b603b4a@my.uq.edu.au>
References: <x2d6pw7q32.fsf@biostat.ku.dk> <Pine.A41.4.44.0210271338060.67500-100000@homer18.u.washington.edu> <20021028005134.GA1555@komensky.surfbest.net> <1035768757.3dbc93b603b4a@my.uq.edu.au>
Message-ID: <20021028153844.GC1139@komensky.surfbest.net>

On Mon, Oct 28, 2002 at 11:32:38AM +1000, Andrew C. Ward wrote:
> I recall SPSS distinguishing between so-called "system" and "user" 
> missing values. Maybe this has something to do with it.

No, it doesn't (I have recoded all missing values to 10, but
nothing shown up). However, partial explanation of the problem
occurred in *.spss newsgroup (see attached). I partially
apologize to SPSS, but I still hold that they should tell me,
that integers are not integers and I do not like the Microsoftish
doing for user more than he asks.

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
A woman without a man is like a fish without a bicycle.
Therefore, a man without a woman is like a bicycle without
a fish.

-------------- next part --------------
An embedded message was scrubbed...
From: unknown sender
Subject: no subject
Date: no date
Size: 3401
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021028/e7eb9900/google.mht

From Detlef.Steuer at unibw-hamburg.de  Mon Oct 28 16:41:18 2002
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Mon, 28 Oct 2002 16:41:18 +0100 (CET)
Subject: [R] arima() in for loop
In-Reply-To: <008901c27e78$3807b640$5c13070a@it.giustizia.it>
Message-ID: <XFMail.20021028164118.steuer@unibw-hamburg.de>

Hi!

Try the try() command for the parts of your code that fail.
Maybe it?s going to be your friend.

detlef

On 28-Oct-2002 vito muggeo wrote:
> hi all,
> In a simulation context I'm running in a for loop the arima() function
> 
> for( i in 1:1000){
>         y<-arima.sim(....)
>         out<-arima(y,....)
>         ........
>          }
> Everything works, but after some cycle (10, say) I get error due to the
> particular y-values simulated. (E.g., a *frequent* error is "Error in
> svd(na.omit(xreg)) : 0 extent dimensions") As a consequence the overall loop
> does not continue!
> 
> Is it possible to skip the "errors" ? i.e I'd like that, when arima() is not
> able to estimate the model, it returns 0, say (or some other object), in
> order to allow the loop to go on.
> 
> I tried to look inside the code of arima(), but I'm not so expert to find
> the solution
> 
> Many thanks,
> best,
> vito
> 
> Sorry if you receive this message two times.
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _

"There is no way to peace, peace is the way." -- Ghandi

Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Oct 28 18:23:17 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 28 Oct 2002 17:23:17 +0000 (GMT Standard Time)
Subject: [R] arima() in for loop
In-Reply-To: <008901c27e78$3807b640$5c13070a@it.giustizia.it>
Message-ID: <Pine.WNT.4.44.0210281722560.2292-100000@gannet.stats.ox.ac.uk>

A case for try(), I think.

On Mon, 28 Oct 2002, vito muggeo wrote:

> hi all,
> In a simulation context I'm running in a for loop the arima() function
>
> for( i in 1:1000){
>         y<-arima.sim(....)
>         out<-arima(y,....)
>         ........
>          }
> Everything works, but after some cycle (10, say) I get error due to the
> particular y-values simulated. (E.g., a *frequent* error is "Error in
> svd(na.omit(xreg)) : 0 extent dimensions") As a consequence the overall loop
> does not continue!
>
> Is it possible to skip the "errors" ? i.e I'd like that, when arima() is not
> able to estimate the model, it returns 0, say (or some other object), in
> order to allow the loop to go on.
>
> I tried to look inside the code of arima(), but I'm not so expert to find
> the solution
>
> Many thanks,
> best,
> vito
>
> Sorry if you receive this message two times.
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From AlessandroSemeria at cramont.it  Mon Oct 28 18:31:48 2002
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Mon, 28 Oct 2002 18:31:48 +0100
Subject: [R] create an object list in a loop
Message-ID: <OF360336D1.5080D2B9-ONC1256C60.004C0434@tomware.it>


Thanks at all for yours precious help. My mistake had origin from the bad
use of '<- ' .
 I thought  (from R-help pages) ' <- ' and 'assign' statements as synonyms.
Evidently I'm not feel with "R-mind", in fact  the suggestion done
by Peter Dalgaard :

aval <- lapply(1:n, function(i) matrix(.....))

is good, it work, but reading R-help ("lapply(X, FUN, ...)....") is not so
clear for me
how this work. Bye
A.S.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Roger.Bivand at nhh.no  Mon Oct 28 19:29:50 2002
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 28 Oct 2002 19:29:50 +0100 (CET)
Subject: [R] labels for scattered points
In-Reply-To: <20021028145137.A24450@creon.profinet.sk>
References: <20021028145137.A24450@creon.profinet.sk>
Message-ID: <49984.213.236.167.186.1035829790.squirrel@webmail.nhh.no>

Rado Bonk wrote:
>
> I have a set of 70 geodata points. I would like to print them with its
> labels (z -value). (I played with points.geodata, however it only
> controls points size, pattern and color. Not labels.)
>

help(text)

text(x=x, y=y, labels=<your labels, say z-value>, your choices of
cex/adj/pos>)

should do what you want.

Roger

-- 
Roger Bivand
NHH, Breiviksveien 40, N-5045 Bergen, Norway
(travelling but still accessible)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mel at mcs.st-and.ac.uk  Mon Oct 28 19:45:22 2002
From: mel at mcs.st-and.ac.uk (Mike Lonergan)
Date: Mon, 28 Oct 2002 18:45:22 -0000
Subject: [R] points on a sphere
In-Reply-To: <5.0.0.25.1.20021026093941.02d490d0@pop.jcu.edu.au>
Message-ID: <NEBBJLLBCLEDFLCCBKDAIEFICJAA.mel@mcs.st-andrews.ac.uk>

Hi Richard,

Here's a non-iterative way of approximately laying out points on the surface
of a sphere. It basically lays out a spiral on the surface (like peeling an
apple) then drops the points along it. I don't know if it will be any actual
use to you, but I quite like it (and would be interested to know what breaks
it).

Cheers,

Mike.


----------------------------------------------------------------
Mike Lonergan

The Observatory, Buchanan Gardens 	ph: (+44) 1334 461803
University of St Andrews		fax:(+44) 1334 461800
Fife, KY16 9LZ, Scotland		email: mel at mcs.st-and.ac.uk
--------------------------------------------------------------------



##########

points.on.unit.sphere<-function(n)
{ # attempts to regularly distribute approximately n points on
  # the surface of a unit sphere non-iteratively
  # by laying them out along a spiral with a fixed (angular) pitch, c,
  # x,y,z are the cartesian coordinates of the points,
  # theta is their longitude, phi their lattitude (in radians)
  # by Mike Lonergan, mel at mcs.st-and.ac.uk

  c<-sqrt(n*pi)/2
  theta<-c(0,2*pi)
  for(i in 3:floor(n/2))
      theta[i]<-theta[i-1]+pi/(c*cos(theta[i-1]/(2*c)-pi/2))
  #   theta[i]<-sqrt(2*c+theta[i-1]^2)
  if (2*floor(n/2)==n)
     theta<-c(theta,2*pi*c-rev(theta))
  else
     theta<-c(theta, pi*c, 2*pi*c-rev(theta))



  pts<-data.frame(theta=theta)

  pts$phi<-theta/(2*c)-pi/2
  pts$x<-cos(theta)*cos(pts$phi)
  pts$y<-sin(theta)*cos(pts$phi)
  pts$z<-sin(pts$phi)

  pts
}


nearest<-function(data)
{ # takes a dataframe with columns x, y, z and returns the (straightline)
nearest
  # neighbour distances between the points in its rows
  # inefficient, but adequate for checking points.on.unit.sphere.

 res<-NA
 for (i in 1:dim(data)[1])
    res[i]<-sqrt(min((data$x[-i]-data$x[i])^2 + (data$y[-i]-data$y[i])^2 +
          (data$z[-i]-data$z[i])^2))

res
}

points.on.unit.sphere(1000)->pous
nearest(pous)->npous

par(mfrow=c(2,2))
hist(npous,main="nearest neighbour distances")
plot(pous$x+sign(pous$z),pous$y,main="plan view")
plot(pous$x+sign(pous$y),pous$z,main="side.view")
plot(npous,ylab="nearest neighbour distances",xlab="theta")
length(which(npous<0.06))

##########

     > -----Original Message-----
     > From: owner-r-help at stat.math.ethz.ch
     > [mailto:owner-r-help at stat.math.ethz.ch]On Behalf Of Richard Rowe
     > Sent: 26 October 2002 00:46
     > To: r-help at stat.math.ethz.ch
     > Subject: [R] points on a sphere
     >
     >
     > Not an R question directly, but has anyone got a method for
     > placing a
     > moderately large number of (near) equi-spaced points on a
     > sphere?  I have a
     > nasty feeling platonic solids are needed for exact solutions and I'm
     > thinking of samplings involving around 200 - 1000
     > regularly-spaced points,
     >
     > Thanks,
     >
     > Richard Rowe
     >
     > Richard Rowe
     > Senior Lecturer
     > Department of Zoology and Tropical Ecology, James Cook University
     > Townsville, Queensland 4811, Australia
     > fax (61)7 47 25 1570
     > phone (61)7 47 81 4851
     > e-mail: Richard.Rowe at jcu.edu.au
     > http://www.jcu.edu.au/school/tbiol/zoology/homepage.html
     >
     > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
     > .-.-.-.-.-.-.-.-.-
     > r-help mailing list -- Read
     > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
     > Send "info", "help", or "[un]subscribe"
     > (in the "body", not the subject !)  To:
     > r-help-request at stat.math.ethz.ch
     > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
     > ._._._._._._._._._
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: points on unit sphere.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021028/c5b5a4b0/pointsonunitsphere.txt

From mschwartz at medanalytics.com  Mon Oct 28 20:21:14 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 28 Oct 2002 13:21:14 -0600
Subject: [R] RE: RPMS of R for Red Hat 8.0
In-Reply-To: <000501c27eb5$acbb94b0$0201a8c0@MARC>
Message-ID: <000601c27eb7$2fd79e10$0201a8c0@MARC>

> From: Martyn Plummer (plummer at iarc.fr)
> Date: Mon Oct 28 2002 - 12:41:28 CET
> 
> A binary RPM package of R 1.6.0 for Red Hat 8.0 should now be 
> available on a CRAN mirror near you. I apologize for the 
> delay, but it took some time to get a copy of the new Red Hat release.
> 
> I shall continue to support Red Hat 7.x.
> 
> For the security conscious: in order to check the GPG 
> signature on this package, you must first import my public 
> key (1024D/97D3544E) into the RPM database. See the man page 
> for rpm. This is a change from previous releases of Red Hat.
> 
> Martyn

Martyn,

I am just curious as the file size of the RPM that you posted is 11.6
Mb, whereas the RPM that I compiled was only 10.8 Mb. 

Is there a different set of configuration options/steps that you use by
default?  I have not yet found any errors, but there may be something I
am missing.

Thanks,

Marc


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From medrecord2001 at yahoo.com  Mon Oct 28 20:51:09 2002
From: medrecord2001 at yahoo.com (Dr. Wong)
Date: Mon, 28 Oct 2002 14:51:09 -0500
Subject: [R] Quick Question
Message-ID: <200210281953.g9SJrExA028583@hypatia.math.ethz.ch>


How can I get the detailing about your products ... ?

Dr. Wong
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dgrove at fhcrc.org  Mon Oct 28 21:16:38 2002
From: dgrove at fhcrc.org (Douglas Grove)
Date: Mon, 28 Oct 2002 12:16:38 -0800 (PST)
Subject: [R] R-1.6.0 crashing on RedHat6.3
Message-ID: <Pine.LNX.4.44.0210281205460.7070-100000@echidna.fhcrc.org>

Hi,

I'm having what I believe are OS problems with my installation
of R-1.6.0.  The machine I'm using was previously running R-1.4.0.
The install seemed fine to me.  I didn't note an error messages
in 'make' or 'make check'.

My problem is that I've been running some memory intesive code,
and the code that ran under 1.4.0 but won't run under R.1.6.0
(or under 1.5.1).  The code crashes with the message:

  Error: cannot allocate vector of size 13 Kb
  Execution halted


There's nothing special about the code I'm trying to run,
in fact it's pretty simple (just memory intensive):

  library(mva)
  pc.norm <- princomp(D,scores=FALSE)

D is a matrix of dim 144x5300
  

My only guess, based on my very limited knowledge, is the 
problem stems from some outdated shared library.

The machine is an two-processor intel-based PC running RedHat6.3.
I would provide more info, but I'm not really sure what's relevant
and I'm not very system-savvy.  

I know the OS should probably be updated, but this isn't feasible
in the short term due to our sys-admin time constraints.
Is there is anything I can do short of updating the entire OS?

BTW, I realize that there isn't much *I* can do, as I'm not the 
system administrator, but I'm trying to figure out where the
problem(s) may lie so that I can tell him what to update.

FWIW, we've had similar problems with Splus6 on this machine
but until now just attributed them to Splus :-)

Thanks,
Doug Grove

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From qwertyu2000us at yahoo.com  Mon Oct 28 21:46:14 2002
From: qwertyu2000us at yahoo.com (dave qwertyu)
Date: Mon, 28 Oct 2002 12:46:14 -0800 (PST)
Subject: [R] nls problem? Error message, Why so?
In-Reply-To: <OF25CC3548.8B78D079-ON86256C5C.00779099@mmm.com>
Message-ID: <20021028204614.48520.qmail@web12708.mail.yahoo.com>


Dear R's:

Thanks for the responses to my question on how to
start a nonlinear square fitting.  Now I encountered
another problem and wonder if I did anything wrong or
the algorithm by R has some difficulty?

My data:

p	theta
0.0	0.5
45.58	0.49
96.9	0.46
150.0	0.42
204.0	0.38
266.7	0.34
346.4	0.3
458.3	0.26
635.9	0.22
979.8	0.18
1990.0	0.14
7998.0	0.11


Then I did:

attach(mydata)
library(nls)
model <- nls( theta ~ thetar + (thetas - thetar)/(1 +
(alfa * p)^n)^(1-1/n),
                  data = mydata, 
                  start = list( thetar = 0.065, thetas
= 0.41, alfa = 0.075, n = 1.89))

I got this error message:

Error in numericDeriv(form[[3]], names(ind), env) : 
        Missing value or an Infinity produced when
evaluating the model


The data and initial guess should be sound and I was
able to fit the model with some fortran program.  I
just wonder how to perform the analysis by using R?

Any insights/comments, thanks a lot in advance!

Dave


__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.connolly at hortresearch.co.nz  Mon Oct 28 22:04:59 2002
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 29 Oct 2002 10:04:59 +1300
Subject: [R] Using the Search Engine & Keywords
In-Reply-To: <Pine.LNX.4.31.0210260548430.8548-100000@gannet.stats>
References: <200210252022.15772.naumov@buffalo.edu> <Pine.LNX.4.31.0210260548430.8548-100000@gannet.stats>
Message-ID: <20021028210459.GB27769@hortresearch.co.nz>

On Sat, 26-Oct-2002 at 06:04AM +0100, ripley at stats.ox.ac.uk wrote:

|> 1) It uses Java, not just javascript.  You do have Java installed and
|> enabled?  It does say in several places it is Java-based.
|> 
|> 2) I have yet to see a Linux installation of R 1.6.0 where this did not
|> work out of the box, although ours are all Red Hat.  I understood from the

I use R 1,6,0 with Red Hat 7.3 and Mozilla 1.0 with java ostensibly
enabled, but it doesn't start.  It works properly in li'l ol' Netscape 4.79.

Any ideas where I should look to see why the two browsers behave so
differently?  Is it simply a case of corrupted profiles?  

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Oct 28 22:20:01 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 28 Oct 2002 22:20:01 +0100
Subject: [R] R-1.6.0 crashing on RedHat6.3
In-Reply-To: <Pine.LNX.4.44.0210281205460.7070-100000@echidna.fhcrc.org>
References: <Pine.LNX.4.44.0210281205460.7070-100000@echidna.fhcrc.org>
Message-ID: <x2r8eajm66.fsf@biostat.ku.dk>

Douglas Grove <dgrove at fhcrc.org> writes:

> Hi,
> 
> I'm having what I believe are OS problems with my installation
> of R-1.6.0.  The machine I'm using was previously running R-1.4.0.
> The install seemed fine to me.  I didn't note an error messages
> in 'make' or 'make check'.
> 
> My problem is that I've been running some memory intesive code,
> and the code that ran under 1.4.0 but won't run under R.1.6.0
> (or under 1.5.1).  The code crashes with the message:
> 
>   Error: cannot allocate vector of size 13 Kb
>   Execution halted
> 
> 
> There's nothing special about the code I'm trying to run,
> in fact it's pretty simple (just memory intensive):
> 
>   library(mva)
>   pc.norm <- princomp(D,scores=FALSE)
> 
> D is a matrix of dim 144x5300
>   
> 
> My only guess, based on my very limited knowledge, is the 
> problem stems from some outdated shared library.
> 
> The machine is an two-processor intel-based PC running RedHat6.3.
> I would provide more info, but I'm not really sure what's relevant
> and I'm not very system-savvy.  
> 
> I know the OS should probably be updated, but this isn't feasible
> in the short term due to our sys-admin time constraints.
> Is there is anything I can do short of updating the entire OS?
> 
> BTW, I realize that there isn't much *I* can do, as I'm not the 
> system administrator, but I'm trying to figure out where the
> problem(s) may lie so that I can tell him what to update.

Are you sure that it is 6.3?? To my knowledge, there is nothing
between 6.2 and 7.0. What's in /etc/redhat-release ?

The Fortran in RH6.x was rather badly broken for some packages, but
one would expect that you had run into that before. 1.6.0 has a memory
leak but it generally affects repeated applications of model fits,
rather than big matrices. 

Do you really mean 144x5300 ? (more columns than rows) That's big: The
covariance matrix at 5300x5300 will take more than 200 MB (OK, it
might only be storing upper or lower triangle.) I tried a matrix like
that on a 1.6.1beta system with about 0.75 GB and got an out of memory
error. A 144x2500 problem is currently running in

  PID USER     PRI  NI  SIZE  RSS SHARE STAT %CPU %MEM   TIME COMMAND
16111 pd        17   0  207M 163M 18536 R    99.8 65.8   1:58 R.bin

and seems to be staying there....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fidler at math.utah.edu  Mon Oct 28 21:22:27 2002
From: fidler at math.utah.edu (Matthew L. Fidler)
Date: 28 Oct 2002 13:22:27 -0700
Subject: [R] Nealder Meade and nlm
Message-ID: <1035836547.20644.6.camel@pceurp52.pharm.utah.edu>

Hello,

I have been using R to fit my data using non-linear least squares.  I
have used the optimize routine to minimize the sum of squared errors
(using Nealder Meade optimization routine), but couldn't get the
non-linear model in R to converge to the estimates acheived in a
convergent Neadler Meade routine.  It tells me about problems with the
gradient.  I was wondering if there is any way to estimate the
covariance matrix for the parameters when using the Nealder Meade
optimization method.  If so is there a book, or article, that I can
refer to about how this is done, it would be greatly appreciated.

Thanks

Matthew L. Fidler

fidler at math.utah.edu
-- 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rawj.mueller at t-online.de  Mon Oct 28 22:24:30 2002
From: rawj.mueller at t-online.de (Richard Mueller)
Date: Mon, 28 Oct 2002 22:24:30 +0100
Subject: [R] changing coordinates?
Message-ID: <3DBDAB0E.3070304@oeko-sorpe.de>

I just detected R and have, after browsing the manual, one question:
I look for quite a lot of time for graphical software which allows to 
plot data from a table or external file _with the axes of the coordinate 
system changed_, i.e. the x-axis should run from top left to bottom 
left, and the y-axis from top-left to top-right. It is of no use to 
interchange the rows in the table, the coordinate system should rely of 
that definition. This type of plot is used in limnological and 
oceanological graphs. Until now I could find no software which can do 
that job. Perhaps one of you can answer this beginner's question with a 
simple yes or no?
Thank you, Richard

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dojoly at wisc.edu  Mon Oct 28 22:59:30 2002
From: dojoly at wisc.edu (Damien O. Joly)
Date: Mon, 28 Oct 2002 15:59:30 -0600
Subject: [R] glmm for binomial data? (OT)
Message-ID: <200210281559.30907@LINUXROCKS>

A while ago (April 2002) there was a short thread on software for generalized 
linear mixed models. 

Since that time, has anyone written or found R code to use a glmm to analyze 
binomial data?  I study CWD in white-tailed deer, and I'd like to do a 
similar analysis as Kleinschmidt et al. (2001, Am. J. Epidemiology 153: 
1213-1221) used to assess control for spatial structure in malaria incidence 
in South Africa.  They used SAS PROC MIXED in an iterative procedure with a 
poisson model, although due to widely varying sample sizes I'd prefer to 
treat my data as binomial (e.g., CWD pos or neg rather than number of CWD pos 
deer).

Thanks,

Damien
-- 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dgrove at fhcrc.org  Mon Oct 28 22:55:19 2002
From: dgrove at fhcrc.org (Douglas Grove)
Date: Mon, 28 Oct 2002 13:55:19 -0800 (PST)
Subject: [R] R-1.6.0 crashing on RedHat6.3
In-Reply-To: <x2r8eajm66.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0210281350390.7517-100000@echidna.fhcrc.org>

> > Hi,
> > 
> > I'm having what I believe are OS problems with my installation
> > of R-1.6.0.  The machine I'm using was previously running R-1.4.0.
> > The install seemed fine to me.  I didn't note an error messages
> > in 'make' or 'make check'.
> > 
> > My problem is that I've been running some memory intesive code,
> > and the code that ran under 1.4.0 but won't run under R.1.6.0
> > (or under 1.5.1).  The code crashes with the message:
> > 
> >   Error: cannot allocate vector of size 13 Kb
> >   Execution halted
> > 
> > 
> > There's nothing special about the code I'm trying to run,
> > in fact it's pretty simple (just memory intensive):
> > 
> >   library(mva)
> >   pc.norm <- princomp(D,scores=FALSE)
> > 
> > D is a matrix of dim 144x5300
> >   
> > 
> > My only guess, based on my very limited knowledge, is the 
> > problem stems from some outdated shared library.
> > 
> > The machine is an two-processor intel-based PC running RedHat6.3.
> > I would provide more info, but I'm not really sure what's relevant
> > and I'm not very system-savvy.  
> > 
> > I know the OS should probably be updated, but this isn't feasible
> > in the short term due to our sys-admin time constraints.
> > Is there is anything I can do short of updating the entire OS?
> > 
> > BTW, I realize that there isn't much *I* can do, as I'm not the 
> > system administrator, but I'm trying to figure out where the
> > problem(s) may lie so that I can tell him what to update.
> 
> Are you sure that it is 6.3?? To my knowledge, there is nothing
> between 6.2 and 7.0. What's in /etc/redhat-release ?

Sorry, I was told it was running 6.3. I just checked and
it's running 6.2.

 
> The Fortran in RH6.x was rather badly broken for some packages, but
> one would expect that you had run into that before. 1.6.0 has a memory
> leak but it generally affects repeated applications of model fits,
> rather than big matrices. 
> 
> Do you really mean 144x5300 ? (more columns than rows) That's big: The
> covariance matrix at 5300x5300 will take more than 200 MB (OK, it
> might only be storing upper or lower triangle.) I tried a matrix like
> that on a 1.6.1beta system with about 0.75 GB and got an out of memory
> error. A 144x2500 problem is currently running in
> 
>   PID USER     PRI  NI  SIZE  RSS SHARE STAT %CPU %MEM   TIME COMMAND
> 16111 pd        17   0  207M 163M 18536 R    99.8 65.8   1:58 R.bin
> 
> and seems to be staying there....

Yep, it's 144x5300.  The machine has 2GB of RAM, and this uses about 1.5GB.





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Oct 28 23:11:40 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 28 Oct 2002 23:11:40 +0100
Subject: [R] R-1.6.0 crashing on RedHat6.3
In-Reply-To: <Pine.LNX.4.44.0210281350390.7517-100000@echidna.fhcrc.org>
References: <Pine.LNX.4.44.0210281350390.7517-100000@echidna.fhcrc.org>
Message-ID: <x2iszmjjs3.fsf@biostat.ku.dk>

Douglas Grove <dgrove at fhcrc.org> writes:

> > Are you sure that it is 6.3?? To my knowledge, there is nothing
> > between 6.2 and 7.0. What's in /etc/redhat-release ?
> 
> Sorry, I was told it was running 6.3. I just checked and
> it's running 6.2.

OK, so the Fortran problems are there, but the usual symptom of that
is crash-on-load.
 

> > The Fortran in RH6.x was rather badly broken for some packages, but
> > one would expect that you had run into that before. 1.6.0 has a memory
> > leak but it generally affects repeated applications of model fits,
> > rather than big matrices. 
> > 
> > Do you really mean 144x5300 ? (more columns than rows) That's big: The
> > covariance matrix at 5300x5300 will take more than 200 MB (OK, it
> > might only be storing upper or lower triangle.) I tried a matrix like
> > that on a 1.6.1beta system with about 0.75 GB and got an out of memory
> > error. A 144x2500 problem is currently running in
> > 
> >   PID USER     PRI  NI  SIZE  RSS SHARE STAT %CPU %MEM   TIME COMMAND
> > 16111 pd        17   0  207M 163M 18536 R    99.8 65.8   1:58 R.bin
> > 
> > and seems to be staying there....
> 
> Yep, it's 144x5300.  The machine has 2GB of RAM, and this uses about 1.5GB.

Hmm. My half-size toy version conked out with 

> D <- matrix(rnorm(2500*144),ncol=2500)
> library(mva)
> pc.norm <- princomp(D,scores=FALSE)
Error in princomp.default(D, scores = FALSE) : 
        covariance matrix is not non-negative definite

which is a bit odd, but at least it didn't run out of memory. However,
the tolerances seem to require some tweaking!

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.connolly at hortresearch.co.nz  Mon Oct 28 23:32:28 2002
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 29 Oct 2002 11:32:28 +1300
Subject: [R] subsetting character vector into groups of numerics
Message-ID: <20021028223228.GC27769@hortresearch.co.nz>

I'm sure there's a simple way to do this, but I can only think of
complicated ones.


I have a number of character vectors that look something like this:

"12 78 23 9 76 43 2 15 41 81 92 5(92 12) (81 78 5 76 9 41) (23 2 15 43)"

I wish to get it into a list of numerical vectors like this:

$Group
[1] 12 78 23 9 76 43 2 15 41 81 92 5

$Subgroup1
[1] 92 12

$Subgroup2
[1] 81 78 5 76 9 41

$Subgroup3
[1] 23 2 15 43

I can't rely on the closing parenthesis as the last character in the
vector, though the subgroup could be clearly defined without it.
Numbers are obvious to the eye, but are not always separated from one
another consistently.  Part of the reason for this exercise is to
check that the Group is made up of the Subgroups with no elements
missing, so getting Group is not simply a matter of concatenating the
subgroups.


Ideas appreciated.



-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maj at waikato.ac.nz  Tue Oct 29 00:00:31 2002
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Tue, 29 Oct 2002 12:00:31 +1300
Subject: [R] Combining simulation results
Message-ID: <E186Ixj-0003Iu-00@euler.math.waikato.ac.nz>

In one saved workspace I have the results of a simulation experiment stored
as an array "resarray".

> dim(resarray)
[1]  10   6 500   3

In another workspace I have a similar array from another run of the
simulation.

I want to combine the two arrays into a single array of dimensions
10, 6, 1000, 3

What's the best way to do this?

Murray Jorgensen


Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html 
Department of Statistics, University of Waikato, Hamilton, New Zealand 
Email: maj at waikato.ac.nz                            Fax +64-7 838 4155
Phone  +64-7 838 4773 wk    +64 7 849 6486 home     Mobile 021 395 862

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From apjaworski at mmm.com  Tue Oct 29 00:09:42 2002
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Mon, 28 Oct 2002 17:09:42 -0600
Subject: [R] R as a library
Message-ID: <OF0EB9B092.CF39FE1A-ON86256C60.007E8F9C@mmm.com>

I would like to write a stand-alone application (in C) using R's
statistical and graphical capabilities.  To make it more challenging I
would have to do it using Windows 2000 platform.  I seem to remember that R
can be compiled into a library of subroutines and linked to an external
program.  Is this true or is my memory playing tricks on me?  I scanned the
FAQs and the "extensions" manual but could not find anything about it.

Thanks in advance for any info on this subject,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Tue Oct 29 00:20:26 2002
From: brahm at alum.mit.edu (David Brahm)
Date: Mon, 28 Oct 2002 18:20:26 -0500
Subject: [R] R v/s S-plus
In-Reply-To: <45006263@toto.iv>
Message-ID: <15805.50746.995826.666539@gargle.gargle.HOWL>

Saket Joshi <joshi at engr.orst.edu> wrote:
> I have Splus and R both on my unix machine. I intend to keep only one...
> Is there any function or group of functions in Splus that are absent in R?

I'm attaching my personal list of differences (which has shrunk considerably
since I posted it here a year ago).  Big picture, the most significant ones
(scoping rules, graphics model, for-loop efficiency) favor R in my opinion.

Please see <http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html> ("R and S") also.

A very nice feature of R is that users can contribute new features or bug fixes
by submitting packages to CRAN or lobbying the R Core team, and all underlying
C code is visible to the user.  Also, questions sent to R-help are immediately
tackled by several very brilliant (if sometimes ornery) experts, whereas
Insightful's technical support (in my experience) can be polite but useless.

S-Plus does have a fancier GUI (but I don't use it).

I think the value added by Insightful is mainly in their ongoing efforts to
build proprietary modules (FinMetrics, NuOpt), external interfaces (Excel,
financial data), and tools that encompass/extend S-Plus (Insightful Miner,
StatServer).  In other words, they do offer a broader product range.


                     ***   R vs. S-Plus (DB 10/28/02)  ***

Language differences:
- Scoping rules differ.  In R, functions see the functions they're in.  Try:
    f1 <- function() {x <- 1; f2 <- function() print(x); f2()};  f1()
- Data must be loaded explicitly in R, can be attach()'ed in S-Plus.
    Addressed by my contributed package "g.data".
- R has a character-type NA, so LETTERS[c(NA,2)] = c(NA,"B") not c("","B")
- paste("a","b", sep="|", sep=".") is an error in R; ok in S-Plus.
- for() loops more efficient in R.

Graphics differences:
- Log scale indicated in S-Plus with par(xaxt)=="l", in R with par("xlog")==T.
- R has cex.main, col.lab, font.axis, etc.  Thus title("Hi", cex=4) fails.
- R has plotmath and Hershey vector fonts.
- R has palette(rainbow(10)) to define colors (both screen and printer).

Functions missing from R:
- unpaste, slice.index, colVars

Functions missing from S-Plus:
- strsplit, sub, gsub, chartr, formatC

Functions that work differently:
- system() has no "input" argument in R.
- substring(s,"x") <- "X" only works in S-Plus, but R has s <- gsub("x","X",s).
- scan expects numbers by default in R.
- which(<numeric>) converts to logical in S-Plus, is an error in R.
- The NULL returned by if(F){...} is invisible in R, visible in S-Plus.
- The NULL returned by return() is visible in R, invisible in S-Plus.
- Args to "var" differ, and R has "cov".  S-Plus na.method="a" ~ R use="p".
- var (or cov) drops dimensions in S-Plus, not R.
- cut allows labels=F in R, not S-Plus (also left.include=T becomes right=F).
- Last argument of a replacement function must be named "value" in R.
- tapply(1:3, c("a","b","a"), sum) is a 1D-array in R, a vector in S-Plus.

-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Tue Oct 29 00:42:11 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 28 Oct 2002 15:42:11 -0800 (PST)
Subject: [R] Nealder Meade and nlm
In-Reply-To: <1035836547.20644.6.camel@pceurp52.pharm.utah.edu>
Message-ID: <Pine.GSO.4.10.10210281540480.29110-100000@fisher.stat.ucla.edu>

If you need standard errors, you can estimate the hessian matrix by
setting `hessian = TRUE' in the optim() function.  Then, take the diagonal
of the inverse.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On 28 Oct 2002, Matthew L. Fidler wrote:

> Hello,
> 
> I have been using R to fit my data using non-linear least squares.  I
> have used the optimize routine to minimize the sum of squared errors
> (using Nealder Meade optimization routine), but couldn't get the
> non-linear model in R to converge to the estimates acheived in a
> convergent Neadler Meade routine.  It tells me about problems with the
> gradient.  I was wondering if there is any way to estimate the
> covariance matrix for the parameters when using the Nealder Meade
> optimization method.  If so is there a book, or article, that I can
> refer to about how this is done, it would be greatly appreciated.
> 
> Thanks
> 
> Matthew L. Fidler
> 
> fidler at math.utah.edu
> -- 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Oct 29 00:56:24 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Oct 2002 00:56:24 +0100
Subject: [R] subsetting character vector into groups of numerics
In-Reply-To: <20021028223228.GC27769@hortresearch.co.nz>
References: <20021028223228.GC27769@hortresearch.co.nz>
Message-ID: <x2elaajexj.fsf@biostat.ku.dk>

Patrick Connolly <p.connolly at hortresearch.co.nz> writes:

> I'm sure there's a simple way to do this, but I can only think of
> complicated ones.
> 
> 
> I have a number of character vectors that look something like this:
> 
> "12 78 23 9 76 43 2 15 41 81 92 5(92 12) (81 78 5 76 9 41) (23 2 15 43)"
> 
> I wish to get it into a list of numerical vectors like this:
> 
> $Group
> [1] 12 78 23 9 76 43 2 15 41 81 92 5
> 
> $Subgroup1
> [1] 92 12
> 
> $Subgroup2
> [1] 81 78 5 76 9 41
> 
> $Subgroup3
> [1] 23 2 15 43
> 
> I can't rely on the closing parenthesis as the last character in the
> vector, though the subgroup could be clearly defined without it.
> Numbers are obvious to the eye, but are not always separated from one
> another consistently.  Part of the reason for this exercise is to
> check that the Group is made up of the Subgroups with no elements
> missing, so getting Group is not simply a matter of concatenating the
> subgroups.
> 
> 
> Ideas appreciated.

Hmm... You seem to be telling us what the format is not. If you want
us to come up with something for the machine to do, it's not too
useful that things are "obvious to the eye"! 

If the format is consistently like the above with subgroups in (),
then you could start with using some of the deeper magic of gsub() to
turn the format into something which would be easier to split into
individual vectors, e.g.

> gsub("\\(([^)]*)\\)", "/\\1", x)
[1] "12 78 23 9 76 43 2 15 41 81 92 5/92 12 /81 78 5 76 9 41 /23 2 15 43"

[What was that? Well, "(" is a special grouping operator in regular
expressions; it isn't part of the RE as such, but things inside (..)
can be referred to with backreferences like \1, which of course needs
to be entered as "\\1". \( is an actual left parenthesis, again
written with the doubled backslash. [^)]* is a sequence consisting of
any character except left parentheses (which is not a grouping
operator when it sits within square brackets). So we're finding the
bits of text delimited by ( and ) and replacing them with a / and the
content of the parentheses. Got it? Don't worry if you don't, I didn't
get it right till the 12th try either! The important thing is knowing
that this kind of stuff is possible if you stare at it long enough.]

Now that it is in an easier format we can use strsplit to get
individual parts:

> s <- strsplit(gsub("\\(([^)]*)\\)", "/\\1", x),"/")
> s
[[1]]
[1] "12 78 23 9 76 43 2 15 41 81 92 5" "92 12 "                          
[3] "81 78 5 76 9 41 "                 "23 2 15 43"                      

and once we have those we might use scan() on each string to get the
numbers. This requires the use of a text connection, like this

> lapply(s[[1]], function(x)scan(textConnection(x)))
Read 12 items
Read 2 items
Read 6 items
Read 4 items
[[1]]
 [1] 12 78 23  9 76 43  2 15 41 81 92  5

[[2]]
[1] 92 12

[[3]]
[1] 81 78  5 76  9 41

[[4]]
[1] 23  2 15 43

...

Your turn!

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From f0z6305 at labs.tamu.edu  Tue Oct 29 03:26:58 2002
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Mon, 28 Oct 2002 20:26:58 -0600
Subject: [R] Numerical Integration
Message-ID: <005101c27ef2$a7e40840$8bd75ba5@IE.TAMU.EDU>

Hey, all

Now I am using EM algorithm to do some
optimization. Within that E-step, I have to
calculate some multivariate integration
given some parameter values Theta and function form
of a probability density function f.

So I want to know if there are some package
in R to do such numerical integration given such
function form and parameter values?

Thanks for your kind support on this.

Have a nice day!

Fred

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.connolly at hortresearch.co.nz  Tue Oct 29 03:29:57 2002
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 29 Oct 2002 15:29:57 +1300
Subject: [R] subsetting character vector into groups of numerics
Message-ID: <20021029022957.GE27769@hortresearch.co.nz>

>From p.connolly at hortresearch.co.nz Tue Oct 29 15:27:34 2002
Date: Tue, 29 Oct 2002 15:27:34 +1300
From: Patrick Connolly <p.connolly at hortresearch.co.nz>
To: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
Subject: Re: [R] subsetting character vector into groups of numerics
Message-ID: <20021029022734.GD27769 at hortresearch.co.nz>
References: <20021028223228.GC27769 at hortresearch.co.nz> <x2elaajexj.fsf at biostat.ku.dk>
Mime-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <x2elaajexj.fsf at biostat.ku.dk>
User-Agent: Mutt/1.4i
Status: RO
Content-Length: 4611
Lines: 133

On Tue, 29-Oct-2002 at 12:56AM +0100, Peter Dalgaard BSA wrote:

|> Patrick Connolly <p.connolly at hortresearch.co.nz> writes:
|> 

[...]

|> > I can't rely on the closing parenthesis as the last character in the
|> > vector, though the subgroup could be clearly defined without it.
|> > Numbers are obvious to the eye, but are not always separated from one
|> > another consistently.  Part of the reason for this exercise is to
|> > check that the Group is made up of the Subgroups with no elements
|> > missing, so getting Group is not simply a matter of concatenating the
|> > subgroups.
|> > 
|> > 
|> > Ideas appreciated.
|> 
|> Hmm... You seem to be telling us what the format is not. If you want
|> us to come up with something for the machine to do, it's not too
|> useful that things are "obvious to the eye"! 

Sorry.  Trying to keep down the verbosity, I made it too brief.  My
main point was that the number of spaces was not always consistent so
the method couldn't rely on, say beginning with a '(' character, and
the subgroups separated by ') (' with the end defined by a ')'.


|> 
|> If the format is consistently like the above with subgroups in (),
|> then you could start with using some of the deeper magic of gsub() to
|> turn the format into something which would be easier to split into
|> individual vectors, e.g.
|> 
|> > gsub("\\(([^)]*)\\)", "/\\1", x)
|> [1] "12 78 23 9 76 43 2 15 41 81 92 5/92 12 /81 78 5 76 9 41 /23 2 15 43"

In any case, that method will work for 

.... 92 5(92 12) (....
and
.... 92 5 (92 12) (....

so the space before the "(" character is not critical.  I was
concerned it would throw a spanner in the works.  When I do a check to
see that the Group is made up of all the Subgroups, I'll be able to
detect if there are any cases of a ')' without a succeeding ')'.  It's
so hard to get good data-entry help these days. :-)

|> 
|> [What was that? Well, "(" is a special grouping operator in regular
|> expressions; it isn't part of the RE as such, but things inside (..)
|> can be referred to with backreferences like \1, which of course needs
|> to be entered as "\\1". \( is an actual left parenthesis, again
|> written with the doubled backslash. [^)]* is a sequence consisting of
|> any character except left parentheses (which is not a grouping
|> operator when it sits within square brackets). So we're finding the
|> bits of text delimited by ( and ) and replacing them with a / and the
|> content of the parentheses. Got it? Don't worry if you don't, I didn't
|> get it right till the 12th try either! The important thing is knowing
|> that this kind of stuff is possible if you stare at it long enough.]

In my case, I needed a bit more help.  That solution is brilliant.
Thanks for the explanation of it too.  It covers everything I can
think of except the occasion where a '(' or ')' is missing.  I know
the final ")" is absent in a few places.  It's probably easiest for me
to do a test and add that character if required before using gsub,
then check if the Groups tally with the subgroups to determine if
there is anything missing.  Those should be rare enough to fix in the
data file instead of trying to come up with a generic method of
detecting them and making the requisite modifications.


|> 
|> Now that it is in an easier format we can use strsplit to get
|> individual parts:
|> 
|> > s <- strsplit(gsub("\\(([^)]*)\\)", "/\\1", x),"/")

I probably would have got that if I'd got that far.


[...]

|> and once we have those we might use scan() on each string to get the
|> numbers. This requires the use of a text connection, like this
|> 
|> > lapply(s[[1]], function(x)scan(textConnection(x)))

I'd never had occasion to use textConnection before and was completely
ignorant of its existence.  Certainly simpler than my idea of
exporting text files and then using a Perl script and then importing
back in.



|> Read 12 items
|> Read 2 items
|> Read 6 items
|> Read 4 items
|> [[1]]
|>  [1] 12 78 23  9 76 43  2 15 41 81 92  5
|> 
|> [[2]]
|> [1] 92 12
|> 
|> [[3]]
|> [1] 81 78  5 76  9 41
|> 
|> [[4]]
|> [1] 23  2 15 43
|> 
|> ...
|> 
|> Your turn!

Can't improve on that!  It's so close to what I require we could call
it a day.  Thanks again.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 29 05:22:33 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 29 Oct 2002 04:22:33 +0000 (GMT)
Subject: [R] Using the Search Engine & Keywords
In-Reply-To: <20021028210459.GB27769@hortresearch.co.nz>
Message-ID: <Pine.LNX.4.31.0210282113490.5708-100000@gannet.stats>

On Tue, 29 Oct 2002, Patrick Connolly wrote:

> On Sat, 26-Oct-2002 at 06:04AM +0100, ripley at stats.ox.ac.uk wrote:
>
> |> 1) It uses Java, not just javascript.  You do have Java installed and
> |> enabled?  It does say in several places it is Java-based.
> |>
> |> 2) I have yet to see a Linux installation of R 1.6.0 where this did not
> |> work out of the box, although ours are all Red Hat.  I understood from the
>
> I use R 1,6,0 with Red Hat 7.3 and Mozilla 1.0 with java ostensibly
> enabled, but it doesn't start.  It works properly in li'l ol' Netscape 4.79.
>
> Any ideas where I should look to see why the two browsers behave so
> differently?  Is it simply a case of corrupted profiles?

We found that mozilla/Netscape 6.x/7.0 was much more security-conscious
than Netscape 4.x. I had to arrange to copy the class files (not link
them) to get Mozilla 1.0 to run under 7.2.  But that's been the case in R
since 1.5.1.  So security is one place to look.

I would check via a java-enabled site that java really is working.
I've found it tricky with Mozilla.  After that, there should be an error
message in the status bar when the search engine is run (or not).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 29 05:30:46 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 29 Oct 2002 04:30:46 +0000 (GMT)
Subject: [R] glmm for binomial data? (OT)
In-Reply-To: <200210281559.30907@LINUXROCKS>
Message-ID: <Pine.LNX.4.31.0210290427530.6304-100000@gannet.stats>

Same as then.

glmmPQL in MASS (approximate, but not a bad approximation)
glmm in GLMMGibbs (needs careful tuning in the binomial case, but
has worked for me).

New info:

There is a section and a couple of worked examples in MASS4.  The
best method there uses R/S+C code which is not yet available to public
release, but we expect it to be within 6 months.

On Mon, 28 Oct 2002, Damien O. Joly wrote:

> A while ago (April 2002) there was a short thread on software for generalized
> linear mixed models.
>
> Since that time, has anyone written or found R code to use a glmm to analyze
> binomial data?  I study CWD in white-tailed deer, and I'd like to do a
> similar analysis as Kleinschmidt et al. (2001, Am. J. Epidemiology 153:
> 1213-1221) used to assess control for spatial structure in malaria incidence
> in South Africa.  They used SAS PROC MIXED in an iterative procedure with a
> poisson model, although due to widely varying sample sizes I'd prefer to
> treat my data as binomial (e.g., CWD pos or neg rather than number of CWD pos
> deer).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 29 05:51:05 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 29 Oct 2002 04:51:05 +0000 (GMT)
Subject: PCA with n << p (was [R] R-1.6.0 crashing on RedHat6.3)
In-Reply-To: <x2iszmjjs3.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.31.0210290441180.6304-100000@gannet.stats>

princomp is the wrong tool here: prcomp is better (and a version using
La.svd would be better still).

What do you want to do with a PCA of such a matrix?  We can almost
certainly give you a better way using La.svd directly.

BDR

On 28 Oct 2002, Peter Dalgaard BSA wrote:

> Douglas Grove <dgrove at fhcrc.org> writes:
>
> > > Are you sure that it is 6.3?? To my knowledge, there is nothing
> > > between 6.2 and 7.0. What's in /etc/redhat-release ?
> >
> > Sorry, I was told it was running 6.3. I just checked and
> > it's running 6.2.
>
> OK, so the Fortran problems are there, but the usual symptom of that
> is crash-on-load.
>
>
> > > The Fortran in RH6.x was rather badly broken for some packages, but
> > > one would expect that you had run into that before. 1.6.0 has a memory
> > > leak but it generally affects repeated applications of model fits,
> > > rather than big matrices.
> > >
> > > Do you really mean 144x5300 ? (more columns than rows) That's big: The
> > > covariance matrix at 5300x5300 will take more than 200 MB (OK, it
> > > might only be storing upper or lower triangle.) I tried a matrix like
> > > that on a 1.6.1beta system with about 0.75 GB and got an out of memory
> > > error. A 144x2500 problem is currently running in
> > >
> > >   PID USER     PRI  NI  SIZE  RSS SHARE STAT %CPU %MEM   TIME COMMAND
> > > 16111 pd        17   0  207M 163M 18536 R    99.8 65.8   1:58 R.bin
> > >
> > > and seems to be staying there....
> >
> > Yep, it's 144x5300.  The machine has 2GB of RAM, and this uses about 1.5GB.
>
> Hmm. My half-size toy version conked out with
>
> > D <- matrix(rnorm(2500*144),ncol=2500)
> > library(mva)
> > pc.norm <- princomp(D,scores=FALSE)
> Error in princomp.default(D, scores = FALSE) :
>         covariance matrix is not non-negative definite
>
> which is a bit odd, but at least it didn't run out of memory. However,
> the tolerances seem to require some tweaking!
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Tue Oct 29 05:53:33 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Mon, 28 Oct 2002 23:53:33 -0500
Subject: [R] changing coordinates?
In-Reply-To: <3DBDAB0E.3070304@oeko-sorpe.de>
References: <3DBDAB0E.3070304@oeko-sorpe.de>
Message-ID: <20021029045332.GA1330@komensky.surfbest.net>

On Mon, Oct 28, 2002 at 10:24:30PM +0100, Richard Mueller wrote:
> I just detected R and have, after browsing the manual, one question:
> I look for quite a lot of time for graphical software which allows to 
> plot data from a table or external file _with the axes of the coordinate 
> system changed_, i.e. the x-axis should run from top left to bottom 
> left, and the y-axis from top-left to top-right. It is of no use to 
> interchange the rows in the table, the coordinate system should rely of 
> that definition. This type of plot is used in limnological and 
> oceanological graphs. Until now I could find no software which can do 
> that job. Perhaps one of you can answer this beginner's question with a 
> simple yes or no?

R is more statistical package than graphical one -- if you need
sophisticated graphs then you are probably much better with
gnuplot (http://www.cs.dartmouth.edu/gnuplot_info.html), which is
similar to R in being highly sophisticated (and ported on many
different architectures -- there are well supported ports to both
Linux and M$-Windows), but it is a pure graphing package.

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
The main idea of the pope's asking for forgivness was not to be
afraid of the truth. DO NOT BE AFRAID OF TRUTH! We have to have
faith in the God's governing power to be able not to be afraid.
    -- On NPR The Connection from March 13, 2000

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Tue Oct 29 07:59:06 2002
From: siim at obs.ee (Ott Toomet)
Date: Tue, 29 Oct 2002 07:59:06 +0100 (CET)
Subject: [R] subsetting character vector into groups of numerics
In-Reply-To: <20021029022957.GE27769@hortresearch.co.nz>
Message-ID: <Pine.LNX.4.44.0210290754040.9134-100000@localhost.localdomain>

On Tue, 29 Oct 2002, Patrick Connolly wrote:

...

  ||> and once we have those we might use scan() on each string to get the
  ||> numbers. This requires the use of a text connection, like this
  ||> 
  ||> > lapply(s[[1]], function(x)scan(textConnection(x)))
  |
  |I'd never had occasion to use textConnection before and was completely
  |ignorant of its existence.  Certainly simpler than my idea of
  |exporting text files and then using a Perl script and then importing
  |back in.

I had used strsplit and as.numeric in that place, e.g.

> a <- c("12 13 14 15 16 888")
> as.numeric(unlist(strsplit(a, " ")))
> [1]  12  13  14  15  16 888

But perhaps Peter's idea is better.

Ott

-- 
Ott Toomet
otoomet at econ.au.dk
---------------------------------------------------------

 (o_         (*_         (O_         (o< -!      (o<)<
//\         //\         //\         //\         //\
V_/_        V_/_        V_/_        V_/_        V_/_

standard    drunken     shocked     noisy      penguin
penguin     penguin     penguin     penguin    eating fish


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dgrove at fhcrc.org  Tue Oct 29 07:58:51 2002
From: dgrove at fhcrc.org (Douglas Grove)
Date: Mon, 28 Oct 2002 22:58:51 -0800 (PST)
Subject: PCA with n << p (was [R] R-1.6.0 crashing on RedHat6.3)
In-Reply-To: <Pine.LNX.4.31.0210290441180.6304-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0210282244310.9142-100000@echidna.fhcrc.org>

> princomp is the wrong tool here: prcomp is better (and a version using
> La.svd would be better still).

Okay. I used princomp as I saw something in your book regarding using
this and NOT prcomp in S-plus, I thought the same would hold in R.  

 

> What do you want to do with a PCA of such a matrix?  We can almost
> certainly give you a better way using La.svd directly.

Looking at microarray data with approx. 5300 'genes' and 144 samples
(72 control, 72 experimental).  Trying to see how well principal
components can separate the different tissue types (Liver, Kidney, Testis)
making up the samples.

In any case, this code is just an example of the problem we're having
with R (and S-plus) crashing with memory allocation related errors.
I used this code since no one could poke holes in it :-)

Thanks for the info on prcomp.  I'll try it out.

Doug



> BDR
> 
> On 28 Oct 2002, Peter Dalgaard BSA wrote:
> 
> > Douglas Grove <dgrove at fhcrc.org> writes:
> >
> > > > Are you sure that it is 6.3?? To my knowledge, there is nothing
> > > > between 6.2 and 7.0. What's in /etc/redhat-release ?
> > >
> > > Sorry, I was told it was running 6.3. I just checked and
> > > it's running 6.2.
> >
> > OK, so the Fortran problems are there, but the usual symptom of that
> > is crash-on-load.
> >
> >
> > > > The Fortran in RH6.x was rather badly broken for some packages, but
> > > > one would expect that you had run into that before. 1.6.0 has a memory
> > > > leak but it generally affects repeated applications of model fits,
> > > > rather than big matrices.
> > > >
> > > > Do you really mean 144x5300 ? (more columns than rows) That's big: The
> > > > covariance matrix at 5300x5300 will take more than 200 MB (OK, it
> > > > might only be storing upper or lower triangle.) I tried a matrix like
> > > > that on a 1.6.1beta system with about 0.75 GB and got an out of memory
> > > > error. A 144x2500 problem is currently running in
> > > >
> > > >   PID USER     PRI  NI  SIZE  RSS SHARE STAT %CPU %MEM   TIME COMMAND
> > > > 16111 pd        17   0  207M 163M 18536 R    99.8 65.8   1:58 R.bin
> > > >
> > > > and seems to be staying there....
> > >
> > > Yep, it's 144x5300.  The machine has 2GB of RAM, and this uses about 1.5GB.
> >
> > Hmm. My half-size toy version conked out with
> >
> > > D <- matrix(rnorm(2500*144),ncol=2500)
> > > library(mva)
> > > pc.norm <- princomp(D,scores=FALSE)
> > Error in princomp.default(D, scores = FALSE) :
> >         covariance matrix is not non-negative definite
> >
> > which is a bit odd, but at least it didn't run out of memory. However,
> > the tolerances seem to require some tweaking!
> >
> > --
> >    O__  ---- Peter Dalgaard             Blegdamsvej 3
> >   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
> >  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> >
> 
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Tue Oct 29 08:09:41 2002
From: siim at obs.ee (Ott Toomet)
Date: Tue, 29 Oct 2002 08:09:41 +0100 (CET)
Subject: [R] changing coordinates?
In-Reply-To: <3DBDAB0E.3070304@oeko-sorpe.de>
Message-ID: <Pine.LNX.4.44.0210290800510.9134-100000@localhost.localdomain>

On Mon, 28 Oct 2002, Richard Mueller wrote:

  |I just detected R and have, after browsing the manual, one question:
  |I look for quite a lot of time for graphical software which allows to 
  |plot data from a table or external file _with the axes of the coordinate 
  |system changed_, i.e. the x-axis should run from top left to bottom 
  |left, and the y-axis from top-left to top-right. It is of no use to 
  |interchange the rows in the table, the coordinate system should rely of 
  |that definition. This type of plot is used in limnological and 
  |oceanological graphs. Until now I could find no software which can do 
  |that job. Perhaps one of you can answer this beginner's question with a 
  |simple yes or no?
  |Thank you, Richard

Short answer is yes, you can do it.

There is no pre-programmed plot command in order to do that, however.  You
have to transform you data a bit, e.g. changing the sign.  Suppose you have
data

> x <- c(1,2,3,-1)
> y <- 1:4

In that case you can do something like

> plot(y, -x, yaxt="n", xaxt="n")
> axis(2, at=pretty(-x), labels=as.character(-pretty(-x)))
> axis(3)

Perhaps you get an idea.

Ott

-- 
Ott Toomet
otoomet at econ.au.dk

---------------------------------------------------------

 (o_         (*_         (O_         (o< -!      (o<)<
//\         //\         //\         //\         //\
V_/_        V_/_        V_/_        V_/_        V_/_

standard    drunken     shocked     noisy      penguin
penguin     penguin     penguin     penguin    eating fish


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Tue Oct 29 08:10:51 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue, 29 Oct 2002 02:10:51 -0500
Subject: [R] changing coordinates?
In-Reply-To: <20021029045332.GA1330@komensky.surfbest.net>; from matej@ceplovi.cz on Mon, Oct 28, 2002 at 11:53:33PM -0500
References: <3DBDAB0E.3070304@oeko-sorpe.de> <20021029045332.GA1330@komensky.surfbest.net>
Message-ID: <20021029021051.A16384@cattell.psych.upenn.edu>

On 10/28/02 23:53, Matej Cepl wrote:
>On Mon, Oct 28, 2002 at 10:24:30PM +0100, Richard Mueller wrote:
>> I just detected R and have, after browsing the manual, one question:
>> I look for quite a lot of time for graphical software which allows to 
>> plot data from a table or external file _with the axes of the coordinate 
>> system changed_, i.e. the x-axis should run from top left to bottom 
>> left, and the y-axis from top-left to top-right. It is of no use to 
>> interchange the rows in the table, the coordinate system should rely of 
>> that definition. This type of plot is used in limnological and 
>> oceanological graphs. Until now I could find no software which can do 
>> that job. Perhaps one of you can answer this beginner's question with a 
>> simple yes or no?
>
>R is more statistical package than graphical one -- if you need
>sophisticated graphs then you are probably much better with
>gnuplot (http://www.cs.dartmouth.edu/gnuplot_info.html), which is
>similar to R in being highly sophisticated (and ported on many
>different architectures -- there are well supported ports to both
>Linux and M$-Windows), but it is a pure graphing package.

Although this may be true, if I understand the current question
then it is not so hard to implement in R.  See the axis()
function, particularly its "side" and "labels" paramaters, and,
in the plot function or an earlier par() function, set xaxt="n"
to block plotting of the default axis.  You need labels to make
the x axis go from top to bottom.  Perhaps there is a more
elegant way but I don't know it.

Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Oct 29 09:16:54 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 29 Oct 2002 09:16:54 +0100
Subject: [R] Numerical Integration
In-Reply-To: <005101c27ef2$a7e40840$8bd75ba5@IE.TAMU.EDU>
References: <005101c27ef2$a7e40840$8bd75ba5@IE.TAMU.EDU>
Message-ID: <15806.17398.876552.296509@gargle.gargle.HOWL>

>>>>> "Feng" == Feng Zhang <f0z6305 at labs.tamu.edu>
>>>>>     on Mon, 28 Oct 2002 20:26:58 -0600 writes:

    Feng> Hey, all
    Feng> Now I am using EM algorithm to do some
    Feng> optimization. Within that E-step, I have to
    Feng> calculate some multivariate integration
    Feng> given some parameter values Theta and function form
    Feng> of a probability density function f.

    Feng> So I want to know if there are some package
    Feng> in R to do such numerical integration given such
    Feng> function form and parameter values?

There's the  adapt  package for multivariate integration.
I think it should solve your problem.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jrgonzalez at ico.scs.es  Tue Oct 29 09:17:19 2002
From: jrgonzalez at ico.scs.es (Juan Ramon Gonzalez)
Date: Tue, 29 Oct 2002 09:17:19 +0100
Subject: [R] new package survrec
Message-ID: <006b01c27f23$99911400$1100a8c0@ico.scs.es>

Dear R-Listers,

I would like to announce a new package called "survrec". The
package estimates the survival function for recurrent event data using
the estimators developed by Pena-Strawderman-Hollander (JASA, 2001) and
Wang-Chang (JASA, 1999). 

The name of the functions are similar to those of the
"survival" package, so they can be familiar to the R users.

Thanks,

Juan R Gonzalez
Cancer Prevention and Control Unit
Catalan Institut of Oncology, Barcelona (Spain)
Telf: 93 260 77 88
Homepage: http://rht.iconcologia.catsalut.net/jrg

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plummer at iarc.fr  Tue Oct 29 09:41:55 2002
From: plummer at iarc.fr (Martyn Plummer)
Date: 29 Oct 2002 09:41:55 +0100
Subject: [R] RE: RPMS of R for Red Hat 8.0
In-Reply-To: <000601c27eb7$2fd79e10$0201a8c0@MARC>
References: <000601c27eb7$2fd79e10$0201a8c0@MARC>
Message-ID: <1035880916.2143.27.camel@xena>

On Mon, 2002-10-28 at 20:21, Marc Schwartz wrote:
> > From: Martyn Plummer (plummer at iarc.fr)
> > Date: Mon Oct 28 2002 - 12:41:28 CET
> > 
> > A binary RPM package of R 1.6.0 for Red Hat 8.0 should now be 
> > available on a CRAN mirror near you. I apologize for the 
> > delay, but it took some time to get a copy of the new Red Hat release.
> > 
> > I shall continue to support Red Hat 7.x.
> > 
> > For the security conscious: in order to check the GPG 
> > signature on this package, you must first import my public 
> > key (1024D/97D3544E) into the RPM database. See the man page 
> > for rpm. This is a change from previous releases of Red Hat.
> > 
> > Martyn
> 
> Martyn,
> 
> I am just curious as the file size of the RPM that you posted is 11.6
> Mb, whereas the RPM that I compiled was only 10.8 Mb. 
> 
> Is there a different set of configuration options/steps that you use by
> default?  I have not yet found any errors, but there may be something I
> am missing.

Perhaps you did not create some of the documentation.  If you want to
investigate, you can extract the contents of an RPM file without 
installing it as follows

rpm2cpio R-1.6.0-1.i386.rpm | cpio -ivd
#This will extract the contents to the directory usr
cp usr usr2
#Now do the same with the other RPM

You can explore differences between the two directories with diff, e.g.

diff --recursive --brief usr usr2

will tell you if a file is present in only one directory.

Martyn

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From otoomet at econ.dk  Tue Oct 29 09:49:29 2002
From: otoomet at econ.dk (Ott Toomet)
Date: Tue, 29 Oct 2002 09:49:29 +0100
Subject: [R] pretty not pretty
Message-ID: <200210290849.g9T8nTV09317@localhost.localdomain>

Hi,

I have a following vector:

> smallch
 [1]  0.0652840  0.1181300  0.0319370  0.0155700  0.0464110  0.0107850
 [7]  0.0158970  0.0375900  0.0603090  0.0310300  0.0105920  0.0540580
[13] -0.0177740  0.0039393

Pretty (R 1.5.1) has problems with zero:

> pretty(smallch)
[1] -2.000000e-02 -3.469447e-18  2.000000e-02  4.000000e-02  6.000000e-02
[6]  8.000000e-02  1.000000e-01  1.200000e-01

You notice -3.46e-18 instead of 0.  Is this feature changed in 1.6.0,
or are there any simple ways to get around of it?

Ott



> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    5.1              
year     2002             
month    06               
day      17               
language R                

-- 
Ott Toomet
otoomet at econ.au.dk
---------------------------------------------------------

 (o_         (*_         (O_         (o< -!      (o<)<
//\         //\         //\         //\         //\
V_/_        V_/_        V_/_        V_/_        V_/_

standard    drunken     shocked     noisy      penguin
penguin     penguin     penguin     penguin    eating fish

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From petr.pikal at precheza.cz  Tue Oct 29 09:58:32 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 29 Oct 2002 09:58:32 +0100
Subject: [R] labels for scattered points
In-Reply-To: <20021028145137.A24450@creon.profinet.sk>
Message-ID: <3DBE5BC8.12198.BF48D9@localhost>

Hi

On 28 Oct 2002 at 14:51, Rado Bonk wrote:

> Hello,
> 
> I have a set of 70 geodata points. I would like to print them with its
> labels (z -value). (I played with points.geodata, however it only
> controls points size, pattern and color. Not labels.)
maybe something like

text(x,y,z,...)

can do the appropriate labeling

see ?text

> 
> Thanks,
> 
> Rado
> 
> -- 
> Radoslav Bonk M.S.
> Dept. of Physical Geography and Geoecology
> Faculty of Sciences, Comenius University
> Mlynska Dolina 842 15, Bratislava, SLOVAKIA
> tel: +421 2 602 96 250 e-mail: rbonk at host.sk
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.- r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help",
> or "[un]subscribe" (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.connolly at hortresearch.co.nz  Tue Oct 29 10:09:13 2002
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 29 Oct 2002 22:09:13 +1300
Subject: [R] Using the Search Engine & Keywords
In-Reply-To: <Pine.LNX.4.31.0210282113490.5708-100000@gannet.stats>
References: <20021028210459.GB27769@hortresearch.co.nz> <Pine.LNX.4.31.0210282113490.5708-100000@gannet.stats>
Message-ID: <20021029090913.GA537@hortresearch.co.nz>

On Tue, 29-Oct-2002 at 04:22AM +0000, ripley at stats.ox.ac.uk wrote:

|> On Tue, 29 Oct 2002, Patrick Connolly wrote:
|> 
|> > On Sat, 26-Oct-2002 at 06:04AM +0100, ripley at stats.ox.ac.uk wrote:
|> >
|> > |> 1) It uses Java, not just javascript.  You do have Java installed and
|> > |> enabled?  It does say in several places it is Java-based.
|> > |>
|> > |> 2) I have yet to see a Linux installation of R 1.6.0 where this did not
|> > |> work out of the box, although ours are all Red Hat.  I understood from the
|> >
|> > I use R 1,6,0 with Red Hat 7.3 and Mozilla 1.0 with java ostensibly
|> > enabled, but it doesn't start.  It works properly in li'l ol' Netscape 4.79.
|> >
|> > Any ideas where I should look to see why the two browsers behave so
|> > differently?  Is it simply a case of corrupted profiles?
|> 
|> We found that mozilla/Netscape 6.x/7.0 was much more security-conscious
|> than Netscape 4.x. I had to arrange to copy the class files (not link
|> them) to get Mozilla 1.0 to run under 7.2.  But that's been the case in R
|> since 1.5.1.  So security is one place to look.
|> 
|> I would check via a java-enabled site that java really is working.
|> I've found it tricky with Mozilla.  After that, there should be an error

Thanks for that, Brian.  It gets me started.

On a machine I have root access to, running RH7.3 and R 1.5.1 with
Mozilla 1.0, I get java pages to function properly.

|> message in the status bar when the search engine is run (or not).
|> 

The status bar tells me 'Done (0.591 sec)' but no message about
starting Java such as the one that Netscape gives, and no error
message about being unable to do so.

Does that indicate anything useful?


On my work machine where I don't have root access, it'll take me a lot
longer to work things out for reasons I won't bore anyone.  When I get
it to work on my own machine, I can tell those authorised what to do
to get it working on it too.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jan.wiener at tuebingen.mpg.de  Tue Oct 29 10:11:09 2002
From: jan.wiener at tuebingen.mpg.de (Jan Malte Wiener)
Date: Tue, 29 Oct 2002 10:11:09 +0100
Subject: [R] unix environment variables under R
Message-ID: <3DBE50AD.6040805@tuebingen.mpg.de>

hi,
i am working on a little R-project with a couple od other guys.we use 
CVS, but everyone keeps the R-source files in different locations in his 
home-directory. of course this causes trouble when sourcing R-files. i 
thought a UNIX environment variable could be the solution, but R doesn't 
seem to know about the environment variables.
e.g. >> source("$PROJECT/xxx.R") results in
 >> Error in file(file, "r") : unable to open connection

is there something like environment variables for R?

greetinx jan

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregor.gawron at rmf.ch  Tue Oct 29 10:34:17 2002
From: gregor.gawron at rmf.ch (Gregor Gawron)
Date: Tue, 29 Oct 2002 10:34:17 +0100 (MET)
Subject: [R] Date: Tue, 29 Oct 2002 10:34:07 +0100
Message-ID: <3635AAE6EA743844B05655F805CB3125DB86DE@titlis.rmf.ch>

Dear all,

I am applying the StructTS function in ts-package. For some time series
the program terminates and the following error appears:

Error in optim(init[mask], getLike, method = "L-BFGS-B", lower = rep(0,
: 
        L-BFGS-B needs finite values of fn

Do someone know what do I have to adjust in the original time series to
avoid this error? It works fine for some subsets of the time series
only.

Thank you in advance. 
---
Gregor Gawron

 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregor.gawron at rmf.ch  Tue Oct 29 10:40:39 2002
From: gregor.gawron at rmf.ch (Gregor Gawron)
Date: Tue, 29 Oct 2002 10:40:39 +0100
Subject: [R] StructTS
Message-ID: <3635AAE6EA743844B05655F805CB312502E15DED@titlis.rmf.ch>

Dear all,

I am applying the StructTS function in ts-package. For some time series
the program terminates and the following error appears:

Error in optim(init[mask], getLike, method = "L-BFGS-B", lower = rep(0,
: 
        L-BFGS-B needs finite values of fn

Do someone know what do I have to adjust in the original time series to
avoid this error? It works fine for some subsets of the time series
only.

Thank you in advance. 
---
Gregor Gawron


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From AlessandroSemeria at cramont.it  Tue Oct 29 11:50:28 2002
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Tue, 29 Oct 2002 11:50:28 +0100
Subject: [R] distributions homogeneity
Message-ID: <OF2CF18E51.CD349005-ONC1256C61.003443BE@tomware.it>

Hello dear R-list! I have to test if N (non linear)  experimantal
distributions fit some of known one. I would proceed in this
way:
1. Fit with 'nlm' and e.g. power law one ( non outlier) distribution of
mine.
2. Perform 'chisq.test' for each pairs (power law ,distribution(i))
but I'm neither a statistician nor a skilled on R, so I think that surely
ther'is
some other way, more telling and efficient, to perform this job.
Thanks in advance for any suggestion!
--------------------------
Sincerely yours.

Dr. Alessandro Semeria                             Tel. +39 544 536811
Models and Simulation Lab of                                 Fax. +39 544
538663
The Environment Research Center - Montecatini (Edison Group),
E-mail: asemeria at cramont.it
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Mon Oct 28 23:12:34 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 29 Oct 2002 11:12:34 +1300
Subject: [R] unix environment variables under R
In-Reply-To: <3DBE50AD.6040805@tuebingen.mpg.de>; from jan.wiener@tuebingen.mpg.de on Tue, Oct 29, 2002 at 10:11:09AM +0100
References: <3DBE50AD.6040805@tuebingen.mpg.de>
Message-ID: <20021029111234.B10632@camille.indigoindustrial.co.nz>

On Tue, Oct 29, 2002 at 10:11:09AM +0100, Jan Malte Wiener wrote:
...
> thought a UNIX environment variable could be the solution, but R doesn't 
> seem to know about the environment variables.
> e.g. >> source("$PROJECT/xxx.R") results in
>  >> Error in file(file, "r") : unable to open connection
> 
> is there something like environment variables for R?

Yep.  Sys.getenv()

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jan.wiener at tuebingen.mpg.de  Tue Oct 29 12:37:53 2002
From: jan.wiener at tuebingen.mpg.de (Jan Malte Wiener)
Date: Tue, 29 Oct 2002 12:37:53 +0100
Subject: [R] unix environment variables under R
References: <3DBE50AD.6040805@tuebingen.mpg.de> <20021029111234.B10632@camille.indigoindustrial.co.nz>
Message-ID: <3DBE7311.2000301@tuebingen.mpg.de>

Jason Turner wrote:
> On Tue, Oct 29, 2002 at 10:11:09AM +0100, Jan Malte Wiener wrote:
> ...
> 
>>thought a UNIX environment variable could be the solution, but R doesn't 
>>seem to know about the environment variables.
>>e.g. >> source("$PROJECT/xxx.R") results in
>> >> Error in file(file, "r") : unable to open connection
>>
>>is there something like environment variables for R?
> 
> 
> Yep.  Sys.getenv()
> 
> Cheers
> 
> Jason

thanks for your answer,
but how do i source a file using that environment variable; if the 
environment variable holds a path to a directory and i want to source a 
file within that directory??
e.g.:
Sys.putenv("ABC"="~/R-Stuff/")
in ~/R-Stuff there a bunch of R-files
now i want to source one of these R-files using the ABC environment 
variable.
sorry, but i do not know how to do this ?

greetinx jan

-- 
Jan Malte Wiener
Max-Planck-Institute for Biological Cybernetics
Spemannstr. 38, 72076 Tuebingen, Germany
Tel.: +49 7071 601 631
Email: jan.wiener at tuebingen.mpg.de

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jan.wiener at tuebingen.mpg.de  Tue Oct 29 12:42:22 2002
From: jan.wiener at tuebingen.mpg.de (Jan Malte Wiener)
Date: Tue, 29 Oct 2002 12:42:22 +0100
Subject: [R] sourcing the content of directories 
Message-ID: <3DBE741E.9020105@tuebingen.mpg.de>

hi,
is there a way to source all R-files that reside in a given directory 
with a single R-call ?
greetinx jan

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gavin.simpson at ucl.ac.uk  Tue Oct 29 12:46:49 2002
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 29 Oct 2002 11:46:49 -0000
Subject: [R] changing coordinates?
In-Reply-To: <3DBDAB0E.3070304@oeko-sorpe.de>
Message-ID: <000c01c27f40$ddfcec50$4c202880@gsimpson>

Hi Richard

It doesn't matter whether you use rows for the x or the y axis.  The
plot commands take sets of data points.  Pass plot two vectors for x and
y and you get your plot.  So if, for example, depth is your "x-axis",
but you want it where the "y-axis" is and you want to plot some data
against it (oxygen profile) then:

plot(x = o2, y = depth) #where o2 and depth are rows or columns of a
data frame, matrix, or two vectors.

Now, I'm a (palaeo)limnologist and we often want y-axis to start from 0
at the top left like you do.  The beauty of R (over some of the other
stratigraphic plotting tools I have had the misfortune to use over the
years) is that you can very simply tell plot() what the axis should be
ranged like:

o2 <- c(1, 5, 6, 8, 10, 2, 3, 4, 8, 9, 15, 10, 4, 7, 3) # made-up o2
profile (random typing ;-) )
depth <- c(0:14) # depth in m from 0m to 14m

plot(x = o2, y = depth, ylim = c(14, 0) + 0.1, type="b", main="O2
profile for Foo Lake") 

If you want to pop the "x-axis" (o2) labels along the top rather than
the default (bottom) then something like this will work:

oldpar <- par(mar = c(3, 4, 5, 2) + 0.1) # give a larger top and smaller
bottom margins
plot(x = o2, y = depth, ylim = c(14, 0) + 0.1, type="b", main="O2
profile for Foo Lake",
	axes = FALSE) #don't plot the axes
axis(side = 2)	# plot the left axis
axis(side = 3)	# plot the top axis
box()			# finish off with a box round the plot
par(oldpar)		# reset margins

So as you can see R's graphics are very flexible and can be made to do
what you want (mostly!).  And that's without getting into lattice()
graphics.

I suggest that you have a look at the Introduction to R manual from CRAN
(under documentation) and read the plotting section for an overview of
what is possible.  Or see one of the Contributed texts (e.g.
Maindonald's "Using R for Data Analysis and Graphics").

Almost every graphics or plotting requirement I have had to do with my
PhD data I have been able to do it in R.  The only thing I couldn't do
was plot vertical dendrograms to finish off an image() plot with
separate dendrograms along the top and the left of the plotting area,
but this has now been added to the functionality of R (from 1.6.0).

Gav


%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

-----Original Message-----
From: owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch] On Behalf Of Richard Mueller
Sent: 28 October 2002 21:25
To: r-help at stat.math.ethz.ch
Subject: [R] changing coordinates?


I just detected R and have, after browsing the manual, one question:
I look for quite a lot of time for graphical software which allows to 
plot data from a table or external file _with the axes of the coordinate

system changed_, i.e. the x-axis should run from top left to bottom 
left, and the y-axis from top-left to top-right. It is of no use to 
interchange the rows in the table, the coordinate system should rely of 
that definition. This type of plot is used in limnological and 
oceanological graphs. Until now I could find no software which can do 
that job. Perhaps one of you can answer this beginner's question with a 
simple yes or no?
Thank you, Richard

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-.-
r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From spahes at joho-shimane.or.jp  Tue Oct 29 13:02:26 2002
From: spahes at joho-shimane.or.jp (Shimane Chikushi)
Date: Tue, 29 Oct 2002 21:02:26 +0900
Subject: [R] The Odds ratio of interactive value
Message-ID: <000201c27f43$20ac62e0$6c00a8c0@vaiotower>

Dear all,

Can R estimate the Odds Ratio of interactive values?
For instance,

glm(y~a+b+a:b,binomial,data,...)

The Odds Ratio about a:b.

Thanks in advance,

Saw

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From erich.neuwirth at univie.ac.at  Tue Oct 29 13:16:40 2002
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Tue, 29 Oct 2002 13:16:40 +0100
Subject: [R] R as a library
References: <OF0EB9B092.CF39FE1A-ON86256C60.007E8F9C@mmm.com>
Message-ID: <3DBE7C28.6000508@univie.ac.at>

If you are willing to be restricted to the Windows platform ONLY for 
this project, using Thomas Baier's R-(D)COM Interface server is a possible way 
to go.
It is available in the Other section on CRAN.



apjaworski at mmm.com wrote:

>I would like to write a stand-alone application (in C) using R's
>statistical and graphical capabilities.  To make it more challenging I
>would have to do it using Windows 2000 platform.  I seem to remember that R
>can be compiled into a library of subroutines and linked to an external
>program.  Is this true or is my memory playing tricks on me?  I scanned the
>FAQs and the "extensions" manual but could not find anything about it.
>  
>

-- 
--
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Oct 29 13:33:24 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Oct 2002 13:33:24 +0100
Subject: [R] unix environment variables under R
In-Reply-To: <3DBE7311.2000301@tuebingen.mpg.de>
References: <3DBE50AD.6040805@tuebingen.mpg.de>
	<20021029111234.B10632@camille.indigoindustrial.co.nz>
	<3DBE7311.2000301@tuebingen.mpg.de>
Message-ID: <x2bs5da0h7.fsf@biostat.ku.dk>

Jan Malte Wiener <jan.wiener at tuebingen.mpg.de> writes:


> thanks for your answer,
> but how do i source a file using that environment variable; if the
> environment variable holds a path to a directory and i want to source
> a file within that directory??
> e.g.:
> Sys.putenv("ABC"="~/R-Stuff/")
> in ~/R-Stuff there a bunch of R-files
> now i want to source one of these R-files using the ABC environment
> variable.
> sorry, but i do not know how to do this ?

As in

> file.path(Sys.getenv("HOME"),"foo.R")
[1] "/home/sfe/pd/foo.R"



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Roger.Bivand at nhh.no  Tue Oct 29 13:36:36 2002
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 29 Oct 2002 13:36:36 +0100 (CET)
Subject: [R] unix environment variables under R
In-Reply-To: <3DBE50AD.6040805@tuebingen.mpg.de>
References: <3DBE50AD.6040805@tuebingen.mpg.de>
Message-ID: <32825.213.236.167.186.1035894996.squirrel@webmail.nhh.no>


> hi,
> i am working on a little R-project with a couple od other guys.we use
> CVS, but everyone keeps the R-source files in different locations in his
>  home-directory. of course this causes trouble when sourcing R-files. i
> thought a UNIX environment variable could be the solution, but R doesn't
>  seem to know about the environment variables.
> e.g. >> source("$PROJECT/xxx.R") results in
>  >> Error in file(file, "r") : unable to open connection
>
> is there something like environment variables for R?

?Sys.getenv

very useful for passing things into an R session.

>
> greetinx jan
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help", or
> "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
Roger Bivand
NHH, Breiviksveien 40, N-5045 Bergen, Norway
(travelling but still accessible)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From partha_bagchi at hgsi.com  Tue Oct 29 14:21:14 2002
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue, 29 Oct 2002 08:21:14 -0500
Subject: [R] unix environment variables under R
Message-ID: <OF188FAFC8.FF88FB84-ON85256C61.00490594@hgsi.com>

One way to do this would be to change to the $PROJECT directory and then 
use source. For example:

> setwd(Sys.getenv("PROJECT"))
> source("xxx.R")

If you wish to remain the current directory after executing the souce then 
save the current location with:

> currdir <- getwd()

Then after sourcing change back to the current directory:

> setwd (currdir)

So the sequence of commands could be:

> currdir <- getwd()
> setwd(Sys.getenv("PROJECT"))
> source("xxx.R")
> setwd (currdir)

HTH,
Partha.





Jan Malte Wiener <jan.wiener at tuebingen.mpg.de>
Sent by: owner-r-help at stat.math.ethz.ch
10/29/2002 06:37 AM

 
        To:     Jason Turner <jasont at indigoindustrial.co.nz>, R <r-help at stat.math.ethz.ch>
        cc: 
        Subject:        Re: [R] unix environment variables under R


Jason Turner wrote:
> On Tue, Oct 29, 2002 at 10:11:09AM +0100, Jan Malte Wiener wrote:
> ...
>
>>thought a UNIX environment variable could be the solution, but R doesn't
>>seem to know about the environment variables.
>>e.g. >> source("$PROJECT/xxx.R") results in
>> >> Error in file(file, "r") : unable to open connection
>>
>>is there something like environment variables for R?
>
>
> Yep.  Sys.getenv()
>
> Cheers
>
> Jason

thanks for your answer,
but how do i source a file using that environment variable; if the
environment variable holds a path to a directory and i want to source a
file within that directory??
e.g.:
Sys.putenv("ABC"="~/R-Stuff/")
in ~/R-Stuff there a bunch of R-files
now i want to source one of these R-files using the ABC environment
variable.
sorry, but i do not know how to do this ?

greetinx jan

--
Jan Malte Wiener
Max-Planck-Institute for Biological Cybernetics
Spemannstr. 38, 72076 Tuebingen, Germany
Tel.: +49 7071 601 631
Email: jan.wiener at tuebingen.mpg.de

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Detlef.Steuer at unibw-hamburg.de  Tue Oct 29 14:21:55 2002
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Tue, 29 Oct 2002 14:21:55 +0100 (CET)
Subject: [R] unix environment variables under R
In-Reply-To: <3DBE50AD.6040805@tuebingen.mpg.de>
Message-ID: <XFMail.20021029142155.steuer@unibw-hamburg.de>

Hi!

Sys.getenv() does the job.

detlef

On 29-Oct-2002 Jan Malte Wiener wrote:
> hi,
> i am working on a little R-project with a couple od other guys.we use 
> CVS, but everyone keeps the R-source files in different locations in his 
> home-directory. of course this causes trouble when sourcing R-files. i 
> thought a UNIX environment variable could be the solution, but R doesn't 
> seem to know about the environment variables.
> e.g. >> source("$PROJECT/xxx.R") results in
>  >> Error in file(file, "r") : unable to open connection
> 
> is there something like environment variables for R?
> 
> greetinx jan
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _

"There is no way to peace, peace is the way." -- Ghandi

Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 29 14:38:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 29 Oct 2002 13:38:02 +0000 (GMT)
Subject: [R] StructTS
In-Reply-To: <3635AAE6EA743844B05655F805CB312502E15DED@titlis.rmf.ch>
Message-ID: <Pine.LNX.4.31.0210291337360.7811-100000@gannet.stats>

On Tue, 29 Oct 2002, Gregor Gawron wrote:

> Dear all,
>
> I am applying the StructTS function in ts-package. For some time series
> the program terminates and the following error appears:
>
> Error in optim(init[mask], getLike, method = "L-BFGS-B", lower = rep(0,
> :
>         L-BFGS-B needs finite values of fn
>
> Do someone know what do I have to adjust in the original time series to
> avoid this error? It works fine for some subsets of the time series
> only.

Specify init in your call to StructTS.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From clists at perrin.socsci.unc.edu  Tue Oct 29 15:08:23 2002
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Tue, 29 Oct 2002 09:08:23 -0500 (EST)
Subject: [R] glmm for binomial data? (OT)
In-Reply-To: <200210281559.30907@LINUXROCKS>
Message-ID: <Pine.LNX.4.21.0210290907520.29298-100000@perrin.socsci.unc.edu>

I used glmmPQL to estimate multilevel (3-level) probit models.  I can try
to dig up the code if you're interested.

Andy Perrin

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu


On Mon, 28 Oct 2002, Damien O. Joly wrote:

> A while ago (April 2002) there was a short thread on software for generalized 
> linear mixed models. 
> 
> Since that time, has anyone written or found R code to use a glmm to analyze 
> binomial data?  I study CWD in white-tailed deer, and I'd like to do a 
> similar analysis as Kleinschmidt et al. (2001, Am. J. Epidemiology 153: 
> 1213-1221) used to assess control for spatial structure in malaria incidence 
> in South Africa.  They used SAS PROC MIXED in an iterative procedure with a 
> poisson model, although due to widely varying sample sizes I'd prefer to 
> treat my data as binomial (e.g., CWD pos or neg rather than number of CWD pos 
> deer).
> 
> Thanks,
> 
> Damien
> -- 
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pwolf at wiwi.uni-bielefeld.de  Tue Oct 29 15:17:05 2002
From: pwolf at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Tue, 29 Oct 2002 15:17:05 +0100
Subject: [R] unix environment variables under R
Message-ID: <3DBE9860.BA686A51@wiwi.uni-bielefeld.de>


Jan Malte Wiener wrote:

>hi,
>i am working on a little R-project with a couple od other guys.we use
>CVS, but everyone keeps the R-source files in different locations in
his
>home-directory. of course this causes trouble when sourcing R-files. i
>thought a UNIX environment variable could be the solution, but R
doesn't
>seem to know about the environment variables.
>e.g. >> source("$PROJECT/xxx.R") results in
> >> Error in file(file, "r") : unable to open connection
>
>is there something like environment variables for R?

What about:

> paste(system("echo $HOME",T),"sourcefile.r",sep="/")

or

> source(paste(system("echo $HOME",T),"sourcefile.r",sep="/"))

Peter Wolf

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Roger.Bivand at nhh.no  Tue Oct 29 15:22:26 2002
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 29 Oct 2002 15:22:26 +0100 (CET)
Subject: [R] unix environment variables under R
In-Reply-To: <3DBE7311.2000301@tuebingen.mpg.de>
References: <3DBE50AD.6040805@tuebingen.mpg.de>
        <20021029111234.B10632@camille.indigoindustrial.co.nz>
        <3DBE7311.2000301@tuebingen.mpg.de>
Message-ID: <62219.129.177.44.49.1035901346.squirrel@webmail.nhh.no>


> Jason Turner wrote:
>> On Tue, Oct 29, 2002 at 10:11:09AM +0100, Jan Malte Wiener wrote: ...
>>
>>>thought a UNIX environment variable could be the solution, but R
>>> doesn't  seem to know about the environment variables.
>>>e.g. >> source("$PROJECT/xxx.R") results in
>>> >> Error in file(file, "r") : unable to open connection
>>>
>>>is there something like environment variables for R?
>>
>>
>> Yep.  Sys.getenv()
>>
>> Cheers
>>
>> Jason
>
> thanks for your answer,
> but how do i source a file using that environment variable; if the
> environment variable holds a path to a directory and i want to source a
> file within that directory??
> e.g.:
> Sys.putenv("ABC"="~/R-Stuff/")
> in ~/R-Stuff there a bunch of R-files
> now i want to source one of these R-files using the ABC environment
> variable.
> sorry, but i do not know how to do this ?

Using your initial example, the shell variable PROJECT is set before you
start R, isn't it?

$ PROJECT=~/tmp ; export PROJECT
$ echo $PROJECT
/home/zzz/tmp
$ R
> proj <- Sys.getenv("PROJECT")
> proj
        PROJECT
"/home/zzz/tmp"
> source(paste(proj, "/xxx.R", sep=""))

or at your choice:

> getwd()
[1] "/home/xxx"
> setwd(proj)
NULL
> getwd()
[1] "/home/xxx/tmp"
> source("xxx.R")

This are two answers to your first question, but your response makes it
look as though this wasn't your actual question, since you seem to know
that the files are in "~/R-Stuff" anyway? I think you have many machines,
with the R files in different directories for different users. Then
defining the shell variable PROJECT for each user on the various machines
to point to the correct directory for that user and machine should fix it,
as Jason pointed out. Then use Sys.getenv() to retrieve the value of the
shell variable, as shown above.

Roger

-- 
Roger Bivand
NHH, Breiviksveien 40, N-5045 Bergen, Norway
(travelling but still accessible)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Oct 29 15:50:51 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 29 Oct 2002 15:50:51 +0100
Subject: [R] Nonlinear time series
In-Reply-To: <200210281414.IAA15189@uhddx01.dt.uh.edu>
References: <200210281414.IAA15189@uhddx01.dt.uh.edu>
Message-ID: <15806.41035.115725.86064@gargle.gargle.HOWL>

>>>>> "Erin" == Erin Hodgess <hodgess at uhddx01.dt.uh.edu>
>>>>>     on Mon, 28 Oct 2002 08:14:32 -0600 (CST) writes:

    Erin> Dear R People:
    Erin> Is there code for nonlinear time series available, please?

"nonlinear" := "anything not linear"
(which is a lot).
Do you mean parametric / non-parametric?
What is the field of application?

The new StructTS() functionality in R's "ts" package can also a
be considered nonlinear. See also Prof Brian Ripley's article in
the latest R News.


    Erin> I'm looking for something that could also provide a model for
    Erin> forecasts.

    Erin> This is for R V1.5.1 on a PC.

There's our  VLMC  package for Variable Length Markov Chains.  
It models very general (non-linear) time series which
__however__ have to have values 
in a small finite set, i.e. X_t \in  {x_1, x_2, ..., x_K}.

For the current implementation, mostly K <= 26 since we are using the
alphabet in several places to represent the values.
The success stories where mostly for K=2 (binary time series) or
also K=4 for DNA-modeling.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregor.gawron at rmf.ch  Tue Oct 29 15:58:17 2002
From: gregor.gawron at rmf.ch (Gregor Gawron)
Date: Tue, 29 Oct 2002 15:58:17 +0100
Subject: [R] StructTS
Message-ID: <3635AAE6EA743844B05655F805CB312502E15DEE@titlis.rmf.ch>

Thank you, it have helped.

P.s. I have forgotten to give the subject name. That's way I have posted
the question twice.

-----Original Message-----
From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk] 
Sent: Dienstag, 29. Oktober 2002 14:38
To: Gregor Gawron
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] StructTS


On Tue, 29 Oct 2002, Gregor Gawron wrote:

> Dear all,
>
> I am applying the StructTS function in ts-package. For some time 
> series the program terminates and the following error appears:
>
> Error in optim(init[mask], getLike, method = "L-BFGS-B", lower = 
> rep(0,
> :
>         L-BFGS-B needs finite values of fn
>
> Do someone know what do I have to adjust in the original time series 
> to avoid this error? It works fine for some subsets of the time series

> only.

Specify init in your call to StructTS.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 29 16:02:54 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 29 Oct 2002 15:02:54 +0000 (GMT)
Subject: [R] unix environment variables under R
In-Reply-To: <3DBE7311.2000301@tuebingen.mpg.de>
Message-ID: <Pine.LNX.4.31.0210291501090.23761-100000@gannet.stats>

source(file.path(Sys.getenv("PROJECT"), "xxx.R"))

and please try not to expect sloppy sh-shell programming to work
in any other language.

On Tue, 29 Oct 2002, Jan Malte Wiener wrote:

> Jason Turner wrote:
> > On Tue, Oct 29, 2002 at 10:11:09AM +0100, Jan Malte Wiener wrote:
> > ...
> >
> >>thought a UNIX environment variable could be the solution, but R doesn't
> >>seem to know about the environment variables.
> >>e.g. >> source("$PROJECT/xxx.R") results in
> >> >> Error in file(file, "r") : unable to open connection
> >>
> >>is there something like environment variables for R?
> >
> >
> > Yep.  Sys.getenv()
> >
> > Cheers
> >
> > Jason
>
> thanks for your answer,
> but how do i source a file using that environment variable; if the
> environment variable holds a path to a directory and i want to source a
> file within that directory??
> e.g.:
> Sys.putenv("ABC"="~/R-Stuff/")
> in ~/R-Stuff there a bunch of R-files
> now i want to source one of these R-files using the ABC environment
> variable.
> sorry, but i do not know how to do this ?
>
> greetinx jan
>
> --
> Jan Malte Wiener
> Max-Planck-Institute for Biological Cybernetics
> Spemannstr. 38, 72076 Tuebingen, Germany
> Tel.: +49 7071 601 631
> Email: jan.wiener at tuebingen.mpg.de
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 29 16:04:21 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 29 Oct 2002 15:04:21 +0000 (GMT)
Subject: [R] sourcing the content of directories 
In-Reply-To: <3DBE741E.9020105@tuebingen.mpg.de>
Message-ID: <Pine.LNX.4.31.0210291503300.23761-100000@gannet.stats>

On Tue, 29 Oct 2002, Jan Malte Wiener wrote:

> hi,
> is there a way to source all R-files that reside in a given directory
> with a single R-call ?

Yes, write a function using list.files() to list them, then a for loop or
lapply along the list.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Oct 29 16:28:43 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 29 Oct 2002 16:28:43 +0100
Subject: [R] sourcing the content of directories
References: <3DBE741E.9020105@tuebingen.mpg.de>
Message-ID: <3DBEA92B.B0B257A0@statistik.uni-dortmund.de>

Jan Malte Wiener wrote:
> 
> hi,
> is there a way to source all R-files that reside in a given directory
> with a single R-call ?
> greetinx jan

This should do the trick:

 direct <- "/given/directory"
 temp <- dir(direct)
 sapply(paste(direct, temp[grep("[.]R$", temp)], sep = "/"), source)

BTW: Consider to create your own package, if you have a couple of files
you are going to source frequently...

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Tue Oct 29 16:13:04 2002
From: brahm at alum.mit.edu (David Brahm)
Date: Tue, 29 Oct 2002 10:13:04 -0500
Subject: [R] Combining simulation results
In-Reply-To: <59574335@toto.iv>
Message-ID: <15806.42368.353280.864785@gargle.gargle.HOWL>

Murray Jorgensen <maj at waikato.ac.nz> wants to combine two arrays, each of dim:
> > dim(resarray)
> [1]  10   6 500   3
into one array of dim c(10, 6, 1000, 3).

A function called "abind" on StatLib <http://lib.stat.cmu.edu/S/abind> does
exactly this, at least in S-Plus.  I have not tried it in R.
-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Tue Oct 29 16:31:17 2002
From: brahm at alum.mit.edu (David Brahm)
Date: Tue, 29 Oct 2002 10:31:17 -0500
Subject: [R] pretty not pretty
Message-ID: <15806.43461.675233.576774@gargle.gargle.HOWL>

Ott Toomet <otoomet at econ.au.dk> wrote:
> Pretty (R 1.5.1) has problems with zero: 
  > pretty(smallch) 
  [1] -2.000000e-02 -3.469447e-18 2.000000e-02 4.000000e-02 6.000000e-02 
  [6] 8.000000e-02 1.000000e-01 1.200000e-01 
> You notice -3.46e-18 instead of 0. Is this feature changed in 1.6.0, 
> or are there any simple ways to get around of it? 

I mentioned this in R-devel on June 14, 2002 ("pretty() sometimes isn't").  It
derives from the roundoff error introduced in seq(-.02, .12, length=8).  I
suggested that the last line of the code for pretty() should get a zapsmall()
around it:
  pretty <- function(...) {
    ...
    zapsmall(seq(z$l, z$u, length = z$n + 1))
  }

Since that hasn't been implemented, you could simply put a zapsmall() around
every pretty() in your code.
-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Oct 29 16:32:14 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 29 Oct 2002 16:32:14 +0100
Subject: [R] unix environment variables under R
References: <3DBE50AD.6040805@tuebingen.mpg.de> <20021029111234.B10632@camille.indigoindustrial.co.nz> <3DBE7311.2000301@tuebingen.mpg.de>
Message-ID: <3DBEA9FE.33D3D39E@statistik.uni-dortmund.de>



Jan Malte Wiener wrote:
> 
> Jason Turner wrote:
> > On Tue, Oct 29, 2002 at 10:11:09AM +0100, Jan Malte Wiener wrote:
> > ...
> >
> >>thought a UNIX environment variable could be the solution, but R doesn't
> >>seem to know about the environment variables.
> >>e.g. >> source("$PROJECT/xxx.R") results in
> >> >> Error in file(file, "r") : unable to open connection
> >>
> >>is there something like environment variables for R?
> >
> >
> > Yep.  Sys.getenv()
> >
> > Cheers
> >
> > Jason
> 
> thanks for your answer,
> but how do i source a file using that environment variable; if the
> environment variable holds a path to a directory and i want to source a
> file within that directory??
> e.g.:
> Sys.putenv("ABC"="~/R-Stuff/")
> in ~/R-Stuff there a bunch of R-files
> now i want to source one of these R-files using the ABC environment
> variable.
> sorry, but i do not know how to do this ?

 directory <- Sys.getenv("ABC")
 source(paste(directory, "anRfile.R", sep = ""))

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Oct 29 17:38:08 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 29 Oct 2002 08:38:08 -0800 (PST)
Subject: [R] sourcing the content of directories 
In-Reply-To: <3DBE741E.9020105@tuebingen.mpg.de>
Message-ID: <Pine.A41.4.44.0210290835170.32274-100000@homer18.u.washington.edu>

On Tue, 29 Oct 2002, Jan Malte Wiener wrote:

> hi,
> is there a way to source all R-files that reside in a given directory
> with a single R-call ?


  lapply(list.files(dirname, pattern="\\.R$"), "source", local=FALSE)

or more simply (but not a single call)

  for(name in list.files(dirname, pattern="\\.R$"))
	source(name)

This will source() them in lexicographic order.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Tue Oct 29 17:34:29 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Tue, 29 Oct 2002 11:34:29 -0500
Subject: PCA with n << p (was [R] R-1.6.0 crashing on RedHat6.3)
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20149D14A@groexmb02.pfizer.com>

	      [Moderator's Note: This message needed manual interaction by me,
	       since the attachment originally was declared as
	        ``application/octet-stream'' even though it was only plain
	       text.  We do not allow octet-stream (aka binary!)
	       attachments on our mailing list -- for virus/spam filtering
	       reasons.  -- MM]

We have also encountered the problem Douglas discusses with prcomp.
Unfortunately, svd() function used by both R and S-Plus is very
inefficient when passed matrix that is very wide, but is very fast
when passed the transpose of  the same matrix.

Attached is a small file that resolved the problem for us.  It
defines two functions, fast.prcomp()  and fast.svd().

fast.svd() is simply a wrapper around the regular svd() that
checks if the number of columns is larger than the number of
rows.  If this is the case, it transposes everything, calls
svd, and then transposes back.  Otherwise it just calls svd
and returns the results.

fast.prcomp() is simply the R prcomp() function  from the mds
library modified to call fast.svd().   This allows it to be
used without worrying about whether the matrix is long (cluster chips)
or wide (cluster probesets).

I've tested this code on R 1.5.1, 1.6.0 and on S-Plus 2000.

-Greg


> -----Original Message-----
> From: Douglas Grove [mailto:dgrove at fhcrc.org]
> Sent: Tuesday, October 29, 2002 1:59 AM
> To: ripley at stats.ox.ac.uk
> Cc: Peter Dalgaard BSA; r-help at stat.math.ethz.ch
> Subject: Re: PCA with n << p (was [R] R-1.6.0 crashing on RedHat6.3)
>
>
> > princomp is the wrong tool here: prcomp is better (and a
> version using
> > La.svd would be better still).
>
> Okay. I used princomp as I saw something in your book regarding using
> this and NOT prcomp in S-plus, I thought the same would hold in R.
>
>
>
> > What do you want to do with a PCA of such a matrix?  We can almost
> > certainly give you a better way using La.svd directly.
>
> Looking at microarray data with approx. 5300 'genes' and 144 samples
> (72 control, 72 experimental).  Trying to see how well principal
> components can separate the different tissue types (Liver,
> Kidney, Testis)
> making up the samples.
>
> In any case, this code is just an example of the problem we're having
> with R (and S-plus) crashing with memory allocation related errors.
> I used this code since no one could poke holes in it :-)
>
> Thanks for the info on prcomp.  I'll try it out.
>
> Doug
>
>
>
> > BDR
> >
> > On 28 Oct 2002, Peter Dalgaard BSA wrote:
> >
> > > Douglas Grove <dgrove at fhcrc.org> writes:
> > >
> > > > > Are you sure that it is 6.3?? To my knowledge, there
> is nothing
> > > > > between 6.2 and 7.0. What's in /etc/redhat-release ?
> > > >
> > > > Sorry, I was told it was running 6.3. I just checked and
> > > > it's running 6.2.
> > >
> > > OK, so the Fortran problems are there, but the usual
> symptom of that
> > > is crash-on-load.
> > >
> > >
> > > > > The Fortran in RH6.x was rather badly broken for some
> packages, but
> > > > > one would expect that you had run into that before.
> 1.6.0 has a memory
> > > > > leak but it generally affects repeated applications
> of model fits,
> > > > > rather than big matrices.
> > > > >
> > > > > Do you really mean 144x5300 ? (more columns than
> rows) That's big: The
> > > > > covariance matrix at 5300x5300 will take more than
> 200 MB (OK, it
> > > > > might only be storing upper or lower triangle.) I
> tried a matrix like
> > > > > that on a 1.6.1beta system with about 0.75 GB and got
> an out of memory
> > > > > error. A 144x2500 problem is currently running in
> > > > >
> > > > >   PID USER     PRI  NI  SIZE  RSS SHARE STAT %CPU
> %MEM   TIME COMMAND
> > > > > 16111 pd        17   0  207M 163M 18536 R    99.8
> 65.8   1:58 R.bin
> > > > >
> > > > > and seems to be staying there....
> > > >
> > > > Yep, it's 144x5300.  The machine has 2GB of RAM, and
> this uses about 1.5GB.
> > >
> > > Hmm. My half-size toy version conked out with
> > >
> > > > D <- matrix(rnorm(2500*144),ncol=2500)
> > > > library(mva)
> > > > pc.norm <- princomp(D,scores=FALSE)
> > > Error in princomp.default(D, scores = FALSE) :
> > >         covariance matrix is not non-negative definite
> > >
> > > which is a bit odd, but at least it didn't run out of
> memory. However,
> > > the tolerances seem to require some tweaking!
> > >
> > > --
> > >    O__  ---- Peter Dalgaard             Blegdamsvej 3
> > >   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
> > >  (*) \(*) -- University of Copenhagen   Denmark      Ph:
> (+45) 35327918
> > > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX:
> (+45) 35327907
> > >
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> > > r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > > Send "info", "help", or "[un]subscribe"
> > > (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> > >
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> > >
> >
> >
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
>



LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fast.prcomp.R
Type: plain/text
Size: 2020 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021029/e6190a76/fast.prcomp.bin

From bm8 at st-andrews.ac.uk  Tue Oct 29 18:19:58 2002
From: bm8 at st-andrews.ac.uk (Bernie McConnell)
Date: Tue, 29 Oct 2002 17:19:58 +0000
Subject: [R] RODBC blues
Message-ID: <5.1.0.14.0.20021029171843.00aaecc0@bute.st-and.ac.uk>

Good Day,

  Perhaps I have missed a posting but ...  I cannot find the RODBC package on
  cran at www.stats.bris.ac.uk/R/.

  Many thanks

Bernie McConnell

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From elvis at xlsolutions-corp.com  Tue Oct 29 18:45:16 2002
From: elvis at xlsolutions-corp.com (Elvis Miller, PhD)
Date: Tue, 29 Oct 2002 12:45:16 -0500
Subject: [R] Course *** R/S-plus Fundamentals and Programming Techniques, November 21-22, Princeton - New Jersey
Message-ID: <200210291745.g9THjGs46435@email.featureprice.com>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud
to announce a 2-day course: "R/S-plus Fundamentals and Programming Techniques".

****Princeton, NJ-----------------> November 21-22


Course Description:

This two-day R/S-plus course focuses on a broad spectrum of topics, 
from reading raw data to a comparison of R and S. We will learn 
the essentials of data manipulation, graphical visualization 
and R/S-plus programming. We will explore statistical data analysis tools,
including graphics with data sets. How to enhance your plots.
We will perform basic statistics and fit linear regression models. Participants are encouraged to bring data for interactive sessions


Course Outline:

- An Overview of R: Installation and Demonstration
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling 
- Generalized Linear Models
- Linear Regression
- Parametric Models, etc
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)



Payments are due AFTER the course and early-bird ends October 31.

Registration:

Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578 x221
Visit us: www.xlsolutions-corp.com/training.htm


Course Format:

This course consists of a series of short lectures with
demonstrations and interactive sessions for the participants.
Each student is provided with bound copies of the notes and
a CD-ROM containing all examples, exercises and software used
on the course.



Share Your Thoughts:

Are there any additional topics you would like for this course to address?
Would you like for this course to be offered in another city?

Please let us know by contributing to our recommendation list:
training at xlsolutions-corp.com.

========================================================================

R/S-Plus Fundamentals and Programming Techniques / Princeton, November 2002
Pre-registration Form (Please email or print and fax: 206-686-1578)
XLsolutions Corporation: For your Solutions needs, Consulting and Training.
www.xlsolutions-corp.com



Title...... First Name ................. Last Name....................

Organization..........................................................

Mailing Address.......................................................

.....................................................................

.....................................................................

Zip Code...................... Country.............................

Telephone........................... Fax ...............................

E-mail................................................................

Payment will be made by: (1) check (2) invoice (3) bank transfer



Elvis Miller, PhD
Manager Training and Technical Support
North American Division
XLSolutions Corporation
Email: elvis at xlsolutions-corp.com
Phone: 206-686-1578
Web: www.xlsolutions-corp.com

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikalzet at libero.it  Tue Oct 29 18:47:35 2002
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Tue, 29 Oct 2002 18:47:35 +0100 (CET)
Subject: [R] Using the Search Engine & Keywords
In-Reply-To: <Pine.LNX.4.44.0210262311320.1871-100000@macchinetta.miadimora>
Message-ID: <Pine.LNX.4.44.0210291844330.1667-100000@macchinetta.miadimora>


> > On Fri, 25 Oct 2002, Aleksey Naumov wrote:
> > 
> > > Can anyone running R on Linux share how they use the "Search Engine &
> > > Keywords" page of R documentation? I cannot do any javascript on this page,
> > > either searching for a term or following the keyword links. I tried Konqueror
> > > (3.0.4, with javascript globally enabled), Mozilla (1.1), and Galeon (1.2.5),
> > > but none of them do anything...

I installed SUN Java on Mandrake 9.0 today and the R search engine works 
fine with mozilla (though not with konqueror). 

-- 
Michele Alzetta

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Tue Oct 29 06:23:57 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 29 Oct 2002 18:23:57 +1300
Subject: [R] sourcing the content of directories
In-Reply-To: <3DBE741E.9020105@tuebingen.mpg.de>; from jan.wiener@tuebingen.mpg.de on Tue, Oct 29, 2002 at 12:42:22PM +0100
References: <3DBE741E.9020105@tuebingen.mpg.de>
Message-ID: <20021029182357.A10774@camille.indigoindustrial.co.nz>

On Tue, Oct 29, 2002 at 12:42:22PM +0100, Jan Malte Wiener wrote:
> hi,
> is there a way to source all R-files that reside in a given directory 
> with a single R-call ?
> greetinx jan

Jan

Given this question, and the previous one about environment variables and
file paths, it looks like you really should set your project up as a 
full R package.  While this might be a painful transition under CVS (never
have changed file paths mid-project, but I hear it's not trivial), 
it should be worth it to eliminate headaches like cross-platform file
sourcing, and should also ease documentation writing and storage.

See the "Writing R Extensions" manual (R-exts.pdf).  You might also 
want to get the book "S Programming", another good one by Venables 
and Ripley.  And *definately* check out the function package.skeleton,
which sets up template files for you (very slick, and helps me remember
details I might normally overlook).

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jwe at bevo.che.wisc.edu  Tue Oct 29 19:59:23 2002
From: jwe at bevo.che.wisc.edu (John W. Eaton)
Date: Tue, 29 Oct 2002 12:59:23 -0600
Subject: [R] Re: Matlab to R ?
In-Reply-To: <XFMail.021004133156.Ted.Harding@nessie.mcc.ac.uk>
References: <15773.17834.519855.498186@gargle.gargle.HOWL>
	<XFMail.021004133156.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <15806.55947.569173.941600@segfault.bogus.domain>

On  4-Oct-2002, (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> wrote:

| For this reason I doubt that Paul Gilbert's
| 'ex' script will encourage many to migrate from matlab/octave
| to R: simple line-editing substitutions do no go far enough;
| the script is not "intelligent".
| 
| [...]
|
| I would agree that a more flexible language such as 'perl' or
| 'python' or (my favourite) 'awk' should be used instead: these
| languages are capable of sophisticated parsing of input lines,
| recognising their intent, and generating appropriate output.
| I.e. the programmer can build "intelligence" into the script.

Sorry to jump in late on this.

If you want to translate Octave code to something else, you might be
able to get the best results for the least effort by using Octave
itself as a starting point because you wouldn't have to write a parser
for the Octave language yourself.  You could just use Octave's parser,
which seems more likely to be complete than anything you could quickly
cook up in Perl, Python, or AWK.  Octave has an internal interface for
walking the parse tree that can be used to emit code.  This method is
already used as a simple pretty printer that can reconstruct a text
representation of Octave code from the parse tree.  Using that code as
a starting point for emitting proper R syntax should not be too hard.
But once you do that, you will still need an appropriate run-time
library.

If I understand the way it is supposed to work, then Duncan's ROctave
interface avoids that problem because it makes all of R and Octave
available at the same time.  If you want to do something that only R
(Octave) knows how to do, you just ask R (Octave) to do it.  It
doesn't matter whether your primary langauge is R or Octave.

So instead of having a translator, I think I'd rather have a way to
make R and Octave work together.

jwe
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Oct 29 20:13:04 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Oct 2002 20:13:04 +0100
Subject: [R] RODBC blues
In-Reply-To: <5.1.0.14.0.20021029171843.00aaecc0@bute.st-and.ac.uk>
References: <5.1.0.14.0.20021029171843.00aaecc0@bute.st-and.ac.uk>
Message-ID: <x2r8e983en.fsf@biostat.ku.dk>

Bernie McConnell <bm8 at st-andrews.ac.uk> writes:

> Good Day,
> 
>   Perhaps I have missed a posting but ...  I cannot find the RODBC package on
>   cran at www.stats.bris.ac.uk/R/.

Did you look in the Devel subdirectory?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Oct 29 21:10:12 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 29 Oct 2002 20:10:12 +0000 (GMT)
Subject: [R] RODBC blues
In-Reply-To: <5.1.0.14.0.20021029171843.00aaecc0@bute.st-and.ac.uk>
Message-ID: <Pine.LNX.4.31.0210292006260.25079-100000@gannet.stats>

Look for it in the Devel area.  It will not build under current R
(nor would it run correctly).

The good news is that a new version from a new maintainer (me) is
imminent.  If you are really desparate there is a release candidate at
http://www.stats.ox.ac.uk/pub/R, but the documentation improvements are
not yet finished.

On Tue, 29 Oct 2002, Bernie McConnell wrote:

>   Perhaps I have missed a posting but ...  I cannot find the RODBC package on
>   cran at www.stats.bris.ac.uk/R/.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tplate at blackmesacapital.com  Tue Oct 29 21:24:41 2002
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue, 29 Oct 2002 13:24:41 -0700
Subject: [R] Combining simulation results
In-Reply-To: <15806.42368.353280.864785@gargle.gargle.HOWL>
References: <59574335@toto.iv>
Message-ID: <5.1.0.14.2.20021029132129.048d9600@mailhost.blackmesacapital.com>

My function abind() on StatLib does not work out of the box on R because 
the return value from match.call() has a different structure in R.  I 
translated it for R and have been meaning to get around to making it 
available.  In the meantime, I'd be happy to email a copy to anyone who 
wants it.

-- Tony Plate

At 10:13 AM 10/29/2002 -0500, David Brahm wrote:
>Murray Jorgensen <maj at waikato.ac.nz> wants to combine two arrays, each of dim:
> > > dim(resarray)
> > [1]  10   6 500   3
>into one array of dim c(10, 6, 1000, 3).
>
>A function called "abind" on StatLib <http://lib.stat.cmu.edu/S/abind> does
>exactly this, at least in S-Plus.  I have not tried it in R.
>--
>                               -- David Brahm (brahm at alum.mit.edu)
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pcboutro at engmail.uwaterloo.ca  Tue Oct 29 21:32:57 2002
From: pcboutro at engmail.uwaterloo.ca (Paul Boutros)
Date: Tue, 29 Oct 2002 15:32:57 -0500 (EST)
Subject: [R] Apply function to column of array
Message-ID: <Pine.GSO.4.05.10210291528110.16298-100000@engmail.uwaterloo.ca>

Hi all,

I would like to apply a function to each column of an 2-dimensional array,
and store the result in a new 1-dimensional vector.  I am not sure how to
go about doing that syntatically.  For instance, can I use lapply?  And,
if so, how do I specify which dimension should be used?  Also, how do I
pre-specify the type of object that will go into the 1-dimensional vector.

I'm not sure if it is important, the function I wish to apply to the
columns is density().  Additionally, I wish to be able to take these
density objects (stored in that 1-dim vector) and place them onto a
multiple-figure environment.

I'm new with R, so I tend to think in loops.  I'd appreciate any guidance
or tips on better ways to handle this problem.

Thanks!
Paul

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From drf5n at mug.sys.virginia.edu  Tue Oct 29 22:37:07 2002
From: drf5n at mug.sys.virginia.edu (David Forrest)
Date: Tue, 29 Oct 2002 16:37:07 -0500 (EST)
Subject: [R] Re: Matlab to R ?
In-Reply-To: <15806.55947.569173.941600@segfault.bogus.domain>
Message-ID: <Pine.LNX.4.33.0210291623150.6470-100000@mug.sys.virginia.edu>


I couldn't find a link to this on google, or on the
http://omega.stat.wisc.edu/
http://omega.stat.wisc.edu/RecentActivities.html pages, but guessed from
the http://omega.stat.wisc.edu/RXLisp/ link:

      http://omega.stat.wisc.edu/ROctave/

and found it.   I haven't got it going yet, since lots of stuff is out of
date on my system, but others might appreciate the link.

Dave,
--
 Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
 drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/

On Tue, 29 Oct 2002, John W. Eaton wrote:

...
>
> If I understand the way it is supposed to work, then Duncan's ROctave
> interface avoids that problem because it makes all of R and Octave
> available at the same time.  If you want to do something that only R
> (Octave) knows how to do, you just ask R (Octave) to do it.  It
> doesn't matter whether your primary langauge is R or Octave.
>
> So instead of having a translator, I think I'd rather have a way to
> make R and Octave work together.
>
> jwe

Dave,
-- 
 Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
 drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jbond at arg.org  Tue Oct 29 23:17:28 2002
From: jbond at arg.org (Jason Bond)
Date: Tue, 29 Oct 2002 14:17:28 -0800
Subject: [R] error in Fields TPS function
Message-ID: <5.1.0.14.2.20021029141550.01dc26a0@38.168.156.2>

Hello, I was wondering whether anyone out there knows of the solution to a 
problem that I'm having with the Fields package.  I am getting the error 
message when I try and run the fields function tps (thin plate 
splines).  Namely, for two different sets of variables, I get:

 > bout <- Tps( bvolcap, bdsm)
Error in svd(tempM) : error  159  in dsvdc
 > wout <- Tps( wvolcap, wdsm)
Error in svd(tempM) : error  546  in dsvdc

Any help would be greatly appreciated.

   Jason

_______________________________

Jason C. Bond, Ph.D.
Biostatistician, Associate Scientist
Public Health Institute
Alcohol Research Group
2000 Hearst Avenue
Berkeley, CA  94709

Telephone: 	(510) 642-7965
Fax:		(510) 642-7175


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Tue Oct 29 23:46:02 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Tue, 29 Oct 2002 17:46:02 -0500
Subject: [R] Apply function to column of array
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20149D152@groexmb02.pfizer.com>


Use the 'apply' function.  For information see ?apply.

To plot the density of each column of a matrix, you can do this

	mat <- matrix( rnorm(100 * 12), ncol=12 )
      par(mfrow=c(3,4))
      density.list <- apply( mat, 2, density)
      sapply( density.list, plot )

-Greg


> -----Original Message-----
> From: Paul Boutros [mailto:pcboutro at engmail.uwaterloo.ca]
> Sent: Tuesday, October 29, 2002 3:33 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Apply function to column of array
> 
> 
> Hi all,
> 
> I would like to apply a function to each column of an 
> 2-dimensional array,
> and store the result in a new 1-dimensional vector.  I am not 
> sure how to
> go about doing that syntatically.  For instance, can I use 
> lapply?  And,
> if so, how do I specify which dimension should be used?  
> Also, how do I
> pre-specify the type of object that will go into the 
> 1-dimensional vector.
> 
> I'm not sure if it is important, the function I wish to apply to the
> columns is density().  Additionally, I wish to be able to take these
> density objects (stored in that 1-dim vector) and place them onto a
> multiple-figure environment.
> 
> I'm new with R, so I tend to think in loops.  I'd appreciate 
> any guidance
> or tips on better ways to handle this problem.
> 
> Thanks!
> Paul
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Wed Oct 30 01:02:55 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 29 Oct 2002 16:02:55 -0800 (PST)
Subject: [R] Apply function to column of array
In-Reply-To: <Pine.GSO.4.05.10210291528110.16298-100000@engmail.uwaterloo.ca>
Message-ID: <Pine.GSO.4.10.10210291554190.23524-100000@fisher.stat.ucla.edu>

It seems that for this you may in fact want to use a loop.  If you have a
matrix with p columns (say it's called 'm'), then you might consider:

results <- vector("list", length = p)
for(i in 1:p) results[[i]] <- density(m[,i])

If you want to use lapply() then something like the following should work:

results <- lapply(1:p, function(i) density(m[,i]))

Then 'results' is a vector of lists which contain the results to the
individual calls to density().  You can then cycle over this vector to
make your plots or whatever.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Tue, 29 Oct 2002, Paul Boutros wrote:

> Hi all,
> 
> I would like to apply a function to each column of an 2-dimensional array,
> and store the result in a new 1-dimensional vector.  I am not sure how to
> go about doing that syntatically.  For instance, can I use lapply?  And,
> if so, how do I specify which dimension should be used?  Also, how do I
> pre-specify the type of object that will go into the 1-dimensional vector.
> 
> I'm not sure if it is important, the function I wish to apply to the
> columns is density().  Additionally, I wish to be able to take these
> density objects (stored in that 1-dim vector) and place them onto a
> multiple-figure environment.
> 
> I'm new with R, so I tend to think in loops.  I'd appreciate any guidance
> or tips on better ways to handle this problem.
> 
> Thanks!
> Paul
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Oct 30 08:54:33 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 30 Oct 2002 08:54:33 +0100
Subject: [R] error in Fields TPS function {svd ...}
In-Reply-To: <5.1.0.14.2.20021029141550.01dc26a0@38.168.156.2>
References: <5.1.0.14.2.20021029141550.01dc26a0@38.168.156.2>
Message-ID: <15807.36921.779502.738006@gargle.gargle.HOWL>

>>>>> "Jason" == Jason Bond <jbond at arg.org>
>>>>>     on Tue, 29 Oct 2002 14:17:28 -0800 writes:

    Jason> Hello, I was wondering whether anyone out there knows of the solution to a 
    Jason> problem that I'm having with the Fields package.  I am getting the error 
    Jason> message when I try and run the fields function tps (thin plate 
    Jason> splines).  Namely, for two different sets of variables, I get:

(if you had provided one of the sets of variables we would have
 a chance to reproduce your problem)

    >> bout <- Tps( bvolcap, bdsm)
    Jason> Error in svd(tempM) : error  159  in dsvdc
    >> wout <- Tps( wvolcap, wdsm)
    Jason> Error in svd(tempM) : error  546  in dsvdc

[Ok, I'm starting a general `sermon' ;-)]

1) After error messages like these, always first try
   traceback()
   ~~~~~~~~~~~  which shows you the function calls nesting
   leading to the error.

2) The above message indicates it comes from svd().
   This should lead you immediately to carefully look at the
   output of
     ?svd   [aka  help(svd) ]

   In this case, this will only help to suggest (to the author
   of Fields!) that maybe  La.svd() should be tried instead of svd().
   svd() is based on LINPACK which was state-of-the-art (in
   numerical linear algebra) in the 70's and (early) 80's. 
   It's successor, LAPACK, is +/- current state-of-the-art and
   that's why  help(svd) suggests using La.svd() for all new projects.

3) For non-standard packages (not "Base" or "Recommended") I'd
   suggest you always first ask the package maintainer, i.e.
   the one in the line "Maintainer : ..........."
   you get from 
	   library(help = Fields)
		   ^^^^^^^
-----------

Back to the concrete problem:
svd's source has

    z <- .Fortran("dsvdc", as.double(x), n, n, p, d = double(mm), 
        double(p), u = u, n, v = v, p, double(n), as.integer(job), 
        info = integer(1), DUP = FALSE, PACKAGE = "base")[c("d", 
        "u", "v", "info")]
    if (z$info) 
        stop(paste("error ", z$info, " in dsvdc"))

which is where the error message is produced.
As R is GNU software and hence Open Source, we can `quickly'(:-)
jump to the Fortran source  <SOURCEDIR>/src/appl/dsvdc.f
and dig there. In the initial comments we find

c     on return
c
	<..........>

c         info      integer.
c                   the singular values (and their corresponding
c                   singular vectors) s(info+1),s(info+2),...,s(m)
c                   are correct (here m=min(n,p)).  thus if
c                   info.eq.0, all the singular values and their
c                   vectors are correct.  in any event, the matrix
c                   b = trans(u)*x*v is the bidiagonal matrix
c                   with the elements of s on its diagonal and the
c                   elements of e on its super-diagonal (trans(u)
c                   is the transpose of u).  thus the singular
c                   values of x and b are the same.

so you now only know that quite a few singular values could
*not* be computed for your matrix / data.

    Jason> Any help would be greatly appreciated.
    Jason> Jason
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From AlessandroSemeria at cramont.it  Wed Oct 30 09:27:01 2002
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Wed, 30 Oct 2002 09:27:01 +0100
Subject: [R] distributions homogeneity2
Message-ID: <OF2CF18E51.CD349005-ONC1256C61.003443BE@tomware.it>

Hello dear R-list!
 I have to test if N (non linear)  experimantal
distributions fit some of known one. I would proceed in this
way:
1. Fit with 'nlm' and e.g. power law one ( non outlier) distribution of
mine.
2. Perform 'chisq.test' for each pairs (power law ,distribution(i))

but I'm neither a statistician nor a skilled on R, so I ask you: ther'is
some other way, more telling and efficient, to perform this task?
Thanks in advance for any suggestion!

--------------------------
Sincerely yours.

Dr. Alessandro Semeria                             Tel. +39 544 536811
Models and Simulation Lab of                                 Fax. +39 544
538663
The Environment Research Center - Montecatini (Edison Group),
E-mail: asemeria at cramont.it
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Oct 30 11:56:36 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 30 Oct 2002 11:56:36 +0100
Subject: [R] pretty not pretty
In-Reply-To: <15806.43461.675233.576774@gargle.gargle.HOWL>
References: <15806.43461.675233.576774@gargle.gargle.HOWL>
Message-ID: <15807.47844.122831.475588@gargle.gargle.HOWL>

>>>>> "DavidB" == David Brahm <brahm at alum.mit.edu>
>>>>>     on Tue, 29 Oct 2002 10:31:17 -0500 writes:

    DavidB> Ott Toomet <otoomet at econ.au.dk> wrote:
    >> Pretty (R 1.5.1) has problems with zero: 
    >> pretty(smallch) 
    DavidB> [1] -2.00000e-02 -3.469447e-18 2.00000e-02 4.00000e-02 6.00000e-02 
    DavidB> [6] 8.000000e-02 1.000000e-01 1.200000e-01 
    >> You notice -3.46e-18 instead of 0. Is this feature changed in 1.6.0, 
    >> or are there any simple ways to get around of it? 

    DavidB> I mentioned this in R-devel on June 14, 2002
    DavidB> ("pretty() sometimes isn't").  It derives from the
    DavidB> roundoff error introduced in seq(-.02, .12,
    DavidB> length=8).  I suggested that the last line of the
    DavidB> code for pretty() should get a zapsmall() around it:


    DavidB> pretty <- function(...) {
    DavidB> ...
    DavidB> zapsmall(seq(z$l, z$u, length = z$n + 1))
    DavidB> }

    DavidB> Since that hasn't been implemented, you could simply
    DavidB> put a zapsmall() around every pretty() in your code.

It *) now _has_ been implemented. ---> will be in R-beta tomorrow
and R 1.6.1.
Whereas for seq() it is clear that you will see these roundoffs,
they are ``wrong'' for pretty().

Thank you David, for the reminder.

*) I've used  zapsmall(seq(z$l, z$u, length = z$n + 1), digits = 7)
   instead in order to make sure that the result will not depend
   on options("digits").

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From susanabarbosa at novalis.fc.up.pt  Wed Oct 30 12:10:36 2002
From: susanabarbosa at novalis.fc.up.pt (Susana Barbosa)
Date: Wed, 30 Oct 2002 11:10:36 +0000
Subject: [R] Estimation of transfer function time series models
Message-ID: <200210301110.36362.susanabarbosa@novalis.fc.up.pt>

Hi,

Is there a function in R to estimate transfer function time series models?

Thanks in advance


Susana Barbosa
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From snw at mcs.st-and.ac.uk  Wed Oct 30 12:16:28 2002
From: snw at mcs.st-and.ac.uk (Simon Wood)
Date: Wed, 30 Oct 2002 11:16:28 +0000 (GMT)
Subject: [R] error in Fields TPS function
In-Reply-To: <5.1.0.14.2.20021029141550.01dc26a0@38.168.156.2>
Message-ID: <Pine.GSO.4.21.0210301107570.19477-100000@dolphin>

This may be a irrelevant, but I had some problems using svd() after R
started allowing optimizations that use floating point registers for
temporary variable storage (because these registers are usually longer than
a standard double then some convergence testing tricks can get fooled by
allowing this). Using la.svd() instead of svd() solved the problem.      

Simon

> Hello, I was wondering whether anyone out there knows of the solution to a 
> problem that I'm having with the Fields package.  I am getting the error 
> message when I try and run the fields function tps (thin plate 
> splines).  Namely, for two different sets of variables, I get:
> 
>  > bout <- Tps( bvolcap, bdsm)
> Error in svd(tempM) : error  159  in dsvdc
>  > wout <- Tps( wvolcap, wdsm)
> Error in svd(tempM) : error  546  in dsvdc
> 
> Any help would be greatly appreciated.
> 
>    Jason
> 
> _______________________________
> 
> Jason C. Bond, Ph.D.
> Biostatistician, Associate Scientist
> Public Health Institute
> Alcohol Research Group
> 2000 Hearst Avenue
> Berkeley, CA  94709
> 
> Telephone: 	(510) 642-7965
> Fax:		(510) 642-7175
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hgoehlmann at gmx.de  Wed Oct 30 13:16:18 2002
From: hgoehlmann at gmx.de (hgoehlmann@gmx.de)
Date: Wed, 30 Oct 2002 13:16:18 +0100 (MET)
Subject: [R] Settings of lattice graphs
References: <15807.36921.779502.738006@gargle.gargle.HOWL>
Message-ID: <30892.1035980178@www33.gmx.net>

I am trying to modify the outer margin of a lattice graph and I am just not
sure whether this is possible or not - something like

par(c(5, 4, 4, 2) + 0.1)

Is there such a thing?

Cheers,
hinrich    d8-)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kgk at pharm.auth.gr  Wed Oct 30 13:19:10 2002
From: kgk at pharm.auth.gr (Kyriakos Kachrimanis)
Date: Wed, 30 Oct 2002 14:19:10 +0200
Subject: [R] mixture variables
Message-ID: <013901c2800e$8d850e00$5e05cf9b@pharm.auth.gr>

Dear list members,

I want to fit a linear model to a data set that contains several independent
variables, some of them continuous and some of them binary. For the binary
variables I am using 1-of-N encoding but I also have two variables that
correspond to mixture ratios. How can I declare to the model that their sum
equals unity? Or perhaps should I treat them as factors instead of  random
variables constrained to [0,1]?
Thank you very much in advance.

Best Regards
Kyriakos Kachrimanis.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From peter.schlattmann at medizin.fu-berlin.de  Wed Oct 30 13:19:03 2002
From: peter.schlattmann at medizin.fu-berlin.de (Dr. Peter Schlattmann)
Date: Wed, 30 Oct 2002 13:19:03 +0100 (CET)
Subject: [R] groupedData
Message-ID: <1296.160.45.195.78.1035980343.squirrel@www.medizin.fu-berlin.de>

Dear all,

I tried to create a groupedData object, where the grouping factor
is not ordered.

Here ist the code:

library(nlme)
test<-groupedData(conc~Time|Subject,order.groups=F,data=as.data.frame(Theoph))
> getGroups(test)

Levels: 6 < 7 < 8 < 11 < 3 < 2 < 4 < 9 < 12 < 10 < 1 < 5

I still get an ordered factor. As always thanks for your help

peter



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chergr at bigpond.com  Wed Oct 30 13:26:56 2002
From: chergr at bigpond.com (Richard)
Date: Wed, 30 Oct 2002 23:26:56 +1100
Subject: [R] Flushing the R output buffer.
Message-ID: <3DBFCFF2.10CCBDF9@bigpond.com>


flusHi,

I am connecting R to a PHP web script.

The first effort attempted to use a named pipe
but gave up on that because PHP could not read
any data from the named pipe.

I changed to using a temp file but it also has problems.
It appears that the file to which R's output is redirected
is not recieving any output until the pipe connection form PHP
is closed. I think this means that R is buffering its output
and there appears to be no flush function.

I would like to use a sequence like:

open pipe to R and incommand redirect R outout to file/fifo

open file
send R command
read response from file
close file

open file
send R command
read response from file
close file
.
.
close pipe

I checked the archives and there a function
flush.console() was mentioned -- I looked for this in
the docs but could not find it. The function does not appear
to affect flushing of the R output to the file.

This is a RedHat Linsux 7.3 on x86 install

Has anyone any suggestions??

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thsudler at swissonline.ch  Wed Oct 30 14:44:59 2002
From: thsudler at swissonline.ch (Thomas Sudler)
Date: Wed, 30 Oct 2002 14:44:59 +0100
Subject: [R] snip.rpart with R 1.6.0
Message-ID: <005e01c2801a$8a48ff60$4bfe55a0@LaptopPrivat>

Hello! 

I've a question to the rpart package. With the snip.rpart function, you can
snip off subtrees. In R 1.5.1 this function works without problems. But in
the new version of R (1.6.0) it isn't possible to snip off the subtrees wi
th this function. Does someone have a solution for this problem? 

thsudler at swissonline.ch 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct 30 15:06:35 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 30 Oct 2002 14:06:35 +0000 (GMT)
Subject: [R] error in Fields TPS function
In-Reply-To: <Pine.GSO.4.21.0210301107570.19477-100000@dolphin>
Message-ID: <Pine.LNX.4.31.0210301403140.7335-100000@gannet.stats>

On Wed, 30 Oct 2002, Simon Wood wrote:

> This may be a irrelevant, but I had some problems using svd() after R
> started allowing optimizations that use floating point registers for
> temporary variable storage (because these registers are usually longer than
> a standard double then some convergence testing tricks can get fooled by
> allowing this). Using la.svd() instead of svd() solved the problem.

Yes, svd uses LINPACK, and LIN/EISPACK were written long before such
chips existed.  It's a good reason to move away from them.

R has always allowed it on Linux (and such problems have been noted
there). What is new-ish is that R under Windows is now built to make use
of extended-fpu registers (it always use the registers, previously with
53-bit not 64-bit mantissa).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From d.orme at ic.ac.uk  Wed Oct 30 15:31:06 2002
From: d.orme at ic.ac.uk (David Orme)
Date: Wed, 30 Oct 2002 14:31:06 +0000
Subject: [R] Mac OS 9 and file type/creator
Message-ID: <a05100306b9e59acee2eb@[129.31.3.212]>

Hi,

I'm using R1.5.0 on Mac OS 9.1 to create graphics as pdf files. One 
problem, admittedly pretty minor, is that the file type and creator 
are blank. Is there any way from within R of setting the file type 
and/or file creator of the resulting files so that OS9 can work out 
which program to open the files in?

Thanks in advance,
David Orme
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Oct 30 15:52:28 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 30 Oct 2002 15:52:28 +0100
Subject: [R] snip.rpart with R 1.6.0
In-Reply-To: <005e01c2801a$8a48ff60$4bfe55a0@LaptopPrivat>
References: <005e01c2801a$8a48ff60$4bfe55a0@LaptopPrivat>
Message-ID: <15807.61996.418768.294233@gargle.gargle.HOWL>

>>>>> "Thomas" == Thomas Sudler <thsudler at swissonline.ch>
>>>>>     on Wed, 30 Oct 2002 14:44:59 +0100 writes:

    Thomas> I've a question to the rpart package. With the
    Thomas> snip.rpart function, you can snip off subtrees. In R
    Thomas> 1.5.1 this function works without problems. But in
    Thomas> the new version of R (1.6.0) it isn't possible to
    Thomas> snip off the subtrees wi th this function. Does
    Thomas> someone have a solution for this problem?

We don't know your problem.
I've tried two examples which worked fine.

Please give a *reproducible* example.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jarioksa at sun3.oulu.fi  Wed Oct 30 16:00:28 2002
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Wed, 30 Oct 2002 17:00:28 +0200
Subject: [R] Sweave in packages
Message-ID: <200210301500.g9UF0Se25985@pc112145.oulu.fi>

Dear R folks, 

One of the fantastic new tools in R is `Sweave'. I have tested it so much that I
know it works and produces fine documentation, and with (GNU) Emacs/ESS it is
nice to work with, too. I started to have a look at including some Swoven (is
that a strong verb?) documentation with my R package, but it seems that there is
no model to copy among those packages that I have installed in my R. Has anybody
used Sweave for package vignettes? I have run into some minor inconveniences,
where I would appreciate hints:

- I cannot find out in R-exts manual how to actually write \VignetteIndexEntry 
so that it would be incorporated into 00Index.dcf. Should you put the entry 
within braces (LaTeX way) or use colon or something before the entry 
(00Index.dcf instructions)? Actually, I cannot get much of an 00Index.dcf: If I 
use --force to build the package, the 00Index.dcf will be replaced with an 
empty file (size 0 bytes). Further, I haven't figured out how to transfer the 
\VignetteIndexEntry to the ultimate pdf file. All my attempts to write the 
00Index.dcf file manually have ended with R sarcastically saying to me that 
my index is not up-to-date and writing over my file with an empty file 
(obviously I should be more careful in my hand writing...). 

- It seems that it is necessary to use Makefile because R CMD BUILD doesn't
clean the inst/doc directory from the interim files Sweave produces to build the
pdf (foo-???.eps, foo-???.pdf, LaTeX files like foo.blg, foo.bbl, foo.aux,
foo.log, etc). Is there any other solution here? 

- Is it indeed the purpose that the final document should be a pdf file even in
source packages. The pdf files tend to become huge, and easily multiply the size
of a source package. As I have a 56KB modem at home (working at ~5KB file
transfer speed in practice) I am really concerned with this aspect as well (it
doesn't concern me at all when at work). Is the assumption that users won't have
tools to build a pdf from the Sweave source?

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jg_liao at yahoo.com  Wed Oct 30 16:23:25 2002
From: jg_liao at yahoo.com (Jason Liao)
Date: Wed, 30 Oct 2002 07:23:25 -0800 (PST)
Subject: [R] two small wishes for R
Message-ID: <20021030152325.92127.qmail@web10505.mail.yahoo.com>

1. allows underscore as part of a variable name
2. Uses C or Java style comments mark.

Jason

=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-8611, fax (732) 235-9777
http://www.geocities.com/jg_liao

__________________________________________________

HotJobs - Search new jobs daily now

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jrogers at cantatapharm.com  Wed Oct 30 16:55:49 2002
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Wed, 30 Oct 2002 10:55:49 -0500
Subject: [R] data.frame as argument to data.frame
Message-ID: <99A12772DCDEEB458B996332957B0D530116D3@mercury.cantatapharm.com>

Hello, 

Documentation for data.frame says, 

"If a list or data frame or matrix is passed to data.frame it is as if
each column had been passed as a separate argument, with the exception
of matrices of class model.matrix. ".

This is not quite true:

> data.frame(a = 1:2, b = 1:4, c = 1:8) # replicates vectors as
necessary
  a b c
1 1 1 1
2 2 2 2
3 1 3 3
4 2 4 4
5 1 1 5
6 2 2 6
7 1 3 7
8 2 4 8

but if one tries to combine a vector with a data.frame that needs to be
replicated, one gets:

> data.frame(data.frame(a = 1:2, b = 1:4), c = 1:8)
Error in data.frame(data.frame(a = 1:2, b = 1:4), c = 1:8) : 
	arguments imply differing number of rows: 4, 8

On the other hand, if one combines a data.frame with a vector that needs
to be replicated, it works:

> data.frame(data.frame(a = 1:8, b = 1:4), c = 1:2)
  a b c
1 1 1 1
2 2 2 2
3 3 3 1
4 4 4 2
5 5 1 1
6 6 2 2
7 7 3 1
8 8 4 2

Is the behavior my second example intended? It would seem more
convenient if the rows of the data.frame were replicated as needed. If
it is intended behavior, a word about this in the documentation might be
helpful. 

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    5.1            
year     2002           
month    06             
day      17             
language R    

Thanks,
Jim Rogers

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From J.B.Bremnes at met.no  Wed Oct 30 17:15:28 2002
From: J.B.Bremnes at met.no (John Bjornar Bremnes)
Date: Wed, 30 Oct 2002 16:15:28 +0000
Subject: [R] plotmath
Message-ID: <3DC005A0.8FD1D579@met.no>

How can I add "%" to each titlein the example below?I am using R1.5.0
on Linux.

par(mfrow=c(2,2))
for (i in c(30,50,70,90)) {
	plot(0, 0, type="n")
	mtext(substitute(RH[925-500] == ii, list(ii=i)))	
}


thanks
-- 
John Bjornar Bremnes
Norwegian Meteorological Institute (met.no)
Research and Development Department
P.O.Box 43 Blindern, N-0313 Oslo, Norway
Phone: (+47) 2296 3326. Fax: (+47) 2269 6355
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct 30 17:16:49 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 30 Oct 2002 16:16:49 +0000 (GMT)
Subject: [R] Flushing the R output buffer.
In-Reply-To: <3DBFCFF2.10CCBDF9@bigpond.com>
Message-ID: <Pine.LNX.4.31.0210301609520.5214-100000@gannet.stats>

On Wed, 30 Oct 2002, Richard wrote:

> flusHi,

???

> I am connecting R to a PHP web script.
>
> The first effort attempted to use a named pipe
> but gave up on that because PHP could not read
> any data from the named pipe.
>
> I changed to using a temp file but it also has problems.
> It appears that the file to which R's output is redirected
> is not recieving any output until the pipe connection form PHP
> is closed. I think this means that R is buffering its output
> and there appears to be no flush function.

Redirected output is normally buffered: it's an issue for your OS's
runtime system.  R is just a C program.

> I would like to use a sequence like:
>
> open pipe to R and incommand redirect R outout to file/fifo
>
> open file
> send R command
> read response from file
> close file
>
> open file
> send R command
> read response from file
> close file
> .
> .
> close pipe
>
> I checked the archives and there a function
> flush.console() was mentioned -- I looked for this in
> the docs but could not find it. The function does not appear
> to affect flushing of the R output to the file.

Well, it is documented for the Windows GUI, where it does work.
How can a function you can't find affect R when you can't run it?

> This is a RedHat Linsux 7.3 on x86 install

Try using connections, in particular a fifo and play with blocking.  It
would not be too hard to implement a flush() function if you want one
(there is internal support for it in the design of connections): if
you do write one, please contribute it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Kosenkov.Kirill at nac.spb.ru  Wed Oct 30 17:27:49 2002
From: Kosenkov.Kirill at nac.spb.ru (=?koi8-r?B?68/Txc7Lz9cg68nSyczMIO7Jy8/MwcXXyd4=?=)
Date: Wed, 30 Oct 2002 19:27:49 +0300
Subject: [R] help needed. Why R does not produce lattice graphics when running command 'source (file_name)'?
Message-ID: <000501c28031$4cf51c40$6900a8c0@nac.net>

Hi!
I have a source file - for example 'my.R' - which uses some functions from
'lattice' library.
It looks like that:

    library(lattice)
    pr<-xtabs(W~ff$'q1'+ff$'q2',data=ff)
    pr<-pr/rowSums(pr)*100
    pr<-as.data.frame(pr)

    barchart(pr[[2]]~pr[[3]]|pr[[1]], horizontal=TRUE, as.table=TRUE,
xlab=NULL, ylab=NULL,  col="plum", box.ratio=1,
groups=as.character(round(pr[[3]])), par.strip.text=list(font=2),
panel=function(x,y,color,subscripts,groups,...)
  { panel.barchart(x=x,y=y,box.ratio=2,col=color)
  ltext(x=x+0.2,y=y,label=groups[subscripts],adj=0,cex=0.7,font=2)
  panel.abline(h=NULL,v=1:10*10,lty="dashed",col="lightgrey")
  })

When i run this source via
> source('my.R', echo=TRUE)
everything is ok
Also, everything is ok when i cut'n'paste this syntax to the R console

But when i run this source via
> source('my.R', echo=FALSE) or source('my.R')
R does not produce any lattice plots - only empty device window
'Non-lattice' plots (like simple barplots and others) produces fine in all
cases...

What i doing wrong? Why i cant have any lattice plots when i run source file
without 'echo=TRUE' option?

Please, help.
I am using R 1.6.0 on Win2k installed from prebuild binaries


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jgentry at jimmy.harvard.edu  Wed Oct 30 17:49:36 2002
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Wed, 30 Oct 2002 11:49:36 -0500 (EST)
Subject: [R] Sweave in packages
In-Reply-To: <200210301500.g9UF0Se25985@pc112145.oulu.fi>
Message-ID: <Pine.SOL.4.20.0210301141030.16763-100000@santiam.dfci.harvard.edu>



On Wed, 30 Oct 2002, Jari Oksanen wrote:
> - I cannot find out in R-exts manual how to actually write \VignetteIndexEntry 
> so that it would be incorporated into 00Index.dcf. Should you put the entry 

As an example from a vignette that I wrote:
%\VignetteIndexEntry{Misc Issues From reposTools}

Just replace the stuff in the braces with your own info.

> figured out how to transfer the \VignetteIndexEntry to the ultimate pdf

What do you mean by this?

Even if not interested in the functionality, you might want to take a look
at the packages from Bioconductor (www.bioconductor.org) - as they all
include working vignettes.  This might help provide a model for you to
work off of.

-J

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From aolinto at bignet.com.br  Wed Oct 30 17:05:06 2002
From: aolinto at bignet.com.br (Antonio Olinto)
Date: Wed, 30 Oct 2002 14:05:06 -0200
Subject: [R] extracting Std. Error value from lm/nls
References: <3DBFCFF2.10CCBDF9@bigpond.com>
Message-ID: <003a01c2802e$22ab5560$39cffea9@batata>

Hi,

How to extract Std. Error values from a lm or a nls?

With coef(model), coef(model)[1], coef(model)[2] and df.residual(model)  I
can get the coeffcients and the degrees of freedom but I couldn't find a way
to get Std. Error  values.

Thanks,

Antonio Olinto




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Oct 30 18:11:17 2002
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 30 Oct 2002 18:11:17 +0100 (MET)
Subject: [R] snip.rpart with R 1.6.0
In-Reply-To: <005e01c2801a$8a48ff60$4bfe55a0@LaptopPrivat>
Message-ID: <Pine.LNX.4.21.0210301810180.15372-100000@artemis>


> Hello! 
> 
> I've a question to the rpart package. With the snip.rpart function, you can
> snip off subtrees. In R 1.5.1 this function works without problems. But in
> the new version of R (1.6.0) it isn't possible to snip off the subtrees wi
> th this function. Does someone have a solution for this problem? 
> 

maybe someone could help you if you would add a small example reproducing
your problem.

Torsten


> thsudler at swissonline.ch 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Wed Oct 30 18:43:42 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Wed, 30 Oct 2002 12:43:42 -0500
Subject: [R] plotmath
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20149D15E@groexmb02.pfizer.com>


How about:


par(mfrow=c(2,2))
for (i in c(30,50,70,90)) {
	plot(0, 0, type="n")
      
	mtext(substitute( RH[925-500] == ii, list(ii=paste(i,"%",sep=""))))

}


-Greg


> -----Original Message-----
> From: John Bjornar Bremnes [mailto:J.B.Bremnes at met.no]
> Sent: Wednesday, October 30, 2002 11:15 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] plotmath
> 
> 
> How can I add "%" to each titlein the example below?I am 
> using R1.5.0
> on Linux.
> 
> par(mfrow=c(2,2))
> for (i in c(30,50,70,90)) {
> 	plot(0, 0, type="n")
> 	mtext(substitute(RH[925-500] == ii, list(ii=i)))	
> }
> 
> 
> thanks
> -- 
> John Bjornar Bremnes
> Norwegian Meteorological Institute (met.no)
> Research and Development Department
> P.O.Box 43 Blindern, N-0313 Oslo, Norway
> Phone: (+47) 2296 3326. Fax: (+47) 2269 6355
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From forporphyry at hotmail.com  Wed Oct 30 18:45:48 2002
From: forporphyry at hotmail.com (graham lawrence)
Date: Wed, 30 Oct 2002 09:45:48 -0800
Subject: [R] sample size in anova and regression
Message-ID: <F19PWic3NUGtX5ehf4Z0001b805@hotmail.com>

Dear R-Help,

Is there a function in R that corresponds to the Sample Size calculation for 
Anova or Regression that is available in Excel and Minitab?

Or should one apply power.t.test to every possible combination and choose 
the largest result?

Thank you in advance for your help

graham lawrence





_________________________________________________________________
Unlimited Internet access for only $21.95/month. Try MSN! 
http://resourcecenter.msn.com/access/plans/2monthsfree.asp

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Wed Oct 30 18:53:36 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Wed, 30 Oct 2002 09:53:36 -0800
Subject: [R] Sweave in packages
In-Reply-To: <200210301500.g9UF0Se25985@pc112145.oulu.fi>
Message-ID: <83C5E546-EC30-11D6-A502-000393860F3C@stat.ucla.edu>

Is your TeX using bitmapped CM fonts ? Use type 1, and
pdf's will be quite small.

On Wednesday, October 30, 2002, at 07:00 AM, Jari Oksanen wrote:

> The pdf files tend to become huge, and easily multiply the size
> of a source package.
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct 30 19:03:37 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 30 Oct 2002 18:03:37 +0000 (GMT)
Subject: [R] Mac OS 9 and file type/creator
In-Reply-To: <a05100306b9e59acee2eb@[129.31.3.212]>
Message-ID: <Pine.LNX.4.31.0210301757480.5393-100000@gannet.stats>

On Wed, 30 Oct 2002, David Orme wrote:

> I'm using R1.5.0 on Mac OS 9.1 to create graphics as pdf files. One
> problem, admittedly pretty minor, is that the file type and creator
> are blank. Is there any way from within R of setting the file type
> and/or file creator of the resulting files so that OS9 can work out
> which program to open the files in?

I don't see file type as a field in the PDF spec, and also don't see
how a field in a file can help tell you which program to open it with,
when it is already open by then ....

The creator field could be filed in as R, I guess, but it won't help you.
It's purely for information.

I think your OS has not got its MIME types sorted.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayan at stat.wisc.edu  Wed Oct 30 19:05:12 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 30 Oct 2002 12:05:12 -0600
Subject: [R] Settings of lattice graphs
In-Reply-To: <30892.1035980178@www33.gmx.net>
References: <15807.36921.779502.738006@gargle.gargle.HOWL> <30892.1035980178@www33.gmx.net>
Message-ID: <200210301205.12663.deepayan@stat.wisc.edu>


On Wednesday 30 October 2002 06:16 am, hgoehlmann at gmx.de wrote:
> I am trying to modify the outer margin of a lattice graph and I am just not
> sure whether this is possible or not - something like
>
> par(c(5, 4, 4, 2) + 0.1)
>
> Is there such a thing?

No, as far as lattice is concerned. par() settings do not affect grid (hence 
lattice) graphics. If you want to leave out space outside the plot, use the 
position argument in print.trellis.

Deepayan


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Oct 30 19:12:04 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 30 Oct 2002 19:12:04 +0100
Subject: [R] plotmath
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C20149D15E@groexmb02.pfizer.com>
References: <D7A3CFD7825BD6119B880002A58F06C20149D15E@groexmb02.pfizer.com>
Message-ID: <x2d6prdcej.fsf@biostat.ku.dk>

"Warnes, Gregory R" <gregory_r_warnes at groton.pfizer.com> writes:

> How about:
> 
> 
> par(mfrow=c(2,2))
> for (i in c(30,50,70,90)) {
> 	plot(0, 0, type="n")
>       
> 	mtext(substitute( RH[925-500] == ii, list(ii=paste(i,"%",sep=""))))
> 
> }

...or

mtext(substitute( RH[925-500] == ii*"%", list(ii=i)))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct 30 19:13:24 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 30 Oct 2002 18:13:24 +0000 (GMT)
Subject: [R] snip.rpart with R 1.6.0
In-Reply-To: <15807.61996.418768.294233@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.31.0210301809160.5490-100000@gannet.stats>

On Wed, 30 Oct 2002, Martin Maechler wrote:

> >>>>> "Thomas" == Thomas Sudler <thsudler at swissonline.ch>
> >>>>>     on Wed, 30 Oct 2002 14:44:59 +0100 writes:
>
>     Thomas> I've a question to the rpart package. With the
>     Thomas> snip.rpart function, you can snip off subtrees. In R
>     Thomas> 1.5.1 this function works without problems. But in
>     Thomas> the new version of R (1.6.0) it isn't possible to
>     Thomas> snip off the subtrees wi th this function. Does
>     Thomas> someone have a solution for this problem?
>
> We don't know your problem.
> I've tried two examples which worked fine.
>
> Please give a *reproducible* example.

I think he may mean that the visual deletion in snip.rpart.mouse is not
working.  It only works if the background colour is opaque, which is not
the default on e.g. x11() in either system.

If that is not it, we do need a reproducible example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Oct 30 19:17:28 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 30 Oct 2002 19:17:28 +0100
Subject: [R] extracting Std. Error value from lm/nls
In-Reply-To: <003a01c2802e$22ab5560$39cffea9@batata>
References: <3DBFCFF2.10CCBDF9@bigpond.com>
	<003a01c2802e$22ab5560$39cffea9@batata>
Message-ID: <x28z0fdc5j.fsf@biostat.ku.dk>

"Antonio Olinto" <aolinto at bignet.com.br> writes:

> Hi,
> 
> How to extract Std. Error values from a lm or a nls?
> 
> With coef(model), coef(model)[1], coef(model)[2] and df.residual(model)  I
> can get the coeffcients and the degrees of freedom but I couldn't find a way
> to get Std. Error  values.

Try looking at coef(summary(model))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From michaell.taylor at reis.com  Wed Oct 30 19:16:42 2002
From: michaell.taylor at reis.com (Michaell Taylor)
Date: Wed, 30 Oct 2002 13:16:42 -0500
Subject: [R] ..of R, OS X, and linux
Message-ID: <200210301316.42202.michaell.taylor@reis.com>


I am an avid linux user who is intrigued with apple's OS X.  

I am now considering purchasing another laptop - which may provide an excuse 
to get a feel of OS X. Of course there are lots of considerations, but R 
command file processing speed is a major factor. 

I know of many speed comparisons between G4/G3 and the various flavors of 
Pentiums, but more useful would be one specifically utilizing R.

Has anyone conducted such a test? 

=========================================
Michaell Taylor, PhD

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Wed Oct 30 07:08:54 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 30 Oct 2002 19:08:54 +1300
Subject: [R] extracting Std. Error value from lm/nls
In-Reply-To: <003a01c2802e$22ab5560$39cffea9@batata>; from aolinto@bignet.com.br on Wed, Oct 30, 2002 at 02:05:06PM -0200
References: <3DBFCFF2.10CCBDF9@bigpond.com> <003a01c2802e$22ab5560$39cffea9@batata>
Message-ID: <20021030190854.A12508@camille.indigoindustrial.co.nz>

On Wed, Oct 30, 2002 at 02:05:06PM -0200, Antonio Olinto wrote:
> Hi,
> 
> How to extract Std. Error values from a lm or a nls?

You get them from the summary object, not the model fit itself.

try something like...

summary(lm(foo ~ bar))$coefficients

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Kosenkov.Kirill at nac.spb.ru  Wed Oct 30 20:09:48 2002
From: Kosenkov.Kirill at nac.spb.ru (=?koi8-r?B?68/Txc7Lz9cg68nSyczMIO7Jy8/MwcXXyd4=?=)
Date: Wed, 30 Oct 2002 22:09:48 +0300
Subject: [R] help needed. Why R does not produce lattice graphics when running command 'source (file_name)'?
References: <D7A3CFD7825BD6119B880002A58F06C20149D15F@groexmb02.pfizer.com>
Message-ID: <00a001c28047$edacbfb0$6900a8c0@nac.net>

Thanx a lot for help for everyone!
print(...some lattice plot...) is really works.. 

Thanx again


> > -----Original Message-----
> > From: Kosenkov.Kirill at nac.spb.ru [mailto:Kosenkov.Kirill at nac.spb.ru]
> > Sent: Wednesday, October 30, 2002 11:28 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] help needed. Why R does not produce lattice 
> > graphics when running command 'source (file_name)'?
> > 
> > 
> > Hi!
> > I have a source file - for example 'my.R' - which uses some 
> > functions from
> > 'lattice' library.
> > It looks like that:
> > 
> >     library(lattice)
> >     pr<-xtabs(W~ff$'q1'+ff$'q2',data=ff)
> >     pr<-pr/rowSums(pr)*100
> >     pr<-as.data.frame(pr)
> > 
> >     barchart(pr[[2]]~pr[[3]]|pr[[1]], horizontal=TRUE, as.table=TRUE,
(cut)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thsudler at swissonline.ch  Wed Oct 30 20:19:41 2002
From: thsudler at swissonline.ch (Thomas Sudler)
Date: Wed, 30 Oct 2002 20:19:41 +0100
Subject: [R] snip.rpart with R 1.6.0, problem solved
Message-ID: <003c01c28049$4d2232d0$1b44da50@homepc>

Hi

Thank you very much for your help. My problem is exactly this one:

"I think he may mean that the visual deletion in snip.rpart.mouse is not
working. It only works if the background colour is opaque, which is not
the default on e.g. x11() in either system."

But now I don't know how to set the background to OPAQUE? Because in R 1.5.1
I didn't have to do this...

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Wed Oct 30 20:37:16 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 30 Oct 2002 14:37:16 -0500
Subject: [R] extracting Std. Error value from lm/nls
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC83B@usrymx10.merck.com>

?summary.lm says, under the "Value" section,

coefficients: a p x 4 matrix with columns for the estimated coefficient,
              its standard error, t-statistic and corresponding (two-
              sided) p-value.

so try summary(fit.lm)$coefficients[,1:2] to get the coefficients and their
SEs.

For nls, it takes a bit more digging, as the documentation is a bit sparse.
Something like:

 summary(nlsfit)$parameters[,1:2]

will give what you want.

Cheers,
Andy

-----Original Message-----
From: Antonio Olinto [mailto:aolinto at bignet.com.br]
Sent: Wednesday, October 30, 2002 11:05 AM
To: R-Help
Subject: [R] extracting Std. Error value from lm/nls


Hi,

How to extract Std. Error values from a lm or a nls?

With coef(model), coef(model)[1], coef(model)[2] and df.residual(model)  I
can get the coeffcients and the degrees of freedom but I couldn't find a way
to get Std. Error  values.

Thanks,

Antonio Olinto




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Oct 30 21:28:53 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 30 Oct 2002 12:28:53 -0800 (PST)
Subject: [R] two small wishes for R
In-Reply-To: <20021030152325.92127.qmail@web10505.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0210301220470.87532-100000@homer25.u.washington.edu>

On Wed, 30 Oct 2002, Jason Liao wrote:

> 1. allows underscore as part of a variable name

Not (yet) possible. Underscore is currently an alternative to <-.
Allowing it as part of variable names is the reason that _ for assignment
now gives a warning in 1.6.0.  It's a fairly major change, though.


> 2. Uses C or Java style comments mark.

This is also a fairly major change to the grammar, not really a small wish


If you want Java, you know where to find it.


	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jbond at arg.org  Wed Oct 30 21:34:57 2002
From: jbond at arg.org (Jason Bond)
Date: Wed, 30 Oct 2002 12:34:57 -0800
Subject: [R] Error in Fields TPS function {svd ...} again
Message-ID: <5.1.0.14.2.20021030121115.01db3650@38.168.156.2>

Thanks for all the helpful responses.  I include the data file and the 
syntax file for reference.  Again, if I use the fields function, as is, I 
get the message:

Error in svd(tempM) : error  159  in dsvdc

using traceback, I get:

 > traceback()
4: stop(paste("error ", z$info, " in dsvdc"))
3: svd(tempM)
2: Krig(x, Y, cov.function = rad.cov, m = m, decomp = decomp, scale.type = 
scale.type,
        outputcall = Tpscall, p = p, ...)
1: Tps(bvolcap, bdsm)
 >


if I change the occurrence of svd in the fields package to La.svd, I get 
the error message

 > bout <- Tps( bvolcap, bdsm)
Error in "[<-"(*tmp*, (nt + 1):np, (nt + 1):np, value = temp$v) :
         number of items to replace is not a multiple of replacement length
 >

traceback() then gives:

 > traceback()
2: Krig(x, Y, cov.function = rad.cov, m = m, decomp = decomp, scale.type = 
scale.type,
        outputcall = Tpscall, p = p, ...)
1: Tps(bvolcap, bdsm)
 >

Sorry to be so useless, I am a R (S) newbie.  Any advice is greatly appreciated.
-------------- next part --------------
data <- read.table("splus-data-black.dat")


bdsmt <-    data[1]
bdsm <-    bdsmt[bdsmt > -777]

bvolcapt <- data[2]
bvolcap <- bvolcapt[bvolcapt > -777]


bout <- Tps( bvolcap, bdsm)
-------------- next part --------------
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
2	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
2	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	1.5
0	3
1	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3
0	3.5
0	5
1	5
0	5
0	5
0	5
1	5
0	6
1	6.5
0	6.5
0	6.5
0	6.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
1	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
1	7.5
1	7.5
1	7.5
1	7.5
0	7.5
1	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	7.5
0	8.5
0	8.5
0	10
0	10
0	10
0	10
0	10
0	11
1	11
0	11
0	11
1	11
0	12.5
0	13.5
0	13.5
0	13.5
0	13.5
0	13.5
1	13.5
0	13.5
0	13.5
0	13.5
0	13.5
0	13.5
0	13.5
1	13.5
0	13.5
0	13.5
0	13.5
0	13.5
0	13.5
0	13.5
0	13.5
0	13.5
0	14.5
0	14.5
0	14.5
0	14.5
0	14.5
0	14.5
0	14.5
1	17
0	17
0	17.5
0	17.5
1	18.5
0	20.5
1	20.5
0	20.5
1	22
1	22
2	22
0	23
0	25
0	25
0	25
0	25
0	25
0	25
0	25
0	25
0	25
0	25
0	25
0	25
0	25
0	26.5
5	26.5
1	30
0	31
2	31
1	31
2	31
0	31
0	31
1	31
1	36
0	36
0	36
1	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
1	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
2	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	36
0	37.5
0	39
0	39.5
0	39.5
0	39.5
0	39.5
0	42.5
0	43
0	43
0	44.5
0	45
0	45
0	45
1	46.5
0	51.5
0	53.5
0	53.5
0	53.5
0	53.5
2	55
0	59.5
0	59.5
3	61
0	61
1	65.5
2	65.5
0	67.5
0	67.5
0	67.5
0	67.5
0	67.5
0	68.5
0	73
0	73.5
1	74
0	82.5
0	85
0	87
0	91.5
0	97.5
0	97.5
0	97.5
3	97.5
0	99
0	102.5
0	104.5
2	109.5
2	117
0	120
0	120
0	120
0	120
0	120
0	120
0	120
4	120
0	120
1	120
1	120
2	120
0	120
0	120
0	120
0	120
0	120
0	121.5
0	126
0	126
0	126
0	126
0	126
1	126
0	126
0	126
0	126
0	126
2	126
0	126
0	126
0	126
0	126
0	126
0	126
0	126
2	126
0	126
0	126
0	126
0	126
1	126
4	126
0	126
1	126
0	126
0	126
0	126
0	126
0	126
0	126
0	126
0	126
0	126
0	126
0	126
1	126
0	126
0	126
0	127.5
0	129.5
0	129.5
0	129.5
2	131
0	132
0	133
0	133
0	133
0	133
0	135.5
0	143.5
0	148.5
0	149.5
0	150
0	150
0	155.5
0	155.5
0	155.5
0	157.5
0	157.5
2	157.5
0	157.5
0	157.5
0	159.5
0	169
3	170.5
0	172.5
0	173.5
1	173.5
0	180
0	183.5
0	184.5
0	184.5
1	187.5
0	187.5
0	191
0	204.5
1	207
0	210
2	210
1	210
0	210
0	223.5
1	240
0	242.5
0	264
3	264
0	264
0	270
0	270
0	270
0	270
0	270
0	270
0	273.5
0	275.5
0	287.5
4	287.5
0	297
1	301.5
5	324
0	330
1	330
0	330
5	376.5
1	401.5
0	420
1	420
0	420
1	420
0	420
0	420
1	420
0	420
1	420
1	420
0	430.5
0	432
0	441.5
5	450
5	450
1	456
1	464.5
0	469.5
0	492
0	492
0	492
0	498
0	511
0	521
0	540
4	540
0	540
0	540
0	540
0	540
0	540
0	543.5
0	547
3	557
0	557.5
4	564
0	582
7	606
2	609
0	666
1	666
0	692.5
1	708
2	715.5
0	756
0	792
1	792
1	804
0	805.5
0	834
6	863
5	900
2	900
6	924
0	924
0	924
0	943.5
1	969
0	1015.5
5	1053
2	1068
0	1068
2	1088
4	1126.5
5	1195.5
0	1267.5
1	1267.5
0	1267.5
2	1285.5
0	1302
0	1357.5
0	1405.5
1	1416
5	1487.5
0	1487.5
0	1512
1	1717.5
0	1722
1	1722
3	1739.5
3	1969
1	2041.5
4	2099.5
3	2121
0	2244
0	2340
2	2352
3	2519
1	2688
0	2807.5
1	2807.5
1	2807.5
2	2807.5
3	3450
1	4080
0	4680
7	4680
0	4680
1	4680
-------------- next part --------------


From king at tolstoy.newcastle.edu.au  Wed Oct 30 22:29:37 2002
From: king at tolstoy.newcastle.edu.au (king@tolstoy.newcastle.edu.au)
Date: Thu, 31 Oct 2002 08:29:37 +1100 (EST)
Subject: [R] sm packcage compilation problem fixed
Message-ID: <Pine.LNX.4.21.0210301149360.32413-100000@tolstoy.newcastle.edu.au>

I have discovered a problem with the compilation of the sm package.

On debian 2.2, sm was not compiling.

* Installing *source* package 'sm' ...
** libs
g77   -fPIC  -g -O2 -c routines.f -o routines.o
gcc -shared  -o sm.so routines.o   -L/usr/lib/gcc-lib/i386-linux/2.95.4
-lreadline -ldl -lncurses -lg2c-pic -lm -L/usr/lib/R/bin -lR
/usr/bin/ld: cannot find -lg2c-pic
collect2: ld returned 1 exit status
make: *** [sm.so] Error 1
ERROR: compilation failed for package 'sm'

But updating to a newer version of g77 and g77-2.95 fixed the problem:

(Reading database ... 81253 files and directories currently installed.)
Preparing to replace g77-2.95 1:2.95.4-0.010810 (using
.../g77-2.95_1%3a2.95.4-7_i386.deb) ...
Unpacking replacement g77-2.95 ...
Preparing to replace g77 2:2.95.4-6 (using
.../g77_2%3a2.95.4-14_i386.deb) ...
Unpacking replacement g77 ...


----
Robert King, Statistics, School of Mathematical & Physical Sciences,
University of Newcastle, Australia
Room V133  ph +61 2 4921 5548
Robert.King at newcastle.edu.au   http://maths.newcastle.edu.au/~rking/







-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.murrell at auckland.ac.nz  Wed Oct 30 22:48:53 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 31 Oct 2002 10:48:53 +1300
Subject: [R] Settings of lattice graphs
References: <15807.36921.779502.738006@gargle.gargle.HOWL> <30892.1035980178@www33.gmx.net> <200210301205.12663.deepayan@stat.wisc.edu>
Message-ID: <3DC053C5.34E7B69A@stat.auckland.ac.nz>

Hi


Deepayan Sarkar wrote:
> 
> On Wednesday 30 October 2002 06:16 am, hgoehlmann at gmx.de wrote:
> > I am trying to modify the outer margin of a lattice graph and I am just not
> > sure whether this is possible or not - something like
> >
> > par(c(5, 4, 4, 2) + 0.1)
> >
> > Is there such a thing?
> 
> No, as far as lattice is concerned. par() settings do not affect grid (hence
> lattice) graphics. If you want to leave out space outside the plot, use the
> position argument in print.trellis.


It is also possible to place lattice plots within generic grid
viewports, which allow you to manipulate the space around the plot in
many different ways.  See the last example in example(print.trellis) --
the important bit is the newpage=FALSE -- also, the following gives a
simple example where the margins could be increased by a number of lines
on each side of the lattice plot ...

    library(lattice)
    x <- y <- 1:10
    myplot <- xyplot(y ~ x)
    
    grid.newpage()
    grid.rect(gp=gpar(col=NULL, fill=trellis.par.get("background")$col))
    push.viewport(plotViewport(c(5, 4, 4, 2) + 0.1))
    print(myplot, newpage=FALSE)
    # Just to show where the extra margin starts
    grid.rect(gp=gpar(lty="dashed"))
    pop.viewport()

... and here's a more complex example that gives a bit of an idea of the
flexibility you can get if you work a bit harder ...

    # Grid viewport to place lattice plot within within
    widths <- unit(c(1, 1, 3), c("inches", "null", "lines"))
    heights <- unit(c(0.1, 1, 1), c("npc", "null", "cm"))
    push.viewport(viewport(layout=grid.layout(3, 3,
                             widths=widths,
                             heights=heights)))
    # Draw the lattice plot
    push.viewport(viewport(layout.pos.col=2,
                           layout.pos.row=2))
    print(myplot, newpage=FALSE)
    pop.viewport()
    # Some annotation of the margins
    push.viewport(viewport(layout.pos.col=1,
                           layout.pos.row=2))
    grid.text("1 inch")
    pop.viewport()
    push.viewport(viewport(layout.pos.col=3,
                           layout.pos.row=2))
    grid.text("3 lines")
    pop.viewport()
    push.viewport(viewport(layout.pos.col=2,
                           layout.pos.row=3))
    grid.text("1 cm", rot=90)
    pop.viewport()
    push.viewport(viewport(layout.pos.col=2,
                           layout.pos.row=1))
    grid.text("0.1 npc", rot=90)
    pop.viewport(2)

Hope that helps :)

Paul
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgilbert at bank-banque-canada.ca  Wed Oct 30 22:44:51 2002
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 30 Oct 2002 16:44:51 -0500
Subject: [R] Sweave in packages
References: <200210301500.g9UF0Se25985@pc112145.oulu.fi>
Message-ID: <3DC052D3.48FB119D@bank-banque-canada.ca>

"Vincent J. Carey, Jr." wrote:
> 
> as we build Sweave documents illustrating package functionalities
> it is sometimes desirable to attach a package "behind
> the scenes".  

Part of the response below is also related to the above.

Jari Oksanen wrote:
> 
> Dear R folks,
> 
> One of the fantastic new tools in R is `Sweave'. 

I agree.

>I have tested it so much that I
> know it works and produces fine documentation, and with (GNU) Emacs/ESS it is
> nice to work with, too. I started to have a look at including some Swoven (is
> that a strong verb?) documentation with my R package, but it seems that there is
> no model to copy among those packages that I have installed in my R. Has anybody
> used Sweave for package vignettes? I have run into some minor inconveniences,
> where I would appreciate hints:

This may be the blind leading the blind, but perhaps the real authority will
speak up when I really mess things up. Most of the information below has been
provided by Friedrich Leisch so I am repeating it in the hope he will not have
to, and can fix other problems I have being bugging him about :-). I have been
converting my Users's Guide from Framemaker to Latex and then using Sweave to
test/fill-in the examples. Sweave can use either tex or noweb style source, but
I know nothing about the latter, so everything below is the tex style.

I am not a hard core Latex user, so there is an extra wrinkle in that I would
often like to use Lyx (a WYSIWYG Latex editor) to edit my files. To do this I
keep my source in guidesrc/guide.tex (Lyx wants a .tex extension) and copy this
to inst/doc/guide.Stex, which Sweave wants as source. Sweave generates a file
guide.tex, so a bit of care is necessary to make sure this does not overwrite my
original source. I can completely remove inst/doc when I clean, so this would be
one way to deal with the extra files that are generated by Sweave. However, I
usually run Sweave in a different directory (tmp) so the extra files are there.

In my Users' Guide examples I typically show user input, but not system output.
Occassionally I change this to hide both (e.g. generating objects generated in
previous sections of the guide), or to show both, or to show generated graphics.
This is done by setting the default in the .Stex file with

\SweaveOpts{eval=TRUE,echo=TRUE,results=hide,fig=FALSE}

and then temporarily changing the default, for a single Scode segment, for
example:

\begin{Scode}{echo=FALSE,results=hide}
   code with neither input or output shown
\end{Scode}

or

\begin{Scode}{fig=TRUE, echo=FALSE}
  graphic is shown, but not input
\end{Scode}

Note that checkVignettes() actually runs all the code to check that it works. If
you want to show results, have results available for the next section of Scode,
or make a library available, then you must have eval=TRUE. This results in the
code being run twice, once for the check and once for making the results
available. (I think there is some possibility this will change in a future
release.)

> - I cannot find out in R-exts manual how to actually write \VignetteIndexEntry
> so that it would be incorporated into 00Index.dcf. Should you put the entry
> within braces (LaTeX way) or use colon or something before the entry
> (00Index.dcf instructions)? 

%\VignetteIndexEntry{Title you would like}

The % makes it a tex comment.

>Actually, I cannot get much of an 00Index.dcf: If I
> use --force to build the package, the 00Index.dcf will be replaced with an
> empty file (size 0 bytes). Further, I haven't figured out how to transfer the
> \VignetteIndexEntry to the ultimate pdf file. All my attempts to write the
> 00Index.dcf file manually have ended with R sarcastically saying to me that
> my index is not up-to-date and writing over my file with an empty file
> (obviously I should be more careful in my hand writing...).

I have not figured this out either, but the index is not much of a problem if
the \VignetteIndexEntry generates it. I am not certain of the relationship of
00Index.dcf  to the ultimate pdf file.

> - It seems that it is necessary to use Makefile because R CMD BUILD doesn't
> clean the inst/doc directory from the interim files Sweave produces to build the
> pdf (foo-???.eps, foo-???.pdf, LaTeX files like foo.blg, foo.bbl, foo.aux,
> foo.log, etc). Is there any other solution here?

I have been using Makefiles, so I haven't consider other solutions. I don't
believe R CMD build actually generates the files there, although I may be wrong
on this point. If they are already there from running checkVignettes(), then
build will copy them unless you indicate otherwise in .Rbuildignore (and have a
version of tar more recent than 1.13 - which is the most recent version on the
GNu site ;-) ).  

> - Is it indeed the purpose that the final document should be a pdf file even in
> source packages. The pdf files tend to become huge, and easily multiply the size
> of a source package. As I have a 56KB modem at home (working at ~5KB file
> transfer speed in practice) I am really concerned with this aspect as well (it
> doesn't concern me at all when at work). Is the assumption that users won't have
> tools to build a pdf from the Sweave source?

Well, I just asked this question yesterday (privately to Friedrich) and have not
yet heard back. My inclination is to distribute the .Stex files and a .pdf file,
so users can attempt to generate the guide, but will have it if they cannot. I
haven't looked at how big this will be. I suppose another option would be to put
the .pdf file on a web site.

Best,
Paul Gilbert

> cheers, jari oksanen
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Wed Oct 30 23:04:29 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Wed, 30 Oct 2002 14:04:29 -0800
Subject: [R] Mac OS 9 and file type/creator
In-Reply-To: <Pine.LNX.4.31.0210301757480.5393-100000@gannet.stats>
Message-ID: <903680C1-EC53-11D6-A502-000393860F3C@stat.ucla.edu>

Macintosh files (in OS 9 and before) basically have three forks: a data  
fork, a resource
fork, and a finder information fork. The finder information has the  
type and a creator
specification, in the case of a pdf file these are PDF /CARO. This  
information
tells the finder which application to open the file with, which icon to  
show,
and so on. There is room for 10^8 vendors, and each of these vendors can
create 10^8 types of files. PDF /CARO get the Adobe icons, etc. The  
files that
R creates are basically  flat files, with a single fork, in which there  
is no room
for finder information.

Although many people deplore this, OS X writes flat files as well and  
derives
type/creator information from the name of the file. So foo.pdf is known  
to be
a pdf file and the finder knows that pdf files must be opened with  
AcroRead
or Preview or whatever you set in your preferences. This is the  
classical
MIME-type scheme, less flexible, more simple.

Since both R and the Mac OS will pretty soon be completely OS X
dominated, I don't think it is really worthwhile to build in legacy OS 9
characteristics which actually hinder portability.


On Wednesday, October 30, 2002, at 10:03 AM, <ripley at stats.ox.ac.uk>  
wrote:

> On Wed, 30 Oct 2002, David Orme wrote:
>
>> I'm using R1.5.0 on Mac OS 9.1 to create graphics as pdf files. One
>> problem, admittedly pretty minor, is that the file type and creator
>> are blank. Is there any way from within R of setting the file type
>> and/or file creator of the resulting files so that OS9 can work out
>> which program to open the files in?
>
> I don't see file type as a field in the PDF spec, and also don't see
> how a field in a file can help tell you which program to open it with,
> when it is already open by then ....
>
> The creator field could be filed in as R, I guess, but it won't help  
> you.
> It's purely for information.
>
> I think your OS has not got its MIME types sorted.
>
> --  
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Wed Oct 30 23:11:09 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Wed, 30 Oct 2002 14:11:09 -0800
Subject: [R] ..of R, OS X, and linux
In-Reply-To: <200210301316.42202.michaell.taylor@reis.com>
Message-ID: <7E227AB3-EC54-11D6-A502-000393860F3C@stat.ucla.edu>

This would depend very much on the task. It is quite obvious that
for heavy floating point, especially double precision floating point
without tweaking, top of the line Pentium will be considerably
faster than current top of the line G4 (single processor). For ordinary
interactive computing, you will not see much difference, I think,
and for the really gigantic computing tasks you need to go to
multiple processors/multiple machines anyway.

On Wednesday, October 30, 2002, at 10:16 AM, Michaell Taylor wrote:

>
> I am an avid linux user who is intrigued with apple's OS X.
>
> I am now considering purchasing another laptop - which may provide an  
> excuse
> to get a feel of OS X. Of course there are lots of considerations, but  
> R
> command file processing speed is a major factor.
>
> I know of many speed comparisons between G4/G3 and the various flavors  
> of
> Pentiums, but more useful would be one specifically utilizing R.
>
> Has anyone conducted such a test?
>
> =========================================
> Michaell Taylor, PhD
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Oct 30 23:40:05 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 30 Oct 2002 22:40:05 +0000 (GMT Standard Time)
Subject: [R] snip.rpart with R 1.6.0, problem solved
In-Reply-To: <003c01c28049$4d2232d0$1b44da50@homepc>
Message-ID: <Pine.WNT.4.44.0210302235170.3868-100000@petrel>

You can't.  You can set it to white, e.g. par(bg="white").

As far as I can see this has been true since 1.4.0: it certainly seems so
on the only remaining 1.5.1 system I have installed.

On Wed, 30 Oct 2002, Thomas Sudler wrote:

> Hi
>
> Thank you very much for your help. My problem is exactly this one:
>
> "I think he may mean that the visual deletion in snip.rpart.mouse is not
> working. It only works if the background colour is opaque, which is not
> the default on e.g. x11() in either system."
>
> But now I don't know how to set the background to OPAQUE? Because in R 1.5.1
> I didn't have to do this...

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgilbert at bank-banque-canada.ca  Wed Oct 30 23:45:54 2002
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 30 Oct 2002 17:45:54 -0500
Subject: [R] Estimation of transfer function time series models
References: <200210301110.36362.susanabarbosa@novalis.fc.up.pt>
Message-ID: <3DC06122.2E3907C5@bank-banque-canada.ca>

Susana Barbosa wrote:
> 
> Hi,
> 
> Is there a function in R to estimate transfer function time series models?
> 
> Thanks in advance
> 
> Susana Barbosa

Transfer function models are very similar to ARMA models. The AR and MA parts
are the denominator and numerator of the transfer function. I tend to think of
these models as the same, with a different emphasis in the terminology. With
transfer functions, one typically thinks of the input as a control (and often
ignores any random inputs). ARMA models typically have random (noise) input and
are called ARMAX if there is a control input (exogenous) in addition to the
noise.

There are a few functions on CRAN for ARMA models. See arima in the ts package
or for multivariate models consider various methods in the dse bundle.

Paul Gilbert
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chergr at bigpond.com  Thu Oct 31 00:22:11 2002
From: chergr at bigpond.com (Richard)
Date: Thu, 31 Oct 2002 10:22:11 +1100
Subject: [R] Flushing the R output buffer.
References: <Pine.LNX.4.31.0210301609520.5214-100000@gannet.stats>
Message-ID: <3DC06999.4FFE91FF@bigpond.com>



ripley at stats.ox.ac.uk wrote:

> On Wed, 30 Oct 2002, Richard wrote:
>
> > flusHi,
>
> ???
>
> > I am connecting R to a PHP web script.
> >
> > The first effort attempted to use a named pipe
> > but gave up on that because PHP could not read
> > any data from the named pipe.
> >
> > I changed to using a temp file but it also has problems.
> > It appears that the file to which R's output is redirected
> > is not recieving any output until the pipe connection form PHP
> > is closed. I think this means that R is buffering its output
> > and there appears to be no flush function.
>
> Redirected output is normally buffered: it's an issue for your OS's
> runtime system.  R is just a C program.

Are you saying that R cannot implement a flush function
and that there is a Linux command to accomplish this?

>
>
> > I would like to use a sequence like:
> >
> > open pipe to R and incommand redirect R outout to file/fifo
> >
> > open file
> > send R command
> > read response from file
> > close file
> >
> > open file
> > send R command
> > read response from file
> > close file
> > .
> > .
> > close pipe
> >
> > I checked the archives and there a function
> > flush.console() was mentioned -- I looked for this in
> > the docs but could not find it. The function does not appear
> > to affect flushing of the R output to the file.
>
> Well, it is documented for the Windows GUI, where it does work.
> How can a function you can't find affect R when you can't run it?

I'm not sure how to interpret this. Its not listed as a function
in refman.pdf. It is mentioned in connection with the Windows
version in the list archives and it seemed reasonable that it should be
available
for any OS. I tried it, it does not produce a run-time error, it simply
does not flush. I can only guess that it is in the interpreter's
table of names but is missing an implementation or is buggy
on Linux.

>
>
> > This is a RedHat Linsux 7.3 on x86 install
>
> Try using connections, in particular a fifo and play with blocking.  It
> would not be too hard to implement a flush() function if you want one
> (there is internal support for it in the design of connections): if
> you do write one, please contribute it.

Well it might be just a few lines of code, but by the time I become
some approximation of a unix systems programmer and study the
R source code to figure out how to modify it and figure out
how to compile R it just might take a long time.

When you say "try using connections" it is not clear if
you are referring to modifying R or doing something
with PHP. PHP has to start up R and at the same time
build some kind of communications link. The cleanest
approach would be a bidirectional pipe but this
appears to be an experimental feature of PHP
(its only available via the CVS distribution according to the docs).
For a production server with 500 student's hanging off
it, experimental features are not ideal.

The other approach, described above, is a unidirectional pipe
combined with
a named pipe or file for the return communications.
(as in: popen("R --silent --slave > named_pipe", "w") )
The lack of a working flush in R makes this approach difficult.

Another approach is to send all of the R script in one go
as part of the command using <<
with popen set to read mode and to use the R print function to surround
each separate item of output with a delimiter and a tag
and then read all of the returned output with PHP
and parse it with PHP to break the output
down into its components. Ick!!



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Thu Oct 31 00:36:47 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 30 Oct 2002 17:36:47 -0600
Subject: [R] groupedData
In-Reply-To: <1296.160.45.195.78.1035980343.squirrel@www.medizin.fu-berlin.de>
References: <1296.160.45.195.78.1035980343.squirrel@www.medizin.fu-berlin.de>
Message-ID: <6radkv7b3k.fsf@bates4.stat.wisc.edu>

"Dr. Peter Schlattmann" <peter.schlattmann at medizin.fu-berlin.de> writes:

> Dear all,
> 
> I tried to create a groupedData object, where the grouping factor
> is not ordered.
> 
> Here is the code:
> 
> library(nlme)
> test<-groupedData(conc~Time|Subject,order.groups=F,data=as.data.frame(Theoph))
> > getGroups(test)
> 
> Levels: 6 < 7 < 8 < 11 < 3 < 2 < 4 < 9 < 12 < 10 < 1 < 5
> 
> I still get an ordered factor. As always thanks for your help

It's because Theoph$Subject is already an ordered factor.  To get rid
of the property of being ordered you must convert it to character and
back to a factor.

> data(Theoph)
> theo <- as.data.frame(Theoph)
> theo$Subject <- factor(as.character(theo$Subject))
> test <- groupedData(conc~Time|Subject,order.groups=FALSE,data=theo)
> getGroups(test)
...
Levels: 1 10 11 12 2 3 4 5 6 7 8 9
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Thu Oct 31 00:46:17 2002
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 30 Oct 2002 15:46:17 -0800
Subject: [R] Re: RODBC update
In-Reply-To: <Pine.LNX.4.31.0210301407280.7335-100000@gannet.stats>
References: <Pine.LNX.4.31.0210301407280.7335-100000@gannet.stats>
Message-ID: <p05111a07b9e613febe5f@[128.115.153.6]>

RODBC with Mac OS X 10.2.1
Installation completed without error messages.
Connection attempt failed.

>  version
          _                     
platform powerpc-apple-darwin6.1
arch     powerpc               
os       darwin6.1             
system   powerpc, darwin6.1    
status                         
major    1                     
minor    6.0                   
year     2002                  
month    10                    
day      01                    
language R                     


The gcc commands from the installation step were
gcc -no-cpp-precomp -I/Users/macq/R/R-1.6.0/build/include 
-I/sw/include -I/usr/local/include   -fno-common  -g -O2 -c RODBC.c 
-o RODBC.o

gcc -bundle -flat_namespace -undefined suppress -L/sw/lib 
-L/usr/local/lib -o RODBC.so RODBC.o -liodbc

Connection attempt failed (blank lines inserted for readability):

>  chn <- 
>odbcConnect('taurus',uid='macq',host='delphi.llnl.gov',pwd='a.valid.password')

/Users/macq/R/R-1.6.0/build/bin/R.bin: can't map file: 
/Library/ODBC/OpenLink Generic ODBC Driver.bundle ((os/kern) invalid 
argument)

/Library/ODBC/OpenLink Generic ODBC Driver.bundle(0): Object Image Load Failure

Warning message:

ODBC connection failed in: odbcConnect("taurus", uid = "macq", host = 
"delphi.llnl.gov", 
>

The DSN, uid, host, and password are valid in the sense that they 
work with at least one OS X native odbc client: Microsoft Excel.

The ODBC driver that R found is partially correct, in that it is from 
OpenLink (www.openlinksw.com). Installing the OpenLink driver in OS X 
also installed an application called iODBC Administrator which is 
used to configure the driver, and some iodbc libraries in /usr/local, 
see below.

Within the "OpenLink Generic ODBC Driver.bundle" is a file named 
oplodbc.so, which might be the file RORACLE is looking for when it 
generates the error message?

OpenLink Generic ODBC Driver.bundle[228]% pwd
/Library/ODBC/OpenLink Generic ODBC Driver.bundle
OpenLink Generic ODBC Driver.bundle[229]%
OpenLink Generic ODBC Driver.bundle[229]% find . -name oplodbc.so
./Contents/MacOS/oplodbc.so

[250]% ls /usr/lib/libio*
/usr/lib/libiodbc.2.1.6.dylib*             /usr/lib/libiodbc.dylib@ 
/usr/lib/libiodbcinst.a
/usr/lib/libiodbc.2.dylib@ 
/usr/lib/libiodbcinst.2.1.6.dylib* 
/usr/lib/libiodbcinst.dylib@
/usr/lib/libiodbc.a                        /usr/lib/libiodbcinst.2.dylib@

Or maybe configure should have found the dylibs?

Maybe I should put a link oplodbc.so somewhere where configure can 
find it? In /usr/lib? Just making wild guesses here...

-Don

At 2:21 PM +0000 10/30/02, <ripley at stats.ox.ac.uk> wrote:
>There is a new version of RODBC, 0.9-1, with a new maintainer (me)
>now on CRAN (Vienna) which works with R 1.6.x.  The Windows binary
>will be there tomorrow, and both will then propagate around CRAN.
>
>This has been tested on Linux under unixODBC against MySQL and Postgresql
>(thanks to Dirk Edelbuettel), and on Windows against Access, MySQL and
>Excel.  The CRAN compilation checks were against iODBC.
>
>I had to make quite a lot of internal changes, so would appreciate
>success/problem reports for other uses.
>
>There are several improvements in this version, some of which I had
>previously submitted to Michael Lapsley: see the ChangeLog.  I am
>moving towards a 1.0 release which will be somewhat incompatible
>(`channel' will be a classed object and quoting names will be
>essential to allow them to be passed as R variables, for example).
>
>In the longer term the planned DBI/ODBC interface may replace RODBC
>entirely via a back-compatibility wrapper.
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272860 (secr)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-announce mailing list -- Read 
>http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wviechtb at s.psych.uiuc.edu  Thu Oct 31 03:41:38 2002
From: wviechtb at s.psych.uiuc.edu (Wolfgang Viechtbauer)
Date: Wed, 30 Oct 2002 20:41:38 -0600 (CST)
Subject: [R] Changing pch spacing
Message-ID: <Pine.SOL.4.30.0210302029480.1374-100000@s.psych.uiuc.edu>

Hello R-Helpers,

plot(x, y, type="b", pch="1")

plots x vs. y with both a line and the symbol "1" but how do I change
the "spacing" of the symbol being plotted. In other words, I don't want
to plot the "1" at every data point, but only at every kth point (things
get too cluttered when there are many data points). Thanks in advance!

--
Wolfgang Viechtbauer

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gbarlow at bellsouth.net  Thu Oct 31 04:58:33 2002
From: gbarlow at bellsouth.net (g barlow)
Date: Wed, 30 Oct 2002 22:58:33 -0500
Subject: [R] Please Help. Subtraction of Matrices?
Message-ID: <4.3.2.7.2.20021030224751.00c34bc8@mail.bellsouth.net>

I am just beginning to learn R.  Please help. I have two matrices. One 20 
columns by 16 rows represent student responses on a 20 question test. The 
second is 20 by 16 representing the correct responses 16 
times.  Subtracting one from the other should yield 0's if a response is 
correct.  Yet Response minus Bigkey doesn't work.  Documents indicate 
vectors should add and subtract, and seem to imply matrix algebra should 
also work.  How can I do this?  Can you help, and save me a great deal of 
time and trial-and-error.  Thanks for any help.--Gene Barlow, Ft. Lauderdale FL.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bmagill at earthlink.net  Thu Oct 31 04:57:57 2002
From: bmagill at earthlink.net (Brett Magill)
Date: Wed, 30 Oct 2002 21:57:57 -0600
Subject: [R] My Functions on the Web (Including Factor Anlysis by Principal Components)
In-Reply-To: <Pine.SOL.4.30.0210302029480.1374-100000@s.psych.uiuc.edu>
Message-ID: <MBBBLGJNHNDJCJCCJCNGCENKCAAA.bmagill@earthlink.net>

I have made some functions that I wrote available on the web.  Not a
package, but I know some people have found them useful.

The url is:

http://home.earthlink.net/~bmagill/MyMisc.html


Included, and of special interest to some is prinfact, my function for
principal components factor analysis--updated and now including print and
plot methods.

Also included:

Reliability estimates (alpha) and item total correlations for scale/test
development.
Frequency tables and descriptive statistics
A function to convert covariance matrix to correlation matrix
Several others

Comments and suggestions are appreciated.


Brett.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hb at maths.lth.se  Thu Oct 31 06:27:37 2002
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 31 Oct 2002 16:27:37 +1100
Subject: [R] Changing pch spacing
In-Reply-To: <Pine.SOL.4.30.0210302029480.1374-100000@s.psych.uiuc.edu>
Message-ID: <000001c2809e$3a5d5b20$7341a8c0@alpha.wehi.edu.au>

Argument 'pch' can also be a vector, e.g.

x <- rnorm(1000)
y <- rnorm(1000)

# pch=".", but every k:th is a "1".
k <- 5
pch <- rep(".", length(x))
pch[seq(1,length(x),by=k)] <- "1"

plot(x,y, type="b", pch=pch)


> -----Original Message-----
> From: owner-r-help at stat.math.ethz.ch 
> [mailto:owner-r-help at stat.math.ethz.ch] On Behalf Of Wolfgang 
> Viechtbauer
> Sent: den 31 oktober 2002 13:42
> To: r-help at stat.math.ethz.ch
> Subject: [R] Changing pch spacing
> 
> 
> Hello R-Helpers,
> 
> plot(x, y, type="b", pch="1")
> 
> plots x vs. y with both a line and the symbol "1" but how do 
> I change the "spacing" of the symbol being plotted. In other 
> words, I don't want to plot the "1" at every data point, but 
> only at every kth point (things get too cluttered when there 
> are many data points). Thanks in advance!
> 
> --
> Wolfgang Viechtbauer
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-> FAQ.html
> Send "info", 
> "help", or "[un]subscribe"
> (in the 
> "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch 
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Thu Oct 31 06:50:58 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 30 Oct 2002 21:50:58 -0800
Subject: [R] ..of R, OS X, and linux
In-Reply-To: <7E227AB3-EC54-11D6-A502-000393860F3C@stat.ucla.edu>
References: <7E227AB3-EC54-11D6-A502-000393860F3C@stat.ucla.edu>
Message-ID: <873cqnw3zx.fsf@jeeves.blindglobe.net>


The new(er,est?) Mac iBook2's are rather nice and cheap (and quiet --
faster and quieter than my wife's slightly older Sony R505, for
example, and comparably sized).

Plus, if you have the know-how, it makes the perfect Linux laptop :-)
(screams from OS-X and Mac die-hards in the background...), except for
a lack of ability to handle external displays and presentations (but
you really do want Mac OS X and the joys of Mac user friendly
auto-detect/config to make that part completely painless).

You still can run OS9 and OSX from within Linux, if you really want to
(MacOnLinux works, though I'm having problems with getting OS9 on > 8
bit graphics, but who needs it?).  

Now, if you are looking for a desktop replacement rather than a small
notebook ("small" was the operative word for me, 12" screen the max I
would tolerate), you probably want an AMD or Intel-based laptop.  The
TiBook is nice and classy, but probably not as cost effective.

best,
-tony




>>>>> "jan" == Jan de Leeuw <deleeuw at stat.ucla.edu> writes:

    jan> This would depend very much on the task. It is quite obvious that
    jan> for heavy floating point, especially double precision floating point
    jan> without tweaking, top of the line Pentium will be considerably
    jan> faster than current top of the line G4 (single processor). For ordinary
    jan> interactive computing, you will not see much difference, I think,
    jan> and for the really gigantic computing tasks you need to go to
    jan> multiple processors/multiple machines anyway.

    jan> On Wednesday, October 30, 2002, at 10:16 AM, Michaell Taylor wrote:

    >> 
    >> I am an avid linux user who is intrigued with apple's OS X.
    >> 
    >> I am now considering purchasing another laptop - which may provide
    >> an  excuse

    >> to get a feel of OS X. Of course there are lots of considerations,
    >> but  R

    >> command file processing speed is a major factor.
    >> 
    >> I know of many speed comparisons between G4/G3 and the various
    >> flavors  of

    >> Pentiums, but more useful would be one specifically utilizing R.
    >> 
    >> Has anyone conducted such a test?
    >> 
    >> =========================================
    >> Michaell Taylor, PhD
    >> 
    >> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-

    >> .-.-.-.-.-
    >> r-help mailing list -- Read
    >> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html

    >> Send "info", "help", or "[un]subscribe"
    >> (in the "body", not the subject !)  To:
    >> r-help-request at stat.math.ethz.ch

    >> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
    >> ._._._._

    >> 
    >> 
    jan> ===
    jan> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
    jan> Editor: Journal of Multivariate Analysis, Journal of Statistical
    jan> Software

    jan> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
    jan> phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
    jan> homepage: http://gifi.stat.ucla.edu
    jan>    ------------------------------------------------------------------------ 
    jan> -------------------------
    jan>            No matter where you go, there you are. --- Buckaroo Banzai
    jan>                     http://gifi.stat.ucla.edu/sounds/nomatter.au
    jan>    ------------------------------------------------------------------------ 
    jan> -------------------------

    jan> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
    jan> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
    jan> Send "info", "help", or "[un]subscribe"
    jan> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
    jan> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayan at stat.wisc.edu  Thu Oct 31 07:04:36 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 31 Oct 2002 00:04:36 -0600
Subject: [R] Changing pch spacing
In-Reply-To: <Pine.SOL.4.30.0210302029480.1374-100000@s.psych.uiuc.edu>
References: <Pine.SOL.4.30.0210302029480.1374-100000@s.psych.uiuc.edu>
Message-ID: <200210310004.36071.deepayan@stat.wisc.edu>


You could try

plot(x, type="o", pch=c(rep(" ", k-1), "1"))

or

plot(x, type="b", pch=c(rep(" ", k-1), "1"))

though neither are probably exactly what you want.


On Wednesday 30 October 2002 08:41 pm, Wolfgang Viechtbauer wrote:
> Hello R-Helpers,
>
> plot(x, y, type="b", pch="1")
>
> plots x vs. y with both a line and the symbol "1" but how do I change
> the "spacing" of the symbol being plotted. In other words, I don't want
> to plot the "1" at every data point, but only at every kth point (things
> get too cluttered when there are many data points). Thanks in advance!
>
> --
> Wolfgang Viechtbauer
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>.-.- r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help", or
> "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jarioksa at sun3.oulu.fi  Thu Oct 31 07:59:51 2002
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Thu, 31 Oct 2002 08:59:51 +0200
Subject: [R] Sweave in packages 
In-Reply-To: Message from Jeff Gentry <jgentry@jimmy.harvard.edu> 
   of "Wed, 30 Oct 2002 11:49:36 EST." <Pine.SOL.4.20.0210301141030.16763-100000@santiam.dfci.harvard.edu> 
Message-ID: <200210310659.g9V6xpC29039@pc112145.oulu.fi>

Thanks to everybody for the hints on Sweaving. I just changed the
\VignetteIndexEntry to use braces (that I had tried yesterday but in vain), and
no everything seemed to work nicely: 00Index.dcf was updated, and junk files
were deleted from the inst/doc directory leaving only the real sources (foo.Rwn,
foo.bib) and the final result (foo.pdf). This is somehow mysterious to me, since
those braces were indeed the only thing I did differently (and I had even tried
them yesterday), but otherwise I issued the same commands as yesterday (I used
my command .history from yesterday). Thanks to everybody and to the original
spinners of Sweave most of all.

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gygax at ifi.unizh.ch  Thu Oct 31 08:10:25 2002
From: gygax at ifi.unizh.ch (Lorenz Gygax)
Date: 31 Oct 2002 08:10:25 +0100
Subject: [R] Symbols for male/female
Message-ID: <Pine.WNT.4.44.0210310755280.700-100000@GYG-63G37>


Dear all,

I would like to use the biological symbols for male and female as plotting
symbols in a scatterplot (ideally filled and non-filled). R does not seem
to have these symbols using pch= in plot() nor are they implemented via
expression() or at least I did not find them. I found that the symbols are
e.g. available in the wasysym and the marvosym package in LaTeX.

I have coded two very rough functions that are able to approximate those
symbols, but not surprisingly, they are not very efficient regarding the
file size they produce (I have included the code for the female symbol at
the end of the mail).

Is there a more or less straightforward way to implement these symbols so
that they can be accessed either by pch= or expression()? Can you give me
some pointers on how I would need to go about this?

Thanks and regards, Lorenz
-- 
Lorenz Gygax, Dr. sc. nat.
Artificial Intelligence Lab, Department of Information Technology
University of Zurich-Irchel, +41-1-635 67 17,  gygax at ifi.unizh.ch


one.female <- function (X, diam= 1, prop= 1, lw= 1) {
  ## X a vector giving the position of the symbol c (x, y)
  ## diam: diameter in the entities on the Y axis
  ## prop: proportion of x to y axis (so that symbols will be round
  ## lw: adjustment of line width for large symbols

  x.ring <- cos (seq (0, 2*pi, len= 500)) * prop * diam/2
  y.ring <- sin (seq (0, 2*pi, len= 500)) * diam/2
  lines (x.ring + X[1], y.ring + X[2], lwd= lw)
  segments (c (0, -diam/4) + X[1],
            c (-diam/2, -3*diam/4) + X[2],
            c (0,  diam/4) + X[1],
            c ( -diam , -3*diam/4) + X[2], lwd= lw)
}

and to plot several iteams at a time

female <- function (x, y, d= 1, p= 1, l= 1) {
  ## x, y vectors of x and y coordinates
  ## d: diameter
  ## p: proportion of symbol
  ## l: line width

  xy <- cbind (x, y)
  apply (xy, 1, FUN= one.female, diam= d, prop= p, lw= l)
}



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ajsmit at botzoo.uct.ac.za  Thu Oct 31 09:56:47 2002
From: ajsmit at botzoo.uct.ac.za (Smit, A, Albertus, Dr)
Date: Thu, 31 Oct 2002 10:56:47 +0200
Subject: [R] ANOVAs per grouping variable
Message-ID: <3DC10C72.19494.999D7F2@localhost>

Dear all

I have a question regarding repeating a series of nested ANOVAs. 
The model is:

fit <- aov(response ~ treatment + plot/rep)

Treatment has three levels, there are three plots and each plot has 
four replicates. Now, the experiment was also repeated six times 
during the year. Ideally I would have liked to include sampling time 
(month) as an additional factor in the analysis, but this is not possible 
as the repeated measures are not independent and I don't have the 
needed replicates to evaluate variation within individual months. So, 
the next best option is separate ANOVAs for each month.

Since I cannot be bothered re-typing the above model for each month 
(I have many such analyses to do), is there an easy way to 
'automatically' repeat the analysis for each level of sampling time, 
maybe using one of the apply() functions, or alternatively, the less 
efficient for() statement? I have looked at the help files - it is easy with 
functions such as mean(), but more complicated functions seem 
(giving my limited experience with R) somewhat more tricky.

Just as an aside: has anyone computed Tony Underwood's ANOVA 
example given on pages 247 (the data) and 256 (the results) of 
'Experiments in Ecology, 1997'? My results (in R) is different from that 
given in the book. The model used is

aov(fec ~ treat + plot/rep).

Why? Or is my model not the same used by Underwood?

Thanks in advance,
Albertus


Dr. Albertus J. Smit
Department of Botany
University of Cape Town
Private Bag Rondebosch
7700
South Africa
Tel. +27 21 689 3032
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pwolf at wiwi.uni-bielefeld.de  Thu Oct 31 10:24:18 2002
From: pwolf at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Thu, 31 Oct 2002 10:24:18 +0100
Subject: [R] Changing pch spacing]
References: <3DC0F357.4967F34C@wiwi.uni-bielefeld.de>
Message-ID: <3DC0F6C2.D31F462E@wiwi.uni-bielefeld.de>

Wolfgang Viechtbauer wrote:

> Hello R-Helpers,
>
> plot(x, y, type="b", pch="1")
>
> plots x vs. y with both a line and the symbol "1" but how do I change
> the "spacing" of the symbol being plotted. In other words, I don't want
> to plot the "1" at every data point, but only at every kth point (things
> get too cluttered when there are many data points). Thanks in advance!
>
> --
> Wolfgang Viechtbauer

See function bplot defined below.

Peter Wolf




"bplot"<-
function(x,y,k,pch="*",space.size=1/70,space.bg="white",pch.col="black",...){
  # plot of x and y, type "b" with symbols at every k-th points  pw 10/02
  # pch:        characters to be plotted
  # space.size: size of area for the points
  # space.bg:   color of area for the points
  # pch.col:    color of the points
  plot(x,y,type="l",...)
  ind<-seq(x)[seq(x)%%k==0]; x<-x[ind]; y<-y[ind]
  wcoord<-par()$usr
  dh<-c(wcoord[2]-wcoord[1],wcoord[4]-wcoord[3])*space.size
  rect(x-dh[1],y-dh[2],x+dh[1],y+dh[2],col=space.bg,border="white")
  points(x,y,pch=pch,col=pch.col)
}

# Example:

x<-1:500;  y<-cumsum(rnorm(length(x),3,3))
k<-40
bplot(x,y,k,pch=1,space.size=1/70,space.bg="red",pch.col="green")


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bhx2 at mevik.net  Thu Oct 31 10:51:18 2002
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge?= Mevik)
Date: 31 Oct 2002 10:51:18 +0100
Subject: [R] Generating balanced incomplete block designs?
Message-ID: <7o65vjgcmh.fsf@foo.nemo-project.org>

Are there any R functions for generating balanced (or nearly balanced)
incomplete block designs?

-- 
Bj?rn-Helge Mevik

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Roger.Bivand at nhh.no  Thu Oct 31 10:56:58 2002
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 31 Oct 2002 10:56:58 +0100 (CET)
Subject: [R] Error in Fields TPS function {svd ...} again
In-Reply-To: <5.1.0.14.2.20021030121115.01db3650@38.168.156.2>
References: <5.1.0.14.2.20021030121115.01db3650@38.168.156.2>
Message-ID: <63261.129.177.44.49.1036058218.squirrel@webmail.nhh.no>


> Thanks for all the helpful responses.  I include the data file and the
> syntax file for reference.  Again, if I use the fields function, as is,
>
It helped to have your example:

> data <- read.table("splus-data-black.dat")
> dim(data)
[1] 606   2
> summary(data)
       V1               V2
 Min.   :0.0000   Min.   :   0.0
 1st Qu.:0.0000   1st Qu.:   3.0
 Median :0.0000   Median :  36.0
 Mean   :0.3977   Mean   : 247.6
 3rd Qu.:0.0000   3rd Qu.: 149.9
 Max.   :7.0000   Max.   :4680.0
> table(data[1])

  0   1   2   3   4   5   6   7
488  64  24  10   7   9   2   2

Tps(x, Y, ...) expects x to be a matrix, in the geostatistical "world
view" of the locations of the observations in say 2d or 3d:

> Tps(data[,2], data[,1])
Error in svd(tempM) : error  159  in dsvdc

The distribution of your Y makes it look like counts, both x and Y have
smaller numbers of unique values than n=606:

> length(unique(data[,1]))
[1] 8
> length(unique(data[,2]))
[1] 161
> plot(data[,2], data[,1])

shows that the data are rather different from the ones in example(Tps). So
this doesn't look like a typical numerical problem, but Tps being used on
data for which it was not designed, and failing to trap this state.

Roger



 I  get the message:
>
> Error in svd(tempM) : error  159  in dsvdc
>
> using traceback, I get:
>
>  > traceback()
> 4: stop(paste("error ", z$info, " in dsvdc"))
> 3: svd(tempM)
> 2: Krig(x, Y, cov.function = rad.cov, m = m, decomp = decomp, scale.type
> =  scale.type,
>         outputcall = Tpscall, p = p, ...)
> 1: Tps(bvolcap, bdsm)
>  >
>
>
> if I change the occurrence of svd in the fields package to La.svd, I get
>  the error message
>
>  > bout <- Tps( bvolcap, bdsm)
> Error in "[<-"(*tmp*, (nt + 1):np, (nt + 1):np, value = temp$v) :
>          number of items to replace is not a multiple of replacement
> length
>  >
>
> traceback() then gives:
>
>  > traceback()
> 2: Krig(x, Y, cov.function = rad.cov, m = m, decomp = decomp, scale.type
> =  scale.type,
>         outputcall = Tpscall, p = p, ...)
> 1: Tps(bvolcap, bdsm)
>  >
>
> Sorry to be so useless, I am a R (S) newbie.  Any advice is greatly
> appreciated.


-- 
Roger Bivand
NHH, Breiviksveien 40, N-5045 Bergen, Norway
(travelling but still accessible)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Thu Oct 31 10:57:48 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 31 Oct 2002 10:57:48 +0100
Subject: [R] Symbols for male/female
In-Reply-To: <Pine.WNT.4.44.0210310755280.700-100000@GYG-63G37>
References: <Pine.WNT.4.44.0210310755280.700-100000@GYG-63G37>
Message-ID: <15808.65180.500421.902936@gargle.gargle.HOWL>

>>>>> "Lorenz" == Lorenz Gygax <gygax at ifi.unizh.ch>
>>>>>     on 31 Oct 2002 08:10:25 +0100 writes:

    Lorenz> Dear all,

    Lorenz> I would like to use the biological symbols for male
    Lorenz> and female as plotting symbols in a scatterplot
    Lorenz> (ideally filled and non-filled). R does not seem to
    Lorenz> have these symbols using pch= in plot() nor are they
    Lorenz> implemented via expression() or at least I did not
    Lorenz> find them. I found that the symbols are
    Lorenz> e.g. available in the wasysym and the marvosym
    Lorenz> package in LaTeX.

    Lorenz> I have coded two very rough functions that are able
    Lorenz> to approximate those symbols, but not surprisingly,
    Lorenz> they are not very efficient regarding the file size
    Lorenz> they produce (I have included the code for the
    Lorenz> female symbol at the end of the mail).

    Lorenz> Is there a more or less straightforward way to
    Lorenz> implement these symbols so that they can be accessed
    Lorenz> either by pch= or expression()? Can you give me some
    Lorenz> pointers on how I would need to go about this?

I've just replied to this in some length on R-devel rather than
R-help since my answer really is about future development of R,
here.

The short answer:  
It is not straightforward but doable in principle by hacking in
the R source, learning some of the internal graphics system
(done in C).   Please use R-devel at .. for further discussion.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hgoehlmann at gmx.de  Thu Oct 31 11:56:31 2002
From: hgoehlmann at gmx.de (hgoehlmann@gmx.de)
Date: Thu, 31 Oct 2002 11:56:31 +0100 (MET)
Subject: [R] Settings of lattice graphs
References: <3DC053C5.34E7B69A@stat.auckland.ac.nz>
Message-ID: <25453.1036061791@www58.gmx.net>

Thanks for the replies already. Still, with all your help I have not been
able to get what I wanted. Ok, I should be a little more detailed.

(1) I would like to create a function which draws a levelplot with a
colorkey at the bottom to a vectorized file (win.metafile)
(2) this function will receive data from a matrix that can vary in number of
rows and will visualize the data in the matrix - I am trying to use
levelplot because I get a nice colorkey with it - unlike image
(3) the colorkey should have a fixed height at the bottom (say 40 pixels)
(4) as the number of rows increases or decreases the size of the graphic
should change accordingly

BUT...   the colorkey dimensions should be fixed (in terms of height of the
colorkey = the 40 pixels) and the height of the rows in the levelplot should
be fixed as well. And this is where the problem starts...   I can define the
canvas size according to nrow(matrix) + x (for the colorkey) and even split
the canvas into two sections (using viewport), but since the levelplot always
draws a margin around itself (even though I am setting scales=list(draw=F) ),
the height of the rows in the levelplot varies with the number of rows I am
feeding into levelplot...

I hope my writing is understandable (and reproducable)...

Thanks very much already for any further suggestion!

Cheers,
hinrich   d8-)


> It is also possible to place lattice plots within generic grid
> viewports, which allow you to manipulate the space around the plot in
> many different ways.  See the last example in example(print.trellis) --
> the important bit is the newpage=FALSE -- also, the following gives a
> simple example where the margins could be increased by a number of lines
> on each side of the lattice plot ...
> 
>     library(lattice)
>     x <- y <- 1:10
>     myplot <- xyplot(y ~ x)
>     
>     grid.newpage()
>     grid.rect(gp=gpar(col=NULL, fill=trellis.par.get("background")$col))
>     push.viewport(plotViewport(c(5, 4, 4, 2) + 0.1))
>     print(myplot, newpage=FALSE)
>     # Just to show where the extra margin starts
>     grid.rect(gp=gpar(lty="dashed"))
>     pop.viewport()
> 
> ... and here's a more complex example that gives a bit of an idea of the
> flexibility you can get if you work a bit harder ...
> 
>     # Grid viewport to place lattice plot within within
>     widths <- unit(c(1, 1, 3), c("inches", "null", "lines"))
>     heights <- unit(c(0.1, 1, 1), c("npc", "null", "cm"))
>     push.viewport(viewport(layout=grid.layout(3, 3,
>                              widths=widths,
>                              heights=heights)))
>     # Draw the lattice plot
>     push.viewport(viewport(layout.pos.col=2,
>                            layout.pos.row=2))
>     print(myplot, newpage=FALSE)
>     pop.viewport()
>     # Some annotation of the margins
>     push.viewport(viewport(layout.pos.col=1,
>                            layout.pos.row=2))
>     grid.text("1 inch")
>     pop.viewport()
>     push.viewport(viewport(layout.pos.col=3,
>                            layout.pos.row=2))
>     grid.text("3 lines")
>     pop.viewport()
>     push.viewport(viewport(layout.pos.col=2,
>                            layout.pos.row=3))
>     grid.text("1 cm", rot=90)
>     pop.viewport()
>     push.viewport(viewport(layout.pos.col=2,
>                            layout.pos.row=1))
>     grid.text("0.1 npc", rot=90)
>     pop.viewport(2)
> 
> Hope that helps :)
> 
> Paul
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Thu Oct 31 11:52:38 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Thu, 31 Oct 2002 05:52:38 -0500
Subject: [R] Please Help. Subtraction of Matrices?
In-Reply-To: <4.3.2.7.2.20021030224751.00c34bc8@mail.bellsouth.net>; from gbarlow@bellsouth.net on Wed, Oct 30, 2002 at 10:58:33PM -0500
References: <4.3.2.7.2.20021030224751.00c34bc8@mail.bellsouth.net>
Message-ID: <20021031055238.B15181@cattell.psych.upenn.edu>

On 10/30/02 22:58, g barlow wrote:
>I am just beginning to learn R.  Please help. I have two matrices. One 20 
>columns by 16 rows represent student responses on a 20 question test. The 
>second is 20 by 16 representing the correct responses 16 
>times.  Subtracting one from the other should yield 0's if a response is 
>correct.  Yet Response minus Bigkey doesn't work.

It should work.  Look at what you get when you do it.  An error
message?  Some matrix other than what you expect?

Possibly Response or Bigkey is not actually a matrix.  Try
is.matrix(Bigkey)
is.matrix(Response)

Also try making up some data and running the same commands (with
smaller matrices perhaps).

Once you get it working, you can simplify it a bit by trasposing
Response with t() and just typing the key once, as a vector.  R
will recycle the vector column by column, e.g.

t(Response) - LittleKey

Jon
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From skala at incoma.cz  Thu Oct 31 11:53:01 2002
From: skala at incoma.cz (=?iso-8859-2?Q?SK=C1LA_Zden=ECk?=)
Date: Thu, 31 Oct 2002 11:53:01 +0100
Subject: [R] Symbols for male/female
Message-ID: <258405913DEE50419B664F16D1D672AE19AAC7@incoma2000.incoma.bbc>

Curtis Clark has made TrueType fonts that include male/female symbols; the license is quite liberal (and included with the fonts). Could it help? I can send you the packet.

Zdenek Skala
skala at incoma.cz

-----Original Message-----
From: Lorenz Gygax [mailto:gygax at ifi.unizh.ch]
Sent: Thursday, October 31, 2002 8:10 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Symbols for male/female



Dear all,

I would like to use the biological symbols for male and female as plotting
symbols in a scatterplot (ideally filled and non-filled). R does not seem
to have these symbols using pch= in plot() nor are they implemented via
expression() or at least I did not find them. I found that the symbols are
e.g. available in the wasysym and the marvosym package in LaTeX.

I have coded two very rough functions that are able to approximate those
symbols, but not surprisingly, they are not very efficient regarding the
file size they produce (I have included the code for the female symbol at
the end of the mail).

Is there a more or less straightforward way to implement these symbols so
that they can be accessed either by pch= or expression()? Can you give me
some pointers on how I would need to go about this?

Thanks and regards, Lorenz
-- 
Lorenz Gygax, Dr. sc. nat.
Artificial Intelligence Lab, Department of Information Technology
University of Zurich-Irchel, +41-1-635 67 17,  gygax at ifi.unizh.ch


one.female <- function (X, diam= 1, prop= 1, lw= 1) {
  ## X a vector giving the position of the symbol c (x, y)
  ## diam: diameter in the entities on the Y axis
  ## prop: proportion of x to y axis (so that symbols will be round
  ## lw: adjustment of line width for large symbols

  x.ring <- cos (seq (0, 2*pi, len= 500)) * prop * diam/2
  y.ring <- sin (seq (0, 2*pi, len= 500)) * diam/2
  lines (x.ring + X[1], y.ring + X[2], lwd= lw)
  segments (c (0, -diam/4) + X[1],
            c (-diam/2, -3*diam/4) + X[2],
            c (0,  diam/4) + X[1],
            c ( -diam , -3*diam/4) + X[2], lwd= lw)
}

and to plot several iteams at a time

female <- function (x, y, d= 1, p= 1, l= 1) {
  ## x, y vectors of x and y coordinates
  ## d: diameter
  ## p: proportion of symbol
  ## l: line width

  xy <- cbind (x, y)
  apply (xy, 1, FUN= one.female, diam= d, prop= p, lw= l)
}



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dmiddleton at fisheries.gov.fk  Thu Oct 31 10:21:32 2002
From: dmiddleton at fisheries.gov.fk (David Middleton)
Date: Thu, 31 Oct 2002 07:21:32 -0200
Subject: [R] Symbols for male/female
Message-ID: <698C02D452EDD411A42300A0C982E91E083DAC@MAIL>

On Thursday, October 31, 2002 7:10 AM, Lorenz Gygax
[SMTP:gygax at ifi.unizh.ch] wrote:

> I would like to use the biological symbols for male and female as plotting
> symbols in a scatterplot (ideally filled and non-filled). R does not seem
> to have these symbols using pch= in plot() nor are they implemented via
> expression() or at least I did not find them. I found that the symbols are
> e.g. available in the wasysym and the marvosym package in LaTeX.

The male and female symbols are available in the Hershey fonts so can be
added via text, for example:

text(x,y,"\\MA",vfont=c("sans serif","bold"))   # male symbol
text(x,y,"\\VE",vfont=c("sans serif","bold"))  # female symbol

These are not the best looking fonts ion my opinion, but this may be the
quickest solution for the moment.

David

Dr David A. J. Middleton, Stock Assessment Scientist
Fisheries Department, Falkland Islands Government
Stanley, Falkland Islands
Tel: +500 27260  Fax +500 27265  Email: dmiddleton at fisheries.gov.fk
Web: http://www.falklandislands.com/business/fisheries.htm

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From krcabrer at perseus.unalmed.edu.co  Thu Oct 31 12:39:51 2002
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Thu, 31 Oct 2002 06:39:51 -0500
Subject: [R] Help with waveslim
References: <3E96F037.60105@arcriswell.com>
Message-ID: <3DC11687.3050809@perseus.unalmed.edu.co>

Hello, dear R-users:

When I use the package waveslim and I call a database.
 >data(ibm)
It appears the following message:
Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file `ibm.txt'

But all the data files are on the rw1060\library\waveslim\data path.
In LINUX it works fine!
What should I do?

Thank you for your help.

Im using R in W2K platform:
$platform [1] "i386-pc-mingw32"
$arch       [1] "i386"
$os          [1] "mingw32"
$system   [1] "i386, mingw32"
$status     [1] ""
$major     [1] "1"
$minor     [1] "6.0"
$year       [1] "2002"
$month    [1] "10"
$day        [1] "01"
$language[1] "R"

-- 

Kenneth Roy Cabrera Torres
Unviersidad Nacional de Colombia, Sede Medell?n
Instituto de Ciencias Naturales y Ecolog?a
Escuela de Geociencias
e-mail krcabrer at unalmed.edu.co
Tel +57 (4) 430-9351



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gbarlow at bellsouth.net  Thu Oct 31 12:51:04 2002
From: gbarlow at bellsouth.net (g barlow)
Date: Thu, 31 Oct 2002 06:51:04 -0500
Subject: [R] Solved! Thanks! Please Help. Subtraction of Matrices?
Message-ID: <4.3.2.7.2.20021031064335.00c55de8@mail.bellsouth.net>

G?ran Brostr?m <gb at stat.umu.se> responded to my call for help (Please Help. 
Subtraction of Matrices?), and has now supplied enough information that I 
should be able to solve my problem.  My very great thanks to all who read 
and responded.  ---

Gene Barlow, Ft. Lauderdale, FL
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20021031/6ca25fe2/attachment.html

From robut at forest.go.th  Thu Oct 31 13:10:31 2002
From: robut at forest.go.th (Robert Cunningham)
Date: Thu, 31 Oct 2002 19:10:31 +0700
Subject: [R] Symbols for male/female
In-Reply-To: <Pine.WNT.4.44.0210310755280.700-100000@GYG-63G37>
References: <Pine.WNT.4.44.0210310755280.700-100000@GYG-63G37>
Message-ID: <15809.7607.793482.253043@gargle.gargle.HOWL>

G'day,



Perhaps this is all that is needed


> x <- rnorm(10)
> plot(x,y,pch=4)
> text(x,y,"\\MA",vfont=c("sans serif symbol","plain"),cex=2)

A few problems:
-A cex too large starts to show the "gaps"
-Perhaps the symbols are not quite centered the way you want-that could
be 'adjusted'
-Filled symbols would need to be made with a carefully 'adjusted' pch=20

These adjustments could be done in a reusable function.

The \\MA comes from Mars and \\VE is the female equivalent, see more
details in:

?Hershey


Cheers, 


Robert Cunningham



Lorenz Gygax writes:
 > 
 > Dear all,
 > 
 > I would like to use the biological symbols for male and female as plotting
 > symbols in a scatterplot (ideally filled and non-filled). R does not seem
 > to have these symbols using pch= in plot() nor are they implemented via
 > expression() or at least I did not find them. I found that the symbols are
 > e.g. available in the wasysym and the marvosym package in LaTeX.
 > 
 > I have coded two very rough functions that are able to approximate those
 > symbols, but not surprisingly, they are not very efficient regarding the
 > file size they produce (I have included the code for the female symbol at
 > the end of the mail).
 > 
 > Is there a more or less straightforward way to implement these symbols so
 > that they can be accessed either by pch= or expression()? Can you give me
 > some pointers on how I would need to go about this?
 > 
 > Thanks and regards, Lorenz
 > -- 
 > Lorenz Gygax, Dr. sc. nat.
 > Artificial Intelligence Lab, Department of Information Technology
 > University of Zurich-Irchel, +41-1-635 67 17,  gygax at ifi.unizh.ch
 > 
 > 
 > one.female <- function (X, diam= 1, prop= 1, lw= 1) {
 >   ## X a vector giving the position of the symbol c (x, y)
 >   ## diam: diameter in the entities on the Y axis
 >   ## prop: proportion of x to y axis (so that symbols will be round
 >   ## lw: adjustment of line width for large symbols
 > 
 >   x.ring <- cos (seq (0, 2*pi, len= 500)) * prop * diam/2
 >   y.ring <- sin (seq (0, 2*pi, len= 500)) * diam/2
 >   lines (x.ring + X[1], y.ring + X[2], lwd= lw)
 >   segments (c (0, -diam/4) + X[1],
 >             c (-diam/2, -3*diam/4) + X[2],
 >             c (0,  diam/4) + X[1],
 >             c ( -diam , -3*diam/4) + X[2], lwd= lw)
 > }
 > 
 > and to plot several iteams at a time
 > 
 > female <- function (x, y, d= 1, p= 1, l= 1) {
 >   ## x, y vectors of x and y coordinates
 >   ## d: diameter
 >   ## p: proportion of symbol
 >   ## l: line width
 > 
 >   xy <- cbind (x, y)
 >   apply (xy, 1, FUN= one.female, diam= d, prop= p, lw= l)
 > }
 > 
 > 
 > 
 > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
 > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
 > Send "info", "help", or "[un]subscribe"
 > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
 > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
 > 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mastropi at uwalumni.com  Thu Oct 31 15:31:02 2002
From: mastropi at uwalumni.com (Daniel Mastropietro)
Date: Thu, 31 Oct 2002 06:31:02 -0800 (PST)
Subject: [R] two small wishes for R
Message-ID: <20021031063102.27396.h005.c014.wm@mail.uwalumni.com.criticalpath.net>

I support these wishes...

Daniel Mastropietro

---------------------
1. allows underscore as part of a variable name
2. Uses C or Java style comments mark.

Jason

=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-8611, fax (732) 235-9777
http://www.geocities.com/jg_liao


 

On Wisconsin!  Get your free University of Wisconsin alumni e-mail at http://uwalumni.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Thu Oct 31 15:36:02 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 31 Oct 2002 09:36:02 -0500
Subject: [R] Symbols for male/female
In-Reply-To: <Pine.WNT.4.44.0210310755280.700-100000@GYG-63G37>
References: <Pine.WNT.4.44.0210310755280.700-100000@GYG-63G37>
Message-ID: <20021031093602.069cc5f3.fharrell@virginia.edu>


On 31 Oct 2002 08:10:25 +0100
Lorenz Gygax <gygax at ifi.unizh.ch> wrote:

> 
> Dear all,
> 
> I would like to use the biological symbols for male and female as plotting
> symbols in a scatterplot (ideally filled and non-filled). R does not seem
> to have these symbols using pch= in plot() nor are they implemented via
> expression() or at least I did not find them. I found that the symbols are
> e.g. available in the wasysym and the marvosym package in LaTeX.
> 
>
. . .


Bill Cleveland's "The Elements of Graphing Data" gives a good explanation of why this type of encoding is ineffective, and he gives some solutions that can already be executed in R.

Frank Harrell

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From a.p.beckerman at stir.ac.uk  Thu Oct 31 15:42:07 2002
From: a.p.beckerman at stir.ac.uk (Andrew Beckerman)
Date: Thu, 31 Oct 2002 14:42:07 +0000
Subject: [R] interval censoring
In-Reply-To: <25453.1036061791@www58.gmx.net>
References: <3DC053C5.34E7B69A@stat.auckland.ac.nz>
Message-ID: <5.1.0.14.0.20021031143647.00afc7c0@falloch.stir.ac.uk>

Dear listers -

R 1.6, WINNT, S+2000 also

I am trying to implement a mark-recapture analysis in R. I have data on the 
timing of the fledging of birds.

Over the course of a 35 day period, I have daily records of a) fledging, b) 
alive or c) missing.  e.g., on any given day, i can see a bird and know 
that it has fledged (it has feathers now and wants to fly). Or I can see a 
bird and it still has not fledged but is alive.  Finally, I can not see the 
bird on that day.

I am having trouble identifying what event code to give each of these 
events in the interval censoring context

(0,1] - alive = ?
(0,1] - missing = ?
(0,1] - fledged = ?

any advice would be most appreciated.
cheers
andrew

-- 
The University of Stirling is a university established in Scotland by
charter at Stirling, FK9 4LA.  Privileged/Confidential Information may
be contained in this message.  If you are not the addressee indicated
in this message (or responsible for delivery of the message to such
person), you may not disclose, copy or deliver this message to anyone
and any action taken or omitted to be taken in reliance on it, is
prohibited and may be unlawful.  In such case, you should destroy this
message and kindly notify the sender by reply email.  Please advise
immediately if you or your employer do not consent to Internet email
for messages of this kind.  Opinions, conclusions and other
information in this message that do not relate to the official
business of the University of Stirling shall be understood as neither
given nor endorsed by it.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plxmh at nottingham.ac.uk  Thu Oct 31 15:42:16 2002
From: plxmh at nottingham.ac.uk (Martin Hoyle)
Date: Thu, 31 Oct 2002 14:42:16 +0000
Subject: [R] Re: gregmisc version 0.7.3 now available
Message-ID: <sdc1414e.071@ccw0c2.nottingham.ac.uk>

Dear Greg,
Thanks for the new release. The decomposition of the SSQ is just what I need!

Regards,
Martin.

Martin Hoyle,
School of Life and Environmental Sciences,
University of Nottingham,
University Park,
Nottingham,
NG7 2RD,
UK
Webpage: http://myprofile.cos.com/martinhoyle

>>> gregory_r_warnes at groton.pfizer.com 10/30/02 07:16PM >>>


Version 0.7.3 of the gregmisc package is now available on CRAN.  A compiled
windows package has also been sent to Brian Ripley for inclusion in the
windows package directory.

This version of gregmisc fixes a number of bugs and introduces several new
functions.

Highlights of this version:
===========================

New Features:
- Introduction of pdirichlet() and rdirichlet() functions.
- Addition of fast.prcomp() and fast.svd(), are more efficient than 
  the built-in versions on very wide matrixes.  (Short term solution 
  until patches are integrated into the R source.)
- Add permute() function as a convenience wrapper for sample()

Bug Fixes:
- Fixed bug in barplot2() when log scale axes are used.
- Fixed contrasts.lm() to allow use on aov objects
- Other miscellaneous bug fixes.
- Removed enhanced version of plot.lm() which has been broken by
  recent changes to R base packages.  

Documentation Enhancements:
- make.contrasts(), which allows easy creation of user specified
  contrasts, is now fully documented.
- Help files for make.contrasts and contrast.lm now show how to
  compute and test contrasts, including SSQ decompositions, in
  analysis of variance models

Description:
============

Package: gregmisc
Description: Misc Functions written/maintained by Gregory R. Warnes
Title: Greg's Miscellaneous Functions
Version: 0.7.3
Date: 2002/10/29
Maintainer: Gregory R. Warnes <Gregory_R_Warnes at groton.pfizer.com>
Author: Gregory R. Warnes.  Includes code provided by Ben Bolker,
        Bendix Carstensen, Don MacQueen, William Venables, and Marc
        Schwartz, Ben Bolker, and Ian Wilson
License: GPL (version 2 or later)
Depends: MASS
Built: R 1.6.0; sparc-sun-solaris2.8; Tue Oct 29 21:40:30 EST 2002

Index:

CrossTable              Cross Tabulation with Tests for Factor
                        Independence
aggregate.table         Create 2-Way Table of Summary Statistics
bandplot                Plot x-y Points with Locally Smoothed Mean and
                        Standard Deviation
barplot2                Enhanced Bar Plots
boxplot.n               Produce a Boxplot Annotated with the Number of
                        Observations
ci                      Compute Confidence Intervals
combinations            Enumerate the Combinations or Permutations of
                        the Elements of a Vector
combine                 Combine R Objects With a Column Labeling the
                        Source
contrast.lm             Compute and test arbitrary contrasts for
                        regression objects
rdirichlet              Functions for the Dirichlet Distribution
estimable               Compute and test estimable linear functions of
                        the fitted coefficients (including contrasts)
                        of regression objects
factorial               Compute factorial function
fast.prcomp             Efficient computation of principal components
                        and singular value decompositions.
glh.test                Test a General Linear Hypothesis for a
                        Regression Model 
hist2d                  Compute and Plot a 2-Dimensional Histogram 
interleave              Interleave Rows of Data Frames or Matrices 
lowess                  Scatter Plot Smoothing
make.contrasts          Construct a User-Specified Contrast Matrix
nobs                    Compute the Number of Non-missing Observations 
permute                 Randomly Permute the Elements of a Vector
plotCI                  Plot Error Bars
plotmeans               Plot Group Means and Confidence Intervals
quantcut                Create a Factor Variable Using the Quantiles of
                        a Continuous Variable
rename.vars             Rename variables in a dataframe 
reorder                 Reorder the Levels of a Factor
running                 Apply a Function Over Adjacent Subsets of a
                        Vector
space                   Space points in an x-y plot so they don't
                        overlap.
undocumented            Undocumented functions
wapply                  Compute the Value of a Function Over a Local


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-announce mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html 
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Thu Oct 31 15:47:16 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Thu, 31 Oct 2002 09:47:16 -0500 (EST)
Subject: [R] Symbols for male/female
In-Reply-To: <Pine.WNT.4.44.0210310755280.700-100000@GYG-63G37>
Message-ID: <Pine.LNX.4.44.0210310944390.30839-100000@bolker.zoo.ufl.edu>


  If you're using LaTeX anyway, one possibility is to use the psfrag
package to post-process the postscript ...

testmf.R
----------------
x <- runif(10)
y <- runif(10)
mf <- sample(0:1,10,TRUE)
postscript("testmf.eps",width=4,height=4,
           horizontal = FALSE, onefile = FALSE, paper = "special")
plot(x,y,type="n")
text(x,y,ifelse(mf==0,"m","f"))
dev.off()


testmf.tex
-----------------
\documentclass{article}
\usepackage{graphicx}
\usepackage{psfrag}
\usepackage{wasysym}

\psfrag{m}{\mars}
\psfrag{f}{\venus}

\begin{document}
\includegraphics{testmf}
\end{document}



On 31 Oct 2002, Lorenz Gygax wrote:

> 
> Dear all,
> 
> I would like to use the biological symbols for male and female as plotting
> symbols in a scatterplot (ideally filled and non-filled). R does not seem
> to have these symbols using pch= in plot() nor are they implemented via
> expression() or at least I did not find them. I found that the symbols are
> e.g. available in the wasysym and the marvosym package in LaTeX.
> 
> I have coded two very rough functions that are able to approximate those
> symbols, but not surprisingly, they are not very efficient regarding the
> file size they produce (I have included the code for the female symbol at
> the end of the mail).
> 
> Is there a more or less straightforward way to implement these symbols so
> that they can be accessed either by pch= or expression()? Can you give me
> some pointers on how I would need to go about this?
> 
> Thanks and regards, Lorenz
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From patrick at burns-stat.com  Thu Oct 31 15:52:25 2002
From: patrick at burns-stat.com (Patrick Burns)
Date: Thu, 31 Oct 2002 14:52:25 +0000
Subject: [R] New home for S Poetry
Message-ID: <3DC143A9.50103@burns-stat.com>

Many readers on this list probably don't know that S Poetry
had an old home.  S Poetry is a book in pdf about programming
in the S language.  It was written mainly with S-PLUS 3.x in
mind when R was still an infant relative to what it is now.

Some parts of the book are still quite accurate for R.  In other
places R is rather different from what is in the book.  The FAQ
on the differences between R and S-PLUS at the R Project is
a good mediator between R and S Poetry.

S Poetry can be found on http://www.burns-stat.com/

Also on that site in the public domain area are three  functions
that run in both R and S-PLUS (corner, head, tail).  These are
useful interactively and occasionally in programming.

There is also a tutorial -- really an advertisement -- on the S
language.

Patrick Burns
patrick at burns-stat.com
+44 (0) 208 525 0696
http://www.burns-stat.com/


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Oct 31 15:57:01 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 31 Oct 2002 06:57:01 -0800 (PST)
Subject: [R] Mac OS 9 and file type/creator
In-Reply-To: <903680C1-EC53-11D6-A502-000393860F3C@stat.ucla.edu>
Message-ID: <Pine.A41.4.44.0210310655550.31282-100000@homer40.u.washington.edu>

On Wed, 30 Oct 2002, Jan de Leeuw wrote:

> Although many people deplore this, OS X writes flat files as well and
> derives
> type/creator information from the name of the file. So foo.pdf is known
> to be
> a pdf file and the finder knows that pdf files must be opened with
> AcroRead
> or Preview or whatever you set in your preferences. This is the
> classical
> MIME-type scheme, less flexible, more simple.

I don't see how it can be that simple -- some of my PDF files think they
belong to Acrobat, and some think they belong to Preview.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at inpharmatica.co.uk  Thu Oct 31 16:09:45 2002
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Thu, 31 Oct 2002 15:09:45 +0000 (GMT)
Subject: [R] Loess with glm ?
Message-ID: <Pine.LNX.4.21.0210311408370.19044-100000@dollis-hill.inpharmatica.co.uk>


Hello,

I am wondering if there is an easy way to combine loess() with glm()
to produce a locally fitted generalised regression.

I have a data set of about 5,000 observations and 5 explanatory variables,
with a binary outcome. One of the explanatory variables (lets call it X)
is much more predictive than the others. A single glm() regression over
the entire data set produces rather poor results, so I have split the
data based on sub ranges of X, and performed a separate glm() regression
on each subset.

This produces much more satisfactory results, but the problem is that
at the boundaries, the result hyper-surfaces don't coincide.

I am using this model in a predictive role so that given a new observation
on the 5 explanatory variables, I want to predict the probability of a
positive outcome (actually whether a protein has a certain conformation
or not). At the boundary determined by the value of X, my prediction has
a discontinuity, which is not very satisfactory. My solution has been to
take a weighted average of the results of adjacent models for cases where X
is close to a boundary so as to smooth over the discontinuities. Although
this works, it seems rather simplistic and arbitrary in terms of choices
about how and where the weighed averages are computed.  It seems to me
that what I am doing is a kind of poor mans loess.

Can anyone suggest a better way to deal with this analysis ? I have only
a sketchy knowledge of loess.

Thanks,

Luke Whitaker
Inpharmatica



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Thu Oct 31 16:34:29 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Thu, 31 Oct 2002 10:34:29 -0500
Subject: [R] GNUPLOT
Message-ID: <20021031153429.GG1822@komensky.surfbest.net>

Hi,

I advertised gnuplot as a better alternative to the general
graphing program. It came to my knowledge, that the website
I have sent to this list is dead -- the correct one is
http://www.gnuplot.info.

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
There is no reason to suppose that most human beings are engaged
in maximizing anything unless it be unhappiness, and even this
with incomplete success.
    -- Ronald Coase
       Introduction to ``The Firm, the Market, and the Law''

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matej at ceplovi.cz  Thu Oct 31 16:28:19 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Thu, 31 Oct 2002 10:28:19 -0500
Subject: [R] ..of R, OS X, and linux
In-Reply-To: <873cqnw3zx.fsf@jeeves.blindglobe.net>
References: <7E227AB3-EC54-11D6-A502-000393860F3C@stat.ucla.edu> <873cqnw3zx.fsf@jeeves.blindglobe.net>
Message-ID: <20021031152818.GF1822@komensky.surfbest.net>

On Wed, Oct 30, 2002 at 09:50:58PM -0800, A.J. Rossini wrote:
> Now, if you are looking for a desktop replacement rather than a small
> notebook ("small" was the operative word for me, 12" screen the max I
> would tolerate), you probably want an AMD or Intel-based laptop.  The
> TiBook is nice and classy, but probably not as cost effective.

My wife now bought new Dell Inspiron and I have confess, that
I terribly envy her 2GHz processor -- it is really fast as hell.
No experience with RISC processors though.

Matej

-- 
Matej Cepl, matej at ceplovi.cz, PGP ID# D96484AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
Economics is the only discipline where two people can win a Nobel
Prize for saying exactly the opposite thing!
    -- Eamonn Butler of Adam Smith Institute
       on Nobel Prize awards for year 2001

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Thu Oct 31 16:56:31 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Thu, 31 Oct 2002 11:56:31 -0400
Subject: [R] Generating balanced incomplete block designs?
References: <7o65vjgcmh.fsf@foo.nemo-project.org>
Message-ID: <3DC152AF.908265FA@umsanet.edu.bo>

The Dopt package from the devel section on CRAN will generate
balanced incomplete block designs (at least with high probablilty)
or nearly balanced ones if balanced does not exist.

Kjetil Halvorsen

Bj?rn-Helge Mevik wrote:
> 
> Are there any R functions for generating balanced (or nearly balanced)
> incomplete block designs?
> 
> --
> Bj?rn-Helge Mevik
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From snw at mcs.st-and.ac.uk  Thu Oct 31 18:06:48 2002
From: snw at mcs.st-and.ac.uk (Simon Wood)
Date: Thu, 31 Oct 2002 17:06:48 +0000 (GMT)
Subject: [R] Loess with glm ?
In-Reply-To: <Pine.LNX.4.21.0210311408370.19044-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <Pine.GSO.4.21.0210311703520.24965-100000@dolphin>

You could take a look at gam() in package mgcv - it will fit thin plate
spline like multi-dimensional smoothers (and other models) in a GLM
setting. (With 5000 observations you'd probably want to check the help
files for some simple tricks to speed up fitting, though.)
Simon 

> I am wondering if there is an easy way to combine loess() with glm()
> to produce a locally fitted generalised regression.
> 
> I have a data set of about 5,000 observations and 5 explanatory variables,
> with a binary outcome. One of the explanatory variables (lets call it X)
> is much more predictive than the others. A single glm() regression over
> the entire data set produces rather poor results, so I have split the
> data based on sub ranges of X, and performed a separate glm() regression
> on each subset.
> 
> This produces much more satisfactory results, but the problem is that
> at the boundaries, the result hyper-surfaces don't coincide.
> 
> I am using this model in a predictive role so that given a new observation
> on the 5 explanatory variables, I want to predict the probability of a
> positive outcome (actually whether a protein has a certain conformation
> or not). At the boundary determined by the value of X, my prediction has
> a discontinuity, which is not very satisfactory. My solution has been to
> take a weighted average of the results of adjacent models for cases where X
> is close to a boundary so as to smooth over the discontinuities. Although
> this works, it seems rather simplistic and arbitrary in terms of choices
> about how and where the weighed averages are computed.  It seems to me
> that what I am doing is a kind of poor mans loess.
> 
> Can anyone suggest a better way to deal with this analysis ? I have only
> a sketchy knowledge of loess.
> 
> Thanks,
> 
> Luke Whitaker
> Inpharmatica
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Thu Oct 31 18:55:09 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 31 Oct 2002 12:55:09 -0500
Subject: [R] Loess with glm ?
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC845@usrymx10.merck.com>

If you really _must_ use loess, the gam() function in Splus allows you to
use loess terms (e.g., as lo(x)).  In R, the gam() function in the mgcv
package uses splines.  However, it sounds like you don't have to use loess,
so mgcv should be sufficient.  There's an article on using gam() in mgcv in
R News, I believe about two issues back.  Prof. Harrell's "Design" library
also has functions that allow spline terms in logistic regression.

If you know roughly where the "break point" is, you can even just do glm
with ns() or bs() terms, so you're still essentially fitting a parametric
model.

HTH,
Andy

-----Original Message-----
From: Luke Whitaker [mailto:luke at inpharmatica.co.uk]
Sent: Thursday, October 31, 2002 10:10 AM
To: r-help
Subject: [R] Loess with glm ?



Hello,

I am wondering if there is an easy way to combine loess() with glm()
to produce a locally fitted generalised regression.

I have a data set of about 5,000 observations and 5 explanatory variables,
with a binary outcome. One of the explanatory variables (lets call it X)
is much more predictive than the others. A single glm() regression over
the entire data set produces rather poor results, so I have split the
data based on sub ranges of X, and performed a separate glm() regression
on each subset.

This produces much more satisfactory results, but the problem is that
at the boundaries, the result hyper-surfaces don't coincide.

I am using this model in a predictive role so that given a new observation
on the 5 explanatory variables, I want to predict the probability of a
positive outcome (actually whether a protein has a certain conformation
or not). At the boundary determined by the value of X, my prediction has
a discontinuity, which is not very satisfactory. My solution has been to
take a weighted average of the results of adjacent models for cases where X
is close to a boundary so as to smooth over the discontinuities. Although
this works, it seems rather simplistic and arbitrary in terms of choices
about how and where the weighed averages are computed.  It seems to me
that what I am doing is a kind of poor mans loess.

Can anyone suggest a better way to deal with this analysis ? I have only
a sketchy knowledge of loess.

Thanks,

Luke Whitaker
Inpharmatica



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From AlessandroSemeria at cramont.it  Thu Oct 31 18:45:03 2002
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Thu, 31 Oct 2002 18:45:03 +0100
Subject: [R] distributions homogeneity3
Message-ID: <OF2CF18E51.CD349005-ONC1256C61.003443BE@tomware.it>

RE-Hello dear R-list!
 I have to test if N (non linear)  experimantal
distributions fit some of known one. I would proceed in this
way:
1. Fit with 'nlm' and e.g. power law one ( non outlier) distribution of
mine.
2. Perform 'chisq.test' for each pairs (power law ,distribution(i))

but I'm neither a statistician nor a skilled on R, so I ask you: ther'is
some other way, more telling and efficient, to perform this task?
Thanks in advance for any suggestion!

--------------------------
Sincerely yours.

Dr. Alessandro Semeria                             Tel. +39 544 536811
Models and Simulation Lab of                                 Fax. +39 544
538663
The Environment Research Center - Montecatini (Edison Group),
E-mail: asemeria at cramont.it
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayan at stat.wisc.edu  Thu Oct 31 19:18:50 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 31 Oct 2002 12:18:50 -0600
Subject: [R] Settings of lattice graphs
In-Reply-To: <25453.1036061791@www58.gmx.net>
References: <3DC053C5.34E7B69A@stat.auckland.ac.nz> <25453.1036061791@www58.gmx.net>
Message-ID: <200210311218.50236.deepayan@stat.wisc.edu>

On Thursday 31 October 2002 04:56 am, hgoehlmann at gmx.de wrote:
> Thanks for the replies already. Still, with all your help I have not been
> able to get what I wanted. Ok, I should be a little more detailed.
>
> (1) I would like to create a function which draws a levelplot with a
> colorkey at the bottom to a vectorized file (win.metafile)
> (2) this function will receive data from a matrix that can vary in number
> of rows and will visualize the data in the matrix - I am trying to use
> levelplot because I get a nice colorkey with it - unlike image
> (3) the colorkey should have a fixed height at the bottom (say 40 pixels)
> (4) as the number of rows increases or decreases the size of the graphic
> should change accordingly
>
> BUT...   the colorkey dimensions should be fixed (in terms of height of the
> colorkey = the 40 pixels) and the height of the rows in the levelplot
> should be fixed as well. And this is where the problem starts...   I can
> define the canvas size according to nrow(matrix) + x (for the colorkey) and
> even split the canvas into two sections (using viewport), but since the
> levelplot always draws a margin around itself (even though I am setting
> scales=list(draw=F) ), the height of the rows in the levelplot varies with
> the number of rows I am feeding into levelplot...
>
> I hope my writing is understandable (and reproducable)...

I am not certain if I understand you correctly, but here goes:

I'm assuming that you know the maximum of the nrows, let's say that's in the 
valiable maxRow. Then, just use

ylim = c(.5, maxRow+.5)

in ALL your levelplot calls. If you want to suppress drawing of the axes, you 
need to use something like

lset(list(axis.line = list(col = "transparent")))

before you call levelplot (but after you have opened the plotting device).




> Thanks very much already for any further suggestion!
>
> Cheers,
> hinrich   d8-)
>
> > It is also possible to place lattice plots within generic grid
> > viewports, which allow you to manipulate the space around the plot in
> > many different ways.  See the last example in example(print.trellis) --
> > the important bit is the newpage=FALSE -- also, the following gives a
> > simple example where the margins could be increased by a number of lines
> > on each side of the lattice plot ...
> >
> >     library(lattice)
> >     x <- y <- 1:10
> >     myplot <- xyplot(y ~ x)
> >
> >     grid.newpage()
> >     grid.rect(gp=gpar(col=NULL, fill=trellis.par.get("background")$col))
> >     push.viewport(plotViewport(c(5, 4, 4, 2) + 0.1))
> >     print(myplot, newpage=FALSE)
> >     # Just to show where the extra margin starts
> >     grid.rect(gp=gpar(lty="dashed"))
> >     pop.viewport()
> >
> > ... and here's a more complex example that gives a bit of an idea of the
> > flexibility you can get if you work a bit harder ...
> >
> >     # Grid viewport to place lattice plot within within
> >     widths <- unit(c(1, 1, 3), c("inches", "null", "lines"))
> >     heights <- unit(c(0.1, 1, 1), c("npc", "null", "cm"))
> >     push.viewport(viewport(layout=grid.layout(3, 3,
> >                              widths=widths,
> >                              heights=heights)))
> >     # Draw the lattice plot
> >     push.viewport(viewport(layout.pos.col=2,
> >                            layout.pos.row=2))
> >     print(myplot, newpage=FALSE)
> >     pop.viewport()
> >     # Some annotation of the margins
> >     push.viewport(viewport(layout.pos.col=1,
> >                            layout.pos.row=2))
> >     grid.text("1 inch")
> >     pop.viewport()
> >     push.viewport(viewport(layout.pos.col=3,
> >                            layout.pos.row=2))
> >     grid.text("3 lines")
> >     pop.viewport()
> >     push.viewport(viewport(layout.pos.col=2,
> >                            layout.pos.row=3))
> >     grid.text("1 cm", rot=90)
> >     pop.viewport()
> >     push.viewport(viewport(layout.pos.col=2,
> >                            layout.pos.row=1))
> >     grid.text("0.1 npc", rot=90)
> >     pop.viewport(2)
> >
> > Hope that helps :)
> >
> > Paul
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>.-.- r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help", or
> "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tmurph6 at po-box.mcgill.ca  Thu Oct 31 19:58:45 2002
From: tmurph6 at po-box.mcgill.ca (Tanya Murphy)
Date: Thu, 31 Oct 2002 13:58:45 -0500
Subject: [R] Tables in graphics window
Message-ID: <3E0AC452@webmail.mcgill.ca>

Hello, I would like to include a table (of rax data, not summary statistics - 
in case this makes any difference) alongside a plot. I know how to use 
'layout' to divide my page into sections, but is it possible to put a table 
into one of these?

Thanks!
Tanya Murphy

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Thu Oct 31 20:09:17 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu, 31 Oct 2002 11:09:17 -0800 (PST)
Subject: [R] Loess with glm ?
In-Reply-To: <Pine.LNX.4.21.0210311408370.19044-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <Pine.GSO.4.10.10210311107290.23605-100000@fisher.stat.ucla.edu>

I believe the `locfit' package does what you want.  

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Thu, 31 Oct 2002, Luke Whitaker wrote:

> 
> Hello,
> 
> I am wondering if there is an easy way to combine loess() with glm()
> to produce a locally fitted generalised regression.
> 
> I have a data set of about 5,000 observations and 5 explanatory variables,
> with a binary outcome. One of the explanatory variables (lets call it X)
> is much more predictive than the others. A single glm() regression over
> the entire data set produces rather poor results, so I have split the
> data based on sub ranges of X, and performed a separate glm() regression
> on each subset.
> 
> This produces much more satisfactory results, but the problem is that
> at the boundaries, the result hyper-surfaces don't coincide.
> 
> I am using this model in a predictive role so that given a new observation
> on the 5 explanatory variables, I want to predict the probability of a
> positive outcome (actually whether a protein has a certain conformation
> or not). At the boundary determined by the value of X, my prediction has
> a discontinuity, which is not very satisfactory. My solution has been to
> take a weighted average of the results of adjacent models for cases where X
> is close to a boundary so as to smooth over the discontinuities. Although
> this works, it seems rather simplistic and arbitrary in terms of choices
> about how and where the weighed averages are computed.  It seems to me
> that what I am doing is a kind of poor mans loess.
> 
> Can anyone suggest a better way to deal with this analysis ? I have only
> a sketchy knowledge of loess.
> 
> Thanks,
> 
> Luke Whitaker
> Inpharmatica
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nklepeis at uclink4.berkeley.edu  Thu Oct 31 20:17:30 2002
From: nklepeis at uclink4.berkeley.edu (Neil Klepeis)
Date: Thu, 31 Oct 2002 11:17:30 -0800
Subject: [R] Zero is not Zero
Message-ID: <3DC181CA.1060904@uclink4.berkeley.edu>

I have a confusing problem with getting the form `x - trunc(x)' to be 
exactly zero when `x' is an integer. It only seems to occur inside of a 
function.  [R-1.6.0 on Linux/Intel]

I have a function to return the highest precision digit of values in `x':

prec<-function(x){
init <- trunc(log10(max(x)))
y <- x - trunc(x)
while (any(y > 0)) {
   init <- init - 1
   x1 <- x*10^(-init)
   y <- x1 - trunc(x1)
}
10^init
}


The problem is that some y's are not exactly zero as they should be.

Printing out pairs of x1 and y:
[Note the algorithm is finished when all y's are zero]

 > prec(c(1.1, 10, 120.34))
[1]   1.10  10.00 120.34
[1] 0.10 0.00 0.34

[1]  0.110  1.000 12.034
[1] 0.110 0.000 0.034

[1]   1.10  10.00 120.34
[1] 0.10 0.00 0.34

[1]   11.0  100.0 1203.4
[1] 0.0 0.0 0.4

# Here is the strange place where `x1-trunc(x1)' is not quite zero:

[1]   110  1000 12034
[1] 1.421085e-14 0.000000e+00 0.000000e+00

[1]   1100  10000 120340
[1] 0 0 0

# here is the highest precision, except it is *wrong*

[1] 0.001

---

Doing `110 - trunc(110)', of course gives "0" when entered on the R 
command-line directly:

 > 110 - trunc(110)
[1] 0

So where does that 1.421085e-14 come from, and how can I get rid of it?


-- 
______________________________________________________
Neil E. Klepeis, UC Berkeley, School of Public Health,
and Lawrence Berkeley National Laboratory,
Berkeley, CA USA.  Voice: 831-768-9510

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Thu Oct 31 20:25:37 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Thu, 31 Oct 2002 11:25:37 -0800
Subject: [R] ..of R, OS X, and linux
In-Reply-To: <873cqnw3zx.fsf@jeeves.blindglobe.net>
Message-ID: <88D2AE82-ED06-11D6-BC31-000393860F3C@stat.ucla.edu>

There will be a processor upgrade and a price drop announced
on November 5, for both iBooks and TiBooks (if the rumor sites
have it right).

I am glad to hear you can run OS 9 from Linux running  on
an iBook.

--- Jan

On Wednesday, October 30, 2002, at 09:50 PM, A.J. Rossini wrote:

>
> The new(er,est?) Mac iBook2's are rather nice and cheap (and quiet --
> faster and quieter than my wife's slightly older Sony R505, for
> example, and comparably sized).
>
> Plus, if you have the know-how, it makes the perfect Linux laptop :-)
> (screams from OS-X and Mac die-hards in the background...), except for
> a lack of ability to handle external displays and presentations (but
> you really do want Mac OS X and the joys of Mac user friendly
> auto-detect/config to make that part completely painless).
>
> You still can run OS9 and OSX from within Linux, if you really want to
> (MacOnLinux works, though I'm having problems with getting OS9 on > 8
> bit graphics, but who needs it?).
>
> Now, if you are looking for a desktop replacement rather than a small
> notebook ("small" was the operative word for me, 12" screen the max I
> would tolerate), you probably want an AMD or Intel-based laptop.  The
> TiBook is nice and classy, but probably not as cost effective.
>
> best,
> -tony
>
>
>
>
>>>>>> "jan" == Jan de Leeuw <deleeuw at stat.ucla.edu> writes:
>
>     jan> This would depend very much on the task. It is quite obvious  
> that
>     jan> for heavy floating point, especially double precision  
> floating point
>     jan> without tweaking, top of the line Pentium will be considerably
>     jan> faster than current top of the line G4 (single processor).  
> For ordinary
>     jan> interactive computing, you will not see much difference, I  
> think,
>     jan> and for the really gigantic computing tasks you need to go to
>     jan> multiple processors/multiple machines anyway.
>
>     jan> On Wednesday, October 30, 2002, at 10:16 AM, Michaell Taylor  
> wrote:
>
>>>
>>> I am an avid linux user who is intrigued with apple's OS X.
>>>
>>> I am now considering purchasing another laptop - which may provide
>>> an  excuse
>
>>> to get a feel of OS X. Of course there are lots of considerations,
>>> but  R
>
>>> command file processing speed is a major factor.
>>>
>>> I know of many speed comparisons between G4/G3 and the various
>>> flavors  of
>
>>> Pentiums, but more useful would be one specifically utilizing R.
>>>
>>> Has anyone conducted such a test?
>>>
>>> =========================================
>>> Michaell Taylor, PhD
>>>
>>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>
>>> .-.-.-.-.-
>>> r-help mailing list -- Read
>>> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>
>>> Send "info", "help", or "[un]subscribe"
>>> (in the "body", not the subject !)  To:
>>> r-help-request at stat.math.ethz.ch
>
>>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
>>> ._
>>> ._._._._
>
>>>
>>>
>     jan> ===
>     jan> Jan de Leeuw; Professor and Chair, UCLA Department of  
> Statistics;
>     jan> Editor: Journal of Multivariate Analysis, Journal of  
> Statistical
>     jan> Software
>
>     jan> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA  
> 90095-1554
>     jan> phone (310)-825-9550;  fax (310)-206-5658;  email:  
> deleeuw at stat.ucla.edu
>     jan> homepage: http://gifi.stat.ucla.edu
>     jan>     
> ----------------------------------------------------------------------- 
> -
>     jan> -------------------------
>     jan>            No matter where you go, there you are. ---  
> Buckaroo Banzai
>     jan>                      
> http://gifi.stat.ucla.edu/sounds/nomatter.au
>     jan>     
> ----------------------------------------------------------------------- 
> -
>     jan> -------------------------
>
>     jan>  
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
>     jan> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>     jan> Send "info", "help", or "[un]subscribe"
>     jan> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
>     jan>  
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
> -- 
> A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
> U. of Washington Biostatistics		rossini at u.washington.edu	
> FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
> -------------- http://software.biostat.washington.edu/ ----------------
> FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
> UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
> (my tuesday/wednesday/friday locations are completely unpredictable.)
>
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Oct 31 20:52:39 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 31 Oct 2002 11:52:39 -0800 (PST)
Subject: [R] interval censoring
In-Reply-To: <5.1.0.14.0.20021031143647.00afc7c0@falloch.stir.ac.uk>
Message-ID: <Pine.A41.4.44.0210311149300.96946-100000@homer13.u.washington.edu>

On Thu, 31 Oct 2002, Andrew Beckerman wrote:
> I am having trouble identifying what event code to give each of these
> events in the interval censoring context
>

For interval censoring you need only the last day when you saw the bird
unfledged (or NA if never) and the first day you saw it fledged (or NA if
never).  The interval between these days is what you need.

So, if you saw a bird unfledged on days 1,3,10,11,15 and fledged on days
20,22,23,30 the interval is [15, 20]

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From di208 at cam.ac.uk  Thu Oct 31 20:53:47 2002
From: di208 at cam.ac.uk (D Imhof)
Date: Thu, 31 Oct 2002 19:53:47 +0000
Subject: [R] Out of office reply (was Re: new package RColorBrewer
  available)
In-Reply-To: <3DC1854C.9010601@univie.ac.at>
Message-ID: <5.1.0.14.0.20021031195347.00a3a440@pop.hermes.cam.ac.uk>


At 19:32 31.10.2002, you wrote:
>
>RColorBrewer 0.1-1
>is available on CRAN.
>The packages provides palettes for drawing nice maps
>shaded according to a variable as an R function.
>The palettes have been designed by and are copyrighted by the ColorBrewer project.
>An interactive palette selection tool byt the original designers is available at
>http://colorbrewer.org
>
>-- 
>--
>Erich Neuwirth, Computer Supported Didactics Working Group
>Visit our SunSITE at http://sunsite.univie.ac.at
>Phone: +43-1-4277-38624 Fax: +43-1-4277-9386
>
>
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-announce mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


Hello,

I received your message, but am currently out of office.

You can reach me on my mobile phone: +41 79 520 31 47

I shall be back on Monday, 11 November 2002.


Best regards.     Daniel





----------
D a n i e l   I M H O F
University of Cambridge
Engineering Department
Trumpington Street
Cambridge CB2 1PZ
United Kingdom

Phone:  +44.1223.332.812
Mobile:  +44.7984.795.836
Fax:      +44.1223.332.813

http://www2.eng.cam.ac.uk/~di208



----------
D a n i e l   I M H O F
University of Cambridge
Engineering Department
Trumpington Street
Cambridge CB2 1PZ
United Kingdom

Phone:  +44.1223.332.812
Mobile:  +44.7984.795.836
Fax:      +44.1223.332.813

http://www2.eng.cam.ac.uk/~di208

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20021031/75d61792/attachment.html

From mschwartz at medanalytics.com  Thu Oct 31 21:20:52 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 31 Oct 2002 14:20:52 -0600
Subject: [R] Tables in graphics window
In-Reply-To: <3E0AC452@webmail.mcgill.ca>
Message-ID: <003201c2811b$02f5f9d0$0201a8c0@MARC>

> Hello, I would like to include a table (of rax data, not 
> summary statistics - 
> in case this makes any difference) alongside a plot. I know 
> how to use 
> 'layout' to divide my page into sections, but is it possible 
> to put a table 
> into one of these?
> 
> Thanks!
> Tanya Murphy


Tanya,

Take a look at these two posts from earlier this summer where I provide
some conceptual and coding examples of plotting column aligned/justified
text in a graphics window.

http://www.r-project.org/nocvs/mail/r-help/2002/5760.html (concept)
http://www.r-project.org/nocvs/mail/r-help/2002/5764.html (example code)

The above examples are for a single "main" plot window, but you should
be able to use these approaches in your various plot regions within a
single window.

As I point out in the first post, using demo(graphics) will also give
you some sample code in creating spreadsheet-like cells within the plot
region into which you can plot math symbols, etc.

If you have any follow questions, let me know.

Best regards and HTH,

Marc Schwartz


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


