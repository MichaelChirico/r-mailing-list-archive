From ||u|@@rev|||@ @end|ng |rom gm@||@com  Thu Jan  2 15:55:39 2025
From: ||u|@@rev|||@ @end|ng |rom gm@||@com (=?UTF-8?Q?Llu=C3=ADs_Revilla?=)
Date: Thu, 2 Jan 2025 15:55:39 +0100
Subject: [R-pkg-devel] Removing packages files
Message-ID: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>

Hi list,

I am developing a package that will download some data, and I'd like
to store it locally to not recalculate it often.
The CRAN policy requires tools::R_user_dir to be used and "the
contents are actively managed (including removing outdated material)"
or using TMPDIR but "such usage should be cleaned up".

When loading a package there is .onLoad or .onAttach to fill or check
those files and other settings required for a package. Is there
something for when a package is removed?

I found some related functions like .Last or reg.fnalizer and setHook
or packageEvent but they are about closing a session or don't have a
specific event for when uninstalling packages via (remove.packages). I
appreciate any feedback, thanks in advance.

Best wishes and a happy new year,

Llu?s


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Jan  2 17:23:40 2025
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 2 Jan 2025 11:23:40 -0500
Subject: [R-pkg-devel] Removing packages files
In-Reply-To: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>
References: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>
Message-ID: <fa376599-ff9f-4509-bc41-c5f8c0f8e9c9@gmail.com>

On 2025-01-02 9:55 a.m., Llu?s Revilla wrote:
> Hi list,
> 
> I am developing a package that will download some data, and I'd like
> to store it locally to not recalculate it often.
> The CRAN policy requires tools::R_user_dir to be used and "the
> contents are actively managed (including removing outdated material)"
> or using TMPDIR but "such usage should be cleaned up".
> 
> When loading a package there is .onLoad or .onAttach to fill or check
> those files and other settings required for a package. Is there
> something for when a package is removed?
> 
> I found some related functions like .Last or reg.fnalizer and setHook
> or packageEvent but they are about closing a session or don't have a
> specific event for when uninstalling packages via (remove.packages). I
> appreciate any feedback, thanks in advance.
> 

Yes, those are described in section "1.5.3 Load hooks" of writing R 
extensions:

"Packages can use a .onDetach or .Last.lib function (provided the latter 
is exported from the namespace) when detach is called on the package. It 
is called with a single argument, the full path to the installed 
package. There is also a hook .onUnload which is called when the 
namespace is unloaded (via a call to unloadNamespace, perhaps called by 
detach(unload = TRUE)) with argument the full path to the installed 
package?s directory. Functions .onUnload and .onDetach should be defined 
in the namespace and not exported, but .Last.lib does need to be exported."

Duncan Murdoch


From ||u|@@rev|||@ @end|ng |rom gm@||@com  Thu Jan  2 22:29:18 2025
From: ||u|@@rev|||@ @end|ng |rom gm@||@com (=?UTF-8?Q?Llu=C3=ADs_Revilla?=)
Date: Thu, 2 Jan 2025 22:29:18 +0100
Subject: [R-pkg-devel] Removing packages files
In-Reply-To: <fa376599-ff9f-4509-bc41-c5f8c0f8e9c9@gmail.com>
References: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>
 <fa376599-ff9f-4509-bc41-c5f8c0f8e9c9@gmail.com>
Message-ID: <CAN+W6_v3opSqb54GP=uo5O_MpA5Do+m3cR_1GyPdUCxJWRqV3Q@mail.gmail.com>

Dear Duncan,

Thank you for your answer. I checked again and made a mock package
that removes a file with .onDetach.
The file was not removed upon uninstalling the package.

Llu?s

On Thu, 2 Jan 2025 at 17:23, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 2025-01-02 9:55 a.m., Llu?s Revilla wrote:
> > Hi list,
> >
> > I am developing a package that will download some data, and I'd like
> > to store it locally to not recalculate it often.
> > The CRAN policy requires tools::R_user_dir to be used and "the
> > contents are actively managed (including removing outdated material)"
> > or using TMPDIR but "such usage should be cleaned up".
> >
> > When loading a package there is .onLoad or .onAttach to fill or check
> > those files and other settings required for a package. Is there
> > something for when a package is removed?
> >
> > I found some related functions like .Last or reg.fnalizer and setHook
> > or packageEvent but they are about closing a session or don't have a
> > specific event for when uninstalling packages via (remove.packages). I
> > appreciate any feedback, thanks in advance.
> >
>
> Yes, those are described in section "1.5.3 Load hooks" of writing R
> extensions:
>
> "Packages can use a .onDetach or .Last.lib function (provided the latter
> is exported from the namespace) when detach is called on the package. It
> is called with a single argument, the full path to the installed
> package. There is also a hook .onUnload which is called when the
> namespace is unloaded (via a call to unloadNamespace, perhaps called by
> detach(unload = TRUE)) with argument the full path to the installed
> package?s directory. Functions .onUnload and .onDetach should be defined
> in the namespace and not exported, but .Last.lib does need to be exported."
>
> Duncan Murdoch
>


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Jan  2 22:41:59 2025
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 2 Jan 2025 13:41:59 -0800
Subject: [R-pkg-devel] Removing packages files
In-Reply-To: <CAN+W6_v3opSqb54GP=uo5O_MpA5Do+m3cR_1GyPdUCxJWRqV3Q@mail.gmail.com>
References: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>
 <fa376599-ff9f-4509-bc41-c5f8c0f8e9c9@gmail.com>
 <CAN+W6_v3opSqb54GP=uo5O_MpA5Do+m3cR_1GyPdUCxJWRqV3Q@mail.gmail.com>
Message-ID: <CAFDcVCQxDLka17fGx4XzdLUOCV4aV2B8GHRaqzhCvgzsxMHtjg@mail.gmail.com>

As a first step, this sounds like something for the 'tools' package,
e.g. tools::cleanup_R_user_dir() that wipes package subfolders of
packages no longer installed, or the specified package, iff given.
With that in place, one could argue for adding a 'cleanup' argument to
remove.packages() that use the former.

Agree, it would be neat if a package could clean up after itself when
uninstalled.

/Henrik

On Thu, Jan 2, 2025 at 1:37?PM Llu?s Revilla <lluis.revilla at gmail.com> wrote:
>
> Dear Duncan,
>
> Thank you for your answer. I checked again and made a mock package
> that removes a file with .onDetach.
> The file was not removed upon uninstalling the package.
>
> Llu?s
>
> On Thu, 2 Jan 2025 at 17:23, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> >
> > On 2025-01-02 9:55 a.m., Llu?s Revilla wrote:
> > > Hi list,
> > >
> > > I am developing a package that will download some data, and I'd like
> > > to store it locally to not recalculate it often.
> > > The CRAN policy requires tools::R_user_dir to be used and "the
> > > contents are actively managed (including removing outdated material)"
> > > or using TMPDIR but "such usage should be cleaned up".
> > >
> > > When loading a package there is .onLoad or .onAttach to fill or check
> > > those files and other settings required for a package. Is there
> > > something for when a package is removed?
> > >
> > > I found some related functions like .Last or reg.fnalizer and setHook
> > > or packageEvent but they are about closing a session or don't have a
> > > specific event for when uninstalling packages via (remove.packages). I
> > > appreciate any feedback, thanks in advance.
> > >
> >
> > Yes, those are described in section "1.5.3 Load hooks" of writing R
> > extensions:
> >
> > "Packages can use a .onDetach or .Last.lib function (provided the latter
> > is exported from the namespace) when detach is called on the package. It
> > is called with a single argument, the full path to the installed
> > package. There is also a hook .onUnload which is called when the
> > namespace is unloaded (via a call to unloadNamespace, perhaps called by
> > detach(unload = TRUE)) with argument the full path to the installed
> > package?s directory. Functions .onUnload and .onDetach should be defined
> > in the namespace and not exported, but .Last.lib does need to be exported."
> >
> > Duncan Murdoch
> >
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Jan  2 22:47:21 2025
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 2 Jan 2025 16:47:21 -0500
Subject: [R-pkg-devel] Removing packages files
In-Reply-To: <CAN+W6_v3opSqb54GP=uo5O_MpA5Do+m3cR_1GyPdUCxJWRqV3Q@mail.gmail.com>
References: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>
 <fa376599-ff9f-4509-bc41-c5f8c0f8e9c9@gmail.com>
 <CAN+W6_v3opSqb54GP=uo5O_MpA5Do+m3cR_1GyPdUCxJWRqV3Q@mail.gmail.com>
Message-ID: <7d36ce00-c0b0-458f-ac50-5aa577396acc@gmail.com>

Sorry, I misunderstood what you are after.  I thought you only wanted to 
keep it for the duration of a session.  I don't think there's a way to 
keep a file beyond the current session, but uninstall it later when the 
package is uninstalled.

I think the way you should handle this is to offer a function to the 
user to download the data to the user directory, not to ever do that 
automatically.  If the data hasn't been downloaded, then give the user a 
message that it needs to be downloaded for things to work.  (Or maybe 
download it to the temp directory, and delete it when your package is 
unloaded.)

Duncan Murdoch


On 2025-01-02 4:29 p.m., Llu?s Revilla wrote:
> Dear Duncan,
> 
> Thank you for your answer. I checked again and made a mock package
> that removes a file with .onDetach.
> The file was not removed upon uninstalling the package.
> 
> Llu?s
> 
> On Thu, 2 Jan 2025 at 17:23, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 2025-01-02 9:55 a.m., Llu?s Revilla wrote:
>>> Hi list,
>>>
>>> I am developing a package that will download some data, and I'd like
>>> to store it locally to not recalculate it often.
>>> The CRAN policy requires tools::R_user_dir to be used and "the
>>> contents are actively managed (including removing outdated material)"
>>> or using TMPDIR but "such usage should be cleaned up".
>>>
>>> When loading a package there is .onLoad or .onAttach to fill or check
>>> those files and other settings required for a package. Is there
>>> something for when a package is removed?
>>>
>>> I found some related functions like .Last or reg.fnalizer and setHook
>>> or packageEvent but they are about closing a session or don't have a
>>> specific event for when uninstalling packages via (remove.packages). I
>>> appreciate any feedback, thanks in advance.
>>>
>>
>> Yes, those are described in section "1.5.3 Load hooks" of writing R
>> extensions:
>>
>> "Packages can use a .onDetach or .Last.lib function (provided the latter
>> is exported from the namespace) when detach is called on the package. It
>> is called with a single argument, the full path to the installed
>> package. There is also a hook .onUnload which is called when the
>> namespace is unloaded (via a call to unloadNamespace, perhaps called by
>> detach(unload = TRUE)) with argument the full path to the installed
>> package?s directory. Functions .onUnload and .onDetach should be defined
>> in the namespace and not exported, but .Last.lib does need to be exported."
>>
>> Duncan Murdoch
>>


From ||u|@@rev|||@ @end|ng |rom gm@||@com  Fri Jan  3 16:04:01 2025
From: ||u|@@rev|||@ @end|ng |rom gm@||@com (=?UTF-8?Q?Llu=C3=ADs_Revilla?=)
Date: Fri, 3 Jan 2025 16:04:01 +0100
Subject: [R-pkg-devel] Removing packages files
In-Reply-To: <CAFDcVCQxDLka17fGx4XzdLUOCV4aV2B8GHRaqzhCvgzsxMHtjg@mail.gmail.com>
References: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>
 <fa376599-ff9f-4509-bc41-c5f8c0f8e9c9@gmail.com>
 <CAN+W6_v3opSqb54GP=uo5O_MpA5Do+m3cR_1GyPdUCxJWRqV3Q@mail.gmail.com>
 <CAFDcVCQxDLka17fGx4XzdLUOCV4aV2B8GHRaqzhCvgzsxMHtjg@mail.gmail.com>
Message-ID: <CAN+W6_uipwj9WopA1Dk5VA9aY1=7HM=XoixWUMXrYPtHj9id_Q@mail.gmail.com>

Thanks Henrik for confirming there is nothing similar currently.

Duncan: Letting the user choose when to remove the folder/data at will is easy.
I was trying to ensure that the system is clean after removing the package.
Thanks.

On Thu, 2 Jan 2025 at 22:42, Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
>
> As a first step, this sounds like something for the 'tools' package,
> e.g. tools::cleanup_R_user_dir() that wipes package subfolders of
> packages no longer installed, or the specified package, iff given.
> With that in place, one could argue for adding a 'cleanup' argument to
> remove.packages() that use the former.
>
> Agree, it would be neat if a package could clean up after itself when
> uninstalled.
>
> /Henrik
>
> On Thu, Jan 2, 2025 at 1:37?PM Llu?s Revilla <lluis.revilla at gmail.com> wrote:
> >
> > Dear Duncan,
> >
> > Thank you for your answer. I checked again and made a mock package
> > that removes a file with .onDetach.
> > The file was not removed upon uninstalling the package.
> >
> > Llu?s
> >
> > On Thu, 2 Jan 2025 at 17:23, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> > >
> > > On 2025-01-02 9:55 a.m., Llu?s Revilla wrote:
> > > > Hi list,
> > > >
> > > > I am developing a package that will download some data, and I'd like
> > > > to store it locally to not recalculate it often.
> > > > The CRAN policy requires tools::R_user_dir to be used and "the
> > > > contents are actively managed (including removing outdated material)"
> > > > or using TMPDIR but "such usage should be cleaned up".
> > > >
> > > > When loading a package there is .onLoad or .onAttach to fill or check
> > > > those files and other settings required for a package. Is there
> > > > something for when a package is removed?
> > > >
> > > > I found some related functions like .Last or reg.fnalizer and setHook
> > > > or packageEvent but they are about closing a session or don't have a
> > > > specific event for when uninstalling packages via (remove.packages). I
> > > > appreciate any feedback, thanks in advance.
> > > >
> > >
> > > Yes, those are described in section "1.5.3 Load hooks" of writing R
> > > extensions:
> > >
> > > "Packages can use a .onDetach or .Last.lib function (provided the latter
> > > is exported from the namespace) when detach is called on the package. It
> > > is called with a single argument, the full path to the installed
> > > package. There is also a hook .onUnload which is called when the
> > > namespace is unloaded (via a call to unloadNamespace, perhaps called by
> > > detach(unload = TRUE)) with argument the full path to the installed
> > > package?s directory. Functions .onUnload and .onDetach should be defined
> > > in the namespace and not exported, but .Last.lib does need to be exported."
> > >
> > > Duncan Murdoch
> > >
> >
> > ______________________________________________
> > R-package-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-package-devel


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Jan  3 17:23:32 2025
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 3 Jan 2025 11:23:32 -0500
Subject: [R-pkg-devel] Removing packages files
In-Reply-To: <CAN+W6_uipwj9WopA1Dk5VA9aY1=7HM=XoixWUMXrYPtHj9id_Q@mail.gmail.com>
References: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>
 <fa376599-ff9f-4509-bc41-c5f8c0f8e9c9@gmail.com>
 <CAN+W6_v3opSqb54GP=uo5O_MpA5Do+m3cR_1GyPdUCxJWRqV3Q@mail.gmail.com>
 <CAFDcVCQxDLka17fGx4XzdLUOCV4aV2B8GHRaqzhCvgzsxMHtjg@mail.gmail.com>
 <CAN+W6_uipwj9WopA1Dk5VA9aY1=7HM=XoixWUMXrYPtHj9id_Q@mail.gmail.com>
Message-ID: <7cca8298-6e75-429f-ac89-dba8a7a79929@gmail.com>

On 2025-01-03 10:04 a.m., Llu?s Revilla wrote:
> Thanks Henrik for confirming there is nothing similar currently.
> 
> Duncan: Letting the user choose when to remove the folder/data at will is easy.
> I was trying to ensure that the system is clean after removing the package.
> Thanks.

No, I was suggesting that you require the user to explicitly ask for the 
data.  You don't want CRAN to install the data during testing and then 
have it left behind at the end.

Duncan Murdoch

> 
> On Thu, 2 Jan 2025 at 22:42, Henrik Bengtsson
> <henrik.bengtsson at gmail.com> wrote:
>>
>> As a first step, this sounds like something for the 'tools' package,
>> e.g. tools::cleanup_R_user_dir() that wipes package subfolders of
>> packages no longer installed, or the specified package, iff given.
>> With that in place, one could argue for adding a 'cleanup' argument to
>> remove.packages() that use the former.
>>
>> Agree, it would be neat if a package could clean up after itself when
>> uninstalled.
>>
>> /Henrik
>>
>> On Thu, Jan 2, 2025 at 1:37?PM Llu?s Revilla <lluis.revilla at gmail.com> wrote:
>>>
>>> Dear Duncan,
>>>
>>> Thank you for your answer. I checked again and made a mock package
>>> that removes a file with .onDetach.
>>> The file was not removed upon uninstalling the package.
>>>
>>> Llu?s
>>>
>>> On Thu, 2 Jan 2025 at 17:23, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>>
>>>> On 2025-01-02 9:55 a.m., Llu?s Revilla wrote:
>>>>> Hi list,
>>>>>
>>>>> I am developing a package that will download some data, and I'd like
>>>>> to store it locally to not recalculate it often.
>>>>> The CRAN policy requires tools::R_user_dir to be used and "the
>>>>> contents are actively managed (including removing outdated material)"
>>>>> or using TMPDIR but "such usage should be cleaned up".
>>>>>
>>>>> When loading a package there is .onLoad or .onAttach to fill or check
>>>>> those files and other settings required for a package. Is there
>>>>> something for when a package is removed?
>>>>>
>>>>> I found some related functions like .Last or reg.fnalizer and setHook
>>>>> or packageEvent but they are about closing a session or don't have a
>>>>> specific event for when uninstalling packages via (remove.packages). I
>>>>> appreciate any feedback, thanks in advance.
>>>>>
>>>>
>>>> Yes, those are described in section "1.5.3 Load hooks" of writing R
>>>> extensions:
>>>>
>>>> "Packages can use a .onDetach or .Last.lib function (provided the latter
>>>> is exported from the namespace) when detach is called on the package. It
>>>> is called with a single argument, the full path to the installed
>>>> package. There is also a hook .onUnload which is called when the
>>>> namespace is unloaded (via a call to unloadNamespace, perhaps called by
>>>> detach(unload = TRUE)) with argument the full path to the installed
>>>> package?s directory. Functions .onUnload and .onDetach should be defined
>>>> in the namespace and not exported, but .Last.lib does need to be exported."
>>>>
>>>> Duncan Murdoch
>>>>
>>>
>>> ______________________________________________
>>> R-package-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From edd @end|ng |rom deb|@n@org  Fri Jan  3 17:34:17 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Fri, 3 Jan 2025 10:34:17 -0600
Subject: [R-pkg-devel] Removing packages files
In-Reply-To: <CAFDcVCQxDLka17fGx4XzdLUOCV4aV2B8GHRaqzhCvgzsxMHtjg@mail.gmail.com>
References: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>
 <fa376599-ff9f-4509-bc41-c5f8c0f8e9c9@gmail.com>
 <CAN+W6_v3opSqb54GP=uo5O_MpA5Do+m3cR_1GyPdUCxJWRqV3Q@mail.gmail.com>
 <CAFDcVCQxDLka17fGx4XzdLUOCV4aV2B8GHRaqzhCvgzsxMHtjg@mail.gmail.com>
Message-ID: <26488.4489.589883.44632@rob.eddelbuettel.com>


On 2 January 2025 at 13:41, Henrik Bengtsson wrote:
| Agree, it would be neat if a package could clean up after itself when
| uninstalled.

Indeed many things could be nicer if we had more package manager integrations
and hooks besides `cleanup` and `configure`.  Someone would have to start
with some patches to get the ball rolling.

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From ||u|@@rev|||@ @end|ng |rom gm@||@com  Fri Jan  3 17:46:36 2025
From: ||u|@@rev|||@ @end|ng |rom gm@||@com (=?UTF-8?Q?Llu=C3=ADs_Revilla?=)
Date: Fri, 3 Jan 2025 17:46:36 +0100
Subject: [R-pkg-devel] Removing packages files
In-Reply-To: <7cca8298-6e75-429f-ac89-dba8a7a79929@gmail.com>
References: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>
 <fa376599-ff9f-4509-bc41-c5f8c0f8e9c9@gmail.com>
 <CAN+W6_v3opSqb54GP=uo5O_MpA5Do+m3cR_1GyPdUCxJWRqV3Q@mail.gmail.com>
 <CAFDcVCQxDLka17fGx4XzdLUOCV4aV2B8GHRaqzhCvgzsxMHtjg@mail.gmail.com>
 <CAN+W6_uipwj9WopA1Dk5VA9aY1=7HM=XoixWUMXrYPtHj9id_Q@mail.gmail.com>
 <7cca8298-6e75-429f-ac89-dba8a7a79929@gmail.com>
Message-ID: <CAN+W6_s4ihi_D65Ph=j7-zDSc+DrgR1J-nOECEPmerROZTJ=4A@mail.gmail.com>

The data is mostly CRAN's own files transformed, I don't expect the
download to be problematic on CRAN's checks.
The R core members made the functionality inside tools to use a local
variable to search for the requested file locally.
Only if the file is not found they are downloaded from the internet.

Regarding tests, I could disable saving the content to a file (Thanks
for mentioning, I hadn't thought about it).
But the functionality/utility of the package is to transform CRAN's data.
If it is failing to do so, I would like to know.

Llu?s

On Fri, 3 Jan 2025 at 17:23, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 2025-01-03 10:04 a.m., Llu?s Revilla wrote:
> > Thanks Henrik for confirming there is nothing similar currently.
> >
> > Duncan: Letting the user choose when to remove the folder/data at will is easy.
> > I was trying to ensure that the system is clean after removing the package.
> > Thanks.
>
> No, I was suggesting that you require the user to explicitly ask for the
> data.  You don't want CRAN to install the data during testing and then
> have it left behind at the end.
>
> Duncan Murdoch
>
> >
> > On Thu, 2 Jan 2025 at 22:42, Henrik Bengtsson
> > <henrik.bengtsson at gmail.com> wrote:
> >>
> >> As a first step, this sounds like something for the 'tools' package,
> >> e.g. tools::cleanup_R_user_dir() that wipes package subfolders of
> >> packages no longer installed, or the specified package, iff given.
> >> With that in place, one could argue for adding a 'cleanup' argument to
> >> remove.packages() that use the former.
> >>
> >> Agree, it would be neat if a package could clean up after itself when
> >> uninstalled.
> >>
> >> /Henrik
> >>
> >> On Thu, Jan 2, 2025 at 1:37?PM Llu?s Revilla <lluis.revilla at gmail.com> wrote:
> >>>
> >>> Dear Duncan,
> >>>
> >>> Thank you for your answer. I checked again and made a mock package
> >>> that removes a file with .onDetach.
> >>> The file was not removed upon uninstalling the package.
> >>>
> >>> Llu?s
> >>>
> >>> On Thu, 2 Jan 2025 at 17:23, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> >>>>
> >>>> On 2025-01-02 9:55 a.m., Llu?s Revilla wrote:
> >>>>> Hi list,
> >>>>>
> >>>>> I am developing a package that will download some data, and I'd like
> >>>>> to store it locally to not recalculate it often.
> >>>>> The CRAN policy requires tools::R_user_dir to be used and "the
> >>>>> contents are actively managed (including removing outdated material)"
> >>>>> or using TMPDIR but "such usage should be cleaned up".
> >>>>>
> >>>>> When loading a package there is .onLoad or .onAttach to fill or check
> >>>>> those files and other settings required for a package. Is there
> >>>>> something for when a package is removed?
> >>>>>
> >>>>> I found some related functions like .Last or reg.fnalizer and setHook
> >>>>> or packageEvent but they are about closing a session or don't have a
> >>>>> specific event for when uninstalling packages via (remove.packages). I
> >>>>> appreciate any feedback, thanks in advance.
> >>>>>
> >>>>
> >>>> Yes, those are described in section "1.5.3 Load hooks" of writing R
> >>>> extensions:
> >>>>
> >>>> "Packages can use a .onDetach or .Last.lib function (provided the latter
> >>>> is exported from the namespace) when detach is called on the package. It
> >>>> is called with a single argument, the full path to the installed
> >>>> package. There is also a hook .onUnload which is called when the
> >>>> namespace is unloaded (via a call to unloadNamespace, perhaps called by
> >>>> detach(unload = TRUE)) with argument the full path to the installed
> >>>> package?s directory. Functions .onUnload and .onDetach should be defined
> >>>> in the namespace and not exported, but .Last.lib does need to be exported."
> >>>>
> >>>> Duncan Murdoch
> >>>>
> >>>
> >>> ______________________________________________
> >>> R-package-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>


From pep|jn@devr|e@ @end|ng |rom out|ook@com  Wed Jan  8 13:51:32 2025
From: pep|jn@devr|e@ @end|ng |rom out|ook@com (Pepijn de Vries)
Date: Wed, 8 Jan 2025 12:51:32 +0000
Subject: [R-pkg-devel] (no subject)
Message-ID: <AM8PR10MB466065432B7F9DA11EA0D279A7122@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>

Dear fellow package developers,

A while back I have submitted a package to CRAN and is now listed under waiting <https://cran.r-project.org/incoming/waiting/openmpt_0.1.1.tar.gz>

As I understand it, incoming packages are listed there if CRAN needs more information from the maintainer. However, I have received no requests from CRAN. In the meantime it has been stagnant in the waiting area for about 22 days.

After some more testing I discovered that the submitted package violates CRAN policy (it does not exit gracefully when online resources are not available). Maybe this is why it is on hold. This has been fixed in <https://github.com/pepijn-devries/openmpt>, but has not been submitted yet. How do I proceed? I think I have the following options:

 - wait even longer for feedback from CRAN;
 - contact CRAN about the status of this package;
 - submit the latest version of the package in which policy violations have been addressed.

Any thoughts are welcome.

Pepijn

From ||u|@@rev|||@ @end|ng |rom gm@||@com  Wed Jan  8 22:17:57 2025
From: ||u|@@rev|||@ @end|ng |rom gm@||@com (=?UTF-8?Q?Llu=C3=ADs_Revilla?=)
Date: Wed, 8 Jan 2025 22:17:57 +0100
Subject: [R-pkg-devel] (no subject)
In-Reply-To: <AM8PR10MB466065432B7F9DA11EA0D279A7122@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>
References: <AM8PR10MB466065432B7F9DA11EA0D279A7122@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <CAN+W6_u9v-XftUpdt0Fu9QZ+2u+Eh7RmxyFOqX+rV0entox0Mg@mail.gmail.com>

Dear Pepijn,

Thank you for the very detailed email.
Part of these 22 days might be explained by CRAN volunteers being on
vacations a couple of weeks, until yesterday.

I would submit the latest version of the package with the improvements you made.
Other options require more manual work from CRAN volunteers and/or more delays.
I'm sure they will appreciate you double checking CRAN policy to make
sure you comply with all the requirements.

To solve some common issues, there is a new resource co-authored by a
CRAN reviewer: the CRAN cookbook:
https://contributor.r-project.org/cran-cookbook/
I hope it helps.

Good luck!
Best,

Llu?s Revilla

PS: There are some issues on AmigaFFH package, you might receive a
message to update it.

On Wed, 8 Jan 2025 at 13:51, Pepijn de Vries <pepijn.devries at outlook.com> wrote:
>
> Dear fellow package developers,
>
> A while back I have submitted a package to CRAN and is now listed under waiting <https://cran.r-project.org/incoming/waiting/openmpt_0.1.1.tar.gz>
>
> As I understand it, incoming packages are listed there if CRAN needs more information from the maintainer. However, I have received no requests from CRAN. In the meantime it has been stagnant in the waiting area for about 22 days.
>
> After some more testing I discovered that the submitted package violates CRAN policy (it does not exit gracefully when online resources are not available). Maybe this is why it is on hold. This has been fixed in <https://github.com/pepijn-devries/openmpt>, but has not been submitted yet. How do I proceed? I think I have the following options:
>
>  - wait even longer for feedback from CRAN;
>  - contact CRAN about the status of this package;
>  - submit the latest version of the package in which policy violations have been addressed.
>
> Any thoughts are welcome.
>
> Pepijn
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From pep|jn@devr|e@ @end|ng |rom out|ook@com  Wed Jan  8 23:00:07 2025
From: pep|jn@devr|e@ @end|ng |rom out|ook@com (Pepijn de Vries)
Date: Wed, 8 Jan 2025 22:00:07 +0000
Subject: [R-pkg-devel] (no subject)
In-Reply-To: <CAN+W6_u9v-XftUpdt0Fu9QZ+2u+Eh7RmxyFOqX+rV0entox0Mg@mail.gmail.com>
References: <AM8PR10MB466065432B7F9DA11EA0D279A7122@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>
 <CAN+W6_u9v-XftUpdt0Fu9QZ+2u+Eh7RmxyFOqX+rV0entox0Mg@mail.gmail.com>
Message-ID: <AM8PR10MB466003A076F7723BBAAFCC0BA7122@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>

Hi Llu?s,

Thank you for you thoughts on this matter and recommendations. I will go ahead to submit the revised version as soon as possible.

Cheers,

Pepijn

________________________________________
Van:?Llu?s Revilla <lluis.revilla at gmail.com>
Verzonden:?woensdag 8 januari 2025 22:17
Aan:?Pepijn de Vries <pepijn.devries at outlook.com>
CC:?Ivan Krylov via R-package-devel <r-package-devel at r-project.org>
Onderwerp:?Re: [R-pkg-devel] (no subject)
?
Dear Pepijn,

Thank you for the very detailed email.
Part of these 22 days might be explained by CRAN volunteers being on
vacations a couple of weeks, until yesterday.

I would submit the latest version of the package with the improvements you made.
Other options require more manual work from CRAN volunteers and/or more delays.
I'm sure they will appreciate you double checking CRAN policy to make
sure you comply with all the requirements.

To solve some common issues, there is a new resource co-authored by a
CRAN reviewer: the CRAN cookbook:
https://contributor.r-project.org/cran-cookbook/
I hope it helps.

Good luck!
Best,

Llu?s Revilla

PS: There are some issues on AmigaFFH package, you might receive a
message to update it.

On Wed, 8 Jan 2025 at 13:51, Pepijn de Vries <pepijn.devries at outlook.com> wrote:
>
> Dear fellow package developers,
>
> A while back I have submitted a package to CRAN and is now listed under waiting <https://cran.r-project.org/incoming/waiting/openmpt_0.1.1.tar.gz>
>
> As I understand it, incoming packages are listed there if CRAN needs more information from the maintainer. However, I have received no requests from CRAN. In the meantime it has been stagnant in the waiting area for about 22 days.
>
> After some more testing I discovered that the submitted package violates CRAN policy (it does not exit gracefully when online resources are not available). Maybe this is why it is on hold. This has been fixed in <https://github.com/pepijn-devries/openmpt>, but has not been submitted yet. How do I proceed? I think I have the following options:
>
>? - wait even longer for feedback from CRAN;
>? - contact CRAN about the status of this package;
>? - submit the latest version of the package in which policy violations have been addressed.
>
> Any thoughts are welcome.
>
> Pepijn
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel

From vo|ody@ @end|ng |rom m|nd@pr|ng@com  Thu Jan  9 04:23:15 2025
From: vo|ody@ @end|ng |rom m|nd@pr|ng@com (Vladimir Dergachev)
Date: Wed, 8 Jan 2025 22:23:15 -0500 (EST)
Subject: [R-pkg-devel] Removing packages files
In-Reply-To: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>
References: <CAN+W6_sjx59W6hGGMyj565smnazws=uasSWbwEHEe7kXT+YLAQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.22.394.2501082220520.45848@iridium>


Hi Llu?s,

   Just wanted to add to the discussion that it would be good to consider 
users that are disconnected or behind a firewall and are installing the 
package from file.

   An option to point the package to a separately downloaded file would be
useful.

best

Vladimir Dergachev

On Thu, 2 Jan 2025, Llu?s Revilla wrote:

> Hi list,
>
> I am developing a package that will download some data, and I'd like
> to store it locally to not recalculate it often.
> The CRAN policy requires tools::R_user_dir to be used and "the
> contents are actively managed (including removing outdated material)"
> or using TMPDIR but "such usage should be cleaned up".
>
> When loading a package there is .onLoad or .onAttach to fill or check
> those files and other settings required for a package. Is there
> something for when a package is removed?
>
> I found some related functions like .Last or reg.fnalizer and setHook
> or packageEvent but they are about closing a session or don't have a
> specific event for when uninstalling packages via (remove.packages). I
> appreciate any feedback, thanks in advance.
>
> Best wishes and a happy new year,
>
> Llu?s
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

From kent@r|emondy @end|ng |rom gm@||@com  Fri Jan 10 15:45:00 2025
From: kent@r|emondy @end|ng |rom gm@||@com (Kent Riemondy)
Date: Fri, 10 Jan 2025 07:45:00 -0700
Subject: [R-pkg-devel] addressing a CRAN submission pre-test clang-san
 warning
Message-ID: <CA+cnB_jbABqxCOsxuCA1-E5sJOf0qZBwrC7t1gNSAH3sHCPKig@mail.gmail.com>

Hi,
  I maintain a package on CRAN (valr) and recently submitted a new version.
The package is failing CRAN pre-test checks due to the warning below from
the clang-san test. The cleancall.c file referenced in the warning isn't in
valr's source code, nor direct dependencies, but eventually I believe
tracks back to the purrr package. Does anyone have any advice for how to
replicate or address this warning?

Flavor: r-devel-linux-x86_64-debian-special-clang-san
Check: Post-processing issues found for clang-san, Result: WARNING
  File: valr-Ex.Rout
  cleancall.c:110:46: runtime error: call to function cb_progress_done
through pointer to incorrect function type 'void (*)(void *)'

  File: tests/testthat.Rout
  cleancall.c:110:46: runtime error: call to function cb_progress_done
through pointer to incorrect function type 'void (*)(void *)'

package source: https://github.com/rnabioco/valr
pre-test artifacts:
https://win-builder.r-project.org/incoming_pretest/valr_0.8.3_20250108_153335/specialChecks/clang-san
/

Thanks in advance,
Kent

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Fri Jan 10 16:06:52 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Fri, 10 Jan 2025 18:06:52 +0300
Subject: [R-pkg-devel] 
 [SPAM Warning!] addressing a CRAN submission pre-test
 clang-san warning
In-Reply-To: <CA+cnB_jbABqxCOsxuCA1-E5sJOf0qZBwrC7t1gNSAH3sHCPKig@mail.gmail.com>
References: <CA+cnB_jbABqxCOsxuCA1-E5sJOf0qZBwrC7t1gNSAH3sHCPKig@mail.gmail.com>
Message-ID: <20250110180652.2d7bbc89@arachnoid>

? Fri, 10 Jan 2025 07:45:00 -0700
Kent Riemondy <kent.riemondy at gmail.com> ?????:

>   cleancall.c:110:46: runtime error: call to function cb_progress_done
> through pointer to incorrect function type 'void (*)(void *)'

This is a (mostly harmless) error in the purrr package:
https://stat.ethz.ch/pipermail/r-package-devel/2024q4/011230.html

It has recently been reported to the package maintainers:
https://github.com/tidyverse/purrr/issues/1157

Instead of casting the cb_progress_done function pointer to (void
(*)(void*)), the function needs to accept (void*) and cast the argument
to SEXP in the function body.

-- 
Best regards,
Ivan


From kent@r|emondy @end|ng |rom gm@||@com  Fri Jan 10 16:21:27 2025
From: kent@r|emondy @end|ng |rom gm@||@com (Kent Riemondy)
Date: Fri, 10 Jan 2025 08:21:27 -0700
Subject: [R-pkg-devel] 
 [SPAM Warning!] addressing a CRAN submission pre-test
 clang-san warning
In-Reply-To: <20250110180652.2d7bbc89@arachnoid>
References: <CA+cnB_jbABqxCOsxuCA1-E5sJOf0qZBwrC7t1gNSAH3sHCPKig@mail.gmail.com>
 <20250110180652.2d7bbc89@arachnoid>
Message-ID: <CA+cnB_gPGQEDXJHPao2TzQjFzFMg+Akn-Padvn_e1Gd03C=UMg@mail.gmail.com>

Ivan,
  Many thanks for the prompt and helpful response. I hadn't seen the
previous r-package-devel message with the same error. I will explain this
situation to CRAN which hopefully will allow valr to stay on CRAN while I
work to get the suggested fix implemented in purrr.

Thanks,
Kent


On Fri, Jan 10, 2025 at 8:08?AM Ivan Krylov <ikrylov at disroot.org> wrote:

> ? Fri, 10 Jan 2025 07:45:00 -0700
> Kent Riemondy <kent.riemondy at gmail.com> ?????:
>
> >   cleancall.c:110:46: runtime error: call to function cb_progress_done
> > through pointer to incorrect function type 'void (*)(void *)'
>
> This is a (mostly harmless) error in the purrr package:
> https://stat.ethz.ch/pipermail/r-package-devel/2024q4/011230.html
>
> It has recently been reported to the package maintainers:
> https://github.com/tidyverse/purrr/issues/1157
>
> Instead of casting the cb_progress_done function pointer to (void
> (*)(void*)), the function needs to accept (void*) and cast the argument
> to SEXP in the function body.
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From pep|jn@devr|e@ @end|ng |rom out|ook@com  Fri Jan 10 18:00:04 2025
From: pep|jn@devr|e@ @end|ng |rom out|ook@com (Pepijn de Vries)
Date: Fri, 10 Jan 2025 17:00:04 +0000
Subject: [R-pkg-devel] gcc-san check warns for non-portable flags
Message-ID: <AM8PR10MB4660B3C058C111F115FC8A9DA71C2@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>

Dear fellow package developers,

There were multiple issues with a package I maintain: @CRAN: <https://cran.r-project.org/package=adfExplorer> @source: <https://github.com/pepijn-devries/adfExplorer/>. As far as I can tell all issues listed @CRAN were fixed in the latest version (available from GitHub and R-Universe). However, when submitting to CRAN, the special gcc san check complains about non-portable flags (see below).

I cannot reproduce this warning myself. As far as I can tell, I don't set these flags myself (neither in the configure script nor in makevars.in). I suspect that these flags are set by the machine that performs the checks. How do I pass this check? Or should I report it to CRAN as a false negative result?

Many thanks for your help.

Kind regards,

Pepijn

> Flavor: r-devel-windows-x86_64, r-devel-linux-x86_64-debian-special-clang-san
> Check: *, Result: OK
>  ?
> Flavor: r-devel-linux-x86_64-debian-special-gcc-san
> Check: compilation flags used, Result: WARNING
> ?Compilation used the following non-portable flag(s):
>  ? ?'-Wno-deprecated-declarations' '-Wno-ignored-attributes'
>  ? ?'-Wno-stringop-truncation'
>  ?including flag(s) suppressing warnings


From d@v|d@gohe| @end|ng |rom @rd@t@@|r  Fri Jan 10 18:17:39 2025
From: d@v|d@gohe| @end|ng |rom @rd@t@@|r (David Gohel)
Date: Fri, 10 Jan 2025 17:17:39 +0000
Subject: [R-pkg-devel] gcc-san check warns for non-portable flags
In-Reply-To: <AM8PR10MB4660B3C058C111F115FC8A9DA71C2@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>
References: <AM8PR10MB4660B3C058C111F115FC8A9DA71C2@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <MRXP264MB0328A82A5EB35DFAAB4BAAA0FA1C2@MRXP264MB0328.FRAP264.PROD.OUTLOOK.COM>

I had the same this week.

Yes, you should answer these are false negative results.

KR,
David

De : R-package-devel <r-package-devel-bounces at r-project.org> de la part de Pepijn de Vries <pepijn.devries at outlook.com>
Date : vendredi, 10 janvier 2025 ? 18:00
? : Ivan Krylov via R-package-devel <r-package-devel at r-project.org>
Objet : [R-pkg-devel] gcc-san check warns for non-portable flags
Dear fellow package developers,

There were multiple issues with a package I maintain: @CRAN: <https://cran.r-project.org/package=adfExplorer> @source: <https://github.com/pepijn-devries/adfExplorer/>. As far as I can tell all issues listed @CRAN were fixed in the latest version (available from GitHub and R-Universe). However, when submitting to CRAN, the special gcc san check complains about non-portable flags (see below).

I cannot reproduce this warning myself. As far as I can tell, I don't set these flags myself (neither in the configure script nor in makevars.in). I suspect that these flags are set by the machine that performs the checks. How do I pass this check? Or should I report it to CRAN as a false negative result?

Many thanks for your help.

Kind regards,

Pepijn

> Flavor: r-devel-windows-x86_64, r-devel-linux-x86_64-debian-special-clang-san
> Check: *, Result: OK
>
> Flavor: r-devel-linux-x86_64-debian-special-gcc-san
> Check: compilation flags used, Result: WARNING
>  Compilation used the following non-portable flag(s):
>     '-Wno-deprecated-declarations' '-Wno-ignored-attributes'
>     '-Wno-stringop-truncation'
>   including flag(s) suppressing warnings

______________________________________________
R-package-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-package-devel

	[[alternative HTML version deleted]]


From pep|jn@devr|e@ @end|ng |rom out|ook@com  Fri Jan 10 21:19:27 2025
From: pep|jn@devr|e@ @end|ng |rom out|ook@com (Pepijn de Vries)
Date: Fri, 10 Jan 2025 20:19:27 +0000
Subject: [R-pkg-devel] gcc-san check warns for non-portable flags
In-Reply-To: <MRXP264MB0328A82A5EB35DFAAB4BAAA0FA1C2@MRXP264MB0328.FRAP264.PROD.OUTLOOK.COM>
References: <AM8PR10MB4660B3C058C111F115FC8A9DA71C2@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>
 <MRXP264MB0328A82A5EB35DFAAB4BAAA0FA1C2@MRXP264MB0328.FRAP264.PROD.OUTLOOK.COM>
Message-ID: <AM8PR10MB4660414895B1D16891E4AEB9A71C2@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>

Hi David,

Thanks for the quick response. I will report it.

Pepijn

________________________________________
Van:?R-package-devel <r-package-devel-bounces at r-project.org> namens David Gohel <david.gohel at ardata.fr>
Verzonden:?vrijdag 10 januari 2025 18:17
Aan:?r-package-devel at r-project.org <r-package-devel at r-project.org>
Onderwerp:?Re: [R-pkg-devel] gcc-san check warns for non-portable flags
?
I had the same this week.

Yes, you should answer these are false negative results.

KR,
David

De : R-package-devel <r-package-devel-bounces at r-project.org> de la part de Pepijn de Vries <pepijn.devries at outlook.com>
Date : vendredi, 10 janvier 2025 ? 18:00
? : Ivan Krylov via R-package-devel <r-package-devel at r-project.org>
Objet : [R-pkg-devel] gcc-san check warns for non-portable flags
Dear fellow package developers,

There were multiple issues with a package I maintain: @CRAN: <https://cran.r-project.org/package=adfExplorer> @source: <https://github.com/pepijn-devries/adfExplorer/>. As far as I can tell all issues listed @CRAN were fixed in the latest version (available from GitHub and R-Universe). However, when submitting to CRAN, the special gcc san check complains about non-portable flags (see below).

I cannot reproduce this warning myself. As far as I can tell, I don't set these flags myself (neither in the configure script nor in makevars.in). I suspect that these flags are set by the machine that performs the checks. How do I pass this check? Or should I report it to CRAN as a false negative result?

Many thanks for your help.

Kind regards,

Pepijn

> Flavor: r-devel-windows-x86_64, r-devel-linux-x86_64-debian-special-clang-san
> Check: *, Result: OK
>
> Flavor: r-devel-linux-x86_64-debian-special-gcc-san
> Check: compilation flags used, Result: WARNING
>? Compilation used the following non-portable flag(s):
>???? '-Wno-deprecated-declarations' '-Wno-ignored-attributes'
>???? '-Wno-stringop-truncation'
>?? including flag(s) suppressing warnings

______________________________________________
R-package-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-package-devel

??????? [[alternative HTML version deleted]]

From |uk@@@@chne|derb@uer @end|ng |rom gm@||@com  Sat Jan 11 10:37:20 2025
From: |uk@@@@chne|derb@uer @end|ng |rom gm@||@com (Lukas Schneiderbauer)
Date: Sat, 11 Jan 2025 10:37:20 +0100
Subject: [R-pkg-devel] SystemRequirements & configure check for FFTW with
 single precision support
Message-ID: <CAHETjtZcmar26ud0s0yn9RGQXwjKtVpkT3gt+o2DGfAyR-T=qg@mail.gmail.com>

Hi list,

I am working on getting a package <https://github.com/lschneiderbauer/fCWTr> to
CRAN. It depends on the FFTW library <https://www.fftw.org/> that is built
with single precision support. I am stuck in the submission process and I
require your help.

Before I come to my questions, some key facts about the package:

The package has an autoconf configure script that uses (among other things,
like OpenMP checks, etc..) AC_SEARCH_LIBS to check whether required
functions of the library 'fftwf' exist, if yes, it adds the corresponding
compiler/linker flags; if no, it errs with a descriptive error message.

The CRAN Windows as well as Linux build service included fftwf in their
fftw build out of the box, and so building there was no problem, R CMD
Check passes there. In the past, building for MacOS was more trouble, since
its fftw package does not include a single-precision build. I reached out
to Simon Urbanek, and he was so kind as to add an appropriate new recipe
"fftw-s" that provided an fftw version with single precision support. As of
now, R CMD check also passes cleanly on the MacOS build service, thanks to
Simon Urbanek's efforts.

Now, I am stuck at submission for two reasons:
1. The SystemRequirements specification in the DESCRIPTION file is
incorrect.
2. It is said that "the package needs a configure check for fftwf".

Add 1.
Initially, I had no mention of the "single precision" version of fftw,
because I thought it is included everywhere by default. It was stated that
I need to add that information. I naturally complied.
This is my current version:
"SystemRequirements: fftw3 (including single precision support fftw3f),
fftw3f_omp (optional), OpenMP (optional)"
In the second subscription run, I was told to add "fftw-s" since I require
the fftw-s package on MacOS. This does not make much sense to me since
"fftw-s" is only the name of this package on Simon Urbanek's MacOS build
service. The library file itself is still called fftwf, like it is on any
other platform. If I added "fftw-s", I would also need to explain that this
is only valid for MacOS which seems to make the SystemRequirements
unnecessary verbose.
* Can someone explain the reason behind this request to me?
* How exactly should I add "fftw-s" to pass the submission process?

Add 2.
I tried to explain now for the second time in the submission notes, that a
check is already in place (see the AC_SEARCH_LIBS paragraph above). But my
explanation gets ignored.
* What am I doing wrong?
* What additional configure checks do I need to add to the package?

Thanks a lot for your help!
Sincerely, Lukas Schneiderbauer

	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Sat Jan 11 19:52:59 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Sat, 11 Jan 2025 12:52:59 -0600
Subject: [R-pkg-devel] 
 SystemRequirements & configure check for FFTW with
 single precision support
In-Reply-To: <CAHETjtZcmar26ud0s0yn9RGQXwjKtVpkT3gt+o2DGfAyR-T=qg@mail.gmail.com>
References: <CAHETjtZcmar26ud0s0yn9RGQXwjKtVpkT3gt+o2DGfAyR-T=qg@mail.gmail.com>
Message-ID: <26498.48651.572674.777799@rob.eddelbuettel.com>


Lukas,

It is, as you noticed, complicated.

One way forward might be to rely on what you can rely on (i.e. a suitable
system fftw on two of the three platforms) and to embed and locally build
where not. Nowadays a number of packages embedding external libraries and
resorting to eg cmake to build locally to provide what their R package needs
(pak now rebuilds curl, igraph 'vendors' a number of external libraries, as
does duckdb and so on), and so on. It is one approach. Others download if
they must (i.e. what I once added to nloptr) but CRAN now leans more against
downloads at build time. [1]

The problem is that SystemRequirements: is all we have to solve a cross-OS,
cross-platform, cross-distro (for Linux), cross-release, ... dependency
issue.  Something for which a (commonly) single-line of free form text is not
all that well suited. But anything more formal would be need to reliably
address the cross-product of cpu architecture, operating system,
flavour/distro, release, ... Not easy for (less than) a handful of already
stretched volunteers.

So this is a hard problem; if it could be fixed easily it would have been
addressed in the 25+ plus years of CRAN.

Cheers, Dirk

PS For the smaller subset of three releases for (currently) one architecture,
one platform, and one distribution flavor this has been address using the
existence of system package manager: r2u covers this reliably and gets you
(CRAN) package binaries for Ubuntu with full and complete system dependency
integration, see https://eddelbuettel.github.io/r2u -- but it is hard /
impossible to generalise to other OSs without a similar package manager.

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From |kry|ov @end|ng |rom d|@root@org  Sat Jan 11 20:09:57 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sat, 11 Jan 2025 22:09:57 +0300
Subject: [R-pkg-devel] 
 SystemRequirements & configure check for FFTW with
 single precision support
In-Reply-To: <CAHETjtZcmar26ud0s0yn9RGQXwjKtVpkT3gt+o2DGfAyR-T=qg@mail.gmail.com>
References: <CAHETjtZcmar26ud0s0yn9RGQXwjKtVpkT3gt+o2DGfAyR-T=qg@mail.gmail.com>
Message-ID: <20250111220957.6f839b0d@Tarkus>

? Sat, 11 Jan 2025 10:37:20 +0100
Lukas Schneiderbauer <lukas.schneiderbauer at gmail.com> ?????:

> I was told to add "fftw-s" since I require the fftw-s package on
> MacOS.

> * Can someone explain the reason behind this request to me?

While the SystemRequirements: field currently contains free-form text,
eventually we might be able to evolve it into something
machine-readable to install the system-level dependencies
automatically. Since the macOS packages are built using the recipes
system to provide the dependencies, it makes certain sense to list the
name of the recipe for their sake, in addition to the name of the
shared library.

> * How exactly should I add "fftw-s" to pass the submission process?

I've tried looking for examples using

db <- tools::CRAN_package_db()
subset(db, grepl('recipe|mac', SystemRequirements, ignore.case=TRUE))

...but found nothing relevant. How about something like the following?

SystemRequirements:
 fftw3 (including single precision support fftw3f; 'fftw-s' macOS
 recipe), fftw3f_omp (optional), OpenMP (optional)

> I tried to explain now for the second time in the submission notes,
> that a check is already in place (see the AC_SEARCH_LIBS paragraph
> above). But my explanation gets ignored.

I'm sorry for asking this admittedly thick question, but are you sure
it's not just R CMD check --as-cran repeating the X-CRAN-Comment: field
(which includes the phrase about not testing for single-precision
FFTW)? Does the rejection e-mail say "please fix and resubmit", list
specific problems, or ask for specific actions?

> * What additional configure checks do I need to add to the package?

The configure test for -lfftwf seems fine to me.

I wouldn't test for OpenMP's omp.h because testing for a working OpenMP
installation is fraught with peril and corner cases [*], but you pick
up R's OpenMP flags correctly and have appropriate #ifdef _OPENMP
sections in the source code, so that shouldn't cause you any real
problems.

-- 
Best regards,
Ivan

[*] https://github.com/Rdatatable/data.table/pull/6642


From gr@eme|eeh|ckey @end|ng |rom gm@||@com  Tue Jan 14 08:08:20 2025
From: gr@eme|eeh|ckey @end|ng |rom gm@||@com (Graeme Hickey)
Date: Mon, 13 Jan 2025 23:08:20 -0800
Subject: [R-pkg-devel] Vignette build issue on Debian platform
Message-ID: <CALvcmje4JO8cfV05o+8dDWTWtCfx4GPGU0zYcxMgw+gTEghqug@mail.gmail.com>

Dear all,


I recently made some minor updates to the joineRML R package to squash some
CRAN CMD check NOTEs that have emerged over the past couple of years.  After
resubmitting to CRAN, a new NOTE appeared on the Debian platform only:


> package joineRML_0.4.7.tar.gz does not pass the incoming checks
automatically, please see the following pre-tests (additional issue checks):

> Windows: <
https://win-builder.r-project.org/incoming_pretest/joineRML_0.4.7_20250114_073418/Windows/00check.log
>

> Status: OK

> Debian: <
https://win-builder.r-project.org/incoming_pretest/joineRML_0.4.7_20250114_073418/Debian/00check.log
>

> Status: 1 NOTE


The NOTE in particular is:


> * checking re-building of vignette outputs ... [116s/30s] NOTE

> Re-building vignettes had CPU time 3.9 times elapsed time


I emailed Uwe Ligges and got a reply:


> We see

> Flavor: r-devel-linux-x86_64-debian-gcc

> Check: re-building of vignette outputs, Result: NOTE

>    Re-building vignettes had CPU time 3.9 times elapsed time


> which suggests you are using more than 2 cores which is not permitted by
default.


There is only one function in my package that uses multiple cores:
bootSE(). However, this function is not called in any of my vignettes
because it is computationally expensive. The Rmd code has `eval = FALSE`
options for all of these cases. Therefore, I am at a loss as to why these
vignettes would be using more than 2 cores or what is causing this, or why
it only impacts the CRAN CMD check Debian system.


I noticed this has been a common reported issue (e.g.,
https://github.com/Rdatatable/data.table/issues/5658), but mainly for those
using data.table or openMP; I use neither. The same issue was showing for
some examples also, which I dealt with by wrapping in \dontrun{} ? not
ideal, but seemed quickest way to avoid.


I have tried many things to fix this:

   1. Modifying the vignettes to make faster
   2. Adding various combinations of Sys.setenv("OMP_THREAD_LIMIT" = 1),
   Sys.setenv("OMP_NUM_THREADS" = 1), options(Ncpus = 1), options(cores = 2)
   to the Rmd vignettes
   3. Checked the package builds using r-lib/actions (GitHub actions) and
   r-hub Debian platform ? I cannot reproduce this CRAN error


CRAN will not accept the update to my package until this NOTE is squashed.
If anyone is able to provide a recommendation on what I might do, I would
appreciate it.


Kind regards,


Graeme Hickey

	[[alternative HTML version deleted]]


From j|@c@@hu|@m@n @end|ng |rom gm@||@com  Tue Jan 14 17:25:23 2025
From: j|@c@@hu|@m@n @end|ng |rom gm@||@com (Jisca Huisman)
Date: Tue, 14 Jan 2025 17:25:23 +0100
Subject: [R-pkg-devel] Vignette build issue on Debian platform
In-Reply-To: <CALvcmje4JO8cfV05o+8dDWTWtCfx4GPGU0zYcxMgw+gTEghqug@mail.gmail.com>
References: <CALvcmje4JO8cfV05o+8dDWTWtCfx4GPGU0zYcxMgw+gTEghqug@mail.gmail.com>
Message-ID: <852a85b8-0966-43fb-9d0b-b10188eb85fd@gmail.com>

Hi Graeme,

> There is only one function in my package that uses multiple cores:
> bootSE(). However, this function is not called in any of my vignettes
> because it is computationally expensive. The Rmd code has `eval = FALSE`
> options for all of these cases. Therefore, I am at a loss as to why these
> vignettes would be using more than 2 cores or what is causing this, or why
> it only impacts the CRAN CMD check Debian system.

CRAN has changed its settings when compiling the vignette, and now 
*does* run everything in chunks with `eval = FALSE`.? The solution is to 
also add `purl=FALSE` to each chunk that should not be run.

If you dig through the mailing list archive you should be able to find 
further details on the why and how of this, or someone else might remember.

Best,

Jisca



On Tue, 14/01/2025 08:08, Graeme Hickey wrote:
> Dear all,
>
>
> I recently made some minor updates to the joineRML R package to squash some
> CRAN CMD check NOTEs that have emerged over the past couple of years.  After
> resubmitting to CRAN, a new NOTE appeared on the Debian platform only:
>
>
>> package joineRML_0.4.7.tar.gz does not pass the incoming checks
> automatically, please see the following pre-tests (additional issue checks):
>
>> Windows: <
> https://win-builder.r-project.org/incoming_pretest/joineRML_0.4.7_20250114_073418/Windows/00check.log
>> Status: OK
>> Debian: <
> https://win-builder.r-project.org/incoming_pretest/joineRML_0.4.7_20250114_073418/Debian/00check.log
>> Status: 1 NOTE
>
> The NOTE in particular is:
>
>
>> * checking re-building of vignette outputs ... [116s/30s] NOTE
>> Re-building vignettes had CPU time 3.9 times elapsed time
>
> I emailed Uwe Ligges and got a reply:
>
>
>> We see
>> Flavor: r-devel-linux-x86_64-debian-gcc
>> Check: re-building of vignette outputs, Result: NOTE
>>     Re-building vignettes had CPU time 3.9 times elapsed time
>
>> which suggests you are using more than 2 cores which is not permitted by
> default.
>
>
> There is only one function in my package that uses multiple cores:
> bootSE(). However, this function is not called in any of my vignettes
> because it is computationally expensive. The Rmd code has `eval = FALSE`
> options for all of these cases. Therefore, I am at a loss as to why these
> vignettes would be using more than 2 cores or what is causing this, or why
> it only impacts the CRAN CMD check Debian system.
>
>
> I noticed this has been a common reported issue (e.g.,
> https://github.com/Rdatatable/data.table/issues/5658), but mainly for those
> using data.table or openMP; I use neither. The same issue was showing for
> some examples also, which I dealt with by wrapping in \dontrun{} ? not
> ideal, but seemed quickest way to avoid.
>
>
> I have tried many things to fix this:
>
>     1. Modifying the vignettes to make faster
>     2. Adding various combinations of Sys.setenv("OMP_THREAD_LIMIT" = 1),
>     Sys.setenv("OMP_NUM_THREADS" = 1), options(Ncpus = 1), options(cores = 2)
>     to the Rmd vignettes
>     3. Checked the package builds using r-lib/actions (GitHub actions) and
>     r-hub Debian platform ? I cannot reproduce this CRAN error
>
>
> CRAN will not accept the update to my package until this NOTE is squashed.
> If anyone is able to provide a recommendation on what I might do, I would
> appreciate it.
>
>
> Kind regards,
>
>
> Graeme Hickey
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From @|mon@urb@nek @end|ng |rom R-project@org  Wed Jan 15 03:59:17 2025
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Wed, 15 Jan 2025 15:59:17 +1300
Subject: [R-pkg-devel] 
 SystemRequirements & configure check for FFTW with
 single precision support
In-Reply-To: <CAHETjtZcmar26ud0s0yn9RGQXwjKtVpkT3gt+o2DGfAyR-T=qg@mail.gmail.com>
References: <CAHETjtZcmar26ud0s0yn9RGQXwjKtVpkT3gt+o2DGfAyR-T=qg@mail.gmail.com>
Message-ID: <4D3E0C0F-263C-4B48-91A6-0E9C56D70B27@R-project.org>

Lukas,

I have not seen the communication so I'm not commenting on that specifically, I only looked at the GitHub link.

Although your configure could be improved (more below), it works well enough to detect fftw3f.

Unfortunately, SystemRequirements don't have a well-defined structure, but there are two commonly used notations:

a) library name and version so in your case that would be something like
libfftw3f (>=3.3.0)

b) deb/rpm package names
libfftw3-dev (deb), fftw3-devel (rpm)

fftw is a bit of a mess, because Debian ships the single-precision static library in libfftw3-dev, but also has libfftw3-single3 which is the dynamic version of the same, while RH does not distinguish. macOS recipe names are usually included only if they are non-obvious, but that would be the case here since installing fftw recipe does not work for you, so mentioning fftw-s is probably a good idea (there are community scripts that try to extract that information from the packages so that the dependencies can be installed).

As for your configure, my main objection would be that it ignores CPPFLAGS (they are not substituted at all even though they *are* used in the tests) and doesn't use pkg-config to get the correct flags. (Also the brew part should go - it's makes unwarranted assumptions [see below] and is entirely superfluous if you use pkg-config instead.) To illustrate what I mean, you get

$ pkg-config --cflags fftw3f
-I/opt/R/x86_64/include
$ pkg-config --libs fftw3f
-L/opt/R/x86_64/lib -lfftw3f -lm

while fCWTr on GitHub only uses

  Configuration for fCWTr 0.2.9000

    cppflags:    
    cxxflags:    
    ldflags:   
    libs:     -lfftw3f    

It actually works despite that, because R will inject the other flags for you, but that will only work is fftw is installed in the same location as the other libraries used by R (which is common, but not guaranteed). I wouldn't say it is dealbreaker, but it would recommend it for robustness.

FWIW with homebrew the correct flags are obtainable from pkg-config:

$ pkg-config --libs fftw3f
-L/opt/brew/Cellar/fftw/3.3.8_1/lib -lfftw3f
$ pkg-config --cflags fftw3f
-I/opt/brew/Cellar/fftw/3.3.8_1/include

Cheers,
Simon



> On Jan 11, 2025, at 10:37 PM, Lukas Schneiderbauer <lukas.schneiderbauer at gmail.com> wrote:
> 
> Hi list,
> 
> I am working on getting a package <https://github.com/lschneiderbauer/fCWTr> to
> CRAN. It depends on the FFTW library <https://www.fftw.org/> that is built
> with single precision support. I am stuck in the submission process and I
> require your help.
> 
> Before I come to my questions, some key facts about the package:
> 
> The package has an autoconf configure script that uses (among other things,
> like OpenMP checks, etc..) AC_SEARCH_LIBS to check whether required
> functions of the library 'fftwf' exist, if yes, it adds the corresponding
> compiler/linker flags; if no, it errs with a descriptive error message.
> 
> The CRAN Windows as well as Linux build service included fftwf in their
> fftw build out of the box, and so building there was no problem, R CMD
> Check passes there. In the past, building for MacOS was more trouble, since
> its fftw package does not include a single-precision build. I reached out
> to Simon Urbanek, and he was so kind as to add an appropriate new recipe
> "fftw-s" that provided an fftw version with single precision support. As of
> now, R CMD check also passes cleanly on the MacOS build service, thanks to
> Simon Urbanek's efforts.
> 
> Now, I am stuck at submission for two reasons:
> 1. The SystemRequirements specification in the DESCRIPTION file is
> incorrect.
> 2. It is said that "the package needs a configure check for fftwf".
> 
> Add 1.
> Initially, I had no mention of the "single precision" version of fftw,
> because I thought it is included everywhere by default. It was stated that
> I need to add that information. I naturally complied.
> This is my current version:
> "SystemRequirements: fftw3 (including single precision support fftw3f),
> fftw3f_omp (optional), OpenMP (optional)"
> In the second subscription run, I was told to add "fftw-s" since I require
> the fftw-s package on MacOS. This does not make much sense to me since
> "fftw-s" is only the name of this package on Simon Urbanek's MacOS build
> service. The library file itself is still called fftwf, like it is on any
> other platform. If I added "fftw-s", I would also need to explain that this
> is only valid for MacOS which seems to make the SystemRequirements
> unnecessary verbose.
> * Can someone explain the reason behind this request to me?
> * How exactly should I add "fftw-s" to pass the submission process?
> 
> Add 2.
> I tried to explain now for the second time in the submission notes, that a
> check is already in place (see the AC_SEARCH_LIBS paragraph above). But my
> explanation gets ignored.
> * What am I doing wrong?
> * What additional configure checks do I need to add to the package?
> 
> Thanks a lot for your help!
> Sincerely, Lukas Schneiderbauer
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> 


From c|yde @end|ng |rom duke@edu  Wed Jan 15 05:26:32 2025
From: c|yde @end|ng |rom duke@edu (Merlise Clyde, Ph.D.)
Date: Wed, 15 Jan 2025 04:26:32 +0000
Subject: [R-pkg-devel] Replacement for SETLENGTH
Message-ID: <CY8PR05MB100342EF92E6E169CA1067103C8182@CY8PR05MB10034.namprd05.prod.outlook.com>

I am trying to determine the best way to eliminate the use of SETLENGTH to truncate over allocated vectors in my package BAS to eliminate the NOTES about non-API calls in anticipation of R 4.5.0.

>From WRE:  "At times it can be useful to allocate a larger initial result vector and resize it to a shorter length if that is sufficient. The functions Rf_lengthgets and Rf_xlengthgets accomplish this; they are analogous to using length(x) <- n in R. Typically these functions return a freshly allocated object, but in some cases they may re-use the supplied object." 

it looks like using 

    x = Rf_lengthgets(x, newsize);  
    SET_VECTOR_ELT(result, 0, x); 
    
before returning works to resize without a performance hit that incurs with a copy.  (will this always re-use the supplied object if newsize < old size?)

There is no mention in section 5.9.2 about the need for re-protection of the object,  but it seems to be mentioned in some packages as well as a really old thread about SET_LENGTH that looks like a  non-API MACRO to lengthgets, 

indeed if I call gc() and then rerun my test I have had some non-reproducible aborts in R Studio on my M3 Mac (caught once in R -d lldb)  

Do I need to do something more like 

PROTECT_INDEX ipx0;.
PROTECT_WITH_INDEX(x0 = allocVector(REALSXP, old_size), &ipx0);

PROTECT_INDEX ipx1;.
PROTECT_WITH_INDEX(x1 = allocVector(REALSXP, old_size), &ipx1);

# fill in values in x0 and  x1up to new_size (random) < old_size
...
REPROTECT(x0 = Rf_lengthgets(x0, new_size), ipx0);
REPROTECT(x1 = Rf_lengthgets(x1, new_size), ipx1);

SET_VECTOR_ELT(result, 0, x0);
SET_VECTOR_ELT(result, 1, x1);
...
UNPROTECT(2);   # or is this 4? 
return(result);


There is also a mention in WRE of R_PreserveObject and R_ReleaseObject -  

looking for advice if this is needed, or which approach is better/more stable to replace SETLENGTH?   (I have many many instances that need to be updated, so trying to get some clarity here before updating and running code through valgrind or other sanitizers to catch any memory issues before submitting an update to CRAN.

best,
Merlise








From |kw@|mmo @end|ng |rom gm@||@com  Wed Jan 15 07:00:02 2025
From: |kw@|mmo @end|ng |rom gm@||@com (Iris Simmons)
Date: Wed, 15 Jan 2025 01:00:02 -0500
Subject: [R-pkg-devel] Replacement for SETLENGTH
In-Reply-To: <CY8PR05MB100342EF92E6E169CA1067103C8182@CY8PR05MB10034.namprd05.prod.outlook.com>
References: <CY8PR05MB100342EF92E6E169CA1067103C8182@CY8PR05MB10034.namprd05.prod.outlook.com>
Message-ID: <CADNULg9fKRf3K6Q062D7X4rUJysO=9cWA1kFEjpSv3J-Oy0bYg@mail.gmail.com>

Hi Merlise!


Referring to here:

https://github.com/wch/r-source/blob/8ca367db0c94194f07ee7bcf4b883e9c5dc11e02/src/main/builtin.c#L832

It seems as though the object is only re-used if the new length is
equal to the old length.

If you use Rf_lengthgets, you will need to protect the return value.
The code you wrote that uses protect indexes looks correct, and the
reprotect is good because you no longer need the old object.

2 is the correct amount to unprotect. PROTECT and PROTECT_WITH_INDEX
(as far as I know) are the only functions that increase the size of
the protect stack, and so the only calls that need to be unprotected.
Typically, people define `int nprotect = 0;` at the start of their
functions, add `nprotect++;` after each PROTECT and PROTECT_WITH_INDEX
call, and add `UNPROTECT(nprotect);` immediately before each return or
function end. That makes it easier to keep track.

I typically use R_PreserveObject and R_ReleaseObject to protect
objects without a need to bind them somewhere in my package's
namespace. This would be that .onLoad() uses R_PreserveObject to
protect some objects, and .onUnload uses R_ReleaseObject to release
the protected objects. I probably would not use that for what you're
describing.


Regards,
    Iris

On Tue, Jan 14, 2025 at 11:26?PM Merlise Clyde, Ph.D. <clyde at duke.edu> wrote:
>
> I am trying to determine the best way to eliminate the use of SETLENGTH to truncate over allocated vectors in my package BAS to eliminate the NOTES about non-API calls in anticipation of R 4.5.0.
>
> From WRE:  "At times it can be useful to allocate a larger initial result vector and resize it to a shorter length if that is sufficient. The functions Rf_lengthgets and Rf_xlengthgets accomplish this; they are analogous to using length(x) <- n in R. Typically these functions return a freshly allocated object, but in some cases they may re-use the supplied object."
>
> it looks like using
>
>     x = Rf_lengthgets(x, newsize);
>     SET_VECTOR_ELT(result, 0, x);
>
> before returning works to resize without a performance hit that incurs with a copy.  (will this always re-use the supplied object if newsize < old size?)
>
> There is no mention in section 5.9.2 about the need for re-protection of the object,  but it seems to be mentioned in some packages as well as a really old thread about SET_LENGTH that looks like a  non-API MACRO to lengthgets,
>
> indeed if I call gc() and then rerun my test I have had some non-reproducible aborts in R Studio on my M3 Mac (caught once in R -d lldb)
>
> Do I need to do something more like
>
> PROTECT_INDEX ipx0;.
> PROTECT_WITH_INDEX(x0 = allocVector(REALSXP, old_size), &ipx0);
>
> PROTECT_INDEX ipx1;.
> PROTECT_WITH_INDEX(x1 = allocVector(REALSXP, old_size), &ipx1);
>
> # fill in values in x0 and  x1up to new_size (random) < old_size
> ...
> REPROTECT(x0 = Rf_lengthgets(x0, new_size), ipx0);
> REPROTECT(x1 = Rf_lengthgets(x1, new_size), ipx1);
>
> SET_VECTOR_ELT(result, 0, x0);
> SET_VECTOR_ELT(result, 1, x1);
> ...
> UNPROTECT(2);   # or is this 4?
> return(result);
>
>
> There is also a mention in WRE of R_PreserveObject and R_ReleaseObject -
>
> looking for advice if this is needed, or which approach is better/more stable to replace SETLENGTH?   (I have many many instances that need to be updated, so trying to get some clarity here before updating and running code through valgrind or other sanitizers to catch any memory issues before submitting an update to CRAN.
>
> best,
> Merlise
>
>
>
>
>
>
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Wed Jan 15 09:58:11 2025
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Wed, 15 Jan 2025 09:58:11 +0100
Subject: [R-pkg-devel] Replacement for SETLENGTH
In-Reply-To: <CY8PR05MB100342EF92E6E169CA1067103C8182@CY8PR05MB10034.namprd05.prod.outlook.com>
References: <CY8PR05MB100342EF92E6E169CA1067103C8182@CY8PR05MB10034.namprd05.prod.outlook.com>
Message-ID: <0be66c5f-1fc1-448e-82b7-90ac17321af9@gmail.com>


On 1/15/25 05:26, Merlise Clyde, Ph.D. wrote:
> I am trying to determine the best way to eliminate the use of SETLENGTH to truncate over allocated vectors in my package BAS to eliminate the NOTES about non-API calls in anticipation of R 4.5.0.
>
>  From WRE:  "At times it can be useful to allocate a larger initial result vector and resize it to a shorter length if that is sufficient. The functions Rf_lengthgets and Rf_xlengthgets accomplish this; they are analogous to using length(x) <- n in R. Typically these functions return a freshly allocated object, but in some cases they may re-use the supplied object."
>
> it looks like using
>
>      x = Rf_lengthgets(x, newsize);
>      SET_VECTOR_ELT(result, 0, x);
>      
> before returning works to resize without a performance hit that incurs with a copy.  (will this always re-use the supplied object if newsize < old size?)
>
> There is no mention in section 5.9.2 about the need for re-protection of the object,  but it seems to be mentioned in some packages as well as a really old thread about SET_LENGTH that looks like a  non-API MACRO to lengthgets,
>
> indeed if I call gc() and then rerun my test I have had some non-reproducible aborts in R Studio on my M3 Mac (caught once in R -d lldb)

The important part for protection is that Rf_lengthgets _may_ return a 
freshly allocated object. This means that the object needs protection 
from garbage collection, implicit or explicit - and that is covered in 
section "Handling the effects of garbage collection".? There are? many 
functions in the? R API that return freshly allocated objects, so don't 
expect that documentation of every such function would give advice on 
how to protect, that is covered in that special section.

So, you are right, some protection is needed _if_ the return value of 
Rf_lengthgets may be exposed to gc().

>
> Do I need to do something more like
>
> PROTECT_INDEX ipx0;.
> PROTECT_WITH_INDEX(x0 = allocVector(REALSXP, old_size), &ipx0);
>
> PROTECT_INDEX ipx1;.
> PROTECT_WITH_INDEX(x1 = allocVector(REALSXP, old_size), &ipx1);
>
> # fill in values in x0 and  x1up to new_size (random) < old_size
> ...
> REPROTECT(x0 = Rf_lengthgets(x0, new_size), ipx0);
> REPROTECT(x1 = Rf_lengthgets(x1, new_size), ipx1);
>
> SET_VECTOR_ELT(result, 0, x0);
> SET_VECTOR_ELT(result, 1, x1);
> ...
> UNPROTECT(2);   # or is this 4?

You have protected two objects here, one was in x0 and one in x1 
(REPROTECT doesn't change the depth of the protection stack). Some 
people put that into a comment:

UNPROTECT(2); /* x1, x0 */

The code above is ok. In some cases, you can shuffle it around a bit or 
rely on implicit protection if you want to reduce the need for explicit 
protection. But perfomance-wise it doesn't matter given code that is 
allocating, etc, that takes much more time - it is more about readability.

For instance,

result = PROTECT(allocVector(...))
x0 = allocVector()
SET_VECTOR_ELT(result, 0, x0);
// now x0 is implicitly protected via result
...

x0 = Rf_lengthgets(..)
SET_VECTOR_ELT(result, 0, x0);
/// now the new value of x0 is implicitly protected via result (the old 
value may not be)

UNPROTECT(1)? // result
return result

> return(result);
>
>
> There is also a mention in WRE of R_PreserveObject and R_ReleaseObject -
>
> looking for advice if this is needed, or which approach is better/more stable to replace SETLENGTH?   (I have many many instances that need to be updated, so trying to get some clarity here before updating and running code through valgrind or other sanitizers to catch any memory issues before submitting an update to CRAN.

PreserveObject/ReleaseObject is good e.g. for global structures, 
probably not in this case. The difficulty there is making sure 
ReleaseObject() does execute in case of error, a non-local return. On 
the other hand, protection via PROTECT/UNPROTECT is automatically robust 
to non-local returns (automatic unprotection).

There is nothing specific about Rf_lengthgets wrt to protection here - 
the same rules apply to any other R API function that returns an SEXP.

For finding protection bugs in code, one can use an R build with barrier 
checking enabled and gctorture or rchk tool. Some bugs may lead to 
crashes or incorrect outputs even in normaln builds. Some bugs may be 
found by UBSAN. But none of this is a verification tool, one can only 
find some bugs in some cases, correctness remains the responsibility of 
the programmer.

Best
Tomas

>
> best,
> Merlise
>
>
>
>
>
>
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From c|yde @end|ng |rom duke@edu  Wed Jan 15 16:30:36 2025
From: c|yde @end|ng |rom duke@edu (Merlise Clyde, Ph.D.)
Date: Wed, 15 Jan 2025 15:30:36 +0000
Subject: [R-pkg-devel] Replacement for SETLENGTH
In-Reply-To: <CADNULg9fKRf3K6Q062D7X4rUJysO=9cWA1kFEjpSv3J-Oy0bYg@mail.gmail.com>
References: <CY8PR05MB100342EF92E6E169CA1067103C8182@CY8PR05MB10034.namprd05.prod.outlook.com>
 <CADNULg9fKRf3K6Q062D7X4rUJysO=9cWA1kFEjpSv3J-Oy0bYg@mail.gmail.com>
Message-ID: <CY8PR05MB10034614E651AB601A74968AFC8192@CY8PR05MB10034.namprd05.prod.outlook.com>

Thanks for the added explanation Iris and Tomas!

So looking at the code for xlengthgets, it does appear that I may take a memory hit for multiple large objects due to the second allocation before the old objects are possibly garbage collected.     There are about 12 such instances per function that are returned (I do use a counter for keeping track of the number of PROTECTED and to UNPROTECT for bookkeeping :-).   For memory limited machines, the alloc/copy was a problem for memory usage - and if I recall was one of the reasons in 2008 I switched to SETLENGTH, which doesn't seem to do an allocation ???  If there is going to be an absolute ban on SETLENGTH  in packages I'll probably need to address memory management differently for those cases.

I did see a note before the function def'n of xlengthgets:

/* (if it is vectorizable). We could probably be fairly */
/* clever with memory here if we wanted to. */

It would seem that memcpy would be more efficient for at least some of the types  (REALSPX, INTSPX) unless I am missing something - but any way to be more clever with VECSPX ?

best,
Merlise



Merlise Clyde (she/her/hers)
Professor of Statistical Science and Director of Graduate Studies
Duke University

________________________________________
From:?Iris Simmons <ikwsimmo at gmail.com>
Sent:?Wednesday, January 15, 2025 1:00 AM
To:?Merlise Clyde, Ph.D. <clyde at duke.edu>
Cc:?r-package-devel at r-project.org <r-package-devel at r-project.org>
Subject:?Re: [R-pkg-devel] Replacement for SETLENGTH
?
Hi Merlise!


Referring to here:

https://github.com/wch/r-source/blob/bb5a829466f77a3e1d03541747d149d65e900f2b/src/main/builtin.c#L834

It seems as though the object is only re-used if the new length is
equal to the old length.

If you use Rf_lengthgets, you will need to protect the return value.
The code you wrote that uses protect indexes looks correct, and the
reprotect is good because you no longer need the old object.

2 is the correct amount to unprotect. PROTECT and PROTECT_WITH_INDEX
(as far as I know) are the only functions that increase the size of
the protect stack, and so the only calls that need to be unprotected.
Typically, people define `int nprotect = 0;` at the start of their
functions, add `nprotect++;` after each PROTECT and PROTECT_WITH_INDEX
call, and add `UNPROTECT(nprotect);` immediately before each return or
function end. That makes it easier to keep track.

I typically use R_PreserveObject and R_ReleaseObject to protect
objects without a need to bind them somewhere in my package's
namespace. This would be that .onLoad() uses R_PreserveObject to
protect some objects, and .onUnload uses R_ReleaseObject to release
the protected objects. I probably would not use that for what you're
describing.


Regards,
??? Iris

On Tue, Jan 14, 2025 at 11:26?PM Merlise Clyde, Ph.D. <clyde at duke.edu> wrote:
>
> I am trying to determine the best way to eliminate the use of SETLENGTH to truncate over allocated vectors in my package BAS to eliminate the NOTES about non-API calls in anticipation of R 4.5.0.
>
> From WRE:? "At times it can be useful to allocate a larger initial result vector and resize it to a shorter length if that is sufficient. The functions Rf_lengthgets and Rf_xlengthgets accomplish this; they are analogous to using length(x) <- n in R. Typically these functions return a freshly allocated object, but in some cases they may re-use the supplied object."
>
> it looks like using
>
>???? x = Rf_lengthgets(x, newsize);
>???? SET_VECTOR_ELT(result, 0, x);
>
> before returning works to resize without a performance hit that incurs with a copy.? (will this always re-use the supplied object if newsize < old size?)
>
> There is no mention in section 5.9.2 about the need for re-protection of the object,? but it seems to be mentioned in some packages as well as a really old thread about SET_LENGTH that looks like a? non-API MACRO to lengthgets,
>
> indeed if I call gc() and then rerun my test I have had some non-reproducible aborts in R Studio on my M3 Mac (caught once in R -d lldb)
>
> Do I need to do something more like
>
> PROTECT_INDEX ipx0;.
> PROTECT_WITH_INDEX(x0 = allocVector(REALSXP, old_size), &ipx0);
>
> PROTECT_INDEX ipx1;.
> PROTECT_WITH_INDEX(x1 = allocVector(REALSXP, old_size), &ipx1);
>
> # fill in values in x0 and? x1up to new_size (random) < old_size
> ...
> REPROTECT(x0 = Rf_lengthgets(x0, new_size), ipx0);
> REPROTECT(x1 = Rf_lengthgets(x1, new_size), ipx1);
>
> SET_VECTOR_ELT(result, 0, x0);
> SET_VECTOR_ELT(result, 1, x1);
> ...
> UNPROTECT(2);?? # or is this 4?
> return(result);
>
>
> There is also a mention in WRE of R_PreserveObject and R_ReleaseObject -
>
> looking for advice if this is needed, or which approach is better/more stable to replace SETLENGTH??? (I have many many instances that need to be updated, so trying to get some clarity here before updating and running code through valgrind or other sanitizers to catch any memory issues before submitting an update to CRAN.
>
> best,
> Merlise
>
>
>
>
>
>
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-package-devel__;!!OToaGQ!ohDoxcAn5uIC25d42XhBz8Kd4YftOJDBoEW1NK9FOmgZpcmv0XIy5fQRm24-s_D8m9O_lR6jo6FcKiA$

From |kw@|mmo @end|ng |rom gm@||@com  Wed Jan 15 16:51:28 2025
From: |kw@|mmo @end|ng |rom gm@||@com (Iris Simmons)
Date: Wed, 15 Jan 2025 10:51:28 -0500
Subject: [R-pkg-devel] Replacement for SETLENGTH
In-Reply-To: <CY8PR05MB10034614E651AB601A74968AFC8192@CY8PR05MB10034.namprd05.prod.outlook.com>
References: <CY8PR05MB100342EF92E6E169CA1067103C8182@CY8PR05MB10034.namprd05.prod.outlook.com>
 <CADNULg9fKRf3K6Q062D7X4rUJysO=9cWA1kFEjpSv3J-Oy0bYg@mail.gmail.com>
 <CY8PR05MB10034614E651AB601A74968AFC8192@CY8PR05MB10034.namprd05.prod.outlook.com>
Message-ID: <CADNULg-ws6Atf6s-=TrHAHhXE=NDt+ij8+s9j5YUhV9KsA7Ggw@mail.gmail.com>

I don't think memcpy works well for VECSXP. The elements being overwritten
need to have their reference counts decreased and the new elements need to
have theirs increased.

Also, I don't entirely know how accurate everything I'm about to say is,
but I think you need to be using SET_TRUELENGTH and SET_GROWABLE_BIT along
with SETLENGTH. There's an example here:

https://github.com/wch/r-source/blob/744b5d34e1b8eb839e5d49d91ab21c1fe6800856/src/main/subassign.c#L257


The example uses SET_STDVEC_LENGTH which shouldn't be used, just replace it
with SETLENGTH.

So in your code, I'd replace:

SETLENGTH(modelspace, nUnique);

with

SET_GROWABLE_BIT(modelspace);
SET_TRUELENGTH(modelspace, nModels);
SETLENGTH(modelspace, nUnique);

On Wed, Jan 15, 2025, 10:30 Merlise Clyde, Ph.D. <clyde at duke.edu> wrote:

> Thanks for the added explanation Iris and Tomas!
>
> So looking at the code for xlengthgets, it does appear that I may take a
> memory hit for multiple large objects due to the second allocation before
> the old objects are possibly garbage collected.     There are about 12 such
> instances per function that are returned (I do use a counter for keeping
> track of the number of PROTECTED and to UNPROTECT for bookkeeping :-).
>  For memory limited machines, the alloc/copy was a problem for memory usage
> - and if I recall was one of the reasons in 2008 I switched to SETLENGTH,
> which doesn't seem to do an allocation ???  If there is going to be an
> absolute ban on SETLENGTH  in packages I'll probably need to address memory
> management differently for those cases.
>
> I did see a note before the function def'n of xlengthgets:
>
> /* (if it is vectorizable). We could probably be fairly */
> /* clever with memory here if we wanted to. */
>
> It would seem that memcpy would be more efficient for at least some of the
> types  (REALSPX, INTSPX) unless I am missing something - but any way to be
> more clever with VECSPX ?
>
> best,
> Merlise
>
>
>
> Merlise Clyde (she/her/hers)
> Professor of Statistical Science and Director of Graduate Studies
> Duke University
>
> ________________________________________
> From: Iris Simmons <ikwsimmo at gmail.com>
> Sent: Wednesday, January 15, 2025 1:00 AM
> To: Merlise Clyde, Ph.D. <clyde at duke.edu>
> Cc: r-package-devel at r-project.org <r-package-devel at r-project.org>
> Subject: Re: [R-pkg-devel] Replacement for SETLENGTH
>
> Hi Merlise!
>
>
> Referring to here:
>
>
> https://github.com/wch/r-source/blob/bb5a829466f77a3e1d03541747d149d65e900f2b/src/main/builtin.c#L834
>
> It seems as though the object is only re-used if the new length is
> equal to the old length.
>
> If you use Rf_lengthgets, you will need to protect the return value.
> The code you wrote that uses protect indexes looks correct, and the
> reprotect is good because you no longer need the old object.
>
> 2 is the correct amount to unprotect. PROTECT and PROTECT_WITH_INDEX
> (as far as I know) are the only functions that increase the size of
> the protect stack, and so the only calls that need to be unprotected.
> Typically, people define `int nprotect = 0;` at the start of their
> functions, add `nprotect++;` after each PROTECT and PROTECT_WITH_INDEX
> call, and add `UNPROTECT(nprotect);` immediately before each return or
> function end. That makes it easier to keep track.
>
> I typically use R_PreserveObject and R_ReleaseObject to protect
> objects without a need to bind them somewhere in my package's
> namespace. This would be that .onLoad() uses R_PreserveObject to
> protect some objects, and .onUnload uses R_ReleaseObject to release
> the protected objects. I probably would not use that for what you're
> describing.
>
>
> Regards,
>     Iris
>
> On Tue, Jan 14, 2025 at 11:26?PM Merlise Clyde, Ph.D. <clyde at duke.edu>
> wrote:
> >
> > I am trying to determine the best way to eliminate the use of SETLENGTH
> to truncate over allocated vectors in my package BAS to eliminate the NOTES
> about non-API calls in anticipation of R 4.5.0.
> >
> > From WRE:  "At times it can be useful to allocate a larger initial
> result vector and resize it to a shorter length if that is sufficient. The
> functions Rf_lengthgets and Rf_xlengthgets accomplish this; they are
> analogous to using length(x) <- n in R. Typically these functions return a
> freshly allocated object, but in some cases they may re-use the supplied
> object."
> >
> > it looks like using
> >
> >     x = Rf_lengthgets(x, newsize);
> >     SET_VECTOR_ELT(result, 0, x);
> >
> > before returning works to resize without a performance hit that incurs
> with a copy.  (will this always re-use the supplied object if newsize < old
> size?)
> >
> > There is no mention in section 5.9.2 about the need for re-protection of
> the object,  but it seems to be mentioned in some packages as well as a
> really old thread about SET_LENGTH that looks like a  non-API MACRO to
> lengthgets,
> >
> > indeed if I call gc() and then rerun my test I have had some
> non-reproducible aborts in R Studio on my M3 Mac (caught once in R -d lldb)
> >
> > Do I need to do something more like
> >
> > PROTECT_INDEX ipx0;.
> > PROTECT_WITH_INDEX(x0 = allocVector(REALSXP, old_size), &ipx0);
> >
> > PROTECT_INDEX ipx1;.
> > PROTECT_WITH_INDEX(x1 = allocVector(REALSXP, old_size), &ipx1);
> >
> > # fill in values in x0 and  x1up to new_size (random) < old_size
> > ...
> > REPROTECT(x0 = Rf_lengthgets(x0, new_size), ipx0);
> > REPROTECT(x1 = Rf_lengthgets(x1, new_size), ipx1);
> >
> > SET_VECTOR_ELT(result, 0, x0);
> > SET_VECTOR_ELT(result, 1, x1);
> > ...
> > UNPROTECT(2);   # or is this 4?
> > return(result);
> >
> >
> > There is also a mention in WRE of R_PreserveObject and R_ReleaseObject -
> >
> > looking for advice if this is needed, or which approach is better/more
> stable to replace SETLENGTH?   (I have many many instances that need to be
> updated, so trying to get some clarity here before updating and running
> code through valgrind or other sanitizers to catch any memory issues before
> submitting an update to CRAN.
> >
> > best,
> > Merlise
> >
> >
> >
> >
> >
> >
> >
> > ______________________________________________
> > R-package-devel at r-project.org mailing list
> >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-package-devel__;!!OToaGQ!ohDoxcAn5uIC25d42XhBz8Kd4YftOJDBoEW1NK9FOmgZpcmv0XIy5fQRm24-s_D8m9O_lR6jo6FcKiA$

	[[alternative HTML version deleted]]


From iuke-tier@ey m@iii@g oii uiow@@edu  Wed Jan 15 18:34:20 2025
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Wed, 15 Jan 2025 11:34:20 -0600 (CST)
Subject: [R-pkg-devel] [External] Re:  Replacement for SETLENGTH
In-Reply-To: <CADNULg-ws6Atf6s-=TrHAHhXE=NDt+ij8+s9j5YUhV9KsA7Ggw@mail.gmail.com>
References: <CY8PR05MB100342EF92E6E169CA1067103C8182@CY8PR05MB10034.namprd05.prod.outlook.com>
 <CADNULg9fKRf3K6Q062D7X4rUJysO=9cWA1kFEjpSv3J-Oy0bYg@mail.gmail.com>
 <CY8PR05MB10034614E651AB601A74968AFC8192@CY8PR05MB10034.namprd05.prod.outlook.com>
 <CADNULg-ws6Atf6s-=TrHAHhXE=NDt+ij8+s9j5YUhV9KsA7Ggw@mail.gmail.com>
Message-ID: <a424ea59-f51e-a0c9-9887-799d66b50e4@uiowa.edu>

On Wed, 15 Jan 2025, Iris Simmons wrote:

> I don't think memcpy works well for VECSXP. The elements being overwritten
> need to have their reference counts decreased and the new elements need to
> have theirs increased.

You do not want to use memcpy or inanyother way try to write to the
locations in a VECSXP. It is not jus the reference counts but also the
integrity of the GC write barrier that you would be damaging.

>
> Also, I don't entirely know how accurate everything I'm about to say is,
> but I think you need to be using SET_TRUELENGTH and SET_GROWABLE_BIT along
> with SETLENGTH. There's an example here:
>
> https://github.com/wch/r-source/blob/744b5d34e1b8eb839e5d49d91ab21c1fe6800856/src/main/subassign.c#L257
>
>
> The example uses SET_STDVEC_LENGTH which shouldn't be used, just replace it
> with SETLENGTH.
>
> So in your code, I'd replace:
>
> SETLENGTH(modelspace, nUnique);
>
> with
>
> SET_GROWABLE_BIT(modelspace);
> SET_TRUELENGTH(modelspace, nModels);
> SETLENGTH(modelspace, nUnique);

These are not part of the API.

Support for growable vectors maybe added to the API in the future, but
probably with a more robust interface.

In any case, this mechanism is intended for growing, not shrinking,
vectors.

Initially over-allocating and returning a smaller result is a
reasonable strategy, but the right way to do it is to allocate a new
shorter result. xlengthgets is a convenient way to do this. Tholonger
vector will be subject to garbage collecion once there are no
remaining references to it.

Attempting to keep alive a longer allocation but pretending it is
shorter is mis-guided: it would keep alive a larger object than is
needed and so waste memory.

Best,

luke

> On Wed, Jan 15, 2025, 10:30 Merlise Clyde, Ph.D. <clyde at duke.edu> wrote:
>
>> Thanks for the added explanation Iris and Tomas!
>>
>> So looking at the code for xlengthgets, it does appear that I may take a
>> memory hit for multiple large objects due to the second allocation before
>> the old objects are possibly garbage collected.     There are about 12 such
>> instances per function that are returned (I do use a counter for keeping
>> track of the number of PROTECTED and to UNPROTECT for bookkeeping :-).
>>  For memory limited machines, the alloc/copy was a problem for memory usage
>> - and if I recall was one of the reasons in 2008 I switched to SETLENGTH,
>> which doesn't seem to do an allocation ???  If there is going to be an
>> absolute ban on SETLENGTH  in packages I'll probably need to address memory
>> management differently for those cases.
>>
>> I did see a note before the function def'n of xlengthgets:
>>
>> /* (if it is vectorizable). We could probably be fairly */
>> /* clever with memory here if we wanted to. */
>>
>> It would seem that memcpy would be more efficient for at least some of the
>> types  (REALSPX, INTSPX) unless I am missing something - but any way to be
>> more clever with VECSPX ?
>>
>> best,
>> Merlise
>>
>>
>>
>> Merlise Clyde (she/her/hers)
>> Professor of Statistical Science and Director of Graduate Studies
>> Duke University
>>
>> ________________________________________
>> From: Iris Simmons <ikwsimmo at gmail.com>
>> Sent: Wednesday, January 15, 2025 1:00 AM
>> To: Merlise Clyde, Ph.D. <clyde at duke.edu>
>> Cc: r-package-devel at r-project.org <r-package-devel at r-project.org>
>> Subject: Re: [R-pkg-devel] Replacement for SETLENGTH
>>
>> Hi Merlise!
>>
>>
>> Referring to here:
>>
>>
>> https://github.com/wch/r-source/blob/bb5a829466f77a3e1d03541747d149d65e900f2b/src/main/builtin.c#L834
>>
>> It seems as though the object is only re-used if the new length is
>> equal to the old length.
>>
>> If you use Rf_lengthgets, you will need to protect the return value.
>> The code you wrote that uses protect indexes looks correct, and the
>> reprotect is good because you no longer need the old object.
>>
>> 2 is the correct amount to unprotect. PROTECT and PROTECT_WITH_INDEX
>> (as far as I know) are the only functions that increase the size of
>> the protect stack, and so the only calls that need to be unprotected.
>> Typically, people define `int nprotect = 0;` at the start of their
>> functions, add `nprotect++;` after each PROTECT and PROTECT_WITH_INDEX
>> call, and add `UNPROTECT(nprotect);` immediately before each return or
>> function end. That makes it easier to keep track.
>>
>> I typically use R_PreserveObject and R_ReleaseObject to protect
>> objects without a need to bind them somewhere in my package's
>> namespace. This would be that .onLoad() uses R_PreserveObject to
>> protect some objects, and .onUnload uses R_ReleaseObject to release
>> the protected objects. I probably would not use that for what you're
>> describing.
>>
>>
>> Regards,
>>     Iris
>>
>> On Tue, Jan 14, 2025 at 11:26?PM Merlise Clyde, Ph.D. <clyde at duke.edu>
>> wrote:
>>>
>>> I am trying to determine the best way to eliminate the use of SETLENGTH
>> to truncate over allocated vectors in my package BAS to eliminate the NOTES
>> about non-API calls in anticipation of R 4.5.0.
>>>
>>> From WRE:  "At times it can be useful to allocate a larger initial
>> result vector and resize it to a shorter length if that is sufficient. The
>> functions Rf_lengthgets and Rf_xlengthgets accomplish this; they are
>> analogous to using length(x) <- n in R. Typically these functions return a
>> freshly allocated object, but in some cases they may re-use the supplied
>> object."
>>>
>>> it looks like using
>>>
>>>     x = Rf_lengthgets(x, newsize);
>>>     SET_VECTOR_ELT(result, 0, x);
>>>
>>> before returning works to resize without a performance hit that incurs
>> with a copy.  (will this always re-use the supplied object if newsize < old
>> size?)
>>>
>>> There is no mention in section 5.9.2 about the need for re-protection of
>> the object,  but it seems to be mentioned in some packages as well as a
>> really old thread about SET_LENGTH that looks like a  non-API MACRO to
>> lengthgets,
>>>
>>> indeed if I call gc() and then rerun my test I have had some
>> non-reproducible aborts in R Studio on my M3 Mac (caught once in R -d lldb)
>>>
>>> Do I need to do something more like
>>>
>>> PROTECT_INDEX ipx0;.
>>> PROTECT_WITH_INDEX(x0 = allocVector(REALSXP, old_size), &ipx0);
>>>
>>> PROTECT_INDEX ipx1;.
>>> PROTECT_WITH_INDEX(x1 = allocVector(REALSXP, old_size), &ipx1);
>>>
>>> # fill in values in x0 and  x1up to new_size (random) < old_size
>>> ...
>>> REPROTECT(x0 = Rf_lengthgets(x0, new_size), ipx0);
>>> REPROTECT(x1 = Rf_lengthgets(x1, new_size), ipx1);
>>>
>>> SET_VECTOR_ELT(result, 0, x0);
>>> SET_VECTOR_ELT(result, 1, x1);
>>> ...
>>> UNPROTECT(2);   # or is this 4?
>>> return(result);
>>>
>>>
>>> There is also a mention in WRE of R_PreserveObject and R_ReleaseObject -
>>>
>>> looking for advice if this is needed, or which approach is better/more
>> stable to replace SETLENGTH?   (I have many many instances that need to be
>> updated, so trying to get some clarity here before updating and running
>> code through valgrind or other sanitizers to catch any memory issues before
>> submitting an update to CRAN.
>>>
>>> best,
>>> Merlise
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> ______________________________________________
>>> R-package-devel at r-project.org mailing list
>>>
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-package-devel__;!!OToaGQ!ohDoxcAn5uIC25d42XhBz8Kd4YftOJDBoEW1NK9FOmgZpcmv0XIy5fQRm24-s_D8m9O_lR6jo6FcKiA$
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu/

From |kry|ov @end|ng |rom d|@root@org  Wed Jan 15 21:13:00 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 15 Jan 2025 23:13:00 +0300
Subject: [R-pkg-devel] Replacement for SETLENGTH
In-Reply-To: <CY8PR05MB10034614E651AB601A74968AFC8192@CY8PR05MB10034.namprd05.prod.outlook.com>
References: <CY8PR05MB100342EF92E6E169CA1067103C8182@CY8PR05MB10034.namprd05.prod.outlook.com>
 <CADNULg9fKRf3K6Q062D7X4rUJysO=9cWA1kFEjpSv3J-Oy0bYg@mail.gmail.com>
 <CY8PR05MB10034614E651AB601A74968AFC8192@CY8PR05MB10034.namprd05.prod.outlook.com>
Message-ID: <20250115231300.2b5ba55b@Tarkus>

On Wed, 15 Jan 2025 15:30:36 +0000
"Merlise Clyde, Ph.D." <clyde at duke.edu> wrote:

> For memory limited machines, the alloc/copy was a problem for memory
> usage - and if I recall was one of the reasons in 2008 I switched to
> SETLENGTH, which doesn't seem to do an allocation ???  If there is
> going to be an absolute ban on SETLENGTH  in packages I'll probably
> need to address memory management differently for those cases.

If you need to adjust the xlength() of your vectors without causing
reallocations, I'm afraid the only API-compliant way to do that for now
is ALTREP [1]. It's a lot of typing because the code will need to
register an ALTREP class for every vector type that needs to be
shrinkable. Moreover, since some of those vectors are of type VECSXP
and "altlist" classes only appeared in R-4.3.0, you will probably
prefer to leave the old implementation based on SETLENGTH() behind #if
R_VERSION < R_Version(4, 3, 0) to avoid requiring your users to upgrade
from R >= 3.0.

A work-in-progress implementation of shrinkable vectors for data.table
can be found at [2]. The real problem is not implementing the same
simple API using SETLENGTH() and ALTREP, but in refactoring the rest of
the code not to violate its assumptions. (Total control over the
allocation of your shrinkable vectors is required: nothing good will
happen if the code tries to call ALTREP methods on an object that is
not of the exact ALTREP class it needs to be.)

My own notes on the use of ALTREP can be found at [3]. I will do my
best to keep them correct, but patches are always welcome.

And now a question:

Would R benefit from a patch to make xlengthgets() more like
EnlargeVector() [4] and sometimes return vectors with GROWABLE_BIT set?
(EnlargeVector() is currently only reachable from the `[<-` operation.)
It wouldn't be a deviation from the currently documented behaviour if
the function tested for NO_REFERENCES() and then used SETLENGTH() when,
say, reducing the length of a vector to 1/2 of its length or more.

-- 
Best regards,
Ivan

[1]
https://rdatatable-community.github.io/The-Raft/posts/2025-01-13-non-api-use/index.html#growable-vectors

[2]
https://github.com/Rdatatable/data.table/blob/growable_refactor/src/growable.c
Everyone is welcome to use this under the terms of GPL-2 or a later
version, or MPL-2, at their choice.

[3]
https://aitap.codeberg.page/R-api/#ALTREP

[4]
https://github.com/r-devel/r-svn/blob/59df414b844eea27c09b352ad30fd82e66764d2d/src/main/subassign.c#L256-L260


From c|yde @end|ng |rom duke@edu  Wed Jan 15 21:53:19 2025
From: c|yde @end|ng |rom duke@edu (Merlise Clyde, Ph.D.)
Date: Wed, 15 Jan 2025 20:53:19 +0000
Subject: [R-pkg-devel] [External] Re:  Replacement for SETLENGTH
In-Reply-To: <a424ea59-f51e-a0c9-9887-799d66b50e4@uiowa.edu>
References: <CY8PR05MB100342EF92E6E169CA1067103C8182@CY8PR05MB10034.namprd05.prod.outlook.com>
 <CADNULg9fKRf3K6Q062D7X4rUJysO=9cWA1kFEjpSv3J-Oy0bYg@mail.gmail.com>
 <CY8PR05MB10034614E651AB601A74968AFC8192@CY8PR05MB10034.namprd05.prod.outlook.com>
 <CADNULg-ws6Atf6s-=TrHAHhXE=NDt+ij8+s9j5YUhV9KsA7Ggw@mail.gmail.com>
 <a424ea59-f51e-a0c9-9887-799d66b50e4@uiowa.edu>
Message-ID: <CY8PR05MB100349ABE1DB2CE78F0D79F06C8192@CY8PR05MB10034.namprd05.prod.outlook.com>


Thanks Luke !   I had seen the usage and discussion of growable vectors, as well as using SET_TRUELENGTH with SETLENGTH and didn't necessarily want to get even more out of API compliance :-). but if that looks like it will allowed (subject to perhaps changes) that seems like the better way forward to handle the different SEXPs.    And switching to smaller vectors and enlarging would be much more efficient in terms of memory.    I'll need to play around with how much to expand by as the enlargement would need to be in the loop with a final resizing before returning.

So if I understand the suggestion the use of xlengthgets basically handles the body of the code in EnlargeVector function  for allocation and copying (but now smaller vectors) with then the extra step to SETLENGTH and SET_TRUELENGTH
If done within a loop over MCMC iterations, then I would need to use SET_GROWABLE_BIT before the loop or when I encounter the need to enlarge.   (so basically a local implementation of EnlargeVector)

For my non-VECSXP objects (REALSXP, INTSXP)  it might be more efficient to use Realloc on a working array within loops and only allocate and assign after determining the final length (nUnique), and freeing the memory myself...  That way I avoid SETLENGTH altogether for those types.

best,
Merlise



Merlise Clyde (she/her/hers)
Professor of Statistical Science and Director of Graduate Studies
Duke University


________________________________________
From:?luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
Sent:?Wednesday, January 15, 2025 12:34 PM
To:?Iris Simmons <ikwsimmo at gmail.com>
Cc:?Merlise Clyde, Ph.D. <clyde at duke.edu>; List r-package-devel <r-package-devel at r-project.org>
Subject:?Re: [External] Re: [R-pkg-devel] Replacement for SETLENGTH
?
On Wed, 15 Jan 2025, Iris Simmons wrote:

> I don't think memcpy works well for VECSXP. The elements being overwritten
> need to have their reference counts decreased and the new elements need to
> have theirs increased.

You do not want to use memcpy or inanyother way try to write to the
locations in a VECSXP. It is not jus the reference counts but also the
integrity of the GC write barrier that you would be damaging.

>
> Also, I don't entirely know how accurate everything I'm about to say is,
> but I think you need to be using SET_TRUELENGTH and SET_GROWABLE_BIT along
> with SETLENGTH. There's an example here:
>
> https://urldefense.com/v3/__https://github.com/wch/r-source/blob/744b5d34e1b8eb839e5d49d91ab21c1fe6800856/src/main/subassign.c*L257__;Iw!!OToaGQ!uACtQIEun1eC8hwn-FzFogXQoPl1wETg9EUSV1NzAif9u15KlRTctzEq1RSA5rcbeVGv0n3geb8UexFngaonYos$
>
>
> The example uses SET_STDVEC_LENGTH which shouldn't be used, just replace it
> with SETLENGTH.
>
> So in your code, I'd replace:
>
> SETLENGTH(modelspace, nUnique);
>
> with
>
> SET_GROWABLE_BIT(modelspace);
> SET_TRUELENGTH(modelspace, nModels);
> SETLENGTH(modelspace, nUnique);

These are not part of the API.

Support for growable vectors maybe added to the API in the future, but
probably with a more robust interface.

In any case, this mechanism is intended for growing, not shrinking,
vectors.

Initially over-allocating and returning a smaller result is a
reasonable strategy, but the right way to do it is to allocate a new
shorter result. xlengthgets is a convenient way to do this. Tholonger
vector will be subject to garbage collecion once there are no
remaining references to it.

Attempting to keep alive a longer allocation but pretending it is
shorter is mis-guided: it would keep alive a larger object than is
needed and so waste memory.

Best,

luke

> On Wed, Jan 15, 2025, 10:30 Merlise Clyde, Ph.D. <clyde at duke.edu> wrote:
>
>> Thanks for the added explanation Iris and Tomas!
>>
>> So looking at the code for xlengthgets, it does appear that I may take a
>> memory hit for multiple large objects due to the second allocation before
>> the old objects are possibly garbage collected.???? There are about 12 such
>> instances per function that are returned (I do use a counter for keeping
>> track of the number of PROTECTED and to UNPROTECT for bookkeeping :-).
>>? For memory limited machines, the alloc/copy was a problem for memory usage
>> - and if I recall was one of the reasons in 2008 I switched to SETLENGTH,
>> which doesn't seem to do an allocation ???? If there is going to be an
>> absolute ban on SETLENGTH? in packages I'll probably need to address memory
>> management differently for those cases.
>>
>> I did see a note before the function def'n of xlengthgets:
>>
>> /* (if it is vectorizable). We could probably be fairly */
>> /* clever with memory here if we wanted to. */
>>
>> It would seem that memcpy would be more efficient for at least some of the
>> types? (REALSPX, INTSPX) unless I am missing something - but any way to be
>> more clever with VECSPX ?
>>
>> best,
>> Merlise
>>
>>
>>
>> Merlise Clyde (she/her/hers)
>> Professor of Statistical Science and Director of Graduate Studies
>> Duke University
>>
>> ________________________________________
>> From: Iris Simmons <ikwsimmo at gmail.com>
>> Sent: Wednesday, January 15, 2025 1:00 AM
>> To: Merlise Clyde, Ph.D. <clyde at duke.edu>
>> Cc: r-package-devel at r-project.org <r-package-devel at r-project.org>
>> Subject: Re: [R-pkg-devel] Replacement for SETLENGTH
>>
>> Hi Merlise!
>>
>>
>> Referring to here:
>>
>>
>> https://urldefense.com/v3/__https://github.com/wch/r-source/blob/bb5a829466f77a3e1d03541747d149d65e900f2b/src/main/builtin.c*L834__;Iw!!OToaGQ!uACtQIEun1eC8hwn-FzFogXQoPl1wETg9EUSV1NzAif9u15KlRTctzEq1RSA5rcbeVGv0n3geb8UexFnr_0lCLM$
>>
>> It seems as though the object is only re-used if the new length is
>> equal to the old length.
>>
>> If you use Rf_lengthgets, you will need to protect the return value.
>> The code you wrote that uses protect indexes looks correct, and the
>> reprotect is good because you no longer need the old object.
>>
>> 2 is the correct amount to unprotect. PROTECT and PROTECT_WITH_INDEX
>> (as far as I know) are the only functions that increase the size of
>> the protect stack, and so the only calls that need to be unprotected.
>> Typically, people define `int nprotect = 0;` at the start of their
>> functions, add `nprotect++;` after each PROTECT and PROTECT_WITH_INDEX
>> call, and add `UNPROTECT(nprotect);` immediately before each return or
>> function end. That makes it easier to keep track.
>>
>> I typically use R_PreserveObject and R_ReleaseObject to protect
>> objects without a need to bind them somewhere in my package's
>> namespace. This would be that .onLoad() uses R_PreserveObject to
>> protect some objects, and .onUnload uses R_ReleaseObject to release
>> the protected objects. I probably would not use that for what you're
>> describing.
>>
>>
>> Regards,
>>???? Iris
>>
>> On Tue, Jan 14, 2025 at 11:26?PM Merlise Clyde, Ph.D. <clyde at duke.edu>
>> wrote:
>>>
>>> I am trying to determine the best way to eliminate the use of SETLENGTH
>> to truncate over allocated vectors in my package BAS to eliminate the NOTES
>> about non-API calls in anticipation of R 4.5.0.
>>>
>>> From WRE:? "At times it can be useful to allocate a larger initial
>> result vector and resize it to a shorter length if that is sufficient. The
>> functions Rf_lengthgets and Rf_xlengthgets accomplish this; they are
>> analogous to using length(x) <- n in R. Typically these functions return a
>> freshly allocated object, but in some cases they may re-use the supplied
>> object."
>>>
>>> it looks like using
>>>
>>>???? x = Rf_lengthgets(x, newsize);
>>>???? SET_VECTOR_ELT(result, 0, x);
>>>
>>> before returning works to resize without a performance hit that incurs
>> with a copy.? (will this always re-use the supplied object if newsize < old
>> size?)
>>>
>>> There is no mention in section 5.9.2 about the need for re-protection of
>> the object,? but it seems to be mentioned in some packages as well as a
>> really old thread about SET_LENGTH that looks like a? non-API MACRO to
>> lengthgets,
>>>
>>> indeed if I call gc() and then rerun my test I have had some
>> non-reproducible aborts in R Studio on my M3 Mac (caught once in R -d lldb)
>>>
>>> Do I need to do something more like
>>>
>>> PROTECT_INDEX ipx0;.
>>> PROTECT_WITH_INDEX(x0 = allocVector(REALSXP, old_size), &ipx0);
>>>
>>> PROTECT_INDEX ipx1;.
>>> PROTECT_WITH_INDEX(x1 = allocVector(REALSXP, old_size), &ipx1);
>>>
>>> # fill in values in x0 and? x1up to new_size (random) < old_size
>>> ...
>>> REPROTECT(x0 = Rf_lengthgets(x0, new_size), ipx0);
>>> REPROTECT(x1 = Rf_lengthgets(x1, new_size), ipx1);
>>>
>>> SET_VECTOR_ELT(result, 0, x0);
>>> SET_VECTOR_ELT(result, 1, x1);
>>> ...
>>> UNPROTECT(2);?? # or is this 4?
>>> return(result);
>>>
>>>
>>> There is also a mention in WRE of R_PreserveObject and R_ReleaseObject -
>>>
>>> looking for advice if this is needed, or which approach is better/more
>> stable to replace SETLENGTH??? (I have many many instances that need to be
>> updated, so trying to get some clarity here before updating and running
>> code through valgrind or other sanitizers to catch any memory issues before
>> submitting an update to CRAN.
>>>
>>> best,
>>> Merlise
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> ______________________________________________
>>> R-package-devel at r-project.org mailing list
>>>
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-package-devel__;!!OToaGQ!ohDoxcAn5uIC25d42XhBz8Kd4YftOJDBoEW1NK9FOmgZpcmv0XIy5fQRm24-s_D8m9O_lR6jo6FcKiA$
>
>??????? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-package-devel__;!!OToaGQ!uACtQIEun1eC8hwn-FzFogXQoPl1wETg9EUSV1NzAif9u15KlRTctzEq1RSA5rcbeVGv0n3geb8UexFnYd-1ZB4$
>

--
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa????????????????? Phone:???????????? 319-335-3386
Department of Statistics and??????? Fax:?????????????? 319-335-3017
??? Actuarial Science
241 Schaeffer Hall????????????????? email:?? luke-tierney at uiowa.edu
Iowa City, IA 52242???????????????? WWW:? https://urldefense.com/v3/__http://www.stat.uiowa.edu/__;!!OToaGQ!uACtQIEun1eC8hwn-FzFogXQoPl1wETg9EUSV1NzAif9u15KlRTctzEq1RSA5rcbeVGv0n3geb8UexFnFDCXgK0$

From joh@nnp||tz|nger @end|ng |rom goog|em@||@com  Wed Jan 15 22:13:36 2025
From: joh@nnp||tz|nger @end|ng |rom goog|em@||@com (Johann Pfitzinger)
Date: Wed, 15 Jan 2025 22:13:36 +0100
Subject: [R-pkg-devel] Help with clang-san warnings for package "tidyfit"
In-Reply-To: <01db66c4$Blat.v3.2.22$368863fe$19b4445fe@mail.statistik.tu-dortmund.de>
References: <01db66c4$Blat.v3.2.22$368863fe$19b4445fe@mail.statistik.tu-dortmund.de>
Message-ID: <aa1193b5-7921-42d8-83a7-bab58f3f7903@gmail.com>

Dear community,

my R package "tidyfit" is failing CRAN submission checks with the 
following warning (see email below for complete results):

Flavor: r-devel-linux-x86_64-debian-special-clang-san
Check: Post-processing issues found for clang-san, Result: WARNING
   File: tidyfit-Ex.Rout
   cleancall.c:110:46: runtime error: call to function cb_progress_done through pointer to incorrect function type 'void (*)(void *)'
   
   File: tests/testthat.Rout
   cleancall.c:110:46: runtime error: call to function cb_progress_done through pointer to incorrect function type 'void (*)(void *)'
   
   File: build_vignettes.log
   cleancall.c:110:46: runtime error: call to function cb_progress_done through pointer to incorrect function type 'void (*)(void *)'
   cleancall.c:110:46: runtime error: call to function cb_progress_done through pointer to incorrect function type 'void (*)(void *)'
   cleancall.c:110:46: runtime error: call to function cb_progress_done through pointer to incorrect function type 'void (*)(void *)'
   cleancall.c:110:46: runtime error: call to function cb_progress_done through pointer to incorrect function type 'void (*)(void *)'
   cleancall.c:110:46: runtime error: call to function cb_progress_done through pointer to incorrect function type 'void (*)(void *)'
   cleancall.c:110:46: runtime error: call to function cb_progress_done through pointer to incorrect function type 'void (*)(void *)'

I have, so far, failed to reproduce this or to find any useful 
information on how to fix it. My best guess based on the output.txt is 
that it originates in "purrr" (which I depend on).

I would really like to get the package back on CRAN as soon as possible. 
Any help is greatly appreciated!

Best regards,
Johann Pfitzinger

-------- Forwarded Message --------
Subject: 	[CRAN-pretest-archived] CRAN Submission tidyfit 0.7.3
Date: 	Tue, 14 Jan 2025 21:38:05 +0100
From: 	ligges at statistik.tu-dortmund.de
Reply-To: 	CRAN-submissions at R-project.org
To: 	johann.pfitzinger at gmail.com
CC: 	CRAN-submissions at R-project.org



Dear maintainer,
package tidyfit_0.7.3.tar.gz does not pass the incoming checks 
automatically, please see the following pre-tests (additional issue checks):
Windows: 
<https://win-builder.r-project.org/incoming_pretest/tidyfit_0.7.3_20250114_204852/Windows/00check.log>
Status: 1 NOTE
Debian: 
<https://win-builder.r-project.org/incoming_pretest/tidyfit_0.7.3_20250114_204852/Debian/00check.log>
Status: 1 NOTE
Additional issues checked: 
<https://win-builder.r-project.org/incoming_pretest/tidyfit_0.7.3_20250114_204852/specialChecks/>
clang-san: Status: WARNING
Last released version's CRAN status: OK: 13
See: 
<https://cran-archive.r-project.org/web/checks/2025/2025-01-14_check_results_tidyfit.html>

Last released version's additional issues:
clang-ASAN <https://www.stats.ox.ac.uk/pub/bdr/memtests/clang-ASAN/tidyfit>
gcc-ASAN <https://www.stats.ox.ac.uk/pub/bdr/memtests/gcc-ASAN/tidyfit>
Please fix all problems and resubmit a fixed version via the webform.
If you are not sure how to fix the problems shown, please ask for help 
on the R-package-devel mailing list:
<https://stat.ethz.ch/mailman/listinfo/r-package-devel>
If you are fairly certain the rejection is a false positive, please 
reply-all to this message and explain.
More details are given in the directory:
<https://win-builder.r-project.org/incoming_pretest/tidyfit_0.7.3_20250114_204852/>
The files will be removed after roughly 7 days.
No strong reverse dependencies to be checked.
Best regards,
CRAN teams' auto-check service

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Attached Message Part
URL: <https://stat.ethz.ch/pipermail/r-package-devel/attachments/20250115/9f28132e/attachment.ksh>

From |kry|ov @end|ng |rom d|@root@org  Thu Jan 16 21:30:48 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Thu, 16 Jan 2025 23:30:48 +0300
Subject: [R-pkg-devel] 
 Help with clang-san warnings for package "tidyfit"
In-Reply-To: <aa1193b5-7921-42d8-83a7-bab58f3f7903@gmail.com>
References: <01db66c4$Blat.v3.2.22$368863fe$19b4445fe@mail.statistik.tu-dortmund.de>
 <aa1193b5-7921-42d8-83a7-bab58f3f7903@gmail.com>
Message-ID: <20250116233048.030ef17e@Tarkus>

? Wed, 15 Jan 2025 22:13:36 +0100
Johann Pfitzinger <johannpfitzinger at googlemail.com> ?????:

> I have, so far, failed to reproduce this or to find any useful 
> information on how to fix it. My best guess based on the output.txt
> is that it originates in "purrr" (which I depend on).

This is, indeed, a purrr bug:
https://github.com/tidyverse/purrr/issues/1157

Since the bug is very minor (R's own .C() and .Fortran() currently do
similar things), a fix for purrr has already been suggested, and
another package with the same problem (valr) has been recently
approved, you have a good chance of your package too being approved if
you reply-all and explain the situation.

-- 
Best regards,
Ivan


From iuke-tier@ey m@iii@g oii uiow@@edu  Thu Jan 16 21:51:54 2025
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Thu, 16 Jan 2025 14:51:54 -0600 (CST)
Subject: [R-pkg-devel] [External] Re:  Replacement for SETLENGTH
In-Reply-To: <CY8PR05MB100349ABE1DB2CE78F0D79F06C8192@CY8PR05MB10034.namprd05.prod.outlook.com>
References: <CY8PR05MB100342EF92E6E169CA1067103C8182@CY8PR05MB10034.namprd05.prod.outlook.com>
 <CADNULg9fKRf3K6Q062D7X4rUJysO=9cWA1kFEjpSv3J-Oy0bYg@mail.gmail.com>
 <CY8PR05MB10034614E651AB601A74968AFC8192@CY8PR05MB10034.namprd05.prod.outlook.com>
 <CADNULg-ws6Atf6s-=TrHAHhXE=NDt+ij8+s9j5YUhV9KsA7Ggw@mail.gmail.com>
 <a424ea59-f51e-a0c9-9887-799d66b50e4@uiowa.edu>
 <CY8PR05MB100349ABE1DB2CE78F0D79F06C8192@CY8PR05MB10034.namprd05.prod.outlook.com>
Message-ID: <b9a35c69-2e58-f7f0-bda9-13e8f4e21b1@uiowa.edu>

You may be over-complicating this. Taking mcmc_new in src/lm_lcmc.c
from https://github.com/merliseclyde/BAS, to minimize code changes I
would arrange the memory management along these lines:

SEXP mcmc_new(...)
{
     /* ... */

     /* create and protect ANS */
     SEXP ANS = PROTECT(allocVector(VECSXP, 16));

     /* create the work vectors; placing them in ANS protects them */
     SEXP modelspace = allocVector(VECSXP, nModels);
     SET_VECTOR_ELT(ANS, 1, modelspace);
     SEXP logmarg = allocVector(REALSXP, nModels);
     SET_VECTOR_ELT(ANS, 2, logmarg);
     SEXP modelprobs = allocVector(REALSXP, nModels);
     SET_VECTOR_ELT(ANS, 3, modelprobs);
     /* etc */

     /* do your computations */

     if (nUnique < nModels) {
 	/* new values are protected via ANS;
 	   old ones are immediately available for GC */
 	SET_VECTOR_ELT(ANS, 1, xlengthgets(modelspace, nUnique));
 	SET_VECTOR_ELT(ANS, 2, xlengthgets(logmarg, nUnique));
 	SET_VECTOR_ELT(ANS, 3, xlengthgets(modelprobs, nUnique));
 	/* etc */
     }

     /* ... */
     UNPROTECT(1); /* ANS */
     return ANS;
}

Best,

luke

On Wed, 15 Jan 2025, Merlise Clyde, Ph.D. wrote:

>
> Thanks Luke !   I had seen the usage and discussion of growable vectors, as well as using SET_TRUELENGTH with SETLENGTH and didn't necessarily want to get even more out of API compliance :-). but if that looks like it will allowed (subject to perhaps changes) that seems like the better way forward to handle the different SEXPs.    And switching to smaller vectors and enlarging would be much more efficient in terms of memory.    I'll need to play around with how much to expand by as the enlargement would need to be in the loop with a final resizing before returning.
>
> So if I understand the suggestion the use of xlengthgets basically handles the body of the code in EnlargeVector function  for allocation and copying (but now smaller vectors) with then the extra step to SETLENGTH and SET_TRUELENGTH
> If done within a loop over MCMC iterations, then I would need to use SET_GROWABLE_BIT before the loop or when I encounter the need to enlarge.   (so basically a local implementation of EnlargeVector)
>
> For my non-VECSXP objects (REALSXP, INTSXP)  it might be more efficient to use Realloc on a working array within loops and only allocate and assign after determining the final length (nUnique), and freeing the memory myself...  That way I avoid SETLENGTH altogether for those types.
>
> best,
> Merlise
>
>
>
> Merlise Clyde (she/her/hers)
> Professor of Statistical Science and Director of Graduate Studies
> Duke University
>
>
> ________________________________________
> From:?luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
> Sent:?Wednesday, January 15, 2025 12:34 PM
> To:?Iris Simmons <ikwsimmo at gmail.com>
> Cc:?Merlise Clyde, Ph.D. <clyde at duke.edu>; List r-package-devel <r-package-devel at r-project.org>
> Subject:?Re: [External] Re: [R-pkg-devel] Replacement for SETLENGTH
> ?
> On Wed, 15 Jan 2025, Iris Simmons wrote:
>
>> I don't think memcpy works well for VECSXP. The elements being overwritten
>> need to have their reference counts decreased and the new elements need to
>> have theirs increased.
>
> You do not want to use memcpy or inanyother way try to write to the
> locations in a VECSXP. It is not jus the reference counts but also the
> integrity of the GC write barrier that you would be damaging.
>
>>
>> Also, I don't entirely know how accurate everything I'm about to say is,
>> but I think you need to be using SET_TRUELENGTH and SET_GROWABLE_BIT along
>> with SETLENGTH. There's an example here:
>>
>> https://urldefense.com/v3/__https://github.com/wch/r-source/blob/744b5d34e1b8eb839e5d49d91ab21c1fe6800856/src/main/subassign.c*L257__;Iw!!OToaGQ!uACtQIEun1eC8hwn-FzFogXQoPl1wETg9EUSV1NzAif9u15KlRTctzEq1RSA5rcbeVGv0n3geb8UexFngaonYos$
>>
>>
>> The example uses SET_STDVEC_LENGTH which shouldn't be used, just replace it
>> with SETLENGTH.
>>
>> So in your code, I'd replace:
>>
>> SETLENGTH(modelspace, nUnique);
>>
>> with
>>
>> SET_GROWABLE_BIT(modelspace);
>> SET_TRUELENGTH(modelspace, nModels);
>> SETLENGTH(modelspace, nUnique);
>
> These are not part of the API.
>
> Support for growable vectors maybe added to the API in the future, but
> probably with a more robust interface.
>
> In any case, this mechanism is intended for growing, not shrinking,
> vectors.
>
> Initially over-allocating and returning a smaller result is a
> reasonable strategy, but the right way to do it is to allocate a new
> shorter result. xlengthgets is a convenient way to do this. Tholonger
> vector will be subject to garbage collecion once there are no
> remaining references to it.
>
> Attempting to keep alive a longer allocation but pretending it is
> shorter is mis-guided: it would keep alive a larger object than is
> needed and so waste memory.
>
> Best,
>
> luke
>
>> On Wed, Jan 15, 2025, 10:30 Merlise Clyde, Ph.D. <clyde at duke.edu> wrote:
>>
>>> Thanks for the added explanation Iris and Tomas!
>>>
>>> So looking at the code for xlengthgets, it does appear that I may take a
>>> memory hit for multiple large objects due to the second allocation before
>>> the old objects are possibly garbage collected.???? There are about 12 such
>>> instances per function that are returned (I do use a counter for keeping
>>> track of the number of PROTECTED and to UNPROTECT for bookkeeping :-).
>>> ? For memory limited machines, the alloc/copy was a problem for memory usage
>>> - and if I recall was one of the reasons in 2008 I switched to SETLENGTH,
>>> which doesn't seem to do an allocation ???? If there is going to be an
>>> absolute ban on SETLENGTH? in packages I'll probably need to address memory
>>> management differently for those cases.
>>>
>>> I did see a note before the function def'n of xlengthgets:
>>>
>>> /* (if it is vectorizable). We could probably be fairly */
>>> /* clever with memory here if we wanted to. */
>>>
>>> It would seem that memcpy would be more efficient for at least some of the
>>> types? (REALSPX, INTSPX) unless I am missing something - but any way to be
>>> more clever with VECSPX ?
>>>
>>> best,
>>> Merlise
>>>
>>>
>>>
>>> Merlise Clyde (she/her/hers)
>>> Professor of Statistical Science and Director of Graduate Studies
>>> Duke University
>>>
>>> ________________________________________
>>> From: Iris Simmons <ikwsimmo at gmail.com>
>>> Sent: Wednesday, January 15, 2025 1:00 AM
>>> To: Merlise Clyde, Ph.D. <clyde at duke.edu>
>>> Cc: r-package-devel at r-project.org <r-package-devel at r-project.org>
>>> Subject: Re: [R-pkg-devel] Replacement for SETLENGTH
>>>
>>> Hi Merlise!
>>>
>>>
>>> Referring to here:
>>>
>>>
>>> https://urldefense.com/v3/__https://github.com/wch/r-source/blob/bb5a829466f77a3e1d03541747d149d65e900f2b/src/main/builtin.c*L834__;Iw!!OToaGQ!uACtQIEun1eC8hwn-FzFogXQoPl1wETg9EUSV1NzAif9u15KlRTctzEq1RSA5rcbeVGv0n3geb8UexFnr_0lCLM$
>>>
>>> It seems as though the object is only re-used if the new length is
>>> equal to the old length.
>>>
>>> If you use Rf_lengthgets, you will need to protect the return value.
>>> The code you wrote that uses protect indexes looks correct, and the
>>> reprotect is good because you no longer need the old object.
>>>
>>> 2 is the correct amount to unprotect. PROTECT and PROTECT_WITH_INDEX
>>> (as far as I know) are the only functions that increase the size of
>>> the protect stack, and so the only calls that need to be unprotected.
>>> Typically, people define `int nprotect = 0;` at the start of their
>>> functions, add `nprotect++;` after each PROTECT and PROTECT_WITH_INDEX
>>> call, and add `UNPROTECT(nprotect);` immediately before each return or
>>> function end. That makes it easier to keep track.
>>>
>>> I typically use R_PreserveObject and R_ReleaseObject to protect
>>> objects without a need to bind them somewhere in my package's
>>> namespace. This would be that .onLoad() uses R_PreserveObject to
>>> protect some objects, and .onUnload uses R_ReleaseObject to release
>>> the protected objects. I probably would not use that for what you're
>>> describing.
>>>
>>>
>>> Regards,
>>> ???? Iris
>>>
>>> On Tue, Jan 14, 2025 at 11:26?PM Merlise Clyde, Ph.D. <clyde at duke.edu>
>>> wrote:
>>>>
>>>> I am trying to determine the best way to eliminate the use of SETLENGTH
>>> to truncate over allocated vectors in my package BAS to eliminate the NOTES
>>> about non-API calls in anticipation of R 4.5.0.
>>>>
>>>> From WRE:? "At times it can be useful to allocate a larger initial
>>> result vector and resize it to a shorter length if that is sufficient. The
>>> functions Rf_lengthgets and Rf_xlengthgets accomplish this; they are
>>> analogous to using length(x) <- n in R. Typically these functions return a
>>> freshly allocated object, but in some cases they may re-use the supplied
>>> object."
>>>>
>>>> it looks like using
>>>>
>>>> ???? x = Rf_lengthgets(x, newsize);
>>>> ???? SET_VECTOR_ELT(result, 0, x);
>>>>
>>>> before returning works to resize without a performance hit that incurs
>>> with a copy.? (will this always re-use the supplied object if newsize < old
>>> size?)
>>>>
>>>> There is no mention in section 5.9.2 about the need for re-protection of
>>> the object,? but it seems to be mentioned in some packages as well as a
>>> really old thread about SET_LENGTH that looks like a? non-API MACRO to
>>> lengthgets,
>>>>
>>>> indeed if I call gc() and then rerun my test I have had some
>>> non-reproducible aborts in R Studio on my M3 Mac (caught once in R -d lldb)
>>>>
>>>> Do I need to do something more like
>>>>
>>>> PROTECT_INDEX ipx0;.
>>>> PROTECT_WITH_INDEX(x0 = allocVector(REALSXP, old_size), &ipx0);
>>>>
>>>> PROTECT_INDEX ipx1;.
>>>> PROTECT_WITH_INDEX(x1 = allocVector(REALSXP, old_size), &ipx1);
>>>>
>>>> # fill in values in x0 and? x1up to new_size (random) < old_size
>>>> ...
>>>> REPROTECT(x0 = Rf_lengthgets(x0, new_size), ipx0);
>>>> REPROTECT(x1 = Rf_lengthgets(x1, new_size), ipx1);
>>>>
>>>> SET_VECTOR_ELT(result, 0, x0);
>>>> SET_VECTOR_ELT(result, 1, x1);
>>>> ...
>>>> UNPROTECT(2);?? # or is this 4?
>>>> return(result);
>>>>
>>>>
>>>> There is also a mention in WRE of R_PreserveObject and R_ReleaseObject -
>>>>
>>>> looking for advice if this is needed, or which approach is better/more
>>> stable to replace SETLENGTH??? (I have many many instances that need to be
>>> updated, so trying to get some clarity here before updating and running
>>> code through valgrind or other sanitizers to catch any memory issues before
>>> submitting an update to CRAN.
>>>>
>>>> best,
>>>> Merlise
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> ______________________________________________
>>>> R-package-devel at r-project.org mailing list
>>>>
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-package-devel__;!!OToaGQ!ohDoxcAn5uIC25d42XhBz8Kd4YftOJDBoEW1NK9FOmgZpcmv0XIy5fQRm24-s_D8m9O_lR6jo6FcKiA$
>>
>> ??????? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-package-devel at r-project.org mailing list
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-package-devel__;!!OToaGQ!uACtQIEun1eC8hwn-FzFogXQoPl1wETg9EUSV1NzAif9u15KlRTctzEq1RSA5rcbeVGv0n3geb8UexFnYd-1ZB4$
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa????????????????? Phone:???????????? 319-335-3386
> Department of Statistics and??????? Fax:?????????????? 319-335-3017
> ??? Actuarial Science
> 241 Schaeffer Hall????????????????? email:?? luke-tierney at uiowa.edu
> Iowa City, IA 52242???????????????? WWW:? https://urldefense.com/v3/__http://www.stat.uiowa.edu/__;!!OToaGQ!uACtQIEun1eC8hwn-FzFogXQoPl1wETg9EUSV1NzAif9u15KlRTctzEq1RSA5rcbeVGv0n3geb8UexFnFDCXgK0$

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu/

From joh@nnp||tz|nger @end|ng |rom goog|em@||@com  Fri Jan 17 09:01:33 2025
From: joh@nnp||tz|nger @end|ng |rom goog|em@||@com (Johann Pfitzinger)
Date: Fri, 17 Jan 2025 09:01:33 +0100
Subject: [R-pkg-devel] 
 Help with clang-san warnings for package "tidyfit"
In-Reply-To: <20250116233048.030ef17e@Tarkus>
References: <01db66c4$Blat.v3.2.22$368863fe$19b4445fe@mail.statistik.tu-dortmund.de>
 <aa1193b5-7921-42d8-83a7-bab58f3f7903@gmail.com>
 <20250116233048.030ef17e@Tarkus>
Message-ID: <dd026412-b763-4d6b-b2e5-b81e030404d4@gmail.com>

Hi Ivan,

thanks for your helpful response and for the background info! Much 
appreciated!

I'll reply-all as you suggested.

Best regards,
Johann

On 16.01.25 21:30, Ivan Krylov wrote:
> ? Wed, 15 Jan 2025 22:13:36 +0100
> Johann Pfitzinger <johannpfitzinger at googlemail.com> ?????:
>
>> I have, so far, failed to reproduce this or to find any useful
>> information on how to fix it. My best guess based on the output.txt
>> is that it originates in "purrr" (which I depend on).
> This is, indeed, a purrr bug:
> https://github.com/tidyverse/purrr/issues/1157
>
> Since the bug is very minor (R's own .C() and .Fortran() currently do
> similar things), a fix for purrr has already been suggested, and
> another package with the same problem (valr) has been recently
> approved, you have a good chance of your package too being approved if
> you reply-all and explain the situation.
>


From p@kr|v|t@ky @end|ng |rom un@w@edu@@u  Fri Jan 17 11:21:27 2025
From: p@kr|v|t@ky @end|ng |rom un@w@edu@@u (Pavel Krivitsky)
Date: Fri, 17 Jan 2025 10:21:27 +0000
Subject: [R-pkg-devel] Best practices for built version checking in packages
 LinkingTo others?
Message-ID: <98a863d7814e843ef600bfb67e742109edc8fa15.camel@unsw.edu.au>

Dear All,

I maintain a package ('ergm') that exports a C API via /inst/include/
that includes header files with data structures, macros, and inline
functions, as well as a number of functions exported in a stubs file
(that use R_FindSymbol() and/or R_GetCCallable() to locate the
functions in 'ergm') that the linking package #includes to access them.

I've recently had an update stall because a source-compatible change in
one of the structs changed the ABI---that is, packages LinkingTo 'ergm'
needs to be rebuilt, and one of them was Suggested by 'ergm' precisely
in order to test the exported C API. As
https://cloud.r-project.org/doc/manuals/r-devel/R-exts.html#Linking-to-native-routines-in-other-packages
suggests, LinkingTo packages should either depend on an exact version
(which is impractical) or test whether the version matches at runtime.

Thus, the questions are:

   1. What is the best way to save this information? I have a
      rudimentary implementation [1], but R already has a mechanism to
      store the build-time R version since it warns about that; can it
      be used for packages as well?
      
   2. How to best test the C API without making updates impossible?
      Obviously, I have my own continuous integration setups, so I
      could simply disable the tests on CRAN, but there is some benefit
      to having tests on CRAN as well [2]. That is, should the testing
      be conditional ABI versions not mismatching, or is this more
      trouble than it's worth?
      
   3. What should be done in case of a mismatch?
      
         1. Is there a way for 'ergm' to detect when a package LinkingTo it
            is being loaded? Checking and handling can be put into .onLoad()
            of the LinkingTo packages, but there is some benefit to putting
            as little code into the LinkingTo package. However, as far as I
            can tell, hooks can only be set for specific packages. Is this
            correct?
            
         2. What should happen if a mismatch is detected? Should the loading
            be blocked (e.g., by having .onLoad() throw an error), or should
            it lead to a "use at your own risk" type warning?

Thanks in advance,
Pavel

[1]

This can be implemented by defining macros with the ABI version in
'ergm', e.g.,

ergm_version.h:

#define ERGM_API_MAJOR 4
#define ERGM_API_MINOR 8

typedef struct {unsigned int major, minor;} APIVersion;

then

ergm_stubs.c (#included from every LinkingTo package into a C file):

#include "ergm_version.h"

APIVersion GetBuiltErgmAPIVersion(void){
  return (APIVersion) {ERGM_API_MAJOR, ERGM_API_MINOR};
}

Then, at compile time, the macros will be resolved so
GetBuiltErgmAPIVersion() will return the build-time 'ergm' version.
R_FindSymbol() could be used to obtain a pointer to
GetBuiltErgmAPIVersion() from a given package and hence its 'ergm'
build version, which can then be returned to R.

[2]

For example (and this actually happened several versions ago) the
package might do something with computational cost that depends on the
number of installed packages.


From |kry|ov @end|ng |rom d|@root@org  Fri Jan 17 14:50:57 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Fri, 17 Jan 2025 16:50:57 +0300
Subject: [R-pkg-devel] 
 Best practices for built version checking in packages
 LinkingTo others?
In-Reply-To: <98a863d7814e843ef600bfb67e742109edc8fa15.camel@unsw.edu.au>
References: <98a863d7814e843ef600bfb67e742109edc8fa15.camel@unsw.edu.au>
Message-ID: <20250117165057.7d994670@arachnoid>

? Fri, 17 Jan 2025 10:21:27 +0000
Pavel Krivitsky via R-package-devel <r-package-devel at r-project.org>
?????:

>    1. What is the best way to save this information? I have a
>       rudimentary implementation [1]

For now, this is the best way we have. Export the ABI version as an
include-time constant and as a registered callable. The LinkingTo
reverse dependencies can give the include-time constant to the
registered callable to compare the two versions.

I agree that we could do better and introduce an ABIversion: field to
the DESCRIPTION file. R CMD INSTALL would write down the current
ABIversion of every package that the current package is LinkingTo (into
the installed package's DESCRIPTION or Meta/features.rds). Later, the
namespace loader would check the ABI versions and provide an
informative message in case a LinkingTo dependency is updated with an
incremented ABI version. A machine-readable list of ABI-level
dependencies should simplify the lives of the binary package
maintainers as well.

(Related may be a problem with S4, where packages may end up caching
parts of the classes from other packages they depend upon, which also
breaks binary installations but self-heals upon reinstalling from
source [1]. This still happens under R-devel. R could store and check
some sort of hash when caching these classes and either reload them in
full or prompt for the package to be reinstalled.)

>    2. How to best test the C API without making updates impossible?

Would abi-compliance-checker [2] have helped there?

It's not exactly designed for static functions and R_GetCCallable(),
but with abi-dumper -all or -dump-static it is possible to use it to
demonstrate incompatibilities between (for example) Matrix_1.6-1.1 and
Matrix_1.7. With either a separate build that exports the functions
destined for R_RegisterCCallable() or some sort of filter for public
symbols, this tool may help detect ABI incompatibilities early.

>    3. What should be done in case of a mismatch?

It's hard to guarantee anything when the ABI is broken. Maybe it's
completely harmless because your code will know that the new structure
member is not initialised. Maybe the wrong stack layout will crash the
process due to a return address mismatch, dooming the process from the
first function call.

>          1. Is there a way for 'ergm' to detect when a package
> LinkingTo it is being loaded?

With inline functions, you could make your every API call perform ABI
version checking, but that obviously comes with potential performance
problems:

// public header in mypackage
#define MYPACKAGE_ABI_VERSION 2
static R_INLINE SEXP mypackage_frobnicate(SEXP arg) {
 (
  (void (*)(int))R_GetCCallable("mypackage", "check_abi_version")
 )(MYPACKAGE_ABI_VERSION); // signals an error on mismatch
 return (
  (SEXP (*)(SEXP))R_GetCCallable("mypackage", "frobnicate")
 )(arg);
}

>          2. What should happen if a mismatch is detected? Should the
> loading be blocked (e.g., by having .onLoad() throw an error), or
> should it lead to a "use at your own risk" type warning?

The safest option would be to signal an error before any of the
potentially incompatible functions are called. It's probably pragmatic
to provide an "I know what I'm doing, void my warranty" emergency
override.

-- 
Best regards,
Ivan

[1] https://stat.ethz.ch/pipermail/r-devel/2023-August/082769.html

[2] https://lvc.github.io/abi-compliance-checker/


From bbo|ker @end|ng |rom gm@||@com  Fri Jan 17 15:13:00 2025
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 17 Jan 2025 09:13:00 -0500
Subject: [R-pkg-devel] 
 Best practices for built version checking in packages
 LinkingTo others?
In-Reply-To: <20250117165057.7d994670@arachnoid>
References: <98a863d7814e843ef600bfb67e742109edc8fa15.camel@unsw.edu.au>
 <20250117165057.7d994670@arachnoid>
Message-ID: <4467ebb8-205f-4c69-96da-15a5d1b2999b@gmail.com>

   I wouldn't guarantee that it's best practices, but for reference this 
is what glmmTMB does about checking the Matrix and TMB versions (Matrix 
has a formal ABI version distinct from its package version; TMB doesn't)


https://github.com/glmmTMB/glmmTMB/blob/b7936f4cbe9f26e3d8d5eae727afd83f6ec2b76b/glmmTMB/R/zzz.R#L21-L26

https://github.com/glmmTMB/glmmTMB/blob/b7936f4cbe9f26e3d8d5eae727afd83f6ec2b76b/glmmTMB/R/utils.R#L232-L252

   cheers
    Ben Bolker


> 
>>     1. What is the best way to save this information? I have a
>>        rudimentary implementation [1]
> 
> For now, this is the best way we have. Export the ABI version as an
> include-time constant and as a registered callable. The LinkingTo
> reverse dependencies can give the include-time constant to the
> registered callable to compare the two versions.
> 
> I agree that we could do better and introduce an ABIversion: field to
> the DESCRIPTION file. R CMD INSTALL would write down the current
> ABIversion of every package that the current package is LinkingTo (into
> the installed package's DESCRIPTION or Meta/features.rds). Later, the
> namespace loader would check the ABI versions and provide an
> informative message in case a LinkingTo dependency is updated with an
> incremented ABI version. A machine-readable list of ABI-level
> dependencies should simplify the lives of the binary package
> maintainers as well.
> 
> (Related may be a problem with S4, where packages may end up caching
> parts of the classes from other packages they depend upon, which also
> breaks binary installations but self-heals upon reinstalling from
> source [1]. This still happens under R-devel. R could store and check
> some sort of hash when caching these classes and either reload them in
> full or prompt for the package to be reinstalled.)
> 
>>     2. How to best test the C API without making updates impossible?
> 
> Would abi-compliance-checker [2] have helped there?
> 
> It's not exactly designed for static functions and R_GetCCallable(),
> but with abi-dumper -all or -dump-static it is possible to use it to
> demonstrate incompatibilities between (for example) Matrix_1.6-1.1 and
> Matrix_1.7. With either a separate build that exports the functions
> destined for R_RegisterCCallable() or some sort of filter for public
> symbols, this tool may help detect ABI incompatibilities early.
> 
>>     3. What should be done in case of a mismatch?
> 
> It's hard to guarantee anything when the ABI is broken. Maybe it's
> completely harmless because your code will know that the new structure
> member is not initialised. Maybe the wrong stack layout will crash the
> process due to a return address mismatch, dooming the process from the
> first function call.
> 
>>           1. Is there a way for 'ergm' to detect when a package
>> LinkingTo it is being loaded?
> 
> With inline functions, you could make your every API call perform ABI
> version checking, but that obviously comes with potential performance
> problems:
> 
> // public header in mypackage
> #define MYPACKAGE_ABI_VERSION 2
> static R_INLINE SEXP mypackage_frobnicate(SEXP arg) {
>   (
>    (void (*)(int))R_GetCCallable("mypackage", "check_abi_version")
>   )(MYPACKAGE_ABI_VERSION); // signals an error on mismatch
>   return (
>    (SEXP (*)(SEXP))R_GetCCallable("mypackage", "frobnicate")
>   )(arg);
> }
> 
>>           2. What should happen if a mismatch is detected? Should the
>> loading be blocked (e.g., by having .onLoad() throw an error), or
>> should it lead to a "use at your own risk" type warning?
> 
> The safest option would be to signal an error before any of the
> potentially incompatible functions are called. It's probably pragmatic
> to provide an "I know what I'm doing, void my warranty" emergency
> override.
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From |uk@@@@chne|derb@uer @end|ng |rom gm@||@com  Sat Jan 18 00:05:10 2025
From: |uk@@@@chne|derb@uer @end|ng |rom gm@||@com (Lukas Schneiderbauer)
Date: Sat, 18 Jan 2025 00:05:10 +0100
Subject: [R-pkg-devel] 
 SystemRequirements & configure check for FFTW with
 single precision support
In-Reply-To: <20250111220957.6f839b0d@Tarkus>
References: <CAHETjtZcmar26ud0s0yn9RGQXwjKtVpkT3gt+o2DGfAyR-T=qg@mail.gmail.com>
 <20250111220957.6f839b0d@Tarkus>
Message-ID: <CAHETjtao+kQMLOG3aoktqAy1GY75jQ+9XMqjhosDG3wKzDc0NA@mail.gmail.com>

Thanks for the feedback and advice!
I removed the omp.h test, I guess using AC_OPENMP should do the trick
anyways.

I will also try your suggestion regarding the SystemRequirements. Let's see
if it will be accepted this time.

I'm sorry for asking this admittedly thick question, but are you sure
> it's not just R CMD check --as-cran repeating the X-CRAN-Comment: field
> (which includes the phrase about not testing for single-precision
> FFTW)? Does the rejection e-mail say "please fix and resubmit", list
> specific problems, or ask for specific actions?


I am pretty confident it was also a personal response, not only the
X-CRAN-Comment: field. But let's see how the next run goes.

Best regards,
Lukas

	[[alternative HTML version deleted]]


From |uk@@@@chne|derb@uer @end|ng |rom gm@||@com  Sat Jan 18 00:15:36 2025
From: |uk@@@@chne|derb@uer @end|ng |rom gm@||@com (Lukas Schneiderbauer)
Date: Sat, 18 Jan 2025 00:15:36 +0100
Subject: [R-pkg-devel] 
 SystemRequirements & configure check for FFTW with
 single precision support
In-Reply-To: <4D3E0C0F-263C-4B48-91A6-0E9C56D70B27@R-project.org>
References: <CAHETjtZcmar26ud0s0yn9RGQXwjKtVpkT3gt+o2DGfAyR-T=qg@mail.gmail.com>
 <4D3E0C0F-263C-4B48-91A6-0E9C56D70B27@R-project.org>
Message-ID: <CAHETjtYdNBA1cR-=GMcxsLfmi7xdvWYAGREjL_=o=gRMKxR3xQ@mail.gmail.com>

Hi Simon,

Thank you for your detailed feedback!
I rebuilt the configure script to use pkg-config, removed the extra
brew-check, fixed the CPPFLAGS issue you mentioned, and included "fftw-s"
in SystemRequirements.
The package is building fine again on all platforms (using rhub tests and
the `devtools::check_win_devel()` test).

Hopefully it will get accepted soon. :)

Best regards,
Lukas


On Wed, Jan 15, 2025 at 3:59?AM Simon Urbanek <simon.urbanek at r-project.org>
wrote:

> Lukas,
>
> I have not seen the communication so I'm not commenting on that
> specifically, I only looked at the GitHub link.
>
> Although your configure could be improved (more below), it works well
> enough to detect fftw3f.
>
> Unfortunately, SystemRequirements don't have a well-defined structure, but
> there are two commonly used notations:
>
> a) library name and version so in your case that would be something like
> libfftw3f (>=3.3.0)
>
> b) deb/rpm package names
> libfftw3-dev (deb), fftw3-devel (rpm)
>
> fftw is a bit of a mess, because Debian ships the single-precision static
> library in libfftw3-dev, but also has libfftw3-single3 which is the dynamic
> version of the same, while RH does not distinguish. macOS recipe names are
> usually included only if they are non-obvious, but that would be the case
> here since installing fftw recipe does not work for you, so mentioning
> fftw-s is probably a good idea (there are community scripts that try to
> extract that information from the packages so that the dependencies can be
> installed).
>
> As for your configure, my main objection would be that it ignores CPPFLAGS
> (they are not substituted at all even though they *are* used in the tests)
> and doesn't use pkg-config to get the correct flags. (Also the brew part
> should go - it's makes unwarranted assumptions [see below] and is entirely
> superfluous if you use pkg-config instead.) To illustrate what I mean, you
> get
>
> $ pkg-config --cflags fftw3f
> -I/opt/R/x86_64/include
> $ pkg-config --libs fftw3f
> -L/opt/R/x86_64/lib -lfftw3f -lm
>
> while fCWTr on GitHub only uses
>
>   Configuration for fCWTr 0.2.9000
>
>     cppflags:
>     cxxflags:
>     ldflags:
>     libs:     -lfftw3f
>
> It actually works despite that, because R will inject the other flags for
> you, but that will only work is fftw is installed in the same location as
> the other libraries used by R (which is common, but not guaranteed). I
> wouldn't say it is dealbreaker, but it would recommend it for robustness.
>
> FWIW with homebrew the correct flags are obtainable from pkg-config:
>
> $ pkg-config --libs fftw3f
> -L/opt/brew/Cellar/fftw/3.3.8_1/lib -lfftw3f
> $ pkg-config --cflags fftw3f
> -I/opt/brew/Cellar/fftw/3.3.8_1/include
>
> Cheers,
> Simon
>
>
>
> > On Jan 11, 2025, at 10:37 PM, Lukas Schneiderbauer <
> lukas.schneiderbauer at gmail.com> wrote:
> >
> > Hi list,
> >
> > I am working on getting a package <
> https://github.com/lschneiderbauer/fCWTr> to
> > CRAN. It depends on the FFTW library <https://www.fftw.org/> that is
> built
> > with single precision support. I am stuck in the submission process and I
> > require your help.
> >
> > Before I come to my questions, some key facts about the package:
> >
> > The package has an autoconf configure script that uses (among other
> things,
> > like OpenMP checks, etc..) AC_SEARCH_LIBS to check whether required
> > functions of the library 'fftwf' exist, if yes, it adds the corresponding
> > compiler/linker flags; if no, it errs with a descriptive error message.
> >
> > The CRAN Windows as well as Linux build service included fftwf in their
> > fftw build out of the box, and so building there was no problem, R CMD
> > Check passes there. In the past, building for MacOS was more trouble,
> since
> > its fftw package does not include a single-precision build. I reached out
> > to Simon Urbanek, and he was so kind as to add an appropriate new recipe
> > "fftw-s" that provided an fftw version with single precision support. As
> of
> > now, R CMD check also passes cleanly on the MacOS build service, thanks
> to
> > Simon Urbanek's efforts.
> >
> > Now, I am stuck at submission for two reasons:
> > 1. The SystemRequirements specification in the DESCRIPTION file is
> > incorrect.
> > 2. It is said that "the package needs a configure check for fftwf".
> >
> > Add 1.
> > Initially, I had no mention of the "single precision" version of fftw,
> > because I thought it is included everywhere by default. It was stated
> that
> > I need to add that information. I naturally complied.
> > This is my current version:
> > "SystemRequirements: fftw3 (including single precision support fftw3f),
> > fftw3f_omp (optional), OpenMP (optional)"
> > In the second subscription run, I was told to add "fftw-s" since I
> require
> > the fftw-s package on MacOS. This does not make much sense to me since
> > "fftw-s" is only the name of this package on Simon Urbanek's MacOS build
> > service. The library file itself is still called fftwf, like it is on any
> > other platform. If I added "fftw-s", I would also need to explain that
> this
> > is only valid for MacOS which seems to make the SystemRequirements
> > unnecessary verbose.
> > * Can someone explain the reason behind this request to me?
> > * How exactly should I add "fftw-s" to pass the submission process?
> >
> > Add 2.
> > I tried to explain now for the second time in the submission notes, that
> a
> > check is already in place (see the AC_SEARCH_LIBS paragraph above). But
> my
> > explanation gets ignored.
> > * What am I doing wrong?
> > * What additional configure checks do I need to add to the package?
> >
> > Thanks a lot for your help!
> > Sincerely, Lukas Schneiderbauer
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-package-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-package-devel
> >
>
>

	[[alternative HTML version deleted]]


From p@kr|v|t@ky @end|ng |rom un@w@edu@@u  Sun Jan 19 06:31:15 2025
From: p@kr|v|t@ky @end|ng |rom un@w@edu@@u (Pavel Krivitsky)
Date: Sun, 19 Jan 2025 05:31:15 +0000
Subject: [R-pkg-devel] 
 Best practices for built version checking in packages
 LinkingTo others?
In-Reply-To: <20250117165057.7d994670@arachnoid>
References: <98a863d7814e843ef600bfb67e742109edc8fa15.camel@unsw.edu.au>
 <20250117165057.7d994670@arachnoid>
Message-ID: <8d9b8f509ae8ea4dc65928d0285e939ef9272442.camel@unsw.edu.au>

Thanks, Ivan! Replies below.

On Fri, 2025-01-17 at 16:50 +0300, Ivan Krylov wrote:
> ? Fri, 17 Jan 2025 10:21:27 +0000
> Pavel Krivitsky via R-package-devel <r-package-devel at r-project.org>
> ?????:
> 
> > ?? 1. What is the best way to save this information? I have a
> > ????? rudimentary implementation [1]
> 
> For now, this is the best way we have. Export the ABI version as an
> include-time constant and as a registered callable. The LinkingTo
> reverse dependencies can give the include-time constant to the
> registered callable to compare the two versions.

Ben Bolker pointed out that since the code in R/ is executed at build-
time, it is also possible to store the build-time ABI information
entirely in R; the downside of this approach is that it requires
instrumenting every client package rather than just the library
package.

> I agree that we could do better and introduce an ABIversion: field to
> the DESCRIPTION file. R CMD INSTALL would write down the current
> ABIversion of every package that the current package is LinkingTo
> (into the installed package's DESCRIPTION or Meta/features.rds).
> Later, the namespace loader would check the ABI versions and provide
> an informative message in case a LinkingTo dependency is updated with
> an incremented ABI version. A machine-readable list of ABI-level
> dependencies should simplify the lives of the binary package
> maintainers as well.

Yes, that would be great to have. (One nitpick: not just incremented,
but different in either direction.)

AFAIK, for those platforms that use binaries, there is already a
mechanism for downloading a different ZIP for a different version of R,
but I believe it's accomplished simply by having a directory for every
version of R with a potentially different ABI.

I suppose this could be generalised along the lines of a directory
hierarchy of the form

/bin/windows/contrib/RVERSION/PKG_ABIVERSION/.../PKG_ABIVERSION/PKG_PKGVERSION.zip

with a nesting level for every LinkingTo package, in lexicographic
order. Then, given the installed R version and the installed versions
of each package in the LinkingTo list, a unique URL can be constructed.
However, I don't know how practical this is and how likely to be
implemented in the foreseeable future.

> > ?? 2. How to best test the C API without making updates impossible?
> 
> Would abi-compliance-checker [2] have helped there?

I meant specifically in the context of R CMD check; the only want to
fully test the C API and associated facilities is to actually install
the client package and see if it works.

That having been said, 'ergm' may be unusual in this, since the API is
mostly used as a way for others to implement calculation of graph
statistics that are then operated on by functions in 'ergm'. That is,
rather than simply offering C functions for the client packages to use,
'ergm' calls C functions from those packages that it locates via
R_FindSymbol(). Thus, it is helpful to test it as a part of 'ergm'
itself rather than just reverse-dependency checks.

> > ?? 3. What should be done in case of a mismatch?
> 
> It's hard to guarantee anything when the ABI is broken. Maybe it's
> completely harmless because your code will know that the new
> structure member is not initialised. Maybe the wrong stack layout
> will crash the process due to a return address mismatch, dooming the
> process from the first function call.k
> 
> > ???????? 1. Is there a way for 'ergm' to detect when a package
> > LinkingTo it is being loaded?
> 
> With inline functions, you could make your every API call perform ABI
> version checking, but that obviously comes with potential performance
> problems:

The reason I ask is that the best time to inform the user of an ABI
change is when the client package is loaded, and it would be helpful if
this could be done without modifying the client package.

Is there a mechanism for the library package to monitor packages being
loaded, and for each one check if it's LinkingTo it to do the version
check?

> > ???????? 2. What should happen if a mismatch is detected? Should
> > the
> > loading be blocked (e.g., by having .onLoad() throw an error), or
> > should it lead to a "use at your own risk" type warning?
> 
> The safest option would be to signal an error before any of the
> potentially incompatible functions are called. It's probably
> pragmatic to provide an "I know what I'm doing, void my warranty"
> emergency override.

Probably an options() setting.

				Best,
				Pavel


From pep|jn@devr|e@ @end|ng |rom out|ook@com  Sun Jan 19 18:07:51 2025
From: pep|jn@devr|e@ @end|ng |rom out|ook@com (Pepijn de Vries)
Date: Sun, 19 Jan 2025 17:07:51 +0000
Subject: [R-pkg-devel] Package builds on all systems except on Fedora with
 clang
Message-ID: <AS8PR10MB4663D3B455E96FE0A05C7640A7E42@AS8PR10MB4663.EURPRD10.PROD.OUTLOOK.COM>

Dear fellow developers,

Recently I've submitted a package to CRAN which builds without problems on most systems:

https://cran.r-project.org/web/checks/check_results_openmpt.html

Except for Fedora with clang:

https://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-fedora-clang/openmpt-00install.html

There are some valgrind and ASAN issues, but most of them are solved at https://github.com/pepijn-devries/openmpt

At first I thought that the problem was caused by a missing system requirement (i.e., the libopenmpt library). However, Prof. Ripley reported that all system requirements are installed on the Fedora machine. He also mentioned that I "need to check in your configure script that the external library you need is available *and* usable with the compilers used to compile R and packages." As I'm new to including static libraries in an R package, I'm not sure how to fix this. Does anyone have a clue to get this fixed?

Kind regards,

Pepijn

From |kry|ov @end|ng |rom d|@root@org  Sun Jan 19 20:40:22 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sun, 19 Jan 2025 22:40:22 +0300
Subject: [R-pkg-devel] 
 Package builds on all systems except on Fedora with clang
In-Reply-To: <AS8PR10MB4663D3B455E96FE0A05C7640A7E42@AS8PR10MB4663.EURPRD10.PROD.OUTLOOK.COM>
References: <AS8PR10MB4663D3B455E96FE0A05C7640A7E42@AS8PR10MB4663.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <20250119224022.49a80684@Tarkus>

? Sun, 19 Jan 2025 17:07:51 +0000
Pepijn de Vries <pepijn.devries at outlook.com> ?????:

> He also mentioned that I "need to check in your configure script that
> the external library you need is available *and* usable with the
> compilers used to compile R and packages."

The Fedora-clang test fails with a symbol lookup error:

>> /data/gannet/ripley/R/packages/tests-clang/openmpt.Rcheck/00LOCK-openmpt/00new/openmpt/libs/openmpt.so:
>> undefined symbol:
>> _ZNK7openmpt6module15ctl_get_integerENSt3__117basic_string_viewIcNS1_11char_traitsIcEEEE

Translated using 'c++filt', the missing function turns out to be
openmpt::module::ctl_get_integer(std::__1::basic_string_view<char,
std::__1::char_traits<char> >) const. Why would libopenmpt.so be
missing a method for an std::string_view?

The problem here is that the Clang checks compile C++ code with the
"libc++" standard library that belongs to the LLVM project (same people
who develop Clang). The openmpt library, on the other hand, comes from
Fedora and is compiled and linked with the GNU "libstdc++" standard
library. The two standard libraries have very different internals and
can't be mixed. There's nothing you should do as a package developer to
make it work [1] (thank you Tomas for the clarification!).

I think that Prof. Ripley is asking you to make a configure test that
fails in these circumstances. Here's one that should work:

1. Write a C++ source file that includes OpenMPT headers and exports a
single function that calls the problematic OpenMPT function.

2. During ./configure, export the environment variables PKG_CPPFLAGS,
PKG_LIBS with the same contents that you intend to give to Makevars.

3. From the same ./configure script, call ${R_HOME}/bin/R CMD SHLIB to
compile the source file from (1) and link it into a shared library.

4. Call R again to dyn.load() the shared library. (Use
.Platform$dynlib.ext to figure out the file extension.)

-- 
Best regards,
Ivan

[1] https://stat.ethz.ch/pipermail/r-package-devel/2024q4/011326.html


From @jenk|n@ @end|ng |rom @tud|oj@u@  Sat Jan 18 17:37:27 2025
From: @jenk|n@ @end|ng |rom @tud|oj@u@ (Steven Jenkins)
Date: Sat, 18 Jan 2025 11:37:27 -0500
Subject: [R-pkg-devel] LaTeX Error: Unicode character not set up for use
 with LaTeX
Message-ID: <8E4AEA76-0732-4D74-95DC-C11C702857CC@studioj.us>

Longtime R user, first-time packager. Devtools are great; it?s pretty easy.

I?m trying to submit a package (https://github.com/jsjuni/massProps) that calculates mass properties and uncertainties for assembly trees. Very standard mechanical engineering stuff. The data are represented in a data frame and a tree.

It is customary in this and other fields to name an uncertainty parameter with ??? subscripted by the symbol of the parameter it characterizes. My code assumes a data frame with column names including ?_mass, ?_Cx, ?_Cy, ?_Ixx, etc. (If you can?t see it in your locale, it?s GREEK SMALL LETTER SIGMA, U+03C3.)

At least in my locale, these are valid names in R, so I used expressions like result$?_mass and input[row, ??_mass?] liberally. Everything works.

Unfortunately, CRAN doesn?t like that. check() complains about Unicode characters. Easy enough to fix. Putting escapes in the R names made the computation code ugly, so I replaced all the internals as, e.g., result$sigma_mass. Read and update operations on the data frame are isolated, so it was fairly straightforward to fix those as input[row, "\u03c3_mass?].

Again, all good. All unit tests pass, check() produces no errors, no warnings, no notes. Doxygen contents documenting the columns (which retain the Unicode character) render perfectly.

Then I get to check(manual = TRUE). LaTeX issues many complaints:

  ! LaTeX Error: Unicode character ? (U+03C3)
                 not set up for use with LaTeX.

After a good bit of searching, I can't find a fix. Bookdown suggests setting the LaTeX engine to ?xelatex?, but I don?t know whether that?s applicable (or possible) here.

So, two questions: (1) Is it bad practice to name columns like this in external serialization? Obviously, I can just use ?sigma_? everywhere, but I prefer it the way it is. (2) Is there some way to change either the Doxygen input or the LaTeX configuration to correct the problem? (Escaping the Doxygen input doesn?t work.)

Thanks in advance for your guidance.

Steve
	[[alternative HTML version deleted]]


From pep|jn@devr|e@ @end|ng |rom out|ook@com  Sun Jan 19 21:42:17 2025
From: pep|jn@devr|e@ @end|ng |rom out|ook@com (Pepijn de Vries)
Date: Sun, 19 Jan 2025 20:42:17 +0000
Subject: [R-pkg-devel] 
 Package builds on all systems except on Fedora with clang
In-Reply-To: <20250119224022.49a80684@Tarkus>
References: <AS8PR10MB4663D3B455E96FE0A05C7640A7E42@AS8PR10MB4663.EURPRD10.PROD.OUTLOOK.COM>
 <20250119224022.49a80684@Tarkus>
Message-ID: <AM8PR10MB46602CEED17D226A6520A93FA7E42@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>

Hi Ivan,

Thank you for the quick response. The linked discussion thread was also helpful.

I think I could write a similar test as used by `cpp11tesseract`:

https://github.com/pachadotdev/cpp11tesseract/blob/2ea8287ef2c27901446bafa402728014d99904d4/configure#L66-L85

Kind regards,

Pepijn

________________________________________
Van:?Ivan Krylov <ikrylov at disroot.org>
Verzonden:?zondag 19 januari 2025 20:40
Aan:?Pepijn de Vries <pepijn.devries at outlook.com>
CC:?Ivan Krylov via R-package-devel <r-package-devel at r-project.org>
Onderwerp:?Re: [R-pkg-devel] Package builds on all systems except on Fedora with clang
?
? Sun, 19 Jan 2025 17:07:51 +0000
Pepijn de Vries <pepijn.devries at outlook.com> ?????:

> He also mentioned that I "need to check in your configure script that
> the external library you need is available *and* usable with the
> compilers used to compile R and packages."

The Fedora-clang test fails with a symbol lookup error:

>> /data/gannet/ripley/R/packages/tests-clang/openmpt.Rcheck/00LOCK-openmpt/00new/openmpt/libs/openmpt.so:
>> undefined symbol:
>> _ZNK7openmpt6module15ctl_get_integerENSt3__117basic_string_viewIcNS1_11char_traitsIcEEEE

Translated using 'c++filt', the missing function turns out to be
openmpt::module::ctl_get_integer(std::__1::basic_string_view<char,
std::__1::char_traits<char> >) const. Why would libopenmpt.so be
missing a method for an std::string_view?

The problem here is that the Clang checks compile C++ code with the
"libc++" standard library that belongs to the LLVM project (same people
who develop Clang). The openmpt library, on the other hand, comes from
Fedora and is compiled and linked with the GNU "libstdc++" standard
library. The two standard libraries have very different internals and
can't be mixed. There's nothing you should do as a package developer to
make it work [1] (thank you Tomas for the clarification!).

I think that Prof. Ripley is asking you to make a configure test that
fails in these circumstances. Here's one that should work:

1. Write a C++ source file that includes OpenMPT headers and exports a
single function that calls the problematic OpenMPT function.

2. During ./configure, export the environment variables PKG_CPPFLAGS,
PKG_LIBS with the same contents that you intend to give to Makevars.

3. From the same ./configure script, call ${R_HOME}/bin/R CMD SHLIB to
compile the source file from (1) and link it into a shared library.

4. Call R again to dyn.load() the shared library. (Use
.Platform$dynlib.ext to figure out the file extension.)

--
Best regards,
Ivan

[1] https://stat.ethz.ch/pipermail/r-package-devel/2024q4/011326.html

From |kry|ov @end|ng |rom d|@root@org  Sun Jan 19 22:23:17 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 20 Jan 2025 00:23:17 +0300
Subject: [R-pkg-devel] 
 Package builds on all systems except on Fedora with clang
In-Reply-To: <AM8PR10MB46602CEED17D226A6520A93FA7E42@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>
References: <AS8PR10MB4663D3B455E96FE0A05C7640A7E42@AS8PR10MB4663.EURPRD10.PROD.OUTLOOK.COM>
 <20250119224022.49a80684@Tarkus>
 <AM8PR10MB46602CEED17D226A6520A93FA7E42@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <20250120002317.36e351e0@Tarkus>

? Sun, 19 Jan 2025 20:42:17 +0000
Pepijn de Vries <pepijn.devries at outlook.com> ?????:

> I think I could write a similar test as used by `cpp11tesseract`:
> 
> https://github.com/pachadotdev/cpp11tesseract/blob/2ea8287ef2c27901446bafa402728014d99904d4/configure#L66-L85

I should have replied to that thread too, but got swamped. If the
compiler flags are right, $CXX -c conftest.cpp will succeed the same way
that the individual object files currently successfully compile on
Fedora-clang [1]:

>> /usr/local/clang19/bin/clang++ -stdlib=libc++ -std=gnu++17
>> -I"/data/gannet/ripley/R/R-clang/include" -DNDEBUG -pthread
>> -I'/data/gannet/ripley/R/test-clang/cpp11/include' -isystem
>> /usr/local/clang19/include -I/usr/local/clang/include    -fpic  -O3
>> -Wall -pedantic -frtti -Wp,-D_FORTIFY_SOURCE=3
>> -Wno-missing-template-arg-list-after-template-kw  -DR_NO_REMAP -c
>> audio.cpp -o audio.o

Even linking the shared library is not enough, because that step
succeeds on Fedora-clang too:

>> /usr/local/clang19/bin/clang++ -stdlib=libc++ -std=gnu++17 -shared
>> -L/usr/local/clang/lib64 -L/usr/local/clang19/lib
>> -L/usr/local/clang19/lib/x86_64-unknown-linux-gnu
>> -L/usr/local/gcc14/lib64 -L/usr/local/lib64 -o openmpt.so audio.o
>> cpp11.o ctl.o format.o get_mod.o helpers.o info.o io.o module_ext.o
>> names.o render.o render_params.o repeat.o setpos.o state.o subsong.o
>> -lopenmpt -lportaudiocpp -lportaudio -lm -lpthread -lasound

Testing only the previous two steps will succeed during ./configure on
the Fedora-clang check and then fail to load the shared library during
package installation, like it currently does. Using R CMD SHLIB, on the
other hand, spares the effort of trying to figure out the right
compiler and giving it all the right flags.

Unrelated, but speaking of the default linker flags,

>> PKG_LIBS="-llibportaudio -llibportaudiocpp -llibopenmpt"

These are a bit counter-intuitive. When you ask the linker to link with
-lfoo, it tries to link with libfoo.a or libfoo.so, i.e. it prepends
the "lib" by itself.

Also unrelated, but is there OpenMPT in the macOS 'recipes' system? I
think it's the recommended way of making use of third-party code in
CRAN packages [2].

-- 
Best regards,
Ivan

[1]
https://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-fedora-clang/openmpt-00install.html

[2]
https://cran.r-project.org/web/packages/external_libs.html


From @|mon@urb@nek @end|ng |rom R-project@org  Mon Jan 20 01:48:15 2025
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Mon, 20 Jan 2025 13:48:15 +1300
Subject: [R-pkg-devel] LaTeX Error: Unicode character not set up for use
 with LaTeX
In-Reply-To: <8E4AEA76-0732-4D74-95DC-C11C702857CC@studioj.us>
References: <8E4AEA76-0732-4D74-95DC-C11C702857CC@studioj.us>
Message-ID: <8B0AEBA4-24D0-40C0-BBD6-850D9C116342@R-project.org>

Steven,


> On 19 Jan 2025, at 05:37, Steven Jenkins <sjenkins at studioj.us> wrote:
> 
> Longtime R user, first-time packager. Devtools are great; it?s pretty easy.
> 
> I?m trying to submit a package (https://github.com/jsjuni/massProps) that calculates mass properties and uncertainties for assembly trees. Very standard mechanical engineering stuff. The data are represented in a data frame and a tree.
> 
> It is customary in this and other fields to name an uncertainty parameter with ??? subscripted by the symbol of the parameter it characterizes. My code assumes a data frame with column names including ?_mass, ?_Cx, ?_Cy, ?_Ixx, etc. (If you can?t see it in your locale, it?s GREEK SMALL LETTER SIGMA, U+03C3.)
> 
> At least in my locale, these are valid names in R, so I used expressions like result$?_mass and input[row, ??_mass?] liberally. Everything works.
> 
> Unfortunately, CRAN doesn?t like that. check() complains about Unicode characters. Easy enough to fix. Putting escapes in the R names made the computation code ugly, so I replaced all the internals as, e.g., result$sigma_mass. Read and update operations on the data frame are isolated, so it was fairly straightforward to fix those as input[row, "\u03c3_mass?].
> 
> Again, all good. All unit tests pass, check() produces no errors, no warnings, no notes. Doxygen contents documenting the columns (which retain the Unicode character) render perfectly.
> 
> Then I get to check(manual = TRUE). LaTeX issues many complaints:
> 
>  ! LaTeX Error: Unicode character ? (U+03C3)
>                 not set up for use with LaTeX.
> 
> After a good bit of searching, I can't find a fix. Bookdown suggests setting the LaTeX engine to ?xelatex?, but I don?t know whether that?s applicable (or possible) here.
> 


No, it is not, it has to work with pdflatex.


> So, two questions: (1) Is it bad practice to name columns like this in external serialization?


Yes. See R-exts 1.6.3:
"First, consider carefully if you really need non-ASCII text. Some users of R will only be able to view correctly text in their native language group (e.g. Western European, Eastern European, Simplified Chinese) and ASCII. Other characters may not be rendered at all, rendered incorrectly, or cause your R code to give an error. "

> m
     sigma_mass
[1,]  -2.173881
[2,]   1.184118
[3,]  -1.295566

is a lot more readable and usable than 

> m
            <U+03C3>_mass
[1,]     -2.173881
[2,]      1.184118
[3,]     -1.295566


> Obviously, I can just use ?sigma_? everywhere, but I prefer it the way it is.


I suspect you may be the a very small minority as non-ASCII characters are really problematic in code as they require special input methods, making your symbols mostly unusable. Unicode has its place in data as text, e.g. when rendering names or words in other languages, but even there they require careful handling (e.g., still won't work in LaTeX output). Row names are fine as long as they reflect real data (e.g. names/words), but in your case it?s just an unnecessarily awkward use of a symbol so it does not fall into that category.

Cheers,
Simon



> (2) Is there some way to change either the Doxygen input or the LaTeX configuration to correct the problem? (Escaping the Doxygen input doesn?t work.)
> 
> Thanks in advance for your guidance.
> 
> Steve
> [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> 


From @jenk|n@ @end|ng |rom @tud|oj@u@  Mon Jan 20 04:13:57 2025
From: @jenk|n@ @end|ng |rom @tud|oj@u@ (Steven Jenkins)
Date: Sun, 19 Jan 2025 22:13:57 -0500
Subject: [R-pkg-devel] LaTeX Error: Unicode character not set up for use
 with LaTeX
In-Reply-To: <8B0AEBA4-24D0-40C0-BBD6-850D9C116342@R-project.org>
References: <8E4AEA76-0732-4D74-95DC-C11C702857CC@studioj.us>
 <8B0AEBA4-24D0-40C0-BBD6-850D9C116342@R-project.org>
Message-ID: <B716A48E-0DB7-49DD-B298-7EC91DAAA465@studioj.us>

Simon,

Thanks for the clear and direct answer. I was prepared for that to be the case :-).

Steve

> On Jan 19, 2025, at 7:48?PM, Simon Urbanek <simon.urbanek at R-project.org> wrote:
> 
> Steven,
> 
> 
>> On 19 Jan 2025, at 05:37, Steven Jenkins <sjenkins at studioj.us> wrote:
>> 
>> Longtime R user, first-time packager. Devtools are great; it?s pretty easy.
>> 
>> I?m trying to submit a package (https://github.com/jsjuni/massProps) that calculates mass properties and uncertainties for assembly trees. Very standard mechanical engineering stuff. The data are represented in a data frame and a tree.
>> 
>> It is customary in this and other fields to name an uncertainty parameter with ??? subscripted by the symbol of the parameter it characterizes. My code assumes a data frame with column names including ?_mass, ?_Cx, ?_Cy, ?_Ixx, etc. (If you can?t see it in your locale, it?s GREEK SMALL LETTER SIGMA, U+03C3.)
>> 
>> At least in my locale, these are valid names in R, so I used expressions like result$?_mass and input[row, ??_mass?] liberally. Everything works.
>> 
>> Unfortunately, CRAN doesn?t like that. check() complains about Unicode characters. Easy enough to fix. Putting escapes in the R names made the computation code ugly, so I replaced all the internals as, e.g., result$sigma_mass. Read and update operations on the data frame are isolated, so it was fairly straightforward to fix those as input[row, "\u03c3_mass?].
>> 
>> Again, all good. All unit tests pass, check() produces no errors, no warnings, no notes. Doxygen contents documenting the columns (which retain the Unicode character) render perfectly.
>> 
>> Then I get to check(manual = TRUE). LaTeX issues many complaints:
>> 
>> ! LaTeX Error: Unicode character ? (U+03C3)
>>                not set up for use with LaTeX.
>> 
>> After a good bit of searching, I can't find a fix. Bookdown suggests setting the LaTeX engine to ?xelatex?, but I don?t know whether that?s applicable (or possible) here.
>> 
> 
> 
> No, it is not, it has to work with pdflatex.
> 
> 
>> So, two questions: (1) Is it bad practice to name columns like this in external serialization?
> 
> 
> Yes. See R-exts 1.6.3:
> "First, consider carefully if you really need non-ASCII text. Some users of R will only be able to view correctly text in their native language group (e.g. Western European, Eastern European, Simplified Chinese) and ASCII. Other characters may not be rendered at all, rendered incorrectly, or cause your R code to give an error. "
> 
>> m
>     sigma_mass
> [1,]  -2.173881
> [2,]   1.184118
> [3,]  -1.295566
> 
> is a lot more readable and usable than 
> 
>> m
>            <U+03C3>_mass
> [1,]     -2.173881
> [2,]      1.184118
> [3,]     -1.295566
> 
> 
>> Obviously, I can just use ?sigma_? everywhere, but I prefer it the way it is.
> 
> 
> I suspect you may be the a very small minority as non-ASCII characters are really problematic in code as they require special input methods, making your symbols mostly unusable. Unicode has its place in data as text, e.g. when rendering names or words in other languages, but even there they require careful handling (e.g., still won't work in LaTeX output). Row names are fine as long as they reflect real data (e.g. names/words), but in your case it?s just an unnecessarily awkward use of a symbol so it does not fall into that category.
> 
> Cheers,
> Simon
> 
> 
> 
>> (2) Is there some way to change either the Doxygen input or the LaTeX configuration to correct the problem? (Escaping the Doxygen input doesn?t work.)
>> 
>> Thanks in advance for your guidance.
>> 
>> Steve
>> [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-package-devel at r-project.org <mailto:R-package-devel at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-package-devel


	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Mon Jan 20 16:03:36 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Mon, 20 Jan 2025 09:03:36 -0600
Subject: [R-pkg-devel] 
 Package builds on all systems except on Fedora with clang
In-Reply-To: <AM8PR10MB46602CEED17D226A6520A93FA7E42@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>
References: <AS8PR10MB4663D3B455E96FE0A05C7640A7E42@AS8PR10MB4663.EURPRD10.PROD.OUTLOOK.COM>
 <20250119224022.49a80684@Tarkus>
 <AM8PR10MB46602CEED17D226A6520A93FA7E42@AM8PR10MB4660.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <26510.26056.951900.698722@rob.eddelbuettel.com>


On 19 January 2025 at 20:42, Pepijn de Vries wrote:
| I think I could write a similar test as used by `cpp11tesseract`:
| 
| https://github.com/pachadotdev/cpp11tesseract/blob/2ea8287ef2c27901446bafa402728014d99904d4/configure#L66-L85

Taking an example from a package not on CRAN 'for policy violations' may not
be the safest best.

`autoconf` has included the ability to conduction these tests for a long
time. Here is an (old) snippet from RProtoBuf which uses a test file to
assert we have a recent enough version:

   ## also check for minimum version
   AC_MSG_CHECKING([if ProtoBuf version >= 2.2.0])
   AC_RUN_IFELSE([AC_LANG_SOURCE([[
   #include <google/protobuf/stubs/common.h>
   int main() {
      if (GOOGLE_PROTOBUF_VERSION >= 2001000) {
           exit (0);
      } else {
           exit(1);
      }
   }
   ]])],
   [pb_version_ok=yes],
   [pb_version_ok=no],
   [pb_version_ok=yes])
   if test x"${pb_version_ok}" = x"no"; then
       AC_MSG_ERROR([Need ProtoBuf version >= 2.2.0])
   else
       AC_MSG_RESULT([yes])
   fi

Note that this happens after we found suitable compiler and linker switches.
And of course, switching to `autoconf` is no small task either. But getting
an external library to build reliably on all platforms is one of the harder
things to set up at CRAN.

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From john@c|@rke @end|ng |rom corner@tonenw@com  Tue Jan 21 11:57:46 2025
From: john@c|@rke @end|ng |rom corner@tonenw@com (John Clarke)
Date: Tue, 21 Jan 2025 11:57:46 +0100
Subject: [R-pkg-devel] Rcpp: how best to include source from another Github
 repository
Message-ID: <CAF0e1n9yrb+M+csGMeYpfFm35-fe4s4B5-8H0fQ-ov8yckEqZQ@mail.gmail.com>

Hi folks,

I have an Rcpp package I'm developing. All but one of the cpp source code
files are pulled from the original/authoritative (CLI) version of the
application. The only unique cpp source code to the Rcpp package is my
wrapper.cpp which contains the Rcpp interface. This approach works fine,
but every time we make changes to the original CLI repository, it requires
a manual (and duplicate) commit to my Rcpp repo. This is not ideal from a
source tracking perspective and is a DRY violation.

What is the recommended way of maintaining the shared cpp code in a Rcpp
repo? Ideally, it would be nice to be able to pull the files from the
source repo using a tag/hash so that the only code change in the Rcpp repo
would be that reference rather than all the changes to the shared source.
It would also be nice to use some sort of symlinkish setup during
development to allow quick testing before making commits in the original
CLI repo. Is this possible? Recommended? (we can assume dev is on MacOS or
Linux)

Thanks,

-John

John Clarke | Senior Technical Advisor |
Cornerstone Systems Northwest | john.clarke at cornerstonenw.com

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Tue Jan 21 13:04:53 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 21 Jan 2025 15:04:53 +0300
Subject: [R-pkg-devel] 
 Rcpp: how best to include source from another Github repository
In-Reply-To: <CAF0e1n9yrb+M+csGMeYpfFm35-fe4s4B5-8H0fQ-ov8yckEqZQ@mail.gmail.com>
References: <CAF0e1n9yrb+M+csGMeYpfFm35-fe4s4B5-8H0fQ-ov8yckEqZQ@mail.gmail.com>
Message-ID: <20250121150453.6d63147a@arachnoid>

? Tue, 21 Jan 2025 11:57:46 +0100
John Clarke <john.clarke at cornerstonenw.com> ?????:

> Ideally, it would be nice to be able to pull the files from the
> source repo using a tag/hash so that the only code change in the Rcpp
> repo would be that reference rather than all the changes to the
> shared source.

I've been using Git submodules for this purpose:

https://codeberg.org/aitap/Ropj/src/branch/master/src

https://git-scm.com/book/en/v2/Git-Tools-Submodules

Every time the upstream changes I have to update the commit pointer in
my repository too, but other than that, it's been working fine. My
.Rbuildignore filters out all the unnecessary files included in the
upstream repository, leaving only the relevant source code in the
resulting source package.

The resulting repository must be cloned with --recurse-submodules (or,
if forgotten, must be initialised with git submodule update --init);
further updates to the tracked commit pointer must be applied with git
submodule update. If the referenced repository becomes unavailable, it
will be impossible to build the package.

-- 
Best regards,
Ivan


From p@kr|v|t@ky @end|ng |rom un@w@edu@@u  Wed Jan 22 13:20:38 2025
From: p@kr|v|t@ky @end|ng |rom un@w@edu@@u (Pavel Krivitsky)
Date: Wed, 22 Jan 2025 12:20:38 +0000
Subject: [R-pkg-devel] 
 Best practices for built version checking in packages
 LinkingTo others?
In-Reply-To: <8d9b8f509ae8ea4dc65928d0285e939ef9272442.camel@unsw.edu.au>
References: <98a863d7814e843ef600bfb67e742109edc8fa15.camel@unsw.edu.au>
 <20250117165057.7d994670@arachnoid>
 <8d9b8f509ae8ea4dc65928d0285e939ef9272442.camel@unsw.edu.au>
Message-ID: <8db72b652984d133b6189786a095d35633f5420b.camel@unsw.edu.au>

Dear All,

I think I have something that works and may even work as a more general
API for checking for LinkingTo ABI compatibility.

It's in 'ergm' 4.8.1 on CRAN, but would it be useful to anyone else if
I posted an explanation of how it works somewhere? Would a package that
provides this API for saving and checking ABI versions be useful to
anyone?

				Best,
				Pavel

On Sun, 2025-01-19 at 05:31 +0000, Pavel Krivitsky via R-package-devel
wrote:
> Thanks, Ivan! Replies below.
> 
> On Fri, 2025-01-17 at 16:50 +0300, Ivan Krylov wrote:
> > ? Fri, 17 Jan 2025 10:21:27 +0000
> > Pavel Krivitsky via R-package-devel <r-package-devel at r-project.org>
> > ?????:
> > 
> > > ?? 1. What is the best way to save this information? I have a
> > > ????? rudimentary implementation [1]
> > 
> > For now, this is the best way we have. Export the ABI version as an
> > include-time constant and as a registered callable. The LinkingTo
> > reverse dependencies can give the include-time constant to the
> > registered callable to compare the two versions.
> 
> Ben Bolker pointed out that since the code in R/ is executed at
> build-
> time, it is also possible to store the build-time ABI information
> entirely in R; the downside of this approach is that it requires
> instrumenting every client package rather than just the library
> package.
> 
> > I agree that we could do better and introduce an ABIversion: field
> > to
> > the DESCRIPTION file. R CMD INSTALL would write down the current
> > ABIversion of every package that the current package is LinkingTo
> > (into the installed package's DESCRIPTION or Meta/features.rds).
> > Later, the namespace loader would check the ABI versions and
> > provide
> > an informative message in case a LinkingTo dependency is updated
> > with
> > an incremented ABI version. A machine-readable list of ABI-level
> > dependencies should simplify the lives of the binary package
> > maintainers as well.
> 
> Yes, that would be great to have. (One nitpick: not just incremented,
> but different in either direction.)
> 
> AFAIK, for those platforms that use binaries, there is already a
> mechanism for downloading a different ZIP for a different version of
> R,
> but I believe it's accomplished simply by having a directory for
> every
> version of R with a potentially different ABI.
> 
> I suppose this could be generalised along the lines of a directory
> hierarchy of the form
> 
> /bin/windows/contrib/RVERSION/PKG_ABIVERSION/.../PKG_ABIVERSION/PKG_P
> KGVERSION.zip
> 
> with a nesting level for every LinkingTo package, in lexicographic
> order. Then, given the installed R version and the installed versions
> of each package in the LinkingTo list, a unique URL can be
> constructed.
> However, I don't know how practical this is and how likely to be
> implemented in the foreseeable future.
> 
> > > ?? 2. How to best test the C API without making updates
> > > impossible?
> > 
> > Would abi-compliance-checker [2] have helped there?
> 
> I meant specifically in the context of R CMD check; the only want to
> fully test the C API and associated facilities is to actually install
> the client package and see if it works.
> 
> That having been said, 'ergm' may be unusual in this, since the API
> is
> mostly used as a way for others to implement calculation of graph
> statistics that are then operated on by functions in 'ergm'. That is,
> rather than simply offering C functions for the client packages to
> use,
> 'ergm' calls C functions from those packages that it locates via
> R_FindSymbol(). Thus, it is helpful to test it as a part of 'ergm'
> itself rather than just reverse-dependency checks.
> 
> > > ?? 3. What should be done in case of a mismatch?
> > 
> > It's hard to guarantee anything when the ABI is broken. Maybe it's
> > completely harmless because your code will know that the new
> > structure member is not initialised. Maybe the wrong stack layout
> > will crash the process due to a return address mismatch, dooming
> > the
> > process from the first function call.k
> > 
> > > ???????? 1. Is there a way for 'ergm' to detect when a package
> > > LinkingTo it is being loaded?
> > 
> > With inline functions, you could make your every API call perform
> > ABI
> > version checking, but that obviously comes with potential
> > performance
> > problems:
> 
> The reason I ask is that the best time to inform the user of an ABI
> change is when the client package is loaded, and it would be helpful
> if
> this could be done without modifying the client package.
> 
> Is there a mechanism for the library package to monitor packages
> being
> loaded, and for each one check if it's LinkingTo it to do the version
> check?
> 
> > > ???????? 2. What should happen if a mismatch is detected? Should
> > > the
> > > loading be blocked (e.g., by having .onLoad() throw an error), or
> > > should it lead to a "use at your own risk" type warning?
> > 
> > The safest option would be to signal an error before any of the
> > potentially incompatible functions are called. It's probably
> > pragmatic to provide an "I know what I'm doing, void my warranty"
> > emergency override.
> 
> Probably an options() setting.
> 
> 				Best,
> 				Pavel
> 
> ______________________________________________
> R-package-devel at r-project.org?mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From john@c|@rke @end|ng |rom corner@tonenw@com  Wed Jan 22 14:33:22 2025
From: john@c|@rke @end|ng |rom corner@tonenw@com (John Clarke)
Date: Wed, 22 Jan 2025 14:33:22 +0100
Subject: [R-pkg-devel] 
 Rcpp: how best to include source from another Github repository
In-Reply-To: <20250121150453.6d63147a@arachnoid>
References: <CAF0e1n9yrb+M+csGMeYpfFm35-fe4s4B5-8H0fQ-ov8yckEqZQ@mail.gmail.com>
 <20250121150453.6d63147a@arachnoid>
Message-ID: <CAF0e1n_tG0BJe-Gs1tL5ah-Zx0A+VB2ZW_+i3L-0c3gaf=nV=g@mail.gmail.com>

Thanks Ivan, this is helpful. I'll do some more research. It would be nice
to have an Rcpp standard/recommended way to do this. I don't want to have a
non-standard ./src or ./data folder structure for my Rcpp package, but
these are the two relevant folders in my original repository. Maybe with
some sort of synlinking I could achieve this 'custom' folder/file mapping.
-John

On Tue, Jan 21, 2025 at 1:05?PM Ivan Krylov <ikrylov at disroot.org> wrote:

> ? Tue, 21 Jan 2025 11:57:46 +0100
> John Clarke <john.clarke at cornerstonenw.com> ?????:
>
> > Ideally, it would be nice to be able to pull the files from the
> > source repo using a tag/hash so that the only code change in the Rcpp
> > repo would be that reference rather than all the changes to the
> > shared source.
>
> I've been using Git submodules for this purpose:
>
> https://codeberg.org/aitap/Ropj/src/branch/master/src
>
> https://git-scm.com/book/en/v2/Git-Tools-Submodules
>
> Every time the upstream changes I have to update the commit pointer in
> my repository too, but other than that, it's been working fine. My
> .Rbuildignore filters out all the unnecessary files included in the
> upstream repository, leaving only the relevant source code in the
> resulting source package.
>
> The resulting repository must be cloned with --recurse-submodules (or,
> if forgotten, must be initialised with git submodule update --init);
> further updates to the tracked commit pointer must be applied with git
> submodule update. If the referenced repository becomes unavailable, it
> will be impossible to build the package.
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From th|b@u|t@v@tter @end|ng |rom gm@||@com  Wed Jan 22 20:53:08 2025
From: th|b@u|t@v@tter @end|ng |rom gm@||@com (Thibault Vatter)
Date: Wed, 22 Jan 2025 20:53:08 +0100
Subject: [R-pkg-devel] 
 Rcpp: how best to include source from another Github repository
In-Reply-To: <CAF0e1n_tG0BJe-Gs1tL5ah-Zx0A+VB2ZW_+i3L-0c3gaf=nV=g@mail.gmail.com>
References: <CAF0e1n9yrb+M+csGMeYpfFm35-fe4s4B5-8H0fQ-ov8yckEqZQ@mail.gmail.com>
 <20250121150453.6d63147a@arachnoid>
 <CAF0e1n_tG0BJe-Gs1tL5ah-Zx0A+VB2ZW_+i3L-0c3gaf=nV=g@mail.gmail.com>
Message-ID: <CAFyih6DGV-08Zej6+F=wwS_8HC7x7tNiCi_X+R+isJjqBAkYPw@mail.gmail.com>

There is balance between DRY, safety, and customization needs. The
symlinkish approach would be "dangerous" imo, because you can't guarantee
the wrapper.cpp will stay compatible with changes in the underlying C++
library.

The submodule approach works well. Alternatives that I know of are:


   - a script that pulls the latest sources in the standalone C++ library
   and does things like adding a preprocessor macro, see e.g. rvinecopulib
   - a "patches" folder with patch files in diff format (.patch or .diff),
   see e.g. RcppEigen

Either way, such scripts or patches folders have to be excluded from being
put into the package via the .Rbuildignore.

On Wed, Jan 22, 2025, 2:33?PM John Clarke <john.clarke at cornerstonenw.com>
wrote:

> Thanks Ivan, this is helpful. I'll do some more research. It would be nice
> to have an Rcpp standard/recommended way to do this. I don't want to have a
> non-standard ./src or ./data folder structure for my Rcpp package, but
> these are the two relevant folders in my original repository. Maybe with
> some sort of synlinking I could achieve this 'custom' folder/file mapping.
> -John
>
> On Tue, Jan 21, 2025 at 1:05?PM Ivan Krylov <ikrylov at disroot.org> wrote:
>
> > ? Tue, 21 Jan 2025 11:57:46 +0100
> > John Clarke <john.clarke at cornerstonenw.com> ?????:
> >
> > > Ideally, it would be nice to be able to pull the files from the
> > > source repo using a tag/hash so that the only code change in the Rcpp
> > > repo would be that reference rather than all the changes to the
> > > shared source.
> >
> > I've been using Git submodules for this purpose:
> >
> > https://codeberg.org/aitap/Ropj/src/branch/master/src
> >
> > https://git-scm.com/book/en/v2/Git-Tools-Submodules
> >
> > Every time the upstream changes I have to update the commit pointer in
> > my repository too, but other than that, it's been working fine. My
> > .Rbuildignore filters out all the unnecessary files included in the
> > upstream repository, leaving only the relevant source code in the
> > resulting source package.
> >
> > The resulting repository must be cloned with --recurse-submodules (or,
> > if forgotten, must be initialised with git submodule update --init);
> > further updates to the tracked commit pointer must be applied with git
> > submodule update. If the referenced repository becomes unavailable, it
> > will be impossible to build the package.
> >
> > --
> > Best regards,
> > Ivan
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From john@c|@rke @end|ng |rom corner@tonenw@com  Thu Jan 23 14:21:18 2025
From: john@c|@rke @end|ng |rom corner@tonenw@com (John Clarke)
Date: Thu, 23 Jan 2025 14:21:18 +0100
Subject: [R-pkg-devel] 
 Rcpp: how best to include source from another Github repository
In-Reply-To: <CAFyih6DGV-08Zej6+F=wwS_8HC7x7tNiCi_X+R+isJjqBAkYPw@mail.gmail.com>
References: <CAF0e1n9yrb+M+csGMeYpfFm35-fe4s4B5-8H0fQ-ov8yckEqZQ@mail.gmail.com>
 <20250121150453.6d63147a@arachnoid>
 <CAF0e1n_tG0BJe-Gs1tL5ah-Zx0A+VB2ZW_+i3L-0c3gaf=nV=g@mail.gmail.com>
 <CAFyih6DGV-08Zej6+F=wwS_8HC7x7tNiCi_X+R+isJjqBAkYPw@mail.gmail.com>
Message-ID: <CAF0e1n_daqkBaAUsWKTJsXhqzTudQUu4Oqt37djrtc+E++btvA@mail.gmail.com>

Thank you Dirk and Thibault for your additional tips and ideas.

I took a look at the vignette for *rcppcorels* and noted that this is
exactly the model/pattern I used to create my package. And it appears that
the /src files are simply copied from the external *corels* C++ library
into the rcppcorel's /src folder. And committed twice: once in the external
C++ repo and again in the rcppcorels repo. That is what I do now, but I
wasn't satisfied with the double commits and also I'd really like users of
the R package to have a reference/version/tag to confirm that what they
have in the R package is the same as a particular release of the C++ repo.

But in the end, it appears that there is no easy (and robust) way to do
this other than copy the files (via script or manually) and re-commit
changes in both repos. I suppose I could add a reference to the tag from
the C++ library, but this step can easily get lost/forgotten and is a
definite DRY violation. Maybe an import/copy script could help with that.

Thanks again for your help and suggestions.

-John











On Wed, Jan 22, 2025 at 8:53?PM Thibault Vatter <thibault.vatter at gmail.com>
wrote:

> There is balance between DRY, safety, and customization needs. The
> symlinkish approach would be "dangerous" imo, because you can't guarantee
> the wrapper.cpp will stay compatible with changes in the underlying C++
> library.
>
> The submodule approach works well. Alternatives that I know of are:
>
>
>    - a script that pulls the latest sources in the standalone C++ library
>    and does things like adding a preprocessor macro, see e.g. rvinecopulib
>    - a "patches" folder with patch files in diff format (.patch or
>    .diff), see e.g. RcppEigen
>
> Either way, such scripts or patches folders have to be excluded from being
> put into the package via the .Rbuildignore.
>
> On Wed, Jan 22, 2025, 2:33?PM John Clarke <john.clarke at cornerstonenw.com>
> wrote:
>
>> Thanks Ivan, this is helpful. I'll do some more research. It would be nice
>> to have an Rcpp standard/recommended way to do this. I don't want to have
>> a
>> non-standard ./src or ./data folder structure for my Rcpp package, but
>> these are the two relevant folders in my original repository. Maybe with
>> some sort of synlinking I could achieve this 'custom' folder/file mapping.
>> -John
>>
>> On Tue, Jan 21, 2025 at 1:05?PM Ivan Krylov <ikrylov at disroot.org> wrote:
>>
>> > ? Tue, 21 Jan 2025 11:57:46 +0100
>> > John Clarke <john.clarke at cornerstonenw.com> ?????:
>> >
>> > > Ideally, it would be nice to be able to pull the files from the
>> > > source repo using a tag/hash so that the only code change in the Rcpp
>> > > repo would be that reference rather than all the changes to the
>> > > shared source.
>> >
>> > I've been using Git submodules for this purpose:
>> >
>> > https://codeberg.org/aitap/Ropj/src/branch/master/src
>> >
>> > https://git-scm.com/book/en/v2/Git-Tools-Submodules
>> >
>> > Every time the upstream changes I have to update the commit pointer in
>> > my repository too, but other than that, it's been working fine. My
>> > .Rbuildignore filters out all the unnecessary files included in the
>> > upstream repository, leaving only the relevant source code in the
>> > resulting source package.
>> >
>> > The resulting repository must be cloned with --recurse-submodules (or,
>> > if forgotten, must be initialised with git submodule update --init);
>> > further updates to the tracked commit pointer must be applied with git
>> > submodule update. If the referenced repository becomes unavailable, it
>> > will be impossible to build the package.
>> >
>> > --
>> > Best regards,
>> > Ivan
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-package-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>>
>

	[[alternative HTML version deleted]]


From jon@th@n @end|ng |rom berr|@ch@b|z  Tue Jan 21 12:04:52 2025
From: jon@th@n @end|ng |rom berr|@ch@b|z (Jonathan Berrisch)
Date: Tue, 21 Jan 2025 12:04:52 +0100
Subject: [R-pkg-devel] 
 Rcpp: how best to include source from another Github repository
In-Reply-To: <CAF0e1n9yrb+M+csGMeYpfFm35-fe4s4B5-8H0fQ-ov8yckEqZQ@mail.gmail.com>
References: <CAF0e1n9yrb+M+csGMeYpfFm35-fe4s4B5-8H0fQ-ov8yckEqZQ@mail.gmail.com>
Message-ID: <e800be15-576a-477a-8de5-69cf9733e244@berrisch.biz>

Hi John,

first of all: I'm not an expert on this and don't really know if there 
is a recommended way.

However, you may look at my 'rcpptimer' package and how it includes 
'cpptimer' as a submodule.

You can find the repository here: https://github.com/BerriJ/rcpptimer

And here you can see 'cpptimer' which is included as a submodule: 
https://github.com/BerriJ/rcpptimer/tree/main/inst/include

Whenever I make commits to 'cpptimer' I have to update the submodule 
(basically changing at what commit I want to have that submodule 
included 'git submodule update --remote'). You'll find good 
documentation about submodules online.

Maybe that helps.

Best Regards,

Jonathan / BerriJ


On 1/21/25 11:57, John Clarke wrote:
> Hi folks,
>
> I have an Rcpp package I'm developing. All but one of the cpp source code
> files are pulled from the original/authoritative (CLI) version of the
> application. The only unique cpp source code to the Rcpp package is my
> wrapper.cpp which contains the Rcpp interface. This approach works fine,
> but every time we make changes to the original CLI repository, it requires
> a manual (and duplicate) commit to my Rcpp repo. This is not ideal from a
> source tracking perspective and is a DRY violation.
>
> What is the recommended way of maintaining the shared cpp code in a Rcpp
> repo? Ideally, it would be nice to be able to pull the files from the
> source repo using a tag/hash so that the only code change in the Rcpp repo
> would be that reference rather than all the changes to the shared source.
> It would also be nice to use some sort of symlinkish setup during
> development to allow quick testing before making commits in the original
> CLI repo. Is this possible? Recommended? (we can assume dev is on MacOS or
> Linux)
>
> Thanks,
>
> -John
>
> John Clarke | Senior Technical Advisor |
> Cornerstone Systems Northwest | john.clarke at cornerstonenw.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>


From john@c|@rke @end|ng |rom corner@tonenw@com  Thu Jan 23 15:22:09 2025
From: john@c|@rke @end|ng |rom corner@tonenw@com (John Clarke)
Date: Thu, 23 Jan 2025 15:22:09 +0100
Subject: [R-pkg-devel] 
 Rcpp: how best to include source from another Github repository
In-Reply-To: <e800be15-576a-477a-8de5-69cf9733e244@berrisch.biz>
References: <CAF0e1n9yrb+M+csGMeYpfFm35-fe4s4B5-8H0fQ-ov8yckEqZQ@mail.gmail.com>
 <e800be15-576a-477a-8de5-69cf9733e244@berrisch.biz>
Message-ID: <CAF0e1n_0UQOv2PejP7hky1c0bo7Ke+G8zvBxVs+BUR5yUOsw4Q@mail.gmail.com>

Thanks Jonathan, this is helpful. I'm just a bit concerned based on other
comments that submodules might not be compatible with CRAN and/or other CI
runners. Plus, I only want a few cpp files copied over.

On Thu, Jan 23, 2025 at 3:19?PM Jonathan Berrisch <jonathan at berrisch.biz>
wrote:

> Hi John,
>
> first of all: I'm not an expert on this and don't really know if there
> is a recommended way.
>
> However, you may look at my 'rcpptimer' package and how it includes
> 'cpptimer' as a submodule.
>
> You can find the repository here: https://github.com/BerriJ/rcpptimer
>
> And here you can see 'cpptimer' which is included as a submodule:
> https://github.com/BerriJ/rcpptimer/tree/main/inst/include
>
> Whenever I make commits to 'cpptimer' I have to update the submodule
> (basically changing at what commit I want to have that submodule
> included 'git submodule update --remote'). You'll find good
> documentation about submodules online.
>
> Maybe that helps.
>
> Best Regards,
>
> Jonathan / BerriJ
>
>
> On 1/21/25 11:57, John Clarke wrote:
> > Hi folks,
> >
> > I have an Rcpp package I'm developing. All but one of the cpp source code
> > files are pulled from the original/authoritative (CLI) version of the
> > application. The only unique cpp source code to the Rcpp package is my
> > wrapper.cpp which contains the Rcpp interface. This approach works fine,
> > but every time we make changes to the original CLI repository, it
> requires
> > a manual (and duplicate) commit to my Rcpp repo. This is not ideal from a
> > source tracking perspective and is a DRY violation.
> >
> > What is the recommended way of maintaining the shared cpp code in a Rcpp
> > repo? Ideally, it would be nice to be able to pull the files from the
> > source repo using a tag/hash so that the only code change in the Rcpp
> repo
> > would be that reference rather than all the changes to the shared source.
> > It would also be nice to use some sort of symlinkish setup during
> > development to allow quick testing before making commits in the original
> > CLI repo. Is this possible? Recommended? (we can assume dev is on MacOS
> or
> > Linux)
> >
> > Thanks,
> >
> > -John
> >
> > John Clarke | Senior Technical Advisor |
> > Cornerstone Systems Northwest | john.clarke at cornerstonenw.com
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-package-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-package-devel
> >
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Thu Jan 23 15:47:49 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Thu, 23 Jan 2025 08:47:49 -0600
Subject: [R-pkg-devel] 
 Rcpp: how best to include source from another Github repository
In-Reply-To: <e800be15-576a-477a-8de5-69cf9733e244@berrisch.biz>
References: <CAF0e1n9yrb+M+csGMeYpfFm35-fe4s4B5-8H0fQ-ov8yckEqZQ@mail.gmail.com>
 <e800be15-576a-477a-8de5-69cf9733e244@berrisch.biz>
Message-ID: <26514.22165.946108.992254@rob.eddelbuettel.com>


On 21 January 2025 at 12:04, Jonathan Berrisch wrote:
| first of all: I'm not an expert on this and don't really know if there 
| is a recommended way.
| 
| However, you may look at my 'rcpptimer' package and how it includes 
| 'cpptimer' as a submodule.
| 
| You can find the repository here: https://github.com/BerriJ/rcpptimer

I had written a longer (private) email to John expressing the view that git
submodules "were once more 'en vogue'" but one sees them less these days.
One reason is that they break some (somewhat standard) workflows, see below.

Overall, this is "no win" situation. You can include the files in the package
as a copy [2] enlarging the package, build process, etc but arguably making
it more robust, or you can keep it external which is cleaner -- but harder as
you now have to ensure users (and CRAN !) can get / have that library.

So it is all tradeoffs one has to make.

Dirk


[1] Log from a standard r2u Ubuntu container, `git` and `ssh` added as needed:

root at 4163d5544547:/# installGithub.r https://github.com/BerriJ/rcpptimer
Downloading GitHub repo BerriJ/rcpptimer at HEAD
'/usr/bin/git' clone --depth 1 --no-hardlinks --recurse-submodules git at github.com:BerriJ/cpptimer.git /tmp/remotes257564d64e0/BerriJ-rcpptimer-35ca024/inst/include/cpptimer
Cloning into '/tmp/remotes257564d64e0/BerriJ-rcpptimer-35ca024/inst/include/cpptimer'...
The authenticity of host 'github.com (140.82.113.3)' can't be established.
ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU.
This key is not known by any other names.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added 'github.com' (ED25519) to the list of known hosts.
git at github.com: Permission denied (publickey).
fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.
Error: Failed to install 'rcpptimer' from GitHub:
  Command failed (128)
In addition: Warning message:
In system(full, intern = TRUE, ignore.stderr = quiet) :
  running command ''/usr/bin/git' clone --depth 1 --no-hardlinks --recurse-submodules git at github.com:BerriJ/cpptimer.git /tmp/remotes257564d64e0/BerriJ-rcpptimer-35ca024/inst/include/cpptimer' had status 128 and error message 'Function not implemented'
root at 4163d5544547:/# 
exit


[2] The "Rcpp-library" vignette John refers to also mentions (IIRC) that this
is preferable for smaller libraries; its 'corels' example fits that
description.  These days other authors also vendor entire applications such
as whole SQL engines: ?\_(?)_/?  I just updated qlcal on CRAN, it explicitly
copies the calendaring (subset) from QuantLib as I learned over 20 years that
users have difficulties with that large library. Tradeoffs.

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From murr@y@e||ord @end|ng |rom ot@go@@c@nz  Fri Jan 24 02:13:44 2025
From: murr@y@e||ord @end|ng |rom ot@go@@c@nz (Murray Efford)
Date: Fri, 24 Jan 2025 01:13:44 +0000
Subject: [R-pkg-devel] Pre-test failure with RcppParallel on Windows R-devel
Message-ID: <SY2PR01MB2539F7680A28FE027A7BF77EACE32@SY2PR01MB2539.ausprd01.prod.outlook.com>

Submitting secr 5.2.0 I get this pre-test installation ERROR which is opaque to me. I haven't changed the relevant code, and the package passes checks on Winbuilder (below) and other systems (with a false positive URL fail NOTE).

* checking whether package 'secr' can be installed ... ERROR Installation failed. See 'd:/RCompile/CRANincoming/R-devel/secr.Rcheck/00install.out' for details.
which includes
undefined reference to `RcppParallel::tbbParallelFor(unsigned long long, unsigned long long, RcppParallel::Worker&, unsigned long long, int)'

Winbuilder and the CRAN precheck appear to use identical settings:

* using log directory 'd:/RCompile/CRANguest/R-devel/secr.Rcheck'
* using R Under development (unstable) (2025-01-22 r87618 ucrt)
* using platform: x86_64-w64-mingw32
* R was compiled by
    gcc.exe (GCC) 13.3.0
    GNU Fortran (GCC) 13.3.0
* running under: Windows Server 2022 x64 (build 20348)

Any ideas? I'm guessing it's a transient CRAN problem.




	[[alternative HTML version deleted]]


From kev|nu@hey @end|ng |rom gm@||@com  Fri Jan 24 03:10:35 2025
From: kev|nu@hey @end|ng |rom gm@||@com (Kevin Ushey)
Date: Thu, 23 Jan 2025 18:10:35 -0800
Subject: [R-pkg-devel] 
 Pre-test failure with RcppParallel on Windows R-devel
In-Reply-To: <SY2PR01MB2539F7680A28FE027A7BF77EACE32@SY2PR01MB2539.ausprd01.prod.outlook.com>
References: <SY2PR01MB2539F7680A28FE027A7BF77EACE32@SY2PR01MB2539.ausprd01.prod.outlook.com>
Message-ID: <CAJXgQP1Bb1KFA4wH9+P3hNu1yLPus_aBgtzJktVOfCadA5S1QA@mail.gmail.com>

Hi Murray,

(repeating some of the conversation we had off-list)

Sorry for the trouble -- I was just in the process of submitting
RcppParallel to CRAN, and the first submission I made had this same
issue. That should now be fixed up with RcppParallel 5.1.10, which is
now on CRAN. Hopefully your next submission should go smoothly.

Thanks,
Kevin

On Thu, Jan 23, 2025 at 5:14?PM Murray Efford via R-package-devel
<r-package-devel at r-project.org> wrote:
>
> Submitting secr 5.2.0 I get this pre-test installation ERROR which is opaque to me. I haven't changed the relevant code, and the package passes checks on Winbuilder (below) and other systems (with a false positive URL fail NOTE).
>
> * checking whether package 'secr' can be installed ... ERROR Installation failed. See 'd:/RCompile/CRANincoming/R-devel/secr.Rcheck/00install.out' for details.
> which includes
> undefined reference to `RcppParallel::tbbParallelFor(unsigned long long, unsigned long long, RcppParallel::Worker&, unsigned long long, int)'
>
> Winbuilder and the CRAN precheck appear to use identical settings:
>
> * using log directory 'd:/RCompile/CRANguest/R-devel/secr.Rcheck'
> * using R Under development (unstable) (2025-01-22 r87618 ucrt)
> * using platform: x86_64-w64-mingw32
> * R was compiled by
>     gcc.exe (GCC) 13.3.0
>     GNU Fortran (GCC) 13.3.0
> * running under: Windows Server 2022 x64 (build 20348)
>
> Any ideas? I'm guessing it's a transient CRAN problem.
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Jan 24 14:02:06 2025
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 24 Jan 2025 14:02:06 +0100
Subject: [R-pkg-devel] confusing NOTE about Authors@R field in winbuilder on
 R devel
Message-ID: <CAJuCY5wvKfsErWCEFqYbUP9ZFHcKQo1Bk9g3BOegcgmES=FK3A@mail.gmail.com>

Dear all,

Can someone elaborate why I'm getting this NOTE on winbuilder? The
difference seems to be in the formatting. The Author field seems to ignore
the vector names in the comment field and Authors at R displays these names.

Best regards,

Thierry

NOTE from winbuilder

* checking DESCRIPTION meta-information ... NOTE
Author field differs from that derived from Authors at R
  Author:    'Thierry Onkelinx [aut, cre] (<
https://orcid.org/0000-0001-8804-4216>, Research Institute for Nature and
Forest (INBO)), Floris Vanderhaeghe [ctb] (<
https://orcid.org/0000-0002-6378-6229>, Research Institute for Nature and
Forest (INBO)), Peter Desmet [ctb] (<https://orcid.org/0000-0002-8442-8025>,
Research Institute for Nature and Forest (INBO)), Els Lommelen [ctb] (<
https://orcid.org/0000-0002-3481-5684>, Research Institute for Nature and
Forest (INBO)), Research Institute for Nature and Forest (INBO) [cph, fnd]'
  Authors at R: 'Thierry Onkelinx [aut, cre] (ORCID: <
https://orcid.org/0000-0001-8804-4216>, affiliation: Research Institute for
Nature and Forest (INBO)), Floris Vanderhaeghe [ctb] (ORCID: <
https://orcid.org/0000-0002-6378-6229>, affiliation: Research Institute for
Nature and Forest (INBO)), Peter Desmet [ctb] (ORCID: <
https://orcid.org/0000-0002-8442-8025>, affiliation: Research Institute for
Nature and Forest (INBO)), Els Lommelen [ctb] (ORCID: <
https://orcid.org/0000-0002-3481-5684>, affiliation: Research Institute for
Nature and Forest (INBO)), Research Institute for Nature and Forest (INBO)
[cph, fnd]'

The DESCRIPTION has

Authors at R: c(

    person("Thierry", "Onkelinx", , "thierry.onkelinx at inbo.be", role =
c("aut", "cre"),
           comment = c(ORCID = "0000-0001-8804-4216", affiliation =
"Research Institute for Nature and Forest (INBO)")),
    person("Floris", "Vanderhaeghe", , "floris.vanderhaeghe at inbo.be",
role = "ctb",
           comment = c(ORCID = "0000-0002-6378-6229", affiliation =
"Research Institute for Nature and Forest (INBO)")),
    person("Peter", "Desmet", , "peter.desmet at inbo.be", role = "ctb",
           comment = c(ORCID = "0000-0002-8442-8025", affiliation =
"Research Institute for Nature and Forest (INBO)")),
    person("Els", "Lommelen", , "els.lommelen at inbo.be", role = "ctb",
           comment = c(ORCID = "0000-0002-3481-5684", affiliation =
"Research Institute for Nature and Forest (INBO)")),
    person("Research Institute for Nature and Forest (INBO)", , ,
"info at inbo.be", role = c("cph", "fnd"))
  )



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
*Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
*Poststukken die naar dit adres worden gestuurd, worden ingescand en
digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
dossiers volledig digitaal behandelen. Poststukken met de vermelding
?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
bezorgd.*
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

	[[alternative HTML version deleted]]


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Fri Jan 24 14:17:14 2025
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Fri, 24 Jan 2025 14:17:14 +0100
Subject: [R-pkg-devel] 
 confusing NOTE about Authors@R field in winbuilder on R devel
In-Reply-To: <CAJuCY5wvKfsErWCEFqYbUP9ZFHcKQo1Bk9g3BOegcgmES=FK3A@mail.gmail.com>
References: <CAJuCY5wvKfsErWCEFqYbUP9ZFHcKQo1Bk9g3BOegcgmES=FK3A@mail.gmail.com>
Message-ID: <7a8224ba-68b9-402c-b409-62bfd70ea3e1@statistik.tu-dortmund.de>

Most easily rebuild your package with a recent version of R-devel.
Then these fields will match again.

Best,
Uwe Ligges


On 24.01.2025 14:02, Thierry Onkelinx wrote:
> Dear all,
> 
> Can someone elaborate why I'm getting this NOTE on winbuilder? The
> difference seems to be in the formatting. The Author field seems to ignore
> the vector names in the comment field and Authors at R displays these names.
> 
> Best regards,
> 
> Thierry
> 
> NOTE from winbuilder
> 
> * checking DESCRIPTION meta-information ... NOTE
> Author field differs from that derived from Authors at R
>    Author:    'Thierry Onkelinx [aut, cre] (<
> https://orcid.org/0000-0001-8804-4216>, Research Institute for Nature and
> Forest (INBO)), Floris Vanderhaeghe [ctb] (<
> https://orcid.org/0000-0002-6378-6229>, Research Institute for Nature and
> Forest (INBO)), Peter Desmet [ctb] (<https://orcid.org/0000-0002-8442-8025>,
> Research Institute for Nature and Forest (INBO)), Els Lommelen [ctb] (<
> https://orcid.org/0000-0002-3481-5684>, Research Institute for Nature and
> Forest (INBO)), Research Institute for Nature and Forest (INBO) [cph, fnd]'
>    Authors at R: 'Thierry Onkelinx [aut, cre] (ORCID: <
> https://orcid.org/0000-0001-8804-4216>, affiliation: Research Institute for
> Nature and Forest (INBO)), Floris Vanderhaeghe [ctb] (ORCID: <
> https://orcid.org/0000-0002-6378-6229>, affiliation: Research Institute for
> Nature and Forest (INBO)), Peter Desmet [ctb] (ORCID: <
> https://orcid.org/0000-0002-8442-8025>, affiliation: Research Institute for
> Nature and Forest (INBO)), Els Lommelen [ctb] (ORCID: <
> https://orcid.org/0000-0002-3481-5684>, affiliation: Research Institute for
> Nature and Forest (INBO)), Research Institute for Nature and Forest (INBO)
> [cph, fnd]'
> 
> The DESCRIPTION has
> 
> Authors at R: c(
> 
>      person("Thierry", "Onkelinx", , "thierry.onkelinx at inbo.be", role =
> c("aut", "cre"),
>             comment = c(ORCID = "0000-0001-8804-4216", affiliation =
> "Research Institute for Nature and Forest (INBO)")),
>      person("Floris", "Vanderhaeghe", , "floris.vanderhaeghe at inbo.be",
> role = "ctb",
>             comment = c(ORCID = "0000-0002-6378-6229", affiliation =
> "Research Institute for Nature and Forest (INBO)")),
>      person("Peter", "Desmet", , "peter.desmet at inbo.be", role = "ctb",
>             comment = c(ORCID = "0000-0002-8442-8025", affiliation =
> "Research Institute for Nature and Forest (INBO)")),
>      person("Els", "Lommelen", , "els.lommelen at inbo.be", role = "ctb",
>             comment = c(ORCID = "0000-0002-3481-5684", affiliation =
> "Research Institute for Nature and Forest (INBO)")),
>      person("Research Institute for Nature and Forest (INBO)", , ,
> "info at inbo.be", role = c("cph", "fnd"))
>    )
> 
> 
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> *Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
> *Poststukken die naar dit adres worden gestuurd, worden ingescand en
> digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
> dossiers volledig digitaal behandelen. Poststukken met de vermelding
> ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
> bezorgd.*
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From murr@y@e||ord @end|ng |rom ot@go@@c@nz  Fri Jan 24 17:56:45 2025
From: murr@y@e||ord @end|ng |rom ot@go@@c@nz (Murray Efford)
Date: Fri, 24 Jan 2025 16:56:45 +0000
Subject: [R-pkg-devel] 
 Pre-test failure with RcppParallel on Windows R-devel
In-Reply-To: <CAJXgQP1Bb1KFA4wH9+P3hNu1yLPus_aBgtzJktVOfCadA5S1QA@mail.gmail.com>
References: <SY2PR01MB2539F7680A28FE027A7BF77EACE32@SY2PR01MB2539.ausprd01.prod.outlook.com>
 <CAJXgQP1Bb1KFA4wH9+P3hNu1yLPus_aBgtzJktVOfCadA5S1QA@mail.gmail.com>
Message-ID: <SY2PR01MB2539F0E78DC90DD46CE107F2ACE32@SY2PR01MB2539.ausprd01.prod.outlook.com>

Yes, that fixed it. My package was quickly re-tested and is now on CRAN. Thanks to all.
Murray
________________________________
From: Kevin Ushey <kevinushey at gmail.com>
Sent: Friday, 24 January 2025 15:10
To: Murray Efford <murray.efford at otago.ac.nz>
Cc: R-package-devel at r-project.org <r-package-devel at r-project.org>
Subject: Re: [R-pkg-devel] Pre-test failure with RcppParallel on Windows R-devel

Hi Murray,

(repeating some of the conversation we had off-list)

Sorry for the trouble -- I was just in the process of submitting
RcppParallel to CRAN, and the first submission I made had this same
issue. That should now be fixed up with RcppParallel 5.1.10, which is
now on CRAN. Hopefully your next submission should go smoothly.

Thanks,
Kevin

On Thu, Jan 23, 2025 at 5:14?PM Murray Efford via R-package-devel
<r-package-devel at r-project.org> wrote:
>
> Submitting secr 5.2.0 I get this pre-test installation ERROR which is opaque to me. I haven't changed the relevant code, and the package passes checks on Winbuilder (below) and other systems (with a false positive URL fail NOTE).
>
> * checking whether package 'secr' can be installed ... ERROR Installation failed. See 'd:/RCompile/CRANincoming/R-devel/secr.Rcheck/00install.out' for details.
> which includes
> undefined reference to `RcppParallel::tbbParallelFor(unsigned long long, unsigned long long, RcppParallel::Worker&, unsigned long long, int)'
>
> Winbuilder and the CRAN precheck appear to use identical settings:
>
> * using log directory 'd:/RCompile/CRANguest/R-devel/secr.Rcheck'
> * using R Under development (unstable) (2025-01-22 r87618 ucrt)
> * using platform: x86_64-w64-mingw32
> * R was compiled by
>     gcc.exe (GCC) 13.3.0
>     GNU Fortran (GCC) 13.3.0
> * running under: Windows Server 2022 x64 (build 20348)
>
> Any ideas? I'm guessing it's a transient CRAN problem.
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://apc01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-package-devel&data=05%7C02%7Cmurray.efford%40otago.ac.nz%7Cec031787d425485d25ad08dd3c1c6162%7C0225efc578fe4928b1579ef24809e9ba%7C0%7C0%7C638732814784925323%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=wtlopPdXVxrQorfWcztJkHz%2BRCuMpZ7o5zIRZ8Zj3G8%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-package-devel>

	[[alternative HTML version deleted]]


From n@r@@ @end|ng |rom @t@n|ord@edu  Sat Jan 25 17:54:45 2025
From: n@r@@ @end|ng |rom @t@n|ord@edu (Balasubramanian Narasimhan)
Date: Sat, 25 Jan 2025 08:54:45 -0800
Subject: [R-pkg-devel] Reliably detecting FLIBS on source build of R (w.r.t
 Rust packages)
Message-ID: <8ae0cb4e-1ae3-42d3-b35e-9d47c3e5cb68@stanford.edu>

I got the note below from Prof. Ripley on my package 'clarabel' failing 
M1mac checks.

This puzzles me because I am using FLIBS determined via`R CMD config 
FLIBS` using the crate I wrote for this very purpose 
(https://github.com/blas-lapack-rs/r-src/blob/966266425b1a21a1e979f767c6023e6bf00616fc/build.rs#L160). 


The only thing I can think of is that FLIBS is being set outside 
config.site or Makevars during the R build.

What could I be missing? (As is remarked, the M1Mac/README.txt may not 
be up to date re: toolchain details.)

Thank you.

-Naras

> Dear maintainer,
>
> Please see the problems shown on
> <https://cran.r-project.org/web/checks/check_results_clarabel.html>.
>
> Please correct before 2025-02-08 to safely retain your package on CRAN.
>
> There is a check service for M1mac issues: see
> https://www.stats.ox.ac.uk/pub/bdr/M1mac/README.txt .
> However, it is running a much older version of the OS
> and toolchain -- and the latter often matters.
>
> The CRAN Team

gfortran is not a system library everywhere so you need to use FLIBS. On 
my macOS box that is

FLIBS =? -L/opt/gfortran/lib/gcc/aarch64-apple-darwin20.0/14.2.0 
-L/opt/gfortran/lib -lemutls_w -lheapt_w -lgfortran -lquadmath

On CRAN distributions these libraries may be found in R_HOME/lib, but 
not when building from sources.


	[[alternative HTML version deleted]]


From @|mon@urb@nek @end|ng |rom R-project@org  Sun Jan 26 04:59:26 2025
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Sun, 26 Jan 2025 16:59:26 +1300
Subject: [R-pkg-devel] 
 Reliably detecting FLIBS on source build of R (w.r.t Rust packages)
In-Reply-To: <8ae0cb4e-1ae3-42d3-b35e-9d47c3e5cb68@stanford.edu>
References: <8ae0cb4e-1ae3-42d3-b35e-9d47c3e5cb68@stanford.edu>
Message-ID: <9637F162-414B-4738-A196-366854D29619@R-project.org>

Naras,

sorry, but since this involves some Rust code, I fear that you'll have to discuss it with Brian directly. FWIW on the CRAN M1 build machine it seems to use the correct flags:

$ grep fortran/lib /Volumes/Builds/packages/big-sur-arm64/results/4.5/clarabel.Rcheck/00install.out 
clang -arch arm64 -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -L/Library/Frameworks/R.framework/Resources/lib -L/opt/R/arm64/lib -o clarabel.so init.o -L/Volumes/Builds/packages/big-sur-arm64/results/4.5/clarabel.Rcheck/00_pkg_src/clarabel/src/rust/target/release -lclarabel -L/Library/Frameworks/R.framework/Resources/lib -lRlapack -L/Library/Frameworks/R.framework/Resources/lib -lRblas -L/opt/gfortran/lib/gcc/aarch64-apple-darwin20.0/14.2.0 -L/opt/gfortran/lib -lemutls_w -lheapt_w -lgfortran -lquadmath -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation
$ R CMD config FLIBS
-L/opt/gfortran/lib/gcc/aarch64-apple-darwin20.0/14.2.0 -L/opt/gfortran/lib -lemutls_w -lheapt_w -lgfortran -lquadmath

I have no idea why it would drop the arch+version specific path (which is the crucial one here - the /opt/gfortran/lib is just a generic fall-back that doesn't have any libraries in our setup).

Cheers,
Simon


> On Jan 26, 2025, at 5:54 AM, Balasubramanian Narasimhan <naras at stanford.edu> wrote:
> 
> I got the note below from Prof. Ripley on my package 'clarabel' failing 
> M1mac checks.
> 
> This puzzles me because I am using FLIBS determined via`R CMD config 
> FLIBS` using the crate I wrote for this very purpose 
> (https://github.com/blas-lapack-rs/r-src/blob/966266425b1a21a1e979f767c6023e6bf00616fc/build.rs#L160). 
> 
> 
> The only thing I can think of is that FLIBS is being set outside 
> config.site or Makevars during the R build.
> 
> What could I be missing? (As is remarked, the M1Mac/README.txt may not 
> be up to date re: toolchain details.)
> 
> Thank you.
> 
> -Naras
> 
>> Dear maintainer,
>> 
>> Please see the problems shown on
>> <https://cran.r-project.org/web/checks/check_results_clarabel.html>.
>> 
>> Please correct before 2025-02-08 to safely retain your package on CRAN.
>> 
>> There is a check service for M1mac issues: see
>> https://www.stats.ox.ac.uk/pub/bdr/M1mac/README.txt .
>> However, it is running a much older version of the OS
>> and toolchain -- and the latter often matters.
>> 
>> The CRAN Team
> 
> gfortran is not a system library everywhere so you need to use FLIBS. On 
> my macOS box that is
> 
> FLIBS =  -L/opt/gfortran/lib/gcc/aarch64-apple-darwin20.0/14.2.0 
> -L/opt/gfortran/lib -lemutls_w -lheapt_w -lgfortran -lquadmath
> 
> On CRAN distributions these libraries may be found in R_HOME/lib, but 
> not when building from sources.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> 


From |kry|ov @end|ng |rom d|@root@org  Sun Jan 26 08:55:48 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sun, 26 Jan 2025 10:55:48 +0300
Subject: [R-pkg-devel] 
 Reliably detecting FLIBS on source build of R (w.r.t Rust packages)
In-Reply-To: <8ae0cb4e-1ae3-42d3-b35e-9d47c3e5cb68@stanford.edu>
References: <8ae0cb4e-1ae3-42d3-b35e-9d47c3e5cb68@stanford.edu>
Message-ID: <20250126105548.4291f45e@Tarkus>

? Sat, 25 Jan 2025 08:54:45 -0800
Balasubramanian Narasimhan <naras at stanford.edu> ?????:

> (https://github.com/blas-lapack-rs/r-src/blob/966266425b1a21a1e979f767c6023e6bf00616fc/build.rs#L160). 

Thank you for providing the link to the code!
 
> The only thing I can think of is that FLIBS is being set outside 
> config.site or Makevars during the R build.

I think this is happening because the r-src crate is running the wrong
R executable to determine the linker flags. The check system is running
/Users/ripley/R/R-devel/bin/R, while there's also a different R (for
example, /usr/local/bin/R) visible on the $PATH. The code ends up
getting the linker flags from the latter when it runs "R" [1].

I think it should be possible to sidestep this issue altogether if you
only enable the static library at [2] and then have R link the package
shared library for you from the static library produced by Rust using
the flags you're correctly setting in Makevars [3].

If you do need Rust to determine the linker flags by itself, make sure
to run ${R_HOME}/bin/R, not just R [4].

Unrelated but probably important: having 'all' or $(SHLIB) depend on a
target that removes the files you've built [5] is a bad idea because
Make is allowed to run independent recipes in undefined order,
including rm -Rf $(SHLIB) $(STATLIB) $(OBJECTS) while $(STATLIB) is
being built [6]. Note how 'rm -Rf ...' is the first command being run
in [7], before any compilation happens. The files you're removing as
part of the $(STATLIB) recipe should be enough; there shouldn't be any
need for the 'C_clean' recipe.

-- 
Best regards,
Ivan

[1]
https://github.com/blas-lapack-rs/r-src/blob/966266425b1a21a1e979f767c6023e6bf00616fc/build.rs#L112

[2]
https://github.com/oxfordcontrol/clarabel-r/blob/13219b94cfa018091cb3ea31c51dff2116704e0a/src/rust/Cargo.toml#L7
see also
https://github.com/r-rust/hellorust/blob/master/src/myrustlib/Cargo.toml

[3]
https://github.com/oxfordcontrol/clarabel-r/blob/13219b94cfa018091cb3ea31c51dff2116704e0a/src/Makevars.in#L12

[4]
https://cran.r-project.org/doc/manuals/R-exts.html#Configure-and-cleanup

[5]
https://github.com/oxfordcontrol/clarabel-r/blob/13219b94cfa018091cb3ea31c51dff2116704e0a/src/Makevars.in#L17

[6]
https://cran.r-project.org/doc/manuals/R-exts.html#Using-Makevars

[7]
https://www.stats.ox.ac.uk/pub/bdr/M1mac/clarabel.log


From n@r@@ @end|ng |rom @t@n|ord@edu  Sun Jan 26 17:22:02 2025
From: n@r@@ @end|ng |rom @t@n|ord@edu (Balasubramanian Narasimhan)
Date: Sun, 26 Jan 2025 08:22:02 -0800
Subject: [R-pkg-devel] 
 Reliably detecting FLIBS on source build of R (w.r.t Rust packages)
In-Reply-To: <20250126105548.4291f45e@Tarkus>
References: <8ae0cb4e-1ae3-42d3-b35e-9d47c3e5cb68@stanford.edu>
 <20250126105548.4291f45e@Tarkus>
Message-ID: <7bd01f7b-d059-4f3c-ab35-f19f5054f8f2@stanford.edu>

Thank you, Simon and Ivan.? And further thanks to Ivan for R sleuthing 
of the first order!

That I'm picking up the wrong R makes sense.? I will incorporate your 
suggestions

Best wishes,

-Naras

On 1/25/25 11:55 PM, Ivan Krylov wrote:
> ? Sat, 25 Jan 2025 08:54:45 -0800
> Balasubramanian Narasimhan <naras at stanford.edu> ?????:
>
>> (https://github.com/blas-lapack-rs/r-src/blob/966266425b1a21a1e979f767c6023e6bf00616fc/build.rs#L160).
> Thank you for providing the link to the code!
>   
>> The only thing I can think of is that FLIBS is being set outside
>> config.site or Makevars during the R build.
> I think this is happening because the r-src crate is running the wrong
> R executable to determine the linker flags. The check system is running
> /Users/ripley/R/R-devel/bin/R, while there's also a different R (for
> example, /usr/local/bin/R) visible on the $PATH. The code ends up
> getting the linker flags from the latter when it runs "R" [1].
>
> I think it should be possible to sidestep this issue altogether if you
> only enable the static library at [2] and then have R link the package
> shared library for you from the static library produced by Rust using
> the flags you're correctly setting in Makevars [3].
>
> If you do need Rust to determine the linker flags by itself, make sure
> to run ${R_HOME}/bin/R, not just R [4].
>
> Unrelated but probably important: having 'all' or $(SHLIB) depend on a
> target that removes the files you've built [5] is a bad idea because
> Make is allowed to run independent recipes in undefined order,
> including rm -Rf $(SHLIB) $(STATLIB) $(OBJECTS) while $(STATLIB) is
> being built [6]. Note how 'rm -Rf ...' is the first command being run
> in [7], before any compilation happens. The files you're removing as
> part of the $(STATLIB) recipe should be enough; there shouldn't be any
> need for the 'C_clean' recipe.
>


From n@r@@ @end|ng |rom @t@n|ord@edu  Sun Jan 26 17:24:32 2025
From: n@r@@ @end|ng |rom @t@n|ord@edu (Balasubramanian Narasimhan)
Date: Sun, 26 Jan 2025 08:24:32 -0800
Subject: [R-pkg-devel] 
 Reliably detecting FLIBS on source build of R (w.r.t Rust packages)
In-Reply-To: <7bd01f7b-d059-4f3c-ab35-f19f5054f8f2@stanford.edu>
References: <8ae0cb4e-1ae3-42d3-b35e-9d47c3e5cb68@stanford.edu>
 <20250126105548.4291f45e@Tarkus>
 <7bd01f7b-d059-4f3c-ab35-f19f5054f8f2@stanford.edu>
Message-ID: <8bbf5f8e-2eef-4159-addc-6ae1d786158c@stanford.edu>

Also, to further clarify, yes I need Rust to determine the linker flags 
since the underlying Clarabel.rs links against BLAS.

-N

On 1/26/25 8:22 AM, Balasubramanian Narasimhan wrote:
> Thank you, Simon and Ivan.? And further thanks to Ivan for R sleuthing 
> of the first order!
>
> That I'm picking up the wrong R makes sense.? I will incorporate your 
> suggestions
>
> Best wishes,
>
> -Naras
>
> On 1/25/25 11:55 PM, Ivan Krylov wrote:
>> ? Sat, 25 Jan 2025 08:54:45 -0800
>> Balasubramanian Narasimhan <naras at stanford.edu> ?????:
>>
>>> (https://github.com/blas-lapack-rs/r-src/blob/966266425b1a21a1e979f767c6023e6bf00616fc/build.rs#L160). 
>>>
>> Thank you for providing the link to the code!
>>> The only thing I can think of is that FLIBS is being set outside
>>> config.site or Makevars during the R build.
>> I think this is happening because the r-src crate is running the wrong
>> R executable to determine the linker flags. The check system is running
>> /Users/ripley/R/R-devel/bin/R, while there's also a different R (for
>> example, /usr/local/bin/R) visible on the $PATH. The code ends up
>> getting the linker flags from the latter when it runs "R" [1].
>>
>> I think it should be possible to sidestep this issue altogether if you
>> only enable the static library at [2] and then have R link the package
>> shared library for you from the static library produced by Rust using
>> the flags you're correctly setting in Makevars [3].
>>
>> If you do need Rust to determine the linker flags by itself, make sure
>> to run ${R_HOME}/bin/R, not just R [4].
>>
>> Unrelated but probably important: having 'all' or $(SHLIB) depend on a
>> target that removes the files you've built [5] is a bad idea because
>> Make is allowed to run independent recipes in undefined order,
>> including rm -Rf $(SHLIB) $(STATLIB) $(OBJECTS) while $(STATLIB) is
>> being built [6]. Note how 'rm -Rf ...' is the first command being run
>> in [7], before any compilation happens. The files you're removing as
>> part of the $(STATLIB) recipe should be enough; there shouldn't be any
>> need for the 'C_clean' recipe.
>>
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From gu|||ermov|nue @end|ng |rom gm@||@com  Mon Jan 27 19:26:10 2025
From: gu|||ermov|nue @end|ng |rom gm@||@com (Guillermo Vinue)
Date: Mon, 27 Jan 2025 19:26:10 +0100
Subject: [R-pkg-devel] CRAN Debian error installation time
Message-ID: <CA+hm8HkNfS=YTVw5M2Cp0Ak-sDEP+mxdkEeOGV2xznS1YLGuNg@mail.gmail.com>

Dear All,

I am writing to you because I am getting this NOTE from the CRAN Debian
machine that is not allowing CRAN acceptance: "Installation took CPU time
2.9 times elapsed time". Uwe Ligges told me that this means that I am using
more than 2 cores, but I must not use more than 2 by default.

In order to overcome this issue, I have included an R script inside the R
folder named with my package name and this content:

.onLoad <- function(libname, pkgname) {
  if (Sys.getenv("OMP_THREAD_LIMIT") == "") {
    Sys.setenv(OMP_THREAD_LIMIT = "2")
  }
}

In addition, I have included explicitly the parameter numThreads
setThreadOptions(numThreads = 1) in the function where I use the
setThreadOptions from the RcppParallel package. However, the CRAN NOTE
persists.

Do you know how to fix that?

Many thanks in advance.

Kind regards,

Guillermo

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Jan 27 20:57:00 2025
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 27 Jan 2025 14:57:00 -0500
Subject: [R-pkg-devel] CRAN Debian error installation time
In-Reply-To: <CA+hm8HkNfS=YTVw5M2Cp0Ak-sDEP+mxdkEeOGV2xznS1YLGuNg@mail.gmail.com>
References: <CA+hm8HkNfS=YTVw5M2Cp0Ak-sDEP+mxdkEeOGV2xznS1YLGuNg@mail.gmail.com>
Message-ID: <29af71d4-812b-430d-93a5-cc1c40fe04ab@gmail.com>

   May have been mentioned up-thread, but perhaps you also need to 
control BLAS parallelization? 
https://stackoverflow.com/questions/72669579/c-how-to-set-environment-variable-so-openblas-runs-multithreaded 
(also see the RhpcBLASctl package; hopefully you don't need it, but 
worth knowing about)

On 2025-01-27 1:26 p.m., Guillermo Vinue wrote:
> Dear All,
> 
> I am writing to you because I am getting this NOTE from the CRAN Debian
> machine that is not allowing CRAN acceptance: "Installation took CPU time
> 2.9 times elapsed time". Uwe Ligges told me that this means that I am using
> more than 2 cores, but I must not use more than 2 by default.
> 
> In order to overcome this issue, I have included an R script inside the R
> folder named with my package name and this content:
> 
> .onLoad <- function(libname, pkgname) {
>    if (Sys.getenv("OMP_THREAD_LIMIT") == "") {
>      Sys.setenv(OMP_THREAD_LIMIT = "2")
>    }
> }
> 
> In addition, I have included explicitly the parameter numThreads
> setThreadOptions(numThreads = 1) in the function where I use the
> setThreadOptions from the RcppParallel package. However, the CRAN NOTE
> persists.
> 
> Do you know how to fix that?
> 
> Many thanks in advance.
> 
> Kind regards,
> 
> Guillermo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From |kry|ov @end|ng |rom d|@root@org  Mon Jan 27 21:36:26 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 27 Jan 2025 23:36:26 +0300
Subject: [R-pkg-devel] CRAN Debian error installation time
In-Reply-To: <CA+hm8HkNfS=YTVw5M2Cp0Ak-sDEP+mxdkEeOGV2xznS1YLGuNg@mail.gmail.com>
References: <CA+hm8HkNfS=YTVw5M2Cp0Ak-sDEP+mxdkEeOGV2xznS1YLGuNg@mail.gmail.com>
Message-ID: <20250127233626.7fd9bbb6@Tarkus>

Dear Guillermo,

Welcome to R-package-devel!

? Mon, 27 Jan 2025 19:26:10 +0100
Guillermo Vinue <guillermovinue at gmail.com> ?????:

> I am writing to you because I am getting this NOTE from the CRAN
> Debian machine that is not allowing CRAN acceptance: "Installation
> took CPU time 2.9 times elapsed time". Uwe Ligges told me that this
> means that I am using more than 2 cores, but I must not use more than
> 2 by default.

The key word here is "installation". Check your configure/build
scripts. Are you using CMake, Ninja, or Cargo? Does it default to using
as many parallel processes as feasible? Most build systems nowadays
accept the -j flag to control that. Make sure to give it the flag that
limits it to two processes (most likely -j 2) when running on CRAN:
http://contributor.r-project.org/cran-cookbook/code_issues.html#using-more-than-2-cores

The above advice is very general and may completely miss the mark. If
you provide the links to the latest CRAN pre-test logs and the package
source code, someone will be able to give more precise advice.

-- 
Best regards,
Ivan


From g@br|e|@b|@|n @end|ng |rom @p@gov@br  Tue Jan 28 11:01:00 2025
From: g@br|e|@b|@|n @end|ng |rom @p@gov@br (Gabriel Constantino Blain)
Date: Tue, 28 Jan 2025 10:01:00 +0000
Subject: [R-pkg-devel] Assistance with 'Surv' and 'is.Surv' Error in
 check_win_devel
Message-ID: <RIZP284MB1546718488AAA7F3DEC812F9A7EF2@RIZP284MB1546.BRAP284.PROD.OUTLOOK.COM>

Dear All,
When I run check_win_devel() on my package, I encounter the following error:

-------------------------
Error: objects 'Surv', 'is.Surv' are not exported by 'namespace:survival'
Execution halted
ERROR: lazy loading failed for package 'SPIChanges'
* removing 'd:/RCompile/CRANguest/R-devel/lib/SPIChanges'


----------------------
However, when I run devtools::check() locally, no errors are reported. I have already included the following directive in the function where the error seems to originate:

-------------------
#' @importFrom survival Surv is.Surv

------------

The issue seems to have started after I added the following lines to my code:

----------------------
loess_model <- stats::loess(zero_rain ~ time, span = 0.8)
prob_zero_rain <- Rmpfr::pmax(0, Rmpfr::pmin(1, stats::predict(loess_model)))

-----------

I do not call Surv or is.Surv explicitly in my package, and I suspect this error might be related to a dependency being triggered indirectly during lazy loading.
Any help or insights on how to resolve this would be greatly appreciated.
Thank you,
Gabriel Constantino Blain



	[[alternative HTML version deleted]]


From john@c|@rke @end|ng |rom corner@tonenw@com  Tue Jan 28 14:25:23 2025
From: john@c|@rke @end|ng |rom corner@tonenw@com (John Clarke)
Date: Tue, 28 Jan 2025 14:25:23 +0100
Subject: [R-pkg-devel] Is it possible to install a pre-compiled R package
 from Github?
Message-ID: <CAF0e1n_dvt6igMxDWqh7bjMyBra_4ceLQThRiS3bPa0RCuzLWw@mail.gmail.com>

Hi all,

I'm wondering if there is a way to point an R package installer to a
pre-compiled release on Github rather than rely on CRAN. I will likely use
CRAN, but I'm curious if installing via pre-compiled versions is limited to
CRAN or whether there is another way. This is related to a Rcpp project I'm
working on (so compiling C++), but I think the question is general enough
that it can be asked on this list.

Thank you,

-John

John Clarke | Senior Technical Advisor |
Cornerstone Systems Northwest | john.clarke at cornerstonenw.com

	[[alternative HTML version deleted]]


From |uc@r @end|ng |rom |edor@project@org  Tue Jan 28 14:27:22 2025
From: |uc@r @end|ng |rom |edor@project@org (=?UTF-8?Q?I=C3=B1aki_Ucar?=)
Date: Tue, 28 Jan 2025 14:27:22 +0100
Subject: [R-pkg-devel] 
 Is it possible to install a pre-compiled R package from Github?
In-Reply-To: <CAF0e1n_dvt6igMxDWqh7bjMyBra_4ceLQThRiS3bPa0RCuzLWw@mail.gmail.com>
References: <CAF0e1n_dvt6igMxDWqh7bjMyBra_4ceLQThRiS3bPa0RCuzLWw@mail.gmail.com>
Message-ID: <CALEXWq307uPA6TLk4jUxghCdR30ky5yW67POz-YdXkveTmf_rQ@mail.gmail.com>

El mar., 28 ene. 2025 14:25, John Clarke <john.clarke at cornerstonenw.com>
escribi?:

> Hi all,
>
> I'm wondering if there is a way to point an R package installer to a
> pre-compiled release on Github rather than rely on CRAN.


Yes, see https://r-universe.dev/

I?aki


I will likely use
> CRAN, but I'm curious if installing via pre-compiled versions is limited to
> CRAN or whether there is another way. This is related to a Rcpp project I'm
> working on (so compiling C++), but I think the question is general enough
> that it can be asked on this list.
>
> Thank you,
>
> -John
>
> John Clarke | Senior Technical Advisor |
> Cornerstone Systems Northwest | john.clarke at cornerstonenw.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>
>

	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Tue Jan 28 15:09:29 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 28 Jan 2025 08:09:29 -0600
Subject: [R-pkg-devel] 
 Is it possible to install a pre-compiled R package from Github?
In-Reply-To: <CALEXWq307uPA6TLk4jUxghCdR30ky5yW67POz-YdXkveTmf_rQ@mail.gmail.com>
References: <CAF0e1n_dvt6igMxDWqh7bjMyBra_4ceLQThRiS3bPa0RCuzLWw@mail.gmail.com>
 <CALEXWq307uPA6TLk4jUxghCdR30ky5yW67POz-YdXkveTmf_rQ@mail.gmail.com>
Message-ID: <26520.58649.620476.466641@rob.eddelbuettel.com>


On 28 January 2025 at 14:27, I?aki Ucar wrote:
| El mar., 28 ene. 2025 14:25, John Clarke <john.clarke at cornerstonenw.com>
| escribi?:
| 
| > Hi all,
| >
| > I'm wondering if there is a way to point an R package installer to a
| > pre-compiled release on Github rather than rely on CRAN.
| 
| 
| Yes, see https://r-universe.dev/

In particular, you can get a binary for Ubuntu 24.04 and either R 4.4.* or R
4.5.* via the step described at [1] as seen in [2] below. Here we use the
'rcppcore' universe as the home for Rcpp:

 > install.packages("Rcpp",
                    repos = c(linux = 'https://rcppcore.r-universe.dev/bin/linux/noble/4.4/',
                              sources = 'https://rcppcore.r-universe.dev', 
                              cran = 'https://cloud.r-project.org'))

[1] https://docs.r-universe.dev/install/binaries.html#does-r-universe-have-linux-binaries

[2] Full log using rocker/r-ubuntu container

edd at rob:~$ docker run --rm -ti rocker/r-ubuntu:24.04 R

R version 4.4.0 (2024-04-24) -- "Puppy Cup"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> install.packages("Rcpp", repos = c(linux = 'https://rcppcore.r-universe.dev/bin/linux/noble/4.4/', sources = 'https://rcppcore.r-universe.dev', cran = 'https://cloud.r-project.org'))
Installing package into ?/usr/local/lib/R/site-library?
(as ?lib? is unspecified)
trying URL 'https://rcppcore.r-universe.dev/bin/linux/noble/4.4/src/contrib/Rcpp_1.0.14.1.tar.gz'
Content type 'application/gzip' length 2210475 bytes (2.1 MB)
==================================================
downloaded 2.1 MB

* installing *binary* package ?Rcpp? ...
* DONE (Rcpp)

The downloaded source packages are in
        ?/tmp/Rtmpwhfif9/downloaded_packages?
> library(Rcpp)
Warning message:
package ?Rcpp? was built under R version 4.4.2         # running apt update; apt upgrade fixes this
> packageVersion("Rcpp")
[1] ?1.0.14.1?
> 



| 
| I?aki
| 
| 
| I will likely use
| > CRAN, but I'm curious if installing via pre-compiled versions is limited to
| > CRAN or whether there is another way. This is related to a Rcpp project I'm
| > working on (so compiling C++), but I think the question is general enough
| > that it can be asked on this list.
| >
| > Thank you,
| >
| > -John
| >
| > John Clarke | Senior Technical Advisor |
| > Cornerstone Systems Northwest | john.clarke at cornerstonenw.com
| >
| >         [[alternative HTML version deleted]]
| >
| > ______________________________________________
| > R-package-devel at r-project.org mailing list
| > https://stat.ethz.ch/mailman/listinfo/r-package-devel
| >
| >
| 
| 	[[alternative HTML version deleted]]
| 
| ______________________________________________
| R-package-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-package-devel

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From |kry|ov @end|ng |rom d|@root@org  Tue Jan 28 15:36:58 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 28 Jan 2025 17:36:58 +0300
Subject: [R-pkg-devel] 
 Is it possible to install a pre-compiled R package from Github?
In-Reply-To: <CAF0e1n_dvt6igMxDWqh7bjMyBra_4ceLQThRiS3bPa0RCuzLWw@mail.gmail.com>
References: <CAF0e1n_dvt6igMxDWqh7bjMyBra_4ceLQThRiS3bPa0RCuzLWw@mail.gmail.com>
Message-ID: <20250128173658.1c126b0f@arachnoid>

? Tue, 28 Jan 2025 14:25:23 +0100
John Clarke <john.clarke at cornerstonenw.com> ?????:

> I'm wondering if there is a way to point an R package installer to a
> pre-compiled release on Github rather than rely on CRAN.

From the point of view of install.packages(), a repository is a
collection of package files plus an index file arranged in a certain
directory structure:
https://cran.r-project.org/doc/manuals/R-admin.html#Setting-up-a-package-repository

You can create these index files yourself using tools::write_PACKAGES()
or the 'drat' package, then publish them on any free web hosting:
https://search.r-project.org/R/refmans/tools/html/writePACKAGES.html
https://cran.r-project.org/package=drat

install.packages() will then be able to use this repository using
either its contriburl=... or the repos=... argument.

The above-mentioned R-Universe will, indeed, not only help you host
your packages, but also build your source packages into binary packages
for a number of platforms.

-- 
Best regards,
Ivan


From |kry|ov @end|ng |rom d|@root@org  Tue Jan 28 15:47:12 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 28 Jan 2025 17:47:12 +0300
Subject: [R-pkg-devel] Assistance with 'Surv' and 'is.Surv' Error in
 check_win_devel
In-Reply-To: <RIZP284MB1546718488AAA7F3DEC812F9A7EF2@RIZP284MB1546.BRAP284.PROD.OUTLOOK.COM>
References: <RIZP284MB1546718488AAA7F3DEC812F9A7EF2@RIZP284MB1546.BRAP284.PROD.OUTLOOK.COM>
Message-ID: <20250128174712.6c23135e@arachnoid>

? Tue, 28 Jan 2025 10:01:00 +0000
Gabriel Constantino Blain <gabriel.blain at sp.gov.br> ?????:

> When I run check_win_devel() on my package, I encounter the following
> error:
> 
> -------------------------
> Error: objects 'Surv', 'is.Surv' are not exported by
> 'namespace:survival' Execution halted

Since Surv and is.Surv are documented functions exported from the
'survival' package, something could be wrong with the copy of
'survival' installed on Win-Builder. Packages uploaded to Win-Builder
are temporarily installed there to be used by other packages uploaded
later (and then regularly deleted). Perhaps last time 'survival' was
uploaded on Win-Builder, something went wrong with the package.

If the problem doesn't go away by itself, it may be worth asking Dr.
Uwe Ligges for advice.

-- 
Best regards,
Ivan


From gu|||ermov|nue @end|ng |rom gm@||@com  Tue Jan 28 16:07:38 2025
From: gu|||ermov|nue @end|ng |rom gm@||@com (Guillermo Vinue)
Date: Tue, 28 Jan 2025 16:07:38 +0100
Subject: [R-pkg-devel] CRAN Debian error installation time
In-Reply-To: <20250127233626.7fd9bbb6@Tarkus>
References: <CA+hm8HkNfS=YTVw5M2Cp0Ak-sDEP+mxdkEeOGV2xznS1YLGuNg@mail.gmail.com>
 <20250127233626.7fd9bbb6@Tarkus>
Message-ID: <CA+hm8HnWWF7nje8V_S7FH_Qze=sHzfkOeAHEBL=5toL0EL5dGA@mail.gmail.com>

Thank you for your help, Ben and Ivan. Unfortunately, the note persists:
https://win-builder.r-project.org/incoming_pretest/fawir_1.0_20250128_113725/Debian/00check.log

The public source repository from my package is here:
https://github.com/guivivi/fawir
The function that seems to cause the problem is
https://github.com/guivivi/fawir/blob/master/R/do_player_recruitment.R
because it uses RcppParallel::setThreadOptions

Until now, my package includes:
- a configure file with this content:
#!/bin/sh
# Globally restrict threads
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export R_INSTALL_NCPUS=1

# Pass make flags
export MAKEFLAGS="-j1"

# Proceed with configuration
exit 0

- an .Rprofile file with this content:
Sys.setenv(R_INSTALL_NCPUS = 1)

- a zzz.R file with this content:
.onLoad <- function(libname, pkgname) {
  # Restrict threading globally
  Sys.setenv(OMP_NUM_THREADS = 1)
  Sys.setenv(MKL_NUM_THREADS = 1)
  Sys.setenv(OPENBLAS_NUM_THREADS = 1)
  Sys.setenv(R_INSTALL_NCPUS = 1)

  # Set RcppParallel to single-threaded
  RcppParallel::setThreadOptions(numThreads = 1)
}

- a vignette with these headers:
 %\VignetteDepends{RcppParallel}
 %\VignetteKeyword{no_install}

- the option \dontrun{} in the examples of the function that uses
setThreadOptions

- this command inside do_player_recruitment:
if (!identical(Sys.getenv("NOT_CRAN"), "true")) {
    invisible(capture.output({word_vectors <-
glove_model$fit_transform(tcm, n_threads = 1)}))
  }

But the note from CRAN persists.

Can anyone provide me with any insight? Many thanks in any case.

Kind regards,

Guillermo

El lun, 27 ene 2025 a las 21:36, Ivan Krylov (<ikrylov at disroot.org>)
escribi?:

> Dear Guillermo,
>
> Welcome to R-package-devel!
>
> ? Mon, 27 Jan 2025 19:26:10 +0100
> Guillermo Vinue <guillermovinue at gmail.com> ?????:
>
> > I am writing to you because I am getting this NOTE from the CRAN
> > Debian machine that is not allowing CRAN acceptance: "Installation
> > took CPU time 2.9 times elapsed time". Uwe Ligges told me that this
> > means that I am using more than 2 cores, but I must not use more than
> > 2 by default.
>
> The key word here is "installation". Check your configure/build
> scripts. Are you using CMake, Ninja, or Cargo? Does it default to using
> as many parallel processes as feasible? Most build systems nowadays
> accept the -j flag to control that. Make sure to give it the flag that
> limits it to two processes (most likely -j 2) when running on CRAN:
>
> http://contributor.r-project.org/cran-cookbook/code_issues.html#using-more-than-2-cores
>
> The above advice is very general and may completely miss the mark. If
> you provide the links to the latest CRAN pre-test logs and the package
> source code, someone will be able to give more precise advice.
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From g@br|e|@b|@|n @end|ng |rom @p@gov@br  Tue Jan 28 16:38:58 2025
From: g@br|e|@b|@|n @end|ng |rom @p@gov@br (Gabriel Constantino Blain)
Date: Tue, 28 Jan 2025 15:38:58 +0000
Subject: [R-pkg-devel] Assistance with 'Surv' and 'is.Surv' Error in
 check_win_devel
In-Reply-To: <20250128174712.6c23135e@arachnoid>
References: <RIZP284MB1546718488AAA7F3DEC812F9A7EF2@RIZP284MB1546.BRAP284.PROD.OUTLOOK.COM>
 <20250128174712.6c23135e@arachnoid>
Message-ID: <CPYP284MB154378F5DE858856505BFEC0A7EF2@CPYP284MB1543.BRAP284.PROD.OUTLOOK.COM>

Dear Ivan,
Thank you for your response.
I will wait for one or two days to see if the problem resolves itself. If it persists, I will reach out to Dr. Uwe Ligges for further advice.
Best regards,
Gabriel
________________________________
From: Ivan Krylov <ikrylov at disroot.org>
Sent: 28 January 2025 11:47
To: Gabriel Constantino Blain <gabriel.blain at sp.gov.br>
Cc: R Package Development <r-package-devel at r-project.org>
Subject: Re: [R-pkg-devel] Assistance with 'Surv' and 'is.Surv' Error in check_win_devel

? Tue, 28 Jan 2025 10:01:00 +0000
Gabriel Constantino Blain <gabriel.blain at sp.gov.br> ?????:

> When I run check_win_devel() on my package, I encounter the following
> error:
>
> -------------------------
> Error: objects 'Surv', 'is.Surv' are not exported by
> 'namespace:survival' Execution halted

Since Surv and is.Surv are documented functions exported from the
'survival' package, something could be wrong with the copy of
'survival' installed on Win-Builder. Packages uploaded to Win-Builder
are temporarily installed there to be used by other packages uploaded
later (and then regularly deleted). Perhaps last time 'survival' was
uploaded on Win-Builder, something went wrong with the package.

If the problem doesn't go away by itself, it may be worth asking Dr.
Uwe Ligges for advice.

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From z@he|d@r|@gh @end|ng |rom gm@||@com  Tue Jan 28 15:47:06 2025
From: z@he|d@r|@gh @end|ng |rom gm@||@com (zahra heidari gh)
Date: Tue, 28 Jan 2025 18:17:06 +0330
Subject: [R-pkg-devel] Issue with non-standard file 'vert.txt' in R CMD check
Message-ID: <CAH7t7eqwFB+1QXKYoafs_kgKGZTiqPOCDptsE-U9nnkafOF9yw@mail.gmail.com>

Dear R Package Development Team,

I am writing to report an issue I encountered during the R CMD check
process for my R package, RHC. A non-standard file named 'vert.txt' is
being generated in the check directory, resulting in a NOTE in the check
results. Despite adding 'vert.txt' to the .Rbuildignore file, the file
continues to appear. Furthermore, I cannot find any commands within my
package's code that would generate this file.

*Details of the issue:*

   - Package name: RHC
   - Version: 0.1.0
   - R version: 4.4.2
   - Operating system: Windows 10
   - Additional details:
      - The package FD is used during package building.
      - In a previous post on the r-help at r-project.org mailing list, I was
      advised that this error might be due to the use of the FD package.

*Attached:*

   - Complete output of the R CMD check process

*Complete output of R CMD check:*

checking examples ... [12s] OK (12.6s)
N checking for non-standard things in the check directory
  Found the following files/directories:
    'vert.txt'
checking for detritus in the temp directory

See

'C:/Users/sana/AppData/Local/Temp/RtmpGWGa7s/file32b039da423/RHC.Rcheck/00check.log'
for details.

?? R CMD check results ??????????????? RHC 0.1.0 ????
Duration: 1m 38.5s

? checking for non-standard things in the check directory ... NOTE
  Found the following files/directories:
    'vert.txt'

0 errors | 0 warnings | 1 note

I would greatly appreciate any guidance on how to resolve this issue.
Thank you for your time and assistance.

Best regards,
Zahra Heidari Ghahfarrokhi
z.heidari.gh at gmail.com
January 28, 2025

-- 

Zahra Heidari Ghahfarrokhi
PhD Student, Faculty of Natural Resources and Earth Sciences, Shahrekord
University
Email: z_heidari_gh at yahoo.com <aa_naghipour at yahoo.com>,
*zahra.heydarigh at stu.sku.ac.ir
<zahra.heydarigh at stu.sku.ac.ir>*

	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Tue Jan 28 17:03:09 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 28 Jan 2025 10:03:09 -0600
Subject: [R-pkg-devel] CRAN Debian error installation time
In-Reply-To: <CA+hm8HnWWF7nje8V_S7FH_Qze=sHzfkOeAHEBL=5toL0EL5dGA@mail.gmail.com>
References: <CA+hm8HkNfS=YTVw5M2Cp0Ak-sDEP+mxdkEeOGV2xznS1YLGuNg@mail.gmail.com>
 <20250127233626.7fd9bbb6@Tarkus>
 <CA+hm8HnWWF7nje8V_S7FH_Qze=sHzfkOeAHEBL=5toL0EL5dGA@mail.gmail.com>
Message-ID: <26520.65469.558105.453889@rob.eddelbuettel.com>


Thank you for actually posting a reference to your package and its source
code. That allows us to take a closer look.

On 28 January 2025 at 16:07, Guillermo Vinue wrote:
| Thank you for your help, Ben and Ivan. Unfortunately, the note persists:
| https://win-builder.r-project.org/incoming_pretest/fawir_1.0_20250128_113725/Debian/00check.log

There is one NOTE here stating that _installation_ takes more compute than
elapsed time.  I have no idea why as I canot reproduce this:
  - with r-release I get
    * checking whether package ?fawir? can be installed ... [11s/7s] OK
  - with r-devel I get
    * checking whether package ?fawir? can be installed ... [16s/13s] OK
Neither one signals an issue. 

| The public source repository from my package is here:
| https://github.com/guivivi/fawir
| The function that seems to cause the problem is
| https://github.com/guivivi/fawir/blob/master/R/do_player_recruitment.R
| because it uses RcppParallel::setThreadOptions
| 
| Until now, my package includes:
| - a configure file with this content:
| #!/bin/sh
| # Globally restrict threads
| export OMP_NUM_THREADS=1
| export MKL_NUM_THREADS=1
| export OPENBLAS_NUM_THREADS=1
| export R_INSTALL_NCPUS=1
| 
| # Pass make flags
| export MAKEFLAGS="-j1"
| 
| # Proceed with configuration
| exit 0

This is likely irrelevant. You package has no source code to compile.
 
| - an .Rprofile file with this content:
| Sys.setenv(R_INSTALL_NCPUS = 1)

I do not think your source package has this and so it will not affect the
CRAN machine.
 
| - a zzz.R file with this content:
| .onLoad <- function(libname, pkgname) {
|   # Restrict threading globally
|   Sys.setenv(OMP_NUM_THREADS = 1)
|   Sys.setenv(MKL_NUM_THREADS = 1)
|   Sys.setenv(OPENBLAS_NUM_THREADS = 1)
|   Sys.setenv(R_INSTALL_NCPUS = 1)

That won't work. Environment variables have be set before the process
starts. You cannot influence the running R process.
 
|   # Set RcppParallel to single-threaded
|   RcppParallel::setThreadOptions(numThreads = 1)
| }
| 
| - a vignette with these headers:
|  %\VignetteDepends{RcppParallel}
|  %\VignetteKeyword{no_install}
| 
| - the option \dontrun{} in the examples of the function that uses
| setThreadOptions
| 
| - this command inside do_player_recruitment:
| if (!identical(Sys.getenv("NOT_CRAN"), "true")) {
|     invisible(capture.output({word_vectors <-
| glove_model$fit_transform(tcm, n_threads = 1)}))
|   }
| 
| But the note from CRAN persists.
| 
| Can anyone provide me with any insight? Many thanks in any case.

One idea may be to consider avoiding the downloading and aggregating of data
on each build.  You could provide a small data sample in the package so user
have something to work with, provide the functions to get more but do not
force them to run on package build?

Dirk

| 
| Kind regards,
| 
| Guillermo
| 
| El lun, 27 ene 2025 a las 21:36, Ivan Krylov (<ikrylov at disroot.org>)
| escribi?:
| 
| > Dear Guillermo,
| >
| > Welcome to R-package-devel!
| >
| > ? Mon, 27 Jan 2025 19:26:10 +0100
| > Guillermo Vinue <guillermovinue at gmail.com> ?????:
| >
| > > I am writing to you because I am getting this NOTE from the CRAN
| > > Debian machine that is not allowing CRAN acceptance: "Installation
| > > took CPU time 2.9 times elapsed time". Uwe Ligges told me that this
| > > means that I am using more than 2 cores, but I must not use more than
| > > 2 by default.
| >
| > The key word here is "installation". Check your configure/build
| > scripts. Are you using CMake, Ninja, or Cargo? Does it default to using
| > as many parallel processes as feasible? Most build systems nowadays
| > accept the -j flag to control that. Make sure to give it the flag that
| > limits it to two processes (most likely -j 2) when running on CRAN:
| >
| > http://contributor.r-project.org/cran-cookbook/code_issues.html#using-more-than-2-cores
| >
| > The above advice is very general and may completely miss the mark. If
| > you provide the links to the latest CRAN pre-test logs and the package
| > source code, someone will be able to give more precise advice.
| >
| > --
| > Best regards,
| > Ivan
| >
| 
| 	[[alternative HTML version deleted]]
| 
| ______________________________________________
| R-package-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-package-devel

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From |kry|ov @end|ng |rom d|@root@org  Tue Jan 28 17:09:45 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 28 Jan 2025 19:09:45 +0300
Subject: [R-pkg-devel] [SPAM Warning!]Re: CRAN Debian error installation
 time
In-Reply-To: <CA+hm8HnWWF7nje8V_S7FH_Qze=sHzfkOeAHEBL=5toL0EL5dGA@mail.gmail.com>
References: <CA+hm8HkNfS=YTVw5M2Cp0Ak-sDEP+mxdkEeOGV2xznS1YLGuNg@mail.gmail.com>
 <20250127233626.7fd9bbb6@Tarkus>
 <CA+hm8HnWWF7nje8V_S7FH_Qze=sHzfkOeAHEBL=5toL0EL5dGA@mail.gmail.com>
Message-ID: <20250128190945.095fd961@arachnoid>

? Tue, 28 Jan 2025 16:07:38 +0100
Guillermo Vinue <guillermovinue at gmail.com> ?????:

> Thank you for your help, Ben and Ivan. Unfortunately, the note
> persists:
> https://win-builder.r-project.org/incoming_pretest/fawir_1.0_20250128_113725/Debian/00check.log

> The public source repository from my package is here:
> https://github.com/guivivi/fawir

My bad. There is no compilation done in the code, so setting build
system flags won't help:
https://win-builder.r-project.org/incoming_pretest/fawir_1.0_20250128_113725/Debian/00install.out

Please remove the configure script. The problem must be elsewhere.

> - a zzz.R file with this content:
> .onLoad <- function(libname, pkgname) {
>
>   Sys.setenv(OMP_NUM_THREADS = 1)
>   Sys.setenv(MKL_NUM_THREADS = 1)
>   Sys.setenv(OPENBLAS_NUM_THREADS = 1)
>   Sys.setenv(R_INSTALL_NCPUS = 1)
>
>   RcppParallel::setThreadOptions(numThreads = 1)
> }

This is not a good idea. First of all, the OpenMP standard requires
the changes done by Sys.setenv(OMP_NUM_THREADS=...) calls after the R
process is started to be ignored; they will only take effect for newly
created child processes (e.g. system() calls). Secondly, if a user does
have a preferred number of threads set using any of these variables,
your package's .onLoad will change this number without a way to set it
back.

So who does create threads while your package is being installed? I
couldn't reproduce the 260% load, but I do see average 150% CPU load
during R CMD INSTALL on my computer.

R's package installation is hard to trace directly because R uses a
series of child processes to perform the various stages of the package
installation procedure. 'ltrace' <https://ltrace.org/> can serve as a
semi-automatic debugger that can follow the child processes and deliver
a stack trace when the function with a given name is called. Let's try
'pthread_create':

ltrace -w 10 -f -e pthread_create -- \
 sh -c '~/R-build/bin/R CMD INSTALL fawir_1.0.tar.gz'

(skipping a lot of output)

[pid 10154] libgomp.so.1->pthread_create(0x7ffcc6a75678, 0x7f13bc0f1720, 0x7f13bc0c6c40, 0x7ffcc6a75600) = 0
                        omp_fulfill_event (ip = 0x7f13bc0c7391)
                        GOMP_parallel (ip = 0x7f13bc0be0b1)
                        _Z16omp_thread_countv (ip = 0x7f133153cfa1)
                        _rsparse_omp_thread_count (ip = 0x7f133151c17b)
                        R_doDotCall (ip = 0x7f13bc900712)
                        bcEval_loop (ip = 0x7f13bc94502c)
                        bcEval (ip = 0x7f13bc94c902)
                        Rf_eval (ip = 0x7f13bc94cc7b)
                        forcePromise.part.0 (ip = 0x7f13bc94d5db)
                        Rf_eval (ip = 0x7f13bc94cf70)

This is the 'rsparse' package empirically measuring the number of
OpenMP threads:
https://github.com/dselivanov/rsparse/blob/695d4ebb87209d880ddbb25c418252e85264d603/R/zzz.R#L12C19-L12C44
https://github.com/dselivanov/rsparse/blob/695d4ebb87209d880ddbb25c418252e85264d603/R/zzz.R#L41C67-L41C83
https://github.com/dselivanov/rsparse/blob/695d4ebb87209d880ddbb25c418252e85264d603/src/utils.cpp#L87

Arguably, 'rsparse' should be using omp_get_thread_limit() instead of
spawning a lot of threads and then counting them one by one. This has
caused troubles for other packages before: 
https://github.com/tidymodels/textrecipes/pull/251#issuecomment-1772868032

-- 
Best regards,
Ivan


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Jan 28 17:44:12 2025
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 28 Jan 2025 11:44:12 -0500
Subject: [R-pkg-devel] Issue with non-standard file 'vert.txt' in R CMD
 check
In-Reply-To: <CAH7t7eqwFB+1QXKYoafs_kgKGZTiqPOCDptsE-U9nnkafOF9yw@mail.gmail.com>
References: <CAH7t7eqwFB+1QXKYoafs_kgKGZTiqPOCDptsE-U9nnkafOF9yw@mail.gmail.com>
Message-ID: <c7db43f5-e9d1-416e-8462-cf6719d1b14f@gmail.com>

Without seeing your package, I don't think anyone could help you, other 
than very generic help:  "Find what is creating that file, and figure 
out how to stop it."

If you submit your package to one of the online check services (e.g. 
https://win-builder.r-project.org/) then you could post a link to their 
results here, and someone could possibly figure it out for you.

Duncan Murdochg

On 2025-01-28 9:47 a.m., zahra heidari gh wrote:
> Dear R Package Development Team,
> 
> I am writing to report an issue I encountered during the R CMD check
> process for my R package, RHC. A non-standard file named 'vert.txt' is
> being generated in the check directory, resulting in a NOTE in the check
> results. Despite adding 'vert.txt' to the .Rbuildignore file, the file
> continues to appear. Furthermore, I cannot find any commands within my
> package's code that would generate this file.
> 
> *Details of the issue:*
> 
>     - Package name: RHC
>     - Version: 0.1.0
>     - R version: 4.4.2
>     - Operating system: Windows 10
>     - Additional details:
>        - The package FD is used during package building.
>        - In a previous post on the r-help at r-project.org mailing list, I was
>        advised that this error might be due to the use of the FD package.
> 
> *Attached:*
> 
>     - Complete output of the R CMD check process
> 
> *Complete output of R CMD check:*
> 
> checking examples ... [12s] OK (12.6s)
> N checking for non-standard things in the check directory
>    Found the following files/directories:
>      'vert.txt'
> checking for detritus in the temp directory
> 
> See
> 
> 'C:/Users/sana/AppData/Local/Temp/RtmpGWGa7s/file32b039da423/RHC.Rcheck/00check.log'
> for details.
> 
> ?? R CMD check results ??????????????? RHC 0.1.0 ????
> Duration: 1m 38.5s
> 
> ? checking for non-standard things in the check directory ... NOTE
>    Found the following files/directories:
>      'vert.txt'
> 
> 0 errors | 0 warnings | 1 note
> 
> I would greatly appreciate any guidance on how to resolve this issue.
> Thank you for your time and assistance.
> 
> Best regards,
> Zahra Heidari Ghahfarrokhi
> z.heidari.gh at gmail.com
> January 28, 2025
>


From edd @end|ng |rom deb|@n@org  Tue Jan 28 18:05:55 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 28 Jan 2025 11:05:55 -0600
Subject: [R-pkg-devel] [SPAM Warning!]Re: CRAN Debian error installation
 time
In-Reply-To: <20250128190945.095fd961@arachnoid>
References: <CA+hm8HkNfS=YTVw5M2Cp0Ak-sDEP+mxdkEeOGV2xznS1YLGuNg@mail.gmail.com>
 <20250127233626.7fd9bbb6@Tarkus>
 <CA+hm8HnWWF7nje8V_S7FH_Qze=sHzfkOeAHEBL=5toL0EL5dGA@mail.gmail.com>
 <20250128190945.095fd961@arachnoid>
Message-ID: <26521.3699.981063.369921@rob.eddelbuettel.com>


Excellent (as usual) sleuthing by Ivan -- colour me impressed (again).

As an aside, your package makes wide use of the excellent resources provided
by other CRAN packages.  But with this comes added complexity.  Depending on
over sixty (!!) other packages (when counting recursively, over seventy when
we add Suggests:) can make your overall setup fragile, and debugging
challenging.

> db <- tools::CRAN_package_db()
> deps <- tools::package_dependencies(c("dplyr", "ggplot2", "ggpubr",
+ "ggtext", "janitor", "magrittr", "polite", "purrr", "RcppParallel",
+ "RhpcBLASctl", "readr", "robotstxt", "rvest", "stringr", "text2vec", "tidyr",
+ "tidytext")) 
> unique(sort(do.call(c, deps)))
 [1] "cli"          "clipr"        "cowplot"      "cpp11"       
 [5] "crayon"       "data.table"   "digest"       "dplyr"       
 [9] "future.apply" "generics"     "ggplot2"      "ggrepel"     
[13] "ggsci"        "ggsignif"     "glue"         "grDevices"   
[17] "grid"         "gridExtra"    "gridtext"     "gtable"      
[21] "hms"          "httr"         "isoband"      "janeaustenr" 
[25] "lgr"          "lifecycle"    "lubridate"    "magrittr"    
[29] "MASS"         "Matrix"       "memoise"      "methods"     
[33] "mgcv"         "mlapi"        "pillar"       "polynom"     
[37] "purrr"        "R6"           "ratelimitr"   "Rcpp"        
[41] "rlang"        "robotstxt"    "rsparse"      "rstatix"     
[45] "rvest"        "scales"       "selectr"      "snakecase"   
[49] "spiderbar"    "stats"        "stringi"      "stringr"     
[53] "tibble"       "tidyr"        "tidyselect"   "tokenizers"  
[57] "tzdb"         "usethis"      "utils"        "vctrs"       
[61] "vroom"        "withr"        "xml2"        
>

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From |kry|ov @end|ng |rom d|@root@org  Tue Jan 28 19:18:10 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 28 Jan 2025 21:18:10 +0300
Subject: [R-pkg-devel] Issue with non-standard file 'vert.txt' in R CMD
 check
In-Reply-To: <CAH7t7eqwFB+1QXKYoafs_kgKGZTiqPOCDptsE-U9nnkafOF9yw@mail.gmail.com>
References: <CAH7t7eqwFB+1QXKYoafs_kgKGZTiqPOCDptsE-U9nnkafOF9yw@mail.gmail.com>
Message-ID: <20250128211810.103fcc78@Tarkus>

Dear Zahra Heidari Ghahfarrokhi,

Welcome to R-package-devel!

? Tue, 28 Jan 2025 18:17:06 +0330
zahra heidari gh <z.heidari.gh at gmail.com> ?????:

>    - Additional details:
>       - The package FD is used during package building.
>       - In a previous post on the r-help at r-project.org mailing list,
> I was advised that this error might be due to the use of the FD
> package.

Thank you for providing these additional details. My analysis still
stands; this is a bug in the 'FD' package:
https://stat.ethz.ch/pipermail/r-help/2024-November/480198.html
https://github.com/cran/FD/blob/1993781d8fa7e6f4107ebd3f52f919c6fe1760f7/R/dbFD.R#L685

This line of code has been there for 16 years and nobody else noticed
the problem. In order to get the bug fixed, you will need to contact
the maintainer (see the output of the maintainer("FD") command in R)
and ask them to change the code so that it only creates temporary files
in the session temporary directory and cleans up afterwards:
https://contributor.r-project.org/cran-cookbook/code_issues.html#writing-files-and-directories-to-the-home-filespace

There is one workaround you can use. Before calling the function from
the 'FD' package, change the current directory and clean everything up
yourself:

# this temporary directory will be for the FD package to leave files in
newdir <- tempfile('FDbug')
stopifnot(dir.create(newdir))
# make sure it disappears after we are done
on.exit(unlink(newdir, recursive = TRUE), add = TRUE)
# 'FD' creates files in current directory, so switch it
olddir <- setwd(newdir)
# make sure the current directory is restored after we are done
on.exit(setwd(olddir), add = TRUE)
# now call the function from the 'FD' package

-- 
Best regards,
Ivan


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Wed Jan 29 09:28:23 2025
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Wed, 29 Jan 2025 09:28:23 +0100
Subject: [R-pkg-devel] Assistance with 'Surv' and 'is.Surv' Error in
 check_win_devel
In-Reply-To: <20250128174712.6c23135e@arachnoid>
References: <RIZP284MB1546718488AAA7F3DEC812F9A7EF2@RIZP284MB1546.BRAP284.PROD.OUTLOOK.COM>
 <20250128174712.6c23135e@arachnoid>
Message-ID: <8ae359b2-588d-4ef0-8b09-599403c16d45@statistik.tu-dortmund.de>

Have you tried at least twice? If it persists, please let me know and 
forward the message you got from winbuilder.

Best,
Uwe Ligges


On 28.01.2025 15:47, Ivan Krylov via R-package-devel wrote:
> ? Tue, 28 Jan 2025 10:01:00 +0000
> Gabriel Constantino Blain <gabriel.blain at sp.gov.br> ?????:
> 
>> When I run check_win_devel() on my package, I encounter the following
>> error:
>>
>> -------------------------
>> Error: objects 'Surv', 'is.Surv' are not exported by
>> 'namespace:survival' Execution halted
> 
> Since Surv and is.Surv are documented functions exported from the
> 'survival' package, something could be wrong with the copy of
> 'survival' installed on Win-Builder. Packages uploaded to Win-Builder
> are temporarily installed there to be used by other packages uploaded
> later (and then regularly deleted). Perhaps last time 'survival' was
> uploaded on Win-Builder, something went wrong with the package.
> 
> If the problem doesn't go away by itself, it may be worth asking Dr.
> Uwe Ligges for advice.
> 


From g@br|e|@b|@|n @end|ng |rom @p@gov@br  Wed Jan 29 13:52:36 2025
From: g@br|e|@b|@|n @end|ng |rom @p@gov@br (Gabriel Constantino Blain)
Date: Wed, 29 Jan 2025 12:52:36 +0000
Subject: [R-pkg-devel] Assistance with 'Surv' and 'is.Surv' Error in
 check_win_devel
In-Reply-To: <8ae359b2-588d-4ef0-8b09-599403c16d45@statistik.tu-dortmund.de>
References: <RIZP284MB1546718488AAA7F3DEC812F9A7EF2@RIZP284MB1546.BRAP284.PROD.OUTLOOK.COM>
 <20250128174712.6c23135e@arachnoid>
 <8ae359b2-588d-4ef0-8b09-599403c16d45@statistik.tu-dortmund.de>
Message-ID: <CPYP284MB1543BA7E3D99D68D72750A15A7EE2@CPYP284MB1543.BRAP284.PROD.OUTLOOK.COM>


Dear Dr. Uwe Ligges,
I tried at least 5 times.
Please se below the message I just got from winbuilder.
Best
Gabriel Blain
------------------------
Dear package maintainer,

this notification has been generated automatically.
Your package SPIChanges_0.0.0.9000.tar.gz has been built (if working) and checked for Windows.
Please check the log files and (if working) the binary package at:
https://win-builder.r-project.org/XW2OAzbdlK2v
The files will be removed after roughly 72 hours.
Installation time in seconds: 2
Check time in seconds: 13
Status: 1 ERROR, 1 NOTE
R Under development (unstable) (2025-01-28 r87664 ucrt)

All the best,
Uwe Ligges
(CRAN maintainer of binary packages for Windows)



________________________________
From: Uwe Ligges
Sent: Wednesday, January 29, 2025 05:28
To: Ivan Krylov; Gabriel Constantino Blain
Cc: R Package Development
Subject: Re: [R-pkg-devel] Assistance with 'Surv' and 'is.Surv' Error in check_win_devel

Have you tried at least twice? If it persists, please let me know and
forward the message you got from winbuilder.

Best,
Uwe Ligges


On 28.01.2025 15:47, Ivan Krylov via R-package-devel wrote:
> ? Tue, 28 Jan 2025 10:01:00 +0000
> Gabriel Constantino Blain <gabriel.blain at sp.gov.br> ?????:
>
>> When I run check_win_devel() on my package, I encounter the following
>> error:
>>
>> -------------------------
>> Error: objects 'Surv', 'is.Surv' are not exported by
>> 'namespace:survival' Execution halted
>
> Since Surv and is.Surv are documented functions exported from the
> 'survival' package, something could be wrong with the copy of
> 'survival' installed on Win-Builder. Packages uploaded to Win-Builder
> are temporarily installed there to be used by other packages uploaded
> later (and then regularly deleted). Perhaps last time 'survival' was
> uploaded on Win-Builder, something went wrong with the package.
>
> If the problem doesn't go away by itself, it may be worth asking Dr.
> Uwe Ligges for advice.
>


	[[alternative HTML version deleted]]


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Wed Jan 29 15:19:57 2025
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Wed, 29 Jan 2025 15:19:57 +0100
Subject: [R-pkg-devel] Assistance with 'Surv' and 'is.Surv' Error in
 check_win_devel
In-Reply-To: <CPYP284MB1543BA7E3D99D68D72750A15A7EE2@CPYP284MB1543.BRAP284.PROD.OUTLOOK.COM>
References: <RIZP284MB1546718488AAA7F3DEC812F9A7EF2@RIZP284MB1546.BRAP284.PROD.OUTLOOK.COM>
 <20250128174712.6c23135e@arachnoid>
 <8ae359b2-588d-4ef0-8b09-599403c16d45@statistik.tu-dortmund.de>
 <CPYP284MB1543BA7E3D99D68D72750A15A7EE2@CPYP284MB1543.BRAP284.PROD.OUTLOOK.COM>
Message-ID: <5cf90927-e245-456e-8f45-39a556b3d7a5@statistik.tu-dortmund.de>

Issue found and fixed: someone else submitted some broken survival for 
the on demand checks which was stuck in the on demand library.
You should be able to resubmit without issues now.

Best,
Uwe



On 29.01.2025 13:52, Gabriel Constantino Blain wrote:
> 
> Dear Dr. Uwe Ligges,
> I tried at least 5 times.
> Please se below the message I just got from winbuilder.
> Best
> Gabriel Blain
> ------------------------
> Dear package maintainer,
> 
> this notification has been generated automatically.
> Your package SPIChanges_0.0.0.9000.tar.gz has been built (if working) 
> and checked for Windows.
> Please check the log files and (if working) the binary package at:
> https://win-builder.r-project.org/XW2OAzbdlK2v <https://win-builder.r- 
> project.org/XW2OAzbdlK2v>
> The files will be removed after roughly 72 hours.
> Installation time in seconds: 2
> Check time in seconds: 13
> Status: 1 ERROR, 1 NOTE
> R Under development (unstable) (2025-01-28 r87664 ucrt)
> 
> All the best,
> Uwe Ligges
> (CRAN maintainer of binary packages for Windows)
> 
> 
> 
> ------------------------------------------------------------------------
> *From:*?Uwe Ligges
> *Sent:*?Wednesday, January 29, 2025 05:28
> *To:*?Ivan Krylov; Gabriel Constantino Blain
> *Cc:*?R Package Development
> *Subject:*?Re: [R-pkg-devel] Assistance with 'Surv' and 'is.Surv' Error 
> in check_win_devel
> 
> Have you tried at least twice? If it persists, please let me know and
> forward the message you got from winbuilder.
> 
> Best,
> Uwe Ligges
> 
> 
> On 28.01.2025 15:47, Ivan Krylov via R-package-devel wrote:
>  > ? Tue, 28 Jan 2025 10:01:00 +0000
>  > Gabriel Constantino Blain <gabriel.blain at sp.gov.br> ?????:
>  >
>  >> When I run check_win_devel() on my package, I encounter the following
>  >> error:
>  >>
>  >> -------------------------
>  >> Error: objects 'Surv', 'is.Surv' are not exported by
>  >> 'namespace:survival' Execution halted
>  >
>  > Since Surv and is.Surv are documented functions exported from the
>  > 'survival' package, something could be wrong with the copy of
>  > 'survival' installed on Win-Builder. Packages uploaded to Win-Builder
>  > are temporarily installed there to be used by other packages uploaded
>  > later (and then regularly deleted). Perhaps last time 'survival' was
>  > uploaded on Win-Builder, something went wrong with the package.
>  >
>  > If the problem doesn't go away by itself, it may be worth asking Dr.
>  > Uwe Ligges for advice.
>  >
>


From v|ncentv@nhee@ @end|ng |rom gm@||@com  Wed Jan 29 17:01:56 2025
From: v|ncentv@nhee@ @end|ng |rom gm@||@com (Vincent van Hees)
Date: Wed, 29 Jan 2025 11:01:56 -0500
Subject: [R-pkg-devel] Slow down of as.POSIXct() when converting numeric
 data with origin specified
Message-ID: <CALnEB155_O+J_6hGz6y_AV-c54gX73V+pWTLMPqr6MGrR5BntQ@mail.gmail.com>

Hello,
I am trying to make the as.POSIXct() calls in my R package (GGIR) backward
compatible with R 4.2.0 (from 2022) by always adding the origin =
"1970-01-01" argument to the as.POSIXct() calls. However, this causes a
substantial slow down when converting vectors of numeric time:

> time = Sys.time()> time = as.numeric(seq(time, time + 500000, by = 0.01))> print(system.time(A <- as.POSIXct(time)))   user  system elapsed
      0       0       0 > print(system.time(B <- as.POSIXct(time,
origin = "1970-01-01")))   user  system elapsed
  0.153   0.326   0.505


I am using R 4.2.2 on Ubuntu 22.04.
In real use cases this equates to hours rather than minutes of run time.

The only somewhat ugly solution I can think of is to rewrite the code as
if-else-statement where the if-branch is run with older R versions and uses
the origin argument, while the else-branch is run with later R versions and
does not use the origin argument.

Does anyone have a more elegant solution?

Thanks, Vincent

	[[alternative HTML version deleted]]


From ||u|@@rev|||@ @end|ng |rom gm@||@com  Wed Jan 29 17:10:39 2025
From: ||u|@@rev|||@ @end|ng |rom gm@||@com (=?UTF-8?Q?Llu=C3=ADs_Revilla?=)
Date: Wed, 29 Jan 2025 17:10:39 +0100
Subject: [R-pkg-devel] Date of CRAN checks
Message-ID: <CAN+W6_uBLsOtqf43FoTTJPhEFMp4GviCXwNXJskmqKep8KkRbA@mail.gmail.com>

Dear list,

Recently after a package update I noticed an ERROR on one flavor.
I believe this is some problem with the r-release-macos-x86_64 flavor.
But I'm not sure if this is fixed on the system or not.
I was waiting to see if this got fixed with time (and thanks to the CRAN
volunteers).

A check landing page on CRAN had a date "Last updated on 2025-01-29
08:49:42 CET." then it changed to "2025-01-29 15:49:25 CET.". Because there
are some checks that are still from the old version of the package and the
failing check is still failing, I'm not sure which checks were updated. Is
this the date of the landing page of all the checks, or all the checks are
updated up to that date?

Bioconductor provides the time with two fields: StartedAt and EndedAt for
each flavor (and step).
I hoped to find a date on the check logs. It would make it easier to know
when it is updated and it has the same result as previously.
Is there a way to know when a given check was run on CRAN?

Best regards,

Llu?s

PS:  The problem is shared by many packages (>50), the vignette can be
built but not rebuilt and it raises an error message about not finding
pandoc.

	[[alternative HTML version deleted]]


From @|mon@urb@nek @end|ng |rom R-project@org  Wed Jan 29 20:08:07 2025
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Thu, 30 Jan 2025 08:08:07 +1300
Subject: [R-pkg-devel] Date of CRAN checks
In-Reply-To: <CAN+W6_uBLsOtqf43FoTTJPhEFMp4GviCXwNXJskmqKep8KkRbA@mail.gmail.com>
References: <CAN+W6_uBLsOtqf43FoTTJPhEFMp4GviCXwNXJskmqKep8KkRbA@mail.gmail.com>
Message-ID: <D5364A6D-A336-4AA9-BED6-3EDED61AE9D9@R-project.org>

Llu?s,

the timestamps are generated by the CRAN server when it updates webpage from the actual check reports so it does not reflect the date/time of the check itself (neither does the timestamp of the URL as it is often re-generated). So in short, no, there is no way to know the timestamp of the check. I think it may be useful, so I'll see if we can add it.

That said, checks are not re-run unless you update the version of your package (or there is an error caused by another package whose update will fix it), so in most cases waiting won't fix anything. If there is a problem you have to report it to the corresponding CRAN maintainer so for macOS that would be me.

Cheers,
Simon


> On Jan 30, 2025, at 5:10 AM, Llu?s Revilla <lluis.revilla at gmail.com> wrote:
> 
> Dear list,
> 
> Recently after a package update I noticed an ERROR on one flavor.
> I believe this is some problem with the r-release-macos-x86_64 flavor.
> But I'm not sure if this is fixed on the system or not.
> I was waiting to see if this got fixed with time (and thanks to the CRAN
> volunteers).
> 
> A check landing page on CRAN had a date "Last updated on 2025-01-29
> 08:49:42 CET." then it changed to "2025-01-29 15:49:25 CET.". Because there
> are some checks that are still from the old version of the package and the
> failing check is still failing, I'm not sure which checks were updated. Is
> this the date of the landing page of all the checks, or all the checks are
> updated up to that date?
> 
> Bioconductor provides the time with two fields: StartedAt and EndedAt for
> each flavor (and step).
> I hoped to find a date on the check logs. It would make it easier to know
> when it is updated and it has the same result as previously.
> Is there a way to know when a given check was run on CRAN?
> 
> Best regards,
> 
> Llu?s
> 
> PS:  The problem is shared by many packages (>50), the vignette can be
> built but not rebuilt and it raises an error message about not finding
> pandoc.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> 


From e@ @end|ng |rom enr|co@chum@nn@net  Wed Jan 29 20:28:36 2025
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Wed, 29 Jan 2025 20:28:36 +0100
Subject: [R-pkg-devel] Slow down of as.POSIXct() when converting numeric
 data with origin specified
In-Reply-To: <CALnEB155_O+J_6hGz6y_AV-c54gX73V+pWTLMPqr6MGrR5BntQ@mail.gmail.com>
 (Vincent van Hees's message of "Wed, 29 Jan 2025 11:01:56 -0500")
References: <CALnEB155_O+J_6hGz6y_AV-c54gX73V+pWTLMPqr6MGrR5BntQ@mail.gmail.com>
Message-ID: <87wmedh123.fsf@enricoschumann.net>

On Wed, 29 Jan 2025, Vincent van Hees writes:

> Hello,
> I am trying to make the as.POSIXct() calls in my R package (GGIR) backward
> compatible with R 4.2.0 (from 2022) by always adding the origin =
> "1970-01-01" argument to the as.POSIXct() calls. However, this causes a
> substantial slow down when converting vectors of numeric time:
>
>> time = Sys.time()> time = as.numeric(seq(time, time + 500000, by = 0.01))> print(system.time(A <- as.POSIXct(time)))   user  system elapsed
>       0       0       0 > print(system.time(B <- as.POSIXct(time,
> origin = "1970-01-01")))   user  system elapsed
>   0.153   0.326   0.505
>
>
> I am using R 4.2.2 on Ubuntu 22.04.
> In real use cases this equates to hours rather than minutes of run time.
>
> The only somewhat ugly solution I can think of is to rewrite the code as
> if-else-statement where the if-branch is run with older R versions and uses
> the origin argument, while the else-branch is run with later R versions and
> does not use the origin argument.
>
> Does anyone have a more elegant solution?
>
> Thanks, Vincent
>

You might consider using `.POSIXct`:

    time <- Sys.time()
    time <- as.numeric(seq(time, time + 500000, by = 0.01))
    
    print(system.time(A <- as.POSIXct(time)))
    print(system.time(B <- as.POSIXct(time, origin = "1970-01-01")))
    print(system.time(C <- .POSIXct(time)))
    
    all(A == B)
    all(B == C)


-- 
Enrico Schumann
Lucerne, Switzerland
https://enricoschumann.net


From cr@|ggower @end|ng |rom gm@||@com  Wed Jan 29 18:13:46 2025
From: cr@|ggower @end|ng |rom gm@||@com (Craig Gower-Page)
Date: Wed, 29 Jan 2025 17:13:46 +0000
Subject: [R-pkg-devel] How to run R CMD CHECK with the installation
 directory set to read-only ?
Message-ID: <CADGnEyE3SnFEAh3paKyBbG6=o2Sjeiu-2meAVwz=h90aNrS61Q@mail.gmail.com>

Hi,

A package of ours had its test code throw an error during its R CMD
CHECK on CRAN due to it attempting to write files to the installation
directory. We were wondering how best to replicate this test on our
local machines as we are unable to see any direct options / flags /
hooks within R CMD CHECK that allows you to specify that the
installation directory should be set to read-only ?

>From the "Writing R extensions" manual there appears to be an option
that allows you to run R CMD CHECK on an installed package (I think
technically it is running on the source package but it suppresses the
installation step and uses the pre-installed version for running the
tests). Quoting the manual below:

> It is possible to install a package and then check the installed package. To do so first install the package and keep a log of the installation:
> R CMD INSTALL -l libdir pkg > pkg.log 2>&1
> and then use
> Rdev CMD check -l libdir --install=check:pkg.log pkg

This appears to do what we need in that we can first install the
package locally, set the directory to read-only with `chmod 500` and
then run R CMD CHECK using the arguments as specified above from the
manual.

HOWEVER - this approach appears to have a bug in that if the source
code doesn't have an explicit `Author` and `Maintainer` field then the
check will fail; that is to say it doesn't appear to be able to expand
the `Author at R` field when running in this mode.

So to summarise my questions are:

* Is my described use of Rdev CMD check -l libdir
--install=check:pkg.log pkg the correct way of using R CMD CHECK to
test if the installed package is writing to the installation directory
?
* If not, what is the recommended way of using R CMD CHECK to catch
this (e.g. how to replicate how CRAN runs R CMD CHECK to catch this) ?
* If yes, is it regarded as a bug or not that R CMD CHECK on installed
packages only works for packages that have an explicit Author /
Maintainer field and not just a Author at R field?

With regards to the potential bug with R CMD CHECK; I tested this on R
4.4.2 on Mac OS Sonoma and have uploaded a small test script to GitHub
that demonstrates it:
https://gist.github.com/gowerc/248f398f421750f7673019d1989cbe6f#file-simple_script-sh


Kind Regards

Craig Gower-Page


From ||u|@@rev|||@ @end|ng |rom gm@||@com  Thu Jan 30 09:10:00 2025
From: ||u|@@rev|||@ @end|ng |rom gm@||@com (=?UTF-8?Q?Llu=C3=ADs_Revilla?=)
Date: Thu, 30 Jan 2025 09:10:00 +0100
Subject: [R-pkg-devel] Date of CRAN checks
In-Reply-To: <D5364A6D-A336-4AA9-BED6-3EDED61AE9D9@R-project.org>
References: <CAN+W6_uBLsOtqf43FoTTJPhEFMp4GviCXwNXJskmqKep8KkRbA@mail.gmail.com>
 <D5364A6D-A336-4AA9-BED6-3EDED61AE9D9@R-project.org>
Message-ID: <CAN+W6_ui_-+-UZnS7xDzo7dsr=i332VU4F7Z75RxUS7-Bc7rGQ@mail.gmail.com>

Dear Simon,

Thank you for clearing my misunderstanding about CRAN's checks.
Looking forward to seeing logs with a date (if possible).

This case  was initiated by teal.reporter, the error is related to pandoc
according to the logs:
Error: pandoc version 1.12.3 or higher is required and was not found (see
the help page ?rmarkdown::pandoc_available). Execution halted
The package imports rmarkdown (? 2.23) that requires pandoc.
In teal.reporter there isn't a specific requirement for pandoc version
1.12.3 (but it doesn't check the version available).

Other packages on that same flavor fail with problems related to pandoc,
for example datacutr, oldr or linevis, have similar errors.
They depend on packages that use pandoc and are also recently published.

Many thanks for your help,

Llu?s

On Wed, 29 Jan 2025 at 20:08, Simon Urbanek <simon.urbanek at r-project.org>
wrote:

> Llu?s,
>
> the timestamps are generated by the CRAN server when it updates webpage
> from the actual check reports so it does not reflect the date/time of the
> check itself (neither does the timestamp of the URL as it is often
> re-generated). So in short, no, there is no way to know the timestamp of
> the check. I think it may be useful, so I'll see if we can add it.
>
> That said, checks are not re-run unless you update the version of your
> package (or there is an error caused by another package whose update will
> fix it), so in most cases waiting won't fix anything. If there is a problem
> you have to report it to the corresponding CRAN maintainer so for macOS
> that would be me.
>
> Cheers,
> Simon
>
>
> > On Jan 30, 2025, at 5:10 AM, Llu?s Revilla <lluis.revilla at gmail.com>
> wrote:
> >
> > Dear list,
> >
> > Recently after a package update I noticed an ERROR on one flavor.
> > I believe this is some problem with the r-release-macos-x86_64 flavor.
> > But I'm not sure if this is fixed on the system or not.
> > I was waiting to see if this got fixed with time (and thanks to the CRAN
> > volunteers).
> >
> > A check landing page on CRAN had a date "Last updated on 2025-01-29
> > 08:49:42 CET." then it changed to "2025-01-29 15:49:25 CET.". Because
> there
> > are some checks that are still from the old version of the package and
> the
> > failing check is still failing, I'm not sure which checks were updated.
> Is
> > this the date of the landing page of all the checks, or all the checks
> are
> > updated up to that date?
> >
> > Bioconductor provides the time with two fields: StartedAt and EndedAt for
> > each flavor (and step).
> > I hoped to find a date on the check logs. It would make it easier to know
> > when it is updated and it has the same result as previously.
> > Is there a way to know when a given check was run on CRAN?
> >
> > Best regards,
> >
> > Llu?s
> >
> > PS:  The problem is shared by many packages (>50), the vignette can be
> > built but not rebuilt and it raises an error message about not finding
> > pandoc.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-package-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-package-devel
> >
>
>

	[[alternative HTML version deleted]]


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Thu Jan 30 10:18:24 2025
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Thu, 30 Jan 2025 10:18:24 +0100
Subject: [R-pkg-devel] How to run R CMD CHECK with the installation
 directory set to read-only ?
In-Reply-To: <CADGnEyE3SnFEAh3paKyBbG6=o2Sjeiu-2meAVwz=h90aNrS61Q@mail.gmail.com>
References: <CADGnEyE3SnFEAh3paKyBbG6=o2Sjeiu-2meAVwz=h90aNrS61Q@mail.gmail.com>
Message-ID: <401141ab-9cfa-4281-a3e2-09c4754993ca@statistik.tu-dortmund.de>



On 29.01.2025 18:13, Craig Gower-Page wrote:
> Hi,
> 
> A package of ours had its test code throw an error during its R CMD
> CHECK on CRAN due to it attempting to write files to the installation
> directory. We were wondering how best to replicate this test on our
> local machines as we are unable to see any direct options / flags /
> hooks within R CMD CHECK that allows you to specify that the
> installation directory should be set to read-only ?
> 
>  From the "Writing R extensions" manual there appears to be an option
> that allows you to run R CMD CHECK on an installed package (I think
> technically it is running on the source package but it suppresses the
> installation step and uses the pre-installed version for running the
> tests). Quoting the manual below:
> 
>> It is possible to install a package and then check the installed package. To do so first install the package and keep a log of the installation:
>> R CMD INSTALL -l libdir pkg > pkg.log 2>&1
>> and then use
>> Rdev CMD check -l libdir --install=check:pkg.log pkg
> 
> This appears to do what we need in that we can first install the
> package locally, set the directory to read-only with `chmod 500` and
> then run R CMD CHECK using the arguments as specified above from the
> manual.

Yes, or mount it read-only


> HOWEVER - this approach appears to have a bug in that if the source
> code doesn't have an explicit `Author` and `Maintainer` field then the
> check will fail; that is to say it doesn't appear to be able to expand
> the `Author at R` field when running in this mode.

First you build the package via R CMD build and then you can unpack it, 
voila.


> 
> So to summarise my questions are:
> 
> * Is my described use of Rdev CMD check -l libdir
> --install=check:pkg.log pkg the correct way of using R CMD CHECK to
> test if the installed package is writing to the installation directory
> ?

At least that is what CRAN does during its regular checks anyway.

> * If not, what is the recommended way of using R CMD CHECK to catch
> this (e.g. how to replicate how CRAN runs R CMD CHECK to catch this) ?
> * If yes, is it regarded as a bug or not that R CMD CHECK on installed
> packages only works for packages that have an explicit Author /
> Maintainer field and not just a Author at R field?

It is fine, as described above. YOu always have to run R CMD build 
before checking as a package may also have build time actions (e.g. for 
the manuals) that oetherwise would not be executed.

Best,
Uwe Ligges



> With regards to the potential bug with R CMD CHECK; I tested this on R
> 4.4.2 on Mac OS Sonoma and have uploaded a small test script to GitHub
> that demonstrates it:
> https://gist.github.com/gowerc/248f398f421750f7673019d1989cbe6f#file-simple_script-sh
> 
> 
> Kind Regards
> 
> Craig Gower-Page
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From wo||g@ng@ro|ke @end|ng |rom upr@edu  Fri Jan 31 16:02:34 2025
From: wo||g@ng@ro|ke @end|ng |rom upr@edu (Wolfgang Rolke)
Date: Fri, 31 Jan 2025 15:02:34 +0000
Subject: [R-pkg-devel] Rcpp in vignette
Message-ID: <BN7PR03MB3649C5E36F55FD09F91FCF099BE82@BN7PR03MB3649.namprd03.prod.outlook.com>

In the vignette of my package Rgof I create a function written in Rcpp, which is then passed and executed in some of the routines included in Rgof. The package passes all the checks on the various platform without errors, warnings or notes except on atlas and gcc13. There I get an error about not being able to find this function. For details see

https://github.com/r-hub2/productive-joking-manatee-Rgof/actions
[https://opengraph.githubassets.com/b40e189207ca774a60d2c41f7b3410850dddf9a6816238d771e042279edbac03/r-hub2/productive-joking-manatee-Rgof]<https://github.com/r-hub2/productive-joking-manatee-Rgof/actions>
Workflow runs ? r-hub2/productive-joking-manatee-Rgof ? GitHub<https://github.com/r-hub2/productive-joking-manatee-Rgof/actions>
Created by R-hub. Contribute to r-hub2/productive-joking-manatee-Rgof development by creating an account on GitHub.
github.com

Is this a known issue? Is there a workaround? I have not tested the package on all 20+ machines, which other ones have the same issue?

The package is already on CRAN, so this error does not lead to it to not being accepted. Still, I would like to know what the problem is and if there is a better way than just to ignore it.

Thanks
Wolfgang


	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Fri Jan 31 16:22:59 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Fri, 31 Jan 2025 09:22:59 -0600
Subject: [R-pkg-devel] Rcpp in vignette
In-Reply-To: <BN7PR03MB3649C5E36F55FD09F91FCF099BE82@BN7PR03MB3649.namprd03.prod.outlook.com>
References: <BN7PR03MB3649C5E36F55FD09F91FCF099BE82@BN7PR03MB3649.namprd03.prod.outlook.com>
Message-ID: <26524.60115.18775.249566@rob.eddelbuettel.com>


Hi Wolfgang,

On 31 January 2025 at 15:02, Wolfgang Rolke via R-package-devel wrote:
| In the vignette of my package Rgof I create a function written in Rcpp, which is then passed and executed in some of the routines included in Rgof. The package passes all the checks on the various platform without errors, warnings or notes except on atlas and gcc13. There I get an error about not being able to find this function. For details see
| 
| https://github.com/r-hub2/productive-joking-manatee-Rgof/actions
| [https://opengraph.githubassets.com/b40e189207ca774a60d2c41f7b3410850dddf9a6816238d771e042279edbac03/r-hub2/productive-joking-manatee-Rgof]<https://github.com/r-hub2/productive-joking-manatee-Rgof/actions>
| Workflow runs ? r-hub2/productive-joking-manatee-Rgof ? GitHub<https://github.com/r-hub2/productive-joking-manatee-Rgof/actions>
| Created by R-hub. Contribute to r-hub2/productive-joking-manatee-Rgof development by creating an account on GitHub.
| github.com
| 
| Is this a known issue? Is there a workaround? I have not tested the package on all 20+ machines, which other ones have the same issue?
| 
| The package is already on CRAN, so this error does not lead to it to not being accepted. Still, I would like to know what the problem is and if there is a better way than just to ignore it.

I only glanced at it via the CRAN mirror repo [1] so some really quick thoughts:

- If the package is in such good standing at CRAN [2] but fails at r-hub, is
  the issue with CRAN or possibly with r-hub?  Can you reproduce locally?
  
- If the Rcpp chunk gives you trouble there after knitting, why not add the
  function to the package itself to call it like a regular package function?

- There is always the workaround of precomputing the call result and
  including it as static output if dynamically computed content gives you issues

- I think you have a mistatement about Rcpp on line 503, many of us have long
  used Rcpp function in multicore/multicpu settings

As always, if you think the question is specific enough to Rcpp you could ask
also on the Rcpp-devel mailing list that exists for such questions as several
experienced users and developers follow it.

Dirk

[1] https://github.com/cran/Rgof/blob/master/vignettes/Rgof.Rmd
[2] https://cloud.r-project.org/web/checks/check_results_Rgof.html

| 
| Thanks
| Wolfgang
| 
| 
| 	[[alternative HTML version deleted]]
| 
| ______________________________________________
| R-package-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-package-devel

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Fri Jan 31 17:44:24 2025
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Fri, 31 Jan 2025 17:44:24 +0100
Subject: [R-pkg-devel] Date of CRAN checks
In-Reply-To: <D5364A6D-A336-4AA9-BED6-3EDED61AE9D9@R-project.org>
References: <CAN+W6_uBLsOtqf43FoTTJPhEFMp4GviCXwNXJskmqKep8KkRbA@mail.gmail.com>
 <D5364A6D-A336-4AA9-BED6-3EDED61AE9D9@R-project.org>
Message-ID: <1c538758-e7ba-4274-902b-3f366e783c80@statistik.tu-dortmund.de>



On 29.01.2025 20:08, Simon Urbanek wrote:
> Llu?s,
> 
> the timestamps are generated by the CRAN server when it updates webpage from the actual check reports so it does not reflect the date/time of the check itself (neither does the timestamp of the URL as it is often re-generated). So in short, no, there is no way to know the timestamp of the check. I think it may be useful, so I'll see if we can add it.
> 
> That said, checks are not re-run 

That is true for Mac flavours. All others get regularly updated 
(R-devel), or at least if any dependency in the hierarchy is updated 
(Windows R-release/oldrelease).

Best,
Uwe Ligges


 > unless you update the version of your package (or there is an error 
caused by another package whose update will fix it), so in most cases 
waiting won't fix anything. If there is a problem you have to report it 
to the corresponding CRAN maintainer so for macOS that would be me.>
> Cheers,
> Simon
> 
> 
>> On Jan 30, 2025, at 5:10 AM, Llu?s Revilla <lluis.revilla at gmail.com> wrote:
>>
>> Dear list,
>>
>> Recently after a package update I noticed an ERROR on one flavor.
>> I believe this is some problem with the r-release-macos-x86_64 flavor.
>> But I'm not sure if this is fixed on the system or not.
>> I was waiting to see if this got fixed with time (and thanks to the CRAN
>> volunteers).
>>
>> A check landing page on CRAN had a date "Last updated on 2025-01-29
>> 08:49:42 CET." then it changed to "2025-01-29 15:49:25 CET.". Because there
>> are some checks that are still from the old version of the package and the
>> failing check is still failing, I'm not sure which checks were updated. Is
>> this the date of the landing page of all the checks, or all the checks are
>> updated up to that date?
>>
>> Bioconductor provides the time with two fields: StartedAt and EndedAt for
>> each flavor (and step).
>> I hoped to find a date on the check logs. It would make it easier to know
>> when it is updated and it has the same result as previously.
>> Is there a way to know when a given check was run on CRAN?
>>
>> Best regards,
>>
>> Llu?s
>>
>> PS:  The problem is shared by many packages (>50), the vignette can be
>> built but not rebuilt and it raises an error message about not finding
>> pandoc.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-package-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>>
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From kev|n@r@coombe@ @end|ng |rom gm@||@com  Fri Jan 31 17:48:33 2025
From: kev|n@r@coombe@ @end|ng |rom gm@||@com (Kevin R. Coombes)
Date: Fri, 31 Jan 2025 11:48:33 -0500
Subject: [R-pkg-devel] test script output
Message-ID: <da6db759-689d-4207-9734-4e8869e9fb07@gmail.com>

Hi,h

I have a package that has been in CRAN for years and is now failing 
checks because some of the output of a test script is differing on some 
machines in the fifth or sixth decimal place. I have managed to fix most 
of these issues (by using the "digits" argument in calls to "summary" to 
hide the differences). the only one that remains yields this R CMD check 
report:

   Comparing ?testDiff.Rout? to ?testDiff.Rout.save? ...52c52
< 2.600e-06 1.328e-01 4.666e-01 1.060e+00 1.369e+00 1.091e+01
---
>  0.000003  0.132800  0.466600  1.060000  1.369000 10.910000 

Here the digit-limited output is the same (to a human mathematician, though not to a string-matching computer), but one machine has decided to report the output in scientific notation. Both versions were produced by a command equivalent to
    print(summary(x, digits = 4))
What is the best cross-platform way to ensure that the output gets printed in the same format? Set "options(scipen=999)"? Pass some argument to "print" as well as to "summary"? (The other alternative I am considering is to just delete the script from the "tests" directory.)

Thanks,
    Kevin

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Jan 31 18:23:54 2025
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 31 Jan 2025 18:23:54 +0100
Subject: [R-pkg-devel] test script output
In-Reply-To: <da6db759-689d-4207-9734-4e8869e9fb07@gmail.com>
References: <da6db759-689d-4207-9734-4e8869e9fb07@gmail.com>
Message-ID: <26525.1834.134177.766980@stat.math.ethz.ch>

>>>>> Kevin R Coombes 
>>>>>     on Fri, 31 Jan 2025 11:48:33 -0500 writes:

    > Hi,

    > I have a package that has been in CRAN for years and is now failing 
    > checks because some of the output of a test script is differing on some 
    > machines in the fifth or sixth decimal place. I have managed to fix most 
    > of these issues (by using the "digits" argument in calls to "summary" to 
    > hide the differences). the only one that remains yields this R CMD check 
    > report:

    > Comparing ?testDiff.Rout? to ?testDiff.Rout.save? ...52c52
    > < 2.600e-06 1.328e-01 4.666e-01 1.060e+00 1.369e+00 1.091e+01
    > ---
    > > 0.000003  0.132800  0.466600  1.060000  1.369000 10.910000 

    > Here the digit-limited output is the same (to a human mathematician, though not to a string-matching computer), but one machine has decided to report the output in scientific notation.

I'm guessing you are slightly off here:
Almost surely it's *not* a difference in machine/platform but only in versions
of R-devel.

My guess comes from the fact that I've been the R core member
who committed this change to R-devel :
  ------------------------------------------------------------------------
  r87625 | maechler | 2025-01-24 16:58:25 +0100 (Fri, 24 Jan 2025)

  parametrize & improve accuracy in print(summary(<numbers>))
  ------------------------------------------------------------------------

a week ago.
... and BTW, if you look carefully, for the first entry, the new
output *is* slightly more accurate also in your example.

I agree that the switch from fixed point to
exponential/scientific format is "unlucky" in this case
[and even unnecessary: in this case, keeping fixed format and
 showing one digit more (using the same amount of characters),
 one could also have shown the 0.0000026 ...]

A workaround for you may be to set something like

   options(scipen = 2) # default is 0

in your testDiff.R  script  before printing

All this is only in R-devel, the development version of R...
and I have contemplated to add more tweaks to
print.summaryDefault()  for that upcoming version of R.

The fear stopping me to do more tweaking was that the
consequence could be even *more* (still small) changes in such
summary() printing output.

    >  Both versions were produced by a command equivalent to
    > print(summary(x, digits = 4))

As you may (or may not ..;-) guess from the above commit message ("parametrize")
is that  print(summary(<numbers>)) got a new argument zdigits.

So, instead of     print(summary(x, digits = 4))
you can, from R version 4.5 (currently only in the development
version of R) on use

    print(summary(x, digits = 4), digits = .., zdigits = ..)

but you could also --- already in current versions of R ---
tweak the output using

    print(summary(x, digits = 4), digits = <n>)

where you can play to see if  n=3 , n=4, or n=5
help you getting better results ..
... actually *not* 'digits = 4'  for summary() at all,
but only the digits argument to print(.)   {where you'll get a
the new 'zdigits' argument *additionally* in R-devel and future
R version's}.


    > What is the best cross-platform way to ensure that the output gets printed in the same format? Set "options(scipen=999)"? 

That's clearly too extreme to generally,
(I mentioned `scipen = 2` earlier).

> Alternatively, pass some argument to "print" as well as to  "summary"?

yes, see above.

> (The other alternative I am considering is to just delete the script from the "tests" directory.)

(I don't think that would be a good idea, .. but rather a very b.. one)


    > Thanks,
    > Kevin
Best,
Martin


From kev|n@r@coombe@ @end|ng |rom gm@||@com  Fri Jan 31 19:07:30 2025
From: kev|n@r@coombe@ @end|ng |rom gm@||@com (Kevin R. Coombes)
Date: Fri, 31 Jan 2025 13:07:30 -0500
Subject: [R-pkg-devel] test script output
In-Reply-To: <26525.1834.134177.766980@stat.math.ethz.ch>
References: <da6db759-689d-4207-9734-4e8869e9fb07@gmail.com>
 <26525.1834.134177.766980@stat.math.ethz.ch>
Message-ID: <074f1e4a-6a54-4c6e-9051-cf0fdd47b28b@gmail.com>

Thanks for the quick (detailed) response.

On 1/31/2025 12:23 PM, Martin Maechler wrote:
>>>>>> Kevin R Coombes
>>>>>>      on Fri, 31 Jan 2025 11:48:33 -0500 writes:
>      > Hi,
>
>      > I have a package that has been in CRAN for years and is now failing
>      > checks because some of the output of a test script is differing on some
>      > machines in the fifth or sixth decimal place. I have managed to fix most
>      > of these issues (by using the "digits" argument in calls to "summary" to
>      > hide the differences). the only one that remains yields this R CMD check
>      > report:
>
>      > Comparing ?testDiff.Rout? to ?testDiff.Rout.save? ...52c52
>      > < 2.600e-06 1.328e-01 4.666e-01 1.060e+00 1.369e+00 1.091e+01
>      > ---
>      > > 0.000003  0.132800  0.466600  1.060000  1.369000 10.910000
>
>      > Here the digit-limited output is the same (to a human mathematician, though not to a string-matching computer), but one machine has decided to report the output in scientific notation.
>
> I'm guessing you are slightly off here:
> Almost surely it's *not* a difference in machine/platform but only in versions
> of R-devel.
The original issues *were* platform dependent, where the fifth digit was 
off-by-one on some platforms. You are correct that what is left is 
because of your change in R-devel.
>
> My guess comes from the fact that I've been the R core member
> who committed this change to R-devel :
>    ------------------------------------------------------------------------
>    r87625 | maechler | 2025-01-24 16:58:25 +0100 (Fri, 24 Jan 2025)
>
>    parametrize & improve accuracy in print(summary(<numbers>))
>    ------------------------------------------------------------------------
>
> a week ago.
> ... and BTW, if you look carefully, for the first entry, the new
> output *is* slightly more accurate also in your example.
Certainly, it is more accurate. But less accurate (in the form of fewer 
digits) was what I needed to solve the cross-platform issues in the 
current release.
> I agree that the switch from fixed point to
> exponential/scientific format is "unlucky" in this case
> [and even unnecessary: in this case, keeping fixed format and
>   showing one digit more (using the same amount of characters),
>   one could also have shown the 0.0000026 ...]
>
> A workaround for you may be to set something like
>
>     options(scipen = 2) # default is 0
>
> in your testDiff.R  script  before printing
>
> All this is only in R-devel, the development version of R...
> and I have contemplated to add more tweaks to
> print.summaryDefault()  for that upcoming version of R.
>
> The fear stopping me to do more tweaking was that the
> consequence could be even *more* (still small) changes in such
> summary() printing output.
>
>      >  Both versions were produced by a command equivalent to
>      > print(summary(x, digits = 4))
>
> As you may (or may not ..;-) guess from the above commit message ("parametrize")
> is that  print(summary(<numbers>)) got a new argument zdigits.
Yes. But I can't use the new devel-version argument to fix the problem 
in the current release...
> So, instead of     print(summary(x, digits = 4))
> you can, from R version 4.5 (currently only in the development
> version of R) on use
>
>      print(summary(x, digits = 4), digits = .., zdigits = ..)
>
> but you could also --- already in current versions of R ---
> tweak the output using
>
>      print(summary(x, digits = 4), digits = <n>)
>
> where you can play to see if  n=3 , n=4, or n=5
> help you getting better results ..
> ... actually *not* 'digits = 4'  for summary() at all,
> but only the digits argument to print(.)   {where you'll get a
> the new 'zdigits' argument *additionally* in R-devel and future
> R version's}.
>
>
>      > What is the best cross-platform way to ensure that the output gets printed in the same format? Set "options(scipen=999)"?
>
> That's clearly too extreme to generally,
> (I mentioned `scipen = 2` earlier).
>
>> Alternatively, pass some argument to "print" as well as to  "summary"?
> yes, see above.
>
>> (The other alternative I am considering is to just delete the script from the "tests" directory.)
> (I don't think that would be a good idea, .. but rather a very b.. one)

Ah, but it may have helped someone who knew what they were talking about 
to answer more rapidly to avoid the bad solution. Thanks again.

I will try the options(scipen) fix for now, and keep the new zdigts 
argument in mind going forward.

>
>
>      > Thanks,
>      > Kevin
> Best,
> Martin
>


From Bernd@Gruber @end|ng |rom c@nberr@@edu@@u  Sun Feb  2 23:56:47 2025
From: Bernd@Gruber @end|ng |rom c@nberr@@edu@@u (Bernd.Gruber)
Date: Sun, 2 Feb 2025 22:56:47 +0000
Subject: [R-pkg-devel] Additional issue clang-ASAN, gcc-ASAN
In-Reply-To: <mailman.11256.10.1738407601.11304.r-package-devel@r-project.org>
References: <mailman.11256.10.1738407601.11304.r-package-devel@r-project.org>
Message-ID: <ME3PR01MB7944A3A9807CADA986349B4CD4EA2@ME3PR01MB7944.ausprd01.prod.outlook.com>

Hi,

I was requested to update my package (dartR.base) that shows a note for an old mac release and the errors below:

Additional issues<https://cran.r-project.org/web/checks/check_issue_kinds.html>
clang-ASAN<https://www.stats.ox.ac.uk/pub/bdr/memtests/clang-ASAN/dartR.base> gcc-ASAN<https://www.stats.ox.ac.uk/pub/bdr/memtests/gcc-ASAN/dartR.base>

When I look into those links I see the output below.

It seems to break when running an example, but the example runs just fine on my machine and also other systems. So no clue what is going on the the output below is definitely above my paygrade.

Any help here would be highly appreciated.

Thanks in advance

* using log directory '/data/gannet/ripley/R/packages/tests-clang-ASAN/dartR.base.Rcheck'
* using R Under development (unstable) (2025-01-31 r87670)
* using platform: x86_64-pc-linux-gnu
* R was compiled by
    clang version 19.1.7
    flang-new version 19.1.7
* running under: Fedora Linux 36 (Workstation Edition)
* using session charset: UTF-8
* using option '--no-stop-on-test-error'
* checking for file 'dartR.base/DESCRIPTION' ... OK
* checking extension type ... Package
* this is package 'dartR.base' version '0.98'
* package encoding: UTF-8
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking if there is a namespace ... OK
* checking for hidden files and directories ... OK
* checking for portable file names ... OK
* checking whether package 'dartR.base' can be installed ... [234s/475s] OK
* checking package directory ... OK
* checking whether the package can be loaded ... [23s/28s] OK
* checking whether the package can be loaded with stated dependencies ... [22s/26s] OK
* checking whether the package can be unloaded cleanly ... [22s/25s] OK
* checking whether the namespace can be loaded with stated dependencies ... [19s/20s] OK
* checking whether the namespace can be unloaded cleanly ... [23s/24s] OK
* checking loading without being on the library search path ... [22s/22s] OK
* checking examples ... [81s/88s] ERROR
Running examples in 'dartR.base-Ex.R' failed
The error most likely occurred in:

> ### Name: gl.filter.factorloadings
> ### Title: Filters loci based on factor loadings for a PCA or PCoA
> ### Aliases: gl.filter.factorloadings
>
> ### ** Examples
>
> pca <- gl.pcoa(testset.gl)
Starting gl.pcoa
  Processing genlight object with SNP data
  Warning: Number of loci is less than the number of individuals to be represented
  Performing a PCA, individuals as entities, loci as attributes, SNP genotype as state
=================================================================
==2742437==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x518000697ff0 at pc 0x7f2e873ccfe0 bp 0x7ffdac8d25d0 sp 0x7ffdac8d25c8
READ of size 16 at 0x518000697ff0 thread T0
    #0 0x7f2e873ccfdf in bytesToDouble /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:225:19
    #1 0x7f2e873ceca5 in snpbin2freq /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:332:5
    #2 0x7f2e873ceca5 in snpbin_dotprod_freq /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:447:5
    #3 0x7f2e873bba42 in GLdotProd /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/GLfunctions.c:42:14
    #4 0x5653c6191567 in do_dotCode /data/gannet/ripley/R/svn/R-devel/src/main/dotcode.c
    #5 0x5653c6232f7f in bcEval_loop /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:8122:14
    #6 0x5653c6225384 in bcEval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:7505:16
    #7 0x5653c622389a in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1167:8
    #8 0x5653c626d36c in R_execClosure /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2393:22
    #9 0x5653c626c531 in applyClosure_core /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2306:16
    #10 0x5653c62242e9 in Rf_applyClosure /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2328:16
    #11 0x5653c62242e9 in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1280:12
    #12 0x5653c627ee00 in do_set /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:3571:8
    #13 0x5653c6223de3 in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1232:12
    #14 0x5653c62faa9a in Rf_ReplIteration /data/gannet/ripley/R/svn/R-devel/src/main/main.c:265:2
    #15 0x5653c62fd1d0 in R_ReplConsole /data/gannet/ripley/R/svn/R-devel/src/main/main.c:317:11
    #16 0x5653c62fd1d0 in run_Rmainloop /data/gannet/ripley/R/svn/R-devel/src/main/main.c:1219:5
    #17 0x5653c62fd262 in Rf_mainloop /data/gannet/ripley/R/svn/R-devel/src/main/main.c:1226:5
    #18 0x5653c600720c in main /data/gannet/ripley/R/svn/R-devel/src/main/Rmain.c:29:5
    #19 0x7f2e9fc2950f in __libc_start_call_main (/lib64/libc.so.6+0x2950f) (BuildId: 8257ee907646e9b057197533d1e4ac8ede7a9c5c)
    #20 0x7f2e9fc295c8 in __libc_start_main at GLIBC_2.2.5 (/lib64/libc.so.6+0x295c8) (BuildId: 8257ee907646e9b057197533d1e4ac8ede7a9c5c)
    #21 0x5653c5f274e4 in _start (/data/gannet/ripley/R/clang-ASAN/bin/exec/R+0x1574e4)

0x518000697ff8 is located 0 bytes after 888-byte region [0x518000697c80,0x518000697ff8)
allocated by thread T0 here:
    #0 0x5653c5fc44b9 in calloc /data/gannet/ripley/Sources2/LLVM/19/latest/compiler-rt/lib/asan/asan_malloc_linux.cpp:75:3
    #1 0x7f2e873cebca in snpbin_dotprod_freq /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:443:23
    #2 0x7f2e873bba42 in GLdotProd /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/GLfunctions.c:42:14
    #3 0x5653c6191567 in do_dotCode /data/gannet/ripley/R/svn/R-devel/src/main/dotcode.c
    #4 0x5653c6232f7f in bcEval_loop /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:8122:14
    #5 0x5653c6225384 in bcEval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:7505:16
    #6 0x5653c622389a in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1167:8
    #7 0x5653c626d36c in R_execClosure /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2393:22
    #8 0x5653c626c531 in applyClosure_core /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2306:16
    #9 0x5653c62242e9 in Rf_applyClosure /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2328:16
    #10 0x5653c62242e9 in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1280:12
    #11 0x5653c627ee00 in do_set /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:3571:8
    #12 0x5653c6223de3 in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1232:12
    #13 0x5653c62faa9a in Rf_ReplIteration /data/gannet/ripley/R/svn/R-devel/src/main/main.c:265:2
    #14 0x5653c62fd1d0 in R_ReplConsole /data/gannet/ripley/R/svn/R-devel/src/main/main.c:317:11
    #15 0x5653c62fd1d0 in run_Rmainloop /data/gannet/ripley/R/svn/R-devel/src/main/main.c:1219:5
    #16 0x5653c62fd262 in Rf_mainloop /data/gannet/ripley/R/svn/R-devel/src/main/main.c:1226:5
    #17 0x5653c600720c in main /data/gannet/ripley/R/svn/R-devel/src/main/Rmain.c:29:5
    #18 0x7f2e9fc2950f in __libc_start_call_main (/lib64/libc.so.6+0x2950f) (BuildId: 8257ee907646e9b057197533d1e4ac8ede7a9c5c)

SUMMARY: AddressSanitizer: heap-buffer-overflow /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:225:19 in bytesToDouble
Shadow bytes around the buggy address:
  0x518000697d00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x518000697d80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x518000697e00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x518000697e80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x518000697f00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
=>0x518000697f80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00[00]fa
  0x518000698000: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x518000698080: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x518000698100: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x518000698180: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x518000698200: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07
  Heap left redzone:       fa
  Freed heap region:       fd
  Stack left redzone:      f1
  Stack mid redzone:       f2
  Stack right redzone:     f3
  Stack after return:      f5
  Stack use after scope:   f8
  Global redzone:          f9
  Global init order:       f6
  Poisoned by user:        f7
  Container overflow:      fc
  Array cookie:            ac
  Intra object redzone:    bb
  ASan internal:           fe
  Left alloca redzone:     ca
  Right alloca redzone:    cb
==2742437==ABORTING
* DONE
Status: 1 ERROR


From: R-package-devel <r-package-devel-bounces at r-project.org> On Behalf Of r-package-devel-request at r-project.org
Sent: Saturday, 1 February 2025 10:00 PM
To: r-package-devel at r-project.org
Subject: R-package-devel Digest, Vol 118, Issue 1

Send R-package-devel mailing list submissions to
r-package-devel at r-project.org<mailto:r-package-devel at r-project.org>

To subscribe or unsubscribe via the World Wide Web, visit
https://stat.ethz.ch/mailman/listinfo/r-package-devel<https://stat.ethz.ch/mailman/listinfo/r-package-devel>
or, via email, send a message with subject or body 'help' to
r-package-devel-request at r-project.org<mailto:r-package-devel-request at r-project.org>

You can reach the person managing the list at
r-package-devel-owner at r-project.org<mailto:r-package-devel-owner at r-project.org>


[UC Logo]<http://www.canberra.edu.au>

[Adobe Creative Campus. Fuel your ceativity, Adobe Express free for all UC Students and Staff.]<https://www.canberra.edu.au/on-campus/adobe-creative-campus/>



The Ngunnawal people are the Traditional Custodians of the ACT where UC's Bruce Campus is situated and are an integral and celebrated part of UC's culture. We also acknowledge other First Nations Peoples.

Australian Government Higher Education Registered Provider (CRICOS) #00212K. TEQSA Provider ID: PRV12003 (Australian University)
Email Disclaimer<https://www.canberra.edu.au/about-uc/disclaimer-copyright-privacy-accessibility>

[UC Facebook]<https://www.facebook.com/UniversityOfCanberra>  [UC Instagram] <https://www.instagram.com/unicanberra/>     [UC Linkedin] <https://au.linkedin.com/school/university-of-canberra/>     [UC Youtube] <https://www.youtube.com/user/uniofcanberra>  [University of Canberra] <http://www.canberra.edu.au>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Feb  3 01:59:22 2025
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 2 Feb 2025 19:59:22 -0500
Subject: [R-pkg-devel] Additional issue clang-ASAN, gcc-ASAN
In-Reply-To: <ME3PR01MB7944A3A9807CADA986349B4CD4EA2@ME3PR01MB7944.ausprd01.prod.outlook.com>
References: <mailman.11256.10.1738407601.11304.r-package-devel@r-project.org>
 <ME3PR01MB7944A3A9807CADA986349B4CD4EA2@ME3PR01MB7944.ausprd01.prod.outlook.com>
Message-ID: <c708c566-05ea-40ca-ae49-a5ac436ce445@gmail.com>

   At first glance, it seems to be happening when you call functions in 
the adegenet package, specifically here:

https://github.com/thibautjombart/adegenet/blob/master/src/snpbin.c#L225

   The CRAN checks for the adegenet package aren't showing a problem; my 
guess is that your code is exercising part of the adegenet code base 
that isn't covered in that package's own tests and examples ... I would 
ask the 'adegenet' maintainer for help tracking and solving the problem ...

On 2025-02-02 5:56 p.m., Bernd.Gruber wrote:
> Hi,
> 
> I was requested to update my package (dartR.base) that shows a note for an old mac release and the errors below:
> 
> Additional issues<https://cran.r-project.org/web/checks/check_issue_kinds.html>
> clang-ASAN<https://www.stats.ox.ac.uk/pub/bdr/memtests/clang-ASAN/dartR.base> gcc-ASAN<https://www.stats.ox.ac.uk/pub/bdr/memtests/gcc-ASAN/dartR.base>
> 
> When I look into those links I see the output below.
> 
> It seems to break when running an example, but the example runs just fine on my machine and also other systems. So no clue what is going on the the output below is definitely above my paygrade.
> 
> Any help here would be highly appreciated.
> 
> Thanks in advance
> 
> * using log directory '/data/gannet/ripley/R/packages/tests-clang-ASAN/dartR.base.Rcheck'
> * using R Under development (unstable) (2025-01-31 r87670)
> * using platform: x86_64-pc-linux-gnu
> * R was compiled by
>      clang version 19.1.7
>      flang-new version 19.1.7
> * running under: Fedora Linux 36 (Workstation Edition)
> * using session charset: UTF-8
> * using option '--no-stop-on-test-error'
> * checking for file 'dartR.base/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'dartR.base' version '0.98'
> * package encoding: UTF-8
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking if there is a namespace ... OK
> * checking for hidden files and directories ... OK
> * checking for portable file names ... OK
> * checking whether package 'dartR.base' can be installed ... [234s/475s] OK
> * checking package directory ... OK
> * checking whether the package can be loaded ... [23s/28s] OK
> * checking whether the package can be loaded with stated dependencies ... [22s/26s] OK
> * checking whether the package can be unloaded cleanly ... [22s/25s] OK
> * checking whether the namespace can be loaded with stated dependencies ... [19s/20s] OK
> * checking whether the namespace can be unloaded cleanly ... [23s/24s] OK
> * checking loading without being on the library search path ... [22s/22s] OK
> * checking examples ... [81s/88s] ERROR
> Running examples in 'dartR.base-Ex.R' failed
> The error most likely occurred in:
> 
>> ### Name: gl.filter.factorloadings
>> ### Title: Filters loci based on factor loadings for a PCA or PCoA
>> ### Aliases: gl.filter.factorloadings
>>
>> ### ** Examples
>>
>> pca <- gl.pcoa(testset.gl)
> Starting gl.pcoa
>    Processing genlight object with SNP data
>    Warning: Number of loci is less than the number of individuals to be represented
>    Performing a PCA, individuals as entities, loci as attributes, SNP genotype as state
> =================================================================
> ==2742437==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x518000697ff0 at pc 0x7f2e873ccfe0 bp 0x7ffdac8d25d0 sp 0x7ffdac8d25c8
> READ of size 16 at 0x518000697ff0 thread T0
>      #0 0x7f2e873ccfdf in bytesToDouble /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:225:19
>      #1 0x7f2e873ceca5 in snpbin2freq /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:332:5
>      #2 0x7f2e873ceca5 in snpbin_dotprod_freq /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:447:5
>      #3 0x7f2e873bba42 in GLdotProd /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/GLfunctions.c:42:14
>      #4 0x5653c6191567 in do_dotCode /data/gannet/ripley/R/svn/R-devel/src/main/dotcode.c
>      #5 0x5653c6232f7f in bcEval_loop /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:8122:14
>      #6 0x5653c6225384 in bcEval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:7505:16
>      #7 0x5653c622389a in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1167:8
>      #8 0x5653c626d36c in R_execClosure /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2393:22
>      #9 0x5653c626c531 in applyClosure_core /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2306:16
>      #10 0x5653c62242e9 in Rf_applyClosure /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2328:16
>      #11 0x5653c62242e9 in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1280:12
>      #12 0x5653c627ee00 in do_set /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:3571:8
>      #13 0x5653c6223de3 in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1232:12
>      #14 0x5653c62faa9a in Rf_ReplIteration /data/gannet/ripley/R/svn/R-devel/src/main/main.c:265:2
>      #15 0x5653c62fd1d0 in R_ReplConsole /data/gannet/ripley/R/svn/R-devel/src/main/main.c:317:11
>      #16 0x5653c62fd1d0 in run_Rmainloop /data/gannet/ripley/R/svn/R-devel/src/main/main.c:1219:5
>      #17 0x5653c62fd262 in Rf_mainloop /data/gannet/ripley/R/svn/R-devel/src/main/main.c:1226:5
>      #18 0x5653c600720c in main /data/gannet/ripley/R/svn/R-devel/src/main/Rmain.c:29:5
>      #19 0x7f2e9fc2950f in __libc_start_call_main (/lib64/libc.so.6+0x2950f) (BuildId: 8257ee907646e9b057197533d1e4ac8ede7a9c5c)
>      #20 0x7f2e9fc295c8 in __libc_start_main at GLIBC_2.2.5 (/lib64/libc.so.6+0x295c8) (BuildId: 8257ee907646e9b057197533d1e4ac8ede7a9c5c)
>      #21 0x5653c5f274e4 in _start (/data/gannet/ripley/R/clang-ASAN/bin/exec/R+0x1574e4)
> 
> 0x518000697ff8 is located 0 bytes after 888-byte region [0x518000697c80,0x518000697ff8)
> allocated by thread T0 here:
>      #0 0x5653c5fc44b9 in calloc /data/gannet/ripley/Sources2/LLVM/19/latest/compiler-rt/lib/asan/asan_malloc_linux.cpp:75:3
>      #1 0x7f2e873cebca in snpbin_dotprod_freq /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:443:23
>      #2 0x7f2e873bba42 in GLdotProd /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/GLfunctions.c:42:14
>      #3 0x5653c6191567 in do_dotCode /data/gannet/ripley/R/svn/R-devel/src/main/dotcode.c
>      #4 0x5653c6232f7f in bcEval_loop /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:8122:14
>      #5 0x5653c6225384 in bcEval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:7505:16
>      #6 0x5653c622389a in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1167:8
>      #7 0x5653c626d36c in R_execClosure /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2393:22
>      #8 0x5653c626c531 in applyClosure_core /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2306:16
>      #9 0x5653c62242e9 in Rf_applyClosure /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:2328:16
>      #10 0x5653c62242e9 in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1280:12
>      #11 0x5653c627ee00 in do_set /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:3571:8
>      #12 0x5653c6223de3 in Rf_eval /data/gannet/ripley/R/svn/R-devel/src/main/eval.c:1232:12
>      #13 0x5653c62faa9a in Rf_ReplIteration /data/gannet/ripley/R/svn/R-devel/src/main/main.c:265:2
>      #14 0x5653c62fd1d0 in R_ReplConsole /data/gannet/ripley/R/svn/R-devel/src/main/main.c:317:11
>      #15 0x5653c62fd1d0 in run_Rmainloop /data/gannet/ripley/R/svn/R-devel/src/main/main.c:1219:5
>      #16 0x5653c62fd262 in Rf_mainloop /data/gannet/ripley/R/svn/R-devel/src/main/main.c:1226:5
>      #17 0x5653c600720c in main /data/gannet/ripley/R/svn/R-devel/src/main/Rmain.c:29:5
>      #18 0x7f2e9fc2950f in __libc_start_call_main (/lib64/libc.so.6+0x2950f) (BuildId: 8257ee907646e9b057197533d1e4ac8ede7a9c5c)
> 
> SUMMARY: AddressSanitizer: heap-buffer-overflow /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:225:19 in bytesToDouble
> Shadow bytes around the buggy address:
>    0x518000697d00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
>    0x518000697d80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
>    0x518000697e00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
>    0x518000697e80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
>    0x518000697f00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
> =>0x518000697f80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00[00]fa
>    0x518000698000: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
>    0x518000698080: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
>    0x518000698100: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
>    0x518000698180: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
>    0x518000698200: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
> Shadow byte legend (one shadow byte represents 8 application bytes):
>    Addressable:           00
>    Partially addressable: 01 02 03 04 05 06 07
>    Heap left redzone:       fa
>    Freed heap region:       fd
>    Stack left redzone:      f1
>    Stack mid redzone:       f2
>    Stack right redzone:     f3
>    Stack after return:      f5
>    Stack use after scope:   f8
>    Global redzone:          f9
>    Global init order:       f6
>    Poisoned by user:        f7
>    Container overflow:      fc
>    Array cookie:            ac
>    Intra object redzone:    bb
>    ASan internal:           fe
>    Left alloca redzone:     ca
>    Right alloca redzone:    cb
> ==2742437==ABORTING
> * DONE
> Status: 1 ERROR
> 
> 
> From: R-package-devel <r-package-devel-bounces at r-project.org> On Behalf Of r-package-devel-request at r-project.org
> Sent: Saturday, 1 February 2025 10:00 PM
> To: r-package-devel at r-project.org
> Subject: R-package-devel Digest, Vol 118, Issue 1
> 
> Send R-package-devel mailing list submissions to
> r-package-devel at r-project.org<mailto:r-package-devel at r-project.org>
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> https://stat.ethz.ch/mailman/listinfo/r-package-devel<https://stat.ethz.ch/mailman/listinfo/r-package-devel>
> or, via email, send a message with subject or body 'help' to
> r-package-devel-request at r-project.org<mailto:r-package-devel-request at r-project.org>
> 
> You can reach the person managing the list at
> r-package-devel-owner at r-project.org<mailto:r-package-devel-owner at r-project.org>
> 
> 
> [UC Logo]<http://www.canberra.edu.au>
> 
> [Adobe Creative Campus. Fuel your ceativity, Adobe Express free for all UC Students and Staff.]<https://www.canberra.edu.au/on-campus/adobe-creative-campus/>
> 
> 
> 
> The Ngunnawal people are the Traditional Custodians of the ACT where UC's Bruce Campus is situated and are an integral and celebrated part of UC's culture. We also acknowledge other First Nations Peoples.
> 
> Australian Government Higher Education Registered Provider (CRICOS) #00212K. TEQSA Provider ID: PRV12003 (Australian University)
> Email Disclaimer<https://www.canberra.edu.au/about-uc/disclaimer-copyright-privacy-accessibility>
> 
> [UC Facebook]<https://www.facebook.com/UniversityOfCanberra>  [UC Instagram] <https://www.instagram.com/unicanberra/>     [UC Linkedin] <https://au.linkedin.com/school/university-of-canberra/>     [UC Youtube] <https://www.youtube.com/user/uniofcanberra>  [University of Canberra] <http://www.canberra.edu.au>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From john@c|@rke @end|ng |rom corner@tonenw@com  Mon Feb  3 10:07:49 2025
From: john@c|@rke @end|ng |rom corner@tonenw@com (John Clarke)
Date: Mon, 3 Feb 2025 10:07:49 +0100
Subject: [R-pkg-devel] 
 Rcpp: how best to include source from another Github repository
In-Reply-To: <26514.22165.946108.992254@rob.eddelbuettel.com>
References: <CAF0e1n9yrb+M+csGMeYpfFm35-fe4s4B5-8H0fQ-ov8yckEqZQ@mail.gmail.com>
 <e800be15-576a-477a-8de5-69cf9733e244@berrisch.biz>
 <26514.22165.946108.992254@rob.eddelbuettel.com>
Message-ID: <CAF0e1n8YFRp-7ev_gg78xggm_2PkvA6pBNkPhx_G9bqWoNzSCw@mail.gmail.com>

Thanks Dirk and others -- I see the tradeoffs now. In my case, I think a
simple copy of source (just a few files), plus maybe some sort of
commit/tag reference to indicate where/when the source is coming from. -John

On Thu, Jan 23, 2025 at 3:47?PM Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 21 January 2025 at 12:04, Jonathan Berrisch wrote:
> | first of all: I'm not an expert on this and don't really know if there
> | is a recommended way.
> |
> | However, you may look at my 'rcpptimer' package and how it includes
> | 'cpptimer' as a submodule.
> |
> | You can find the repository here: https://github.com/BerriJ/rcpptimer
>
> I had written a longer (private) email to John expressing the view that git
> submodules "were once more 'en vogue'" but one sees them less these days.
> One reason is that they break some (somewhat standard) workflows, see
> below.
>
> Overall, this is "no win" situation. You can include the files in the
> package
> as a copy [2] enlarging the package, build process, etc but arguably making
> it more robust, or you can keep it external which is cleaner -- but harder
> as
> you now have to ensure users (and CRAN !) can get / have that library.
>
> So it is all tradeoffs one has to make.
>
> Dirk
>
>
> [1] Log from a standard r2u Ubuntu container, `git` and `ssh` added as
> needed:
>
> root at 4163d5544547:/# installGithub.r https://github.com/BerriJ/rcpptimer
> Downloading GitHub repo BerriJ/rcpptimer at HEAD
> '/usr/bin/git' clone --depth 1 --no-hardlinks --recurse-submodules
> git at github.com:BerriJ/cpptimer.git
> /tmp/remotes257564d64e0/BerriJ-rcpptimer-35ca024/inst/include/cpptimer
> Cloning into
> '/tmp/remotes257564d64e0/BerriJ-rcpptimer-35ca024/inst/include/cpptimer'...
> The authenticity of host 'github.com (140.82.113.3)' can't be established.
> ED25519 key fingerprint is
> SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU.
> This key is not known by any other names.
> Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
> Warning: Permanently added 'github.com' (ED25519) to the list of known
> hosts.
> git at github.com: Permission denied (publickey).
> fatal: Could not read from remote repository.
>
> Please make sure you have the correct access rights
> and the repository exists.
> Error: Failed to install 'rcpptimer' from GitHub:
>   Command failed (128)
> In addition: Warning message:
> In system(full, intern = TRUE, ignore.stderr = quiet) :
>   running command ''/usr/bin/git' clone --depth 1 --no-hardlinks
> --recurse-submodules git at github.com:BerriJ/cpptimer.git
> /tmp/remotes257564d64e0/BerriJ-rcpptimer-35ca024/inst/include/cpptimer' had
> status 128 and error message 'Function not implemented'
> root at 4163d5544547:/#
> exit
>
>
> [2] The "Rcpp-library" vignette John refers to also mentions (IIRC) that
> this
> is preferable for smaller libraries; its 'corels' example fits that
> description.  These days other authors also vendor entire applications such
> as whole SQL engines: ?\_(?)_/?  I just updated qlcal on CRAN, it
> explicitly
> copies the calendaring (subset) from QuantLib as I learned over 20 years
> that
> users have difficulties with that large library. Tradeoffs.
>
> --
> dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From john@c|@rke @end|ng |rom corner@tonenw@com  Mon Feb  3 13:26:14 2025
From: john@c|@rke @end|ng |rom corner@tonenw@com (John Clarke)
Date: Mon, 3 Feb 2025 13:26:14 +0100
Subject: [R-pkg-devel] 
 Is it possible to install a pre-compiled R package from Github?
In-Reply-To: <20250128173658.1c126b0f@arachnoid>
References: <CAF0e1n_dvt6igMxDWqh7bjMyBra_4ceLQThRiS3bPa0RCuzLWw@mail.gmail.com>
 <20250128173658.1c126b0f@arachnoid>
Message-ID: <CAF0e1n81WNkA+f2K6_7W_VWTchaWtTjnxmXh1L=7QooykTOozw@mail.gmail.com>

Thanks Ivan, I?aki, and Dirk for your answers -- I'm happy to know about
https://r-universe.dev/. I also deduce that I can compile my own binaries
and host them as releases in Github and have R users install from these
binaries as well. Kind regards, -John

On Tue, Jan 28, 2025 at 3:37?PM Ivan Krylov <ikrylov at disroot.org> wrote:

> ? Tue, 28 Jan 2025 14:25:23 +0100
> John Clarke <john.clarke at cornerstonenw.com> ?????:
>
> > I'm wondering if there is a way to point an R package installer to a
> > pre-compiled release on Github rather than rely on CRAN.
>
> From the point of view of install.packages(), a repository is a
> collection of package files plus an index file arranged in a certain
> directory structure:
>
> https://cran.r-project.org/doc/manuals/R-admin.html#Setting-up-a-package-repository
>
> You can create these index files yourself using tools::write_PACKAGES()
> or the 'drat' package, then publish them on any free web hosting:
> https://search.r-project.org/R/refmans/tools/html/writePACKAGES.html
> https://cran.r-project.org/package=drat
>
> install.packages() will then be able to use this repository using
> either its contriburl=... or the repos=... argument.
>
> The above-mentioned R-Universe will, indeed, not only help you host
> your packages, but also build your source packages into binary packages
> for a number of platforms.
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Tue Feb  4 12:30:03 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 4 Feb 2025 14:30:03 +0300
Subject: [R-pkg-devel] Additional issue clang-ASAN, gcc-ASAN
In-Reply-To: <ME3PR01MB7944A3A9807CADA986349B4CD4EA2@ME3PR01MB7944.ausprd01.prod.outlook.com>
References: <mailman.11256.10.1738407601.11304.r-package-devel@r-project.org>
 <ME3PR01MB7944A3A9807CADA986349B4CD4EA2@ME3PR01MB7944.ausprd01.prod.outlook.com>
Message-ID: <20250204143003.22982e7b@arachnoid>

? Sun, 2 Feb 2025 22:56:47 +0000
Bernd.Gruber <Bernd.Gruber at canberra.edu.au> ?????:

> READ of size 16 at 0x518000697ff0 thread T0
>     #0 0x7f2e873ccfdf in bytesToDouble
> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:225:19
> #1 0x7f2e873ceca5 in snpbin2freq
> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:332:5
> #2 0x7f2e873ceca5 in snpbin_dotprod_freq
> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:447:5
> #3 0x7f2e873bba42 in GLdotProd
> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/GLfunctions.c:42:14

Ben Bolker is exactly right; the problem happens in the 'adegenet'
code. Why?

bytesToDouble() is asked to unpack the bytes from the 'vecbytes' array
(26 bytes) into individual bits stored as doubles in the 'out' array.
The latter was allocated by the snpbin_dotprod_freq() function to
contain 199 elements [1]. Every byte must be unpacked into 8 bits, and
199 is less than 26*8 = 208. Where did the values come from?

The C function GLsumFreq() stores them unchanged from its arguments
[2], and those come from the SNPbin objects passed by R code [3] from
nLoc(x) and length(x$gen[[1]]@snp[[1]]). Where do they originate?

The R traceback at the point of the crash is dartR.base::gl.pcoa ->
adegenet::glPca -> adegenet::glDotProd. The object 'possums.gl' of S4
class 'dartR' exported by 'dartR.base' appears valid: its .$n.loc is
exactly equal to length(.$gen[[1]]@snp[[1]]) * 8, so the allocation size
matches the packed binary content.

The subset possums.gl[1:50,] that is used to perform PCA, on the other
hand, is invalid: length(possums.gl[1:50,]$gen[[1]]@snp[[1]]) is 26
instead of 25, which later causes bytesToDouble() to try to write extra
8 doubles (64 bytes) into the buffer.

This happens because trying to extract all SNPs from an SNPbin object
introduces an extra byte:

possums.gl at gen[[1]] |> _ at snp |> lengths()
# [1] 25 25

possums.gl at gen[[1]][rep(TRUE, nLoc(possums.gl at gen[[1]]))] |>
 _ at snp |> lengths()
# 26 26

This can be traced to a bug in adegenet:::.subsetbin:

.subsetbin(as.raw(0xff), 1:8)
# [1] ff 00 # <-- should be just 'ff'

xint <- as.integer(rawToBits(x)[i]) # may be not divisible by 8
# so introduce padding: the following line gives 8 bits of padding
# instead of 0 when length(xint) is divisible by 8
zeroes <- 8 - (length(xint)%%8)
# instead use something like:
# zeroes <- (8 - (length(xint)%%8)) * (length(xint)%%8 > 0)
# (could probably be golfed further)
return(packBits(c(xint, rep(0L, zeroes))))

But we're getting two bugs for the price of one, because even with a
25-byte buffer, nLoc(.) == 199 would still result in an 8-byte
overflow. This is solely on the bytesToDouble() C function: it ought to
know to stop after writing *reslength elements into the 'vecres' array.

I'm afraid there is no easy way to work around either of the bugs in
the dartR.base code.

-- 
Best regards,
Ivan

[1]
https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/src/snpbin.c#L443-L444

[2]
https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/src/GLfunctions.c#L124

[3]
https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/R/glFunctions.R#L215-L216


From |uc@r @end|ng |rom |edor@project@org  Tue Feb  4 12:46:04 2025
From: |uc@r @end|ng |rom |edor@project@org (=?UTF-8?Q?I=C3=B1aki_Ucar?=)
Date: Tue, 4 Feb 2025 12:46:04 +0100
Subject: [R-pkg-devel] Additional issue clang-ASAN, gcc-ASAN
In-Reply-To: <20250204143003.22982e7b@arachnoid>
References: <mailman.11256.10.1738407601.11304.r-package-devel@r-project.org>
 <ME3PR01MB7944A3A9807CADA986349B4CD4EA2@ME3PR01MB7944.ausprd01.prod.outlook.com>
 <20250204143003.22982e7b@arachnoid>
Message-ID: <CALEXWq3_vDeJHNVLgFjdKAMcmAYPT32yLvDN=i3bhOjJnwu=Lw@mail.gmail.com>

@Ivan: Excellent anaylsis as always.

@Bernd: So what can **you** do about it? You are using adegenet
correctly as Ivan pointed out, so IMHO CRAN should have requested
adegenet's maintainer to fix this. But since it's your package that is
on the line here, I would put that example inside a dontrun{} chunk
for now, to avoid triggering this issue on CRAN, and I would report
Ivan's analysis upstream.

I?aki


On Tue, 4 Feb 2025 at 12:30, Ivan Krylov via R-package-devel
<r-package-devel at r-project.org> wrote:
>
> ? Sun, 2 Feb 2025 22:56:47 +0000
> Bernd.Gruber <Bernd.Gruber at canberra.edu.au> ?????:
>
> > READ of size 16 at 0x518000697ff0 thread T0
> >     #0 0x7f2e873ccfdf in bytesToDouble
> > /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:225:19
> > #1 0x7f2e873ceca5 in snpbin2freq
> > /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:332:5
> > #2 0x7f2e873ceca5 in snpbin_dotprod_freq
> > /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:447:5
> > #3 0x7f2e873bba42 in GLdotProd
> > /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/GLfunctions.c:42:14
>
> Ben Bolker is exactly right; the problem happens in the 'adegenet'
> code. Why?
>
> bytesToDouble() is asked to unpack the bytes from the 'vecbytes' array
> (26 bytes) into individual bits stored as doubles in the 'out' array.
> The latter was allocated by the snpbin_dotprod_freq() function to
> contain 199 elements [1]. Every byte must be unpacked into 8 bits, and
> 199 is less than 26*8 = 208. Where did the values come from?
>
> The C function GLsumFreq() stores them unchanged from its arguments
> [2], and those come from the SNPbin objects passed by R code [3] from
> nLoc(x) and length(x$gen[[1]]@snp[[1]]). Where do they originate?
>
> The R traceback at the point of the crash is dartR.base::gl.pcoa ->
> adegenet::glPca -> adegenet::glDotProd. The object 'possums.gl' of S4
> class 'dartR' exported by 'dartR.base' appears valid: its .$n.loc is
> exactly equal to length(.$gen[[1]]@snp[[1]]) * 8, so the allocation size
> matches the packed binary content.
>
> The subset possums.gl[1:50,] that is used to perform PCA, on the other
> hand, is invalid: length(possums.gl[1:50,]$gen[[1]]@snp[[1]]) is 26
> instead of 25, which later causes bytesToDouble() to try to write extra
> 8 doubles (64 bytes) into the buffer.
>
> This happens because trying to extract all SNPs from an SNPbin object
> introduces an extra byte:
>
> possums.gl at gen[[1]] |> _ at snp |> lengths()
> # [1] 25 25
>
> possums.gl at gen[[1]][rep(TRUE, nLoc(possums.gl at gen[[1]]))] |>
>  _ at snp |> lengths()
> # 26 26
>
> This can be traced to a bug in adegenet:::.subsetbin:
>
> .subsetbin(as.raw(0xff), 1:8)
> # [1] ff 00 # <-- should be just 'ff'
>
> xint <- as.integer(rawToBits(x)[i]) # may be not divisible by 8
> # so introduce padding: the following line gives 8 bits of padding
> # instead of 0 when length(xint) is divisible by 8
> zeroes <- 8 - (length(xint)%%8)
> # instead use something like:
> # zeroes <- (8 - (length(xint)%%8)) * (length(xint)%%8 > 0)
> # (could probably be golfed further)
> return(packBits(c(xint, rep(0L, zeroes))))
>
> But we're getting two bugs for the price of one, because even with a
> 25-byte buffer, nLoc(.) == 199 would still result in an 8-byte
> overflow. This is solely on the bytesToDouble() C function: it ought to
> know to stop after writing *reslength elements into the 'vecres' array.
>
> I'm afraid there is no easy way to work around either of the bugs in
> the dartR.base code.
>
> --
> Best regards,
> Ivan
>
> [1]
> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/src/snpbin.c#L443-L444
>
> [2]
> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/src/GLfunctions.c#L124
>
> [3]
> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/R/glFunctions.R#L215-L216
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>


-- 
I?aki ?car


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Tue Feb  4 12:56:28 2025
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Tue, 4 Feb 2025 12:56:28 +0100
Subject: [R-pkg-devel] Additional issue clang-ASAN, gcc-ASAN
In-Reply-To: <CALEXWq3_vDeJHNVLgFjdKAMcmAYPT32yLvDN=i3bhOjJnwu=Lw@mail.gmail.com>
References: <mailman.11256.10.1738407601.11304.r-package-devel@r-project.org>
 <ME3PR01MB7944A3A9807CADA986349B4CD4EA2@ME3PR01MB7944.ausprd01.prod.outlook.com>
 <20250204143003.22982e7b@arachnoid>
 <CALEXWq3_vDeJHNVLgFjdKAMcmAYPT32yLvDN=i3bhOjJnwu=Lw@mail.gmail.com>
Message-ID: <79394630-e305-4c3a-8781-01135867d508@statistik.tu-dortmund.de>



On 04.02.2025 12:46, I?aki Ucar wrote:
> @Ivan: Excellent anaylsis as always.
> 
> @Bernd: So what can **you** do about it? You are using adegenet
> correctly as Ivan pointed out, so IMHO CRAN should have requested
> adegenet's maintainer to fix this. But since it's your package that is
> on the line here, I would put that example inside a dontrun{} chunk
> for now, to avoid triggering this issue on CRAN, and I would report
> Ivan's analysis upstream.

Putting it in dontrun is the wrong advise in any case, as we like to 
track whether the underlying issue has been fixed. And both Professor 
Ripley and I already asked to liase with the adegenet maintainer to get 
this fixed. So I wonder why the most relevant person (Zhian N. Kamvar) 
was not included here (CCIng now).
Ivan's analysis is as always extremely helpful, particularly for the 
adegenet maintainer.

Best,
Uwe



> I?aki
> 
> 
> On Tue, 4 Feb 2025 at 12:30, Ivan Krylov via R-package-devel
> <r-package-devel at r-project.org> wrote:
>>
>> ? Sun, 2 Feb 2025 22:56:47 +0000
>> Bernd.Gruber <Bernd.Gruber at canberra.edu.au> ?????:
>>
>>> READ of size 16 at 0x518000697ff0 thread T0
>>>      #0 0x7f2e873ccfdf in bytesToDouble
>>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:225:19
>>> #1 0x7f2e873ceca5 in snpbin2freq
>>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:332:5
>>> #2 0x7f2e873ceca5 in snpbin_dotprod_freq
>>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:447:5
>>> #3 0x7f2e873bba42 in GLdotProd
>>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/GLfunctions.c:42:14
>>
>> Ben Bolker is exactly right; the problem happens in the 'adegenet'
>> code. Why?
>>
>> bytesToDouble() is asked to unpack the bytes from the 'vecbytes' array
>> (26 bytes) into individual bits stored as doubles in the 'out' array.
>> The latter was allocated by the snpbin_dotprod_freq() function to
>> contain 199 elements [1]. Every byte must be unpacked into 8 bits, and
>> 199 is less than 26*8 = 208. Where did the values come from?
>>
>> The C function GLsumFreq() stores them unchanged from its arguments
>> [2], and those come from the SNPbin objects passed by R code [3] from
>> nLoc(x) and length(x$gen[[1]]@snp[[1]]). Where do they originate?
>>
>> The R traceback at the point of the crash is dartR.base::gl.pcoa ->
>> adegenet::glPca -> adegenet::glDotProd. The object 'possums.gl' of S4
>> class 'dartR' exported by 'dartR.base' appears valid: its .$n.loc is
>> exactly equal to length(.$gen[[1]]@snp[[1]]) * 8, so the allocation size
>> matches the packed binary content.
>>
>> The subset possums.gl[1:50,] that is used to perform PCA, on the other
>> hand, is invalid: length(possums.gl[1:50,]$gen[[1]]@snp[[1]]) is 26
>> instead of 25, which later causes bytesToDouble() to try to write extra
>> 8 doubles (64 bytes) into the buffer.
>>
>> This happens because trying to extract all SNPs from an SNPbin object
>> introduces an extra byte:
>>
>> possums.gl at gen[[1]] |> _ at snp |> lengths()
>> # [1] 25 25
>>
>> possums.gl at gen[[1]][rep(TRUE, nLoc(possums.gl at gen[[1]]))] |>
>>   _ at snp |> lengths()
>> # 26 26
>>
>> This can be traced to a bug in adegenet:::.subsetbin:
>>
>> .subsetbin(as.raw(0xff), 1:8)
>> # [1] ff 00 # <-- should be just 'ff'
>>
>> xint <- as.integer(rawToBits(x)[i]) # may be not divisible by 8
>> # so introduce padding: the following line gives 8 bits of padding
>> # instead of 0 when length(xint) is divisible by 8
>> zeroes <- 8 - (length(xint)%%8)
>> # instead use something like:
>> # zeroes <- (8 - (length(xint)%%8)) * (length(xint)%%8 > 0)
>> # (could probably be golfed further)
>> return(packBits(c(xint, rep(0L, zeroes))))
>>
>> But we're getting two bugs for the price of one, because even with a
>> 25-byte buffer, nLoc(.) == 199 would still result in an 8-byte
>> overflow. This is solely on the bytesToDouble() C function: it ought to
>> know to stop after writing *reslength elements into the 'vecres' array.
>>
>> I'm afraid there is no easy way to work around either of the bugs in
>> the dartR.base code.
>>
>> --
>> Best regards,
>> Ivan
>>
>> [1]
>> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/src/snpbin.c#L443-L444
>>
>> [2]
>> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/src/GLfunctions.c#L124
>>
>> [3]
>> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/R/glFunctions.R#L215-L216
>>
>> ______________________________________________
>> R-package-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>>
> 
> 


From |uc@r @end|ng |rom |edor@project@org  Tue Feb  4 13:01:26 2025
From: |uc@r @end|ng |rom |edor@project@org (=?UTF-8?Q?I=C3=B1aki_Ucar?=)
Date: Tue, 4 Feb 2025 13:01:26 +0100
Subject: [R-pkg-devel] Additional issue clang-ASAN, gcc-ASAN
In-Reply-To: <79394630-e305-4c3a-8781-01135867d508@statistik.tu-dortmund.de>
References: <mailman.11256.10.1738407601.11304.r-package-devel@r-project.org>
 <ME3PR01MB7944A3A9807CADA986349B4CD4EA2@ME3PR01MB7944.ausprd01.prod.outlook.com>
 <20250204143003.22982e7b@arachnoid>
 <CALEXWq3_vDeJHNVLgFjdKAMcmAYPT32yLvDN=i3bhOjJnwu=Lw@mail.gmail.com>
 <79394630-e305-4c3a-8781-01135867d508@statistik.tu-dortmund.de>
Message-ID: <CALEXWq0rdWVpPyBmb_JDmw-2289zNhpDQ7GodK5Q2vDjO_vQdw@mail.gmail.com>

On Tue, 4 Feb 2025 at 12:56, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>
>
>
> On 04.02.2025 12:46, I?aki Ucar wrote:
> > @Ivan: Excellent anaylsis as always.
> >
> > @Bernd: So what can **you** do about it? You are using adegenet
> > correctly as Ivan pointed out, so IMHO CRAN should have requested
> > adegenet's maintainer to fix this. But since it's your package that is
> > on the line here, I would put that example inside a dontrun{} chunk
> > for now, to avoid triggering this issue on CRAN, and I would report
> > Ivan's analysis upstream.
>
> Putting it in dontrun is the wrong advise in any case, as we like to
> track whether the underlying issue has been fixed. And both Professor
> Ripley and I already asked to liase with the adegenet maintainer to get
> this fixed.

Great, we obviously didn't know this, but only that Bernd's package is
scheduled to be archived soon, thus my advice.

I?aki

> So I wonder why the most relevant person (Zhian N. Kamvar)
> was not included here (CCIng now).
> Ivan's analysis is as always extremely helpful, particularly for the
> adegenet maintainer.
>
> Best,
> Uwe
>
>
>
> > I?aki
> >
> >
> > On Tue, 4 Feb 2025 at 12:30, Ivan Krylov via R-package-devel
> > <r-package-devel at r-project.org> wrote:
> >>
> >> ? Sun, 2 Feb 2025 22:56:47 +0000
> >> Bernd.Gruber <Bernd.Gruber at canberra.edu.au> ?????:
> >>
> >>> READ of size 16 at 0x518000697ff0 thread T0
> >>>      #0 0x7f2e873ccfdf in bytesToDouble
> >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:225:19
> >>> #1 0x7f2e873ceca5 in snpbin2freq
> >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:332:5
> >>> #2 0x7f2e873ceca5 in snpbin_dotprod_freq
> >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:447:5
> >>> #3 0x7f2e873bba42 in GLdotProd
> >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/GLfunctions.c:42:14
> >>
> >> Ben Bolker is exactly right; the problem happens in the 'adegenet'
> >> code. Why?
> >>
> >> bytesToDouble() is asked to unpack the bytes from the 'vecbytes' array
> >> (26 bytes) into individual bits stored as doubles in the 'out' array.
> >> The latter was allocated by the snpbin_dotprod_freq() function to
> >> contain 199 elements [1]. Every byte must be unpacked into 8 bits, and
> >> 199 is less than 26*8 = 208. Where did the values come from?
> >>
> >> The C function GLsumFreq() stores them unchanged from its arguments
> >> [2], and those come from the SNPbin objects passed by R code [3] from
> >> nLoc(x) and length(x$gen[[1]]@snp[[1]]). Where do they originate?
> >>
> >> The R traceback at the point of the crash is dartR.base::gl.pcoa ->
> >> adegenet::glPca -> adegenet::glDotProd. The object 'possums.gl' of S4
> >> class 'dartR' exported by 'dartR.base' appears valid: its .$n.loc is
> >> exactly equal to length(.$gen[[1]]@snp[[1]]) * 8, so the allocation size
> >> matches the packed binary content.
> >>
> >> The subset possums.gl[1:50,] that is used to perform PCA, on the other
> >> hand, is invalid: length(possums.gl[1:50,]$gen[[1]]@snp[[1]]) is 26
> >> instead of 25, which later causes bytesToDouble() to try to write extra
> >> 8 doubles (64 bytes) into the buffer.
> >>
> >> This happens because trying to extract all SNPs from an SNPbin object
> >> introduces an extra byte:
> >>
> >> possums.gl at gen[[1]] |> _ at snp |> lengths()
> >> # [1] 25 25
> >>
> >> possums.gl at gen[[1]][rep(TRUE, nLoc(possums.gl at gen[[1]]))] |>
> >>   _ at snp |> lengths()
> >> # 26 26
> >>
> >> This can be traced to a bug in adegenet:::.subsetbin:
> >>
> >> .subsetbin(as.raw(0xff), 1:8)
> >> # [1] ff 00 # <-- should be just 'ff'
> >>
> >> xint <- as.integer(rawToBits(x)[i]) # may be not divisible by 8
> >> # so introduce padding: the following line gives 8 bits of padding
> >> # instead of 0 when length(xint) is divisible by 8
> >> zeroes <- 8 - (length(xint)%%8)
> >> # instead use something like:
> >> # zeroes <- (8 - (length(xint)%%8)) * (length(xint)%%8 > 0)
> >> # (could probably be golfed further)
> >> return(packBits(c(xint, rep(0L, zeroes))))
> >>
> >> But we're getting two bugs for the price of one, because even with a
> >> 25-byte buffer, nLoc(.) == 199 would still result in an 8-byte
> >> overflow. This is solely on the bytesToDouble() C function: it ought to
> >> know to stop after writing *reslength elements into the 'vecres' array.
> >>
> >> I'm afraid there is no easy way to work around either of the bugs in
> >> the dartR.base code.
> >>
> >> --
> >> Best regards,
> >> Ivan
> >>
> >> [1]
> >> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/src/snpbin.c#L443-L444
> >>
> >> [2]
> >> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/src/GLfunctions.c#L124
> >>
> >> [3]
> >> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/R/glFunctions.R#L215-L216
> >>
> >> ______________________________________________
> >> R-package-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> >>
> >
> >
>


-- 
I?aki ?car


From gr@eme|eeh|ckey @end|ng |rom gm@||@com  Tue Feb  4 17:13:10 2025
From: gr@eme|eeh|ckey @end|ng |rom gm@||@com (Graeme Hickey)
Date: Tue, 4 Feb 2025 16:13:10 +0000
Subject: [R-pkg-devel] Vignette build issue on Debian platform
In-Reply-To: <852a85b8-0966-43fb-9d0b-b10188eb85fd@gmail.com>
References: <CALvcmje4JO8cfV05o+8dDWTWtCfx4GPGU0zYcxMgw+gTEghqug@mail.gmail.com>
 <852a85b8-0966-43fb-9d0b-b10188eb85fd@gmail.com>
Message-ID: <CALvcmjc0y1tjDY13cXO8E3J-pCsPKapMnvRu=mOHtag3PgEArQ@mail.gmail.com>

Thank you, Jisca. I learned something new. Unfortunately the NOTE was not
being triggered by this, but rather somehow the package was using OpenMP. I
found the trick was to throttle the number of OpenMP threads courtesy of
Dirk Edubuettel's post here: https://dirk.eddelbuettel.com/blog/2023/10/31/.

On Tue, 14 Jan 2025 at 16:34, Jisca Huisman <jisca.huisman at gmail.com> wrote:

> Hi Graeme,
>
> > There is only one function in my package that uses multiple cores:
> > bootSE(). However, this function is not called in any of my vignettes
> > because it is computationally expensive. The Rmd code has `eval = FALSE`
> > options for all of these cases. Therefore, I am at a loss as to why these
> > vignettes would be using more than 2 cores or what is causing this, or
> why
> > it only impacts the CRAN CMD check Debian system.
>
> CRAN has changed its settings when compiling the vignette, and now
> *does* run everything in chunks with `eval = FALSE`.  The solution is to
> also add `purl=FALSE` to each chunk that should not be run.
>
> If you dig through the mailing list archive you should be able to find
> further details on the why and how of this, or someone else might remember.
>
> Best,
>
> Jisca
>
>
>
> On Tue, 14/01/2025 08:08, Graeme Hickey wrote:
> > Dear all,
> >
> >
> > I recently made some minor updates to the joineRML R package to squash
> some
> > CRAN CMD check NOTEs that have emerged over the past couple of years.
> After
> > resubmitting to CRAN, a new NOTE appeared on the Debian platform only:
> >
> >
> >> package joineRML_0.4.7.tar.gz does not pass the incoming checks
> > automatically, please see the following pre-tests (additional issue
> checks):
> >
> >> Windows: <
> >
> https://win-builder.r-project.org/incoming_pretest/joineRML_0.4.7_20250114_073418/Windows/00check.log
> >> Status: OK
> >> Debian: <
> >
> https://win-builder.r-project.org/incoming_pretest/joineRML_0.4.7_20250114_073418/Debian/00check.log
> >> Status: 1 NOTE
> >
> > The NOTE in particular is:
> >
> >
> >> * checking re-building of vignette outputs ... [116s/30s] NOTE
> >> Re-building vignettes had CPU time 3.9 times elapsed time
> >
> > I emailed Uwe Ligges and got a reply:
> >
> >
> >> We see
> >> Flavor: r-devel-linux-x86_64-debian-gcc
> >> Check: re-building of vignette outputs, Result: NOTE
> >>     Re-building vignettes had CPU time 3.9 times elapsed time
> >
> >> which suggests you are using more than 2 cores which is not permitted by
> > default.
> >
> >
> > There is only one function in my package that uses multiple cores:
> > bootSE(). However, this function is not called in any of my vignettes
> > because it is computationally expensive. The Rmd code has `eval = FALSE`
> > options for all of these cases. Therefore, I am at a loss as to why these
> > vignettes would be using more than 2 cores or what is causing this, or
> why
> > it only impacts the CRAN CMD check Debian system.
> >
> >
> > I noticed this has been a common reported issue (e.g.,
> > https://github.com/Rdatatable/data.table/issues/5658), but mainly for
> those
> > using data.table or openMP; I use neither. The same issue was showing for
> > some examples also, which I dealt with by wrapping in \dontrun{} ? not
> > ideal, but seemed quickest way to avoid.
> >
> >
> > I have tried many things to fix this:
> >
> >     1. Modifying the vignettes to make faster
> >     2. Adding various combinations of Sys.setenv("OMP_THREAD_LIMIT" = 1),
> >     Sys.setenv("OMP_NUM_THREADS" = 1), options(Ncpus = 1), options(cores
> = 2)
> >     to the Rmd vignettes
> >     3. Checked the package builds using r-lib/actions (GitHub actions)
> and
> >     r-hub Debian platform ? I cannot reproduce this CRAN error
> >
> >
> > CRAN will not accept the update to my package until this NOTE is
> squashed.
> > If anyone is able to provide a recommendation on what I might do, I would
> > appreciate it.
> >
> >
> > Kind regards,
> >
> >
> > Graeme Hickey
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-package-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-package-devel
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From gr@eme|eeh|ckey @end|ng |rom gm@||@com  Tue Feb  4 17:16:38 2025
From: gr@eme|eeh|ckey @end|ng |rom gm@||@com (Graeme Hickey)
Date: Tue, 4 Feb 2025 16:16:38 +0000
Subject: [R-pkg-devel] [SPAM Warning!]Re: CRAN Debian error installation
 time
In-Reply-To: <26521.3699.981063.369921@rob.eddelbuettel.com>
References: <CA+hm8HkNfS=YTVw5M2Cp0Ak-sDEP+mxdkEeOGV2xznS1YLGuNg@mail.gmail.com>
 <20250127233626.7fd9bbb6@Tarkus>
 <CA+hm8HnWWF7nje8V_S7FH_Qze=sHzfkOeAHEBL=5toL0EL5dGA@mail.gmail.com>
 <20250128190945.095fd961@arachnoid>
 <26521.3699.981063.369921@rob.eddelbuettel.com>
Message-ID: <CALvcmjeTn4CSVzPG=7h8U7p0UWU64u4_tWMMiCbJfd6P7YD1-w@mail.gmail.com>

Having spent the best part of a month troubleshooting an almost
identical issue, I came across Dirk's blog post here:
https://dirk.eddelbuettel.com/blog/2023/10/31/. He discusses how to
throttle the number of threads, and exports 2 handy functions in the
RcppArmadillo package, which you can use with tests, examples, and
vignettes. Thank you, Dirk... your trick just saved me!

On Tue, 28 Jan 2025 at 17:06, Dirk Eddelbuettel <edd at debian.org> wrote:

>
> Excellent (as usual) sleuthing by Ivan -- colour me impressed (again).
>
> As an aside, your package makes wide use of the excellent resources
> provided
> by other CRAN packages.  But with this comes added complexity.  Depending
> on
> over sixty (!!) other packages (when counting recursively, over seventy
> when
> we add Suggests:) can make your overall setup fragile, and debugging
> challenging.
>
> > db <- tools::CRAN_package_db()
> > deps <- tools::package_dependencies(c("dplyr", "ggplot2", "ggpubr",
> + "ggtext", "janitor", "magrittr", "polite", "purrr", "RcppParallel",
> + "RhpcBLASctl", "readr", "robotstxt", "rvest", "stringr", "text2vec",
> "tidyr",
> + "tidytext"))
> > unique(sort(do.call(c, deps)))
>  [1] "cli"          "clipr"        "cowplot"      "cpp11"
>  [5] "crayon"       "data.table"   "digest"       "dplyr"
>  [9] "future.apply" "generics"     "ggplot2"      "ggrepel"
> [13] "ggsci"        "ggsignif"     "glue"         "grDevices"
> [17] "grid"         "gridExtra"    "gridtext"     "gtable"
> [21] "hms"          "httr"         "isoband"      "janeaustenr"
> [25] "lgr"          "lifecycle"    "lubridate"    "magrittr"
> [29] "MASS"         "Matrix"       "memoise"      "methods"
> [33] "mgcv"         "mlapi"        "pillar"       "polynom"
> [37] "purrr"        "R6"           "ratelimitr"   "Rcpp"
> [41] "rlang"        "robotstxt"    "rsparse"      "rstatix"
> [45] "rvest"        "scales"       "selectr"      "snakecase"
> [49] "spiderbar"    "stats"        "stringi"      "stringr"
> [53] "tibble"       "tidyr"        "tidyselect"   "tokenizers"
> [57] "tzdb"         "usethis"      "utils"        "vctrs"
> [61] "vroom"        "withr"        "xml2"
> >
>
> Dirk
>
> --
> dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Tue Feb  4 17:47:46 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 4 Feb 2025 10:47:46 -0600
Subject: [R-pkg-devel] [SPAM Warning!]Re: CRAN Debian error installation
 time
In-Reply-To: <CALvcmjeTn4CSVzPG=7h8U7p0UWU64u4_tWMMiCbJfd6P7YD1-w@mail.gmail.com>
References: <CA+hm8HkNfS=YTVw5M2Cp0Ak-sDEP+mxdkEeOGV2xznS1YLGuNg@mail.gmail.com>
 <20250127233626.7fd9bbb6@Tarkus>
 <CA+hm8HnWWF7nje8V_S7FH_Qze=sHzfkOeAHEBL=5toL0EL5dGA@mail.gmail.com>
 <20250128190945.095fd961@arachnoid>
 <26521.3699.981063.369921@rob.eddelbuettel.com>
 <CALvcmjeTn4CSVzPG=7h8U7p0UWU64u4_tWMMiCbJfd6P7YD1-w@mail.gmail.com>
Message-ID: <26530.17586.810752.840564@rob.eddelbuettel.com>


On 4 February 2025 at 16:16, Graeme Hickey wrote:
| Having spent the best part of a month troubleshooting an almost
| identical?issue, I came across Dirk's blog post here:?https://
| dirk.eddelbuettel.com/blog/2023/10/31/. He discusses how to throttle the number
| of threads, and exports 2 handy functions in the RcppArmadillo package,?which
| you can?use with tests,?examples, and vignettes. Thank you, Dirk... your trick
| just saved me!

Yay, glad to hear that, and happy it helped!

There is in fact an example package with just the throttling example:
https://github.com/eddelbuettel/rcpparmadilloopenmpex

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jo@|@h@p@rry @end|ng |rom gm@||@com  Tue Feb  4 22:11:10 2025
From: jo@|@h@p@rry @end|ng |rom gm@||@com (Josiah Parry)
Date: Tue, 4 Feb 2025 13:11:10 -0800
Subject: [R-pkg-devel] Failed: Future File Timestamp Check
Message-ID: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>

I'm running R CMD check for my package {calcite} (source:
https://github.com/r-arcGIS/calcite) which is failing due to what *looks* like
a bug.

R CMD check fails at "checking for future file timestamps"

I get this error:  ...Error in if (abs(unclass(now_local) -
unclass(now)[1]) > 300) missing value where TRUE/FALSE needed.

It seems that an NA is being generated somehow during this check but I'm
unsure how.

One thing that comes to mind is that the file that contains all of my
function definitions is generated using writeLines() but the output of `
file.info()` looks normal to me.

Have others encountered this? I'm on R 4.4.0 Puppy Cup

platform       aarch64-apple-darwin20
arch           aarch64
os             darwin20
system         aarch64, darwin20
status
major          4
minor          4.0
year           2024
month          04
day            24
svn rev        86474
language       R
version.string R version 4.4.0 (2024-04-24)
nickname       Puppy Cup

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Feb  4 23:54:36 2025
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 04 Feb 2025 14:54:36 -0800
Subject: [R-pkg-devel] Failed: Future File Timestamp Check
In-Reply-To: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>
References: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>
Message-ID: <D3452FFB-A24B-4643-B8F5-0737DB9A46C0@dcn.davis.ca.us>

Packages are supposed to work when mounted in a read-only filesystem... using writeLines seems like a very bad idea since you can't assume the package install is writeable when it is run, and running code from tmp is a security hole.

If you absolutely cannot think of a way around running code from generated files, then maybe you should use textConnection to run from internal RAM.

On February 4, 2025 1:11:10 PM PST, Josiah Parry <josiah.parry at gmail.com> wrote:
>I'm running R CMD check for my package {calcite} (source:
>https://github.com/r-arcGIS/calcite) which is failing due to what *looks* like
>a bug.
>
>R CMD check fails at "checking for future file timestamps"
>
>I get this error:  ...Error in if (abs(unclass(now_local) -
>unclass(now)[1]) > 300) missing value where TRUE/FALSE needed.
>
>It seems that an NA is being generated somehow during this check but I'm
>unsure how.
>
>One thing that comes to mind is that the file that contains all of my
>function definitions is generated using writeLines() but the output of `
>file.info()` looks normal to me.
>
>Have others encountered this? I'm on R 4.4.0 Puppy Cup
>
>platform       aarch64-apple-darwin20
>arch           aarch64
>os             darwin20
>system         aarch64, darwin20
>status
>major          4
>minor          4.0
>year           2024
>month          04
>day            24
>svn rev        86474
>language       R
>version.string R version 4.4.0 (2024-04-24)
>nickname       Puppy Cup
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-package-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-package-devel

-- 
Sent from my phone. Please excuse my brevity.


From jo@|@h@p@rry @end|ng |rom gm@||@com  Wed Feb  5 00:27:34 2025
From: jo@|@h@p@rry @end|ng |rom gm@||@com (Josiah Parry)
Date: Tue, 4 Feb 2025 15:27:34 -0800
Subject: [R-pkg-devel] Failed: Future File Timestamp Check
In-Reply-To: <D3452FFB-A24B-4643-B8F5-0737DB9A46C0@dcn.davis.ca.us>
References: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>
 <D3452FFB-A24B-4643-B8F5-0737DB9A46C0@dcn.davis.ca.us>
Message-ID: <CAL3ufULzoyPe_35-JvJhD4JODvf8BqiB+gKAizdeJX7=Hro20Q@mail.gmail.com>

The file was written using writeLines() but it is just a normal R script
with normal function definitions and is included in the R/ directory. The
source code is just programmatically generated.


On Tue, Feb 4, 2025 at 14:54 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Packages are supposed to work when mounted in a read-only filesystem...
> using writeLines seems like a very bad idea since you can't assume the
> package install is writeable when it is run, and running code from tmp is a
> security hole.
>
> If you absolutely cannot think of a way around running code from generated
> files, then maybe you should use textConnection to run from internal RAM.
>
> On February 4, 2025 1:11:10 PM PST, Josiah Parry <josiah.parry at gmail.com>
> wrote:
> >I'm running R CMD check for my package {calcite} (source:
> >https://github.com/r-arcGIS/calcite) which is failing due to what
> *looks* like
> >a bug.
> >
> >R CMD check fails at "checking for future file timestamps"
> >
> >I get this error:  ...Error in if (abs(unclass(now_local) -
> >unclass(now)[1]) > 300) missing value where TRUE/FALSE needed.
> >
> >It seems that an NA is being generated somehow during this check but I'm
> >unsure how.
> >
> >One thing that comes to mind is that the file that contains all of my
> >function definitions is generated using writeLines() but the output of `
> >file.info()` looks normal to me.
> >
> >Have others encountered this? I'm on R 4.4.0 Puppy Cup
> >
> >platform       aarch64-apple-darwin20
> >arch           aarch64
> >os             darwin20
> >system         aarch64, darwin20
> >status
> >major          4
> >minor          4.0
> >year           2024
> >month          04
> >day            24
> >svn rev        86474
> >language       R
> >version.string R version 4.4.0 (2024-04-24)
> >nickname       Puppy Cup
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-package-devel at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-package-devel
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Feb  5 01:04:56 2025
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 04 Feb 2025 16:04:56 -0800
Subject: [R-pkg-devel] Failed: Future File Timestamp Check
In-Reply-To: <CAL3ufULzoyPe_35-JvJhD4JODvf8BqiB+gKAizdeJX7=Hro20Q@mail.gmail.com>
References: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>
 <D3452FFB-A24B-4643-B8F5-0737DB9A46C0@dcn.davis.ca.us>
 <CAL3ufULzoyPe_35-JvJhD4JODvf8BqiB+gKAizdeJX7=Hro20Q@mail.gmail.com>
Message-ID: <A96FB475-2453-474C-A7E7-7DB890EDA5A6@dcn.davis.ca.us>

That was clear to me, and changes nothing about my comments.

On February 4, 2025 3:27:34 PM PST, Josiah Parry <josiah.parry at gmail.com> wrote:
>The file was written using writeLines() but it is just a normal R script
>with normal function definitions and is included in the R/ directory. The
>source code is just programmatically generated.
>
>
>On Tue, Feb 4, 2025 at 14:54 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Packages are supposed to work when mounted in a read-only filesystem...
>> using writeLines seems like a very bad idea since you can't assume the
>> package install is writeable when it is run, and running code from tmp is a
>> security hole.
>>
>> If you absolutely cannot think of a way around running code from generated
>> files, then maybe you should use textConnection to run from internal RAM.
>>
>> On February 4, 2025 1:11:10 PM PST, Josiah Parry <josiah.parry at gmail.com>
>> wrote:
>> >I'm running R CMD check for my package {calcite} (source:
>> >https://github.com/r-arcGIS/calcite) which is failing due to what
>> *looks* like
>> >a bug.
>> >
>> >R CMD check fails at "checking for future file timestamps"
>> >
>> >I get this error:  ...Error in if (abs(unclass(now_local) -
>> >unclass(now)[1]) > 300) missing value where TRUE/FALSE needed.
>> >
>> >It seems that an NA is being generated somehow during this check but I'm
>> >unsure how.
>> >
>> >One thing that comes to mind is that the file that contains all of my
>> >function definitions is generated using writeLines() but the output of `
>> >file.info()` looks normal to me.
>> >
>> >Have others encountered this? I'm on R 4.4.0 Puppy Cup
>> >
>> >platform       aarch64-apple-darwin20
>> >arch           aarch64
>> >os             darwin20
>> >system         aarch64, darwin20
>> >status
>> >major          4
>> >minor          4.0
>> >year           2024
>> >month          04
>> >day            24
>> >svn rev        86474
>> >language       R
>> >version.string R version 4.4.0 (2024-04-24)
>> >nickname       Puppy Cup
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-package-devel at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-package-devel
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Feb  5 02:19:25 2025
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 4 Feb 2025 20:19:25 -0500
Subject: [R-pkg-devel] Failed: Future File Timestamp Check
In-Reply-To: <CAL3ufULzoyPe_35-JvJhD4JODvf8BqiB+gKAizdeJX7=Hro20Q@mail.gmail.com>
References: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>
 <D3452FFB-A24B-4643-B8F5-0737DB9A46C0@dcn.davis.ca.us>
 <CAL3ufULzoyPe_35-JvJhD4JODvf8BqiB+gKAizdeJX7=Hro20Q@mail.gmail.com>
Message-ID: <ddb92b2a-0140-421f-b38a-cf9993f0ed34@gmail.com>

One question is when that file is produced.  Do you produce it before 
preparing the tarball, or is it produced as part of the installation 
process?

Duncan Murdoch

On 2025-02-04 6:27 p.m., Josiah Parry wrote:
> The file was written using writeLines() but it is just a normal R script
> with normal function definitions and is included in the R/ directory. The
> source code is just programmatically generated.
> 
> 
> On Tue, Feb 4, 2025 at 14:54 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> Packages are supposed to work when mounted in a read-only filesystem...
>> using writeLines seems like a very bad idea since you can't assume the
>> package install is writeable when it is run, and running code from tmp is a
>> security hole.
>>
>> If you absolutely cannot think of a way around running code from generated
>> files, then maybe you should use textConnection to run from internal RAM.
>>
>> On February 4, 2025 1:11:10 PM PST, Josiah Parry <josiah.parry at gmail.com>
>> wrote:
>>> I'm running R CMD check for my package {calcite} (source:
>>> https://github.com/r-arcGIS/calcite) which is failing due to what
>> *looks* like
>>> a bug.
>>>
>>> R CMD check fails at "checking for future file timestamps"
>>>
>>> I get this error:  ...Error in if (abs(unclass(now_local) -
>>> unclass(now)[1]) > 300) missing value where TRUE/FALSE needed.
>>>
>>> It seems that an NA is being generated somehow during this check but I'm
>>> unsure how.
>>>
>>> One thing that comes to mind is that the file that contains all of my
>>> function definitions is generated using writeLines() but the output of `
>>> file.info()` looks normal to me.
>>>
>>> Have others encountered this? I'm on R 4.4.0 Puppy Cup
>>>
>>> platform       aarch64-apple-darwin20
>>> arch           aarch64
>>> os             darwin20
>>> system         aarch64, darwin20
>>> status
>>> major          4
>>> minor          4.0
>>> year           2024
>>> month          04
>>> day            24
>>> svn rev        86474
>>> language       R
>>> version.string R version 4.4.0 (2024-04-24)
>>> nickname       Puppy Cup
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-package-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From jo@|@h@p@rry @end|ng |rom gm@||@com  Wed Feb  5 02:29:46 2025
From: jo@|@h@p@rry @end|ng |rom gm@||@com (Josiah Parry)
Date: Tue, 4 Feb 2025 17:29:46 -0800
Subject: [R-pkg-devel] Failed: Future File Timestamp Check
In-Reply-To: <ddb92b2a-0140-421f-b38a-cf9993f0ed34@gmail.com>
References: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>
 <D3452FFB-A24B-4643-B8F5-0737DB9A46C0@dcn.davis.ca.us>
 <CAL3ufULzoyPe_35-JvJhD4JODvf8BqiB+gKAizdeJX7=Hro20Q@mail.gmail.com>
 <ddb92b2a-0140-421f-b38a-cf9993f0ed34@gmail.com>
Message-ID: <CAL3ufULwxVHzhQJcRD+_Rg893jehghughMWty1cSVNMJsufSow@mail.gmail.com>

Thanks, Duncan!

It is produced before preparing the tarball. It?s just a way to automate
defining many 100ish  functions that have the same structure.  l run the
script manually when I want to update definitions.

There is not any auto-magical process that creates a file before the build
or install step. This would be the equivalent of something like running the
following once during the development process

writeLines(?hello_world <- function() { ?Hello, world!? }?,
?R/hello-world.R?)


On Tue, Feb 4, 2025 at 17:19 Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> One question is when that file is produced.  Do you produce it before
> preparing the tarball, or is it produced as part of the installation
> process?
>
> Duncan Murdoch
>
> On 2025-02-04 6:27 p.m., Josiah Parry wrote:
> > The file was written using writeLines() but it is just a normal R script
> > with normal function definitions and is included in the R/ directory. The
> > source code is just programmatically generated.
> >
> >
> > On Tue, Feb 4, 2025 at 14:54 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > wrote:
> >
> >> Packages are supposed to work when mounted in a read-only filesystem...
> >> using writeLines seems like a very bad idea since you can't assume the
> >> package install is writeable when it is run, and running code from tmp
> is a
> >> security hole.
> >>
> >> If you absolutely cannot think of a way around running code from
> generated
> >> files, then maybe you should use textConnection to run from internal
> RAM.
> >>
> >> On February 4, 2025 1:11:10 PM PST, Josiah Parry <
> josiah.parry at gmail.com>
> >> wrote:
> >>> I'm running R CMD check for my package {calcite} (source:
> >>> https://github.com/r-arcGIS/calcite) which is failing due to what
> >> *looks* like
> >>> a bug.
> >>>
> >>> R CMD check fails at "checking for future file timestamps"
> >>>
> >>> I get this error:  ...Error in if (abs(unclass(now_local) -
> >>> unclass(now)[1]) > 300) missing value where TRUE/FALSE needed.
> >>>
> >>> It seems that an NA is being generated somehow during this check but
> I'm
> >>> unsure how.
> >>>
> >>> One thing that comes to mind is that the file that contains all of my
> >>> function definitions is generated using writeLines() but the output of
> `
> >>> file.info()` looks normal to me.
> >>>
> >>> Have others encountered this? I'm on R 4.4.0 Puppy Cup
> >>>
> >>> platform       aarch64-apple-darwin20
> >>> arch           aarch64
> >>> os             darwin20
> >>> system         aarch64, darwin20
> >>> status
> >>> major          4
> >>> minor          4.0
> >>> year           2024
> >>> month          04
> >>> day            24
> >>> svn rev        86474
> >>> language       R
> >>> version.string R version 4.4.0 (2024-04-24)
> >>> nickname       Puppy Cup
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-package-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-package-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-package-devel
>
>

	[[alternative HTML version deleted]]


From zk@mv@r @end|ng |rom gm@||@com  Wed Feb  5 02:32:31 2025
From: zk@mv@r @end|ng |rom gm@||@com (Zhian Kamvar)
Date: Tue, 4 Feb 2025 17:32:31 -0800
Subject: [R-pkg-devel] Additional issue clang-ASAN, gcc-ASAN
In-Reply-To: <CALEXWq0rdWVpPyBmb_JDmw-2289zNhpDQ7GodK5Q2vDjO_vQdw@mail.gmail.com>
References: <mailman.11256.10.1738407601.11304.r-package-devel@r-project.org>
 <ME3PR01MB7944A3A9807CADA986349B4CD4EA2@ME3PR01MB7944.ausprd01.prod.outlook.com>
 <20250204143003.22982e7b@arachnoid>
 <CALEXWq3_vDeJHNVLgFjdKAMcmAYPT32yLvDN=i3bhOjJnwu=Lw@mail.gmail.com>
 <79394630-e305-4c3a-8781-01135867d508@statistik.tu-dortmund.de>
 <CALEXWq0rdWVpPyBmb_JDmw-2289zNhpDQ7GodK5Q2vDjO_vQdw@mail.gmail.com>
Message-ID: <CAPsXksKbbg1d0JM1VgWUkLOWZsJ3Wss-mcgmaNX3s0qnbc8HmQ@mail.gmail.com>

Thank you, Uwe for tagging me in. Huge thank you to Ivan for the detailed
analysis. This reflects what Max Coulter found in
https://github.com/thibautjombart/adegenet/issues/363. I just merged in
https://github.com/thibautjombart/adegenet/issues/363 yesterday and I
believe that should fix the issue.

I am going to run a test using the
https://hub.docker.com/r/rocker/r-devel-san/ to confirm that this is fixed
before I send it off to CRAN.

Best,
Zhian


On Tue, Feb 4, 2025 at 4:01?AM I?aki Ucar <iucar at fedoraproject.org> wrote:

> On Tue, 4 Feb 2025 at 12:56, Uwe Ligges <ligges at statistik.tu-dortmund.de>
> wrote:
> >
> >
> >
> > On 04.02.2025 12:46, I?aki Ucar wrote:
> > > @Ivan: Excellent anaylsis as always.
> > >
> > > @Bernd: So what can **you** do about it? You are using adegenet
> > > correctly as Ivan pointed out, so IMHO CRAN should have requested
> > > adegenet's maintainer to fix this. But since it's your package that is
> > > on the line here, I would put that example inside a dontrun{} chunk
> > > for now, to avoid triggering this issue on CRAN, and I would report
> > > Ivan's analysis upstream.
> >
> > Putting it in dontrun is the wrong advise in any case, as we like to
> > track whether the underlying issue has been fixed. And both Professor
> > Ripley and I already asked to liase with the adegenet maintainer to get
> > this fixed.
>
> Great, we obviously didn't know this, but only that Bernd's package is
> scheduled to be archived soon, thus my advice.
>
> I?aki
>
> > So I wonder why the most relevant person (Zhian N. Kamvar)
> > was not included here (CCIng now).
> > Ivan's analysis is as always extremely helpful, particularly for the
> > adegenet maintainer.
> >
> > Best,
> > Uwe
> >
> >
> >
> > > I?aki
> > >
> > >
> > > On Tue, 4 Feb 2025 at 12:30, Ivan Krylov via R-package-devel
> > > <r-package-devel at r-project.org> wrote:
> > >>
> > >> ? Sun, 2 Feb 2025 22:56:47 +0000
> > >> Bernd.Gruber <Bernd.Gruber at canberra.edu.au> ?????:
> > >>
> > >>> READ of size 16 at 0x518000697ff0 thread T0
> > >>>      #0 0x7f2e873ccfdf in bytesToDouble
> > >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:225:19
> > >>> #1 0x7f2e873ceca5 in snpbin2freq
> > >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:332:5
> > >>> #2 0x7f2e873ceca5 in snpbin_dotprod_freq
> > >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/snpbin.c:447:5
> > >>> #3 0x7f2e873bba42 in GLdotProd
> > >>>
> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/GLfunctions.c:42:14
> > >>
> > >> Ben Bolker is exactly right; the problem happens in the 'adegenet'
> > >> code. Why?
> > >>
> > >> bytesToDouble() is asked to unpack the bytes from the 'vecbytes' array
> > >> (26 bytes) into individual bits stored as doubles in the 'out' array.
> > >> The latter was allocated by the snpbin_dotprod_freq() function to
> > >> contain 199 elements [1]. Every byte must be unpacked into 8 bits, and
> > >> 199 is less than 26*8 = 208. Where did the values come from?
> > >>
> > >> The C function GLsumFreq() stores them unchanged from its arguments
> > >> [2], and those come from the SNPbin objects passed by R code [3] from
> > >> nLoc(x) and length(x$gen[[1]]@snp[[1]]). Where do they originate?
> > >>
> > >> The R traceback at the point of the crash is dartR.base::gl.pcoa ->
> > >> adegenet::glPca -> adegenet::glDotProd. The object 'possums.gl' of S4
> > >> class 'dartR' exported by 'dartR.base' appears valid: its .$n.loc is
> > >> exactly equal to length(.$gen[[1]]@snp[[1]]) * 8, so the allocation
> size
> > >> matches the packed binary content.
> > >>
> > >> The subset possums.gl[1:50,] that is used to perform PCA, on the
> other
> > >> hand, is invalid: length(possums.gl[1:50,]$gen[[1]]@snp[[1]]) is 26
> > >> instead of 25, which later causes bytesToDouble() to try to write
> extra
> > >> 8 doubles (64 bytes) into the buffer.
> > >>
> > >> This happens because trying to extract all SNPs from an SNPbin object
> > >> introduces an extra byte:
> > >>
> > >> possums.gl at gen[[1]] |> _ at snp |> lengths()
> > >> # [1] 25 25
> > >>
> > >> possums.gl at gen[[1]][rep(TRUE, nLoc(possums.gl at gen[[1]]))] |>
> > >>   _ at snp |> lengths()
> > >> # 26 26
> > >>
> > >> This can be traced to a bug in adegenet:::.subsetbin:
> > >>
> > >> .subsetbin(as.raw(0xff), 1:8)
> > >> # [1] ff 00 # <-- should be just 'ff'
> > >>
> > >> xint <- as.integer(rawToBits(x)[i]) # may be not divisible by 8
> > >> # so introduce padding: the following line gives 8 bits of padding
> > >> # instead of 0 when length(xint) is divisible by 8
> > >> zeroes <- 8 - (length(xint)%%8)
> > >> # instead use something like:
> > >> # zeroes <- (8 - (length(xint)%%8)) * (length(xint)%%8 > 0)
> > >> # (could probably be golfed further)
> > >> return(packBits(c(xint, rep(0L, zeroes))))
> > >>
> > >> But we're getting two bugs for the price of one, because even with a
> > >> 25-byte buffer, nLoc(.) == 199 would still result in an 8-byte
> > >> overflow. This is solely on the bytesToDouble() C function: it ought
> to
> > >> know to stop after writing *reslength elements into the 'vecres'
> array.
> > >>
> > >> I'm afraid there is no easy way to work around either of the bugs in
> > >> the dartR.base code.
> > >>
> > >> --
> > >> Best regards,
> > >> Ivan
> > >>
> > >> [1]
> > >>
> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/src/snpbin.c#L443-L444
> > >>
> > >> [2]
> > >>
> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/src/GLfunctions.c#L124
> > >>
> > >> [3]
> > >>
> https://github.com/thibautjombart/adegenet/blob/c7287597155ab18989d892a72eff33cf8c288958/R/glFunctions.R#L215-L216
> > >>
> > >> ______________________________________________
> > >> R-package-devel at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> > >>
> > >
> > >
> >
>
>
> --
> I?aki ?car
>

	[[alternative HTML version deleted]]


From @|mon@urb@nek @end|ng |rom R-project@org  Wed Feb  5 02:44:51 2025
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Wed, 5 Feb 2025 14:44:51 +1300
Subject: [R-pkg-devel] Failed: Future File Timestamp Check
In-Reply-To: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>
References: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>
Message-ID: <94DC06FD-5C10-406E-83D0-78D5902BA6ED@R-project.org>

Josiah,

that test tests the accuracy of the system clock by querying https://worldtimeapi.org/api/timezone/etc/UTC so my guess would be that you have either network or proxy issues which cause that request to fail by providing garbage instead of the actual response. 

The call to test yourself is
> readLines("http://worldtimeapi.org/api/timezone/etc/UTC", warn=FALSE)
[1] "{\"utc_offset\":\"+00:00\",\"timezone\":\"Etc/UTC\",\"day_of_week\":3,\"day_of_year\":36,\"datetime\":\"2025-02-05T01:42:19.272728+00:00\",\"utc_datetime\":\"2025-02-05T01:42:19.272728+00:00\",\"unixtime\":1738719739,\"raw_offset\":0,\"week_number\":6,\"dst\":false,\"abbreviation\":\"UTC\",\"dst_offset\":0,\"dst_from\":null,\"dst_until\":null,\"client_ip\":\"121.98.39.155\"}"

It has to have the "datetime" entry. If you can't fix your network you can skip that test with

_R_CHECK_FUTURE_FILE_TIMESTAMPS_=FALSE

Cheers,
Simon


> On Feb 5, 2025, at 10:11 AM, Josiah Parry <josiah.parry at gmail.com> wrote:
> 
> I'm running R CMD check for my package {calcite} (source:
> https://github.com/r-arcGIS/calcite) which is failing due to what *looks* like
> a bug.
> 
> R CMD check fails at "checking for future file timestamps"
> 
> I get this error:  ...Error in if (abs(unclass(now_local) -
> unclass(now)[1]) > 300) missing value where TRUE/FALSE needed.
> 
> It seems that an NA is being generated somehow during this check but I'm
> unsure how.
> 
> One thing that comes to mind is that the file that contains all of my
> function definitions is generated using writeLines() but the output of `
> file.info()` looks normal to me.
> 
> Have others encountered this? I'm on R 4.4.0 Puppy Cup
> 
> platform       aarch64-apple-darwin20
> arch           aarch64
> os             darwin20
> system         aarch64, darwin20
> status
> major          4
> minor          4.0
> year           2024
> month          04
> day            24
> svn rev        86474
> language       R
> version.string R version 4.4.0 (2024-04-24)
> nickname       Puppy Cup
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> 


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Wed Feb  5 09:44:09 2025
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Wed, 5 Feb 2025 09:44:09 +0100
Subject: [R-pkg-devel] Additional issue clang-ASAN, gcc-ASAN
In-Reply-To: <CAPsXksKbbg1d0JM1VgWUkLOWZsJ3Wss-mcgmaNX3s0qnbc8HmQ@mail.gmail.com>
References: <mailman.11256.10.1738407601.11304.r-package-devel@r-project.org>
 <ME3PR01MB7944A3A9807CADA986349B4CD4EA2@ME3PR01MB7944.ausprd01.prod.outlook.com>
 <20250204143003.22982e7b@arachnoid>
 <CALEXWq3_vDeJHNVLgFjdKAMcmAYPT32yLvDN=i3bhOjJnwu=Lw@mail.gmail.com>
 <79394630-e305-4c3a-8781-01135867d508@statistik.tu-dortmund.de>
 <CALEXWq0rdWVpPyBmb_JDmw-2289zNhpDQ7GodK5Q2vDjO_vQdw@mail.gmail.com>
 <CAPsXksKbbg1d0JM1VgWUkLOWZsJ3Wss-mcgmaNX3s0qnbc8HmQ@mail.gmail.com>
Message-ID: <970789b4-451d-4d36-8b40-d970983c8192@statistik.tu-dortmund.de>

Great, thanks,
Uwe


On 05.02.2025 02:32, Zhian Kamvar wrote:
> Thank you, Uwe for tagging me in. Huge thank you to Ivan for the 
> detailed analysis. This reflects what Max Coulter found in https:// 
> github.com/thibautjombart/adegenet/issues/363 <https://github.com/ 
> thibautjombart/adegenet/issues/363>. I just merged in https:// 
> github.com/thibautjombart/adegenet/issues/363 <https://github.com/ 
> thibautjombart/adegenet/issues/363> yesterday and I believe that should 
> fix the issue.
> 
> I am going to run a test using the https://hub.docker.com/r/rocker/r- 
> devel-san/ <https://hub.docker.com/r/rocker/r-devel-san/> to confirm 
> that this is fixed before I send it off to CRAN.
> 
> Best,
> Zhian
> 
> 
> On Tue, Feb 4, 2025 at 4:01?AM I?aki Ucar <iucar at fedoraproject.org 
> <mailto:iucar at fedoraproject.org>> wrote:
> 
>     On Tue, 4 Feb 2025 at 12:56, Uwe Ligges <ligges at statistik.tu-
>     dortmund.de <mailto:ligges at statistik.tu-dortmund.de>> wrote:
>      >
>      >
>      >
>      > On 04.02.2025 12:46, I?aki Ucar wrote:
>      > > @Ivan: Excellent anaylsis as always.
>      > >
>      > > @Bernd: So what can **you** do about it? You are using adegenet
>      > > correctly as Ivan pointed out, so IMHO CRAN should have requested
>      > > adegenet's maintainer to fix this. But since it's your package
>     that is
>      > > on the line here, I would put that example inside a dontrun{} chunk
>      > > for now, to avoid triggering this issue on CRAN, and I would report
>      > > Ivan's analysis upstream.
>      >
>      > Putting it in dontrun is the wrong advise in any case, as we like to
>      > track whether the underlying issue has been fixed. And both Professor
>      > Ripley and I already asked to liase with the adegenet maintainer
>     to get
>      > this fixed.
> 
>     Great, we obviously didn't know this, but only that Bernd's package is
>     scheduled to be archived soon, thus my advice.
> 
>     I?aki
> 
>      > So I wonder why the most relevant person (Zhian N. Kamvar)
>      > was not included here (CCIng now).
>      > Ivan's analysis is as always extremely helpful, particularly for the
>      > adegenet maintainer.
>      >
>      > Best,
>      > Uwe
>      >
>      >
>      >
>      > > I?aki
>      > >
>      > >
>      > > On Tue, 4 Feb 2025 at 12:30, Ivan Krylov via R-package-devel
>      > > <r-package-devel at r-project.org <mailto:r-package-devel at r-
>     project.org>> wrote:
>      > >>
>      > >> ? Sun, 2 Feb 2025 22:56:47 +0000
>      > >> Bernd.Gruber <Bernd.Gruber at canberra.edu.au
>     <mailto:Bernd.Gruber at canberra.edu.au>> ?????:
>      > >>
>      > >>> READ of size 16 at 0x518000697ff0 thread T0
>      > >>>? ? ? #0 0x7f2e873ccfdf in bytesToDouble
>      > >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/
>     snpbin.c:225:19
>      > >>> #1 0x7f2e873ceca5 in snpbin2freq
>      > >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/
>     snpbin.c:332:5
>      > >>> #2 0x7f2e873ceca5 in snpbin_dotprod_freq
>      > >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/
>     snpbin.c:447:5
>      > >>> #3 0x7f2e873bba42 in GLdotProd
>      > >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/
>     GLfunctions.c:42:14
>      > >>
>      > >> Ben Bolker is exactly right; the problem happens in the 'adegenet'
>      > >> code. Why?
>      > >>
>      > >> bytesToDouble() is asked to unpack the bytes from the
>     'vecbytes' array
>      > >> (26 bytes) into individual bits stored as doubles in the 'out'
>     array.
>      > >> The latter was allocated by the snpbin_dotprod_freq() function to
>      > >> contain 199 elements [1]. Every byte must be unpacked into 8
>     bits, and
>      > >> 199 is less than 26*8 = 208. Where did the values come from?
>      > >>
>      > >> The C function GLsumFreq() stores them unchanged from its
>     arguments
>      > >> [2], and those come from the SNPbin objects passed by R code
>     [3] from
>      > >> nLoc(x) and length(x$gen[[1]]@snp[[1]]). Where do they originate?
>      > >>
>      > >> The R traceback at the point of the crash is
>     dartR.base::gl.pcoa ->
>      > >> adegenet::glPca -> adegenet::glDotProd. The object 'possums.gl
>     <http://possums.gl>' of S4
>      > >> class 'dartR' exported by 'dartR.base' appears valid: its .
>     $n.loc is
>      > >> exactly equal to length(.$gen[[1]]@snp[[1]]) * 8, so the
>     allocation size
>      > >> matches the packed binary content.
>      > >>
>      > >> The subset possums.gl <http://possums.gl>[1:50,] that is used
>     to perform PCA, on the other
>      > >> hand, is invalid: length(possums.gl <http://
>     possums.gl>[1:50,]$gen[[1]]@snp[[1]]) is 26
>      > >> instead of 25, which later causes bytesToDouble() to try to
>     write extra
>      > >> 8 doubles (64 bytes) into the buffer.
>      > >>
>      > >> This happens because trying to extract all SNPs from an SNPbin
>     object
>      > >> introduces an extra byte:
>      > >>
>      > >> possums.gl at gen[[1]] |> _ at snp |> lengths()
>      > >> # [1] 25 25
>      > >>
>      > >> possums.gl at gen[[1]][rep(TRUE, nLoc(possums.gl at gen[[1]]))] |>
>      > >>? ?_ at snp |> lengths()
>      > >> # 26 26
>      > >>
>      > >> This can be traced to a bug in adegenet:::.subsetbin:
>      > >>
>      > >> .subsetbin(as.raw(0xff), 1:8)
>      > >> # [1] ff 00 # <-- should be just 'ff'
>      > >>
>      > >> xint <- as.integer(rawToBits(x)[i]) # may be not divisible by 8
>      > >> # so introduce padding: the following line gives 8 bits of padding
>      > >> # instead of 0 when length(xint) is divisible by 8
>      > >> zeroes <- 8 - (length(xint)%%8)
>      > >> # instead use something like:
>      > >> # zeroes <- (8 - (length(xint)%%8)) * (length(xint)%%8 > 0)
>      > >> # (could probably be golfed further)
>      > >> return(packBits(c(xint, rep(0L, zeroes))))
>      > >>
>      > >> But we're getting two bugs for the price of one, because even
>     with a
>      > >> 25-byte buffer, nLoc(.) == 199 would still result in an 8-byte
>      > >> overflow. This is solely on the bytesToDouble() C function: it
>     ought to
>      > >> know to stop after writing *reslength elements into the
>     'vecres' array.
>      > >>
>      > >> I'm afraid there is no easy way to work around either of the
>     bugs in
>      > >> the dartR.base code.
>      > >>
>      > >> --
>      > >> Best regards,
>      > >> Ivan
>      > >>
>      > >> [1]
>      > >> https://github.com/thibautjombart/adegenet/blob/
>     c7287597155ab18989d892a72eff33cf8c288958/src/snpbin.c#L443-L444
>     <https://github.com/thibautjombart/adegenet/blob/
>     c7287597155ab18989d892a72eff33cf8c288958/src/snpbin.c#L443-L444>
>      > >>
>      > >> [2]
>      > >> https://github.com/thibautjombart/adegenet/blob/
>     c7287597155ab18989d892a72eff33cf8c288958/src/GLfunctions.c#L124
>     <https://github.com/thibautjombart/adegenet/blob/
>     c7287597155ab18989d892a72eff33cf8c288958/src/GLfunctions.c#L124>
>      > >>
>      > >> [3]
>      > >> https://github.com/thibautjombart/adegenet/blob/
>     c7287597155ab18989d892a72eff33cf8c288958/R/glFunctions.R#L215-L216
>     <https://github.com/thibautjombart/adegenet/blob/
>     c7287597155ab18989d892a72eff33cf8c288958/R/glFunctions.R#L215-L216>
>      > >>
>      > >> ______________________________________________
>      > >> R-package-devel at r-project.org <mailto:R-package-devel at r-
>     project.org> mailing list
>      > >> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-package-devel>
>      > >>
>      > >
>      > >
>      >
> 
> 
>     -- 
>     I?aki ?car
> 


From @jenk|n@ @end|ng |rom @tud|oj@u@  Wed Feb  5 15:36:51 2025
From: @jenk|n@ @end|ng |rom @tud|oj@u@ (Steven Jenkins)
Date: Wed, 5 Feb 2025 09:36:51 -0500
Subject: [R-pkg-devel] puzzling result from revdep_check()
Message-ID: <C3C8C49D-616C-4BBB-9AA1-9F70C9FB6C1B@studioj.us>

Running as a command indicates everything as expected:

> revdepcheck::revdep_check(num_workers = 4)
?? INIT ????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????? Computing revdeps ??
?? INSTALL ????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????? 2 versions ??
Installing CRAN version of rollupTree
Installing DEV version of rollupTree
Installing 1 packages: igraph
?? CHECK ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????? 1 packages ??
? massProps 0.2.0                        ?? E: 0     | W: 0     | N: 0                                                                                                    
OK: 1                                                                                                                                                                   
BROKEN: 0
Total time: <1 min
?? REPORT ????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
Writing summary to 'revdep/README.md'
Writing problems to 'revdep/problems.md'
Writing failures to 'revdep/failures.md'
Writing CRAN report to 'revdep/cran.md?

Despite logging the revdep massProps 0.2.0 above, the Revdeps section in the summary is empty. What am I missing?

# Platform

|field    |value                                 |
|:--------|:-------------------------------------|
|version  |R version 4.4.2 (2024-10-31)          |
|os       |macOS Sequoia 15.1.1                  |
|system   |aarch64, darwin20                     |
|ui       |RStudio                               |
|language |(EN)                                  |
|collate  |en_US.UTF-8                           |
|ctype    |en_US.UTF-8                           |
|tz       |America/New_York                      |
|date     |2025-02-05                            |
|rstudio  |2024.12.0+467 Kousa Dogwood (desktop) |
|pandoc   |3.6.2 @ /usr/local/bin/pandoc         |

# Dependencies

|package    |old   |new        |?  |
|:----------|:-----|:----------|:--|
|rollupTree |0.2.0 |0.2.0.9000 |*  |
|igraph     |NA    |2.1.4      |*  |

# Revdeps

Steve
	[[alternative HTML version deleted]]


From zk@mv@r @end|ng |rom gm@||@com  Thu Feb  6 04:52:57 2025
From: zk@mv@r @end|ng |rom gm@||@com (Zhian Kamvar)
Date: Wed, 5 Feb 2025 19:52:57 -0800
Subject: [R-pkg-devel] S3 generic/method consistency NOTE
Message-ID: <CAPsXksKyQyMntOdN40yiDeDwqfcPQJYxBs-j2Jhg9=Nz4tqFLw@mail.gmail.com>

I'm getting this warning in an old package and im not quite sure how to fix
it. I've always understood the is.thing sort of functions as always taking
a single argument, which is usually "x"

Do I have to update the is.genind etc signature to take two arguments?

Note below

Check: S3 generic/method consistency, Result: NOTE
  Mismatches for methods registered for non-generic:
  is:
    function(object, class2)
  is.genind:
    function(x)

  is:
    function(object, class2)
  is.genpop:
    function(x)

  sample:
    function(x, size, replace, prob)
  sample.haploGen:
    function(x, n)
  See section 'Registering S3 methods' in the 'Writing R Extensions'
  manual.

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Thu Feb  6 09:10:19 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Thu, 6 Feb 2025 11:10:19 +0300
Subject: [R-pkg-devel] S3 generic/method consistency NOTE
In-Reply-To: <CAPsXksKyQyMntOdN40yiDeDwqfcPQJYxBs-j2Jhg9=Nz4tqFLw@mail.gmail.com>
References: <CAPsXksKyQyMntOdN40yiDeDwqfcPQJYxBs-j2Jhg9=Nz4tqFLw@mail.gmail.com>
Message-ID: <20250206111019.679e89f1@Tarkus>

? Wed, 5 Feb 2025 19:52:57 -0800
Zhian Kamvar <zkamvar at gmail.com> ?????:

>   Mismatches for methods registered for non-generic:
>   is:
>     function(object, class2)
>   is.genind:
>     function(x)
> 
>   is:
>     function(object, class2)
>   is.genpop:
>     function(x)
> 
>   sample:
>     function(x, size, replace, prob)
>   sample.haploGen:
>     function(x, n)

Neither methods::is nor base::sample are S3 generics, so these S3
method registrations are not needed:

https://github.com/thibautjombart/adegenet/blob/e4874e73f0d39ebdddeca05b7eb1359fab771aaf/NAMESPACE#L50-L51
https://github.com/thibautjombart/adegenet/blob/e4874e73f0d39ebdddeca05b7eb1359fab771aaf/NAMESPACE#L73

In other words, calling is(new("genind", ...)) or sample(haploGen(...))
won't dispatch to is.genind() or sample.haploGen() anyway; these
functions are probably intended to be called by their full names.

Removing these lines and re-generating NAMESPACE should help:

https://github.com/thibautjombart/adegenet/blob/e4874e73f0d39ebdddeca05b7eb1359fab771aaf/R/basicMethods.R#L546
https://github.com/thibautjombart/adegenet/blob/e4874e73f0d39ebdddeca05b7eb1359fab771aaf/R/basicMethods.R#L553
https://github.com/thibautjombart/adegenet/blob/e4874e73f0d39ebdddeca05b7eb1359fab771aaf/R/haploGen.R#L529

-- 
Best regards,
Ivan


From zk@mv@r @end|ng |rom gm@||@com  Thu Feb  6 23:42:34 2025
From: zk@mv@r @end|ng |rom gm@||@com (Zhian Kamvar)
Date: Thu, 6 Feb 2025 14:42:34 -0800
Subject: [R-pkg-devel] S3 generic/method consistency NOTE
In-Reply-To: <20250206111019.679e89f1@Tarkus>
References: <CAPsXksKyQyMntOdN40yiDeDwqfcPQJYxBs-j2Jhg9=Nz4tqFLw@mail.gmail.com>
 <20250206111019.679e89f1@Tarkus>
Message-ID: <CAPsXks+AHM1wo4GsH6e9TsFQomSyV0XELn7+5=p6pG1EKDyj0w@mail.gmail.com>

This was the correct answer, thank you!

On Thu, Feb 6, 2025 at 00:10 Ivan Krylov <ikrylov at disroot.org> wrote:

> ? Wed, 5 Feb 2025 19:52:57 -0800
> Zhian Kamvar <zkamvar at gmail.com> ?????:
>
> >   Mismatches for methods registered for non-generic:
> >   is:
> >     function(object, class2)
> >   is.genind:
> >     function(x)
> >
> >   is:
> >     function(object, class2)
> >   is.genpop:
> >     function(x)
> >
> >   sample:
> >     function(x, size, replace, prob)
> >   sample.haploGen:
> >     function(x, n)
>
> Neither methods::is nor base::sample are S3 generics, so these S3
> method registrations are not needed:
>
>
> https://github.com/thibautjombart/adegenet/blob/e4874e73f0d39ebdddeca05b7eb1359fab771aaf/NAMESPACE#L50-L51
>
> https://github.com/thibautjombart/adegenet/blob/e4874e73f0d39ebdddeca05b7eb1359fab771aaf/NAMESPACE#L73
>
> In other words, calling is(new("genind", ...)) or sample(haploGen(...))
> won't dispatch to is.genind() or sample.haploGen() anyway; these
> functions are probably intended to be called by their full names.
>
> Removing these lines and re-generating NAMESPACE should help:
>
>
> https://github.com/thibautjombart/adegenet/blob/e4874e73f0d39ebdddeca05b7eb1359fab771aaf/R/basicMethods.R#L546
>
> https://github.com/thibautjombart/adegenet/blob/e4874e73f0d39ebdddeca05b7eb1359fab771aaf/R/basicMethods.R#L553
>
> https://github.com/thibautjombart/adegenet/blob/e4874e73f0d39ebdddeca05b7eb1359fab771aaf/R/haploGen.R#L529
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From zk@mv@r @end|ng |rom gm@||@com  Fri Feb  7 00:23:15 2025
From: zk@mv@r @end|ng |rom gm@||@com (Zhian Kamvar)
Date: Thu, 6 Feb 2025 15:23:15 -0800
Subject: [R-pkg-devel] Additional issue clang-ASAN, gcc-ASAN
In-Reply-To: <970789b4-451d-4d36-8b40-d970983c8192@statistik.tu-dortmund.de>
References: <mailman.11256.10.1738407601.11304.r-package-devel@r-project.org>
 <ME3PR01MB7944A3A9807CADA986349B4CD4EA2@ME3PR01MB7944.ausprd01.prod.outlook.com>
 <20250204143003.22982e7b@arachnoid>
 <CALEXWq3_vDeJHNVLgFjdKAMcmAYPT32yLvDN=i3bhOjJnwu=Lw@mail.gmail.com>
 <79394630-e305-4c3a-8781-01135867d508@statistik.tu-dortmund.de>
 <CALEXWq0rdWVpPyBmb_JDmw-2289zNhpDQ7GodK5Q2vDjO_vQdw@mail.gmail.com>
 <CAPsXksKbbg1d0JM1VgWUkLOWZsJ3Wss-mcgmaNX3s0qnbc8HmQ@mail.gmail.com>
 <970789b4-451d-4d36-8b40-d970983c8192@statistik.tu-dortmund.de>
Message-ID: <CAPsXksKo6fjE0z7WBvBp08L58V0DM1bQhkmPb4OrntVx=Mqcng@mail.gmail.com>

The new version of adegenet is on CRAN now. Thank you all for your help.

I am curious: what happens with dartR.base? Will the removal notice go away
in a few days?

On Wed, Feb 5, 2025 at 00:44 Uwe Ligges <ligges at statistik.tu-dortmund.de>
wrote:

> Great, thanks,
> Uwe
>
>
> On 05.02.2025 02:32, Zhian Kamvar wrote:
> > Thank you, Uwe for tagging me in. Huge thank you to Ivan for the
> > detailed analysis. This reflects what Max Coulter found in https://
> > github.com/thibautjombart/adegenet/issues/363 <https://github.com/
> > thibautjombart/adegenet/issues/363>. I just merged in https://
> > github.com/thibautjombart/adegenet/issues/363 <https://github.com/
> > thibautjombart/adegenet/issues/363> yesterday and I believe that should
> > fix the issue.
> >
> > I am going to run a test using the https://hub.docker.com/r/rocker/r-
> > devel-san/ <https://hub.docker.com/r/rocker/r-devel-san/> to confirm
> > that this is fixed before I send it off to CRAN.
> >
> > Best,
> > Zhian
> >
> >
> > On Tue, Feb 4, 2025 at 4:01?AM I?aki Ucar <iucar at fedoraproject.org
> > <mailto:iucar at fedoraproject.org>> wrote:
> >
> >     On Tue, 4 Feb 2025 at 12:56, Uwe Ligges <ligges at statistik.tu-
> >     dortmund.de <mailto:ligges at statistik.tu-dortmund.de>> wrote:
> >      >
> >      >
> >      >
> >      > On 04.02.2025 12:46, I?aki Ucar wrote:
> >      > > @Ivan: Excellent anaylsis as always.
> >      > >
> >      > > @Bernd: So what can **you** do about it? You are using adegenet
> >      > > correctly as Ivan pointed out, so IMHO CRAN should have
> requested
> >      > > adegenet's maintainer to fix this. But since it's your package
> >     that is
> >      > > on the line here, I would put that example inside a dontrun{}
> chunk
> >      > > for now, to avoid triggering this issue on CRAN, and I would
> report
> >      > > Ivan's analysis upstream.
> >      >
> >      > Putting it in dontrun is the wrong advise in any case, as we like
> to
> >      > track whether the underlying issue has been fixed. And both
> Professor
> >      > Ripley and I already asked to liase with the adegenet maintainer
> >     to get
> >      > this fixed.
> >
> >     Great, we obviously didn't know this, but only that Bernd's package
> is
> >     scheduled to be archived soon, thus my advice.
> >
> >     I?aki
> >
> >      > So I wonder why the most relevant person (Zhian N. Kamvar)
> >      > was not included here (CCIng now).
> >      > Ivan's analysis is as always extremely helpful, particularly for
> the
> >      > adegenet maintainer.
> >      >
> >      > Best,
> >      > Uwe
> >      >
> >      >
> >      >
> >      > > I?aki
> >      > >
> >      > >
> >      > > On Tue, 4 Feb 2025 at 12:30, Ivan Krylov via R-package-devel
> >      > > <r-package-devel at r-project.org <mailto:r-package-devel at r-
> >     project.org>> wrote:
> >      > >>
> >      > >> ? Sun, 2 Feb 2025 22:56:47 +0000
> >      > >> Bernd.Gruber <Bernd.Gruber at canberra.edu.au
> >     <mailto:Bernd.Gruber at canberra.edu.au>> ?????:
> >      > >>
> >      > >>> READ of size 16 at 0x518000697ff0 thread T0
> >      > >>>      #0 0x7f2e873ccfdf in bytesToDouble
> >      > >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/
> >     snpbin.c:225:19
> >      > >>> #1 0x7f2e873ceca5 in snpbin2freq
> >      > >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/
> >     snpbin.c:332:5
> >      > >>> #2 0x7f2e873ceca5 in snpbin_dotprod_freq
> >      > >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/
> >     snpbin.c:447:5
> >      > >>> #3 0x7f2e873bba42 in GLdotProd
> >      > >>> /tmp/RtmpNNPUz9/R.INSTALL3cef1f2b1bd39c/adegenet/src/
> >     GLfunctions.c:42:14
> >      > >>
> >      > >> Ben Bolker is exactly right; the problem happens in the
> 'adegenet'
> >      > >> code. Why?
> >      > >>
> >      > >> bytesToDouble() is asked to unpack the bytes from the
> >     'vecbytes' array
> >      > >> (26 bytes) into individual bits stored as doubles in the 'out'
> >     array.
> >      > >> The latter was allocated by the snpbin_dotprod_freq() function
> to
> >      > >> contain 199 elements [1]. Every byte must be unpacked into 8
> >     bits, and
> >      > >> 199 is less than 26*8 = 208. Where did the values come from?
> >      > >>
> >      > >> The C function GLsumFreq() stores them unchanged from its
> >     arguments
> >      > >> [2], and those come from the SNPbin objects passed by R code
> >     [3] from
> >      > >> nLoc(x) and length(x$gen[[1]]@snp[[1]]). Where do they
> originate?
> >      > >>
> >      > >> The R traceback at the point of the crash is
> >     dartR.base::gl.pcoa ->
> >      > >> adegenet::glPca -> adegenet::glDotProd. The object 'possums.gl
> >     <http://possums.gl>' of S4
> >      > >> class 'dartR' exported by 'dartR.base' appears valid: its .
> >     $n.loc is
> >      > >> exactly equal to length(.$gen[[1]]@snp[[1]]) * 8, so the
> >     allocation size
> >      > >> matches the packed binary content.
> >      > >>
> >      > >> The subset possums.gl <http://possums.gl>[1:50,] that is used
> >     to perform PCA, on the other
> >      > >> hand, is invalid: length(possums.gl <http://
> >     possums.gl>[1:50,]$gen[[1]]@snp[[1]]) is 26
> >      > >> instead of 25, which later causes bytesToDouble() to try to
> >     write extra
> >      > >> 8 doubles (64 bytes) into the buffer.
> >      > >>
> >      > >> This happens because trying to extract all SNPs from an SNPbin
> >     object
> >      > >> introduces an extra byte:
> >      > >>
> >      > >> possums.gl at gen[[1]] |> _ at snp |> lengths()
> >      > >> # [1] 25 25
> >      > >>
> >      > >> possums.gl at gen[[1]][rep(TRUE, nLoc(possums.gl at gen[[1]]))] |>
> >      > >>   _ at snp |> lengths()
> >      > >> # 26 26
> >      > >>
> >      > >> This can be traced to a bug in adegenet:::.subsetbin:
> >      > >>
> >      > >> .subsetbin(as.raw(0xff), 1:8)
> >      > >> # [1] ff 00 # <-- should be just 'ff'
> >      > >>
> >      > >> xint <- as.integer(rawToBits(x)[i]) # may be not divisible by 8
> >      > >> # so introduce padding: the following line gives 8 bits of
> padding
> >      > >> # instead of 0 when length(xint) is divisible by 8
> >      > >> zeroes <- 8 - (length(xint)%%8)
> >      > >> # instead use something like:
> >      > >> # zeroes <- (8 - (length(xint)%%8)) * (length(xint)%%8 > 0)
> >      > >> # (could probably be golfed further)
> >      > >> return(packBits(c(xint, rep(0L, zeroes))))
> >      > >>
> >      > >> But we're getting two bugs for the price of one, because even
> >     with a
> >      > >> 25-byte buffer, nLoc(.) == 199 would still result in an 8-byte
> >      > >> overflow. This is solely on the bytesToDouble() C function: it
> >     ought to
> >      > >> know to stop after writing *reslength elements into the
> >     'vecres' array.
> >      > >>
> >      > >> I'm afraid there is no easy way to work around either of the
> >     bugs in
> >      > >> the dartR.base code.
> >      > >>
> >      > >> --
> >      > >> Best regards,
> >      > >> Ivan
> >      > >>
> >      > >> [1]
> >      > >> https://github.com/thibautjombart/adegenet/blob/
> >     c7287597155ab18989d892a72eff33cf8c288958/src/snpbin.c#L443-L444
> >     <https://github.com/thibautjombart/adegenet/blob/
> >     c7287597155ab18989d892a72eff33cf8c288958/src/snpbin.c#L443-L444>
> >      > >>
> >      > >> [2]
> >      > >> https://github.com/thibautjombart/adegenet/blob/
> >     c7287597155ab18989d892a72eff33cf8c288958/src/GLfunctions.c#L124
> >     <https://github.com/thibautjombart/adegenet/blob/
> >     c7287597155ab18989d892a72eff33cf8c288958/src/GLfunctions.c#L124>
> >      > >>
> >      > >> [3]
> >      > >> https://github.com/thibautjombart/adegenet/blob/
> >     c7287597155ab18989d892a72eff33cf8c288958/R/glFunctions.R#L215-L216
> >     <https://github.com/thibautjombart/adegenet/blob/
> >     c7287597155ab18989d892a72eff33cf8c288958/R/glFunctions.R#L215-L216>
> >      > >>
> >      > >> ______________________________________________
> >      > >> R-package-devel at r-project.org <mailto:R-package-devel at r-
> >     project.org> mailing list
> >      > >> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> >     <https://stat.ethz.ch/mailman/listinfo/r-package-devel>
> >      > >>
> >      > >
> >      > >
> >      >
> >
> >
> >     --
> >     I?aki ?car
> >
>
>

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Fri Feb  7 04:57:08 2025
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 7 Feb 2025 03:57:08 +0000
Subject: [R-pkg-devel] 'library' or 'require' call not declared
Message-ID: <AD9AAD48-572C-4317-A546-C362FFDCC26D@temple.edu>

I don't understand what this message means

Flavor: r-devel-linux-x86_64-debian-gcc
Check: for unstated dependencies in 'demo', Result: NOTE
 'library' or 'require' call not declared from: 'MASS'

it is coming from HH_3.1-53.tar.gz that I sent in this evening.
It is also visible for HH_3.1-52.tar.gz on the CRAN package check page


From m|ch@e|ch|r|co4 @end|ng |rom gm@||@com  Fri Feb  7 05:09:18 2025
From: m|ch@e|ch|r|co4 @end|ng |rom gm@||@com (Michael Chirico)
Date: Thu, 6 Feb 2025 20:09:18 -0800
Subject: [R-pkg-devel] 'library' or 'require' call not declared
In-Reply-To: <AD9AAD48-572C-4317-A546-C362FFDCC26D@temple.edu>
References: <AD9AAD48-572C-4317-A546-C362FFDCC26D@temple.edu>
Message-ID: <CAPRVBcwrs1bAc595mq9iBJnurQpA2fyYusewN02xKpeHvGRbvA@mail.gmail.com>

You haven't shared enough info to help well, but it looks like you use
package MASS in your demo/ directory without a corresponding entry in your
DESCRIPTION file.

Add MASS as Suggests or Imports should be enough.

If you point to where your code is on GitHub or another public-facing
repository it is easier to help more specifically.

On Thu, Feb 6, 2025, 7:57?PM Richard M. Heiberger <rmh at temple.edu> wrote:

> I don't understand what this message means
>
> Flavor: r-devel-linux-x86_64-debian-gcc
> Check: for unstated dependencies in 'demo', Result: NOTE
>  'library' or 'require' call not declared from: 'MASS'
>
> it is coming from HH_3.1-53.tar.gz that I sent in this evening.
> It is also visible for HH_3.1-52.tar.gz on the CRAN package check page
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Fri Feb  7 06:05:09 2025
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 7 Feb 2025 05:05:09 +0000
Subject: [R-pkg-devel] 
 [External]  'library' or 'require' call not declared
In-Reply-To: <CAPRVBcwrs1bAc595mq9iBJnurQpA2fyYusewN02xKpeHvGRbvA@mail.gmail.com>
References: <AD9AAD48-572C-4317-A546-C362FFDCC26D@temple.edu>
 <CAPRVBcwrs1bAc595mq9iBJnurQpA2fyYusewN02xKpeHvGRbvA@mail.gmail.com>
Message-ID: <0F66EAFD-8308-42C0-8A19-7AE5FD8E005C@temple.edu>

Michael and Brian.

thank you
exactly correct.

> On Feb 6, 2025, at 23:09, Michael Chirico <michaelchirico4 at gmail.com> wrote:
> 
> You haven't shared enough info to help well, but it looks like you use package MASS in your demo/ directory without a corresponding entry in your DESCRIPTION file.
> Add MASS as Suggests or Imports should be enough.
> If you point to where your code is on GitHub or another public-facing repository it is easier to help more specifically.
> 
> On Thu, Feb 6, 2025, 7:57?PM Richard M. Heiberger <rmh at temple.edu> wrote:
> I don't understand what this message means
> 
> Flavor: r-devel-linux-x86_64-debian-gcc
> Check: for unstated dependencies in 'demo', Result: NOTE
>  'library' or 'require' call not declared from: 'MASS'
> 
> it is coming from HH_3.1-53.tar.gz that I sent in this evening.
> It is also visible for HH_3.1-52.tar.gz on the CRAN package check page
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel



From br|@n @end|ng |rom br@verock@com  Fri Feb  7 05:02:27 2025
From: br|@n @end|ng |rom br@verock@com (Brian G. Peterson)
Date: Thu, 06 Feb 2025 22:02:27 -0600
Subject: [R-pkg-devel] 'library' or 'require' call not declared
In-Reply-To: <AD9AAD48-572C-4317-A546-C362FFDCC26D@temple.edu>
References: <AD9AAD48-572C-4317-A546-C362FFDCC26D@temple.edu>
Message-ID: <d11dbd180f5d155636c4989ea3f097452eec84c1.camel@braverock.com>

Add 'MASS' to either Suggests or Imports?

If you add it to Imports, you'll need to add the requisite function
imports, but if the only place you use MASS is in 'demo'  (maybe a more
searchable name is in order here?), then 'Suggests' should be plenty.

Brian


On Fri, 2025-02-07 at 03:57 +0000, Richard M. Heiberger wrote:
> I don't understand what this message means
> 
> Flavor: r-devel-linux-x86_64-debian-gcc
> Check: for unstated dependencies in 'demo', Result: NOTE
> ?'library' or 'require' call not declared from: 'MASS'
> 
> it is coming from HH_3.1-53.tar.gz that I sent in this evening.
> It is also visible for HH_3.1-52.tar.gz on the CRAN package check
> page
> 
> ______________________________________________
> R-package-devel at r-project.org?mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> 


From k@b||@n151414 @end|ng |rom gm@||@com  Fri Feb  7 07:51:27 2025
From: k@b||@n151414 @end|ng |rom gm@||@com (KABILAN S)
Date: Fri, 7 Feb 2025 06:51:27 +0000
Subject: [R-pkg-devel] How to solve this error while running python script
 in R environment?
Message-ID: <AS8PR02MB10148368DB584F8B99E1D8136ACF12@AS8PR02MB10148.eurprd02.prod.outlook.com>

When I am creating the R package based on the python script, I am getting the below error while checking the package.


* checking examples ... [60s] ERROR
Running examples in 'transformerForecasting-Ex.R' failed
The error most likely occurred in:

> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: TRANSFORMER
> ### Title: Transformer Model for Time Series Forecasting
> ### Aliases: TRANSFORMER
>
> ### ** Examples
>
> data(S_P_500_Close_data)
> df <- S_P_500_Close_data
> result <- TRANSFORMER(df = S_P_500_Close_data, study_variable = "Price")
Error: Valid installation of TensorFlow not found.

Python environments searched for 'tensorflow' package:
 C:\Users\CRAN\Documents\.virtualenvs\r-reticulate\Scripts\python.exe

Python exception encountered:
 Traceback (most recent call last):
  File "D:\RCompile\CRANpkg\lib\4.5\reticulate\python\rpytools\loader.py", line 122, in _find_and_load_hook
    return _run_hook(name, _hook)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\RCompile\CRANpkg\lib\4.5\reticulate\python\rpytools\loader.py", line 96, in _run_hook
    module = hook()
             ^^^^^^
  File "D:\RCompile\CRANpkg\lib\4.5\reticulate\python\rpytools\loader.py", line 120, in _hook
    return _find_and_load(name, import_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'tensorflow'


You can install TensorFlow using the install_tensorflow() function.
Execution halted

How to solve this?

	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Fri Feb  7 16:09:55 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Fri, 7 Feb 2025 09:09:55 -0600
Subject: [R-pkg-devel] 
 [External]  'library' or 'require' call not declared
In-Reply-To: <0F66EAFD-8308-42C0-8A19-7AE5FD8E005C@temple.edu>
References: <AD9AAD48-572C-4317-A546-C362FFDCC26D@temple.edu>
 <CAPRVBcwrs1bAc595mq9iBJnurQpA2fyYusewN02xKpeHvGRbvA@mail.gmail.com>
 <0F66EAFD-8308-42C0-8A19-7AE5FD8E005C@temple.edu>
Message-ID: <26534.8771.151983.983697@rob.eddelbuettel.com>


On 7 February 2025 at 05:05, Richard M. Heiberger wrote:
| Michael and Brian.
| 
| thank you
| exactly correct.

For completeness: this check is a fairly recent addition to r-devel and hence
a 'policy change'.

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Fri Feb  7 17:06:54 2025
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Fri, 7 Feb 2025 16:06:54 +0000
Subject: [R-pkg-devel] 
 How to solve this error while running python script
 in R environment?
In-Reply-To: <AS8PR02MB10148368DB584F8B99E1D8136ACF12@AS8PR02MB10148.eurprd02.prod.outlook.com>
References: <AS8PR02MB10148368DB584F8B99E1D8136ACF12@AS8PR02MB10148.eurprd02.prod.outlook.com>
Message-ID: <b0c33e6b-88ab-4e3f-b3a6-a7324014801f@dewey.myzen.co.uk>

Have you got tensorflow installed somewhere where R knows about it?

Michael

On 07/02/2025 06:51, KABILAN S wrote:
> When I am creating the R package based on the python script, I am getting the below error while checking the package.
> 
> 
> * checking examples ... [60s] ERROR
> Running examples in 'transformerForecasting-Ex.R' failed
> The error most likely occurred in:
> 
>> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
>> ### Name: TRANSFORMER
>> ### Title: Transformer Model for Time Series Forecasting
>> ### Aliases: TRANSFORMER
>>
>> ### ** Examples
>>
>> data(S_P_500_Close_data)
>> df <- S_P_500_Close_data
>> result <- TRANSFORMER(df = S_P_500_Close_data, study_variable = "Price")
> Error: Valid installation of TensorFlow not found.
> 
> Python environments searched for 'tensorflow' package:
>   C:\Users\CRAN\Documents\.virtualenvs\r-reticulate\Scripts\python.exe
> 
> Python exception encountered:
>   Traceback (most recent call last):
>    File "D:\RCompile\CRANpkg\lib\4.5\reticulate\python\rpytools\loader.py", line 122, in _find_and_load_hook
>      return _run_hook(name, _hook)
>             ^^^^^^^^^^^^^^^^^^^^^^
>    File "D:\RCompile\CRANpkg\lib\4.5\reticulate\python\rpytools\loader.py", line 96, in _run_hook
>      module = hook()
>               ^^^^^^
>    File "D:\RCompile\CRANpkg\lib\4.5\reticulate\python\rpytools\loader.py", line 120, in _hook
>      return _find_and_load(name, import_)
>             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> ModuleNotFoundError: No module named 'tensorflow'
> 
> 
> You can install TensorFlow using the install_tensorflow() function.
> Execution halted
> 
> How to solve this?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> 

-- 
Michael Dewey


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Feb  7 17:15:38 2025
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 7 Feb 2025 11:15:38 -0500
Subject: [R-pkg-devel] 
 [External] 'library' or 'require' call not declared
In-Reply-To: <26534.8771.151983.983697@rob.eddelbuettel.com>
References: <AD9AAD48-572C-4317-A546-C362FFDCC26D@temple.edu>
 <CAPRVBcwrs1bAc595mq9iBJnurQpA2fyYusewN02xKpeHvGRbvA@mail.gmail.com>
 <0F66EAFD-8308-42C0-8A19-7AE5FD8E005C@temple.edu>
 <26534.8771.151983.983697@rob.eddelbuettel.com>
Message-ID: <ef9b6651-778c-4b1c-982a-7e504d4a415e@gmail.com>

On 2025-02-07 10:09 a.m., Dirk Eddelbuettel wrote:
> 
> On 7 February 2025 at 05:05, Richard M. Heiberger wrote:
> | Michael and Brian.
> |
> | thank you
> | exactly correct.
> 
> For completeness: this check is a fairly recent addition to r-devel and hence
> a 'policy change'.
> 

I don't think it's a policy change:  it's documented that all packages 
used in package code need to be declared.

Writing R Extensions in 4.4.2 says "All packages that are needed to 
successfully run R CMD check on the package must be listed in one of 
?Depends? or ?Suggests? or ?Imports?. Packages used to run examples or 
tests conditionally (e.g. via if(require(pkgname))) should be listed in 
?Suggests? or ?Enhances?. (This allows checkers to ensure that all the 
packages needed for a complete check are installed.)"

It may be that the tests weren't enforcing this rule until recently, but 
I think the rule has been there for a long time.

Duncan


From edd @end|ng |rom deb|@n@org  Fri Feb  7 17:33:38 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Fri, 7 Feb 2025 10:33:38 -0600
Subject: [R-pkg-devel] 
 [External] 'library' or 'require' call not declared
In-Reply-To: <ef9b6651-778c-4b1c-982a-7e504d4a415e@gmail.com>
References: <AD9AAD48-572C-4317-A546-C362FFDCC26D@temple.edu>
 <CAPRVBcwrs1bAc595mq9iBJnurQpA2fyYusewN02xKpeHvGRbvA@mail.gmail.com>
 <0F66EAFD-8308-42C0-8A19-7AE5FD8E005C@temple.edu>
 <26534.8771.151983.983697@rob.eddelbuettel.com>
 <ef9b6651-778c-4b1c-982a-7e504d4a415e@gmail.com>
Message-ID: <26534.13794.872984.938696@rob.eddelbuettel.com>


On 7 February 2025 at 11:15, Duncan Murdoch wrote:
| On 2025-02-07 10:09 a.m., Dirk Eddelbuettel wrote:
| > 
| > On 7 February 2025 at 05:05, Richard M. Heiberger wrote:
| > | Michael and Brian.
| > |
| > | thank you
| > | exactly correct.
| > 
| > For completeness: this check is a fairly recent addition to r-devel and hence
| > a 'policy change'.
| > 
| 
| I don't think it's a policy change:  it's documented that all packages 
| used in package code need to be declared.
| 
| Writing R Extensions in 4.4.2 says "All packages that are needed to 
| successfully run R CMD check on the package must be listed in one of 
| ?Depends? or ?Suggests? or ?Imports?. Packages used to run examples or 
| tests conditionally (e.g. via if(require(pkgname))) should be listed in 
| ?Suggests? or ?Enhances?. (This allows checkers to ensure that all the 
| packages needed for a complete check are installed.)"
| 
| It may be that the tests weren't enforcing this rule until recently, but 
| I think the rule has been there for a long time.

Both parts are true, but the addition of the test is new in r-devel, and that
was the point I made.

I have been on record for years stating that 'Depends != Suggests' (title of
an old blog post of mine; these days it would be 'Imports != Suggests'),
particularly in the context of tests. But I also happened to at times have
tucked some code away in demo/ _precisely because_ it would not lead to
inflating Suggests. And in those cases I now use examples/, or bite the
bullet and expand Suggests.

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From |kry|ov @end|ng |rom d|@root@org  Fri Feb  7 17:41:57 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Fri, 7 Feb 2025 19:41:57 +0300
Subject: [R-pkg-devel] 
 How to solve this error while running python script
 in R environment?
In-Reply-To: <AS8PR02MB10148368DB584F8B99E1D8136ACF12@AS8PR02MB10148.eurprd02.prod.outlook.com>
References: <AS8PR02MB10148368DB584F8B99E1D8136ACF12@AS8PR02MB10148.eurprd02.prod.outlook.com>
Message-ID: <20250207194157.6e01d424@arachnoid>

? Fri, 7 Feb 2025 06:51:27 +0000
KABILAN S <kabilan151414 at gmail.com> ?????:

> > result <- TRANSFORMER(df = S_P_500_Close_data, study_variable =
> > "Price")  
> Error: Valid installation of TensorFlow not found.
> 
> Python environments searched for 'tensorflow' package:
>  C:\Users\CRAN\Documents\.virtualenvs\r-reticulate\Scripts\python.exe

I'm afraid you'll have to wrap your examples in checks for
py_module_available(...):
https://stat.ethz.ch/pipermail/r-package-devel/2024q3/011076.html

-- 
Best regards,
Ivan


From henr|k@bengt@@on @end|ng |rom gm@||@com  Fri Feb  7 22:27:57 2025
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Fri, 7 Feb 2025 13:27:57 -0800
Subject: [R-pkg-devel] Failed: Future File Timestamp Check
In-Reply-To: <94DC06FD-5C10-406E-83D0-78D5902BA6ED@R-project.org>
References: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>
 <94DC06FD-5C10-406E-83D0-78D5902BA6ED@R-project.org>
Message-ID: <CAFDcVCSrJu=r51B4245CLrnNkeWGiz_BPd1Qreo17osyTm3aBQ@mail.gmail.com>

> It has to have the "datetime" entry. If you can't fix your network you can skip that test with
>
> _R_CHECK_FUTURE_FILE_TIMESTAMPS_=FALSE

I'm quite sure that is overridden 'R CMD check' when using the
--as-cran flag. The workaround that I have found is to set environment
variable:

_R_CHECK_SYSTEM_CLOCK_=FALSE

I have observed <http://worldtimeapi.org/api/timezone/etc/UTC> timing
out a lot over the last couple of months from several different
networks and hosts. I've seen it happen in the past too (last couple
of years), but it has got considerably worse recently. Maybe they're
throttling in per IP(?). I consider it quite unreliable these days, so
I use _R_CHECK_SYSTEM_CLOCK_=FALSE by default now.

/Henrik

On Tue, Feb 4, 2025 at 5:50?PM Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> Josiah,
>
> that test tests the accuracy of the system clock by querying https://worldtimeapi.org/api/timezone/etc/UTC so my guess would be that you have either network or proxy issues which cause that request to fail by providing garbage instead of the actual response.
>
> The call to test yourself is
> > readLines("http://worldtimeapi.org/api/timezone/etc/UTC", warn=FALSE)
> [1] "{\"utc_offset\":\"+00:00\",\"timezone\":\"Etc/UTC\",\"day_of_week\":3,\"day_of_year\":36,\"datetime\":\"2025-02-05T01:42:19.272728+00:00\",\"utc_datetime\":\"2025-02-05T01:42:19.272728+00:00\",\"unixtime\":1738719739,\"raw_offset\":0,\"week_number\":6,\"dst\":false,\"abbreviation\":\"UTC\",\"dst_offset\":0,\"dst_from\":null,\"dst_until\":null,\"client_ip\":\"121.98.39.155\"}"
>
> It has to have the "datetime" entry. If you can't fix your network you can skip that test with
>
> _R_CHECK_FUTURE_FILE_TIMESTAMPS_=FALSE
>
> Cheers,
> Simon
>
>
> > On Feb 5, 2025, at 10:11 AM, Josiah Parry <josiah.parry at gmail.com> wrote:
> >
> > I'm running R CMD check for my package {calcite} (source:
> > https://github.com/r-arcGIS/calcite) which is failing due to what *looks* like
> > a bug.
> >
> > R CMD check fails at "checking for future file timestamps"
> >
> > I get this error:  ...Error in if (abs(unclass(now_local) -
> > unclass(now)[1]) > 300) missing value where TRUE/FALSE needed.
> >
> > It seems that an NA is being generated somehow during this check but I'm
> > unsure how.
> >
> > One thing that comes to mind is that the file that contains all of my
> > function definitions is generated using writeLines() but the output of `
> > file.info()` looks normal to me.
> >
> > Have others encountered this? I'm on R 4.4.0 Puppy Cup
> >
> > platform       aarch64-apple-darwin20
> > arch           aarch64
> > os             darwin20
> > system         aarch64, darwin20
> > status
> > major          4
> > minor          4.0
> > year           2024
> > month          04
> > day            24
> > svn rev        86474
> > language       R
> > version.string R version 4.4.0 (2024-04-24)
> > nickname       Puppy Cup
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-package-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-package-devel
> >
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From greg @end|ng |rom ||rm@n@y@h@com  Fri Feb  7 22:54:28 2025
From: greg @end|ng |rom ||rm@n@y@h@com (Greg Hunt)
Date: Sat, 8 Feb 2025 08:54:28 +1100
Subject: [R-pkg-devel] Failed: Future File Timestamp Check
In-Reply-To: <CAFDcVCSrJu=r51B4245CLrnNkeWGiz_BPd1Qreo17osyTm3aBQ@mail.gmail.com>
References: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>
 <94DC06FD-5C10-406E-83D0-78D5902BA6ED@R-project.org>
 <CAFDcVCSrJu=r51B4245CLrnNkeWGiz_BPd1Qreo17osyTm3aBQ@mail.gmail.com>
Message-ID: <CAAS8PAKxNwKP_oBpQeQFkG_UpVmjzqdaOM5UPB+xwS1aK34mRw@mail.gmail.com>

Does all this mean that the check is not handling its own errors?

On Sat, 8 Feb 2025 at 8:28?AM, Henrik Bengtsson <henrik.bengtsson at gmail.com>
wrote:

> > It has to have the "datetime" entry. If you can't fix your network you
> can skip that test with
> >
> > _R_CHECK_FUTURE_FILE_TIMESTAMPS_=FALSE
>
> I'm quite sure that is overridden 'R CMD check' when using the
> --as-cran flag. The workaround that I have found is to set environment
> variable:
>
> _R_CHECK_SYSTEM_CLOCK_=FALSE
>
> I have observed <http://worldtimeapi.org/api/timezone/etc/UTC> timing
> out a lot over the last couple of months from several different
> networks and hosts. I've seen it happen in the past too (last couple
> of years), but it has got considerably worse recently. Maybe they're
> throttling in per IP(?). I consider it quite unreliable these days, so
> I use _R_CHECK_SYSTEM_CLOCK_=FALSE by default now.
>
> /Henrik
>
> On Tue, Feb 4, 2025 at 5:50?PM Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
> >
> > Josiah,
> >
> > that test tests the accuracy of the system clock by querying
> https://worldtimeapi.org/api/timezone/etc/UTC so my guess would be that
> you have either network or proxy issues which cause that request to fail by
> providing garbage instead of the actual response.
> >
> > The call to test yourself is
> > > readLines("http://worldtimeapi.org/api/timezone/etc/UTC", warn=FALSE)
> > [1]
> "{\"utc_offset\":\"+00:00\",\"timezone\":\"Etc/UTC\",\"day_of_week\":3,\"day_of_year\":36,\"datetime\":\"2025-02-05T01:42:19.272728+00:00\",\"utc_datetime\":\"2025-02-05T01:42:19.272728+00:00\",\"unixtime\":1738719739,\"raw_offset\":0,\"week_number\":6,\"dst\":false,\"abbreviation\":\"UTC\",\"dst_offset\":0,\"dst_from\":null,\"dst_until\":null,\"client_ip\":\"121.98.39.155\"}"
> >
> > It has to have the "datetime" entry. If you can't fix your network you
> can skip that test with
> >
> > _R_CHECK_FUTURE_FILE_TIMESTAMPS_=FALSE
> >
> > Cheers,
> > Simon
> >
> >
> > > On Feb 5, 2025, at 10:11 AM, Josiah Parry <josiah.parry at gmail.com>
> wrote:
> > >
> > > I'm running R CMD check for my package {calcite} (source:
> > > https://github.com/r-arcGIS/calcite) which is failing due to what
> *looks* like
> > > a bug.
> > >
> > > R CMD check fails at "checking for future file timestamps"
> > >
> > > I get this error:  ...Error in if (abs(unclass(now_local) -
> > > unclass(now)[1]) > 300) missing value where TRUE/FALSE needed.
> > >
> > > It seems that an NA is being generated somehow during this check but
> I'm
> > > unsure how.
> > >
> > > One thing that comes to mind is that the file that contains all of my
> > > function definitions is generated using writeLines() but the output of
> `
> > > file.info()` looks normal to me.
> > >
> > > Have others encountered this? I'm on R 4.4.0 Puppy Cup
> > >
> > > platform       aarch64-apple-darwin20
> > > arch           aarch64
> > > os             darwin20
> > > system         aarch64, darwin20
> > > status
> > > major          4
> > > minor          4.0
> > > year           2024
> > > month          04
> > > day            24
> > > svn rev        86474
> > > language       R
> > > version.string R version 4.4.0 (2024-04-24)
> > > nickname       Puppy Cup
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-package-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-package-devel
> > >
> >
> > ______________________________________________
> > R-package-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-package-devel
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From m|ch@e|ch|r|co4 @end|ng |rom gm@||@com  Fri Feb  7 23:18:53 2025
From: m|ch@e|ch|r|co4 @end|ng |rom gm@||@com (Michael Chirico)
Date: Fri, 7 Feb 2025 14:18:53 -0800
Subject: [R-pkg-devel] Failed: Future File Timestamp Check
In-Reply-To: <CAAS8PAKxNwKP_oBpQeQFkG_UpVmjzqdaOM5UPB+xwS1aK34mRw@mail.gmail.com>
References: <CAL3ufUJxydcAAJTFVJKEFuTzzfjPST-hBcKG0h3s_35YtofqHQ@mail.gmail.com>
 <94DC06FD-5C10-406E-83D0-78D5902BA6ED@R-project.org>
 <CAFDcVCSrJu=r51B4245CLrnNkeWGiz_BPd1Qreo17osyTm3aBQ@mail.gmail.com>
 <CAAS8PAKxNwKP_oBpQeQFkG_UpVmjzqdaOM5UPB+xwS1aK34mRw@mail.gmail.com>
Message-ID: <CAPRVBcyDnMNwvbpthEhzQzFfsgx8apXa_goWN+jB7h_SB8AS_A@mail.gmail.com>

Actually, it looks like R CMD check has _intended_ to just skip in the
case the website is misbehaving:

https://github.com/r-devel/r-svn/blob/3578a3f858136a8abcd2f708f38a8dff6225ec42/src/library/tools/R/check.R#L549-L552

My guess is this test should be improved, currently we get (logical)
NA if the read throws an error, but not if the API returns but in an
unexpected format:

identical(as.POSIXct(NA), NA)
# [1] FALSE

I filed a bug & patch:

https://bugs.r-project.org/show_bug.cgi?id=18852

On Fri, Feb 7, 2025 at 1:54?PM Greg Hunt <greg at firmansyah.com> wrote:
>
> Does all this mean that the check is not handling its own errors?
>
> On Sat, 8 Feb 2025 at 8:28?AM, Henrik Bengtsson <henrik.bengtsson at gmail.com>
> wrote:
>
> > > It has to have the "datetime" entry. If you can't fix your network you
> > can skip that test with
> > >
> > > _R_CHECK_FUTURE_FILE_TIMESTAMPS_=FALSE
> >
> > I'm quite sure that is overridden 'R CMD check' when using the
> > --as-cran flag. The workaround that I have found is to set environment
> > variable:
> >
> > _R_CHECK_SYSTEM_CLOCK_=FALSE
> >
> > I have observed <http://worldtimeapi.org/api/timezone/etc/UTC> timing
> > out a lot over the last couple of months from several different
> > networks and hosts. I've seen it happen in the past too (last couple
> > of years), but it has got considerably worse recently. Maybe they're
> > throttling in per IP(?). I consider it quite unreliable these days, so
> > I use _R_CHECK_SYSTEM_CLOCK_=FALSE by default now.
> >
> > /Henrik
> >
> > On Tue, Feb 4, 2025 at 5:50?PM Simon Urbanek
> > <simon.urbanek at r-project.org> wrote:
> > >
> > > Josiah,
> > >
> > > that test tests the accuracy of the system clock by querying
> > https://worldtimeapi.org/api/timezone/etc/UTC so my guess would be that
> > you have either network or proxy issues which cause that request to fail by
> > providing garbage instead of the actual response.
> > >
> > > The call to test yourself is
> > > > readLines("http://worldtimeapi.org/api/timezone/etc/UTC", warn=FALSE)
> > > [1]
> > "{\"utc_offset\":\"+00:00\",\"timezone\":\"Etc/UTC\",\"day_of_week\":3,\"day_of_year\":36,\"datetime\":\"2025-02-05T01:42:19.272728+00:00\",\"utc_datetime\":\"2025-02-05T01:42:19.272728+00:00\",\"unixtime\":1738719739,\"raw_offset\":0,\"week_number\":6,\"dst\":false,\"abbreviation\":\"UTC\",\"dst_offset\":0,\"dst_from\":null,\"dst_until\":null,\"client_ip\":\"121.98.39.155\"}"
> > >
> > > It has to have the "datetime" entry. If you can't fix your network you
> > can skip that test with
> > >
> > > _R_CHECK_FUTURE_FILE_TIMESTAMPS_=FALSE
> > >
> > > Cheers,
> > > Simon
> > >
> > >
> > > > On Feb 5, 2025, at 10:11 AM, Josiah Parry <josiah.parry at gmail.com>
> > wrote:
> > > >
> > > > I'm running R CMD check for my package {calcite} (source:
> > > > https://github.com/r-arcGIS/calcite) which is failing due to what
> > *looks* like
> > > > a bug.
> > > >
> > > > R CMD check fails at "checking for future file timestamps"
> > > >
> > > > I get this error:  ...Error in if (abs(unclass(now_local) -
> > > > unclass(now)[1]) > 300) missing value where TRUE/FALSE needed.
> > > >
> > > > It seems that an NA is being generated somehow during this check but
> > I'm
> > > > unsure how.
> > > >
> > > > One thing that comes to mind is that the file that contains all of my
> > > > function definitions is generated using writeLines() but the output of
> > `
> > > > file.info()` looks normal to me.
> > > >
> > > > Have others encountered this? I'm on R 4.4.0 Puppy Cup
> > > >
> > > > platform       aarch64-apple-darwin20
> > > > arch           aarch64
> > > > os             darwin20
> > > > system         aarch64, darwin20
> > > > status
> > > > major          4
> > > > minor          4.0
> > > > year           2024
> > > > month          04
> > > > day            24
> > > > svn rev        86474
> > > > language       R
> > > > version.string R version 4.4.0 (2024-04-24)
> > > > nickname       Puppy Cup
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-package-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-package-devel
> > > >
> > >
> > > ______________________________________________
> > > R-package-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-package-devel
> >
> > ______________________________________________
> > R-package-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-package-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From ||u|@@rev|||@ @end|ng |rom gm@||@com  Sat Feb  8 19:18:59 2025
From: ||u|@@rev|||@ @end|ng |rom gm@||@com (=?UTF-8?Q?Llu=C3=ADs_Revilla?=)
Date: Sat, 8 Feb 2025 19:18:59 +0100
Subject: [R-pkg-devel] Registering methods conditionally
Message-ID: <CAN+W6_s7j-mwDfYG=-gorpdNMGuMz8dWpgk5LhiiqPAysyOq9A@mail.gmail.com>

Dear list,

Checks of the package BaseSet I maintain are failing on r-devel with:
  Error in UseMethod("tidy") : no applicable method for 'tidy' applied to
an object of class "GeneSet" Calls: tidy Execution halted
Surprisingly, similar code on tests pass without errors.

This GeneSet is a S4 class exported by GSEABase and has been exported for
several years [1]. tidy is a S3 method defined on the package.

As this package is a suggested package, following WRE recommendations [2] I
tried to register the method conditionally under requireNamespace:

if (requireNamespace("GSEABase", quietly = TRUE)) {
importClassesFrom(GSEABase, GeneSetCollection)
S3method(tidy, GeneSetCollection)
importClassesFrom(GSEABase, GeneSet)
S3method(tidy, GeneSet)
importClassesFrom(GSEABase, CollectionType)
S3method(tidy, CollectionType)
}

However, the new NAMESPACE doesn't pass checks:
* checking package dependencies ... ERROR
Namespace dependency missing from DESCRIPTION Imports/Depends entries:
?GSEABase?

There have been some threads on r-devel about registering dependencies to
classes defined in other packages [3]. I also saw some packages that
register the S3 method via .onLoad [4]. In this package I defined several
S3 methods for an S4 class. Should I define S4 methods for S4 classes not
defined in my package?

I would appreciate some advice on how to proceed,

Llu?s


[1]: https://code.bioconductor.org/browse/GSEABase/blob/devel/NAMESPACE#L66
[2]:
https://cran.r-project.org/doc/manuals/R-exts.html#Specifying-imports-and-exports
[3]: https://stat.ethz.ch/pipermail/r-devel/2025-January/083780.html
[4]: https://vctrs.r-lib.org/reference/s3_register.html

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Sat Feb  8 21:07:26 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sat, 8 Feb 2025 23:07:26 +0300
Subject: [R-pkg-devel] Registering methods conditionally
In-Reply-To: <CAN+W6_s7j-mwDfYG=-gorpdNMGuMz8dWpgk5LhiiqPAysyOq9A@mail.gmail.com>
References: <CAN+W6_s7j-mwDfYG=-gorpdNMGuMz8dWpgk5LhiiqPAysyOq9A@mail.gmail.com>
Message-ID: <20250208230726.67d344b3@Tarkus>

? Sat, 8 Feb 2025 19:18:59 +0100
Llu?s Revilla <lluis.revilla at gmail.com> ?????:

> Error in UseMethod("tidy") : no applicable method for 'tidy' applied
> to an object of class "GeneSet"

This seems to be a distant consequence of
<https://github.com/Bioconductor/BiocGenerics/issues/20>.

The example for BaseSet::tidy starts with

>> if (requireNamespace("GSEABase", quietly = TRUE)) {

which produces the following messages:

Loading required package: BiocGenerics
Loading required package: generics 
Attaching package: ?generics? 
The following objects are masked from ?package:BaseSet?:         
   tidy, union                    # <-- BaseSet::tidy now shadowed

Indeed, at the point of the error, 'tidy' is

Browse[1]> tidy
function (x, ...) 
{
    UseMethod("tidy")
}
<bytecode: 0x5615feed95c0>
<environment: namespace:generics>

...which is different from your own 'tidy' generic:

Browse[1]> BaseSet::tidy
function (object) 
{
    UseMethod("tidy")
}
<bytecode: 0x5615eed320c8>
<environment: namespace:BaseSet>

...and the method is registered for the BaseSet::tidy generic, not the
generics::tidy generic:

Browse[1]> 'tidy.GeneSet' %in% ls(BaseSet:::.__S3MethodsTable__.)
[1] TRUE
Browse[1]> 'tidy.GeneSet' %in% ls(generics:::.__S3MethodsTable__.)
[1] FALSE

The problem only appears on R-devel because only the development
version of 'BiocGenerics' has the Depends: relationship with 'generics'.

This one is easier to diagnose than to cure. The example seems to work
fine if the methods are registered for the other generic at runtime:

library(BaseSet)
# these are undocumented, use .S3method() in more normal circumstances
registerS3method("tidy", "GeneSet", BaseSet:::tidy.GeneSet,
                 loadNamespace("generics"))
registerS3method("tidy", "GeneSetCollection",
                 BaseSet:::tidy.GeneSetCollection,
                 loadNamespace("generics"))
example("tidy") # doesn't crash

Since BaseSet depends on a new enough R version, it could in theory use
delayed S3 method registration in its NAMESPACE file [1] in addition to
registering a method for BaseSet::tidy, but I think that you're now
expected to importFrom(generics, tidy) and export(tidy) to register S3
methods on it. It's unfortunate that generics::tidy has a different
documented purpose. Perhaps the people better-versed in Bioconductor
have a better suggestion?

Not sure where S4 method dispatch comes into play in your example, but
conditional import of S4 classes may be hard to implement. NAMESPACE
files use R syntax but different semantics. Testing for getRversion()
works because that doesn't usually change for the lifetime of the
package library. Testing for requireNamespace() wouldn't have worked
because the results are normally cached at installation time. Maybe
there's a way using load hooks, but we'd need an S4 wizard to implement
that correctly. Thankfully, 'BaseSet' seems to only call setMethod()
for its own classes, so there are no copies of foreign classes creating
binary dependencies in its namespace.

-- 
Best regards,
Ivan

[1]
https://cran.r-project.org/doc/manuals/R-exts.html#Registering-S3-methods


From ||u|@@rev|||@ @end|ng |rom gm@||@com  Sun Feb  9 12:03:43 2025
From: ||u|@@rev|||@ @end|ng |rom gm@||@com (=?UTF-8?Q?Llu=C3=ADs_Revilla?=)
Date: Sun, 9 Feb 2025 12:03:43 +0100
Subject: [R-pkg-devel] Registering methods conditionally
In-Reply-To: <20250208230726.67d344b3@Tarkus>
References: <CAN+W6_s7j-mwDfYG=-gorpdNMGuMz8dWpgk5LhiiqPAysyOq9A@mail.gmail.com>
 <20250208230726.67d344b3@Tarkus>
Message-ID: <CAN+W6_saySgDW7vaexx1Uqof1ueZuTmzNFRHNez95zj4rCZhow@mail.gmail.com>

Hi Ivan,

Thanks for the careful investigation. I didn't notice that tidy was masked!

I expected that a delayed registration could prevent the error. But I think
I made a bad decision when I defined tidy and I will probably change the
method name.

But I'll talk with Bioconductor people, for advice to see what can be done.
I don't think when BiocGenerics depended on generics they accounted for
this kind of breakage or informed their reverse dependencies.

Many thanks for your help.

On Sat, 8 Feb 2025 at 21:07, Ivan Krylov <ikrylov at disroot.org> wrote:

> ? Sat, 8 Feb 2025 19:18:59 +0100
> Llu?s Revilla <lluis.revilla at gmail.com> ?????:
>
> > Error in UseMethod("tidy") : no applicable method for 'tidy' applied
> > to an object of class "GeneSet"
>
> This seems to be a distant consequence of
> <https://github.com/Bioconductor/BiocGenerics/issues/20>.
>
> The example for BaseSet::tidy starts with
>
> >> if (requireNamespace("GSEABase", quietly = TRUE)) {
>
> which produces the following messages:
>
> Loading required package: BiocGenerics
> Loading required package: generics
> Attaching package: ?generics?
> The following objects are masked from ?package:BaseSet?:
>    tidy, union                    # <-- BaseSet::tidy now shadowed
>
> Indeed, at the point of the error, 'tidy' is
>
> Browse[1]> tidy
> function (x, ...)
> {
>     UseMethod("tidy")
> }
> <bytecode: 0x5615feed95c0>
> <environment: namespace:generics>
>
> ...which is different from your own 'tidy' generic:
>
> Browse[1]> BaseSet::tidy
> function (object)
> {
>     UseMethod("tidy")
> }
> <bytecode: 0x5615eed320c8>
> <environment: namespace:BaseSet>
>
> ...and the method is registered for the BaseSet::tidy generic, not the
> generics::tidy generic:
>
> Browse[1]> 'tidy.GeneSet' %in% ls(BaseSet:::.__S3MethodsTable__.)
> [1] TRUE
> Browse[1]> 'tidy.GeneSet' %in% ls(generics:::.__S3MethodsTable__.)
> [1] FALSE
>
> The problem only appears on R-devel because only the development
> version of 'BiocGenerics' has the Depends: relationship with 'generics'.
>
> This one is easier to diagnose than to cure. The example seems to work
> fine if the methods are registered for the other generic at runtime:
>
> library(BaseSet)
> # these are undocumented, use .S3method() in more normal circumstances
> registerS3method("tidy", "GeneSet", BaseSet:::tidy.GeneSet,
>                  loadNamespace("generics"))
> registerS3method("tidy", "GeneSetCollection",
>                  BaseSet:::tidy.GeneSetCollection,
>                  loadNamespace("generics"))
> example("tidy") # doesn't crash
>
> Since BaseSet depends on a new enough R version, it could in theory use
> delayed S3 method registration in its NAMESPACE file [1] in addition to
> registering a method for BaseSet::tidy, but I think that you're now
> expected to importFrom(generics, tidy) and export(tidy) to register S3
> methods on it. It's unfortunate that generics::tidy has a different
> documented purpose. Perhaps the people better-versed in Bioconductor
> have a better suggestion?
>
> Not sure where S4 method dispatch comes into play in your example, but
> conditional import of S4 classes may be hard to implement. NAMESPACE
> files use R syntax but different semantics. Testing for getRversion()
> works because that doesn't usually change for the lifetime of the
> package library. Testing for requireNamespace() wouldn't have worked
> because the results are normally cached at installation time. Maybe
> there's a way using load hooks, but we'd need an S4 wizard to implement
> that correctly. Thankfully, 'BaseSet' seems to only call setMethod()
> for its own classes, so there are no copies of foreign classes creating
> binary dependencies in its namespace.
>
> --
> Best regards,
> Ivan
>
> [1]
> https://cran.r-project.org/doc/manuals/R-exts.html#Registering-S3-methods
>

	[[alternative HTML version deleted]]


From Bernd@Gruber @end|ng |rom c@nberr@@edu@@u  Mon Feb 10 22:55:07 2025
From: Bernd@Gruber @end|ng |rom c@nberr@@edu@@u (Bernd.Gruber)
Date: Mon, 10 Feb 2025 21:55:07 +0000
Subject: [R-pkg-devel] how to notify users of obsolete and new package
Message-ID: <ME3PR01MB7944C5F281053D6D917BCBF2D4F22@ME3PR01MB7944.ausprd01.prod.outlook.com>

Hi,

I have a quick question. I have an older package (dartR) that is now superseded by a series of new packages.

Still we noticed that several users have not updated yet and moved to the new package. Hence the question:

Is it okay to submit a "shell" package under the name of the old package that does nothing else than telling the user to install the new package (and a link/code how to do that)?

There would only be one function which is updating some legacy data to a new format.

Is that accepted or is there another way to let user know (e.g. via the CRAN package pages)?

Thanks and regards, Bernd


==============================================================================
Dr Bernd Gruber       Tel: (02) 6206 3804 Fax: (02) 6201 2328
Professor
Institute for Applied Ecology
Faculty of Applied Science
University of Canberra   ACT 2601 AUSTRALIA
Email: bernd.gruber at canberra.edu.au<mailto:bernd.gruber at canberra.edu.au>
WWW: http://www.canberra.edu.au/faculties/science/staff/profiles/dr-bernd-gruber

Australian Government Higher Education Provider Number CRICOS:#00212K

NOTICE & DISCLAIMER: This email and any files transmitted with it may contain
confidential or copyright material and are for the attention of the addressee
only. If you have received this email in error please notify us by email
reply and delete it from your system. The University of Canberra accepts
no liability for any damage caused by any virus transmitted by this email.

==============================================================================

[UC Logo]<http://www.canberra.edu.au>

[Adobe Creative Campus. Fuel your ceativity, Adobe Express free for all UC Students and Staff.]<https://www.canberra.edu.au/on-campus/adobe-creative-campus/>



The Ngunnawal people are the Traditional Custodians of the ACT where UC's Bruce Campus is situated and are an integral and celebrated part of UC's culture. We also acknowledge other First Nations Peoples.

Australian Government Higher Education Registered Provider (CRICOS) #00212K. TEQSA Provider ID: PRV12003 (Australian University)
Email Disclaimer<https://www.canberra.edu.au/about-uc/disclaimer-copyright-privacy-accessibility>

[UC Facebook]<https://www.facebook.com/UniversityOfCanberra>  [UC Instagram] <https://www.instagram.com/unicanberra/>     [UC Linkedin] <https://au.linkedin.com/school/university-of-canberra/>     [UC Youtube] <https://www.youtube.com/user/uniofcanberra>  [University of Canberra] <http://www.canberra.edu.au>

	[[alternative HTML version deleted]]


From kev|n@r@coombe@ @end|ng |rom gm@||@com  Tue Feb 11 05:15:41 2025
From: kev|n@r@coombe@ @end|ng |rom gm@||@com (Kevin Coombes)
Date: Mon, 10 Feb 2025 23:15:41 -0500
Subject: [R-pkg-devel] how to notify users of obsolete and new package
In-Reply-To: <ME3PR01MB7944C5F281053D6D917BCBF2D4F22@ME3PR01MB7944.ausprd01.prod.outlook.com>
References: <ME3PR01MB7944C5F281053D6D917BCBF2D4F22@ME3PR01MB7944.ausprd01.prod.outlook.com>
Message-ID: <CAHJ+2V+UOtGFnVz4CZ2JF_wPJcN3WQXq5Mz=Ouks2a9hnVbNSQ@mail.gmail.com>

Does the old package give incorrect results? Or does it just give slower
results? What makes the new one better?

Unless the old one is actually wrong, as a user, I would be unhappy with it
being replaced by a shell. I have this obsession with reproducibility. So,
if you force me to change to the new package, I have to go through a lot of
work and perform many tests to make sure my old calculations are still
correct in the new context. And I have to hunt down every place I used the
package to make the changes.

Why not just create a package startup message for the old package that
tells users why you think your new package is better? It should then be up
to them to decide if and when they make a change.

But what do I know? I still use emacs as my default editor. It took me
decades to switch from plain TeX to LaTeX. I still manage photos with an
archived version of Google's Picasa, since I don't have any reason to store
all my personal photos in the cloud (but I do use an automated cloud
backup). And I still use a music composition program that was written for
Windows 95, by running it in a Windows XP virtual machine on my Windows 11
laptop. And I get (mildly) annoyed every time R Core makes a change that
causes the test scripts in one of the R packages I maintain to give
different answers than they have been giving for years.

Best,
   Kevin

On Mon, Feb 10, 2025, 4:55?PM Bernd.Gruber <Bernd.Gruber at canberra.edu.au>
wrote:

> Hi,
>
> I have a quick question. I have an older package (dartR) that is now
> superseded by a series of new packages.
>
> Still we noticed that several users have not updated yet and moved to the
> new package. Hence the question:
>
> Is it okay to submit a "shell" package under the name of the old package
> that does nothing else than telling the user to install the new package
> (and a link/code how to do that)?
>
> There would only be one function which is updating some legacy data to a
> new format.
>
> Is that accepted or is there another way to let user know (e.g. via the
> CRAN package pages)?
>
> Thanks and regards, Bernd
>
>
>
> ==============================================================================
> Dr Bernd Gruber       Tel: (02) 6206 3804 Fax: (02) 6201 2328
> Professor
> Institute for Applied Ecology
> Faculty of Applied Science
> University of Canberra   ACT 2601 AUSTRALIA
> Email: bernd.gruber at canberra.edu.au<mailto:bernd.gruber at canberra.edu.au>
> WWW:
> http://www.canberra.edu.au/faculties/science/staff/profiles/dr-bernd-gruber
>
> Australian Government Higher Education Provider Number CRICOS:#00212K
>
> NOTICE & DISCLAIMER: This email and any files transmitted with it may
> contain
> confidential or copyright material and are for the attention of the
> addressee
> only. If you have received this email in error please notify us by email
> reply and delete it from your system. The University of Canberra accepts
> no liability for any damage caused by any virus transmitted by this email.
>
>
> ==============================================================================
>
> [UC Logo]<http://www.canberra.edu.au>
>
> [Adobe Creative Campus. Fuel your ceativity, Adobe Express free for all UC
> Students and Staff.]<
> https://www.canberra.edu.au/on-campus/adobe-creative-campus/>
>
>
>
> The Ngunnawal people are the Traditional Custodians of the ACT where UC's
> Bruce Campus is situated and are an integral and celebrated part of UC's
> culture. We also acknowledge other First Nations Peoples.
>
> Australian Government Higher Education Registered Provider (CRICOS)
> #00212K. TEQSA Provider ID: PRV12003 (Australian University)
> Email Disclaimer<
> https://www.canberra.edu.au/about-uc/disclaimer-copyright-privacy-accessibility
> >
>
> [UC Facebook]<https://www.facebook.com/UniversityOfCanberra>  [UC
> Instagram] <https://www.instagram.com/unicanberra/>     [UC Linkedin] <
> https://au.linkedin.com/school/university-of-canberra/>     [UC Youtube] <
> https://www.youtube.com/user/uniofcanberra>  [University of Canberra] <
> http://www.canberra.edu.au>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From ro||turner @end|ng |rom po@teo@net  Tue Feb 11 10:40:29 2025
From: ro||turner @end|ng |rom po@teo@net (Rolf Turner)
Date: Tue, 11 Feb 2025 09:40:29 +0000
Subject: [R-pkg-devel] how to notify users of obsolete and new package
In-Reply-To: <ME3PR01MB7944C5F281053D6D917BCBF2D4F22@ME3PR01MB7944.ausprd01.prod.outlook.com>
References: <ME3PR01MB7944C5F281053D6D917BCBF2D4F22@ME3PR01MB7944.ausprd01.prod.outlook.com>
Message-ID: <20250211224029.5a6d3e2b@new-hp>


On Mon, 10 Feb 2025 21:55:07 +0000
Bernd.Gruber <Bernd.Gruber at canberra.edu.au> wrote:

> Hi,
> 
> I have a quick question. I have an older package (dartR) that is now
> superseded by a series of new packages.
> 
> Still we noticed that several users have not updated yet and moved to
> the new package. Hence the question:
> 
> Is it okay to submit a "shell" package under the name of the old
> package that does nothing else than telling the user to install the
> new package (and a link/code how to do that)?
> 
> There would only be one function which is updating some legacy data
> to a new format.
> 
> Is that accepted or is there another way to let user know (e.g. via
> the CRAN package pages)?
> 
> Thanks and regards, Bernd

I am sympathetic to the points made by Kevin Coombes, who has also
replied to you.  OTOH I am obsessive about redundancy and clutter.  So
I dunno.

Some while back I put a package "hse" (standing for "hope springs
eternal" ??) up on CRAN.  Then later I wrote a paper about the ideas
implemented in hse.  A referee objected to the name, so I changed the
name to "dbd" ("discretised beta distribution").  But I left a skeleton
of hse on CRAN.  It just consists of the .onAttach() function.  If you
install and load hse you just get the message:

     This package, "hse" is now deprecated.   Users 
     should install and use its successor "dbd".

So far no-one has yelled at me ....  But maybe no-one ever used hse.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619


From greg @end|ng |rom ||rm@n@y@h@com  Tue Feb 11 12:09:57 2025
From: greg @end|ng |rom ||rm@n@y@h@com (Greg Hunt)
Date: Tue, 11 Feb 2025 22:09:57 +1100
Subject: [R-pkg-devel] how to notify users of obsolete and new package
In-Reply-To: <ME3PR01MB7944C5F281053D6D917BCBF2D4F22@ME3PR01MB7944.ausprd01.prod.outlook.com>
References: <ME3PR01MB7944C5F281053D6D917BCBF2D4F22@ME3PR01MB7944.ausprd01.prod.outlook.com>
Message-ID: <CAAS8PAKYke0x8Y96+qOiuOxNWDqVON1aQmscGUOoeD0ymsBohA@mail.gmail.com>

If as your install page says, there are only trivial differences in the
code that uses the old and new packages, why force people to reinstall by
disabling their code with what you term a shell?  Surely a package startup
message would be enough, and better than disabling your users' previously
(hopefully) working code.  Having a package suddenly stop working is fairly
annoying and happens all the time through the usual entropy in complex open
source systems, having that failure created deliberately is just adding to
the annoyance and is likely to impose time costs on users at moments that
they did not choose.   I have had this happen a number of times:  some
small project that I've left for a few weeks and returned to expecting to
take a few minutes to do some trivial update and re-generate a graph or a
notebook and discovered that due to a rash update of some kind (R, Python
or OS packages) that I have to spend time I don't have bringing the pieces
up to date.  Big, long-lived things, sure, they get their environment
frozen, but the transient or ad-hoc pieces of work eat time with this type
of problem.  If it can be avoided, it should be.

The dartR GitHub page (https://green-striped-gecko.github.io/dartR/) and at
https://github.com/green-striped-gecko/dartR/ does not mention that the
package has been superseded, you have to read the install page, which is
surprising given this email thread.  One additional way of letting people
know about the new version would be to put it on the github page and in the
readme.

It looks like the dartR package has been removed from CRAN due to
uncorrected errors in the code.

Greg

On Tue, 11 Feb 2025 at 08:55, Bernd.Gruber <Bernd.Gruber at canberra.edu.au>
wrote:

> Hi,
>
> I have a quick question. I have an older package (dartR) that is now
> superseded by a series of new packages.
>
> Still we noticed that several users have not updated yet and moved to the
> new package. Hence the question:
>
> Is it okay to submit a "shell" package under the name of the old package
> that does nothing else than telling the user to install the new package
> (and a link/code how to do that)?
>
> There would only be one function which is updating some legacy data to a
> new format.
>
> Is that accepted or is there another way to let user know (e.g. via the
> CRAN package pages)?
>
> Thanks and regards, Bernd
>
>
>
> ==============================================================================
> Dr Bernd Gruber       Tel: (02) 6206 3804 Fax: (02) 6201 2328
> Professor
> Institute for Applied Ecology
> Faculty of Applied Science
> University of Canberra   ACT 2601 AUSTRALIA
> Email: bernd.gruber at canberra.edu.au<mailto:bernd.gruber at canberra.edu.au>
> WWW:
> http://www.canberra.edu.au/faculties/science/staff/profiles/dr-bernd-gruber
>
> Australian Government Higher Education Provider Number CRICOS:#00212K
>
> NOTICE & DISCLAIMER: This email and any files transmitted with it may
> contain
> confidential or copyright material and are for the attention of the
> addressee
> only. If you have received this email in error please notify us by email
> reply and delete it from your system. The University of Canberra accepts
> no liability for any damage caused by any virus transmitted by this email.
>
>
> ==============================================================================
>
> [UC Logo]<http://www.canberra.edu.au>
>
> [Adobe Creative Campus. Fuel your ceativity, Adobe Express free for all UC
> Students and Staff.]<
> https://www.canberra.edu.au/on-campus/adobe-creative-campus/>
>
>
>
> The Ngunnawal people are the Traditional Custodians of the ACT where UC's
> Bruce Campus is situated and are an integral and celebrated part of UC's
> culture. We also acknowledge other First Nations Peoples.
>
> Australian Government Higher Education Registered Provider (CRICOS)
> #00212K. TEQSA Provider ID: PRV12003 (Australian University)
> Email Disclaimer<
> https://www.canberra.edu.au/about-uc/disclaimer-copyright-privacy-accessibility
> >
>
> [UC Facebook]<https://www.facebook.com/UniversityOfCanberra>  [UC
> Instagram] <https://www.instagram.com/unicanberra/>     [UC Linkedin] <
> https://au.linkedin.com/school/university-of-canberra/>     [UC Youtube] <
> https://www.youtube.com/user/uniofcanberra>  [University of Canberra] <
> http://www.canberra.edu.au>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Fri Feb 14 09:47:38 2025
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Fri, 14 Feb 2025 09:47:38 +0100
Subject: [R-pkg-devel] how to notify users of obsolete and new package
In-Reply-To: <20250211224029.5a6d3e2b@new-hp>
References: <ME3PR01MB7944C5F281053D6D917BCBF2D4F22@ME3PR01MB7944.ausprd01.prod.outlook.com>
 <20250211224029.5a6d3e2b@new-hp>
Message-ID: <6cbc2d92-889d-42d1-946b-2c9844d4f03d@statistik.tu-dortmund.de>



On 11.02.2025 10:40, Rolf Turner wrote:
> 
> On Mon, 10 Feb 2025 21:55:07 +0000
> Bernd.Gruber <Bernd.Gruber at canberra.edu.au> wrote:
> 
>> Hi,
>>
>> I have a quick question. I have an older package (dartR) that is now
>> superseded by a series of new packages.
>>
>> Still we noticed that several users have not updated yet and moved to
>> the new package. Hence the question:
>>
>> Is it okay to submit a "shell" package under the name of the old
>> package that does nothing else than telling the user to install the
>> new package (and a link/code how to do that)?
>>
>> There would only be one function which is updating some legacy data
>> to a new format.

You can do that and then let that package be archived after a while.


>>
>> Is that accepted or is there another way to let user know (e.g. via
>> the CRAN package pages)?

Yes, we can archive a package and report on the web page of the package 
that it has been superseded.
Some example:
<https://cran.r-project.org/package=eodhd>


Note that CRAN does not like the idea of retiring a package and 
replacing it by another one. This should only be a very exceptional 
action and CRAN will decide case based.
Ideally a new version of the old package should do.

Best,
Uwe Ligges




>
>> Thanks and regards, Bernd
> 
> I am sympathetic to the points made by Kevin Coombes, who has also
> replied to you.  OTOH I am obsessive about redundancy and clutter.  So
> I dunno.
> 
> Some while back I put a package "hse" (standing for "hope springs
> eternal" ??) up on CRAN.  Then later I wrote a paper about the ideas
> implemented in hse.  A referee objected to the name, so I changed the
> name to "dbd" ("discretised beta distribution").  But I left a skeleton
> of hse on CRAN.  It just consists of the .onAttach() function.  If you
> install and load hse you just get the message:
> 
>       This package, "hse" is now deprecated.   Users
>       should install and use its successor "dbd".
> 
> So far no-one has yelled at me ....  But maybe no-one ever used hse.
> 
> cheers,
> 
> Rolf Turner
> 


From john@c|@rke @end|ng |rom corner@tonenw@com  Fri Feb 14 15:54:39 2025
From: john@c|@rke @end|ng |rom corner@tonenw@com (John Clarke)
Date: Fri, 14 Feb 2025 15:54:39 +0100
Subject: [R-pkg-devel] Retrieving versioned csv datasets for use in an R
 package
Message-ID: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>

Hi folks,

I've looked around for this particular question, but haven't found a good
answer. I have a versioned dataset that includes about 6 csv files that
total about 15MB for each version. The versions get updated every few years
or so and are used to drive the model which was written in C++ but is now
inside an Rcpp wrapper. Apart from the fact that CRAN does not permit large
files, I want to have a better way for users to access particular versions
of the dataset.

Usage idea:
 # The following would hopefully also download default/most recent version
of the csv files from CRAN (if allowed) or Github or some other repository
for academic open source data.
install.packages("MyPackage")
mypackage = new(MyPackage)

Then, if necessary, the user could change the dataset used with something
like:
mypackage.dataset("2.1.0") which would retrieve new csv files if they
haven't already been downloaded and update the data_folder path internally
to point to 2.1.0 directory.

Requirements:
- The dataset is csv (not a R data object) and the Rcpp MyPackage expects
this format
- Would be nice to properly include citations for the data as they will
likely be initially released through a journal publication

What is the best practice for this sort of dataset management for a package
in R? Is it okay to use Github to store and version the data? Or
preferred to use an R package (ignoring the file size limit). Or some other
open source data hosting? I see https://r-universe.dev/ as an option as
well. In any case, what is the proper mechanism for retrieving/caching the
data?

Thanks,

-John

John Clarke | Senior Technical Advisor |
Cornerstone Systems Northwest | john.clarke at cornerstonenw.com

	[[alternative HTML version deleted]]


From r@|@@pere|r@@br @end|ng |rom gm@||@com  Fri Feb 14 16:08:01 2025
From: r@|@@pere|r@@br @end|ng |rom gm@||@com (Rafael H. M. Pereira)
Date: Fri, 14 Feb 2025 12:08:01 -0300
Subject: [R-pkg-devel] Retrieving versioned csv datasets for use in an R
 package
In-Reply-To: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
References: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
Message-ID: <CAA42DG=iDrRshdJfyZSequGGaB=SELJWRYHb-zFoHiooHgWh1w@mail.gmail.com>

Hi John,

There are different alternatives on where to host the data (e.g. OSF, a
proprietary server, Github etc). The solution I've been adopting in most of
my packages is to use a combination of  a  proprietary server and Github.
So the data is first downloaded from our own server and only if our server
is offline, then the download is redirected to Github. This is what I try
to do so our packages do not overload Github. Of course, this creates some
additional work from our side to make sure the files in our server are
always mirrored on github.

A key point to pay attention to when hosting the data on Github is to host
it as an attachment to a *release* . A good way to manage the files and
releases is using the {piggyback} package, by Carl Boettiger et al at
ROpenSci. The documentation of the package is a really great guide on how
to host data on github and it has some really convenient functions to
create releases, upload and download files. Kudos to them !
https://docs.ropensci.org/piggyback/

Best,

Rafael Pereira

On Fri, Feb 14, 2025 at 11:55?AM John Clarke <john.clarke at cornerstonenw.com>
wrote:

> Hi folks,
>
> I've looked around for this particular question, but haven't found a good
> answer. I have a versioned dataset that includes about 6 csv files that
> total about 15MB for each version. The versions get updated every few years
> or so and are used to drive the model which was written in C++ but is now
> inside an Rcpp wrapper. Apart from the fact that CRAN does not permit large
> files, I want to have a better way for users to access particular versions
> of the dataset.
>
> Usage idea:
>  # The following would hopefully also download default/most recent version
> of the csv files from CRAN (if allowed) or Github or some other repository
> for academic open source data.
> install.packages("MyPackage")
> mypackage = new(MyPackage)
>
> Then, if necessary, the user could change the dataset used with something
> like:
> mypackage.dataset("2.1.0") which would retrieve new csv files if they
> haven't already been downloaded and update the data_folder path internally
> to point to 2.1.0 directory.
>
> Requirements:
> - The dataset is csv (not a R data object) and the Rcpp MyPackage expects
> this format
> - Would be nice to properly include citations for the data as they will
> likely be initially released through a journal publication
>
> What is the best practice for this sort of dataset management for a package
> in R? Is it okay to use Github to store and version the data? Or
> preferred to use an R package (ignoring the file size limit). Or some other
> open source data hosting? I see https://r-universe.dev/ as an option as
> well. In any case, what is the proper mechanism for retrieving/caching the
> data?
>
> Thanks,
>
> -John
>
> John Clarke | Senior Technical Advisor |
> Cornerstone Systems Northwest | john.clarke at cornerstonenw.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From john@c|@rke @end|ng |rom corner@tonenw@com  Fri Feb 14 16:28:19 2025
From: john@c|@rke @end|ng |rom corner@tonenw@com (John Clarke)
Date: Fri, 14 Feb 2025 16:28:19 +0100
Subject: [R-pkg-devel] Retrieving versioned csv datasets for use in an R
 package
In-Reply-To: <CAA42DG=iDrRshdJfyZSequGGaB=SELJWRYHb-zFoHiooHgWh1w@mail.gmail.com>
References: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
 <CAA42DG=iDrRshdJfyZSequGGaB=SELJWRYHb-zFoHiooHgWh1w@mail.gmail.com>
Message-ID: <CAF0e1n9LdbaPYfLFRAHmzQySanKOopGqDqUwnjzit-f=dSYxrw@mail.gmail.com>

Thanks so much Rafael, I think piggyback is exactly what I was looking for.
I wonder if it is possible/best practice to include a call to it during the
install.packages('MyPackage') process so that the data is available prior
to running tests in the R CMD build Github Action (and also for users to
have the default/most recent dataset) downloaded alongside the package.
-John

On Fri, Feb 14, 2025 at 4:08?PM Rafael H. M. Pereira <
rafa.pereira.br at gmail.com> wrote:

> Hi John,
>
> There are different alternatives on where to host the data (e.g. OSF, a
> proprietary server, Github etc). The solution I've been adopting in most of
> my packages is to use a combination of  a  proprietary server and Github.
> So the data is first downloaded from our own server and only if our server
> is offline, then the download is redirected to Github. This is what I try
> to do so our packages do not overload Github. Of course, this creates some
> additional work from our side to make sure the files in our server are
> always mirrored on github.
>
> A key point to pay attention to when hosting the data on Github is to host
> it as an attachment to a *release* . A good way to manage the files and
> releases is using the {piggyback} package, by Carl Boettiger et al at
> ROpenSci. The documentation of the package is a really great guide on how
> to host data on github and it has some really convenient functions to
> create releases, upload and download files. Kudos to them !
> https://docs.ropensci.org/piggyback/
>
> Best,
>
> Rafael Pereira
>
> On Fri, Feb 14, 2025 at 11:55?AM John Clarke <
> john.clarke at cornerstonenw.com> wrote:
>
>> Hi folks,
>>
>> I've looked around for this particular question, but haven't found a good
>> answer. I have a versioned dataset that includes about 6 csv files that
>> total about 15MB for each version. The versions get updated every few
>> years
>> or so and are used to drive the model which was written in C++ but is now
>> inside an Rcpp wrapper. Apart from the fact that CRAN does not permit
>> large
>> files, I want to have a better way for users to access particular versions
>> of the dataset.
>>
>> Usage idea:
>>  # The following would hopefully also download default/most recent version
>> of the csv files from CRAN (if allowed) or Github or some other repository
>> for academic open source data.
>> install.packages("MyPackage")
>> mypackage = new(MyPackage)
>>
>> Then, if necessary, the user could change the dataset used with something
>> like:
>> mypackage.dataset("2.1.0") which would retrieve new csv files if they
>> haven't already been downloaded and update the data_folder path internally
>> to point to 2.1.0 directory.
>>
>> Requirements:
>> - The dataset is csv (not a R data object) and the Rcpp MyPackage expects
>> this format
>> - Would be nice to properly include citations for the data as they will
>> likely be initially released through a journal publication
>>
>> What is the best practice for this sort of dataset management for a
>> package
>> in R? Is it okay to use Github to store and version the data? Or
>> preferred to use an R package (ignoring the file size limit). Or some
>> other
>> open source data hosting? I see https://r-universe.dev/ as an option as
>> well. In any case, what is the proper mechanism for retrieving/caching the
>> data?
>>
>> Thanks,
>>
>> -John
>>
>> John Clarke | Senior Technical Advisor |
>> Cornerstone Systems Northwest | john.clarke at cornerstonenw.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-package-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>>
>

	[[alternative HTML version deleted]]


From rhe|p @end|ng |rom eoo@@dd@@n|  Fri Feb 14 17:10:58 2025
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Fri, 14 Feb 2025 17:10:58 +0100
Subject: [R-pkg-devel] Retrieving versioned csv datasets for use in an R
 package
In-Reply-To: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
References: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
Message-ID: <2eefc627-448c-4b55-846a-0dde80a50907@eoos.dds.nl>


Not an answer, but a request from someone often working behind firewalls 
and/or machines not connected to the internet. Please have a way to have 
the package search for the data at some user specified location such as 
a local directory.

Best,

Jan



On 14-02-2025 15:54, John Clarke wrote:
> Hi folks,
> 
> I've looked around for this particular question, but haven't found a good
> answer. I have a versioned dataset that includes about 6 csv files that
> total about 15MB for each version. The versions get updated every few years
> or so and are used to drive the model which was written in C++ but is now
> inside an Rcpp wrapper. Apart from the fact that CRAN does not permit large
> files, I want to have a better way for users to access particular versions
> of the dataset.
> 
> Usage idea:
>   # The following would hopefully also download default/most recent version
> of the csv files from CRAN (if allowed) or Github or some other repository
> for academic open source data.
> install.packages("MyPackage")
> mypackage = new(MyPackage)
> 
> Then, if necessary, the user could change the dataset used with something
> like:
> mypackage.dataset("2.1.0") which would retrieve new csv files if they
> haven't already been downloaded and update the data_folder path internally
> to point to 2.1.0 directory.
> 
> Requirements:
> - The dataset is csv (not a R data object) and the Rcpp MyPackage expects
> this format
> - Would be nice to properly include citations for the data as they will
> likely be initially released through a journal publication
> 
> What is the best practice for this sort of dataset management for a package
> in R? Is it okay to use Github to store and version the data? Or
> preferred to use an R package (ignoring the file size limit). Or some other
> open source data hosting? I see https://r-universe.dev/ as an option as
> well. In any case, what is the proper mechanism for retrieving/caching the
> data?
> 
> Thanks,
> 
> -John
> 
> John Clarke | Senior Technical Advisor |
> Cornerstone Systems Northwest | john.clarke at cornerstonenw.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Feb 14 18:02:23 2025
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 14 Feb 2025 09:02:23 -0800
Subject: [R-pkg-devel] Retrieving versioned csv datasets for use in an R
 package
In-Reply-To: <2eefc627-448c-4b55-846a-0dde80a50907@eoos.dds.nl>
References: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
 <2eefc627-448c-4b55-846a-0dde80a50907@eoos.dds.nl>
Message-ID: <6EB9183F-3FAB-4345-925F-5104ECFA49B5@dcn.davis.ca.us>

Seconded... have the support for obtaining the desired file be completely initiated by the user, and explicitly pass the filename into the functions that use the data. It is also easier to trace which file was used in a past analysis this way... auto config seems convenient, but it is hard to record the inputs used that way. You can make the function(s) that retrieve/cache the data as simple as you like, but please no simpler than specifying the data version somewhere in every script that uses the data.

On February 14, 2025 8:10:58 AM PST, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
>
>Not an answer, but a request from someone often working behind firewalls and/or machines not connected to the internet. Please have a way to have the package search for the data at some user specified location such as a local directory.
>
>Best,
>
>Jan
>
>
>
>On 14-02-2025 15:54, John Clarke wrote:
>> Hi folks,
>> 
>> I've looked around for this particular question, but haven't found a good
>> answer. I have a versioned dataset that includes about 6 csv files that
>> total about 15MB for each version. The versions get updated every few years
>> or so and are used to drive the model which was written in C++ but is now
>> inside an Rcpp wrapper. Apart from the fact that CRAN does not permit large
>> files, I want to have a better way for users to access particular versions
>> of the dataset.
>> 
>> Usage idea:
>>   # The following would hopefully also download default/most recent version
>> of the csv files from CRAN (if allowed) or Github or some other repository
>> for academic open source data.
>> install.packages("MyPackage")
>> mypackage = new(MyPackage)
>> 
>> Then, if necessary, the user could change the dataset used with something
>> like:
>> mypackage.dataset("2.1.0") which would retrieve new csv files if they
>> haven't already been downloaded and update the data_folder path internally
>> to point to 2.1.0 directory.
>> 
>> Requirements:
>> - The dataset is csv (not a R data object) and the Rcpp MyPackage expects
>> this format
>> - Would be nice to properly include citations for the data as they will
>> likely be initially released through a journal publication
>> 
>> What is the best practice for this sort of dataset management for a package
>> in R? Is it okay to use Github to store and version the data? Or
>> preferred to use an R package (ignoring the file size limit). Or some other
>> open source data hosting? I see https://r-universe.dev/ as an option as
>> well. In any case, what is the proper mechanism for retrieving/caching the
>> data?
>> 
>> Thanks,
>> 
>> -John
>> 
>> John Clarke | Senior Technical Advisor |
>> Cornerstone Systems Northwest | john.clarke at cornerstonenw.com
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-package-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>
>______________________________________________
>R-package-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-package-devel

-- 
Sent from my phone. Please excuse my brevity.


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Feb 14 19:58:55 2025
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 14 Feb 2025 19:58:55 +0100
Subject: [R-pkg-devel] Retrieving versioned csv datasets for use in an R
 package
In-Reply-To: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
References: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
Message-ID: <CAJuCY5wpJc=5Np0+igkJ=EBZr_QH1QUnnTN-4UdtTR7wz6FGJQ@mail.gmail.com>

Dear John,

Our workflow for an open and reproducible workflow is to publish the data
via Zenodo. https://zenodo.org/ is maintained by CERN.
- The data is freely available.
- Your data is easy to cite.
- Every version gets its own DOI + one stable DOI that always points to the
most recent version. E.g. https://doi.org/10.5281/zenodo.14179531

The zen4R package makes it easy to upload and download the data from within
R. Our functions assume the data is in a local folder. Only when the data
is missing, we try to download it from Zenodo.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
*Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
*Poststukken die naar dit adres worden gestuurd, worden ingescand en
digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
dossiers volledig digitaal behandelen. Poststukken met de vermelding
?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
bezorgd.*
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 14 feb 2025 om 15:55 schreef John Clarke <
john.clarke at cornerstonenw.com>:

> Hi folks,
>
> I've looked around for this particular question, but haven't found a good
> answer. I have a versioned dataset that includes about 6 csv files that
> total about 15MB for each version. The versions get updated every few years
> or so and are used to drive the model which was written in C++ but is now
> inside an Rcpp wrapper. Apart from the fact that CRAN does not permit large
> files, I want to have a better way for users to access particular versions
> of the dataset.
>
> Usage idea:
>  # The following would hopefully also download default/most recent version
> of the csv files from CRAN (if allowed) or Github or some other repository
> for academic open source data.
> install.packages("MyPackage")
> mypackage = new(MyPackage)
>
> Then, if necessary, the user could change the dataset used with something
> like:
> mypackage.dataset("2.1.0") which would retrieve new csv files if they
> haven't already been downloaded and update the data_folder path internally
> to point to 2.1.0 directory.
>
> Requirements:
> - The dataset is csv (not a R data object) and the Rcpp MyPackage expects
> this format
> - Would be nice to properly include citations for the data as they will
> likely be initially released through a journal publication
>
> What is the best practice for this sort of dataset management for a package
> in R? Is it okay to use Github to store and version the data? Or
> preferred to use an R package (ignoring the file size limit). Or some other
> open source data hosting? I see https://r-universe.dev/ as an option as
> well. In any case, what is the proper mechanism for retrieving/caching the
> data?
>
> Thanks,
>
> -John
>
> John Clarke | Senior Technical Advisor |
> Cornerstone Systems Northwest | john.clarke at cornerstonenw.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From @tephen@@br@m@ @end|ng |rom gm@||@com  Fri Feb 14 04:20:50 2025
From: @tephen@@br@m@ @end|ng |rom gm@||@com (Stephen Abrams)
Date: Thu, 13 Feb 2025 22:20:50 -0500
Subject: [R-pkg-devel] R package submission - too many threads error
Message-ID: <CAE_v-D5aT0Wa8YU-x9QNPoLQJs8X7P3AT3SL=4ecDNTrHCHcRA@mail.gmail.com>

Hi - my submission was rejected with the following error in one of my
vignettes.

On Debian GNU/Linux trixie/sid:

Error: processing vignette 'modeling_with_binary_classifiers.Rmd'
failed with diagnostics:
24 simultaneous processes spawned

On Windows:

Error: processing vignette 'modeling_with_binary_classifiers.Rmd'
failed with diagnostics:
72 simultaneous processes spawned

I encountered a similar error while using R CMD check --as-cran on my local
(windows) machine and solved it by using a suggestion from this thread:
https://stackoverflow.com/questions/50571325/r-cran-check-fail-when-using-parallel-functions

Specifically, checking for Sys.getenv("_R_CHECK_LIMIT_CORES_", "") and
forcibly bypassing the parallel processing capability in the package. Is
there a better way to do this? Should I just skip the vignette altogether
and try to resolve this after the package is accepted?

For a little more detail, the package (called spect) uses the caret package
under the hood and takes advantage of parallel processing if the user
specifies it. The package is located at the github repo below. The bypass
occurs at line 378 of spect.R:
https://github.com/dawdawdo/spect

A secondary worry is that even if I resolve this, there might be something
else causing threads to spin up. How can I test for that when the error
doesn't trigger when I run R CMD check? I don't want to waste shared
resources if I can check it myself first.

Any help would be greatly appreciated. Thanks!


-- 
Stephen Abrams
Divergent Blue <http://www.divergentblue.com/>

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Fri Feb 14 21:48:29 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Fri, 14 Feb 2025 23:48:29 +0300
Subject: [R-pkg-devel] R package submission - too many threads error
In-Reply-To: <CAE_v-D5aT0Wa8YU-x9QNPoLQJs8X7P3AT3SL=4ecDNTrHCHcRA@mail.gmail.com>
References: <CAE_v-D5aT0Wa8YU-x9QNPoLQJs8X7P3AT3SL=4ecDNTrHCHcRA@mail.gmail.com>
Message-ID: <20250214234829.3596ff57@Tarkus>

Dear Stephen Abrams,

Welcome to R-package-devel!

? Thu, 13 Feb 2025 22:20:50 -0500
Stephen Abrams <stephen.abrams at gmail.com> ?????:

> A secondary worry is that even if I resolve this, there might be
> something else causing threads to spin up.

Instead of using detectCores() [*] and creating cluster objects
yourself, how about letting the user provide a cluster object for you
as a function argument? Yes, it takes slightly more typing for the user,
but on the other hand it lets the user:

 - choose the number of cores for themselves (currently the code seems
   to be ignoring the 'cores' argument)
 - distribute the computation over the network by connecting to the
   machines they know about
 - provide a completely custom, non-PSOCK cluster object that
   'parallel' will nevertheless will work with

Since you're already using doParallel, maybe the right choice is to let
the user call registerDoParallel()?

Determining the right amount of parallelism in your code is a
surprisingly hard problem. Especially on shared computers, a program
naively deciding to use all (or 3/4 of all, or 1/2 of all) processors
may end up working much worse than a purely sequential one [**].

While rendering the vignette in a CRAN package, create a two-process
cluster or set use_parallel = FALSE: CRAN needs the rest of the
processors to check other packages in parallel with yours [***].

Good luck!

-- 
Best regards,
Ivan

[*]
https://github.com/dawdawdo/spect/blob/d48b002332f1a1c2d302afb28e08e7998f416200/R/spect.R#L388

[**]
https://mastodon.social/@henrikbengtsson/113835651303559942

[***]
http://contributor.r-project.org/cran-cookbook/code_issues.html#using-more-than-2-cores


From @tephen@@br@m@ @end|ng |rom gm@||@com  Sat Feb 15 01:37:56 2025
From: @tephen@@br@m@ @end|ng |rom gm@||@com (Stephen Abrams)
Date: Fri, 14 Feb 2025 19:37:56 -0500
Subject: [R-pkg-devel] R package submission - too many threads error
In-Reply-To: <20250214234829.3596ff57@Tarkus>
References: <CAE_v-D5aT0Wa8YU-x9QNPoLQJs8X7P3AT3SL=4ecDNTrHCHcRA@mail.gmail.com>
 <20250214234829.3596ff57@Tarkus>
Message-ID: <CAE_v-D5W2WxNPpnkMtwPwmajxjEczuGRi=2=ZF+J_+YV-CKcaw@mail.gmail.com>

I appreciate the welcome! Also - I believe that replying to an email is the
way to respond here, but please let me know if that's not the case.

In any event - passing in a cluster context is an interesting idea. I will
think about that. Also, it seems that despite me telling myself to write
bug-free code, you have correctly identified that I don't actually make use
of the passed cores parameter - oops! This is where it would have really
helped me to have a peer reviewer. Thanks!

On Fri, Feb 14, 2025 at 3:48?PM Ivan Krylov <ikrylov at disroot.org> wrote:

> Dear Stephen Abrams,
>
> Welcome to R-package-devel!
>
> ? Thu, 13 Feb 2025 22:20:50 -0500
> Stephen Abrams <stephen.abrams at gmail.com> ?????:
>
> > A secondary worry is that even if I resolve this, there might be
> > something else causing threads to spin up.
>
> Instead of using detectCores() [*] and creating cluster objects
> yourself, how about letting the user provide a cluster object for you
> as a function argument? Yes, it takes slightly more typing for the user,
> but on the other hand it lets the user:
>
>  - choose the number of cores for themselves (currently the code seems
>    to be ignoring the 'cores' argument)
>  - distribute the computation over the network by connecting to the
>    machines they know about
>  - provide a completely custom, non-PSOCK cluster object that
>    'parallel' will nevertheless will work with
>
> Since you're already using doParallel, maybe the right choice is to let
> the user call registerDoParallel()?
>
> Determining the right amount of parallelism in your code is a
> surprisingly hard problem. Especially on shared computers, a program
> naively deciding to use all (or 3/4 of all, or 1/2 of all) processors
> may end up working much worse than a purely sequential one [**].
>
> While rendering the vignette in a CRAN package, create a two-process
> cluster or set use_parallel = FALSE: CRAN needs the rest of the
> processors to check other packages in parallel with yours [***].
>
> Good luck!
>
> --
> Best regards,
> Ivan
>
> [*]
>
> https://github.com/dawdawdo/spect/blob/d48b002332f1a1c2d302afb28e08e7998f416200/R/spect.R#L388
>
> [**]
> https://mastodon.social/@henrikbengtsson/113835651303559942
>
> [***]
>
> http://contributor.r-project.org/cran-cookbook/code_issues.html#using-more-than-2-cores
>


-- 
Stephen Abrams
Divergent Blue <http://www.divergentblue.com/>

	[[alternative HTML version deleted]]


From @|mon@urb@nek @end|ng |rom R-project@org  Sat Feb 15 07:50:28 2025
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Sat, 15 Feb 2025 19:50:28 +1300
Subject: [R-pkg-devel] Retrieving versioned csv datasets for use in an R
 package
In-Reply-To: <CAJuCY5wpJc=5Np0+igkJ=EBZr_QH1QUnnTN-4UdtTR7wz6FGJQ@mail.gmail.com>
References: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
 <CAJuCY5wpJc=5Np0+igkJ=EBZr_QH1QUnnTN-4UdtTR7wz6FGJQ@mail.gmail.com>
Message-ID: <C45E0F9A-F6B4-4E24-9BA4-D9D5E6E0A343@R-project.org>

I would like to second the Zenodo recommendation. Github is not reliable enough for reproducible research (your files can disappear at any point - or can change without notice), that's why Zenodo was created. It assumes that your package has the list of DOIs to offer, but that should be ideally the case, because you don't want to change the data after your package was published -- again, for reproducibility's sake.

Cheers,
Simon


> On Feb 15, 2025, at 7:58 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear John,
> 
> Our workflow for an open and reproducible workflow is to publish the data
> via Zenodo. https://zenodo.org/ is maintained by CERN.
> - The data is freely available.
> - Your data is easy to cite.
> - Every version gets its own DOI + one stable DOI that always points to the
> most recent version. E.g. https://doi.org/10.5281/zenodo.14179531
> 
> The zen4R package makes it easy to upload and download the data from within
> R. Our functions assume the data is in a local folder. Only when the data
> is missing, we try to download it from Zenodo.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> *Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
> *Poststukken die naar dit adres worden gestuurd, worden ingescand en
> digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
> dossiers volledig digitaal behandelen. Poststukken met de vermelding
> ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
> bezorgd.*
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op vr 14 feb 2025 om 15:55 schreef John Clarke <
> john.clarke at cornerstonenw.com>:
> 
>> Hi folks,
>> 
>> I've looked around for this particular question, but haven't found a good
>> answer. I have a versioned dataset that includes about 6 csv files that
>> total about 15MB for each version. The versions get updated every few years
>> or so and are used to drive the model which was written in C++ but is now
>> inside an Rcpp wrapper. Apart from the fact that CRAN does not permit large
>> files, I want to have a better way for users to access particular versions
>> of the dataset.
>> 
>> Usage idea:
>> # The following would hopefully also download default/most recent version
>> of the csv files from CRAN (if allowed) or Github or some other repository
>> for academic open source data.
>> install.packages("MyPackage")
>> mypackage = new(MyPackage)
>> 
>> Then, if necessary, the user could change the dataset used with something
>> like:
>> mypackage.dataset("2.1.0") which would retrieve new csv files if they
>> haven't already been downloaded and update the data_folder path internally
>> to point to 2.1.0 directory.
>> 
>> Requirements:
>> - The dataset is csv (not a R data object) and the Rcpp MyPackage expects
>> this format
>> - Would be nice to properly include citations for the data as they will
>> likely be initially released through a journal publication
>> 
>> What is the best practice for this sort of dataset management for a package
>> in R? Is it okay to use Github to store and version the data? Or
>> preferred to use an R package (ignoring the file size limit). Or some other
>> open source data hosting? I see https://r-universe.dev/ as an option as
>> well. In any case, what is the proper mechanism for retrieving/caching the
>> data?
>> 
>> Thanks,
>> 
>> -John
>> 
>> John Clarke | Senior Technical Advisor |
>> Cornerstone Systems Northwest | john.clarke at cornerstonenw.com
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-package-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> 


From edd @end|ng |rom deb|@n@org  Sat Feb 15 16:28:48 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Sat, 15 Feb 2025 09:28:48 -0600
Subject: [R-pkg-devel] Retrieving versioned csv datasets for use in an R
 package
In-Reply-To: <C45E0F9A-F6B4-4E24-9BA4-D9D5E6E0A343@R-project.org>
References: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
 <CAJuCY5wpJc=5Np0+igkJ=EBZr_QH1QUnnTN-4UdtTR7wz6FGJQ@mail.gmail.com>
 <C45E0F9A-F6B4-4E24-9BA4-D9D5E6E0A343@R-project.org>
Message-ID: <26544.45744.991423.778990@rob.eddelbuettel.com>


On 15 February 2025 at 19:50, Simon Urbanek wrote:
| Github is not reliable enough for reproducible research (your files can 
| disappear at any point - or can change without notice),

I'm curious: Do you have a concrete example of a no-longer-reproducible study
whose data or other support files changed and thereby caused this breakage?

| that's why Zenodo was created.

But AFAIK Zenodo offers DOI issuance only, not storage (as, say, OSF would).
So this does not address the problem faced by the OP.

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From wo||g@ng@ro|ke @end|ng |rom upr@edu  Sun Feb 16 14:00:55 2025
From: wo||g@ng@ro|ke @end|ng |rom upr@edu (Wolfgang Rolke)
Date: Sun, 16 Feb 2025 13:00:55 +0000
Subject: [R-pkg-devel] GPU programming in R packages
Message-ID: <BN7PR03MB36494D71901B81FD4608130E9BF82@BN7PR03MB3649.namprd03.prod.outlook.com>

Hi, I am currently working on a project that requires calculations on large matrices, for example calculating pairwise distances of points in higher dimensions. This seems to be a natural task for GPU programming, unfortunately I don't have any experience with this. I did some research online and found that a number of R packages such as rput are no longer available on CRAN, so I suppose I shouldn't use those. So my question is, how should I implement a GPU based calculation in a package that will eventually be acceptable for CRAN?

Any hints are appreciated!

Wolfgang

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Feb 17 09:16:22 2025
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 17 Feb 2025 09:16:22 +0100
Subject: [R-pkg-devel] Retrieving versioned csv datasets for use in an R
 package
In-Reply-To: <26544.45744.991423.778990@rob.eddelbuettel.com>
References: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
 <CAJuCY5wpJc=5Np0+igkJ=EBZr_QH1QUnnTN-4UdtTR7wz6FGJQ@mail.gmail.com>
 <C45E0F9A-F6B4-4E24-9BA4-D9D5E6E0A343@R-project.org>
 <26544.45744.991423.778990@rob.eddelbuettel.com>
Message-ID: <CAJuCY5xx=ahS8qh0P1+D_-7muy5nmug62iDZh28JvaHkYedKDg@mail.gmail.com>

Dear Dirk,

Zenodo does offer storage. The default quota are 50GB and 100 files per
record (version). See
https://help.zenodo.org/docs/deposit/manage-files/#prepare

Best regards,

Thierry


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
*Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
*Poststukken die naar dit adres worden gestuurd, worden ingescand en
digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
dossiers volledig digitaal behandelen. Poststukken met de vermelding
?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
bezorgd.*
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op za 15 feb 2025 om 16:28 schreef Dirk Eddelbuettel <edd at debian.org>:

>
> On 15 February 2025 at 19:50, Simon Urbanek wrote:
> | Github is not reliable enough for reproducible research (your files can
> | disappear at any point - or can change without notice),
>
> I'm curious: Do you have a concrete example of a no-longer-reproducible
> study
> whose data or other support files changed and thereby caused this breakage?
>
> | that's why Zenodo was created.
>
> But AFAIK Zenodo offers DOI issuance only, not storage (as, say, OSF
> would).
> So this does not address the problem faced by the OP.
>
> Dirk
>
> --
> dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Mon Feb 17 12:05:32 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 17 Feb 2025 14:05:32 +0300
Subject: [R-pkg-devel] GPU programming in R packages
In-Reply-To: <BN7PR03MB36494D71901B81FD4608130E9BF82@BN7PR03MB3649.namprd03.prod.outlook.com>
References: <BN7PR03MB36494D71901B81FD4608130E9BF82@BN7PR03MB3649.namprd03.prod.outlook.com>
Message-ID: <20250217140532.4d75d701@arachnoid>

? Sun, 16 Feb 2025 13:00:55 +0000
Wolfgang Rolke via R-package-devel <r-package-devel at r-project.org>
?????:

> I am currently working on a project that requires calculations on
> large matrices, for example calculating pairwise distances of points
> in higher dimensions.

How large are the matrices? Are CPU-side calculations (possibly done in
special-purpose parallel code written in C/C++/Fortran/Rust) out of
question? What are your performance goals?

> So my question is, how should I implement a GPU based calculation in
> a package that will eventually be acceptable for CRAN?

How about OpenCL [1]?

Pros:

* The 'OpenCL' package is already on CRAN, making it possible to write
  and run "kernels" straight from R.
* Unlike CUDA, OpenCL is an open standard, relatively portable between
  video card vendors. It is even possible to use a CPU-only
  "installable client driver" that would (probably very slowly) run the
  kernels on the processor when no compatible video card is present.

Cons:

* Additional user setup is required. The OpenCL package will fail to
  load if the OpenCL runtime is not installed; installing it from
  source will also require the OpenCL SDK with headers.
* Your code will also fail to run if OpenCL cannot find a working
  "platform", so any examples and tests will need to check for
  length(oclPlatforms) > 0 [2].

-- 
Best regards,
Ivan

[1]
https://www.khronos.org/opencl/

[2]
https://www.r-project.org/nosvn/R.check/r-release-windows-x86_64/OpenCL-00check.html


From edd @end|ng |rom deb|@n@org  Mon Feb 17 14:23:58 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Mon, 17 Feb 2025 07:23:58 -0600
Subject: [R-pkg-devel] Retrieving versioned csv datasets for use in an R
 package
In-Reply-To: <CAJuCY5xx=ahS8qh0P1+D_-7muy5nmug62iDZh28JvaHkYedKDg@mail.gmail.com>
References: <CAF0e1n-ZzgkqT-zcVUJjaWXpART7QmPe-94b6xiqQMA2pjpv1w@mail.gmail.com>
 <CAJuCY5wpJc=5Np0+igkJ=EBZr_QH1QUnnTN-4UdtTR7wz6FGJQ@mail.gmail.com>
 <C45E0F9A-F6B4-4E24-9BA4-D9D5E6E0A343@R-project.org>
 <26544.45744.991423.778990@rob.eddelbuettel.com>
 <CAJuCY5xx=ahS8qh0P1+D_-7muy5nmug62iDZh28JvaHkYedKDg@mail.gmail.com>
Message-ID: <26547.14446.787206.942022@rob.eddelbuettel.com>


Hi Thierry,

On 17 February 2025 at 09:16, Thierry Onkelinx wrote:
| Zenodo does offer storage. The default quota are 50GB and 100 files per record
| (version). See https://help.zenodo.org/docs/deposit/manage-files/#prepare

So TIL! Thanks for the heads-up and correction.

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From wo||g@ng@ro|ke @end|ng |rom upr@edu  Mon Feb 17 15:55:28 2025
From: wo||g@ng@ro|ke @end|ng |rom upr@edu (Wolfgang Rolke)
Date: Mon, 17 Feb 2025 14:55:28 +0000
Subject: [R-pkg-devel] GPU programming in R packages
In-Reply-To: <20250217140532.4d75d701@arachnoid>
References: <BN7PR03MB36494D71901B81FD4608130E9BF82@BN7PR03MB3649.namprd03.prod.outlook.com>
 <20250217140532.4d75d701@arachnoid>
Message-ID: <BN7PR03MB36490A3502EB3E7D6CF7596E9BFB2@BN7PR03MB3649.namprd03.prod.outlook.com>

Ivan,

I am working on a package that implements several tests for the multivariate twosample problem. Some of them are based on the distance between the points. Now say the two data sets have 1000 observations each in 10 dimensions. Calculating such a test statistic requires roughly 1000*1000*10=10^7 operations. Now some of them don't come with a p value but one needs to use the permutation methods, say another 1000 times, and we are up to 10^10 operations. Finally one might want to do some power study, and so we need another 10*1000, and are at 10^14. And finally I really want to do 20 or 30 such studies. So it is clear we need something very fast.

Currently I have everything implemented in Rcpp and using parallel programing, but even that is not good enough. So I thought doing the calculation of the pairwise distances using GPU might be worth looking into.

Wolfgang

________________________________
From: Ivan Krylov <ikrylov at disroot.org>
Sent: Monday, February 17, 2025 8:05 AM
To: Wolfgang Rolke via R-package-devel <r-package-devel at r-project.org>
Cc: Wolfgang Rolke <wolfgang.rolke at upr.edu>
Subject: Re: [R-pkg-devel] GPU programming in R packages

? Sun, 16 Feb 2025 13:00:55 +0000
Wolfgang Rolke via R-package-devel <r-package-devel at r-project.org>
?????:

> I am currently working on a project that requires calculations on
> large matrices, for example calculating pairwise distances of points
> in higher dimensions.

How large are the matrices? Are CPU-side calculations (possibly done in
special-purpose parallel code written in C/C++/Fortran/Rust) out of
question? What are your performance goals?

> So my question is, how should I implement a GPU based calculation in
> a package that will eventually be acceptable for CRAN?

How about OpenCL [1]?

Pros:

* The 'OpenCL' package is already on CRAN, making it possible to write
  and run "kernels" straight from R.
* Unlike CUDA, OpenCL is an open standard, relatively portable between
  video card vendors. It is even possible to use a CPU-only
  "installable client driver" that would (probably very slowly) run the
  kernels on the processor when no compatible video card is present.

Cons:

* Additional user setup is required. The OpenCL package will fail to
  load if the OpenCL runtime is not installed; installing it from
  source will also require the OpenCL SDK with headers.
* Your code will also fail to run if OpenCL cannot find a working
  "platform", so any examples and tests will need to check for
  length(oclPlatforms) > 0 [2].

--
Best regards,
Ivan

[1]
https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.khronos.org%2Fopencl%2F&data=05%7C02%7Cwolfgang.rolke%40upr.edu%7Cc85446bf85ee4d7d4e1108dd4f43128b%7C0dfa5dc0036f461599e494af822f2b84%7C0%7C0%7C638753871684927834%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=syu4D2bBFWJPzNKSP1mEE8xua1XZg6MsCOQtILhl%2F9M%3D&reserved=0<https://www.khronos.org/opencl/>

[2]
https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.r-project.org%2Fnosvn%2FR.check%2Fr-release-windows-x86_64%2FOpenCL-00check.html&data=05%7C02%7Cwolfgang.rolke%40upr.edu%7Cc85446bf85ee4d7d4e1108dd4f43128b%7C0dfa5dc0036f461599e494af822f2b84%7C0%7C0%7C638753871684946998%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=YuAKmccy%2Flz8%2Bgcwc5P9ZnDXQscIkVwhstPrxS5v3Ro%3D&reserved=0<https://www.r-project.org/nosvn/R.check/r-release-windows-x86_64/OpenCL-00check.html>

	[[alternative HTML version deleted]]


From zh@ngh@u@tc @end|ng |rom gm@||@com  Tue Feb 18 05:28:24 2025
From: zh@ngh@u@tc @end|ng |rom gm@||@com (Han Zhang)
Date: Mon, 17 Feb 2025 23:28:24 -0500
Subject: [R-pkg-devel] How to fix "attribute "id" has invalid value" when
 submitting new package to CRAN
Message-ID: <CAJbGH5G6DDVOK-n-Y3TJPXrx-6MBzL4k1NHvgo9WJz8+i=T+pA@mail.gmail.com>

Hi,

It is my first time to see this NOTE when submitting a new package to CRAN.
It seems to happen on Debian and Windows, but I don't have a machine with
those OS installed. I searched for this note but did not find solutions.
Please advise. Thank you.

 * checking HTML version of manual ... [1s/1s] NOTE Found the following
HTML validation problems: GraphicalTesting.html:114:1
(GraphicalTesting.Rd:170): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-new" GraphicalTesting.html:168:1
(GraphicalTesting.Rd:212): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-reset" GraphicalTesting.html:185:1
(GraphicalTesting.Rd:223): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-is_valid_hid"
GraphicalTesting.html:214:1 (GraphicalTesting.Rd:240): Warning: <a>
attribute "id" has invalid value "method-Graphical Testing
Procedure-get_hypothesis_name" GraphicalTesting.html:243:1
(GraphicalTesting.Rd:257): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-get_weight" GraphicalTesting.html:274:1
(GraphicalTesting.Rd:276): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-set_weight" GraphicalTesting.html:307:1
(GraphicalTesting.Rd:297): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-get_alpha" GraphicalTesting.html:339:1
(GraphicalTesting.Rd:317): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-set_alpha" GraphicalTesting.html:370:1
(GraphicalTesting.Rd:336): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-get_hypotheses_ids"
GraphicalTesting.html:386:1 (GraphicalTesting.Rd:346): Warning: <a>
attribute "id" has invalid value "method-Graphical Testing
Procedure-get_number_hypotheses" GraphicalTesting.html:402:1
(GraphicalTesting.Rd:356): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-get_hids_not_in_graph"
GraphicalTesting.html:418:1 (GraphicalTesting.Rd:366): Warning: <a>
attribute "id" has invalid value "method-Graphical Testing
Procedure-get_testable_hypotheses" GraphicalTesting.html:435:1
(GraphicalTesting.Rd:377): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-has_testable_hypotheses"
GraphicalTesting.html:452:1 (GraphicalTesting.Rd:388): Warning: <a>
attribute "id" has invalid value "method-Graphical Testing
Procedure-is_in_graph" GraphicalTesting.html:481:1
(GraphicalTesting.Rd:405): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-is_testable"
GraphicalTesting.html:510:1 (GraphicalTesting.Rd:422): Warning: <a>
attribute "id" has invalid value "method-Graphical Testing
Procedure-get_hid" GraphicalTesting.html:540:1 (GraphicalTesting.Rd:440):
Warning: <a> attribute "id" has invalid value "method-Graphical Testing
Procedure-reject_a_hypothesis" GraphicalTesting.html:570:1
(GraphicalTesting.Rd:458): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-set_trajectory"
GraphicalTesting.html:599:1 (GraphicalTesting.Rd:475): Warning: <a>
attribute "id" has invalid value "method-Graphical Testing
Procedure-get_trajectory" GraphicalTesting.html:618:1
(GraphicalTesting.Rd:488): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-test_hypotheses"
GraphicalTesting.html:672:1 (GraphicalTesting.Rd:523): Warning: <a>
attribute "id" has invalid value "method-Graphical Testing Procedure-test"
GraphicalTesting.html:751:1 (GraphicalTesting.Rd:578): Warning: <a>
attribute "id" has invalid value "method-Graphical Testing
Procedure-get_current_testing_results" GraphicalTesting.html:790:1
(GraphicalTesting.Rd:602): Warning: <a> attribute "id" has invalid value
"method-Graphical Testing Procedure-get_current_decision"
GraphicalTesting.html:816:1 (GraphicalTesting.Rd:618): Warning: <a>
attribute "id" has invalid value "method-Graphical Testing Procedure-print"
GraphicalTesting.html:854:1 (GraphicalTesting.Rd:644): Warning: <a>
attribute "id" has invalid value "method-Graphical Testing Procedure-clone"
GroupSequentialTest.html:95:1 (GroupSequentialTest.Rd:97): Warning: <a>
attribute "id" has invalid value "method-Group Sequential Test-new"
GroupSequentialTest.html:142:1 (GroupSequentialTest.Rd:132): Warning: <a>
attribute "id" has invalid value "method-Group Sequential Test-get_name"
GroupSequentialTest.html:158:1 (GroupSequentialTest.Rd:142): Warning: <a>
attribute "id" has invalid value "method-Group Sequential Test-get_alpha"
GroupSequentialTest.html:174:1 (GroupSequentialTest.Rd:152): Warning: <a>
attribute "id" has invalid value "method-Group Sequential
Test-set_alpha_spending" GroupSequentialTest.html:204:1
(GroupSequentialTest.Rd:170): Warning: <a> attribute "id" has invalid value
"method-Group Sequential Test-get_alpha_spending"
GroupSequentialTest.html:220:1 (GroupSequentialTest.Rd:180): Warning: <a>
attribute "id" has invalid value "method-Group Sequential
Test-get_max_info" GroupSequentialTest.html:236:1
(GroupSequentialTest.Rd:190): Warning: <a> attribute "id" has invalid value
"method-Group Sequential Test-set_max_info" GroupSequentialTest.html:267:1
(GroupSequentialTest.Rd:209): Warning: <a> attribute "id" has invalid value
"method-Group Sequential Test-get_stage" GroupSequentialTest.html:283:1
(GroupSequentialTest.Rd:219): Warning: <a> attribute "id" has invalid value
"method-Group Sequential Test-reset" GroupSequentialTest.html:305:1
(GroupSequentialTest.Rd:235): Warning: <a> attribute "id" has invalid value
"method-Group Sequential Test-set_trajectory"
GroupSequentialTest.html:337:1 (GroupSequentialTest.Rd:255): Warning: <a>
attribute "id" has invalid value "method-Group Sequential
Test-get_trajectory" GroupSequentialTest.html:354:1
(GroupSequentialTest.Rd:266): Warning: <a> attribute "id" has invalid value
"method-Group Sequential Test-get_stage_level"
GroupSequentialTest.html:371:1 (GroupSequentialTest.Rd:277): Warning: <a>
attribute "id" has invalid value "method-Group Sequential Test-test_one"
GroupSequentialTest.html:421:1 (GroupSequentialTest.Rd:315): Warning: <a>
attribute "id" has invalid value "method-Group Sequential Test-test"
GroupSequentialTest.html:468:1 (GroupSequentialTest.Rd:350): Warning: <a>
attribute "id" has invalid value "method-Group Sequential Test-print"
GroupSequentialTest.html:484:1 (GroupSequentialTest.Rd:360): Warning: <a>
attribute "id" has invalid value "method-Group Sequential Test-clone" *
checking for non-standard things in the check directory ... OK * checking
for detritus in the temp directory ... OK * DONE Status: 2 NOTEs

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Tue Feb 18 11:19:56 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 18 Feb 2025 13:19:56 +0300
Subject: [R-pkg-devel] 
 How to fix "attribute "id" has invalid value" when
 submitting new package to CRAN
In-Reply-To: <CAJbGH5G6DDVOK-n-Y3TJPXrx-6MBzL4k1NHvgo9WJz8+i=T+pA@mail.gmail.com>
References: <CAJbGH5G6DDVOK-n-Y3TJPXrx-6MBzL4k1NHvgo9WJz8+i=T+pA@mail.gmail.com>
Message-ID: <20250218131956.34177ada@arachnoid>

Dear Han Zhang,

Welcome to R-package-devel!

? Mon, 17 Feb 2025 23:28:24 -0500
Han Zhang <zhangh.ustc at gmail.com> ?????:

> Found the following
> HTML validation problems: GraphicalTesting.html:114:1
> (GraphicalTesting.Rd:170): Warning: <a> attribute "id" has invalid
> value "method-Graphical Testing Procedure-new"

Thank you for providing the NOTE you are receiving. It's best to also
provide a link to the source code of your package, because the error
messages alone are frequently not enough to diagnose the problem, and
it's not always easy to find out the code in question from a few
breadcrumbs in the error messages.

In the few cases I've checked, R CMD check points at the lines
containing \if{html}{\out{...}} statements [1]. This seems to be a
problem with 'roxygen2': it did not expect your class name to contain
spaces [2], so it did not replace them in the 'id' attribute while
generating the HTML fragment for the class documentation. You can
rename the class or ask the 'roxygen2' developers to adjust their HTML
generation.

In the future, please compose your messages to this list in plain text.
When you compose them in HTML, we only receive the plain text version
automatically generated by your mailer, which doesn't present the
intended formatting intact [3].

Good luck!

-- 
Best regards,
Ivan

[1]
https://github.com/zhangh12/TrialSimulator/blob/93b6ef034108f4562a7658c33b9c946346ea9d1c/man/GraphicalTesting.Rd#L170

[2]
https://github.com/zhangh12/TrialSimulator/blob/93b6ef034108f4562a7658c33b9c946346ea9d1c/R/GraphicalTesting.R#L139

[3]
https://hypatia.math.ethz.ch/pipermail/r-package-devel/2025q1/011504.html


From edd @end|ng |rom deb|@n@org  Tue Feb 18 14:05:06 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 18 Feb 2025 07:05:06 -0600
Subject: [R-pkg-devel] False positive antivirus reports on package vignettes
Message-ID: <26548.34178.308460.573242@rob.eddelbuettel.com>


Something that had happened to the Rcpp package in the past (but seemingly
went away on its own ?) is now apparently hitting package RcppArmadillo.

I received private email from the CRAN maintainers reporting, without
offering a fix as there seems to be none, that one of the two pdf vignettes
(which I happen to create as a shallow Rnw -> pdf wrapper around a pre-made
pdf, here that inner pdf had not changed in five years, sigh ...)  now upsets
one of these (idiotic, but hey, I am sure that at least they are very
expensive) anti-virus checkers.

Has anybody figured out a workaround?  I see withdrawing the pdf vignette as
(simple but bad) route. Or should I just change the (internal, binary) pdf
payload of the file (hey, one can always update the .bib to newer versions of
the cited packages) and hope for the best?  Any other route?

Help or tips would be appreciated.

Best, Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From |kry|ov @end|ng |rom d|@root@org  Tue Feb 18 14:26:11 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 18 Feb 2025 16:26:11 +0300
Subject: [R-pkg-devel] 
 False positive antivirus reports on package vignettes
In-Reply-To: <26548.34178.308460.573242@rob.eddelbuettel.com>
References: <26548.34178.308460.573242@rob.eddelbuettel.com>
Message-ID: <20250218162611.2050ade4@arachnoid>

On Tue, 18 Feb 2025 07:05:06 -0600
Dirk Eddelbuettel <edd at debian.org> wrote:

> one of the two pdf vignettes (which I happen to create as a shallow
> Rnw -> pdf wrapper around a pre-made pdf, here that inner pdf had not
> changed in five years, sigh ...)  now upsets one of these (idiotic,
> but hey, I am sure that at least they are very expensive) anti-virus
> checkers.

Does VirusTotal confirm the non-zero virus detection?

> Has anybody figured out a workaround?

Last time [*] it turned out to be a collision of a 32-bit checksum in
the virus database. Try re-compressing the vignette or finding a
comment that can be changed. For example, (La)TeX-produced vignettes
sometimes contain a comment that says charToRaw('PTEX') |> as.integer()
|> bitwXor(0x80) |> as.raw(), and these four bytes can be replaced by
four spaces.

-- 
Best regards,
Ivan

[*] https://stat.ethz.ch/pipermail/r-package-devel/2024q1/010411.html


From edd @end|ng |rom deb|@n@org  Tue Feb 18 14:31:59 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 18 Feb 2025 07:31:59 -0600
Subject: [R-pkg-devel] 
 False positive antivirus reports on package vignettes
In-Reply-To: <20250218162611.2050ade4@arachnoid>
References: <26548.34178.308460.573242@rob.eddelbuettel.com>
 <20250218162611.2050ade4@arachnoid>
Message-ID: <26548.35791.607627.371692@rob.eddelbuettel.com>


On 18 February 2025 at 16:26, Ivan Krylov wrote:
| On Tue, 18 Feb 2025 07:05:06 -0600
| Dirk Eddelbuettel <edd at debian.org> wrote:
| 
| > one of the two pdf vignettes (which I happen to create as a shallow
| > Rnw -> pdf wrapper around a pre-made pdf, here that inner pdf had not
| > changed in five years, sigh ...)  now upsets one of these (idiotic,
| > but hey, I am sure that at least they are very expensive) anti-virus
| > checkers.
| 
| Does VirusTotal confirm the non-zero virus detection?

I have no idea. They have not communicated with me. I am only the relevant
author so why whould they. 
 
| > Has anybody figured out a workaround?
| 
| Last time [*] it turned out to be a collision of a 32-bit checksum in
| the virus database. Try re-compressing the vignette or finding a
| comment that can be changed. For example, (La)TeX-produced vignettes
| sometimes contain a comment that says charToRaw('PTEX') |> as.integer()
| |> bitwXor(0x80) |> as.raw(), and these four bytes can be replaced by
| four spaces.

Can you translate that tip into an actionable `sed` (or, of course `Rscript`
or `r`) expression I could add to the Makefile?

I just updated the (outdated, here) bibliography also adding DOI fields so we
have a net gain.  The particular vignette needs a refresh, I will try to
check some content too.

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From |kry|ov @end|ng |rom d|@root@org  Tue Feb 18 15:03:36 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 18 Feb 2025 17:03:36 +0300
Subject: [R-pkg-devel] 
 False positive antivirus reports on package vignettes
In-Reply-To: <26548.35791.607627.371692@rob.eddelbuettel.com>
References: <26548.34178.308460.573242@rob.eddelbuettel.com>
 <20250218162611.2050ade4@arachnoid>
 <26548.35791.607627.371692@rob.eddelbuettel.com>
Message-ID: <20250218170336.0c7e03df@arachnoid>

On Tue, 18 Feb 2025 07:31:59 -0600
Dirk Eddelbuettel <edd at debian.org> wrote:

> I have no idea. They have not communicated with me. I am only the
> relevant author so why whould they. 

That's unfortunate. I've just fed the RcppArmadillo-sparseMatrix
vignette to VirusTotal, and, indeed, there is one match:

https://www.virustotal.com/gui/url/f8d4551cce926dbe1ca4ade853038e9b358a65ce06e448f83825247df0c9f375

> Can you translate that tip into an actionable `sed` (or, of course
> `Rscript` or `r`) expression I could add to the Makefile?

It's probably doable with `sed`, but here's R:

contents <- readBin(pdf_file, raw(), file.size(pdf_file))
# both PDFTeX and QPDF add a 4-byte comment here that can be changed
stopifnot(grepl(
 '^%PDF-1.5\n%[^\n]{4}\n$',
 rawToChar(contents[1:15]),
 useBytes = TRUE
))
# so replace it with spaces
contents[11:14] <- charToRaw('    ')
writeBin(contents, pdf_file)

No matches after the four-byte change:

https://www.virustotal.com/gui/file/e0bf6c55e5d1377c3375b962b24bbaaead4424d0bf5f9bcdaadd47c39b36abe7

Your bytes match what QPDF usually writes when re-compressing a
vignette [*], not PDFTeX's "PTEX" + (not xor) 128. This is also to be
expected.

-- 
Best regards,
Ivan

[*]
https://github.com/qpdf/qpdf/blob/8a1d34bb74e6bae1b57076485386fc56e7c22aaa/libqpdf/QPDFWriter.cc#L2321-L2323


From edd @end|ng |rom deb|@n@org  Tue Feb 18 15:11:15 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 18 Feb 2025 08:11:15 -0600
Subject: [R-pkg-devel] 
 False positive antivirus reports on package vignettes
In-Reply-To: <26548.35791.607627.371692@rob.eddelbuettel.com>
References: <26548.34178.308460.573242@rob.eddelbuettel.com>
 <20250218162611.2050ade4@arachnoid>
 <26548.35791.607627.371692@rob.eddelbuettel.com>
Message-ID: <26548.38147.783242.767388@rob.eddelbuettel.com>


This really is Dadaism (or maybe Absurdism? Where are our art historians?)

By now I heard from one of the affected scientists via a private slack
message. A choice quote:

   basically the pdf is moved into quarantine, and our IT are now threatening
   us to format all our laptops

This is beyond parody.

Anyway, as a first step I changed the (binary) pdf file (by an update of the
underlying .bib file) and r-universe has new builds one can install via

  repos <- c("https://rcppcore.r-universe.dev", getOption("repos"))
  install.packages('RcppArmadillo', repos = repos)

Maybe these do not tickle the silly anti-virsu tool.

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From |uc@r @end|ng |rom |edor@project@org  Tue Feb 18 15:14:10 2025
From: |uc@r @end|ng |rom |edor@project@org (=?UTF-8?Q?I=C3=B1aki_Ucar?=)
Date: Tue, 18 Feb 2025 15:14:10 +0100
Subject: [R-pkg-devel] 
 False positive antivirus reports on package vignettes
In-Reply-To: <26548.34178.308460.573242@rob.eddelbuettel.com>
References: <26548.34178.308460.573242@rob.eddelbuettel.com>
Message-ID: <CALEXWq2id72BAvgYNL-hjSJmyYAucOwVGPqbC95W-Zok3nXjTw@mail.gmail.com>

On Tue, 18 Feb 2025 at 14:05, Dirk Eddelbuettel <edd at debian.org> wrote:
>
>
> Something that had happened to the Rcpp package in the past (but seemingly
> went away on its own ?) is now apparently hitting package RcppArmadillo.
>
> I received private email from the CRAN maintainers reporting, without
> offering a fix as there seems to be none, that one of the two pdf vignettes
> (which I happen to create as a shallow Rnw -> pdf wrapper around a pre-made
> pdf, here that inner pdf had not changed in five years, sigh ...)  now upsets
> one of these (idiotic, but hey, I am sure that at least they are very
> expensive) anti-virus checkers.
>
> Has anybody figured out a workaround?  I see withdrawing the pdf vignette as
> (simple but bad) route. Or should I just change the (internal, binary) pdf
> payload of the file (hey, one can always update the .bib to newer versions of
> the cited packages) and hope for the best?  Any other route?

What happened in Rcpp is that the antivirus were detecting an old
version of ghostscript that could produce potentially vulnerable
outputs. We solved it by rebuilding the vignettes with a newer version
of ghostscript. This is most likely the same issue. I can rebuild them
and send a PR your way if you want.

Best,
I?aki

>
> Help or tips would be appreciated.
>
> Best, Dirk
>
> --
> dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>


-- 
I?aki ?car


From |kry|ov @end|ng |rom d|@root@org  Tue Feb 18 15:19:11 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 18 Feb 2025 17:19:11 +0300
Subject: [R-pkg-devel] 
 False positive antivirus reports on package vignettes
In-Reply-To: <26548.38147.783242.767388@rob.eddelbuettel.com>
References: <26548.34178.308460.573242@rob.eddelbuettel.com>
 <20250218162611.2050ade4@arachnoid>
 <26548.35791.607627.371692@rob.eddelbuettel.com>
 <26548.38147.783242.767388@rob.eddelbuettel.com>
Message-ID: <20250218171911.4172eb8f@arachnoid>

On Tue, 18 Feb 2025 08:11:15 -0600
Dirk Eddelbuettel <edd at debian.org> wrote:

> Maybe these do not tickle the silly anti-virsu tool.

Looks like they don't, so no need to tinker with raw PDF bytes:
https://www.virustotal.com/gui/url/2ef08a12060e046308afd6923b6447be10eafc36416b3af0734f724ce5127f22

(As they shouldn't. If there was still a match, it would be much harder
to explain as a checksum collision.)

-- 
Best regards,
Ivan


From edd @end|ng |rom deb|@n@org  Tue Feb 18 15:34:46 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 18 Feb 2025 08:34:46 -0600
Subject: [R-pkg-devel] 
 False positive antivirus reports on package vignettes
In-Reply-To: <CALEXWq2id72BAvgYNL-hjSJmyYAucOwVGPqbC95W-Zok3nXjTw@mail.gmail.com>
References: <26548.34178.308460.573242@rob.eddelbuettel.com>
 <CALEXWq2id72BAvgYNL-hjSJmyYAucOwVGPqbC95W-Zok3nXjTw@mail.gmail.com>
Message-ID: <26548.39558.519851.420203@rob.eddelbuettel.com>


On 18 February 2025 at 15:14, I?aki Ucar wrote:
| What happened in Rcpp is that the antivirus were detecting an old
| version of ghostscript that could produce potentially vulnerable
| outputs. We solved it by rebuilding the vignettes with a newer version
| of ghostscript. This is most likely the same issue. I can rebuild them
| and send a PR your way if you want.

Bingo. The combination of (re-)using an old pdf (in this case from Feb 2020)
inside a freshly made-from-Rnw pdf is likely at fault, and my simply rebuild
with updated .bib should take care of it.

Ivan, in parallel emails, is on the trail too and reports the file is good
now and I _think_ he refers to the updated pdf one by now gets from the
GitHub repo, or for R user convenience, in the r-universe builds from it. And
hence in the next release (once we work through effects from upstream
changes see [1]).

Excellent assistance from both of you here. Many thanks, as usual.

Cheers, Dirk

[1] https://github.com/RcppCore/RcppArmadillo/issues/462
-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From zh@ngh@u@tc @end|ng |rom gm@||@com  Thu Feb 20 08:41:22 2025
From: zh@ngh@u@tc @end|ng |rom gm@||@com (Han Zhang)
Date: Thu, 20 Feb 2025 02:41:22 -0500
Subject: [R-pkg-devel] 
 How to fix "attribute "id" has invalid value" when
 submitting new package to CRAN
In-Reply-To: <20250218131956.34177ada@arachnoid>
References: <CAJbGH5G6DDVOK-n-Y3TJPXrx-6MBzL4k1NHvgo9WJz8+i=T+pA@mail.gmail.com>
 <20250218131956.34177ada@arachnoid>
Message-ID: <CAJbGH5F-W4dSZpe8nbzHUgVHKrV-sjWBGpb_ApA1JA=Fq-YK-Q@mail.gmail.com>

Hi Ivan,

Thank you for your suggestions. These notes are eliminated after space is
removed from R6 class name!

Best,
Han

On Tue, Feb 18, 2025 at 5:20?AM Ivan Krylov <ikrylov at disroot.org> wrote:

> Dear Han Zhang,
>
> Welcome to R-package-devel!
>
> ? Mon, 17 Feb 2025 23:28:24 -0500
> Han Zhang <zhangh.ustc at gmail.com> ?????:
>
> > Found the following
> > HTML validation problems: GraphicalTesting.html:114:1
> > (GraphicalTesting.Rd:170): Warning: <a> attribute "id" has invalid
> > value "method-Graphical Testing Procedure-new"
>
> Thank you for providing the NOTE you are receiving. It's best to also
> provide a link to the source code of your package, because the error
> messages alone are frequently not enough to diagnose the problem, and
> it's not always easy to find out the code in question from a few
> breadcrumbs in the error messages.
>
> In the few cases I've checked, R CMD check points at the lines
> containing \if{html}{\out{...}} statements [1]. This seems to be a
> problem with 'roxygen2': it did not expect your class name to contain
> spaces [2], so it did not replace them in the 'id' attribute while
> generating the HTML fragment for the class documentation. You can
> rename the class or ask the 'roxygen2' developers to adjust their HTML
> generation.
>
> In the future, please compose your messages to this list in plain text.
> When you compose them in HTML, we only receive the plain text version
> automatically generated by your mailer, which doesn't present the
> intended formatting intact [3].
>
> Good luck!
>
> --
> Best regards,
> Ivan
>
> [1]
>
> https://github.com/zhangh12/TrialSimulator/blob/93b6ef034108f4562a7658c33b9c946346ea9d1c/man/GraphicalTesting.Rd#L170
>
> [2]
>
> https://github.com/zhangh12/TrialSimulator/blob/93b6ef034108f4562a7658c33b9c946346ea9d1c/R/GraphicalTesting.R#L139
>
> [3]
> https://hypatia.math.ethz.ch/pipermail/r-package-devel/2025q1/011504.html
>

	[[alternative HTML version deleted]]


From b|eon@rd @end|ng |rom m|t@edu  Thu Feb 20 18:36:33 2025
From: b|eon@rd @end|ng |rom m|t@edu (Brian Leonard)
Date: Thu, 20 Feb 2025 17:36:33 +0000
Subject: [R-pkg-devel] Package with JS dependency
Message-ID: <PH7PR01MB755965AD0088263041F2346DCDC42@PH7PR01MB7559.prod.exchangelabs.com>

Hello there,

[TLDR: I'm curious to know the degree to which including a pure javascript program (via the V8 package) in an R package affects the potential of passing CRAN review]

I'm working on implementing an R package to support users of the Psych-DS data specification<https://github.com/psych-ds>. The package will include a shiny app with helpful functions for assembling and publishing high-quality datasets in the behavioral sciences, but one of the core functions will be to validate existing datasets (local directories) according to the rules of our schema.

We already have this validator functionality set up as a Deno application, and we can use certain Deno tools, along with esbuild, to generate node-based and pure-javascript bundled versions of validator.

We'd like to be able to leverage our existing code instead of having to reinvent the wheel for the R context. If we try to publish our package to CRAN with this javascript script as a core part of the package's functionality, will that severely affect our chances of passing the review process? I know that having sufficient unit tests and well documented processes is crucial to getting a package through, but the validator code in this scenario would be stringy and minified, and the bundle would not include unit tests for all the validator's internal functions. Is it the case that a dependency like this is equally subject to CRAN review scrutiny, or would it be sufficient to have all the R-based components comply with CRAN requirements?

Thanks,
Brian Leonard
Software Engineer, Psych-DS (MIT)



	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Feb 21 18:01:30 2025
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 21 Feb 2025 12:01:30 -0500
Subject: [R-pkg-devel] Package with JS dependency
In-Reply-To: <PH7PR01MB755965AD0088263041F2346DCDC42@PH7PR01MB7559.prod.exchangelabs.com>
References: <PH7PR01MB755965AD0088263041F2346DCDC42@PH7PR01MB7559.prod.exchangelabs.com>
Message-ID: <d5140e6f-6cd2-4c41-9738-85dd79b3fa04@gmail.com>

On 2025-02-20 12:36 p.m., Brian Leonard wrote:
> Hello there,
> 
> [TLDR: I'm curious to know the degree to which including a pure javascript program (via the V8 package) in an R package affects the potential of passing CRAN review]
> 
> I'm working on implementing an R package to support users of the Psych-DS data specification<https://github.com/psych-ds>. The package will include a shiny app with helpful functions for assembling and publishing high-quality datasets in the behavioral sciences, but one of the core functions will be to validate existing datasets (local directories) according to the rules of our schema.
> 
> We already have this validator functionality set up as a Deno application, and we can use certain Deno tools, along with esbuild, to generate node-based and pure-javascript bundled versions of validator.
> 
> We'd like to be able to leverage our existing code instead of having to reinvent the wheel for the R context. If we try to publish our package to CRAN with this javascript script as a core part of the package's functionality, will that severely affect our chances of passing the review process? I know that having sufficient unit tests and well documented processes is crucial to getting a package through, but the validator code in this scenario would be stringy and minified, and the bundle would not include unit tests for all the validator's internal functions. Is it the case that a dependency like this is equally subject to CRAN review scrutiny, or would it be sufficient to have all the R-based components comply with CRAN requirements?

I am not a member of CRAN, so I can't give you authoritative advice on 
this.  But I think one issue is that if you are only including minified 
code, then they wouldn't see that as the original source.  My rgl 
package includes a few thousand lines of Javascript code which is 
minified when installed; the tarball contains the original source.

Duncan Murdoch


From m|ch@e|ch|r|co4 @end|ng |rom gm@||@com  Fri Feb 21 18:06:20 2025
From: m|ch@e|ch|r|co4 @end|ng |rom gm@||@com (Michael Chirico)
Date: Fri, 21 Feb 2025 09:06:20 -0800
Subject: [R-pkg-devel] Package with JS dependency
In-Reply-To: <d5140e6f-6cd2-4c41-9738-85dd79b3fa04@gmail.com>
References: <PH7PR01MB755965AD0088263041F2346DCDC42@PH7PR01MB7559.prod.exchangelabs.com>
 <d5140e6f-6cd2-4c41-9738-85dd79b3fa04@gmail.com>
Message-ID: <CAPRVBcyB_H++qnUrgh1PwJRWPn+2FT+Mu4f3FrmP66+xtrdhyA@mail.gmail.com>

Here are 2,800 JavaScript files in CRAN packages:

https://github.com/search?q=org%3Acran+path%3Amin.js+-path%3ALICENSE.txt&type=code

You might have a look at those. To Duncan's point, note there are also
0 min.js files:

https://github.com/search?q=org%3Acran+path%3Amin.js+-path%3ALICENSE.txt&type=code

Mike C

On Fri, Feb 21, 2025 at 9:01?AM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 2025-02-20 12:36 p.m., Brian Leonard wrote:
> > Hello there,
> >
> > [TLDR: I'm curious to know the degree to which including a pure javascript program (via the V8 package) in an R package affects the potential of passing CRAN review]
> >
> > I'm working on implementing an R package to support users of the Psych-DS data specification<https://github.com/psych-ds>. The package will include a shiny app with helpful functions for assembling and publishing high-quality datasets in the behavioral sciences, but one of the core functions will be to validate existing datasets (local directories) according to the rules of our schema.
> >
> > We already have this validator functionality set up as a Deno application, and we can use certain Deno tools, along with esbuild, to generate node-based and pure-javascript bundled versions of validator.
> >
> > We'd like to be able to leverage our existing code instead of having to reinvent the wheel for the R context. If we try to publish our package to CRAN with this javascript script as a core part of the package's functionality, will that severely affect our chances of passing the review process? I know that having sufficient unit tests and well documented processes is crucial to getting a package through, but the validator code in this scenario would be stringy and minified, and the bundle would not include unit tests for all the validator's internal functions. Is it the case that a dependency like this is equally subject to CRAN review scrutiny, or would it be sufficient to have all the R-based components comply with CRAN requirements?
>
> I am not a member of CRAN, so I can't give you authoritative advice on
> this.  But I think one issue is that if you are only including minified
> code, then they wouldn't see that as the original source.  My rgl
> package includes a few thousand lines of Javascript code which is
> minified when installed; the tarball contains the original source.
>
> Duncan Murdoch
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From jonthegeek @end|ng |rom gm@||@com  Sat Feb 22 17:20:07 2025
From: jonthegeek @end|ng |rom gm@||@com (Jon Harmon)
Date: Sat, 22 Feb 2025 10:20:07 -0600
Subject: [R-pkg-devel] Package with JS dependency
In-Reply-To: <mailman.11332.13.1740222002.4427.r-package-devel@r-project.org>
References: <mailman.11332.13.1740222002.4427.r-package-devel@r-project.org>
Message-ID: <CAAEaqJELq3q=CHX7YVgXXNs62+4JsiPbaYsNrfSCfEcYDP10cA@mail.gmail.com>

There are definitely packages with minified JS. I suspect this GitHub
search policy is causing the empty search: "Vendored and generated code is
excluded"

Even with "is:generated" and/or "is:vendored", I can't get a search to find
this, for example:
https://github.com/cran/cookies/blob/eb72bda92734d7537061e008191c2041dbe49dff/inst/js/js.cookie.min.js

On  Fri, 21 Feb 2025 09:06 AM Michael Chirico <michaelchirico4 at gmail.com>
wrote:

> You might have a look at those. To Duncan's point, note there are also
> 0 min.js files:
>
>
> https://github.com/search?q=org%3Acran+path%3Amin.js+-path%3ALICENSE.txt&type=code

	[[alternative HTML version deleted]]


From m|ch@e|ch|r|co4 @end|ng |rom gm@||@com  Sat Feb 22 17:30:26 2025
From: m|ch@e|ch|r|co4 @end|ng |rom gm@||@com (Michael Chirico)
Date: Sat, 22 Feb 2025 08:30:26 -0800
Subject: [R-pkg-devel] Package with JS dependency
In-Reply-To: <CAAEaqJELq3q=CHX7YVgXXNs62+4JsiPbaYsNrfSCfEcYDP10cA@mail.gmail.com>
References: <mailman.11332.13.1740222002.4427.r-package-devel@r-project.org>
 <CAAEaqJELq3q=CHX7YVgXXNs62+4JsiPbaYsNrfSCfEcYDP10cA@mail.gmail.com>
Message-ID: <CAPRVBcz0rgXJMBrcsG5X-YgfrwZ=oaVYzdSvEsSyPyiquU9ZnQ@mail.gmail.com>

Ah, thanks for looking into it further, I was a but surprised myself.
Apologies for the misstatement & added noise.

Could be that GitHub just doesn't index the potentially huge files, I've
come across that with my r-mailing-list-archive repo.

On Sat, Feb 22, 2025, 8:20?AM Jon Harmon <jonthegeek at gmail.com> wrote:

> There are definitely packages with minified JS. I suspect this GitHub
> search policy is causing the empty search: "Vendored and generated code is
> excluded"
>
> Even with "is:generated" and/or "is:vendored", I can't get a search to find
> this, for example:
>
> https://github.com/cran/cookies/blob/eb72bda92734d7537061e008191c2041dbe49dff/inst/js/js.cookie.min.js
>
> On  Fri, 21 Feb 2025 09:06 AM Michael Chirico <michaelchirico4 at gmail.com>
> wrote:
>
> > You might have a look at those. To Duncan's point, note there are also
> > 0 min.js files:
> >
> >
> >
> https://github.com/search?q=org%3Acran+path%3Amin.js+-path%3ALICENSE.txt&type=code
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Mon Feb 24 23:08:07 2025
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (NP))
Date: Mon, 24 Feb 2025 22:08:07 +0000
Subject: [R-pkg-devel] Package with JS dependency
In-Reply-To: <CAPRVBcz0rgXJMBrcsG5X-YgfrwZ=oaVYzdSvEsSyPyiquU9ZnQ@mail.gmail.com>
References: <mailman.11332.13.1740222002.4427.r-package-devel@r-project.org>
 <CAAEaqJELq3q=CHX7YVgXXNs62+4JsiPbaYsNrfSCfEcYDP10cA@mail.gmail.com>
 <CAPRVBcz0rgXJMBrcsG5X-YgfrwZ=oaVYzdSvEsSyPyiquU9ZnQ@mail.gmail.com>
Message-ID: <AS8PR08MB9193825BEB07E60EA42529DC8BC02@AS8PR08MB9193.eurprd08.prod.outlook.com>

Like Duncan's rgl package, the mathjaxr package (https://cran.r-project.org/package=mathjaxr) also contains JS code (for MathJax). And one of the requirements to get the package onto CRAN was that the source package had to contain the unminified javascript files. The minification then happens during the installation process with the help of the 'js' package (using the lovely named uglify_files() function). So if you want to get the package on CRAN, I suspect you would have to go a similar route.

Best,
Wolfgang

> -----Original Message-----
> From: R-package-devel <r-package-devel-bounces at r-project.org> On Behalf Of
> Michael Chirico
> Sent: Saturday, February 22, 2025 17:30
> To: Jon Harmon <jonthegeek at gmail.com>
> Cc: R Package Development <r-package-devel at r-project.org>
> Subject: Re: [R-pkg-devel] Package with JS dependency
>
> Ah, thanks for looking into it further, I was a but surprised myself.
> Apologies for the misstatement & added noise.
>
> Could be that GitHub just doesn't index the potentially huge files, I've
> come across that with my r-mailing-list-archive repo.
>
> On Sat, Feb 22, 2025, 8:20?AM Jon Harmon <jonthegeek at gmail.com> wrote:
>
> > There are definitely packages with minified JS. I suspect this GitHub
> > search policy is causing the empty search: "Vendored and generated code is
> > excluded"
> >
> > Even with "is:generated" and/or "is:vendored", I can't get a search to find
> > this, for example:
> >
> https://github.com/cran/cookies/blob/eb72bda92734d7537061e008191c2041dbe49dff/in
> st/js/js.cookie.min.js
> >
> > On  Fri, 21 Feb 2025 09:06 AM Michael Chirico <michaelchirico4 at gmail.com>
> > wrote:
> >
> > > You might have a look at those. To Duncan's point, note there are also
> > > 0 min.js files:
> > >
> > https://github.com/search?q=org%3Acran+path%3Amin.js+-
> path%3ALICENSE.txt&type=code

From edd @end|ng |rom deb|@n@org  Mon Feb 24 23:34:08 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Mon, 24 Feb 2025 16:34:08 -0600
Subject: [R-pkg-devel] Package with JS dependency
In-Reply-To: <AS8PR08MB9193825BEB07E60EA42529DC8BC02@AS8PR08MB9193.eurprd08.prod.outlook.com>
References: <mailman.11332.13.1740222002.4427.r-package-devel@r-project.org>
 <CAAEaqJELq3q=CHX7YVgXXNs62+4JsiPbaYsNrfSCfEcYDP10cA@mail.gmail.com>
 <CAPRVBcz0rgXJMBrcsG5X-YgfrwZ=oaVYzdSvEsSyPyiquU9ZnQ@mail.gmail.com>
 <AS8PR08MB9193825BEB07E60EA42529DC8BC02@AS8PR08MB9193.eurprd08.prod.outlook.com>
Message-ID: <26556.62432.869253.701845@rob.eddelbuettel.com>


On 24 February 2025 at 22:08, Viechtbauer, Wolfgang (NP) wrote:
| Like Duncan's rgl package, the mathjaxr package (https://cran.r-project.org/package=mathjaxr) also contains JS code (for MathJax). And one of the requirements to get the package onto CRAN was that the source package had to contain the unminified javascript files. The minification then happens during the installation process with the help of the 'js' package (using the lovely named uglify_files() function). So if you want to get the package on CRAN, I suspect you would have to go a similar route.

It is not only CRAN who may require it but _other downstream uses_ might too:
I maintain (among other packages) rgl and mathjaxr for Debian, and Debian
requires 'un-minified' sources (for the usual reasons of being able to make
changes to open source code) so the compromise of 'un-minified in source,
possibly minified in installed package' is something that seems to work for
everybody.

Cheers, Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From k@b||@n151414 @end|ng |rom gm@||@com  Wed Feb 26 09:57:10 2025
From: k@b||@n151414 @end|ng |rom gm@||@com (KABILAN S)
Date: Wed, 26 Feb 2025 08:57:10 +0000
Subject: [R-pkg-devel] =?iso-8859-1?q?How_do_you_make_it=A0possible_to_ru?=
 =?iso-8859-1?q?n_the_example_that_requires_a=A0Conda_environment=3F?=
Message-ID: <AS8PR02MB101481E0D5A2A3073DE0B9486ACC22@AS8PR02MB10148.eurprd02.prod.outlook.com>

I have given an example in an R function which requires a Conda environment, tensorflow, keras, and pandas to run. I can run the example in my local system. But if I submit the package to CRAN, the example is not running and returning an error message. Even if I mention \donttest{} to avoid the automatic checking of example, the CRAN team members are not allowing. How can I solve this problem?

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Wed Feb 26 12:49:56 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 26 Feb 2025 14:49:56 +0300
Subject: [R-pkg-devel] 
 How do you make it possible to run the example that
 requires a Conda environment?
In-Reply-To: <AS8PR02MB101481E0D5A2A3073DE0B9486ACC22@AS8PR02MB10148.eurprd02.prod.outlook.com>
References: <AS8PR02MB101481E0D5A2A3073DE0B9486ACC22@AS8PR02MB10148.eurprd02.prod.outlook.com>
Message-ID: <20250226144956.21c5e1c4@arachnoid>

? Wed, 26 Feb 2025 08:57:10 +0000
KABILAN S <kabilan151414 at gmail.com> ?????:

> if I submit the package to CRAN, the example is not running and
> returning an error message. Even if I mention \donttest{} to avoid
> the automatic checking of example, the CRAN team members are not
> allowing.

Does it help to use if (reticulate::py_module_available(...)) { ... }
instead of \donttest{...} in your examples?

https://cran.r-project.org/web/packages/reticulate/vignettes/package.html#checking-and-testing-on-cran

-- 
Best regards,
Ivan


From mccrowey@c||nton @end|ng |rom ep@@gov  Fri Mar  7 14:21:19 2025
From: mccrowey@c||nton @end|ng |rom ep@@gov (McCrowey, Clinton)
Date: Fri, 7 Mar 2025 13:21:19 +0000
Subject: [R-pkg-devel] 
 How do you make it possible to run the example that
 requires a Conda environment?
In-Reply-To: <20250226144956.21c5e1c4@arachnoid>
References: <AS8PR02MB101481E0D5A2A3073DE0B9486ACC22@AS8PR02MB10148.eurprd02.prod.outlook.com>
 <20250226144956.21c5e1c4@arachnoid>
Message-ID: <CO6PR09MB78942AC6C421FECD5502824F96D52@CO6PR09MB7894.namprd09.prod.outlook.com>

I wrapped my examples in \dontrun{} and the CRAN maintainers never complained to me.



Clinton Mccrowey |  Physical Scientist | U.S. Environmental Protection Agency - Region III | Air and Radiation Division | Office Number: 14-202 | Air Quality Analysis Branch | Philadelphia, PA | Mail Code: 3AD40 | Email: mccrowey.clinton at epa.gov | Phone: 215-814-2157 | Fax: 215-814-2124

-----Original Message-----
From: R-package-devel <r-package-devel-bounces at r-project.org> On Behalf Of Ivan Krylov via R-package-devel
Sent: Wednesday, February 26, 2025 6:50 AM
Cc: r-package-devel at r-project.org
Subject: Re: [R-pkg-devel] How do you make it possible to run the example that requires a Conda environment?

Caution: This email originated from outside EPA, please exercise additional caution when deciding whether to open attachments or click on provided links.


? Wed, 26 Feb 2025 08:57:10 +0000
KABILAN S <kabilan151414 at gmail.com> ?????:

> if I submit the package to CRAN, the example is not running and
> returning an error message. Even if I mention \donttest{} to avoid the
> automatic checking of example, the CRAN team members are not allowing.

Does it help to use if (reticulate::py_module_available(...)) { ... } instead of \donttest{...} in your examples?

https://cran.r-project.org/web/packages/reticulate/vignettes/package.html#checking-and-testing-on-cran

--
Best regards,
Ivan

______________________________________________
R-package-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-package-devel


From jo@|@h@p@rry @end|ng |rom gm@||@com  Fri Mar  7 16:36:42 2025
From: jo@|@h@p@rry @end|ng |rom gm@||@com (Josiah Parry)
Date: Fri, 7 Mar 2025 07:36:42 -0800
Subject: [R-pkg-devel] 
 How do you make it possible to run the example that
 requires a Conda environment?
In-Reply-To: <CO6PR09MB78942AC6C421FECD5502824F96D52@CO6PR09MB7894.namprd09.prod.outlook.com>
References: <AS8PR02MB101481E0D5A2A3073DE0B9486ACC22@AS8PR02MB10148.eurprd02.prod.outlook.com>
 <20250226144956.21c5e1c4@arachnoid>
 <CO6PR09MB78942AC6C421FECD5502824F96D52@CO6PR09MB7894.namprd09.prod.outlook.com>
Message-ID: <CAL3ufU+-rbENGJ+MKXwpbbpjB5XPEoxJZLvc0gbAX+QUFdXPsQ@mail.gmail.com>

Whereas, I just had a CRAN submission fail for using \dontrun{} just once!
?

On Fri, Mar 7, 2025 at 06:47 McCrowey, Clinton via R-package-devel <
r-package-devel at r-project.org> wrote:

> I wrapped my examples in \dontrun{} and the CRAN maintainers never
> complained to me.
>
>
>
> Clinton Mccrowey |  Physical Scientist | U.S. Environmental Protection
> Agency - Region III | Air and Radiation Division | Office Number: 14-202 |
> Air Quality Analysis Branch | Philadelphia, PA | Mail Code: 3AD40 | Email:
> mccrowey.clinton at epa.gov | Phone: 215-814-2157 | Fax: 215-814-2124
>
> -----Original Message-----
> From: R-package-devel <r-package-devel-bounces at r-project.org> On Behalf
> Of Ivan Krylov via R-package-devel
> Sent: Wednesday, February 26, 2025 6:50 AM
> Cc: r-package-devel at r-project.org
> Subject: Re: [R-pkg-devel] How do you make it possible to run the example
> that requires a Conda environment?
>
> Caution: This email originated from outside EPA, please exercise
> additional caution when deciding whether to open attachments or click on
> provided links.
>
>
> ? Wed, 26 Feb 2025 08:57:10 +0000
> KABILAN S <kabilan151414 at gmail.com> ?????:
>
> > if I submit the package to CRAN, the example is not running and
> > returning an error message. Even if I mention \donttest{} to avoid the
> > automatic checking of example, the CRAN team members are not allowing.
>
> Does it help to use if (reticulate::py_module_available(...)) { ... }
> instead of \donttest{...} in your examples?
>
>
> https://cran.r-project.org/web/packages/reticulate/vignettes/package.html#checking-and-testing-on-cran
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From br|@n @end|ng |rom br@verock@com  Fri Mar  7 16:57:41 2025
From: br|@n @end|ng |rom br@verock@com (Brian G. Peterson)
Date: Fri, 07 Mar 2025 09:57:41 -0600
Subject: [R-pkg-devel] 
 How do you make it possible to run the example that
 requires a Conda environment?
In-Reply-To: <CAL3ufU+-rbENGJ+MKXwpbbpjB5XPEoxJZLvc0gbAX+QUFdXPsQ@mail.gmail.com>
References: <AS8PR02MB101481E0D5A2A3073DE0B9486ACC22@AS8PR02MB10148.eurprd02.prod.outlook.com>
 <20250226144956.21c5e1c4@arachnoid>
 <CO6PR09MB78942AC6C421FECD5502824F96D52@CO6PR09MB7894.namprd09.prod.outlook.com>
 <CAL3ufU+-rbENGJ+MKXwpbbpjB5XPEoxJZLvc0gbAX+QUFdXPsQ@mail.gmail.com>
Message-ID: <49fb48e535907215d75d1348743aaee03933a035.camel@braverock.com>

\dontrun{} is allowed by CRAN. ?If your package got rejected for using
\dontrun{} I would guess that maybe your example needs a package that
isn't in "Suggests" in your DESCRIPTION file. ?Even in \dontrun{} you
should still tell the user that certain packages may be needed to
access specific optional functionality.

-- 
Brian G. Peterson
ph: +1.773.459.4973
im: bgpbraverock

On Fri, 2025-03-07 at 07:36 -0800, Josiah Parry wrote:
> Whereas, I just had a CRAN submission fail for using \dontrun{} just
> once!
> ?
> 
> On Fri, Mar 7, 2025 at 06:47 McCrowey, Clinton via R-package-devel <
> r-package-devel at r-project.org> wrote:
> 
> > I wrapped my examples in \dontrun{} and the CRAN maintainers never
> > complained to me.
> > 
> > 
> > 
> > Clinton Mccrowey |? Physical Scientist | U.S. Environmental
> > Protection
> > Agency - Region III | Air and Radiation Division | Office Number:
> > 14-202 |
> > Air Quality Analysis Branch | Philadelphia, PA | Mail Code: 3AD40 |
> > Email:
> > mccrowey.clinton at epa.gov?| Phone: 215-814-2157 | Fax: 215-814-2124
> > 
> > -----Original Message-----
> > From: R-package-devel <r-package-devel-bounces at r-project.org> On
> > Behalf
> > Of Ivan Krylov via R-package-devel
> > Sent: Wednesday, February 26, 2025 6:50 AM
> > Cc: r-package-devel at r-project.org
> > Subject: Re: [R-pkg-devel] How do you make it possible to run the
> > example
> > that requires a Conda environment?
> > 
> > Caution: This email originated from outside EPA, please exercise
> > additional caution when deciding whether to open attachments or
> > click on
> > provided links.
> > 
> > 
> > ? Wed, 26 Feb 2025 08:57:10 +0000
> > KABILAN S <kabilan151414 at gmail.com> ?????:
> > 
> > > if I submit the package to CRAN, the example is not running and
> > > returning an error message. Even if I mention \donttest{} to
> > > avoid the
> > > automatic checking of example, the CRAN team members are not
> > > allowing.
> > 
> > Does it help to use if (reticulate::py_module_available(...)) { ...
> > }
> > instead of \donttest{...} in your examples?
> > 
> > 
> > https://cran.r-project.org/web/packages/reticulate/vignettes/package.html#checking-and-testing-on-cran
> > 
> > --
> > Best regards,
> > Ivan
> > 
> > ______________________________________________
> > R-package-devel at r-project.org?mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-package-devel
> > 
> > ______________________________________________
> > R-package-devel at r-project.org?mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-package-devel
> > 
> 
> ????????[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org?mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> 

	[[alternative HTML version deleted]]


From @tephen@@br@m@ @end|ng |rom gm@||@com  Sun Mar  9 20:03:00 2025
From: @tephen@@br@m@ @end|ng |rom gm@||@com (Stephen Abrams)
Date: Sun, 9 Mar 2025 15:03:00 -0400
Subject: [R-pkg-devel] How to resolve missing packages without Notes
Message-ID: <CAE_v-D6HrMoBMm1nu_a_JSbErad0ZkhP6FN_AF-y0APHuzLYDg@mail.gmail.com>

Hi again - I'm working through the final details of a submission. My
current problem is that I make use of a dependency of the caret package
(kernlab) in one of my vignettes. If I don't include kernlab in my
DESCRIPTION file, I get the following ERROR:

* checking re-building of vignette outputs ... [16s] ERROR
Error(s) in re-building vignettes:
--- re-building 'create_synthetic_data.Rmd' using rmarkdown
--- finished re-building 'create_synthetic_data.Rmd'

--- re-building 'modeling_with_binary_classifiers.Rmd' using rmarkdown

Quitting from lines 56-63 [unnamed-chunk-4]
(modeling_with_binary_classifiers.Rmd)
Error: processing vignette 'modeling_with_binary_classifiers.Rmd' failed
with diagnostics:
Required packages are missing: kernlab
--- failed re-building 'modeling_with_binary_classifiers.Rmd'

If I do include kernlab as a dependency in my DESCRIPTION file, I get the
following NOTE:

* checking dependencies in R code ... NOTE
Packages in Depends field not imported from:
  'kernlab' 'randomForest'
  These packages need to be imported from (in the NAMESPACE file)
  for when this namespace is loaded but not attached.

My NAMESPACE file is auto-generated by roxygen and actually says not to
edit it. I think the problem is the implicit dependency inside caret, but
I'm not sure how to solve it so the automated checks work. When I run this
on my own machine, it passes the --as-cran check. Any advice would be
greatly appreciated.

Thanks!


-- 
Stephen Abrams
Divergent Blue <http://www.divergentblue.com/>

	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Sun Mar  9 20:12:46 2025
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Sun, 9 Mar 2025 14:12:46 -0500
Subject: [R-pkg-devel] How to resolve missing packages without Notes
In-Reply-To: <CAE_v-D6HrMoBMm1nu_a_JSbErad0ZkhP6FN_AF-y0APHuzLYDg@mail.gmail.com>
References: <CAE_v-D6HrMoBMm1nu_a_JSbErad0ZkhP6FN_AF-y0APHuzLYDg@mail.gmail.com>
Message-ID: <26573.59438.228939.875461@rob.eddelbuettel.com>


On 9 March 2025 at 15:03, Stephen Abrams wrote:
| Hi again - I'm working through the final details of a submission. My
| current problem is that I make use of a dependency of the caret package
| (kernlab) in one of my vignettes. If I don't include kernlab in my
| DESCRIPTION file, I get the following ERROR:
[...]
| My NAMESPACE file is auto-generated by roxygen and actually says not to

You need to edit DESCRIPTION (by hand). That is all that there is, and
_Writing R Extensions_ is fairly clear about this. Here is a quote from
Section 1.1.3

     The ?Suggests? field uses the same syntax as ?Depends? and lists
  packages that are not necessarily needed.  This includes packages used
  only in examples, tests or vignettes (*note Writing package
  vignettes::), and packages loaded in the body of functions.

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From @tephen@@br@m@ @end|ng |rom gm@||@com  Sun Mar  9 23:41:21 2025
From: @tephen@@br@m@ @end|ng |rom gm@||@com (Stephen Abrams)
Date: Sun, 9 Mar 2025 18:41:21 -0400
Subject: [R-pkg-devel] How to resolve missing packages without Notes
In-Reply-To: <26573.59438.228939.875461@rob.eddelbuettel.com>
References: <CAE_v-D6HrMoBMm1nu_a_JSbErad0ZkhP6FN_AF-y0APHuzLYDg@mail.gmail.com>
 <26573.59438.228939.875461@rob.eddelbuettel.com>
Message-ID: <CAE_v-D5VA4R5o8df+gE3QKG7fDEKVAhp2Ppxc1M0ufMdMJGR3g@mail.gmail.com>

Awesome - much appreciated. I think I'm missing the forest for the trees at
this point - thanks!

On Sun, Mar 9, 2025 at 3:12?PM Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 9 March 2025 at 15:03, Stephen Abrams wrote:
> | Hi again - I'm working through the final details of a submission. My
> | current problem is that I make use of a dependency of the caret package
> | (kernlab) in one of my vignettes. If I don't include kernlab in my
> | DESCRIPTION file, I get the following ERROR:
> [...]
> | My NAMESPACE file is auto-generated by roxygen and actually says not to
>
> You need to edit DESCRIPTION (by hand). That is all that there is, and
> _Writing R Extensions_ is fairly clear about this. Here is a quote from
> Section 1.1.3
>
>      The ?Suggests? field uses the same syntax as ?Depends? and lists
>   packages that are not necessarily needed.  This includes packages used
>   only in examples, tests or vignettes (*note Writing package
>   vignettes::), and packages loaded in the body of functions.
>
> Dirk
>
> --
> dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>


-- 
Stephen Abrams
Divergent Blue <http://www.divergentblue.com/>

	[[alternative HTML version deleted]]


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Mon Mar 10 12:29:53 2025
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Mon, 10 Mar 2025 12:29:53 +0100
Subject: [R-pkg-devel] 
 How do you make it possible to run the example that
 requires a Conda environment?
In-Reply-To: <49fb48e535907215d75d1348743aaee03933a035.camel@braverock.com>
References: <AS8PR02MB101481E0D5A2A3073DE0B9486ACC22@AS8PR02MB10148.eurprd02.prod.outlook.com>
 <20250226144956.21c5e1c4@arachnoid>
 <CO6PR09MB78942AC6C421FECD5502824F96D52@CO6PR09MB7894.namprd09.prod.outlook.com>
 <CAL3ufU+-rbENGJ+MKXwpbbpjB5XPEoxJZLvc0gbAX+QUFdXPsQ@mail.gmail.com>
 <49fb48e535907215d75d1348743aaee03933a035.camel@braverock.com>
Message-ID: <00f2c98a-69f7-40a9-ab2d-95add9061736@statistik.tu-dortmund.de>



On 07.03.2025 16:57, Brian G. Peterson wrote:
> \dontrun{} is allowed by CRAN. ?If your package got rejected for using
> \dontrun{} I would guess that maybe your example needs a package that
> isn't in "Suggests" in your DESCRIPTION file. ?Even in \dontrun{} you
> should still tell the user that certain packages may be needed to
> access specific optional functionality.
> 

A package will rejected if \dontrun is not needed and there are better 
ways to structure the examples. Frequently code such as Ivan's proposal

    (reticulate::py_module_available(...)) { ... }

is perferrable, so that the code runs if the requirements are fullfilled 
/ suggested packages are available.

Best,
Uwe Ligges





